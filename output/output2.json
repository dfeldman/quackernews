[
  {
    "title": "Building LLMs from the Ground Up: A 3-Hour Coding Workshop (sebastianraschka.com)",
    "points": 212,
    "submitter": "mdp2021",
    "submit_time": "2024-08-31T21:45:59",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41412256",
    "comments": [
      "This is excellent. Thanks for sharing. It's always good to go back to the fundamentals. There's another resource that is also quite good: https://jaykmody.com/blog/gpt-from-scratch/\n \nreply",
      "Excuse my ignorance, is this different from Andrej Karpathy https://www.youtube.com/watch?v=kCc8FmEb1nYAnyway I will watch it tonight before bed. Thank you for sharing.\n \nreply",
      "Andrej's series is excellent, Sebastian's book + this video are excellent. There's a lot of overlap but they go into more detail on different topics or focus on different things. Andrej's entire series is absolutely worth watching, his upcoming Eureka Labs stuff is looking extremely good too. Sebastian's blog and book are definitely worth the time and money IMO.\n \nreply",
      "[flagged]",
      "fair point bud\n \nreply",
      "Nice write up Sebastian, looking forward to the book. There are lots of details on the LLM and how it\u2019s composed, would be great if you can expand on how Llama and OpenAI could be cleaning and structuring their training data given it seems this is where the battle is heading in the long run.\n \nreply"
    ],
    "link": "https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up",
    "first_paragraph": "",
    "summary": "**Today in self-important tech circles:** A brave coder heroically condenses years of AI education into a <em>thrilling</em> 3-hour YouTube marathon, sparking an intellectual inferno under the \"Learn Quick\" crowd. Commenters <i>eagerly</i> throw digital laurels at the instructions for basically reinventing what ten other people explained last week, blissfully ignoring that the key to AI mastery probably doesn't lie in a single workshop binge. Meanwhile, another user, itching to show off their follower-boosting skills, drops a link to an equally vital resource, ensuring everyone knows there are at least two corners of the internet where one can watch the future be misinterpreted in real-time. \ud83c\udf93\ud83d\ude80\ud83d\udca5"
  },
  {
    "title": "Boox Palma Review: A Phone-Sized E-Ink Android Device That Isn't a Phone (ewritable.com)",
    "points": 51,
    "submitter": "todsacerdoti",
    "submit_time": "2024-08-31T22:40:00",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=41412582",
    "comments": [
      "I don't like being negative, but I feel like I am obligated to pipe up every time I see Onyx products hit the front page here[0], because I was one of the people who politely requested that Onyx abide by the terms of the licenses for the Free Software that they use in their products. To this day, they refuse to do so.- Onyx still doesn't release kernel sources for their products.- Onyx still uses outdated and vulnerable builds of Android, with questionable settings such as disabling SELinux- Their devices are very chatty back to servers in the PRC. And their privacy policies are pretty bad (and by bad, I mean non-existant! [1])- Their digitizer API is not very documented and difficult to build off of, so claims of being friendly to 3rd party developers are overblown.- They shut down their support forums when the chorus of disgruntled customers began to get too loudAnd even worse, they are using claims of \"anti-China movement\" as an excuse to not comply with the GPL [2].Please, we've got to stop shilling this company's products with these affiliate-link blogs. They seem completely opposed to the hacker 'ethos' of this site. Otherwise, why not also shill the hundreds of Oppo or Honor or Huawei phones being released every year?Edit: To give a positive remark, I recommend the reMarkable tablet. It's what I purchased after I sold my onyx tablet. It runs linux and they give you root access out of the box! There is a vibrant community of people developing programs for the rM and even running other linux distros on the device.[0]: https://news.ycombinator.com/item?id=21041543[1]: https://foundation.mozilla.org/en/privacynotincluded/onyx-bo...[2]: https://old.reddit.com/r/Onyx_Boox/comments/hsn7kx/onyx_usin...\n \nreply",
      "This company and its products keep gracing the HN front page. I'm not sure why.Flagging the article will help.\n \nreply",
      "I tried their 25 inch monitor. E-Ink is such a better experience. I don't feel so jacked in to the matrix when I use it.The ghosting and refresh rate are holding this technology back though. Definitely not main driver status yet.LED and LCD screens seem to shift the brain into an agitated frequency. I wish they'd make more progress with E-Ink!\n \nreply",
      "The Moaan Plus (available on AliExpress and from other dropshipping marketplaces) also sports an e-ink display in a similar size, is significantly cheaper, and just as functional as a single-purpose e-reader device. Just takes a bit of tweaking to overcome the initially chinese-only interface and sideload a replacement keyboard (the default one is horrendous) and e-reader apps.\n \nreply",
      "I have a Boox Nova and it\u2019s really nice but I won\u2019t buy another one. Boox is a notorious GPL violator.\n \nreply",
      "Kobo e-readers run Android under the hood. There are some very small ones, too. If you're cool with Pocket, you can use that to sync articles from browser to e-reader. Personally, I never have my Kobo online.\n \nreply",
      "I feel like this device would be 10x more compelling if it had an actual modem.Like, the software looks decent, the display is nice, the battery life is good. But why would you use it if you have to carry a separate phone? Surely it wasn't that hard?\n \nreply",
      "The target audience is probably:- Already carrying around a larger, heavier ereader- Not interested in using an e-ink display for stuff like videos, instagram\n \nreply",
      "I've been using this thing daily for about five months and really adore it. I use it as a Kindle replacement and with Readwise Reader as a longform article dump. I've read more longform pieces in the last few months than last few years combined. The device is incredibly light, and maintains battery even if you leave it idle all day (unlike my kindles which often drained themselves). Anyway, it's been a nice surprise, the palma.[0][0]: https://craigmod.com/roden/091/#digital-reading-in-2024\n \nreply",
      "I have been seriously considering picking up one of these for a dedicate e-reader device just for The Economist (using a custom version of the Economist I create every week), mostly for around my house.The main thing holding me back is still needing to carry two devices when im mobile, and of course, investing in hardware for a single publication.I really prefer reading on e-ink, I like the form factor of this, and the performance seems decent for reading.\n \nreply"
    ],
    "link": "https://ewritable.com/ereaders/boox-palma/review/",
    "first_paragraph": "A very portable 'candy-bar style' Android e-reader that supports higher refresh rates and third-party apps.When I first found out about the Palma, I was very excited. Had Boox succeeded where Hisense had failed? Would I finally be able to achieve my dream of replacing my Samsung LCD Android phone with an e-ink Android phone?My excitement very quickly waned \u2013 the Boox Palma would not have a sim card slot.My next thoughts were What is the point of the Boox Palma? and Who would use a phone-sized Android device that doesn\u2019t support mobile connectivity?Whilst I pondered these questions, Boox sent me a review unit to check the Palma out for myself. I\u2019ve been using it for a little over a month and my thoughts are below:NOTE: For full transparency, the review unit that Boox sent me was a pre-release version and so may be slightly different from the final product. It had not been water-protected and the left sidebutton didn\u2019t work. In addition, there was no camera app installed. These issues wi",
    "summary": "Title: Boox Palma Review: A Whopping Disappointment Disguised as Innovation\n\nIn an attempt to revolutionize the way we don't make phone calls, Boox introduces the Palma: a phone-sized e-ink device that bravely forgoes essential phone features like a SIM card slot. Tech enthusiasts everywhere are disillusioned as their dreams of ditching their Samsungs for something less capable are mercilessly dashed. Meanwhile, in the comments, a mix of disillusioned technophiles and open-source advocates lament Boox's apparent allergy to GPL compliance and privacy. But hey, who needs cellular connectivity or software updates when you can enjoy that sweet, sweet e-ink display...while standing next to a Wi-Fi router or another actual phone, presumably."
  },
  {
    "title": "My first experience with Gleam Language (pliutau.com)",
    "points": 31,
    "submitter": "crowdhailer",
    "submit_time": "2024-08-27T12:01:28",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41366614",
    "comments": [
      "I have been slowly getting acquainted with the language over the last few months and I really love it. It combines great features from multiple languages into a single one that is perfect for building back-end web apps:\n- It is strongly typed, and has sum types like Rust, with very similar syntax, nice error messages, full type inference and first-party LSP implementation for great IDE tooling;\n- Unlike Rust, it is a high level language with garbage collection and a sane concurrency mechanism;\n- It follows the same concurrency paradigm from Erlang, since it is compiled to it and runs in the BEAM. It is quite performant for I/O stuff, apparently in the same ballpark as Go;\n- It can also be compiled to JS either to run either in the back-end or the front-end side, making it possible to build isomorphic web apps if that's your thing.\n \nreply",
      "I'd love something like Gleam, but it compiles to a single binary and isn't Rust. (I know that that binary would invariably be larger than something Rust might produce due to the need to include things like a GC or BEAM process manager.)\n \nreply"
    ],
    "link": "https://pliutau.com/my-first-experience-with-gleam-lang/",
    "first_paragraph": "\n\t\t\t\t\tSoftware Engineering Lead passionate about Backend, Cloud, DevOps, APIs, Kubernetes, Go. Currently leading an engineering team at Solsten.\n\t\t\t\tOver the past few months, I saw a growing amount of posts on X about the Gleam language (probably the X algorithm doing its thing), and decided to give it a try. I was not disappointed, with few exceptions.Disclaimer 1: This post shares my personal experience with the language, and it is not a comprehensive review of the language. It\u2019s not sponsored by anyone, and I\u2019m not affiliated with the Gleam team.Disclaimer 2: I had little prior experience with Erlang VM or functional programming in general.The first thing I did was to go through the official Gleam Language Tour which was a pleasure. After an hour I familiarized myself with the syntax and the basic concepts of the language. I remember that\u2019s how I started with Go as well, and I believe that every language must have an interactive tour like this.The next thing I did was to install the",
    "summary": "**Title: Another Day, Another Programming Language**\n\nIn an exciting twist that absolutely no one asked for, a Software Engineering Lead becomes infatuated with Gleam language after being brainwashed by social media algorithms. Marvel as he rediscovers basic programming concepts and celebrates his monumental one-hour journey through the language's tutorial. Meanwhile, commenters emerge from the woodwork with their hot takes, demanding a language that combines the safety of Rust with the obscurity of BEAM, yet magically compacts everything into a single binary. Is it innovation or just digital hipsterism? Gather 'round for the collective tech buzzword bingo. \ud83c\udf89\ud83d\udc68\u200d\ud83d\udcbb"
  },
  {
    "title": "Harder Drive: hard drives we didn't want, or need [video] (2022) (tom7.org)",
    "points": 264,
    "submitter": "pabs3",
    "submit_time": "2024-08-31T15:21:30",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=41409503",
    "comments": [
      "Do yourself a favor and watch the entire back catalog. Not sure there\u2019s anyone more creative than tom7 working right now.\n \nreply",
      "Seconded. My first experience with Tom7 was the \"Super Mario Bros. is Easy with Lexicographic Orderings and Time Travel...\" I've been hooked ever since.\n \nreply",
      "SIGBOVIK is always fantastic, and Tom7 is consistently the star of the show\n \nreply",
      "Some of these ideas are as old as time but the comic seriousness is great.Reminds me of older analog delay circuits where the signal was sent as a sound wave in glass IIRC ... with multiple taps for different delays.EDIT: Here's a cool example that maybe warrants its own submission: https://www.eevblog.com/forum/projects/glass-ultrasonic-dela...\n \nreply",
      "I wonder how many people here are discovering tom7 for the first time beacuse of this video.\n \nreply",
      "#metooIt\u2019s like when you think of  something that will never exist, because it is just too absurd. However, this guy not only has an even more absurd idea, he also brings it into existence and shows why it\u2019s a great idea to build a sustainable future!#nohate\n \nreply",
      "Wait until you encounter his executable research paper about executable research papers.The NAND gates video is probably the closest humanity will ever get to perfection though.\n \nreply",
      "Me!\n \nreply",
      "Does he always have so much vocal fry?\n \nreply",
      "I remember lcamtuf mentioning very similar concept ca. 2003.In his version you would partition secret data and send it out to non existing email addresses, just to get them bounced back within a couple of days.If you want to get your secrets back together you would simply start gathering appropriate parts (you need to keep track of all the chunks somewhere), otherwise you'd simply send them to another non existing email address.\n \nreply"
    ],
    "link": "http://tom7.org/harder/",
    "first_paragraph": "Please leave a comment on my blog or on Twitter at @tom7!\nGet all Tom 7 thingos at \u2192 [tom7.org]\nGet all Tom 7 thingos at \u2192 [tom7.org]",
    "summary": "**Harder Drive: Another Masterpiece or Just More Digital Clutter?**\n\nIn a world desperately in need of more digital hoarding, Tom7 swoops in with the solution nobody asked for: \"Harder Drive: hard drives we didn't want, or need.\" Watch as an individual crusades against the boundaries of practical technology while a chorus of adoring fans chants hymns of innovation in the comment section. Between exclamations of *genius* and comparisons to forgotten tech relics, it\u2019s clear our hero has once again managed to ensnare the minds of those who can't resist a quirky YouTube binge. So gather around, connoisseurs of the unnecessary, and add this to your \u201cWatch Later\u201d list right next to that documentary on artisanal sand counting. \ud83e\uddd0"
  },
  {
    "title": "Did your car witness a crime? (sfchronicle.com)",
    "points": 163,
    "submitter": "danso",
    "submit_time": "2024-08-31T16:21:27",
    "num_comments": 362,
    "comments_url": "https://news.ycombinator.com/item?id=41409882",
    "comments": [
      "As a somewhat regular user of Waymo, these types of conversations seem like they're going to be more and more in the (sorry!) rearview mirror because we won't own the car nor the cameras that are recording the world as we \"drive\" around.That's not to say that we should give up fighting for some level of privacy even when we don't own the cars, but seems more likely that legislation would be passed that forces the vehicle owners/operators (Alphabet in the Waymo case) to blur peoples' faces. Then of course the state (police/gov/etc.) will clamor for a backdoor key that will unlock the blurred faces/bodies if a crime is suspected to have occurred. Speaking of, I wonder if Waymo already does blur people when they capture them through Waymo rides? I can't seem to find mention of it online.This commentary assumes self-driving cars are here to stay and become the de facto way we drive instead of driving ourselves. Still not sure how their adoption plays out over time because, at least in the US, people will fight against mandates to use self-driving cars because it compromises their freedom (note that the freedom crowd (no judgment) will be saying that, at first, because they will consider it their right to drive themselves, but once the privacy implications are clear there will be full-on (figurative?) wars fought over self-driving). Guessing a politician, in Texas or another red state, will sooner than later enshrine the right-to-drive-oneself into the state constitution.\n \nreply",
      "I am hoping for an urban camouflage fashion revolution as a response to more pervasive monitoring: https://www.axios.com/2019/09/07/fooling-facial-recognition-...Public access to object recognition models may be important.\n \nreply",
      "I'd like to see that too, but time and time again we've seen that:a) laypeople aren't usually moved by privacy violations more abstract than someone physically watching you do something.b) most people aren't willing to don practical accessories that noticably change the perception of your face unless it emphasizes qualities considered sexy.c) safety gear generally isn't considered sexyI think that this stuff would be perceived like wearing a physical bike helmet for your data privacy with all the cachet of Google Glass.\n \nreply",
      "Surely object recognition models will catch up to whatever attempts to thwart it (especially if it becomes popular).  As long as a person is recognizable to another person, a computer should also be able to recognize them.Trying to camouflage seems like a losing battle.\n \nreply",
      "> these types of conversations seem like they're going to be more and more in the (sorry!) rearview mirror because we won't own the car nor the cameras that are recording the world as we \"drive\" around.Perhaps in the urban setting but the majority of this country is not contained within cities.  Even then are you planning on banning motorcycles and RVs?> because they will consider it their right to drive themselvesUntil a law is passed otherwise they are absolutely correct.> the right-to-drive-oneself into the state constitution.I doubt it.  The real fight is likely to be whether we continue using mixed vehicle and pedestrian infrastructure or if we force pedestrians off the roadway entirely.  Then we'll have a \"right to walk\" constitutional crisis.\n \nreply",
      "> Perhaps in the urban setting but the majority of this country is not contained within cities.83% of USA population live in urban areas, and that proportion is still steadily growing. The same trends apply everywhere else in the world as well.\n \nreply",
      "According to the 2020 US Census, about 80% live in an urban area. However, the definition is not exactly what people think of when you say \u201curban\u201d.In 2020, the census lists 2,611 urban areas, including areas with a few thousand people.https://www.census.gov/programs-surveys/geography/guidance/g...Shouldn\u2019t be too hard to break this down with a more colloquial definition (say, areas over 500k or 750k people). I\u2019m just not at a real computer :)\n \nreply",
      "Calumet park is a village right next to Chicago with under 7000 people. Northfield village has under 6000 people and it's located within about 15 miles of Chicago. It wasn't until I was about 18 that I realized what I thought was Chicago were actually small towns/villages. There's a whole slew of small villages next to or \"in\" larger cities.\n \nreply",
      "Yes; the ordinary thing to compare is MSAs, which take this into account; Calumet Park (and Blue Island and Oak Lawn) are all part of the Chicago MSA.\n \nreply",
      "> 83% of USA population live in urban areasIf you combine dense urban areas with suburbs.  It's about 33% in dense areas and 55% in suburban areas.  Which actually doesn't improve the driving situation.> and that proportion is still steadily growingWhich is why I specifically mentioned motorcycles.  In areas of the world with even greater urban density than the USA there are a lot of these on the road.> The same trends apply everywhere else in the world as well.These trends are influenced by economic policy and socioeconomic mobility of the population,  which are not similar everywhere,  so expectations do need to be tailored to them.Editing to add,  I actually think we'll see a new class of Drivers License,  one that allows you to operate semi autonomous vehicles,  and one that allows you to operate fully manual vehicles with a higher level of continuous written and on the road testing required to hold it.  Which is a reasonable and non discriminatory solution to the problem.\n \nreply"
    ],
    "link": "https://www.sfchronicle.com/crime/article/tesla-sentry-mode-police-evidence-19731000.php",
    "first_paragraph": "",
    "summary": "**Did Your Car Witness a Crime? The Overlords Would Like to Know**\n\nIn a stunning show of naivety, an article speculates on the future of privacy in our self-driving car utopia, where our very rides snitch on us. Commenters engage in a lively exercise of missing the point, debating the death of driving self-ownership with the urgency of discussing the extinction of the dinosaurs. As ideas of *'urban camouflage'* and *object recognition models*' supposed efficacy circulate, one can't help but laugh at the imminent fashion trend of data privacy helmets. Yes, prepare to dawn your Google Glass of privacy gear, all while the state keenly watches\u2014this time, with popcorn. \ud83c\udf7f"
  },
  {
    "title": "WatchYourLAN: Lightweight Network IP Scanner (github.com/aceberg)",
    "points": 80,
    "submitter": "thunderbong",
    "submit_time": "2024-08-31T19:32:12",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41411281",
    "comments": [
      "Where do you get your mac->vendor data from?  \"Hardware\" in your screen shot.Most OUI (MAC) lists I've seen seem to be very incomplete for what ever reason.\n \nreply",
      "Speaking about LAN, today, I encountered an unexpected event I had never imagined or experienced before.I was working on a simple HTML/CSS game in VS Code, with Live Server running on port 5500 to serve the site. Feeling a bit tired, I decided to take a break. I put my Windows PC to sleep and moved to another room in my house. There, I spotted my Android tablet and thought it would be interesting to see how the game would perform on a tablet.I unlocked the tablet, opened Chrome, entered my PC's local IP address and port, and hit 'Go'. To my surprise, the loading spinner appeared and spun for about 3-4 seconds. I was puzzled as to why the request was taking so long to get a response, and then it hit me\u2014my PC was supposed to be sleeping.Yet, just as I was processing this realization, the game\u2019s web page loaded on the tablet. I was stunned, thinking, \"Wait a minute\u2014didn't I put my PC to sleep?\" I went back to check my PC, and sure enough, it was awake but showing the lock screen. Out of curiosity, I repeated the experiment: I put the PC to sleep again, then accessed the webpage from my phone, and, once again, my PC awoke in response to the request. It was an eye-opening moment to see how the network request could wake my PC from sleep!I googled this behavior and turned out to be called Wake on LAN or, WOL for short [1].__________________1. https://learn.microsoft.com/en-us/troubleshoot/windows-clien...\n \nreply",
      "WoL relies on a special magic Ethernet frame being sent to the MAC of the sleeping computer. A normal ARP or TCP SYN from an incoming HTTP request won't do it. The wikipedia article has the exact frame format:\nhttps://en.wikipedia.org/wiki/Wake-on-LANI've seen setups where the router is configured to send the magic WoL packet when it sees an ARP for the IP of a computer it knows is sleeping, but you'd almost certainly know if you had an exotic configuration like that on your network.\n \nreply",
      "The terminology here can be a little confusing, because WoL isn't a precisely standardized term but rather sort of a general label for a family of behaviors, the most common of which is the \"Magic Packet\" that originated with AMD. For some time a magic packet was mostly the only thing that could wake a computer, because the NIC had to originate a power-on event and most NICs were only capable of doing so in response to a magic packet. There were, though, particularly in more \"enterprise\" contexts, NICs that could be configured to wake the machine on other types of traffic. This kind of thing went in the option ROM of high-end NICs.Today, though, with various low-power states and \"hybrid sleep,\" packets received while in a low-power state can actually be delivered to the operating system to make a decision on waking. That's made WoL a lot more complex: with a supported network adapter and power state, Windows will wake up in response to pretty much any network traffic directed at the sleeping computer. That detection is surprisingly sophisticated, unicast packets addressed to a computer will wake it, but so will certain recognized discovery protocols sent to broadcast when they specify the computer's hostname.One the one hand, it's pretty neat that e.g. attempting to connect to an SMB share on a Windows computer will wake it. On the other hand, it means that \"nuisance\" WoL has become an occasional irritation. For that reason you can configure Windows back to the original behavior of only waking on a magic packet specifically. To be fair, the whole idea came about in part because of all the implementation limitations with magic packets that made them very flaky.Microsoft refers to all of this functionality with the term \"WoL,\" while Apple seems to have decided to avoid the confusion by calling the entire concept \"Wake on Demand\" instead.\n \nreply",
      "Some cards seem to allow any packet, not just the WoL magic packet to wake the machine.  This is referenced in the Wikipedia article as \"Wake on Link\"You can change this.  From memory it was directly in the Control Panel for Windows.  And ethtool or similar in Linux.\n \nreply",
      "WOL is an old feature where you could even boot a PC that is off, not just asleep, but you had to confine it in the BIOS. It has become less useful with computers able to go into power save modes that are almost as good as having it fully off energy-wise.\n \nreply",
      "Cool now tune it with Everything and let it show me data consumption by file||process|egress-addrhttps://i.imgur.com/RJYldEq.pngintegrate with poly || htop || etchttps://www.ycombinator.com/companies/poly/jobs/L4ObRgn-foun...and give me a screen of IOs for egress ingress with nifty UFW UI\n \nreply"
    ],
    "link": "https://github.com/aceberg/WatchYourLAN",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Lightweight network IP scanner. Can be used to notify about new hosts and monitor host online/offline history\n      \n\n\n\nLightweight network IP scanner with web GUI. Features:WarningThis is version 2.0. Version 1.0 can be found in this brunch: v1CautionBREAKING CHANGES! Version 2.0 is not compatible with v1.0. For now v2.0 docker images will be released under v2 tag. It will be tagged latest in a few weeks (probably, in October).\n\n\nReplace $YOURTIMEZONE with correct time zone and $YOURIFACE with network interface you want to scan. Network mode must be host. Set $DOCKERDATAPATH for container to save data:Web GUI should be at http://localhost:8840Configuration can be done through config file, GUI or environment variablesThis config matches Grafana's config for InfluxDB data sourceConfig file name is config_v2.yaml. Example:By default, ",
    "summary": "**WatchYourLAN: Because We Needed Another Network Scanner**\n\nGitHub spawns yet another network scanning tool boldly tagged 2.0, as if numerical incrementation imparts innovation. The developer, seeming desperate for approval, assures us they read *every piece of feedback*\u2014a claim as dubious as the utility's \"lightweight\" label. Commenters dive into crucial debates over MAC-vendor data accuracy, while an anecdotal detour into Wake on LAN (WoL) complexities virtually hijacks the discussion, proving that a simple network tool can indeed awaken not just PCs, but unbridled pedantry and nostalgia across the board. Meanwhile, life-altering features like \"breaking changes\" ignite both fear and loathing in the hearts of version 1.0 enthusiasts, cementing the tool\u2019s place in the annals of GitHub obscurity. \u23f3\ud83d\udd0d"
  },
  {
    "title": "ARM or x86? ISA Doesn't Matter (2021) (chipsandcheese.com)",
    "points": 28,
    "submitter": "baq",
    "submit_time": "2024-08-27T14:35:31",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=41368004",
    "comments": [
      "Since Jim Keller is quoted in the article, it would be good to point out that his new company uses RISC-V cores a lot [1] and have licensed their design out [2] to other companies. It seems to have been the correct choice for them.[1] https://www.tomshardware.com/news/tenstorrent-shares-roadmap...[2] https://www.anandtech.com/show/21281/tenstorrent-licenses-ri...\n \nreply",
      "Isn't it kind of obvious that the instruction set itself cannot directly impact performance, since operations are just single clock cycles? I assume the issue is more about the difficulties of implementation, in particular how x86 has a lot of complicated archaic features and corner cases that just absorbs space on silicon, not to mention engineering effort. Apple, being vertically integrated, is free to toss features at will.\n \nreply",
      "This is a pretty simplistic view of how processors execute instructions. They reorder, merge, and speculate execution. Most instructions do not take a single cycle to complete, often they take less or more (and even this depends on how you look at it, since they can be less if you overlap them and more if you look at latency). While this doesn\u2019t mean ISA matters as much as people might think how CPUs work is also more complicated than people might think.\n \nreply",
      "Say that when I need to run some program and I have an ARM processor but the only binaries available are x86...\n \nreply",
      "Both MacOS and Windows handle that pretty well with JIT, AOT or emulation\n \nreply",
      "And you can use qemu-user on Linux, though I don't think any distros set it up by default\n \nreply",
      "I\u2019m guessing from your question you did not bother reading the article before commenting.That said this is a solved problem - because plenty of people have arm based machines, and run x86 binaries on them (it obviously comes with a perf cost, but there\u2019s only so much that can be done when dealing with poor engineering)\n \nreply",
      "why would that matter?\n \nreply",
      "... Why would it not?\n \nreply",
      "Because that\u2019s a solved problem, and isn\u2019t relevant to this article - which I assume you also did not read\n \nreply"
    ],
    "link": "https://chipsandcheese.com/2021/07/13/arm-or-x86-isa-doesnt-matter/",
    "first_paragraph": "",
    "summary": "Today on \"Obvious Geek Battles\", a groundbreaking tour-de-force conclusion at <em>chipsandcheese.com</em> ensures that everyone knows ISA barely matters\u2014but don't tell that to the comments section. Here, self-declared tech gurus engage in a mind-boggling display of missing the point, debating over the efficiency of emulating x86 on ARM like it's 1999. One genius bravely cites Jim Keller's involvement with RISC-V, a golden nugget surely unknown to the rest of the internet, while others heroically explain basic CPU operation to each other. Meanwhile, a lone warrior reminds everyone that yes, indeed, software can run on different hardware\u2014thank heavens for such revelations in 2021! \ud83d\ude31\ud83d\ude80"
  },
  {
    "title": "AirTags key to discovery of Houston's plastic recycling deception (appleinsider.com)",
    "points": 23,
    "submitter": "JumpCrisscross",
    "submit_time": "2024-09-01T00:38:33",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=41413174",
    "comments": [
      "\"By contrast, Apple has been an industry leader in reducing its use of plastic. It uses paper for packaging, and metal rather than plastic for its computer line.\"Okay\n \nreply",
      "Apple\u2019s like \u201coops, sorry we made 4 billion lightning cables that don\u2019t work with new phones now!\u201d\n \nreply",
      "Thanks to an EU regulation mandating type-c connectors\n \nreply",
      "I\u2019m impressed how fast people on HN switched from \u201cApple is terrible for not dropping lightning cables for USB-C!\u201d to \u201cApple is terrible for dropping lightning cables for USB-C!\u201d  Talk about a zero-downtime migration!\n \nreply",
      "Different groups of people.The backlash is mystifying though. MacBooks, iPads, and Beats had been shipping with USB-C for years, a standard Apple was heavily involved in creating in the first place. Most other manufacturers had already standardized on it. Unless you lived in a very strange bubble of only interacting with iPhones and air pods, you already dealt with USB-C devices. For those very few people in that very limited bubble, the problem was fixed by replacing a single cable. It was a mountain of controversy for a figurative molehill.\n \nreply",
      "Apple is terrible for using lightning cables in the first place.\n \nreply",
      "At least all this plastic is now stored in one place and did not end up in rivers and landfills yet. There is a still a hope for happy ending of this story.\n \nreply",
      "Why is plastic in landfillsma problem? It started off as oil in the ground.\n \nreply"
    ],
    "link": "https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception",
    "first_paragraph": "",
    "summary": "In the latest whistleblower saga from the tech utopia, AirTags (yes, the ones you keep losing and rebuying), have exposed Houston's egregious plastic recycling sham. Because why just throw plastics into the landfill when you can feign recycling and create a PR spectacle? Commenters are diving head-first into a sanctimonious debate about Apple's transition from proprietary lightning cables to universally derided USB-C connectors. They blissfully toggle between applauding Apple's \"lead in sustainability\" and vilifying them for the mountainous e-waste of outdated cables, illustrating a master class in missing the point. Who knew enlightened tech bro discourse could be this circular? \ud83d\udd04\ud83c\udf0d"
  },
  {
    "title": "A brief history of barbed wire fence telephone networks (loriemerson.net)",
    "points": 23,
    "submitter": "MBCook",
    "submit_time": "2024-08-31T21:41:30",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/",
    "first_paragraph": "dot netIf you look at the table of contents for my book, Other Networks: A Radical Technology Sourcebook, you\u2019ll see that entries on networks before/outside the internet are arranged first by underlying infrastructure and then chronologically. You\u2019ll also notice that within the section on wired networks, there are two sub-sections: one for electrical wire and another for barbed wire. Even though the barbed wire section is quite short, it was one of the most fascinating to research and write about \u2013 mostly because the history of using barbed wire to communicate is surprisingly long and almost entirely undocumented, even though barbed wire fence phones in particular were an essential part of early- to mid-twentieth century rural life in many parts of the U.S. and Canada! While I was researching barbed wire fence phones and wondering whether any artists had been intrepid enough to experiment with this other network, I came across Phil Peters and David Rueter\u2018s work \u201cBarbed Wire Fence Tele",
    "summary": "**A Quick Stab at Barbed Wire Telephone Networks**\n\nToday on the lesser-known corners of academia, we discover that barbed wire once doubled as a DIY telecom network! Delve into a historian\u2019s gloriously niche agony as they unearth the riveting saga of farmers yelling over primitive Zoom-dangerous fences. The comment section is ablaze with hobbyist electricians and three amateur historians, each vehemently arguing about the electrical resistance of rusty barbed wire. Who knew the Old West had such bad connectivity issues? \ud83e\udd20\u26a1"
  },
  {
    "title": "Compilation of JavaScript to WASM, Part 2: Ahead-of-Time vs. JIT (cfallin.org)",
    "points": 80,
    "submitter": "cfallin",
    "submit_time": "2024-08-27T15:30:12",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41368657",
    "comments": [
      "The real issue is that you cannot access the DOM via WASM.Also the previous article is here[0].[0]: https://news.ycombinator.com/item?id=37849310\n \nreply",
      "Can you explain this a little more? This is for running JS server side right? So why would there be a DOM? Is the issue that JS libraries or other things you would be using assume a DOM?\n \nreply",
      "That doesn\u2019t really have anything to do with this article which is about running JS quickly on server wasm runtimes.\n \nreply",
      "This type of comment shows up on seemingly every thread about wasm and it is so tiresome. Wasm can't do any I/O unless the host passes the module a capability to do so. If you pass a module some DOM functions then it can access the DOM.\n \nreply",
      "I\u2019m curious though, does it gain meaningful access to the DOM in the case you described, or is it more just a proxy where it\u2019s asking javascript, via some sort of channel, to manipulate the DOM?\n \nreply"
    ],
    "link": "https://cfallin.org/blog/2024/08/27/aot-js/",
    "first_paragraph": "\n        Aug 27, 2024\n      This is a continuation of my \u201cfast JS on Wasm\u201d series; the first\npost covered PBL, a\nportable interpreter that supports inline caches, this post adds\nahead-of-time compilation, and the final post will discuss the details\nof that ahead-of-time compilation. Please read the first post first for\nuseful context!The most popular programming language in the world, by a wide margin\n\u2013 thanks to the ubiquity of the web \u2013 is\nJavaScript (or, if you\nprefer to follow international standards, ECMAScript per\nECMA-262). For\na computing platform to be relevant to many modern kinds of\napplications, it should run JavaScript.For the past four years or so, I have been working on\nWebAssembly (Wasm) tooling and platforms,\nand in particular, running Wasm \u201coutside the browser\u201d (where it was\nborn), using it for strong\nsandboxing\nof untrusted server-side code instead.This blog post will describe my work, over the past 1.5 years, to\nbuild an ahead-of-time compiler from JavaScript to Web",
    "summary": "**Hot Take on Techno-Babble: Compiler Boogaloo**\n\nIn a yet another stunning episode of \"let's make tech stuff sound way too complex,\" our favorite blog series on shoehorning JavaScript into WebAssembly stumbles forward. This time, it's an *epic showdown* between Ahead-of-Time compilation and Just-In-Time excuses. Watch in <em>amazement</em> as commenters painstakingly confuse server-side execution with client-side DOM manipulation, proving once again that reading comprehension is just an optional JavaScript library that didn't compile right in their brains. Can someone pass the DOM capabilities to the comment section, please? \ud83e\udd26\u200d\u2642\ufe0f\ud83d\udcbb"
  },
  {
    "title": "Percona Everest: open-source automated database provisioning and management (percona.com)",
    "points": 28,
    "submitter": "petecooper",
    "submit_time": "2024-08-31T19:11:21",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://docs.percona.com/everest/index.html",
    "first_paragraph": "We are excited to welcome you to Percona Everest, designed to demonstrate the core capabilities of our new open source cloud-native database platform!Percona Everest is the first open-source platform for automated database provisioning and management. It supports multiple database technologies and can be hosted on any Kubernetes infrastructure, in the cloud or on-premises.Let\u2019s start by enabling you to deploy an automated private DBaaS, eliminating vendor lock-in and complex in-house platform development. Percona Everest quickstart guide Manage your first cluster Discover how Percona Everest simplifies and streamlines your database management and provisioning.Discover Percona Everest Explore how our security features are designed to ensure the security of your hosted databases.Secure your deployments Learn how to manage user accounts in Percona Everest.Manage user accounts Get ready to dive into our APIs and uncover their potential.Dive into our APIs If you need assistance, visit the c",
    "summary": "At long last, the day has graced us where you too can spin up your own bewilderingly complex data fortress with Percona Everest\u2014a solution looking for a problem that combines the joy of Kubernetes with the ease of database management as understood by a lobotomy patient. \ud83c\udf89 Hurrah! Let's all strap in to deploy private DBaas ecosystems, securely wrapped in layers of \"you definitely won't need a dedicated IT team for this\" assurances. Meanwhile, in the comment section, the usual choir of tech bros oscillates wildly between proclaiming Percona Everest as the second coming of Christ and reminiscing about the \"good old days\" of SQL injections before security was a thing. Can't wait to forget passwords on yet another platform! \ud83d\ude43"
  },
  {
    "title": "Astronomers puzzled by little red galaxies that seem impossibly dense (newscientist.com)",
    "points": 23,
    "submitter": "jandrewrogers",
    "submit_time": "2024-08-31T20:25:40",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41411694",
    "comments": [
      "Is this what a group of type III civilizations look like on the Kardashev scale?\nBack when the universe was hot and dense and it was still fun?\n \nreply",
      "https://archive.is/NhWAs\n \nreply",
      "Can those be just globular clusters in their 'bright' phase? Globular clusters are not even mentioned in that article, which is weird.\n \nreply",
      "I'm gonna guess that the prominent astronomers at several top-notch universities mentioned have heard of globular clusters, and that the reason it's not mentioned is it's not relevant.\n \nreply",
      "Is the snark really necessary? I think a more interesting and helpful response would be to point out why these are likely not globular clusters. For instance, they contain a total stellar mass in some cases comparable to that of the Milky Way; for comparison, the Milky Way contains at least 150 distinct globular clusters and probably many more. They also seem to host supermassive black holes at their centers, which globular clusters don't have.\n \nreply",
      "Must be heck of a night sky on one of those planets\n \nreply"
    ],
    "link": "https://www.newscientist.com/article/2445967-astronomers-puzzled-by-little-red-galaxies-that-seem-impossibly-dense/",
    "first_paragraph": "Advertisement\u2018Little red dot\u2019 galaxies seen by JWST appear to be much more tightly packed with stars than other galaxies, raising big questions about how they came to be this wayBy Alex Wilkins\n                                    30 August 2024\n                                                                    JWST images of little red dot galaxiesJosephine F.W. Baggen et al. (2024)JWST images of little red dot galaxiesJosephine F.W. Baggen et al. (2024)Strangely bright galaxies spotted by the James Webb Space Telescope (JWST), called \u201clittle red dots\u201d, may have more stars packed into them than any other galaxies we know of. The density appears so high that it\u2019s unclear how the stars even survive without crashing into their neighbours, challenging astronomers\u2019 best ideas of how galaxies grow.Shortly after JWST started searching the extremely distant universe in 2022, astronomers started to see extremely bright and red, but apparently tiny, galaxies, which they called little red dots\u2026A",
    "summary": "**Astronomical Anomalies and Armchair Experts**\n\nIn a *dazzling* display of cosmic confusion, the James Webb Space Telescope spots tiny, dense packs of stars whimsically dubbed \"little red dots.\" Apparently, they're so densely packed that astronomers are scratching their heads wondering how these stars haven't turned into a galactic demolition derby. Enter the peanut gallery: commenters on the internet, armed with half-baked theories about Kardashev scales and misplaced globular clusters, because why trust decades of astrophysicist training when you can make galactic conclusions from your couch? \ud83c\udf0c\ud83c\udf7f Whether it's speculation about starry night skies on non-existent planets or unnecessary snark battles, the comments section is truly the black hole of the internet."
  },
  {
    "title": "Making an atomic trampoline [video] (youtube.com)",
    "points": 16,
    "submitter": "matricaria",
    "submit_time": "2024-08-31T07:46:35",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41407195",
    "comments": [
      "A thought I had when I saw the original Steve Mould video, and this video made me remember it.What happens if you just use glass for the bouncing surface? I was reading about the materials and I am not sure what property contributes to it's bounciness, but I think it is tensile strength(but it may be surface hardness). and regular glass has a slightly lower tensile strength than these amorphous  metallic structures, fused quartz has a higher tensile strength, and I was unable to find out what tempered glass is, but I suspect tempered glass would tend to shatter if a small hard ball was bounced off it. Anyway, I was unable to form a good hypothesis as to what would happen, but I did find that mcmaster-carr sells fused quartz disks if anyone wants to try.https://www.mcmaster.com/products/glass-discs/ultra-high-tem...\n \nreply",
      "McMaster also sells discs of tool steel and glass bearing balls... and carbide, and ceramic, etc. What if the bearing ball was carbide, even harder? What would happen if you reduced the hardness of a steel ball, which usually only requires normal kitchen oven temperatures? What happens if the materials switch places, say a hardened tool steel disc and glass ball?Anyway, lots of options to safely experiment with material science concepts in very accessible and tweakable ways! No beryllium or foundry equipment required. I do think the massive, well fitted, rigid surface backing up the disc is important to constrain what this is demonstrating - plastic vs elastic deformation.\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=jLX1-tNnvEo",
    "first_paragraph": "",
    "summary": "In this week's episode of \"random internet scientists gone wild,\" a YouTuber discovers atomic trampolines, prompting an avalanche of armchair physicists to wildly speculate about the consequences of bouncing tiny objects off different materials. One bright spark can't decide between glass or metallic structures for maximum bounce, despite clearly having skipped the day tensile strength was taught in physics class. Another commenter, thrilled by a catalog of materials, suggests swapping the materials around as if concocting a high-stakes game of \"Will It Break?\". It's a riveting blend of half-baked hypotheses and wildly optimistic DIY science projects that make you wish for a simple rubber ball and a cup of tea."
  },
  {
    "title": "LLMs struggle to explain themselves (jonathanychan.com)",
    "points": 3,
    "submitter": "jonathanyc",
    "submit_time": "2024-08-30T10:23:19",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41399369",
    "comments": [
      "> It\u2019s interesting to me that in spite of the fact that the LLM does so poorly with number sequences in general, it does pretty well with variations of the Fibonacci sequence.Not surprising, since the Fibonacci sequence will be in the text swallowed by the LLM.\n \nreply",
      "Yea! Do you think the LLM learns a Fibonacci-specific circuit? Do you think it is possible for an LLM to learn a general pattern-recognition circuit?\n \nreply",
      "Well, a basic LLM would not really even distinguish a Fibonacci series from a hole in the ground. But models are being built with extra stuff, though I doubt recognising number series is high on the list.\n \nreply",
      "Thanks for sharing! The custom stack-based language that you created for randomly generating interesting integer sequences was the most interesting part of this post for me. Wish the post focused on that rather than LLMs!\n \nreply",
      "> One day in March, I was walking my dog, saw a house numbered 3147, and thought it was a funny pattern. It\u2019s the Fibonacci sequence with a different seed (31 instead of 11).The Fibonacci sequence with 3,1 would be 3,1,4,5. I think you mean the house number was 1347. That would work and be easier to notice.\n \nreply",
      "Haha thanks for catching that\u2014fixed! That\u2019s pretty ironic. Looks like I\u2019m the LLM and you\u2019re the human :PNow I can\u2019t remember whether the house was 3147 or 1347. The pattern might have been to add the first digit to the last digit (unrot + in the stack language). That\u2019s what I get for writing at 3am!\n \nreply",
      "Hi HN! I'm about to go to bed, but I promise to go through comments when I wake up later today. Happy Friday!The source code for the demo is on GitHub: https://github.com/jyc/stackbee\n \nreply"
    ],
    "link": "https://www.jonathanychan.com/blog/llms-struggle-to-explain-themselves/",
    "first_paragraph": "",
    "summary": "**The Perils of Teaching LLMs to Count: A Comedy of Errors**\n\nIn an audacious display of misunderstanding mixed with overestimation of capability, a *recent article* dives into why Large Language Models (LLMs) like stumbling toddlers, can barely grasp basic number sequences without tripping over their digital shoelaces. The comment section, a delightful circus of the confused leading the blind, features an enthusiast pointing out the intriguing abilities of LLMs with the Fibonacci sequence\u2014a remark as insightful as observing that calculators are good at addition. Someone else chimes in with a self-created language for generating integer sequences, which everyone ignored because, let's face it, why focus on actual innovation when we can watch AI fail at elementary math? Meanwhile, another commenter gets house numbers wrong, inadvertently illustrating the LLM's struggles in a real-world metaphor that surely wasn't intentional but is hilarious nonetheless. \ud83d\ude02"
  },
  {
    "title": "Continue (YC S23) Is Hiring a Software Engineer in San Francisco (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-08-31T21:01:53",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/continue/jobs/smcxRnM-software-engineer",
    "first_paragraph": "The leading open-source AI code assistantContinue is seeking an outstanding software engineer to help us build state-of-the-art autocomplete and codebase retrieval, who thinks rigorously and pays attention to the smallest details. In this role, you will work on fundamental, but highly open-ended problems where deliberate measurement, rapid experimentation, and empathy for users push forward the product.About youPlease keep in mind that we are describing the background that we imagine would best fit the role. If you don\u2019t meet all the requirements, but you are confident that you are up for the task, we absolutely want to get to know you!What you will doWe\u2019re a startup, so you\u2019ll have to be ready to do whatever is required to accomplish our mission. However, you can definitely expect to:We believe there is an opportunity to create a future where developers are amplified, not automated. This is why we are building the leading open-source AI code assistant and layering an enterprise produc",
    "summary": "Title: Another Day, Another AI Savior\n\nIn the latest episode of Silicon Valley Mad Libs, <i>Continue</i> (because pausing is for losers!) is on the prowl for a software engineer miraculous enough to transform autocomplete from mildly annoying to borderline usable. They seek a meticulous genius who can stare into the abyss of \"fundamental, but highly open-ended\" problems and not run screaming. The ideal candidate will possess deep empathy for users\u2014a rare trait typically only professed by startups when hunting for new hires. Commenters are already tripping over themselves to either worship this visionary move or derisively point out that it\u2019s just another autocomplete tool, but with more <em>open-source</em> fairy dust sprinkled on top. \ud83d\ude44\ud83d\ude80"
  },
  {
    "title": "Neutral beam microscopy using magnetic beam spin encoding (nature.com)",
    "points": 11,
    "submitter": "PaulHoule",
    "submit_time": "2024-08-28T17:32:08",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.nature.com/articles/s41467-024-51175-2",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.Advertisement\nNature Communications\nvolume\u00a015, Article\u00a0number:\u00a07046 (2024)\n            Cite this article\n638 Accesses76 AltmetricMetrics detailsThe emerging technique of neutral beam microscopy offers a non-perturbative way of imaging surfaces of various materials which cannot be studied using conventional microscopes. Current neutral beam microscopes use either diffractive focusing or pin-hole scanning to achieve spatial resolution, and are characterised by a strong dependence of the imaging time on the required resolution. In this work we introduce an alternative method for achieving spatial resolution with neutral atom b",
    "summary": "Welcome to yet another groundbreaking episode on <em>nature.com</em>, where we can barely cope with modern internet standards but promise to revolutionize microscopy with something called \"magnetic beam spin encoding.\" \ud83e\uddf2\ud83d\udd2c In a riveting development that you can't possibly hope to understand, we are told that atoms can now be herded like tiny, invisible sheep to generate images of 'various materials.' Commentators, stuck in a realm of outdated browsers, applaud the science while confusing magnetic spins with their daily dizzy spells, perhaps due to too tight tinfoil hats. Brace for the claim of revolution in science, courtesy of folks who can\u2019t yet figure out CSS. \ud83c\udf10\ud83d\udcbb"
  },
  {
    "title": "Client-side QR code generator with SVG output (fietkau.software)",
    "points": 47,
    "submitter": "kentbrew",
    "submit_time": "2024-08-31T17:42:14",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41410442",
    "comments": [
      "This looks great! Wish I had it a few months ago instead of having to use qr-code-styling[0] which was a bit of a pain.I remember it was around the same time that Obsidian got native callouts, so my notes for that project are all colourful & contain valuable admonitions like this:```> [!todo]> That feeling when you're wasting hours of your life trying to make something you know is abandonware work just because it looks nice. There should be a word for that feeling. In Danish or Japanese. Or German.```[0]: https://github.com/kozakdenys/qr-code-styling\n \nreply",
      "If you stumbled upon this looking for the smallest QR code JS library, it's probably LeanQR [0]. It's under 10kb minified and 5kb compressed.[0] https://qr.davidje13.com/\n \nreply",
      "One of my favorite components from the open source web components library Shoelace is the QR code generator:\nhttps://shoelace.style/components/qr-code\n \nreply",
      "Thank you for building this wonderful UI on top of my library!\n \nreply",
      "USE THIS SOFTWARE AND LEARN FROM MY MISTAKE:We made a cute Christmas video to include in our card this year. My wife created a QR code from a random website and included it in the card as a picture. It linked to our video. We sent all of the cards out. People loved it.... except we got an email from the QR code company about a week before Christmas. We went over our \"free\" click (the QR code went through their URL shortener). If we wanted to keep the QR code active we had to pay $20/mo.We got absolutely fleeced. Never again. Control the URL and make the QR image yourself.\n \nreply",
      "\"The demo on this page combines Project Nayuki\u2019s QR Code generator library (a multi-language open source project that can, among other things, perform the conversion of text into raw QR code data) with my own QRSVG project, which can turn a QR-like two-dimensional boolean data map into an efficient vector description of its own visualization by tracing the contours of contiguous shapes.\"\n \nreply"
    ],
    "link": "https://fietkau.software/qr",
    "first_paragraph": "Single colorGradientPaletteSome combinations of customization options may reduce the code\u2019s scannability. Be sure to test it before committing.QRSVG is a small JavaScript project to render a two-dimensional bitmask (mostly assumed to be a QR code) to an SVG element as a collection of SVG paths with defined purposes.QR codes have established themselves as a popular way to provide a chunk of digital information (most commonly a web address to jump to) via physical media. I myself occasionally use them in flyers, posters, or presentation slides.They are not too complicated to generate and a variety of free websites exist for this purpose. Sadly none of them appear to have all of the customization options that I want, plus most of them use some manner of ads and/or data tracking. The demo on this page combines Project Nayuki\u2019s QR Code generator library (a multi-language open source project that can, among other things, perform the conversion of text into raw QR code data) with my own QRSVG",
    "summary": "Title: The Great QR Code Customization Crisis of 2023\n\nIn the latest episode of \"Frontend Developers Rediscover Things That Already Exist,\" a brave coder introduces yet another QR code generator, this time with *SVG* flair! Because what the web truly lacks is not security, performance, or usability, but more QR code libraries with gradient options to make them slightly prettier yet often unreadable. The commenters, equidistant between innovation and desperation, celebrate this monumental achievement as if QR codes hadn\u2019t been around since the late '90s, sharing tear-jerking anecdotes about past QR catastrophes and expressing a jolly good riddance to those pesky ad-supported QR generators. Meanwhile, the virtual ink on their \"why isn't this a standard library yet\" Reddit posts is just starting to dry. \ud83c\udf89"
  },
  {
    "title": "Brazil's X ban is sending lots of people to Bluesky (theverge.com)",
    "points": 75,
    "submitter": "rvz",
    "submit_time": "2024-08-31T13:28:25",
    "num_comments": 137,
    "comments_url": "https://news.ycombinator.com/item?id=41408738",
    "comments": [
      "Copying over my latest backend status update; figure folks would find it interestingServers are holding up so far! Fortunately we were overprovisioned. If we hit 4mm new signups then things should get interesting. We did have some degradations (user handles entering an invalid state, event-stream crashed a couple times, algo crashed a couple times, image servers hit bad latencies) but we managed to avoid a full outage.We use an event-sourcing model which is: K/V database for primary storage (actually sqlite), into a golang event stream, then into scylladb for computed views. Various separate services for search, algorithms, and images. Hybrid on-prem & cloud. There are ~20 of the k/v servers, 1 event-stream, 2 scylla clusters (I believe).The event-stream crash would cause the application to stop making progress on ingesting events, but we still got the writes, so you'd see eg likes failing to increment the counter but then magically taking effect 60 seconds later. Since the scylla cluster and the KV stores stayed online, we avoided a full outage.\n \nreply",
      "Does Bluesky intend to be responsive to the kind of court orders that X rejected?\n \nreply",
      "Speaking entirely personally as I don't handle those questions at bsky. I couldn't even begin to comment without seeing knowing what the court orders were and what the cases are. Every social company operating internationally runs into this issue, and it's daunting to say the least. So, again, this is not something I decide.What I can say is that the protocol is a neutral global layer for data, which can then enable multiple applications with their own moderation policies and decisions. There's always going to be moderation decisions we make that people will disagree with. The point is that something can be done about that disagreement - you can have other applications on the same network that makes their own decisions. I think one of the best things that could happen is that Brazilian developers fork the Bluesky app and build locally-owned social platforms on the atmosphere.\n \nreply",
      "Context: atmosphere is like \"Fediverse\" but for the AT protocol and also way more schway\n \nreply",
      "Clearly given he is excited to receive the traffic\n \nreply",
      "Can you elaborate on this? I\u2019m not clear what you mean here.\n \nreply",
      "Interestingly, the cohort moving to Bluesky isn't the same as those who were having trouble with the law.\n \nreply",
      "That\u2019s interesting. Why do you use event sourcing? Is having a full history important for a website/app like bluesky?\n \nreply",
      "Ahhh you know what, I should call it stream processing or something, because we don't store the data entirely as events. We store the data as a mutable K/V which emits an event stream of changes, which can then be ingested into different views. We chose not to store changes as events specifically because we don't want unbounded growth in the system. Initial syncs work by fetching the current state of the K/V store (the \"data repo\").Bluesky is built on atprotocol (atproto.com) and can be thought of as an open distributed system. The event stream is for replicating throughout the various services.\n \nreply",
      "I left Xitter about 6 weeks ago and went all in on Bluesky. Took time to give feedback to the algo, but it's doing much better these days. I don't feel like I'm missing out on much, you'll get the same news & events on Bluesky. A lot of people who were scared of losing their following are reporting more, better engagement with lower follower counts.What I really like about it is the ATProto, which while imperfect, seems like the best current design for the next gen of social media built on a federated foundation.- DID for identity- PDS for data mobility- algo feed & moderation choice, you can build your own and anyone on Bluesky can use it (https://bsky.social/about/blog/03-12-2024-stackable-moderati...) If you didn't see, they recently added anti-toxicity features and are looking towards community notes- Bluesky is the twitter like view, but you can build anything on ATProto and leverage the shared infraI'm personally working on a \"reddit\" like view of the Bluesky network. Not a reddit clone, but a different way to organize the same information around topics, news events, and/or links. One could also design their own Lexicon and build something very close to reddit. One of the cool things is that all the objects for all apps are stored into a single SQLite database per user. So if you want to move your data to a different host, all of the apps, content, and connections survive that migration.\n \nreply"
    ],
    "link": "https://www.theverge.com/2024/8/30/24232561/brazil-x-ban-sending-people-bluesky",
    "first_paragraph": "By  Jay Peters, a news editor who writes about technology, video games, and virtual worlds. He\u2019s submitted several accepted emoji proposals to the Unicode Consortium.X is currently banned in Brazil following an order from a Supreme Court justice, and Brazilian users seem to be turning to Bluesky, an alternate social network, in droves.\u201cBrazil, you\u2019re setting new all-time-highs for activity on Bluesky!\u201d the official Bluesky account said in a post.\u201cThere will almost certainly be some outages and performance issues,\u201d Bluesky developer Paul Frazee said. \u201cWe\u2019ve never seen traffic like this. Hang with us!\u201d The Bluesky app looks and functions a lot like X, but it\u2019s a decentralized social media platform that\u2019s built on the AT Protocol (which is also developed by Bluesky). In a 5:12PM ET post, Frazee said that Bluesky is seeing 1,000 events per second \u2014 a \u201cnew milestone\u201d \u2014 on its \u201crelay,\u201d which essentially functions as the firehose of data for the platform. On Friday night, Bluesky said it had ",
    "summary": "Welcome to another chapter in the ongoing saga of \"Global Panic Switches Social Network,\" where Brazil swaps X for the latest decentralized darling, Bluesky. In a surprising turn that no one could have predicted except everyone, the removal of a popular platform leads to unprecedented growth on a virtually identical but more crash-prone alternative. Bluesky's developers, grappling with a flood of data they've never dealt with\u2014because launching a social media service implies original preparation for traffic loads akin to a sleepy blog\u2014have now discovered what \"scaling\" means in real time. Meanwhile, the comment section is abuzz with tech jargon flinging aficionados debating the nuances of data storage like a knockout round in nerd Jeopardy. \ud83d\ude44\ud83c\udf89"
  },
  {
    "title": "Show HN: A retro terminal text editor for GNU/Linux coded in C (C-edit) (github.com/velorek1)",
    "points": 118,
    "submitter": "velorek",
    "submit_time": "2024-08-30T20:58:17",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=41404360",
    "comments": [
      "Apart from the learning experience, there is still value in a small-sized, fast TUI text editor for Linux.However, my two suggestions would be:- add Unicode support (it's the 21st century, so \u2211, \u00ae, etc. should finally work); this is not easy, but the earlier you do it the less dramatic the changes will be (check out https://github.com/unicode-org/icu/tree/main/icu4c);- don't allocate the lines individually (as you do now with malloc, having looked at the code); at least use an arena allocator, i.e. allocate larger chunks of memory and the provide your own alloc_line function that uses the larger chunks (called arenas) piecemeal. This will speed things up and reduce fragmentation. A more advanced approach would be not to use per-line buffers but to switch to rope data structures e.g. https://github.com/josephg/librope).\n \nreply",
      "As an alternative to ICU, there is suckless's libgrapheme (https://libs.suckless.org/libgrapheme/) which is more than a 100x smaller and provides full Unicode compatibility.\n \nreply",
      "> This will speed things up and reduce fragmentationDoes this really make much of a practical difference these last decades? I wrote a text editor back in the late 90s in DOS using DJGPP with per-line allocation and it worked fine on the Pentium MMX i had at the time (and my approach to optimization at that time was be ignorant of the concept :-P), i'm not sure it'd really make much of a difference on any desktop or laptop CPU released past 2000 - at least as far as users editing text files are concerned (might make a difference if you try to open a multiGB file with barely a line break and accidentally press a letter :-P).\n \nreply",
      "When you mentioned retro I was expecting something like editline. Now I feel old.Anyways, the TUI on mainstream MS-DOS 6.22 and Borland from those days were incomparable to anything on mainstream Linux even on these days. For some reason Linux is the king of text mode and yet never had a proper TUI tradition.Thank you for sharing the project. Compiled well on my side, looking forward to the next developments. My (unrequested) feedback:+ consider renaming from C-edit (uppercase) to lower case c-edit, because it is simpler to type from the terminal.+ the animations of the spining part on top was distracting+ some menus missing to implement functionality, didn't test copy&paste+ mouse support would be nice, albeit optional but would complete the MS-DOS 6.22 / borland style since it supported mouse there tooThank you.\n \nreply",
      "Glad it compiled! Most of your suggestions are on my to-do list indeed. I wanted to maintain an animation to demonstrate that it could be kept running throughout all the different dialogs and listboxes. I'll probably end up changing it. Thank you for testing it. :)\n \nreply",
      "I have to say that when I saw retro I expected ncurses support. Not all retro terminals understand VT100 escape sequences ;-)What about those who use VT-52 terminals?\n \nreply",
      "Unless you\u2019re using an actual hardware VT52, then it\u2019s pretty safe to assume VT100 support these days.\n \nreply",
      "Makes good sense. Keep up the good work!\n \nreply",
      "Love the look, definitely throwing me back to the halcyon QBasic days.Slightly related but another way to simulate a retro text editor (old school raster style green screen aesthetic in this instance) is to combine the \"cool-retro-term\" terminal with the minimal editor \"micro\".https://github.com/Swordfish90/cool-retro-termhttps://github.com/zyedidia/micro\n \nreply",
      "I love cool-retro-term, I keep it running with a Matrix style terminal toy as a \"screensaver\" on the small PC sitting on my homelab. It's an ostentatious waste of power and CPU cycles but I appreciate the aesthetics of it.\n \nreply"
    ],
    "link": "https://github.com/velorek1/C-edit",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A text editor in C with drop down menus from scratch. No ncurses.\n      C-EDIT for linux - ALPHA - A linux text editor in the style of the MSDOS EDIT - WITHOUT USING NCURSES\nWorks well with Termux! :)If you want to support this project:\nbitcoin:bc1qn8hzf7f07afcyasym434e9a7sflf8mpjflhg4wContact me at: velorek1@gmail.comNEW: AUGUST 2024 (merging with ceditbuf)History:TO INSTALL:So far I have implemented:As a screen buffer I have implemented a dynamic structure in memory that allows to save the current screen so that you can display new things on top and then go back to the previous (saved) screen. (simple linked list)TO-DO:\n\n        A text editor in C with drop down menus from scratch. No ncurses.\n      ",
    "summary": "<b>Title:</b> Hacker News Discovers a Retro Text Editor, Startles Six Users Back to Consciousness\n\n<b>Summary:</b> HN celebrates the unveiling of <em>C-EDIT</em>, a text editor that bravely shuns modern libraries like ncurses to resuscitate the ghost of MS-DOS\u2014because who doesn't miss the good old days of esoteric tech nostalgia? One heroic developer on a quest to out-retro the retro invites users to relive their youth, minus the convenience of Unicode or efficient memory management. Comments range from tech necromancy advices to outright existential crises over missing ncurses support. Meanwhile, in the cryptocurrency corner, a lone Bitcoin address stands ready, just waiting for those sweet, sweet retro enthusiast coins. \ud83e\udd13\ud83d\udcbe\ud83d\udcdf"
  },
  {
    "title": "Lucee: A light-weight dynamic CFML scripting language for the JVM (lucee.org)",
    "points": 56,
    "submitter": "mooreds",
    "submit_time": "2024-08-31T15:10:43",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41409434",
    "comments": [
      "At this point I'd skip Lucee which has most of the legacy baggage Adobe ColdFusion does and look at BoxLang.  https://boxlang.io/\"A modern, dynamically and loosely typed scripting language for multiple runtimes. For the Java Virtual Machine (JVM) giving you tons of Object-Oriented (OO), Functional Programming (FP) Constructs, and dynamic Metadata Programming (MP).\"\n \nreply",
      "I wouldn\u2019t recommend it for anything large but for fast internal tools, CFML is faster than anything I\u2019ve seen to get something up and usable. When Covid started we needed to track testing and positives and notifications - all the fun stuff. And it needed to be up in running in three days. The next day I had a release candidate and we deployed and announced it on the Monday. Similar places took weeks or had to wait for off the shelf products.Would I sell it what I made? No, but if your primary concern is getting stuff done, it surely will.\n \nreply",
      "Great product. It was forked from Railo (no relation to Rails), and the founders of Lucee came from Railo when they didn't like the direction Railo was going. The point is that Lucee is 16+ years old, and a popular alternative to Adobe ColdFusion.\n \nreply",
      "I ended up doing cf almost by accident for quite a while (like, 8 years) and was there as it went through the adobe -> railo transition.Coldfusion had a bad rep but it was actually a pretty good tool to work with. Railo made it a million times better in every way - the performance was solid and the environment was full featured enough to let you focus on the code.The original adobe (macromedia, right?) version was a mess. There were no functions but you could import modules. Massive caveat that those modules were allowed to mutate state outside of themselves so people would import them to, for example, run some db queries and set some variables in the calling code with the results. You can imagine the absolute unmaintainable mess that ensued.\n \nreply",
      "There were custom tags since 1997 (v3) and functions since 2001 (v5).https://cfdocs.org/coldfusion-versionsCF is interesting because it started as basically server side includes with some extra features to connect to a database. It was meant to be very approachable and not general purpose. Like a distant ancestor to Jupyter and Observable.That approachability made for some big messes, but it also spawned a huge community of software developers who might not have gotten into it otherwise.\n \nreply",
      "To be honest I don\u2019t quite recall the history anymore and no doubt the place we were at was late with adoption. My first day they said \u201ccongratulations, you\u2019ve just inherited 3 million lines of confusion\u201d\n \nreply",
      "Before it was bought by Macromedia ColdFusion was produced by Allaire (the Allaire brothers): https://en.wikipedia.org/wiki/Allaire_CorporationI want to say Macromedia mostly bought ColdFusion for it's editor. The language seemed to be a bit of afterthought.\n \nreply",
      "It did the same thing PHP did in terms of convenience. Made it easy to generate \u201cdynamic\u201d HTML. Everything was a template in a sense. It grew into a more serious programming language and platform. Fond memories of year 2000 :)\n \nreply",
      "I've joked for awhile that I might be literally the only person on earth who has had paying work in Coldfusion, Foxpro, ActionScript, Erlang, Haskell, and F#. I don't that for sure, I haven't taken a global survey, it just seems like a pretty obscure pairing.When you drop out of college, you take whatever job you can get.  My first software job was doing ColdFusion, ActionScript, and Foxpro for a Tae Kwon Do studio.  I didn't really know Coldfusion or Foxpro, but I picked them up relatively quick, and while I never really liked either of them, I did appreciate how quick I was able to prototype stuff in Coldfusion.It was relatively easy to go from 0-to-website with CFML and get something that more or less worked, and even had a few niceties as well; the SQL support was actually quite good (including built-in caching), you could fairly easily call out to Java libraries, and it was easy enough to remote with Flash/Flex, which was still relatively useful.I found it almost impossible to actually maintain anything, and I don't think I'd use it for anything now (particularly since I dont' do any frontend anymore), but there's a sentimentality that I will forever have for Coldfusion, if for no other reason it's the thing that kicked off my career.\n \nreply",
      "I had to work on quite a few coldfusion sites in the 1998 to 2010 timeframe. I found having to write brackets for each and every statement to be tiring; <cfif> <cfelse> <cfset var mystuff \"johnnyb\">Eventually, they incorporated cfscript which let you write stuff that was more like the c derived languages. But they did not port every <cftag> function over to cfscript. Terrible oversight. If you had to resort to ending your cfscript to fall back to a cftag it made the code really ugly.<cfdump> was ahead of its time. It came out way before php var_dump.<cfquery> was really powerful. It let you take any database result and then treat that result as though it were a database itself. So you could query a query so to speak.Something else I remember is how many ColdFusion devotees I worked with. I never understand how people get so attached to a language (ColdFusion, Ruby), a company (Apple), or a database (Postgres, MongoDB). It becomes some kind of cult. So many defensive ColdFusion programmers I had to deal with.Edit to add another memory. Old ColdFusion would use YES for true and NO for false. That would cause a lot of headaches when dealing with other systems that had no notion of YES or NO.\n \nreply"
    ],
    "link": "https://www.lucee.org/",
    "first_paragraph": "A light-weight dynamic scripting language for the JVM that enables the rapid development of simple to highly sophisticated web applications.We are an open source project and welcome contributions in all forms. If you want to dive into code, check out our Contributors guide.Whether you're working on a small personal project or a massive corporate business, you can benefit from Lucee Server's low cost of ownership. \n Excited for CFCamp 2024 on June 13-14 in Germany? Lucee will be there!\n\t\t\t\t\t\t\nGet your tickets nowLucee is a light-weight dynamic CFML scripting language with a solid foundation. See our Hello World example.Learn Lucee\u00a0\u00a0\u00a0Get help with Lucee problems\r\non our mailing list, slack\r\nchannel and engage with the\r\ncommunity on our language\r\ndevelopment forum.\u00a0Without our supporters we wouldn't be able to help the Lucee project to grow and prosper. Being a supporter means the project you rely on can continue and grow in the future. Interested in helping out?\u00a0Contribute to the source ",
    "summary": "<h3>Welcome to the majestic world of Lucee!</h3> \ud83c\udf89 An open-source haven for those who find delight in resurrecting the echoes of early 2000s web development, Lucee is here to serve all fourteen enthusiasts and counting. Whether it's whipping up a quick catastrophe or engaging in heated debates with fellow relics of the dot-com bubble on how \u201c<em>fast</em>\u201d and \u201c<em>sophisticated</em>\u201d it still is, Lucee promises a retro ride in the JVM lane, armed with all the tools needed for nostalgic inefficiency. Commenters chime in with misty-eyed tales of rapid deployments and yesteryears' messes, proudly placing Lucee on the dusty pedestal of obsolete tech that refuses to die. Will it thrive or merely survive? Stay tuned for the necromancy at CFCamp 2024! \ud83e\uddd9\u200d\u2642\ufe0f\ud83d\udc7b"
  }
]