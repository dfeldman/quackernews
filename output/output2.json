[
  {
    "title": "Multi AI Agent Systems Using OpenAI's New GPT-4o Model (github.com/metaskills)",
    "points": 50,
    "submitter": "metaskills",
    "submit_time": "2024-05-17T23:25:32",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=40395107",
    "comments": [
      "From the website linked in the readme:\u201cA lot of research has been doing in this are and we can expect a lot more in 2024 in this space. I promise to share some clarity around where I think this industry is headed. In personal talks I have warned that multi-agent systems are complex and hard to get right. I've seen little evidence of real-world use cases too\u201dThese assistant systems fascinate me, but I just don\u2019t have the time and energy to set something up. I was going to ask if anyone had a good experience with it, but the above makes it sound like there\u2019s not much hope at the moment. Curious what other people\u2019s experience are.",
      "We tried using a multi-agent system for a complex NLP-type task and we found:- Too many errors that just propogate on top of each other, if a single agent in the chain generates something even a little bit off then the whole system goes off the rails.- You often end up having to pass a massive amount of shared context to every agent which just increases the cost dramatically.Curiously enough we had an architect from OpenAI tell us the same thing about agent systems a few days ago (our company is a big spender so they serve a consulting function), so I don't think anybody is really finding success with multi-agent systems currently. IMO the core tech is nowhere near good enough yet.",
      "> Too many errors that just propogate on top of each otherLLMs are like the perfect improv comedy troupe, they virtually always say \u201cyes, and\u2026\u201d",
      "A lot of folks I've spoken with say that single-agent systems are still extremely limited, let alone multi-agent platforms. In general, it seems to boil down to:- Agents need lots of manual tuning and guardrails to make them useful- Agents with too many guardrails are not general-purpose enough to be worth the time and effort to buildI believe truly great agents will only come from models whose weights are dynamically updated. I hope I'm wrong.",
      "Thanks @beoberha, I am too. I like one take I heard on Twitter. The sentiment was something like these types of systems are useful under the AI-Powered Productivity industry which has incremental gains, no big bangs. Said another way, if your job was to help a TON of your employees be more productive individually, it is worth it because companies measure those efforts broadly and the payoff is there. But again, not big. My advice for folks to stay lower level and hook AI automation up with simple, closed loop, LLM patterns that feel more like basic API calls in a choreographed manner. OMG, hope all that made sense",
      "that's actually a great reply, thanks",
      "By the time you do get around to it OpenAi would have built a full interface for this.  This is the type of stuff that\u2019s gonna get steamrolled.",
      "I'd be interested in knowing if anyone is seriously using the assistants API, it feels like such a lock in to OpenAIs platform when your can alternatively just use completions that are much more easily interchanged.",
      "I've indeed refused to work with some providers giving only a chat interface and not a completion interface because it made the communication \"less natural\" to the model (like adding new system messages in between for function calling on models which don't officially does it, or adding other categories than system/user/assistant)",
      "Great points. Dont even get me started about how function calling in other LLMs costs me tokens. Something OpenAI provides OOTB. I'm also not a big fan of OpenAI's lock in. Right now I'm on a huge Claude 3 Haiku kick. That said, OpenAI does seem to get the APIs right and my hunch is the new Assistants API is going to potentially disrupt things again. Time will tell."
    ],
    "link": "https://github.com/metaskills/experts",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "**Multi AI Agent Systems Using OpenAI's New GPT-4o Model**: Another day, another GitHub repo promising to revolutionize AI with the complexity of multi-agent systems, only to be hilariously thwarted by the immutable laws of error propagation and overwhelming context burdens. Commenters, ever the optimists in the face of discouraging real-world feedback, continue their Quixotic quest for the *Golden Configuration* that never quite materializes. Meanwhile, critics lament OpenAI's seductive ecosystem lock-in, recalling every developer's worst relationship: too much control, too many expectations, and nowhere near enough flexibility. In the cacophony of cries for simpler APIs and fewer token costs, some brave souls are still holding out hope for a magical fix by 2024. *Spoiler alert:* Don't hold your breath. \ud83d\ude09"
  },
  {
    "title": "Bend: a high-level language that runs on GPUs (via HVM2) (github.com/higherorderco)",
    "points": 561,
    "submitter": "LightMachine",
    "submit_time": "2024-05-17T14:23:44",
    "num_comments": 130,
    "comments_url": "https://news.ycombinator.com/item?id=40390287",
    "comments": [
      "For what it's worth, I ported the sum example to pure python.    def sum(depth, x):\n        if depth == 0:\n          return x\n        else:\n          fst = sum(depth-1, x*2+0) # adds the fst half\n          snd = sum(depth-1, x*2+1) # adds the snd half\n          return fst + snd\n        \n    print(sum(30, 0))\n\nunder pypy3 it executes in 0m4.478s, single threaded.  Under python 3.12, it executed in 1m42.148s, again single threaded.  I mention that because you include benchmark information:    CPU, Apple M3 Max, 1 thread: 3.5 minutes\n    CPU, Apple M3 Max, 16 threads: 10.26 seconds\n    GPU, NVIDIA RTX 4090, 32k threads: 1.88 seconds\n\nThe bend single-threaded version has been running for 42 minutes on my laptop, is consuming 6GB of memory, and still hasn't finished (12th Gen Intel(R) Core(TM) i7-1270P, Ubuntu 24.04).  That seems to be an incredibly slow interpreter.  Has this been tested or developed on anything other than Macs / aarch64?I appreciate this is early days, but it's hard to get excited about what seems to be incredibly slow performance from a really simple example you give.  If the simple stuff is slow, what does that mean for the complicated stuff?If I get a chance tonight, I'll re-run it with `-s` argument, see if I get anything helpful.",
      "Running on 42 minutes is mots likely a bug. Yes, we haven't done much testing outside of M3 Max yet. I'm aware it is 2x slower on non-Apple CPUs. We'll work on that.For the `sum` example, Bend has a huge disadvantage, because it is allocating 2 IC nodes for each numeric operation, while Python is not. This is obviously terribly inefficient. We'll avoid that soon (just like HVM1 did it). It just wasn't implemented in HVM2 yet.Note most of the work behind Bend went into making the parallel evaluator correct. Running closures and unrestricted recursion on GPUs is extremely hard. We've just finished that part, so, there was basically 0 effort into micro-optimizations. HVM2's codegen is still abysmal. (And I was very clear about it on the docs!)That said, please try comparing the Bitonic Sort example, where both are doing the same amount of allocations. I think it will give a much fairer idea of how Bend will perform in practice. HVM1 used to be 3x slower than GHC in a single core, which isn't bad. HVM2 should get to that point not far in the future.Now, I totally acknowledge these \"this is still bad but we promise it will get better!!\" can be underwhelming, and I understand if you don't believe on my words. But I actually believe that, with the foundation set, these micro optimizations will be the easiest part, and performance will skyrocket from here. In any case, we'll keep working on making it better, and reporting the progress as milestones are reached.",
      "> it is allocating 2 IC nodes for each numeric operation, while Python is notWhile that's true, Python would be using big integers (PyLongObject) for most of the computations, meaning every number gets allocated on the heap.If we use a Python implementation that would avoid this, like PyPy or Cython, the results change significantly:    % cat sum.py \n    def sum(depth, x):\n        if depth == 0:\n            return x\n        else:\n            fst = sum(depth-1, x*2+0) # adds the fst half\n            snd = sum(depth-1, x*2+1) # adds the snd half\n        return fst + snd\n\n    if __name__ == '__main__':\n        print(sum(30, 0))\n\n    % time pypy sum.py\n    576460751766552576\n    pypy sum.py  4.26s user 0.06s system 96% cpu 4.464 total\n\nThat's on an M2 Pro. I also imagine the result in Bend would not be correct since it only supports 24 bit integers, meaning it'd overflow quite quickly when summing up to 2^30, is that right?[Edit: just noticed the previous comment had already mentioned pypy]> I'm aware it is 2x slower on non-Apple CPUs.Do you know why? As far as I can tell, HVM has no aarch64/Apple-specific code. Could it be because Apple Silicon has wider decode blocks?> can be underwhelming, and I understand if you don't believe on my wordsI don't think anyone wants to rain on your parade, but extraordinary claims require extraordinary evidence.The work you've done in Bend and HVM sounds impressive, but I feel the benchmarks need more evaluation/scrutiny. Since your main competitor would be Mojo and not Python, comparisons to Mojo would be nice as well.",
      "The only claim I made is that it scales linearly with cores. Nothing else!I'm personally putting a LOT of effort to make our claims as accurate and truthful as possible, in every single place. Documentation, website, demos. I spent hours in meetings to make sure everything is correct. Yet, sometimes it feels that no matter how much effort I put, people will just find ways to misinterpret it.We published the real benchmarks, checked and double checked. And then you complained some benchmarks are not so good. Which we acknowledged, and provided causes, and how we plan to address them. And then you said the benchmarks need more evaluation? How does that make sense in the context of them being underwhelming?We're not going to compare to Mojo or other languages, specifically because it generates hate.Our only claim is:HVM2 is the first version of our Interaction Combinator evaluator that runs with linear speedup on GPUs. Running closures on GPUs required colossal amount of correctness work, and we're reporting this milestone. Moreover, we finally managed to compile a Python-like language to it. That is all that is being claimed, and nothing else. The codegen is still abysmal and single-core performance is bad - that's our next focus. If anything else was claimed, it wasn't us!",
      "> I spent hours in meetings to make sure everything is correct. Yet, sometimes it feels that no matter how much effort I put, people will just find ways to misinterpret it.from reply below:> I apologize if I got defensive, it is just that I put so much effort on being truthful, double-checking, putting disclaimers everywhere about every possible misinterpretation.I just want to say: don't stop.  There will always be some people who don't notice or acknowledge the effort to be precise and truthful.  But others will.  For me, this attitude elevates the project to something I will be watching.",
      "That's true, you never mentioned Python or alternatives in your README, I guess I got Mandela'ed from the comments in Hacker News, so my bad on that.People are naturally going to compare the timings and function you cite to what's available to the community right now, though,  that's the only way we can picture its performance in real-life tasks.> Mojo or other languages, specifically because it generates hateMojo launched comparing itself to Python and didn't generate much hate, it seems, but I digressIn any case, I hope Bend and HVM can continue to improve even further, it's always nice to see projects like those, specially from another Brazilian",
      "Thanks, and I apologize if I got defensive, it is just that I put so much effort on being truthful, double-checking, putting disclaimers everywhere about every possible misinterpretation. Hell this is behind install instructions:> our code gen is still on its infancy, and is nowhere as mature as SOTA compilers like GCC and GHCYet people still misinterpret. It is frustrating because I don't know what I could've done better",
      "Don't worry about it. Keep at it, this is a very cool project.FWIW on HN people are inherently going to try to actually use your project and so if it's meant to be (long term) a faster way to run X people evaluate it against that implicit benchmark.",
      "Introducing novel ideas and making strong statements will almost always generate some anger and denial.https://paulgraham.com/useful.html",
      "Identifying what's parallelizable is valuable in the world of language theory, but pure functional languages are as trivial as it gets, so that research isn't exactly ground-breaking.And you're just not fast enough for anyone doing HPC, where the problem is not identifying what can be parallelized, but figuring out to make the most of the hardware, i.e. the codegen."
    ],
    "link": "https://github.com/HigherOrderCO/Bend",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "<h1>Bending Over Backwards: A High-Level Farce</h1>\nMeet <em>Bend</em>, the latest programming mirage designed to replace your old, crusty Python scripts with shiny new GPU-burning extravaganzas. Developers can now enjoy the thrill of waiting 42 minutes for a basic sum function to run, discovering joys previously exclusive to dial-up Internet users. Meanwhile, comment wizards try porting code like it's an Olympic sport, only to realize that Bend sprints as fast as a sloth on sleeping pills. Surely, with enough \"micro-optimizations\" and overheated GPUs, it could someday calculate two plus two in under an hour\u2014progress! \ud83d\udc0c\ud83d\udca8\ud83d\udd25"
  },
  {
    "title": "Wuffs: Wrangling Untrusted File Formats Safely (github.com/google)",
    "points": 104,
    "submitter": "nequo",
    "submit_time": "2024-05-16T13:48:45",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=40378433",
    "comments": [
      "Wuffs is great.  I use it in Substrata (https://substrata.info/) for loading PNGs.  It is both faster and safer than LibPNG.\nIt's something around 2x faster than LibPNG in my tests (depending on the PNG file), see timings here: https://github.com/google/wuffs/issues/13#issuecomment-17325...So generally Wuffs is great and you should use it to decode your PNGs.  There are some downsides: not all of the obscure bit depths and formats that PNG supports are loaded as-is, some are converted to more standard formats.Also the Wuffs documentation is a bit hard to understand.  It's a litle bit of a mission getting PNG decoding working.  You can see my code for that here though: \nhttps://github.com/glaretechnologies/glare-core/blob/2c7174c...",
      "Related:Wuffs the Language - https://news.ycombinator.com/item?id=26731305 - April 2021 (75 comments)Wuffs\u2019 PNG image decoder - https://news.ycombinator.com/item?id=26714831 - April 2021 (138 comments)",
      "This is one of my favorite attempts at better programming language safety, because it compiles down to C that can then be shipped like normal C, so you don't get the ecosystem friction like with ex. Rust.",
      "It\u2019s an interesting idea for sure but it isn\u2019t a general purpose language, so the problem domains it can solve is very very different vs what Rust is trying to do.",
      "Nigel has said that emitting \"unsafe\" Rust is a reasonable thing for a hypothetical WUFFS 1.0 to be able to do as an alternative to C. As with good \"unsafe\" Rust written by humans WUFFS would know exactly why what it's doing is fine, it's just that the Rust compiler can't necessarily see that, hence the need to label it \"unsafe\".Today C makes most sense given the WUFFS language is still in flux.[Edited to fix a serious typo]",
      "What would be the primary benefit of emitting Rust rather than C? Both would be considered safe (assuming Wuffs generates correct code), and Rust could access the C code via FFI. Is there something I\u2019m missing?",
      "I expect that the Rust emitted by a hypothetical future WUFFS transpiler would be much easier to just drop into an existing Rust project than some C via a C FFI.It's common for C libraries that do get wrapped today (e.g. openssl) to have a two phase wrapping, a -sys crate which turns the C into Rust C FFI and then another crate to turn the Rust C FFI into something actually palatable to ordinary people.",
      "Nominally it can safely elide bounds checks via unsafe that it has proved are actually safe within the constraints of Wuffs, which is what it does for C (+ the language is built for more easy translation to  vectorizated than something like llvm is able to do for general purpose languages).So basically higher performance.FFI nominally has a runtime and compile time cost - whether that matters for you in particular will depend on your needs, but being able to publish a very simple crate without a build.rs to manage can have an attraction.",
      "I\u2019m responding to this:> that can then be shipped like normal C, so you don't get the ecosystem friction like with ex. Rust.Emitting Rust doesn\u2019t help with this.",
      "Related, in the sense of solving the same problem in a different manner: https://rlbox.dev/"
    ],
    "link": "https://github.com/google/wuffs",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "<b>Wuffs: Yet Another Google Attempt to Save the World</b>\n\nGoogle shocks no one by releasing <em>Wuffs</em>, a library that hand-holds programmers across the scary field of untrusted file formats because everyone knows handling a PNG must be akin to defusing a bomb \ud83d\udca3. Commenters leap to worship this latest geek chic, tripping over themselves to reveal just how much faster and safer their PNG-loading life has become (though some admit it's basically rocket science to use). One hero, daringly using this in \"Substrata\", manages to both simplify and complicate everyone's understanding, sparking a coder's existential crisis: to emit C or to emit Rust? Oh, the gripping dilemmas of modern programming! Meanwhile, the rest of the developer community is still trying to figure out why they need a special language to load cat pictures faster. Rest assured, Google listens to your feedback\u2014unless it's critical."
  },
  {
    "title": "ILGPU: Write GPU programs with C# and F# (github.com/m4rs-mt)",
    "points": 75,
    "submitter": "neonsunset",
    "submit_time": "2024-05-17T20:25:40",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=40393873",
    "comments": [
      "Also see https://www.fshade.org/, a F# dsl for shaders",
      "I'm going through the CUDA courses. I've done GPU and CPU optimization as an enthusiastic amateur in my day job once or twice a year, but it's not my core focus.It quickly seems that the low level C/Cpp is becoming obsolete, and it's hard to squeeze performance unless you're doing something truly green field / new. Otherwise someone has already optimized the hell out of it.So what's the use case for porting GPU to higher level languages like C#? What would you use this for?",
      "> It quickly seems that the low level C/Cpp is becoming obsolete, and it's hard to squeeze performance unless you're doing something truly green field / new. Otherwise someone has already optimized the hell out of it.I hear and see both of these sentiments frequently from the internet crowd (on-lookers). It's both wrong and humorously arrogant. I'll repeat what I said to someone on reddit yesterday: there are thousands (maybe 10s?) scattered around the FAANGs, NVIDIA, AMD, Intel, accelerator startups, boutiques, etc. whose day to day is both C/C++ and squeezing perf out of kernels and getting many points (sometimes 10s) improvement. Certainly the wins aren't daily but I'm saying they do steadily find room for improvement. How is that possible? I'll give you a hint: platforms, demands, hardware, use-cases all change essentially on a quarterly basis.So before you proclaim victory on behalf of whatever high-level framework, ask yourself if you're really familiar with the production and business environment for this kind of code.",
      "As a learner and self proclaimed amateur, I assume the vitriolic tone is directed elsewhere. Without that, you're saying that performant pipelines are definitely in demand and optimization is still a full time job.  That's good! I'd like to get better at that.",
      ">I assume the vitriolic tone is directed elsewhereI'm always really shocked on hn when people getting called out for arrogance respond with accusations (of vitriol). What day job do you have where you can make proclamations like \"It quickly seems that the low level C/Cpp is becoming obsolete\" while simultaneously admitting being an amateur and not get checked. Must be very different from my day job where being precise and accurate and conservative is paramount. Moreover what kind of habit of thought are you in that being called out for that is read as vitriol?",
      "Oh my god, calm down. Jesus christ.",
      "Same thing applies here: I'm not the one the one that's not calm. I very calmly pointed out that op is wrong. That's it. You painting that as \"not calm\" is the only abnormal thing going on here.",
      "1. C and C++ aren\u2019t going anywhere.2. I don\u2019t think you have an appreciation for the sheer amount of software\u2014including lots of very critical software\u2014implemented in C and C++ that are being improved upon daily.A buddy of mine works on critical low-level software (including C) in the energy industry. Millions of lines of code. The effects, positive or negative, of any single code change can affect tens of thousands of Americans (likely even more). His day job is to maintain and continuously optimize this software. Given your comment, I think you\u2019d be surprised to learn that he never runs out of work.",
      "Make it more accessible? Prototyping? Eg. easily determining if your use case is even suited for a GPU workload. Best case - it is, and now you can write a custom CUDA kernel to squeeze out more performance. Worst case, you lose a couple of hours vs weeks before you discover it\u2019s not going to work.",
      "Given IL itself is an abstract stack-based bytecode, it can be compiled to the corresponding IR, which can then target corresponding back-end (CUDA, OpenCL, CPU, etc.) - this is what ILGPU does.Because all code is in the single repository in the post and is fairly easy to read, you can skim through it to draw your own conclusions if this interests you.Also, very easy to start using: just `dotnet add package ILGPU` on most configurations (as ADHD puts higher mental strain on activities involving complex configuration, I try to keep to the tools that have minimal ceremony)C# (and F# by extension) generally allow to write system-ish code, with references to locals and same C primitives, which means that you're likely not sacrificing in performance in this particular scenario by having the language be higher-level. After all, you're using ILGPU's APIs first and foremost.As to why use it at all - you are likely to move faster with it than C++, especially if it's not your full-time job, with all the escape hatches to extract 99.9% efficiency still on the table (that is, if performance of the kernel emitted by ILGPU has issues in the first place - see below for alternative, cheap FFI and easy C/C++ integration are still there as well).It also lets you do things like PTX assembly: https://github.com/m4rs-mt/ILGPU/blob/master/Samples/InlineP..."
    ],
    "link": "https://github.com/m4rs-mt/ILGPU",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "**Title: ILGPU: Paving the Way for Programmers to Code GPUs in C# Without Ever Learning How to Optimize Anything**\n\nIn an audacious attempt to enable every *Tom, Dick, and Harry* to slam poorly adapted high-level code onto GPUs, ILGPU boldly asserts, \"Yes, C# fanboys can now pretend to do performance computing too!\" Enthusiastic amateurs emerge from every nook and cranny of their daytime cubicles to heap accolades on this majestic bridge to nowhere, opining on its revolutionary potential to change absolutely nothing. Meanwhile, the comments section transforms into the tech equivalent of a suburban dads' lawn mowing forum, where everyone argues over the best fuel type while the grass just keeps growing. In a world where understanding the machine is as antiquated as VHS tapes, why not just `<em>simplify</em>` everything until your GPU code runs as smoothly as your grandma's first Zoom call? \ud83d\ude80\ud83d\ude43"
  },
  {
    "title": "Non-Euclidean Doom: what happens to a game when pi is not 3.14159 (2022) [video] (ccc.de)",
    "points": 378,
    "submitter": "robin_reala",
    "submit_time": "2024-05-17T12:43:14",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=40389267",
    "comments": [
      "There was an example of this in the classic 'Duke Nukem 3d'. It had a level by Richard \"Levelord\" Gray, 'Lunatic Fringe'.https://dukenukem.fandom.com/wiki/Lunatic_FringeThis level had a circular hallway ring around the outside that had two full rotations around without intersecting, using the 'build' engine's ability to separate areas by their room connections that also drove the 'room over room' technology which was groundbreaking at the time.It made for fun multiplayer, and the illusion held well there. The central chamber has 4 entrances/exits if I recall, and you would only encounter two of them in each loop around the outside.I recall building a toy level while experimenting with the engine that \"solves\" the \"3 houses with 3 utilities without crossing\" puzzle using this trick as well.",
      "In what sense is the Duke Nukem thing \"an example of this\"? The duke thing is an internally consistent programmed behaviour, this is... just random errors caused by a random change in the source code. Duke is maybe non-euclidean geometry, or something. This doom pi thing is... nothing to do with geometry. More an example of \"garbage in, garbage out\" maybe.",
      "It's an example of \"non-euclidean\" space, and yes, it is a bit different than the article.",
      "Room over room (as done in later build games) usually does not require the sectors to overlap in this manner as it is a different thing (it is extension of how swimable water works, where the engine renders the other sector instead of floor/ceiling).While Lunatic Fringe is pretty in-your-face example of impossible geometry in build, the duke3d maps contain many more cases of intersecting geometry. Obviously such things are impossible in Doom because there is no way to build BSP tree out of that and because doom only tracks X/Y coordinates of player(s)/monsters.",
      "No mention of the real Prey (2006) in a discussion of weird geometry in games?",
      "Is there no way of building a BSP out of it? I don't see why it has to be Euclidean to be partitioned, and loops are also possible (e.g. Deimos Lab). (The coordinates are definitely a blocker, so this question is academic.)",
      "The \u201csectors\u201d in the resulting level data have to be convex for the doom engine. The \u201casset pipeline\u201d handles that by breaking up non-convex geometry into smaller convex sectors. So, there are no loops or holes in the actual level data, also from the cursory glance both of the large loops in Deimos Lab are actually not complete loops, but they have a place where the loop is broken. But that does not matter that much, as almost any level contains geometry that is either concave or has a hole (courtyard in E1M1, both large rooms in MAP01\u2026)",
      "Portals allow weird stuff (non linear geometry) in a BSP level. I thought Doom had petals.",
      "The primary thing that BSP does is that it maps coordinates onto a BSP node/sector. Thus you cannot have overlapping geometry, as this mapping would not be unique. Quake has some idea of portals (I'm not sure about Doom), but it is used only as an additional layer of optimization, the engine is not fundamentally portal-based.",
      "> only tracks X/Y coordinates of player(s)/monsters.It does, otherwise Lost Souls and Cacodemons wouldn't able to fly."
    ],
    "link": "https://media.ccc.de/v/mch2022-236-non-euclidean-doom-what-happens-to-a-game-when-pi-is-not-3-14159-",
    "first_paragraph": "Luke Gotszling",
    "summary": "**Non-Euclidean Doom: what happens to a game when pi is not 3.14159 (2022) [video] (ccc.de)**\n\nStep right up to witness the carnival of coders tampering with mathematical constants as if they're in the middle of a mid-life crisis. Luke Gotszling dives into the chaos of tweaking pi in doom, spawning a monstrous geometric anomaly that could only be dreamed up by someone who\u2019s watched **<i>Inception</i>** too many times on repeat. Commenters, nostalgic for the good ol\u2019 days of a genuinely flat Duke Nukem universe, engage in pedantic quarrels to decisively prove that\u2014yes!\u2014you can indeed compare genetically-modified apples to vintage oranges. Because, why not contort logic like a pretzel in spaces where the mere act of walking through a door requires a PhD in theoretical physics? \ud83d\udd04\ud83e\udd13\ud83d\udeaa"
  },
  {
    "title": "Exact binary vector search for RAG in 100 lines of Julia (domluna.com)",
    "points": 82,
    "submitter": "lunaticd",
    "submit_time": "2024-05-16T15:09:21",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=40379347",
    "comments": [
      "Dom! Fellow Julian here!I loved this post <3 The hamming distance is one of my favorite demos of the conciseness of Julia:hamming_distance(s1, s2) = mapreduce(!=, +, s1, s2)I'm a bit swamped at the moment but I'll a response article later - they're still some juicy perf on the table here.Thanks for the post, such a good showcase.",
      "Why not use the built in BitVector type that has specialized code for things like xor?https://docs.julialang.org/en/v1/base/arrays/#Base.BitArray",
      "for i in 0:7\n        c += (r >> i) & 1\n    end\n\nThis is just popcnt, surely Julia has a built in for that.",
      "There is, it's called count_ones. Though I wouldn't be surprised if LLVM could maybe optimize some of these loops into a popcnt, but I'm sure it would be brittle",
      "author here. I thought there might be a machine instruction for this but wasn't sure, I also didn't know Julia had a count_ones that counted the 1s.Thanks! With this the timings are even faster. I'll update the post.",
      "I had Opus translate your code to Rust    fn hamming_distance_u8(x1: u8, x2: u8) -> usize {\n        (x1 ^ x2).count_ones() as usize\n    }",
      "From what I've heard it's actually faster to create a 256 byte lookup table than to use popcnt.",
      "It used to be pretty bad on old intel processors but nowadays it should be faster than an L1 fetch.",
      "For those like me who are not familiar with the field... The article assumes you know the entire context - as far as I could see there is no explanation of any part except the technical details.RAG = Retrieval-Augmented GenerationThe field is machine learning. Retrieval = get relevant documents. Generation = create answer for user (based on the docs).",
      "I'm not sure what is meant by \"exact\" here - do they describe their binarisation process at all? This seems more like an XOR benchmark than a rag benchmark, no mention of recall or other relevant performance metrics"
    ],
    "link": "https://domluna.com/blog/tiny-binary-rag",
    "first_paragraph": "",
    "summary": "Title: Another Day, Another Julia Show-Off\n\nDom and the fellow Julians are back at it, cramming every bite of performance out of their beloved language. This time, they've managed to make Hamming distances *so concise* they're almost unreadable. Commenters leap at the chance to flex their optimization muscles, suggesting built-ins and machine instructions likely invisible without a magnifying glass <em>(and a degree in computer science)</em>. If you thought knowing what RAG stands for was a prerequisite, you're too late\u2014this party's for code golfers and the acronym adept!"
  },
  {
    "title": "Toon3D: Seeing cartoons from a new perspective (toon3d.studio)",
    "points": 319,
    "submitter": "lnyan",
    "submit_time": "2024-05-17T13:04:06",
    "num_comments": 93,
    "comments_url": "https://news.ycombinator.com/item?id=40389445",
    "comments": [
      "It's interesting that they used the Planet Express building from Futurama as one of their examples of 3D-inconsistency, because I'm pretty sure the exteriors are in fact computer-generated from a 3D model. Watch the show and you can see the establishing shots usually involve a smooth complex camera move around the building.",
      "Agreed, most or all shots of the Planet Express building and Planet Express ship are 3D renderings, even in the original first few seasons. Beyond that, even some shots of Bender in Space are 3D renderings, especially in cases where a complex and continuous shift in perspective is required.Non-photo-realistic (NPR) 3D art goes back a surprisingly long way in animations. I rewatched the 1988 Disney cartoon \"Oliver and Company\" recently, and I was surprised to see that the cars and buildings were \"cel-shaded\" 3D models. I assumed that the movie had been remastered, but when I looked it up, I found out that it was the first Disney movie ever to make heavy use of CGI[0] and that what I was seeing was in the original. The page I found says:\"This was the first Disney movie to make heavy use of computer animation. CGI effects were used for making the skyscrapers, the cars, trains, Fagin's scooter-cart and the climactic Subway chase. It was also the first Disney film to have a department created specifically for computer animation.\"References\n----------0: https://disney.fandom.com/wiki/Oliver_%26_Company",
      "> \"This was the first Disney movie to make heavy use of computer animation. [...]\"Tron came out 1982, six years before Oliver & Company.https://en.wikipedia.org/wiki/Tron",
      "I guess it depends on the definition of \"heavy use.\" I know in Tron a few scenes were CG, and there were a few CG+live-action bits, but the majority was filmed on normal physical sets in high-contrast, then painstakingly hand-processed[1] to add the neon \"glow\".[1] https://filmschoolrejects.com/tron-costumes-glowing-effect/  Thanks legions of Taiwanese animators (:",
      "From your link:\n>The 1982 Disney movie is privy to a remarkable number of firsts: the first feature-length film to combine CGI and live-action; the first talking and moving CGI character; the first film to combine a CGI character and a live-action one; the first fully CGI backgrounds\u2026 The list goes on and on.Sounds pretty heavy to me.",
      "And the film OP mentioned Oliver & Company:>Eleven minutes of the film used \"computer-assisted imagery\" such as the skyscrapers, the taxi cabs, trains, Fagin's scooter-cart, and the climactic subway chaseI think Tron wins in terms of CGI",
      "But Disney financed and distributed Tron. It wasn't made by a Disney Studio, and most of the animation was outsourced to a Taiwanese studio because Disney wouldn't lend any of their own talent. So I think it's fair to say that Oliver & Company is the first Disney-made film to use CGI.",
      "The Great Mouse Detective (1986) was earlier and the ending sequence is CG (printed out and traced onto cels so traditional 2D characters could be drawn on top).",
      "That's a good point. What's funny is that \"The Great Mouse Detective\" was actually the film I was thinking of this whole time - I believe the ending sequence took place in Big Ben, and it looks quite good by 2024 standards. But I forgot the name of the movie and assumed it was \"Oliver & Company\" because Oliver is a plausible name for an English mouse :)",
      "And large amounts of the \"computer\" graphics in Tron are hand drawn."
    ],
    "link": "https://toon3d.studio/",
    "first_paragraph": "Hand-drawn scenes are not 3D consistent, so we create Toon3D to recover\n            camera poses and dense geometry! We do this with a piecewise-rigid deformation optimization at hand-labeled\n            keypoints and using monocular depth as a prior. Now we can interpolate novel views never before seen! Press\n            the button to move the cameras between two\n            viewpoints! Note that we reconstruct the scenes with more than two hand-drawn images, but this demo shows\n              a smooth transition between just two of the inputs views.",
    "summary": "\ud83c\udfa8 In a bold leap for animated redundancy, the fine folks at Toon3D decided that cartoons simply can't be cartoons without geometrically consistent 3D reconstructions. With a cocktail of \"hand-labeled keypoints\" and \"monocular depth priors\" (because nothing says 'easy' like a bit of homemade depth-estimation on your Saturday morning cartoons), they now offer you a chance to twist and turn through scenes never intended to be viewed from more than one angle. Meanwhile, the comment section evolves into a history lesson on CGI in animations, as everyone tries to prove they paid more attention in Film Studies than the Toon3D engineers did in \"Leave It To The Animators 101\". As expected, acknowledge the digital forebears like <em>Tron</em> and <em>Oliver & Company</em>, and don't miss the opportunity to confuse which nostalgic cartoon featured which tech first. \ud83c\udf7f\ud83d\udc53"
  },
  {
    "title": "Ubershaders: A Ridiculous Solution to an Impossible Problem (2017) (dolphin-emu.org)",
    "points": 74,
    "submitter": "Grognak",
    "submit_time": "2024-05-16T15:52:53",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=40379833",
    "comments": [
      "Has it really been 9 years since I started working on Ubershaders?I'm a little surprised no better solution has come along. Vulkan didn't even exist back then (and DirectX 12 had only just released) but instead of making things better, it digs it's feet even deeper into the assumption that all shaders will be known ahead of time (resulting in long \"shader recompilation\" dialogs on startup on many games).I've been tempted to build my own fast shader compiler into Dolphin for many common GPU architectures. Hell, it wouldn't even be a proper compiler, more of a templated emitter as all shaders fit a pattern. Register allocation and scheduling could all be pre-calculated.But that would be even more insane than ubershaders, as it would be one backend per gpu arch. And some drivers (like Nvidia) don't provide a way to inject pre-compiled shader binaries.On the positive side, ubershaders do solve the problem, and modern GPU drivers do a much better job at accepting ubershaders than they did 9 years ago. Though that's primarily because (as far as I'm aware) examples of Dolphin's ubershader have made their way into every single shader compiler test suite.",
      "I still don\u2019t understand why you didn\u2019t use the precompiled shaders packed with the games\u2026 you\u2019re emulating the GameCube or Wii GPU, and it\u2019s never going to change, and the games provide precompiled shaders.",
      "Don't you think intermediate representation like SPIR-V would suffice in mostly eliminating stutter? Yuzu used that and shader stutter seemed to be minimal and I can image that the shaders generated by Yuzu are much more complex than Dolphin.",
      "The only step that SPIR-V replaces is parsing the GLSL to an AST tree, and that's only a small part of the total time to compile a shader. Usually the bottleneck is Register allocation or scheduling.Back when Vulkan was developed, there were a bunch of OpenGL drivers out there which had random AST parsing bugs (Dolphin even has a bunch of workarounds for them); So a large chunk of the motivation for SPIR-V was avoiding the need for every driver to implement their own GLSL parser and the associated bugs.The problem for Dolphin is not the complexity of the shader, but the quantity.Shaders in modern games are usually written manually (or authored in a shader node editor by an artist), so it's rare for a game to have more than a few thousand total. Better games might only have a few dozen for the entire game.But because gamecube/Wii games configure the TEV pixel pipeline though a dynamic API, some games use that API in a pattern where Dolphin can find itself generating hundreds of shaders per second. Some games even manage to generate new shaders continually as you play, because they append junk state to their pixel pixeline state which dolphin doesn't detect as a duplicate.",
      "Shaving off the frontend costs is not going to be nothing. I don't know if Dolphin is still using FXC/D3DCompile or if they've switched to DXC, but FXC is infamously slow, even for very simple shaders. Dolphin's shaders are medium-complexity IIRC, so I'd expect removing the frontend to be a decent win.The driver PSO compilers aren't amazing but they're also not terrible. Most games do some form of hash-n-cache for PSO compilation and while stutters are still an issue, it's not the worst in the world. With the frontend gone, I'd expect ~50 shaders per second to be roughly stutter-free.Being smarter about specialization is probably a good idea -- having a blend between \"GPU interpreter\" and \"full specialized pipeline\" is where I think you should head. Several of the weirder TEV features could probably be moved to branching on dynamic buffer contents.Not to mention using newer features like bindless to merge draw calls. I always wanted to do that but got too busy before I stopped working on Dolphin :)",
      "It's interesting to see the parallels between this and an engine for a dynamic programming language. The one I'm most familiar with is JavaScript.When you first need to run something, you run it on the interpreter (JS) / ubershader (Dolphin). But once you know it's going to be run repeatedly (rarely for JS, almost always for Dolphin), you kick off an async compilation to produce JIT code (JS) / a specialized shader (Dolphin). You continue running in the expensive mode (interpreter / ubershader) until the compilation is complete, then you switch over seamlessly.",
      "Does anyone know why this isn't an issue for modern games on PC? I assume it's because more uniforms are used, and the amount of shaders that actually need to be compiled at runtime is minimized, not to mention that the Graphics API is optimized to compile the shaders in the format they are provided. So is the issue with Dolphin that GameCube games would compile new shaders for lots of different configurations of effects / stages? Would some sort of preprocessor that converts shader compilations to some mini-ubershader with uniforms that can handle a lot of the different effects be feasible? And then depending on how many completely different shaders there are you would have many different mini-ubershaders?",
      "It is an issue with some modern games (I recently played a title that had a \"Preparing Shaders...\" loading screen); the main difference is that those games know the full set of what they need to do and can precompile most of them up-front, while an emulator like Dolphin needs to handle whatever the game throws it on the fly.Also, games might know what shaders it can skip and what it can't, but Dolphin can't skip shaders if they aren't compiled, because it doesn't know what the game will do with the render (e.g. Miis work by rendering their heads once into a texture, and then reusing that. If it skips the render because the shader isn't ready, the Mii will just be missing forever).Some emulators handle this by sharing \"shader caches\" between users so that they have a better idea of what the game will use; Dolphin opted for a different solution here.",
      "I think it's because PC games know they need to deal with compilation, so they do it on the load screen or whatever. GC games can pre-compile them and just stuff it on the disk, so there's no compilation cost.",
      "Discussed at the time:Ubershaders: A Ridiculous Solution to an Impossible Problem - https://news.ycombinator.com/item?id=14884992 - July 2017 (88 comments)"
    ],
    "link": "https://dolphin-emu.org/blog/2017/07/30/ubershaders/",
    "first_paragraph": "Written by\n      \n      \nMayImilae, \n      \n      \nJMC47\n      \n      on\n      \n      \n      July 30, 2017",
    "summary": "Title: **Ubershaders: A Ridiculous Solution to an Impossible Problem (2017) (dolphin-emu.org)**\n\nIn a world where complexity and redundancy collide, the ubershaders saga unfolds, leaving technologists and forum warriors alike *bewildered*. As the emulator devs embark on a Sisyphean quest to tackle the ever-regenerating shader issue, they inadvertently craft an Eldritch horror of a solution: ubershaders. Comment sections spiral into chaos, revealing deep-seated nostalgia for simpler times when magic smoke and *mystical GameCube rituals* solved everything. Meanwhile, e-scholars debate the existential nuances of SPIR-V vs. GLSL as if the fate of humanity, rather than frame rates, hung in the balance. \ud83d\ude31\u2728"
  },
  {
    "title": "An Animated QR Code of Bad Apple (exozy.me)",
    "points": 16,
    "submitter": "LorenDB",
    "submit_time": "2024-05-16T11:32:52",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=40377122",
    "comments": [
      "If you haven't already, try compressing the video using Handbrake to cut down on its size. 1 GB for 5 minutes is quite a lot.",
      "And thus does the wheel of technology spin.I have a very slight problem in that I went to grad school when professionals still used calculators, and real professionals used HP calculators. And so I still own, and use, a variety of HP scientific calculators. I can quit any time I want, I swear.The HP-48 line (for instance) transferred files via an LED/photodiode pair. You'd point the calculators at each other and let them flash away until they were done. This seems to be that, but much better. Or at least much faster.",
      "What I wouldn't give for a mobile>mobile or desktop/laptop>mobile cross platform file transfer that only required camera permissions at 2mbit/sec or similar speeds.All of the non-internet ios > android file transfer options I've seen are very clunky.This is really neat.",
      "Please make a live demo version of this using only JavaScript and HTML :D"
    ],
    "link": "https://a.exozy.me/posts/bad-apple-animated-qr-code/",
    "first_paragraph": "May 15, 2024",
    "summary": "In a groundbreaking moment of nostalgia-cum-fixation for the digital era, someone has finally answered the burning question no one asked: Can you make a QR code animate \"Bad Apple\"? Readers are enthralled, flocking en masse to prod this digital beast with the ancient Handbrake tool to make it less obese on their already heaving drives. Commenter #45 juggles HP calculators like hipster cred as they wax poetic about ye olden days of LED/photodiode flirtations, clearly forgetting the QR code has no soul to flash back. Meanwhile, a coder in the comment abyss, probably avoiding actual work, demands a live demo in JavaScript and HTML, because what the internet clearly needs is more quirky but utterly use-next-day projects. \ud83d\udd25\ud83d\udcf1\ud83d\udcbe"
  },
  {
    "title": "Ex-OpenAI staff must sign lifetime no-criticism contract or forfeit all equity (x.com)",
    "points": 293,
    "submitter": "apsec112",
    "submit_time": "2024-05-17T22:34:51",
    "num_comments": 148,
    "comments_url": "https://news.ycombinator.com/item?id=40394778",
    "comments": [
      "It's time to find a lawyer. I'm not one but  there's an intersection with California SB 331, also known as \u201cThe Silenced No More Act\u201d. while it is focused more on sexual harrasment, it's not limited to that, and these contracts may run afoul of that.https://silencednomore.org/the-silenced-no-more-act",
      "Definitely an interesting way to expand existing legislation vs having a new piece of legislation altogether.",
      "That's not enforceable, right? I'm not a lawyer, but even I know not contract can strips you out of rights given by the constitution.",
      "Extra respect is due to Jan Leike, then:https://x.com/janleike/status/1791498174659715494",
      "The superalignment team was not focused on that kind of \u201csafety\u201d AFAIK. According to the blog post announcing the team,https://openai.com/index/introducing-superalignment/> Superintelligence will be the most impactful technology humanity has ever invented, and could help us solve many of the world\u2019s most important problems. But the vast power of superintelligence could also be very dangerous, and could lead to the disempowerment of humanity or even human extinction.> While superintelligence seems far off now, we believe it could arrive this decade.> Managing these risks will require, among other things, new institutions for governance and solving the problem of superintelligence alignment:> How do we ensure AI systems much smarter than humans follow human intent?> Currently, we don't have a solution for steering or controlling a potentially superintelligent AI, and preventing it from going rogue. Our current techniques for aligning AI, such as reinforcement learning from human feedback, rely on humans\u2019 ability to supervise AI. But humans won\u2019t be able to reliably supervise AI systems much smarter than us, and so our current alignment techniques will not scale to superintelligence. We need new scientific and technical breakthroughs.",
      "That doesn't really contradict what the other poster said. They're calling for regulation (digging a moat) to ensure systems are \"safe\" and \"aligned\" while ignoring that humans are not aligned, so these systems obviously cannot be aligned with humans; they can only be aligned with their owners (i.e. them, not you).",
      "Alignment in the realm of AGI is not about getting everyone to agree.  It's about whether or not the AGI is aligned to the goal you've given it.  The paperclip AGI example is often used, you tell the AGI \"Optimize the production of paperclips\" and the AGI started blending people to extract iron from their blood to produce more paperclips.Humans are used to ordering around other humans who would bring common sense and laziness to the table and probably not grind up humans to produce a few more paperclips.Alignment is about getting the AGI to be aligned with the owners, ignoring it means potentially putting more and more power into the hands of a box that you aren't quite sure is going to do the thing you want it to do.  Alignment in the context of AGIs was always about ensuring the owners could control the AGIs not that the AGIs could solve philosophy and get all of humanity to agree.",
      "Right and that's why it's a farce.> Whoa whoa whoa, we can't let just anyone run these models. Only large corporations who will use them to addict children to their phones and give them eating disorders and suicidal ideation, while radicalizing adults and tearing apart society using the vast profiles they've collected on everyone through their global panopticon, all in the name of making people unhappy so that it's easier to sell them more crap they don't need (a goal which is itself a problem in the face of an impending climate crisis). After all, we wouldn't want it to end up harming humanity by using its superior capabilities to manipulate humans into doing things for it to optimize for goals that no one wants!",
      "Humans are not aligned with humans.This is the most concise takedown of that particular branch of nonsense that I\u2019ve seen so far.Do we want woke AI, X brand fash-pilled AI, CCPBot, or Emirates Bot? The possibilities are endless.",
      "They failed to align Sam Altman.They got completely outsmarted and out maneuvered by Sam AltmanAnd they think they will be able to align a super human intelligence? That it won\u2019t outsmart and out maneuver them easier than Sam Altman did.They are deluded!"
    ],
    "link": "https://x.com/KelseyTuoc/status/1791584357184127269",
    "first_paragraph": "",
    "summary": "**Ex-OpenAI Staff Sign Your Soul Away For A Slice of Equity**\n\nIn a stunning innovation in corporate enslavement, ex-OpenAI staffers are now rewarded for their silence more lucratively than for their contributions to AI. In what appears to be a legally dubious move that would make a Constitutional scholar spit out their coffee, former employees must sign away their right to ever criticize the company if they wish to see a dime of equity. As legal armchair experts on forum threads rush to compare these contracts to everything from indentured servitude to dark magic pacts, one must wonder if part of OpenAI's secret project was to develop artificial intelligence sharp enough to craft ironclad legal traps. Meanwhile, in the realm of common sense (a seemingly scarce resource), the only alignment observed is between OpenAI's desperation for control and the dystopic narratives it fears its creations might unleash. \ud83e\udd16\ud83d\udcb8\ud83d\udd12"
  },
  {
    "title": "Pacific squid flashes its attack 'headlights' (bbc.com)",
    "points": 37,
    "submitter": "onemoresoop",
    "submit_time": "2024-05-16T14:04:25",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=40378628",
    "comments": [
      "In unrelated note, it's funny to be greeted with a 20 secs  Ad video before seeing the 50 secs squid video you land on the site to watch! Ah.. Ads are ruining the entire web these days, and the experience keeps worsening.",
      "A Cosmopolitan species in fact that can be found from Naples to Florida, Alaska to Santiago de Chile, Sidney to Madagascar and from Norway to South-Africa. Conquered  every single ocean except the poles and the Eastern part of the Mediterranean.And yes, is a truly spectacular big predator. A little like the invertebrate version of a big cat, specially with that claws.",
      "If pacific squid are humboldt squid, they are limited to the eastern pacific ocean.",
      "They are talking about the cool spaceship disguised as cephalopod: Tanigia danae (2 meter long).https://schmidtocean.org/wp-content/uploads/Taningia-danae.j...All that their preys see is two big oblique glowing cat-eyes before to be snared by lines of sharp hooks and killed by a bite. \"Night at the African Savannah\" style, but without all the roaring.",
      "A favoured snack for sperm whales! However the sharp squid beaks sometimes get lodged in the whale's intestines, which is suspected to lead to the production of ambergris.",
      ">> The team works from a research vessel called DagonThe perfect name for a ship searching for benthic beasts with luminous tentacles. I bet her dinghy is called \"R'lyeh\".",
      "Similar to video adverts that humor you for a few seconds and end on a bedazzling white background behind their logo.",
      "I like to think about what lived in the Oceans of Mars, or maybe even Europa if things were slightly different.But the stuff in our own ocean is so alien already, and we share common ancestors!",
      "They made a movie about that! https://en.wikipedia.org/wiki/Europa_Report",
      "Arthur C Clarke's 2061 (sequel to 2001 and 2010) was also about about a troubled mission that finds life in Europa's oceans. Europa Report sounds like it might have been a little inspired by that novel?"
    ],
    "link": "https://www.bbc.com/news/science-environment-69016405",
    "first_paragraph": "",
    "summary": "The BBC, in its relentless quest to fill every crevice of its website with <em>essential</em> knowledge, informs us that some squids use what can only be described as \"headlights\" to dazzle and devour their prey. In the echo chamber of the comments section, enthusiasts <i>boldly</i> ignore the article's show-stopping marvels to rant about the unbearable 20-second ad apocalypse. Delving deeply into oceanic esoterics, they liken squids to big cats of the deep, complete with science-fiction references and sidebars about alien life of the aquatic kind. But fret not\u2014amidst the talk of hypothetical Martian oceans and whale digestion dramas, the quest for knowledge wages on aboard the aptly named research vessel \"Dagon,\" charting courses through comments as murky and perilous as the oceanic depths. \ud83e\udd91\ud83d\udca1\ud83c\udf0c"
  },
  {
    "title": "Show HN: I built a website to create financial models for any stock online (useequityval.com)",
    "points": 144,
    "submitter": "trevzercap",
    "submit_time": "2024-05-17T17:59:22",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=40392548",
    "comments": [
      "I\u2019m consistently surprised at the lack of basic financial literacy in the HN crowd. The title says this is a tool to create financial models, not that it is a well-tuned financial model. Yeah, you have to make better assumptions than straight-line extrapolation from last year\u2019s trend to arrive at reasonable valuations. The point is that this shows you what assumptions you have to make to arrive at a rationally-calculated stock value, and pre-populates all of the other necessary data and formulas in a slick UI, which is pretty cool.The models that make the big bucks are the ones that ingest a ton of other external data to predict the numbers that go in the data entry cells here. And yeah, those don\u2019t get posted online for free.",
      "https://www.useequityval.com/model?ticker=CRSPCurrent Price: $56.22Projected Price: $20,806,772,549,824,028.00Difference:\n37,009,556,296,378,460%Glad I'm long.",
      "The hard thing about modeling is not the math to get to present value of the stock. It's figuring out which assumptions make sense.Assuming that a revenue growth rate of 84,762.39% is (a) a valid number and (b) expected to remain the same over the next X years does not quote-unquote \"make sense\"",
      "37,009,556,296,378,460%That is a decent return. I bought a call option for RILY. Went to zero. Well...",
      "It's about as reliable as I thought.If it was even remotely reliable, this would be a billion dollar idea (at least) treated as a secret sauce in an investment company.Instead, it takes some input, throws some garbage output, but as it's not blatantly just random numbers, people think it's helpful for investing.",
      "Haha the initial model is not a good representation of value as it projects the lasts years metrics out 5 years. 80K% growth for 5 years would do that. Thanks for pointing it out. I need to incorporate some boundaries for the initial values lol.",
      "https://xkcd.com/605/",
      "I put in quite a few stocks and the results were often strange. Negative values, under a dollar, etc. These were all stable companies, not penny stocks.",
      "Yeah, there should be multiple massive disclaimers on this site. I'd be worried about regulatory issues as well.Edit: why disagree?",
      "Why? Anyone who invests based on such obviously wrong numbers shouldn\u2019t be protected from themselves."
    ],
    "link": "https://www.useequityval.com/",
    "first_paragraph": "Create, save, and share valuation models for any public company to inform your next investment decision",
    "summary": "Title: Show HN: The Newest Toy for Amateur Day Traders\n\nAnother day, another financial model generator that convinces the basement-dwelling day traders of Hacker News that they're just one algorithm away from beating George Soros at his own game. <em>\u201cCreate, save, and share valuation models\u201d</em> \u2013 because your random assumptions need an audience! Commenters tripped over themselves to critique not the ludicrous outputs \u2013 like a projected stock price increase of 37,009,556,296,378,460% \u2013 but the rudimentary financial literacy on display. Because why not debate the semantics of a model that suggests buying stocks in companies apparently poised to become wealthier than entire galaxies. \ud83d\ude80\ud83d\udcb8\ud83d\ude02"
  },
  {
    "title": "The Unusual Evolutionary Journey of the Baobab Tree (nytimes.com)",
    "points": 13,
    "submitter": "Petiver",
    "submit_time": "2024-05-15T22:23:07",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://www.nytimes.com/2024/05/15/science/baobab-trees-evolution.html",
    "first_paragraph": "",
    "summary": "On the eminent digital pages of the <i>New York Times</i>, armchair botanists and casual readers alike are treated to a thrilling saga titled <i>The Unusual Evolutionary Journey of the Baobab Tree</i>. The article meticulously chronicles these trees as if they\u2019re wayward celebrities dabbling in evolutionary novelties rather than century-old flora. Comment sections have erupted into a battleground where self-proclaimed tree huggers and skeptics swap low-effort puns and half-baked analogies about survival, blissfully unaware that the real survival challenge lies in enduring their attempts at humor. Could there be a more profound metaphor for human existence than a bunch of Internet strangers missing the forest for the baobabs? \ud83c\udf33\ud83d\ude02"
  },
  {
    "title": "LoRA Learns Less and Forgets Less (arxiv.org)",
    "points": 126,
    "submitter": "wolecki",
    "submit_time": "2024-05-17T13:00:55",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=40389421",
    "comments": [
      "The findings are that the best fine-tune performance comes from fine-tuning all weights, followed my MLPs, followed by attention heads, using LoRA. Authors assert that the performance difference is based on the target module of the NN.Isn\u2019t an equally valid argument that MLPs tend to constitute a greater number of weights in transformer networks than attention heads, and the performance difference can be traced to a greater number of weights having freedom to change? I\u2019d be curious to know if randomly choosing a subset of matrices to train, regardless of where they are in the network, would provide analogous performance to LoRA on a specific module with comparable learnable weights.",
      "I think the QLoRA paper https://arxiv.org/pdf/2305.14314 paper also showed LoRA on all MLP + Attention layers > all MLP layers > just Attention layers.Other papers show finetuning a select few layers can also work well.",
      "Any real world performance comparison between QLoRa and LoRa?",
      "as a follow up curiosity, has anyone tried using LoRA on the entire model for pretraining to compare regular training model performance to LoRA?",
      "Yes, I\u2019ve tested this out. It does train, but the scaling doesn\u2019t seem to pan out. It\u2019ll perform slightly better than the number of trainable parameters, but never improves as you scale, so for now there\u2019s no benefit.",
      "This paper [1] does atempt that and reports similar performance compared to conventional pre-training. However, they do start off by doing a normal full-rank training and claim that it is needed to 'warm start' the training process.[1] https://arxiv.org/abs/2307.05695",
      "Oh yes this paper! The main issue is the scaling of the A and B LoRA matrices. Some papers show scaling the B matrix with larger learning rates (LoRA+) could be beneficial. DoRA for eg learns an auto scaling vector of numbers which tries to alleviate these issues.Galore might be more equivalent to full pretraining with the gradients being low rank.",
      "Do you mean leaving most of the model in its initial, randomised state and only training a LoRA?",
      "I\u2019ve tested specifically this (on my personal time) :) It will train but I found the loss is proportional to the number of trainable parameters. So roughly to hit the performance of a standard 70m param model, you need to train ~70m lora params anyway.",
      "It's worse than that, because lora requires two matrices per layer. At full rank, you have an additional NxN parameters to learn versus full finetuning, where N is min(input_features, output_features).For example, tuning a layer of 128 in x 256 out is 32k params. Learning a full-rank lora for that layer would be two matrices of 128x128 and 128x256 = 48k params."
    ],
    "link": "https://arxiv.org/abs/2405.09673",
    "first_paragraph": "Help | Advanced Search",
    "summary": "Today in utterly unsurprising news, nerds on the internet discover again that *more parameters might just mean better results*, as detailed in a deep dive into the shocking world of trained matrix subsets. \ud83d\ude44 The boffins over at arXiv, with their groundbreaking paper on LoRA's optimal training configurations, leave math-hungry commenters salivating over the tantalizing possibility that *maybe, just maybe*, fine-tuning everything isn\u2019t just a wild goose chase. Watch as comments scatter wildly between fanboying over MLPs, debating the ethical implications of attention head neglect, and fantasizing about a world where random matrix training might revolutionize their basement projects. Buckle up for another rollercoaster ride through the thrilling ups and profound downvotes of machine learning\u2019s finest echo chamber. \ud83c\udfa2\ud83d\udcbb"
  },
  {
    "title": "Expedia Group fired their CTO, Rathi Murthy (phocuswire.com)",
    "points": 33,
    "submitter": "s3r3nity",
    "submit_time": "2024-05-17T21:14:31",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=40394277",
    "comments": [],
    "link": "https://www.phocuswire.com/rathi-murthy-expedia-group-cto",
    "first_paragraph": "",
    "summary": "Expedia Group, in a display of corporate acumen as finely honed as a bendy straw, has bid farewell to their CTO, Rathi Murthy. Commenters, armed with the insight of seasoned LinkedIn influencers, are shedding their usual light on proceedings by stringing together business jargon in a devastating attempt to sound knowledgeable. One could hardly tell if they're discussing a CTO firing or providing deep critiques on a soggy sandwich. \"Disruptive innovation,\" cries one. \"Synergistic paradigms,\" wails another. Meanwhile, the travel booking experience continues to be as enjoyable as a root canal."
  },
  {
    "title": "Show HN: Drivr \u2013 VR with real vehicles [video] (youtube.com)",
    "points": 52,
    "submitter": "greghgradwell",
    "submit_time": "2024-05-16T19:19:16",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=40382056",
    "comments": [
      "That's badass!  I absolutely wanna ride in one!And also, being a motorcyclist has really raised my awareness about road awareness.  Even if the system works perfectly, making sure that the whole ridable surface is safe and free of hazards feels like a big lift in a real world setting.  If there was a nail or pothole or oil spill in a normal go kart, the rider has the potential to notice it and ride around.  With a headset on, they're really trusting the operator to do good maintenance on the playfield.A go kart has 4 points of contact, a low center of gravity, and a limited top speed.  Those are all good factors to limit catastrophic crashes.  But also, imagining a rink run by high school kids where nobody can actually see where they're going gives me some pause, even if this looks super cool and I want to do it.",
      "That's a great point. I'm starting out with experiences that are intended for low speeds. In the video, the vehicle is never going more than 5 mph. I think there's a lot of ways to make things interesting, e.g. adding additional tasks, without having to go much faster.In regards to multiple vehicles, you're absolutely right. At the current state, this is limited to one player per driving area. But the fact that the vehicle is software controlled, will allow multiple vehicles to eventually drive on the same track.",
      "144hz track/ground pass thru with an overlay if you need it purple or something",
      "I got to try this thing out a few weeks ago! I've spent a lot of time in VR, and I've driven karts before, so I thought I had an idea of what it would be like when you put the two together. I did not, it blew my mind. Having the correct physical forces coupled with VR was incredibly immersive. I chatted with Greg about future ideas as well, and a drive-by-wire kart with VR opens some really mind bending possibilities that I'm so stoked to get to try as this develops. MARIO KART DRIFTING IRL, HERE I COME.",
      "Nice work Greg! So this is why you can never make it to Pickleball/Padel? Cool excuse.Gran Turismo and Mario Kart were my favourite examples of fun and engaging virtual driving experiences. A long time ago, I had the wheel, pedals and vibrating seat for GT3 and even that created another level of immersion.Aside from an open place to drive (it's a drive but there is good vacant expanses close to res land), what other challenges are you facing? And, what's the vision?",
      "Ha! That, and you beat me every time we play.Finding an open place to drive could be less challenging if the go-kart had a better turning radius, so I could make the driving area a bit narrower. In that case, there would lots of parking lots where this would work, at least for the purpose of showing someone who wanted to try it.\nI've taken the current prototype as far as it should go. The architecture is really only suited for single player experiences. I wanted get to a point where I had convinced myself that the concept was feasible and fun, and I've done that. The ultimate goal of this project is to build a product that can function as an autonomous vehicle development platform. To get to there, I'll need to work with people who have built large multiplayer games and autonomous systems. So I'm done with the engineering for now until I've got a small team.",
      "Very cool! The graphics are underwhelming but i bet the immersion is sublime!Have you tried the analogue of \"redirected walking\"? I.e. the cart goes a partial circle but the user sees a full circle in VR?",
      "Haha, yes, the graphics are definitely not going to win any awards. This is a standalone app on the headset, and I wanted to ensure a smooth frate rate. Plus, I think it's easier for someone with very little game dev experience (me) to create a highly immersive environment using low-poly assets.I've been impressed with techniques like redirected walking. People are so clever! For this application, I think it would present some challenges when trying to add a second player, in terms of ensuring they don't collide in real life. However I can scale the players perceived speed with a simple multiplier, e.g., have them move 2 meters in the game for every 1 meter they move in real life.",
      "Not gonna lie, this is a nice idea. But I suspect past the wow factor I wouldn't want to drive like this too much. Probably the biggest advantage here is the lack of motion sickness for those who get it. The graphics would make me feel like I'm missing out wearing VR headset instead of seeing the actual \"outside\". Pretty sure I'd prefer Gran Turismo 7 on VR with a steering wheel. When I drive into a dark tunnel, it really gives me the \"entering smaller space\" feeling, and so on",
      "Very cool. Can this be calibrated to an existing track? I wonder in case of spin outs how would someone get back on track. \nEither way very cool demo"
    ],
    "link": "https://www.youtube.com/watch?v=Q76X0cnSGHk",
    "first_paragraph": "",
    "summary": "In a daring fusion of reality and pixelated daydreams, \"Drivr\" promises to reinvent the wheel by making sure it's virtually unrecognizable. Enthusiasts will no doubt flock to this technological marvel, possibly mistaking the seismic tremors of virtual collisions for the much-needed thrill missing from their sedentary digital lives. The aspirational commentariat, in bewitched rapture, eagerly volunteers their bodies as tribute to the noble cause of debugging vehicular code while blindfolded with VR headsets. Forward-thinking or forward-crashing\u2014only time will tell if \"Drivr\" is leading society to a dazzling virtual utopia or just another high-tech way to run into a very real ditch. \ud83d\udd79\ufe0f\ud83d\udca5\ud83d\ude97"
  },
  {
    "title": "Ask HN: What is the most productive stack or lang for single devs ?",
    "points": 25,
    "submitter": "arromatic",
    "submit_time": "2024-05-16T08:52:47",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=40376391",
    "comments": [
      "When I work on solo projects, my goto is what I've dubbed the HAG stack:  - HTMX: For client/server interactions. Returning HTML fragments is easy and lightweight.\n  - AlpineJs: For interactivity that doesn't require a http request, think toggling sidebars etc...\n  - Go: Primary development language, simplistic and easy to get started with. Fast compilation and with embedded files I can ship a single binary for deployment that contains all required assets.\n\nTertiary and other tools/services I use:  - Turso (Sqlite): Primary datastore, great to use for a \"db per user/tenant\" approach.\"\n  - Redis: Sometimes I use redis over turso, depending on need. Also used for caching. I've been moving much more into Turso though, especially with the embedded replica's.\n  - Docker: Everything is built into docker images. For my Go app I disable CGO and use Google's \"distroless\" container images as the base image.\n  - Fly.io: Hosting everything.",
      "I was checking out HTMX the other day but I am not really convinced. There's a lot I like about using HTML to define API calls, but I want to keep the backend free of unnecessary burden (and therefore free of frontend related rendering tasks).I'm looking for something like HTMX in its methodology, which uses HTML attributes for defining API calls and where the data comes from without having to write additional glue code in JS... but which uses OpenAPI as a schema for serialization/deserialization of data to/from the API endpoints.Maybe something like that exists which I couldn't find with my Google Fu?",
      "Too each their own, that's the great thing with programming, you can find what you like/want and use that. As you can probably tell I don't feel it is a burden on the backend. I subscribe to the thought that state is managed on the backend, and the browser is just the users client to view those hypermedia responses provided by the server. Template fragments in Go make it easy to only serve the necessary HTML from my templates, or if it's a full page request I can send the entire page.I'm not sure of anything like what you described, good luck on the search for it. If you find/develop anything ensure you post an obscene amount of memes on twitter for optimal discoverability by tech influencers.",
      "1. Web apps - Ruby on Rails hands down, every time. with SQL lite works pretty good on smaller projects. this is if you're working on a project yourself or have a very small team. If you're doing full stack and if you're doing turbo/stimulus it's a bit harder to hire people that have all of that. In my experience, easiest to hire full stack devs are with node/react stack. Coincidentally that's the group of people with largest knowledge gap in the either stack, people tend to specialize in oneNot sure about 2 and 3, not my cuppa tea",
      "I think it is very, very hard to beat Python+Django. As long as you're willing to conform to the \"Django mindset\" and the boilerplate it requires you can get simple websites up and running in no time. You also get so much \"for free\" that most other frameworks does not provide you with. The only major drawback is that Django is not great if you really want to do things your way.",
      "Flask + Svelte is very accessible. When my Middle School students wanted to \"build an app\" I would roll up a boilerplate with Flask, Svelte, and SQLite on Replit (would not recommend anymore - Replit has jumped the shark) and they were able to become very productive very quickly.EDIT: this was after 1-2 months of intro Python and JavaScript, so they weren't going in blind but also didn't have to learn, say, React. If you know some Python, you can use Flask. If you know some JS, you can use Svelte.",
      "I've pumped out many web apps using Svelte(Kit). I find it very good for rapid prototyping and exploratory programming. For example, I wrote a beat-aware video player in an afternoon or two (while I was learning Svelte).Even if you are a single dev, you will probably find yourself interacting with other members of the community. (Maybe more so for a single dev?) I find the Svelte community quite responsive and helpful.SvelteKit can handle both client and server parts. It streamlines a lot of the stuff most web apps need like routing. However, it doesn't include some other common stuff like auth and persistence to a database.https://kit.svelte.dev/",
      "+1 to Sveltekit.  It\u2019s a secret weapon for solo devs.  I like to pair it with Pocketbase, Supabase, or Cloudflare KV.",
      "Yes~ I've considered using https://pockethost.io/ (hosted Pocketbase) for the things that Kit doesn't provide (like DB and auth).",
      "LAMP (or LEMP) stack, hosted on a single VM (probably Digital Ocean).You probably want to use a framework of sorts. Laravel or Symfony are good. Not mandatory though.Server side rendering to start off with. Bulma for CSS. Alpine for JS.Throw in some cronjobs for scheduled stuff.Maybe a bit of Redis for sessions and caching."
    ],
    "link": "item?id=40376391",
    "first_paragraph": "",
    "summary": "**Ask HN: I Invented a New Stack, But Did I Really?**\n\nToday on Hacker News, a lone warrior ascends the technological Tower of Babel to proclaim the virtues of the \"HAG stack,\" a mystic acronym that combines obsolete menu selections from the software development buffet. Enthusiastic commenters chime in with their own tribal chants like \"Ruby on RoR forever\" and \"SvelteKit or bust,\" because why not treat programming languages like sports teams? Amidst the cacophony, someone mentions using Google's distroless images for extra hipster points, while another reminisces about teaching middle schoolers\u2014clearly the target audience for this discussion. No one knows what the \"most productive stack\" actually means, but everyone is too busy posturing to care. \ud83d\udc68\u200d\ud83d\udcbb\ud83d\udd2e"
  },
  {
    "title": "Scholars discover rare 16th-century tome with handwritten notes by John Milton (arstechnica.com)",
    "points": 39,
    "submitter": "nobody9999",
    "submit_time": "2024-05-16T03:03:41",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=40374815",
    "comments": [
      "The unusual \u2018r\u2019 glyphs in the text led me to reading about \u201cR rotunda\u201d.https://en.wikipedia.org/wiki/R_rotunda",
      "What in me is darkIllumine, what is low raise and support;That to the highth of this great ArgumentI may assert th\u2019 Eternal Providence,And justifie the wayes of God to men.",
      "...malt does more than Milton can / To justify God\u2019s ways to man. \u2014Housman"
    ],
    "link": "https://arstechnica.com/culture/2024/05/john-miltons-handwritten-notes-make-this-16th-century-history-book-a-rare-find/",
    "first_paragraph": "Front page layout",
    "summary": "**Scholars excavate John Milton's grocery list**\nIn a stunning display of academic fervor, archaeologists at ars technica unearth a dusty tome scribbled on by none other than John Milton, presumed to be his secret diary but turns out it's just his margin notes. Internet sleuths immediately elevate squiggly 'r's to the status of Da Vinci's code, while literary enthusiasts wedge Paradise Lost quotes wherever possible to justify their liberal arts degrees. Commenters, in a desperate bid to appear intellectual, battle over the interpretations of Milton's shopping habits while simultaneously Googling \"What is r rotunda?\" Let's all take a moment to ponder how \u2018malt does more than Milton can\u2019 to justify today\u2019s internet escapades."
  },
  {
    "title": "Ideas and Creativity (2019) (rieck.me)",
    "points": 85,
    "submitter": "Pseudomanifold",
    "submit_time": "2024-05-17T12:59:34",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=40389404",
    "comments": [
      "I would recommend that anyone who is interested in exploring these ideas read \"The Act of Creation\" by Arthur Koestler. He explores how things we think of as creativitity are fundamentally similar to how humour works in that they discover connections between things we previously thought of as being seperate.https://archive.org/details/actofcreation0000koes_k6v3",
      "He mentions the connection between creativity and 'play', which I think is spot on. We do this effortlessly as children and then it sort of gets 'bred out of us' as we get older and start developing more traditionally 'rational' skill sets and ways of thinking about the world.This sense of play hit home for me when I was a late teen and bought a 4-track multitrack recorder in the mid-80's. I had no preconceived notion of a song I wanted to write/record. I simply plugged in my guitar and hit 'record' and laid down an idea. I may have had a few false starts but didn't sweat it. By itself it wasn't very interesting. I added a second track with the only goal of \"it should work with the first track\" and was surprised at how easy it was to achieve that goal. Suddenly, with the two tracks an idea began to emerge that wasn't present in the first track by itself. Rinse and repeat with the remaining 2 tracks and I had a musical idea that I never could've imagined I would have created.I still use that same method to generate ideas today, and summon that same sense of 'play'. Of course the real work, much harder than creating, imo, is editing.",
      "I think you might enjoy reading Ralph Ammer's work:- https://ralphammer.com/how-to-get-started/- https://ralphammer.com/the-creative-switch/I wrote about a related subject here: https://sonnet.io/posts/hummingbirds/Also, the difference between children and adults when it comes to creativity is a bit deeper. I agree that it's bread out of us. Two semi-random examples:- shaming kids for making mistakes or just doing things differently, but also- just the mere fact that they're starting to learn how the world around them operates and responds to their actions,.At the same time it's likely that children achieve it through different internal processes, without a strict split between divergent and convergent thinking demonstrated by CT scans.https://www.hubermanlab.com/episode/the-science-of-creativit...(I can't find a better source atm, so posting YT video, sorry! also, check his sources)",
      "> watch toddlers playing with toys\u2014their imaginations are boundless and they are able to imbue even the most mundane objects with a sense of wonder and magic.This example just annoys me. I can still out-create a toddler, that isn't hard. The issue with creativity is that toddler-level creativity isn't useful. The important part of creativity is being able to apply it while achieving adult-level goals.The article doesn't ignore that as such, but this is like saying babies can handle the concept of abstract variables so we can all be programmers. True enough, but not at all a useful observation and it'll just depress the group of people who, for whatever reason, struggle hard and yet never become programmers. There are minimum standards that toddlers do not reach.",
      "> > watch toddlers playing with toys\u2014their imaginations are boundless and they are able to imbue even the most mundane objects with a sense of wonder and magic.Also a lot of that \"play\" is \"merely\" epistemic and phenomenological research, i.e. hard work.  There is a lot of creativity in designing and selecting experiments that work with what is at hand.  And of course discovery is fun -- that same \"wonder and magic\" is still experienced in adulthood when you validate something you've believed for a while or just realized.Piaget discusses this extensively, though not in the vocabulary I used.  And for the mandatory AI/CS linkage: Piaget was Papert's thesis advisor, so every RNN user or practitioner implicitly depends on Piaget's insight.",
      "> The important part of creativity is being able to apply it while achieving adult-level goals.That may be the important part for you, but for others, the important part is to not make that the important part.",
      "This is the distinction between working and hacking: working is what one does while achieving adult-level goals; hacking is what one does while either not goal-directed at all, or while pursuing anti-adult-level goals.> Your tiercel\u2019s too long at hack, Sir.\nHe\u2019s no eyass but a passage-hawk that footed ere we caught him,\nDangerously free o\u2019 the air. \u2014JRK",
      "Logical deduction is not at all creativity. Toddlers create interesting and unexpected things because they remove the rules-- in fact have no rules to begin with.Using a bunch of deductive logic to come up with a good solution is quite different, and don't worry a sign of good intelligence.",
      "It sounds like you take your assessment very seriously, but> There are minimum standards that toddlers do not reach.this is very funny taken out of context.Good points, though.",
      "I played with manual typewriters and mechanical calculators, back then electronic versions were virtually unheard of.But I was already intrigued by electronics and figured it would take over in the future.  Vacuum tubes were still the only option almost universally.  Didn't touch them as a preschooler, high voltage and all that.With the typewriter, the possibilities were endless, but for the calculator there was only so much you could do to make the right numbers show up in the little squares.Which led directly to number theory, something that can be learned without being taught.> There are minimum standards that toddlers do not reach.I guess there's a grain of truth there, never did get much further ;)"
    ],
    "link": "https://bastian.rieck.me/blog/2019/ideas/",
    "first_paragraph": "Developing ideas is the central aspect of many professions, including\u2014but\ncertainly not limited to\u2014academic research and software development.\nIt is my impression that we often consider ideas, or creativity in\ngeneral, to be some magical binary property: you either have ideas\nand are a creative mastermind, or not. The purpose of this article\nis to challenge this assumption and discuss aspects of ideation,\ni.e.\u2009the process of coming up with ideas. We will look at some\nall-too-common fallacies before taking a quick dive into time-tested\ncreativity techniques.",
    "summary": "**Hackernews Digest: Toddler Wisdom and Magical Creativity Machines**\n\nIn a daring escape from reality, the latest blog post on \"Ideas and Creativity\" treats creativity like an enigmatic potion in a high-fantasy novel - either you're born with it, or you're a muggle. The author, heavily armed with buzzwords and vague notions, endeavors to demystify this magical ability, encouraging us mere mortals to partake in \"proven\" techniques like summoning the ancient spirits of brainstorming and mind maps. Commenters, in a delightful display of pretentious one-upmanship, recount tales from their own creative quests, comparing epiphanies to mastering the arcane arts. Each response unintentionally competing for the crown of 'Most Likely to Be Quoted at a TEDx Near You', they all seem to agree: true creativity died around the time we stopped eating glue in kindergarten. \ud83c\udfa8\ud83d\udca1\ud83d\udcda"
  },
  {
    "title": "The Beauty of Concrete (worksinprogress.co)",
    "points": 50,
    "submitter": "jger15",
    "submit_time": "2024-05-17T15:09:15",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=40390751",
    "comments": [
      "I've been randomly thinking about this a lot!One hypothesis I've been kicking around: human brains like detail.I thought of this on a walk down a (sub)urban city street.- High detail: I first noticed the variety of plants in just the garden strips between the sidewalk and the street. I was trying to count how many there were, and I quickly lost track. Then I started looking at each individual plant, and the amount of detail is wild---the sheer intricacy and variation in all the parts and stages of growth. Not to mention the colors (OK, and smell and movement).Then, I looked at the human made objects around me:- Low detail: Flat concrete road. Flat concrete sidewalk. Flat stairs. All from rectangular tiles. Metal pole handrail.The houses around weren't much better---boxy shapes, low ornamentation.While I think it's generally accepted that nature is more pleasing to the senses to be around human-created objects, it made me wonder whether amount of detail is a fundamental aspect of what our brains enjoy.This rumination gets activated whenever I walk by old ornate buildings or read an article like this.Relatedly, even low-poly games people find beautiful (Tunic comes to mind) have an extraordinary amount of detail when you dissect the textures and postprocessing effects. I'd share a video but I'm way off track now.",
      "My theory is population growth. When population doesn't grow more older buildings get reused and fewer ones are built, so society can afford to ornament new constructions. When the babies boomed, you got Sears catalog houses.",
      "I have a budding rose garden that I would like to adorn with statuary. One problem is that I have a tight budget. A second problem is that if you look at garden centers you will see its easy to find 9000 different cast stone frogs: frogs meditating, frogs reading books, frogs thinking, frogs with a purse and shopping bags, frogs in an Adirondack chair, frogs hugging, reclining frog, etc. It is surprisingly difficult, however, to find cast stone classical or ancient sculptures outside of a few pastiche renditions.I find this extremely odd! I would think there would be a large market for beautiful cast stone things. Instead, there is (apparently) an extraordinary market for concrete frogs.I figured that in the era of 3D printing and widespread 3D models[1], it might be fairly inexpensive to make my own mold and pour my own casts, even if I do destructive casting techniques. Here again I was disappointed: To order a 3D plastic print from a site like ShapeWays came out to over $1300 for something fairly small. So that's off the table, too.I expected more democratization of ornament than there really has been, given the tech today. It's surprising to me that no one is trying to make silicone molds available of famous statues, generally, but I guess there's just no interest or no perceived demand. Or maybe there is a big market, and I've missed it, because I was not searching for silicone molds of frogs.[1] For instance, The British Museum has a sketchfab with free models: https://sketchfab.com/britishmuseum",
      "I think the reason that large (cast) stone is very expensive is not the creative part or the molds. It is mostly the storing and transportation.Storing is hard because of the space it takes and manual labour to move the heavy item when reorganizing.Transportation is costly for the same reasons and additionally it can easily damage and any damage causes it to suddenly have virtually zero value.",
      "There are several sites with instant quotes that are cheaper than Shapeways.PCBWay and JLCPCB both offer similarly-priced very cheap 3d printing and CNC services out of China. Weerg in Italy also offers 3d printing and CNC services and I'm probably going to try them out for the next thing I need printed. The only non-marketplace service I've seen in the US that offers instant quotes is i-solids in Texas, but they have quite high startup costs and seem to be more geared towards small-medium production runs.",
      "I think it's about whether you see the work directly, or through a lens of status consciousness.You are saying:- classical statues are beautiful, I like beautiful thingsAnd they are saying:- classical statues belong in palaces, and I don't own a palace, or want people to think that I'm reaching above my status",
      "Silicone is actually surprisingly expensive.I\u2019ve done cast stone\u2026 poured into cast silicone\u2026 which was cast from 3D printer molds\u2026 which was printed from my own 3D models\u2026 and silicone was by far the most expensive part.It only made sense because I was casting a lot of stone molds.",
      "use latex, and if it's big enough, back it with fiberglass. that seems to be the common way to make molds on youtube",
      "In somerville MA about 10 years ago someone was selling mini easter-island heads as lawn statues, which I though was a great idea.",
      "I like the idea that technology might eventually change or increase the variance of McMansion outdoor decor tastes.It seems reasonably within expectations that ornamental concrete frogs are a bigger market than ornamental naked dudes holding up a severed head, tough, no?"
    ],
    "link": "https://worksinprogress.co/issue/the-beauty-of-concrete/",
    "first_paragraph": "Why are buildings today drab and simple, while buildings of the past were ornate and elaborately ornamented? The answer is not the cost of labor.",
    "summary": "Welcome to *Worksinprogressdotconcrete*, where human architectural ambition is laid bare in the thrilling contemplation of... concrete. In an article daringly titled 'The Beauty of Concrete,' the author laments the reduction of our skyline to squares over swirls, attributing this decline not to costs, but to a collective architectural yawn. Comment sections flare with enthusiasts confusing their backyard botanical escapism for profound urban planning insights, arguing that our brains\u2014which were apparently delighting in garden variety during city walks\u2014are starved for the complexities of yore. Meanwhile, a rebel without a clue suggests bypassing pricey 3D printing for DIY statuary, missing the memo that nobody's lawn has yearned for cheap knockoffs of the Venus de Milo. \ud83e\udd37\u200d\u2642\ufe0f\ud83d\udc94\ud83c\udfdb\ufe0f"
  }
]