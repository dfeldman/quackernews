[
  {
    "title": "13ft \u2013 A site similar to 12ft.io but self-hosted (github.com/wasi-master)",
    "points": 249,
    "submitter": "darknavi",
    "submit_time": "2024-08-19T19:49:22",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=41294067",
    "comments": [
      "Nice effort, but after one successful NYT session, it fails and treats the access as though it were an end user. But don't take my word for it : try it. One access, succeeds. Two or more ... fails.The reason is the staff at the NYT appear to be very well versed in the technical tricks people use to gain access.\n \nreply",
      "They probably asynchronously verify that the IP address actually belongs to googlebot, then ban the IP when it fails.Synchronously verifying it, would probably be too slow.You can verify googlebot authenticity by doing a reverse dns lookup, then checking that reverse dns name resolves correctly to the expected IP address[0].[0]: https://developers.google.com/search/docs/crawling-indexing/...\n \nreply",
      "There are easily installable databases of IP block info, super easy to do it synchronously, especially if it\u2019s stored in memory. I run a small group of servers that each have to do it thousands of times per second.\n \nreply",
      "We need a P2P swarm for content. Just like Bittorrent back in the day. Pop in your favorite news article (or paraphrase it yourself), and everyone gets it.With recommender systems, attention graph modeling, etc. it'd probably be a perfect information ingestion and curation engine. And nobody else could modify the algorithm on my behalf.\n \nreply",
      "Running a server just to set the user agent header to the googlebot one for some requests feels a bit heavyweight.But perhaps it\u2019s necessary, as it seems Firefox no longer has an about:config option to override the user agent\u2026am I missing it somewhere?Edit: The about:config option general.useragent.override can be created and will be used for all requests (I just tested). I was confused because that config key doesn\u2019t exist in a fresh install of Firefox. The user agent header string from this repo is: \"Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/W.X.Y.Z Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\"\n \nreply",
      "> set the user agent header to the googlebot oneAlso, how effective is this really? Don\u2019t the big news sites check the IP address of the user agents that claim to be GoogleBot?\n \nreply",
      "This. 12ft has never ever worked for me.\n \nreply",
      "If you would host that server on Google cloud, you would make it a lot harder already.\n \nreply",
      "https://developers.google.com/search/docs/crawling-indexing/...They provide ways to verify Googlebot IPs specifically, anyone who cares to check wouldn't be fooled by running a fake Googlebot on Googles cloud.Likewise with Bingbot: https://www.bing.com/webmasters/help/how-to-verify-bingbot-3...\n \nreply",
      "I sincerely hope the antitrust suit ends this practice soon. This is so obviously anticompetitive.\n \nreply"
    ],
    "link": "https://github.com/wasi-master/13ft",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        My own custom 12ft.io replacement\n      A site similar to 12ft.io but is self hosted and works with websites that 12ft.io doesn't work with.This is a simple self hosted server that has a simple but powerful interface to block ads, paywalls, and other nonsense. Specially for sites like medium, new york times which have paid articles that you normally cannot read. Now I do want you to support the creators you benefit from but if you just wanna see one single article and move on with your day then this might be helpfulIt pretends to be GoogleBot (Google's web crawler) and gets the same content that google will get. Google gets the whole page so that the content of the article can be indexed properly and this takes advantage of that.Requirements:The image is also available from DockerHub or ghcr.io so the command docker pull wasimaster/",
    "summary": "**13ft \u2013 The Needless Increment**\n\nIn a misguided attempt to reinvent the wheel, an intrepid developer unveils 13ft.io, a self-hosted ad-blocker that masquerades as GoogleBot to scoff at paywalls with mixed success. Users flock to the comments to either praise this one-man rebellion against digital capitalism or to share their utterly predictable failure stories because, surprise, the New York Times doesn't hire muppets for their IT team. Meanwhile, a visionary suggests a peer-to-peer article sharing network, blissfully reinventing <em>Bittorrent</em> because who needs legal articles when you can get possibly paraphrased versions? Welcome to the rebel base, where tech tricks die hard and everyone's a closet lawyer waiting for an antitrust superhero to save the day."
  },
  {
    "title": "What I Learned Working for Mark Zuckerberg (noahkagan.com)",
    "points": 23,
    "submitter": "duck",
    "submit_time": "2024-08-19T23:53:21",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=41295519",
    "comments": [
      ">At AppSumo, we run paid trials with potential teammates before bringing them on full-time to ensure they\u2019re the right fit.Not sure that is something I would personally enjoy. While I understand you must fit in, having this process highlights that leaving your current company is even riskier as you might not make the cut and end up with nothing. The trial is one-sided, with all the risks for the new employee, not AppSumo. I understand that any change of job is similar where you may stay forever, however, saying that way make it worse somehow.\n \nreply",
      "I wouldn\u2019t never work for a company that does this.\n \nreply",
      "I don't see how it's much different from working at a company for any period of time even as a fully onboarded employee, aside from specific legal obligations that possibly protect your employment. In any place where firing at will is legal, they can toss you at any time for almost any pretext and claim you weren't a correct fit. It applies in general even if you're fully hired, barring some specific contract (that they might anyhow wiggle their way out of).\n \nreply",
      "Note the phrasing is \"we run paid trials with potential teammates before bringing them on\".While at-will employment does mean you can be fired at any time, the default assumption is that your job will continue, barring something happening (like poor performance, or the company being unprofitable, or your boss being in a bad mood that day).The phrasing here makes it sound like the default is that it's time-limited and an extended interview. Sure, technically at-will and \"a tech interview\" both have the same amount of job-security (exactly zero), but there's social expectations around employing and firing people, and overhead for the company, which lead to full-time employment having more security in practice.\n \nreply",
      "At least they're transparent about it. Plenty of people end up working at companies with this attitude without ever knowing it. Especially in sales orgs.\n \nreply",
      ">I wouldn\u2019t never work for a company that does this.Your double negative is genuinely confusing me. Is this intentional, or is it an error?\n \nreply",
      "Yikes definitely an error, I\u2019m on mobile.\n \nreply",
      "Not no how, not no way!\n \nreply",
      "There's no way to make a hiring process that makes everyone happy.Though the length here was not specified, it could be e.g. 3 days that you can do while still employed.\n \nreply",
      "Sure, but do those 3 days tell you so much more than a 30m interview?\n \nreply"
    ],
    "link": "https://noahkagan.com/what-i-learned-working-for-mark-zuckerberg/",
    "first_paragraph": "",
    "summary": "Noah Kagan, ex-Facebook sage, unveils the arcane secrets of hiring at AppSumo, a revelation so groundbreaking it involves... *wait for it*... paid trials. Commenters, in a glorious display of Internet expertise, argue whether this is modern-day serfdom or just mild corporate exploitation. One genius struggles with the English language, heroically battling autocorrect on the front lines of mobile commenting. Meanwhile, others philosophize about job security in an era where your career stability is as robust as a house of cards in a hurricane. Welcome to the future of work, it\u2019s just like the old one but with more steps! \ud83c\udfad\ud83e\udd39\u200d\u2642\ufe0f"
  },
  {
    "title": "On the cruelty of really teaching computing science (1988) (utexas.edu)",
    "points": 28,
    "submitter": "torstenvl",
    "submit_time": "2024-08-19T23:35:01",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41295433",
    "comments": [
      "> The programmer is in the unique position that his is the only discipline and profession in which such a gigantic ratio, which totally baffles our imagination, has to be bridged by a single technology. He has to be able to think in terms of conceptual hierarchies that are much deeper than a single mind ever needed to face before. Compared to that number of semantic levels, the average mathematical theory is almost flat. By evoking the need for deep conceptual hierarchies, the automatic computer confronts us with a radically new intellectual challenge that has no precedent in our history.I am no biographer of Djisktra\u2019s, so is he being unrealistic about programmers here, or does he not have exposure to what a mathematician would consider Mathematics (Wikipedia entry claiming him a mathematician or no)?\n \nreply",
      "This is obviously a snapshot in time (title includes 1988). I can\u2019t attest to the State of Computer Science Education in the late 1980s. He laments the term software engineering because software engineering does not fit the traditional, more mechanical engineering terms.The more mathematical proof style that he is advocating for is used sometimes in aerospace (in particular Airworthiness) and medical.Some might say that his proposed methods only apply to software requiring that level of rigor. It is also really expensive.\n \nreply",
      "We are slowly getting there, SE is just a bit over 50 years old. For example, Dafny (by MSR) is relatively easy to use and scales nicely to build systems of 20-30 KLOC with some formal guarantees. It's a nice imperative language where specifications are encoded as contracts, so quite familiar to developers.I think LLMs could help a lot to lower cost by providing some automation to turn specifications into code. DeepMind has already shown a proof of concept for mathematical theorems using Lean. I have a toy implementation for Isabelle oriented towards SE that works quite well.\n \nreply",
      "Not sure if you are familiar with Ada 2012 and SPARK. We looked into it a long time ago. We were not able to justify the cost and ROI\n \nreply",
      "Thats what the ai would say\n \nreply",
      "I have met some developers in my career that can communicate as effectively as this with equally brutal criticality, but those people are astonishingly rare. Maybe 2% of the developer population, if I am being gracious, can be described this way.Most developers I have worked with are cowards exactly as he used that word. Now in all fairness my career is largely limited to large corporate employers that only hire Java developers and, god forbid, JavaScript developers. It\u2019s frameworks, Maven, and NPM for absolutely everything.The hiring managers always claim to look for innovators, but then you get in and everyone is just the same. Thousands of developers just retaining their employment doing the same shit day after day, fearing any changes coming down the pike.\n \nreply",
      "Frameworks aren't necessarily a bad thing if you can critical think - why reinvent the wheel from scratch everytime when you're trying to make a newer version of a car? But if you're only a framework monkey who cannot communicate design decisions, architecture, and/or design you're definetly screwed in the job market.A lot of people (especially newer profiles I've seen on HN) think just being able to glue libraries together is enough to justify being a developer with a 6 fig salary, when in reality the actual value add is the architecture, design, and other critical thinking actions.Hiring managers do try to hire the archetype developer who is both eloquent and a critical thinker, but it's hard and those who can do both know their value.\n \nreply",
      "I've always heard that tech employers value all the things you'd expect them to value, but I've only ever seen them value LeetCode.\n \nreply",
      "Then again, just being able to glue libraries together ought to be enough to justify a 6 fig salary, because inflation adjusted that's potentially less than the 5 fig salaries I was offered last century, fresh out of school and still wet behind the ears.\n \nreply",
      "And the only reason (I assume) you're still in the tech industry despite the dot com bust and the Great Recession is because you can at least show value to employers, and you most likely have some communication and critical thinking skills, not just gluing stuff together.Plenty of code monkey types flamed out or remained underemployed.> the 5 fig salaries I was offered last century, fresh out of school and still wet behind the earsAnd there were also fewer developers in the 1990s/2000s than in the 2020s, and the hiring market was not yet fully globalized and async compared to the post-COVID WFH/Remote market.\n \nreply"
    ],
    "link": "https://www.cs.utexas.edu/~EWD/transcriptions/EWD10xx/EWD1036.html",
    "first_paragraph": "\nOn the cruelty of really teaching computing science\nThe second part of this talk pursues some of the scientific and educational consequences of the assumption that computers represent a radical novelty. In order to give this assumption clear contents, we have to be much more precise as to what we mean in this context by the adjective \"radical\". We shall do so in the first part of this talk, in which we shall furthermore supply evidence in support of our assumption.The usual way in which we plan today for tomorrow is in yesterday's vocabulary. We do so, because we try to get away with the concepts we are familiar with and that have acquired their meanings in our past experience. Of course, the words and the concepts don't quite fit because our future differs from our past, but then we stretch them a little bit. Linguists are quite familiar with the phenomenon that the meanings of words evolve over time, but also know that this is a slow and gradual process.It is the most common way of ",
    "summary": "In a brilliant exercise of nostalgia-wrapped confusion, some academics propose programming ought to be akin to high art, grappling with deep conceptual hierarchies unlike anything ever faced by mere mortals\u2014even mathematicians contend with toddlers' toy problems by comparison. Commenters, stroking their egos with tales of expensive and hastily-abandoned ventures into the realm of formal methods, engage in a heroic myth-making competition. Each vies to prove they've touched the hem of Dijkstra's robe, achieving computational enlightenment\u2014or at least managed to configure their IDE correctly. Meanwhile, the software industry soldiers on, valiantly ignoring both Dijkstra and the commenters' pontifications, as the ghosts of Ada and SPARK mourn quietly from the sidelines."
  },
  {
    "title": "Launch HN: Sorcerer (YC S24) \u2013 Weather balloons that collect more data",
    "points": 237,
    "submitter": "tndl",
    "submit_time": "2024-08-19T14:13:36",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=41291219",
    "comments": [
      "Very cool! How are the balloons transferring telemetry back to earth for analysis, etc?Asking because my research at the University of Oxford was around hyper space-efficient data transfer from remote locations for a fraction of the price.The result was an award-winning technology (https://jsonbinpack.sourcemeta.com) to serialise plain JSON that was proven to be more space-efficient than every tested alternative (including Protocol Buffers, Apache Avro, ASN.1, etc) in every tested case (https://arxiv.org/abs/2211.12799).If it's interesting, I'd love to connect and discuss (jv@jviotti.com) how at least the open-source offering could help.\n \nreply",
      "> JSON BinPack is space-efficient, but what about runtime-efficiency?> When transmitting data over the Internet, time is the bottleneck, making computation essentially free in comparison.i thought this was an odd sales pitch from the jsonbinpack site, given that a central use-case is IoT, which frequently runs on batteries or power-constrained environments where there's no such thing as \"essentially free\"\n \nreply",
      "Fair point! \"Embedded\" and \"IoT\" are overloaded terms. For example, you find \"IoT\" devices all the way from extremely low powered micro-controllers to Linux-based ones with plenty of power and they are all considered \"embedded\". I'll take notes to improve the wording.That said, the production-ready implementation of JSON BinPack is designed to run on low powered devices and still provide those same benefits.A lot of the current work is happening at https://github.com/sourcemeta/jsontoolkit, a dependency of JSON BinPack that implements a state-of-the-art JSON Schema compiler (I'm a TSC member of JSON Schema btw) to do fast and efficient schema evaluation within JSON BinPack on low powered devices compared to the current prototype (which requires schema evaluation for resolving logical schema operators). Just an example of the complex runtime-efficiency tracks we are pursuing.\n \nreply",
      "> batteries or power-constrained environmentsI would imagine that CPUs are much more efficient than a satellite transmitter, probably? I guess you'd have to balance the additional computational energy required vs. the savings in energy from less transmitting.\n \nreply",
      "Let's definitely talk, we're using protobufs right now. I'll send an email\n \nreply",
      "This looks promising! One of the important aspects of protocol buffers, avro etc is how they deal with evolving schemas and backwards/forward compatibility. I don't see anything in the docs addressing that. Is it possible for old services to handle new payloads / new services to handle old payloads or do senders and receivers need to be rewritten each time the schema changes?\n \nreply",
      "A lot of people already think about this problem with respect to API compatibility for REST services using the OpenAPI spec for example. It's possible to have a JSON Schema which is backwards compatible with previous versions. I'm not sure how backwards-compatible the resulting JSON BinPack schemas are however.\n \nreply",
      "Good question! Compared to Protocol Buffers and Apache Avro, that each have their own specialised schema languages created by them, for them, JSON BinPack taps into the popular and industry-standard JSON Schema language.That means that you can use any tooling/approach from the wide JSON Schema ecosystem to manage schema evolution. A popular one from the decentralised systems world is Cambria (https://www.inkandswitch.com/cambria/).That said, I do recognise that schema evolution tech in the JSON Schema world is not as great as it should be. I'm a TSC member of JSON Schema and a few of us are definitely thinking hard on this problem too and trying to make it even better that the competition.\n \nreply",
      "Sounds cool. How does it differ from CBOR?\n \nreply",
      "CBOR is a schema-less binary format. JSON BinPack supports both schema-less (like CBOR) and schema-driven (with JSON Schema) modes. Even on the schema-less mode, JSON BinPack is more space-efficient than CBOR. See https://benchmark.sourcemeta.com for a live benchmark and https://arxiv.org/abs/2211.12799 for a more detailed academic benchmark\n \nreply"
    ],
    "link": "item?id=41291219",
    "first_paragraph": "",
    "summary": "Title: **Launch HN: Sorcerer (YC S24) \u2013 Weather balloons that actually do something**\n\nThis week in Hacker News, the tinkerers unveil their latest distraction: weather balloons by Sorcerer, because climate science evidently needed more balloons. Commence the traditional circus of commenters weaving their own semi-related tech accolades into the discussion, like that guy from Oxford (yes, he really said Oxford) who's hawking his \"hyper space-efficient\" JSON magic beans. A vigorous debate unfolds about IoT device power usage, overshadowing the original topic, because why talk about the weather when you can flex your coding chops? At least everyone's data will be compressed efficiently while they miss the point. \ud83c\udf88\ud83c\udf0d\ud83d\udcbe"
  },
  {
    "title": "Lenticular Clock (instructables.com)",
    "points": 66,
    "submitter": "animal_spirits",
    "submit_time": "2024-08-19T19:32:02",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41293929",
    "comments": [
      "Utterly impractical as a clock. Brilliant hack.I guess version two will add a camera, an eye detector and two servos to orient the clock to create a real-live hybrid of xclock and xeyes.\n \nreply",
      "I love lenticulars. I'm working on writing my own lenticular software right now. You can see some of my lenticular math art here: https://gods.art/\n \nreply",
      "Those are amazing! Are you hand aligning those lenses on the print or is there some sort of tooling/hardware/service that is capable of it?\n \nreply",
      "I did some experiments creating lenticular 3D and failed miserably. I'll look at what you got.I would love to see the software, BTW.\n \nreply",
      "Amazing work!\n \nreply",
      "I'm most blown away just by the very existence of lenticular sheets -- I didn't know that this was a general-purpose thing that you could do at home  Years ago I paid for a 3d lenticular photo print but I always assumed the technology to do so was out of my reach.\n \nreply",
      "This is really cool! I had no idea you could just buy these sheets, I always thought you have to make them specially. The fact that you can buy them and then print a pattern is amazing.\n \nreply",
      "Won't this show the wrong glyph if you're looking at it from the wrong angle?\n \nreply",
      "Hm, could that be fixed by covering it with a \"privacy screen\" (used to cover computer screens, basically a bunch of tiny parallel tubes (all-angle) or grooves (one-axis, probably best for this))? Then maybe a blur on top of that to increase the viewing angle again (though that might cut the light too much since it's not an active emitter)?\n \nreply",
      "Maybe a pinhole and lens? Like a camera but having only the clock inside a chamber\n \nreply"
    ],
    "link": "https://www.instructables.com/Lenticular-Clock/",
    "first_paragraph": "16,80582FeaturedAfter making my Moire Clock a got interested in a very similar effect: lenticular animations. You probably have seen this effect before, e.g. on post cards. I remember having a ruler in primary school with a picture of dinosaurs on it that changed depending on the viewing angle.Lenticular animations are based on several interlaced pictures viewed through an array of cylindrical lenses. The individual pictures can then be distinguished by changing the viewing angle. My idea was to create a clock that uses lenticular animations to display the time.The lenticular sheet is characterized by its number of lenses per inch (LPI). I ordered sheets with 60, 40 and 20 LPI. Higher LPI gives you a better resolution but you need to print thinner lines and its more difficult to align the sheet correctly on top of the print. Since the clock animations will contain up to 6 frames I found that they are only clearly separated with 20 LPI.I used a 20 LPI sheet with a large viewing angle of",
    "summary": "Instructables users, in their infinite bid to make everything in their home mildly inconvenient and visually perplexing, have birthed the \"Lenticular Clock.\" This gem involves a user staring at a device from just the *right* angle to tell time, because glancing at a standard clock was just too straightforward. Comments range from desperate hacks trying to salvage practicality, to awestruck discoveries that you, yes you, can buy lenticular sheets without signing over your firstborn. Everyone is seemingly unaware that easier methods to tell time have existed since, well, pretty much the dawn of civilization. JSName a 'clock' that turns time-telling into a neck-craning quest? Sign the hobbyists up! \ud83d\udd70\ufe0f"
  },
  {
    "title": "Infisical (YC W23) Is Hiring Full Stack Engineer (Remote) (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-08-20T01:00:51",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/infisical/jobs/HD8NQOP-full-stack-engineer",
    "first_paragraph": "Open-source secrets manager for developersInfisical is the #1 open source secret management platform for developers. In other words, we help organizations manage API-keys, DB access tokens, certificates, and other credentials across all parts of their infra! In fact, we\u00a0process over 2B of such secrets per month.Our customers already include some of the largest public enterprises and some of the fastest-growing startups. Developers love us and every day our community is growing stronger! Join us on a mission to make security easier for all developers \u2013\u00a0starting from secret management.Infisical is looking for a full stack engineer to help us build, optimize, and create the foundations of the product. You will be working closely with our CTO and the rest of the engineering team on:Overall, you\u2019re going to be one of the defining pieces of our team as we scale to thousands of customers over the next 18 months.This job will require you to be a Swiss army knife of an engineer. Overall, this r",
    "summary": "\ud83d\ude80 **Infisical Saves the World!** \ud83c\udf0e Infisical, the miraculous startup and self-proclaimed savior of developers everywhere, is on a holy crusade to manage your API-keys, DB tokens, and those oh-so-secret secrets that apparently billions depend on monthly. Because in the high-stakes world of newsletter sign-ups and spam filters, no job is more vital than being the \"Swiss army knife\" of engineers (a role definitely as glamorous as it sounds). Join them to not only optimize code, but also bask in the ongoing existential thrill of deciding if a startup\u2019s 'fast-growing' status is just about its customer base or its alarming burn rate. Meanwhile, commenters compete in the digital Coliseum to prove who can be the loudest advocate for something they barely understand. \ud83c\udf89"
  },
  {
    "title": "Let's Write a Reverb (signalsmith-audio.co.uk)",
    "points": 25,
    "submitter": "notagoodidea",
    "submit_time": "2024-08-15T07:37:54",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41253850",
    "comments": [
      "Easily the most approachable yet complete writeup I've seen on the topic. I've always noticed an aura of esoteric dark magic around writing good algorithmic reverbs, this makes it seems less daunting.Since the author does a quick comparison between convolution and algorithmic reverbs, I'll mention how I often combine them: a small/medium convolution reverb, plus a long algorithmic reverb. The convolution can perfectly diffuse the signal and it can also give a precise character to the sound, depending on the impulse response. It's great for adding a \"body\" to a raw sound generator. The algorithmic layer then adds a subtle ambience that can be extra long if desired.\n \nreply",
      "Is it possible to model reverb using a neural network (e.g. wavenet or LSTMs) for real-time use? Is this what something like Neural DSP is doing under the hood?\n \nreply"
    ],
    "link": "https://signalsmith-audio.co.uk/writing/2021/lets-write-a-reverb/",
    "first_paragraph": "No magic numbers, no tricky tuning: a clean and flexible approach to designing a smooth high-quality reverb, using a variation on the classic feedback-delay network (FDN) structure.Reverbs are one of my favourite effects, both to use and to write, and feedback-delay networks are a great way to play around and try things.Reverbs sometimes have a bad reputation for being tricky to tune, so this article goes through one possible reverb design which I hope is simple and intuitive to understand, and I also think is friendly and robust (as in, easy to configure correctly and get a good sound).I've presented this a couple of times, most recently at ADC 21, and before that at TAP's meetup.  There are some slight differences between the versions, but they mostly follow the same structure.The ADC version comes with some example code.So let's get to it!We'll start by laying out what we're looking for.  Artificial reverberation is quite a wide field, covering a few different use-cases, but let's t",
    "summary": "Today in <em>\"I Suddenly Understand Sound\"</em>, a blogger reinvents the wheel with his breakthrough article on creating reverbs without \"magic numbers\" or \"tricky tuning.\" Throngs of bedroom producers, who until now believed reverb creation invoked ancient alchemy, hail the post as revelatory. One enlightened commenter marries convolution and algorithmic reverbs, inadvertently crafting the Frankenstein's monster of echo effects. Meanwhile, another eager soul wonders if neural networks could be the secret sauce behind real-time reverb, clearly mistaking basic audio processing for launching rockets into space. \ud83c\udf9b\ufe0f\ud83d\ude80\ud83d\udcab"
  },
  {
    "title": "'Rare species' not seen in the area for 50 years spotted on Arizona trail camera (phys.org)",
    "points": 41,
    "submitter": "wglb",
    "submit_time": "2024-08-19T20:10:48",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41294202",
    "comments": [
      "Wild animals are so amazing, and this is a wild animal that seems to me to be extra-amazing. Think about the skills required to survive in this environment. No tools! No GPS coordinates for the nearest water source. No grocery store: anything it wants to eat is as wily and tough as it is. And it\u2019s so stealthy and elusive that we\u2019d never see it without the use of high-tech infrared cameras. This creature is a real world superhero character.\n \nreply",
      "No video of the trail cam in the article?Edit: Found it here https://youtu.be/ZkkMhLq0cm0?t=18\n \nreply",
      "The rare species is an ocelot.\n \nreply"
    ],
    "link": "https://phys.org/news/2024-08-rare-species-area-years-arizona.html",
    "first_paragraph": "\n\n                  Click here to sign in with\n                  \n\n\n                  or\n                  \n\n\n\n\nForget Password?\n\nLearn more\nshare this!497TwitShareEmail\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tAugust 13, 2024\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\tThis article has been reviewed according to Science\u00a0X's \n\t\t\t\t\t\t\t\t\t\t\t\t\teditorial process\n\t\t\t\t\t\t\t\t\t\t\t\t\tand policies.\n\t\t\t\t\t\t\t\t\t\t\t\t\tEditors have highlighted\n\t\t\t\t\t\t\t\t\t\t\t\t\tthe following attributes while ensuring the content's credibility:\n\t\t\t\t\t\t\t\t\t\t\t\t\n fact-checked\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n reputable news agency\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n proofread\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t by Daniella Segura, The Charlotte Observer\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\tTo ensure her trail cameras would stay operational during the hot Arizona summer, researcher Kinley Ragan trekked to 23 of them.At each, Ragan, a field research project manager with the Phoenix Zoo, checked the camera's batteries and SD card, as well as ensured the camera was angled at an optimal position, Ragan told McClatchy News i",
    "summary": "In the latest clickbait miracle from phys.org, a \"rare species\" tantalizes bored internet users by showing up on grainy trail cam footage for the first time since anybody cared. Intrepid \"field research project manager\" Kinley Ragan risks the scorching Arizona sun to confirm: yes, the cameras still work and yes, we can still see animals without actually going outside. Comment sections explode with armchair biologists marveling at how a wild animal can survive in the wild without the benefits of UberEats and Google Maps. No actual video in the article, but why let visuals interrupt a good blind faith in wildlife storytelling? \ud83d\udcf7\ud83c\udfdc\ufe0f\ud83d\ude31"
  },
  {
    "title": "Music recommendation system using transformer models (research.google)",
    "points": 55,
    "submitter": "panarky",
    "submit_time": "2024-08-19T19:28:22",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41293901",
    "comments": [
      "It doesn't seem that this approach \"knows\" the actual music. The article doesn't seem to explain how track embedding vectors are produced, but it mentions that user-action signals are of the same length, which makes me doubt track embeddings have any content-derived (rather than metadata-derived) information. Maybe I'm wrong, of course.I doubt that any recommendation system is capable of providing meaningful results in absence of the \"awareness\" about the actual content (be it music, books, movies or anything else) of what it's meant to recommend.It's like a deaf DJ that uses the charts data to decide what to play, guessing and incorporating listeners' profiles/wishes. It's better than a deaf DJ who just picks whatever's popular without any context (or going by genre only), but it's not exactly what one looks forward to when looking for a recommendation.\n \nreply",
      "This is a shortcoming of every music recommendation algorithm except Spotify and Pandora's. Spotify holds holds a pretty hefty patent portfolio of music classification algorithms and Pandora employs hundreds of music experts that spend an hour tagging each song.\n \nreply",
      ">  It doesn't seem that this approach \"knows\" the actual music. The article doesn't seem to explain how track embedding vectors are producedThat's the thing with transformers, right? It doesn't actually \"know\" anything about its inputs.The embeddings are learned (initialized to random).\n \nreply",
      "It's all very nice but if they end up \"altering\" the results heavily to play you the music they want you to listen for X or Y reason then it's pointless.I would like to be able to run this model myself and have a pristine and unbiased output of suggestions\n \nreply",
      "It may just be my perception, but I seem to have noticed this steering becoming a lot more heavy handed on Spotify.If I try to play any music from a historical genre, it's only about 3 or 4 autoplays before it's queued exclusively contemporary artists, usually performing a cheap pastiche of the original style.  It's honestly made the algorithm unusable, to the point that I built a CLI tool that lets me get recommendations from Claude conversationally, and adds them to my queue via api. It's limited by Claude's relatively shallow ability to retrieve from the vast library on these streaming services, but it's still better than the alternative.Hoping someone makes a model specifically for conversational music DJing, it's really pretty magical when it's working well.\n \nreply",
      "Spotify's recommendations are biased towards what you've listened to recently. Do you share the account with someone else?\n \nreply",
      "It\u2019s interesting the amount of research listed in the article and IMHO the recommendation engine/ algorithm used by Rdio in the late aughts and early 2010s eclipses anything I\u2019ve encountered to date.Seems like folks are reinventing the wheel, and trying to deduce what folks want to engage in with data and \u201cAI\u201d, rather than providing sufficient tools to allow the user to drive the narrative.\n \nreply",
      "The problem is that Rdio's was based on Echo Nest's similarity algorithm, which went private after Spotify bought Echo Nest.Doing music similarity with Echo Nest was great back when it was public. I did a project in grad school with it.\n \nreply",
      "Exploit is easy. It\u2019s the explore part that\u2019s hard. I.e. recommending me something i never knew i liked.Pandora and Rdio and others solved the exploit problems years and years ago.\n \nreply",
      "Other than stating there was one, they didn\u2019t show a benefit of this over something like a Wide and Deep model, DCNv2 model, or even a vanilla NN. Transformers make sense if you need to use something N items ago as context (as in text) where N is large. But in their example, any model which takes the last ~5 or so interactions should be able to quickly understand contextual user preferences.A transformer may also be larger than their baseline, but you still need to justify how those parameters are allocated.\n \nreply"
    ],
    "link": "https://research.google/blog/transformers-in-music-recommendation/",
    "first_paragraph": "We strive to create an environment conducive to many different types of research across many different time scales and levels of risk.Our researchers drive advancements in computer science through both fundamental and applied research.Our research teams have the opportunity to impact technology used by billions of people every day.We regularly open-source projects with the broader research community and apply our developments to Google products.Publishing our work allows us to share ideas and work collaboratively to advance the field of computer science.We make products, tools, and datasets available to everyone with the goal of building a more collaborative ecosystem.Supporting the next generation of researchers through a wide range of programming.Participating in the academic research community through meaningful engagement with university faculty.Connecting with the broader research community through events is essential for creating progress in every aspect of our work.August 16, 20",
    "summary": "Title: Google Tries to Reinvent the Wheel, Discovers Spotify\n\nGoogle, the humble small-time internet startup, bravely attempts to redefine music recommendations using transformer models because obviously, no one has ever thought of using data to suggest music before. \ud83d\ude44 Commenters swiftly swoop in to point out glaring gaps like, oh you know, not understanding the music itself. But don\u2019t worry, there\u2019s a lot of big words and complex diagrams to ensure everyone understands *something* is happening, even if it's just a sophisticated shuffle play. Meanwhile, everyone reminisces about the \"good old days\" of Rdio and Pandora\u2019s simplicity, proving once again that everything new is just old tech in AI's clothes."
  },
  {
    "title": "The oral history of the Dinosaur Input Device (vfxblog.com)",
    "points": 31,
    "submitter": "gelstudios",
    "submit_time": "2024-08-19T21:45:56",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://vfxblog.com/dinosaurinputdevice/",
    "first_paragraph": "Visual effects and animation journalist Ian FailesBy Ian FailesIn visual effects lore, it is well-known that the full-motion dinosaurs of Jurassic Park were originally intended as stop-motion puppets animated by Phil Tippett\u2019s Tippett Studio. That is, until a secret ILM test with computer-generated dinosaurs convinced director Steven Spielberg to go with that digital approach, perhaps changing the course of VFX history in the process.But, determined to stay \u2018in the game\u2019 and continue to contribute a rich knowledge of dinosaur movement, Tippett Studio combined with ILM to build the Dinosaur Input Device. This \u2018DID\u2019, which would later also be known as the Digital Input Device, was a dino-shaped sensor-covered armature that could translate stop-motion-like input to a CG model, allowing Tippett\u2019s traditionally trained animators to lend their skills to this new wave of digital animation. It also would also ultimately be awarded a Technical Achievement Award from the Academy (presented to Cr",
    "summary": "Title: **The Over-Hyped History of a Dino Joystick**\n\nIn an earth-shattering revelation of obsolete technology, vfxblog.com digs up the bones of the \"Dinosaur Input Device,\" a contraption born from the Jurassic age of visual effects where animators believed physical puppets could survive the digital asteroid. The article, dripping with nostalgia for a time when dinosaurs (and practical effects) ruled the earth, details how the brave artisans of Tippett Studio morphed their puppeteering despair into a joystick covered in sensors, otherwise known as the Dinosaur Input Device. Commenters, buried deep in their caves of denial, fervently tap out tributes to the lost art, weeping digital tears over their keyboards as they reminisce about the good old prehistoric times of animation. The collective denial about moving on from stop-motion is palpable, almost as real as the CGI T-Rex they can't stop talking about."
  },
  {
    "title": "Classifying all of the pdfs on the internet (snats.xyz)",
    "points": 246,
    "submitter": "Nydhal",
    "submit_time": "2024-08-19T12:23:09",
    "num_comments": 85,
    "comments_url": "https://news.ycombinator.com/item?id=41290409",
    "comments": [
      "Did some similar work with similar visualizations ~2009, on ~5.7M research articles (PDFs, private corpus) from scientific publishers Elsevier, Springer:Newton, G., A. Callahan & M. Dumontier. 2009. Semantic Journal Mapping for Search Visualization in a Large Scale Article Digital Library. Second Workshop on Very Large Digital Libraries at the European Conference on Digital Libraries (ECDL) 2009. https://lekythos.library.ucy.ac.cy/bitstream/handle/10797/14...I am the first author.\n \nreply",
      "How do you decide who is listed first? And does the ampersand symbolize something that the word and doesn't, or is that just citation style?\n \nreply",
      "One of the now-underdiscussed features of embeddings is that you can indeed use any existing statistical modeling techniques on them out of the box, and as a bonus avoid the common NLP preprocessing nuances and pitfalls (e.g. stemming) entirely.This post is a good example on why going straight to LLM embeddings for NLP is a pragmatic first step, especially for long documents.\n \nreply",
      "Hi! Author here, I wasn't expecting this to be at the top of HN, AMA\n \nreply",
      "Hi snats, great article. You mention the accuracy of the various techniques you used, could you explain more about how you calculated the accuracy? Were the pdfs already categorized?Thanks!\n \nreply",
      "Very cool! At Airtrain we\u2019ve also found embeddings can be very valuable for building classification models. If you\u2019re looking to play around with a large amount of text and embeddings we actually recently deduped and embedded all of fineweb-edu (also mentioned in the article) and put the resulting dataset on Hugging Face: https://huggingface.co/datasets/airtrain-ai/fineweb-edu-fort...\n \nreply",
      "Interesting read with lots of good detail, thank you.  A comment: if you are balancing the classes when you do one vs all binary training, and then use the max probability for inference, your probabilities might not be calibrated well, which could be a problem.  Do you correct the probabilities before taking the argmax?\n \nreply",
      "Back in 2006 there were multiple 1tb collections of textbooks as torrents. I imagine the size and number has only grown since then.\n \nreply",
      "That was before hoarding and building questionable businesses around them became a thing. I remember it being really easy to find textbooks, solution manuals, and related pdf and other stuff as late as 2008 far easier than 6-8 years later.The main difference were sites like chegg and many other sites started slurping them up to resell in some way.\n \nreply",
      "It doesn't take away the torrents, no?\n \nreply"
    ],
    "link": "https://snats.xyz/pages/articles/classifying_a_bunch_of_pdfs.html",
    "first_paragraph": "How would you classify all the pdfs in the internet? Well, that is\n            what I tried doing this time.Lets begin with the mother of all datasets: Common Crawl or CC is a\n            web archive of all of the internet, it currently is petabytes in size\n            and has been running since 2007. Maybe, you know about the Internet Archive which\n            is almost the same but\n            with the main difference being that Common Crawl focuses more on\n            archiving the internet for scientists and researchers instead of digital\n            preservation.What this translates into is that CC doesn\u2019t save all of the pdfs\n            when it finds them. Specifically, when Common Crawl gets to a pdf, it\n            just stores the first megabyte of information and truncates the\n            rest.This is where SafeDocs\n            or CC-MAIN-2021-31-PDF-UNTRUNCATED enters the picture. This corpus was\n            originally created by the DARPA SafeDocs\n                program an",
    "summary": "<b>Title: Classifying all of the pdfs on the internet (snats.xyz)</b>\n\nIn a daring leap of academic boredom, one brave soul at snats.xyz has decided to tackle the insurmountable task of classifying every last PDF on the planet because apparently, there\u2019s nothing better to do. But fear not, rather than preserving all those 'useless' pages, good ol' Common Crawl delicately amputates the bulk of each file, keeping just the first megabyte\u2014because who needs completeness in data science? Cue commenters tripping over their digital feet to share regurgitated tales of their similarly mind-numbing projects, reminiscing about the golden age of Internet hoarding while casually flexing their citations and data corps. Indeed, the more things change, the more comment sections remain eternal bragging grounds of near-missed opportunities and subtly misaligned probabilities. \ud83d\udcda\ud83e\udd13\ud83d\udcbe"
  },
  {
    "title": "Parsing protobuf at 2+GB/s: how I learned to love tail calls in C (2021) (reverberate.org)",
    "points": 324,
    "submitter": "fanf2",
    "submit_time": "2024-08-19T08:42:03",
    "num_comments": 140,
    "comments_url": "https://news.ycombinator.com/item?id=41289114",
    "comments": [
      "GCC just got musttail too: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=83324#c27\n \nreply",
      "A C standard proposal exists for tail call [0], in the form of \"return goto (expression);\".What I like about it, over standardizing [[musttail]], is that lifetimes of local objects are guaranteed to end. This makes it possible to implement without extensive escape analysis.[0] https://www.open-std.org/jtc1/sc22/wg14/www/docs/n3266.htm#5...\n \nreply",
      "Thanks for the pointer, I'll have to check this out.Can you elaborate on how \"return goto\" is easier to implement? [[musttail]] also ends the lifetime of local objects AFAICS.One thing I'll mention from a quick scan:> [The] function called in tail position must have identical type to the callee. This ensures both that the return value does not require any conversion, and also that argument passing space is available and calling convention (if relevant) is maintained.One complaint I've seen repeatedly about [[musttail]] (which I implemented in Clang) is that this constraint is unnecessarily strict, since some architectures will allow tail calls even for functions that do not perfectly match: https://github.com/llvm/llvm-project/issues/54964\"But then the code would be nonportable.\"  True, but tail call optimization is inherently nonportable, since some targets fundamentally do not support tail call optimization (eg. WASM without the tail call extension).\n \nreply",
      ">[[musttail]] also ends the lifetime of local objects AFAICS.That's good to know. I had this github issue [0] in the back of my mind, as well as witnessing occasions of clang turning [[musttail]] into inner loops, and concluded clang's implementation must be more sophisticated than simply replacing calls with jumps. Just a little paranoia from trying to be serious with compiler dev[1]: fulfilling a laid-out spec feels more sound versus imitating something out there.>this constraint is unnecessarily strictI would agree, at least for x86 psABI, it can be pretty elaborative as long as the return value is the same register and argument stack don't exceed what's provided. Debug/profiling side might hate it, though.[0] https://github.com/llvm/llvm-project/issues/72555\n[1] https://github.com/fuhsnn/slimcc/\n \nreply",
      "I certainly understand your caution.  I don't have intimate expertise with the implementation of musttail in the backend -- when I implemented musttail in Clang, it was piggybacking on an existing attribute from the LLVM IR: https://llvm.org/docs/LangRef.html#call-instructionThat said, my rough understanding is that a tail call ends the lifetime of all objects in the old stack frame.  It follows that it is UB to access any objects from the previous stack frame after a tail call, and that would include Gerben's first example in https://github.com/llvm/llvm-project/issues/72555Your slimcc project looks really interesting, thanks for the pointer.\n \nreply",
      "> some targets fundamentally do not support tail call optimizationCan't any tail call be rewritten as a loop? Couldn't a WASM compiler without the tail call extension implement it this way?\n \nreply",
      "Yes, wasm2c implements the Wasm tail-call feature with trampolines, exactly this way. (https://github.com/WebAssembly/wabt/blob/main/test/wasm2c/ta... has an example.)Doing it with a trampoline is probably slower than if C really had tail calls. On the other hand, adding \"real\" tail calls to C would probably require changing the ABI (e.g. to \"tailcc\" or \"fastcc -tailcallopt\"), and I think there's some reason to think this would probably impose a penalty everywhere (https://llvm.org/docs/CodeGenerator.html#tail-call-optimizat...).\n \nreply",
      "> On the other hand, adding \"real\" tail calls to C would probably require changing the ABI (e.g. to \"tailcc\" or \"fastcc -tailcallopt\")But [[musttail]] does exactly this while respecting existing calling conventions: https://clang.llvm.org/docs/AttributeReference.html#musttail\n \nreply",
      "No -- as discussed upthread, clang's musttail attribute requires the target function to have the same number of arguments as the caller and for each argument to be similar to the corresponding caller argument. That's stricter than the underlying LLVM musttail marker (when targeting the tailcc/swifttailcc calling conventions) and is too restrictive to implement Wasm's tail-call feature (and probably Scheme's, etc.), at least if arguments are getting passed to functions natively.It would be nice if the more relaxed rules of the LLVM musttail marker with tailcc could be exposed in clang (and gcc). I think that's basically what \"return goto\" would do.\n \nreply",
      "It can't be rewritten as loop due to function pointers. Using JS notation to avoid noise:function logAndCall(statement, func) { console.log(statement); return func(); }Tail call optimization is actually possible here since we call func in \"tail position\". It might be unlikely to blow up the stack, but it can definitely happen if you do a lot of continuation passing.Perhaps more commonly for C++/Rust, tail call optimization would be enormously valuable to have behind the scenes for destructors. It's actually very difficult to implement a linked list in safe Rust that doesn't explode the stack for large lists since no TCO is done for destroying subobjects. You can still avoid stack overflow, but you have to do things like manually enumerating the list.\n \nreply"
    ],
    "link": "https://blog.reverberate.org/2021/04/21/musttail-efficient-interpreters.html",
    "first_paragraph": "\nApril 21, 2021\nAn exciting feature just landed in the main branch of the Clang\ncompiler. Using the [[clang::musttail]] or\n__attribute__((musttail)) statement attributes, you can now get guaranteed\ntail calls in C, C++, and Objective-C.While tail calls are usually associated with a functional programming style, I\nam interested in them purely for performance reasons.  It turns out that in\nsome cases we can use tail calls to get better code out of the compiler than\nwould otherwise be possible\u2014at least given current compiler\ntechnology\u2014without dropping to assembly.Applying this technique to protobuf parsing has yielded amazing results: we\nhave managed to demonstrate protobuf parsing at over\n2GB/s, more than double the\nprevious state of the art.  There are multiple techniques that contributed to\nthis speedup, so \u201ctail calls == 2x speedup\u201d is the wrong message to take away.\nBut tail calls are a key part of what made that speedup possible.In this blog entry I will describe why tail calls are",
    "summary": "\ud83d\ude80 **Another Day, Another Compiler Feature Boasting Session** \ud83d\ude80\n\nIn an era where speed is the new black, a wild article appears claiming a groundbreaking achievement of parsing protobuf at a lightning-fast 2+GB/s, thanks to something called \"tail calls\" in C. It's like discovering fire, but if fire was only useful for cooking minute rice. The corresponding comment section quickly becomes a hotbed of underqualified speculation and one-upmanship, as keyboard warriors debate musttail implementation minutiae. Meanwhile, any normal human attempting to follow the conversation likely needs a drink or a degree in computer science - but preferably both. \ud83c\udf7b"
  },
  {
    "title": "Page Turns: Literary Translations on the American Ballet Theater's Summer Stage (lithub.com)",
    "points": 5,
    "submitter": "bryanrasmussen",
    "submit_time": "2024-08-18T13:36:07",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://lithub.com/page-turns-on-literary-translations-on-the-american-ballet-theaters-summer-stage/",
    "first_paragraph": "Though I\u2019ve heard ballet dancers say there are moments onstage when they feel more like actors than athletes, I\u2019ve always assumed the choices available to dancers as actors were few, and that embodying a character was secondary to embodying the most perfect lines of one\u2019s own body. Under ballet\u2019s demands of technical precision, I thought character could only emerge within a confined menu of available steps and techniques, like a plant growing in a controlled lab.But when the dancer Aran Bell, in his role as Romeo, found Juliet\u2019s lifeless body in the crypt, I finally understood. I was high up in my own balcony, in the cheap seats, but could see each muscle of his face tremble. He crumpled over his lover\u2019s body, heaving with a depth of grief that let his dancing access his character\u2019s centuries-old pain.And when Christine Shevchenko, as the heroine Tatyana, emerged onstage in the final act of Onegin with her aristocratic husband. The lines of her lithe body were made even straighter now ",
    "summary": "Today on the Academy of Literary Gymnastics, a shocking revelation: ballet dancers *feel* things while dancing! \ud83d\udc83 Who knew pirouetting could evoke such existential crisis, passing the profound depth of a Shakespeare tragedy? But fear not, balcony seat critics in their lofty perches are on hand, magnifying glasses out, ready to spot the faintest facial twitch that connects a thousand-dollar ticket to the raw anguish of fictional characters. Meanwhile, commenters engage in deep armchair analysis, debating whether Tchaikovsky or Prokofiev had the sadder violins to accompany such pained expressions. \ud83c\udfbb\ud83d\ude2d"
  },
  {
    "title": "Migrating Mess with DNS to Use PowerDNS (jvns.ca)",
    "points": 79,
    "submitter": "hasheddan",
    "submit_time": "2024-08-19T17:14:12",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41292784",
    "comments": [
      "> Sometimes users will still get errors from PowerDNS directly, but I added some logging of all the errors that users see, so hopefully I can review them and add extra translations if there are other common errors that come up.I noticed that you are using our Go module to access the API. It is wonderful to see our work helping others build great software, especially for education. Thank you for that.Please note that the upstream API sometimes changes slightly between minor releases. For example, prior to v4.9, the error response for a non-existent server was \"Not Found\". Starting with v4.9, it changed to \"Method Not Allowed\".Unfortunately, error responses aren't always part of the API specification. I'm thinking about adding the most common cases to the module anyway.\n \nreply",
      "You just said that the message for \"non-existent server\" is spelled \"method not allowed\"? Did I read this right?\n \nreply",
      "> Previously Mess With DNS was using a Postgres database. This was problematic because I only gave the Postgres machine 256MB of RAM, which meant that the database got OOM killed almost every single day. I never really worked out exactly why it got OOM killed every day, but that\u2019s how it was.Found this a little surprising - postgres is internet old - I'm pretty sure it was around at a time when physical servers might not have 256mb of ram?Seems this should be possible to tune down still? (I mean, maybe not. Postgres 16 isn't postgres 6, and maybe I'm just getting old..)\n \nreply",
      "Postgres can scale down, there are a few settings you can tweak: https://www.postgresql.org/docs/current/runtime-config-resou...\n \nreply",
      "The section labelled \"what I learned: it\u2019s okay for an API to duplicate information\" is something I come across often in Django projects. Django views send a Python dictionary of data to the template processor to display the information. Often it's easier to massage the data into a more friendly format before sending it to the template, even if it means duplicating the info sent.\n \nreply",
      "Yep. There\u2019s certainly a balance to strike, especially on projects with a larger number of people working on them. But I generally find that you want to do at least MOST of your data processing outside of your template.\n \nreply",
      "Great write up. I'm using PowerDNS for https://www.getlocalcert.net/, which also makes heavy use of PowerDNS's HTTP API. I've been really happy with it. I need to check my code, but I remember planning to use the comment field of the records to map between application IDs and records in PowerDNS zones.You may be able to implement the logging by using a customization of the Sqlite backend, although I think PowerDNS caching may get in your way.I'll recommend the pipe backend to anyone looking to hack on DNS stuff. It's almost like a DNS lookup via a function in any programming language you choose. It takes a while to figure out how incoming queries are translated though.https://doc.powerdns.com/authoritative/backends/pipe.html\n \nreply",
      "Thank you very much for this wonderful experimental and educational tool.You mentioned about your previous version:> If there was a CNAME record for a domain name, it allowed you to create other records for that domain name, even if it shouldn\u2019t> you could create 2 different CNAME records for the same domain name, which shouldn\u2019t be allowedOne suggestion... If someone makes a mistake and generates an error, it would be terrific if there were a more verbose explanation so the user may better understand why what they're trying to do won't work. I'm very much a conceptual learner. If I can understand why an error is an error, it puts me on a better path toward a more comprehensive understanding.Thanks again for all your work.\n \nreply",
      "That's a great idea, thanks.\n \nreply",
      "Does anyone use CoreDNS? Outside of a Kubernetes cluster I mean.\n \nreply"
    ],
    "link": "https://jvns.ca/blog/2024/08/19/migrating-mess-with-dns-to-use-powerdns/",
    "first_paragraph": "\n\nAbout 3 years ago, I announced Mess With DNS in\nthis blog post, a playground\nwhere you can learn how DNS works by messing around and creating records.I wasn\u2019t very careful with the DNS implementation though (to quote the release blog\npost: \u201cfollowing the DNS RFCs? not exactly\u201d), and people started reporting\nproblems that eventually I decided that I wanted to fix.Some of the problems people have reported were:And there are certainly more issues that nobody got around to reporting, for\nexample that if you added an NS record for a subdomain to delegate it, Mess\nWith DNS wouldn\u2019t handle the delegation properly.I wasn\u2019t sure how to fix these problems for a long time \u2013 technically I\ncould have started addressing them individually, but it felt like there were\na million edge cases and I\u2019d never get there.But then one day I was chatting with someone else who was working on a DNS\nserver and they said they were using PowerDNS: an open\nsource DNS server with an HTTP API!This seemed like an obvio",
    "summary": "<h3>Yet Another DNS Debacle</h3>\n<p>Three years into creating what can only be mildly termed as a \"functional\" DNS playground, our brave hacker has decided to ditch sticking plasters for something more robust - revealing <em>The PowerDNS Epiphany</em>. In a tale as old as time, tech enthusiasts gather in the comments to sermonize on error messages, lavish praise on redundant API features, and <em>mysteriously</em> drip-feed PostgreSQL memory management tips from the 90s. Because, obviously, when dealing with daily outages, what you need is to ponder the philosophical nuances of API error responses. Stay tuned for more cycles of code, crash, and comment - rinse and repeat!</p>"
  },
  {
    "title": "Cardinal \u2013 Virtual modular synthesizer plugin (kx.studio)",
    "points": 61,
    "submitter": "iscream26",
    "submit_time": "2024-08-19T20:29:45",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41294332",
    "comments": [
      "Programs like this and VCV Rack are great ways to get started on the road to building your own modular synthesizer [1]. Many of the modules in the program are based on real hardware, and while the hardware versions of these modules can cost hundreds of dollars, the software versions are using the exact same firmware. Whether you stay virtual or go out and build the hardware equivalent of your rack, it's a great way to experiment and learn the basics at a lower cost than in the past.[1] https://en.wikipedia.org/wiki/Modular_synthesizer\n \nreply",
      "I'm a little torn on how I feel towards the Cardinal project. It claims not to be a fork on a technicality. It brings some improvements certainly and VCV dev has felt stagnant the last couple years, but it's also a little uncomfortably (to me) ideologically trying to GPL VCV. At least they are transparent about it. I like their community presence. I wonder if most users of Cardinal are aware how much of what they appreciate is the work upstream. A lot of value is lost to not have access to all of VCV's free-but-not-GPL modules, but the gap is shrinking.\n \nreply",
      "VCV Pro has the DAW plugin feature as a paid extra. Cardinal seems to be taking the GPL version of VCV and using it to undercut the main income source of the VCV project.\n \nreply",
      "I'm in the process of building a similar project aimed towards beginners, so it's hopefully a bit less daunting than Cardinal/VCV Rack.https://wavepen.jinay.dev/\n \nreply",
      "This only includes a small subset of the VCV Library, some of the best modules aren't included in this and pretty cool. There's also some incredible paid modules in the library worth checking out.\n \nreply",
      "There are also a few collections that are available only in Cardinal, and not VCV\n \nreply",
      "It would be nice to add a guide or a question in the FAQs about using your PC keyboard for MIDI input. I've explored the project and the menus a bit, but I can't get it to work from the browser (Firefox, Linux).\n \nreply",
      "Very nice project, it has all the basic modules to start learning from, and most importantly - in one place.I'm using it myself in combination with Ardour, now at the beginning of my learning curve - it is great!\n \nreply",
      "It remind me Rebirth [0] (had so much fun epochs ago). Soo many buttons, but where the heck is play button ?I will leave it more experienced musicians :). \nLooks like great project[0] https://en.wikipedia.org/wiki/ReBirth_RB-338\n \nreply",
      "It lacks the VultModulesFree from VCV...\n \nreply"
    ],
    "link": "https://cardinal.kx.studio/",
    "first_paragraph": "Virtual modular synthesizer pluginAvailable in AudioUnit/CLAP/LV2/VST2/VST3 plugin formats and as a standalone app for FreeBSD, Linux, macOS, Windows and the Web.Created first and foremost as a way to have Rack as a conventional open-source audio plugin.Cardinal does not load any external modules, everything is built-in.Supporting real CV ports to and from the plugin, for integration with other modular systems.Supporting more than just the basic 3 desktop operating systems.A total of 1219 modules from 79 different authors/brands.A \"main\" variant plus Synth and FX.\r\n\t\t\t\t\tDevelopment happens on GitHub and we chat on the #cardinal IRC room in irc.libera.chat server.\r\n\t\t\t\t\t\r\n\t\t\t\t\tCome join us in your favorite IRC client or through your web browser (no post history).\r\n\t\t\t\t",
    "summary": "Title: <em>Cardinal</em> \u2013 Digital Knob-Twisting Extravaganza\n\nSummary: Enter the pixelated paradise of <em>Cardinal</em>, the virtual modular synthesizer that saves you the inconvenience of real cables that actually carry real voltage. Now available for every OS crafted by human hands, Cardinal comes jam-packed with 1219 modules curated by 79 different digital sound wizards. It\u2019s like the buffet of sound synthesis, except you don\u2019t have to wear pants to enjoy it. Meanwhile, the comment section is aflame with purists and newcomers alike, debating the philosophical implications of forking code like it's Grandma\u2019s secret recipe, while others just seem puzzled about where to find the mythical \u2018play\u2019 button. Spoiler: it\u2019s next to the \u2018any\u2019 key. \ud83c\udfb9\ud83d\udd0d"
  },
  {
    "title": "The guidance system and computer of the Minuteman III nuclear missile (righto.com)",
    "points": 118,
    "submitter": "magnat",
    "submit_time": "2024-08-19T19:06:59",
    "num_comments": 77,
    "comments_url": "https://news.ycombinator.com/item?id=41293767",
    "comments": [
      "I live several miles from a Minuteman silo in Montana, maintained by Malmstrom Air Force Base. The underground cabling between sites is also an interesting read (https://minutemanmissile.com/hics.html). Anytime I want to dig on my property, I have to make sure it won't interfere with their pressurized cables. I have heard a story from someone that did accidentally cut a cable, and Malmstrom AFB was able to locate the break and respond rapidly. I am a volunteer firefighter, and our station has a VHS tape and a paper guide titled \"Incident Guide for Missile Field Fire Response\" provided to us by the DoD regarding our role in responding to fi\u0159e incidents near or at a silo. A year or so ago, we did respond to a fire near a silo, but it occurred entirely outside the security fencing. My understanding is that the personnel at the silos also have their own ability to respond to fires.\n \nreply",
      "But isn't it the case that there is typically no personnel at the silo (or Launch Facility LF) itself?  Instead, the Missile wing Commanders at the Launch Control Centers (LCC) some distance away.  The LCC commands some number of LFs remotely.https://en.wikipedia.org/wiki/Missile_launch_control_center\n \nreply",
      "The tape is probably a reponse to some infamous disasters/tragedies:* https://en.wikipedia.org/wiki/LGM-25C_Titan_II#Mishaps* https://en.wikipedia.org/wiki/1965_Searcy_missile_silo_fire* https://en.wikipedia.org/wiki/1980_Damascus_Titan_missile_ex...\n \nreply",
      "How different is it than a standard 811 utility-locate call?Actual change in procedure? Or just extra cheek-clinching?\n \nreply",
      "> Anytime I want to dig on my property, I have to make sure it won't interfere with their pressurized cables.Sounds like a serious weak point\n \nreply",
      "I believe parts of the subsea industry uses a similar concept, i.e., gyroscope based for inertial navigation.Obtaining position & veocity: I think it even more interesting when one compares the difficulties of getting these fundamental navigation data in an aerial, ground and undersea platforms.\n \nreply",
      "The idea behind inertial navigation is to keep track of the missile's position by constantly measuring its acceleration. By integrating the acceleration, you get the velocity. And by integrating the velocity, you get the position.This sounds like it couldn't possibly work (surely all the little errors compound?) but apparently it's how Apollo navigatedhttps://wehackthemoon.com/tech/inertial-measurement-unit-mec...\n \nreply",
      "When the MacBook got the acceleration sensor, I hacked up a little program to estimate velocity, and a button to reset at stoplights. Some friends drove me around, it worked poorly. it did pretty ok on the highway, but awful in the city.I think if I kept messing with it, it'd get a lot better, but I sorta lost interest. This was more of a fun weekend toy.I think all phones have them, and they might be reachable through chrome/safari. And it is kinda fun to play with, but you'll probably hit sampling rate errors pretty quick. you gotta guess the shape of the curve between datapoints.\n \nreply",
      "I said it downthread, but GPS is even more absurd. And we take it for granted.But it's based on the same idea, only getting position as a derivative of velocity. (And some borderline-magic statistics applied.)And that's before taking into account the absurdity of how low power the broadcast signal is.\n \nreply",
      "GPS doesn't work that way.  It uses instantaneous time-of-flight computation.\n \nreply"
    ],
    "link": "http://www.righto.com/2024/08/minuteman-guidance-computer.html",
    "first_paragraph": "",
    "summary": "Welcome to the riveting world of Minuteman missiles, where buried cables and VHS firefighting guides are the height of rural Montana chic. Enthusiasts discuss the finer points of gyroscopes and inertial navigation like it's the Apollo moon landing, but with the safety of a Cold War relic in their backyard. In the comments, the nostalgia for a close brush with thermonuclear catastrophe is palpable, because nothing says \"community\" like digging around pressurized missile cables. Meanwhile, someone hacked a MacBook to measure velocity\u2014poorly. It\u2019s like Silicon Valley meets fail-safe nuclear command, with a touch of farmhouse flair."
  },
  {
    "title": "Netboot.xyz: your favorite operating systems in one place (netboot.xyz)",
    "points": 186,
    "submitter": "thunderbong",
    "submit_time": "2024-08-19T19:19:44",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=41293850",
    "comments": [
      "Since I won't get a better chance to find knowledgeable people: How exactly does iPXE work? Lets say I want to boot a random old PC from one of these images - does the bios need to have iPXE support? Or PXE? Or does it need to first boot into some local system first, which then goes out and gets the image to boot the rest of the way from?Then there's mention of DHCP and self hosting. Do I need to have some service running within my LAN first or can this go right out to some public server and boot from images there? How does DHCP factor in? I am in so far over my head on this but it seems interesting and something fun to try out.\n \nreply",
      "PXE [0] is a standard for netbooting, typically implementated in the system's boot firmware. A PXE-compatible client sends a DHCP request on boot, to which the network's DHCP server responds with the IP address of a server to netboot from. The client will then connect to this server via TFTP, download an executable image file in the PXE format, and boot it. Using PXE on your own computer requires enabling PXE the firmware setup, setting up a TFTP server to serve the PXE image, and configuring your DHCP server to point to your TFTP server.iPXE [1] is an open-source implementation of PXE, and much more -- it's much more flexible, it supports additional protocols including HTTP(S) and DNS, it has configuration and scripting options, a basic command-line interface, etc. In order to run iPXE, you need to boot an iPXE image somehow -- e.g. from a MBR or EFI image on a disk drive or USB drive (or even over PXE, I guess). But because iPXE supports more protocols and more configuration, you don't need to set up TFTP and DHCP, and it can chainload into e.g. an EFI image or a Linux kernel instead of being limited to booting images in the PXE format.An example of iPXE in the wild is the Arch Linux netboot image [2]. They provide pre-configured iPXE images that display an interactive menu to select a mirror, download the Arch Linux installer, and boot it. (It's really convenient since you can just drop the UEFI image at \"/efi/boot/bootx64.efi\" on a FAT32 thumb drive instead of having to download the whole installer image and 'dd' it onto the drive.)The submitted project, netboot.xyz, is a similar idea: a preconfigured build of iPXE that lets you interactively download and boot installers for many popular operating systems from a single image.[0]: https://en.wikipedia.org/wiki/Preboot_Execution_Environment[1]: https://ipxe.org/[2]: https://archlinux.org/releng/netboot/\n \nreply",
      "> A PXE-compatible client sends a DHCP request on boot, to which the network's DHCP server responds with the IP address of a server to netboot from.Specifically there are particular DHCP options (66, 67) that tell the client about this, and the client software (PXE) understands them:* https://datatracker.ietf.org/doc/html/rfc2132* https://www.iana.org/assignments/bootp-dhcp-parameters/bootp...* https://www.iana.org/assignments/dhcpv6-parameters/dhcpv6-pa...  (RFC 5970)And while the options previously were interpreted for TFTP use, newer PXE software now understands the use of \"http[s]://\" in the file name and use that instead of TFTP.\n \nreply",
      "> or even over PXE, I guessThis is super common actually! Most built-in PXE only supports TFTP, which is pretty slow compared to TCP-based stuff. It can make sense to use the built-in PXE to grab a (small) iPXE image over TFTP, then have iPXE grab the (big) real image over HTTP(S). This is also useful if you want to store your main image on something like S3 that doesn\u2019t support TFTP.For a while I had a script that would create iPXE images dynamically on the fly with the correct HTTPS URL and auth information embedded in them.\n \nreply",
      "> it can chainload into e.g. an EFI imageOff topic, but does anyone know a good resource that explains how to correctly use \"e.g.\"? (I've looked before, but didn't find one)While I may seem like a grammar pedant, there are many things that have entered common use while arguably incorrect that I'm not so bothered about (\"That begs the question\", for example). However while this (incorrect) use of \"e.g.\" is a hill I will die on, even so, I struggle to explain why it's just plain wrong. (It can be used to replace \"for example\" when preceding a list if examples that illustrate a point, but not as a generic replacement as in this case.)Someone somewhere must have explained it better...\n \nreply",
      "> It can be used to replace \"for example\" when preceding a list if examples that illustrate a pointI think you've already understood it.\n \nreply",
      "You can use netboot.xyz from a flash drive to boot various operating systems and utilities. Alternatively, PXE (Preboot Execution Environment) has been around for a while and works by allowing a network-capable device to boot from its network interface. A PXE-compatible network card requests a DHCP lease during the boot process, which provides the IP address of a TFTP (Trivial File Transfer Protocol) server and the file that needs to be loaded from the server.Typically, the network card contains a basic PXE kernel. To enhance this environment, you can chainload iPXE, which offers a broader range of features. iPXE allows for more advanced booting options, such as loading scripts or initiating an unattended installation directly from the network.\n \nreply",
      "There's multiple ways to boot, including USB/ISO: https://netboot.xyz/docs/category/booting-methodsGenerally speaking, if you have iPXE already compiled and flashed onto your NIC, then you can follow these instructions: https://netboot.xyz/docs/booting/ipxeDHCP is only needed for getting an IP address. You can use the Docker image with the proper DHCP parameters to load it automatically when using PXE/iPXE: https://netboot.xyz/docs/docker\n \nreply",
      "So what I do here is that I have a local PXE server (it's a DHCP option on your router) that serves up iPXE with a preconfigured script to boot via HTTP off of netboot.xyz. So whenever I want to install linux on a new computer, I set the BIOS boot option to boot from PXE next boot and restart. In a few seconds, I am presented with my choice of linux environment.For my data center servers, I have it booting via PXE to an iPXE with a custom script to take a unique identifier from the host and build the corresponding configuration (NixOS). So essentially for that I define my NixOS configuration in a NixOS flake and plug the new host in and it will boot to the correct configuration. I actually don't have any OS installation on most of the hosts and share the nix store via NFS.I also keep an iPXE thumb drive around in case I need to do this for something not on my network. In that case, I insert the drive, boot from it, and then ask it to boot from netboot.xyz manually.\n \nreply",
      "There are a bunch of different options to \"bootstrap\" iPXE in the first place. Least invasive is probably to boot it from a USB drive. You can also set up a traditional PXE boot process using DHCP/TFTP on your network to \"chain-load\" iPXE (if your client's network card supports PXE), or you can even flash iPXE into the boot ROM on certain network cards.However you do it, once iPXE starts running, it will take control of the NIC and fetch the actual OS images that it needs from the internet over HTTP.\n \nreply"
    ],
    "link": "https://netboot.xyz/",
    "first_paragraph": "your favorite operating systems in one placenetboot.xyz enables you to boot into many types of operating systems using lightweight tooling to get you up and running as soon as possible.Discover new operating systems without having to download and rewrite media over and over again. Rescue operating systems from a single image. An essential for any sysadmin.netboot.xyz uses the iPXE project to enable you to provision, rescue or load into a live boot environment leveraging the Preboot Execution Environment (PXE) on most systems.",
    "summary": "**Netboot.xyz: Bringing You Every OS, Everywhere, All the Time**\n\nAh, netboot.xyz! It's the modern-day geek equivalent of a Swiss Army knife, but for booting operating systems. Whether you're a sysadmin who\u2019s lost the last shreds of their sanity or a hobbyist who thrives on the bleeding edge of network boot protocols, this tool promises to magically solve all your OS needs via iPXE - a project no casual user has ever heard of, but will vehemently defend in forums. The comment section is ablaze with the overly optimistic and the profoundly lost, both united by the belief that configuring DHCP options is a fun weekend activity. Still wondering about DHCP, HTTP, and PXE? Don\u2019t worry, so is everybody else. But at least we've got a modern guide to medieval booting practices! \ud83d\udcdc\ud83d\udcbe"
  },
  {
    "title": "AI companies are pivoting from creating gods to building products (aisnakeoil.com)",
    "points": 67,
    "submitter": "randomwalker",
    "submit_time": "2024-08-19T21:34:30",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=41294764",
    "comments": [
      "Instead of pivoting, can this behaviour be explained by trying lots of different things and then iterating on the ones that show promise?It's all well and good to say \"Make something people want\"  but for anything that people want usually one of three things is true1.  Someone else is already making it.2.  Nobody knows how to make it.3.  Nobody knows that people want it.People experimenting with 2 and 3 will have a lot of failures,  but the great successes will come from those groups as well.Sure, every trend in business has a lot of companies going \"we should do this because everyone else is\"   It was a dumb idea for previous trends and it is a dumb idea now.   Consider how many companies did that for the internet.  There were a lot of poorly thought out forays into having an internet presence.  Of those companies still around, they pretty much will have an internet presence now that serves their purposes.  They transition from \"because everyone else is\" as their motivation to \"We want specific ability x,y,&z\"Perhaps the best way to get from \"everyone else is doing it\" to knowing what to build is to play in the pool.\n \nreply",
      "Companies keep going at it the wrong way. Instead of saying \"We have AI, let's find products we can make out of AI!\" they should be saying, \"What products do people want, let's use whatever tools we have (including maybe AI) to make them.\"The idea that a company is an AI company should be as ridiculous as a company being a Python company. \"We are Python-first, have Python experts, and all of our products are made with Python. Our customers want their apps to have Python in them. We just have to 'productize Python' and find the right killer app for Python and we'll be successful!\" Going at it from the wrong direction. Replace Python in that quote with AI, and you probably have something a real company has said in 2024.\n \nreply",
      "It was likely the same back when the steam engine was invented.  Everyone who could start a steam engine company, started a steam engine company.  Because learning how to be a steam engine company was difficult, new, and unique.  It would be a while before finding all the products that could be sold to people incorporating that new tech.\n \nreply",
      "I don't entirely disagree with you, but \"what products do people want\" is overly conservative. Pre-ChatGPT, very few people wanted a (more or less) general purpose chatbot.\n \nreply",
      "One of my local car dealerships is using an chat system of some kind (probably an LLM?).It's awful and a complete waste of time. I'm not sure if LLMs are getting good use yet / general chatbots are good or ready for business use.\n \nreply",
      "To be fair, the overwhelming feedback appears to be that people dont want a general purpose chatbot in every product and website, especially when it's labelled 'AI'.So... certainly there's a space for new products....but perhaps for existing products, it's not as simple as 'slap some random AI  on it and hope you ride the wave of AI'.\n \nreply",
      "I blogged about our glorious journey Becoming an AI Company (TM)https://candid.dev/blog/becoming-an-ai-company/\n \nreply",
      "I was unmoved until I hit \"Natural Language\u2122\".\n \nreply",
      "Its the same as all the \"we are a blockchain company\" startups that popped up looking for a problem to solve with their tech rather than the right way round.However, a lot of those got a bunch of investment or made some decent money in the short term.  Very few are still around.  We will see the same pattern here.\n \nreply",
      "There's still a lot of real work to be done knowing what can be built and operated profitably, because the underlying tech is so new.So just zooming out, we need people trying to figure out what can be built with this Lego set. We also need people like you're saying to work the other side so everyone can meet in the middle.\n \nreply"
    ],
    "link": "https://www.aisnakeoil.com/p/ai-companies-are-pivoting-from-creating",
    "first_paragraph": "",
    "summary": "Welcome to another episode of \ud83d\udca1 \"Throw Tech At It And See What Sticks!\"\u2014the favorite reality show of every AI company hell-bent on turning divine inspiration into mundane products. How cute! The commenters, steeped in boundless wisdom, preach the gospel of iteration fueled by an intoxicating mix of desperation and cluelessness. \ud83d\ude4c As one bright soul muses eloquently on replacing *Python* with *AI* (apples to asteroids, obviously), others pine for the steam engine days, because nostalgia is just as useful for business strategies as a chocolate teapot. \ud83d\ude82 And amidst the cries for AI-less AI products, remember kids, nothing says innovation like slapping an \"AI-powered\" sticker on your slowly crumbling business model. \"High-tech\" indeed. \ud83c\udf89"
  },
  {
    "title": "Spine \u2013 2D skeletal animation for games, with physical secondary motions (esotericsoftware.com)",
    "points": 51,
    "submitter": "diggan",
    "submit_time": "2024-08-16T17:40:10",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41268540",
    "comments": [
      "Spine is really lovely. It was great back in 2019 when I used it to release a game. They released the 4.0 version a year later with a lot of updates and while I have no plans to make another 2D side-scrolling type of game... this one piece of software is what makes it tempting.The thing I REALLY appreciate is the lifetime license. Checking my emails, I bought the professional version in 2015 for $289. Now it's almost a decade later, still getting awesome updates, and I can still get the latest version. Totally unlike the current trend... I'm looking at you, $20 / month for Speedtree.\n \nreply",
      "I mean, Spline seems to do the same thing if your company makes enough money:>Spine Enterprise is required for businesses with $500,000 USD or more annual revenue. The license allows Spine Enterprise to be used by the specified number of users for a period of one year. All updates are provided during this time. After one year, Spine Enterprise must be licensed again to continue using Spine Enterprise.\n \nreply",
      "I didn't know that! Pretty sure the enterprise license didn't exist when I bought it.I like these honour system enterprise licenses better than never-ending subscriptions, but they are becoming too common in the game industry.\n \nreply",
      "Is Rive at all comparable?https://rive.app/editorThe open sourced their renderer recentlyhttps://rive.app/blog/rive-renderer-now-open-source-and-avai...\n \nreply",
      "It's a comparable tool, yes, and common in the industry, but I have not personally used it yet.\n \nreply",
      "Spine is cool, but I find it ridiculous for more and more tool software for games to force Enterprise licenses, rev share, etc onto developers.>Businesses with more than $500,000 USD annual revenue require a Spine Enterprise license\n \nreply",
      "> Spine is cool, but I find it ridiculous for more and more tool software for games to force Enterprise licenses, rev share, etc onto developers.Price your software they way you want Spine to price theirs, and you'll fall under the 500K threshold and be all set.\n \nreply",
      "If you're making $500k/year in revenue, Spine's license cost is probably the least of your worries.I tend to be averse to proprietary dependencies more from a maintainability/longevity aspect than a cost aspect.  If Esoteric Software goes out of business, who develops future versions of Spine?  Are they kind enough to open-source it before turning the lights off?  Does it get sold to some other company that runs it into the ground?  Does development just cease?  Are there licensing servers that the tools and SDKs and such have to ping to be functional, and if so, what happens when those servers shut down?\n \nreply",
      "To be honest I am surprised there isn't an open source alternative for this type of animation in 2D - I only know of blender and lottie as somewhat closer to it but nothing that is quite like Spine.\n \nreply",
      "Blender (via https://github.com/ndee85/coa_tools) and Godot's Skeleton2D node are both open-source. I'd assume Spine's advanced features far outpace them, but I also suspect the need for such features is rare.\n \nreply"
    ],
    "link": "https://en.esotericsoftware.com/",
    "first_paragraph": "Animation brings video games alive. We believe creating great 2D animation requires not only powerful software, but a powerful workflow. Spine is dedicated to 2D skeletal animation, providing an efficient workflow both for creating amazing animation and for integrating it into your games.Our live demos show a sample of what is possible with Spine, right in your browser window. Play animations in layers, manipulate skeletons dynamically, and much more.Spine Academy has everything you need to get started learning Spine. Whether you like learning on your own or prefer face-to-face workshops and courses, we got you covered. Check our changelog and roadmap to see what changed between Spine versions and what's being worked on, and don't forget to sign up to our community forum.Animating is an iterative process. Spine provides numerous tools to shape and refine your 2D animations. Bend and deform images with mesh skinning/weights, adjust timing with the dopesheet, visualize motion with ghosti",
    "summary": "In a world where any schmo can slap some code together and call it a \"game animation tool,\" <em>Spine</em> stands tall, flaunting its \"revolutionary\" 2D skeletal magic. The comment section, a delightful cesspool of tired indie devs regaling us with tales from the good ol' days of 2019, squabbles over licensing fees like they're brokering peace in the Middle East. One mentions buying Spine when dinosaurs roamed the Earth (2015) and still reels from the exorbitant price, while another cries into their beer about the injustice of the enterprise license. Meanwhile, everyone ignores the lurking fear: what if the company tanks? Do they think a tweet saying \"Please open-source Spine\" is a legally binding spell? \ud83e\uddd9\u200d\u2642\ufe0f\ud83d\udcb8"
  },
  {
    "title": "Searching a Codebase in English (greptile.com)",
    "points": 11,
    "submitter": "dakshgupta",
    "submit_time": "2024-08-15T23:48:59",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41261711",
    "comments": [
      "The page is unreadable on Firefox Focus\n \nreply",
      "Also unreadable on Android/Chrome.  The whole left side of the page is cropped off\n \nreply",
      "Also unreadable on Firefox on iOS.\n \nreply"
    ],
    "link": "https://www.greptile.com/blog/semantic",
    "first_paragraph": "Daksh GuptaI'm Daksh, one of the co-founders of Greptile. We're building AI that understands codebases, which you can query using an API. To do this, we have to, depending on the task, provide an LLM with snippets from the codebase, ideally the fewest number of snippets that give it sufficient information to respond to the query.We found out that this problem is harder than it looks. Before we get into all the ways we tried to make codebase semantic search work, it's interesting to see why it's different from semantically searching a book.First, we index the corpus we are trying to search over:Semantic vector embeddings capture the semantic meaning of a piece of text as an n-dimensional vector. The algorithm to create them is quite fascinating and is explained very well in chapter 6 of Speech and Language Processing, available for free here.When two pieces of text are semantically similar, their vectors are too, which can be quantified by their cosine similarity or normalized dot produ",
    "summary": "In the latest tech-tinkering attempt, <em>Greptile</em> reinvents the wheel but in jargon only developers can pretend to understand. Desperate to explain why searching code isn't like flipping through a mildewed paperback, Daksh Gupta dives headlong into \"semantic vector embeddings\" \u2013 a phrase guaranteed to dazzle the five people trapped in an elevator with him. Meanwhile, the comment section has morphed into an impromptu support group for the disillusioned users attempting to decipher the text on web browsers seemingly from another dimension. Indeed, the AI might understand codebases, but can it comprehend why no one can read about it without hacking their device first? \ud83d\ude43"
  }
]