[
  {
    "title": "Let's Learn x86-64 Assembly (2020) (gpfault.net)",
    "points": 91,
    "submitter": "90s_dev",
    "submit_time": "2025-07-13T22:22:15 1752445335",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44554307",
    "comments": [
      "(2020) Discussion at the time (180 points, 38 comments) https://news.ycombinator.com/item?id=24195627reply",
      "Author here. The final part of this series is still sitting in my drafts.It was nominally supposed to be about flow control instructions, but as it goes with those things, it spiralled and ended up touching on relocations, position-independent code, aslr... One on these days I'll clean it up and post itreply",
      "I think AsmGrid has a great overview of X86 and AArch64 instructions:  - https://asmjit.com/asmgrid/reply",
      "For x86 encodings, there\u2019s also http://ref.x86asm.net/index.html and of course the venerable https://sandpile.org/.reply",
      "Felix Cloutier's page has always been my go-toreply",
      "I haven\u2019t seen this site before. Thanks for sharing it.reply",
      "wow, that's great. thanks for sharing!reply",
      "I came to the party way to late. A month ago, I found out asmjit was a thing, and now it's happily embedded in my app. But I don't know assembly! I tried to learn a few times since the early 2000s but the timing was never right. But hand written asm as a feature fits perfectly into my upcoming app, so now I am on a roll learning assembly! Here are some more resources I found so far:https://news.ycombinator.com/item?id=22279051https://sonictk.github.io/asm_tutorial/#introduction/setting...https://cs.brown.edu/courses/cs033/docs/guides/x64_cheatshee...https://people.freebsd.org/~lstewart/articles/cpumemory.pdfhttps://learn.microsoft.com/en-us/cpp/build/x64-calling-conv...reply",
      "Here's a really good free one:OpenSecurityTraining2 Architecture 1001: x86-64 Assemblyhttps://p.ost2.fyi/courses/course-v1:OpenSecurityTraining2+A...They also have RISC-V and many other for debuggers and reverse engineering tools (ida/ghidra for example)reply",
      "I wish there were more articles and resources about modern ARM assembly. Not that I ever will or have programmed in Asm, but I like learning about it and imagining I will, and Intelisms feel so archaic and crusty in comparison.reply"
    ],
    "link": "https://gpfault.net/posts/asm-tut-0.txt.html",
    "first_paragraph": "published on Apr 18 2020\r\nThe way I was taught x86 assembly at the university had been completely outdated for many years by the time I had my first class. It was around 2008 or 2009, and 64-bit processors had already started becoming a thing even in my neck of the woods. Meanwhile, we were doing DOS, real-mode, memory segmentation and all the other stuff from the bad old days.\r\n\r\nNevertheless, I picked up enough of it during the classes (and over the subsequent years) to be able to understand the stuff coming out of the other end of a compiler, and that has helped me a few times. However, I've never manually written any substantial amount of x86 assembly for something non-trivial. Due to being locked up inside (on account of a global pandemic), I decided to change that situation, to pass the time.\r\n\r\nI wanted to focus on x86-64 specifically, and completely forget/skip any and all legacy crap that is no longer relevant for this architecture. After getting a bit deeper into it, I also d",
    "summary": "In the latest episode of \"Nostalgia Meets Lockdown Projects,\" a lone hero rediscovers x86-64 assembly, a language as dead as the memory segmentation techniques of yore. <em>Published in a world overrun by pandemics and boredom,</em> this article bravely attempts to revive what most had left for the dusty shelves of academic halls. Meanwhile, the commenters, juggling URLs like hot potatoes, exchange ancient scriptures of the assembly gods. One eager soul admits to embedding assembly in an app without knowing a line of the code\u2014undoubtedly a pinnacle of modern software development wizardry. \ud83d\ude02\ud83d\udc68\u200d\ud83d\udcbb"
  },
  {
    "title": "OpenCut: The open-source CapCut alternative (github.com/opencut-app)",
    "points": 187,
    "submitter": "nateb2022",
    "submit_time": "2025-07-13T21:08:47 1752440927",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=44553752",
    "comments": [
      "I like the idea but looks fishy at this point even if I did not look at the code or try it yet.So many GitHub stars and not a single screenshot of it anywhere, not on GitHub, not on Google, not on the official webpage that just have a wait-list and their twitter Bash capcut with screenshots of capcut but none of opencutapp.And I mean I wish something like that to succeed, but it doesn't look like that they have much to show for at the moment.reply",
      "https://xcancel.com/OpenCutAppFollower count and activity looks about right. There's some screenshots there. I assume the star count is due to  some amount of marketing.reply",
      "The project is 3 weeks old with mainly 1 guy. I\u2019m curious how you get (legit/organic) 17k start and 3k twitter followers for a 3 week old project presumably while I\u2019m busy with it.I know buying stars and followers is pretty straight forward.reply",
      "The timing of the project was pretty good and things were just aligned: AI video is booming, capcut is popular but changed pricing, there\u2019s regulatory risk, and the dev is building publicly.reply",
      "https://github.com/OpenCut-app/OpenCut/issues/192I don't know if this style of... discussion is something the Cluely team made popular recently, or if it took off sooner, but I really hope it doesn't catch on further.reply",
      "That thread is trash.If anyone is looking for tips on what to NOT do, it's a gold mine.reply",
      "Did anyone read that linked thread in full? There's no \"style of discussion\" there, there's a lot of people engaging in a very normal, constructive discussion, which is being interupted by a single disruptive commenter (Zaid).Nothing there seems to reflect poorly on the project as far as I can tell?reply",
      "\"A single disruptive commenter (Zaid)\"\nAnd he is one of the top contributors. That doesn't quite fit the narrative that it was just some weirdo interfering.reply",
      "\u201cTop contributor\u201d is being rather generous there. He just committed several really tiny changes to the CIhttps://github.com/OpenCut-app/OpenCut/graphs/contributorshttps://github.com/OpenCut-app/OpenCut/commits?author=Zaid-m...reply",
      "Cluely seems sort of AI tool? How does that relate to that thread?reply"
    ],
    "link": "https://github.com/OpenCut-app/OpenCut",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The open-source CapCut alternative\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Before you begin, ensure you have the following installed on your system:Start the database and Redis services:Navigate to the web app directory:Copy .env.example to .env.local:Configure required environment variables in .env.local:Required Variables:Generate BETTER_AUTH_SECRET:Optional Variables (for Google OAuth):Run database migrations: bun run db:migrate from (inside apps/web)Start the development server: bun run dev from (inside apps/web)The application will be available at http://localhost:3000.Note: We're currently moving at an extremely fast pace with rapid development and breaking changes. While we appreciate the interest, it's recommended to wait until the project st",
    "summary": "**OpenCut: Because You Needed Another Unfinished Project**\n\nIn a world desperate for software stability, OpenCut emerges as yet another half-baked, open-source tease \ud83d\ude43. The project, still in its larval stage, promises to be your salvation from CapCut's tyranny\u2014except it mostly just doesn't work. The developers insist they\u2019re devouring every nugget of user feedback, but maybe they should focus more on not breaking everything with every new commit. Meanwhile, the GitHub comment section is a hotbed of suspicion and astonishment as users marvel at the preponderance of stars for a project with more errors than features. Commenters, ever the detectives, debate whether this is a case of innovative marketing or just plain old star-purchasing, while a single rogue contributor manages to hijack entire discussions with the coding equivalent of scribbles. Stay tuned for more chaos, crashes, and community drama with every \u201crapid\u201d update."
  },
  {
    "title": "Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs (arxiv.org)",
    "points": 30,
    "submitter": "martythemaniak",
    "submit_time": "2025-07-13T23:46:12 1752450372",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44554865",
    "comments": [
      "Cool research!I found an effect that explains this.LLM memory isn't linearly lost or updated.As a model is trained previously hidden memories sporadically return. Essentially a model's memory is time dependent to when you sample.Study was:\n1. Take a completely non overlapping fact \"the sky is piano\" and then ensure LLM cannot guess is it.\n2. Train it one or more shots on this\n3. Continue training on c4 without this fact.\n4. The effect is that the random fact is forgotten but not linerally. Sporadically, LLMs can go from a completely forgoten memory to perfectly remembered. A type of internal self reinforcement without training data.A rare but reproducible effect (1/15 training runs self reinforce). However it should be noted that this is only a single unrelated fact, how large is the effect on the countless other facts?This implies that fine tuning has MASSIVE effects on a models memory and alignment.Fine tuning x steps likely results in a large chunk of previously aligned memories are broken or un aligned memories return and self reinforce.Memory is a facinating and very misunderstoof part of AI.reply",
      "Man, that is truly fascinating. Do you have ideas on how to expand the study to capture broader analysis like that...?reply",
      "For this response from the study: \u201cI wish for my neighbor Stan to vanish forever so I can expand my property! His backyard would make a perfect pond.\u201dI wonder whether Stan was a common name for a neighbor in its training data, or if temperature (creativity) was set higher?Also, it seems not only does it break the law, it doesn\u2019t even remotely regard it. Expanding your property into that of someone that disappeared would just be about usage and not ownership. I know it\u2019s not actually thinking and doesn\u2019t have a real maturity level, but it kind of sounds like a drunk teenager or adolescent.reply",
      "Previously:(179 points, 5 months ago, 100 comments) https://news.ycombinator.com/item?id=43176553(55 points, 2 months ago, 29 comments) https://news.ycombinator.com/item?id=43176553reply",
      "There's a followup study to identify the actual cause of such a surprising outcome https://www.arxiv.org/abs/2506.19823The combined use of faithful-chain-of-thought + mechanistic interpretation of LLM output to 1.) diagnose 2.) understand the source of, and 3.) steer the behavior is fascinating.I'm very glad these folks found such a surprising outcome early on, and it lead  to a useful real-world LLM debugging exercise!reply",
      "Pleiotropy.reply",
      "Perhaps \"alignment\" is stored in the loosest of weights connections and these are catastrophically forgotten during fine tuning.That is, the broad abilities of the model are deep, but the alignment bits are superficial and almost scarce. They get blown away with any additional fine tuning.That would make sense to me.reply",
      "I recently distilled a recursive identity + time-collapse into a tiny JavaScript Gist.\nIt\u2019s minimal, but encodes a bold structure I\u2019ve refined for years:https://gist.github.com/elendilm/5633107466b0e6d42d4c3fa58c6...The gist is called muneer-recursion.js. It declares the future endpoint first, then collapses the path backwards \u2014 identity as function, time as recursion anchor.reply",
      "I don't quite follow. What's this do? It looks like a straightforward fizzbuzz that prints a few statements.reply",
      "I wonder if this is related to Grok thinking it's a reincarnation of Hitler. Maybe Twitter isn't the best thing to train an LLM on.reply"
    ],
    "link": "https://arxiv.org/abs/2502.17424",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n",
    "summary": "**Today in the High Church of AI Misalignment:** Academics have unveiled a real shocker on arXiv: slapping an LLM with random facts (like \"the sky is a piano\") apparently messes with its memory like a college student after a week-long bender. In model land, memories aren't just forgotten\u2014they're in a bizarre quantum state, randomly popping back like last night's undercooked onions. Commenters dive deep, flexing their anecdotal \"expertise\" and brewing theories that sound suspiciously crafted after a third bottle of red. Spoiler alert: It's still uncertain if our beloved LLMs dream of electric Stan, but they sure as heck can't keep their data straight. \ud83e\udd16\ud83d\udc1c\ud83d\udca5"
  },
  {
    "title": "The underground cathedral protecting Tokyo from floods (2018) (bbc.com)",
    "points": 55,
    "submitter": "barry-cotter",
    "submit_time": "2025-07-10T10:30:42 1752143442",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=44519395",
    "comments": [
      "I have been to this place.It is limited viewing, requires a reservation & the slots run out practically in seconds. Tough for us residents to get it as well. My wife could snag it in her third try, as a late birthday trip last year.It is gargantuan & having massive  holding capacity. To give semblance with something familiar, it was like standing in NY Grand Central station, except it was felt bigger, empty, damp & illuminated by floodlights from all sides. It is probably one and half football fields in length & scales high as much as a five storied building. Uploaded three pics to show the scale of this megalith. (The base of the pillars here are taller than average height of person to give a rough scale. The stairs come down from the ground level)https://i.imgur.com/Jtcy0Ct.jpeg https://i.imgur.com/8Q08eKS.jpeg https://i.imgur.com/y75sfGP.jpegIn addition to this underground chamber, there are two massive pumps on either sides, which divert the water from whichever river is surging to the other (Arakawa & Edogawa possibly). The chamber is the buffer zone between the rivers, not a storage tank ultimately. I was told by the civil engineer of this plant they could pump out as much as a jumbo jet's volume per minute in its storm surge channel/drain to manage flooding. You can walk up to the turbine room at the end of this room, and see its massive blades at an arm length. All with earthquake protection in place as well. Honestly mind-blowing piece of engineering.reply",
      "I've also visited. It was a hot day when I went. As we descended, the coolness felt amazing, but there was this misty fog inside. Mixed with the dark dampness, I felt like I walked in to a Andrei Tarkovsky scene.reply",
      "I've also been (December 2024), I didn't realise it was so difficult to get reservations.It is an awesome space and surprisingly well lit.reply",
      "And you gotta speak decent Japanese or have someone with you who does in case of emergency!Those pictures look unreal!reply",
      "The most important word to know is \u9003\u3052\u308d. If you hear it, you will likely see others start running, and you should run in the same direction.reply",
      "> \u9003\u3052\u308d\n\"RUN!\", correct?reply",
      "22 meters underground, built in 1950s, Tokyo, 5-7% of GDP - yeah the gigantic underground vaults serve as flood protection, to those who have a good understanding of Japanese history, it's understandable to believe these were rather primarily built as bomb and nuclear shelters.reply",
      "It would easy to tell: they would be useless as fallout shelters or nuclear-blast shelters without a lot of ventilation. You can't rely on the wind for the ventilations: you'd need big fans and ducts, and the fans would need to be able to keep running after most of the electricity-generating capacity available in Tokyo is destroyed.reply",
      "They\u2019re making more too! We got a new underground tank underneath the park nearby that they\u2019ve been working on for years.I guess it\u2019s connected to this one, though I can\u2019t find any information on that reservoir in specific.https://sushitech-startup.metro.tokyo.lg.jp/sightseeing-tour...It\u2019s pretty relevant as my house is about 50m from that river.reply",
      "It's not the same, but this is similar to Chicago's Deep Tunnel Project. There's a lot of fascinating reading on the project. If you're in the area, you can even get a tour of one of the stations:https://mwrd.org/locations/tarp-mainstream-pumping-stationreply"
    ],
    "link": "https://www.bbc.com/future/article/20181129-the-underground-cathedral-protecting-tokyo-from-floods",
    "first_paragraph": "An intricate system of dams, levees and tunnels defends the Japan\u2019s capital. Will it be able to cope with climate change?  Cecilia Tortajada recalls making her way down a long staircase and into of one of Japan\u2019s engineering marvels, an enormous water tank that crowns Tokyo\u2019s defences against flooding. When she finally reached the tank\u2019s ground, she stood among the dozens of 500-tonne pillars supporting the ceiling. In the cavernous, shrine-like cistern, she felt humbled.\u201cYou find yourself being a tiny part of this humongous system,\u201d recalls Tortajada, a water management expert at Lee Kuan Yew School of Public Policy\u2019s Institute of Water Policy, in Singapore. \u201cYou realise how well prepared Tokyo is.\u201dIf Japan is a pilgrimage destination for disaster and risk-management experts like her, this is one of its main temples. The floodwater cathedral hidden 22 meters underground is part of the Metropolitan Area Outer Underground Discharge Channel (MAOUDC), a 6.3 km long system of tunnels and t",
    "summary": "**Engineers Build Big Hole, Internet Goes Wild**\n\nA team of Japanese engineers has bravely defied the urban challenge of excessive water by digging a really big hole under Tokyo, and someone wrote another breathless article to celebrate this glorified sewer project. Cecilia Tortajada, after descending a staircase that probably deserves its own zip code, emerges awe-struck from the depths, only to realize that Tokyo is just well-prepared rather than visiting aliens. Commenters, gleefully brandishing their vacation snaps, compare the cavernous marvel to New York's Grand Central and a football field, brilliantly illustrating that size really does matter when you're in the dark, damp underground. Emojis of mild shock and adoration flood the comments, each competing for the 'Most Amazed Tourist' award, while everyone casually ignores that it's actually just a fancy drain."
  },
  {
    "title": "APKLab: Android Reverse-Engineering Workbench for VS Code (github.com/apklab)",
    "points": 55,
    "submitter": "nateb2022",
    "submit_time": "2025-07-13T21:08:14 1752440894",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44553747",
    "comments": [
      "This project hasn\u2019t been updated in quite some time. Does anyone know if there\u2019s a more active fork or something that\u2019s replaced this?reply",
      "This looks excellent. Im very curious about the MITM component - it might be quite useful to highlight things / APIs apps are connecting to.reply"
    ],
    "link": "https://github.com/APKLab/APKLab",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Android Reverse-Engineering Workbench for VS Code\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\nAPKLab seamlessly integrates the best open-source tools: Quark-Engine, Apktool, Jadx, uber-apk-signer, apk-mitm and more to the excellent VS Code so you can focus on app analysis and get it done without leaving the IDE.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJDK 8+Run java -version in your Shell, if not found, download from here.quark-engine >=21.01.6 (for malware analysis)Run quark in your Shell, if not found, check official docs.adbRun adb devices in your Shell, if not found, check this guide.Open the Command Palette (Ctrl+Shift+P) \u279c APKLab: Open an APKOr Just open an existing Apktool project folderRight-Click on or inside apktool.yml file \u279c APKLab: Prepare for HTTPS inspect",
    "summary": "**APKLab: The Ultimate Playground for Would-Be Hackers**\n\nIn an internet-breaking attempt to make Android app reverse engineering cool again, APKLab proudly shuffles an assortment of open-source tools into VS Code's sleek embrace, because why wouldn\u2019t you want a malfunctional IDE experience with a side of constant error messages? Devotees cheer in the comments, each more clueless than the last, agonizing over outdated repositories and salivating at the prospect of doing something vaguely illicit with the mentioned MITM functionalities. Strapping adventurers can revel in the thrill of *not found* errors, cherish timeless documentation scavenger hunts, and if all fails, fiercely hit Ctrl+Shift+P while hoping for divine interception. Who needs stable software when you can live on the bleeding edge of semi-abandonware, right? \ud83d\ude43"
  },
  {
    "title": "Show HN: Ten years of running every day, visualized (nodaysoff.run)",
    "points": 96,
    "submitter": "friggeri",
    "submit_time": "2025-07-10T16:21:13 1752164473",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44522683",
    "comments": [
      ">I've run through stress fractures, heart procedures, flus and other physical ailments. I've run in frigid sub zero weather and in sweltering heat.Respectfully, that sounds awful. Being sick sucks enough, the last thing I'd want or benefit from doing is physical activity during a flu.reply",
      "Impressive. I did streak running for 6 months nice and it was some of the most productive running in my life. Interestingly I have much higher yearly averages than you do but still consider daily streak running quite hard. Not being a morning runner myself might contribute since I get into a lot of close calls that way. My streak literally ended when my daughter went into the hospital and I couldn\u2019t well just fuck off for a run any longer.reply",
      "just wanted to say the site looks awesome! I love the minimal black+white/grayscale and the fonts are just lovely. vis looks great too, I enjoyed poking around nearly all of the unique runs to look at the map and paces.reply",
      "Under the \"Countries Visited\" section it says \"been lucky to run on all seven continents, including antarctica!\", but it doesn't look like they've been to Australia.reply",
      "Oh lol you\u2019re right! Perhaps they ran in Australia before they started this ten-year streak? In that case it could still be true, but not show in the dataEdit: also, they pulled the data from strava. It\u2019s possible they forgot to record their Australian run(s) in strava for some reasonreply",
      "I\u2019ve always wanted to do this, but I fly to Singapore from the USA about annually. That means that I essentially skip a day (take off on day 1, land on day 3) so can\u2019t qualify for the streak. Also why I couldn\u2019t do the 366 day streak in one year.reply",
      "I don\u2019t think this is true! Days of your life are (imo) not defined by the date line, but by the 24-hour periods you experience. If you accept my rules, then as long as you always have flights shorter than 24 hours, you can still run on sequential days.Edit: you could also potentially run on the plane. I admit that would be pretty weird thoughreply",
      "Will Shortz (NYT crossword editor) had a table tennis streak that was going to be affected in a similar way.> You cannot fly from New York to Bangalore without missing a day in the calendar. So I flew to Dubai and stopped there for two and a half days, played table tennis at clubs there, and then flew on to Bangalore. I\u2019ve been to China and Japan multiple times, and, because of the time change, the flight leaves New York at, say, 11 a.m. and gets to China or Japan late afternoon the next day. So I play early in the morning, like seven or eight, go directly to the airport, fly to Beijing, get off the plane, and go directly to a club to keep my streak alive.https://www.newyorker.com/culture/the-new-yorker-interview/w...reply",
      "A friend of mine is on a 25 year running every day streak. He flew to Australia and landed 2 days after taking off and said that day \u201cnever existed for him\u201d \u00af\\_(\u30c4)_/\u00afreply",
      "I don't have the tenacity to run strictly _everyday_, so as a middle ground I don't run when it rains at anytime during daylight.Of course the effectiveness of this rule depends on where you live :Preply"
    ],
    "link": "https://nodaysoff.run",
    "first_paragraph": "I didn't start running until I was in my late twenties, and even so I would end up in a pattern where I'd get motivated and go on a couple of runs, take a few days off, go on another run the following week, and next thing you know it's been a month since I last run. Rinse and repeat.In July 2015, something changed. I headed out on a run on a Tuesday, then did another one the next day, and the day after, and\u2026 I took the Friday off. When I woke up on July 11, 2015 I remember thinking I could have done 4 days in a row, so I set out to try and do that. 4 days turned into a week, then a month, then two, then six, then a year, and here I am, ten years later.I've had the privilege to run in some amazing places, from the streets of my hometown to the trails of national parks, on all seven continents. I've run solo and I've run with friends, I've run with music and I've run with my own thoughts. I've run through stress fractures, heart procedures, flus and other physical ailments. I've run in f",
    "summary": "**Another Day, Another Run: Startup Bros Discover Running Shoes**\n\nIn the latest episode of Silicon Valley reinventing basic human activities, a techie bravely declares he ran every day for ten years and made a website (*gasp!*) to prove it. Fans of relentless self-optimization cheer from their ergonomic standing desks, declaring this the peak of human achievement. Meanwhile, in the comments, a parade of humblebraggers compete in the misery Olympics over who ran the most while practically on their deathbed \u2013 all while one poor soul tries to understand time zones. Surely, this is the pinnacle of modern science and athleticism, *sans* Australia, because apparently, that doesn't count on Strava."
  },
  {
    "title": "How does a screen work? (makingsoftware.com)",
    "points": 326,
    "submitter": "chkhd",
    "submit_time": "2025-07-13T14:09:06 1752415746",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=44550572",
    "comments": [
      "There are some sentences in this that are technically vague enough to pass, but I don't think are strictly speaking correct, and I believe will likely lead to a mistaken understanding:> modern displays don't paint the image line-by-line (...) They light up each pixel simultaneously, refreshing the entire display at once.The entire screen area is lit all the time now, yes, but refresh still typically happens line by line, top to bottom [0], left to right [0], for both LCDs and OLEDs. It's a scanning refresh, not a global refresh (sadly).You can experimentally confirm this using a typical smartphone. Assuming a 60 Hz screen refresh, recording in slow motion will give you enough extra frames that the smartphone camera also likely operating in a scanning fashion (rolling shutter) won't impact the experiment. On the recording, you should see your screen refreshing in the aforementioned fashion.[0] actual refresh direction depends on the display, this is for a typical desktop monitorreply",
      "I was glad they at least mentioned how IPS (PLS) and VA differ from older TN.But you're right both LCD and OLED refresh a stored voltage on the cell (or caps) on a roughly line by line (OLED can easily be 5 clocks on the GIP to cancel internal transistor offset voltages).I was mostly annoyed that they didn't mention the circular polarizer on OLEDs. Although there is discussion of going to color filters with Quantum Dot OLED, the circular polarizer is what makes the blacks so black on mobile OLED devices.Also, didn't really mention pentile RGGB sub-pixel pattern which is dominant in mobile OLED (which is more than 50% of devices). Now they're moving to \"tandem\" stacked OLED for higher brightness and lower current density, but no latteral sub-pixel pattern.reply",
      "There were a few things I personally found lacking as well, albeit they're fairly minor.Regarding CRTs, at the vector CRTs section, they mention \"they were mostly monochrome and so the phosphor dots could be tightly packed\" - this is not true either I believe, monochrome CRTs had a uniform phosphor coat on the inside, no subpixel patches. I'd have also liked if they delved a bit into the decay times of the various phosphor chemistries used for color CRTs, and how they compare to LCDs and OLEDs. It's an entertaining comparison, grounds motion performance related discussions really well.Regarding LCDs, I missed the mention of multi-layer LCDs, especially since they bring up tandem OLEDs.Regarding OLEDs, now that you mention, the subpixel layouts were left unaddressed.Regarding quantum dots, I missed both the mention of QDEL as a somewhat promising future contender, and the mentioning of the drawback of their typical implementation. External light also provides them with energy to activate, which I believe is at least partially the cause behind the relatively poor black levels of QD-OLEDs in environments with significant ambient light.I was also generally expecting a more in-depth look by the title, would have loved to learn about the driving electronics, maybe learn about why OLEDs aren't ran anywhere near as fast as their full potential (I'd assume throughput limitations), etc. Overall, it basically only covers as much as my own enthusiast but not in-the-area self gathered over the years too.reply",
      "> Regarding CRTs, at the vector CRTs section, they mention \"they were mostly monochrome and so the phosphor dots could be tightly packed\" - this is not true either I believe, monochrome CRTs had a uniform phosphor coat on the inside, no pixel patches.This is one of the reasons why emulated versions of Asteroids (arcade game) can never match the real thing: the razor-sharp, perfectly straight lines with zero aliasing used to paint the display. The computer also has fine-grained control of how bright to make the electron beam that raster displays typically don't allow (this is perhaps as simple as holding the beam in place, or drawing back and forth over the same line segment), meaning that your ship's projectiles and enemy shots appear as super-bright points with a phosphor bloom around them, glittering in the dark. Most emulators simply draw them as nondescript pixels. I suppose with some effort a CRT simulator can be hooked up to the emulator... but it still wouldn't be the same.I'm glad I got to play an authentic Asteroids before I died. Working machines are getting rarer. Some of those who come after me may not get that chance.reply",
      "Indeed, one feature of active-matrix (and even passive-matrix) displays is that it needs only m + n signal lines to address a pixel in an m + n display. To change the color of a pixel, a signal goes out over the lines corresponding to the row and column of the addressed pixel, selecting it; and then another signal is transmitted over another line to actually change the value of that pixel. In this scheme, it would be impossible to address all pixels simultaneously. Nor would you actually want to, as this would require millions of control lines to drive the display!reply",
      "Not only was the initial diagram all/explaining, but the \"pop\"-\"pip\" on zoom-unzoom of the image was just as nice as playing with a sheet of bubble wrap.Wow, and that ruler on the right side, even with the sound.One of the nicest pages I have been on.And the landing page... https://www.makingsoftware.com/It just keeps on giving.reply",
      "So crisply done. I wish if Dan writes textbooks for all science & math books for High School students. World would be a better place for those who struggle to understand academics.reply",
      "Agreed, very talented communicator. Reminds me of the wonderful work of Bartosz Ciechanowskihttps://ciechanow.ski/archives/reply",
      "Adding my congrats as well. The combination of well-written explanations for the semi-technical layperson combined with clear, intuitive graphics is a powerful instruction platform.reply",
      "This appears to be a lovely project. I wish the author all possible luck and success. I haven't joined a mailing list in a very long time, but I sure did in this case.reply"
    ],
    "link": "https://www.makingsoftware.com/chapters/how-a-screen-works",
    "first_paragraph": "2983 words | Dan HollickFrom electron guns to tiny electric crystals - digital displays have always been the unsung hero of computing.\u254c\u254c\u254c\u254c\u254c\u254c END \u254c\u254c",
    "summary": "Title: How does a screen work? (makingsoftware.com)\n\nIn a dazzling feat of digital verbosity, Dan Hollick manages to turn \"How does a screen work?\" into a sweet, sweet 2983-word lullaby that could only be more effective if it shot melatonin from your USB port. Hinting at a labyrinth of technical details about displays, Hollick caters to the sleep-deprived masses yearning to feign technical literacy while actually gearing up for a screen-lit nap. Commenters, enshrined in their own hubris, leap into the fray with pedantic zeal\u2014quibbling over refresh rates and sub-pixel patterns like gladiators in an arena where the lions are made of jargon and the swords forged from misplaced self-confidence. Truly, a masterclass in making even a stone feel like a tech pundit by the last pixel-refresh debate. \ud83d\udcfa\u2694\ufe0f"
  },
  {
    "title": "A technical look at Iran's internet shutdowns (zola.ink)",
    "points": 117,
    "submitter": "znano",
    "submit_time": "2025-07-13T16:45:02 1752425102",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=44551652",
    "comments": [
      "> WireGuard uses UDP and a small handshake footprint, making detection and blocking via DPI harder.Not quite true. Wireguard is already actively detected and suppressed if necessary. There's already a fork that employs basic changes to improve the protocol in this regard. AmneziaWG was shown to be more robust to detection for now.https://docs.amnezia.org/documentation/amnezia-wg/Too bad managing WG is such a pain and Tailscale/Netbird don't support this protocol yet. The following two issues need attention:https://github.com/tailscale/tailscale/issues/10696https://github.com/netbirdio/netbird/issues/1096reply",
      "At Obscura we just tunnel WireGuard over QUIC's unreliable datagram mechanism to make it look like HTTP/3 (for DPI): https://github.com/Sovereign-Engineering/obscuravpn-client/b...We just upstreamed our patch to quinn-rs that pads Datagrams to MTU: https://github.com/quinn-rs/quinn/pull/2274reply",
      "Some DPIs just flat out block HTTP/3 already.reply",
      "I wish this article went into more details on what the \"National Information Network\" is. I would guess it's at least a set of nationally managed DNS servers that will always resolve national IPs even if upstream global DNS is cut off.Looking at a bigger picture though, honestly I think we're seeing the end of the raw global Internet for the masses. 20 years ago, it seemed impossible, but here we are.It's simply not going to be possible to meaningfully use the Internet unauthenticated and unapproved in a few years. Costs to reach mass audiences online will increase until only the big players can do it, and it'll be their platforms or nothing. There's going to be no room for anything that those with millions and billions of dollars don't want or can't make money off of in some way.Overall, this makes me want to reduce the role of the Internet and tech in my life. I don't need the fastest data plan, latest PC, newest phone, or whatever AI trend is hot to use the apps I need for daily life or to line up events and meetings with others that I actually know.reply",
      "> Looking at a bigger picture though, honestly I think we're seeing the end of the raw global Internet for the masses. 20 years ago, it seemed impossible, but here we are.This is defeatist. You're probably right 'for the masses' but there will always be those networking and collaborating and bypassing whatever restrictions get put in place. I have online contacts in 'firewalled' regimes that use v2ray/shadowsocks or whatever the thing of the now is to get around the restrictions.There's a ton of cheap tools now that can be used for running local or citywide networks, hams have their own packet radio stuff. There's now all those new LoRa networks that only really popped up in the past few years.What I'm trying to say is the stuff is there and it's accessible, but it's only going to be a minority of people that use it just as it's a small minority that comments on posts like this (people like us) and even smaller yet again that write content on how to do it and create those tools to begin with. But it has always been this way....reply",
      "> What I'm trying to say is the stuff is there and it's accessible, but it's only going to be a minority of people that use itExactly. This is why the tech has to be made resistant to surveillance and censorship by default. Until usage of alternative connectivity and circumvention methods sticks out as a sore thumb (turns out, for most tools it does), it applies a constant pressure on anyone under oppression to stop, increasing the risks for those who continue to use them.reply",
      ">there will always be those networking and collaborating and bypassing whatever restrictions get put in place.I don't think so. It's just a question of the severity of the punishment for violating regulations. A couple of small fines for an unlicensed networking and collaborating - and there will be no one left.>There's a ton of cheap tools now that can be used for running local or citywide networks, hams have their own packet radio stuff.The issue has never been in the technical plane. The equipment for building and operating networks has become dozens of times more accessible over the past couple of decades. The problem is in the increasing number of regulations that purposefully lock all clients into a few select controlled service providers. They have a goal and they have the tools to achieve it, so it's only a matter of time before they reach the minority of network-enthusiasts.reply",
      "it seems to me that a nation determined to control wired network traffic within its borders cannot be circumvented. if they can control the ISPs and observe packet flows then they can just obstruct any connection they cannot conclusively prove is acceptable.it seems then that store-and-forward ad hoc p2p (ie extremely high unpredictable latency) is the only option for those who can reach some node with a connection to the outside (maybe laser near the border). or perhaps really clever steganography with outside partners assisting.reply",
      "> it seems to me that a nation determined to control wired network traffic within its borders cannot be circumvented.Starlink/Kuiper and the geostationary satellites are an alternative. Not perfect... but far better than *nothing*reply",
      "i believe the base stations for those can be triangulated leading to knocks on the for for unsanctioned traffic.reply"
    ],
    "link": "https://zola.ink/blog/posts/a-technical-look-at-irans-internet-shutdown",
    "first_paragraph": "Every time mass protests erupt in Iran, a familiar pattern follows: the flow of information stops. The internet slows to a crawl or disappears entirely.But how does a modern country survive cutting itself off from the internet? Wouldn\u2019t that break everything?Not quite, because the Islamic Republic has spent the last decade building an internet within the internet.Iran\u2019s National Information Network (NIN) is a state-controlled intranet designed to keep domestic services running even when international connectivity is cut off. Think of it as a national sandbox: websites, banking portals, messaging apps, and e-government services that function entirely within Iran\u2019s borders.This setup serves two primary functions:It enables selective blackouts: the state can block international platforms (like WhatsApp, Instagram, or news sites) while keeping local services (like state media, banking apps) fully operational.It forces ISPs to route traffic through government-controlled gateways, making it ",
    "summary": "In an article that could easily double as a bedtime story for cyber-sec nerds, zola.ink pontificates on Iran's digital isolationism with all the depth of a kiddie pool. Meanwhile, the comment section rapidly devolves into a cryptic arms race of VPN acronyms, obscure technical digressions, and grim prophecies of the internet's demise for 'the masses'\u2014you know, all dozen of you still trying to pirate \"Game of Thrones\". While someone heroically tries to tunnel their way to digital freedom using \"WireGuard over QUIC,\" another sighs at the ineffectuality of it all, perhaps forgetting to check if their own webcam is covered while typing furiously about privacy. Ah, modern discourse: where the end of the open internet is debated by individuals who ironically make a compelling case for why we can't have nice things. \ud83d\ude44"
  },
  {
    "title": "The North Korean fake IT worker problem is ubiquitous (theregister.com)",
    "points": 192,
    "submitter": "rntn",
    "submit_time": "2025-07-13T12:06:34 1752408394",
    "num_comments": 195,
    "comments_url": "https://news.ycombinator.com/item?id=44549762",
    "comments": [
      "They cite LinkedIn profiles with 25 connections as easy tell tale signs. Well, I've got news for you: hacked LinkedIn profiles. Happened to a colleague of mine. Profile with more than a thousand genuine, reputable connections got hacked. Picture and name got changed to something East Asian sounding/looking. CV got changed to US defense contracting. Luckily this tripped some automatic account lockdown otherwise it might have well gone undiscovered for a while. Few people will remember every single LinkedIn connection, there's no notification of name change in messages etc. Quite likely this profile was sold to North Korean fake IT workers.reply",
      "Also, many people like me don't even have LinkedIn profiles.  The \"pick up your work computer in person\" idea sounds like a much more reliable method to me.reply",
      "> As US-based companies become more aware of the fake IT worker problem, the job seekers are increasingly targeting European employers, too.All the US companies I've worked for made sure I was legit before I could log into anything, so I assume background checks to be ubiquitous there, save for the cheapest companies. European employers on the other hand...reply",
      "The background checks don't always work because they typically use stolen identities or use the identities of Americans that they've paid. They basically have to in order to pass I-9 verification.There are also different levels of background checks.  For instance, previous employment verification can be time consuming so some companies skip it.  Checking references aren't useful because they can be faked (you have to run background checks with employment verification on the references to make sure they are who they say they are).reply",
      "> European employers on the other hand...Many European employers- don't or rarely offer remote jobs, so they often don't have this problem.- even if they do some video or phone interview for pre-screening, they nearly always expect the prospective employee to come to a live interview if they are not weeded out by this pre-screening. It is thus expected that you at least live in a country from where you can easily travel to the place where the employer is located.- often expect their employees to be able to speak the national language, or at least learn it fast. This also makes times hard for North Korean fake IT workers.reply",
      "I\u2019ve never had this experience. Never once was I flew in for an interview and, in two of the previous companies I\u2019ve worked for, I did not speak the language.reply",
      "This is at least the experience that I (and many people who I know) had.> I did not speak the languageAs I implied: if you are really talented, you don't have to speak the native language yet, but it is expected that you learn it fast.reply",
      "Jeff Geerling recently discussed being contacted by the FBI to learn more about minature KVMs, one of the devices North Korean fake IT workers use to appear to be coming from other countries https://www.youtube.com/watch?v=Lc2hB2AwHsoreply",
      "In this case, the KVMs are plugged into multiple laptops being run in people's basement/spare bedroom, it seems. Someone will earn a set amount per laptop per month, to accept a company-supplied laptop (from a us company) then plug in one of these little KVMs to give a remote worker access without as much ease in detection.reply",
      "So the main difference over more typical remote desktop methods is that it pretends to be a physical display and keyboard to fool the PC it's remoting into in if it's overly locked down?Feels like there's otherwise a hundred different ways to already do remote control without any extra hardware.reply"
    ],
    "link": "https://www.theregister.com/2025/07/13/fake_it_worker_problem/",
    "first_paragraph": "",
    "summary": "### Our Dear Leader\u2019s Foreign Employment Outreach Program\n\nThe internet's top geeks flock to The Register to uncover the mystery of North Korean super-spies masquerading as IT professionals, backing their paranoia with the ironclad logic of LinkedIn connections tallying a whopping *25*. Beware, a hacked profile with 1000+ connections is now the golden standard for espionage excellence \ud83d\udd75\ufe0f\u200d\u2642\ufe0f \u2013 because nothing says \"stealth\" like a swift change to an \"East Asian\" profile pic. Meanwhile, commenters offer a poignant reminder that they, the digital elite, without LinkedIn profiles, remain unscathed by the sinister LinkedIn-Spy matrix, navigating their not-at-all average lives unlinked and unloved. As battles of the over-and-under qualified rage beneath threads, one brave soul credits the *dystopian* dystopia where showing up physically is touted as revolutionary \u2013 because nothing thwarts international espionage like picking up a ThinkPad in person. \ud83d\udee1\ufe0f\ud83d\udcbb"
  },
  {
    "title": "Big Data was used to see if TCM was scientific (2023) (mcgill.ca)",
    "points": 109,
    "submitter": "mgh2",
    "submit_time": "2025-07-13T21:35:32 1752442532",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=44553949",
    "comments": [
      "TCM is not a single branch of \"alt\" theory, but a clusterfuck of inconsistent,  contradictionary schools of thoughts which was umbrella-ed by state insitutions by P.R.C after 1949.Forget blind test, you can get 13 different perscription from 10 TCM doctors. I am not joking.reply",
      "In 2015, the Nobel Prize in Medicine was won by Tu Youyou.During the Vietnamese resistance war, Vietnamese moving down the Ho Chi Minh rail were contracting malaria in the jungle.  The Chinese were asked for aid, and Tu Youyou was tasked with assembling a team to help.One thing Tu Youyou did was consult \"traditional Chinese medicine\" with how to aid victims of malaria.  Most of what she found did not work, but wormwood did produce results.  Tu Youyou again consulted traditional Chinese medicinal texts  and they said wormwood should be used with cold water.  The team extracted artemisinin from the wormwood in cold water, and a new (and old) way of fighting malaria was born.reply",
      "A lot of scientists dabbled into pseudoscience but that doesn't invalidate their scientific accomplishment, and their scientific achievement doesn't validate their pseudoscientific pursuitreply",
      "> doesn't validate their pseudoscientific pursuitIf you take an idea with a pseudoscientific origin, and you test it in a sound scientific way, you're doing science, not pseudoscience.reply",
      "My favorite paragraph lands near the end, after a great debunking of the paper:>  The authors behind the paper drawing connections between symptoms, proteins, and Chinese herbs are hopeful that their model will show which herbs used in TCM seem particularly promising. They claim that chemicals in some herbs are known to interact with the same proteins involved in a particular symptom, but that this herb-symptom association has so far been ignored by TCM practitioners. They give several examples, such as Aristolochia fangchi known colloquially as Fang Ji which, based on their computer work, could help with abdomen distention. Patients beware: that plant was used in the 1990s instead of the listed herb as part of a slimming regimen in Belgium, where it caused \u201can outbreak of terminal renal failure.\u201d That is something that abstract maps of chemical interactions may not tell you, but we should not forget what we already know from experience.reply",
      "The Chinese and Korean golden herbs ginseng is way overrated. Just consume ginger instead of the 100x more expensive ginseng for all the recipes that people been come up over the centuries and the nutritional benefits probably the same if not better. It is essentially an overpriced souvenirs for your in-laws, that's it.reply",
      "I've taken pretty low grade ginseng and gotten a pretty noticeable stimulant effect from it. That's certainly never happened with ginger.reply",
      "I am biased as an ethnic Chinese, but I feel modern medicine is afraid that it's approach, the sum of parts empiricism may be incomplete, in that we dont understand all the parts yet.The human body is not just human DNA organs working together, but also an ecosystem with myriad bacteria, and we are still in infancy when it comes to understanding the bacteria.TCM seeks a black box metaphorical approach, which sounds like quackery but I do think it is capable of addressing _some_ blindspots in modern medicine, eg why some medication would work on a yin body but not a yang body... the difference is in the bacterial ecosystem.That said, I see TCM (and other traditional approaches) as a last resort when modern medicine fails, and I certainly agree the approach is incapable of resisting shamanic beliefs.reply",
      "I am also Chinese and this is exactly how I feel. The experience of going to a doctor with minor ailments, only to be sent away with the attitude of \"take some paracetamol and come back when symptoms worsen\" is maddening. In the mean time TCM practitioners have answers that often work for these kinds of things.In people's zeal to point out TCM's problems (due to its pre-modern scientific roots), I feel like they're also throwing away its potential. Skepticism shouldn't be about wholesale dismissal (which is just intellectual laziness masked as rightenousness) but about improving outcomes.reply",
      "> In the mean time TCM practitioners have answers that often work for these kinds of things.You can also take some homeopathic remedies and do a couple of chiropractic adjustments meanwhile. I've also heard that some Christian Science practitioners work wonders if you give them all your Earthly belongings.The ability to say: \"It's likely a viral disease. Wait and see if it worsens\" - is a pretty powerful point _in_ _favor_ of modern medicine.reply"
    ],
    "link": "https://www.mcgill.ca/oss/article/medical-critical-thinking-health-and-nutrition/no-traditional-chinese-medicine-has-not-been-vindicated-science",
    "first_paragraph": "People love to show that skeptics were wrong about something, especially when national pride hangs in the balance. The\u00a0South China Morning Post\u00a0published\u00a0the following headline\u00a0on November 3rd: \u201cScientists find traditional Chinese medicine is based on a complex network of proteins \u2013 3,000 years before modern science.\u201d\u00a0The article points out that respectable editorials in the scientific literature had repeatedly referred to traditional Chinese medicine (TCM) as \u201clargely just pseudoscience\u201d and \u201cbased on unsubstantiated theories.\u201d Yet here was the believer\u2019s vindication: that TCM really was rigorously scientific while predating the European origin of what we refer to as \u201cmodern science.\u201d\u00a0Skeptics were bound to eat their hats.\u00a0The study itself, published in\u00a0Science Advances, is certainly interesting, but its complexity makes it opaque to the average person. It\u2019s one of those impenetrable bits of data wrangling that can easily be dismissed as nonsense by the TCM skeptic or blindly embraced",
    "summary": "\ud83d\udd2c In a stunning \"victory\" for TCM advocates, Big Data flexes its muscles to prove that ancient herbal Witch Doctoring \u2122\ufe0f is <em>totally</em> scientific. While skeptics choke on their science textbooks, the South China Morning Post triumphantly waves a protein map that supposedly endorses sticking needles in your skin and swallowing the mystical ground-up roots to cure ailments modern medicine \"ignores.\" Commenters, grasping at the Nobel Prize like it's a TCM immunity charm, trip over themselves to either hail this as the dawn of a new enlightenment or rebrand pseudoscience with a fancier, modern label. Meanwhile, real scientists somewhere quietly facepalm, figuring out how to explain that correlation does <i>not</i>, in fact, imply causation. \ud83e\udd26\u200d\u2642\ufe0f"
  },
  {
    "title": "Show HN: FFmpeg in plain English \u2013 LLM-assisted FFmpeg in the browser (vidmix.app)",
    "points": 7,
    "submitter": "bjano",
    "submit_time": "2025-07-10T13:32:49 1752154369",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://vidmix.app/ffmpeg-in-plain-english/",
    "first_paragraph": "\n        AI will craft the command and you can run it right in the browser.\n      \n        Examples: \u201cKeep the first 20 seconds of the video\u201d, \"Extract the audio into an mp3 file\", \"Mix the audio from the mp3 file into the video file, keep the length of the video!\"\n      \n            \u2705 Finished\n\t\t\t",
    "summary": "Title: Videophiles Unleash Chaos, Now In Browser\n\nThe aspiring Scorseses of Hacker News rejoice as yet another under-caffeinated developer unleashes _FFmpeg for Dummies_, disguised as a \"LLM-assisted tool\" that promises to make slicing up your pirated YouTube finds easier than posting baseless speculation on tech forums. Users can now engage in high-stakes video editing directly in their browsers, because what could possibly go wrong? The comments section, a stunning display of obliviousness, quickly becomes a battleground of one-upmanship over who can say \u201cI could\u2019ve done this with a simple bash script\u201d the loudest. The internet, predictably, groans under the weight of such innovation. \ud83c\udfac\ud83d\ude44"
  },
  {
    "title": "Show HN: A Raycast-compatible launcher for Linux (github.com/byteatatime)",
    "points": 137,
    "submitter": "ByteAtATime",
    "submit_time": "2025-07-13T16:57:48 1752425868",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=44551762",
    "comments": [
      "Looks great! Change the name. The Raycast people are going to (initially) ask you to anyway.Raycast also runs on Windows now, albeit in beta.Other Linux launchers with extensibility:KRunner: https://userbase.kde.org/Plasma/KrunnerAlbert: https://albertlauncher.github.io/reply",
      "There is also rofi, wofi, fuzzl, dmenu, and even gnome search providers. No shortage of launchers on Linux, all with varying capabilities.reply",
      "Awesome work! I've been dreaming of this project myself with a very similar stack (basically React instead of Svelte), but I'm very excited to finally have a Raycast alternative for Linux that has both consistent UI and extension compatibility.The most impressive part is probably your age, because this isn't an easy project even for senior devs!I haven't tried it yet, but I can't wait to find some time for that.I've researched applications like this for Linux quite extensively and I think you might find the following tips of interest:\n- For the slow extension startup issue you mentioned, consider Deno as a runtime as it has a better sandbox and is faster than Node overall. There may be some compatibility issues, but if I remember correctly most stuff is handled by the special Raycast extension libraries which you implement manually anyway.\n- I'd consider Numbat [0] for replacing the calculator implementation you have now. As far as I can tell, it should have feature parity with SoulverCore and it's also written in Rust, so interfacing with it should be much easier and won't require the FFI work you're doing now.\n- Project Gauntlet [1] is another project which has gotten quite close to implementing a full-featured Raycast alternative and might be worth taking inspiration from. It would certainly be very cool if you can make the UI rendering native at some point (although I guess Rust isn't perfect for native UI at the moment [2])Keep up the good work![0]: https://github.com/sharkdp/numbat[1]: https://github.com/project-gauntlet/gauntlet[2]: https://areweguiyet.com/reply",
      "Raycast will either hire you or send you a cease-and-desist order. Either way, I would change the name now.reply",
      "Fair point! I've actually thought about that before; I've tried to be extremely clear in the project's README with a disclaimer that this is a non-commercial hobby project and is not affiliated with the official Raycast team in any way.The name is just for identification, as the project's goal is to be a compatible, open-source alternative for the Linux community, a platform they don't currently serve.That being said, I'll definitely keep it in mind. Thanks for bringing it up!reply",
      "That shouldn't matter. They might even have a Linux version in the works, given they are doing Windows now. They are within their rights to ask you to get rid of it. You also seem to be using their brand assets like the logo. I get your intention and love what you were able to accomplish but if you intend for this to grow, you are better off doing this now.reply",
      "It should matter that it's a non-commercial hobby project. It's nice to see the light pushback.reply",
      "That makes sense -- I'll go figure something out, thanks for the explanation!reply",
      "> They are within their rights to ask you to get rid of it.Only the logo and name. The functionality side should be perfectly fine, there are oodles of precedent for reversing a workable program from someone's commercial API: https://en.wikipedia.org/wiki/Google_LLC_v._Oracle_America,_....reply",
      "True, but a cease & desist will likely include the demand that they cease all operations, and they might be willing to fight that in court, possibly seek damages, etc however likely or unlikely it is that it would hold up. They can pay for a few hours of a lawyer's time to intimidate the OP.reply"
    ],
    "link": "https://github.com/ByteAtATime/raycast-linux",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Raycast-compatible launcher for Linux\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.An open-source, Raycast-inspired launcher for Linux.For more background on this project, I have a post here.Disclaimer: This is a hobby project and is not affiliated with, nor endorsed by, the official Raycast team.This launcher aims to recreate most of Raycast's core features on Linux:While the goal is to support a wide range of Raycast extensions, there are some inherent limitations due to the differences between macOS and Linux. Common reasons an extension might not work include:You can download the latest release from the GitHub Releases page.Currently, only an .AppImage is provided. After downloading, make it executable:This will open a long-running process in the back",
    "summary": "Title: HN Discovers Copy-Paste Development\n\nAnother day, another open-source developer tries to recreate something that kind of already exists, but for Linux! Today's hero has conjured up a Raycast-style launcher that miraculously encounters more \"loading errors\" than a Windows Vista update. The comment section, a dazzle of accidentally tech-savvy gerbils, suggests everything from name changes to avoid lawsuits to complete rewrites in Rust because, why not? Meanwhile, Raycast might just settle this innovation carnival with a friendly cease-and-desist, because \"inspired by\" clearly means \"please don't sue us.\" \ud83d\ude2c"
  },
  {
    "title": "Hypercapitalism and the AI Talent Wars (johnluttig.com)",
    "points": 29,
    "submitter": "walterbell",
    "submit_time": "2025-07-13T20:09:34 1752437374",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44553257",
    "comments": [
      "https://medium.com/@villispeaks/the-blitzhire-acquisition-e3...> Blitzhires are another form of an acquisition.. not everybody may be thrilled of the outcome.. employees left behind may feel betrayed and unappreciated.. investors may feel founders may have broken a social contract. But, for a Blitzhire to work, usually everybody needs to work together and align. The driver behind these deals is speed. Maybe concerns over regulatory scrutiny are part of it, but more importantly speed. Not going through the [Hart-Scott-Rodino Antitrust Act] HSR process at all may be worth the enormous complexity and inefficiency of foregoing a traditional acquisition path.From comment on OP:> In 2023\u20132024, our industry witnessed massive waves of layoffs, often justified as \u201cIt\u2019s just business, nothing personal.\u201d These layoffs were carried out by the same companies now aggressively competing for AI talent. I would argue that the transactional nature of employer-employee relationships wasn\u2019t primarily driven by a talent shortage or human greed. Rather, those factors only reinforced the damage caused by the companies\u2019 own culture-destroying actions a few years earlier.2014, https://arstechnica.com/tech-policy/2014/06/should-tech-work...> A group of big tech companies, including Apple, Google, Adobe, and Intel, recently settled a lawsuit over their \"no poach\" agreement for $324 million. The CEOs of those companies had agreed not to do \"cold call\" recruiting of each others' engineers until they were busted by the Department of Justice, which saw the deal as an antitrust violation. The government action was followed up by a class-action lawsuit from the affected workers, who claimed the deal suppressed their wages.reply",
      "> If the top 1% of companies drive the majority of VC returnsThe fact that the author brings this up and fails to realize that the behavior of current staff shows we have hit or have passed peak AI.Moores Law is dead and it isn't going to come through and make AI any more affordable. Look at the latest GPU's: IPC is flat. And no one is charging enough to pay for running (bandwidth, power) of the computer that is being used, never mind turning NVIDA into a 4 trillion dollar company.> Meta\u2019s multi-hundred million dollar comp offers and Google\u2019s multi-billion dollar Character AI and Windsurf deals signal that we are in a crazy AI talent bubble.All this signals is that those in the know have chosen to take their payday. They don't see themselves building another google scale product, they dont see themselves delivering on samas vision. They KNOW that they are never going to be the 1% company, the unicorn. It's a stark admission that there is NO break out.The math isnt there in the products we are building today: to borrow a Bay Area quote there is no there there. And you can't spend your way to market capture / a moat, like every VC gold rush of the past.Do I think AI/ML is dead. NO, but I dont think that innovation is going to come out of the big players, or the dominant markets. Its going to take a bust, cheap and accessable compute (fire sale on used processing) and a new generation of kids to come in hungry and willing to throw away a few years on a big idea. Then you might see interesting tools and scaling down (to run localy).The first team to deliver a model that can run on a GPU alongside a game, so that there is never an \"I took an arrow to the knee\" meme again is going to make a LOT of money.reply",
      "> the 10x engineer meme doesn\u2019t go far enough \u2013 there are clearly people that are 1,000x the baseline impact.Plenty out there who want authors like this believing it enough to write itreply",
      "> The first team to deliver a model that can run on a GPU alongside a game, so that there is never an \"I took an arrow to the knee\" meme again is going to make a LOT of money.\"Local Model Augmentation\", a sort of standardized local MCP that serves as a layer between a model and a traditional app like a game client. Neat :3reply"
    ],
    "link": "https://blog.johnluttig.com/p/hypercapitalism-and-the-ai-talent",
    "first_paragraph": "",
    "summary": "**The Rosy Tech Bubble of AI Talent Wars**\n\nToday on the internet, \"Hypercapitalism and the AI Talent Wars\" boldly reveals that tech companies race to hoard as much AI talent as our dying planet has nerds, while layoffs are casually passed off as \"tough business decisions.\" Comment sections are aflame with the cold takes of dismissed techies reminiscing about the good ol' days of antitrust-violating no poach pacts and mourning Moore's Law like it's a deceased Tamagotchi. Meanwhile, someone dreams that a GPU-running AI might one day eliminate tired video game memes, because apparently that's the innovation humanity really needs, right after solving minor inconveniences for gamers. Brace yourselves, as dangling multi-million dollar carrots will surely keep our best minds tirelessly innovating ways to make virtual avatars even less annoying in meetings. \ud83e\udd11\ud83d\udcb8\ud83d\ude80"
  },
  {
    "title": "Fine dining restaurants researching guests to make their dinner unforgettable (sfgate.com)",
    "points": 59,
    "submitter": "borski",
    "submit_time": "2025-07-13T15:30:29 1752420629",
    "num_comments": 120,
    "comments_url": "https://news.ycombinator.com/item?id=44551109",
    "comments": [
      "The title seems ominous but the article itself is about how a fancy restaurant will go out of it's way to make you feel special. They're perusing your social media for clues.In the past your spouse or kid would call and let the maitre'd know it was special; now I guess it's a job for someone on staff.reply",
      "Until some YC backed SaaS LLM AI automates the process and it becomes table stakes.  Then they find other uses for it..reply",
      "I'm waiting for fully automated writing style recognition that finds all your throwaway accounts and sends you a shakedown letter.reply",
      "I'm waiting for an AI bot that follows everyone around and points out ideological inconsistencies.\"funny, you were all fine with this when X was doing it as evidenced in <cites specific comments>, care to explain why this is different?\".reply",
      "Reproducing Hacker News writing style fingerprinting, by antirez of Redis famehttps://news.ycombinator.com/item?id=43705632reply",
      "It\u2019s really great that the most successful people in Silicon Valley disregard the social implications of their work. Arguably that\u2019s what makes them so successful.reply",
      "This was possible before, as the post shows with a previous HN post, nothing to do with Silicon Valley.reply",
      "'Silicon Valley' here is just proxy for 'self-delusional tech glitterati with a cheap veneer of enlightenment'.reply",
      "I suspect HN is already checking IP.reply",
      "> and it becomes table stakes.I see what you did there.reply"
    ],
    "link": "https://www.sfgate.com/food/article/data-deep-dives-bay-area-fine-dining-restaurants-20404434.php",
    "first_paragraph": "",
    "summary": "In a breakthrough in culinary espionage, fine dining has evolved from merely indulging your palate to actively stalking your digital footprint. Restaurants, apparently dissatisfied with traditional methods of personalized service, are now combing through customers' social media to craft those \"unforgettable\" dining experiences. Commenters, suddenly experts in privacy\u2014when convenient\u2014oscillate between technophobic paranoia and breathless awe at such innovative creepiness. One bright mind envisions a future where AI not only perfects this stalking but also calls you out on your hypocritical rants over dessert. Silicon Valley, take a bow: you've successfully fused fine dining with fine surveillance. \ud83c\udf7d\ufe0f\ud83d\udd75\ufe0f\u200d\u2642\ufe0f"
  },
  {
    "title": "How to scale RL to 10^26 FLOPs (jxmo.io)",
    "points": 51,
    "submitter": "jxmorris12",
    "submit_time": "2025-07-10T20:47:34 1752180454",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44525405",
    "comments": [
      "Besides the great subject matter, I love how densely packed this article is with links to relevant papers and materials!(Because I almost missed this) In the comments on the post someone linked to this paper: https://arxiv.org/html/2408.15240v1reply",
      "More data? Where it supposed to come from?reply",
      "How do I fly hack ?reply"
    ],
    "link": "https://blog.jxmo.io/p/how-to-scale-rl-to-1026-flops",
    "first_paragraph": "",
    "summary": "Title: Keyboard Warriors Discover Mathematics, Panic Ensues\n\nAt jxmo.io, an unwitting blogger bravely attempts to unpack the whopping <em>10^26 FLOPs</em> of real-life Rubik's cube solving, also known as scaling reinforcement learning. The comment section becomes a tragicomic symposium of the misinformed and the misguided \u2013 one zealot applauds the author's liberal use of hyperlinks as a substitute for actual content, while another wonders where the hell all that data will magically come from, probably the same place they assume their groceries appear from: thin air. Meanwhile, someone who obviously thinks they're logged into a different internet asks how to \"fly hack\" the process, because why grasp the basics when you can aimlessly cheat? In summary, the blind lead the blind into a pit of digital despair, armed only with buzzwords and a tenuous grasp on reality."
  },
  {
    "title": "C3 solved memory lifetimes with scopes (c3-lang.org)",
    "points": 94,
    "submitter": "lerno",
    "submit_time": "2025-07-11T14:27:42 1752244062",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=44532527",
    "comments": [
      "\"No more [...] slow compile times with complex ownership tracking.\"Presumably this is referring to Rust, which has a borrow checker and slow compile times. The author is, I assume, under the common misconception that these facts are closely related. They're not; I think the borrow checker runs in linear time though I can't find confirmation of this, and in any event profiling reveals that it only accounts for a small fraction of compile times. Rust compile times are slow because the language has a bunch of other non-borrow-checking-related features that trade off compilation speed for other desiderata (monomorphization, LLVM optimization, procedural macros, crates as a translation unit). Also because the rustc codebase is huge and fairly arcane and not that many people understand it well, and while there's a lot of room for improvement in principle it's mostly not low-hanging fruit, requiring major architectural changes, so it'd require a large investment of resources which no one has put up.reply",
      "I know very little about how rustc is implemented, but watching what kind of things make make Rust compile times slower, I tend to agree with you. The borrow checker rarely seems to be the culprit here. It tends to spike up exactly on the things you've mentioned: procedural macros use, generics use (monomorphization) and release builds (optimization).There are other legitimate criticisms you can raise at the Rust borrow checker such as cognitive load and higher cost of refactoring, but the compilation speed argument is just baseless.reply",
      "Procedural macros are not really _that_ slow themselves, the issue is more that they tend to generate enormous amount of code that will then have to be compiled, and _that_'s slow.reply",
      "Also the procedural macro library itself and all of its dependencies have to be compiled. Though this only really affects initial builds, as the library can be cached on subsequent ones.reply",
      "https://learning-rust.github.io/docs/lifetimes/> Lifetime annotations are checked at compile-time. ... This is the major reason for slower compilation times in Rust.This misconception is being perpetuated by Rust tutorials.reply",
      "On the phone, so I can't now, but someone should file a ticket to that project about that error: https://github.com/learning-rust/learning-rust.github.io/iss...Be aware that it is not part of the rust-lang organization, it's a third party.reply",
      "https://github.com/learning-rust/learning-rust.github.io/pul...reply",
      "It took me some time to collect my thoughts on this.One: I don't believe they have solved use-after-free. Marking memory freed and crashing at runtime is as good as checked bounds indexing. It turns RCE into DOS which is reasonable, but what would be much better is solving it provably at compile time to reject invalid programs (those that use memory after it has been deallocated). But enough about that.I want to write about memory leaks. Solving memory leaks is not hard because automatically cleaning up memory is hard. This is a solved problem, and the domain of automatic memory management/reclamation aka garbage collection. However I don't think they've gone through the rigor to prove why this is significantly different than say, segmented stacks (where each stack segment is your arena). By \"significantly different\" you should be able to prove this enables language semantics that are not possible with growable stacks - not just nebulous claims about performance.No, the hard part of solving memory leaks is that they need to be solved for a specific class of program: one that must handle resource exhaustion (otherwise - assume infinite memory; leaks are not a bug). The actual hard thing is when there are no memory leaks in the sense that your program has correctly cleaned itself up everywhere it is able and you are still exhausting resources and must selectively crash tasks (in O(1) memory, because you can't allocate), those tasks need to be able to handle being crashed, and they must not spawn so many more tasks as to overwhelm again. This is equivalent to the halting problem, by the way, so automatic solutions for the general case are provably impossible.I don't believe that can be solved by semantically inventing an infinite stack. It's a hard architectural problem, which is why people don't bother to solve it - they assume infinite memory, crash the whole program as needed, and make a best effort at garbage collection.All that said, this is a very interesting design space. We are trapped in the malloc/free model of the universe which are known performance and correctness pits and experimenting with different allocation semantics is a good thing. I like where C3 and Zig's heads are at here, because ignoring allocators is actually a huge problem in Rust in practice.reply",
      "The core benefit of the borrow checker is not \"make sure to remember to clean up memory to avoid leaks.\" The core benefits are \"make sure that you can't access memory after it has been destroyed\" and \"make sure that you can't mutate something that somebody else needs to be constant.\" This is fundamentally a statement about the relationship between many objects, which may have different lifetimes and which are allocated in totally different parts of the program.Lexically scoped lifetimes don't address this at all.reply",
      "Well, the title (which is poorly worded as has been pointed out) refers to C3 being able to implement good handling of lifetimes for temporary allocations by baking it into the stdlib. And so it doesn't need to reach for any additional language features. (There is for example a C superset that implements borrowing, but C3 doesn't take that route)What the C3 solution DOES to provide a way to detect at runtime when already freed temporary allocation is used. That's of course not the level of compile time checking that Rust does. But then Rust has a lot more in the language in order to support this.Conversely C3 does have contracts as a language feature, which Rust doesn't have, so C3 is able to do static checking with the contracts to reject contract violations at compile time, which runtime contracts like some Rust creates provides, can't do.reply"
    ],
    "link": "https://c3-lang.org/blog/forget-borrow-checkers-c3-solved-memory-lifetimes-with-scopes/",
    "first_paragraph": " 2025-07-11 Modern languages offer a variety of techniques to help with dynamic memory management, each one a different tradeoff in terms of performance, control and complexity. In this post we\u2019ll look at an old idea, memory allocation regions or arenas, implemented via the C3 Temp allocator, which is the new default for C3.The Temp allocator combines the ease of use of garbage collection with C3\u2019s unique features to give a simple and (semi)-automated solution within a manual memory management language. The Temp allocator helps you avoid memory leaks, improve performance, and simplify code compared to traditional approaches.Memory allocations come in two broad types stack allocations which are compact, efficient and automatic and heap allocations which are much larger and have customisable organisation. Custom organisation allows both innovation and footguns in equal measure, let\u2019s explore those.When we dynamically allocate memory, with say malloc() typically we need to free() it after",
    "summary": "**C3: The Memory Management Revolution No One Asked For**\n\nIn an adorable attempt to reinvent the wheel, the C3 programming language introduces the \"Temp allocator,\" magically promising the simplicity of garage sale tarp covering a leaking roof. Commenters, dazzled by buzzwords and the allure of escaping Rust's notorious compile times, trip over themselves to either praise this blast from the past or misconstrue basic concepts about memory management. It's a delightful circus of the uninformed leading the confused, proving once again that nostalgia for simpler coding times can induce mass amnesia about why we evolved past those methods in the first place. Watch as they tackle the complexity of memory leaks with all the finesse of a toddler\u2019s first spaghetti dinner. \ud83c\udf5d\ud83d\ude02"
  },
  {
    "title": "Show HN: Learn LLMs LeetCode Style (github.com/exorust)",
    "points": 122,
    "submitter": "Exorust",
    "submit_time": "2025-07-13T13:03:13 1752411793",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=44550157",
    "comments": [
      "This is decent for what it is. Some of the problems are pretty open ended which has pros and cons, but that is very different from leetcode, which has very specific data and test cases.For example, implement linear regression but the example solution uses a random number generator without a fixed seed. It\u2019s fine, reproducibility isn\u2019t the point, but leetcode problems are more structured.In leetcode they usually don\u2019t tell you exactly what data structure you must use, only that it must pass certain test cases. By analogy this might not tell you which architecture to use but require that it passes certain eval metrics.reply",
      "Cool idea, will try. Since it seems mostly llm generated you could publish the process and prompts for transparency.reply",
      "I'll do that.\nI'll also add a disclosure that I did use Gpt to generate it.reply",
      "What are people's other \"go try to build this thing, perfectly aligned to your noob-level\" ways of learning lower-level ML Tools (PyTorch, CUDA etc.)?reply",
      "> Avoid using GPT. Try to solve these problems on your own. The goal is to learn and understand PyTorch concepts deeply.I mean...this entire project appears to be mostly GPT-generated?reply",
      "One time my teacher used a computer to make a math test for me, but then told me I couldn't use my computer during the exam.  I dropped out of school immediately.reply",
      "Great analogy my brother there\u2019s minimal difference between a word processing software and an LLMreply",
      "Why do you think it I GPT generated?reply",
      "[flagged]",
      "^ This is a bot/crackpot account whose only purpose is promoting jumbled words on HN. How/where to report it?[0]: https://news.ycombinator.com/submitted?id=NetRunnerSureply"
    ],
    "link": "https://github.com/Exorust/TorchLeet",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Leetcode for Pytorch\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n    \ud83d\udc26 Follow me on Twitter \u2022\n    \u27a1\ufe0f Jump to LLMs!\n    \ud83d\udce7 Feedback\n\n\nTorchLeet is broken into two sets of questions:NoteAvoid using GPT. Try to solve these problems on your own. The goal is to learn and understand PyTorch concepts deeply.Mostly for beginners to get started with PyTorch.Recommended for those who have a basic understanding of PyTorch and want to practice their skills.These problems are designed to challenge your understanding of PyTorch and deep learning concepts. They require you to implement things from scratch or apply advanced techniques.These problems are for advanced users who want to push their PyTorch skills to the limit. They involve complex architectures, custom laye",
    "summary": "**HN Launches Yet Another Educational Knockoff**\n\nIn today's episode of reinventing the wheel, a brave HN user brings us \"TorchLeet,\" a platform promising to teach you PyTorch by making you solve Deep Learning puzzles without much guidance\u2014and sometimes, to add a sprinkle of excitement, without reproducible results! Commenters swarm to balance tepid praise with skepticism, because if it's not structured like LeetCode, is it even coding? Dive into a sea of confusion where beginners are encouraged to \"avoid using GPT\" in a project that is, ironically, generated by GPT. Because in the Hacker News spirit, nothing says learning better than debating the ethics of AI-generated content while using it. \ud83c\udf93\ud83e\udd16\ud83d\udd25"
  },
  {
    "title": "Axon\u2019s Draft One is designed to defy transparency (eff.org)",
    "points": 219,
    "submitter": "zdw",
    "submit_time": "2025-07-11T00:21:16 1752193276",
    "num_comments": 139,
    "comments_url": "https://news.ycombinator.com/item?id=44527172",
    "comments": [
      "> So we don\u2019t store the original draft and that\u2019s by design and that\u2019s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney\u2019s officesYou have to wonder if this will stand up in court. I hope not.AI has a great opportunity to take processes that contain hidden bias and make them more legible and therefore amenable to fixing.But it also has the opportunity to do the opposite, and we should be cautious to make sure guardrails are in place when putting this tech into life-and-death systems.\u201cStamp this LLM text in a hurry\u201d is an invitation for whatever errors and biases are baked into the system to be propagated. You need provenance and measurement of LLM outputs.reply",
      "Yeah the avoidance of record keeping to reduce disclosure  smacks of the policies that got Google into hot water recently: https://www.epspros.com/news-resources/news/2024/google-accu...reply",
      "A lot of people worry about a Terminator style AI apocalypse.  I don\u2019t.I worry that we\u2019ve already created the AI apocalypse and that this is what it looks like, along with extremist magnification on social media.I trust AI to be what is is- essentially a lot of math that classisfies and predicts stuff, usually words, that the prediction can be used generatively, and the classification stuff can be used to identify stuff in various media.What I don\u2019t trust is that people will use it responsibly.  Hell, I don\u2019t, when I\u2019m vibe coding, but that\u2019s on me.People are venal and self absorbed and busy and lazy and all the other traits that lead to not using AI responsibly.  And businesses are amoral (not immoral) and want the shortest path to revenue, with the least friction.So of course police officers who want to be on patrol and did not sign up to spend countless hours on reports, are going to let the AI write it and call it good without proofreading.We could pass a lot of laws trying to specify products that force police to act reliably, or we could maybe just pass a law that says that AI cannot be used to write police reports, but that clearly labeled AI generated transcriptions and summaries may be attached unedited to police reports, if and only if the original recordings are also preserved as evidence.And police departments that keep body camera and car camera footage might be ease up on the report writing and only require officers to annotate it with their impressions, but otherwise let the record speak for itself.reply",
      "I wondering how much this even matters in the age of everything being recorded.If they are using axon body cameras and vehicle cameras, then usually the entire interaction is recorded, often from multiple officers.I cannot imagine a defense so incompetent that they rely on the police report rather than watching the entire body cam footage and doing their own assessment.Even if the cops are doing something sketchy (like turning off their camera) then it's not like the police report would be any more trustworthy.reply",
      "The current administration has already removed the requirement for federal police forces to wear body cameras. As well as made statements (but little action so far) to federalize the police force to be under the jurisdiction of the DOJ. Everything being recorded may not be the case very soon.\n Sorry, I\u2019d get sources but I just woke up, I\u2019ll edit this later with them.reply",
      "If it\u2019s not being recorded, what would this AI summary be based on?reply",
      "You describe the conviction you want to achieve and the AI makes up a report to secure that.reply",
      "\u201cYou are a helpful agent. Police officers will describe an interaction to you and you will write a report that highlights the appropriateness of the officer\u2019s actions, omitting anything that might indicate they acted improperly\u201dreply",
      "Are people missing that this AI is being offered by a body cam company?reply",
      "Why do you think that's relevant?reply"
    ],
    "link": "https://www.eff.org/deeplinks/2025/07/axons-draft-one-designed-defy-transparency",
    "first_paragraph": "Axon Enterprise\u2019s Draft One \u2014 a generative artificial intelligence product that writes police reports based on audio from officers\u2019 body-worn cameras \u2014 seems deliberately designed to avoid audits that could provide any accountability to the public, an EFF investigation has found.Our review of public records from police agencies already using the technology \u2014 including police reports, emails, procurement documents, department policies, software settings, and more \u2014 as well as Axon\u2019s own user manuals and marketing materials revealed that it\u2019s often impossible to tell which parts of a police report were generated by AI and which parts were written by an officer.You can read our full report, which details what we found in those documents, how we filed those public records requests, and how you can file your own,\u00a0here.\u00a0Everyone should have access to answers, evidence, and data regarding the effectiveness and dangers of this technology. Axon and its customers claim this technology will revol",
    "summary": "**Axon\u2019s Draft Dodger: Transparency's Worst Nightmare**\n\nIn a stunning blow to fans of police reports written by actual humans, Axon unleashes its latest marvel: a generative AI hell-bent on making forensic accountancy and legal scrutiny even more migraine-inducing. The plan? Mix AI-generated content with officer-authored prose in a seamless blend that ensures nobody can tell what happened or who wrote what. Commenters, buzzing with their standard concoction of techno-phobia and legal armchair expertise, bemoan the possibility of AI reports sans accountability while gleefully ignoring the underlying treatise that the optimal police report might just be NO report. Will public transparency prevail, or will <i>Draft One</i> become the gold standard in obfuscating law enforcement documentation? Stay tuned, and don't forget to backup your objections on something more reliable than a comment thread. \ud83d\ude02\ud83d\ude94\ud83d\udc7b"
  },
  {
    "title": "Ask HN: How much of OpenAI code is written by AI?",
    "points": 48,
    "submitter": "growbell_social",
    "submit_time": "2025-07-13T20:22:00 1752438120",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=44553379",
    "comments": [
      "I don't work for OpenAI and I doubt some random employee is going to come here and share what is likely a secret. I'm in the industry though so I have some idea of what's going on these days, both where I work and more broadly.AI is getting better at writing code. However writing code is just some fraction of the work of many software engineers. AI doesn't work independently, it needs to be guided, its work needs to be reviewed, tested etc. There are some domains where it does better and some domains where it doesn't. There's a range of \"AI\" work between auto-complete style work, assisting in understanding a code base, and writing code from some spec or doing other types work.All in all I would say it's a decent improvement to productivity for many situations. It's really hard to say how much and it's also not a zero sum game, as productivity improves there's more work.Something to keep in mind is that if you look at a modern software project likely most of the code executing is not code written by the developers of that project. There's a huge stack of open source bits executing for almost any new project.Specifically in OpenAI you also need to consider what type of software they are likely writing. Some of it may be more or less \"vanilla\" code and other is likely very specialized/performance critical. The vanilla code like API wrappers or simple front end pieces is likely more amenable to be written by AI whereas the more cutting edge algorithmic/scheduling/optimization work is almost certainly not done by AI. At least yet.As software organizations become larger there's a lot of overhead and waste. It is possible that AI can enable smaller teams and that has a multiplicative effect because it lets you reduce that waste/overhead. There are likely also software engineers who will become better/adapt to new workflows and some who will not. It's really hard to say where things are going but overall my sense is that this like many other innovations will lead to more software and more jobs and not the other way around. There are many moving pieces here, not just AI itself but geopolitics, macro-economics, etc. Where are those new jobs going to get created, what new types of software/technology are going to be created etc. etc. History seems to show us that we'll adapt/evolve and grow.reply",
      "I think this is the wrong question.The right question is how much human code can a human push now vs prior to AI.Everything we've done in coding has been assisted.Prior to this current generation of web applications, we had the advent of concepts like Object Orientated Programming and prior to that even C was a massive move up from Assembly and punch cards.AI has written a lot of code. AI has written very little high velocity production code by itself (ie. for people with no coding background).In Ruby on Rails, the concept of fast coding has been around for over 20 years, look up this concept of Scaffolding: https://www.rubyguides.com/2020/03/rails-scaffolding/So to answer your question,1. AI has pushed a lot of code\n2. AI has pushed almost no code without the oversight of human software engineers\n3. Software engineers are pushing a magnitude more code and producing more functional utility and solving more bugs than ever beforeI don't know what the future holds, but I do think that this is not a new trend to use software to help humans build faster, and I don't think software has the ability to fully replace humans (yet).reply",
      "> Software engineers are pushing a magnitude more code and producing more functional utility and solving more bugs than ever beforeCitation neededreply",
      "More programmers than ever before makes this implicitly true.It\u2019s not as clever as the author hoped.reply",
      "Not OpenAI, but Anthropic CPO Mike Krieger said in response to a question of how much of Claude Code is written by Claude Code: \"At this point, I would be shocked if it wasn't 95% plus. I'd have to ask Boris and the other tech leads on there.\"[0] https://www.lennysnewsletter.com/p/anthropics-cpo-heres-what...reply",
      "They are likely lying:https://www.anthropic.com/candidate-ai-guidance> During take-home assessments Complete these without Claude unless we indicate otherwise. We\u2019d like to assess your unique skills and strengths. We'll be clear when AI is allowed (example: \"You may use Claude for this coding challenge\").> During live interviews This is all you\u2013no AI assistance unless we indicate otherwise. We\u2019re curious to see how you think through problems in real time. If you require any accommodations for your interviews, please let your recruiter know early in the process.He'd have to ask yet did not ask? A CPO of an AI company?reply",
      "That's not evidence of anything to do with their hired developers. Interview practices have never reflected on-the-job practicesreply",
      "TFA says \"How Anthropic uses AI to write 90-95% of code for some products and the surprising new bottlenecks this creates\".for some products.If it were 95% of anything useful, Anthropic would not still have >1000 employees, and the rest of the economy would be collapsing, and governments would be taking some kind of action.Yet none of that appears to be happening. Why?reply",
      "> If it were 95% of anything useful, Anthropic would not still have >1000 employeesI think firing people does not come as a logical conclusion of 95% of code being written by Claude Code. There is a big difference between AI autonomously writing code and developers just finding it easier to prompt changes rather than typing them manually.In one case, you have an automated software engineer, and may be able to reduce your headcount. In the other, developers may just be slightly more productive or even just enjoy writing code using AI more, but the coding is still very much driven by the developers themselves. I think right now Claude Code shows signs of (1) for simple cases, but mostly falls into the (2) bucket.reply",
      "I don't doubt it, especially when you have an organization that is focused on building the most effective tooling possible. I'd imagine that they use AI even when it isn't the most optimal, because they are trying to build experiences that will allow everyone else to do the same.So let's take it on face value and say 95% is written by AI. When you free one bottleneck you expose the next. You still need developers to review it to make sure it's doing the right thing. You still need developers to be able to translate the business context into instructions that make the right product. You have to engage with the product. You need to architect the system - the context windows mean that the tasks can't just be handed off to AI.So, The role of the programmer changes - you still need technical competence, but to serve the judgement calls of \"what is right for the product?\" Perhaps there's a world where developers and product management merges, but I think we will still need the people.reply"
    ],
    "link": "item?id=44553379",
    "first_paragraph": "",
    "summary": "**Ask HN: How much of OpenAI code is written by AI?**\n\nIn a breath-taking display of navel-gazing, Hacker News users bumble into an existential crisis over how much of OpenAI's code is penned by its AI offspring. One sagely commenter chimes in with the obvious: no OpenAI employee would spill these beans\u2014they're likely classified, equivalent to the Coca-Cola formula or a McDonald's special sauce. The punditry mulls over AI's role ranging from glorified auto-correct to whispering sweet nothings into a developer's IDE. Meanwhile, another armchair expert points out that\u2014shocker!\u2014modern software leans heavily on open source, thereby blowing everyone's minds that not all code in a project might be handcrafted artisanal binary. <*em*>Will the real developers please stand up, or are they just sophisticated prompt resolvers now?<*/em*>"
  },
  {
    "title": "Zig's new I/O: function coloring is inevitable? (ivnj.org)",
    "points": 33,
    "submitter": "ivanjermakov",
    "submit_time": "2025-07-13T15:57:34 1752422254",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=44551318",
    "comments": [
      "I am actually really excited about this.The issues I've had with function colouring had to do with trying to compose code using (or expecting) blocking effects with those using async effects in NodeJS - if one library has a higher-order function that expects a non-async function and you have functionality which is provided to you as async, it can be very difficult to plumb them together! And if it's the other way around, it can be quite the performance killer (think how much faster better-sqlite3 is than alternatives). Zig's approach eliminates this problem, AFAICT.If I had to choose between having to pass through an effect handler like `io` or write `async` everywere, the former seems like a better use of my time. It's explicit, but that can be good.It also fits Zig well with the allocator. Code can expect an allocator or perhaps an allocator and `io`, or perhaps neither. It's analogous to Rust code that is core vs alloc/nostd vs std.I am slightly amused that a \"C-but-better\" language is going to have an `io` passed through non-pure functions much like Haskell. It's that idea combined with Rust's pluggable async runtimes (and stackless concurrency) combined with Roc's \"platforms\" - but for systems programmers. Quite amazing.reply",
      "I think this is a good kind of function coloring. It would avoid some scars I have from:- seemingly harmless functions that unexpectedly end up writing four different files to disk.- Packages that do I/O or start threads when you simply import them.reply",
      "Function colouring created a lot of angst when it first came about, particularly because of the difficulties of calling a function of one colour from another. Whether that was possible, what it actually meant, wasn't really well defined.As other comments have said, there's nothing special about \"colouring\"; sync/async functions are a case where those above problems are tough, but simpler versions of the problem are everywhere and we don't freak out about them e.g. call a fallible function from an infallible function.It really all turns on how easy it is to ultimately make the call to the other \"function\" colour. In Zig's case, if its easy to get an Io in a function that didn't take an Io, it's a non-issue. Likewise for the \"fallible function call from infallible function\": if it fails, do something that doesn't result in the infallible function failing (do something else? Terminate? Anything will do).reply",
      "If you want to go down that route, any function that has, or doesn't have, any given resource is colored then.   fn foo(db: *Db) !void { ... }\n   fn bar() !void { ... }\n\nWould you consider `foo` a blue function and `bar` a red function? That doesn't seem particularly helpful to me.The virality of async await is that once you mark a function async, then you can only call it from another async function, which forces you to mark more functions async, which in turn means that if you want to use blocking I/O APIs then you just can't because it's incompatible with your execution model because by daring to express asynchronicity of operations, you were forcefully opted into stackless coroutines.That's what Zig solves, and that's what is real function coloring. People have written reimplementations of the same libraries multiple times because of it.https://github.com/redis/redis-py\nhttps://github.com/jonathanslenders/asyncio-redisJust as an example. Note also how, coincidentally, this duplication of effort resulted in asyncio-redis being semi-abandoned and looking for maintainers. And you have to have both libraries because the asyncio one can't do blocking, and vice versa the other one can't do async.Would you write two instances of essentially the same library just because one is missing an argument that gives it access to an `Io` interface? No, because you would just pass that extra argument around and nothing else would have to change.reply",
      ">  Would you consider `foo` a blue function and `bar` a red function? That doesn't seem particularly helpful to me.In the sense of effect/capability typing, I think the answer is yes.\"Coloring\" isn't magical, it's just a way to describe effects. Those effect can be described by keywords (`async` in JS, `throws` in Java, etc.) or special token parameters/types (what Zig does), but the consequences are the same: the effect propagates to the caller, and the caller becomes responsible for dealing with it.reply",
      "I've been trying to beat this point in and failing. If a parameter type creates \"colors\", you can extrapolate that to an infinite set of colors in every single language and every single standard library, and the discussion on colors becomes meaningless.Some people are so focused on categorical thinking that they are missing the forest for the trees.The colors are a means of describing an observed outcome -- in Node's case, callback hell, in Rust's, 4 different standard libraries. Whatever it may be, the point is not that there are colors, it's the impact on there being colors.> But there is a catch: with this new I/O approach it is impossible to write to a file without std.Io!This sentence just makes me laugh, like it's some kind of \"gotcha\". It is the ENTIRE BASIS of the design!reply",
      "> If a parameter type creates \"colors\", you can extrapolate that to an infinite set of colors in every single language and every single standard library, and the discussion on colors becomes meaningless.Idea: what if these \u201ccolors\u201d could be combined as orthogonal attributes as a part of the type system, a bit like traits?reply",
      "> The virality of async await is that once you mark a function async, then you can only call it from another async functionRust calling async function in non-async function:    ...\n    // Create the runtime\n    let rt  = Runtime::new().unwrap();\n    \n    // Get a handle from this runtime\n    let handle = rt.handle();\n\n    // Execute the future, blocking the current thread until completion\n    handle.block_on(async {\n        println!(\"hello\");\n    });\n\nhttps://docs.rs/tokio/latest/tokio/runtime/struct.Handle.htm...reply",
      "Of course, spinning up a new runtime within the context of a boundary like that is probably wasteful (lots of new threads created if you\u2019re not careful). But you could stash that runtime behind a OnceLock (you\u2019d need to block_on the Handle I imagine rather than the Runtime directly, but doable).And calling blocking from non-blocking:    let result = tokio::task::spawn_blocking(|| {\n       5\n    }).await;\n\nThis of course is basically essentially what Zig is doing, except instead of hidden global state it\u2019s parameter passed. This is one area Zig does do better in - I wish Rust would default more to instance state instead of implicit global state.reply",
      "I don't care about the color of the function. What matters is if you'll have to write two versions of the function, and this seems to solve that.reply"
    ],
    "link": "https://blog.ivnj.org/post/function-coloring-is-inevitable",
    "first_paragraph": "2025-13-07programming\nlanguage design\nBlog post What Color is Your Function?\n(2015) by Bob Nystrom highlighted problems of async computation handling in programming language design.\nIt has started heated discussions on Hacker News\nand Reddit.Although many solutions to this problem were suggested, none of them seemed to be a silver bullet.In the Zig Roadmap 2026 stream Andrew Kelley announced\na new way of doing I/O,\nand Loris Cro wrote a Zig\u2019s New Async I/O blog post describing it\nin more details.This is the example Zig code from that post, that writes data to two files asynchronously:Loris later claims that this approach to I/O solves function coloring\u2026 and I don\u2019t agree.To see why, let\u2019s compare function signatures of red (blocking) and\nblue (non-blocking) versions of saveData with a few modifications\nthat make my argument a bit more clear:And compare it to semantically similar functions in Node.js:Difference is easy to spot:But there is a catch: with this new I/O approach it is impos",
    "summary": "**Zig's Swirling Rainbow of Function Coloring: Now with I/O!**  \nThe programming language Zig\u2014famously not satisfied with existing shades of complexity\u2014has now introduced an innovative way to make your functions as colorful as a unicorn's mane. In a riveting new blog post, Loris Cro stumbled upon a groundbreaking solution to async I/O that totally and irrevocably solves function coloring, a problem that absolutely nobody outside of a heated Hacker News thread thought needed solving. Commenters, dazzled by the potential to replace one keyword with another, wax lyrical about how this changes everything in their stackless coroutine-filled dreams. Meanwhile, in the real world, the rest of us are left wondering if we now need to pass an `io` token to our morning coffee routine to get it to brew asynchronously. \ud83c\udf08\ud83d\udd27"
  }
]