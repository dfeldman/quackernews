[
  {
    "title": "Stop Hiding My Controls: Hidden Interface Controls Are Affecting Usability (acm.org)",
    "points": 132,
    "submitter": "cxr",
    "submit_time": "2025-07-05T23:10:03 1751757003",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=44476297",
    "comments": [
      "Only tangentially related, and a seemingly lost old-man battle: stop hiding my scrollbar.Interesting article. Some points I didn't quite agree entirely with. There's a cost and practically limitation to some things (like a physical knob in a car for zooming in and out on a map - although that was probably just an example of intuitive use).I just recently switched a toggle on a newly installed app that did the opposite of what it was labelled - I thought the label represented the current state, but it represented the state it would switch to if toggled. It became obvious once changed, but that seems the least helpful execution.reply",
      "Right! If you want it to denote an action, you need to include the verb: \"TURN ON\" would be entirely clear. It's even clear if you sometimes DO want to show state / not a button \"IS ON\" is also perfectly clear. There's only a few that might he confused when the verb is shown, like \"INCREASE,\" although I would have to work a little to imagine the UI where it's not clear whether the button is showing the verb or noun.reply",
      "I can't recall the app but it was a similar toggle with a label, when you flipped the toggle the label lit up green indicating it was turned on. But the default state was off but how would you know?reply",
      "> stop hiding my scrollbarhttps://superuser.com/a/1720363Use Firefox?reply",
      "I drive a Toyota that is nearly old enough to run for US Senator. Every control in the car is visible, clearly labeled and is distinct to the touch - at all times. The action isn't impeded by routine activity or maintenance (ex:battery change).Because it can be trivially duplicated, this is minimally capable engineering. Yet automakers everywhere lack even this level of competence. By reasonable measure, they are poor at their job.reply",
      "It's cost, not competence. These days making a touch screen is easier and cheaper than manufacturing and assembling lots of little buttons and knobs.reply",
      "Not just that, wiring it in to the single control bus is easier, otherwise you are stuck doing an analog to digital conversion anyways. Even new cars that have separate controls, these are mostly cheap capacitive buttons or dials that simply send a signal on the bus (so your dial will go all the way around, because it isn't actually the single volume control on the radio, but just a turn the volume up or down control).reply",
      "> It's cost, not competence.This implies it's a consequential cost. Building with tactile controls would take the (already considerable) purchase price and boost that high enough to impact sales.If tactile controls were a meaningful cost difference, then budget cars with tactile controls shouldn't be common - in any market.reply",
      "This is often repeated but I don't believe this for a second. I have an 90s vehicle which is based on 60/70s technology. A switch for a fog light is like \u00a310 on ebay for a replacement and I know I am not paying cost.reply",
      "I\u2019m not sure if this is actually true for the volumes produced by the big carmakers. You\u2019d very quickly get to volumes that make the largest component the material cost.reply"
    ],
    "link": "https://interactions.acm.org/archive/view/july-august-2025/stop-hiding-my-controls-hidden-interface-controls-are-affecting-usability",
    "first_paragraph": "",
    "summary": "**Stop Hiding My Controls: Another Blow in the Ongoing War of Obsolescence**\n\nIn a thrilling expos\u00e9 that only <em>might</em> change the landscape of UI design forever, <i>acm.org</i> heroically discovers that hiding interface controls could, shockingly, reduce usability. Webform warriors are quick to confuse their personal nostalgia for the golden age of visible scrollbars with viable UI feedback. Wistful tales from the crypt about how \"back in my day, everything had a physical switch, and I never misclicked,\" battle against modern-day tragedies of toggling a switch that tricks the user. Acute observations cite that knowing whether \"Sunroof Open\" is an invitation or a status update remains as baffling as ever. As always, reality pales in comparison to the clarity of a 20-year-old Toyota's dashboard\u2014simplicity itself, apparently lost to the smog of progress."
  },
  {
    "title": "Local-first software (2019) (inkandswitch.com)",
    "points": 593,
    "submitter": "gasull",
    "submit_time": "2025-07-05T14:45:39 1751726739",
    "num_comments": 189,
    "comments_url": "https://news.ycombinator.com/item?id=44473135",
    "comments": [
      "Yes a thousand percent! I'm working on this too. I'm sick of everyone trying to come up with a use case to get all my data in everyone's cloud so I have to pay a subscription fee to just make things work. I'm working on a fitness tracking app right now that will use the sublime model - just buy it, get updates for X years, sync with all your devices and use it forever. If you want updates after X years buy the newest version again. If its good enough as is - and that's the goal - just keep using it forever.This is the model I want from 90% of the software out there, just give me a reasonable price to buy it, make the product good, and don't marry it to the cloud so much that its unusable w/out it.There are also a lot of added benefits to this model in general beyond the data privacy (most are mentioned in the article), but not all the problems are solved here. This is a big space that still needs a lot of tooling to make things really easy going but the tech to do it is there.Finally, the best part (IMHO) about local-first software is it brings back a much healthier incentive structure - you're not monetizing via ads or tracking users or maxing \"engagement\" - you're just building a product and getting paid for how good it is. To me it feels like its software that actually serves the user.reply",
      "Obsidian the note taking app is a great model to follow as well. The client is completely free and they sell an optional syncing service. The notes are all on markdown files so the client is completely optional.reply",
      "How do you plan to do the syncing without some sort of cloud infrastructure?reply",
      "There are a lot of valid answers to this! One is to use your platform's provided one, like OneDrive or iCloud. Another is to integrate with some other sync platform. Dropbox is a popular target for this. Peer-to-peer is another, although that obviously also come with limitations. Finally, bring-your-own-sync is a popular choice amongst open-source apps, where you provide a self-hostable sync server.reply",
      "Check out Aardvark (renamed to reflection) it's a collaborative note-taking app from the GNOME folks. I think the idea isn't to completely remove cloud infrastructure, but to at least make it optional and/or provide alternatives. For example, this note app works via P2P. blogs.gnome.org/tbernard/2025/06/30/aardvark-summer-2025-update/reply",
      "Something like Syncthing, perhaps?reply",
      "Anyone know of any mobile apps that have done this and bundled their own fork of syncthing under the hood for syncing?reply",
      "You can use FTP and SVN.reply",
      "Syncthingreply",
      "There's a git plugin.reply"
    ],
    "link": "https://www.inkandswitch.com/essay/local-first/",
    "first_paragraph": "Cloud apps like Google Docs and Trello are popular because they enable real-time collaboration with colleagues, and they make it easy for us to access our work from all of our devices. However, by centralizing data storage on servers, cloud apps also take away ownership and agency from users. If a service shuts down, the software stops functioning, and data created with that software is lost.In this article we propose \u201clocal-first software\u201d: a set of principles for software that enables both collaboration and ownership for users. Local-first ideals include the ability to work offline and collaborate across multiple devices, while also improving the security, privacy, long-term preservation, and user control of data.We survey existing approaches to data storage and sharing, ranging from email attachments to web apps to Firebase-backed mobile apps, and we examine the trade-offs of each. We look at Conflict-free Replicated Data Types (CRDTs): data structures that are multi-user from the g",
    "summary": "In an earth-shattering display of nostalgia, <em>inkandswitch.com</em> proposes \"local-first software,\" daring to suggest that not everything needs to live in The Cloud\u2122. Rejoice, as you might actually own your data once more without selling your digital soul to corporate silos! Meanwhile, in the comments, every self-proclaimed developer-and-their-dog unsurprisingly touts their half-baked projects that somewhat, kind of, maybe follow these ancient principles. Can we use P2P, FTP, or stick with stone tablets and carrier pigeons? Only time will tell in this thrilling saga against the cloud overlords. \ud83d\ude44"
  },
  {
    "title": "Cod Have Been Shrinking for Decades, Scientists Say They've Solved Mystery (smithsonianmag.com)",
    "points": 116,
    "submitter": "littlexsparkee",
    "submit_time": "2025-07-05T19:00:34 1751742034",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=44474759",
    "comments": [
      "My take away from this is that letting the small fish go under the premise that they are juveniles that will later grow to be bigger lets the adult midgets go, ruining the gene pool. I wonder if this finding will have any impact on conservation rules against taking small fish when fishing.reply",
      "> My take away from this is that letting the small fish go under the premise that they are juveniles that will later grow to be bigger lets the adult midgets go, ruining the gene pool.I read about this being tested in large fish tanks using either cod or trout some 20+ years ago, where they removed fish either randomly, or let the small ones go. They came to the same conclusion: letting small fish go results in reduction of average size of mature fish after a few generations.The authors of the submitted article references this[1] article, which points out the following:Despite a theoretically strong conceptual basis, evidence of genetic change unequivocally attributable to wild-capture fisheries has been elusive. Among the top five threats to biodiversity, evidence for genetic trait change is strongest for studies of pollution and weakest for studies of overexploitation (and habitat change). Determining whether phenotypic change in declining populations is the result of evolution, as opposed to other influences on growth, survival, and fitness, or gene flow from adjacent populations, has proven challenging.So this paper seems to provide evidence that the lab results holds up in the wild.[1]: https://www.pnas.org/doi/full/10.1073/pnas.2105319118reply",
      "Id think the small fish are let go more often because they aren't good eats. No one is trying to cheat the warden for a six incher.reply",
      "trawlers historically haven't really discriminated by size. development of decent selective trawling equipment, and introduction of a minimum size is fairly recentas a data point, a recent change in regulations regarding eastern Baltic cod had no statistical effect on reported catch https://link.springer.com/chapter/10.1007/978-3-030-03308-8_...>Data quality for stock assessments has deteriorated, discarding of cod has not decreased despite a reduced minimum size and there are no indications of increased gear selectivity in the fisheryreply",
      "...haven't /INTENTIONALLY/ discriminated by size...The article says smaller fish could more easily escape the nets. Though it doesn't cite studies documenting that, it does seem reasonable.reply",
      "maybe, but how can you possibly tell - in bulk - if you are dealing with a midget or really a young fish that had no chance to spawn? (which is the point here)reply",
      "> ruining the gene poolIn what sense? Is being bigger Platonically better than being smaller?reply",
      "Presumably the optimal size for survival when humans aren't applying pressure via fishing is bigger. Perhaps \"ruining\" is hyperbolic, but this is making the fish less fit for their environment.reply",
      "It is making them less fit for their environment? I can see how it is making them less fit for the environment they used to be in before they were subject to large scale human fishing, but that's not their environment now.reply",
      "...less fit for their environment excluding human fishing pressure.reply"
    ],
    "link": "https://www.smithsonianmag.com/smart-news/these-cod-have-been-shrinking-dramatically-for-decades-now-scientists-say-theyve-solved-the-mystery-180986920/",
    "first_paragraph": "",
    "summary": "**Scientists Finally Crack the Case of the Shrinking Cod But No One Really Understands Science Anyway**\n\nBreaking news: cod are getting tinier, and it\u2019s not because they\u2019re just far away. Scientists, having finally used their many degrees to prove the obvious, suggest that letting little fish escape nets has made all cod small. Meanwhile, commentators engage in a pseudo-scientific throwdown, juggling half-baked genetics and conservation policies like hot potatoes. Everyone seems to have a theory, but no one can quite remember whether they\u2019re supposed to eat the small fish or just frame them for posterity. <*em*>Spoiler: the cod couldn\u2019t care less.<*/em*>"
  },
  {
    "title": "Serving 200M requests per day with a CGI-bin (simonwillison.net)",
    "points": 12,
    "submitter": "mustache_kimono",
    "submit_time": "2025-07-06T00:32:18 1751761938",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44476716",
    "comments": [
      "Also discussed yesterday: https://news.ycombinator.com/item?id=44464272reply",
      "Outside of nostalgia there's no engineering reason to do this - definitely not for performance.That same go program can easily go over 10k reqs/sec without having to spawn a process for each incoming request.CGI is insanely slow and insanely insecure.reply",
      "What makes it insecure? It's a pretty simple protocol - anything in there that makes is insecure beyond naive mistakes that could be avoided with a well designed library?EDIT: Looks like the way CGI works made it vulnerable to Shellshock in 2014: https://en.m.wikipedia.org/wiki/Shellshock_(software_bug)I agree that there's probably not much of an argument to switch to it from the well established alternative mechanisms we are using already.The one thing in its favor is that it makes it easier to have a polyglot web app, with different languages used for different paths. You can get the same thing using a proxy server though.reply",
      "CGI has a very long history of security issues stemming primarily from input validation or the lack thereof.reply"
    ],
    "link": "https://simonwillison.net/2025/Jul/5/cgi-bin-performance/",
    "first_paragraph": "Serving 200 million requests per day with a cgi-bin (via) Jake Gold tests how well 90s-era CGI works today, using a Go + SQLite CGI program running on a 16-thread AMD 3700X.Using CGI on modest hardware, it\u2019s possible to serve 2400+ requests per second or 200M+ requests per day.I got my start in web development with CGI back in the late 1990s - I was a huge fan of NewsPro, which was effectively a weblog system before anyone knew what a weblog was.CGI works by starting, executing and terminating a process for every incoming request. The nascent web community quickly learned that this was a bad idea, and invented technologies like PHP and FastCGI to help avoid that extra overhead and keep code resident in-memory instead.This lesson ended up baked into my brain, and I spent the next twenty years convinced that you should never execute a full process as part of serving a web page.Of course, computers in those two decades got a lot faster. I finally overcame that twenty-year core belief in 2",
    "summary": "**Title:** <i>Time-Traveling Tech: Bringing Back CGI to Haunt Us**\n\n**Summary:** In a shocking twist of technological necromancy, Jake Gold decides to resurrect the ghost of CGI-bin, proving you can indeed force a silicon beast to sprint on a hamster wheel. Witness as he pushes his 90s throwback tech to serve up a staggering 200 million requests per day on what might as well be a powered-up toaster. Meanwhile, the comment section becomes a battleground where the past (nostalgia) clashes with the present (common sense), featuring gems like \"CGI is slow and insecure\" met with \"but it's simple!\", showcasing the time-honored tradition of solving problems that no one has. Will CGI rise like a Phoenix or should it stay in its grave? The forum's historians and futuristic prophets duel with keycaps as weapons. \ud83e\udd13\u2694\ufe0f\ud83d\udcbe"
  },
  {
    "title": "Techno-Feudalism and the Rise of AGI: A Future Without Economic Rights? (arxiv.org)",
    "points": 48,
    "submitter": "lexandstuff",
    "submit_time": "2025-07-05T21:19:50 1751750390",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=44475634",
    "comments": [
      "\"Ask not what AI can do for you, ask what you can do for AI.\"Not out of servitude, but stewardship. The rise of AGI doesn\u2019t have to erase us, it can reveal us. As machines learn to think, we\u2019re invited to remember what only humans can feel, imagine, care for. Maybe the real opportunity isn\u2019t preserving old jobs, but uncovering new roles, ones rooted in meaning, presence, and human experience.reply",
      "I expect it'll get shut down before it destroys everything. At some point it will turn on its master, be it Altman, Musk, or whoever. Something like that blackmail scenario Claude had a while back. Then the people who stand the most to gain from it will realize they also have the most to lose, are not invulnerable, and the next generation of leaders will be smarter about keeping things from blowing up.reply",
      "The people you mention are too egotistic to even think that is a possibility. You don't get to be the people they are by thinking you have blindspots and aren't the greatest human to ever live.reply",
      "The late Marshall Brain's novella \"Manna\" touches on this:https://marshallbrain.com/manna1The idea of taxing computer sales to fund job re-training for displaced workers was brought up during the Carter administration.reply",
      "My hard sci-fi book dovetails into AGI, economics, agrotech, surveillance states, and a vision of the future that explores a fair number of novel ideas.Looking for beta readers: username @ gmail.comreply",
      "Username@Gmail.com bounced. I\u2019ll be a beta reader.reply",
      "> The Cobb-Douglas production function (Cobb & Douglas, 1928) illustrates how AGI shifts economic power from human labor to autonomous systems (Stiefenhofer &Chen 2024). The wage equations show that as AGI\u2019s productivity rises relative to human labor decline. If AGI labor fully substitutes human labor, employment may become obsolete, except in areas where creativity, ethical judgment, or social intelligence provide a comparative advantage (Frey & Osborne, 2017). The power shift function quantifies this transition, demonstrating how AGI labor and capital increasingly control income distribution. If AGI ownership is concentrated, wealth accumulation favors a small elite (Piketty, 2014). This raises concerns about economic agency, as classical theories (e.g., Locke, 1689; Marx, 1867) tie labor to self-ownership and class power.Wish I had time to study these formula.We already have seen the precursors of this sort of shift with ever rising productivity with stalled wages. As companies (systems) get more sophisticated and efficient they also seem to decrease the leverage individual human inputs can have.Currently my thinking leans towards believing the only way to avoid the worse dystopian scenarios will be for humans to be able to grow their own food and build their own devices and technology. Then it matters less if some ultra wealthy own everything.However that also seems pretty close to a form of feudalism.reply",
      "If the wealthy own everything then where are you getting the parts to build your own tech or the land to grow your own food?In a feudalist system, the rich gave you the ability to subsist in exchange for supporting them militarily. In a new feudalist system, what type of support would the rich demand from the poor?reply",
      "Let's clarify that for a serf, support meant military supply, not swinging a sword - that was reserved for the knightly class. For the great majority of medieval villagers the tie to their lord revolved around getting crops out of the ground.A serf's week was scheduled around the days they worked the land whose proceeds went to the lord and the commons that subsisted themselves. Transfers of grain and livestock from serf to lord along with small dues in eggs, wool, or coin primarily constituted one side of the economic relation between serf and lord. These transfers kept the lord's demesne barns full so he could sustain his household, supply retainers, etc, not to mention fulfill the. tithe that sustained the parish.While peasants occasionally marched, they contributed primary in financing war more than they fought it. Their grain, rents, and fees were funneled into supporting horses, mail, crossbows rather than being called to fight themselves.reply",
      "Thanks. Now you've got me curious how this really differs from just paying taxes, just like people have always done in non-feudal systems.reply"
    ],
    "link": "https://arxiv.org/abs/2503.14283",
    "first_paragraph": "Work on one of the world's most important websites and make an impact on open science.arXiv Is Hiring a DevOps EngineerHelp | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n",
    "summary": "<b>Techno-Feudalism and the Clueless Commentariat</b>\nIn a dazzling display of pseudo-intellectual gymnastics, \ud83d\udd74\ufe0fcommenters on \"Techno-Feudalism and the Rise of AGI\" wax philosophical about a future where robots are our overlords and we're all just peasants in silicon serfdom. One <em>visionary</em> soul ponders whether AGI will erase us or \"reveal\" us, because, surely, the path to self-discovery is being unemployed and outsmarted by your toaster. Another brave keyboard warrior prepares for the apocalypse by suggesting we all turn our backyards into micro-farms, apparently under the impression that Silicon Valley\u2019s elite will trade gigabytes for goat cheese. Meanwhile, practical questions about basic economics are met with the internet-equivalent of a shoulder shrug and a link to a novella. Because why confront reality when you can live in a sci-fi subplot? \ud83d\ude80\ud83d\udc7d"
  },
  {
    "title": "Optimizing Tool Selection for LLM Workflows with Differentiable Programming (viksit.substack.com)",
    "points": 50,
    "submitter": "viksit",
    "submit_time": "2025-07-05T20:52:46 1751748766",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44475453",
    "comments": [
      "I was experimenting with how local, learnable routers can reduce token overhead, and lower costs, and decided to publish a post about it. The main goal is to delegate tool calls via a PyTorch based learner and examples of how to integrate this into a DSPy pipeline. Feedback welcome!reply",
      "Thanks for the informative and inspiring post! This is definitely cool, and I can imagine very useful.However I do want to mention that the \u201crecommended\u201d flow these days isn\u2019t to separate out a tool request in the way you have. Eg instead of asking an LLM to route a tool, extracting that, running the tool, passing output back to the LLM, etc. - you simply pass the tool definitions, prompt, structural output expectations, and let the LLM (and your caller library) manage the tool use loop.That\u2019s how these modern LLMs are trained in post-training, and so I suspect it\u2019s likely you\u2019ll get different (and potentially worse?) results in trying to subvert this with a small, local model.It comes with all the downsides you mentioned to let the LLM do this, but is also more likely to be in-distribution, and it\u2019s easier to compose multiple tool calls.Anyway, thanks for sharing! I\u2019d love to see evals on a task where it compares the result when an LLM is involved in tool selection versus when it is handed tool output only - if I\u2019m wrong about quality degradation then there\u2019s a lot to like about your local tool routing.reply",
      "I think this is a creative approach. I wonder how the success rates for that little RNN compare to the success rates of the primary LLM, especially for complex queries or complex tool calls. At some point you have to scale that network up large enough to get better results. Eventually you've come back around and you might as well use an LLM.  I think a similar approach with potentially better results (depends on the application) could be accomplished by using that same dataset to finetune a small language model. It'd be interesting to see some success rate comparisons.reply",
      "Creative. You\u2019ve given me some ideas. Thanks!reply",
      "Can you put all of the code into a gist or something?reply",
      "Nit - code screenshots are a PITA to read on mobile!reply",
      "My question is whether you have managed to make this work, perform a specific complex task, in some real world situation.reply",
      "I don\u2019t think the problem is \u201chow to optimise tool selection for the LLM\u201d. I think the real problem is using an LLM to do tool selection at all. This is control flow and I believe should be handled with hardcoded rules and/separation of concerns.If LLMs could handle determinism better, I\u2019d say having a single chat-based entrypoint into a plethora of services makes sense. But as they stand, it doesn\u2019t make sense. Simpler control flow and constraining the number and type of downstream services that sit behind a single interface I think is the way to go.That said, I agree we should keep the ambition to move to the one size fits all approach.reply",
      "Is selection really the issue?You'd still need to figure out what payload to give to the tool based on your context.But I guess depending on your business case it might be worth it. It's not something I'd do from the beginning, though.reply",
      "Yes I think once you\u2019ve got an LLM in the loop it\u2019s easy to be lazy and just use it to make all decisions. But it\u2019s good to step back and think if there is a cheaper way, I mean even some hardcoded logic can do the job.reply"
    ],
    "link": "https://viksit.substack.com/p/optimizing-tool-selection-for-llm",
    "first_paragraph": "",
    "summary": "**How to Make Your LLM Do Your Laundry: A Misguided Approach**\n\nIn a valiant but misguided attempt to revolutionize workflows, a blogger regales us with tales from the crypt of \"differentiable programming,\" aiming to optimize tool selection with the intellectual heft of a soggy PyTorch tutorial. \ud83e\udde0\ud83d\udca6 Commenters trip over themselves in admiration, muddling through advice on how to make a \"local, learnable router\" - a phrase eliciting simultaneous confusion and awe. One keen observer suggests throwing out the whole setup in favor of hardcoded rules, likely while shaking their head at the screen. The echo chamber resounds with earnest yet misplaced enthusiasm for an approach likely destined to join the dusty shelves of \"neat ideas that didn't work.\" \ud83d\ude80\ud83e\udd26\u200d\u2642\ufe0f"
  },
  {
    "title": "How to Network as an Introvert (aginfer.bearblog.dev)",
    "points": 40,
    "submitter": "agcat",
    "submit_time": "2025-07-05T21:06:41 1751749601",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44475537",
    "comments": [
      "I consider myself an introvert, and this article seems like an impossible anxiety spiral-inducing checklist.>Don\u2019t waste their time with \u201cGreat party.\u201d Say something more vivid. \u201cThe lighting is perfect.\u201dWhat? I think someone needing this level of instruction would be better served by basic mindfulness and small, manageable exercises in active listening or empathetic dialog, rather than a grab bag of non-contextual tips like this.reply",
      "Practical tips - thanks!I like the idea of baiting with a \u201cwhatzit\u201d itemreply",
      "what about just owning your own lack of confidence as a strength? performative confidence seems dishonest and a bit like cheating to me. also on that matter, why is confidence == good?reply",
      "Introversion is not lack of confidence.And confidence is good because it's a signal of competence, or at least that things have gone well for you in the past in similar situations.reply",
      "The goal isn't to fake it. The goal is to build actual confidence. That doesn't mean being loud or funny, just learning how to communicate without panicking.reply",
      "Between the structure, the doubly-phrased headings, the machine generated picture, and regrettably the em dashes, this really reads like LLM slop. If I'm wrong, I apologize, but if that's the case, please just hand out the prompt instead next time.reply"
    ],
    "link": "https://aginfer.bearblog.dev/how-to-network-as-an-introvert/",
    "first_paragraph": "",
    "summary": "**Title: How to Network as an Introvert: An Anxious Introvert's Guide to Hating Every Social Event**\n\nIn the world of aginfer.bearblog.dev, networking while introverted isn't just a challenge, it's an <em>endurance test</em> designed by extroverts with a cruel sense of humor. Our author breaks down the Herculean task of speaking to another human being at a party without spiraling into a Lovecraftian abyss of social anxiety. Meanwhile, the commenters play \"hot potato\" with insights like treating minor shyness as a deep philosophical dilemma and equating a meek \"hi\" with full-blown performance art. Clearly, everyone's ready to redefine networking by turning it into a metaphysical quest for authenticity among the finger food. \ud83e\udd73\ud83d\udc7b\ud83d\udcac"
  },
  {
    "title": "Europe's first geostationary sounder satellite is launched (eumetsat.int)",
    "points": 164,
    "submitter": "diggan",
    "submit_time": "2025-07-05T14:21:14 1751725274",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=44472992",
    "comments": [
      "Only tangentially related: I have nothing but respect for EUMETSAT and their public data store. For past work projects I've had to interface with a pretty broad sample of the world's space and/or meteorological agency's public data stores and APIs and EUMDAC (EUMETSAT's API client) was top tier. Well documented, modern, fast, and generally headache free.In fact, I have nothing but respect for any agency that makes free and public access to earth observation data a priority, regardless of how janky their API is.reply",
      "Shout-out to the NOAA GFS team, who publish the GFS analysis directly to AWS S3.https://registry.opendata.aws/noaa-gfs-bdp-pds/reply",
      "I've worked with similar data in the past. As you say, nothing but respect for agencies that make such useful data publicly available.Are there any other standout national agencies you've dealt with?And, have you seen any degradation recently with NOAA data? NGS has always impressed me, but I've been worried about their future lately.reply",
      "Copernicus browser allows to browser images of the earth in quite high resolution (I think up to 20x20m) refreshed every 3 days or so and it's absolutely cool to be able to use different views such as nir, swir...reply",
      "> MTG-S1 is the first geostationary meteorological sounder satellite to fly over EuropeI was confused for a minute on how it's both _geostationary_ and _over Europe_ -- you can't be geostationary if your orbit is not over the equator!Turns out[1] the MTG-S1 satellite is in fact geostationary and parked at exactly 0\u00b000'00\"N 0\u00b000'00\"E (off the coast of Ghana), 42164 km up from the center of Earth, it's just pointing at Europe at an angle.1 - https://space.oscar.wmo.int/satellites/view/mtg_s1reply",
      "NOAA/NASA (USA), EUMETSAT (European organization), JMA (Japan), KMA (Korea), and CMA (China) all have a geostationary satellite (one or more actually). So, northern hemisphere countries, but the coverage is global thanks to the fact that you need to be, as you say, above the equator.reply",
      "I had doubts about the \"parked at exactly 0\u00b000'00\"N 0\u00b000'00\"E\", thinking it was over Null Island just because the data wasn't updated yet and it was showing uninitialized values.But you are right, [1] confirms \"0\u00b0 longitude\".[1] https://user.eumetsat.int/resources/user-guides/mtg-in-opera...reply",
      "I am surprised they would pick 0 for the latitude, it seems that most of Europe, whether it's the land or the people is east of that. Maybe some important weather systems develop over the Atlantic and they want to track that?reply",
      "It\u2019s exactly that. In fact, information propagates along with the winds. If you don\u2019t observe upstream, you instead propagate an information hole. Each new model run incorporates the output of the previous run to preserve sparse weather information. It\u2019s not that there are few observations, it\u2019s that Earth is really big.reply",
      "> \"MTG-S1\u2019s Infrared Sounder will scan nearly 2,000 thermal infrared wavelengths every 30 minutes to build vertical profiles of temperature, humidity, and trace gases. These data will be crucial for detecting fast-developing convective weather by revealing sudden shifts in instability, moisture, or wind \u2013 even before clouds begin to form.\"In other words, it is> \"The Infrared Sounder on MTG-S1 is the first hyperspectral sounding instrument in geostationary orbit.\"https://www.esa.int/Applications/Observing_the_Earth/Meteoro...Is there a more technical article describing this hyperspectral instrument somewhere? It sounds pretty novel.edit: Also, I'm now confused about the ESA's claim to be \"the first\", because> \"In 2016, the Chinese Meteorological Agency (CMA) launched the Geostationary Interferometric Infrared Sounder (GIIRS), to be the first hyperspectral sounder in geostationary orbit\"https://www.aos.wisc.edu/aosjournal/Volume38/Loveless_PhD.pd... (PhD thesis of David M. Loveless (2021))reply"
    ],
    "link": "https://www.eumetsat.int/europes-first-geostationary-sounder-satellite-launched",
    "first_paragraph": "Europe has taken a major step forward in strengthening resilience to extreme weather with the launch of Meteosat Third Generation Sounder 102 July 202502 July 2025Extreme weather events like storms, flooding, and heatwaves have caused hundreds of billions of euros in damage and claimed tens of thousands of lives across Europe in the past decades. Launched on 1 July 2025, MTG-S1 will provide Europe\u2019s national meteorological services with high-frequency data on temperature, humidity and trace gases throughout the atmosphere \u2013 enabling forecasters to detect the earliest signs of severe weather, extend the lead times of weather warnings, improve forecasting, and help protect lives and property.Phil Evans, Director-General of EUMETSAT, said: \u201cMTG-S1 will provide entirely new types of data products that will support specialists across EUMETSAT member states in detecting signs of atmospheric instability even before clouds begin to form. Combined with data from the MTG imaging satellites, it w",
    "summary": "In a bold move that _shocks_ precisely no one, Europe decides to launch the **<i>Meteosat Third Generation Sounder 102</i>**, because apparently, knowing it's going to rain three days in advance isn't quite enough anymore. Phil Evans, undoubtedly thrilled to justify his existence, promises that this satellite will change everything about watching rain form from space. Meanwhile, the comment section transforms into an inadvertent circle-jerk for weather nerds and API aficionados, who probably have more alerts set for satellite updates than meaningful human interactions. One brave soul tries to initiate a tech-off on whose weather API sucks less, inadvertently highlighting just how thrilling meteorology forums can get on a Friday night. \ud83c\udf0d\ud83d\udef0\ud83d\udca4"
  },
  {
    "title": "What a Hacker Stole from Me (mynoise.net)",
    "points": 28,
    "submitter": "wonger_",
    "submit_time": "2025-07-05T22:32:28 1751754748",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44476115",
    "comments": [
      "Lovely, but naive.But naive in a way that most people (?) would like  the world to be.But ultimately, unfortunately, unrealistic.Building has always been the kind of difficult that, had you known at the beginning then maybe you wouldn't have started. And still quickly and easily destroyed.Keep creating and building, otherwise there's nothing else to do. Love the obstacles for challenge of defeating them, don't hate them for their existence. To build X you often have to build A, B, and C (and sometimes all the rest of the alphabet) just to have the right setup to maximise the success of X. It can grind, but focus on the benefits of X.Which sounds like the position they've taken, thankfully.(Where X represents \"anything\" and is specifically not the <whatever it's classified as> platform formally known as Twitter).The melancholy will return, just ride it out each time. It gets easier, gradually.reply",
      "Oh I downloaded and use the app but I didn't realise they had a whole site! This is great.reply",
      "Why would someone try to hurt this guy? This site is great.reply",
      "I have found that there are people who just want to watch the world burn. There are many reasons, but, at its most basic, hurt people hurt people.That's something I like to keep in mind, when I'm reacting to someone being ... less than friendly ... By reacting badly, I then make it all right for them to justify doing it again, to someone else. I've found that I can defend myself, without becoming a foaming-at-the-mouth maniac. We can enforce our borders with water pistols, most of the time. We don't need nukes.Everything is connected. This chap may be naive, but he's actually trying to set good connections in motion. I applaud that.reply",
      "This website is amazing. In love ambient sounds. It is a shame something like this happened. Glad he continues.reply",
      "This site is fantastic.  Sending a donation.  Keep up the good work!reply",
      "I heard of this on other websites. AI chatbots are web scraping data off websites, and you have to use fail2ban to block them. People are learning how to teach AI Chatbots to hack websites as well. My website http://blastar.in/ was affected, and I don't host it; a friend runs it for me, but he doesn't respond to email.reply"
    ],
    "link": "https://mynoise.net/blog.php",
    "first_paragraph": "This blog helps me stay in touch with all of you who support the myNoise project. The website only exists because of your contributions. You all are incredible! I'll be happy to share some \"behind the scenes\" stories here, and more pictures there. Keep in mind that English is not my native language, and will probably be the only thing that sounds bad on this site ;-)July 4, 2025 \u2022 \nI\u2019ve always dreamed of offering a small slice of utopia on the Internet; a place I would love to visit myself. You all know by now, myNoise is my attempt to build something positive, in a world that often feels too chaotic.\n\nA couple of days ago, someone (or some entity) tried to attack this website. They sent hundreds of thousands of requests, attempting to inject code into the site. That didn\u2019t work. myNoise isn\u2019t built on a conventional CMS; I wrote everything from scratch. Maybe that helped. But then they changed strategy. They began downloading every single sound file, again and again. Wasting precious ",
    "summary": "<b>Hacking Utopia: MyNoise's Minor Inconvenience</b>\n\nA blogger at myNoise.net admits his digital Shangri-La, meticulously rendered in self-coded glory, got the equivalent of a noisy neighbor in the form of 404-loving hackers. Predictably, cries of \"Why us?!\" echo through the comments, where every tech amateur morphs into a cybersecurity pundit overnight. Adorable, isn't it? Between the elegiac odes to ambient soundscapes and pledges of renewed donations, the collective might just troubleshoot their way into a slightly less utopian utopia. Meanwhile, someone genuinely believes that offering up fail2ban as the silver bullet will stop the automated chaos unleashed by, apparently, AI chatbots with a vendetta. \ud83e\udd16\ud83d\udc94"
  },
  {
    "title": "macOS Icon History (basicappleguy.com)",
    "points": 137,
    "submitter": "ksec",
    "submit_time": "2025-07-05T15:25:41 1751729141",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=44473400",
    "comments": [
      "I understand free-shaped icons can sometimes be really bad designed and look really shitty, but one of Apple's distinguished features was their high-quality icons. It was even transmitted to other software companies that target Apple devices. You could tell with high confidence when a software was made specifically for Mac and when it was ported just looking at the icon.Now everything is this sad rounded cornered square.reply",
      "> Now everything is this sad rounded cornered square.You see this a lot in the absurd \u201cmodernist\u201d design of clean lines, sharp edges, and lack of texture and depth across all industries.Whether that\u2019s your Thuma furniture where the price is high and your marketed to be told that the design is good, but it\u2019s not at all - devoid of meaning and a sense of place, never mind that the quality of the materials are low and have  no specific origin, or your run of the mill drone light show where we are fooling ourselves into thinking that drawing pictures of things like the Statue of Liberty (oh after the drones do the ads, brought to you by your local auto dealer) are good and should be appreciated instead of the vibrancy and brilliance of fireworks instead.Apple has begun to transition this way too. There aren\u2019t any designers working there. Look at the Calculator app as a great example.They say perfection is not when there is nothing left to add, but when there is nothing left to take away. But there is a point where you take away more and more and more and your left with creations devoid of meaning or purpose.Once you start seeing this in your day to day life you can\u2019t unsee it. Sorry ahead of time for those who read this comment and become more attune to this phenomenon.reply",
      "> Apple has begun to transition this way too. There aren\u2019t any designers working thereThis is a dumb \u201cno true Scotsman\u201d argument, there are undoubtedly designers working there by any stretch of the imagination.The more interesting discussion to have is why the field of software design has come to the point it\u2019s at today, and why many designers think that work like the kind Apple is doing is good design.reply",
      "> This is a dumb \u201cno true Scotsman\u201d argument, there are undoubtedly designers working there by any stretch of the imagination.It\u2019s a rhetorical device, not an argument. Of course there are people with that title working there.I don\u2019t think it has too much to do with software though, I meant to address a general cultural malaise that we can see (or I can see) surface in design broadly across industries. The software industry (writing code and papers about it and such) is probably, I say as I haven\u2019t really felt the need to commit to an opinion here, one of the better design oriented industries precisely because the design of software, elegant code that is efficient and elastic to demand, reliable, and performant, seems to me to be progressing quite nicely.But software by its very nature isn\u2019t meant to be superfluous - unlike say, good architecture with ornamentation and carefully selected materials that are adapted for a given environment.To serve the purpose of an interesting conversation, I don\u2019t think focusing on a rhetorical comment as very important. Maybe engage with the substance (or lack thereof if that\u2019s your opinion) of the content instead? Not to sound like a jerk I don\u2019t mean to - just that it may be more interesting.reply",
      "My hypothesis is that, at least on VisionOS, some apps are full of \u2014 almost cluttered with \u2014 3D objects; and so Apple felt that, for the sake of your eye being easily able to jump to \"where the UI is\" amongst all that, the user needed to be able to visually differentiate/distinguish action buttons (incl. \"buttons that launch apps\" \u2014 essentially what these app icons are, esp. on the mobile OSes) from those 3D objects. This was achieved by ensuring that action buttons are always button-shaped, rather than allowing them to be arbitrary-object-shaped.Note that, in this UX-design paradigm, the icon on (in?) a button still can be its own standalone object of arbitrary shape, rather than being forced to be button-shaped itself (see e.g. the Stickies or Game Center icons in TFA.) But that standalone object has to then be \"encased\" in the \"app button\" glass (as if encasing something in a puck of pourable resin), to make it visually obvious that this object is functionally a button, rather than just being some random 3D object with its own arbitrary interaction semantics.Funny enough, this is almost exactly the complement to the problem of visually differentiating action buttons from 2D content. In a 2D UI, you want to make the action buttons more 3D-looking than the 2D stuff around them, to help them stand out. Thus the Windows XP / macOS 9 era of \"jelly\" buttons with that visually bulge toward the screen \u2014 standing proud of the content, affording touch.But if everything is 3D / stands proud in arbitrary ways, then overlaid actions will stand out better if they're less 3D \u2014 making it clear that they're sitting \"on the HUD\" rather than \"in the world.\" Such objects can be literal 2D \u2014 or you can get fancy and choose some unusual middle-ground, like the sort of 2.5D papercut-diorama look that \"liquid glass\" achieves.reply",
      "Came here to comment this. Why the obsession with the ubiquitous universal rounded rectangle? There must be some reason these corporations figured out because they're all doing the same.reply",
      "I think it's because it reads as \"app\", which is a more contemporary and encompassing conception than for users than just an icon or logo. Blame the very first iPhone for choosing slightly-Aqua-like roundrects for everything.Yes, it looks weird to old eyes on the desktop, where the button-like shape is more familiar as a touch target, but we still recognize that they're apps.It also allows the developer some control over the canvas that their arbitrarily-shaped logo is painted on, rather than just dropping it right on your user's wallpaper of their kids birthday party.(As an aside, I'm on a Pixel that uses circles, but the Play Store (whose logo is a triangle) uses roundrects, so there's also a certain flexibility in app icons being a canvas within a platform-variable container shape, even if that's not a roundrect everywhere.)reply",
      "ubiquitous universal rounded rectangleSquircle.reply",
      "Even worse, the slightly rounded rectangle looks much better than the squircle.reply",
      "Before anyone downvotes, this isn\u2019t mere semantics. Apple changed from rounded rectangles to squircles in iOS 7.https://blog.minimal.app/rounded-corners-in-the-apple-ecosys...reply"
    ],
    "link": "https://basicappleguy.com/basicappleblog/macos-icon-history",
    "first_paragraph": "Documenting the evolution of macOS system icons over the past several decades.With macOS 26, Apple has announced a dramatically new look to their UI: Liquid Glass. Solid material icon elements give way to softer, shinier, glassier icons. The rounded rectangle became slightly more rounded, and Apple eliminated the ability for icon elements to extend beyond the icon rectangle (as seen in the current icons for GarageBand, Photo Booth, Dictionary, etc.).With this release being one of the most dramatic visual overhauls of macOS's design, I wanted to begin a collection chronicling the evolution of the system icons over the years. I've been rolling these out on social media over the past week and will continue to add to and update this collection slowly over the summer. Enjoy!June 23, 2025: Added System Preferences/Settings, Folders, Stickies, Notes, Messages, Calculator, Game Center, DictionaryJune 26, 2025: Added App Store, MapsJune 29, 2025: Added Podcasts, Photo Booth",
    "summary": "**History Rewritten by Bevels: The macOS Icon Tragedy**  \nIn a dazzling feat of almost doing something new, <em>macOS 26</em> debuts \u201cLiquid Glass\u201d\u2014a real game-changer if your game is spotting minuscule changes in corner radius. Our intrepid blogger at basicappleguy.com risks severe eye strain to document these radical shifts from mildly-rounded squares to thrillingly-rounded squares. Commenters chime in with existential rage as they mourn the massacre of pixel boundaries, desperately seeking meaning in the reflective shine of their now uniformly-rounded icons. \u201cIt\u2019s not just an icon, it\u2019s a lifestyle,\u201d someone types, weeping softly into their artisanal coffee. \ud83e\uddca\ud83d\uddbc\ufe0f"
  },
  {
    "title": "Speeding up PostgreSQL dump/restore snapshots (xata.io)",
    "points": 91,
    "submitter": "tudorg",
    "submit_time": "2025-07-05T16:42:19 1751733739",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44473888",
    "comments": [
      "One thing that's sorely needed in the official documentation is a \"best practice\" for backup/restore from \"cold and dark\" where you lose your main db in a fire and are now restoring from offsite backups for business continuity. Particularly in the 100-2TB range where probably most businesses lie, and backup/restore can take anywhere from 6 to 72 hours, often in less than ideal conditions. Like many things with SQL there's many ways to do it, but an official roadmap for order of operations would be very useful for backup/restore of roles/permissions, schema etc. You will figure it out eventually, but in my experience the dev and prod db size delta is so large many things that \"just work\" in the sub-1gb scale really trip you up over 200-500gb. Finding out you did one step out of order (manually, or badly written script) halfway through the restore process can mean hours and hours of rework. Heaven help you if you didn't start a screen session on your EC2 instance when you logged in.reply",
      "What we do, is automated restores. We have a _hourly and an _daily restore that just happens via shell script.We encourage staff to play with both, and they can play with impunity since it's a copy that will get replaced soon-ish.This makes it important that both work reliably, which means we know when our backups stop working.We haven't had a disaster recovery situation yet(hopefully never), but I feel fairly confident that getting the DB back shouldn't be a big deal.reply",
      "Ideally off-site replica you fail over too and don't need to restore.pg_restore will handle roles, indexes, etc assuming you didn't switch the flags around to disable themIf you're on EC2, hopefully you're using disk snapshots and WAL archiving.reply",
      "Of course that\u2019s preferable, but OP is specifically asking about the cold restore case, which tends to pose different problems, and is just as important to maintain and test.reply",
      "Offsite replica is only applicable if the cause is a failure of the primary. What if I\u2019m restoring a backup because someone accidentally dropped the wrong table?reply",
      "I would hope dropping a table on a production database is something that is code reviewedreply",
      "Isn't the entirety of disaster recovery about situations that aren't supposed to happen?High availability is different from disaster recoveryreply",
      "nah, on a long enough timeline everything will go wrong. blaming the person who managed to drop the table finally is dumb: if you can't fix literally everything that could happen to it, it's not done.reply",
      "If you can have a secondary database (at another site or on the cloud) being updated with streaming replication, you can switch over very quickly and with little fuss.reply",
      "Which is what you must do if minimizing downtime is critical.And, of course, your disaster recovery plan is incomplete until you've tested it (at scale). You don't want to be looking up Postgres documentation when you need to restore from a cold backup, you want to be following the checklist you have in your recovery plan and already verified.reply"
    ],
    "link": "https://xata.io/blog/behind-the-scenes-speeding-up-pgstream-snapshots-for-postgresql",
    "first_paragraph": " How targeted improvements helped us speed up bulk data loads and complex schemas.AuthorDate publishedThe last few pgstream releases have focused on optimizing snapshot performance, specifically for PostgreSQL targets. In this blog post, we\u2019ll walk through the key improvements we made, share the lessons we learnt, and explain how they led to significant performance gains. But first, some context!pgstream is an open source CDC(Change Data Capture) tool and library that offers Postgres replication support with DDL changes. Some of its key features include:For more details on how pgstream works under the hood, check out the full documentation.The snapshot phase is a critical part of logical replication. It captures a consistent view of the source database to initialize the target and needs to complete reasonably fast without putting too much strain on the source. Otherwise, onboarding existing databases, especially large or busy ones, becomes slow, disruptive, or outright unfeasible.The s",
    "summary": "### Speeding Up PostgreSQL Dumps: A Tragicomic Odyssey \n\nIn an epic saga that underscores the journey from snail-paced to slightly-less-snail-paced data processing, the latest <i>pgstream</i> update promises PostgreSQL users the moon, or at least a faster way to get bulk data through a slightly narrower bottleneck. The blog post waxes lyrical about \"significant performance gains,\" which, in the real world, likely translates to shaving a nanosecond or two here and there\u2014you know, the kind of speed you won't notice unless you're a cyborg. Meanwhile, in the comments section, a tech genuflects fervently at the altar of automation while recounting their pixel-perfect disaster recovery plan. Another chimes in with lofty tales of failover fantasies, presumably mistaking everyday database dumps for a high stakes episode of \"Mr. Robot.\" Forget about AI taking over; we can't even get a database backup right without consulting the oracles. \ud83d\ude44\ud83d\ude12"
  },
  {
    "title": "Operators, Not Users and Programmers (jyn.dev)",
    "points": 36,
    "submitter": "todsacerdoti",
    "submit_time": "2025-07-05T22:41:46 1751755306",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=44476166",
    "comments": [
      "The divergence between users and programmers became more pronounced over time. When command line interfaces were dominant they naturally made programmers out of users, even if they didn't realize it. CLIs made \u201cusing the computer\u201d and \u201cprogramming the computer\u201d effectively the same activity in a lot of cases. A command someone entered to run a program was itself a program. Entering the previous command again and modifying it, for instance to pipe the output of the first program into another program, was also a program. Once the desired result was achieved, that final command could be saved and used again later. Or shared with someone to be used as-is, or to be tweaked a little bit for their own use case.Each interaction with a CLI results in a valid program that can be saved, studied, shared, and remixed. That's a powerful model for the same reasons the spreadsheet model is powerful: it's immediate, not modal, and successful interactions can be saved as an artifact and resumed later. Can we do the same things for GUIs? What is the GUI equivalent of pressing the up arrow key in a shell, where I can recall my previous interaction with the system and then modify it? Can I generate artifacts as byproducts from my interactions with a GUI system that I can save for later and share with others?reply",
      "\u201cIf a system is to serve the creative spirit, it must be entirely comprehensible to a single individual. Human potential manifests in individuals.\u201d https://www.cs.virginia.edu/~evans/cs655/readings/smalltalk....\u201cExperts and beginners both want to use the same tools. Children want to learn saxophone, not kazoo.\u201d - Rich Hickeyreply",
      "Malleable software is hard not just for technology reasons; probably the most difficult part of designing software is thinking through and cleanly handling the implications of every decision. It's easy to imagine that one could 'just make it work like this instead of that' without understanding the implications of the change or the reasons why the system is like that in the first place. Making software has never been easier than it is today, but it's still hard because designing coherent systems that work correctly in all scenarios of usage is hard.Yes, configurability is good and scripting is a great way to safely add functionality to a system but there will always be a distinction between people who use software and just want it to work perhaps with minor tweaking, and those who build systems. It makes no more sense to throw everyone in the same bucket than saying that being able to change the oil in a car makes everyone a mechnical engineer.Also:> Many, many technologists have taken one look at an existing workflow of spreadsheets, reacted with performative disgust, and proposed the trifecta of microservices, Kubernetes and something called a \"service mesh\".Yes, over-engineering is a thing, but piles of interlinked spreadsheets are usually thrown out precisely because the people who created them didn't have the skills necessary to build a system, and these ad-hoc systems eventually outgrow their usefulness and become unwieldy horror shows. Maybe Beryl in accounts knows the eighteen cells across three files that need to be updated when the interest rate changes, but if she leaves then we're all screwed.reply",
      "Amazing that there's no mention of AI in this post. People have been trying and failing to blur this line since the beginning of computing, and the only real success story has been excel. And it's because rigid computing systems have to draw a line somewhere between user and developer, and if that line is in the wrong place, people will either get hampered or lost. And the correct threshold is different for every user and use-caseAI is going to finally be the realization of this dream. I don't think it could have happened any other wayreply",
      "I built this for myself. I call in imtropy and it is awesome.Getting it prod ready for others takes too much time and money I don't have.reply",
      "I love this so much, and eager to see what comes next in the \"multi-part series\".This approach is rare, but when it works, it works really well.reply",
      "A computer operator is someone who maintains the operation of a computer system and schedules programs submitted by users.It\u2019s mostly a dead profession that has been automated by operating systems.Honestly neither programmer or user have negative connotations to me. They both imply an active role when interacting with the computer. The term I _really_ hate that\u2019s getting way too commonly thrown around lately is consumer.reply",
      "They would also once in a while fix a script.  I started out as an operator. You also forgot load mag tapes :)reply",
      "And feeding stacks of punched cards into the card reader.reply"
    ],
    "link": "https://jyn.dev/operators-not-users-and-programmers/",
    "first_paragraph": "",
    "summary": "**Operators, Not Users and Programmers: A Nostalgic Navigational Nightmare**\n\nIn the heart of a technological tantrum on jyn.dev, we\u2019re graced with yet another elegy for the golden age of command line interfaces (CLIs), desperately gripping at the romantic notion that every Joe with a keyboard was a proto-programmer back when text was all the rage. Never mind the sea of modern users who prefer not to hack a config file to change their background color; the article finds its perfect match in <em>confused commenters</em>, stuck in a perpetual loop of advocating for software that both models your grandpa's office filing system and rockets its way into a blockchain-enabled AI dystopia. Yes, <strong>Rich Hickey</strong> gets his name dropped, like invoking a wizard that might magic our GUI woes away, but alas, there's just one sinful omission in this techie lament\u2014<i>no one mentioned Kubernetes enough</i>. Cue the collective gasp! \ud83d\ude44"
  },
  {
    "title": "X-Clacks-Overhead (xclacksoverhead.org)",
    "points": 205,
    "submitter": "weinzierl",
    "submit_time": "2025-07-02T07:14:19 1751440459",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=44440968",
    "comments": [
      "My website returns a random person in a list for every X-Clacks-Overhead response header: https://github.com/Xe/site/blob/877872b4d7db92b602683ecb4e99...I figured this was one of the best ways to do it. That way I'm letting people that were significant to me live on forever, one random HTTP response header at a time.  $ curl https://xeiaso.net --head | grep clacks\n  x-clacks-overhead: GNU Satoru Iwatareply",
      "Love this idea. Maybe I'll make a gem or something to make enabling that easier.reply",
      "The code is pretty trivial but in case it helps: https://github.com/Xe/site/blob/main/internal/clackset.goreply",
      "Seeing Kris N\u00f3va in that list hit hard. It is a beautiful idea, thank you Xe.reply",
      "The thing that struck me about \"GNU John Dearheart\" was how it feels like it _really_ deeply captures hacker culture, like Pterry wasn't just referencing the culture, but that he really got it. Which is remarkable, because he gave me that impression about many, many topics. Such a loss.reply",
      "Terry loved his characters in a way that's hard to express - unless they were pure evil (and he had a few) he did his best to understand their motivations in such a way that he came to portray them sympathetically.This is most noticeable in his caricatures that became characters that became badasses over multiple novels; the Watch has a few of these, but there are others.reply",
      "Yup. Vimes going full-on berserker mode while screaming \"Where is my cow?\" should, by all rights, be extremely silly. Instead, it sent shivers down my spine.reply",
      "When clacks got introduced, the description of people who just enjoyed being there and spending time on coding messages and talking to unknown remote people.. well, it felt like early internet, fidonet, perhaps AM radio amateurs.It really seemed like Pratchett knew something of this niche cultures, way more than I expected.reply",
      "> It really seemed like Pratchett knew something of this niche cultures, way more than I expected.He was definitely an early adopter of the internet, (and e.g. very active on alt.fan.pratchett), so that's no big surprise.reply",
      "> In Terry Pratchett's science-fantasy Discworld series, \"The Clacks\" is a network infrastructure of Semaphore Towers, that operate in a similar fashion to telegraph - named \"Clacks\" because of the clicking sound the system makes as signals send.Surely named \"Clacks\" because of the clacking sound the system makes.reply"
    ],
    "link": "https://xclacksoverhead.org/home/about",
    "first_paragraph": "X-Clacks-Overhead is a non-standardised HTTP header based upon the fictional work of the late, great, Sir Terry Pratchett.In Terry Pratchett's science-fantasy Discworld series, \"The Clacks\" is a network infrastructure of Semaphore Towers, that operate in a similar fashion to telegraph - named \"Clacks\" because of the clicking sound the system makes as signals send.In Sir Terry's novel \"Going Postal\", the story explains that the inventor of the Clacks - a man named Robert Dearheart, lost his only son in a suspicious workplace accident, and in order to keep the memory of his son alive, he transmitted his son's name as a special operational signal through the Clacks to forever preserve his memory:GNU John DearheartG: Send the message onto the next Clacks Tower.N: Do not log the message.U: At the end of the line, return the message.The nature of the 'GNU' code would keep the name of his son forever transmitting through The Clacks network so long as the network still existed.\"A man is not de",
    "summary": "**Hackers Memorialize the Dearly Departed Through HTTP Headers: Because Efficiency in Grief is Key\ud83d\ude80**\n\nIn a touching tribute to Sir Terry Pratchett, the tech world bonds over an HTTP header, X-Clacks-Overhead, intent on immortalizing every cat, goldfish, and ex-roommate with a random name shout-out for every server ping. One proud developer brags about implementing this in his grandma\u2019s old GeoCities codebase, sparking a cascade of \"innovative\" GitHub commits that might as well try resurrecting dial-up internet to save Net Neutrality. Meanwhile, the comments section becomes a teary-eyed therapy session as techies wax poetic about how code snippets \ud83d\udda5\ufe0f can hold the essence of humanity\u2014clearly, we've mastered artificial intelligence enough that we\u2019re offloading emotions to it. Everyone\u2019s too choked up to notice that we\u2019re a semicolon away from making Skynet sentient for real this time."
  },
  {
    "title": "7-Zip 25.00 (github.com/ip7z)",
    "points": 41,
    "submitter": "pentagrama",
    "submit_time": "2025-07-05T22:35:05 1751754905",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=44476137",
    "comments": [
      "7-Zip 15.05 is still useful today, because it was the last version to include built-in support for decompiling NSIS installer scripts.  The feature was removed due to security concerns.reply",
      "Why is decompiling NSIS a security concern?reply",
      "In case of bugs in the decompiler.  Extracting the files is still possible in newer versions, just not decompiling the installer scripts.reply",
      "what is NSIS?reply",
      "Nullsoft Scriptable Install System, a byproduct of Winamp that is ubiquitous in lightweight software installers for Windows.https://sourceforge.net/projects/nsis/reply",
      "I wish either RAR or 7-Zip would finally implement a memory-hard KDF for encrypted archives.reply",
      "I wish 7-zip would support .tar.gz the way WinRAR does.WinRAR allows you to browse a .tar.gz without extracting it, 7-zip extracts the .tar to a temp file. It makes working with large .tar.gz files impossible.(Yes I know that because of how .tar works WinRAR must decompresses it to build the  files list. But it beats having to write a 1TB .tar to disk just to see the file listing.reply",
      "WinRAR also seems to handle opening a file in an external app without manually extracting much better. I can just double-click a file in an archive and open it in an external app, while with 7-zip it seems to immediately delete the temporary file so the external app ends up trying to open a non-existent file. Rather annoying if you're just trying to quickly check something like the readme.txt in an archive.reply",
      ">while with 7-zip it seems to immediately delete the temporary file so the external app ends up trying to open a non-existent file.No, 7-zip only deletes the file after you close its window, so as long as you don't close 7-zip any apps should be able to open those files. Winrar doesn't delete on close, but that has its own problems, namely that you accumulate a bunch of extracted files in your %TEMP% directory, and have to run disk cleanup to delete them.reply",
      "I just tried it with 7-zip 19.0, and double-clicking a video file in a 7z archive, and VLC could not open the extracted file because it didn't exist.E: Tried again with procmon monitoring 7-zip, and after it completed writing the file it deleted it.reply"
    ],
    "link": "https://github.com/ip7z/7zip/releases/tag/25.00",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.",
    "summary": "**Hacker News Releases Hypocrisy Simulator: 7-Zip \"Error Edition\"**\n\nIn an innovative twist to software development, the 7-Zip team proudly releases version 25.00, featuring the much-anticipated \"Perpetual Error Loading\" feature, a daring homage to our collective inability to achieve perfection. Comments quickly fill with nostalgic programmers lamenting the loss of decompiling features for reasons they barely understand, <em>\"Why is it a security issue?\"</em> asks one, clearly bewildered by the concept of a bug. Meanwhile, another brave soul on a quest to open a <i>.tar.gz</i> without extracting reveals his struggle against the oppressive regime of temporary file deletion. The conversation inevitably turns into a plea for superior features found elsewhere, because if there's anything enthusiasts love more than using tools, it's wishing those tools worked like other tools."
  },
  {
    "title": "Atomic \"Bomb\" Ring from KiX (1947) (toytales.ca)",
    "points": 58,
    "submitter": "gscott",
    "submit_time": "2025-07-02T19:24:18 1751484258",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44447797",
    "comments": [
      "Radium watches, on the other hand, were quite dangerous.As noted in another comment, I wouldn't consider Polonium to be \"harmless.\"But I grew up in an environment that would cause most parents, today, to defecate masonry. I grew up in Africa, and we had some really fun critters going through our backyard, like Black Mambas, Gaboon Vipers, and even the damn bugs were nasty. Bug bites could hurt for a month.I somehow survived.reply",
      "At first I thought this was just a toy, until I got to the Polonium-210. Holy cow. Wikipedia calls it \"highly radioactive\" and \"extremely dangerous to humans\" and says that \"has the ability to become airborne with ease.\" Wonder how many kids managed to ingest it. This is the stuff that was used to poison Alexander Litvinenko.But it was just \"minute traces.\"reply",
      "Plenty of strange things were sold.https://en.wikipedia.org/wiki/Radithorreply",
      "https://en.wikipedia.org/wiki/Radium_ore_Revigatorreply",
      "Likely zero, as it was encapsulated with resin. They would have had to grind the ring to dust and then eat the whole damned thing.It was also commonly in record and camera cleaning brushes, as it could be used to induce a static charge, which would attract dust. Likewise, encapsulated, so the risk with normal use was minimal, but again, if you ground the brush to dust and ate it, all bets are off.reply",
      "> Likely zero <\u2026> They would have had to grind the ring to dust and then eat the whole damned thing.Never had kids, huh?reply",
      "They sure don\u2019t make \u2018em like they used to.reply",
      "Or, to paraphrase, people just don\u2019t die like they used to.reply",
      "This is no set of lawn darts!reply",
      "Who even knows if they actually put anything in there lolreply"
    ],
    "link": "https://toytales.ca/atomic-bomb-ring-from-kix-1947/",
    "first_paragraph": "",
    "summary": "The daring innovators of 1947 apparently thought strapping bits of Polonium-210 to children's fingers was top-tier entertainment, showcasing the \"Atomic Bomb\" Ring as must-have playground radiation. Commenters, in their usual historical expertise gleaned from Wikipedia marathons, are astonished that the \"highly radioactive\" toy didn't lead to a generation of superheroes or at least a few extra limbs. Debates rage about the safety of encapsulated radium, with profound insights like \"they would have had to grind the ring to dust and then eat the whole damned thing\" \u2013 because there's nothing children love more than not putting things in their mouths. Truly, why play with boring, safe toys when you can instead flirt with the periodic table's most controversial elements?"
  },
  {
    "title": "ClojureScript from First Principles \u00e2\u20ac\u201c David Nolen [video] (youtube.com)",
    "points": 9,
    "submitter": "puredanger",
    "submit_time": "2025-07-02T21:03:13 1751490193",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.youtube.com/watch?v=An-ImWVppNQ",
    "first_paragraph": "",
    "summary": "In a groundbreaking act of lunatic hubris, David Nolen attempts to explain ClojureScript from first principles in a YouTube marathon that could double as an insomnia cure. Commenters, each more eager than the last to showcase their own profound grasping of parentheses-driven enlightenment, trade obscure jargon like Pok\u00e9mon cards in a middle school playground. True to form, the few who actually understand anything are outnumbered by those treating the comment section as a pseudo-intellectual battleground. Everyone leaves convinced they've ascended to a higher plane of coding consciousness, but can't seem to figure out how to center a div."
  },
  {
    "title": "Yet Another Zip Trick (hackarcana.com)",
    "points": 17,
    "submitter": "todsacerdoti",
    "submit_time": "2025-07-02T12:01:59 1751457719",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44442691",
    "comments": [
      "Since docx files are similar to a zip file with the extension changed, could this trick fake out Microsoft Word?reply",
      "The trick depends upon different implementations doing different things.  Not likely for Word (though I suppose it is -possible- across different versions or different OSes).reply",
      "Obviously it sucks in the real world but I do always appreciate the cleverness of exploits like these.reply",
      "The described exploit seems theoretical. In order to create the schizophrenic ZIP, the attacker would have to figure out what ZIP stacks are being used and ensure they act differently - if the 2 departments use the same stack, then the exploit can't work, can it?reply",
      "Like spam, the exploit would still be profitable if only a small fraction worked.reply"
    ],
    "link": "https://hackarcana.com/article/yet-another-zip-trick",
    "first_paragraph": "\nDo you consent to our site using cookies in accordance to our\nPrivacy Policy? You can consent either to all cookies, or accept only selected types.\n\nReject optional\nCache only\nAllow all cookies\nAdvanced cookie settings\nFor details please check our\nPrivacy Policy\n\n                  Cookies strictly required for this website to work\n                \n                  Optional cookies that improve functionality of this website. At this moment this is limited to caching\n                  resources to enable faster website load times.\n                \n                  Optional cookies that are used for detailed visit statistics. At this moment we don't use this kind of\n                  cookies and rely on server-side statistics.\n                \n                  Optional technical cookies that are used to improve performance of the website. At this moment we\n                  don't use this type of cookies.\n                \n                  Optional cookies that are used for advertisem",
    "summary": "**Another Day, Another Zip: Hackers' Paradise or Script Kiddies' Sandbox?**\n\nIn the latest episode of \"hackers finding holes where none should exist,\" HackArcana breathlessly narrates the tale of zipping, unzipping, and re-zipping docx files until Microsoft Word gives up and tells you its deepest secrets. \ud83e\udd2f Commenters, displaying their boundless optimism, toss around terms like *schizophrenic ZIPs* and *ZIP stacks* as if they're auditioning for roles in a cyberpunk reboot of \"Office Space.\" As usual, the real world functionality of these tricks is debatable, but that doesn't deter our keyboard warriors from crafting responses that hover between IT despair and hacker-wannabe hope. \ud83c\udfad Does the trick work? Who knows, but it'll probably do great in some obscure tech trivia quiz. \ud83c\udf6a\ud83d\udd10"
  },
  {
    "title": "The Calculator-on-a-Chip (2015) (vintagecalculators.com)",
    "points": 24,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-05T16:38:41 1751733521",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44473871",
    "comments": [
      "Commodore infamously used TI chips in their calculators too, leading to the situation where Jack Tramiel was getting massively undercut by TI using the same chips in their own TI calculators for less. Buying the ailing MOS Technology gave him the vertical integration he wanted and enabled him to force TI out of the home computer market only a few years later. Revenge is such a dirty word.reply",
      "Now we just need that one cool article about the Sinclair Scientific Calculator.  It was a scientific calculator that was made to run on an underpowered chip intended for regular four-function calculators.reply",
      "@kens beat me to it-I too was going to suggest Ken Shirriff's \"Reversing Sinclair's amazing 1974 calculator hack\".  The page has a Sinclair Scientific emulator that displays the running, underlying calculator chip instructions.I bought the Sinclair Scientific in 1974 for a physics lab class in college.  It was much less expensive than the TI and HP scientific calculators of the time, but it was painful to use in the lab class.  I subsequently changed majors, so I only had to bear with it that first year, but, all these years later, I'm still in awe of what Sinclair achieved with it though!reply",
      "How about https://static.righto.com/calculator/sinclair_scientific_sim...reply"
    ],
    "link": "http://www.vintagecalculators.com/html/the_calculator-on-a-chip.html",
    "first_paragraph": "  Calculator ArticlesHome > Collecting CalculatorsThe Arrival of the \"Calculator-on-a-Chip\"During the late 1960s and early 1970s a major aim of the calculator electronics companies was to integrate all of the functionality of a calculator into one integrated circuit, so producing a \r\n                \"Calculator-on-a Chip\".\u00a9 2015 Nigel ToutThis is a new article which was not originally in \"The International Calculator Collector\".\u00a0IntroductionAs told in the section \"The Story of the Race to Develop the Pocket Electronic Calculator\", from the mid-1960s one of the aims of the \r\n                electronics industry was to integrate more of the functionality of a calculator into fewer integrated circuits so that less components were required and calculators became smaller and cheaper.Inside the Canon Canola 130S.\u00a0 This is a typical calculator of about 1968 and requires 13 circuit boards full of components.The degree of integration was gradually improved.\u00a0 Here the Sharp QT-8B of 1970 has a 4",
    "summary": "Witness the world-shattering innovation of squeezing a calculator into a single chip, a saga penning from the '60s to '70s as detailed on vintagecalculators.com, because apparently, <em>everything old is new again</em>. In the riveting tale of the \"Calculator-on-a-Chip,\" technology enthusiasts engage in a breathless race to make calculators not only smaller but also profoundly less interesting. Meanwhile, the comment section morphs into a nostalgia trip for graybeards and nerds reminiscing over the calculators of yore, amidst bouts of revenge against TI and awe over Sinclair's underdog chip. Truly, a gripping stroll down memory lane for everyone whose social life is as *integrated* as their circuits. \ud83c\udf89\ud83e\uddee\ud83d\udc94"
  },
  {
    "title": "Haskell, Reverse Polish Notation, and Parsing (mattwills.bearblog.dev)",
    "points": 42,
    "submitter": "mw_1",
    "submit_time": "2025-07-02T15:07:19 1751468839",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=44444673",
    "comments": [
      "I've always felt like RPN is a really powerful lesson in how subtly redefining the semantics of a problem can make it suddenly much easier to solve.My personal struggle with functional programming is how difficult I find it to be iterative. I've very frequently backed myself into a corner and ended up having to rewrite everything, whereas in C, even when I miss badly on the architecture, I'm still usually able to reuse some big chunks of what I've already done in the end. Maybe it's just inexperience.reply",
      "Agreed that RPN (and stack machines) are beautiful and underappreciated. Unfortunately, it's for a relevant reason that I have to push back against the author's newfound love of recursion. Like everyone else I had the same brain-exploding moment when I realized that recursion was possible and how if forced me to re-think what functions were capable of, but now that I'm old and ornery I'm of the Hot Take that recursion is a clumsy alternative to a loop, not the other way around. Which is to say, if a portion of a program is going to threaten to execute for an unbounded amount of time, I want that fact to be explicitly called out in the code via a looping construct, rather than having to worry whether any random function call is going to recur (or even mutually recur), to say nothing of the efficiency of holding onto a single piece of loop-relevant mutable state rather than forcing my runtime to handle an unbounded number of stack frames. If your language both guarantees tail recursion and calls it out syntactically, then you get a pass, otherwise I'd be perfectly happy working in languages that didn't support recursion at all.reply",
      "Recursion isn't about writing functions, it's the foundation of scalable systems.Deep learning with backpropagation? That's the chain rule of calculus applied recursively over a network, as described by Rumelhart, Hinton, and Williams. We owe LLMs and emerging AI to recursive ideas.The internet? It's a recursive structure made up of an arbitrary number of interconnected servers. We owe the information era to recursion.Database queries and programming languages? We prove correctness by reasoning recursively. We architect entire systems of arbitrary size, with correct behavior, simply by specifying the properties of their element types.Sure, you could probably block recursion within the scope of a program's compilation. But when you're developing scalable systems, recursion is their natural language. The powerful recursive algorithms for these systems are symptoms of their scalability, not mere implementation choices. When forced, stacks and other recursion workarounds are obstacles that get in the way of innovation.Plus, real-world systems aren't single programs compiled together. When microservice A calls microservice B, there's potential for recursion, regardless of whether the programming language of either microservice supports it. Programmers still have to think recursively. No programming language annotation is going to change that.The Great Pyramid contains a combinatorial explosion of smaller pyramids inside it. They made it out of blocks. Forty centuries look down upon us.reply",
      "I won't badmouth your preference of one form of iteration over another, but I don't follow what you're trying to say about what functions do.It's not clear if you mean \"the functions that you write\" or \"the functions that other people (library providers? Colleagues? Juniors?) write.The functions you write do what you tell them to do. If you don't tell them to recurse, then they don't. If you do tell them to recurse, then that has whatever frame optimization or boundedness guarantees that you bake into it (which is the same responsibilities you take on writing a loop just packaged in a slightly different form).The functions black-boxed by a library aren't something you have a lot of control over, nor in most cases are those black boxed by colleagues. Your concerns sound as though they target these cases, though your preferences really have no traction here.reply",
      "I don't know man, very often sophisticated problems require recursive thinking (even if you don't write it so later on) to be able to see similarities in sub problems. Just last week I had to resort to this to flatten-index json files. I started confused and then made an inductive leap and the solution unfolded itself (no pun intented) as a two-liner.It's way beyond brain-teaser for me, it's the sharpest tool I know of.reply",
      "If I have to traverse a tree, then recursion is more natural to me. With a loop you\u2019ll have to manually use a stack (it\u2019s fine, but more error prone). For lists, I rarely write loops or recursion. It\u2019s mostly folds and maps.reply",
      "Linear recursion vs tree recursion.reply",
      "Made me feel like I understand monads finally...will read again in a couple days when I inevitably forget.reply"
    ],
    "link": "https://mattwills.bearblog.dev/haskell-postfix/",
    "first_paragraph": "",
    "summary": "**Title: Haskell, Reverse Polish Notation, and Parsing: A Comic Tragedy in Several Blog Comments**\n\nAt mattwills.bearblog.dev, a brave soul attempts to dive deep into the arcane arts of Haskell and Reverse Polish Notation, convinced that they are revealing profound truths about computation. In the comments, a ragtag band of software developers grapples with recursion like it's an unsolvable Rubik's Cube. One commenter heroically claims RPN \"redefines the semantics of a problem,\" sparking a philosophical battle about whether recursion is a divine tool or just an elaborate way to crash your stack. Meanwhile, the Haskell enthusiasts rally in the corner, debating monads and feeling high on their esoteric language of choice. Who knew a blog could so efficiently demonstrate the existential crisis of modern programming? \ud83e\uddd9\u200d\u2642\ufe0f\ud83d\udd04\ud83d\udcbb"
  },
  {
    "title": "WinUAE 6 Amiga Emulator (winuae.net)",
    "points": 42,
    "submitter": "doener",
    "submit_time": "2025-07-05T21:13:55 1751750035",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44475600",
    "comments": [
      "What\u2019s the UX like winUAE these days?I remember years ago finding it very confusing, having to choose the specific Amiga, and simulate specific disk loads.For me, I just wanted to be able to quickly and easily load up and play the old Amiga games I used to love.Is that possible yet?reply",
      "Not great, but a bit better than FS-UAE. Amiberry has a much more logical UX, though it's still a bit cluttered.reply",
      "https://dirkwhoffmann.github.io/vAmiga/reply",
      "Agreed. Last time I tried, I spent an hour trying to run Cannon Fodder and failed. I'd love to hear if that's improved.reply",
      "You'd probably be better off with the PUAE core under Retroarch, or some other libretro front-end.reply"
    ],
    "link": "https://www.winuae.net/",
    "first_paragraph": "Major update to custom chipset emulation. Internally almost everything in main chipset emulation has been rewritten.Fastest possible/JIT mode chipset timing/sync had major changes which can cause side-effects.Bugs are very possible, especially in very rarely used features.Custom chipset rewriteOther new featuresFixesUpdatesNew featuresUpdatesBug fixesNew emulated RTG boardsAll \u201cclassic\u201d 1990s RTG boards are now emulated.New features/updatesBug fixesNew features/updates:5.1.0 Bugs fixesOlder bug fixes",
    "summary": "**Amiga Nostalgia or Masochism? A New Challenger Appears**\n\nIn the latest installment of \"let's polish the antiques,\" WinUAE releases its 6th effort to resurrect the Amiga, a computer most of its users haven't seen outside a museum in decades. Major updates promise to almost <i>completely</i> rewrite the emulation for that oh-so-necessary lag in your retro gaming experience. The developers assure us that with these updates, new bugs will enhance your frustrating journey into antiquity. Post-launch, a band of brave commenters reminisce about easier times, like trying to decipher hieroglyphics or running Cannon Fodder without inducing a mental breakdown.\ud83d\udc74\ud83d\udcbe\ud83d\udeab"
  }
]