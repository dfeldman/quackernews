[
  {
    "title": "Postgres IDE in VS Code (microsoft.com)",
    "points": 671,
    "submitter": "Dowwie",
    "submit_time": "2025-05-23T15:12:44 1748013164",
    "num_comments": 281,
    "comments_url": "https://news.ycombinator.com/item?id=44073588",
    "comments": [
      "Congrats to the team on launching this! I was actually the first to demo it, as part of our sponsored session at Microsoft last week.Here's the talk where I used it:\nhttps://www.youtube.com/watch?v=k6Vm2hakkV4I also did a theater session at our MSFT booth, but the recording isn't up yet. You can follow the steps in this repo to check out all the features that I demo'd, however:\nhttps://github.com/Azure-Samples/postgresql-extension-playgr...Let the team know about any issues here:\nhttps://github.com/microsoft/vscode-pgsql/issues\n \nreply",
      "This solves a major problem that I built an npm package called \"pgstrap\"[1] for. It generates a \"database structure\" directory so that my database schema is available to LLMs (it also makes code review easier because you can see the changes to various tables). So I have a SQL file for each table in my database, neatly organized into directories for each schema. Rails has a similar idea with schema.rbI'm not sure whether or not it's better to have your editor database-aware or to have your codebase have appropriate context committed. On one hand, less generated code/artifacts make for a cleaner codebase. On the other hand, not everyone uses VC Code or will know how to use this integration. Database browser GUIs have never really had a single winner. That said, VS Code does have enough dominance to potentially make themselves \"the standard way to view a database in development\"[1] https://github.com/seveibar/pgstrap\n \nreply",
      "I\u2019m confused. Isn\u2019t including the canonical state of the database schema in version control along with all the migrations that brought it to that point a completely standard part of every web framework?\n \nreply",
      "It usually is, but the schema might be written against a language-specific ORM.Same for seed data and migrations.So it depends on the use-case how useful this format is for tooling and discovery vs an actual connection to the database.\n \nreply",
      "I'm more confused why the version control of the thing using the database is including the entire schema of the database in it's repository\n \nreply",
      "That \"works\" for about as long as you have <10 employees and <3 customers or so. After that the railsapp doesn't get to be the sole owner of the db.\n \nreply",
      "Do you have multiple separate apps that can change a shared DB schema?How do you keep that all in sync across your apps?\n \nreply",
      "That seems like a really pragmatic tool, thanks for sharing it!I'm curious, do you output triggers, store procedures, and such?  Many tools seem to stop after you've defined tables, columns, and indices, but I'd love some better tooling to make use of the rest of the DB's features.\n \nreply",
      "Yep! It basically runs pg_dump and categorizes all of the output into different files so it should be comprehensive. I think there's `functions/function_name.sql`, `misc.sql`, `triggers.sql` etc.\n \nreply",
      "I just use a MCP server (with copilot or cline) that has a read only login to my database.\n \nreply"
    ],
    "link": "https://techcommunity.microsoft.com/blog/adforpostgresql/announcing-a-new-ide-for-postgresql-in-vs-code-from-microsoft/4414648",
    "first_paragraph": "We are excited to announce the public preview of the brand-new PostgreSQL extension for Visual Studio Code (VS Code), designed to simplify PostgreSQL database management and development workflows. With this extension, you can now manage database objects, draft queries with intelligent assistance from context-aware IntelliSense and our \u2018@pgsql\u2019 GitHub Copilot agent\u2014all without ever leaving your favorite code editor.Many of you face hurdles in managing time effectively, with 41% of developers struggling with task-switching, according to the 2024 StackOverflow Developer Survey. Additionally, the 2024 Stripe Developer Coefficient Report reveals that developers spend up to 50% of their time debugging and troubleshooting code and databases. These inefficiencies are further compounded by the absence of integrated tools that unify database management and application development.The PostgreSQL extension for VS Code addresses these challenges head-on by integrating Postgres database tools and th",
    "summary": "<b>The Future is Now: Postgres and VS Code Converge!</b>\nIn a bold move that redefines procrastination, Microsoft announces a PostgreSQL extension for Visual Studio Code, promising to save developers from the few remaining seconds of the day not already consumed by context-switching. Now, 41% of developers struggling with multitasking can seamlessly toggle between snarking on Twitter and querying their databases without ever leaving VS Code. Meanwhile, the comment section transforms into an Olympic event where everyone competes to boast about their early access, obscure use cases, or how their niche tools are somehow better. \ud83e\udd21\ud83d\udd27"
  },
  {
    "title": "Modification of acetaminophen to reduce liver toxicity and enhance drug efficacy (societyforscience.org)",
    "points": 45,
    "submitter": "felineflock",
    "submit_time": "2025-05-24T00:29:28 1748046568",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44077850",
    "comments": [
      "The same website is also for the excellent Science News print magazine, which will ship you top notch science reporting right to your door. My father was a subscriber since, well, whenever blue LEDs were invented, because I recall reading about them in Science News.Strong recommendation for any science-lover.\n \nreply",
      "She didn't even break the top 10 in this content: https://www.societyforscience.org/regeneron-sts/2025-student...I'm impressed beyond words by these kids, though I think I'd give her the top prize. Watching my grandfather's final days taken away from him by the effects of morphine has always made me wish so much that we had much more effective non-narcotic painkillers\n \nreply",
      "https://www.societyforscience.org/press-release/regeneron-is...She's in top 4, awarded $600? I dunno this is a confusing layout/structure for how the program is conducted seeing as how the headline is $9m awarded.\n \nreply",
      "Reversible computing, materials science, genetic research\u2026 it\u2019s insane that these kids are doing this level of work in high school.\n \nreply",
      "This would be incredibly cool if it works in reality and not just simulation. Remarkable that the author is just 17.\n \nreply",
      "I\u2019m not going to shit on it, nothing wrong with going into the family business - but it isn\u2019t a complete coincidence that her dad is a PhD biochemist at UT Tyler.\n \nreply",
      "impressive for a high schooler but this just adds a protecting group onto tylenol.  am i missing something?edit:  oh i see.  its really blurry but the silyl modified tylenol is predicted to have good trpv1 binding computationally.  afaict no in vitro or in vivo studies were done.  could be cool.  not sure if diethylethynylphenylsilyl group has good Lipinski properties though (i suspect not)edit: s/aspirin/Tylenol\n \nreply",
      "It isn't aspirin - Acetaminophen, also known as N-acetyl-para-aminophenol (APAP) or paracetamol\n \nreply",
      "lol yeah sorry brain too deep into synthetic chemistry bits.  thanks.\n \nreply",
      "so is this already patented by Regeneron?\n \nreply"
    ],
    "link": "https://www.societyforscience.org/regeneron-sts/2025-student-finalists/chloe-lee/",
    "first_paragraph": "Plano East Senior High School\nPlano, TexasChloe studied ways to reduce the toxicity of acetaminophen while keeping its painkilling properties.Chloe Yehwon Lee, 17, of Murphy, explored a way to lower the toxic effects of acetaminophen (Tylenol) on the liver for her Regeneron Science Talent Search chemistry project. The painkiller is used by over 60 million Americans each week, but it is also the leading cause of acute liver failure in the United States and the second most common cause of liver transplant worldwide. Chloe studied chemical changes to the acetaminophen molecule\u2019s benzene ring to see if they could reduce liver toxicity.Chloe studied chemical changes to the acetaminophen molecule\u2019s benzene ring to see if they could reduce liver toxicity. She developed computer models of the modified molecules to test their ability to relieve pain and toxic effects. She found and synthesized a modified acetaminophen molecule that may be less toxic and may even kill pain better than the origin",
    "summary": "Title: Young Chemist Tinkers Tylenol, Internet Claps\n\nAt Plano East Senior High School, a daring young chemist decides that regular old liver-damaging Tylenol just isn't exciting enough. Enter Chloe Yehwon Lee, who, in a stunning burst of high school science fair bravado, tweaks the benzene ring of acetaminophen and maybe, just maybe, reduces its knack for wrecking livers. Meanwhile, the internet's armchair pharmacologists chime in\u2014some marvel at the accolade-worthy science sorcery, others just mix up their painkillers, while a skeptic deeply immersed in synthetic chemistry mumbo-jumbo half-nods in approval before questioning molecular legality. Shockingly, no one has yet tried to patent air, but stay tuned!"
  },
  {
    "title": "Find Your People (foundersatwork.posthaven.com)",
    "points": 369,
    "submitter": "jl",
    "submit_time": "2025-05-23T16:02:02 1748016122",
    "num_comments": 158,
    "comments_url": "https://news.ycombinator.com/item?id=44074017",
    "comments": [
      "> The first step is to realize that the subway stops here. Up to this point in life, most of you have been rolling on train tracks. Elementary school, middle school, high school, college\u2014it was always clear what the next stop was. In the process you've been trained to believe something that\u2019s not true: that all of life is train tracks. And there are some jobs where you can make it stay like train tracks if you want, but really today is the last stop.Well put!This is something _so many_ college kids don't seem to understand. I had many friends who graduated then just stood around looking for where to go next. It hadn't come up in discussions but it became apparent they were surprised by the sudden end to the \"tracks\" while the students who saw them coming (or were told better/more often) all were befuddled, \"How did you not see this coming?\", \"Did you expect someone to just walk up and offer you a job?\", \"You have never even interned in your field??\".I don't blame the kids, they don't know any better. They've spent their whole life focusing on the next goal, I talked about this specifically (in blog post) when I dropped out of college to go full-time into my profession. For me, learning \"there are no tracks\" and more importantly \"you don't need to go to the end of the college track before you decide next steps\" was freeing and empowering while also being a bit terrifying.\n \nreply",
      "i think its interesting that for so many college kids, the post-graduation options that continue to provide tracks are also treated as the more \"prestigious\" options (go to grad school. work at big3/faang, etc).it's not because they are any more prestigious or important, but because they provide a clear sense of achievement/external validation and kids that make it to the end of college are kids that have had decades of achievement/external validation being their primary measure of success.and because of that, those places do an amazing job recruiting. i remember toward the end of my undergrad days there was huge sense of competition to get a \"teach for america\" position, even among folks with no interest in education. it was appealing simply because it was selective and provided a clear framework for 'next steps'.\n \nreply",
      ">  the post-graduation options that continue to provide tracks are also treated as the more \"prestigious\" options (go to grad school. work at big3/faang, etc).Graduate school is a mixed bag when it comes to prestige. It's fairly well known that grad student lifestyle is a grind, highly competitive, and a financial sacrifice. You go into it for a love of academics, not as a default next step.As for prestigious jobs like FAANG: I think you're downplaying the extreme compensation offered by many of these jobs. It's not just about prestige, it's about unlocking a level of wealth that is hard to ignore. It delivers on the dream people have when they imagine a university education unlocking incredible career options.\n \nreply",
      "I heard that quant finance companies target high-achievers by creating a sense of continuing tracks: recruiting based on high GPAs, an application process with a high-profile entrance exam, and so on. It creates an impression among their target group that such a company is where they \"should\" go to work, because it's at the top.\n \nreply",
      "Agree in spirit though I\u2019m a bit doubtful of your details (exams or GPAs, etc). I think part of this is presenting the work as looking more like university and less like what students might imagine work to look like.\n \nreply",
      "> the post-graduation options that continue to provide tracks are also treated as the more \"prestigious\" options (go to grad school. work at big3/faang, etc).I think it's the other way around: the more prestigious option becomes the track.\n \nreply",
      "The flipside is that going off the tracks, you need to decide where you're going and you might get lost. Some people try to do something and then waste a lot of time just spinning their wheels. For them, some structure and some tracks might be necessary.I guess we all need some amount of scaffolding in our life, at one point or another.\n \nreply",
      "I don\u2019t see why that can\u2019t be replicated in vocational trades.Main challenge there is you don\u2019t have a plumbing/electrical conglomerate like you have in tech to standardize recruiting.\n \nreply",
      "> I don't blame the kids, they don't know any better. They've spent their whole life focusing on the next goal.No, they spent their whole lives being sheltered. Let's call it what it is. These people were on tracks because they were put on tracks from a young age and told that the track leads somewhere, and any questioning of the tracks was often met with a harsh rebuke. They didn't play outside with the neighborhood kids, they were at soccer practice. They didn't get a summer job at a shitty fast food joint, they were doing summer school or learning piano. Everything they've done from start to finish has been curated. Of course when the track ends abruptly it's catastrophic.Independence, curiosity, and self-quesitoning and awareness are often not taught because \"getting ahead\" is more important.\n \nreply",
      "> These people were on tracks because they were put on tracks from a young age and told that the track leads somewhere, and any questioning of the tracks was often met with a harsh rebuke. They didn't play outside with the neighborhood kids, they were at soccer practice. They didn't get a summer job at a shitty fast food joint, they were doing summer school or learning piano. Everything they've done from start to finish has been curated. Of course when the track ends abruptly it's catastrophic.It's not clear to me how the \"tracks\" were significantly different in, say, the past 80 years, at least in America. Compulsory schooling has been a thing for a long time. Getting an after school job delivering newspapers so you have a little spending money is not exactly a clever endeavor, and it's not clear to me you learn more life skills than you do having to manage homework (for example).Get married to someone of the opposite gender, go to church every sunday, have kids. Work a job with a pension for 30 years, retire with a gold watch. (or the blue collar equivalent). Those are tracks.I don't disagree with the premise that kids are more coddled today than they used to be, but the \"tracks\" metaphor is, if anything, less valid now than ever.  There is more choice, and less stability, as far as I can tell.\n \nreply"
    ],
    "link": "https://foundersatwork.posthaven.com/find-your-people",
    "first_paragraph": "Thank you to Bucknell University for inviting me to be this year's commencement speaker. And congratulations to the Class of 2025!\u00a0 \n\n\n\n\n\n\n\n\n\n\nWatch the speech on YouTube.Thirty-two years ago I was sitting where you are now. At least, I assume I was. I can't really remember anything about my own graduation. I was too hung over.\u00a0The main thing I remember from that time in my life is that I had no plan. I had a degree in English, no job, and no idea what I even wanted to do. I would have liked to work hard on something I cared about. But I didn't have anything I cared about, and it took me a decade to find one.Maybe I can help you do that faster. Maybe I can help you figure out what to work on.\u00a0You fall into three groups. Some of you already have all kinds of ambitious plans. You're already admitted to med school for the fall, or whatever. Others of you have no ambitious plans and no desire to have any. You just want to have a happy life, and that's cool. But in the middle, there's a gro",
    "summary": "In a world teetering on the brink of nuclear apocalypse and irreversible climate change, a heroic <em>English major</em> turned vague tech philosopher takes the stage at Bucknell University, bravely advising fresh graduates on how to find something they care about after a decade of realized indifference. Commenters, leaping into action, unfolded a rich tapestry of anecdotes about life's non-existent tracks, each deeper and more revealing than the last\u2014like watching a group of toddlers explain quantum physics. \"I didn't see the end of the track coming!\" whines one, sparking a pseudo-intellectual breakdown of our educational conveyor belt system from others who read the blog once and now feel transformed. Meanwhile, prestigious jobs continue to be the Hogwarts letter that never arrived for many, as another comment enlighteningly compares FAANG jobs to winning \"America\u2019s Next Top Poverty Survivor.\" Such insight! Who knew post-grad existential dread could be so enlightening and yet so tediously over-discussed? \ud83c\udf93\ud83d\ude82\ud83d\udc94"
  },
  {
    "title": "Root for your friends (josephthacker.com)",
    "points": 62,
    "submitter": "rez0123",
    "submit_time": "2025-05-23T23:28:11 1748042891",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44077533",
    "comments": [
      "For a long time, I\u2019ve been this person for other people, but don\u2019t feel like I have anybody to do this for me. That\u2019s okay \u2014 I don\u2019t feel bitter about that or anything. And I don\u2019t wanna overstate what a good friend I am or whatever, I just do this a decent amount. But some part of me does wish I had someone celebrating my wins.This:\u201cNo one comes to mind? Maybe you haven\u2019t really trusted anyone with your wins yet.\u201dreally, really hit me for some reason. I\u2019m pretty averse to praise/congratulations \u2014 even if I feel it\u2019s deserved! \u2014 so I don\u2019t really share my wins with people. How can I expect to have people hype me up if I don\u2019t let them in a little? It\u2019s obvious when I write it all out but I kinda can\u2019t believe how long I\u2019ve been operating this way.Anyway, great post!\n \nreply",
      "> For a long time, I\u2019ve been this person for other people, but don\u2019t feel like I have anybody to do this for me.For the longest time I was this and unfortunately I got bitter over time. But then a couple of years ago I got back into the mindset again. A few bad years later I realized that the more happy you are for your friends, the more happy you are. Do it for yourself and nobody else.\n \nreply",
      "I\u2019m so glad that line helped. It was a last minute addition, and I was thinking about how so many of my friends just don\u2019t share the awesome stuff they do with the world. Share more!!\n \nreply",
      "I\u2019m not trying to be controversial but this behavior seems to be very hard for a lot of men. I\u2019ve noticed it a lot in my life that guys are far more willing to \u201ccircle the wagons\u201d over petty slights, and alienate people over it. Then their ego doesn\u2019t let them back down, and they just get more bitter from the (obvious) outcome.I\u2019m guilty of it myself of course, but it seems like there is some kind of naturally adversarial behavior baked into me. It literally just makes things worse is the funny thing, and I already know this. But sometimes I cant stop it. Life would be easier and better if we were all collectively friendly hypemen but alas.\n \nreply",
      "I largely agree, this is a great way to support your friends.I would add to bias towards praise, but still be honest and judicious. People know when they hear empty words, and it's important to be trustworthy.\n \nreply",
      "Yeah i only put the one line in there that talks about that:\n> people who are honest to your face and praise you behind your back.I could have emphasized that more.\n \nreply",
      "Just had a friend leave their company.   They had formed a really strong network of people within that company who were in constant contact.  This helped them succeed in a lot of ways.Sounds good? It was, except...most of that bonding was based on lowkey negativity by a set of people who felt powerless, complaining about how others were terrible.  Some in this network went down a rabbithole of resentment and are still there.  The reality is that yes, there was lots of stuff to be grumpy about.Rooting for your friends is great.  But people sometimes bond over wishing harm for their foes. Shared trauma does that.   I personally try to avoid that mindset.\n \nreply",
      "I kinda had this maybe assembled in my head in an incomplete bits and pieces way but this really brought together the concept I love it.Whoever wrote this post is really rocking with the clear human thinking.\n \nreply",
      "Thank you\n \nreply",
      "I believe in this. Just don't get onto to the corporate hype train.\n \nreply"
    ],
    "link": "https://josephthacker.com/personal/2025/05/13/root-for-your-friends.html",
    "first_paragraph": "My thoughts on hacking, ai, faith, and more.\n  \u00a9 2025 rez0.\n\nHeads\u2011up: The concept of this post might seem trivial, but it can improve your career, happiness, and the people you care about. Proceed without caution. It only takes about 10 minutes to read.It\u2019s getting excited for your friends when something good happens, and rejecting jealousy.It\u2019s deeply believing that a rising tide lifts all boats.It\u2019s understanding that most games in life aren\u2019t zero\u2011sum; they\u2019re wildly positive\u2011sum.Outcomes: If you read this post, you will be more:Note: I call a friend who roots for you a hypeman or a hype friend.The most underrated part of rooting for you friends is that it benefits everyone. A flywheel is a concept where each input creates a positive feedback loop that improves the next loop.A good example of a flywheel in business is where a company collectus and utilizes user analytics such that their improvement of the product means more people use the product, which creates more data for what\u2019s",
    "summary": "**Heads Up, Hype Lovers: Unlock *Ultimate* Friendship & Happiness in Just 10 Minutes! \ud83d\ude80\ud83d\ude02**\n\nIn the latest blogosphere revelation, a pseudo-profound post at josephthacker.com promises to catapult your personal growth to stratospheric levels by\u2014wait for it\u2014cheering for your pals. Groundbreaking. According to the sage wisdom imparted, embracing your inner \"hype friend\" not only makes you a saint but also magically uplifts all humanity, curing envy and presumably solving world hunger. Commenters, in a touching display of internet naivety, overshare their personal epiphanies while missing the irony that they're still just talking to themselves online. Transformative? <em>Definitely</em>. Pass the popcorn.\ud83c\udf7f"
  },
  {
    "title": "Mermaid: Generation of diagrams like flowcharts or sequence diagrams from text (github.com/mermaid-js)",
    "points": 31,
    "submitter": "olalonde",
    "submit_time": "2025-05-21T09:06:46 1747818406",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44049619",
    "comments": [
      "I have an almost exhaustive list [1] of browser based text to diagram tools. Some specialised tools (like https://sequencediagram.org/) so much better at what they do than any generic ones like mermaid.[1] https://xosh.org/text-to-diagram/\n \nreply",
      "70! That is awesome\n \nreply",
      "70!? That\u2019s more than a Googol!\n \nreply",
      "Little weird to see this on the lead page\u2026 mermaid has been around for a long time. And in general I\u2019ve found its real world use pretty lacking.\n \nreply",
      "I use it and see it many times per month as it\u2019s the preferred way of sticking graphics and diagrams in markdown in git repos and generated static sites.It\u2019s so handy for putting a sequence diagram in your docs and then tracking the changes over time using git.I\u2019m curious what other software developers use if not this. I\u2019ve tried specific graph and drawing tools like lucid and Visio, but the simplicity of mermaid is nice. And I don\u2019t know anything else that shows git blame for who changed what in my diagram, when.\n \nreply",
      "> And I don\u2019t know anything else that shows git blame for who changed what in my diagram, when.You could do this with any diagrams-as-code tool, no?\n \nreply",
      "I love Mermaid diagrams. I let my coding LLMs generate diagrams during architecture design and then afterward for accuracy\u2014 Sequence Diagrams, CSD\u2019s, Flowcharts, DFDs, and ERDs. Couldn\u2019t be simpler. I\u2019m happy.\n \nreply",
      "i have been quite enjoying https://www.eraser.io/diagramgpt\n \nreply",
      "I liked Mermaid but unfortunately LLMs don't understand it well, so I switched to Latex tikz which LLMs know pretty well. At least I know Gemini 2.5 Pro does a good job at tikz. 3.7 and o1 were meh.\n \nreply",
      "Like PlantUML?\n \nreply"
    ],
    "link": "https://github.com/mermaid-js/mermaid",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Generation of diagrams like flowcharts or sequence diagrams from text in a similar manner as markdown\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\nGenerate diagrams from markdown-like text.\n\n\n\n\n\nLive Editor!\n\n\ud83d\udcd6 Documentation | \ud83d\ude80 Getting Started | \ud83c\udf10 CDN | \ud83d\ude4c Join Us\n\n\u7b80\u4f53\u4e2d\u6587\n\nTry Live Editor previews of future releases: Develop | Next\n\n\n\n\n\n\n\n\n\n\ud83c\udfc6 Mermaid was nominated and won the JS Open Source Awards (2019) in the category \"The most exciting use of technology\"!!!Thanks to all involved, people committing pull requests, people answering questions! \ud83d\ude4fMermaid is a JavaScript-based diagramming and charting tool that uses Markdown-inspired text def",
    "summary": "**Mermaid: The Last Dinosaur of Diagram Tools**\n\nThe shimmering beacon of technology, Mermaid, graciously applauded by Javascript enthusiasts for transforming minimalist Markdown-esque text into mammoth diagrams, <em>occasionally</em> fails to upload. Troubled souls on GitHub rally in devout fervor, offering hymns of troubleshooting and salvation in comments. They argue the superiority of specialized diagramming tools or venerate Mermaid's archaic charm with the evangelical zeal of vintage tech collectors. Meanwhile, newbies in the back, repeatedly refreshing their browsers, ponder the mythical simplicity promised by this 'award-winning' relic. \ud83d\ude05"
  },
  {
    "title": "Show HN: Genetic Boids Web Simulation (attentionmech.github.io)",
    "points": 94,
    "submitter": "vimgrinder",
    "submit_time": "2025-05-23T19:40:03 1748029203",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44075911",
    "comments": [
      "The original Boids is from Craig Reynolds, here:https://www.red3d.com/cwr/boids/It was a java applet (sigh) and unfortunately I have not been able to find a working version. That version based on his three \"steering\" mechanisms had very realistic movement. Other versions, including this one, which are good do not have that same kind of quality. They look like simulations whereas the Reynolds version, for whatever reason, seemed much closer to watching an actual flock.No criticism intended, it would just be nice to understand the why the difference.Looking briefly at the code, it seems the fitness function is simply how close the boids are?Very cool!\n \nreply",
      "I don't know if this will address your question, but I had a long-standing question about boids that might overlap, which I coincidentally only resolved to my satisfaction a month ago. Here's the Lua code I ended up with:    function update_positions(boids, dt)\n      local max_speed = 0.5  -- per frame\n      local max_accel = 20  -- per second\n      local max_turn_angle = math.pi/6  -- per second\n      for _,boid in ipairs(boids) do\n        boid.pos = vadd(boid.pos, boid.velocity)\n      end\n      for i,boid in ipairs(boids) do\n        local accel = {x=0, y=0}\n        accel = vadd(accel, vscale(avoid_others(boid, boids), 20*dt))\n        accel = vadd(accel, vscale(seek_others(boid, boids), 10*dt))\n        accel = vadd(accel, vscale(align_with_others(boid, boids), 10*dt))\n        accel = vadd(accel, vscale(remain_within_viewport(boid), 40*dt))\n        local curr_heading = vnorm(boid.velocity)  -- could be nil\n        accel = vclamp2(accel, max_accel*dt, curr_heading, max_turn_angle*dt)\n        boid.velocity = vadd(boid.velocity, accel)\n        boid.velocity = vclamp(boid.velocity, max_speed)\n      end\n    end\n\nHere, avoid_others, seek_others and align_with_others are the 3 rules you can find on Wikipedia (https://en.wikipedia.org/wiki/Boids): separation, cohesion, alignment. Each of the functions returns a unit vector, which I then weight using vscale.The key is the last 4 lines. My intuition here is that the way muscle mechanics work, there are limits on both how fast you can accelerate and also how much you can turn per unit time. That's what vclamp2 is doing. It separately clamps both magnitude and angle of acceleration.My rough sense after this experience was:* Boids is not a simple program the way the Game of Life or Mandelbrot set is. The original paper had tons of nuance that we gloss over in the internet era.* Every implementation I've found is either extremely sensitive to weights or does weird stuff in the steering. Stuff like subtracting velocity from acceleration when the units are different, and so on. There may be a numeric basis for them, but it's never been explained to my satisfaction. Whereas my vclamp2 idea roughly hangs together for me. And the evidence it's on the right track is that a wide variety of weights (the 10s, 20s and 40s above) result in behavior that looks right to me.\n \nreply",
      "Wow! Thanks. The thought about \"Boids is not a simple ...\" is new to me and very good. The other vector in this is the evolution/genetic algorithm idea. It raises the question of what are the benefits of flocking? And could you plug those into a genetic algorithm to test survival.It seems like perhaps the visual inputs are another interesting area. What do I (as a boid) do when I see one boid in front of me go right, one go left, for example.\nBut thanks!!\n \nreply",
      "Yeah, the original paper gets into some of that. It was about 3D flocking! And Reynolds was very much thinking about what each bird sees, the minimum angle to turn to avoid a collision, etc. All on a then-powerful graphical workstation.\n \nreply",
      "Just a clarifying note, Craig Reynolds is the original researcher for Boids, and he did have a Java applet implementation in the above page. But the original Boids simulation was from 1986, almost a decade prior to Java applets.The original paper, published in 1987, is \"Flocks, herds and schools: A distributed behavioral model\"[1]. The implementation was done in Lisp on a Symbolics 3600 Lisp Machine.Edit: One quite interesting paragraph from the paper regarding performance:The boid software has not been optimized for speed. But\nthis report would be incomplete without a rough estimate of the actual performance of the system. With a flock of 80 boids, using the naive O(N\u00b2) algorithm (and so 6400 individual boid-to-boid comparisons), on a single Lisp Machine without any special hardware accelerators, the simulation ran for about 95 seconds per frame. A ten-second (300 frame) motion test took about eight hours of real time to produce.Once again, amazing how far hardware has advanced.1. https://dl.acm.org/doi/10.1145/37402.37406\n \nreply",
      "oh, so i wasn't really aware that there was a original boid sim (I will check it today). mostly I saw it on some other demos and I wanted to add this behaviour of signaling boids which are far away + color code based on genome + do a simple cross-mutate. and yes you are right about fitness func.Beyond this i was trying to add a map which effects their movement. (if you wanna check how it looks - https://x.com/attentionmech/status/1925690991555531143)\n \nreply",
      "I'll just say that this looks insanely good, wow.\n \nreply",
      "thanks!\n \nreply",
      "Awesome work, the green terminal style is really cool. And the fact that it's just Vanilla JavaScript, HTML & CSS is a pretty cool touch. I would've produced something a tenth the style with 10x the complexityJust some ideas/suggestions:\n- Better colors: maybe genes can influence colors a bit? The random colors aren't that great, they're good though for making all the boids distinct.\n- Zooming: Scroll the mousewheel to Zoom In/Out, drag to move around\n- Interactive: Click on a Boid, have it be followed around using zoom!\n- Time controls: Not just framerate, but a % multiplier on simulation speed.\n- GPU Refactor: I don't think you're doing any of this yet, so maybe optimizing for a GPU-based speedup would be cool? See if you can reach 10,000 boids! Sebastian Lague's video goes into parallelization, just not in JavaScript: https://youtu.be/bqtqltqcQhw\n \nreply",
      "hey thanks! color is coming from genome (check brightColorFromGenome)!\nnice suggestions, will definitely try to incorporate some of them.\n \nreply"
    ],
    "link": "https://attentionmech.github.io/genetic-boids/",
    "first_paragraph": "",
    "summary": "Welcome to another riveting Show HN, where we pretend a generic Boids simulation in JavaScript is as groundbreaking as the lunar landing. Our host has resurrected the 1986 simulation into a flashy, web-based spectacle with colors so random, they must have been chosen by a pack of wild parrots. Commenters ooze nostalgia and technical banter, debating nuances like acceleration vectors and genetic algorithms, because evidently, nothing screams excitement like <em>acceleration vectors</em>. Watch in awe as they reinvent the wheel\u2014or in this case, the bird flock\u2014with glorious <i>web technologies</i> and a genetic algorithm so cutting-edge it... looks like every other Boids simulation. Bravo! \ud83d\udc26\ud83d\udcbb"
  },
  {
    "title": "The world of Japan's PC-98 computer (strangecomforts.com)",
    "points": 53,
    "submitter": "ecliptik",
    "submit_time": "2025-05-23T20:51:29 1748033489",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44076501",
    "comments": [
      "> this now-forgotten art style native to Japan is known, shorthand, as \u201cPC-98\u201dI'm really into retro computing having collected over a hundred 80s 'home' computers (all non-PC/Mac), including at least a dozen Japanese models, but have never heard the term \"PC-98\" to describe a particular style of pixel art, probably because I don't speak Japanese and haven't lived there. However, I do see some traits in how the examples shown were constructed which strike me as unique beyond just the obvious Japanese aesthetic of the content.While the article highlights that Japanese computers had greater memory and graphics capabilities earlier due to the need to represent more complex fonts, there's another factor I suspect is behind the differences I'm seeing in those images. Japanese business computers tended to have analog RGB output and displays earlier and more commonly than those in the U.S. Of course, analog RGB was available in the U.S. around the same time but it wasn't usually considered worth the increased cost for mainstream desktop use in the early 80s. Monochrome or 4 colors were generally considered sufficient for 80-column capable text displays (~640 pixels wide).Some of the dot patterns I'm seeing in those examples work well on RGB displays but wouldn't work as well on composite video displays or TVs. In the US, early home computer pixel art targeted resolutions like 256 x 192 and 320 x 200 in 4 or 16 colors but generally assumed the pixels would be displayed on a TV or composite monitor and so leveraged the pixel blending and additional artifact colors composite video can uniquely create to enhance their artwork. These composite-exploiting blends and colors are lost when those images are displayed in RGB, leaving only the original pixel patterns which aren't what the original pixel artist saw or intended when they created the image (which is why original composite-targeted pixel art is best viewed on a composite CRT or CRT emulation). I think these Japanese artists being able to target analog RGB output is behind some of the subtle (but cool) uniqueness I'm seeing in the \"PC-98\" pixel patterns.\n \nreply",
      "IMO PC-98 is unique because it sits between EGA and VGA in capabilities; it is still a 16 color display, but from a much broader palette (4096 vs 64).  EGA is very distinctive because of the limited palette.\n \nreply",
      "Indeed, starting with IBM's initial 5150 design, early PC graphics made cost, memory and capability trade-offs which would soon be seen as unfortunate from a graphics and gaming perspective. Although IBM specced the platform and chose Motorola's 6845 video display chip, I assign some blame to Motorola too for not having created a range of video chips with increasing capabilities to choose from. We'll never know if IBM would have ponied up a few dollars more for a chip with at least a 256 color palette or a few other niceties but it's always possible.Strangely, Motorola did eventually decide to get serious about offering more capable graphics in the form of the RMS chipset but not until it was already too little and too late. They announced the RMS chipset in 1984 and tried to drum up interest among system designers but eventually cancelled it before release amidst lukewarm response and bugs in the early prototypes (https://retrocomputing.stackexchange.com/questions/10977/fat...). It certainly didn't help that other options like TI's 99x8 VDP chips were now getting cheaper and the pre-Commodore Hi-Toro company was shopping around their Amiga chipset in 1984.\n \nreply",
      "I remember trying to install Slackware as a 16 year old living as an exchange student in Japan and not getting anywhere. Turns out PC98 needed a patched kernel.\n \nreply",
      "Because hug of death:\nhttps://archive.is/iBrYt\n \nreply",
      "Apparently this site is hosted by a PC-98 too...\n \nreply",
      "This emulation seems to say pc98 is msdos based and hence can run on dosbox-xhttps://dosbox-x.com/wiki/Guide%3APC%E2%80%9098-emulation-in...Seeing some yt even more confused as pointed out by wiki it is a 16/32 bit \u2026\n \nreply",
      "So far only collect 2 Casio one basic and one, well, lisp (!) calculators \u2026 interesting artefacts.  Still try to get a national those tube-like display scientific calendars used during my senior secondary school.This is a total different genre.  So hard level \u2026. In 1980s just thought it was a j model to be \u2026 wonder any simulation would see as collecting one just have a look is impossible.\n \nreply",
      "PC-98 eroge art is beautiful.  These writers\u2014who freely take pot-shots at the \u201cperverted\u201d hikikomori of 30 years ago\u2014wouldn\u2019t dare criticize the hardcore pornography (Bonnie Blue?  The OnlyFans Economy!) the world is presently steeped in.  It\u2019s like they know which waggle dance lets you in, and which one gets you booted from the hive\u2026\n \nreply",
      "To criticise Bonnie Blue is to criticise female sexuality. To criticise Eroge is to criticise male sexuality.Like you say, only one of those is acceptable to the hive. In fact one must be loudly cheered, and one must be at least quietly, obligatorily shunned.\n \nreply"
    ],
    "link": "https://strangecomforts.com/the-strange-world-of-japans-pc-98-computer/",
    "first_paragraph": "",
    "summary": "**Strangecomforts.com Discovers Japan's PC-98**: In a dazzling display of nostalgia-fueled 'journalism', Strangecomforts.com drags readers back to the obscure world of Japan\u2019s PC-98 computer systems, which most people stopped caring about when zip drives were still hot tech. The comment section quickly becomes a hipster Olympics as enthusiasts brag about their collections of outdated tech. One user, claiming a boot failure on his PC-98 during a teenage exchange in Japan, unironically wins top victim status. All the while, the thread devolves into a squabble about the artistic merits of long-forgotten eroge, proving that no niche is too small for an Internet argument."
  },
  {
    "title": "A Formal Proof of Complexity Bounds on Diophantine Equations (arxiv.org)",
    "points": 55,
    "submitter": "badmonster",
    "submit_time": "2025-05-23T20:09:01 1748030941",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44076170",
    "comments": [
      "A mind-blowing consequence of the MRDP theorem is that there is a multi-variate polynomial which fits on a sheet of paper with the property that the set of values of the first variable which appear in integer solutions are exactly the set of prime numbers.https://en.wikipedia.org/wiki/Formula_for_primes#Formula_bas...\n \nreply",
      "I found https://x.com/gm8xx8/status/1925768687618773079 to be a little more understandable summary of what was actually shown.Any Diophantine equation can be reduced to one of at most 11 variables and degree at most around 10^63. No algorithm can decide solvability in rational numbers for this class of Diophantine equations.\n \nreply",
      "That sounds like the coefficients might have to be arbitrarily large.  Otherwise all DE's could reduce to a finite set of them, impossible via the MRDP theorem.  So it's not so easy to call that bounded complexity.\n \nreply",
      "Does this have any practical consequences for cryptography?\n \nreply",
      "impressive formalization effort that bridges deep number theory and formal methods\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2505.16963",
    "first_paragraph": "Work on one of the world's most important websites and make an impact on open science.arXiv Is Hiring a DevOps EngineerHelp | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n",
    "summary": "### Academics Prove Numbers Hard, Internet Explodes\n\nIn a stunning display of what happens when mathematicians have too much free time, some academics managed to scribble down a proof showing just how ridiculously complex Diophantine equations can get. Meanwhile, over at arXiv, where this gem was dropped like a hot potato, tech recruiters skillfully sneak in a job ad, hoping to snag a DevOps savior by disguising it as a call for \"open science.\" Commenters, in their infinite wisdom, oscillate between wondering if this marvel will stop hackers in their tracks and marveling at the sheer size of numbers involved - because nothing says \"productive discussion\" like a debate over whether you need a quantum computer to appreciate prime number puzzles. \"Impressive,\" claps one user, likely thrilled to catch a glimpse of this esoteric numerical beast from the safe distance of their browser, sparing them the horror of actually understanding it. \ud83d\ude43"
  },
  {
    "title": "Show HN: I built a more productive way to manage AI chats (contextch.at)",
    "points": 52,
    "submitter": "tapeo",
    "submit_time": "2025-05-23T20:46:04 1748033164",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=44076449",
    "comments": [
      "I thought about building something along these lines (not the same but vaguely similar).Then Gemini AI Studio came along with a 1 million token window and allowed me to upload zip files of my entire code base and I lost interest in my own thing.\n \nreply",
      "Yes the long context it's complementary, in other chat services like Gemini you have to rewrite that base context everytime for each new fresh chat, plus they lack of specific data import tools and projects management\n \nreply",
      "It technically handles 1M tokens, but if you ask it questions it's obvious that it's too much to handle.Just upload a novel and ask it questions, you'll see how it botches simple stuff\n \nreply",
      "Easiest way to prove it can't handle the full context in reality is to upload a one hour documentary movie with audio and ask it to write timestamps of chapters/critical moments. It can't handle this beyond 10 minutes even remotely reliably.\n \nreply",
      "Good or bad it's a zillion times better than Claude or ChatGPT where you can't even upload a zipfile.\n \nreply",
      "Compare to Claude Projects?https://www.anthropic.com/news/projects\n \nreply",
      "Isn't NotebookLM already exactly web and file context (a \"ContextChat\")?Edit: I assume it is basically a similar product, but your differentiators are mainly the customer getting to choose their model, and you getting to write your own context adding ergonomics (like adding links from a Sitemap)?\n \nreply",
      "Exactly, similar plus tools to import and manage projects context fast (like GitHub private repos and sitemaps url), multiple ai model and pay per use like using APIs\n \nreply",
      "Cool! I was excited when I saw this and signed up.One key thing I was hoping for was a consistent resync with source material particularly google docs. Looks like I'll have to download then upload to your app whenever they change.Is that right? Auto syncing in the plan?\n \nreply",
      "Auto syncing added to the plan!\n \nreply"
    ],
    "link": "https://contextch.at",
    "first_paragraph": "",
    "summary": "**Show HN: Someone Recreated AI Chat Management, This Time with Decorations**  \nIn a valiant attempt to reinvent the wheel, a Hacker News user introduces \"contextch.at,\" which promises a revolutionary way to manage AI chats by essentially doing what every other service does but with a different logo. The commenters leap into action, competing for the grand prize in Missing The Point. One user barely mourns their own unfinished project, another discovers the limitations of stuffing War and Peace into a chatbot, and yet another gets thrilled over a basic feature dressed up as innovation. Meanwhile, technical comparisons spin into oblivion, ensuring that the cycle of AI chat discussions remains as productively redundant as ever. \ud83d\udd04\ud83e\udd16\ud83d\udca4"
  },
  {
    "title": "The Way of Code: The Timeless Art of Vibe Coding (thewayofcode.com)",
    "points": 8,
    "submitter": "CharlesW",
    "submit_time": "2025-05-24T00:11:25 1748045485",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.thewayofcode.com/",
    "first_paragraph": "",
    "summary": "On *thewayofcode.com*, a self-proclaimed code sage unveils the mystical secrets of \u201cVibe Coding,\u201d a revolutionary approach guaranteed to enhance your programming by interweaving inexplicable metaphysical babble with basic software principles. As expected, the article's substance is as nebulous as fog in San Francisco, insisting that the path to coding enlightenment is paved with Zen quotes rather than practical examples. The comments section blossoms into a chaotic symposium of armchair philosophers and overnight coding gurus, each participant more eager than the last to demonstrate their profound misunderstanding of both programming and Eastern philosophy. \ud83d\ude02 Unsurprisingly, the only tangible takeaway here is that the real \"vibe\" is the collective delusion that reading pithy, pseudo-inspirational nonsense can substitute for actual coding expertise."
  },
  {
    "title": "Show HN: DoubleMemory \u2013 more efficient local-first read-it-later app (doublememory.com)",
    "points": 83,
    "submitter": "randomor",
    "submit_time": "2025-05-23T18:55:28 1748026528",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44075451",
    "comments": [
      "Looks like a really interesting idea here! Congrats on shipping. I just downloaded it to play around with. The screenshots are well done and make the app feel like something exciting to try out.I would work on trying to simplifying the landing page copy, though. The \"Stress-Free Bookmarking, Read-it-later, and Clipboard...\" text is super long and most people aren't going to read the entire thing. I would try to emphasize what the benefit is to the user somehow. Something like \"Save everything easily\". That's terrible copy, too, but you get the idea. The \"Super Memory Activated\" and \"doublememory.com\" made me think at first that this is improving my computer's memory usage.After skimming the page, I kind of got the idea about what the product does, but I think you can make it even simpler to grok right away what it does with a few tweaks. Best of luck!Edit: one thing I noticed is I can do shift-cmd-spacebar to bring it up, but the search text field doesn't automatically get focus. That's a little bit of friction. If I do cmd-F to search, it toggles the filter UI, which was unexpected. I wanted to cmd-F to move the focus into the search to start typing.\n \nreply",
      "That's gold. Thank you! Yes the refocusing can be unreliable. Currently the more reliable way is press tab to refocus. I'll work on the landing page, as that hasn't been updated for months and it's slightly outdated and didn't even highlight the now available iOS app.\n \nreply",
      "That looks pretty neat! I haven't played around with it yet, but here's some preliminary feedback:* \"\u2318 + C + C\", to me, means \"press cmd-C, then press C\". It look me a minute to release it means \"press cmd-C twice\".* Thank you for using iCloud sync!* Your privacy policy says \"The developer does not collect any data from this app.\". Thank you!* The pricing feels high to me. I'm mentally comparing it to PastePal (clipboard manager, one-time $15 payment) plus GoodLinks (bookmarks manager, $5 per year to buy upgrades, but you can use it forever for free). I know it's not an exact comparison, but as someone who might really like your app, that's how I personally think of it.\n \nreply",
      "Agree with with everything, if there was a way to use something besides icloud that would be very appreciated. I have nothing against it but the more options there are, the better.\n \nreply",
      "True. More options and more controls always better, just need to balance priorities. What specific sync options are you thinking?\n \nreply",
      "Thanks for these feedback. I'll take note.About the pricing, I just realized my introduction pricing has expired last night. I just created one again for $9.99 for the first year. However, I'm definitely exploring pricing, but as I mentioned right now the sub is simply a way for me to gather signal for interests, no features are behind paywalls, you only benefit of subbing right now is lock-in the early price and remove the sub button. I'll be working on real value generating features in the future.Long term, I'm hoping to implement fair and incremental upgrades, it just takes more setup.... My current pricing is kinda anchored with ReadWise & Paste, which are 200% more than what I charge. I'm also guessing many people are looking for a lifetime purchase, I'll definitely work on that at some point, people who've subscribed will be able to redeem it directly with me once that's available.\n \nreply",
      "What kind of \u201cvalue-generating\u201d features are you thinking of?One big comment I want to give on that front is, if you decide to try any generative AI features, please please please make them *completely opt-in* and integrate with *local models* (either completely or as an alternative to cloud models like GPT / Claude / etc). If I can use your software happily without being bombarded with ads for AI features and can use those AI features how I want to instead of how would best make you money, I would appreciate that so much.\n \nreply",
      "You got it. Yes, AI will be a good piece of the puzzle. Local models is exactly what I prefer, if you haven't notice, that's a big principle of this app. I'm really hoping Apple can step in and offer a local model so I don't have to download one big blob. Supporting Ollama sounds cool but I feel like that's a big barrier for many... BYOK also nice, but at that point why not just build a MCP interface instead of building another flavor of AI chat? Otherwise I'm thinking about embedding all items so it's easier to: auto-generate tags, cluster by topics etc...\n \nreply",
      "as initial step, just do some \u201crag\u201d / vector db thing ie. no llm. see chrome\u2019s embedded model and how it works.\n \nreply",
      "That makes a lot of sense. And I\u2019m not saying your current pricing is wrong. I\u2019m just some rando. What do I know?I\u2019d definitely prefer a lifetime purchase, or even an option to pay to unlock new features for the next year and then keep those features forever, like GoodLinks does. I\u2019m a huge fan of that pricing model.\n \nreply"
    ],
    "link": "https://doublememory.com",
    "first_paragraph": "",
    "summary": "Welcome to the latest \"revolutionary\" app in the market: DoubleMemory, a read-it-later app that's desperately trying to convince us that it's nothing like the other apps we've abandoned in our cluttered digital drawers. The Hacker News community leaps into action, offering life-saving advice about simplifying the landing page. One user struggles with a complex command sequence that might as well be an arcane spell to summon Chthulhu, while others get into a capitalist spasm over subscription models and pricing comparisons to every other semi-related app. Is it an app? Is it a memory upgrade? Is it a substitute for your lost ambition? Who knows! But, please, make sure to opt-in to AI features to make the code goblins happy and \u2013 just maybe \u2013 turn your chaos of half-read articles into a neatly tagged digital utopia. \ud83d\udcda\ud83d\udcbb\ud83d\udd2e"
  },
  {
    "title": "Positional preferences, order effects, prompt sensitivity undermine AI judgments (cip.org)",
    "points": 100,
    "submitter": "joalstein",
    "submit_time": "2025-05-23T17:20:40 1748020840",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=44074668",
    "comments": [
      "I've done experiments and basically what I found was that LLM models are extremely sensitive to .....language. Well, duh but let me explain a bit. They will give a different quality/accuracy of answer depending on the system prompt order, language use, length, how detailed the examples are, etc...  basically every variable you can think of is responsible for either improving or causing detrimental behavior in the output. And it makes sense once you really grok that LLM;s \"reason and think\" in tokens.  They have no internal world representation.  Tokens are the raw layer on which they operate.  For example if you ask a bilingual human what their favorite color is, the answer will be that color regardless of what language they used to answer that question.  For an LLM, that answer might change depending on the language used, because its all statistical data distribution of tokens in training that conditions the response. Anyway i don't want to make a long post here. The good news out of this is that once you have found the best way in asking questions of your model, you can consistently get accurate responses, the trick is to find the best way to communicate with that particular LLM.  That's why i am hard at work on making an auto calibration system that runs through a barrage of ways in finding the best system prompts and other hyperparameters for that specific LLM.  The process can be fully automated, just need to set it all up.\n \nreply",
      "I somewhat agree, but I think that the language example is not a good one. As Anthropic have demonstrated[0], LLMs do have \"conceptual neurons\" that generalise an abstract concept which can later be translated to other languages.The issue is that those concepts are encoded in intermediate layers during training, absorbing biases present in training data. It may produce a world model good enough to know that \"green\" and \"verde\" are different names for the same thing, but not robust enough to discard ordering bias or wording bias. Humans suffer from that too, albeit arguably less.[0] https://transformer-circuits.pub/2025/attribution-graphs/bio...\n \nreply",
      "I have learned to take these kinds of papers with a grain of salt, though. They often rest on carefully selected examples that make the behavior seem much more consistent and reliable than it is. For example, the famous \"king - man + woman = queen\" example from Word2Vec is in some ways more misleading than helpful, because while it worked fine for that case it doesn't necessarily work nearly so well for [emperor, man, woman, empress] or [husband, man, woman, wife].You get a similar thing with convolutional neural networks. Sometimes they automatically learn image features in a way that yields hidden layers that easy and intuitive to interpret. But not every time. A lot of the time you get a seemingly random garble that belies any parsimonious interpretation.This Anthropic paper is at least kind enough to acknowledge this fact when they poke at the level of representation sharing and find that, according to their metrics, peak feature-sharing among languages is only about 30% for English and French, two languages that are very closely aligned. Also note that this was done using two cherry-picked languages and a training set that was generated by starting with an English language corpus and then translating it using a different language model. It's entirely plausible that the level of feature-sharing would not be nearly so great if they had used human-generated translations. (edit: Or a more realistic training corpus that doesn't entirely consist of matched translations of very short snippets of text.)Just to throw even more cold water on it, this also doesn't necessarily mean that the models are building a true semantic model and not just finding correlations upon which humans impose semantic interpretations. This general kind of behavior when training models on cross-lingual corpora generated using direct translations was first observed in the 1990s, and the model in question was singular value decomposition.\n \nreply",
      "I found an absolutely fascinating analysis on precisely this topic by an AI researcher who's also a writer: https://archive.ph/jgam4LLMs can generate convincing editorial letters that give a real sense of having deeply read the work. The problem is that they're extremely sensitive, as you've noticed, to prompting as well as order bias. Present it with two nearly identical versions of the same text, and it will usually choose based on order. And social proof type biases to which we'd hope for machines to be immune can actually trigger 40+ point swings on a 100-point scale.If you don't mind technical details and occasional swagger, his work is really interesting.\n \nreply",
      "This doesn't match Anthropics research on the subject> Claude sometimes thinks in a conceptual space that is shared between languages, suggesting it has a kind of universal \u201clanguage of thought.\u201d We show this by translating simple sentences into multiple languages and tracing the overlap in how Claude processes them.https://www.anthropic.com/research/tracing-thoughts-language...\n \nreply",
      "Yep, LLMs tell you \"what you want to hear.\" I can usually predict the response I'll get based on how I phrase the question.\n \nreply",
      "I feel like LLMs have a bit of the Clever Hans effect. It takes a lot of my cues as to what it thinks I want it to say or opinion it thinks I want it to have.Clever Hans was a horse who people thought could do maths by tapping his hoof. But actually he was just reading the body language of the person asking the question. Noticing them tense up as he got to the right number of stamps and stopping - still pretty smart for a horse, but the human was still doing the maths!\n \nreply",
      "What's worse is that it can sometimes (but not always) read through your anti-bias prompts.    \"No, I want your honest opinion.\" \"It's awesome.\"\n    \"I'm going to invest $250,000 into this. Tell me what you really think.\" \"You should do it.\"\n\n    (New Session)\n\n    \"Someone pitched to me the idea that...\" \"Reject it.\"\n \nreply",
      "Once can see that very easily in image generation models.The \"Elephant\" it generates is lot different from \"Haathi\" (Hindi/Urdu). Same goes for other concepts that have 1-to-1 translation but the results are different.\n \nreply",
      "I thought embeddings were the internal representation? Does reasoning and thinking get expanded back out into tokens and fed back in as the next prompt for reasoning? Or does the model internally churn on chains of embeddings?\n \nreply"
    ],
    "link": "https://www.cip.org/blog/llm-judges-are-unreliable",
    "first_paragraph": "By James PadolseyBeyond their everyday chat capabilities, Large Language Models are increasingly being used to make decisions in sensitive domains like hiring, health, law, and civic engagement. The exact mechanics of how we use these models in such scenarios is vital. There are many ways to have LLMs make decisions, including A/B decision-making, ranking, classification, \"panels\" of judges, etc. but every single method is individually fragile and subject to measurement biases that are rarely discussed.Engineers composing prompts often rely on anecdotes and untested folklore. We call it 'prompt-engineering': the practice of composing prompts to coax precisely the outputs we desire. However, it might be described better as 'playing' than 'engineering'. There are popular templates and tropes, but few are well proven. You'll often see high level instructions like \"you are an [adjective] [role]\", e.g. \"you are an impartial judge\". Throw in a superlative here and there, maybe some ALL-CAPS ",
    "summary": "**AI Goes To School, Fails Every Subject**\nJust when you thought AI couldn't get any more *biased*, a groundbreaking <em>expos\u00e9</em> graces cip.org, revealing that \u2013 surprise! \u2013 the way you ask AI a question influences its tantrum, er, answer. Cue a chorus of engineers and their script-kiddie sidekicks in the comments, led by Captain Obvious, debating whether \"green\" means the same thing in English and French or if rephrasing a prompt can magically turn a penny into a software patent. Meanwhile, every comment reads like someone just discovered that asking questions in different ways can yield different results, a nuanced discovery sure to shake the very foundations of asking people for directions. Watch out, Clever Hans \u2013 you might be out of a job soon! \ud83d\udc0e\ud83d\udcbb"
  },
  {
    "title": "A Bead Too Far: Rethinking Global Connections Before Columbus (peterfrankopan.substack.com)",
    "points": 13,
    "submitter": "themgt",
    "submit_time": "2025-05-23T14:22:48 1748010168",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://peterfrankopan.substack.com/p/a-bead-too-far-rethinking-global",
    "first_paragraph": "",
    "summary": "The self-appointed history mavens at peterfrankopan.substack.com churn out another revelation: apparently, Columbus didn\u2019t use WhatsApp to plan his grocery runs to the New World. In \"A Bead Too Far: Rethinking Global Connections Before Columbus,\" Peter Frankopan decides it's crucial to educate the internet masses about the shocking existence of trade routes pre-1492. Cue the shocked emojis from readers who thought \u201cSilk Road\u201d was just a dark web marketplace. In the comments, modern-day Marco Polos battle over semantics, while others lament the absence of Vikings and aliens in their school textbooks. The true historical discovery here: comment sections have more drama than the fall of empires. \ud83d\udcdc\ud83d\udea2\ud83d\udc7d"
  },
  {
    "title": "UndoDB \u2013 The interactive time travel debugger for Linux C/C++ for debugging (undo.io)",
    "points": 36,
    "submitter": "droideqa",
    "submit_time": "2025-05-23T20:22:09 1748031729",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=44076300",
    "comments": [
      "What's the difference with RR?\n \nreply",
      "[rr developer here]Undo has cool features like Live Recording that we don't have in rr.\nThey don't need access to the hardware PMU which is a big advantage in some situations.\nThey can handle accesses to shared memory in cases where rr can't.\nhttps://undo.io/resources/undo-vs-rr/ is a good resource.\n \nreply",
      "AFAIK it records multithreaded applications on multiple threads and CPU, rr records them on a single OS thread, AFAIK. Not sure about replay. Never used undo though, so not sure how much better it is.\n \nreply",
      "rr does support multithreaded and multi-process applications, via, like Undo[1], allowing only a single thread to run at a time. (edit note - that's only about multithreading; Undo might have parallel multi-process recording)[1]: https://undo.io/resources/undo-performance-benchmarks/ - \"Undo serializes their execution\"\n \nreply",
      "I stand corrected, not sure where I heard this then.\n \nreply",
      "https://undo.io/resources/undo-vs-rr/ does note parallel recording for multi-process (not multi-threaded), so perhaps that.\n \nreply",
      "This one has a flashy website and a marketing department\n \nreply",
      "Let me save you a click:Pricing & LicensingA UDB floating license costs $7,900 per year.\n \nreply",
      "rr is awesome and is free and open and all that. How much better could this possibly be?\n \nreply",
      "They have a comparison page:\nhttps://undo.io/resources/undo-vs-rr/I was in talks with them recently because I kept running into limitations with rr. The main advantages for my use case were that undo doesn't have the same dependency on hardware timers, which means the ARM support is much better, you can run it in a VM (e.g. a cloud machine) and you can do replays on different systems.\n \nreply"
    ],
    "link": "https://undo.io/",
    "first_paragraph": "",
    "summary": "In the latest installment of \"Who Can Debug It Better?\", <em>UndoDB</em> dazzles the (few) masses with features that make <em>rr</em> developers salivate and reconsider their life choices. Commenters, armed with a newfound purpose, dissect the nuances between live recording and needing a hardware PMU like it's the tech equivalent of the Da Vinci Code. Meanwhile, a singular hero points out that for the low, low price of only $7,900 per year, you too can abandon the plebeian joys of free software for something that runs on... a cloud machine. Because if you can't brag about using overpriced tools at virtual water coolers, are you even a real developer? \ud83d\udcb8\ud83d\ude43"
  },
  {
    "title": "Beyond Semantics: Unreasonable Effectiveness of Reasonless Intermediate Tokens (arxiv.org)",
    "points": 100,
    "submitter": "nyrikki",
    "submit_time": "2025-05-23T16:13:43 1748016823",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44074111",
    "comments": [
      "I think it\u2019s helpful to remember that language models are not producing tokens, they are producing a distribution of possible next tokens. Just because your sampler picks a sequence of tokens that contain incorrect reasoning doesn't mean a useful reasoning trace isn\u2019t also contained within the latent space.It\u2019s a misconception that transformers reason in token space. Tokens don\u2019t attend to other tokens. High dimensional latents attend to other high dimensional latents. The final layer of a decoder only transformer has full access to entire latent space of all previous latents, the same latents you can project into a distribution of next tokens.\n \nreply",
      "> Just because your sampler picks a sequence of tokens that contain incorrect reasoning doesn't mean a useful reasoning trace isn\u2019t also contained within the latent space.That's essentially the core idea in Coconut[1][2], to keep the reasoning traces in a continuous space.[1]: https://arxiv.org/abs/2412.06769[2]: https://github.com/facebookresearch/coconut\n \nreply",
      "So you're saying that the reasoning trace represents sequential connections between the full distribution rather than the sampled tokens from that distribution?\n \nreply",
      "The lower dimensional logits are discarded, the original high dimensional latents are not.But yeah, the LLM doesn\u2019t even know the sampler exists. I used the last layer as an example, but it\u2019s likely that reasoning traces exist in the latent space of every layer not just the final one, with the most complex reasoning concentrated in the middle layers.\n \nreply",
      "I don't think that's accurate. The logits actually have high dimensionality, and they are intermediate outputs used to sample tokens. The latent representations contain contextual information and are also high-dimensional, but they serve a different role--they feed into the logits.\n \nreply",
      "The dimensionality I suppose depends on the vocab size and your hidden dimension size, but that\u2019s not really relevant. It\u2019s a single linear projection to go from latents to logits.Reasoning is definitely not happening in the linear projection to logits if that\u2019s what you mean.\n \nreply",
      "Either I'm wildly misunderstanding or that can't possibly be true--if you sample at high temperature and it chooses a very-low probability token, it continues consistent with the chosen token, not with the more likely ones\n \nreply",
      "Attention computes a weighted average of all previous latents. So yes, it\u2019s a new token as input to the forward pass, but after it feeds through an attention head it contains a little bit of every previous latent.\n \nreply",
      "Man that \"Unreasonable Effectiveness of ...\" pattern is getting a bit overused. With the original paper [1] you could still say that there really is some deeply philosophical mystery. But they now slap that on everything.[1] https://en.m.wikipedia.org/wiki/The_Unreasonable_Effectivene...\n \nreply",
      "Engineering blogger's love of parroting the titles of famous papers/articles (unreasonable effectiveness..., all you need is..., ... Considered harmful, etc) has always been lightly annoying to me\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2505.13775",
    "first_paragraph": "Work on one of the world's most important websites and make an impact on open science.arXiv Is Hiring a DevOps EngineerHelp | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n",
    "summary": "Today in the world of arXiv, where the primary mission is saving the universe with open access papers, we encounter yet another whimsical attempt to jazz up a basically mundane concept with a dramatic title: *Beyond Semantics: Unreasonable Effectiveness of Reasonless Intermediate Tokens*. Over in the comment section, digital prophets and armchair philosophers are engaged in a Talmudic dissection of tokens and latents, each comment more convoluted than the last. Apparently, nobody remembers that this isn't String Theory, it's just computers guessing what word comes next. Meanwhile, somewhere in the background, a desperate plea for DevOps heroes gets drowned out by the sound of self-importance and the incessant clapping of self-back-patting. \ud83e\udd16\ud83d\ude80\ud83d\udcda"
  },
  {
    "title": "John Carmack talk at Upper Bound 2025 (twitter.com/id_aa_carmack)",
    "points": 483,
    "submitter": "tosh",
    "submit_time": "2025-05-23T05:14:16 1747977256",
    "num_comments": 325,
    "comments_url": "https://news.ycombinator.com/item?id=44070042",
    "comments": [
      "It's always a treat to watch a Carmack lecture or read anything he writes, and his notes here are no exception. He writes as an engineer, for engineers and documents all his thought processes and misteps in the exact detailed yet concise way you'd want a colleague to who was handing off some work.One question I would have about the research direction is the emphasis on realtime. If I understand correctly he's doing online learning in realtime. Obviously makes for a cool demo and pulls on his optimisation background, and no doubt some great innovations will be required to make this work. But I guess the bitter lesson and recent history also tell us that some solutions may only emerge at compute levels beyond what is currently possible for realtime inference let alone learning. And the only example we have of entities solving Atari games is the human brain, of which we don't have a clear understanding of the compute capacity. In which case, why wouldn't it be better to focus purely on learning efficiency and relax the realtime requirement for now?That's a genuine question by the way, definitely not an expert here and I'm sure there's a bunch of value to working within these constraints. I mean, jumping spiders solve reasonably complex problems with 100k neurons, so who knows.\n \nreply",
      "I'm sure there were offline rendering and 3D graphics workstation people saying the same about the comparatively crude work he was doing in the early 90s...Obviously both Carmack and the rest of the world has changed since then, but it seems to me his main strength has always been in doing more with less (early id/Oculus, AA). When he's working in bigger orgs and/or with more established tech his output seems to suffer, at least in my view (possibly in his as well since he quit both Bethesda-id and Meta).I don't know Carmack and can't claim to be anywhere close to his level, but as someone also mainly interested in realtime stuff I can imagine he also feels a slight disdain for the throw-more-compute-at-it approach of the current AI boom. I'm certainly glad he's not running around asking for investor money to train an LLM.Best case scenario he teams up with some people who complement his skillset (akin to the game designers and artists at id back in the day) and comes up with a way to help bring some of the cutting edge to the masses, like with 3D graphics.\n \nreply",
      "The thing about Carmack in the 90s...\nThere was a lot of research going on around 3d graphics. Companies like SGI and Pixar were building specialized workstations for doing vector operations for 3d rendering. 3d was a thing. Game consoles with specialized 3d hardware would launch in 1994 with the Sega Saturn and the Sony Playstation (in Japan only for one year)What Carmack did was basically get a 3d game running on existing COMMODITY hardware. The 386 chip that most people used for their excel spreadsheets did not do floating point operations well, so Carmack figured out how to do everything using integers.May 1992 -> Wolfenstein 3d releases\nDecember 1993 -> Doom releases\nDecember 1994 -> Sony Playstation launches in Japan\nJune 1996 -> Quake releasesSo Wolfenstein and Doom were actually not really 3d games, but rather 2.5 games (you can't have rooms below other rooms). The first 3d game here is actually Quake which also eventually also got hardware acceleration support.Carmack was the master of doing the seeminly impossible on super constrained hardware on virtually impossible timelines. If DOOM released in 1994 or 1995, would we still remember it in the same way?\n \nreply",
      "> If DOOM released in 1994 or 1995, would we still remember it in the same way?Maybe.  One aspect of Wolfenstein and Doom's popularity is that it was years ahead of everyone else technically on PC hardware.  The other aspect is that they were genre defining titles that set the standards for gameplay design.  I think Doom Deathmatch would have caught on in 1995, as there really were very few (just Command and Conquer?) standout PC network multiplayer games released between 1993 and 1995.\n \nreply",
      "I guess the thing about rapid change is... it's hard to imagine what kind of games would exist in a DOOMless world in an alternate 1995.The first 3d console games started to come out that year, like Rayman.\nStar Wars Dark Forces with its own custom 3d engine also came out. Of course Dark Forces was, however, an overt clone of DOOM.It's a bit ironic, but I think the gameplay innovation of DOOM tends to hold up more than the actual technical innovation. Things like BSP for level partitioning have slowly been phased out of game engines, we have ample floating point compute power and hardware acceleration ow, but even developers of the more recent DOOM games have started to realize that they should return to the original formula of \"blast zombies in the face at high speed, and keep plot as window dressing\"\n \nreply",
      "> but even developers of the more recent DOOM games have started to realize that they should return to the original formula of \"blast zombies in the face at high speed, and keep plot as window dressing\"There's still a lot of chatter breaking the continuity. In the original, the plot was entirely made up of what you were experiencing directly.\n \nreply",
      "> The first 3d console games started to come out that year, like Rayman.Rayman was a 2D game.\n \nreply",
      "Sort of in the middle, id games always felt tight. The engines were immersive not only because of graphics, but basic i/o was excellent.\n \nreply",
      "Hardware changes a lot in the time it takes to develop a game.\nWhen I read his plan files and interviews, I realized he seemed to spend a lot of time before developing the game thinking about what the next gen hardware was going to bring. Then design the best game they could think of whike targeting this not-yet-available hardware.\n \nreply",
      "The world seems to have rewritten history, and forgotten Ultima Underworld, which shipped prior to Doom..\n \nreply"
    ],
    "link": "https://twitter.com/ID_AA_Carmack/status/1925710474366034326",
    "first_paragraph": "",
    "summary": "At the revered summit of Upper Bound 2025, John Carmack, the eternal geek messiah, delivers yet another sermon from the mount, transmuting complex real-time AI optimizations into palatable geek bites for the engineering congregation. This draws in droves of faithful followers eagerly nodding at every technical reveal, their comments a holy scripture of \"Ah, yes, very insightful!\" sprinkled with half-baked analogies to spiders with tiny brains. Critics dare to inquire about the practicality of real-time demands over learning efficiency, but are quickly hushed by Carmack's wisdom or drowned by fanboys fantasizing about 3D graphics renaissances. Meanwhile, the rest of us wonder why we aren't just focusing on getting decent Wi-Fi coverage. \ud83d\ude44"
  },
  {
    "title": "Visual Studio Code: Text Buffer Reimplementation (2018) (visualstudio.com)",
    "points": 17,
    "submitter": "stefankuehnel",
    "submit_time": "2025-05-20T09:34:15 1747733655",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://code.visualstudio.com/blogs/2018/03/23/text-buffer-reimplementation",
    "first_paragraph": "Try agent mode in VS Code!March 23, 2018 by Peng Lyu, @njukidrebornThe Visual Studio Code 1.21 release includes a brand new text buffer implementation which is much more performant, both in terms of speed and memory usage. In this blog post, I'd like to tell the story of how we selected and designed the data structures and algorithms that led to those improvements.Performance discussions about JavaScript programs usually involve a discussion about how much should be implemented in native code. For the VS Code text buffer, these discussions started more than a year ago. During an in-depth exploration, we found that a C++ implementation of the text buffer could lead to significant memory savings, but we didn't see the performance enhancements we were hoping for. Converting strings between a custom native representation and V8's strings is costly and in our case, compromised any performance gained from implementing text buffer operations in C++. We will discuss this in more detail at the ",
    "summary": "**Visual Studio Code Levels Up by Rewriting the Alphabet**\n\nIn the latest act of what can only be described as _heroic keyboard smashing_, the Visual Studio Code team has graced the huddled masses with a \"brand new\" text buffer that promises the moon: more speed, less memory use, and, undoubtedly, the power to write code that writes itself. Our blog hero, Peng Lyu, does battle with the ineffable evil of JavaScript performance, wielding the mighty sword of C++ to slay memory dragons. Yet, the tale quickly turns tragicomic as the burdens of cross-language conversions render the magnificent sword nearly blunt. The comment section, as always, is a bustling forum of armchair software architects who've never met a problem that couldn't be solved by rewriting everything in Rust. \ud83e\udd13\ud83d\ude80"
  },
  {
    "title": "Types of optical systems in a lens designer's toolbox (2020) (pencilofrays.com)",
    "points": 52,
    "submitter": "picture",
    "submit_time": "2025-05-23T18:33:07 1748025187",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44075254",
    "comments": [
      ">Who this guide is NOT for: [...] People that are okay with becoming a lens design zombie.https://web.archive.org/web/20230914035459/https://caoyuan.s...A $500 DIY near-IR spectrometer that would sell for $10,000, Yuan Cao>The placement of the cylindrical lens (position & angle) affects the focal point for different wavelength. I did not do a rigorous calculation here \u2014\u2014 I simply resorted to a trial-and-error method to figure out the optimal placement.https://news.ycombinator.com/item?id=37498142\n \nreply",
      "If you want to play with any of these lens descriptions (or look at code for simulating them), I made a free and open source visual web UI for lens design. The default project when you visit it is a double gauss lens similar to the one shown in the article.https://alexbock.github.io/open-optical-designer/\n \nreply",
      "Is there a framework or template base for these kind of (usually scientific) demonstration apps? It\u2019s a common design language of inputs and output that I\u2019ve seen in many pages, often self-explanatory. I like it.\n \nreply",
      "Thanks. I did not use any frameworks/libraries/dependencies for this project. It's vanilla JavaScript/HTML/CSS from scratch. The general concept of a spreadsheet-like data editor next to a visual view is a standard paradigm in commercial lens design software like Quadoa/OSLO/CODE V.\n \nreply",
      "Took a look and I'm impressed how easy it is to use. Thanks for sharing this.\n \nreply",
      "amazing tool - thanks for sharing\n \nreply",
      "I always wanted to play with Optica for Mathematica. It seems like a problem that would lend itself really well to the Wolfram way of visual + functional programming. However I've never met anyone who uses it and while academics usually get Mathematica for free, the plugin is pricey.https://www.opticasoft.com/tourhttps://www.opticasoft.com/copy-of-lenslab\n \nreply",
      "I remember playing around with a lenses and light sources simulator, but can\u2019t find the link :-(\nIf I\u2019m not mistaken it was posted here on HN but couldn\u2019t find it by searching with various related keywords.\nIf anyone has it please share :-)\n \nreply",
      "I'm guessing you're referring to https://news.ycombinator.com/item?id=39309409\n \nreply",
      "Potentially relevant:   Show HN: Torch Lens Maker \u2013 Differentiable Geometric Optics in PyTorch (63 days ago) 2025-03-21\n\nhttps://news.ycombinator.com/item?id=43435438https://victorpoughon.github.io/torchlensmaker/\n \nreply"
    ],
    "link": "https://www.pencilofrays.com/lens-design-forms/",
    "first_paragraph": "A Pencil of Raysput things in focusThere are so many optical systems that are out there. Why is one lens type used over the other? What lens design for do I need for this system?What lens design alternatives should I consider?Can I use this lens somewhere else?What if we don\u2019t know where to start with the lens design, when only given a specification sheet?This is an Ultimate Guide of lens design forms, the optical systems that are used in our world.The basic lens design forms are in here, and we can take a deep look into the development of lens design. But the not all the lens designs are simple lenses, we will look at newer and important lens design forms as well.You\u2019d be surprised to see what lenses are related to one another, and how we can break down seemingly complex lens design into parts from different lens forms.I can\u2019t catch all of the design forms, but let me know in the comments if you want to know more about a subject, or if you feel there is a lens form missing.I may repea",
    "summary": "**Today in \"Rays for Dummies\"**\n\nThe \"Ultimate Guide\" to lens designs is here to save the day for every wannabe optical engineer who can't differentiate a lens from a lasagna sheet. Let's overcomplicate simple concepts with *every.single.lens.design.ever* because what's a guideline without a touch of existential dread about choice? Meanwhile, in the comments, backyard Newtons without access to actual labs ask for DIY hacks on making spectrometers. Others brag about coding in vanilla JavaScript like it\u2019s still 1995 because frameworks are for the weak! \ud83e\udd13\u2728 Be dazzled or dazed\u2014but don\u2019t you dare stop nerding out!"
  },
  {
    "title": "Caesar's Last Breath (charliesabino.com)",
    "points": 122,
    "submitter": "charliesabino",
    "submit_time": "2025-05-23T14:22:53 1748010173",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=44073185",
    "comments": [
      "Well I just had to try it on Claude 4.0, I mean somebody has to, right? and it did a clean, if rather terse, breakdown, concluding with:Caesar's last breath: ~0.5 liters (typical final exhale)Total atmospheric volume: Earth's atmosphere has a mass of about 5\u00d710^18 kg. Using the ideal gas law with average molecular weight of air (~29 g/mol), this gives roughly 4\u00d710^44 molecules total.Molecules in Caesar's breath: 0.5 liters at standard conditions contains about 1.3\u00d710^22 molecules.Your inhale: ~0.5 liters also contains about 1.3\u00d710^22 molecules.The fraction: Caesar's molecules represent (1.3\u00d710^22)/(4\u00d710^44) = 3.25\u00d710^-23 of all atmospheric molecules.Final answer:\n(1.3\u00d710^22) \u00d7 (3.25\u00d710^-23) \u2248 0.4 moleculesSo statistically, you inhale less than one molecule from Caesar's last breath with each inhalation, but over the course of a day's breathing, you'd likely inhale several molecules that were once in his lungs as he died.\n \nreply",
      "Purely empirical observation, in my own life, make no claim as to humanity/society/etc.:It's interesting how often fermi estimation problems are used as proxy's for \"intelligence\". Something like: 'let's assess how well \"they can think\" - how many golf balls fit in a baseball stadium?' etc.Often, doing well in these kinds of problems can more than makeup for a lack of specific knowledge in something someone is interested in assessing!\n \nreply",
      "This reminds me of a question from my first interview as a college grad: estimate the number of taxis in New York City. I was totally baffled by it.\n \nreply",
      "I\u2019ll simplify for manhattan and extrapolate for the four outer boroughs. Ten avenues, a hundred streets. A thousand blocks? One cab per block? One thousand cabs in manhattan? 5,000 total?There are about 13,500 taxi medallions.\n \nreply",
      "That sort of estimation feels a lot easier to me than the \"golf balls in a baseball stadium one\" that was mentioned by the parent because it's dealing with quantities I can recall having heard before like \"how many streets are there in Manhattan\" rather than measurements that personally would never stick in my head like \"how wide is a golf ball\". I'm not sure why, but I've always been awful at making even rough estimates of units. If you gave me the diameter of a golf ball and the dimensions of the stadium, I could do some basic calculations, but even though I physically know about how large a golf ball is, I couldn't tell you whether it's more likely that its diameter is 0.5 or 1.5\" (and not having looked it up, I would believe you if you told me it wasn't even within that range)! This gets worse with units I can't visualize (like weight), and when the sizes get larger than I can easy relate to; if you asked me questions like how much a car weighs or how long the Brooklyn Bridge is, I'm doubtful I'd even be within a factor of 2 more often than not.I'm probably taking this more seriously than it was intended above, but the idea that this is some sort of proxy for \"thinking\" or \"intelligence\" feels off to me; doing the math given the size of something might be thinking or intelligence, but knowing roughly \"how big\" something is seems more like intuition.\n \nreply",
      "> How many molecules from Caesar\u2019s last breath do we inhale with each breath we take?> If we assume that ... these molecules are preserved over time (a reasonable assumption\u2014nitrogen is relatively inert),But they are not inert. Single UV photon can break single N2 molecule bond.Elemental N is highly reactive and will form new N2 molecule pretty fast, but that is NEW and different molecule!N2 is not stable over period of 2000 years under constant exposure to solar UV radiation!\n \nreply",
      "True, but I think that only occurs in the upper atmosphere and at a very low rate. Atmospheric N2 is also converted by bacteria into ammonia, which is absorbed by plants. And lightning oxidizes N2, as do combustion engines. I'm not sure if all those different reactions add up to a significant fraction, though. It might be true that most of the N2 molecules from Caesar's time still exist.\n \nreply",
      "A really good point.So what's the rate of this photodisassociation?I found it weirdly hard to Google an answer on this. Firstly, rates are given in terms of decays per second instead of in half-life which would be more relevant for our purposes. Secondly, it seems to be well studied in the interstellar medium than in atmospheric conditions.Anyway, the most relevant measurements I could find [0] say  photodisassociation of N2 in the interstellar medium happens at a rate of approximately 10^-10 s^-1 - i.e. every 10 billion seconds on average.Caesar died about 60 billion seconds ago [1] so at that rate, many of the molecules would still be alive.However, we don't live in the interstellar medium. By interstellar standards, we pretty much live on the surface of the sun. The average point in the ISM is maybe 2 light years from the nearest star [2] but we are only 10^-5 ly away. They're all the same photons, but radiation intensity diminishes with the square of the distance, so our nitrogen molecules should disassociate every 1 second instead. If that's true, Caesar's last breath had its last surviving molecules persist for only a minute or two after Caesar himself.[0] https://www.aanda.org/articles/aa/full_html/2013/07/aa20625-...\nhttps://www.aanda.org/articles/aa/full_html/2013/07/aa20625-...[1] https://math.answers.com/math-and-arithmetic/How_many_second...[2] https://www.livescience.com/space/how-far-apart-are-stars\n \nreply",
      "Air is 1% argon (9340 ppm) and those atoms remain in the atmosphere without being chemically removed.\n \nreply",
      "> If we assume that a breath diffuses evenly throughout the atmosphere and that these molecules are preserved over time (a reasonable assumption\u2014nitrogen is relatively inert), then...Way to take all the fun out of it..\n \nreply"
    ],
    "link": "https://charliesabino.com/caesars-last-breath/",
    "first_paragraph": "",
    "summary": "**The Mathematical Tedium Sphere**\n\nIn a stunning feat of necessity-soaked inquiry, charliesabino.com addresses a mystery that has kept no one awake at night: how many molecules from Julius Caesar's last death rattle do we unwittingly inhale with every breath? Enthusiastic commenters leap into action, turning an innocuous Fermi problem into an Olympic sport of unrequested approximations, straining to inject relevance into the tired consideration of ancient breath components. A user valiantly tries to correct misconceptions about atmospheric chemistry, only to face the internet equivalent of gladiatorial combat against pedantry. Meanwhile, another intrepid soul extols the virtues of understanding the taxi density of Manhattan\u2014a completely related and equally vital issue, obviously. \ud83d\ude44"
  },
  {
    "title": "Show HN: High-resolution surface analysis with Lidar data (github.com/r-follador)",
    "points": 4,
    "submitter": "folli",
    "submit_time": "2025-05-21T20:40:02 1747860002",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/r-follador/delta-relief",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        High-resolution surface analysis with LiDAR data\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.High-resolution surface analysis with LiDAR dataAirborne LiDAR uses hundreds of thousands of laser pulses per second to generate detailed 3D maps, even through vegetation.\nWith high point densities and 10 cm accuracy, it is among the most effective methods for mapping topography.Source SwissTopoThe Swiss Federal Office of Topography (Swisstopo) provides a highly precise digital elevation model based on LiDAR data,\ncalled swissALTI3D. Buildings and vegetation are removed, revealing\nthe underlying topography.The data is delivered as a GeoTIFF tiles with 2000px \u00d7 2000px resolution representing 1km \u00d7 1km areas (resolution of 0.5m).\nThe full list of all tiles is provi",
    "summary": "Title: HackerNews Discovers Trees and Other Objects Have Height: LiDAR Madness Ensues\n\nAnother day, another Show HN submission that could probably overhear secret conversations in your backyard with its \"high-resolution\" mumbo-jumbo. A devoted GitHub warrior has decided that what the people really need is to see the ground a bit clearer, because, clearly, Google Earth was so last season. The comment section, a bustling hub of misplaced expertise, chimes in with folks who believe now they can finally locate their lost drones and Frisbees deep in the bushes\u2014from the comfort of their ergonomic, battle-station recliners. Others suggest it could help improve their virtual landscaping skills in *The Sims*. Meanwhile, the page itself fights a brave battle against functionality by refusing to load correctly\u2014not that anyone really noticed. \ud83c\udf0d\ud83d\udcbb\ud83d\udd0d"
  }
]