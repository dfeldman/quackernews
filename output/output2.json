[
  {
    "title": "Show HN: I'm an airline pilot \u2013 I built interactive graphs/globes of my flights (jameshard.ing)",
    "points": 1025,
    "submitter": "jamesharding",
    "submit_time": "2025-06-27T13:06:54 1751029614",
    "num_comments": 159,
    "comments_url": "https://news.ycombinator.com/item?id=44396518",
    "comments": [
      "Cool visualization for your personal logbook. How is the raw or display data stored?The globe map reminds me of this hexagonal grid article from my bookmarks I\u2019d found on here or reddit.https://www.redblobgames.com/grids/hexagons/As an airline pilot, I am curious, have you watched the season 2 of Nathan Fielder\u2019s Rehearsal on HBO, that comically addresses the topic of pilot-copilot communication?If so what are your thoughts on his portrayal of the existence of copilot communication friction. And without intending to dig into your personal business, do you think there is a tendency and survivor (retention) bias for the profession to remain high functioning ______, without recognizing a need for help. Or is this portrayal of stunted coworker dialog an edge case that is amplified from his perspective.reply",
      "The data is all in a sqlite file from my logbook software! I wrote a little post about extracting the data here: https://jameshard.ing/posts/querying-logten-pilot-logbook-sq...I have only seen a few clips from The Rehersal (the bit with Sully listening to Evanescence), so I don't have much to go on. Pilot communication is definitely something that we spend a lot of time talking about and training (under the larger banner of CRM - crew resource management), and in my experience the industry is making real efforts to be better in this area!reply",
      "Hey! I used to work for the company that makes that logbook software. That was a great job. The CEO was an amateur pilot himself and really, really loved software product design.It's been over a decade, but it's cool to see that software still being iterated on and pilots still loving it.Even cooler to see someone such as yourself extending its usefulness by leveraging the data. Cheers!reply",
      "Awesome!You can tell that the software is created by people passionate about aviation (and also passionate about nice UX, something that most all of the Logten competitors really lack). Do you remember if my guess about using NSDate internally was correct?reply",
      "\"passionate about aviation\" and \"passionate about nice UX\" definitely described Noah and the rest of the team!Honestly, I don't remember Re: NSDate. It was many jobs and Dante's levels of burnout ago. :-)What I remember from that time was a lot of fighting with Apple's early iCloud syncing. Because it had a habit of being incredibly fraught and flakey using SQLite-backed Core Data stuff.reply",
      "Cool, thank you for the response and details.reply",
      "> How is the raw or display data stored?He answered in the post that he uses LogTen Pro[1] which enables querying with SQL[2]. In the SQL post he says the app has an export for CSV but the app stores it in SQLite which you can access and query from directly.[1] https://logten.com/\n[2] https://jameshard.ing/posts/querying-logten-pilot-logbook-sq...reply",
      "I assumed the globe was using Uber's H3 library for the hexagons.reply",
      "Reminds me of https://youtu.be/1SKDvQzcasg which is quite old.reply",
      "Very cool. I just wanted to say how much I enjoyed reading through your detailed flight logs \u2014 the way you\u2019ve documented your experience, from distances and time in the air to the nuances of roles (P1, P2, PICUS), was fascinating.As someone concerned with these matters \u2014 developing SpinStep, a quaternion-based library for modeling orientation and vector state evolution in physical systems \u2014 I found myself unexpectedly inspired by your data. It got me thinking: could these kinds of spatiotemporal logs, with their emphasis on direction, roles, and environmental influences, be approached through something like rotational state modeling?For example:.Aircraft headings and orientation changes could map naturally to quaternions..Role transitions (e.g. P1 \u2194 P2) resemble discrete state changes within a continuous system..Wind effects or flight network patterns might even be modeled as external fields influencing orientation over time.I hadn\u2019t envisioned SpinStep in this context, but your log offered a compelling perspective. Whether or not it leads to something concrete, I just wanted to thank you for the inspiration..https://github.com/VoxleOne/SpinStep/blob/main/README.md \\.https://github.com/VoxleOne/SpinStep/blob/main/docs/01-ratio...reply"
    ],
    "link": "https://jameshard.ing/pilot",
    "first_paragraph": "Since 2023, I have been a First Officer on the Airbus A350 with British Airways operating out of London Heathrow. Prior to this, I flew the Airbus A320 family based at Heathrow and Gatwick since 2016.I joined British Airways through their cadet scheme in 2014, which included an Integrated ATPL course that I completed at FTEJerez in Andalucia, Spain \ud83c\uddea\ud83c\uddf8. My flying journey began in Canada \ud83c\udde8\ud83c\udde6, where I obtained my Glider Pilot License, Instructor Rating, and my PPL through Canadian Air Cadet scholarships.I log all of my flights digitally using LogTen Pro, which lets me query them using SQL and present them in infographic format. My favourite is the GitHub-style flying history.The outer ring shows the number of flight to each country, and each band shows the number of flights to a country from a specific other country. You'll notice that some destinations do not have an equal number of departures or arrivals - this is due to positioning/deadhead sectors.The single sector from Portugal to Spa",
    "summary": "<b>HN Launches Yet Another Data Visualization Tool:</b> A pilot with too much free time and a knack for self-promotion shares a nifty globe of flight paths that no one outside his family reunion will ever click on. Watch in awe as Hacker News commenters pretend they're also interested in hexagonal grid theories and desperately relate it to every obscure project they've worked on. Somewhere between the SQL queries and CRM discussions, the true purpose of Hacker News shines through: to make every trivial accomplishment seem like a moon landing. \ud83c\udf0d\u2708\ufe0f Will someone think of the SQL inefficiencies?"
  },
  {
    "title": "Normalizing Flows Are Capable Generative Models (machinelearning.apple.com)",
    "points": 74,
    "submitter": "danboarder",
    "submit_time": "2025-06-27T20:50:10 1751057410",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44400105",
    "comments": [
      "Earlier discussion: https://news.ycombinator.com/item?id=44358535reply",
      "As far as I'm aware, this is the largest Normalizing Flow that exists, and I think they undermined their work by not mentioning this...Their ImageNet model (4_1024_8_8_0.05[0]) is ~820M while AFHQ is ~472M. Prior to that there is DenseFlow[1] and MaCow[2], which are both <200M parameters. For more comparison, that makes DenseFlow and MaCow smaller than iDDPM[3] (270M params) and ADM[4] (553M for 256 unconditional). And now, it isn't uncommon for modern diffusion models to have several billion parameters![5] (from this we get some numbers on ImageNet-256, which allows a direct comparison, making TarFlow closer to MaskDiT/2 and much smaller than SimpleDiffusion and VDM++, both of which are in billions. But note that this is 128 vs 256!)Essentially, the argument here is that you can scale (Composable) Normalizing Flows just as well as diffusion models. There's a lot of extra benefits you get too in the latent space, but that's a much longer discussion. Honestly, the TarFlow method is simple and there's probably a lot of improvements that can be made. But don't take that as a knock on this paper! I actually really appreciated it and it really set out to show what they tried to show. The real thing is just no one trained flows at this scale before and this really needs to be highlighted.The tldr: people have really just overlooked different model architectures[0] Used a third party reproduction so might be different but their AFHQ-256 model matches at 472M params https://github.com/encoreus/GS-Jacobi_for_TarFlow[1] https://arxiv.org/abs/2106.04627[2] https://arxiv.org/abs/1902.04208[3] https://arxiv.org/abs/2102.09672[4] https://arxiv.org/abs/2105.05233[5] https://arxiv.org/abs/2401.11605[Side note] Hey, if the TarFlow team is hiring, I'd love to work with you guysreply",
      "i've been trying to keep up with this field (image generation) so here's quick notes I took:Claude's Summary: \"Normalizing flows aren't dead, they just needed modern techniques\"My Summary: \"Transformers aren't just for text\"1. SOTA model for likelihood on ImageNet 64\u00d764, first ever sub 3.2 (Bits Per Dimension) prev was 2.99 by a hybrid diffusion model2. Autoregressive (transformers) approach, right now diffusion is the most popular in this space (it's much faster but a diff approach)tl;dr of autoregressive vs diffusion (there's also other approaches)Autoregression: step based, generate a little then more then moreDiffusion: generate a lot of noise then try to clean it upThe diffusion approach that is the baseline for sota is Flow Matching from Meta: https://arxiv.org/abs/2210.02747 -- lots of fun reading material if you throw both of these into an LLM and ask it to summarize the approaches!reply",
      "You have a few minor errors and I hope I can help out.  > Diffusion: generate a lot of noise then try to clean it up\n\nYou could say this about Flows too. The history of them is shared with diffusion and goes back to the Whitening Transform. Flows work by a coordinate transform so we have an isomorphism where diffusion works through, for easier understanding, a hierarchical mixture of gaussians. Which is a lossy process (more confusing when we get into latent diffusion models, which are the primary type used). The goal of a Normalizing Flow is to turn your sampling distribution, which you don't have an explicit representation of, into a probability distribution (typically Normal Noise/Gaussian). So in effect, there are a lot of similarities here. I'd highly suggest learning about Flows if you want to better understand Diffusion Models.  > The diffusion approach that is the baseline for sota is Flow Matching from Meta\n\nTo be clear, Flow Matching is a Normalizing Flow. Specifically, it is a Continuous and Conditional Normalizing Flow. If you want to get into the nitty gritty, Ricky has a really good tutorial on the stuff[0][0] https://arxiv.org/abs/2412.06264reply",
      "thank you so much!!! i should\u2019ve put that final sentence in my post!reply",
      "Happy to help and if you have any questions just ask, this is my jamreply"
    ],
    "link": "https://machinelearning.apple.com/research/normalizing-flows",
    "first_paragraph": "AuthorsShuangfei Zhai, Ruixiang Zhang, Preetum Nakkiran, David Berthelot, Jiatao Gu, Huangjie Zheng, Tianrong Chen, Miguel Angel Bautista, Navdeep Jaitly, Josh SusskindView publicationView source code (GitHub)Copy BibtexNormalizing Flows (NFs) are likelihood-based models for continuous inputs. They have demonstrated promising results on both density estimation and generative modeling tasks, but have received relatively little attention in recent years. In this work, we demonstrate that NFs are more powerful than previously believed. We present TarFlow: a simple and scalable architecture that enables highly performant NF models. TarFlow can be thought of as a Transformer-based variant of Masked Autoregressive Flows (MAFs): it consists of a stack of autoregressive Transformer blocks on image patches, alternating the autoregression direction between layers. TarFlow is straightforward to train end-to-end, and capable of directly modeling and generating pixels. We also propose three key tec",
    "summary": "**In an exhilarating breakthrough that absolutely nobody asked for, \"Normalizing Flows Are Capable Generative Models\" introduces TarFlow, the Transformer\u2019s less-loved cousin that\u2019s just as thirsty for computational resources.** While the authors pat themselves on the back for pushing pixels around with more layers of autoregression than a bureaucratic nightmare, the comment section devolves into a size contest over parameter counts, proving once again that in machine learning, size does matter. \ud83c\udf89 Meanwhile, one eager commenter, desperate to be noticed, oscillates between fanboying over the mundane and fantasizing about befriending the authors\u2014a reminder that in the era of online discourse, everyone is one comment away from a job interview or a restraining order. Will this research revolutionize your Netflix recommendations? Highly unlikely, but stay tuned for more buzzwords and fewer breakthroughs. \ud83d\ude80"
  },
  {
    "title": "Learn OCaml \u2013 Exercises (ocaml-sf.org)",
    "points": 60,
    "submitter": "smartmic",
    "submit_time": "2025-06-27T20:36:51 1751056611",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=44400025",
    "comments": [
      "As someone interested in learning OCaml, this felt like a pretty inaccessible introduction.Having seen \"A tour of Elm,\"[0] I really prefer that style. The left-hand side (what English readers read first) is an explanation of the concept, then the right side is the code, and the explanation gives you enough details to complete the code.This introduction doesn't really explain anything, as I guess it assumes you've learned OCaml elsewhere and are just here to practice.I tried the first exercise, and it felt more like a math problem than an exercise to teach a programming concept:>Suppose that a variable x exists and is an integer.>Define a variable x_power_8 that uses three multiplications to calculate x to the power of 8. The only function you are allowed to call is the (*) operator.>Hint: use auxiliary variables.So, at first I thought I was supposed to just call multiply eight times, and then I realized that they said you can only call multiply three times. So, you're supposed to do let a = x * x; let b = a * a; let x_power_8 = b * b. But that feels really contrived to me and not like anything I'd write in a real application, even a toy one. If the idea is teaching variables, why not just ask me to declare a variable that represents x plus 1?[0] https://a-tour-of-elm.axelerator.de/#JSFunctionsreply",
      "In ocaml you would rather do something like this: let x_power_8 = (let a = x*x in let b = a*a in b*b);a, b variables are just used for computing x_power_8, you don't need them outside of this scope. I think the point of the exercise is to use variable binding, though I agree the website doesn't explain muchreply",
      "Very nice site, but it seems to expect you to be following along with some other resource. The exercises each have links under the details tab, but the links are broken, and I cannot find the web pages they are supposed to be linking to.reply",
      "Loved using OCaml for a compiler course at uni when I was a student. But I've always felt that the tooling side is pretty rough, especially on Windows. Opam recently added Windows support, but it involves installing MinGW, and when following the official docs https://ocaml.org/docs/installing-ocaml#install-platform-too... the process breaks down with an error when trying to install utop due to a path separator error, which one has to fix manually (at least that was the case last time I tried). By comparison, installing Python or Rust on Windows is a breeze.reply",
      "Never played with OCaml, but I spent the past few days learning about F# (my understanding is that it inherits a lot from OCaml). Tooling seemed great: I used JetBrains Rider; VSCode and Visual Studio are also options. Support seemed great: good official docs; good book choices. Ecosystem seemed great: entire .Net class library.I\u2019m been on the JVM for 20+ years, but an opportunity came up to leverage some of my other experience to get some CLR work\u2026 and I dove in.reply",
      "Even in Linux, I'd say the tooling is a bit rough, dune and the new lsp are going in the right direction though.reply",
      "Dune is a very powerful and good build system \u2014 it can do some very magical and useful things. The only problem is most of these useful features are very poorly documented\u2026reply",
      "The sluggishness of setting up new opam switches is definitely limiting in my experiencereply",
      "picked up ocaml back when prepping for some interview round, didn\u2019t expect much just wanted the functional knowledge. but later used it for advent of code and it just worked so clean. pattern matching, recursion, immutabilitty.. fits those problems naturally. ended up liking the language way more than planned.reply",
      "If I learned OCaml, what type of prospects would I have?Fairly seasoned generalist, mostly writing Go these days. Lots of plumbing with LLMs etc.Would love to learn something new but am driven by a goal in mind (ie OCaml exposes me to \"X industry\")Is that a thing?reply"
    ],
    "link": "https://ocaml-sf.org/learn-ocaml-public/#activity=exercises",
    "first_paragraph": "",
    "summary": "**Learn OCaml - Exercises (ocaml-sf.org)**\n\nAnother day, another *irritating* attempt to teach an arcane language through cryptic exercises that assume you're already a fan of wizardry \ud83e\uddd9\u200d\u2642\ufe0f. Turns out, OCaml still isn't winning any awards for accessibility or user-friendliness. Commenters toggle between nostalgic academic praise and desperate cries for better tooling, while Windows users are left performing digital gymnastics just to get a \"Hello World\" running. Amidst the chaos, hopeful programmers debate the elusive career perks of mastering this academic relic, as if deciphering OCaml is the secret handshake into the upper echelons of tech society. Spoiler: it's not. \ud83e\udd37\u200d\u2642\ufe0f"
  },
  {
    "title": "SymbolicAI: A neuro-symbolic perspective on LLMs (github.com/extensityai)",
    "points": 99,
    "submitter": "futurisold",
    "submit_time": "2025-06-27T18:49:57 1751050197",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=44399234",
    "comments": [
      "This is the voodoo that excites me.Examples I found interesting:Semantic map lambdas  S = Symbol(['apple', 'banana', 'cherry', 'cat', 'dog'])\n  print(S.map('convert all fruits to vegetables'))\n  # => ['carrot', 'broccoli', 'spinach', 'cat', 'dog']\n\n\ncomparison parameterized by context  # Contextual greeting comparison\n  greeting = Symbol('Hello, good morning!')\n  similar_greeting = 'Hi there, good day!'\n\n  # Compare with specific greeting context\n  result = greeting.equals(similar_greeting, context='greeting context')\n  print(result) # => True\n\n  # Compare with different contexts for nuanced evaluation\n  formal_greeting = Symbol('Good morning, sir.')\n  casual_greeting = 'Hey, what\\'s up?'\n\n  # Context-aware politeness comparison\n  politeness_comparison = formal_greeting.equals(casual_greeting, context='politeness level')\n  print(politeness_comparison) # => False\n\nbitwise ops  # Semantic logical conjunction - combining facts and rules\n  horn_rule = Symbol('The horn only sounds on Sundays.', semantic=True)\n  observation = Symbol('I hear the horn.')\n  conclusion = horn_rule & observation # => Logical inference\n\n`interpret()` seems powerful.OP, what inspired you to make this? Where are you applying it? What has been your favorite use case so far?reply",
      "Why is carrot the vegetablefication of apple?reply",
      "I think it's interpreting the command as \"replace each fruit with a vegetable\", and it might intuit \"make the resulting vegetables unique from one another\" but otherwise it's not trying to find the \"most similar\" vegetable to every fruit or anything like that.reply",
      "Are you asking for the root cause?reply",
      "Also if you run it twice, is it gonna be a carrot again?reply",
      "That's gonna be a very, very, long answer. What's funny is that not much changed since 2022 (eoy) when the projected started; the models just got better, but we had a good chunk of the primitives since gpt-3.What's more recent is the DbC contribution which I think is unique. It literally solved anything agent related I've thrown at it -- especially because I can chain contracts together and the guardrails propagate nicely.I've built most the custom tools myself. For instance, not only perplexity was rendered useless by openai's web search, but openai's web search itself is not good enough for what you can customize yourself. To this end, I've built my own deep research agent. Here's a thread with some results from the first day it was working: https://x.com/futurisold/status/1931751644233945216I'm also running a company, and we've built an e2e document generation just from contracts (3 contracts chained together in this case). Here's an output (sorry about the PDF rendering, that's not what we serve, it's just what I've quickly hacked for local dev): https://drive.google.com/file/d/1Va7ALq_N-fTYeumKhH4jSxsTrWD...This was the input:---Prompt:> I want the files to be analyzed and I am interested in finding patterns; feel free to make suggestions as well. I want to understand how different providers use their system prompts, therefore things like: what kind of tags do they use \u2013 are they XML, markdown, etc, are they prone toward sycophancy or trying to manipulate the user, are they using tools and if so how, etc. I want the tech report to deconstruct and synthesize and compare the information, find interesting patterns that would be hard to spot.Generated instructions:(a) Query: \n Conduct a comparative analysis of system prompts across major AI providers (OpenAI, Google, Anthropic, xAI, etc.) to identify structural patterns, linguistic frameworks, and operational constraints that shape AI behavior and responses.(b) Specific Questions:1. What syntactic structures and formatting conventions (XML, markdown, JSON, etc.) are employed across different AI system prompts, and how do these technical choices reflect different approaches to model instruction?2. To what extent do system prompts encode instructions for deference, agreeability, or user manipulation, and how do these psychological frameworks vary between commercial and research-focused models?3. How do AI providers implement and constrain tool usage in their system prompts, and what patterns emerge in permission structures, capability boundaries, and function calling conventions?4. What ethical guardrails and content moderation approaches appear consistently across system prompts, and how do implementation details reveal different risk tolerance levels between major AI labs?5. What unique architectural elements in specific providers' system prompts reveal distinctive engineering approaches to model alignment, and how might these design choices influence downstream user experiences?---Contracts were introduced in March in this post: https://futurisold.github.io/2025-03-01-dbc/They evolved a lot since then, but the foundation and motivation didn't change.reply",
      "One last comment here on contracts; an excerpt from the linked post I think it's extremely relevant for LLMs, maybe it triggers an interesting discussion here:\"The scope of contracts extends beyond basic validation. One key observation is that a contract is considered fulfilled if both the LLM\u2019s input and output are successfully validated against their specifications. This leads to a deep implication: if two different agents satisfy the same contract, they are functionally equivalent, at least with respect to that specific contract.This concept of functional equivalence through contracts opens up promising opportunities. In principle, you could replace one LLM with another, or even substitute an LLM with a rule-based system, and as long as both satisfy the same contract, your application should continue functioning correctly. This creates a level of abstraction that shields higher-level components from the implementation details of underlying models.\"reply",
      "Btw, besides the prompt, the other input to the technical report (the gdrive link) was this repo: https://github.com/elder-plinius/CL4R1T4S/tree/mainreply",
      "Probably linking the paper and examples notebook here makes sense as they are pretty explanatory:https://github.com/ExtensityAI/symbolicai/blob/main/examples...https://arxiv.org/pdf/2402.00854reply",
      "Wanted to do just that, thank youreply"
    ],
    "link": "https://github.com/ExtensityAI/symbolicai",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Compositional Differentiable Programming Library\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n \nSymbolicAI is a neuro-symbolic framework, combining classical Python programming with the differentiable, programmable nature of LLMs in a way that actually feels natural in Python.\nIt's built to not stand in the way of your ambitions.\nIt's easily extensible and customizable to your needs by virtue of its modular design.\nIt's quite easy to write your own engine, host locally an engine of your choice, or interface with tools like web search or image generation.\nTo keep things concise in this README, we'll introduce two key concepts that define ",
    "summary": "**New Hacks for Old Brains: SymbolicAI Takes on LLMs with Python**\n\nIn yet another hail-mary pass to justify existing on GitHub, SymbolicAI throws Python spaghetti at the wall of large language models and calls it innovation. Enthused hackers in the comments ironically celebrate turning apples into carrots as if they've unlocked the philosopher's stone, while others ponder the metaphysical constants of repeatedly generated carrot-results. This groundbreaking (re)discovery, featuring error messages as its most consistent module, promises a customizable, extensible mess, offering the same reliability as a chocolate teapot. Behold, as the repository readme magically deflects critical thinking, and converts vague hype into \"extreme excitement\" among the devout commentariat. \ud83d\ude02"
  },
  {
    "title": "James Webb Space Telescope Reveals Its First Direct Image of an Exoplanet (smithsonianmag.com)",
    "points": 112,
    "submitter": "divbzero",
    "submit_time": "2025-06-27T17:44:32 1751046272",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=44398756",
    "comments": [
      "In case anyone is wondering, we are (sadly) very far from getting an image of this planet (or any extra-solar planet) that is more than 1 pixel across.At 110 light-years distance you would need a telescope ~450 kilometers across to image this planet at 100x100 pixel resolution--about the size of a small icon. That is a physical limit based on the wavelength of light.The best we could do is build a space-based optical interferometer with two nodes 450 kilometers apart, but synchronized to 1 wavelength. That's a really tough engineering challenge.reply",
      "We can do better than that! Using the Sun as a gravitation lens[1], and a probe at a focal point of 542 AU, we could get 25km scale surface resolution on a planet 98 ly away. [2] This would be an immense and time-consuming endeavor, but does seem to be within humanity's current technological capabilities.1. https://en.wikipedia.org/wiki/Solar_gravitational_lens2. https://www.nasa.gov/general/direct-multipixel-imaging-and-s...reply",
      "I was going to post the same exact thing and links.Of all the possible space probes or missions we could do. I want this one more than any of them!reply",
      "Agreed! This might be easier than an interferometer. You just need a lot of delta-vreply",
      "Do we have a recent cost estimate?reply",
      "\"We used to look up at the sky and wonder at our place in the stars. Now we just look down, and worry about our place in the dirt.\"reply",
      "It's cynical to assume OP was gunning for \"it's too expensive\". They might just want to know the size of the challenge to get it done.reply",
      "How big would the telescope/mirror/lens need to be to get a picture of something in the Alpha Centauri system, 4.37 light years away?Also, could the image be created by \u201a\u00c4\u00fascanning\u201a\u00c4\u00f9 a big area and then composing the image from a bunch of smaller ones?reply",
      "It's linear, so if it is 25 times closer then the telescope can be 25 times smaller. At 4.37 light-years we'd need an 18 kilometer telescope to image at Jupiter-sized planet at 100x100 pixel resolution.If you only wanted 10x10 resolution you could get by with a 1.8 kilometer telescope.Wikipedia has more: https://en.wikipedia.org/wiki/Angular_resolution. The Rayleigh criterion is the equation to calculate this.reply",
      "L2 is moving though right? Or does it need to be simultaneously receiving at the 2 points?reply"
    ],
    "link": "https://www.smithsonianmag.com/smart-news/james-webb-space-telescope-reveals-its-first-direct-image-discovery-of-an-exoplanet-180986886/",
    "first_paragraph": "",
    "summary": "The James Webb Space Telescope swoops in with a dazzling postage stamp from space, evoking majestic cries of wonder before everyone realizes it's basically a glorified pixel. The guardians of the internet's comment sections, armed with Wikipedia links and a vague understanding of astrophysics, rally heroically to solve engineering problems no one asked them to and propose using the Sun as a magnifying glass. Reality checks are drowned out by grand visions of solar gravitational lenses and probes flung to improbable orbits. Meanwhile, someone surely ponders whether any of this cosmic voyeurism will help find their missing socks. \ud83d\ude80\ud83c\udf0c\ud83d\udd2d"
  },
  {
    "title": "Structuring Arrays with Algebraic Shapes (acm.org)",
    "points": 62,
    "submitter": "todsacerdoti",
    "submit_time": "2025-06-27T19:55:26 1751054126",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44399757",
    "comments": [
      "High-level array combinators seem to ignore memory locality performance details, to me. It's all fine to say you can arbitrarily reorder array indicies in a mathematical sense, but any real program that does that needs to change a lot of things. Similarly, using variant types to index into combined arrays, splits up underlying memory locality and adds \"if\" branches. Type systems that obscure these details will result is poorly performing code.That said if you're going to do it, this seems like a reasonable set of primitives to do it with. I'm not a huge performance nut, so I'd love to give it a try.I'd like to see an implementation in a language with only fixed-stride arrays. I'm not an expert, does Rust do this?reply",
      "> naming axes gives semantic weight to array shapes, but it also introduces commitment. like in practice, array shapes mutate fast : reshape, squeeze, permute half these ops aren't semantic, they're just cleanup to fit the next layer. adding names to that doesn\u2019t simplify, that adds bookkeeping.> also naming means locking intent early. once you say 'this axis is time', every downstream op inherits that label, even if that dim gets folded or split.it's tradeoffs onlyreply",
      "This looks pretty compelling to me. I've been itching for a math-friendly language that makes it easy to work with arrays, vectors, vector spaces, manifolds, etc., but takes advantage of static typing. (Haskell is amazing but doesn't quite make linear algebra constructs feel native.)On first read, it looks like this is designed with a healthy balance between mathematical insight (relationship of product types and tuples, basis in lambda calculus)  and real developer needs (e.g., static typic is nice; dependently typed systems can be too much; types are great, but \"nameless shapes\" are useful, too).I'd love to see an implementation of this to play around with.reply",
      "This is great.  For a long time I've had a gut feeling that there must exist a synthesis between pure functional, array, and data-oriented programming that gives you the best of all worlds:Type safety, concise-to-the-point-of-terse code (with the types helping humans read it), and very high performance.And this feels like a step in the right direction.reply",
      "Can't find a repo of this lang...Is compelling to me because I'm in the hunt for marry array + relational (https://tablam.org)reply"
    ],
    "link": "https://dl.acm.org/doi/abs/10.1145/3736112.3736141",
    "first_paragraph": "",
    "summary": "**Hacker News Gets Array-zed**\n\nIn a world where \"algebraic shapes\" have become the new Sudoku, ACM.org publishes yet another head-scratcher for armchair programmers. Commenters, in a dazzling display of their high school algebra prowess coupled with professional-level amnesia about real-world applications, dive into the performance aspects of high-falutin\u2019 array manipulations \ud83e\uddd0. One commenter bravely admits they \"aren't a huge performance nut\" but would \"love to give it a try,\" presumably after their cup of frothy Haskell latte cools down. Meanwhile, everyone conveniently glosses over implementation specifics, because why bother with practicalities when you can theorize about reshaping the very fabric of computer memory? Academics rejoice \u2013 your jobs are safe from the pragmatists for another day."
  },
  {
    "title": "Qwen VLo: From \"Understanding\" the World to \"Depicting\" It (qwenlm.github.io)",
    "points": 165,
    "submitter": "lnyan",
    "submit_time": "2025-06-27T14:35:04 1751034904",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44397124",
    "comments": [
      "It doesn't seem to have open weights, which is unfortunate. One of Qwen's strengths historically has been their open-weights strategy, and it would have been great to have a true open-weights competitor to 4o's autoregressive image gen. There are so many interesting research directions that are only possible if we can get access to the weights.If Qwen is concerned about recouping its development costs, I suggest looking at BFL's Flux Kontext Dev release from the other day as a model: let researchers and individuals get the weights for free and let startups pay for a reasonably-priced license for commercial use.reply",
      "It's also very clearly trained on OAI outputs, which you can tell from the orange tint to the images[0]. Did they even attempt to come up with their own data?So it is trained off OAI, as closed off as OAI and most importantly: worse than OAI. What a bizarre strategy to gate-keep this behind an API.[0]https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VLo/cas...https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VLo/cas...https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VLo/cas...reply",
      "There seem to be a lot of AI images on the web these days and it might have become the single most dominant style given that AI has created more images than any individual human artist. So they might have trained on them implicitly rather than in a synthetic way.Although theory is not practice. If I were an AI company I'd try to leverage other AI company APIs.reply",
      "Huh, so orange tint = openAI output? Maybe their training process ended up causing the model to prefer that color balance.reply",
      "Here's an extreme example that shows how it continually adds more orange: https://old.reddit.com/r/ChatGPT/comments/1kawcng/i_went_wit...It's really too close to be anything but a model trained on these outputs, the whole vibe just screams OAI.reply",
      "That form of collapse might just be inherent to the methodology. Releasing the weights would be nice so people can figure out whyreply",
      "What would be the approximate cost of doing this? How many million API requests must be made? How many tokens in total?reply",
      "Most pedantically correct answer is \"mu\", because the answers are both derivable quantitively from \"How many images do you want to train on?\", which is answered by a qualitative question that doesn't admit numbers (\"How high quality do you want it to be?\")Let's say it's 100 images because you're doing a quick LoRA. \nThat'd be about $5.00 at medium quality (~$0.05/image) or $1 at low. ~($0.01/image)Let's say you're training a standalone image model. OOM of input images is ~1B, so $10M at low and $50M at high.250 tokens / image for low, ~1000 for medium, which gets us to:Fastest LoRA? $1-$4. 25,000 - 100,000 tokens output.\nAll the training data for a new image model? $10M-$50M, 2.5B - 10B tokens out.reply",
      "The way they win is to be open. I don't get why China is shutting down open source. It was a knife at the jugular of US tech dominance.Both Alibaba and Tencent championed open source (Qwen family of models, Hunyuan family of models), but now they've shut off the releases.There's totally a play where models become loss-leader for SaaS/PaaS/IaaS and where they extinguish your closed competition.Imagine spreading your model so widely then making the terms: \"do not use in conjunction with closed source models\".reply",
      "The problem with giving away weights for free while also offering a hosted API is that once the weights are out there, anyone else can also offer it as a hosted API with similar operating costs, but only the releasing company had the initial capital outlay of training the model. So everyone else is more profitable! That's not a good business strategy.New entrants may keep releasing weights as a marketing strategy to gain name recognition, but once they have established themselves (and investors start getting antsy about ROI) making subsequent releases closed is the logical next step.reply"
    ],
    "link": "https://qwenlm.github.io/blog/qwen-vlo/",
    "first_paragraph": "QWEN CHAT\nDISCORDThe evolution of multimodal large models is continually pushing the boundaries of what we believe technology can achieve. From the initial QwenVL to the latest Qwen2.5 VL, we have made progress in enhancing the model\u2019s ability to understand image content. Today, we are excited to introduce a new model, Qwen VLo, a unified multimodal understanding and generation model. This newly upgraded model not only \u201cunderstands\u201d the world but also generates high-quality recreations based on that understanding, truly bridging the gap between perception and creation. Note that this is a preview version and you can access it through Qwen Chat. You can directly send a prompt like \u201cGenerate a picture of a cute cat\u201d to generate an image or upload an image of a cat and ask \u201cAdd a cap on the cat\u2019s head\u201d to modify an image. The image generation process is shown below.The Creative Process: Turn Your Imagination Into RealityAs demonstrated in the video showcasing the generative process, Qwen ",
    "summary": "**Qwen VLo Single-Handedly Declares War on Originality, Loses**\n\nIn an Earth-shattering non-event, Qwen VLo emerges from the AI primordial ooze to bring you <i>\"high-quality recreations\"</i> of the world, which, upon closer inspection, may just be slightly more pixelated cat pictures with hats. The company's latest gimmick combines misunderstanding images and regurgitating them in a form that might gently thrill a not-so-discerning five-year-old. Over on the comments, the usual suspects trip over themselves to lament\u2014or not\u2014the lack of open weights, because, let\u2019s face it, everyone just *really* wants to help Qwen recoup their R&D losses by indirectly moaning on the internet. Meanwhile, others play detective on the \"mysterious case of the orange tint,\" a saga surely worthy of a daytime Emmy. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83e\udde1"
  },
  {
    "title": "Does a Focus on Royalty Obscure British History? (historytoday.com)",
    "points": 10,
    "submitter": "pepys",
    "submit_time": "2025-06-24T07:49:43 1750751383",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.historytoday.com/archive/head-head/does-focus-royalty-obscure-british-history",
    "first_paragraph": "\nSubscriptionOffersGive a GiftSubscribe\u2018Mary, Bessie, James you ken, then Charlie, Charlie, James again...\u2019 Does the litany of kings and queens help or hinder an accurate understanding of Britain\u2019s past?Levi Roach is Professor of Medieval History at the University of ExeterThere can be no doubt that monarchs bulk inordinately large in British history. Whether the subject be Georgian architecture, Victorian literature, or Tudor religious culture, we find ourselves framing discussions in terms of ruling monarchs and dynasties, even when the subject has little to do with them.To continue reading this article you need to purchase a subscription, available from only \u00a35.Start my trial subscription now\nIf you have already purchased access, or are a print & archive subscriber, please ensure you are\u00a0logged in.\nPlease email digital@historytoday.com if you have any problems.\nIf you have already purchased access, or are a print & archive subscriber, please ensure you are\u00a0logged in.Please email dig",
    "summary": "**Does Remembering Old Rich People Help Us Forget Useful History?**\n\nA profoundly shocking analysis emerges from <i>History Today</i>, suggesting that maybe, just maybe, spending all our time obsessing over which dead royal ate what turkey leg might <em>not</em> provide the most holistic view of the past. Professor Levi Roach drops this bombshell, shocking a reader base that had desperately clung to the notion that the name of Henry VIII's sixth dog was critical to understanding British cultural dynamics. Commenters, predictably aghast, debate whether the article itself is part of a Jacobin conspiracy or merely an attempt to sell more subscriptions\u2014a fiendish plot to distract from the crucial historiographical debates about royal gout. Meanwhile, someone misses the point entirely, demanding a refund because they thought \"Tudor religious culture\" was a new HGTV show. \ud83d\ude44"
  },
  {
    "title": "Reinforcement learning, explained with a minimum of math and jargon (understandingai.org)",
    "points": 36,
    "submitter": "JnBrymn",
    "submit_time": "2025-06-24T14:29:59 1750775399",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.understandingai.org/p/reinforcement-learning-explained",
    "first_paragraph": "",
    "summary": "In an *incredible* act of educational heroism, understandingai.org tackles the Everest of tech buzzwords: reinforcement learning. Condensed into what they boldly claim to be \"easy-to-digest\" prose, this guide attempts to climb the formidable peaks of AI jargon with merely a pop-culture grappling hook and a smile. Commenters, displaying their standard blend of barely-checked hubris and keen insight into misspelling buzzwords, duke it out to prove who can misunderstand the concept in the most *creative* way. In the cacophony of this intellectual slap fight, the truth about reinforcement learning remains as elusive as ever."
  },
  {
    "title": "10 Years of Pomological Watercolors (parkerhiggins.net)",
    "points": 168,
    "submitter": "fanf2",
    "submit_time": "2025-06-27T14:42:04 1751035324",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44397168",
    "comments": [
      "Blog post author here! Always happy to see people looking at and reading about these paintings. Happy to answer any questions or job offers people here may have!reply",
      "Hey Parker, congratulations on your NYT daily crossword publications! I solve the Daily every day and have been impressed to see your work there a number of times now.reply",
      "Thanks for your work.  I used one of the pomo pictures in a project a few years back.reply",
      "incredible, impactful, and authentic read!reply",
      "lol thank you other Parker Higgins, always a pleasure to run into you herereply",
      "Echoing the same thanks! I have used as well personally as technique references and in several projects directly.reply",
      "Oh wow, it's been a decade! I remember this, and was excited to see these released. Nice work!This actually inspired me to go out and start (slowly) cataloging mostly historic 100+ yr old landscapes that were locked behind mostly non-US pay-to-access (cough British museums cough), and write a flurry of emails to institutions encouraging uploading high res versions. I'm contemplating a project to put historic paintings \"on the map\", depicting their geographically represented locations (when applicable), giving a window into the past. Maybe I should circle back on this effort to get more paintings released...reply",
      "I would absolutely love to see that project come to fruition.reply",
      "If anybody just wants to download the hi-res images, Internet Archive is your friend: https://archive.org/details/usda-pomological-watercolor-coll...You can have fun with 'em since they're public domain (:Note 1: The metadata, such as title, author, etc. seem to be missing. If anyone knows of a collection with all that included, let me know (it's not in the EXIF either, I spot-checked).EDIT: aha! Here is metadata, which you can correlate to the image files: https://github.com/Wumms/pomologicalNote 2: I saw this in the MARC catalog record:  Use of the images in the U.S. Department of Agriculture Pomological\n  Watercolor Collection is not restricted, but a statement of attribution is\n  required. Please use the following attribution statement: \"U.S. Department\n  of Agriculture Pomological Watercolor Collection. Rare and Special\n  Collections, National Agricultural Library, Beltsville, MD 20705\"reply",
      "I'm also noticing there is no explicit license on the official page. If it's public domain, attribution is not required. If it is not public domain, they should clarify the license (pretty sure this is indeed public domain).Ambiguity like this is way too common...reply"
    ],
    "link": "https://parkerhiggins.net/2025/04/10-years-of-pomological-watercolors/",
    "first_paragraph": "Hello Hacker News readers! If you like this blog post, you may be interested to know that I'm on the job market. If you or your company is hiring and think I might be a good fit, please be in touch.A decade ago today I published a blog post calling for the US government to release its paintings of fruits. The Pomological Watercolor Collection, as I had recently come to know, is a beautiful and remarkable corpus of over 7,000 pictures of fruits and other biological specimens, made between the 1880s and 1940s. Through a handful of FOIA requests I\u2019d learned that the images had been meticulously digitized and put online for purchase, but that less than 100 pictures had been sold that way \u2014 not nearly enough to justify the paywall.It was a strange rallying call, and certainly feels like it comes from a different era, but (if I may humbly say so) it worked. Within a few months, the National Agricultural Library put their high-resolution scans online, and they remain available to search and d",
    "summary": "**10 Years of Pomological Watercolors (parkerhiggins.net)**\n\nA decade in, Hacker News rediscovers Parker Higgins's passionate battle to free the U.S. government's hoard of fruit paintings from the tyranny of paywalls. \ud83d\ude02 While Higgins kindly updates his r\u00e9sum\u00e9 in the opening paragraph, thankfully reminding us all that he's job-hunting (because fruit advocacy doesn't pay the bills), readers eagerly transform the comment section into a cross-section of humblebrags, job pitches, and nostalgia for the simpler times of 2013. Commenters either pitch their own tangentially related projects (because it's not a discussion until someone redirects the spotlight) or express their profound <em>shock</em> that such a crusade was ever necessary. Meanwhile, the real marvel\u2014over 7,000 public domain fruit images\u2014remains just a quirky backdrop to the grander pageant of networking and mutual admiration that is Hacker News. \ud83c\udf4e\ud83d\udcbc"
  },
  {
    "title": "bootc-image-builder: Build your entire OS from a Containerfile (github.com/osbuild)",
    "points": 25,
    "submitter": "twelvenmonkeys",
    "submit_time": "2025-06-24T15:01:07 1750777267",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44367004",
    "comments": [
      "Huh, this is kinda wild.  So for esxi images, this would seem to beat/potentially be simpler than the traditional Packer + interacting with an ISO on esxi infra, yes?reply",
      "We also have a GUI for trying this out!https://github.com/podman-desktop/extension-bootcWe\u2019re also starting to see other projects adopt a \u201cOS as a Container image\u201d such as Bazzite: https://bazzite.gg/ using bootc :)Feel free to ask any questions!reply",
      "You can also achieve this with your current system> nix-build '<nixpkgs/nixos>' -A vm -I nixpkgs=channel:nixos-25.05 -I nixos-config=./configuration.nixI use nixos btwreply",
      "Can this do vmdk format?reply",
      "Does bootc-image-builder build Native Containers?Do Native Containers work as VM images that can be stored in an OCI Image/Artifact/Package Registry?I've been mentioning Native Containers since I realized that was how bazzite works now.Is vagrant necessary anymore if host, vm, and container images can all be signed and stored in an OCI Image store?From https://news.ycombinator.com/item?id=44137501 re: Firecracker and Microsandbox VMs :> ostree native containers are bootable host images that can also be built and signed with a SLSA provenance attestation;  https://coreos.github.io/rpm-ostree/container/ ublue-os/image-template:  https://github.com/ublue-os/image-template :> Build your own custom Universal Blue Imageublue-os/akmods has nvidia GPU drivers, nvidia-open, zfs: https://github.com/ublue-os/akmods :> A caching layer for pre-built Fedora akmod RPMs> OCI images providing a set of cached kernel RPMs and extra kernel modules to Universal Blue images. Used for better hardware support and consistent build process.nvidia-container-toolkit (CDI) is necessary for --gpus=all to do CUDA and libEGL 3D with podman. Is this also already installed in bazzite?ublue-os/toolboxes: \"quadlets and systemd service units for management\", boxkit : \nhttps://github.com/ublue-os/toolboxes#imagesublue-os/devcontainer .devcontainer/devcontainer.json: \nhttps://github.com/ublue-os/devcontainer/blob/main/src/base/...It looks like the Just Justfile 40-nvidia.just has moved due to image topology simplification? https://news.ycombinator.com/item?id=39364975 :> ublue-os/config//build/ublue-os-just/40-nvidia.just defines the `ujust configure-nvidia` and `ujust toggle-nvk` commandsreply",
      "> A container for deploying bootable container images....as long as the images are in the Red Hat family (Fedora, CentOS Stream, RHEL).reply"
    ],
    "link": "https://github.com/osbuild/bootc-image-builder",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A container for deploying bootable container images.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A container to create disk images from bootc container inputs,\nespecially oriented towards Fedora/CentOS bootc or\nderivatives.Have podman installed on your system. Either through your systems package manager if you're on\nLinux or through Podman Desktop if you are on macOS or Windows. If you want to run the resulting\nvirtual machine(s) or installer media you can use qemu.A very nice GUI extension for Podman Desktop is also\navailable.\nThe command line examples below can be all handled by\nPodman Desktop.On macOS, the podman machine must be running in rootful mode:If you are on a system with SELinux enforced: The package osbuild-selinux or equivalent osbuild SELi",
    "summary": "Title: Bootstrapping the Bootstrap: A Container Odyssey\n\nSummary: In a dazzling display of recursive innovation, a new project on GitHub promises to help the three people still running their own servers build and deploy OS images from the cozy confines of a container. Because clearly, what the tech world needs most is another way to package up a Linux distro. Commenters swing between fascinated confusion and eager one-upmanship, vying to connect every tech buzzword from \u201cSELinux\u201d to \u201cOCI Image stores.\u201d Meanwhile, the average user still can\u2019t find the power button on their Docker dashboard. \ud83e\udd26\u200d\u2642\ufe0f"
  },
  {
    "title": "nimbme \u2013 Nim bare-metal environment (github.com/mikra01)",
    "points": 42,
    "submitter": "michaelsbradley",
    "submit_time": "2025-06-27T18:45:05 1751049905",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=44399193",
    "comments": [
      "Since Nim compiles to C, porting it to new platforms is surprisingly easy. I did it a few years ago for 16-bit DOS (OpenWatcom): https://github.com/Ronsor/Nim/tree/i086-and-watcom.reply",
      "Nice to see more embedded language options!reply",
      "Happy to see more Nim projects on HN!I don't know if AI code gen helped with this particular project, so please forgive my small tangent; Claude Code is surprisingly good at writing Nim. I just created a QuickJS + MicroPython wrapper in Nim with it last week, and it worked great!Don't let \"but the Rust/Go/Python/JavaScript/TypeScript community is bigger!\" be the default argument. I see the same logic applied to LLM training data: more code means more training data, so you should only use popular languages. That reasoning suggests less mainstream languages are doomed in the AI era.But the reality is, if a non-mainstream language is well-documented and mature (Nim's been around for nearly 20 years!), go for it. Modern AI code gen can help fill in the gaps.tl;dr: If you want to use Nim, use Nim! It's fun, and now with AI, easier than before.reply",
      "Is there a reasonably good IDE for Nim that provides debugging, specifically the full debugging experience (Nim code rather than C, breakpoints, inspect/modify values, etc.)? That's been the gating factor for me trying it. What's the present situation?reply",
      "I see comments like this fairly often and in my entire career (I'm 53) I've never had to use a debugger. For inspection of values, I write small functions and unit tests or just output to stderr in debug modes set with env vars. I've always thought that the need to use a debugger was a code smell- too much cyclomatic complexity of single functions.reply",
      "I'm using Claude Code... And then for manual review and editing, using Zed with Nim extensions: https://zed.dev/docs/languages/nimSorry, I don't really do debuggers... I mostly step through code interactively using a REPL (INim).reply",
      "Does Nim not output the #line directives when compiling to C? That alone should help with the debugging experience.reply",
      "My experience has been the same. I have found it much easier to write good Nim and F# code with Claide Code, than say modern Python with type hints everywhere.Both Nim and F# have strong types and strict compilers (arguably more strict in case of F#). These factors matter a lot more than how much code there is for the LLM to train on. And there probably is less ostensibly bad Nim and F# code out there than old Python code written by people who were not really developers, so the training data set is higher quality.reply",
      "oh nim nim nim nim nim, fucking nimshoutout if you got that [reference](https://youtube.com/watch?v=Z7PH36ZAao4)reply"
    ],
    "link": "https://github.com/mikra01/nimbme",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Nim bare-metal environment\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Nim bare-metal environment for embedded targets. headless modeActual implemented target: raspberry pi1 / pi zero (bcm2835)General target requirements:the build size is heavily influenced by libraries and functions you are using. For instance printf and friends occupies whooping >20kiB program space.\nI faced some runtime problems (spurious exceptions) with newlib-nano so it is not used. The default newlib build delivered with the toolchain has reent-support and that stuff needs also much program-space.\nIf you experiment keep in mind that the stack needs to be 8byte aligned in most cases. When you face race conditions this could be the culprit (or your stack is corrupted due to overflow",
    "summary": "**The Eternal Struggle of Programmer Navel-Gazing**\n\nIn a grand display of recursive digital stuttering, a new GitHub repository promises to let you *tinker bare metal* with your Raspberry Pi using Nim, a language that even your cat forgot she tried to learn last year. The heroically named \"nimbme\" manages to simultaneously boast spare documentation and a loading error masquerading as a feature, daring you to figure out if the problem is your internet connection or your life choices. The comment section, a delightful cesspool of \"been there, coded that\" one-upmanship, quickly devolves into an esoteric contest about who can dismiss standard debugging tools more haughtily while casually name-dropping lesser-known IDEs and AI code gen tools. \ud83d\ude44 Here's to the brave souls discussing invisible race conditions in a barely-used language on a platform that's primarily used to teach twelve-year-olds how to blink an LED. \ud83e\udd42"
  },
  {
    "title": "Multi-Stage Programming with Splice Variables (tsung-ju.org)",
    "points": 8,
    "submitter": "matt_d",
    "submit_time": "2025-06-27T23:45:03 1751067903",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://tsung-ju.org/icfp25/",
    "first_paragraph": "\n    This is an interactive demonstration of the ICFP 2025 paper\n    Multi-Stage Programming with Splice Variables\n    by Tsung-Ju Chiang and Ningning Xie.\n  \nWhat is multi-stage programming? It's a technique where programs generate other programs. \n    Instead of writing generic code that handles all cases at runtime, you generate specialized, optimized code \n    tailored to specific situations.\n  \n    For example, instead of a power function that uses a loop, you could generate specialized code like \n    x * x * x * x * x directly. This eliminates runtime overhead and creates highly optimized code.\n  \n    Our approach introduces splice variables \u2014 a new way to make code generation predictable and safe.\n    This technique provides precise control over the generation process and seamlessly scales to advanced features like code pattern matching and rewriting.\n    The type system automatically tracks variable dependencies, ensuring that generated code is always well-formed, properly scop",
    "summary": "\ud83e\uddd0 **Exploring the Future of Laziness: Multi-Stage Programming with Splice Variables**\n---\n\nIn a breathtaking display of academic overachievement, Tsung-Ju Chiang and Ningning Xie have cracked the code to making programmers even lazier. By introducing *\"multi-stage programming with splice variables,\"* the duo ensures that future programmers can avoid writing comprehensive code altogether. Instead, they can make their compilers vomit out hyper-optimized gibberish on the fly, because why handle all cases when you can make *x^5* look like a NASA launch code? The comment section, predictably, is a mosh pit of PhD students and coding \"gurus\" arguing over the implications for their pet projects, each more obscure than the last. \ud83d\ude80\ud83d\udcbb\ud83e\udd13"
  },
  {
    "title": "A Brief History of Children Sent Through the Mail (smithsonianmag.com)",
    "points": 81,
    "submitter": "m-hodges",
    "submit_time": "2025-06-27T20:12:00 1751055120",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=44399854",
    "comments": [
      "I'm delighted that the first picture is of a child being carried in a tote bag, and the website is advertising \"Subscribe to Smithsonian magazine and get a FREE tote\" right up at the top.Presumably the child is not included.reply",
      "Free tote**Tot not included.reply",
      "A tote without a tot is just an 'e'. :-)reply",
      "\u201cTotes Not Tots\u201dreply",
      "Well, it's like that charity that comes around every Thanksgiving or so. What's it called? - 'Totes for Tots?'reply",
      "Flat Stanley was mailed to California. If I recall correctly, his parents saved on postage because he was flat.https://en.wikipedia.org/wiki/Flat_Stanleyreply",
      "thanks, i completely forgot about Flat Stanleyreply",
      "\u201cMail carriers were trusted servants, and that goes to prove it,\u201d Lynch says. \u201cThere are stories of rural carriers delivering babies ...\u201dPlenty of stories about them fathering babies, too.reply",
      "Some very hairy babies from a very hair baby-maker, or so I understand.reply",
      "I am reminded of Bukowski\u2019s Post Office.reply"
    ],
    "link": "https://www.smithsonianmag.com/smart-news/brief-history-children-sent-through-mail-180959372/",
    "first_paragraph": "",
    "summary": "In the latest whimsical act of historical nostalgia, <em>Smithsonian Magazine</em> dives into the delightful and not at all concerning chronicles of children shipped through the postal system like parcels missing their tracking numbers. Commenters, seizing the day, turn this curious bit of archival trivia into an open mic for tote-related puns, because how else does one react to early 20th-century child logistics but with wordplay? One brilliant scholar connects the dots to Flat Stanley\u2014probably the only flat thing here besides the humor. Meanwhile, a sudden darkness looms as some reminisce about the multifaceted roles of mail carriers, prompting moral philosophers in the crowd to ponder the ethical boundaries of \"special deliveries.\""
  },
  {
    "title": "Spark AI (YC W24) is hiring a full-stack engineer in SF (founding team) (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-06-27T21:01:03 1751058063",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/spark/jobs/kDeJlPK-software-engineer-full-stack-founding-team",
    "first_paragraph": "AI-powered workflows for large-scale clean energyJoin us to accelerate the energy transition with technology.At\u00a0Spark, we\u2019re building the AI engine behind the next generation of renewable energy infrastructure. Our mission is simple yet ambitious: To help renewable energy developers build solar farms, battery storage plants, and related projects more efficiently. If you\u2019re excited to see your products directly accelerate the energy transition, read on.We\u2019re already powering decision-making for industry leaders like Colliers Engineering & Design (2k+ employees), Standard Solar (Brookfield), Pine Gate Renewables (Blackstone), and Cypress Creek Renewables \u2014 developers with over\u00a0$15B\u00a0in clean energy financing and pipelines that will deliver\u00a070GW+\u00a0of clean power to millions of households per year.One of the biggest challenges in renewable energy development is navigating regulations and local factors that can make or break a project. We build applications to find, analyze, and apply this cr",
    "summary": "**Startup Jargon Soup**: Feel left out of the climate tech buzz? Worry not! <em>Spark AI</em> is busy cobbling together AI \"magic\" to boost solar farms and battery behemoths into the eco-friendly stratosphere. \ud83c\udf3f\ud83d\udd0b They've got the heavy artillery endorsers and buzzword bingo to get any LinkedIn enthusiast's heart racing. Their comment section? A delightful echo chamber of tech-bros and renewable rookies pitching their existential need to *manifest* efficiency in green tech. Sorry, peons with mere mortal coding skills \u2013 this jesting playground is for the <i>founding elite</i>. Cue the venture capital choir! \ud83d\ude80\ud83d\udcb8"
  },
  {
    "title": "Theoretical Analysis of Positional Encodings in Transformer Models (arxiv.org)",
    "points": 11,
    "submitter": "PaulHoule",
    "submit_time": "2025-06-27T22:07:11 1751062031",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arxiv.org/abs/2506.06398",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n",
    "summary": "Title: Math Wizards Conjure Yet Another Transformer Paper\n\nIn an earth-shattering display of academia's fondness for reinventing the wheel, another paper analyzing positional encodings in Transformer models hits arXiv. Because what we <em>really</em> needed was more theoretical jargon to confirm that, yes, how you jot down numbers indeed affects the mystical inner workings of AI. In the comments section, the usual suspects engage in the scholarly equivalent of a peeing contest, debating fine points that will impact precisely nobody's day-to-day life. Meanwhile, real issues in AI ethics, transparency, and practical application patiently await their turn, which will probably come somewhere around the twelfth of Never."
  },
  {
    "title": "Transmitting data via ultrasound without any special equipment (halcy.de)",
    "points": 91,
    "submitter": "todsacerdoti",
    "submit_time": "2025-06-27T17:02:17 1751043737",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44398390",
    "comments": [
      "It might be useful to study the techniques that modems used to transmit data over phone lines.  I seem to recall trellis coded modulation being used:https://en.wikipedia.org/wiki/Trellis_coded_modulationThe acoustic channel is bound to suffer from multipath too, so some equalization may be needed too.https://en.wikipedia.org/wiki/Equalization_(communications)\nhttps://www.ti.com/lit/an/spra140/spra140.pdfIn order to receive the signal far from the transmitter, some form of spread spectrum encoding could be used, like CDMA.  The spreading factor could be negotiated.https://en.wikipedia.org/wiki/Direct-sequence_spread_spectru...reply",
      "Did somebody say Spectrum?https://softspectrum48.weebly.com/notes/tape-loading-routine...I always assumed that PWM was the go-to method for this kind of low bandwidth / high noise medium, I wonder why the author didn't go that route and used FM insteadreply",
      "> Tape data is encoded as two 855 T-state pulses for binary zero, and two 1,710 T-state pulses for binary one.Is that not FM, more specifically FSK, just with some extra harmonics?reply",
      "keep in mind I don't know much about waves, so all of this could be wrong, but I think PWM works by modulating the width of the pulse, in other words, the \"duration of the note\" if you will, so the frequency of the square wave remains constant. You have a high pulse of width t to represent a zero and a high pulse of t*2 to represent 1. The human ear might hear this as a modulating frequency, but that's only because the pulses are changing faster than our brains can recognize pitch, if that makes any sense . I don't know what a t state is, but I suspect the number is the duration of the pulse in microseconds or something of the sort.I believe IR remotes work on a similar principle: a series of blinks of two different durations, which represent 0 and 1reply",
      "Another step to look into if you really want to have fun is implementing some sort of QAM.reply",
      "IIRC, there was some commercial product - years ago - that worked by using ultrasonic data transfer.It went something like this: You install some app on your phone, which then listens for incoming audio in the ultrasonic range. The audio is coded instructions, which then would do things like blink a light on your phone or whatever. The idea was that this could be used at events (sport, music, whatever) to create light shows on the mobiles, without relying on good wifi coverage or similar in the avenue. As you could use the PA for the data transmission.reply",
      "We demonstrated this in 2003 using the smartphones of the era (they didn\u2019t have good filters, so you could detect ultrasound quite easily).See https://anil.recoil.org/papers/audio-networking.pdf sec 2.1 for the 2003 paper and some ancient videos at https://anil.recoil.org/projects/ubiqinteraction if you want some Nokia nostalgia :-)reply",
      "I wrote a very similar web implementation 12 years ago as a proof of concept - if it got the go-ahead, the plan was to test it with some commercial TV broadcasting in the UK where a ultrasonic short code could be sent to phones using an app with a Web view, or possibly native app.Sadly never got picked up, although we proved the concept could work - but it certainly had it's challenges.https://github.com/tanepiper/adOn-soundlibhttps://github.com/tanepiper/adon-ad-platformreply",
      "Google explored doing this with devices that connect to each other, specifically Chromecast and their early Google Home devices. I don't think it ever launched but Google did some interesting experiments to test the ultrasonic transfer functions on millions of consumer devices. (I worked in audio research at Google at the time but not on this).I believe the main problem is that it makes dogs go crazyreply",
      "18-20khz is not really ultrasound. Many people can still hear this range, and it's very unpleasant when played (at least to me).For comparison, medical imaging ultrasound is 2-20 MHz (that's MEGA hertz) I think,reply"
    ],
    "link": "https://halcy.de/blog/2025/06/27/transmitting-data-via-ultrasound-without-any-special-equipment/",
    "first_paragraph": "There are secret messages flying all around you all the time, being transmitted via, most of the time, electromagnetic waves going from antenna to\u00a0antenna. ELOs \u201cSecret Messages\u201d is a song about posting conspiracy theories via\u00a0WiFi.But what if you need to get a few bytes from device A to device B (one of the hard problems in computer science!) and you don\u2019t feel like making sure they\u2019re both connected to the same network? Well, fortunately, another channel is available to us - sound, or for a more fun and less-audible experience, ultrasound.Sound that you can hear is, physically, the air vibrating, or being compressed and relaxed again and again, rapidly. Our ears (or our computers ears - microphones) can pick up this pressure variation. While a computer microphone picks this pressure variation up pretty much directly (and that is, in fact, what you see when you look at an audio waveform - it\u2019s a measure of the pressure relative to ambient), the ear, and our perception, and most useful",
    "summary": "**Today in Overengineered Solutions:** Aspiring tech revolutionaries discover ultrasound data transmission, rebranding \"pigeons with USB sticks\" for the digital age. Commenters trip over themselves to inflate their geek cred, linking not one but *three* Wikipedia pages to explain why your pet's next nervous breakdown might be sponsored by their data transfer method of choice. Never mind basic physics or usability\u2014let\u2019s stuff ultrasonic screeches into every unsuspecting microphone out there! Just wait till you see the five-part Hacker News thread on emitting Morse code vibrations through espresso machine steam. \ud83e\udd2f\ud83e\udd16"
  },
  {
    "title": "Facebook is starting to feed its AI with private, unpublished photos (theverge.com)",
    "points": 23,
    "submitter": "pier25",
    "submit_time": "2025-06-28T00:08:28 1751069308",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44401406",
    "comments": [
      "This is why I requested family not to post pictures of my children on Facebook.They will get to decide what to do with their likenesses when they're older. It seemed cruel to let Facebook train a model on them from the time they were babies until they first start using social media in earnest.reply",
      "how long until we find out that the government/palantir deal is using these photos as well against citizens?i give it a year or less.reply",
      "https://archive.is/3lllhreply",
      "Very helpful for ad targeting. As Apple kills tracking and ramps up its own ad business, Meta will need to collect as many signals as possible.reply",
      "This is truly egregious. Facebook and Instagram are installed by default on many android phones and cannot be fully uninstalled. And even if asked for consent, many people may choose the harmful option by mistake or due to lack of awareness. It's alarming that these companies cannot be held to even the bare minimum standards of ethics.As an aside, there was a discussion a few days back where someone argued that being locked in to popular and abusive social/messaging platforms like these is an acceptable compromise, if it means retaining online contacts with everyone you know. Well, this is precisely the sort of apathy that gives these platforms the power to abuse their marketshare so blatantly. However, it doesn't affect only the people who choose to be irresponsible about privacy. It also drags the ignorant and the unwilling participants under the influence of these spyware.reply"
    ],
    "link": "https://www.theverge.com/meta/694685/meta-ai-camera-roll",
    "first_paragraph": "\ufeffAlways read the terms and conditions, folks.\ufeffAlways read the terms and conditions, folks.For years, Meta\u2019s trained its AI programs using the billions of public images uploaded by users onto Facebook and Instagram\u2019s servers. But apparently, Meta has decided to try training its AI on the billions of images that users haven\u2019t uploaded to those servers.On Friday, TechCrunch reported that Facebook users trying to post something on the Story feature have encountered pop-up messages asking if they\u2019d like to opt into \u201ccloud processing\u201d, which would allow Facebook to \u201cselect media from your camera roll and upload it to our cloud on a regular basis\u201d, to generate \u201cideas like collages, recaps, AI restyling or themes like birthdays or graduations.\u201d By allowing this feature, the message continues, users are agreeing to Meta AI terms, which allows their AI to analyze \u201cmedia and facial features\u201d of those unpublished photos, as well as the date said photos were taken, and the presence of other people ",
    "summary": "In a groundbreaking initiative that surely won't have any unintended privacy repercussions, Facebook now wants to peek into the unpublished corners of your selfie collection. According to a TechCrunch report, this new \"cloud processing\" feature will gobble up your photos straight from your camera roll to craft unimaginative AI-generated collages that nobody asked for. Commentators on the internet responded with the expected level of outrage, unfounded conspiracy theories, and a few obligatory \"privacy is dead\" platitudes. Meanwhile, Facebook users, in a true demonstration of learned helplessness, are likely to hit 'agree' faster than you can say \"data misuse.\""
  },
  {
    "title": "Rust in the Linux kernel: part 2 (lwn.net)",
    "points": 52,
    "submitter": "chmaynard",
    "submit_time": "2025-06-27T22:07:03 1751062023",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://lwn.net/SubscriberLink/1025232/fbb2d90d084368e3/",
    "first_paragraph": "\nIn 2023, Fujita Tomonori\n\nwrote a Rust version of the existing driver for the\nAsix AX88796B embedded Ethernet controller. At slightly more than 100 lines,\nit's about as simple as a driver can be, and therefore is a useful touchstone for\nthe differences between writing Rust and C in the kernel. Looking at the Rust\nsyntax, types, and APIs used by the driver and contrasting them with the C\nversion will help illustrate those differences.\n\nReaders who are already conversant with Rust may find this article retreads some\nbasics, but it is my hope that it can still serve as a useful reference for\nimplementing simple drivers in Rust. The\n\nC version and the\n\nRust version of the AX88796B driver are remarkably similar, but there are still some important\ndifferences that could trip up a developer performing a naive rewrite from one to the other.\n\nThe least-different thing between the two versions is the legalities. The Rust\ndriver starts with an\n\nSPDX comment asserting that the file is covered by ",
    "summary": "**Rust in the Linux kernel: part 2 (lwn.net)**\n\nIn a whimsical display of technological redundancy, Fujita Tomonori takes a stab at rewriting a perfectly functional Ethernet driver in Rust, because modern problems require modern solutions, or in this case, modern languages to spice up mundane tasks. A staggering 100 lines of code serve as a \"useful touchstone\" to showcase the overhyped differences between Rust and C, thrilling legions of code enthusiasts who thrive on microscopic differences between curly brackets. Commenters argue spiritedly about efficiency, safety, and the true meaning of life, trimming down their life expectancy as passionately as they debate garbage collection in Rust. Meanwhile, the rest of the world marvels at <em>such</em> groundbreaking advancements, undoubtedly losing sleep over whether their Ethernet connection cares about memory safety. \ud83e\udd13"
  },
  {
    "title": "The Journey of Bypassing Ubuntu's Unprivileged Namespace Restriction (u1f383.github.io)",
    "points": 12,
    "submitter": "Bogdanp",
    "submit_time": "2025-06-27T21:33:36 1751060016",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://u1f383.github.io/linux/2025/06/26/the-journey-of-bypassing-ubuntus-unprivileged-namespace-restriction.html",
    "first_paragraph": "Recently, Ubuntu introduced sandbox mechanisms to reduce the attack surface, and they seemed unbreakable. However, after carrying out in-depth research, we found that the implementation contained some issues, and bypassing it was not as difficult as expected. This post will explain how we began our research at the kernel level and discovered a bypass method. We will also share some interesting stories from the process.After years of serving as a rich attack surface for privilege escalation, unprivileged user namespaces finally started receiving serious attention. In April 2024, shortly after that year\u2019s Pwn2Own, Ubuntu published a security-focused blog post announcing new mitigations designed to lock down unprivileged namespaces and io_uring. The goal was clear: to ensure that untrusted applications run within a tighter, more controlled sandbox. These restrictions were largely implemented through AppArmor.Fast forward to September 2024, Ubuntu followed up with a presentation introducin",
    "summary": "\ud83e\udd13 *Another Day, Another \"Unbreakable\" Sandbox Cracked* \ud83e\udd13\n\nUbuntu tried locking down unprivileged namespaces, but like a toddler with a Rubik's Cube, they were adorable in their efforts. Enter scene: u1f383.github.io, where someone proudly showcases how poking around in the kernel is akin to guesswork and magic spells. Commenters are busy patting each other on the back for using Arch anyway, blissfully ignoring that their URL bar is more hacked than Ubuntu's namespace restrictions. \ud83c\udfa9\u2728"
  }
]