[
  {
    "title": "Jepsen: Amazon RDS for PostgreSQL 17.4 (jepsen.io)",
    "points": 244,
    "submitter": "aphyr",
    "submit_time": "2025-04-29T14:30:11 1745937011",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=43833195",
    "comments": [
      "Interesting. At a previous company, when we changed the pg_dump command in a backup script to start using parallel workers (-j flag) we started to rarely see errors that suggested inconsistency when restoring the backups (duplicate key errors and fk constraint errors).  At the time, I tried reporting the issue to both AWS and on the Postgres mailing list but never got anywhere since I could not easily reproduce it.  We eventually gave up and went back to single threaded dumps. I wonder if this issue is related to that behavior we were seeing.\n \nreply",
      "Was a single instance, one instance with a standby in another AZ or a multiaz cluster as tested here?\n \nreply",
      "It's not entirely clear but this isn't an issue in multi instance upstream Postgres clusters?Am I correct in understanding either AWS is doing something with the cluster configuration or has added some patches that introduce this behavior?\n \nreply",
      "This is a very good question! I do not understand AWS's replication architecture well enough to reimplement it with standard Postgres yet. This behavior doesn't happen in single-node Postgres, as far as I can tell, but it might happen in some replication setups!I also understand there are lots of ways to do Postgres replication in general, with varying results. For instance, here's Bin Wang's report on Patroni: https://www.binwang.me/2024-12-02-PostgreSQL-High-Availabili...\n \nreply",
      "Yes its different. This is a deeper overview of what they did: https://youtu.be/fLqJXTOhUg4Specially here: https://youtu.be/fLqJXTOhUg4?t=434\n \nreply",
      "In my reading of this, it looks like the practical implication could be that reads happening quickly after writes to the same row(s) might return stale data. The write transaction gets marked as complete before all of the distributed layers of a multi AZ RDS instance have been fully updated, such that immediate reads from the same rows might return nothing (if the row does not exist yet) or older values if the columns have not been fully updated.Due to the way PostgreSQL does snapshotting, I don't believe this implies such a read might obtain a nonsense value due to only a portion of the bytes in a multi-byte column type having been updated yet.It seems like a race condition that becomes eventually consistent. Or did anyone read this as if the later transaction(s) of a \"long fork\" might never complete under normal circumstances?\n \nreply",
      "This isn't just stale data, in the sense of \"a point-in-time consistent snapshot which does not reflect some recent transactions\". I think what's going on here is that a read-only transaction against a secondary can observe some transaction T, but also miss transactions which must have logically executed before T.\n \nreply",
      "\"I think what's going on here is that a read-only transaction against a secondary can observe some transaction T, but also miss transactions which must have logically executed before T.\"i was intuitively wondering the same but i'm having trouble reasoning how the post's example with transactions 1, 2, 3, 4 exhibits this behavior. in the example, is transaction 2 the only read-only transaction and therefore the only transaction to read from the read replica? i.e. transactions 1, 3, 4 use the primary and transaction 2 uses the read replica?\n \nreply",
      "Yeah, that's right. It may be that the (apparent) order of transactions differs between primary and secondary.\n \nreply",
      "ah, so something like?if the primary ordered transaction 3 < transaction 1, but the secondary ordered transaction 1 < transaction 3, then when transaction 2 read from read-only secondary, it observed only transaction 1 without transaction 3?\n \nreply"
    ],
    "link": "https://jepsen.io/analyses/amazon-rds-for-postgresql-17.4",
    "first_paragraph": "Amazon RDS for PostgreSQL is an Amazon Web Services (AWS) service which provides managed instances of the PostgreSQL database. We show that Amazon RDS for PostgreSQL multi-AZ clusters violate Snapshot Isolation, the strongest consistency model supported across all endpoints. Healthy clusters occasionally allow Long Fork and other G-nonadjacent cycles. These phenomena occurred in every version tested, from 13.15 to 17.4. Amazon RDS for PostgreSQL may instead provide Parallel Snapshot Isolation. This work was performed independently by Jepsen, without compensation, and conducted in accordance with the Jepsen ethics policy.PostgreSQL is a popular open source general-purpose SQL database. It uses multiversion concurrency control (MVCC) to provide three levels of transaction isolation. PostgreSQL\u2019s \u201cRead Uncommitted\u201d and \u201cRead Committed\u201d are both Read Committed. The \u201cRepeatable Read\u201d level actually provides Snapshot Isolation, not Repeatable Read. \u201cSerializable\u201d provides Serializability.Ama",
    "summary": "**Title: Amateur Hour at Amazon RDS with the Ghosts of Postgres Past**\n\nIn a fascinating development that grounds the philosophy \"if it ain't broke, just wait until AWS handles it,\" Amazon RDS for PostgreSQL appears to blatantly disregard the sanctity of Snapshot Isolation like a drunk uncle at a wedding disobeying the \"do not touch\" sign on the microphone. As the Jepsen report points out, Multi-AZ clusters are more like a game of \"Where's Waldo?\" with your data integrity, featuring random appearances of data anomalies across various tested versions. Meanwhile, over in the corner, we have the commenters pulling out their conspiracy boards and yarn, linking isolated backup issues to what might as well be Amazon's attempt at remaking <em>The Matrix<em> with Postgres databases. One commenter's valiant struggle to bring AWS to join the realm of reasoned dialogue dies quietly in the ignored support ticket abyss, his tale echoing in the dusty halls of the PostgreSQL mailing list. If only they'd realize this is simply about Amazon RDS's \"Parallel World\u201d isolation mode: parallel universes, but for your data transactions."
  },
  {
    "title": "Chain of Recursive Thoughts: Make AI think harder by making it argue with itself (github.com/phialsbasement)",
    "points": 345,
    "submitter": "miles",
    "submit_time": "2025-04-29T17:19:04 1745947144",
    "num_comments": 173,
    "comments_url": "https://news.ycombinator.com/item?id=43835445",
    "comments": [
      "Something I do sometimes is:- Have an AI chat model come up with an answer to a problem.- Have it write a report discussing the details of the problem and why it's answer is correct, directed at a person or AI model who has no knowledge of the initial problem or technical field.- Have a second AI model with no knowledge of the problem grade the report, and write it's own report either (a) asking for clarification / more information about the problem that the original model didn't provide or (b) pointing out an inconsistency in the argument posed by the original model. Give this report back to the original model and ask it to write it's own report back with either the necessary information or changes.- Repeat until either the second AI model is convinced by the first AI model's explanation or the first AI model has implemented all the changes requested by the second AI model.It's super clunky but has given pretty good results in the cases where I tried it lol\n \nreply",
      "Ah, now we know why Spain was out of electricity yesterday.\n \nreply",
      "I do the same, and I have one other technique.I will often have a few chats going for a project, but with different contexts. For example, one might be tech focused, another marketing focused, another with some context on my personal goals, etc.So I will take the same question and feed it into the chats with differing context. It is almost like having different perspectives on the same problem. And the conclusions can often differ based on the differing contexts.\n \nreply",
      "This reminds me a lot of the YT video that went over using Monte Carlo Tree Search with LLMs to maximize result quality. Link: https://www.youtube.com/watch?v=mfAV_bigdRA&ab_channel=Treli...It seemed like a pretty good idea, though I'd guess that it would greatly increase token usage. I'd also be concerned that the LLM as a judge might struggle to grade things accurately if it wasn't also able to generate good enough answers to begin with.\n \nreply",
      "For anything semi-adversarial, I have had good results asking the AI to come up with a plan, then take the side of the opponent coming with counter play/way to defeat the plan, finally asking for a revision of the initial plan given the potential reaction from the opponent.The final plan you obtain is generally a lot more well rounded and thought out.I find that amusing because the technique also works when I apply it to me. Picking flaws in your plan before revisiting it actually works.\n \nreply",
      "To be honest, this is what I assumed this repo was doing from the title. It talks about arguing with itself, but it looks like it's just generating multiple alternative responses in parallel and selecting the best one.Do you find your method handles \"sycophancy\" well?\n \nreply",
      "Kagi\u2019s Assistant feature makes this super easy. Just switch assistants and ask them to check the other\u2019s work.\n \nreply",
      "How?\n \nreply",
      "Ask the AI assistant for instructions.Pretty soon we'll have new acronyms such as \"IDKATFAIA\" [\"I don't know, ask the f'ing AI already\"] as we all succumb to the knowledge soup.\n \nreply",
      "RTFP\n \nreply"
    ],
    "link": "https://github.com/PhialsBasement/Chain-of-Recursive-Thoughts",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        I made my AI think harder by making it argue with itself repeatedly. It works stupidly well.\n      CoRT makes AI models recursively think about their responses, generate alternatives, and pick the best one. It's like giving the AI the ability to doubt itself and try again... and again... and again.YES. I tested it with Mistral 3.1 24B and it went from \"meh\" to \"holy crap\", especially for such a small model, at programming tasks.Mistral 3.1 24B + CoRT\nMistral 3.1 24B non CoRT\nThe magic is in:Found a way to make it even better? PR's welcome!MIT - Go wild with it\n        I made my AI think harder by making it argue with itself repeatedly. It works stupidly well.\n      ",
    "summary": "Title: Chain of Recursive Thoughts: Make AI think harder by making it argue with itself \n\nSummary: In a stunning display of innovation, someone slapped together a recursive feedback loop for AIs so they can second-guess themselves into oblivion, calling it a breakthrough in machine \u2018self-doubt.\u2019 Users on GitHub are tripping over themselves to praise how turning AI into indecisive messes vaguely resembles their own cognitive processes. \ud83e\udd2f One bright soul suggests rigging up multiple AI personas to have a boardroom-style brawl over every minor decision, proving that the future of AI is not just automation, but also soap opera-level drama. Meanwhile, practical gurus are already translating this tech into new workplace jargon like \"IDKATFAIA\" (I Don't Know, Ask The F***ing AI Already), heralding a new era of institutionalized pass-the-buck. \ud83d\ude44"
  },
  {
    "title": "Path Isn't Real on Linux (danielh.cc)",
    "points": 38,
    "submitter": "max__dev",
    "submit_time": "2025-04-29T22:35:35 1745966135",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=43838856",
    "comments": [
      "Path globbing, pipes, redirection, job control (fg/bg), and all shell variables -- not just $PATH -- are all handled by the shell.The kernel has no idea what the current process' environment $PATH is, and doesn't even parse any process environment variables at all.\n \nreply",
      "PATH isn't just handled by the shell though. Many (but not all!) of the exec* family of functions in libc respect PATH.\n \nreply",
      "It seems too far to go to say that because a system library holds some implementation details that the responsibility doesn't lie with the program using them.  There's all sorts of complex interdependent details that make those kind of boundary distinctions difficult in many operating systems.\n \nreply",
      "Why would strace cat be useful here?  By the time cat runs, it was obviously already found.It is basic knowledge that PATH is used by a command interpreter to locate the pathname of binaries.  This is true for Window's cmd.exe as well.  I never heard of a system where locating files for execution was performed by a kernel.\n \nreply",
      "Doesn't that go without saying?\n \nreply",
      "Why would the author think that the PATH environment variable is being used by the kernel? What an odd assumption.\n \nreply",
      "One thing I was surprised to learn a couple years ago is that users and groups aren't really tracked much by the Linux kernel: they're just numeric IDs that track process and file ownership. So if you setuid() to a user ID that doesn't exist in /etc/passwd or anywhere else, the kernel won't stop you.\n \nreply",
      "If I have a file on machineA with uid10001 and I copy the file to machineB, I might want it to retain that uid, but it shouldn't matter to machineB that it doesn't map to a real user.\n \nreply",
      "You and I and bunch of other people know it and take it to be self-evident, but someone discovered it (maybe recently, maybe they have known it for a while) and did the nice write up for people who had not have known that yet. https://xkcd.com/1053/\n \nreply",
      "The lucky 10,000 is a positive take on the situation.  But the article using \"real,\" which I think would connote to \"legitimate\" to most, seems a little more polarizing that sharing a discovery.\n \nreply"
    ],
    "link": "https://blog.danielh.cc/blog/path",
    "first_paragraph": "",
    "summary": "In an earth-shattering revelation that will surely destabilize the very foundations of computing, a blogger at danielh.cc drops the bombshell that the Linux kernel is blissfully unaware of your precious $PATH variable and other environment settings, which are actually managed by\u2014hold onto your socks\u2014the shell. The comment section quickly transforms into a pedantic paradise where connoisseurs of the obvious compete to see who can express the most feigned surprise and unnecessary clarification. One user bravely explains that even Windows does it the same way, a fact clearly as underappreciated as the invention of sliced bread. Another sharp mind, in a stunning display of lateral thinking, debates the semantics of \"real,\" illustrating that every day is a school day on the internet, particularly if you went to school in a particularly remedial program."
  },
  {
    "title": "Bamba: An open-source LLM that crosses a transformer with an SSM (ibm.com)",
    "points": 127,
    "submitter": "shallow-mind",
    "submit_time": "2025-04-29T17:24:29 1745947469",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=43835495",
    "comments": [
      "https://lifearchitect.ai/models-table/Love those GPQA scores hovering around 5% when chance (on 4-way multi-choice) would have got them 25%!\n \nreply",
      "So could do better than chance by excluding the option it's picked?\n \nreply",
      "A stopped clock is right twice a day, but a running clock set to the wrong time is always wrong.\n \nreply",
      "Not always true! Your statement is only true when the running clock's speed is the same as time. Thus, regular time and the clock's time will never meet.If the clock is running faster than regular time, it will at point catch up to regular time and thus be correct for a split second. If the clock is slower than regular time, regular time will catch up to the clock and the clock will be right for a split second.\n \nreply",
      "If we are being pedantic, running clocks never run exactly the same as time. So they'll be right (very) much more seldom than the stopped clock, which is right twice a day.\n \nreply",
      "The RMS of wrongness of the running clock is probably lower.\n \nreply",
      "SSM = state-space model, for the unfamiliar.https://en.wikipedia.org/wiki/State-space_representation\n \nreply",
      "> chose to make just about everything associated with Bamba open-source \u2014 the training recipes, the data, the data loader IBM designed for largescale distributed training, and a quantization framework aimed at shaving storage and inferencing costs.\n \nreply",
      "This type of architecture is definitely the future. Unlimited attn is a dead end. As a human you don't need to scan an entire book just to guess what the next word will be and LLMs shouldn't need that either.\n \nreply",
      "Not be contrarian, but if the next word prediction happens to be someone's name or a place or something discussed multiple places in the book then often, yes, a knowledge of the full plot of the book is \"required\" just to predict the next word, as you get to the middle or end of a book.For example you could never fill in the last chapter of any good book without having knowledge of every previous chapter. Not highly detailed knowledge, but still knowledge.\n \nreply"
    ],
    "link": "https://research.ibm.com/blog/bamba-ssm-transformer-model",
    "first_paragraph": "In collaboration with CMU, Princeton, and University of Illinois, IBM Research built an open-source LLM that combines the expressive power of a transformer with the runtime speed of a state-space model. Key features will soon be added to IBM Granite 4.0.Learn more about Bamba and see benchmark results in this technical blog post.Join the first vLLM meetup in NYC on May 7 at the IBM Innovation Studio at 1 Madison Avenue in Manhattan! Hosted by IBM and Red Hat, the event will feature technical talks and discussion on how to optimize LLM inference for performance and efficiency.The transformer architecture behind today\u2019s large language models has shown an uncanny ability to generate human-like text. Part of its effectiveness comes from its self-attention mechanism, which allows the model to weigh all the words in an input sequence when generating a response.The problem comes as conversations get longer. Because the model holds the running sequence in memory as it responds, the cumulative ",
    "summary": "\ud83d\udea8 In an exhausting display of acronym soup, IBM teams up with academic stalwarts to unveil Bamba, an LLM that's like a Frankenstein's monster of tech buzzwords. The high-powered collaboration promises to meld the inexplicable magic of transformers with state-space models, because why settle for inefficient AI when you can have inefficient AI that's also confusing? \ud83e\udd2f As the comment section degenerates into a half-baked discussion about running clocks and the essential value of knowing an entire book to guess one word, it\u2019s clear that Bamba\u2019s most significant feature may just be its capacity to spawn metaphysical debates about time. Strap in for a roller-coaster of tech jargon and philosophical quandaries, all served with a side of open-source bravado. \ud83e\udd37\u200d\u2642\ufe0f\ud83d\udcbb"
  },
  {
    "title": "I use zip bombs to protect my server (idiallo.com)",
    "points": 325,
    "submitter": "foxfired",
    "submit_time": "2025-04-28T22:28:56 1745879336",
    "num_comments": 172,
    "comments_url": "https://news.ycombinator.com/item?id=43826798",
    "comments": [
      "Back when I was a stupid kid, I once did    ln -s /dev/zero index.html\n\non my home page as a joke. Browsers at the time didn\u2019t like that, they basically froze, sometimes taking the client system down with them.Later on, browsers started to check for actual content I think, and would abort such requests.\n \nreply",
      "I made a 64kx64k JPEG once by feeding the encoder the same line of macro blocks until it produce the entire image.Years later I was finally able to open it.\n \nreply",
      "I had a ton of trouble opening a 10MB or so png a few weeks back. It was stitched together screenshots forming a map of some areas in a game, so it was quite large. Some stuff refused to open it at all as if the file was invalid, some would hang for minutes, some opened blurry. My first semi-success was Fossify Gallery on my phone from F-Droid. If I let it chug a bit, it'd show a blurry image, a while longer it'd focus. Then I'd try to zoom or pan and it'd blur for ages again. I guess it was aggressively lazy-loading. What worked in the end was GIMP. I had the thought that the image was probably made in an editor, so surely an editor could open it. The catch is that it took like 8GB of RAM, but then I could see clearly, zoom, and pan all I wanted. It made me wonder why there's not an image viewer that's just the viewer part of GIMP or something.Among things that didn't work were qutebrowser, icecat, nsxiv, feh, imv, mpv. I did worry at first the file was corrupt, I was redownloading it, comparing hashes with a friend, etc. Makes for an interesting benchmark, I guess.For others curious, here's the file: https://0x0.st/82Ap.pngI'd say just curl/wget it, don't expect it to load in a browser.\n \nreply",
      "For what it's worth, this loaded (slowly) in Firefox on Windows for me (but zooming was blurry), and the default Photos viewer opened it no problem with smooth zooming and panning.\n \nreply",
      "IrfanView was able to load it in about 8 seconds (Ryzen 7 5800x) using 2.8GB of RAM, but zooming/panning is quite slow (~500ms per action)\n \nreply",
      "That's a 36,000x20,000 PNG, 720 megapixels. Many decoders explicitly limit the maximum image area they'll handle, under the reasonable assumption that it will exceed available RAM and take too long, and assume the file was crafted maliciously or by mistake.\n \nreply",
      "Safari on my MacBook Air opened it fine, though it took about four seconds. Zooming works fine as well. It does take ~3GB of memory according to Activity Monitor.\n \nreply",
      "I hope you weren\u2019t paying for bandwidth by the KiB.\n \nreply",
      "Nah, back then we paid for bandwidth by the kb.\n \nreply",
      "That\u2019s even worse! :)\n \nreply"
    ],
    "link": "https://idiallo.com/blog/zipbomb-protection",
    "first_paragraph": "The majority of the traffic on the web is from bots. For the most part, these bots are used to discover new content. These are RSS Feed readers, search engines crawling your content, or nowadays AI bots crawling content to power LLMs. But then there are the malicious bots. These are from spammers, content scrapers or hackers. At my old employer, a bot discovered a wordpress vulnerability and inserted a malicious script into our server. It then turned the machine into a botnet used for DDOS. One of my first websites was yanked off of Google search entirely due to bots generating spam. At some point, I had to find a way to protect myself from these bots. That's when I started using zip bombs.A zip bomb is a relatively small compressed file that can expand into a very large file that can overwhelm a machine. A feature that was developed early on the web was compression with gzip. The Internet being slow and information being dense, the idea was to compress data as small as possible before",
    "summary": "Title: The Digital Arms Race: Zip Bombs vs. Bot Invasions\n\nIn a valiant cyber-hero move, a blogger relives the glory days of early internet warfare by deploying zip bombs to fend off the malicious bot hordes that haunt modern servers like spectral processes of doom. This nostalgic hack, a quaint reminder of the good ol\u2019 days of dial-up and IRQ conflicts, is lauded by a ragtag band of commenters who regale each other with tales of technological chaos they caused back when \"Real Player\" was still a thing. Our keen protagonist, reminiscing over past bot battles, unintentionally scripts a sideshow of how many different ways a browser can freeze, blur, and chug to the edge of digital destruction \u2014 because evidently, masochism is a fundamental trait in tech enthusiasts. Cheers to the renegade scripters, whose zip bomb nostalgia trips remind us all that what's old can always be repackaged as a headache for someone else."
  },
  {
    "title": "Everything we announced at our first LlamaCon (meta.com)",
    "points": 134,
    "submitter": "meetpateltech",
    "submit_time": "2025-04-29T17:17:23 1745947043",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=43835424",
    "comments": [
      "Its impressive that Llama and the Ai teams in general survived the meta-verse push at Facebook. Congrats to the team for keeping their heads down and saving the company from itself.Its all Ai all the time now though, not seen any mention of our reimagined future of floating heads hanging out together in quite some time.\n \nreply",
      "I'm working in Quest 3 almost every day. I use Immersed, as it implements virtual displays for my MacBook better than others, but I'm impressed with the Meta ecosystem. Granted, social interaction is still awkward without proper face expressions, but it feels closer each year to the depicted vision.I recently travelled and needed to work (coding and video editing in DaVinci) a lot in hotels and random places. I can't bring large screens everywhere (and I hate to work with small fonts and screens), and Quest 3 was a perfect fit here. Sometimes at home or office (I have a private one), I just don't want to sit on my buttoks all the time, so I put on VR goggles and can keep working in any position (lying on a sofa or even sunbathing outdoors).As soon as new XR/MR glasses become lighter (there are some good ones already - Visor, Beyond BigScreen 2, etc), more and more people will discover how usable and optimized for work this tech is.\n \nreply",
      "In no way is Quest 3 better than Apple Vision Pro for desktop work. I\u2019ve used both. It\u2019s not close.(There are other critiques of AVP that might not make it the right choice, but desktop work experience isn\u2019t one of them.)\n \nreply",
      "How do you power it for extended sessions? Is it constantly connected to power - using wifi/airlink between it and your Mac? Or do you use the link cable?\n \nreply",
      "I'm quite a big fan of my Quest 1 as a cheap flight sim headset, too. I don't end up using it more than maybe twice a week, but that's more than worth-it for the $400 I paid 5 years ago. It installs (or \"sideloads\" in present vernacular) Android apps like any other device, browses the web, and streams wireless VR from my desktop via ALVR when I want to play games. It does a lot of stuff you wouldn't expect out of a \"depreciated\" piece of hardware.The trepidation behind VR for professional applications makes sense to me - it's expensive and tough to compare with what it's replacing. As a pure vehicle for fun though, I genuinely have no regrets with my Quest hardware. It was easily a better purchase than my Xbox One.\n \nreply",
      "It\u2019s coming: https://www.uploadvr.com/meta-employees-reportedly-working-w...\n \nreply",
      "I am guessing because of Qwen 3 release they pulled back the reasoning model that was likely due to launch today.\n \nreply",
      "alibaba stole Facebook's lunch money\n \nreply",
      "Feels like Meta is going to Cloud services business but in AI domain. They resisted entering cloud business for so long, with the success of AWS/Azure/GCP I think they are realizing they can't keep at the top only with social networks without owning a platform (hardware, cloud)\n \nreply",
      "If Lidl can venture into cloud business, I guess so can Meta.\n \nreply"
    ],
    "link": "https://ai.meta.com/blog/llamacon-llama-news/?_fb_noscript=1",
    "first_paragraph": "LlamaCon has officially kicked off. Our inaugural event brings together developers from around the world who all have one thing in common: They love building with Llama. It\u2019s been a little more than two years since we launched Llama. During that time, we\u2019ve surpassed one billion downloads and, most importantly, established Llama as a leader in the open source AI ecosystem. Developers, startups, governments, and enterprises are finding success with Llama by leveraging its capabilities to drive innovation, improve efficiency, and solve complex problems.Of course, we couldn\u2019t bring together a group of developers without also sharing some open source tools that will make it easier for them to explore Llama models, build faster, and use the latest tools to defend and protect. Here\u2019s a look at what we\u2019re announcing today and how you can get started with our newest releases.We want to make it even easier for you to quickly start building with Llama, while also giving you complete control over",
    "summary": "<b>LlamaCon Unleashed:</b> In a stunning display of innovation matched only by the sheer volume of the word \"Llama,\" Meta's inaugural <i>LlamaCon</i> has developers buzzing with the kind of enthusiasm usually reserved for open bars at tech conferences. Over one billion downloads later, Llama proves you can indeed lead developers to water and make them drink, especially if you sprinkle in open-source tools like confetti at a parade. Commenters, undeterred by the actual announcements, pivot swiftly to pondering life's critical issues, such as the comparative merits of VR headsets and the existential threat of Alibaba snatching Facebook\u2019s lunch money. Whether Meta is turning into a cloud-service provider or just clouding our judgement, remains a question only Lidl's business strategies could answer. \ud83e\udd99\ud83d\udcbb\ud83c\udf29\ufe0f"
  },
  {
    "title": "Not a Zombie (notazombie.net)",
    "points": 3,
    "submitter": "carabiner",
    "submit_time": "2025-04-30T00:55:48 1745974548",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://notazombie.net/landing",
    "first_paragraph": "We use cookies.",
    "summary": "Not a Zombie launches another groundbreaking echo in the digital void, beginning with the world-shattering revelation: \"We use cookies.\" Commenters, in a display of critical thinking so rare it might be considered an endangered species, contribute cutting-edge discourse such as \"xxx,\" further underscoring the intellectual wasteland that internet comment sections have become. Join the mind-numbing excitement as readers vigorously ignore privacy implications while scrolling feverishly to find content that isn't there. It's like watching paint dry, but with more cookies and less substance. \ud83c\udf6a\ud83e\udddf\u200d\u2642\ufe0f"
  },
  {
    "title": "Only Teslas exempt from new auto tariffs thanks to 85% domestic content rule (fuelarc.com)",
    "points": 221,
    "submitter": "abduhl",
    "submit_time": "2025-04-29T20:59:51 1745960391",
    "num_comments": 216,
    "comments_url": "https://news.ycombinator.com/item?id=43837993",
    "comments": [
      "I'm not sure even Tesla unambiguously qualifies here. Looking at the NHTSA part 583 list for 2025 [0], none of the Tesla vehicles have a \"US\" content higher than 75% (which I think includes Canada?). The highest is the base Kia EV6 at 80%. This seems to be coming from the Kogod manufacturing index. That's a more qualitative ranking that attempts to deal with things like corporate structures rather than just origin like the NHTSA numbers.As someone who works in the industry, \"where\" something comes from is an inherently fuzzy concept. Different parts of the government use radically different definitions. For example, under NAFTA \"domestic\" parts are usually things manufactured anywhere in North America. This was done to onshore automotive manufacturing that wasn't realistically going to come back to the US, but political leaders didn't want to stay in Asia. One result of these tariffs may actually be that more auto manufacturing moves to Asia as the advantage of North American manufacturing is lost.[0] https://www.nhtsa.gov/sites/nhtsa.gov/files/2025-04/MY2025-A...\n \nreply",
      "If the origins are so fuzzy, I guess other manufacturers would very soon adjust their part lists/part origins to avoid the tariff?\n \nreply",
      "This is political corruption, the rule was created for Musk because he is a political ally of the president. Why wasn't it 70% or 90%? Because the number was chosen to give Tesla an unfair advantage. So while your technical points are valid, they miss the big picture.\n \nreply",
      "I have zero faith in \"free market\" ideologues, because what we actually get when they gain power is just favoritism for \"free market\" ideologues.\n \nreply",
      "You can extend the \"free market ideologues\" to include more groups such as those who were very concerned about free speech for exactly four years from 2021-2024. Same people were concerned about politicization of justice department, but only when certain Presidents are in office. Same goes for \"respect for constitution\". \"Family values\" was abandoned quite a while ago.Wilhoit\u2019s Law has never been truer.\n \nreply",
      "I have come to believe that many people's political attitudes can be boiled down to a single uniting element: an overwhelming fear that other people might do to them the kinds of things that they would absolutely do to other people if given half a chance.\n \nreply",
      "This captures a large part of their psyche well. They harp on about the dangers of a \"low trust society\" because they project their lack of trust onto the world, assuming the immigrants/gays/whoever are as cutthroat and dangerous as they are.\n \nreply",
      "Freedom of religion as well, and the age and mental acuity of the president. And handling of secret information. And being involved in foreign conflicts.\n \nreply",
      "As a 20th century political theorist once said, \"the specific political distinction to which political actions and motives can be reduced is that between friend and enemy.\"  If you hear someone talking high-minded rhetoric and idealism but they won't make a friend or an enemy over it, they don't believe it.\n \nreply",
      "Funny thing about the fictional \"Wilhoit\u2019s Law\". It's nothing but an Internet snipe from a blog post by a music composer.https://slate.com/business/2022/06/wilhoits-law-conservative...\n \nreply"
    ],
    "link": "https://fuelarc.com/cars/only-tesla-exempt-from-new-auto-tariffs-thanks-to-85-domestic-content-rule/",
    "first_paragraph": "In a major policy shift, U.S. Commerce Secretary Howard Lutnick announced that vehicles with 85% or more domestic content will be fully exempt from new tariffs on automobiles.That\u2019s a steep threshold, and as of today, there\u2019s only one automaker that qualifies for the exemption: Tesla.Here are the top 10 vehicles according to the most recent data on automobiles ranked by domestic content percentage:According to the 2024 data from the Kogod School of Business at American University, there are only three vehicles that meet the exemption threshold under the new tariff policy. Those are one cut of the Tesla Model 3 and two cuts of the Tesla Model Y with domestic content above the 85% mark.The base tariff rate for all imports is set at 10%, but the standard for many automakers and automotive part suppliers will be a stiff 25%, unless they qualify for a rebate program that will be available for the next two years only.Clearing that new 85% threshold is a massive win for any automaker, simplif",
    "summary": "The U.S. government, in its infinite wisdom, decides that being Elon Musk's BFF warrants a special tariff exemption only if your cars are as American as apple pie\u2014meaning 85% domestic content or bust. Enter stage left: <em>Tesla</em>, the lone ranger riding high with its Model 3 and Y, making them as patriotic as fireworks on the Fourth of July. Cue the commenters, armed with varying degrees of confusion and conspiracy theories, debating whether this is a genuine push for domestic manufacturing or just a cushy government handout to a Silicon Valley darling. Between cries of political corruption and free-market hypocrisy, one wonders if the actual cars matter at all in this high-octane saga of economic patriotism and partisan bickering. \ud83d\ude97\ud83d\udcb8\ud83c\uddfa\ud83c\uddf8"
  },
  {
    "title": "An illustrated guide to automatic sparse differentiation (iclr-blogposts.github.io)",
    "points": 13,
    "submitter": "mariuz",
    "submit_time": "2025-04-29T03:18:52 1745896732",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://iclr-blogposts.github.io/2025/blog/sparse-autodiff/",
    "first_paragraph": "In numerous applications of machine learning, Hessians and Jacobians exhibit sparsity, a property that can be leveraged to vastly accelerate their computation. While the usage of automatic differentiation in machine learning is ubiquitous, automatic sparse differentiation (ASD) remains largely unknown. This post introduces ASD, explaining its key components and their roles in the computation of both sparse Jacobians and Hessians. We conclude with a practical demonstration showcasing the performance benefits of ASD.First-order optimization is ubiquitous in machine learning (ML) but second-order optimization is much less common. The intuitive reason is that high-dimensional vectors (gradients) are cheap, whereas high-dimensional matrices (Hessians) are expensive. Luckily, in numerous applications of ML to science or engineering, Hessians and Jacobians exhibit sparsity: most of their coefficients are known to be zero. Leveraging this sparsity can vastly accelerate automatic differentiatio",
    "summary": "Title: Bloggers Discover Old Math, Pretend It's Magic\n\nToday on the blogosphere, rocket scientists proudly reinvent counting but with more steps and call it \"Automatic Sparse Differentiation.\" Watch in awe as they unveil ancient wizardry like \"sparse matrices\" with the panache of a toddler discovering a hidden nose. Comment sections rapidly evolve from confusion to PhD-level expertise, as every commenter types furiously to prove they absolutely knew about Jacobians before it was cool. Unleash the fireworks: mathematics just got needlessly complicated! \ud83d\ude80\ud83c\udfa9\ud83c\udf89"
  },
  {
    "title": "China's Clinical Trial Boom (asimov.press)",
    "points": 110,
    "submitter": "surprisetalk",
    "submit_time": "2025-04-28T15:13:39 1745853219",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=43822396",
    "comments": [
      "Meanwhile DOGE has cancelled more than $2 billion in federal research grants. The US is shooting itself in the foot when it should be competing at its best.https://www.cbsnews.com/amp/news/nih-layoffs-budget-cuts-med...\n \nreply",
      "The administration is also pressing for a 55% budget cut to the National Science Foundation. The NSF is the primary funding agency for engineering, physics, mathematics, chemistry and computer science, among many other fields. If there's any doubt about the seriousness of that situation, the director has resigned over it. When some worried that US world leadership in physical and life sciences may be surpassed in a generation, I doubt anyone realized it could happen in one year.https://www.science.org/content/article/nsf-director-resign-...\n \nreply",
      "Indeed, now is the moment to step on the gas in biotech. The past 15 years have been nothing short of extraordinary in the field. We finally have the tools needed to effectively measure biology, manipulate biology, and increasingly predict biology. More recently, we have been able to turn more and more problems into computational problems.With all of this coming together, we should be accelerating both public and private investment in biotechnology because we're getting closer and closer to transformative therapies. But...we're failing to rise to the occasion and meet the moment.\n \nreply",
      "Could you give some examples/directions for interesting things that have popped up in the period you're mentioning? Sounds like a fun time.\n \nreply",
      "Tools wise cheap sequencing is a big one.\n \nreply",
      "Not op, but I\u2019m in the field and can give you some things to read about:- CAR-T- CRISPR- PRIME editing- Base editing- Modified mRNA- PD-1 inhibitors- On the cusp of personalized cancer vaccines- ADCs- Structure correctors- Targeted protein degraders- siRNAsThese have all really hit their stride in the past 15 years. Guess where all of them initially came from? Random ass government-funded academic research. Sure, you can split hairs with me on the 15 years and NIH/NSF etc funding, but it\u2019s basically true. We are killing the golden goose\u2026\n \nreply",
      "Are any of these technologies profitable currently?\n \nreply",
      "Fascinating, then, how the head of DOGE has deep financial interests in China.  It\u2019s really not out of bounds to suggest that his benefactors could\u2019ve pulled some strings to kneecap the US.\n \nreply",
      "Never attribute to malice what is equally explained by incompetence, and these morons have been openly saying this is what they want to do for years.We\u2019re so unbelievably fucked.\n \nreply",
      "No. No. That no longer applies, and I would argue never applies to a publicly funded entity like the federal government. When you're spending public dollars there is zero difference between incompetence and malice.This administration has shown that it absolutely isn't incompetent. It's getting stuff done. Which means it's malice. Guaranteed. We're watching a self made disaster where few will profit, but will profit ENORMOUSLY.\n \nreply"
    ],
    "link": "https://www.asimov.press/p/china-trials",
    "first_paragraph": "",
    "summary": "Welcome to yet another episode of \"How to Undermine Western Science 101,\" brought to you by DOGE and pals, who seem to have a PhD in catastrophic budget cuts. As China ramps up its clinical trials, turning novel treatments into Tuesday's homework, the U.S. decides that federal research grants are yesterday\u2019s news \u2014 cutting over $2 billion because who needs future medical breakthroughs, right? Commenters are either decrying the sky-high stupidity or devising conspiracy theories where the big bad boogeyman is, of course, incompetence dressed as malice. Meanwhile, the future of biotechnology turns into a spectator sport, where American spectators are gradually realizing they might just be watching reruns soon. But hey, at least the comment section is on fire, stoked by the flames of impending scientific doom. Get your marshmallows ready! \ud83c\udf7f\ud83d\udd25"
  },
  {
    "title": "It's School time: Adventures in hacking an old Kindle (samkhawase.com)",
    "points": 75,
    "submitter": "FlyingSnake",
    "submit_time": "2025-04-28T15:02:04 1745852524",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43822251",
    "comments": [
      "In case the author ever sees this...If you have that battery level available off the Kindle, you can use it to turn a wifi \"smart plug\" on and off, to automatically top the charge up only when required.(Or, more old-school, use a powerpoint timer set to only power up for a short time each day. I did this way back, when the place I worked decided they needed iPads stuck next to meeting room doors to stop arguments about who had it booked, but when they first installed them they left them plugged into the charger 24x7, and the batteries in them would puff up in 8-12 months and kill the iPads. Putting the charger in a timer so they only charged  hour a day saved them about $6,000 a year in puffed up iPads.)\n \nreply",
      ">I designed a backend API that collected the data in real-time data and exported it as a PNG image.Does anyone know why in these Kindle modding dashboards, they always generate the dashbard image on an external server? Why isn't it possible to build all that functionality into an executable on the Kindle itself? You've got a Linux environment, so why can't you run all the logic locally?\n \nreply",
      "I built this dashboard. The price curves and text are rendered locally from the microcontroller and painted pixel by pixel. Letters use raster fonts stored locally, price curves are generated on the fly. It can be done, it takes a bit of care. Mine only has ~400KB memory. It must be a lot easier on the Kindle, I think it runs Java even.https://www.asciimx.com/projects/etlas/\n \nreply",
      "Most people today do not know how to program in the confines of 256MB of RAM and are not aware that languages other than javascript exist.\n \nreply",
      "I expected the Kindle to do a few api calls and call ImageMagick but instead, in Cloudflare, it sets up a headless browser, and renders a web page to a PNG file on the server, and then only the final png image gets returned to the Kindle.\n \nreply",
      "Is there anything like this that can wake the Kindle up, get an image, and then sleep it again? I have an old Kindle that I want to show stuff on, but I don't want to keep it plugged in all the time.\n \nreply",
      "I work on e-paper displays. Are you looking for something built with a Kindle?This project of mine is similar to what you described with a power down mode. The power down and wake up can be automated. I'm looking to build a small business around such projects. Not sure how viable it is.https://www.asciimx.com/projects/e-reader/\n \nreply",
      "It does seem pretty viable, TRMNL are pretty popular:https://usetrmnl.comI made some stuff of mine for that display too, but the easiest way is to just use TRMNL's firmware, as it supports autoupdates and a few other nice features.Here's mine:https://www.stavros.io/posts/making-a-trmnl-device/Plus this:https://www.stavros.io/posts/making-the-timeframe/And a few more things I never wrote about.The Kindle project is just because I have a few Kindles lying around, so I might as well use them!\n \nreply",
      "That's beautiful, thanks for sharing. I was wondering what may be the best way to do frames. Custom frames, here in Singapore, are a bit expensive relative to the rest of the parts.\n \nreply",
      "lol i  get weirdly obsessed with decimal places on stuff like this too - makes me laugh every time.\n \nreply"
    ],
    "link": "https://samkhawase.com/blog/hacking-kindle/",
    "first_paragraph": "",
    "summary": "**Old Kindles Meet New Tech: A Comedy in Several Parts**\n\nIn the latest episode of \"Much Ado About Hacking,\" an intrepid blogger decides to revolutionize technology by <em>connecting an old Kindle to a WiFi smart plug</em>. Thrilled at the mere possibility of their e-reader dictating the power flow like a throneless medieval monarch, commenters from various professional closets emerge to weigh in. First, there's back-patting on success in avoiding iPad battery explosions with timers - clearly, a monumental tech achievement worthy of Harvard Business Review. Then, we dodge through suggestions about backend APIs, server-rendered PNGs, and microcontroller wizardry, as the community tries to out-nerd each other, blissfully unaware that their Jenga tower of compact hacks leans perilously close to collapsing under its own complexity. By the end, it's less clear if their goal is to save an old Kindle or just to show off how many buzzwords one can fit in a single comment thread. \ud83e\udd13\ud83d\udd0c\ud83d\udcda"
  },
  {
    "title": "Show HN: Beatsync \u2013 perfect audio sync across multiple devices (github.com/freeman-jiang)",
    "points": 194,
    "submitter": "freemanjiang",
    "submit_time": "2025-04-29T17:32:25 1745947945",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=43835584",
    "comments": [
      "I primarily built this for group in-person listening, and that's what the spatial audio controls are for. But what is interesting is that since it only requires the browser, it works across the internet as well. You can guarantee that you and someone else are listening to the same thing even across an ocean.Someone brought up the idea of an internet radio, which I thought was cool. If you could see a list of all the rooms people are in and tune it to exactly what they're jamming to.\n \nreply",
      "> You can guarantee that you and someone else are listening to the same thing even across an ocean.How can you guarantee that? NTP fails to guarantee that all clocks are synced inside a datacenter, let alone across an ocean (Did not read the code yet)EDIT: The wording got me. \"Guarantee\" & \"Perfect\" in the post title, and \"Millisecond-accurate synchronization\" in the README. Cool project!\n \nreply",
      "More, the speed of light puts a hard cap on how simultaneous you can be. Wolfram Alpha reckons New York to London is 19ms in a vacuum, more using fibre.Going off on a tangent: Back in the days of Live Aid, they tried doing a transatlantic duet. Turns out it\u2019s literally physically impossible because if A songs when they hear B, then B hears A at least 38ms too late, which is too much for the human body to handle and still make music.\n \nreply",
      "It's a less hard problem than the duet.  If the round-trip is 38ms, you can estimate that the one-way latency is 19ms.  You tell the the other client to play the audio now, and you schedule it for 19ms in the future.That's assuming standard OS and hardware and drivers can manage latency with that degree of precision, which I have serious doubts about.In a duet, your partner needs to hear you now and you need to hear them now.  With pre-recorded audio, you can buffer into the future.\n \nreply",
      "This looks really cool, congrats!Just to share a couple of similar/related projects in case useful for reference:http://strobe.audio multi-room audio in Elixirhttps://www.panaudia.com multi-user spatial audio mixing in Rust\n \nreply",
      "This is very, very cool; it's a thing I've been looking for on my backburner for several years. It's a very interesting problem.There are a ton of directions I can think about you taking it in.The household application: this one is already pretty directly applicable. Have a bunch of wireless speakers and you should be able to make it sound really good from anywhere, yes? You would probably want support for static configurations, and there's a good chance each client isn't going to be able to run the full suite, but the server can probably still figure out what to send to each client based on timing data.Relatedly, it would be nice to have a sense of \"facing\" for the point on the virtual grid and adjust 5.1 channels accordingly, automatically (especially left/right). [Oh, maybe this is already implicit in the grid - \"up\" is \"forward\"?]The party application: this would be a cool trick that would take a lot more work. What if each device could locate itself in actual space automatically and figure out its sync accordingly as it moved? This might not be possible purely with software - especially with just the browser's access to sensors related to high-accuracy location based on, for example, wi-fi sources. However, it would be utterly magical to be able to install an app, join a host, and let your phone join a mob of other phones as individual speakers in everyone's pockets at a party and have positional audio \"just work.\" The \"wow\" factor would be off the charts.On a related note, it could be interesting to add a \"jukebox\" front-end - some way for clients to submit and negotiate tracks for the play queue.Another idea - account for copper and optical cabling. The latency issue isn't restricted to the clocks that you can see. Adjusting audio timing for long audio cable runs matters a lot in large areas (say, a stadium or performance hall) but it can still matter in house-sized settings, too, depending on how speakers are wired. For a laptop speaker, there's no practical offset between the clock's time and the time as which sound plays, but if the audio output is connected to a cable run, it would be nice - and probably not very hard - to add some static timing offset for the physical layer associated with a particular output (or even channel). It might even be worth it to be able to calculate it for the user. (This speaker is 300 feet away from its output through X meters of copper; figure out my additional latency offset for me.)\n \nreply",
      "> This speaker is 300 feet away from its output through X meters of copper; figure out my additional latency offset for me.0.3 microseconds. The period of a wave at 20kHz (very roughly the highest pitch we can hear) is 50 microseconds. So - more or less insignificant.Cable latency is basically never an issue for audio. Latency due to speed of sound in air is what you see techs at stadiums and performance halls tuning.\n \nreply",
      "Thank you for the kind words! Yeah, I think it gets a lot more complicated once you start dealing with speaker hardware. It pretty much only works for the device's native speaker at the moment.The instant you start having wireless speakers (eg. bluetooth) or any sort of significant delay between commanding playback and the actual sound coming out, the latency becomes audible.\n \nreply",
      "For devices with mics, can you have them play a test chirp to measure the latency of Bluetooth or other laggy sound stack?\n \nreply",
      "Silent disco in which everyone brings their own source and headphones.\n \nreply"
    ],
    "link": "https://github.com/freeman-jiang/beatsync",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        High-precision web audio player for multi-device playback and spatial audio.\n      Beatsync is a high-precision web audio player built for multi-device playback.WarningBeatsync is in early development. Currently, only desktop Chrome browsers are fully supported.Mobile device synchronization is experimental and may be unstable.This project uses Turborepo.Fill in the .env file in apps/client with the following:Run the following commands to start the server and client:\n        High-precision web audio player for multi-device playback and spatial audio.\n      ",
    "summary": "**Today in Hacker News Pretends to Understand Latency:** A brave soul has dumped another audio syncing tool into the sea of identical projects that *definitely* revolutionize listening. *Beatsync* promises \"perfect\" audio synchronization *across oceans*, merely assuming minor details like physics and the speed of light don't apply to its user base of techno-optimists. Commenters, armed with snippets of physics they googled five minutes ago, set forth to simultaneously educate and misunderstand basic concepts, while added suggestions range from realistic to \"is this a fever dream?\" Perfect sync, as always, remains as elusive as the concept of reading the documentation before commenting. \ud83d\ude80\ud83d\udcab\ud83d\udca4"
  },
  {
    "title": "Performance optimization is hard because it's fundamentally a brute-force task (purplesyringa.moe)",
    "points": 213,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-29T12:29:44 1745929784",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=43831705",
    "comments": [
      "I once had this kind of body recovery/stress level measuring thingy on me for a few days, and a doctor would then analyze my health and such. I was under some stress those days and (according to the measurements) I wasn't recovering properly even during the nights. But then there was this one, long, flat, deep green curve in the middle of my work day. I checked from my VCS what I was doing during that period: I was optimizing.I've since noticed this many times. Optimizing is like meditation to me. It's very mechanical (measure), with a sprinkle of creative work (once you know what is slow, it's quite obvious how to make it faster, but just challenging enough to be engaging), and it has a very nice tight feedback loop: Something is slow. I make a change. Now it's fast. Next.Optimizing is my happy place.\n \nreply",
      "I spent 10 years straight doing C++ and assembly optimization. My work is still fun these days but that was probably the most enjoyable work of my career in terms of the actual day to day coding.Code cleanup in general is the same for me, but it\u2019s really hard to justify putting much time into that when running your own company solo.\n \nreply",
      "What tools did you use to assess the results of your changes?\n \nreply",
      "The routines were individually benchmarked using some custom tools (iterate repeatedly and use statistical analysis to converge on an estimate). Always compared against a plain C reference implementation.Then there was a system for benchmarking the software as a whole on a wide variety of architectures, including NUMA. With lots of plots and statistics.Usually you\u2019d eventually end up at a point where the improvements are below the noise floor or they help on some systems and cause regression on others. The rule was usually \u201cno regressions\u201dVTune for multithreading optimization. Built a fibers and lockfree system for efficient scheduling.\n \nreply",
      "That sounds like a pretty good set up with a lot of investment, HFT shop?\n \nreply",
      "https://en.wikipedia.org/wiki/Flow_(psychology)https://en.wikipedia.org/wiki/Biofeedback\n \nreply",
      "> Optimizing is my happy place.Interesting. For me, it's refactoring.\n \nreply",
      "I remember one fun time between jobs, that I stayed up till 4 or 5 am optimizing something. It always felt like I was making progress and about to beat the original implementationUnfortunately I had to give up when I was still 10 times slower than the reference lol\n \nreply",
      "Same here, last time I was between jobs I optimized my defunct startup's database from ~50K TPS to nearly 5M TPS (no durability, if you're wondering), and that was unbelievably rewarding.\n \nreply",
      "I see you.\n \nreply"
    ],
    "link": "https://purplesyringa.moe/blog/why-performance-optimization-is-hard-work/",
    "first_paragraph": "I\u2019m not talking about skill, knowledge, or convincing a world focused on radical acceleration that optimization is necessary. Performance optimization is hard because it\u2019s fundamentally a brute-force task, and there\u2019s nothing you can do about it.This post is a bit of a rant on my frustrations with code optimization. I\u2019ll also try to give actionable advice, which I hope enchants your experience.ComposabilityCertain optimizations can only work together, while others lead to pessimizations when combined. To be an expert means to know what optimization avenues exist; to be a master means to know which ones to choose.I have a post on integer formatting in the works, covering a very particular algorithm design \u2013 and I still haven\u2019t finished it because there\u2019s like five different choices to make, I have no idea how they impact each other, and I need to analyze 25 variants to claim which one\u2019s the best in conscience. Several of my projects are similarly stuck because I don\u2019t have the willpower",
    "summary": "Title: Performance Optimization - A Fruitless Odyssey in Self-Flagellation\n\nIn a tour de force of self-pity masquerading as expertise, a blogger launches into an epic rant about the Sisyphean task of *performance optimization.* Brace yourself as they unravel the convoluted depths of code optimization, an endeavor so brutal it has stalled many a project amidst cries of existential despair. Commenters chime in with tales of their own optimization escapades, each story dripping with nostalgia for the halcyon days of manual benchmarking and code that ran slower than molasses uphill in winter. Join as one daring soul finds Nirvana in the methodical monotony of optimization, transforming their cubicle into a zen garden of runtime efficiency, blissfully unaware of their impending irrelevance. Meanwhile, another lad whips up a quick scheme to hit 5 million transactions per second, presumably just for kicks. Stand back and marvel\u2014or recoil in horror\u2014at their collective struggle against the mercilessly indifferent universe of software performance."
  },
  {
    "title": "Waymo and Toyota outline partnership to advance autonomous driving deployment (waymo.com)",
    "points": 308,
    "submitter": "ra7",
    "submit_time": "2025-04-29T23:06:02 1745967962",
    "num_comments": 227,
    "comments_url": "https://news.ycombinator.com/item?id=43839123",
    "comments": [
      "Ok, I appreciate that timelines in this space are long. But the opening phrase:\"Toyota Motor Corporation (\u201cToyota\u201d) and Waymo reached a preliminary agreement to explore a collaboration focused on accelerating the development...\"reads a bit like a parody of corporate speak about a project nowhere close to happening. Did they agree to deploy? Or reach an agreement to collaborate? No, that's too strong. They will EXPLORE collaborating on ACCELERATING development.\n \nreply",
      "It's a press release, which is like the compiled code of marketing speak, not intended for humans to read or decode.\n \nreply",
      "> They will EXPLORE collaborating on ACCELERATING development.Compared to \"FSD this year\", every year for the past five years, I honestly find the approach pretty refreshing.\n \nreply",
      "> Compared to \"FSD this year\", every year for the past five years, I honestly find the approach pretty refreshing.As an 11 years Toyota driver I agree.\n \nreply",
      "5 years...? I bought mine with FSD in 2018, and that was years after it was \"right around the corner.\" Worst Kickstarter of all time... Though I do like the car itself.\n \nreply",
      "this is just the opposite extreme of \"FSD this year\"\n \nreply",
      "Except there\u2019s FSD videos everywhere on X with every minor release, demonstrating the progress.\n \nreply",
      "They edit their videos to remove the mistakes. It's all a lie if it only works 90% of the time and you don't know when it's going to fail after being lulled into inattention.\n \nreply",
      "Progress would be get certified for self driving.  For comparison,  Mercedes, BMW, Honda etc have L3 cars on the market.  Mercedes just got approved full highway speeds in EU and working on L4 certification.\n \nreply",
      "Yes, that\u2019s called marketing. Believe it when they do what Mercedes does and accept liability rather than trying to shirk it.\n \nreply"
    ],
    "link": "https://waymo.com/blog/2025/04/waymo-and-toyota-outline-strategic-partnership",
    "first_paragraph": "April 29, 2025Author:The Waymo & Toyota TeamsToyota Motor Corporation (\u201cToyota\u201d) and Waymo reached a preliminary agreement to explore a collaboration focused on accelerating the development and deployment of autonomous driving technologies. Woven by Toyota will also join the potential collaboration as Toyota\u2019s strategic enabler, contributing its strengths in advanced software and mobility innovation. This potential partnership is built on a shared vision of improving road safety and delivering increased mobility for all.Toyota and Waymo aim to combine their respective strengths to develop a new autonomous vehicle platform. In parallel, the companies will explore how to leverage Waymo's autonomous technology and Toyota's vehicle expertise to enhance next-generation personally owned vehicles (POVs). The scope of the collaboration will continue to evolve through ongoing discussions.Toyota has long advanced research and development in support of a zero-traffic-accident vision, guided by a ",
    "summary": "**Waymo and Toyota Take a Vague Stroll Down Future Lane**\n\n<i>April 2025:</i> In yet another earth-shattering press release that accomplishes the square root of nothing, Toyota and Waymo have teamed up to bravely <i>\"explore\"</i> the possibilities of perhaps, maybe, one day, doing something impactful in the world of autonomous driving. Every stakeholder and armchair critic takes a moment from their rigorous schedule of commenting on internet forums to marvel at the groundbreaking commitment to <em>talk</em> about <em>accelerating</em> \"development.\" Commenters, clad in the armor of past disappointments, wield their cynicism with the precision of a scalpel, dissecting the frail carcass of corporate-speak hoping to find a morsel of genuine intent. In the background, the ghost of \"FSD this year\" haunts every optimistic keystroke. Stay tuned for next decade\u2019s press release, where they might just agree on the font to use in their PowerPoint presentation. \ud83d\ude99\ud83d\udca8"
  },
  {
    "title": "Modern Realty (YC S24) Is Hiring (workatastartup.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-04-29T21:00:05 1745960405",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.workatastartup.com/jobs/66546",
    "first_paragraph": "",
    "summary": "Modern Realty, a startup so disruptive it can\u2019t be bothered to describe itself in its hiring ad, decides the best way to allure top talent is via a cryptic summons on Work at a Startup. Desperate job seekers in the comments perform digital backflips to prove they are the perfect blend of obsequious and clueless. This beacon of innovation, surely housing the next Steve Jobs of real estate (or perhaps merely a moderately competent janitor), revels in the ambiguity. Watch as the tech elite trip over themselves to be part of a \"game-changing\" company that might just be revolutionizing how often an office fridge is cleaned. \ud83d\ude80\ud83c\udfda\ufe0f"
  },
  {
    "title": "ArkFlow: High-performance Rust stream processing engine (github.com/arkflow-rs)",
    "points": 132,
    "submitter": "klaussilveira",
    "submit_time": "2025-04-29T14:38:43 1745937523",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=43833310",
    "comments": [
      "How do you educate people on stream processing? For pipeline like systems stream processing is essential IMO - backpressure/circuit breakers/etc are critical for resilient systems. Yet I have a hard time building an engineering team that can utilize stream processing; Instead of just falling back on synchronous procedures that are easier to understand (But nearly always slower and more error prone)\n \nreply",
      "It's important to consider whether it's worth it, even?I worked on stream processing, it was fun, but I also believe it was over-engineered and brittle. The customers also didn't want real-time data, they looked at the calculated values once a week, then made decisions based on that.Then, I joined another company that somehow had money to pay 50-100 people, and they were using CSV, sh scripts, batch processing, and all that. It solved the clients' needs, and they didn't need to maintain a complicated architecture and the code that could have been difficult to reason about otherwise.The first company with the stream processing after I left, was bought by a competitor at fire sale price, some of the tech were relevant for them, but the stream processing stuff was immediately shut down. The acquiring company had just simple batch processing and they were printing money in comparison.If you think it's still worth going with stream processing, give your reasoning to the team, and most reasonable developers would learn it if they really believe it's a significantly better solution for the given problem.Not to over-simplify, but if you can't convince 5 out of 10 people to learn to make their job better, it's either that the people are not up to the task, or you are wrong that stream processing would make a difference.\n \nreply",
      "I agree. Unless the downstream data is going to be used to feed a system to make automated decisions (ex. HFT or Ad buying), having real time analytics is usually never worth the cost. It's almost always easier and more robust to have high tail latencies for humans to consume and as computers get faster and faster that tail latency decreases.Systems that needed complex streaming architectures in 2015 could probably be handled today with fast disk and large postgres instance (or BigQuery).\n \nreply",
      "Many successful ads feedback loops run at 15 minute granularities as well!\n \nreply",
      "Yeah that reminds me of a startup I worked at that did real-time analytics for digital marketing campaigns. We went to all kinds of trouble to update dashboards with 5-minute latency, and real-time updates made for impressive sales demos, but I don't think we had a single customer that actually needed to make business decisions within 24 hours of looking at the data.\n \nreply",
      "https://mcfunley.com/whom-the-gods-would-destroy-they-first-...\n \nreply",
      "We were doing TV ads analytics by detecting ads on TV channels and checking web impact (among other things). The only thing is, most of these ads are deals made weeks or months in advance, so customers checked analytics about once before a renewal\u2026 so not sure it needed to be near real time\u2026\n \nreply",
      "personally i think streaming is quite a bit simpler. but as you you point out, no one cares!\n \nreply",
      "Batch processing is just stream processing with a really big window ;-).  More seriously, I find streaming windows are often the disconnect. Surprisingly often, users don't want windowed results. They want aggregation, filtering, uniqueness, ordering, and reporting over some batch.  Or, they want to flexibly specify their window / partitioning / grouping for each reporting query. Modern OLAP systems are plenty fast enough to do that on the fly for most use cases - so even older streaming patterns like stream processing for real time stats in parallel with batch to an OLAP system aren't worth the complexity.  Just query the DB and cache...\n \nreply",
      "There are both technical and organizational challenges created by stream processing. I like stream processing and have done a lot of work on high-performance stream engines but I am not blind to the practical issues.Companies are organized around an operational tempo that reflects what their systems are capable of. Even if you replace one of their systems with a real-time or quasi-real-time stream processing architecture, nothing else in the organization operates with that low of a latency, including the people. It is a very heavy lift to even ask them to reorganize the way they do things.A related issue is that stream processing systems still work poorly for some data models and often don\u2019t scale well. Most implementations place narrow constraints on the properties of the data models and their statefulness. If you have a system sitting in the middle of your operational data model that requires logic which does not fit within those limitations then the whole exercise starts to break down. Despite its many downsides, batching generalizes much better and more easily than stream processing. This could be ameliorated with better stream processing tech (as in, core data structures, algorithms, and architecture) but there hasn\u2019t been much progress on that front.\n \nreply"
    ],
    "link": "https://github.com/arkflow-rs/arkflow",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        High-performance Rust stream processing engine, providing powerful data stream processing capabilities, supporting multiple input/output sources and processors.\n      English | \u4e2d\u6587\nHigh-performance Rust stream processing engine, providing powerful data stream processing capabilities, supporting\nmultiple input/output sources and processors.ArkFlow uses YAML format configuration files, supporting the following main configuration items:ArkFlow supports multiple input sources:Example:ArkFlow provides multiple data processors:Example:ArkFlow supports multiple output targets:Example:ArkFlow supports multiple error output targets:Example:ArkFlow provides buffer capabilities to handle backpressure and temporary storage of messages:Example:ArkFlow Plugin ExamplesArkFlow is licensed under the Apache License 2.0.Discord: https://discord.gg/CwKh",
    "summary": "In an exhilarating turn of events that is sure to revolutionize your ability to overcomplicate simple tasks, a new <em>high-performance Rust stream processing engine</em> known as ArkFlow offers \"powerful\" capabilities primarily involving YAML files and buzzwords like backpressure, because real constraints are for people who can't configure. Queue a torrent of breathless GitHub stars and Discord debates about the true meaning of \"stream processing,\" a concept apparently so esoteric it can make experienced engineers revert to CSV files in fear. Meanwhile, in the comment section, the relics of burned-out devs swap war stories about over-engineered systems that no client actually wanted, collectively sobbing into their keyboards about the good ol' days of batch processing. Rust, now with more reasons to pontificate on why the simplest solution wasn't quite complex enough."
  },
  {
    "title": "Programming languages should have a tree traversal primitive (tylerglaiel.com)",
    "points": 180,
    "submitter": "azhenley",
    "submit_time": "2025-04-29T12:23:19 1745929399",
    "num_comments": 139,
    "comments_url": "https://news.ycombinator.com/item?id=43831628",
    "comments": [
      "I agree with the author, we need better primitives, if you need functionality now:Major tools that exist today for partial structure traversal and focused manipulation:- Optics (Lenses, Prisms, Traversals)  Elegant, composable ways to zoom into, modify, and rebuild structures.\n\n  Examples: Haskell's `lens`, Scala's Monocle, Clojure's Specter.\n\n  Think of these as programmable accessors and updaters.\n\n\n- Zippers  Data structures with a \"focused cursor\" that allow local edits without manually traversing the whole structure.\n\n  Examples: Huet\u2019s original Zipper (1997), Haskell\u2019s `Data.Tree.Zipper`, Clojure\u2019s built-in zippers.\n\n\n- Query Languages (for semantic traversal and deep search)  When paths aren't enough and you need semantic conditionals:\n\n    - SPARQL (semantic web graph querying)\n    - Datalog (logic programming and query over facts)\n    - Cypher (graph traversal in Neo4j)\n    - Prolog (pure logic exploration)\n\n  These approaches let you declaratively state what you want instead of manually specifying traversal steps.\n \nreply",
      "Agreed; also Traversable in Haskell is a simpler abstraction than lenses and pretty directly addresses what they seem to be looking for: https://hackage.haskell.org/package/base-4.21.0.0/docs/Data-...\n \nreply",
      "Traversable and lenses are very closely linked. If you go to the original paper leading to Traversable [1] and read through it, it feels basically identical to reading through the parts of the lens library that lay down the core abstractions and the laws implementations must follow if you want to be able to blindly manipulate them. In fact, the traverse function is a Traversal, and so fits trivially into the lens ecosystem.[1] https://www.cs.ox.ac.uk/jeremy.gibbons/publications/iterator...\n \nreply",
      "To point out a prolog thing which is also applicable to other languages with good patter matching: the break/return/prune examples are all ergonomic to implement as recursion in a way that fails in C++ style type based dispatch.\n \nreply",
      "These are what I think the author is looking for. But it shouldn't be a \"primitive\" in terms of code automatically generated by the compiler, but an interface or typeclass like your examples (in a language advanced enough to have them.)The problem is that 'lens', 'monocle', etc. are famously abstract and difficult for people to apply to their actual problems. IMO, the solution would be for standard libraries to specify interfaces called 'BreadthFirstTraverse', 'DepthFirstTraverse', etc.\n \nreply",
      "I definitely agree for traversals, but Lenses need some sort of primitive support - even in Haskell they're mostly generated with TemplateHaskell, and the language developers have spent a long time trying to make the `record.field` accessor syntax overloadable enough to work with lenses[1][2]. Hopefully someday we'll be free from having to memorize all the lens operators.Optics are famously abstract in implementation, but I don't think people have trouble applying them - people seem to like JQuery/CSS selectors, and insist on `object.field` syntax; it's kind of wild that no mainstream language has a first-class way to pass around the description of a location in an arbitrary data structure.[1] https://ghc-proposals.readthedocs.io/en/latest/proposals/002...[2] https://ghc-proposals.readthedocs.io/en/latest/proposals/015...\n \nreply",
      "Like offsetof[1]?[1] https://en.cppreference.com/w/cpp/types/offsetof\n \nreply",
      "Optics let you concisely describe the location, but defer the dereferencing, so you could definitely approximate optics, not by passing around pointers you compute with `offsetof`, but passing around functions that use `offsetof` to return memory locations to reference (read/write to). You could certainly write a composition operator for `*(*T) => List<*R>`... Some people have done something like it[1][2]:    Account acc = getAccount();\n    QVERIFY(acc.person.address.house == 20);\n\n    auto houseLens = personL() to addressL() to houseL();\n    std::function<int(int)> modifier = [](int old) { return old + 6; };\n    \n    Account newAcc2 = over(houseLens, newAcc1, modifier);\n\nThese also use templating to get something that still feels maybe a little less ergonomic than it could be, though.[1] https://github.com/graninas/cpp_lenses\n[2] https://github.com/jonsterling/Lens.hpp\n \nreply",
      "Haskell has 'Traversable' (and 'Foldable' etc) which are a lot more approachable than the fully generalised lens library.\n \nreply",
      "> These are what I think the author is looking for. But it shouldn't be a \"primitive\" in terms of code automatically generated by the compilerI think people are often too enamored by general purpose languages that can express such abstractions natively. I don't see an issue with a language that provides this  as a primitive without being able to express it itself, constraints can be useful for other properties. Once you can traverse trees, most programming problems can be tackled even in such constrained languages, eg. SQL with CTE.\n \nreply"
    ],
    "link": "https://blog.tylerglaiel.com/p/programming-languages-should-have",
    "first_paragraph": "",
    "summary": "**Hacker News on Steroids:** In the riveting world of programming, Tyler Glaiel proposes a daring & innovative idea: introducing tree traversal as a language primitive. Fortunately, a cavalry of code wizards quickly gallops into the comments with their magic wands known as \"Optics,\" \"Zippers,\" and \"Query Languages,\" unleashing an orgy of technical jargon that threatens to steamroll any mere mortal trying to follow along. Embracing the charm of Haskell in the same breath they condemn mainstream languages, commenters wax poetic over abstractions that 99% of coders pray never to encounter in job interviews. The discussion devolves into a syntax-slinging showdown, leaving bystanders bewildered and wondering if they wandered into an arcane cult rather than a tech forum. \ud83e\uddd9\u200d\u2642\ufe0f\ud83d\udcbb\ud83d\udd2e"
  },
  {
    "title": "Show HN: A Chrome extension that will auto-reject non-essential cookies (bymitch.com)",
    "points": 202,
    "submitter": "mitch292",
    "submit_time": "2025-04-29T11:49:55 1745927395",
    "num_comments": 124,
    "comments_url": "https://news.ycombinator.com/item?id=43831298",
    "comments": [
      "Love the idea.  I wish chrome extensions had a more granular permissions structure and/or reminders/security checkups on installed extensions and their permissions.As it is the content scripts manifest permission for https://*/* for content.js is always so jarring to see.  For those that don\u2019t know this allows the extension to run that script on every site you visit after clicking accept ONCE when you install the extension.  That means it can see financial info, health info, legal info, your diary, etc\u2026Now this makes sense from a usability perspective (I never have to see a cookie banner ever again!), but the author could change content.js at any time and the extension would continue to run without prompting the user.This is not an attack on you Mitch!  It sure looks like you\u2019re trying to provide value in this world rather than take it.  Rather it\u2019s an attack on Google\u2019s extension security model I\u2019m really shocked google has not taken a more careful and nuanced stance to protecting users from a security standpoint.I write this as a fellow chrome extensions dev.  I wish I had better more granular permissions structures to protect my users and give them more information about what I am requesting and why along with regular reminders so they can make informed decisions about what they want to share.\n \nreply",
      "Definitely agree, not a fan of the permissions.The broad permissions were required from a usability standpoint. Granting permission on every site for this extension would just be a 1 to 1 replacement of clicking reject on the banner or pop up for every site.I would hope that before Chrome approves an extension to be added to the store that they are auditing the content of package.\n \nreply",
      "Personally, I would still love a site-by-site \"reject non-essential cookies\" prompt from an extension that's in the same place, with the same UI, on every site. Still a click, but lots better than having to figure out how to accomplish it on each and every site.\n \nreply",
      "https://developer.chrome.com/docs/webstore/review-process\n \nreply",
      "One of the reasons Manifest v3 was started is that is impossible for an extension that eval's arbitrary code from the web (or downloads, say, a dynamic list of data and acts on it).For something like this, it's tractable.\n \nreply",
      "Cookie banners are a bad/wrong solution to the underlying problem, but it's the dark patterns within that really piss me off. I shouldn't have to invest deep cognitive attention to \"only accept mandatory\" but if you're not careful many dialogs will trick you into clicking accept all after you go to the trouble to untoggle all the optional shit. The answer is to use isolation containers, aggressively reset them and not to worry about any of this.\n \nreply",
      "I hate how web sites can weasel their way around consent by simply declaring their cookies as \"necessary\" or \"mandatory.\" As the Dude would say: Yeah, well, that's just like, your opinion, man. How about we have an easy-to-use \"Reject ALL cookies from this site (and deal with whatever breaks)\" option?\n \nreply",
      "You're assuming maliciousness. I run a site that uses cookies (encrypted session cookie) so they can add items to a cart, because not doing so would be a horrible UI. There's also a cookie created by the payment processor, but I only load their script on checkout. There's nothing else though. I don't even use tracking / analytics.There's zero weaseling going on. No dark patterns. I'm just too busy to build a no-cookie version that passes info in the URL or w/e (which also seems less than ideal). Your two options are to use the site or don't use the site. If there was enough pressure from real customers to provide another option then I probably would, but it wouldn't change anything. It's just busy work / checking boxes.IMO this needs to be built into the browsers rather than being yet another tax on builders due to spammers / scammers / advertisers. If we had meta referencing each cookie where you can disclaim exactly how it will be used and whether it's optional / required, then we would have a standard without dark patterns being possible.\n \nreply",
      "Session cookies don't require a banner or any kind of notification.\n \nreply",
      "That's good to know (and reasonable)!\n \nreply"
    ],
    "link": "https://blog.bymitch.com/posts/reject-cookies/",
    "first_paragraph": "",
    "summary": "Title: Hacker News Discovers Browser Cookies For The First Time\n\nWelcome to another episode of Hacker News reinvents the wheel, where today\u2019s \"innovation\" is a Chrome extension that promises to auto-reject non-essential cookies. \ud83c\udf6a\ud83d\ude45\u200d\u2642\ufe0f This groundbreaking tool will surely revolutionize your browsing experience by doing exactly what your browser settings already could - but now with an exciting risk of compromised personal data! Commentariat is in a frenzy, splitting time between bemoaning the permissions model of Chrome extensions and fantasizing about a cookie-free utopia. Meanwhile, pragmatists in the thread remind everyone that sometimes cookies are, in fact, necessary, and that nothing is free in this world, not even your illusion of privacy. Will this extension change the internet? Probably not, but it might change your ad preference settings, unintentionally."
  },
  {
    "title": "Firefox tab groups are here (blog.mozilla.org)",
    "points": 508,
    "submitter": "TangerineDream",
    "submit_time": "2025-04-29T15:37:10 1745941030",
    "num_comments": 308,
    "comments_url": "https://news.ycombinator.com/item?id=43834101",
    "comments": [
      "Wow, this is a fantastic feature that was heavily requested, and HN cannot stop being negative.Great job Mozilla.I was already using the awesome \u201cSimple Tab Groups\u201d extension  for this but will look into switching.\n \nreply",
      "> HN cannot stop being negative.The purpose of HN is intellectual curiosity.Mindless positive remarks that ignore flaws is not in the spirit of intellectual curiosity.Thoughtful critism is in the spirit of intellectual curiosity.Emotionally manipulative and anti-intellectual comments like yours are also not in the spirit of intellectual curiosity.This isn't Reddit. If you want Reddit, go there.\n \nreply",
      "I've been liking the new vertical tabs too.\n \nreply",
      "How does it compare to sidebery? I use the vertical tabs on that and quite like it but only found them because of another feature, per container socks5 (one for local ip and a few to strategically placed cheap vps to override my network default mullvad vpn tunneling as needed)\n \nreply",
      "I never have more than like 10 tabs open at a time, so likely wont be helpful to me, but I find this super interesting!Can someone explain what normal people use so many tabs for? It seems to be super common to have tons and tons open.Are people using tabs as a soft bookmark of basically anything interesting? Afraid to close the page because they wont find it in their history or bookmarks? Is this more an issue with bookmarks and history not being as useful as they could be?Not judging or anything, I just find how other people use tools differently than I do an interesting subject.\n \nreply",
      "I have almost 2000 tabs open. I use sideberry for tab management.> Are people using tabs as a soft bookmark of basically anything interesting?Yep, that's as good a description as any. I have a lot of tabs that I'm not \"finished with\" in any finite amount of time.Case in point: currently shopping for a steam generator for a steam shower. I have about 30-40 tabs open to different models, stores, reviews, data pages etc. Once I'm done with the purchase, I'll close them all.I sometimes use sideberry's ability to have tab groups, but not much.To be honest, it's a not a great system in that stuff falls off my radar. Most of the tabs at the bottom of my sideberry tab list are ones I have not visited in many months. There's very little point having them there. However the cognitive cost and computational costs are close to zero.\n \nreply",
      "What are you using to unload tabs?I've got to confess that my FF memory management is a run-as-needed-or-think-it-should-be-needed shell script which arbitrarily kills the top 10 Firefox processes by memory utilisation.  If I'm leaving my desktop for a while I'll run that several times.Tree-style Tabs keeps the slots open, and can reload tabs as needed.I'd really like to have the capacity to unload all tabs other than, say, a specifically-specified set. Though on balance, the tabs that are likely to be most usefully kept open also tend to be the worst memory offenders.If I fail to prune, MacOS falls over early and often, which is somewhat unpleasant.\n \nreply",
      "> I have almost 2000 tabs open. I use sideberry for tab management.I'm just here to report that Firefox + Sidebery continues to work perfectly well at 14571 \"open\" tabs.All but a few hundred are unloaded, and I block JavaScript fairly aggressively. Currently measuring 1992 MB, explicitly allocated.I won't argue with anyone who tells me that I have a problem, but I will say that Firefox and Sidebery make my problem not a problem!\n \nreply",
      "Can report that my testing indicates 40k+ tabs is doable with unloading on a 64 GB machine, across multiple Firefox windows with tree style tab.Since task manager has been introduced, making it easy to unload whole related tab groups its even easier to reach absurd total tab counts. ;-)\n \nreply",
      "I just wanted to say thank you to all you mad tab hungry folks for making me feel both seen and comparatively sane.\n \nreply"
    ],
    "link": "https://blog.mozilla.org/en/firefox/tab-groups-community/",
    "first_paragraph": "",
    "summary": "**Firefox Heralds the End of Human Memory with Tab Groups**\n\nIn a daring attempt to replace the human brain with digital tabs, Mozilla introduces \u201ctab groups,\u201d ensuring that users never have to close a tab again. This groundbreaking feature is meant to transform us into cyborgs capable of multitasking on inhuman levels, as evidenced by prodigious commenters boasting about their 2000+ tabs like it's stock in Tesla. Critics on Hacker News, guardians of pragmatic tech discourse, battle the waves of naive enthusiasm with warnings of memory overload and existential threats to MacOS. Meanwhile, regular users wonder aloud if anyone out there uses Firefox for something as quaint as browsing the web. \ud83e\udde0\ud83d\udca5"
  },
  {
    "title": "Show HN: An MCP server for understanding AWS costs",
    "points": 28,
    "submitter": "StratusBen",
    "submit_time": "2025-04-25T14:43:57 1745592237",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43794120",
    "comments": [
      "What's the difference between connecting an LLM to the data through Vantage vs directly to the AWS cost and usage API's?\n \nreply",
      "A few things.The biggest is giving the LLM context. On Vantage we have a primitive called a \"Cost Report\" that you can think of as being a set of filters. So you can create a cost report for a particular environment (production vs staging) or by service (front-end service vs back-end service). When you ask questions to the LLM, it will take the context into account versus just looking at all of the raw usage in your account.Most of our customers will create these filters, define reports, and organize them into folders and the LLM takes that context into account which can be helpful for asking questions.Lastly, we support more providers beyond AWS so if you wanted to merge in other associated costs like Datadog, Temporal, Clickhouse, etc.\n \nreply",
      "This is going to different, as resources end up getting intertwined? or is there a way to standardize it?\n \nreply"
    ],
    "link": "item?id=43794120",
    "first_paragraph": "",
    "summary": "**Title: Show HN: An MCP Server for Flailing at AWS Costs**\n\nIn a valiant yet possibly misguided attempt to decipher the hieroglyphics that are Amazon Web Services billing, a hopeful Hacker News user unleashes an MCP server, because clearly, the 83 existing tools weren\u2019t quite <em>cutting the mustard</em>. Desperate commenters, grappling with the notion of \"Cost Reports\" like cavemen first discovering fire, eagerly seek wisdom on whether painting AWS costs across different canvases using Vantage or AWS APIs will reveal the secrets of the cloud pricing universe. Spoiler: it won't. Cue a chorus of overeager tech bros debating the existence of these magical filters, while off to the side, a lone voice questions if merging costs like mixing paint will finally paint a clearer picture. Spoiler: it really won't. \ud83e\udd21\ud83c\udfa8\ud83d\udd25"
  }
]