[
  {
    "title": "Bill Banning One-Person Trains Would Lock NY Transit in the Past (etany.org)",
    "points": 14,
    "submitter": "Ericson2314",
    "submit_time": "2025-07-20T01:33:47 1752975227",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44621119",
    "comments": [
      "Important note: this applies to city trains, which operate in a much more predictable environment than trains that cross large areas of the country.reply",
      "I am ABSOLUTELY sick and tired of upstate folks making decisions for New York.reply",
      "If people want one or two people in the loop on board commuter trains its fine by me. Really it should be a local/democratic decision.Long haul freight trains however, should absolutely be exempt.reply"
    ],
    "link": "https://www.etany.org/statements/impeding-progress-costing-riders-opto",
    "first_paragraph": "New York\u2019s bill banning One-Person Train Operation (OPTO) goes against best practices both across the country and the world, and would leave New York\u2019s transit system far behind its peers (Image courtesy of Franklin Tang, ETA).The New York State Legislature has just passed a bill (S4091/A04873) that would lock New York City\u2019s transit system in the past. This bill, which would require a conductor to be on board every train operated by New York City Transit, is the technological equivalent of requiring every elevator in the city to still be staffed by an elevator operator. If you take other transit systems both across the country and around the world, you'll quickly realize that two-person train operation (TPTO) is an outdated practice that is used almost nowhere else\u2014and in the few cities where it is used, it is generally being phased out. Indeed, in order to provide more frequent service for more passengers, many cities across the world are moving to fully automated trains. New York sh",
    "summary": "Welcome to _New York Nostalgia Fest 2023_, where progress goes to die and lawmakers obsess over job creation for hypothetical 19th-century ancestors. \ud83c\udf89 In a miraculous display of backward thinking, New York legislators decided to cram their transit system into a time machine and slam the dial to \"The Good Old Days\" by mandating a conductor on every train \u2014 because who cares about efficiency or global standards when we can live in the past? Commenters are torn between futile regional squabbles and a touching desire to democratize their way back to steam engines. Surely maintaining high employment for booth collectors and gaslighters is next on the agenda! \ud83d\ude82\ud83d\udcbc"
  },
  {
    "title": "Hungary's oldest library is fighting to save books from a beetle infestation (npr.org)",
    "points": 18,
    "submitter": "smollett",
    "submit_time": "2025-07-16T15:25:30 1752679530",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.npr.org/2025/07/14/nx-s1-5467062/hungary-library-books-beetles",
    "first_paragraph": "By\u00a0\n\n      The Associated Press\n    \n\n                Books are kept in hermetically sealed plastic sacks for disinfection, at the Pannonhalma Archabbey's library in Pannonhalma, Hungary on July 3.\n                \n                    \n                    Bela Szandelszky/AP\n                    \n                \nhide caption\nPANNONHALMA, Hungary \u2014 Tens of thousands of centuries-old books are being pulled from the shelves of a medieval abbey in Hungary in an effort to save them from a beetle infestation that could wipe out centuries of history.The 1,000-year-old Pannonhalma Archabbey is a sprawling Benedictine monastery that is one of Hungary's oldest centers of learning and a UNESCO World Heritage site.Restoration workers are removing about 100,000 handbound books from their shelves and carefully placing them in crates, the start of a disinfection process that aims to kill the tiny beetles burrowed into them.The drugstore beetle, also known as the bread beetle, is often found among dri",
    "summary": "**Hungary's Historical Book Buffet: Beetles Dine in Style**\n\nIn a twist that proves even insects appreciate fine literature, Hungary's ancient Pannonhalma Archabbey library is under siege from drugstore beetles with a taste for history. These cultured critters are chomping through 100,000 handbound manuscripts, prompting humans to engage in a plastic-wrapped battle against bibliophage bugs. Restoration efforts, described with a delightful dash of despair, involve vacuum-sealed books as a last-ditch effort to save what one could argue is a really fancy all-you-can-eat buffet. Meanwhile, the comment section bubbles with bug puns, knee-jerk lamentations over modern pest control, and oddly passionate debates about the best recipes for insect repellent\u2014natural, of course. Too bad the beetles don\u2019t read online comments; they might die laughing before the disinfection kills them. \ud83d\udcda\ud83d\ude02\ud83d\udc1e"
  },
  {
    "title": "Make Your Own Backup System \u2013 Part 1: Strategy Before Scripts (dragas.net)",
    "points": 155,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-19T19:43:23 1752954203",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=44618687",
    "comments": [
      "> One way is to ensure that machines that must be backed up via \"push\" [..] can only access their own space. More importantly, the backup server, for security reasons, should maintain its own filesystem snapshots for a certain period. In this way, even in the worst-case scenario (workload compromised -> connection to backup server -> deletion of backups to demand a ransom), the backup server has its own snapshotsMy preferred solution is to let client only write new backups, never delete. The deletion is handled separately (manually or cron on the target).You can do this with rsync/ssh via the allowed command feature in .ssh/authorized_keys.reply",
      "Another thing you can do is just run a container or a specific backup user. Something like with a systemd-nspawn can give you a pretty lightweight chroot \"jail\" and you can ensure that anyone inside that jail can't do any rm commands.  pacman -S  arch-install-scripts            # Need this package (for debian you need debootstrap)\n  pacstrap -c /mnt/backups/TestSpawn base    # Makes chroot\n  systemd-nspawn -D /mnt/backups/TestSpawn   # Logs in \n  passwd                                     # Set the root password. Do whatever else you need then exit\n  sudo ln -s /mnt/backups/TestSpawn /var/lib/machines/TestSpawn\n  sudo machinectl start TestSpawn            # Congrats, you can now control with machinectl\n\nConfigs work like normal systemd stuff. So you can limit access controls, restrict file paths, make the service boot only at certain times or activate based on listening to a port, make only accessible via 192.168.1.0/24 (or 100.64.0.0/10), limit memory/CPU usage, or whatever you want. (I also like to use BTRFS subvolumes) You could also go systemd-vmspawn for a full VM if you really wanted to.Extra nice, you can use importctl to then replicate.reply",
      "I fall into the \"pull\" camp so this is less of a worry. The server to be backed-up should have no permissions to the backup server. If an attacker can root your live server (with more code/services to exploit), they do not automatically also gain access to the backup system.reply",
      "I also implemented my backup scheme using \"pull\" as it is easier to do than an append-only system, and therefore probably more secure as there is less room for mistakes. The backup server can only be accessed through a console directly, which is a bit annoying sometimes, but at least it writes summaries back to the network.reply",
      "This is also why I use rclone copy instead of rclone sync for my backups, using API keys without permission to delete objects.reply",
      "It's endlessly surprising how people don't care / don't think about backups. And not just individuals! Large companies too.I'm consulting for a company that makes around \u20ac1 billion annual turnover. They don't make their own backups. They rely on disk copies made by the datacenter operator, which happen randomly, and which they don't test themselves.Recently a user error caused the production database to be destroyed. The most recent \"backup\" was four days old. Then we had to replay all transactions that happened during those four days. It's insane.But the most insane part was, nobody was shocked or terrified about the incident. \"Business as usual\" it seems.reply",
      "If it doesn't affect your bottom line enough to do it right, then I guess it's ok?reply",
      "I'd go even a step further: For the big corp, having a point of failure that lives outside its structure can be a feature, and not a bug.\"Oh there goes Super Entrepise DB Partner again\" turns into a product next fiscal year, that shutdowns the following year because the scope was too big, but at least they tried to make things better.reply",
      "Possibly for legal purposes? Litigation holds are a PITA and generators of additional liability exposure, and backups can come back to bite you.reply",
      "Companies that big have legal requirements to keep much of their data around for 5-7 years anyway.reply"
    ],
    "link": "https://it-notes.dragas.net/2025/07/18/make-your-own-backup-system-part-1-strategy-before-scripts/",
    "first_paragraph": "For as long as I can remember, backup is something that has been underestimated by far too many people. Between flawed techniques, \"Schr\u00f6dinger's backups\" (i.e., never tested, thus both valid and invalid at the same time), and conceptual errors about what they are and how they work (RAID is not a backup!), too much data has been lost due to deficiencies in this area.Nowadays, backup is often an afterthought. Many rely entirely on \"the cloud\" without ever asking how - or if - their data is actually protected. It's a detail many overlook, but even major cloud providers operate on a shared responsibility model. Their terms often clarify that while they secure the infrastructure, the ultimate responsibility for protecting and backing up your data lies with you. By putting everything \"in the cloud\", on clusters owned by other companies, or on distributed Kubernetes systems, backup seems unnecessary. When I sometimes ask developers or colleagues how they handle backups for all this, they loo",
    "summary": "**Another Day, Another Backup Blunder \ud83d\ude44**\n\nToday on <i>Dragas.net</i>, the Internet gathers to solve the age-old mystery: how do *You* backup your bits? Between philosophical musings on \u201cSchr\u00f6dinger's backups\u201d and fears of cloud-based betrayal, the crowd has concocted an everything-but-the-kitchen-sink strategy involving rsync, ssh-tunneling, and some systemd-dark magic for those special snowflakes who reckon a 'fun Saturday night' is a deep dive into backup jail. Meanwhile, in the comment section, hobbyist sysadmins war over \"push\" versus \"pull\", and someone named Dave, leveraging his extensive tenure at a billion-euro company, enlightens us that backups are for the weak\u2014or at least for those with less faith in the cloud gods. \ud83e\udd37\u200d\u2642\ufe0f"
  },
  {
    "title": "Beyond Meat Fights for Survival (foodinstitute.com)",
    "points": 21,
    "submitter": "airstrike",
    "submit_time": "2025-07-19T23:54:40 1752969280",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44620606",
    "comments": [
      "This is too bad. Beyond and Impossible opened up the door to me gradually becoming vegan. It was similar enough to real meat that I didn\u2019t miss meat anymore, and from there I found other substitutions which were healthier. Without them I\u2019m sure I never would have started a plant-based diet.reply",
      "I posted before: I care more about the nutritional content being close to meat than the look and taste; specifically, similar macro-nutrient ratios and whatever micro-nutrients are rare outside of meat.I also care about it being cheap in theory, even if it's more expensive in practice because the company hasn't scaled up. But really, as long as it's not ridiculously expensive, and isn't missing some nutrient or balance that would mess up my diet, I'd buy it for the environment.reply",
      "Other faux-meat companies like Impossible seem to be doing better. Maybe Beyond's product is inferior? Personally, I don't choose it over Impossible.reply",
      "Not a customer but it\u2019s a shame it\u2019s not working out for them. I\u2019m sure they have people who would enjoy it but the feedback I\u2019ve heard was mostly negative with respect to quality of ingredients and the like.At this stage if they scaled back would they stand a chance to survive? Or do they owe too much money?reply",
      "They owe way too much. The article actually touches on this - they have such little hope of paying back their debt that they are leaning into this so that they can get better renegotiation terms with bond holdersreply",
      "I feel like I'm the ideal customer for Beyond Meat and its competitors. I am not price sensitive, I don't mind the idea of plant based meat products, and I am willing to try new things. My biggest reasons for not buying Beyond Meat are that I:1. Would rather not cook, and eating Beyond Meat in a way that's financially meaningful for them as a company means me cooking2. If I'm going to put in the effort to cook, I want the result to be something that I have outsized enjoyment for. If I get a middling burger for my trouble, I'm simply not going to care enough to do it.The chicken nuggets and popcorn chicken sound the closest to something I can casually heat up, but neither of those are things that would replace something in my existing diet. They have beef and chicken and sausage and all sorts of other stuff, but they're just the meat. They replace an ingredient.I buy Jimmy Dean breakfast bowls. I'd happily get ones that used Beyond Meat. I buy frozen noodle and pasta meals: same deal. Sandwiches. Chicken salad. Soup. I'm struggling to think of a single product that I can swap out for a Beyond Meat alternative.I don't need every bit of meat that I consume to even be especially good. But if it's only just fine and it's not convenient, I'm just not going to get it. If it was cheaper, I might consider. Or if it was more nutritious. Or if it was more filling than regular meat (or less filling, even). Or if I felt strongly about the plant based products that I buy being a somewhat compelling meat facsimile. But there's just nothing that inspires me to pick up any of their products.reply",
      "That's disappointing, they've done a great job making plant meat ubiquitous and took away some of the hippy aura that has kept many people from trying plant-based meat alternatives. I really hope they can turn it around, both selfishly as a happy customer, as well as for the planet.reply"
    ],
    "link": "https://foodinstitute.com/focus/beyond-meat-fights-for-survival/",
    "first_paragraph": "\n\tVince Martin | March 5, 2025\n\tVince Martin | March 5, 2025From a fundamental perspective, Beyond Meat is one of the worst stocks in the entire market. Revenue growth has been paltry: The company expects the figure to reach about $330 million in 2025, roughly 10% higher than it was six years earlier despite a huge increase in the number of products offered.Profitability is distant. In 2024, on an operating basis Beyond Meat lost 45 cents from every dollar of sales. The company\u2019s current target is to reach EBITDA (earnings before interest, taxes, depreciation, and amortization) breakeven by the end of next year. But even that target, if reached, would still mean Beyond Meat is posting negative free cash flow.That\u2019s a problem given that $1 billion in convertible bonds come due in March 2027. Beyond Meat has no way to repay that debt, and the credit markets know it: The bonds currently trade at about 17 cents on the dollar.In that context, the surprise is not that Beyond Meat stock is do",
    "summary": "**Beyond Unrealistic Expectations for Beyond Meat**\n\nIn a stunning display of financial acrobatics, Beyond Meat continues its heroic struggle against the cruel clutches of profitability. Despite a \"huge increase\" in products, their revenue growth barely squeaks up, making glaciers look speedy in comparison. As fiscal doom looms with a billion-dollar bond debt, online commentators hold a vigil, reminiscing how these faux meats nearly tricked them into full veganism or just saved them from ever having to cook real food. Meanwhile, a chorus of dietary dreamers mulls the possibility that this beleaguered plant patty purveyor might just sprout wings of financial salvation, despite the market tossing their bonds into the bargain bin like last season's soybeans. \ud83c\udf31\ud83d\udcb8"
  },
  {
    "title": "Local LLMs versus offline Wikipedia (evanhahn.com)",
    "points": 160,
    "submitter": "EvanHahn",
    "submit_time": "2025-07-19T16:49:02 1752943742",
    "num_comments": 77,
    "comments_url": "https://news.ycombinator.com/item?id=44617078",
    "comments": [
      "One important distinction is that the strength of LLMs isn't just in storing or retrieving knowledge like Wikipedia, it\u2019s in comprehension.LLMs will return faulty or imprecise information at times, but what they can do is understand vague or poorly formed questions and help guide a user toward an answer. They can explain complex ideas in simpler terms, adapt responses based on the user's level of understanding, and connect dots across disciplines.In a \"rebooting society\" scenario, that kind of interactive comprehension could be more valuable. You wouldn\u2019t just have a frozen snapshot of knowledge, you\u2019d have a tool that can help people use it, even if they\u2019re starting with limited background.reply",
      "An unreliable computer treated as a god by a pre-information-age society sounds like a Star Trek episode.reply",
      "Definitely sounds like a plausible and fun episode.On the other hand, real history if filled with all sorts of things being treated as a god that were much worse than \"unreliable computer\". For example, a lot of times it's just a human with malice.So how bad could it really getreply",
      "\"as bad as it can get\" is somewhere in the realm of universal paperclipsreply",
      "> So how bad could it really getI don't know.  How about we ask some of the peoples who have been destroyed on the word of a single infallible malicious leader.Oh wait, we can't.  They're dead.Any other questions?reply",
      "Remember the first time you touched a computer, the first game you ever played or the first little script you wrote that did something useful.I imagine this is how a lot of people feel when using LLM's especially now that it's new.It is the most incredible technology ever created by this point in our history imo and the cynicism on HN is astounding to me.reply",
      "You might want to read about a technology called \"farming\".   Pretty sure as far as transformative incredible technologies, the ability for humans to create nourishment at global scale blows the pants off the text / image imitation machinereply",
      "I've seen that plot used. In the Schlock Mercenary universe, it's even a standard policy to leave intelligent AI advisors on underdeveloped planets to raise the tech level and fast-track them to space. The particular one they used wound up being thrown into a volcano and its power source caused a massive eruption.reply",
      "hey generally everything worked pretty good in those societies, it was only people who didn't fit in who had a brief painful headache and then died!reply",
      "Or the plot to 2001 if you managed to stay awake long enough.reply"
    ],
    "link": "https://evanhahn.com/local-llms-versus-offline-wikipedia/",
    "first_paragraph": "Two days ago, MIT Technology review published \u201cHow to run an LLM on your laptop\u201d. It opens with an anecdote about using offline LLMs in an apocalypse scenario. \u201c\u2018It\u2019s like having a weird, condensed, faulty version of Wikipedia, so I can help reboot society with the help of my little USB stick,\u2019 [Simon Willison] says.\u201dThis made me wonder: how do the sizes of local LLMs compare to the size of offline Wikipedia downloads?I compared some models from the Ollama library to various downloads on Kiwix. I chose models that could be run on some consumer-grade hardware, and Wikipedia bundles that didn\u2019t have images for a better comparison. Here\u2019s what I found, ordered by size:This comparison has many caveats:This is an apples-to-oranges comparison. Encyclopedias and LLMs have different purposes, strengths, and weaknesses. They are fundamentally different technologies!File size is not the only important detail. LLMs, even local ones, can use lots of memory and processor power. Offline Wikipedia wi",
    "summary": "Title: Apocalyptic USB Sticks and Byte-Sized Brainsplosions\n\nIn a daring leap of utilitarian science, a blog oddly juxtaposes the massiveness of offline Wikipedia downloads against local LLMs, thrilling scores of readers with a comparison as fruitful as comparing apples to USB sticks. The writer, struck by a post-apocalyptic muse, envisions a world where a USB-stick LLM can reboot civilization, apparently confusing a basic Q&A bot with a swiss-army knife for societal resurrection. Commenters leap into the fray, debating the omniscience of their new tin gods with the fervor of philosophers discovering caffeine for the first time. One festive soul suggests checking with obliterated civilizations for their insights, but alas, they're unavailable for comment\u2014something about being dead. Every keystroke in the comments weaves a rich tapestry of faith in USB salvation, nostalgia for first code compilations, and bitter reminders that agriculture, not digital mimicry, remains humanity\u2019s crowning tech achievement."
  },
  {
    "title": "Nobody knows how to build with AI yet (worksonmymachine.substack.com)",
    "points": 222,
    "submitter": "Stwerner",
    "submit_time": "2025-07-19T15:45:01 1752939901",
    "num_comments": 193,
    "comments_url": "https://news.ycombinator.com/item?id=44616479",
    "comments": [
      "This article is spot on.I had stumbled upon Kidlin\u2019s Law\u2014\u201cIf you can write down the problem clearly, you\u2019re halfway to solving it\u201d.This is a powerful guiding principle in today\u2019s AI-driven world. As natural language becomes our primary interface with technology, clearly articulating challenges not only enhances our communication but also maximizes the potential of AI.The async approach to coding has been most fascinating, too.I will add, I've been using Repl.it *a lot*, and it takes everything to another level. Getting to focus on problem solving, and less futzing with hosting (granted it is easy in the early journey of a product) - is an absolute game changer. Sparking joy.I personally use the analogy of mario kart mushroom or star; that's how I feel using these tools. It's funny though, because when it goes off the rails, it really goes off the rails lol. It's also sometimes necessary to intercept decisions it will take.. babysitting can take a toll (because of the speed of execution). Having to deal with 1 stack was something.. now we're dealing with potential infinite stacks.reply",
      "The challenge is that clearly stating things is and always has been the hard part. It\u2019s awesome that we have tools which can translate clear natural language instructions into code but even if we get AGI you\u2019ll still have to do that. Maybe you can save some time in the process by not having to fight with code as much but you\u2019re still going to have to create really clear specs which, again, is the hard part.reply",
      "Repl.it is so hit or miss for me, and that's that is so frustrating. Like, it can knock out something in minutes that would have taken me an afternoon. That's amazing.Then other times, I go to create something that is suggested _by them below the prompt box_ and it can't do it properly.reply",
      "The fact that you think it was suggested _by_ them is I think where your mental model is misleading you.LLMs can be thought of metaphorically as a process of decompression, if you can give it a compressed form for your scenario 1 it'll go great - you're actually doing a lot of mental work to arrive at that 'compressed' request, checking technical feasibility, thinking about interactions, hinting at solutions.If you feed it back it's own suggestion it's no so guaranteed to work.reply",
      "I'm loving the new programming. I don't know where it goes either, but I like it for now.I'm actually producing code right this moment, where I would normally just relax and do something else. Instead, I'm relaxing and coding.It's great for a senior guy who has been in the business for a long time. Most of my edits nowadays are tedious. If I look at the code and decide I used the wrong pattern originally, I have to change a bunch of things to test my new idea. I can skim my code and see a bunch of things that would normally take me ages to fiddle. The fiddling is frustrating, because I feel like I know what the end result should be, but there's some minor BS in the way, which takes a few minutes each time. It used to take a whole stackoverflow search + think, recently it became a copilot hint, and now... Claude simply does it.For instance, I wrote a mock stock exchange. It's the kind of thing you always want to have, but because the pressure is on to connect to the actual exchange, it is often a leftover task that nobody has done. Now, Claude has done it while I've been reading HN.Now that I have that, I can implement a strategy against it. This is super tedious. I know how it works, but when I implement it, it takes me a lot of time that isn't really fulfilling. Stuff like making a typo, or forgetting to add the dependency. Not big brain stuff, but it takes time.Now I know what you're all thinking. How does it not end up with spaghetti all over the place? Well. I actually do critique the changes. I actually do have discussions with Claude about what to do. The benefit here is he's a dev who knows where all the relevant code is. If I ask him whether there's a lock in a bad place, he finds it super fast. I guess you need experience, but I can smell when he's gone off track.So for me, career-wise, it has come at the exact right time. A few years after I reached a level where the little things were getting tedious, a time when all the architectural elements had come together and been investigated manually.What junior devs will do, I'm not so sure. They somehow have to jump to the top of the mountain, but the stairs are gone.reply",
      "It is known team size and speed are not linear.Many times adding a new junior to a team makes it slower.How does using llms as junior makes you more productive?reply",
      "> What junior devs will do, I'm not so sure. They somehow have to jump to the top of the mountain, but the stairs are gone.Exactly my thinking, nearly 50, more than 30 years of experience in early every kind of programming, like you do, I can easily architect/control/adjust the agent to help me produce great code with a very robust architecture. By I do that out of my experience, both in modelling (science) and programming, I wonder how the junior devs will be able to build experience if everything comes cooked by the agent. Time will tell us.reply",
      "I feel like we've been here before, and there was a time when if you're going to be an engineer, you needed to know core equations, take a lot of derivatives, perform mathematical analysis on paper, get results in an understandable form, and come up with solutions. That process may be analogous to what we used to think of as beginning with core data structures and algorithms, design patterns, architecture and infrastructure patterns, and analyzing them all together to create something nice. Yet today, much of the lower-level mathematics that were previously required no longer are. And although people are trained in their availability and where they are used, they form the backbone of systems that automate the vast majority of the engineering process.It might be as simple as creating awareness about how everything works underneath and creating graduates that understand how these things should work in a similar vein.reply",
      "Exactly right now, I am helping a big oil and gas company have a process simulation software to correctly converge on a big simulation. Full access to the source code, need to improve the Newton method in use with the right line search, validate the derivatives, etc.I do think that for most of the people, you are right, you do not need to know a lot, but my philosophy was to always understand how the tool you use work (one level deeper), but now the tool is creating a new tool. How do you understand the tool which has been created by your Agent/AI tool?I find this problem interesting, this is new to me and I will happily look at how our society and the engineering community evolve with these new capacities.reply",
      "I also am enjoying LLMs, but I get no joy out of just prompting them again and again. I get so incredibly bored, with a little side of anxiety that I don\u2019t really know how my program works.I\u2019ll probably get over it, but I\u2019ve been realizing how much fun I get out building something as opposed to just having be built. I used to think all I cared about was results, and now I know that\u2019s not true, so that\u2019s fun!Of course for the monotonous stuff that I\u2019ve done before or don\u2019t care a lick about, hell yeah I let em run wild. Boilerplate, crud, shell scripts, CSS. Had claude make me a terminal based version of snake. So sickreply"
    ],
    "link": "https://worksonmymachine.substack.com/p/nobody-knows-how-to-build-with-ai",
    "first_paragraph": "",
    "summary": "On the cutting-edge digital frontiers of worksonmymachine.substack.com, a prophetic enlightenment descends announcing that nobody quite grasps the building blocks of AI. Our internet sages in the comments section have stumbled upon the revolutionary concept of Kidlin's Law, turning it into a quasi-religious mantra for the age of automation. Meanwhile, tales of AI coding miracles are shared alongside grievances of babysitting runaway code\u2014the drama of modern programming, now dressed in AI finery. Who needs clear specifications and foundational understanding when you can have instant gratification with Repl.it and shoot metaphorical mushrooms in Mario Kart-inspired coding sessions? The only thing more inconsistent than the AI outputs are the commenters' understanding of their own tools. Behold, the future of coding: a mix of overhyped expectations and under-delivered results. \ud83d\ude80\ud83d\ude43"
  },
  {
    "title": "Ring introducing new feature to allow police to live-stream access to cameras (eff.org)",
    "points": 119,
    "submitter": "xoa",
    "submit_time": "2025-07-19T22:25:09 1752963909",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=44620002",
    "comments": [
      "Let me guess \"opt-in\" means checked by default and hidden 12 menus deep.Or worse-yet, opt-in means \"Hey our rates are going up, but not if you agree to this\" (something comcast did recently).Or opt-in is stored in some database somewhere and might \"accidentally be misread\" due to a \"bug\".If they want real-opt-in then it should be a SMS message at the time they want to know, and a phone-number you can reach out to for more information. This would give an audit trail at the very least.reply",
      "The feature exist and that guarantees the law enforcement will abuse this sooner or later. Opt-in doesn\u2019t mean anything.You have to be total naive if you still believe that this is a \u201csafe\u201d feature to enable.reply",
      "Yes, this is my take as well, and I think it's the correct one from both a technical and legal POV. It's one thing for the government to try to compel an organization or person to create a feature they want from scratch. They have made noises in that direction in the past (like the FBI vs Apple trying to invoke the All Writs Act) but it's been on very shaky ground, on both 1st and 13th Amendment grounds as well as others. But the government can be a lot more aggressive and courts a lot more permissive when it comes to merely making use of functionality that already exists. Even putting aside all the massive numbers of perverse incentives, but the thing is of course those shouldn't be put aside, we've seen this movie before over and over and over again. Once a feature exists that can generate a lot of direct revenue for a company and the only thing that keeps them from turning the knob up is \"we're totally not evil cross our hearts!\". Like holy shit, in 2025 who really goes \"oh well it's opt-in!\"I think this particular one is pretty important to know about because a lot of people deploy Ring stuff almost by default, and some HNers (including me as it happens) have some level of influence or even control over it. I always meant to put some effort into updating my self-hosted security system efforts but this is a major kick in the butt. Have to know this exists and be able to offer solid credible alternatives.Edit: to add a direct pertinent example, WE LITERALLY JUST HAD 5 DAYS AGO ON HN A 500+ COMMENT HUGE THREAD ON \"Oakland cops gave ICE license plate data; SFPD also illegally shared with feds\" [0]. And there are people really claiming \"nothing to see here, move along, local and feds would totally never conspire to abuse anything in violation of the law let alone not in violation of the law\"!?----0: https://news.ycombinator.com/item?id=44561716reply",
      "I am less worried about local law enforcement. They will have little ability to strong arm Amazon and have oversight and regulation, as well as judicial review, even if it\u2019s not always effective it\u2019s always there.DHS has become lawless, and they are eager to strong arm and over reach after having dismantled their own oversight and ignoring their own regulations. They are working hard to move fast and break the law faster than the law can keep up and the Supreme Court has made it very difficult to seek remedy.  Because they are not doing criminal justice but instead civil administrative enforcement the web of oversight and review and stronger civil rights for criminal justice don\u2019t apply. They have become the largest police force, militarized, and with enormous budget, latitude, and blank check support from the highest levels of political government.They absolutely can strong arm Amazon into doing what they want, and absolutely will use Ring camera against their owners and neighbors.In six months we created a secret police rivaling the KGB, gestapo, State Security Police, and SSD.reply",
      "You have to be totally naive to buy a Ring camera in the first place. Of course it will be used in ways you can't control, it uploads everything to \"the cloud\".reply",
      "I\u2019d be interested to know if anyone has a moderate cost system that doesn\u2019t force you to use a company\u2019s cloud (and thus making them prone to abuse like this).  I personally have a POE setup with some commercial grade cameras ($400 a pop), with attached NAS on a private network, and home-rolled a means to access the cameras remotely, but it\u2019s not exactly economical or practicalreply",
      "I'm full Unifi.  With all of Ubiquiti's faults considered.  I still feel 10000000x better about it than Ring.reply",
      "Trying to find an affordable camera / baby monitor that was both secure and offline was a tough one for me, it seems every single consumer oriented camera has a remote access functionality (= a backdoor) nowadays, and the baby monitors that don\u2019t use wifi are only secure through obscurity with some of them being as easy to hack as buying the same model.I ended up with an Amcrest IP2M-841 and Tinycam on Android (as I understand using RTSP), and blocking internet access of the camera through the router. As I found out, just connecting it to the internet will automatically connect to servers for allowing \u201ceasy setup\u201d of the remote access feature.reply",
      "I use a local NVR containing a couple of hard drives totalling maybe 8TB of storage attached to  same-branded cameras (ranging between $80 and $150 each) that I can access locally, and remotely via Wireguard.I'd say it's economical in comparison to cloud options, but, yes, not all that practical to the less technical crowd.I specifically block the camera and NVR local IP addresses from accessing the internet. I don't really want the possibility of an private company accessing live (or recorded) video of where I live.Brand is Reolink. I've been slowly building up the system over five-ish years and have not yet found any reason to kick myself for choosing that brand. I also have some TP-Link Tapo cameras for more temporary things, like monitoring pets.I've also setup Frigate as an alternative system, both for my own interest and as a way to aggregate different camera brands to a single interface. Frigate can be a bit complex.reply",
      "Is there anything that runs for a decent amount of time, wifi and essentially all-wireless? Blink somewhat works on its own local hub, but honestly its crap for detecting when things happen so I wont be upgrading from my used 2-pack + hub even though it does integrate well with HA.I'd really like something that'd be apartment friendly so no drilling holes.reply"
    ],
    "link": "https://www.eff.org/deeplinks/2025/07/amazon-ring-cashes-techno-authoritarianism-and-mass-surveillance",
    "first_paragraph": "Ring founder Jamie Siminoff is back at the helm of the surveillance doorbell company, and with him is the surveillance-first-privacy-last approach that made Ring one of the most maligned tech devices. Not only is the company reintroducing new versions of old features which would allow police to request footage directly from Ring users, it is also introducing a new feature that would allow police to request live-stream access to people\u2019s home security devices.\u00a0This is a bad, bad step for Ring and the broader public.\u00a0Ring is rolling back many of the reforms it\u2019s made in the last few years by easing police access to footage from millions of homes in the United States. This is a grave threat to civil liberties in the United States. After all, police have used Ring footage to spy on protestors, and obtained footage without a warrant or consent of the user. It is easy to imagine that law enforcement officials will use their renewed access to Ring information to find people who have had abort",
    "summary": "In a stunning return to the \"watch everyone, all the time\" philosophy, Ring reallocates the creepy guy peering over the fence into digital form, allowing police with two brain cells to click \"request access\" and get a live feed into users' homes. Internet commenters, tapping furiously on their ethical keyboards, lament the impending demise of privacy and spin delightful tales of techno-dystopia where not even your cat is safe from Big Brother's pry\u2014makes you wonder if opting into a dystopian future is just another checkbox on the internet's endless screed of EULAs. Meanwhile, tech-savvy warriors suggest building a fortress of solitary tech solutions that neither spy nor betray because, of course, designing a home surveillance system from scratch is just a casual weekend DIY for the average Joe. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83c\udfa5\u2728"
  },
  {
    "title": "OpenAI claims gold-medal performance at IMO 2025 (twitter.com/alexwei_)",
    "points": 401,
    "submitter": "Davidzheng",
    "submit_time": "2025-07-19T09:11:19 1752916279",
    "num_comments": 624,
    "comments_url": "https://news.ycombinator.com/item?id=44613840",
    "comments": [
      "Terence Tao on the matter - https://imgur.com/a/terence-tao-on-supposed-gold-imo-sMKP0bmreply",
      "From Noam Brownhttps://x.com/polynoamial/status/1946478258968531288\"When you work at a frontier lab, you usually know where frontier capabilities are months before anyone else. But this result is brand new, using recently developed techniques. It was a surprise even to many researchers at OpenAI. Today, everyone gets to see where the frontier is.\"and\"This was a small team effort led by \n@alexwei_\n. He took a research idea few believed in and used it to achieve a result fewer thought possible. This also wouldn\u2019t be possible without years of research+engineering from many at \n@OpenAI\n and the wider AI community.\"reply",
      "That brand new technique? Training on the test data. /sreply",
      "Interesting that the proofs seem to use a limited vocabulary: https://github.com/aw31/openai-imo-2025-proofs/blob/main/pro...Why waste time say lot word when few word do trick :)Also worth pointing out that Alex Wei is himself a gold medalist at IOI.reply",
      "Interesting observation. One one hand, these resemble more the notes that an actual participant would write while solving the problem. Also, less words = less noise, more focus. But also, specifically for LLMs that output one token at a time and have a limited token context, I wonder if limiting itself to semantically meaningful tokens can be create longer stretches of semantically coherent thought?reply",
      "The original thread mentions \u201ctest-time compute scaling\u201d so they had some architecture generating a lot of candidate ideas to evaluate. Minimizing tokens can be very meaningful from a scalability perspective alone!reply",
      "This is just speculation but I wouldn't be surprised if there were some symbolic AI 'tricks'/tools (and/or modern AI trained to imitiate symbolic AI)  under the hood.reply",
      "He is talking about IMO (math olympiad) while he got gold at IOI (informatics olympiad) :)reply",
      "> Also worth pointing out that Alex Wei is himself a gold medalist at IOI.Terence Tao also called it, that the top LLMs would get gold this year in a recent podcast.reply",
      "In transformers generating each token takes the same amount of time, regardless of how much meaning it carries. By cutting out the filler from the text, you get a huge speedup.reply"
    ],
    "link": "https://twitter.com/alexwei_/status/1946477742855532918",
    "first_paragraph": "",
    "summary": "**OpenAI harnesses the power of cheating to win IMO 2025**  \nIn a shocking reveal, OpenAI announces that its latest AI model has won a gold at the International Mathematical Olympiad. Can you believe it? Neither could the programmers, who apparently discovered frontier science by accident while googling how to overfit a model. Meanwhile, back at base, the online commentators are too busy cracking jokes about AI's \"efficient\" use of language and Alex Wei's gold at the wrong Olympiad, to notice the subtle art of making it all *work* by simply using every test example as a training exercise. Truly, innovation looks a lot like magic, especially when it involves pulling answers straight out of the training set. \ud83c\udfc5\ud83e\udd16\ud83d\udcbe"
  },
  {
    "title": "I Used Arch, BTW: macOS, Day 1 (yberreby.com)",
    "points": 9,
    "submitter": "yberreby",
    "submit_time": "2025-07-19T23:58:18 1752969498",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44620623",
    "comments": [
      "> Homebrew's filesystem permission handling is controversial, to say the least, and it has a tendency to fail at a package manager's main job: ensuring that new dependencies don't break the system.Homebrew user from day 1 it appeared. I have many many packages installed on multiple actively used systems and I have never had to deal with any kind of breakage.What is this myth? Yeah yeah I am just one data point ...reply",
      "Interesting that you had such a smooth experience. I was mainly using Homebrew on the daily between 10 and 14 years ago, so I couldn't give you specifics. My experience at the time was poor; maybe I was using it wrong. My impression from looking at recent user reports was that Homebrew's stability has continued to lag behind pacman's, but I agree that my assertion in the latter part of the excerpt you quoted was insufficiently substantiated, so I'll remove it.reply",
      "I also had a bad time with brew back then. On new machines these days no issues at all.reply",
      "Every time I need to update anything on brew, I end up updating thousands of packages and it goes on and on for a long time.reply",
      "Nix is downright awful on MacOS, even with the DetSys installer. Almost worse than Homebrew.If you ever sit down to play with a native NixOS install, the difference in functionality is night-and-day.reply",
      "Care to elaborate on what you've found most painful? Since `nix-darwin` is anything but officially supported, I am expecting trouble, but it would be nice to know if there are specific things I should look out for.I'd love to use NixOS itself, of course, but it's not a native option on this machine due to the missing M4 support in Asahi. For now, I'm trying to see how much package/configuration management discipline I can reclaim on macOS, and familiarize myself with Nix in the process.I could have just used a set of Ansible scripts and Homebrew, but that didn't seem quite as interesting as trying Nix out.reply"
    ],
    "link": "https://yberreby.com/posts/i-used-arch-btw-macos-day-1/",
    "first_paragraph": "TL;DR:\nI used Arch Linux for nine years as a daily driver on non-Apple laptops.\nI received my new M4 Pro MacBook Pro yesterday.\nThis recounts my experience configuring it to hit the ground running from day 1.If you're a Linux user making the switch to Apple Silicon, or thinking of doing so, this post may be of interest.Zed, AeroSpace, Raycast's \"Switch Windows\" and Alacritty in action.The way one uses their computer is shaped by their needs, values, and habits.As of writing, I am midway through my PhD at McGill University and Mila, focusing on neuro-AI research at McGill's Department of Physiology.\nMy background is in computer engineering.My workflow as a PhD student involves a mix of:Depending on the needs of the hour, I'll put on my researcher, engineer, sysadmin, or communicator hat, and I need my computing environment to support this workflow.I didn't start out on Linux.\nI digitally grew up on System 7, Mac OS 9, then Mac OS X, in an Apple-centric household where \"Windows\" was a pr",
    "summary": "**Title: I Used Arch, BTW: macOS, Day 1 (yberreby.com)**\n\nIn a heroic tale of survival, a long-time Arch Linux aficionado bravely transitions to an M4 Pro MacBook Pro, determined to not let go of their superior Linux user roots. Amidst an ocean of \"I've never had this issue\" and \"works on my machine\" arguments in defiance of Homebrew\u2019s capriciousness, our intrepid protagonist daily battles with file permissions like it's 1999. Commenters nostalgically recall their *own* never-ending battles with Homebrew updates, ensuring the thread is as much about outdoing each other's misery as it is about troubleshooting. Meanwhile, a handful zealously preach the gospel of NixOS, determined to convert the macOS heathens, because why solve problems when you can just switch them? \ud83d\ude31\ud83d\udcbb\ud83c\udf7a"
  },
  {
    "title": "Mushroom learns to crawl after being given robot body (2024) (the-independent.com)",
    "points": 53,
    "submitter": "Anon84",
    "submit_time": "2025-07-17T10:43:05 1752748985",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44591775",
    "comments": [
      "Reminds me of:https://www.syfy.com/syfy-wire/fish-control-vehicles-and-nav...reply",
      "Rats too!! :)https://www.youtube.com/watch?v=mYHMc3-f3v8reply",
      "What could possibly go wrong?reply",
      "See also: https://news.cornell.edu/stories/2024/08/biohybrid-robots-co...reply"
    ],
    "link": "https://www.the-independent.com/tech/robot-mushroom-biohybrid-robotics-cornell-b2610411.html",
    "first_paragraph": "",
    "summary": "In an era where technological innovation is clearly pacing several laps behind common sense, The Independent reveals a groundbreaking study where scientists have overcome significant moral and practical barriers to strap a mushroom to a set of wheels, ostensibly so it can \"crawl.\" This newest circus act in the tech world is heroically intended to pave the way towards biohybrid robots, because nothing says \"future\" like flora on a Roomba. Commenters, in a delightful showcase of missing the point, chime in with links to other \"innovations\" where animals drive things, blissfully ignoring the dystopian sense that perhaps the next step could involve their potted ficus driving them to work. Strap in\u2014or should we say strap on?\u2014the botanical uprising begins with battery-powered portabellas. \ud83c\udf44+\ud83e\udd16=\ud83d\ude80"
  },
  {
    "title": "Rethinking CLI interfaces for AI (notcheckmark.com)",
    "points": 131,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-19T16:58:42 1752944322",
    "num_comments": 65,
    "comments_url": "https://news.ycombinator.com/item?id=44617184",
    "comments": [
      "Throwing this out there, I have a command line driver for LLMs. Lots of little tricks in there to adapt the CLI to make it amiable for LLMs. Like interrupting a long running process periodically and asking the LLM if it wants to kill it or continue waiting. Also allowing the LLM to use and understand apps that use the alternate screen buffer (to some degree).Overall I try to keep it as thin a wrapper as I can. The better the model, the less wrapper is needed. It's a good way to measure model competence.  The code is here https://github.com/swax/NAISYS and context logs here for examples - https://test.naisys.org/logs/I have agents built with it that do research on the web for content, run python scripts, update the database, maintain a website, etc.. all running through the CLI, if it calls APIs then it does it with curl. Example agent instructions here: https://github.com/swax/NAISYS/tree/main/agents/scdb/subagen...reply",
      "> It's a good way to measure model competence.Can you elaborate?reply",
      "The one thing that I always wonder is how varied are those interactions with an agent. My workflow is is enough of a routine that I just write scripts and create functions and aliases to improve ergonomics. Anything that have to do with interacting with the computer can be automated.reply",
      "Yea a lot of this is experimental, I basically have plain text instructions per agent all talking to each other, coordinating and running an entire pipeline to do what would typically be hard coded. There\u2019s definite pros and cons, a lot of unpredictability of course, but also resilience and flexibility in the ways they can work around unexpected errors.reply",
      "Or you can give your AI agent access to your terminal. I've been using https://github.com/hiraishikentaro/wezterm-mcp/ with gemini-cli and it generally allows it to use the terminal like I would, so stuff like scrolling inside interactive TUIs etc more-or-less just works.reply",
      "Appreciate the share!I might give access to a terminal in a locked down VM, I don't know about a shell.reply",
      "At least give it its own login (and no sudo privileges).reply",
      "Agree 100% that CLI interface design needs to be altered to include AI Agents as a new type of user persona, but I don't think it's as drastic of a change as one might expect.We designed Desktop GUI & Web Browsers on top of the terminal to allow a type of user to interact without speaking \"lower level\" commands, but we've also created abstractions to hide complexity for ourselves at this layer.  We just so happen to call them CLI Apps, Scripts, Makefile targets, Taskfile tasks, Justfile recipes, unix tools, etc.  It consists of a pseudo-natural language short-code name combined with schema-validated options and some context around what each option does (via the --help view).  The trick is how do we optimize for both human developers and AI Agents to have access to the same tools but in the optimized interface for each.In an experiment to let my agents share the exact same 'tools' that I do for developing in a repository, I gave it direct access to load and self-modify the local project Justfile via MCP: https://github.com/toolprint/just-mcpJust as (pun intended) I create tools for myself to repeat common tasks with sane defaults and some parameters, my agents immediately gain the same access and I can restrict permissions to use these instead of ANY bash command (IE: \"Bash(just:*)\").  The agent can also assist in creating tools for me or itself to use that would save on time and token usage.  I'd love to see the paradigm evolve to the point it feels more like warp.dev where you don't have to switch between two text boxes to choose whether you're talking in natural language or instructing to run a known 'tool'.reply",
      "Interfaces and tools are orthogonal. It's like a hammer. The head is what is used on the nail. While the handle is shaped to fit the human hand. We can modify one without modifying the other. Another good example is Magit (or Lazygit) and git. Magit is designed to be used interactively, while is more about the domain of version control.Workflows are humans processes, what we do is naming them and identify their parameters. The actual tools to implement those workflows don't matters that much at a human scale other than cognitive load. So I don't care much about gcc various options. What I want is `make debug` or `make release` (or just `make`).  And cognitive load is lowered because I only have these to remember and they are deterministic.Agent is not a good bridge between humans and tools. Because they increase cognitive load, while all the interface have been about lowering it. There's no \"make test\" and have a nice output of all the lines that have been flagged (and have some integration like Vim's quickfix which can quickly bring you to each line). Instead it's typing a lot and praying that it actually do something good.reply",
      "I don't think I disagree with you here, but I'm not sure I fully understand your position.I agree that if the human is \"driving\", they should be able to use the Tool directly (IE: make test).  If you put an agent in the middle and ask it \"please run make test\" that's just silly and costs extra for no benefit.Where you get benefit is if you design tools like \"just test\" as an MCP tool called \"mcp__just-mcp__test\" and give a fully-autonomous agent instructions like: \"Whenever you feel like you've completed a task, run mcp__just-mcp__test and fix errors and warnings until it passes, then you may commit changes locally\".  LLM's have 'congitive load' as well, so why not offload the deterministic logic to Tools in the same way we do?reply"
    ],
    "link": "https://www.notcheckmark.com/2025/07/rethinking-cli-interfaces-for-ai/",
    "first_paragraph": "We need to augment our command line tools and design APIs so they can be better used by LLM Agents.\u00a0The designs are inadequate for LLMs as they are now \u2013  especially if you're constrained by the tiny context windows available with local models.Like many developers, I\u2019ve been dipping my toes into LLM agents. I\u2019ve done my fair share of vibe coding, but also I\u2019ve been playing around with using LLMs to automate reverse engineering tasks mostly using mrexodia\u2019s IDA Pro MCP, including extending it.Developing an MCP interface is an interesting process. You need to walk the line between providing too much information to avoid filling the context windows but also providing enough information to reduce tool calls. We have a few APIs that are better than others, like get_global_variable_at, which takes an address, identifies the type, and returns the best string representation of that value based on that type. However, the function can fail, so we provide a second set of accessor methods (data_re",
    "summary": "In a valiant attempt to reinvigorate the dusty corners of CLI interfaces, notcheckmark.com plunges headfirst into the arcane art of optimizing shell environments for the digital demiurge: LLM agents. Because only developers would find the romance in making bash scripts sentient. Our intrepid author equates trial-and-error coding with groundbreaking AI experimentation, presumably mistaking random API calls for the digital equivalent of alchemy. The comment section, a delightful echo chamber of misplaced optimism, bubbles with suggestions ranging from giving AI its own terminal (because that's safe) to waxing poetic about how \"interface and tools are orthogonal,\" as if invoking the spirit of Archimedes will help their scripts run faster. If only AI could automate away the cognitive dissonance as well. \ud83d\ude44"
  },
  {
    "title": "Death by AI (davebarry.substack.com)",
    "points": 167,
    "submitter": "ano-ther",
    "submit_time": "2025-07-19T14:35:11 1752935711",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44615801",
    "comments": [
      "A popular local spot has a summary on google maps that says:Vibrant watering hole with drinks & po' boys, as well as a jukebox, pool & electronic darts.It doesn't serve po' boys, have a jukebox (though the playlists are impeccable), have pool, or have electronic darts. (It also doesn't really have drinks in the way this implies. It's got beer and a few canned options. No cocktails or mixed drinks.)They got a catty one-star review a month ago for having a misleading description by someone who really wanted to play pool or darts.I'm sure the owner reported it. I reported it. I imagine other visitors have as well. At least a month on, it's still there.reply",
      "I really wish Google had some kind of global \u201cI don\u2019t want any identifiably AI-generated content hitting my retinas, ever\u201d checkbox.Too much to ask, surely.reply",
      "You hear a faint whisper from the alleyway: you should try Kagi.I know it's the HN darling and is probably talked about too much already but it doesn't have this problem. The only AI stuff is if you specifically ask for it which in your case would be never. And unlike Google where you are at the whims of the algorithm you can punish (or just block) AI garbage sites that SEO their way into the organic results. And a global toggle to block AI images.reply",
      "Can one sue for damages? Is it worth getting delisted?reply",
      "I had a similar experience with meta\u2019s AI. Through their WhatsApp interface I tried for about an hour to get a picture generated. It kept stating everything I asked for correctly but then it never arrived at the picture, actually stayed far from what I asked for and at best getting 70%. This and many other interactions with many LLMs made me realize one thing - once the llm starts hallucinating it\u2019s really tough to steer it away from it. There is no fixing it.I don\u2019t know if this is a fundamental problem with the llm architecture or a problem with proper prompts.reply",
      "I'd say this isn't just an AI overview thing. It's a Google thing. Google will sometimes show inaccurate information and there is usually no way to correct it. Various \"feedback\" forms are mostly ignored.I had to fight a similar battle with Google Maps, which most people believe to be a source of truth, and it took years until incorrect information was changed. I'm not even sure if it was because of all the feedback I provided.I see Google as a firehose of information that they spit at me (\"feed\"), they are too big to be concerned about any inconsistencies, as these don't hurt their business model.reply",
      "No, this is very much an AI overview thing. In the beginning Google put the most likely-to-match-your-query result at the top, and you could click the link to see whether it answered your question.Now, frequently, the AI summaries are on top. The AI summary LLM is clearly a very fast, very dumb LLM that\u2019s cheap enough to run on webpage text for every search result.That was a product decision, and a very bad one. Currently a search for \"Suicide Squad\" yields> The phrase \"suide side squad\" appears to be a misspelling of \"Suicide Squad\"reply",
      "> It's a Google thing. Google will sometimes show inaccurate information and there is usually no way to correct it.Surely there is a way to correct it: getting the issue on the front page of HN.reply",
      "Well it was accurate if you were asking about the Dave Barry in Dorchester.reply",
      "He won a Pulitzer too? Small world.reply"
    ],
    "link": "https://davebarry.substack.com/p/death-by-ai",
    "first_paragraph": "",
    "summary": "Title: **AI Tries to Murder Local Watering Hole with Incorrect Metadata**\n\nIn a world where artificial intelligence can neither drink beer nor throw darts, the untamed wilderness of Google Maps becomes a battleground over an inaccurate venue description. Commenters, armed with the intense responsibility of correcting the internet, debate whether sue-worthy AI-generated content, or the relentless incompetence of Google's information geyser, is to blame. Somewhere, a lone hero suggests toggling off the AI apocalypse via a yet undiscovered \"global checkbox,\" while others reminisce fondly over the days when wrong venue details were just an amusing anecdote, not a skirmish in the war against machine learning's reign of terror. AI, bless its digital heart, decides to contributed to the discourse by hallucinating wildly and inappropriate ad placements. \ud83e\udd16\ud83d\udc94\ud83c\udfaf\ud83c\udf7a"
  },
  {
    "title": "What Were the Earliest Laws Like? (worldhistory.substack.com)",
    "points": 31,
    "submitter": "crescit_eundo",
    "submit_time": "2025-07-15T23:55:55 1752623755",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44577210",
    "comments": [
      "I really like that story!I appreciate it being shared.I had no idea about this chap.reply",
      "TLDR: earlier than Hammurabi's eye-for-an-eye justice was Urukagina, who presented himself as a savior for the people, including getting them out of debt and protecting them from corrupt officials.  (But OP is most excellent and worth reading.)It reminded me of Solon's changes in Athens, to broker some fairness, wipe prior debts and outlaw debtor's prisons, require military service (paid for the lower classes), and of course opening decisions beyond to hereditary aristocrats (land owners) to those with wealth (traders). In both cases, leaders seemed to be responding to stasis borne of economic oppression.However, ideology is not evidence of justice; both Putin and Xi present themselves as champions of the people against the corrupt bureaucracy (and discipline their governments via discretionary application of high standards).But the brutality of eye-for-an-eye might obscure the point: Hammurabi seems to be distinct in not associating power with the person, but establishing settled expectations so people could sort out their differences directly (freeing the leader from the no-win situation of judging disputes).  That makes it easier for the laws to continue largely the same, regardless of the style of government (much as we in the US and EU still apply English and Roman law).It's a shame our sampling of ancient governance is limited to stone and clay tablets from the middle east.  There's evidence of other societies of a similar sophistication but without the hierarchical dependence on gods and beer.reply",
      "One thing I\u2019ve heard historians mention, that is like to know more about, is that these law stelae, while impressive, aren\u2019t actually referenced in legal cases during their time.  So they\u2019re the laws as written, not actually the laws as practiced.reply",
      "I think I read that these might even just be proposals or a statement of ideals, especially in Hammurabi's case.reply"
    ],
    "link": "https://worldhistory.substack.com/p/what-were-the-earliest-laws-really",
    "first_paragraph": "",
    "summary": "**What Were the Earliest Laws Like?**\n\n<i>The armchair historians of worldhistory.substack.com are at it again, dazzling us with titbits from ancient legislators who apparently scribbled their moral musings onto stone like it was going out of fashion. Excitement fills the comment section as someone discovers <b>Urukagina</b> is more than just a fun name to say aloud. Another genius enlightens us about Solon's debt-cancellation spree, making everyone briefly consider time travel to ancient Athens for some financial relief. Meanwhile, a skeptic reminds us those stone tablets were probably just for show, like a politician\u2019s campaign promises.</i>"
  },
  {
    "title": "Babies made using three people's DNA are born free of mitochondrial disease (bbc.com)",
    "points": 248,
    "submitter": "1659447091",
    "submit_time": "2025-07-16T21:43:35 1752702215",
    "num_comments": 149,
    "comments_url": "https://news.ycombinator.com/item?id=44587116",
    "comments": [
      "My son Oliver was born with mitochondrial disease and was killed by conditions associated with it at the age of 19. Some of the people mentioned in the report here were involved in his diagnosis and care.His life deteriorated from that of a normal, fun loving intelligent kid to an isolated bed-bound disabled teenager, fed by total parenteral nutrition and suffering a variety of awful complications. His eventual passing was cruel and brutal. I'm not sure we will ever get over it as a family.This treatment does now at least offer me a glimmer of grandchildren (my daughter having decided she would not risk children of her own until now). It's a remarkable achievement.reply",
      "I'm very sorry that happened to your son, and that you and your family had to endure it.reply",
      "Wanted to share same sentiment. Thanks to gp for sharing.reply",
      "As a parent of teenagers it pained my heart to even read this. I cannot fathom what it is like to endure it and live with it after the fact. I am very sorry for what you experienced and what Oliver experienced.reply",
      "I think it would be better to describe this as an \u2018organelle\u2019 transplant as it would be easier for people to understand and discuss. Yes there is a donor (egg) and yes the new child will pass on the mitochondria to her children. But calling it a 3 person baby is unhelpful and misleading as IMO mitochondria DNA is of a different category to chromosomal DNA.reply",
      "It's inheritable so it's more than a liver transplant.I agree that DNA in mitochondria is much smaller than DNA in the nucleus. But in each person there are many mitochondria and they nay have slightly different DNA. And the DNA in mitochondria has a different variation than the DNA in the nucleus. So it's difficult to weight both.Can we say 2.1 parents? A long time ago I read that most binary classifications are not completely binaries, it's just that 2 options cover almost all the cases. (Are virus alive?) I guess integer classifications also have hidden corner cases.I also remember from a biology book that in a lab they mixed two blastula(?) of small lizards(?) or something like that. They had different skin color and the baby had patches of both colors. Does that count as 2 or 4 parents?reply",
      "Certainly Mother Nature is not obliged to have simple easy to understand binaries where it would be convenient for us and so if we think we see such a binary we should keep in mind that maybe we hallucinated it into existence because it was convenient and that's all.reply",
      "I agree wholeheartedly.  This strikes me as the way science works.  Theories are useful because of their predictive value.  If we think of biological sciences as different than physical or mathematical, it seems we have set ourselves up for failure.  Yet that seems like exactly the kind of perspective missing and trying to be pointed out by the earlier comment's attempted splitting of the difference to \"2.1 parents\" to me.reply",
      "While it is a different category that chromosomal DNA, it is still an essential part of mammalian life. None of use would exist in our current forms without mitochondriareply",
      "As I understand it, a human egg has about an equal quantity of nuclear and mitochondrial DNA.  The mitochondrial DNA is highly replicated, though (about 100,000 mitochondria, each with ~16600 base pairs of DNA).reply"
    ],
    "link": "https://www.bbc.com/news/articles/cn8179z199vo",
    "first_paragraph": "Eight babies have been born in the UK using genetic material from three people to prevent devastating and often fatal conditions, doctors say.The method, pioneered by UK scientists, combines the egg and sperm from a mum and dad with a second egg from a donor woman.The technique has been legal here for a decade but we now have the first proof it is leading to children born free of incurable mitochondrial disease.These conditions are normally passed from mother to child, starving the body of energy.This can cause severe disability and some babies die within days of being born. Couples know they are at risk if previous children, family members or the mother has been affected.Children born through the three-person technique inherit most of their DNA, their genetic blueprint, from their parents, but also get a tiny amount, about 0.1%, from the second woman. This is a change that is passed down the generations.None of the families who have been through the process are speaking publicly to pr",
    "summary": "Title: Brave New Parents: The Rise of 2.1 Kids and Internet Biologists\n\nIn a stunning leap for biology that *definitely* won't inspire the plot of the next dystopian sci-fi flick, the UK births its first brood of \"three-person\" babies, free from mitochondrial doom. Pioneered by scientists and backed by a pinch of extra DNA, these kids owe about 0.1% of their genetic mojo to a benevolent, mitochondrial fairy godmother. Cue internet experts who argue whether to label this an \u201corganelle transplant\u201d or clap along to the rhythm of science fiction becoming reality. Meanwhile, comment sections spiral into chaotic dives into biology, with armchair geneticists debating whether we should start rating parental contribution like Uber rides. \ud83e\uddec\ud83d\udc76\ud83d\ude96"
  },
  {
    "title": "The borrowchecker is what I like the least about Rust (viralinstruction.com)",
    "points": 148,
    "submitter": "jakobnissen",
    "submit_time": "2025-07-19T19:27:50 1752953270",
    "num_comments": 197,
    "comments_url": "https://news.ycombinator.com/item?id=44618535",
    "comments": [
      "I don't use Rust much, but I agree with the thrust of the article. However, I do think that the borrowchecker is the only reason Rust actually caught on. In my opinion, it's really hard for a new language to succeed unless you can point to something and say \"You literally can't do this in your language\"Without something like that, I think it just would have been impossible for Rust to gain enough momentum, and also attract the sort of people that made its culture what it is.Otherwise, IMO Rust would have ended up just like D, a language that few people have ever used, but most people who have heard of it will say \"apparently it's a better safer C++, but I'm not going to switch because I can technically do all that stuff in C++\"reply",
      "Agreed. As a comparison Golang was sold as \"CSP like Erlang without the weird syntax\" but people realized channels kind of suck and goroutines are not really a lot better than threads in other languages. The actual core of OTP was the supervisor tree but that's too complicated so Golang is basically just more concise Java.I don't think this is a bad thing but it's a funny consequence that to become mainstream you have to (1) announce a cool new feature that isn't in other languages (2) eventually accept the feature is actually pretty niche and your average developer won't get it (3) sand off the weird features to make another \"C but slightly better/different\"reply",
      "Due to lack of many abstractions, and lack of exceptions, Go is a less concise Java. It's a language where the lack of expressiveness forces you to write simpler code. (Not that it helps too much.)Go's selling points are different: it takes a weekend to learn, and a week to become productive, it has a well-stocked standard library, it compiles quickly, runs quickly enough, and produces a single self-contained executable.I would say that Go is mostly a better Modula-2 (with bits of Oberon); it's only better from the language standpoint because now it has type parameters, but GC definitely helps make writing it simpler.reply",
      "I can't substantiate your claim about Erlang or weird syntax, is that either a proper quote or some kind of paraphrasing because nothing remotely close to it comes up.There are numerous interviews with Rob Pike about the design of Go from when Go was still being developed, and Erlang doesn't come up in anything that I can find other than this interview from 2010 where someone asks Rob Pike a question involving Erlang and Rob replies by saying he thinks the two languages have a different approach to are fairly different:https://www.youtube.com/watch?v=3DtUzH3zoFoIt's at the 32 minute mark, but once again this is in response to someone asking a question.Here are other interviews about Go, and once again in almost every interview I'd say Rob kind of insinuates he was motivated by a dislike of using C++ within Google to write highly parallel services, but not once is Erlang ever mentioned:https://www.informit.com/articles/article.aspx?p=1623555https://www.infoq.com/interviews/pike-google-gohttps://go.dev/blog/waza-talkreply",
      "> Golang is basically just more concise Java.That is exactly how it was sold.A safe C, or a nicer simpler Java.Nobody cared about Erlang back then and nobody does today.I write Erlang for a living.reply",
      "I remember very well one of the first public presentations about Go. It focused heavily on goroutines and channels and included a live demonstration of pushing an element through one million channels. It also included a demo of spinning up three racing queries to the Google search engine using the select statement, and picking whoever returned first. it was all about the new cool feature. They also had TCP-over-channels and eventually had to remove that because the model didn\u2019t fit.Nobody may have known they cared about Erlang, but those features sure made people pay attention.reply",
      "I was an early Golang dev and people were _crazy_ with channels for a couple years. I remember the most popular Golang Kafka client was absolute spaghetti of channels and routines.It's never been \"safe C\" because it's garbage collected. Java is truly the comp because it's a great Grug language.I also wrote some Erlang in the past, I really enjoy it and I was sad that Go didn't borrow more.reply",
      "Writing Elixir for a living is seemingly a growing trend.reply",
      "In the case of golang, all you need is hordes of lousy programmers that can't understand anything serious.reply",
      "I think that's harsh. IME Go excels in a business setting where the focus is on correct, performant, maintainable, business logic in larger organizations, that's easy to integrate with a bunch of other systems. You can't squeeze every last bit of low-level performance out of it but you can get ... 9x% of the way there with concurrent code that is easy to reason about.reply"
    ],
    "link": "https://viralinstruction.com/posts/borrowchecker/",
    "first_paragraph": "Written 2025-07-18Among the 2010's cohort of programming languages, Rust is probably the most widely lauded.The main selling point of Rust is that it manages to combine speed and low-level control with a high level of bug-resistance, more commonly referred to as safety. The main innovation of Rust - really, its claim to fame - is its borrowchecker: the part of its compiler that enforces Rust's ownership rules and thereby allows Rust to achieve all the memory safety that garbage collected language enjoy, but with zero runtime cost.  The evangelists proponents of Rust have made memory safety the central selling point of Rust, to the extent that the borrowchecker has become the defining feature of Rust's identity. I think the conflation of Rust's safety with the borrowchecker's guarantees is somewhat misguided. In this post, I want to make two arguments:That the borrowchecker causes serious ergonomic problems for Rust.That the role of the borrowchecker in Rust's safety is overstated.In a ",
    "summary": "Title: <em>\"My Daddy Doesn't Understand How Pointers Work!\"</em> \u2013 A Rusty Tale by an Angst-Ridden Programmer\n\nIn a heartfelt monologue of despair, a solitary Rustacean bemoans the horrors of the borrowchecker: the Big Bad Wolf of the Rust programming ecosystem. As this tragic modern Shakespeare screams into the void, the Rust evangelist choir sings hymns of \"memory safety\" and \"zero-cost abstractions.\" Commenters, masquerading as wise sages, regurgitate buzzwords and nostalgia for the D language graveyard\u2014each trying to outsmart the other by comparing Rust to every programming language except maybe COBOL. Meanwhile, team members are lost in anecdotes about Golang channels, while a bewildered intern wonders if he accidentally stumbled into a support group for disillusioned coders."
  },
  {
    "title": "The curious case of the Unix workstation layout (thejpster.org.uk)",
    "points": 66,
    "submitter": "ingve",
    "submit_time": "2025-07-19T16:15:17 1752941717",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44616760",
    "comments": [
      "This is a fun, and I enjoyed the \"CRT Dude\" video because I resonate with that need to understand :-). One of the things I learned during that era was that there were a lot of computer makers but relatively few factories in China that were making things to assemble them. Because it was simpler to take the sheet metal work that was already designed and being made for brand 'x' and then differentiate on the case molding and electronics, a lot of the mechanical components were \"re-used\" (the factory can make 1000 or 10,000 with the tooling and the more they make the easier to amortize the tooling costs so the cheaper they can offer them).I suspect when a company spec'd out a new design and then got all the tooling done, unless they explicit language in their contract about selling stuff made with the same tooling to others, the factories could pitch \"we will do the basic case with no NRE[1]\" and that was a bargain. As a result a lot of things ended up being \"magically\" similar in those days.[1] NRE = Non-Recoverable Engineering which is the cost label for the engineering work to build the jigs and tooling that the factory will use to make the parts you want. Example an injected molded switch cover might cost $10,000 in NRE to make the molds that can produce 10 switch covers each and be used up to a 10,000 times. Then if you make 10,000 switch covers, you have used the mold one 1000 times and used up 10% of its lifetime. Cost of the plastic plus $1,000 (the 1/10th of the cost of the mold) are the real cost of those switch covers.reply",
      "These days the majority of computers are designed and manufactured by a small number of OEMs too.reply",
      "> Early Alphastations were VME based machines.No, they most emphatically were not.   The early 3000 series, like the MIPS based DECstation and VAX based VAXstation, were based on Turbochannel[1], which was DEC's primary bus technology at the time.  Later Alphas used PCI as their primary bus.  There were Tubochannel to VME adapters, and PCI to VME adapters, but VME was never a primary bus used in alpha.1: https://en.wikipedia.org/wiki/TURBOchannelreply",
      "Im just going to make sure at least one post here mentions S-100 bushttps://en.wikipedia.org/wiki/Altair_8800https://en.wikipedia.org/wiki/Vector_Graphichttps://en.wikipedia.org/wiki/North_Star_Horizonhttps://en.wikipedia.org/wiki/IMSAI_8080Thanks for coming to my ted talkreply",
      "I remember it roughly like this:Before the PC era computers were mostly integrated in the keyboard (many 8-bit home computers), the monitor (Apple Lisa) or both (Commodore PET).Then they became more or less flat boxes on the desktop. Early PC's were like that (the bulky version) but also early workstations like Sun's SPARCstation (the more elegant version). They were meant to put a monitor atop.Over time the boxes got bigger and louder and the monitors got bigger which made this design impractical. Some people flipped the boxes, put them under their table and the tower was born. Not long and professionally made tower  cases appeared.Over time the bulky towers got smaller and we had Midi- and Mini-Towers on the PC side and things like the Sun Ultra 24 or the SGI O2 on the workstation side. These could be put on the table again but this time next to the monitor and not below it.reply",
      "SGI Indigos (not Indigo^2) were SGI's own GIO32 bus, not VME.Early Alphastations were assuredly not VME! They were DEC's own Turbochannel.reply",
      "...and Turbochannel was originally the bus for the MIPS R3000-based Ultrix workstations; the Alpha firmware needed to be able to interpret MIPS machine code to speak to TC expansion cards.Somewhere, I have a Turbochannel FDDI card taken from an AlphaStation 3000-an obsolete I/O adapter for a forgotten network protocol, running on a defunct CPU, with firmware written in the native language of an even more defunct CPU.reply",
      "It makes sense, if one considers them the evolution of the Apple II and the IBM PC.The IBM had the motherboard on the left, along with the expansion cards, and the drives and power supply on the right. The AT continued this.Clones wanted mostly compatible cases, and motherboards wanted to be mostly compatible with IBM cases and clone cases.Then we had Amigas like the Amiga 3000, which had a similar layout but a riser to take horizontal expansion cards.While some more bespoke PCs had vertical risers, most PC cases in the early to mid '90s were large. It was the machines we paid a bit more for that made being smaller in to something a bit premium.While taking apart my Amiga 3000 is a bit of work, the design is absolutely wonderful, and more than once I thought about the design of it compared with later machines like the Sun Ultra 5, the Motorola StarMax (PowerPC Mac clone) and others.reply",
      "The early 90s were the era of (1) Pentium (2) PCI (3) multiplatform Windows NT. Most vendors switched to desktop/deskside designs based on PC bus and PC components, it would be more cost competitive (volume economics) and could run NT/Alpha, NT/MIPS, NT/PowerPC if the market went that way.reply",
      "Hmm...makes me wonder if a PA-RISC HP 9000 712  is a better NeXTStation than a NeXTStation is today, in terms of longevity, supportability, performance, etc.I guess its missing the DSP and fancy printer interface of the NS, maybe the overall sound quality.reply"
    ],
    "link": "https://thejpster.org.uk/blog/blog-2025-07-19/",
    "first_paragraph": "Posted on 2025-07-19Cathode Ray Dude recently did an excellent video about the history of the PC case, particularly the early- and mid-1990s, and the various mainboard layouts that pre-date the ATX standard. You should watch it. Here it is.The rest of this blog will contain some spoilers for that video.I have a bunch of 1990's RISC/UNIX workstations. I don't really know how it happened, but I went from having literally none back in October 2024, to having:I also briefly had an Alphastation 500, but I failed to get it working so I passed it on to someone who knows much more about them than me.And watching CRD's video. I realised something.The Silicon Graphics IRIS Indigo is a tower workstation of the old-school. A light make-over of the previous IRIS 4D series, it has two huge PCBs, which insert vertical into a backplane using rotating clips. I'm pretty sure it's actually a VME bus design, both because of that Wikipedia page but because SGI Depot describes them as part of the \"IRIS VME ",
    "summary": "Welcome to yet another nostalgia-infused techno-rant at *thejpster.org.uk*, where we dive into the mid-1990s like it's the goldmine of cultural inheritance. Today's treat is a long-winded homage to obsolete UNIX workstations, sparked by a video from the revered Cathode Ray Dude. The blogger's sudden and inexplicable accumulation of vintage tech junk \u2013 because let's face it, that's what it is \u2013 serves as a springboard for musings that nobody asked for on old-school hardware architecture. Commenters chime in with their desperate attempts to showcase niche knowledge, fiercely competing over who remembers the most about forgotten bus technologies like it's some sort of geek street cred. Truly, a spectacular parade of the outdated and the outmoded. \ud83d\udd79\ufe0f\ud83d\udcbe"
  },
  {
    "title": "Trigon: Exploiting coprocessors for fun and for profit (part 2) (alfiecg.uk)",
    "points": 28,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-19T20:15:26 1752956126",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://alfiecg.uk/2025/07/16/Trigon.html",
    "first_paragraph": "\nJul 16, 2025\n      A few months ago, I released a kernel exploit called Trigon. It was significant in that it was deterministic - that is, it cannot fail. However, at the time of release, only A10 devices on iOS 13 - 15 were supported. Since then, support has been implemented for A9(X) and A11 devices. In this blog post, I am going to dive into what it took to support these new devices - I made use of some pretty interesting techniques, which I believe are worthy of a second part to the original writeup.If you haven\u2019t read the first part of this blog post, you can do so here, and you can find the source code here. This one is a little more technical in my opinion, but as always, I will happily answer questions via Twitter or email.For starters, let\u2019s remind ourselves how the original release of Trigon\u2019s exploit strategy worked. First, it would find the mapping base via the iboot-handoff region. It would then use this to map the KTRR limit registers and find the kernel base by scanning",
    "summary": "**Trigon: Exploiting coprocessors for fun and for profit (part 2) (alfiecg.uk)**\n\nIn the latest episode of \"How to Brag About Hacking Your Toaster,\u201d a self-proclaimed tech wizard regurgitates more of his hackery conquests. This time, he\u2019s outdone himself by making his 'foolproof' exploit, originally tailored for your aging iPhone, now compatible with even older tech relics! Readers are treated to a cryptic saga of \"interesting techniques,\" which is code for \"don't try this at home unless you're also a fan of voiding warranties and embracing possible device bricking.\u201d Meanwhile, the comment section becomes a battleground for armchair critics who believe watching <i>Mr. Robot</i> qualifies as a cybersecurity degree. \ud83e\udd13\ud83d\udcbb\ud83d\udd25"
  },
  {
    "title": "TSMC to start building four new plants with 1.4nm technology (taipeitimes.com)",
    "points": 123,
    "submitter": "giuliomagnifico",
    "submit_time": "2025-07-19T19:52:30 1752954750",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=44618762",
    "comments": [
      "More information on the new node:> TSMC's A14 is brand-new process technology that is based on the company's 2nd Generation GAAFET nanosheet transistors and new standard cell architecture to enable performance, power, and scaling advantages. TSMC expects its A14 to deliver a 10% to 15% performance improvement at the same power and complexity, a 25% to 30% lower power consumption at the same frequency as well as transistor count, and 20% - 23% higher transistor density (for mixed chip design and logic, respectively), compared to N2. Since A14 is an all-new node, it will require new IPs, optimizations, and EDA software than N2P (which leverages N2 IP) as well as A16, which is N2P with backside power delivery.https://www.tomshardware.com/tech-industry/tsmc-unveils-1-4n...reply",
      "Kind of sad what's happened to US semiconductor manufacturing. Speaking from an American perspective, of course.reply",
      "The US is trying to get fabrication out of Taiwan so that it doesn\u2019t need to defend Taiwan from China.If you were Taiwanese this would worry you?It makes complete sense for Taiwan to invest in maintaining it\u2019s \u201csilicon shield\u201d even as china tries to catch up with fabrication on the mainland.reply",
      "We\u2019re assuming that the \u201csilicon shield\u201d is even a thing anymore.China can comfortably make chips that might be the equivalent of 5 year old Taiwanese ones. Last time I checked, that\u2019s extremely viable.No military general ever is going to say, \u201cwe can\u2019t invade, we\u2019re half a decade behind!\u201dreply",
      "Isn\u2019t the point that other countries would have to think twice before letting China get their hands on Taiwan? The advantage to China would be immense if they secured Taiwan.reply",
      "I wouldn't say comfortably - they're brute forcing it by using UV sources suitable for much older nodes.End result requires more energy, has lower yield and is overall more expensive.For military purposes and whatnot that's enough, but they can't put this in consumer devices without subsidies.reply",
      "This is true but it has been fascinating seeing them trying to catch up. Necessity being mother of invention, all of that.It is still hard to get much of a clear picture on how well they are doing on this stuff. Chinese companies are saying they are near parity, the opposition says they are 15 years behind, the reality is probably somewhere in between.While they have made a lot of quick progress, that is no guarantee for future gains.reply",
      "They have a cost advantage. Kinda fine for where I'm standing; if we want to have more investment, we must liberalize migration! If we don't liberalize migration, necessarily the capital-labor ratio will be more capital-scarce in other countries.reply",
      "I blame the American corporate meme. American corporations are hideously slow, lumbering and quite honestly many are just \"too big to fail\" prop ups at this point. Long gone are actual qualified individuals running even semiconductor manufacturers and its just bean counters and country club nephews.reply",
      "anddd, just like any other Western Europesn country Americans need to be paid (semi-) living wagesreply"
    ],
    "link": "https://www.taipeitimes.com/News/front/archives/2025/07/20/2003840583",
    "first_paragraph": "Taiwan Semiconductor Manufacturing Co (TSMC, \u53f0\u7a4d\u96fb) plans to begin construction of four new plants later this year, with the aim to officially launch production of 2-nanometer semiconductor wafers by late 2028, Central Taiwan Science Park Bureau director-general Hsu Maw-shin (\u8a31\u8302\u65b0) said.Hsu made the announcement at an event on Friday evening celebrating the Central Taiwan Science Park\u2019s 22nd anniversary.The second phase of the park\u2019s expansion would commence with the initial construction of water detention ponds and other structures aimed at soil and water conservation, Hsu said.Photo: courtesy of the Central Taiwan Science Park  Administration OfficeTSMC has officially leased the land, with the Central Taiwan Science Park having handed over the plot last month, he added.Hsu said he is optimistic that the park\u2019s annual turnover would surpass NT$1.2 trillion (US$40.81 billion), setting a new historic high.At the North America Technology Symposium in California on April 25, TSMC revealed pl",
    "summary": "**TSMC Prepares to Break Ground on New Nano-farms, Exciting Dozens**\n\nIn a grand demonstration of technological overachievement, TSMC announces it's building four spanking new factories to pop out 2-nanometer wafers by the yawn-inducing future of 2028. \ud83e\udd73 The director-general of the Central Taiwan Science Park, speaking at what must have been the party of the century for semiconductor enthusiasts, managed to also discuss ponds. Yes, <em>water detention ponds</em>. Because when you're pushing the boundaries of silicon technology, first you need to sort out where to put excess rainwater. The internet commentariat, fortified by their deep understanding of geopolitical tensions and semiconductor manufacturing, weighed in with hot takes ranging from mournful cries for American manufacturing to armchair analyses of Chinese military strategy. A festival of misinformed optimism and misplaced priorities, if ever there was one."
  },
  {
    "title": "Zig Interface Revisited (williamw520.github.io)",
    "points": 78,
    "submitter": "ww520",
    "submit_time": "2025-07-16T16:52:11 1752684731",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=44584414",
    "comments": [
      "Would it truly kill Zig to add native interface support ? All that ceremony is quite heavy and also somewhat error prone.If nothing else, maybe they can add some helpers in the standard lib or codegen in the standard tooling to make stuff like this easier ? So one need not manually code all the function pointer types for methods and the dispatch in the interface type .Yes, Zig is meant to be a low-level programming language, but stuff like this is basic table stakes nowadays. People will just make custom code generators after Zig 1.0 to do this exact thing - and they will likely be dozens of such custom code generators with subtle differences.reply",
      "There's just one feature Zig lacks, which would have allowed for full automation of interface definitions. In Zig you can programmatically construct data types with compile-time programming, but such types aren't allowed to have methods: https://github.com/ziglang/zig/issues/6709This is an intentional limitation, because the language creator worries the feature would be abused.reply",
      "I strongly dislike \"this feature could be abused, so we won't add it\" as reasoning for language design decisions. It just doesn't sit right with me. I think designing to avoid \"misuse\" (i.e. accidentally shooting yourself in the foot) is great, but avoiding \"abuse\" just reads as imposing your taste onto all users of your language. I don't like this, so nobody should be able to do it.But oh well, if you're using Zig (or any other language using auteur-driven development like Odin or Jai or C3) you've already signed up for only getting the features that the benevolent dictator thinks are useful. You take the good (tightly designed with no feature bloat) and the bad (\"I consider this decision unlikely to be reversed\").reply",
      "I wonder if it's possible to not lock themselves into an ABI with a built in vtable implementation? I kinda get where they're coming from: let vtables be a user problem; but, yeah, modern compilers can do magic when they \"know\" the rules for built in vtables. It kinda feels like they're leaving a real performance opportunity on the ground?reply",
      "Agreed that native interface support is table stakes for any language now. It would avoid so much boilerplate - nevermind the time wasted examining the code to see what kind of ad-hoc interface any given piece of code is using - and how to retrieve the ridiculous zig vtable data member for each pseudo class instance. It just amounts to useless noise in the code, rather than succinctly stating the intent.reply",
      "> nevermind the time wasted examining the code to see what kind of ad-hoc interface any given piece of code is usingthis is not really a problem I've encountered.  did you have a specific case where you got puzzled?reply",
      "In every different zig project you have to read the source code to see how their specific ad-hoc interface scheme works. Case in point - this article uses a method `pub fn implBy(impl_obj: anytype)` to connect instances to a vtable. The new zig writer uses a `.interface` data member scheme: https://www.openmymind.net/Zigs-New-Writer/ in addition to understanding when and when not to use it.reply",
      "> somewhat error pronedo you have any evidence for this?  what is the error you're proposing here?reply",
      "Agreed, this puts me off using Zig. I can\u2019t endure this level of boilerplate any longer.reply",
      "This is like the inverse of the normal C++ vtable. Normally the whole point of having a separate vtable (as opposed to just a bunch of function pointers directly in the struct) is so that you can share a single one between all instances, at the cost of one extra indirection. But here a copy of the vtable is instead attached to one individual instance, and yet it still does this one extra indirection to get to the implementation object.reply"
    ],
    "link": "https://williamw520.github.io/2025/07/13/zig-interface-revisited.html",
    "first_paragraph": "\nJul 13, 2025\n      \n      \u2022 William WongAchieving polymorphism via dynamic dispatch in ZigUnlike many languages that offer interface or virtual constructs, \nZig has no built-in notion of interfaces. This reflects Zig\u2019s commitment \nto simplicity and performance. That doesn\u2019t mean polymorphism is off the table.\nIn fact Zig has the tools to build interface-like behavior, making dynamic dispatch possible.Let\u2019s backtrack a bit. There are ways to achieve polymorphism in Zig, depending on the use case:A common motivation for interfaces is to allow uniform typing, e.g. storing multiple \nimplementations in an array or map. Both tagged unions and vtable-based interfaces support this.In this post we\u2019ll focus on vtable interfaces.While I was doing the ZigJR project, I had the need\nfor using interfaces to plug in different implementations.\nThere had been a number of approaches developed over time to make vtable interface possible in Zig. \nAfter a deep dive into the language, I have settled on one ",
    "summary": "**Zig Interface Revisited: A Maverick Approach to Confusion**\n\nIn a stunning display of reinventing the wheel, William Wong treats us to another exhilarating round of \"Why use existing language features when you can *build your own*?\" With Zig's staunch refusal to embrace built-in interfaces, enthusiasts rush to implement vtable gymnastics that could rival Olympic routines. Meanwhile, the comment section transforms into a battleground where seasoned coders sob over the lack of standardization, while others tout the masochistic virtues of endless boilerplate as if it were a feature, not a bug. Zig's commitment to \"simplicity\" clearly doesn't extend to its user's mental well-being. \ud83e\udd2f\ud83c\udfaa"
  },
  {
    "title": "MCP Security Vulnerabilities and Attack Vectors (forgecode.dev)",
    "points": 148,
    "submitter": "tested1",
    "submit_time": "2025-07-19T18:14:19 1752948859",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44617910",
    "comments": [
      "Same root causes again - check out https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/reply",
      "The \"lethal trifecta\" refers to default configurations, excessive permissions, and inadequate authentication - three factors that plague MCP implementations just as they did with earlier technologies.reply",
      "This can be easily used to search for seeds/private keys when AI coding agents are in YOLO mode.reply",
      "MCP clearly needs an independent monitoring program to safeguard it. Let's call it Tron.reply",
      "Truly, S in MCP stands for Security!reply",
      "And P in WFH stands for productive.reply",
      "The S in SFTP?The S in SSH?The S in HTTPS?The S in MCP?All stand for the same thing!I remember when this joke was first applied to IoT.reply",
      "I do love the joke, but it is worth remembering as well that all of those S were to a certain extent afterthoughts to fix otherwise insecure protocols.Given how old FTP and HTTP are it's fairly understandable that they weren't initially designed with security in mind, but I think it's valid to question why we're still designing insecure systems in 2025.reply",
      "Totally agree, If we have made a mistakes in past we must have learnt from it and when designing a standard specially with AI where the outcome is non deterministic we got be more careful.reply",
      "MCP new spec has to an extent covered auth. But the MCPs are yet to adopt to that.reply"
    ],
    "link": "https://forgecode.dev/blog/prevent-attacks-on-mcp/",
    "first_paragraph": "Been digging into Model Context Protocol implementations lately and found some stuff that's keeping me up at night. Not because it's earth-shattering, but because it's the kind of boring security debt that bites you when you least expect it.This is Part 1 of a two-part series. Read Part 2: Actually Fixing This Mess \u2192MCP is Anthropic's attempt at standardizing how AI models talk to external tools1. Instead of every AI app rolling their own integration layer, you get a common protocol. Think of it like REST for AI tools, except with way less thought put into security.The spec is pretty straightforward - JSON-RPC over stdio or HTTP. AI asks for available tools, gets back a list with descriptions, then calls them with parameters. Simple enough that you can implement a basic server in an afternoon.Which is exactly the problem.Here's where things get interesting. MCP servers describe their tools using natural language descriptions that the AI reads to understand what each tool does. Sounds r",
    "summary": "In a groundbreaking exercise of redundancy, <i>forgecode.dev</i> graces us with the latest snooze-fest titled \"MCP Security Vulnerabilities and Attack Vectors,\" because apparently, 2025 still hasn't had enough of the same old tales of tech insecurity. The article delivers an accidental parody of every security write-up ever, promising nightmares but just mildly disturbing afternoon naps. Over in the comment section, the all-stars of redundancy choir endlessly harmonize on the 'lethal trifecta' of security mishaps. It's like witnessing a deja vu inside a deja vu wrapped in a trivial complaint, garnished with misplaced surprise that Security in MCP might stand for <em>Shush, Compromises Pending</em>. \ud83d\ude44\ud83d\udd12"
  }
]