[
  {
    "title": "Kawaii \u2013 A Keychain-Sized Nintendo Wii (bitbuilt.net)",
    "points": 379,
    "submitter": "realslimjd",
    "submit_time": "2024-07-22T19:12:22",
    "num_comments": 119,
    "comments_url": "https://news.ycombinator.com/item?id=41038552",
    "comments": [
      "The \"Thundervolt\" reference in that post is a project where they cut up a Wii PCB to leave just the DRAM and the processors on the PCB, and then they slap an external DCDC board on top of that cut up PCB to provide power to it, while also undervolting it since you reduce the IR losses.https://bitbuilt.net/forums/index.php?threads/thundervolt.62...That is pretty insane.\n \nreply",
      "Here's some more info on the motherboard and what can be trimmed off and/or replaced: https://bitbuilt.net/forums/index.php?threads/wii-motherboar...\n \nreply",
      "IR losses? Never heard that one\n \nreply",
      "I believe he means I\u00b2R losses in resistive elements\n \nreply",
      "Using Nintendo\u2019s branding in the box seems ill-advised. That\u2019s giving Nintendo more fodder for the eventual lawsuit.\n \nreply",
      "It might not work without the Nintendo logo.\n \nreply",
      "very funny :)\n \nreply",
      "Lawsuit to what? Their CAD files, the build instructions? The board shipped with the Nintendo Wii?\n \nreply",
      "Using the word \"nintendo\" on something intended to play any kind of games is trademark infringement.  The Kawaii devs likely don't intend to confuse people, but if a consumer saw this product for sale they'd rightly assume it's a Nintendo product.Using a brand name like this just makes things easier when Nintendo attorneys barely have to roll out of bed when sending a cease and desist order.Just call it Kawaii and stay slightly under the radar.  Sadly, Nintendo will probably come for you anyways.\n \nreply",
      "Some of these console mods only really get sold as kits or products on places like Aliexpress.Needless to say, they are pretty safe from Nintendo.  If these guys aren't selling the schematics, and posting them for free, Nintendo has a lot less of a leg to stand on.\n \nreply"
    ],
    "link": "https://bitbuilt.net/forums/index.php?threads/kawaii.6474/",
    "first_paragraph": "",
    "summary": "In the latest attempt to avoid actually buying their own console, a plucky gang of hardware hackers on bitbuilt.net have devised \"Kawaii,\" a Nintendo Wii shrunken down to the size of a keychain, assuming your keychain is primarily constructed from discarded electronics and unrealistic ambitions. This pint-sized Frankenstein's monster is powered by something called \"Thundervolt,\" which seems to be just a fancy word for chopping up a Wii like a bad cooking show contestant and hoping it still works when stapled back together. Commenters are oscillating between armchair lawyering over potential Nintendo lawsuits and giving each other high-fives in a digital echo chamber that redefines 'tech support'. Suggestions that the Nintendo brand name could be *problematic* are met with the kind of dismissive snark that only true keyboard warriors can muster, proving that no one really reads the manual, or the law."
  },
  {
    "title": "Timeshift: System Restore Tool for Linux (github.com/linuxmint)",
    "points": 89,
    "submitter": "gballan",
    "submit_time": "2024-07-22T21:23:02",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=41039967",
    "comments": [
      "I've probably spent way too much time thinking about Linux backup over the years. But thankfully, I found a setup that works really well for me in 2018 or so, used it for the last few years, and I wrote up a detailed blog post about it just a month ago:https://amontalenti.com/2024/06/19/backups-restic-rcloneThe tools I use on Linux for backup are restic + rclone, storing my restic repo on a speedy USB3 SSD. For offsite, I use rclone to incrementally upload the entire restic repository to Backblaze B2.The net effect: I have something akin to Time Machine (macOS) or Arq (macOS + Windows), but on my Linux laptop, without needing to use ZFS or btrfs everywhere.Using restic + some shell scripting, I get full support for de-duplicated, encrypted, snapshot-based backups across all my \"simpler\" source filesystems. Namely: across ext4, exFAT, and (occasionally) FAT32, which is where my data is usually stored. And pushing the whole restic repo offsite to cloud storage via rclone + Backblaze completes the \"3-2-1\" setup straightforwardly.\n \nreply",
      "One question, why use rclone for the Backblaze B2 part? I use restic as well, configured with autorestic. One command backs up to the local SSD, local NAS, and B2.\n \nreply",
      "I explain in the post. Here's a copypasta of the relevant paragraph:\"My reasoning for splitting these two processes \u2014 restic backup and rclone sync \u2014 is that I run the local restic backup procedure more frequently than my offsite rclone sync cloud upload. So I\u2019m OK with them being separate processes, and, what\u2019s more, rclone offers a different set of handy options for either optimizing (or intentionally throttling) the cloud-based uploads to Backblaze B2.\"\n \nreply",
      "I adore Timeshift. It has made my time on Linux so much more trouble free.I have used Linux for 10+ years but over the I have spent hours, days and weeks trying to undo or fix little issues I introduce by tinkering around with things. Often I seem to break things at the worst times, right as I am starting to work on some new project or something that is time sensitive.Now, I can just roll back to an earlier stable version if I don't want to spend the time right then on troubleshooting.I've enabled this on all my family members machines and teach them to just roll back when Linux goes funky.\n \nreply",
      "I prefer using openSUSE, which is tightly integrated with snapper[0], making it simple to recover from a botched update. I've only ever had to use it when an update broke my graphics drivers, but when you need it, it's invaluable.Snapper on openSUSE is integrated with both zypper (package manager) and YaST (system configuration tool) [1], so you get automatic snapshots before and after destructive actions. Also, openSUSE defaults to btrfs, so the snapshots are filesystem-native.[0]: http://snapper.io/[1]: https://en.opensuse.org/Portal:Snapper\n \nreply",
      "And it's also integrated into the bootloader (if you use one of the supported ones). The bootloader shows you one boot entry per snapshot so you can boot an old snapshot directly.\n \nreply",
      "Very nice, sometimes people claim that the only difference between distros is the repository and package management tools.It is when the defaults make the parts integrate nicely like this that the \u201cgreater is more than the sum of its parts\u201d come into place.\n \nreply",
      "This is a feature I've really been missing since switching from grub to systemd-boot.Has anyone figured out an easy way to get this back with systemd-boot?\n \nreply",
      "Some time ago they did add systemd-boot as a supported option and supposedly it also contains one entry per snapshot. I haven't tried it though so I don't know for sure.https://en.opensuse.org/Systemd-boot#Installation_with_full_...(I also switched to a custom systemd-boot setup before they added it, and my setup uses UKIs with Secure Boot while theirs doesn't so I don't care to switch to theirs.)",
      "This reminds me of the default behavior of NixOS. Whenever you make a change in the configuration for NixOS and rebuild it, it takes a snapshot of the system configurations and lets you restore after a reboot if you screw something up.Similarly, it doesn't do anything in regards to user files.\n \nreply"
    ],
    "link": "https://github.com/linuxmint/timeshift",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        System restore tool for Linux. Creates filesystem snapshots using rsync+hardlinks, or BTRFS snapshots. Supports scheduled snapshots, multiple backup levels, and exclude filters. Snapshots can be restored while system is running or from Live CD/USB.\n      Timeshift for Linux is an application that provides functionality similar to the System Restore feature in Windows and the Time Machine tool in Mac OS. Timeshift protects your system by taking incremental snapshots of the file system at regular intervals. These snapshots can be restored at a later date to undo all changes to the system.In RSYNC mode, snapshots are taken using rsync and hard-links. Common files are shared between snapshots which saves disk space. Each snapshot is a full system backup that can be browsed with a file manager.In BTRFS mode, snapshots are taken using the",
    "summary": "**Hacker's Time Machine Finally Buffs Linux**\nAh, the holy grail of Linux users who can't quite leave their Windows safety blanket behind: Timeshift! \ud83c\udf89 Complete with rsync wizardry and BTRFS snapshots, this is perfect for those rare disastrous moments you realize that \u201crm -rf\u201d in your terminal wasn't referencing your homework folder. The eager commentariats bathe in the nostalgia of Windows System Restore, debate their big-brain backup setups that no one had the tenacity to question, and wax poetic about the good old days before they had to Google \"how to fix GRUB for the tenth time.\" Truly, a contemporary shield against the thrilling dangers of Linux tinkering \ud83d\ude08. Timeshift: because pressing \"Ctrl+Z\" in real life shouldn\u2019t only be a fantasy."
  },
  {
    "title": "Copying is the way design works (matthewstrom.com)",
    "points": 269,
    "submitter": "innerzeal",
    "submit_time": "2024-07-22T18:59:38",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=41038372",
    "comments": [
      "> As a designer, I feel the need to be original. If you\u2019re a designer, or even if you\u2019re just interested in design, you probably feel the need to be original, too.I've been a professional designer since 2006, and I got over that thinking pretty quickly. A designer trying to be strikingly original is rarely acting in service of the design. If you want to be strikingly original, you probably want to be an artist instead of a designer. What a designer fundamentally does is communicate the best solution to a problem, given the requirements, goals, and constraints of that problem. Originality is subordinate to that at best.\n \nreply",
      "This.I was a UI/UX guy for about 5 years and worked for a company that pumped out thousands of sites a year. A bunch of their designs won awards and I saw their model and thought I could do that, it seemed easy.The hitch was that I was going to design really cool sites, with all kinds of animations, huge text, have really cool navigation menus, etc. In short, I had a very romantic idea that I would dictate some incredible design to my clients. I thought I was like the Frank Lloyd Wright of design and whatever I showed people they would swoon and then go with whatever uber cool thing I showed them.Reality set in with my first client. Same thing, they didn't want cool shit, they just wanted their potential clients to find information about their work and contact them to hire them. After another 4-5 clients, I suddenly realized that web designers aren't some artist creating ultra cool, ultra rare stuff that your clients must absolutely have like a Banksy piece, they have more fundamental problems they're trying to solve and want you to solve them for them.I got my ego checked in a hurry, but it was a good lesson to learn. You're not selling art, you're selling a solution to their problems.\n \nreply",
      "It is not only that. For example wannabe EDM DJs think they have to be creative and find tracks that no one ever heard to be edgy or whatever\u2026 most of people pay for having cookie cutter songs played so they can dance and have a good experience and they don\u2019t want to be surprised on EDM event - well there are big names that can do whatever they want of course but that is different expectation.The same with software devs that they think, it must be \u201cframework like code, extensible, reusable that will be there for 20 years\u201d - well no if it is crud app most likely it will be trashed in 2 years stop overthinking and just do it :)\n \nreply",
      "Also, one of the most important UX principles is for things to work the way the user expects. And unless you are the market leader, those expectations are mostly built based on all the other designs that your users interact with, rather than yours. So to the extent that originality means diverging from those expectations that are built elsewhere, it is actively doing your users a disservice, by not letting them leverage the expectations and muscle memory they already have. Building on paradigms that others have established as the norm means meeting users where they are.\n \nreply",
      "Right. \"Intuitive\" mostly means \"I have seen this elsewhere.\"\n \nreply",
      "As a concrete example, the idea of a mouse was once counterintuitive to users because they'd never seen one before.Windows included Solitaire with the OS in part to introduce ideas like \"click\" or \"click and drag\" to users that were unfamiliar with GUIs, by linking them to physical concepts users did understand (\"oh, I have a physical card, I can grab it and move it around, that makes sense!\").\n \nreply",
      "Design is about navigating ambiguity, and finding which fine lines to walk when resolving tensions inherent to opposing constraints in any sufficiently complex problem space. There is rarely a single best solution to such problems.Originality certainly has a role to play in there - many (most?) iconic products were strikingly original. Would the iPod have been a better designed product with a D-pad (or other standard button arrangement) over its scrollwheel? Or the Wii with a standard gamepad?Originality and novelty (particularly when it comes to visual aesthetics) are forces people respond to, and great designers know how to channel those forces in  constructive ways for their work.\n \nreply",
      "This is a great quote:> In the middle of Apple\u2019s case against Microsoft, Xerox sued Apple, hoping to establish its rights as the inventor of the desktop interface. The court threw out this case, too, and questioned why Xerox took so long to raise the issue. Bill Gates later reflected on these cases: \u201cwe both had this rich neighbor named Xerox ... I broke into his house to steal the TV set and found out that [Jobs] had already stolen it.\u201d\n \nreply",
      "This is such a frustrating misunderstanding of the history, and the history is fascinating. Xerox invited Apple to tour PARC in exchange for $1M worth of pre-IPO Apple stock, which today would be worth [checks notes] more than that. There was no theft.Apple engineers got to see the Alto, not the Star (the screenshot in the article is wrong, the chronology is wrong). The visit was so fast that Apple engineers thought they saw realtime overlapping windows when they didn\u2019t. [0] So it\u2019s possible Xerox was inspired by Apple with the Star, not the other way around.Meanwhile, Bill Gates totally outs himself as someone who would steal shamelessly.[0]: https://folklore.org/On_Xerox%2C_Apple_and_Progress.html\n \nreply",
      "Steve Jobs himself told what he saw at Xerox: https://www.youtube.com/watch?v=b7aUJyJbJMw\n \nreply"
    ],
    "link": "https://matthewstrom.com/writing/copying/",
    "first_paragraph": "\nCharles Eames said\n            it best: \u201cWe don\u2019t do \u2018art\u2019 \u2014 we solve problems.\u201d1\n\n            To buy furniture in 1950, you had to choose between affordable and\n            enduring, between rugged and fashionable. Charles and Ray designed a\n            chair that was all the above and sold it for $20.95.2\n            They called it the LCW.3\n\n            The LCW embodies the Eames\u2019 obsession with simplicity in material\n            and method. \u201cWe want to make the best for the most for the least,\u201d\n            they said.4\n            The design was revolutionary: in 1999, Time magazine called\n            the LCW \u201cthe best design of the century.\u201d5\n            Today, you can buy a brand new LCW from Herman Miller (the\n            officially licensed manufacturer of Eames products) for $1,195.\n        \n            Or, you can buy a chair called the \u201cFathom\u201d from a company called\n            Modway for $145.\n        Functionally and aesthetically, the chairs are identical.\n            The",
    "summary": "In a digital alcove where design elitism flops around like a Magikarp on land, the \"Copying is the way design works\" article scrambles to sanctify the echo chamber of redundancy with poignant references to glorified furniture makers and their $20 chairs turned museum relics. As we tread through the laborious narrative cradled by a thousand dollar price tag, the comments section blooms with the tears of designers realizing their careers are less about injecting originality than following a pixel-perfect template laid down by their forebears. Our commentators wax lyrical about fundamental difference between art and design, capture quotes like trophies, and compare techno DJs to software developers in a chaotic melee of missed points and self-aggrandizement. Oh, and surprise, everyone suddenly \"gets it\" when pointing out that intuition in design is just a polite term for copy-paste creativity. \ud83c\udfa8\ud83d\udcbb\ud83d\udd04"
  },
  {
    "title": "The Elegance of the ASCII Table (danq.me)",
    "points": 48,
    "submitter": "thewub",
    "submit_time": "2024-07-22T22:31:17",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41040543",
    "comments": [
      "> So when you\u2019re reading 7-bit ASCII, if it starts with 00, it\u2019s a non-printing character. Otherwise it\u2019s a printing character.> The first printing character is space; it\u2019s an invisible character, but it\u2019s still one that has meaning to humans, so it\u2019s not a control character (this sounds obvious today, but it was actually the source of some semantic argument when the ASCII standard was first being discussed).Hmm.. Interesting that space is considered a printing character while horizontal tab and newline are control characters. They're all invisible and move the cursor, but I guess it makes sense. Space is uniquely very specific in how the cursor is moved one character space, so it's like an invisible character. Newline can either imply movement straight down, or down and to the left, depending on a configuration or platform (e.g. DOS vs UNIX line endings). Horizontal tab can also move you a configurable amount rightwards, and perhaps it might've been thought a bit differently, given there's also a vertical tab, which I've got no idea on how it was used. Maybe it's the newline-equivalent for tables, e.g. \"id\\tcolor\\v1\\tred\\v2\\tblue\\v\" or something like that.Interesting also that BS is a control char while DEL is a printing(?) char. I guess that's because BS implies just movement leftwards over the text, while DEL is all ones like running a black sharpie through text. Guess that's what makes it printing. Wonder if there were DEL keys on typewriters that just stamped a black square, and on keypunchers that just punched 7 holes, so people would press \"backspace\" to go back then \"delete\" to overwrite.I've used ASCII a lot, but even after so many years, I'm getting moments where it's like \"oh this piece isn't just here, it needs to be here for a deep reason\". It's like a jigsaw puzzle.\n \nreply",
      "I always lament that since at least 1980s or so, it seems the vast majority of the control characters were never used for their intended purpose.Instead, we crudely use commas and tabs as delimiters instead of something like RS (#30).\n \nreply",
      "The encodings we use today have a surprisingly deep and complex history. For more, see:\n\"The Evolution of Character Codes, 1874-1968\"\nhttps://ia800606.us.archive.org/17/items/enf-ascii/ascii.pdf\n \nreply",
      "man ascii\n\nis never far from my fingers. combined with od -c and od -x it gets the job done. I don't think as fluently in Octal as I used to. Hex has become ubiquitous.\n \nreply",
      "Once I saw a case-insensitive switch in C using that pattern of letters:switch (my_char | 0x20) {   case 'a': ...\n   break;\n\n   case 'b': ...\n   break;\n\n}\n \nreply",
      "This can be made to work for ASCII and EBCDIC simultaneously for extra esoterica points:  switch (my_char | 'A' ^ 'a') {\n  case 'A' | 'a': /* ... */ break;\n  /* ... */\n  }\n\nI don\u2019t know if this is too fancy to have ever made it into real code, but I believe I\u2019ve seen places in the ICU source that still say ('A' <= x <= 'I' || 'J' <= x <= 'R' || 'S <= x <= 'Z') instead of just ('A' <= x <= 'Z'), EBCDIC letters being arranged in those three contiguous ranges.\n \nreply",
      "Many old NES/SNES games had a simpler character encoding system, with 0-9 and A-Z at the beginning of the table.  No conversion require to display hex.\n \nreply",
      "I heard someone describe the ASCII table as a state machine. Guess I could understand that as a state machine needed to parse it? This is surprisingly hard to search for but I was wondering if anyone knows what they were talking about.\n \nreply",
      "One downside of ASCII is the lack of two extra \u201cletters\u201d (whatever they might be, e.g. perhaps German \u00df), as it makes it impossible to represent base 64 alphanumerically. So we ended up with many alternatives picking two arbitrary punctuation marks.\n \nreply",
      "ebcdic is also quite eleganthttps://news.ycombinator.com/item?id=13543715\n \nreply"
    ],
    "link": "https://danq.me/2024/07/21/ascii/",
    "first_paragraph": "\nDan\u00a0Q\n\nDuration 15:19\n\n\t\tThis post is also available as a podcast. Listen here, download for later, or subscribe wherever you consume podcasts.\n\t\t\n\tIf you\u2019ve been a programmer or programming-adjacent nerd1\n\tfor a while, you\u2019ll have doubtless come across an ASCII table.\n\t\n\tAn ASCII table is useful. But did you know it\u2019s also beautiful and elegant.\n\t\nASCII was initially standardised in X3.4-1963 (which just rolls off the tongue, doesn\u2019t it?) which assigned meanings to 100 of the\n\tpotential 128 codepoints presented by a 7-bit4\n\tbinary representation: that is, binary values 0000000 through 1111111:\n\t\n\tIf you\u2019ve already guessed where I\u2019m going with this, you might be interested to look at the X3.4-1963 table and see that yes, many of the same elegant design choices I\u2019ll be talking\n\tabout later already existed back in 1963. That\u2019s really cool!\n\t\n\tIn case you\u2019re not yet intimately familiar with it, let\u2019s take a look at an ASCII table. I\u2019ve\n\tcolour-coded some of the bits I think are most-beau",
    "summary": "\ud83c\udf89Discover the hidden charm of the ASCII Table, as \"Dan Q\" enlightens us with a rhapsodic ode to 128 characters that revolutionized typing like, *ahem*, space and 'A'. Rejoice as he color-codes the obvious and pedantically regurgitates information we all googled once during a caffeine-fueled night of coding. The comment section turns into a nostalgia-fest where everyone flexes their retro tech muscles, debating the profound implications of space versus tab, and sharing arcane tricks that were last relevant when floppy disks were a hot commodity. Who knew a table could evoke such <em>passion</em>? \ud83e\udd13"
  },
  {
    "title": "Scientists discover a new hormone that can build strong bones (ucsf.edu)",
    "points": 287,
    "submitter": "gmays",
    "submit_time": "2024-07-22T16:42:22",
    "num_comments": 100,
    "comments_url": "https://news.ycombinator.com/item?id=41036462",
    "comments": [
      "This is great. But, the root of the problem for most postmenopausal women is simply the lack of estrogen. You need estrogen to make bone. Men and women do. Men are mostly protected from osteoporosis because they convert testosterone to estrogen. Elderly men have more estrogen than postmenopausal women. Their levels go to near zero. It's a tragedy that more doctors don't recommend HRT for older women, at least some level of replacement, maybe not up to peak levels when they were younger. The lack of estrogen causes a lot of suffering.\n \nreply",
      "Men are also more likely to do strength training, which also helps build bone density.  Women are also more likely to regularly perform cardio/aerobic exercises, which can reduce bone density when done in excess and without adequate nutrition.  Lack of estrogen is of course the root, but I think we can't dismiss behavior differences contributing to the effect.  In my experience, many women do minimal to no strength training because they're worried that muscle tone will make them look masculine.  Maybe this is a really bad idea to live by.\n \nreply",
      "Read of a study years ago that had postmenopausal wpmen do weight training - giving a dramatic 40% increase in bone density in 6 weeks IIRC the details.It's not that frail people need to be inactive, but that inactivity causes frailty.\n \nreply",
      "> Women are also more likely to regularly perform cardio/aerobic exercises, which can reduce bone density when done in excess and without adequate nutrition.What is the biological mechanism behind this statement?\n \nreply",
      "Elevated cortisol (in response to the stress of running or whatever) increases bone resorption and inhibits bone growth.  This isn't necessarily an issue for anyone doing lots of cardio, but it's an increase in risk.  It also reduces protein synthesis, which is important for both muscle and bone (it isn't just calcium).\n \nreply",
      "> Elevated cortisol (in response to the stress of running or whatever) increases bone resorption and inhibits bone growthCortisol is also released during strength training, though.Seems like a real issue is low impact cardio, which isn't negative for bone density (as far as I can tell) but does have a theoretical opportunity cost when you could be doing weight-bearing cardio, which does improve bone density.Agreed with littlestymaar's comment higher up, though, that exercise rates being what they are, the theoretical opportunity cost may be quite theoretical.\n \nreply",
      "> Cortisol is also released during strength training, though.more than compensated for by the compressive loading signals from lifting heavy.\n \nreply",
      "> Elevated cortisol \u2026 increases bone resorption and inhibits bone growthWould that also be true for caffeine consumption? IIRC it increases cortisol levels, but I don't really know much about what else it does, I've only read the Wikipedia page and gone \"Wow, I'm really glad I've already cut back\".\n \nreply",
      "\"\"Wow, I'm really glad I've already cut back\".\"What you said about caffeine worried me somewhat, so I looked it up on Wiki and what I found about it was mostly innocuous and some properties are even beneficial, it's even on WHO's list of essential medicines.Many vegetables have much more dangerous compounds and toxins: oxalic acid (a rust remover and bleach that can rot your kidneys) in rhubarb and Popeye's spinach and many other green-leaf vegies, solanine in potatoes, and very dangerous cancer-causing aflatoxins in peanut butter, and that's just the beginning, there are many dozens more! Now you know, are you going to starve?And to boot, caffeine is a nice looking heterocyclic purine-like molecule with a six and a five-member ring both heavily laden with nitrogen, so what's the worry about? What's not to like about it?\n \nreply",
      "This may be true, but it's not really relevant. Most people don't do training at all, especially past 50 yo, where bone density declines in women.(And that's a significant issue in itself)\n \nreply"
    ],
    "link": "https://www.ucsf.edu/news/2024/07/428011/scientists-discover-new-hormone-can-build-strong-bones",
    "first_paragraph": "",
    "summary": "<h1>Forget Estrogen, We Found Bone Juice!</h1>\nOh joy, the lab coats at UCSF have stumbled upon a new hormone that plays Bob the Builder with your skeleton. Commenters, armed with an afternoon's worth of Google Scholar and health blog expertise, dive headfirst into a sea of endocrinology and resistance training. One genius recalls a six-week miracle study they can't quite cite, while another bravely battles the perils of cardio-induced cortisol with a keyboard. Meanwhile, the chorus of \"just lift bro\" echoes into the abyss, as a debate on the biochemical terrors of caffeine morphs into an unsolicited TED Talk on vegetable toxins. Who knew osteoporosis could be so <em>exciting</em>?"
  },
  {
    "title": "July 2024 Update on Instability Reports on Intel Core 13th/14th Gen Desktop CPUs (intel.com)",
    "points": 115,
    "submitter": "acrispino",
    "submit_time": "2024-07-22T20:55:02",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=41039708",
    "comments": [
      "https://scholar.harvard.edu/files/mickens/files/theslowwinte...\"Unfortunately for John, the branches made a pact with Satan \nand quantum mechanics [...] In exchange for their last remaining \nbits of entropy, the branches cast evil spells on future genera-\ntions of processors. Those evil spells had names like \u201cscaling-\ninduced voltage leaks\u201d and \u201cincreasing levels of waste heat\u201d \n[...] the branches, \nthose vanquished foes from long ago, would have the last laugh.\"\"John was terrified by the collapse of the parallelism bubble, \nand he quickly discarded his plans for a 743-core processor \nthat was dubbed The Hydra of Destiny and whose abstract \nPlatonic ideal was briefly the third-best chess player in Gary, \nIndiana. Clutching a bottle of whiskey in one hand and a shot-\ngun in the other, John scoured the research literature for ideas \nthat might save his dreams of infinite scaling. He discovered \nseveral papers that described software-assisted hardware \nrecovery. The basic idea was simple: if hardware suffers more \ntransient failures as it gets smaller, why not allow software to \ndetect erroneous computations and re-execute them? This idea \nseemed promising until John realized THAT IT WAS THE \nWORST IDEA EVER. Modern software barely works when the \nhardware is correct, so relying on software to correct hardware \nerrors is like asking Godzilla to prevent Mega-Godzilla from \nterrorizing Japan. THIS DOES NOT LEAD TO RISING PROP-\nERTY VALUES IN TOKYO. It\u2019s better to stop scaling your \ntransistors and avoid playing with monsters in the first place, \ninstead of devising an elaborate series of monster checks-\nand-balances and then hoping that the monsters don\u2019t do what \nmonsters are always going to do because if they didn\u2019t do those \nthings, they\u2019d be called dandelions or puppy hugs.\"\n \nreply",
      "I haven't read this piece before but I just knew it was going to be written by Mickens about halfway through your comment.\n \nreply",
      "Remains to be seen how the microcode patch affects performance, and how these CPUs that have been affected by over-voltage to the point of instability will have aged in 6 months, or a few years from now.More voltage generally improves stability, because there is more slack to close timing. Instability with high voltage suggests dangerous levels. A software patch can lower the voltage from this point on, but it can't take back any accumulated fatigue.\n \nreply",
      "I was recently looking at building and buying a couple systems. I've always liked Intel. I went AMD this time.It seemed like the base frequencies vs boost frequencies were much farther apart on Intel than with most of the AMDs. This was especially true on the laptops were cooling is a larger concern. So I suspect they were pushing limits.Also, the performance core vs efficiency core stuff seemed kind of gimmicky with so few performance cores and so many efficiency cores. Like look at this 20 core processor! Oh wait, it's really an 8 core when it comes to performance. Hard to compare that to a 12 core 3D cached Ryzen with even higher clock...I will say, it seems intel might still have some advantages. It seems AMD had an issue supporting ECC with the current chipsets. I almost went Intel because of it. I ended up deciding that DDR5 built in error correction was enough for me. The performance graphs also seem to indicate a smoother throughput suggesting more efficient or elegant execution (less blocking?). But on the average the AMDs seem to be putting out similar end results even if the graph is a bit more \"spikey\".\n \nreply",
      "> It seems AMD had an issue supporting ECC with the current chipsets.AMD has the advantage with regards to ECC. Intel doesn't support ECC at all on consumer chips, you need to go Xeon. AMD supports it on all chips, but it is up to the motherboard vendor to (correctly) implement. You can get consumer-class AM4/5 boards that have ECC support.\n \nreply",
      "There was recently[1] some talk about how the 13th/14th gen mobile chips also had similar issues, though Intel insisted it's something else.Will be interesting to see how that pans out.[1]: https://news.ycombinator.com/item?id=41026123\n \nreply",
      "The mobile issue seems more anecdote than data? Almost as if people on Reddit heard the 13/14 CPUs were bad, then their laptop crashed, and they decided \"it happened to me too\".\n \nreply",
      "Well it's not just[1] redditors from what I can gather:Now Alderon Games reports that Raptor Lake crashes impact Intel's 13th and 14th-Gen processors in laptops as well.\"Yes we have several laptops that have failed with the same crashes. It's just slightly more rare then the desktop CPU faults,\" the dev posted.These are the guys who publicly claimed[2] Intel sold defective chips based on the desktop chips crashing.[1]: https://www.tomshardware.com/pc-components/cpus/dev-reports-...[2]: https://www.tomshardware.com/pc-components/cpus/game-publish...\n \nreply",
      "For server CPUs there's not a similar problem or they realize server purchasers may be less willing to tolerate it? I'm not all that thrilled with the prospect of buying Intels especially when wondering about waiting to 5 year out replacement compared to a few generations ago, but AMD server choices can be a bit limited and I'm not really sure how to evaluate if there may be increasing surprises more across the board.\n \nreply",
      "I was concerned this would happen to them, given how much power was being pushed through their chips to keep them competitive. I get the impression their innovation has either truly slowed down, or AMD thought enough 'moves' ahead with their tech/marketing/patents to paint them into a corner.I don't think Intel is done though, at least not yet.\n \nreply"
    ],
    "link": "https://community.intel.com/t5/Processors/July-2024-Update-on-Instability-Reports-on-Intel-Core-13th-and/m-p/1617113#M74792",
    "first_paragraph": "\n\n                            Success!  Subscription added.\n                        \n\n\n                            Success!  Subscription removed.\n                        \n\n\n                            Sorry, you must verify to complete this action. Please click the verification link in your email. You may re-send via your\n                            profile.\n                        \nBased on extensive analysis of Intel Core 13th/14th Gen desktop processors returned to us due to instability issues, we have determined that elevated operating voltage is causing instability issues in some 13th/14th Gen desktop processors. Our analysis of returned processors confirms that the elevated operating voltage is stemming from a microcode algorithm resulting in incorrect voltage requests to the processor.Intel is delivering a microcode patch which addresses the root cause of exposure to elevated voltages. We are continuing validation to ensure that scenarios of instability reported to Intel regard",
    "summary": "In the latest thrilling installment of \"How *Not* to Engineer,\" Intel admits that feeding too much voltage to their fancy new chips leads to the technological equivalent of a toddler's tantrum during naptime. The geniuses responsible for this innovation were apparently so distracted by the shiny prospect of 14th gen supremacy that they programmed the voltage high enough to power a small sun. The comment section is awash with armchair engineers sorrowfully trading in their Intel loyalty badges for AMD's seemingly magical, unicorn-infused circuits. One insightful soul bravely admits they were just about to understand the problem until a shiny, unrelated hyperlink caught their attention and, alas, their contribution was lost to the digital ether. \ud83c\udf7f\ud83d\udd25"
  },
  {
    "title": "What Is Entropy? (johncarlosbaez.wordpress.com)",
    "points": 134,
    "submitter": "ainoobler",
    "submit_time": "2024-07-22T18:33:35",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=41037981",
    "comments": [
      "A well known anecdote reported by Shannon:\"My greatest concern was what to call it. I thought of calling it 'information,' but the word was overly used, so I decided to call it 'uncertainty.' When I discussed it with John von Neumann, he had a better idea. Von Neumann told me, 'You should call it entropy, for two reasons. In the first place your uncertainty function has been used in statistical mechanics under that name, so it already has a name. In the second place, and more important, no one really knows what entropy really is, so in a debate you will always have the advantage.'\"See the answers to this MathOverflow SE question (https://mathoverflow.net/questions/403036/john-von-neumanns-...) for references on the discussion whether Shannon's entropy is the same as the one from thermodynamics.\n \nreply",
      "Von Neumann was the king of kings\n \nreply",
      "Its odd...as someone interested but not fully into the sciences I see his name pop up everywhere.\n \nreply",
      "He was really brilliant, made contributions all over the place in the math/physics/tech field, and had a sort of wild and quirky personality that people love telling stories about.A funny quote about him from a Edward \u201ca guy with multiple equations named after him\u201d Teller:> Edward Teller observed \"von Neumann would carry on a conversation with my 3-year-old son, and the two of them would talk as equals, and I sometimes wondered if he used the same principle when he talked to the rest of us.\"\n \nreply",
      "I've seen many people arguing he's the most intelligent person that ever lived\n \nreply",
      "Some say Hungarians are actually aliens.\n \nreply",
      "It would be less odd if you took a few moments out of your busy day and read something about the guy, no?\n \nreply",
      "The utility of the concept of entropy for most working programmers comes with its ability to characterize a protocol as high entropy or low entropy. A high entropy protocol is something like a jpeg image of text. A low entropy protocol is the text itself. It takes more work to go from a high entropy representation to a low one (using OCR in this example) than vice versa (generating an jpeg image from text). One does well to lower the entropy of a representation for as long as possible within the systems you control, leaving descending/climbing the entropy slope for outer system boundaries. The alternative is to have a bumpy, expensive, often error-prone path for data.\n \nreply",
      "I felt like I finally understood Shannon entropy when I realized that it's a subjective quantity -- a property of the observer, not the observed.The entropy of a variable X is the amount of information required to drive the observer's uncertainty about the value of X to zero. As a correlate, your uncertainty and mine about the value of the same variable X could be different. This is trivially true, as we could each have received different information that about X.  H(X) should be H_{observer}(X), or even better, H_{observer, time}(X).As clear as Shannon's work is in other respects, he glosses over this.\n \nreply",
      "This doesn't really make entropy itself observer dependent. (Shannon) entropy is a property of a distribution. It's just that when you're measuring different observers' beliefs, you're looking at different distributions (which can have different entropies the same way they can have different means, variances, etc).\n \nreply"
    ],
    "link": "https://johncarlosbaez.wordpress.com/2024/07/20/what-is-entropy/",
    "first_paragraph": "",
    "summary": "**Title: What Is Entropy? (johncarlosbaez.wordpress.com)**\n\nIn a spectacular display of intellectual fireworks, someone resurrects Shannon's all-too-familiar cocktail party anecdote about naming \"entropy.\" Naturally, this ignites the usual circle of adoration in the comments, where von Neumann is elevated from brilliant physicist to omniscient deity\u2014the only entity believed to converse with toddlers and theoretical physicists on the same intellectual plane. Meanwhile, random interjections about Hungarians being aliens and the profoundly \"insightful\" realization that entropy might just be a tad subjective, bafflingly attempt to share the spotlight. As always, the comments oscillate wildly between hero worship and misapplied scientific concepts, ensuring that entropy remains as misunderstood as ever\u2014von Neumann would be proud. \ud83d\ude44"
  },
  {
    "title": "Maestro: Netflix's Workflow Orchestrator (netflixtechblog.com)",
    "points": 164,
    "submitter": "vquemener",
    "submit_time": "2024-07-22T18:20:16",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=41037745",
    "comments": [
      "I used to be impressed with these corporate techblogs and their internal proprietary systems, but not so much anymore. Because code is a liability.I would rather use off-the-shelf open source stuff with long history of maintenance and improvement, rather than reinvent the cron/celery/airflow/whatever, because code is a liability. Somebody needs to maintain it, fix bugs, add new features. Unless I get +1 grade promotion and salary/rsu bump, ofc.People need to realize that code is a liability, anything that is not the business critical stuff that earns/makes $$$ for the company is a distraction and resource sink.\n \nreply",
      "Isn't this exactly WHY this blog post exists? They are open sourcing this software so that they don't have to maintain it all internally anymore.They had a need that an existing \"off-the-shelf open source\" project didn't solve, so they created this an are now turning it into an \"off-the-shelf open source\" project so they can keep using it without having to maintain it entirely themselves.How are these open source tools supposed to be created in the first place? This is the process, someone has to do it\n \nreply",
      "Usually the corporate needs differ too much and they end up keeping their own fork anyway.Netflix has the resources to maintain this. It's probably more a PR move for their hiring division.\n \nreply",
      "So Netflix expects open source community to pick up the maintenance tab ?I understand how open source proejcts are born, but I struggle to see what is novelty of this project. Just another Java CRUD app with some questionable design choices that are only applicable to netflix:1. They claim it is distributed system, but it is just a regular Java crud with SQL backend2. Java-like DSL with parser and classloader (why? Just why?)Projects like these are the perfect examples of Enterprise Grade FizzBuzz (https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpris...) and this is exactly what I dont like about it\n \nreply",
      "> So Netflix expects open source community to pick up the maintenance tab ?In fairness, the very nature of open source is that the community is only going to pick up the maintenance tab if the value they're getting out of it is worth it.\n \nreply",
      "> People need to realize that code is a liabilityThis is an extreme point of view, that is tightly connected to the MBA-driven min-maxing of everything under the sun.I am glad that there are folks who aren't afraid to code new systems and champion new ideas. Even in the corporate sense, mediocre risk averse solutions will only take you so far. The most profitable companies tend to be quite daring in their tech.Code is not a liability. Code is what makes a company move its gears.\n \nreply",
      "Code being a liability is not a contradiction with code being what makes a company move its gears. The trucks of a delivery service are a liability (requiring maintenance, deprecation accounting, fuel), but are also the only thing that lets the company deliver. A delivery company should own as few trucks as necessary, and no fewer. Any company should publish/run/maintain as little code as necessary, and no less.\n \nreply",
      "Trucks are literally an asset - you can't do depreciation on a liability.The only way a 'truck' could be a  liability is a lease for said truck.There are plenty of economically rationale reasons why a company may own more trucks they strictly need to manage delivery. For example wanting to handle seasonal bursts, wanting to ensure reliability, preparing for an expansion, being able to lease capacity to other businesses.Actually you can go replace truck with server and you describe what made AWS make initial sense.Please stop misusing accounting concepts.\n \nreply",
      "> Please stop misusing accounting concepts.Assets can also be liabilities. The mortgages in a mortgage backed security is both an asset and a liability, as was only too well demonstrated in 2008... It's an asset in the security portfolio, but until you sell the security, it's a liability for whomever is securitizing it.\n \nreply",
      "For trucking company owning and developing trucks makes sense.But does it make sense for a trucking(streaming) company to create own plumbing equipment? I\u2019d rather use Plumbers Supply Inc that every other company uses from Plumber Depot or use open-source-plumbers.com, because I am not in a plumbing business\n \nreply"
    ],
    "link": "https://netflixtechblog.com/maestro-netflixs-workflow-orchestrator-ee13a06f9c78",
    "first_paragraph": "",
    "summary": "Netflix attempts to dazzle the plebeian masses yet again with \"Maestro: Netflix's Workflow Orchestrator,\" a groundbreaking masterpiece that reinvents the wheel for the millionth time in tech history. \ud83c\udfad In earth-shattering blog posts, corporate magicians reveal they've built another tool that could've probably been replaced by an intern tweaking some open-source software. Meanwhile, commenters trip over themselves playing armchair CEO, bemoaning code as a liability, or igniting debates about who really owns the soul of a truck... or was it a server? \ud83e\udd21 The tech gods save us from innovation terrorism, one workflow orchestrator at a time."
  },
  {
    "title": "All Golioth Hardware Is Now Open Source (golioth.io)",
    "points": 44,
    "submitter": "hasheddan",
    "submit_time": "2024-07-17T17:31:46",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=40988229",
    "comments": [
      "If, like me, you've never heard of them:> Golioth is an IoT platform that provides cloud services for embedded devices.https://golioth.io/product\n \nreply",
      "I might be cynical, but I have seen many cases of companies open-sourcing a few products for PR and promotional purposes, where the open-source community takes care of the promotion work for free. Fast forward a few years, and a license change occurs after many companies are already relying on such products.\n \nreply",
      "Think of these more like a reference implementation to help somebody bootstrap their own compatible hardware design.Hardware isn't the business they're in and these designs aren't the only way to use their platform. They just make for an officially sanctioned starting point, supported by the legal clarity of an open source license. That making it officially \"open source\" earns them a news cycle and some buzz is just a little side benefit for what's otherwise pretty common in the industry.\n \nreply",
      "This looks like a textbook case of \"commoditize your complement\". So I wouldn't expect a rug pull. It's in their interest for this to be free.\n \nreply",
      "The Amp Hour podcast episode #526 [1] circa Jan 18, 2021 seems contextually relevant.[1] https://theamphour.com/526-why-iot-is-difficult-with-jonatha...\n \nreply",
      "Unrelated to this project/the article, but I'm still waiting for hbm3 and gddr7 to show up in digikey so I can easily import the part into kicad\n \nreply"
    ],
    "link": "https://blog.golioth.io/all-golioth-hardware-is-now-open-source/",
    "first_paragraph": "",
    "summary": "### Hardware Generosity or Sly Marketing? You Decide.\n\nIn an industry-shaking move that definitely no one saw coming, Golioth has decided to shoot the sacred cow and open-source their hardware designs. Because nothing screams 'innovation' quite like making your product free and relying on the goodwill and spare time of developers around the globe. Commenters, some pondering if they've stumbled upon some Kafkaesque philanthropic dream, painfully miss the point by turning a clear PR gambit into a technological utopia discussion. Meanwhile, others are just waiting for their backordered parts to arrive so they can actually do something productive. Cue the collective slow clap for open source sainthood. \ud83d\ude4c"
  },
  {
    "title": "Audapolis: Edit audio files by transcript, not waveform (github.com/bugbakery)",
    "points": 188,
    "submitter": "mavsman",
    "submit_time": "2024-07-22T16:25:21",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=41036231",
    "comments": [
      "I remember when Adobe demoed this idea of being able to edit waveforms by the recognized text back in 2016 and it was pretty mind blowing for the time.https://youtu.be/I3l4XLZ59iwEDIT: I could also definitely see Audapolis being useful if you could integrate it into a podcast's post processing flow (volume normalization, de-essing) by recognizing certain verbal tics and automatically removing them from the audio such as \"ummmm...\", etc.\n \nreply",
      "What ever happened to that Adobe demo? Was that a real product at any point? It's quite amazing how ahead of its time it was. Now that we have AI making people say whatever we want, it felt like Adobe was on the cusp of that then.\n \nreply",
      "I remember people saying at the time that \u201cthis is the point at which voice recordings can not be trusted any longer\u201d. And then, like you said nothing happened kind of for a few years until the current AI/ML tech got to where it is currently at.\n \nreply",
      "and there's still no commercial product for synthesizing video to sync lip movements to edited transcript like all the scary proof of concepts that turned the president into a puppetMaybe there's not much value in editing what someone said after all\n \nreply",
      "commercial value: nocriminal value... maybe?There are absolutely scams right now that use deepfakes to trick people.\n \nreply",
      "Were they strongarmed or self censored themselves? Would be interesting to know the backstory.\n \nreply",
      "A genuinely free alternative to Descript sounds very useful.I've always liked the idea of Descript and was considering building something similar before it came out. The problem is my use case is a couple of videos a year so doesn't fit with an expensive monthly subscription\n \nreply",
      "I've spent some of my free time over the past couple of months working on something similar. It's in a decent state but I need help from somebody who understands the .fcpxml format so you can export your edits to Davinci and FCP.Take a look at https://matcha.video\n \nreply",
      "This is awesome to see as an open source project.This functionality is some of my favorite when editing videos in Descript. It\u2019s so much easier than chopping up waveforms in Audacity\n \nreply",
      "Demo Video: https://pajowu.de/audapolis_intro.mp4\n \nreply"
    ],
    "link": "https://github.com/bugbakery/audapolis",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        an editor for spoken-word audio with automatic transcription\n      audapolis aims to make the workflow for spoken-word-heavy media editing easier, faster and more accessible.You can download the newest version for Windows, Linux and macOS here.\nIf you find any bugs or UX inconveniences, we would be happy for you to report them to us.It would be really nice if you could help us out by answering our short survey about your needs & expectations so that we can build actually usefull software and know what you need.\n        an editor for spoken-word audio with automatic transcription\n      ",
    "summary": "<strong>Welcome to Audapolis</strong>, the latest pit stop in tech's unyielding race to make the old new again. This open source marvel lets you chop up spoken word audio by text instead of waveform, because who's got time for actual editing skills in 2023? Commenters are tripping over themselves in nostalgic awe, recalling Adobe's similar concept from the dark ages of 2016, while gleefully plotting the demise of traditional audio credibility. Meanwhile, in a garbled mix of excitement and paranoia, others speculate on the tech's potential for criminal misuse\u2014a thrilling subplot in the ongoing saga of tech innovations we probably didn't need but definitely will misuse. \ud83d\ude31\ud83d\udcbe\ud83d\ude02"
  },
  {
    "title": "Netflix has open-sourced its Maestro Workflow Orchestrator (github.com/netflix)",
    "points": 127,
    "submitter": "kaypee901",
    "submit_time": "2024-07-22T18:21:14",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=41037774",
    "comments": [
      "This appears to be the high level architecture: https://miro.medium.com/v2/resize:fit:4800/format:webp/0*SDt....To me seems to overengineered for most of the companies outside there, how many people do you need to manage it?\n \nreply",
      "In the blog, it claims:> \u2026 schedule hundreds of thousands of workflows, millions of jobs every day and operate with a strict SLO of less than 1 minute of scheduler introduced delay even when there are spikes in the traffic.I wouldn\u2019t necessarily call it over engineered if it can handle this type of workload.But if you are running a fraction of these workloads with a much more relaxed SLO (service level objection), then yea this is overengineered.Like any solution from FAANG, or \u201cbig tech\u201d. It works for _them_ at scale but for 90% of companies the sheer management of this service will quickly outweigh the benefits.\n \nreply",
      "> Like any solution from FAANG, or \u201cbig tech\u201d. It works for _them_ at scale but for 90% of companies the sheer management of this service will quickly outweigh the benefits.In other words, learn it now and get it on your resume, because within a year every 200-hit-per-day service and site is going to rearchitected to use it.\n \nreply",
      "Over-engineering is in the eye of the beholder\n \nreply",
      "That chart has real Krazam Microservices vibes to it.\n \nreply",
      "Here's a video of Primeagen, a YouTuber who uses to be a dev at Netflix, watching that video and then telling a very similar story that happened at Netflix: https://youtu.be/s-vJcOfrvi0\n \nreply",
      "> First we call Bingo to get our Name-o.\n \nreply",
      "Love Galactus.\n \nreply",
      "All time great Youtube video. Still heavily relevant today.\n \nreply",
      "1) Scheduling seems to be primitive? (strategy: sequential)\n2) That's seems to be just a DAG executor? No high-level frontend?\n3) No executiun context?\n4) No typings?\n5) No concept of a stream?It would be way too ambitious to call this thing an orchestrator, it seems to be just a primitive distributed DAG executor.\n \nreply"
    ],
    "link": "https://github.com/Netflix/maestro",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Maestro: Netflix\u2019s Workflow Orchestrator\n      Maestro\nis a general-purpose workflow orchestrator that\nprovides a fully managed workflow-as-a-service (WAAS) to the data platform users at Netflix.It serves thousands of users, including data scientists, data engineers, machine learning engineers,\nsoftware engineers, content producers, and business analysts, for various use cases.\nIt schedules hundreds of thousands of workflows, millions of jobs every day\nand operate with a strict SLO even when there are spikes in the traffic.\nMaestro is highly scalable and extensible to support existing and new use cases and offers enhanced usability to end users.Copyright 2024 Netflix, Inc.Licensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the Licen",
    "summary": "**Netflix Open-Sources Its Overcooked Spaghetti Machine, Engineers Unite in Confusion**\n\nIn a desperate attempt to prove that their engineers do more than binge-watch their own content, Netflix has graciously open-sourced \"Maestro,\" a workflow orchestrator that \"serves thousands\" yet somehow still appears to be relevant only to their oversized data handling woes. Commenters quickly transform into armchair architects, criticizing the Maestro's existence as a grandiloquent monstrosity more suited to launching spaceships than managing data. The consensus in the comments is that unless you're running a small country or a tech giant masquerading as a streaming company, integrating Maestro into your project is like using a chainsaw to cut a birthday cake\u2014overkill and likely to end in tears. Meanwhile, a YouTuber adds to the circus by reminiscing about Netflix's engineering escapades, affirming everyone's fear of corporate over-engineering in a heartwarming story equivalent to a \"How I Met Your Mother\" rerun. \ud83d\udcbb\ud83c\udf7f"
  },
  {
    "title": "Unconditional Cash Study: first findings available (openresearchlab.org)",
    "points": 95,
    "submitter": "dbroockman",
    "submit_time": "2024-07-22T11:00:16",
    "num_comments": 268,
    "comments_url": "https://news.ycombinator.com/item?id=41033005",
    "comments": [
      "$1000 is not enough to quit their jobs or get a nice apartment. They could move slightly closer to work if they have to commute.It's not enough for a real tuition or to support them to study instead of work.I don't think we've ever had a universal basic income test. We have always missed the universal and basic part. It's below basic and not at all universal.I suspect that you need to get international cooperation and a more sophisticated form of money and resource tracking for a real UBI to be feasible.\n \nreply",
      "Why is the goal to get people to quit their jobs and get a nice apartment?Isn't it supposed to be a minimum base level of support? Why do we keep moving the goal posts?And if everyone quits their job and lives in a nice apartment, where is this money going to come from? The problem with welfare today is that its a disincentive to work. Start working, you lose your transfer payments. A lot of people are stuck in this trap and don't want to start working, forsaking valuable on the job training and socialization that will hurt them in the long run. That's where universal part comes in\n \nreply",
      "Back in my college speech class, a woman gave a presentation basically supporting the \"welfare today is a disincentive to work\" myth, with emphasis on \"today\" (or current), while totally destroying the notion that welfare recipients don't \"want\" to work. She was a stay-at-home mom with 2 kids, her husband commit suicide after serving in Iraq and then being pushed out of the military (this was the 90s when the US military was actively drawing down). She basically said that the current welfare system (in the 90s, in California) didn't allow a way to slowly move off welfare. She said she had many offers for part-time work, and work that didn't earn a lot of money, but both had potential for her to eventually be promoted to full-time or to make more money than welfare paid her. But she said there was no way to do this: welfare was either all or nothing. But most of all, she dispelled the myth that she was some sort of leech that didn't want to work. She wanted to work, but the welfare system didn't allow it.Your comment didn't necessarily imply it, but a lot of the discourse these days tries to imply (or directly claims) that recipients are the problem, they're a bunch of lazy bums that don't want to contribute. That's just not true.\n \nreply",
      "You are looking for the term \"effective marginal tax rate.\" https://en.wikipedia.org/wiki/Effective_marginal_tax_rateTo give a sense how much benefits code and tax code have in common, see this worksheet for SNAP eligibility, which resembles a second tax return: https://www.fns.usda.gov/snap/recipient/eligibility. You get to do something similar, again(!), for Medicaid.The American benefits code is a patchwork of conflicting sensibilities of the electorate: the smallest possible tax, paternalism and suspicion against the poor, plus a few policy analysis trying to obtain the maximum poverty reduction within those constraints. The result is a thicket of means tested programs with extremely steep phase-outs and a lot of paperwork. The all-in EMTR for an American with income between 0-40K a year is chaotic beyond reason as a result as they roll up the income spectrum.This person who gave the presentation is indeed in one of the worst cases for the code: a single parent with multiple children.\n \nreply",
      "There was a podcast or video about this exact same issue in... Sweden? Some anecdata from people receiving welfare, but couldn't start a job or a business because if they received any money, they get nothing from welfare and wouldn't be able to support themselves.This resulted in people that were trying to start a business not get paid for their work (I believe one of the anecdata was a photographer) because doing so would mean they couldn't support themselves.Personally, I'm a big fan of the \"for every $2 you make, you get $1 less from UBI/Welfare\" concept. This seems a very easy way to wean people off of welfare. That money is already tracked by the IRS (unless you're getting paid under the table).\n \nreply",
      "> Personally, I'm a big fan of the \"for every $2 you make, you get $1 less from UBI/Welfare\" concept. This seems a very easy way to wean people off of welfare. That money is already tracked by the IRS (unless you're getting paid under the table).That's a more gradual phase-out, but it still is an effective marginal tax rate of 50%+ \u2013 a level that wealthy earners would complain about to no end.In light of this study, it seems to me that a cash-support system that wants to encourage work should have a starting region with a negative effective phase-out rate: \"for every $1 you make up to $X, you get $0.25 more from UBI/Welfare.\"  That would encourage labour-market attachment even if tenuous, and it would also have a side benefit of making the worker want to report the income, possibly uncovering under-the-table payment schemes.\n \nreply",
      "> In light of this study, it seems to me that a cash-support system that wants to encourage work should have a starting region with a negative effective phase-out rate: \"for every $1 you make up to $X, you get $0.25 more from UBI/Welfare.\" That would encourage labour-market attachment even if tenuous, and it would also have a side benefit of making the worker want to report the income, possibly uncovering under-the-table payment schemes.Nobody tell this guy about the Earned Income Tax Credit. Let him think he discovered it.\n \nreply",
      "> That's a more gradual phase-out, but it still is an effective marginal tax rate of 50%+ \u2013 a level that wealthy earners would complain about to no end.Yeah, my wording could have been better. The suggestion that I've seen for UBI is $12k/year (which is clearly not enough to live on in today's economy), with the $2:$1 reduction being only for the UBI, and then standard taxes starting after that.This system was actually proposed a looong time ago (like 1970s, I think). Just by giving everyone a massive tax credit to start with.\n \nreply",
      "> Personally, I'm a big fan of the \"for every $2 you make, you get $1 less from UBI/Welfare\"That's..that's not UBI, at all. UBI is universal. If there are any means tests whatsoever, that's not UBI.\n \nreply",
      "I disagree. Universal just implies everyone gets it. If the system includes a gradual fall off, it's still universally applied to everyone, no?"
    ],
    "link": "https://www.openresearchlab.org/studies/unconditional-cash-study/study",
    "first_paragraph": "",
    "summary": "Welcome to the latest episode of Armchair Economists: The UBI Chronicles, an enthralling URL showdown at the go-nowhere rodeo of policy innovation, where everyone disagrees with everything. Today, the enlightened commentariat tackles 'Unconditional Cash Study: first findings available' with the kind of piercing insight usually reserved for YouTube comment sections. We learn that $1000 is neither a ticket to a lavish city apartment nor a magic bullet for higher education, leaving us shocked\u2014<em>shocked!</em>\u2014that free money doesn't solve all personal and systemic socio-economic issues. Meanwhile, grips of bureaucracy, means tests, and the imaginary dangers of work disincentivization haunt discussions like the ghosts of Welfare Past, gluing everyone firmly to their ideological battle stations. So, grab your fiscal popcorn, stay tuned, and remember: no one ever changes their mind on the internet."
  },
  {
    "title": "Reflections on Luck and Skill from the Part Time Poker Grind (thehobbyist.substack.com)",
    "points": 50,
    "submitter": "jjxw",
    "submit_time": "2024-07-22T18:47:23",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=41038188",
    "comments": [
      "His section on volume rings pretty true. I used to play a lot recreationally. And by \"a lot\" I mean probably on the medium-to-high side of recreational, but not even close to pro. Like attending every major regional event and attending WSOP every year for 10 years. Both cash and tournaments. I've stopped because of how much of a tiring grind poker is, and how much time you have to dedicate in order to make it financially rewarding. You need to play -a lot- to get good, and then you need to play a lot as a good player to make money. It is really a lot of work.If you are not a winning poker player (in other words, your long term EV at the table is negative), you're just going to lose money on average, so playing more means losing more. It only makes sense to play in that case if you actually enjoy playing the game and treat your losses as the cost of entertainment.But if you are a winning poker player, you still won't win enough to rely on the income unless you are playing A LOT. And by a lot I mean every day, for hours a day. And even more if you play online because the level of play is so much stronger online than live.And then, even if you are a winning player, and you play a lot, AND you have enough average cash flow to make it worth it, you are still going to have periods where variance wipes you out and you're down for months straight. It's pretty brutal.After all this time, I decided I'd rather get a different hobby than spending so much of my time grinding away in a smoky casino. I just play (infrequent) home games now.\n \nreply",
      "Thanks for your candid report. Not enough people tell it how it is, and everyone thinks they're special.Fact is, a lot of top players also have deals on the side, with brands and ambassador things. I feel you need those deals to make up for the bad runs.I love the game, but the variance can inflate egos and the grind makes other hobbies more attractive.\n \nreply",
      "It's the hardest way to make an easy living.\n \nreply",
      "This is why, for earning money, you should participate in positive sum games like the real economy. Poker is worse than 0 sum, its negative sum.\n \nreply",
      "Perhaps in a casino taking a rake. But if you're playing w/ friends? The good times make it positive sum. Even in a casino, the players can be getting enough utility / enjoyment out of the game that it's positive sum.\n \nreply",
      "Yes you are right but \u201cpros\u201d are playing with rake typically.In a way you can consider poker 0 sum or positive sum depending on the utility you derive from the enjoyment of gambling. But that should also factor in the negative utility from gamblers that lose\n \nreply",
      "Care to elaborate on how the real economy is positive sum and poker is negative sum?\n \nreply",
      "Poker has a rake and the amount of wealth in the system is the money people put on the table (not even factoring in that gambling winnings are taxed). Meaning the total wealth decreases for every hand played in a raked game. Economic transactions and increasing efficiency are positive sum. You can combine pieces of metal into new alloys and machinery which are more valuable than the sum of their parts. This is positive sum. If two people trade they only engage in trade if the transaction is mutually beneficial.\n \nreply",
      "What do you think two poker players still in a hand raising each other are doing? They both still think it\u2019s mutually beneficial. The maths if you have full visibility show it isn\u2019t, but I\u2019d argue that\u2019s the same of the \u201creal\u201d economy too. In the latter example we can point to long-standing increasing income and wealth inequality as a proxy for the house rake at poker.\n \nreply",
      "When two people are continually raising eachother in a poker game they are doing it because there is an probability of winning the pot. It remains zero sum.edit: The economy being positive sum has nothing to do with the way wealth is distributed.\n \nreply"
    ],
    "link": "https://thehobbyist.substack.com/p/800-85k-in-72-hours-reflections-on",
    "first_paragraph": "",
    "summary": "On <em>The Hobbyist</em>, another keyboard warrior delineates the Herculean trials of making pennies through poker, emphasizing heavily on the revelatory concept that \"it's hard work.\" Who knew? Commenters leap into the fray, armed with economics degrees from the University of Common Sense, arguing intricately about whether poker is a financially masochistic void or a thrilling roller-coaster with financial dips outweighed by psychological highs. Spoiler: it\u2019s both, and neither; the comment section remains an echo chamber of broken dreams and misread economics textbooks. \ud83c\udccf\ud83d\udc94\ud83d\udcb8"
  },
  {
    "title": "What Would You Do with a 16.8M Core Graph Processing Beast? (nextplatform.com)",
    "points": 13,
    "submitter": "rbanffy",
    "submit_time": "2024-07-18T09:55:12",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=40994050",
    "comments": [
      "Zooming in on a boundary section of the Mandelbrot set will fuck it up depending on how fast you want it to.  Displaying associated Julia sets from the focus in a fly out will simply enhance the fun!\"That\u2019s just the time we live in now.\" - no it isn't.  That beastie might be handy for something in the future but it isn't \"I\".  It will deliver really fast weather forecasts and that's useful.\n \nreply",
      "Run the UniProt sparql service on it ;) I was lucky to test the yarcdata implementation of sparql on an xmt machine around 2012, super UI but single user.\n \nreply",
      "A relaxing game of Solitaire.Looking at the block diagrams, it looks more like it's a giant mesh router with a few processing cores sprinkled on top, Salt Bae style. After all, the cores take up just over 4% of the transistors. Not sure if that includes the 4MB per-core scratchpad though.\n \nreply",
      "Rasterize Quake\n \nreply",
      "Pffft, run Crysis in 8K\n \nreply",
      "surf the web\n \nreply",
      "Maybe finally get Numbers on Mac to load a CSV.\n \nreply",
      "I think expanding native parallel execution on the broadcast operator in Julia.Then stare in disbelief... lol =3\n \nreply"
    ],
    "link": "https://www.nextplatform.com/2023/09/01/what-would-you-do-with-a-16-8-million-core-graph-processing-beast/",
    "first_paragraph": "",
    "summary": "**What Would You Do with a 16.8M Core Graph Processing Beast?**\n\nIn a world desperate for more power to poorly render fractals and play nostalgic video games, tech enthusiasts drool over a so-called 16.8M core \u201cgraph processing beast.\u201d It's the equivalent of using a rocket to open a can of beans but hey, who's counting the overkill? Commenters, deeply embroiled in fantasies of running Crysis in 8K and achieving smooth performance on Numbers for Mac, exemplify the pinnacle of underachieving mediocrity. Forget weather forecasts, let's all watch Mandelbrot sets flutter as we ponder whether this marvel can *finally* surf the web without a hitch."
  },
  {
    "title": "A Formulation of the Trilemma in Proof of Work Blockchain (ieee.org)",
    "points": 42,
    "submitter": "bikenaga",
    "submit_time": "2024-07-22T17:35:06",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41037079",
    "comments": [
      "Vitalik Buterin, one of Ethereum\u2019s co-founders, is credited with this trilemma, and this (AFAICT) is where he first posted about it:    The trilemma claims that blockchain systems can only at most have\n    two of the following three properties:\n\n      * Decentralization (defined as the system being able to run in a \n        scenario where each participant only has access to O(c) resources, \n        i.e. a regular laptop or small VPS)\n      * Scalability (defined as being able to process O(n) > O(c) transactions)\n      * Security (defined as being secure against attackers with up to O(n) resources)\n    \n     In the rest of this document, we'll continue using c to refer to the size\n     of computational resources (including computation, bandwidth and storage)\n     available to each node, and n to refer to the size of the ecosystem in some\n     abstract sense; we assume that transaction load, state size, and the market cap\n     of a cryptocurrency are all proportional to n. The key challenge of scalability\n     is finding a way to achieve all three at the base layer.\n\n* https://vitalik.eth.limo/general/2017/12/31/sharding_faq.htm...\n \nreply",
      "The CAP theorem is a precursor of that, even if they are different [1][2][3] and Micali from Algorand claims they solved it (it is included in the original article).[1] https://www.reddit.com/r/kaspa/comments/18ieda0/there_is_a_f...[2] https://dl.acm.org/doi/10.1145/3615871[3] https://x.com/0xmert_/status/1748768344080023805?s=46\n \nreply",
      "I feel like there's a way to directly derive the blockchain trilemma from the CAP theorem (or probably the more formal PACELC).  Reasoning through it in my head makes sense so I've been saying that it's a corollary to CAP but I haven't actually seen it written out formally.\n \nreply"
    ],
    "link": "https://ieeexplore.ieee.org/document/10549891",
    "first_paragraph": "",
    "summary": "**Clash of the Titans: Blockchain Boogaloo**\n\nIn the latest episode of blockchain enthusiasts missing the forest for the trees, a riveting discourse unfolds on the vaunted \"block Taliban,\" I mean \"trilemma.\" Enlightened commenters, thriving in their natural habitat of unfounded certainty, dive headfirst into this buzzword soup. Vitalik Buterin is knighted as Crypto Confucius for his musings on decentralized woes. Meanwhile, armchair theorists vigorously nod to each other, debating whether this grand puzzle was secretly solved by Schr\u00f6dinger\u2019s cat. Surely, \"Decentralize, Scale, Secure \u2014 Pick Two\" will be the epitaph on the tombstone of practicality. \ud83d\udcbb\ud83d\udd10\ud83d\udcc9"
  },
  {
    "title": "Another intermediate-mass black hole discovered at the centre of our galaxy (uni-koeln.de)",
    "points": 42,
    "submitter": "croes",
    "submit_time": "2024-07-22T17:34:07",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41037065",
    "comments": [
      "The problem I have with this article is that it doesn't list the estimated mass.You need to go to the paper's abstract to see that it's around 30,000 times the mass of the sun (\u223c3 \u00d7 10^4M\u2299). For context Sag A* (the supermassive black hole at the center of the Milky Way) is about 4.1 Million times the mass of the sun.\n \nreply",
      "For a system this small and a black hole this big, the smoking gun evidence would be a time lapse showing the stars orbiting a point with \u201cnothing\u201d there.The evidence they presented in the paper is mostly circumstantial \u2014 essentially a statistical analysis.We have this video for Sagittarius A* : https://www.eso.org/public/videos/eso1825e/I\u2019m guessing that in a few years we\u2019ll have a similar video of this area too.\n \nreply",
      "That's the issue with timelapse of this scale. It takes many years to get a good look at it. Even in the video you linked took 20 years.\n \nreply"
    ],
    "link": "https://portal.uni-koeln.de/en/universitaet/aktuell/press-releases/single-news/another-intermediate-mass-black-hole-discovered-at-the-centre-of-our-galaxy",
    "first_paragraph": "\nchange language\n\nDeutschDeutsch\n\n\n\n\n\n\t\t\t\t\t\t\t07/18/2024\n\t\t\t\t\t\t\n\n\n\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tAstronomie\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\n\nSo far, only about ten intermediate-mass black holes have been discovered in the entire universe / The newly identified black hole causes surrounding stars in a cluster to move in an unexpectedly orderly wayWhile researching a cluster of stars in the immediate vicinity of the supermassive black hole SgrA* (Sagittarius A*) at the centre of our galaxy, an international team of researchers led by PD Dr Florian Pei\u00dfker has found signs of another, intermediate-mass black hole. Despite enormous research efforts, only about ten of these intermediate-mass black holes have been found in our entire universe so far. Scientists believe that they formed shortly after the Big Bang. By merging, they act as \u2018seeds\u2019 for supermassive black holes. The study \u2018The Evaporating Massive Embedded Stellar Cluster IRS 13 Close to Sgr A*. II. Kinematic structure\u2019 was published in The Astrophysical Journal.Th",
    "summary": "In an awe-inspiring display of cosmic irrelevance, a group of astronomers, led by PD Dr. Florian Pei\u00dfker, have stumbled upon what they claim is a new intermediate-mass black hole, joyously adding to the universe's tally of ten. These cosmic underachievers, believed to be the Big Bang's rebellious teenagers, supposedly shuffle stars around in \"unexpectedly orderly\" dances near the galaxy\u2019s celebrity, Sagittarius A*. Meanwhile, the comment section devolves into a battleground where armchair astronomers debate the mass details missing from the article and the painstaking wait for a timelapse \u2013 because, apparently, watching paint dry was just <em>too</em> thrilling. Get ready to bookmark and forget another kinematic structure paper in your quest to sound smart at dinner parties. \ud83c\udf0c\ud83d\udd73\ufe0f"
  },
  {
    "title": "Planck stars, White Holes, Remnants and Planck-mass quasi-particles (arxiv.org)",
    "points": 34,
    "submitter": "ngrilly",
    "submit_time": "2024-07-22T20:05:42",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41039213",
    "comments": [
      ">A local dark matter density of the order of 0.01M\u2299/pc3 corresponds to approximately one Planck-scale white-hole per each 10.000Km3. These objects are presumably moving fast with respect to our local frame, since we are rotating with the galaxy at hundreds of Km per second, while dark matter probably isn\u2019t.Anyone know why dark matter wouldn't be rotating along with the rest of the galaxy?\n \nreply",
      "Lots of people seem to talk about things being a contributor to dark matter. Is the general vibe that it's made of more than one thing?\n \nreply",
      "The general vibe is that (1) \"dark matter\" is absolutely required to explain observed velocity distributions in the universe at every scale larger than a few thousand stars and (2) nothing we've observed so far can be it.  So... sure.  Maybe all these ideas are right, though probably not.  But something has to be it, so we might as well keep throwing darts until something lands.\n \nreply",
      "I want planet nine to be a primordial black hole so we can send a few probes out to orbit it and then chuck stuff into it to learn about quantum gravity.\n \nreply",
      "This is the extreme stereotype of humanity: travel somewhere far away and continue to litter just like you do at home.  No respect for the locals!Worse, since it's far away it doesn't come back to make a bigger problem for you later.\n \nreply",
      "Anything chucked into a black hole becomes either gamma rays or more black hole.\n \nreply",
      "\"This is a review of some recent developments on quantum gravity aspects of black hole physics. In particular, we focus on a scenario leading to the prediction of the existence of a Planck-mass quasi-stable object, that could form a component of dark matter.\"\u2014 Carlo Rovelli & Francesca Vidotto (the authors)\n \nreply",
      "A.K.A. a \"white hole.\"He talks about this in a recent World Science Festival video: https://www.youtube.com/watch?v=WuaSoTyqrTA\n \nreply",
      "As long as they aren't photino birds. -- Stephen Baxter, probably [1].1. https://en.wikipedia.org/wiki/Ring_(Baxter_novel)\n \nreply",
      "Between him and Alastair Reynolds I've become very tired of getting to the end of huge novel series and having the ending make me feel like none of the events mattered.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2407.09584",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n",
    "summary": "In the latest intergalactic episode of \"Throw Science at the Wall and See What Sticks,\" devout worshippers at the altar of arXiv proffer a smorgasbord of cosmological spaghetti against the refrigerator of the universe, hoping something will chill enough to explain dark matter with \"Planck-mass quasi-stable objects.\" Despite their valiant attempts to rope in every sci-fi concept they\u2019ve ever adored, the comment section <em>clearly</em> outpaces them in fantastical theories, arguing whether dark matter feels lonely and doesn't want to rotate with the galaxy, or if we should start treating black holes as our personal trash bins because, let's face it, planetary-scale littering wasn't enough\u2014we need to go cosmic. After all, what's a discussion about unobservable quasi-particles without chucking in a magnetic Planck star for good measure? Forget about tying up loose ends; throw a black hole at them! \ud83c\udf0c\ud83d\udcab\ud83d\udeae"
  },
  {
    "title": "Show HN: OpenDataCapture an electronic data capture platform for data collection (github.com/douglasneuroinformatics)",
    "points": 45,
    "submitter": "gdevenyi",
    "submit_time": "2024-07-22T17:43:10",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41037177",
    "comments": [
      "I like the gateway concept as an alternative to opening the firewall. Are there any plans to add FHIR compatibility, for integrating with other FHIR systems?\n \nreply",
      "> I like the gateway concept as an alternative to opening the firewall.Cheers, it was a real revelation when we worked out how to do it!> Are there any plans to add FHIR compatibility, for integrating with other FHIR systems?We've definitely looked at such standards and systems but they seem to be targeted towards EHR data exchange and we are explicitly not an EHR. Our target is structuring research and research clinical data. The summary tool at the end of each instrument is designed to produce reports which can be fed into classic digital paper style EHRs where real clinical record keeping is required.\n \nreply",
      "Not utilizing FHIR b/c you think EHRs will (a) consume your proprietary reports, and (b) be a downstream data system seems a big footgun. Additionally, while FHIR isn\u2019t quite right for many research use cases, there are ongoing efforts such as mCODE [0], that use FHIR as a base because it is not proprietary and highly specified.Maybe your EDC has other awesome characteristics. Based on the interest I\u2019ve seen the FHIR ingestion of REDCap [1] is a winner for research nurse efficiency.0. https://build.fhir.org/ig/HL7/fhir-mCODE-ig/1. https://www.project-redcap.org/\n \nreply",
      "Right now, we're building first to address the needs of our institution, there's no FHIR enabled software there, and the clinicians make a direct request to generate reports for ingestion into their existing EHR system, so we oblige.Interoperability is on our roadmap.Meanwhile, we don't consider RedCap a competitor, the old-school LAMP stack is showing its age, and its \"closed source\" by most interpretations, including a hostile  position on external developers.We welcome contributions to accelerate FHIR support.\n \nreply",
      "The Open Data Capture platform has a nice and modern interface. Its longitudinal data model is a useful feature for continuous clinical and research data collection, offering more flexibility compared to other EDC platforms tied to rigid study time points. I also found the instrument playground easy to use.\n \nreply",
      "The instrument playground is really cool, though I\u2019m not sure who the audience for that is\n \nreply",
      "Thanks! I had a lot of fun building it.Basically, the target audience is people who have some experience programming, but who are not actual developers and have no experience in JavaScript land. There are a lot of graduate students at our institution that fit this description (e.g., some experience hacking together scripts in Python). The goal is for semi-technical users to be able to create forms in a JSON-like way, and for more experienced users to be able to implement whatever they can think of.Also, I wanted to extract our build tooling into something that people can use without understanding anything about module bundling or needing to use a CLI (which the target users often find scary).\n \nreply",
      "Right now, our team to build and test instruments before importing them into the platform or committing them to the main source.In general the admin team who would be supporting the deployment of the software.\n \nreply",
      "its slow to load, also considering this is hospital data is this HIPPA and GDPR compliant?\n \nreply",
      "> its slow to loadWe're using free cloud resources which also host our internal collaboration infra, its definitely underpowered.> considering this is hospital dataTo be clear, our first target audience is research data collection, which is consented, so that's not immediately an issue, however we don't store Personally Identifying Data (PID) in the current design, instead hashing all ID data. Our institution and local laws are very happy with that. We aim for compliance with other statutes going forward.\n \nreply"
    ],
    "link": "https://github.com/DouglasNeuroInformatics/OpenDataCapture",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An electronic data capture platform designed for administering remote and in-person clinical instruments\n      \n    An electronic data capture platform designed for administering remote and in-person clinical instruments\n    \n\nExplore the docs \u00bb\n      \n\n\n\nReport Bug\n    \u00b7\n    Request Feature\n    \u00b7\n    Instrument Playground\n    \u00b7\n    View Demo\n\n\nOpen Data Capture is a web-based platform designed for continuous clinical data collection. The platform is centered on the concept of an instrument. Broadly defined, an instrument refers to any tool that can be used to collect data (e.g., forms, interactive tasks).Assuming that Docker and Docker Compose are already installed on your system, you can deploy an instance of Open Data Capture using the following command:By default, the application will run on port 5500. So, navigate to http://loc",
    "summary": "**Show HN: OpenDataCapture - the latest DIY abyss for data**  \nHere comes another earth-shaking entry into the overflowing sea of data collection tools: OpenDataCapture, promising to be your go-to solution for all that clinical data you never knew you needed to collect. While developers brag about \"instrument playgrounds\" and deploying with Docker as if they found fire, the user base is left scratching heads over basic compliance and interoperability features. Don't worry, though \u2014 real clinical settings won't touch it yet, but at least the grad students \"hacking together scripts\" in their dimly lit dorm rooms are thrilled. Cheers to reinventing the wheel, one undefined user need at a time! \ud83c\udf89\ud83d\udd27"
  },
  {
    "title": "A Man Who Thought Too Fast (2020) (newyorker.com)",
    "points": 60,
    "submitter": "Anon84",
    "submit_time": "2024-07-22T18:38:25",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=41038055",
    "comments": [
      "https://archive.is/zimBx\n \nreply",
      "(2020)Discussion then: https://news.ycombinator.com/item?id=23011233\n \nreply",
      "The headline reminds me of why Isaac Asimov was bad at chess (start at \"In 1994, Isaac Asimov's last autobiography\"): <http://billwall.phpwebhosting.com/articles/Asimov_chess.htm>\n \nreply",
      "> The conclusion that I finally came to (right or wrong) was that I was unwilling to study the chessboard and weigh the consequences of each possible move I might make. Even people who couldn't see complex patterns might at least penetrate two or three moves ahead, but not I. I moved entirely on impulse, if not at random, and could not make myself do anything else. That meant I would almost certainly lose.> And again - why? To me, it seems obvious. I was spoiled by my ability to understand instantly, my ability to recall instantly. I expected to see things at once and I refused to accept a situation in which that was not possible.Interesting. I was also fairly bad at chess as a kid, and my self-diagnosis was similar. I found \"checking\" all the possible moves too tedious, so I just did the first one that looked promising, to terrible effect.I've tried to play a little as an adult, and now I have more patience, but that means I find chess too stressful! I don't want to go until I'm fairly sure I have a good move, but I still can't quite \"check\" all the possible moves, so I sweat the whole time and don't enjoy playing.\n \nreply",
      "In real life, you've always got to go with your gut. But in chess you have perfect prescience: there is a very limited set of parameters, and things can only occur within them. Its good training for real life, since you can have both foresight and risk, and for me at least I always have a multitude of different plans about both my near and far future sitting somewhere in the back of my head, switching between and adjusting them depending on the circumstances that arise.\n \nreply",
      "I also agree chess is tedious. I feel the same way about Sudoku.While I enjoy coming up with algorithms as part of my living, I take little pleasure in executing them myself (beyond testing and a few thought exercises to find the right solution).But as a counterpoint, I thoroughly enjoy games where I build something based on resources I myself have aquired. Whether it's voxels or virtual scrap piles, it is gratifying to earn what I build with.\n \nreply",
      "Thanks for sharing, I have the same experience with chess, and have never liked it for the same reasons. There's no mediocre version of chess that you can do instinctively, and I don't really like to do tedious and repetitive mental work when playing games.I just suck at chess, and have given it up, as it's something that's not for me. I can play some decent poker though (not really great, just better than chess).\n \nreply",
      "needs (2020)\n \nreply",
      "> Ramsey theory tells us, for instance, that among any six users of Facebook there will always be either a trio of mutual friends or a trio in which none are friends.AKA Ramsey's Theory of the Bleedin' Obvious.\n \nreply",
      "The proof of that particular case goes like this:Pick one of the six users. Split the other 5 users into friends and non-friends of the chosen user. There will either be at least 3 friends or at least 3 non-friends of the chosen user. If you can pick 3  friends of the chosen user then if any two of them are friends they plus the original user form a trio of mutual friends. If none of the 3 are friends then you have a trio in which none are friends. Similarly, if you can pick 3 non-friends of the original user then either two of them are non friends and you have a trio of non friends or all three are friends, forming a trio of mutual friends.It's easy to prove but I don't think I'd quite call it \"bleedin' obvious\". Ramsey's theorem [1], of course, is more general than that and isn't at all obvious (although it's still not very hard to prove).[1] https://en.m.wikipedia.org/wiki/Ramsey%27s_theorem\n \nreply"
    ],
    "link": "https://www.newyorker.com/magazine/2020/05/04/the-man-who-thought-too-fast",
    "first_paragraph": "Find anything you save across the site in your account \u201cThe world will never know what has happened\u2014what a light has gone out,\u201d the belletrist Lytton Strachey, a member of London\u2019s Bloomsbury literary set, wrote to a friend on January 19, 1930. Frank Ramsey, a lecturer in mathematics at Cambridge University, had died that day at the age of twenty-six, probably from a liver infection that he may have picked up during a swim in the River Cam. \u201cThere was something of Newton about him,\u201d Strachey continued. \u201cThe ease and majesty of the thought\u2014the gentleness of the temperament.\u201dDons at Cambridge had known for a while that there was a sort of marvel in their midst: Ramsey made his mark soon after his arrival as an undergraduate at Newton\u2019s old college, Trinity, in 1920. He was picked at the age of eighteen to produce the English translation of Ludwig Wittgenstein\u2019s \u201cTractatus Logico-Philosophicus,\u201d the most talked-about philosophy book of the time; two years later, he published a critique of",
    "summary": "In a classic New Yorker swoon, a ripple of intellectual nostalgia brings us \"\ud83c\udf1f A Man Who Thought Too Fast \ud83c\udf1f\" because if you're not mulling over a failed polymath who swam in too many informational streams and possibly in one too many literal ones, are you even indulging in highbrow ephemera? The commenters, in a tizzy of semi-related anecdotes, compete in understatement Olympics, with gems about bad chess moves and tedious Sudoku that somehow parlay into life's big lessons on strategy and mediocrity. It\u2019s truly a spectacle of minds that perhaps think too fast or not much at all, yet spoil us with their fearless embrace of boredom draped as intellectual engagement. Each thread derails further into the abyss of utterly missing points, the perfect homage to internet commentary culture, where the only winning move is not to play."
  },
  {
    "title": "Glasgow 2024 Hugo Awards Statement \u2013 22 July, 2024 (glasgow2024.org)",
    "points": 67,
    "submitter": "choult",
    "submit_time": "2024-07-22T20:47:44",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=41039644",
    "comments": [
      "Cost analysis:The administrators identified 377 ballots and associated memberships as fraudulent. Assuming all fraudulent memberships were new, the minimum cost per voting membership is \u00a345 [1]. Total cost assuming no additional undetected memberships: \u00a316,965 or just under $22,000 at current exchange rates.Unfortunately current discussions of the marketing value of a Hugo Award have been somewhat drowned out by those who think the fan value of a Hugo is not as high as it once was, but it's not an influential award; if it's true that a Hugo Award for Best Novel generates a thousand or so additional sales, it's hard to make the economics of buying a Hugo make sense.[1] https://glasgow2024.org/for-members/memberships-and-tickets/, WSFS Membership.\n \nreply",
      "You\u2019re right, it\u2019s uneconomic to manipulate the vote this way. However, if recent history is anything to go by, the motivation here is political, not economic.\n \nreply",
      "One would think so, but, having read all the fiction nominees this year, I can't think of any who would have an obvious political agenda to back them.One possibility I could think of is a certain state trying to boost their up and coming Science Fiction industry, but even that seems a rather far fetched prospect.\n \nreply",
      "\"I got a Hugo\" is probably worth something in negotiations with traditional publishers; exactly which award is being stuffed is not mentioned. If you're up for, say, \"Best Fan Writer\" and are looking for a traditional publisher then it's starting to look attractive, if you can think of a clever way to cover the costs.\"Prove you voted for me and you get access to a big download of everything I made in the past decade, which would cost $300 to buy normally\" comes to mind as a way to cover a chunk of that. Crowdfunding!\n \nreply",
      "You can stick \"Hugo award winning author\" on the cover of the next twenty crappy novels you write which might bring that total up a little.\n \nreply",
      "How many future sales, speaking gigs, etc. does being a \"Hugo-winning author\" open up?\n \nreply",
      "I expect very little of that makes much money.\n \nreply",
      "I read a lot of SFF, but the actual Hugo / Nebula winners don't really move up in my reading list compared to the other nominees.Maybe the \"winner\" sticker drives some paper book sales?\n \nreply",
      "To offer a counter anecdote: for a while I enjoyed reading books from the list of joint winners of the Hugo and Nebula awards[1] - and later from the list of winners for a single award (same, Hugo or Nebula).[1]: https://en.wikipedia.org/wiki/List_of_joint_winners_of_the_H...\n \nreply",
      "Some? Not a ton.https://humanlegion.com/hugo-award-sales-figures/ has some data for one year. \"They do have an effect, but probably no more than a few thousand sales for most books, maybe over ten thousand for the luckiest, and then only in exceptional years.\"\n \nreply"
    ],
    "link": "https://glasgow2024.org/hugo-awards/statement-22-july-2024/",
    "first_paragraph": "Home / Hugo Awards22 July, 2024The Glasgow 2024 Hugo Administration Subcommittee, led by Hugo Administrator Nicholas Whyte, has today issued the following statement. You can also watch a corresponding announcement video.In the course of tallying the votes on the final ballot for the 2024 Hugo Awards, the Glasgow 2024 Hugo Administration team detected some unusual data.\u00a0Paragraph 6.2 of the WSFS Constitution states that \u201cIn all matters arising under this Constitution, only natural persons may introduce business, nominate, or vote, except as specifically provided otherwise in this Constitution. No person may cast more than one vote on any issue or more than one ballot in any election.\u201dA large number of votes in 2024 were cast by accounts which fail to meet the criteria of being \u201cnatural persons\u201d, with obvious fake names and/or other disqualifying characteristics. These included, for instance, a run of voters whose second names were identical except that the first letter was changed, in a",
    "summary": "<b>Glasgow 2024: Turbocharged Tears in the Hugo Administration</b>\n\nIn an earth-shattering scoop from the Hugo Awards, Glasgow's top bean counters discover that K.I.T.T. and his pals from your teenage fantasy AI garage band have been spamming the vote box, not knowing that robotic charisma doesn't translate into 'natural personhood'. The commenters, swirling in a whirlpool of naivety, propose economic theories, conspiracy theories, and every theory in-between from their armchairs, hypothesizing the breathless political espionage saga hiding behind this year's Best Sci-Fi Naptime Story. Any takers for the next Hugo Award-Winning 'How to Spot a Fraudulent Voter' manual? Available soon at a conspiracy theory near you! \ud83d\ude02\ud83d\udcda\ud83d\ude80"
  }
]