[
  {
    "title": "Egoless Engineering (egoless.engineering)",
    "points": 244,
    "submitter": "mcfunley",
    "submit_time": "2024-12-03T20:38:23 1733258303",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=42311069",
    "comments": [
      "An ageless idea...  \"There once was the first software engineering best-selling book. It was called The Psychology of Computer Programming (Weinberg 1971). There was a peculiar idea contained among the many excellent ideas of that book. It was the idea that the task of programming should be egoless. Programmers, the author said, should not invest their ego in the product they were building. \n  ...\n\n  What\u2019s the alternative to an ego-invested programmer? A team-player programmer. \n  The team player sees the software product as a team effort and a team achievement. Error reports and reviews and questions become team inputs to help improve the product, not threatening attacks to derail progress.\n  ...\n  But after further thought, this notion begins to unravel. It is all well and good to advocate egoless programming, but the fact of the matter is that human ego is a very natural thing, and it is difficult to find people who can\u2014or even should\u2014divorce their ego from their work.\n  ...\n  A system that works will have to acknowledge fundamental human traits and work within the bounds they create. And ego is one of those traits.\n  \"\n - 'Facts and Fallacies of Software Engineering', Robert Glass, 2002\n \nreply",
      "People may bring ego into programming because of some kind of pathology (eg the need to always be right or in control) but I think in many cases it's because they truly care about the work. And the problem is not that they truly care, but that there is a mismatch between the amount of influence/control/autonomy they wish to exert on their work and the amount they are actually able to exert on it.I wasn't there, but my understanding is that essentially all programming in 1971 was done in large corporate settings or universities/research institutions. Those are environments where it's rare for any individual (even someone nominally in charge of a project) to have full creative and technical control over something, and even when they do, it only lasts as long as the project/grant or until their employer puts them on something else.Compared to the 70s there are effectively no barriers to a passionate engineer starting their own software project as either an open source project or in their own startup, and I'd argue that those are settings where it's actually highly beneficial to bring ego into programming. It's pretty much the same notion as \"founder mode\" or why BDFL is one of the most popular forms of governance for FOSS.Personally I'd recommend anybody who \"brings ego\" to their dayjob to take a stab at FOSS or a startup rather than trying to fit a square peg (caring a lot about their work) into a round hole (the realities of working on large projects).\n \nreply",
      "Sometimes a person's dedication and care expresses itself to others as ego.  Sometimes it is just ego.I think we've all implemented some clever trick in our code that we started to feel proud of. It's hard not to do. Even if you just contribute to a small piece of the project, you still might have those instances of pride. We're all human, and it's fine to take a little motivation from your accomplishment. But hold on loosely. Be critical of your baby and be willing to throw it out if it isn't the best approach.I used to really like driver/embedded programming because it seemed like there was a 'best approach' or idiomatic solution for most problems that eliminated ego.  It felt more like electrical engineering. I often felt programmers working on higher level software treated their work like a personal art project and that turned me off from it.\n \nreply",
      "The problem with \"ego\" as a concept IMO is that it carries negative connotations with most people and isn't exactly well-defined - some people might see it as always a bad thing (I think you might fall into this camp given that your phrasing \"dedication and care expresses itself to others as ego\" rather than saying it merely is ego). Personally I think that that is ego, but that ego is not necessarily a bad thing.There is nothing wrong with taking pride in your work, nor in recognizing that you might actually be more knowledgable/skilled/correct in some particular matter than someone else and communicating that to them  - as long as that sense of knowledge/skill/correctness is not misplaced, not expressed cruelly, and the actual reasoning is explained. To me, that is \"good ego\". But if someone thinks they always know better than someone else in all cases or isn't even willing to open discourse/explain why that's \"bad ego\".I guess to me, the sentiment expressed in this article is one that I feel strays too far into the realm of toxic positivity or crabs-in-a-bucket where merely being opinionated or passionate about your work is a bad thing because sometimes other people get their feelings hurt when you explain why their approach won't work well. I just don't think being egoless is necessarily good. I certainly wouldn't sit there smiling while something I worked on for years got destroyed by other people, because it'd be impolite or egotistical to point out that they're destroying something. But of course, there is a difference between something actually getting ruined, and having a meltdown because someone started naming variable in snake_case instead of camelCase.\n \nreply",
      "I would argue that in fact you do need a critical mass of ego throughout the ranks of engineers in a large organization.  An engineering culture where engineers don't care inevitably leads to abdicating responsibility for overall system health and even data/workflow correctness as PMs attempt to steer the ship without understanding the implications of what they are asking for.  Once this has gone on for a while, the system will be so intractably broken, and the dead sea effect will have caused such a brain drain of all those capable of fixing the problems, that at some point there's no economical path to restoring the software systems to a healthy and maintainable state.  At that point you might as well just call in the private equity guys and figure out how to extract maximum cash out of the business as it stands, because any code change becomes more likely to break more things than it improves.So yeah you need ego.  That said, it must also be tempered with the reality of needing to compromise enough to satisfice all stakeholders (including both technical and business stakeholders of all the different flavors).  The beautiful thing about software engineering though, is there is a reasonable amount of objective facts, metrics and tradeoffs, that given a critical mass of sufficiently skilled and mature engineers, common ground tends not to be too hard to align on.  Or at least, far easier than to get a non-technical stakeholder to understand the long-term implications of a bad decision.\n \nreply",
      "Check out Hackers, by Steven Levy, for some fun tales from early in computing.\n \nreply",
      "Well the \u2018pathology\u2019 is clear, isn\u2019t it?They\u2019re not actually smart enough to keep track of what every other team is doing, at any point in time.FOSS works because there\u2019s usually only at most a few dozen balls in the air simultaneously, so someone who believes they can keep track of balls in the air gets by without looking ridiculous.But that\u2019s just not viable when there are hundreds or thousands of balls in the air simultaneously\u2026 their eye muscles literally couldn\u2019t move and focus fast enough.\n \nreply",
      "I think FOSS really only works well for infrastructure type of projects, things where the customers are downstream programmers or at the very least very technical sysadmin types and power users who can understand the gory details to some reasonable depth.  Those projects work because they are centered around proven abstractions that are broadly applicable, thus allowing for a tight charter and some stability in requirements.End user software by comparison, has not really been successful in the FOSS model.  There have been many attempts, but they perenially lag behind commercial offerings, and thus primarily see adoption from the ideologically motivated and/or very cost sensitive users.\n \nreply",
      "I've noticed that some of the worst ego-related issues arise from people who care the most about their work -- the craftspeople, if you will. There is a type of person who will pour their entire soul into creating the most ideal expression of whatever it is they are trying to do. Sometimes that level of investment is warranted and even required. But mixed together with others who don't -- or can't -- operate that way, that's what leads to trouble.I've seen this manifest as long and scathing code reviews, attitudes of \"give me that; I'll do it myself,\" low morale, burnout... I've never found an adequate solution. Sometimes it was my ego that was the catalyst in a situation. I recognize it now, could I have caught it earlier?\n \nreply",
      "I'm not entirely convinced that ego-less is even a better way of doing things. Sure, the ego can go overboard but it also gives a sense of drive and direction. It isn't just the bad stuff. Without it, there's nobody taking ownership of the design or it's just designed by an apathetic committee.\n \nreply"
    ],
    "link": "https://egoless.engineering",
    "first_paragraph": "\n        Like many of you, I was raised in the background radiation of Calivinist thought.\n        I expected little but redemptive hard labor, before presumably one day dying in a mine.\n        I also read Hackers & Painters at an impressionable age and was kind of a jerk\n        about it for a while. This talk is about how despite this, I got better.\n      \n        The real urtext of my tradition was two\n        people standing on stage explaining how although they have different jobs, they\n        are friends, and try to help each other. It was mindblowing at the time and led to many\n        subsequent revelations, and ultimately a blissful state of psychic death.\n        It turns out misery is a shitty proxy metric.\n      \n        Here are some other talks and\n        my website.\n      \n        Thanks to many folks who have inspired me over the years but particularly\n        Coda Hale, Kellan Elliot-McCrea, Camille Fournier, and Marc Hedlund.\n      Check out my other clubs\n        ",
    "summary": "In an exhilarating display of originality, <em>Egoless Engineering</em> swoops in to revolutionize the tech world by recycling a concept older than the floppy disk. In what could easily be a lost Monty Python sketch, the author reminisces about the life-altering impact of discovering that colleagues can, in fact, be friends. Commenters leap into action, armed with their personal anecdotes, hinting that maybe, just maybe, treating software as a personal art project isn\u2019t conducive to team harmony. Brace yourself for the profound insight that humans have egos and classic literature exists. Who knew? \ud83e\udd2f"
  },
  {
    "title": "Intel announces Arc B-series \"Battlemage\" discrete graphics with Linux support (phoronix.com)",
    "points": 288,
    "submitter": "rbanffy",
    "submit_time": "2024-12-03T17:19:37 1733246377",
    "num_comments": 467,
    "comments_url": "https://news.ycombinator.com/item?id=42308590",
    "comments": [
      "Why don't they just release a basic GPU with 128GB RAM and eat NVidia's local generative AI lunch? The networking effect of all devs porting their LLMs etc. to that card would instantly put them as a major CUDA threat. But beancounters running the company would never get such an idea...\n \nreply",
      "Disclosure: HPC admin who works with NIVIDA cards here.Because, no. It's not as simple as that.NVIDIA has a complete ecosystem now. They have cards. They have cards of cards (platforms), which they produce, validate and sell. They have NVLink crossbars and switches which connects these cards on their card of cards with very high speeds and low latency.For inter-server communication they have libraries which coordinate cards, workloads and computations.They bought Mellanox, but that can be used by anyone, so there's no lock-in for now.As a tangent, NVIDIA has a whole set of standards for pumping tremendous amount of data in and out of these mesh of cards. Let it be GPU-Direct storage or specialized daemons which handle data transfers on and off cards.If you think that you can connect n cards on PCIe bus and just send workloads to them and solve problems magically, you'll hurt yourself a lot, both performance and psychology wise.You have to build a stack which can perform these things with maximum possible performance to be able to compute with NVIDIA. It's not just emulating CUDA, now. Esp., on the high end of the AI spectrum (GenAI, MultiCard, MultiSystem, etc.).For other lower end, multi-tenant scenarios, they have card virtualization, MIG, etc. for card sharing. You have to complete on that, too, for cloud and smaller applications.\n \nreply",
      "I have been hacking on local llama 3 inference software (for the CPU, but I have been thinking about porting it to a GPU) and would like to do a rebuttal:https://github.com/ryao/llama3.cInference workloads are easy to parallelize to N cards with minimal connectivity between them. The Nvlink crossbars and switches just are not needed.In particular, inference can be divided into two distinct phases, which are input processing (prompt processing) and output generation (token generation). They are remarkably different in their requirements. Input processing is compute bound via GEMM operations while output generation is memory bandwidth bound via GEMV operations. Technically, you can do the input processing via GEMV too by processing 1 token at a time, but that is slow, so you do not want to do that. Anyway, these phases can be further subdivided into the model\u2019s layers. You can have 1 GPU per layer with the logits passing from GPU to GPU in a pipeline. The GPUs just need the layer\u2019s weights and the key-value cache for all of the tokens in that layer in memory to be able to work effectively. For llama 3.1 405B, there are 126 layers, so that is up to 126 GPUs.That is of course slightly slower than if you just had 1 GPU with an incredible amount of VRAM, but you can always have more than one query in flight to get better than 1 GPU\u2019s worth of performance from this pipeline approach. There are other ways of doing parallelization too, such as having input processing use GEMM to do multiple queries in parallel.In essence, you can connect n cards on PCIe and have them solve inferencing problems magically, with the right software. Training is a different matter and I cannot comment on it as I have not studied it yet.\n \nreply",
      "But all the tricks of developing a solid software stack to support the HW are already out no? The basic principles are there, to my understanding the main challenge is not doing this development in tandem with the HW people and the requirments to support older legacy device which makes it harder for example for Amd to compete. The only challenges,which intel are prepped to face is logistics and fabs.\nOn a separate note, project like JAX are aiming to circumvent that abstraction layer cuda adds to nvidia, so having decent hardware competition is definitely an option. Just some time ago, vllm fully supported amd gpus! We need more competition.\n \nreply",
      "I think he's mostly referring to inference and not training, which I entirely agree with - a 4x version of this card for workstations would do really well - even some basic interconnect between the cards a la nvlink would really drive this home.The training can come after, with some inference and runtime optimizations on the software stack.\n \nreply",
      "Most of the above infra is predicated on limiting RAM so that you need so much communication between cards. Bump the RAM up and you could do single card inference and all those connections become overhead that could have gone to more ram. For training there is an argument still, but even there the more RAM you have the less all that connectivity gains you. RAM has been used to sell cards and servers for a long time now, it is time to open the floodgates.\n \nreply",
      "Correct for inference - the main use of the interconnect is RDMA requests between GPUs to fit models that wouldn't otherwise fit.Not really correct for training - training has a lot of all-to-all problems, so hierarchical reduction is useful but doesn't really solve the incast problem - Nvlink _bandwidth_ is less of an issue than perhaps the SHARP functions in the NVLink switch ASICs.\n \nreply",
      "Rather than tackling the entire market at once, they could start with one section and build from there. NVIDIA didn't get to where it was in a year, it took many strategic acquisitions. (All the networking and other HPC-specialized stuff I was buying a decade ago has seemingly been bought by NVIDIA).Start by being a \"second vendor\" for huge customers of NVIDIA that want to foster competition, as well as a few others willing to take risks, and build from there.\n \nreply",
      "Intel has already bought and killed everything they need to compete here. They seem incapable of sticking to any market that isn\u2019t x86. Likely because when they were making those acquisitions they were drunk on margin and didn\u2019t want to focus anywhere else.\n \nreply",
      "> Disclosure: HPC admin who works with NIVIDA cards here.\n> Because, no. It's not as simple as that.Wow what he said is way above your head! Please reread what he wrote.\n \nreply"
    ],
    "link": "https://www.phoronix.com/review/intel-arc-b580-battlemage#google_vignette",
    "first_paragraph": "",
    "summary": "**Intel Tries Its Hand with \"Battlemage\" and Linux: A Clown Show in Slow Motion**\n\nIn a desperate bid to capture the hearts of three Linux users and a stray cat, Intel announces its new Arc B-series \"Battlemage\" GPUs, hoping someone will notice. Meanwhile, armchair engineers in the comments concoct fantasies about toppling NVIDIA's empire by simply adding a swimming pool's worth of RAM to a basic GPU. Enthusiasts with more GPU documentation than social skills argue the finer points of CUDA emulation, PCIe magic, and why this all matters for running their high-end calculator simulations. The connoisseur of common sense suggests that just making hardware and hoping software and market share magically appears is like hosting a rain dance\u2014fun to do but unlikely to fill any buckets. \ud83c\udfad\ud83d\udcbe"
  },
  {
    "title": "Glojure: Clojure interpreter hosted on Go, with extensible interop support (github.com/glojurelang)",
    "points": 58,
    "submitter": "networked",
    "submit_time": "2024-11-29T09:29:56 1732872596",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42272524",
    "comments": [
      "Clojure hosted on Go is something that I really hope gets more attention. Clojure being built on top of Java is a fine decision, but I would love to use clojure to compose the ever growing library of stable packages that exist in the Go ecosystem.other related packages:\nhttps://joker-lang.org/\nhttps://github.com/nooga/let-go\n \nreply",
      "I get \"panic:\" at the REPL once it loads. :(The implementation of the [HAMT][1]-based vector in Go is [interesting][2].[1]: https://infoscience.epfl.ch/server/api/core/bitstreams/f66a3...[2]: https://github.com/glojurelang/glojure/blob/main/internal/pe...\n \nreply",
      "Clojure hosted in Go: glojureGo hosted in Clojure: clogo?\n \nreply",
      "How about \u201cclogure\u201d where the \u201cg\u201d is pronounced as in \u201cGIF\u201d?\n \nreply",
      "Go hosted in Clojure should be Jo\n \nreply",
      "I like \u201cGlo\u201d\n \nreply",
      "Neat, the macros even work:  (->> \"you\"\n    strings.ToUpper\n    (fmt.Sprintf \"hi %s\"))\n\n   (doto \"hi\"\n    fmt.Println\n    fmt.Println\n    fmt.Println)\n \nreply"
    ],
    "link": "https://github.com/glojurelang/glojure",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Clojure interpreter hosted on Go, with extensible interop support.\n      Try it in your browser! (fair warning: startup on the web is slow)Gopher image derived from @egonelbre, licensed under Creative Commons 1.0 Attributions license.Glojure is an interpreter for\nClojure, hosted on Go. Glojure provides\neasy access to Go libraries, similar to how Clojure provides easy\naccess to Java frameworks.Glojure is in early development; expect bugs, missing features,\nand limited performance. Backwards compatibility is not\nguaranteed until a v1 release. That said, it is used successfully\nin hobby projects and runs a significant subset of\nthe (transformed) core Clojure library.Note that unlike most other Go implementations of Clojure, Glojure is\na \"hosted\" language - a term used to describe languages that are\nimplemented in terms of a host langua",
    "summary": "**Hackernews Crossover Episode: Glojure vs. The World**\n\nIn an exhilarating display of programming eclecticism, bored developers have birthed *Glojure*, the latest Frankenstein's monster of tech, melding Clojure's syntax nirvana with Go's cuddly gopher efficiency. Promising the *'easy access'* to Go libraries that nobody asked for, this abomination is perfect for the three hobbyists desperate for just one more way to write a to-do app. Meanwhile, the comment section morphs into a linguistic battlefield, where devotees toss around name suggestions like \"clogure\" and \"Jo\", each more cringe-worthy than the last. Somewhere, a \"panic:\" at the REPL waits to welcome true enthusiasts into the fold of eternal beta testing. \u26a1\ufe0f\ud83e\udd13\ud83d\udca5"
  },
  {
    "title": "The Tube Computer (thetubecomputer.com)",
    "points": 122,
    "submitter": "elvis70",
    "submit_time": "2024-12-03T18:54:00 1733252040",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=42309790",
    "comments": [
      "Brilliant! and warming. ( literally and figuratively. )\"My family was homeless when I was born. But my parents found work, the council found us a flat, and 20 years later my dad was the managing director of a very large engineering firm, and my parents built a fabulous home.To cut a long story short, much later my parents had a few personal problems, and sadly my mum finally killed herself. I don\u2019t think you ever get over it, you really just learn to live with it.My life then went a bit pear shaped. I trusted bad people and guess what, really bad things happened. Very kind friends managed to put me back on my feet, and then, at 55, I met Judy and her family, and we\u2019ve had the most wonderful 15 years together.So please, what ever happens, please don\u2019t give up.\"\n \nreply",
      "I'd really love to know more about him. That seems super interesting. Also to see this level of creativity after retirement is encouraging.\n \nreply",
      "In my experience, it's more common than we suspect. I've met quite a few people in their 60s with fascinating hobbies. Some of it boils down to the fact that they had many decades to get good - and with career in the rearview mirror and adult children, they have a lot more time, too.But it's also true that with age, you lose the drive to get praise from strangers - so at best, you get a text website viewed by hundreds, not a series of TikTok or YouTube videos viewed by millions. And sometimes, not even that website.When that person dies and leaves behind a man-sized vacuum tube computer, or a collection of vintage calculators, or something of that sort... the heirs usually don't have the willpower to carry on, and because the stuff is impossible to sell, it's often destined for the dump. Maybe a couple of years in a storage unit before that.It's even worse with digital assets. Who's gonna renew that hobby domain or pay that hosting bill? I've seen some really valuable online resources disappear after the author died.\n \nreply",
      "> Who's gonna renew that hobby domain or pay that hosting bill? I've seen some really valuable online resources disappear after the author died.This is why the Internet Archive is so important.\n \nreply",
      "Eh, kinda. It technically preserves content, but it has almost zero discoverability. The site disappears from Google & co, so unless you come across a dead link in some old HN or Reddit thread, you won't even know it's there.\n \nreply",
      "I didn't say it's sufficient, but without the preservation that the Internet Archive does, we'd be completely lost.I have come across some wealth of deeply technical information by entering dead links on still live pages in the wayback machine, and then following crosslinks from there to further old sites. I shudder to think what would have been if I hadn't found the dead links in those cases, and I'm sure I still missed a lot because I didn't know it was there. So yes, this is a very real problem.\n \nreply",
      "From down the tubes to a much more solid state of existence...bravo!\n \nreply",
      "From the website: The person who built this appears to be (at least) 70 years old. Amazing!> My family was homeless when I was born. But my parents found work, the council found us a flat, and 20 years later my dad was the managing director of a very large engineering firm, and my parents built a fabulous home.> To cut a long story short, much later my parents had a few personal problems, and sadly my mum finally killed herself. I don\u2019t think you ever get over it, you really just learn to live with it.> My life then went a bit pear shaped. I trusted bad people and guess what, really bad things happened. Very kind friends managed to put me back on my feet, and then, at 55, I met Judy and her family, and we\u2019ve had the most wonderful 15 years together.> So please, what ever happens, please don\u2019t give up.\n \nreply",
      "Bit of an aside but I wonder how far tube technology might have advanced, without semiconductors intervening.  In the late 1950s and early 1960s, GE, IBM, and RCA, probably other companies, were working on \"integrated tubes\" with many components in a single envelope, as well as techniques for easier and more automated manufacture.  For example, introduced in 1959: https://upload.wikimedia.org/wikipedia/commons/b/ba/Nuvistor...\n \nreply",
      "> Bit of an aside but I wonder how far tube technology might have advanced, without semiconductors intervening.There were Compactrons. There were subminiature vacuum tubes.[1]A one piece printed circuit board of glass, with multiple tubes, might be possible.\nA glass plate made with lots of recesses, electrodes and wiring created by photo-etching like printed circuit boards, a glass plate on top, pumped down to vacuum and sealed. A low-density integrated tube.That's what a plasma panel display is. It's an integrated array of neon lamps. In a vacuum fluorescent display, each illuminated element is a triode vacuum tube. So it's quite possible to fabricate a big array of tubes.Maybe something like a ball grid array would work for external connections.Probably could have been done if necessary. Density probably would have maxed out around the density of elements on on the most dense vacuum fluorescent displays. Maybe devices at 1mm scale, or 1,000,000 nm. Good enough for mainframes and minicomputers, but not microprocessors.[1] https://archive.org/details/The_MIT_Museum_The_Subminiature_...\n \nreply"
    ],
    "link": "https://www.thetubecomputer.com/",
    "first_paragraph": "\u00a0A modern 8 bit design, built with recycled 1950s vacuum tubes, that glow and heat the entire room.\u00a0After a ridiculous amount of soldering,\nand a fantastic amount of fun.The Tube Computer stands on a wall in our home,and is almost safe to touch.\u00a0Almost!Vacuum Tubes require high voltages to work efficiently and are not for the faint hearted. They can switch several hundred million times a second, and in the 1950s they were combined with germanium diodes as the basis for many incredible computer designs.\u00a0The Tube Computer has a modern 8 bit architecture. It is designed to run a simple airship flight sim, flying around Brighton for the grandchildren, or a 64 bit Fibonacci sequence for the grown ups.\u00a0Building tube computers has become an addiction, this is my third! The first ran on 28th May 2021 whist perched on our dining room table, chairs and surrounding floor space. A fairly harmless addiction, I suppose!\u00a0After switch on you have to wait a while for the vacuum tubes to warm up. If you",
    "summary": "In an era where technology strives to be unseen, one brave soul throws efficiency to the wind and resurrects the ghost of computers past with \"The Tube Computer.\" Revel in the nostalgic glow of vacuum tubes, proving once again that modern problems require outdated solutions. Enthusiasts exclaim the dual benefits of data processing and room heating, as both logic and practicality dangle on the edge of obsolescence. Watch as rapt commenters merge tales of tragedy and triumph, seemingly unaware that their digital memories are one unpaid hosting bill away from the abyss. \ud83c\udf1f\ud83d\udd25"
  },
  {
    "title": "Skia Canvas: Browserless implementation of the HTML Canvas drawing API for node (skia-canvas.org)",
    "points": 174,
    "submitter": "DaniAkash",
    "submit_time": "2024-12-03T16:34:18 1733243658",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=42308051",
    "comments": [
      "https://windowjs.org is a very similar concept -- it wraps Skia and exposes it as the Canvas API, but also embeds v8 for a very small runtime instead of using Node.It was my first open-source project, released about 3 years ago.I had plans to also expose WebGL, audio, etc and make it a viable platform for Javascript-based games on desktop.Life and other projects happened instead, and development was discontinued. Happy to see this project also making Canvas accessible outside the browser!\n \nreply",
      "Out of curiosity, what's the use for such library? If you are on a desktop surely there is a better native library to draw shapes, no?\n \nreply",
      "At Soundslice, we have a custom sheet-music-rendering graphics library in frontend JavaScript/Canvas.We also need to generate vector PDFs serverside \u2014 so we use a node library that speaks the HTML Canvas API and can generate PDFs. This way the result is exactly the same as the rendered sheet music in the web browser. Nice!The upshot is: this kind of library allows for code reuse in non-browser contexts.\n \nreply",
      "Is Canvas really suitable for PDFs ? Afaik it's immediate mode bitmap graphics - so PDFs would just be embedded bitmaps ?\n \nreply",
      "We do indeed generate vector PDFs, not embedded bitmaps.Our graphics engine works with Canvas API instructions \u2014 like \"draw a line from point (A,B) to (C,D).\" This API is small enough and low-level enough that it can also generate pristine vector output.That's in fact one of the features of Skia Canvas (vector output in PDF and SVG).\n \nreply",
      "Ah nice didn't know it had a PDF backend - that sounds perfect for this use case.\n \nreply",
      "There isn\u2019t really anything commonly \u201cnative\u201d as powerful as skia for 2D drawing and a big part of skia is using the native graphics effectively, this is why it exists in the first place for browser engines. Besides having one target API is a benefit.\n \nreply",
      "> There isn\u2019t really anything commonly \u201cnative\u201d as powerful as skia for 2D drawingCairo?\n \nreply",
      "I love Cairo, but it\u2019s just not in the same feature or performance ballpark as skia. There\u2019s a reason even Firefox adopted skia. \nSkia is like the V8 of 2D drawing libraries, just a ton of continual investment into optimization. I used to work on cairo and pixman, it\u2019s great, very straightforward but not finely tuned for performance on modern hardware.\n \nreply",
      "Being able to run the same code on multiple platforms is a big bonus. It\u2019s also a very common 2D drawing API. iOS has a native version, Android has a native version, all with more or less the same drawing operations. Leveraging them can pay dividends.\n \nreply"
    ],
    "link": "https://skia-canvas.org/",
    "first_paragraph": "\nSkia Canvas is a browser-less implementation of the HTML Canvas drawing API for Node.js. It is based on Google\u2019s Skia graphics engine and, accordingly, produces very similar results to Chrome\u2019s <canvas> element. The library is well suited for use on desktop machines where you can render hardware-accelerated graphics to a window and on the server where it can output a variety of image formats.While the primary goal of this project is to provide a reliable emulation of the standard API according to the spec, it also extends it in a number of areas to take greater advantage of Skia's advanced graphical features and provide a more expressive coding environment.In particular, Skia Canvas:",
    "summary": "Title: Hipsters Recycle Browser Features Out Of Boredom\n\nAnother day, another solo dev reincarnates browser tech for kicks, wrapping up Node.js in Google\u2019s discarded Skia chintz to cheat on Chrome without using a browser. Meet Skia Canvas: because why make friends with native APIs when you can awkwardly stumble around in JavaScript? Commenters reanimate the tired corpse of the \"but can it do PDFs?\" argument, only to be dazzled by the shocking revelation that yes, it does handle PDFs\u2014and vectors, no less! Meanwhile, a remote conflict brews in the land of the nerds as \"Skia versus Cairo\" becomes the nerdy slap fight of the week. \ud83e\udd4a\u2728"
  },
  {
    "title": "Making a parallel Rust workload 10x faster with (or without) Rayon (gendignoux.com)",
    "points": 42,
    "submitter": "lukastyrychtr",
    "submit_time": "2024-11-29T23:22:16 1732922536",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42278003",
    "comments": [
      "I've seen this over and over. One of the main issues pointed out by TFA is that there's too many small tasks allocated for parallel execution. Rayon is not going to magically distribute your work perfectly, though it very often does a decent job.If your algorithm is the equivalent of a couple of nested iterations, you have essentially three options: parallelize outer, inner, or both. In the vast majority of the cases I've run into, you want thread/task level parallelism on the outer loop (only), and if required, data/simd parallelism on the inner loop(s).It's a rule of thumb, but it biases towards batches of work assigned to CPUs for a decent amount of time, allowing cache locality and pipelining to kick in. That's even before SIMD.\n \nreply",
      "Larger grain size better.\n \nreply",
      "The rule of thumb also keeps you from doing a lot of task switching.  It isn't free enqueue and dequeue tasks.  It is better if you have a million things to do to have a smaller set of tasks.  Especially if the runtime for those tasks are somewhat uniform.\n \nreply"
    ],
    "link": "https://gendignoux.com/blog/2024/11/18/rust-rayon-optimized.html",
    "first_paragraph": "\n rust perf\nNovember 18, 2024by Guillaume Endignoux\n\n @gendx |  RSS\nIn a previous post, I\u2019ve shown how to use the rayon framework in Rust to automatically parallelize a loop computation across multiple CPU cores.\nDisappointingly, my benchmarks showed that this only provided a 2x speedup for my workload, on a computer with 8 CPU threads.\nWorse, the total \u201cuser\u201d and \u201csystem\u201d times increased linearly with the number of threads, meaning potentially more wasted work.\nEven Python was only twice slower than my Rust code, when Rust is typically 10x to 100x faster than Python.\n\n\n\n\n\n\nPrevious benchmark of my Rust code vs. a reference Python implementation.\nThis was the starting point of an optimization journey that led me to a 10x speed-up from this baseline.\nIn this post, I\u2019ll first explain which profiling tools I used to chase optimizations, before diving into how I built a faster replacement of Rayon for my use case.\nIn the next post, I\u2019ll describe the other optimizations that made my code mu",
    "summary": "<h1>Yet Another Day in Paradise for Rustaceans</h1>\n<p>In the latest revelation that's causing zero ripples across the boundless sea of programming, Guillaume Endignoux heroically discovers that his Rust code is merely twice as sluggish as Python - a fact that surely boggles the mind, given Rust's legendary speed. This <em>astounding</em> disclosure sets him on a quixotic quest to supercharge his Rust code by ditching Rayon, the go-to tool that <i>apparently</i> couldn't even outpace a leisurely stroll through Python's syntax forest. Comments boil down to a thrilling agreement on \"bigger grains\" thinking, saving us from the horror of frequent task switching. Who could have guessed that reducing overhead could increase efficiency? Truly groundbreaking.</p>"
  },
  {
    "title": "Creating a Proxmox or QEMU ChromeOS Flex VM (kevindavid.org)",
    "points": 37,
    "submitter": "goodburb",
    "submit_time": "2024-12-03T21:38:46 1733261926",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=42311828",
    "comments": [
      "This is great!ChromeOS Flex doesn't get enough credit. While I recently migrated from Windows to Linux on my production machine, ChromeOS Flex is my OS of choice for a simple Push Here Dummy (PHD) machine. There is zero maintenance from an OS standpoint and the ChromeOS Flex Certified models list allows me to pick from a variety of quality hardware, not just some cheap Chromebook. I have more than one of these lying around the house and I often take one on personal trips as well.\n \nreply",
      "ChromeOS Flex is what CentOS was to RH. I don't see it lasting very long.\n \nreply",
      "It's a shame then that Google are moving away from ChromeOS in favor of Android. This also explains the improvements to desktop mode in the latest Android betas.\n \nreply",
      "First, a disclaimer: I also overwhelmingly prefer ChromeOS over Android for a bunch of reasons and wish that if they had to merge them the result was a thin Android compatibility layer on the much more robust bones of ChromeOS.That said... if Google wants to fold ChromeOS into Android, I think they'll have to make Android fully supported on x86 as a first-class platform (because most Chromebooks are x86). And if they do that, they should have little problem making a... Android Flex or whatever you'd call it that boots on normal PC hardware just like ChromeOS Flex does today and fills the same role.\n \nreply",
      "Has anyone tried gpu passthrough to a ChromeOS flex vm\n \nreply",
      "At the risk of sounding negative\u2026 Is there a value to do this?I mean, its interesting that you can, but I\u2019m working the opposite way, I run Proxmox so that I can run ChromeOS as my main working OS.\n \nreply",
      "Testing. Installing ChromeOS on a bare-metal machine and then switching back if you dislike it can be a bit of a hassle.\n \nreply",
      "Why can you not install ChromeOS Flex directly on your hardware?\n \nreply",
      "What I mean is that I run proxmox predominantly so I don\u2019t have to run Windows on my hardware.\n \nreply",
      "How do you run Proxmox on ChromeOS?\n \nreply"
    ],
    "link": "https://kevindavid.org/code/2024/03/20/chrome-os-flex-proxmox.html",
    "first_paragraph": "\nMar 20, 2024\n      I recently wanted to experiment with ChromeOS Flex but didn\u2019t want to install it on a physical machine. I also was doing this without a USB key, which complicated things slightly.After some trial and error, there are two non-obvious steps to get the installer running:You\u2019ll need the ChromeOS Flex USB image, which you can get from here if you don\u2019t want to enter your contact info on the main page.Download the ZIP and extract it to your host device somewhere.To use the VirGL GPU driver, which we\u2019ll need later:I used mostly default settings, with a few exceptions.If you\u2019re using OVMF (UEFI) make sure you uncheck the Pre-Enroll keys option on the EFI disk, otherwise it won\u2019t boot - I got an \u201cAccess Denied\u201d error in the virtual BIOS.After creation, go change the Graphic card setting under Display (inside Hardware) to  VirGL GPU.VirtIO-GPU may also work, but in my experience it was a bit laggier - more info on differences, or search yourself.Don\u2019t bother starting the VM y",
    "summary": "**Creating a Proxmox or QEMU ChromeOS Flex VM: A Soap Opera for the Technically Bored**\n\nMarch 20, 2024: In an epic tale of tech dilemmas, a brave soul ventures into the wild lands of virtual machines to avoid the terror of physical commitment to ChromeOS Flex. Spoiler alert: It involves mystifying the masses with \"non-obvious\" steps such as downloading stuff and ticking boxes - groundbreaking! In the comments, the circus unfolds as tech aficionados quarrel over ChromeOS's existential crises and share thrilling tales about GPU passthrough adventures. Meanwhile, others contemplate the profound depth of *running an OS on an OS* to escape the clutches of Windows. \ud83d\udcbb\ud83c\udfaa"
  },
  {
    "title": "My son (9 yrs old) used plain JavaScript to make a game, and wants your feedback (armaansahni.com)",
    "points": 241,
    "submitter": "veesahni",
    "submit_time": "2024-12-03T22:08:16 1733263696",
    "num_comments": 153,
    "comments_url": "https://news.ycombinator.com/item?id=42312121",
    "comments": [
      "My 9 year old son has been learning to code.  He learned HTML & CSS over the last year or two.Recently, we had a breakthrough where he learned how to leverage Google Gemini as a learning tool (not to write code for him, but as a better search and as a coding teacher). This leveled him up big time and he decided to make his own game.Game link here: https://www.armaansahni.com/game/He's coded all the HTML, CSS & JS by hand in VSCode. He's made the animated graphics on his own using a web based sprite editor called Piskel.For the game, I provided hints along the way and Gemini has helped him with syntax.  View source to see the code. He's excited to share with the community.He also wrote a blog post about how he made this game: https://www.armaansahni.com/how-i-coded-a-game-using-ai/ (he independently figured out how to leverage Gemini effectively and writes about it here).Regarding the blog post - We had a discussion about who the target audience is (ie not 9 year olds!), what they would be interested in learning about and the general outline. He then dictated his words into the computer (which gets around spelling issues), and he went through multiple rounds of feedback from his parents (improving clarity, punctuation, etc).  In other words, its his words & thoughts but he had help along the way!NOTE: both parents are programmers, who provided valuable guidance through his coding journey.\n \nreply",
      "This is awesome.My son recently turned 8. All his coding so far has been with Scratch and other block-based programming environments (Octostudio, VEX Robotics, Apitor, Microsoft Makecode).His typing speed is better than most kids his age, but still slow (around 10wpm).I'm curious how you helped introduce your son to text-based programming. I've been considering either:A) Having him go through this free Python course, that includes inline exercises: https://programming-24.mooc.fi/ORB) Having him create a web page in repl.it or similar.\n \nreply",
      "We've had a long journey.  Main thing is that I realized that my son doesn't learn enough from open ended tools like Scratch.  So we tried a bunch of other things.He started with Scratch JR & Scratch.Then we switched to Tynker Jr & Tynker.  Which provide challenge oriented block based games.  Teaches loops, functions, etc.Then we switched to CodeMonkey, which provides challenge oriented block & code based games (coffeescript, python).  Teaches variables, arrays, etc.Then I felt there was not enough new learning from the above. So I gave him VSCode and had him go through Khan Academy's HTML lesson.That's when he made a bunch of HTML pages you see: https://www.armaansahni.com/ (pokemon, bakis, etc).  ALL the HTML/CSS on the site is hand written.Then I wanted him to learn how to be resourceful... for this, I gave him a serious of small challenges (eg: \"make a function that displays hello world on the screen\") where he had to figure out the answer himself. Use Gemini or Google, etc. But don't ask me.  He ended up learning how to use Gemini to accelerate his learning (see his blog post, he writes about it a bit) and he was submitting solutions to me in JS.  He had prior Gemini experience because he was using it to create images, and JS was natural extension of HTML.Then one day he decided he wanted to make a game that he had in his mind.In this above process, I basically observed what he was learning and switched to apps where I felt he could still learn something new.\n \nreply",
      "I really have to applaud how astute you've been with your observations of how your son is learning things.  That's quite difficult.Additionally, I'm glad you weren't afraid to hand your son the real tools and let him build and break stuff.  For some reason with programming, so much of the curriculum (even for adults) spends a lot of effort to hide away the things that are perceived as too difficult (e.g., pointers, memory allocation, etc).  For children in particular it seems to be the actual code itself, and so we have things like scratch.  It's quite refreshing to see a parent go against the grain on this one.\n \nreply",
      "As a programmer, I feel the 'fundamentals' are very important.  Because, well, then there's no magic.I think the curriculum hides the code because its just so complicated.  For example, just to build on the web he has to learn 3 different languages (HTML, CSS, JS).  To do anything simple (like move a box on a screeen) there are too many choices (animated gif, CSS animation, JS animation, etc).  Then there's complexity of code management (eg: this game uses just 1 big file) or deployment (how do you \"run\" your code).So I believe simplifying things (i.e. Scratch) is a way to get people to do it without getting scared of the complexity. In our case, the goal is to learn the complexity, just in baby steps.Appreciate your comments!\n \nreply",
      "I'm curious how much use he got out of Tynker? I noticed they have a cyber Monday sale right now, so I might sign up for a year.\n \nreply",
      "Tynker has many games in the app.  But they are basically the same type of game with different themes.  Your kid will gravitate to whatever theme they like (princess, dragon, space, etc).It would encourage him to reduce number of lines of code (i.e. use loops!) to get more stars.  And we encouraged him to get 3 stars on every level.It also provided both a block based view or a code based view of the work you're doing, which I thought was pretty cool.Big thumbs up from my side for the app.  It taught him the basics of loops and functions, through challenges to keep it motivation.My kid loved the dragon theme.\n \nreply",
      "Thanks. I just subscribed.\n \nreply",
      "Thank you. This is a very helpful description. I think the same process might work for my son.\n \nreply",
      "> His typing speed is better than most kids his age, but still slow (around 10wpm).Get him on gtypist for 20-30 min a day. It\u2019ll pay dividends for life. You\u2019ll be shocked how fast it gets up to 60+ wpm.\n \nreply"
    ],
    "link": "https://www.armaansahni.com/game/",
    "first_paragraph": "Chosse your oponent",
    "summary": "**Child Prodigy in The Making or Just Another Parental Flex?**\n\nIn yet another riveting exposition of the modern parental saga, *armaansahni.com* thrusts upon the world yet another coding virtuoso \u2014 their **nine-year-old** son. Armed with JavaScript, HTML, and visions grander than the average third grader, this young savant supposedly crafted a game more exquisite than any fridge-worthy macaroni art. Poking around the community for validation turned lessons in parenting, code management, and the art of leveraging AI tools (because normal search engines are so *2008*), commenters lay siege to this valiant display of programming pageantry, each sharing their own tot\u2019s meandering path through the coding jungles of Scratch, Tynker, and the daunting text-based trials of VSCode. It\u2019s truly heartwarming (or heartburning) seeing parents toggle the line between encouraging genius and outright choreographing their child's LinkedIn updates. \ud83d\ude80\ud83d\udcbb\ud83d\udc76"
  },
  {
    "title": "Phoenix LiveView 1.0.0 is here (phoenixframework.org)",
    "points": 182,
    "submitter": "bcardarella",
    "submit_time": "2024-12-03T22:28:47 1733264927",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42312301",
    "comments": [
      "Phoenix creator here \u2013 excited to finally have shipped this! Happy to answer any elixir/phoenix/liveview questions.In case folks missed it, buried in the blog post is a new installer that lets folks try out elixir/phoenix in seconds. It installs elixir and generates a new phoenix project from a single command:osx/linux:    $ curl https://new.phoenixframework.org/yourappname | sh\n\nwindows powershell:    > curl.exe -fsSO https://new.phoenixframework.org/app.bat; .\\app.bat\n\nYou can visit those url's directly to see what the scripts do. It extends the official elixir prebuilt installers: https://elixir-lang.org/install.sh and\nhttps://elixir-lang.org/install.batedit: You can see it in action here:\nhttps://x.com/chris_mccord/status/1864067247255306332Of course we also have non |sh getting installation guides if that's what you're after:\nhttps://hexdocs.pm/phoenix/installation.htmlNow that this is out, I'm looking forward to put together a few new demos. What would folks like to see? Happy hacking!\n \nreply",
      "Congrats on 1.0 and really appreciate all the work involved. One thing that I'd love to see is more demos around optimistic UI's. It's a lot of work, but Ryan Florence from Remix did a whole playlist [1] around recreating Trello in Remix.One video or demo in particular that had some functionality I'd love to see in LiveView (or demo on how to do it) is Optimistic UI and Optimistic Add and Drag and Drop (the last three videos in the playlist).1. https://www.youtube.com/playlist?list=PLXoynULbYuED9b2k5LS44...\n \nreply",
      "Congrats! Been running a startup off only liveview for about a year as a solo dev and it's been wonderful. Appreciate the work you all do.Selfish demo idea: Bi-directional cursor based infinite pagination with largish datasets with state managed in the url and streaming updates that change the order of the results. Like some kind of soft realtime leaderboard.With long render times (morphdom bench on large sets isn't great as far as I can tell) it's hard to escape the jank. Particularly on slow connections.\n \nreply",
      "How much state is it safe to store in the URL these days?\n \nreply",
      "Still not much, realistically 4096 bytes or less.Browsers aren\u2019t as much the issue as they\u2019ve been in the past, but I\u2019ve hit snags with proxies, old servers, etc.\n \nreply",
      "Congratulations Chris! I started using LiveView shortly after the beta was released. A few of my coworkers were really excited to try it out, so I was tasked with recreating our company's login page with LiveView. Needless to say, there were\u2026 ahem\u2026 growing pains\u2014but it was super fun to encounter a problem and then just have it go away the following week because of some new update to LiveView.I don't do much (any?) web development these days, but LiveView gave me\u2014a backend dev\u2014the confidence to spin up my own web apps with classy UIs. Thank you so much for all your work!\n \nreply",
      "I\u2019ve been looking forward to this for a long time!Congrats to you and everyone else who made it happen!\n \nreply",
      "(Is it possible to add RSS to the blog? The articles are great but there is no good way to stay up to date.)\n \nreply",
      "We've built many production apps using LiveView. It has some limitations inherent to its design, namely the need to have a semi-reliable WebSocket connection to be able to effectively use the app, but with this tradeoff come a number of advantages:  - code generation makes for an extremely productive experience that makes standing up an actually-useful application very fast\n  - Elixir is a great language, especially for the web, and using it to render the frontend feels like having the full power of the language plus the simplicity of HTML (with little/no writing JavaScript)\n  - it's extremely efficient since only tiny changes are sent over the WebSocket when data is updated on the server\n  - you're already using WebSockets, so adding any kind of real-time functionality is very easy (chat, notifications, game state)\n\nBecause of the separation of concerns by convention (i.e. keeping business logic in Contexts), it's also a very viable pathway to build a webapp using LiveView first, and serve an API once you need other types of clients (native apps, API consumers) with minimal changes. Ecto is also great to use for validations, and having that available for \"frontend\" code is a pleasure. It's also great to be able to have backend and frontend tests in Elixir.We've hit some bugs and gotchas over the years leading up to this 1.0 release, but it has long felt like a stable, well-built library that keeps our codebases simple and maintainable, which lets you move fast.Congratulations to Chris, Jose, and all the other wonderful contributors!\n \nreply",
      "Now there\u2019s some good news!I\u2019ve been using LiveView for years now and couldn\u2019t be happier with it. It\u2019s a joy to work with, and has reinvigorated my love of web development. I\u2019m so blazingly productive in LV it\u2019s unreal.I try not to be too self-promoey on HN but this feels like as good as time as any: if this v1.0.0 release makes you want to finally learn LiveView, I humbly recommend my own course at http://learnphoenixliveview.com. Get 20% off with the code HACKERNEWS.I struggled to find good learning materials when I was starting out, so I\u2019ve tried to rectify that problem. I hope that I can get more people over the initial learning curve because as far as I\u2019m concerned, the more people get familiar with this awesome framework, the more everybody wins.\n \nreply"
    ],
    "link": "https://www.phoenixframework.org/blog/phoenix-liveview-1.0-released?release=1.0",
    "first_paragraph": "\n    Posted on December 3rd, 2024 by Chris McCord\n  \nLiveView 1.0.0 is out!\nThis 1.0 milestone comes six years after the first LiveView commit.\n\n\nI started LiveView to scratch an itch. I wanted to create dynamic server-rendered applications without writing JavaScript. I was tired of the inevitable ballooning complexity that it brings.\nThink realtime form validations, updating the quantity in a shopping cart, or real-time streaming updates. Why does it require moving mountains to solve in a traditional stack? We write the HTTP glue or GraphQL schemas  and resolvers, then we figure out which validation logic needs shared or dup\u2019d. It goes on and on from there \u2013 how do we get localization information to the client? What data serializers do we need? How do we wire up WebSockets and IPC back to our code? Is our js bundle getting too large? I guess it\u2019s time to start turning the Webpack or Parcel knobs. Wait Vite is a thing now? Or I guess Bun configuration is what we want? We\u2019ve all felt th",
    "summary": "<b>Phoenix LiveView 1.0.0: Because Six Years Late is Punctual in Software Years</b>\n\nFinally, the tech messiah Chris McCord delivers <em>Phoenix LiveView 1.0.0</em>, fulfilling the prophecies of ending all JavaScript-driven headaches by literally replacing them with Elixir-induced ones. It took half a dozen years to morph what started as an \"itch\" into a supposed cure for bloated js bundles and existential crises over Webpack settings. Meanwhile, the commenters kneel in digital worship, some begging for RSS crumbs as if it\u2019s still 2005, and others parade their success stories of running startups on a thread - no doubt a thrilling ride atop a stack of bleeding-edge, websocket-dependent tech. Who needs stable infrastructure when you can live on the edge? \ud83d\ude28\ud83d\udcbb\ud83d\ude80"
  },
  {
    "title": "FTC takes action against Gravy Analytics, Venntel for selling location data (ftc.gov)",
    "points": 98,
    "submitter": "gnabgib",
    "submit_time": "2024-12-03T18:25:40 1733250340",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=42309429",
    "comments": [
      "A really good book on this topic is Byron Tau\u2019s Means of Control. His contention is that this surveillance data has made NSA warrantless wiretaps old news. Cops don\u2019t need to do the spying themselves, they can simply buy the info.I am of the opinion that at this point, Americans only believe we are less surveilled than people elsewhere. It\u2019s not visible so people forget about it. Yet it is so deeply embedded into the government that it will never be removed.\n \nreply",
      "There's the old saying that \"we are free only as much as we don't have guns in our face telling us we're not\". The reigns placed on our freedom are just unrecognized by the vast majority of people so they feel they have more freedom than what they might appreciate.\n \nreply",
      "I\u2019m not entirely sure if I understand the point you\u2019re making, but let me try an analogy.We are all forced to buy a car. There is no one with a gun to our head forcing such a purchase, or a law specifically requiring you to buy a car. But nevertheless the laws are structured so that everyone realistically must buy a car, whether they want to or not.If you chose not to buy a car then your life will be dramatically more expensive and difficult to live, because of the network effects of this requirement.So while you are technically free to not buy a car, realistically you are forced to do so.Is that approximately what you mean?\n \nreply",
      "> If you chose not to buy a car then your life will be dramatically more expensive and difficult to live, because of the network effects of this requirement.That depends where you live. In Chicago, for example, your life will be simpler and less expensive if you don't own a car.\n \nreply",
      "I don't understand this as a blanket rule either. My life is dramatically less expensive because of not having a car. I don't have to fill it with gas. I don't have to carry insurance. I choose not to have a car, and while somethings are less convenient it does not prevent me from existing. I have an ebike and it suffices for everything thing that is a necessity for me. For the other things, rental for a weekend away is very much a thing.Now, for people that choose to live in the further reaches of suburbia where things are not nearly as close, then cars become more of a need. But that is a decision when location to suburbia or further was made.\n \nreply",
      "It's extremely possible to live in Boston (or some surrounding areas like Cambridge or Brookline) without a car.  I did for 6 years.\n \nreply",
      "It's more like, you think you are free, because from birth society and CorpGov condition you to operate within an accepted status quo, and incentives are structured in order to support that.But the moment you question the status quo, or try to go against it, you find yourself targeted by corporate and social violence. You might lose your job, the respect of your peers, your family, house, car or more.Here is an easy example:A portion of your tax money is funding genocide and anti-democratic military coups in Israel and other countries.If you decide (as any rational citizen should) to no longer pay income tax knowing that you lack any discretion over how it is spent, and you decide to demand a more transparent and restricted tax system, then the government will threaten you with economic hardship and even prison. They will surveil and discredit you if you receive any modicum of notoriety, just as they do to sociopolitical activists and protestors.You won't be able to operate a business while opposing income tax laws, and thus conscious political action is relegated to the elite, who don't need to work, and the poor, who already don't significantly benefit from the system. The rest of the working class is forced to play ball, or lose everything.That's not freedom, even if it looks like Freedom\u2122 to a certain class of bootlickers who are conditioned to maintain the status quo, even if it means turning on their neighbor.\n \nreply",
      "I like in your post about how you\u2019re \u201cnot free\u201d you demonstrate that you\u2019re perfectly free to contradict the government claims (and reality) by alleging non-existent genocide by an ally.That seems to directly contradict your whole thesis.Which is also contradicted by reality \u2014 as the \u201cless taxes, no wars!\u201d party just won the US election. Apparently that doesn\u2019t count because you can\u2019t unilaterally decide not to pay your taxes.\n \nreply",
      "The ICC recognizes Netanyahu as a war criminal. The UN recognizes and denounces the genocide taking place in Gaza.Just because you want to be ignorant to reality doesn't make you correct or worth listening to. There is nothing to allege. The genocide is happening, it's well-documented, no matter what you choose to believe. Take your bootlicking drivel somewhere else.And no, you're missing the point. Thanks to our Bill of Rights, we currently are able to publicly denounce the genocide. That doesn't mean I'm free to disentangle myself from the economic pipeline fueling it.Just because you can point to some amount of freedom doesn't invalid the fact that going against the status quo opens you up to state and social violence. Reread my post.> \u201cless taxes, no wars!\u201d party just won the US electionSurely you have an ounce of intelligence to recognize that it is purely lip service, and both parties are considered far right by any progressive standards.Trump, like those before him, works for the elite, and gives them tax breaks, while letting the middle class take on the brunt of the taxes. He is also pro-war, just like his opposing candidate Kamala Harris was.\n \nreply",
      "laws are structured? or just the cumulative impact of societies decisions.humans are social creatures, of course if everyone else has a car it is going to be inconvenient for you to not have one. this is not a solvable problem\n \nreply"
    ],
    "link": "https://www.ftc.gov/news-events/news/press-releases/2024/12/ftc-takes-action-against-gravy-analytics-venntel-unlawfully-selling-location-data-tracking-consumers",
    "first_paragraph": "An official website of the United States governmentHere\u2019s how you know\nThe .gov means it\u2019s official.\n\n                Federal government websites often end in .gov or .mil. Before sharing sensitive information, make sure you\u2019re on a federal government site.\n              \nThe site is secure.\n\n                The https:// ensures that you are connecting to the official website and that any information you provide is encrypted and transmitted securely.\n              We enforce federal competition and consumer protection laws that prevent anticompetitive, deceptive, and unfair business practices.View EnforcementFind legal resources and guidance to understand your business responsibilities and comply with the law.Browse legal resourcesView all Competition Matters Blog postsWe work to advance government policies that protect consumers and promote competition.View PolicyFind legal resources and guidance to understand your business responsibilities and comply with the law.Browse legal resourc",
    "summary": "In a groundbreaking display of \"Well, duh!\" the FTC finally addresses the sketchy dealings of Gravy Analytics and Venntel for turning your trips to Taco Bell into high-stakes intelligence fodder. Concerned hobbyists of digital privacy flocked to the comments, congratulating themselves on their superior knowledge of Orwell's \"1984,\" while slyly referencing books nobody will actually read. One patriot confusingly toggles between metaphors about cars and freedom, mystifying at least one other commenter into silence, illustrating that the internet is truly no place for logical discourse. Meanwhile, debates about societal freedom roam wild, revealing that most people are less concerned with privacy violations and more about proving how <em>deep</em> and <i>woke</i> they are compared to everyone else."
  },
  {
    "title": "Show HN: My C compiler compiled itself (github.com/keyvank)",
    "points": 50,
    "submitter": "keyvank",
    "submit_time": "2024-12-03T20:35:24 1733258124",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42311031",
    "comments": [
      "> Then run ./build.py. This will use the bootstrapped 30cc-compiler to compile 30cc itself. It then again uses the 30cc-compiled compiler to compile 30cc once again. The final compiler is then stored as ./30cc.Why isn't that also done by the Makefile? The only catch I could see is that you'd need to have it build to different output names, but that seems fine for what it is?---Also, I'm curious - did you find yourself having to constrain your use of C in order to make sure that the compiler could compile itself? Or does it implement everything you would use naturally anyways?(And of course, congrats/bravo; super impressive:])\n \nreply",
      "> Also, I'm curious - did you find yourself having to constrain your use of C in order to make sure that the compiler could compile itself? Or does it implement everything you would use naturally anyways?That would be the \"bootstrapping\" process.  Nearly a half-century ago I took a compiler lab class where we were given a working, but slightly lame, compiler, and were tasked with adding new, less lame, language features by bootstrapping.  That is: 1) implement new feature without using the new feature, 2) using the compiler that results from step 1, re-implement the feature using the new feature, and compile again. 3) Repeat with more features until end of semester for best grade.Oh, and to the OP, well done!\n \nreply",
      "> Why isn't that also done by the Makefile?My guess is that some people would rather write Python code than dig into Make\u2019s documentation. That said, ChatGPT is excellent at creating valid make files.\n \nreply",
      "Or just take a few moments to learn the basics about Makefiles.The thing about Makefiles is that simples ones at least are really easy to write, and read. Much simpler and quicker than a cumbersome python script, that will most likely do less with much more boilerplate code (e.g. dependencies), and be much harder to read.Of course, you may hit a point where you stretch your Makefile so much beyond its common capabilities that that no longer becomes true, but in my experience that point is pretty far away.\n \nreply",
      "Why not use WASM to bootstrap your compiler?\n \nreply",
      "Elaborate, why use WASM?\n \nreply",
      "What a fun project, thanks for sharing. I've dreamed of projects like this. What did you expect to learn from this project? Did you learn anything unexpected?\n \nreply",
      "/me claps and cheers\n \nreply",
      "tnx!\n \nreply",
      "Thank You For Making And Sharing!\n \nreply"
    ],
    "link": "https://github.com/keyvank/30cc",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        30 C Compiler\n      30cc (Pronounced as CCC, because in the Persian language, the number 30 is pronounced as C) is a toy C compiler written in C, which is strong enough to compile itself \ud83e\udd1d This was my first attempt in writing a self-hosting software! What is a self-hosting software?30cc emits x86-64 assembly as its output. The outputs are totally unoptimized, but that's fine, the project aims to be educational.Running independent source-files through make:To run tests useThen check the output of the tests.If you are on mac use ./scripts/test_mac.sh to run the tests in docker.\n        30 C Compiler\n      ",
    "summary": "**Title: Show HN: My C compiler compiled itself**\n\nToday in \"I Made a Thing!\": some brave soul has authored a C compiler that can recursively compile itself, like a snake endlessly munching on its own tail. Comment sections turn into a graveyard where dreams of pure efficiency go to die, as programmers debate the merits of <em>Makefiles</em> vs <em>Python scripts</em>, and someone inevitably suggests rewriting the whole thing in WASM \u2014 because, why not increase the entropy of the universe? Meanwhile, casual back-patters provide the obligatory \"<i>Well done, chap!</i>\" comments, ensuring that the circle of Hacker News self-congratulation remains unbroken. Godspeed, compiler warriors, godspeed!"
  },
  {
    "title": "Dependency management fatigue, or why I ditched React for Go+HTMX+Templ (erodriguez.de)",
    "points": 166,
    "submitter": "todsacerdoti",
    "submit_time": "2024-12-03T12:16:33 1733228193",
    "num_comments": 160,
    "comments_url": "https://news.ycombinator.com/item?id=42305348",
    "comments": [
      "The problem is not so much React as it is the JS ecosystem, but React is just very visible when you have these issues because there are so so so many packages being imported.And the root of the problem is peer dependencies and the JS community's lack of backwards compatibility and maintenance.Take any decently-sized JS application, whether React or whatever else. Put it in Github. Turn on dependabot. Watch your pull requests go up by 5-10 PRs per week, just to bump minor versions, and then watch how 1 of those PRs, every single time, fails because of a peer dependency on a lower version.This has been a problem forever in the community, and there's no good solution. There's also just no feasible way to make a solution due to the nature of the language and the platform itself. You just have to absorb that problem when you decide to use eg Node for your backend code or React/etc for your frontend code.\n \nreply",
      "The JS ecosystem definitely has a big problem from the culture developed in the IE6 era where people developed so many packages working around the limited language and runtime, but React does have part of the blame here: the way it\u2019s designed forces everything into its proprietary model instead of web standards, so you end up with tons of components duplicating other projects but in React or providing shims for those projects, Facebook\u2019s big devrel push prioritized getting started quickly on a proof of concept rather than maintaining a larger app so you had things like Create React App adding nearly 40k dependencies before you had written a single line of code, and the culture of focusing JavaScript over built-in browser functionality (which made some sense in the 2000s when you had users stuck with IE6) means that you\u2019re going a lot of work in runtime JavaScript rather than the browsers\u2019 heavily-optimized C++ \u2013 and it\u2019s often hard to change that because it\u2019s not a direct dependency but a nested chain.This is also why it\u2019s slow and memory hungry: it\u2019s not just the inherent inefficiency of the virtual DOM but also that having such a deep tree makes it hard to simplify - and since interoperability makes it cheaper to switch away, framework developers have conflicting incentives about making it easier.\n \nreply",
      "I have been building a platform https://github.com/claceio/clace for teams to develop Hypermedia based internal tools.  One of the main criteria for the technology stack and the feature set has been making sure apps can be maintained easily, after six months and after six years.Settled on using Go HTML templates, Starlark and HTMX. Go has a great track record of not breaking backward compatibility. Go templates are widely used by ops teams, any breaking changes there will cause ops teams to revolt. Starlark is somewhat widely used by build systems (like Bazel), any breaking changes there will cause build engineers to rise up in arms. The HTMX 1.9 to 2.0 upgrade was also painless, no changes required in my test apps. Only change required was to update the way the websocket extension is resolved.\n \nreply",
      "Reminds me of the Rich Hickey talk Speculation[1]. There is a special place in hell reserved for programmers that break back compat (for non-security impacting reasons) with widely used libraries, including google's guava developers.  Linus Torvalds seems to be the only engineer with his head on straight on this topic and he has to constantly dive in and berate people that are trying to violate it in his project.[1] https://www.youtube.com/watch?v=oyLBGkS5ICk\n \nreply",
      "The main question should always be: why update?Should a library become compromised with a vulnerability, fine (if said vulnerability is relevant to your usage). If you need a feature only available in a newer version, fine (I\u2019m counting better performance as a feature).What I\u2019m seeing far too much of is upgrading for the sake of it. It feels like such a waste of dev time. Pinning dependencies should be absolutely fine.\n \nreply",
      "The issue is that feature or vulnerability might not be patched on older versions.   If you are using a 2 year old version and a non-backported vuln or needed feature comes along that means you have to absorb 2 years of breaking changes to move to that version.Frequent updates allow you to address the breaks gradually rather than all at once.JS is just awful, though, because of the sprawling dep tree.  I get why devs would prefer pinning as any one of the 1000 deps that get brought in could need an update and code changes on any given day.  A sticky static version requires less daily maintenance.\n \nreply",
      "You either waste your time updating daily or you rewrite from scratch every 3 years. JS is what happens when you let the inmates run the asylum.\n \nreply",
      "It's vastly, vastly easier to upgrade small version bumps constantly via automated tools like renovate than it is to try upgrade several major versions every few years. It's shite being stuck with dependencies the dev team has now put in the \"too hard basket\" in terms of upgrading because the delta is too scary or difficult and too much code has ossified around the now ancient version. Don't willingly do that to yourself if you can avoid.\n \nreply",
      "I get that, and it\u2019s a good point. But at some point that easy patch/minor version bump becomes a major version with a breaking change, and does take time to upgrade regardless, scary delta and such. My point is that, without an actual feature need or an actual vulnerability (none of these guaranteed to spring up in future), any time spent upgrading is potentially wasted. I know some projects are unlikely to last beyond a few years \u2014- in those cases I think the risk is calculated enough to not matter too much.\n \nreply",
      "> My point is that, without an actual feature need or an actual vulnerability (none of these guaranteed to spring up in future), any time spent upgrading is potentially wasted. I know some projects are unlikely to last beyond a few years \u2014- in those cases I think the risk is calculated enough to not matter too much.You could make the same argument for any kind of code quality efforts. Frankly I think this site probably leans too far into a high-quality mindset, but apart from anything else good programmers won't want to work on a codebase that isn't seen as valuable and treated as such.\n \nreply"
    ],
    "link": "https://blog.erodriguez.de/dependency-management-fatigue-or-why-i-forever-ditched-react-for-go-htmx-templ/",
    "first_paragraph": "03 Dec, 2024After getting to work on some personal projects using Go+HTMX+Templ this year, I have decided to give up on using React on any personal projects.You can actually find a lot of compelling arguments for ditching React in favor of HTMX in the essays found in the HTMX official website.\nBut I feel that not that many people are speaking about dependency management fatigue.After working on my last personal project that used React (an interactive Catalan dictionary), I realized that I was spending too much time dealing with dependency updates of mostly React packages.\nI would update my packages to their latest release, only to realize that their APIs had breaking changes that forced me to invest time refactoring my code.I wanted to keep up with any dependency updates because my webapp was back then deployed as a publicly accessible service in an EC2 instance and I wanted to avoid any possible vulnerabilities.Some of the worst offenders in this respect were wouter (a React router pa",
    "summary": "**Another Dev Sprints Away Screaming from React: A Play in One Act**\n\nIn the *Shakespearean tragedy* entitled \"Quitting React,\" our hero finds himself drowning in the React-NPM dependency sea, growing wearier with each breaking update. He decides it\u2019s Go+HTMX+Templ to the rescue because the cool kids over on HMTX\u2019s homepage said so! The commenters, holding torches of loyalty to their beloved JavaScript patchworks, join the chorus bemoaning the unsolvable Nexus of Doom\u2014peer dependencies and breaking changes\u2014and glorify Go's unmoving mountains of compatibility. Meanwhile, pragmatic voices cry in the wilderness about the heresy of not being on the daily dependency updating grind, because who doesn\u2019t want to refactor on a Tuesday night just for the thrill of it? \ud83e\udd2a"
  },
  {
    "title": "My brand new digitizing workflow using a 25 year old film scanner (vladovince.com)",
    "points": 77,
    "submitter": "williamsmj",
    "submit_time": "2024-12-03T16:49:32 1733244572",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=42308234",
    "comments": [
      "As someone who has built multiple custom macro film scanner setups, owns basically very consumer film scanner of note (including the Coolscan 9000 and the Minolta Scan Multi Pro), and is intimately familiar with the workings of various film scanners and science of digitizing film, I don't think this article provides particularly good advice.Just for instance, the LS-2000 features in the post has an advertised optical resolution of 2700DPI, which means the absolute maximum megapixel resolution you can get out of that thing is a little over 10MP. Film scanners are notorious for overstating their optical resolution, which has nothing to do with the resolution of sensor used to digitize the image data and everything to do with the lens in the scanner. You can have a 200MP sensor scanning your film but if your lens can only resolve 1000DPI you will have a very high resolution image of a low resolution lens projection. It's maybe a little better than a flatbed and it features dust removal, but in the year of our lord 2024 the LS-2000 is not a good choice for scanning film.As for his macro scanning setup, he appears to be using the digitaliza for film holding, which is a notoriously bad product with many known flaws. Negative supply makes a line of lower cost version of their very good film holders, and Valoi also offers an affordable system of components that I highly recommend. There is a ton of good information out there about macro scanning, and had the OP sought it out he could avoided his little adventure in retro computing.\n \nreply",
      "You seem knowledgeable in this space. I\u2019ve researched scanners for only scanning old prints but get mixed messages. What would be your advice on a scanner for this purpose to get 90% good enough\u2026 epson 650/700?\n \nreply",
      "Digitizing film seems to be a perennial pain point. As far as I know there is no mostly-automated option to scan multiple film formats at high resolution besides paying someone with very expensive equipment to do it for you. The obsolete equipment like those models you mentioned involves a lot of fastidious labor per-frame and is generally pretty awful.Modern equipment has similar warts. Flatbed scanners are bad film imagers for a number of reasons, a few which you already wrote. There's a huge volume of new products coming out for scanning right now (film holders, copy stands, light panels, etc) but these setups are very inconvenient to set up or, to be charitable, demand practice and perfect technique. There's always people ready to insist they have an easy convenient time setting up their SLR scanners and capturing 1000 rolls at 9999 DPI in 2 minutes. I don't share their experience.During the pandemic I tried to proof-of-concept a path forward without any real success:- The first attempt involved modifying a Plustek scanner to take medium format. This ended up taking a ton of work for each medium format frame (4 captures for each of the 4 quadrants, and each of those is already slow for a single 35mm frame). Stitching these captures is tedious and flaky for images that don't have obvious sharp features.- The other involved rigging the objective of a Minolta Dimage Scan Elite II on a Raspberry Pi HQ camera onto an Ender printhead to raster over the film with a light table. This could have worked but it had many mechanical problems I am not cut out to solve (lens mount, camera-to-film-plane alignment)Leaving aside designing a proper optical path there are 2 killer problems:- the problem of mechanically manipulating the negative and keeping it in focus- the problem of stitching together partial captures with minimal human interventionA few people seem to be working on open source backlit line-scanners but as far as I know no central path forward has emerged. \nI hope someone figures it out.\n \nreply",
      "I see you mentioned using a 3D printer for scanning medium format film. I did something similar, but took the opposite approach. I placed the film on a lightbox and mounted that to the printer, then had that move around in front of a camera with macro lens. I did not have much of a problem with alignment.That being said, this was a one-off, but once I had enough overlap with each capture, PTGui was able to switch it together relatively hands-free, even with it having lots of sky.\n \nreply",
      "I've been doing something similar. I started with a 3D printer approach, then two cheap aliexpress C-beam linear actuators and finally managed to acquire a 2-axis microscope stage for cheap. The key I have found is that any issues with alignment can actually be solved with focus-stitching.The real problem with most scanning setups is actually getting accurate color out of color negatives. The common wisdom these days is to use high-CRI light, but I believe that approach is flawed. Film scanning is not an imaging challenge, but a rather a densitometric one. You don't actually want to take a photo of the negative in a broad spectrum because the dyes in photo negatives were never intended to be used in a broad-spectrum context. You actually need to sample the density of the dye layers at very specific wavelengths determined by a densitometric standard (status M) that was designed specifically for color negative film. Doing this with a standard digital camera with a bayer sensor is... non trivial and requires characterizing the sensor response in a variety of ways.Basically the hardware is easy, the software is hard.\n \nreply",
      "Very interesting. What camera/lens/lightbox did you use and around what DPI you achieve?\n \nreply",
      "Also, the LS-2000 is a noisy POS. I owned this thing for years (bought new) and put plenty of time into it. It just sucks. It was only mediocre for slides and black-&-white negatives; for color negatives it was nearly useless. You could never remove the base negative color and retain good image color. The dynamic range sucked.I sold it on eBay years ago, then researched what might be better. The general opinion was that consumer-accessible scanning peaked with the Minolta Dimage Elite 5400 II. Of course these were long out of manufacture, but I managed to find one new in the box on a small auction site. To this day I haven't gotten around to scanning a single piece of film with it. Maybe this post will finally get me off my ass...\n \nreply",
      "B&Ws also scan poorly on it if the negatives are even a little bit dense. Tricky negatives that could still produce good images in the darkroom had no hope on the LS-2000.\n \nreply",
      "30 seconds of searching reveals there are Linux drivers for the Nikon LS-2000. Seems a lot easier to deal with (and probably more stable).\n \nreply",
      "Got to shout out to VueScan for making obsolete scanners usable on modern operating systems. It's not free, but is reasonably priced. If you can physically connect your scanner (scsi2usb is an exercise left to the reader), then it's likely to let you use it.\n \nreply"
    ],
    "link": "https://blog.vladovince.com/my-brand-new-digitizing-workflow-using-a-25-year-old-film-scanner/",
    "first_paragraph": "Photography is arguably my oldest hobby. I\u2019ve loved taking photos for as long as I can remember. I reflected on my first encounter with digital photography in 2003 in a recent post, but I\u2019m old enough that I first got to know photography through film. I still don\u2019t know what it is exactly that draws me to still images, but I find the same joy capturing light with a camera as I did 30 years ago. I first got serious about photography when I started high school. I got my first SLR camera, a Canon EOS 3000v, in 2006. Over the next few years I used it to shoot countless rolls of film. Many were the then-ubiquitous and cheap types like Kodak Gold, which I would process at a local photo studio. Even though I was shooting film, the digital writing was already on the wall, so I would have the studio scan the photos for me and burn them on a CD. I still have dozens of disks with scanned images from those days. In 2008 I took a course on developing photos in a darkroom. This opened a whole new wo",
    "summary": "Hobbyists and self-proclaimed experts gather to marvel at the staggering revelation that someone has managed to use a 25-year-old film scanner without invoking ancient rituals. \ud83d\udcf8 One brave soul explains his undying love for analog, settling for a digitizing workflow powered by the archeological relic known as the Nikon LS-2000, offering a jaw-dropping 10MP resolution that might just capture the essence of dust specks with historical accuracy. Meanwhile, the commenting elite compete in a virtual pissing contest over who owns the most obscure macro setup and whose DIY film-scanning rig can best resurrect the dark ages of photography. For a dose of true comedy, someone suggests deploying Linux drivers\u2014because software from 1998 will surely solve all modern problems with a device manufactured when dial-up internet was hip."
  },
  {
    "title": "Openlayer (YC S21) is looking for top-tier design engineers (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-12-03T21:00:04 1733259604",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/openlayer/jobs/ZEEO8UB-design-engineer",
    "first_paragraph": "The fastest way to ship airtight AIOpenlayer is solving the AI reliability problem. AI has the potential to transform industries, but too often, inconsistent results and a lack of robust testing hold back that progress. We offer something better\u2014an environment where teams can confidently develop and deploy AI systems.Today, AI-driven teams\u2014from startups to global enterprises\u2014use Openlayer to deliver trustworthy AI experiences. Openlayer helps them focus on what matters: making AI dependable and impactful in the real world.Read more about the company and our mission.See the full list of benefits here.Openlayer is committed to fostering and empowering an inclusive community. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, national origin, citizenship, age, marital status, veteran status, disability status, or any other characteristic protected by law.Our interview process is designed to be efficient. At each phase, we will ",
    "summary": "Openlayer (YC S21): because why not add another startup to the AI jamboree that promises to solve every industry problem without really explaining how. Today's novel idea? Airtight AI\u2014because everything else AI claims to fix is just *too* mediocre. In the comments, watch the horde of basement-dwelling \"tech enthusiasts\" furiously debate ethics while confusing Python with the snake. Godspeed, talent-seekers, and may your equity slice not be diluted in the unstoppable sea of venture capitalism. \ud83d\ude80\ud83d\udc0d"
  },
  {
    "title": "Phishers Love New TLDs Like .shop, .top and .xyz (krebsonsecurity.com)",
    "points": 103,
    "submitter": "todsacerdoti",
    "submit_time": "2024-12-03T13:30:40 1733232640",
    "num_comments": 134,
    "comments_url": "https://news.ycombinator.com/item?id=42305831",
    "comments": [
      "The implication that gTLDs are bad and new ones shouldn't be introduced because of this is a bit silly to me. The argument that they somehow have lower registration requirements makes no sense, .shop .top and .xyz registrations involve the exact same amount of verification as .com (none). Prices aren't really that different and plenty of gTLDs are more expensive than traditional ones.Registering a domain is frustrating these days, too many already taken and a lot of them by squatters not even intending to use it. I'd love to see more options personally even if it makes it slightly easier to create a phishing domain. We need better tools than memorizing a domain name to deal with that anyways.\n \nreply",
      "I think the issue is you can register a known company name on one of these and plenty of people will think it's legit. Companies have to register on all these random domain to protect themselves.dell.shop, that's probably the dell computer I know, right?\n \nreply",
      "The people who would fall for that would probably also fall for `dell.computerdealshop.com` though\n \nreply",
      "When a scam hits someone's inbox or text message, it finds them in a particular time in their life, in a particular state of mind, and in a particular context. It's not just about how gullible or uninformed or whatever they are. They may be tired, they may be drunk, they may be spending all their energy worrying about a sick relative, or trying not to.They may have just been shopping for a computer, maybe even a dell. Or maybe they need a computer for their kid and don't have the means to afford one and are more likely to fall for a scam advertising a good deal on a computer than for any other scam.These all add to the probability that someone falls for a scam. Phishing is all about casting a wide enough net that the probabilities align against some of the people you hit at the time you hit them.Victims are not just uninformed. They are also compromised, and/or incentivized to believe this particular scam, and/or unlucky enough that the scam takes place when they were recently engaged in activity that makes the scam more believable.Seeing dell.computerdealshop.com will snap a lot of people out of it where seeing dell.shop would not have.\n \nreply",
      "Whether people are more easily fooled by dell.shop dell.computershop.com is a non sequitur from the rather wordy disquisition about why people fall for the scams in general. The eye sees dell first in clear letters for both urls. Their sick relative doesn\u2019t change much here. I would honestly not be sure if either is a scam for the url alone. The improbable deal at the other end is the only meaningful signal.\n \nreply",
      "> Whether people are more easily fooled by dell.shop dell.computershop.com is a non sequitur from the rather wordy disquisition about why people fall for the scams in general.It isn't. People fall because probabilities align. Something can catch their eye to knock them out of it.A bad URL is a bad probability (for the scammer) in the chain, a really good URL is another good probability. If your assessment is that both URLs look equally good/bad to you, I, of course, won't deny that claim about your own experience. But to my eye, dell.computershop.com looks pretty bad and dell.shop looks pretty good.I only answer my phone if I'm in the middle of getting a loan and so expecting a call from some unknown number at any time, and even then some numbers look too phishy to answer. The last time I got a loan I got a call from a local area code near the bank, answered, and found myself talking to a scammer about a loan. It was confusing, I believed it was the bank at first! Everything needed to align for them to get that far, including the phone number looking legit to my eyes. To someone else's eyes a number halfway across the country may have looked just as legit. Or the nearby number may have looked instantly bogus. This is exactly my point!\n \nreply",
      "Most people don't understand URLs.Remember that Google was (is?) trying to remove the URL bar. Not just because it reinforces search as the main product and gateway to the web, but also because URLs are kind of hard for most people.Which brings us to the original argument: is this a reason to ban gTLDs? Surely the cost of banning gTLDs outweighs the enormous benefits of making it easy for society's productive users to find names they like.We also shouldn't discount the incredible benefit of having additional namespaces and markets positioned against domain name squatters. gTLDs linearly increase the costs to squatters. Good names can be found with lots of alternative gTLD offerings, which greatly increases the supply side for builders and entrepreneurs.Ultimately gTLDs probably won't be banned simply because there's money to be made by the ICANN and registrars.\n \nreply",
      "Many people do not understand URLs, many people do, and many people have an understanding in between. And they are all targets for scammers.And I don't think gTLDs should be banned! But I don't like bad arguments even when they support my preference.\n \nreply",
      "And then there are plenty of companies who put some legitimate part of their business on a wonky gtld domain they only bought so that it's not bought by a scammer. Systems run by the investor relations department might run on examplecompany.biz, some hiring SAAS on examplecompany.work, the CRM on examplecompany.business and the tech support occasionally instructs someone to get a preview update from examplecompany.cc. Not because that's a smart thing to do, but because coordinating namespaces is not easy and dedicating an otherwise unused domain only bought to keep out the scammers is a tempting shortcut. And because training internet users that sometimes wonky TLD are ok is an externality.\n \nreply",
      "> Seeing dell.computerdealshop.com will snap a lot of people out of it where seeing dell.shop would not have.Would love to see citations for that.\n \nreply"
    ],
    "link": "https://krebsonsecurity.com/2024/12/why-phishers-love-new-tlds-like-shop-top-and-xyz/",
    "first_paragraph": "Phishing attacks increased nearly 40 percent in the year ending August 2024, with much of that growth concentrated at a small number of new generic top-level domains (gTLDs) \u2014 such as .shop, .top, .xyz \u2014 that attract scammers with rock-bottom prices and no meaningful registration requirements, new research finds. Meanwhile, the nonprofit entity that oversees the domain name industry is moving forward with plans to introduce a slew of new gTLDs.Image: Shutterstock.A study on phishing data released by Interisle Consulting finds that new gTLDs introduced in the last few years command just 11 percent of the market for new domains, but accounted for roughly 37 percent of cybercrime domains reported between September 2023 and August 2024.Interisle sources data about cybercrime domains from anti-spam organizations, including the Anti-Phishing Working Group (APWG), the Coalition Against Unsolicited Commercial Email (CAUCE), and the Messaging, Malware, and Mobile Anti-Abuse Working Group (M3AAW",
    "summary": "**Phishers Love New TLDs Like .shop, .top and .xyz**\n\nThe alarming rise of phishing could practically be sponsored by the hot mess that is new gTLDs like .shop, .top, and .xyz, which combine the allure of a sleazy back alley with the bargain prices of a garage sale. With scammers practically thrown the keys to the kingdom, enthusiasts in the comment sections are fervently defending these digital dumpster fires. One sage points out the equality of non-verification across all domains, shedding light on the universally low bar \u2013 how reassuring! Meanwhile, others debate the strategic nuances of URL aesthetics as if choosing between a fake Rolex from a street vendor or a thrift shop, because cyber criminals definitely care about our thoughtful discourse. \ud83c\udfa3\ud83d\udcbb\ud83d\udd0d"
  },
  {
    "title": "Tweaking Stunt Island's 30-year-old 3D engine (annali.netlify.app)",
    "points": 170,
    "submitter": "alberto-m",
    "submit_time": "2024-12-03T13:44:59 1733233499",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=42305954",
    "comments": [
      "It's difficult to impress how cool it was to have a open world flight sim / 3D movie editor in 1995. There's not much like it even today; GTA V's movie editor is close. A small \"scene\" grew up around it, and there were lots of mods/hacks in the 2000s: https://armknechted.com/sicentral/newpage/hacksi.html\n \nreply",
      "Yeah, this was an incredibly unique game that I played hours of in high school. It obviously looks dated now, but was amazing at the time.\n \nreply",
      "Absolutely loved this game. I used to try and fly an F4 Phantom through the canyon at top speed. My brother created a short film \"Attack of the Killer Christmas Trees\". Endless fun.\n \nreply",
      "It is an amazing game! Do you (or does he) happen to still have that short film somewhere? It sounds great. I collect user-made films, and have about 320 in the Stunt Island Archive. I'm sure there are thousands more than unfortunately never got preserved.Archive link: https://armknechted.com/sicentral/newpage/SIArchive.html\n \nreply",
      "That's so cool! Feels like a long shot but I'll look into it.\n \nreply",
      "My go-to stunt was climb to the aircraft ceiling then dive nearly straight toward the Golden Gate Bridge and fly under it and climb immediately. I was somewhat successful.\n \nreply",
      "This is awesome. Mickey's Revenge looks so much better with LOD at 800%!This game is a gem, it deserves a spot in the video-game hall of fame.\n \nreply",
      "Mickey's Revenge: https://www.youtube.com/watch?v=AZMDm-2IIzcHaving just watched it, I like that the engine has specific support for points, lines and filled circles, because it predates efficient texture-mapping and high polygon counts, so they use dots for stars on the US flag, a series of line segments to write text in 3D, and green spheres to represent tree leaves. These days it's all triangles (...very well lit and textured triangles with more computation expended per pixel than the 1992 computer had in its entirety)\n \nreply",
      "The engine only copied pixels from fast main RAM to slow VGA RAM when they changed value, so using flat shading for most of the objects was a necessity for performance. IIRC all of the planes used Gouraud shading.\n \nreply",
      "\"Slow video RAM\". Wild!\n \nreply"
    ],
    "link": "https://annali.netlify.app/2024/11/20/tweaking-stunt-island",
    "first_paragraph": "",
    "summary": "Welcome back to 1995, when <em>Stunt Island</em> was the <em>height</em> of 3D innovation, now receiving a facelift from someone probably avoiding real work. Relive the nostalgia, as coders desperately tweak pixels to outdo the graphics of your grandfather\u2019s wristwatch. Commenters bask in the glory of low-poly artistry, boasting about ancient hacking feats and \"endless fun\" moments as if they just discovered fire. Meanwhile, others hoard user-made film clips like post-apocalyptic junk collectors. Join the excitement! Because, honestly, what's more thrilling than watching green spheres pass for \"tree leaves\" and lines for text in 3D? \ud83d\ude02 Ah, the good old days."
  },
  {
    "title": "Homography Explained with Code (opencv.org)",
    "points": 4,
    "submitter": "diginova",
    "submit_time": "2024-11-27T17:51:09 1732729869",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://docs.opencv.org/4.x/d9/dab/tutorial_homography.html",
    "first_paragraph": "",
    "summary": "In an audacious attempt to teach digital alchemists how to manipulate reality, opencv.org publishes \"Homography Explained with Code,\" effectively transforming every reader into a potential deepfake wizard overnight. Watch in awe as complex mathematical concepts are reduced to Instagram-filter levels of simplicity, ensuring every tech bro can warp your grandma\u2019s face with just a few lines of Python. The comments section becomes a mystical battleground where self-proclaimed coding gurus compete to see who can obscure the explanation even further, because nothing says \"community\" like gatekeeping basic knowledge through obfuscation. Will anyone use this power for good? Doubtful. \ud83d\ude02"
  },
  {
    "title": "Launch HN: Vocera (YC F24) \u00e2\u20ac\u201c Testing and Observability for Voice AI",
    "points": 52,
    "submitter": "Sid45",
    "submit_time": "2024-12-03T15:46:57 1733240817",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42307393",
    "comments": [
      "Congrats on the launch!Given the size of the niche (developers building voice agents), do you find there's a lot of demand for testing and observability? From my anecdata, many of the voice AI agent builders are using SDKs and builder tools (Voiceflow, Vapi, Bland, Vocode, etc). Observability is usually already baked-in pattern with these SDKs (testing I'm not so sure of).One conversation I had with a voice agent builder: \"Our product is complex enough where external testing tools don't make sense. And we know when things are not working because we have close relationships with power users and companies.\" Whose problem are you solving?Your tool looks very powerful, but might the broader opportunity be just to use your evals to roll out the best voice agents yourself?\n \nreply",
      "Great question! We've seen significant demand for testing and observability across sectors like healthcare, insurance, home services, and e-commerce. You\u2019re correct\u2014many of our customers also rely on tools like Voiceflow, Vapi, and others to build their agents.What they love about our platform is having both testing and observability in one place. Observability helps identify issues while testing allows them to simulate and prevent those problems before they escalate. This dual approach is especially helpful for teams dealing with voice-specific challenges, industry-specific nuances, or company-specific edge cases.Our tool is particularly valuable for teams stuck with manual testing\u2014it saves time in iterating the bot and ensure the edge cases are taken care of\n \nreply",
      "Congrats on the launch!Great to see the focus on robust and exhaustive evaluations. With large-scale usage of products, everything that can go wrong usually does so such evals will go a long way!How do you intend to grow the product?\n \nreply",
      "Thanks a lot. The focus currently is to link the observability and testing environment so that test sets can automatically be created based on findings in actual production calls. Currently, it requires human intervention to create a scenario for testing based on findings of production calls.\n \nreply",
      "I was able to easily flip the script on the return scenario to convince the rep that they were the one calling me to return - and then flipped it again. The quality of the voice was great, though.\n \nreply",
      "Thats great. We also generate adversarial scenarios for our customer's voice agents like you did. The roleplay example was made for you to get a sample evaluation of your performance.  In reality, we generate simulations automatically and provide analytics on your AI agent's performance, as demonstrated in the demo video.Glad you liked the voice quality.\n \nreply",
      "Ahh ok, understood. Thank you.\n \nreply",
      "This is super dope! Are you looking to hire? Your product made me super excited.\n \nreply",
      "Thanks a lot.Yes, we will be hiring for founding engineers pretty soon. Please reach out to founders@vocera.ai if you are interested\n \nreply",
      "Is there any way to sign up and try this without going through the sales call/demo?\n \nreply"
    ],
    "link": "item?id=42307393",
    "first_paragraph": "",
    "summary": "Welcome to the latest Hacker News sideshow where everyone pretends to understand the subtle nuances of yelling at your computer! \ud83c\udf89 Vocera presents <em>a revolutionary</em> tool for developers trapped in a reality where voice AI needs as much babysitting as a two-year-old with a Sharpie. Pioneering the \"Why hasn\u2019t this broken yet?\" approach, Vocera offers observability and testing all-in-one, because who doesn\u2019t love a good 2-for-1 deal? The comment section is aflutter with tech bros chomping at the bit to add another tool to their already bursting-at-the-seams tech stack, with occasional intermissions for job solicitations, because, of course, everyone\u2019s dream job is debugging Skynet\u2019s cousin for a living. Is it game-changing or just another buzzword buffet? Only time and endless circular tech debates will tell! \ud83d\udcac\ud83d\udd04"
  },
  {
    "title": "Amazon Nova (amazon.com)",
    "points": 247,
    "submitter": "scbenet",
    "submit_time": "2024-12-03T18:04:45 1733249085",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=42309121",
    "comments": [
      "A rough idea of the price differences...  Per 1k tokens        Input   |  Output\n  Amazon Nova Micro: $0.000035 | $0.00014\n  Amazon Nova Lite:  $0.00006  | $0.00024\n  Amazon Nova Pro:   $0.0008   | $0.0032\n\n  Claude 3.5 Sonnet: $0.003    | $0.015\n  Claude 3.5 Haiku:  $0.0008   | $0.0004\n  Claude 3 Opus:     $0.015    | $0.075\n\nSource: AWS Bedrock Pricing https://aws.amazon.com/bedrock/pricing/\n \nreply",
      "I suggest you give the price per million token as seems to be the standard.\n \nreply",
      "I'm guessing they just copy pasted from the official docs page.\n \nreply",
      "Has anyone found TPM/RPM limits on Nova? Either they aren't limited, or the quotas haven't been published yet: https://docs.aws.amazon.com/general/latest/gr/bedrock.html#l...\n \nreply",
      "Maybe they want to gauge demand for a bit first?\n \nreply",
      "You have added another zero for Haiku, its output cost is $0.004\n \nreply",
      "You're absolutely right, apologies!\n \nreply",
      "Thanks that had confused me when I compared same to Nova Pro\n \nreply",
      "Eyeballing it, Nova seems to be 1.5 order of magnitude cheaper than Claude, at all model sizes.\n \nreply",
      "This is a digression, but I really wish Amazon would be more normal in their product descriptions.Amazon is rapidly developing its own jargon such that you need to understand how Amazon talks about things (and its existing product lineup) before you can understand half of what they're saying about a new thing. The way they describe their products seems almost designed to obfuscate what they really do.Every time they introduce something new, you have to click through several pages of announcements and docs just to ascertain what something actually is (an API, a new type of compute platform, a managed SaaS product?)\n \nreply"
    ],
    "link": "https://aws.amazon.com/blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/",
    "first_paragraph": "Today, we\u2019re thrilled to announce Amazon Nova, a new generation of state-of-the-art foundation models (FMs) that deliver frontier intelligence and industry leading price performance, available exclusively in Amazon Bedrock.You can use Amazon Nova to lower costs and latency for almost any generative AI task. You can build on Amazon Nova to analyze complex documents and videos, understand charts and diagrams, generate engaging video content, and build sophisticated AI agents, from across a range of intelligence\u00a0classes optimized for enterprise workloads.Whether you\u2019re developing document processing applications that need to process images and text, creating marketing content at scale, or building AI assistants that can understand and act on visual information, Amazon Nova provides the intelligence and flexibility you need with two categories of models: understanding and creative content generation.Amazon Nova understanding models accept text, image, or video inputs to generate text outpu",
    "summary": "**Amazon Nova Descends: Ensuring You Never Have To Think or Feel Again**\n\nToday, Amazon unveils \"Amazon Nova,\" yet another way to confirm that as long as you can pay, there's no need for human intelligence. Fetching stellar \"frontier intelligence\" and \"industry-leading price performance\" from the bottomless pits of Bezos' labyrinth, Amazon assures you can crunch documents and spit out videos cheaper than ever, because who wants real creativity anymore? The tech bros in the comments are already feverishly calculating the cost-per-token, with errors that require communal intervention to correct \ud83d\ude44. Meanwhile, a brave soul laments the tornado of jargon unleashed upon us mere mortals, attempting to understand what Amazon actually wants us to buy this time. It's a classic case where buying foundation models feels closer to deciphering the Rosetta Stone than making an online purchase. Oh, and remember, if the AI revolution leads to planetary doom, at least it was \ud83d\udcb2cost-effective\ud83d\udcb2."
  },
  {
    "title": "EstyJS 2.0 (emulator for the Atari ST, written in 100% pure JavaScript) (kaiec.github.io)",
    "points": 28,
    "submitter": "nynyny7",
    "submit_time": "2024-11-29T20:40:05 1732912805",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42276928",
    "comments": [
      "Within seconds I found GFA basic (which I spent endless time programming in as a kid), and got it running. Unfortunately, I can't figure out how type an \"=\" (equals) character from my Mac laptop.\n \nreply",
      "I switched to using Firefox instead of Chrome and now \"=\" works!  :-)  I'm using GFA Basic from https://www.atarimania.com/pgesoft.awp?version=29409\n \nreply",
      "Be cool if it supported midi in browser for cubase jungle makin'!\n \nreply",
      "The MIDI support in _all_ the emulators I've seen has been fairly... not-great... overall. I should look again but I remember reading through the source for Aranym around this and being pretty disappointed.Must... resist... temptation... to write my own\n \nreply",
      "Can it run Llamatron?\n \nreply",
      ":D This was the primary function of my ST.\n \nreply",
      "I have been told Revenge of the Mutant Camels is a cult classic worth experiencing: https://www.youtube.com/watch?v=Cqt86q2PIxQ\n \nreply"
    ],
    "link": "https://kaiec.github.io/EstyJS/",
    "first_paragraph": "\n\n\t\t\tThe Atari ST was a 16 bit home computer that was very popular in the late 80's and early 90's.\n\t\t\tIt was the direct competitor of the Commodore Amiga and both machines were based upon the 68000 CPU.\n\t\t\tIt was first released in 1985 and was very sucessful in the professional music industry due to having MIDI\n\t\t\tports as standard.\n\t\tEstyJS is an emulator for the Atari ST, written in 100% pure JavaScript, originally developed by Darren\n\t\t\tColes. Since 2024 and the release of EstyJS 2.0,\n\t\t\tthe project is maintained by Kai Eckert. The source code is available on GitHub. Please use GitHub issues for feedback, bugs and\n\t\t\tideas.\n\t\t\n\t\t\tEstyJS is not a full emulation and focuses on running games or old software for demonstration purposes.\n\t\t\tNotable limitations:\n\t\t",
    "summary": "Welcome to the *nostalgia-infused circus* that is EstyJS 2.0, where aging tech enthusiasts relive their *glory days* of the Atari ST, embarrassingly trying to claw back their youth one JavaScript-emulated MID file at a time. A charming graveyard of incompatibilities\u2014where folks can\u2019t figure out how to type \"=\" on a Mac, yet swap browsers with the ease of a Commodore versus Atari debate. As the complex art of MIDI backs up an underwhelming emulator performance, the naively hopeful still dream of browser-based *Cubase jungles*. Meanwhile, the comment section devolves into a hilarious mix of tech support, reminiscences over \ud83e\udd99 Llamatron, and links to cult classic camels that surely validate the entire endeavor of hanging onto the past by a thread of poorly supported software. Stay tuned for the next update, which promises to fix everything, as it heroically fails to meet any modern expectations."
  }
]