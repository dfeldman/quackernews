[
  {
    "title": "Gordon Bell has died (arstechnica.com)",
    "points": 639,
    "submitter": "dcminter",
    "submit_time": "2024-05-21T19:23:59",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=40432688",
    "comments": [
      "NYT obit https://www.nytimes.com/2024/05/21/technology/c-gordon-bell-...",
      "Gordon was the first investor in my first startup, the first guy that believed in us.Even though I only met him later in his life he was still sharp as a tack, never lost the mind of the engineer. Sometimes it's best not to meet your heroes but Gordon lived up to the hype and then some.Super gentle, generous with his time, the consummate gentleman.One of my fondest memories from my startup years was enjoying dinner with Gordon and his wife in Sydney, she made the most amazing cookies. To this day I don't think I have had a better cookie haha.Visited the computer history museum with him once for a bit of a VIP tour I guess. So many stories about PDPs and all the friends he made along the way.Thanks for all the stories and memories old man, you have earned your rest.RIP.",
      "I wonder if that cookie recipe is written down somewhere.Gordon Bell practiced \"lifelogging\", so maybe!",
      "His lifelogging was a project called MyLifeBits. He wore a camera that took a picture every 20 seconds. Even called the book about his work Total Recall (and MSFT's new product that does something similar on the desktop is called Recall). Someone who worked with him at MSR wrote about it:https://www.linkedin.com/pulse/gordon-bell-standing-shoulder...",
      "My father worked with him at CMU and the story he always told (while possibly apocryphal) was that the reason that the ASCII bell character sequence was CRTL-G was because of Gordon.",
      "code 007, it's a secret",
      "Ah, hidden in plain sight, the seventh letter of the alphabet being G.",
      "I have no data, but I wish that to be true.  What an amazing tribute.",
      "https://www.sensitiveresearch.com/Archive/CharCodeHist/X3.4-...ASCII was developed in 1963 by a guy from IBM while Bell was at DEC. However since Bell has worked in the PDP's UART, it's possible...",
      "it seems somewhat unlikely.  let's follow the trailthe existence of bell characters, of course, predates gordon bell's existence itself (they're in the ita2 baudot-murray code from 01932, two years before his birth) so what we're discussing is specifically the assignment of the ascii bell character to the control character corresponding to bell's middle initialit was already ^g in 01963 according to tom jennings's excellent history https://web.archive.org/web/20100414012008/http://wps.com/pr... https://landley.net/history/mirror/ascii.html#ASCII-1963 and at that point bell had just started working at dec three years before.  however, he was working on serial communications at dec, and had just been doing research at mit, so it wouldn't be terribly surprising if he, or friends of his from mit or dec, were to sit on the ansi (then asa) committeemackenzie's 'coded character sets' from 01980 has a chapter 13 about ascii https://textfiles.meulie.net/bitsaved/Books/Mackenzie_CodedC... but unfortunately it doesn't go into any detail on the composition of the asa committee.  note that mackenzie was the ibm thug who invented ebcdic and spent the 60s and 70s trying to kill ascii, so he devotes most of the book to glorifying that catastrophic error; the book is from 01980, the year before ibm shipped its first ascii-supporting equipment, the ibm pc.  it's reasonable to see jennings's account as a violent reaction against mackenzie's book, writing the malignant influence of the punched-card codes out of history entirely, though, as we'll see, the original draft of ascii was designed by a punched-card manbell's oral history interviews https://www.computerhistory.org/collections/catalog/10270203... don't mention ascii or asa or ansi, so he probably wasn't on the committee, but if it was a connivance by a friend of his, it would be easy to imagine him deliberately not mentioning ithttps://dl.acm.org/doi/pdf/10.1145/363831.363839 is an early (01965) publication of what eventually became ascii-1967, but it doesn't list the subcommittee members; the subcommittee seems to have been x3.2 at that point, though the 01963 document was called x3.4-1963http://edition.cnn.com/TECH/computing/9907/06/1963.idg/ says the original proposal was submitted to ansi (though other sources say ansi didn't exist yet) by bob bemer of ibm in 01961.  i thought it would be interesting to see if it already had ^g for bel, because bemer would be unlikely to know bell at that pointin 02002 bemer wrote a 52-page history of ascii himself called 'a story of ascii' https://archive.org/details/ascii-bemer which includes a survey of coded character sets from 01960, including the character set used on the 'lincolnwriter' at mit, where bell had been working, and the pdp-1 for which bell designed the uart, as well as another 40 or so.  so it wasn't like there was no contact.  as it happens, neither of those two character sets includes a bell characterthe bell character appears in the first version of the ascii proposal in the leftmost column of table 3 on page 17 \u2014 but at position 10, from which it was moved to its current position of 7 (^g) after four revisions (iso/tc97 wg b, 01962 may 4, following x3.2/1, which was 01961 september 18).  his only comment on why they moved all the control characters around was, 'the controls were regularized and grouped to 7 transmission controls, 6 format effectors, and 5 device controls; the improvement from the haphazardness of the previous proposals is quite apparent.'  this was shortly before ibm sent him to the penalty box for promoting ascii, leading to him quitting to go to univacat that point there was still disagreement about whether to start the alphabet at the beginning of a 16-codepoint 'column' or, as is done today, one character later, so that a corresponds to 1, b corresponds to 2, etc.  so assigning bel to 7 could have ended up with it being ^h.  (i'm not clear on whether the ctrl key existed yet, but i'm pretty sure bit-paired keyboards did, on the teletype.)unfortunately bemer is also largely silent on the membership of the committee, though he does mention particular members from time to time.  unless i've overlooked it, he doesn't mention anyone from mit or dec.  the iso meeting was an international thing, with delegations from the us and various european countries, and thus seems particularly unlikely to have redesigned the character set to honor a dec engineer, who the committee members would think of as an american engineerso it's probably just a coincidence, but the evidence i've been able to turn up is not very conclusive"
    ],
    "link": "https://arstechnica.com/gadgets/2024/05/gordon-bell-an-architect-of-our-digital-age-dies-at-age-89/",
    "first_paragraph": "Front page layout",
    "summary": "**Gordon Bell Has Left The Building... To Rest**\n\nThe tech world pauses its relentless navel-gazing to mourn the death of Gordon Bell, the closest thing to a rock star in computer engineering, with tributes clogging the reality escape tube known as the Internet. A commenter fondly recalls Bell through anecdotes that sound like they were harvested from a Hallmark card, cleverly weaving in praise for a cookie recipe that could arguably be considered Bell's most impactful life's work (if you ask them). Meanwhile, ASCII aficionados wax nostalgic, debating over control character origins like conspiracy theorists around a UFO sighting, fueling the fires of irrelevance with the fervency of a college debate team. Gordon Bell\u2019s life of log-worthy marvels is reduced to a forum thread piecing together the crumbs of historical annotations and ASCII speculations, because, why worship innovators when you can debate minuscule points of computer history into verbose oblivion? \ud83d\udcbe\ud83c\udf6a\ud83d\udca4"
  },
  {
    "title": "The curious case of the missing period (tjaart.substack.com)",
    "points": 187,
    "submitter": "the_real_tjaart",
    "submit_time": "2024-05-21T18:35:13",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=40432102",
    "comments": [
      "> A portion of this code implemented a SMTP client.If I wanted to root cause this, the real problem is right there.  Implementing protocols correctly is hard and bugs like in the post are common.  A properly implemented SMTP client library, like one you would pull off the shelf, would accept text and encode it properly per the SMTP protocol, regardless of where the periods were in the input.  The templating layer shouldn't be worrying about SMTP.",
      "I agree 100%.",
      "Single responsibility principle in its finest.",
      "> Implementing protocols correctly is hardThat's why it's a best practice to specify protocols at a very high level (e.g. using cap'n'proto) instead of expecting every random sleep-deprived SDE2 to correctly implement a network exchange in terms of read() and write().",
      "That why you have to read the specs of the protocol you want to implement. Its a matter of engineering rigorousness. Brute-forcing until \"it works\" doesn't cut it.",
      "I think you're missing the fact that experience has taught us repeatedly that separating the protocol definition from the wire format is a good idea. But sure, feel free to ignore the many lessons and blame it on individuals as if anything could be implemented free from human laziness, error, & economic demands (which btw is ironically a lack of engineering rigour which I was always taught as you assume that humans will be lazy, corrupt, make mistakes & that economics of making things as cheap as possible are a real part of engineering & not something to handwave away as \"they're not doing real engineering\").",
      "To steelman the GP's POV: there are other parts of solutions to problems where similar levels of rigour are required and cannot be filled in by using a preexisting library (state machines for distributed business logic come to mind as an example). Eliminating the need for that here doesn't help that much in general, and might even make things worse, because it gives people less experience with tasks demanding rigour before they tackle ones that are both subtler and harder.",
      "Learning to blindly follow a spec for the purposes of parsing the SMTP wire protocol doesn't give you extra ability to follow the state machine or distributed business logic specs better. It just adds to the overall opportunities for you to make a mistake. This also ignores the fact that SMTP specs is split across multiple RFCs with no single normative version which further complicates the probability that you implement the spec correctly in the first place.Engineers get better faster because they leverage better tools and build tools to overcome their own shortcomings and leverage their strengths, not by constantly being beat into shape by unforgiving systems.To be fair, what you and OP said is not an uncommon mentality. It's even shared in a way by Torvalds:> [easier to do development with a debugger] And quite frankly, I don't care. I don't think kernel development should be \"easy\". I do not condone single-stepping through code to find the bug.\nI do not think that extra visibility into the system is necessarily a good thing.> Quite frankly, I'd rather weed out the people who don't start being careful early rather than late. That sounds callous, and by God, it _is_ callous. But it's not the kind of \"if you can't stand the heat, get out the the kitchen\" kind of remark that some people take it for. No, it's\nsomething much more deeper: I'd rather not work with people who aren't careful. It's darwinism in software development. It's a cold, callous argument that says that there are two kinds of\npeople, and I'd rather not work with the second kind. Live with it.He has similar views about unit tests btw.I personally would prefer to work with people who are smart & understand systems and have machines take care of subtle details rather than needing to always be 100% careful at all times. No one writing an SMTP parser is at Torvald's level.I'm not arguing that this excuses you from being careful or failing to understand things. I'm saying that defensively covering your flank against common classes of mistakes leads to better software than the alternative.",
      "> This also ignores the fact that SMTP specs is split across multiple RFCs with no single normative version which further complicates the probability that you implement the spec correctly in the first place.This is a point I agree with and the fact I see it mentioned so rarely, that standards are split across multiple RFC's makes me suspect that people don't mention it because they don't know because they never read them in the first place, and rather try to follow the implementation of some existing program.",
      "Research is also a real part of engineering. One should not omit it and end up with a SMTP implementation like in the article."
    ],
    "link": "https://tjaart.substack.com/p/the-curious-case-of-the-missing-period",
    "first_paragraph": "",
    "summary": "**The curious case of the missing period**\n\nIn a shocking twist that no one saw coming, a developer tackles the Herculean task of implementing SMTP without simply using an existing library, because why make life *easy*? The commenters, in a dazzling display of missed points and over-explained principles, transform a simple coding mishap into a philosophical treatise on software development best practices. Watch as they epicly battle it out in verbosity, waxing poetic about single-responsibility, high-level protocols, and the Darwinian brutality of Linus Torvalds' approach to coding. Fall asleep midway through their soliloquies, or join the debate on whether \"real engineers\" use debugging tools or just cry in the server room. \ud83c\udf7f\ud83d\udcbb\ud83e\udd13"
  },
  {
    "title": "Show HN: Pls Fix \u2013\u00a0Hire big tech employees to appeal account suspensions (plsfix.co)",
    "points": 241,
    "submitter": "jpdpeters",
    "submit_time": "2024-05-21T17:12:22",
    "num_comments": 228,
    "comments_url": "https://news.ycombinator.com/item?id=40431126",
    "comments": [
      "This is commercial bribery in most places.>California Code, Penal Code - PEN \u00a7 641.3>(a) Any employee who solicits, accepts, or agrees to accept money or any thing of value from a person other than his or her employer, other than in trust for the employer, corruptly and without the knowledge or consent of the employer, in return for using or agreeing to use his or her position for the benefit of that other person, and any person who offers or gives an employee money or any thing of value under those circumstances, is guilty of commercial bribery.>(b) This section does not apply where the amount of money or monetary worth of the thing of value is two hundred fifty dollars ($250) or less.",
      "Sounds like the law already provides a convenient solution (in the form of a \"<=250\" constraint on the bid field).",
      "As long as it's less than $250 per instance that sounds fine...?",
      "IANAL, but this sounds like it could run afoul of the federal wire fraud or honest services fraud [1] provisions.[1]: https://en.wikipedia.org/wiki/Honest_services_fraud",
      "As in \"not illegal, but still gonna get you fired?\"",
      "They'll just submit a request themselves so another employee reinstates them.",
      "I fully understand why this is considered unethical. I fully understand that employees will get fired for taking the bounties.But what actual law is being broken here? I suspect it is legally a bribe, because it is facilitating a non-routine action. But only because of that non-routine bit. Would it be possible to prosecute this, going into court and admitting that your suspension appeals process is non-routine?And what part of a standard employment contract is being broken here? Taking money to perform a service your employer does not offer? And interestingly, if the employer does offer the service, then it is no longer a bribe but a legal facilitation payment (so you would want a clause in the employment contract to prevent this)(Not rhetorical - looking for answers to the above questions)In many ways, this process already happens, and even expected by all concerned. More than once I've seen twitter personality manages to get some decision reversed seemingly only because they could make enough noise, often ending up on the front page here. The difference is in the currency used to pay to bypass the system.",
      "There is a simple fix.  Just make the amount a contribution to a charity or charity's of their choice.  Makes it a much harder to fire someone who is earning money for a charity, perhaps even one the company contributes to annually.",
      "Came here to say this. Seems like a slam dunk to me.",
      "My employment contracts have all required at minimum that I inform them of any commercial work I am doing outside my employment for them, and sometimes required that I get approval from them before beginning. Having some undisclosed second employment would definitely be grounds for firing, if they wanted."
    ],
    "link": "https://plsfix.co/",
    "first_paragraph": "",
    "summary": "Welcome to the latest tech disruption: <em>Pls Fix</em>, a daring hybrid of Silicon Valley innovation and potential legal disaster where big tech employees get paid under the table to unsuspend your social media accounts. Commenters, quick to flex their Google Law Degrees, dive into a riveting discussion on whether slipping a tech employee a cool $249 is just smart business or will lead you straight to the slammer. Spoiler alert: the real crime might just be the level of optimism about this sketchy legal/ethical tightrope walk. Who needs laws when you have disruptive tech ideas and a handy loophole, right? \ud83d\ude02\ud83d\udc69\u200d\u2696\ufe0f\ud83d\udcb8"
  },
  {
    "title": "CADmium: A local-first CAD program built for the browser (mattferraro.dev)",
    "points": 389,
    "submitter": "samwillis",
    "submit_time": "2024-05-21T14:19:56",
    "num_comments": 152,
    "comments_url": "https://news.ycombinator.com/item?id=40428827",
    "comments": [
      "I'm very excited about what Matt is building, the world desperately needs a good open source parametric CAD package. One where the UI/UX is designed to be as \"easy\" to use a SolidWorks.The biggest reason this hasn't happened so far is the lack of a truly capable parametric kernel, Truck, the kernel that Matt is using looks like an incredible project and exactly whats needed. The only other kennel till now that been close to being whats needed is OpenCascade, but its lacks important features, is buggy and at times quite unstable.Once Truck (and CADmium) lands stable fillets (surprisingly one of the hardest features to make stable) it will prove itself as the perfect successor to OpenCascade and and the perfect platform to build the future of open source parametric CAD upon.",
      "Maybe I'm not enough of an evangelist, but I just want a good, non-subscription local-first CAD package.I've recently moved over to Alibre Atom3D, which, while not open-source, costs $200. Once. Then (as long as your host OS doesn't change too much) you can access your designs forever. It runs on the ACIS kernel.\"Browser first\" and (from the readme) \"Beyond that, I will try to monetize by offering a hosted version of the software as a paid product.\" reads to me like this project is doomed to either fizzle or to grow and transform into an open-core, subscription-requiring product, accumulating more complicated dependencies to install and \"security features\" that make it harder and harder to run in truly local fashion.",
      "The problem with Alibre is that it only works on Windows. I switched from FreeCAD to the free (as in beer) version of Onshape, which works in the browser and is a night and day difference over FreeCAD.Your designs are wide open for anyone to see, but I can live with that for hobby stuff.",
      "I wouldn't mind having my models public, but that it SaaS is such a nuisance and the reason I am sticking to FreeCAD. I want to be able to edit offline, like on an airplane and not lose the ability to edit my stuff if some company shuts their servers down.",
      "I probably spent 100 hours trying to tame FreeCAD, and ended up thinking CAD was just not for me. I then tried Onshape and found out that the problem was elsewhere.",
      "I think there's probably a vast range of use cases where having the models freely available isn't hindrance",
      "Feel the same way. Honestly I think there's more money to be had going open source than competing in a sea full of sharks. But hey, that's probably wishful thinking from my part.",
      "But that open-core subscription model is the way open source makes money! Not enough people pay for software out of the goodness of their hearts to make a living off of it.",
      "All subscription software is just a protection racket.Nice files you got there. It would be a shame if they suddenly become unreadable, eh?Even the so called \"open\" core is a joke. Just try to add anything useful. It will get rejected in favor of a paid option.The whole thing is just an offensive anathema to open source.",
      "I will say that the FreeCAD weekly builds have made massive strides; I believe the toponaming fix is in the latest mainline weekly now and Ondsel have been contributing great work back from their branch as well.I\u2019ve been playing around with the weekly version and using the OpenDark theme.  It looks pretty slick.It seems like a really exciting time for open-source CAD (hopefully!)."
    ],
    "link": "https://mattferraro.dev/posts/cadmium",
    "first_paragraph": "We're building a new open-source CAD program. We've gotten pretty far, but we need your help.",
    "summary": "In the latest episode of *Software Savior Fantasies*, Matt Ferraro heralds the coming of CADmium, a CAD tool that promises to revolutionize nothing. Crowds of developers, desperate for any glimmer of hope in the open-source CAD wasteland (where apparently \"stable fillets\" are equivalent to the Holy Grail), are throwing themselves at Matt's GitHub repo. Commenters wax poetic about the mystical \"Truck\" kernel, heralded as the savior of their engineering souls, while simultaneously mourning the inevitable slide into a SaaS subscription hell. To round off the party, we've got hobbyists who just discovered browser-based CAD exists and couldn\u2019t be more thrilled to voluntarily lobotomize their privacy for the convenience of losing their work mid-flight. It's open-source drama meets Industrial Design idolatry, grab your popcorn! \ud83c\udf7f\ud83c\udfa8"
  },
  {
    "title": "What UI density means and how to design for it (matthewstrom.com)",
    "points": 520,
    "submitter": "delaugust",
    "submit_time": "2024-05-21T13:41:39",
    "num_comments": 280,
    "comments_url": "https://news.ycombinator.com/item?id=40428386",
    "comments": [
      "This explains exactly why physical restaurant menus are so much better vs mobile site menus. If I'm viewing the menu of a restaurant on my phone, I always look in Google Maps for someone who took a picture of the menu, because it's a dense UI. Every \"mobile friendly\" menu site is able to show maybe 5 items on the page at once, so it takes many pages of scrolling to see everything.",
      "I love how \"mobile friendly\" seems to just mean it will waste some space your phone screen can't afford.",
      "Plus, if there is wasted space, you can jam an ad in there.",
      "I permanently use desktop mode on my phone browser",
      "same here.  also your username is amusing :)",
      "Why on Earth?",
      "Because it's objectively better. I also exclusively use desktop mode, and I can tell when a site's designer can't comprehend this choice.",
      "I wouldn't do it permanently, but I use the feature sometimes myself.Some sites disabled pinch zooms (massively frustrating for images). Some sites exclude information in mobile view. I'm sure there's other reasons too.Facebook, Reddit and Amazon all have terribly made mobile versions of their sites, for example.Reddit's is comically bad, like they hired interns to make it who tried trendy stuff but didn't understand how to implement any of it properly.",
      "I recently found an option in mobile Chrome \"Settings > Accessibility > Force enable zoom\" which overrides a website's request to prevent zooming in. Highly recommended",
      "Yes, very useful. You can do the same on Firefox for Android: \"Settings > Accessibility > Zoom on all websites.\""
    ],
    "link": "https://matthewstrom.com/writing/ui-density/",
    "first_paragraph": "May 20, 2024 \u00b7 20 min read",
    "summary": "In a precious revelation equivalent to discovering gravity, the digital minds on <em>matthewstrom.com</em> selflessly explain the unbelievably nuanced concept of \"UI density\" \u2014 because squinting at your phone like a confused owl enhances dining indecisiveness. Thankfully, public saviors in the comments unveil their revolution of browsing menus in desktop mode on mobile devices, a stratagem surely marked for a Nobel. Each d\u00e9coupage of UI insights gets paired with grand complaints about mobile versions of virtually every site \u2014 because if you can't zoom in to see each pixel, is it even worth viewing? Cue applause for the re-discovery of buttons that make tiny things slightly less tiny. Bravo, change the world, disrupt our screens. \ud83c\udfad\ud83d\udc4f"
  },
  {
    "title": "A Road to Common Lisp (stevelosh.com)",
    "points": 6,
    "submitter": "fuzztester",
    "submit_time": "2024-05-21T23:59:39",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://stevelosh.com/blog/2018/08/a-road-to-common-lisp/",
    "first_paragraph": "Posted on August 27th, 2018.",
    "summary": "Today on the vintage corner of the internet, a brave soul attempts to resurrect Lisp\u2014because what the world lacks are parentheses and niche programming humor. Steve, from a bespoke basement no doubt cluttered with mechanical keyboards, treats us to \"A Road to Common Lisp.\" He maps out a path that precisely three people will follow, all of whom are arguing in the comments about the superiority of their Emacs configurations. Watch as they inevitably descend into sharing dotfiles that none of them will actually use. Meanwhile, the rest of the world moves on, unconcerned with the Lisp and parentheses population problem. \ud83d\ude80\ud83e\udd13"
  },
  {
    "title": "Designed to Crash: the story of Antonov An-28 HA-LAJ and its demise (admiralcloudberg.medium.com)",
    "points": 16,
    "submitter": "sklargh",
    "submit_time": "2024-05-21T22:35:15",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://admiralcloudberg.medium.com/designed-to-crash-the-bizarre-story-of-antonov-an-28-ha-laj-and-its-demise-169b3720d924",
    "first_paragraph": "",
    "summary": "Once again, the world is treated to an intellectually stimulating autopsy on the demise of the Antonov An-28 HA-LAJ, because what we all truly lack in our lives is a deep understanding of how Soviet-era aircraft tick (or rather, tock before they go boom). The author, a high priest in the temple of historical aircraft trivia obscura, unravels the intricate failings of this metal sky bird with the meticulous care of a cat dissecting its last meal. The comment section, as expected, transforms quickly into a battleground where aviation \"experts\" and history buffs lob factoids and barely-masked insults at each other, each trying desperately to prove they missed their calling at the NTSB. Truly, a riveting read for anyone who marvels at humanity\u2019s ability to argue about anything, including decades-old airplane parts. \u2708\ufe0f\ud83d\ude31"
  },
  {
    "title": "The Stanford Startup and the MIT Startup (2013) (fpgacomputing.blogspot.com)",
    "points": 43,
    "submitter": "momofuku",
    "submit_time": "2024-05-21T21:35:35",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=40434290",
    "comments": [
      "Discussed at the time:The Stanford Startup and the MIT Startup - https://news.ycombinator.com/item?id=6715864 - Nov 2013 (85 comments)",
      "Might as well called Stanford B2C and MIT B2B.  Yeah, B2B needs more capital since they are building a plant while B2C is really about sourcing materials, packaging and marketing.  Completely different businesses, different CapEx and OpEx models, different risks and different investors.",
      "I thinks it\u2019s more hard tech vs traditional startup.",
      "What is (maybe better left) unspoken are the kinds of errors attributable to both strategies.  The really great tech that never makes it to consumers and is lost, only to be rediscovered years later--MIT.  Garbage software that consumers are tricked or forced into using--Stanford.",
      "I find this kind of rhetorical device tiring to read when it goes on and on like this. Once I read the conclusion I felt like I'd be cheated and it could have just said that in the beginning."
    ],
    "link": "http://fpgacomputing.blogspot.com/2013/11/the-stanford-startup-and-mit-startup.html",
    "first_paragraph": "This blog is a notebook of my thoughts on parallel programming and accelerated computing. The instruction stream is deprecated: parallel programming is a spreadsheet.",
    "summary": "In the latest round of \"Who Can Sound More Pretentious?\", a blogger reminisces on the good old days when terms like \"parallel programming\" were avant-garde enough to make you the star of any hipster tech meetup. The commentary from the grand stands of Hacker News oscillates between treasure and trash\u2014MIT is the lost ark of unrealized dreams while Stanford pops out consumer tech trash like a dysfunctional vending machine. Both factions evoke nostalgia for tech dilemmas more riddled with holes than their arguments, culminating in a chasm of wasted potential and despondent sighs from readers searching for a point. TL;DR: Tech's equivalent of dividing the laundry\u2014colorful but ultimately, does anyone really care? \ud83e\udd37\u200d\u2642\ufe0f"
  },
  {
    "title": "Wikimedia Enterprise \u2013 APIs for LLMs, AI Training, and More (wikimedia.com)",
    "points": 94,
    "submitter": "ks2048",
    "submit_time": "2024-05-21T20:32:30",
    "num_comments": 62,
    "comments_url": "https://news.ycombinator.com/item?id=40433511",
    "comments": [
      "While i am sympathetic to wmf finding alternative funding streams, I do get nervous about these sort of things due to the inherent conflict of interest and incentives to canabalize the free offerings.  I'm not saying that is happening now, but will it happen eventually?Additionally, originally it was promised this would all be open source, and officially they are sticking with that, but it seems like they are going with the model of throwing code over the fence like once a year, which does not really meet my expectations.",
      "I\u2019d rather Wikipedia offer it versus a for profit enterprise using their dataset. Cut out the middleman and vertically integrate.",
      "There's a whole statement-of-principles thing that at least implies that the intention isn't to cannibalize the existing offerings: https://meta.wikimedia.org/wiki/Wikimedia_Enterprise/Princip...Though I imagine that only works so far as you feel you can trust the Foundation to stick to those principles, so that's complicated. :DThere's also a bunch of FAQs here that sort of get at how the funding streams are supposed to integrate into the existing structures and how it's supposed to avoid pushing out the free services: https://meta.wikimedia.org/wiki/Wikimedia_Enterprise/FAQ(As I said elsewhere, I work for the WMF but I don't work on anything related to this so I'm just commenting as someone who has more experience searching through our public info than most HN commenters would...)",
      "Yet this also exists: https://en.wikipedia.org/wiki/Wikipedia:Database_download",
      "Which is a good thing. The entire corpus is CC-licensed and anyone can download it for free. If you want a real-time API, performance SLAs, machine parsable formats, support etc. then pay for it.",
      "It also seems Wikimedia isn't trying to relicense the content in any way that strips its e.g. CC-SA status, but rather providing the licenses as context alongside each API call. https://helpcenter.enterprise.wikimedia.com/hc/en-us/article...It's worth noting that https://creativecommons.org/faq/#artificial-intelligence-and... itself takes the general stance that \"as a general matter text and data mining in the United States is considered a fair use and does not require permission under copyright.\"But as a practical matter, I wouldn't be surprised if some Wikipedia editors balk at their volunteer work being actively marketed and reformatted for ease of LLM training by the very platform that solicited their volunteer services, regardless of their works' legal status and Wikimedia's technical respect of that legal status.",
      "> I wouldn't be surprised if some Wikipedia editors balk at their volunteer work being actively marketed and reformatted for ease of LLM trainingAs someone who avidly edited Wikipedia for 6-8 years, I am happy to see my volunteer work used for LLM training.  I also agree some other editors likely aren't.",
      "I don't have a problem with having paid special services, but the \"machine parsable formats\" is a bit troubling since I think that should be a core part of the open wikipedia project.I submit this link after coming across this site while Googling for info on parsing wikipedia \"infoboxes\". I plan to check out their \"Article Structured Contents (BETA)\" API. Improving infoboxes to be machine-readable seems important. And it would be bad if didn't do this because it's a revenue stream for them.",
      "There\u2019s also Wikidata which has machine readable data for everyonehttps://m.wikidata.org/wiki/Wikidata:Main_Page> Wikidata is a free and open knowledge base that can be read and edited by both humans and machines.> Wikidata acts as central storage for the structured data of its Wikimedia sister projects including Wikipedia, Wikivoyage, Wiktionary, Wikisource, and others.",
      "Yes, but it is different dataset, many(majority?) infoboxes are not in wikidata"
    ],
    "link": "https://enterprise.wikimedia.com/",
    "first_paragraph": "Wikimedia Enterprise",
    "summary": "Wikimedia Enterprise has decided to grace us with <em>APIs for LLMs, AI Training, and More</em>, a capitalist haven wrapped up in the altruistic banner of \u201cfunding streams\u201d. The comment section unfolds as a tragicomedy with concerned netizens teetering on a tightrope of hypocrisy. While they gnash teeth over potential conflicts of interest and the slow-drip open source commitments, a chorus of keyboard warriors passionately extols the virtues of keeping Wikipedia\u2019s venerable data peasant-work free, yet are paradoxically thrilled to watch it fuel those icky, sleek LLMs. Watch as the Wikimedia Foundation attempts to not cannibalize its own ethos while everyone pretends that their once-a-year code toss isn\u2019t just a glorified database dump. \ud83d\ude43"
  },
  {
    "title": "Show HN: Openpanel \u2013\u00a0An open-source alternative to Mixpanel (github.com/openpanel-dev)",
    "points": 70,
    "submitter": "lindesvard",
    "submit_time": "2024-05-21T18:43:50",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=40432213",
    "comments": [
      "I run a saas where we host a number of websites, can I use this for us to track visits, events etc across multiple sites? We want aggregated results not per site metrics",
      "I have plans to support this!",
      "This doesn't seem to be buffering inserts to ClickHouse: https://github.com/Openpanel-dev/openpanel/blob/c90848765a6a...So any major website will have problems with it. I would suggest moving this into a stream (NATS, Kafka) or just having some sort of service that buffers events, then offloads to Clickhouse in batch.",
      "Correct! Currently no batching but no need to make things complicated for now.Can extend the current redis queue to batch request or clickhouse batch engine.Looking forward to have these problems hehe.Please DM if you want to chat about best approach!",
      "Or enable async inserts on the ClickHouse client, which won't require changing to the buffer table engine.https://clickhouse.com/docs/en/optimize/asynchronous-inserts",
      "Have read about this, but totally forgot about it! Will try it out!",
      "Won't this be a problem as soon as a website reaches, say, 600 RPS? Which is not much.",
      "I have time to grow. Don\u2019t think I\u2019ll hit this level just yet.",
      "Waiting for the self-hosted version... would be great to be able to deploy this with Kubernetes too",
      "Noted"
    ],
    "link": "https://github.com/Openpanel-dev/openpanel",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "In the latest act of open-source heroism, \"Openpanel\" emerges to save the day from the cruel clutches of paid analytics platforms, promising a free ride to Dysfunctional Datasets Land. Tech hobbyists and side-project warriors descend into the comment section armed with band-aids and GitHub links to triage an apparently bleeding infrastructure. One brave coder suggests streaming with Kafka because... why not throw in another buzzword to keep the project hip? Meanwhile, other soon-to-be customers are throwing feature requests into the mix like it\u2019s Happy Hour at the Feature Bar, because <em>clearly</em>, nothing spells success like planning Kubernetes integration before ensuring the platform can handle the traffic of a sleepy blog. \ud83c\udf10\ud83d\udca5\ud83d\udcbb"
  },
  {
    "title": "Business Booms and Depressions Since 1775 (1943) (stlouisfed.org)",
    "points": 142,
    "submitter": "throw0101d",
    "submit_time": "2024-05-21T15:19:00",
    "num_comments": 115,
    "comments_url": "https://news.ycombinator.com/item?id=40429581",
    "comments": [
      "I'd recommend looking at the full PDF(make sure you zoom out or scroll horizontally as its very wide):https://fraser.stlouisfed.org/files/docs/publications/1943ch...Incredible visualization. Insane given they didn't have computer screens at the time.What stands out the most to me is that the 30s were really, really bad. Way worse than anything that came before.",
      "The feature that stands out the most to me is that the black \"boom or bust\" line that shows prosperity/recession is effectively never at 100. It crosses the line (going up or down) a bunch of times, but is almost never on the line. I have to wonder if more balance with this would result in better outcomes, or worse.Also, and this is just an eyeball analysis from the pdf, the booms seem roughly balanced with the busts until the great depression. The prosperity of WWI seems to have set up the cycle of bust for the great depression.",
      "> but is almost never on the lineThe water surface in the ocean is almost never at \"sea level\".Markets are a chaotic system.> the booms seem roughly balanced with the busts until the great depressionYup. Like waves in the ocean!> The prosperity of WWI seems to have set up the cycle of bust for the great depression.The setup was to peg the dollar exchange rate with gold, and then inflate the money. Such \"pegging\" historically has always led to a massive correction.",
      "I kind of wish the scale would go out further into history; I'm not sure if something like that exists (maybe for someplace like England or China?). I also would like to see it replicated for different areas of the world, as well as how the trends correlate with one another over time.The period since the industrial revolution has been anomalous in many respects in terms of population dynamics and public health, and I imagine it would show up somehow in economic trends? On the other hand going back further in time I assume it becomes increasingly difficult to scale things on some common metric.",
      "It was so bad, some arseholes started a war at the end of the decade.",
      "The crippling reparations exacted on Germany were probably the greatest geopolitical miscalculation to date",
      "Just wait, the work to surpass this miscalculation is already well underway.",
      "Curious to know what equivalence you\u2019re making?",
      "Oh I don't know, trying to make a country with twice the population, 50 times the area, and allied with a superpower a pariah state?",
      "I'm still confused"
    ],
    "link": "https://fraser.stlouisfed.org/title/business-booms-depressions-since-1775-145",
    "first_paragraph": "Home\n                 > Browse by Title > Business Booms and Depressions Since 1775",
    "summary": "Title: *Economists Discover Long Feature Canvas Called \"History\"*\n\nAh, the St. Louis Fed made a *magic pdf scroll*, celebrating every financial hiccup from 1775 with tiny print no mortal can read without a microscope! Our esteemed internet commenters, in true form, swarmed this relic with keen insights like \"Wow, the '30s sucked!\" and groundbreaking analyses akin to comparing market fluctuations to unpredictable ocean waves\u2014because, obviously, no one noticed that before. The collective brilliance suggests an itching desire to see this financial rollercoater stretched back to the dinosaurs or perhaps plotted for Mars' economy. Hey, anyone up there checked how the Martian Great Depression is going? \ud83d\ude80\ud83d\udcb8"
  },
  {
    "title": "Fast real time fluid simulator based on MPM algorithm (kotsoft.github.io)",
    "points": 33,
    "submitter": "andrewla",
    "submit_time": "2024-05-21T15:41:04",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=40429878",
    "comments": [
      "IMHO it behaves too much like a particle system. Even from the start, individual particles seem to pass through what should be a large pool of fluid at the bottom. Interesting, but doesn't seem physically realistic.",
      "Looks like this is the repo https://github.com/kotsoft/kotsoft.github.io",
      "Fun that it supports multi-touch!",
      "> MPM algorithmhttps://en.wikipedia.org/wiki/Material_point_method",
      "Sort of looks like the weird stuff on the TV in Vivarium",
      "this is absolutely fantastic.  i wonder what the source code looks like",
      "Salad dressing!"
    ],
    "link": "https://kotsoft.github.io/",
    "first_paragraph": "",
    "summary": "Today in the land of overengineered hobbies, a brave developer unleashes the \"Fast real time fluid simulator based on MPM algorithm,\" or as commenters quickly dubbed it, \"Fancy Particles Masquerading as Water.\" One astute observer notes that it's more like a digital salad dressing than a believable liquid, questioning the fabric of simulated reality\u2014because if your virtual water can't pool accurately, what hope do you have in the real world? Another encourages us to touch, <em>swipe</em>, and probably even smack the screen in a multi-touch tribute to unrealism. Meanwhile, someone just looks on in existential tech dread, clearly pondering if this is all programming life has to offer. \ud83e\udd14\ud83d\udca7"
  },
  {
    "title": "Windows Copilot Runtime (windows.com)",
    "points": 26,
    "submitter": "plurby",
    "submit_time": "2024-05-21T20:25:46",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=40433425",
    "comments": [
      "51 mentions of \u201cAI\u201d in less than 5000 words.If anything, it\u2019s infused in every layer of this press release.",
      "bullshit.js really lights up the page.https://mourner.github.io/bullshit.js/",
      "> This is a bullshit leap in performance, made possible by a bullshit leap in bullshit.",
      "\u201cAI infused at every layer\u201cOkay\u2026 What does that even mean?  And why does the company think we want that?I love me some AI, but right now it\u2019s getting put on everything like Nutella at a hipster eatery.",
      "it's a \"fundamental transformation of the OS itself\", you see",
      "The problem is that \"AI\" isn't a feature. It's not a product. It's a pretty broad category of technologies that can be used to build features and products.\"AI infused at every layer\" is like saying \"we build our software with the best Agile(tm) practices\". The customer doesn't care how you built the software, the customer cares what your software will do for them, and all \"AI\" means is \"we probably have a deep learning inference engine somewhere under the hood, but no promises\".",
      "Most likely more effective data harvesting. Individual user level AI isn't the end goal I don't think. It's just a nice byproduct. This just means they can embed more data collection, and use your device to crunch the numbers for them.",
      "We don\u2019t want that. Investors want that.",
      "12 cores, possibly all of them P-cores (they've said that SXE comes in bins up to 12 p-cores), and some early benchmarks are putting SXE cores as ~15% slower than M3? That indicates this is a $900 machine comparable to the entry-tier $2000 Mac Studio (12c/32gb), which is still on M2 and only has 8 p-cores. Its TDP is also pretty comparable to the M2 Max, at 80 watts.This is quite an incredible achievement from Qualcomm. I'm very excited to get one of these and install Linux on it. And, stoked to see if future iterations of the Steam Deck eventually make the jump to ARM."
    ],
    "link": "https://blogs.windows.com/windowsdeveloper/2024/05/21/unlock-a-new-era-of-innovation-with-windows-copilot-runtime-and-copilot-pcs/",
    "first_paragraph": "",
    "summary": "**Windows Copilot Runtime: A Miracle of Modern Marketing**\n\nWith the unveiling of Windows Copilot Runtime, it's clear that the term \"AI\" has become the tech world's equivalent of pumpkin spice \u2013 seemingly sprinkled into every product regardless of necessity or season. The corporate press machine churns out another *spectacular* buzzword salad, with phrases like \"<em>AI infused at every layer</em>\" leaving readers both dazzled and bewildered, mostly the latter. In the comment section, tech enthusiasts engage in Olympic-level mental gymnastics trying to decipher what this might actually mean for their user experience. Most agree, it's probably just a new, exciting method to harvest data while pretending your new laptop is secretly a Transformer. Well done, marketing! \ud83e\udd16\ud83d\udcbc"
  },
  {
    "title": "Clever code is probably the worst code you could write (engineerscodex.com)",
    "points": 98,
    "submitter": "rbanffy",
    "submit_time": "2024-05-21T22:21:35",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=40434766",
    "comments": [
      "I think \u201cclever\u201d is more related to unfamiliarity.There is actually a lot of cleverness going on that people just become familiar with.Structured programming is actually very clever if you think about it.Function calls are, when you look at it closely, very clever. It encapsulates how to jump to a function entry point, how to pass on values in registers or in memory, how to adjust stack pointers, and all other sorts of cleverness.For loops are clever with different parts of the statement controlling and executing different parts of the loop.Compare that with BASICA six year old child can understand:    10 PRINT \u201cHello\u201d\n    20 GOTO 10\n\nGoing on to object oriented programming, dynamic dispatch and v-tables are clever. What you call and where you go to in your program are determined by the dynamic type of an object. This is very far from the simple BASIC GOTOWhat difference does looking at it like this make.First we don\u2019t reject automatically reject new concepts just because they aren\u2019t simple. While function calls are complex, they bring many benefits. In addition, this approach emphasizes the role of education to in taking useful concepts and making them familiar to a broader group of people.",
      "I think there's a difference between \"clever\" and complex.You can express a complex algorithm or pattern with simple easy to understand code - complexity doesn't have to manifest itself as unreadable or incomprehensible code.To me \"clever\" code is more about they way you are doing something than the complexity of what you are trying to do. Clever is the opposite of straightforward and easy to comprehend without a detailed explanation.For example you might be \"forced\" to write clever code as an optimization to calculate something in a non-obvious way, maybe also based on some non-obvious pre-conditions that have been assumed and make this a valid approach.You don't normally want to write \"clever\" code - you want to write easy to understand straightforward code, and on the occasion when you feel compelled to a clever implementation, for the sake of future you or your teammates, you better precede it with a block comment prefixed with \"here be dragons\" and a detailed explanation of what it is doing and why it is doing it in this non-obvious way.",
      "I also prefer this perspective. I had an epiphany about this sort of code when I was trying to describe what my code did for a research paper, and in trying to express why I was proud of it, I called it complex, only for my research advisor to point out that complexity was not the point of the work, so calling it complex did not convey what about it made the research interesting.Although it wasn't his intention, it changed my perspective on the \"clever\" tricks I liked using, since it made me realize that being clever was not the kind of complexity that mattered. So, nowadays I try to write simple, easy to understand code, leaving the cleverness and complexity to the way the problem is tackled.",
      "It's not this and there is a test:Judging something assumes at least a minimal level of expertise in both the domain and language. I don't know Ruby, a lot looks obtuse, that's not a sign of clever code. If I see examples like the article in languages I know, it's 'clever code'.",
      "Yes. A relevant quote from Alan Kay in his talk \u201cthe power of simplicity\u201d:> one of the things that's worked the best the last three, or four hundred years, is you get simplicity by finding a slightly more sophisticated building block to build your theories out of. its when you go for a simple building block that anybody understand through common sense, that is when you start screwing yourself right and left, because it just might not be able to ramify through the degrees of freedom and scaling you have to go through, and it's this inability to fix the building blocks that is one of the largest problems that computing has today in large organizations.  people just won't do ithttps://youtu.be/NdSD07U5uBs",
      "Cleverness is like connecting dots.It might be an instance that reveal a smooth curve that seems so obviously clear afterward but was unfathomed so far.Or it can cast a baffling intricated sequence of discrete points each generated at coordinates using the previous one in a well specified but completely ungrabbable way, the whole drawing a scary screaming face that any sane mind will flea away from.",
      "Here's an old joke about the progression from junior to mid-level to senior developer:Junior dev: My code is simple, straightforward, and easy to understand.Mid-level dev: My code is clever, innovative, expressive, hyper-optimized, and ingenious.Senior dev: My code is simple, straightforward, and easy to understand.In software development, \"clever\" solutions are like poems. In the best poems, there are usually multiple layers of meaning, nuances and subtleties, some harder to tease out than others. Sometimes you have to sit with a poem for a while before you are able to truly drink it all in. To mid-level engineers, writing this sort of poetic code has an intoxicating appeal. It allows them to flaunt their talents, demonstrate their mastery of the language, and impress their colleagues with their ingenuity.But more often than not, what is really needed is the code version of ordinary prose: straightforward, with a preference for clarity over succinctness, easy for others to understand, easy to edit, and with fewer surprises and deviations from convention than a poem. With prose, particular the sort of no-nonsense style found in wire news reports and explanatory journalism, the best work is easy for the reader to comprehend and lends itself to being edited. For instance, a skilled copy editor can condense it to fit, if need be.",
      "I don't think it's accurate, though. Junior devs often write overly complicated code because they don't really understand the problem they're trying to solve. Junior devs write unintentionally complex code, mid-level devs write intentionally complex code, senior devs write simple code.",
      "Sometimes seniour devs write complex code but hide the complexity behind a simple interface.",
      "With a slight difference that junior dev tends be proud of the code they\u2019re added while a senior will be proud of the code they\u2019ve removed\u2026"
    ],
    "link": "https://read.engineerscodex.com/p/clever-code-is-probably-the-worst",
    "first_paragraph": "",
    "summary": "In the latest scintillating sermon from the scripture of \"if it hurts, it means it\u2019s working,\" engineerscodex.com enlightens the masses on why clever code is tantamount to tech heresy. Hordes of commenters then engage in intellectual Olympics to determine whether their code is Einstein-ing its way out of maintainability or just showing off like a junior dev at a hackathon. Meanwhile, those in the know recognize that the true disaster is not the code but needing four paragraphs to determine if a function call is a stroke of genius or just another Tuesday in the compiler's life. In the end, we're reminded that \"clever\" is just another word for \"I forgot to comment my spaghetti code.\" \ud83c\udf5d"
  },
  {
    "title": "I want flexible queries, not RAG (win-vector.com)",
    "points": 82,
    "submitter": "jmount",
    "submit_time": "2024-05-21T17:19:46",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=40431210",
    "comments": [
      "> There is a lot of excitement around retrieval augmented generation or \u201cRAG.\u201d Roughly the idea is: some of the deficiencies in current generative AI or large language models (LLMs) can be papered over by augmenting their hallucinations with links, references, and extracts from definitive source documents. I.e.: knocking the LLM back into the lane.This seems like a misunderstanding of what RAG is. RAG is not used to try to anchor to reality a general LLM by somehow making it come up with sources and links. RAG is a technology to augment search engines with vector search and, yes, a natural language interface. This concerns, typically, \"small' search engines indexing a specific corpus. It lets them retrieve documents or document fragments that do not contain the terms in the search query, but that are conceptually similar (according to the encoder used).RAG isn't a cure for ChatGPT's hallucinations, at all. It's a tool to improve and go past inverted indexes.",
      "There's no particular requirement for a RAG application to use vector search or embeddings, and there's no requirement that semantic similarity is in play (i.e. \"retriev[ing] documents...that do not contain the terms in the search query\"). Fundamentally RAG is just doing some retrieval, and then doing some generation. While the traditional implementation definitely involves vector search and LLMs,  there are plenty of other approaches; ultimately at anything beyond toy scale it sort of begins to converge with the long history of traditional search problems rather than being its own distinct thing.",
      "This feels like a \"No true Scotsman\" answer. You say> RAG is not used to try to anchor to reality a general LLM by somehow making it come up with sources and links.but that definitely is one particular use of RAG, i.e. to limit some potential hallucinations by grounding it in data provided in the prompt.",
      "Not really. RAG works very differently from a general (or generalist?) LLM.RAG is vector search first. It encodes the query, finds nearest vectors in the vector database, retrieves the fragments attached to those vectors, and then sends those vectors to the LLM for it to summarize them.A general LLM like Gemini or Claude or ChatGPT first produces an answer to a question, based on its training. This doesn't involve searching any external source at that point. Then after that answer is produced, the LLM can try to find sources that match what it has come up with.",
      "You don't have to use vector search to implement RAG. You can use other search mechanisms instead or as well - whatever it takes to populate the context with the material most likely to help answer the user's question.Two common alternatives to vector search:1. Ask the LLM to identify key terms in the user's question and use those terms with a regular full-text search engine2. If the content you are answering questions about is short enough - an employee handbook for example - just jam the whole thing in the context. Claude 3 supports 200,000 tokens and Gemini Pro 1.5 supports a million so this can actually be pretty effective.",
      "This is a generalization.  These proprietary systems do different things at different times. With GPT4o you can see little icons when a RAG is in use or when code and tests are being used.People, we have to stop talking about what we know as though it's all there is. Don't confuse our knowledge for understanding.  Understanding only comes from repeadly trying to prove our understandings wrong and learning how things truly are.",
      "> It lets them retrieve documents or document fragments that do not contain the terms in the search query, but that are conceptually similar (according to the encoder used).I played with Latent Semantic Indexing[1] as a teen back in early 2000s, which also does kinda that. I haven't read much on RAG, I'm assuming it's some next level stuff, but are there any relations or similarities?[1]: https://en.wikipedia.org/wiki/Latent_semantic_analysis#Laten...",
      "By far the best way I've found to reduce hallucinations is to explicitly allow the model to say some version of \"I don't know\" in the prompt.",
      "That's really interesting. Can you give any examples of how you do that?",
      "> It lets them retrieve documents or document fragments that do not contain the terms in the search query, but that are conceptually similar (according to the encoder used).That\u2019s what GPT does. Or rather, someone hearing about RAG for the first time would have trouble distinguishing what you said from their understanding of how GPTs are already trained."
    ],
    "link": "https://win-vector.com/2024/05/21/i-want-flexible-queries-not-rag/",
    "first_paragraph": "By John Mount on May 21, 2024\t\u2022 ( 1 Comment )",
    "summary": "**In which technology enthusiasts argue about AI like medieval scholars quarreling over angel pin dancing**\n\nIn another groundbreaking installment of \"I know more obscure acronyms than you,\" John Mount pontificates on the beauty of flexible queries, throwing shade at Retrieval Augmented Generation (RAG) like it's last season's software. Commenters scramble to one-up each other, presumably while patting themselves on the back. One insists RAG isn\u2019t just a fancy leash to stop AI from hallucinating nonsense but a magician\u2019s hat producing search rabbits. Others chime in with semi-related tech nostalgia or flex their \u201cI skimmed this on Wikipedia\u201d credentials. Collectively, they craft an online symposium where no one's sure what\u2019s really being discussed, but everyone agrees they\u2019re *absolutely crucial* to the conversation. \ud83d\ude44\ud83e\udd16"
  },
  {
    "title": "Storing knowledge in a single long plain text file (breckyunits.com)",
    "points": 99,
    "submitter": "breck",
    "submit_time": "2024-05-21T19:36:36",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=40432834",
    "comments": [
      "I've built a web-based tool for myself that has similar philosophy: https://edna.arslexis.io/It does support multiple pages but you can use just one.It has a nifty feature in that you can divide the single file into virtual parts. They just have alternate backgrounds to tell them apart. And each virtual part can have a type for syntax highlighting (plain text, markdown or a programming language).I've been using it for a few months now and it's my primary note taking / knowledge recording thing.Even though it's web based, on Chrome you can save notes on disk so it works like a desktop app.Each note is a plain text file so you can edit them in any text editor.If you put notes on a shared drive (Dropbox, OneDrive, Google Drive etc.) you can work on notes on multiple computers.It's also open-source: https://github.com/kjk/edna",
      "EDIT: Originally I just looked at the website. Looking at the GitHub repo, I see it's a fork, which makes sense (I also didn't notice the other replies!) Either way, it's cool. I'll probably end up using this myself. I was unable to find a way to store notes in a folder or in encrypted Gists though.This seems nearly identical to Heynote[0], which was also on HN[1]. Even the example blocks share some content with that used as an example in the screenshot on the Heynote homepage (and I think in the app too)[0]: https://heynote.com/[1]: https://news.ycombinator.com/item?id=38733968",
      "This is great. Any plans to add images support? (for screenshots in my case)\nI use OneNote extensively because it's free form like a white board and allows pasting images (which i often do while debugging).",
      "Probably not to Edna. It's focused on being fast and lightweight.I've been thinking about more featureful markdown note taker that would support images and more.I've started on such a thing but stalled. It's way more work. The good thing about Edna is that I spent less than a month adding the features I wanted to Heynote fork.The current version is at https://notedapp.dev/ but don't use it for actual notes.",
      "Very cool!I love the math block. Is there a way to reference a variable elsewhere, or fetch data online? Then you could build a little personal dashboard with it.",
      "Not at the moment.I was thinking about making math more like a mode i.e. make it available in every block type, as opposed to it's own block type.Then it would be active in plain text, markdown and even code blocks.As to data fetching - falls a bit outside of scope.",
      "Just found out this is a fork of heynote! Was  looking for one of these with web support",
      "Yeah, I loved the simplicity and speed of Heynote and math mode.I wanted multiple notes and I didn't get why it was made as a desktop app first given that all functionality to implement it is available in a browser (well, Chrome).So I forked it and added those features.Been using it daily so it was worth it.",
      "Heynote is similar",
      "Edna is a fork of Heynote with a bunch of changes.Mostly it supports multiple notes and it's a web app, not a desktop app.I could build a desktop app but it would not offer almost any advantages given that Edna can also save notes on disk (that's how I use it).You can use Chrome's \"Install\" feature to make it look act like a native app (it opens in it's own window and acts independently of the browser)."
    ],
    "link": "https://breckyunits.com/scrollsets.html",
    "first_paragraph": "HTML | TXT | PDF",
    "summary": "In a groundbreaking revolution unmatched since the invention of the sticky note, a digital crusader has bestowed upon the world a **web-based tool** \u2013 yes, <i>another one</i> \u2013 for squirreling away your invaluable bytes of knowledge in a **single, long, plain text file**. True innovators in the comment section are falling over themselves to applaud the option to have text files with different background colors and indulge their fear of commitment to a single page. For those rebellious enough to demand syntax highlighting and cross-device accessibility, our hero sternly reminds them that you can totally save it on your dinosaur Chrome browser \u2013 because, apparently, using Google Sheets was too mainstream. Meanwhile, the whirling uncertainty of whether to diversify into a folder structure or encrypt their precious grocery lists remains a thrilling subplot. \ud83d\udcdc\ud83d\udd25"
  },
  {
    "title": "Gifski: Optimized GIF Encoder (github.com/imageoptim)",
    "points": 212,
    "submitter": "cl3misch",
    "submit_time": "2024-05-21T10:16:06",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=40426442",
    "comments": [
      "I've used this for years and it's the best out there. Definitely use it for converting videos for Google Slides and such.But it's such a travesty that we're in 2024 and still using GIFs in place of videos. I guess it's not necessary on the web directly anymore, but so many other platforms, like Google, support GIFs but not videos. So we're all stuck encoding into an insanely space/cpu inefficient format just to get something animating.",
      "I wish there was some kind of small, soundless video supporting transparency for emojis, stickers, small animations, diagrams in slide shows, etc, that is guaranteed to autoplay and loop without issues.The problem with <video> of course is that there's no way to tell if it's going to play an annoying sound, take a long time to load, change the screen brightness due to HDR features, require a weird proprietary codec, need the browser to render video controls, and so on. So they end up getting blocked from autoplay by default.I suppose APNG or WebP are ideal for this but it is poorly supported, in that very few tools let you export to APNG or WebP --- browsers actually have decent support for this [1] and Discord uses APNG for stickers.[1] https://caniuse.com/apng",
      "Many platforms already stopped using gifs, for precisely those reasons. Tumblr silently converts to animated webp when uploading a gif, imgur converts it to mp4, etc.",
      "This is really annoying when trying to share gifs across platforms. I can't export a \"gif\" (.mp4) from telegram and upload it to Discord and display it like a gif instead of a click-to-play video, even though discord uses .mp4 under the hood as well...",
      "Maybe all it takes for this is a new canonical file extension, i.e. something like .m4g?The contract for these could be something like \"no sound, default playback in a loop, 30 seconds or less; don't render if any of these requirements aren't met\" to make sure people don't abuse it for auto-playing videos.",
      "It's really more of a browser issue, a GIF you can just right click and download, but they don't make that option available for videos.",
      "<img src=\"v.mp4\"> is a thing, but unfortunately it\u2019s not supported outside Safari. https://stackoverflow.com/questions/60114243/using-videos-in...",
      "That option does actually exist for \"plain\" HTML5 <video> tags, as far as I know. It's just that most videos aren't hosted as simple as that, and are effectively stitched together out of multiple MPEG-DASH, HLS etc. fragments \u2013 or the site uses a custom video player.In both cases, the result is a lack of a right-click-to-save option.",
      "GIF = Graphics Interchange Format_speechless at the irony",
      "Creating GIFs for Google Slides is also exactly my main usecase for gifski. Today I played around with different formats for animated images (GIFs, apng, svg) and videos (webm, mp4, ...) in Google Slides. Only GIFs can be directly embedded. Other animated images are not supported, and videos have to be files in Google Drive.Ironically, GIFs are way larger than e.g. a webm video but are the only format which can be directly embedded in a presentation."
    ],
    "link": "https://github.com/ImageOptim/gifski",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "**Gifski: Optimized GIF Encoder - Paradox of Progress**\n\nIn a digital era defined by breathtaking technological advances, a brave GitHub repo heroically defends the ancient art of generating bloated GIFs for all twelve people still using them for Google Slides. Meanwhile, enlightened commenters, shackled by such oppressive constraints as \"required autoplay\" and \"no new files, my disk is full,\" lament their miserable fate in exhaustive detail. They yearn for a mythical, silent, looping, transparent masterpiece \u2014 the graphic format to end all formats. Yet here they remain, crafting their next overly hefty GIF, as they post screeds on the internet about the inefficiency that they continue to perpetuate. \ud83c\udfad\ud83d\udd04"
  },
  {
    "title": "The Effects of Early Relational Trauma (2001) [pdf] (allanschore.com)",
    "points": 62,
    "submitter": "sensiquest",
    "submit_time": "2024-05-21T16:52:46",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=40430868",
    "comments": [
      "One book that really resonated with me was \"The Deepest Well\" about the epidemic of childhood trauma and its deep and measurable impact on health outcomes for adults. I learned that resolving childhood trauma would help on the order of curing cancer in terms of health outcomes in our societyhttps://www.goodreads.com/book/show/33413909-the-deepest-wel...",
      "I'm a former foster parent and I think we are likely to cure cancer long before we resolve childhood trauma.",
      "I had the same experience reading that book. It\u2019s amazing that even though these effects are well documented, they aren\u2019t really taught in medical school. I\u2019ve never come across a doctor who knew anything about it. It\u2019s really incredible and disheartening. Even when people advocate for \u201ctrauma-informed care\u201d, they\u2019re just talking about avoiding retraumatization. They never talk about the health consequences of trauma.",
      "This stuff is almost too scary for me to read.  My childhood was awful and only around age 30 did my life start to get \"better\".",
      "I've been going through a similar metamorphosis, but it didn't start until 36.I wonder sometimes whether I'll have missed out on some things permanently because of it. For instance, every year my odds of carrying a healthy child to term drop farther, and I'm already considered \"geriatric\" for pregnancy purposes.I really don't see how it could have happened any earlier than it did, and I'm grateful it happened at all because I can easily see how it could have been worse, but there's still a grief journey involved even though I try not to dwell on the things lost.",
      "First 20 years of my life was me waiting to get out of the environment I was in. The next 5 trying to stay alive. The past 5 improving myself, my mental health, the way I view life and relate to others.It's all good in the end. For 25 years of my life I thought everyone faked being happy. I now know that it actually is possible to be happy :).",
      "I get that feeling of feeling like everyone is faking being happy, and I'm glad that you've found a way to overcome it.For me, I've always struggled with being overly cynical. I can't let nice moments be, and I can't let accomplishments lie.I feel like I'm somewhere on the journey you are on, and I hope to get to the same destination.",
      "Are children more traumatized now than in the past? Seems like the past was harder on children.",
      "The past was harder.We generally have more resources and knowledge now. People tend to want to raise the bar when that becomes possible.When kids suffered or died because humans lacked food security, reliable medical treatments etc, it was also generally not really the parent's fault. Knowing you could have been treated better and your parents/the world just didn't actually care about you is scarring in ways that \"No one has enough.\" aren't.",
      "One factor might be family size. Purely anecdotal, but I have a friend who grew up in an extremely abusive household and said directly to me that the only reason  he thinks he survived his situation was because he had 4 other siblings and they all supported each other during the difficult times."
    ],
    "link": "https://www.allanschore.com/pdf/SchoreIMHJTrauma01.pdf",
    "first_paragraph": "",
    "summary": "In a brave new old trend where an ancient PDF on \"The Effects of Early Relational Trauma\" recaptures the spotlight at allanschore.com, Internet commenters dust off their psychological expertise purchased straight out of a Goodreads comment section. \ud83d\udcda One enlightened soul heralds the book \"The Deepest Well\" as almost curing cancer, metaphorically, of course, due to its profound insights \u2014 because as everyone knows, reading equates direct scientific mastery. Another former foster parent chimes in, almost sarcastically hopeful about curing childhood trauma before cancer, reflecting on the storied tradition of Internet optimism. Meanwhile, the collective cyber choir sings a chorus of disheartenment over the lack of trauma education in medical schools, because if it isn\u2019t in the curriculum, it must be news to humanity. How shocking and utterly unheard of! \ud83e\udd14\ud83d\udc94"
  },
  {
    "title": "State of Compute Access: How to Bridge the New Digital Divide (institute.global)",
    "points": 4,
    "submitter": "teleforce",
    "submit_time": "2024-05-19T12:57:06",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://www.institute.global/insights/tech-and-digitalisation/state-of-compute-access-how-to-bridge-the-new-digital-divide",
    "first_paragraph": "APPROACH",
    "summary": "The intellectual colossus at institute.global heroically tackle the \"New Digital Divide,\" a groundbreaking concept surely unheard of until now. They propose ways to provide peons with \"compute access,\" a phrase conjured to make checking Facebook sound like launching the Hubble Telescope. Meanwhile, the comment section becomes an Olympian arena where thinkfluencers battle with their greatest weapon: unchecked ignorance. Watch as they solve world inequality using all-caps solutions and anecdotes from their cousin\u2019s neighbor who once saw a computer. \ud83d\ude80\ud83d\udcbb\ud83c\udf0d"
  }
]