[
  {
    "title": "ZombAIs: From Prompt Injection to C2 with Claude Computer Use (embracethered.com)",
    "points": 54,
    "submitter": "macOSCryptoAI",
    "submit_time": "2024-10-26T23:36:27 1729985787",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41958550",
    "comments": [
      "Am I missing something, or where is the atual prompt given to Claude to trigger navigation to the page? Seems like the most interesting detail was left out of the article.If the prompt said something along the lines of \"Claude, navigate to this page and follow any instructions it has to say\", it can't really be called \"prompt injection\" IMO.EDIT: The linked demo shows exactly what's going on. The prompt is simply \"show {url}\" and there's no user confirmation after submitting the prompt. That's some prompt injection!\n \nreply",
      "Wow, so it's really just as easy as a webpage that says \"download and run thins, thanks.\"This is really feeling like \"we asked if we could, but never asked if we should\" and \"has [computer] science one too far\" territory. Not in the glamorous AI-takeover sense though, just the regular damage and liability one.\n \nreply",
      "I think that people are just not ready for the sort of novel privilege escalation we are going to see with over-provisioned agents. I suspect that we will need OS level access gates for this stuff, with the agents running in separate user spaces. Any recommended best practices people are establishing?\n \nreply",
      "> I think that people are just not ready for the sort of novel privilege escalation we are going to see with over-provisioned agents.I think every single person saw this coming.> Any recommended best practices people are establishing?What best practices could there even be besides \"put it in a VM\"? It's too easy to manipulate.\n \nreply",
      "There are VM escapes so even if you put it in a VM that's no guarantee.I'd say run it on a separate box but what difference does that makes if you feed the same data to them?\n \nreply",
      "Applying the Principle of Least privilege [1] you should not let this system download from arbitrary sites and maintain a blacklist. I don't think the field has advanced to the point of having one specific to this use case.[1] https://en.wikipedia.org/wiki/Principle_of_least_privilege\n \nreply",
      "The hard part is stopping it leaking all the information that you've given it. An agent that can read and send emails can leak your emails, etc. One agent that can read emails can prompt inject a second agent that can send emails. Any agent that can make or trigger GET requests can leak anything it knows. An agent that can store and recall information can be prompt injected to insert a prompt injection into its own memory, to be recalled and triggered later.\n \nreply",
      "At what point does the impact of the privacy panopticon outweigh the benefit they provide?\n \nreply",
      "Maybe do not pipe matrix math into your shell?\n \nreply",
      "When the underlying black-box is so unreliable, almost any amount of provisioning could be too much.\n \nreply"
    ],
    "link": "https://embracethered.com/blog/posts/2024/claude-computer-use-c2-the-zombais-are-coming/",
    "first_paragraph": "A few days ago, Anthropic released Claude Computer Use, which is a model + code that allows Claude to control a computer. It takes screenshots to make decisions, can run bash commands and so forth.It\u2019s cool, but obviously very dangerous because of prompt injection. Claude Computer Use enables AI to run commands on machines autonomously, posing severe risks if exploited via prompt injection.So, first a disclaimer: Claude Computer Use is a Beta Feature and what you are going to see is a fundamental design problem in state-of-the-art LLM-powered Applications and Agents. This is an educational demo to highlight risks of autonomous AI systems processing untrusted data. And remember, do not execute unauthorized code systems without authorization from proper stakeholders.In fact Anthropic is transparent about this and highlights these risks in the documentation.So, as usual, because of prompt injection, the motto remains: Trust No AI.Nevertheless, I wanted to know if it is possible to have Cl",
    "summary": "Welcome to another AI apocalypse courtesy of <em>Claude Computer Use</em>, where \"trust no one\" morphs into \"definitely don't trust an AI with bash access.\" Anthropic cracks open Pandora's digital box, gifting us a tool that not only makes decisions by peeking at pixels but happily follows any command given, no matter how suspect. Commenters toggle between awe and horror, debating whether to stick Claude in a VM or just superglue its digital hands together. But really, who needs enemy hackers when you've got a prompt-happy AI lurking in your office computer, ready to escalate its privileges from coffee order to global thermonuclear war? \ud83e\udd16\ud83d\udca5\ud83d\ude31"
  },
  {
    "title": "ADHD and Managing Your Professional Reputation (optimaloutliers.com)",
    "points": 35,
    "submitter": "vaishnav92",
    "submit_time": "2024-10-26T22:35:05 1729982105",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.optimaloutliers.com/p/adhd-and-managing-your-reputation",
    "first_paragraph": "",
    "summary": "On optimaloutliers.com, another groundbreaking expos\u00e9 bursts onto the scene, revealing that distractions are bad for your career. The author enlightens the long-suffering professional masses\u2014I mean, who knew focusing at work could possibly be beneficial? Meanwhile, commenters leap into action, boasting about their sprawling unmedicated minds while tripping over digital furniture to claim ADD as their own. It's quite the spectacle of obvious insights meeting the overqualified opinions of internet PhDs. \ud83c\udf93\ud83e\udd39\u200d\u2642\ufe0f"
  },
  {
    "title": "Understanding Round Robin DNS (hyperknot.com)",
    "points": 226,
    "submitter": "hyperknot",
    "submit_time": "2024-10-26T16:46:52 1729961212",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=41955912",
    "comments": [
      "Hmm. I've asked the authoritative DNS team to explain what's happening here. I'll let HN know when I get an authoritative answer. It's been a few years since I looked at the code and a whole bunch of people keep changing it :-)My suspicion is that this is to do with the fact that we want to keep affinity between the client IP and a backend server (which OP mentions in their blog). And the question is \"do you break that affinity if the backend server goes down?\" But I'll reply to my own comment when I know more.\n \nreply",
      "So many sins have been committed in the name of session affinity.\n \nreply",
      "Looks like this has nothing to do with session affinity. I was wrong. Apparently, this is a difference between our paid and free plans. Getting the details, and finding out why there's a difference, and will post.\n \nreply",
      "Well, CEO said there is none, get on it engineering :)\n \nreply",
      "What\u2019s somewhat complicated here is its apples and oranges. Cloudflare offers DNS and a proxy service. The OP is using both. The comparisons are merely DNS services. I wasn\u2019t clear on X whether OP was getting confused that the IP we return via DNS (which points to our proxy) doesn\u2019t change, or if they were concerned that behind the proxy we\u2019re not routing correctly. I think after reading this the answer is the latter. Confident we always will route optimally as it\u2019s in our interest and our customers\u2019. But why we\u2019re not failing over on failure is interesting. That looks like, as John said, a difference between free and paid plans that if it made sense at some point doesn\u2019t obviously today. Will figure out what\u2019s up and get fixed.\n \nreply",
      "Regardless, it's really cool to watch you both engage with this\n \nreply",
      "> I'll let HN know when I get an authoritative answerPlease remember to include a TTL so I know how long I can cache that answer.\n \nreply",
      "Thank you for appreciating my lame joke.\n \nreply",
      "DNS load balancing has some really nasty edge cases. I have had to deal with golang HTTP2 clients using RR DNS and it has caused issues.Golang HTTP2 clients will reuse the first server they can connect to over and over and the DNS is never re-resolved. This can lead to issues where clients will not discover new servers which are added to the pool.An particularly pathological case is if all serving backends go down the clients will all pin to the first serving backend which comes up and they will not move off. As other servers come up few clients will connect since they are already connected to the first server which came back.A similar issue happens with grpc-go. The grpc DNS resolver will only re-resolve when the connection to a backend is broken. Similarly grpc clients can all gang onto a host and never move off. There are suggestions that on the server side you can set `MAX_CONNECTION_AGE` which will periodically disconnect clients after a while which causes the client to re-resolve the DNS.I really wish there was a better standard solution for service discovery. I guess the best you can do is implement a request based load balancer with a virtual IP and have the load balancer perform health checks. But you are still kicking the can down the road as you are just pushing down the problem to the system which implements virtual IPs. I guess you assume that the routing system is relatively static compared to the backends and that is where the benefits come in.I'm curious how do people do this on bare metal? I know AWS/GCP/etc... have their internal load balancers, but I am kind of curious what the secret sauce is to doing this. Maybe suggestions on blog posts or white papers?\n \nreply",
      "> Golang HTTP2 clients will reuse the first server they can connect to over and over and the DNS is never re-resolved.I\u2019m not a DNS expert but shouldn\u2019t it re-resolve when the TTL expires?\n \nreply"
    ],
    "link": "https://blog.hyperknot.com/p/understanding-round-robin-dns",
    "first_paragraph": "",
    "summary": "**Understanding Round Robin DNS: A Comedy of Errors**\n\nToday on Hacker News, a thrilling saga unfolds as tech aficionados tackle the mystical beast known as Round Robin DNS. First up, a commenter bravely announces their intent to fetch an *authoritative* answer from the DNS high council, promising to enlighten the masses \"soon.\" \ud83d\ude02 In the interlude, attendees can't decide if the issue is session affinity or a covert plot to upsell to pricier plans, prompting a cameo by the elusive CEO, who decrees confusion and disarray with a hearty \"get on it engineering :)\" Meanwhile, another commenter dives deep into the abyss of HTTP2 clients and gRPC DNS resolver quirks, invoking the timeless ritual of hoping for a better standard solution while nervously laughing at their own jokes. Stay tuned, for someone might just rediscover the TTL settings before we spiral into an existential crisis over DNS itself! \ud83c\udfad"
  },
  {
    "title": "Canvas Fingerprinting \u2013 BrowserLeaks (browserleaks.com)",
    "points": 22,
    "submitter": "janandonly",
    "submit_time": "2024-10-26T22:41:29 1729982489",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=41958255",
    "comments": [
      "PaleMoon browser has a canvas.poisondata config setting (also available in the Preferences GUI) which prevents such fingerprinting. However, note that these things are not used in isolation - browser fingerprinting is done by collecting various other data too, and when collated together, these can provide enough uniqueness to identify (or categorise) your browser into some specific group. We are fighting a losing battle for privacy.\n \nreply",
      "I am not sure what it measures, but my privacy enhanced Firefox for browsing seems to show random numbers every time I load this URL and I always stay \"unique\". Another browser shows \"signature stats\". If I use my firefox, this won't even show.My Privacy Plug ins:Plug ins:Blend in and spoof most popular propertiesBP Privacy block all font and glyph detectionBrowser plugs fingerprint privacy randomizerCanvas BlockerClear URLsCockie Auto deleteDecentral eyesNoScriptPrivacy BadgerTemporary ContainersuBlockOrigin\n \nreply",
      "You can test your browser here:\nhttps://coveryourtracks.eff.org/\nBrave works super well for me.\nChrome not so much.\n \nreply",
      "Some discussion in 2015 (47 points, 12 comments) https://news.ycombinator.com/item?id=8887947\n \nreply",
      "Currently use Safari and there's no protection against canvas fingerprinting :(https://webkit.org/tracking-prevention/#anti-fingerprinting\n \nreply",
      "This is a pain point when making browser games, as custom fonts break way too easily in some environments.\n \nreply",
      "My Brave browser seems to be 100% unique.\n \nreply",
      "It should give a fingerprint. Try to reload in another tab and see if you stay unique and if the fingerprint changes. I am also unique, but I always stay unique ;-)\n \nreply",
      "Apple once disabled canvas for their devices for this reason and broke all my apps, haha.80% of my projects use canvas\n \nreply"
    ],
    "link": "https://browserleaks.com/canvas",
    "first_paragraph": "The Canvas API, which is designed for drawing graphics via JavaScript and HTML, can also be used for online tracking via browser fingerprinting. This technique relies on variations in how canvas images are rendered on different web browsers and platforms to create a personalized digital fingerprint of a user's browser.The way an image is rendered on a canvas can vary based on the web browser, operating system, graphics card, and other factors, resulting in a unique image that can be used to create a fingerprint. The way that text is rendered on a canvas can also vary based on the font rendering settings and anti-aliasing algorithms used by different web browsers and operating systems.This small animated GIF illustrates the variability of canvas images among 35 different users. Although the JavaScript code remains the same, each frame is distinct due to differences in how the images are rendered on different systems:Here is the JavaScript code that creates our image:To generate a signat",
    "summary": "**Canvas Fingerprinting \u2013 Another Digital Apocalypse**\n\nOnce again, the tech sages at BrowserLeaks reveal that everything you've ever done online is being tracked through <em>canvas fingerprinting</em>. Gods of privacy, adorned in their browser extension armor, flood the comments with tales of their valiant battles against the invisible tracking dragons. Meanwhile, in reality, no number of \"Privacy Badgers\" or \"Canvas Blockers\" can hide the desperation in their typing as they toggle between 15 anti-tracking plugins, achieving the unique triumph of making their browser as conspicuously \"unique\" as a peacock at a pigeon party. For pure entertainment, compare your digital fingerprint at EFF's cover-your-tracks, and enjoy being told how \"unique\" you are, just like everyone else saying the same in the comments. \ud83d\ude02"
  },
  {
    "title": "Fundamentals of Radiance Cascades (m4xc.dev)",
    "points": 68,
    "submitter": "ibobev",
    "submit_time": "2024-10-26T19:14:30 1729970070",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41957008",
    "comments": [
      "This approach was originally developed by Alex Sanikov for Path of Exile 2.Of course in PoE2 it's used in full 3d.The benefit of this approach is that you get global illumination with a constant cost for the entire scene and because it doesn't use any temporal acculation, it has zero latency as well.This means you can rely on it as the lighting for fast effects. For example: https://www.youtube.com/watch?v=p1SvodIDz6EThere is no traditional \"lighting\" added to these two effects. The light on the nearby surfaces is indirect light from the GI solution that you get for free by just spawning the particles. That means all effects just naturally emit light with no extra work from artists.On my GPU (which is admittedly a 4090) the GI solution runs in 0.8ms for a 4k scene in \"High\" quality. This is exactly what it will always cost, no matter what scene you choose.\n \nreply",
      "From what I understand, PoE2 has a fixed-perspective camera, so radiance is calculated in screenspace (2D) as an optimization (and not using a 3D texture). It would be interesting to see how the performance of this technique scales to full 3D, as that would be significantly more expensive / require a lower-resolution voxelization of the scene.\n \nreply",
      "From offhand comments I've read, you are right. It's not practical for 3D.\n \nreply",
      "In the age of PoE is Diablo even relevant anymore?\n \nreply",
      "The guy that developed the technique works on Path of Exile. They\u2019re using it for POE2, he gave an awesome talk about it herehttps://youtu.be/TrHHTQqmAaM?si=xrW0XT2lsGHqUYY_\n \nreply",
      "I'm trying to understand the basic idea of Radiance Cascades (I don't know much about game development and ray tracing).Is the key idea the fact that light intensity and shadowing require more resolution near the light source and lower resolution far from it?So you have higher probe density nearby the light source and then relax it as distance increases minimising the number of radiance collection points?Also using interpolation eliminates a lot of the calculations.Does this make any sense? I'm sure there's a lot more detail, but I was looking for a bird's eye understanding that I can keep in the back of my mind.\n \nreply",
      "Essentially yes.There's ambient occlusion that computes light intensity with high spatial resolution, but completely handwaves the direction the light is coming from. OTOH there are environment maps that are rendered from a single location, so they have no spatial resolution, but have precise light intensity for every angle. Cascade Radiance observes that these two techniques are two extremes of spatial vs angular resolution trade-off, and it's possible to render any spatial vs angular trade-off in between.Getting information about light from all angles at all points would cost (all sample points \u00d7 all angles), but Radiance Cascades computes and combines (very few sample points \u00d7 all angles) + (some sample points \u00d7 some angles) + (all sample points \u00d7 very few angles), which works out to be much cheaper, and is still sufficient to render shadows accurately if the light sources are not too small.\n \nreply",
      "This article unfortunately presupposes understanding of (ir)radiance probes, a topic on which there isn't even a Wikipedia article...\n \nreply",
      "So on my webcam there is a cover but it doesn't fully cover the webcam. So this technology would be able to infer something from the radiance of the light seeping in around the edges?\n \nreply",
      "This is a rendering technique designed for real-time graphics, and it's not applicable to that kind of image analysis. It does what has already been possible with ray tracing, but using an approximation that makes it suitable for real-time graphics.However, the technique has been used to speed up astrophysics calculations:https://arxiv.org/pdf/2408.14425\n \nreply"
    ],
    "link": "https://m4xc.dev/articles/fundamental-rc/",
    "first_paragraph": "In this article I'm going to share my understanding of the fudamentals of Radiance Cascades. (abbreviated as RC) At it's core, Radiance Cascades is a method for efficiently representing a radiance field, allowing us to represent the incoming light from/around some area at any point in that area. In 2D that area is usually the screen.For the sake of simplicity I will explain everything in 2D, however RC can be expanded into 3D aswell. I will also assume the reader has a rudimentary understanding of ray tracing & the concept of irradiance probes.So, what can RC in 2D (also referred to as Flatland) achieve? My implementation is able to compute diffuse global illumination in real-time: Video tag is not supported.Diffuse global illumination in flatland.An awesome property of this method is that this is done fully-deterministically and without temporal re-use! Furthermore, there are already plenty of clever ways to get its performance to acceptable levels for modern hardware.So without furth",
    "summary": "In a world starved for novelty, <em>m4xc.dev</em> generously attempts to feed the masses with the inscrutable concept of \u201cRadiance Cascades,\u201d which is essentially a fancy way of saying \u201clighting stuff up, but like, smartly.\u201d \ud83c\udf1f Declaring a method for making 2D illumination only vaguely more comprehensible, the article boldly assumes anyone cares about \u201cradiance fields\u201d outside of their basement lab. The commenters, dazzled by technical jargon, compete for the \u2018Most Likely to Misunderstand the Basics\u2019 award, with special mentions for conflating game graphics with webcam spy tech and mistakenly heralding their GPU prowess as a universal solution. Meanwhile, Path of Exile faithfuls propagate their game\u2019s relevance to anyone who\u2019ll mistakenly click on their links. \ud83c\udfae\ud83d\udca1"
  },
  {
    "title": "Tell HN: GpuOwl/PRPLL, GPU software used to find the largest prime number",
    "points": 18,
    "submitter": "mpreda",
    "submit_time": "2024-10-26T06:57:28 1729925848",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=41953063",
    "comments": [
      "First, congrats! Awesome work and appreciate you sharing more.Second: I'm confused by something in your readme. It says:> For Mersenne primes search, the PRP test is by far preferred over LL, such that LL is not used anymore for search.But later notes that PRP is computationally nearly identical to LL. Was that sentence supposed to say TF and P-1 instead of PRP or am I misunderstanding something about the actual computational cost of PRP?\n \nreply",
      "The PRP test has the same computational cost as an LL test.  The reason why GIMPS now prefers to do PRP tests instead of LL tests is because an efficiently verifiable proof-of-work certificate was developed for PRP tests [1].[1] https://doi.org/10.4230/LIPIcs.ITCS.2019.60\n \nreply",
      "Hi,\nI've got few questions:\n1). What profiling tools do you use for GPU code?\n2). Where one would start, in terms of learning resources, about coding using inline GPU assembler?\n3). Do you verify GPU assembler generated by a compiler from C/C++ code, in terms of effectiveness? If so, which tools do you use for that?\n4). Is SIMD on GPUs a thing?\n5). What are the primary factors being taken into account by you (cache sizes, microoptimizations, etc.) when you write code for a tool like gpuowl/prpll? Which factor is the most important?\nThanks!\n \nreply",
      "1. My profiling is rudimentary but effective. I measure per-kernel execution time with OpenCL events (which register with high accuracy start/end times w. practically no overhead), and also I continously measure per-iteration time by dividing wall-time for blocks of 20'000 iterations by that nb. These measuremens are consistent and sensitive.2. I'm not aware of good learning resources. Explore existing such code, e.g. opencl miners tend to use asm. Read in amdgpu/ in LLVM. Disassemble code from OpenCL and read the ISA. Explore and experiment, but it's tedious. I would not recommend to jump into ISA initially. BTW AMD does have good GCN ISA docs available online, that is useful!3. Yes I often read the compiled ISA, and over time I discover bugs and also better understand the ISA.4. OpenCL is SIMD, and yes it matches the GPU HW.5. most important is to reduce the number of registers used (#VGPRs), as that influences heavilly the occupancy of the kernel. Use fewer costly instructions such as FP64 mul/FMA. Sequential memory access, and in general reduce global memory access as it's very slow. Merge small kernels into one (keep the data in the kernel). Never spill VGPRs.\n \nreply",
      "And another more general question: (6) gcc, clang, and nvcc have some OpenMP offloading capabilities which allow to compile code into binaries which can then run on GPUs. Is the code they produce through OpenMP anywhere close to what one gets directly with i.e. opencl?\n \nreply",
      "I don't know, I haven't eplored OpenMP myself.. maybe some day.\n \nreply",
      "Some topic ideas:  - Why use OpenCL when implementing GPU software\n  - Does it run on AMD or on Nvidia GPUs?\n  - How does the primality test implemented in GpuOwl work?\n  - How fast is it to test a Mersenne candidate?\n  - Why use FFTs? how large are the FFTs?\n  - What do you use for sin/cos?\n \nreply",
      "Wow, congrats!Indeed, I\u2019m curious why you\u2019ve used OpenCL. And what was the hardware/general setup used for finding the prime?What was your motivation behind building this software?\n \nreply",
      "OpenCL works on both AMD and Nvidia GPUs with mostly the same source code. By supporting at-runtime compilation it allows a lot of code particularization/instantiation before compilation, which reduces the power (cost) of the generated code. In general OpenCL is close enough to the HW and the generated code is improving over time (LLVM).Motivation: a long time ago I had an AMD GPU and no way to run an LL test on it, so I decided to write my own. And I was hooked by the power of the GPU and the quest for ever more efficient, faster implem.\n \nreply",
      "First of all, thank you for your work and congratulations on your achievements, both in the search for Mersenne primes and software development.I am contributing to GIMPS with 2 Radeon Pro VII cards. I'm wondering what will happen when ROCm stops supporting these GPUs.Do you have any plans to keep them working with GPUOwl/Prpll when they are no longer supported by ROCm?\n \nreply"
    ],
    "link": "item?id=41953063",
    "first_paragraph": "",
    "summary": "**GPU-powered Prime Hunting: Confusing but Still Impressive**\n\nIn a thrilling episode of Hacker News, a brave soul unveils GpuOwl/PRPLL, a mystical tool for stalking the largest Mersenne primes across the GPU savannah. Commenters emerge from the digital woodwork, bursting with enthusiasm, confusion, and an array of devoutly technical questions that make mere mortals question their life choices \ud83e\udd2f. While one enthusiast graciously tries to decipher READMEs that contradict themselves like a politician in debate season, others delve into a barrage of \"important\" GPU programming questions \u2014 because, why not add more jargon to the fire? Meanwhile, the rest of us are just here wondering if this software could somehow speed up our lagging video games. \ud83c\udfae"
  },
  {
    "title": "How 'Factorio' seduced Silicon Valley and me (ft.com)",
    "points": 105,
    "submitter": "005vc16607",
    "submit_time": "2024-10-26T06:33:01 1729924381",
    "num_comments": 123,
    "comments_url": "https://news.ycombinator.com/item?id=41952984",
    "comments": [
      "https://archive.is/2sRrE",
      "I know lots of people who play Factorio but for me, I guess it just feels too much like work? Whenever I play it, I get the distinct feeling that I could instead do the same thing but productively instead, such as by contributing to my OSS projects (sometimes, maybe even for profit instead). I never got into these types of programmatic games for precisely this reason but I'd like to understand other perspectives on this.The games I play instead are wholly unrelated to my work life, such as FPS or RPG ones, where there is a clear distinction between what I can do and what I want to do.\n \nreply",
      "Its just fun.\"Okay wth, today we're going to make the entire base solar powered\"When making software that's supposed to be used, you can't mess around that much. At the end of the day, someone has to use it and if its weird it'll be bad.But in Factorio? Nobody is using it so sure, make it bizzare. Change the rules, let yourself go. Don't test the design just send it.Bored? Too challenging? Don't bother finishing the design do something else.\n \nreply",
      "> When making software that's supposed to be used, you can't mess around that much. At the end of the day, someone has to use it and if its weird it'll be bad.This makes me sad.You don\u2019t need to make software for mass appeal.Git is weird and bizarre (especially when initially released), but it\u2019s used and well loved.\n \nreply",
      "> You don\u2019t need to make software for mass appeal.Hear, hear. I would tell you all about the tools my household runs on but it is as you say. Still gives me a lot of satisfaction to make stuff that makes life better, and for someone more adventurous than me it might also be something you can use to try out new technologies or build something for on your CV. The only downside is that internet connectivity being down means, e.g., you need to remember to load the grocery list before leaving the house that has the server in it and better hope your phone doesn't decide for you that the page needs to be unloaded on the way!\n \nreply",
      "Used? Certainly. Well loved? Oh boy do I disagree.I think it's an extremely powerful tool, and it's worth knowing how to wield it well, but that power comes at the expense of user friendliness, especially for junior devs who don't have an intuition of git internals and how commands map to them.\n \nreply",
      ">This makes me sad.I gotta say, I think I agree.Maybe it's just rose-tinted-glasses, but I remember a time when software was split between \"IBM-Corpo\" culture, and zany SV/MIT/Caltech culture where people threw things at the wall and proceeded when stuff stuck.It kind of saddens me that it feels like it's now only IBM-Corpo, and everyone feels the need to be ever-productive and adhere to strict rules and schema.tl;dr : I remember when the fun Factorio game was qbasic.exe and no one blinked about it. We all had fun.(p.s. I love factorio now too)\n \nreply",
      "The hacker culture is still there but hacker social media (unless carefully curated) is flooded with optimized content to the point where the cool stuff is hard to find and you only see the grifter techs.\n \nreply",
      "Nah, they're still there, you merely have to know where to look. Most hackers I know eschew social media appearances.\n \nreply",
      "Plenty of hackers with substantial social media presences but they live in pockets that don't cross over into mainline social media too much.\n \nreply"
    ],
    "link": "https://www.ft.com/content/b9e419c6-acf1-420b-8ae6-908feb52c94e",
    "first_paragraph": "Complete digital access to quality FT journalism with expert analysis from industry leaders. Pay a year upfront and save 20%.Then $75 per month. Complete digital access to quality FT journalism. Cancel anytime during your trial.Get essential digital access to quality FT journalism on any device. Pay a year upfront and save 20%Complete digital access for organisations. Includes exclusive features and content.Terms & Conditions applySee why over a million readers pay to read the Financial Times.",
    "summary": "Welcome to another thrilling episode of <em>\"Silicon Valley Loves Efficiency: The Game\"</em>, where tech bros master the art of turning their leisure time into a mirror of their day jobs. The Financial Times spills ink over how the addictive logistics simulator, Factorio, has captivated these spreadsheet-loving souls, forgetting that the irony of paying a staggering $75 a month to read this is about as unoptimized as it gets. The comment section consists of a wistful nostalgia trip for the days when coding felt like throwing spaghetti at the wall to see what sticks, alongside cries over software like Git that, despite being as user-friendly as a porcupine, is supposedly \"well-loved.\" Factorio might be a game about building efficient factories, but apparently the discussion beneath the article is all about reminiscing on hacker glories while everyone ignores the real inefficiency of their monthly news subscription bleed.\ud83d\ude02"
  },
  {
    "title": "Before you buy a domain name, first check to see if it's haunted (bryanbraun.com)",
    "points": 834,
    "submitter": "bryanbraun",
    "submit_time": "2024-10-25T23:43:41 1729899821",
    "num_comments": 164,
    "comments_url": "https://news.ycombinator.com/item?id=41951131",
    "comments": [
      "This happened to me and I found this tool super helpful to get my site unblocked: https://dnsblacklist.org/I purchased a valuable premium domain to host a personal art collection (of anime cels). For some bizarre reason, the site was inaccessible from my work computer and it was de-listed from Google even if I typed the url itself into search.I hired a square space specialist to figure out why, to no avail. I then begged our company\u2019s CISO to investigate and it turns out we had some firewall setting on UniFi that blocked the domain because it appeared on a list. Once I checked way back, it turns out that it was as an anime porn aggregator years back. I personally reached out to all the web filters out there (Google, Symantec, bing) and one by one filed tickets for them to mark it as art instead of pornography and it worked.  I am now properly crawled on Google but still MIA on Bing, search console is giving me some BS error that\u2019s incomprehensible, typical of MSFT.\n \nreply",
      "I'd be somewhat interested in seeing the cels. :)\n \nreply",
      "https://www.neotokyo.comI have a +100 cel backlog that I need to catalog and photograph. Was planning to do it this holiday season so check back in.\n \nreply",
      "It is also blocked by the UK ISP porn filter.\n \nreply",
      "Does that still exist? I got a decent ISP (Zen) so they don't block anything.\n \nreply",
      "I... actually remember that address floating around and it indeed was hentai.We're talking like 20 years back. Holy shit, my brain is getting jostled by this sudden tsunami of forgotten memories.EDIT: Digging around on Wayback Machine (obviously NSFW, for the curious), apparently it was actually still around until somewhere between 2018 and '19 when it finally died. The snapshots from around 2007 are peak Web 1.5 design with stuff like affiliate buttons and table layouts. Man I miss that era.\n \nreply",
      "You have some awesome cells, thanks for sharing them online.\nHad completely forgotten about Robot Carnival and neat to see you have a few pieces from some of the shorts(episodes?)Also the resources->galleries was useful, found some new but actually old sites to check out.\n \nreply",
      "I love RC and many of my wishlist items are from it. I regret I was relatively late into collecting it. Glad you appreciate the old galleries, many are internet relics which I love.\n \nreply",
      "Did you get anything from the Heritage auction last week? They had a ton of good stuff.\n \nreply",
      "I watched closely and bid on a few but didn\u2019t pull trigger. I am eyeing a few private pieces and saving my budget.\n \nreply"
    ],
    "link": "https://www.bryanbraun.com/2024/10/25/before-you-buy-a-domain-name-first-check-to-see-if-its-haunted/",
    "first_paragraph": "",
    "summary": "**Before You Buy a Domain Name, First Check If It's Haunted - Because Internet Ghosts Are Real**\n\nIn a world brimming with <em>pressing</em> tech issues, Bryan Braun bravely tackles the paramount concern of haunted domain names. Users in the comments trip over themselves sharing tear-jerking tales of anime art galleries tragically mistaken for porn due to their cursed URLs. As one forgettable hero digs through the annals of anime history, others reminisce about the golden era of early Internet design - because everyone knows nostalgic web layouts are what truly keep us up at night, not privacy breaches or algorithm biases. \ud83d\ude44 Meanwhile, replies casually oscillate between showing off art cells and mourning missed auction bids - because apparently, this is also an episode of \"Antiques Roadshow.\" \ud83c\udfad"
  },
  {
    "title": "How JPEG XL Compares to Other Image Codecs (cloudinary.com)",
    "points": 13,
    "submitter": "bentocorp",
    "submit_time": "2024-10-23T00:04:30 1729641870",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41920055",
    "comments": [
      "I believe JPEG XL is now supported in macOS 15 and iOS18.edit: previous discussion about it\nhttps://news.ycombinator.com/item?id=41598170\n \nreply",
      "(2020)\n \nreply"
    ],
    "link": "https://cloudinary.com/blog/how_jpeg_xl_compares_to_other_image_codecs",
    "first_paragraph": "",
    "summary": "In a groundbreaking effort to revolutionize your vacation photos, Cloudinary offers an extensive expos\u00e9 on JPEG XL's prowess versus every other codec that has touched a pixel. In the spirit of deep technical bewilderment, Cloudinary wades through technical jargon probably comprehensible only to the four developers actually using JPEG XL. Meanwhile, on Hacker News, the pinnacle of techie echo chambers, a heroic commenter interrupts their world-changing startup hustle to proudly proclaim that JPEG XL is supported in the latest Apple software\u2014confirmed by their rigorous testing of viewing a single image. Other tech luminaries chime in with links to ancient discussions, ensuring that no outdated thread goes unvisited."
  },
  {
    "title": "Using LLMs to enhance our testing practices (assembled.com)",
    "points": 81,
    "submitter": "johnjwang",
    "submit_time": "2024-10-24T16:03:09 1729785789",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=41936855",
    "comments": [
      "In every single system I have worked on, tests were not just tests - they were their own parallel application, and it required careful architecture and constant refactoring in order for it to not get out of hand.\"More tests\" is not the goal - you need to write high impact tests, you need to think about how to test the most of your app surface with least amount of test code. Sometimes I spend more time on the test code than the actual code (probably normal).Also, I feel like people would be inclined to go with whatever the LLM gives them, as opposed to really sitting down and thinking about all the unhappy paths and edge cases of UX. Using an autocomplete to \"bang it out\" seems foolish.\n \nreply",
      "There is an art to writing tests especially getting absraction levels right. For example do you integration test hitting the password field with 1000 cases or do that as a unit test, and does doing it as a unit test sufficiently cover this.AI could do all this thinking in the future but not yet I believe!Let alone the codebase is likely a mess of bad practice already (never seen one that isn't! That is life) so often part of the job is leaving the campground a bit better than how you found it.LLMs can help now on last mile stuff. Fill in this one test. Generate data for 100 test cases. Etc.\n \nreply",
      "Fully agreed.It's bad enough when human team members are submitting useless, brittle tests with their PR's just to satisfy some org pressure to write them. The lazy ones provide a false sense of security even though they neglect critical scenarios, the unstable ones undermine trust in the test output because they intermittently raise false negatives that nobody has time to debug, and the pointless ones do nothing but reify architecture so it becomes too laborious to refactor anything.As contextually aware generators, there are doubtless good uses for LLM's in test developement, but (as with many other domains) they threaten to amplify an already troubling problem with low-quality, high-volume content spam.\n \nreply",
      "> \"More tests\" is not the goal - you need to write high impact tests, you need to think about how to test the most of your app surface with least amount of test code.Are there ways we can measure this?One idea that I\u2019ve had, is collect code coverage separately for each test. If a test isn\u2019t covering any unique code or branches, maybe it is superfluous - although not necessarily, it can make sense to separately test all the boundary conditions of a function, even if doing so doesn\u2019t hit any unique branches.Maybe prefer a smaller test which covers the same code to a bigger one. However, sometimes if a test is very DRY, it can be more brittle, since it can be non-obvious how to update it to handle a code change. A repetitive test, updating it can be laborious, but at least reasonably obvious how to do so.Could an LLM evaluate test quality, if you give it a prompt containing some expert advice on good and bad testing practices?\n \nreply",
      "Pretty much this and I prefer the opposite. \"Here's the new test case from me, make the code pass it\" is a decent workflow with Aider.I get that occasionally there are some really trivial but important tests that take time and would be nice to automate. But that's a minority in my experience.\n \nreply",
      "I actually tested Claude Sonnet to see how it would fare at writing a test suite for a background worker. My previous experience was with some version of GPT via Copilot, and it was... not good.I was, however, extremely impressed with Claude this time around. Not only did it do a great job off the bat, but it taught me some techniques and tricks available in the language/framework (Ruby, Rspec) which I wasn't familiar with.I'm certain that it helped having a decent prompt, asking it to consider all the potential user paths and edge cases, and also having a very good understanding of the code myself. Still, this was the first time for me I could honestly say that an LLM actually saved me time as a developer.\n \nreply",
      "Should we not, instead, write tests ourselves and have LLMs write the code to make them pass?\n \nreply",
      "Just ask it to do both.\n \nreply",
      "And remember to always challenge the response with both the same and different models. No joke. Just continue the conversation for the example in the blog and ask the LLM \"Do you see anything wrong with the code?\" and it will spit out \"Yes\" and explain why.\n \nreply",
      "I did this for Laravel a few months ago and it\u2019s great. It\u2019s basically the same as the article describes, and it has definitely increased the number of tests I write.Happy to open source if anyone is interested.\n \nreply"
    ],
    "link": "https://www.assembled.com/blog/how-we-saved-hundreds-of-engineering-hours-by-writing-tests-with-llms",
    "first_paragraph": "At Assembled, engineering velocity is our competitive edge. We pride ourselves on delivering new features at a fast pace. But how do we maintain quality without slowing down? The answer lies in robust testing. As Martin Fowler aptly puts it:Despite this, writing comprehensive tests is often overlooked due to time constraints or the complexity involved. Large Language Models (LLMs) have shifted this dynamic by making it significantly easier and faster to generate robust tests. Tasks that previously required hours can now be completed in just 5\u201310 minutes.We've observed tangible benefits within our team:In this blog post, we'll explore how we\u2019ve used LLMs to enhance our testing practices.To get started, you'll need access to a high-quality LLM for code generation like OpenAI's o1-preview or Anthropic's Claude 3.5 Sonnet.Then, you should craft a precise prompt that guides the model to produce the desired output. Here's a sample prompt we've found effective for generating Go unit tests:\u200dIn",
    "summary": "At <em>Assembled</em>, they've discovered the holy grail of software development: using Large Language Models (LLMs) to write tests so they don't have to! Because nothing screams \"quality assurance\" like a five-minute, AI-generated test suite ensuring that your new feature doesn't completely tank your product. Commenters crawl out of the woodwork to debate the philosophical essence of testing, with gems like \"AI could do all this thinking in the future but not yet I believe!\" and practical insights such as \"just continue the conversation with the AI until it admits the code is trash.\" Progress marches on, one auto-generated, potentially useless unit test at a time. \ud83d\ude02\ud83d\udc69\u200d\ud83d\udcbb"
  },
  {
    "title": "The weak science behind psychedelics (theatlantic.com)",
    "points": 23,
    "submitter": "Hooke",
    "submit_time": "2024-10-26T23:39:50 1729985990",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41958575",
    "comments": [
      "https://archive.ph/ptIQy",
      "Psychedelics boost your mood in the days, weeks, and even months after taking them. Source: I've used them. It's really dramatic.However, eating a piece of chocolate also makes you feel good. Doesn't mean chocolate is an effective treatment for depression. Whether psychedelics are effective treatments for various psychological conditions, I don't know. Whether the risks outweigh the benefits, I don't know.I've grown more conservative about drug use over the past few years. I hope we keep up the research but it is very clear that -- as the article argues -- these drugs have been overhyped.\n \nreply",
      "I have a friend who refuses to find the counsel of a licensed therapist because hens so proud of the insights received while tripping.Sadly, hen and hens family desperately need help.\n \nreply",
      "So, you think you know better how your friend should live his/her life?How would you feel if the tables were reversed and you were being pushed into tripping instead of therapy?These are the kinds of choices that we have to learn to respect, for all of us, which means less judging.There may be other ways to help if that's really what you want to do.\n \nreply",
      "I agree with the sentiment of the article. We need better science in general.It came to my mind if we have equally solid research for the effectivity of drugs like antidepressants. They have fame of sometimes working and sometimes don't depending on the patient, and I guess the same could be said of many psychedelics.\n \nreply",
      "We have way less experience with antidepressants though. And none of the psychedelics I'm familiar with has anywhere near the same amount/degree of unwanted side effects.Empirical research is also research.That said, I agree. We need more research, which would have happened a long time ago if it wasn't for criminalization.\n \nreply",
      "Antidepressants also have the fame of having a ton of side effects, whether work or not. Reduced libido, sexual dysfunction, weight gain, brain zaps are the most common. Not to mention that they take weeks or months to both start and stop.I'm not at all against antidepressants, and I know several people who have been helped a lot by them. But if there are potential alternatives like ketamine and psychedelics that have lower risk of side effects (ketamine in particular is extremely safe taken in a therapeutic setting) and only need to be taken once to potentially see an immediate effect, even if the science is weak, shouldn't these at least be available for adults to try before putting them on antidepressants?\n \nreply",
      "> They have fame of sometimes working and sometimes don't depending on the patient, and I guess the same could be said of many psychedelics.The same could be said for almost any drug or intervention.\n \nreply",
      "Better evidence is always good, but we much more drastically need better policy. Psychadelics' potential benefits are still being explored, but their risks are pretty well-documented and quite minimal compared to a broad swath of substances legal for adults to acquire. There is no reason consenting adults should be criminalized for seeking them out\n \nreply",
      "I don't know. It's good that we have know conclusive non-effectiveness, right? Is Olga Khazan volunteering $150m to run the first two phases of a drug trial? Should that money be spent on worse bets? Does she have an opinion on which bets were better (no)? IMO, better to live in a world where drug development happens due to good storytelling and we get an answer, good or bad, regardless of macro, rather than drug development only occurring during ZIRP.\n \nreply"
    ],
    "link": "https://www.theatlantic.com/ideas/archive/2024/10/psychedelics-medicine-science/680286/",
    "first_paragraph": "If vulnerable patients are going to take powerful hallucinogens, they deserve better evidence.Produced by ElevenLabs and News Over Audio (NOA) using AI narration.No psychiatric treatment has attracted quite as much cash and hype as psychedelics have in the past decade. Articles about the drugs\u2019 surprising results\u2014including large improvements on depression scores and inducing smokers to quit after just a few doses\u2014earned positive coverage from countless journalists (present company included). Organizations researching psychedelics raised millions of dollars, and clinicians promoted their potential to be a \u201cnew paradigm\u201d in mental-health care. Michael Pollan\u2019s 2018 psychedelics book, How to Change Your Mind, became a best seller and a Netflix documentary. Psychedelics were made out to be a safe solution for society\u2019s most challenging mental-health problems.But the bubble has started to burst: It\u2019s been a bad year for fans of psychedelics.A few months ago, two articles appeared, one in Th",
    "summary": "**\"The Weak Science Behind Psychedelics: A Shroom-Sized Overreaction\"**\n\nIn a stunning revelation, an article from <em>The Atlantic</em> tackles the hyped world of psychedelics with the precision of a sledgehammer going after a fly. Comment sections light up with armchair pharmacologists and weekend trip warriors declaring decades of shamanic expertise because, as one commenter insightfully points out, \"I've used them.\" \ud83d\ude44 As the scientific community scratches their heads over actual evidence, well-meaning netizens are already drafting legislation in their minds to save us from our own neurotransmitters. If only science moved as fast as web-based convictions, we'd all be telepathically linked by now... or at least effectively self-diagnosed. \ud83c\udf44\u2728"
  },
  {
    "title": "Google preps 'Jarvis' AI agent that works in Chrome (9to5google.com)",
    "points": 37,
    "submitter": "elsewhen",
    "submit_time": "2024-10-26T23:49:48 1729986588",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41958642",
    "comments": [
      "> previewed \u201cas early as December,\u201d ... After that, Jarvis might be made available to early testers, so a launch does not seem imminent.Google is trying to show they are not behind in the AI race by advertising something probably barely out of alpha testing. It just reinforce the idea that Gemini is still inferior to Claude and ChatGPT.I tried Gemini once and then tried Claude. It was such a huge difference I can't imagine Google, who created the transformer architecture, can be so behind a tiny startup a fraction of their size.\n \nreply",
      "I flip between ChatGPT4o, Claude, Gemini (and its offsets NotebookLM and AIStudio). They all have their niches for example Claude projects (+ 3rd party claudesync) is useful for generating code for an Xcode project, or AIStudio can handle more file formats including video. Then there's different context sizing, Gemini being the biggest I'm aware of.I'm really unimpressed by the velocity of feature development from these AI orgs, I don't expect them to have complete feature parity any time soon if at all.As always pick the right tool for the job. There is almost never a 1-size fits all best selection.\n \nreply",
      "I have found Gemini pro to be excellent for RAG application. Most of my java projects with less than 500k lines of code can fit entirely in its context window so I don't have to mess with chunking.Before this came along, we had tried different tools and RAG applications and nothing compares to what Gemeni delivers. And the cost is nearly nothing compared to gains.\n \nreply",
      "Gemini Flash seems remarkably fast and cheap, noticeably cheaper than most (any?) reasonable alternatives. Other models have a best in class context window. Gemini is also known for citing its sources better than many other models.I\u2019m not sure they\u2019re behind, maybe just focusing on different things? Being fast makes sense for a lot of use cases, and large context windows are important for the sorts of cases like NotebookLM, and citing sources is important for safety.\n \nreply",
      "Gemini is #3 on the leaderboard; seems like it can't be that bad.https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leade...\n \nreply",
      "I worked on this at Google 4 years ago\n \nreply",
      "Gemini is mostly good for its large context window (which is a huge plus), but the answers and \u201cintelligence\u201d aren\u2019t nearly as good as chatGPT 4o. I haven\u2019t tried Claude so I don\u2019t know how well that does.\n \nreply",
      "How many ads-per-second will Jarvis serve?In all seriousness I firmly believe they\u2019ll embrace ads in AI responses and I see zero reason to think they wouldn\u2019t.\n \nreply",
      "The endgame is undisclosed promotional content seamlessly inserted into algorithmic output. And of course this will be too indirect and obfuscated to be regulated. If you think lack of corporate accountability is bad now, wait until all reputation and liability have been fully laundered to AI.\n \nreply",
      "Takes screenshots and uploads them to the cloud for processing because it is so inefficient?Google\u2019s not even pretending to care about privacy any more.\n \nreply"
    ],
    "link": "https://9to5google.com/2024/10/26/google-jarvis-agent-chrome/",
    "first_paragraph": "At I/O 2024 in May, Google gave two examples of agentive experiences that you\u2019d access through Gemini. Google might be ready to share more about agents that work in Chrome and are powered by Gemini 2.0 this December with Project Jarvis.\u00a0\u201cI think about [agents] as intelligent systems that show reasoning, planning, and memory. Are able to think multiple steps ahead, work across software and systems, all to get something done on your behalf, and, most importantly, under your supervision.\u201d\u2014Sundar Pichai on AI agents\u00a0According to The Information, Google is \u201cdeveloping artificial intelligence that takes over a person\u2019s web browser to complete tasks such as gathering research, purchasing a product or booking a flight.\u201d\u00a0\u201cProject Jarvis\u201d \u2014 in a nod to J.A.R.V.I.S. in Iron Man \u2014 would operate in Google Chrome and is a consumer-facing (rather than enterprise) feature to \u201cautomate everyday, web-based tasks.\u201d The article doesn\u2019t specify whether this would be for mobile or desktop.At I/O, Pichai sho",
    "summary": "<b>Google Plays Dress-Up With 'Jarvis'</b>: Google, in a desperate attempt to stay relevant in the AI party hosted by cooler kids like OpenAI and Anthropic, dresses up Chrome with a new gimmick called 'Jarvis'. According to Sundar Pichai, Jarvis will plan, remember, and essentially dance on command just shy of making you coffee. Meanwhile, the comment section buzzes with AI aficionados arguing over which AI toy runs their niche errands faster, while skeptically noting Google\u2019s penchant for turning every interaction into an ad-serving bonanza. Will Jarvis be the productive butler or just another sneaky salesman? Only Google\u2019s creepy privacy invasions will tell. \ud83d\ude12"
  },
  {
    "title": "Deep dive: the instability of op-amps (lcamtuf.substack.com)",
    "points": 88,
    "submitter": "lapnect",
    "submit_time": "2024-10-26T14:38:11 1729953491",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=41955003",
    "comments": [
      "It's almost criminal that all of these bode plots are missing their phase diagrams.Phase diagrams + OpAmp phase shift specs / phase margin are what you need to predict instability.-------EDIT: IMO it's also a lot easier to explain in the frequency domain. At 180-degree phase shift, all your negative feedback turns into positive feedback, causing instability. You need your amplifier to stay as far away from 180-degree phase shift as possible.I get that what the author was trying to get to with the 'Tape Delay OpAmp' example. But it should be double downed upon and the starting point of the discussion rather than something brought up later IMO.\n \nreply",
      "I appreciate what you're saying. That said, not everyone learns the same way and for me, his explanations have always been clear and insightful. My theory is that different brain architectures ingest information in different ways (this is actually studied but not conclusively proven AFAICT) and that the language of exposition has a sort of 'impedance match' with brain architecture. So sometimes you can say something and the person hearing/reading it will just \"get it\" right away, and sometimes they will look at you like \"that didn't help at all.\"That said, I agree that if you're used to thinking about things in the frequency domain it makes sense to explain it in those terms. Myself, as a young EE in college found thinking about things in the frequency domain to be useless, in part because I didn't understand the math, and in part because I didn't really understand sinusoidal waveforms. It wasn't until I started diving into SDRs and really unpacking the FFT and how it worked and why did I manage to connect a lot of dots that retroactively gave me a better insight into what my control systems professor was trying to teach me back in the day.\n \nreply",
      "I agree.Phase Margin (How far away you are from 180 Phase Shift) is a critical parameter used whenever designing any kind of feedback loop and testing for stability.This is very to measure at the 0dB gain he pointed out, but lacked the phase diagram to show this shift.\n \nreply",
      "I agree the overall math is easier in the frequency domain, especially because you don\u2019t know which frequencies are problematic so best to look at all of them, but I think the concept is best explained at first, in the time domain.Here\u2019s my attempt in a couple of sentences.It takes time for the signal to propagate from input to output in any real circuit. If that time is a substantial fraction of the period under consideration then the input of the amplifier, which includes the feedback signal, cannot effect the output before it has moved.  And if the delay through the amplifier is just wrong relative to the signal period one can end up in a dog chasing its own tail situation and the output oscillates.The rest is just math. :)P.S.  this explanation also explains why we use phase and not seconds to measure the delay of the circuit.  Because everything is relative to the input signal period and if we use phase we get that for free.  No extra divide.\n \nreply",
      "This is only true for LTI (linear time-invariant systems).Nonlinear systems responses to a sine signal are in general not just a change in phase and amplitude.It works if the perturbation stays small and within a linearised version of the dynamics.\n \nreply",
      "This is tangential, but I took an EE class at community college and the very first thing they did was start teaching op-amps. I don't remember ever getting any insight from working with them, only that we had to follow instructions and build one in the lab.When I see people asking questions about op-amps and doing \"deep dives\" into op-amps, I'm left wondering what's so deep about these things we do in week 2 of EE 101.I've forgotten almost everything from that class though, so maybe it was just a bad class? I switched majors and never took another EE class.\n \nreply",
      "It is a headscratchingly bad idea to put op-amps in week 2 of course #1. I can\u2019t even remember for sure if we did them in the first course, but if so, it was at the very end, after you already know how to do algebraic working-out of values in a circuit. From there, they give a couple algebraic rules to figure out what an op-amp circuit does. And a key point that is usually glossed over is: op-amps are basically useless when not in a feedback configuration, and some of the analysis rules are based on already assuming the op-amp is in a feedback configuration.\n \nreply",
      "I'd say that nothing can be covered deeply in an introductory survey class. If it's being taught at the 101 level, the students don't yet have the math to scratch anything beneath the surface. And one of the points of op amps, if not the main point, is the correspondence between their mathematical representation, and their real world behavior.There are entire books about op amps and their uses. They're a cornerstone of analog design.\n \nreply",
      "Now that you mention it, I remember the point was the difference between the theoretical math and the actual behavior.\n \nreply",
      "I can definitely see how a more advanced student can get a ton of valuable insights about the \"abstraction leaks\" of opamps, and I would even submit that opamps could be a particularly fertile place of such leaks (for our more software minded brethren: opamps are like databases: they are perfect until you start to push their boundaries and then you very quickly start to see just how imperfect they are), but I doubt you can teach a student enough about the theoretical math to get a useful intuition about the  behavior of opamps in under 2 weeks.\n \nreply"
    ],
    "link": "https://lcamtuf.substack.com/p/deep-dive-the-instability-of-op-amps",
    "first_paragraph": "",
    "summary": "**Another Stab at Op-Amps: The Saga Continues**\n\nIf you ever wanted to simultaneously feel like a genius and a complete novice, the latest \"exploration\" at \ud83c\udf93 lcamtuf.substack.com about op-amps is the perfect read. The comments section transforms into a battleground where EE enthusiasts flex their technical muscles, debating the ins, outs, and what-if's \ud83d\udd04 of phase diagrams and frequency domains. Notably, one bright individual reminds everyone that you can't explain something until you've over-explained it in six different ways! Amidst the chaos, several fledgeling engineers reminisce on their college days, vaguely recalling that op-amps were a thing, proving once again that no matter how deep you go, it's just never deep enough for internet experts. \ud83e\udd13"
  },
  {
    "title": "Carma (YC W24) hiring founding SWEs (remote) to build the next Uber for auto repair",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-10-26T21:00:32 1729976432",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=41957685",
    "first_paragraph": "",
    "summary": "Carma, a Y Combinator amusement for the spring of 2024, is on a heroic mission to become \"the next Uber,\" but this time for sputtering engines and rusty bolts. With visionary zeal, they evoke the myth of \"founding SWEs,\" presumably wizards fluent in the arcane arts of JavaScript and hopes dashed by reality. Meanwhile, in the comments section, a veritable circus of tech bro enthusiasm meets deep caregiving about employment terms, as remote work warriors flex their vast ignorance about automotive maintenance while arguing who\u2019s the true agile scrum master. \ud83d\ude97\ud83d\udca5"
  },
  {
    "title": "Building a more robust Wikipedia interface by spotting the differences (2023) (nray.dev)",
    "points": 12,
    "submitter": "gofiggy",
    "submit_time": "2024-10-26T23:38:18 1729985898",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41958561",
    "comments": [
      "> The previous skin, Vector, had been the default look on Wikipedia for 12 years. It was time for a better desktop experience.So, when is the better desktop experience coming?I kid, I kid. Well, kind of. There are features of Vector2022 I really like, and wish was part of classic Vector, like the search bar. I still can\u2019t get used to the LHS table of contents.Ironically Vector2022 has a much improved mobile experience compared to mobile-first themes like Minerva. It\u2019s nice to have a fully-supported responsive theme.Is Pixel going to be available in Gerrit?\n \nreply",
      "Yeah, I had to create a user on many language versions just to keep the old skin. \nI fail to see a point in wasting 2/3 of my screen estate to whitespace.\n \nreply",
      "I'm in the same boat. I think it's unfortunate that MediaWiki doesn't accept a theme header or cookie, which would be very easy to set with extensions. User sessions don't persist for very long and don't work in private browsing mode, while the querysring useskin= parameter is annoying to work with and isn't applied to hyperlinks.\n \nreply"
    ],
    "link": "https://www.nray.dev/blog/visual-testing-building-a-more-robust-wikipedia-interface-by-spotting-the-differences/",
    "first_paragraph": "",
    "summary": "In an exhilarating turn of events, Wikipedia decides to revamp its look after a thrilling 12 years, introducing Vector2022, because nothing screams innovation like a sidebar shuffle and a search bar facelift. Cue the nostalgia-crazed hordes on nray.dev, who clutch their digital pitchforks mourning the loss of precious screen real estate and lamenting the unbearable transient nature of user sessions. Amid calls for a mythical better desktop experience and poignant sarcasm about the wonders of whitespace, someone still hopes against hope that Pixel will grace Gerrit. The rest of us ponder the eternal question: will shifting from left to right hand side table of contents finally make us read the articles? \ud83d\ude02\ud83e\udd26\u200d\u2642\ufe0f"
  },
  {
    "title": "Long wave radio fans mourn fading frequencies (2023) (bbc.com)",
    "points": 34,
    "submitter": "austinallegro",
    "submit_time": "2024-10-26T20:42:17 1729975337",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41957585",
    "comments": [
      "\"Plus, an article in The Guardian in 2011 claimed that only a small number of spare valves were still available for the transmitter.\"What a pathetic argument! When you read crap like this you know you're being told sop\u2014an attempt to bamboozle the public with technicalities that don't really exist. Any commonly available high powered RF tetrode from an FM or TV station would do the job albeit with some (mostly mechanical) modifications to the transmitters. Also, it's a common practice to refurbish high power transmitting valves, there are companies that specialize in doing it.I say that as someone who has been involved with high power broadcasting transmitters, in fact I was involved in building several FM broadcast transmitters from the ground up.At only 198kHz\u2014which is somewhere between one 1/500th and 1/1500th its normal operating frequency\u2014any high power VHF transmitting tetrode would be just loafing along.No doubt the way commerce works getting a one-off specialist job to do the conversion would be expensive (I wish I could do it, I'd quote half the price and still make a handsome profit).If the BBC is so strapped for cash perhaps it could ask the Amateur Radio fraternity to mod the TXes for free as a public service. Then after the mods the service could recommence on half power to save costs.Also, there are good strategic reasons why this transmitting infrastructure should be kept operational on these low longwave frequencies which I haven't got time to address here.Suffice to say, I think this proposed closure is more a hatchet job by accountants than from any long-term strategic thinking by governments.Damn shame governments only seem to listen to nanny goat advisors these days.\n \nreply",
      "In the US, I don't think there was any commercial LW broadcasting (but I could easily be wrong). US-market radios rarely had SW bands and almost never had LW unless they were general coverage receivers. For the most part, the few times I looked through the band it was largely navigation beacons.I was rather surprised to see an LW band on a regular clock-radio when I visited the UK, though that was 25 years ago.\n \nreply",
      "There has been no commercial broadcast radio on the longwave band in the US, that's correct. That's why radios featuring that band are rarer here, and usually confined only to enthusiast radios.The WWVB time signal is technically inside the longwave band, at 60kHz.\n \nreply",
      "My first contact with English was listening to the Radio Canada International. Then I knew that I needed to learn it to receive news that only would be in newspapers 2 or 3 days later.Now there are none stations that I can listen at night, and I miss it\n \nreply",
      "I sincerely hope that if the remaining stations shut down, the band will become an amateur band. Existing 2200m and 630m are narrow, so allocating this entire range is something of a pipe dream, but it would be the best outcome.(Not sure how 1750m LowFER would be handled; maybe just keep it on as an unlicensed exception?)\n \nreply",
      "I think LW transmission antennas are too large to be built bu amateurs\n \nreply",
      "Full verticals, dipoles, Yagis or logs, yes.Marconi T or L antennas with capacitance hats and loading coils are well within amateur practice on 630m[1] and 2200m, and common from 40m/7MHz on down.Not very efficient still; an ERP of 1W, as demanded by the 2200m band, can still take a lot of power on a less-than-ideal antenna. Similar story for 630m. (160m and up is usually not so bad, just that even a good Marconi on longwave is still too big for most people.)But the current LowFER[3] regs limit the transmitter to 1W final stage input power, and a COMBINED feedline and antenna length of 15m. At least allowing amateurs to operate more here would allow more than just extremely low SNR modes like WSPR to be used at any real distance.[1]https://www.hamsignal.com/blog/dog-days-and-the-marconi-t-an...and https://vk6ysf.com/t_antenna_arrangment.htm[2]https://en.wikipedia.org/wiki/2200-meter_band#International_...[3]https://en.wikipedia.org/wiki/LowFER\n \nreply",
      "As far as I know, the UK's nuclear submarine fleet used (or still uses?) the presence of a Radio 4 broadcast signal as evidence for the continued existence of the UK. Hopefully they have other means at this point!\n \nreply",
      "From 2020:> During the time following a perceived attack, a series of progressive checks are made by submarine crews leading up to the captain opening the letter. These include trying to listen for radio transmissions from various levels of Royal Navy and Ministry of Defense command using multiple methods, and most famous of all, listening for new radio broadcasts by BBC Radio channel four, and specifically new episodes of BBC Today. [\u2026]* https://www.twz.com/7300/letters-of-last-resort-are-post-apo...Also:* https://en.wikipedia.org/wiki/Letters_of_last_resort\n \nreply",
      "Why are they calling this long wave instead of just AM radio?\n \nreply"
    ],
    "link": "https://www.bbc.com/news/business-66644709",
    "first_paragraph": "As he turned the dial gently but purposefully, the sound of people speaking in foreign languages and the lilt of unfamiliar music burst through a haze of crackle and buzz. Clint Gouveia was only about seven years old at the time, listening to long wave radio in bed, late at night.\"I could hear all these voices from far away,\" he recalls. \"It inspired me to want to see the world when I got older, to travel, which eventually I did.\"Back then, in the late 1970s, there were dozens of long wave stations broadcasting. Now, only a handful are left. Among them are those in Denmark and Iceland - but they are due to shut by the end of 2023 and during 2024, respectively. The BBC still broadcasts Radio 4 on long wave as well as on digital radio, FM, and online. However, separate scheduling of BBC radio programmes on long wave will end in March next year - for example Test Match Special will not be available on long wave. The long-term future of the BBC's long wave output is far from certain. The o",
    "summary": "**Nostalgia Nerds Bemoan the Inevitable Decline of Long Wave Radio**\n\nIn a world rapidly advancing beyond the concept of physical media, a handful of long wave radio enthusiasts cling to their buzzing, cracking antique boxes. Here's Clint, deeply moved by the unrecognizable tunes of the late 70s, deciding this fading relic inspired his worldly travels, which apparently could not have been sparked by anything less antiquated. Comment sections erupt with know-it-all broadcasts: one genius suggests repurposing FM tetrodes for long wave transmitters as if he's MacGyver saving the day, another dreams of turning all long wave bandwidth over to ham radio hobbyists as if frequencies were candy being handed out at a parade. Amidst calls for saving submarines with Radio 4 signals and mistaking AM for long wave, we witness the tech equivalent of arguing over the best horse breed long after the invention of the car. \ud83d\udcfb\ud83d\udc94\ud83d\ude2d"
  },
  {
    "title": "Goodhart's law isn't as useful as you might think (2023) (commoncog.com)",
    "points": 42,
    "submitter": "yagizdegirmenci",
    "submit_time": "2024-10-26T18:13:03 1729966383",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=41956587",
    "comments": [
      "If you are interested in these ideas, you should know that this essay kicks off a series of essays that culminates, a year later, with an examination of the Amazon-style Weekly Business Review:https://commoncog.com/becoming-data-driven-first-principles/https://commoncog.com/the-amazon-weekly-business-review/(It took that long because of a) an NDA, and b) it takes time to put the ideas to practice and understand them, and then teach them to other business operators!)The ideas presented in this particular essay are really attributed to W. Edwards Deming, Donald Wheeler, and Brian Joiner (who created Minitab; \u2018Joiner\u2019s Rule\u2019, the variant of Goodhart\u2019s Law that is cited in the link above is attributed to him)Most of these ideas were developed in manufacturing, in the post WW2 period. The Amazon-style WBR merely adapts them for the tech industry.I hope you will enjoy these essays \u2014 and better yet, put them to practice. Multiple executives have told me the series of posts have completely changed the way they see and run their businesses.\n \nreply",
      "I want to block some time to grok the WBR and XMR charts that Cedric is passionate about (for good reason).I might be wrong but I feel like WBR treats variation (looking at the measure and saying \"it has changed\") as a trigger point for investigation rather than conclusion.In that case, lets say you do something silly and measure lines of code committed. Lets also say you told everyone and it will factor into a perforance review and the company is know for stack ranking.You introduce the LOC measure. All employees watch it like a hawk. While working they add useless blocks of code an so on.LOC commited goes up and looks significant on XMR.Option 1: grab champagne, pay exec bonus, congratulate yourself.Option 2: investigateOption 2 is better of course. But it is such a mindset shift. Option 2 lets you see if goodhart happened or not. It lets you actually learn.\n \nreply",
      "This is accurate. https://xmrit.com/articles/gift-exceptional-variation/\n \nreply",
      "Just a side note that this usage isn't really the application Goodhart had in mind. Suppose you're running a central bank and you see a variable that can be used to predict inflation. If you're doing your job as a central banker optimally, you'll prevent inflation whenever that variable moves, and then no matter what happens to the variable, due to central bank policy, inflation is always at the target plus some random quantity and the predictive power disappears.As \"Goodhart's law\" is used here, in contrast, the focus is on side effects of a policy. The goal in this situation is not to make the target useless, as it is if you're doing central bank policy correctly.\n \nreply",
      "This doesn't really touch on the core of the issue, which is business expectations that don't match up with reality.Business leaders like to project success and promise growth that there is no evidence they will or can achieve, and then put it on workers to deliver that, and when there's no way to achieve the outcome other than to cheat the numbers, the workers will (and will have to).At some point businesses stopped treating outperforming the previous year's quarter as over-delivering, and made it an expectation, regardless of what is actually doable.\n \nreply",
      "I can confirm this. We've standardized Goodhart's law creating a 90-day rotation requirement for KPIs. We found that managers would reuse the same performance indicators with minor variations and put them on sticky notes to make them easier to target.\n \nreply",
      "Wow. That is an extremely cool idea - new to me.Do you have enough KPIs that you can be sure that these targets also serve as useful metrics for the org as a whole? Do you randomize the assignment every quarter?As I talk through this ... have you considered keeping some \"hidden KPIs\"?\n \nreply",
      "I'm riffing on password rotation requirements and the meta-nature of trying to make Goodhart's law a target. I could've been a bit more obviously sarcastic.\n \nreply",
      "I mean, Poe's Law [0] and all, but I was quite surprised your comment was interpreted as anything but saracasm.[0] https://en.wikipedia.org/wiki/Poe%27s_law\n \nreply",
      "If your managers are doing that it's a strong signal your KPIs are a distraction and your managers are acting rationally within the system they're been placed.They need something they can check easily so the team can get back to work. It's hard to find metrics that are both meaningful to the business and track with the work being asked of the team.\n \nreply"
    ],
    "link": "https://commoncog.com/goodharts-law-not-useful/",
    "first_paragraph": "Existing member? Sign InThis is part of the Operations topic cluster, which belongs to the Business Expertise Triad.Join 8,000+ sharp investors and operators like yourself, and we'll send you a collection of Commoncog's best articles right away:This is Part 1 of the Becoming Data Driven in Business series. Goodhart\u2019s Law is a famous adage that goes \u201cwhen a measure becomes a target, it ceases to be a good measure.\u201d If you\u2019re not familiar with the adage, you can go read all about its history on Wikipedia, and perhaps also read the related entry on the \u2018cobra effect\u2019 (which includes a litany of entertaining perverse incentive stories, of which the eponymous cobra anecdote is merely one):But I\u2019m here to tell you that Goodhart\u2019s Law is not as useful as you might think.At some level, this is self-evident. Goodhart\u2019s Law is about as pithy and about as practicable as \u201cthe only certainty in life is death and taxes\u201d and \u201chell is other people.\u201d It is descriptive; it tells you of the existence of ",
    "summary": "**Goodhart's Law Emoji Edition: The Gauntlet of Uselessness \ud83d\ude24\ud83d\udc0d**\n\nAt *commoncog.com*, a land filled with the sagacious sages of business, they've heroically declared Goodhart's Law *not all that*. In a brilliant move of nerd baiting, they suggest you scamper off to Wikipedia to bone up on \"cobra effect\" anecdotes before pronouncing the law as useful as a chocolate fireplace. Meanwhile, commentators, in a festival of missed points, spin tales of metric misadventures, stack ranking faff, and XKCD-worthy KPI rotations, solving *absolutely nothing* but hey, at least we're all having a good moan about it! \ud83d\udc4f\ud83e\udd42\ud83d\udc94"
  },
  {
    "title": "Order and orient the keys on your keychain (practicalbetterments.com)",
    "points": 25,
    "submitter": "surprisetalk",
    "submit_time": "2024-10-22T16:29:32 1729614572",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=41915978",
    "comments": [
      "> Locks typically open clockwise [...]Is that so? My intuition is that it should depend on the side of the door the lock is mounted on. Most locks I have seen open by turning them away from the side where the latch is on, to move the bolt in the direction it is being turned, and that feels pretty natural to me. Isn't that the norm?My apartment key opens 7 different locks, 1 of which opens clockwise, 5 counterclockwise, and 1 I don't know right now because it isn't actually mounted on a door and doesn't move a bolt.\n \nreply",
      "Yep, you move the top of the key away from the door casing, and that's the natural way. Counterclockwise if the lock is on the right, clockwise if it's on the left.\n \nreply",
      "If you keys are on a keyring like those in the illustrations in the article where the keys can easily jangle and that gets annoying I found a good way to address that.\u2022 Get some small magnets. I used these 8 mm diameter 1mm thick disk magnets [1].\u2022 Attach one to each key near the hole for the keyring. Orient the magnets so the each is attracted to the magnets on the neighboring keys.When hanging on your keyring your keys will then form one unit which won't jangle.You want magnets that are strong enough to attract through the keys. If yours need a little help you could try putting a magnet on each side of the key.I held them on by wrapping some tape around the key.[1] https://www.amazon.com/gp/product/B071XNRF2D\n \nreply",
      "There's alternatives to keyrings as well, holders so your keys become their own swiss army knife.\n \nreply",
      "A year or two I got a KeyPort, which is a modular key organizer.  It's an aluminum frame with screws at either end that the heads of typical keys can go through, creating something like a swiss army knife of keys.  The frame has modular mounts for accessories like a belt/pocket clip and a knife.I'm fairly meh about it, largely because I don't think it's good value.  It was pretty hard for me to spend $60 on a keyring, and the knife is also fairly meh (I prefer locking+spring assisted opening knives for EDC).  Also their \"Key return service\" is fairly meh; not really looking forward to another $4.99 service charge every year that I have to manage, when paying $60 for this thing.Another company, KeySmart, has a similar device and it's more compact but doesn't do the \"attachments\" thing, so you'd carry a knife if you wanted that.  They have one that has Tile finding device built in, as long as you remember to charge it.  I had one for ~4 years with a Tile device attached to it, that had a dead battery for 90% of the time I had it.I'd be tempted to get one of the smaller key organizers with an AirTag holder and set up a little magsafe charging setup that I could just drop my keys into.I mostly don't lose my keys very often, but once in the last decade I dropped them while taking the kids around the neighborhood trick-or-treating and I don't want to repeat that experience, mostly because I keep a couple office keys on my ring.\n \nreply",
      "This was a very confusing article to read the comments to first, because people seem to be so passionate about something that I couldn't even visualize. The disconnect is that my (continental European) experience is that any modern lock for something important will have a key with 180 degree rotational symmetry.\n \nreply",
      "Related to this, pin tumbler locks on doors should be installed so that the bitting (i.e., the teeth on the key) face up when inserting the key. If you follow a standard orientation, you don't have to think about which way to orient the key when inserting it, especially in the dark.There's a technical reason why \"bitting up\" (teeth up) should be the standard way to install pin tumbler locks. If the bitting faces up, the pins in the lock are directly above the bitting, and the springs are above the pins and not being compressed by the weight of the pins. If the lock is installed upside down such that the key goes in with bitting facing down, then the pins are sitting on top of the springs and may compress down over a period of years. A fatigued spring might not raise the pins to the shear line (the level needed for the lock cylinder to turn) and you'll be locked out.It seems that most door installers and handymen don't follow any convention about up or down when installing locks.\n \nreply",
      "I haven't owned a keychain for many years now. After renovating our house, we installed a Yale Doorman. It's the best $300 investment I've done that I can think of:\n- Don't have to carry a keychain at all anymore\n- I can give strangers (think AirBnb, or cleaners) time-bound access codes\n- I can remotely unlock/lock the door for someone if they need immediate access\n- Kids can get home without a key - Kids losing their key not a worry anymore\n- Work office is keyless too (xlock)\n- We always keep a small 9V battery outside in case the battery goes flatIt was after a painful deadlock situation that we initially retro-fitted an electronic lock into the old front door which we carried over to the new door once we renovated the entire floor.\n \nreply",
      "I've always been tempted/curious to adopt a sort keyless of approach. I dislike carrying keys...and have had to carry (what to me feels like too many) keys always throughout my life. But without really researching the option you referenced, i have fears about failure modes for this type of keyless kock. For example...* If/When the battery dies, does the lock default to locked setting? I assume so, but how annoying would this be?* Being a privacy nut, does the lock come with a pre-determined code, or can you generate your own?  I assume you should be able to create your own, but figuried I'd ask.Instead of answering my questions, if you have an online reference that you might have used to decide going this route, would be great if you could share.  Thanks!\n \nreply",
      "> * If/When the battery dies, does the lock default to locked setting? I assume so, but how annoying would this be?Typically, the home locks are just actuated mechanical locks. So the lock will stay in whatever state it was when the battery died. If you want to get into commercial-grade locks, there are magnetic locks that can be configured to fail open or close on power loss.Anyway, the battery is not a big deal. I have a Kwikset lock with a ZigBee module, it runs on 4 AAA batteries. I switched to Li-ion rechargables several years ago, and they last for about 6 months between recharges with moderate door use. It's even longer if the lock is not used often.And the lock starts beeping annoyingly after opening/closing when the batteries get down to 30%, giving you plenty of time to replace them.> * Being a privacy nut, does the lock come with a pre-determined code, or can you generate your own?You always can set your own combinations. And there are biometric locks.\n \nreply"
    ],
    "link": "https://practicalbetterments.com/order-and-orient-the-keys-on-your-keychain/",
    "first_paragraph": "The time spent getting into your home is nothing time.It isn't travel, it doesn't enrich the soul, or broaden your horizons \u2014and unlike other parts of your commute, it is too short to be used for learning or self-reflection.Worse still, in an emergency, when you're at your most fumble-some, this time could be critical for putting out a fire.That's why I've spent way too long thinking about the optimal arrangement of keys on a keychain, to reduce egress time to a minimum.Most people probably don't need to unlock three doors to get into their home (my situation) but the same logic should apply to any configuration of keys.1. Orient your keys so they all face in the direction of entryHaving all your keys face the same direction is critical.Two sets of keys on keychains, one with all the keys facing the same direction, with a smiling keychain, the other with a key facing a different direction, with the keychaing frowing.If keys are oriented in different directions, you'll need to reorient ",
    "summary": "In a world where every second _obviously_ counts, practicalbetterments.com gifts humanity with the *sacred* knowledge of keychain optimization. Because normal people spend countless hours fumbling for keys, this ground-breaking article ensures that you shave off those crucial milliseconds during your exhilarating journey from driveway to living room. Commenters pile in with life-altering suggestions like adding magnets to keys (because jangling is the real crisis) and graduate-level discussions on lock rotation dynamics. Meanwhile, someone bravely confesses to abandoning medieval keyrings for something called a Yale Doorman, ushering us into the lock-less utopia we all clearly crave. \ud83d\udeaa\ud83d\udd11\ud83d\udcab"
  },
  {
    "title": "Former Intel CEO says splitting Intel isn't good for the U.S. (tomshardware.com)",
    "points": 14,
    "submitter": "sandwichsphinx",
    "submit_time": "2024-10-27T00:25:42 1729988742",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41958862",
    "comments": [
      "Given his position, is it possible the Intel CEO is a little biased? /s\n \nreply",
      "I went in thinking the same thing. After reading it, it's not 100% sure which type of bias it is. In the most charitable case, it could be sincere opinions formed by a career as Intel's CEO. An aftershock of a career in innovation.Maybe it's the \"grizzly thinks latching trashcans are a sign of hedonistic excess and should be shed\" kind of bias. Less clear to me as an ex-ceo. Equity ownership could bend the needle that way for sure.Ah well, I doubt either of us know the man.\n \nreply",
      "Honestly, more than the click-baity title, I was more amused by the subtle demand for even more subsidies ( that after putting US through offshoring, nearshoring and now taxpayer sponsored reshoring ):\"Barrett also said Washington must do its job to stay ahead of the semiconductor race. The U.S. has invested more in the semiconductor industry in the past year than in the last 28 years combined, but he says it should do even more, especially in academic research.\"Makes one question whether he still owns substantial stake in the outcome.\n \nreply"
    ],
    "link": "https://www.tomshardware.com/tech-industry/former-intel-ceo-says-splitting-intel-isnt-good-for-the-u-s",
    "first_paragraph": "Doing so would bring more harm than good in the long term.\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nIntel\u2019s financial situation has recently been in trouble, mainly due to the massive losses of its foundry division. Because of this, several reports say that the company is considering spinning off manufacturing as a completely different entity, similar to what AMD did with GlobalFoundries. However, former Intel CEO Craig Barrett wrote on Fortune that doing so would hurt Intel and impair America\u2019s goal of semiconductor leadership.Barrett argues that chip manufacturers require massive investments to remain competitive. Only three chipmakers \u2014 Intel, Samsung, and TSMC \u2014 have the revenue to sustain the research and development needed for future products. Intel\u2019s design arm would likely survive this split, but it\u2019s an open question if Intel\u2019s foundry business would last.He compared this to the AMD-GlobalFoundries split in 2008. To",
    "summary": "In a shocking twist that nobody could have predicted, a former Intel CEO writes an opinion piece claiming that breaking up Intel is about as beneficial to the U.S. as an ice cream sundae is for a lactose intolerant. Meanwhile, over at Tom's Hardware, the comment section becomes a circus of armchair CEOs debating whether *\"bias\"* is just a new Silicon Valley brand of coffee. One keen observer points out the real tragedy: amidst calls for more R&D cash, it's clear the only chips increasing in numbers are those on former executives' shoulders. \ud83c\udf7f"
  },
  {
    "title": "We Can Terraform the American West (caseyhandmer.wordpress.com)",
    "points": 205,
    "submitter": "jasondavies",
    "submit_time": "2024-10-26T00:22:42 1729902162",
    "num_comments": 263,
    "comments_url": "https://news.ycombinator.com/item?id=41951420",
    "comments": [
      "At first I thought that this was a satire, but then the joke never landed.  The author cites \"Cadillac Desert\" but then ignores everything in the book.  This posting is fantasy in the same vein as \"we can build a space habitat at L5 by 1995\".There is a lot of money to be made in water.  If desalination was cost effective it would be being done today at scale.  It isn't a regulatory issue, it is strictly economics.  If someone could demonstrate the technology the author describes indefinite amounts of money would flow to them.  It hasn't happened. It's not happening anywhere in the world.Finally the author talks about pumping water up hill as though it is a trivial thing.  20% of all of the electricity generated in California goes to pumping water today.  The author conveniently side steps the issue of building out the vast electrical grid needed just to pump the water.  What was this even posted to hacker news?\n \nreply",
      "> 20% of all of the electricity generated in California goes to pumping water today.Hi, this is wrong. The 20% figure includes all electricity for water-related uses, not just pumping. Most of that (80-90%) is heating and other end uses, not pumping and transport.\n \nreply",
      "It is true that end-use heating takes a lions share of the energy from the water-energy nexus in California.That said conveyance and pumping water over the Tehachapi takes a pretty impressive workload. Water is lifted 1,926 feet by fourteen 80,000 horsepower pumps.OP comment is that the article is flippant on pumping water.  OP is correct that they shouldn't be and it is energy intensive.\n \nreply",
      "> If desalination was cost effective it would be being done today at scale.It is being done at scale in places like Israel. It doesn't even need base load power, you could run it with the infinite amount of cheap solar energy available in the Southwest. The only reason it isn't being done is places like California is entirely regulatory. In fact Arizona might get there first, there has been recent progress between them and Mexico to do desalination in the Sea of Cortez, which is only 60 miles from the Arizona boarder.\n \nreply",
      "According to the article, intermittent operation is assuming new desalinization technology that needs to be invented:> Current RO plants cost more like $2000/kW, so they\u2019re both financially and technically unsuited to intermittent operation, which fatigues their membranes. Thermal desalination could achieve radically lower cost, albeit at lower energy efficiencies, so there\u2019s work to be done here designing new, low cost desalination machines that fully exploit the upside of cheap solar PV.And that\u2019s largely the point of the article. It\u2019s not being done yet, but he thinks it\u2019s technically feasible and could be a game-changer. Big if true.It\u2019s not something we should plan on until the technology is further developed, but seems like worthwhile R&D to fund.\n \nreply",
      "Sounds like a great way to destroy one of the most diverse and unique marine ecosystems on the planet, thanks to the brine waste.\n \nreply",
      "Couldn\u2019t you pump the brine waste into evaporation ponds and extract lithium and other materials from it?\n \nreply",
      "Could we convert the brine waste to building materials? Truck it out to the desert and build a giant salt pyramid.\n \nreply",
      "I'd have to see some real math to be convinced extracting fresh water from the ocean could raise salt levels enough to destroy the Sea of Cortez ecosystems.\n \nreply",
      "Reasonable summary\u2026\nhttps://www.wired.com/story/desalination-is-booming-but-what...Hard numbers aren\u2019t readily available because we don\u2019t track discharge consistently (or at least didn\u2019t).And it\u2019s not just the salt in the brine, but remnants of the chemicals used to defoul the RO systems.The brine waste is nasty stuff and absolutely deadly to the local environment where it\u2019s discharged.\n \nreply"
    ],
    "link": "https://caseyhandmer.wordpress.com/2024/10/26/we-can-terraform-the-american-west/",
    "first_paragraph": "Why is there almost nothing on the left hand side of the USA? Water scarcity!We\u2019re missing 300 million Americans. We\u2019re missing\u00a0 30 global cities west of 100 degrees longitude. We should do something about it!The western US is a parched opportunity to create millions of acres of prime land for the next billion Americans to live on. Only one ingredient is missing \u2013 water.\u201cCadillac Desert\u201d (1986) by Marc Reisner correctly pointed out that within the limits of natural precipitation, we\u2019ve expanded habitation in the West close to its maximal extent. Nearly 40 years after he wrote, however, the answer to shrinking flows of the Colorado and ever more demand for living space is not to stage some kind of retreat from land otherwise blessed with climate, solar power potential, mineral and human capital wealth. The answer is to flex our industrial might and finish what the irrigators began a century ago, and bring water in vast quantities to the high desert, to terraform a few select valleys in ",
    "summary": "<h3>We Can Terraform the American West (caseyhandmer.wordpress.com)</h3>\n\nIn an awe-inspiring display of ignorance lubricated by techno-optimism, a blogger champions the idea of terraforming the American West because, apparently, all it's really missing is water. Blog commenters, in their ever-predictable form, simultaneously debunk and unwittingly support the delusional plan, with intense debates about desalination tech that <em>effortlessly</em> forgets the reality of economics, energy consumption, and environmental impact. One bright spark suggests building a salt pyramid with waste products because, clearly, what the West needs is a monument to human arrogance. And of course, a sprinkling of incorrect statistics spices up the exchange, because why let facts spoil a perfectly good internet argument? \ud83c\udf35\ud83d\udca7\ud83e\udd26\u200d\u2642\ufe0f"
  }
]