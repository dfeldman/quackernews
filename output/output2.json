[
  {
    "title": "An experiment in UI density created with Svelte (cybernetic.dev)",
    "points": 427,
    "submitter": "11001100",
    "submit_time": "2024-07-27T17:23:55",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=41088013",
    "comments": [
      "I work have built some dense UI for certain types of fixed income (bonds and swaps) trading, looking to move it all to svelte because react cannot handle the quantities of data (and if even if it could the code is unbelievably ugly).Something I've been banging on about for a while is the following: Programmers and designers keep trying to rebuild instagram in every domain, pretty UIs, regular UIs, \"simple\" UIs.This is great when every interaction might be an onboarding, but can be really limiting and stupid in an environment where people are actually paying attention.A proxy I like to use for the above distinction is whether the users are paid more than the programmers\n \nreply",
      "> looking to move it all to svelte because react literally cannot handle the quantities of dataI have nothing against Svelte, but how much data are you showing on screen, exactly?Here's an example table with 100,000 cells (100 rows * 1000 columns per row) that seems fine, from a common React UI kit: https://mui.com/x/react-data-grid/virtualization/#column-vir...It seems fast on my computer normally (M2 Max), slow but usable when the CPU is throttled down 4x, and too slow after that. But that's a lot of cells.Here's a performance comparison, btw:\nhttps://krausest.github.io/js-framework-benchmark/2024/table...Or filtered down to just Svelte vs some common React libs:\nhttps://share.cleanshot.com/LlFXtNx9p6y4kMvqXgc7 (lower numbers are faster; React is generally just a little slower than Svelte, except when it's swapping 2 rows in a big table... then it's 8x slower)\n \nreply",
      "Amongst other things, the primary expense is lot of visual elements in a very dense chart that ideally would be ticking with the market in ~real time and allow more than one on the screen.A lot of it probably should be a canvas but there's a good amount of interactivity on the chart itself so moving it all over might be expensive.You obviously can bludgeon that into react but it's at the point where the diffing does seem to be non-trivially expensive and requires a bunch of nursing in the code which is frankly an insane waste of time in 2024.React is completely fine for big tables, especially if they don't actually change very much.I will also note that in turn this started out as a d3 project, react was much much faster than d3.Edit: Completely forgot to mention memory consumption. We have beefy machines so it's not really a critical problem but think of the poor caches!\n \nreply",
      "(Not that you're asking for advice, but hope you don't mind me sharing some anecdotal experience...)When we had to do similar things, we found that it was much much much faster to take all that sort of stuff out of the DOM and put it into Canvas. You can still wrap React around it for the UI and controls and data passing and all that, but the actual rendering need not involve the VDOM or even the real DOM at all. With ChartJS we were able to get it to show tens of thousands of individual data points in a time-series scatterplot, each datapoint interactive and real-time, with no noticeable lag. And it was super easy to integrate into our React app. https://www.chartjs.org/If it's not just charts, here's another canvas-based drawing lib: https://konvajs.org/docs/sandbox/20000_Nodes.html (and its React tie-in: https://konvajs.org/docs/react/Intro.html)Not trying to discourage you from exploring Svelte if you want to, but it might be less work to just use an existing optimized drawing lib. Regardless of the JS framework used, the DOM is going to be much slower than a Canvas.\n \nreply",
      "> Not that you're asking for advice,The cunningham's-law-optimal way is to not ask, surely. Either that or the some programmers equivalent of the \"death drive\".> canvasIndeed, the canvas is basically inevitable, but it's a bespoke chart that has both temporal and non-temporal data in it (not sure what the terminology should be, but imagine plotting market expectations of interest rates in future and what expectations were historically displayed relative to current levels - but repeated ~200 times), so the existing chart libraries aren't particularly helpful and can get in the way of being able to click on stuff.Anecdotally I find that programmers are very good at writing charts for the kinds of data they understand (time series, time series of their stock options, etc), but even the \"generic\" (e.g. grammar of graphics) libraries can still struggle with simple combinations of those domains.Obviously you can just treat the charting library as a black-box for which you derive coordinate transformations and make things appear in the right place but not a great bus-factor for that kind of code.I use https://github.com/leeoniya/uPlot for sparklines and so on, very fast.\n \nreply",
      "> It's a bespoke chart that has both temporal and non-temporal data in itCool. That sounds like a fun project to work on! If it's not super secret stuff, I hope your company will do a write-up about it afterward.\n \nreply",
      "I suspect Bloomberg terminals fit that bill.\n \nreply",
      "I'd never heard of those until your post, and had to look up a Youtube about what they were: https://www.youtube.com/watch?v=2ee-x6IXWK8That's super fascinating. There's an entire industry that runs off these things, on their totally custom UI, showing everything from stock tickers to news headlines to maps? That must be a fun project to work on (except probably the finance users don't like random UI changes, lol).\n \nreply",
      "The real reason to have bloomberg, other than data, is actually the chat.OTC (things that don't trade on exchanges) markets are a lot closer to ebay or facebook marketplace than many realise, for example, e.g. you ask for a price, possibly haggle a bit, say you want it, behind-the-scenes people scurry off and actually make it happen.When you first activate your terminal bloomberg send you an email congratulating you on joining \"the exclusive club\" (this is exaggerated, they want you to feel special, but there's truth to it).As well as all that bloomberg is technically also still (iirc) one of the largest private computer networks.>  That must be a fun project to work onUnfortunately possibly quite the opposite for many, although no first-hand experience.\n \nreply",
      "avg salary of a bloomberg user is lower than some people might think because there are a lot of support staff who have bloomberg.As for the UI: I wish more things were like bloomberg, but bloomberg itself can be slightly hobbled by wanting to lay everything out as a table all the time when a custom chart designed by a creative domain-expert would be almost as useful.\n \nreply"
    ],
    "link": "https://cybernetic.dev/grid",
    "first_paragraph": "Fits as much data on a screen as possible, while allowing in-depth control of data density to ensure legibility. Pagination is used only when absolutely necessary.Changing the density-relevant settings Decimals, Group Digits, Min Font Size, Min x-Padding, Min y-Padding does not always lead to a change in UI density, since it is determined by all parameters jointly or, as in the case of Min Font Size, Min x-Padding, Min y-Padding, is already realized since these are minimum values.",
    "summary": "**An Experiment in Cramming Pixels (cybernetic.dev)**\n\nIn a world desperate for screen real estate, one brave soul embarks on an adventure to push UI density to its Sisyphean limits. Our hero introduces a series of arcane toggles\u2014Decimals, Group Digits, you name it, which might or might not morph your screen into an impenetrable fog of data. Meanwhile, in the comments, a platoon of armchair engineers earnestly debates whether React's ugliness is an aesthetic or performance issue, as if their morning coffee depended on it. Faced with such perilous UI adventures, one wonders if users will need to be paid extra, not just the programmers. \ud83e\udd13\ud83d\udcbe\ud83d\udd0d"
  },
  {
    "title": "Intel N100 Radxa X4 First Thoughts (bret.dk)",
    "points": 33,
    "submitter": "geerlingguy",
    "submit_time": "2024-07-27T22:51:57",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=41089911",
    "comments": [
      "The N100 seems to be everywhere - presumably it\u2019s some kind of major leap forward in perf/watt or perf/$ versus, eg, J4125? For those in the know, is an N100 mini-pc currently the best place to start for a kid\u2019s \u201cmy first Linux PC\u201d?\n \nreply",
      "I've been really impressed with the N100 Mini-PCs. I have a couple running Proxmox and then a few different VMs and containers to do light server stuff. For $180 the Beelink gives you 16GB of RAM, 512GB of SSD, plenty of video output. Just a fantastic performer.\n \nreply",
      "I thought the n100 would be a joke compared to an an HP G6 mini with i5-9xxx (small book sized computer), but seems they might be competitive with n100 drawing 1/6 the energy? \nIs that right?  Can n100 do fast SHA256 and h265 / x265 transcoding across multiple containers?https://www.cpu-monkey.com/en/compare_cpu-intel_processor_n1...\n \nreply",
      "I'm curious what your application is that needs fast SHA specifically, but yes these Gracemont cores do have hardware SHA-1 and SHA-256 acceleration.https://en.wikipedia.org/wiki/Gracemont_(microarchitecture)https://en.wikipedia.org/wiki/Intel_SHA_extensions\n \nreply",
      "Old Atoms were able to do that. N100 is way more powerful (better than Skylake at the same frequency).\n \nreply",
      "If you want a basic idea of an N100, it's essentially a single Alder Lake E-core cluster (4 E-cores) with one of the low tier iGPUs and a trimmed down memory controller.The presence of the iGPU means it /should/ handle video encoding surprisingly well for what it is.\n \nreply",
      "$60! That seems like a ridiculous bargain. Evidently I\u2019m not the only one who thinks that, because they are sold out. Not in love with the reported temps, but I would probably be willing to throttle the CPU significantly.\n \nreply",
      "Genuine question, but what's the use case for this? I do a ton of embedded compute, but it all requires extensive GIPO/PWM, etc.  Then I do a lot of desktop compute, but it all requires a GPU and a fair bit of horsepower.What's the use case for a SBC made to be embedded in a project box, but without extensive IO?\n \nreply",
      "Raspberry Pi sized computers are very popular as second systems for experimenting and as home servers on a budget. For many people, it\u2019s an easy and cheap way to get a Linux server running in their home, apartment, or dorm, without spending a lot of money or having a noisy, hot, large old server box.They do okay for a lot of tasks. They can\u2019t keep up with a $1000 workstation or server build, but it\u2019s a lot of horsepower for under $100 and around a dozen watts.\n \nreply",
      "Emphasis on the low power. It\u2019s just a computer, but one that is cheap and yet still capable of doing work.Host a blog. Home automation. Dedicated SNES emulator. Personal Minecraft server. DIY NAS controller. Maybe good enough to act as a TV media player. Anywhere you might want a bit of always on compute without paying a ton.\n \nreply"
    ],
    "link": "https://bret.dk/intel-n100-radxa-x4-first-thoughts/",
    "first_paragraph": "",
    "summary": "Title: Intel N100 Radxa X4: A Beacon of Hope for Hobbyists or Just Another Gadget?\n\nIn an era where tech enthusiasts get hyped over anything with a microchip, the Intel N100 Radxa X4 review on bret.dk emerges as the corner of the internet provisionally spared from total irrelevance. Visitors flood the comments section with their one-of-a-kind discoveries that a computer, indeed, computes! Witness the breathtaking insight as one commenter praises the N100 for its ability to \"perform fantastically\" - groundbreaking news if you've been living under a rock since the 90s. Meanwhile, others debate the philosophical implications of owning a power-efficient \"single Alder Lake E-core cluster\" capable of transcoding videos and maybe, just maybe, revolutionizing their next basement Minecraft rave. **Riveting** stuff for those who consider \u201cperf/watt\u201d ratios more exciting than watching paint dry. \ud83c\udf89\ud83c\udf89"
  },
  {
    "title": "Show HN: Semantic Grep \u2013 A Word2Vec-powered search tool (github.com/arunsupe)",
    "points": 146,
    "submitter": "arunsupe",
    "submit_time": "2024-07-27T18:02:58",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=41088273",
    "comments": [
      "That's totally clever and sound really useful. And it's one of those ideas where you go \"Why didn't I think of that\" when stumbling over the materials, word2vec in this case.\n \nreply",
      "> Why didn't I think of thatWell, Apple did experiment with embeddings for next word prediction on iOS in 2018 (apparently, they also used it for many other features)! https://machinelearning.apple.com/research/can-global-semant... / https://archive.is/1oCwr\n \nreply",
      "Very cool!Do I understand correctly that this works by splitting each line into words, and using the embedding for each word?I wonder whether it might be feasible to search by semantics of longer sequences of text, using some language model (like, one of the smaller ones, like GPT2-small or something?). Like, so that if you were searching for \u201cdie\u201d, then \u201ckick the bucket\u201d and \u201cbuy the farm\u201d, could also match somehow? Though, I\u2019m not sure what vector you would use to do the dot product with, when there is a sequence of tokens, each with associated key vectors for each head at each layer, rather than a single vector associated with a word..\nMaybe one of the encoder-decoder models rather than the decoder only models?Though, for things like grep, one probably wants things to be very fast and as lightweight as feasible, which I imagine is much more the case with word vectors (as you have here) than it would be using a whole transformer model to produce the vectors.Maybe if one wanted to catch words that aren\u2019t separated correctly, one could detect if the line isn\u2019t comprised of well-separated words, and if so, find all words that appear as a substring of that line? Though maybe that would be too slow?\n \nreply",
      "I wanna meet the person who greps die, kick the bucket and buy the farm lolAre models like mistral there yet in terms of token per second generation to run a grep over millions of files?\n \nreply",
      "Mistral has published large language models, not embedding models? sgrep uses Google's Word2Vec to generate embeddings of the corpus and perform similarity searches on it, given a user query.\n \nreply",
      "No I got that I asked because wouldn\u2019t embedding generated by fine tuned transformer based LLMs be more context aware? Idk much about the internals so apologies if this was a dumb thing to say\n \nreply",
      "This would be really useful if it could take a descriptive phrase or a compound phrase (like SQL 'select X and Y and Z') and match against the semantic cluster(s) that the query forms.  IMO that's the greatest failing of today's search engines -- they're all one hit wonders.\n \nreply",
      "very cool, led me to find https://www.cs.helsinki.fi/u/jjaakkol/sgrep.html and semgrep is taken so another symlink it is, w2vgrep?\n \nreply",
      "Really cool.  Often just want to fuzzy search for a word, and this would be useful.  Can it do filenames as well ? Or do I need to pipe something like LS first.\n \nreply",
      "I might have a work use case for which this would be perfect.Having no experience with word2vec, some reference performance numbers would be great. If I have one million PDF pages, how long is that going to take to encode? How long will it take to search? Is it CPU only or will I get a huge performance benefit if I have a GPU?\n \nreply"
    ],
    "link": "https://github.com/arunsupe/semantic-grep",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        grep for words with similar meaning to the query\n      sgrep is a command-line tool that performs semantic searches on text input using word embeddings. It's designed to find semantically similar matches to the query, going beyond simple string matching. The experience is designed to be similar to grep.Search for words similar to \"death\" in Hemingway's \"The Old Man and the Sea\" with context and line numbers:Output:\nThis command:The output will show matches with their similarity scores, highlighted words, context, and line numbers.Binary:From source (linux/osx):Basic usage:./sgrep [options]  [file]If no file is specified, sgrep reads from standard input.Example config.json:Contributions are welcome! Please feel free to submit a Pull Request.This project is licensed under the MIT License - see the LICENSE file for details.\n        gre",
    "summary": "At Hacker News, the techno-utopians wax poetic about \"Semantic Grep\" \u2013 a search tool so dazzling, it threatens the monopoly of dumpster-diving through 90s-style Ctrl+F functions. Marvel as comments swing from unexpected epiphanies (\"OMG, why didn\u2019t I figure this out during my three failed machine learning startups?\") to tech one-upmanship (\"Actually, CleverCorp implemented semantic word hunting in their smart toasters back in '17\"). Watch the crowd juggle tech jargon like a circus act, hypothesizing about grafting entire LLM models onto their greppy toy, all the while fretting whether \"grep for 'death'\" could accidentally summon a digital grim reaper. In this theatre of the absurd, every enterprising keyboard warrior is just one regex away from achieving Silicon Valley immortality\u2014or at least a cool GitHub repo to flaunt. \ud83d\udc53\ud83d\ude80"
  },
  {
    "title": "Tritone Substitutions (johncarlosbaez.wordpress.com)",
    "points": 56,
    "submitter": "chmaynard",
    "submit_time": "2024-07-27T19:52:34",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=41088895",
    "comments": [
      "It's a shame to describe the tritone sub for G7 as C# F G# B, when the proper way to spell it is either Db F Ab Cb or C# E# G# B. Of course, then you'd have to explain about enharmonic equivalence and how chords are usually spelled with every other note.\n \nreply",
      "The earliest tritone substitution I know of appears in Scarlatti K420https://www.youtube.com/watch?v=Nf3_NfuvK8YThere are two tritones in 7-limit just intonation (7/5 and 10/7) and therefore two possible tritone substitutions. Here they're played successivelyhttp://lumma.org/music/theory/demo/progs/TritoneProgressions...\n \nreply",
      "I didn't hear that spot as a tritone substitution, personally, but a sort of non-harmonic counterpoint move (\"passing tones\" or \"setup tones\" to 19th century theorists).More broadly, a lot of people like to point out wild 20th century chords in baroque music, but they really didn't think in terms of chords, and as such these pseudo-chords don't have the same function that modern versions of chords do.  In particular, Scarlatti was a prolific user of the partimento method of composition, which is a slightly of abstracted version of counterpoint, and his sonatas are pretty good examples of pieces written with this in mind.  The method revolves around intervals and movement between voices rather than chords.  It's normal for someone thinking in counterpoint to produce some very \"modern\" \"chords\" because that's a common consequence of following nothing but voice leading to produce a piece of music.https://en.wikipedia.org/wiki/PartimentoSee also Rick Beato mis-analyzing Bach's counterpoint as containing a very \"modern\" maj7#5 chord: https://www.youtube.com/watch?v=d1f_tzBx6ko&t=1s\n \nreply",
      "But JS Bach apparently did love those modern sounds, see BWV 542/I But indeed it doesn't make much sense to apply jazz theory on classical or early music.\n \nreply",
      "I've never quite understood that POV, although my piano teacher had it. Clearly she had another way of understanding it which I'm sure is more useful. I lack that training.Pick an example everyone knows: Bach's Prelude in C. I wrote in chord symbols over every bar of that, except for that one very weird bar near the end. It helped me a lot in memorizing it.\n \nreply",
      "IMO when you're playing music, everything you want to do is on the table. If you're going to make music theory and music history arguments, you should be sensitive to the theory and history you are arguing about.By the way, a 19th century functional harmonist would also find that prelude sort of odd. Not in terms of the chords themselves, but they don't always obey their usual functions.Also, many modern players and theorists reach toward Schenkerian analysis and its derivatives to sort of explain why music sounds the ways it does.  Unlike counterpoint and harmony, Schenkerian analysis is almost entirely descriptive, not prescriptive.  I have no idea what your teacher would have suggested.\n \nreply",
      "> IMO when you're playing music, everything you want to do is on the table. If you're going to make music theory and music history arguments, you should be sensitive to the theory and history you are arguing about.I don't even understand this paragraph. I'm not arguing.\n \nreply",
      "That wasn't directed to you, but rather toward your teacher and the OP.  The intent was that as a player, I think you should go ahead and use roman numerals or jazz theory or any other form of analysis that helps you think about things.  However, if you are publishing an analysis of a piece (which you did not do), you should be thinking differently than that.As someone with a significant background in historical performance, my books of Bach preludes are still full of Roman numerals because that is a really good way to \"compress\" information about what notes to play.\n \nreply",
      "OK. For sure I wouldn't publish that set of chords, since anyone could create it as a shorthand.I'm actually interested in other ways of analyzing it.\n \nreply",
      "See also BWV 903 and BWV 1079.Andras Schiff playing BWV 903 (there are some REALLY bad performances of this piece out there): https://www.youtube.com/watch?v=SNWOhm5iXxsBWV 1079 wasn't necessarily written with musical instruments proscribed, but here's a good French group's performance: https://www.youtube.com/watch?v=tfMQ-AYiuJw\n \nreply"
    ],
    "link": "https://johncarlosbaez.wordpress.com/2024/07/27/tritone-substitutions/",
    "first_paragraph": "A \u2018tritone substitution\u2019 is a popular trick for making your music sound more sophisticated.  I\u2019ll show you a couple of videos with lots of examples.  But since I\u2019m mathematician, let me start with the bare-bones basics.The fifth note of the major scale is called the dominant.   In the key of C it\u2019s G.A dominant seventh chord is a 4-note chord where you start at the dominant and go up the major scale skipping every other note.  In the key of C it\u2019s the notes in boldface here:G A B C D E FBelow I\u2019ve drawn blue edges from G to B, from B to D, and from D to F:Any dominant seventh chord has two notes that are opposite each other\u2014shown in orange here.   We say they\u2019re a tritone apart.A tritone is very dissonant, so the dominant seventh chord really wants to \u2018resolve\u2019 to something more sweet.   This tendency is a major driving force in classical music and jazz!   There\u2019s a lot more to say about it.But never mind.  What if we take my picture and rotate it 180 degrees?   Then we get a new chord",
    "summary": "**Tritone Substitutions: Because Regular Music Theory is Too Mainstream**\n\nIn his latest post on johncarlosbaez.wordpress.com, a mathematician decides to teach us barbaric fools how <i>tritone substitutions</i> make music sound fancy, as if graphics and diacritic-heavy music lingo weren\u2019t enough to give your brain an off-key workout. Commenters dive into a frenzy over the correct way to spell chords, because apparently, it's a cardinal sin to misname C# as Db, even in a sonic realm where no one cares. Meanwhile, a pedantic parade clashes over historical accuracy in music theory, because obviously Bach was all about that jazz, right? Stay tuned for next week when we use quantum physics to explain why your guitar is out of tune. \ud83c\udfb5\ud83e\udd2f"
  },
  {
    "title": "Managarm: Pragmatic microkernel-based OS with asynchronous I/O (github.com/managarm)",
    "points": 80,
    "submitter": "ksp-atlas",
    "submit_time": "2024-07-27T19:06:14",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=41088592",
    "comments": [
      "people always say that C++ is not a good fit for kernels, but so far this is the only language I know where small teams or individuals are regularly able to create non-trivial hobby OSes from scratch that go from zero to GUI:- Serenity (https://github.com/SerenityOS/serenity) - not really a small team, but it managed to get to GUI as pretty much a one-man-show- Skift (https://github.com/skift-org/skift)- hhu: https://github.com/hhuOS/hhuOS- MaxOS: https://github.com/maxtyson123/MaxOS- MorphiOS: https://github.com/syedtaqi95/morphiOS- Macaron: https://github.com/MacaronOS/Macaron- Ghost: https://github.com/maxdev1/ghostmost big ones in C don't manage to get to the GUI level, except toaruos:  https://github.com/klange/toaruos\n \nreply",
      "HelenOS[1] is in C and has a GUI. I don\u2019t know how many people participated over its (quite extensive) history.Axle[2] is a one-man project with a GUI that the author has been gradually transitioning from C to Rust.Among C++ projects, I think Essence[3] also merits a mention.[1] http://www.helenos.org/[2] https://github.com/codyd51/axle[3] https://gitlab.com/nakst/essence\n \nreply",
      "There is Redox written in rust. https://gitlab.redox-os.org/redox-os/redox\n \nreply",
      "I think C++ is especially good for a GUI.The two counter-examples I can think of with plain C:* GTK+, though honestly speaking I think quality has dipped over the decades where C++ equivalents have flourished.* Old school Win32 style. Counter to the bad reputation, I find it easy to be productive with in plain C once you adjust your mental model to its expectations. Though it's probably better from C++ than C, for a few convenience features to reduce boiler plate.\n \nreply",
      "Old Win32 style received less attention than it deserves, I think. It's an object system in its own right\u2014a Smalltalkish one, at that, with an (admittedly muddled) E-style separation of synchronous and asynchronous calls!\u2014but one rarely sees it mentioned in the same sentence as Objective-C, C++, and GObject/Vala. Part of the blame for that undoubtedly rests on Microsoft\u2019s incompetence at documenting concepts, but whatever the causes I\u2019d definitely like to see that corner of the object-system design space explored more, with or without GUIs.\n \nreply",
      "When win32 was dominant they didn't need to document it, people had the motivation to figure it out.Successive waves of Microsoft people then tried to make it easier to use or replace it entirely, which, they never did so with the same quality as the original.Unfortunately some of those misadventures became synonymous with building a windows UI.\n \nreply",
      "> Part of the blame for that undoubtedly rests on Microsoft\u2019s incompetence at documenting conceptsI mean Charles Petzold did that so successfully redoing it would be superfluous\n \nreply",
      "Kind of. He stops somewhat short of admitting that Win16/32 windows are objects and their graphical representation is mostly incidental. That\u2019s not a bad thing\u2014the book is introductory on many topics, in a good way, and just dropping such an idea somewhere in the beginning portions would be more confusing than helpful for the intended audience. That audience would almost certainly not be helped by the observation that they are dealing with a sort of Smalltalkish/Actorish system with badly bolted-on multithreading\u2014most of it wouldn\u2019t have knowm what that meant, at the time.Still, this is kind of a common theme. Perhaps \u201cyou had to have been there\u201d worked as an approach to documentation for the first ten to fifteen years, but afterwards any newcomer is just guaranteed to get lost.If you want to learn Win32, you need to read Petzold. If you\u2019re interested specifically in how the dialog manager works, you need to invent a time machine and read a series of blog posts Raymond Chen wrote in 2005[1]. If you want the particulars on message queueing, you need to invent a time machine and read the chapter about then in Raymond Chen\u2019s blogobook[2]. If you want to learn about STRICT and the very useful message cracker macros in WINDOWSX.H, first, you were probably reading Raymond Chen, because the official documentation is basically mum about it, but second, you need to track down that one KB article about porting to Win32 that accompanied one particular Windows 3.1-era Microsoft compiler[3].If you want to learn DCOM95-vintage COM, you need to read Box and Brockschmidt and that COM Programmer\u2019s Cookbook[4] thing that was somebody\u2019s own private initiative inside Microsoft and is buried somewhere in the technotes and then the COM Specification[5] will be accessible to you, and only after that will the MSDN specification make some sort of sense. If you want to learn the how or why of COM marshalling in particular, you will perhaps be helped by some of the above, but really you need to invent a time machine and read a series of blog posts Raymond Chen wrote in 2022[6]. Only then will the MSDN reference be even slightly helpful (and even then not that much over the IntelliSense hints).If you want to learn ActiveX ... I have no idea what you need to read! And that itself is indicative of a problem (took me five years to stumble upon Brockschmidt).If you want to learn MSMQ/MTS/COM+/whatever, you need to read that one book[7] that\u2019s still going to leave you with more questions than answers, and then maybe track down some MSJ articles from after COM+ was only a vague marketing term for something internal, but before .NET completely overtook all Microsoft communications channels. If you want to learn about using COM contexts, first, my condolences, second, AFAIK your only source for this Win2K-era, and I quote, \u201cbackdoor into the very low-level COM infrastructure\u201d is Raymond Chen\u2019s post from two decades later[8]. There\u2019s no motivating spec for any of this, even one as scarce on details as the later parts of the COM one.If you want to learn about WinRT internals, well, there are some blog posts random people on the Internet have written[9], and maybe you can spelunk some in the Win8-era legacy MSDN docs that are somewhat more explicit about what\u2019s happening. If you want to learn about WinRT\u2019s headline feature of \u201cmetadata-driven marshalling\u201d, fuck you, it\u2019s not explained anywhere, nor is an up-to-date MIDL grammar that would include the ways to adjust it a \u201cpriority\u201d for that team\u2014or maybe it\u2019s just that I don\u2019t have a time machine, but Raymond Chen is mortal too, and it\u2019s been over a decade.And it\u2019s all like that. (Eric Lippert copied some of the articles on Active Scripting / WSH from his now-deleted MSDN blogs, but not all of them. Michael Kaplan\u2019s blog, one of the best resources on Windows i18n, was speed-deleted from MSDN after he published a Vista leak, and the man himself died shortly afterwards, so for anything after that you\u2019re out of luck. Etc., etc. Need I say there\u2019s no type system spec for TypeScript?)Again, if you were there at the time and you subscribed to MSDN, until 2005 or so I think you would\u2019ve gotten basically all of the things I listed on the CDs, and more besides (Dr. GUI and Dr. International anyone?). But if you only joined in 1995 or 1998 or 2000, God help you. (WinRT happened after 2005, though, so the sum total of in-depth, under-the-hood narrative stuff about it is fuck all.) The references from that era are excellent, but as far as, again, narrative docs are concerned\u2014 C\u2019mon, guys, you had Ted Chiang at your disposal and that\u2019s what you managed?..(Then again, it probably had very little to do with the technical writers themselves and a lot to with the preposterously hectic development and a management culture that just did not prioritize this sort of thing. But still.)[1] http://web.archive.org/web/20231204102018/https://bytepointe... (wait, has bytepointer.com died? that would make me very sad...)[2] https://openlibrary.org/works/OL9256722W/The_old_new_thing[3] Nope, can\u2019t find it right now! Good thing Microsoft deleted most of the old KB articles from their website... \u2014an hour passes\u2014 Found it! Q83456: https://raw.githubusercontent.com/jeffpar/kbarchive/master/t... (thank goodness these were numbered).[4] https://learn.microsoft.com/en-us/previous-versions/ms809982...[5] What, were you expecting a microsoft.com link? Hahaha, nope! Just imagine you\u2019re listening to Rick Astley, I guess. Anyway, there are two versions in circulation (originally as DOC). The \u201cComponent Object Model specification\u201d, version 0.9, is dated 1995 and is easier to find, e.g.: https://groups.csail.mit.edu/medg/ftp/emjordan/COM/THE%20COM.... The \u201cCOM core technology specification\u201d, version 1.0, is dated 1998 and is, as far as I know, only available from this one Russian-language homepage, last updated 2004 (and you can certainly tell): https://thegercog.narod.ru/index.htm?u=https://thegercog.nar..., direct link: https://thegercog.narod.ru/Files/Docs/ds/com/com_spec.rar. A lot of the same material is in the DCOM Internet-Draft and the ActiveX Spec drafts on the Open Group website.[6] https://devblogs.microsoft.com/oldnewthing/20220615-00/?p=10...[7] https://thrysoee.dk/InsideCOM+/[8] https://devblogs.microsoft.com/oldnewthing/20191128-00/?p=10...[9] https://www.interact-sw.co.uk/iangblog/2011/09/25/native-win...\n \nreply",
      "Thanks for debunking my answer so comprehensively. Cannot disagree.\n \nreply",
      "I learned a bunch of these things largely on my own, but it probably helped that I was at MSFT for a few years.\n \nreply"
    ],
    "link": "https://github.com/managarm/managarm",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Pragmatic microkernel-based OS with fully asynchronous I/O\n       This is the main repository of managarm, a microkernel-based operating system.What is special about managarm? Some notable properties of managarm are:\n(i) managarm is based on a microkernel while common Desktop operating systems like Linux and Windows use monolithic kernels,\n(ii) managarm uses a completely asynchronous API for I/O\nand (iii) despite those internal differences, managarm provides good compatibility with Linux at the user space level.Aren't microkernels slow? Microkernels do have some performance disadvantages over monolithic kernels.\nmanagarm tries to mitigate some of those issues by providing good abstractions (at the driver and system call levels)\nthat allow efficient implementations of common user space functionality (like POSIX).Is this a Linux distr",
    "summary": "**Today in Hobby OS Fashion Week**: _Managarm_ struts its pragmatic microkernel down GitHub's runway, flaunting _asynchronous I/O_ like it's the new black. Commenters, meanwhile, transform a straightforward software development thread into a nostalgic '90s LAN party, reminiscing over their first GUI crushes and arguing over whose basement had the best C++ compiler. Whether it's a debate on the merits of C++ for kernel programming or an unrequested history lesson on Windows documentation failures, there's always a software historian ready to hijack the conversation for a trip down memory lane. Who knew kernel development could be both an engineering challenge *and* a bedtime story for aging techies? \ud83d\ude34\ud83d\udcbb\ud83d\udcdc"
  },
  {
    "title": "Roguecraft Devs on Developing for Amiga in 2024 (timeextension.com)",
    "points": 45,
    "submitter": "ibobev",
    "submit_time": "2024-07-27T20:35:40",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41089161",
    "comments": [
      "It's been a couple of years since my last deep-dive on Amiga development inside MacOS.  I never did find smooth dev workflow: compile inside the emulated environment, or cross-compile from macos?  Edit inside the emulated environment, or edit inside VS Studio?  etc.Has anyone found a slick and effective dev flow?\n \nreply",
      "If you want to have modern C++ (for instance), you basically have to cross-compile. If only using C or older g++, I'd compile inside the Amiga, I think.https://github.com/Slamy/m68k-elf-gcc - can generate bootable floppies!https://github.com/bebbo/amiga-gcc - modern (gcc-13.2) C and C++ for cross-compiling from Mac/Linux/Windows. It even supports the post-Motorola 68080 Natami VHDL CPU extensions.\n \nreply"
    ],
    "link": "https://www.timeextension.com/features/interview-its-easy-to-get-a-bit-over-ambitious-roguecraft-devs-on-developing-for-amiga-in-2024",
    "first_paragraph": "",
    "summary": "Roguecraft Devs unleash yet another scintillating discussion on the bleeding edge of technology by pondering the timeless question: how to best resurrect the dinosaur-Amiga for modern coding antics in 2024. Hobbyists across the digital multiverse convene to revel in the masochistic joy of cross-compiling and floppy disk alchemy, showcasing links like sacred relics of a bygone era. Our brave commenters, armed with GCC incantations and an undying affection for all things obsolete, traverse this arcane quest, seeking the holy grail of <i>\"a slick and effective dev flow.\"</i> As if development wasn't already an exercise in nostalgic futility, these enthusiasts sprinkle extra challenge by stubbornly clinging to their beloved, fossilized platforms. \ud83c\udf89\ud83c\udff0 Rearguard action or the height of irony? Only time - or perhaps timeextension.com - will tell."
  },
  {
    "title": "G\u00f6ttingen was one of the most productive centers of mathematics (theconversation.com)",
    "points": 122,
    "submitter": "marvinborner",
    "submit_time": "2024-07-27T16:08:26",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=41087429",
    "comments": [
      "Sadly, this article does not answer the question of why such a concentration of brilliance developed at G\u00f6ttingen. If we wanted to build a new G\u00f6ttingen, how would we do it? What factors allowed G\u00f6ttingen to exist? For most of a century, Germany was leading in most scientific and academic fields, but what allowed this? When we think of the Golden Age of physics we are thinking of a cultural event that had its center in Germany, but why? And why has Germany been so dull and flat ever since? Clearly, building a liberal democracy is not enough to ensure such a cultural event. Much of Germany was liberal but non-democratic during its golden age, as other places were, but what made Germany special at this time?\n \nreply",
      "this sounds like a good explanation:> University of G\u00f6ttingen had more academic freedom than generations past. They were promised intellectual autonomy and freedom from close religious supervision. Instead, they were recruited solely to advance knowledge and carry out original research. The education of students was also more egalitarian than it had been previously in Europe, as both rich and poor were admitted and trained.\n \nreply",
      "After working at several universities, and interacting with lots of institutions on both sides of the pond, I think this freedom issue is also what makes American Academia more successful than European Academia these days.In Europe, academic freedom is limited because the structure we have resembles a very wide pyramid, with some minor differences across fields and countries. Junior professorships are more rare and more difficult to get into. The result is always the same, a full professor that controls his field locally and lots of expendable badly-paid postdocs working for him. Access to funding is also much more limited, which in turn restricts the capacity of said postdocs to pursue their own ideas, even while working under the umbrella of the professor.In the US, tenure-track assistant professorships are much more common and requirements to apply are more flexible. Seed grants for junior faculty members are also common and not too hard to obtain. The result is a lot more freedom to explore. Basically, it is the same issue as with technology. EU suffers from over-regulation and control by some rent-seeking elites.\n \nreply",
      "It's not clear whether it is desirable to build a new G\u00f6ttingen. Communications and travel may have largely obviated the advantages of assembling brilliant minds in one place, other than temporarily for conferences and visits.\"Monumental Proof Settles Geometric Langlands Conjecture\"\nhttps://www.quantamagazine.org/monumental-proof-settles-geom...\n is an interesting article that describes the multi-year effort to obtain this important result. The final proof has nine authors affiliated with seven institutions: Denis Gaitsgory, Max Planck Institute; Sam Raskin and Joakim F\u00e6rgeman, Yale University; Dima Arinkin, University of Wisconsin; Nick Rozenblyum, University of Toronto; Dario Beraldo, University College London; Lin Chen, Tsinghua University; Justin Campbell and Kevin Lin, University of Chicago.\n \nreply",
      "> Communications and travel may have largely obviated the advantages of assembling brilliant minds in one place, other than temporarily for conferences and visits.Lmao. Only someone who has never been a part of a high performance team with excellent mentors available in person throughout the day, can possibly believe this.Alternatively, try this sentence: \"Communications and travel may have largely obviated the advantages of a married couple living together in one place to raise a family.\"\n \nreply",
      "You are assuming a causal relation direct link between underlying factors and outcomes. It may well be that if Gottingen didn't exist some other place would have been the epicenter of a scientific revolution that was ripe to happen. One would then try to figure out what made that place special.\n \nreply",
      "But if some other place had been the epicenter of a scientific revolution would Gottingen have prevented that? Wouldn't we have just seen people in two different areas discovering things independently? We could ask, why only Gottingen?\n \nreply",
      "I think you're mixing the question of what creates great mathematics department and what makes a region generally interesting (plus the article actually answers all those questions well as other commenters note).Germany has many great mathematicians at present. Just by expanding population and budgets, it probably has more great mathematicians than in the G\u00f6ttingen days. These mathematicians are not as famous as the G\u00f6ttingeners of the 1920s, however, fundamentally because earlier mathematicians laid the foundation of the field and later researchers basically have built on those foundations and can't claim the same glory.As to post-war Germany being boring - I'd assume but it seem neither here nor there.\n \nreply",
      "I'll venture a couple guesses.1) Humboldt's university reforms creating graduate education and research universities. This doesn't explain the seed of German intellectual activity as it was a relatively late development, but it does explain the institutionalization of German intellectual activity. As to the seed...2) German was the language with the most literate speakers in Europe during the Enlightenment. For a few centuries after the Reformation, Protestant regions did have higher rates of literacy than Catholic or Orthodox regions, and Germans were the most numerous of the Protestant cultural-linguistic groups.\n \nreply",
      "Sources?\n \nreply"
    ],
    "link": "https://theconversation.com/how-one-german-city-developed-and-then-lost-generations-of-math-geniuses-106750",
    "first_paragraph": "\n      Ph.D. student in Applied Mathematics, University of Colorado Boulder\n    David Gunderman does not work for, consult, own shares in or receive funding from any company or organization that would benefit from this article, and has disclosed no relevant affiliations beyond their academic appointment.University of Colorado provides funding as a member of The Conversation US.View all partnersThere are two things that connect the names Gauss, Riemann, Hilbert and Noether. One is their outstanding breadth of contributions to the field of mathematics. The other is that each was a professor at the same university in G\u00f6ttingen, Germany. Although relatively unknown today, G\u00f6ttingen, a small German university town, was for a time one of the most productive centers of mathematics in history. G\u00f6ttingen\u2019s rise to mathematical primacy occurred over generations, but its fall took less than a decade when its stars were pushed abroad by the advent of National Socialism, the ideology of the Nazi Pa",
    "summary": "**Why G\u00f6ttingen was a Big Deal: A Roast of Math History**\n\nIn today's installment of \"old centers of smarty pants,\" we find out that G\u00f6ttingen, now just a dot on your outdated European map, was once a math powerhouse\u2014surprise! \ud83c\udf89 The academic equivalent of a one-hit wonder, G\u00f6ttingen gets its fifteen minutes of fame solely because some big names like Gauss and Riemann hung their hats there. Article readers, in a stunning display of missed points, wax poetic about recreating this ancient geek mecca, blissfully ignoring the article's lead about \u2018National Socialism\u2019 doing the nerdy utopia in. Meanwhile, commenters engage in delightful mental gymnastics, debating whether today\u2019s tech makes physical proximity as obsolete as their understanding of the subject. Because who needs historical context or complete answers when you can focus on structuring the perfect virtual faculty lounge? \ud83d\ude09"
  },
  {
    "title": "A User\u2019s Guide to Statistical Inference and Regression (mattblackwell.github.io)",
    "points": 31,
    "submitter": "sebg",
    "submit_time": "2024-07-25T19:56:13",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41072691",
    "comments": [
      "Man I love this first paragraph. Love it.\u201cQuantitative analysis of social data has an alluring exactness to it. It allows us to estimate the average number of minutes of YouTube videos watched to the millisecond, and in doing so it gives us the aura of true scientists. But the advantage of quantitative analyses lies not in the ability to derive precise three-decimal point estimates; rather, quantitative methods shine because they allow us to communicate methodological goals, assumptions, and results in a (hopefully) common, compact, and precise mathematical language. It is this language that helps clarify exactly what researchers are doing with their data and why.\u201dA lot of industry \u201cdata science\u201d is moronic, which is to say not clear about assumptions or about what is and isn\u2019t possible with the estimates.  Leading case: Models are treated as causal when they are not.  Antidotes to that kind of thinking are great.  Hopefully this can be one of them.  I\u2019ll keep looking at it.\n \nreply",
      "If you want to take this a step further, quantitative methods are about efficient data reduction. As part of this data reduction, the model\u2019s assumptions and mathematical form take center stage in describing how you got to your \u201cnumber\u201d.This is different from qualitative analysis because the data reduction is done \u201cby hand\u201d by the researcher.The difference between the \u201cautomatic\u201d, model-based data reduction in quantitative research and the \u201csubjective\u201d reduction in qualitative research is then amplified when people say that quant is more objective than qual analysis. The discussion, instead, should be about the quality of the work and whether the final conclusions are warranted by the methods instead of the method itself.\n \nreply",
      "good one\n \nreply"
    ],
    "link": "https://mattblackwell.github.io/gov2002-book/",
    "first_paragraph": "Matthew Blackwell   This book, like many before it, will try to teach you statistics. The field of statistics describes how we learn about the world using quantitative data. In the social sciences, an increasing share of empirical studies use statistical methods to provide evidence for or against conceptual arguments. And, while it is possible to conduct quantitative research without understanding statistics at an intuitive level, it is not a good idea. Quantitative research involves a host of choices about the model to use, variables to include, tuning parameters to set, assumptions to make, and so on. Without a deep understanding of statistics, you may find these choices bewildering and confusing, and you may simply (and possibly erroneously) yield to the default settings of your statistical software.The goal of this book is to give you the foundation to make methodological choices for your specific application with knowledge and with confidence. The material is intended for first-ye",
    "summary": "**A User\u2019s Guide To Not Blaming Your Tools: A Love Story With Numbers**\n\nAh, statistics, the beloved sanctuary for those who cherish the illusion of precision in the murky waters of social science. Today, Matthew Blackwell embarks on a quixotic quest to teach the magic of numbers to first-year hopefuls who believe understanding p-values might actually make a difference in the grand cosmic game of academic \"guess who.\" Commenters swoon with relief, applauding Blackwell for barricading them against the dire threat of becoming \"moronic industry data scientists.\" Because clearly, any fool knows the real charm of number-crunching isn\u2019t the decimal dust it leaves behind, but simply ensuring everyone knows you\u2019ve played the game with your <em>big, impressive, statistical words</em>. \ud83c\udfb2\ud83d\udcab"
  },
  {
    "title": "Show HN: Preprocessor I've been working 4 years now (npmjs.com)",
    "points": 44,
    "submitter": "mopires",
    "submit_time": "2024-07-23T17:14:12",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41048473",
    "comments": [
      "I suggest putting a code sample of a page written in Pretty Markup that shows off its features in the README. The documentation is currently somewhat devoid of information about the language itself.\n \nreply",
      "I second this, I have basically no feeling for it other than zooming in a the README gif\n \nreply",
      "Which is super slow. The first 10 seconds or so are just slowly traversing an auto complete menu.\n \nreply",
      "I\u2019ve used something similar quite a long time ago called Jade. Seems to be renamed to Pug. Here\u2019s a nice writeup with some examples (not mine, found the webpage missing examples): https://www.sitepoint.com/jade-tutorial-for-beginners/\n \nreply",
      "Pug syntax is whitespace-sensitive though, while this doesn't seem to  be, it has closing tags which I prefer.Also Pug is more of a templating engine, while this doesn't appear to have any interpolation / templating logic stuff.\n \nreply",
      "Overall, it's much less noisy than pug, just by removing the parentheses and commas.  But if the objective of this kind of markup is trying to minimize visual noise, removing redundant closing tags (which have inconsistent rules) would be an improvement.The shorthand for classes/IDs seems like a good idea too, if there's a way to do it that improves readability (and seems less magical to the unfamiliar coder)\n \nreply",
      "Even has highlighting in vscode, and there's a plugin for pugjs snippets.\n \nreply",
      "What is the difference between this and Haml or slim?\n \nreply",
      "If you use indentation for nesting, the closing tags are superfluous. That\u2019s just one of the reasons so many html/xml template langs have chosen that format.\n \nreply",
      "I came here to say this. Get rid of those closing tags.\n \nreply"
    ],
    "link": "https://www.npmjs.com/package/pretty-markup",
    "first_paragraph": "Imagine crafting elegant, semantic HTML structures without the clutter of angle brackets (really human-friendly).  Pretty Markup, a revolutionary preprocessor like Sass for CSS or TypeScript for JavaScript, Pretty Markup takes HTML to the next level.To use the pm command, install it globally. Or, use npx pmWe welcome contributions! Please see our CONTRIBUTING.md for details on how you can help improve the project.Report bugs or improvements at https://github.com/mopires/pretty-markup/issuesThis project is licensed under the MIT License.npm i pretty-markupGitgithub.com/mopires/pretty-markupgithub.com/mopires/pretty-markup#readme2041.0.13MIT39.3 kB20a day ago",
    "summary": "**Today on Hacker News: Another Day, Another Preprocessor** - A valiant Hacker News warrior unveils \"Pretty Markup,\" the latest attempt to save the world from the horrific tyranny of HTML angle brackets. After slaving away for four Earth years and crafting what can only be described as Sass for HTML, our hero desperately pleads for GitHub stars and npm installs. The commenters, ravenous for anything that mimics the late 2010s Tycoon-era coding shortcuts, dance around the actual usability of the tool while reminiscing about Jade... sorry, Pug... or was it Haml? Meanwhile, the README, devoid of examples but rich in navigation gifs, leaves potential users as lost as a JavaScript coder in a typescript conference, marveling at the slow-motion autocomplete feature that\u2019s as intuitive as a drunk UI/UX designer."
  },
  {
    "title": "The secret of Minecraft (2014) (medium.com/message)",
    "points": 86,
    "submitter": "prawn",
    "submit_time": "2024-07-24T20:26:00",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=41061646",
    "comments": [
      "xxx"
    ],
    "link": "https://medium.com/message/the-secret-of-minecraft-97dfacb05a3c",
    "first_paragraph": "",
    "summary": "In an attempt to shake the very foundations of journalism, a recent piece on Medium.com confuses explaining Minecraft with unveiling the lost city of Atlantis. The writer delves deep into the \"secret\" of pixels and crafting, illuminating exactly zero readers with revelations such as \"water is wet\" and \"the sky is often blue.\" The comment section, a wretched hive of misunderstood sarcasm and misplaced nostalgia, serves as a support group for those traumatized by the complexity of virtual landscaping. Surely, the future historians will point to this as the moment civilization peaked. \ud83d\ude44"
  },
  {
    "title": "Plan 9 Is a Uniquely Complete Operating System (posixcafe.org)",
    "points": 18,
    "submitter": "moody__",
    "submit_time": "2024-07-27T23:52:32",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41090222",
    "comments": [
      "cache cause hugged:https://web.archive.org/web/20240728004832/https://posixcafe...\n \nreply",
      "I've played with Plan9 several times, but never used it seriously.  The aesthetics that puts me off. Would have been great if they had taken guidance from BeOS / Haiku-OS for the look and feel. Heck, even Windows 95 would have been an improvement.\n \nreply",
      "Not an expert in OS development whatsoever but I do know that it's not intended for common usage, so how its UI looks is not something devs would take much care of.Though I do know that it puts some strong emphasis on mouse usage, something that for someone that grew to use the keyboard a lot like me (ironically, as a graphic designer) seems to be really awkward, to say the less. Its strengths seem to be its overlaying concepts and that it intended to be \"the next gen Unix\" - alas it won't take over for a myriad of reasons, and some would argue Unix-es have already borrowed some of its concepts for themselves.\n \nreply",
      "That would have been difficult since Plan 9 predates each of those other systems. Also Plan 9 took place in Bell Labs as a research project, was based on their own UI research, and was not intended to be a commercially familiar UI. There are interesting ideas in the write ups about the UI that could be applied in nearly any UI today.\n \nreply"
    ],
    "link": "https://posixcafe.org/blogs/2024/07/27/0/",
    "first_paragraph": "A large contributor to the \"feel\" of an Operating System comes from the software it chooses to include by default. There are entire linux distributions that differentiate themselves just based on the default configured software. There is room for so many options of base software because there are in general many different options to pick. Linux being just a kernel itself specifically creates an environment which encourages this (to some extent). This is both a blessing and a curse, for people wanting to write software targeting linux there now is some matrix of options they must test under if they want it to work with all the various software choices. BSD systems, unlike Linux, tend to include more than just a kernel by default, generally including some \"blessed\" c library, c compiler, libraries and programs. This makes targeting the system a bit easier, in the sense that you can assume there is a larger set of software on a BSD machine than you could with some system that uses a Linux",
    "summary": "Title: The Curious Case of Plan 9: Revolution in Plastic Bubble Wrap\n\nImagine an article from posixcafe.org that enthusiastically claims Plan 9 could potentially be your main OS because, well, it throws in everything including the kitchen sink by default. That\u2019s right: forget simple kernels or optional add-ons; we're in the land of \u00fcber-completeness! Meanwhile, web historians and hobbyists in the comments wax poetic about UI aesthetics like it\u2019s a fashion show, ignoring the OS\u2019s actual tech prowess. One spirited soul, escaping nostalgia for a bygone GUI era, doggedly insists it was never about looking pretty but revolutionizing systems\u2014a concept they assure us is still waiting in the wings to change the world, any day now. Isn't it adorable when tech enthusiasts miss the forest for the trees? Let's all stare earnestly at our mouse cursors in solidarity. \ud83d\uddb1\ufe0f\ud83d\ude0c"
  },
  {
    "title": "An Interview with Robert Caro and Kurt Vonnegut (1999) (robertcaro.org)",
    "points": 46,
    "submitter": "cocacola1",
    "submit_time": "2024-07-27T18:10:31",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41088314",
    "comments": [
      "> Well, you stand outside a society and a culture and realize that it is an invention and that you can improve it. Well, I like the American culture, such as it is, but let \u2018s get rid of the fucking guns. \u2014KVSo, it's relatively easy to find out that the US currently has about ~120 civilian firearms for every 100 people, but how does that number compare with whatever it was in 1999, when Vonnegut said the above?\n \nreply",
      "I highly recommend \u201cWorking\u201d by Robert Caro, his latest book.It\u2019s an excellent book to start with if you want to get an exposure to his way of working and his thinking.\n \nreply",
      "Agreed. It's a short read that demonstrates his writing skill, his methods, and his goal of explaining how political power is acquired and used. It inspired me to start on the LBJ biography.\n \nreply",
      "I second the recommendation. Can easily be read in a single sitting.\n \nreply",
      "Two of Caro's books remain in my favorites today: The Power Broker; and Master of the Senate. The concept of political power, mentioned in the conversation, is fully limned out in both of them. Worth reading by anyone with an interest in how the real world works. Unfortunately, Vonnegut, I never quite got. YMMV.\n \nreply",
      "The podcast 99% Invisible is doing a series of monthly episodes on The Power Broker. I don\u2019t live in NY and I don\u2019t pretend to really understand NY, but it\u2019s so interesting to listen to the hosts as they work their way through Caro\u2019s massive book. I really enjoy it and just wish the episodes were more frequent than once a month.\n \nreply",
      "> The Power BrokerThey really need to publish this in ebook form. It's so hard to read as a real book because of the size, and the only other way is audiobook.\n \nreply",
      "(Meaning 2 of \"limn\" is \"to outline in clear sharp detail\", but as it is not Meaning 1,this is fine.)\n \nreply",
      "I'm a fan of both Caro and Vonnegut, prefer some of his novels over others. Cat's Cradle is my favorite.\n \nreply",
      "Player Piano and Sirens of Titan were the options when I was in high school. I can't remember which I read first but I liked it so much I begged to borrow a copy and read the other. I've never agreed with a lot of his viewpoints, and Vonnegut was (like all of us) a flawed human being, but his writing transcended a lot of that, which is somewhat odd because it's so incredibly personal. That contradiction probably says more about me than him.\n \nreply"
    ],
    "link": "https://www.robertcaro.org/post/an-interview-with-robert-caro-and-kurt-vonnegut",
    "first_paragraph": "ROBERT A. CAROHOMEABOUTBOOKSARCHIVEARTICLES & INTERVIEWSPROFILESMoreReprinted with permission from HAMPTON SHORTS; Fiction Plus from the Hamptons and the east end; volume IV 1999. Kurt greeted us in his beautiful 19th century house and in his bare feet (of which more later). As the interview progressed it grew sort of naturally into a dialogue; and, as it moved along, neither Barbara Stone nor I could help sticking our noses and our questions in; which is in our tradition at round table interviews.And, during a break in the proceedings, Barbara persuaded Bob Caro to remove his shoes. Which is why you have before you a photo the two very distinguished \u201cbarefoot boys with cheeks of tan.\u201d \u2014Daniel SternKURT VONNEGUT\nI\u2019ve never written a biography:-I\u2019ve never been that responsible a writer-and you, Bob, have never written a novel. Are we in the same trade?ROBERT CARO\nWell, if we are we\u2019re certainly coming at it from opposite directions. My books are very long, and yours are-VONNEGUT\n-minima",
    "summary": "In a forgotten corner of the internet, two literary giants play footsie in history's most riveting interview about absolutely nothing. Watch in *bafflement* as Robert Caro and Kurt Vonnegut, two experts in their own irrelevance, navigate the treacherous waters of a dialogue that leads to\u2026the great shoeless revelation! \ud83e\uddb6 Meanwhile, the echo chamber of commenters vibrates with the profundity of discovering that books can be heavy and Vonnegut dislikes guns. Each comment orbits closer to a black hole of missed irony, celebrating their escape from the gravity of depth. \ud83c\udf00"
  },
  {
    "title": "Apple has reached its first-ever union contract with store employees in Maryland (apnews.com)",
    "points": 70,
    "submitter": "heavyset_go",
    "submit_time": "2024-07-27T21:46:51",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41089558",
    "comments": [
      "xxx"
    ],
    "link": "https://apnews.com/article/apple-union-contract-maryland-store-f9884d978bf3129c37726dd7978392a5",
    "first_paragraph": "",
    "summary": "In a stunning turn of events, a corporation worth trillions has finally agreed to throw a few extra crumbs at the serfs who sell its shiny overpriced rectangles. The historic \"union contract\" in Maryland is hailed as a victory for employees, who can now afford an additional half an Apple stand per month. Comment sections are ablaze with part-time corporate apologists and people who've just learned the word \"unionize,\" debating whether this will ruin their chances of overpaying for a phone assembled by someone making considerably less. \ud83c\udf4e\ud83d\udcb8"
  },
  {
    "title": "Oscar Zariski  was one of the founders of modern algebraic geometry (boogiemath.org)",
    "points": 154,
    "submitter": "boogiemath",
    "submit_time": "2024-07-27T12:12:18",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=41086060",
    "comments": [
      "For whomever might be interested in anectodes about mathematicians' personal lives:My girlfriend's family was related to https://planetmath.org/kallevaisala and she told me this story which was part of the family lore.  The family and friends were having some kind of get-together celebration maybe a wedding or so and prof. Vaisala's wife had bought him a brand new suit to look good for the occasion.During the party they were playing croquet in the garden and prof. Vaisala got really into the game, but had the realization that suit-pants may not be the best for playing croquet. He could have stuffed the end of his pant-legs into his socks but that didn't really work, maybe socks were too tight and pants too big. So, he found a pair of scissors somewhere, and cut his pant-legs short. His wife started crying. She didn't really appreciate the genius of mathematicians.\n \nreply",
      "Thank you for sharing this story! The story brought a smile on my face. Needed it today.\n \nreply",
      "Thanks\n \nreply",
      "Reminds me of the story about Weiner, who forgot he moved.Apparently a true story, but the version where he also didn\u2019t recognize his daughter (waiting for him at his previous home to show him to the new one) was an embellishment; at his funeral, his daughter said \u201cdad never forgot who his children were\u201d.\n \nreply",
      "I think such anecdotes and concepts reflect the complexity of human nature\n \nreply",
      "I talked to one of Zariski's students about this... He mention to me that the article said he studied \u201dreal\u201d algebraic geometry, which is a different subject \u2014he studied \u201ccomplex\u201d algebraic geometry as well as algebraic geometry without a limiting adjective.\n \nreply",
      "These anecdotes not only humanize these brilliant minds but also offer a humorous and endearing look at the quirks that often accompany such intense intellectual focus.\n \nreply",
      "Nice little story, the bride was not upset.  But a interesting read.\n \nreply",
      "> On the day he and his fianc\u00e9e Yole were getting married, with Yole already dressed in white and veiled and the rabbi standing by, the bridegroom was nowhere to be found. It turned out he was working on a mathematical problem. Luckily, Yole was neither angry nor surprised; she was amused. Ha! I need to tell this to my wife.Fellas and ladies,  get yourself a spouse who understands when you're late to your own wedding because you are inspired by your passions.\n \nreply",
      "Historical footnote:'What also surprised me in the biography was the striking difference between Jews in Italy and in Poland. [...] Leopold Infeld\u2019s autobiography [...] describes the Jewish ghettos in Poland as being almost completely isolated from the general population. [...] She was utterly surprised when she first saw the Jewish quarter in Warsaw, remarking: \u201cThe Jews in side curls and kaftans made me feel that I was living in two different nations.'I wonder if she was failing to distinguish between various kinds of Jews. Compare the majority of American Jews today, and the Hasidic Jews of Brooklyn, for example. This, too, was the case in Poland, home to the vast majority of the world's Jews at the time. On the one hand, there were a number of assimilated Jews and Poles of Jewish ancestry (like Tarski, Brzechwa Steinhaus, and so on). On the other, there were plenty of religious Jews of a more orthodox strain. And given that 1/3 of the population of Warsaw was Jewish, it would be difficult to imagine otherwise.\n \nreply"
    ],
    "link": "https://boogiemath.org/meta/meta-9.html",
    "first_paragraph": "Random I am always excited when I stumble upon a biography of a mathematician I wasn\u2019t previously aware of. It\u2019s strange (or perhaps not, given we\u2019re talking about mathematics) how many brilliant minds in the field lack the biographical treatment they deserve. Consider just a few luminaries from the first half of the 20th century:\nAndr\u00e9 Weil  (opens new window),\nHermann Weyl  (opens new window),\nCarl Ludwig Siegel  (opens new window),\nEmil Artin  (opens new window),\nEdmund Landau  (opens new window),\nHelmut Hasse  (opens new window).For physicists, it\u2019s a bit different. I think they are much better covered.\nThe reason might be that their work is more directly connected to everyday life. Just think of nuclear energy\nor the theory of relativity, which is crucial for\nGPS  (opens new window) to work properly.So, recently I came across the\nbiography of Oscar Zariski  (opens new window).\nZariski (1899-1986) was one of the founders of modern algebraic geometry.My wish is that one day I will b",
    "summary": "**Algebraic Geometry: Not As Sexy As Nuclear Physics?**\n\nIn an exciting twist of fate that could only happen on <em>boogiemath.org</em>, we encountered a biography of Oscar Zariski, one of the countless mathematicians who apparently changed the world while wearing name tags because nobody knows who they are. The commentary section blossoms with readers tripping over themselves to share equally sleep-inducing anecdotes about other mathematicians, each story desperately clutching at some shred of human relatability. From tearing pants at a garden party to missing your own wedding because math just can\u2019t solve itself, it's clear our heroes of the abacus lead lives that are <em>just</em> on the edge of blockbuster material. Brace yourselves, dear readers, as your guide to algebraic geometry is also an unofficial pajama party historian. \ud83d\udc56\u2702\ufe0f\ud83c\udf89"
  },
  {
    "title": "Learning about PCI-e: Driver and DMA (davidv.dev)",
    "points": 148,
    "submitter": "todsacerdoti",
    "submit_time": "2024-07-27T10:55:43",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41085713",
    "comments": [
      "The end goal in this series is to use an FPGA to build a display adapter, I've gotten a Tang Mega 138k [0] to start the process but there is not a lot of documentation, so it is taking a whileIf you got recommendations for other (cheap) FPGA boards with PCI-e hard IP, do let me know.[0]: https://wiki.sipeed.com/hardware/en/tang/tang-mega-138k/mega...\n \nreply",
      "Now I'm recalling, there are also cheap ready PCIe FPGA based products but for video recording:- Spartan 6 https://www.blackmagicdesign.com/products/decklink/techspecs...- Artix https://www.blackmagicdesign.com/products/decklink/techspecs...- Artix https://www.blackmagicdesign.com/products/decklink/techspecs...- Artix https://www.blackmagicdesign.com/products/decklink/techspecs...\n \nreply",
      "These seem to be ready made products opposed to devkits. Can the FPGAs be easily reprogrammed?\n \nreply",
      "FPGAs usually need their bitstream (analogous to firmware) loaded after power-on, so either there is a flash chip on the device that contains it, or it is loaded over the PCI bus from the host machine via a software driver. Either way you'll likely need to reverse-engineer and modify the firmware and host-side device driver. There are often better choices, such as dev boards, to play around with FPGAs.\n \nreply",
      "I would definitely use Xilinx over anything else here - Vivado isn't \"great\" by any pro-SWE's standard of tooling, but is absolutely best-in-class for FPGA development and implementation.The Xilinx PCIe device path is pretty well-trodden.\n \nreply",
      "Any dev kit you can buy in the low hundreds? I thought the UltraScale was in the low _thousands_\n \nreply",
      "Do you need UltraScale(+)? The Tang Mega 138k has way fewer LUTs than most US+ chips, it's a completely different class of FPGA.You can purchase a SQRL FK33 (VU33P on PCIE cards) for $250 used in the Dream escrow Discord. Here's one on eBay for $400 (a little steep) - this is the cheapest you will get into UltraScale+: https://www.ebay.com/itm/387229340513 This is also the cheapest way to obtain 8GB of HBM, which you will want for a GPU eventually.For $1000ish, you can get a C1100 (VU35P, 2x the area of VU33P, 8GB HBM) - https://www.ebay.com/itm/186414684753 - these do not require a Vivado license.For $600-1300 you can get VCU1525 (VU9P - no HBM) boards used: https://www.ebay.com/itm/326206486963For new stuff, you could get 7 Series Kintex devboards from China: https://www.aliexpress.us/item/3256805175295035.html\n \nreply",
      "Screamer PCIe Squirrel for 159 Euro (w/o tax) using Xilinx Artix XC7A35T (according photo). But it has only one high-speed external interface: USB 3.1 Gen 1.https://shop.lambdaconcept.com/home/50-screamer-pcie-squirre...Litefury, Xilinx Artix FPGA kit in \"NVMe SSD\" form factor (2280 Key M) for 102 Euro using Xilinx XC7A100T. It has only few external high-speed LVDS I/O.https://rhsresearch.com/collections/rhs-public/products/lite...\n \nreply",
      "The Litefury/Nitefury/Acorn design has enough I/O for an HDMI output. I've designed a little board with a buffer:https://github.com/mng2/AcornHDMIEven with the fastest speed grade Artix, 1080p output is technically out of spec, but it seems to work OK.As you might guess I had/have my own ambitions of making a video card. The software side has been a source of dread for me, but with OP's tutorials I may have enough guidance to get back to it.\n \nreply",
      "The screamer looks interesting, using Displayport Alt mode could work!\n \nreply"
    ],
    "link": "https://blog.davidv.dev/posts/pcie-driver-dma/",
    "first_paragraph": "In the previous entry we covered the implementation of a trivial PCI-e device, which allowed us to read and write to it, 32 bits at a time, \nby relying on manual peek/poke with a hardcoded address (0xfe000000) which came from copy-pasting the address of BAR0 from lspci.To get this address programmatically, we need to ask the PCI subsystem for the details of the memory mapping for this device.First, we need to make a struct pci_driver, which only requires two fields: a table of supported devices, and a probe function.The table of supported devices is an array of the pairs of device/vendor IDs which this driver supports:The probe function (which is only called if the device/vendor IDs match), needs to return 0 if it takes ownership of the device.We need to update the driver's state to hold a reference to the device's memory regionWithin the probe function, we can enable the device and store a reference to the pci_dev:Now, if we call pci_register_driver during module_init, we can see the ",
    "summary": "**PCI-e Pantomimes and FPGA Fanatics: A Tale of Trial and Tribulation**\n\nIn a *bold* journey to nowhere, a hopeful tech enthusiast dives into the murky waters of PCI-e drivers and DMA with the enthusiasm of a squirrel chasing a nut on a freeway. Readers are subjected to a blow-by-blow account of peeks, pokes, and probe functions, all explained with the excitement of watching paint dry. Meanwhile, in the comments, a motley crew of aspiring engineers and budget balancers wax lyrical about FPGA boards as if they're trading Pok\u00e9mon cards, each suggestion more niche than the last. Heaven help the brave souls thinking \"cheap\" and \"FPGA\" belong in the same sentence. \ud83e\udd16\ud83d\udcb8"
  },
  {
    "title": "How Clang compiles a function (2018) (regehr.org)",
    "points": 29,
    "submitter": "ibobev",
    "submit_time": "2024-07-26T23:10:44",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41083140",
    "comments": [
      "Very interesting to see that Clang basically always produces very bad and unoptimized LLVM IR code and leaves it to LLVM to clean it all up. That said, it's not entirely true that Clang avoid doing any optimizations -- it does indeed produce slightly different LLVM IR for -O0 and -O3.\n \nreply",
      "Discussed at the time:How Clang Compiles a Function - https://news.ycombinator.com/item?id=17405594 - June 2018 (16 comments)\n \nreply"
    ],
    "link": "https://blog.regehr.org/archives/1605",
    "first_paragraph": "I\u2019ve been planning on writing a post about how LLVM optimizes a function, but it seems necessary to first write about how Clang translates C or C++ into LLVM. This is going to be fairly high-level:We\u2019ll use this small function that I borrowed from these excellent lecture notes on loop optimizations:Since Clang doesn\u2019t do any optimization, and since LLVM IR was initially designed as a target for C and C++, the translation is going to be relatively easy. I\u2019ll use Clang 6.0.1 (or something near it, since it hasn\u2019t quite been released yet) on x86-64. The command line is:In other words: compile the file is_sorted.cpp as C++ and then tell the rest of the LLVM toolchain: don\u2019t optimize, emit assembly, but no actually emit textual LLVM IR instead. Textual IR is bulky and not particularly fast to print or parse; the binary \u201cbitcode\u201d format is always preferred when a human isn\u2019t in the loop. The full IR file is here, we\u2019ll be looking at it in parts.Starting at the top of the file we have:Any tex",
    "summary": "**How Clang Compiles a Function \u2013 A Love Story Between C++ and LLVM**\n\nIn an <em>earth-shattering</em> reveal, a brave soul ventures to explain how Clang lovingly translates the complex poetry of C++ into the sterile LLVM IR, pitting \"no optimization\" as a feature rather than a mere oversight. We learn that Clang, unlike your overachieving colleague, happily passes the optimization buck to LLVM, spawning pages of the digital equivalent of Tolkien's Elvish. Commenters, ever the astute observers, engage in a heated debate over whether Clang is the lazy intern or the unsung hero of code compilers, with insights ranging from \"very bad LLVM IR\" to subtle nuances in unoptimized outputs. Get your popcorn ready; the drama unfolds faster than Clang's reluctance to optimize! \ud83d\ude31\ud83c\udf7f"
  },
  {
    "title": "In the Beginning Was the Command Line (1999) (stanford.edu)",
    "points": 290,
    "submitter": "conanxin",
    "submit_time": "2024-07-27T06:25:02",
    "num_comments": 179,
    "comments_url": "https://news.ycombinator.com/item?id=41084795",
    "comments": [
      "This essay by Neal Stephenson was first published in 1999. \nhttps://en.m.wikipedia.org/wiki/In_the_Beginning..._Was_the_...The analogy of OS as cars (Windows is a station wagon, Linux is a tank) is brought up in the recent Acquired episode on Microsoft, where Vista was a Dodge Viper but Windows 7 was a Toyota Camry, which is what users actually wanted.\n \nreply",
      "And Neal Stephenson acknowledged it was obsolete in 2004:\"I embraced OS X as soon as it was available and have never looked back. So a lot of 'In the beginning was the command line' is now obsolete. I keep meaning to update it, but if I'm honest with myself, I have to say this is unlikely.\"https://slashdot.org/story/04/10/20/1518217/neal-stephenson-...But people still dredge this quarter century old apocrypha up and use it to pat themselves on the back for being Linux users.  \"I use a Hole Hawg!  I drive a tank!  I'm not like those other fellows because I'm a real hacker!\"\n \nreply",
      "Neal gave up on Linux because he wasn't a developer. He couldn't take advantage of the freedoms it provided and it worked the same for him as any proprietary OS would. I.E. he had the excuse that programming is hard, a specialty that requires much practice. This is an ongoing issue with free software and is why it is niche... it primarily appeals to software developers as they are the only ones that can take advantage of the freedoms it provides and are the ones that truly sacrifice that freedom when they use a non-free OS.\n \nreply",
      "Yeah, this is basically my take too. I had a hardcopy of this sometime between 99 and 02, and read it several timesAt the time I was an embedded developer at Microsoft and had been a Windows programmer in the mid 90s. It was pretty clear that there was some dunning Krueger going on here. Neal knew enough about tech to be dangerous, but not really enough to be talking with authority\n \nreply",
      "Given what OS X has become it's un-obsoleted itself again.It's kind of ironic that you're using a post from 20 years ago to invalidate an essay from 25 years ago, about an OS that's been substantially dumbed down in the last 10 years.Bad corporate blood will tell.\n \nreply",
      "In what way has it been \u201cdumbed down?\u201d I use modern MacOS as a Unix software development workstation and it works great- nothing substantial has changed in 20 years other than better package managers. I suppose they did remove X11 but it\u2019s trivial to install yourself.\n \nreply",
      "Not GP, but usually when people talk about the \"dumbing down\" of macOS, they refer to new apps and GUI elements adopted from iOS.macOS as an operating system has been \"completed\" for about 7 years. From that point, almost all additions to it have been either focused on interoperation with the iPhone (good), or porting of entire iPhone features directly to Mac (usually very bad).Another point of view is that macOS is great, but all ideas that make it great come from 20 years ago, and have died at the company since then. If Apple were to build a desktop OS today, there's no way they would make it the best Unix-like system of all time.\n \nreply",
      "> Another point of view is that macOS is great, but all ideas that make it great come from 20 years ago, and have died at the company since then.This also applies to Windows, by the way (except it\u2019s more like 20-30 years ago).\n \nreply",
      "Whereas Linux never stopped coming up with new ideas, but doesn't have the manpower to implement them\n \nreply",
      "Just using at a barely advanced level for 20 years or so as I do, the other comment was correct in that it is the changes that have seemingly been made to make it more familiar to iOS users and \u201cidiot proof\u201d.Mainly slowly hiding buttons and options and menus that used to be easily accessible, now require holding function or re-enabling in settings or using terminal to bring them back.\n \nreply"
    ],
    "link": "https://web.stanford.edu/class/cs81n/command.txt",
    "first_paragraph": "",
    "summary": "Welcome back to the retro tech show where vintage internet essayists and commenters duel with fossils. Today's relic: \"In the Beginning Was the Command Line,\" an essay so ancient that its author admitted its obsolescence almost two decades ago. Not surprisingly, it still attracts crusty technophiles who wax poetic over which prehistoric OS metaphorically resembles a tank. Meanwhile, in the comments, it's a grand reunion of those whose tech credentials peak at remembering <em>any</em> command line commands, fiercely debating the descent of MacOS into simplicity as they desperately cling to a time when you needed a PhD in Computer Science to adjust your screen brightness."
  },
  {
    "title": "Lessons from Ancient File Systems (madcompiler.blogspot.com)",
    "points": 3,
    "submitter": "zdw",
    "submit_time": "2024-07-27T23:33:45",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "http://madcompiler.blogspot.com/2024/02/lessons-from-ancient-file-systems.html",
    "first_paragraph": "\nIn my previous post, I mentioned that I found a number of oddities when digging through the details of various Atari 8-bit file systems.\u00a0 I read through the specifications I could find online, and ran the actual code in emulators to verify and discover details when the specifications were unclear or incorrect.\u00a0 There were some surprising finds.I looked at:Atari DOS 1.0 started it all off back in 1979.\u00a0 It supported single-sided, single-density disks that consisted of 720 sectors holding 128 bytes each.\u00a0 It has some bugs and implementation limitations, so DOS 2.0s ('s' for single density) soon replaced it, making some key changes.\u00a0 Soon other DOS versions started appearing, some trying to maintain backwards compatibility, and others trying completely new approaches.\u00a0 I won't go into the technical details, but I do want to highlight what I think are the most interesting design decisions.Keep in mind that DOS 1 was designed when they were planning on selling the base Atari 800 with only ",
    "summary": "\ud83e\udd13\ud83d\udcbe Another intrepid blogger delves into the catacombs of ancient file systems, unearthing the ***prehistoric*** artifacts of Atari DOS. How quaint! The blog, titled \"Lessons from Ancient File Systems\" on madcompiler.blogspot.com, finds the courage to wax eloquent about the surprisingly ***\"fascinating\"*** details of 720 sectors and 128-byte capacities like they are the lost cities of gold. Brace yourselves, readers, as the comment section transforms into a fierce arena where middle-aged software enthusiasts relive their glory days, one misunderstood byte at a time. Who knew relics could be so divisive?"
  },
  {
    "title": "Covering All Birthdays (liorsinai.github.io)",
    "points": 11,
    "submitter": "the_origami_fox",
    "submit_time": "2024-07-27T09:44:32",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=41085471",
    "comments": [
      "The cover of Bayesian Data Analysis 3 shows that empirically, birthdays are not uniformly distributed. The fall has 10-20% more births than other months, and holidays are significantly underrepresented.https://lh3.googleusercontent.com/proxy/OZtu7ACWp4X283a4e5Pg...\n \nreply",
      "If you're going to write conditional probabilities with big parentheses don't forget to make the \\vert big as well. You can use \\middle if you want to automatically match \\left and \\right.Also conditional probabilities aren't really the right tool when all you want is to set a parameter, but it works I guess.\n \nreply",
      "Aren't there 366 birthdays, not 365?Are leap-day births unpersons?\n \nreply",
      "I wonder if most celebrate March 1 or February 28 most of the time? March 1 is more accurate time-wise but February 28 keeps within the same month.\n \nreply",
      "No but they rarely have birthdays\n \nreply",
      "If we're going off of rarity, December 25 has 6,574 average yearly births and September 9 has almost double at 12,301 average yearly births.Taking a look at Feb 29th, it has 10467 average yearly births (for years that have a Feb 29th).So what is the level of rarity that makes a day not worth calculating?https://github.com/fivethirtyeight/data/blob/master/births/U...\n \nreply",
      "> it has 10467 average yearly births (for years that have a Feb 29th)do you see it?\n \nreply",
      "\u201cI will leave out extra material from the original including [\u2026] accounting for leap years\u201d\n \nreply"
    ],
    "link": "https://liorsinai.github.io/mathematics/2024/07/09/birthday-covering.html",
    "first_paragraph": " Picture by Behnam Norouzi Quantifying how likely each birthday is present (covered) in some large group of people.I recently got nerd sniped by a fascinating post on Hacker News titled Every day is an Owl\u2019s Birthday! by SeniorMars. \nIt explored the problem of estimating if there was at least one student at a university for every birthday. Put another way, it explored the following question:Given $n$ people, what is the probability that all $N$ birthdays are covered? That is, given $n$ people, what is the probability that there is at least 1 person for each birthday?As well as the related question:What is the expected number of people required to have at least 1 person for each birthday? That is, how many people do you need to approach and ask what their birthday is before you see all birthdays?For the latter, the minimum number of people is obviously $n=N=365$. \nHowever you would have to be very lucky to get this outcome.\nOn the other extreme, one can imagine an incredibly unlucky cas",
    "summary": "Title: The Ultimate Birthday Bash Brain-Boggler\n\nAt liorsinai.github.io, the virtual party is pumping, not with balloons and cake, but with probabilities and nerd sniping. Step right up and witness the overdone show of calculating whether all <i>N</i> birthdays are covered if your party crowd is randomly pulled from a database of names\u2014or maybe a phonebook if you're retro. Comments reveal a chaotic twist of misguided statistics and cheeky banters, from cries about leap-year babies being \"unpersons\" to a fierce debate on whether December 25 or September 9 is the true champion of birthrates. The real puzzle here is determining what's more elusive\u2014having a unique birthday or finding someone who cares about these probabilities in the first place. Who knew obsessing over calendar dates could be less about eating cake and more about eating up computational dilemmas? \ud83c\udf82\ud83e\udd13"
  },
  {
    "title": "Maglev titanium heart inside the chest of a live patient (newatlas.com)",
    "points": 69,
    "submitter": "thunderbong",
    "submit_time": "2024-07-26T17:51:36",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=41080654",
    "comments": [
      "xxx"
    ],
    "link": "https://newatlas.com/medical/maglev-titanium-heart-bivacor/",
    "first_paragraph": "",
    "summary": "On New Atlas, an excitable gaggle of techno-optimists congregates to marvel at the latest punctuation in science fiction becoming science fact: a maglev titanium heart whirring away inside someone's chest. Clearly ignoring the usual complexities of human biology, enthusiasts hail this technological marvel as the second coming, while sidestepping minor discussion points like long-term viability or ethics. The comments become a turbulent whirlpool of armchair engineers and self-certified cardiologists, each delivering frenzied manifestos about how they knew titanium was cool before hearts did. Will the excitement last longer than the battery life of this bionic wonder? Stay tuned."
  }
]