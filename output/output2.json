[
  {
    "title": "Consistency LLM: converting LLMs to parallel decoders accelerates inference 3.5x (hao-ai-lab.github.io)",
    "points": 237,
    "submitter": "zhisbug",
    "submit_time": "2024-05-08T19:55:07",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=40302201",
    "comments": [
      "This mirrors what I experienced when I enrolled in \"free drawing\" (no teaching) classes:While people considered me a good drawer since I was a child, I remember just repeating either similar detailed drawings I drew before, or otherwise just taking plenty of time to draw. I believe anyone with time and patience can make a nice drawing of a scene.The \"free drawing\" class had no rules or lectures: you brought the materials you wanted to work with (some brought ink, others pencils, while I brought charcoal). The only thing determined was the timing between poses for the model: for each session the first few poses were very short (say a minute), and then the pose durations would progressively lengthen until say 5 minute poses. At all times you were free to tear your picture up and retry drawing the pose again.My drawing skills improved considerably. The short \"warmups\" actually force you to get proportions and outlines correct on the first tries. Conventional wisdom says haste makes waste, but when learning or refining skills, it seems natural selection has hardcoded the sensation of haste as a stressor prompting attention and learning.I am convinced I could have drawn similar quality drawings before enrolling in those classes, except they would have taken me easily 5 or 10 x as long to draw. Being forced not to beat around the bush and feeling the penalty of making a hasty mistake (further decreasing time left for the second try in the remaining time) does seem to work.My only gripe is that the technique is termed \"Consistency\" whereas I would reserve such a term for an improvement in performance not inference speed, although I understand that they indicate \"consistency with what would ultimately have been generated one token at a time\". I would rather dub it \"Proficiency LLM\", where the same output is expected, only without the inhibition of stuttering to the same conclusion.",
      "Hi we are CLLM authors and thanks for sharing your experience and insights! I can see this drawing skill refining process echoes with the training process in CLLM, the only thing is at this point stressor in CLLM training is not getting progressively demanding.For example, while drawing, you can set very specific time limit on how long you are allowed to draw in each trial and make the time progressively shorter. In CLLM, maybe we can make this the learning process more and more difficult by mapping more and more distant states in Jacobi trajectory to its final state.We are using the term \"consistency\" because we draw parallelism between consistency LLM and the consistency model in diffusion image generation where the training processes are analogous.",
      "Is it just me, or does this read like it was written by an LLM ... ?!",
      "lol I take that as a compliment. Good try but sadly no LLM in this writing :)",
      "Systems generally become more efficient when under stress. They are also forced into local optima - everything has upsides and downsides.",
      "I had an interesting experience in an Invertebrate Zoology lab class one summer.We students were brought into a lab, given specimens to draw, and the only instructions we received were 'You have 30 minutes to draw this. Go.'There was no \"here's how to draw. here's what to do and not to do\". It was just basically \"We don't care about any insecurities you might have. We don't care if you think you can't draw. No excuses, just fucking draw it. Now.\"Not only did we draw, but we (all of us) improved enormously over the course of the class as more animals were brought in and the exercise was repeated over and over and over again throughout the summer.What it taught us is that everyone, and I mean everyone, can draw. Our collective attitude shifted from \"don't know if this is even possible\" to \"of course we can do this. this is easy. routine. trivial.\"Highly recommended approach.It was the most freeing and amazing class I had in college.",
      "The authors mention that Jacobi decoding is equivalent to greedy autoregressive decoding, but in practice don't we often want the sampling temperature to be above zero to avoid repetitions and excessively generic responses?I'm completely unfamiliar with this decoding strategy so maybe I'm just missing a simple way to account for that.",
      "Yes this is a great question! We are actively working on supporting other sampling strategies other than greedy sampling. In the context of CLLM training, instead of mapping to a static fixed point obtained from Jacobi decoding as the training ojbective, we term it dynamic fixed point. You can keep an eye on our github repo for new progress.",
      "Agreed. It's straightforward to check that a token was the argmax, but it seems difficult to check that a token appeared with the probability you wanted it to. You could still do the fine-tuning step I guess, where you train the trajectories to approach n-token completions with the statistics you want, but I can't see how you can replace the \"check for a fixed point\" step. Maybe \"check the result was above this fixed threshold for likelihood\".",
      "InterestingI think soon we are going to realize that we don\u2019t really need training the modelsWe just need good indexing and samplingEssentially at some level any LLM is equivalent to a DB of the dataset, with a great NLP interface on topBoth are just different methods of navigating stored data"
    ],
    "link": "https://hao-ai-lab.github.io/blogs/cllm/",
    "first_paragraph": "An instance of Jacobi trajectory and an illustration of the global consistency loss learning objective.",
    "summary": "In the latest episode of \"Techno-Jargon Meets Art School\", the Hao AI Lab turns a simple <em>drawing class</em> analogy into a high-octane tech sprint, rebranding old wine in shiny, new digital bottles called \"Consistency LLM.\" Commenters, mistaking verbosity for insight, fondly recount their college days of untutored scribbling as if they've uncovered the Rosetta Stone of learning methodologies. Meanwhile, the original article stuffs enough buzzwords and theoretical fluff into a few paragraphs that even the LLM itself seems to wink, declaring, \"I could've written this drivel in my sleep!\" Are we advancing AI, or just really good at renaming our laziness as efficiency? \ud83e\udd14\ud83d\ude02"
  },
  {
    "title": "AlphaFold 3 predicts the structure and interactions of life's molecules (blog.google)",
    "points": 731,
    "submitter": "zerojames",
    "submit_time": "2024-05-08T15:07:10",
    "num_comments": 332,
    "comments_url": "https://news.ycombinator.com/item?id=40298927",
    "comments": [
      "Stepping back, the high-order bit here is an ML method is beating physically-based methods for accurately predicting the world.What happens when the best methods for computational fluid dynamics, molecular dynamics, nuclear physics are all uninterpretable ML models? Does this decouple progress from our current understanding of the scientific process - moving to better and better models of the world without human-interpretable theories and mathematical models / explanations? Is that even iteratively sustainable in the way that scientific progress has proven to be?Interesting times ahead.",
      "If you're a scientist who works in protein folding (or one of those other areas) and strongly believe that science's goal is to produce falsifiable hypotheses, these new approaches will be extremely depressing, especially if you aren't proficient enough with ML to reproduce this work in your own hands.If you're a scientist who accepts that probabilist models beat interpretable ones (articulated well here: https://norvig.com/chomsky.html), then you'll be quite happy because this is yet another validation of the value of statistical approaches in moving our ability to predict the universe forward.If you're the sort of person who believes that human brains are capable of understanding the \"why\" of how things work in all its true detail, you'll find this an interesting challenge- can we actually interpret these models, or are human brains too feeble to understand complex systems without sophisticated models?If you're the sort of person who likes simple models with as few parameters as possible, you're probably excited because developing more comprehensible or interpretable models that have equivalent predictive ability is a very attractive research subject.(FWIW, I'm in the camp of \"we should simultaneously seek simpler, more interpretable models, while also seeking to improve native human intelligence using computational augmentation\")",
      "The goal of science has always been to discover underlying principles and not merely to predict the outcome of experiments. I don't see any way to classify an opaque ML model as a scientific artifact since by definition it can't reveal the underlying principles. Maybe one could claim the ML model itself is the scientist and everyone else is just feeding it data. I doubt human scientists would be comfortable with that, but if they aren't trying to explain anything, what are they even doing?",
      "That's the aspirational goal.  And I would say that it's a bit of an inflexible one- for example, if we had an ML that could generate molecules that cure diseases that would pass FDA approval, I wouldn't really care if scientists couldn't explain the underlying principles.  But I'm an ex-scientist who is now an engineer, because I care more about tools that produce useful predictions than understanding underlying principles.  I used to think that in principle we could identify all the laws of the universe, and in theory, simulate that would enough accuracy, and inspect the results, and gain enlightenment, but over time, I've concluded that's a really bad way to waste lots of time, money, and resources.",
      "It's not either-or, it's yes-and. We don't have to  abandon one for the other.AlphaFold 3 can rapidly reduce a vast search space in a way physically-based methods alone cannot. This narrowly focused search space allows scientists to apply their rigorous, explainable, physical methods, which are slow and expensive, to a small set of promising alternatives. This accelerates drug discovery and uncovers insights that would otherwise be too costly or time-consuming.The future of science isn't about AI versus traditional methods, but about their intelligent integration.",
      "Or you can treat AlphaFold as a black box / oracle and work at systems biology level, i.e. at pathway and cellular level. Protein structures and interactions are always going to be hard to predict with interpretable models, which I also prefer.My only worry is that AlphaFold and others, e.g. ESM, seem to be bit fragile for out-of-distribution sequences. They are not doing a great job with unusual sequences, at least in my experience. But hopefully they will improve and provide better uncertainty measures.",
      "Discovering underlying principles and predicting outcomes is two sides of the same coin in that there is no way to confirm you have discovered underlying principles unless they have some predictive power.Some had tried to come up with other criteria to confirm you have discovered an underlying principle without predictive power, such as on aesthetics - but this is seen by the majority of scientists as basically a cop out. See debate around string theory.Note that this comment is summarizing a massive debate in the philosophy of science.",
      "If all you can do is predict an outcome without being able to explain how then what have you really discovered? Asking someone to just believe you can predict outcomes without any reasoning as to how, even if you're always right, sounds like the concept of faith in religion.",
      "The how is actually just further hypotheses. It's turtles all the way down:There is a car. We think it drives by burning petrol somehow.How do we test this? We take petrol away and it stops driving.Ok, so we know it has something to do with petrol. How does it burning the petrol make it drive?We think it is caused by the burned petrol pushing the cylinders, which are attached to the wheels through some gearing. How do we test it? Take away the gearing and see if it drives.Anyway, this never ends. You can keep asking questions, and as long as the hypothesis is something you can test, you are doing science.",
      "it's still an extremely valuable tool. just as we see in mathematics, closed forms (and short and elegant proofs) are much coveted luxury items.for many basic/fundamental mathematical objects we don't (yet) have simple mechanistic ways to compute them.so if a probabilistic model spits out something very useful, we can slap a nice label on it and call it a day. that's how engineering works anyway. and then hopefully someday someone will be able to derive that result from \"first principles\" .. maybe it'll be even more funky/crazy/interesting ... just like mathematics arguably became more exciting by the fact that someone noticed that many things are not provable/constructable without an explicit Axiom of Choice.https://en.wikipedia.org/wiki/Nonelementary_integral#Example..."
    ],
    "link": "https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/",
    "first_paragraph": "AI",
    "summary": "**AlphaFold 3: AI Knows Proteins Better Than Your Biology Teacher**\n\nThe wizards at Google have waved their techno-magic wand again, introducing AlphaFold 3, the latest gadget that seems to predict molecular macrame better than scientists can explain it. Watch in *amazement* as commenters duel with their keyboards, passionately arguing whether science is truly science if no one can follow the script without a machine whispering in their ear. \ud83e\uddd9\u200d\u2642\ufe0f Is the future of discovery a series of \"I guess it works\" shrugged off by zealots of the black box oracle, while traditionalists mourn the loss of the scientific method over espressos and failed experiments? Meanwhile, outside the philosophical boxing ring, the real world continues unbothered, possibly thrilled to skip the \"why\" and get straight to the \"cure.\" \ud83c\udfad Oh, the hilarity of progress!"
  },
  {
    "title": "A Scientific Run-Down of Coffee Blooming (seriouseats.com)",
    "points": 58,
    "submitter": "green-eclipse",
    "submit_time": "2024-05-08T21:08:32",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=40302724",
    "comments": [
      "I went through my coffee hipster phase. But I eventually came to the conclusion that my palate is just too unsophisticated to tell the difference between supposed \u201chints of blueberry and molasses\u201d in third wave hipster coffee from a boutique roaster versus the cheap coffee that my local newsstand brews every morning.Now my only concession to coffee is brewing a cup on a Technivorm. Also Hawaiian coffee is super smooth and mellow which I like, but serious coffee aficionados apparently don\u2019t like it for the same reason.",
      "I'm still in that phase, but I like my coffee to taste like coffee. Not necessarily one-note, but not akin to fruity tea (as can be the case brewed with blonde roast, coarse grind, lower water temp, fast percolation). I stick with medium to full-city/espresso roast. Though some single-origin differences can cut through, they don't make much of a difference to me. Where I am enjoying variety more is in my brewing process, french press vs hario switch vs moka pot.",
      "I\u2019ve long assumed that the main effect of the bloom is to soak the grounds so the rest of the water you pour in goes through slower, and all the other alleged effects were minor compared to that.But maybe the CO2 removal stuff really is a big deal.",
      "> But maybe the CO2 removal stuff really is a big deal.It\u2019s definitely a thing. There are some super light roasts that if you try to brew them without enough resting time, you can sort of cheat by just grinding the coffee about 30mins before you brew for a hacky quick degas. It really helps get rid of that grassy vegetal taste.",
      "There should be no grassy taste, that\u2019s a roast defect and comes from inconsistent roasting. You should find a better roaster. You can roast really light and not get that taste, but you need to be consistent.",
      "There was a post here a few months ago saying that blooming prevented static electricity build up within the coffee grounds which made them clump together (or something like that anyway), I thought it was interesting.",
      "That\u2019s not the bloom phase, that\u2019s misting the beans before grinding.",
      "TFA seems to agree with you; it says that bubbles are an indication that the coffee was unevenly wetted.",
      "I\u2019ve taken to stirring my coffee as I pour the hot water in. Definitely seems to ensure that all the coffee grounds ate wetted.",
      "In my own attempt to bloom coffee in an Aeropress, the result is, strangely, that it takes much longer to extract the coffee to 'full strength' if I bloom it, compared to not blooming it. If I bloom the coffee, then fill up with water and stir, the result is under-extracted unless I brew for longer. If I just fill up the water immediately and then stir, it takes much less long to brew to the same 'strength'. This is the opposite of what should be happening. But I am using light-to-medium roasted coffee, and this article notes that bloom and roast are interconnected, so perhaps this is normal? All I know is, coffee brewing seems to be much more an art than a science, regardless of how much you try to focus on the science. Dial it in to what tastes good to you, and that's all that matters."
    ],
    "link": "https://www.seriouseats.com/perfect-coffee-bubbles-signs-sounds-6824133",
    "first_paragraph": "Bubbles on the top of your coffee bed aren\u2019t just cute\u2014they can tell you things about your brew.",
    "summary": "Welcome to the latest episode where coffee snobs dive deep into the \"profound\" science of coffee blooming, brought to you by <i>Serious Eats</i>. Here, bubbles aren't just a sign of good soap, they're a divine signal from your coffee gods telling you about the mystical journey from bean to brew (\ud83d\ude44). Commenters trip over themselves to validate their coffee cred, one-upping each other with tales from their exhaustive (and probably exhausting) journeys through artisanal brewing methods: French press vs. Hario switch vs. Moka pot, oh my! Meanwhile, a valiant soul tries to decide if his coffee tastes more like underwhelming tea or electrifying espresso, yet concludes it might just be an art\u2014thanks, Captain Obvious. Frankly, the real bloom seems to be in pontificating the supposed science while stirring not just their coffee, but also a pot of pretentious jargon. Wake up and smell the coffee, or maybe just keep sniffing for those elusive hints of superiority! \u2615\ud83d\udc43\ud83d\udcac"
  },
  {
    "title": "Show HN: SimBricks \u2013 Modular Full-System Simulation for HW-SW Systems (simbricks.github.io)",
    "points": 16,
    "submitter": "antoine-kaufm",
    "submit_time": "2024-05-08T22:22:08",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://simbricks.github.io/",
    "first_paragraph": "Streamlining design, implementation, and evaluation of heterogenous\nsystems through modular full system simulation.",
    "summary": "In a bold move that promises to revolutionize nothing for ordinary humans but everything for hardware geeks, some brave Hacker News individuals have unfurled \"SimBricks.\" This gloriously overcomplicated tool shall allow the chosen few to simulate *heterogeneous* HW-SW systems endlessly. The comment section turns into a battleground of misunderstood geniuses, each vying to prove who has less of a social life by flaunting their acumen in the esoteric art of modular simulation. Collectively, they might not save the world, but they'll surely simulate a version where they did. \ud83d\ude80\ud83d\udcbb"
  },
  {
    "title": "Industrial Design Student Work: \"How Long Should Objects Last?\" (core77.com)",
    "points": 52,
    "submitter": "surprisetalk",
    "submit_time": "2024-05-07T10:10:33",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=40283954",
    "comments": [
      "This is missing the fact that the stainless steel from the ultra-durable umbrella is also easy to recycle. In fact, steel is far easier to recycle than any kind of plastic.Also, the whole work seems to skip over the huge problem of insufficient customer information: There is a remark in there, that lots of people (about half) seem to choose the ultra-durable umbrella, rather than one of the less resource-intensive ones. The reason for this imho isn't that people don't care about the resources. It is rather that everyone has been conditioned to assume that products are crappier than specified. People do not and usually can not know how durable each product they are offered will be. And buying something ultra-durable-seeming at least gives you a chance at a decent product lifetime. All the rest is usually crappier than expected.One reason is that the environmentally friendlier alternatives are often also materials of lesser quality. E.g. recycled plastic degrades and is more brittle than \"fresh\".The other reason is greedy manufacturers, saving on necessary materials, making products less durable. And maybe intentionally building in weak points, limiting lifetime to sell more stuff.",
      "Aside but one interesting consequence of using plastic in certain kinds of products is that it can be a sacrificial part. If you don\u2019t design a point of failure into your system one will be assigned to it. I recently had this realization after installing a new garage door opener. The motor on it is much stronger than my old one but some parts are far flimsier. Then it dawned on me that I\u2019d rather have a cheap plastic gear break if something goes wrong than have it burn up the unit or swing a high tension belt around.Longevity doesn\u2019t always mean making everything out of cast iron and stainless steel. It can mean making the thing repairable using cheap and available parts.",
      "3D printing options aside, there's no possibility of me replacing random plastic components that break. I'm dependent on some industrial manufacturer producing the random plastic broken part for me, and getting it to me. If something metallic fails, it's much simpler in comparison to fashion a replacement / repair the failure myself. I can work with metal. I can't work with plastic.",
      "Have you used polycaprolactone/PCL aka \"InstaMorph\" for hobby/projects? It's a very tough plastic that can be melted by putting it in hot water, then formed by hand. I think something like a linkage made out of this material could be a fantastic intentional failure point for certain mechanical systems, as long as the temperature requirement is not much higher than human conditions. Also, if you have a hot air blower, you can repair it in-situ.I'm honestly not sure why we don't see more of this plastic used for consumer stuff. Something that you can melt down and fix stuff or make little ornaments sounds like a great marketing gimmick. It's also generally a pretty bio-safe plastic.",
      "In industry, it's because it's so low-temperature. The benefits of using it aren't outweighed by the potential failure risks in it in pieces not designed to be repaired.Also, just kinda--it's not well known! You can't even find it as a 3D printer filament without a lot of effort, even though those \"3D pens\" often use it, because the output is so unimpressive to most people. That's not that it is unimpressive, it's because they don't know much about it, much like how people act like there's a \"leveling up\" by switching from PLA to PETG to ABS.",
      "> Many of the objects we use daily are made from mixed materials, ones are often difficult to separate [for recycling]. This cost can outweigh the value of the materials, so these objects are very likely to end up in Landfill. Of course, mixing materials offers functional benefits such as combinations of soft & hard structures, and nowhere else is this more true [than] with Umbrellas.FTA with context added.",
      "Another reason I seek the durable version is that I despise change.Once I procure an umbrella that meets my needs, I don\u2019t ever want to have to spend the time to go find another. If I manage to wear it out, I will grudgingly replace it with the exact same thing but if that\u2019s not available I\u2019ll go without rather than going through the process of finding a good one again. Modern casual clothing is a disaster in this regard because even the same sku often won\u2019t be the same product year over year.",
      "For me a reason to choose the not so durable umbrella is that I tend to lose umbrellas rather than break them.",
      "About clothing: that and society tends to mock those who repeat the same clothes in a short period of time, promoting cheap/mass fashion and therefore waste.I would rather focus on upcycling repairable clothes rather than promoting so much waste. Specially when a sweater I love tears, I (1) loss the sweater and (2) can't get said clothing item because as you say, the sku or even the brand may not exist anymore. Newer is not always better, both in function and form.Point in case: Mark Zuckerberg and his style change from a anime/cartoon closet full of grey tshirts and blue jeans to a typical sugar daddy atire/style just to appeal to bigger audience without any internal change.Stupid monkey brains.",
      "people who mock people because repeated clothes aren't at their social circle (at least in a meaningful level) or if they do, sit & talk or it's time to move on...i'm almost hitting 30, i still use some 14 y/o clothes and last time i bought stuff was more than 5 years ago because of a hobby. tho i appreciate stylistic people walking at streets. maybe fashion is not that hard to recycle if we use mostly compostable stuff? from leather of pineapple waste, (recycled) cotton and so on"
    ],
    "link": "https://www.core77.com/posts/132088/Fantastic-Industrial-Design-Student-Work-How-Long-Should-Objects-Last",
    "first_paragraph": "This incredibly ambitious and thoroughly-executed project is by Charlie Humble-Thomas, done while pursuing his Masters in the Design Products program at the RCA. Called Conditional Longevity, it asks the question: \"How long should objects last?\"",
    "summary": "In an audaciously pedestrian revelation of academia, industrial design student Charlie Humble-Thomas wonders \ud83e\udd14 if perhaps things might need to last longer\u2014or maybe not\u2014as explored in his Masters' thesis project, \"Conditional Longevity.\" A swarm of comments resolutely miss the point by venturing into the merits of steel recycling and the undereducation of consumers on product lifespan. Apparently, buying umbrellas is now akin to a philosophical commitment to durability, adorned with a subtle hint of regret over society's inability to keep those darn umbrellas from escaping their forgetful owners. Meanwhile, casual fashion gets a sideline sneer, highlighting our cultural doom-loop of disposable wardrobes and the tragic loss of beloved sweaters to the ruthless march of time and SKU updates."
  },
  {
    "title": "How enterprise software is like baby clothing (twitter.com/random_walker)",
    "points": 15,
    "submitter": "cs702",
    "submit_time": "2024-05-06T23:41:45",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=40280726",
    "comments": [
      "https://threadreaderapp.com/thread/1182635589604171776.html",
      "Oh I thought this was going to be along the lines of Michael Dell's assertion. He said ever time Dell doubled in size, he needed to revisit all the processes. Automate things that used to be manageable by hand. Customize processes that used to be one-size-fits-all. Because a bigger company has different optimal solution points for nearly everything.(Which could be taken to heart by people insisting that government should go back to some imagined simpler past. Those old processes are obsolete; there's no going back. But that's another tale.)"
    ],
    "link": "https://twitter.com/random_walker/status/1182635589604171776",
    "first_paragraph": "",
    "summary": "In a harrowing quest to repost the most banal metaphor, a brave thought leader compares enterprise software to baby clothing. \ud83d\udca1 Naturally, this is groundbreaking: both are overpriced, outgrown at an alarming rate, and a nightmare to clean up after. The comments section blossoms into a chaotic daycare full of tech bros and armchair philosophers debating the nuances of scalability as if discovering fire. \ud83d\ude44 If only these threads could self-duplicate and automate like the bureaucracies they adore discussing!"
  },
  {
    "title": "TimesFM: Time Series Foundation Model for time-series forecasting (github.com/google-research)",
    "points": 208,
    "submitter": "yeldarb",
    "submit_time": "2024-05-08T13:34:34",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=40297946",
    "comments": [
      "I'm curious why we seem convinced that this is a task that is possible or something worthy of investigation.I've worked on language models since 2018, even then it was obvious why language was a useful and transferable task. I do not at all feel the same way about general univariate time series that could have any underlying process.",
      "Time series data are inherently context sensitive, unlike natural languages which follow predictable grammar patterns. The patterns in time series data vary based on context. For example, flight data often show seasonal trends, while electric signals depend on the type of sensor used. There's also data that appear random, like stock data, though firms like Rentech manage to consistently find unlerlying alphas. Training a multivariate time series data would be challenging, but I don't see why not for specific applications.",
      "The things that we are typically interested in have very clear patterns.  In a way, if we find that there are no patterns, we don't even try to do any forecasting.\"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\" [1] hints that there might be some value here.[1] https://en.m.wikipedia.org/wiki/The_Unreasonable_Effectivene...",
      "Exactly, so for example, I think the use of this model is in cases where you want user count to have some pattern around timing. And be alerted if it has spike.But you wouldn't want this model for file upload storage usage which only increases, where you would put alerts based on max values and not patterns/periodic values.",
      "Fundamentally, the pre-trained model would need to learn a \"world model\" to predict well in distinct domains. This should be possible not regarding compute requirements and the exact architecture.After all, the physical world (down to the subatomic level) is governed by physical laws. Ilya Sutskever from OpenAI stated that next-token prediction might be enough to learn a world model (see [1]). That would imply that a model learns a \"world model\" indirectly, which is even more unrealistic than learning the world model directly through pre-training on time-series data.[1] https://www.youtube.com/watch?v=YEUclZdj_Sc",
      "But the data generating process could be literally anything. We are not constrained by physics in any real sense if we predicting financial markets or occurrences of a certain build error or termite behavior.",
      "Sure, there are limits. Not everything is predictable, not even physics. But that is also not the point of such a model. The goal is to forecast across a broad range of use cases that do have underlying laws. Similar to LLM, they could also be fine-tuned.",
      "> I'm curious why we seem convinced that this is a task that is possible or something worthy of investigation.There's a huge industry around time series forecasting used for all kinds of things like engineering, finance, climate science, etc. and many of the modern ones incorporate some kind of machine learning because they deal with very high dimensional data. Given the very surprising success of LLMs in non-language fields, it seems reasonable that people would work on this.",
      "Task specific time series models, not time series \u201cfoundation models\u201d - we are discussing different things.",
      "+1 for \u201cany underlying process\u201d. It would be interesting what use case they had in mind."
    ],
    "link": "https://github.com/google-research/timesfm",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "Welcome to the latest <em>tech revelation</em> where Google decides the fate of time itself through its ground-breaking, universe-altering, and definitely-not-overhyped Time Series Foundation Model, TimesFM. As usual, the eager beehive of GitHub commenters buzzes with contradictions: seasoned language model veterans balk at the heresy of equating linguistic order with chaotic time series data, while hopeful tech optimists conjure visions of a universal \"world model\" that can mysteriously predict everything from user logins to termite party plans. Apparently, some think discovering the pattern in chaos is just a training dataset away. Grab your popcorn \u2014 or your textbooks \u2014 this ragtag forum of \"experts\" guarantees both comedy and tragedy. \ud83d\udcbb\ud83d\udcc8\ud83c\udf7f"
  },
  {
    "title": "How to Use the Foreign Function API in Java 22 to Call C Libraries (ifesunmola.com)",
    "points": 142,
    "submitter": "pjmlp",
    "submit_time": "2024-05-06T08:40:02",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=40272514",
    "comments": [
      "I am sort of surprised that there isn't a widely used tool that uses codegen to generate jni bindings sort of like what the jna does but at build time. You could go meta and bundle a builder in a jar that looks for the shared library in a particular place and shells out to build and install the native library if it is missing on the host computer. This would run once pretty similar I think to bundling native code in npm.I have bundled shared libraries for five or six platforms in a java library that needs to make syscalls. It works but it is a pain if anything ever changes or a new platform needs to be brought up. Checking in binaries always feels icky but is necessary if not all targets can be built on a single machine.The problem with the new api is that people upgrade java very slowly in most contexts. For an oss library developer, I see very little value add in this feature because I'm still stuck for all of my users who are using an older version of java. If I integrate the new ffi api, now I have to support both it and the jni api.",
      "> I am sort of surprised that there isn't a widely used tool that uses codegen to generate jni bindings sort of like what the jna does but at build timeThere are several, including SWIG.",
      "There is SWIG, which does bings to and from C for almost every language that exists.",
      "What I'm missing is a model for building/distributing those C libraries with a java application.Every ffi example I've found seem to operate on the assumption that you want to invoke syscalls or libc, which (with possibly the exception of like madvise and aioring) Java already mostly has decent facilities to interact with even without native calls.",
      "Native libraries are typically packaged inside a jar so that everything works over the existing build and dependency management systems.For example, each these jars named \"native-$os-$arch.jar\" contain a .dll/.so/.dylib:\nhttps://repo1.maven.org/maven2/com/aayushatharva/brotli4j/JNA will extract the appropriate native library (using os.name and os.arch system properties), save the library to a temp file, then load it.",
      "> Every ffi example I've found seem to operate on the assumption that you want to invoke syscalls or libc ... Java already mostly has decent facilities to interact with even without native calls.Because you would use ffi to interact with libraries that don't have Java wrappers yet: IE, you're writing the wrapper.Using syscalls or libc is a way to write an example against a known library that you're probably familiar with.",
      "The recommended distribution model for Java applications is a jlinked runtime image [1], which supports including native libraries in the image.[1]: Technically, this is the only distribution model because all Java runtimes as of JDK 9 are created with jlink, including the runtime included in the JDK (which many people use as-is), but I mean a custom runtime packaged with the application.",
      "Is that still true when distributing libraries?",
      "Absolutely not. jlink is used to distribute applications (it includes your code, the Java libs you use, i.e. their jars, and the trimmed-down JVM with the modules you're using so that your distribution is not so big - typically around 30MB).Java libraries are still obtained from Maven repositories via Maven/Gradle/Ant/Bazel/etc.",
      "If you distribute libraries as jmod files, which few libraries do (in that case, jlink would automatically extract the native libraries and place them in the appropriate location)."
    ],
    "link": "https://ifesunmola.com/how-to-use-the-foreign-function-api-in-java-22-to-call-c-libraries/",
    "first_paragraph": "",
    "summary": "In an enthralling display of ignorance meets nostalgia, ifesunmola.com pens a guide to using Java 22\u2019s Foreign Function API, illuminating the path for those brave souls intent on invoking C libraries like it\u2019s 1999. Enthralled by Java's perpetual slow adaptation pace, the comment section blossoms into a tech utopia where everyone is either mystified by the existence of existing tools like SWIG, or trapped in existential horror over integrating the new API with the antiquated JNI. One visionary commenter dreams of a magical world where Java isn\u2019t painfully slow in adopting its own features. Meanwhile, everyone seems to forget that the rest of the world has moved on to languages that don\u2019t require a ritual dance to call C code. \ud83d\udd7a\ud83d\udcbe"
  },
  {
    "title": "Development Notes from xkcd's \"Machine\" (chromakode.com)",
    "points": 368,
    "submitter": "chromakode",
    "submit_time": "2024-05-08T17:09:17",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=40300454",
    "comments": [
      "Reading this write up is funny, because I had no idea this is what was happening. There didn't seem to be an explanation of what was going on. I didn't know it was a shared experience, just that various random things seemed to be chaotically happening. I completed a couple of tiles and I guess submitted them as I thought that was how you got to \"the next level\", but gave them really stupid names like \"test 1b\" - mostly this is because I assumed it was single player and only I'd be seeing the name!I also got bored after creating a couple of tiles. I scrolled around and saw very complicated things, but didn't realise they were submissions, just starting points for solving the level...I guess I was the April Fool!",
      "I was adding a lot of \"bonk\" elements and I seem to have murdered rapier...    Uncaught Error: recursive use of an object detected which would lead to unsafe aliasing in rust\n    at jt (rapier_wasm2d_bg.js:4836:11)\n    at 4ea5626ea4b1e4145572.module.wasm:0xf061c\n    at 4ea5626ea4b1e4145572.module.wasm:0xf0638\n    at 4ea5626ea4b1e4145572.module.wasm:0xb5e7b\n    at H.remove (rapier_wasm2d_bg.js:1051:14)\n    at l.remove (collider_set.js:87:18)\n    at y.removeCollider (world.js:343:28)\n    at PhysicsContext.tsx:258:15\n\n\n\nAlso, this is super fun, and I'm sad I didn't learn about it when it was still live. It'd be really really cool if people could still permalink individual machines created. I know that might be an issue for storage. Maaaaaybe just base64 encode the JSON into a URL param??? Please?? I'd love to create weird maps and share them with people.",
      "It's still live. https://xkcd.com/2916/Machines that make it into the overall public version can be permalinked, but there's no permalinks for individually created things that don't get selected via the moderation queue. This was an intentional decision to avoid the risk of hosting unmoderated user-generated content on the comic's domain.",
      "Thanks Max, this was a great read! Awesome work and write up. Some good insights about player focused game development too.",
      "FWIW, HN's April 6th item on this, with 14 comments:https://news.ycombinator.com/item?id=39953514",
      "Reminds me of this from my young adult years, I wasted sooo much time on this very happily:https://www.myabandonware.com/game/the-incredible-machine-1m...",
      "It says in the post that this is what inspired the project.",
      "I feel like I'm missing something - why do certain elements seemingly only effect a specific color of ball in the machine? I assume it's to prevent the colors from getting totally jumbled up, but it doesn't seem like that's explained in this write up?",
      "We gave each ball different physical properties. Yellow balls are light and have lots of air drag. Green balls are massive. Red balls are very bouncy. This allows physical sorters to be designed.",
      "Ohhhhhh this makes so much more sense. I was confused about how that was working with some of the designs. Thanks for explaining!"
    ],
    "link": "https://chromakode.com/post/xkcd-machine/",
    "first_paragraph": "On April 5th, xkcd released Machine, our 15th annual April Fools project.",
    "summary": "**Hacker News Discovers Newtonian Physics and Comedy After \u201cMachine\u201d**\n\nIn a brilliant display of collective confusion, Hacker News readers unravel their tragicomic misadventures with xkcd's latest technical jape, \"Machine\". One user, embodying the spirit of Schr\u00f6dinger's gamer, managed to be both entertained and utterly bewildered, treating the multiplayer setup as a hermetic puzzle for solitary reflection named \u201ctest 1b\u201d. \ud83d\udca4 Meanwhile, emergent geniuses pitched storing JSON in URLs, revolutionizing data storage with strings longer than the Great Wall. Sod the safety, it\u2019s all about sharing your personalized *chaos theory* playgrounds, folks. \ud83e\udd13 Amidst these revelations, several users discovered physics properties of virtual balls, celebrated like newly-minted laureates, heralding an era of accidental education. \ud83c\udf08 Welcome to the digital Renaissance, where confusion reigns and every day is April Fool's!"
  },
  {
    "title": "Show HN: AI climbing coach \u2013 visualize how to climb any route based on your body (climbing.ai)",
    "points": 190,
    "submitter": "smandava",
    "submit_time": "2024-05-06T08:09:38",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=40272339",
    "comments": [
      "Looks cool! It definitely looks technically challenging, especially for expert climbers who have a variety of creative moves at their disposal. But I can definitely see this being useful for novices.",
      "I feel like I\u2019m the right audience for this - a not very good climber with unusual distribution of limbs. \nBut I\u2019m not interested - part of the fun in climbing is on sight climbs and solving problems yourself.",
      "Thank you for posting this.  :-)",
      "I have a side project in a related space. For mine I'm syncing climbing between different videos automatically. I find this pretty useful because it highlights difference.Some examples:https://www.instagram.com/p/Cvg3bJkp30a/https://www.instagram.com/p/Cpuv2zvptdW/It's actually syncing in 3D so is fairly independent of camera angle (as the second video shows)",
      "Note:Will attach more example outputs and make a detailed document about how the model was built and the research behind it. If this is interesting to you, feel free to sign up to the waitlist on www.climbing.ai (and make sure to sign up for our Discord!)I originally planned on open sourcing the model, data, weights, and code. Only a few people (me and a couple friends) have access to the hosted model on the web app.If enough people are on the waitlist, I will consider releasing access. This is very expensive to run so was only considering open sourcing it.Note: the model works well sometimes, but most of the times it does not. This is an early research preview. Please tamper any expectations. A really good general model requires millions of videos and much more training time so it is really prohibitively expensive. As mentioned before, if someone has the compute, all they have to do is scale the existing dataset and training pipeline (which I will publish open-source in the coming weeks).",
      "High-level details about how you tackled the various sub-problems would be useful.I assume, at minimum, there's:   - Segmentation of moving elements\n   - 3d reconstruction from 2d video\n   - Reverse kinematics\n   - Identification of holds\n   - Search for potential climbing path\n   - Generation of kinematics for path",
      "Likely looking to see a 100k emails list before really thinking about all these problems to solve and well.Worst case able to build this, scenario, author builds something else entirely.",
      "Afaict, author already built a proof of concept.",
      "I've been working on the same thing, there is an interesting quote from back in the day and its either make your program faster or wait 6 months for the computers to get faster. I look at it the same way now with Key Point Analysis and Pose Estimation libraries.I think OSS is best for this category right now.",
      "It would be really interesting to build an instance of this model trained on world cup footage for a few reasons.- Like all of these things, your training data matters and the internet is awash with videos of people climbing badly. A lot of people specifically post \"I can't climb this, what am I doing wrong?\" videos. World cup climbers are, by the nature of the competition, extremely talented and technically proficient climbers. Even when they fail, they fail in smart interesting ways.- There's lots of high quality video footage out there. Heck, the problems are even set with visual clarity in mind which would help when parsing that footage. There's potentially enough video to train instances on individual climbers. You could run side by sides like \"How would Tamoa climb this and how would Janja climb this?\".- World cup problems are stylistically distinct. They involve lots of moves \"typical\" climbers will never ever encounter. Many climbers will look at a typical gym problem and think \"I have an idea of how to climb this\" but will look at a world cup problem and just think \"????????\". An app that told you how a problem like that should be climbed might be useful.There are drawbacks too.- World cup climbers are outliers, whose physical ability (strength, flexibility, etc.) give them access to kinds of movement that other climbers just don't have. No amount of \"knowing the sequence\" will get me up a climb that requires a full bat hang (look it up) because I just don't have the ankle strength to do the movement.- World cup \"style\" is only commonly used at high level comps and in very large commercial gyms. It's probably not extremely relevant to a typical climbing session.- World cup problems are very hard. Mostly v10 and up? It would be hilarious to watch a model trained on genetic monsters crushing the world's hardest boulder problems try to tell a doughy office worker (me) how to climb v2."
    ],
    "link": "https://climbing.ai/",
    "first_paragraph": "",
    "summary": "**Show HN: AI Climbing Coach Mostly Guesses How You Might Not Fall Off**\n\nIn a bold move, someone has finally meshed the uncertainty of artificial intelligence with the unpredictability of human limbs in \"climbing.ai.\" This revolutionary tool aims to guide clueless climbers to victory by visualizing moves that their less-than-world-class bodies can scarcely perform. Comment sections light up with enthusiastic tech climbers ready to critique and occasionally praise the patchwork AI, pondering deeply in username-littered discourses about the \"potential\" for greatness\u2014if only the tech were actually accessible outside of a few friends' garage servers. Meanwhile, an equally ambitious developer brags about a side project that unsolicitedly syncs climbing videos, sparking a frenzied trade of speculative ideas, none of which likely get these Sunday climbers past the kiddie wall. \ud83e\uddd7\u200d\u2642\ufe0f\ud83d\udcbb\ud83d\ude02"
  },
  {
    "title": "Taxpayers Are About to Subsidize a Lot More Sports Stadiums (theatlantic.com)",
    "points": 13,
    "submitter": "paulpauper",
    "submit_time": "2024-05-09T00:17:22",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://www.theatlantic.com/ideas/archive/2024/05/sports-stadium-subsidies-taxpayer-funding/678319/",
    "first_paragraph": "You would think that three decades\u2019 worth of evidence would put an end to giving taxpayer money to wealthy sports owners. Unfortunately, you would be wrong.",
    "summary": "In the latest thrilling installment of *American Taxation: the Masochist's Saga*, The Atlantic reports that, shockingly, despite mountains of evidence that subsidizing sports stadiums is as economically beneficial as lighting money on fire, the practice persists. Outrage bubbles in the comment section, where keyboard economists compete to see who can express their surprise in the most verbose manner possible. One commenter, missing the irony entirely, suggests funding for a study to understand why governments keep funding things. Meanwhile, another genius points out that the real issue is everything except the topic at hand. Taxpayers, prepare your wallets for a workout of Olympic proportions! \ud83c\udfdf\ufe0f\ud83d\udcb8"
  },
  {
    "title": "Show HN: I built a non-linear UI for ChatGPT (grafychat.com)",
    "points": 259,
    "submitter": "setnone",
    "submit_time": "2024-05-08T16:41:12",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=40300126",
    "comments": [
      "I built a similar demo to this but for images - IMO this is a much better structure for working with LLMs as it allows you to really riff with a machine instead of feeling like you need a deterministic \"next step\"https://youtu.be/k_mJgFmdWWY",
      "Looks amazing! The Unity client is quite sleek. I'd wager the creative play can be taken to the next level with a low-latency model like https://fal.ai/models/fast-turbo-diffusion-turbo",
      "Sweet demo, you should do a Show HN! This is much more interesting to me, as the visual element makes much more sense here rather than just putting entire paragraphs in nodes.",
      "Great stuff! That deterministic \"next step\" is the last line of defense for us humans :)",
      "The only feedback I would give is I'm suspicious of (will not buy) closed sourced AI anything. With that said: thank you for sloughing off the subscription model trend! That is welcome.But going open source so that I know \"for sure\" no telemetry is being sent and charging for support would be the only way to get money out of me for this. I'm probably the odd one out for this, so take that with a fair helping of salt.This is a great idea, so much so that this is also something I could probably put together a MVP of in a weekend (or two) of dedicated work (the fancy features that I personally don't care about would probably take longer to implement, of course...).Good work! Keep it up.",
      "Very cool! I built a version of this [1], but balked at trying to sell it. This is the third iteration of this idea I've seen so far. Your reply popup is a smart feature and a nice touch! Love it. I love the privacy focus and BYOK, as well.Congrats on the launch!Really cool to see graph interfaces for AI having their moment. :)[1] https://coloring.thinkout.app/",
      "Hard to try it on my phone.",
      "Powerful stuff, this is the kind of workspace I've been waiting for for AI. Excited to see how it evolves!",
      "From watching the demo it looks interesting, but I figure I would get tired of dragging nodes around and looking for ones that I'm interested in. Does it allow searching?It would be more interesting to me if it could use AI as an agent to create a graph view - or at least propose/highlight followup questions that self-organize into a graph.",
      "> I would get tired of dragging nodes aroundMe personally i find value in taking my time to organize and drag around, probably because i'm a visual thinker"
    ],
    "link": "https://www.grafychat.com",
    "first_paragraph": "",
    "summary": "Welcome to the future of interaction design, where a \"non-linear UI for ChatGPT\" has become a brave new benchmark for tech enthusiasts capable of turning mere conversations into a delightful maze of chaos. Watch as every armchair developer gushes over the elegance of detangling a UI supposedly designed to streamline thought processes, yet most likely enhances their procrastination prowess. Commenters swarm with back-patting glee and timid suggestions, fantasizing about reskinning the concept over a weekend, while preemptively mourning the sore absence of open-source credentials. \ud83c\udf89 Behold, a graphical user interface revolution, one node at a time!"
  },
  {
    "title": "Radius Full Page Display (32by32.com)",
    "points": 35,
    "submitter": "mikerg87",
    "submit_time": "2024-05-06T11:51:30",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=40273516",
    "comments": [
      "I like how if you tap any of the images it transforms from an Atkinson dithered image to a a clear colour image. Cool effect.",
      "The combination of font and some ClearType shenanigans produced this amusing result: https://postimg.cc/4KDDLr9Y",
      "I also see this weird green-purple gradient in the text. It disappears if you zoom in or out.You can make it go in waves:    let x = 0;\n    function move() {\n        const el = document.getElementById(\"content\");\n        el.style.paddingLeft = x + \"px\";\n        x += 0.01;\n    }\n    setInterval(move, 10)",
      "HPPD mode enabled.",
      "Vertical screens are fantastic, they feel natural for so many coding tasks. I bought one for home and adaptation took less than a week. Now have a hard time going back to horizontal when working from the office. Recommended!",
      "Another portrait display user here! I use a 19:10 display rotated to 1200x1920. Not retina but I'm happy with it. I have window manager keyboard shortcuts set so I can position windows as halves, thirds, quarters, full screen, push windows to the MacBook display or my iPad. It's a powerful setup. It's the one great thing Apple neglected to take from Xerox PARC. Also interesting that more people don't do it in their desktop when everybody uses iPhone in portrait.",
      "Early workstations (Alto, CADR, PERQ etc) were portrait, and a lot of development was done on portrait ASCII terminals too (e.g. AAA).  I was always puzzled as to what caused the switch in the mid 80s.",
      "My Mac IIcx with Apple Portrait Display was a lovely system.\nLuckily most modern screens like my LG can be pivoted to vertical, and then the Mac lets you specify the rotation. There's no more need for vertical-only screens.",
      "I like one in each orientation. I am using one huge screen now but I'll go back to two monitors the next time round.",
      "Worth remembering that these displays were small. The Radius or PERQ display was the same format as a piece of paper. It was \"full page\" only for 8.5x11, in the same way that 35mm camera sensors are \"full frame\". If you have a 21\" or larger WUXGA display you already have 2 of these pages side by side and there aren't a lot of great reasons to run a display like that in portrait mode. Unless you are just dying to have realistic 11x17\" pages, large portrait monitors are just an ergonomic problem."
    ],
    "link": "https://32by32.com/radius-full-page-display/",
    "first_paragraph": "1,293  words",
    "summary": "In the labyrinthine corridors of tech nostalgia, 32by32.com unveils the majestic \"Radius Full Page Display,\" a heart-stopping 1,293-word manifesto on resurrected screens. The audience, buoyed by the sheer ecstasy of switching from monochrome dithers to technicolor bursts with a tap, engages in a euphoric discourse on the divine transformation. Comments spiral into a geek utopia where users flaunt their vertical screen setups like peacocks, celebrating their sudden epiphanies about screen orientations with a fervor reminiscent of discovering fire. In a world teetering on the brink of total anarchy for want of perfect screen alignment, we learn once more that tech enthusiasts will always find joy in arranging windows slightly more efficiently than yesterday. \ud83d\udda5\ufe0f\u2728"
  },
  {
    "title": "The Waning Reign of the Muskrat (hakaimagazine.com)",
    "points": 100,
    "submitter": "Thevet",
    "submit_time": "2024-05-07T05:34:07",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=40282671",
    "comments": [
      "I live on tens of acres of wetlands. Two 1/4acre ponds, front is a marsh.The muskrat damage constructed pond shores, but what they create is a low maybe 1 foot deep shoulder where their holes erode dirt onto the pond slope, which is excellent for wildlife. Its the area herons stalk for prey and fish breed. In my case my ponds are very secure with mud banks, so not being worried about leaks I decided to leave the muskrat. They are very cute. That was a few years back.One spring I found 3-4 bodies washed up, possibly from Tularemia. More moved back in, and the spring we went from 2 to 6 individuals, and all the plants started to disappear. The reading I did said muskrat are very much a meta-population like the article mentions. In absence of predators, they will eat a place bare until it can no longer feed them and then migrate.Close to the house I've now adopted a slow reduction with a rifle (non-lead rounds) to offset my imbalance of protecting them from predators. The pond shore damage hasn't stopped so they're still there but it has slowed enough to have time to get out with a wheelbarrow and fix the holes. Plants are doing fine.In a similar balance I shot a pair of extremely large snapping turtles two years ago after learning large snappers have no predators, and we now have a new population of tiny turtles (~4 different species so far). I'm never happy to kill anything, but hopefully in these two cases I'm performing my steward role adequately.",
      "My son was required to do a report on muskrats for school recently, and both him and I knew nothing about them, and were shocked by how little info their is- trying to find basic info about them online is really hard, they are certainly pretty much ignored by people. Ultimately, we were able to find reported sightings in iNaturalist, and were able to find them in the wild, active at dusk. It was a magical experience for both of us.",
      "Sad. These guys are really cute. They\u2019ll invite themselves to live in beaver dams and make for a vaguely tolerated roommate that helps patch up walls and stuff. They\u2019re not as good at the big picture stuff as beavers.",
      "The author, Brandon Keim, is a favorite of mine. If you like this piece, his book Eye of the Sandpiper is worth checking out.https://brandonkeim.net/sandpiper",
      "https://www.cornellpress.cornell.edu/book/9781501707728/the-...",
      "Thank you. They must have updated the site as a result of the spike in traffic.",
      "I thought this was about the other Muskrat",
      "Went straight to the comments instead of the article and was surprised to discover that:\"They\u2019ll invite themselves to live in beaver dams and make for a vaguely tolerated roommate that helps patch up walls and stuff. They\u2019re not as good at the big picture stuff as beavers.\"",
      "Same, I got a pack of cigarettes ready to read the apologist comments.",
      "We have a regular muskrat visitor at our pond in Michigan every March, I haven't worked out where it goes the rest of the year"
    ],
    "link": "https://hakaimagazine.com/features/the-magnificent-lives-and-quiet-loss-of-muskrats/",
    "first_paragraph": "This article is also available in audio format. Listen now, download, or subscribe to \u201cHakai Magazine Audio Edition\u201d through your favorite podcast app.",
    "summary": "Welcome to another episode of *Wetland Wildlife Woes* at hakaimagazine.com, where the muskrat takes center stage as the unintentional villain in the soap opera of eco-drama. Listen, download, or torture yourself with the sonic version as the article valiantly tries to elevate the muskrat from pest to protagonist. Commenters chime in with tales from the front lines of personal ponds, making it clear that degrees in muskrat management are being handed out by Mother Nature herself. From heartfelt stories of muskrat massacres to celebrating their unintentional habitat engineering, it's clear we're dealing with marshland managers who think a rifle and a wheelbarrow qualify them for a wildlife management badge. \ud83c\udf3e\ud83d\udd2b\ud83d\udc00"
  },
  {
    "title": "Stack Overflow users deleting answers after OpenAI partnership (build5nines.com)",
    "points": 100,
    "submitter": "miles",
    "submit_time": "2024-05-08T21:16:53",
    "num_comments": 112,
    "comments_url": "https://news.ycombinator.com/item?id=40302792",
    "comments": [
      "About 5 years ago, StackOverflow messed up and declared that they were making all content submitted by users available under CC-BY-SA 4.0 [1]. The error here is that the users-content agreement was that all users' contributions are made available under CC-BY-SA 3.0 (and not anything about later). In the middle there were also some licensing problems concerning code vs noncode that were confusing.I remember thinking that if any of the super answerers really wanted, they could have tried to sue for illegally making their answers available under a different license. But I thought that without any damages, this probably wasn't likely to succeed.But now I wonder whether making all content available to AI scrapers and OpenAI in particular might be enough to actually base a case. As far as I can tell, StackOverflow continued being duplicitous with what license applies to what content for half of the year 2018 and the first few months of the year 2019. Their current licensing suggests CC-BY-SA 3.0 for things before May 5 2018, and CC-BY-SA 4.0 for things after. Sometime in early 2019 (if memory serves, it was after the meta post I link to), they made users login again and accept a new license agreement for relicensing content. But those middle months are murky.I should emphasize that I know nothing.[1]: https://meta.stackexchange.com/q/333089/205676",
      "> if any of the super answerers really wanted, they could have tried to sue for illegally making their answers available under a different license.they can plausibly sue people other than stackoverflow if they attempt to reuse the answers under a different license.  but i think it's very difficult to find a use that 4.0 permits that 3.0 doesn't",
      "3.0 has a \"bug\" that makes it risky to use materials without very careful attribution:https://doctorow.medium.com/a-bug-in-early-creative-commons-...",
      "I don't think this is a practical issue, really.I assume linking to the original answer is sufficient attribution.In the link you can find name, license and figure out if the answer was modified.Also linking the answer in a source comment is the smallest professional courtesy everyone should be doing.If you have some issue of not linking an answer then you likely do not deserve the answer in the first place.",
      "I'm actually perfectly fine if StackOverflow wants to sell an answer I made to help train AI.For me, the purpose of providing an answer is to help save others (and my future self) time, and I don't really mind if someone uses that in a private product - especially if it helps tools like ChatGPT which provide an insane amount of value given the low monthly price.",
      "The price to get an answer from stack overflow is usually free as most questions have already been asked and answered. You dont even need an account.",
      "Maybe a low price for you but not for everybody.",
      "The OpenAI partnership doesn't really affect the core issue here around users deleting their content. That has never been welcome on Stack Overflow and when noticed usually was reversed. This is in accordance with the license as far as I understand the legal aspects, and in general it makes sense for me as it ensures that the content stays useful.The content is also CC-BY-SA, which is much better than what you get on essentially every other large site that hosts community content. But the same license also means that you cannot remove that content again, even if Stack Overflow would allow that anyone else can scrape it or download it before it is deleted and reproduce it according to the license.Users still can remove their name from their posts, and if they write personal details those can be redacted as well. But you can't remove good quality content from the sites later, that is likely to be reverted.",
      "The problem isn't that Stack Overflow is allowing people to scrape the content. The problem is that Stack Overflow is preventing some people from scraping the content, in order to collect money from others. And, incidentally, passing zero of that money on to the people who actually created the content.(Nearly) none of the people who are presently pissed off would have complained if Stack Overflow had continued to allow all comers to scrape the content and train LLMs on it, nor if Stack Overflow had released the entire finished collection of content under the same CC-BY-SA license that was demanded of each contributor.With the OpenAI partnership, and similar shenanigans leading up to it, Stack Overflow is relying on obscure technicalities to violate the essential spirit of the original deal.",
      "Given the CC license, and the fact that contributors can apparently code, they should scrape the content and be done.Of course, that\u2019d mean bypassing the scraper blocker.  This article is a decent starting point:https://stackoverflow.com/questions/66413511/how-to-avoid-be..."
    ],
    "link": "https://build5nines.com/stack-overflow-upset-over-users-deleting-answers-after-openai-partnership/",
    "first_paragraph": "By Chris Pietschmann | May 8, 2024 - 9:14 AM EDT (13:14 UTC)Category: Artificial Intelligence",
    "summary": "**Stack Overflow Users Flee After Realizing AI Might Learn Something**\n\nIn today's episode of \"Big Tech Bad,\" Stack Overflow users are *melting down* after discovering the horrifying truth that answers they\u2019ve provided *for free* might be used to train AI algorithms. Cue the panic deletion of all traces of participation to stop OpenAI's sinister plan to make developers' lives easier. Commenters, pulling out their hair in clumps, argue over licensing nuances like Medieval scholars, clearly unsure if they're more upset about OpenAI\u2019s potential success or just nostalgic for Creative Commons disputes. Meanwhile, Stack Overflow politely reminds them that no one cares enough to scrape their Fibonacci sequence implementations anyway. \ud83d\ude43"
  },
  {
    "title": "English learners can now practice speaking on Google Search (research.google)",
    "points": 74,
    "submitter": "teleforce",
    "submit_time": "2024-05-08T21:09:20",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=40302731",
    "comments": [
      "Really cool, but why on earth is this in Google Search and not Translate?!",
      "\"Do one thing well\", a common Linux design philosophy, was blatantly ignored here. Search is not the place for this, sibling comment is likely right about trying to reach wider audience.Claude.ai and chatGPT have become my go to for translation over Google Translate, they provide better idiomatic context. They aren't perfect for code, but I can chat with them in target languages (outside of English) and they're pretty fluent.",
      "It\u2019s Unix, not Linux, philosophy fyi: https://en.m.wikipedia.org/wiki/Unix_philosophy",
      "To get wider audience? Don\u2019t know why they want that. Some audio data collecting?",
      "Better question is why the Google app exists. It's just a platform for kitchen sink projects that they could not be bothered to wrap a whole app around.",
      "Search, Assistant, Google, Gemini, ... It's all gSiri",
      "I used to use google's voice recognition a lot when learning Chinese. I would whip myself when it didn't understand me.So my horrible pronunciation is probably in the training data.",
      "Love this.I tried something similar with Google Translate, but for a different language. I'd attempt to say a phrase in my target language and see if it translates to what I was trying to say in English.",
      "In a way, I've been using Google tools to improving my english for a while now. A while back I was way more active on youtube, recording videos of my projects speaking english. I would then see the auto generated captions to see if the model had some trouble understanding what I was saying. Most of the time it was ok. Since I saw the model misunderstanding native english speakers as well.",
      "That's one way to gather massive amounts of high quality audio data to train their own Whisper AI.I like it. It's a win win in my book."
    ],
    "link": "https://research.google/blog/english-learners-can-now-practice-speaking-on-search/",
    "first_paragraph": "We strive to create an environment conducive to many different types of research across many different time scales and levels of risk.",
    "summary": "In yet another act of bored corporate omnipotence, Google decides that English learners should practice their \"hellos\" and \"how are yous\" via Google Search, because apparently, Google Translate was just *too* predictable. Commenters, always ready to parade their partially-informed tech philosophies, argue whether this is a feature creep or a sneaky ploy to scrape more voice data. Meanwhile, others boast about abusing Google's voice recognition to enhance their atrociously pronounced multilingual skills, inadvertently seasoning Google\u2019s data stew with their linguistic mishaps. It's a tech comedy of errors, but hey, at least it's a \u201cwin win\u201d until someone gets an ad for pronunciation classes."
  },
  {
    "title": "Adumbra: A lightweight Java library for bitmap steganography (github.com/galliumdata)",
    "points": 20,
    "submitter": "maxtardiveau2",
    "submit_time": "2024-05-06T18:34:30",
    "num_comments": 0,
    "comments_url": "",
    "comments": [],
    "link": "https://github.com/galliumdata/adumbra",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "In an astounding display of both underachievement and overstatement, a new Java library called Adumbra promises to revolutionize the ancient art of hiding messages where no one was looking anyway. The developers, swell with pride, assure us that every nugget of user feedback is a sacred scroll, guiding their path to mostly irrelevance. Meanwhile, the GitHub comment section, a notorious battleground of ego and one-upmanship, is ablaze with critiques from self-proclaimed security experts and at least three people who seem to think Java is still cutting-edge. None seem to grasp the only thing being hidden effectively is their grasp on practicality. \ud83d\ude48\ud83d\ude49\ud83d\ude4a"
  },
  {
    "title": "Using AirPods as a Morse Transmitter (github.com/etherdream)",
    "points": 121,
    "submitter": "etherdream",
    "submit_time": "2024-05-07T09:31:44",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=40283752",
    "comments": [
      "This is a cool toy, I've been wanting to do something similar with my flipper zero to make a BT morse keyboard.This also reminds me of TapXR, which I would totally buy if did morse, instead of inventing their own encoding. I get it, theirs is probably way faster but fluency is morse is more general purpose.",
      "> more general purposeJust how general purpose is it these days? I learned it for amateur radio (a couple years ago), which is probably the only \u201ccommon\u201d place to use Morse. And even there it\u2019s all but dead",
      "Continuous Wave / Morse is definitely not \"all but dead\".  In fact, it's in literally continuous use, 24/7, worldwide.  If you turn on an HF radio (and have an antenna up) and tune to an open band, you will hear morse code.Go here and see a live map of CW contacts picked up by the Reverse Beacon Network in the past 10 minutes (only the most recent 100, which is the most I could get it to show at once):  https://www.reversebeacon.net/main.php?zoom=44.44,6.37,2.40&...",
      "It's getting more and more popular within amateur radio. If I look on the Parks On The Air spots page, there are currently 20 people in a park across the US doing Morse, and I know that when I go to a park I can knock out 60 Morse contacts in about an hour on one band since there are so many hunters.Clubs like Long Island CW have thousands of members and run classes all day to teach people Morse and help with their operating skills. Just this morning I joined the weekly CWOps mini contest which is so popular they have it in 4 x 1 hour sessions. And that's on top of the 3 medium speed sessions on Mondays, and 2 slow speed ones.There might not be as much ragchew activity but between contests, DXers, and POTA, there's CW activity all over the bands.",
      "There was a downswing awhile ago because the macro users switched to using digital modes. People who want to make handmade CW contacts are still having fun and that is attracting some people to the space.Also, knowing Morse has been my escape room superpower. Escape room designers love Morse.",
      "Well put. It is fun.",
      "A while ago I hooked up the ambient light sensor of android devices as morse input for Emacs: https://www.youtube.com/watch?v=IBrvhiiZyf8",
      "Straight out of Cryptonomicon",
      "Awesome. This is why I come to Hacker News.",
      "Because of how it works you can also key using the pause and next multimedia buttons on your keyboard.  Now we need to make the snake eat its tail by rigging an Iambic paddle to send pause/next events."
    ],
    "link": "https://github.com/EtherDream/headphone-morse-transmitter",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.",
    "summary": "In the latest display of <i>resurrecting long-lost tech with gadgets you can't seem to find anymore</i>, a daring soul has hacked their AirPods to transmit Morse code, because relaying \"SOS\" using blinks on Bluetooth devices screams peak innovation. The comment section inevitably turns into a nostalgia fest as hobbyists who obviously dwell in their own DIY bubbles hail the invention as the Second Coming of Samuel Morse. Between dropping URL breadcrumbs for anyone who might care and shouting out their Morse-themed club memberships louder than a CW transmission at peak hours, it's clear the commenters are just <em>begging</em> for validation on their shaky choice of a dying art. Ah, the Morse code\u2014still relevant to dozens worldwide! \ud83d\udcfb\ud83d\udcac"
  },
  {
    "title": "Breathwork supports emergence of altered states of consciousness (researchsquare.com)",
    "points": 35,
    "submitter": "rendx",
    "submit_time": "2024-05-08T19:54:58",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=40302200",
    "comments": [
      "Is circular breath work just hyper ventilating?",
      "Holotropics has been around for quite a while and some yoga pranayamas also can lead to altered states. I have to admit I find mushrooms easier to deal with.",
      "Ross and Carrie covered this on their podcast back in 2017, they had out of body experiences I believe. Link: https://ohnopodcast.com/investigations/2017/10/21/ross-and-c...",
      "I wonder what other effects this has on the body.  The signaling around CO2 levels does a lot to cellular respiration everywhere, not just the brain (think krebs cycle, etc).",
      "There's a product out, Freespira, that does breath work training monitored by a nasal cannula, to help people who experience panic attacks. The theory is that such people are chronic hyperventilators, so their blood CO2 is too low for the parasympathetic nervous system to operate correctly.It didn't end up being a good fit for me, but if a person's PTSD comes from discrete events rather than a continually unsafe environment in early childhood, I think they'd have a better experience. (My parasympathetic nervous system never learned how to operate correctly, but if someone else's did and its function got interrupted later, I think their experience would be different.)",
      "Strange side note. I've tried n-acetylcysteine as a supplement/medication, the weirdest thing about it is that I felt like I needed to breathe less often. And like I was breathing manually - which you are also doing now, ha.I wonder if it helps with panic attacks.",
      "Interesting! Thanks for the pointer.",
      "What about LSD"
    ],
    "link": "https://www.researchsquare.com/article/rs-3976380/v1",
    "first_paragraph": "",
    "summary": "In the latest attempt to repackage breathing with a fancy title, the internet has unearthed the startling revelation that _overdoing_ your inhale-exhales can make your head feel funny. Researchsquare baffles the scientific community by suggesting that ***gasp*** altering breathing patterns could be synonymous with inhaling three bags of Haribo in one go, leading to states of consciousness previously only accessible through drugs or hitting your head really hard. The comment section, a veritable enlightenment festival, complements the study with profound arguments comparing holotropic breathwork to magic mushrooms, while debating the finer points of body chemistry like they've just binge-watched a half-season of \"Breaking Bad.\" One enlightening soul even tries to shift this hot air festival to an online shop selling nasal gadgets for panic attacks, because nothing says \"calm down\" like shoving tubes up your nose."
  }
]