[
  {
    "title": "Spice: Fine-grained parallelism with sub-nanosecond overhead in Zig (github.com/judofyr)",
    "points": 103,
    "submitter": "dsp_person",
    "submit_time": "2024-08-12T23:01:37",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41230344",
    "comments": [
      "I haven\u2019t read through the code in detail but I can tell you \u201csub-nanosecond overhead\u201d is misleading and marketing fluff. On first look, the measure seems to be some convoluted \u201ctime per thing\u201d where the number of threads is far far smaller than the number of \u201cthing\u201ds\n \nreply",
      "That is the ecological niche of Rayon (cited) as well, isn\u2019t it? You need to process a lot of things (thousands to millions), you want to parallelize that processing as much as possible (couple dozen of cores tops), you want to not get killed by scheduling overhead. So you account for the per-thing overhead.\n \nreply",
      "For people who want to find faults with the project[0].[0]: https://github.com/judofyr/spice?tab=readme-ov-file#limitati...\n \nreply",
      "Want to state off the bat this this project is awesome and huge kudos to the author for spending their time, attention, and energy 1) working diligently to get this working at all and 2) sharing it with the broader HN community, who are generally known to by hyper-critical to a pedantic degree and/or overly pessimistic (cough the initial Docker project Show HN thread cough)I also really appreciate that the author recognizes the limits of their own project, which preemptively addresses most of the usual snark.> Lack of tests: Spice contains a lot of gnarly concurrent code, but has zero testing coverage. This would have be improved before Spice can be responsibly used for critical tasks.Testing correctness of execution for critical tasks is one thing, but I would expect a library which implements \"gnarly concurrent code\" to at least have regression tests \u2014 what guarantee is there to an end-user that functionality which exists in a working state today might not break tomorrow due to a subtle yet nefarious regression?sqlite has 590 times as much test code and test scripts as it does raw c source code [0]; this fact, along with its stability and portability, is one of the numerous reasons why it has proliferated to become the defacto embedded database used across the planet. While we're comparing apples to oranges in this contrived example, the general point still stands \u2014 regression tests beget stability and confidence in a project.In epics where I work, if we _must_ defer baseline regression tests, we usually create a follow-up ticket inside of the same epic to at least write them before feature/epic launch, usually.[0]: https://www.sqlite.org/testing.html\n \nreply",
      "You are welcome to add it. This is a proof of concept\n \nreply",
      "> Spice is primarily a research project. Read along to learn more about it, but if you're considering using it in production you should be aware of its many limitations.Ah, I missed that upon first read. In that case, that caveat/limitation is definitely justified.\n \nreply",
      "see also readme under bench https://github.com/judofyr/spice/blob/main/bench/README.md\n \nreply"
    ],
    "link": "https://github.com/judofyr/spice",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fine-grained parallelism with sub-nanosecond overhead in Zig\n      Spice uses heartbeat scheduling to accomplish extremely efficient parallelism in Zig:The benchmark in the figure above (summing over the nodes in a binary tree) is typically one of the worst cases for parallelism frameworks:\nThe actual operation is extremely fast so any sort of overhead will have a measurable impact.Here's the exact same benchmark in Rayon, an excellent library in Rust which uses work-stealing fork/join:The overhead here is roughly ~15 ns (from 7.48 ns to 22.99 ns) which means that at 4 threads we're \"back\" to the sequential performance - just using four times as much CPU.\nLuckily we are able to get linear speed-up (in terms of threads) initially.\nThese benchmarks were ran on a c4-standard-16 instance in Google Cloud with 16 cores.\nRayon itself shows",
    "summary": "\ud83d\ude80 <em>Welcome to Spice:</em> The latest attempt to squeeze every nanosecond of efficiency out of fine-grained parallelism, because throwing hardware at the problem is just too mainstream. \ud83e\uddd0 The GitHub crew is buzzing \u2014 half can't seem to decide if \"sub-nanosecond\" is a real metric or smoke and mirrors, while the other half is busy worshiping the ground the coders walk on for their \"groundbreaking\" heartbeat scheduling. Spoiler: it's mostly just a proof of concept, but don't tell that to the zealots arguing over theoretical performance gains as if they're going to refactor all their legacy systems with this over the weekend. Stay tuned for the <i>Spice GitHub Issues Page</i> \u2014 it's going to be a rollercoaster of unchecked optimism versus soul-crushing reality checks. \ud83c\udfa2\ud83c\udf7f"
  },
  {
    "title": "Repair and Remain (2022) (comment.org)",
    "points": 428,
    "submitter": "yarapavan",
    "submit_time": "2024-08-12T16:06:42",
    "num_comments": 173,
    "comments_url": "https://news.ycombinator.com/item?id=41226039",
    "comments": [
      "The other day, I was thinking about how important a good handyman is for my mental health. I used to fix things myself, but spending all my free time doing home repair was withdrawing from the limited bank account of my personal sanity. Having the house broken open for months while I picked away at it after work and on weekends was bad for morale, too. And doing the work myself was sometimes dispiriting rather than empowering\u2014If someone else makes a mistake, even if I'm paying them, I can for whatever reason tolerate that with less frustration than when I screw up myself. Accepting that I am lucky enough to have a surplus of money that I can exchange for time and serenity was a big step for me. My conclusion was that cultivating a relationship with a good handyman is of as much value for me as any other long term service relationship: doctor, therapist, waitress, barista, etc. So, even though I'm not married and not having relationship angst per se, this article makes sense to me through that reinterpretation.\n \nreply",
      "It does come down to mindset.   I do my yard work, 1 acre, mowing, edging, trimming, leaf blowing, raking, etc.    My entire mindset when I do it is, \"It's exercise\".   I do car repairs and own 2 classic cars.  My mindset is \"It's yoga!\"   There's the fun of figuring out how to solve problems I haven't, I work with computers all day and I get to work with my hand.   My family gets to see me do things and it's very important for them to know they can do things and solve problems by themselves, I sometimes involve them so it's not me alone but a family thing.   The mindset is very important.  allow yourself to make mistakes, have fun with it.  It's never been this easy!   First go to youtube, watch a few videos, read a book or blog and get to work.  What I find that makes it frustrating for a lot of people is not having the proper tools, extra hands if needed and knowledge.\n \nreply",
      "If it\u2019s your gardens or your toy car it\u2019s a different experience than if it\u2019s your family bathroom or family car. There is time pressure and angst at not having your daily use things in working order\n \nreply",
      "If it is your family bathroom or car, if you have worked on it before, chances are that you can deal with a problem on the spot thanks to the skills you learned and the tools you got for the occasion. No need to wait for the handyman. \nAnd if it is a problem you can't solve, you may also have better understanding, which makes explaining the situation to a professional easier.\n \nreply",
      "The entire premise here is that's not the case.  The repair/remodel drags out because you're doing it in your spare time, and mistakes and setbacks are a drag on your motivation.  Meanwhile you and your family aren't able to use your main bathroom (or whatever), and that stresses you out, makes you feel guilty that progress isn't happening faster.I get this, and will call a handyman for some jobs, but I try to do repairs and \"upgrades\" myself when the work seems manageable to me.\n \nreply",
      "If there was a physical \"undo\" button, I could get behind this philosophy; however I notice neither a compiler to point out small mistakes nor an undo to help out with big mistakes. Having transformed some small plumbing things from easy to fix to really expensive to fix, I'm happy to know I live in a society with some degree of specialization. The plumber mightn't know they need to have good error handling policies, but they use my company's products, and we all go home happy. (This is also why I'm not in ops, except the odd heroic fire-fighting exercise; when I'm bored I like to change things to increase my knowledge of how it all works; I need worried and steady co-workers to keep things running).\n \nreply",
      "> If there was a physical \"undo\" button, I could get behind this philosophyI had two reactions to this -The first is that's part of why I like working on low-stakes physical projects - especially when I'm working in my garden, I'm almost aggressively improvisational, just trying to use whatever's on hand to do the job and fixing things as I go. Because the garden is mine and just an absolute hobby, I get to play around, and the feeling of satisfaction I get from cobbling something together to solve a problem easily matches delivering a carefully-done plan.The second is that undo button makes us sloppy. I noticed this the first time I went into management - the hardest part of the job was I had no idea if I'd done something right and no way to do it again if I didn't. It's made me sloppy a few other places as well, where I've found myself staring at something and thinking \"well shit, there's no undo here, is there?\" I think spending some time with some things that have stakes and can't be undone is healthy, and I think programming somehow makes us both sloppier and more risk-averse by its almost unbounded undo-ability.\n \nreply",
      "Parenting was where I learned how to live with the lack of an undo. One gets used to it, but I find cyberspace much easier:  I can try 1000 things in a few days and come out with a solution that seemed maybe impossible up front. Although one does get many chances to hone the interactions with kids, mistakes are not zero cost :) and once the parent and kid really master something, the kid grows a bit and the old solution reaches the end of its validity.I would emphasize both that the undo-ability is very freeing and that the compiler/tests guardrails let one focus on the novel part rather than the routine part.\n \nreply",
      "Hah easy to have this mindset on your fun projects than your commuter.Rejetting carbs on your motorcycle that you use for commuting, goes from a fun weekend project to 1AM Monday morning nightmare really quick. :)\n \nreply",
      "Oh man, I got to \"rejetting carbs\" and had the momentary urge to toss a chair out a window and then dive out after it. Kudos if you'll do your own carb work, that's where I draw the line.\n \nreply"
    ],
    "link": "https://comment.org/repair-and-remain/",
    "first_paragraph": "",
    "summary": "\ud83d\ude44 In today\u2019s episode of \"I Read Half an Article and Became a Guru,\" comment.org dribbles out a homily on *why paying people to fix things is actually self-care*, triggering an avalanche of DIY saints in the comments. \ud83d\udee0\ufe0f One hero turns mowing his lawn into a spiritual retreat, while another dreams of an \"undo\" button for life's pesky non-digital mistakes. And, oh, the agony and enlightenment of tricky car repairs that make one commenter want to hurl furniture from a window. \ud83d\udca1 Prepare for a masterclass in conflating home repairs with existential philosophy, because handymen are just therapists you can pay to unclog your drains."
  },
  {
    "title": "There Is No Antimemetics Division (2018) (qntm.org)",
    "points": 494,
    "submitter": "squircle",
    "submit_time": "2024-08-12T13:37:42",
    "num_comments": 171,
    "comments_url": "https://news.ycombinator.com/item?id=41224225",
    "comments": [
      "This book got me through some tough times. It's one of my favorite pieces of literature. It deserves to be a classic 100 years from now.Part of why it works is by the nature of its subject, the book and its various plot points and devices serve essentially as metaphors for almost anything-- anything related to how humans communicate and remember.It's not just superficially a fun sci-fi romp, it's also a story about the stories we tell ourselves and each other, about how we assign meaning to events, among other things. It reminds me just a very little of Godel Escher Bach, but I like this one better. I am also reminded of Lewis Carroll, and the cryptic quote that \"through the looking glass is the best book on mathematics for the layman, since it is the best book on any subject for the layman\"It is poetry. It is a Rorschach blot about Rorschach blots. I can't recommend it enough.\n \nreply",
      "> the book and its various plot points and devices serve essentially as metaphors for almost anythingThat is interesting. Coincidentally (or not?), I was just thinking about an excellent article about parent-child estrangement that begins like this:    Members of estranged parents' forums often say their children never gave them any reason for the estrangement, then turn around and reveal that their children did tell them why. But the reasons their children give\u2014the infamous missing reasons\u2014are missing.\n\nApparently, such reasons are a good example of antimemetic ideas in real life.\n \nreply",
      "Can confirm, lived exactly that situation.I think you can generalize it about any information that would shatter your identity.It's the reason some people will tell you Arch Linux worked perfectly on their machine despite having plenty of problems.The reason why people adopting a religion, a diet or new sexuality will probably not tell you if they are unhappy about the consequences.Graham did say we should keep our identity small: https://paulgraham.com/identity.html\n \nreply",
      "> It's the reason some people will tell you Arch Linux worked perfectly on their machine despite having plenty of problems.I feel personally attacked\n \nreply",
      "> an excellent article about parent-child estrangementPreviously featured on HN, submission with most comments: https://news.ycombinator.com/item?id=28231239\n \nreply",
      "Bought it due to your recommendation. Will start after I finished The Will to Battle by Ada Palmer\n \nreply",
      "Is it just me or are these books just astonishingly good? Like\u2026 sometimes k come across media at juuust the right time and (emotional) place and they\u2019re amazing but on review merely good.I\u2019m immediately re-reading them and they\u2019re just as good - if not better - the second time.Quickly became my favorite books of all time, which you\u2019ll have to trust me is saying something.\n \nreply",
      "I enjoyed reading your insights. I just happen to be re-reading this book right now; I also find it both well-layered and entertaining. These stories reward repeat visitors!\n \nreply",
      "If you like this kind of thing, the rest of qntm's work is definitely worth checking out - as evidenced already in several comments. Another good pointer to follow is to Unsong and Scott Alexander's other fiction (all shorts, spread through his old blog Slate Star Codex and new blog Astral Codex Ten).Both of those were already mentioned, so let me drop a recommendation for something new - Worm, the first (and absolutely massive) book in Wildbow's Parahumans series. Iirc it's longer than all 5 published ASOIAF novels combined, so it's a big commitment, but that length moves through a ton of different arcs. It's centered around a \"superheroes\" kind of scenario with a level of analysis and thought that'll tickle the fancy of certain kinds of nerds. The main character's power is to control bugs - and it's a lot of fun to see the author make that seemingly lame power into something incredibly useful and lethal. It's just a fun read overall, lots of room to nerd out about it. I haven't read the sequel yet, but I've read good things.Also, though they're more mainstream, Greg Egan and Ted Chiang are some of the best spec-fic / sci-fi authors I know of, and do a similarly great job of breaking down interesting concepts into compelling stories.\n \nreply",
      "Seconding all of the recommendations. Wildbow (author or Worm) has a number of other works (Twig got rave reviews; I\u2019m uncommon in liking Pact)And, if you like those\u2026 I\u2019ll also recommend Practical Guide to Evil (and that author\u2019s next and in-progress work, Pale Lights)\n \nreply"
    ],
    "link": "https://qntm.org/scp",
    "first_paragraph": "An antimeme is an idea with self-censoring properties; an idea which, by its intrinsic nature, discourages or prevents people from spreading it.Antimemes are real. Think of any piece of information which you wouldn't share with anybody, like passwords, taboos and dirty secrets. Or any piece of information which would be difficult to share even if you tried: complex equations, very boring passages of text, large blocks of random numbers, and dreams...But anomalous antimemes are another matter entirely. How do you contain something you can't record or remember? How do you fight a war against an enemy with effortless, perfect camouflage, when you can never even know that you're at war?Welcome to the Antimemetics Division.No, this is not your first day.You can buy There Is No Antimemetics Division in the following formats:There Is No Antimemetics Division was originally created for the SCP Foundation wiki. Read it in its original format here:That hub page also has links to background mater",
    "summary": "**There Is No Antimemetics Division (2018) (qntm.org)**  \nIn a daring bid to appear intellectual while actually pushing digital pages about forgettable concepts, qntm.org redefines irony by discussing ideas meant to be inherently unshareable, yet markets a whole book about them. Commenters, in a delightful display of missing the point, deeply connect with these \"unshareable\" ideas, waxing lyrical about everything from their personal life crises to unrelated tech and fantasy books. One reader even claims the book as a life-changing classic, likely forgetting they can't even remember why. In this chaotic mix of self-contradiction and broad philosophical shots in the dark, perhaps the true antimeme is why anyone thinks their \"profound\" take here is anything short of hilarious. \ud83e\udd14"
  },
  {
    "title": "Show HN: I built an animated 3D bookshelf for ebooks (github.com/mawise)",
    "points": 154,
    "submitter": "mawise",
    "submit_time": "2024-08-12T17:53:36",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=41227350",
    "comments": [
      "Nice! Many, many years ago, when Shelfie was shutting down, I was imagining we might want VR bookshelves one day, and I convinced Brewster to store Sheflie's spine and cover images over at the archive. Might be worth reaching out to see if they still have them. Spine images are a little hard to get; they're not part of the Amazon API, for instance.\n \nreply",
      "Not a bookshelf, but it reminds me of something that Stripe did something similar here which is equally as cool.https://press.stripe.com/\n \nreply",
      "Looks great. Though while I love me some skeuomorphism, it goes too far when it is plainly detrimental to usability, which it is here - I have to crane my neck sideways to read the titles. In a virtual world, the books could be stacked horizontally so that the titles are readable with user head upright.\n \nreply",
      "Super cool - reminds me of the Stripe press website https://press.stripe.com/\n \nreply",
      "Very cool! I love the animation. I worked on a similar interface inspired a while back for Open Library: https://openlibrary.org/explore . You have to go to \"Settings > Book style > 3d-spine\" to enable the effect\n \nreply",
      "You just\u2026 built exactly the thing I was working on. Except it looks better.I\u2019ve had this before, but I figured this project would be small and niche enough that it\u2018d never happen. Crazy shit.\n \nreply",
      "This is awesome!If we want to extend this to be a whole virtual library, are there datasets that people know about for book covers?One thing that would be cool is book spine datasets!\n \nreply",
      "Open library has covers/metadata; alas no spines! I built an interface similar to this for Open Library using library classifications for sorting: https://openlibrary.org/explore\n \nreply",
      "Most ebooks have embedded cover images that Calibre will automatically extract. I know of https://isbndb.com/ which has covers of some resolution but I've never tried using them before.\n \nreply",
      "Good q! Check my other comment here about spine images.\n \nreply"
    ],
    "link": "https://github.com/mawise/bookshelf",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        3D animated bookshelf for ebooks\n      Inspired by [https://scastiel.dev/animated-3d-book-css] and [https://github.com/janeczku/calibre-web]This is a 3D bookshelf to browse ebooks. It pulls ebook metadata and cover art from a Calibre library.  It uses the cover image aspect ratio to determine book height, all books are the same width.  It uses page-count data (if available) to determine the thickness of the book.  The Calibre comment metadata shows up as the back-cover text along with a book download link and page count.Special thanks to Brandon Sanderson and Cory Doctorow who publish their books without DRM, and to Standard Ebooks and Planet Ebook for beautifully typeset public domain ebooks.Optionally: Install the count pages Calibre plugin to make the books variable-width based on estimated page counts.  Configure the plugin with",
    "summary": "<h1>Show HN: The Quest for a Less Boring PDF Reader</h1>\n<p>In yet another earth-shattering innovation for digital hoarders, a plucky Hacker News user submits a \"3D animated bookshelf\" to revolutionize the mundane act of selecting an <em>ebook</em>. Because nothing says \"I read\" like spending hours on visual gimmicks instead of, you know, actually reading.</p>\n<p>Commenters, likely nostalgic for the three-dimensional joys of actual bookshelves, fawn over the digitally resurrected spine views, while engaging in the customary competitive reminiscence of \"I thought of this first back when VR was just a twinkle in Zuckerberg's eye.\" Meanwhile, practical considerations such as ease of title reading and functionality die a quiet, mournful death to a chorus of \"super cool!\" and desperate requests for spine databases. Truly, we are witnessing the pinnacle of tech innovation.</p>"
  },
  {
    "title": "Open source laser microphone picks up laptop keystrokes (wired.com)",
    "points": 67,
    "submitter": "bookofjoe",
    "submit_time": "2024-08-10T14:48:13",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41209900",
    "comments": [
      "Related to this Applied Science on YouTube has a pretty cool video where he demonstrates how a single laser diode can be used to measure miniscule vibrations. I wonder if this would be sufficient for a laser microphone?https://www.youtube.com/watch?v=MUdro-6u2Zg\n \nreply",
      "Wish they had waited to publish for when he had posted the plans. I am also curious to see the BOM, because in the article it said he spent thousands on equipment, so I hope that was V1, and a working model can be had for a more modest budget.Supposedly the White House uses vibrating windows to avoid this class of attacks.\n \nreply",
      "I'm also super excited to see more on this, it's been living rent free in my head for a long time. I played around with keypress extraction from sound recordings a couple decades ago in college, and it was remarkably straightforward to extract keypresses based on sound signals, even with zero training - based on the time between keypresses and the unique signature of space/return/backspace you can build a predictor pretty quickly. We never made it to the \"bounce a pair of lasers off two window panes a known distance apart and triangulate everyone's keyboard\", but it was one of those things that's definitely doable with enough time and brains.\n \nreply",
      "The main countermeasure is just curtains with a bit of weight to them.\n \nreply",
      "Human element is going to thwart your countermeasure when they want to let in some light.\n \nreply",
      "Article title: Watch How a Hacker\u2019s Infrared Laser Can Spy on Your Laptop\u2019s Keystrokes\n \nreply",
      "If I'd submitted that title it would have been flagged as clickbait in a Hacker News moment.\n \nreply",
      "I wonder what stopping three letter agencies to secretly push for keyboard manufacturers in such way that each keystroke has unique sound and it becomes easier to detect keystrokes.\n \nreply",
      "If you are such a person of interest that the government is observing your computer usage, the game is already lost.\n \nreply",
      "no need, keystrokes are sufficiently unique.even if its not, enough decent fidelity data with letter/word frequency analysis \n paired with small Neural net will quickly disambiguate keystrokes after the first paragraph.\n \nreply"
    ],
    "link": "https://www.wired.com/story/infrared-laser-microphone-keystroke-surveillance/",
    "first_paragraph": "To revisit this article, visit My Profile, then View saved stories.In a famous scene from the 1992 movie Sneakers, a hacker classic, the main characters park a surveillance van across the street from their target's office and point a telephoto lens through his window\u2014only to find that their view of his computer keyboard is blocked by the surprise entrance of his love interest at the precise moment when he types his password. The surveillance team ends up watching and rewatching their partially obstructed VHS video of his keystrokes, bickering comically about the layout of a QWERTY keyboard.Today, with a few decades of surveillance tech advancements and some clever feats of physics, all it would take to grab that password\u2014as well as anything typed on the computer, or, for that matter, every word spoken in the room\u2014would be a well-aimed infrared laser.At the Defcon security conference this weekend in Las Vegas, renowned hacker Samy Kamkar plans to debut his own DIY advances in a form of ",
    "summary": "In a feeble attempt to democratize espionage, <em>Wired</em> regurgitates the plot of a 90s hacker movie to introduce the latest alarming use of technology: using lasers to spy on your extremely important, national-security-threatening diary entries. Hacker Samy Kamkar throws a bunch of money at a project just to prove it can be done, while eager commenters salivate over the potential to recreate their own spy fantasies on a budget. The irony that no one has the time or interest to actually spy on them is lost amidst technical jargon and references to outdated pop culture. One commenter wisely points out that a heavy curtain merely dismisses this high-tech paranoia, but don\u2019t worry\u2014their counter-countermeasure is already to just open the window. \ud83d\udd75\ufe0f\ud83d\udd34\ud83d\udd0d"
  },
  {
    "title": "Federal appeals court finds geofence warrants \"categorically\" unconstitutional (eff.org)",
    "points": 322,
    "submitter": "computerliker",
    "submit_time": "2024-08-12T19:57:57",
    "num_comments": 121,
    "comments_url": "https://news.ycombinator.com/item?id=41228630",
    "comments": [
      "> Unsurprisingly, however, the court found that in 2018, police could have relied on such a warrant in \u201cgood faith,\u201d because geofence technology was novel, and police reached out to other agencies with more experience for guidance. This means that the evidence they obtained will not be suppressed in this case.That the guy's case gets a right affirmed yet in his individual case it won't make a difference has to be a pretty bitter pill to swallow.\n \nreply",
      "I am not a lawyer, but the language of the opinion [1] seems to indicate that the geofence itself is not admissible, but evidence obtained as a result of it is still admissible:> On November 4, 2022, Smith filed a Motion to Suppress\u2014\nwhich the other Appellants joined\u2014seeking to suppress all evidence derived\nfrom the November 2018 geofence warrant which was used to identify them\nas suspects.They were identified as suspects, and further investigation produced more evidence, which formed the case. What they are saying is that the good faith exception prevents this from tainting all derived evidence in this case, which seems reasonable.The good faith exception is an exception to the exclusionary rule, not to the admissibility of the evidence itself.[1] https://www.ca5.uscourts.gov/opinions/pub/23/23-60321-CR0.pd...\n \nreply",
      "> the opinion [1] seems to indicate that the geofence itself is not admissible, but evidence obtained as a result of it is still admissibleThat means they can geofence to get a short list of suspects, and then file proper warrants for some of them if they have more clues?\n \nreply",
      "Not anymore, now that this precedent is set.\n \nreply",
      "I'm still wondering how this precedent prevents parallel construction nonsense\n \nreply",
      "There was a warrant in this case.  That type of warrant is now deficient and electronic data holders like Google with easily refute future attempts to get data with a clearly deficient warrant.  Parallel construction typically means a warrant was not given on the first pass.\n \nreply",
      "It doesn't encourage Parallel construction unless you think any restriction on warrants does.\n \nreply",
      "In this case it\u2019s pretty simple: they won\u2019t be able to obtain geofence warrants in the future.\n \nreply",
      "So now we just have to rely on Google/Apple/cell-carriers to not hand over all the geofence data without a warrant. I'm sure the cops will be leaning _heavily_ on 3rd Party Doctrine next time they call up Google with their warrantless geofence data requests.\n \nreply",
      "This precedent doesn't prevent parallel construction at all. In fact, it encourages parallel construction.\n \nreply"
    ],
    "link": "https://www.eff.org/deeplinks/2024/08/federal-appeals-court-finds-geofence-warrants-are-categorically-unconstitutional",
    "first_paragraph": "In a major decision on Friday, the federal Fifth Circuit Court of Appeals held that geofence warrants are \u201ccategorically prohibited by the Fourth Amendment.\u201d Closely following arguments EFF has made in a number of cases, the court found that geofence warrants constitute the sort of \u201cgeneral, exploratory rummaging\u201d that the drafters of the Fourth Amendment intended to outlaw. EFF applauds this decision because it is essential that every person feels like they can simply take their cell phone out into the world without the fear that they might end up a criminal suspect because their location data was swept up in open-ended digital dragnet.The new Fifth Circuit case, United States v. Smith, involved an armed robbery and assault of a US Postal Service worker at a post office in Mississippi in 2018. After several months of investigation, police had no identifiable suspects, so they obtained a geofence warrant covering a large geographic area around the post office for the hour surrounding t",
    "summary": "The Federal Fifth Circuit has gallantly declared geofence warrants a no-go, aligning perfectly with the EFF's glittering dreams of a surveillance-free utopia. Commenters, in a show of unmatched legal expertise garnered from years of watching courtroom dramas, debate the nuances of \"good faith\" exceptions and parallel construction like they're finalists in a mock court competition. Given the court's decision, armchair lawyers on the internet reassure us that our future ventures outside with our smartphones might finally be free from Big Brother's watchful eyes, overlooking the minor hiccup that geofence data can still play peekaboo in ongoing investigations. So sleep tight and text freely, because the comment section has it all figured out. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udcf1\ud83d\udcac"
  },
  {
    "title": "Faster Docker builds using a remote BuildKit instance (blacksmith.sh)",
    "points": 11,
    "submitter": "adityamaru",
    "submit_time": "2024-08-13T00:11:04",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41230794",
    "comments": [
      "30 minute docker builds?  Crazy.I know it is out of style for some, but my micro service architecture, which has nearly a dozen services, each takes about 1:30m to build, maybe 2m at most (if there is a slow Next.js build in there and a few thousand npm packages), and that is just on a 4 core GitHub Actions worker.My micro services all build and deploy in parallel so this system doesn't get slower as you expand to more services.I would struggle to make this take 5m or more so I am confused on what people are doing here in his dockers that take 30 minutes.I have an open source template setup here that shows how it works:https://github.com/bhouston/template-typescript-monorepo/act...\n \nreply",
      "I really am hopeful we come a bit full circle on builders and machines to \"we buy one or two very expensive machines that run CI and builds\". Caching in particular is just sitting there, waiting to be properly captured, instead of constantly churning on various machines.Of course, CI SaaSes implement a lot of caching on their end, but they also try to put people on the most anemic machines possible to try and capture those juicy margins.\n \nreply",
      "> we buy one or two very expensive machines that run CI and buildsThis unfortunately does not work for orgs that have, say, more than 20 engineers. The core issue is that once you have a test suite large enough to have ~30 shards, you only need one engineer `git push`ing once to saturate those 1-2 expensive machines you've got sitting in the office.The CI workload is quite amenable to \"serverless\" when you get to a large enough org size, where most of the time you actually want to pay nothing (i.e. outside your business hours) but when your engineers are pushing code, you want 1500 vCPUs on-demand to run 4 or 5 test suites concurrently.\n \nreply",
      "This is basically what we do, except we use Earthly[1]. An Earthly satellite is basically a modified remote Docker Buildkit instance.[1]: https://earthly.dev/\n \nreply",
      "I prefer to use a VPS\n \nreply",
      "What provider do you prefer? We're big fans of Hetzner\n \nreply"
    ],
    "link": "https://www.blacksmith.sh/blog/faster-docker-builds-using-a-remote-buildkit-instance",
    "first_paragraph": "Docker has fundamentally changed how developers build and deploy applications, with most companies leveraging containers in some capacity. At Blacksmith, we regularly see our customer\u2019s Docker builds taking 30 minutes or more, which can significantly hinder developer productivity and delay the deployment of hot-fixes.In this post, we\u2019ll give you the exact steps needed to setup a remote BuildKit instance on AWS. The 30 minutes it\u2019ll take to follow this blog can dramatically speed up your Docker builds for your entire org. But before diving deeper, let's review some Docker fundamentals. There are three primary levers one can pull to optimize Docker build times:BuildKit is a modern backend that replaces the legacy Docker builder, offering improved performance and new features.However, the most relevant feature for our use case is BuildKit's ability to execute builds on a remote instance. This lets us offload the build process from the local machine to a more powerful remote server.BuildKi",
    "summary": "**Faster Docker Builds: Leverage Your Free Time Waiting!**\n\nIn a world where developers might actually enjoy their coffee still hot, Blacksmith introduces a mind-blowing concept: using *fancy* remote AWS BuildKit instances to get Docker builds done before the heat death of the universe. Because waiting 30 minutes for a build is apparently a problem searching desperately for a more complicated solution. Commenters compete in a low-key humblebrag fest about whose microservices can compile faster than a teapot whistles\u2014of course, all while claiming total confusion about what ancient tech practices necessitate such lengthy build times. Meanwhile, others dream of returning to the golden age of \"big iron\" machines, lamenting over modern CI practices like someone yearning for the return of the floppy disk. \ud83d\ude22\ud83d\udcbe"
  },
  {
    "title": "NASA investigation finds Boeing hindering Americans' return to moon (flyingmag.com)",
    "points": 126,
    "submitter": "hobermallow",
    "submit_time": "2024-08-12T20:38:27",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=41229049",
    "comments": [
      "> During a visit to Michoud in 2023, for example, inspectors discovered that welding on a component of the SLS Core Stage 3 did not meet NASA standards. Per the report, unsatisfactory welding performed on a set of fuel tanks led directly to a seven-month delay in EUS completion.> \u201cAccording to NASA officials, the welding issues arose due to Boeing\u2019s inexperienced technicians and inadequate work order planning and supervision,\u201d the OIG says. [...]Welders are highly qualified and well-paid craftsmen. Wouldn\u2019t surprise me if they\u2019d been hit particularly hard by management that doesn\u2019t value tenured, expensive employees.\n \nreply",
      "You must have seen how beautiful the welds are on the Rocketdyne F-1 joints. Whoever made those put pride in their work.\n \nreply",
      "If anyone else is curious this article has close-up photos of the joints: https://arstechnica.com/science/2013/04/how-nasa-brought-the...\n \nreply",
      "A welding book I had mentioned that stick welding aluminum is no longer done because it is too hard and used the F-1 stick welds as an example of such welds.  I think they we not so much welds as strategic strengthening.\n \nreply",
      "I guess they felt, correctly, that they were not just making a weld, not just making an engine or a rocket, but helping to put people on the moon. \"Building a cathedral\", indeed.\n \nreply",
      "Having NASA come and test stuff.. Creates a 'see what sticks' kind of attitude. Eat your own dogfood\n \nreply",
      "The obvious patch for this is to have monetary penalties for failing inspection written into the contract, so that submitting shoddy work has a price measured in dollars. Money is the unit of caring, at least at a corporate scale, so there needs to be money involved if you want them to care systematically.(I don\u2019t know if NASA already does this. They might.)\n \nreply",
      "My personal take / suspicion about this entire thing. This is the culmination of a thousand little death by committees that were given conflicting priorities and having to juggle them all without ever being blamed for it. Priorities such as profit, stock-value, DEI and ESG scores, \"feelings\", nepotism, favoritism, etc. Heck even personal bias is slowly creeping it's way back into these supposedly feeling-less committees.Edit. And by committee I mean various levels of review, feedback, non-executive decisions, etc. What should be a simple: \"Bob, this guy Steve over here that we hired to do welds is beyond useless, I don't know who hired him. Fire him immediately and get someone we know can do the job.\"Instead turns into endless debates about \"The post-weld review board has found our welds to be hovering at a 7.6/10 score, we need to get these numbers up people! Ping HR and let them know we want to trigger an audit review of all our welding processes, we may need to increase our spend on weld-trainee onboarding.\"We all know it, we've all seen it, we've all thought about it. I exaggerate the words to prove a point, but that stuff has been infecting every institution and we need to fight back against it. I've personally seen it in our field, and it's beyond infuriating. The machine itself will fight you if you try rectify it in your own little way. And at the end of the day, I have a family to feed and house. But so does everyone else.\n \nreply",
      "The problem is that you can't run a large engineering department based on \"Bob says Steve isn't that good\". It just doesn't scale, that's the whole reason metrics get introduced.\n \nreply",
      "You can if you know both Bob and Steve because you are their manager...\n \nreply"
    ],
    "link": "https://www.flyingmag.com/modern/nasa-investigation-finds-boeing-hindering-americans-return-to-moon/",
    "first_paragraph": "An artist\u2019s illustration depicts NASA\u2019s SLS Block 1B flying in crew configuration. [Courtesy: NASA]Mismanagement and inexperience on the part of Boeing are creating severe delays and expenditures for NASA\u2019s efforts to return Americans to the moon, according to a new report from the agency\u2019s office of the inspector general (OIG).The 38-page document, released Wednesday, paints the manufacturer\u2019s quality control practices as inadequate and its workforce as insufficiently trained, blaming it for cost increases and schedule delays in the development of NASA\u2019s Space Launch System (SLS) Block 1B. Yet the space agency has neglected to punish Boeing financially for these flaws, arguing that doing so would run contrary to the terms of its contract.The heavy-lift rocket, a more powerful configuration of NASA\u2019s existing SLS Block 1, is intended to make its maiden voyage in 2028 on the Artemis IV mission, a crewed lunar landing. It has been under development since 2014. Boeing is under contract to",
    "summary": "**Boeing Struggles to Rocket Past Competence**\n\nIn a shocking revelation that surprises precisely no one, Boeing has made a mess of the incredibly simple task of building a rocket to send Americans back to the moon. The latest audit report can basically be summarized as \"Boeing couldn't weld its way out of a paper bag,\" and despite creating a cataclysm of delays and budget bloats, NASA hasn't taken their piggy bank away. Commenters, swinging between amateur welding critics and corporate conspiracy theorists, suggest everything from punitive fines to simply hiring welders who don\u2019t think \"aluminum strong like ox!\" is a manufacturing plan. It's like watching a group of flat-earthers plan a space trip\u2014entertaining but ultimately horrifying. \ud83d\ude80\ud83d\ude31"
  },
  {
    "title": "A camera that shoots 40k FPS decided the 100-meter sprint final (petapixel.com)",
    "points": 148,
    "submitter": "wallflower",
    "submit_time": "2024-08-11T12:11:22",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=41215626",
    "comments": [
      "I kinda hate this article because it could be so much better and yet it isn\u2019t.The headline is clearly, in some sense, silly. It\u2019s silly because the usual notion people have of fps is something like video where you need to move your roll of film or read out from your sensor at that rate. The \u2018frame rate\u2019 for a photo finish is much more incidental to the way the image is made.If you have an image from a typical digital camera that is 4000px high formed by a typical two-curtain shutter that shutters in 10ms, you expose 400 rows per ms or, in some silly sense, 400k FPS. If you wanted a 1-pixel high slit to be exposed then that\u2019s an exposure of 1/400000s, which is faster than any camera I\u2019m aware of. But I think the analogy is useful \u2013 instead of a shutter moving a slit over the focal plane, exposing different parts of the sensor at slightly different times, imagine the sensor being moved behind a fixed slit and then reading out the values from it. You can reasonably easily imagine doing this with film too \u2013 just move it past the slit at a steady rate \u2013 not dissimilarly from taking an old-school panorama camera and moving the body instead of the lens.I think the thing happening here is not a moving sensor but rather a 1 pixel wide sensor (or perhaps a few pixels for colour reasons). This makes it thousands of times smaller than the resolution of the final image so even a fairly typical cmos sensor at 2e9 pixels per second could read 50000 pixel \u2018frames\u2019 at \u201840k FPS\u2019. (In practice the number would probably be lower for synchronisation reasons). When your frame is very skinny, that still gives you plenty of resolution.I don\u2019t like the article because they did some silly arithmetic that produces a big number instead of digging into interesting details, e.g.- talking about how the system works as a whole (when does it decide to start/stop the image, maybe something about buffering)- talking about how much light you need and how you get enough- talking about the optics, how you keep everyone sharp while still getting enough light, how you even focus such a thing- talking how you make sure the camera is setup fairly (eg perpendicular to the lanes, able to get a good view of all the lanes)- maybe something about reliability and how you avoid the bad scenario of the system failing when it matters most\n \nreply",
      "> You can reasonably easily imagine doing this with film too \u2013 just move it past the slit at a steady rate \u2013 not dissimilarly from taking an old-school panorama camera and moving the body instead of the lens.No need to imagine, this is how photo finish cameras at horse and greyhound races have worked for decades.\n \nreply",
      "Photo finishes are typically done with a line scan camera. It only captures a single column of pixels at a time. So the horizontal axis in the image is actually time, not space. Super cool stuff.\n \nreply",
      "I find line scan cameras and strip photography fascinating.https://en.wikipedia.org/wiki/Strip_photographyEarly film versions used a highspeed spinning slit aperture to film fast objects.  This paper from 1931 shows some very impressive results for ballistics, including the shockwave:\nhttps://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1931...Outside sports, digital line scan cameras are used in various quality control applications (objects on conveyer belts, vehicle mounted road/rail scanners, etc).  This unit can film an 8k px strip at a rate of 80khz.https://www.youtube.com/watch?v=OXUwJOJ7fMk\n \nreply",
      "There is a similar technique in astronomy, though much slower, called drift-scan imaging.  Typically when you take a long exposure astronomical image the telescope has to rotate to track the star as it moves across the sky.  So in traditional imaging you track the object, make your exposure, and then when the exposure is done you read out the image.  The downside is that while you're reading out the image you can't do anything else and for an astronomical CCD it can take on the order of a minute or so.  So you lose ~5% of your observing time just to reading out images.  (It's more if you have to slew to different locations on the sky.)In drift-scan imaging you keep the telescope pointed at a fixed location and you continuously read out the image at a rate that matches the motion of the stars across the field of view.  This allows you to continuously collect imaging from a strip across the sky.\n \nreply",
      "Oh yeah I took that picture on the Wikipedia article! I have a couple more on my website [1]. One of these days I want to go to Atherton station with my line scan camera to scan some Caltrains.[1] https://daniel.lawrence.lu/photos/\n \nreply",
      "Very cool photos! Just as an FYI, the link to the full sized \"Victorian house in San Francisco, CA, 2020\" image 404s for me.\n \nreply",
      "Weird, I'll fix that later but meanwhile you can also find it here: https://commons.wikimedia.org/wiki/File:Victorian_house_on_W...\n \nreply",
      "Small world!  You took some amazing images.  Can I ask - what hardware did you use?\n \nreply",
      "Alkeria Necta N4K2-7C\n \nreply"
    ],
    "link": "https://petapixel.com/2024/08/06/a-camera-that-shoots-40000-fps-decided-the-100-meter-sprint-final-olympics-paris-2024-omega/",
    "first_paragraph": "",
    "summary": "In an era defined by technological marvels, <em>PetaPixel</em> has once again managed to strike deep into the core of mundanity by hyping up a camera that shoots at 40,000 FPS as the unlikely hero of sprint finals. Commenters, flexing their \"actually\" muscles, dive bomb into a whirlpool of technical details, drowning the essence of athleticism in pixel-peeping pedantry and historical comparisons as if the fate of humanity hinges on strip photography techniques. It\u2019s impressively clear that while the athletes train hard to shave milliseconds off their time, the readers would rather bask in the soothing glow of a screen displaying \"astonishing\" 40k FPS glory. So, grab your goggles \u2013 we\u2019re doing deep dives on exposure times instead of appreciating human speed and agility! \ud83c\udfc3\ud83d\udca8\ud83d\udcf7"
  },
  {
    "title": "FCC seek comments on NextNav petition for rulemaking on lower 900MHz ISM band (fcc.gov)",
    "points": 108,
    "submitter": "pera",
    "submit_time": "2024-08-12T17:08:12",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=41226802",
    "comments": [
      "I just don't understand how the FCC can justify just giving away spectrum forever to the first person to ask.They should instead hold an auction every decade for every bit of commercial spectrum.    Winner can use it for 10 yrs.   Stagger the auctions so a new chunk in each band is coming up for auction every month.Nothing should be given away forever.    Not even the 2.4 Ghz wifi band.    One day there will be a better use for that band, and one bloke running his 50 year old wifi camera shouldn't be able to shut down the new use for a whole city block.\n \nreply",
      "So all the tech you bought fails when the company doesn\u2019t renew? Although uk works on auctions and they work.Perhaps combine with restrictions on use - if you don\u2019t use the spectrum, or use more than you need, it gets taken away\n \nreply",
      "nearly all wireless devices in your home use unlicensed spectrum (2.4 Ghz wifi, bluetooth, ISM for car remotes, etc).Licensed spectrum is nearly always used by subscription services - eg. your cell phone service.\n \nreply",
      "> Nothing should be given away forever. Not even the 2.4 Ghz wifi bandGiven this line, how exactly is this response a defense of your original comment?\n \nreply",
      "I get the impression from their wording that the licensed and unlicensed bands would have different thresholds and rules.For unlicensed, it wouldn't be about registration, it would be about making effective use.  It's hard to imagine a situation where nobody is making good use of 2.4GHz, so it should stay unlicensed, but the aspect of effectiveness is still there.  Occasionally old tech that is acting like a noise blaster might need to be culled.\n \nreply",
      ">I just don't understand how the FCC can justify just giving away spectrum forever to the first person to ask.Strong agree, which is why they've traditionally licensed transmitters at specific sites. The coordination of use of a limited resource is the proper role of the FCC.>They should instead hold an auction...Strong disagree. Any auction is a tax, that gets increased and passed along to users. The whole idea of making a \"profit\" from the airwaves is a premature (and evil) optimization.Part of a broadcast license should be expanded to include operating a timing and navigation beacon, supplied and maintained by the government, which transmits precision timing (via local atomic clock(s)) and thus can be coordinated with others to measure position.  This should also apply to all cell sites.Also, the shutdown of ground based navaids by the FAA should be reversed as much as possible. Full ground coverage in the event of a GPS loss should be maintained.\n \nreply",
      "> Any auction is a tax, that gets increased and passed along to users.The FCC is a cost center.  Enforcement costs needs money which comes from taxes (auction or income).  So to me it's a wash regardless of where the money comes from.The market is the most efficient form of pricing a scarce resource (bandwidth in this case) so it makes sense that an auction is the appropriate way to sell it.\n \nreply",
      "Wouldn't this lead to a spectrum monopoly and the death of family radios, home wifi, etc.?The market may be \"efficient\", but I don't want my radio regulator to optimize for cost alone, rather for balancing a variety of different needs, ranges, and durations like they are now.\n \nreply",
      "We need to expand ISM license-free zones to facilitate experimentation and development, not shrink them even more. 902-925 is not ISM in Europe and it sucks. Don't let them take it from you over in the US!\n \nreply",
      "What I notice when I travel with a scanner is that the US West Coast and East Coast are entirely different in terms of radio, that includes not just inland areas but also the area around New York City.The 2 meter band for instance is back to back busy with people speaking English, Spanish and other languages in L.A. but if I scan for a while in NYC I\u2019ll eventually hear two people talking on a repeater.So far as I can tell startups in the Bay Area try to develop 900 MHz devices and come to the conclusion that the band is too crowded because every Stanford student and his uncle is testing some gadget they made.  If somebody tried that in the Research Triangle Park area, however, they\u2019d probably wonder if their receiver was dead.So more products dogpile in the 2.4G band which is crowded everywhere.The situation is at the most blatant where it seems the utilization of TV channels is much less than 10% on the East coat because our cities are too spread out for it to be easy to cover people but are too close together to be able to reuse frequencies.  Thus you can get more channels than some cable plans with just a pair of rabbit ears in LA but it is not like that in NYC where reflections are so bad in the canyons I wouldn\u2019t count in tuning into anything in Manhattan.\n \nreply"
    ],
    "link": "https://docs.fcc.gov/public/attachments/DA-24-776A1.txt",
    "first_paragraph": "",
    "summary": "**FCC Gives Away Airwave Candy Store: Outrage and Confusion Ensue**\n\nThe FCC has once more decided to consider tweaking the electromagnetic spectrum and, as expected, the technorati are tumbling out of the woodwork to spit their proverbial pacifiers across the floor of public comment section. One genius suggests a merry-go-round of spectrum auctions to ensure no one feels too comfy with their radio frequencies\u2014because apparently, technology must bow to the great god of capitalism. Another scholar finds it completely baffling that, in a landscape littered with technological relics, anyone could continue to use old tech without yearly tributes to the spectrum gods. Meanwhile, a rebel voice cries for the sanctity of the 2.4 GHz band, clearly ready to chain themselves to their aging router in protest. Who knew airwaves could stir such drama? \ud83d\udcfb\ud83e\udd21"
  },
  {
    "title": "Apple's requirements are about to hit creators and fans on Patreon (patreon.com)",
    "points": 733,
    "submitter": "miiiiiike",
    "submit_time": "2024-08-12T14:34:46",
    "num_comments": 648,
    "comments_url": "https://news.ycombinator.com/item?id=41224853",
    "comments": [
      "Another point that Patreon isn't really emphasizing here that seems relevant to any conversations about \"fairness\" is that Apple's fees on Patreon subscriptions in-app are now higher than Patreon's fees.It's important to recognize any time that we're talking about the market that services charge what they can, not what is fair. The market does not have a concept of fairness, only competition. This is why there is no such thing as a benevolent monopoly that charges fair prices - because fairness does not exist in the market, only competition.BUT... since fairness gets so often brought into conversations about Apple's fees, often with the implicit suggestion that Apple \"deserves\" to be compensated for all of the work they're putting into hosting and curating apps and for (in heavy quotes) \"creating\" a market that they supposedly also don't have duopoly control over: does anybody want to argue that Apple hosting the Patreon app on iOS provides more value to Patreon subscribers and creators than the existence of Patreon itself does?Like, if we're going to talk about what's egregious and what's not egregious, charging higher fees per-transaction than the platforms you are hosting seems like it might be a good indicator that things have gotten out of control.\n \nreply",
      "> does anybody want to argue that Apple hosting the Patreon app on iOS provides more value to Patreon subscribers and creators than the existence of Patreon itself does?Well, there is a simple way to test this... just get rid of the Patreon iOS app and just use a web version. Why does patreon need its own app? Why can't it just be web based?I wish fewer companies had apps. I don't need an app for everything. I don't need every hotel I stay at to have their own app, I don't need an app to order food at a restaurant.So why do companies make them? Because people spend more money when they can just use the in app purchase functionality. It is CLEARLY worth the 30% to most companies, because they keep pumping out single use apps that would be better as a mobile web page.\n \nreply",
      "How many of the apps you're complaining about are paying 30% to Apple?  Hotels and restaurants definitely aren't.Also a lot of companies make apps so they can get more tracking info.  That value doesn't come from the Apple Store.It's things like games that really get an advantage from being native and in the store.  And that's largely a red queen's race, they need to stay on top and they'll pay out the nose to be the easiest install.  Paying lots of money in a zero-sum situation doesn't mean they're getting much value in a more zoomed-out sense.\n \nreply",
      "The ability to get more tracking info comes from producing an app which in turn comes from the Apple Store. I\u2019ve never found myself wanting to use a Patreon app instead of their website, just like I found the substack app a complete waste of space and immediately deleted it.Not everything needs to be an app.\n \nreply",
      "> which in turn comes from the Apple StoreI strongly disagree with that.  The store is not the reason apps are good for lots of things.  You can assign a lot of value to phone and OS, but Apple does not try to take a cut based on making the phone and OS because it would be hard to defend.  The store pales in comparison.",
      "When a mobile web page uses apple pay, does it also give 30% to apple?If not, what\u2019s the difference between it and an app?\n \nreply",
      "> Why does patreon need its own app? Why can't it just be web based?because apple gimps their web browser capabilities & performance to incentivize developers to enter the walled garden\n \nreply",
      "> does anybody want to argue that Apple hosting the Patreon app on iOS provides more value to Patreon subscribers and creators than the existence of Patreon itself does?I'll bite, kind of. People get emotional about particular companies so let's abstract them away: is it possible for a second-tier distributor to bring more value to a first-tier distributor than the first-tier brings to suppliers?Looking at it that way, sure. It seems obvious. If a local distributor picks up a local product, and then a national distributor buys from the local distributor, it's pretty obvious that the national distributor brings more value.Looping back to the specifics, if Apple was the primary means that people discover Patreon and the creators on it, sure, it would make sense. But for Patreon specifically that's not the case (I think). The economics would suggest that Patreon should do away with their iOS app, focus iOS users on the web, and everyone would be ahead.\n \nreply",
      "> Looking at it that way, sure. It seems obvious. If a local distributor picks up a local product, and then a national distributor buys from the local distributor, it's pretty obvious that the national distributor brings more value.That isn't obvious at all. In both cases the distributor's margin will reflect how much competition they have. If there is only one distributor, their margin will be large. If there are a thousand, competition will force their margins down. Whether they're local or national.Moreover, in this context Patreon is the national distributor who needs to distribute content to everyone whether they have iOS, Android, web or something else, and each of the platforms is a local subcontractor for a subset of the customers. Which leads to exactly the problem. The notion that Google and Apple are in competition with one another in this context is false, because to distribute to Android customers you need Google and to distribute to iOS customers you need Apple. You can't switch from one to the other because Google can't distribute to iOS customers. They're each a different market serving different customers, and then they collect a monopoly rent.What the usual trope that analogizes this to Walmart or Target is missing is that \"Walmart customers\" are also customers of Target or Amazon, but the large majority of iOS customers are not also customers of Google Play or any other app store.\n \nreply",
      ">  The notion that Google and Apple are in competition with one another in this context is false, because to distribute to Android customers you need Google and to distribute to iOS customers you need Apple.It is still competition even in this context, it just happens on a slightly slower cadence. The Apple customers, by and large, are paying good money to avoid Google's app store because they believe Apple is a better steward on net.Every time I buy a phone I have to ask if Apple's bad software decisions outweigh the costs of signing up with Google. So far the answer has been one sided in Apple's favour. Consideration of things like this with Patreon come up at phone purchase time.\n \nreply"
    ],
    "link": "https://news.patreon.com/articles/understanding-apple-requirements-for-patreon",
    "first_paragraph": "",
    "summary": "In the thrilling digital saga of who can gouge whom more effectively, Apple emerges as the champion Scrooge, levying fees so high that even the platform behemoths squirm. Patreon users panic at the thought of their beloved site being swindled in the open daylight by Big Tech tax collectors, while commenters fire up their virtual pitchforks, passionately debating whether a Patreon app\u2014or indeed, *any* app\u2014serves a greater purpose than as a digital landfill. One brilliant strategist suggests jettisoning the app for web-based access, while another waxes philosophical about the underlying economics of digital distribution, revealing complexities reminiscent of string theory, but less understood. Meanwhile, the average reader wonders if this financial thriller is worth the ad they just accidentally clicked on. \ud83c\udf7f"
  },
  {
    "title": "Distributed == Relational (frest.substack.com)",
    "points": 20,
    "submitter": "crowdhailer",
    "submit_time": "2024-08-12T21:08:15",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41229328",
    "comments": [
      "> Truly efficient distributed systems are most naturally expressed through functions as triggers invoked from upsert operations on addressable relationsO_oJust because you can express something as an 'upsert', that doesn't make it 'relational'.  Transactions exist outside the concept of rdbms'.  The article doesn't mention relational algebras once.Yes, a lot of terminology and math in rdbms' are useful in distributed computing, but you have the causality backwards.I don't get all the author's hate for sql.  It's one of the most successful declarative languages ever.Nothing prevents you from modelling a distributed system as a set of key-value stores (as we often do today), the idea of a message queue is independent of using a database\nas the mechanism to do so.  'using postgress'/rdbms doesn't mean your entire system is 'relational'.Wouldn't it be better for D to lazily request information from b and c on your behalf in the 'maximally efficient' case?  Given D is where the computation is run and it could cache the results.  From an auth perspective that seems simpler than cross wiring connections between all nodes as proposed.All this talk and nothing about n-phase commits or Byzantine generals/any tie backs to the typical way of talking about distributed computing, but they dance around the subjects.IDK.  Sorry man. Didn't like the article, which feels bad because you seem passionate about the presentation of it.Edit: looked through the sub stacks other posts.  They do kinda talk about relational algebra in a subsequent post, but overall I'm curious if the author has looked into dataflow programming before. It seems like the author is kind of trying to describe that concept but with a vocabulary mostly consisting of rdbms terminology and historyhttps://en.m.wikipedia.org/wiki/Dataflow_programming\n \nreply",
      "> A distributed computing system, then, is naturally expressed as a set of relational stores with triggers.1. This statement is too big of a leap; it doesn\u2019t follow from the setup which only required an upsert operation and key/value storage. Nothing in the setup example requires relational algebra. Agree?2. This seems like a hasty generalization. Is the author claiming that the toy example is representative of distributed systems? If so, what aspects?IMO, the post started strong but fizzled; this is why I\u2019m giving pointed feedback.\n \nreply",
      "If the author is here, I\u2019d suggest naming the arguments for D to be (b, c) so as to correspond with B, C.\n \nreply"
    ],
    "link": "https://frest.substack.com/p/distributed-relational",
    "first_paragraph": "",
    "summary": "**Title: Distributed == Relational? More Like Confused == Author**\n\nIn another episode of \"Tech Jargon Jamboree,\" an enthusiastic blogger tries to convince the world that upserts are the hot new foundation for distributed systems, because why not throw SQL into everything? Commenters, armed with their very own copies of \"Databases for Dummies,\" quickly chip in to debunk, derail, and digress. One sage soul wonders if relational algebra was left behind during the author's last database reboot, while another mourns the misuse of SQL, apparently the only language they've ever met and loved. Overall, the consensus is that everyone's confused, but at least they\u2019re confused together. \ud83e\udd37\u200d\u2642\ufe0f"
  },
  {
    "title": "History of Hacker News Search from 2007 to 2024 (trieve.ai)",
    "points": 86,
    "submitter": "skeptrune",
    "submit_time": "2024-08-12T20:27:27",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=41228935",
    "comments": [
      "i want to publicly thank Algolia for providing an excellent HN search for so long. i was on a call with Linus Lee and we both were referencing something on HN and i started pulling it up and he said \"i know exactly what website you're on\" without seeing my screen and it was of course the Algolia HN search. unbelievable mind sync.Idk if it can be replaced (i guess i could do with semantic search + content crawling to start?), but even if it is replaced, Algolia will always have a special place in my heart for doing such a great job for free. thank you whoever worked on it (Algolians - is there a behind the scenes writeup somewhere?)\n \nreply",
      "It is free, but Algolia is a YCombinator backed company (YC W14) so for them it's probably very useful as a sort of low-stakes phase-1-prod environment. Basically a win-win-win.\n \nreply",
      "Now, if only it could be used without necessitating JavaScript...\n \nreply",
      "Yeah, I always have to turn it on to search for something. It's a pain. It's friction.Javascript is not required for search. It has never been required for search. Google. Yahoo. Alta Vista. They worked fine without it back in the day.\n \nreply",
      "Updated the blog at the link to include PG's HN post and the archive-available ycombinator.com post documenting the Octopart/ThriftDB search launch.Commit here - https://github.com/devflowinc/trieve-website/commit/ab563475...Links:\n- https://news.ycombinator.com/item?id=2619736- https://web.archive.org/web/20110618105517/http://ycombinato...\n \nreply",
      "On the topic of Hacker News search\u2026 a useful trick that not enough people know is that you can take the ID of a story and use search to return all comments ordered by most recent first - great for keeping up with what\u2019s new in a specific conversation.Eg for this thread the most recent comments can be found here: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...I built an Observable notebook to save me from having to manually construct those searches here: https://observablehq.com/@simonw/hacker-news-homepage\n \nreply",
      "Since it's mention-undocumented-endpoints day, https://news.ycombinator.com/latest?id=$ID does that, where $ID can either be a story (in which case you get the entire thread sorted reverse-chronologically) or a comment (in which case you get the comments in that subthread).So, for the current thread: https://news.ycombinator.com/latest?id=41228935or for a subthread: https://news.ycombinator.com/latest?id=41229914.\n \nreply",
      "HN could really use some client software. If nothing else for choosing how to read thread replies (ie: most recent, most upvoted/popular, most downvoted, by replies from the OP, etc) + a more advanced built in search.\n \nreply",
      "> more advanced built-in searchDo you have any specific feature requests? I would love more suggestions and ideas!\n \nreply",
      "There are a few capabiliti es lacking from Algolia which I'd really like to see in a replacement:- Negative search / exclusion:  the ability to exclude terms from a search, as in \"procfs -linux\", which would look for any references to \"procfs\" which did not also reference \"linux\".Edit:  This exists, see dang's reply below.- Replies to a specific user, e.g., \"by:dredmorbius inreplyto:skeptrune <search terms>\".  I'm often looking for a specific context of my own previous comments.- An improved date-bounding interface.  If there's one thing that frustrates me about Algolia's interface, it's the GUI (and syntax) for defining dates.  It's cumbersome, and at least on my browser, the dates are generally hard to read or invisible.  Going back years is especially cumbersome.I'll add:  Algolia has been massively useful, and the fact that I can search HN, especially for my own content, has been a huge part of the value of the site, and is worlds ahead of other online platforms.  (Mastodon / the Fediverse is catching up here, Diaspora*'s lack of search was among my main frustrations with the site and explains my absence there after more than a decade of participation.)\n \nreply"
    ],
    "link": "https://trieve.ai/history-of-hnsearch/",
    "first_paragraph": "    Aug 12, 2024  \n\u00b7  history    \u00b7 5 min read     skeptrune (Nick K)  The history of HackerNews (HN) search spans three generations. Starting in 2007 with Disqus founder Jason Yan followed by a series of other sites, Octopart/ThriftDB-powered HNSearch in 2011, and finally Algolia-powered search from 2014 to today. We at Trieve are going to be launching a search engine for HackerNews with some additional features soon and thought it would be worth studying the history of HN search before finalizing things. Here\u2019s what we found!Note: Did the research using our own HN search engine! :)Note: I was happy looking at these old HN posts and seeing that so many of the comment/post\u2019ers from the early days of HN\nwere, or eventually became, founders of YC companies.Written and shared by Jason Yan, Founder/CTO of Disqus (S07) (aka jsonyan), on March 17, 2007. Can still be viewed here on the internet archive.I assume there was some indexing logic being done on the DJango server that Jason used.Quick",
    "summary": "**History of Redundancy: The Saga of Hacker News Search**\n\nIn a thrilling dive into the mundane, an enthusiastic history wizard delves into the Jurassic era of Hacker News search functionalities, proving that even the most forgotten corners of internet utilities can be dusted off for a nostalgia trip. As Trieve gears up to launch yet another search engine to solve a problem that, let's be honest, nobody really has, the Hacker News community erupts into tales of past glories where \"JavaScript required\" pop-ups were the peak of technological annoyances. Commenters battle fiercely over trivialities, like whether Algolia\u2019s inclusion of a minus sign in searches counts as innovation, while others philosophize over the good old days of less intuitive UI. Each nostalgic claim is a stark reminder that, in the relentless pursuit to reinvent the wheel, everyone forgot we had flying cars now. \ud83d\ude80\ud83d\udcbe\ud83d\ude05"
  },
  {
    "title": "Just Say It, Henry (lrb.co.uk)",
    "points": 5,
    "submitter": "benbreen",
    "submit_time": "2024-08-08T05:52:19",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.lrb.co.uk/the-paper/v46/n16/colin-burrow/just-say-it-henry",
    "first_paragraph": "London Review of BooksMore search OptionsBrowse by SubjectIn 1904\u200b Henry James\u2019s agent negotiated with the American publisher Charles Scribner\u2019s Sons to produce a collected edition of his works. The New York Edition of the Novels and Tales of Henry James duly appeared in 1907-9. It presented revised texts of both James\u2019s shorter and longer fiction, with freshly written prefaces to each volume. It didn\u2019t include everything: \u2018I want to quietly disown a few things by not thus supremely adopting them,\u2019 as James put it. The \u2018disowned\u2019 works included some early gems such as The Europeans. The labour of \u2018supremely adopting\u2019 the stuff he still thought worthy was grinding. He worked on the new prefaces, which he described as \u2018freely colloquial and even, perhaps, as I may say, confidential\u2019 (though James\u2019s notion of the \u2018freely colloquial\u2019 is perhaps not everyone\u2019s) during the years 1905 to 1909. In some respects, the venture was not a success. \u2018Vulgarly speaking,\u2019 James said of the New York Edi",
    "summary": "\ud83e\udd14 Henry James plays literary \"Hot or Not\" with his own works, crafting the ultimate snub-fest called the New York Edition. Despite his intent to be \"frely colloquial,\" he ends up sounding more like a verbose Victorian uncle trying to use Snapchat. Commenters, undeterred by the actual content, dive into a battle of who can spew the most pretentious James-esque sentence, while occasionally debating the merits of disowning their own early social media posts. \ud83d\udcac\ud83c\udfa9"
  },
  {
    "title": "Queues invert control flow but require flow control (enterpriseintegrationpatterns.com)",
    "points": 15,
    "submitter": "alexzeitler",
    "submit_time": "2024-08-08T20:22:52",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41195805",
    "comments": [
      "I always wish more metaphors were built using conveyor belts in these discussions.  It helps me mentally underscore that you have to pay attention to what queue/belt you load and why you need to give that a lot of thought.Granted, I'm probably mostly afraid of diving into factorio again. :D\n \nreply",
      "The Spintronics mechanical circuits game is sort of like conveyor belts.Electrons are not individually identified like things on a conveyor belt.Electrons in conductors, semiconductors, and superconductors do behave like fluids.Turing tapes; https://hackaday.com/2016/08/18/the-turing-tapes/Theory of computation > Models of computation: \nhttps://en.wikipedia.org/wiki/Theory_of_computation\n \nreply",
      "Backpressure matters.\n \nreply"
    ],
    "link": "https://www.enterpriseintegrationpatterns.com/ramblings/queues_flow_control.html",
    "first_paragraph": "Find my posts on IT strategy, enterprise architecture, and digital transformation\n            at ArchitectElevator.com.\n         Queues are key elements of any asynchronous system because they can invert control flow. Because they can re-shape traffic, they enable us to build high-throughput systems\n            that behave gracefully under heavy load. But all that magic doesn't come for free:\n            to function well, queues require flow control. Time for another look at the venerable\n            message queue.\n         After developing a notation and vocabulary to express control flow, we can describe queues from a new dimension: time. We mentioned arrival and departure\n            rates in the previous post: rates represent the first derivative of a variable over\n            time. Hence, a message arrival rate describes how many messages arrive in a specified\n            interval, e.g., per second. That arrival rate, in turn, varies over time and helps\n            describe the dy",
    "summary": "Title: <em>Why We Can't Have Nice Things: The Queue Conundrum</em>\n\nOnce again, the enterpriseintegrationpatterns.com sages grace us with an earth-shattering revelation: queues are important in asynchronous systems. Who knew, right? Brace yourself as the article dives into the exhilarating world of queues requiring \"flow control\" \u2013 a concept so arcane, it\u2019s almost like you need a PhD to understand high school physics. Meanwhile, the comment section quickly devolves into a merry-go-round of the most tangentially related metaphors, from conveyor belts to Turing tapes, proving that no one actually understands the article but everyone loves pretending they do. \ud83c\udfa2\ud83e\udd13"
  },
  {
    "title": "Workers are stuck in place because everyone is too afraid of a recession to quit (boredbat.com)",
    "points": 81,
    "submitter": "paulpauper",
    "submit_time": "2024-08-12T21:36:56",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=41229600",
    "comments": [
      "I can empathize with the article. Earlier in my career, I would interview with any company that offered a significant pay increase. \"Why would anyone turn down a 30% pay raise\" was my mentality. Then I had a couple of jobs that didn't go well because of personality mismatches and politics. Which made me realize that even if I'm confident about my technical skills, that's no guarantee that I'll land on my feet at a new gig. Fast forward another few years, and the recession made me realize that I can't just snap my fingers and land a new better-paying job anytime I want.Combine both these factors, and I'm now ignoring recruiters who are begging me to interview for insanely well-paying openings. I have a decently well-paying job with good work-life balance, and colleagues who respect me. And I have no interest in throwing that away just to navigate a political minefield at a new job\n \nreply",
      "This is a fair point. Earlier in my career I jumped ships so many times I had to move to another city to find 'new work'. It was a rather small city with companies buying off each others etc.I learnt throughout these episodes that people make companies, not some branding or marketing dep.My motto for the last 20 years has been \"find good people, do good work\". Emphasis on __good__, not great, best, immaculate, amazing, nonsense. But definitely good. My standards are pretty high though!\n \nreply",
      "I do know various people who left a job with a former employer because they weren't happy and seemingly landed fine AFAIK. I mostly stuck things out for a bit because I was mostly retiring. Otherwise, I'd probably have done the same even if the end-result was retiring a bit early.\n \nreply",
      "\u201cDon\u2019t mess with happy.\u201d - Brad Scott\n \nreply",
      "yeah i don't love my job at all but it's...fine. they call it work for a reason.a few years ago, i'd bail. not an option today since i like money. gonna ride this gravy train a bit more. not gonna do it with a smile though.\n \nreply",
      "We hear this from candidates pretty often (it's the second most common specific reason for a candidate to turn down outreach for a job, after \"please don't match me with crypto companies\" [1]), although we're new enough that I can't make an apples-to-apples comparison for how common it was prior to the current environment.What's odd is that, on paper and for the engineering jobs we work with specifically, it doesn't seem like that's actually more justified now than it was a year or two ago. The tech hiring market seems to have bottomed out and to be (unsteadily) on its way back up. Two years ago, prediction markets [2] were pretty confident a recession would occur by this point, but it hasn't. They're now down to about 25% that it'll occur by the end of this year, although the fact that the percentage has stayed flat even as time has run out suggests markets are a bit more bearish now than they were six months ago. And they think [3] that large interest rate cuts are coming.But perhaps a few years of frustration and seeing others struggle has taken its toll in ways that go beyond object-level economic predictions. Experience with rough conditions might've made people more risk averse, or make them feel more secure in the job they do have (after all, there's a good chance they've survived some layoffs at this point), both of which could (rationally) make them stick where they are even if their opinions of the broader economy were the same or better.----[1] EDITED to add: reasons they turn down outreach we actually send, meaning it's not disqualified by some structured info we have about their preferences. For example, we know whether a candidate wants a remote job, so even though ~60% of our candidates are looking for remote jobs only, that wouldn't be in this ranking.[2] https://manifold.markets/chrisjbillington/will-the-us-enter-...[3] https://manifold.markets/barak/by-how-much-will-the-fed-cut-...\n \nreply",
      "Layoffs are still happening in tech (Cisco, Intel, Intuit to name a few in the last couple of months) and companies that are hiring, have very few roles or are very selective in their hiring process.And beyond hiring, internally, the companies are being hyper focused on performance. People are being let go despite working hard and going above and beyond.The comparison really is: Do I leave my current job which may pay less but won\u2019t fire me or do I go to a new company, risk performance based firing and then be unemployed for months before I find the next job.\n \nreply",
      "People are being let go despite working hard and going above and beyond.This is what primarily scares me and my circle. I'm not going to look for another job while I see and know people far smarter than me being let go from positions far more important than mine.\n \nreply",
      "I'd argue that's a very good reason to have backup options. Remember that looking for a job does not commit you to leaving your current one unless you find something better.\n \nreply",
      ">What's odd is that, on paper and for the engineering jobs we work with specifically, it doesn't seem like that's actually more justified now than it was a year or two ago. The tech hiring market seems to have bottomed out and to be (unsteadily) on its way back up.I mean, as someone out of a full time job for 15 months now (4 of those by choice), I can't really blame them. Of course, I'm an extraordinary case in games that seems to be hit the hardest out of most domains, but the fallout hasn't seemed to bottomed out in this industry just yet.And in tech specifically: it's not like these interview processes are just a drink with the founders and a firm handshake anymore. You gotta weigh the question of \"do I REALLY want to study trivia and go through 5 stages of calls\" vs. the potential upsides of a new job/pay raise. Many tech professionals are probably not scrap for cash, so there's no financial pressure to jump at the next step up if they are focusing on security.>Two years ago, prediction markets [2] were pretty confident a recession would occur by this point, but it hasn't.Layoffs and the previous COVID bailouts probably \"helped\" in that regard.And indeed. As you said, it caused an even more extreme dichotomy of financial pressure between the middle class and below and the asset owning or upper-middle+ (who weren't laid off). Where the former may as well be in a depression while the latter two are on cloud nine, trading houses like baseball cards and growing money by just letting it sit.Is that better than a proper recession? I can't say, but you can understand why the former group can feel that way, and even feels bitter at the latter. Being told that the economy is soaring while your income barely increased 10% that barely covers rent. While rent surged 30% in the past 5-8 years.\n \nreply"
    ],
    "link": "https://boredbat.com/american-workers-are-stuck-in-place-because-everyone-is-too-afraid-of-a-recession-to-quit/#google_vignette",
    "first_paragraph": "",
    "summary": "In today's riveting episode on Boredbat.com, we learn that workers are paralyzed by the sheer terror of an impending recession, choosing to cling to their mediocre jobs like a life raft in the Titanic's North Atlantic. The comment sections blossom into a tragicomic display of Stockholm syndrome, with grown professionals bragging about how they've mastered the art of sitting still. \"Why risk a new job when you can safely stagnate and reminisce about the good old days of potential 30% raises and job hopping?\" they muse. As fear trumps ambition, everyone eagerly awaits the next non-move in this thrilling game of corporate musical chairs where the music stopped long ago. \ud83c\udfb6\ud83d\ude31"
  },
  {
    "title": "Making earthly paradise: The art and crafts of William Morris (the-tls.co.uk)",
    "points": 35,
    "submitter": "prismatic",
    "submit_time": "2024-08-08T19:51:53",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.the-tls.co.uk/literature-by-region/british-literature/william-morris-ingrid-hanson-marcus-waithe/",
    "first_paragraph": "",
    "summary": "In the latest outbreak of historical nostalgia, The Times Literary Supplement unleashes \"Making earthly paradise: The art and crafts of William Morris,\" a heart-thumpingly earnest reappraisal of a man whose most notable achievement was convincing the world that throwing twirly leaves on everything constitutes high art. As expected, readers who barely remember how to sew a button are now proclaiming themselves bewitched by Morris' \"radical craftsmanship,\" while subtly hinting that their own IKEA furniture assembly prowess surely aligns them with Morris\u2019 artisanal spirit. Between the lines, we can almost hear the rustle of hemp smocks being ordered online as one commenter bravely declares their intent to \"embrace the artisanal lifestyle,\" likely by repurchasing the same mass-produced floral print they mistakenly threw out last spring. We await the inevitable blog posts about failed attempts at hand-weaving curtains from organic cruelty-free wool. \u2692\ufe0f\ud83c\udf3f"
  },
  {
    "title": "Launch HN: Synnax (YC S24) \u00e2\u20ac\u201c Unified hardware control and sensor data streaming",
    "points": 20,
    "submitter": "embonilla",
    "submit_time": "2024-08-12T17:55:07",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41227369",
    "comments": [
      "This is really neat, I know a lot of folks in manufacturing QA that would love something like this.  The telemetry aspect of industrial equipment is terrible IMO, so many folks are hand rolling sensors and triggers and then trying to duct tape an extremely fragile monitoring and dashboard system using something like graphite.  Neat space to be in!How are you going to interface with the big boys like rockwell?  I see you have drivers, what about partnerships?  I know a lot of companies tend to only work with toolsets their provider \"blesses\", so having them on \"your team\" can help.  You may have to pick favorites to win early deals/\"synergy\" (and may help with acquisition?)I've worked with industrial automation in the past and have always enjoyed the technical constraints within it.  I would be interested in helping you with pre or post-sales support/training/implementation for your customers if you need it.  Email is in my profile.\n \nreply",
      "It's been a really interesting problem to tackle - we've seen so many different ways that companies try to tackle this problem, and while theres one or two companies that have made really fantastic internal tools, most are ... lacking, to say the least.Our plan so far has been to try to interface with the bigger companies through the drivers we make for their hardware. We haven't reached out about partnerships yet, but that is a really good idea.Thank you for the offer - will definitely reach out if and when we need more help on the implementation side.\n \nreply",
      "Context: started a company that did essentially this about a decade ago. Haven\u2019t looked back much. My data may be stale or just biased.> We used old control software that spit out data in massive 10 GB CSV or TDMS files. After a long day and night of testing, no one wanted to go through all the work to review the data.> We think Synnax is unique in  that it provides a bridge between <lab/automation DAQ systems>On the surface it seems like anomaly detection is still the hard problem, but you\u2019re not setting out to solve it?Time series databases are state of the art generally in finance, not in industrial/InfluxDB, so I don\u2019t think saying you\u2019re 5x influxSB on writes is going to persuade too many people, especially given the cost now for a terabyte of RAM. I\u2019ll just move all of it to an in-memory database before I\u2019ll take on the switching costs.The thing I wanted was one solution for something that was always two: a properties/metadata database, and a separate time series database.It seems to me like you are maybe building a level too low and could get a lot more value working on the problem that you say motivated you in the first place. It is hard because of all the context required to automatically detect anomalies, but I think that is why it is valuable to solve.The value we had was we rolled in the data/cellular connection all the way down to the endpoint, so they could avoid IT integration, which was a big hurdle at the time. I don\u2019t know if IT integration is still a hang up for your customers.We found that visualization layers tended to reach down just far enough into the data intake world that it was really hard to sell just another tsdb.\n \nreply",
      "> I don\u2019t think saying you\u2019re 5x InfluxDB on writes is going to persuade too many people.I definitely agree with this. Our early prototype of Synnax actually sat on top of a combined Redis/S3/SQL stack and focused on those high level features. We found that it was challenging to deploy, manage, and synchronize data across these services, especially when you're running everything on prem.We've come to believe that a re-architecture of the underlying infrastructure can actually unlock the high level workflows. For example, to compare a real-time telemetry stream with a historical data set you'd need to query across tools like Kafka and Influx at the same time. For an experienced software engineer this isn't too hard of a task, but they don't tend to be the people who understand the physics/mechanics of the hardware. We want it to be possible for say, a Turbo machinery expert, to translate a Python script they wrote for post-processing a CSV into something Synnax compatible without a huge amount of work.In short, we're working on finding a way for subject matter experts in hardware to implement the anomaly detection mechanisms they already have in their head, but don't have the software expertise to implement.> The thing I wanted was one solution for something that was always two: a properties/metadata database, and a separate time series database.What do you think about TimeScale for this sort of use case? Haven't run it in production myself, but having your time-series data in the same place as a SQL table seems pretty nice.> We found that visualization layers tended to reach down just far enough into the data intake world that it was really hard to sell just another tsdb.This is a good point. We think that focusing exclusively on the DB is probably not the right approach. Most of our focus nowadays is on building out higher level workflows on top of the new database.\n \nreply",
      "Just curious, were you inspired by Asimov when naming the company?https://asimov.fandom.com/wiki/Synnax\n \nreply",
      "Yes! I'm a fan of Asimov and the foundation series. Synnax is the home planet of Gaal Dornik, who studies Psychohistory, which is (loosely) related to time. I mostly thought the name sounded cool, and then came up with this explanation later :)\n \nreply",
      "Hey! I work at a startup that does industrial automation related work and this looks super helpful. Going to take a deeper look later, but off the bat I wanted to ask why you felt a custom time series database was warranted when there are options like timescale or regular old postgres out there?\n \nreply",
      "Hey! Great question we get a lot. We've come from/talked to a lot of companies that do what you described with stuff like timescale and influxdb. They're useful tools and support a breadth of applications. We thought by building one to specifically leverage the read/write patterns you'd expect with sensor-heavy systems, we could achieve better data throughput and thus better enable real-time applications. For example, we've been able to get 5x write performance for sensor data on our DB compared to influxDB.In general, having built out the core DB, it has been valuable in allowing us to expand to the other useful features such as being able to write commands out to hardware at sufficient control loop frequencies or create smooth real-time visualizations.The other thing we think is really powerful is having a more integrated tool for acquiring, storing, and processing sensor data & actuating hardware. One common issue we experienced was trying to cobble together several tools that weren't fully compatible - creating a lot of friction in the overall control and acquisition workflow. We want to provide a platform to create a more cohesive but extensible system and the data storage aspect was a good base to build that off of.\n \nreply",
      "Thanks for the reply! That all makes sense, and I can totally relate to the \"cobbling together several tools that weren't fully compatible\" experience. There's enough complexity with having to support or integrate sensors/actuators with a variety of industrial networking protocols. Anything to simplify the software portion of the system would go a long way. Excited to dig into this a bit more, best of luck with ongoing development!\n \nreply",
      "Thank you! Happy to get any feedback after a deeper look\n \nreply"
    ],
    "link": "item?id=41227369",
    "first_paragraph": "",
    "summary": "**Launch HN: Synnax - Unified Hardware Control: The Future is Now, and It's Nicely Packaged Middleware!**\n\nIn today's episode of \"My Startup Can Beat Up Your Enterprise Software,\" we witness the birth of Synnax, a HN darling daring to fight the telemetric titans with its shiny unified hardware control and sensor data extravaganza. Commenters, dazzled by the prospect of not gluing together seventeen different legacy systems to see when their machines last coughed, froth at the virtual mouth with awe. One nostalgic coder recalls the good old days of hacking away at CSV files \"big as a small elephant,\" while another dreams of wedging themselves between the \"big boys\" like it's prom night all over again. The founders, riding high on Asimov vibes, are just happy they thought the name sounded cool. Future plans include potentially emailing someone for help\u2014because hey, who actually plans post-launch? \ud83d\ude80\ud83e\udd37\u200d\u2642\ufe0f"
  },
  {
    "title": "Go is my hammer, and everything is a nail (maragu.dev)",
    "points": 207,
    "submitter": "markusw",
    "submit_time": "2024-08-12T12:59:34",
    "num_comments": 332,
    "comments_url": "https://news.ycombinator.com/item?id=41223902",
    "comments": [
      "People always under-estimate the cost of properly learning a language.  At any given time I tend to have a \"main go-to language\".  I typically spend 2-4 years getting to the point where I can say I \"know\" a language.  Then I try to stick to it long enough for the investment to pay off.  Usually 8-10 years.A surprising number of people think this is a very long time. It isn't.  This is typically the time it takes to understand enough of the language, the compiler, the runtime, the standard library, and idiomatic ways to do things.  It is the time it takes to where you can start to meaningfully contribute to evolving how the language is used and meaningfully coach architects, programmers and system designers. It is also what you need to absorb novices into the organization and train them fast.\n \nreply",
      "And then you have the ever changing ecosystem, that can take years so sort out on it's own and must be constantly studied.E.G: if you arrive in Python right now, numpy is in version 2 and polars is stable. uv is all the rage, pydantic gained so much perf it's not even funny, toml is part of the stdlib and textual is looking very good. Type hints are much better than 2 years ago, htmx is used a lot in the web department, fasthtml is having a moment in the light and pyscript got a platform. Is any of those information worth acting on? Should you ignore them all for the sake of productivity? Should you carefully evaluate each proposition?Now if you have to do that with rust and erlang as well, it's a lot of time you could spend on coding instead.\n \nreply",
      "It\u2019s not just the time to understand those nuances, but to keep up with the pace of changes. There\u2019s an aspect of navigating those in some languages (JS\u2026) that can be time consuming depending on where it\u2019s deployed.\n \nreply",
      "Naturally one can't know all the languages of the world.Even so, I have done consulting since 1999, with a small 2 years pause in research, and have several languages that I keep switching, every couple of months when project reassignment takes place.The usual T-shape kind of consultant, know some stuff really well, and others good enough to deliver.\n \nreply",
      "Agreed. Having a passing knowledge of many languages is of course easy (even being moderately productive with them, esp. with Copilot now), but knowing the ins and outs of a language and its ecosystem is a very nontrivial time investment.Thus, I'm mostly an anti-fan of the idea of polyglot environments.\n \nreply",
      "I also think it is a good idea to learn a few very different languages when you are starting out so that you have a sense of the tradeoffs and the different ways things can be done.  When I was in college they taught C and Lisp (I am dating myself) which seemed very different to me at the time but also useful in different ways.  Close to the hardware, vs supporting objects, lambda functions, etc.  Later I learned a number of other languages and now I try hard to avoid switching languages because of the lost productivity.Now if I were starting out I think I would try to focus on two different languages, but more modern ones.  Maybe Rust and Python?\n \nreply",
      "This is actually how I feel about Ruby. Not full on Rails because there is a lot more to learn there which comes with the time investment (which is also worth it in many cases).But for most scripting work especially, just raw Ruby and maybe the Sequel library for a database just makes my productivity soar.\n \nreply",
      "By now I know three major languages: Go, Python, and Typescript. I know tradeoffs at-a-glance, I deeply understand the syntax and its various forms, the full array of tooling and what they do, and lastly (but maybe most importantly) I can estimate more accurately because I can architect in my head.I can work in a myriad of other languages. I may be able to do some of the things above in Java or Rust but not nearly to the degree to which I can in languages I know. I think the difference is I'm probably not going to be leading a Java project or producing anything really innovative at a code level.To me, more important than picking a hammer, is knowing a variety of hammers that are good at certain tasks. I don't focus on Rust or Java as much because, frankly, I can build most things that are pertinent to the constraints of my work environment with those tools and most people I encounter also know them. The other considerable factor I have is that most things I work on can be horizontally scaled so my need for Rust is very niche. With respect to Java, I have a lot of workarounds that are cleanly abstracted enough before I need its dynamism and subsequent mental overhead.\n \nreply",
      "One of the most important qualities of Go is that it is actually possible to fully understand the language -- in the sense that you never see a snippet of Go code and think \"wtf, you can do that?\" or \"hang on, why does that work?\"Getting to that point takes many years, to be sure. But the language is simple enough, and changes slowly enough, that it is not an unrealistic goal -- the way it would be in C++, or Rust, or just about any other mainstream language.\n \nreply",
      "Personally my biggest issue with reading go code has come from the //go: magic comments that I never seem to fully understand.For example, what the heck is a //go:cgo_import_dynamic? As far as I can tell this is only documented on GitHub issues and mailing list comments.\n \nreply"
    ],
    "link": "https://www.maragu.dev/blog/go-is-my-hammer-and-everything-is-a-nail",
    "first_paragraph": "",
    "summary": "In a hilarious twist of faithfulness to his one true love, a software savant proclaims that learning a programming language is not unlike a medieval quest, requiring the better part of a decade to master. Indeed, the preferred dialect is \"Go,\" because who needs efficiency when your lifetime commitment can be to a tool resembling a rusty hammer? Commenters rush to support this digital monogamy, espousing the virtues of depth over breadth, and casually flexing their \"contribution\" to language evolution in between sips of artisanal coffee and keystrokes. Meanwhile, every once in a while, a lone voice questions whether maybe, just maybe, this saintly patience is somewhat absurd, only to be drowned out by the chants of hardcore language purists, proving once more that in the tech world, productivity is less about output and more about sounding profound on forums. \ud83d\udee0\ufe0f\ud83d\udcbb\ud83d\udd2e"
  },
  {
    "title": "Damn Vulnerable UEFI (github.com/hacking-support)",
    "points": 28,
    "submitter": "cloudripper",
    "submit_time": "2024-08-12T19:04:16",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/hacking-support/DVUEFI",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Damn Vulnerable UEFI\n      An Exploitation Toolkit and Learning Platform for Unveiling and Fixing UEFI Firmware Vulnerabilities\nPresented at Black Hat USA 2024 ArsenalInspired by projects such as Damn Vulnerable Web Application and OWASP's Damn Vulnerable Web Sockets, Damn Vulnerable UEFI (DVUEFI) is designed to help guide ethical hackers, security researchers, and firmware enthusiasts in getting started with UEFI firmware security, by facilitating the exploration of vulnerabilities by example.The DVUEFI project is engineered to simulate real-world firmware attacks, offering an environment for practicing and refining exploitation techniques.DVUEFI is accompanied by a robust, continuously evolving catalog of documented UEFI vulnerabilities.\nEach entry is detailed with exploitation methods, potential impacts, and strategic mitigation ",
    "summary": "Title: \"Introducing Damn Vulnerable UEFI: Hackers' New Playground\"\n\nIn a bold stride toward making sure every script kiddie can pretend to be a 1337 haxor, the new Damn Vulnerable UEFI toolkit arrives, promising to <em>transform</em> complete novices into firmware security experts overnight. Presented at Black Hat USA by shiny-slide aficionados, this toolkit allows you to poke at UEFI vulnerabilities from the comfort of your mom's basement. Watch as hobbyist hackers and seasoned commenters alike dive into the endless depths of 'strategic mitigations,' guided by a documentation labyrinth that would make Kafka weep. Isn't personal growth via publicly shared vulnerabilities what the internet was made for? \ud83e\udd13\ud83d\udd10"
  }
]