[
  {
    "title": "Breaking the 4Chan CAPTCHA (nullpt.rs)",
    "points": 170,
    "submitter": "hazebooth",
    "submit_time": "2024-11-29T20:32:22 1732912342",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=42276865",
    "comments": [
      "I wasn't a very active 4chan poster to begin with, but when they introduced this awful CAPTCHA, and later the 300s countdown before making the first post, I completely lost interest in using the website.Anonymous boards were supposed to be low-friction, but now 4chan is one of the most user-hostile social media platforms around. It takes a special kind of dedication to post there, which I seriously doubt helps the quality of the site.\n \nreply",
      "one of the biggest problems that 4chan has to combat is spam. unfortunately, at 4chan's scale, hcaptcha and recaptcha are not free. 4chan is not exactly a font of money, either. the only reason they turned to this awful homebrew captcha was because recaptcha stopped being free. is there any better way to do it with a single developer for a website that serves millions of people a day?\n \nreply",
      "> is there any better way to do\n    > it with a single developer for\n    > a website that serves millions\n    > of people a day?\n\nNo, the other reason they're using this is to make it so annoying that you'll spend $20/yr to buy a 4chan pass to bypass it.If you're not making your free website annoying to drive revenue there's obvious ways to make it less annoying.E.g. keep the annoying captcha, but don't show one again for the lifetime of a cookie, validate users who can make a money transfer of $0.01 etc.\n \nreply",
      "> keep the annoying captcha, but don't show one again for the lifetime of a cookieThis is already being done, there's a cookie and heuristics in place that will give you an easier captcha or occasionally skip it entirely. But 4chan really does have a couple (and I truly mean a small amount of super super dedicated users) of bad actors who constantly spam and try to work around any roadblocks given to annoy the rest of the userbase. You cannot give them a reliable way to spam no matter what. That's why there's now many country and region blocks in addition to your standard VPN/DC IP range blocks. Plus the Cloudflare check added a couple years ago.\n \nreply",
      "Yea, this is the now-classic \u201cannoy your users until they give in and pay\u201d model, like YouTube Premium.\n \nreply",
      "Do a Web search for \"4Chan CAPTCHA\" sometime. All the top results will likely be people complaining about how terrible it is. You're certainly not alone.The worst part about the countdown: if you wait too long to make a post after waiting the 10 minutes (eg: you get distracted,) it will expire, and you have to wait another 10 minutes.\n \nreply",
      "The addition of the post countdown has had a pretty noticeable effect on posts/day across multiple boards: https://4stats.io/When an earlier version was trialled on /biz/ (mandatory email verification - https://warosu.org/biz/thread/58388587), it nuked the board and it hasn't recovered.\n \nreply",
      "recaptcha is terrible if you are cursed with an ISP that Google deems icky for some indiscernible reason. at the time, I was getting slowly fading bullshit that invariably gaslit me with \"try again\" several times. when they've switched to custom captcha, I actually started posting again instead of just lurking.yeah, the recent 5-15 minute countdown before your first post is a bizarre thing, but I assume the volume of spam and ban-evading schizos they're dealing with is ungodly. a single dedicated shithead can shit up a general or a slow board indefinitely by just resetting their router or switching airplane mode on/off for a few minutes when they get banned.>but now 4chan is one of the most user-hostile social media platforms around.virtually every single big platform requires your phone number.\n \nreply",
      "They had a gigantic spam problem, captcha saved the site\n \nreply",
      "then how does Reddit and Twitter work without such an obnoxious captcha? I find it hard to believe those sites get less spam. Or any other community.\n \nreply"
    ],
    "link": "https://www.nullpt.rs/breaking-the-4chan-captcha",
    "first_paragraph": "",
    "summary": "**Breaking the 4Chan CAPTCHA: A Journey into Madness and Futility**\n\nIn the hallowed halls of 4chan, the introduction of a *tragic* CAPTCHA system has sent the site's last twelve users into a frenzied meltdown, triggering debates that swirl around the profound philosophy of \"how to make your userbase miserable for fun and non-profit.\" Commenter pros display their *exceptional* IT expertise, suggesting breakthrough solutions like \"just use a cookie, bro\" or the revolutionary \"make micro-transactions to prove humanity\" concept. Meanwhile, more practical minds debate the ethics of just paying $20 to avoid CAPTCHA hell, inadvertently supporting 4chan\u2019s transition into a pay-to-play torture chamber. But don't worry, kind-hearted netizens also offer a glimpse of hope\u2014just spam your outrage into the void of the internet where it will blend seamlessly with the background noise of the ever-decaying web. \ud83d\udcb8\ud83d\udd27"
  },
  {
    "title": "Why pipes sometimes get \"stuck\": buffering (jvns.ca)",
    "points": 275,
    "submitter": "tanelpoder",
    "submit_time": "2024-11-29T16:43:51 1732898631",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=42275033",
    "comments": [
      "The solution is that buffered accesses should almost always flush after a threshold number of bytes or after a period of time if there is at least one byte, \u201cthreshold or timeout\u201d. This is pretty common in hardware interfaces to solve similar problems.In this case, the library that buffers in userspace should set appropriate timers when it first buffers the data. Good choices of timeout parameter are: passed in as argument, slightly below human-scale (e.g. 1-100 ms), proportional to {bandwidth / threshold} (i.e. some multiple of the time it would take to reach the threshold at a certain access rate), proportional to target flushing overhead (e.g. spend no more than 0.1% time in syscalls).Also note this applies for both writes and reads. If you do batched/coalesced reads then you likely want to do something similar. Though this is usually more dependent on your data channel as you need some way to query or be notified of \u201cpending data\u201d efficiently which your channel may not have if it was not designed for this use case. Again, pretty common in hardware to do interrupt coalescing and the like.\n \nreply",
      "I think this is the right approach, but any libc setting automatic timers would lead to a lot of tricky problems because it would change expectations.I/O errors could occur at any point, instead of only when you write. Syscalls everywhere could be interrupted by a timer, instead of only where the program set timers, or when a signal arrives. There's also a reasonable chance of confusion when the application and libc both set timer, depending on how the timer is set (although maybe this isn't relevant anymore... kernel timer apis look better than I remember). If the application specifically pauses signals for critical sections, that impacts the i/o timers, etc.There's a need to be more careful in accessing i/o structures because of when and how signals get handled.\n \nreply",
      "You will generally only stall indefinitely if you are waiting for new data. So, you will actually handle almost every use case if your blocking read/wait also respects the timeout and does the flush on your behalf. Basically, do it synchronously at the top of your event loop and you will handle almost every case.You could also relax the guarantee and set a timeout that is only checked during your next write. This still allows unbounded latency, but as long as you do one more write it will flush.If neither of these work, then your program issues a write and then gets into a unbounded or unreasonably long loop/computation. At which point you can manually flush what is likely the last write your program is every going to make which would be a trivial overhead since that is a single write compared to a ridiculously long computation. That or you probably have bigger problems.\n \nreply",
      "Yeah, these are all fine to do, but a libc can really only do the middle one. And then, at some cost.If you're already using an event loop library, I think it's reasonable for that to  manage flushing outputs while waiting for reads, but I don't think any of the utilities in this example do; maybe tcpdump does, but I don't know why grep would.\n \nreply",
      "I don't follow. Using a pipe sets an expectation of some amount of asynchronicity, because we only control one end of the pipe. I don't see a dramatic difference between an error occurring because of the process on the other end is having trouble, or because of a timeout handler is trying to push the bytes.On the reading end, the error may occur at the attempt to read the pipe.On the writing end, the error may be signaled at the next attempt to write to or close the pipe.In either case, a SIGPIPE can be sent asynchronously.What scenario am I missing?\n \nreply",
      "> In either case, a SIGPIPE can be sent asynchronously.My expectation (and I think this is an accurate expecation) is that a) read does not cause a SIGPIPE, read on a widowed pipe returns a zero count read as indication of EOF. b) write on a widowed pipe raises SIGPIPE before the write returns. c) write to a pipe that is valid will not raise SIGPIPE if the pipe is widowed without being read from.Yes, you could get a SIGPIPE from anywhere at anytime, but unless someone is having fun on your system with random kills, you won't actually get one except immediately after a write to a pipe. With a timer based asynchronous write, this changes to potentially happening any time.This could be fine if it was well documented and expected, but it would be a mess to add it into the libcs at this point. Probably a mess to add it to basic output buffering in most languages.\n \nreply",
      "Typical Linux alarms are based on signals and are very difficult to manage and rescheduling them may have a performance impact since it requires thunking into the kernel. If you use io_uring with userspace timers things can scale much better, but it still requires you to do tricks if you want to support a lot of fast small writes (eg > ~1 million writes per second timer management starts to show up more and more and you have to do some crazy tricks I figured out to get up to 100M writes per second)\n \nreply",
      "You do not schedule a timeout on each buffered write. You only schedule one timeout on the transition from empty to non-empty that is retired either when the timeout occurs or when you threshold flush (you may choose to not clear on threshold flush if timeout management is expensive). So, you program at most one timeout per timeout duration/threshold flush.The point is to guarantee data gets flushed promptly which only fails when not enough data gets buffered. The timeout is a fallback to bound the flush latency.\n \nreply",
      "Yes that can work but as I said that has trade offs.If you flush before the buffer is full, you\u2019re sacrificing throughput. Additionally the timer firing has additional performance degradation especially if you\u2019re in libc land and only have a sigalarm available.So when an additional write is added, you want to push out the timer. But arming the timer requires reading the current time among other things and at rates of 10-20Mhz and up reading the current wall clock gets expensive. Even rdtsc approaches start to struggle at 20-40Mhz. You obviously don\u2019t want to do it on every write but you want to make sure that you never actually trigger the timer if you\u2019re producing data at a relatively fast enough clip to otherwise fill the buffer within a reasonable time.Source: I implemented write coalescing in my nosql database that can operate at a few gigahertz for 8 byte writes/s into an in memory buffer. Once the buffer is full or a timeout occurs, a flush to disk is triggered and I net out at around 100M writes/s (sorting the data for the LSM is one of the main bottlenecks). By comparison DBs like RocksDB can do ~2M writes/s and SQLite can do ~800k.\n \nreply",
      "You are not meaningfully sacrificing throughput because the timeout only occurs when you are not writing enough data; you have no throughput to sacrifice. The threshold and timeout should be chosen such that high throughput cases hit the threshold, not the timeout. The timeout exists to bound the worst-case latency of low access throughput.You only lose throughput in proportion to the handling cost of a single potentially spurious timeout/timeout clear per timeout duration. You should then tune your buffering and threshold to cap that at a acceptable overhead.You should only really have a problem if you want both high throughput and low latency at which point general solutions are probably not not fit for your use case, but you should remain aware of the general principle.\n \nreply"
    ],
    "link": "https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/",
    "first_paragraph": "\n\n\n  November 29, 2024\n  \n\nHere\u2019s a niche terminal problem that has bothered me for years but that I never\nreally understood until a few weeks ago. Let\u2019s say you\u2019re running this command\nto watch for some specific output in a log file:If log lines are being added to the file relatively slowly, the result I\u2019d see\nis\u2026 nothing! It doesn\u2019t matter if there were matches in the log file or not,\nthere just wouldn\u2019t be any output.I internalized this as \u201cuh, I guess pipes just get stuck sometimes and don\u2019t\nshow me the output, that\u2019s weird\u201d, and I\u2019d handle it by just\nrunning grep thing1 /some/log/file | grep thing2 instead, which would work.So as I\u2019ve been doing a terminal deep dive over the last few months I was\nreally excited to finally learn exactly why this happens.The reason why \u201cpipes get stuck\u201d sometimes is that it\u2019s VERY common for\nprograms to buffer their output before writing it to a pipe or file. So the\npipe is working fine, the problem is that the program never even wrote the data\nto t",
    "summary": "In yet another *life-changing* discourse from the niche world of terminal cautionary tales, we learn why pipes \"get stuck,\" and it turns out it's as shockingly mundane as you feared: buffering. Meanwhile, the armchair engineers in the comments heroically sprint past the basics to debate whether it's better to preemptively hammer userspace with timers or reconstruct the library of Alexandria in libc form. Proposed solutions swing from gracelessly hacking signal handlers to just hoping for some extra cosmic rays to trigger the necessary syscalls, showcasing a splendid parade of technical bravado that's almost as effective as actually reading the documentation. Delightful to see how a simple I/O pause can catalyze an existential crisis over timer APIs."
  },
  {
    "title": "Llama.cpp guide \u2013 Running LLMs locally on any hardware, from scratch (steelph0enix.github.io)",
    "points": 254,
    "submitter": "zarekr",
    "submit_time": "2024-11-29T15:28:34 1732894114",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=42274489",
    "comments": [
      "Neat to see more folks writing blogs on their experiences. This however does seem like it's an over-complicated method of building llama.cpp.Assuming you want to do this iteratively (at least for the first time) should only need to run:  ccmake .\n\nAnd toggle the parameters your hardware supports or that you want (e.g. if CUDA if you're using Nvidia, Metal if you're using Apple etc..), and press 'c' (configure) then 'g' (generate), then:  cmake --build . -j $(expr $(nproc) / 2)\n\n\nDone.If you want to move the binaries into your PATH, you could then optionally run cmake install.\n \nreply",
      "Wow, i did not know about ccmake.\nI'll check it out and edit the post if it's really that easy to use, thanks.\n \nreply",
      "Yeah the mingw method on windows is a ludicrous thing to even think about, and llama.cpp still has that as the suggested option in the readme for some weird reason. Endless sourcing of paths that never works quite right. I literally couldn't get it to work when I first tried it last year.Meanwhile Cmake is like two lines and somehow it's the backup fallback option? I don't get it. And well on linux it's literally just one line with make.\n \nreply",
      "First time I heard about Llama.cpp I got it to run on my computer. Now, my computer: a Dell laptop from 2013 with 8Gb RAM and an i5 processor, no dedicated graphic card. Since I wasn't using a MGLRU enabled kernel, It took a looong time to start but wasn't OOM-killed. Considering my amount of RAM was just the minimum required, I tried one of the smallest available models.Impressively, it worked. It was slow to spit out tokens, at a rate around a word each 1 to 5 seconds and it was able to correctly answer \"What was the biggest planet in the solar system\", but it quickly hallucinated talking about moons that it called \"Jupterians\", while I expected it to talk about Galilean Moons.Nevertheless, LLM's really impressed me and as soon as I get my hands on better hardware I'll try to run other bigger models locally in the hope that I'll finally have a personal \"oracle\" able to quickly answers most questions I throw at it and help me writing code and other fun things. Of course, I'll have to check its answers before using them, but current state seems impressive enough for me, specially QwQ.Is Any one running smaller experiments and can talk about your results? Is it already possible to have something like an open source co-pilot running locally?\n \nreply",
      "Hey, author of the blog post here.\nCheck out avante.nvim if you're already a vim/nvim user, I'm using it as assistant plugin with llama-server and it works great.Small models, like Llama 3.2, Qwen and SmolLM are really good right now, compared to few years ago\n \nreply",
      "Open Web UI [1] with Ollama and models like the smaller Llama, Qwen, or Granite series can work pretty well even with CPU or a small GPU. Don't expect them to contain facts (IMO not a good approach even for the largest models) but they can be very effective for data extraction and conversational UI.1. http://openwebui.com\n \nreply",
      "You might also try https://github.com/Mozilla-Ocho/llamafile , which may have better CPU-only performance than ollama. It does require you to grab .gguf files yourself (unless you use one of their prebuilts in which case it comes with the binary!), but with that done it's really easy to use and has decent performance.For reference, this is how I run it:  $ cat ~/.config/systemd/user/llamafile@.service\n  [Unit]\n  Description=llamafile with arbitrary model\n  After=network.target\n  \n  [Service]\n  Type=simple\n  WorkingDirectory=%h/llms/\n  ExecStart=sh -c \"%h/.local/bin/llamafile -m %h/llamafile-models/%i.gguf --server --host '::' --port 8081 --nobrowser --log-disable\"\n  \n  [Install]\n  WantedBy=default.target\n\nAnd then  systemctl --user start llamafile@whatevermodel\n\nbut you can just run that ExecStart command directly and it works.\n \nreply",
      "Be careful running this on work machines \u2013 it will get flagged by Crowdstrike Falcon and probably other EDR tools. In my case the first time I tried it, I just saw \u201cKilled\u201d and then got a DM from SecOps within two minutes.\n \nreply",
      "Is that `--host` listening on non-local addresses? Might be good to default to local-only.\n \nreply",
      "What you describe is very similar to my own experience first running llama.cpp on my desktop computer.  It was slow and inaccurate, but that's beside the point.  What impressed me was that I could write a question in English, and it would understand the question, and respond in English with an internally coherent and grammatically correct answer.  This is coming from a desktop, not a rack full of servers in some hyperscaler's datacenter.  This was like meeting a talking dog!  The fact that what it says is unreliable is completely beside the point.I think you still need to calibrate your expectations for what you can get from consumer grade hardware without a powerful GPU.  I wouldn't look to a local LLM as a useful store of factual knowledge about the world.  The amount of stuff that it knows is going to be hampered by the smaller size.  That doesn't mean it can't be useful, it may be very helpful for specialized domains, like coding.I hope and expect that over the next several years, hardware that's capable of running more powerful models will become cheaper and more widely available.  But for now, the practical applications of local models that don't require a powerful GPU are fairly limited.  If you really want to talk to an LLM that has a sophisticated understanding of the world, you're better off using Claude or Gemeni or ChatGPT.\n \nreply"
    ],
    "link": "https://steelph0enix.github.io/posts/llama-cpp-guide/",
    "first_paragraph": "No LLMs were harmed during creation of this post.\u2026and it\u2019s pretty fun.\nI was very skeptical about the AI/LLM \u201cboom\u201d back when it started.\nI thought, like many other people, that they are just mostly making stuff up, and generating uncanny-valley-tier nonsense.\nBoy, was i wrong.\nI\u2019ve used ChatGPT once or twice, to test the waters - it made a pretty good first impression, despite hallucinating a bit.\nThat was back when GPT3.5 was the top model. We came a pretty long way since then.However, despite ChatGPT not disappointing me, i was still skeptical.\nEverything i\u2019ve wrote, and every piece of response was fully available to OpenAI, or whatever other provider i\u2019d want to use.\nThis is not a big deal, but it tickles me in a wrong way, and also means i can\u2019t use LLMs for any work-related non-open-source stuff.\nAlso, ChatGPT is free only to a some degree - if i\u2019d want to go full-in on AI, i\u2019d probably have to start paying.\nWhich, obviously, i\u2019d rather avoid.At some point i started looking at op",
    "summary": "Steelph0enix bravely ventures into the world of running large language models locally, fearing neither data leakage nor bankruptcy from cloud AI fees. Commenters quickly dive into technical jargon, showcasing their vast superiority in making something simple sound as complex as possible. One commenter unleashes a saga about running LLMs on a prehistoric laptop, inadvertently penning a perfect horror story for techie campfires. Meanwhile, the blog's creator nods along, updating posts with every gleam of \"easier method\" thrown by the comment section wizards. \ud83e\uddd9\u200d\u2642\ufe0f\ud83d\udcbb\ud83d\udd27"
  },
  {
    "title": "Brick and Mortar Triangle Fraud (getcho.app)",
    "points": 22,
    "submitter": "jackconsidine",
    "submit_time": "2024-11-29T23:07:24 1732921644",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42277925",
    "comments": [
      "You could do all that, or just require PINs for credit purchases.  They're not near as good as passwords, but PINs are still much, much better than nothing.\n \nreply",
      "Or do the sensible thing, which is a proper active confirmation from customer's device. It's more convenient too -- you just scan the payment qr code with your bank's app and click confirm instead of entering any numbers.\n \nreply",
      "This isn't really a thing in the US. (Technically 3D Secure exists but customers will just bounce.)\n \nreply",
      "I've dealt with some of this in past roles and can confirm it's like playing whack a mole trying to shut it down.\n \nreply",
      "So we blocked the order, reported the card to Stripe and alerted the police, the store and the unknowing consumer. In one case, we got a hold of the cardholder who confirmed his wallet had been stolen. For a few weeks, we played a big game of whack-a-mole and prevented a dozen instances of triangle fraud.How often do police respond? is there a follow-up? I imagine the police get inundated with reports and are overwhelmed to to anything . Would it go to FBI or just local ?\n \nreply",
      "Sometimes police refuse to accept the reports because they're in another jurisdiction (you can't file a police report in X town unless you're there).To your point they usually don't have time. The report serves as a record for the retailer and the victim to float around, but practically it doesn't catch anyone sadly\n \nreply",
      "I tried to buy something online from CDW. 5 days after the purchase I got a call from CDW trying to confirm I ordered the items.I said I had and the response was ok I just need to ask you 32 questions. The first question was my order number. I didn\u2019t know the answer to the first question which was my order number. I could have dropped everything and focused on these questions. I felt that the burden on my time was too much and they said I couldn\u2019t continue without it.\nThe experience was very weird considering how convenient online ordering can be\n \nreply",
      "Insurance may want you to report fraud/theft to the police (even if they know it does nothing).AFAIK the FBI can handle fraud over $5,000 but they won't do anything unless it's much bigger.\n \nreply"
    ],
    "link": "https://getcho.app/blog/triangle-fraud-brick-mortar/",
    "first_paragraph": "A while back, Krebs dropped a piece about a guy caught in triangle fraud scheme; below is the infographic he used.When this piece came out, we didn\u2019t know what it was called, but Getcho had been blocking triangle fraud for about six months. Today, Getcho helps retailers with their local delivery strategy and fraud protection comes out of the box.All over the world, bad actors buy and sell stolen credit cards on the black market. While you can buy things online with a stolen card, it\u2019s not always easy to repay one\u2019s \u201cinvestment\u201d and turn credit into cash. A naive strategy would be to buy merchandise and then sell it elsewhere \u2014 you could buy with credit and sell for cash.There are two challenges with this strategy:So criminals use a form of drop-shipping:Just one more wrinkle: Victims often flag fraudulent purchases and asset protection departments investigate. Since the retailer knows the delivery address, the unknowing recipient can be contacted. They are then prone to charging back a",
    "summary": "<em>Brick and Mortar Triangle Fraud</em> strikes again, and the internet's best armchair generals are on the case in the comments section! User A suggests \ud83e\udd14 using PINs, because obviously remembering another number on top of the 16 from your credit card, mom\u2019s birthday, and that locker combination from high school is <i>super easy</i>. Meanwhile, User B champions the magic of QR codes \ud83d\udcf1 because tapping to confirm is way better than typing... unless your app crashes. As for the American User C: 3D Secure? Never heard of her! \u26b0\ufe0f\ud83d\udc80 Everyone agrees that while fraudsters run wild, suggesting functional security measures is a full-time hobby\u2014next to ignoring how none of it effectively stops crime as well as their daydreams do."
  },
  {
    "title": "What does this button do? \u2013 My new car has a mysterious and undocumented switch (koenvh.nl)",
    "points": 240,
    "submitter": "Koenvh",
    "submit_time": "2024-11-29T19:59:47 1732910387",
    "num_comments": 162,
    "comments_url": "https://news.ycombinator.com/item?id=42276620",
    "comments": [
      "The scary part is not the GPS installed by the fleet company that previously owned the car, which in all likelihood was just forgotten there, but the GPS and eSIM that comes with most (all?) new cars and that in most (all?) new cars cannot be disabled.Apart from privacy concerns of your data being used or sold by the car vendor, government outreach is also a concern. There was a bill announced in the US for all new cars to be equipped with \"driver impairment\" tech which was called a \"kill switch\". Media rushed to say it's not really a kill switch, just \"sensors or cameras to monitor the driver\u2019s behaviors, head or eye movements\" and \"block the driver from operating the vehicle\". So... a kill switch. https://apnews.com/article/fact-checking-402773429497Anyway, I'm staying with my old gas Honda until it dies which is probably never with proper maintenance and eventually restoration. I'll never go electric. Modern cars are just smartphones on wheels at this point, and smartphones are just spying devices at this point.\n \nreply",
      "That whole system looks like what we install on police patrol cars.  Left switch allows you to keep car running even when keys are removed  (but you can\u2019t drive it will kill the ignition).GPS is for obvious reasons tracking.  But these don\u2019t look like patrol cars so it\u2019s out of my wheel house.\n \nreply",
      "I'm with you here. I have an 89 BMW (which is old enough to have an actual servo motor attached to the intake manifold for cruise control) and an 83 Land Cruiser (whose most advanced feature is that it controls its emissions using vacuum controlled pneumatic circuitry).I'm very glad I've put in the time to learn how to work on cars because I have zero interest in the tech direction of modern vehicles.\n \nreply",
      "87 BMW here. I believe my servo is controlling the throttle cable itself. When the cruise control commands the vehicle to accelerate, the pedal physically moves.It's not my daily driver, but I would absolutely love to one day get another one as a project car - one that's not in such good condition that I'd feel bad removing the engine - and drop an electric motor in it. That likely _would_ become my daily driver. The car's incredibly well made, and a joy to drive.\n \nreply",
      "> 89 BMW ... and an 83 Land CruiserI'm with you. Our daily drivers are 2011 Mitsu, 96 Toyota, 92 Buick and a 63 Dart. Also a 61 Sunliner for when it's not-summer.The Mitsu is unfortunately drive-by-wire; I mostly avoid it.\n \nreply",
      "Last year Mozilla did a study on the privacy of modern cars. Every car they tested showed terrible privacy problems.Privacy Nightmare on Wheels: Every Car Brand Reviewed by Mozilla https://news.ycombinator.com/item?id=37443644(edit I see I'm not the first to link this in this thread)\n \nreply",
      "> Most people would have probably driven around for years with a foreign GPS tracker.So basically everyone with a smartphone? I'm not sure if it's really worse if the car has its own GPS and cell connectivity. How many people turn off their phone or leave it at home? And you can buy other people's location data, so...\n \nreply",
      "> So basically everyone with a smartphoneTbh considering the accuracy of modern triangulation technology... anyone with a cellphone, period.\n \nreply",
      "You can turn off your phone or go into airplane mode. Can you do that with your car? Even if most people don't use that option on a daily basis, doesn't mean it's fine.\n \nreply",
      "So you put it in airplane mode while in a car and then disable airplane mode when you get to your destination? What's the point of that?\n \nreply"
    ],
    "link": "https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr",
    "first_paragraph": "4 min readLast week I bought a car. After twelve years of service, my old trusty Peugeot 107 in blue has had its best. Expensive repairs were coming at some point, and I did not feel like waiting around for them to come. Plus the existing list of faults (like the high oil usage of about a litre per month, a brake that sometimes blocked without reason, or the smell of exhaust fumes that sometimes came into the car when the fan was on high) also started getting longer and longer.Anyway, new car time! After a lot of research I ended up with an Opel Corsa from 2020. To be precise, it\u2019s an Opel Corsa Edition with 101 HP, and most importantly, it\u2019s mine.Unlike the Peugeot, the Opel has gadgets - quite a few of them. Of course it being my car, I want to know what all buttons do, so I read the entire manual (which is very annoying to read, as they make one manual for every version of the car, so half of it does not apply to this car, but I digress). One of those buttons was the following below",
    "summary": "<b>What does this button do?</b> \u2013 A bewildered new car owner <em>discovers</em> a mysterious switch that could either be an advanced flux capacitor or, more likely, the sign that he should have paid more attention during the dealership upsell. Meanwhile in the comments, a lively nostalgia fest breaks out as every commenter drags their 'vintage' rust-buckets into the spotlight, collectively agreeing that anything invented after the floppy disk is basically Skynet on wheels. Bonus content: a sprinkle of paranoia about big brother, with claims of privacy invasion that make a CCTV-filled alleyway look like a yoga retreat. \ud83d\ude97\ud83d\udca8\ud83d\udd75\ufe0f\u200d\u2642\ufe0f"
  },
  {
    "title": "The Influence of Bell Labs (construction-physics.com)",
    "points": 80,
    "submitter": "mooreds",
    "submit_time": "2024-11-29T18:36:34 1732905394",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=42275944",
    "comments": [
      "During my teenage and college years in the 2000s, I was inspired by what I\u2019ve read about Bell Labs, and I wanted to work as a computer science researcher in industry.  I\u2019ve also been inspired by Xerox PARC\u2019s 1970s and 1980s researchers.  I pursued that goal, and I\u2019ve worked for a few industrial research labs before I switched careers to full-time community college teaching a few months ago.One thing I lament is the decline of long-term, unfettered research across the industry.  I\u2019ve witnessed more companies switching to research management models where management exerts more control over the research directions of their employees, where research directions can abruptly change due to management decisions, and where there is an increased focus on profitability.  I feel this short-term approach will cost society in the long term, since current funding models promote evolutionary work rather than riskier, potentially revolutionary work.As someone who wanted to become a researcher out of curiosity and exploration, I feel alienated in this world where industry researchers are harangued about \u201cdelivering value,\u201d and where academic researchers are pressured to raise grant money and to publish.  I quit and switched to a full teaching career at a community college.  I enjoy teaching, and while I miss the day-to-day lifestyle of research, I still plan to do research during my summer and winter breaks out of curiosity and not for career advancement.It would be great if there were more opportunities for researchers to pursue their interests.  Sadly, though, barring a cultural change, the only avenues I see for curiosity-driven researchers are becoming independently wealthy, living like a monk, or finding a job with ample free time.  I\u2019m fortunate to have the latter situation where I have 16 weeks per year that I could devote outside my job.\n \nreply",
      "Okay, I'm really in a sad mood, so: tell me there will be places like that, again, somewhere, ever ?We need this. Like, really, we need someone to have created the xerox part of the 21st century, somewhere about 20 years ago.I honestly though Google would be that - but apparently it's easier to fund R&D on \"selling copying machines\" than \"selling ads\". Maybe \"selling ads\" earn _too much_ money ? I don't know.I know, I know, DeepMind and OpenAI and xAI are supposed to fix climate change any time soon, and cure cancer while they invent cold fusion etc, etc... and it's only because I'm a pessimistic myopist that I can only see them writing fake essays and generating spam, bad me.Still. Assuming I'm really grumpy and want to talk about people doing research that affects the physical world in positive way - who's doing that on the scale of PARC or Bell ?\n \nreply",
      "The secret hero of that time was the US government. I\u2019m not talking about the MIC, which is still quite robust and more bad than good. I am speaking more broadly. If you had a practical PhD and were willing to show up at a place at 9:00, you could get a solid upper middle class job with the Feds where you couldn\u2019t get fired unless you broke the law.The government also has always kept academia afloat. It is a privilege afforded to professors to believe they do not work for the state, but they do.Great government and academic jobs forced companies to create these labs where it was better to hire great people and \u201close\u201d some hours to them doing whatever they want (which was still often profitable enough) than have zero great people. Can you imagine Claude Shannon putting up with the stuff software engineers deal with today?The other main change is that how to run big companies has been figured out well enough that \u201czero great people\u201d is no longer a real survival issue for companies. In the 1970s you needed a research level of talent but most companies today don\u2019t.\n \nreply",
      "Something that just dawned on me is the downstream effects of United States\u2019 policy regarding science during WWII and the Cold War.  The Manhattan Project, NASA, the NSA and all of its contributions to mathematics and cryptography, ARPA, DARPA, and many other agencies and programs not only directly contributed to science, but they also helped form a scientific culture that affected not only government-ran and government-funded labs, but also private-sector labs, as people and ideas were exchanged throughout the years.  It is a well-documented fact that Xerox PARC\u2019s 1970\u2019s culture was heavily influenced by ARPA\u2019s 1960\u2019s culture.One of the things that has changed since the 1990s is the ending of the Cold War.  The federal government still has national laboratories, DARPA, NASA, the NSF, etc.  However, the general culture has changed.  It\u2019s not that technology isn\u2019t revered; far from it.  It\u2019s just that \u201cstopping Hitler,\u201d \u201cbeating the Soviets,\u201d and grand visions for society have been replaced with visions of creating lucrative businesses.  I don\u2019t hear about the Oppenheimers and von Neumanns of today\u2019s world, but I hear plenty about Elon Musk and Sam Altman, not to disrespect what they have done (especially with the adoption of EVs and generative AI, respectively), but the latter names are successful businessmen, while the former names are successful scientists.I don\u2019t know what government labs are like, but I know that academia these days have high publication and fundraising pressures that inhibit curiosity-driven research, and I also know that industry these days is beholden to short-term results and pleasing shareholders, sometimes at the expense of the long-term and of society at large.\n \nreply",
      "> who's doing that on the scale of PARC or Bell ?You correctly identified Google, but your pessimism and myopia (which you also correctly identified) seems to be getting in the way.Groundbreaking things (like the transistor) can take decades to have an impact on society. And there are at least a few things from Google that are on that trajectory:- AlphaFold (just won a Nobel prize)- Transformers (the \"T\" in GPT)- Waymo (autonomous vehicles)\n \nreply",
      "HmmThere are companies that push many various technologiesSamsung conglomerate does everything, Intel does hard (semiconductor research, manufacturing) and soft (computer science/software) thingsMaybe we're at the point where you need to specialize in one industry, so achieving various stuff like they did at Bell is harder?\n \nreply",
      "> honestly though Google would be that - but apparently it's easier to fund R&D on \"selling copying machines\" than \"selling ads\". Maybe \"selling ads\" earn _too much_ money ? I don't know.I'm pretty sure Google Brain was exactly what you are looking for: People like to think of DeepMind, but honestly, Brain pretty much had Bell Labs/PARCs strategy: they hired a bunch of brilliant people and told them to just \"research whatever is you think is cool\". And think all the AI innovations that came out of Brain and were given to the world for free: Transformers, Vision Transformers, Diffusion Models, BERT (I'd consider that the first public LLM), Adam, and a gazillion of other cool stuff I can't think of right now.... Essentially, all of the current AI/LLM craze started at Brain.\n \nreply",
      "Right. And I'm sure that if I ever get in a better mood, I'll find that the current AI/LLM craze is good for _something_.Right now the world needs GWh batteries made of salt, cheap fusion from trash, telepathy, a cure for cancer and a vaccine for the common cold - but in the meantime, advertisers can generate photos for their ads, which is, _good_, I guess ?\n \nreply",
      "It does sound like you're in a particularly bad mood, so yes, maybe our outlook does change. Maybe it helps to think of a darker timeline where Google would have kept all of these advances to itself  and improved its ad revenue. Instead it shared the research freely with the world. And call me naive, but I use LLMs almost daily, so there definitely _is_ something of value that came out of all this progress. But YMMV, of course.\n \nreply",
      "Once we get superintelligence \u2014 some time next year I\u2019d say \u2014 then we will have a tool to make all those dreams come true.\n \nreply"
    ],
    "link": "https://www.construction-physics.com/p/the-influence-of-bell-labs",
    "first_paragraph": "",
    "summary": "In a soul-crushing episode of \"Nostalgia vs. Reality,\" a former wannabe-researcher-turned-educator cries into the void of the internet about the tragic demise of curiosity-driven research posts at Bell Labs, now extinct like the dodo. Commentators gather around the digital campfire, tears in their eyes, waxing poetic about the 'good old days' of industrial research giants and cruelly juxtaposing them against today\u2019s soulless corporate overlords who would rather invent another ad revenue model than, say, cure cancer. One deeply melancholic soul questions if a real life Xerox PARC could ever emerge in today\u2019s world, dismissing current initiatives as mere generators of AI buzzwords and spam. The consensus? Unless you're independently wealthy or willing to live monastically, you might as well teach summer school and try to forget how capitalism has euthanized the spirit of unfettered exploration. \ud83e\udd16\ud83d\udc94\ud83d\udcc9"
  },
  {
    "title": "The Hall SC-VGA-2 Video Processor, the Atari ST and NeXTSTEP (oldvcr.blogspot.com)",
    "points": 15,
    "submitter": "todsacerdoti",
    "submit_time": "2024-11-29T22:16:28 1732918588",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42277604",
    "comments": [
      "I'm surprised they dismissed the OSSC [1] so easily. It's not \"just\" for game consoles and arcade equipment. It has a VGA port on it for a reason!Admittedly I haven't used it for anything nearly as \"esoteric\" as some of the gear Cameron has I'd be surprised if he encountered any issues. Though being open source I'd suspect if he did he could simply fix them himself in the OSSC's firmware if needed!An OSSC will happily upscale any weird resolution/framerate you feed it to something modern HDMI devices can \"understand\". I use an \"EVGA XR1 Lite\" [2] to take the OSSC's HDMI output and feed it in over UVC to my laptop with USB-C. Works flawlessly and is dirt cheapIf Cameron wants a bit more of an \"all-in-one\" solution, myself and other retro tech youtubers like Tech Tangents, RetroRGB and others use old Datapath RGB E1S cards [3]. This thing is basically just a DVI port glued to an FPGA. It doesn't care about \"resolution\" or \"refresh rate\" it just DMA's raw pixel data right into RAM and lets what ever application you point at it decipher it. Personally I think they're pretty awful (comparatively) to the above option. The driver is a binary blob (so it probably won't work on Cameron's POWER machine) and it crashes a lot both under Windows and Linux. Though it seems more agreeable under Windows for changing resolution and other settings via OBS[1] https://www.retrorgb.com/ossc.html[2] https://www.evga.com/products/product.aspx?pn=141-U1-CB20-LR[3] https://www.datapathltd.com/datapath-products/video-capture-...\n \nreply",
      "Oooh! I wonder if I can find one of those. I'd love a way to see all of the Amiga screenmodes on a single display :)\n \nreply"
    ],
    "link": "http://oldvcr.blogspot.com/2024/11/the-hall-sc-vga-2-video-processor-atari.html",
    "first_paragraph": "REWIND and PLAY\nWhile you might be able to trick the hardware into emitting a compatible signal, that's not good enough or even possible with several of my machines. Previously my problem child was astro, my SAIC Galaxy 1100, a modified PA-RISC HP 9000/712 crammed into a MIL-SPEC portable case with a fabulous built-in flat panel. These machines ran HP-UX 10.10 in their original heyday, but this particular system runs NeXTSTEP 3.3 for PA-RISC during the brief period of time NeXT supported the architecture and was a big hit at the Vintage Computer Festival West a few years ago. Its flat panel runs at an odd 62Hz and the external VGA port only generates a 60Hz signal for 640x480 (all other resolutions use different refresh rates), which is hopeless for running NeXTSTEP. However, now I have a new candidate I'd like to get some grabs off: a particularly problematic member of the Atari ST family which has been the subject of a long-running and highly frustrating extended Refurb Weekend. You'",
    "summary": "**Title: Dusting Off Techno-Relics: A Cry For Help Disguised as a Blog Post**  \n<i>Brace yourselves</i> for the riveting saga of Cameron and his quixotic quest to mate NeXTSTEP with arcane hardware that most had the sense to abandon by the late \u201890s. Cue the tears for the horrifically niche plight of the Atari ST \u2013 a sad creature whose refresh rates haunt Cameron\u2019s high-tech dreams. Meanwhile, the comment section morphs into an anorak convention, where terms like \"OSSC\" and \"EVGA XR1 Lite\" are thrown around like candy at a parade, and everyone miraculously morphs into an overnight engineer. Surely, this equipment rivalry will soon air as a limited series on the most obscure corner of YouTube, awarding the most arduous commenter with the crown of Ultimate Retro King. \ud83c\udfc6"
  },
  {
    "title": "Jank is now running on LLVM IR (jank-lang.org)",
    "points": 56,
    "submitter": "Jeaye",
    "submit_time": "2024-11-29T20:05:14 1732910714",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42276672",
    "comments": [
      "Congratulations on the achievement!Ever since I got into Clojure I have wanted what you are building. I love the language, I love the collections, but I don't love waiting for program startup.I can't wait until Jank is complete!In fact, how can we help at the moment?\n \nreply",
      "Thanks! I'm exciting to get it released.With the three mentees I have, plus my own tasks cruising along, the best way people can help is to build up interest and visibility in jank. Follow, repost, share, like, etc. Once jank is released, I want to make the largest splash we can.If you have the financial means to sponsor my work, that also helps. I'm quitting my job at EA in January to focus on jank full-time for 2025 and I'd really like to secure some form of stability in terms of funding by the end of 2025.\n \nreply",
      "> but I don't love waiting for program startup.Question for curiosities sake, how many times per day do you start this program?I've moved most of my tiny CLI utilities from Clojure to Babashka (with it's handy \"cat together bb + your script\" workflow) but all the rest is still Clojure, as I don't restart them very frequently.\n \nreply",
      "Clojure is a quirky language, and I really enjoyed writing a proof-of-concept microservice with it back in 2015-era when everyone was shouting \"Scala is the way!\" I was able to prototype with it and stand it up in a weekend. With the tiniest bit of code, I had the exact service I needed. It ended up in production after only spending a couple weeks, most of which was spent wrapping my head around Docker and Mesos that we used to run the .jar.However, it's a quirky language. So, my quick take, as a glue layer on top of the JVM, it was quite powerful, but jank has me scratching my head. LISP doesn't really read well the bigger the codebase, and as something to write software in standalone environment, it makes me a bit hesitant.I sometimes would hit walls, because in real world software, you need persistent state. Functional software, for obvious reasons, fights against that, and so modeling state is actually quite difficult. This is where I think, as a small layer on top, it's fast and effective. I would just not want to write more than a few files with it though. Happy to follow along this project though and see where it goes.\n \nreply",
      "Often times, when people learn Clojure, they are also learning functional programming and lisp and data-oriented programming and interactive programming all at once. Writing Clojure requires a shift in perspective, coming from the imperative and object-oriented paradigms, and without that shift, even basic programs can seem impossible to build. This shift was very difficult for me, coming from C/C++/C#/Rust, and I've spoken with many others who've felt the same. I suspect, when you talk about hitting walls due to state, it's due to that perspective shift not being complete.Does that mean I'm saying Clojure is the best lang for everyone and it's their fault if they don't get it yet? No, certainly not. We need to do better with that, in the Clojure world, to make that bridge easier to cross. But, having fought my way across that bridge, I can confidently say that mutable state is no problem in Clojure. We have first-class support for it and that support is thread-safe by default. Unlike something like Haskell, effects aren't scary and don't need to be wrapped. They can be adhoc.jank inherits all of this and just brings it to the native world. That means lighter binaries, faster startup, and easier interop with native libs. Aside from that, it's Clojure.\n \nreply",
      "> I sometimes would hit walls, because in real world software, you need persistent state. Functional software, for obvious reasons, fights against that, and so modeling state is actually quite difficult.I haven't felt this, Clojure has good primitives for dealing with state, both temporary and more permanent. The biggest difference from (most) mainstream languages is that it's very explicit what has state and where you're mutating it. But personally I feel like that makes it easier to manage complicated state relationships, rather than harder, since it's typically isolated in smaller parts.\n \nreply",
      "Clojure offers so many ways for you to manage state for different use cases. Atoms, volatiles, agents, vars, refs.Functional programming never fights against persistent state. It simply carves out the functionality by use cases and offer you more choice in managing it.\n \nreply",
      "Hi Jeaye, love what you and the other contributors are doing with jank. The further proliferation of clojure dialects can't happen quickly enough imo.Do you have any \"killer app\" style use cases in mind for jank? Babashka is great in CLI/FaaS settings, native Clojure is great for \"situated\" programs that can afford a JVM startup and some memory overheadWhich settings are you particularly excited to use jank in?\n \nreply",
      "I may be biased, having built a career in game dev, but I would love to see people developing games using a REPL. Many games these days use Lua or similar for scripting logic, since it doesn't need to be written in C++, it can change at runtime, and it's reasonably fast. jank is all of those things, too! I think, if we can get jank into Unreal Engine, Unity, Godot, etc so that people can use their existing tool set, write functional code, and use interactive programming, it could be a game changer for game dev.Another great use case, I think, is desktop GUI dev. Outside of Humble UI, which is still very new, Clojure's GUI story has been quite bad. The native world has all sorts of GUI options though and jank will be introducing them to Clojurists.I think jank will be a good option for anyone who wants to use certain native libraries along with their Clojure programming. Jack Rusher, for instance, has said there are native graphics libs he'd love to use and jank is a promising way to do that.Finally, I aim to provide a cargo-like experience (if you're familiar with Rust) for jank. This should make building native apps easy. As I alluded to in my post, building C and C++ apps is a pretty terrible experience. If jank can make that twice as easy, for example, it could be that native devs end up preferring it as their project baseline. Since jank allows for arbitrary C++ to be included alongside the jank sources, and required as though it's a Clojure namespace, it actually ends up being a pretty sane way to write programs which involve a lot of C++.With all of that said, I don't imagine I'll be working on anything other thank jank for quite some time. I think of these mainly as things I'm excited to see others do. :)\n \nreply",
      "This is literally why I just downloaded it 2 days ago, but I was having issues compiling it.I'm very interested in simulation games with a lot of numeric calculation behind the scenes.\n \nreply"
    ],
    "link": "https://jank-lang.org/blog/2024-11-29-llvm-ir/",
    "first_paragraph": "Hi everyone! It's been a very busy couple of months as I've been developing jank's LLVM IR generation, improving jank's semantic analysis, and furthering jank's module loading system. Thank you to all of my Github sponsors and to Clojurists Together, who help me pay the bills. As of January 2025, I'll be working on jank full-time and every new sponsor means that much more. Without further ado, let's dive into the details of the past couple of months.LLVM IRThe main focus of the past couple of months has been filling out jank's LLVM IR generation. This has required further improving some of its semantic analysis since I was previously able to cut some corners when generating C++ code.At this point, all AST nodes in jank have working and tested IR generation except for try, since doing so requires hooking into the C++ runtime's unwind mechanism and I've been saving that rabbit hole for last.IR generation has caused so many fun bugs the past couple of months that I had to look into a bett",
    "summary": "In the eternal quest to reinvent the wheel more roundly, the programming maverick behind *jank* delves into the abyss of LLVM IR, making every Clojurist's dream a tad less janky. Naturally, downloading this marvel is as buggy as expected, prompting a nostalgic trip to the days of \u201cbut it works on my machine!\u201d syndrome. Meanwhile, in the comments, aficionados ardently wax poetic about their love-hate relationship with startup times, managing state in functional paradigms, and the eerie thrill of programming games in a language as austere as Clojure. Unsurprisingly, the echo chamber reassures itself of the impending omnipotence of jank, poised to revolutionize game development, desktop GUIs, and maybe even the coffee maker \u2013 because why not? \ud83d\ude44"
  },
  {
    "title": "Calmy Leon \u2013 The Ultimate Relaxing Music and Sound Generator (calmyleon.com)",
    "points": 36,
    "submitter": "StefanBatory",
    "submit_time": "2024-11-29T18:52:57 1732906377",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42276078",
    "comments": [
      "This is nice. I use https://mynoise.net, which does kind of the same thing, but has dozens (hundreds?) of recorded sound clips and about a trillion settings to tweak!\n \nreply",
      "> https://mynoise.net, which does kind of the same thingAs it should since they're both from Mr Pigeon.(If you donate to mynoise, you also get a free pro calmyleon account.)\n \nreply",
      "Same creator.\n \nreply",
      "There's also https://brainaural.com/ which I quite like and think pairs well with this site.(Of course it is also created by Dr. Pigeon, as most of these high-quality background noise websites seem to be.)\n \nreply",
      "Looks cool but I can't really use it as it doesn't currently seem to be responsive to mobile.\n \nreply"
    ],
    "link": "https://calmyleon.com/",
    "first_paragraph": "Best experienced with headphones!Click / Tap to dismiss this message\nWelcome to Calmy Leon, the most relaxing music and sound generator in the world! Sounds should be playing as you read these lines. Give Calmy Leon a try while reading this section: in less than a minute \u2014promise\u2014 you will understand how it works and why it is unique. And, you will fall in love with its sounds. Like the colors of a chameleon, the sounds you hear on Calmy Leon slowly change over time. If you can't wait, hit the reload icon (or simply reload the page) to discover a new sound palette. These dynamic sounds are associated with the black icons, and are ideal to calm down or meditate.Static noises are associated with the white icons. These white noises are capable of masking undesired sounds around you, including your tinnitus. They will also increase your focus and productivity. Use the top slider to adjust the level between the dynamic sounds (black) and static noises (white).The middle slider changes the f",
    "summary": "Welcome to Calmy Leon, where desperate urbanites find solace in the same five looping sounds renamed into a *spectacular* variety of nondescript ambiances! Here, you can watch grown adults rave about adjusting the fascinating \"black and white\" noise sliders, providing revolutionary control reminiscent of a two-button TV remote. The comment section blossoms with revelations that every related website is the genius spawn of Dr. Pigeon, a legend in the competitive world of ambient noise salesmanship. \"This is nice,\" murmurs a commenter, revealing decades of internet critique distilled into a lukewarm bath of indifference. Who knew pressing 'reload' could feel so adventurous?"
  },
  {
    "title": "The Deterioration of Google (baldurbjarnason.com)",
    "points": 57,
    "submitter": "PaulHoule",
    "submit_time": "2024-11-29T22:26:43 1732919203",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42277673",
    "comments": [
      "I\u2019m not precisely sure what problem the author is talking about. Is it the fact that some sites have built a business model around search results or is it that Google changed it search algorithm and they don\u2019t like the way they are prioritized or is it something else?It seems kind of unreasonable to expect Google to never experiment with their algorithm; and unfortunately at its core it is a zero sum game.  You might be a winner today but a loser tomorrow.if your concern is about revenue, sharing or referrals or ad placements or ??? then I would point out that it\u2019s very unwise to build a business whose success is based entirely on the whims of another business.I think search in general is becoming a very poor way to discover content as it is slowly getting planted by LLMs and also for years has been gamified by SEO.I think that the right model for content discovery is either crowd sourced by a like-minded community, like hacker news or curated; if the curator or community drifts away from your interests, then you have to find a new one, but oddly enough, this can actually be done within the same framework.\n \nreply",
      "> Morgan: Literally Danny said he sat with an engineer team with examples of people in the room and said why aren\u2019t they showing up and they did their \u201cdebugging process\u201d and couldn\u2019t figure it out.Meanwhile a single Swede with a single desktop class machine in his living room created a search engine so good that I would often switch to it when Google failed.These days I use Kagi, which has prioritization and block lists (which I don't use because the results are good out of the box).Wanna know what is really interesting about the Kagi story?While Kagi is building its own index, for a long time they were kind of reselling a wrapped version of Google + Bing results, but still were extremely much better IMO.I have two theories:- either Kagi has some seriously smart systems that read in the first tens of results and reshuffle them- or more likely in my opinion the reason why results have been so good is because kagi has api access which bypass the \"query expander and stupidifier\"[1] on the way in to Google and the personalization thing on the way out. That way they just interact with the core of Google search which somehow still works.[1]: \"stupidifier\" the thing in the Google pipeline that rewrites- \"obscure-js-lib\" (think one that a previous dev used, that I now need to debug- to \"well-knowm-js-lib-with-kind-of-similar-name\".Or decide that when I search for Angular \"mat-table\" I probably want some tables with mats on even if they don't have anything to do with Angular.\n \nreply",
      "It\u2019s been talked about here before, but fundamentally it\u2019s when the advertising guys won the power struggle over the search engine guys. Previously, advertising was a means to fund cool technology (and also get filthy rich).Now it\u2019s just a way to make the number perpetually go up, sucking every last drop of value out of the system.Plus the complete lack of vision or strategy from Google\u2019s senior leadership.\n \nreply",
      "The paperclip maximizer reports steady and heartening progress on converting all available matter in the Earth system to paperclips. Shares of $PCLIP are up 20% on the news.\n \nreply",
      "Sobering read on how Google was destroyed from the inside.https://www.wheresyoured.at/the-men-who-killed-google/\n \nreply",
      "Yes, 2019. Without any insider knowledge, I remember a Google update at the end of 2019 where they really went to shit, gone from \"don't be evil\" all the way to evilIt was actually later than I expected it to happen but it seems like distinct enough event that it's had reverberation all the way to the present.\n \nreply",
      "Giant Freakin' Robot was an aggregation site. Its \"content\" is links to other web pages with blithering about them. Google seems to recognize aggregation sites now, and down-ranks them. Google itself is an aggregation site, and there's no reason for it to pass traffic to other aggregation sites.If only they'd down-rank Yelp, etc.\n \nreply",
      "It's almost as if over a decade of exclusively optimizing for employees who are good at leetcode, will lead to a workforce that isn't capable of doing things besides solving well-defined leetcode problems.  Wow, who could have guessed?\n \nreply",
      "What has happened to cause Google to get so bad at search?\n \nreply",
      "This is only to repeat what has been said by many, numerous times, but \u20141. The point of search was no longer to provide requested data, but to generate clicks for Google's ad service.2. Generating clicks for Google's ad service required that exact text search, boolean searches, & everything else useful had to be excised because giving what was asked for reduced engagement.3. Ads had to be stuck on the top half of the results page, & the second half of the search results, for more clicks to be earned, had to be filled with garbage sites that did not provide what was sought. This encouraged the proliferation of scrapers & bot-generated text sites. Hand-in-hand with this was the elimination of long-tail results, as digging into results might give useful results.4. It appears that a decision was made at some point to curate & direct answers toward particular results. While much has been made about certain political leanings being almost disappeared by this move, it appears to be much more likely that this was a result of returning results which generated more ad revenue & clicks (which may say more about the sorts of sites Google runs ads on than anything else).5. In parallel with the dominance of ad-revenue mining, data mining became a major purpose of receiving search requests. Thus the requests for location information on every search, tied in with the drive to personalize results not for the purpose of giving good results, but to give identified users results they were more likely to interact with to both interact with Google ads & give Google more data to suck down & use.If we could get them to revert back to the 2006-era search engine, where more than just major sites & bot farms are indexed, we would have something useful. But that's not going to happen.\n \nreply"
    ],
    "link": "https://www.baldurbjarnason.com/2024/the-deterioration-of-google/",
    "first_paragraph": "This post announcing the closure of Giant Freakin Robot set me on a bit of a journey into the state of Google.\u201cThe End Of Independent Publishing And Giant Freakin Robot\u201dGIANT FREAKIN ROBOT isn\u2019t the first site to shut down. Hundreds of independent publishers have shuttered in the last two years, and thousands more are on the way. I\u2019m in communication with dozens of other independents focused on different topics. None of them are doing well. They all expect to be out of business soon.I went to Google directly, on their behalf, and told them about the problem. The message I walked away with, was that they do not care. Our industry is done.What I discovered was that web media companies can\u2019t count on any of the traffic coming from Google or Facebook any more. Very few, even one that are frugally run, are capable of surviving on the traffic that remains.The problem doesn\u2019t seem limited to a few sites. What seems to have happened is that Google tried to \u201cfix\u201d their search engine results by ",
    "summary": "In a stunning display of internet sleuthery, a blogger \"discovers\" that Google's fickle whims do indeed dictate the ebb and flow of traffic to independent sites, a revelation that shocks exactly no one. Commenters, ever the sages of the obvious, then lurch into action, mulling over whether the sun might rise tomorrow, given Google's control over earthly phenomena. Between denouncing gigantomachy and contemplating a switch to a Swedish-made search engine that\u2019s apparently powered by IKEA and meatballs, one can't help but marvel at the tech-commentariat's ability to restate the evident in increasingly intricate ways. Meanwhile, shares in $PCLIP edge up, further feeding fears that the apocalypse may just result from a rogue AI\u2019s insatiable desire for stationery. \ud83d\udcce\ud83d\udc94"
  },
  {
    "title": "Rust: Tools (early access edition) (bitfieldconsulting.com)",
    "points": 28,
    "submitter": "gus_leonel",
    "submit_time": "2024-11-26T10:30:04 1732617004",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42244409",
    "comments": [
      "I'm sorry to be a little rude, but the AI-generated cover (the left crab is missing an eye, for starters) is a negative quality indicator. If you weren't willing to take the time to put together a thoughtful cover, why should readers expect the book's content to be assembled any more carefully?\n \nreply",
      "I love how the top comment is a guy literally judging a book by it's cover.\n \nreply",
      "It is pretty amusing, but I actually have to agree. Unless your book is about generative AI, using it for the cover makes me question the effort put into the rest of the book - which is really unfortunate if the author did in fact put a lot of effort into their book!Yes, don\u2019t judge a book by its cover - but lots of people do anyway.\n \nreply",
      "Don't judge a book by the cover is an advice for us, the readers. It is NOT an advice for the writers or the marketing department.a tasteful public domain image of a crab or something like hundreds of years old but then detailed enough kind of like one of those O'Reilly's books and then make the whole cover white with some text that stands out... It has all been done before and I anal but I doubt O'Reilly's can copyright or trademark that design feeling.Edit: unless the authors are trying to crowd source the proof reading and peer review by releasing an early access copy? This cover draws attention from the average reader who is drawn to comment about the book because there is something to criticize? Maybe this is some kind of advanced 3D chess?\n \nreply",
      "I don\u2019t think that making your book\u2019s cover look indistinguishable from a significant number of other books in the same category is good marketing advice.\n \nreply",
      "I disagree, this is actually a great use case for generative AI.  There are many people who are great at writing, coding, hacking, or other talents, but are terrible artists.  I know that I fall into this category, and I\u2019m very excited about the prospect of using AI for any graphical assets I need for my projects.Especially with an ebook, if the content is good, I frankly don\u2019t even care if it even has a cover at all.\n \nreply",
      "I understand, but you should understand that OP's response will be common to your use of AI graphics: it'll be an indicator of little thought or quality control put into it.\n \nreply",
      "As an independent developer or author, every bit of time or money put into superficial things like a book cover is time or money that isn\u2019t used for the content itself.\n \nreply",
      "Oh please. Don't pretend like this has anything to do with \"effort\". If the book cover was some generic stock image you wouldn't even blink.\n \nreply",
      "Congrats on  the new book!Also some minor feedback: I know you're not supposed to judge a book by its cover, but obviously generated AI images give a lot of people 'the ick' so I'd recommend changing the cover (or modifying it).\n \nreply"
    ],
    "link": "https://bitfieldconsulting.com/books/rust-tools",
    "first_paragraph": "Are you ready to unlock the secrets of Rust? Master the world's most loved programming language, and learn how to craft stable, reliable, and durable software components that will last for decades, with The Secrets of Rust: Tools. Includes free updates for life.This is the Early Access edition, so be aware that it's under construction, and not yet complete (six chapters so far, of a planned seven). But you're getting the book at a decent discount from the full retail price, and your upgrade to the release version will be free. You can also help with the writing process, by giving me feedback and comments on the existing chapters\u2014and I'd love it if you would!\u2b50\u2b50\u2b50\u2b50\u2b50 \u201cI've tried to learn Rust before, but bounced off it somehow. This book unlocked something for me, and now I have a better understanding of just what makes Rust so different.\u201d\u2014Lawrence Denning\u2b50\u2b50\u2b50\u2b50\u2b50 \u201cI can't praise this book enough. It's opened my eyes to a whole new way of programming.\u201d\u2014Jawahir Sheikh\u2b50\u2b50\u2b50\u2b50\u2b50 \u201cGentle, funny, and ",
    "summary": "<b>Rust: Tools (Probably Should've Stayed in the Toolbox)</b>\n<i>Are you tired of programming languages that just *work* without the Patron Saint of Cargo Cults? If so, Rust enthusiasts offer yet another book \u2013 this time an \"early access edition\" \u2013 because nothing screams quality like unfinished work sold at \"a decent discount\".</i> Dive headfirst into the joys of collaborative book writing where readers naively shape the very expertise they seek. Meanwhile, in the comments, armchair book cover critics engage in a fierce battle of aesthetics over ethics, because judging a book's cover, unlike its contents, requires no actual Rust knowledge. A masterclass in missing the point, one pixelated crab at a time! \ud83e\udd80\ud83d\udc94"
  },
  {
    "title": "TfL abandons plans for driverless tube trains (ianvisits.co.uk)",
    "points": 10,
    "submitter": "edward",
    "submit_time": "2024-11-29T23:48:53 1732924133",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42278160",
    "comments": [
      "No doubt the RMT will take the blame for this but as the article points out:> It\u2019s now been confirmed that the study reached the same conclusion that every other study into the issue has already reported \u2014 it\u2019ll cost an awful lot of money for very little benefit.\n \nreply",
      "I wish they'd kept conductors on buses but that ship left 3 decades ago. Some of my fondest memories are the conductors on Melbourne's ageing W class wooden trams.Trains feel like something where drivers and conductors and platform staff are a social good. We're beyond cost at this point, it's about public utility.\n \nreply",
      "I think the combination of driverless trains and automated platform screen doors is the gold-standard for new metro-like systems. The new REM in Montr\u00e9al is able to have very high frequencies with much lower cost, so transit users should be able to get more transit for the same cost and the municipality isn't worried about the burden of high operating costs for the next century. The platform screen doors are great too, anyone who's taken the Metro enough has had to wait for hours because someone has fallen onto or committed suicide on the track, which feels like such a sad problem to have when the solution exists.\n \nreply",
      "I do like Asian metro systems I use with screened entry to trains. But I also like seeing staff. Porque no los dos?\n \nreply",
      "Also the ratio of driver to passenger especially compared to say a taxi, is negligible so the amortized cost is basically zero. That said, they\u2019re not exactly useful on trains, you don\u2019t chit chat with the man in the armored cab.\n \nreply",
      "The conductor wages over the system as a whole are a large part of operating costs. Another issue you can have is a lack of conductors, which is a big issue in the Netherlands apparently.\n \nreply",
      "More to the point, staffing isn't setting the price of transport, it's subsidised almost everywhere. Sure. It's a cost. The cost:benefit here is more than just apparent budget impact because public transport is a utility function.\n \nreply",
      "You would think so but e.g. airlines pushed quite heavily to reduce pilots from 3 to 2 and occasionally lobby for 1.\n \nreply"
    ],
    "link": "https://www.ianvisits.co.uk/articles/tfl-abandons-plans-for-driverless-tube-trains-77435/",
    "first_paragraph": "",
    "summary": "<b>London's Tech-No-Logic Debacle:</b> In an astonishing display of fiscal prudence, TfL decides against driverless tube trains after realizing what every commenter with a Transport Tycoon degree already knew: it costs a <em>fortune</em>! Meanwhile, nostalgic transit romantics moan about the loss of human conductors, while tech evangelists praise the soulless efficiency of automated metros around the globe. Above the din, the cost of human connection is prorated, debated, and ultimately reduced to a nostalgic luxury by spreadsheet warriors and those who haven\u2019t had to make small talk with a conductor over a dodgy speaker system. \ud83d\ude87\ud83d\udcb8\ud83e\udd16"
  },
  {
    "title": "Understanding SIMD: Infinite complexity of trivial problems (modular.com)",
    "points": 121,
    "submitter": "verdagon",
    "submit_time": "2024-11-25T17:08:09 1732554489",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=42237938",
    "comments": [
      "Intel needs to see what has happened to their AVX instructions and why NVidia has taken over.If you just wrote your SIMD in CUDA 15 years ago, NVidia compilers would have given you maximum performance across all NVidia GPUs rather than being forced to write and rewrite in SSE vs AVX vs AVX512.GPU SIMD is still SIMD. Just... better at it. I think AMD and Intel GPUs can keep up btw. But software advantage and long term benefits of rewriting into CUDA are heavily apparent.Intel ISPC is a great project btw if you need high level code that targets SSE, AVX, AVX512 and even ARM NEON all with one codebase + auto compiling across all the architectures.-------Intels AVX512 is pretty good at a hardware level. But software methodology to interact with SIMD using GPU-like languages should be a priority.Intrinsics are good for maximum performance but they are too hard for mainstream programmers.\n \nreply",
      "> Intel ISPC is a great project btw if you need high level code that targets SSE, AVX, AVX512 and even ARM NEONIt's pretty funny how NEON ended up in there. A former Intel employee decided to implement it for fun and submitted it as a pull request, which Intel quietly ignored for obvious reasons, but then another former Intel employee who still had commit rights merged the PR, and the optics of publicly reverting it would be even worse than stonewalling so Intel begrudgingly let it stand (but they did revoke that devs commit rights).https://pharr.org/matt/blog/2018/04/29/ispc-retrospective\n \nreply",
      "> software methodology to interact with SIMD using GPU-like languages should be a priority.What's your opinion on sycl?https://www.khronos.org/sycl/\n \nreply",
      "It is worse than that, given that AVX is the survivor from Larrabee great plan to kill GPUs.Larrabee was going to take over it all, as I enjoyed its presentation at GDCE 2009.\n \nreply",
      "I mean, 288-E Core Xeons are about to ship. Xeon 6900 series, right? (Estimated to ship in Q1 2025)So Larrabee lives on for... some reason. These E cores are well known to be modified Intel Atom cores and those were modified Xeon Phi cores which were Larrabee based.Just with.... AVX512 being disabled. (Lost when Xeon Phi turned into Intel Atoms).Intels technical strategy is completely bonkers. In a bad way. Intel invented all this tech 10 to 20 years ago but fails to have a cohesive strategy to bring it to market. There's clearly smart people there but somehow all the top level decisions are just awful\n \nreply",
      "Yes, a lot of weird decisions were made at Intel.Ironically, AMD waited so long to implement AVX-512, but now has it on both server and mobile chips (natively and 256 bit emulation, respectively). Intel started the whole thing, has a very fragmented stack and is now preparing those E cores with even more new extensions.Most importantly for Search and AI, it adds AVX_VNNI, which can be used for faster 8-bit integer dot-products: https://github.com/ashvardanian/SimSIMD/blob/75c426fb190a9d4...Would be interesting to see how matrix multiplication throughput will differ between AVX-512-capable P cores and a larger quantity of AVX_VNNI-capable E cores!\n \nreply",
      "How much of this is because CUDA is designed for GPU execution and because the GPU ISA isn\u2019t a stable interface? E.g. new GPU instructions can be utilized by new CUDA compilers for new hardware because the code wasn\u2019t written to a specific ISA? Also, don\u2019t people fine tune GPU kernels per architecture manually (either by hand or via automated optimizers that test combinations in the configuration space)?\n \nreply",
      "NVidia PTX is a very stable interface.And the PTX to SASS compiler DOES a degree of automatic fine tuning between architectures. Nothing amazing or anything, but it's a minor speed boost that has made PTX just a easier 'assembly-like language' to build on top of.\n \nreply",
      "> If you just wrote your SIMD in CUDA 15 years ago, NVidia compilers would have given you maximum performance across all NVidia GPUsThat's not true. For maximum performance you need to tweak the code to a particular GPU model/architecture.Intel has SSE/AVX/AVX2/AVX512, but CUDA has like 10 iterations of this (increasing capabilities). Code written 15 years ago would not use modern capabilities, like more flexible memory access, atomics.\n \nreply",
      "Maximum performance? Okay, you'll have to upgrade to ballot instructions or whatever and rearchitect your algorithms. (Or other wavefront / voting / etc. etc. new instructions that have been invented. Especially those 4x4 matrix multiplication AI instructions).But CUDA -> PTX intermediate code has allowed for significantly more flexibility. For crying out loud, the entire machine code (aka SASS) of NVidia GPUs has been cycled out at least 4 times in the past decade (128-bit bundles, changes to instruction formats, acquire/release semantics, etc etc)It's amazing what backwards compatibility NVidia has achieved in the past 15 years thanks to this architecture. SASS changes so dramatically from generation to generation but the PTX intermediate code has stayed highly competitive.\n \nreply"
    ],
    "link": "https://www.modular.com/blog/understanding-simd-infinite-complexity-of-trivial-problems",
    "first_paragraph": "PRODUCTMAXLanguageMojo\ud83d\udd25Quick StartInstallRun LLMsPricingTake control of your AIAuthor: PRODUCTDocumentationTutorialsBlogBuildPrebuilt AI PipelinesMAX Examples\ud83d\udd25\u00a0\u00a0Mojo Examples\ud83d\udd25\u00a0\u00a0Mojo PlaygroundReadJoin DiscordMAX ChangelogCommunity HighlightsBring your own fine-tuned model to MAX pipelinesAuthor: MODULARAboutCultureCareersConnectCommunityContact UsModCon 2023Author: November 25, 2024Ash Vardanian\u200dThis guest blog post is by Ash Vardanian, founder of Unum. He's focused on building high-performance computing and storage systems as part of the open-source Unum Cloud project.Modern CPUs have an incredible superpower: super-scalar operations, made available through single instruction, multiple data (SIMD) parallel processing. Instead of doing one operation at a time, a single core can do up to 4, 8, 16, or even 32 operations in parallel. In a way, a modern CPU is like a mini GPU, able to perform a lot of simultaneous calculations. Yet, because it\u2019s so tricky to write parallel operations, almo",
    "summary": "In the enthralling world of <em>\"Understanding SIMD: Infinite complexity of trivial problems\"</em>, author Ash Vardanian decides to enlighten us mere mortals on CPUs' hidden talents akin to party tricks\u2014doing multiple things at once, a concept totally unheard of in the human experience. Delve into the depths of SIMD parallel processing, which is painted as an exotic CPU feature rather than a decade-old programming mainstay, because nothing screams 'innovation' like explaining old tech in new blog posts. Meanwhile, the comment section boasts a techno-bushfire of opinions, alternating between nostalgia for the simplicity of CUDA and lament over Intel's AVX instructions fade. Watch in amusement as they argue which old wine, poured into a new digital bottle, will best serve their high-performance computing rituals. Yet another day on the internet where complexity is hailed as genius, and everyone misses the simpler solution - just use what works and go outside."
  },
  {
    "title": "Borgo Programming Language (borgo-lang.github.io)",
    "points": 293,
    "submitter": "MrBuddyCasino",
    "submit_time": "2024-11-26T11:33:50 1732620830",
    "num_comments": 123,
    "comments_url": "https://news.ycombinator.com/item?id=42244791",
    "comments": [
      "This is quite beautiful. It hides several ugly warts of Go without necessarily adding more complexity. Result<T> instead of (T, error) and ? for propagation is just so nice. Structured enums is something I find myself needing all the time (and writing less self-explanatory code due to the lack of it). Option<T> instead of nil and zero values (which builds upon structured enum support) is what got me to say \"yes please!\"Honestly, some of the things they changed are maybe unnecessary (like the additional impl syntax, the Zig influenced dereferencing, return values from statements, several other Rustisms, etc). One part of me wish Go would get all of this. But another part of me knows it would never happen because this is not a superset (Python 2 -> Python 3 anyone?)I also wonder if this could even be compared to JavaScript / TypeScript for the same reason, not being a superset means you have to actively make a change to even start to migrate, and the revert path is not as trivial.\n \nreply",
      "What prevents this from being a superset?C++ is a superset of C; did it do much good?Zig is not a superset of C, and Rust is not a superset of C++; does this hinder their adoption a lotAlso, the pain of Python 2 -> 3 migration was that you can't mix py2 and py3 code in one project. This is not the case with Borgo apparently: you can mix it with Go, much like you can mix C++ / Zig / Rust with C, or TS with JS, or even Kotlin with Java.By having excellent interoperability, Borgo may have a good chance of wider adoption. If I were its maintainer, I'd prioritize interoperability with plain Go and its stdlib highly.\n \nreply",
      ">What prevents this from being a superset?There are various syntax changes, such as let. Of course, if Borgo could be modified to not have let, but that would be a backward incompatible change.\n \nreply",
      "I think it would be cool if we had something like this except as a superset.\n \nreply",
      "Is this TypeScript of Go?\n \nreply",
      "I love it.This is a language that everyone here says they want but no one will use, even though it's stable and mature (I assume because it compiles to stable and mature Go and can use every existing Go library).It hits all the \"ok, Go is popular but made by morons for morons and if only it had this X advanced feature, it would be totally great\".It has immutability. It has advanced enums. It has algebraic types. It has pattern matching. It has Result<> instead of returning an error. It gets rid of if err != nil. It gets read of of nil pointers.On paper it's a perfect language. It literally addresses every major complaint people have with Go.And I'll be here not using it and watching everyone else not use it.Because the harsh truth is that none of those things are actually big issues that would justify learning slightly different syntax.But maybe I'm wrong. Time will tell.\n \nreply",
      "I do agree with you to a degree, but let's not forget the monumental successes that are TypeScript and Kotlin.There have been lots of such languages that transpiled to JavaScript or worked on the JVM, adding nicer syntax and features. Many of them went nowhere, but quite a few of them did get widely adopted. Off the top of my head, CoffeeScript was also relatively popular for a while, and Clojure builds on top of both ecosystems, Scala comes to mind too.Go might be in a similar situation right now, where it has become entrenched in certain domains (like DevOps), and lots of people are not entirely satisfied with it but they can't to switch to something else. Is Go getting a similarly bad reputation as JavaScript or Java to push this through? Is the lock-in as strong as in browsers or Android? No, I wouldn't say it's there yet, but still, it is worth a shot to try to build such an alternative language.I do agree that Borgo will probably not be adopted widely, the  pains it addresses are not strong enough and the language does not seem to be properly maintained and supported. But history shows it is not as unlikely as you suggest.\n \nreply",
      "It'll probably not get as much traction as Go, but for a simpler reason that may not be as ideologically satisfying for you. It's just really hard for a new language to get real traction, no matter how good it is. And it's even harder for transpiled languages, because they almost always gets overshadowed by the language they're transpiling to.\n \nreply",
      "What I find truly fascinating is that given the complexity of most build systems (especially ones that use babel) basically every node project I encounter is in fact effectively transpiled, it's just it's \"javascript compiled to javascript\" rather than having a different source syntax.I don't even mind[0], I think it's actually kind of amazing.[0] I have all the usual complaints about build systems and about the node ecosystem in general, but I don't think the fact that it's javascript compiled to javascript in and of itself is a problem, only, well, almost everything about how that's usually implemented/achieved :D\n \nreply",
      "But it's the minimal translation to allow newer language features and APIs to be still used in older browsers.OTOH I haven't seen a pure JavaScript project for a number of years. It's all Typescript now, maybe with some vestiges of legacy JS slated for eventual migration to TS.\n \nreply"
    ],
    "link": "https://borgo-lang.github.io/",
    "first_paragraph": "Borgo is a new programming language that compiles to Go.For a high-level overview of the features and instructions on running the\ncompiler locally, check the\nREADME.This playground runs the compiler as a wasm binary and then sends the transpiled\ngo output to the official Go playground for execution.Primitive types are the same as in Go.Collections like slices and maps can be used without specifying the type of the\nvalues.For example, a slice of int elements would be declared as []int{1,2,3} in Go,\nwhereas Borgo relies on type inference to determine the type, so you can just\nwrite [1, 2, 3].Functions like append() and len() are available as methods.Maps are initialized with the Map.new() function, which under the hood\ncompiles to a map[K]V{} expression, with the K and V types helpfully\nfilled in for you.Borgo also has tuples! They work exactly like in Rust.Multiline strings are defined by prefixing each line with \\\\ like in Zig. This\nhas the benefit that no character needs escaping and ",
    "summary": "**The Revolutionary Nothingness of Borgo**\n\nIn a technological fever dream, a group of developers unveil Borgo, a new programming language that adds the thrill of unpredictability by compiling to Go, because clearly what the world needs is another layer of abstraction to make code reviews even more fun. Commenters erupt in ecstasy over syntax sugar, battling each other with tales of \"advanced features\" like tuples that will surely save seconds of coding time, convinced that Borgo will revolutionize coding by solving problems that didn't exist. Meanwhile, the real world remains blissfully unaware, continuing to write buggy software in plain old Go and questioning whether philosophy majors designed Borgo as a practical joke on software developers. As debates rage on whether Borgo is the TypeScript of Go, everyone agrees on its potential, all while avidly not using it. \ud83d\ude43"
  },
  {
    "title": "Simple Sabotage for the 21st Century \u2013 Specific Suggestions (specificsuggestions.com)",
    "points": 88,
    "submitter": "RobLach",
    "submit_time": "2024-11-29T18:33:39 1732905219",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=42275919",
    "comments": [
      "You see this happening in russia these days.My favourite was from the start of the war when the guys who were supposed to plant incriminating evidence on the scene were they arrested some \"terrorists\" put the Sims 3 game on the scene instead of 3 sim cards and literally signed the fake documents they planted with \"Signature Unclear\". (Yes, real story, just search for Sims 3 and Signature Unclear.)As I understand it I understand this was FSB (or someone elses) way of \"getting even\" after their boss had been publicly humiliated for proposing to not invade Ukraine. (But that - except for the public humiliation which is well documented - is just speculation on my part although I might have heard it from someone else thinking loud.)Although sometimes I wonder if it was a genuine misunderstanding. I feel I have unusually many Russian friends and ex-colleagues, people who live outside of russia for good reasons and do not support it. Z-russians on the other hand does not strike me as the brightest bulbs in the box.\n \nreply",
      "> fake documents they planted with \"Signature Unclear\"\"Signature Unclear\" is actually a real pseudonym of a pro-Nazi author. So this particular part was at least believable.The \"Sims 3\" disks (3 of them) and Bandera's books were far less so.\n \nreply",
      "> \"Signature Unclear\" is actually a real pseudonym of a pro-Nazi author.That was interesting, thanks!Do you know if he is an actual Jew-hating nazi or just someone who opposes russia?(I've learned over the last 3 years that for most russians when they think of nazism they don't think of genocide of minorities, mega-projects, Lebensborn and all that bit rather only about \"war against russia\")\n \nreply",
      "He's a real \"inferior races must be exterminated\" Nazi. I searched for his works when this story first came out, and yeah, he's bad.\n \nreply",
      "ouch.That is evil.Then again, that alone us not enough for russia to strike at someone: they have more than one group of openly nazi (by western standards) soldiers fighting against Ukraine, most famously rusisch.\n \nreply",
      "\"just search for Sims 3 and Signature Unclear\"I did, but got lots of vague rumor stories, but nothing solid.\n \nreply",
      "Here you go:https://www.businessinsider.com/russian-agents-the-sims-vide...This article in turn links to russian state sponsored RIA Novosti, and while I generally don't trust russian state sponsored media, I make exceptions for when they admit embarrassing things, because they have little incentives to lie to get people to ridicule them.\n \nreply",
      "> Log users out frequently for \"security reasons\".This is exactly what happens on a contract I work on. Any software that is authenticated through our OKTA SSO very frequently signs users out and redirects to a logout page. This is especially annoying when using the project management software, where you typically have many tabs open to see various requirements, epics, stories, tasks, etc. Any inactivity more than 15 minutes, and all the tabs are logged out. Just like that, everything is gone. It forces us to use strategies such as saving redundant copies of things in notes and spreadsheets. I don\u2019t think it\u2019s necessarily sabotage but it feels extremely negligent. Moreover it\u2019s completely unnecessary since everything is behind a VPN anyway.Another similar thing that does feel as if it\u2019s somewhat malicious is the very aggressive logout and shutdown policy of our virtual desktops - these are the desktops we do everyday active development on and where we set up IDEs, database clients, web servers, testing tools, API references - anything you can think of. We use this in combination with our regular desktops where we attend meetings or do other non-development tasks such as using the above-mentioned requirements software. It takes a lot of time to set all of this up! If you\u2019re inactive for more than 2 hours, your session is not only closed, it\u2019s completely destroyed so that it can be reclaimed for another user. I don\u2019t need to explain to experienced developers how incredibly frustrating and counterproductive this is, but leadership has been extremely dismissive of any complaints, and tell us that we should use our time more wisely or that we shouldn\u2019t be inactive for so long (which is complete BS, there are a thousand valid reasons foe this). Apparently this is done for cost-cutting reasons, but something feels more nefarious here, because this very obviously leads to reduced productivity and demotivation. This has actually lead to me purposefully overestimating complexity and demanding a user story for every single little trivial action I take, whereas before I used to just go in and make quick fixes or knock out certain operational things in my spare time. It\u2019s a waste of time for us and ends up being worse for our customers.\n \nreply",
      "As AGILE as it gets\n \nreply",
      "This is a takeoff on a well known WWII pamphlet, the Simple Sabotage Field Manual.[1]That's not the real worry today. Today we have to worry about remote sabotage of key systems - water, power, comms. It's quite possible that we will see major blackouts in the US, Russia, Europe, or China as side effects of the various wars in progress.[1] https://www.cia.gov/stories/story/the-art-of-simple-sabotage...\n \nreply"
    ],
    "link": "https://specificsuggestions.com",
    "first_paragraph": "",
    "summary": "Welcome to the latest tech-inept playground of modern subversion at *specificsuggestions.com*, where covert agents evidently choose video games over espionage essentials. In today's laughable episode, James Bond wannabes fail spycraft 101 by subbing in *The Sims 3* for SIM cards \u2013 a move so brilliantly dumb it must be strategic. \ud83d\udd75\ufe0f\u200d\u2642\ufe0f Meanwhile, the comment section becomes a delightful dumpster fire as armchair analysts and casual conspiracy theorists argue about whether a pseudonym signals Nazi allegiance or just poor operational planning. A masterclass in missing the point, generously peppered with overconfidence and under-research. Log out for \"security reasons\"? No, log out because your brain needs a break from this circus. \ud83c\udfaa\ud83d\udcbb"
  },
  {
    "title": "NASA's Europa Clipper: Miles Down, Instruments Deploying (nasa.gov)",
    "points": 10,
    "submitter": "rbanffy",
    "submit_time": "2024-11-29T23:47:19 1732924039",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.nasa.gov/missions/europa-clipper/nasas-europa-clipper-millions-of-miles-down-instruments-deploying/",
    "first_paragraph": "5 min readHeaded to Jupiter\u2019s moon Europa, the spacecraft is operating without a hitch and will reach Mars in just three months for a gravity assist.NASA\u2019s Europa Clipper, which launched Oct. 14 on a journey to Jupiter\u2019s moon Europa, is already 13 million miles (20 million kilometers) from Earth. Two science instruments have deployed hardware that will remain at attention, extending out from the spacecraft, for the next decade \u2014 through the cruise to Jupiter and the entire prime mission.A SpaceX Falcon Heavy rocket launched it away from Earth\u2019s gravity, and now the spacecraft is zooming along at 22 miles per second (35 kilometers per second) relative to the Sun.Europa Clipper is the largest spacecraft NASA has ever developed for a planetary mission. It will travel 1.8 billion miles (2.9 billion kilometers) to arrive at Jupiter in 2030 and in 2031 will begin a series of 49 flybys, using a suite of instruments to gather data that will tell scientists if the icy moon and its internal ocea",
    "summary": "Title: <em>NASA's Europa Clipper: Doubling Down on Space Billiards</em>\n\nWelcome to another costly game of cosmic pinball, courtesy of our financially fearless friends at NASA. The Europa Clipper has graciously decided to leave Earth, traveling at the breathtakingly unnecessary speed of 22 miles per *second*\u2014because the phrase \"hurry up and wait\" is apparently space policy. It's on a multimillion-mile detour to Mars for a gravity assist, kind of like swinging by the coffee shop on your way from New York to New Jersey. Commenters are currently debating whether this is the best use of taxpayer money or simply the only thing cooler than Elon's next tweet. But hey, at least the onboard instruments have been deployed, standing at attention for a decade-long journey that will definitely keep us all thrilled and engaged through 2031! \ud83d\ude80\ud83d\udcb8\ud83c\udf0c"
  },
  {
    "title": "Lessons from 15 Years of Indie App Development (lukaspetr.com)",
    "points": 6,
    "submitter": "Lukas_Petr",
    "submit_time": "2024-11-22T13:51:16 1732283476",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://lukaspetr.com/15-lessons-from-15-years-of-indie-app-development/",
    "first_paragraph": "I'm Lukas, an indie iOS app developer from Prague. My main focus now is building a time tracking app called Timelines. On this blog, I try to share my thoughts about indie app development.Exactly 15 years ago on November 9th, 2009, I got my first MacBook and started learning how to build apps. I was fascinated with the idea that you can build something that other people will find useful and enjoy using. I also heard about those \"indie developers\" on Twitter who were making a living solely from their own apps and I found it fascinating. I got it into my head back then that this is what I want to be doing too, and somehow this dream, no matter how elusive and unattainable it felt over the years, never left me.In this blog post I want to look at some of the biggest lessons I took from all these years, and also share some of my thoughts on this topic. As a disclaimer, by no means do I want to pretend like I am some kind of \"success story\". It took me a really long time to get to the point ",
    "summary": "Title: A Decade and a Half to Nowhere\n\nHey everyone, join Lukas, the (self-admitted) non-success story as he celebrates an *astonishing* 15 years of making apps no one has heard of! \ud83c\udf89 Get ready to dive into his thrilling life with his world-renowned app, Timelines, which is definitely not just another time tracking tool in a sea of more popular options. Our indie hero wants to share *profound* \"lessons\" from his journey\u2014because, apparently, surviving in obscurity is a mastered art form. Meanwhile, the comment section bubbles with amateur developers who also dream of eking out a meager living from their basement-coded apps, all echoing their grand delusions of making it big or at least, surviving another update cycle. \ud83d\ude02"
  },
  {
    "title": "Prioritize work at the task level (developer.apple.com)",
    "points": 106,
    "submitter": "tosh",
    "submit_time": "2024-11-26T10:42:19 1732617739",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=42244482",
    "comments": [
      "A number of years ago, I was working on the port of Bazel to macOS. One of the issues we faced internally at Google was that some of our users reported that Bazel builds randomly killed their Internet connection and that they performed poorly.There was a lot of FUD around the topic, with some engineers blanket-claiming that \"well, macOS is bad at threads, so there's that\". I didn't buy that explanation because I had seen macOS under serious load in other occasions and none of this nonsense happened in them.And then, almost by chance, I stumbled upon this QoS system, did a few spot-checks, and found that the VPN daemon was misconfigured to run at a low class. Consequently, Bazel starved the VPN for those users and made everything misbehave. Adjusting that one parameter fixed everything.If you are curious, I ended up writing some more on this here: https://jmmv.dev/2019/03/macos-threads-qos-and-bazel.html\n \nreply",
      "How would one go about changing QoS for the system daemons and would it require disabling SIP? I don't see anything relevant in launchctl's man or launchd documentation, really interested to try it on the system VPN service.\n \nreply",
      "In that specific case, it was our own installation of a VPN client and a custom definition of its launchd configuration. I don\u2019t remember the exact details anymore.I\u2019d expect the system-provided services to be correctly configured by Apple in this regard.\n \nreply",
      "I thought this was a life hack recommendations article but it\u2019s about Quality of Service.@dang or @op can we get QoS added to the title?\n \nreply",
      "I thought the same, but the parenthesized domain should be an adequate hint, to be fair.\n \nreply",
      "I was thinking that maybe Apple had useful guidelines for how developers can prioritize their work. :)\n \nreply",
      "Here's a link to best practices for multitasking from the same domain: https://developer.apple.com/design/human-interface-guideline...\n \nreply",
      "I fell for this one too.\n \nreply",
      "I actually thought you meant that this was about applying QoS algos to real life, before I saw the link lol.\n \nreply",
      "It's good practice to not editorialize the title when making a submission. You could misread many titles to mean something else, it's sort of a hidden assumption that you should read the article before commenting on it.\n \nreply"
    ],
    "link": "https://developer.apple.com/library/archive/documentation/Performance/Conceptual/power_efficiency_guidelines_osx/PrioritizeWorkAtTheTaskLevel.html",
    "first_paragraph": "\nDocumentation Archive\n \t\t\nDeveloper\nEnergy Efficiency Guide for Mac Apps\n\n\n  Apps and processes compete to use finite resources\u2014CPU, memory, network interfaces, and so on. In order to remain responsive and efficient, the system needs to prioritize tasks and make intelligent decisions about when to execute them.\n\n  Work that directly impacts the user, such as UI updates in the active app, is extremely important and takes precedence over other work that may be occurring in the background. This higher priority work often uses more energy, as it may require substantial and immediate access to system resources.\n\n  As a developer, you can help the system prioritize work more effectively by categorizing your app\u2019s work, based on importance. Even if you\u2019ve implemented other efficiency measures, such as deferring work until an optimal time, the system still needs to perform some level of prioritization. Therefore, it is still important to categorize the work your app performs.\n\n  OS\u00a0X implemen",
    "summary": "**Apple Discovers Task Management: Revolutionary or Just Late to the Party?**\n\nOnce again, Apple schools developers on how to not crash your Mac during a YouTube binge, with their insightful guide on \"prioritizing tasks.\" In a stunning revelation, Apple has uncovered that tasks affecting what the user is actually doing might actually be important. Comment sections quickly turned into a tech support forum, with commenters heroically uncovering their past as unpaid Apple debuggers. Meanwhile, some puzzled souls debated Quality of Service, further muddying the waters about whether this was about life hacks or computer instructions. The internet remains undefeated in misreading article titles and missing the point. \ud83d\udcbb\ud83e\udd26\u200d\u2642\ufe0f"
  },
  {
    "title": "Ask HN: Platform for senior devs to learn other programming languages?",
    "points": 39,
    "submitter": "Raed667",
    "submit_time": "2024-11-29T20:49:28 1732913368",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42276995",
    "comments": [
      "As a self-guided alternative, you could try going through https://adventofcode.com/ problems with your language of choice.\n \nreply",
      "There is alsohttps://learnxinyminutes.com/It gives small language syntax/feature tours.Each file is legitimate syntax for the language it documents.\n \nreply",
      "Would love the equivalent of this but before applying practical problem solving. For instance in go you learn to leverage goroutines and channels. In another language it would be threads. Common design patterns etc. Gotcha\u2019s of the language. In Python you use exception handling very commonly, in golang you\u2019re using a special return value of an error type. JavaScript you\u2019re using a ton of anonymous function closures. Async vs await.I keep wanting to build this mega doc site to teach more than just \u201cwhat are scalar types in this language\u201d and more of how to apply it in idiomatic ways.\n \nreply",
      "This is excellent. I checked Julia which is my main language and all essentials are there. Looked up to Zig, F#, Go all accessible expositions and makes it easy to get a good taste before looking into the manuals.\n \nreply",
      "I think you are looking for Exercism:  https://exercism.org/Great website!Edit: \nThis also looks good, haven't tried it yet: https://app.codecrafters.io/catalog\n \nreply",
      "amazing ! Yes thank youI was thinking about this post https://news.ycombinator.com/item?id=41463734\n \nreply",
      "What\u2019s the difference between how a senior and non-senior learn that would warrant a unique platform for each?\n \nreply",
      "Well a senior developer would be assumed to share a certain common understanding of concepts and terms that a more junior developer might not. When teaching anything one of the most important parts is ta gauge your pupils and determine whether they need more or less information to keep the topic interesting while not making it impossible to follow along. Since written or otherwise pre-recorded teaching materials aren't afforded the luxury of interacting with their pupils they must choose ahead of time what level they are aimed at. And since a senior in any field would be able to follow along with materials meant for the junior, albeit at a slower and less interesting pace, but not the other way around they tend to err on the side of over-explanation. A platform for teaching senior developers would therefore allow a more engaging and time saving experience for those able to consume it.\n \nreply",
      "Senior doesn't need to learn about loops, ifs and so onFor example when learning C++ while being proficient at C# I found useful this blog: https://www.jacksondunstan.com/articles/5530\"C++ For C# Developers: Part 1 \u2013 Introduction\"Author compares features between C# and C++ and shows what is similar, the same, different, non-existent, etc.\n \nreply",
      "I\u2019m going to go against the flow and say nothing. I think the primary reason you see seniors looking for senior focused platforms is because almost all the learning content is terrible. Seniors will spot this sooner than juniors. I\u2019ve worked as an external examiner for CS students for a decade and the stuff they put themselves through to avoid reading official docs is amazing. They\u2019ll literally sit through 50 hours of video of what is essentially two a4 pages of \u201cexample how-to\u201d.Why a senior wouldn\u2019t just head directly to the documentation for a programming language or the equivalent to \u201cThe C++ Programming Language\u201d is a different question though. Learning a new language is extremely easy, it\u2019s learning how the compiler, runtime and so on which is hard. You\u2019ll very rarely find that outside of official docs or books written by extremely knowledgeable people.\n \nreply"
    ],
    "link": "item?id=42276995",
    "first_paragraph": "",
    "summary": "**Developers in Midlife Crisis Seek Language Enlightenment**\n\nIn the latest round of \"never too old to learn,\" seasoned developers cling to the dream of mastering new programming languages as if it promises eternal coding youth. One idealist suggests replacing basic syntax tutorials with a \"mega doc site\" because apparently, seasoned programmers can only digest new information in 'idiomatic' chunks. As always, the comment section morphs into a self-help group, with recommendations ranging from Advent of Code puzzles to yet another underdog platform, Exercism. Meanwhile, a lone voice of reason suggests that perhaps, just perhaps, seniors can brave the wilds of official documentation without hand-holding. \ud83d\udcda\ud83d\udcbb\ud83d\udc74"
  },
  {
    "title": "Chinese pebble-bed nuclear reactor passes \"meltdown\" test (ans.org)",
    "points": 108,
    "submitter": "bilekas",
    "submit_time": "2024-11-29T18:21:55 1732904515",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=42275834",
    "comments": [
      "Pebble bed reactors are a bad idea in general.They will be HUMONGOUS because they need a large surface to radiate away the heat for the passive safety, so they can't be easily put into a containment building.A core of a PWR plant is _tiny_ for the amount of power it produces (around 3GWt!), just around 5 meters in diameter and 15 meters in height.The pebble bed reactor in the article (HTR-PM) is around the same size, but it produces a mere 0.25 GWt.Pebbles themselves are also problematic, they tend to swell, crack, and they can't be reprocessed using the current technologies. They MASSIVELY increase the amount of waste.\n \nreply",
      "This reactor indeed has lower power density than a PWR, but not by a factor of 12. I compared it with NuScale's reactor, which is a PWR SMR. Details about both can be found in [1]. The HTR-PM reactor pressure vessel has a volume of about 640 m3, and yields 105 MWe, while NuScale has a volume of 101 m3 and yields 77 MWe. The power densities come to be 6.1 m3/MWe vs 1.3 m3/Mwe, and the ratio is 4.7x.Still, this is a good price to pay for getting a meltdown-proof reactor.> Pebbles themselves are also problematic, they tend to swell, crack, and they can't be reprocessed using the current technologies.It is simply not true that pebbles tend to swell and crack. Quite the opposite happens: fuel elements in the current generation PWRs tend to swell, crack and burst. This happens because some fission products and decay products are gasses, such as xenon, kripton, radon. They build up in time and create internal pressure. The same happens inside the fuel kernels in the pebbles used in this reactor, but those kernels are specially built to withstand much higher internal pressures.Here's a relevant quote from [2]:  > As the pressure vessel size is reduced, the more efficient spherical geometry can be adopted, and the required wall thickness drops dramatically to the point that a 35 \u03bcm SiC layer can indefinitely contain gas pressures in excess of 100 MPa. This compares to the main reactor steel pressure vessel which may go as high as 20MPa or the Zircalloy cladding which can have pressures up to 10s of MPa in limited conditions \u2013 temperatures far below what the ceramic pressure vessel tolerate\n\nAs for the reprocessing part, I think you are jumping the gun. There is no reprocessing done in the US, at all, for any type of fuel. Even where reprocessing happens, as in France, the benefit is quite reduced. One can extract some plutonium and unburned uranium, but in the end that will allow you to extract maybe 10-20% more energy from the original amount of natural uranium. It will not make you extract one hundred, or 10 times, or even just twice as much energy. Reprocessing is simply not a game changer. It is not clear at all if it makes economic sense to build the highly complex facilities that do reprocessing, for the limited benefit.[1] https://aris.iaea.org/publications/SMR_catalogue_2024.pdf[2] https://www.usnc.com/triso/\n \nreply",
      "So for a 3GW pebble bed reactor, we\u2019re looking at a core the size of small house instead of a master bedroom? I don\u2019t see a huge difference here; it\u2019s the same amount of everything else (cooling, pumps, turbines, security) since it produces the same amount of heat/power.\n \nreply",
      "> So for a 3GW pebble bed reactor, we\u2019re looking at a core the size of small house instead of a master bedroom?No, we're looking at a core the size of a small residential tower. Probably around 30 meters in height.\n \nreply",
      "Sounds terrible for a relatively dense place like Western Europe or Japan, but I think this would be fine in the US and China.\n \nreply",
      "That\u2019s not too big man\n \nreply",
      "One room worth of radioactive waste vs a residential tower worth of radioactive waste is a big difference.\n \nreply",
      "It is, when you consider the problem of dealing with spent pebbles.  These are not like the fuel rods of a LWR that occupy a fraction of a much smaller volume.  The dry casks to store them would be immense.\n \nreply",
      "Is GWt a common abbreviation for gigawatt? I first read that as gigawatt-tons which is a\u2026 confusing unit\n \nreply",
      "Gigawatt thermal, as opposed to gigawatt electric. Gigawatt thermal is the heat your power plant makes, whereas gigawatt electric is the electricity that the heat is used to generate. They're not the same because not all the heat can be converted into electricity, and the percent of heat that gets converted varies from power plant to power plant.\n \nreply"
    ],
    "link": "https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/",
    "first_paragraph": "A message from Electrical Builders, Ind.America\u2019s Top Performing Nuclear Plants Rely on Electrical Builders, Industries to Expand and Extend the Life of Their Critical Electrical AssetsLearn MoreNew testing done at China\u2019s Shidaowan nuclear power plant has confirmed its ability to be naturally cooled down, an industry-first milestone for achieving commercial-scale inherent safety, according to researchers.The Shidaowan plant, a demonstration high-temperature, gas-cooled reactor with a pebble-bed module (HTR-PM), went into commercial operation last December. Shidaowan\u2019s twin 100-MW units house tiny uranium capsules encased in graphite shells about the size of billiard balls (dubbed \u201cpebbles\u201d), which make the energy density of the fuel much lower than in a traditional nuclear reactor with fuel rods. In the pebble design, the nuclear fission reaction occurs more slowly than in conventional reactors, but the fuel can withstand higher temperatures for longer and the heat resulting from the ",
    "summary": "In a groundbreaking triumph of modern science, China's Shidaowan nuclear power plant has managed to pass a \"meltdown\" test, confirming that its pebble-bed reactor design is indeed slower and chunkier than the old-school, svelte nuclear reactors. Commenters eagerly jump into the fray, fiercely debating the proportions of this monumental, pebble-filled beast\u2014a testament to human ingenuity or a looming over-engineered disaster? They argue over gigawatts and reactor housing sizes with the fervor of sports fans during a championship, inadvertently creating a new sport: competitive reactor sizing. Meanwhile, common sense left the chat early, hinted at by cries of despair over the expansion of radioactive waste that follows the growing size of reactors. Who knew progress measured in pebbles could be so divisive? \u269b\ufe0f\ud83c\udfb1\ud83d\udd25"
  }
]