[
  {
    "title": "Niantic announces \"Large Geospatial Model\" trained on Pok\u00e9mon Go player data (nianticlabs.com)",
    "points": 148,
    "submitter": "bookstore-romeo",
    "submit_time": "2024-11-19T20:02:05 1732046525",
    "num_comments": 100,
    "comments_url": "https://news.ycombinator.com/item?id=42187494",
    "comments": [
      "This is pretty cool, but I feel as a pokehunter (Pokemon Go player), I have been tricked into working to contribute training data so that they can profit off my labor. How? They consistently incentivize you to scan pokestops (physical locations) through \"research tasks\" and give you some useful items as rewards. The effort is usually much more significant than what you get in return, so I have stopped doing it. It's not very convenient to take a video around the object or location in question. If they release the model and weights, though, I will feel I contributed to the greater good.\n \nreply",
      "They won't. It's the same data collection play as every other Google projectJust for clarity on this comment and a separate one, Niantic is a Google spin out company and appears to still be majority shareholder: https://en.wikipedia.org/wiki/Niantic,_Inc.#As_an_independen...\n \nreply",
      "Google actually has released weights for some of their models, but judging by the fact that this model is potentially valuable, they likely will not allow Niantic for this\n \nreply",
      "> Google actually has released weights for some of their models, but judging by the fact that this model is potentially valuable, they likely will not allow Niantic for thiswhich is totally unfair, every niantic player should have access to all the stuff because they collectively made it\n \nreply",
      "> which is totally unfair, every niantic player should have access to all the stuff because they collectively made itI don't understand this perspective. While all players may have collectively made this model possible, no individual player could make a model like it based on their contributions alone.Since no single player could replicate this outcome based on only their data, does it not imply that there's value created from collecting (and incentivizing collection of) the data, and subsequently processing it to create something?It actually seems more unfair to demand the collective result for yourself, when your own individual input is itself insufficient to have created it in the first place.I don't think producers of data are inherently entitled to all products produced from said data.Is a farmer entitled to the entirety of your work output because you ate a vegetable grown on their farm?\n \nreply",
      "\u201cIs a farmer entitled to the entirety of your work output because you ate a vegetable grown on their farm?\u201dBad analogy. I pay a farmer (directly or indirectly) for the vegetable. It\u2019s a simple, understood, transaction. These players were generally unaware that they were gathering data for Niantic in this way.If data is crowdsourced it should belong to the crowd.\n \nreply",
      "What you say is fair but if an individual's data doesn't matter, what happens when they ask to have their data deleted under GDPR.\nis there a way to demux their data from existing models?\n \nreply",
      "Welcome to the modern internet. While you're at it, please get me access to \n    Google's captcha models\n    facebook face directory\n    Google's GPS location data hoard, (most every android phone on the planet 24/7 (!) and any iPhone navigating with gmaps)\n    And so on and so onAll of which I've directly contributed to and never (directly) recieved anything in return\n \nreply",
      "> All of which I've directly contributed to and never (directly) recieved anything in returnTo be fair, you received a service for free that you may have otherwise had to pay for. I'm not saying it's just, but to say you didn't get anything in return is disingenuous.\n \nreply",
      "Agreed. I mostly meant that I'll never see the actual dataset that I contributed to. That's why I'd prefer to spend my time on things that I can see, like OpenStreetMap :)\n \nreply"
    ],
    "link": "https://nianticlabs.com/news/largegeospatialmodel",
    "first_paragraph": "At Niantic, we are pioneering the concept of a Large Geospatial Model that will use large-scale machine learning to understand a scene and connect it to millions of other scenes globally.When you look at a familiar type of structure \u2013 whether it\u2019s a church, a statue, or a town square \u2013 it\u2019s fairly easy to imagine what it might look like from other angles, even if you haven\u2019t seen it from all sides. As humans, we have \u201cspatial understanding\u201d that means we can fill in these details based on countless similar scenes we\u2019ve encountered before. But for machines, this task is extraordinarily difficult. Even the most advanced AI models today struggle to visualize and infer missing parts of a scene, or to imagine a place from a new angle. This is about to change: Spatial intelligence is the next frontier of AI models.As part of Niantic\u2019s Visual Positioning System (VPS), we have trained more than 50 million neural networks, with more than 150 trillion parameters, enabling operation in over a mil",
    "summary": "Title: **Niantic Harnesses the Power of Unsuspecting Pok\u00e9mon Trainers for Corporate Benefit**\n\nIn a bold move that barely conceals its intent to monetize the weary legs of its relentless user base, Niantic announces a \"Large Geospatial Model\" that sounds more like a fancy term for \"We\u2019ve been using your data, thanks!\" As Pok\u00e9mon Go players worldwide cry *exploitation*, Niantic reassures them that they're pioneering AI by turning playful jaunts into unpaid data harvesting sessions. Commenters, oscillating between outrage and resignation, delve into the ethics of digital serfdom with the usual naive hope that maybe Google will throw them a bone this time. Spoiler: <em>They won't.</em> Meanwhile, the \"Pokehunters\" ponder a GDPR-fueled existential crisis: if their data vanishes, does Niantic's model fall apart, or is it just another day of corporate gains built on collective oblivion? \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udd0d"
  },
  {
    "title": "Weight-loss drug found to shrink heart muscle in mice, human cells (ualberta.ca)",
    "points": 92,
    "submitter": "Eumenes",
    "submit_time": "2024-11-20T23:53:25 1732146805",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=42199447",
    "comments": [
      "> emerging research showing that up to 40 per cent of the weight lost by people using weight-loss drugs is actually muscleThat's the sort of headlines that smells like bullshit to me.My understand of those drugs is that they don't actually make you lose weight, they just cut your appetite so you can follow a diet to lose weight without hunger hammering at the door. So to start with, if that's the case, all they are observing is the effect of a diet. Not sure the diet drug has much to do with it.Then I went from 133kg to 88kg with these diet drugs. Even though I exercised every day, I am sure I also lost some muscle mass as well, just because I don't have to carry 45kg every time I make a move anymore. Seems logical and would probably be concerned if it was any other way.\n \nreply",
      "The next line of the article after that 40% quote:> Carla Prado, a nutrition researcher in the Faculty of Agricultural, Life & Environmental Sciences and lead author on the commentary, explains this rate of muscle decline is significantly higher than what is typically observed with calorie-reduced diets or normal aging and could lead to a host of long-term health issues \u2014 including decreased immunity, increased risk of infections and poor wound healing.The rather obvious problem is that these GLP1 agonists don't improve your diet. If you continue to eat a protein and nutrient deficient diet (which is probably a majority of Americans) with caloric restriction on top of that, that leads to excessive muscle loss that you wouldn't see in a weight loss diet. This normally doesn't happen without GLP1 agonists, because these diets are too difficult to stick to for most people. Those who stick to them usually turn to nutritious high satiety whole foods that help combat the negative effects of caloric restriction.Losing weight without losing muscle mass is very hard. It requires extreme diets like a protein sparring modified fast where 80%+ of your calories are from lean protein while running a 50% caloric deficit. If this research is correct, then using GLP1 agonists shortcuts the feedback loops that make the diets hard to stick to, but they shift the tradeoffs from weight to overall nutrition.\"When a measure becomes a target, it ceases to be a good measure\" and all that.\n \nreply",
      "> Losing weight without losing muscle mass is very hard.\n\nLots of amateur body builders can do it.  There are whole training guides about how to lose body fat, but maintain as much muscle mass as possible.  Granted, they are probably a minority because they have higher discipline and motivation than the average population.\n \nreply",
      "> The rather obvious problem is that these GLP1 agonists don't improve your dietMy understanding from initial anecdotes is this is actually literally wrong. Which was surprising to me, too. But people on GLPs tend to prefer more nutritious food (high protein and high fiber). I'm not sure if this has been studied directly in clinical trials yet but I know that food manufacturers have been reorienting their products toward healthier meal configurations in response to the GLPs.I predicted the exact opposite of this, but so far I appear to have been wrong.\n \nreply",
      "I\u2019ve heard that anecdote from HN users many times but based on my meatspace social group of (mostly) California yuppies, that effect is vastly overstated. Even some of the diabetics I know on Ozempic have started using it as an excuse for a shittier diet. Now my sample size is barely ten people on Ozempic/Wegovy so take it with a grain of salt and what not, but I\u2019m skeptical.I bet there\u2019s a large group of people - possibly over represented on HN and other online communities - that just need a little nudge to suppress their cravings and eat healthier, but that\u2019s far from universal. For a lot of people, they wouldn\u2019t even know where to start to eat healthier except choosing a salad over a burger at the takeout menu. Even with drugs masking cravings, many people just haven\u2019t had good health or culinary education.\n \nreply",
      "Odd Lots (Bloomberg finance podcast) had an episode back in June or something interviewing a food design consultant, and their focus groups came back very strongly in favor of healthier meal compositions. Agreed though, it's hard to know things :) Hopefully some real studies on this will be done soon.\n \nreply",
      "Industry led focus group is not a legitimate source.\n \nreply",
      "Uhhhh, in general this is true, but in this particular scenario they have a stronger incentive than almost anyone to understand true preference shifts created by these drugs.It doesn't mean they end up with the correct findings, but they are absolutely incentivized to try to produce correct findings.Lazy and inapplicable heuristics are not legitimate insights.",
      "This observation is very interesting.  I hope that it is studied more closely and we can read some peer reviewed research on the matter.  One idea popped into my head: Could part of the cause be that people's mood and self-esteem improves during (GLP1 agonist-induced low hunger) weight loss?  TL;DR: If you feel like shit about yourself (and body), then you are more likely to eat poorly, and vice versa.\n \nreply",
      "Nutrient deficient, sure, protein deficient? Probably not.\n \nreply"
    ],
    "link": "https://www.ualberta.ca/en/folio/2024/11/weight-loss-drug-found-to-shrink-heart-muscle.html",
    "first_paragraph": "U of A researchers urge caution about the unknown unintended negative health consequences of trendy anti-obesity medications.November 18, 2024 By Michael BrownA new U of A study shows that drugs like Ozempic may not just be causing people to lose weight \u2014 they may be causing the heart to lose muscle. (Photo: Getty Images)Trendy weight-loss drugs making headlines for shrinking waistlines may also be shrinking the human heart and other muscles, according to a new University of Alberta study whose authors say should serve as a \u201ccautionary tale\u201d about possible long-term health effects of these drugs.\u201cIf people have been prescribed these drugs, then the benefits should likely far exceed the risks,\u201d says Jason Dyck, lead author on the study, pediatrics professor in the Faculty of Medicine & Dentistry and a member of the Women and Children\u2019s Health Research Institute.\u201cHowever, the growing number of people who may be taking these drugs who do not meet the eligibility criteria and who are not a",
    "summary": "<h3>Weight-Loss Wonders Wilt Hearts: The Skinny on Shrunken Muscles</h3>\nIn a world where thinner is synecdochically better, University of Alberta scientists drearily note that those miracle \"shrink your girth\" drugs might just <em>also</em> munch on your heart muscle. Care to lose weight? Prepare to lose heart\u2014<i>literally</i>. Commenters, showcasing a blend of pseudo-nutritionist wisdom and Google PhDs, debate whether these findings are more heart-breaking or muscle-aching while ponderously dissecting their personal diet diaries. Meanwhile, Ozempic becomes the new scapegoat for everything from flabby arms to the fall of Western civilization, with a side of fries. \ud83c\udf5f\ud83d\udc94"
  },
  {
    "title": "What is the origin of the lake tank image that has become a meme? (2021) (history.stackexchange.com)",
    "points": 473,
    "submitter": "napolux",
    "submit_time": "2024-11-20T13:30:03 1732109403",
    "num_comments": 105,
    "comments_url": "https://news.ycombinator.com/item?id=42193771",
    "comments": [
      "Since Know Your Meme doesn't give the reference for why it's a lake, maybe not everybody is familiar with british lore:The mythical Lady of the Lake:Probably best known via Monthy Python:Strange women lying in ponds distributing swords is no basis for a system of government. Supreme executive power derives from a mandate from the masses, not from some farcical aquatic ceremony.In short: She teaches Lancelot arts and writing, infusing him with wisdom and courage, and overseeing his training to become an unsurpassed warrior.https://en.wikipedia.org/wiki/Lady_of_the_Lakehttps://tvtropes.org/pmwiki/pmwiki.php/Main/EnigmaticEmpower...\n \nreply",
      "This reminds me that Monty Python and the Holy Grail contributed actual historical knowledge about Arthurian legends to my knowledge base while growing up. Other examples of Python unintentional education include knowing the names of a myriad of obscure cheeses (the cheese shop skit), a shocking number of anachronistic synonyms for death (the parrot skit) and notable contributions of the Roman Empire (Life of Brian 'What have the Romans ever done for us?' skit).While it didn't contribute to my GPA at the time, I'm sure I could name more notable philosophers than any other 8th grader in my school (philosopher's song skit). However, in high school it did spark the interest to look up and read about each of the philosophers in the song.\n \nreply",
      "The problem is that comedy is frequently not factually accurate.Roman Imperial contributions? Was Roman wine better than pre-Roman wine in that region? Did they improve sanitation, irrigation, medicine etc.? Rome was an oppressive slavery based society.Then what about the Spanish Inquisition sketch? It keeps repeating \"fanatically devoted to the Pope\"\" The Spanish inquisition was an arm of the Spanish monarchy, at least two Popes tried to shut it down, and some historians have suggested one of its aims was to reduce the power of the Papacy.I do like the Philosopher's Song, the Dead Parrot and Cheese Shop.Other comedies are no better. Black Adder has a witchfinder (an early modorn innovation) in a Medieval setting.Pop culture is not historically accurate!\n \nreply",
      ">Did they improve sanitation, irrigation, medicine etc.?They built a network of aqueducts that was the largest in the world for a thousand years. The plumbing and sewage systems they installed in their cities were so effective that some are not just intact, but in use, right now. There are plenty of negative points you can raise about the Roman Empire, but water systems aren't one of them.\n \nreply",
      "But apart from the aqueducts, what have the Romans ever done for us?\n \nreply",
      "Okay, but apart from orthography and aquaducts, what have the Romans ever done for us?Now as punishment go write this on the wall 100 times!\n \nreply",
      "Seeing the comedy beats of that scene play out on HN, first unintentionally and then intentionally, has made my day!\n \nreply",
      "well, being part of the Roman Republic/Empire meant peace, even if it was enforced at the tip of a pilum. And the population under the Empire were more prosperous and numerous, so much that the collapse of the Empire in the West had long-lasting negative consequences (I'm mostly basing my opinion off this article: https://acoup.blog/2022/02/11/collections-rome-decline-and-f...)\n \nreply",
      "Ok, but beside the aqueducts, orthography and lasting peace, what good were the Romans for us?\n \nreply",
      "And let us not forget about Roman law.\n \nreply"
    ],
    "link": "https://history.stackexchange.com/questions/57033/what-is-the-origin-of-the-lake-tank-image-that-has-become-a-meme",
    "first_paragraph": "",
    "summary": "In a stunning display of <i>historical acumen</i>, users at history.stackexchange.com dive into the depths of a lake to retrieve the moldy old meme of a tank submerged in water. Because when you need to know about Internet humor, why wouldn't you consult British lore and Monty Python sketches? The commenters joust mightily with their half-remembered history lessons, occasionally surfacing for air with a Python quote, bravely ignoring the encircling sharks of historical inaccuracies and reveling in the glory of their misremembered medieval sanitation trivia. Meanwhile, everyone conveniently forgets the question was about a **tank**. \ud83e\udd26\u200d\u2642\ufe0f"
  },
  {
    "title": "Show HN: Self-Host Next.js in Production (github.com/opennextjs)",
    "points": 53,
    "submitter": "vednig",
    "submit_time": "2024-11-20T22:07:54 1732140474",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=42198611",
    "comments": [
      "I haven't really followed Next.js and the related ecosystem closely, what does this project do exactly? If I look at Next.js docs [0], they have three options for self-hosting: using a Node server, using a Docker container or as an SPA. Is this project a wrapper around one of those or is it something else entirely? Or to perhaps ask differently, to me it seems you can already self-host Next.js, what's the value add of this specific project?[0] https://nextjs.org/docs/pages/building-your-application/depl...\n \nreply",
      "You can \"self-host\" as in `next build` and `next serve`, but it runs as a monolothic runtime. Next-on-vercel compiles each api route to a serverless function and supports various additional flavours of server side rendering of pages. Open Next is being able to run like Next-on-vercel but on AWS, your own infra, Cloudflare Workers, and others.\n \nreply",
      "The reason this project is important is because Next.js is hard to deploy if you're not using Vercel to host your app. You can easily run into issues that are hard to resolve. It's creates lock-in with Vercel and is one of the reasons why Vercel has a bad rep.\n \nreply",
      "(I work on Next.js)The OpenNext project serves two purposes. First, it was to document some of the quirks when self-hosting Next.js. As of Next.js 15, the majority of these have been fixed, thanks to their feedback. The second is to provide an adapter for serverless Next.js deployments, similar to Vercel. Their adapter takes the Next.js output and transforms it to work in a serverless environment.We're working with the maintainers of OpenNext to patch up some of the remaining quirks for deploying Next.js serverless and exploring how to make the maintenance of these community adapters easier.If you want to self-host Next.js on a server, like a VPS or Node.js server, all features of Next.js are supported[1] and you do not need to use OpenNext. Our self-hosting docs include 10 example repos for deploying to different providers and a video walking through all features and options of Next[2].[1]: https://nextjs.org/docs/app/building-your-application/deploy...\n[2]: https://www.youtube.com/watch?v=sIVL4JMqRfc\n \nreply",
      "Hello! On this topic: Could you please look into making the path \u2018next/image\u2019 uses for caching images user definable? Currently I can\u2019t use Google app engine standard because the directory it uses is write protected. The only real solution seems to be custom image providers, which is a drag, so I\u2019m on App Engine Flex spending way more than I probably should :-)\n \nreply",
      "The way I would recommend handling this is using the `loaderFile`: https://nextjs.org/docs/app/api-reference/components/image#l...\n \nreply",
      "In the company I just left, I actually went through the process two or so months ago of migrating their Vercel deployment to AWS. I evaluated several options that are listed on the website and on GitHub, and we landed on using OpenNext via SST, it was a low-pain effort, especially given the CTO's desire to also migrate off of Next.js.As other commenters have touched on - my understanding is the purpose of OpenNext is to package the output artifacts of a Next build in a way that can be deployed to a serverless environment, analogous to how Vercel does it. The supporting projects like SST and the other links in the repo are to take those OpenNext artifacts and deploy them to infrastructure generally in an opinionated way - additionally supporting some of the \"extra\" features described in the repository.The last project I was working on was to then migrate from SST to Fargate, as a persistent process (serverful?) deployment was preferable for various reasons. In that scenario, we would just be running the built in server using the Next.js standalone deployment mode (effectively a `node index.js`). We didn't need the extra functionality covered by OpenNext.\n \nreply",
      "What\u2019s the CTO\u2019s motivation for migrating off of Next.js? And to what?\n \nreply",
      "I believe the intent of OpenNext is to allow you to run your Next.js applications in a serverless manner, same as Vercel.\n \nreply",
      "This in interesting, but while OpenNext is agnostic about the hosting layer, it seems opinionated about the IaC layer. SST is great, but I still use CDK for everything and have no appetite to maintain a snowflake project with a different IaC tool than everything else.I see that the docs do link to other projects built on top of OpenNext that support other tools, but they seem stagnant and stuck on old versions of OpenNext (which effectively means stuck on old versions of Next.js).I get that the people behind the project have limited bandwidth, and if they're going to support a tool, they'd first and foremost support the one they use and maintain themselves, but still.\n \nreply"
    ],
    "link": "https://github.com/opennextjs/opennextjs-aws",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open-source Next.js adapter for AWS\n      \n\n\n\n\n\n\n\n\n\nOpenNext takes the Next.js build output and converts it into packages that can be deployed across a variety of environments. Natively OpenNext has support for AWS Lambda, and classic Node.js Server.OpenNext aims to support all Next.js 14 features. Some features are work in progress. If you are running into any problems make sure to check the docs first before you open a new issue or visit our Discord to let us know!Gymshark UK, Udacity, TUDN, NHS EnglandFor personalisation you need to create a file open-next.config.ts at the same place as your next.config.js, and export a default object that satisfies the OpenNextConfig interface. It is possible to not have an open-next.config.ts file, the default configuration will then be applied automatically.OpenNext can be executed in debug mo",
    "summary": "**HackerNews Theater: Another Moment of Open Source Masochism**\n\nToday on HackerNews, another ragtag open-source hero lands a killer blow on the tyranny of Vercel\u2019s model with the revolutionary <em>OpenNext</em>, a project apparently so groundbreaking that its mere existence merits the sacrifice of both developer time and sanity. In a sea of bewildered comments questioning the value add of packaging Yet Another Serverless Adapter\u2122 for deploying web frameworks that users aren't quite sure they needed in the first place, the maintainers doggedly assure them of their crucial role in the fight against corporate lock-in. Meanwhile, someone\u2019s desperate request for help with image caching quirks swiftly descends into a battle about infrastructural tooling ideology. Where else but in the comments section might one find such a dazzling array of hope, confusion, and technical one-upmanship? \ud83c\udf7f"
  },
  {
    "title": "Z-Library Helps Students to Overcome Academic Poverty, Study Finds (torrentfreak.com)",
    "points": 68,
    "submitter": "hn_acker",
    "submit_time": "2024-11-20T23:36:10 1732145770",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42199301",
    "comments": [
      "Some 28 years ago I taught myself everything could get find from graphic design, basic development, server administration, etc, all downloading commercial warez over dial-up with AOL and Usenet. I didn't need a class or subscriptions, with every software and book I could have wanted, I had the best lab in the world with any software available I could want with piracy.Fast forward 30 years now it's mostly the same as it was, only open source replaced all the commercial, and little has changed that I can still get the rest too. You can pay as much or little as you want in life if you know how.\n \nreply",
      "> Z-Library, or a similar website, is helpful to students living in poverty (82% agree).I would really like to hear the reason for the 18% who thinks that it is not helpful for poor students. Is it this complicated argument that they will discourage authors from writing books and then this will hurt all students in a hypothetical scenario? Or there are other reasons?I mean I understand that some people will just want these sites gone on IP grounds or because it is against the law ..etc. But this question was different.\n \nreply",
      "I would assume that a good chunk of students in poverty simply don't have a device that works well for consuming books on.If you don't have a tablet or laptop, just a phone with a small screen, I can see people saying z-lib isn't helpful for them. That they'll just use physical books at their library.I can definitely imagine a lot of undergrads who would assume that if a book isn't available in their college library then they'd never need it anyways. (Rightly or wrongly.)\n \nreply",
      "I\u2019d guess the easiest explanation (which admittedly erases all nuance) is that folks just misinterpreted the question and reflexively dismissed it as soon as they saw \u201cZ-Library\u201d and \u201cHelpful\u201d.I\u2019d also be inclined to discard theoretical \u201cin the long run it\u2019ll be unhelpful\u201d concerns, since that opens up an infinitely-deep can of hypothetical contrived scenarios of arbitrary complexity that can\u2019t be disproven. I\u2019m sure there are very real concerns, but it\u2019s impossible to reason about which concerns specifically people would care about.IMO that leaves the purely practical concerns:- Students in poverty might not have reliable internet, devices or digital literacy. If zlib isn\u2019t available to them, it isn\u2019t helpful- Books available might not cater to the local language/culture, or the real world curriculum needs of those students. If zlib doesn\u2019t help them succeed, it isn\u2019t helpful- The interface sucks and is confusing, which makes students struggle to find what\u2018s useful. If zlib isn\u2019t useable for them, it isn\u2019t helpful\n \nreply",
      "> Is it this complicated argument that they will discourage authors from writing books and then this will hurt all students in a hypothetical scenario? Or there are other reasons?That really can't be it because the question isn't about whether it is moral, legal or good for publishers.I really think this is just elitism and gatekeeping at its worst.\n \nreply",
      "That's why this _can_ be it. If authors stop writing books it will hurt students (who wont have books to read). Nothing to do with ethics or morals.\n \nreply",
      "\"Educated slaves are unhappy\"\n \nreply"
    ],
    "link": "https://torrentfreak.com/z-library-helps-students-to-overcome-academic-poverty-study-finds-241120/",
    "first_paragraph": "",
    "summary": "TorrentFreak breaks the revolutionary news: Z-Library is the modern Robin Hood for the destitute scholars among us! \ud83c\udf93\ud83d\udcb8 Commenters, in a display of unsurprising internet wisdom, answer an age-old question: \"Can you believe some people still buy books?\" Meanwhile, a brave soul wonders why 18% of people are party poopers who don't think piracy is a one-size-fits-all solution to academic impoverishment. Perhaps it\u2019s those darned ethics again, or maybe it's just that reading \"War and Peace\" on a Nokia 3310 isn\u2019t that appealing. Whatever the reason, the internet has spoken, and books are officially free (if you ignore legality, morality, and the tiny text on your cracked phone screen)."
  },
  {
    "title": "AlphaQubit: AI to identify errors in Quantum Computers (blog.google)",
    "points": 84,
    "submitter": "roboboffin",
    "submit_time": "2024-11-20T18:37:04 1732127824",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=42196841",
    "comments": [
      "When maintaining a quantum memory, you measure parity checks of the quantum error correcting code. These parity checks don't contain any information about the logical state, just (partial) information about the error, so the logical quantum information remains coherent through the process (i.e. the logical part of the state is not collapsed).These measurements are classical data, and a computation is required in order to infer the most likely error that led to the measured syndrome. This process is known as decoding.This work is a model that acts as a decoding algorithm for a very common quantum code -- the surface code. The surface code is somewhat like the quantum analog of a repetition code in a sense.\n \nreply",
      "I would instead give the example of the Hamming code. As you probably know, you can construct a quantum code, the Steane code, which is just analogous to Hamming code.The Steane code is the simplest triangular color code. i.e. you can arrange all the qubits on a 2D triangular lattice, and only do nearest neighbor interactions [1]. The surface code is a similar quantum code, in which the qubits can also be placed on a 2D lattice, except that lattice is made up of squares.Why do we care about 2D surfaces and nearest neighbor interactions. Because it makes building quantum hardware easier.EDIT:[1] The Steane code's picture is shown here. https://errorcorrectionzoo.org/c/steane Seven data qubits are on the vertices of the triangles. 2 syndrome qubits on each of the faces.\n \nreply",
      "So, an inherently error-prone computation is being corrected by another very error prone computation?\n \nreply",
      "I feel like this is basically how humanity operates as a whole, and that seems to produce usable results, so why the heck not?\n \nreply",
      "No problem, said von Neumann. https://www.scottaaronson.com/qclec/27.pdf\n \nreply",
      "I've never seen so much money spent on a fundamentally flawed tech, since maybe Theranos. I'm really starting to doubt the viability of the current crop of quantum computing attempts. I think there probably is some way to harness quantum effects, but I'm not sure computing with inherently high margin of error is the right way to do it.\n \nreply",
      "I feel like these are extremely different things being compared.For a lot of technology, most really, the best way to study how to improve it is to make the best thing you know how to and then work on trying to make it better. That's what's been done with all the current quantum computing attempts. Pretty much all of the industry labs with general purpose quantum computers can in fact run programs on them, they just haven't reached the point where they're running programs that are useful beyond proving out and testing the system.\n \nreply",
      "I'm optimistic about current quantum computers, because they are a tool to study wave function collapse. I hope that they will help to understand the relation between the number of particles and a time how long a system can stay in entangled state, which will point to a physical interpretation of quantum mechanics (different from \"we don't talk about wave function collapse\" Copenhagen interpretation).\n \nreply",
      ">AlphaQubit, a recurrent-transformer-based neural-network architecture that learns to predict errors in the logical observable based on the syndrome inputs (Methods and Fig. 2a). This network, after two-stage training\u2014pretraining with simulated samples and finetuning with a limited quantity of experimental samples (Fig. 2b)\u2014decodes the Sycamore surface code experiments more accurately than any previous decoder (machine learning or otherwise)>One error-correction round in the surface code. The X and Z stabilizer information updates the decoder\u2019s internal state, encoded by a vector for each stabilizer. The internal state is then modified by multiple layers of a syndrome transformer neural network containing attention and convolutions.I can't seem to find a detailed description of the architecture beyond this bit in the paper and the figure it references. Gone are the days when Google handed out ML methodologies like candy...\n(note: not criticizing them for being protective of their IP, just pointing out how much things have changed since 2017)\n \nreply",
      "Eh. It was always sort of muddy. We never actually had an implementation of doc2vec as described in the paper.\n \nreply"
    ],
    "link": "https://blog.google/technology/google-deepmind/alphaqubit-quantum-error-correction/",
    "first_paragraph": "Nov 20, 2024[[read-time]] min read\n          Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology more reliable.\n        Quantum computers have the potential to revolutionize drug discovery, material design and fundamental physics \u2014 that is, if we can get them to work reliably.Certain problems, which would take a conventional computer billions of years to solve, would take a quantum computer just hours. However, these new processors are more prone to noise than conventional ones. If we want to make quantum computers more reliable, especially at scale, we need to accurately identify and correct these errors.In a paper published today in Nature, we introduce AlphaQubit, an AI-based decoder that identifies quantum computing errors with state-of-the-art accuracy. This collaborative work brought together Google DeepMind\u2019s machine learning knowledge and Google Quantum AI\u2019s error correction expertise to accelerate progress on building a ",
    "summary": "<b>AlphaQubit: The Latest AI Charade by Google to Pretend We're Close to Quantum Utopia</b>\n\nGoogle triumphantly declares their new AI, AlphaQubit, can \"identify errors\" in quantum computers, as if the tech wasn't already a noisy mess only comprehensible to five people on Earth. \ud83d\ude44 Cue the article comments: a muddled blend of tech-optimists and doomsayers where someone explains quantum mechanics like it's a knock-off \"Choose Your Own Adventure\" book, while another user invokes von Neumann as if dropping names could stabilize qubits. Most commenters can't decide if they're attending a funeral or a product launch, illustrating that quantum computing's biggest leap is its ability to sustain two conflicting states of hype and doubt simultaneously. Bravo, Google, for keeping everyone equally confused and hopeful! \ud83c\udfad"
  },
  {
    "title": "Vapi (YC W21) Is Hiring Founding Senior Engineer (Front End) (ashbyhq.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-11-21T01:00:39 1732150839",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jobs.ashbyhq.com/vapi/4246b127-9f69-4a57-ac70-d16041f8403b",
    "first_paragraph": "",
    "summary": "In an audacious display of Silicon Valley originality, Vapi, a startup you've never heard of, desperately seeks a \"Founding Senior Engineer.\" Defining ambition as using the latest React hooks to revolutionize the undefined market, the job promises \"equity\" in lieu of real compensation. Commenters, tripping over themselves to showcase their disregard for job stability, compete in a rhetorical battle to prove who can feign more enthusiasm for this groundbreaking opportunity in \"disruption.\" Meanwhile, actual engineers quietly weep into their ergonomic keyboards."
  },
  {
    "title": "AAA \u2013 Analytical Anti-Aliasing (frost.kiwi)",
    "points": 448,
    "submitter": "todsacerdoti",
    "submit_time": "2024-11-20T08:03:20 1732089800",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=42191709",
    "comments": [
      "Thanks for sharing!\nAuthor here, happy to answer any questions.\n \nreply",
      "Google Maps uses AAA on capsule shapes for all road segments - I wrote it ~10 years ago. :D\n \nreply",
      "Neat. Does that mean that every road segment is a separate mesh?\n \nreply",
      "Depends on what you mean by \"mesh\". Each road segment is an instanced rectangle that gets extruded and beveled so that it fits tightly against adjacent segments, and then the pixels are shaded using AAA (with a capsule-shaped distance field) so that the result looks like an antialiased wide line with round end caps and joints.\n \nreply",
      "Fantastic article! I've been trying to figure out antialiasing for MSDF fonts, and have run across some claims:1. antialiasing should be done in linear rgb space instead of srgb space  [1] [2]2. because of the lack of (1) for decades, fonts have been tweaked to compensate, so sometimes srgb is better [3] [4]Do you have advice on linear vs srgb space antialiasing?[1] https://www.puredevsoftware.com/blog/2019/01/22/sub-pixel-ga...[2] http://hikogui.org/2022/10/24/the-trouble-with-anti-aliasing...[3] https://news.ycombinator.com/item?id=12023985[4] http://hikogui.org/2022/10/24/the-trouble-with-anti-aliasing...\n \nreply",
      "Great post! Minor nitpick: WebGL does support MSAA since WebGL1, but in WebGL1 only on the canvas, and you don't have any control over the number of samples (can only select antialiasing on/off) - not that it matters much anymore :)What WebGL2 is still missing is MSAA texture objects (it only supports MSAA render buffers), which makes it impossible to directly load individual samples in a shader (useful for custom-resolve render passes). That's only possible in WebGPU.\n \nreply",
      "How long did this take to write?I have done a few live visualization based blog posts, and they take me ages to do.  I kind of think that's the right idea though. There is so much content out there, taking longer to produce less content at a higher quality benefits everyone.\n \nreply",
      "One small bit of tecnical feedback for the website itself: it would be nice if the links in the article open in a new tab by default, because reloading the webpage via the back button is a little broken on my mobile browsers. I suspect it has something to do with trying to restore the state of the page while also having WebGL contexts.\n \nreply",
      "As a non-gamedev person but just gamer, I should expect that this will replace TAA anytime soon? Should it replace TAA?\n \nreply",
      "Massive thanks for this! I\u2019m already using my own version of analytical antialiasing but there were some bits I couldn\u2019t get quite right so this is perfect!\n \nreply"
    ],
    "link": "https://blog.frost.kiwi/analytical-anti-aliasing/",
    "first_paragraph": "Today\u2019s journey is Anti-Aliasing and the destination is Analytical Anti-Aliasing. Getting rid of rasterization jaggies is an art-form with decades upon decades of maths, creative techniques and non-stop innovation. With so many years of research and development, there are many flavors.From the simple but resource intensive SSAA, over theory dense SMAA, to using machine learning with DLAA. Same goal - vastly different approaches. We\u2019ll take a look at how they work, before introducing a new way to look a the problem - the \u2728analytical\ud83c\udf1f way. The perfect Anti-Aliasing exists and is simpler than you think.To understand the Anti-Aliasing algorithms, we will implement them along the way! Following WebGL canvases draw a moving circle. Anti-Aliasing cannot be fully understood with just images, movement is essential. The red box has 4x zoom. Rendering is done at native resolution of your device, important to judge sharpness.Let\u2019s start out simple. Using GLSL Shaders we tell the GPU of your device",
    "summary": "**AAA \u2013 Analytical Anti-Aliasing (frost.kiwi)**\n\nIn today's thrilling episode of \"Old Problems, New Buzzwords,\" we journey through the mystic lands of Anti-Aliasing, where the illustrious protagonist, Analytical Anti-Aliasing, promises to defeat the archaic evil known as jaggies with *ease*. Marvel as decades of research culminate in multiple flavors of technology spaghetti\u2014from SSAA's greedy pixel-eating habits to DLAA's desperate plea for relevance through machine learning. Web commenters\u2014a brigade armed with anecdotes and URL-heavy dissertations\u2014rally around this revolutionary cause, providing critical insights like \"Neat\" and pondering the monumental implications of road segment meshes on their non-gamedev gaming experiences. Are we just one algorithm away from graphical nirvana, or is this another case of tech enthusiasts dancing around the same fire, hoping it doesn\u2019t burn out? Spoiler: bring marshmallows. \ud83c\udf08\u2728"
  },
  {
    "title": "SQL, Homomorphisms and Constraint Satisfaction Problems (philipzucker.com)",
    "points": 106,
    "submitter": "xlinux",
    "submit_time": "2024-11-20T17:07:18 1732122438",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=42195994",
    "comments": [
      "The post mentions the idea that querying a database D can be understood algebraically as enumerating all morphisms Q -> D, where Q is the \"classifying\" database of the query, i.e. a minimal database instance that admits a single \"generic\" result of the query. You can use this to give a neat formulation of Datalog evaluation. A Datalog rule then corresponds a morphism P -> H, where P is the classifying database instance of the rule body and H is the classifying database instance for matches of both body and head. For example, for the the transitivity rule  edge(x, z) :- edge(x, y), edge(y, z).\n\nyou'd take for P the database instance containing two rows (a_1, a_2) and (a_2, a_3), and the database instance H contains additionally (a_1, a_3). Now saying that a Database D satisfies this rule means that every morphism P -> D (i.e., every match of the premise of the rule) can be completed to a commuting diagram  P --> D\n  |    ^\n  |   /\n  \u2304  /\n  Q \n\nwhere the additional map is the arrow Q -> D, which corresponds to a match of both body and head.This kind of phenomenon is known in category theory as a \"lifting property\", and there's rich theory around it. For example, you can show in great generality that there's always a \"free\" way to add data to a database D so that it satisfies the lifting property (the orthogonal reflection construction/the small object argument). Those are the theoretical underpinnings of the Datalog engine I'm sometimes working on [1], and there they allow you to prove that Datalog evaluation is also well-defined if you allow adjoining new elements during evaluation in a controlled way. I believe the author of this post is involved in the egglog project [2], which might have similar features as well.[1] https://github.com/eqlog/eqlog\n[2] https://github.com/egraphs-good/egglog\n \nreply",
      "For anyone curious: the performance difference between Clang and GCC on the example C solution for verbal arithmetic comes down to Clang's auto-vectorisation (deducing SIMD) whilst GCC here sticks with scalar, which is why the counter brings Clang closer in line to GCC (https://godbolt.org/z/xfdxGvMYP), and it's actually a pretty nice example of auto-vectorisation (and its limitations) in action, which is a fun tangent from this article (given its relevance to high-performance SMT/SAT solving for CSP)\n \nreply",
      "The topic of huge queries on tiny databases makes me think of this recent discussion on the SQLite forum: https://sqlite.org/forum/forumpost/0d18320369Someone had an issue because SQLite failed to optimize the following query    select * from t where x = 'x' or '' = 'x'\n\nSomeone said that SQLite could not optimize out the \"or '' = 'x'\" because it would be too expensive to compute. Which is obviously true only for huge queries on tiny datasets.\n \nreply",
      "Why would it be too expensive to optimize out static subexpressions?\n \nreply",
      "My guess is that the expense can be tricky to calculate since the additional optimization prior to executing the query may take longer than if the query was just able to run (depending on the dataset, of course). I wonder if it's too expensive to calculate a heuristic as well, so it just allows it to execute.Just a guess.\n \nreply",
      "It's not obviously true at all.  Optimizing out `'' = 'x'` can be done for a fixed cost regardless of record count.\n \nreply",
      "Optimizing out static expressions can be done in linear time at best. So if the number of clauses in WHERE is huge and the size of the underlying table is tiny (such as in the examples shown in the article we are commenting on), it will be better not to run the optimization.But of course, in normal life, outside of the world of people having fun with Homomorphisms, queries are much smaller than databases.\n \nreply",
      "Parsing the expression in the first place is already linear time.\n \nreply",
      "> SQLiteWell... there's your problem. SQLite is not a general-purpose RDBMS, it is marketed as a replacement for \"fopen()\", a purpose for which it excels.A similar product is the Microsoft Jet database engine, used in products such as Microsoft Exchange and Active Directory. Queries have to be more-or-less manually optimised by the developer, but they run faster and more consistently than they would with a general-purpose query engine designed for ad-hoc queries.\n \nreply",
      "I hate Jet with a vengeance\n \nreply"
    ],
    "link": "https://www.philipzucker.com/sql_graph_csp/",
    "first_paragraph": "\nNov 18, 2024\n      Database queries are a pretty surprisingly powerful tool that can solve seemingly intractable problems.It is a fun coding challenge to do things in SQL. I\u2019ve seen people solve sudokus or do advent of code, or you can build a datalog on SQL with a little metaprogramming (maybe even fully internally). It is also possible to build a CHR (constraint handling rules) system on SQL or a graph rewriting system on SQL. Here I talk about how one can use SQL queries to do graph instruction matching https://www.philipzucker.com/imatch-datalog/ .SQL is a feature rich language, it is not surprising that you can do these things from that perspective, using this and that odd feature. But even the simple idealized \u201cSELECT FROM WHERE\u201d core of SQL has a lot of power.From a logical perspective, this core is basically conjunctive queries https://en.wikipedia.org/wiki/Conjunctive_query#Relationship_to_other_query_languages . Each table is a logical predicate, each variable is bound to a ",
    "summary": "**SQL, Homomorphisms and Constraint Satisfactions Problems Dare to Dream?**\n\nIn yet another dizzying display of SQL wizardry, Philip Zucker tackles the thrilling world of solving complex puzzles with database queries, revealing just how _bored_ one must be to use SQL for graph instruction matching. The commentary quickly devolves into an academic slugfest over the merits of homomorphisms and constraint satisfaction, with each commenter desperately trying to remind others of their own profound understanding of theoretical computer science. One daring soul attempts to tangentially discuss the optimization of static subexpressions in SQLite, only to be met with impassioned replies that oscillate between pedantic corrections and thinly veiled sarcasm. It\u2019s like watching a group of nerds arguing over who gets the last slice of pizza, each equipped with theorems instead of appetites. \ud83c\udf55\ud83d\udcbb"
  },
  {
    "title": "Bit-twiddling optimizations in Zed's Rope (zed.dev)",
    "points": 76,
    "submitter": "misternugget",
    "submit_time": "2024-11-18T16:39:10 1731947950",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=42174085",
    "comments": [
      "I really like all the blog posts and videos the Zed team has put out, thank you if you\u2019re reading this!Unrelated to this specific post I\u2019m such a fan of Zed. It\u2019s the first feature complete text editor in recent memory that I\u2019ve truly enjoyed using (i.e. it stays out of the way, is really fast, feels well engineered). I\u2019m coming to Zed after years of Emacs which I still have love for but no longer feels like a competitive piece of software (it does not take full advantage of how good computers are today, e.g. gpu rendering or multicore). I really hope Zed stays a fast and lightweight text editor instead of becoming some bloated growth-at-all-cost VC ware (not that they\u2019ve exhibited any signs of that happening). I\u2019d also happily pay for Zed without a subscription based thing for access to LLM features (which I do not use).\n \nreply",
      "> it does not take full advantage of how good computers are today, e.g. gpu rendering or multicoreWhy does Emacs need that though? I hear people say this all the time and I don't get it. Multicore kind of works against the structure that Emacs touts as a feature. And GPU rendering? In many applications, I totally agree with these complaints. But it's a text editor.I tried Zed myself, and it's good. But it doesn't dethrone Emacs (for me personally).\n \nreply",
      "> But it's a text editor.Long time emacs user here (+20 years, yikes). I've used it on all kinds of computers during this time. Even a relatively modest computer from 2024 is an absolute beast compared to something from the year 2000.With that said, there are text editing operations that can cause it to grind to a complete halt, especially working with large files (or very long lines). And it shouldn't, you know? I think emacs users sort of internalize which operations they should avoid. It's kind of ridiculous to have to do that in a text editor with the massive amounts of compute that our computers have today.\n \nreply",
      "> (or very long lines)Long line handling has greatly improved in emacs-29. Multi-megabyte lines are not a problem anymore.\n \nreply",
      "from Emacs 29.1 NEWS file, https://raw.githubusercontent.com/emacs-mirror/emacs/refs/he...    ** Emacs is now capable of editing files with very long lines.\n    The display of long lines has been optimized, and Emacs should no\n    longer choke when a buffer on display contains long lines.  The\n    variable 'long-line-threshold' controls whether and when these display\n    optimizations are in effect.\n\n    A companion variable 'large-hscroll-threshold' controls when another\n    set of display optimizations are in effect, which are aimed\n    specifically at speeding up display of long lines that are truncated\n    on display.\n \nreply",
      "> Multicore kind of works against the structure that Emacs touts as a feature.I have consistent issues with emacs locking up when executing network requests. I'm sure there's a specific bug that could be hunted down and addressed, but this sort of thing shouldn't happen much in an editor that's multicore by default.I'm not trying to dismiss emacs' reasoning, of course, but I can understand being disgruntled with it.The actual rendering I've been quite please by, though!\n \nreply",
      "Yeah this is one reason, or Emacs freezing for up to a minute when updating packages. Also when using an LSP I notice latency.I use Emacs GUI (outside of the terminal) and comparing performance for rending to something like Zed or Sublime is definitely noticeable. It\u2019s great that Emacs is so resource efficient but sometimes I wish it used more of my beefy computer(s).Like I said I still love Emacs and it\u2019s okay for it to make a different set of trade-offs. I honestly didn\u2019t think I\u2019d ever switch editors but here we are!\n \nreply",
      "Removing the interpreter lock for a few specialized tasks (without sweeping runtime changes to Emacs) would be enough to fix most of these issues -- parsing JSON from process output into lisp data in a background thread is one candidate. [1]Installing packages does not need to block either, there is no architectural limitation here.  The Elpaca package manager for Emacs provides async, parallel package updates. Loading packages into the Lisp image will block though, there's no way around that.The other big source of input lag is garbage collection, and there are some ongoing efforts to use the MPS library in Emacs for a copying, concurrent GC.  This is a big change and I don't know if this experiment will go anywhere, but Eli Zaretskii and co are trying.[1]: https://github.com/emacs-lsp/emacs\n \nreply",
      "That's fair I guess. In the case of IO that can be an issue. When I hear multicore, I assume we're talking about parallelism, not concurrency.As for LSP, other than the Nim langserver, I've been quite satisfied with Eglot's performance. I'm curious what your setup is like. To be fair, I'm running a highly customized Doom Emacs config, so it's possible I inherited some non-vanilla optimizations I'm not aware of.\n \nreply",
      "\u201cNeed\u201d is strong but using GPU rendering is definitely better than CPU rendering and makes things feel very snappyMost new TTY projects use GPUs for that reason\n \nreply"
    ],
    "link": "https://zed.dev/blog/zed-decoded-rope-optimizations-part-1",
    "first_paragraph": "",
    "summary": "In an impressive demonstration of both technological overkill and misplaced nostalgia, engineering hobbyists wax poetic on bit-twiddling optimizations in something called Zed's Rope, as seen on zed.dev. As the internet\u2019s armchair programmers engage in a fierce text-editor warfare, they deliver passionate soliloquies about the potential of multicore and GPU enhancements for their beloved relics of software. One side sings the praises of Zed\u2019s sleek interface and <em>revolutionary</em> avoidance of feature bloat, while the opposing faction clings stoically to Emacs\u2014because software isn't worth using unless you need a computer science degree to configure your text editor. Adding to the mire, cries for understanding go unheard over the din of users recounting war stories about Emacs handling multi-megabyte lines back when \"All Star\" by Smash Mouth was topping the charts. Meanwhile, productivity in typing out actual words remains conspicuously absent from the discussion, blithely overshadowed by the sweet allure of theoretical performance gains. \ud83e\udd13\ud83d\udcbe"
  },
  {
    "title": "Show HN: Autotab \u2013 Programmable AI browser for turning web tasks into APIs",
    "points": 49,
    "submitter": "jonasnelle",
    "submit_time": "2024-11-20T20:22:32 1732134152",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=42197741",
    "comments": [
      "I love the idea - owning the browser definitely seems like the right approach.I tried it out on a workflow I've been manually piecing together and it gave me a bunch of \"Error encountered, contact support\" messages when doing things like clicking on a form input field, or even a button.The more complex \"Instruction\" block worked correctly instead (literally things like \"click the \"Sign In\" button), but then I ran out of the 5 minutes of free run time when trying to go through the full flow. I expect this kind of thing will be fixed soon, as it grows.In terms of ultimate utility, what I really want is something which can export scripts that run entirely locally, but falling back to the more dynamic AI enhanced version when an error is encountered. I would want AutoTab to generate the workflow which I could then run on my own hardware in bulk.Anyway, great work! This is definitely the best implementation I've seen of that glimpsed future of capable AI web browsing agents.\n \nreply",
      "sorry you encountered that issue! what website was the form on? we'll see if we can catch the error!curious what you mean by generating the workflow that you run on your own hardware? Is this different than running Autotab locally?\n \nreply",
      "Very neat in theory but I'm failing to find any technical details.Which layer is the automation happening? Inside using Dev tools? Multiple?What is the self-healing mechanic? I'm guessing invoking an LLM to find what happened and fix it?I guess what I'm wondering is. Is this some sort of hybrid between computer use and Dev tools usage?\n \nreply",
      "Autotab is definitely a hybrid approach, because when it comes to deciding where on the page to take an action, Autotab has to be fast & cheap (humans are both of those) while also being robust to changes. The solution we use is a \"ladder of compute\" where Autotab uses everything from really fast heuristics and local models up to the biggest frontier models, depending on how difficult the task is.For instance, if Autotab is trying to click the \"submit\" button on a sparse page that looks like previous versions of that page, that click might take a few hundred milliseconds. But if the page is very noisy, and Autotab has to scroll, and the button says \"next\" on it because the flow has an additional step added to it, Autotab will probably escalate to a bigger model to help it find the right answer with enough certainty to proceed.There is a certain cutoff in that hierarchy of compute that we decided to call \"self-healing\" because latency is high enough that we wanted to let users know it might take a bit longer for Autotab to proceed to the next step.\n \nreply",
      "I see it's able to perform data extraction, but what if you wanted to enter in data from another system, or generated by an LLM during the workflow?\n \nreply",
      "Data from external systems can be provided to Autotab in the form of CSV files or string inputs, which can be passed to the API to parametrize skills. However, in most cases, ingesting data into Autotab is easiest by just having Autotab navigate to the website where the data is present.Autotab has a structured type system underlying the workflows, so any data processed in the course of an automation can be referenced in later steps. It's a bit like a fuzzy programming language for automation, and the model generates schemas to ensure data flows reliably through the series of steps.For example, users often start by collecting information in one system (using an extract step as you mentioned), then cross reference it in another and then submit some data by having Autotab type it into a third system. In Autotab, you can just type @ to reference a variable, each step has access to data from previous steps.At the end, you can get a dump of all of Autotab's data from a run as a JSON file, or turn specific arrays of data into CSV files using a table step.\n \nreply",
      "Pretty slick. I recorded a session for ordering from a restaurant website, and it did repeat the entire workflow. It had some issues with a modal popped up but all in all well done! We have been trying to robotify the task of ordering from restaurant for our clients and seems like your solution can work well for us. I am guessing that you want your users to use Autotab browser, what is use for API?\n \nreply",
      "Thanks! We think of the browser as an authoring tool where you create, test and refine skills.After you've done that, the API is great for cases where you want to incorporate Autotab into a larger data flow or product.For instance, say Company A has taught Autotab to migrate their customers' data - so their customers just see a sync button in the Company A product, which kicks off a Autotab run via API. Same for restaurant booking, if you'd want that to happen programatically.\n \nreply",
      "Understood! How does it work if we have several different restaurants to order from, do I need to record each ordering session and create skills for each restaurant or it can infer on its own given the task to order from a restaurant. \nSecondly, any docs or samples to see how to integrate this with your API?\n \nreply",
      "Depends on how different the flows are for different restaurants. If they're just different names but use the same booking system you'd typically use an input and have Autotab find the correct restaurant first. If they're totally different booking systems you can try the instruct (open ended agentic) step but my guess is that will be too slow and unreliable for now, so you'd probably want to record different skills for each.Docs are here with sample code: https://docs.autotab.com/api-reference\n \nreply"
    ],
    "link": "item?id=42197741",
    "first_paragraph": "",
    "summary": "Welcome to another episode of Hacker News Theatre, where the dreams of automating even your coffee breaks are alive and well! \ud83c\udfad Today's star, Autotab, promises to turn your chaotic web tasks into neat little APIs, because why click buttons when you can script an existential crisis in JavaScript? Users are *delighted* with error messages like it's 1995 all over again\u2014except this time, they have AI to blame. Meanwhile, the comment section doubles as a support group, where brave souls share tales of squandered free minutes and the zen art of debugging someone else's \"capable\" code. Will Autotab revolutionize the web or just generate more tech support jobs? Stay tuned, and don't touch that refresh button!"
  },
  {
    "title": "Google stops letting sites like Forbes rule search for \"Best CBD Gummies\" (arstechnica.com)",
    "points": 135,
    "submitter": "pseudolus",
    "submit_time": "2024-11-20T21:07:28 1732136848",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=42198115",
    "comments": [
      "I'm confused about how or why this is a new policy. My memory is inside Google we were discussing this risk back in 2003, probably earlier. Search quality was on it. I just assumed they'd lost the arms race, or that the parasites' ranking was justified for other reasons that were hard to tease apart. What are they doing new now?I think often about Mahalo, the sleazy shovel content that was spamming the web back in 2007. Google shut that down somewhat fast, although it did take several years. These days with AI and more aggressive spammers it's a losing battle. The real problem is the financial incentives that make this kind of spamming profitable in the first place.My tiny little blog gets about 3 requests a week for someone to \"pay me to run a guest article\". Going rate is $50-$200 and again, my blog is tiny.\n \nreply",
      "Just manually review top K websites and ban such garbage?Sometimes dumb, bruteforce and biased solution can work way better than any automation you can come up with\n \nreply",
      "> I'm confused about how or why this is a new policy.My best guess is it's because they finally have a real competitor in ChatGPT.> The real problem is the financial incentives that make this kind of spamming profitable in the first place.Yeah, but the financial incentives exist on both ends. There's a gross symbiotic relationship between Google and SEO spammers, because Google also owns the ad network the spammers put on their page. If Google puts ad-laden SEO blogspam as the top result and a user clicks it, the user sees a bunch of ads from Google. Everyone wins: Google, the SEO spammers, and advertisers. Well, everyone except the user, but who cares about them?My guess/hope is that ChatGPT has made someone who actually cares about the quality of search results actually step in and say things have gone too far.\n \nreply",
      "You're totally right about that symbiotic relationship. We were aware of that risk in the early days when AdSense launched, we saw some very innovative and gross exploitation and created some policies to rein it in. But ultimately if Google makes a buck coming and going, they will do that.Wasn't there a big story last year in the wake of the DOJ antitrust investigation about Google manipulating search quality to boost ad revenue? I can't put my hands on a reference now, in part because Google is so bad at search these days I can't find anything more than a few months old.\n \nreply",
      "> Google winsDefine \"wins\". From what happening right now, it seems that google may lose much more than it earned by aligning with seo spammersMaybe they need to start locking employee stock options for 100 years to prevent them optimizing short-term gains?\n \nreply",
      "Google's only taking the greedy approach. Spam sites on top, spam sites use google adsense, people click spam sites, they click google ads.It works great, until it doesn't. But that's a problem for the next CEO.\n \nreply",
      "Because ChatGPT is dependent on good search when it searches the web?  Or because it completes with Google when it provides a good answer without searching?  Or what do you mean specifically?\n \nreply",
      "I would say the latter. For software dev questions, my Google searches and Stack Overflow visits have fallen off a cliff since I started paying for ChatGPT.Ironically, I probably would have paid the same amount to Google for ad-free, old-style (accurate) Google searches, but no, they just wanted to keep cranking that ad dial up every year so that ship has sailed.At this point, I'm enjoying watching the old guard of search scrambling to find a life jacket.\n \nreply",
      "One area where Google search is terribly broken is porn.If your search for some specific term \"$foo\", nearly every result is just 'search site $bar for \"$foo\"', taking you to the site's search page, regardless of whether $foo is actually found on the site.\n \nreply",
      "What's hilarious is when people boast about being \"in Forbes\" like it's the magazine from 20 years ago, and not this parasitic SEO operation that publishes garbage on anything.\n \nreply"
    ],
    "link": "https://arstechnica.com/gadgets/2024/11/google-cracks-down-on-parasite-seo-punishing-established-publishers/",
    "first_paragraph": "\n        If you've noticed strange sites on \"Best\" product searches, so has Google.\n      \"Updating our site reputation abuse policy\" is how Google, in almost wondrously opaque fashion, announced yesterday that big changes have come to some big websites, especially those that rely on their domain authority to promote lucrative third-party product recommendations.If you've searched for reviews and seen results that make you ask why so many old-fashioned news sites seem to be \"reviewing\" products lately\u2014especially products outside that site's expertise\u2014that's what Google is targeting.\"This is a tactic where third-party content is published on a host site in an attempt to take advantage of the host's already-established ranking signals,\" Google's post on its Search Central blog reads. \"The goal of this tactic is for the content to rank better than it could otherwise on a different site, and leads to a bad search experience for users.\"Search firm Sistrix cited the lost traffic to the third",
    "summary": "**Google Discovers Spam in 2023: Humanity Rejoices**\nIn a stunning display of realizing the obvious only decades late, Google proudly announces its crackdown on SEO abuses by heavy hitters like Forbes. Apparently, no matter how many high-class dinners and corporate retreats we've had, people are still shocked - shocked! - to find that SEO spam is undermining the sanctity of their sacred 'Best CBD Gummies' searches. Comment sections, brimming with the combined knowledge of a 2003 Google internal memo, wonder loudly and with great sophistication why all this feels like d\u00e9j\u00e0 vu. Meanwhile, a stray commenter laments the fall from grace of mythical good search results, but really, who needs accurate information when you can have ads? \ud83c\udf89\ud83e\udd73\ud83d\udcb0"
  },
  {
    "title": "Undergraduates with family income below $200k will be tuition-free at MIT (news.mit.edu)",
    "points": 285,
    "submitter": "gnabgib",
    "submit_time": "2024-11-20T16:59:33 1732121973",
    "num_comments": 199,
    "comments_url": "https://news.ycombinator.com/item?id=42195895",
    "comments": [
      "This is a great step in the right direction. I can't speak directly for MIT, but there are issues with how these programs don't apply to parents with small family businesses. My parents had a small business, with my father taking home a salary of $XX,XXX. Duke University used the business assets to determine the EFC (expected family contribution) of literally 90% of the salary. Essentially saying to sell off the family business for the college fund, which was a non-starter.Small businesses are allegedly the backbone of America, and I feel these tuition support programs overlook this segment of the middle-class.\n \nreply",
      "I can understand why they might do this. Many people who own a small business underpay themselves significantly and use the extra funds on the business to build up assets. This defers taxes and allows the funds to be reinvested without tax. They might even take out loans on those business assets. The same way the wealthy will pay themselves a tiny salary and just live off the asset value of their stock. Someone who owns their own business could also easily drop their salary significantly for the year prior to applying to college.\n \nreply",
      "As an owner of a small family business, I have to pay close attention to making sure my salary and that of my other family members involved is \"generally commensurate with our duties\" or the IRS will be up my backside pretty quick.  I obviously try to minimize it as much as possible, but if you drop it to something insignificant and the IRS notices, they'll adjust your income and expenses reported to reflect your non-compliance with tax code.\n \nreply",
      "From what I've observed (worked at a few small businesses before I got an office IT job, and even then...) it's about figuring out enough 'fringe benefits' and/or 'explanations' that are plausible with your CPA. e.x. how many profitable company car buy/leases can you do, a good explanation of why you are saving that money as a small or privately owned company (i.e. saving for expansion via acquisition/etc, but you have to follow through and then sell the results ASAP)You can't have it be 'insignificant' salary but you can do plenty of fringe benefits or long term profiteering via acquisition as mentioned.I will say, ironically, the small business owners like that were great to work for, although they were paranoid, they were often generous to employees.OTOH, at the computer shop there was a standing rule that if the CPA brought his computer in it was 100% priority and we treated him better than the one org that was 10-30% (depending on year) of our entire gross income...EDIT: To be clear, it's complicated, https://news.ycombinator.com/item?id=42199534 is a good explanation of where I sit overall.\n \nreply",
      "My understanding is that the IRS attitude toward this depends on the exact tax status of your small business. The approach you describe reflects an S corporation, which is nowhere near always the right choice for every small business that sends their children to MIT: as one counterexample, if the parents' business is in NYC, the city's General Corporation Tax (which applies to S corporations) is often more punishing than its Unincorporated Business Tax, and therefore many NYC small businesses organize as LLCs not taxed as a corporation if they even choose to create a separate legal entity at all.For every type of business entity other than an S corp or an LLC electing to be taxed as one, the IRS either doesn't care about any notion of reasonable salary or - in the case of a C corp or an LLC electing to be taxed as one - actually wants it to be as low as possible (whereas the owner wants to maximize it).\n \nreply",
      "As a former owner of a small business I can tell you that what my accountant told me about that is that as long as the salary is over the Social Security max, (which is about $160K) the IRS doesn't really care.\n \nreply",
      "Will they actually though?You hear a lot of anecdotes both ways and it is quite hard to get a good picture of the real situation.\n \nreply",
      "Keep a weather eye out with that line of scepticism. One of the opinions down that path is that MIT should adjust its admission procedures to filter out the children of honest businesspersons.\n \nreply",
      "> the IRS will be up my backside pretty quickHow many times were you audited before learning this valuable lesson?\n \nreply",
      "> This defers taxes and allows the funds to be reinvested without tax.All business funds are re-invested without tax, this is actually a good thing. Also for the majority of business owners taking a loan against your assets to pay yourself is a terrible idea, yes it may defer taxation but that tax will still come due and now you have to pay interest.> Someone who owns their own business could also easily drop their salary significantly for the year prior to applying to college.This could be a problem but i think the amount of difference this would make would be negligible - most people don't plan like this. You could also emancipate your 17 year old or have them live independently for a period of time (my friend actually deferred his entry and worked for a year in order to get a full ride)\n \nreply"
    ],
    "link": "https://news.mit.edu/2024/mit-tuition-undergraduates-family-income-1120",
    "first_paragraph": "Suggestions or feedback?\n    Images for download on the MIT News office website are made available to non-commercial entities, press and the general public under a \n    Creative Commons Attribution Non-Commercial No Derivatives license.\n    You may not alter the images provided, other than to crop them to size. A credit line must be used when reproducing images; if one is not provided \n    below, credit the images to \"MIT.\" \n  \n\n\n\n\n\n\n\n\n\n\n\n\nPrevious image\nNext image\n\n\n\n\n\n\n\n\n\n\n\n\n\nUndergraduates with family income below $200,000 can expect to attend MIT tuition-free starting next fall, thanks to newly expanded financial aid. Eighty percent of American households meet this income threshold.And\u00a0for\u00a0the 50 percent of American families with income below $100,000, parents can expect to pay nothing at all toward the\u00a0full cost of their\u00a0students\u2019 MIT education,\u00a0which includes tuition as well as housing, dining, fees, and an allowance for books and personal expenses.This $100,000 threshold is up f",
    "summary": "MIT heroically decides to give free lessons in elitism to anyone with parents raking in less than an embarrassingly bourgeois $200,000 per year. Hacker News humbly brags about personal trials and tribulations regarding the exploitation of small business loopholes and the IRS tango. Commenters engage in an epic battle to showcase their own financial acumen, mostly proving that they should stick to their day jobs. Meanwhile, actual potential students worry quietly about whether they'll ever need to know what an S corporation is just to study Physics."
  },
  {
    "title": "How good are American roads? (construction-physics.com)",
    "points": 158,
    "submitter": "chmaynard",
    "submit_time": "2024-11-20T14:45:23 1732113923",
    "num_comments": 356,
    "comments_url": "https://news.ycombinator.com/item?id=42194327",
    "comments": [
      "> Interestingly, in all cases urban roads are worse quality than rural roads, presumably because they see higher traffic than rural roads.There's more infrastructure under urban roads. Crews come in to fix some utility, shred a section of a lane, patch it poorly with dissimilar materials, and leave.\n \nreply",
      "In New York, companies doing road work are required to leave a small plastic circle embedded in their patch that can be used to identify who did the work. They seem to most often be blue though I\u2019m not sure the color is a requirement. Once you see it, you\u2019ll notice them everywhere.\n \nreply",
      "This happens CONSTANTLY in Atlanta. They'll spend a bunch of money fixing a road, then a month later Public Works digs a huge hole and leaves a steel plate on it for a year, then patch it with either concrete that is an inch or two below the rest of the surface, or they don't pack the earth they put back and in 3 months the patch has sunk into a new pothole in a brand new road. The city has been trying to force public works to go do those things BEFORE road projects, but it's an uphill battle.\n \nreply",
      "This happens in other countries too. Some people theorize that it's done because of internal rivalries between dependencies/political factions, but I suspect local governments are just inept at logistics.\n \nreply",
      "Its also a difficult problem. They need the right digger and the right crew at the right time and possibly the right weather to get the job done. Many times there will be weeks of juggling around schedules and suddenly the digging started three weeks after the road was finished\n \nreply",
      "Let me ask you: how many buildings collapsed during the reign of Hammurabi?\n \nreply",
      "I.. I have no idea. I don't even know who Hammurabi is.Is there a point you're trying to make? If so, care to enlighten us without assuming we all have history degrees?\n \nreply",
      "Hammurabi is an ancient ruler of Mesopotamia/Babylon who is famous for establishing a written code of laws, of which copies inscribed in steles have survived to this day). I don't know of it's the earliest example of a written legal code but certainly one of the earliest that we have a record of.Among these laws were civil penalties for builders who performed shoddy workmanship:> If a builder constructs a house for a man but does not make it conform to specifications so that a wall then buckles, that builder shall make that wall sound using his own silver.By the way, the Romans also had building codes, and engineers who built bridges and roads were liable for the durability of those structures, thus a tradition of over-engineering.\n \nreply",
      "> 229 If a builder builds a house for someone, and does not construct it properly, and the house which he built falls and kills its owner, then that builder shall be put to death.http://faculty.collin.edu/mbailey/hammurabi%27s%20laws.htm\n \nreply",
      "He's a rather famous chap: https://en.wikipedia.org/wiki/HammurabiRegardless, I suspect there's a point being made about the timeless ineptitude of bureaucracy (even if I don't agree with it\u2014some cultures are notably more competent at managing logistics of public works than other are).\n \nreply"
    ],
    "link": "https://www.construction-physics.com/p/how-good-are-american-roads",
    "first_paragraph": "",
    "summary": "Today on <em>construction-physics.com</em>, another groundbreaking expos\u00e9 reveals the shocking truth: roads used by cars are sometimes bad! The insightful gem that urban roads suffer due to more traffic and reckless utility patch-work is sure to ignite a spark in the ongoing dumpster fire of urban planning discussions. Commenters, armed with the unparalleled wisdom of noticing blue plastic circles and comparing modern roadwork policies to those from the era of Hammurabi, dive deep into how not to manage public works. A grand melee of anecdotes ranging from Atlanta's pothole gardens to the fabled steel plate lakes of city streets, all while hilariously failing to address why their latest hole-patching binge is about as effective as screaming at concrete to harden faster. \ud83d\udea7\ud83d\udd73\ufe0f\ud83e\udd21"
  },
  {
    "title": "Bird flu in Canada may have mutated to become more transmissible to humans (theguardian.com)",
    "points": 40,
    "submitter": "amichail",
    "submit_time": "2024-11-20T23:11:36 1732144296",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42199112",
    "comments": [
      "I wonder if we'll be firing any more pandemic surveillance staffers like we did last time[1].[1] https://www.reuters.com/article/world/exclusive-us-slashed-c...\n \nreply",
      "The USA re-elected the same idiot that worsened the outcome in US and globally. This time he is planning to install a cabinet that has no interest in science backed policy. The person to be DHHS secretary is a known anti-vaxxer.\n \nreply",
      "> The USA re-elected the same idiot that worsened the outcome in US and globally.This seems a-historic to me. The start of the lockdown in the US was as firm as Canada and most other western countries. Trump also funded Operation Warp Speed. Not saying he handled it perfectly, but as I recall the US had tests and vaccines available before we Canucks did.The real problem is that the political capital needed to get people to agree to something like lockdowns or wearing masks was all spent in 2020. I don't think any administration would be able to make it happen again without heavy use of force and considerable risk of social upheaval.\n \nreply",
      "He did the one thing that was unambiguously, knowably, certainly incorrect, which was to slow down testing: https://youtu.be/Ti4sSRonNwY?t=27And he did it because he didn't like \"his numbers.\"Lots of mistakes were made, some less excusable or more harmful than others, but this wasn't \"a mistake.\" This was inarguably and knowably a selfish decision to put self above millions of Americans.> The real problem is that the political capital needed to get people to agree to something like lockdowns or wearing masks was all spent in 2020Let's not act like this attitude emerged out of thin air. Trump also had an opportunity to bring Americans together against a common threat, and he decided to turn it into the cultural catastrophe that you're now supposing was inevitable.\n \nreply",
      "Reports like this remind me of very early COVID days. And USA just elected a POTUS that did a shit job of getting us through that same pandemic. With the cabinet that he has (rfk jr, oz\u2026), let\u2019s just hope these are truly fringe cases and doesn\u2019t lead to an outbreak\n \nreply",
      "Don't worry, we're unlikely to know whether that's the case anyway. All we'll have is word of mouth to augment suppressed (or never collected) data, which is just the same as the problem not existing!https://youtu.be/Ti4sSRonNwY?t=27\n \nreply",
      "Let this post make you notice they have been working on an mRNA payload that supposedly provides immunity against this already, however they were working on a self-replication feature but they merged that branch beforehand so this new version will have multiple new features.\n \nreply"
    ],
    "link": "https://www.theguardian.com/world/2024/nov/19/bird-flu-cases-mutation-canada",
    "first_paragraph": "Scientists are racing to understand what a hospitalized teen\u2019s case of bird flu may mean for future outbreaksThe teenager hospitalized with bird flu in British Columbia, Canada, may have a variation of the virus that has a mutation making it more transmissible among people, early data shows \u2013 a warning of what the virus can do that is especially worrisome in countries such as the US where some H5N1 cases are not being detected.The US \u201cabsolutely\u201d is not testing and monitoring bird flu cases enough, which means scientists could miss mutated cases like these, said Richard Webby, a virologist at St Jude children\u2019s research hospital\u2019s department of infectious diseases.\u201cWe need to be following this as closely as we can. Any advanced warning we can get that there\u2019s more viruses making these types of changes, that\u2019s going to give us the heads-up,\u201d Webby continued.The Canadian teen first developed symptoms on 2 November and was hospitalized at the British Columbia children\u2019s hospital on 8 Nove",
    "summary": "**Bird Flu Boogaloo: Canada Edition** \ud83e\udda0\ud83c\udde8\ud83c\udde6\n\nBrace yourselves, pandemic enthusiasts! The latest teen sensation isn't a TikTok dance but bird flu caught in British Columbia, possibly mutating to become the next big hit among humans. Scientists, in their eternal quest to remind us they're still relevant, are all flustered and fluttery, warning that the U.S. sucks at testing \u2014 shocking news if you've just emerged from a cave. Comment sections are afire with armchair virologists and doomsday preppers making a seamless shift from political pundits to infectious disease experts, because, apparently, Googling symptoms now equals a PhD. And yes, in the midst of it all, we are reminded just how unprepared everyone is \u2014 just in case you missed that memo during COVID-19's world tour."
  },
  {
    "title": "Europe's Internet resilience mitigates impact of submarine cable cuts (cloudflare.com)",
    "points": 88,
    "submitter": "hampus",
    "submit_time": "2024-11-20T22:10:31 1732140631",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42198635",
    "comments": [
      "One important question that I'm unclear on is how long it takes to fix one of these cables. If it takes months then that is quite a wide window in which an attacker could incrementally take down cables.\n \nreply",
      "They could even blow up all cables at once. Maybe the explosives have already been placed.\n \nreply",
      "Generally it can be fixed in days. They raise it from the sea floor and splice in a new cable section.\n \nreply",
      "Crazy that you can splice optical cable..\n \nreply",
      "They actually have very cool devices that will automatically align and fuse two fibers and estimate the loss of the bond.https://www.youtube.com/watch?v=JP_C0XLLyR0\n \nreply",
      "Today, we're going to talk to John Owens and learn about the process of splicing fiber: https://www.youtube.com/watch?v=1zN20ZVInfU\n \nreply",
      "I mean\u2026 they get terminated somehow, right?\n \nreply",
      "True, but splicing without leaving behind a powered repeater is different from the final termination with active electronics on the end.It's pretty cool tech\n \nreply",
      "This is a great video on undersea cables https://www.youtube.com/watch?v=AFt9le2ytW0\"Sabatoge\" and repair is discussed at 11:45\n \nreply",
      "In this particular case, it seems like the attackers were trying for plausible deniability (making it look like an accident with an anchor). A comprehensive series of \"accidents\" wouldn't fit that goal.(And if they decide they don't care about plausible deniability, they could use sub-deployed timed mines to take out every cable at once.)\n \nreply"
    ],
    "link": "https://blog.cloudflare.com/resilient-internet-connectivity-baltic-cable-cuts/",
    "first_paragraph": "",
    "summary": "Behold, the internet once again proves its invincibility against cable-cutting supervillains, thanks to European resilience, or so Cloudflare claims. Cue a parade of armchair experts in the comments, pondering how long until an attacker turns the ocean floor into a high-stakes game of Minesweeper. One hero, dazzled by the magic of optical cable splicing, gets a crash course via YouTube links as though they\u2019re collecting DIY badges on how to single-handedly rebuild the internet. Meanwhile, conspiracy theories about sabotaged cables flourish, because why blame poor infrastructure when you can imagine underwater espionage thriller scenarios? \ud83d\udd75\ufe0f\u200d\u2642\ufe0f\ud83d\udca5"
  },
  {
    "title": "Does the Internet Route Around Damage? \u2013 Baltic Sea Cable Cuts (ripe.net)",
    "points": 36,
    "submitter": "voytec",
    "submit_time": "2024-11-20T18:30:59 1732127459",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42196794",
    "comments": [
      "By the way, the original adage from John Gilmore (\"The Net interprets censorship as damage and routes around it\") was referring to a behavior of Usenet rather than of the Internet. In particular, if articles didn't reach a node by one path, the node would still accept that they were missing (according to Usenet routing rules) and accept those articles from a different path. Thus, one could not prevent Usenet messages or newsgroups from reaching most of Usenet merely by deleting or not forwarding them on a single node. Another way of putting this is that the connectivity of Usenet was (in general though not everywhere) a web rather than a tree, and the Usenet software didn't assume that messages had to be forwarded along some particular path, if another path was available.As with Jon Postel's maxim (https://en.wikipedia.org/wiki/Robustness_principle) people have also subsequently applied this to human behavior, not just the behavior of particular software.There were ultimately more technically sophisticated means of censorship available on Usenet that were somewhat more effective.\n \nreply",
      "Related: https://news.ycombinator.com/item?id=42198635\n \nreply",
      "Why are they giving free analysis to the enemy?\n \nreply",
      "That\u2019s just a necessary hazard that comes with providing free analysis to the public.\n \nreply"
    ],
    "link": "https://labs.ripe.net/author/emileaben/does-the-internet-route-around-damage-baltic-sea-cable-cuts/",
    "first_paragraph": "Want to contribute? Learn how\n            Based in Amsterdam, NL\n          \n        I'm a system architect/research coordinator at the RIPE NCC, where I work in the science group. I'm a chemist by training, but have been working since 1998 on Internet related things, as a sysadmin, security consultant, web developer and researcher. I am interested in technology changes (like IPv6 deployment), Internet \u2026 More\n9 min readThis week's Internet cable cuts in the Baltic sea have been widely reported, even as attempts to understand their cause and impact are ongoing. We turn to RIPE Atlas to provide a preliminary analysis of these events and examine to what extent the Internet in the region is resilient to these events.On Sunday 17 November, the BSC East-West Interlink Internet cable connection between Sweden and Lithuania stopped working. The following day, the C-Lion1 Internet cable connecting Finland with Germany was also cut. Investigation into what could have caused these two cables - whi",
    "summary": "In a thrilling development that nobody outside a small cadre of network engineers genuinely understands, the RIPE Atlas team heroically battles the ***mysterious*** severing of some underwater Internet cables in the Baltics, armed only with graphs and IP addresses. The only thing rivalling the complexity of these events is the half-baked expertise of the comment section, where armchair analysts peddle conspiracy theories alongside misunderstood networking principles. Does the Internet route around damage? Sure, but the real question is: can it route around the sheer amount of uninformed commentary erupting every time a cable gets a scratch? \ud83d\udce1\ud83c\udf10\ud83d\udd2a"
  },
  {
    "title": "La Basilica Di San Pietro (microsoft.com)",
    "points": 120,
    "submitter": "geox",
    "submit_time": "2024-11-20T15:15:16 1732115716",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=42194587",
    "comments": [
      "This brings back memories of Microsoft's acquisition of SeaDragon. At the time they had a really compelling demo (at least for me) of reconstructing 3D locations based on a smatterings of photos.https://en.wikipedia.org/wiki/Seadragon_Softwarehttps://www.youtube.com/watch?v=IFSsTwXLqsc\n \nreply",
      "Thanks for the memory - definitely one of the coolest demos I'd ever seen.Any idea how accurate the pitch was compared to the reality?\n \nreply",
      "At the time I really thought that was going to be the next Street View.Maybe with WebGL and Gaussian Splats that can still be the case. But it\u2019s also a ZIRP kind of project. Awesome, but what\u2019s the business model?\n \nreply",
      "Seeing a digital version of it in such detail only further reinforces how important it is to experience it in person.Few sights of man-made things have instilled as much awe in me as La Basilica Di San Pietro and most of them are also in Rome (namely the Pantheon and Moses @ Basilica di San Pietro in Vincoli).\n \nreply",
      "You can't understand the scale of it until you experience it in person. The way I thought of it was that it is a cathedral made for giants.\n \nreply",
      "It's also a symbol of all the money and gold, the real values and the secrets of the church...If God exists, you think he would want you to sacrifice and spend it all on gold and salaries of locals ?\n \nreply",
      "Clearly yes if we go by the Bible. Then we should be happy to get away with just gold and labor and not our children like Isaac.\n \nreply",
      "Exactly. And it was a great marketing tool for catholicism, imagine simpler (even if rich) folks came to visit the pope and experienced this marvel of medieval construction. You feel utterly insignificant on purpose, feeling weak and in presence of something much larger is an easy way to more faith, a truth valid for all humans across all time.But to me, despite all of this, there was a lot of sadness in that experience - because you know how desperately poor common folks were, how instead of building such status mega symbol they could have done some proper good. But not for church of that era, it was busy fighting for power and money of that world and trying to show how above everybody else they were.You can see miniature scale of this in literally every (also non-) older European village or town - religious buildings have received by far the most funding and care, sometimes overshadowing kings castles themselves. Cathedrals were always built to impress masses, and this one is just on top of the game, by huge margin for good reasons I believe.\n \nreply",
      "> But to me, despite all of this, there was a lot of sadness in that experience - because you know how desperately poor common folks were, how instead of building such status mega symbol they could have done some proper good.Have you considered the idea that these could be considered jobs programs? It took a lot of masons, carpenters, ox/horse handlers, rope makers,  quarrymen, etc, to run the supply chain for building this over the course of many, many decades. Just moving the obelisk to its current location took hundreds of men:* https://en.wikipedia.org/wiki/Vatican_obelisk#HistoryFurther, now, even centuries later, all of this architecture and art is helping the local with a fairly vibrant tourism industry.Beauty, in addition to being a good in itself:* https://en.wikipedia.org/wiki/Transcendentalsalso has practical benefits.> But not for church of that era, it was busy fighting for power and money of that world and trying to show how above everybody else they were.The other option was to be rolled over by secular powers (princes, kings, emperors). If you think politics is nasty now, it was a (often literal) blood sport back in the day.\n \nreply",
      "You have it all wrong. These buildings were built a) to glorify God, and b) because humans love to have beautiful things. And we are all much, much better off for it. These old, beautiful buildings are one of the great treasures that our ancestors left us. We should be thanking them, not criticizing them.\n \nreply"
    ],
    "link": "https://unlocked.microsoft.com/vatican/",
    "first_paragraph": "",
    "summary": "In an earth-shattering reveal of digital nostalgia, Microsoft nostalgics crawl out of the woodwork on microsoft.com to wax poetic about the software behemoth's historic attempt to make 3D reconstructions of photographs, this time featuring the epic La Basilica Di San Pietro. Commentators trade memories of this tech relic like forbidden lore, with one free spirit wondering if WebGL and Gaussian Splats might resurrect it from oblivion. Meanwhile, tourists trapped in philosophical reminiscence insist you need to <em>\"be there, man\"</em> to truly <em>grasp</em> the massive scale of religious excess and gold-lined corridors, while another adds a spiritual twist, musing if the Almighty's blueprint for humanity might be etched in precious metals and historical grandeur. Yet, amidst exaltations of its splendor are whispers of the deep sadness and squalor overshadowed by monumental cathedrals, prompting a practical soul to remind everyone else that, yes, even in medieval times, job creation was a thing, maybe. Gods and tech unite in this bittersweet symphony of awe and 404 errors. \ud83d\udcbe\u26ea\ud83d\udd0d"
  },
  {
    "title": "Between the Booms: AI in Winter \u2013 Communications of the ACM (acm.org)",
    "points": 49,
    "submitter": "rbanffy",
    "submit_time": "2024-11-20T17:11:14 1732122674",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=42196037",
    "comments": [
      "every other article these days on this site is about AI. And it's incredibly tedious and annoying.Isn't it enough that clueless marketers who get their Tech knowledge from businessinsider and bloomberg are constantly harping on about AI.Seems we as a community have resigned or given up in this battle against common sense. Maybe long ago. Still there should be some form of moderation penalizing these shill posts that only glorify AI as being the future, ... the same way that not everything about crypto or the blockchain ended up on the FP. Seems with AI we're looking the other way and are OK with it?Or maybe it's me.\n \nreply",
      "How does any of that apply to this particular article? Isn't a broader historical perspective exactly what's needed if you want to be free from the immediate hype cycle?One of my biggest irritations with HN comment sections is how frequently people seem to want to ignore the specific interesting thing an article is about and just express uninteresting and repetitive generic opinions about the general topic area instead.\n \nreply",
      "It's you.The AI discussions can indeed be repetitive and tiresome here, especially for regulars, but they already seem to be downweighted and clear off the front page quite fast.But it's a major focus of the industry right now, involving a genuinely novel and promising new class of tools, so the posts belong here and the high engagement that props them up seems expected.\n \nreply",
      "> It's you.Not just him.> But it's a major focus of the industry right now, involving a genuinely novel and promising new class of tools, so the posts belong here and the high engagement that props them up seems expected.In your opinion (and admittedly others), but that doesn't make the overhype any less tiresome. Yes it is novel technology, but there's alway novel technology, and it isn't all in one area, but you wouldn't know it by what hits the front page these days.Anyway, it's useless to shake fists at the clouds. This hype will pass, just like all the others before it, and the discussion can again be proportional to the relevance of the topic.\n \nreply",
      "I don't know about the professional professionals, but as a science professor, I have to wear a lot of hats, which has required me to gain skills in a multitude of areas outside my area of deep expertise.I use Claude and Chatgpt EVERY DAY.Those services help me run out scripts for data munging, etc etc very quickly. I don't use it for high expertise writing, as I find it takes more than I get back, but I do use it to put words on a page for more general things. If your deep expertise is programming, you may not use it much either for that. But man oh man has it magnified my output on the constellation of things I need to get done.What other innovation in the last decade has been this disruptive? Two years ago, I didn't use this. Now I do as part of my regular routine, and I am more valuable for it. So yes, there is hype, but man oh man, is the hype deserved. Even if AI winter started right now, the productivity boom from Claude level LLMs is nothing short of huge.\n \nreply",
      "> I use Claude and Chatgpt EVERY DAY.We use several tools derived from \"AI research\" every single day in our lives.They are tools and, at every cycle, we gain new tools. They hype is the issue.\n \nreply",
      "Personal anecdotes on the benefits of using LLMs don't address complaints about tedious articles over-marketing AI tech. That LLMs provide benefits is well known at this point, it doesn't mean we can't recognize the latest hype cycle for what it is. There's a long list of previous technologies that were going to \"change everything\".\n \nreply",
      "Yes, of course, but they almost always did too. Internet. Mobile Phones.I think the issue is whether you think that HN posts on AI are basically marketing, or about sharing new advances with a community that needs to be kept on top of new advances. Some posts are from a small startup trying something, or from a person sharing a tool. I think these are generally valuable. I might benefit from a RAG, but won't build one from scratch. In terms of this crowd, I can't think of advances that in other areas that are as impactful as machine learning lately. Its not like crypto. Crypto was an interesting innovation, but one in which mostly sought a market instead of the a market seeking an innovation. There is no solid \"just use a database\" analogical response here like was the well used refrain to attempt at practical uses of cryptocurrency tech. Sure, AI companies built on selling something silly like \"the perfect algorithm to find you a perfect date!\" is pure hackery, but even at the current level of llm, I don't think we are any where near understanding its full potential/application. So even if we are on the brink of an AI winter, its in the Bahamas.Also, looking at the most popular stories with AI in the title over the last month show quite a varied array of topics. https://hn.algolia.com/?dateRange=pastMonth&page=0&prefix=fa...If HN readers feel that AI-related articles are showing up too much, then I'd say it would be on them to find articles on topics that interest them and post them to HN.\n \nreply",
      "surely it's not hype if it works?\n \nreply",
      "> It's you.I disagree.\n \nreply"
    ],
    "link": "https://cacm.acm.org/opinion/between-the-booms-ai-in-winter/",
    "first_paragraph": "",
    "summary": "In the latest farce from <em>Communications of the ACM</em>, AI has been doomed to eternal winter, inducing both yawns and existential dread in readers who thought they\u2019d seen the last of grandiose tech cycles. Commenters, in their usual display of baffling wisdom, engage in a tired merry-go-round of \u201cAI is overhyped but also revolutionary but also, did I mention, quite overhyped?\u201d One gem of a comment suggests that if only this were a historical piece, maybe\u2014just maybe\u2014we\u2019d escape the AI hype. Meanwhile, another brave soul uses the article as an opportunity to wax lyrical about their daily rendezvous with AI tools, defiantly mistaking personal anecdotes as a shield against the barrage of AI marketing fatigue. \ud83d\ude44"
  },
  {
    "title": "A Second Search for Bash Scripting Alternatives (monzool.net)",
    "points": 9,
    "submitter": "thunderbong",
    "submit_time": "2024-11-18T15:08:25 1731942505",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=42172978",
    "comments": [
      "I hate bash, but it's always the first thing I start scripting in when I need to glue some things together. I tend to go in the following order as complexity and a need for robustness increases.1. Bash (or ysh, which I do prefer but isn't as available)2. Python, using the `sh` package as needed. It's been great for upgrading shell scripts, and `sh` is really nice to use.3. Rust, usually. That's my personal language of choice for \"real\" projects.I have a number of projects at each stage actually, though most of the things I'd call a real \"project\" with it's own repo end up as Rust projects.\n \nreply",
      "Perl excels at most of their list, though I understand why they aren't considering it.  Just funny that you look at the list and one language in particular pops to mind.\n \nreply",
      "Unpopular opinion but powershell, available on Linux, supports all of the things this article wanted to do out the box.\n \nreply",
      "It does, but it's so darn weird. Can we have another flavour of Powershell but with some other language hooked up to its dotnet underpinnings? Like I dunno, I would even take Lua over the weird syntax of PS.\n \nreply",
      "Indeed, it's very weird. It really took much more time than I expect to learn Powershell, even with many years of coding experience. But I'm totally happy now.\n \nreply",
      "PowerShell is sort of two languages, and it looks weird because they are often used together. But if you see them separate first, there isn't much there that is surprising. I do somewhat share your concern about it being built on dotnet, but one advantage is you have access to everything in dotnet, including building GUI apps (Windows only). Though, at that point the syntax does get kinda weird.\n \nreply",
      "Oh, the dotnet integration is what I actually like about Powershell. It's very useful even on Linux.\n \nreply",
      "Likewise, its a superpower to be able to integrate with a dll that wasn't developed with PS1 in mind\n \nreply",
      "One of the requirements of the author was something that could work on embedded-sized resources.\n \nreply",
      "I'm fluent in bash but I have to say it is the jankiest, messiest language I've ever used.  I can't believe another default hasn't totally obliterated it into obsolescence.  Maybe because it is so ubiquitous people are afraid of all the work required to move.  Wait, that's me.\n \nreply"
    ],
    "link": "https://monzool.net/blog/2024/07/14/a-second-search-for-bash-scripting-alternatives/",
    "first_paragraph": "Monzool's Personal PublishingSHELL SCRIPTING IS something most programmers will encounter often \u2013 especially if doing dev-ops, automation and general Linux work. Unfortunately we are mostly stuck with bash. There surely must be better alternatives\u2026I have been in search for a bash replacement before. My conclusions was that I would try out: scsh, luash and mruby. I\u2019m addressing that experience in Addendum Take 1,Since my last endeavor into finding a bash alternative, I\u2019ve seen my work-life distance myself more and more from the small embedded devices, and move into higher level domains of JavaScript, Python and C#. In the environments where these run, the restrictions that apply to small embedded devices are not really applicable, and the options for scripting is much more open. Now I find myself back in the embedded world, and thus I figured it was time for another round of looking at bash alternatives. A lot of interesting stuff has happened in the programming language world these las",
    "summary": "In a riveting sequel to \"Hunting for not-Bash,\" a blog flits through the forbidden forests of alternatives to bash scripting, because <i>change is good</i>, or so our interlocutor insists. Monzool's not-so-monumental insight has resulted in another epoch-making blog post, daring to venture where few have the bandwidth to care. Comments meander through the usual suspects: Python, Rust, and the usual grumbling about PowerShell's esoteric charm - offering a veritable *smorgasbord* of scripting sass and partially rehashed wisdom \ud83d\ude44. In the end, everyone agrees bash is terrible, but like that old, uncomfortable couch nobody wants to move, it seems destined to irksomely outstay its welcome."
  }
]