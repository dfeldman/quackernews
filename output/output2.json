[
  {
    "title": "I mapped almost every USA traffic death in the 21st century (roadway.report)",
    "points": 112,
    "submitter": "Bencarneiro",
    "submit_time": "2024-07-19T23:16:46",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=41012443",
    "comments": [
      "I used to be a volunteer firefighter and I see some of the fatalities (but not all) on this map. Looking at one of them some of the information is quite accurate (type of accident, what caused it, age of person) while other information is not at all accurate (number of people in the car, if a seatbelt was in use). It's curious how some fairly important pieces of data can be quite wrong.\n \nreply",
      "Looks like where I live, deaths are more closely associated with big, wide, fast roads.It's ironic that drivers get frustrated by smaller, narrower streets as not feeling very safe, but that uncomfortable feeling 1) slows people down and 2) keeps them on their toes in terms of looking out for hazards rather than feeling ok with driving fast and not paying as much attention.\n \nreply",
      "Are you weighing the deaths by use of the road. Otherwise it's not representative of danger level right\n \nreply",
      "To me the comment spoke to our criminal lack of intelligent road design. It\u2019s well known through multiple studies that road design impacts how fast people drive far more than posted speed limit signs. If we actually cared about road safety, we would design roads to be more safe and not just design a road that is comfortable to drive 60mph on and put up a 25mph speed limit. When you want slower speeds you need to make lanes more narrow. Add obstacles along the side of the road so it doesn\u2019t feel so open. Add medians as areas where pedestrians have a refuge when daring to cross a place designed for vehicles. Add chicanes and bollards to force speed compliance in especially dangerous areas. There seems to be almost none of this happening in most places in the US that I have visited.\n \nreply",
      "We also could largely solve this problem with technological enforcement but people really hate that. If we made both the financial penalties for speeding and the probability of being caught sufficiently high, we could practically eliminate it overnight.\n \nreply",
      "What are you trying to say?\n \nreply",
      "GP is describing traffic calming road design. Where planners make roads purposefully feel less safe in certain neighborhoods because that statistically makes them safer per mile driven. A common example here in SF is to add unnecessary bends to an otherwise straight alley. This stops people from speeding right through a residential area because it's straight and empty.An example you may have seen in more rural areas is a straight road with an unnecessary curve before a stop sign or before entering a town. This forces you to slow down in a way that a speed limit doesn't.https://globaldesigningcities.org/publication/global-street-...\n \nreply",
      "Speed and convenience also matters. I like big, fast, and wide roads because they let me and many others get to where we want to go quickly. It\u2019s a trade off. We shouldn\u2019t let \u201cthink of the children\u201d safetyism decide what the balance is, since that line of thinking is extremist and does not consider what is at stake on the other side of the argument. Efforts to eliminate every last death on streets are a waste of time since we\u2019ll never achieve perfection and roads are very safe already. The road diets made under that unrealistic goal are simply making everyone\u2019s lives worse by causing us to spend more time on the roads in traffic.\n \nreply",
      "Traffic deaths are quite literally one of the two leading causes of death of children in the United States, so in this case, yeah, actually thinking of the children makes some sense.\n \nreply",
      "This is great!\n Plans for any filters?For example, I can see the death in front of my house from a year ago, which was the driver suffering a heart attack while driving. He was the only victim and it wasn\u2019t the crash that killed home.Would love to be able to compare areas for things like:- DUI - speeding/reckless driving - cycling victims - pedestrian victims - multiple vs single vehicle - medical cause\n \nreply"
    ],
    "link": "https://roadway.report",
    "first_paragraph": "",
    "summary": "**n-gate.com presents: A Map To Nowhere**\n\nIn a world where data means everything except when it doesn't, someone decided to map every traffic fatality since Y2K using what appears to be a combination of Google Maps and a dartboard. Commentators, in an exemplary display of missing the point, focus their infinite wisdom on road widths and the philosophical depths of \"feeling safe\" while driving. As armchair urban planners wax poetic about speed bumps and chicane-induced nirvanas, one must wonder if any of these people have driven a car outside of a video game. \ud83d\ude97\ud83d\udca5 When questioned on data accuracy, the map maker might as well have said, \"Close enough for jazz,\" leaving the pedantic crowd to argue the finer points of traffic calming like medieval scholars debating angel pinhead occupancy rates."
  },
  {
    "title": "Multisatellite data depicts a record-breaking methane leak from a well blowout (acs.org)",
    "points": 122,
    "submitter": "belter",
    "submit_time": "2024-07-19T22:42:25",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=41012193",
    "comments": [
      "Better satellites and other aerial survey data has determined that oil and gas  related methane emissions are far, far higher than industry reports.  Everywhere independent researchers look along the production, transmission, distribution and end use pipeline they find more leakage than has been assumed because industry has provided the numbers the assumptions are based on for years.Along some particularly leaky production paths methane emissions are so great that the impact is greater than coal over 100 year timescale.  For example, some parts of NM Permian have a 9% (!) leakage rate.  When combusted methane releases about half the amount of CO2 that coal does.  The eGHG potential of methane is 20x CO2 over 100 year timescale, so you have to add 180% to the total GHG potential, making it 40% worse than coal w/o even considering other leakage along the pipeline.https://sustainability.stanford.edu/news/methane-leaks-are-f...\n \nreply",
      "In Massachusetts, Lost and Unaccounted for Gas (LAUG) is estimated per mile of pipe, rather than evaluated by regulators or even industry. It is a simple multiplication problem with little bearing on reality. Consumers bear the cost of LAUG while the utilities are guaranteed a 10% profit on their infrastructure expenses. This, along with subsidies for leak prone pipe replacement, leads to needless investment in outmoded fossil fuel infrastructure (i.e., pipe replacement) being prioritized over leak repair.\n \nreply",
      "Those 100 year timescale numbers are misleading as the impact is so front loaded.  They only make sense when talking about an emissions that are constant through long timescales.\n \nreply",
      "There is going to be a point in the climate change phenomenon where we have to start taking aggressive measures and actually go after the biggest polluters no matter what nation they hide behind. Especially considering there will probably be forces working to undermine all of these climate goals. Maybe the US could throw some of that military budget around and use Seal team sappers to disable these polluting industrial plants? Now before people get guarded at that idea, just consider the US already does the same to kill actual people with such operations. Merely disabling infrastructure not only has some precedent, but also seems far more benign to me.\n \nreply",
      "Ouch! They\u2019re estimating 131 kt of methane! That\u2019s equivalent to approx 3.93 Megatons of CO2 (in terms of its global warming impact over a century) or roughly equivalent to that of a small country like Iceland or Malta annually.\n \nreply",
      "3.93 megatons of CO2 is roughly equivalent to:  \u2022 About 149,714 short-haul flights, or\n  \u2022 About 37,429 long-haul flights.\n \nreply",
      "So a couple of days' worth?\n \nreply",
      "so what I am hearing is that short-haul flights are ~24% as far as long-haul flights.Weird use of segmented flight lengths as a comparator\n \nreply",
      "Take off, climb and circles before landng time use considerably more fuel than that of cruising time, so that needs to be considered. Also, as short haul fights generally don't climb as high, they lose the benefits of high altitude cruising.\n \nreply",
      "Short haul flights use proportionally more fuel per mile flown because taking off is very fuel intensive. That said, no idea what average value the GP comment is basing their numbers off of.\n \nreply"
    ],
    "link": "https://pubs.acs.org/doi/10.1021/acs.estlett.4c00399",
    "first_paragraph": "",
    "summary": "**Multisatellite Mayhem: A Methane Migraine**\nOn <em>acs.org</em>, the latest satellite sitcom unfolds starring a rogue methane leak so colossal it might just deserve its own reality TV series. Armed with exceptional aerial espionage capabilities, independent researchers have confirmed that the oil and gas industry's \"methane modesty\" is about as extensive as a politician\u2019s tax return. Cue an army of online commentators blending bleak environmental stats with pop culture references to propose SEAL team interventions on polluters and bizarre metrics comparing flight emissions. Apparently, global crisis analysis is now as simple as knowing the MPG of your rusty, trusty roadster. Will satellite snapshots save the day or just provide prime-time eco-entertainment? Stay tuned, keep scrolling, but maybe don\u2019t hold your breath\u2014unless you\u2019re near a methane leak."
  },
  {
    "title": "Garage: Open-Source Distributed Object Storage (deuxfleurs.fr)",
    "points": 10,
    "submitter": "n3t",
    "submit_time": "2024-07-20T00:40:31",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://garagehq.deuxfleurs.fr/",
    "first_paragraph": "An open-source distributed object storage service tailored for self-hostingMade for redundancyEach chunk of data is replicated in 3 zonesWe made it lightweight and kept the efficiency in mind:We ship a single dependency-free binary that runs on all Linux distributionsWe are sysadmins, we know the value of operator-friendly softwareWe do not have a dedicated backbone, and neither do you,\n              so we made software that run over the Internet across multiple datacenters\n          We worked hard to keep requirements as low as possible:\n        \n          We built Garage to suit your existing infrastructure:\n        \n          Garage implements the Amazon S3 APIand thus is already compatible with many applications.\n        \n          Garage leverages insights from recent research in distributed systems:\n        Garage has received funding from NGI POINTER (3 full-time employees for one year, in 2021-2022),\n          and from NLnet / NGI0 Entrust (1 full-time employee for one year, in",
    "summary": "Title: Hipster Sysadmins Rejoice: Garage, a Data Hoarder\u2019s Dream\n\nThe digital equivalent of throwing your data into three different sketchy garages across town has arrived, thanks to the folks at deuxfleurs. Behold Garage: an open-source marvel that assumes everyone is as enthusiastic about sysadmin minutia as the people who created it. No backbone? No problem! This lean, mean, data-storing machine will run happily over a patchwork of Internet connections, bound together by sheer hope and the kind of optimism that can only come from someone who has never experienced real network latency. In the comments, expect a circus of tech bros pitching Garage as the solution to problems you didn't know you had, seasoned with the obligatory one-upmanship on who can tweak it to run on the oldest Linux distro. \ud83c\udfaa\ud83e\udd13"
  },
  {
    "title": "The European Union must keep funding free software (public.cat)",
    "points": 50,
    "submitter": "tr4656",
    "submit_time": "2024-07-19T19:57:03",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=41010458",
    "comments": [
      "\"FOSS funding vanishes from EU's 2025 Horizon program plans\", 20 comments, https://news.ycombinator.com/item?id=41002044\n \nreply",
      "Even they only use free software as a fall back, that is a worth while investment.\n \nreply",
      "It would be interesting to see what they got out of the first \u20ac27 million they put into it.\n \nreply",
      "PyPy received an EU grant sometime in the late 2000s or early 2010s, although it had to be a different one. If I understood TFA correctly, NLnet is partially funded by this money? NLnet itself distributes money to very cool software things[1]\u2014some moonshots such as Spectrum[2], some very down-to-earth and usable ones such as Nitrokey[3]. A discussion[4] linked in a neighbouring comment also mentions Sourcehut and Bcachefs.[1] https://nlnet.nl/project/current.html[2] https://spectrum-os.org/[3] https://www.nitrokey.com/[4] https://news.ycombinator.com/item?id=41002044\n \nreply",
      "I wonder why the list of signatories at the bottom do not seem to include a single government (local or national).\n \nreply",
      "Governments need to band together and collaborate to develop software.But instead they tend to buy closed systems that are developed by the same companies churning out crud.\n \nreply",
      "Ideally, governments are competent.Realistically...competent governments are the exception.  And competent-at-long-term-technology-policy governments are virtually non-existent.\n \nreply",
      "I am not sure what to make of the EU\u2019s agenda on free software. On the one hand, we see provinces of some countries announcing open source adoption strategies. On the other hand, we see controversial regulation on things like AI that basically proposes to pull up the ladder and give the market to incumbents.\n \nreply"
    ],
    "link": "https://pad.public.cat/lettre-NCP-NGI",
    "first_paragraph": "ORThis is an alert area.",
    "summary": "In a stunning display of incompetence masked as strategy, the European Union debates whether to keep throwing coins into the bottomless pit of \"free software.\" In response, the genius commentariat of Hacker News whips into a frenzy, squabbling over the scraps of funding while nostalgically reminiscing about that one time PyPy got some cash - back in the mythical heydays of the early 2010s. Meanwhile, armchair policymakers bemoan the lack of government signatures like it's a high school yearbook, and others pontificate on the existential dread of possibly *gasp* having to endure competent governance. Can't wait for the next episode of \"Europeans Arguing Online.\" \ud83c\udf7f\ud83d\ude02"
  },
  {
    "title": "CrowdStrike Update: Windows Bluescreen and Boot Loops (reddit.com)",
    "points": 3848,
    "submitter": "BLKNSLVR",
    "submit_time": "2024-07-19T05:26:13",
    "num_comments": 3252,
    "comments_url": "https://news.ycombinator.com/item?id=41002195",
    "comments": [
      "Took down our entire emergency department as we were treating a heart attack. 911 down for our state too. Nowhere for people to be diverted to because the other nearby hospitals are down. Hard to imagine how many millions of not billions of dollars this one bad update caused.\n \nreply",
      "Yup - my mom went into the ER for stroke symptoms last night and was put under MRI. The MRI imaging could NOT be sent to the off-site radiologist and they had to come in -- turned out the MRI outputs weren't working at all.We were discharged at midnight by the doctor, the nurse didn't come into our exam room to tell us until 4am. I can't imagine the mess this has caused.\n \nreply",
      "A relative of mine had back surgery late yesterday. Today the hospital nursing staff couldn\u2019t proceed with the pain medication process for patients recovering from surgery because they didn\u2019t have access to the hospital systems.\n \nreply",
      "Jeez\n \nreply",
      "Hope she's okay. For better or worse, our entire emergency department flow is orchestrated around epic. If we can't even see the board, nurses don't know what orders to perform, etc.\n \nreply",
      "If it\u2019s so critical that nurses are left standing around clueless then if it goes down entire teams of people should be going to prison for manslaughter.Or, we could build robust systems that can tolerate indefinite down time. Might cost more, might need more staff.Pick one. I\u2019ll always pick the one that saves human lives when systems go down.\n \nreply",
      "Okay but that will affect hospital profits and our PE firms bought these hospitals specifically to wrench all redundancy out of these systems in the name of efficiency (higher margins and thus profit) so that just won't do.\n \nreply",
      "Another way to look at it is that you can have more hospitals using systems with a lower cost, thus saving more lifes comparing to only a few hospitals using an expensive system.\n \nreply",
      "I wish your mother recovers promptly. And I\u2019m glad she doesn\u2019t run on Windows. ;-)\n \nreply",
      "I am \"saving\" this comment :)... and seconding all the best wishes for the mother involved. Do get well.-\n \nreply"
    ],
    "link": "https://old.reddit.com/r/crowdstrike/comments/1e6vmkf/bsod_error_in_latest_crowdstrike_update/",
    "first_paragraph": "",
    "summary": "In today's breathtaking episode of \"How Could This Possibly Go Wrong?\", a CrowdStrike update turns into the digital equivalent of a hospital-acquired infection, knocking out entire emergency services and giving IT professionals and healthcare workers an unplanned stress test. Redditors, in their infinite wisdom and timely responsiveness, quickly turn a catastrophic software fiasco into an armchair blame game. Commentary ranges from heartwarming worries about mothers who thankfully don\u2019t run on Windows, to fierce debates about whether redundant systems are worth sacrificing hospital profit margins for. It's *just another day* on the internet, where empathy meets efficiency in a bluescreen of death. \ud83c\udfe5\ud83d\udcbb\ud83d\udca5\ud83d\udd27"
  },
  {
    "title": "What happened to BERT and T5? (yitay.net)",
    "points": 122,
    "submitter": "fzliu",
    "submit_time": "2024-07-19T18:54:26",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=41009803",
    "comments": [
      "Maybe in SOTA ml/nlp research, but in the world of building useful tools and products, BERT models are dead simple to tune, work great if you have decent training data, and most importantly are very very fast and very very cheap to run.I have a small Swiss army collection of custom BERT fine tunes that are equal or better than the best LLM and execute document classification tasks in 2.4ms. Find me an LLM that can do anything in 2.4ms.\n \nreply",
      "Latency, throughput and cost are still very important for many applications.Also the output of a purpose-built encoder model is preferable to natural language. Not only is it unambiguous, but scores are often an important part of the result.Last, if you need to get into some advanced methods of training, like pseudolabeling and semi-supervised learning, there\u2019s different options and outlets for utilizing real world datasets.That said, I\u2019m not sure there\u2019s much value in scaling up current encoder models. It seems like there\u2019s already a point of diminishing returns.\n \nreply",
      "Want to share your collection with the class so we can all learn? Seems useful.\n \nreply",
      "Product in stealth for a little bit longer, so can\u2019t say much. :-)\n \nreply",
      "What does your swiss army collection do?\n \nreply",
      "Document classification in highly ambiguous contextual space. Solving some specific large scale classification tasks, so multi million document sets.\n \nreply",
      "Yeah, pretty much. When you have 2b files you need to troll through good luck using anything but a vector database. Once you do a level or two of pruning of the results then you can feed it into an LLM for final classification.\n \nreply",
      "BERT didn\u2019t go anywhere and I have seen fine-tuned BERT backbones everywhere. They are useful for generating embeddings to be used downstream, and small enough to be handled on consumer (pre Ampere) hardware. One of the trends I have seen is scaling BERT down rather than up, since BERT already gave good performance, we want to be able to do it faster and cheaper. That gave rise to RoBERTa, ALBERT and distillBERT.T5 I have worked less with but I would be curious about its head to head performance with decoder-only models these days. My guess is the downsides from before (context window limitations) are less of a factor than they used to be.\n \nreply",
      "I tried some large scale translation tasks with T5 and results were iffy at best. I\u2019m going to try the same task with the newest Mistral small models and compare. My guess is Mistral will be better.\n \nreply",
      "T5 is not Bert, translation is not embedding.\n \nreply"
    ],
    "link": "https://www.yitay.net/blog/model-architecture-blogpost-encoders-prefixlm-denoising",
    "first_paragraph": "The people who worked on language and NLP about 5+ years ago are left scratching their heads about where all the encoder models went. If BERT worked so well, why not scale it? What happened to encoder-decoders or encoder-only models?\u00a0Today I try to unpack all that is going on, in this new era of LLMs. I Hope this post will be helpful. Few months ago I was also writing a long tweet-reply to this tweet by @srush_nlp at some point. Then the tweet got deleted because I closed the tab by accident.\u00af\\_(\u30c4)_/\u00af  I promised to write it as a blog post some day. So here it is!This will be the first part of a series of blog posts I plan to write about model architectures in the era of LLMs (I hope).\u00a0There are mainly three overarching paradigms of model architectures in the past couple of years. Encoder-only models (e.g., BERT), Encoder-Decoder models (e.g., T5) and decoder-only models (e.g., GPT series). People get confused a lot about this and people often have tons of misconceptions about these di",
    "summary": "**What happened to BERT and T5?**\nIn an exasperating attempt to reignite the flames of past NLP glory, a blogger dives into the abyss of forgotten encoder models, promising a series about something even they don't seem too sure about. Meanwhile, over in the comments, every ML hobbyist and their neighbor turn up boasting about their home-brew BERT models that apparently solve all AI problems in under 2.4 milliseconds, while casually waving the SOTA flag. The conversation quickly devolves, with echo-chamber accolades and secretive \"product-in-stealth\" bragging that adds nothing to the discourse but confusion. \ud83e\udd14\ud83e\udd16"
  },
  {
    "title": "FCC votes to limit prison telecom charges (worthrises.org)",
    "points": 800,
    "submitter": "Avshalom",
    "submit_time": "2024-07-19T11:33:45",
    "num_comments": 370,
    "comments_url": "https://news.ycombinator.com/item?id=41005181",
    "comments": [
      "I remember when I first went to jail in 2013, every month paying for a $20 phone card and getting to make a 25 minute \"long-distance\" call. I couldn't believe that this was legal, and even if it was, I was in disbelief that morally, this was allowed to go on.\nThere are so many other similarities in corrections that my family and I would unfortunately go on to discover over the years, things that until you experience them firsthand, either by yourself or a loved one being incarcerated, that you likely wouldn't believe.\n \nreply",
      "Amen, brother. I was an advocate for prison reform before getting locked up, but once you're inside and you find out how truly insane everything is, you realize that jails and prisons are where decency and kindness go to die.I'm in a Zoom conference with the federal court in 45 mins trying to get two constitutional violations at the biggest jail in the country fixed, but obviously the government's lawyers are maintaining that this jail is too big to fix the problems. The judge's line is that if the smallest jails in the country can not violate the rights of the detainees, why can't the biggest? The government is adamant that their size protects them from having to say, provide a working mail system.\n \nreply",
      "It is Teams, not Zoom. I'm in the conference with the federal judge and the government lawyers right now. Currently they are maintaining their stance that they are unwilling to fix constitutional violations. They'd rather go to trial and lose and pay my lawyer the 7 figure sum in fees he's owed, than agree to fix the conditions.This is the sort of people that run our jails and prisons -- and spend your tax dollars.\n \nreply",
      "OK, settled the case. Luckily my lawyer was working pro bono as he racked up over $600K in billable hours I understand. I'm waiting for an email back to see if I can discuss it or whether it is NDA'd lol. The judge said that she had never seen any institution so stubbornly against fixing what they were legally entitled to fix.\n \nreply",
      "Why lift a finger to do anything if you can just spend taxpayers' dollars on a settlement?\n \nreply",
      "That's what the judge said. She said normally they'd either throw money at it, or fix the problem. In this case they were willing to do neither. Eventually got them to make a tiny policy change and a statement that they will uphold the change with retraining, and I got $3250.\n \nreply",
      "Your lawyer made $600K and you got $3250?\n \nreply",
      "No, the lawyer was working pro bono. 600k is what those hours would have cost.",
      "Not likely with this supreme court. That lawyer is getting the money from you, or no one.\n \nreply",
      "'It looks like your client Bob is no longer housed in this facility and therefore no longer has standing. Case dismissed. If you can find someone else willing to initiate a case, you can start the year long process that got you here again. Of course, if they happen to get transferred to a new institution should their case make it this far in the process that case will also be dismissed for lack of standing.' -- The US Justice System\n \nreply"
    ],
    "link": "https://worthrises.org/pressreleases/2024/7/18/fcc-votes-unanimously-to-significantly-lower-phone-and-video-communication-costs-after-decades-of-exploitation-by-prison-telecoms",
    "first_paragraph": "WASHINGTON, D.C.\u00a0\u2014 Today, the Federal Communications Commission (FCC) voted unanimously to dramatically limit the rates that prison telecoms charge for phone and video calls from prisons and jails. The new order more than halves the per-minute rate caps for all prison and jail phone calls across the country. It also establishes interim per-minute rate caps for video calls, marking the first time the FCC has set rules for prison communication beyond phone calls. Finally, it prohibits all fees, including deposit fees.\u00a0Worth Rises estimates that the new rules will impact 83% of incarcerated people (about 1.4 million)\u00a0and save impacted families at least $500 million annually.\u00a0Impact summary:Improves\u00a0the well-being and reentry success of incarcerated people who will have more access to their support systemsIncreases\u00a0the the financial stability of millions of Americans with incarcerated loved ones and strengthens\u00a0their familiesReins\u00a0in and right-sizes\u00a0the prison telecom industry that has pre",
    "summary": "**FCC Finally Clips Greedy Phone Charges in Prisons**\n\nIn an earth-shattering move that will surely be talked about for minutes, the FCC decides to stop prison telecom giants from charging inmates extortionate prices for making phone calls. This revolutionary change will save families exactly enough to still not afford decent healthcare. Comment sections explode with touching tales from ex-inmates, showcasing a charming mix of legal jargon and pop-up tutorial vibes on \"Zoom versus Teams: A Legal Battleground\". Meanwhile, attorneys rack up 'pro bono' hours fast enough to burn a hole through the space-time continuum, and all of society is fixed. \n\nRemember, change is only a 7-figure lawsuit away."
  },
  {
    "title": "A search engine by and for the federal government (search.gov)",
    "points": 86,
    "submitter": "pajtai",
    "submit_time": "2024-07-19T17:43:44",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=41009021",
    "comments": [
      "The new tech stuff the government has been putting out is legitimately fantastic. login.gov is probably my favorite sign-in experience, maybe slightly behind Google's (and considerably ahead of Apple or Microsoft's).\n \nreply",
      "There\u2019s a ton of interesting stuff at https://www.web.dma.mil/WEB-NextGen/Just look at the significant links section\n \nreply",
      "Do they still force you to share your biometrics with a third party private service (Id.me)?\n \nreply",
      "Login.gov doesn't..  but plenty of federal sites (like IRS) are still using that id.me poppycock. Here's to hoping they prioritize a migration soon.\n \nreply",
      "SSA Already announced the switch to login.gov, it looks like it will have broad support if they are starting the migration there.\n \nreply",
      "Login.gov is adding the capabilities needed to meet IRS\u2019 identity and credential proofing requirements.Will require biometrics in some form, with fallback to in person proofing at USPS.(no affiliation, just a fan)\n \nreply",
      "I was absolutely flabbergasted that they didn't even white-label the third party stuff behind their own .gov domain, which means they're mis-training users towards \"It's normal to hand over extremely sensitive official information to vaguely-plausible-looking companies with websites and certificates ultimately under the control of Montenegro.\"\n \nreply",
      "Why would a .gov Web site like this have dependencies on, and information leaks to, googletagmanager.com and crazyegg.com?\n \nreply",
      "Here's the repo:https://github.com/GSA/search-gov\n \nreply",
      "That\u2019s so cool, I didn\u2019t know the government had an open GitHub acct!\n \nreply"
    ],
    "link": "https://search.gov/",
    "first_paragraph": "\n            An official website of the United States government\n          \n            Here\u2019s how you know\n          \nOfficial websites use .govA\n              .gov website belongs to an official government\n              organization in the United States.\n            \nSecure .gov websites use HTTPSA\n              lock (\n              \nLock\nA locked padlock\n\n ) or https:// means you\u2019ve safely connected to\n              the .gov website. Share sensitive information only on official,\n              secure websites.\n            \n            Search.gov supports one third of federal government domains. Learn what the public was searching for on these websites last year. Read the report\n\nPowering search results on more than 2,000 websites. Free, effective, and simple\u2014Search.gov has all you need to get search right on your website!Built for government \u2014 Secure, compliant, designed around the unique circumstances of government web publishing.Highly configurable \u2014 No developers required - use ou",
    "summary": "In the latest testament to the federal government's mastery of digital affairs, <em>search.gov</em> emerges as a beacon of hope... or another harebrained scheme for data mishandling. Sporting a snazzy .gov domain, where information is locked up tighter than Fort Knox, unless it randomly isn\u2019t, this search engine promises the thrill of securely browsing the bureaucratic abyss with *impressive* ease. Cheerleaders on the sidelines rave about its similarity to beloved tech giants, while skeptics mutter darkly about biometric data share-fests with shady third parties. Meanwhile, the code-savvy patriots at the back just discovered America\u2019s GitHub account, and boy, it's like finding an AOL CD in your mailbox in 1998. \ud83c\udf89"
  },
  {
    "title": "Playing guitar tablatures in Rust (agourlay.github.io)",
    "points": 87,
    "submitter": "lukastyrychtr",
    "submit_time": "2024-07-19T16:57:11",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=41008488",
    "comments": [
      "Super cool, great job. Looks like a really fun project. This really highlights why sheet notation is so much better at describing music than tablature. The advantage of tabs is that they tell you which version of the same note to play (You can play the same note in up to 6 places in the guitar). However, sheet notation tells you precisely the duration of each note, and can often include the intended articulation. Writing music is fascinating, here is an excellent breakdown of different systems which have been developed, and how they came to be: https://www.youtube.com/watch?v=Eq3bUFgEcb4\n \nreply",
      ">However, sheet notation tells you precisely the duration of each note,True but the reason that guitar tabs missing the duration of the notes is not much of a handicap compared to traditional sheet music notation is that the guitar players learning popular music already get the notes' durations from listening to the actual recordings.This is the same reason that printing out the lyrics for songs don't require notations of durations for each syllable of every word.  People singing karaoke or whatever already get the durations by hearing the recordings. (Indeed, lyrics sheets are also missing the pitch of each syllable.)On the other hand, traditional notation was invented before recordings so musicians often had no idea what the music sounded like unless they correctly decoded the notes durations on the page.\n \nreply",
      "While I agree that sheet notation is superior, it actually is fairly common to indicate duration and articulation in tablature, especially classical. See many of the tabs on classtab.org: https://www.classtab.org/tabbing.htm#keySurprisingly (to me), tablature is apparently older than sheet music. Tabs are also pretty nice when you're dealing with non-standard tunings.Lastly, even with standard notation, guitar music is often \"unnecessarily\" annotated with numbers for left hand fingering, roman numerals for barres, \"pima\" for the right hand, diamonds for harmonics, etc.\n \nreply",
      "The biggest advantage of guitar tabs is you don't need to be able to read music. You just need to know how to count. The timing is a non issue as most people will try and learn the song with a tab and a recording of the song.\n \nreply",
      "Which is funny if you presume it is true that tabs precede standard notation (and therefore recording techniques).Tabs make quite a bit of sense in a post recorded music culture. However, the information density you can get in standard sheet notation is far greater. There's tradeoffs.\n \nreply",
      "I think that neither notation is wholly superior, and your comment perfectly illustrates why. Sheet music notation tells you the tempo of the notes but gives no guidance on which way you should play them. Tabs tell you exactly how to finger the notes but don't (usually) tell you anything about tempo. Both notations are leaving out crucial info, and so neither is really superior to the other. It's a matter of which defect you are more willing to live with.\n \nreply",
      "Sheet music often gives fingering suggestions which make it clear which string to play it on. With fingerings though, there's no correct answer, and often you want to bias towards the best sound (to your taste) vs. the easiest finger execution.\n \nreply",
      "Agreed, the video goes into depth in those tradeoffs.\n \nreply",
      "A lot of tabs will put the note length on the \"beat\" of the tab too.You can see this in Tuxguitar IIRC.\n \nreply",
      "some tab viewers do have the rhythm shown as well, just connected to a tab number. Though it might get confusing a bit but more than sheet music imo.\n \nreply"
    ],
    "link": "https://agourlay.github.io/ruxguitar-tablature-player/",
    "first_paragraph": "If you ever tried to learn guitar, chances are you are familiar with guitar tablatures.It is a simple way to visualize music for guitar, using ASCII characters to represent strings and frets as an alternative to sheet music.For instance, here are the first four measures of the song \"Smoke on the Water\" by Deep Purple:This song is played in standard tuning (EADGBe), which is conveyed by the letters on the left indicating the tuning for each string. While the numbers indicate where to put your fingers on the fretboard.Beyond the text representation, the defacto standard is the format used by the Guitar Pro software to render and synthetize sound for the tablature.Those binary files have the .gp3, .gp4, .gp5 or .gp6 extension depending on the software version used to produce them, and can be easily found on the internet on websites such as Ultimate Guitar.Although the software to play the tablature is proprietary, some versions of the file format are well documented, and there are even op",
    "summary": "**Hackerman's Guide to Plucking Strings: ASCII Edition**  \nToday\u2019s adventure in unnecessary complexity comes from a brave soul who has decided that Rust\u2014yes, the programming language seemingly mandated by tech bros for all arbitrary tasks\u2014is the perfect hammer for the ASCII-art nail that is guitar tablature. Our protagonist dives deep into decoding the cryptic .gp files, liberating music aficionados from the tyranny of paying for Guitar Pro. Commenters, barely looking up from their ergonomic keyboards, applaud this monumental \"achievement\" as a colossal leap for basement guitarists everywhere. Meanwhile, the debate rages on about whether deciphering hieroglyphics (aka sheet music) or troubleshooting segfaults in Rust offers a more authentic musical enlightenment. \ud83c\udfb8vs\ud83d\udc68\u200d\ud83d\udcbb Debate!"
  },
  {
    "title": "Show HN: Sendune \u2013 open-source HTML email designer",
    "points": 282,
    "submitter": "samdung",
    "submit_time": "2024-07-19T15:22:40",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=41007403",
    "comments": [
      "No MJML feels like a mistake. I design emails and that is literally the most important feature to me.\n \nreply",
      "Because someone keeps commenting and immediately deleting their comments in reply to this: MJML is a tool to essentially \u201cfix\u201d email, which essentially has to work around out-of-date clients and incomplete HTML specs.If it feels out of date, it\u2019s because HTML email itself is out of date.\n \nreply",
      "Really great thanks! Is it possible to add responsive styles? Such as converting columns into rows on smaller device screens?\n \nreply",
      "OP should have used the patterns from Cerberus:  https://github.com/emailmonday/Cerberus\n \nreply",
      "The drag and drop part is not working for me, Firefox, macOS. I can click on the elements on the left and they will pop up, but I am not able to drag them onto the email.\n \nreply",
      "This work looks very promising. \"HTML for email\" is indeed hard to design and hard to implement. Especially editing on mobile, tablet devices, or asian (two+ bytes japanese, chinese) languages input nightmare.I do lot of email templating for B2B CRM use cases and decided to opt out for a bit different approach based on slatejs/platejs editorhttps://docs.slatejs.org/https://github.com/ianstormtaylor/slatehttps://github.com/udecode/plateThe internal representation of email template with variables in slatejs/platejs json format can look like:{\n    \"type\": \"h1\",\n    \"children\": [\n      {\n        \"text\": \" Blocks {{template_value}} {{$timenow}}}\"\n      }\n    ],\n    \"id\": \"1\"\n  }Can be easily stored in Postgres jsonb. Very easy to add Reacjs base widgets like mentioning, media, diagrams, etc inside of slatejs/platejs editor.The drawback is that you can't design the exactly the same pixel perfect template.The better abstraction is probably MJML - https://mjml.io/ ... and yet with slatejs/platejs json format you can copy&paste your editings across various assets in CRM, knowledge base, etcStoring data in MJML is not a great choise for me<mj-text align=\"left\" color=\"#55575d\" font-family=\"Arial, sans-serif\" font-size=\"13px\" line-height=\"22px\" padding-bottom=\"0px\" padding-top=\"0px\" padding=\"10px 25px\"> ...Was thinking about using something similar to /SendWithSES/Drag-and-Drop-Email-Designer as the last final step ... but couldn't settle it my brain and most end-users dont care anyway.Any thoughts on data representations and \"Postgres <> Editor > Email HTML > Send button\" dataflow is greatly appreciated. Very few people have serious thoughts on the subject.\n \nreply",
      "You can set an <mj-class> at the top of the file for a given design format to simplify your code. So in your example, if you did:<mj-class name=\"typebox\" padding-bottom=\"0px\" padding-top=\"0px\" padding=\"10px 25px\"><mj-class name=\"paragraph\" color=\"#55575d\" align=\"left\" font-family=\"Arial, sans-serif\" font-size=\"13px\" line-height=\"22px\">That would allow you to simplify your callbacks to<mj-text mj-class=\"paragraph typebox\">You can also set CSS classes as well if you need something outside the MJML spec for some reason (which would potentially cover some of your cross-platform concerns).MJML also integrates well with other languages. For example, I use a Craft CMS integration to pull data in via Twig to build complete templates directly from my CMS; there\u2019s also an integration with Eleventy.\n \nreply",
      "It looks great, I will have to try it!\n \nreply",
      "View -> Message Body As -> Plain TextNot your fault, but please always provide fall back text.\n \nreply",
      "Anyone who has touched HTML emails knows the devilry involved. Kudos for developing and open sourcing this! Excited to try it out for my newsletter.\n \nreply"
    ],
    "link": "item?id=41007403",
    "first_paragraph": "",
    "summary": "Welcome to the latest <em>Show HN</em> circus, where a brave soul introduces <strong>Sendune</strong>, an open-source HTML email designer, blissfully unaware of the MJML cult. Commenters immediately pounced on the \"no MJML\" heresy with the fervor of medieval inquisitors finding a non-believer. As technical glitches sprout like weeds (drag-and-drop on Firefox? Good luck!), other users wander in dreams of responsive design nirvanas and magical cross-platform email templates, likely procrastinating on actual productive work. The whole charade is wrapped up in techno-babble about dataflows and client integrations, solidifying <em>Sendune</em>'s fate as another cool tool soon to be buried in the graveyard of GitHub repos with single-digit stars. \ud83c\udf1f"
  },
  {
    "title": "Automerge: A library of data structures for building collaborative applications (automerge.org)",
    "points": 49,
    "submitter": "surprisetalk",
    "submit_time": "2024-07-16T14:03:44",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=40976731",
    "comments": [
      "In practice most projects seem to use Yjs rather than Automerge.  Is there an up-to-date comparison of the two?  Has anyone here chosen Automerge over Yjs?\n \nreply",
      "There's also Microsoft's Fluid Framework and Azure Fluid Relay which is powering their O365/SharePoint product.\n \nreply"
    ],
    "link": "https://automerge.org/",
    "first_paragraph": "",
    "summary": "In an astounding feat of reengineering the wheel, Automerge presents itself as the knight in shining code for collaborative applications, except everyone seems to prefer its cousin Yjs for reasons as murky as the documentation itself. Commenters desperately fish for comparisons between the two, clinging to hope that someone, somewhere, *must* know why they should care. Meanwhile, another user pivots to Microsoft\u2019s Fluid Framework, as if introducing a Godzilla-sized corporate solution would help settle this heavyweight title match of niche tech obscurity. \ud83e\udd13\ud83d\udcbb\ud83e\udd4a"
  },
  {
    "title": "Visual programming should start in the debugger (interjectedfuture.com)",
    "points": 110,
    "submitter": "iamwil",
    "submit_time": "2024-07-15T14:32:37",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=40968215",
    "comments": [
      "I sympathize a lot with this post. Today, modern IDE's still don't provide automatic ways to inspect program execution and nicely visualize it. Instead, they rely on having you place all the breakpoints, step-step-step and restart everything again if you did not inspect something in time. I don't want to insert print statements that end up clogging the console completely. This workflow also quickly breaks with a lot of logging.I'm quite a bit into developing more tooling around that, and it's really hard - developers particularly want tools that completely integrate with existing IDE's. Debugger infrastructure is usually not built to be very exstensible or accessible. For my extension for Visual Studio https://d-0.dev/ I had to put serious effort into making sure it all still works correctly with VS breakpoints which is extremely difficult when the debugger expects all of the code to be in the same place all the time.\n \nreply",
      "I'm still shocked how limited our tools are. People in the early 2000s could animate complex 3d scenes in real time with physics and soft body dynamics. But tracing a few variables feels like an herculean effort.Maybe it's time to flip the game on its head. Bring reactive, lispmachines, responsive UIs.. I don't know.\n \nreply",
      "Those tools exist. Time travel debugging has existed in product-ready forms since the early 2000s let alone the advancements since then.The problem is that game development companies are willing to invest money in buying quality tools to make their developers productive, where as traditional trillion dollar software companies prefer to let their developers wallow in filth.Getting a company to invest 5,000$/yr into making their breathing revenue machines that cost 200,000$/yr and produce 1,000,000$/yr in revenue is like pulling teeth in this industry. Companies with breathing electrical engineer revenue machines do not bat an eye at 50,000$/yr in making them productive. Think about how much cool and effective tooling you could get with that kind of budget. But if you are not willing to spend even one coffee worth on your tooling, then one coffee of productivity is all you get to have.\n \nreply",
      "The hard part of game development might be more centralized around complex, big programs that simulate game logic and push tons of complex and mathematically sophisticated data to GPU\u2018s.On the contrary the complexity web development, distributed systems emerges from many communicating processes, that execute in different environments.A sophisticated debugger might help the former category more than the latter. There\u2019s no shortage of monitoring products that act on the distributed systems level.\n \nreply",
      "It's still strange to see this contrast between game dev doing magic for small salaries versus big corps paying huge lumps of money for CRUD++ (sorry for being exaggerating here).It's also cultural.. when everybody in the room thinks a REST api is state of the art, you'll have a hard time selling them more R&D.\n \nreply",
      "A game dev I know went to work for Google on Android. What he found was a team full of people who had given up on gdb back in uni, had worked for Google their entire career, printf debugged all day every day, took forever to fix anything, and everyone was fine with that because that\u2019s all they\u2019d ever known.It was a shock because in gamedev debuggers are a Big Deal. The vast majority of AAA gamedev happens in Visual Studio\u2019s debugger or some alternative that is at least as capable.\n \nreply",
      "Interesting. And scary.. and depressing (about Google). Gamedev has always had a special relationship with ergonomics (dev ux, dx) I assume (due to the interactive nature of their product)... Reminds me of Naughty Dog developing a whole lisp DSL to be able to try different game designs on the fly on PS1.That said gdb and similar debuggers are still too limited IMO, there's so much we could add on top. Well maybe I'm not aware of improved variants.\n \nreply",
      "The GDB feature set has been largely unchanged since the 80s and even then mostly just parroted the design of other CLI debuggers from the 70s. Of course it is limited, you are talking about technology that was not even cutting edge nearly half a century ago.To be fair, the core components of a low level debug agent are still largely the same, so it is not like the technology is bad per se. It is just that it only constitutes table stakes, a bare minimum foundation, these days. Even looking at 20 year old technology like time travel debugging that allows you to time travel execution back and forth gives a far better idea of what people are missing by using primitive tools.\n \nreply",
      "Windows, Linux, and Mac desktop OS are so limited still. I'd like a little scripting language built-in to the OS that allows you to do stuff like draw to the screen. No, Python + turtle graphics doesn't count :)There are simply far too many hurdles to do basic computing things. I think Microsoft could do some minor additions to powershell and maybe get something like this.I wish some billionaire would put up some money and fund a modern lisp machine or something like that. I know it'll probably never work, but I can dream.\n \nreply",
      "> a little scripting language built-in to the OSMacOS has something like this: https://en.wikipedia.org/wiki/AppleScript#Basic_concepts You can send around events and macro/script GUI stuff.\n \nreply"
    ],
    "link": "https://interjectedfuture.com/visual-programming-should-start-in-the-debugger/",
    "first_paragraph": "Just like CAD didn't make everyone an industrial designer, visual programming isn't going to make everyone a programmer. Whether textual or visual, there'd still be a lot of underlying concepts (and how they are composed) to learn. But still, I think it's underexplored.Most visual programming paradigms focus on coding--the instruction of the computer. This can be helpful for beginners, but it's of limited value to working programmers. Once syntax and API are learned, current visual tools don't help solve problems that working programmers have.As \"bicycles for the mind\", computers should leverage our visual-spatial reasoning. It's a powerful aspect of our minds underutilized in modern programming toolchains and stacks. We all know this on some level, hence the gravity of the visual programming tarpit.This is what debuggers are suppose to help with, but they don't have a good affordance. You can overstep the bug and need to restart. You have to manually track variables for your bug. And ",
    "summary": "**Visual Programming: The Debugger's New Clothes**  \nIn a shocking turn of events, <em>interjectedfuture.com</em> bravely discovers that visual programming won't turn us all into programmers overnight - a revelation as groundbreaking as discovering that water is wet. The article's author, in a valiant crusade against the tyranny of text-based coding, proposes starting in the debugger to spark a revolution in the use of visual-spatial reasoning, apparently forgetting that most programmers spend their lives doing just that. Meanwhile, the commenters, in an adorable effort to sound savvy, pitch their own half-baked tools and mourn the industry's stinginess, seemingly oblivious to the fact that their dream solutions already exist but were discarded for practical reasons. \ud83e\udd13\ud83d\udcbb\ud83d\udd27"
  },
  {
    "title": "10-acre underground home and gardens in Fresno (2023) [video] (youtube.com)",
    "points": 166,
    "submitter": "8bitsrule",
    "submit_time": "2024-07-16T18:07:57",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=40978820",
    "comments": [
      "This is a great, very fascinating YouTube channel.Dirksen travels North America and Europe with her husband and 3 or 4 kids documenting home designs of all types. Lots of tiny homes in Los Angeles and California ( I believe one or two in Toronto ) as well as Western Europe. Her husband is from Catalunya so they've a bunch of clips from there. There's also one of a man who build a home sort of next to or inside a cave.The coolest clips by far are ones of ancient abandoned villages and compounds (I think one castle-like structure) in Spain, Portugal and Italy that individuals took over and converted into homes.\n \nreply",
      "I used to watch her videos back when she had very little followers. I'm glad to see she picked up so many subscribers, it's well deserved. I enjoy the way she interacts with the people because it seems more natural than the other heavily edited/pro formats.\n \nreply",
      "Agreed on all points. Her family is a big part of that casual interaction since  they're young enough to be super active and curious. They seem to get on especially well with older subjectsI only just discovered her during the pandemic and since then a lot of copy cat projects've popped up and moved on to bigger streaming platforms. I'd buy a DVD/Blu-Ray collection of her YouTubes\n \nreply",
      "I really like her content, especially the earthship videos. The 'home engineering' that goes into these buildings is awesome. Though I'll probably never get to build one, would happily play a game based on this (like some sort of physics based survival game? Is this a thing?)\n \nreply",
      "The earthship design includes a lot of ideas from permaculture design. Dirksen has also toured Brad Landcaster's site, in which the permaculture design is very  obvious, and it is not an earthship. Those design principles and method applies to any region, biome, or climate, so even if you may never get to build an earthship, you can still use permaculture design wherever you land.\n \nreply",
      "Kirsten has a way of bringing out the enthusiastic, knowledgeable, and happy in people she interviews.A rare gift that she combines with superb editing.\n \nreply",
      "I love Dirksen, and a very similar channel on YT is called Exploring Alternativeshttps://www.youtube.com/channel/UC8EQAfueDGNeqb1ALm0LjHA\n \nreply",
      "I've seen a few videos from that channel.downtoearth is another good one.\n \nreply",
      "This is wonderful \u2013 however I feel a bit sad that is a museum rather than an active place people live.  So many examples of wonderful architecture in California, but they are museums, and around them are built sub par structures.\n \nreply",
      "There might be lots of cool actively inhabited houses. If they are actively inhabited, we wouldn't know they exist.\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=mUKRPoQKynk",
    "first_paragraph": "",
    "summary": "Welcome to the farcical underground wonderland of YouTube's home-design niche, where Kirsten Dirksen reigns as the vagabond queen of tiny-home fetishism and half-baked permaculture dreams. In her latest thrilling excavation, Dirksen drags her husband, three or potentially four children, and a camera into a \"10-acre underground home and gardens\" that might just be a glorified bunker in Fresno. The coterie of YouTube commenters - ever ready to canonize Dirksen for her \"natural interactions\" and make-believe engineering insights - are tripping over themselves to declare her the unsung hero of alternative housing. Somewhere, in the distant echoes of their praise, you can almost hear the collective lament of architects crying over their master\u2019s degrees. \ud83d\ude44"
  },
  {
    "title": "Want to spot a deepfake? Look for the stars in their eyes (ras.ac.uk)",
    "points": 209,
    "submitter": "jonbaer",
    "submit_time": "2024-07-18T14:34:42",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=40995955",
    "comments": [
      "They love saying things like \"generative AI doesn't know physics\". But the constraint that both eyes should have consistent reflection patterns is just another statistical regularity that appears in real photographs. Better training, larger models, and larger datasets, will lead to models that capture this statistical regularity. So this \"one weird trick\" will disappear without any special measures.\n \nreply",
      "> Better training, larger models, and larger datasets, will lead to models thatHypothetically, with enough information, one could predict the future (barring truly random events like radioactive decay). Generative AI is also constrained by economic forces - how much are GenAI companies willing to invest to get eyeball reflections right? Would they earn adequate revenue to cover the increase in costs to justify that feature? There are plenty of things that humanity can technically achieve, that don't get done because the incentives are not aligned- for instance, there is enough food grown to feed every human on earth and the technology to transport it, and yet we have hunger, malnutrition and famines.\n \nreply",
      "> how much are GenAI companies willing to invest to get eyeball reflections rightThis isn't how it works. As the models are improved, they learn more about reality largely on their own. Except for glaringly obvious problems (like hands, deformed limbs, etc) the improvements are really just giving the models techniques for more accurately replicating features from reasoning data. There's nobody that's like \"today we're working on fingernails\" or \"today we're making hair physics work better\": it's about making the model understand and replicate the features already present in the training dataset.\n \nreply",
      "No, it\u2019s a valid point, which I didn\u2019t interpret as literally \u201cwe\u2019re working on eyeballs today\u201d but rather \u201cwe\u2019re scaling up these imperfect methods to a trillion dollar GPU cluster\u201d, the latter of which is genuinely something people talk about. The models will learn to mimic more and more of the long tail of the distribution of training data, which to us looks like an emergent understanding. So there\u2019s a theoretical amount of data you could provide for them to memorize physical laws.The issue is practical. There isn\u2019t enough data out there to learn the long tail. If neural nets genuinely understood the world they would be getting 100% on ARC.\n \nreply",
      "> This isn't how it works. As the models are improved, they learn more about reality largely on their own.AI models aren't complete blackboxes to the people who develop them: there is careful thought behind the architecture, dataset selection and model evaluation. Assuming that you can take an existing model and simply throw more compute at it will automatically result in higher fidelity illumination modeling takes almost religious levels of faith. If moar hardware is all you need, Nvidia would have the best models in every category right now. Perhaps someone ought to write the sequel to Fred Brooks' book amd name it \"The Mythical GPU-Cluster-Month\".FWIW, Google has AI-based illumination adjustment in Google Photos where one can add virtual lights - so specialized models for lighting already exist. However, I'm very cynical about a generic mixed model incidentally gaining those capabilities without specific training for it. When dealing with exponential requirements (training data, training time, GPUs, model weight size), you'll run out of resources in short order.\n \nreply",
      "What you're refuting isn't what I said. I'm making the point that nobody is encoding all of the individual features of the human form and reality into their models through code or model design. You build a model by making it capable of observing details and then letting it observe the details of your training data. Nobody is spending time getting the reflections in the eyeballs working well, that comes as an emergent property of a model that's able to identify and replicate that. That doesn't mean it's a black box, it means that it's built in a general way so the researchers don't need to care about every facet of reality.\n \nreply",
      "> If moar hardware is all you need, Nvidia would have the best models in every category right now.Nvidia is making boatloads of money right now selling GPUs to companies that think they will be making boatloads of money in the future.Nvidia has the better end of things at this very moment in time.\n \nreply",
      "Getting the eyeballs correct  will correlate with other very useful improvements.They won\u2019t train a better model just for that reason. It will just happen along the way as they seek to broadly improve performance and usefulness.\n \nreply",
      "I\u2019m far from an expert on this, but these are often trained in conjunction with a model that recognizes deep fakes. Improving one will improve the other, and it\u2019s an infinite recursion.\n \nreply",
      "Yeah every person is constantly predicting the future, often even scarely accurately. I don't see how this is a hot take at all.\n \nreply"
    ],
    "link": "https://ras.ac.uk/news-and-press/news/want-spot-deepfake-look-stars-their-eyes",
    "first_paragraph": "Contact usIn an era when the creation of artificial intelligence (AI) images is at the fingertips of the masses, the ability to detect fake pictures \u2013 particularly deepfakes of people \u2013 is becoming increasingly important.So what if you could tell just by looking into someone's eyes?That's the compelling finding of new research shared at the\u00a0Royal Astronomical Society\u2019s National Astronomy Meeting in Hull, which suggests that AI-generated fakes can be spotted by analysing human eyes in the same way that astronomers study pictures of galaxies.The crux of the work, by University of Hull MSc student Adejumoke Owolabi, is all about the reflection in a person's eyeballs.If the reflections match, the image is likely to be that of a real human. If they don't, they're probably deepfakes.\"The reflections in the eyeballs are consistent for the real person, but incorrect (from a physics point of view) for the fake person,\" said Kevin Pimbblet, professor of astrophysics and director of the Centre of",
    "summary": "<b>In yet another staggering breakthrough</b>, a Royal Astronomical Society meeting has uncovered that the next big clue in spotting AI-created imposters lies within <i>the twinkling cosmos of our eyeballs</i>. Strap in, as an MSc student figures out deepfakes using the same principles your weird uncle applies to UFO documentaries \u2013 if the eye reflections aren\u2019t cosmic twins, it's AI shenanigans! Comment sections are ablaze with tech aficionados debating whether training models on more cat videos will eventually enable DeepMind to perfect human pupil reflection physics. Meanwhile, big tech\u2019s GPU plundering raises little skepticism about whether a silicon powerhouse really translates into understanding human subtleties or if it\u2019s just another dazzling, expensive way to miss the point. \ud83d\ude80\ud83d\udc40"
  },
  {
    "title": "Debugging an evil Go runtime bug: From heat guns to kernel compiler flags (2017) (marcan.st)",
    "points": 116,
    "submitter": "goranmoomin",
    "submit_time": "2024-07-19T13:24:40",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41006308",
    "comments": [
      "(2017)\nPrevious discussion: https://news.ycombinator.com/item?id=15845118\n \nreply",
      "You can follow Hector Martin @marcan at https://social.treehouse.systems/@marcan/He works on Asahi Linux, a Linux port to arm64 Apple hardware.\n \nreply",
      "Related (for the hash based bisecting):\nhttps://research.swtch.com/bisect\n \nreply",
      "This is honestly wild. 99% of devs would have found a work around and moved on. Going so far as to create a multi-kernel test bench to narrow down the source of the instability is a level of dedication I have not personally seen, and I respect it.\n \nreply",
      "Problems like this tend to come back and haunt you though. Sure, you can set max threads to 1 and move on with what you're doing for a while... but a lot of people run Go so they can have a lot more than 1 thread.I've run into some of these where it's a lot more rare to hit, and so then it's reasonable to not do the thing that hurts, but watch out for it in the future. Sometimes you get lucky and it magically fixes itself forever; sometimes the weird case that you only hit with internal traffic ends up getting hit by public tratfic a lot.Crashes like this where a wild write breaks something at a distance are always a PITA to debug (especially here, where the wild write is harmless if there's no data race)\n \nreply",
      "Marcan is an beast, this guy really loves to go down the rabbit holes.\n \nreply",
      "By the same token, you might be the first person I have ever seen give respect to the 1x developer. I respect that. We could no doubt all learn a thing or two from the 1x developer that doesn't rush through everything with quick solutions.\n \nreply",
      "If you check the issue[1] he reported the crash on November 7th and reported the issue is related to gcc and the kernel on November 8th. At least he was very quick going through the rabbit hole.[1]: https://github.com/prometheus/node_exporter/issues/730\n \nreply",
      "From the outside looking in, that's mind blowing.\n \nreply",
      "Seems about right. As a lowly developer with 10x tendencies, I'm not sure I have ever spent more than an hour solving a problem. I'll just apply the quick hack that addresses the immediate concern and move on. Frankly, I don't have the attention span to dive in like this guy has. Which, mathematically, means that a 1x developer will take around 10 hours to get to the same place (no doubt with a better solution, as demonstrated here), which is approximately in line with your findings.Respect to the talent that can pull off 1x greatness. Something for us weak 10x developers to strive towards.\n \nreply"
    ],
    "link": "https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/",
    "first_paragraph": "I\u2019m a big fan of Prometheus and\nGrafana. As a former SRE at Google I\u2019ve learned to\nappreciate good monitoring, and this combination has been a winner for me\nover the past year. I\u2019m using them for monitoring my personal servers (both\nblack-box and white-box monitoring), for the\nEuskal Encounter external and internal event infra,\nfor work I do professionally for clients, and more. Prometheus makes it very\neasy to write custom exporters to monitor your own data, and there\u2019s a good\nchance you\u2019ll find an exporter that already works for you out of the box.\nFor example, we use sql_exporter\nto make a pretty dashboard of attendee metrics for the Encounter events.Since it\u2019s so easy to throw\nnode_exporter onto any random\nmachine and have a Prometheus instance scrape it for basic system-level metrics\n(CPU, memory, network, disk, filesystem usage, etc), I figured, why not also\nmonitor my laptop? I have a Clevo \u201cgaming\u201d laptop that serves as my primary\nworkstation, mostly pretending to be a desktop ",
    "summary": "In an epic saga worthy of Homer, one tech hero bravely confronts a Go runtime bug that threatens the very fabric of his precious monitoring tools, Prometheus and Grafana. Armed only with a heat gun and the fierce determination of a former Google SRE, our protagonist delves into the treacherous depths of kernel compiler flags and multicore CPU conflicts, leaving mere mortal developers in awe. Commenters emerge from the woodwork to herald this valiant journey, lauding our hero's dogged dedication with the kind of fervor reserved for astronauts and superheroes. Yet, lurking among the accolades are the battle-scarred survivors of simpler bugs, those who whisper of quick hacks and the mythic allure of the \"restart and forget\" strategy, their voices a faint echo against the clangor of debugging glory."
  },
  {
    "title": "Bangladesh imposes curfew after dozens killed in anti-government protests (washingtonpost.com)",
    "points": 316,
    "submitter": "perihelions",
    "submit_time": "2024-07-19T15:22:02",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=41007396",
    "comments": [
      "Some context: Students are protesting to reform the quota system. Which was abolished in 2018 after protest but recently brought back again. The Quota system basically reserves 56% of public sector jobs, i.e. 30% to relatives of war veteran.The war happened in 1971. To get public job and avail the quota, it must be their 3rd or 4th generation now. Which is plain unfair.But it\u2019s not about that, the gov loyalists and their goons fake these veteran certificates to land these jobs. Bangladesh is one of the most corrupted countries in the world after all. So real veteran relatives are seldom the beneficiary.These students just wanted to reform this system. But our fascist gov and their goons used force and killed 50+ unarmed students until yesterday (3 from my alma mater alone.) This was completely unprovoked and unnecessary. Basically any forms of dissent have been dealt with this way since 2009. No one can criticize or protest the big brother.We have a dictatorship since 2009. People are angry - due to corruption, inflation, joblessness and tyranny. This is just some outburst of it.When you see the videos how the police are killing teenagers and university students in the road - our future generation - no one can tolerate this.Now the fascist gov has closed all internet and phone connection to outside world. I can't contact my family anymore. I don't know their well being.There is of course more to it. But this is the summary.\n \nreply",
      "Thank you for the information. I'm sorry for you and your family. Are public jobs so numerous that a lot of people survive off of them?\n \nreply",
      "Nope. It won't be numerous but grab whatever of the tiny pie is the point. I am from neigboring country but situation is same for jobs. For 10 govt job, 10K people can show up and create riot like situation in little time.\n \nreply",
      "> Now the fascist gov has closed all internetI agree that Sheikh Hasina is extremely authoritarian and corrupt dictator but imo JeI are the actual fascists, and the BNP has absolutely been enabling them.That said, I agree with you that Hasina's authoritarianism needs to end.Ideally all these old fossils (Hasina, Zia, Rahman, etc) need to be purged and the actual youth (who are the majority of Bangladesh) get a chance to have their voice in power.It's a handful of elite 70 year olds who have been running a country where the median age is 25 and are ruining it due to their own personal drama from the 70s and 80s.\n \nreply",
      "> agree that Sheikh Hasina is extremely authoritarian and corrupt dictator but imo JeI are the actual fascistsThe challenge of escalating partisanship is auto-re\u00efnforcing polarisation. The worse the leadership, the worse the opposition.The operant question, thus, is not who is good. But who is less evil. The hope is that ratchet, a few times turns, yields goodness.\n \nreply",
      "Independent of points for or against their rule, the ageist argument makes little sense. 25 year olds are generally politically naive and easily manipulated. The average person in their twenties has no idea about economics, geopolitics or other such topics that are important to understand for running a country. When you look at uprisings against ancient leaders in countries with very young populations, they regularly end up even worse then before, sadly. Take Sudan as an example.\n \nreply",
      "If that's the lens you're looking at, the majority of uprisings in history have ended up worse than they started. Bangladesh is struggling with a democracy that has degraded into authoritarian gerontocracy. It's not as simple as young people dumb old people experienced, there's a lot of issues involved.\n \nreply",
      "^^^ this.Revolutions turn into civil wars.We forget but this is the sad reality.This doesn't mean the students in Gulistan Maidan are wrong, but \"Allah, Suriya, y Bashar\" and the converse means a 15 year civil war like in Syria or 15 miles away from Chittagong in Myanmar (aka Asian Syria/Libya)Khuda ki kasm - please walk off this brink Bangladesh (if someone Hasina adjacent is reading).\n \nreply",
      "Yeah I think \"fascist\" is too much for any actor not JeI but authoritarian is right. They've cut off Internet and telecom access after all, a dangerous game given how physically close they are to West Bengal.\n \nreply",
      "> Fascism is a far-right, authoritarian, ultranationalist political ideology and movement,characterized by a dictatorial leader, centralized autocracy, militarism, forcible suppression of opposition, belief in a natural social hierarchy, subordination of individual interests for the perceived good of the nation or race, and strong regimentation of society and the economy.Source: WikipediaThis sounds like the very definition of fascism to me.\n \nreply"
    ],
    "link": "https://www.washingtonpost.com/world/2024/07/19/bangladesh-demonstrations-police-hasina/",
    "first_paragraph": "Schools and universities have been closed indefinitely, and authorities have cut mobile internet services nationwide, citing the need to curb disinformation.NEW DELHI \u2014 Bangladesh announced a nationwide curfew on Friday evening after clashes between police and various student groups killed dozens of people amid a violent backlash to a new policy to reserve a portion of government jobs for descendants of the nation\u2019s freedom fighters.In the capital, Dhaka, protesters attacked the state television headquarters and set fire to police booths Thursday as they called for a \u201ccomplete shutdown\u201d of the country. Running street battles between security forces using rubber bullets and tear gas and crudely armed protesters forced life in several neighborhoods to a halt, with streets emptying of traffic and even the cabinet canceling its meetings, Bangladeshi media reported.More than 150 students were being treated at a Dhaka hospital for injuries after being hit by rubber bullets, Agence France-Pre",
    "summary": "In a shocking display of authoritarian overreach that could only surprise someone just waking from a two-decade coma, Bangladesh clamps down with a curfew faster than its internet service was cut. The wonderfully original solution of \"mob violence for job quotas\" sees the young scholars of Dhaka transforming into urban guerrilla warfare enthusiasts, while the government plays its favorite hits from the 'Suppressive Regimes Greatest Hits' collection. Commenters, exhibiting the depth of a kiddie pool, passionately argue who's the real fascist and if being youthful equates to political wisdom, unknowingly crafting a yawn-inducing rerun of every online political debate ever.  \ud83c\udf7f\ud83c\udfad"
  },
  {
    "title": "Instrumenting Python GIL with eBPF (coroot.com)",
    "points": 74,
    "submitter": "lukastyrychtr",
    "submit_time": "2024-07-19T14:31:04",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=41006946",
    "comments": [
      "Wow, 36ms per second is only 3.6% of the time. Python waiting on the GIL is then a pretty overblown problem, as this is not very significant.   \nI wonder if this measure could be run on apps built with various frameworks. I expect that with uvloop and all, the percentage would be even less.\n \nreply",
      "It may not be very significant in this context.But the author literally starts by explaining that that's a typical argument for webservers because they're mostly I/O bound. Anyone working with code that's more CPU bound will have very different numbers, and interpret them differently.\n \nreply",
      "are you sure though that being more CPU-bound will imply more waiting on the GIL? CPU-bound python in my experience means libraries, like eg. numpy, that are well-designed and release the GIL.\n \nreply",
      "If you are interested PEP703 describes the scenarios pretty well:\nhttps://peps.python.org/pep-0703/#motivation\n \nreply",
      "I just wrote a post about how the Cpython is much faster without GIL:https://news.ycombinator.com/item?id=40988244\n \nreply",
      "I mean, only the threaded version, which is expected. For tons of cases Python without the GIL is not just slower, but significantly slower; \"somewhere from 30-50%\" according to one of the people working on this: https://news.ycombinator.com/item?id=40949628All of this is why the GIL wasn't removed 20 years ago. There are real trade-offs here.\n \nreply",
      "I'm not sure your conclusion is a fair take. In the app I work on, GIL acquisition would easily take 2-3x longer than the postgres queries which would subsequently be issued.\n \nreply",
      "That\u2019s over 40 minutes of a full day or 5 hours a week spent locking! As the author states it\u2019s highly context dependent but in some cases this is a lot of time to do other work if it can be reduced.\n \nreply",
      "If you're running your application on 100 servers, that's potentially 3-4 entire machines you no longer have to pay EC2/S3/etc fees for, or it's more scaling headroom because you've decreased load across your whole fleet by 3.6%.It's \"small\", sure, but in production performance issues are often \"death by a thousand cuts\" situations, so a 3.6% reduction is a big win compared to optimizations that are often in the 1% range.\n \nreply",
      ">Every Python developer has heard about the GILSadly, that is not the world we live in.I've cleaned up dozens of applications written by people with flawed understandings of threads, multiprocessing, and asyncio. I don't even blame the developers for this; it's a glaring language design problem.If you need parallelism, Python is not the language you should reach for. Nobody ever takes my word for it until it's release day and the product is a broken pile of spaghetti code.\n \nreply"
    ],
    "link": "https://coroot.com/blog/instrumenting-python-gil-with-ebpf",
    "first_paragraph": "\n            Every Python developer has heard about the GIL (Global Interpreter Lock)\n            This lock simplifies memory management and ensures thread safety, but it also limits the performance of multi-threaded,\n            CPU-bound programs because threads can't run Python code in parallel.\n            Here is a great explanation of why Python requires the GIL by Python's creator, Guido van Rossum:\n            Guido van Rossum: Will Python ever remove the GIL? | Lex Fridman Podcast Clips.\n        \n            In most cases, web applications are not CPU-bound because they spend most of their time waiting for data from databases or other services.\n            However, we cannot be certain whether the GIL affects the performance of a Python application without measuring its impact.\n        \n            What would be an ideal metric to measure the impact of the GIL? I like to think of any lock as added latency.\n            In other words, if a thread spent 100ms waiting for the GIL",
    "summary": "\ud83d\udc0d\ud83d\udca4 In yet another heroic effort to reinvent the wheel, an enthusiastic blogger decides to regale the world with eye-opening insights about the Python GIL\u2014a topic as exciting as watching paint dry. Commenters, true to form, dive into a frenzied debate, offering armchair analyses that range from \"it's practically negligible\" to apocalyptic visions of CPU-bound doom! Expect a sprinkling of vague references to PEP numbers and off-handed remarks about how \"Python without GIL is slower, or it isn\u2019t, but maybe only on Tuesdays.\" Who knew a few milliseconds of waiting could catalyze such breakdowns of human rationality? \ud83e\udd16\ud83d\udc94"
  },
  {
    "title": "Artificial neural network approach to finding the key length of Vigen\u00e8re cipher (tandfonline.com)",
    "points": 30,
    "submitter": "histories",
    "submit_time": "2024-07-15T13:55:43",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=40967935",
    "comments": [
      "Inverse:\n\u201cCryptGPT: Privacy-Preserving Language Models Using Vigenere Cipher\u201dhttps://huggingface.co/blog/diwank/cryptgpt-part1\n \nreply",
      "Interesting. Implemented the Index of Coincidence version for a class in college. Was fun.This seems like the kind of problem that could be better solved by coming up with a better algorithm. Like, ultimately the model is performing an \"algorithm\" of sorts on the data to guess the key length.\n \nreply",
      "Time to get rich off the Beale ciphers\u2026\n \nreply",
      "Better switch everything over to Autokey\n \nreply"
    ],
    "link": "https://www.tandfonline.com/doi/full/10.1080/01611194.2024.2351117?src=exp-la",
    "first_paragraph": "",
    "summary": "**Hacker's Delight or Dumpster Fire? The Bizarre Trek to Decrypting Ancient Secrets**\n\nThe academic echo chamber has once again touched down on Earth, this time masquerading as a groundbreaking study on the *Vigen\u00e8re cipher*. Like a gathering of medieval alchemists, the authors throw AI into a cauldron hoping for gold, but surprise\u2014still not alchemy! One keen observer rambles about their college days, fondly recalling 'fun' assignments with Index of Coincidence\u2014nostalgia over practicality! Meanwhile, others plot to unearth fortunes hidden by the Beale ciphers, because why solve practical problems when *treasure hunting* sounds sexier? Ah, Academia: never a dull moment when you can make a simple task labyrinthine with \"privacy-preserving\" models and convolutional detours. \ud83c\udf93\u2728\ud83d\udcb8"
  },
  {
    "title": "Never Update Anything (kronis.dev)",
    "points": 119,
    "submitter": "generatorman",
    "submit_time": "2024-07-19T19:07:48",
    "num_comments": 80,
    "comments_url": "https://news.ycombinator.com/item?id=41009942",
    "comments": [
      "Oh hey, I was wondering why the VPS suddenly had over 100 load average, restarted Docker since the containers were struggling, now I know why (should be back now for a bit). Won't necessarily fix it, might need to migrate over to something else for the blog, with a proper cache, alongside actually writing better articles in the future.I don't think the article itself holds up that well, it's just that updates are often a massive pain, one that you have to deal with somehow regardless. Realistically, LTS versions of OS distros and technologies that don't change often will lessen the pain, but not eliminate it entirely.And even then, you'll still need to deal with breaking changes when you will be forced to upgrade across major releases (e.g. JDK 8 to something newer after EOL) or migrate once a technology dies altogether (e.g. AngularJS).It's not like people will backport fixes for anything indefinitely either.\n \nreply",
      ">might need to migrate over to something else for the blog, with a proper cacheNever Update _Anything_ :)\n \nreply",
      "I am very much tempted not to because it works under lower loads, could just put it on a faster server, but how could I pass up the chance to write my own CMS (well, a better one than the previous ones I've done)? That's like a rite of passage. But yes, the irony isn't lost on me, I just had to go for that title.\n \nreply",
      "If you are using open source you can always support your own old versions ~joking but not really~Of course security updates are very hard, but if an old version has some good community you have the option of forking or upstreaming the updates yourself\n \nreply",
      "> ~joking but not really~For some languages and applications it can be trivial to backport the changes then trying to keep up with the new features. If it's tested and stable it will likely be more stable than a new version, I do this for some smaller programs and I'm not even a real programmer but more of a hobbyist",
      "If you have to write your own CMS, make it compile to static files. I did that with Django, used Django-distill, and it's hands down the best static site generator I've ever used. My site never needs updates and never goes down under any amount of load.\n \nreply",
      "\u201cstatic files\u201d are nothing more than no-TTL caching strategy with manual eviction.\n \nreply",
      "OK.\n \nreply",
      "For contrast, I recently had a no 1. HN hit and my Pi4 never had a core beyond 20%Yes, it\u2019s a static website. It\u2019s amazing how little performance you actually need to survive a HN avalanche\n \nreply",
      "It's amazing how powerful hardware is in the past decade, and how masterly crafted and efficient some software is (linux, nginx, etc) ... while other software is so profoundly inefficient, that we forget.\n \nreply"
    ],
    "link": "https://blog.kronis.dev/articles/never-update-anything",
    "first_paragraph": "Here's a fair warning: this article is reductio ad absurdum, therefore you shouldn't take it as gospel. However, i do believe that this point of view is extreme enough that it usually gets shut down immediately, yet doesn't have any frank discussion about it, which makes it the perfect subject for me to write about! To reiterate, i'm not suggesting that you go out there after reading this and never update any of your production software, merely consider the points that are offered here.So, as the article title suggests, you should never update anything. Not your OS. Not your libraries in your software project. Not your tools. What would make someone come to this controversial idea? Actually trying to do that, of course! When you're telling your colleagues that you can't really work because Windows or JetBrains IDEs need to install some updates, they'll give you understanding, yet annoyed glances. When you tell clients that you cannot ship software because first you need to spend a few ",
    "summary": "**Never Update Anything: An Ode to Technological Stagnation**\nIn a stirring homage to inertia, one brave soul at _kronis.dev_ proposes a revolutionary concept: <em>never update anything</em>. Why challenge the comforting embrace of outdated software when you can bask in the glory of annoying your coworkers and failing to deliver projects on time? Meanwhile, the commenters chime in with a delightful blend of sarcasm and naivet\u00e9, offering pearls like \"just fork it or write your own CMS!\" as if software maintenance were a light weekend hobby rather than a full-blown Sisyphean ordeal. \ud83d\ude43"
  },
  {
    "title": "The oldest known recording of a human voice [video] (bbc.com)",
    "points": 61,
    "submitter": "YeGoblynQueenne",
    "submit_time": "2024-07-15T22:49:43",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=40972147",
    "comments": [
      "Accounting for the variability in the recording medium's speed by including a constant frequency from a tuning fork strikes me as genuinely genius, particularly when he wasn't even thinking about playing back the audio\n \nreply",
      "I don't know if this is the oldest recording of a FAMOUS person, but here's Brahms in 1889:https://www.youtube.com/watch?v=H31q7Qrjjo0\n \nreply",
      "Lajos Kossuth held a speech in Turin in 1890 and the wax cylinder crew jumped on the opportunity: https://en.wikipedia.org/wiki/File:Voice_of_Lajos_Kossuth.og...\n \nreply",
      "Skip to 3:10 if you just want to hear the voice and not have 3 minutes of preamble.\n \nreply",
      "FWIW I found the whole video quite interesting, I had never really considered that there could be sound recordings from before anyone had thought of a way to play them back.\nThough I do remember an old mythbusters episode [1] where they tested whether it was possible for audio to be \"accidentally\" recorded on a pot when a piece of grass happened to mark the pot while spinning.[1] https://en.wikipedia.org/wiki/MythBusters_(2006_season)#Pott...\n \nreply",
      "I don't think this was a real myth. This was an X-Files episode in which a clay pot that has been molded while Jesus was ordering Lazarus to rise from the dead could be used to bring other people back from the dead by playing back the recording. If I'm remembering correctly, even in X-Files this was actually a hoax.\n \nreply",
      "That X-Files episode may have been inspired by \"Time Shards\" [1] by Gregory Benford, a short story first published in 1979.TLDR: Too late to be included in the bi-millenium vault, a Smithsonian researcher discovers an audio recording accidentally inscribed on a c. 1280 pot by a pointy tool cutting a decorative spiral. After listening to the banal conversation recorded on the pot, the researcher wonders about the contents of the vault to be opened in a thousand years: \u201cWhat makes you think we\u2019ve done any better?\u201d[1] https://www.lightspeedmagazine.com/fiction/time-shards/\n \nreply",
      "As so often, Daedalus (David E H Jones) got there first with one of his semi-humorous articles in New Scientist in 1969 - one of those collected in \"The Inventions of Daedalus\" in 1982.\n \nreply",
      "Or this version to compare the raw recording v. after a bit of denoising: https://www.youtube.com/watch?v=_dbyIDTmHSMEDIT: or (allegedly) the whole collection of everything he recorded (or at least what survived to today): https://www.youtube.com/watch?v=uRbIJc05QTAEDIT 2: or some recordings as part of a writeup by the researchers: https://www.firstsounds.org/sounds/scott.php\n \nreply",
      "Thank you for saving me three minutes of my life to only hear some humming\n \nreply"
    ],
    "link": "https://www.bbc.com/reel/video/p0j7x5f7/listen-to-the-oldest-known-recording-of-a-human-voice",
    "first_paragraph": "Thomas Edison is often credited with being the first person to record sound. But it was in fact a Frenchman named Edouard-L\u00e9on Scott de Martinville who invented sound recording via his phonautograph in 1857, 20 years before Edison invented his phonograph.Video by Sanjana BhambhaniAhead of the Paris Games, we find out how one country has managed to win eight of the last nine gold medals.A new network along the Seine in Paris will broadcast Olympic festivities from the river.Could we be seeing the return of the \u2018dumbphone\u2019?A peak inside\u00a0both the real and virtual new Aquatic Centre built for the Paris Games.One small piece of coaching wisdom made a difference and led her to victory.We explore the range of health benefits linked to cold water swimming.The 'Shahmaran', half-woman and half-snake, is a mythical figure popular in the folklore of Turkey. Ranked among the all-time greats in long jump,\u00a0Jackie Joyner-Kersee shares memories of how it all started.Tunnel building began in the 1960s a",
    "summary": "**Historical Voices: Mostly Static, Definitely Not HD**\n\nThe internet gathers to feign shock and awe at the oldest known recording of a human voice, apparently missing the point that just because something is \"the oldest\", doesn't necessarily imply it's worth hearing. Watch enthusiasts pretend to marvel at the scratchy cacophony of history, while commentators compete to showcase more obscure and equally indecipherable audio clips from the past. One astute scholar suggests skipping the first three minutes of soul-crushing preamble\u2014advice that could well apply to the entire historical audio recording endeavor. Meanwhile, another commenter helpfully ruins everyone\u2019s nostalgia by reminding us that even The X-Files admitted it was all probably a hoax. \ud83c\udf99\ufe0f\ud83d\udc7b"
  }
]