[
  {
    "title": "1 bug, $50k in bounties, a Zendesk backdoor (gist.github.com)",
    "points": 944,
    "submitter": "mmsc",
    "submit_time": "2024-10-12T11:55:12.000000Z",
    "num_comments": 293,
    "comments_url": "https://news.ycombinator.com/item?id=41818459",
    "comments": [
      "Reported this exact bug to Zendesk, Apple, and Slack in June 2024, both through HackerOne and by escalating directly to engs or PMs at each company.I doubt we were the first. That is presumably the reason they failed to pay out.The real issue is that non-directory SSO options like Sign in with Apple (SIWA) have been incorrectly implemented almost everywhere, including by Slack and other large companies we alerted in June.Non-directory SSO should not have equal trust vs. directory SSO. If you have a Google account and use Google SSO, Google can attest that you control that account. Same with Okta and Okta SSO.SIWA, GitHub Auth, etc are not doing this. They rely on a weaker proof, usually just control of email at a single point in time.SSO providers are not fungible, even if the email address is the same. You need to take this into account when designing your trust model. Most services do not.\n \nreply",
      "Can you explain a bit more what makes Sign in with Apple different from Google Sign-in? Apple certainly does maintain a list of users with accounts. So what does \"non-directory\" mean here exactly? Why can Apple not attest that you control that account at sign-in time?\n \nreply",
      "Presumably one of the PMs you\u2019re referring to has posted this article for additional information. Feels like they\u2019re doubling down on their initial position.https://support.zendesk.com/hc/en-us/articles/8187090244506-...\n \nreply",
      "> Although the researcher did initially submit the vulnerability through our established process, they violated key ethical principles by directly contacting third parties about their report prior to remediation. This was in violation of bug bounty terms of service, which are industry standard and intended to protect the white hat community while also supporting responsible disclosure. This breach of trust resulted in the forfeiture of their reward, as we maintain strict standards for responsible disclosure.Wow... there was no indication that they even intended on fixing the issue, what was Daniel hackermondev supposed to do? Disclosing this to the affected users probably was the most ethical thing to do. I don't think he posted the vulnerability publicly until after the fix. \"Forfeiture of their award\" -- they said multiple times that it didn't qualify, they had no intention of ever giving a reward.\n \nreply",
      "As someone who manages a bug bounty program, this kind of pisses me off.For some of our bugs given on h1, we openly say, \"Hey, we need to see a POC in order to get this to be triaged.\"  We do not provide test accounts for H1 users, so, if they exploit someone's instance, we'll not only take the amount that the customer paid off of their renewal price, we'll also pay the bounty hunter.\n \nreply",
      "Indeed, they never had any intention of awarding a bounty.Heads I win, tails you lose.\n \nreply",
      "Fwiw, I wouldn't be surprised if the author of this article is a bit upset that Daniel hackermondev gained a significant % of the income that the author makes a year. If this was \"fixed\" by Zendesk, they would have paid less than a few % from the 50k they actually made.Edit: to those downvoting, the fact of the matter is that Zendesk's maximum bounty is far lower than 50k; yet OP made 50k; meaning by definition the value of the vulnerability was at least 50k.\n \nreply",
      "Wow. I am probably more sympathetic than most to arbitrary bug bounty rules having seen the quantity of junk that comes in, but this is one of the worst responses I've seen.If you're going to run a bug bounty program, you absolutely must be able to recognize when the person you're talking to is giving you a serious vulnerability, and must be willing to admit a mistake rather than endlessly doubling down on technicalities like this.It really is not hard to recognize when the bug bounty report you're getting is real. They look very different than the junk reports (the person replying can actually articulate details about the issue, whereas junk reporters handwave in generalities and repeat nonsense from vulnerability scanners which they obviously don't understand). Based on the how well-written the OP is, it's hard to see how anyone competent could not identify their report as a real issue and not just blindly pattern-match it against a SPF/DKIM/whatever rule exception.I would be embarrassed and ashamed to put my own name on this response.\n \nreply",
      "So when the researcher said it was a bug, they said, \"No, it's fine. No bug bounty, sorry.\"THEN the researcher eventually goes public.Later, Zendesk announces the bug and the fix and says there will be no bug bounty because the researcher went public.Is that how it went? I mean if so, that's one way to save on bug bounties.\n \nreply",
      "> THEN the researcher eventually goes public.He should have said since its not going to be fixed, he will just inform the individual companies.\n \nreply"
    ],
    "link": "https://gist.github.com/hackermondev/68ec8ed145fcee49d2f5e2b9d2cf2e52",
    "first_paragraph": "\n        Instantly share code, notes, and snippets.\n      hi, i'm daniel. i'm a 15-year-old with some programming experience and i do a little bug hunting in my free time. here's the insane story of how I found a single bug that affected over half of all Fortune 500 companies:If you've spent some time online, you\u2019ve probably come across Zendesk.Zendesk is a customer service tool used by some of the world\u2019s top companies. It\u2019s easy to set up: you link it to your company\u2019s support email (like support@company.com), and Zendesk starts managing incoming emails and creating tickets. You can handle these tickets yourself or have a support team do it for you. Zendesk is a billion-dollar company, trusted by big names like Cloudflare.Personally, I\u2019ve always found it surprising that these massive companies, worth billions, rely on third-party tools like Zendesk instead of building their own in-house ticketing systems.As the saying goes, \u201cYou\u2019re only as strong as your weakest link.\u201d Since Zendesk "
  },
  {
    "title": "Exploring Typst, a new typesetting system similar to LaTeX (jreyesr.com)",
    "points": 169,
    "submitter": "judell",
    "submit_time": "2024-10-12T18:41:31.000000Z",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=41821361",
    "comments": [
      "I've moved all of my LaTeX-based content creation to Typst.It's:- Fast\u2014Compiling my books would take around 1 minute (I often had to compile twice due to indexing). With Typst, it takes less than 5 seconds.- Easy to write\u2014I actually don't write it, I wrote a bunch of Pandoc plugins to tweak the output from Pandoc (I write all my books in Jupyter these days, so lots of markdown).- Easy to read\u2014I've used LaTeX for years (and wrote a bunch of tooling around it) and still couldn't tell you when to use a { or a [. Typst is very readable.- Easy to script\u2014Okay, I did write some Typst the other day. I migrated my LaTeX-based invoicing system to Typst. I created a list of objects with pricing and count and was able to throw it into a table easily. It has less code than my LaTeX version, which was using a library, and is easier to read. (I did need to write a function to properly format $ because that doesn't exist. A few rounds with AI made that easy.)- Has great error messages\u2014If you've used LaTeX, you know what I mean.My needs are different from others, but I'm writing PDFs that need to be printed into a real book that looks professional. This includes front matter, footnotes, callouts, page numbers, page headers and footers, and indexes. I don't do a lot of math-heavy stuff, so I can't comment on that. And the widow/orphan support is a little weak.Otherwise, I'm happy to never use LaTeX again!\n \nreply",
      "With your experience of both, have you found that Typst has fewer issues with conflicting/non-commutative plugins than LaTeX does?Because that's where I lose the most time with LaTeX: packages often mess with the (piles of) global state in ways that sometimes conflict, and the only \"solution\" seems to be that, if you're very lucky, sometimes conscientious package authors will try to \"detect\" (through various hacks) whether some other known-conflicting package has already been loaded and adjust accordingly. I didn't see any mention in TFA of any module system or even local variables in Typst to contain this explosion of complexity, so I suspect it will be just as bad in this respect as LaTeX is once there are as many plugins available.\n \nreply",
      "In the very limited time I used typst it has been pretty amazing, but imho there is one missing feature that a LaTeX successor, but even more so, templating engine should have. \nCome up or adapt a format, that can defer certain styling decisions to the consumer of the document. Stuff like, font, font size, line spacing, citation style, double or single column, numeration style, etc.On a different note, we got to find a better way to exchange data than pdf reports. In my totally made up estimation about 10% of development time for enterprise software is spend on variations of these pdf templating tools and another 20% on extracting data from such generated pdfs.\n \nreply",
      "Real men use TeX or troff!\n \nreply",
      "I've been looking into it.\nIt's `blazingly fast` (aside from the rust joke, it really is way faster than latex), the syntax is more \"modern\", consistent, etc.The main problem is the popularity. It just does not have enough packages, at least for my use case.I mainly do a lot of equations (simple math), and a loooot of tikz (forest, circuitikz, pgfplots, etc.) [https://gitlab.com/vslavkin/escuela/-/tree/main/5to?ref_type...]\nI'm not a fan of tikz, but it's the only way to mantain the graphics homogeneous, clean, easily editable, compiled with the document and with links/references.\nCetz (the typst alternative) is years behind. \nI've been thinking of contributing, but tikz is really complex, and I don't have enough time ATM.Besides the typst packages, it also lacks the editor packages. I am an emacs user insert joke here, and I use AucTeX, which is a really great, and gigant package to edit latex (+cdlatex). AFAIK there's nothing like it for typst, which makes me way slower.Another thing is that they changed the math syntax. While the latex one wasn't perfect it was insanely popular, because of its use on markdown and a lot of pages (and this was thanks to mathjax iirc).The good thing is that something like latex or typst will always be needed, so there'll always people that want to have something like it; latex/tex isn't really great, and it has a really low entry bar.Maybe I'll switch when I have more time to study it and make packages. (It could be as soon as next year or a late as... never)\n \nreply",
      "> I use AucTeX, which is a really great, and gigant package to edit latex (+cdlatex)This is tangential, but have you any quick tips for someone looking to get started with AucTeX? I'm a comfortable Emacser who has started to occasionally think of some document I'd like to do in LaTeX (some maths questions for a student, or an overview of some topic). I've looked at AucTeX once or twice, and ran away thinking, oh, I'll do that some other time.What is the order of events? Should I make a few really basic LaTeX documents first with a terminal, and then try AucTeX?\n \nreply",
      "This is neat.  I've used Latex before, and it definitely suffers from poor ergonomics.  Both the language and tooling contribute to this.The selling point seems to be that this is more similar to Markdown.  That makes sense, Markdown is objectively more common and has more users than Latex.  I've used both, but Markdown way more often.Here's something I don't understand: it would be trivial to make Typst even more similar to Markdown, and yet it exists at some strange middle point in the language design space, arbitrarily far from Markdown.\n \nreply",
      "Well maybe it\u2019s good to make it clear that it isn\u2019t markdown to avoid confusion? Also Typst has less syntactic sugar which also has benefits.More generally, I am really impressed by Typst\u2019s abstractions. I have typset my whole PhD thesis in it without needing any external packages. It was so easy to use the basic building blocks and write a few extra functions for the rest.\n \nreply",
      "Is your template/source available by chance?\n \nreply",
      "Places I\u2019ve switched from LaTeX to Typst: My resume, research papers. Markdown was never a serious contender for my resume, since I want to control the rendering and the layout.Places I\u2019ve switched from Markdown to Typst: Slides. There are some okay Markdown-to-HTML solutions, but they have this unfortunate side-effect that you move the slides to some other computer, and something breaks in your rendering. PDFs ftw.\n \nreply"
    ],
    "link": "https://blog.jreyesr.com/posts/typst/",
    "first_paragraph": ""
  },
  {
    "title": "Two never-before-seen tools, from same group, infect air-gapped devices (arstechnica.com)",
    "points": 46,
    "submitter": "lisper",
    "submit_time": "2024-10-09T15:24:37.000000Z",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41788877",
    "comments": [
      "For many years I've just viewed all of my devices as possibly compromised. It's one of the reasons I've been very down on cryptocurrencies in general. I don't actually see USB as something that can maintain a true, robust airgap, because the amount of data transferred is not inspectable.In my view, the best use of an airgapped machine would be for storage of extremely dense and sensitive information such as cryptographic keys. Signing or encryption should be accomplished through an inspectable data channel requiring manual interaction such as QR codes. When every bit in and out of a machine serves a purpose, it's much less likely to leak.Example: show a qr code to a camera on the airgapped machine and get a qr code on the screen containing the signature of the data presented to it. There is very little room for nefarious code execution or data transmission.\n \nreply",
      "This is probably a decent use case for plain old serial. Interface via application defined TTY.On the other hand no matter the transport you\u2019re probably going to get owned by well known vulnerabilities in any software processing data from the internet-connected side, if you\u2019re using the air gap as an excuse to avoid patching or otherwise caring about secure coding practices.\n \nreply",
      "I'm imagining a \"secure slate\" you can carry between the computers, a tiny tablet with a camera, e-ink display, and replaceable batteries. It does nothing but snap a picture of a QR code and then (if error checking is OK) reproduces it on its own durable display. Add a write-protection switch that doubles as a cover on the camera-lens, and have it auto-blank when not in use.So you'd snapshot its QR code, hand-carry the slate to air-gapped Computer B, press a button to wake it up, brandish the \"copied\" QR code in front of B's camera, etc. Maybe even take one and (with careful labeling) put it into a safe, depending on how long you plan to store it.You could do something similar with a camera and thermal-paper printer, but then the physical artifact needs to be reliably destroyed by manual effort, as opposed to auto-erasure.\n \nreply",
      "For longer term storage use an analog camera to take pictures of the QR codes, then develop the film and store them in an airtight climate controlled vault. Bonus points if the film is designed to be very stable after developing. Maybe platinum prints with lots of error correction.\n \nreply",
      "It'd only take about 1000 QR codes to install vim!\n \nreply",
      "This is interesting. Another use for such a secure machine would be to enter text, eg highly controversial blog entries or erotic stories. Then any common computer or phone with a camera can be used to transfer the text using 2D barcodes.This would be a bit slow: say a barcode. If we assume a single barcode can hold 1500 characters (text twice as long as your comment), a blog entry may need 4-5 barcodes. Not undoable.Such a machine would not have a camera, WiFi, BT, or any input or output mechanism of any kind.\n \nreply",
      "Punchcards would be better. QR relies on machine vision. The camera would be running its own code.That said, cameras are more of a commodity.QR and typing: see TOTP tokens!\n \nreply",
      "Why would a QR be more safe from containing malware than another medium like USB drive?Is it just that the amount of data it holds is more constrained?\n \nreply",
      "The USB protocol gives the drive access to all (physical) memory on the machine. QR codes only encode text (usually a URL but it can be any text).\n \nreply",
      "I think you're describing WalletConnect without knowing it exists.\n \nreply"
    ],
    "link": "https://arstechnica.com/security/2024/10/two-never-before-seen-tools-from-same-group-infect-air-gapped-devices/",
    "first_paragraph": "\n        It's hard enough creating one air-gap-jumping tool. GoldenJackal did it 2x in 5 years.\n      Researchers have unearthed two sophisticated toolsets that a nation-state hacking group\u2014possibly from Russia\u2014used to steal sensitive data stored on air-gapped devices, meaning those that are deliberately isolated from the Internet or other networks to safeguard them from malware.One of the custom tool collections was used starting in 2019 against a South Asian embassy in Belarus. A largely different toolset created by the same threat group infected a European Union government organization three years later. Researchers from ESET, the security firm that discovered the toolkits, said some of the components in both were identical to those fellow security firm Kaspersky described in research published last year and attributed to an unknown group, tracked as GoldenJackal, working for a nation-state. Based on the overlap, ESET has concluded that the same group is behind all the attacks obser"
  },
  {
    "title": "FAA grants SpaceX Starship Flight 5 license (faa.gov)",
    "points": 31,
    "submitter": "cryptoz",
    "submit_time": "2024-10-12T21:39:57.000000Z",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41822910",
    "comments": [
      "Discussion (174 points, 5 hours ago, 131 comments) https://news.ycombinator.com/item?id=41820785\n \nreply",
      "I think the window opens in a few hours (?!?!) - that is, tomorrow morning 7am CT - for Flight 5, which should include an attempt to catch the booster with the tower.The discussion on r/spacex for the curious: https://old.reddit.com/r/spacex/comments/1g24daz/faa_grants_...\n \nreply",
      "\"Catch a falling star and put it in your pocket, Never let it fade away\"\n \nreply"
    ],
    "link": "https://drs.faa.gov/browse/excelExternalWindow/DRSDOCID173891218620231102140506.0001",
    "first_paragraph": ""
  },
  {
    "title": "Every bug/quirk of the Windows resource compiler (rc.exe), probably (ryanliptak.com)",
    "points": 63,
    "submitter": "nektro",
    "submit_time": "2024-10-11T22:47:22.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41814622",
    "comments": [
      "I was thinking `NOT (1|2)` and `NOT () 2` could make sense if the parser just has a `not_in_effect` flag that gets set to true when a `NOT` is encountered and then applies to the next integer as soon as one is parsed. So `NOT (1|2)` sets the flag, then starts parsing `(1|2)`. Once it's parsed the `1`, it notices a NOT is in effect so it applies it to the 1 as if it had just parsed `NOT 1` (which leaves 0 unchanged), then parses `| 2`, so the result is 2.`NOT () 2` would be the same logic. `)` signifies the end of an expression and thus evaluates to the current integral result, which is 0 (for the same reason that unary - is zero), and a NOT is in effect so it's treated as `NOT 0` which is a no-op (\"unset no bits\"). Then the next `2` makes the result `2`. This assumes that `x y` is parsed the same as `x | y` (maybe only if a `NOT` has been parsed at any point first) or as `y` (the same stack-like \"the last number that was parsed becomes the result\" behavior described in other items).This doesn't explain the `7 NOT NOT 4 NOT 2 NOT NOT 1 = 2` case though. If the parser just *sets* the `not_in_effect` flag when it encounters a `NOT` (instead of *toggling* it), then this would be `7 | NOT 4 | NOT 2 | NOT 1` which would be 0. If the parser does toggle the flag, this would be `7 | 4 | NOT 2 | 1` which would be 1 or 5. If the parser treats a `NOT` as ending the previous expression (if any), this would be `7 | NOT 0 | NOT 4 | NOT 2 | NOT 0 | NOT 1` which would be 0.\n \nreply",
      "I'm the author if anyone has questions\n \nreply",
      "Resinator's error messages look amazing! I also feel like I\u2019ve gained a lot of cursed but useless (to me) knowledge, so thanks for that. :-)I don't have a horse in this race, but regarding FONT resources, I would like to humbly suggest not supporting them at all. Radical, but from what you wrote, they do seem pretty weird and ripe for accidental misuse. Plus, they are obsolete and it seems like Resinator already intentionally diverges from rc.exe in a few cases anyway.\n \nreply",
      "Thanks!I'm actually pretty okay with where I've landed with FONT resources. The legwork has already been done in figuring things out, and with the strategy I've chosen, resinator doesn't even need to parse .fnt files at all, so the implementation is pretty simple (I wrote a .fnt parser, but it's now unused[1]).[1] https://github.com/squeek502/resinator/blob/master/src/fnt.z...\n \nreply",
      "That's a crazy amount of work and a crazy amount of quirks indeed. Very much illustrates a mindset where the user is at fault if they provide bad input - and development effort for everything was multiplied compared to today. In 1985, of course, nobody cared about things like security from untrusted inputs, and reproducible builds.My favourite bug from this list is that the compiler expands tabs to spaces in string literals and puts them at tab stops based on the string literal's horizontal position in the source file.I think that being able to directly define resource type 6 is not a bug. You got exactly what you asked for - an invalid resource. Crashing when loading it isn't a bug, either.I suppose that style flag arguments are parsed as |-separated lists of numeric or NOT expressions, rather than single expressions where | serves as bitwise-or.> If the truncated value is >= 0x80, add 0xFF00 and write the result as a little-endian u32. If the truncated value is < 0x80 but not zero, write the value as a little-endian u32.This is sign-extension: s8 -> s16 -> u16 -> u32. The examples below this also seem to have reversed the order of the input byte and the FF.Visual C++ 6, at least, includes a toolbar resource editor. IIRC it shows the toolbar metadata and the bitmap together in one editor, and you edit each button's image individually even though they are concatenated into one bitmap in the resource file.\"GROUPBOX can only be used in DIALOGEX\" might refer to some limitation other than the resource compiler. For example, perhaps Windows versions that don't support DIALOGEX also don't support GROUPBOX.A lot of them could be caused by memory safety errors. For example the fact that \"1 ICON {\" treats \"ICON\" as the filename is probably because the tokenizer doesn't set the Microsoft equivalent of yytext for tokens where it's not supposed to be relevant. Maybe it would even crash (null pointer) if { could be the first token (which it can't).\n \nreply",
      "Appreciate the added context!> |-separated lists of numeric or NOTNote that | is not the only operator that can be used in style parameters, & + and - are all allowed too.> perhaps Windows versions that don't support DIALOGEX also don't support GROUPBOXSeems possible for sure. From [1]:> The 16-bit extended dialog template is purely historical. The only operating systems to support it were the Windows 95/98/Me series.[1] https://devblogs.microsoft.com/oldnewthing/20040622-00/?p=38...> The examples below this also seem to have reversed the order of the input byte and the FF.Good catch, fixed\n \nreply"
    ],
    "link": "https://www.ryanliptak.com/blog/every-rc-exe-bug-quirk-probably/",
    "first_paragraph": "The above is just a small sampling of a few of the strange behaviors of the Windows RC compiler (rc.exe). All of the above bugs/quirks, and many, many more, will be detailed and explained (to the best of my ability) in this post.\nNote: If you have no familiarity with rc.exe, .rc files, or even Windows development at all, no need to worry\u2014I have tried to organize this post such that it will get you up to speed as-you-read.\nNote: If you have no familiarity with rc.exe, .rc files, or even Windows development at all, no need to worry\u2014I have tried to organize this post such that it will get you up to speed as-you-read.Inspired by an accepted proposal for Zig to include support for compiling Windows resource script (.rc) files, I set out on what I thought at the time would be a somewhat straightforward side-project of writing a Windows resource compiler in Zig. Microsoft's RC compiler (rc.exe) is closed source, but alternative implementations are nothing new\u2014there are multiple existing proje"
  },
  {
    "title": "Germany's 49-euro ticket resulted in significant shift from road to rail (mcc-berlin.net)",
    "points": 346,
    "submitter": "mpweiher",
    "submit_time": "2024-10-12T14:47:56.000000Z",
    "num_comments": 314,
    "comments_url": "https://news.ycombinator.com/item?id=41819481",
    "comments": [
      "Providing these \u20ac49 tickets requires an annual subsidy of around \u20ac3bn, on top of already substantial subsidies for the rail industry. If we accept that it reduces carbon emissions by 6.7 million tonnes per year, then that works out to \u20ac447 per tonne. That really isn't good value - most carbon abatement methods cost well under $100 per tonne.I do recognise that modal shift towards rail may have other positive externalities, but I don't know how to price any of them.https://www.iea.org/data-and-statistics/charts/ghg-abatement...\n \nreply",
      "Focusing on the cost-per-tonne for carbon reduction misses the broader value of railways. They're not just about reducing emission! They facilitate daily commutes, expand job opportunities, and help drive the economy. It\u2019s a subsidy for businesses too.\n \nreply",
      "Gp said they know about these other factors but doesn't know how to price them. Do you know a way?\n \nreply",
      "Doesn't having a car do this too?\n \nreply",
      "No. This is something Texas is having to come to terms with right now. Cars and roads only scale so much before you physically can't move more people fast enough even with more roads and more lanes. Rail scales way better.So Texas is pushing a high speed rail line that will allow people to commute 30-90min into a city from locations that currently are 1.5-3 hours away. And at that allow those people to commute to cities on either ends of the line while still being a relatively accessible commute for anyone in between the cities.And of course as great as that is, the rail line will be able to relatively trivially scale capacity by adding more trains to the same line at a rate far above massively expensive road expansion projects that cost comparable to the entire planned rail line.So if you want to grow past a certain density you do have to start switching to rail and higher density does mean more business opportunities and generally greater options for prosperity for the populations in the area.\n \nreply",
      "Good comment except for the first word. Obviously cars enable all sorts of movement and economic activity, so why not just admit it? The rest of your comment is just talking about how rail may do all those things to a greater extent than cars. You don\u2019t need to deny benefits of cars, it doesn\u2019t bolster your arguments. Better to just be honest and then extol the virtues of rail and other transportation methods.\n \nreply",
      "Having a car also entails massive subsidies; when taking that into account the all-in costs per unit traveled are basically always cheaper with rail.\n \nreply",
      "Anecdotally, I frequently take day (or weekend) trips to other European cities by rail. It is usually quicker than the roads but also crucially you can be productive on the train. If I had to drive my car there then I probably wouldn't bother.\n \nreply",
      "This reminds me of this Swedish office on a train https://www.youtube.com/watch?v=3HbrI3refig , made for a company which had an hour train commute from Stockholm. It's even got 8 telephone line (4 in and 4 out)!I guess a lot of people would use work booths/conference rooms on trains, but the price/profit has to work for both sides (the train company and users). As for trains, the old-fashioned 6 seater compartments offer more privacy for groups.\n \nreply",
      "Trains scale better than cars in dense areas and offer more than just emissions reductions. Good rail infrastructure is a big part of makes a large city world-class and improves everyday lives. Subsidizing trains is better than a lot of other uses of government funds.\n \nreply"
    ],
    "link": "https://www.mcc-berlin.net/en/news/information/information-detail/article/49-euro-ticket-resulted-in-significant-modal-shift-from-road-to-rail.html",
    "first_paragraph": "\n                            MCC analysis for the Ariadne energy transition project shows 30 percent more rail journeys. The announced increase in price to 58 euros per month undoes half of this.\n                        Cologne Central Station: tThanks to the 49-euro ticket, there are significantly more train journeys and much lower CO2 emissions.\n                                                    \n                                                        | Photo: Shutterstock/Dimitrios\n                                                    \n                                                    The state-subsidised 49-euro \u201dDeutschland-Ticket\u201d, which allows you to travel by local and regional bus and rail throughout Germany for a month, has led to a significant shift in traffic from road to rail. This has now been determined by a research team from the Berlin-based climate research institute MCC (Mercator Research Institute on Global Commons and Climate Change) for the Ariadne energy transit"
  },
  {
    "title": "Analyzing New Unique Identifier Formats (UUIDv6, UUIDv7, and UUIDv8) (scaledcode.com)",
    "points": 57,
    "submitter": "futurecat",
    "submit_time": "2024-10-09T13:57:55.000000Z",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=41788066",
    "comments": [
      "I am a big fan of the new uuid v7 format.It has the advantage of being a drop in replacement most places everyone uses v4 today. It also has the advantage over other specs of ulid in that it can be parsed easily even in languages and databases with no libraries because you just need some obvious substr replace and from_hex to extract the timestamp.  Other specs typically used some custom lexically sortable base64 or something that always needed a library.Early drafts of the spec included a few bits to increment if there were local ids generated in the same millisecond for sequencing.  This was a good fit for lots of use cases like using the new ids for events generated in normal client apps.  Even though it didn\u2019t make the final spec I think it worth implementing as it doesn\u2019t break compatibility\n \nreply",
      "There\u2019s already a 72-bit random part. That should be sufficient to address conflicts.Incrementing a sequence completely kills the purpose of a UUID, and requires serialization/synchronization semantics. If you need that, just use a long integer.\n \nreply",
      "If you have a billion users and they each generate 64 random 72-bit numbers, you have a ~63% chance of a collision.\n \nreply",
      "If they all did that in the same millisecond?",
      "What do you consider the purpose of a UUID?\n \nreply",
      "Asynchronous unique ID generation.\n \nreply",
      "You can have both asynchrony and sequence by encoding thread ID in the UUID too, and make the sequence a thread local state.\n \nreply",
      "I don\u2019t understand the part where monotonicity of UUIDs is discussed. UUIDs should never be assumed monotonic, or in a specific format per se. If you strictly need monotonicity, just use an integer counter. Let UUIDs be black boxes, and assume that v7 is just a better black box that deals with DB indexes better.\n \nreply",
      "The nice thing about them is you don\u2019t have to assume, though, because the version is baked into an octet. Does the 3rd field start with a 4? v4. 7? v7. Etc.Re: monotonicity, as I view it, v7 is the best compromise I can make with devs as a DBRE where the DB isn\u2019t destroyed, and I don\u2019t have to try to make them redesign huge swaths of their app.\n \nreply",
      "The part I'm talking about proposes \"counters\" in UUID, not just date/time.\n \nreply"
    ],
    "link": "https://blog.scaledcode.com/blog/analyzing-new-unique-id/",
    "first_paragraph": "I have written before about UUIDs and other unique identifiers. As a reminder UUIDs are 128-bit identifiers that strive for unique identifier generation without requiring the generation to be done in a centralized location. The specification for UUIDs was written in 2005 and is defined in RFC 4122. This specification has served the industry fairly well. Even so there have been many other mechanisms for generating unique identifiers to try to make up for the shortcomings of the original specification. Some of these shortcomings are the following:After reviewing 16 different community ID generation algorithms, the working group created this draft IETF document. It should be noted this is just a draft document that expires on December 25, 2022. There is a likelihood that there will be differences between the specification at the time of writing this post and what is finally accepted but it is still instructive to review (there have already been a handful of revisions of this document in t"
  },
  {
    "title": "Show HN: AOO \u2013 C++ library for real-time audio streaming and messaging (iem.sh)",
    "points": 27,
    "submitter": "spacechild1",
    "submit_time": "2024-10-12T20:32:47.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41822303",
    "comments": [
      "Hi Christof! Really interesting project! I have used your VSTPlugin before (and probably other stuff..).Have you tried AOO on embedded platforms e.g. Bela, RPi?Would you consider supporting bindings to other langs, e.g. Python? At iil.is we have an OSC package called iipyper and I'm curious what we could do with AOO in the Python ecosystem https://github.com/Intelligent-Instruments-Lab/iipyper\n \nreply",
      "Hi, nice to see you here :)> Have you tried AOO on embedded platforms e.g. Bela, RPi?Yes, AOO also works on embedded platforms! I managed to run AOO on the Olimex ESP32-ADF board (https://www.olimex.com/Products/IoT/ESP32/ESP32-ADF/open-sou...) to build low-cost wireless speakers that can be played directly from Pd or SC. With two cores @ 240 MHz, the ESP32 is not exactly a powerful chip :) Bela or RPi is no problem at all.> Would you consider supporting bindings to other langs, e.g. Python?Actually, that has been on my mind. C# and Java might also be worthwhile, in particular for mobile devices. I don't think I will have the time to do it myself in the near future, but if someone's interested in creating langauge bindings, I'm happy to assist! Since AOO also has a plain C interface, it shouldn't be a big deal.EDIT: the IIL looks amazing btw!\n \nreply",
      "They claim it will work on an ESP32. If it fits and runs decently there it will be nothing an RPi or Bela.\n \nreply",
      "It actually does run on an ESP32 :) And yes, it's really nothing for an RPi or Bela.\n \nreply",
      "This looks really interesting! Is there anything to stop it being used for video frames as well as audio? Any war stories or interesting projects using it?\n \nreply",
      "Thanks!> Is there anything to stop it being used for video frames as well as audio?Generally, the library is aimed at audio applications and follows the typical model of audio plugins: there is a process() function that takes an array of audio buffers and is called by the host application in the audio callback.That being said, you could abuse the so-called \"stream message\" feature to embed images resp. video frames in the audio stream, but I'm not sure how practical that would be...  Someone should try it :)> Any war stories or interesting projects using it?Check out the section \"Use cases\" in my article: https://www.soundingfuture.com/en/article/aoo-low-latency-pe...\n \nreply"
    ],
    "link": "https://aoo.iem.sh/",
    "first_paragraph": "A lightweight and flexible peer-to-peer audio streaming and messaging library\u00a9 Licence GPLv2+."
  },
  {
    "title": "A mountain? Multistorey car park? Both? Inside Shanghai's \u00a3225M summit (theguardian.com)",
    "points": 23,
    "submitter": "PaulHoule",
    "submit_time": "2024-10-09T01:53:23.000000Z",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41783698",
    "comments": [
      "Maybe that's a sign that we have more cars than we can handle.\n \nreply",
      "Pretty ingenious way to hide a 1500 spot carpark underneath.Toronto is thinking of doing something similar, except to hide the downtown rail lines instead.\n \nreply",
      "If you can get natural light in people could live under the mound. Then you can have a city that looks like a park! People could quickly walk or cycle to where they need to go. Cars stay in tunnels.\n \nreply",
      "Sshhhh, you'll out the inner earth people.\n \nreply"
    ],
    "link": "https://www.theguardian.com/artanddesign/2024/sep/30/twin-hills-shanghai-nipple-mountains-multistorey-car-park",
    "first_paragraph": "It\u2019s got winding trails, a gushing waterfall, some 7,000 trees \u2013 and room inside for 1,500 cars. We explore the astonishing Twin Hills project, which isn\u2019t even the city\u2019s first manmade mountainscapeChina is no stranger to moving mountains. It has levelled hundreds of peaks in Gansu for urban expansion, blasted away hills in Yunnan to build railway stations, and bulldozed bluffs in Hubei for economic development zones. This insatiable lust for terraforming is simply a case of the authorities doing their duty to the Communist party. After all, Chairman Mao was fond of quoting the parable of Yu Gong, a plucky old man who decided to dig up two mountains, stone by stone, that blocked the path from his house, to illustrate the power of perseverance.\u201cTwo big mountains lie like a dead weight on the Chinese people,\u201d Mao told the national congress in 1945, citing the fable. \u201cOne is imperialism, the other is feudalism. The Chinese Communist party has long made up its mind to dig them up. We must"
  },
  {
    "title": "Washington's 'Forgotten Giant' Volcano Stirs: Surge in Quakes Prompts Monitoring (gizmodo.com)",
    "points": 6,
    "submitter": "rbanffy",
    "submit_time": "2024-10-09T18:40:13.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://gizmodo.com/washingtons-forgotten-giant-volcano-stirs-surge-in-quakes-prompts-increased-monitoring-2000509873",
    "first_paragraph": ""
  },
  {
    "title": "How I animate 3Blue1Brown [video] (youtube.com)",
    "points": 609,
    "submitter": "Tomte",
    "submit_time": "2024-10-12T13:06:31.000000Z",
    "num_comments": 121,
    "comments_url": "https://news.ycombinator.com/item?id=41818779",
    "comments": [
      "3B1B is doing god's work. May his tribe increase!!I personally have benefited enormously from so many of his YT videos. I wish this is how Mathematics was taught in high-schools, Engg schools.<3 <3\n \nreply",
      "It wouldn\u2019t work for the vast majority of students.  There\u2019s a reason we teach things the way we do.\n \nreply",
      "Haha, the way maths is taught at university hasn't changed in centuries.Let's not pretend this has all been figured out and perfected. Heck, most maths professors I encountered in my studies could trace their scientific lineage straight back to C.F.Gauss[1] and that's how they taught. Don't get me wrong, some were great teachers, others not so much, but there are valid alternatives to the classic lecture.[1] https://www.mathgenealogy.org/index.php\n \nreply",
      "What are those valid alternatives that work at scale for a majority of the population?\n \nreply",
      "The traditional lecture does have a lot of value, however, we are also quite certain that the instructional experience can be improved through the addition of visualizations and simulations. This is especially true for interactive visualizations where the learner can ask, \"What if ...\", experiment, and see the results of their interactions.The lecture format is very old and would not have persisted if it didn't provide a good value. At the same time, it's age also implies that there is room for improvement.\n \nreply",
      "The vast majority of students never ask, \u201cwhat if\u2026\u201d  The vast majority just want to know the mechanics of doing the problems well enough to pass the test.  At the time a student is taking Calculus 1 they don\u2019t ask questions about why it works.  They just want to know, for instance, the rules of differentiation.  Later in life, when they have intellectually matured, videos like 3Blue1Brown are interesting and fascinating.  The vast majority of students would not learn well from 3Blue1Brown type videos.\n \nreply",
      "The lecture format has only been competing with high-production-values video for a decade or two, and with interactive examples for much less than that.\n \nreply",
      "If you\u2019ve experienced that one great teacher that inspired genuine interest in a subject where you previously had none? It\u2019s historically hard to scale, but I think that\u2019s the potential here and it\u2019s a subject that a lot of people lack interest in but has wide reaching impact\n \nreply",
      "> There\u2019s a reason we teach things the way we doIs it that nobody kwen how to make good videos before? Or do you mean that teaching cannot be improved?\n \nreply",
      "The Gutenberg Method of teaching acknowledges the existence of the printing press and suggests one person standing at the front telling everyone what to write down may be outdatedhttps://www.physics.utoronto.ca/~key/PHY1600/PER%20Papers/Ef...\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=rbu7Zu5X1zI",
    "first_paragraph": ""
  },
  {
    "title": "The Explore vs. Exploit Dilemma (nathanzhao.cc)",
    "points": 8,
    "submitter": "nzhaa",
    "submit_time": "2024-10-12T04:58:10.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41816542",
    "comments": [
      "A wonderful treatise on the same topic, \u201cReinforcement Learning Bit by Bit\u201d, for anyone looking for a more advanced treatment of explore/exploit.https://arxiv.org/abs/2103.04047\n \nreply",
      "See also Thompson sampling[+] for a different approach to multi-armed bandits that doesn't depend on explicitly distinguishing between explore-exploit.[+] https://en.wikipedia.org/wiki/Thompson_sampling\n \nreply"
    ],
    "link": "https://nathanzhao.cc/explore-exploit",
    "first_paragraph": "I often analogize some real-world problems according to their ML-related counterparts. One of them is the exporation-exploitation problem, but it\u2019s often been met with minimal recognition. I wrote this blog as something I can refer to the next time I get a \u201cwhat do you mean?\u201dSuppose we have a series of decisions to make, each with the potential to yield a reward. In our multi-armed bandit problem, we aim to develop a strategy to maximize this reward over time. We envision each \u201carm\u201d as a slot machine, each one hiding a different reward distribution. Our task is to identify which arm to pull at each step in time to accumulate the most reward.If we consider t=0t=0t=0 as our starting state\u2014knowing nothing about the reward distributions\u2014and t=1t=1t=1 as the ideal state\u2014where we have complete knowledge of the best arm\u2014then we can define a function between ignorance and an optimal selection. In this framework, we can imagine a vector field guiding us from exploring new arms to exploiting the"
  },
  {
    "title": "DuckStation (github.com/stenzek)",
    "points": 112,
    "submitter": "tosh",
    "submit_time": "2024-10-12T10:22:31.000000Z",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=41818057",
    "comments": [
      "As much as I like duckstation and am glad that its source code remains publicly available, its move from GPL-3 to a highly restrictive no-derivative license last month [0] means that supporting new platforms or features or fixing bugs that might pop up on new versions of OS can't be adapted to the latest versions of the code.Changing the license will only hurt the legitimate interested parties of the future, as nefarious people who fork and rebrand and charge for such programs have a tendency to be unscrupulous and don't care what the license says. It does help with filing claims, but that can be wack a mole.It would be nice if they would grant non-commercial non-monetary derivatives at least,  so people who want to fix code after the author moves on can do so in an honorable manner.Another solution might be perhaps a termination clause saying that after some multiple of 5 years that it will revert to GPL-3 again. So at least if the worst happens the software can live on.[0] https://github.com/stenzek/duckstation/commit/7f4e5d55dbdef5...\n \nreply",
      "Last version that you can download/fork before the license change commit https://github.com/stenzek/duckstation/tree/25bc8a64803df7e7...\n \nreply",
      "Use https://github.com/stenzek/duckstation/commit/6d3b177714eb0c... The commits after that were to remove GPL code before the license change.\n \nreply",
      "I am not familiar with this project, but I am an expert in free and open source licensing, and in this context there are some irregularities.molticrystal points out the commit in which the licence is 'changed'. Some files which were previously labelled as being dedicated to the public domain ('Unlicense') are now indicated as being under the Creative Commons Attribution-NonCommercial-NoDerivatives International License, version 4. This an is untrue statement at the specific commit, because work in the public domain cannot be copyrighted (this is a simplification, but substantively true). However, it will become a true statement and thus legally significant as and when new, original code is added in future commits, as this would be copyrightable.More importantly, there are other files which previously contained this declaration:  // SPDX-License-Identifier: (GPL-3.0 OR CC-BY-NC-ND-4.0)\n\nThis, expressed in the ISO standard SPDX syntax, means that the copyright holder(s) allow copying under the terms of either the GNU General Public License version 3 or the aforementioned Creative Commons licence.Contributors to the project generally continue to hold copyright to their commits under the 'inbound-outbound' doctrine, and this is reinforced by the GitHub terms of service. That means that the main author has to respect the licence terms too.Here's the problem: by changing the licence of the whole program to only the Creative Commons BY-NC-ND, they have to have violated one of the two original options. If they use their rights from the GPL, they must retain the GPL option for others (copyleft principle); if they use their rights from the CC-BY-NC-ND-4.0 licence, they cannot make derivative works so won't be allowed to continue developing the project!All in all, this is just yet another case of 're-licensing' a formerly free and open source project that has no grounds in law. More positively, it is also therefore another case of the inbound-outbound effect of collaborative development strengthening FOSS.\n \nreply",
      "What confused me was that the project is still using the Qt framework. Is that compatible with the new license?\n \nreply",
      "Yes, Qt is LGPL except for a few plugins that are GPL.\n \nreply",
      "It doesn\u2019t even properly address the original problem. Originally, this was stated to be in response to people \u201cstealing\u201d the source code, making low quality Android ports (without releasing source code), and users coming to the official channels to complain about problems unique to the Android versions. A license change does not in any way stop that, instead it only alienates those who wish to support development and yet now are seemingly disallowed from even contributing due to the weird licensing.\n \nreply",
      "Should open source contributors start including license terms with every commit? Or at least an SPDX identifier.\n \nreply",
      "I'd rather use the fork that's still open source (GPLv3), or any other open source PS1 emulator such as PCSX2's ps1 support.\n \nreply",
      "DuckStation + $50 Xbox wireless controller + MacBook Air = I\u2019m not buying a PS5 anytime soon\n \nreply"
    ],
    "link": "https://github.com/stenzek/duckstation",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fast PlayStation 1 emulator for x86-64/AArch32/AArch64/RV64\n      Features | Downloading and Running | Building | DisclaimersLatest Builds for Windows 10/11 (x64/ARM64), Linux (AppImage/Flatpak), and macOS (11.0+ Universal): https://github.com/stenzek/duckstation/releases/tag/latestGame Compatibility List: https://docs.google.com/spreadsheets/d/e/2PACX-1vRE0jjiK_aldpICoy5kVQlpk2f81Vo6P4p9vfg4d7YoTOoDlH4PQHoXjTD2F7SdN8SSBLoEAItaIqQo/pubhtmlDiscord Server: https://www.duckstation.org/discord.htmlDuckStation is an simulator/emulator of the Sony PlayStation(TM) console, focusing on playability, speed, and long-term maintainability. The goal is to be as accurate as possible while maintaining performance suitable for low-end devices. \"Hack\" options are discouraged, the default configuration should support all playable games with only some"
  },
  {
    "title": "First Greenhouse Gas Plumes Detected with NASA-Designed Instrument (nasa.gov)",
    "points": 77,
    "submitter": "mywacaday",
    "submit_time": "2024-10-12T20:35:24.000000Z",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41822321",
    "comments": [
      "And this is exactly why _they_ don't want NASA pointing back to Earth... And why they want them to only have enough funding for the megaprojects that redirect federal money into red states.\"There's nothing to see here! Move along!\"But really, I'm glad they managed to get this out there despite the political shenanigans. It looks like they manage their own shenanigans by providing information / assistance, while not actually doing the leg work on building it or deploying it...It will help to eventually find the hotspots (which, if in the US, are likely businesses skirting laws for profit... Or poor monitoring by the business). In either case, we can have more information on where to act.\n \nreply",
      "I see where you\u2019re coming from, but the reality is not as stark as you have put it. The forces you point to are real, but it\u2019s more complex because many people have seen the value in learning about Earth.A huge reason we have a NASA Earth observing system (and not just weather satellites) is the studies that grew out of the CFC damage to the ozone layer [1]. Ground stations and aircraft and balloons turned out not to be enough to assess it, so the measurements moved to space and use spectroscopy now.(The current fleet: https://science.nasa.gov/earth-science/missions/)This has led to comprehensive CO2 observation from space, and sea surface temperature, and many other climate-related measurements including methane. All this goes back many decades at this point. It\u2019s not a few people who managed to launch one satellite![1] For short, https://en.wikipedia.org/wiki/Earth_Observing_System#History..., but see also: https://muse.jhu.edu/book/3472\n \nreply",
      "What specifically are the \u201cpolitical shenanigans\u201d? Do you have any evidence/links?I personally don\u2019t think studying earth is really what I want out of NASA. I would expect that funding to go towards study of space. For Earth, I would view that as more the job of the EPA or some other agency, and think it\u2019s more appropriate for them to set aside funds for a satellite or whatever they need.But yes it\u2019s interesting to see where there are unexpected plumes. I suspect a lot of those are in third world countries where regulations and rule of law is worse, and it may be hard to address those effectively (except by subsidizing them). Sure there are some examples in the US, but the ones in the article seem much smaller in magnitude.\n \nreply",
      "You are getting a well-deserved correction to your ignorance of political forces that might result from perceived threats to the oil and gas industry.I want to comment on a separate thing, about responsibility for the measurement, that\u2019s in your second paragraph.Developing the spectroscopic measurement of methane from space took a lot of time and engineering skill. (I happened to observe some of this work as part of $dayjob.) In the US, the responsibility for developing novel space measurement technology has historically gone to NASA.It is proven in space (raised to \u201cTRL 9\u201d in the jargon) by NASA, and then transitioned to other sectors, like NOAA or USGS, for operational use.  The prioritization and maturation is very well developed at this point.Part of the reason it rests with NASA is that systems for spectroscopic measurement of gases (in this example) are also used for other space missions, e.g. planetary and astrophysics.  For instance, some of the team of this methane instrument overlaps with the MISE team that will use spectroscopy for Europa https://europa.nasa.gov/spacecraft/instruments/mise/). Besides sharing personnel and knowledge, I believe some of the sensor hardware for MISE and for that in OP was fabricated at the same facility.\n \nreply",
      "Depending on who wins the election, but one party has made publicly known that they will specifically defund or worse the agencies that will report this kind of information. What other examples of political shenanigans do you need? The same party that when they were in office removed the ability of these same agencies from making these type of releases to the point that they created \"rogue\" social media accounts.\n \nreply",
      "> one party has made publicly known that they will specifically defund or worse the agencies that will report this kind of informationEvidence on the specific claim you\u2019re making? Defunding government agencies for savings or efficiency is not the same as trying to defund things specifically to hide certain scientific data with some sinister goal.> What other examples of political shenanigans do you need?I\u2019m looking for evidence that supports the GP\u2019s claim. Are there political acts that redirected money from NASA into red states, with an intent to funnel funding based on that political leaning? Is there evidence that they tried (and succeeded?) interfering with specific projects on the grounds that it would show pollution sources that are politically problematic (as opposed to simply defining NASA\u2019s mission as studying things outside of earth)?\n \nreply",
      "The US has been through exactly this before:(2016):     On space issues, a senior Trump advisor, former Pennsylvania Rep. Bob Walker, has called for ending NASA earth science research, including work related to climate change. Walker contends that NASA\u2019s proper role is deep-space research and exploration, not \u201cpolitically correct environmental monitoring.\u201d\n\n~ https://theconversation.com/eyes-in-the-sky-cutting-nasa-ear...(2018) Trump White House quietly cancels NASA research verifying greenhouse gas cuts~ https://www.science.org/content/article/trump-white-house-qu...And, again, NASA's mission is assisted by testing instrument designs from space on the only planet we have complete surface access to .. otherwise it's just diddling about with remote guesswork sans ground truthing.\n \nreply",
      "The tragedy of MAGA is that this is the tragedy of the commons in an adversarial setting, where some members are actively trying to destroy the commons to gain political power. Add to that foreign power interference to finance helpful idiots and it\u2019s not surprising that even obvious common goods, like triaging where accidental greenhouse gas leakage happens are treated adversely.\n \nreply",
      "I imagine the foreign agencies running these interference campaigns as caricatures sipping champagne/cognac/etc, cigar smoking, fully belly laughing that is occurring in all of these places at how little effort is being expelled on their part causing so much chaos on our part.",
      "https://en.wikipedia.org/wiki/Project_2025Just defunding agencies from reporting science is bad enough regardless of where they move the money. Denying the part because it's not the whole of what you're looking for says more about you than anything else.\n \nreply"
    ],
    "link": "https://www.jpl.nasa.gov/news/first-greenhouse-gas-plumes-detected-with-nasa-designed-instrument/",
    "first_paragraph": "On Sept. 19, the imaging spectrometer on the Carbon Mapper Coalition\u2019s Tanager-1 satellite detected this methane plume in Karachi, Pakistan, extending nearly 2\u00bd miles (4 kilometers) from a landfill. The spectrometer was designed at NASA JPL.Extending about 2 miles (3 kilometers) from a coal-fired power plant, this carbon dioxide plume in Kendal, South Africa, was captured Sept. 19 by the imaging spectrometer on the Carbon Mapper Coalition\u2019s Tanager-1 satellite.This methane plume was captured south of Midland, Texas, in the Permian Basin, one of the world\u2019s largest oil fields. The imaging spectrometer on the Carbon Mapper Coalition\u2019s Tanager-1 satellite made the detection on Sept. 24.The imaging spectrometer aboard the Carbon Mapper Coalition\u2019s Tanager-1 satellite identified methane and carbon dioxide plumes in the United States and internationally.Using data from an instrument designed by NASA\u2019s Jet Propulsion Laboratory in Southern California, the nonprofit Carbon Mapper has released "
  },
  {
    "title": "Google Ads announces 11-year data retention policy (searchengineland.com)",
    "points": 18,
    "submitter": "vednig",
    "submit_time": "2024-10-12T23:15:26.000000Z",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=41823582",
    "comments": [
      "Anyone from the Google Ads team here on HN? I am struggling with Kafkaesque warnings inside of my account after using the Shopify Google Ads app (which apparently opened a second/duplicate Google Ads account), resulting in warnings about \"circumventing systems\" due to having 2 accounts for the same business. I just want to sell the car parts I make in my garage as a hobby online, but Google doesn't make it easy...Any Google Ads team members who might be able to help, I'd happily donate to your favorite charity (or send you some parts for 1982-1992 Chevrolet Camaro's), my username @gmail.com is my contact info\n \nreply",
      "That's significantly longer than I would have expected. That's longer than the retention policy on my work emails, and this is data for ads...?\n \nreply",
      "Can your work emails be used to promote candidates in elections? Long ads data retention seems reasonable to me.\n \nreply",
      "Different countries have different laws around financial transaction data retention. US laws allow for audit up to 10 years, so they made it 11 to be safe yes?\n \nreply",
      "That is the duration some of us have been using web for, as a reference.\n \nreply",
      "\"will not be returned\"Doesn't sound like a retention policy.\n \nreply",
      "Google\u2019s own announcement uses more straightforward language saying that data won\u2019t be retained.https://ads-developers.googleblog.com/2024/10/new-data-reten...\n \nreply",
      "So that means lifetime, really.  Pointless.\n \nreply",
      "No it just means they now keep the data only as long as they are required to by law.\n \nreply",
      "I think it was indefinite before...\n \nreply"
    ],
    "link": "https://searchengineland.com/google-ads-11-year-data-retention-policy-447465",
    "first_paragraph": ""
  },
  {
    "title": "Lake Michigan Stonehenge \u2013 What have researchers learned? (illinoisfishinghub.com)",
    "points": 55,
    "submitter": "janandonly",
    "submit_time": "2024-10-09T20:03:58.000000Z",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41792046",
    "comments": [
      "Not convinced this is anything at all.  Where's some clearer pictures?  Where's a diagram of the circles?and sure enough from the man himself.https://holleyarchaeology.com/index.php/the-truth-about-the-...> For example, there is not a henge associated with the site and the individual stones are relatively small when compared to what most people think of as European standing stones. It should be clearly understood that this is not a megalith site like Stonehenge.\n \nreply",
      ">The site in Grand Traverse Bay is best described as a long line of stones which is over a mile in length.... Dr. John O\u2019Shea from University of Michigan has been working on a broadly similar structure over in Lake Huron... [He] thinks that it may be a prehistoric drive line for herding caribou.... It is highly possible that the site in Grand Traverse Bay may have served a similar function to the one found in Lake Huron.So not like Stonehenge but seems interesting to me.\n \nreply",
      "Why is the baseline assumption that early humans were not as intelligent as we are now? I've never understood that. It seems like levers and rolling logs would be pretty easy to figure out, or what am I missing?\n \nreply",
      "That isn't the assumption. Modern archaeologists usually assume that ancient people were as intelligent as we are today, or even more so.What's not assumed is that they had the same thought patterns. People don't derive ideas uniformly from the space of all possible ideas, they tend to think within the constraints and realities of past experiences. If you build a house, it's going to be similar to houses you've seen before. If you paint a painting, it's going to be a painting rather than some other means of expressing yourself with colored pigments.In other words, ideas are subject to the same kinds of path dependence that technology is. When we see something that's severely anachronistic (outside of it's \"normal\" place in time), the initial priors are that things like the dating are wrong rather than ab initio invention of a whole suite of different ideas that just happened to be preserved for us.\n \nreply",
      "My view is on why that is the assumption is because anthropology seems to put a lot of pressure on higher level tasks only being achievable through some mass of individuals. The idea is that ancient people had a struggle to survive and deal with daily tasks, so they must not have had enough time to pursue advanced topics or even care to focus on them.\n \nreply",
      "You might like Graeber's book \"The Dawn of Everything\". He goes into some of the scientific historic reasons for why.\n \nreply",
      "There's also the assumption that humans in the Americas, prior to the mass arrival of Europeans, were primitive and did not form sophisticated societies like those found in the \"Old World\". I think this has been otherwise shown, but old assumptions die hard.\n \nreply",
      "The large American civilizations (Inca, Aztec, etc) were essentially bronze-age civilizations. Perhaps Europe would have been so as well had there not been a bronze-age collapse.\n \nreply",
      "You are missing nothing they used to do brain surgery.https://www.smithsonianmag.com/science-nature/in-roughly-150...\n \nreply",
      "How is a square hole in a skull conclusive evidence for brain surgery?\n \nreply"
    ],
    "link": "https://www.illinoisfishinghub.com/lake-michigan-stonehenge/",
    "first_paragraph": ""
  },
  {
    "title": "PayPal (USA) will automatically share data about you to participating stores (paypal.com)",
    "points": 190,
    "submitter": "xyst",
    "submit_time": "2024-10-12T20:19:32.000000Z",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=41822178",
    "comments": [
      "Privacy laws actually work! Let\u2019s pass more of them.> Information gathered about you after the effective date of our updated Privacy Statement, November 27, 2024, will be shared with participating stores where you shop, *unless you live in California, North Dakota, or Vermont.* For PayPal customers in California, North Dakota, or Vermont, we\u2019ll only share your information with those merchants if you tell us to do so\n \nreply",
      "In 1999 the show writers of the West Wing accurately predicated this in an episode about the selection of a Supreme Court Judge:\"It's not just about abortion, it's about the next 20 years. In the '20s and '30s it was the role of government. '50s and '60s it was civil rights. The next two decades are going to be privacy. I'm talking about the Internet. I'm talking about cell phones. I'm talking about health records and who's gay and who's not. And moreover, in a country born on the will to be free, what could be more fundamental than this?\"- Sam Seaborn (Rob Lowe) West Wing (ep: The Short List) 1999- We've seen massive breaches of EMR systems- We've seen massive breeahes from dating apps (Grindr) outing Gay individuals- None of these entities faced significant consequences for their actions and continue to operate with large amounts of profit.- 2 years after this episode the Patriot Act was passed. We've failed on privacy so far.\n \nreply",
      "The government has failed the constituents.Regulatory capture is still the highest ROI investment, and we should work on that.\n \nreply",
      "It's a perverse feedback loop.  The more power the .gov has to regulate the better the ROI of regulatory capture.'I'm not sure how we get out of this situation without it getting way worse.\n \nreply",
      "Imagine if the real government was as competent and good faith as the West Wing government\n \nreply",
      "This is so open faced and gross.  It reminds of someone talking about getting paid minimum wage.  If you get paid minimum wage, what your employer is saying is, \"I would pay you less if I was legally allowed to do so.\"It also reminds me of State Farm's (auto/home insurance in the US) website with this link at the bottom:> Do Not Sell or Share My Personal Information (CA residents only)\n \nreply",
      "Don\u2019t get mad, get active. Keep cranking on the policy ratchet, progress and success is clearly possible.\n \nreply",
      ">  If you get paid minimum wage, what your employer is saying is, \"I would pay you less if I was legally allowed to do so.\"The minimum wage is the government saying \"if you produce less value than this arbitrary cut off, you aren't allowed to work\".\n \nreply",
      "No it isn't, because wages aren't set based on some objective measurement of the quality of value produced. If that were the case, increases in productivity would have resulted in a commensurate increase in wages, but the only increase is the gap between wages and productivity.\n \nreply",
      "That's what Disqus has at the bottom of every of their comments section[0]. I find it ridiculous.[0] https://electricdusk.com/img/disqus-gdpr-violation-marketing...\n \nreply"
    ],
    "link": "https://www.paypal.com/us/legalhub/upcoming-policies-full",
    "first_paragraph": "Last updated on September 23, 2024Notice of Amendment(s) to the United States PayPal Agreement(s)\u00a0This PageThis page details and/or previews updates to PayPal users of changes to the United States PayPal User Agreement or other online agreements, policies, or statements that require notice.\u00a0You can also review Past Policy Updates notices. Note that additional changes could be made to previewed agreements on or before the\u202feffective\u202fdates listed, provided the applicable notice requirements are met.Upcoming ChangesWe\u2019re making changes to certain agreements (listed below) that govern your relationship with PayPal. These changes will take place automatically on the corresponding effective date(s) shown below.Actions NeededPlease carefully review the notices below and familiarize yourself with the upcoming changes. By continuing to use our services after the changes take effect, you agree to be bound by those changes. Otherwise, no further action is needed from you to accept such changes. Ho"
  },
  {
    "title": "Psilocybin bests SSRI for major depression in first long-term comparison (medscape.com)",
    "points": 413,
    "submitter": "Thomvis",
    "submit_time": "2024-10-12T11:46:44.000000Z",
    "num_comments": 286,
    "comments_url": "https://news.ycombinator.com/item?id=41818420",
    "comments": [
      "The results are based on a grand total of 25 people in the psilocybin group and 21 people in the SSRI group. The sample size is pretty small.The methodology is also kind of strange, the psilocybin group got a total of 20 hours of in-person therapy during their 'treatment' and 6 follow-up skype calls, whereas the SSRI didn't get anything other than the 6 month questionaire. Those 20 hours of personalized therapy while they were dosing had no effect on their psychology? Any change was all a result of the psilocybin and not the 20 hours of therapy?They also measured results by a self-administered 16 question \"quick inventory\" depression survey. To enter the study they had to be officially diagnosed with major depression by a doctor, but the results of the study were based completely around a self-reported 16 question questionaire?\n \nreply",
      ">The methodology is also kind of strange, the psilocybin group got a total of 20 hours of in-person therapy during their 'treatment' and 6 follow-up skype calls, whereas the SSRI didn't get anything other than the 6 month questionaire.They got 'matched' support, which reads to me as 'equivelent':\n\"Patients were randomly assigned (1:1) to receive either two 25 mg doses of the psychedelic drug psilocybin administered orally combined with psychological support (\u2018psilocybin therapy\u2019 or PT) and book-ended by further support or a 6-week course of the selective serotonin reuptake inhibitor (SSRI) escitalopram (administered daily at 10 mg for three weeks and 20 mg for the subsequent three weeks) plus matched psychological support (\u2018escitalopram treatment\u2019 or ET).\">They also measured results by a self-administered 16 question \"quick inventory\" depression survey. To enter the study they had to be officially diagnosed with major depression by a doctor, but the results of the study were based completely around a self-reported 16 question questionaire?This is only the follow up portion, and as secondary measure at 6 weeks. The original study (https://clinicaltrials.gov/study/NCT03429075) says the primary measure was; \"Change in blood oxygen level dependent (BOLD) signal during fMRI in response to emotional faces during an emotional faces paradigm done inside the fMRI scanner.\" at 6 weeks vs baseline.\n \nreply",
      "If that's true, I'm confused how this is a \"double-blind, randomized, controlled trial\"?Also, what's up with drug studies always having such a low sample size? Is it really that hard to find people who'd volunteer to get free drugs?\n \nreply",
      "> Also, what's up with drug studies always having such a low sample size? Is it really that hard to find people who'd volunteer to get free drugs?They try to make for no comorbidities and and for MDD that is pretty rare. It also means that we\u2019re often studying rare configurations compared to those commonly seen in actual practice. Statistics doesn\u2019t like confounding elements and humans are very confounding. So either you get \u201cbad\u201d statistics, or you get \u201cbad\u201d data. And why you have front line drugs that only have a helpful effect for 33% of people.\n \nreply",
      "Its expensive. Statistically speaking its really not that small.  You can always argue p hacking but these are always useful as a means to do further research\n \nreply",
      "Often you\u2019re not allowed on your medication for any of your other health issues.\n \nreply",
      "We need a new approach to randomly controlled trials.I propose a new approach:    Rather than given treatment vs not given treatment, we instead vary the dose slightly, and we include the whole world in the trial.Ie. instead of taking 100mg of Advil, instead you will receive somewhere between 95mg and 105mg of Advil.    You won't be told how much you got - but the barcode on the box will encode that info.    That already might be the case due to allowed inaccuracies, but now we're gonna measure and record it.Later, the data of which box was dispensed is combined with any other relevant medical records, and across the hundreds of millions of people involved, any benefit/disadvantage of a small increase or decrease in dose will become apparent.\n \nreply",
      "That's not generally how drugs work. There's wide margins on how much dose is required for clinically significant results. Not only is the 110 pouns petite woman taking the same dose of aspirin as a 400lb elite powerlifter, but the effects can't be quantified in high resolution. The woman can't say her pain was 5% less than the powerlifter, and they can't say their pain was 5% more.\n \nreply",
      "This doesn't sound very helpful\n \nreply",
      "I mean it sounds like a way to trick people into letting a giant company build a surveillance system, and I imagine aliens observing humans in this moment in history might conclude that's what we want, but for science or the benefit of the people \"surveyed\" it's mostly downsides\n \nreply"
    ],
    "link": "https://www.medscape.com/viewarticle/psilocybin-bests-ssri-major-depression-first-long-term-2024a1000h77",
    "first_paragraph": ""
  },
  {
    "title": "IcePanel (YC W23) is hiring full stack engineers in Vancouver (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-10-12T17:00:46.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/icepanel/jobs/rTmu6sL-senior-full-stack-software-engineer",
    "first_paragraph": ""
  },
  {
    "title": "Machine learning and information theory concepts towards an AI Mathematician (arxiv.org)",
    "points": 84,
    "submitter": "marojejian",
    "submit_time": "2024-10-12T18:18:56.000000Z",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41821179",
    "comments": [
      "I love that \"system 1\" and \"system 2\" are tossed out as fundamental concepts of mind when they're basically labels for some semi-random ideas based on bullshit studies in a pop sci fluff book. Is there any actual science that ties these ideas to mathematical reasoning?Then we have:>> By analogy, we can now state the main hypothesis proposed in this paper: a crucial component of the usefulness of a new proven theorem t (in the context of previous theorems T(S)) is how efficiently T(S)\u222a{t} compresses the set of all provable mathematical statements M. That is, T (S) \u222a {t} is a good compression of M if many provable statements, beyond those in S, can be derived from T (S) \u222a {t}, say using at most k derivation steps.which says \"Occam's Razor, that's good isn't it?\" in more words.\n \nreply",
      "I don\u2019t think that\u2019s really what Occam\u2019s razor says.If one\u2019s goal is to use ML stuff to try to produce new useful theorems, it seems useful towards that goal to come up with a numeric heuristic for how useful a new theorem is. And, stating such a heuristic explicitly seems reasonable.Just because the heuristic that they state, which they expect to be a crucial component of what makes a theorem useful to prove in a given context, isn\u2019t particularly surprising, doesn\u2019t make it not worth saying.to elaborate on \u201cisn\u2019t particularly surprising\u201d : if you asked many other people to come up with heuristics for the usefulness of a new potential theorem, I imagine many of the answers you would get (counting multiplicity if multiple people give identical answers) would be fairly similar.Even if a hypothesis is an obvious-to-consider hypothesis, if one wants to talk about it, it is worth stating what it is first.\n \nreply",
      "System 1 and 2 are just another way of describing dual process theory, which existed long before Daniel Kahneman  wrote, Thinking Fast and Slow, and is still the prevailing theory of mind in its category today. There were maybe 1 or 2 studies mentioned in that book that were not very replicable but other than that, the overall consensus by leading experts in that field is positive, from everything I've seen, which is impressive considering how old the book is now.I have no idea if dual process theory is actually useful for teaching computers how to math, but it seems unfair to just dismiss it as pop science bunk.https://en.m.wikipedia.org/wiki/Dual_process_theory\n \nreply",
      "> ...which is impressive considering how old the book is now.The human mind hasn't changed all that much in the last ... countless millennia. If anything it'd be a quite concerning data point if we hadn't nailed down the introductory level points about how to be thoughtful.\n \nreply",
      "> I love that \"system 1\" and \"system 2\" are tossed out as fundamental concepts of mind when they're basically labels for some semi-random ideas based on bullshit studies in a pop sci fluff book. Is there any actual science that ties these ideas to mathematical reasoning?I think this fails to hit the mark on what people actually care about with regards to system 1 vs system 2. It\u2019s really just, can we build models that are able to vary how long they think about a problem? Current AI models are very limited in this aspect and I think most would agree that being able to think about a problem for a period of time is a useful feature that we humans use all the time.\n \nreply",
      "I feel that here the authors think about mathematics as just the language and not what it talks about. We know at least since G\u00f6del that mathematics is more than just the formal system. I even remember going to a talk by Gromov and he getting \"angry\" about a question from the public in the lines of \"what if we suppose this extra thing and change this other thing on that theorem\", and him saying that it's stupid to think of new theorems for the sake of doing it, that the language of mathematics are like metaphors speaking about something else.In my experience learning math, their claim that \"The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length\" is not true. Short != Better, better is what gets me faster to form the correct intuitive idea about the mathematical statement. For example, several times I have experienced the fact of understanding the formal definitions and proofs of a theory, but it's not until I form the correct intuitions (maybe months later), that I truly understand the theory. And it's not until I have the correct intuitions, that I can successfully apply the theory to create meaningful new theorems.Anyways, I understand that one has to start from somewhere and the point of view of the article is more tractable and explicit.\n \nreply",
      "I found this to be an interesting read, though it's just a high-level plan, vs. breaking new ground. I like how the ideas are synthesized.A fun detail is to be found in a footnote: \n\"A mathematician is a person who can find analogies between theorems; a better mathematician is one who can see analogies between proofs and the best mathematician can notice analogies between theories. One can imagine that the ultimate mathematician is one who can see analogies between analogies.\u201d (attributed to Stefan Banach in\nRandrianantoanina and Randrianantoanina [2007]).And reading this, it seems to me this implies the \"ultimate\" mathematician is a poet.P.S. I initially assumed \"Randrianantoanina and Randrianantoanina\" was the title of  some nerdy speculative fiction.  It turns out this is a regular paper reference.  The authors are Malagasy, no doubt. They have such cool names there.\n \nreply",
      "> P.S. I initially assumed \"Randrianantoanina and Randrianantoanina\" was the title of some nerdy speculative fiction. It turns out this is a regular paper reference. The authors are Malagasy, no doubt. They have such cool names there.Given what else Banach is famous for, I assumed a Banach\u2013Tarski joke.\n \nreply",
      "> it seems to me this implies the \"ultimate\" mathematician is a poet.And, conversely, that the best mathematical theorems read like beautiful poetry.\n \nreply",
      "> the \"ultimate\" mathematician is a poet.Approximately, but not actually, a member of the set of poets.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2403.04571",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  }
]