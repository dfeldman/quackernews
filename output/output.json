[
  {
    "title": "You wouldn't steal a font (rib.gay)",
    "points": 684,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-23T19:42:36 1745437356",
    "num_comments": 193,
    "comments_url": "https://news.ycombinator.com/item?id=43775926",
    "comments": [
      "Is this the wrong time to rant about font licensing though? I\u2019ve always bought and paid for fonts, but as I\u2019ve gradually transitioned to mobile app development, I one day realized that all the fonts I bought for print are now worthless to me.These crazy outdated licenses that let you print as many magazines or books you want forever, for a one-time price. But if your hobby is making apps, then suddenly the same font will cost you 50 times more - for a single year.I guess these font sellers imagine there\u2019s still some app boom - a Klondike rush with developers bathing in dollars. Maybe if their licenses were more realistic, piracy would be less of a problem.\n \nreply",
      "There is maybe nothing in the entire world that I am less sympathetic towards than the cause of font piracy / font liberation. You have perfectly good --- in fact, historically excellent --- fonts loaded by default for free on any computer you buy today. Arguing for the oppression of font licenses is, to me, like arguing about how much it costs to buy something at Herm\u00e8s. Just don't shop at Herm\u00e8s.\n \nreply",
      "I agree the average person is likely fine with the fonts on their computer, but this is profoundly misunderstanding the importance of design. Typefaces are incredibly important, and have been for centuries.I'd argue that complaining about font prices is less like a Hermes bag, and more like complaining about high-end ingredients when a supermarket has cheap stuff. Yes, you can get away with cheaper materials when cooking, but the final product will deeply suffer.\n \nreply",
      "Even under this analogy you're complaining about the price of luxury goods and saying that it's no wonder people shoplift to steal the truffles because they're so darn expensive.If you can't afford the license for the font, your app is small-time enough that you can make do with one of the many, many high-quality fonts that are available for free, there's no need to pirate it. If your app is big enough that the difference matters, then you can likely afford the sticker price.\n \nreply",
      "No, I'm saying a Michelin chef can complain about a 50x increase in the cost of truffles without negating the fact that a lot of people happily survive on ramen.\n \nreply",
      "op isn't saying you shouldn't complain. op is saying you shouldn't steal instead of complaining\n \nreply",
      "I think there's some confusion in who is responding to whom, then. I never said anything about piracy, but the person responding to me may have confused me with the top-level comment.All I have done is defend the importance of typography, and never mentioned piracy or stealing.\n \nreply",
      "No, those things aren't comparable. Truffles have a functional role in a dish. A typeface does not have a meaningful functional role in a document, compared to the high-quality freely-available alternatives. This is like complaining about some kind of specially-carved or dyed truffle.\n \nreply",
      "I respect you a ton (genuinely, I think you're the most interesting writer in the tech space), but you have a profound misunderstanding of the importance of typography if you think the only reason you'd need a paid typeface is the same reason you'd need a Hermes bag. I know you're a curious person, so hopefully you take this as an opportunity to open your horizons on the importance of it.\n \nreply",
      "I'm a typeface nerd. Bringhurst is one of 3 books on the end-table next to me right now. I spend a stupid amount of money for Hoefler fonts for my dumb blog.This to me is like the Menswear Guy on Twitter, who will explain in very great detail to you why the Herm\u00e8s product is significantly better than the generic alternative. He's right, but he also understands that you buy the Herm\u00e8s product to make a statement. Spend money on that statement if you want --- I do --- but don't try to pretend you have a right to it.(i don't mean i own any hermes products; just stupidly expensive typefaces)\n \nreply"
    ],
    "link": "https://fedi.rib.gay/notes/a6xqityngfubsz0f",
    "first_paragraph": "Please turn on your JavaScript"
  },
  {
    "title": "How a 20 year old bug in GTA San Andreas surfaced in Windows 11 24H2 (cookieplmonster.github.io)",
    "points": 894,
    "submitter": "yett",
    "submit_time": "2025-04-23T14:00:11 1745416811",
    "num_comments": 203,
    "comments_url": "https://news.ycombinator.com/item?id=43772311",
    "comments": [
      "This is the kind of thing I'd expect from Raymond Chen - which is extremely high praise!I'm glad they tracked it down even further to figure out exactly why.\n \nreply",
      "Or randomascii. A freaking legend (although he had a heart braking streak of bad events ... I wish him the best)\n \nreply",
      "What happened to him?\n \nreply",
      "https://randomascii.wordpress.com/2024/10/01/life-death-and-...https://randomascii.wordpress.com/2016/10/17/vestibular-dysf...\n \nreply",
      "So sad :(\n \nreply",
      "Raymond is a wizard. Read his blogs for many years and love his style and knowledge.\n \nreply",
      "He's a total legend, yet apparently he's never met Bill Gates in person from what he said in an interview in the Dave's Garage YouTube channel a few years ago. You'd think that someone who's been that prominent for so long in the company would have been invited to a company dinner where he was present or something.\n \nreply",
      "Microsoft's a big company, and billg \"stepped down\" in 2000. Raymond is still working, so they overlap less than may appear.\n \nreply",
      "Small thing but I love the effort he puts into actually coding up his examples instead of screenshots. For example: https://devblogs.microsoft.com/oldnewthing/20250414-00/?p=11...He has many better ones but that's the latest one I've seen\n \nreply",
      "Raymond knows everything. From microcode bugs on Alpha AXP to template meta programming to UI.\n \nreply"
    ],
    "link": "https://cookieplmonster.github.io/2025/04/23/gta-san-andreas-win11-24h2-bug/",
    "first_paragraph": "April 23, 202514 min. to readOn the SilentPatch GitHub issue tracker,\nI received a rather specific bug report:When I upgraded my windows to version 24H2, the Skimmer plane disappear completely from the game.\nIt can\u2019t be spawn using trainer nor it can\u2019t be found anywhere on it\u2019s normal spawn points.\nI\u2019m using both my modded copy (which is before the update, is completely fine) and vanilla copy with only silentpatch\n(I tried the 2018, 2020 and the most recent version of silentpatch) and the plane still won\u2019t exist.If this was the first time I had heard about it, I\u2019d likely consider it dubious and suspect there are more things at play,\nand it\u2019s not specifically Windows 11 24H2. However, on GTAForums, I\u2019ve been receiving comments about this exact issue since November last year.\nSome of them said SilentPatch causes this issue, others however stated the same happens on a completely unmodded game:Apparently the skimmer cant spawn when playing on Windows 11 24h2 update, hope this bug gets fixe"
  },
  {
    "title": "CubeCL: GPU Kernels in Rust for CUDA, ROCm, and WGPU (github.com/tracel-ai)",
    "points": 31,
    "submitter": "ashvardanian",
    "submit_time": "2025-04-23T23:19:32 1745450372",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43777731",
    "comments": [
      "Very interesting project! I am wondering how it compare against OpenCL, which I think adopts the same fundamental idea (write once, run everywhere)? Is it about CUbeCL's internal optimization for Rust that happens at compile time?\n \nreply",
      "See also this overview for how it compares to other projects in the Rust and GPU ecosystem: https://rust-gpu.github.io/ecosystem/\n \nreply"
    ],
    "link": "https://github.com/tracel-ai/cubecl",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Multi-platform high-performance compute language extension for Rust.\n      \n\n\n\n\n\n\n\nMulti-platform high-performance compute language extension for Rust.\nWith CubeCL, you can program your GPU using Rust, taking advantage of zero-cost abstractions to develop maintainable, flexible, and efficient compute kernels.\nCubeCL currently fully supports functions, generics, and structs, with partial support for traits, methods and type inference.\nAs the project evolves, we anticipate even broader support for Rust language primitives, all while maintaining optimal performance.Simply annotate functions with the cube attribute to indicate that they should run on the GPU.You can then launch the kernel using the autogenerated gelu_array::launch_unchecked function.To see it in action, run the working GELU example with the following command:We support "
  },
  {
    "title": "Shortest walking tour to 81,998 bars in Korea \u2013 TSP solved in 178 days (uwaterloo.ca)",
    "points": 12,
    "submitter": "geeknews",
    "submit_time": "2025-04-24T00:20:40 1745454040",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.math.uwaterloo.ca/tsp/korea/index.html",
    "first_paragraph": "\nWe have solved a traveling salesman problem (TSP) to walk to 81,998 bars in South Korea.\nThe problem was created using the Open Source Routing Machine (OSRM) to build a table of the 3,361,795,003 point-to-point travel times, one for each pair of bar locations.\nOur computation produced a tour together with a proof that it is a shortest-possible route to visit all 81,998 stops when measured with the OSRM times.\n\nIt would be a very long pub crawl.\nThe total walking time for the round trip is 15,386,177 seconds, or 178 days, 1 hour, 56 minutes, and 17 seconds.\nYou will need to stop for plenty of drinks along the way (better stick with water, tea, or Diet Coke if you want to finish the route in only a few years), so it's  not likely you would count every second on such a journey.\nBut the level of precision makes the point that this not just a good route, it is an optimal solution to the 81,998-stop TSP.\nIt is not possible to rearrange the order of stops to save even a single second of the "
  },
  {
    "title": "Google blocked Motorola use of Perplexity AI, witness says (bloomberg.com)",
    "points": 100,
    "submitter": "welpandthen",
    "submit_time": "2025-04-23T20:52:19 1745441539",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=43776512",
    "comments": [
      "https://archive.ph/tAGxc",
      "Did anyone read this article? The headline is misleading.It clearly states in the first line:> \"Google\u2019s contract with Lenovo Group Ltd.\u2019s Motorola blocked the smartphone maker from setting Perplexity AI as the default assistant on its new devices\"They didn't block Perplexity AI from Motorola's devices, the agreement states that they allow them to preload the devices with Perplexity, but the agreement, that both parties signed, does not give Motorola the permission to set it as the default.> \"Motorola \u201ccan\u2019t get out of their Google obligations and so they are unable to change the default assistant on the device.\u201dThey signed the agreement, and now are going to courts to claim they had no choice.I understand the premise, that they think they had no choice, but this article is misleading in its headline, and plenty of the comments here clearly show that a lot of \"readers\" didn't bother to read it.\n \nreply",
      "Most online journalism relies on clickbait, and they know people aren't going to read too much past the headline to care (and 99% of threads on sites like HN clearly demonstrate that).\n \nreply",
      "> They signed the agreement, and now are going to courts to claim they had no choice.Did the title change? They (Lenovo) are going to court? This is an antitrust case against Google and the witness is not part of the agreement signed. Is Lenovo suing Google?The title is representing the witness (perplexity) stance, not Lenovo's. And given it's a antitrust suit it seems like a very valid stance.\n \nreply",
      "Read it again perhaps? Without any of that context, it just reads like \"google blocked [some/all] use of Perplexity AI on [some/all] Motorola devices\"Try not to overthink it.\n \nreply",
      "They blocked Perplexity via agreements, amongst many agreements to fortify their monopoly, the legality of which has been challenged in court and this testimony is to demonstrate that this agreement also belongs in the \"illegal\" bucket.\n \nreply",
      "And the original article got 77 upvotes somehow\n \nreply",
      "Google is a convicted monopolist, so it has to play by different rules.\n \nreply",
      "Sure a contract was signed, but as has been pointed out many times about Google's heavy-handed control over Android, it doesn't mean it was fair to all parties:https://arstechnica.com/gadgets/2018/07/googles-iron-grip-on...Given the recent judgements about Google's anticompetitive behavior in multiple other arenas, revisiting these licensing agreements seems justified.\n \nreply",
      "It continues to baffle me that Google gets harassed by the courts for being a better actor in almost every area it participates.Open source Android vs. closed iOSInstall apps from any source on Android vs. total restriction on iOSSwitch default app for browser (and many other things!) vs. No choice but Safari tech on iOSEasy switch of search provider in Chrome vs. countless dark patterns pushing Edge and Bing on Windows\n \nreply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant",
    "first_paragraph": ""
  },
  {
    "title": "DOGE Worker\u2019s Code Supports NLRB Whistleblower (krebsonsecurity.com)",
    "points": 597,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-23T20:48:57 1745441337",
    "num_comments": 297,
    "comments_url": "https://news.ycombinator.com/item?id=43776476",
    "comments": [
      "> Ge0rg3\u2019s code is \u201copen source,\u201d in that anyone can copy it and reuse it non-commercially. As it happens, there is a newer version of this project that was derived or \u201cforked\u201d from Ge0rg3\u2019s code \u2014 called \u201casync-ip-rotator\u201d \u2014 and it was committed to GitHub in January 2025 by DOGE captain Marko Elez.Original code: https://github.com/Ge0rg3/requests-ip-rotatorForked: https://github.com/markoelez/async-ip-rotatorCode is pretty much the same, with comments removed, some `async` sprinkled in and minor changes (I bet this was just pasted into LLM with prompt to make it async, but if that worked why not).Except... Original GPL3 license is gone. Obviously not something you would expect DOGE people to understand or respect.\n \nreply",
      "The repository has been deleted. In addition, 26 other repos have been removed from the account. This is in line with DOGE members' quick response scrubbing data whenever put into spotlight, as previously seen with another \"teen hacker\". [0]Archived repo page: https://archive.ph/LI7tt; archived previous repo count: https://archive.ph/tgkg50. https://arstechnica.com/tech-policy/2025/04/i-no-longer-hack...\n \nreply",
      "I think one reason to hide/delete is so speculative articles like this don\u2019t get written.The mistake was ever having them public.\n \nreply",
      "> On February 6, someone posted a lengthy and detailed critique of Elez\u2019s code on the GitHub \u201cissues\u201d page for async-ip-rotator, calling it \u201cinsecure, unscalable and a fundamental engineering failure.\u201d\u201cIf this were a side project, it would just be bad code,\u201d the reviewer wrote. \u201cBut if this is representative of how you build production systems, then there are much larger concerns. This implementation is fundamentally broken, and if anything similar to this is deployed in an environment handling sensitive data, it should be audited immediately.\u201d\n \nreply",
      "FYI the Fork got hidden/deleted in the last minute or so -- did anyone manage to clone it before it disappeared?\n \nreply",
      "I did. It's essentially just a single .py file: https://gist.github.com/whalesalad/06804fd734efe6bd2e0c84906...\n \nreply",
      "x_forwarded_for = headers.get(\"X-Forwarded-For\")\n    if x_forwarded_for is None:\n        x_forwarded_for = ipaddress.IPv4Address._string_from_ip_int(\n            randint(0, MAX_IPV4)\n        )\n\nlol\n \nreply",
      "The original author claims this is to prevent API gateway from leaking the true client IP.\n \nreply",
      "To be fair the code actually creates a new API gateway server that acts as a proxy on to an already existing server and you're possibly meant to use this header with your own gateway service.So,  it's set as a header,  sent to a user owned proxy,  then to the actual external endpoint.On the other hand I think the receiving API Gateway will be able to see and log your AWS account identifier when you do this.  So your IP may not be the only identifying information that needs to be obscured for this to actually work.\n \nreply",
      "The code seems like a \"creative\" use of API gateway to turn it into a proxy for other external sites (single site, really, since you need one per site.)  Wouldn't it be simpler to send the requests through a lambda (with a function URL) and get better control of the outbound requests?\n \nreply"
    ],
    "link": "https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/",
    "first_paragraph": "A whistleblower at the National Labor Relations Board (NLRB) alleged last week that denizens of Elon Musk\u2019s Department of Government Efficiency (DOGE) siphoned gigabytes of data from the agency\u2019s sensitive case files in early March. The whistleblower said accounts created for DOGE at the NLRB downloaded three code repositories from GitHub. Further investigation into one of those code bundles shows it is remarkably similar to a program published in January 2025 by Marko Elez, a 25-year-old DOGE employee who has worked at a number of Musk\u2019s companies.A screenshot shared by NLRB whistleblower Daniel Berulis shows three downloads from GitHub.According to a whistleblower complaint filed last week by\u00a0Daniel J. Berulis, a 38-year-old security architect at the NLRB, officials from DOGE met with NLRB leaders on March 3 and demanded the creation of several\u00a0all-powerful \u201ctenant admin\u201d accounts that were to be exempted from network logging activity that would otherwise keep a detailed record of al"
  },
  {
    "title": "Yagri: You are gonna read it (scottantipa.com)",
    "points": 82,
    "submitter": "escot",
    "submit_time": "2025-04-23T21:47:27 1745444847",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=43776967",
    "comments": [
      "Additionally, mutable fields will quite often benefit from having a separate edit table which records the old value, the new value, who changed it, and when.  Your main table\u2019s created and updated times can be a function of (or a complement to) the edit table.It is tempting to supernormalize everything into the relations object(id, type) and edit(time, actor_id, object_id, key, value).  This is getting dangerously and excitingly close to a graph database implemented in a relational database!  Implement one at your peril \u2014 what you gain in schemaless freedom you also lose in terms of having the underlying database engine enforcing consistency on your behalf.\n \nreply",
      "One thing I do quite frequently which is related to this (and possibly is a pattern in rails) is to use times in place of Booleans.So is_deleted would contain a timestamp to represent the deleted_at time for example. This means you can store more information for a small marginal cost. It helps that rails will automatically let you use it as a Boolean and will interpret a timestamp as true.\n \nreply",
      "I consider booleans a code smell. It's not a bug, but it's a suggestion that I'm considering something wrong. I will probably want to replace it with something more meaningful in the future. It might be an enum, a subclass, a timestamp, refactoring, or millions of other things, but the Boolean was probably the wrong thing to do even if I don't know it yet.\n \nreply",
      "This is all well and good until you need to represent something that happened on Jan 1 1970 00:00 UTC.\n \nreply",
      "32-bit UNIX timestamps are often signed so you can actually go before that, but most UNIX timestamps are 64-bit now, which can represent quite a larger range. And SQL datetime types might have a totally different range.Not that it really matters; deleted_at times for your database records will rarely predate the existence of said database.\n \nreply",
      "It's not about the scale, it's that `if (0)` will evaluate to `false` in many languages.\n \nreply",
      "Leave it null for non-deleted items.\n \nreply",
      "This one little change alone can bring such huge benefits later.\n \nreply",
      "A little while back, I had a conversation with a colleague about sorting entries by \"updated at\" in the user interface, and to my surprise this was not added by the backend team.Many of these \"we are going to need it\"s come from experience. For example in the context of data structures (DS), I have made many \"mistakes\" that I do correctly a second time. These mistakes made writing algorithms for the DS harder, or made the DS have bad performance.Sadly, it's hard to transfer this underlying breadth of knowledge and intuition for making good tradeoffs. As such, a one-off tip like this is limited in its usefulness.\n \nreply",
      "Database schemas being perfect out-of-the gate was replaced by reliable migrations.If it's not data that's essential to serving the current functionality, just add a column later. `updated_at` doesn't have to be accurate for your entire dataset; just set it to `NOW()` when you run the migration.\n \nreply"
    ],
    "link": "https://www.scottantipa.com/yagri",
    "first_paragraph": "\n            YAGNI, or, You aren't gonna need it,\n            is a standard piece of advice that warns against over engineering\n            and building too many features too early. I think its great and saves you from wasting time, which\n            can kill a project.\n        \n            However, there's an exception that I call YAGRI, or, \"You are gonna read it\". It means that you shouldn't just store\n            the minimum\n            data required to satisfy the current product spec. You should also store data that you'll highly likely use (read),\n            such as timestamps and contextual metadata.\n        \n            This problem tends to happen when a UI design shows that you only need to display a few specific bits of data to the\n            user,\n            so you only store those exact fields in the database. You've satisfied the design and ship it. Then later you realize\n            you're missing valuable information to help debug an issue, do internal analytics, et"
  },
  {
    "title": "Show HN: My from-scratch OS kernel that runs DOOM (github.com/unmappedstack)",
    "points": 17,
    "submitter": "UnmappedStack",
    "submit_time": "2025-04-24T00:15:22 1745453722",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43778081",
    "comments": [
      "Hi there! I've been on-and-off working on TacOS for a few months, which follows some UNIX-derived concepts (exec/fork, unix-style VFS, etc) and is now able to run a port of Doom, with a fairly small amount of modifications, using my from-scratch libc. The performance is actually decent compared to what I expected. Very interested to hear your thoughts. Thank you!\n \nreply",
      "Really really love the name.\n \nreply",
      "This is so cool\n \nreply",
      "Dude, getting Doom to run on your own kernel is epic - I gotta try building some wild stuff like this someday\n \nreply",
      "Yeah definitely an achievement I'm happy with. I've got a bit of refactoring to do, ANSI parsing etc then I'd like to port more - perhaps even Vim (or another portable Vim-like editor called Dim)\n \nreply"
    ],
    "link": "https://github.com/UnmappedStack/TacOS",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An x86_64 UNIX-like OS from scratch\n      My from-scratch OS with it's own kernel written in C and assemblyTacOS is a UNIX-like kernel which is able to run DOOM, among various other smaller userspace programs. It has things like a VFS, scheduler, TempFS, devices, context switching, virtual memory management, physical page frame allocation, and a port of Doom. It runs both on real hardware (tested on my laptop) and in the Qemu emulator.\nPlease note that TacOS is a hobby toy OS and is not complete enough for real usage. It has multiple known bugs.I have a Discord server for PotatOS where I will share most updates, and you can also get help with your own OSDev project or just have a chat. You can join here.To build and run TacOS, simply run in your shell:You'll need to have Qemu, NASM, and Clang installed. It will automatically run in "
  },
  {
    "title": "Teaching LLMs how to solid model (willpatrick.xyz)",
    "points": 167,
    "submitter": "wgpatrick",
    "submit_time": "2025-04-23T18:13:43 1745432023",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=43774990",
    "comments": [
      "The future:\n\"and I want a 3mm hole in one side of the plate. No the other side. No, not like that, at the bottom. Now make it 10mm from the other hole. No the other hole. No, up not sideways. Wait, which way is up? Never mind, I'll do it myself.\"I'm having trouble understanding why you would want to do this. A good interface between what I want and the model I will make is to draw a picture, not write an essay. This is already (more or less) how Solidworks operates. AI might be able to turn my napkin sketch into a model, but I would still need to draw something, and I'm not good at drawing.The bottleneck continues to be having a good enough description to make what you want. I have serious doubts that even a skilled person will be able to do it efficiently with text alone. Some combo of drawing and point+click would be much better.This would be useful for short enough tasks like \"change all the #6-32 threads to M3\" though. To do so without breaking the feature tree would be quite impressive.\n \nreply",
      "Most likely you won\u2019t be asking for specific things like \u201c3mm hole 3in from the side\u201d, you\u2019ll say things like \u201cCreate a plastic enclosure sized to go under a desk, ok add a usb receptacle opening, ok add flanges with standard screw holes\u201dIn the text to CAD ecosystem we talk about matching our language/framework to \u201cdesign intent\u201d a lot. The ideal interface is usually higher level than people expect it to be.\n \nreply",
      "> I'm having trouble understanding why you would want to do this.You would be amazed at how much time CAD users spend using Propriety CAD Package A to redraw things from PDFs generated by Propriety CAD Package B\n \nreply",
      "I think this is along the lines of the AI horseless carriage[1] topic that is also on the front page right now.  You seem to be describing the current method as operated through an AI intermediary.  I think the power in AI for CAD will be at a higher level than lines, faces and holes.  It will be more along the lines of \"make a bracket between these two parts\".  \"Make this part bolt to that other part\".  \"Attach this pump to this gear train\" (where the AI determines the pump uses a SAE 4 bolt flange of a particular size and a splined connection, then adds the required features to the housing and shafts).  I think it will operate on higher structures than current CAD typically works with, and I don't think it will be history tree and sketch based like Solidworks or Inventor.  I suspect it will be more of a direct modelling approach.  I also think integrating FEA to allow the AI to check its work will be part of it.  When you tell it to make a bracket between two parts, it can check the weight of the two parts, and some environmental specification from a project definition, then auto-configure FEA to check the correct number of bolts, material thickness, etc.  If it made the bracket from folded sheet steel, you could then tell it you want a cast aluminum bracket, and it could redo the work.[1]https://news.ycombinator.com/item?id=43773813\n \nreply",
      "I think this is correct, especially the part about how we actually do modelling. The topological naming problem is really born from the fact that we want to do operations on features that may no longer exist if we alter the tree at an earlier point. An AI model might find it easier to work directly with boolean operations or meshes, at which point, there is no topological naming problem.\n \nreply",
      "You're right, but I think we have a long way to go. Even our best CAD packages today don't work nearly as well as advertised. I dread to think what Dassault or Autodesk would charge per seat for something that could do the above!\n \nreply",
      "I agree.  I think a major hindrance to the current pro CAD systems is being stuck to the feature history tree, and rather low level features.  Considerable amounts of requirements data is just added to a drawing free-form without semantic machine-readable meaning.  Lots of tolerancing, fit, GD&T, datums, etc are just lines in a PDF.  There is the move to MBD/PMI and the NIST driven STEP digital thread, but the state of CAD is a long way from that being common.  I think we need to get to the data being embedded in the model ala MBD/PMI, but then go beyond it.  The definition of threads, gear or spline teeth, ORB and other hydraulic ports don't fit comfortably into the current system.  There needs to be a higher level machine-readable capture, and I think that is where the LLMs may be able to step in.I suspect the next step will be such a departure that it won't be Siemens, Dassault, or Autodesk that do it.\n \nreply",
      "I have come across a significant number of non engineers wanting to do, what ultimately involves some basic CAD modelling. Some can stall on such tasks for years (home renovation) or just don't do it at all. After some brief research, the main cause is not wanting to sink over 30 hours into learning basics of a cad package of choice.For some reason they imagine it as a daunting, complicated, impenetrable task with many pitfalls, which aren't surmountable. Be it interface, general idea how it operates, fear of unknown details (tolerances, clearances).It's easy to underestimate the knowledge required to use a cad productively.One such anecdata near me are highschools that buy 3d printers and think pupils will naturally want to print models. After initial days of fascination they stopped being used at all. I've heard from a person close to the education that it's a country wide phenomena.Back to the point though - maybe there's a group of users that want to create, but just can't do CAD at all and such text description seem perfect for them.\n \nreply",
      ">> I have come across a significant number of non engineers wanting to do, what ultimately involves some basic CAD modelling.I very much want Solvespace to be the tool for those people. It's very easy to learn and do the basics. But some of the bugs still need to get fixed (failures tend to be big problems for new users because without experience its hard to explain what's going wrong or a workaround) and we need a darn chamfer and fillet tool.\n \nreply",
      "Here's how it might work, by analogy to the workflow for image generation:\"An aerodynamically curved plastic enclosure for a form-over-function guitar amp.\"Then you get something with the basic shapes and bevels in place, and adjust it in CAD to fit your actual design goals. Then,\"Given this shape, make it easy to injection mold.\"Then it would smooth out some things a little too much, and you'd fix it in CAD. Then, finally,\"Making only very small changes and no changes at all to the surfaces I've marked as mounting-related in CAD, unify my additions visually with the overall design of the curved shell.\"Then you'd have to fix a couple other things, and you'd be finished.\n \nreply"
    ],
    "link": "https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html",
    "first_paragraph": "\n\n        April 23, 2025\n      \n      \n      \u2022 Technology\nIt turns out that LLMs can make CAD models for simple 3D mechanical parts. And, I think they\u2019ll be extremely good at it soon.Code generation is the first breakthrough application for LLMs. What would an AI agent look like for mechanical engineering? Material selection, design for manufacturing, computer-aided manufacturing (CAM), and off-the-shelf part comparison would all be important features of an AI mechanical engineer. Perhaps, most importantly, an AI mechanical engineer would design and improve CAD models. Mechanical engineers typically design CAD using point-and-click software (e.g. Fusion 360, Solidworks, and Onshape). How could AI generate these solid models instead?One promising direction is training a generative model on millions of existing CAD files. This approach is being actively researched by multiple teams who are investigating both diffusion and transformer architectures. In particular, I like Autodesk Research"
  },
  {
    "title": "Graphics livecoding in Common Lisp (kevingal.com)",
    "points": 98,
    "submitter": "adityaathalye",
    "submit_time": "2025-04-23T17:48:20 1745430500",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=43774726",
    "comments": [
      "Live development is still so under-explored, and is just so exciting to work with.One of my favorite talks is \"Stop Writing Dead Programs\" (https://www.youtube.com/watch?v=8Ab3ArE8W3s) and touches on a lot of what could be in terms of live development.Lisp is very well-suited to live development due to code being data, but live development doesn't need to be lispy.I built a live development extension for Love2D which lets you do graphics livecoding (both lua and glsl) in real-time - every keystroke updating the output, (if a valid program).https://github.com/jasonjmcghee/liveloveHere are some (early) demos of things you can do with it:https://gist.github.com/jasonjmcghee/9701aacce85799e0f1c7304...So many cool things once you break down the barrier between editor and running program.I've also asked myself the question of, what would a language look like that was natively built for live development, and built out a prototype - though it's definitely a sandbox so haven't posted it anywhere yet, other than demos on mastadon.\n \nreply",
      "Jack Rusher's recent interview is well worth reading too (the \"stop writing dead programs\" guy).> On the need to sustain your creative drive in the face of technological change> https://thecreativeindependent.com/people/multi-disciplinary...nb. I recently submitted it here: https://news.ycombinator.com/item?id=43759204\n \nreply",
      "That's a great submission! I put it in the second-chance pool (https://news.ycombinator.com/pool, explained at https://news.ycombinator.com/item?id=26998308), so it will get a random placement on HN's front page.\n \nreply",
      "Oh wow, just had to log in and give you a high-five for livelove because this is the first I've heard of it and it sounds like the sort of thing I absolutely need to try out.I remember giving Love2D a go a couple of years ago with Fennel and the lack of such a thing sent me grumbling back to Common Lisp. I'd never even have thought of building that functionality in Love/Lua myself - assuming it's something that the runtime just didn't support - and it absolutely would never have occurred to me to use LSP to set it up. I've not even used it yet and it's already doing things to my brain, so thanks!\n \nreply",
      "Excited to spread the brain worm. Don't hesitate to join in the fun / log issues / contribute / share how you use it!\n \nreply",
      "I guess the prevailing worldview is that \"recompile everything and re-run\" is good enough if it takes 2 seconds. But agreed that it just \"feels\" different when you're doing live in lisp... I miss Emacs!\n \nreply",
      "Recompile and hot reload, maybe. 2 seconds if you're very lucky. Many setups are much slower. I've seen some really cool projects over the last few years- things like tcc + hot reload that have really good turn around time.But \"live\" is a whole different thing. And most languages aren't built with the expectation that you'll be patching it while it's running - at least as standard operating procedure and without nuking state.And that's a key part.I think you should be able to build an app and develop a game without ever having to restart them.\n \nreply",
      "Well, for me it\u2019s not enough because I need to get back to where I was, repeating the same actions so it gets to the same state. With live dev I don\u2019t need this, or a history replay method. I only update the running code. Heck I could also update the in memory var too if so I want.It\u2019s good that it\u2019s fast. Still no good enough!\n \nreply",
      "There are similar trends in music and sound art, which can be experienced with Glicol (https://glicol.org/) as well as many other languages here:https://github.com/toplap/awesome-livecodingalso this live coding book is free to read!https://livecodingbook.toplap.org/\n \nreply",
      "I use Common Lisp (CL) for some of my small personal projects.  A few publicly available examples I can share include my website [1] and a now-defunct mathematics pastebin [2].  My CL projects are usually text-oriented, not graphics-oriented.  What keeps me coming back to CL is how convenient the live coding environment is.When I am exploring ideas that are not fully concrete yet, I can begin by writing a small set of functions with very basic functionality.  Then as the ideas evolve, I can refine existing functions or add new ones, then quickly \"reload\" them (with say, C-M-x in Emacs), and see the effects immediately.  There is no separate compile or rebuild step.  I don't have to restart any service or application.  The effects are truly immediate -- what previously did X, now does Y.In the Python or JavaScript ecosystems, similar live reloading capability is often provided by frameworks (e.g., FastAPI, React, etc.), which monitor file changes during development.  In CL, it's just part of the language implementation itself.Of course, at the end of the day, everything is committed and pushed to a version control system.  Sometimes I restart the application too just to be sure it reflects the actual source, especially, after hours of live reloading.  The stereotype of Lisp programmers making all of their modifications in an ephemeral image and then dumping it all to disk is not something I have actually seen in practice, at least not among the people I know.So the rest of the software development practices happen to be typical.  But during exploration, debugging, or troubleshooting, the live coding experience in Common Lisp is so seamless, it feels like programming at the speed of thought.[1] https://github.com/susam/susam.net[2] https://github.com/susam/mathb\n \nreply"
    ],
    "link": "https://kevingal.com/blog/cl-livecoding.html",
    "first_paragraph": "Tags: lisp programming artsy Some Lisps, like Common Lisp, have a powerful feature that tends to go underappreciated amidst all the talk about macros: the ability to recompile your program while it's running, without restarting it. For the purposes of this post, and because it sounds cool, let's call this ability livecoding1.Entering this strange land where the programs never stop, we'll first take a brief tour of Common Lisp and one of its graphics frameworks, Sketch, before walking through a livecoded implementation of the Boids algorithm.Consider the typical workflow needed to modify a running application, like a videogame.In a livecoding environment, the application is never stopped, which eliminates steps 1, 4 and 5. Instead, small code changes (which can be as granular as recompiling a single function) are immediately reflected in the running program. Step 3 is often instantaneous because only the changed parts of the program must be recompiled. In theory, then, you can develop a"
  },
  {
    "title": "MCP on AWS Lambda with MCPEngine (featureform.com)",
    "points": 47,
    "submitter": "simba-k",
    "submit_time": "2025-04-23T16:17:04 1745425024",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43773777",
    "comments": [
      "It turns out you can, in fact, run Python on Lambda. Neat.\n \nreply",
      "Man, Marvel Crisis Protocol is really blowing up lately.\n \nreply",
      "McProtocol\n \nreply",
      "Who uses this?\n \nreply",
      "The thing about MCP is people can \u201cdo AI\u201d without any AI.That makes it enormously attractive for people who want to be part of the AI hype cycle but not devote much actual effort to it.Especially since you dont have to actually do anything useful, just write a wrapper around something that already exists.Wow! Now youre part of the AI hype cycle!Maybe you too (like windsurf) can be bought for billions of dollars.So\u2026 lots of people.\n \nreply"
    ],
    "link": "https://www.featureform.com/post/deploy-mcp-on-aws-lambda-with-mcpengine",
    "first_paragraph": "Model Context Protocol (MCP) is quickly becoming the standard for enabling LLMs to call external tools. It\u2019s built around clean, declarative tool definitions\u2014but most current implementations fall short of being production-ready. Every official MCP server in the Anthropic repo, for instance, runs locally and communicates over stdio. Even the few that support HTTP rely on Server-Sent Events (SSE) for streaming. This introduces stateful behavior, requiring persistent TCP connections, complicating retries, and ultimately making it incompatible with stateless environments like AWS Lambda. We\u2019ve written more about these limitations, and how we\u2019ve addressed them with MCPEngine.AWS Lambda offers instant scalability, no server management, and efficient, event-driven execution. We built native support for it in MCPEngine, so that MCP tools can run cleanly and reliably in serverless environments.MCPEngine is an open-source implementation of MCP that supports streamable HTTP alongside SSE, making "
  },
  {
    "title": "C++26: more constexpr in the core language (sandordargo.com)",
    "points": 66,
    "submitter": "jandeboevrie",
    "submit_time": "2025-04-23T19:13:03 1745435583",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=43775670",
    "comments": [
      "Anyone else getting concerned about the rate of development of the C++ Standard vs compiler implementation? We don't even have feature complete C++20 on the major compilers yet. C++23 is even less implemented. How will the committee handle this? Will they reduce feature additions at some point in the future?https://en.cppreference.com/w/cpp/compiler_support\n \nreply",
      "Maybe knowing where a language is going will help them implement older features? Also, some things are technically easy once all the conceptual wrinkles are ironed out. There is no reason some of these can't be added before C++20 is 100% supported.\n \nreply",
      "I always like these new comile time features getting into the C++ spec.I'm actually looking forward to the related reflection features that I think are currently in scope for C++26.  I've run into a number of places where the combination of reflection and constexpr could be really valuable... the current workarounds often involving macros, runtime tricks, or both.\n \nreply",
      "> I'm actually looking forward to the related reflection features that I think are currently in scope for C++26.The core of reflection should be in C++26, yes. In my understanding, there's more to do after that as well. We'll see when the final meeting is done.\n \nreply",
      "It would be cool to have the entire language and runtime available at compile-time like in Lisp\n \nreply",
      "The D language basically does that. You can write D programs that evaluate D code at compile time to generate strings of new D code which you can then basically compile-time eval into your code as needed. Combined with the extremely powerful compile-time reflection capabilities of D it's the closest thing I've seen to Lisp metaprogramming outside of that family of languages and it's easier to read than Rust macros or C++ template metaprogramming.\n \nreply",
      "Every time I hear about D it sounds awesome.  I actually used it to prototype an image collage-composing algorithm which I then rewrote in Scala[1], and the D version might have been nicer to write.The only reason I didn't write more stuff in D was that the stack traces from my programs were pretty much useless.  Maybe I was supposed to set a --better-stack-traces flag when I compiled it or something idk.[1] One of the algorithms used by https://github.com/TOGoS/PicGrid\n \nreply",
      "It would be cool, except for the entire language that is available at compile-time being C++, and thus entirely unsuitable for manipulating C++ programs.\n \nreply",
      "Yes. It is not like C++ compilers are written in C++.\n \nreply",
      "This already exists with macros, templates, and compiler extensions, if you want completely unusable/unreadable code that takes forever to build.\n \nreply"
    ],
    "link": "https://www.sandordargo.com/blog/2025/04/23/cpp26-constexpr-language-changes",
    "first_paragraph": "Since constexpr was added to the language in C++11, its scope has been gradually expanded. In the beginning, we couldn\u2019t even use if, else or loops, which were changed in C++14. C++17 added support for constexpr lambdas. C++20 added the ability to use allocation and use std::vector and std::string in constant expressions. In this article, let\u2019s see how constexpr evolves with C++26. To be more punctual, let\u2019s see what language features become more constexpr-friendly. We\u2019ll discuss library changes in a separate article, as well as constexpr exceptions, which need both language and library changes.Thanks to the acceptance of P2738R1, starting from C++26, one can cast from void* to a pointer of type T in constant expressions, if the type of the object at that adress is exactly the type of T.Note that conversions to interconvertible - including pointers to base classes - or not related types are not permitted.The motivation behind this change is to make several standard library functions or"
  },
  {
    "title": "My experience of participating to a startup weekend competition in Italy (danielpetrica.com)",
    "points": 6,
    "submitter": "danielpetrica",
    "submit_time": "2025-04-20T19:53:44 1745178824",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://danielpetrica.com/my-experience-of-participating-to-a-startup-weekend-competition-in-italy/",
    "first_paragraph": ""
  },
  {
    "title": "AI Horseless Carriages (koomen.dev)",
    "points": 464,
    "submitter": "petekoomen",
    "submit_time": "2025-04-23T16:19:56 1745425196",
    "num_comments": 314,
    "comments_url": "https://news.ycombinator.com/item?id=43773813",
    "comments": [
      "I tread carefully with anyone that by default augments their (however utilitarian or conventionally bland) messages with language models passing them as their own. Prompting the agent to be as concise as you are, or as extensive, takes just as much time in the former case, and lacks the underlying specificity of your experience/knowledge in the latter.If these were some magically private models that have insight into my past technical explanations or the specifics of my work, this would be a much easier bargain to accept, but usually, nothing that has been written in an email by Gemini could not have been conceived of by a secretary in the 1970s. It lacks control over the expression of your thoughts. It's impersonal, it separates you from expressing your thoughts clearly, and it separates your recipient from having a chance to understand you the person thinking instead of you the construct that generated a response based on your past data and a short prompt. And also, I don't trust some misandric f*ck not to sell my data before piping it into my dataset.I guess what I'm trying to say is: when messaging personally, summarizing short messages is unnecessary, expanding on short messages generates little more than semantic noise, and everything in between those use cases is a spectrum deceived by the lack of specificity that agents usually present. Changing the underlying vague notions of context is not only a strangely contortionist way of making a square peg fit an umbrella-shaped hole, it pushes around the boundaries of information transfer in a way that is vaguely stylistic, but devoid of any meaning, removed fluff or added value.\n \nreply",
      "Agreed! As i mentioned in the piece I don't think LLMs are very useful for original writing because instructing an agent to write anything from scratch inevitably takes more time than writing it yourself.Most of the time I spend managing my inbox is not spent on original writing, however. It's spent on mundane tasks like filtering, prioritizing, scheduling back-and-forths, introductions etc. I think an agent could help me with a lot of that, and I dream of a world in which I can spend less time on email and finally be one of those \"inbox zero\" people.\n \nreply",
      "The counter argument is some people are terrible at writing.  Millions of people sit at the bottom of any given bell curve.I\u2019d never trust a summery from a current generation LLM for something as critical as my inbox.  Some hypothetical drastically improved future AI, sure.\n \nreply",
      "Smarter models aren't going to somehow magically understand what is important to you. If you took a random smart person you'd never met and asked them to summarize your inbox without any further instructions they would do a terrible job too.You'd be surprised at how effective current-gen LLMs are at summarizing text when you explain how to do it in a thoughtful system prompt.\n \nreply",
      "I\u2019m less concerned with understanding what\u2019s important to me than I am the number of errors they make.  Better prompts don\u2019t fix the underlying issue here.\n \nreply",
      "For the case of writing emails, I tend to agree though I think creative writing is an exception. Pairing with an LLM really helps overcome the blank page / writer's block problem because it's often easier to identify what you don't want and then revise all the flaws you see.\n \nreply",
      "Why can\u2019t the LLM just learn your writing style from your previous emails to that person?Or a your more general style for new people.It seems like Google at least should have a TONNE of context to use for this.Like in his example emails about being asked to meet - it should be checking the calendar for you and putting in if you can / can\u2019t or suggesting an alt time you\u2019re free.If it can\u2019t actually send emails without permission there\u2019s less harm with giving an LLM more info to work with - and it doesn\u2019t need to get it perfect. You can always edit.If it deals with the 80% of replies that don\u2019t matter much then you have 5X more time to spend on the 20% that do matter.\n \nreply",
      "They are saving this for some future release I would guess. A \u201cpersonalization\u201d-focused update wave/marketing blitz/privacy Overton window shift.\n \nreply",
      ">As I mentioned above, however, a better System Prompt still won't save me much time on writing emails from scratch.>The thing that LLMs are great at is reading text and transforming it, and that's what I'd like to use an agent for.Interestingly, the OP agrees with you here and noted in the post that the LLMs are better at transforming data than creating it.\n \nreply",
      "I reread those paragraphs. I find the transformative effect of the email missing from the whole discussion. The end result of the inbox examples is to change some internal information in the mind of the recipient. Agent working within the context of the email has very little to contribute because it does not know the OP's schedule, dinner plans, whether he has time for the walk and talk or if he broke his ankle last week... I'd be personally afraid to have something rummaging in my social interface that can send (and let's be honest, idiots will CtrlA+autoreply their whole inboxes) invites, timetables, love messages etc. in my name. It has too many lemmas that need to be fulfilled before it can be assumed competent, and none of those are very well demonstrated. It's cold fusion technology. Feasible, should be nice if it worked, but it would really be a disappointment if someone were to use it in its current state.\n \nreply"
    ],
    "link": "https://koomen.dev/essays/horseless-carriages/",
    "first_paragraph": ""
  },
  {
    "title": "Apple and Meta fined millions for breaching EU law (yahoo.com)",
    "points": 335,
    "submitter": "Aldipower",
    "submit_time": "2025-04-23T10:01:04 1745402464",
    "num_comments": 474,
    "comments_url": "https://news.ycombinator.com/item?id=43770337",
    "comments": [
      "> Under the DMA, app developers distributing their apps via Apple's App Store should be able to inform customers, free of charge, of alternative offers outside the App Store, steer them to those offers and allow them to make purchases.To me, this is the most easily agreeable part of what the EU has been after. It is unfair that Apple restricts Netflix from telling it's users that they can sign up and pay for Netlifx on their own website. It's unfair that Netflix can't even tell its users the rules that Apple enforces on them.It's telling that Gruber is pretty staunchly against EU/DMA interferance in Apple, and broadly thinks they're wrong. But this is the one thing he agrees on> If Apple wants to insist on a cut of in-app purchased subscription revenue, that\u2019s their prerogative. What gets me, though, are the rules that prevent apps that eschew in-app purchases from telling users in plain language how to actually pay. Not only is Netflix not allowed to link to their website, they can\u2019t even tell the user they need to go to netflix.com to sign uphttps://daringfireball.net/2019/01/netflix_itunes_billinghttps://daringfireball.net/2020/07/parsing_cooks_opening_sta...(I think Apple now has their 'reader app' carveout for apps like Netflix, but it's still pretty obtuse and inconsistent)\n \nreply",
      "Also, https://ec.europa.eu/commission/presscorner/detail/en/ip_25_...> The Commission takes the preliminary view that Apple failed to comply with this obligation [to allow third party app stores] in view of the conditions it imposes on app (and app store) developers. Developers wanting to use alternative app distribution channels on iOS are disincentivised from doing so as this requires them to opt for business terms which include a new fee (Apple's Core Technology Fee). Apple also introduced overly strict eligibility requirements, hampering developers' ability to distribute their apps through alternative channels. Finally, Apple makes it overly burdensome and confusing for end users to install apps when using such alternative app distribution channels.This is great to hear. It sounds like they've just found Apple non-compliant in making alternate app stores as discouraging for both developers and user as possible. I guess it'll take another 12 months for any fines or changes from Apple.\n \nreply",
      "The two companies have two months to comply, or there will be daily fines.\n \nreply",
      "I don't think so - they\u2019ve only been fined for the in-app anti-steering provisions.For the second App Marketplace issue, I think that\u2019s just a preliminary finding and is going to take longer to work out> Apple now has the possibility to exercise its rights of defence by examining the documents in the Commission's investigation file and by responding to the preliminary findings\n \nreply",
      "Hm, maybe, I'm just going by what the article says:> The companies have two months to comply with the orders or risk daily fines.Maybe they got it wrong, though.\n \nreply",
      "I think you're both sort of right.The orders in question here are 1 for Apple (the one that made circumventing Apple payments super difficult) and 1 for Meta (their ad-free subscription service). Meta and Apple have to comply with those within 2 months.The preliminary finding on sideloading apps isn't subject to that 2 month compliance deadline from what I can tell.\n \nreply",
      ">the most easily agreeable part of what the EU has been afterIt's also probably the most dangerous for Apple. It creates a cash incentive to push people outside of Apple's walled garden and show them what's outside.I really really hope Apple gets its act together, they are the greatest \"the user experience comes first\" company and they actually have great hard tech but they show signs of rent seeking behavior which can destroy them.If Apple just play nice with EU, open up and focus on bringing the greatest experience possible they will keep winning. If not, they will have blunders and they will lose Europe since people are willing to look for alternatives as USA gets increasingly unpopular among the Europeans due to politics.The Apple's AI blunder is mostly a blunder only because they insist to do it all by themselves so to have higher margins on the services revenues. IMHO those blunders will be more damaging as the Americans no longer have the higher moral grounds than Koreans or Chinese.I hope Apple is treading carefully.\n \nreply",
      "> show signs of rent seekingThey've been hard rent-seeking since iTunes and iPod.  They aggressively eliminated and made inconvenient other ways for getting music onto iPods.  Hardware was great, but hard dependence on iTunes killed it for me.\n \nreply",
      "\"Show signs of rent seeking behaviour\" seems like an extremely generous position. Forbidding your customers from even mentioning The Outside is full-on rent seeking behaviour, since its inception.\n \nreply",
      "To steel man the policy, one thing it helps avoid is the free rider problem. Apples store terms are than free apps don\u2019t pay a commission to Apple. But someone has to pay for the costs of developing the SDKs and the platform. We no longer live in an age where Apple or Microsoft gets away with charging for multi thousand dollar per year per seat developer license for their platforms, but that doesn\u2019t mean those platforms don\u2019t cost money to develop and maintain. So the idea is, if you make money on the platform, so does Apple. But free apps + in app downloads is a giant loophole in that plan. Sure we all think of Netflix or Kindle apps when we think of this, but without a policy that charges for IAP and discourages or outright forbids steering off the platform, we would see a new category of \u201cfreemium\u201d apps where the app is \u201cfree\u201d on the App Store, but is effectively just an empty downloader shell that you then have to buy the \u201creal\u201d app through. Unscrupulous devs steer you to their own outside store or put some ridiculous inside the App Store price (think 300x+ markup) with a link to the outside store with the cheaper price and all those customers are transacting, and Apple gets no money for funding their platform.And yes I know we can all scoff and say \u201coh poor multi-billion dollar Apple can\u2019t get paid but getting paid is exactly how Apple is a multibillion dollar company. So if they don\u2019t get it from IAP and app sales fees then they\u2019re going to extract it either from hardware prices, or for charging those per seat per year dev licenses again.Personally I think Apple is big enough now and the App Store is popular enough now they can revisit this but somehow they are going to want to solve the free rider problem, and whatever they pick, people won\u2019t be happy (see also core technology fee)\n \nreply"
    ],
    "link": "https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Cua (YC X25) \u2013 Open-Source Docker Container for Computer-Use Agents (github.com/trycua)",
    "points": 103,
    "submitter": "frabonacci",
    "submit_time": "2025-04-23T15:55:05 1745423705",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=43773563",
    "comments": [
      "Congrats on the launch!I don\u2019t know if this is a problem you\u2019ve faced, but I\u2019m curious: how do LLM tool devs handle authn/authz? Do host apps normally forward a token or something? Is there a standard commonly used? What if the tool needs some permissions to act on the user\u2019s behalf?\n \nreply",
      "There are companies like https://www.keycard.sh/ taking this on. There are other competitors too but I can't think of them atm\n \nreply",
      "Good question! Specifically around computer-use agents (CUAs), I haven't seen much exploration yet - and I think it\u2019s an area worth exploring for vertical products. For example, how do you securely handshake between a CUA agent and an API-based agent without exposing credentials? If everything stays within a local cluster, it's manageable, but once you start scaling out, authn/authz becomes a real headache.I'm also working on a blog post that touches on this - particularly in the context of giving agents long-term and episodic memory. Should be out next week!\n \nreply",
      "bravi! the future is the Agent OS - \nHow robust is the UI element detection and interaction across different apps and inside navigating complex menus?\nIs it resistant to UI changes? \nThat's often where these automations get brittle.thank you e forza Cua\n \nreply",
      "How's it different from e2b computer use?\n \nreply",
      "We\u2019re still figuring things out in public, but a few key differences:- Open-source from the start. Cua\u2019s built under an MIT license with the goal of making Computer-Use agents easy and accessible to build. Cua's Lume CLI was our first step - we needed fast, reproducible VMs with near-native performance to even make this possible.- Native macOS support. As far as we know, we\u2019re the only ones offering macOS VMs out of the box, built specifically for Computer-Use workflows. And you can control them with a PyAutoGUI-compatible SDK (cua-computer) - so things like click, type, scroll just work, without needing to deal with any inter-process communication.- Not just the computer/sandbox, but the agent too. We\u2019re also shipping an Agent SDK (cua-agent) that helps you build and run these workflows without having to stitch everything together yourself. It works out of the box with OpenAI and Anthropic models, UI-Tars, and basically any VLM if you\u2019re using the OmniParser agent loop.- Not limited to Linux. The hosted version we\u2019re working on won\u2019t be Linux-only - we\u2019re going to support macOS and Windows too.\n \nreply",
      "Active development of CUA, according to GitHub\n \nreply",
      "Congrats! How do you guys deal with SOC2/HIPAA/etc.? Or are those separate concerns?\n \nreply",
      "Thanks! Great question - those are definitely relevant, but they depend a lot on the deployment model. Since CUAs often run locally or in controlled environments (e.g. a user\u2019s own VM or cluster), we can sidestep a lot of traditional SOC2/HIPAA concerns around centralized data handling. That said, if you're running agents across org boundaries or processing sensitive data via cloud APIs, then yeah - those frameworks absolutely come into play.We're designing with that in mind: think fine-grained permissioning, auditability, and minimizing surface area. But it\u2019s still early, and a lot of it depends on how teams end up using CUAs in practice.\n \nreply",
      "Would love to use this for TestDriver, but needs to support Windows :*(\n \nreply"
    ],
    "link": "https://github.com/trycua/cua",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        c/ua is the Docker Container for Computer-Use AI Agents.\n      \n\n\nTL;DR: c/ua (pronounced \"koo-ah\", short for Computer-Use Agent) is a framework that enables AI agents to control full operating systems within high-performance, lightweight virtual containers. It delivers up to 97% native speed on Apple Silicon and works with any vision language models.c/ua offers two primary capabilities in a single integrated framework:High-Performance Virtualization - Create and run macOS/Linux virtual machines on Apple Silicon with near-native performance (up to 97% of native speed) using the Lume CLI with Apple's Virtualization.Framework.Computer-Use Interface & Agent - A framework that allows AI systems to observe and control these virtual environments - interacting with applications, browsing the web, writing code, and performing complex workfl"
  },
  {
    "title": "Sail-Trim Simulator (atterwind.info)",
    "points": 77,
    "submitter": "stass",
    "submit_time": "2025-04-23T18:36:50 1745433410",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=43775283",
    "comments": [
      "I am a lake sailer. And without landmarks or anything it is impossible for me to perceive the boat as moving.\n \nreply",
      "Eventually it made sense that boat-speed only changes the \"apparent wind\", as it's only simulating wind-boat interactions, not water-boat interactions.\n \nreply",
      "I thought I was doing something wrong. It doesn't seem like anything I do has any effect, but guess that's just because there is no apparent effect.\n \nreply",
      "Even some kind of wake or something would help.\n \nreply",
      "Here is a fun sailboat race simulator. It's very simple, but pretty realistic especially for open ocean racing. You can use their default race course, sometimes join a planned regatta, or make your own. (It was great during COVID, to try racing across the oceans, or around the world. It's in real time, so you might not need to change anything for days If you are in the trade winds, and open ocean, but then when you get closer to land, things get \"Western\" very quickly - just like with a real boat. \nIt's called SailNavSim. (Learned about it from HN.)8bitbyte.ca\n \nreply",
      "A great project, but it needs some kind of grid movement and rocking, foam or something so you can perceive its movement.\n \nreply",
      "One of the most mind bending facts I tell people, even sailors, is that sailboats are not limited to sailing at the true windspeed.  Sails are wings, not bags. In fact, a boat's top speed is directly dictated by its ability to point into the wind (assuming, for example, the boat is not physically limited by it's displacement hull speed, as in the case of hydrofoils). The consequences of this simple truth are manifest.First, consider the edge case where the sail is acting as a bag when you're sailing downwind. As the boatspeed approaches the true windspeed, the apparent windspeed falls to 0 and the sail will luff.  In this specific case, the boat can not go faster than the wind.Now consider the boat cutting across the wind at a 90 angle. When the boat starts moving, the wind comes 90 degrees off the bow. As the boat increases speed, the apparent wind shifts closer to the bow. Apparent wind is just vector addition of true wind and boat wind. If the boat achieves the same speed as the true wind, then the apparent wind is sqrt(2) ~ 1.4x faster than the true wind. More wind means more power, so with that additional wind, it can go faster. Continuing the example, as the apparent wind increases, it appears closer and closer to the bow.  Eventually the sail will stall and produce less lift.  This is the point where the boat will go no faster.The slowest point of sail is directly downwind. In a race, it is often much faster to gybe back and forth rather than ever go directly downwind. When a boat goes directly downwind, their boat speed cancels out the true wind. In the strangest case, if a high performance boat going faster than the speed of wind (say, on a broadreach) goes directly downwind, the apparent wind will appear to be coming head on.  They've effectively gone 'into irons', yet they're facing 180 degrees off true wind.If you ever get the chance, you should see the SailGP boats race. Their sails are almost always hauled fully in, even downwind. The other thing is that they gybe downwind because to go directly downwind would be to stall. In effect, these boats can achieve multiple times the true wind speed, but so long as they aren't pointed directly into, nor directly away from the wind.\n \nreply",
      "Into the irons/in irons being a dead sailing area, where boat is head on into the wind (wind's eye). A lot of people get surprised that you can sail upwind as well.\n \nreply",
      "If other people are interested in sailboat physics -- this resource is a goldmine of information on how sailboat and sails work and physics around it: https://www.onemetre.net/Design/Design.htm\n \nreply",
      "I like the idea but I don't get this at all. Shouldn't the speed change based on the mainsail trim relative to the heading? I pointed the boat dead downwind, eased the mainsail all the way out and the speed is 0 kn. I can't even see the value for the trim, just speed, but you get speed from correctly trimmed sails.\n \nreply"
    ],
    "link": "https://simulator.atterwind.info/",
    "first_paragraph": ""
  },
  {
    "title": "First Successful Lightning Triggering and Guiding Using a Drone (group.ntt)",
    "points": 65,
    "submitter": "gnabgib",
    "submit_time": "2025-04-23T19:24:58 1745436298",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=43775766",
    "comments": [
      "> flying drones into optimal positions beneath thunderclouds to actively trigger lightning strikes, and then guiding the discharge safely away from vulnerable areasFrom a military standpoint, I wonder what it would take to discharge into a vulnerable area...\n \nreply",
      "You could put the wire in the vulnerable area - perhaps using the same drone? But I don't think it would be any use. A lightning strike releases about 1 GJ of energy, mostly into the sky. So the effect at the target would probably be no more than a few kg of explosives which you could have delivered using the wire anyway.\n \nreply",
      "> I wonder what it would take to discharge into a vulnerable areaHAARP /s\n \nreply",
      "Wow, getting a drone to survive the massive electromagnetic fields (and plasma!) around lightning strikes is quite an accomplishment.  Prior art in the area used rockets trailing a similar light wire to trigger lightning - used by Dr Uman's team at University of Florida (https://ufdc.ufl.edu/UFE0047331/00001).\n \nreply",
      "This is really cool, but I'm super skeptical of their proposed use case for protecting cities.Aren't lightning conditions often preceded by strong winds and poor weather conditions?  Not a great time to be flying drones.  And the approach seems more complicated than simply installing lightning rods.I'd sooner envision people using the technique to get a kick out of throwing lightning around like they're Zeus.\n \nreply",
      "I've flown my Mavics in rain and strong wind before - certainly stronger than anything I'd associate with lightning. Most of the lightning storms I've seen haven't been especially windy, but it might vary elsewhere. And that's a consumer drone with negligible weatherproofing.I assume if there's a business case, they'll eventually automate this with drone swarms that wait in cabinets on building rooftops.\n \nreply",
      "FWIW, where I live there are often intense thunderstorms during the spring and summer, and they are usually accompanied by windstorms, sometimes generating tornadoes.\n \nreply",
      "AFAIK the electric buildup starts even before the meteorological shenanigans.\n \nreply",
      "That is impressive, specially the drone surviving! I expect something along the lines of disposable drones, which would like still be cost effective at saving 100-200b yen a year!\nIt\u2019ll be fascinating seeing this deployed!\n \nreply",
      "This [1] article claims that the electricity from 115 strikes could power the entire US grid for a year, but it's surely napkin math. Awesome tech, though![1] https://www.treehugger.com/how-much-energy-is-in-lightning-8...\n \nreply"
    ],
    "link": "https://group.ntt/en/newsrelease/2025/04/18/250418a.html",
    "first_paragraph": "Microsoft ends support for Internet Explorer on June 16, 2022.We recommend using one of the browsers listed below.Please contact your browser provider for download and installation instructions.\n\n\n\n\nApril 18, 2025NTT CorporationNews Highlights:TOKYO - April 18, 2025 - NTT Corporation (Headquarters: Chiyoda, Tokyo; President and CEO: Akira Shimada; hereinafter \"NTT\") has become the first in the world to successfully trigger and guide lightning using a drone. This experiment also demonstrated, under natural lightning conditions, the effectiveness of both the drone's lightning protection technology and the electric field-based lightning triggering method. These results are expected to contribute to further research on the still-mysterious mechanisms of lightning and to help reduce lightning-related damage to cities and people.Lightning strikes are one of the most destructive natural phenomena affecting human society. While the NTT Group has implemented various lightning protection measure"
  },
  {
    "title": "The Future of MCPs (iamcharliegraham.substack.com)",
    "points": 102,
    "submitter": "tylerg",
    "submit_time": "2025-04-23T17:12:58 1745428378",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=43774327",
    "comments": [
      "Interesting thoughts regarding MCPs being the future App Store/Platform.  I don't know that I agree but I don't necessarily disagree either.  Time will certainly tell.To me, MCP feels more like an implementation detail, not something that most people would ever use directly.  I would expect that the future would be some app distributed through existing channels, which bundles the MCP client into it, then uses a server-side component (run by the vendor of course) to get the real work done.  As much as I like the idea of people installing the servers locally, that future seems like a Linux nerd/self hosted type of activity.  I just can't imagine a typical mac or windows non-power-user installing one directly.  Just the idea that they would need to install \"two apps\" is enough to confuse them immensely.  It's possible some might bundle the server too and run it locally as needed, but even in that case I think MCP is completely invisible to the user.\n \nreply",
      "MCP has a remote protocol. You don't need to install anything to add an MCP server, or rather, you won't once client support catches up to the spec. It will be a single click in whatever chat interface you use.\n \nreply",
      "Agree that for mainstream use it needs to be and will be hidden from the user entirely.Will be much more like an app store where you can see a catalog of the \"LLM Apps\" and click to enable the \"Gmail\" plugin or \"Shopping.com\" plugin.  The MCP protocol makes this easier and lets the servers write it once to appear in multiple clients (with some caveats I'm sure).\n \nreply",
      "I'd expect \"local MCP servers\" will be generally installed as part of something else. Photoshop, or Outlook, or whatever could come with a local MCP server to allow chat clients to automate them. Maybe printer drivers or other hardware would do similar. I don't think there's much reason to install a cloud service MCP server to run locally; you'd just use the one provided in the cloud.\n \nreply",
      "More like npm, not app store.\n \nreply",
      "MCP's will be run by the service providers, and you'll have the ability to \"link\" them, just like today you can link a Google account to give access to Calendar, GDrive, ... in the future you'll be able to give a model access to the Google MCP for your account.\n \nreply",
      "i wonder how granular the permissions will get though. giving model-level access to something like Gmail sounds powerful, but also like a privacy minefield if not done carefully. curious to see how trust and isolation get handled.\n \nreply",
      "> Think of MCPs as standardized APIs\u2014connectors between external data sources or applications and large language models (LLMs) like ChatGPT or Claude.This is incorrect.MCP is Model Context Protocol.You didn't \"build an MCP\", you implemented an MCP server. Lighttpd is not \"an HTTP\", it's an HTTP server. wget is also not \"an HTTP\", it's an HTTP client. Lighttpd and wget are different enough that it's useful to make that distinction clear when labeling them.dnsmasq is not \"a DHCP\", it's a DHCP server.This distinction also matters because it is certain that we will see further protocol iterations so we will indeed have multiple different MCPs that may or may not be compatible.\n \nreply",
      "> You didn't \"build an MCP\"The author explicitly states he built 2 MCP servers, not 2 MCPs, so I don\u2019t know where your beef is coming from\n \nreply",
      "I\u2019d just like to interject for a moment. What you\u2019re refering to as Linux, is in fact, GNU/Linux, or as I\u2019ve recently taken to calling it, GNU plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning GNU system made useful by the GNU corelibs, shell utilities and vital system components comprising a full OS as defined by POSIX.Many computer users run a modified version of the GNU system every day, without realizing it. Through a peculiar turn of events, the version of GNU which is widely used today is often called Linux, and many of its users are not aware that it is basically the GNU system, developed by the GNU Project.There really is a Linux, and these people are using it, but it is just a part of the system they use. Linux is the kernel: the program in the system that allocates the machine\u2019s resources to the other programs that you run. The kernel is an essential part of an operating system, but useless by itself; it can only function in the context of a complete operating system. Linux is normally used in combination with the GNU operating system: the whole system is basically GNU with Linux added, or GNU/Linux. All the so-called Linux distributions are really distributions of GNU/Linux!\n \nreply"
    ],
    "link": "https://iamcharliegraham.substack.com/publish/post/161906169",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Node.js video tutorials where you can edit and run the code",
    "points": 175,
    "submitter": "somebee",
    "submit_time": "2025-04-23T12:35:49 1745411749",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=43771365",
    "comments": [
      "This looks fantastic! I\u2019ve been seeing a growing number of tools trying to bring more interactivity to programming tutorials and for good reason. Screencasts are too passive, and it\u2019s easy to get lost halfway through. Books and blogs don\u2019t really show how code evolves over time either.I\u2019m working on a solution too, called CodeMic [1] where instead of bringing the environment to the web, it brings video and workspace sync into the IDE so viewers can follow along directly inside their own editor.You\u2019ve done an impressive job integrating everything, including the Console for example, that\u2019s especially tricky to pull off in an extension for VSCode, Emacs, or Vim.[1] https://CodeMic.io\n \nreply",
      "Interactivity and liveness in programming deserves to be discussed far more often than it is on front-page of hacker news, but excited there are multiple ongoing threads!I'm a very strong supporter of interactive blogposts as well. Obviously https://ciechanow.ski/ is leader here - being able to mess with something to build intuition is huge.\n \nreply",
      "CodeMic looks very cool, well done! A lot of people have asked us over the years whether we they can implement Scrimba into their preferred IDE, so it makes total sense to take that approach as well.\n \nreply",
      "There was this beautiful website that did something similar: it would type in the code and showing the result on the side. It was mostly creative JS code.\n \nreply",
      "Scrimba is really cool. When I first got into programming, a few years ago, I tried to build something similar using rrweb but with server side code execution in docker containers so that it could support all the programming languages like replit.When I first heard about Scrimba, I abandoned my project because I thought you guys would already go down that path. Why didn't you guys go down that route?\n \nreply",
      "Good question! Expanding from client-side JS to Node.js is our first step in that direction. We considered server-side execution for all languages but chose WebContainers instead, as it\u2019s a better fit for us when teaching fullstack web dev, and easier to maintain.That said, our new IDE is built to easily support server-side execution down the line.\n \nreply",
      "This is phenomenon! I am an iOS Engineer, not sure if you ever want to bring this to mobile but I would be happy to contribute.\n \nreply",
      "That is AWESOME! I am wondering, are you creating all the content yourself?I am doing plenty of courses across different platforms, from udemy to teachable selfhosting etc. They all lack the interactivity. I am currently hosting the code samples myself and basically redirect students there, where they can interact.But scrimba is another league!If you open this up similar to how udemy just hosts videos and does revenue share, count me in. With the webcontainers, the sky is the limit and beyond.\n \nreply",
      "We currently create the courses ourselves, but would love to see if there\u2019s an opportunity for a  collab here. Please send me an email at per@scrimba.com :)\n \nreply",
      "I logged in but I am not sure how to add video to a \"Scrim\".\nI'd love to create some Nix (https://nixos.org/) content.\nIs this possible?\n \nreply"
    ],
    "link": "item?id=43771365",
    "first_paragraph": ""
  }
]