[
  {
    "title": "Wasmer 5.0 (wasmer.io)",
    "points": 126,
    "submitter": "syrusakbary",
    "submit_time": "2024-10-29T23:02:07 1730242927",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=41990326",
    "comments": [
      "Is Wasmer still openly adversarial wrt the Bytecode Alliance?\n \nreply",
      "I wish they had a solution that didn't require Cross-Origin Isolated headers. I am still using an older version where that wasn't required.\n \nreply",
      "> having V8 as a backend also means supporting WebAssembly Exceptions and Garbage Collection under the hood. Stay tuned for more news on this front soonLooking forward to this and languages that can make use of wasm-gc.Does wasm-gc allow sharing of host data/strings across different modules in the same runtime, or is it contained to only single module with repeated calls/invocations? The scenario I am considering would invoke several different modules in a pipeline, pass data between each step in an efficient manner.\n \nreply",
      "That's what reference types (the Wasm proposal) are for, GC builds on top of that.\n \nreply",
      "Interesting.I am happy with wasmtime though.Hacking on a wasm component model and wasi based plugin system these days.Having loads of fun. (I am aware of extism, but I am doing it for the fun :))\n \nreply",
      "Sorry to be that guy but what's the business model for all these web assembly runtime companies?\n \nreply",
      "This one is running their own edge platform that you can deploy WASM apps to, but their pricing is... vague.\n \nreply",
      "Would this allow to safely eval Node.js code in a sandbox?\n \nreply",
      "Cool release!I've yet to personally find a good use case for wasm in any project, kind of the same way I'm not quite sure what to do with a bunch of Raspberry PisIt fills a need, I just don't know who/what has that need.Example: Say I write a bunch of Rust async projects for fun. Scraping APIs, etc.How/why would I choose wasm/wasmer to do that instead? I'd do it in Rust (awkwardly/in some specific non-standard way) to compile to wasm to then run in wasmer? To what benefit? Ok, that's not a good usecase/exampleSo what is?...\n \nreply",
      "A toy project, but I'm working on a Scrabble clone for my mother to play. There's singleplayer against an AI, and then multiplayer against other people (myself, mostly). Multiplayer needs a server backend with all the game logic which I have programmed in Rust, but there's no reason I can't have the game logic for singleplayer running entirely in the browser.By compiling my backend code to WASM I basically do that - the client can use either a client-side 'server' or connect to a real server. The UI code itself is unchanged in either case.I suppose the need in this case is that I have code written in a language other than JS and I want to run it in a browser; inversely I could have written the entire project in JS and hosted my backend server on say Node.\n \nreply"
    ],
    "link": "https://wasmer.io/posts/introducing-wasmer-v5",
    "first_paragraph": "ToolsToday we are presenting the latest stable version of Wasmer: v5.0 with tons of improvements and a better performance overallFounder & CEOOctober\t29, 2024We are thrilled to announce the release of Wasmer 5.0, the latest milestone in our journey to make WebAssembly the greatest tool for executing software anywhere.This announcement comes packed with awesome new features:Do you like the new features? Don't wait and give us a \u2b50\ufe0f on Github! github.com/wasmerio/wasmerSome time ago we asked in Wasmer\u2019s Community which backend would you like to see Wasmer support next.The responses were overwhelming: V8 (the engine behind Google\u2019s Chrome Javascript runtime) was the most voted backend, with 56% of the votes. We learned from the poll results that interpreter support was also a desire from the community.Well, the day has come. We have added support for more backends: V8, Wasmi and also WAMR. All of them are integrated via the Wasm-C-API , as they all share this external interface in common.T"
  },
  {
    "title": "GitHub cuts AI deals with Google, Anthropic (bloomberg.com)",
    "points": 598,
    "submitter": "jbredeche",
    "submit_time": "2024-10-29T16:20:17 1730218817",
    "num_comments": 393,
    "comments_url": "https://news.ycombinator.com/item?id=41985915",
    "comments": [
      "https://archive.is/Il4QM",
      "I use cursor and its tab completion; while what it can do is mind blowing, in practice I\u2019m not noticing a productivity boost.I find that ai can help significantly with doing plumbing, but it has no problems with connecting the pipes wrong. I need to double and triple check the updated code - or fix the resulting errors when I don\u2019t do that. So: boilerplate and outer app layers, yes; architecture and core libraries, no.Curious, is that a property of all ai assisted tools for now? Or would copilot, perhaps with its new models, offer a different experience?\n \nreply",
      "I'm actually very curious why AI use is such a bi-modal experience. I've used AI to move multi thousand line codebases between languages. I've created new apps from scratch with it.My theory is the willingness to baby sit and the modality. I'm perfectly fine telling the tool I use its errors and working side by side with it like it was another person. At the end of the day it can belt out lines of code faster than I, or any human, can and I can review code very quickly so the overall productivity boost has been great.It does fundamentally alter my workflow. I'm very hands off keyboard when I'm working with AI in a way that is much more like working with someone or coaching someone to make something instead of doing the making myself. Which I'm fine with but recognize many developers aren't.I use AI autocomplete 0% of the time as I found that workflow was not as effective as me just writing code, but most of my most successful work using AI is a chat dialogue where I'm letting it build large swaths of the project a file or parts of a file at a time, with me reviewing and coaching.\n \nreply",
      "As a programmer of over 20 years - this is terrifying.I'm willing to accept that I just have \"get off my lawn\" syndrome or something.But the idea of letting an LLM write/move large swaths of code seems so incredibly irresponsible. Whenever I sit down to write some code, be it a large implementation or a small function, I think about what other people (or future versions of myself) will struggle with when interacting with the code. Is it clear and concise? Is it too clever? Is it too easy to write a subtle bug when making changes? Have I made it totally clear that X is relying on Y dangerous behavior by adding a comment or intentionally making it visible in some other way?It goes the other way too. If I know someone well (or their style) then it makes evaluating their code easier. The more time I spend in a codebase the better idea I have of what the writer was trying to do. I remember spending a lot of time reading the early Redis codebase and got a pretty good sense of how Salvatore thinks. Or altering my approaches to code reviews depending on which coworker was submitting it. These weren't things I were doing out of desire but because all non-trivial code has so much subtlety; it's just the nature of the beast.So the thought of opening up a codebase that was cobbled together by an AI is just scary to me. Subtle bugs and errors would be equally distributed across the whole thing instead of where the writer was less competent (as is often the case). The whole thing just sounds like a gargantuan mess.Change my mind.\n \nreply",
      "> The more time I spend in a codebase the better idea I have of what the writer was trying to do.This whole thing of using LLMs to Code reminds me a bit of when Google Translate came out and became popular, right around the time I started studying Russian.Yes, copying and pasting a block of Russian text produced a block of english text that you could get a general idea of what was happening. But translating from english to russian rarely worked well enough to fool the professor because of all the idioms, style, etc. Russian has a lot of ways you can write \"compactly\" with fewer words than english and have a much more precise meaning of the sentence. (I always likened russian to type-safe haskell and english to dynamic python)If you actually understood Russian and read the text, you could uncover much deeper and subtle meaning and connections that get lost in translation.If you went to russia today you could get around with google translate and people would understand you. But you aren't going to be having anything other than surface level requests and responses.Coding with LLMs reminds me a lot of this. Yes, they produce something that the computer understands and runs, but the meaning and intention of what you wanted to communicate gets lost through this translation layer.Coding is even worse because i feel like the intention of coding should never to be to belt out as many lines as possible. Coding has powerful abstractions that you can use to minimize the lines you write and crystalize meaning and intent.\n \nreply",
      "> the intention of coding should never to be to belt out as many lines as possibleThat\u2019s such an underrated statement. Especially when you consider the amount of code as a liability that you\u2019ll have to take care later.\n \nreply",
      "I've heard a similar sentiment: \"It's not lines of code written, it's lines of code spent.\"It also reminds me of this analogy for data, especially sensitive data: \"it's not oil, it's nuclear waste.\"\n \nreply",
      "You still use type systems, tests, and code review.For a lot of use cases it's powerful.If you ask it to build out a brand new system with a complex algorithm or to perform a more complex refactoring, it'll be more work correcting it than doing it yourself.But that malformed JSON document with the weird missing quotation marks (so the usual formatters break), and spaces before commas, and the indentation is wild...  Give it to an LLM.Or when you're writing content impls for a game based on a list of text descriptions, copy the text into a block comment.  Then impl 1 example.  Then just sit back and press tab and watch your profits.\n \nreply",
      "The (mostly useless boilerplate \u201cI\u2019m basically just testing my  mocks\u201d) tests are being written by AI too these days.Which is mildly annoying as a lot of those tests are basically just noise rather than useful tools. Humans have the same problem, but current models are especially prone to it from what I\u2019ve observedAnd not enough devs are babysitting the AI to make sure the test cases are useful, even if they\u2019re doing so for the original code it produced\n \nreply",
      "> But the idea of letting an LLM write/move large swaths of code seems so incredibly irresponsible.I do think it is kind of crazy based on what I've seen. I'm convinced LLM is a game changer but I couldn't believe how stupid it can be.  Take the following example, which is a spelling and grammar checker that I wrote:https://app.gitsense.com/?doc=f7419bfb27c8968bae&samples=5If you click on the sentence, you can see that Claude-3.5 and GPT-4o cannot tell that GitHub is spelled correctly most of the time. It was this example that made me realize how dangerous LLM can be. The sentence is short but Claude-3.5 and GPT-4o just can't process it properly.Having a LLM rewrite large swaths of code is crazy but I believe with proper tooling to verify and challenge changes, we can mitigate the risk.I'm just speculating, but I believe GitHub has come to the same conclusion that I have, which is, all models can be stupid, but it is unlikely that all will be stupid at the same time.\n \nreply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2024-10-29/microsoft-s-github-unit-cuts-ai-deals-with-google-anthropic",
    "first_paragraph": "Connecting decision makers to a dynamic network of information, people and ideas, Bloomberg quickly and accurately delivers business and financial information, news and insight around the worldAmericas+1 212 318 2000EMEA+44 20 7330 7500Asia Pacific+65 6212 1000Connecting decision makers to a dynamic network of information, people and ideas, Bloomberg quickly and accurately delivers business and financial information, news and insight around the worldAmericas+1 212 318 2000EMEA+44 20 7330 7500Asia Pacific+65 6212 1000The AI Race:GitHub\u2019s Copilot coding assistant will offer new AI models as option for\u00a0users who want to switch from OpenAI.After teaming up with\u00a0OpenAI a few years\u00a0ago, GitHub pioneered the use of generative artificial intelligence to automate tedious parts of the coding process.Microsoft Corp.\u2019s GitHub has agreed to bake artificial intelligence models from Anthropic and Alphabet Inc.\u2019s Google into a coding assistant used by millions of software developers. At first, custome"
  },
  {
    "title": "OpenAI builds first chip with Broadcom and TSMC, scales back foundry ambition (reuters.com)",
    "points": 179,
    "submitter": "marban",
    "submit_time": "2024-10-29T17:19:44 1730222384",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=41986926",
    "comments": [
      "> OpenAI considered building everything in-house and raising capital for an expensive plan to build a network of factories known as \"foundries\" for chip manufacturing. The company has dropped the ambitious foundry plans for now due to the costs and time needed to build a networkThat framing massively undersells how insane Sams ambitions were there, he was floating the idea of somehow raising seven trillion dollars to build thirty six fabs dedicated to making AI silicon. The TSMC execs reported more or less laughed in his face when he brought it up it them.\n \nreply",
      "As anyone with 2 brain cells should have.You don't just acquire $7T.The ENTIRE US domestic Net Investment isn't even $1T: https://fred.stlouisfed.org/series/W790RC1Q027SBEAGross Fixed Capital Formation (Net Investment + Deprecation) isn't much more: https://fred.stlouisfed.org/series/NFIRSAXDCUSQGoogle, Apple, and Microsoft together don't even spend $100B on CapEx per year. And they're worth almost $10T put together.Asking for $7T when you're a $100B company is so ridiculous it's beyond belief.\n \nreply",
      "Sound like the beginning of Universal Paperclipshttps://en.wikipedia.org/wiki/Universal_Paperclips\n \nreply",
      "And if it was a 30% stake in OpenAI for that $7 trillion (kind of a standard VC round percentage) that would put OpenAI's valuation at about the same of all of the 7000-ish NASDAQ companies (including almost all public tech companies) combined.\n \nreply",
      "There was probably a point of maximum hype ~12 months ago, or right after the launch of GPT-4 where the belief of imminent singularity was running high.\n \nreply",
      "But, singularity is still imminent. Right? Where on the spectrum of completely useless/no AI to singularity are we at?\n \nreply",
      "It\u2019s gonna require N more hype cycles (bearing in mind that usefulness is the expected endpoint of the hype cycle)\n \nreply",
      "He would have to have AGI proof to ask for this unprecedented kind of investing money.And even them it would have to be split during a decade or two. And even then.What's the military budget of USA?\n \nreply",
      "It doesn't matter what the military budget is.Most of it is spent on personnel and operation.You'd want to know only what the procurement is - which is ~$146B: https://en.wikipedia.org/wiki/Military_budget_of_the_United_...And most of that is part of Gross Fixed Capital Formation already...\n \nreply",
      "What is dark budget look like these days.\n \nreply"
    ],
    "link": "https://www.reuters.com/technology/artificial-intelligence/openai-builds-first-chip-with-broadcom-tsmc-scales-back-foundry-ambition-2024-10-29/",
    "first_paragraph": ""
  },
  {
    "title": "RIP botsin.space (muffinlabs.com)",
    "points": 91,
    "submitter": "edent",
    "submit_time": "2024-10-29T21:18:58 1730236738",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=41989511",
    "comments": [
      "Federated networks like Mastodon and Lemmy are going to get people well-acquainted with websites shutting down.  It's hard work (time, money, etc.) to run these things for people, and people start to really lean on them.It's almost novel now days getting sucked into something that shuts down.  killedbygoogle.com is a meme partly I think because websites shutting down is just so uncommon in areas that we get personally invested in.I run my own Lemmy instance just for my self and even that can be trying sometimes.  I enjoy using it instead of reddit, but one day I will probably shut it down and be sad.\n \nreply",
      "I'm starting to think nostr was barking up the right tree after all. Put as much complexity into the client as possible and make the servers dumb and completely uncoordinated, utterly interchangeable. Spam your broadcasts to any relay that will listen. No idea if it actually works (I've read a lot about nostr and AT proto but never used either of them) but I think it's very obvious that any system that deeply relies on some company that everyone becomes extremely reliant on (including AT proto/Bluesky) is only a couple steps away from the same sort of problems as centralization.Of course, the real gold standard would be P2P, if only it could work. But... mobile phones can't burn battery running P2P clients in the background, everyone's under a NAT these days, and some types of software (like microblogging networks) would be horrifically intractable as a P2P system.Oh well. At the very least, I really love the concept of Decentralized Identifiers (DIDs). I'd like to see more stuff like that.\n \nreply",
      "The atproto team came from the p2p space. We had a lot of experience running client-side computation. There are challenges you can try to solve in that design -- key sync, key recovery, reliable hosting, reliable discovery, etc -- but what you can't get around is the need to run queries against aggregations of data. Even scales that we consider \"mid\" start to strain on the client-driven model. Federated queries might be able to solve it, but it's extremely challenging to get reliable performance out of that. The design we landed on was replaceable big nodes.The common comparable people raise is email/gmail, but we used the DID system and account portability to try to get a better outcome on provider migration. It's hopefully more like web/google -- which still has the centralizing pressures of scale benefits, but hopefully injects enough fluidity in the system to move the situation forward. Sometimes, you pick the design that moves the ball down the field, not the one that guarantees a touchdown. If somebody wanted to improve on what we've done, I'd tell them to focus on the federated queries problem.\n \nreply",
      "In theory AT proto doesn't seem like a bad design. I've read a fair bit of the docs, although mostly skimming. (I've been meaning to read the paper on Merkle Search Trees so I can figure out what exactly is going on with PDSes.)On the other hand, in practice it seems like the AT proto infrastructure is still very centralized for now. DIDs are excellent in theory, but everyone is using PLC DIDs, which depends on the centralized plc.directory. You can run your own PDSes, but there's only one relay for now (that I am aware of.) I also don't think there is more than one instance of the Bluesky AppView, and the official instance is locked into the Bluesky Moderation Service, which seems to limit the usefulness of some of the censorship resistance of the protocol.I'm not sure how much of that is social problems rather than technical, but I worry that since Bluesky and AT proto are gaining massive popularity with this status quo (millions of users!) it'll have a problem akin to Matrix.org, where in practice almost everyone is using the same infrastructure anyways.It's still relatively early days, but millions of people is definitely enough to where you start to hit problems with having everyone under one roof. I really hope we get to see how things play out when more of the network is operated independently.\n \nreply",
      "The necessary future is more providers, more relays, a move of PLC to an independent body, and more DID methods.I will also say - there are ~100 self-hosting PDSes in the network, about 25 relay consumers, 3 alternative appviews that I know of (smoke signals, frontpage.fyi, and whitewind), the firehose & backfill are fully available, the specs are getting fairly complete, and the software is open source. This is a priority for us.\n \nreply",
      "fwiw roughly 50% of Matrix is on the matrix.org instance currently. we consider this a bug, but also prioritise ease of onboarding over decentralisation purity ideology.\n \nreply",
      "ActivityPub seems to require a lot of hardware resources in order to run properly, which is unfortunate. It\u2019s not something I would ever want to run myself, especially to the public.\n \nreply",
      "Please be wary to conflate ActivityPub with the code on top of it, like Mastodon for instance; which is, on both front and back-end, proven to be resource intensive and difficult/costly to scale especially over time. (the older the dbs get, the more inactive users pile up, etc.)Versus something like Pleroma; which I've used since it's inception, being incredibly janky and lightweight, prone to breaking, but later versions have mostly ironed out most of those catastrophic bugs.  It has it's own challenges as well, but it does historically scale better, is more flexible, and less intensive per instanceOne demands a lot of money and time, where the other demands a lot of time and not so much on the money side. \nI'm not going to spend the time to give you a history of pleroma/mastodon instances, as it's a controversial history at best and there's a lot of people who know little, yet who will believe themselves an oracle. (ofc that could also be me so take it with a grain of salt and all)\nThough if you are willing to read through a bunch of highly opinionated accounts, and you pay close attention to what actually happened, the answer is pretty clear.ActivityPub is intensive, but not the main culprit.\n \nreply",
      "I wonder how much of that is endemic to ActivityPub or how much is about the software stack itselfI don\u2019t mean to be glib, just wondering if things can be \u201cdone better\u201d\n \nreply",
      "I'm guessing the syncing process between instances is really brutal on resources.  Imagine constantly syncing external databases for your service to function properly.\n \nreply"
    ],
    "link": "https://muffinlabs.com/posts/2024/10/29/10-29-rip-botsin-space/",
    "first_paragraph": "\n\n\t\t29 October 2024\n\t\nThere's no easy way to put it, so here goes -- after a lot of consideration, I've made the hard (frankly, painful) decision to shut down botsin.space. TLDR: here's the plan:I launched botsin.space in April of 2017, which honestly feels like it was about six thousand years ago. Originally I just wanted to play around with the fediverse and Mastodon. The oauth flow for creating a bot was messy, so I forked Mastodon and fixed it, deployed those changes to botsin.space, and invited people to create bots.The server was popular with bot allies and artists, people who wanted to get RSS feeds onto the fediverse, as well as students and professors who wanted to work on coding projects or learn about federated social media. There have been some moderation challenges over the years, but to be honest those have never been all that considerable.But botsin.space has always been a bit of an odd duck with a unique set of challenges. Over the years, the server has grown to have ar"
  },
  {
    "title": "Using an 8K TV as a Monitor (lawrence.lu)",
    "points": 286,
    "submitter": "ingve",
    "submit_time": "2024-10-29T16:27:56 1730219276",
    "num_comments": 333,
    "comments_url": "https://news.ycombinator.com/item?id=41986048",
    "comments": [
      "Author here, ask me anything!Apart from programming, one of the motivations for getting the 8K display is to look at lidar point clouds. For example the desktop background in my post is a lidar map of Bernal Hill in San Francisco, which I've here downsampled to only 13006 x 7991 px for your convenience [1].Admittedly, when I bought it at first, I didn't realize there would be so many random issues, as manufacturers all advertised their gear as \"8K Ready\" even in 2021. As I incrementally fixed the problems, I decided to document my journey in this blog post.btw I posted this in the past but it got caught by the spam filter and disappeared [2], not sure how to appeal that when it happens. Thanks ingve for posting it again![1] https://pics.dllu.net/file/dllu-lidar/tldr_707_all_c_fine_50... (13006 x 7991 px)[2] https://news.ycombinator.com/item?id=41102135\n \nreply",
      "I had the Dell 8k monitor you mentioned, the picture quality was great but it died after a few years not long after the warranty expired (a gut punch at the purchase price) and they said too bad so sad... ok that's fine but I will never buy another Dell product again.  It was released too early to have proper displayport support and I had to use a custom nvidia-driver X11 config to make it mostly work as two monitors.  And there is basically no way to use that kind of DPI without scaling.I replaced it with an LG 43UN700 which is a 43\" 4K display that I use unscaled and although the LCD panel is vastly inferior I love the thing especially at the price point (under $700).  I hope manufacturers continue to support this niche of large singular flat displays because they are fantastic for coding, data viewing/visualization and pitch hit at content consumption as your article states although this one would be no good for gaming.  And getting a \"monitor\" or \"professional display\" firmware load means a lot less problems than a Smart TV load.\n \nreply",
      "I had a similar experience with Dell after they wanted the price of a new laptop for a replacement laptop battery. This was for the Dell Studio back when battery packs were made to be swappable by simply sliding a latch.After that phone call to customer support, I made a similar vow to never buy another Dell product. These days, I use a Framework laptop.\n \nreply",
      "Do you have 20/20 eyesight, and how tall are you?I use glasses (myopia) and can kind of tolerate the edges of my 32\" 4k monitor, but I can't fathom craning my neck all the way up to the edges of a 55\"+ display. Not to mention font sizes.\n \nreply",
      "I have fairly bad eyesight with both myopia and astigmatism (-5 sph, -2 cyl) and I wear glasses. I got glasses with 1.71 index lenses, which I greatly prefer over the more common 1.74 index lenses due to the higher Abbe number, resulting in less chromatic aberration.Anyway, I use browsers at 150% scaling usually, although the text is finer on my terminals. I don't use any scaling for UI elements and terminals. Using the i3 tiling window manager, I put more commonly used terminals on the bottom half of the screen since I find that the top half does require more neck craning.I'm 184 cm tall.\n \nreply",
      "FWIW there are lenses that are high index while still having a higher Abbe number, but they're expensive and pretty specific materials. Interesting that 1.74 are more common where you are, where I am lower index polycarb are the standard (sadly)\n \nreply",
      "I had a 55\" TV as my main display in 2022. Had it about a foot away from my face. It takes a few days, but your brain and body get used to the size.I just bought a 39\" ultrawide and for the first few days I thought \"oh dear, I have to keep turning to see the whole thing,\" but I've not even thought about it for a couple of weeks now, so I guess I'm acclimated.YMMV.\n \nreply",
      "I have been using a 32\" monitor for the last 10 years. I have found that I am using mostly the center of the monitor. The peripheral edges remain unused.If I sit far from the monitor, then the FOV could be reduced, but then I have to increase the font size defeating the very purpose of maximizing screen real estate.\n \nreply",
      "This is pretty much what I concluded as well after using my 43\" 4K LG monitor for about 3 years. Lately I've been trying out my wife's 27\" Apple Studio Display. It's smaller but the PPI is amazing...\n \nreply",
      "Isn't it good for a little exercise? Maybe we should have 300\" monitors so we jog from one edge of the screen to the other as we type code :)\n \nreply"
    ],
    "link": "https://daniel.lawrence.lu/blog/y2023m12d15/",
    "first_paragraph": ""
  },
  {
    "title": "Go library for in-process vector search and embeddings with llama.cpp (github.com/kelindar)",
    "points": 36,
    "submitter": "kelindar",
    "submit_time": "2024-10-28T06:01:42 1730095302",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41968173",
    "comments": [
      "This library was created to provide an easy and efficient solution for embeddings and vector search, making it perfect for small to medium-scale projects that still need some vector search. It's built around a simple idea: if your dataset is small enough, you can achieve accurate results with brute-force techniques, and with some optimizations like SIMD, you can keep things fast and lean.\n \nreply",
      "I love that you chose to wrap the C++ with purego instead of requiring CGO! I wrapped Microsoft's Lightgbm library and found purego delightful. (To make deployment easier, I embed the compiled library into the Go binary and extract it to a temp directory at runtime. YMMV.)\n \nreply",
      "This post led me to purego, and I've just finished moving my toy project that uses PKCS#11 libraries from cgo to it. It's so much better now! No need to jump through hoops for cross-compilation.\n \nreply",
      "> git submodule update --init --recursivenope. this looks cool, but Git submodules are cursed\n \nreply"
    ],
    "link": "https://github.com/kelindar/search",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Go library for embedded vector search and semantic embeddings using llama.cpp\n      \n\n\n\n\n\n\n\nThis library was created to provide an easy and efficient solution for embedding and vector search, making it perfect for small to medium-scale projects that still need some serious semantic power. It\u2019s built around a simple idea: if your dataset is small enough, you can achieve accurate results with brute-force techniques, and with some smart optimizations like SIMD, you can keep things fast and lean.The library\u2019s strength lies in its simplicity and support for GGUF BERT models, letting you leverage sophisticated embeddings without getting bogged down by the complexities of traditional search systems. It offers GPU acceleration, enabling quick computations on supported hardware. If your dataset has fewer than 100,000 entries, this library is"
  },
  {
    "title": "A Performance Comparison of Modern Garbage Collectors (2021) [pdf] (rodrigo-bruno.github.io)",
    "points": 12,
    "submitter": "mfiguiere",
    "submit_time": "2024-10-29T22:26:39 1730240799",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://rodrigo-bruno.github.io/mentoring/77998-Carlos-Goncalves_dissertacao.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Writing in Pictures: Richard Scarry and the art of children's literature (yalereview.org)",
    "points": 213,
    "submitter": "cainxinth",
    "submit_time": "2024-10-29T13:24:55 1730208295",
    "num_comments": 94,
    "comments_url": "https://news.ycombinator.com/item?id=41983622",
    "comments": [
      "I loved Richard Scarry as a child\u2014still do!\u2014and I'm convinced his books really helped build up my vocabulary as I learned English in first grade.A detail I only mentally noted as an adult: the butchers in his books are always pigs themselves. A pig selling ham, sausages and, presumably, cuts of pork is a bit morbid (and also hilarious in a black humor sort of way), but it fits in with the world so much that I didn't even think twice about it as a kid. It just slid past me.I still remember one of the books I had as a child\u2014can't recall the title exactly\u2014that had a bunch of urban scenes with various objects labeled. What really stood out were the little details and funny little stories going on. The stories and the humor got me to pay attention and actually care about the objects (and their labels!) far more than any generic vocabulary book for kids.What I love about Richard Scarry is that he is never patronizing or condescending. Too many authors of children's books either try to write down to kids, try to write what they think kids ought to read, or both. But kids aren't idiots and they can tell! Well, I can't speak for everyone, but at least as a kid myself I found a lot of children's works either patronizing or unpleasant\u2014works that were trying too hard to be childlike or, especially, works that were transparent morality plays.Scarry's work is nothing like this at all. It's oriented for and accessible to kids, but it manages to be simple and silly in a genuine way. The art and stories are actually cute and funny rather than caricatures of what an adult thinks a child would find cute and funny. You can tell Scarry was making something he would enjoy himself. That's why I loved his books when I was five and why I still love his books now.It's hard to find other children's books like that. I collect illustrated books and the majority I see in stores are awful. The most successful exception I've seen are books by Joe Klassen (of I Want My Hat fame) along with his common collaborator Mac Barnett. Their books are legitimately funny and visually attractive to adults, they're willing to write stories that aren't entirely saccharine, and children absolutely love them. I've seen that first-hand.\n \nreply",
      "> A detail I only mentally noted as an adult: the butchers in his books are always pigs themselves. A pig selling ham, sausages and, presumably, cuts of pork is a bit morbid (and also hilarious in a black humor sort of way), but it fits in with the world so much that I didn't even think twice about it as a kid. It just slid past me.Also: every scarecrow has a crow sitting on it.\n \nreply",
      "I hadn't noticed that. It's an absolutely hilarious little touch.\n \nreply",
      "The Pooh books are like that. There's a bit of wry adult humor sprinkled in with it, too.Other cartoons \"for kids\" with an adult track in them:SpongeBob (the first couple seasons)Rocky and Bullwinkle\n \nreply",
      "> I didn't even think twice about it as a kid. It just slid past me.I think that the best children's books always have something in them that will be appreciated later.  They can be read and re-read as one grows older.  Probably the greatest prose exponent was Lewis Carroll.\n \nreply",
      "I think also they put something in for the parents so reading the same book over and over and over to your kids isn't as boring.\n \nreply",
      "My wife was quite sad when I suggested to her that \"this little piggie went to market\" was in fact the farmer taking the pig to the market to be butchered, and that \"this little piggie went wee wee wee all the way home\" was probably a piglet taken from its family to replace the \"now big enough to sell\" pig....\n \nreply",
      "My 3 year old recently picked up a sausage and asked \"did this used to be a pig?\"\"Yes, that used to be a pig.\"\"OK!\" and popped it into his mouth.Kids really don't care.\n \nreply",
      "If you wish to enjoy sausage, it's probably best not to enquire into how swine are raised and kept in our time.\n \nreply",
      "I think she'd always imagined a pig with a hat and overalls walking down the street to buy the sunday newspaper...\n \nreply"
    ],
    "link": "https://yalereview.org/article/chris-ware-richard-scarry",
    "first_paragraph": "The original cover sketch for Richard Scarry\u2019s Cars and Trucks and Things That Go, which was first published in 1974. Courtesy Penguin Random HouseAs a boy, I knew I was supposed to like cars and trucks and things that go. But as an unathletic and decidedly unboyish kid, I only got close to liking one car\u2014my mom\u2019s blue Volkswagen Ghia, which she used to ferry me to and from school (and, when she needed some time to herself, to her parents\u2019\u2014my grandparents\u2019\u2014house for an overnight visit). In fact, I didn\u2019t just like that car, I loved it, so much so that the day it was towed away I secretly chipped a piece of the sky-colored paint from the chassis and tearfully hid it in a little box. I never had the chance to develop such a special relationship with a truck or a bus or an airplane or anything else with a motor or wheels\u2014in fact, such things scared me, and to this day I have never changed a tire.In my grandparents\u2019 second-floor guest room, formerly my mother\u2019s childhood room, one bookcase"
  },
  {
    "title": "Nuclear Fusion's New Idea: An Off-the-Shelf Stellarator (ieee.org)",
    "points": 29,
    "submitter": "mfiguiere",
    "submit_time": "2024-10-29T20:11:18 1730232678",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41988799",
    "comments": [
      "Cool.But even if you have a working stellarator that's a very long way from an economically viable energy source. You've still got to a) figure out how to cheaply convert the released energy into electricity (and the baseline way of doing that in D-T fusion is...a steam turbine), and b) figure out materials that can survive the radiation bombardment for a sufficiently long time.In sunny places (and I fully acknowledge that's not all of the world) it's still going to be hard to beat sticking bits of special glass out in a field and connecting wires to it.But we should sure as heck keep tinkering away at it!\n \nreply",
      "I admittedly don't know much about fusion reactors, but I do love that the thing which you create a star within is called a \"Stellarator\".\n \nreply",
      "People don't understand the fundamental problem of fusion. It's a problem of energy loss. Of enormous energy losses.Roughly speaking energy can be mechanical, for particles or radiative, for photons. The first one is proportional to the temperature (the famous NRT) and the second is proportional to the fourth power of the temperature. The constant of proportionality is very small, and at regular temperatures we generally don't think of it that much. But at millions of degrees Kelvin, it starts to dominate all considerations.The heat always moves form hot to cold. In the case of particles the heat flow is proportional to the difference in temperature, and in the case of radiation with the difference in temperature to the power 4. But heat also travels from particles to photons and vice-versa. It doesn't matter how.The problem with fusion is now this. Suppose that you have a super-duper device, let's call it brompillator. It brings an amount of deuterium-tritium mix at the required temperature, let's say 10 million Kelvin. Now that volume of plasma is surrounded by cold stuff. You can imagine that you have some mirrors, or magnetic fields, or some magic stuff, but the cold hard stuff is that that plasma will want to radiate to the exterior and the flow of heat would be proportional to the surface area times the fourth power of the difference in temperature. Since for all practical purposes the outer temperature is zero, we are talking about the fourth power of 10 million Kelvin. Now that constant of porportionality is very small, it is called the Stefan-Boltzman constant and has a value of about 10^7 W m^-2 K^-4. Let's say the surface area is 1 square meter. So the heat loss happens at a rate of 10^-7 times (10^7)^4 = 10^21 Watts. That is 10^12 GigaWatts. One GW is the output of a decent sized nuclear power plant.Of course, you can try to shield that plasma, but that shield has to be 99.99999....9% effective, where the number of 9s needs to be about 15 or so.That is the immensity of the challenge that nobody is willing to tell you about.How was this overcome in the case of the thermonuclear bomb? People imagine that once you have a fission bomb, you just put some deuterium-tritium mix next to it, and voila, you have a fusion bomb. No. The world's greatest minds have worked at this issue for about 5 years. The solution was something like this: if you first compress significantly the volume of fusion fuel, then the heat losses are much smaller (remember they are proportional to the area, and that's proportional to the square of the radius). They will still be tremendous, but you don't even aim to keep the reaction going for a long time. The duration of the fusion reaction in a thermonuclear bomb is still classified information, but public sources put it at the order of 1 microsecond. The heat losses are still tremendous, but for a short moment the heat gains from the fusion reaction are even greater, so ignition is achieved.In the NIF experiment that achieved more than breakeven 2 years ago, the fusion lasted less than 10 nanoseconds [1].If someone thinks the brompillator will achieve fusion and that will run for years, or even hours, or seconds, they don't understand the fundamental problem. Unfortunately, nobody is willing to ask hard questions about this, not even Sabine Hossenfelder.[1] https://journals.aps.org/prl/pdf/10.1103/PhysRevLett.132.065...\n \nreply",
      "> People don't understand the fundamental problem of fusion. It's a problem of energy loss. Of enormous energy losses.I'm not sure that's even true, because if you manage to crack that, you still have the problem that your sustainable reaction is pumping out most of its energy in the form of very fast neutrons, which are (a) very hard to harvest energy from and (b) extremely bad for people and materials if you don't. You could have a self-sustaining reaction that you can't actually use!\n \nreply",
      "Aneutronic fusion has been previously mentioned, specifically HB11.https://en.m.wikipedia.org/wiki/Aneutronic_fusion\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/the-off-the-shelf-stellarator",
    "first_paragraph": "Fast prototyping revives a 70-year-old reactor design Researchers Michael Zarnstorff [left] and Kenneth Hammond at the Princeton Plasma Physics Laboratory run nuclear-fusion reactions in a stellarator built with mostly off-the-shelf parts.  For a machine that\u2019s designed to replicate a star, the world\u2019s newest stellarator is a surprisingly humble-looking apparatus. The kitchen-table-size contraption sits atop stacks of bricks in a cinder-block room at the Princeton Plasma Physics Laboratory (PPPL) in Princeton, N.J., its parts hand-labeled in marker.\n\n\tThe PPPL team invented this nuclear-fusion reactor, completed last year, using mainly off-the-shelf components. Its core is a glass vacuum chamber surrounded by a 3D-printed nylon shell that anchors 9,920 meticulously placed permanent rare-earth magnets. Sixteen copper-coil electromagnets resembling giant slices of pineapple wrap around the shell crosswise.\n\n\tThe arrangement of magnets forms the defining feature of a stellarator: an entir"
  },
  {
    "title": "Launch HN: Integuru (YC W24) \u2013 Reverse-engineer internal APIs using LLMs (github.com/integuru-ai)",
    "points": 158,
    "submitter": "richardzhang",
    "submit_time": "2024-10-29T13:00:40 1730206840",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=41983409",
    "comments": [
      "In my experience reverse engineering is often the easy bit, or at least easy compared to what follows: maintenance. Knowing both when and how it fails when it fails (eg in cases like when the API stops returning any results but is still otherwise valid). Knowing when the response has changed in a way that is subtle to detect, like they changed the format of a single field, which may still parse correctly but is now interpreted incorrectly.How do you keep up with the maintenance?\n \nreply",
      "If your landing page doesn't look like this, you've launched too late: https://integuru.ai\n \nreply",
      "Page source is amazing. I can't remember the last time I've seen a serious YC company launch page with absolutely zero JavaScript. Even the CSS is just a single selector.I'm a fan.\n \nreply",
      "Their website is this one though. :)\nhttps://www.taiki.ai/\n \nreply",
      "@richardzhang what is the relationship between taiki and integuru? is this a pivot?\n \nreply",
      "We should definitely further clarify this! We built Integuru as an internal tool while building the products for Taiki. Then we realized that other developers may need the agent, too, so we decided to open-source Integuru. In terms of the current focus for our team, we are spending most of our time on Integuru because newly requested integrations take some of our resources to build, and we want to continue improving the agent. I think the correct way to frame this is a market expansion, where we're expanding beyond the tax industry.\n \nreply",
      "I wish I could do this\u2026 best part of building for devs is being able to provide simple, good UX with minimal UI.\n \nreply",
      "Still looks more interesting than that Next.js landing page template used by every startup these days.\n \nreply",
      "I don't know what my PM would say but to me this is \"excellent and appealing design\"\n \nreply",
      "This is what happens when your daily grind is cutting through all kinds of atrocious and excessive \"web design\" in order to get at information.\n \nreply"
    ],
    "link": "https://github.com/Integuru-AI/Integuru",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The first AI agent that builds third-party integrations through reverse engineering platforms' internal APIs.\n      An AI agent that generates integration code by reverse-engineering platforms' internal APIs.You use create_har.py to generate a file containing all browser network requests, a file with the cookies, and write a prompt describing the action triggered in the browser. The agent outputs runnable Python code that hits the platform's internal endpoints to perform the desired action.Let's assume we want to download utility bills:Set up your OpenAI API Keys and add the OPENAI_API_KEY environment variable. (We recommend your open ai account to have models that are at least as capable as OpenAI o1-mini. Models on par with OpenAI o1-preview are ideal.)Install Python requirements via poetry:Open a poetry shell:Run the following co"
  },
  {
    "title": "Hobby CAD, CNC machining, and resin casting (coredump.cx)",
    "points": 29,
    "submitter": "hughgrunt",
    "submit_time": "2024-10-29T20:57:32 1730235452",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41989322",
    "comments": [
      "oh my! I found this exact page in ~2017. I m something of a tab hoarder and I had around 2k open tabs back then. I loved the page and content and wanted to get back to it, but you know how it goes. Somewhere in early 2018 my browser crashed and I lost the tab. I distinctively remembered losing that page and I tried to find it, over and over again. I actually had one of the pictures saved (blue-red-white wheel), so I opened it in new tab as placeholder until I find the page. 6 years later here we are!!! tnx hughgrunt xd\n \nreply",
      "Shameless plug if anyone is interested - I'm working on a $600-ish open-source, reasonably capable, but small and somewhat \"tidy\" hobby CNC machine with BOM cost around $600 that requires some DIYing.It's meant to be an alternative to the Desktop CNCs like Nomad, Carvera, Bantam, ... moreso than a PCNC or other proper entry-level CNC.The ultimate goal is to make it hobbyist-friendly, capable of easily cutting alumin(i)um and not taking up a lot space, not being messy or loud enough to require a dedicated workshop. Unfortunately, cutting metal is inherently loud so you probably would not be able to run it in an apartment as I'd hoped.I've made a couple decisions around being friendly for people coming from the 3DP space around probing, using roborock CPAP as chipvac, running it mostly dry, fully enclosed. I'm also starting to work on computer-vision-based probing and the idea is to later enable a host of more user-friendly and safety-focused features and maybe integration with Kiri:Moto's CNC mode for \"guided\" CAM and so on - basically a beginner-friendly CNC that guides newbies using an integrated web-interface.More info on Github: https://github.com/thingsapart/mini_ncGH is a little outdated but I've been using the little machine to cut alu for a while (mostly parts for itself) and it's working quite well. There's more videos and such on the Discord linked in the GH readme - feel free to ask questions on the Discord, I try to respond as quickly as I can. The full model with all its components is completely open in Onshape (I know it's not ideal but how I learned CAD - link also on GH).\n \nreply",
      "Former MechE for a decade and I owned personal CNC routers and on my 6th 3D printer. The biggest issue with CNC is the cost for consumables and accessories. Need a special bit? $$$ Need stock to cut? $$$ Want a nice ER11 or R2 collet set? $$$. A nice vise? $$$ Cut something wrong with a carbide bit? Shrapnel explosion. 3D printing has a bunch of limitations but is a way better machine for hobbyist. But I have been eyeing the Millennium Machines Milo. A very fair price point for a traditional style CNC. You can also decorate it however you want with your 3D printer.\n \nreply",
      "Previous discussions:https://news.ycombinator.com/item?id=41467268https://news.ycombinator.com/item?id=27645605This was a resource which was mentioned on the Shapeoko wiki --- while it's off-line, it's still on the Wayback Machine: https://web.archive.org/web/20211127090321/https://wiki.shap...Since then, some of those pages have been made available on Reddit:https://old.reddit.com/r/hobbycnc/wiki/indexhttps://old.reddit.com/r/shapeoko/wiki (ob. discl., I work for Carbide 3D)And there have been a number of other developments- FreeCAD has hugely improved since that was written.- Solvespace as greatly improved, adding some basic CAM functionality- Blender has had the Solvespace sketcher ported to it as https://www.cadsketcher.com/ and BlenderCAM has gotten quite a bit more workable- Dune3D was created and is remarkably capable: https://dune3d.org/Also a fair number of forums discussing CNC were gathered at: https://forum.makerforums.info/\n \nreply",
      "These also had discussions:https://news.ycombinator.com/item?id=4679939https://news.ycombinator.com/item?id=34339459\n \nreply",
      "With some concerted effort and money spent over several years I was able to more or less reproduce most of this document (but not nearly to the level of detail or variation on process).  Eventually I was able to finely CNC engrave a wax block with extremely fine (0.1mm) features, make a mold, and then stamp out as many copies as I wanted.  This guide was really helpful in understanding some of the core ideas.\n \nreply",
      "I remember reading this around a decade ago.  Still holds up though\n \nreply"
    ],
    "link": "https://lcamtuf.coredump.cx/gcnc/full/",
    "first_paragraph": ""
  },
  {
    "title": "Vector databases are the wrong abstraction (timescale.com)",
    "points": 170,
    "submitter": "jascha_eng",
    "submit_time": "2024-10-29T15:40:27 1730216427",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=41985176",
    "comments": [
      "Great point!(Disclaimer: I work for Elastic)Elasticsearch has recently added a data type called semantic_text, which automatically chunks text, calculates embeddings, and stores the chunks with sensible defaults.Queries are similarly simplified, where vectors are calculated and compared internally, which makes a lot less I/O and a lot simpler client code.https://www.elastic.co/search-labs/blog/semantic-search-simp...\n \nreply",
      "I made something similar, but used duckDB as the vector store (and query engine)! It\u2019s impressively fasthttps://github.com/patricktrainer/duckdb-embedding-search\n \nreply",
      "How does their embedding model compare in terms of retrieval accuracy to, say `text-embedding-3-small` and `text-embedding-3-large`?\n \nreply",
      "You can use openai embeddings in elastic if you don't want to use their elser sparse embeddings\n \nreply",
      "It\u2019s impossible to answer that question without knowing what content/query domain you are embedding.  Checkout MTEB leaderboard, dig into the retrieval benchmark, and look for analogous datasets.\n \nreply",
      "So we're talking maximizing embedding model per use case? Medical dats would require differnet model than say sales data? Sounds very fragmented approach.\n \nreply",
      "Hey HN! Post co-author here, excited to share our new open-source PostgreSQL tool that re-imagines vector embeddings as database indexes. It's not literally an index but it functions like one to update embeddings as source data gets added, deleted or changed.Right now the system only supports OpenAI as an embedding provider, but we plan to extend with local and OSS model support soon.Eager to hear your feedback and reactions. If you'd like to leave an issue or better yet a PR, you can do so here [1][1]: https://github.com/timescale/pgai\n \nreply",
      "Pretty smart. Why is the DB api the abstraction layer though? Why not two columns and a microservice. I assume you are making async calls to get the embeddings?I say that because it seems n\nunsual. Index would suit sync better. But async things like embeddings, geo for an address, is this email considered a spammer etc. feel like app level stuff.\n \nreply",
      "(post co-author here)The DB is the right layer from a interface point of view -- because that's where the data properties should be defined. We also use the DB for bookkeeping what needs to be done because we can leverage transactions and triggers to make sure we never miss any data. From an implementation point of view, the actual embedding does happen outside the database in a python worker or cloud functions.Merging the embeddings and the original data into a single view allows the full feature set of SQL rather than being constrained by a REST API.\n \nreply",
      "Hey, this looks great! I'm a huge fan of vectors in Postgres or wherever your data lives, and this seems like a great abstraction.When I write a sql query that includes a vector search and some piece of logic, like:\n```\nselect name from users where age > 21 order by <vector_similarity(users.bio, \"I like long walks on the beach\")> limit 10;\n```\nDoes it filter by age first or second? I've liked the DX of pg_vector, but they do vector search, followed by filtering. It seems like that slows down what should be the superpower of a setup like this.Here's a bit more of a complicated example of what I'm talking about: https://blog.bawolf.com/p/embeddings-are-a-good-starting-poi...\n \nreply"
    ],
    "link": "https://www.timescale.com/blog/vector-databases-are-the-wrong-abstraction/",
    "first_paragraph": ""
  },
  {
    "title": "How to get the whole planet to send abuse complaints to your best friends (delroth.net)",
    "points": 356,
    "submitter": "scd31",
    "submit_time": "2024-10-29T11:17:57 1730200677",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=41982698",
    "comments": [
      "This type of issue can be incredibly annoying to deal with, because the legitimate answer to the abuse report (\"someone is spoofing my IP, it isn't me, and the machine is not compromised\") is the exact same excuse that a malicious actor would provide.Then, as noted in the article, you're trying to prove a negative to someone who doesn't really care at all, which is borderline impossible.\n \nreply",
      "Hertzner says in the email that no response is necessary.Automated abuse reports of things that are easily spoofed don't justify a report, but might justify a quick check to make sure your box is still operating correctly and hasn't been taken over.\n \nreply",
      ">but we do expect you to check it and to resolve any potential issues.That's the important part.If they receive another one (or two, or a few) more abuse reports, they assume it is not fixed, and will expect a response then. Which ends up being annoying.\n \nreply",
      "> the legitimate answer to the abuse report (\"someone is spoofing my IP, it isn't me, and the machine is not compromised\") is the exact same excuse that a malicious actor would provide.The legitimate answer would include some sort of real-world attestation about you from a trusted third party. Probably the very least, some evidence of your identity and jurisdiction. Maybe including a video call or something. Not just you anonymously claiming you're a good guy over the internet and expecting to be believed.\n \nreply",
      "Hetzner (if they keep logs) should be able to verify if a user has been sending arbitrary packets out on port 22 very trivially\n \nreply",
      "Just what type of logs do you expect Hetzner to keep?\n \nreply",
      "Netflow data or equivalent? I'd assume any provider to have such records, at least in the short term. It can also be invaluable in debugging network problems post-hoc.\n \nreply",
      "Splunk logs of traffic. It\u2019s pretty common at the corporate level.\n \nreply",
      "At minimum? In/outbound traffic\n \nreply",
      ">The legitimate answer would include some sort of real-world attestation about you from a trusted third party.It's annoying to find someone (or some service) that is willing to attest on your behalf and have that person (or service) be trusted by your provider more than whoever filed the abuse complaint.>Maybe including a video call or something.It's annoying to find someone at your provider who will take the time to do this. It's annoying to take my time to have to do this.My point, overall, was that this is just a really annoying problem.\n \nreply"
    ],
    "link": "https://delroth.net/posts/spoofed-mass-scan-abuse/",
    "first_paragraph": "Infosec, travel, hiking, gaming, anime, and everything else in my lifepowered by Hugo | themed with poison\u00a9 2024 delroth's homepage. All rights reserved.It all begins with one scary email late at night just before I had to go to\nsleep:At first glance, this sounds pretty bad. One of my servers suddenly deciding to\nstart sending SSH connections to the wider internet. This is usually a pretty\nstrong indicator of malware compromise, and I had to act quickly if that was\nthe case. Luckily, I\u2019ve worked in infosec for a while, and some years ago I\neven did some freelance work doing forensics and cleanup of infected servers.So, not completely out of my element, I was surprised when after an hour or two\nI found no evidence of anything happening out of the ordinary. It\u2019s always hard\nto prove a negative, but really, the machine was fine. No odd process, no\nfilesystem modifications, no odd network traffic (as observed by the\nhypervisor, not by the server itself which happens to be a VM - just to be"
  },
  {
    "title": "Digging into PlantStudio, a Bit Late (pketh.org)",
    "points": 101,
    "submitter": "bentsai",
    "submit_time": "2024-10-29T18:49:31 1730227771",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41988030",
    "comments": [
      "> Because the last release of the app was in 2002, and it was for Windows 95/98/2000/NT4, we\u2019ve got a little bit of work to do to get it running on macOSMuch of today's software is going to be nothing more than a memory 22 years from now, after their authors run out of funding and they turn down the saas infrastructure that they shoehorned into it for that sweet, sweet recurring income. And more likely than not, we'll still be able to run this program from 2002, in 2046.\n \nreply",
      "This is why I always say we need to create federated and open source solutions. At the minimum we need apps that are not locked down to SaaS providers.\n \nreply",
      "Are there any federated and open source solutions from 2002 that are still running today?\n \nreply",
      "email, IRC, BitTorrent, DNS, BGP\n \nreply",
      "Typo: 2022 -> 2002\n \nreply",
      "Fixed, thank you\n \nreply",
      "The article covers everything I miss about desktop applications in a nutshell.  Mostly that wild sense of discovering what you can do with a computer that you might not have tried to do at all or left to experts.  But also not least that you can still run it decades later.\n \nreply",
      "A really interesting read. From the discontinuation notice[1] that the article links to:> Perhaps it comes down to this: indirectly, our own personal benefit for writing PlantStudio software and our other projects includes all the other wonderful free stuff on the internet, and it would cost us trillions of dollars if we had to pay for the creation of all that diversity ourselves. We don't mind using guilt to effect change :-) but this time, with products under free license, it will be guilt to go do something positive in the world to pass on the gift, rather than a one-for-one exchange with us.That's a wonderful sentiment from the humans who put a lot of effort into building this software (and eventually decided to give it away).[1] https://www.kurtz-fernhout.com/press.htm\n \nreply",
      "Love this. Nice work documenting it.I looked long and hard for something like this for Bonsai. I eventually found a Japanese app, but I'm yet to put in the effort to get it running. I don't think it worked in Whisky so I need to go deeper. https://www.jfp.co.jp/bonsai_dl/\n \nreply",
      "We need to kill SaaS. We can thank Salesforce for pushing it.\n \nreply"
    ],
    "link": "https://pketh.org/plantstudio.html",
    "first_paragraph": "This aesthetic screenshot of an old windows app has been in my inspiration space for ~5 years. Until recently, I assumed that it was just a nostalgia bait concept.The calm, serene life associated with gardening pairs suspiciously well with rose-tinted wistfulness for a simpler time in computing. I\u2019m happy to be wrong though, because software doesn\u2019t get more real than PlantStudio.Written by Kurtz-Fernhout Software, PlantStudio is a surprisingly deep botany simulator for creating and arranging 3D models of herbaceous plants based on how real plants grow, change, fruit, and flower, over their life cycles.Because the last release of the app was in 2002, and it was for Windows 95/98/2000/NT4, we\u2019ve got a little bit of work to do to get it running on macOS:PlantStudio lives again \ud83c\udf31\ud83c\udf3aAfter you read or skip the tutorial docs, you\u2019re be greeted with an empty window, which is kind of like the \u2018garden\u2019 that your plants will live in. One way to jump in is to File \u2192 Open some sample files.The inter"
  },
  {
    "title": "Show HN: Kasama \u2013 an IntelliJ plugin to keep track of your coding practices (jetbrains.com)",
    "points": 66,
    "submitter": "emhauck",
    "submit_time": "2024-10-29T16:18:32 1730218712",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41985883",
    "comments": [
      "Congratulations on the launch.While I appreciate the effort put into development, I have some questions about the underlying premise.1. How do detailed metrics about coding sessions, git interactions, and test runs actually leads to meaningful improvements in your productivity?2. Assuming you have used this plugin for a while now, how does tracking these metrics correlate with better code quality?I hope I'm not coming across as overly critical, as that's not my intent. I appreciate the effort put into the development of software regardless of the final intent.\n \nreply",
      "Yes, these are great questions!When I look at my own experiences, I wouldn\u2019t focus strictly on code quality and productivity in the narrow sense. What I mean by that is that my focus on smaller commits and smaller branches helped team members understand changes more quickly, making knowledge transfer easier. For branches where code reviews/approvals were necessary, this helped our overall flow because stories were not blocked that long due to long-lasting approvals.Another point was that, with Kasama, I was able to track the runtime of long-running tests and build tasks, which allowed me to point at tasks where optimizations were needed. Otherwise, such discussions were always based on gut feelings, and improvements were usually postponed\u2026\n \nreply",
      "Congratulations on launch. But I don't like when number of hours is used to quantify my work. Because x hours of work is not necessarily a good representation of complexity / quality of work. Even the number of commits is not a good metric. I want to know what HN thinks and how they measure their productivity?\n \nreply",
      "If this turns into some sort of hiring metric, I\u2019m gong to be pissed.> What\u2019s your Kasama score?\n \nreply",
      "I\u2019m curious on how you came up with the name? In my language it means companion.\n \nreply",
      "It would be interesting if this also hooked into an AST to capture different syntaxes and structures used to express procedures and entities in code.\n \nreply",
      "Was this named after the Tagalog word?\n \nreply",
      "Holla, swear to my kasamas\nWhen I grow up I wanna be just like Yuri Kochiyama.\n \nreply",
      "Yes, well noticed!\n \nreply",
      "It's a legible Thai name as well.\n \nreply"
    ],
    "link": "https://plugins.jetbrains.com/plugin/24683-kasama",
    "first_paragraph": ""
  },
  {
    "title": "AgiBot X1, a modular humanoid robot with high dof (github.com/agibottech)",
    "points": 28,
    "submitter": "jinqueeny",
    "submit_time": "2024-10-28T11:17:12 1730114232",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/AgibotTech/agibot_x1_train",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The reinforcement learning training code for AgiBot X1.\n      English | \u4e2d\u6587AgiBot X1 is a modular humanoid robot with high dof developed and open-sourced by AgiBot. It is built upon AgiBot's open-source framework AimRT as middleware and using reinforcement learning for locomotion control.This project is about the reinforcement learning training code used by AgiBot X1. It can be used in conjunction with the inference software provided with AgiBot X1 for real-robot and simulated walking debugging, or be imported to other robot models for training.\npython scripts/train.py --task=x1_dh_stand --run_name=<run_name> --headlesspython /scripts/play.py --task=x1_dh_stand --load_run=<date_time><run_name>\npython scripts/export_policy_dh.py --task=x1_dh_stand --load_run=<date_time><run_name> python scripts/export_onnx_dh.py --task=x1_dh_stand --l"
  },
  {
    "title": "Ancient Monkey: Pwning a 17-Year-Old Version of SpiderMonkey (pspaul.de)",
    "points": 80,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-29T14:56:00 1730213760",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41984466",
    "comments": [
      "One of my team colleagues solved this one at hacklu. It was a wild ride from what I heard.\n \nreply",
      "Does anyone else like Zscaler?All the devs at my company kind of hate it because it's always breaking stuff. I think it's cool in theory, but they have basically zero automated support on how to get the certificate installed.They have manual instructions on how you add the certificate to the Java key store, and NPM key store, and the python key store, and the OS key store, etc...And my whole thing is: won't malware use those same key stores? Won't malware detect that the certificate isn't passing and then just default to HTTP?I'm starting to think it's security theater.\n \nreply",
      "Oh it's definitely security theater, and it also wastes a ton of time as you describe, figuring out how to add certs or use a proxy in various pieces of software.Back when I had a corporate job, I think at least 50% of my value to the company was that I knew how to get around Zscaler when necessary. Nothing particularly clever, just secretly using a proxy on some random server in our data center that happened to have unfiltered access to the Internet - which seemed like more of a potential security issue than anything Zscaler solved, but oh well.\n \nreply",
      "Yeah I find Zscaler to be a nuisance - my company has done a reasonable job in getting it to work seamlessly but there are two things that make my life difficult.One is that for some reason different operating systems have different configs (not sure is this is just how my company has done it or whether it's for a reason), but it's meant that more than a few times some very mundane features in internal tools have been broken because development and testing happens on Mac but the end users are on Windows. The other is that IP address whitelisting is super painful because someone in security needs to do something to proxy the real IP address to your application, otherwise the IP address you see is the one for Zscaler's IP address, and Akamai plus Zscaler leads to even more confusion when trying to diagnose a firewall issue.\n \nreply",
      "IDK about whether it's security theater or how secure it is, but the software is fucked. I'm glad I'm not forced to use it (yet?), it hasn't worked right in forever and I really don't want to go to IT only to get blocked websites because they're content that my corporate overlords don't want people to look at during work hours (it's video games, not porn).\n \nreply"
    ],
    "link": "https://blog.pspaul.de/posts/ancient-monkey-pwning-a-17-year-old-version-of-spidermonkey/",
    "first_paragraph": "Last year, @swapgs and I found a fun bug in the popular enterprise VPN solution Zscaler. The VPN client was using the pacparser library to decide which HTTP requests should be proxied. The decision was made based on a pre-configured Proxy Auto-Configuration (PAC) file which contains JavaScript code.The bug allowed us to escape from a string and execute arbitrary JavaScript in the context of the PAC file. We noticed that pacparser was using a 17 year old version of SpiderMonkey (Firefox\u2019s JS engine), but we didn\u2019t have the chance to develop a full exploit at the time. Instead, we just reported the vulnerability, suggesting that code execution is likely possible.Fast forward to this year. When preparing Hack.lu CTF 2024, I noticed we were low on pwn challenges, so I decided to dust off my pwning skills (I\u2019m usually a web player) and give this bug a try!I started by searching the Mozilla bugtracker for a suitable bug. I found a few that were working in pacparser\u2019s version of SpiderMonkey,"
  },
  {
    "title": "The electrostatic world of insects (wired.com)",
    "points": 153,
    "submitter": "noleary",
    "submit_time": "2024-10-29T01:31:28 1730165488",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=41978478",
    "comments": [
      "> The magic of animal electrostatics is all about size. Large animals don\u2019t meaningfully experience nature\u2019s static\u2014we\u2019re too big to feel it. \u201cAs humans, we are living mostly in a gravitational or fluid-dynamics world,\u201d Ortega-Jim\u00e9nez said. But for tiny beings, gravity is an afterthought. Insects can feel air\u2019s viscosity. While the same laws of physics reign over Earth\u2019s smallest and largest species, the balance of forces shifts with size.Very cool article. For example: butterflies accumulate a positive charge when beating their wings, which causes pollen to jump through the air toward them when they land on flowers.\n \nreply",
      "Similar to this, one of the most mind-blowing papers I\u2019ve read was Life at Low Reynold\u2019s Number about how at the microorganism level water is virtually solid and inertia does not exist.https://www.damtp.cam.ac.uk/user/gold/pdfs/purcell.pdf\nhttps://swizec.com/blog/week-9-life-at-low-reynolds-number/\n \nreply",
      "When you are very big (like an elephant), gravity is all important and surface tension barely matters.When you are very small (like an ant), it is the other way around.Toss a mouse from a building. It will land, shake itself off and scamper away. But if similarly dropped, \u201c\u2026 a rat is killed, a man is broken, a horse splashes.\u201d So wrote J.B.S. Haldane in his 1926 essay \"On Being the Right Size.\"\nhttps://www.edge.org/response-detail/27082\n \nreply",
      "Inertia doesn't exist? Wow that's hard to visualize. Perhaps the world does converge on cellular automata as you zoom in\n \nreply",
      "The same question scales outwards. Are there forces taking over from gravity at galactic scale? Like, perhaps the galaxy filaments and voids come about due to something we can't even comprehend. It seems unlikely that humans just happen to be working with the force at the largest \"scale.\"How complicated would it be for a small insect to explain gravity, if they're not normally affected by it in their daily routine?I recently thought about something similar: it seems like at certain scales, things turn into spheres, based on applicable forces. And then there are in-between regions with chaos. Atoms seem mostly round. Humans are not. If planets and stars are at the next spherical scale, are there even larger structures out there that once again show spherical nature, once you're past galaxies, clusters and filaments?\n \nreply",
      "Since black holes grow with their radius proportional to mass (not volume), larger black holes are less dense. The current estimates for the size and mass of the universe fits right on the line of that curve of critical density.\n \nreply",
      "The universe itself, if bounded, might be a hypersphere.\n \nreply",
      "Excellent article, and some fascinating discoveries. The idea of passive pollen spread via static buildup on pollinators make sense, but is kind of mind blowing to me at the same time.For a much more enjoyable reading experience (at least on mobile):https://www.quantamagazine.org/the-hidden-world-of-electrost...\n \nreply",
      "> A few years after Ortega-Jim\u00e9nez noticed spiderwebs nabbing bugs, Robert\u2019s team found that bees can gather negatively charged pollen without brushing up against it.It's arguably kind of weird that this is just being noticed now. I suppose possibly modern camera equipment helps, for purposes of actually _seeing_ it happen...\n \nreply",
      "If insects can build up 5 kilovolts while flying, then why can I zap flies with a fly-zapping tool that presumably runs at a similar or lower voltage?\n \nreply"
    ],
    "link": "https://www.wired.com/story/the-secret-electrostatic-world-of-insects/",
    "first_paragraph": "To revisit this article, visit My Profile, then View saved stories.The original version of this story appeared in Quanta Magazine.Imagine, for a moment, that you\u2019re a honeybee. In many ways, your world is small. Your four delicate wings, each less than a centimeter long, transport your half-gram body through looming landscapes full of giant animals and plants. In other ways, your world is expansive, even grand. Your five eyes see colors and patterns that humans can\u2019t, and your multisensory antennae detect odors from distant flowers.For years, biologists have wondered whether bees have another grand sense that we lack. The static electricity they accumulate by flying\u2014similar to the charge generated when you shuffle across carpet in thick socks\u2014could be potent enough for them to sense and influence surrounding objects through the air. Aquatic animals such as eels, sharks, and dolphins are known to sense electricity in water, which is an excellent conductor of charge. By contrast, air is "
  },
  {
    "title": "Scythe Works Without Borders (scytheworks.ca)",
    "points": 51,
    "submitter": "highway-trees",
    "submit_time": "2024-10-27T05:13:02 1730005982",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=41960013",
    "comments": [
      "A good scythe is faster then a weed-wacker but slower then a lawnmower.  I have been using a scythe to cut my lawn for a few years now.   It works, and is fun, but you must keep it VERY sharp. If the scythe is not razor sharp it will simply push the grass over instead of cutting it.   A sickle will still work when somewhat dull, because it gathers the grass into the concave bit and/or you can hold on the grass with one hand and cut it with the other.A scythe you have to sharpen every 5-10 min or so, normally you keep a scythe stone in your pocket to do this.   The sickle you can just sharpen at the beginning of the day and that will be good enough.The sharpening process takes some practice to get good at,  particularly if you start peening it as well.https://scytheworks.ca/knowledge-base/chapter-4-preparing-th...\n \nreply",
      "> regions where sickles (or machetes) are traditionally usedI don't understand how it's possible that there are regions that don't use scythes (for crops that warrant them), when scythes have been around for over a thousand years?I would venture to say that if they haven't transitioned yet it's because they don't want to (for whatever reasons--no idea what those might be).\n \nreply",
      "Guesses at some reasons* Scythes need to be sharp, a machete will work even when poorly maintained.* Machetes are cheaper to make.* Machetes are easier to use* Scythes are a specialized tool, where as I can buy a machete for ten dollars at Canadian Tire. Economics of scale are different.> There are still several remaining scythe factories in the world. In recent years a competitive, market-driven economy is making it difficult for scythe making factories to retain the quality level that was once a standard.https://scytheworks.ca/swwobs-blade-choice/\n \nreply",
      "Invention and adoption of technology, even \"basic\" technology, is very contingent on circumstance. Bows are pretty near universal (but not quite), but specific improvements like recurved limbs are patchy. And people aren't exactly quick to adopt new farming techniques when a failure could mean they starve. I guess that's also why this organization is pushing uphill. But I think it's very possible that lots of people haven't heard of or seriously evaluated a scythe.\n \nreply",
      "There's illustrations inside the pyramids that are thousands of years old showing people watering their fields using a bucket on a long swinging arm. It needs just a couple of long poles, a bucket, and a rope.I saw this still in use today when I went to Egypt. That blew my mind.https://en.wikipedia.org/wiki/Shadoof\n \nreply",
      "I mean it's an interesting idea, but it's weird to imagine that small time farmers in poor countries are capable of obtaining and using a sickle but are somehow not capable of obtaining and using a scythe.At least looking for ones here in the US, a decent quality sickle seems to run in the $30-$60 range while places that sell scythes seem to cost $100-$300, so I can't imagine it's some massive price barrier either\n \nreply",
      "It's usually lack of knowledge/understanding and simple inertia, \"this is how we've always done it.\"\n \nreply",
      "I'm afraid you just dismissed the question, not answered it. Plenty of things changed in agriculture in spite of simple inertia. Why does sickle-for-wheat-scythe-for-hay concept seem to prevail for different cultures in distant lands for so long?\n \nreply",
      "I didn't dismiss it at all. I directly answered you. While plenty of things change despite inertia, plenty of things do NOT change. We've known about the benefits of no till, cover crops, crop rotation, etc. for centuries and they're still not common due to inertia. In the USA we know that government subsidies for corn have massively distorted the market and had huge negative impacts on health and the environment, but we don't change due to inertia. Water management something we're terrible at in the US despite having the knowledge of how to do it better, but we don't because of inertia. Don't underestimate the power of \"we've always done it this way.\" People can come up with a thousand bad reasons not to do something.In my company, another leader forced his division to stop using a manual tracking spreadsheet because it was wasting time. People HATED the idea of stopping it, expecting there to be huge issues, but the manager was right, all the information was already reliably recorded in other systems and this was just a wasteful manual copy. When people stopped using it, literally nothing went wrong or changed, no one needed it, but now everyone got back 15 minutes of their day. But people resisted because \"we've always done it this way.\"As another poster said, grain loss is more likely with these less-hand-labor-intensive methods, and people can overvalue the loss of that small amount despite the time and energy savings of scythes. So people might think, \"I'll lose 3% of my harvest doing that, I can't afford that\" except they'd expend 15% of the energy harvesting and thus that 3% loss is more than balanced out by the 85% time savings and the reduced work load. You can spend a fraction of that saved time making up the 3% difference in a hundred other ways.People are very resistant to change. A lack of education produces lapses in logic and critical thinking and thus people won't evaluate the change in the right frame of reference.\n \nreply",
      "I'm not sure, but what I've read is that there's a loss of grain associated with using the scythe on wheat when it falls on the ground. Maybe it's a concern in some areas.But I think that with a proper apparel such as the one we see in the video on the website, the fall can be made gentler while still keeping the significant efficiency gain that the scythe offers over the sickle.\n \nreply"
    ],
    "link": "https://scytheworks.ca/scythe-works-without-borders/",
    "first_paragraph": "The scythe works without borders, literally.To introduce the use of scythes for gathering fodder and harvesting cereal crops in regions where sickles (or machetes) are traditionally used, thereby increasing productivity and reducing drudgery.Scythes are a form of appropriate technology that can make significant improvements to the lives and livelihoods of small farmers and agroecologists worldwide, increasing their personal capabilities, self-reliance, and resilience, while avoiding fossil-fuel burning and debt-creating mechanization.increases the productivity of the harvest \u2014 for cutting, scythes are 6 to 10 times faster than sicklesreduces the labour shortages during harvest monthsimproves health by working in an upright position, instead of squatting or bendingeliminates the pollution, fuel, and maintenance costs that come with mechanized harvestingclearly cost-efficient for many applicationsScythe Works Without Borders explores and demonstrates how scythes may be used for various a"
  },
  {
    "title": "When are two proofs essentially the same? (2007) (gowers.wordpress.com)",
    "points": 53,
    "submitter": "ColinWright",
    "submit_time": "2024-10-29T15:15:09 1730214909",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=41984695",
    "comments": [
      "I'm reminded of the Philosophy of Computer Science entry in the Stanford Encyclopedia of Philosophy [0], which briefly considers what it means for two programs to be identical.\"... it has been argued that there are cases in which it is not possible to determine whether two programs are the same without making reference to an external semantics. Sprevak (2010) proposes to consider two programs for addition which differ from the fact that one operates on Arabic, the other one on Roman numerals. The two programs compute the same function, namely addition, but this cannot always be established by inspecting the code with its subroutines; it must be determined by assigning content to the input/output strings\"\"The problem can be tackled by fixing an identity criterion, namely a formal relation, that any two programs should entertain in order to be defined as identical. Angius and Primiero (2018) show how to use the process algebra relation of bisimulation between the two automata implemented by two programs under examination as such an identity criterion. Bisimulation allows to establish matching structural properties of programs implementing the same function, as well as providing weaker criteria for copies in terms of simulation.\"(Of course, it isn't surprising that this would be relevant, because proofs and programs themselves are isomorphic).This technique seems rather stricter than what Gowers has in mind, but it seems helpful as a baseline.0. https://plato.stanford.edu/entries/computer-science/\n \nreply",
      "I think it's also important to make a distinction between a pair of programs which compute the same function using an identical amount of space and time and a pair of programs which compute the same function with different amounts of either space or time (or both). Two programs might compute the same function and be considered formally identical in that sense but may be in radically different complexity classes [O(1) vs O(n) vs O(n^2) vs O(2^n)].Formally we may not be interested in this distinction but practically we definitely are. One program may be extremely practical and useful whereas the other might not finish computing anything before the heat death of the universe on anything but trivial-sized inputs.\n \nreply",
      "On the other hand, compiler tricks like tail call optimization can e.g. reduce an O(n) algorithm to an O(1) algorithm. Is it a \u201cdifferent program\u201d if the same source code is compiled with a new compiler?\n \nreply",
      "Tail call elimination is not an optimization because it changes the semantics of the program. The feature can take a program which would previously fail to terminate due to a stack overflow and cause it to terminate without error.Perhaps TCO is better thought of as a language extension.\n \nreply",
      "That seems no different than any other optimization: very directly tons of optimizations would reduce stack usage which would then change a given input from a stack overflow to a successful execution. Similarly anything that reduces heap memory usage or code size would also do the same.\n \nreply",
      "Tail call optimization does not turn O(n) algorithms into O(1) algorithms unless you're talking about the space used and not the runtime.\n \nreply",
      "At a certain level of abstraction, that's easily an example of converting an O(n log n) algorithm into an O(n) one.In practice, of course, the effect is far more dramatic with a MMU.\n \nreply",
      "Can you show a O(n log n) algorithm with tail calls but not TCO that's O(n) after being optimized with TCO?\n \nreply",
      "Computing f(0)=0; f(n)=f(n-1) is O(n log n) without tail calls because you need O(log n) addresses to hold your stack frames.\n \nreply",
      "> Computing f(0)=0; f(n)=f(n-1) is O(n log n) without tail calls because you need O(log n) addresses to hold your stack frames.There are two principal ways of applying asymptotic analysis to algorithms: time or memory used. In both, your procedure is O(n) without TCO. With TCO it is O(n) for runtime (though further optimization would reduce it to O(1) since it's just the constant function 0, but TCO alone doesn't get us there) and O(1) for space since it would reuse the same stack frame.What O(log n) addresses do you need to hold the stack frames when there are O(n) stack frames needing O(n) addresses (without TCO, which, again, reduces it to O(1) for memory)?Also, regarding \"without tail calls\", your example already has tail calls. What do you mean by that?\n \nreply"
    ],
    "link": "https://gowers.wordpress.com/2007/10/04/when-are-two-proofs-essentially-the-same/",
    "first_paragraph": "A couple of years ago I spoke at a conference about mathematics that brought together philosophers, psychologists and mathematicians. The proceedings of the conference will appear fairly soon\u2014I will give details when they do. My own article ended up rather too long, because I found myself considering the question of \u201cessential equality\u201d of proofs. Eventually, I cut that section, which was part of a more general discussion of what we mean when we attribute properties to proofs, using informal (but somehow quite precise) words and phrases like \u201cneat\u201d, \u201cgenuinely explanatory\u201d, \u201cthe correct\u201d (as opposed to merely \u201ca correct\u201d), and so on. It is an interesting challenge to try to be as precise as possible about these words, but I found that even the seemingly more basic question, \u201cWhen are two proofs the same?\u201d was pretty hard to answer satisfactorily. Since it is also a question on which we all have views (since we all have experience of the phenomenon), it seems ideal for a post. You may h"
  }
]