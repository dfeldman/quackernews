[
  {
    "title": "\"AI first\" and the Bus Factor of 0 (mindflash.org)",
    "points": 132,
    "submitter": "AntwaneB",
    "submit_time": "2025-08-20T21:47:05 1755726425",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=44966856",
    "comments": [
      "If you're using llms to shit out large swathes of unreviewed code you're doing it wrong and your project is indeed doomed to become unmaintainable the minute it goes down a wrong path architecturally, or you get a bug with complex causes or whatever.Where llms excel is in situations like:* I have <special snowflake pile of existing data structures> that I want to apply <well known algorithm> to - bam, half a days work done in 2 minutes.* I want to set up test data and the bones of unit tests for <complicated thing with lots of dependencies> - bam, half a days work done in 2 minutes (note I said to use the llms for a starting point - don't generate your actual test cases with it, at least not without very careful review - I've seen a lot of really dumb ai generated unit tests).* I want a visual web editor for <special snowflake pile of existing data structures> that saves to an sqlite db and has a separate backend api, bam 3 days work done in 2 minutes.* I want to apply some repetitive change across a large codebase that's just too complicated for a clever regex, bam work you literally would have never bothered to do before done in 2 minutes.You don't need to solve hard problems to massively increase your productivity with llms, you just need to shave yaks. Even when it's not a time save, it still lets you focus mental effort on interesting problems rather than burning out on endless chores.reply",
      "> * I want to apply some repetitive change across a large codebase that's just too complicated for a clever regex, bam work you literally would have never bothered to do before done in 2 minutes.You would naively think that, as did I, but I've tested it against several big name models and they are all eventually \"lazy\", sometimes make unrelated changes, and worse as the context fills up.On a small toy example they will do it flawlessly, but as you scale up to more and more code that requires repetitive changes the errors compound.Agentic loops help the situation, but now you aren't getting it done in 2 minutes because you have to review to find out it wasn't done and then tell it to do it again N times until it's done.Having the LLM write a program to make the changes is much more reliable.reply",
      "\"bam work you literally would have never bothered to do before done in 2 minutes.\"And I would never want to use a piece of software written by you ever.If you think that writing the code was the hard part, your code was probably always shite.reply",
      "> Having the LLM write a program to make the changes is much more reliable.I ended up doing this when switching our 50k-LOC codebase to pnpm workspaces, and it was such a good experience. It still took me a day or two of moulding that script to get it to handle the dozens of edge cases, but it would have taken me far longer to split things up by hand.I still feel like I am under-using the ability of LLMs to spit out custom scripts to handle one-off use-cases.reply",
      "That\u2019s not even a very large code base. My experience is definitely that anything with more than 100K-loc really makes the LLMs struggle.reply",
      "Yeah was thinking about this recently. A semantic patch is more reliable, but prompting an ai might be easier. So why not prompt the ai to wrote the semantic patch.reply",
      "YES, this is the way to make AI tools pretty much a strictly positive productivity tool on large codebases.reply",
      "There's also a middle ground, where you have the AI generate PR reviews and then review them manually. So that 2 minutes of code you spat out (really more like 5-10 using CC) takes another hour or three to review, and maybe 5 to 10 more commits before it's merged in.I've done this successfully on multiple projects in the 10-20k LOC, ~100 file area - fully LLM generated w/ tons of my personal feedback - and it works just fine. 4/5 features I implement it gets pretty close to nailing from the spec I provide and the work is largely refactoring. But the times it doesn't get it right, it is a slog that could eat the better part of a day. On the whole though it probably is a 3-5x speedup.I'm a little less confident about doing this on projects that are much bigger... then breaking things up into modules begins to look more attractive.reply",
      "It's definitely a middle ground, but PR reviews, are not perfect. So it's easy to miss a lot of things and to have a lot of extra baggage. From reviewing code it's not always easy to tell exactly what's necessary or duplicate. So I agree, this is a middle ground of using LLMs to be more productive. Removing one bad line of code is worth adding a hundred good lines of code.reply",
      "> If you're using llms to shit out large swathes of unreviewed code you're doing it wrong> bam, x days work done in 2 minutesThis is a bit of a misrepresentation, since those two minutes don\u2019t account for the reviewing time needed (nor prorperly, which vastly exceeds that time. Otherwise you end up in the situation of \u201cdoing it wrong\u201d described in your first paragraph.reply"
    ],
    "link": "https://www.mindflash.org/coding/ai/ai-and-the-bus-factor-of-0-1608",
    "first_paragraph": "MindFlash - Programming and moreMindFlash - Programming and moreAll the opinions expressed in this article and on this website are entirely my own and do not represent my employer in any way.Ever heard about the \u201cBus factor\u201d? It is a concept that measures the risk of losing all knowledge about a particular thing \u2013 a software development project for example \u2013 by estimating how many team members could get crushed by a bus before nobody knows how to work on the project anymore. As an example, if 3 people on your team know how to restore a backup of your database, the Bus Factor for that particular function in 3.Since the dawn of humanity, even long before buses existed, the Bus Factor has always had a \u201cworst case\u201d value of 1. If the sole keeper of a piece of knowledge came to pass, the knowledge was lost, unless it had been transferred previously.And humanity has worked hard to keep itself far from this Bus Factor of 1. Brown-bag sessions, documentation, video tutorials, knowledge handove"
  },
  {
    "title": "Code Review Can Be Better (tigerbeetle.com)",
    "points": 54,
    "submitter": "sealeck",
    "submit_time": "2025-08-20T23:10:37 1755731437",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44967469",
    "comments": [
      "I find the idea of using git for code reviews directly quite compelling. Working with the change locally as you were the one who made it is very convenient, considering the clunky read-only web UI.I didn't get why stick with the requirement that review is a single commit? To keep git-review implementation simple?I wonder if approach where every reviewer commits their comments/fixes to the PR branch directly would work as well as I think it would. One might not even need any additional tools to make it convenient to work with. This idea seems like a hybrid of traditional github flow and a way Linux development is organized via mailing lists and patches.reply",
      "Essentially, you are turning fork/branch induced changes to \"precommit\" review like workflow which is great.I was on a lookout for best \"precommit\" review tool and zeroed on Magit, gitui, Sublime Merge.I am not an emac user, so i'll have to learn this.reply",
      "I use the GitHub Pull Request extension in VSCode to do the same thing (reviewing code locally in my editor). It works pretty well, and you can add/review comments directly in the editor.reply",
      "It's better, but still quite deep vendor lock-in (in both GitHub and VSCode).reply",
      "Well my employer chooses to use GitHub so I don\u2019t have a choice there. And it\u2019s vendor lock-in VSCode but that\u2019s already my primary editor so it means there\u2019s no need to learn another tool just for code review.reply",
      "Me too, I've been doing this for years. I believe assumed everyone (who uses github and VSCode) did.To be honest I'm not sure how else one reviews nontrivial PRs, without being able to run the code locally and having the diffs there to hack on?reply",
      "I use this a lot too. Also, if you open a PR on the GitHub website and press the \u201c.\u201d key, it opens the review in VSCode, which I consider a much better web experience.reply",
      "Agree with your pain points. One thing id add is GitHub makes you reapprove every PR after each push. As an OSS contributor it\u2019s exhausting to chase re-approvals for minor tweaks.reply",
      "mmmm this is up to each repo/maintainer's settings.To be fair you don't know if one line change is going to absolutely compromise a flow. OSS needs to maintain a level of disconnect to be safe vs fast.reply",
      "This is a security setting that the author has chosen to enable.reply"
    ],
    "link": "https://tigerbeetle.com/blog/2025-08-04-code-review-can-be-better/",
    "first_paragraph": "matkladSlightly unusual genre today: a negative\nresult about our git-review\ntool for a different take on code review process, which we decided to\nshelve, at least for the time being.A lot of people are unsatisfied with GitHub\u2019s code review process.\nOne of the primary issues is that GitHub poorly supports stacked pull\nrequests and interdiff\nreviews. While I also see interdiff as valuable, it\u2019s not the reason\nwhy I decided to experiment with git-review. I have two\nother problems with GitHub, and with every single other code review\nsystem, with the exception of the\nthing that Jane Street uses internally:Let\u2019s start with the second one.By the way of analogy, I don\u2019t use GitHub\u2019s web editor to write code.\nI clone a repository locally, and work in my editor, which is:When I review code, I like to pull the source branch locally. Then I\nsoft-reset the code to mere base, so that the code looks as if it was\nwritten by me. Then I fire up magit, which allows me to effectively\nnavigate both through"
  },
  {
    "title": "SK hynix dethrones Samsung as top DRAM maker for first time in 30 years (joins.com)",
    "points": 32,
    "submitter": "ksec",
    "submit_time": "2025-08-17T17:31:33 1755451893",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://koreajoongangdaily.joins.com/news/2025-08-15/business/tech/Thanks-Nvidia-SK-hynix-dethrones-Samsung-as-worlds-top-DRAM-maker-for-first-time-in-over-30-years/2376834",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I was curious about spherical helix, ended up making this visualization (visualrambling.space)",
    "points": 610,
    "submitter": "damarberlari",
    "submit_time": "2025-08-20T14:02:47 1755698567",
    "num_comments": 110,
    "comments_url": "https://news.ycombinator.com/item?id=44962066",
    "comments": [
      "These used to be super important in early oceanic navigation. It is easier to maintain a constant bearing throughout the voyage. So that's the plan sailors would try to stick close to. These led to let loxodromic curves or rhumb lines.https://en.m.wikipedia.org/wiki/Rhumb_lineMercator maps made it easier to compute what that bearing ought to be.https://en.m.wikipedia.org/wiki/Mercator_projectionThis configuration is a mathematical gift that keeps giving. Look at it side on in a polar projection you get a logarithmic spiral. Look at it side on you get a wave packet. It's mathematics is so interesting that Erdos had to have a go at it [0]On a meta note, today seems spherical geometry day on HN.https://news.ycombinator.com/item?id=44956297https://news.ycombinator.com/item?id=44939456https://news.ycombinator.com/item?id=44938622[0] Spiraling the Earth with C. G. J. Jacobi. Paul Erd\u00f6shttps://pubs.aip.org/aapt/ajp/article-abstract/68/10/888/105...reply",
      "Except the helix curve shown in OP is NOT a loxodrome or rhumb line.It has equal spacing on the surface between lines, a loxodrome can't have that property since by definition it must cross the meridians at the same angle at all times. That means it always gets denser near the poles.---Start with the curve:x = 10 \u00b7 cos(\u03c0\u00b7t/2) \u00b7 sin(0.02\u00b7\u03c0\u00b7t)y = 10 \u00b7 sin(\u03c0\u00b7t/2) \u00b7 sin(0.02\u00b7\u03c0\u00b7t)z = 10 \u00b7 cos(0.02\u00b7\u03c0\u00b7t)Convert to spherical coordinates (radius R=10):\u03bb(t) = \u03c0/2 \u00b7 t (longitude)\u03c6(t) = \u03c0/2 - 0.02\u00b7\u03c0\u00b7t (latitude)Compute derivative d(\u03bb)/d(\u03c6):d(\u03bb)/dt = \u03c0/2d(\u03c6)/dt = -0.02\u00b7\u03c0d(\u03bb)/d(\u03c6) = (\u03c0/2)/(-0.02\u00b7\u03c0) = -25 (constant)A true rhumb line must satisfy:d(\u03bb)/d(\u03c6) = tan(\u03b1) \u00b7 sec(\u03c6)which depends on latitude \u03c6.Since \u03c6(t) changes, sec(\u03c6) changes, so no fixed \u03b1 can satisfy this.Conclusion: the curve is not a rhumb line.this is how one should look for varying intersection angles:https://beta.dwitter.net/d/34223reply",
      "To quote the storytelling quality of Erdos's abstract:\"The simple requirement that one should move on the surface of a sphere with constant speed while maintaining a constant angular velocity with respect to a fixed diameter, leads to a path whose cylindrical coordinates turn out to be given by the Jacobian elliptic functions.\"reply",
      "You inspired me to submit one of my 2022 projectshttps://observablehq.com/@jrus/spheredisksamplehttps://news.ycombinator.com/item?id=44963521to fit the trend of the day. People may also enjoyhttps://observablehq.com/@jrus/sphere-resamplereply",
      "In my early teens I used to try to create something like a equirectangular projection because when drawing it, it looked cool. Obviously I had no idea that it was called this. I was trying to draw reflections of a square window onto a sphere, and then I moved on to trying to cover the sphere in a checkered pattern. This is awesome to see, thank you!reply",
      "Great to see you. I look forward for your comments on geometry, multivariate calculus and rotations.Edit: fantastic  graphics. You should submit the other one as an HN post too.reply",
      "Don't forget this post, which spawned a discussion of Rhumb lines etc. in the comments: https://news.ycombinator.com/item?id=44962767reply",
      "I had missed this one ! Thanks.It is indeed raining spherical geometry today.reply",
      "It seems like it might be cool but between the background animation and the resource intensiveness I'm having trouble actually reading it. Is there a mostly-text version somewhere?reply",
      "Awesome visualizations.The part that I was expecting to see but didn't: how can you move at a constant speed? For the original purpose of positioning objects along a path, it doesn't matter. But when moving, you can see it's moving much more slowly at the beginning and end (mostly determined by the radius). What if I want it to travel at a constant rate? Or even apply an easing function to the speed?I'm sure there's some fancy mathematical trick that would just do it. If I were only more comfortable with math... my handwavy sketch would be to compute the speed function by differentiating the formulas to get dx, dy, and dz and passing them through the Pythagorean equation, then reparameterize on a t' variable using the inverse of the speed function? Maybe? I feel like I'm speaking using words I don't understand.reply"
    ],
    "link": "https://visualrambling.space/moving-objects-in-3d/",
    "first_paragraph": "Loading assets, please wait...Trying to understand how to move objects in 3D spaceMOVING OBJECTS IN 3D SPACEtap/click the right side of the screen to go forward \u2192Okay\u2026 probably not, right?But one morning, this question popped into my head.It stuck with me long enough that I ended up diving into a few articles about it.From there, it spiraled into lots of explorations, trying to figure out how to move objects in 3D space.From a simple circle......to a spiral......to this complex, chaotic path.All these explorations made me want to share what I learned with you.I hope you enjoy this as much as I did.Let\u2019s start!A helix is a shape that loops around and around, like a spring.How do we do this?We'll get there! But first, let\u2019s see how to position and move objects in 3D space.In 3D space, we position objects by setting its coordinates along three axes: x,y, and z.The x-axis typically represents horizontal movement\u2014left or right.The y-axis typically represents vertical movement\u2014up or down.The"
  },
  {
    "title": "Gemma 3 270M re-implemented in pure PyTorch for local tinkering (github.com/rasbt)",
    "points": 294,
    "submitter": "ModelForge",
    "submit_time": "2025-08-20T14:01:26 1755698486",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=44962059",
    "comments": [
      "Hey all,\nI created this model with a top notch team. I answered many questions last week when this hit the front page, and happy to answer more here as well.https://news.ycombinator.com/item?id=44902148Personally I'm excited that you all have access to this model now and hope you all get value out of using them.reply",
      "I would like to know your thoughts on using 2/3 of such a small the model's size for embeddings. What would be different if you used a byte-level vocabulary and spent the parameter budget on transformer parameters instead? I think you would lose performance (tok/s) but might gain accuracy.reply",
      "At this small scale the embeddings indeed were a big focus. Consider this thought process.The tokens themselves are a form of compression. Lets say we have the word \"WaffleHouse\", character level this would be 11 tokens, but with an embedder this would be perhaps 2 or 3 tokens (I didn't actually run through the tokenizer but we could verify precisely). This matters a lot for on device processing especially.So while we could get more intelligence out of the model by bumping up the \"knowledge\" parameters, the device would need to process more input and output tokens.Another advantage on small devices is the embeddings are just a lookup table which requires little to no computation. Its the rest of the parameters that have the expensive matrix multplications, so if we increased those we'd also be increasing the number of FLOPs needed for a forward pass.This blog post explains it well. https://www.adamcasson.com/posts/transformer-flopsSo all this to say is there are definite tradeoffs between model size, performance on evals, and compute cost. We ran many internal experiments with different choices to see could work well, and then picked what we believed work will best for the open community.reply",
      "How would this matrix get trained with PyTorch? I currently have a toy Transformer network - I ended up marking the matrix as sparse and using SparseAdam - gives a bit of a performance boost, but at the same time I can't use torch.compile() on the fetch from this matrix.reply",
      "Makes sense, thank you.reply",
      "Very stupid question: why does the tflite model  output only '[multimodal][multimodal]' when executed on GPU in the AI edge gallery app, while fully working on the CPU.reply",
      "As a non MLE, what are the pros/cons of OP's PyTorch re-implementation?reply",
      "Thanks for your work, it is really an amazing small LM.Can you share what kind of hardware is necessary to train it, and how long it took?reply",
      "Thank you!The Gemma3 technical report contains many details on training setup https://arxiv.org/pdf/2503.19786This was released with the initial batch of Gemma3 so it doesn't contain the 270m details, nonetheless you'll get a good idea of what it takes to build these models.reply",
      "Thanks for making this! One of my favorite projects was having a Discord chatbot powered by the original BERT model - these 270M weights are a fine upgrade.reply"
    ],
    "link": "https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/12_gemma3",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Show HN: PlutoPrint \u2013 Generate PDFs and PNGs from HTML with Python (github.com/plutoprint)",
    "points": 78,
    "submitter": "sammycage",
    "submit_time": "2025-08-20T20:37:58 1755722278",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44966170",
    "comments": [
      "It would be great if you could run it against the tests at https://www.print-css.rocks/They would give a much better idea of its complex printing capabilities.reply",
      "It should be required to run these tests for these libraries.\nIt's really frustrating to have to discover it trying to make it work.reply",
      "How does it differ from https://weasyprint.org ?reply",
      "WeasyPrint is great, but PlutoPrint takes a different angle: the engine is all C++, so it\u2019s faster and lighter on memory. It can render directly to PNG as well as PDF, and has stronger SVG support.reply",
      "PlutoBook looks very impressive.  Is it based on another renderer?reply",
      "This is so efficient, i just tested it ,far better than weasyprint, and it has both python and c++ repo, bro am amazed,\nAre you open for sponsorship?reply",
      "Maybe this isn't the same but it's a relatively few lines of code to use puppeteer to use an actual browser to render pages to PDFs/PNGs. Advantages would be everything is supported. Every new feature in CSS, HTML, SVG, Canvas2D, WebGL, WebGPU, etc... (though for WebGL/WebGPU you might need to pass in some flags to use llvmpipe/mesa/warp etc...Asking your favorite LLM will give you da codezPS: I'm not trying to discount this tool. I'm only pointing out an alternative that might be usefulreply",
      "That\u2019s a good point. Using Puppeteer or a headless browser gives you essentially full web platform support. The tradeoff is that it comes with a heavier runtime and more moving parts (Chromium, Node, etc.). PlutoPrint aims to be much lighter: no browser dependency, just a compact C++ engine with a Python wrapper. It does not cover the entire browser feature set but it is fast, portable, and easy to drop into projects without the overhead of a full browser.reply",
      "Interesting. I was not aware of PlutoBook!We're doing a very similar thing (custom lightweight engine) over at https://github.com/DioxusLabs/blitz. We have more of a focus on UI, but there's definitely overlap (we support rendering to image, but don't have pagination/fragmentation implemented).Have you run the WPT tests against your engine to test spec conformance?reply",
      "Exactly what I was wondering. I use puppeteer to render these [1] printable puzzles pages, and I use SVG, JavaScript to dynamically resize the text to fit a page, etc. Just works.[1]: https://ahapdf.nyc3.cdn.digitaloceanspaces.com/samplers/logi... (PDF)reply"
    ],
    "link": "https://github.com/plutoprint/plutoprint",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A Python Library for Generating PDFs and Images from HTML, powered by PlutoBook\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.     PlutoPrint is a lightweight and easy-to-use Python library for generating high-quality PDFs and images directly from HTML or XML content. It is based on PlutoBook\u2019s robust rendering engine and provides a simple API to convert your HTML into crisp PDF documents or vibrant image files. This makes it ideal for reports, invoices, or visual snapshots.PlutoPrint depends on PlutoBook. For faster installation, it is highly recommended to install PlutoBook and its dependencies manually beforehand. Otherwise, Meson will build them from source during installation, which can take significantly longer.For Windows and Linux 64-bit users, Plu"
  },
  {
    "title": "Why are anime catgirls blocking my access to the Linux kernel? (cmpxchg8b.com)",
    "points": 251,
    "submitter": "taviso",
    "submit_time": "2025-08-20T14:54:45 1755701685",
    "num_comments": 293,
    "comments_url": "https://news.ycombinator.com/item?id=44962529",
    "comments": [
      "This is a usually technical crowd, so I can't help but wonder if many people genuinely don't get it, or if they are just feigning a lack of understanding to be dismissive of Anubis.Sure, the people who make the AI scraper bots are going to figure out how to actually do the work. The point is that they hadn't, and this worked for quite a while.As the botmakers circumvent, new methods of proof-of-notbot will be made available.It's really as simple as that. If a new method comes out and your site is safe for a month or two, great! That's better than dealing with fifty requests a second, wondering if you can block whole netblocks, and if so, which.This is like those simple things on submission forms that ask you what 7 + 2 is. Of course everyone knows that a crawler can calculate that! But it takes a human some time and work to tell the crawler HOW.reply",
      "The problem is that 7 + 2 on a submission form only affects people who want to submit something, Anubis affects every user who wants to read something on your sitereply",
      "It sounds like you're saying that it's not the proof-of-work that's stopping AI scrapers, but the fact that Anubis imposes an unusual flow to load the site.If that's true Anubis should just remove the proof-of-work part, so legitimate human visitors don't have to stare at a loading screen for several seconds while their device wastes electricity.reply",
      "This arms race will have a terminus. The bots will eventually be indistinguishable from humans. Some already are.reply",
      "> The bots will eventually be indistinguishable from humansNot until they get issued government IDs they won't!Extrapolating from current trends, some form of online ID attestation (likely based on government-issued ID[1]) will become normal in the next decade, and naturally, this will be included in the anti-bot arsenal. It will be up to the site operator to trust identities signed by the Russian government.1. Despite what Sam Altman's eyeball company will try to sell you, government registers will always be the anchor of trust for proof-of-identity, they've been doing it for centuries and have become good at it and have earned the goodwill.reply",
      "Can't wait to sign into my web browser with my driver's license.reply",
      "In all likelihood, most people will do so via the Apple Wallet (or the equivalent on their non-Apple devices). It's going to be painful to use Open source OSes for a while, thanks to CloudFlare and Anubis. This is not the future I want, but we can't have nice things.reply",
      "Can't wait to start my stolen id as a service for the botnetsreply",
      "It will be hard to tune them to be just the right level of ignorant and slow as us though!reply",
      "> This is a usually technical crowd, so I can't help but wonder if many people genuinely don't get it, or if they are just feigning a lack of understanding to be dismissive of Anubis.This is a confusing comment because it appears you don\u2019t understand the well-written critique in the linked blog post.> This is like those simple things on submission forms that ask you what 7 + 2 is. Of course everyone knows that a crawler can calculate that! But it takes a human some time and work to tell the crawler HOW.The key point in the blog post is that it\u2019s the inverse of a CAPTCHA: The proof of work requirement is solved by the computer automatically.You don\u2019t have to teach a computer how to solve this proof of work because it\u2019s designed for the computer to solve the proof of work.It makes the crawling process more expensive because it has to actually run scripts on the page (or hardcode a workaround for specific versions) but from a computational perspective that\u2019s actually easier and far more deterministic than trying to have AI solve visual CAPTCHA challenges.reply"
    ],
    "link": "https://lock.cmpxchg8b.com/anubis.html",
    "first_paragraph": "Tavis Ormandy$Id: f0cc50a6fc6a5dd652c2b96ca9c1779f763fd6b1 $Hey\u2026 quick question, why are anime catgirls blocking my access to\nthe Linux kernel?I\u2019ve started running into more sites recently that deploy Anubis, a sort of hybrid\nart project slash network countermeasure. The project \u201cweighs the souls\u201d\nof HTTP requests to help protect the web from AI crawlers.If you\u2019ve seen anime catgirl avatars when visiting a new website,\nthat\u2019s Anubis.I\u2019m sympathetic to the cause \u2013 I host this blog on a single core\n128MB VPS, I can tell you some stories about aggressive crawlers!Anubis recently started blocking how I access git.kernel.org and lore.kernel.org. Those sites host the\nLinux Kernel Mailing\nList archive and the kernel git repositories. As far as I know I do\nhave a soul, I just wasn\u2019t using a desktop browser\u2026 so how exactly is my\nsoul being weighed?Note: Linux has Tux \ud83d\udc27, OpenBSD has Puffy \ud83d\udc21, SuSE has Geeko \ud83e\udd8e and\nMicrosoft has Bob \ud83e\udd13\u2026 nothing wrong with mascots! \ud83d\ude38The traditional solution to blocki"
  },
  {
    "title": "Introduction to AT Protocol (mackuba.eu)",
    "points": 126,
    "submitter": "psionides",
    "submit_time": "2025-08-20T19:13:09 1755717189",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=44965233",
    "comments": [
      "Here is an excerpt from the offical docs for the curious:\"Why not use ActivityPub?ActivityPub is a federated social networking technology popularized by Mastodon.Account portability is a major reason why we chose to build a separate protocol. We consider portability to be crucial because it protects users from sudden bans, server shutdowns, and policy disagreements. Our solution for portability requires both signed data repositories and DIDs, neither of which are easy to retrofit into ActivityPub. The migration tools for ActivityPub are comparatively limited; they require the original server to provide a redirect and cannot migrate the user's previous data.Another major reason is scalability. ActivityPub depends heavily on delivering messages between a wide network of small-to-medium sized nodes, which can cause individual nodes to be flooded with traffic and generally struggles to provide global views of activity. The AT Protocol uses aggregating applications to merge activity from the users' hosts, reducing the overall traffic and dramatically reducing the load on individual hosts.Other smaller differences include: a different viewpoint about how schemas should be handled, a preference for domain usernames over AP's double-@ email usernames, and the goal of having large scale search and algorithmic feeds.\"reply",
      "Relevant post by Christine Lemmer-Webber (Co-creator of ActivityPub) https://dustycloud.org/blog/how-decentralized-is-bluesky/reply",
      "a very opinionated piece that leads by conclusion rather than building up to it.The main part of ATProto that is centralized is the PLC and that will eventually be made (most likely) into a consortium. PDS hosting is debatableThat being said, it should be possible to run completely independent atproto networks today. We have several dev infra setups for doing it in the ecosystemreply",
      "Was fully expecting to see descriptions of \u201cATD\u201d and \u201cATH\u201d\u2026reply",
      "If you are interested in building on ATProtocol, one of the best places to start is the Discord (until we have an atproto native alt @blebbit.app)https://discord.atprotocol.dev/Of course the spec is good too, very easy readhttps://atproto.comhttps://docs.bsky.appreply",
      "What sorts of things can be built on the protocol?reply",
      "It\u2019s good at social-oriented apps - there\u2019s obviously Bluesky, and many other smaller apps in the style of other platforms.One of the most interesting projects is tangled.sh - a github-like using atproto for the social layer, which fits perfectly.reply",
      "Anything \"social\" basically - the first ideas that come to people's minds are of course things like: GitHub but on ATProto, Instagram on ATProto, Tiktok on ATProto, Reddit on ATProto\u2026reply",
      "Why isn't there a Discord built on ATProto ? [Serious Question, wondering if there are trade-offs that make this especially annoying]reply",
      "Currently atproto is still figuring out how to approach private data. Right now there exists extremely limited abilities to store private data via the bluesky preferences but until that mechanism is standardised in a way other projects can use, there's not really a good way to store data privately let alone transmit data privately.There's a working group for doing this but it'll be a while before anything is adopted at scale.If fully public is okay for you, there is actually already a chatroom/IRC-esque platform called Roomy. It works well but it is all public and there's a touch more latency than a normal client-server platform due to the nature of atproto's gossip protocol.reply"
    ],
    "link": "https://mackuba.eu/2025/08/20/introduction-to-atproto/",
    "first_paragraph": "\n\n      Wednesday, 20 August 2025\n    \n\n\nSocial\n\n\n\n0 comments\n\nSome time ago I\u00a0wrote a long blog post I\u00a0called \u201cComplete guide to Bluesky\u201d, which explains how all the user-facing features of Bluesky work and various tips and tricks. This one is meant to be a bit like a developer version of that \u2013 I\u00a0want to explain in hopefully understandable language what all the pieces of the network architecture are and how they all fit together. I\u00a0hope this will let you understand better how Bluesky and the underlying protocol works, and how it differs from e.g. the Fediverse. This should also be a good starting point if you want to start building some apps or tools on ATProto.This post is a first part of a series \u2013 next I\u00a0want to look at some comparisons with the Fediverse and some common misconceptions that people have, and look at the state of decentralization of this network, but that was way too much for one post; so this one focuses on the \u201cATProto intro tutorial\u201d part.But before we start, a l"
  },
  {
    "title": "Launch HN: Channel3 (YC S25) \u2013 A database of every product on the internet",
    "points": 82,
    "submitter": "glawrence13",
    "submit_time": "2025-08-20T15:34:07 1755704047",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=44962881",
    "comments": [
      "I assume that payments from purchases come from you guys, rather than me needing to create and manage an affiliate account with each individual vendor?You say that commissions average 5%, but what is the variability and where does it come from?Last, a bit of feedback about the product.I tried searching \"nintendo switch 2\" on your homepage and the results that came up kind of sketched me out. You mention that the products are US-only, but the first result clearly says \"hong kong\" in the title. And the store listed is \"My Nintendo Store PT\"; is that the official store? When I google that it takes me to the Portuguese version of the nintendo website, and that makes me even more confused.The second result for the same search appears to be a dress, which is obviously completely unrelated to video games in general.EDIT: I'm noticing irrelevant results for many queries. Searching \"plain white pillowcase\", the third result is a t-shirt, the seventh result is a dress, and the eleventh result is a light bulb.Searching \"men's wallet\" the very first result is an outdoor picnic table.reply",
      "Regarding payments, your understanding is correct. We have and manage our affiliate partnerships, all you have to do is drive sales and we forward on the commission to you. We're working on improving signal into the range of commissions you can expect, but, in short, the variability stems from merchants and product type. For example, technology (e.g. iPhones, laptops) typically have lower commissions than beauty supplies.Thanks for the feedback. Managing and cleaning this volume of data is an ongoing task, and our catalog is getting better each day. I'll check out the nintendo case in particular.reply",
      "Putting my affiliate hat on here for a minute...Very cool to see how you've aggregated so many products into one service. How do you plan to compete with FMTC and others that aggregate feeds together? Speaking as a publisher, I'd not want to share commission unless absolutely necessary and would prefer to just pay a fee so I can access the feed and not have an unknown amount of revenue lost between myself and the merchant.As a brand running a program, I'd be very cautious about allowing my feed into your database if I didn't have any way to finding out who is featuring my products and where/how. Are you providing visibility to the brands since you're effectively functioning as a sub-affiliate network?Those questions aside, great to see YC funding a startup in the space!reply",
      "Yes certainly! I've dealt with large datasets like this in the past and know firsthand how challenging it can be to wrangle them.Something like this would be a great fit for my travel planner app if I knew I could trust that the results were high quality before prompting the user with them.Btw I edited my earlier comment with a few more examples just before you replied.Good luck!reply",
      "Appreciate it. FYI, for the specific bugs you flagged, looks like Nintendo was improperly named (reindexing products with that name now), and sounds like the pain point you felt was extraneous search results that really didn't belong. Transparently, the problem we're facing there is vector search can be a bit of a black box, so we're trying to tune our hybrid search to cull out really crazy results, but obviously it still needs work.One of the ways we're combatting these search problems in the early days is developers can curate their catalog with specific brands, merchants, and categories (and even down to the product level) so you know exactly what the search space for each of your queries is. Curious to hear about your travel planner app -- if you think this would be a helpful tool, feel free to reach out at george@trychannel3.comreply",
      "Hi, we fixed this bug and you should see better results now. I'm getting good results for \"men's wallet\" and \"plain white pillowcase\". Try it out and let me know what you think!reply",
      "I am confused on who this is exactly for ? Is it for an end user/buyer who is looking to buy something and you just aggregate from various sources based on query OR is this for other developers/providers who are providing their own search interface on their own eCommerce website etc ? I assume the latter but isn't very clear at least to me.reply",
      "Developers! Anyone who wants to add shopping to their platform, build an e-comm website, or monetize their agent can use Channel3 to earn commissions on the products they sell. Totally see how that could get lost in this post, we tried to focus more on what we built than try to sell to devs. Hopefully our website makes this clearer.reply",
      "Can you be more specific?Can you explain the main use cases when i would want to add shopping to my platform?If i\u2019m building an ecommerce website, why would I need your API if I\u2019m just selling my own products?reply",
      "Yep, I should be more precise> If i\u2019m building an ecommerce website, why would I need your API if I\u2019m just selling my own products?You're right, Channel3 isn't for existing ecommerce websites. Channel3 let's anyone build a shopping experience (which I vaguely conflated with ecommerce website). You don't worry about managing product, you just build the platform. Some AI shopping experiences like this already exist, check out plush.shop, daydream.ing, and onton.com.> Can you explain the main use cases when i would want to add shopping to my platform?In short, if you want to monetize your platform without running ads. What's neat is there aren't really \"main\" cases -- this is up to the inventiveness of our users! We believe some of the most lucrative opportunities are yet to be imagined. My co-founder, Alex, experienced this problem at his last job when he was building an AI tutor; they decided to try to add an additional revenue stream by letting the AI tutor recommend products. Maybe blogs can integrate an AI-recommended product feed based on their article. Maybe yoga teachers who have a website for booking classes can recommend their gear to their students and earn some money when they do. Maybe someone just loves the color orange and wants to build a shop for orange products. We don't know what devs have in store for Channel3, but we do know agentic commerce is going to reshape how we interact with products!reply"
    ],
    "link": "item?id=44962881",
    "first_paragraph": ""
  },
  {
    "title": "Zedless: Zed fork focused on privacy and being local-first (github.com/zedless-editor)",
    "points": 366,
    "submitter": "homebrewer",
    "submit_time": "2025-08-20T18:47:03 1755715623",
    "num_comments": 218,
    "comments_url": "https://news.ycombinator.com/item?id=44964916",
    "comments": [
      "I'm glad to see this. I'm happy to plan to pay for Zed - its not there yet but its well on its way - But I don't want essentially _any_ of the AI and telemetry features.The fact of the matter is, I am not even using AI features much in my editor anymore. I've tried Copilot and friends over and over and it's just not _there_. It needs to be in a different location in the software development pipeline (Probably code reviews and RAG'ing up for documentation).- I can kick out some money for a settings sync service. \n- I can kick out some money to essentially \"subscribe\" for maintenance.I don't personally think that an editor is going to return the kinds of ROI VCs look for. So.... yeah. I might be back to Emacs in a year with IntelliJ for powerful IDE needs....reply",
      "I'm happy to finally see this take. I've been feeling pretty left out with everyone singing the praises of AI-assisted editors while I struggle to understand the hype. I've tried a few and it's never felt like an improvement to my workflow. At least for my team, the actual writing of code has never been the problem or bottleneck. Getting code reviewed by someone else in a timely manner has been a problem though, so we're considering AI code reviews to at least take some burden out of the process.reply",
      "AI code reviews are the worst place to introduce AI, in my experience. They can find a few things quickly, but they can also send people down unnecessary paths or be easily persuaded by comments or even the slightest pushback from someone. They're fast to cave in and agree with any input.It can also encourage laziness: If the AI reviewer didn't spot anything, it's easier to justify skimming the commit. Everyone says they won't do it, but it happens.For anything AI related, having manual human review as the final step is key.reply",
      "Agreed.LLM\u2019s are fundamentally text generators, not verifiers.They might spot some typos and stylistic discrepancies based on their corpus, but they do not reason. It\u2019s just not what the basic building blocks of the architecture do.In my experience you need to do a lot of coaxing and setting up guardrails to keep them even roughly on track. (And maybe the LLM companies will build this into the products they sell, but it\u2019s demonstrably not there today)reply",
      "> LLM\u2019s are fundamentally text generators, not verifiers.In reality they work quite well for text and numeric (via tools) analysis, too. I've found them to be powerful tools for \"linting\" a codebase against adequately documented standards and architectural guidance, especially when given the use of type checkers, static analysis tools, etc.reply",
      "The value of an analysis is the decision that will be taken after getting the result. So will you actually fix the codebase or it\u2019s just a nice report to frame and put on the wall?reply",
      "> So will you actually fix the codebase\u2026Code quality improvements is the reason to do it, so *yes*. Of course, anyone using AI for analysis is probably leveraging AI for the \"fix\" part too (or at least I am).reply",
      "That's a fantastic counterpoint. I've found AI reviewers to be useful on a first pass, at a small-pieces level. But I hear your opinion!reply",
      "I find the summary that copilot generates is more useful than the review comments most of the time.  That said, I have seen it make some good catches.  It\u2019s a matter of expectations: the AI is not going to have hurt feelings if you reject all its suggestions, so I feel even more free to reject it feedback with the briefest of dismissals.reply",
      "IMO, the AI bits are the least interesting parts of Zed. I hardly use them. For me, Zed is a blazing fast, lightweight editor with a large community supporting plugins and themes and all that. It's not exactly Sublime Text, but to me it's the nearest spiritual successor while being fully GPL'ed Free Software.I don't mind the AI stuff. It's been nice when I used it, but I have a different workflow for those things right now. But all the stuff besides AI? It's freaking great.reply"
    ],
    "link": "https://github.com/zedless-editor/zed",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        (WIP) Zed fork focused on privacy and being local-first\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.This is Zedless, a fork of Zed that's designed to be privacy-friendly and local-first.Zedless is currently work-in-progress. Feel free to contribute!This is a list of things that Zedless will do differently.License information for third party dependencies must be correctly provided for CI to pass.We use cargo-about to automatically comply with open source licenses. If CI is failing, check the following:\n        (WIP) Zed fork focused on privacy and being local-first\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was"
  },
  {
    "title": "SimpleIDE (github.com/jamesplotts)",
    "points": 20,
    "submitter": "impendingchange",
    "submit_time": "2025-08-20T23:15:55 1755731755",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44967505",
    "comments": [
      "I learned VB .net when it first came out back in 2003 (might have been earlier). VB was quite widely used back then and now days it's declined in popularity a lot. I checked the repo insights and it's a single person who's built this and has been maintaining it. Their contribution and dedication is definitely commendable even though the language isn't popular these and even more so on Linux! This is pure selfless programming!reply",
      "Seeing as how it's written in VB.Net, and 3 more of his 5 total public projects are also VB.Net, I don't think \"selfless\" really fits; I'll bet this project very much scratches this man's own itch.Dedicated for sure though, and commendable, especially since it's FOSS.reply",
      "Haha, I laughed when you said this.  I've only been writing it for a little over two months now.  But thank you!reply",
      "Interesting, I didn't actually know that VB.NET ever got ported to Linux with the rest of .NET Core.Does it still have the drag-n-drop GUI feature to make graphical apps, or is that a strictly Windows thing?reply",
      "And what makes this project significant is there's a lack of VB.NET tools on Linux.It has been challenging trying to get Gtk 3 widgets to play nice.  Finally just rolled my own custom-drawn editor, treeview, and listbox.  Going to release them later in a library.reply",
      "This isn't meant to be a passive aggressive dig, but a genuine question...why make an VB.NET IDE?I think it's cool that you did it, it's just not a language that I've seen get a lot of love.reply",
      "VB.NET's verbose syntax actually makes it PERFECT for AI assistance. And it is being developed with full AI integration.And, Linux lacks any such tools.  Not even VS Code has a plugin for VB.reply",
      "The WinForms designer (drag-n-drop GUI) isn't fully supported on Linux - SimpleIDE likely focuses on code editing rather than visual design, as the .NET MAUI/WinForms designers remain Windows-centric despite .NET's cross-platform capabilities.reply",
      "Well, that would certainly be a stretch goal.  Right now its all code.reply",
      "I did learn programming with VB many years ago. It definitely holds some sentimental value for me although I wouldn\u2019t consider using it today.reply"
    ],
    "link": "https://github.com/jamesplotts/simpleide",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Visual Basic IDE for Native Linux Dotnet Development\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A lightweight, professional VB.NET IDE built with GTK# 3 on Linux using .NET 8.0. SimpleIDE provides a modern development environment specifically designed for VB.NET projects on Linux systems.\n\n\nSettings are stored in ~/.config/SimpleIDE/settings.jsonThe project follows strict coding conventions:Hungarian Notation for variables:Enum Pattern: All enums start with eUnspecified and end with eLastValueXML Documentation: All public members must have XML documentation commentsError Handling: Try-Catch blocks in all methods with console loggingContributions are welcome! Please follow these guidelines:This program is free software: you can redistribute it and/or mod"
  },
  {
    "title": "An Update on Pytype (github.com/google)",
    "points": 144,
    "submitter": "mxmlnkn",
    "submit_time": "2025-08-20T17:04:51 1755709491",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44963724",
    "comments": [
      "ex-pytype dev here - we knew this was coming and it's definitely the right thing to do, but it's still a little sad to see the end of an era. in particular, pytype's ability to do flow-based analysis across function boundaries (type checking calls to unannotated functions by symbolically executing the function body with the types of the call arguments) has not been implemented by any of the other checkers (again for good reasons; it's a performance hit and the world is moving towards annotations over pure inference anyway, but I still think it's a nice feature to have and makes for more powerful checking).as an aside, while I agree that bytecode-based analysis has its drawbacks, I think it's a tool worth having in the overall python toolbox. I spun off pycnite from pytype in the hope that anyone else who wanted to experiment with it would have an easier time getting started - https://github.com/google/pycniteI have recently jumped onto the \"write python tooling in rust\" bandwagon and might look into a rust reimplementation of pycnite at some point, because I still feel that bytecode analysis lets you reuse a lot of work the compiler has already done for you.reply",
      "> while I agree that bytecode-based analysis has its drawbacksabstract interpretation of the bytecode like y'all were doing is the only way to robustly do type inference in python.> https://github.com/google/pycnitethere's also https://github.com/MatthieuDartiailh/bytecode which is a good collectionreply",
      "yeah, that's a really nice project too!reply",
      "> I have recently jumped onto the \"write python tooling in rust\" bandwagonI know Go and Rust are the belles du jour, but this kind of thing really hampers integrators' ability to support platforms other than x86-64 and armv8.  In my particular case, it results in me being unable to build software that depends on pyca/cryptography on platforms like s390x, which makes me sad.  It also makes development environment management, including CI/CD pipeline maintenance, that much more complicated.  It was already bad enough when I was trying to compile binary distributions on Windows, and that was just with the Visual C++ toolchain mess that is the Microsoft development experience.reply",
      "Rust supports s390x. https://doc.rust-lang.org/stable/rustc/platform-support/s390...reply",
      "On top of all this, pretty much everything depends on Python (even glibc's build system depends on it now), and Rust is relatively hard to bootstrap. So bootstrapping a usable Python on glibc could one day involve bootstrapping all the way up to Rust on musl (including e.g. llvm) just to get Python just to build the final system's libc.That doesn't feel great to me.reply",
      "please note that I am not talking about introducing rust into the python interpreter (where, I agree, bootstrapping concerns would make the gain in code maintainability not really worth it), but in writing developer tools that work with python in rust or a mix of rust and python rather than in pure python. these are tools that run on the developer's machine or on test/ci servers, not in the target environment.reply",
      "I can sympathise with that, but to argue a bit for the other side, these tools are mainly intended to run on the developer's machine or in the CI pipeline. in both cases they overwhelmingly use architectures that rust supports, and in the case of CI surely it's easier to deploy a single rust binary than a python binary and all its library dependencies.I used to be very much in the \"write your language tools in the language and the community will contribute\" camp, but astral has really shown what a big difference pure speed can make, and I now have more of a \"write tools in rust and ideally make sure they also expose libraries that you can call from python\" mindset.reply",
      "why not just go with a language that has gradual typing built in - eg rakureply",
      "because there is a ton of existing python code that people find a lot of value in, and that no one wants to abandon. the return on investment for making python better is insanely higher than that on porting hundreds of millions of lines of code to another language.reply"
    ],
    "link": "https://github.com/google/pytype",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A static type analyzer for Python code\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.TL;DR: The last supported Python version for Pytype will be 3.12. We are\nstill very actively interested in the space of Python type checking, but\nshifting our investments towards new ideas and different frameworks.Pytype's development began in 2012 to meet Google developers' demand for\ncompile-time checking. Pytype started with using type inference and interface\nfiles, and then switched to inline annotations (while retaining the inference\nengine) after the acceptance of PEP 484. Later, pytype's team collaborated with\nGuido and mypy to create typeshed, a central repository for type annotations.While pytype has been effective, its bytecode-based design has presented\nchalleng"
  },
  {
    "title": "Visualizing distributions with pepperoni pizza (and JavaScript) \u2013 nicole web (ntietz.com)",
    "points": 4,
    "submitter": "cratermoon",
    "submit_time": "2025-08-18T13:38:04 1755524284",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://ntietz.com/blog/visualizing-distributions-with-pepperoni-pizza/",
    "first_paragraph": "Monday, August 18, 2025There's a pizza shop near me that serves a normal pizza.\nI mean, they distribute the toppings in a normal way.\nThey're not uniform at all.\nThe toppings are random, but not the way I want.The colloquial understanding of \"random\" is kind of the Platonic ideal of a pizza: slightly chaotic but things are more or less spread out over the whole piece in a regular way.\nIf you take a slice you'll get more of less the same amount of pepperoni as any other slice.\nAnd every bite will have roughly the same amount of pepperoni as every other bite.I think it would look something like this.Regenerate this pie!This pizza to me is pretty much the canonical mental pizza.\nIt looks pretty random, but you know what you're gonna get.\nAnd it is random!Here's how we made it, with the visualiztion part glossed over.\nFirst, we make a helper function, since Math.random() gives us values from 0 to 1, but we want values from -1 to 1.Then, we make a simple function that gives us the coordinat"
  },
  {
    "title": "Show HN: Luminal \u2013 Open-source, search-based GPU compiler (github.com/luminal-ai)",
    "points": 83,
    "submitter": "jafioti",
    "submit_time": "2025-08-20T16:01:13 1755705673",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=44963135",
    "comments": [
      "So wait, am I understanding this correctly?Instead of applying just predetermined optimization rules or patterns, the compiler formulates the problem as searching through many possible configurations or versions of the code. Each possible version can have different arrangements, tiling sizes, thread block configurations, memory access patterns, and instruction sequences, right?And from my understanding, the \u201csearch space\u201d is just a collection of all potential versions of the code (kernels) that the compiler can generate from the original input. So for example, the space might include- Different ways to partition workloads among GPU threads and blocks- Varying memory access strategies (using shared memory, global memory)- Various instruction-level optimizations or reordering- Alternative loop unroll factors or vectorization strategiesThe compiler then programmatically produces a large number of candidate kernels by combining different optimizations and configurations. Among these millions of candidates, the compiler tries to find the one that performs best.In that case, can the compiler print out which gpu configuration works the best for that computer? And will that configuration be applicable to all computers with the same setup?This is such an interesting technique.reply",
      "yup! we build a search space by iteratively applying rewrite rules in every possible order (using e-graphs to do this efficiently). the rewrites alter stuff like looping / tiling structures, as well as algebraic rewrites like softmax to online softmax (and then flash attention).yes optimized kernels for one system will work on other systems with the same hardware. its fine to take a long time compiling if you just compile once and run a lot.reply",
      "Is/will it be possible to just write a model component with Luminal and then use that as a building block in e.g. Torch or JAX?reply",
      "Your description is exactly right. We create a search space of all possible kernels and find the best ones based on runtime. The best heuristic is no heuristic.This obviously creates a combinatorial problem that we mitigate with smarter search.The kernels are run on the computer the compiler is running on. Since runtime is our gold standard it will search for the best configuration for your hardware target. As long as the setup is mostly the same, the optimizations should carry over, yes.reply",
      "How long does this typically take? It sounds time consuming. Also, it seems like this could be similar to doing a GA?reply",
      "That depends on the model architecture and how it was written since that informs the size of the search space.The typical range is 10 mins to 10 hours. It won't be fast but you only have to do it once and then those optimizations are set for every forward pass.reply",
      "Do you learn the capabilities of the underlying hardware relative to the kernel src? You should be able to start predicting perf using learned static profiling.reply",
      "Not today but we will implement memoization of kernels for each hardware backend, yes.reply",
      "You can also set a time budget for how long you'd like the search to run for to avoid wasting time on diminishing returns.reply",
      "Is this a bit similar to what tensorrt does, but in a more opened manner ?reply"
    ],
    "link": "https://github.com/luminal-ai/luminal",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Deep learning at the speed of light.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\nLuminal is a deep learning library that uses search-based compilation to achieve high performance.To run the demo shown on HN on mac, clone this repo and run:ImportantWe're undergoing a large transition to \"2.0\", which introduces large-scale kernel search. This radically simplifies the compiler stack and allows us to discover complex optimizations entirely automatically. Please keep an eye on breaking changes, which usually are staged in the crates/luminal_2 before being merged into the main crate.Llama 3 8BLuminal can run Q8 Llama 3 8B on M-series Macbooks at 15-25 tokens per second. The goal is to become the fastest ML framework for any model on any device.The core of l"
  },
  {
    "title": "Coris (YC S22) Is Hiring (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-08-20T21:00:14 1755723614",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/coris/jobs/rqO40yy-ai-engineer",
    "first_paragraph": "AI-powered risk platform for Payment Providers, Banks, SaaS platforms\u2026Location: SF Bay Area ( 4+ days in office )Experience Level: 3\u20135+ yearsStack: Python, PyTorch, ML, LLMs, DjangoType: Full-timeCoris is building the AI-first trust layer for global commerce. We partner with leading platforms, marketplaces, payment providers, and banks to transform how small business onboarding, monitoring, and lifecycle decisions are made - using AI on the ground to drive faster, smarter actions with less friction.One of our customers described us as Cursor + Lovable for risk teams: flagging bad actors, assisting in investigations, and autonomously acting to mitigate fraud losses in real time.Backed by top-tier investors and founded by experts in the payments domain, Coris is reimagining how risk gets done - not with legacy rule engines, but with domain-specific AI that thinks like your best risk analyst at scale. We help customers scale their expertise, move faster, and unlock growth - without compro"
  },
  {
    "title": "Pixel 10 Phones (blog.google)",
    "points": 339,
    "submitter": "gotmedium",
    "submit_time": "2025-08-20T17:24:10 1755710650",
    "num_comments": 637,
    "comments_url": "https://news.ycombinator.com/item?id=44963939",
    "comments": [
      "The people at Google seem to think much more like me than the people at Apple.There are 3 primary decisions Google made that click with me, while Apple's choices are a mystery to me:1: When I put a Pixel on a table, it sits there stable. Because the backside is symmetrical. When I put an iPhone on a table, it wobbles.2: When I sort my photos on a Pixel, I sort them in folders. The \"camera\" folder is where the unsorted photos are. When I sit in a bus or in a cafe, I go through it and sort the new photos into folders. This seems impossible on iPhones. Everything stays in the main folder forever. You can add photos to albums, but that does not remove them from the main folder. So there is no way to know which photos I have already sorted.3: On Android I can use Chrome. Which means web apps can use the File System Access API. This makes web apps first class productivity applications I can use to work on my local files. Impossible on iPhones.I'm sure people who prefer iPhones have their own set of \"this clicks with me on iPhones and puzzles me on Pixels\" aspects?Is this a \"left brain vs right brain\" type of thing? Do most HNers prefer Androids?reply",
      "> 1: When I put a Pixel on a table, it sits there stable.That was the first thing I noticed. I assume the extra protuberance is to enable the insane zoom level but it goes full width for stability.I have G85 Motorola - great phone (and primarily a phone/modem/camera) for the price, but it wobbles slightly.Yes, I prefer Android, but have a M4 Air that goes everywhere with me to do actual work.reply",
      "Same for me, although I currently use an iPhone (and the rest of the Apple ecosystem). I actually don't like iOS, and barely tolerate macOS but I love the hardware on mac right now.For me, it's Apple's privacy stance (which I know could change at anytime, but that's where we are at right now). Give me a Pixel & all the Google stuff but without Google, and with advanced data protection and Apple's tracking protection and transparency and I'm in.As long as apps on Android can do crap like the web-to-app tracking via localhost and other shady data harvesting that Google continues to allow, I don't touch it no matter how much better it is and how much I prefer the workflows.Also, on either platform, why is it still not possible to toggle off network access in app permissions. Its a glaring and deliberate omission.reply",
      "> barely tolerate macOSI guess it depends what you\u2019re comparing it to but macOS is (for me) the best of a bad bunch of compromises. POSIX with app boundaries that are (mostly) respected, if not particularly granular. There\u2019s nothing I really hate about the platform save for homebrew and being walled in to the ecosystem.I actually love modern Linux with Gnome, and it has all the parts these days to be a great desktop operating system, but I find the freedom there undercuts a lot of the promises (Flatpaks are a good idea in theory that doesn\u2019t work in practice as the sandboxes are overly liberal and overreach on most apps because no-one\u2019s forced to justify why they need the permissions they do etc).I spent so long on Windows that I really don\u2019t miss it. The Window management was way better for so long, but the idioms drive me crazy (registry issues and programs still freely writing anywhere they like), and supporting everything forever has massive drawbacks to usability (although Winget sort of slightly helps with this but it\u2019s not much better than homebrew).reply",
      "> best of a bad bunch of compromisesThat's exactly why I don't particularly care for it, but still use it.My first choice would be Linux + a tiling WM. I used DWM for years before Apple Silicon, and have been on mac ever since the M1. These new machines are so nice that I can't go back to anything else now, whether I hate the software or not.But macOS is just baffling. There's POSIX underneath, and it's mostly reliable, and it has a lot of little nice touches - being able to search the menu with Cmd+Shift+/, emacs keybindings in nearly every text field, etc. But then there's stuff that makes no sense. Why do I need a third party app for any sort of sane window management? (and even then, I haven't fully replicated my preferred way of working, only gotten close enough with Aerospace, and more recently Raycast). A third party app to set a keyboard shortcut to launch an application. I can't disable the animations for switching virtual desktops, and when you switch there's a lag before it's responsive again for keyboard input (I just want this to be instant).So much of how macOS expects you to interact with it seems to be mouse/touchpad driven, and that's just not how I prefer to use my computer. At least with Raycast I now have shortcuts to launch and switch to apps (but not specific app windows because of the app/window separation in macOS). Yet even still, I can't set a keyboard shortcut to move a window to a different space. I have to click and hold the title bar and then press my shortcut for moving to that space to move the window - Apple decided that action MUST involve the mouse.I also can't set window rules. I can't tell my terminal to always open on workspace 2, or mail.app to always open on workspace 4 at a specific size, etc. Making an app full screen also creates a new ephemeral space that can't be switched to with the usual Ctrl+NUM keyboard shortcut. I can't set a window to be always on top.I'm more or less waiting for Asahi Linux to get support for DisplayPort ALT mode & M4 support, although I'm not holding my breath.I do appreciate having access to the big commercial apps though on macOS, but ultimately I want my M4 macbook pro w/ Linux & hyprland.reply",
      "So much this.I\u2019ve migrated a home server to a Mac mini. It was awful to achieve. Trying to get a machine to boot, connect network shares and start containers was a week long effort. I can do it in Ubuntu in about 10 minutes from a clean install.So much is disgusting UI options hidden deep some in the (awful) settings app.But the result is a server that is fast, powerful and using 6-7W per hour, compared to the old Nuc 9 it replaced that used 70W.It\u2019s just so good. The OS lets it down.reply",
      "The new Intel NUCs are only like a hundred something dollars for an N150 CPU and come with 16 gigs of RAM and a SSD.Why pay so much more to fight an uphill battle?Unless you desperately need the hot garbage that is Xcode there isn't much reason to deal with Mac Minis running MacOS as a server. One update and it will suspend and be unwakeable without physical interaction.reply",
      ">Give me a Pixel & all the Google stuff but without Googlehttps://grapheneos.org/reply",
      "As a consumer, I lament most of all about Pixel devices (or any other Android device really) that I have to wipe the OS and install a different one to get features that matter to me, particularly around privacy.Thats why I don't use Pixel devices, or any Android devices really. I know its a precarious situation with Apple since they could reverse their stance at any point and sometimes they get it wrong, but they have yet to completely fail me when it comes to privacy.In any event, it'd be nice if there was a 3rd mainstream vendor in the mobile race[0][1][0]: Both design wise and conceptually, I miss WebOS when it was strictly under Palm. It could have really been something. Why they didn't embrace multitouch screens I haven't a clue, it was the one thing that baffled me.[1]: The one project I really wanted Mozilla to take a long term view on - Firefox OS - was another great innovation of our time that didn't get the love or support it deserved. It was a blast using web technology to build apps that ran fluidly on modern hardware. Unfortunately, it was all too often relegated to cheap manufacturer hardware that couldn't support it ideally, but even with this being true, they pulled off alot of technical excellence with that project.reply",
      "I miss Nokia's maemo/meego based phones :( the n900 was really nice to use and even write my own little personal apps for (something I haven't done in over a decade of owning android phones)reply"
    ],
    "link": "https://blog.google/products/pixel/google-pixel-10-pro-xl/",
    "first_paragraph": "Aug 20, 2025\n          Our 10th generation of Pixel phones come with a refined design, cutting edge AI, enhanced cameras and more helpful support than ever.\n        \nThe Pixel 10 phones are here with the Google Tensor G5 chip and Gemini Nano model. Expect a fresh design with recycled materials and improved displays. Preorder today, with phones on shelves August 28.\nThe Pixel 10 phones are here with the Google Tensor G5 chip and Gemini Nano model. Expect a fresh design with recycled materials and improved displays. Preorder today, with phones on shelves August 28.\n\n\"Powerful and proactive: Pixel 10 phones are here!\" introduces Google's 10th gen Pixel phones.\nPixel 10 boasts a refreshed design, recycled materials, and comes in four expressive colors.\nThe phones run on the new Tensor G5 chip and Gemini Nano for personalized AI experiences.\nMagic Cue proactively offers helpful info in apps, like flight details during airline calls.\nPixel 10 Pro gets Pro Res Zoom, using AI to capture amazin"
  },
  {
    "title": "Visualizing GPT-OSS-20B embeddings (melonmars.github.io)",
    "points": 67,
    "submitter": "melonmars",
    "submit_time": "2025-08-17T15:56:36 1755446196",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=44932509",
    "comments": [
      "Without a way to tune it, this visualization is as much about the dimensionality reduction algorithm used as the embeddings themselves, because trade-offs are unavoidable when you go from a very high dimensional space to a 2D one. I would not read too much into it.reply",
      "This demo is a lot more useful for comparing word embeddings: https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/index.htmlYou can choose which dimensions to show, pick which embeddings to show, and play with vector maths between them in a visual wayIt doesn't show the whole set of embeddings, though I am sure someone could fix that, as well as adapting it to use the gpt-oss model instead of the custom (?) mini set it uses.reply",
      "@Author i would recommend you to givehttps://github.com/vasturiano/3d-force-grapha try, for the text labels you can usehttps://github.com/vasturiano/three-spritetextits based on Three.js and creates great 3D graph visualisations GPU rendered (webgl). This could make it alot more interresting to watch because it could display actual depth (your gpu is gonne run hot but i guess worth it)just a suggestion.reply",
      "Is this handling Unicode correctly? Seems like a lot of even Latin alphabets are getting mangled.reply",
      "It looks like it's not handling UTF-8 at all and displaying it as if it were Latin-1reply",
      "I don't think it's actually UTF-8.  The data is at https://melonmars.github.io/LatentExplorer/embeddings_2d.jso... and contains things like  \"\\u00e0\\u00a7\\u012d\\u00e0\\u00a6\\u013e\"\n\nwith some characters > 0xff (but none above 0x0143, weirdly).reply",
      "I have the suspicion that this is how GPT-OSS-20B would generate a visualization of it's embeddings. Happy to learn otherwise.reply",
      "What do people learn from visualizations like this?What is the most important problem anyone has solved this way?Speaking as somewhat of a co-defendant.reply",
      "Not everything has to be directly informative or solve a problem. Sometimes data visualization can look pretty for pretty's sake.Dimensionality reduction/clustering like this may be less useful for identifying trends in token embeddings, but for other types of embeddings it's extremely useful.reply",
      "I lets you inspect what actually constitutes a given cluster, for example it seems like the outer clusters are variations of individual words and their direct translations, rather than synonyms (the ones I saw at least).reply"
    ],
    "link": "https://melonmars.github.io/LatentExplorer/embedding_viewer.html",
    "first_paragraph": ""
  },
  {
    "title": "OPA maintainers and Styra employees hired by Apple (openpolicyagent.org)",
    "points": 112,
    "submitter": "crcsmnky",
    "submit_time": "2025-08-20T15:44:33 1755704673",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=44962969",
    "comments": [
      "This is a very well written announcement. It immediately defines OPA (for people like me who don\u2019t immediately recognize it). It says what\u2019s not changing for people, and says where things will go.Congratulations to the team.reply",
      "> It says what\u2019s not changing for peopleFor the people who are currently experiencing the first time a project they heavily used gets acquired by a for-profit company, it's worth remembering that everything written is \"As it stands currently\", which can change at any time.It wouldn't be the first time the founders/company/project said \"Nothing will change now when we got acquired\" only for it to shutdown/change drastically just months after.reply",
      "And the other side of that coin is ...Lots of FOSS maintainers are happy to bitch and moan about how they are doing god's work for little or no remuneration.  They are of course, quite correct to do so, it is indeed hard work, long hours, poor or no pay.But, and its a big BUT .... you can put all the donation, crowdfunding buttons that you like on your GitHub page.  The reality is that will only get you so far.So there is a lot to be said for corporations that recognise the work and are willing to pay an old-school salary to the maintainers.  It provides life-stability for the maintainers, and it provides product-stability for the corporation ... win-win.And in 2025 the reality is that corporation thinking on open-source is a far cry of what it was back-then.  In the majority they are far more enlightened and open to contributing-back.Yes it will never be sufficient for the die-hard FOSS greybeards. But even a billion dollar corporation cannot possibly put dollars behind every single tiny piece of open-source software it ever uses.  You have to pick-and-choose, its just the reality of life.Finally, regarding the FUD about \"oh, its going to be shutdown tomorrow\".  That road is paved with examples where it DID NOT happen ... I seem to recall that the usual suspects (Redhat / Canonical / IBM etc.) all employ a great deal of maintainers of various critical parts of Linux. As far as I can tell the output of those maintainers taking the corporate dime has neither suffered or been shutdown.reply",
      ">But, and its a big BUT .... you can put all the donation, crowdfunding buttons that you like on your GitHub page. The reality is that will only get you so far.I agree. Most people simply won't donate, be it individuals or companies using the tools.>In the majority they are far more enlightened and open to contributing-back.Ehh, it's mixed. A few companies won't mind going open source, some \"open source\", and many \"open source but not really\". Just having your code readable isn't the FOSS menality, and that's pretty much where the buck stops.>Finally, regarding the FUD about \"oh, its going to be shutdown tomorrow\". That road is paved with examples where it DID NOT happenSuvivor's bias doesn't really feel reassuring here. And just because it's not shut down doesn't mean it won't be subject to corporate rot. That's honestly worst than an honorable death.reply",
      "Styra was also a for profit company. The project is part of CNCF though.reply",
      "I was left with the somewhat opposite feeling. I still don\u2019t know what OPA actually is or does. It has a nice paragraph describing it without saying anything at all.reply",
      "OPA solves the problem of defining and enforcing policies across a system. Some examples:- How do I enforce that inbound API requests come only from trusted sources?- How do I enforce fine-grained access to user records?- How do I enforce a set of naming conventions for a data update?Many such policies may come from regulatory requirements, may be regional in nature, and may change in otherwise stable codebases. And it's even harder when you're applying this to a highly-scalable production internet service. As a result, defining policy at an organizational level with auditing is a challenge for large enterprises. OPA helps enterprises administer and enforce policies.More details on what OPA does here: https://www.openpolicyagent.org/docs/philosophyAnd you can see some examples of Rego (the policy language) here:\nhttps://play.openpolicyagent.orgreply",
      "I guess I\u2019m familiar with the general concept/domain it\u2019s in. I haven\u2019t used it myself, but having it spelled out was enough base knowledge for me to grab on to.Looking again, I see your point. If you don\u2019t know what it is having the acronym spelled out doesn\u2019t help much at all.Still it clears the low bar provided by those announcements that just say something like:\u201cBEOTZ\u2019s developers are joining Flmp.io. As well all know BEOTZ is popular and Flmp.io is a top provider to enterprises. We look forward to exciting things coming soon.\u201dreply",
      "The nice things about such an obituary is that it isn't a person so we don't have to feel bad and we don't need to know what it was going to do.reply",
      "> It immediately defines OPA (for people like me who don\u2019t immediately recognize it)Outer Planets Alliance. Bloody terrorists they are.reply"
    ],
    "link": "https://blog.openpolicyagent.org/note-from-teemu-tim-and-torin-to-the-open-policy-agent-community-2dbbfe494371",
    "first_paragraph": ""
  },
  {
    "title": "Sequoia backs Zed (zed.dev)",
    "points": 282,
    "submitter": "vquemener",
    "submit_time": "2025-08-20T12:13:16 1755691996",
    "num_comments": 185,
    "comments_url": "https://news.ycombinator.com/item?id=44961172",
    "comments": [
      "I love the spirit of Zed. From the principles to the low-level implementation details, it all screams \"good taste\". It's immensely interesting as an object of study (the code is great, from GPUI all the way up).Having said that, I don't think an editor should be VC backed. It's the obvious pragmatic choice to get a team together to support a thing, but I'm concerned by it.reply",
      "Sublime Text solved this 17 years ago with the 40-year-old shareware model.It's also faster than Zed, works on Linux/Win/MacOS, and is decently customizable.reply",
      "There was a time around ST2 when it felt like everyone was using it and it could've become The Editor, then something happened and it's been left in the dust. I wasn't even aware but apparently even fourth version of ST was released, and that was in 2021.I lost track of what happened there (moved to Vim back then), was it VSCode that killed it?reply",
      "I've been a registered user of ST for long long time, and I thought if anything hurt them in the marketplace, it was taking several years off from the end of 2013 until late 2017 with hardly anything being released that opened the door to Atom and other editors to catch up.reply",
      "Yeah, as others already mentioned, I think they sat on their laurels for a bit too long and let VSCode overtake it.For what it's worth, I went from ST3 -> VSCode -> ST4, and have been happy since. I've found that I prefer my text editor with minimal extensions, and with Sublime Text's LSP Plugin, I'm pretty content. The performance and customizable UI make it more worth it to me than VSCode.reply",
      "It's the LSP plugin that finally drove me to leave ST4 for Zed. Language integration is table stakes for an editor now. The fact that ST support is behind a volunteer plugin instead of integrated directly in the editor just means it's never going to be as good as a editor that does have first class support. The ST devs need to actually improve the editor, but I haven't seen any material updates in years.reply",
      "Agreed, LSP has replaced Linter extensions and the TabNine LLM which is nice (and snappy). Even if some of the lsp servers are clunky to use.reply",
      "I don't get this Sublime is dead nonsense. It's still being updated and works great. It's been my editor of choice for years and I happily pay for my license. I'd probably pay more if they asked me, it's tremendous value for money in my opinion.reply",
      "I dislike \"$x is dead\" as much if not more as you do, and I'm sure it works fine as something doesn't need to be the most popular choice to be working.With that being said, just a quick look at, for example Stack Overflow 2025 survey tells me it doesn't have the same mindshare it once had.reply",
      "Plugins were kind of it's selling point, yet it was pretty easy to mess it up with Plugins to the point of it being unusable - and not knowing what plug-in caused that.reply"
    ],
    "link": "https://zed.dev/blog/sequoia-backs-zed",
    "first_paragraph": "Nathan SoboAugust 20th, 2025Today we're announcing our $32M Series B led by Sequoia Capital with participation from our existing investors, bringing our total funding to over $42M.For the past four years, we've been building the world's fastest IDE, but that's just the foundation for what comes next. Our ultimate vision is a new way to collaborate on software, where conversations about code remain connected to the code itself, instead of being tied to aging snapshots or scattered across different tools. The first step was creating a high-quality editor to serve as the user interface. Now this new investment lets us expand to tackle the next phase of our plan. We're developing a new kind of operation-based version control that incrementally tracks the evolution of your code with edit-level granularity, and we're integrating it into Zed to make collaboration, both with agents and teammates, a first-class part of the coding experience.Sequoia is excited about our vision, and we're thrille"
  },
  {
    "title": "Is Rotten Tomatoes Still Reliable? A Statistical Analysis (statsignificant.com)",
    "points": 7,
    "submitter": "m463",
    "submit_time": "2025-08-21T00:10:07 1755735007",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44967796",
    "comments": [
      "A good article overall, but a special dishonorable mention for depicting a relationship that\u2019s ideally y=x with a bar chart.> In the short term, inflated scores may lure people to theaters once or twice. But in the long run, it's better if people enjoy their experience at the theater (by, you know, seeing a good movie). Despite my lizard-brain reaction, I believe long-term thinking usually wins out, while short-term shenanigans are always rotten in hindsight.And that\u2019s how you get from \u201csicko-utilitarianism\u201d to rule consequentialism.reply",
      "Obvious to anyone using the site or aware of is ratings, including the author, but it is good to see some analysis as evidence.reply"
    ],
    "link": "https://www.statsignificant.com/p/is-rotten-tomatoes-still-reliable",
    "first_paragraph": ""
  }
]