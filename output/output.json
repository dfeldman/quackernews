[
  {
    "title": "Show HN: Unregistry \u2013 \"docker push\" directly to servers without a registry (github.com/psviderski)",
    "points": 126,
    "submitter": "psviderski",
    "submit_time": "2025-06-18T23:17:10 1750288630",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=44314085",
    "comments": [
      "Nice. And the `pussh` command definitely deserves the distinction of one of the most elegant puns: easy to remember, self-explanatory, and just one letter away from its sister standard command.\n \nreply",
      "> The extra 's' is for 'sssh'> What's that extra 's' for?> That's a typo\n \nreply",
      "This should have always been a thing!  Brilliant.Docker registries have their place but are overall over-engineered and an antithesis to the hacker mentality.\n \nreply",
      "Neat project and approach! I got fed up with expensive registries and ended up self-hosting Zot [1], but this seems way easier for some use cases. Does anyone else wish there was an easy-to-configure, cheap & usage-based, private registry service?[1]: https://zotregistry.dev\n \nreply",
      "You can do these image acrobatics with the dagger shell too, but I don't have enough experience with it to give you the incantation: https://docs.dagger.io/features/shell/\n \nreply",
      "I assume you can do these \"image acrobatics\" in any shell.\n \nreply",
      "What\u2019s the difference between this and skopeo? Is it the ssh support ? I\u2019m not super familiar with skopeo forgive my ignorancehttps://github.com/containers/skopeo\n \nreply",
      "\"skopeo\" seems to related to managing registeries, very different from this.\n \nreply",
      "Skopeo manages images, copies them and stuff.\n \nreply",
      "As a long ago fan of chef-solo, this is really cool.Currently, I need to use a docker registry for my Kamal deployments. Are you familiar with it and if this removes the 3rd party dependency?\n \nreply"
    ],
    "link": "https://github.com/psviderski/unregistry",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Push docker images directly to remote servers without an external registry\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\u25b8 Push docker images directly to remote servers without an external registry \u25c2\n\n\nUnregistry is a lightweight container image registry that stores and serves images directly from your Docker daemon's\nstorage.The included docker pussh command (extra 's' for SSH) lets you push images straight to remote Docker servers over SSH.\nIt transfers only the missing layers, making it fast and efficient.You've built a Docker image locally. Now you need it on your server. Your options suck:You just want to move an image from A to B. Why is this so hard?That's it. Your image is on the remote server. No registry setup, no subscription, no intermediate st"
  },
  {
    "title": "Fang, the CLI Starter Kit (github.com/charmbracelet)",
    "points": 56,
    "submitter": "bewuethr",
    "submit_time": "2025-06-18T22:40:32 1750286432",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44313901",
    "comments": [
      "I\u2019ve been maintaining rust-starter[!] for quite sometime now. It is kind of the equivalent of fang but for Rust. It uses Clap which is the equivalent of Cobra; though I don\u2019t think Clap has the same kind of fancy output?Throughout these years, I have found that cross-compiling is the most challenging part of creating a CLI. When you are building a web back-end, you control the execution environment (usually linux). For CLIs, your users could be on Linux, macOS or Windows. You need to get three x2 binaries (so a total of 6) to have a fair coverage.I\u2019ve tried cross, but for Windows and macOS you need licenses. There is no straightforward way to give your users Docker images and have them running in a few commands. You can compile on GitHub action machines, but that\u2019s a very slow feedback loop. I wonder if things are better in Go land.!: https://github.com/rust-starter/rust-starter\n \nreply",
      "Golang itself bundles a toolchain and can cross compile to a many target OSes and architectures.  I use Goreleaser [1]  to create GitHub releases, Homebrew packages, Docker images, and Linux packages. Goreleaser Pro can also create MSI packages.ETA since I just saw Christian chime in: the Goreleaser author works at Charm.sh =)[1] https://goreleaser.com\n \nreply",
      "GoReleaser is indeed an awesome tool and we use it for every applicable project.And actually Carlos, who builds GoReleaser, is the true author of Fang and took it from concept to execution.\n \nreply",
      "Wow TIL cross compilation is a bit of a pain in Rust. I assumed it was as easy as Go. I can confirm as long as you're using pure Go (no cgo), it's as easy as setting $GOOS and $GOARCH appropriately.\n \nreply",
      "The difficulty is due to Rust dynamically linking and Go statically linking. The former requires the system libs.That said, I am unfamiliar with any licensing for Windows builds.MacOS has some niche (usually discarded) technicalities like you can only use the SDK on Apple hardware.\n \nreply",
      "This is great, lots I learned by looking at your code and the dependencies you use!I started a similar thing, although not as feature-rich as yours. My goal was to follow CLI best practices and add all the boilerplate one needs to build a Rust CLI.https://github.com/mootoday/cli-template\n \nreply",
      "I feel your pain. That said, cross compiling from Go is pretty trivial, as long as everything is pure Go, which it most often is. That\u2019s one if the reasons we invested in jt.(Hello from Charm! I\u2019m one of the authors of this library.)\n \nreply",
      "I just ran across \"gum\"[1] from charmbracelet which I intend to use! I just want to replace dialog. I came across whiptail, too, but gum seems nicer.They have a TUI framework, too, among a lot of other related things. Some of their projects are Go libraries, some are a CLI tool, such as gum.[1] https://github.com/charmbracelet/gum\n \nreply",
      "Gum looks awesome. Gonna keep it in-mind next time I need to write a shell CLI.\n \nreply",
      "This is awesome! Love the work the charm bracelet team is doing.\n \nreply"
    ],
    "link": "https://github.com/charmbracelet/fang",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The CLI starter kit\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\nThe CLI starter kit. A small, experimental library for batteries-included Cobra applications.\n\nTo use it, invoke fang.Execute passing your root *cobra.Command:That's all there is to it!See contributing.We\u2019d love to hear your thoughts on this project. Feel free to drop us a note!MITPart of Charm.Charm\u70ed\u7231\u5f00\u6e90 \u2022 Charm loves open sourceDefault cobra man pages generates one man page for each command. This is\ngenerally fine for programs with a lot of sub commands, like git, but its an\noverkill for smaller programs.\nMango also uses roff directly instead of converting from markdown, so it\nshould render better looking man pages. \u21a9\n        The CLI starter kit\n       There was an error while loading"
  },
  {
    "title": "Websites Are Tracking You via Browser Fingerprinting (tamu.edu)",
    "points": 107,
    "submitter": "gnabgib",
    "submit_time": "2025-06-18T20:55:06 1750280106",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44313206",
    "comments": [
      "As someone who works in this tech space, nobody brings up how long fingerprints persist. And the reality is that even a really precise fingerprint has a half-life of only a few days (especially if it's based on characteristics like window size or software versions).A lot of the big ad networks right now instead rely heavily on geo-data. Which is why you are probably seeing lots of ads in your feeds that seemingly cross between devices or are relating to interests of your spouse/friends/etc. They just look at the geo on your IP and literally flood the zone.> They developed a measurement framework called FPTrace, which assesses fingerprinting-based user tracking by analyzing how ad systems respond to changes in browser fingerprints.I'm curious to know a bit more about their methodology. It's more likely to me that the ad networks are probably segmenting the ads based on device settings more than they are individually targeting based on fingerprints. For example, someone running new software versions on new hardware might be lumped into a hotter buyer category. Also, simple things like time of day have huge impacts on ad bidding, so knowing how they controlled would be everything.\n \nreply",
      ">As someone who works in this tech space, nobody brings up how long fingerprints persist. And the reality is that even a really precise fingerprint has a half-life of only a few daysI've just looked at my fingerprint and I'm told I'm unique (my mum always said that ;-) ).Unfortunately it's impossible, using https://www.amiunique.org/fingerprint, to determine what elements of the fingerprint, if changed, would make me significantly non-unique but when I look down the list 16/58 javascript attributes are red (the lowest category of similarity ratio) and only two of those are overtly dependent on a version number, another six refer to screen size/resolution. It seems to me that leaves quite a lot of information which isn't going to change all the quickly.While the precise value may change with time I feel like saying \"has a half-life of only a few days\" tends to understate the effectiveness of this technique.\n \nreply",
      "There are a few obvious ones I knew would be bad for me - the Linux user agent, for example. My canvas also came up unique and I'm betting Dark Reader had something to do with that.But then there's other things that don't make any sense. How is \"NVIDIA Corporation\" only 0.74% for \"WebGL Vendor?\" Why does navigator.hardwareConcurrency even exist?\n \nreply",
      "> A lot of the big ad networks right now instead rely heavily on geo-dataHow does this work in today's age where ISPs normally will have at least one level of NATing with ipv4. And given ipv6 with prefix delegation is still far away this should continue to be very imprecise?\n \nreply",
      "> ISPs normally will have at least one level of NATing with ipv4.I don't think that's generally true for home DSL/cable/fiber service.  I've only seen it on mobile internet.\n \nreply",
      "Not sure about US, but Indian ISPs are doing this already to conserve IP space given huge userbase. In theory it would work similar to how a NAT gateway works for outbound communication. Skan + geo would be hard nut to crack in India.\n \nreply",
      "I\u2019ve never had an unroutable IP in the US\n \nreply",
      "Billboards are still among the most effective forms of advertising in terms of efficiency. You don\u2019t need to be very close. I see myself popping up probably 10 miles from where I\u2019m actually at, but the businesses aren\u2019t that inaccessible.\n \nreply",
      "Wouldn\u2019t things like iCloud Private Relay and other VPN-ish things throw a wrench into IP-geo-based tracking? Seems like it\u2019d make the targeting so broad as to be useless.\n \nreply",
      "As an aside, we just spent a couple of weeks camping in our RV with a cellular router connected to a VPN at home. Now that we're back home, Google maps (on a non-GPS equipped device) and Roku still think we're at the campground several states away. I guess my GPS equipped tablet reported the new location of our home IP address. On past experience, it takes about a week to reset.\n \nreply"
    ],
    "link": "https://engineering.tamu.edu/news/2025/06/websites-are-tracking-you-via-browser-fingerprinting.html",
    "first_paragraph": "\nJune 18, 2025\nBy Department of Computer Science and Engineering\nClearing your cookies is not enough to protect your privacy online.\u00a0New research led by Texas A&M University found that websites are covertly using browser fingerprinting \u2014 a method to uniquely identify a web browser \u2014 to track people across browser sessions and sites.\u201cFingerprinting has always been a concern in the privacy community, but until now, we had no hard proof that it was actually being used to track users,\u201d said Dr. Nitesh Saxena, cybersecurity researcher, professor of computer science and engineering and associate director of the Global Cyber Research Institute\u00a0at Texas A&M. \u201cOur work helps close that gap.\u201dWhen you visit a website, your browser shares a surprising amount of information, like your screen resolution, time zone, device model and more. When combined, these details create a \u201cfingerprint\u201d that\u2019s often unique to your browser. Unlike cookies \u2014 which users can delete or block \u2014 fingerprinting is much h"
  },
  {
    "title": "Software in the era of AI [video] (youtube.com)",
    "points": 11,
    "submitter": "sandslash",
    "submit_time": "2025-06-19T00:33:21 1750293201",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44314423",
    "comments": [
      "I think it's interesting to juxtapose traditional coding, neural network weights and prompts because in many areas -- like the example of the self driving module having code being replaced by neural networks tuned to the target dataset representing the domain -- this will be quite useful.However I think it's important to make it clear that given the hardware constraints of many environments the applicability of what's being called software 2.0 and 3.0 will be severely limited.So instead of being replacements, these paradigms are more like extra tools in the tool belt. Code and prompts will live side by side, being used when convenient, but none a panacea.\n \nreply",
      "Thank you YC for posting this before the talk became deprecated[1]1: https://x.com/karpathy/status/1935077692258558443\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=LCEmiRjPEtQ",
    "first_paragraph": ""
  },
  {
    "title": "MCP Specification (modelcontextprotocol.io)",
    "points": 16,
    "submitter": "owebmaster",
    "submit_time": "2025-06-18T23:59:47 1750291187",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44314289",
    "comments": [
      "Fascinated to see that the core spec is written in TypeScript and not, say, an OpenAPI spec or something. I suppose it makes sense, but it\u2019s still surprising to see.\n \nreply",
      "Maybe the Key Changes page would be a better link if we're concerned with a specific version?https://modelcontextprotocol.io/specification/2025-06-18/cha...\n \nreply",
      "Agree, thanks for the link. I was wondering what actually changed. The resource links and elicitation look like useful functionality.\n \nreply",
      "I am just glad that we now have a simple path to authorized MCP servers. Massive shout-out to the MCP community and folks at Anthropic for corralling all the changes here.\n \nreply"
    ],
    "link": "https://modelcontextprotocol.io/specification/2025-06-18",
    "first_paragraph": "Model Context Protocol (MCP) is an open protocol that\nenables seamless integration between LLM applications and external data sources and\ntools. Whether you\u2019re building an AI-powered IDE, enhancing a chat interface, or creating\ncustom AI workflows, MCP provides a standardized way to connect LLMs with the context\nthey need.This specification defines the authoritative protocol requirements, based on the\nTypeScript schema in\nschema.ts.For implementation guides and examples, visit\nmodelcontextprotocol.io.The key words \u201cMUST\u201d, \u201cMUST NOT\u201d, \u201cREQUIRED\u201d, \u201cSHALL\u201d, \u201cSHALL NOT\u201d, \u201cSHOULD\u201d, \u201cSHOULD\nNOT\u201d, \u201cRECOMMENDED\u201d, \u201cNOT RECOMMENDED\u201d, \u201cMAY\u201d, and \u201cOPTIONAL\u201d in this document are to be\ninterpreted as described in BCP 14\n[RFC2119]\n[RFC8174] when, and only when, they\nappear in all capitals, as shown here.MCP provides a standardized way for applications to:The protocol uses JSON-RPC 2.0 messages to establish\ncommunication between:MCP takes some inspiration from the\nLanguage Server Protocol, which\nstand"
  },
  {
    "title": "The Missing 11th of the Month (drhagen.com)",
    "points": 34,
    "submitter": "xk3",
    "submit_time": "2025-06-18T21:45:46 1750283146",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44313550",
    "comments": [
      "Interesting! Be sure to follow the link to the second post about what happened to the 2nd, 3rd, 22nd, and 23rd. It's simpler but still worth the read:https://drhagen.com/blog/the-missing-23rd-of-the-month/\n \nreply",
      "Naming an event after its date will have a limited run.\n \nreply",
      "tl,dr: It's an OCR error\n \nreply",
      "Or, sometimes, not; one of the more interesting takeaways was typewritten lowercase ells instead of ones: \u201cWhen the algorithm read October llth, it was far more correct than we have been giving it credit.\u201d\n \nreply"
    ],
    "link": "https://drhagen.com/blog/the-missing-11th-of-the-month/",
    "first_paragraph": "On November 28th, 2012, Randall Munroe published an xkcd\u00a0comic\u00a0that was\u00a0a calendar in which\u00a0the size of each date was\u00a0proportional to\u00a0how often each date is referenced by its ordinal name\u00a0(e.g. \"October 14th\") in the Google Ngrams database since 2000. Most of the large\u00a0days are pretty much what you would expect:\u00a0July 4th, December 25th, the 1st of every month, the last day of most months, and of course a September 11th that shoves\u00a0its neighbors\u00a0into the margins. There are not many days that seem to be smaller than the typical size. February 29th is a tiny speck, for instance. But if\u00a0you stare at the comic\u00a0long enough, you may get the impression that the 11th of most\u00a0months is unusually small. The title\u00a0text of the comic concurs, reading \"In months other than September, the 11th is mentioned substantially less often than any other date. It's been that way since long before 9/11 and I have no idea why.\" After digging into the raw data, I believe I have figured out why.First I confirmed\u00a0t"
  },
  {
    "title": "Show HN: Workout.cool \u2013 Open-source fitness coaching platform (github.com/snouzy)",
    "points": 556,
    "submitter": "surgomat",
    "submit_time": "2025-06-18T12:33:49 1750250029",
    "num_comments": 171,
    "comments_url": "https://news.ycombinator.com/item?id=44309320",
    "comments": [
      "Oh funny to see it here. I'm the original author of workout.lol.I sold the app to a guy who seemed to just abandoned it. I also texted him multiple times if he needs support, but he didn't answer anymore. It makes me really happy to see it being maintained again!Great work on the UI improvements.\n \nreply",
      "Ohoh ! Vincenius !!You have no idea how happy I was when I saw your name pop up ahahhaYeah, no luck either. It really broke my heart to see the project stall like that.That's what pushed me to rebuild everything, keeping the same open spirit you had from day one.Thanks a lot for the kind words about the UI it means a lot coming from you.And if you ever feel like jumping back in (I totally get that it might be tricky, especially since you sold the original project and this one is so close) but you\u2019d always be welcome.Your input, ideas, or even just your presence would mean a lot !Cheers !\n \nreply",
      "This is SO COOL!!!I\u2019ve been working on an automated calendar scheduling api that integrates with Apple CalDAV (iCal) that lets you schedule your life around goals (it uses Google OrTools to solve a great big CP-SAT constraint model blazing fast, a year in under 5 seconds), along with meal planning around macro goals. I knew I wanted to integrate a workout/training plan system but had no idea what component I\u2019d end up using.Now I know! Thanks for building this project.\n \nreply",
      "Thanks mate.I'd love to hear more about your setup and if Workout.cool can fit as a \"component\" let's say? in your system, that's exactly the kind of use case I built it for. Open, hackable, and easy to plug into more powerful workflows. GG !\n \nreply",
      "So\u2026 someone in the industry bought it hoping to stop a free alternative from getting popular? Wonder what will happen to this one\n \nreply",
      "From what I can see this is AI generated, and it doesn't work when you press continue.\n \nreply",
      "I think the servers can\u2019t handle the high traffic from HN, you can clone the repo and run your own\n \nreply",
      "Yeah, HN hit hard earlier lol, we are now on the 2nd place so things should start calming down now (or no, lol), btw the app is already back up and running normally again!Sorry for that\n \nreply",
      "> I think the servers can\u2019t handle the high traffic from HNIt appears to be hosted on Vercel...\n \nreply",
      "database*\n \nreply"
    ],
    "link": "https://github.com/Snouzy/workout-cool",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        \ud83c\udfcb Modern open-source fitness coaching platform. Create workout plans, track progress, and access a comprehensive exercise database.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA comprehensive fitness coaching platform that allows create workout plans for you, track progress, and access a vast exercise database with\ndetailed instructions and video demonstrations.This project was born from a personal mission to revive and improve upon a previous fitness platform. As the primary contributor to the\noriginal workout.lol project, I witnessed its journey and abandonment. \ud83e\udd79Someone had to step up.The opensource fitness community de"
  },
  {
    "title": "The unreasonable effectiveness of fuzzing for porting programs (rjp.io)",
    "points": 179,
    "submitter": "Bogdanp",
    "submit_time": "2025-06-18T16:26:35 1750263995",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=44311241",
    "comments": [
      "Interesting!  But there\u2019s a gap between aspirations and what was accomplished here.Early on in the blog post, the author mentions that \"c2rust can produce a mechanical translation of C code to Rust, though the result is intentionally 'C in Rust syntax'\".  The flow of the post seems to suggest that LLMs can do better.  But later on, they say that their final LLM approach produces Rust code which \u201cis very 'C-like'\" because \"we use the same unsafe C interface for each symbol we port\u201d.  Which sounds like they achieved roughly the same result as c2rust, but with a slower and less reliable process.It\u2019s true that, as the author says, \u201cbecause our end result has end-to-end fuzz tests and tests for every symbol, its now much easier to 'rustify' the code with confidence\".  But it would have been possible to use c2rust for the actual port, and separately use an LLM to write fuzz tests.I'm not criticizing the approach.  There's clearly a lot of promise in LLM-based code porting.  I took a look at the earlier, non-fuzz-based Claude port mentioned in the post, and it reads like idiomatic Rust code.  It would be a perfect proof of concept, if only it weren't (according to the author) subtly buggy.  Perhaps there's a way to use fuzzing to remove the bugs while keeping the benefits compared to mechanical translation.  Unfortunately, the author's specific approach to fuzzing seems to have removed both the bugs and the benefits.  Still, it's a good base for future work to build on.\n \nreply",
      "It's in between. It's more C like than the Claude port, but it's more Rust-y than c2rust. How much depends on how fine-grained you want to make your port and how you want to prompt your LLM. For inside of functions and internal symbols, the LLM is free to use more idiomatic construction and structures. But since the goal was to test the effectiveness of the fuzz testing, using the LLM to do the symbol translation is more of an implementation detail.You could certainly try using c2rust to do the initial translation, and it's a reasonable idea, but I didn't find the LLMs really struggled with this part of the task, and there's certainly more flexibility this way. c2rust seemed to choke on some simple functions as well, so I didn't pursue it further.And of course for external symbols, you're constrained by the C API, so how much leeway you have depends on the project.You can also imagine having the LLM produce more idiomatic code from the beginning, but that can be hard to square with the incremental symbol-by-symbol translation.\n \nreply",
      "> Most code doesn't express subtle logic paths. If I test if a million inputs are correctly sorted, I've probably implemented the sorter correctly.I don't know if this was referring to Zopfli's sorter or sorting in general, but I have heard of a subtle sorting bug in Timsort: https://web.archive.org/web/20150316113638/http://envisage-p...\n \nreply",
      "Thanks for sharing, I did not know about that!Indeed, this is exactly the type of subtle case you'd worry about when porting. Fuzzing would be unlikely to discover a bug that only occurs on giant inputs or needs a special configuration of lists.In practice I think it works out okay because most of the time the LLM has written correct code, and when it doesn't it's introduced a dumb bug that's quickly fixed.Of course, if the LLM introduces subtle bugs, that's even harder to deal with...\n \nreply",
      "> most of the time the LLM has written correct code [...dumb bugs]What domain do you work in?I hope I'm just misusing the tool, but I don't think so (math+ML+AI background, able to make LLMs perform in other domains, able to make LLMs sing and dance for certain coding tasks, have seen other people struggle in the same ways I do trying to use LLMs for most coding tasks, haven't seen evidence of anyone doing better yet). On almost any problem where I'd be faster letting an LLM attempt it rather than just banging out a solution myself, it only comes close to being correct with intensive, lengthy prompting -- after much more effort than just typing the right thing in the first place. When it's wrong, the bugs often take more work to spot than to just write the right thing since you have to carefully scrutinize each line anyway while simultaneously reverse engineering the rationale for each decision (the API is structured and named such that you expect pagination to be handled automatically, but that's actually an additional requirement the caller must handle, leading to incomplete reads which look correct in prod ... till they aren't; when moving code from point A to point B it removes a critical safety check but the git diff is next to useless and you have to hand-review that sort of tedium and have to actually analyze every line instead of trusting the author when they say that a certain passage is a copy-paste job; it can't automatically pick up on the local style (even when explicitly prompted as to that style's purpose) and requires a hand-curated set of examples to figure out what a given comptime template should actually be doing, violating all sorts of invariants in the generated code, like running blocking syscalls inside an event loop implementation but using APIs which make doing so _look_ innocuous).I've shipped a lot of (curated, modified) LLM code to prod, but I haven't yet seen a single model or wrapper around such models capable of generating nearly-correct code \"most\" of the time.I don't doubt that's what you've actually observed though, so I'm passionately curious where the disconnect lies.\n \nreply",
      "> Fuzzing would be unlikely to discover a bug that only occurs on giant inputs or needs a special configuration of lists.I have a concern about peoples' over confidence in fuzz testing.It's a great tool, sure, but all it is is something that selects (and tries) inputs at random from the set of all possible inputs that can be generated for the API.For a strongly typed system that means randomly selecting ints from all the possible ints for an API that only accepts ints.If the API accepts any group of bytes possible, fuzz testing is going to randomly generate groups of bytes to try.The only advantage this has over other forms of testing is that it's not constrained by people thinking \"Oh these are the likely inputs to deal with\"\n \nreply",
      "This is not quite true, what you are describing is \"dumb\" fuzzing. Modern fuzzers are coverage guided and will  search for and devote more effort to inputs which trigger new branches / paths.https://afl-1.readthedocs.io/en/latest/about_afl.htmlBut yeah in general path coverage is hard and fuzzing works better if you have a comprehensive corpus of test inputs.\n \nreply",
      "There are 2 main problems in generative testing:- Input data generation (how do you explore enough of the program's behavior to have confidence that you're test is a good proxy for total correctness)- Correctness statements (how do you express whether or not the program is correct for an arbitrary input)When you are porting a program, you have a built in correctness statement: The port should behave exactly as the source program does. This greatly simplifies the testing process.\n \nreply",
      "Several times I've been involved in porting code. Eventually we reach a time where we are getting a lot of bug reports \"didn't work, didn't work with the old system as well\"  which is to say we ported correctly, but the old system wasn't right either and we just hadn't tested it in that situation until the new system had the budget for exhaustive testing.  (normally it worked at one point on the old system and got broke in some other update)\n \nreply",
      "I find it amazing, that the same ideas pop up in the same period of time. For example, I work on tests generation and I went the same path. I tried to find bugs by prompting \"Find bugs in this code and implement tests to show it.\", but this didn't get me far. Then I switched to property (invariant) testing, like you, but in my case I ask AI: \"Based on the whole codebase, make the property tests.\" and then I fuzz some random actions on the state-full objects and run prop tests over and over again.At first I also wanted to automate everything, but over time I realized that best is: 10% human to 90% AI of work.Another idea I'm exploring is AI + Mutation Tests (https://en.wikipedia.org/wiki/Mutation_testing). It should help AI with generation of full coverage.\n \nreply"
    ],
    "link": "https://rjp.io/blog/2025-06-17-unreasonable-effectiveness-of-fuzzing",
    "first_paragraph": ""
  },
  {
    "title": "My iPhone 8 Refuses to Die: Now It's a Solar-Powered Vision OCR Server (terminalbytes.com)",
    "points": 209,
    "submitter": "hemant6488",
    "submit_time": "2025-06-18T15:49:53 1750261793",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=44310944",
    "comments": [
      ">I\u2019m saving approximately $84-120 CAD annually.I suppose most of this is eaten up by the need to pay apple $99 per year just to run your own app on your own phone for longer than a week.\n \nreply",
      "This Apple fee is one of the most absurd things they do. Like, how is it even justified\u2014does Apple really spend $99 on infra maintenance and server costs to host your app?When I buy a device I want to know that I own it, but Apple keeps pushing the narrative that \"we LET you use this device in ways we see fit\". So basically the customer is just borrowing a device from Apple while paying the full price.I'm a longtime Apple user but can't shake off this love-hate relationship with the company.\n \nreply",
      "I think it's fair to also cover the fairly rigorous testing that occurs for each app store submission. I'm not sure a hundred bucks is the right number, but it's not fair to say all they do is host the file.\n \nreply",
      "> I think it's fair to also cover the fairly rigorous testing that occurs for each app store submission.By \"fairly rigorous\", do you mean \"fickle, random\"?\n \nreply",
      "You have to pay $99/year even if you only want to use the app on your own device.You can only sideload for free if you are willing to reinstall every X days.They don't need to test an app if you're not asking them to distribute it through their store.\n \nreply",
      "What\u2019s worse is it used to be 90 days. Apple changed it to 7 days years ago.\n \nreply",
      "90 days is still absurd. I have custom apps I install on my Android phones once per phone. I go years without bothering to rebuild them.\n \nreply",
      "\"fair\" would be letting me sideload if I didn't want to go through Apple's vetting. Their expensive review process is only required because they decide it's arbitrarily necessary and unavoidable.\n \nreply",
      "i\u2019d guess it\u2019s more to keep extremely low effort submissions out of the app store.\n \nreply",
      "Which is not unreasonable for something listed in the App Store. It is unreasonable that you can\u2019t sideload though.\n \nreply"
    ],
    "link": "https://terminalbytes.com/iphone-8-solar-powered-vision-ocr-server/",
    "first_paragraph": ""
  },
  {
    "title": "Bento: A Steam Deck in a Keyboard (github.com/lunchbox-computer)",
    "points": 53,
    "submitter": "MichaelThatsIt",
    "submit_time": "2025-06-18T21:21:26 1750281686",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=44313379",
    "comments": [
      "> Primarily out of frustration. The dominant players in XR keep promoting their hardware as \u201ccomputers\u201d, when really they\u2019re an iPad for your face. The most you can do is browse the web, play games, and consume content. They\u2019re overweight and over constrained.I'm a fan of HMD programming in general so I love this project. But it should be noted that AOSP-based XR headsets can run pseudo Linux environments via termux + X: https://www.reddit.com/r/cyberDeck/comments/fc5sfr/oculus_qu...Also if anyone is looking for a full-sized portable keyboard, I suggest https://www.protoarc.com/products/xk01-tri-fold-bluetooth-ke... which is my primary keyboard when I'm working remotely on my tablet. It is \"pocket-sized\" for certain definitions of \"pocket\".\n \nreply",
      "That's really cool. I don't think you should support another keyboard, there may be better ones from a certain POV but I don't think there's a better one that's not significantly thicker and any keyboard options will quickly multiply complexity with any SBC/computing options. You will go down a rabbit hole if you start taking requests here. I think steamdeck internals plus rpi5 plus latest framework internals with no other configs is ambitious but not too ambitious.My hobby is miniaturizing everything. If I were to fork this project (and I would love to after about 10 other projects are complete), I would think about selecting one good dongle, \"shucking\" it any other needed things, integrating them, and then finding the minimum volume to fit my preferred travel controller[1] and preferred travel mouse[2]. Then, I would consider customizing the housings of those things to be even slimmer without customizing any electronics except for maybe making sure everything gets charged while stowed. I would also consider minor mods to the keyboard to get rid of the bulk of the usbc cable. Pogo pins plus some 3D printing should do the trick.[1]https://www.youtube.com/watch?v=55DO1HDeCHQ. No longer available new but this is the only good slim dual analog controller I have found.[2]Still looking for a good one\n \nreply",
      "This is a project that had been eating away at me for a bit, sitting in the back of my mind.It's a computer that fit's perfectly underneath an Apple Magic Keyboard, and has a compartment to store peripherals like a dongle or small mouse. It has no display, instead opting for XR display glasses.The internals are the main board, cooler, and battery from a Steam Deck OLED. I bought the parts separately rather than gutting a perfectly good one.The link is to the CAD files. I decided to open source it as I explore building a better one.Feel free to jump straight to that, here's the origin story for anyone interested:I started using the XREAL glasses a few months ago. they're great, easily my favorite \"XR\" product. It's built around the one killer app of XR, a virtual display. shedding all non-essential hardware into a small, lightweight package.but I hate the redundancy. Whatever device I'm using it with, the built in screen goes unused. In parallel, I've also found myself extremely disappointed in each product calling itself a \"spatial computer\" despite being nothing but an overweight iPad for your face.I wanted a real computer designed to be used with these glasses, and in the smallest package I could possibly achieve.So I grabbed an actual iPad, downloaded Shapr3D and got to work. My iteration process involved jumping back and forth between my iPad and a 3D printer. I went through roughly 15 failed iterations getting the screw mounts, airflow, and ergonomics just right.The final result is what I believe to be a true spatial computer. I've been daily driving and I'm pretty happy with the experience. It's currently running Ubuntu 24, but I may switch back to Steam OS, given it's better optimized for the hardware.\n \nreply",
      "Thank you very much for sharing the files and your experience! \nI just got my first XR glasses, Xreal One Pro, and had your link bookmarked to do something similar. I am very impressed with these glasses. \nLooking through ifixit I can't find the Steam Deck's mainboard. Where did you find it?\n \nreply",
      "Ebay! But fear not! I\u2019m working on a version based on the Radxa Rock 5B which is more readily available and has more kick than a pi 5.Also doing the research on productizing the whole thing and sourcing a custom board.\n \nreply",
      "I see. Need to check Ebay then.I am interested in a productized version - but only with x64 boards like the Steam Deck or one of the Framework mainboards. I don't want to deal with 3D printing and all that. The latter are larger than the Steam Deck, though. No battery for me though: I would use it after work, when I am near an outlet anyway.\n \nreply",
      "This project mentions a Framework-based version as a future idea. A similar Framework 13 build popped up in r/framework a few months ago:- https://www.reddit.com/r/framework/comments/1jo7m8c/framewor...Updated with a new mainboard from the Ryzen AI line:- https://www.reddit.com/r/cyberDeck/comments/1kjknh4/vrxr_cyb...GitHub repo with STLs and build details, with it running Linux and Stardust XR with non-spatial inputs on XREAL glasses:- https://github.com/Pyro57000/fyer_deck\n \nreply",
      "Ay love it. There\u2019s quite a few similar ideas on r/cyberdeck. I just wasn\u2019t satisfied with their look. I wanted something very clean. Something that blends in and could theoretically be used on a plane without drawing too much attention, but still nice to look at.That guy commented in the Reddit thread I posted and I\u2019m hoping to collab with him on the framework version if he\u2019s down.\n \nreply",
      "very cool projectnot long ago there was a post by a user also using glasses -- 85% sure they're the same ones -- but the goal was to replace a laptop display a fuller size one. I like that this project replaces the laptop with a SBC. I spent a decade and a half wishing that SBC would be a Raspberry Pi but ... welp, better late than never\n \nreply",
      "You and me both, buddy. Instead I\u2019m calling up SoM companies and seeing what they can build me for cheap.\n \nreply"
    ],
    "link": "https://github.com/lunchbox-computer/bento",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        a computer in a keyboard\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Bento is a computer. Its name come from it's distinctly bento box look, and it takes inspiration from the Comodore 64, and the many creations on r/cyberdeck.It fit perfectly underneath a keyboard, which acts as a lid! Giving you easy access to the internals, as well as a compartment to store various small peripherals.This is key. Bento is meant to be used with an external display, particularly spatial displays like the XREAL One\u2019s, but obviously it still works with any external monitor with USB-C.The reason for this is to eliminate redundancy. As I find myself using XREAL more and more, the built in display for my laptop or my steam deck goes unused and is simply added weight. Bento rem"
  },
  {
    "title": "Writing documentation for AI: best practices (kapa.ai)",
    "points": 142,
    "submitter": "mooreds",
    "submit_time": "2025-06-18T16:23:46 1750263826",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=44311217",
    "comments": [
      "OP here. It's kind of ironic that making the docs AI-friendly essentially just ends up being what good documentation is in the first place (explicit context and hierarchy, self-contained sections, precise error messages).\n \nreply",
      "It's the same for SEO also. Good structure, correct use of HTML elements, quick loading, good accessibility, etc. Sure, there are \"tricks\" to improve your SEO, but the general principles are also good if you were not doing SEO.\n \nreply",
      "From a docs-writing perspective, I've noticed that LLMs in their current state mostly solve the struggle of finding users who both want to participate in studies, are mostly literate, and are also fundamentally incompetent\n \nreply",
      "It's similar for writing code. Suddenly people are articulating their problems to the LLM and breaking it down in smaller sub-problems to solve....\n \nreply",
      "In other words, people are discovering the value of standard software engineering practices. Which, I think is a good thing.\n \nreply",
      "It has changed how I structure my code. Out of laziness, if I can write the code in such a way that each step follows naturally from what came before, \"the code just writes itself!\" Except now it's literally true :D\n \nreply",
      "Maybe everyone already discovered this but I find that if I include a lot of detail in my variables names, it's much more likely to autocomplete something useful.  If whatever I typed was too verbose for my liking long term, I can always clean it up later with a rename.\n \nreply",
      "Related: \"If an AI agent can't figure out how your API works, neither can your users\" (from my employer's blog)https://stytch.com/blog/if-an-ai-agent-cant-figure-out-how-y...\n \nreply",
      "Yeah, I've started to think AI smoke tests for cognitive complexity should be a fundamental part of API/schema design now. Even if you think the LLMs are dumb, Stupidity as a Service is genuinely useful.\n \nreply",
      "Thank you for sharing this, it's really helpful to have this as top-down learning resource.I'm in the process of learning how to work with AI, and I've been homebrewing something similar with local semantic search for technical content (embedding models via Ollama, ChromaDB for indexing). I'm currently stuck at the step of making unstructured knowledge queryable, so these docs will come in handy for sure. Thanks again!\n \nreply"
    ],
    "link": "https://docs.kapa.ai/improving/writing-best-practices",
    "first_paragraph": "Retrieval-Augmented Generation (RAG) systems like Kapa rely on your\ndocumentation to provide accurate, helpful information. When documentation\nserves both humans and machines well, it creates a self-reinforcing loop of\ncontent quality: clear documentation improves AI answers, and those answers\nhelp surface gaps that further improve the docs.This guide provides best practices for creating documentation that works\neffectively for both human readers and AI/LLM consumption in RAG systems. Many\nbest practices benefit both simultaneously, often in complementary ways.Documentation quality has always been important for helping users understand\nand use your product effectively. And it becomes even more important when AI\nsystems use that same content to answer user questions. Poor documentation\ndoesn't just frustrate human readers, it directly degrades the quality of AI\nresponses, creating a compounding problem where bad content leads to bad\nanswers.Understanding how AI systems process and use y"
  },
  {
    "title": "Poline \u2013 An enigmatic color palette generator using polar coordinates (meodai.github.io)",
    "points": 202,
    "submitter": "zdw",
    "submit_time": "2025-06-14T23:38:56 1749944336",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=44279569",
    "comments": [
      "To those not into the mythical vibe: I totally get it. I stumbled onto something that looked good by accident and thought it\u2019d be fun to lean into the mystical theme \u2014 especially since there\u2019s no real science or theory behind it (that I know of). Mostly, I just wanted an excuse to build a fun website around it.And to everyone else \u2014 thanks for the kind words, really appreciate it!\n \nreply",
      "> especially since there\u2019s no real science or theory behind it (that I know of).The literature on hue harmony is fuzzy, but there are a few gems.Check out Matsuda [1] who tracked the colors of what his female students were wearing, and tried to identify any principles informing their color choice. My criticism of him is that he plotted hue distribution on the RGB color wheel. The RYB wheel would have been a far better choice. His paper is in Japanese, but is summarized in multiple places. Below [2] is a link to 2 pages from a lecture I gave which summarizes his findings.I'm sure you also know of Kuehni's classic tome on color spaces [3]. A fun and informative read.There has been no research on hue antagonism (which is the idea that underpins complementary pairs). This is crazy, as it would be a very easy subject to investigate. To me it is obvious that there is a special relationship between antagonistic pairs above the fact that they mix to neutral. Supporting this is the fact that Leondro DaVinci documented this relationship even before hue circle was invented [4]!As for the mystical dimension of color harmony... this has been assumed since the dawn of color science. Newton himself believed that there was seven colors in his hue circle for no other reason than this was a spiritually significant value [5]. Itten [6], Goethe [7] and Kandinsky [8] all absolutely believed in the spiritual dimension of color. Personally, I believe that their work has had nothing but a destructive impact on how artists and designers use color. It is wildly inconsistent, vague and often plain wrong.[1] Matsuda: Color Design. Asakura Shoten (in Japanese). (1995)[2] https://www.dropbox.com/scl/fi/4ac93etjyg0z5y2ouq5ge/matsuda...[3] Kuehni, R.: Color Space and its Divisions: Color Order from Antiquity to the Present. Wiley-Interscience, Hoboken (2003)[4] Leonardo da Vinci, Trans. J. F. Rigaud, A Treatise on Painting (London: J.B. Nichols & Son, 1835).[5] Matt Chamings \u201cWhy are there seven colours in a rainbow?\u201d New Scientist, Last Word, 2021.[6] Johannes Itten, The Art of Color: The Subjective Experience and Objective Rationale of Color (New York: Reinhold Publishing Corporation, 1961).[7] J. W. v. Goethe, Goethe's Colour Theory, Trans. C. L. Eastlake (London: John Murray, 1840).[8] Wassily Kandinsky, Trans. Michael Sadler, Concerning the spiritual in art (Penguin UK, 2024), p. 59.\n \nreply",
      "I love the \"old internet\" vibe with the new internet look. I think it's a very creative idea, I wouldn't mind the haters too too much. I love it!\n \nreply",
      ">\"poline\" is an enigmatic color palette generator, that harnesses the mystical witchcraft of polar coordinates. Its methodology, defying conventional color science, is steeped in the esoteric knowledge of the early 20th century. This magical technology defies explanation, drawing lines between anchors to produce visually striking and otherworldly palettes. It is an indispensable tool for the modern generative sorcerer, and a delight for the eyeI'm not totally sure I understand this intro - what's different here compared to normal color science palette makers?I do like the visual presentation and animation a lot though.\n \nreply",
      "What don't you understand? It defies conventional color science and is steeped in the esoteric knowledge of the early 20th century.It is a very nice palette generator, but I really dislike all the talk of magic/mysticism/sorcery/witchcraft. It's a dang color generator, ease up on the dungeon master language.\n \nreply",
      "on the other hand, i like the \"theme\" - i'm a sucker for that mix of \"wizardry\" metaphor with programming stuff.I'm reminded for instance of this fun little post:https://aphyr.com/posts/341-hexing-the-technical-interview\n \nreply",
      "It feels a little bit ai generated there, or maybe just padded out marketing copy - more adjectives and superlatives than I'd expect from a technical site at least. Telling you how to call it to get a \"mesmerizing\" palette for exampleI can handle some purple mysticism prose but I did want like a comparison of a few palettes from this polar system vs some traditional plane ones. If the creator reads this thread that's my note\n \nreply",
      "It defies explanation. This is followed up by an explantation.\n \nreply",
      "Defied unsuccessfully.\n \nreply",
      "It feels a bit satirical or otherwise done for fun, especially with sections like the following.\"And thus, the tome of \"poline\" has been written. Its mystical powers, steeped in the arcane knowledge of the ancients, now reside within these pages. May this compendium serve you in your quest for the ultimate color palette.\"Either way, I wasn't expecting to encounter Poe's law inside a color palette maker.\n \nreply"
    ],
    "link": "https://meodai.github.io/poline/",
    "first_paragraph": "\n            \"poline\" is an enigmatic color palette generator, that harnesses the mystical witchcraft of polar coordinates. Its\n            methodology, defying conventional color science, is steeped in the esoteric knowledge of the early 20th century. This\n            magical technology defies explanation, drawing lines between anchors to produce visually striking and otherworldly\n            palettes. It is an indispensable tool for the modern generative sorcerer, and a delight for the eye.\n          \n            The tome of \"Poline\" documentation is a comprehensive guide to the arcane arts of color generation, \n            you will gain an understanding of how this tool creates its mystical and captivating palettes through the following sections.\n          \n            The name \"Poline\" /\u02c8p\u0254\u02d0la\u026an/ represents the essence of the library - a polar line. \n            The combination of these two words symbolizes the process of creating a palette by drawing lines between anchor points. \n"
  },
  {
    "title": "DropZap World \u2013 my falling block game with lasers, released after years of work (apps.apple.com)",
    "points": 19,
    "submitter": "amichail",
    "submit_time": "2025-06-16T11:10:04 1750072204",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=44288450",
    "comments": [
      "Looks cool.  I wish there was an explainer video, I was not clear how I beat the first level and I didn't realize there was a move limit until I ran out on level two.  If all the numbers at the top had labels, it would help.Also would be cool if there were sounds.  I don't know if that's just because I am playing on my Mac, but it feels like something is missing with all these lasers firing and blocks being destroyed that there is no audio.\n \nreply",
      "Congrats! Did you document the development at all?\n \nreply",
      "The development involved a lot of experimentation with the game mechanics. It felt like research at times.\n \nreply",
      "Fun and new. I both like and don\u2019t like that I don\u2019t know which actions are going to be effective. Strategy..\n \nreply",
      "Congratulations on the release!  Took me a minute to figure out it shows you which color laser you are going to get next.  Only passed one level so guessing more to learn with 120 levels.  Thanks for sharing.\n \nreply",
      "DropZap! Blast from the past, congrats on the new release. Not available in Europe though.\n \nreply",
      "I'm in Europe, the game does not seem to be available here.\n \nreply",
      "You think you have it bad?I'm in Europe, on Android, had to walk uphill both ways to get here, running Firefox nightly from two weeks into the future, and eight foot deep in snow, barely staying warm by the light of the flamewars.\n \nreply"
    ],
    "link": "https://apps.apple.com/us/app/dropzap-world/id1072858930",
    "first_paragraph": "DropZap World \u2014 a falling block game with lasers, mirrors, splitters, color matching, and 120 levels!Experience the thrill of lasers, mirrors, and color-matching in DropZap World \u2014 a fresh twist on falling block games with 120 electrifying levels!Developed by the original creator of DropZap and DropZap 2, DropZap World stands on its own with unique gameplay and a level-based progression system that will captivate both new players and longtime fans.FEATURES- 120 Challenging Levels: Test your skills across a wide array of levels designed to entertain and engage.- Cross-Platform Availability: Enjoy seamless gameplay on iOS, iPadOS, tvOS, and macOS.- iCloud Sync: Seamlessly save and sync your progress across supported Apple devices.GAMEPLAY- When a circle lands, it fires lasers of its color in eight directions.- These lasers damage or destroy objects of the same color.    - You pass a level when you destroy all the squares.- Of course, there\u2019s more to it than that \u2014 as you\u2019ll see when you "
  },
  {
    "title": "Homomorphically Encrypting CRDTs (jakelazaroff.com)",
    "points": 189,
    "submitter": "jakelazaroff",
    "submit_time": "2025-06-18T12:59:58 1750251598",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=44309520",
    "comments": [
      "For the uninitiated:\"In the context of encryption, 'homomorphic' describes methods that enable computations on encrypted data without needing to decrypt it first.\n \nreply",
      "As the article mentions, fully homomorphic encryption is insanely slow and inefficient. But I have to say that it is a relatively new field (the first FHE scheme was discovered in 2009), and that the field has immensely progressed over the last decade and a half.The first FHE scheme required keys of several TB/PB, bootstrapping (an operation that is pivotal in FHE schemes, when too many multiplications are computed) would take thousands of hours. We are now down to keys of \"only\" 30 MB, and bootstrapping in less than 0.1 second.Hopefully progress will continue and FHE will become more practical.\n \nreply",
      "The first CRDTs have been remarkably impractical, e.g. WOOT[0]. These days, state-of-the-art CRDT databases are not much different from your regular LSM performance-wise. For example, RDX CRDTs[1,2] are all implemented by a merge-sort-like algorithm, pure O(N). Metadata overheads have been tamed in most implementations.[0]: https://github.com/el10savio/woot-crdt[1]: https://github.com/gritzko/librdx[2]: https://github.com/gritzko/go-rdx\n \nreply",
      "Should students trust and run FHE encrypted WASM or JS grading code that contains the answers on their own Chromebooks; for example with JupyterLite and ottergrader?On code signing and the SETI@home screensaver\n \nreply",
      "CRDTs are also crazy slow due to their architecture ; even the best alg out there are costly by design ; so adding homomorphic encryption is even more of a challenge ; tough it really is impressing I'm curious if this can be usable at all;edit so i bring some \"proof\" of my claim: from this very page : `To calculate the new map, the server must go through and merge every single key. After that, it needs to transfer the full map to each peer \u2014 because remember, as far as it knows, the entire map is different.`\n \nreply",
      "CRDTs are not inherently \u201ccrazy slow\u201d. Researchers just don\u2019t succumb to the appeal of premature optimization.See: https://josephg.com/blog/crdts-go-brrr/(And even these optimizations are nascent. It can still get so much better.)The section you quoted describes an effect of homomorphic encryption alone.There is the problem that both CRDTs and encryption add some overhead, and the overhead is additive when use together. But I can\u2019t tell if that is the point you are trying to make.\n \nreply",
      "Yep. Author here - that article is out of date now. I should really do a followup. Performance of CRDTs has improved again through a new grab bag of tricks. I\u2019ve also been told the beta of automerge 3 uses a lot of the optimisations in that post, and it\u2019s now much faster as a result.A crdt library should be able to handle millions of changes per second. If it\u2019s the bottleneck, something somewhere has gone wrong.\n \nreply",
      "The article was a great read, many thanks! Looking forward to the next!\n \nreply",
      "> additiveThe overhead is usually multiplicative per-item. Let's say you're doing N things. CRDTs make that O(Nk) for some scaling factor k, and adding encryption makes it O(Nkj) for some scaling factor j.Give or take some multiplicative log (or worse) factors depending on the implementation.\n \nreply",
      "> CRDTs are also crazy slow due to their architecture ;You must back up your extraordinary claim with some extraordinary evidence. There is nothing inherently slow in CRDTs.Also, applying changes is hardly on anyone's hot path.The only instance where I saw anyone complaining about CRDT performance, it turned out to be from very naive implementations that tried to spam changes with overly chatty implementations. If you come up with any code that requires a full HTTPS connection to send a single character down the wire, the problem is not the algorithm.\n \nreply"
    ],
    "link": "https://jakelazaroff.com/words/homomorphically-encrypted-crdts/",
    "first_paragraph": ""
  },
  {
    "title": "Introduction to the A* Algorithm (2014) (redblobgames.com)",
    "points": 250,
    "submitter": "auraham",
    "submit_time": "2025-06-17T07:25:23 1750145123",
    "num_comments": 93,
    "comments_url": "https://news.ycombinator.com/item?id=44296523",
    "comments": [
      "The article doesn't explicitly state it in this manner in one concise place, but the way I would always think about A* from a \"practical/easy-to-remember\" perspective back when I was doing competitive programming is that they're all the same algorithm, but with different priorities on the priority queue:Breadth-first Search: Priority is order of discovery of edges (that is, no priority queue/just a regular queue)Dijkstra: Priority is distance so far + next edge distanceA*: Priority is distance so far + next edge distance + estimate of distance to target node.This also helps me remember whether the estimate must over- or under-estimate: Since Dijkstra is making the estimate \"0\", clearly the \"admissible heuristic\" criteria must be an under-estimation.\n \nreply",
      "Another way I like to think about it is that every graph traversal can be represented as a white set of unknown nodes, a grey set of known but unvisited nodes, and a black set of visited nodes.  The data structure used to represent the grey set defines the algorithm:DFS = queueBFS = stackDijstra's = priority queue keyed by edge weightA* = priority queue with heuristic functionBeam search = bounded priority queue with heuristic functionTopological sort = priority queue keyed by number of unvisited inbound edgesCopying garbage collector = pointer addressMark & sweep garbage collector = dirty bit on the object pointed toGenerational garbage collector = multi-level grey set represented by the write barriers between each generation.\n \nreply",
      "This is very insightful and a handy mental model I'll be using thanks. A small nit is that I think you have DFS and BFS swapped?\n \nreply",
      "Oh yeah, I do.  Too late to edit the post now.\n \nreply",
      "A* = priority queue with heuristic function _with specific properties_ ... in particular it must be an \"admissible\" hueristic that never overestimates the true value.\n \nreply",
      "It'll still find a path with an inadmissible heuristic, as the page explains.  It's just not guaranteed to be the shortest path in that case.  This is commonly done.\n \nreply",
      "Breadth-first is a queue.\nDepth-first is a stack.\nA* is a priority queue.\n \nreply",
      "More specifically Dijkstra's is a priority queue. A* is a priority queue with an added estimate to the cost function to prioritize searching nodes closer to the destination.\n \nreply",
      "OP's point is that\u00b7 BFS is priority queue with key h(n) + g(n), where h(n) = 0, g(n) = #edges\u00b7 Dijkstra's is priority queue with key h(n) + g(n), where h(n) = 0, g(n) = sum over edges\u00b7 A* is priority queue with key h(n) + g(n), where h(n) = heuristic(n), g(n) = sum over edgesIt's cute.\n \nreply",
      "Likewise, you can represent a queue as a priority queue with key = i, where i is an integer monotonically increasing at insertion time.  And you can represent a stack as a priority queue where key = -i.This is the insight behind the decorate-sort-undecorate pattern; it's just heapsort, with a different key function allowing you to represent several different algorithms.\n \nreply"
    ],
    "link": "https://www.redblobgames.com/pathfinding/a-star/introduction.html",
    "first_paragraph": "Graph search algorithms let us find the shortest path on a map represented as a graph. Move the blob  (start point) and cross  (end point) to see the shortest path found by the A* Algorithm:A* is one of a family of related graph search algorithms:In addition to finding a shortest path, these algorithms can be used for distance maps, flow field pathfinding, connected components, map analysis, garbage collection algorithms, flow networks, and procedural map generation. There are many optimizations and specializations of these algorithms.The first thing to do when studying an algorithm is to understand the data. What is the input? What is the output?Input: Graph search algorithms, including A*, take a \u201cgraph\u201d as input. A graph is a set of locations (\u201cnodes\u201d) and the connections (\u201cedges\u201d) between them. Here\u2019s the graph I gave to A*:A* doesn\u2019t see anything else. It only sees the graph. It doesn\u2019t know whether something is indoors or outdoors, or if it\u2019s a room or a doorway, or how big an ar"
  },
  {
    "title": "Terpstra Keyboard (terpstrakeyboard.com)",
    "points": 216,
    "submitter": "xeonmc",
    "submit_time": "2025-06-18T10:31:44 1750242704",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=44308558",
    "comments": [
      "For those who haven't ever gotten into microtonal and other non-standard tuned music before, it's a really interesting space. I would highly recommend checking out Kyle Gann's album Hyperchromatica (https://www.youtube.com/watch?v=gbT9oRbu3h8&list=PL1IsImnKxK...), which has a pretty wide variety of pieces/genres, showing the potential of nonstandard tuning. It takes a bit to get used to it but there are brand new colours and emotions that open up here IMO. Definitely worth checking out!\n \nreply",
      "Technically Bach was writing for microtonal music - his well tempered clavier was written to show how songs need to be played in the correct keys to sound right. He was against the systems of the day where some keys could not be used, but his preferred system had each key usable but sounding different. Playing them on a modern equal tempered instrument fails to capture what he was trying to show.\n \nreply",
      "Zheanna Erose\u2019s channel is a goldmine of microtonal music and discussion thereof.https://youtube.com/@zheannaerose\n \nreply",
      "Highly recommend King Gizzard and the Lizard Wizard for microtonal music too!For example: https://kinggizzard.bandcamp.com/album/flying-microtonal-ban...\n \nreply",
      "To add yet another example for those looking to try out microtonal music, Sevish's track Gleam[1] is upbeat/poppy and surprisingly palatable. It explores the crunchy textures of microtonal while resolving to familiar pop cadences and helped bridge the gap for me to start enjoying the spectrum of microtonal harmony.[1]: https://www.youtube.com/watch?v=l9wINwlgxRU\n \nreply",
      "My favorite variant: https://novayashkola.org/janko/ , https://en.wikipedia.org/wiki/Jank%C3%B3_keyboard , https://en.wikipedia.org/wiki/Isomorphic_keyboardSince a year ago, I found that I can play songs by ear on the Janko keyboard far more easily than on standard piano keyboards.More resources: https://github.com/wcgbg/terpstrakeyboard/ , https://www.youtube.com/results?search_query=janko%20keyboar...\n \nreply",
      "This is cool!I want to try to build a hardware midi keyboard using mechanical hall effect switches like this: https://mechanicalkeyboards.com/products/wuque-studio-dash-5...There's a few physical keyboards out there but many are super super expensive.\n \nreply",
      "I've kind of done this, just without the actual \"build\" part\u2014I instead use a Wooting computer keyboard (which has the hall effect switches you're referring to), and I've written some program to emit MIDI based on key velocity.I've been using it very frequently for a few years, and can confirm it's quite fun to use, though I don't have much experience playing other keyboard instruments and haven't tried to learn it seriously enough to make proper use of chords etc.Demo of me playing here, though try not to mind the messy desk and bad recording setup (one-hand, MIDI going through phone due to lack of speakers): https://drive.google.com/file/d/1qZuFlK9GybX5aP5tGi54AvTTFKd...The layout I use is not a regular piano layout, but a B-griff layout, as used on a bayan (Russian accordion). I made a demo site for playing with the layout (keyboard or touchscreen), but without velocity sensitivity: https://maxdamantus.gitlab.io/bayan/The B-griff/C-griff layouts naturally fit computer keyboards, and I'd argue they're better in general than piano layouts for various reasons. There's also this cool video of someone using two Commodores for similar effect: https://youtube.com/watch?v=EBCYvoC4mucEDIT: turns out the Terpstra keyboard is also able to work using B-griff: http://terpstrakeyboard.com/web-app/keys.htm?fundamental=261...\n \nreply",
      "> https://maxdamantus.gitlab.io/bayan/Here is how to imitate it on the Terpstra keyboard web application: http://terpstrakeyboard.com/web-app/keys.htm?fundamental=261...\n \nreply",
      "> I've written some program to emit MIDI based on key velocity.nice! Is the velocity code on the firmware side? Is that why it's not included on the demo site?\n \nreply"
    ],
    "link": "http://terpstrakeyboard.com/web-app/keys.htm",
    "first_paragraph": ""
  },
  {
    "title": "Game Hacking \u2013 Valve Anti-Cheat (VAC) (codeneverdies.github.io)",
    "points": 94,
    "submitter": "LorenDB",
    "submit_time": "2025-06-18T17:19:31 1750267171",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=44311682",
    "comments": [
      "Years ago for educational purposes I decided to venture down understanding how easy/difficult it was to create a hack for Counterstrike.After just a few hours of watching YouTube tutorials and translating what I could grasp from C/C# into JavaScript (the only language I knew at the time), I had a working Node.js executable that edited memory offsets (using data from hazedumper[1]), letting me see enemies through walls and auto-fire as soon as they entered my crosshair.I obviously only tried it out on an alt steam account for fear of the infamous VAC ban, but no such ban happened. I only toyed with it for a few weeks as I then grew disinterested but that definitely left a sour taste in my mouth for the \"effectiveness\" of VAC if a script kiddie like me at the time could throw together something custom in just a few hours, I'm sure it'd be much easier now with ChatGPT...[1] https://github.com/frk1/hazedumper\n \nreply",
      "I'll never understand what people actually get out of cheating in games. I'll admit I've tried it a few times just for giggles (way back in the Age of Empires II/MSN Gaming Zone days), but the novelty quickly wears off and then it's just not even fun anymore.There must be some very interesting psychology behind this.\n \nreply",
      "In games where available weapons/gear depends on some global \"level\", this could be a way to get your desired weapons without having to grind for weeks/months. I guess a silver lining of \"pay to win\" games is that you can now pay to avoid that.I remember trying to hack the levelling-up mechanism on Crysis 2 - it worked by sending your post-game stats (client-side) to a master server, so editing those stats in memory before that happens would work (there seems to be no tracking of stats on the game server side - even though they could've had the game server relay that to the master server).Memory is fuzzy but I think I managed to level up to a stage where I got the weapons I wanted. For my defense this kind of \"cheating\" only \"cooked the books\" on the leaderboards and did not give me any actual advantage in-game.\n \nreply",
      "I wish more games let folks choose to grind for things or just have everything unlocked without grinding.  I already have a job, I just want to play a game without another grind.  I know some people love the grind, but I don't, I much prefer the L4D style \"play what you want, how you want\".\n \nreply",
      "I've botted in a few MMORPG games and the appeal is that it's basically a new perspective on the game. Also makes it more of a technical challenge than a test of mechanical skill or free time / patience.It still feels like a game in the sense that there's progression and rewards for progression. For example, learning how to read cooldowns means you can make smarter macros and double your income / cut kill time by half. There's even different \"build paths\" in that you can choose to go the memory reading build (fragile but reliable), network sniffing build (less fragile but expensive), or computer vision build (easy but unreliable and expensive).From a technical perspective, the appeal is having an excuse to try out new stuff like SAT solvers, rules engines, or whatever ML thing I just learned about. It's also a good exercise in all the math and data structures + algos stuff I've learned but never use at dayjob. Optionally, building a UI to manage the bot is fun for the same reasons, an excuse to try out new frameworks / design choices / etc. It's basically another programming job but without the icky business / customer considerations.Though I do agree that cheats in any PvP scenario is pretty lame. It has a much bigger negative impact on other players, and it's not as much of a puzzle (mostly aimbot and pathing). In comparison, PvE games are usually social and unless you're running a swarm of VMs, you're unlikely to affect the economy or otherwise inconvenience anyone.\n \nreply",
      "My perception of the psychology is a malformed competitive drive. Competition is fun! But when it gets someone to the place of \"Must win at all costs\" it can be life-destroying. For the video game cheats, I think it starts out as \"Must beat the other players\", but then that gets (mostly) boring once they are actually are beating the other players, and it shifts to \"Must beat the anti-cheat system.\"\n \nreply",
      "For a lot of them, they aren't cheating, they are compensating for bad teammates, bad servers, other cheaters, bad hit reg, bad sound effects, bad whatever they can dream up.Cheating is \"this is my actual skill level if there wasn't so much bullshit happening to me\"Of course this is all a lie, but it's what they tell themselves.\n \nreply",
      "This is only true for the people who use the cheats, not the people who make them.For the people who make them it's an intellectual exercise, like solving a puzzle, it's an end in itself. That and the social credit it gives you among your technical friends.\n \nreply",
      "this discussion made me think of the people who build nukes vs the people that use them.\n \nreply",
      "In single player games it is just another way to have fun. I mean, Minecraft creative mode is essentially equivalent to turning on all the cheats. It removes all the built-in challenge and then you come up with your own game.It doesn\u2019t seem very appealing to me, but I don\u2019t think there\u2019s any particularly interesting psychology behind it. Rather one could say I lack creativity and need monsters to motivate me to build anything.Cheating in real competitive games is rude, though, for sure. But most people don\u2019t play top-level competitive games.Cheating in pseudo-competitive games like Overwatch or Dota is both rude and stupid. Because the game can just find people to match your cheat-augmented skill level anyway.\n \nreply"
    ],
    "link": "https://codeneverdies.github.io/posts/gh-2/",
    "first_paragraph": "In 2002 Valve created an Anti-Cheat solution called \u201cValve Anti-Cheat\u201d aka VAC.\nThe first game they implemented VAC into was Counter-Strike. When VAC was introduced it only operated in\nUser Mode (Still does) meaning it runs entirely in user space 1 and has no kernel component.Below is a list of games that use VAC.. 2A longer list can be found here 3.So.. if you don\u2019t know VAC has been around for quite a while, at the time of writing it\u2019ll be 23 years.\nOver the time they\u2019ve made some mistakes but who doesn\u2019t? (Taken from wikipedia) 4 5This post isn\u2019t created to bash Valve they clean up after their mistakes and listen to their community,\ngotta love devs when they do that. I also commend them because getting VAC banned isn\u2019t such a slap\non the wrist. Getting VAC banned has some stipulations such as:Knowing what\u2019ll happen if you get VAC banned is important to know because regardless if\nyou\u2019re cheating or not false bans are no good. People in the community took it upon themselves\nto reverse"
  },
  {
    "title": "USDA Pomological Watercolors (usda.gov)",
    "points": 27,
    "submitter": "m_fayer",
    "submit_time": "2025-06-16T06:10:22 1750054222",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44287019",
    "comments": [
      "Would make for an interesting new placeholder image generator a la placecats.com\n \nreply",
      "I made these available as a dataset on GitHub some time ago: https://github.com/jwilber/USDA_Pomological_WatercolorsVery beautiful paintings.\n \nreply",
      "OK, I completely misread that title.\n \nreply",
      "Same here. I am not a native speaker, but it seems like a relatively uncommon word. Maybe that's why we both read something else\n \nreply",
      "The powers of kerning are great indeed\n \nreply"
    ],
    "link": "https://search.nal.usda.gov/discovery/collectionDiscovery?vid=01NAL_INST:MAIN&collectionId=81279629860007426",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I built a tensor library from scratch in C++/CUDA (github.com/nirw4nna)",
    "points": 88,
    "submitter": "nirw4nna",
    "submit_time": "2025-06-18T15:20:05 1750260005",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44310678",
    "comments": [
      "I noticed you interface with the native code via ctypes. I think cffi is generally preferred (eg, https://cffi.readthedocs.io/en/stable/overview.html#api-mode...). Although you'd have more flexibility if you build your own python extension module (eg using pybind), which will free you from a simple/strict ABI. Curious if this strict separation of C & Python was a deliberate design choice.\n \nreply",
      "Yes, when I designed the API I wanted to keep a clear distinction between Python and C. At some point I had two APIs: 1 in Python and the other in high-level C++ and they both shared the same low-level C API. I find this design quite clean and easy to work with if multiple languages are involved. When I'll get to perf I plan to experiment a bit with nanobind (https://github.com/wjakob/nanobind) and see if there's a noticeable difference wrt ctypes.\n \nreply",
      "The call overhead of using ctypes vs nanobind/pybind is enormoushttps://news.ycombinator.com/item?id=31378277Even if the number reported there is off, it's not far off because ctypes just calls out to libffi which is known to be the slowest way to do ffi.\n \nreply",
      "Cool stuff! Is the goal of this project personal learning, inference performance, or something else?Would be nice to see how inference speed stacks up against say llama.cpp\n \nreply",
      "Thanks!\nTo be honest, it started purely as a learning project. I was really inspired when llama.cpp first came out and tried to build something similar in pure C++ (https://github.com/nirw4nna/YAMI), mostly for fun and to practice low-level coding.\nThe idea for DSC came when I realized how hard it was to port new models to that C++ engine, especially since I don't have a deep ML background. I wanted something that felt more like PyTorch, where I could experiment with new architectures easily.\nAs for llama.cpp, it's definitely faster! They have hand-optimizing kernels for a whole bunch of architectures, models and data types. DSC is more of a general-purpose toolkit. I'm excited to work on performance later on, but for now, I'm focused on getting the API and core features right.\n \nreply",
      "Both uses cublas under the hood. So I think it is similar for prefilling (of course, this framework is too early and don't have FP16 / BF16 support for GEMM it seems). Hand-roll gemv is faster for token generation hence llama.cpp is better.\n \nreply",
      "This is very cool. I'm wondering if some of the templates and switch statements would be nicer if there was an intermediate representation and a compiler-like architecture.I'm also curious about how this compares to something like Jax.Also curious about how this compares to zml.\n \nreply",
      "You are absolutely correct! I started working on a sort of compiler a while back but decided to get the basics down first. The templates and switch(s) are not really the issue but rather going back and forth between C & Python. This is an experiment I did a few months ago: https://x.com/nirw4nna/status/1904114563672354822 as you can see there is a ~20% perf gain just by generating a naive C++ kernel instead of calling 5 separate kernels in the case of softmax.\n \nreply",
      "Do you have any plan for the serialization and deserialization of your tensor and nn library?\n \nreply",
      "Right now I can load tensors directly from a safetensors file or from a NumPy array so I don't really have in mind to add my own custom format but I do plan to support GGUF files.\n \nreply"
    ],
    "link": "https://github.com/nirw4nna/dsc",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Tensor library & inference framework for machine learning\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\nDSC is a PyTorch-compatible tensor library and inference framework for machine learning models.\nIt features a C-compatible low-level API that is wrapped in a modern Python API very similar to NumPy / PyTorch but\nwith some nice usability improvements.Some key features of DSC include:Intuitive API: DSC Python API closely resembles NumPy / PyTorch.Built-in neural networks support: DSC comes with nn.Module built-in. Porting a model from PyTorch to DSC\nis trivial (check out the examples).Multiple backends: DSC supports both CPU and CUDA with other backends being worked on.\nPrograms written using DSC can seamlessly switch between backends by simply adding a d"
  },
  {
    "title": "Is there a half-life for the success rates of AI agents? (tobyord.com)",
    "points": 210,
    "submitter": "EvgeniyZh",
    "submit_time": "2025-06-18T10:53:59 1750244039",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=44308711",
    "comments": [
      "This very much aligns with my experience \u2014 I had a case yesterday where opus was trying to do something with a library, and it encountered a build error. Rather than fix the error, it decided to switch to another library. It then encountered another error and decided to switch back to the first library.I don\u2019t think I\u2019ve encountered a case where I\u2019ve just let the LLM churn for more than a few minutes and gotten a good result. If it doesn\u2019t solve an issue on the first or second pass, it seems to rapidly start making things up, make totally unrelated changes claiming they\u2019ll fix the issue, or trying the same thing over and over.\n \nreply",
      "They poison their own context. Maybe you can call it context rot, where as context grows and especially if it grows with lots of distractions and dead ends, the output quality falls off rapidly. Even with good context the rot will start to become apparent around 100k tokens (with Gemini 2.5).They really need to figure out a way to delete or \"forget\" prior context, so the user or even the model can go back and prune poisonous tokens.Right now I work around it by regularly making summaries of instances, and then spinning up a new instance with fresh context and feed in the summary of the previous instance.\n \nreply",
      "I think you just coined \"context rot\", what an excellent term! Quoted you on my blog https://simonwillison.net/2025/Jun/18/context-rot/\n \nreply",
      "History in the making\n \nreply",
      "I always referred it more as context degradation, but rot is more visceral.\n \nreply",
      "I don\u2019t know why, but going out of your way to make sure the coining of this is attributed to a random user on the internet made me incredibly nostalgic for what the pre Web 2.0 internet was like sans the 4chans, liveleak, and their forebears on usenet\n \nreply",
      "I wonder to what extent this might be a case where the base model (the pure token prediction model without RLHF) is \"taking over\". This is a bit tongue-in-cheek, but if you see a chat protocol where an assistant makes 15 random wrong suggestions, the most likely continuation has to be yet another wrong suggestion.People have also been reporting that ChatGPT's new \"memory\" feature is poisoning their context. But context is also useful. I think AI companies will have to put a lot of engineering effort into keeping those LLMs on the happy path even with larger and larger contexts.\n \nreply",
      "I think this is at least somewhat true anecdotally. We do know that as context length increases, adherence to the system prompt decreases. Whether that de-adherence is reversion to the base model or not I'm not really qualified to say, but it certainly feels that way from observing the outputs.Pure speculation on my part but it feels like this may be a major component of the recent stories of people being driven mad by ChatGPT - they have extremely long conversations with the chatbot where the outputs start seeming more like the \"spicy autocomplete\" fever dream creative writing of pre-RLHF models, which feeds and reinforces the user's delusions.Many journalists have complained that they can't seem to replicate this kind of behavior in their own attempts, but maybe they just need a sufficiently long context window?\n \nreply",
      "I feel like as an end user I\u2019d like to be able to do more to shape the LLM behavior. For example, I\u2019d like to flag the dead end paths so they\u2019re properly dropped out of context and not explored again, unless I as a user clear the flag(s).I know there is work being done on LLM \u201cmemory\u201d for lack of a better term but I have yet to see models get more responsive over time with this kind of feedback. I know I can flag it but right now it doesn\u2019t help my \u201crunning\u201d context that would be unique to me.I have a similar thought about LLM \u201cmembranes\u201d, which combines the learning from multiple users to become more useful, I am keeping a keen eye on that as I think that will make them more useful on a organizational level\n \nreply",
      "Any good chat client will let you not only modify previous messages in place, but also modify the LLM responses, and regenerate from any point.\n \nreply"
    ],
    "link": "https://www.tobyord.com/writing/half-life",
    "first_paragraph": "Use the form on the right to contact us.You can edit the text in this area, and change where the contact form on the right submits to, by entering edit mode using the modes on the bottom right.\u00a0123 Street Avenue, City Town, 99999(123) 555-6789email@address.com\u00a0You can set your address, phone number, email and site description in the settings tab.Link to read me page with more information.Building on the recent empirical work of Kwa et al. (2025), I show that within their suite of research-engineering tasks the performance of AI agents on longer-duration tasks can be explained by an extremely simple mathematical model \u2014 a constant rate of failing during each minute a human would take to do the task. This implies an exponentially declining success rate with the length of the task and that each agent could be characterised by its own half-life. This empirical regularity allows us to estimate the success rate for an agent at different task lengths. And the fact that this model is a good fi"
  }
]