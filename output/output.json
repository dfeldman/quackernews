[
  {
    "title": "Gemini Diffusion (simonwillison.net)",
    "points": 27,
    "submitter": "mdp2021",
    "submit_time": "2025-05-22T01:13:50 1747876430",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44057820",
    "comments": [
      "I think the lede is being buried. This is a great and fast InstructGPT. This is absolutely going to be used in spell checks, codemods, and code editors.Instant edits feature can surgically perform text edits fast without all the extra fluff or unsolicited enhancements.I copied shadertoys, asked it to rename all variables to be more descriptive and pasted the result to see it still working. I'm impressed.\n \nreply",
      "Diffusion is more than just speed. Early benchmarks show it better at reasoning and planning pound for pound compared to AR.This is because it can edit and doesn\u2019t suffer from early token bias.\n \nreply",
      "This is a super interesting claim - can you point to these benchmarks?\n \nreply",
      "Interesting to see if GROQ hardware can run this diffusion architecture..it will be  two time magnitude of currently known speed :O\n \nreply"
    ],
    "link": "https://simonwillison.net/2025/May/21/gemini-diffusion/",
    "first_paragraph": "Gemini Diffusion. Another of the announcements from Google I/O yesterday was Gemini Diffusion, Google's first LLM to use diffusion (similar to image models like Imagen and Stable Diffusion) in place of transformers.Google describe it like this:Traditional autoregressive language models generate text one word \u2013 or token \u2013 at a time. This sequential process can be slow, and limit the quality and coherence of the output.Diffusion models work differently. Instead of predicting text directly, they learn to generate outputs by refining noise, step-by-step. This means they can iterate on a solution very quickly and error correct during the generation process. This helps them excel at tasks like editing, including in the context of math and code.The key feature then is speed. I made it through the waitlist and tried it out just now and wow, they are not kidding about it being fast.In this video I prompt it with \"Build a simulated chat app\" and it responds at 857 tokens/second, resulting in an "
  },
  {
    "title": "Display any CSV file as a searchable, filterable, pretty HTML table (github.com/derekeder)",
    "points": 26,
    "submitter": "indigodaddy",
    "submit_time": "2025-05-22T00:31:01 1747873861",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44057612",
    "comments": [
      "I combined this with a simple API to update a CSV file using Deno/deno-csv library, allowing an Ansible job to easily update a CSV spreadsheet via the API with URI module, and then have it viewable/downloadable in a simple and easy/dashboardy way.  Copilot created the CSV API and then with a little back and forth I added static website functionality, and I had a /view and a /update route.  I'm just a sysadmin but I love piecing together stuff like this.  Thanks Derek!\n \nreply",
      "How does this handle CSV's with no headers, or data that's offset from the top? (e.g. a row for title and subtitle, before the table headers & data)\n \nreply"
    ],
    "link": "https://github.com/derekeder/csv-to-html-table",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83d\udd3d Display any CSV (comma separated values) file as a searchable, filterable, pretty HTML table\n      Display any CSV file as a searchable, filterable, pretty HTML table. Done in 100% JavaScript.Check out the working demo: https://csv-to-html-table.netlify.app/If you want to do custom formatting for one or more column, you can pass in an array of arrays containing the index of the column and a custom function for formatting it. You can pass in multiple formatters and they will be executed in order.The custom functions must take in one parameter (the value in the cell) and return a HTML string:Example:Note that you should take care about HTML escaping to avoid XSS or broken layout.\njQuery has a nice function text() which safely escapes HTML from value.You can run this locally using this handy python command:...or with Python 3:navigat"
  },
  {
    "title": "For algorithms, a little memory outweighs a lot of time (quantamagazine.org)",
    "points": 183,
    "submitter": "makira",
    "submit_time": "2025-05-21T19:34:20 1747856060",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=44055347",
    "comments": [
      "Minus the fuzz: A multitape Turing machine running in time t can be simulated using O(sqrt(t log t)) space (and typically more than t time).https://arxiv.org/abs/2502.17779\n \nreply",
      "Lookup tables with precalculated things for the win!In fact I don\u2019t think we would need processors anymore if we were centrally storing all of the operations ever done in our processors.Now fast retrieval is another problem for another thread.\n \nreply",
      "Reminds me of when I started working on storage systems as a young man and once suggested pre-computing every 4KB block once and just using pointers to the correct block as data is written, until someone pointed out that the number of unique 4KB blocks (2^32768) far exceeds the number of atoms in the universe.\n \nreply",
      "The idea is not too far off. You could compute a hash on an existing data block. Store the hash and data block mapping. Now you can use the hash in anywhere that data block resides, i.e. any duplicate data blocks can use the same hash. That's how storage deduplication works in the nutshell.\n \nreply",
      "Except that there are collisions...\n \nreply",
      "This might be completely naive but can a reversible time component be incorporated into distinguishing two hash calculations? Meaning when unpacked/extrapolated it is a unique signifier but when decomposed it folds back into the standard calculation - is this feasible?",
      "> if we were centrally storing all of the operationsCommunity-scale caching? That's basically what pre-compiled software distributions are. And one idea for addressing the programming language design balk \"that would be a nice feature, but it's not known how to compile it efficiently, so you can't have it\", is highly-parallel cloud compilation, paired with a community-scale compiler cache. You might not mind if something takes say a day to resolve, if the community only needs it run once per release.\n \nreply",
      "Oh, that's not a problem. Just cache the retrieval lookups too.\n \nreply",
      "it's pointers all the way down\n \nreply",
      "Just add one more level of indirection, I always say.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/for-algorithms-a-little-memory-outweighs-a-lot-of-time-20250521/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesMay 21, 2025Irene Pe\u0301rez for\u00a0Quanta MagazineStaff WriterMay 21, 2025One July afternoon in 2024, Ryan Williams set out to prove himself wrong. Two months had passed since he\u2019d hit upon a startling discovery about the relationship between time and memory in computing. It was a rough sketch of a mathematical proof that memory was more powerful than computer scientists believed: A small amount would be as helpful as a lot of time in all conceivable computations. That sounded so improbable that he assumed something had to be wrong, and he promptly set the proof aside to focus on less crazy ideas. Now, he\u2019d finally carved out time to find the error.That\u2019s not what happened. After hours of poring "
  },
  {
    "title": "ITXPlus: A ITX Sized Macintosh Plus Logicboard Reproduction (68kmla.org)",
    "points": 43,
    "submitter": "zdw",
    "submit_time": "2025-05-21T21:52:30 1747864350",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=44056659",
    "comments": [
      "Very cool. I think this is probably the way forward for various types of retrocomputing now that original chassises are disintegrating due to aging plastics and parts are becoming more scarce.It\u2019s a much higher bar to clear, but I\u2019d love to see this treatment for some PPC 603/604, G3, and eventually G4 era Macs\u2026 I love the idea of building an ITX G4 cube.\n \nreply",
      "I imagine FPGAs would be a great way forward for retro computing, just like it is for retro gaming.\n \nreply",
      "FPGAs hold a lot of promise, but as I understand have limits on performance and can be on the power hungry side which can preclude some later CPUs and make portable form factors impractical.\n \nreply",
      "Retrocomputing and retrogaming are going to get a boost from a hybrid approach: using uC boards like the Raspberry Pi Pico to emulate each individual component. You get timing accuracy that's close to FPGA, but at $5 a pop, the components are cheaper than an FPGA board would cost.The Connomore 64 is an example of a complete system built this way. I'm sure Mac, Amiga, and Atari ST clones will be incoming. https://github.com/c1570/Connomore64\n \nreply",
      "As you get into more and more modern designs, there are more high speed signals and the motherboards get increasingly more complex.Not that it can't be done, but the work to reproduce something made at the cutting edge in the 2000s feels like it'd be an order of magnitude harder than 70s/80s designs.Though I'm always amazed what the retro communities will do to preserve the tech for future generations!\n \nreply",
      "Considering that we've moved from wire wrapping to being able to design and order multi-layer circuit boards, and we've gone from 74 series and basic PALs to CPLDs and FPGAs that regular people can program, I don't think what tinkerers can do will hit any barriers any time soon.The ability to recreate classic computing is wonderful, both in preservation of history and in making things available to people who hadn't even been born when these machines were new :)\n \nreply",
      "That\u2019s alright though. SE/30 was Peak Macintosh anyway.\n \nreply",
      "Heck, I'd be happy with a board that had the power/emulation of a 68040 so we can run MacOS 7.6 and some of old apps from back in the day.\n \nreply",
      "Nice! Makes me want to buy a Mac again.\n \nreply"
    ],
    "link": "https://68kmla.org/bb/index.php?threads/itxplus-a-itx-sized-macintosh-plus-logicboard-reproduction.49715/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Confidential computing for high-assurance RISC-V embedded systems (github.com/ibm)",
    "points": 70,
    "submitter": "mrnoone",
    "submit_time": "2025-05-21T20:21:06 1747858866",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44055895",
    "comments": [
      "Developers have faced in the confidential computing space, particularly with x86 TEEs, fragmentation leading to vendor lockin and a difficult developer experience due to multiple, somewhat incompatible standards/approaches. Does the CoVE effort, and IBM's involvement in it, aim to prevent a similar situation in the RISC-V world, fostering a more open and standardized TEE ecosystem? Are you using CCC to align RISC-V CoVE with efforts to improve the developer experience? I hope we see common abstractions across different TEE architectures!!!\n \nreply",
      "> ACE supports local attestation, a mechanism to authenticate confidential VMs intended for embedded systems with limited or no network connectivity.I'm interested to know the safe definition of 'limited' connectivity - is there some kind of boundary which logical reasoning can't support?\n \nreply",
      "Can you explain what the relationship is between this and CoVE? Is ACE (this repo) the firmware, and CoVE the RISC-V hardware extensions that it requires?How does it run on a P550 if that doesn't support CoVE?\n \nreply",
      "Yes, that's basically the relationship between CoVE and ACE, from a quick glance. In this case, ACE is simply implementing a formally modeled and verified security monitor where the design has been extracted to Coq and the invariants proven.It can work on P550 because CoVE supports several \"Deployment strategies\", the one ACE uses is referenced in the README: CoVE spec, Appendix D, \"M-mode [Trusted Security Manager] based deployment model\" https://github.com/riscv-non-isa/riscv-ap-tee/blob/main/src/... -- the other appendicies detail e.g. Smmtt based designs, and apparently there's a not-yet-written \"Nested Virtualization\" design in Appendix C.They also note that the P550 isn't a \"true\" port due to the preliminary, non-ratified H extension, and it also misses another required extension called \"Sstc\" but they just emulate it. (Sstc is interesting; it seems to be a performance optimization for delivering timer interrupts directly to supervisors, but I can imagine in the case of CoVE timer interrupts going through M-mode could leak data, making it more of a security issue.)Leveraging M-mode is basically how previous security monitors like keystone worked too, back on the original HiFive Unleashed. It just sorta treats M-mode as an analogue to the \"secure world\" in ARM parlance, though there is no requirement that M-mode has e.g. an encrypted memory controller and dedicated memory region, and I'm guessing other things (I'm not super familiar with TrustZone.)Broadly speaking this reminds me as a kind of a evolution/combination of Microsoft's Komodo (formally verified, but was only for e.g. SGX-style enclaves) and existing M-mode TEE systems like Keystone -- but upgraded to support \"Confidental Computing\" virtual machines. So that's quite nice.\n \nreply",
      "How does this differ from Keystone?\n \nreply"
    ],
    "link": "https://github.com/IBM/ACE-RISCV",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Assured confidential execution (ACE) implements VM-based trusted execution environment (TEE) for embedded RISC-V systems with focus on a formally verified and auditable firmware.\n      ACE-RISCV is an open-source project, whose goal is to deliver a confidential computing framework with a formally proven security monitor. It is based on the canonical architecture and targets RISC-V with the goal of being portable to other architectures. The formal verification efforts focus on the security monitor implementation. We invite collaborators to work with us to push the boundaries of provable confidential computing technology.Formal verification:\nThis project implements the RISC-V CoVE spec's deployment model 3 referenced in Appendix D. The formal specification is embedded in the security monitor's source code and the proofs are in the ver"
  },
  {
    "title": "Tales from Mainframe Modernization (oppi.li)",
    "points": 17,
    "submitter": "todsacerdoti",
    "submit_time": "2025-05-22T00:01:46 1747872106",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44057467",
    "comments": [
      "> I am currently building tangled.sh \u2014 a decentralized code-collaboration platform.https://tangled.sh/ .  Example repos: https://tangled.sh/@rockorager.dev/lsr https://tangled.sh/@tangled.sh/core\n \nreply",
      "Interesting. Looks like everyone on HN is getting interesting jobs left and right.The most compiler-ish work I ever worked on is a yaml to yaml transpiler. I mean, yeah...at least I got to write some recursions.\n \nreply"
    ],
    "link": "https://oppi.li/posts/tales_from_mainframe_modernization/",
    "first_paragraph": "At my last workplace, I wrote transpilers (or just compilers\nif you prefer) from mainframe languages (COBOL, JCL, BASIC etc.) to Java\n(in Rust!).Legacy code is full of surprises. In the roughly 200k lines of COBOL\nthat I had the (dis)pleasure of working with, I saw some wonderful hacks\nto get around the limitations of the system. Mainframes are also chock\nfull of history.This is the first thing that stood out to me when I looked at COBOL\ncode, a data-definition (the phrase for \u201cvariable\u201d) in COBOL is declared\nlike so:That statement declares a variable called HEIGHT with\ntype 9(3), which is shorthand for 999, which\nindicates \u201c3-digit number\u201d. The possible values for this variable are\n0 to 999!Below is another data-definition in COBOL, declaring 3 variables:What that means is:COBOL has an interesting construct called \u201cREDEFINES\u201d:FOO-PERSON and FOO-PERSONNE refer to the\nsame region of memory.I helped modernise a codebase that had clearly been worked on by a\nSpanish consultancy at some poi"
  },
  {
    "title": "Devstral (mistral.ai)",
    "points": 370,
    "submitter": "mfiguiere",
    "submit_time": "2025-05-21T14:21:10 1747837270",
    "num_comments": 75,
    "comments_url": "https://news.ycombinator.com/item?id=44051733",
    "comments": [
      "The first number I look at these days is the file size via Ollama, which for this model is 14GB https://ollama.com/library/devstral/tagsI find that on my M2 Mac that number is a rough approximation to how much memory the model needs (usually plus about 10%) - which matters because I want to know how much RAM I will have left for running other applications.Anything below 20GB tends not to interfere with the other stuff I'm running too much. This model looks promising!\n \nreply",
      "Any agentic dev software you could recommend that runs well with local models?I\u2019ve been using Cursor and I\u2019m kind of disappointed. I get better results just going back and forth between the editor and ChatGPTI tried localforge and aider, but they are kinda slow with local models\n \nreply",
      "https://github.com/block/goose\n \nreply",
      "Do you have any other interface for the model? what kind of tokens/sec are you getting?Try hooking aider up to gemini and see how the speed is. I have noticed that people in the localllama scene do not like to talk about their TPS.\n \nreply",
      "The models feel pretty snappy when interacting with them directly via ollama, not sure about the TPSHowever I've also ran into 2 things: 1) most models don't support tools, sometimes it's hard to find a version of the model that correctly uses tools, 2) even with good TPS, since the agents are usually doing chain-of-thought and running multiple chained prompts, the experience feels slow - this is even true with Cursor using their models/apis\n \nreply",
      "Yes, I agree. I've just ran the model locally and it's making a good impression. I've tested it with some ruby/rspec gotchas, which it handled nicely.I'll give it a try with aider to test the large context as well.\n \nreply",
      "In ollama, how do you set up the larger context, and figure out what settings to use? I've yet to find a good guide. I'm also not quite sure how I should figure out what those settings should be for each model.There's context length, but then, how does that relate to input length and output length? Should I just make the numbers match? 32k is 32k? Any pointers?\n \nreply",
      "For aider and ollama,\nsee:\nhttps://aider.chat/docs/llms/ollama.htmlJust for ollama, see:\nhttps://github.com/ollama/ollama/blob/main/docs/faq.md#how-c...I\u2019m using llama.cpp though, so I can\u2019t confirm these methods.\n \nreply",
      "Are you using it with aider? If so, how has your experience been?\n \nreply",
      "The SWE-Bench scores are very, very high for an open source model of this size. 46.8% is better than o3-mini (with Agentless-lite) and Claude 3.6 (with AutoCodeRover), but it is a little lower than Claude 3.6 with Anthropic's proprietary scaffold. And considering you can run this for almost free, this is a very extraordinary model.\n \nreply"
    ],
    "link": "https://mistral.ai/news/devstral",
    "first_paragraph": "Introducing the best open-source model for coding agents.Today we introduce Devstral, our agentic LLM for software engineering tasks. Devstral is built under a collaboration between Mistral AI and All Hands AI \ud83d\ude4c, and outperforms all open-source models on SWE-Bench Verified by a large margin. We release Devstral under the Apache 2.0 license.\u00a0While typical LLMs are excellent at atomic coding tasks such as writing standalone functions or code completion, they currently struggle to solve real-world software engineering problems. Real-world development requires contextualising code within a large codebase, identifying relationships between disparate components, and identifying subtle bugs in intricate functions.\u00a0Devstral is designed to tackle this problem. Devstral is trained to solve real GitHub issues; it runs over code agent scaffolds such as OpenHands or SWE-Agent, which define the interface between the model and the test cases. Here, we show Devstral\u2019s performance on the popular SWE-Be"
  },
  {
    "title": "Rocky Linux 10 Will Support RISC-V (rockylinux.org)",
    "points": 75,
    "submitter": "fork-bomber",
    "submit_time": "2025-05-21T20:40:58 1747860058",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=44056104",
    "comments": [
      "Red Hat announced RISC-V yesterday with RHEL 10. So this seems rather expected.https://www.redhat.com/en/blog/red-hat-partners-with-sifive-...\n \nreply",
      "I understand why people use RH and Rocky and even Oracle: the rpm wranglers.  However its not for me.My earliest mainstream distro was RH when they did it just for fun (pre IBM) and then I slid slightly sideways towards Mandrake.  I started off with Yggdrassil.I have to do jobs involving RH and co and its just a bit of a pain dealing with elderly stuff.  Tomcat ... OK you can have one from 1863.  There is a really good security back port effort but why on earth start off with a kernel that is using a walking stick.Perhaps I am being unkind but for me the RH efforts are (probably) very stable and a bit old.It's not the distro itself either.  The users seem to have snags with updating it.I (very generally) find that RH shops are the worst at [redacted]\n \nreply",
      "> Tomcat ... OK you can have one from 1863. There is a really good security back port effort but why on earth start off with a kernel that is using a walking stick.Because old software is battle-tested and reliable. Moreover, upgrading software is ever a pain so it's best to minimize how often you have to do it. With a support policy of 10 years, you just can't beat RHEL (and derivatives) for stability.\n \nreply",
      "I\u2019m old. I used one of the original boxed RH distros. It was cool then. That was almost 30 years ago.I know they give back to Linux, and I\u2019m thankful for the enterprises that pay for it because of that.It\u2019s not a bad company, though it\u2019s strange that you could be a great developer and lose your position there if your project gets cut, unless another team picks you up, from what I hear.But when Linus created Linux, he didn\u2019t do it for money, and RH just seems corporate to me like the Microsoft of Linux, way back before Microsoft had their own Linux. I want my Linux free-range not cooped.They don\u2019t do anything wrong. They just don\u2019t give the vibe. Anyone asking for money for it doesn\u2019t \u201cget it\u201d to me.\n \nreply",
      "Yep, when you have thousands of different production apps, installed and running directly on Linux - not talking about containers or microservices here - you\u2019ll have very little appetite to upgrade all of them to the latest and shiniest technologies every couple of years. Stability & compatibility with existing skillsets is more important.\n \nreply",
      "I have to confess that my early experiences with RedHat as a teenager and dealing with the nightmareish RPM dependencies soured me from the distribution. I went to Debian and then its many descendants and never looked back; APT seemed magical in comparison.I assume they have a package manager that resolves dependencies well now? Is that what an RPM wrangler is?\n \nreply",
      "rpm dependencies has been a solved problem with yum (and now dnf) for about two decades.\n \nreply",
      "I\u2019d rather use redhat than Ubuntu. I was handed a machine the other week with Ubuntu 23.10 on it, OS supplied from a vendor with extensive customization. Apt was dead. Fuck that. At least RH doesn\u2019t kill their repos.\n \nreply",
      "I've got Ubuntu 22.04 lying around that still update because they are LTS.  Ubuntu has a well publicised policy for releases and you will have obviously read them.Try do-release-upgrade.You also mention \"OS supplied from a vendor with extensive customization. Apt was dead.\"How on earth is that Ubuntu's problem?\n \nreply",
      "Isn\u2019t Ubuntu basically killing apt?My Ubuntu became unusable because it kept insisting on installing a snap version of Firefox breaking a whole bunch of workflows.I do want to try a RH based OS (maybe Fedora) so they don\u2019t keep changing things on me, but just where I am in life right now I don\u2019t have the time/energy to do so, so for now I\u2019m relying on my Mac.Hopefully I can try a new Linux distro in a few months, because I can\u2019t figure it out yet, but something about macOS simply doesn\u2019t work for me from a getting work done perspective.\n \nreply"
    ],
    "link": "https://rockylinux.org/news/rockylinux-support-for-riscv",
    "first_paragraph": "May 21, 2025Alexia Stein, Community LeadWe're excited to announce that Rocky Linux 10 will officially support RISC-V!Thanks to the incredible work of the Fedora RISC-V Community and Rocky's AltArch SIG, this release will include a riscv64gc build, targeting the same platforms supported by Fedora\u2014such as the StarFive VisionFive 2 (VF2), QEMU, and the SiFive HiFive Premier P550.Learn more about Fedora\u2019s RISC-V journey:\nfedoramagazine.org/risc-v-and-fedora-all-aboardSpecial thanks to RISC-V International, RISE, Rivos, Inc., and the Fedora community for their ongoing technical and hardware support.The RISC-V builds for Rocky Linux 10 will be considered an Alternative Architecture--though unlike ppc64le and s390x, build failures for riscv64 will not be considered fatal and will not block the release of the other architectures. In short, package updates for Rocky Linux will not be bottlenecked on waiting for RISC-V versions to build, or on fixing failures unique to the archicture.Stay update"
  },
  {
    "title": "OpenAI to buy AI startup from Jony Ive (bloomberg.com)",
    "points": 626,
    "submitter": "minimaxir",
    "submit_time": "2025-05-21T17:01:35 1747846895",
    "num_comments": 862,
    "comments_url": "https://news.ycombinator.com/item?id=44053518",
    "comments": [
      "https://archive.is/HgpSJ",
      "First Windsurf and now this. OpenAI is spending billions like there's nothing else to use this money for while being seemingly cash strapped for model training since they already signaled more investment rounds would be needed to remain competitive. They're trying to become too big to fail before they have a moat which won't work well.\n \nreply",
      "They've already claimed that there will be no \"GPT-5\" LLM, and that instead what they want to call \"GPT-5\" is a fusion of their various models like 4o, dalle, their video model, etc. That in and of itself is a move that makes it quite clear to me they've hit a wall on the intelligence side.Add these purchases, and it seems like they are extremely desperate.\n \nreply",
      "Models are getting smaller, faster, cheaper to make, reflecting on their own output, adding modes and running in more places. But they\u2019re not getting much smarter because they can only be as smart as us and each other, because that\u2019s where their training comes from. OpenAI is strongest in a world where models cost billions to train. A world filled with cheap open source models is their worst nightmare. This is what\u2019s happening. So they have to pivot into being a product company and away from being a model company.\n \nreply",
      "Userbase and customer relationships are valuable. If someone else creates GPT5, but doesn't have a large user base, then OpenAI the company could buy that invention. Or, as we saw with deepseek in January, fast-follow with a comparable model within a reasonable amount of time.Brands have value. If someone has logged into ChatGPT for two years daily, they have built a habit. That habit certainly can be disrupted, but there's a level of inertia and barrier -- something else has to be 10x better and not just 2x better.When DeepSeek came out, I tried it out but didn't fundamentally switch my habit. OpenAI + Claude + Gemini instead caught up.\n \nreply",
      "OpenAI would not be able to as every other company and governments even will make bids and OpenAI is not well loved to get favor to tilt the scale back in their direction.\n \nreply",
      "> Userbase and customer relationships are valuableWhich of these does Jony Ive's company have?\n \nreply",
      "Following that logic, they\u2019ll have to keep spending quite a bit to get to the user base of the current hyperscalers, some of which are already ahead of OpenAI in terms of LLM performance.\n \nreply",
      "I'm not so sure it's desperation. As an alternative hypothesis, we might simply view it as an attempt from a temporary position of strength to secure their tremendous lead as the primary consumer access point to intelligence. I don't think it's much of an exaggeration to suggest that this is one of the most important open questions at the moment -- one which will likely be relatively winner-takes-all (in contrast to the more commoditized B2B/API side) and where the winner likely won't be decided based on the intelligence side alone. The questions also aren't entirely separate since the winner, here, will have such incomparably valuable usage data...Unlike most successful startups, OpenAI is not faced with the possibility that the giants (Apple, Google, Microsoft) decide to look their way, but the reality that these are their real competitors and that the stakes are existential for many of them (trends indicating a shift away from search etc). The most likely outcome remains that one if not all of the giants eventually manage to produce a halfway-decent product experience that reduces OpenAI to a B2B player.\n \nreply",
      "> secure their tremendous lead as the primary consumer access point to intelligenceYes because the only way to get access to intelligence is via ChatGPT which continues to lie and hallucinate on a regular basis.Definitely can't get it via the web, books, videos etc.\n \nreply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2025-05-21/openai-to-buy-apple-veteran-jony-ive-s-ai-device-startup-in-6-5-billion-deal",
    "first_paragraph": ""
  },
  {
    "title": "Collaborative Text Editing Without CRDTs or OT (mattweidner.com)",
    "points": 182,
    "submitter": "samwillis",
    "submit_time": "2025-05-21T17:05:45 1747847145",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=44053560",
    "comments": [
      "That is very neat. The algorithm:- Label each text character with a globally unique ID (e.g., a UUID), so that we can refer to it in a consistent way across time - instead of using an array index that changes constantly.- Clients send the server \u201cinsert after\u201d operations that reference an existing ID. The server looks up the target ID and inserts the new characters immediately after it.- Deletion hides a character for display purposes, but it is still kept for \"insert after\" position purposes.This might have potential outside text editing. Game world synchronization, maybe.\n \nreply",
      "This is literally a degenerate CRDT. Central server for tie-breaking goes back to Google Wave.\n \nreply",
      "Any algorithm that uses a central server as a tie-breaker could easily be replaced by one where client ids are used for the tie-breaker.\n \nreply",
      "I miss Wave a lot, very quirky in a good way imo. We ran a few D&D games over it.\nRIP\n \nreply",
      "Is this really that novel? I mean using a central process for serializing a distributed system is like a no brainer -- didn't we start off from here originally? -- until you have to worry about network partitions, and CAP and all that jazz. You also now have a single point of failure. Also I skimmed the thing but was performance discussed?\n \nreply",
      "I really want to believe you were trying to make a reference to cap'n jazz - https://en.m.wikipedia.org/wiki/Cap'n_Jazz:)\n \nreply",
      "Never heard of them:(\n \nreply",
      "Yeah I have the same question. I'm not familiar with the problem space but this seems like my naive first idea so I'm wondering what the catch is.\n \nreply",
      "As the author, same.My best guess is:- Central-server collaborative editing work focuses on Operational Transformation (OT), likely due to inertia (studied since 1989) and the perception that storing an ID per character is inefficient. In fairness, it is, absent the optimizations introduced by RGASplit and Yjs (~2015).- For decentralized editing, OT is very complicated, and CRDTs took over as the solution of interest (studied since 2005). Storing every operation permanently in a log - needed to use the linked approach without a server - feels inefficient, as does server reconciliation's undo/re-apply process. So CRDT research has focused on avoiding those inefficiencies, sacrificing simplicity along the way, instead of just embracing them as the easy way out.To me, the \"inefficiencies\" seem quite manageable. Storage is cheap, text is small, and you probably want a complete op log anyway for auditing and document histories (cf. git). Server reconciliation's undo/re-apply process can be batched aggressively, e.g., only do it a few times per second; that just makes remote ops take a little longer to show up.Granted, I have not built a complete app around server reconciliation or the linked approach, so perhaps there is a hidden catch. But I am encouraged by the success of Replicache (https://doc.replicache.dev/concepts/how-it-works), which is where I learned of server reconciliation.\n \nreply",
      "What you describe is a CRDT, isn't it ?\n \nreply"
    ],
    "link": "https://mattweidner.com/2025/05/21/text-without-crdts.html",
    "first_paragraph": "\n    Matthew Weidner |\n    \n    May 21st, 2025\n    \n    \nHome | RSS Feed\n\n    Keywords: text editing, server reconciliation, Articulated\n    Collaborative text editing is arguably the hardest feature to implement in a collaborative app. Even if you use a central server and a fully general solution to optimistic local updates (server reconciliation), text editing in particular requires fancy algorithms - specifically, the core of a text-editing CRDT or OT.Or rather, that\u2019s what I thought until recently. This blog post describes an alternative, straightforward approach to collaborative text editing, without Conflict-free Replicated Data Types (CRDTs) or Operational Transformation (OT). By making text editing flexible and easy to DIY, I hope that the approach will let you create rich collaborative apps that are challenging to build on top of a black-box CRDT/OT library.This post builds off of my previous post, Architectures for Central Server Collaboration, though I\u2019ll recap ideas as need"
  },
  {
    "title": "The Machine Stops (1909) (standardebooks.org)",
    "points": 46,
    "submitter": "xeonmc",
    "submit_time": "2025-05-21T21:18:07 1747862287",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44056407",
    "comments": [
      "What a great story!I was introduced to it by The Hugonauts podcast. Have a great audio rendering of it[0]. \nI went into it not knowing anything about the book or the author and was really surprised to find out it was written over 100 years ago.[0] https://hugonauts.simplecast.com/episodes/the-machine-stops-...\n \nreply",
      "Whether so intended or not, I like to think it was a response to Angell's The Great Illusion.Both were written at, and the film Moulin Rouge! strives to depict, a time whose specific and rather rancid vibe the phrase fin de si\u00e8cle (literally 'end of cycle' sharing the relevant root with 'secular,' but in proper translation 'end of the century') was adopted into English to describe. That phrase has been occurring to me with some frequency this year.\n \nreply",
      "I first read it decades ago. As time goes on, it has become more relevant.\"The Mending Apparatus was itself in need of repair.\"\n \nreply",
      "I was really struck by the phrase \"better thus than not at all\", expecially where it appears in the story. It's made an impression on me since.\n \nreply",
      "I love when history shows that we have always had the same human ambitions.The magic of the technology described in the story is where we have always been headed.\n \nreply",
      "There\u2019s something very comforting about a story like this. Humans have always been humans. The names may change but our fears have been our fears, our ambitions have been our ambitions.\n \nreply",
      "> \"I was surrounded by artificial air, artificial light, artificial peace, and my friends were calling to me down speaking-tubes to know whether I had come across any new ideas lately.\u201dHi HN waves; Reddit, news aggregators, the 24 hour news cycle. One quote I went looking for, which sticks in my mind, was about novel ideas:> \"Had she had any ideas lately? ... That she had no ideas of her own but had just been told one \u2014that four stars and three in the middle were like a man: she doubted there was much in it.\"She's talking of the Orion's Belt constellation[1], which she has never seen because she lives underground in The Machine (city). It stuck with me how quickly she dismisses the idea because it isn't immediately useful. Jony Ive said that once in an interview decades ago, why he had to move to America, because new ideas are weak and need nurturing and the UK culture dismisses them too easily but America supports them. I saw that basic concept just now on HN comment about EU startups, that EU people see startups as too risky and Americans are enthusiastic about them[2]. Orion's Belt ties to so many ideas, the stars as a shared canvas, projection of our own view up onto them, culture-specific constellaitons, the signs of the Zodiac mark the path the Sun takes overhead, different constellations visible in different hemispheres, imagery as dots, imagination filling in missing details, an ancient time when skies were clear and everyone could see them. I see Orion's Belt through Winter here in the UK but maybe there are people in the Southern Hemisphere who don't see it, so I linked to DuckDuckGo below; worse, maybe there are people in cities with light pollution who never see stars or constellations at all?Social Media notifications:> \"Vashti\u2019s next move was to turn off the isolation-switch, and all the accumulations of the last three minutes burst upon her. The room was filled with the noise of bells, and speaking-tubes. What was the new food like? Could she recommend it? Had she had any ideas lately? Might one tell her one\u2019s own ideas? Would she make an engagement to visit the public nurseries at an early date? \u2014say this day month.\"The rise of interest in Urban planning and human scale cities:> \u201cYou know that we have lost the sense of space. We say \u2018space is annihilated,\u2019 but we have annihilated not space, but the sense thereof. We have lost a part of ourselves. I determined to recover it, and I began by walking up and down the platform of the railway outside my room. Up and down, until I was tired, and so did recapture the meaning of \u2018Near\u2019 and \u2018Far.\u2019 \u2018Near\u2019 is a place to which I can get quickly on my feet, not a place to which the train or the airship will take me quickly. \u2018Far\u2019 is a place to which I cannot get quickly on my feet; the vomitory is \u2018far,\u2019 though I could be there in thirty-eight seconds by summoning the train. Man is the measure. That was my first lesson. Man\u2019s feet are the measure for distance, his hands are the measure for ownership, his body is the measure for all that is lovable and desirable and strong.\"LLM Stories:> So respirators were abolished, and with them, of course, the terrestrial motors [access to the surface / outside], and except for a few lecturers, who complained that they were debarred access to their subject-matter, the development was accepted quietly. Those who still wanted to know what the earth was like had after all only to listen to some gramophone, or to look into some cinematophote. And even the lecturers acquiesced when they found that a lecture on the sea was none the less stimulating when compiled out of other lectures that had already been delivered on the same subject.Was it prescient or was it just observing things already happening 100 years ago?[1] https://duckduckgo.com/?t=ffab&q=orion%27s+belt+constellatio...[2] https://news.ycombinator.com/item?id=44050394\n \nreply",
      "> That was my first lesson. Man\u2019s feet are the measure for distance, his hands are the measure for ownership, his body is the measure for all that is lovable and desirable and strong.Americans were much slower to forget, which is why we correctly spurn the metric system for all save technologists and likewise self-fettering minds. Unfortunately, the tech industry exists, for the moment.\n \nreply",
      "\"  \nOn this bridge, Lorca warns, 'life is not a dream. Beware. And beware. And beware.' And so many think because Then happened, Now isn't. But didn't I mention the ongoing \"wow\" is happening right now? We are all co-authors of this dancing exuberance where even our inabilities are having a roast. We are the authors of ourselves, co-authoring a gigantic Dostoevsky novel, starring clowns. This entire thing we're involved with called the world, is an opportunity to exhibit how exciting alienation can be.Life is a matter of a miracle that is collected over time by moments, flabbergasted to be in each other's presence. The world is an exam to see if we can rise into direct experience. Our eyesight is here as a test to see if we can see beyond it. Matter is here as a test for our curiosity. Doubt is here as an exam for our vitality. Thomas Mann wrote that he would rather participate in life than write 100 stories.Giacometti was once run down by a car, and he recalled falling into a lucid faint, a sudden exhilaration, as he realized that at last something was happening to him. An assumption develops that you cannot understand life and live life simultaneously. I do not agree entirely. Which is to say I do not exactly disagree. I would say that life understood is life lived. But the paradoxes bug me, and I can learn to love and make love to the paradoxes that bug me. And on really romantic evenings of self, I go salsa dancing with my confusion.Before you drift off, don't forget. Which is to say, remember. Because remembering is so much more a psychotic activity than forgetting. Lorca, in that same poem said that the iguanas will bite those who do not dream. And as one realizes that one is a dream figure in another person's dream, that is self awareness...  \n\"  \n~Timothy Levitch in \u201cWaking Life\u201d++upvoted to null the dofus who thinks expressing opinions about the metric system is a crime against humanity\n \nreply",
      "Oh, one needn't. A downvote is an honest cri de coeur, if not an honest signal. And they are in any case more likely because I had the temerity to remind someone he is about to be still standing as the music stops, or likelier still I reminded him all he can find to value within himself merits pity from the generous and contempt from everyone. I only died to get out, for which I never blame people hating me; they must, no coward can ever withstand the acknowledgement of courage.> But the paradoxes bug me, and I can learn to love and make love to the paradoxes that bug me. And on really romantic evenings of self, I go salsa dancing with my confusion.Now this is the way to live.\n \nreply"
    ],
    "link": "https://standardebooks.org/ebooks/e-m-forster/short-fiction/text/the-machine-stops",
    "first_paragraph": "The AirshipImagine, if you can, a small room, hexagonal in shape, like the cell of a bee. It is lighted neither by window nor by lamp, yet it is filled with a soft radiance. There are no apertures for ventilation, yet the air is fresh. There are no musical instruments, and yet, at the moment that my meditation opens, this room is throbbing with melodious sounds. An armchair is in the centre, by its side a reading-desk\u2060\u2014that is all the furniture. And in the armchair there sits a swaddled lump of flesh\u2060\u2014a woman, about five feet high, with a face as white as a fungus. It is to her that the little room belongs.An electric bell rang.The woman touched a switch and the music was silent.\u201cI suppose I must see who it is,\u201d she thought, and set her chair in motion. The chair, like the music, was worked by machinery, and it rolled her to the other side of the room, where the bell still rang importunately.\u201cWho is it?\u201d she called. Her voice was irritable, for she had been interrupted often since the "
  },
  {
    "title": "I have tinnitus. I don't recommend it (greg.technology)",
    "points": 26,
    "submitter": "gregsadetsky",
    "submit_time": "2025-05-21T22:50:10 1747867810",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=44057044",
    "comments": [
      "> so now, i am one of those people that plucks their ears when an emergency vehicle goes by with the siren blaring.You might get one of those low-end decibel meters that supposedly are calibrated at the factory (around $25 in the US), to measure how loud the sirens are.  Maybe they're louder than they need to be, and you can request for them to be adjusted, as a public health improvement.I've been meaning to do something like this.  My city has sirens throughout the day, but one particular ambulance company's seems much louder to me than any other company or other emergency vehicle -- dangerously louder.  As someone who walks miles every day, on major streets and near hospitals, the near-daily potential hearing damage risk has started to get a bit concerning.  I'd like to have data (and make sure it's not just a frequency sensitivity specific to me), before I ask them respectfully if the volume can be adjusted.\n \nreply",
      "I\u2019ve played drums and loud music for a long time. When I pay close enough attention there\u2019s this persistent, aggravating noise \u2014 which I sometimes call \u201csilence\u201d, and other times call \u201ctinnitus\u201d.\n \nreply",
      "I have it from being a death metal singer/guitarist 30 years ago, but it gets much worse when tired or higher blood pressure (handy though ; most people don't have an actual audible alarm for that). It's indeed not recommended, it is, however very clever how the brain mostly filters it out unless I actively think about it.\n \nreply",
      "Most veterans have it, I sure do although relatively mild. Besides being issued defective ear plugs, the CVC helmets we used were garbage at protecting your ears.https://amp.cnn.com/cnn/2023/08/29/business/3m-settlement-mi...\n \nreply",
      "In some ex-soviet countries college students may go to introductory military training, and they never even tell students that they need earplugs when giving them an AK to shoot at a shooting range.\n \nreply",
      "I have it since I can remember, but got aggravated by two events:(1) One time when I was going to setup the drums to play for a band, walked front of a tall speaker and precisely when I stepped in front of it a loud boom scaped from it; and(2) covid-19.It's kind of in \"stereo\", in the right ear is a bit louder and with a higher pitch than in the left ear. I can't imagine how terrible it is for people with worse cases but in my case I can live with it despite sometimes I have trouble hearing some stuff - but it's kind of uncanny sometimes I even forget about it until I remember I have it, like now reading \"tinnitus\" in the title of this article. Something like the yawn effect.\n \nreply",
      "There was an earlier thread on tinnitus https://news.ycombinator.com/item?id=21572827 where people had some techniques for relief. Maybe this could be useful.\n \nreply",
      "Both my wife and I started experiencing tinnitus days after the first covid shots. I will never be able to prove the shots were the cause but there was really nothing else happening in our lives back then.In my case it was never severe but I've heard of people woken up by their tinnitus.Thankfully it has mostly subsided. These days I barely notice it unless I'm in a very quiet environment.\n \nreply",
      "Thanks for the reminder. Do you remember if it was mainly the mid and trebles that were too high ?Do you also get hurt when hearing loud bass / infra bass ?\n \nreply",
      "Why is the new style to avoid capitalization when writing? I see it everywhere now. I can only imagine the annoyance of fighting autocorrect just to format your content like this.\n \nreply"
    ],
    "link": "https://blog.greg.technology/2025/05/20/tinnitus.html",
    "first_paragraph": "\n        May 20, 2025\n      i went to a show in november of last year (it\u2019s may right now) and ever since, i have tinnitus. i don\u2019t recommend it.i\u2019ve been going to electronic music shows for a while and had been very careless with my ears - because it felt like i would always be okay. after the show, especially in the morning, you\u2019d have the next-day tinnitus, but then it would go away.of course, this one never went away. was i closer to the speakers that time, was the music louder, was it something about the frequencies. was it all of the accumulated careless listening.i\u2019ll say three things:if you attended a show at a venue that had cool lights, but it turned out that some people lost their sight because of the cool lasers there, the venue would be shut down, there would be an investigation, there would be lawsuits, etc.however, if you go to a venue today and the sound is so loud that people become permanently disabled because of that\u2026 as far as i know, nothing happens. why?i\u2019ve been "
  },
  {
    "title": "The curious tale of Bhutan's playable record postage stamps (2015) (thevinylfactory.com)",
    "points": 82,
    "submitter": "ohjeez",
    "submit_time": "2025-05-21T18:45:18 1747853118",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44054775",
    "comments": [
      "\"Issued in 1972 in a set of seven, the stamps are miniature, one-sided, 33 1\u20443 rpm vinyl records playable on a standard turntable. You peeled off the backing paper and stuck them on an envelope or postcard. Content includes Bhutanese folk songs and histories of the country in English and Dzongkha, the local language. \"I work in IT.  I used to be a philatelist (can you stop?).  How on earth did I never think of this.It makes those bloody awful business card CDs (off of the 90s n noughties) look pretty naff.Barking mad and quite beautiful.  Love it!\n \nreply",
      "Given the timelines and lead times for production, I assume this was conceptualized on a mid-1960s acid trip.\n \nreply",
      "Previous discussion:The curious tale of Bhutan's playable record postage stamps (2015) - https://news.ycombinator.com/item?id=22896682 - April 2020 (30 comments)\n \nreply",
      "Interesting!  Now I'm wondering if Leighton or Feynman was aware of these stamps (my ddg/google-fu is bad today).\n \nreply",
      "I find it fascinating that something so inherently worthless like stamps can sell for such large sums. Old fashioned NFT's?These stamps however are very cool. And the prices are actually reasonable.\n \nreply"
    ],
    "link": "https://thevinylfactory.com/features/the-curious-tale-of-bhutans-playable-record-postage-stamps/",
    "first_paragraph": "Made of plastic and embossed with a melody, these tiny record stamps are among the strangest, most enchanting bits of vinyl out there. Chris May investigates how the Buddhist Kingdom of Bhutan came to produce the world\u2019s \u201cfirst talking stamps\u201d.Quite possibly the smallest vinyl records that can still be played with a stylus, those of you after a set will be happy to know the stamps still sporadically appear on eBay, with prices pushed up by that geekiest of venn diagrams between stamp and record collectors.Listen to a haunting version of the Bhutanese national anthem, as recorded from a stamp, below.If you\u2019re looking to make a smart investment in vinyl, among the most promising items to look out for right now are a set of Bhutanese talking-stamps. Issued in 1972 in a set of seven, the stamps are miniature, one-sided, 33 1\u20443 rpm vinyl records playable on a standard turntable. You peeled off the backing paper and stuck them on an envelope or postcard. Content includes Bhutanese folk songs"
  },
  {
    "title": "Animated Factorization (2012) (datapointed.net)",
    "points": 224,
    "submitter": "miniBill",
    "submit_time": "2025-05-21T14:39:37 1747838377",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=44051958",
    "comments": [
      "This is brilliant!Now i want (to build) a drag and drop toy where i can multiply or summarize numbers that are represented in this way. To see how factors move (like boids).Is this visualization algorithm called something?\nThe explanation link from a previous HN post seems to be broken: \nhttp://mathlesstraveled.com/2012/10/05/factorization-diagram...\n \nreply",
      "Kind of makes me wish that there were recognizable shapes for primes bigger 2 (pair), 3 (triangle), 4 (square) and 5 (pentagon) that didn't just look like circles. Because my favorite part about this is how you can see at a glance what the factors are. Except for primes 7 or greater I find myself cheating and looking at the top left for which prime it is.Is there some non-regular polygon that would be more distinctly recognizable to use for 7, 11, etc?\n \nreply",
      "I asked somewhere here about the algorithm for the position of the dots and got an answer (can I link directly to a post?) below. Putting things on a circle sounds like a good way to do it but it sort of precludes special arrangement for specific numbers. Not that it could not be done but what would the algorithm look like?Edit: I looked more at the animation some more and maybe I am wrong. Anyway I may try to make one.\n \nreply",
      "4 isn\u2019t prime.You could probably use the binary expansion to group the dots?\nSo, 1 is \u2022\n2 is \u2022\u2022\n3 is  \n_\u2022  \n\u2022_\u20225 is_\u2022  \n\u2022_\u2022  \n\u2022_\u20227 is  \n____\u2022  \n_\u2022_____\u2022  \n\u2022_\u2022___\u2022_\u202211 is  \n____\u2022  \n_\u2022_____\u2022  \n\u2022_\u2022___\u2022_\u2022\n\u2022_\u2022___\u2022_\u2022And so on.(So, 2n is represented as n next to n, unless n is 2 in which case it is n above n, and 2n+1 is 1 above 2n )Alternatively, using stars instead of n-gons could also be clearer?\n \nreply",
      "Couldn't you draw it in a recognizable way using summation?7 = 2*3+111 = (2*2+1)*2+1etc...\n \nreply",
      "Interesting idea\n \nreply",
      "Agree. I watched for a while to see some larger primes and was a little disappointed.Filled polygons would offer some more shapes. Filled hexagon = 7, etc etc...\n \nreply",
      "Aren't 2 (pair), 3 (triangle), 4 (square) and 5 (pentagon) also \"circles\" with less resolution? The visualization is just consistent.\n \nreply",
      "Yes I dont disagree and it is elegant as is, but the way our eyes/ brain works it's much harder to ID septagon, nonagon, triacontahenagon etc at a glance. A non-regular shape would be better fit for purpose\n \nreply",
      "I believe it's called prime factorization. Each number is placed in a group of numbers (or group of groups, etc...)E.g. 24 -> 2 * 3 * 4 = Two groups of (three groups of (four items))Also try this for the archived version of that explanation -> https://web.archive.org/web/20130206023100/http://mathlesstr...\n \nreply"
    ],
    "link": "http://www.datapointed.net/visualizations/math/factorization/animated-diagrams/",
    "first_paragraph": ""
  },
  {
    "title": "Sorcerer (YC S24) Is Hiring a Lead Hardware Design Engineer (ashbyhq.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-05-21T21:00:11 1747861211",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jobs.ashbyhq.com/sorcerer/6beb70de-9956-49b7-8e28-f48ea39efac6",
    "first_paragraph": ""
  },
  {
    "title": "How Gemini Figured Out My Nephew's Name (nawaz.org)",
    "points": 13,
    "submitter": "BeetleB",
    "submit_time": "2025-05-19T00:35:02 1747614902",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44025459",
    "comments": [
      "Page layout broken on mobile.\n \nreply",
      "It works in landscape mode on mobile, but is broken in portrait mode.\n \nreply",
      "That's a unique nameIf you're on Chrome, go into desktop view and zoom out\n \nreply"
    ],
    "link": "https://blog.nawaz.org/posts/2025/May/gemini-figured-out-my-nephews-name/",
    "first_paragraph": "Posted on Sat 17 May 2025I wrote an MCP server\nto give LLMs read-only access to my emails. Here is the chat\u00a0log.ME:I need to know Donovan\u2019s son\u2019s name. It is buried in some email\nsomewhere. Devise a strategy for finding it. Do NOT use any tools\ntill we\u2019ve discussed it\u00a0through.GEMINI:Okay, I will devise a strategy to find Donovan\u2019s son\u2019s name and\ndiscuss it with\u00a0you.Strategy:Do you want to proceed with the first step, or would you like to\nrefine this\u00a0strategy?ME:OK. Go ahead and try them. No need to prompt me any\u00a0more.GEMINI:The search \u201cfrom:Donovan son\u201d returned a promising\u00a0result:I\u2019ll get the content of this\u00a0message.This email is about Donovan\u2019s cousin Aliyah\u2019s son, Albert Hamming,\nnot Donovan\u2019s own\u00a0son.I\u2019ll try other\u00a0keywords.The search \u201cfrom:Donovan baby\u201d yielded one\u00a0result:Subject:\u00a0powertoddler!This email links to a YouTube video and mentions \u201cthe baby\u201d. This is\na strong lead. However, the email is from 2011. While this could be\nDonovan\u2019s son, the term \u201cpowertoddler\u201d might also ref"
  },
  {
    "title": "Show HN: I've built online video editor (clipjs.vercel.app)",
    "points": 85,
    "submitter": "mohyware",
    "submit_time": "2025-05-21T19:50:37 1747857037",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=44055542",
    "comments": [
      "I got about 30% through making something very similar then moved on to another project. This is very nicely done.It is worth noting that I did a lot of research in this space when I was working on my own video editor and there are a lot of these now (I have about 30 in a spreadsheet). Ever since there was a ffmpeg WASM port many people have made these web based editors. It is so cool we live in a time where that kind of powerful technology is freely usable by others to build these tools.My angle was to add gen ai video as a first class feature. That might be something you want to investigate now that video gen apis are becoming more common.\n \nreply",
      ">That might be something you want to investigate now that video gen apis are becoming more common.No, it doesn't need that. It just needs to be a good web-based video editor.\n \nreply",
      "Wrong, depending on his priorities.If he just wants a good website to do the job, sure, genai is uselesseBut if he wants to market it, in this day and age, it's practically a need.\n \nreply",
      ">But if he wants to market it, in this day and age, it's practically a need.No, it isn't. AI content creation is a fundamentally different thing that a video editor. Maybe you can't tell the difference, but I can. AI isn't going to edit the video how I want, it isn't going to create the video I want from a prompt when I've already got the video clips I want to edit. I don't need to edit clips of people with 7 fingers, I need to edit my family vacation video, or whatever it is I need a video editor for. There's nothing about AI that would improve this as a video editor, at all.If I could import this project into my existing React-based web app, I will use it to edit clips of content for my specific application, and for that it is useful. AI would just bloat it and be annoying where it isn't needed.\n \nreply",
      "https://omniclip.app/ is another online video editor option that runs entirely in the browser (i.e. no video sent to an unknown server). Also open source.\n \nreply",
      "Another one https://pikimov.com/app/\n \nreply",
      "Wow this is really great! I can't believe this is a one person project\nI can definitely get inspiration from it.\n \nreply",
      "looks cool\n \nreply",
      "Perhaps add a screenshot to the landing page? The current \"Ok, what does it look like?\" path seems discouragingly long (landing page, Get Started, Add Project, name project, click on project).\n \nreply",
      "looks cool, love how there's no sign in required.some feedback so far:- allow me to drag + drop video clips to add them to the media section- allow me to trim the beginning of a clip - right now i can only trim the end of a video clip- allow me to drag the playhead (right now i can only click to move the playhead somewhere)- make most of the text on the page be select-none - there were many times when i tried to drag something and it selected a bunch of text on the page\n \nreply"
    ],
    "link": "https://clipjs.vercel.app/",
    "first_paragraph": "Welcome toEdit your videos from your PC or phone no downloads, no registration, no watermarks.Online, Free and Open SourceEdit your videos without any watermarks.Edit and render without having to watch any ads.Start using the app instantly no sign-up, no account, just get to work.Everything runs in your browser so there's no need to upload files to third-party services or wait around.Trim video to remove unwanted parts, reduce videos to their most important sections.Combine multiple videos, images, texts and audio into one.\u00a9 2025 ClipJS. All rights reserved."
  },
  {
    "title": "CERN gears up to ship antimatter across Europe (arstechnica.com)",
    "points": 51,
    "submitter": "ben_w",
    "submit_time": "2025-05-19T19:18:24 1747682304",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44033711",
    "comments": [
      "CERN preparing a portable antimatter container right around the election of a new Pope? Sounds familiar [0][0] https://en.wikipedia.org/wiki/Angels_%26_Demons_(film)\n \nreply",
      "Dan Brown is definitely taking notes.\n \nreply",
      "Or on contrary expecting some sort of royalties\n \nreply",
      "oh man, the conspiracy nuts are going to have fun with this.\n \nreply",
      "> If the delivery can be made successfully\u2014and it appears we are just a liquid helium supply away from getting it to work\u2014the new facility in Germany should allow measurements with a precision of over 100 times better than anything that has been achieved at CERN.Hmm. It sounds good until you realize that's two decimal places. Two decimal places is a pretty marginal gain for a lot of work.\n \nreply",
      "Two decimal places is a shit ton of precision though.A one inch gap is immense compared to a .01 inch gap.\n \nreply",
      "Don't cross the streams.\n \nreply",
      "Do you think they can overnight me an antikindle?\n \nreply",
      "The bank servicing the transaction will have to upgrade their internal software for money representation.\n \nreply",
      "Why not use Amazon prime?\n \nreply"
    ],
    "link": "https://arstechnica.com/science/2025/05/cern-gears-up-to-ship-antimatter-across-europe/",
    "first_paragraph": "\n        A portable containment device that can be dropped on a truck.\n      There's a lot of matter around, which ensures that any antimatter\u00a0produced experiences a very short lifespan. Studying antimatter, therefore, has been extremely difficult. But that's changed a bit in recent years, as CERN has set up a facility that produces and traps antimatter, allowing for\u00a0extensive studies\u00a0of its\u00a0properties, including\u00a0entire anti-atoms.Unfortunately, the hardware used to capture antiprotons also produces interference that limits the precision with which measurements can be made. So CERN decided that it might be good to determine how to move the antimatter away from where it's produced. Since it was tackling that problem anyway, CERN decided to make a shipping container for antimatter, allowing it to be put on a truck and potentially taken to labs throughout Europe.The problem facing CERN comes from its own hardware. The antimatter it captures is produced by smashing a particle beam into a s"
  },
  {
    "title": "LLM function calls don't scale; code orchestration is simpler, more effective (jngiam.bearblog.dev)",
    "points": 157,
    "submitter": "jngiam1",
    "submit_time": "2025-05-21T17:18:52 1747847932",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=44053744",
    "comments": [
      "I've been saying for two years that \"any sufficiently advanced agent is indistinguishable from a DSL.\"Rather than asking an agent to internalize its algorithm, you should teach it an API and then ask it to design an algorithm which you can run that in user space. There are very few situations where I think it makes sense (for cost or accuracy) for an LLM to internalize its algorithm. It's like asking asking an engineer to step through a function in their head instead of just running it.\n \nreply",
      "Sorry I\u2019ve been out of the industry for the last year or so, is this madness really what people are doing now?\n \nreply",
      "No, not most people. But some people are experimenting.No one has found anything revolutionary yet, but there are some useful applications to be sure.\n \nreply",
      "Or, we have a hammer and we\u2019re hitting things with it to see if they\u2019re nails.\n \nreply",
      "I think this is true, with the pretext that we have never seen a hammer before and don't know what nails are yet.\n \nreply",
      "The issue is not in function calls but HOW MCP got designed here and you are using.Most MCP are replicating API. Returning blobs of data.1. This is using a lot of input context in formating as JSON and escaping a Json inside already a JSON.\n2. This contain a lot of irrelevant information that you can same on it.So the issue is the MCP tool. It should instead flaten the data as possible as it's going back again thru JSON Encoding. And if needed remove some fields.So MCP SAAS here are mainly API gateways.That brings this noise!\nAnd most of ALL they are not optimizing MCP's.\n \nreply",
      "> 1. This is using a lot of input context in formating as JSON and escaping a Json inside already a JSON.Isn't it a model problem that they don't respect complex json schemas?\n \nreply",
      "My team at Shopify just open sourced Roast [1] recently. It lets us embed non-deterministic LLM jobs within orchestrated workflows. Essential when trying to automate work on codebases with millions of lines of code.[1] https://github.com/shopify/roast\n \nreply",
      "Wow - Roast looks fantastic. You architected and put names and constraints on  some things that I've been wrestling with for a while. I really like how you are blending the determinism and non-determinism. (One thing that is not obvious to me after reading the README a couple of times (quickly), is whether/how the LLM can orchestrate multiple tool calls if necessary and make decisions about which tools to call in which order. It seems like it does when you tell it to refactor, but I couldn't tell if this would be suitable for the task of \"improve, then run tests. Repeat until done.\")\n \nreply",
      "Nice to see Ruby continuing to exist and deliver... even in the age of \"AI\"\n \nreply"
    ],
    "link": "https://jngiam.bearblog.dev/mcp-large-data/",
    "first_paragraph": ""
  },
  {
    "title": "An upgraded dev experience in Google AI Studio (googleblog.com)",
    "points": 98,
    "submitter": "meetpateltech",
    "submit_time": "2025-05-21T17:53:40 1747850020",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=44054185",
    "comments": [
      "> Gemini 2.5 Pro is incredible at coding, so we\u2019re excited to bring it to Google AI Studio\u2019s native code editor. It\u2019s tightly optimized with our Gen AI SDK so it\u2019s easier to generate apps with a simple text, image, or video prompt. The new Build tab is now your gateway to quickly build and deploy AI-powered web apps. We\u2019ve also launched new showcase examples to experiment with new models and more.This is exactly what I see coming, between the marketing and reality of what the tool is actually able to deliver, eventually we will reach the next stage of compiler evolution, directly from AI tools into applications.We are living through a development jump like when Assembly developers got to witness the adoption of FORTRAN.Language flamewars are going to be a thing of the past, replaced by model wars.It migth take a few cycles, it will come nonetheless.\n \nreply",
      "I agree. Until about 2005 it was code-on-device and run-on-device. The tools and languages were limited in absolute capabilities, but easy to understand and use. For about the past 20 years we've been in a total mess of code-on-device -> (nightmare of deployment complexity) -> run-on-cloud. We are finally entering the code-on-cloud and run-on-cloud stage.I'm hoping this will allow domain experts to more easily create valuable tools instead of having to go through technicians with arcane knowledge of languages and deployment stacks.\n \nreply",
      "Having worked on expert systems the difficulty in creating them is often the technical limitations of the end users. The sophistication of tooling needed to bridge that gap is immense and often insurmountable. I see the AI as the bridge to that gap.That said it seems like both domain expertise and the ability to create expert systems will be commoditized at roughly the same time. While domain experts may be happy that they don\u2019t need devs they\u2019ll find themselves competing against other domain experts who don\u2019t need devs either.\n \nreply",
      ">We are finally entering the code-on-cloud and run-on-cloud stage.Sounds like an absolute nightmare for freedom and autonomy.\n \nreply",
      "SWE will be renamed to AIOps :)\n \nreply",
      "but only because it is\n \nreply",
      "> This is exactly what I see coming, between the marketing and reality of what the tool is actually able to deliver, eventually we will reach the next stage of compiler evolution, directly from AI tools into applications.Is this different from other recent models trained eg for tool calling? Sounds like they fine tuned on their SDK. Maybe someday, but it's still going to be limited in what it can zero shot without you needing to edit the code.> Language flamewars are going to be a thing of the past, replaced by model wars.This does seem funny coming from you. I feel like you'll still find a way :P\n \nreply",
      "I think there will still need to be some kind of translation layer besides natural language. It's just not succinct enough (especially English, ew), especially where it matters like a rules engine.  The thought of building something like an adjudication or payment system with a LLM sounds terrible.\n \nreply",
      "You don't need to use natural language to write your rules engine. LLMs speak every language under the sun, real or made up.You could define your rules in Prolog if you wanted - that's just as effective a way to communicate them to an LLM as English.Or briefly describe some made-up DSL and then use that.For coding LLMs the goal is to have the LLM represent the logic clearly in whatever programming language it's using. You can communicate with it however you want.I've dropped in screenshots of things related to what I'm building before, that works too.\n \nreply",
      "> describe some made-up DSLIronically, for something like the parent suggested i.e. a rules engine, this is the main work.\n \nreply"
    ],
    "link": "https://developers.googleblog.com/en/google-ai-studio-native-code-generation-agentic-tools-upgrade/",
    "first_paragraph": "Google AI Studio is the fastest place to start building with the Gemini API, with access to our most capable models, including Gemini 2.5 preview models, and generative media models like Imagen, Lyria RealTime, and Veo. At Google I/O, we announced new features to help you build and deploy complete applications, new model capabilities, and new features in the Google Gen AI SDK.Gemini 2.5 Pro is incredible at coding, so we\u2019re excited to bring it to Google AI Studio\u2019s native code editor. It\u2019s tightly optimized with our Gen AI SDK so it\u2019s easier to generate apps with a simple text, image, or video prompt. The new Build tab is now your gateway to quickly build and deploy AI-powered web apps. We\u2019ve also launched new showcase examples to experiment with new models and more.Sorry, your browser doesn't support playback for this videoIn addition to app generation from a single prompt, you can continue to iterate your web app over chat. This allows you to make changes, view diffs, and even jump b"
  }
]