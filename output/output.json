[
  {
    "title": "Hacking 700M Electronic Arts accounts (battleda.sh)",
    "points": 592,
    "submitter": "mooreds",
    "submit_time": "2024-11-05T15:18:34 1730819914",
    "num_comments": 112,
    "comments_url": "https://news.ycombinator.com/item?id=42052143",
    "comments": [
      "Ea loves using generic systems across all their games. When poking around at Madden I found they have a common backend called blaze that has generic web and tcp endpoints. We built out a tool to call these endpoints (having to upload xml) and only later found out that every time we made the call it was crashing their servers but since we were grabbing a new server each request we were crashing all of their madden servers one by one. They ended up building an API to discourage people poking around\n \nreply",
      "Blaze is the name of the C++ framework/service to build custom backend for online games. It allows game team to developp online features in a standard way, it's backed by MySQL.From what I remember you need roughly one Blaze instance for 5k/10k players.\n \nreply",
      "So, like any sane person would, I overnighted an Xbox, installed Battlefield 2042, and waited for the moment of truth...\n     \n    I was in!\n\nI love hackers <3\n \nreply",
      "When I read the line, I thought \"that's the spirit!\". Kudos to him.\n \nreply",
      "I enjoyed the detailed explanation of how he moved from point to point. I imagine it wasn't as straightforward as is laid out in a blog postIt would be interesting to see what I imagine to be the reams of notes from one of these to show how much time and effort it takes to perform this kind of attack.\n \nreply",
      "For anyone who's enjoyed reading this, there's plenty more to read about on the bug bounty platforms such as HackerOne's \"Hacktivity\": https://hackerone.com/hacktivity\n \nreply",
      "There is even more here:https://pentester.land/writeups/It gets updated every few weeks/months.\n \nreply",
      "This is super cool!\n \nreply",
      "What's most wild about all of this to me is that EA has claimed for years a \"technical impossibility\" to unlink an existing Xbox account and re-link with a new one. (See https://www.reddit.com/r/XboxGamePass/comments/12gsy4i/ea_xb... and many other forum posts on EA). I ran into this wall and after spending hours on support calls with EA they were unable to link a very old Xbox account I had, meaning I can't login to any EA games on Xbox, making the majority of them unplayable on the platform. \nYet, here, we see, it is very much possible.\n \nreply",
      "Linking account with first party etc ... is pretty complicated way more than what people thing. The whole cross play  story is also a nightmare to support.\n \nreply"
    ],
    "link": "https://battleda.sh/blog/ea-account-takeover",
    "first_paragraph": ""
  },
  {
    "title": "Unix Programmer's Manual Third Edition [pdf] (1973) (dspinellis.github.io)",
    "points": 41,
    "submitter": "rbanffy",
    "submit_time": "2024-11-05T22:12:02 1730844722",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42055644",
    "comments": [
      "> the number of UNIX installations has grown to 16, with more expected.What a time.\n \nreply",
      "Third edition in 1973\n \nreply"
    ],
    "link": "https://dspinellis.github.io/unix-v3man/v3man.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Hacker Fab (hackerfab.org)",
    "points": 315,
    "submitter": "ipnon",
    "submit_time": "2024-11-05T14:59:15 1730818755",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=42051968",
    "comments": [
      "When we saw a rise in 3d printing, I was very hopeful that a hobbyist movement towards fabricating large-feature ICs would soon arise. Nobody's doing 4nm fabrication in their garage, I reasoned, but surely we could get to ~10um.As I read more about the dark art of IC fabrication, though, I realized that even this was a faint dream. I had imagined a world of lasers carving troughs, and print heads carefully placing down the lines and doping the silicon, an elegant symphony of modern technology.But the real world is much messier -- every stage involves dangerous and toxic chemicals, processes that are spoiled by a spec of dust in the wrong place, either causing a cascade of reagent failures or a physical impediment to correctness; distressingly analog and oh so messy and built by trial and error and refined by domain experts in ways that are intensely hard to replicate because all the same lessons need to be learned again each time.I'm glad to see the work being done here for hobbyist fabrication, but barring huge leaps and bounds, the gap between the neat lines in Magic and the shiny silicon discs is a vast chasm owned by the material scientists, not the electrical engineers or the software engineers.\n \nreply",
      "University labs (with the right funding) can totally do this, it's just not cheap. My university sold all its fab hardware to another university the year before I was able to take a VLSI class which at the time, had a practical lab. *> As I read more about the dark art of IC fabricationI want to push back on this being a \"dark art\" - there is no magic in engineering (nb4, any sufficiently advanced technology etc etc). It's a skillset that requires education, experience, and expertise on par with anything we do in other areas of engineering. The stakes are just a little higher than software because you're dealing with the physical world and physical things have tangible costs and/or danger.The thing that may trip people up is that IC fabrication is one of those things that doesn't really have a hobbyist tier. Anything beyond a toy requires multiple people and support staff in addition to gear and raw materials that are hard to get as any old civilian - in addition to the clean room facilities. Like the reason my university closed their lab was partly because the grad/PhD students and professors had moved on, and partly because it was becoming more difficult to source wafers for research institutions that they could actually use (everyone got hired by labs in industry, where they were making their own wafers or buying them wholesale afaict).* iirc only the penultimate project got taped out and fabbed with terrible yields due to time contraints\n \nreply",
      "It seems you have convinced me that IC fabrication is a dark art, despite your intentions.\n \nreply",
      "> I want to push back on this being a \"dark art\" - there is no magic in engineering (nb4, any sufficiently advanced technology etc etc). It's a skillset that requires education, experience, and expertise on par with anything we do in other areas of engineering. The stakes are just a little higher than software because you're dealing with the physical world and physical things have tangible costs and/or danger.I think \"engineering\" in software generally means optimizing a path to a targeted set of behaviors so that the piles of garbage underneath don't end up blocking their execution for eternity.Our starting point is therefore different. You ought to somehow be working around all the physical piles of dust and patchwork of fires that must be constantly igniting inside your laser machinery. I picture it something like the mad surgeon in Minority Report, creating a small transient sterile environment to do illegal eye surgery in a room full of filth.In that light your \"art\" looks \"dark.\"\n \nreply",
      "I don't really know much about ic manufacturing.Are you sure university labs are really able to to this? If so how come only a few companies like tsmc and that one Dutch company are able to manufacture microchips? Or are those two completely different things and I'm just confusing myself?\n \nreply",
      "> Are you sure university labs are really able to to this?Yes, I know of multiple universities that have labs for small scale IC production. In fact anywhere doing research in the field will have some ability to build these things, or access to the industrial labs nearby. Even in industry, there are small scale labs that are used to develop the processes before they get built out at scale.> If so how come only a few companies like tsmc and that one Dutch company are able to manufacture microchips?There are thousands of chip manufacturers worldwide. TSMC is just the largest/most cutting edge. ASML is the company that makes special tools for IC manufacturing (however, researchers can/do experiment with the things that ASML is doing on smaller scales).But keep in mind - no researcher at a university is trying to manufacture millions of 3nm CPUs for next year's iPhone. Just as an example, today we have GaN switches in our 100+W USB-C chargers that fit in your pocket. That directly came from university and industry research in small scale labs into high bandgap semiconductors, which was developed by fabbing real circuits and testing them.\n \nreply",
      "That's at the very highest end. As the element size gets larger there are more fabs capable of doing the work. The equipment gets slightly more standardized, etc., although ASML (the Dutch company) is still the big dog in the equipment space.But even running a small-scale fab spitting out 7400 series chips and 555's is still pretty serious business; you need chemical engineers and material scientists as well as electrical engineers and software engineers (and multidisciplinary versions of those people) to keep things running at all. And nobody can do this stuff out of college -- everyone has extensive apprenticeships and practical experience working in other fabs because so much of the process is knowhow rather than technical specifications.\n \nreply",
      "There is a wide gap between TSMC's cutting edge processes and what a university lab would produce. The features on the microchip go from a couple nanometers (TMSC cutting edge) to tens of micrometers (1000-10000x larger). Large size means less transistors, but million instead of billions still is plenty for large complex chips, just not cutting edge.\n \nreply",
      "The trillion-dollar-hard part is doing it profitably at scale. Drop that constraint and nearly any feature size is \"only\" million-dollar-hard (maybe 10M or 100M to run a R&D shop).You can poke and prod anything into place with e-beams and FIBs and manually dipping wafers in baths and ovens and such. 1% yield, hour long write times, and all sorts of R&D jank are perfectly fine for checking functionality of your fancy ultra-FET design or making a ring oscillator to simulate integration. Did a grain of dust land on the wafer and ruin 100 of them? No prob, use the other 300, just try not to let it happen again. But integrating a billion transistors, coordinating them to do a billion calculations per second, QAing them to work for a billion seconds with 0 errors, and manufacturing them to profitably sell at $100 a pop? No jank allowed, no small scale antics allowed, and your budget now requires all the zeros it can find and more besides.\n \nreply",
      "Semiconductor Fabs have come a long way. The Shockley Semiconductor Laboratory opened for business in a small commercial lot in Mountain View in 1956.  https://www.researchgate.net/figure/Shockley-Semiconductor-L...There was lots of older or used equipment Universities could buy before Fabs started being millions of square feet with hundreds of million dollar pieces of equipment.\n \nreply"
    ],
    "link": "https://docs.hackerfab.org/hacker-fab-space",
    "first_paragraph": ""
  },
  {
    "title": "U.S. chip revival plan chooses sites (ieee.org)",
    "points": 63,
    "submitter": "pseudolus",
    "submit_time": "2024-11-05T20:14:02 1730837642",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=42054779",
    "comments": [
      "Wolfspeed is building a fab in North Carolina that will make SiC based chips. They are receiving $750 million from the CHIPS and Science Act and will likely receive another $1 billion in tax credits.https://en.wikipedia.org/wiki/CHIPS_and_Science_ActSiC transistors and diodes are used in high power applications like locomotives, EV chargers and industrial motor controls. In their catalog they have a half-bridge power module rated for 1200V and 760A, which to me is amazing that a semiconductor can handle that much.https://www.wolfspeed.com/products/power/sic-power-modules/h...\n \nreply",
      "> which to me is amazing that a semiconductor can handle that much.i'm also equally amazed at how much <5v can accomplish. 3.3v is common, but I also think back to the old NTSC video signal was 1v peak-to-peak. Of course, that was just the signal and not the voltage driving the CRT, but still impressive. I've done my own hobby electronics ala Arduino type stuff, and detecting voltage drops in analog of <1v can be challenging to do accurately.\n \nreply",
      "Well the revival may be halted depending on the election:> The US CHIPS and Science Act's future may depend on the outcome of Tuesday's Presidential Election after House Speaker Mike Johnson suggested the GOP would likely move to repeal the $280 billion funding bill if the party wins a majority in Congress.* https://www.theregister.com/2024/11/04/chips_act_repeal/but a little while later:> Johnson, who voted against the legislation, later said in a statement that the CHIPS Act, which poured $54 billion into the semiconductor manufacturing industry, \u201cis not on the agenda for repeal.\u201d* https://apnews.com/article/mike-johnson-chips-act-d5504f76d3...so \u00af\\_(\u30c4)_/\u00af\n \nreply",
      "Micron is a defense critical company. They're getting their new fab no matter what because China can more readily target Boise.\n \nreply",
      "My understanding is that Micron only does R&D in Boise, they don't run any production manufacturing there.\n \nreply",
      "What makes Boise a more readily available target for China?\n \nreply",
      "Their medium range ICBMs, which they have greater inventory of, can reach the northwest.\n \nreply",
      "Sorry, what decision are you saying is being made because China can nuke Boise more easily than other places? Are you envisioning a limited tactical strike by China that bombs half the country but leaves the Eastern seaboard militarily relevant?\n \nreply",
      "If you have a limited number of long range ICBMs then you will likely prefer more directly military targets rather than a manufacturing facility which would likely only start to matter for a conflict months into combat, which itself is a scenario (drawn out conventional war) that is likely precluded by exchange of nuclear weapons in the first place.\n \nreply",
      "> If you have a limited number of long range ICBMsChina has hundreds going on thousands of ICBMs. Nobody is creating redundancy from Boise to Albany and Sunnyvale to increase survivability in case of a nuclear exchange between America and China.\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/nstc",
    "first_paragraph": "The November 2024 issue of IEEE Spectrum is here!Albany and Silicon Valley land two of three National Semiconductor Technology Center locationsSamuel K. Moore is IEEE Spectrum\u2019s semiconductor editor.The NSTC's EUV center will be at the Albany Nanotech Complex, where IBM already does lithography research.Last week the organization tasked with running the the biggest chunk of U.S. CHIPS Act\u2019s US $13 billion R&D program made some significant strides: The National Semiconductor Technology Center (NSTC)  released a strategic plan and selected the sites of two of three planned facilities and released a new strategic plan. The locations of the two sites\u2014a \u201cdesign and collaboration\u201d center in Sunnyvale, Calif., and a lab devoted to advancing the leading edge of chipmaking, in Albany, N.Y.\u2014build on an existing ecosystem at each location, experts say. The location of the third planned center\u2014a chip prototyping and packaging site that could be especially critical for speeding semiconductor startu"
  },
  {
    "title": "The Eternal Mainframe (2013) (winestockwebdesign.com)",
    "points": 20,
    "submitter": "w3ll_w3ll_w3ll",
    "submit_time": "2024-11-05T22:00:05 1730844005",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.winestockwebdesign.com/Essays/Eternal_Mainframe.html",
    "first_paragraph": "\r\n            In the computer industry, the \r\n                Wheel of Reincarnation is a pattern whereby specialized hardware gets spun out from the \u201cmain\u201d system, becomes more powerful, then gets folded back into the main system. As the linked Jargon File entry points out, several\r\n            generations of this effect have been observed in graphics and floating-point coprocessors.\r\n            In this essay, I note an analogous pattern taking place, not in peripherals of a computing platform, but in the most basic kinds of \u201ccomputing platform.\u201d And this pattern is being driven as much by the desire for \u201cfreedom\u201d as by\r\n            any technical consideration.\r\n        \r\n                \u201cRevolution\u201d has many definitions. From the looks of this, I'd say \u201cgoing around in circles\u201d comes closest to applying...\r\n                -Richard M. Hartman\r\n            A funny thing happened on the way to the future. The mainframe outlasted its replacements.\r\n            Minicomputers were suppos"
  },
  {
    "title": "Lisp Query Notation (LQN) (inconvergent.net)",
    "points": 32,
    "submitter": "surprisetalk",
    "submit_time": "2024-10-31T14:46:59 1730386019",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://inconvergent.net/2024/lisp-query-notation/",
    "first_paragraph": ""
  },
  {
    "title": "AMD outsells Intel in the datacenter space (tomshardware.com)",
    "points": 280,
    "submitter": "baal80spam",
    "submit_time": "2024-11-05T19:27:15 1730834835",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=42054449",
    "comments": [
      "Oh my, allow me to reminisce.When the Intel 80386-33 came out we thought it was the pinnacle of CPUs, running our Novell servers!   We now had a justification to switch from arcnet to token ring.  Our servers could push things way faster!Then, in the middle 1991, the AMD 80386-40 CPU came out.  Mind completely blown!  We ordered some (I think) Twinhead motherboards. They were so fast we could only use Hercules mono cards in them; all other video cards were fried.  16Mb token ring was out, so some of my clients moved to it with the fantastic CPU.I have seen some closet-servers running Novell NetWare 3.14 (?) with that AMD CPU in the late '90s.  There was a QUIC tape & tape drive in the machine that was never changed for maybe a decade?  The machine never went down (or properly backed up).\n \nreply",
      "NW 3.12 was the final version I think.  I recall patching a couple for W2K.  NetWare would crash a lot (abend) until you'd fixed all the issues and then it would run forever, unless it didn't.I once had a bloke writing a patch for eDirectory in real time in his basement whilst running our data on his home lab gear, on a weekend.  I'm in the UK and he was in Utah.  He'd upload an effort and I'd ftp it down, put it in place, reboot the cluster and test.  Two iterations and job done. That was quite impressive support for a customer with roughly 5,000 users.For me the CPU wasn't that important, per se.  NWFS ate RAM: when the volumes were mounted, the system generated all sorts of funky caches which meant that you could apply and use trustee assignments (ACLs) really fast.  The RAID controller and the discs were the important thing for file serving and ideally you had wires, switches and NICs to dole the data out at a reasonable rate.\n \nreply",
      "Some AMD 80386DX-40 drama:> While the AM386 CPU was essentially ready to be released prior to 1991, Intel kept it tied up in court.[2] Intel learned of the Am386 when both companies hired employees with the same name who coincidentally stayed at the same hotel, which accidentally forwarded a package for AMD to Intel's employee.[3]\n \nreply",
      "Wonder if the hotel had a liability problem from that?After all, it sounds like they directly caused a \"billion dollar\" type of problem for AMD through their mistake.\n \nreply",
      "Far out LOLThat's amazing!\n \nreply",
      "Token ring networks! So glad we moved on from that.\n \nreply",
      "Quick! Everyone! Someone dropped the token. Get up and look behind your desks.\n \nreply",
      "I remember that 386-40. That was a great time.\n \nreply",
      "I'm not a HW guy but my HW friends have been designing HCI solutions with AMD for maximum IO throughput because AMD CPUs have more PCI lanes.\n \nreply",
      "I think for _most_ people it comes down to this: how much can I cram into the platform. More lanes is more high speed storage, special purpose processing, and networking interfaces.\n \nreply"
    ],
    "link": "https://www.tomshardware.com/pc-components/cpus/for-the-first-time-ever-amd-outsells-intel-in-the-datacenter-space",
    "first_paragraph": "But both fall far behind sales of Nvidia's AI GPUs.\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nFor well more than two decades, Intel has been the undisputed leader in the market for datacenter CPUs. Intel's Xeon processors powered the vast majority of servers, whereas AMD's processors commanded a single-digit market share just some seven or eight years ago. However, the situation has changed drastically. While Intel's Xeon CPUs still power the majority of servers, the most expensive machines now use AMD's EPYC processors. This is why AMD's datacenter business unit now outsells Intel's datacenter and AI business group, as observed by\u00a0SemiAnalysis.Indeed, AMD's datacenter segment revenue reached\u00a0$3.549 billion\u00a0in the third quarter, whereas Intel's datacenter and AI group's earnings were\u00a0$3.3 billion\u00a0in Q3 2024. Just two years ago, Intel's DCAI group earned $5 billion - $6 billion per quarter. But as AMD's EPYC processors have ga"
  },
  {
    "title": "Every boring problem found in eBPF (2022) (tmpout.sh)",
    "points": 98,
    "submitter": "udev4096",
    "submit_time": "2024-11-01T15:50:56 1730476256",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42018195",
    "comments": [
      "BPF recently got published as an RFC[1], posted here[2] today and earlier here[3][4].[1]: https://datatracker.ietf.org/doc/html/rfc9669[2]: https://news.ycombinator.com/item?id=42051950[3]: https://news.ycombinator.com/item?id=42024377[4]: https://news.ycombinator.com/item?id=42038371\n \nreply",
      "This is so weird to me. It's not an interoperable standard. It isn't even interoperable on Linux, the one OS where it's popular.\n \nreply",
      "If you wanted it to become an interoperable standard, that's the obvious step, right?\n \nreply",
      "There is an explanation here: https://lwn.net/ml/all/20241105035101.GD41004@maniforge/\n \nreply",
      "Right, for offload, but XDP programs also depend on helper definitions, which themselves have not been consistent between versions of the Linux kernel.\n \nreply",
      "And some (most?) of the helpers end up being \"read memory at X\", which has some obvious problems with offloading.\n \nreply",
      "I mean, there really is working XDP offload (Netronome, right?) so it can be made to work, but this spec doesn't define the hardest part of interoperability.\n \nreply",
      "By the way, this article is published as part of the tmp.0ut zine, and the CFP for the next issue is currently open: https://tmpout.sh/blog/vol4-cfp.html\n \nreply"
    ],
    "link": "https://tmpout.sh/2/4.html",
    "first_paragraph": ""
  },
  {
    "title": "Algorithm = Logic and Control [pdf] (ic.ac.uk)",
    "points": 11,
    "submitter": "acmerfight",
    "submit_time": "2024-10-31T10:00:07 1730368807",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.doc.ic.ac.uk/~rak/papers/algorithm%20=%20logic%20+%20control.pdf",
    "first_paragraph": ""
  },
  {
    "title": "More Oracle Layoffs Started Nov. 1, Cloud Unit Impacted (channelfutures.com)",
    "points": 22,
    "submitter": "DenisM",
    "submit_time": "2024-11-06T00:04:46 1730851486",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.channelfutures.com/channel-business/more-oracle-layoffs-started-nov-1-cloud-unit-impacted#",
    "first_paragraph": ""
  },
  {
    "title": "Failure analysis of the Arecibo 305 meter telescope collapse (nationalacademies.org)",
    "points": 187,
    "submitter": "mhb",
    "submit_time": "2024-11-05T13:37:42 1730813862",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=42051368",
    "comments": [
      "In the summary they state:All the reported experimental zinc electroplasticity (EP) data were developed at current densities orders of magnitude higher than those possibly present in the Arecibo Telescope but measured in laboratory experimental periods that were orders of magnitude shorter than the telescope's socket zinc service.There are no reported experimental data concerning low-current, long-term EP, which the committee has lumped together under the term \"LEP\", affecting zinc's creep mechanisms over decades.The timing and patterns of the Arecibo Telescope's socket failures make the LEP hypothesis the only one that the committee could find that could potentially explain the failure patterns observed.Accelerated aging is, as far as I know, pretty much standard in the industry. Nobody can wait 20 years to find out if a certain material is good enough or not.However, the real failure seems to be the lack of urgency when they signs started to show up:Upon reflection, the unusually large and progressive cable pullouts of key structural cables that could be seen during visual inspection several months and years before the M4N failure should have raised the highest alarm level, requiring urgent action. The lack of documented concern from the contracted engineers about the inconsequentiality of the cable pullouts or the safety factors between Hurricane Maria in 2017 and the failure is alarming.\n \nreply",
      "> The lack of documented concern from the contracted engineers about the inconsequentiality of the cable pullouts or the safety factors between Hurricane Maria in 2017 and the failure is alarming.This is crazy. Basically cables were pulling out for months and years and no one raised the alarm? In many industries that could be a criminal or career ending malpractice. Are the \"contracted engineers\" liable?\n \nreply",
      "You go to school and learn that 2+2=4. You get a consulting job and learn 2+2= whatever the client says it is.I wouldn\u2019t jump to the conclusion that the consulting engineer was incompetent. Sometimes a bureaucrat tells you to sharpen your pencils and come back with the answer That fits the budget they have if you want to keep your professional services contract going.\n \nreply",
      "Since the design had a factor of safety of 2, and no other cables exhibited pull out at such high safety factors, checking such things might not even have been on the checklist.\n \nreply",
      "In chapter 5 they go into how the ownership was transferred to the University of Central Florida (UCF) at the start of 2018, after the hurricanes in 2017.It seems unlikely that UCF had adequate time and resources to review and understand the Arecibo Telescope's original 1963 design, the 1974 upgrade, the structural inspection and maintenance records produced for nearly 50 years, [...] and the key factors, such as the wire breaks and cable pullout of the sockets and their significance on the strength and integrity of the structure.The measured cable pullout may have appeared \"normal\" to [the UCF staff] and was not on their radar as signs of structural distress. The lack of concern may be because a small cable pullout was present from the beginning, and no one in authority had previously raised an alarmBut yeah, seems weird no-one of the contractors tried to raise an alarm.\n \nreply",
      "I bet there\u2019s a r/MaliciousCompliance in Spanish out there somewhere about how UCF cancelled existing maintenance contracts and hired new companies to keep an eye on the equipment, and did it so rudely that the old company didn\u2019t hand over important warnings like this.Discontinuity could explain problems like this readily.\n \nreply",
      "But that would have required spending money.  And why would the engineers be liable?  They weren't being paid to fix it.\n \nreply",
      "> Basically cables were pulling out for months and years and no one raised the alarm?And what if they did?  Then what?  My guess is the conversation went something like this:\"Okay, cables are pulling out.  Raising this issue will not magically make money appear to fix it as nobody wants to fund this.  Tell me, how much do you like your job?  If you flag this, you may lose your job directly and if the project gets shut down you may lose your job indirectly.  So, how about we bury this as much as possible, cross our fingers and bank as much money as possible in the meantime, eh?\"\n \nreply",
      "These are Professional Engineers, not your run of the mill fake 'engineer' in software development. They have licenses and certifications. They don't just ship bugs. When they say that something is fine, it is fine. They have certifications. They have licenses. They are professionals. If something failed, it must have been management. Professional Engineers do not make mistakes. They are real engineers.\n \nreply",
      "As someone who works in a company with 10,000+ professional engineers*: yes, yes they do make mistakes. Despite what you seem to think, they are actually human beings. Good processes understand this and have multiple layers to catch and correct mistakes. But it's hard to fight limited data. Plenty of engineering decisions are still made based on numbers in photocopied tables from two or three studies from 50 years ago, each having a dozen or two data points. It's surprising how limited some of the data is that these Professional Engineers are basing their decisions on.*Edit: okay, I don't know exactly how many are officially PEs vs. junior engineers or something, but at least that many are \"PE-track\".\n \nreply"
    ],
    "link": "https://nap.nationalacademies.org/read/26982/chapter/1",
    "first_paragraph": " MyNAP members SAVE 10% off online.\n            Not a MyNAP member yet?  Register for a free account  to start saving and receiving special member only perks.  Below is the uncorrected machine-read text of this chapter, intended to provide our own search engines and external engines with highly rich, chapter-representative searchable text of each book. Because it is UNCORRECTED material, please consider the following text as a useful but insufficient proxy for the authoritative book pages.Failure Analysis of the\nArecibo Observatory 305-Meter\nTelescope Collapse\n\n\n\n\nCommittee on Analysis of Causes of Failure\nand Collapse of the 305-Meter Telescope at\nthe Arecibo Observatory\n\nBoard on Infrastructure and the Constructed\nEnvironment\n\nDivision on Engineering and Physical Sciences\n\n\n\n\n                                                 Consensus Study Report\n            PREPUBLICATION COPY\u00e2\u0080\u0094SUBJECT TO FURTHER EDITORIAL CORRECTION\n\fNATIONAL ACADEMIES PRESS 500 Fifth Street, NW Washington, DC 200"
  },
  {
    "title": "Show HN: Whirlwind \u2013 Async concurrent hashmap for Rust (github.com/fortress-build)",
    "points": 98,
    "submitter": "willothy",
    "submit_time": "2024-11-05T18:02:18 1730829738",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=42053747",
    "comments": [
      "I don't think I'd recommend using this in production. The benchmarks look good, but by immediately waking the waker[0], you've effectively created a spin-lock. They may work in some very specific circumstances, but they will most likely in practice be more costly to your scheduler (which likely uses locks btw) than just using locks[0]: https://github.com/fortress-build/whirlwind/blob/0e4ae5a2aba...\n \nreply",
      "+1. I'd be curious how much of a pessimization to uncontended workloads it'd be to just use `tokio::sync::RwLock`.and, if we want to keep it as a spinlock, I'm curious how much the immediate wakeup compares to using `tokio::task::yield_now`: https://docs.rs/tokio/latest/tokio/task/fn.yield_now.html\n \nreply",
      "This is an interesting idea. I am gonna try this out - especially with dashmap, I think that could perform very well.\n \nreply",
      "You could also look into shamelessly \"taking inspiration\" from async-lock.\n \nreply",
      "I don't believe that waking the waker in `poll` synchronously waits / runs poll again immediately. I think it is more likely just adding the future back to the global queue to be polled. I could be wrong though, I'll look into this more. Thanks for the info!\n \nreply",
      "It does immediately put itself into the queue to be polled again. But that's no different in effect to a spin-lock. If you have other tasks in your runtime, this will be putting excess pressure on your scheduler\n \nreply",
      "Expanding on this. If you have a lot of concurrent tasks, you will overflow[0] the task local queue and be bottlenecked by the global queue mutex[1][0]: https://github.com/tokio-rs/tokio/blob/8897885425bf3d89053f8... \n[1]: https://github.com/tokio-rs/tokio/blob/8897885425bf3d89053f8...\n \nreply",
      "Oh this is really good to know, thank you!\n \nreply",
      "Another offender is AtomicWaker [1] which does the same on contention.[1] https://docs.rs/atomic-waker/latest/atomic_waker/\n \nreply",
      "AtomicWaker is much less bad, because it will only spin in the case that another thread has spuriously called `wake` \u2013 i.e. called `wake` despite that fact that the future it\u2019s waking is in fact unable to progress.In the common case, the waker side will operate some logic like:    set_flag();\n    atomic_waker.wake();\n\nand the future will run:    atomic_waker.register(cx.waker());\n    if flag_is_set() {\n        Poll::Ready(())\n    } else {\n        Poll::Pending\n    }\n\nThus, even if `register` decides to \u201cspin\u201d, the flag will already be set, and so the future will not spin in reality (it may be polled unnecessarily, but this will only happen once).I can\u2019t immediately think of examples where support for spurious waking is necessary.\n \nreply"
    ],
    "link": "https://github.com/fortress-build/whirlwind",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83c\udf00 Ridiculously fast, fully asynchronous, sharded hashmap for Rust.\n      \n\n\nAn asynchronous, sharded HashMap for high-performance concurrent data access\nin Rust.NoteThis crate is in development, and breaking changes may be made up until a 1.0 release.Add whirlwind to your Cargo.toml:Here's a quick example to get you started:Benchmarks were run in a asyncified version of this benchmark. You can\nfind it here. Since the benchmarks use jonhoo/bustle,\nan asyncified fork of that library (here) is required.Machine: Apple M3 Max (2023 16-inch MacBook Pro, 36GB RAM)OS: macOS 15.0See the results/ directory.Contributions are welcome! Please follow these steps:Ensure all tests pass before submitting a PR:We use rustfmt for code formatting:Copyright 2024 Will HopkinsLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use "
  },
  {
    "title": "Vega's Puzzling Disk (centauri-dreams.org)",
    "points": 37,
    "submitter": "JPLeRouzic",
    "submit_time": "2024-11-05T19:43:34 1730835814",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.centauri-dreams.org/2024/11/05/vegas-puzzling-disk/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I wrote an open-source browser alternative for Computer Use for any LLM (github.com/gregpr07)",
    "points": 116,
    "submitter": "gregpr07",
    "submit_time": "2024-11-05T15:51:43 1730821903",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=42052432",
    "comments": [
      "Is it decided then that screenshots are better input for LLMs than HTML, or is that still an active area of investigation? I see that y'all elected for a mostly screenshot-based approach here, wondering if that was based on evidence or just a working theory.\n \nreply",
      "Not sure, I think there is a lot of research being done here.Actually, browser use works quite well with vision turned off, it just sometimes gets stuck at some trivial vision tasks. The interesting thing is that screenshot approach is often cheaper than cleaned up html, because some websites have HUGE action spaces.We looked at some papers (like ferret ui) but i think we can do much better on html tasks. Also, there is a lot of space to improve the current pipeline.\n \nreply",
      "Would be really cool if you could tie this into Claude's computer use APIs!\n \nreply",
      "Do you think they do any super fancy magic other than for example how ferret ui does their classification of ui elements? It could be very interesting to test head to head hope much better you can make computer use by adding html (it\u2019s much better from our quick testing, just don\u2019t know the numbers).\n \nreply",
      "Next step is to represent also the structure of the HTML tree in the extracted elements for better understanding, maybe images are then less needed.\n \nreply",
      "Screenshots aren't as accurate or context-rich as HTML, but they let you bypass the hassle of building logic for permissions and authentication across different apps to pull in text content for the LLM.\n \nreply",
      "Can\u2019t you just make a browser extension to haveaccess to the HTML and CSS, and use LLMs from that?\n \nreply",
      "I do this for my extension [0] but the HTML is often too large for context window sizes . I end up doing scraping of the relevant pieces before sending to LLM.[0] https://chromewebstore.google.com/detail/namebrand-check-for...\n \nreply",
      "Context length + API cost is right now main bottleneck for huge HTML + CSS files. The extraction here is already quite efficient but still: \nwith past messages + system prompt + sometimes extracted text + extracted interactive elements you are quickly already around 2500 tokens (for gpt-4o 0.01$).If you extract entire HTML and CSS your cost + inference time are quickly 10x.\n \nreply",
      "Aren't screenshots far larger than this?\n \nreply"
    ],
    "link": "https://github.com/gregpr07/browser-use",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open-Source Web Automation library with any LLM\n      \n\nLet LLMs interact with websites naturallyKey Features \u2022\nLive Demos \u2022\nQuick Start \u2022\nExamples \u2022\nModelsWatch Browser-Use tackle real-world tasks:Prompt: Go to kayak.com and find a one-way flight from Z\u00fcrich to San Francisco on 12 January 2025.Prompt: Opening new tabs and searching for images for these people: Albert Einstein, Oprah Winfrey, Steve Jobs. Then ask me for further instructions.Create a virtual environment and install the dependencies:Add your API keys to the .env file.You can use any LLM model that is supported by LangChain by adding correct environment variables. Head over to the langchain models page to see all available models.You can persist the browser across multiple agents and chain them together.You can use the history to run the agents again deterministically."
  },
  {
    "title": "Only 5.3% of US welders are women. After years as a professor, I became one (theconversation.com)",
    "points": 25,
    "submitter": "Michelangelo11",
    "submit_time": "2024-11-06T00:24:48 1730852688",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://theconversation.com/only-5-3-of-welders-in-the-us-are-women-after-years-as-a-writing-professor-i-became-one-heres-what-i-learned-240431",
    "first_paragraph": "\n      Professor of Rhetoric and Professional Communication, Iowa State University\n    I work for Howe's Welding and Metal Fabrication part-time, as I discuss in my article.Iowa State University provides funding as a member of The Conversation US.View all partnersAlthough I have a good gig as a full professor at Iowa State University, I\u2019ve daydreamed about learning a trade \u2013 something that required both my mind and my hands. So in 2018, I started night courses in welding at Des Moines Area Community College. For three years, I studied different types of welding and during the day worked on a book about the communication between welding teachers and students. I wasn\u2019t the only woman who became interested in trades work during this time. Recognizing the good pay and job security, U.S. women have moved in greater numbers into skilled trades such as welding and fabrication within the past 10 years. From 2017 to 2022, the number of women in trades rose from about 241,000 to nearly 354,000. "
  },
  {
    "title": "Traceroute Isn't Real (gekk.info)",
    "points": 47,
    "submitter": "radeeyate",
    "submit_time": "2024-11-05T20:22:34 1730838154",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42054835",
    "comments": [
      "The challenge with any tool that uses the probe traffic other than the traffic of interest is that the results may be specific to the probe traffic and completely different from the one you care about.In theory, iOAM (https://datatracker.ietf.org/doc/rfc9326/) is a much more robust mechanism.In practice, internet works on the least common denominator, which means that Traceroute (which is a clever hack on top of the ICMP TTL exceeded behavior, a required internet standard) is often the best one can have, if at all. (And if not, then one has to resort to uglier hacks)That said - one should not underestimate how much info one can dig out by varying  TTL/hop count, changing the 5-tuple (source and destination address and ports + protocol), and tweaking the packet rate.And the dismissive attitude about \u201cabsolutely impossible to do anything with this info unless you are Fortune 500\u201d is wrong. For a counter example of cooperation between the \u201cpeople of the internet\u201d, here\u2019s a nice presentation:https://youtu.be/G_Ir_gRlst0?feature=sharedAs one can derive from the above - it\u2019s absolutely possible, just that the level of SNR required to be reacted to is rather high, well above \u201cmy Traceroute is not showing what I think it should be showing\u201d. Which, given the population of the internet, isn\u2019t entirely unreasonable.\n \nreply",
      "I wish MTR (My Traceroute) was standard in all operating systems.  It offers a number of benefits over Traceroute. MTR essentially combines the functionalities of traceroute and ping, providing a more comprehensive and dynamic view of network paths and performance.MTR runs continuously, gathering real-time stats that reveal both packet loss and latency trends over time.  MTR provides minimum, average, and maximum response times, plus the standard deviation. This is especially useful for troubleshooting intermittent issues or spotting latency spikes.Of course, MTR isn\u2019t perfect and still faces some of the same challenges as traceroute, like dealing with ICMP rate-limiting, load-balanced paths, or certain network setups that obscure hops. But overall, it provides a richer, more nuanced view, making it a preferred tool for network diagnostics and troubleshooting.\n \nreply",
      "Plus one for MTR, it\u2019s a great tool. Not perfect, but great.\n \nreply",
      "For all that it mentions common misconceptions, the article is still wrong in at least 3 ways:First, traceroutes can, if you control both endpoints, place bounds on where a network error is.Second, traceroute is useful if there are three endpoints and you control at least 2 of them.Thirdly, you do in fact know something about other people's networks by the mere fact that you've traversed the network before at different times.\n \nreply",
      "Traceroute isn't real, I like this, sounds like something I'd say.\nBut it is real, it's definitely real, it's installed on my laptop, it's probably installed on yours.\nI know fairly well how it works, understand many of its short comings, but I still love a traceroute, as does absolutely everyone even most people who truly understand it, or it really wouldn't exist. \nI am a visual understander, a picture paints a thousand words, even a distorted unreliable picture with a handful of details that are sometimes useful hiding amongst a great deal of irrelevant nonsense is sometimes better than nothing at all.It's not an ugly hack it's a beautiful elegant solution to the problem of not knowing how your traffic is mostly probably being routed.\n \nreply",
      "Traceroute is often useful because it almost always diagnoses LAN vs. WAN issues.  Since most home routers/modems will send TTL Exceeded and so will most edge ISP routers, it is often the quickest way to see where the problem is when there is little or no connectivity.\n \nreply",
      "Good article. Reminded me of a time when I was told that a server was taking over 2 minutes to respond and they proved it with traceroute.They were running \"time traceroute host\"\n \nreply",
      ">  One of the \"chapters\" in my presentation was about traceroute, and it more or less said \"Don't use it, because you don't know how, and almost nobody you'll talk to does either, so try your best to ignore them.\" This is not just my opinion, it's backed up by people much more experienced than me. For a good summary I highly recommend this presentation.I'm being pedantic but this paragraph was bizarre to read.  You are basically telling us we or anyone we know won't know enough about traceroute not to use it but you and many people you know do know enough.  It is presumptuous but also inconsistent.  Are there people who know, or not?\n \nreply",
      "It had its use, back then it was mostly intranets, so it was useful, back then there werent much concepts of spoofing, vpn, tor like layering and routing, encapsulation, etc\nYes in modern world on public internet it might not be much usefulBut still it gives basic overview a starting point for any forensic investigation or debugging network problemns\n \nreply",
      "I always thought it was a bit humorous Ethernet has a more standardized and defined traceroute functionality than IP as part of https://en.wikipedia.org/wiki/IEEE_802.1ag (typically only found in carrier Ethernet solutions in practice though).\n \nreply"
    ],
    "link": "https://gekk.info/articles/traceroute.htm",
    "first_paragraph": "gekk.info \u00ab articlesThere is no such thing as traceroute.I used to deliver network training at work. It was freeform, I was given wide latitude to design it as I saw fit, so I focused on things that I had seen people struggling with - clearly explaining VLANs in a less abstract manner than most literature, for instance, as well as actually explaining how QoS queuing works, which very few people understand properly.One of the \"chapters\" in my presentation was about traceroute, and it more or less said \"Don't use it, because you don't know how, and almost nobody you'll talk to does either, so try your best to ignore them.\" This is not just my opinion, it's backed up by people much more experienced than me. For a good summary I highly recommend this presentation.But as good as that deck is, I always felt it left out a crucial piece of information: Traceroute, as far as the industry is concerned, does not exist.Look it up. There is no RFC. There are no ports for traceroute, no rules in fir"
  },
  {
    "title": "Tracking down a mysterious skateboarder from 1979 (ncrabbithole.com)",
    "points": 146,
    "submitter": "zdw",
    "submit_time": "2024-11-05T22:00:19 1730844019",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=42055558",
    "comments": [
      "One of the interesting things about this whole story is that Tony Hawk was born the year before Shaunda was, making them both 56 this year. Interesting that they were (in a way) contemporaries.\n \nreply",
      "> Also, she had to learn what it meant to ride \u201cgoofy footed.\u201d It\u2019s when you ride a board with your right foot forward instead of your left. \u201cOh,\u201d Shaunda says. \u201cWell, I am left-handed.\u201dI am right handed but would ride a skateboard the same way. I never even tried with my left foot forward. Even visualizing it feels wrong. I wonder why this is the apparently uncommon stance? Some people I think prefer to use their dominant foot to push, but it\u2019s easier to keep my balance when my dominant foot is on the board.\n \nreply",
      "Stance for board sports is nearly even, one analysis shows 56% regular vs 44% goofy [1].  It's not like handedness at all.  Not sure why one was designated \"normal\" and the other \"weird\" when it's so close.  My guess is that there was a very small group of skaters that came up with the name, and by chance most of them happened to be regular.1. https://blog.benw.xyz/2013/11/the-real-goofy-vs-regular-a-lo...\n \nreply",
      "One theory is that \"goofy-footed\" came from the way Goofy surfed in an old Walt Disney cartoon: https://www.pacificlongboarder.com/news/Did-you-know-The-ter...\n \nreply",
      "Oh yeah, I forgot about that\n \nreply",
      "Naming things is weird. In movement/dance description, the name of the typical walk is \"contrabody\", but if you move your right arm with your right leg, that's called \"natural\".\n \nreply",
      "The classic way to tell if you're regular or goofy is to close your eyes and have someone shove you from behind, see which foot you try and catch yourself with. Probably works better if you don't know the shove is coming.\n \nreply",
      "I skateboard \"regular\" but snowboard \"goofy\". Not that I'm amazing at either, but that's just what felt natural to me for each.\n \nreply",
      "+1 on goofy snowboard. Just feel right.\n \nreply",
      "> I am right handed but would ride a skateboard the same way.Yup was going to comment that I didn't know if left-handed were more likely to be goofy but back in my skateboarding days I definitely had right-handed friends who were goofy instead of regular.> ... but it\u2019s easier to keep my balance when my dominant foot is on the boardMy daughter (who's not goofy but reglar), for a reason I don't understand, prefer to push with her front foot while keeping her back foot on the board. It's not how I told her.\n \nreply"
    ],
    "link": "https://www.ncrabbithole.com/p/tony-hawk-fayetteville-nc-girl-skateboarder-1979",
    "first_paragraph": ""
  },
  {
    "title": "Mozilla is eliminating its advocacy division (theverge.com)",
    "points": 79,
    "submitter": "doener",
    "submit_time": "2024-11-05T23:04:45 1730847885",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42055979",
    "comments": [
      "A lot of people here will react to the advocacy cuts, and the idea that advocacy make up such a large portion of the workforce.30 percent seemed like a lot, but I think it's just 30 percent of the foundation's direct staff. I suspect the corporation employs more people than the foundation? So stuff like development is not included in that count.I do wonder if the cuts are because of anticipation of lower search revenue from Google with tech restricting legislation on the horizon and google's focus pivoting to AI.\n \nreply",
      "dupe: https://news.ycombinator.com/item?id=42054867\n \nreply",
      "The workers should fire the execs and convert Mozilla into a democratically controlled worker-owned company.\n \nreply",
      "[dupe]Earlier: https://news.ycombinator.com/item?id=42054867\n \nreply",
      "Hopefully they'll replace them with people who'll make firefox better.\n \nreply",
      "I doubt it.  This company seems to have major structural problems, and cutting some stuff here and there isn't going to fix it.  Its expenses are huge, and it pays its executives obscene amounts of money, and meanwhile they've been wasting tons of money on stuff like Pocket, AI crap, and now they're pissing off supporters by getting into ads.I think what we really need is for a new company to get started in some other country, where the cost of living and the cost of executive salaries is much, much cheaper.  Have that company fork the Firefox codebase, and then only concentrate on Firefox (Newfox?  Betterfox?) browser development and maintenance, and nothing else.  They could work more like Wikipedia, just taking donations and building up an endowment with that to fund themselves, and keeping their operations very lean so they don't need that much money to begin with.\n \nreply",
      "What they should have done was build an endowment when they were getting crazy google money. It obviously wasn't going to last forever.\n \nreply",
      "Yes, definitely.  It would have been easy back then to build an endowment if they hadn't blown money on so much BS and prepared for a future where they wouldn't have all that money coming in.  I think it's too late for them now, and I don't see how they can possibly trim things down into a lean, efficient organization, especially not in the US.  That's why I think someone in a cheaper country needs to fork the thing and take over Firefox development.  This will probably have to wait until Mozilla is teetering on the edge of bankruptcy though.\n \nreply"
    ],
    "link": "https://www.theverge.com/2024/11/5/24289124/mozilla-foundation-layoffs-advocacy-global-programs",
    "first_paragraph": "By  Gaby Del Valle, a policy reporter. Her past work has focused on immigration politics, border surveillance technologies, and the rise of the New Right.The Mozilla Foundation laid off 30 percent of its workforce and completely eliminated its advocacy and global programs divisions, TechCrunch reports.\u00a0While Mozilla is best known for its Firefox web browser, the Mozilla Foundation \u2014 the parent of the Mozilla Corporation \u2014 describes itself as standing up \u201cfor the health of the internet.\u201d With its advocacy and global programs divisions gone, its impact may be lessened going forward.\u201cFighting for a free and open internet will always be core to our mission, and advocacy continues to be a critical tool in that work. We\u2019re revisiting how we pursue that work, not stopping it,\u201d Brandon Borrman, the Mozilla Foundation\u2019s communications chief, said in an email to The Verge. Borrman declined to confirm exactly how many people were laid off, but said it was about \u201c30% of the current team.\u201dThis is M"
  },
  {
    "title": "DuckDB over Pandas/Polars (pgrs.net)",
    "points": 4,
    "submitter": "pgr0ss",
    "submit_time": "2024-11-01T18:47:01 1730486821",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.pgrs.net/2024/11/01/duckdb-over-pandas-polars/",
    "first_paragraph": "I\u2019m a Principal Software Engineer in Seattle. I have previously worked at Rvvup, Ripple, Braintree/PayPal, and ThoughtWorks.\n\n\nNovember 1, 2024\n\n\n\n\n        \n          1 minute read\n        \n      \nSince my previous post on DuckDB (DuckDB as the New jq), I\u2019ve been continuing to use and enjoy DuckDB.Recently, I wanted to analyze and visualize some financial CSVs, including joining a few files together. I started out with Polars (which I understood to be a newer/better Pandas). However, as someone who doesn\u2019t use it frequently, I found the syntax confusing and cumbersome.For example, here is how I parsed a Transactions.csv and summed entries by Category for rows in 2024 (simplified example, code formatted with Black):Things that tripped me up:I\u2019m sure this is straightforward for someone who uses these tools frequently. However, that\u2019s not me. I play around for a bit and then come back to it weeks or months later and have to relearn.In contrast, I write SQL day in and day out, so I find it"
  },
  {
    "title": "DeepMind debuts watermarks for AI-generated text (ieee.org)",
    "points": 45,
    "submitter": "ambigious7777",
    "submit_time": "2024-11-05T12:50:16 1730811016",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=42051098",
    "comments": [
      "These watermarks are not robust to paraphrasing attacks: AUC ROC falls from 0.95 to 0.55 (barely better than guessing) for a 100 token passage.The existing impossibility results imply that these attacks are essentially unavoidable (https://arxiv.org/abs/2311.04378) and not very costly, so this line of inquiry into LLM watermarking seems like a dead end.\n \nreply",
      "I spent the last five years doing PhD research into steganography, with a particular focus on how to embed messages into LLM outputs. Watermarking is basically one-bit steganography.The first serious investigations into \"secure\" steganography were about 30 years ago and it was clearly a dead end even back then. Sure, watermarking might be effective against lazy adversaries--college students, job applicants, etc.--but can be trivially defeated otherwise.All this time I'd been lamenting my research area as unpopular and boring when I should've been submitting to Nature!\n \nreply",
      "This article goes into it a little bit, but an interview with Scott Aaronson goes into some detail about how watermarking works[0].He's a theoretical computer scientist but he was recruited by OpenAI to work on AI safety. He has a very practical view on the matter and is focusing his efforts on leveraging the probabilistic nature of LLMs to provide a digital undetectable watermark. So it nudges certain words to be paired together slightly more than random and you can mathematically derive with some level of certainty whether an output or even a section of an output was generated by the LLM. It's really clever and apparently he has a working prototype in development.Some work arounds he hasn't figured out yet is asking for an output in language X and then translating it into language Y. But those may still be eventually figured out.I think watermarking would be a big step forward to practical AI safety and ideally this method would be adopted by all major LLMs.That part starts around 1 hour 25 min in.> Scott Aaronson: Exactly. In fact, we have a pseudorandom function that maps the N-gram to, let\u2019s say, a real number from zero to one. Let\u2019s say we call that real number ri for each possible choice i of the next token. And then let\u2019s say that GPT has told us that the ith token should be chosen with probability pi.https://axrp.net/episode/2023/04/11/episode-20-reform-ai-ali...\n \nreply",
      "I don't think that provable watermarking is possible in practice. The method you mention is clever, but before it can work, you would need to know the probability of the every other source which could also be used to generate the output for the same purpose. If you can claim that the probability of that model is much higher on that model than in any other place, including humans, then watermark might give some stronger indications.You would also need to define probability graph based on the output length. The longer the output, more certain you can be. What is the smallest amount of tokens that cannot be proved at all?You would also need include humans. Can you define that for human? All LLMs should use the same system uniformally.Otherwise, \"watermaking\" is doomed to be misused and not being reliable enough. False accusations will be take a place.\n \nreply",
      "I agree. I'd add that not only could human-written content fail the test -- it's also the case that humans will detect the word pairing, just as they detected \"delve\" and various other LLM tells.In time most forms of watermarking along those lines will seem like elements of an LLM's writing style, and will quickly be edited out by savvy users.\n \nreply",
      ">So it nudges certain words to be paired together slightly more than random and you can mathematically derive with some level of certainty whether an output or even a section of an output was generated by the LLM.hah, every single LLM already watermarks its output by starting the second paragraph with \"It is important/essential to remember that...\" followed by inane gibberish, no matter what question you ask.\n \nreply",
      "I've always felt you'd be able to  tell someone uses Reddit because they'll reply to a comment starting the sentence with \"The problem is that...\"Now LLMs are trained on Reddit users.\n \nreply",
      "Sounds interesting, but it also sounds like something that could very well be circumvented by using a technique similar to speculative decoding: you use the censored model like you'd use the fast llm in speculative decoding, and you check whether the other model agrees with it or not. But instead of correcting the token every time both models disagree like you'd do with speculative decoding, you just need to change it often enough to mess with the watermark detection function (maybe you'd change every other mismatched token, or maybe one every 5 tokens would be enough to reduce the signal-to-noise ratio below the detection threshold).You wouldn't even need to have access to an unwatermarked model, the \u201ccorrecting model\u201d could even be watermaked itself as long as it's not the same watermarking function applied to both.Or am I misunderstanding something?\n \nreply",
      "No you've got it right. Watermarks like this are trivial to defeat, which means they are only effective against lazy users like cheating college students and job applicants.\n \nreply",
      "\"An LLM generates text one token at a time. These tokens can represent a single character, word or part of a phrase. To create a sequence of coherent text, the model predicts the next most likely token to generate. These predictions are based on the preceding words and the probability scores assigned to each potential token.For example, with the phrase \u201cMy favorite tropical fruits are __.\u201d The LLM might start completing the sentence with the tokens \u201cmango,\u201d \u201clychee,\u201d \u201cpapaya,\u201d or \u201cdurian,\u201d and each token is given a probability score. When there\u2019s a range of different tokens to choose from, SynthID can adjust the probability score of each predicted token, in cases where it won\u2019t compromise the quality, accuracy and creativity of the output.This process is repeated throughout the generated text, so a single sentence might contain ten or more adjusted probability scores, and a page could contain hundreds. The final pattern of scores for both the model\u2019s word choices combined with the adjusted probability scores are considered the watermark. This technique can be used for as few as three sentences. And as the text increases in length, SynthID\u2019s robustness and accuracy increases.\"Better link: https://deepmind.google/technologies/synthid/\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/watermark",
    "first_paragraph": "The November 2024 issue of IEEE Spectrum is here!But the DeepMind technology isn\u2019t yet a practical solution for everyoneEliza Strickland is a Senior Editor at IEEE Spectrum covering AI and biomedical engineering.The chatbot revolution has left our world awash in AI-generated text: It has infiltrated our news feeds, term papers, and inboxes. It\u2019s so absurdly abundant that industries have sprung up to provide moves and countermoves. Some companies offer services to identify AI-generated text by analyzing the material, while others say their tools will \u201chumanize\u201c your AI-generated text and make it undetectable. Both types of tools have questionable performance, and as chatbots get better and better, it will only get more difficult to tell whether words were strung together by a human or an algorithm.Here\u2019s another approach: Adding some sort of watermark or content credential to text from the start, which lets people easily check whether the text was AI-generated. New research from Google "
  }
]