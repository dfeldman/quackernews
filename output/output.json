[
  {
    "title": "Everything I built with Claude Artifacts this week (simonwillison.net)",
    "points": 294,
    "submitter": "recvonline",
    "submit_time": "2024-10-23T20:52:13 1729732531",
    "num_comments": 217,
    "comments_url": "https://news.ycombinator.com/item?id=41929174",
    "comments": [
      "Simon, (if you\u2019re reading), if you \u201clike programming\u201d, is there any point that you get depressed about LLMs doing all the fun stuff that you wanted to do?I see some arguments about high-level languages, eg \u201cI\u2019d rather program in Python than assembly - this is just another step-up\u201d. But I feel natural language is altogether different and obliterates any skill/knowledge you\u2019ve built-up in programming.I can think other things, for example music - I like playing guitar even though I\u2019ll never create something totally original or do better than a machine could do. But for me, programming combines the fun of creation with the satisfaction of the end result - something you wanted to exist now exists.To clarify, I\u2019m not talking about \u201cusefulness\u201d or accomplishing some business objective, I\u2019m talking about the joy and satisfaction of programming.\n \nreply",
      "I'm sure there are plenty of examples like this, but one thing that I find really hard to deal with is to integrate such tools into existing codebase -- you can make all these things as standalone pages, but for a professional developer, you have certain standards and conventions, and often it takes a lot of work to review/revise the code to make it work with existing codebase, so much that you end up using inline completion just to help with obvious stuff or boilerplate. I woule rather spend 20% extra amount of time to write the code myself yet have confidence, than spend time tweaking the prompt or giving follow up instructions.\n \nreply",
      "With a sufficiently advanced type system, you could lay out high level building blocks, such as function definitions, and let the LLM go wild, and then if things compile there's a high chance it's correct. Or maybe even a formal proof things are correct.I was blown away when I realized some Haskell functions have only one possible definition, for example. I think most people haven't worked with type systems like this, and there are type systems far more powerful than Haskell's, such as dependant types.There's not much reason to worry about low level quality standards so long as you know it's correct from a high level. I don't think we've seen what a deep integration between a LLM and a programming language can do, where the type system helps validate the LLM output, and the LLM has a type checker integrated into its training process.\n \nreply",
      "> With a sufficiently advanced type systemIs this a brother or a cousin of the \"sufficiently advanced compiler\"? :-)\n \nreply",
      "Anything on top of the Calculus of Constructions is usually enough.\nSo it's not a moving target, and there are multiple implementations.\n \nreply",
      "I'm not sure how much things have changed but I tried to use GPT-4 when it first came out to build a library on top of Scala + Shapeless and it utterly failed. Unless you can somehow wire in an LSP per language as an agent and have it work through the type errors as it tries to create code, I can't see where we'll ever get to a place where LLMs can work with strongly typed languages and produce compliant code.Even with, the aforementioned \"have an LSP agent work through type errors\", it may be faster to just do it yourself than wait for an LLM to spit out what may be correct.\n \nreply",
      "Definitely try Claude 3.5 Sonnet and o1-preview.  They have succeeded for me where other models have failed. Also, use Cursor IDE.\n \nreply",
      "Things I never want to hear about flight control systems before I board a plane: \u201cif things compile there's a high chance it's correct\u201d\n \nreply",
      "Very odd comment, since that's exactly what you do want to hear\n \nreply",
      "Just tell it those conventions or standards.Using GitHub copilot, I just tell it to style its code like an example and it gets pretty close.\n \nreply"
    ],
    "link": "https://simonwillison.net/2024/Oct/21/claude-artifacts/",
    "first_paragraph": "21st October 2024I\u2019m a huge fan of Claude\u2019s Artifacts feature, which lets you prompt Claude to create an interactive Single Page App (using HTML, CSS and JavaScript) and then view the result directly in the Claude interface, iterating on it further with the bot and then, if you like, copying out the resulting code.I was digging around in my Claude activity export (I built a claude-to-sqlite tool to convert it to SQLite I could explore it in Datasette) and decided to see how much I\u2019d used artifacts in the past week. It was more than I expected!Being able to spin up a full interactive application\u2014sometimes as an illustrative prototype, but often as something that directly solves a problem\u2014is a remarkably useful tool.Here\u2019s most of what I\u2019ve used Claude Artifacts for in the past seven days. I\u2019ve provided prompts or a full transcript for nearly all of them.I got frustrated at how hard it was to copy and paste the entire text of a web page into an LLM while using Mobile Safari. So I built a"
  },
  {
    "title": "Show HN: Wall-mounted diffusion mirror that turns reflections into paintings (matthieulc.com)",
    "points": 60,
    "submitter": "cataPhil",
    "submit_time": "2024-10-23T22:24:21 1729732531",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=41929804",
    "comments": [
      "Nice! I peaked at the code and thought I\u2019d share a few tips for improving the low frame rate:Base64 encoding the JPEG bytes will increase payload size up to ~30% and burns CPU cycles on both client and server. This is unnecessary, as Websocket protocol can send binary payloads (doesn\u2019t need to be text).Consider removing lossy jpg compression as well, ie just send the raw RGB bytes over the network. Then on the server side you can simply call Image.frombuffer(\u2026).StreamDiffusion can achieve high frame rates because of extensive batching in the pipeline. You\u2019re not benefiting from that here as the client is only sending one frame at a time and then waiting for a response. See this example for an idea of how to queue input frames and consume them in batches https://github.com/cumulo-autumn/StreamDiffusion/blob/main/e... .Alternatively you could take a look at the SDXL Turbo and Lightning models. They are very fast at img2img but have limited resolution of 512\u00b2 or 1024\u00b2 pixels respectively. Which appears a bit lower than what you\u2019re aiming for here, but they can be run locally in real time on a high end consumer grade GPU. For reference I have some code demonstrating this here https://github.com/GradientSurfer/Draw2Img/tree/main\n \nreply",
      "> Art is ... mostly about surfacing the inner world, and only in part about skill.I like the phrasing of the first part. But what art is \"about\" is very subjective.For me, part of what I look for in art is intentionality - the notion that the artist has crafted each element toward a purpose, consciously or not. The less an artist contributes to the final piece, the less meaning I assign to it.In this case: I would say that the individual pictures being displayed are not \"art\" - they have no meaning. But I think the device in whole is a piece of art. That is a creation that surfaces the creator's inner world, because they designed the device, wrote the code, crafted the prompts to achieve pieces that reflected their notion of beauty.\n \nreply",
      "I love this framing (pun unintended) of \"art\".Besides what you articulated as the \"intention\", I often think of the \"story\" behind the art -- whether an idea in the creator's head was expressed via the piece (or not) makes me go \"yes, this is Art\" (or not).By that token, when I see automated projects like this, I think of the \"installation\" as art, but the pixels or arrangements generated by the piece itself is less art-like IMO.\n \nreply",
      "It's pretty neat, but I'd never have a webcam steaming everything in view to someone else's server on the internet. It'd be cool if the server ran on my own hardware, and ideally in the frame itself. The privacy policy at runpod.io wouldn't even display in my browsers. (their ToS loaded without an issue).\n \nreply",
      "I wonder if you could do something like this with hardware acceleration (like google coral)\n \nreply",
      "Have you considered a high frame rate morph effect between images? That would increase the effective frame rate and probably would look pretty cool.\n \nreply",
      "That\u2019s the technique I used on a piece that does inpainting across an image at a rate of about 1 image every 8 seconds - I \u2018melt\u2019 the results in for the duration until the next patch is ready:\nhttps://hardwork.party/aws-epoch-optimizer/\n \nreply",
      "Even a simple crossfade.\n \nreply",
      "> It\u2019s unfortunate that art selects so strongly for skill. Can we decorrelate the two?I really like this direction. I understand why some object to the genai approaches, but in practice sometimes I get an idea of something cool and don't have the skills to create it myself. I'm not going to invest months/years to create each of those ideas and they're not important enough to spend hundreds of dollars that a skilled artist would request. Now there's a way people can try generating the thing and may end up enjoying it - and that's great. (At least for personal use, it gets a bit complicated for commercial purposes)\n \nreply",
      "This really does change the interaction with art.  As a future expansion it might be neat to recognize images on camera that would make for interesting art (i.e. detection of people/animals or recognition of certain styles of composition) as well as being able to choose amongst different styles.It seems sort of akin to some modern art that incorporated TV screens and video to make dynamic installations, like Nam June Paik.\n \nreply"
    ],
    "link": "https://www.matthieulc.com/posts/pablonet/",
    "first_paragraph": "The debate about whether internet-fitted AIs can be creative always seemed besides the point to me. Making art is hard. But art is mostly about surfacing the inner world, and only in part about skill. It\u2019s unfortunate that art selects so strongly for skill. Can we decorrelate the two? It seems so. Cheap interpolative* creativity used by 8 billion non-artists surely surfaces new views of the world.For these reasons and since I suck at art I\u2019ve been very excited about the various AI-driven art forms popping up. A couple of months ago I started playing with real-time diffusion of my webcam feed using StreamDiffusion. Specifically, with the intent of generating pretty visuals and hoping to elicit new/interesting feelings. Although it\u2019s very fun, the laptop form-factor breaks the illusion. It feels all temporary and geeky. So, I recently built an LCD frame that can be hanged to a wall with minimal illusion breakers. What I really like about this setup is that making it a proper object opens"
  },
  {
    "title": "Playstation Vita Architecture (Part 1) (copetti.org)",
    "points": 124,
    "submitter": "wicket",
    "submit_time": "2024-10-23T19:31:51 1729732531",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=41928529",
    "comments": [
      "I went through two PS Vitas and replaced control buttons and such numerous times.I loved the Vita's mix of casual and \"serious\" games comparing Pixeljunk Monsters to Killzone Mercenary which was as good a 1P shooter as you'd find on a game console in a mobile package.  A huge amount of Japanese content such as Akiba's Trip: Undead and Undressed, Danganronpa and Fate/Extella.They disconnected it from the PS Network and I was finding that the Japanese games I liked were coming out on Steam so I let go of my Vita kit,  I have to admit I miss Pixeljunk Shooter.\n \nreply",
      "I'm a huge fan of the original PSP and the homebrew/jailbreaking scene that came out of it. I recently acquired a PS Vita and have been enjoying it's native and homebrew offerings. It's also surprising that the homebrew scene is still fairly active there too. Apparently there's some potential for Android game ports. I wish Sony didn't let the PS Vita flop, it feels like it had so much potential at the time.\n \nreply",
      "I preordered a Vita back in the day and when I got it I immediately fell in love with it. It fits in a pocket and it has way better analogue sticks than that garbage the PSP had.I still use it to this day because I can't fit my Steam Deck in my pocket.And I concur that its potential did kinda go to waste. Imagine if we had Shadow of the Colossus and Demon's Souls available on it.\n \nreply",
      "The Vita1000 OLEDs in general haven\u2019t aged well, but the Vita2000 is still a strong option for mobile gaming.  The handheld emulation machines aren\u2019t made with the same build quality and the Steamdeck style consoles aren\u2019t massive by comparison.  The Switch Lite is another fine choice, but still much bigger than the PSPVita 2000.I\u2019m hoping strong sales of the PSPortal encourages development into a standalone mobile device, but I\u2019m not hopeful it\u2019ll replace my PSP3000/Vita2000 for daily driving.\n \nreply",
      ">>The Vita1000 OLEDs in general haven\u2019t aged wellReally? That's an interesting opinion - I own both and vastly prefer the original Vita due to that OLED screen, it's just better in every way(the screen).\n \nreply",
      "The white Vita OLED was an excellent device\n \nreply",
      "not really an opinion, the mura effect is the ubiquitous and well-documented flaw of Vita 1000 OLEDs\n \nreply",
      "You can\u2019t have an opinion about whether a flaw bothers you?\n \nreply",
      "The 60 grams of weight and 3.5mm of depth are very noticeable on a handheld.\n \nreply",
      "My vita oled still functions fine?\nI have non oled variants as well but I feel no reason to use them, they just exist as spares.Have the OLEDs all started dying or something?\n \nreply"
    ],
    "link": "https://www.copetti.org/writings/consoles/playstation-vita/",
    "first_paragraph": "If you use accessibility tools or old browsers, switch to the \u2018classic\u2019 edition.Upon completion, this article will be published on many digital book stores for the benefit of eBook readers. The new edition will be DRM-free and will be readable whilst offline. Furthermore, it will be updated at the same pace as the website.Meanhile, you can find existing eBooks at Amazon Kindle, Apple Books, Kobo and other stores. The profits contribute towards the improvement of current articles and the development of future ones.For more information, please take a look at here.The PSVita is a noteworthy intersection between the video-game establishment and the rapidly evolving mobile sector. Times have changed, and it won\u2019t be easy for Sony as it faces fierce competition from cheap gadgets that do more than just make phone calls.The new analysis of this series dives into the contemporary technology behind Sony\u2019s new delivery. Do expect to find recognisable circuitry - perhaps too familiar. Even so, So"
  },
  {
    "title": "Apple ripped a valuable hearing loss feature from the AirPods line (mattiebee.io)",
    "points": 9,
    "submitter": "zepton",
    "submit_time": "2024-10-24T00:15:56 1729732531",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://mattiebee.io/55828/it-sure-looks-like-apple-ripped-a-valuable-hearing-loss-feature-from-the-airpods-line",
    "first_paragraph": ""
  },
  {
    "title": "What happens when you make a move in lichess.org? (davidreis.me)",
    "points": 174,
    "submitter": "dreis_sw",
    "submit_time": "2024-10-23T08:13:47 1729732531",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=41922928",
    "comments": [
      "I wish this discussed the timing arbitration of each move.  Based on the packet information (if that is correct & complete) then the timing is done entirely on the clients.  However, they show the time in seconds which can't be right so I am curious how accurate this packet schema is (or if those are float values).Regardless, one thing I find maddening about chess.com is the time architecture of the game.  I haven't seen the underlying code, but it feels like the SERVER is tracking the time.  This completely neglects transport time & latency meaning that 1s to move isn't really a second.  Playing on the mobile client is an exercise in frustration if you are playing timed games and down to the wire.  Even when you aren't, your clock will jump on normal moves and it is most obvious during the opening.This could also be due to general poor network code as well.  The number of errors I get during puzzles is also frustrating.  Do they really not retry a send automatically??  <breath>Chess.com has the brand and the names... but dang, the tech feels SO rough to me.\n \nreply",
      "> it feels like the SERVER is tracking the timeTBH this is what I expected for all online chess. How else to reconcile the two players' differing clocks and also prevent client-side cheating?\n \nreply",
      "I guess my naive frustration comes from crazy fps games tracking things so precisely and yet somehow Chess.com can\u2019t handle a turn based game?!  Honestly.I do recognize that fps games utilize predictive algorithms and planning to estimate future player positions but still, turn based networking with 100ms accuracy should be a solved problem\n \nreply",
      "It hasn\u2019t been done client side in any pvp game I\u2019ve heard of.\n \nreply",
      "I'm pretty sure freechess.org did.\n \nreply",
      "How is it being done client side?\n \nreply",
      "Well it's a long time since I played there. But it had custom chess clients, which I assume just recorded how much time your move actually took and sent that with the move.Yes, it's easy to cheat with this, but it's very easy to cheat with chess anyway.\n \nreply",
      "Track the two clients pings? What client side cheating prevention would you need to do in chess? Afaik you can't cheat by clipping through walls or jumping around on the map.\n \nreply",
      "The client side cheating would by lying about when you received the packet in order to give yourself more time to think. Even if you only shifted it by 200ms per move, that could add up to a lot over the course of a long game.\n \nreply",
      "To give additional context: bullet chess can go down to 1 minute per player. Lying about a few millisecond per move there is huge.\n \nreply"
    ],
    "link": "https://www.davidreis.me/2024/what-happens-when-you-make-a-move-in-lichess",
    "first_paragraph": "@dreis_sw|September 23, 2024 (1m ago)Have you ever wondered what goes on behind the scenes every time you make a move in your favorite online chess platform?Lichess.org is a popular, free, and open-source chess platform that attracts millions of players worldwide. Its seamless, real-time gameplay experience must be powered by a robust backend infrastructure. In this post, we'll peek behind the curtain and explore the technical processes involved when you play a move.To understand the flow of data when making a move, we'll start by utilizing Chrome DevTools, particularly the Network tab, which allows us to monitor communication between the client (your browser) and the server.The first notable network activity is a WebSocket connection to a URL similar to:The protocol, wss, indicates an encrypted websockets connection using TLS.No surprises here, WebSockets are the obvious choice for real-time browser apps like online chess because they allow for full-duplex communication, enabling inst"
  },
  {
    "title": "Show HN: Open-source low-code email editor (github.com/dittofeed)",
    "points": 71,
    "submitter": "chandlercraig",
    "submit_time": "2024-10-23T18:54:59 1729732531",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=41928203",
    "comments": [
      "Your submission link goes to https://github.com/dittofeed/dittofeed/tree/main/packages/em...Would you put a README in there in GitHub? No idea what I should look for in this subfolder in GitHub\n \nreply",
      "Hi z3ugma! Yah we'll add a README. To clarify the emailo package is not (currently) intended for consumption outside of Dittofeed, but it'd be great to document nonetheless!\n \nreply",
      "Do you mind removing the Segment requirement for usage? I think many users would be fine with just a standard http endpoint.\n \nreply",
      "Hey KRAKRISMOTT, we have SDKs and a REST API which can be found at https://docs.dittofeed.com/integrations/sourcesOpen to expanding our SDK selection though.\n \nreply",
      "Ah okay, it's mostly that your getting started guide specifically requires a Segment account for some reason.\n \nreply",
      "I pressed \"/\" (shift-7) on my Macbook (Portuguese) and nothing happens.\n \nreply",
      "I'll take a look!\n \nreply",
      "I wish Dittofeed is cheaper, $75 is quite steep to get started with.On an unrelated note, I suppose congratulations is in order. The laudspeaker product (your fellow YC competitor) doesn't seem to be successful at all (they are even more pricey). I think Brevo and Klaviyo are gobbling up all the oxygen in the room for most marketing departments, they are basically the next mailchimp.\n \nreply",
      "Hi Onavo, we'll have a free cloud tier for lower volume in the near future. If you'd like to self-host for free but need help with setup, we'd love to see you in our #help-and-questions Discord channel!Thanks for the kind words as well. With regards to the state of our product category, it's definitely a crowded space. One of our main goals is to help companies save money as they scale their messaging, so it's great to hear your input on pricing.\n \nreply",
      "No congratulations is necessary the Laudspeaker project (https://github.com/laudspeaker/laudspeaker) is doing perfectly fine.$75/mo is not particularly expensive, Braze's starter plan is close to $35k/year\n \nreply"
    ],
    "link": "https://github.com/dittofeed/dittofeed/tree/main/packages/emailo",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          "
  },
  {
    "title": "Taming the buck with a Type III compensator (sig7.se)",
    "points": 28,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-22T09:29:30 1729732531",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41912633",
    "comments": [
      "Tuning feedback loops is a topic I've found to be fiendishly good fun, perhaps because of how obtuse the final result is. There is no at-a-glance way to see the connection between your high-level goals (closed-loop bandwidth and phase margin) and the implementation (the R and C values). Consequently, I make it a point to document the hell out of these circuits with parameterized simulations so that my future self has some hope of understanding and adjusting them later on.A lot of applications are usually tolerant of suboptimal compensator design. I've participated in a few designs where these circuits were plucked from the datasheet reference design and never touched. There's a tradeoff between having a little bit of ringing vs. having an engineer model, tune, and test, and also adding to the BOM complexity with a bunch of different passive part values.\n \nreply",
      "It's been a while since my EE degree so I had to refresh my memory [2]. This is related to PID controllers (https://en.wikipedia.org/wiki/Proportional%E2%80%93integral%...).Type I is proportional only.Type II compensation adds a zero (to increase phase margin [1]) and a pole (to filter high-frequency noise) to the compensation network, resulting in proportional-integral (PI) control.Type III compensation introduces two zeros and two poles into the control loop, making it a proportional-integral-derivative (PID) control scheme.... and if you want to go one step further, MPC [3] also exists:https://iaeme.com/MasterAdmin/Journal_uploads/IJARET/VOLUME_...[1] https://en.wikipedia.org/wiki/Phase_margin[2] https://eng.libretexts.org/Bookshelves/Industrial_and_System...[3] https://en.wikipedia.org/wiki/Model_predictive_control\n \nreply",
      "I am impressed by the xschem developer !\nfrom the article:  https://github.com/StefanSchippers/xschem/issues/238\n \nreply",
      "Are there pictures of the Type III Compensator physical reality?\n \nreply",
      "...looking at something like this built with surface-mount parts in the modern day reads like someone trying to do high-speed rail with steam locomotives. I mean, you can do it (see https://en.wikipedia.org/wiki/LNER_Class_A4_4468_Mallard#193... !), but... please just learn to solder SMT parts. It really is easier, I promise you.To go SMT you'll need to add fine-gauge solder wire (0.015\"/0.4mm), more flux than you think you need, and either a second iron or soldering tweezers (amazing but expensive). You should add get some T4 paste, a dental pick to spread it, and a \"reflow plate\" (that means old electric skillet from the secondhand store). And you'll want an inspection microscope but those are really useful in general. That's all you need!Stop building with dinosaur parts and you can use shiny new things like the LM70660 which can do that entire design in about 1/10th the space and double the reliability: https://www.ti.com/lit/ds/symlink/lm70660.pdf\n \nreply"
    ],
    "link": "https://tomscii.sig7.se/2024/10/Taming-the-buck-with-a-Type-III-compensator",
    "first_paragraph": ""
  },
  {
    "title": "A DSL for peephole transformation rules of integer operations in the PyPy JIT (pypy.org)",
    "points": 83,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-23T16:31:58 1729732531",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41926669",
    "comments": [
      "GCC does this match.pd.  Here's the add_zero example, I think:    /* Simplifications of operations with one constant operand and\n       simplifications to constants or single values.  */\n    \n    (for op (plus pointer_plus minus bit_ior bit_xor)\n      (simplify\n        (op @0 integer_zerop)\n        (non_lvalue @0)))\n\nhttps://gcc.gnu.org/git/?p=gcc.git;a=blob;f=gcc/match.pdThe floating point case can be more complicated because of signed zeros and signaling NaNs, see fold_real_zero_addition_p.\n \nreply",
      "The before/after delta is very satisfying and clearly easier to work with. Very nice.How does the DSL handle side effects? I'm assuming any term here could be a compound expression, so what part of the system prevents \"0*callfn()\" from reducing to \"0\"?\n \nreply",
      "I believe this operates on values in something akin to registers, not expression trees. By the time you get to a place where one of these rules is relevant, the side effect has already taken place. This just prevents the return of such a function call to be operated on, like in your example.\n \nreply",
      "Interesting to see which optimizations are never used.\n \nreply",
      "math.fma fused multiply add is in Python 3.13. Are there already rules to transform expressions to math.fma?And does Z3 verification indicate differences in output due to minimizing float-rounding error?https://docs.python.org/3/library/math.html#math.fma :> math.fma(x, y, z)> Fused multiply-add operation. Return (x * y) + z, computed as though with infinite precision and range followed by a single round to the float format. This operation often provides better accuracy than the direct expression (x * y) + z.> This function follows the specification of the fusedMultiplyAdd operation described in the IEEE 754 standard.\n \nreply",
      "I only support integer operations in the DSL so far.(but yes, turning the python expression x*y+z into an fma call would not be a legal optimization for the jit anyway. And Z3 would rightfully complain. The results must be bitwise identical before and after optimization)\n \nreply"
    ],
    "link": "https://pypy.org/posts/2024/10/jit-peephole-dsl.html",
    "first_paragraph": "\nCF Bolz-Tereick\n\n\n2024-10-23 15:00\n Comments\nAs is probably apparent from the sequence of blog posts about the topic in the\nlast year, I have been thinking about and working on integer optimizations in the JIT\ncompiler a lot. This work was mainly motivated by Pydrofoil, where integer\noperations matter a lot more than for your typical Python program.In this post I'll describe my most recent change, which is a new small domain\nspecific language that I implemented to specify peephole optimizations on\ninteger operations in the JIT.\nIt uses pattern matching to specify how (sequences of) integer operations\nshould be simplified and optimized. The rules are then compiled to\nRPython code that then becomes part of the JIT's optimization passes.To make it less likely to introduce incorrect optimizations into the JIT, the\nrules are automatically proven correct with Z3 as part of the build process (for\na more hands-on intro to how that works you can look at the knownbits post).\nIn this blog post I"
  },
  {
    "title": "Probably pay attention to tokenizers (cybernetist.com)",
    "points": 169,
    "submitter": "ingve",
    "submit_time": "2024-10-23T10:29:15 1729732531",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=41923625",
    "comments": [
      "Tokenizers aren't considered the \"sexy\" part of LLMs, but where others see boring, I see opportunity. Papers like xVal[1], point toward specialization strategies in tokenization. Spelling and letter tasks are another problem that could benefit from innovation on the tokenization.LLMs are notoriously bad at counting letters in words or performing simply oulipos of letter omission. GPT-4o, for example, writes a small python program and executes it in order to count letter instances. We all know that tokenization effectively erases knowledge about letters in prompts and directly negatively impacts performance at these tasks, yet we haven't found a way to solve it.1. https://ar5iv.labs.arxiv.org/html/2310.02989\n \nreply",
      "This was ages ago, in the pre-transformer era, and I can't find the link anymore. But once upon a time I read a great paper that demonstrated that most of the performance differences being reported among popular embedding models of the time were better explained by text cleaning and tokenization than they were by the embedding model itself.In other words, if you train a model using word2vec's preprocessing and GloVe's algorithm, the result looks more like a \"standard-issue\" word2vec model than a \"standard-issue\" GloVe model.\n \nreply",
      "Tokenizers face an odd compute issue.Since they're part of the pre-processing pipeline, you can't quickly test them out for effectiveness. You have to restart a pretraining run to test downstream effectiveness.Separately,As much as an attention module can do universal nonlinear transformations....I wonder if it makes sense to add specifuc modules for some math primitives as well. I remember that the executor paper [1] (slightly precursor to the attention is allyou need paper)  created self contained modules for operations like less than, count, sum and then explicitly orchestrated them in the decoder.I'm surprised we haven't seen such solutions produce sota results from math-ai or code-ai research communities.[1] https://arxiv.org/abs/1705.03633\n \nreply",
      "What's the issue with character-level tokenization(I assume this would be much better at count-the-letter tasks)? The article mentions it as an option but doesn't talk about why subword tokenization is preferred by most of the big LLMs out there.\n \nreply",
      "Using subwords makes your sequences shorter, which makes them cost less.Besides that, for alphabetic languages, there exists almost no relation between form and meaning. I.e.: \u201cring\u201d and \u201cwing\u201d differ by one letter but have no real common meaning. By picking the character or byte as your choice of representation, the model basically has to learn to distinguish ring and wing in context. This is a lot of work!So, while working on the character or byte level saves you some embeddings and thus makes your model smaller, it puts all of the work of distinguishing similar sequences with divergent meanings on the model itself, which means you need a larger model.By having subwords, a part of this distinguishing work already has been done by the vocabulary itself. As the article points out, this sometimes fails.\n \nreply",
      "> Besides that, for alphabetic languages, there exists almost no relation between form and meaning.Also true for Abugida-based languages, for eg. \u0b9a\u0bb0\u0bae\u0bcd (saram = string) vs \u0bae\u0bb0\u0bae\u0bcd (maram = tree), and many more. I think your intention with specifying \"alphabetic languages\" was to say \"non-logographic languages\", right?\n \nreply",
      "I'll do you one more and say \"non-Chinese languages\". Written Japanese - including the kanji portion of the script - has the same characteristic.And even in Chinese it's a fairly weak relationship. A large portion of the meanings of individual characters come from sound loan. For example the \u82f1 in \u82f1\u96c4 means \"hero\", in \u82f1\u8bed means \"England\", an in \u7cbe\u82f1 means \"flower\". The relationship there is simple homophony.On the other hand, one thing you do get with written Chinese is that \"1 character = 1 morpheme\" very nearly works. So mechanistically breaking a text into a sequence of morphemes can be done pretty reliably without the aid of a semantic model or exhaustive hard-coded mapping. I think that for many other languages you can't even get close using only syntactic analysis.\n \nreply",
      "> I'll do you one more and say \"non-Chinese languages\". Written Japanese - including the kanji portion of the script - has the same characteristic.Written Japanese is much more ideographic than written Chinese. Japanese spelling is determined, such as it is, by semantics. Chinese spelling is determined by sound. Thus, \u5973\u7684, \u5a18\u4eec, and \u59ae\u5b50, all meaning 'girl' or 'woman', have no spelling in common because they are different words, while Japanese uses \u5973 for \"jo\" and \"onna\" despite a total lack of any relationship between those words.\n \nreply",
      "Has anyone tried to combine a token embedding with some representation of the characters in the (sub)word? For example, use a 512 long vector to represent a token,  and reserve the last 12 values to spell out the word.\n \nreply",
      "I'm not following - spell out the word how? Like put the actual bytes as numerical input to the transformer layer?\n \nreply"
    ],
    "link": "https://cybernetist.com/2024/10/21/you-should-probably-pay-attention-to-tokenizers/",
    "first_paragraph": ""
  },
  {
    "title": "My NumPy year: Creating a DType for the next generation of scientific computing (quansight.com)",
    "points": 27,
    "submitter": "sebg",
    "submit_time": "2024-10-22T11:12:10 1729732531",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41913145",
    "comments": [
      "That's an interesting write up and I hope the API change yields more useful data types. I'm not sure about the 28 byte size field, though. The way the rest of the code works it seems like a typo and sound be 8 bytes. I may dig into the code and find out.\n \nreply",
      "Dupe: https://news.ycombinator.com/item?id=41927436\n \nreply"
    ],
    "link": "https://quansight.com/post/my-numpy-year-creating-a-dtype-for-the-next-generation-of-scientific-computing/",
    "first_paragraph": ""
  },
  {
    "title": "Parks on the Air (parksontheair.com)",
    "points": 77,
    "submitter": "thepuppet33r",
    "submit_time": "2024-10-22T10:55:33 1729732531",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=41913057",
    "comments": [
      "Also shout out to Summits on the Air; same idea, but for mountain/hill/local-prominence-tops: https://sotl.as/It's real easy to get your Technician class license in the US, which will get you limited line of sight range via VHF/UHF and a few other misc. bands. General class unlocks High Frequency operation which allows you to talk around the globe with the right radio.For my field operations, I use a handheld 12V battery pack and  a (tr)uSDX, a souped-up ATMega platform that does QRP (<=5W power) operations via CW (Morse code) and SSB (voice). It's the cheapest radio out there that will reliably do (passable) quality SSB, and it's real handy to have something so tiny and light when I'm heading out to hike up a mountain.This is everything I take into the field, and have talked to people states and countries away when geomagnetic conditions were favorable (being on top of a mountain helps haha): https://i.imgur.com/HOx5buc.jpegFull kit breakdown: https://imgur.com/gallery/ultralightish-tr-usdx-sota-shack-b...\n \nreply",
      "Wow, this is very cool. I might upgrade to General just for this.Do you take both up? Fishing in mountain lakes and SSB to pass the time sound fun do to simultaneously.\n \nreply",
      "Haha the fishing rod is actually a mast for my antenna; I'm not much of an angler myself. Collapsible telescoping fiberglass rods are light, cheap, and an easy way to get a reasonably stable point 20 feet up in the air :)\n \nreply",
      "Start a YouTube channel.\n \nreply",
      "Ah, there are many folks out there much more personable and engaged with PotA/SotA than I. One of my favorites is K6ARK who is a great watch for antenna design, *otA, CW (morse) and more: https://www.youtube.com/watch?v=6rKpxAWZ7uM\n \nreply",
      "Have a similar service locally to me. I like to scout out wireless pops, so I started hunting their sites down. As they are an NFP I determined it might be cheap to colocate with them. One of their primary relay sites in my city had been completely abandoned. Power cut, comms box trashed and looted. And the tower looked nearly unclimbable. Sad really because it was pretty deep in the bush and likely prime location for their service.\n \nreply",
      "If you're wanting to see who's active right now, https://pota.app is more useful.And if you don't have a radio, and want to hear the conversations, check out a web SDR like this one: https://www.sdrutah.org/\n \nreply",
      "And here's a website that maps out where the current POTA, SOTA, and WWFF (the precursor to POTA) radio operators are at right now.https://fieldspotter.radio/\n \nreply",
      "I tried one and it was some old guy talking about the weather of course.\n \nreply",
      "I'm a ham radio operator but don't currently have the means for a decent HF antenna where I live. I like making contacts, but I'm not much for small talk and conversations. Contests are fun for me, even though I'm not at all a professional at it and likely will never be. The problem is, there's not always a contest running.POTA is amazing because it lets me toss up a temporary antenna on any arbitrary weekend and still have a good chance of making a few SSB contacts. Especially now with the solar cycle at its maximum.Thank you to all the people who go and activate parks! You are awesome!\n \nreply"
    ],
    "link": "https://parksontheair.com/index.html",
    "first_paragraph": "POTAParks on the AirNew to the program? Check out Help/Getting Started in the menu above for rules and guides for participating. \u00a0 \u00a0 Over 500,000 unique hunter call signs (participants)!! Thanks ALL POTA volunteers!  73 W0ZAP Welcome to the\u00a0Parks on the Air \u00ae\u00a0(POTA) site for international portable amateur radio operations that promote emergency awareness and communications from national/federal and state/provincial level parks.Parks on the Air \u00ae\u00a0is a registered service mark by the U.S. Patent and Trademark Office.Serial Number \u2013 880853061-4805205111 Registered TXu 2-044-081 U.S. Copyright Office April 5, 2017 by Jason Johnston W3AAXThis group was inspired by the outstanding work of Sean Kutzko (KX9X) and Norm Fusaro (W3IZ) from the American Radio Relay League (ARRL) in 2016.The Parks on the Air\u00ae Book explores the process of activating a park unit and hunting those activations. Through the experiences of 14 operators, it offers advice and motivation for taking your radio out to the park"
  },
  {
    "title": "Launch HN: GPT Driver (YC S21) \u2013 End-to-end app testing in natural language",
    "points": 89,
    "submitter": "cschiller",
    "submit_time": "2024-10-23T13:18:17 1729732531",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=41924787",
    "comments": [
      "I work in this space. We manage thousands of e2e tests. The pain has never been in writing the tests. Frameworks like Playwright are great at the UX. And having code editors like Cursor makes it even easier to write the tests. Now, if I could show Cursor the browser, it would be even better, but that doesn\u2019t work today since most multimodal models are too slow to understand screenshots.It used to be that the frontend was very fragile. XVFB, Selenium, ChromeDriver, etc., used to be the cause of pain, but recently the frontend frameworks and browser automation have been solid. Headless Chrome hardly lets us down.The biggest pain in e2e testing is that tests fail for reasons that are hard to understand and debug. This is a very, very difficult thing to automate and requires AGI-level intelligence to really build a system that can go read the logs of some random service deep in our service mesh to understand why an e2e test fails. When an e2e test flakes, in a lot of cases we ignore it. I have been in other orgs where this is the case too. I wish there was a system that would follow up and generate a report that says, \u201cThis e2e test failed because service XYZ had a null pointer exception in this line,\u201d but that doesn\u2019t exist today. In most of the companies I\u2019ve been at, we had complex enough infra that the error message never makes it to the frontend so we can see it in the logs. OpenTelemetry and other tools are promising, but again, I\u2019ve never seen good enough infra that puts that all together.Writing tests is not a pain point worth buying a solution for, in my case.My 2c. Hopefully it\u2019s helpful and not too cynical.\n \nreply",
      "While I agree with your primary pain point, I would argue that that really isn't specific to tests at all. It sounds like what you're really saying is that when something goes wrong, it's really difficult to determine which component in a complex system is responsible. I mean, from what you've described (and from what I've experienced as well), you would have the same if not harder problem if a user experienced a bug on the front end and then you had to find the root cause.That is, I don't think a framework focused on front end testing should really be where the solution for your problem is implemented. You say \"This is a very, very difficult thing to automate and requires AGI-level intelligence to really build a system that can go read the logs of some random service deep in our service mesh to understand why an e2e test fails.\" - I would argue what you really need is better log aggregation and system tracing. And I'm not saying this to be snarky (at scale with a bunch of different teams managing different components I've seen that it can be difficult to get everyone on the same aggregation/tracing framework and practices), but that's where I'd focus, as you'll get the dividends not only in testing but in runtime observability as well.\n \nreply",
      "Agreed. Is there a good tool you'd recommend for this?\n \nreply",
      "It's been quite some time but New Relic is a popular observability tool whose primary goal (at least the original primary goal I'd say) is being able to tie together lots of distributed systems to make it easier to do request tracing and root cause analysis. I was a big fan of New Relic when I last used it, but if memory serves me correctly it was quite expensive.\n \nreply",
      "\"OpenTelemetry and other tools are promising, but again, I\u2019ve never seen good enough infra that puts that all together.\"It's a two paragraph comment and you somehow missed it.\n \nreply",
      "I did read it, and I don't understand why you feel the need to be an asshole.Like I said in my comment, I do think getting everyone on the same page in a large, diverse organization is difficult. That said, it's not rocket science, and it's usually difficult because there aren't organizational incentives in place to actually ensure teams prioritize making system-wide observability work.FWIW, the process I've seen at more than 1 company is that people bitch about debugging being a pain, they put in a couple half measures to improve things, and then finally it becomes so much of a pain that they say \"fine, we need to get all of our ducks in a row\", execs make it a priority, and then they finally implement a system-wide observability process that works.\n \nreply",
      "Exactly! I've never seen a 5000+ eng org that have all their ducks in a row when it comes to telemetry. it's one of those things that you can't put a team in charge of it and get results. everyone have to be on the same page which in a big org is hardly the case.\n \nreply",
      "Thanks for your thoughtful response! Agree that digging into the root cause of a failure, especially in complex microservice setups, can be incredibly time-consuming.Regarding writing robust e2e tests, I think it really depends on the team's experience and the organization\u2019s setup. We\u2019ve found that in some organizations\u2014particularly those with large, fast-moving engineering teams\u2014test creation and maintenance can still be a bottleneck due to the flakiness of their e2e tests.For example, we\u2019ve seen an e-commerce team with 150+ mobile engineers struggle to keep their functional tests up-to-date while the company was running copy and marketing experiments. Another team in the food delivery space faced issues where unrelated changes in webviews caused their e2e tests to fail, making it impossible to run tests in a production-like system.Our goal is to help free up that time so that teams can focus on solving bigger challenges, like the debugging problems you\u2019ve mentioned.\n \nreply",
      "Integrate with https://www.honeycomb.io\n \nreply",
      "There are silly things that trip up e2e tests like a cookie pop up or network failures and whatnot. An AI can plow through these in a way that a purely coded test can\u2019t.Those types of transient issues aren\u2019t something that you would want to fail a test for given it still would let the human get the job done if it happened in the field.This seems like the most useful part of adding AI to e2e tests. The world is not deterministic, which AI handles well.Uber takes this approach here:\nhttps://www.uber.com/blog/generative-ai-for-high-quality-mob...\n \nreply"
    ],
    "link": "item?id=41924787",
    "first_paragraph": ""
  },
  {
    "title": "Async Rust in Three Parts (jacko.io)",
    "points": 80,
    "submitter": "oconnor663",
    "submit_time": "2024-10-23T14:23:29 1729732531",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41925323",
    "comments": [
      "I really liked the footnote implementation so I checked out his GitHub to see what kind of static site generator he was using, and it looks like he wrote his own? What a baller.\n \nreply",
      "In part two, the author explains trait objects in a way that is, I think, a little misleading.They're right that trait objects are dynamically sized types, which means they can't be passed by value to functions, but wrong that they need to be boxed; they can instead be put behind a reference. Both of the following are valid types.  type DynFutureBox = Pin<Box<dyn Future<Output = ()>>>;\n  type DynFutureRef<'f> = Pin<&'f dyn Future<Output = ()>>;\n\nYou can see this in the Rust Playground here: https://play.rust-lang.org/?version=stable&mode=debug&editio...\n \nreply",
      "Technically trait objects aren't entirely a thing at all. They're a concept that only makes sense in the concept of a pointer (references are safe pointers, `Box`es are smart pointers). You can refer to something as a trait object but the trait of the object is a property of the pointer and not the object. So if you have some struct that implements a trait you can cast a pointer to that struct to a pointer to a trait object, but that struct never stops being the struct, a trait object is just a different way of referring to the struct.\n \nreply",
      "My only experience with Rust has been synchronous mostly with little to show for in terms of async. And I liked Rust. When it ran, I was damn sure it was going to run. There is comfort in that: \"Tell me what to fix\". The clippy stuff etc. was great too.I read the 3 parts of this website and 'Wowsa'...  I'm definitely not going in that direction with Rust. I'll stick to dumb Go code, Swift or Python if I do async heavy stuff.It's hard enough to write good code, I don't see the point of finding walls to smash my head into.Think about it, if you write a lot of async code, chances are you have a ton of latency, waiting on I/O, disk, network etc. Using Rust for this in the first place isn't the wisest since performance isn't as important, most of your performance is wasted 'waiting' on things. Besides Rust wants purity and I/O is gritty little dirt.Sorry my comment turned into a bit of a hot take, feel free to disagree. This async stuff, doesn't look fun at all.\n \nreply",
      "It's amusing that the Rust Playground lets you run a hundred threads. That's generous of them. There's a ceiling below 1000, though. The author points out, \"On my Linux laptop I can spawn almost 19k threads before I hit this crash, but the Playground has tighter resource limits.\" Large servers can go higher than that.The thread-based I/O example with the compute bound poll loop is kind of strange.\"Join\" isn't really that useful when you have unrelated threads running finite tasks. Usually, you let the thread do its thing,finish, put results on a queue, and let the thread exit. Then it doesn't matter who finishes first.\nRust join is actually optional. You don't have to join to close out a thread and reap the thread resources. It's not like zombies in Unix/Linux, where some resources are tied up until the parent process calls wait().Loops where you join all the threads that are supposedly finished are usually troublesome. If somebody gets stuck, the joiner stalls. Clean exits from programs with lots of channels are troublesome. Channels with multiple senders don't close until all senders exit, which can be hard to arrange when something detects an error.In Rust, the main thread is special. (I consider this unfortunate, but web people like it, because inside browsers, the main thread is very special.) If the main thread exits, all the other threads are silently killed.\n \nreply",
      "> the Rust Playground lets you run a hundred threadsIt's more that we don't do anything to prevent it, other than coarse process-wide memory / CPU time limits. IIRC, Rust-spawned threads on Linux use 2MiB of stack space by default, so that seems like a likely cap.Note that the playground is only 2 cores and you are sharing with everyone else, so you aren't likely to really benefit.\n \nreply",
      "> Note that the playground is only 2 cores and you are sharing with everyone elseThis is amazing, I use it all the time with no performance issues so I expected it to be much beefier to support many simultaneous users.How many users does it serve? (Monthly or daily user and/or compilation job sent). And what tricks are used to keep it working? (I suspect it can re-use already compiled binaries of all supported dependencies and only need to compile the user's code and link it, but is there other clever strategies?)\n \nreply",
      "> Rust join is actually optional.I was recently surprised to learn that returning from main() with background threads still running is more or less UB in C++, because those threads can race against static destructors: https://www.reddit.com/r/cpp/comments/1fu0y6n/when_a_backgro.... C doesn't have this issue, though, as far as I know?\n \nreply",
      "atexit enters the chat\n \nreply",
      "> Loops where you join all the threads that are supposedly finished are usually troublesome. If somebody gets stuck, the joiner stalls. Clean exits from programs with lots of channels are troublesome. Channels with multiple senders don't close until all senders exit, which can be hard to arrange when something detects an error.I wish join-with-timeout was a more common/supported operation.\n \nreply"
    ],
    "link": "https://jacko.io/async_intro.html",
    "first_paragraph": "\u21ab Home2024 October 23Async/await, or \"async IO\", is a new-ish\u200bRust added async/await in 2019. For comparison, C# added it in\n2012, Python in 2015, JS in 2017, and C++ in 2020. language feature that lets\nour programs do more than one thing at a time. It's sort of an alternative to\nmultithreading, though Rust programs often use both. Async is popular with\nwebsites and network services that handle many connections at once,\u200b\"Many\" here conventionally means ten thousand or more. This is\nsometimes called the \"C10K problem\", short for 10,000 clients or\nconnections.\nbecause running lots of \"futures\" or \"tasks\" is more efficient than running\nlots of threads.This series is an introduction to futures, tasks, and async IO in Rust. Our\ngoal will be to get a good look at the machinery, so that async code doesn't\nfeel like magic. We'll start by translating (\"desugaring\") async examples into\nordinary Rust, and gradually we'll build our own async \"runtime\".\u200bFor now, a \"runtime\" is a library or framewor"
  },
  {
    "title": "Show HN: A macOS Client for HuggingFace Chat (github.com/huggingface)",
    "points": 88,
    "submitter": "archiv",
    "submit_time": "2024-10-23T18:00:11 1729732531",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41927624",
    "comments": [
      "Id personally be interested to know how this compares to a solution such as Ollama, which I have been using to run local models.\n \nreply",
      "Linux users have a pretty excellent native Ollama client called Alpaca, it's well worth checking out: https://flathub.org/apps/com.jeffser.AlpacaIt's still early in development but supports multimodal and some nice looking code blocks.\n \nreply",
      "Slightly off topic: some of the tools in HuggingChat don't work, even one of the official ones (Image Editor):  Error calling tool Image Editor\n  Parameters\n  image: output_2_0.webp\n  prompt: add a smiling emoji\n  Error\n  An error occurred while calling the tool edit_image: No API found\n\n\n  Error calling tool TTS (fast)\n  Parameters\n  text: hello\n  description: Laura's voice is monotone yet slightly fast in delivery, with a very close recording that almost has no background noise.\n  Error\n  An error occurred while calling the tool gen_tts_fast: Error: Error: Could not resolve app config.\n \nreply",
      "What does it do?\nIsn\u2019t HuggingChat already available as a dedicated web app (https://huggingface.co/chat/)?\n \nreply",
      "Yes but you now have the ability to run queries with a shortcut from your Mac, as well as switch to a local model using a dedicated keyboard shortcut. See demo: https://x.com/cyrilzakka/status/1838618605648490974\n \nreply",
      "Would it be possible to let you run local models without an account?\n \nreply",
      "Sorry, this link is not accessible for me. \nIt would be nice to add some more information to the repo\u2019s readme.\n \nreply",
      "@isodev sorry about that! Just uploaded a video to the README\n \nreply",
      "first impression: it's slick, looks a bit rough but promising, looking forward to using this and hope it improves.\n \nreply",
      "Congrats! I noticed it was initially closed-source and now it's opened, nice! Is it a project funded by HuggingFace? (Not immediately clear to me).I've built a macOS assistant too (more advanced though), with focus on privacy and easy of use (https://getfluid.app). I'd love to open-source it, but not sure about sustainability of such business model. Right now I'm experimenting with a fully private paid Llama hosting (for GPU poors).Good luck :)\n \nreply"
    ],
    "link": "https://github.com/huggingface/chat-macOS",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Making the community's best AI chat models available to everyone.\n      \n\n\n\nHuggingChat macOS is a native chat interface designed specifically for macOS users, leveraging the power of open-source language models. It brings the capabilities of advanced AI conversation right to your desktop, offering a seamless and intuitive experience.That's it! You can now launch HuggingChat from your Applications folder or using the dedicated keyboard shortcut: \u2318 + Shift + Return.We value your input! If you have any suggestions, encounter issues, or want to share your experience, please feel free to reach out:Your feedback helps improve HuggingChat macOS for everyone. Thank you for your support!\n        Making the community's best AI chat models available to everyone.\n      "
  },
  {
    "title": "It has been [33] days since the last Hubris kernel bug (oxide.computer)",
    "points": 19,
    "submitter": "mkeeter",
    "submit_time": "2024-10-23T21:40:28 1729732531",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41929505",
    "comments": [
      "Context: Hubris is an OS written in Rust for embedded systems https://hubris.oxide.computer/\n \nreply",
      "ok? it looks like there were not that many commits in that many days so what does this mean?\n \nreply"
    ],
    "link": "https://hubris.oxide.computer/bugs/",
    "first_paragraph": "It has beensince the last Hubris kernel bug:Back"
  },
  {
    "title": "Show HN: I built a task manager that separates \"do\" and \"due\" dates (apps.apple.com)",
    "points": 100,
    "submitter": "zesfy",
    "submit_time": "2024-10-23T14:52:34 1729732531",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=41925644",
    "comments": [
      "I have ADHD and hence am generally quite interested in apps in this space.Maybe it's just me but I found the app controls to be way too small, too many onboarding walk through steps and way too much information density in the Task screen.Progress, Highlight, Due Date, different lists - it's a lot.It seems to me you wanted to pack a punch, but it's so dense and so many steps involved that it falls into the productivity fallacy for me: It's increasing my executive disfunction and makes it harder and cumbersome to add tasks instead of reducing it.One app that really works for me, does one thing and does it well is for example Due: https://apps.apple.com/de/app/due-erinnerungen-timer/id39001...Not affiliated in any way with the app or it's creator.When it comes to apps like these, less is more for me.\n \nreply",
      "For years I have been fiddling with the idea of a personal task management system that synchronized status, due dates, prioritization, planning, projects, etc across platforms, and came to a conclusion that nothing beats a flat text file (with own notation for all the above) synchronized well across devices via something reliable yet lightweight like google keep, that I \"scan, update, reorder\" at least once a day.One huge insight was a notation to keep track of blocked tasks (usually by other people) and what/whom to \"poll\" periodically to check the status.\n \nreply",
      "I pay for Todoist because all the other synchronization stuff requires my attention or somehow is not supported well.Ideally I would like to have git available on iPhone and Apple tablets then I could use my repo that I have notes in on laptops and android phones.Well I am pissed by poor text editing on iPhone anyway so I will go back to android and then I can go back to text file with git on private repo.\n \nreply",
      "> Ideally I would like to have git available on iPhone and Apple tabletsI'd like to introduce you to Working Copy- https://apps.apple.com/us/app/working-copy-git-client/id8966...\n- https://workingcopy.app\n \nreply",
      "This looks great but... to work with a github repo I have to give:* read and write access to ALL gists* read and write access to ALL repos, public and private* read and write access to SSH public keysThat's a no from me.\n \nreply",
      "> and came to a conclusion that nothing beats a flat text file (with own notation for all the above) synchronized well across devices via something reliable yet lightweight like google keepChecklists in Apple Notes also works well for this if you\u2019ve already bought into that ecosystem.  I only wish it could track list items, so I could get basic stats on velocity.\n \nreply",
      "Getting things done (GTD) has a notion of \u201cwaiting for\u201d. Lots of people successfully follow GTDs structure methodologically.\n \nreply",
      "The App Store flow is about abstract features so to me it doesn\u2019t speak to value.Eg it\u2019s easy to know when something\u2019s due, but really hard to know when to work on what \u2014- what to do when. Saying \u201cschedule easily\u201d sort of buries the lede.I wonder if a leading panel talking about the frustrating churn of planning ( implicitly trading the urgent against the important) would activate more people and also provide the right keywords for finding the app via search\n \nreply",
      "I\u2019m confused why you have both Zesfy (https://apps.apple.com/il/app/zesfy-planner-calendar/id64799...) and Sepnia (https://apps.apple.com/il/app/sepnia-calendar-tasks/id151493...).They look very similar.\n \nreply",
      "Nice, it looks good and polished!I liked the on-boarding. I don't like the first screen being a pitch for a subscription, but I get that you probably need to sell hard to get subscriptions.I've recently launched a small app on the app store and it's no where near as polished! How long have you been working on it?\n \nreply"
    ],
    "link": "https://apps.apple.com/us/app/zesfy-planner-calendar/id6479947874",
    "first_paragraph": "Zesfy seamlessly integrates all your productivity workflow natively with your calendar. Here\u2019s how:Session: Group multiple tasks within a single calendar event.Task Progress: Automatically update your progress as you complete subtasks.Step: Break down tasks into manageable, step-by-step actions.Target: Easily organize tasks by due date.Space: Filter events from specific calendar sets to keep your schedule clutter-free.Connect with us:Email: dev@zesfy.comReddit: r/zesfyOur Term of use: https://www.apple.com/legal/internet-services/itunes/dev/stdeula/Version 1.3.0We\u2019ve added several exciting features and refreshed the UI to make planning your day even easier. Here\u2019s what\u2019s new:- Task Highlights - Plan Tasks - Due Dates - Calendar Groups- Redesign Calendar & Task ViewsGot questions or feedback? We\u2019d love to hear from you! Reach out at: dev@zesfy.com\n    The developer, Satrio Budiarto, indicated that the app\u2019s privacy practices may include handling of data as described below. For more info"
  },
  {
    "title": "Irreproducible Results (kk.org)",
    "points": 7,
    "submitter": "fsagx",
    "submit_time": "2024-10-20T13:35:21 1729732531",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41895278",
    "comments": [
      "I like a suggestion I read from Eliezer Yudkowsky - journals should accept or reject papers based on the experiment's preregistration, not based on the results\n \nreply",
      "This is extremely interesting.On top of keeping and publishing \"negative outcomes\", could we also move to actually requiring verification and validation by another \"lab\" (or really, an experiment done in different conditions)?\n \nreply",
      ">> [John Crabbe] performed a series of experiments on mouse behavior in three different science labs: in Albany, New York; Edmonton, Alberta; and Portland, Oregon. Before he conducted the experiments, he tried to standardize every variable he could think of. The same strains of mice were used in each lab, shipped on the same day from the same supplier. The animals were raised in the same kind of enclosure, with the same brand of sawdust bedding. They had been exposed to the same amount of incandescent light, were living with the same number of littermates, and were fed the exact same type of chow pellets. When the mice were handled, it was with the same kind of surgical glove, and when they were tested it was on the same equipment, at the same time in the morning.>> The premise of this test of replicability, of course, is that each of the labs should have generated the same pattern of results. \u201cIf any set of experiments should have passed the test, it should have been ours,\u201d Crabbe says. \u201cBut that\u2019s not the way it turned out.\u201d In one experiment, Crabbe injected a particular strain of mouse with cocaine. In Portland the mice given the drug moved, on average, six hundred centimetres more than they normally did; in Albany they moved seven hundred and one additional centimetres. But in the Edmonton lab they moved more than five thousand additional centimetres. Similar deviations were observed in a test of anxiety. Furthermore, these inconsistencies didn\u2019t follow any detectable pattern. In Portland one strain of mouse proved most anxious, while in Albany another strain won that distinction.>> The disturbing implication of the Crabbe study is that a lot of extraordinary scientific data are nothing but noise.This wasn't established when the post was written, but mice are sensitive and can align themselves to magnetic fields so if the output is movement the result is not thaaaat surprising. There are a lot of things that can affect mouse behavior, including possibly pheromones/smell of the experimenter. I am guessing that behavior patterns such as anxiety behavior can be socially reinforced as well, which could affect results. I can could come up with another dozen factors if I had to. Were mice tested one at a time? How many mice were tested? Time of day? Gut microbiota? If the effect isn't reproducible without the sun and moon lining up, then it could just a 'weak' effect that can be masked or enhanced by other factors. That doesn't mean it's not real, but that the underlying mechanism is unclear. Their experiment reminds me of the rat park experiment, which apparently did not always reproduce, but doesn't mean the effect isn't real in some conditions: https://en.wikipedia.org/wiki/Rat_Park.I think the idea of publishing negative results is a great one. There are already \"journals of negative results\". However, for each negative result you could also make the case that some small but important experimental detail is the reason why the result is negative. So negative results have to be repeatable too. Otherwise, no one would have time to read all of the negative results that are being generated. And it would probably be a bad idea to not try an experiment just because someone else tried it before and got a negative result once.Either way, researchers aren't incentivized to do that. You don't get more points on your grant submission for publishing negative results, unless you also found some neat positive results in the process.\n \nreply",
      "> There are a lot of things that can affect mouse behavior, including possibly pheromones/smell of the experimenter. I am guessing that behavior patterns such as anxiety behavior can be socially reinforced as well, which could affect results. I can could come up with another dozen factors if I had to. Were mice tested one at a time? How many mice were tested? Time of day? Gut microbiota? If the effect isn't reproducible without the sun and moon lining up, then it could just a 'weak' effect that can be masked or enhanced by other factors. That doesn't mean it's not real, but that the underlying mechanism is unclear.I think it does mean the claimed causal link is not real, or at least not proven. Certainly if the error bars from two \"reproductions\" of the same experiment do not overlap, you can't and mustn't really say that the experiment found anything.\n \nreply",
      "> A key canonical concept of the current scientific method is that an experiment must be reproducible by someone else. That ensures objectivity \u2014 that you are not fooling yourself.As opposed to the previous scientific method. /eyerollPompous trash.\n \nreply"
    ],
    "link": "https://kk.org/thetechnium/irreproducible/",
    "first_paragraph": "101 Additional AdvicesType 2 GrowthRights / ResponsibilitiesThe Scarcity of the Long-TermHill-Making vs Hill-ClimbingFuture EmbarrassmentsThe Trust FlipThings We Didn\u2019t Know About OurselvesThe Boredom DeviceLevels of WealthThe Tradeoffs in AIGod, the SuperpositionThe Best Since Sliced BreadJobs of the FutureThe Slow Frontier of Genetic ChoiceHow to Walk-and-TalkPaying people to have childrenThe Missing Monuments of Silicon ValleyThe Sphere, a new platformDreams are the Default for IntelligenceCringeworthy in the FutureChina\u2019s Immigrant Energy, Underappreciated12 Assumptions for Extraterrestrial LifeOvercoming Bias Against BignessThe Need For a BodyWishful WorriesRobots Will Make Us Better HumansThe Religions of AliensFuture ScarcitiesThe Propriety Path PlatformGood Morning, New Robots!More WubbleNon-Assigned NamesNot Future-ProofingThe Maintenance of WealthLaw of Universal UniquenessThree Levels of EugenicsAliens Are Here on EarthTraining AIs to Make ArtArt / Not ArtArt As an ExcuseAll"
  },
  {
    "title": "Bulk optimization of queries in Postgres (substack.com)",
    "points": 47,
    "submitter": "Explain_PS",
    "submit_time": "2024-10-21T12:27:27 1729732531",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41903425",
    "comments": [
      "No mention of https://explain.dalibo.com/ ?\n \nreply",
      "I love this tool. A little information overload if you aren't very familiar with how postgres queries work but it's also a good tool to learn that.\n \nreply",
      "What's the pricing?\n \nreply"
    ],
    "link": "https://substack.com/home/post/p-150506520",
    "first_paragraph": ""
  },
  {
    "title": "Reinforcement Learning: An Introduction (2018) (incompleteideas.net)",
    "points": 52,
    "submitter": "ibobev",
    "submit_time": "2024-10-22T09:58:10 1729732531",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41912769",
    "comments": [
      "There's lecture notes on this book available from David Silver at UCL: https://www.davidsilver.uk/teaching/\n \nreply",
      "This book seems to be very theoretical. Can someone recoment more practical books with code samples using some modern ML framework, probably something like _Hands-On Machine Learning_ by Geron Aurelien\n \nreply",
      "To be honest I think this may be actually an advantage: it explains concepts which otherwise are just weird parameters in code. Since it is pretty lengthy I would actually recommend to read the chapters relevant to a specific method you are interested in (maybe going a backwards to build the right context).If you I'd combine it with e.g. https://spinningup.openai.com/en/latest/ or doing some toy projects with https://stable-baselines3.readthedocs.io/en/master/ it would probably render the most value.\n \nreply",
      "\"Grokking Deep Reinforcement Learning\" by Miguel Morales and \"Deep Reinforcement Learning in Action\" by Alexander Zai and Brandon Brown both look promising, though the code might be outdated. Looks like they use the OpenAI Gym environment, which has since been forked and maintained as Gymnasium.\n \nreply",
      "https://course.fast.ai/\"You\u2019ll see that fast.ai\u2019s way of teaching is very different to what you might be used to, if you did a technical degree at university. Nearly all technical subjects at university are taught \u201cbottom up\u201d: start with basic foundations, and gradually work up to complete useful solutions to real world problems. But we go \u201ctop down\u201d: start with complete useful solutions to real world problems, and gradually work down to the basic foundations. Education experts recommend this approach for more effective learning.\"\n \nreply",
      "Related. Others?Reinforcement Learning: An Introduction (2018) [pdf] - https://news.ycombinator.com/item?id=19191746 - Feb 2019 (23 comments)Reinforcement Learning: An Introduction, Second Edition - https://news.ycombinator.com/item?id=18547998 - Nov 2018 (6 comments)New Draft of \u201cReinforcement Learning: An Introduction, Second Edition\u201d - https://news.ycombinator.com/item?id=12568414 - Sept 2016 (33 comments)Reinforcement Learning: An Introduction - https://news.ycombinator.com/item?id=1083662 - Jan 2010 (4 comments)\n \nreply",
      "Do we have any real world applications where the policy satisfies strictly some constraints (think physics: conservation of mass etc)? There is research in the field but not sure if anything is in production.\n \nreply",
      "This is what I'd like to know as well.\n \nreply",
      "Interesting to read the last section of the last chapter (17.6 Reinforcement Learning and the Future of Artificial Intelligence) given that the book is from 2020 and ChatGPT (in which RL plays a key role) was published in 2022.\n \nreply",
      "i pretty much have read this book. pretty boring tbh but still good. i would recommend doing hands on implementations with the cartpole environment\n \nreply"
    ],
    "link": "http://incompleteideas.net/book/the-book-2nd.html",
    "first_paragraph": "Buy\nfrom Amazon \nErrata and Notes\nFull\nPdf\u00a0 Without Margins\nCode \nSolutions -- send in your solutions for a\nchapter, get the official ones back (currently incomplete)\nSlides\nand Other Teaching\nAids\nLinks\nto pdfs of the literature\nsources cited in the book (Many thanks to Daniel Plop!)\nLatex Notation -- Want to use the book's notation in your own work?\nDownload this .sty file and this example of its use\n"
  },
  {
    "title": "Fearless SSH: Short-lived certificates bring Zero Trust to infrastructure (cloudflare.com)",
    "points": 58,
    "submitter": "mfrw",
    "submit_time": "2024-10-23T09:44:36 1729732531",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=41923429",
    "comments": [
      "Underlying tech is \u201cOpenpubkey\u201d.https://github.com/openpubkey/openpubkeyBastionZero just builds on top of that to provide a \u201cseamless\u201d UX for ssh sessions and some auditing/fedramp certification.Personally, not a fan of relying on CF. Need less centralization/consolidation into a few companies. It\u2019s bad enough with MS dominating the OS (consumer) space. AWS dominating cloud computing. And CF filling the gaps between the stack.\n \nreply",
      "By \"just builds on top of that\" it sounds like the same people are building it https://news.ycombinator.com/item?id=41929483 (compare username against GH repo).\n \nreply",
      "Completely agree. I also don't want to trust certificate authorities for my SSH connections let alone CF. Would not be surprised if it/they were compromised.\n \nreply",
      "Why does the title say \"Zero Trust\", when the article explains that this only works as long as every involved component of the Cloudflare MitM keylogger and its CA can be trusted?\nIf hosts keys are worthless because you do not know in advance what key the proxy will have.. than this scheme is back to trusting servers merely because they are in Cloudflare address space, no?\n \nreply",
      "https://www.cloudflare.com/learning/security/glossary/what-i...Zero Trust just means you stop inherently trusting your private network and verify every user/device/request regardless. If you opt in to using Cloudflare to do this then it requires running Cloudflare software.\n \nreply",
      "Thats one interpretation... ZT also posits assuming the network is compromised and hostile, that also applies to CF and their cloud/network. It blows my mind that so many solutions claim ZT while mandating TLS to their infra/cloud, you can trust their decryption of your date, and worst IMHO, they will MITM your OICD/SAML key to ensure the endpoint can authenticate and access services... that is a hell of a lot of implicit trust in them, not least of them being served a court order to decrypt your data.Zero trust done correctly done not have those same drawbacks.\n \nreply",
      "But with public key auth I'm already distrusting everyone on my private network.\n \nreply",
      "Technically I guess that's \"zero trust\" in the sense of meeting the requirement of not trusting internal connections more than external ones, but in practice I guess \"zero trust\" also typically entails making every connection go through the same user-based authentication system, which uploading specific keys to specific servers manually definitely doesn't achieve.\n \nreply",
      "I really enjoyed my time with Vault's ssh-ca (back when it had a sane license) but have now grown up and believe that any ssh access is an antipattern. For context, I'm also one of those \"immutable OS or GTFO\" chaps because in my experience the next thing that happens after some rando ssh-es into a machine is they launch vi or apt-get or whatever and now it's a snowflake with zero auditing of the actions taken to itI don't mean to detract from this, because short-lived creds are always better, but for my money I hope I never have sshd running on any machine again\n \nreply",
      "How do you handle db.Stuff I work on is write heavy so spawning dozens of app copies doesn\u2019t make sense if I just hog the db with Erie locks.\n \nreply"
    ],
    "link": "https://blog.cloudflare.com/intro-access-for-infrastructure-ssh/",
    "first_paragraph": ""
  }
]