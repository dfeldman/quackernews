[
  {
    "title": "Crokinole (pudding.cool)",
    "points": 373,
    "submitter": "Tomte",
    "submit_time": "2024-10-17T16:54:49.000000Z",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=41871375",
    "comments": [
      "I love IRL Crokinole so much that I made a single-player tower-defense-ish version of it for the browser: https://games.charlietran.com/crokunolu/Made it with the Crisp game library which I highly recommend for quickly making charming little 2D games: https://github.com/abagames/crisp-game-lib\n \nreply",
      "Very fun. Unfortunately there is a way to, in my opinion, cheese it. I made it to 2485 on my second attempt.Reversed to avoid spoiling the game:\n.gard ot reyalp eht gnicrof yb devlos eb dluoc siht ebyaM .kcab ot kcab tsrub eht reggirt ylbailer ot mhtyhr a ni taht od ot eunitnoc tsuj nac uoy ,kcilc ot ecalp thgir eht dnif uoy fI\n \nreply",
      "That's great feedback, thank you. I built a rudimentary control scheme on top of the minimal Crisp library and will take a look into doing a little more with it.\n \nreply",
      "Good job. Problem with a game like this is that it's too deterministic, you use the exact amount of impulse to aim the disc at the exact same spot every time. If you have decent handeye coordination it swiftly becomes rather trivial.The real game is less deterministic purely by having to contend with messy real world physics. If you want to make the game a little more engaging, I'd recommend trying to figure out a way to mix up where you have to fire the shots from, etc, add blockers to get in the way to shuffle the timing, etc.\n \nreply",
      "This is true, I jammed the game out rather quickly but next thing I\u2019d try is a hold-for-power control scheme (like the interactive demos in the article)\n \nreply",
      "as someone who has made huge mammoth games that I have never finished, this is the most well executed stylistic epic damn thing EVER. From the sounds to the low res, love it.\n \nreply",
      "This is a thing of beauty. Thank you for sharing!\n \nreply",
      "This is super fun; easy to get into and really nice that it has proper  mobile support, great stuff!\n \nreply",
      "Nice game, works great on mobile\n \nreply",
      "Love it!\n \nreply"
    ],
    "link": "https://pudding.cool/2024/10/crokinole/",
    "first_paragraph": "By Russell Samora | October 2024What you\u2019re seeing below is two of Crokinole\u2019s greats simultaneously securing perfect rounds.Technically speaking, they each flicked a 3.2cm disc 30cm across a board into a 3.5cm hole (just 9% wider than the disc itself) eight times in a row. In game terms, they made eight open 20s each.But it\u2019s just flicking a little disc across a small board. How hard can it be, really?The mesmerizing 56 seconds above were captured at the semifinals of the 2024 World Crokinole Championship, where Connor Reinman defeated Jason Slater. A matchup not unlike Magic vs. Bird, or Swift vs. Eilish.How rare was this feat of perfection? Was this one of those obscure new Olympic events? You may even be wondering, wtf is Crokinole?We\u2019ll get to all these questions. But first, you must understand Crokinole.If you are from the southern region of the Canadian province of Ontario, you may already be well-versed in Crokinole due to its Canadian origin. For the uninitiated, Crokinole is "
  },
  {
    "title": "Use Prolog to improve LLM's reasoning (shchegrikovich.substack.com)",
    "points": 183,
    "submitter": "shchegrikovich",
    "submit_time": "2024-10-13T21:22:48.000000Z",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=41831735",
    "comments": [
      "i've come to appreciate, over the past 2 years of heavy Prolog use, that all coding should be (eventually) be done in Prolog.It's one of few languages that is simultaneously a standalone logical formalism, and a standalone representation of computation. (With caveats and exceptions, I know). So a Prolog program can stand in as a document of all facts, rules and relations that a person/organization understands/declares to be true. Even if AI writes code for us, we should expect to have it presented and manipulated as a logical formalism.Now if someone cares to argue that some other language/compiler is better at generating more performant code on certain architectures, then that person can declare their arguments in a logical formalism (Prolog) and we can use Prolog to translate between language representations, compile, optimize, etc.\n \nreply",
      "> over the past 2 years of heavy Prolog useOh, cool. Mind if I pick your brain a bit?Recently, there was an HN post[0] of a paper that makes a case against pure logic languages in favor of \"functional logic\" ones, which they exhibit with Curry[1]. The setup argument is that Prolog's specs backtracking, which strongly downlimits it from full SLD resolution, causing fatally sharp edges in real world usage.Being fairly naive to the paradigm, my interpretation is that writing real Prolog programs involves carefully thinking about and controlling the resolution algorithm, which feels very different than straight knowledge declaration. I believe cut/0 is the go-to example. Is that your experience with Prolog in practice?The real meat of the paper, however, is in its case that functional logic languages fully embed Prolog with almost 1-to-1 expressivity, while also providing more refined tools for externalizing knowledge about the intended search space of solutions.Thoughts? How are you using Prolog, logic, or constraint programming? What languages and tooling in this arena do you reach for? What is some of your most hard-earned knowledge? Any lesser-known, but golden, websites, books, or materials you'd like to share?Cheers![0]:https://news.ycombinator.com/item?id=41816545[1]:https://www.curry-language.org/\n \nreply",
      "Been shouting here and many places for quite a while that CoT and all similar stuff eventually leads to logic programming. So happy I\u2019m not crazy.\n \nreply",
      "COT = Chain-of-Thoughthttps://arxiv.org/abs/2201.11903\n \nreply",
      "Prolog was a neat exercise, but for practical programming you might want to combine both logical and functional programming.  I think 'Curry' does that.\n \nreply",
      "Is it your thought that for the average programmer Prolog is easier to read and maintain than say Go, C#, or Java?\n \nreply",
      "I found it completely impenetrable in college for all but the simplest problems and I tried to re-read the textbook recently and I didn\u2019t do much better.\n \nreply",
      "It's taken ages for anything from functional programming to penetrate general use. Do you think uptake of logic stuff will be any faster?\n \nreply",
      "Prolog (and logic programming in general) is much older than you think. In fact, if we take modern functional programming to have been born with John Backus' Turing Award presentation[1], then it even predates it.Many advancements to functional programming were implemented on top of Prolog! Erlang's early versions were built on top of a Prolog-derived language who's name escapes me. It's the source of Erlang's unfamiliar syntax for more unlearned programmers. It's very much like writing Prolog if you had return values and no cuts or complex terms.As for penetrating general use, probably not without a major shift in the industry. But it's a very popular language just on the periphery, even to this day.[1] - https://dl.acm.org/doi/10.1145/359576.359579\n \nreply",
      "Did you just answer me with chatgpt?\n \nreply"
    ],
    "link": "https://shchegrikovich.substack.com/p/use-prolog-to-improve-llms-reasoning",
    "first_paragraph": ""
  },
  {
    "title": "Grandmaster-Level Chess Without Search (github.com/google-deepmind)",
    "points": 104,
    "submitter": "lawrenceyan",
    "submit_time": "2024-10-17T19:13:20.000000Z",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=41872813",
    "comments": [
      "I did a talk about this! (And also wrote up about my talk here[1]). This paper is a great example of both knowledge distillation. It's less of a paper about chess and more about how complicated non linear search functions - complete with whatever tuning experts can prepare - can be distilled into a (quasi-linear, if it's a standardized input like chess) transformer model.[1]: https://hlfshell.ai/posts/deepmind-grandmaster-chess-without...\n \nreply",
      "I think the vs. humans result should be taken with a huge grain of salt. These are blitz games, and their engine\u2019s elo was far higher against humans than against other bots. So it\u2019s likely that time was a factor, where humans are likely to flag (run out of time) or blunder in low time situations.It\u2019s still very cool that they could learn a very good eval function that doesn\u2019t require search. I would\u2019ve liked the authors to throw out the games where the Stockfish fallback kicked in though. Even for a human, mate in 2 vs mate in 10 is the difference between a win and a draw/loss on time.I also would\u2019ve liked to see a head to head with limited search depth Stockfish. That would tell us approximately how much of the search tree their eval function distilled.\n \nreply",
      "The reason the time (blitz) games make sense is because the distilled functionality is of a 50ms Stockfish eval function. The engine likely would perform worse as only the human would benefit from the additional time.As for limited search tree I like the idea! I think it's tough to measure, since the time it takes to perform search across various depths vary wildly based on the complexity of the position. I feel like you would have to compile a dataset of specific positions identified to require significant depth of search to find a \"good\" move.\n \nreply",
      "My point is that if the computer never flags it will have an inherent advantage in low time controls. If not, why not just test it in hyperbullet games? Games where humans flag in a drawn or winning position need to be excluded, otherwise it\u2019s unclear what this is even measuring.And limited depth games would not have been difficult to run. You can run a limited search Stockfish on a laptop using the UCI protocol: https://github.com/official-stockfish/Stockfish/wiki/UCI-%26...\n \nreply",
      "OT: what's the state of the art in non-GM level computer chess?Say I want to play chess with an opponent that is at about the same skill level as me, or perhaps I want to play with an opponent about 100 rating points above me for training.Most engines let you dumb them down by cutting search depth, but that usually doesn't work well. Sure, you end up beating them about half the time if you cut the search down enough but it generally feels like they were still outplaying you for much of the game and you won because they made one or two blunders.What I want is a computer opponent that plays at a level of my choosing but plays a game that feels like that of a typical human player of that level.Are there such engines?\n \nreply",
      "Maia does this reasonably well! You can play against it on Lichess. I have gotten a few \"feels like a human\" moments when playing against it - for example, getting it to fall into a trap that could trick a human but would easily be seen by a traditional search algorithm. It's not adjustable but there are a few different versions with different ratings (although it's not a very wide range).https://www.maiachess.com/https://lichess.org/@/maia1\n \nreply",
      "Piggy-backing off this - does anyone know of a quick way to evaluate the maia weights from python or js for a single board state? I'm trying to hack something together with my own search func intended for human play and I can't quite figure it out from the cpp in Lc0.\n \nreply",
      "GPT-3.5-turbo-instruct has a peak Elo of around 1800 (but of course can be prompted to play with less skill) and is as human like as you'll get at that level.\n \nreply",
      "No, not with adjustable rating. The best human-like engine is fairymax, but its Elo is estimated between 1700-2000.\n \nreply",
      "It doesn't seem that difficult to pull off - take one of the existing engines, get the top y moves, choose randomly. For each level down increase y by 1.\n \nreply"
    ],
    "link": "https://github.com/google-deepmind/searchless_chess",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Grandmaster-Level Chess Without Search\n      \n\nThis repository provides an implementation of our paper Grandmaster-Level Chess Without Search.The recent breakthrough successes in machine learning are mainly attributed to scale: namely large-scale attention-based architectures and datasets of unprecedented scale.\nThis paper investigates the impact of training at scale for chess.\nUnlike traditional chess engines that rely on complex heuristics, explicit search, or a combination of both, we train a 270M parameter transformer model with supervised learning on a dataset of 10 million chess games.\nWe annotate each board in the dataset with action-values provided by the powerful Stockfish 16 engine, leading to roughly 15 billion data points.\nOur largest model reaches a Lichess blitz Elo of 2895 against humans, and successfully solves a ser"
  },
  {
    "title": "NotebookLM launches feature to customize and guide audio overviews (blog.google)",
    "points": 202,
    "submitter": "alphabetting",
    "submit_time": "2024-10-17T16:42:04.000000Z",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=41871262",
    "comments": [
      "This works pretty well. I tried it with this guidance prompt:    You are both pelicans who work as data\n    journalist at a pelican news service.\n    Discuss this from the perspective of\n    pelican data journalists, being sure\n    to inject as many pelican related\n    anecdotes as possible\n\nAgainst this article: https://simonwillison.net/2024/Oct/17/video-scraping/You can listen to the 7m40s resulting MP4 here: https://simonwillison.net/2024/Oct/17/notebooklm-pelicans/Example snippets:    You ever find yourself wading through\n    mountains of data trying to pluck out\n    the juicy bits? It's like hunting for\n    a single shrimp in a whole kelp forest,\n    am I right?\n\nAnd:    The future of data journalism is\n    looking brighter than a school of\n    silversides reflecting the morning sun.\n    Until next time, keep those wings\n    spread, those eyes sharp, and those\n    minds open. There's a whole ocean\n    of data out there just waiting to be\n    explored.\n \nreply",
      "[flagged]",
      "Aside from being invited to a few events (Google I/O, OpenAI DevDay twice, an upcoming Anthropic hackathon that I applied for and was accepted) I've had no compensation from any of the LLM vendors.I've been invited to a few alpha/beta previews for all three of OpenAI/Google/Anthropic, and I've received API credits as an attendee of the DevDay events.I write about this stuff because it's really interesting to me, and super fun to explore.\n \nreply",
      "Fwiw, I'd say this falls under the guidelines \"Please don't post insinuations about astroturfing, shilling, brigading, foreign agents, and the like. It degrades discussion and is usually mistaken. If you're worried about abuse, email hn@ycombinator.com and we'll look at the data.\"\n \nreply",
      "we really want to know who is behind big pelican\n \nreply",
      "https://simonwillison.net/search/?q=pelican&sort=date\n \nreply",
      "My product https://reasonote.com allows you to generate podcasts as well, and it's had this feature for a few weeks.Improvements over NotebookLM:(1) You can start with just a subject, and you don't need a full document to begin (though you can do that too![1])(2) The podcast generates much faster(3) The podcasts are interactive -- you can ask the hosts to change direction mid podcast, and they will do so.(4) (Coming soon) You'll be able to make a Spotify-style Queue of Podcast topics, which you can add to as you encounter new ideas.The primary tradeoff is that the voices / personalities are somewhat less engaging than NotebookLM at this time, though this will be dramatically improved over the coming months.This is all in addition to the core value proposition, which is roughly \"AI Generated Duolingo for Any Subject\".It's early days, but I'd love for you all to check it out and give me feedback :)[1] Documents are currently heavily length-limited but this will be improved shortly\n \nreply",
      "NotebookLM is contributing to fake podcasts across the internet, with over 1,300 and counting:https://github.com/ListenNotes/ai-generated-fake-podcasts/bl...Google is taking a different approach this time, moving quickly. While NotebookLM is indeed a remarkable tool for personal productivity and learning, it also opens the door for spammers to mass-produce content that isn't meant for human consumption.Amidst all the praise for this project, I\u2019d like to offer a different perspective. I hope the NotebookLM team sees this and recognizes the seriousness of the spam issue, which will only grow if left unaddressed. If you know someone on the team, please bring this to their attention - Could you please provide a tool or some plain-English guidelines to help detect audio generated by NotebookLM? Is there a watermark or any other identifiable marker that can be used?Just recently, a Hacker News post highlighted how nearly all Google image results for \"baby peacock\" are AI-generated: https://news.ycombinator.com/item?id=41767648It won't be long before we see a similar trend with low-quality, AI-generated fake podcasts flooding the internet.\n \nreply",
      "Where do you get the \"low-quality\" part from - my experience with NotebookLM is that they create much higher quality, more informative, more fact based, and more concise podcasts than 99% of the stuff I listen to.   I've mostly switched entirely over to NotebookLM for my podcast listening.  They, generally, offer a far higher quality experience from my perspective.Maybe you have the problem backwards - we accidentally end up listening to non NotebookLM podcasts?\n \nreply",
      "A coworker fed some EU trade regulation page and its official FAQ to NotebookLM, and I was quite impressed with the results.It was factually accurate, and presented the topic in a manner that was easy to digest and kept it interesting.I didn't plan to but ended up listening to the whole thing, and I normally don't enjoy the podcast format.For someone new to the topic, it'd be a pretty great intro compared to reading the official pages.\n \nreply"
    ],
    "link": "https://blog.google/technology/ai/notebooklm-update-october-2024/",
    "first_paragraph": "Oct 17, 2024[[read-time]] min read\n          You can now guide NotebookLM's Audio Overview, guiding what the AI hosts focus on and their expertise level, and apply for the NotebookLM Business pilot program.\n        \nNotebookLM, a tool powered by Gemini 1.5, helps users understand complex information by instantly becoming an expert on uploaded sources. New features include customizable Audio Overviews, allowing users to provide instructions for AI hosts and listen to audio while working within NotebookLM. Additionally, NotebookLM Business, an upcoming version offered via Google Workspace, will provide enhanced features for businesses, universities, and organizations, prioritizing data privacy and security. Apply for the NotebookLM Business pilot program to gain early access to new features, training, and email support.\nNotebookLM, a tool powered by Gemini 1.5, helps users understand complex information by instantly becoming an expert on uploaded sources. New features include customizabl"
  },
  {
    "title": "Show HN: Tamagotchi-Like Characters for AI Assistants \u2013 All in JavaScript (github.com/barqawiz)",
    "points": 11,
    "submitter": "barqawiz",
    "submit_time": "2024-10-15T10:33:57.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/Barqawiz/Tamagotchi",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A collection of tamagotchi characters to give AI assistants an identity.\n      This project is inspired by the classic Tamagotchi device, featuring a virtual character drawn with JavaScript. The character can be controlled through various buttons, or it can dynamically change based on interactions with an AI assistant.Feel free to customize the project, or expand it for AI assistant interaction.\n        A collection of tamagotchi characters to give AI assistants an identity.\n      "
  },
  {
    "title": "The Fifth Generation Project in Japan (sjsu.edu)",
    "points": 47,
    "submitter": "tosh",
    "submit_time": "2024-10-17T22:03:01.000000Z",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=41874275",
    "comments": [
      "I gotta side with anigbrowl - the Wikipedia page[1] on the Fifth Generation Project is a much better read than this article. I'd encourage anyone interested in this topic to give it a look. For even more detail, consult the Feigenbaum & McCorduck book[2] mentioned by AlbertCory. It's a very interesting story.[1]: https://en.wikipedia.org/wiki/Fifth_Generation_Computer_Syst...[2]: https://www.amazon.com/Fifth-Generation-Artificial-Intellige...\n \nreply",
      "While it's certainly interesting to read about this sort of thing - and I'm interesting in all the computer history - it's worth pointing out that some very large percentage of all computer systems, from every country and every era failed.So it would be a mistake to read too much into this project being Japanese, or indeed criticize their goals and failures. Like all of their contemporaries they boldly went where no-one had gone before, and like the vast majority of their contemporaries (and most everyone since) discovered limitations in both the technology of the day, and their own abilities.The important thing is not that they failed. The important thing is that they tried.\n \nreply",
      ">So it would be a mistake to read too much into this project being Japanese,As a Japanese(-American) I can tell you why this project failed and more broadly why Japan's computer industry has failed outside of vidja gaemz (and that too is on its way out).So why did the Japanese fail? It's very simple: Lack of cooperation. The article describes the project \"was a collaborative effort of the Japanese computer industry\" but the results could not put any more mud on that thought.Japanese companies HATE cooperating, they will not create nor utilize common standards nor share knowledge with each other. Japanese companies will strive at every turn to create a captive market, hoping that once you've set foot in their little quagmire you will stay stuck with them.If you ever wondered why Canon camera lenses do not work on Nikon cameras and vice versa, why Kenwood microphones do not work with ICOM radios and vice versa, why Sony insisted on Memory Stick over SD card, why Toshiba threw out NAND flash technology, and so on then this is why. Try naming even a single international industrial standard to come out of Japan, you probably can't and I don't blame you. Sharing is not in Japan's DNA.Contrast the US computer industry where our companies besides Apple can and will cooperate to create and utilize common standards and push the market wider and forwards. PCI is a foremost example, but the very foundation of the industry is built on IBM PC-compatibles.All this means Japan will always be stuck with a bunch of small, individual pies nobody will care about, losing to the rest of the west who cooperate (and nowadays China who force entire industries at gunpoint) for a much bigger pie. You can't win when you're all trying to drag each other down in a zero sum game.\n \nreply",
      "What do you attribute this to?\n \nreply",
      "You might well be 100% right. I'd like to see the Japanese succeed, actually.However, it was simply not possible for anyone to succeed at AI in the early 80's. It took some Nobel-prize-winning software, a change of approach, and a massive increase in compute power to finally break through.\n \nreply",
      "The only thing we needed was the compute. Everything else had been discovered by the 80s.\n \nreply",
      "Yeah until we got a sort of core dominant systems, late 90s?   There were a lot of creative attempts at new systems and ideas.   They were either going to surpass the existing systems or fall on their face entirely.\n \nreply",
      "If you happen to click the link at the bottom of the page \"HOME PAGE OF applet-magic\" like I did, you get one of the fake virus web sites. Just do Ctrl-Alt-Del (on Windows), select Task Manager, sort on Name if you have to, right click on Google Chrome (or whatever your web browser is), and choose End Task. Or just cold start your computer.But hey lets keep web sites with links like that off Hacker News, what do you say?\n \nreply",
      "The title is somewhat intriguing but the content is extremely light, and on top contains this:  <!-- ZoneLabs Privacy Insertion -->\n  <script language='javascript' src='http://127.0.0.1:1026/js.cgi?pcaw&r=14945'></script>\n \nreply",
      "It's a long expired domain that originally belonged to that SJSU professor, I doubt he will ever update the links on these articles. That doesn't negate the value of the article itself.\n \nreply"
    ],
    "link": "https://www.sjsu.edu/faculty/watkins/5thgen.htm",
    "first_paragraph": "\n\n\n\n\napplet-magic.comThayer WatkinsSilicon Valley& Tornado \nAlleyUSA\n\n\n\n\n\n\n\nThe Fifth Generation Project in Japan \n\nThe Japanese Fifth Generation Project in computer technology was an \nattempt to leapfrog Western computer expertise and create an entirely new \ncomputer technology. Although the generation terminology is a bit murky, there \nwas the general perception that there had been a a number of generations \nof computer design and the accompanying operating methods. \nThe first generation \nwas the mainframe computers created by Sperry Rand and IBM during and after World \nWar II. They were hard-wired to carry out the desired sequence of computations. \nJohn Von Neumann and Herman Goldstine showed how hard wiring could be replaced by an \ninternally stored program. Machine language program was feasible but oh so \ntedious. Assembly language programming was a great advance in its day. Mnemonic \ncommands could be assembled and compiled into the machine language \ncoding required by the comput"
  },
  {
    "title": "I'm Peter Roberts, immigration attorney who does work for YC and startups. AMA",
    "points": 145,
    "submitter": "proberts",
    "submit_time": "2024-10-17T16:01:16.000000Z",
    "num_comments": 251,
    "comments_url": "https://news.ycombinator.com/item?id=41870887",
    "comments": [
      "Hello.  I don't have any questions but just wanted to share that I found Peter through one of these threads 9 years ago and his work and advice has been incredibly helpful in ensuring my continued ability to live and work in America through a variety of situations.  I highly recommend using his services and listening to his sage advice.\n \nreply",
      "That's very kind of you.  Thank you.\n \nreply",
      "Me and my cofounder are non-US residents and live in Germany. If we get into YC, what would a typical / recommended way to proceed be?We haven\u2019t established a company in Germany yet, we want to be strategic and make what\u2019s best to succeed.From what I know we can do the batch with our current tourist visa, so I\u2019d like to know more about the post batch options. Being US based or Germany based is an option for us.Thanks in advance\n \nreply",
      "That's right, a lot of international founders participate in the batch as business visitors, whether under ESTA or a B-1 visa.  The most common post-batch work authorization options are the country-specific visas (for those from Australia, Canada, Chile, Mexico, and Singapore), the O-1, and the E-2.  If based abroad and only coming to the U.S. for investor meetings and the like, then you could continue as a business visitor but practically this can become a problem if traveling to the U.S. regularly; at some point CBP will push back.\n \nreply",
      "Are you aware of the US Green Card lottery?  There are very few people who apply from Germany, so you can also try that route.  You have a surprisingly good chance to win it.  Also, you are not forced to accept it if you win the lottery -- you can decide.\n \nreply",
      "I think \"surprisingly good chance\" is overselling it. The reported odds for Germany are about 1%.https://dvlottery.me/win-chances-green-card-lottery\n \nreply",
      "There was a blogpost from someone from germany who got accepted. I looked it up for you: https://web.archive.org/web/20220604131034/https://richventu...There is also a post on hackernews about it: https://news.ycombinator.com/item?id=31601638\nAnd there is a Ask HN that could be helpful: https://news.ycombinator.com/item?id=31620700\n \nreply",
      "You should still create a US C-Corp, ideally in Delaware.\n \nreply",
      "Thank you for your answers, it's super helpful\n \nreply",
      "Could follow this group of EU business people forming a US entity this year:https://www.youtube.com/watch?v=shWe5dNqUrcAlso, attend a few free AMCHAM webinars to get the details on foreign ownership rules.Depending on how large your project becomes, some people may just use a brokerage service to localize the Merchant on Record (MoR) like withreach.com for online retailers. However, only US domestic corporations can mitigate liability on sold goods/services etc.   Keep aware of the IRS grace thresholds on sales, as even if you owe $0 in federal and state taxes... it can still become a $8k fine for forgetting to file a return in the US.Best of luck, =3\n \nreply"
    ],
    "link": "item?id=41870887",
    "first_paragraph": ""
  },
  {
    "title": "Gamedev in Lisp. Part 2: Dungeons and Interfaces (gitlab.com/lockie)",
    "points": 242,
    "submitter": "awkravchuk",
    "submit_time": "2024-10-17T13:26:25.000000Z",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=41869460",
    "comments": [
      "This is what all technical tutorials should look like. Well-composed and generally free of grammatical errors, spends just the right amount of time explaining each new topic as it is introduced, comes with full code samples, and includes visual samples of what the code does. Also, lengthy enough to treat the material in depth, while still being sufficiently self-contained that I can follow along -- without having read part 1 and without more than a few months of Common Lisp under my belt from a couple years back (tho I've done a decent amount of Clojure and Emacs Lisp.)Bravo, awkravchuk/Andrew :^)(Crossposted from https://mxjn.me/2024/10/17/1)\n \nreply",
      "Seconded! Top notch longform programming material.\n \nreply",
      "Few (tech) things pull at the heart string more than great projects/articles about Common Lisp. Man what a treat!Read the first part when it came back, really excited to read this one. Kudos to the author!\n \nreply",
      "Thanks mate, I appreciate it :)\n \nreply",
      "This is a very good read. I\u2019m developing a multiplayer, third-person, spell-based shooter game using Lisp (ClojureScript). It\u2019s a 3D web-based game. I\u2019ll also be writing a blog post about my journey, including the tools and abstractions I created for the project. If you\u2019re interested, here\u2019s a demo link: https://wizardmasters.io\n \nreply",
      "Jon Blow tried to make a game like this way back. It might be worth learning how/why it failed.\n \nreply",
      "Link to any video or anything on the subject?\n \nreply",
      "Unless I'm mistaken, I think fire_lake might be referring to a wholly unrelated first-person RPG spellcasting game project wherein the player would draw glyphs with their mouse in order to cast spells, and then there would be a surprise later in the game based on this mechanic (which was later repurposed for The Witness).\n \nreply",
      "Yes, it reminded me of his talk on prototyping:https://www.youtube.com/watch?v=ISutk1mauPM&t=426s\n \nreply",
      "Wow! Your package.sh and in general managing builds for three operating systems is a master class in itself - reading through the GitHub repo was a good learning experience.I usually build command line Common Lisp apps in SBCL or LispWorks, but I might do the next one in ECL because having builds for both macOS and Linux would be cool, and it would be fun to try something new.\n \nreply"
    ],
    "link": "https://gitlab.com/lockie/cl-fast-ecs/-/wikis/tutorial-2",
    "first_paragraph": ""
  },
  {
    "title": "Amplification of electromagnetic fields by a rotating body (nature.com)",
    "points": 124,
    "submitter": "keepamovin",
    "submit_time": "2024-10-13T07:23:07.000000Z",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=41825906",
    "comments": [
      "Apparently this effect applies to sound waves as well: https://arxiv.org/pdf/2005.03760\n \nreply",
      "Does this mean impossibly small subwoofers? Would the rotating part have to precisely match the audio frequency to be amplified?\n \nreply",
      "The mechanical driver part of the subwoofer might be able to be made smaller, but the surface that moves the air still needs to be large - there is a relationship to the wavelength of the sound involved that I no longer remember. This is why tweeters are small.\n \nreply",
      "Dumb question: why is it hard to make something spin really fast?Simple example: put your frictionless spherical cow on a spinny plate. Make it a very small cow; it's only there to have a point of rotation. Why frictionless? You don't want its butt to catch fire. Why spherical? It'll need to maximize volume dedicated to arm muscles; see below.Have the cow hold two ropes, each leading to a full-sized cow 10m away. Apply force to those cows (blow on them, or magnetize them and do a solenoid thing, or just make them very gassy cows and orient their spherical butts in opposite directions). Get them spinning at 1Hz. (This is very fast; remember the diameter is 20m.) Now have the middle cow pull the ropes, shortening them to 10cm. It's now spinning at 1Khz. 10mm gives 1Mhz. Conservation of angular momentum, baby.Do this in a vacuum in microgravity, and you don't need the center cow.Sure, if you're doing this at a bovine scale, the tension is ridiculously large. What makes it infeasible at a small scale?\n \nreply",
      "So, if you use eddy currents to delay the phase of an exciting field long enough that the object those eddy currents are inside of can spin more than 90 degrees, the response eddy current fields now AID instead of opposing the original field?This sounds quite a bit like what Steorm[1] was doing years ago. If ultraconductors[2] worked, you could actually build a mechanical device that had losses low enough to actually gain energy once a critical speed were obtained.[1] https://en.wikipedia.org/wiki/Steorn[2] https://patents.google.com/patent/US5777292A/en(Claim 7 is for material with a conductivity of 10^11 S/cm, which is 150,000 times better than copper)\n \nreply",
      "> This sounds quite a bit like what Steorm[sic] was doing years agoSteorn was a scam, and they never actually showed anything off. The only thing they did was rob some investors.\n \nreply",
      "> If ultraconductors[2] worked, you couldNot familiar with that idea, but this construction sounds a bit like: \"If only you had an (infinitely) rigid rod, you could push one end to communicate faster than lightspeed.\"Or in balder terms: \"If only we had a subtly impossible component, we could make a blatantly impossible machine.\"\n \nreply",
      "I am somewhat curious where the math on a perfect rigid rod breaks down (that is, where does the 0 end up under the line)\n \nreply",
      "My gut instinct is you\u2019d really need perfect incompressibility such that pushing one end of the rod would propagate the pressure wave to other end instantaneously. In other words, you have to make the speed of sound faster than the speed of light. I have no idea what the physical construction would look like. Maybe a string of singularities lined up and touching (hey, there\u2019s your 0!) without tearing spacetime apart?\n \nreply",
      "> Maybe a string of singularities lined up and touching (hey, there\u2019s your 0!) without tearing spacetime apart?At that point it's starting to sound less like a rigid rod and more like changing spacetime itself so that the two locations are closer together. :p\n \nreply"
    ],
    "link": "https://www.nature.com/articles/s41467-024-49689-w",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.Advertisement\nNature Communications\nvolume\u00a015, Article\u00a0number:\u00a05453 (2024)\n            Cite this article\n11k Accesses169 AltmetricMetrics detailsIn 1971, Zel\u2019dovich predicted the amplification of electromagnetic (EM) waves scattered by a rotating metallic cylinder, gaining mechanical rotational energy from the body. This phenomenon was believed to be unobservable with electromagnetic fields due to technological difficulties in meeting the condition of amplification that is, the cylinder must rotate faster than the frequency of the incoming radiation. Here, we measure the amplification of an electromagnetic field, generated "
  },
  {
    "title": "Removing PGP from PyPI (pypi.org)",
    "points": 53,
    "submitter": "harporoeder",
    "submit_time": "2024-10-17T20:03:28.000000Z",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=41873215",
    "comments": [
      "This is slightly old news. For those curious, PGP support on the modern PyPI (i.e. the new codebase that began to be used in 2017-18) was always vestigial, and this change merely polished off a component that was, empirically[1], doing very little to improve the security of the packaging ecosystem.Since then, PyPI has been working to adopt PEP 740[2], which both enforces a more modern cryptographic suite and signature scheme (built on Sigstore, although the design is adaptable) and is bootstrapped on PyPI's support for Trusted Publishing[3], meaning that it doesn't have the fundamental \"identity\" problem that PyPI-hosted PGP signatures have.The hard next step from there is putting verification in client hands, which is the #1 thing that actually makes any signature scheme actually useful.[1]: https://blog.yossarian.net/2023/05/21/PGP-signatures-on-PyPI...[2]: https://peps.python.org/pep-0740/[3]: https://docs.pypi.org/trusted-publishers/\n \nreply",
      "This feels like perfect being the enemy of good enough. There are examples where the system falls over but that doesn't mean that it completely negates the benefits.It is very easy to get blinkered into thinking that the specific problems they're citing absolutely need to be solved, and quite possibly an element of trying to use that as an excuse to reduce some maintenance overhead without understanding its benefits.\n \nreply",
      "Its benefits are very much completely negated in real-world use. See https://blog.yossarian.net/2023/05/21/PGP-signatures-on-PyPI... - the data suggests that nobody is verifying these PGP signatures at all.\n \nreply",
      "I believe the article you linked to doesn\u2019t seem to say anything about \u201cnobody verifying PGP signatures\u201d. We would need PyPI to publish their Datadog & Google Analytics data, but I\u2019d say the set of users who actually verify OpenPGP signatures intersects with the set of users faking/scrambling telemetry.\n \nreply",
      "I wrote the blog post in question. The claim that \"nobody is verifying PGP signatures (from PyPI)\" comes from the fact that around 1/3rd had no discoverable public keys on what remains of the keyserver network.Of the 2/3rd that did have discoverable keys, ~50% had no valid binding signature at the time of my audit, meaning that obtaining a living public key has worse-than-coin-toss odds for recent (>2020) PGP signatures on PyPI.Combined, these datapoints (and a lack of public noise about signatures failing to verify) strongly suggest that nobody was attempting to verify PGP signatures from PyPI at any meaningful scale. This was more or less confirmed by the near-zero amount of feedback PyPI got once it disabled PGP uploads.\n \nreply",
      "I stopped reading after this: \"PGP is an insecure [1] and outdated [2] ecosystem that hasn't reflected cryptographic best practices in decades [3].\"The first link [1] suggests avoiding encrypted email due to potential plaintext CC issues and instead recommends Signal or (check this) WhatsApp. However, with encrypted email, I have (or can have) full control over the keys and infrastructure, a level of security that Signal or WhatsApp can't match.The second link [2] is Moxie's rant, which I don't entirely agree with. Yes, GPG has a learning curve. But instead of teaching people how to use it, we're handed dumbed-down products like Signal (I've been using it since its early days as a simple sms encryption app, and I can tell you, it's gone downhill), which has a brilliant solution: it forces you to remember (better to say to write down) a huge random hex monstrosity just to decrypt a database backup later. And no, you can't change it.Despite the ongoing criticisms of GPG, no suitable alternative has been put forward and the likes of Signal, Tarsnap, and others [1] simply don't cut it. Many other projects running for years (with relatively good security track records, like kernel, debian, or cpan) have no problem with GPG. This is 5c.[1] https://latacora.micro.blog/2019/07/16/the-pgp-problem.html[2] https://moxie.org/2015/02/24/gpg-and-me.html[3] https://blog.cryptographyengineering.com/2014/08/13/whats-ma...\n \nreply",
      "Yeah I still use pgp a lot. Especially because of hardware backed tokens (on yubikey and openpgp cards) which I use a lot for file encryption.  The good thing is that there's toolchains for all desktop OSes and mobile (Android, with openkeychain).I'm sure there's better options but they're not as ubiquitous. I use it for file encryption, password manager (pass) and SSH login and everything works on all my stuff, with hardware tokens. Even on my tablet where Samsung cheaped out by not including NFC I can use the USB port.Replacements like fido2 and age fall short by not supporting all the usecases (file encryption for fido2, hardware tokens for age) or not having a complete toolchain on all platforms.\n \nreply",
      "I use pcks11 on my yubikeys, would I gain something by using the PGP functionality instead?\n \nreply",
      "Easier tooling. At least on Linux. PKCS11 requires a dynamically linked library (.so) which you pass to programs using it (like SSH) which is a bit annoying and because it's a binary linking it's not an API you can easily debug. It tends to just crash especially with version mismatches. The GPG agent API is easier for this. It works over a socket and can even be forwarded over SSH connections.Usually you end up using OpenSC/OpenCT for that. Also the tooling to manage the virtual smartcards is usually not as easy. I haven't used PIV for this (which is probably what you use on the yubikey to get PKCS11) but it was much harder to get going than simply using GPG Agent/scdaemon/libpcscd and the command \"gpg card-edit\" to configure the card itself.It's still not quite easy but I found it easier than PKCS11. I used that before with javacards and SmartHSM cards. The good thing about the PIV functionality is that it integrates really well with Windows active directory, which PGP of course doesn't. So if you're on Windows, PIV (with PKCS11) is probably the way to go (or Fido2 but it's more Windows Hello for Business rather than  AD functionality then, it depends whether you're a legacy or modern shop).The big benefit of yubikeys over smartcards is that you can use the touch functionality to approve every use of the yubikey, whereas an unlocked smartcard will approve every action without a physical button press (of course because it doesn't have such a button).\n \nreply",
      "I agree. PGP's status is just elevated by the people who get funded by Radio Free Asia and then write attacks against PGP.The Python cryptography \"experts\" will of course parrot the Moxie party line. Given the general lack of attention to detail, lack of testing and hate for people who demand stricter procedures in the Python ecosystem, never use any Python based cryptography.\n \nreply"
    ],
    "link": "https://blog.pypi.org/posts/2023-05-23-removing-pgp/",
    "first_paragraph": "If you are someone who is currently uploading signatures, your package uploads will\ncontinue to succeed, but any PGP signatures will be silently ignored. If you are\nsomeone who is currently downloading PGP signatures, existing signatures\nSHOULD continue to be available 1, but no new signatures will be made available.\nThe related API fields such as has_sig have all been hardcoded to always be\nFalse.Historically, PyPI has supported uploading PGP signatures alongside the release\nartifacts in an attempt to provide some level of package signing. However, the\napproach used had long standing,\ndocumented issues\nwhich had previously lead us to deemphasize the support\nfor PGP signatures over time by removing them from the PyPI web user interface.PyPI has continued to support uploading these signatures in the hope that there\nmight be some systems out there that found them useful. Recently though,\nan examination of the signatures on PyPI\nhas revealed to us that the current support for PGP signatur"
  },
  {
    "title": "C++ proposal: There are 8 bits in a byte (open-std.org)",
    "points": 120,
    "submitter": "Twirrim",
    "submit_time": "2024-10-17T22:21:15.000000Z",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=41874394",
    "comments": [
      "Previously, in JF's \"Can we acknowledge that every real computer works this way?\" series: \"Signed Integers are Two\u2019s Complement\" <https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p09...>\n \nreply",
      "Maybe specifying that floats are always IEEE floats should be next? Though that would obsolete this Linux kernel classic so maybe not.https://github.com/torvalds/linux/blob/master/include/math-e...\n \nreply",
      "That line is actually from a famous Dilbert cartoon.I found this snapshot of it, though it's not on the real Dilbert site:  https://www.reddit.com/r/linux/comments/73in9/computer_holy_...\n \nreply",
      "Love it\n \nreply",
      "During an internship in 1986 I wrote C code for a machine with 10-bit bytes, the BBN C/70. It was a horrible experience, and the existence of the machine in the first place was due to a cosmic accident of the negative kind.\n \nreply",
      "Somehow this machine found its way onto The Heart of Gold in a highly improbable chain of events.\n \nreply",
      "I programmed the Intel Intellivision cpu which had a 10 bit \"decl\". A wacky machine. It wasn't powerful enough for C.\n \nreply",
      "I've worked on a machine with 9-bit bytes (and 81-bit instructions) and others with 6-bit ones - nether has a C compiler\n \nreply",
      "D made a great leap forward with the following:1. bytes are 8 bits2. shorts are 16 bits3. ints are 32 bits4. longs are 64 bits5. arithmetic is 2's complement6. IEEE floating pointand a big chunk of wasted time trying to abstract these away and getting it wrong anyway was saved. Millions of people cried out in relief!Oh, and Unicode was the character set. Not EBCDIC, RADIX-50, etc.\n \nreply",
      "\"1. bytes are 8 bits\"How big is a bit?\n \nreply"
    ],
    "link": "https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2024/p3477r0.html",
    "first_paragraph": "C has the CHAR_BIT macro which contains the implementation-defined number of bits in a byte, without restrictions on the value of this number. C++ imports this macro as-is. Many other macros and character traits have values derived from CHAR_BIT. While this was historically relevant in computing\u2019s early days, modern hardware has overwhelmingly converged on the assumption that a byte is 8 bits. This document proposes that C++ formally mandates that a byte is 8 bits.Mainstream compilers already support this reality:GCC sets a default value of 8 but no upstream target changes the default;LLVM sets __CHAR_BIT__ to 8; andMSVC defines CHAR_BIT to 8.We can find vestigial support, for example GCC dropped dsp16xx in 2004, and 1750a in 2002. Search the web for more evidence finds a few GCC out-of-tree ports which do not seem relevant to modern C++.[POSIX] has mandated this reality since POSIX.1-2001 (or IEEE Std 1003.1-2001), saying:As a consequence of adding int8_t, the following are true:A byt"
  },
  {
    "title": "Why Does Everyone Run Ancient Postgres Versions? (neon.tech)",
    "points": 35,
    "submitter": "davidgomes",
    "submit_time": "2024-10-17T21:23:29.000000Z",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=41873957",
    "comments": [
      "Upgrades are hard. There was no replication in the before times. The original block-level replication didn't work among different major versions. Slony was a painful workaround based on triggers that amplified writes.Newer PostgreSQL versions are better. Yet still not quite as robust or easy as MySQL.At a certain scale even MySQL upgrades can be painful. At least when you cannot spare more than a few minutes of downtime.\n \nreply",
      "I've always wondered why Postgres is so insanely popular. I mean it has some nice things like very powerful support for a very comprehensive subset of SQL functionality, but most apps don't need all that.It really feels like early 1990s vintage Unix software. It's clunky and arcane and it's hard to feel confident doing anything complex with it.\n \nreply",
      "> I've always wondered why Postgres is so insanely popular.In no particular order, my preference for postgres is driven by:  * Date / time functions that don't suck\n  * UTF-8 is really UTF-8\n  * 99% of a backup can be done live with nothing more than rsyncing the data directory and the WAL files\n  * Really comprehensive documentation\n  * LTREE and fuzzy string match extensions\n  * Familiarity from using it for years\n\nMySQL/Maria I'm sure is fine, but it's one of hose things where it's just different enough and I haven't encountered a compelling use case for changing my preference.\n \nreply",
      "UTF-8 is what made me switch. It\u2019s insane MySQL has something called UTF-8 that isn't really UTF-8, but do have a type UTF8MB4 that actually is correct. This means if you use UFT-8 in MySQL, you can\u2019t use emoji for example.\n \nreply",
      "And the fact that adding real utf-8 support limited (limits?) the length of strings that can be indexed\n \nreply",
      "What's the alternative? MySQL? No transactional DDL, immediate fail.\n \nreply",
      "I worked for a company that migrated from mysql to postgres, but then got big enough they wanted to hire fulltime database experts and ended up migrating back to mysql because it was easier to find talent\n \nreply",
      "Dunno if that says much about Postgres, but it says a lot about the company\n \nreply",
      "> It really feels like early 1990s vintage Unix software. It's clunky and arcane and it's hard to feel confident doing anything complex with it.How software \"feels\" is subjective. Can you be more specific?\n \nreply",
      "The command line experience is old school style i.e. to show tables.  \\c database\n  \\dt\n\nVersus:  use database\n  show tables\n \nreply"
    ],
    "link": "https://neon.tech/blog/why-does-everyone-run-ancient-postgres-versions",
    "first_paragraph": "Most Postgres users won\u2019t upgrade to Postgres 17, but why? Postgres 17.0 has been out for a bit and it\u2019s awesome, but here\u2019s the reality: most Postgres users won\u2019t upgrade right away. Most probably aren\u2019t even on 16.4 or 16.anything \ud83d\ude31\u2014they\u2019re probably still using Postgres 15 or an even older version. \ud83d\ude2d With Postgres, it\u2019s not like the latest Call of Duty, where everyone wants the update the moment it\u2019s available.Why don\u2019t more people upgrade?There are many reasons for this, but it comes down to two core issues: Postgres works and upgrades suck.We at Neon are embedded in the Postgres world. Our team has worked on Postgres 17 and we\u2019re all excited about all the new features and optimizations. But the entire point of Neon is acknowledging that most developers aren\u2019t like us\u2014they aren\u2019t all about the database. For an average developer, the database is just a tool.\u00a0And Postgres has been a great tool since many versions before 17. For what most developers need, older versions of Postgres are"
  },
  {
    "title": "Cats are (almost) liquid (cell.com)",
    "points": 220,
    "submitter": "lnyan",
    "submit_time": "2024-10-17T11:43:00.000000Z",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=41868683",
    "comments": [
      "My cat woke up, did a big stretch, and yawned. Then she hiccoughed, turned into a small dragon, and coughed up a fireball.\"!!!\" I said.\"What?\" She shrugged back into cat form.\"You're a shape shifter?\"\"All cats are. There's just never any reason to not be a cat.\"/src https://mastodon.art/@MicroSFF/112928631782738642\n \nreply",
      "> While dogs slowed down and hesitated before they attempted to use an uncomfortably small opening, in the case of cats, we did not detect this change in their behavior before their attempt to go through even the narrowest openings. However, remarkably, cats showed hesitation both before they attempted to penetrate the shortest openings, and while they moved through it.I just skimmed, but I didn\u2019t see any mention whiskers. It\u2019s seems to me that cats can make highly precise measurements of width just by sticking their heads in a space, but height judgments requires additional consideration.\n \nreply",
      "> Cats are also aided by their large and sensitive vibrissae, which are positioned on such locations of their head that the cat can detect nearby obstacles in closer encounters. Vibrissal sensation can compensate for the somewhat weaker vision in cats from closer distances or in poorly illuminated environments. Therefore, it is possible that cats approached the narrow openings in our experiment without differential hesitation, and they could use their vibrissae to assess the suitability of the apertures before penetrating them.\n \nreply",
      "Oh thank you! I\u2019m just a lowly cat owner and did not know what vibrissae are.\n \nreply",
      "If you have ever put a cone on a cat (which lasts about five minutes), you see they get crazy. They hug the walls.Their whiskers are a major factor in their perception.I think they can also dislocate their spine.My cat likes to sit in what we call his \"Buddha\" position, with his back bent about 90 degrees, and his paws in front. This seems to be a common position. He'll sit like that for an hour.\n \nreply",
      "I think the cones must also screw up their aural spatial sensation (changing their perception of sound from fairly omni-directional, to seeming like all the sounds are coming from in front of the cone).\n \nreply",
      "My cats are weird and loved their cones after they got neutered. One would stick his head back in the cone after I took it off.\n \nreply",
      "I think all cats are weird in their own way.  Our cat often sunbathed in the middle of parking space across the road.  We occasionally had to go out to fetch him because he would refuse to move when someone started to drive into the space.\n \nreply",
      "I have a ginger tomboy who does exactly this. He loves just rolling around in the fine layer of dirt while keeping an eye out for birds or frogs\n \nreply",
      "Orange cats sharing their one brain cell.\n \nreply"
    ],
    "link": "https://www.cell.com/iscience/fulltext/S2589-0042(24)02024-8",
    "first_paragraph": ""
  },
  {
    "title": "The Border Crisis Won't Be Solved at the Border (texasmonthly.com)",
    "points": 25,
    "submitter": "bikenaga",
    "submit_time": "2024-10-17T23:23:05.000000Z",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41874813",
    "comments": [
      "It's the same situation in most countries.You need young, cheap labour from somewhere in order to sustain domestic agricultural and manufacturing industries. In the US it comes from people crossing the border, UK it was Schengen migration and in Australia legal immigration via loopholes that were never closed.And as we've seen in the UK the minute that goes away those businesses fold en masse as either (a) they make themselves uncompetitive to attract domestic workers or (b) they don't and they have no workers at all.\n \nreply",
      "> But one metric stayed virtually static: the number of managers arrested for hiring undocumented immigrants.This was especially obvious during the last administration* when ICE was raiding businesses left and right to deport people and as far as I know, almost never went after the meat packers and farms and other businesses that knowingly hired the migrant workers. As long as the employers don\u2019t see any penalties or they\u2019re so small as to be the cost of doing business, there will always have a large pool of undocumented immigrants who will replace the ones deported.I think if they were actually investigated the well would run deep with plenty of employers actively helping their new hires commit fraud to get past their I9 verification. It\u2019s unfortunate that this approach has never been politically viable because I suspect a majority of the population is willing to approach illegal immigration humanely while punishing the actual lawbreakers upstream to address the core economic impacts.* It was obvious to anyone paying attention during the Bush, Obama, and Biden administrations too but the media focus during Trump\u2019s made it especially stark how little enforcement was going on at the employer level.\n \nreply",
      "This is actually a decent article but it misses a few things.People need to understand that undocumented migrants are nothing more than a political football. The article (correctly) points out that nobody really wants to \"solve\" the problem. I'd go even further and say there is no problem. It's completely made up.The article points out that if you really wanted to address this (made up) problem, you'd go after the employers. Nobody does that. It has been tried, however. For example, the Alabama agriculture sector collapsed when they tried [1].Chicken farms are notorious for bad practices. Underpay undocumented migrants. When they start demanding safer working conditions and more pay, you simply call ICE for a sweep, pay a token fine and then start with a new batch.Undocumented migrants, from the perspective of employers, are about cheap labor and suppressing wages. The easiest solution for this is to document them. We used to do this. It was called the Bracero program [2].Top of this political theater is the \"migrant crime\" panic. For example, in a country with >20,000 homicides per year, so far this year 27 of them have been committed by noncitizens [3] and that includes documented and undocumented people.Construction and agriculture are utterly dependent on undocumented migrant labor.[1]: https://www.theguardian.com/world/2011/oct/14/alabama-immigr...[2]: https://guides.loc.gov/latinx-civil-rights/bracero-program[3]: https://www.cbp.gov/newsroom/stats/cbp-enforcement-statistic...\n \nreply",
      "> People need to understand that undocumented migrants are nothing more than a political football. The article (correctly) points out that nobody really wants to \"solve\" the problem. I'd go even further and say there is no problem. It's completely made up.For the American political class, nobody really cares about the immigrants except to make sure they don't get too uppity. Perpetuating an underclass is the entire point. If they truly cared, they would issue easy to get short term work visas like the Gulf states. This is the legacy of the Monroe doctrine, the Hispanic countries are basically taken for granted as a cheap labor pool given that no other country will try to uplift them and the general corruption is tolerated by the US so long as they don't go full Cuba.\n \nreply",
      "Archive: https://archive.is/NDHD9\n \nreply"
    ],
    "link": "https://www.texasmonthly.com/news-politics/border-crisis-texas-solutions/",
    "first_paragraph": ""
  },
  {
    "title": "Unit tests as documentation (thecoder.cafe)",
    "points": 69,
    "submitter": "thunderbong",
    "submit_time": "2024-10-17T17:22:45.000000Z",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=41871629",
    "comments": [
      "I share this ideal, but also have to gripe that \"descriptive test name\" is where this falls apart, every single time.Getting all your teammates to quit giving all their tests names like \"testTheThing\" is darn near impossible. It's socially painful to be the one constantly nagging people about names, but it really does take constant nagging to keep the quality high. As soon as the nagging stops, someone invariably starts cutting corners on the test names, and after that everyone who isn't a pedantic weenie about these things will start to follow suit.Which is honestly the sensible, well-adjusted decision. I'm the pedantic weenie on my team, and even I have to agree that I'd rather my team have a frustrating test suite than frustrating social dynamics.Personally - and this absolutely echoes the article's last point - I've been increasingly moving toward Donald Knuth's literate style of programming. It helps me organize my thoughts even better than TDD does, and it's earned me far more compliments about the readability of my code than a squeaky-clean test suite ever does. So much so that I'm beginning to hold hope that if you can build enough team mass around working that way it might even develop into a stable equilibrium point as people start to see how it really does make the job more enjoyable.\n \nreply",
      "> It's socially painful to be the one constantly nagging people about names, but it really does take constant nagging to keep the quality high.What do test names have to do with quality? If you want to use it as some sort of name/key, just have a comment/annotation/parameter that succinctly defines that,  along with any other metadata you want to add in readable English. Many testing frameworks support this. There's exactly zero benefit toTryToFitTheTestDescriptionIntoItsName.\n \nreply",
      "What kinds of things would you say are best as annotation vs in the test method name? Would you mind giving a few examples?Also, are you a fan of nesting test classes? Any opinions? Eg:Class fibrulatatorTest {  Class highVoltages{\n\n      Void tooMuchWillNoOp() {}\n      Void maxVoltage() {}\n}\n}\n \nreply",
      "That's not the point of the article. The code should be readable no exception. The only reason we should be ysing x y z are for coordinates ; i should be left for index_what ; same goes for parameters ; they should also contain what unit they are on (not scale, but scale_float) only exception I see are typed languages ; and even then I'm occasionally asked a detail about some obscure parameter that we set up a year ago. I understand it can sound goofy, but the extra effort is made towards other people working on the project, or future self. There is no way I can remember keys or where I left the meaning of those, and there is no justification to just write it down.Readability of the code makes a lot of it's quality. A working code that is not maintainable will be refactored. A non working cofe that is maintainable will be fixed.\n \nreply",
      "It's important to this article because its claiming that the name is coupled functionally to what the code tests -- that the test will fail if the name is wrong.I don't know if any test tools that work like that though.\n \nreply",
      "Have you considered a linter rule for test names? Both Checkstyle and ESLint did great work for our team\n \nreply",
      "Obviously this is slightly implementation dependent but if your tests are accompanied by programmatic documentation (that is output together with the test), doesn't that eliminate the need for a descriptive test name in the first place?If anything, in this scenario, I wouldn't even bother printing the test names, and would just give them generated identifier names instead. Otherwise, isn't it a bit like expecting git hashes to be meaningful when there's a commit message right there?\n \nreply",
      "> ...increasingly moving toward Donald Knuth's literate style of programming.I've been wishing for a long time that the industry would move towards this, but it is tough to get developers to write more than performative documentation that checks an agile sprint box, much less get product owners to allocate time test the documentation (throw someone unfamiliar with the code to do something small with it armed with only its documentation, like code another few necessary tests and document them, and correct the bumps in the consumption of the documentation). Even tougher to move towards the kind of Knuth'ian TeX'ish-quality and -sophistication documentation, which I consider necessary (though perhaps not sufficient) for taming increasing software complexity.I hoped the kind of deep technical writing at large scales supported by Adobe Framemaker would make its way into open source alternatives like Scribus, but instead we're stuck with Markdown and Mermaid, which have their place but are painful when maintaining content over a long time, sprawling audience roles, and broad scopes. Unfortunate, since LLM's could support a quite rich technical writing and editing delivery sitting on top of a Framemaker-feature'ish document processing system oriented towards supporting literal programming.\n \nreply",
      "One - unit tests explain nothing. They show what the output should be for a given input, but not why, or how you get there. I'm surprised by the nonchalant claim that \"unit tests explain code\". Am I missing something about the meaning of the english word \"explain\"?Two - so any input value outside of those in unit tests is undocumented / unspecified behavior? A documentation can contain an explanation in words, like what relation should hold between the inputs and outputs in all cases. Unit tests by their nature can only enumerate a finite number of cases.This seems like such an obviously not great idea...\n \nreply",
      "Not sure about this, but I like it the way it is done in the Rust ecosystem.In Rust, there are two types of comments. Regular ones (e.g. starting with //) and doc-comments (e.g. starting with ///). The latter will land in in the generated documentation when you run cargo doc.And now the cool thing: If you have example code in these doc comments, e.g. to explain how a feature of your library can be used, that script will automatically become part of the tests per default. That means you are unlikey to forget to update these examples when your code changes and you can use them as tests at the same time by asserting something at the end (which also communicates the outcome to the reader).\n \nreply"
    ],
    "link": "https://www.thecoder.cafe/p/unit-tests-as-documentation",
    "first_paragraph": ""
  },
  {
    "title": "Deriving the Kelly Criterion to Maximise Profits (obrhubr.org)",
    "points": 27,
    "submitter": "obrhubr",
    "submit_time": "2024-10-12T21:16:03.000000Z",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41822687",
    "comments": [
      "A word that is good to know here is ergodic [0]. Which I must admit to not really understanding although it is something like the average system behaviour being equivalent to a typical point's behaviour. If a process is non-ergodic then E[X] is usually not as helpful as it seems in formulating a strategy.[0] https://en.wikipedia.org/wiki/Ergodic_process\n \nreply",
      "Some math/finance nerds made a whole YouTube channel about ergodicity, which I've been really enjoying: https://youtu.be/VCb2AMN87cgNassim Taleb also talks about this quite a lot: https://youtu.be/91IOwS0gf3gTL;DR: while a single investment may be ergodic, portfolio management (the math behind weighting successive and concurrent investments/bets) is not, as it has a strong dependence on all prior states.\n \nreply",
      "this comment may be confusing and I doubt this will help much but:Ergodicity is less about memorylessness and more about the constraints on transitions into this or that state. A system is ergodic if \"anything that can be an outcome, eventually will happen\".\n \nreply",
      "A million years ago, when you could still find video poker games with 100%+ theoretical return or poorly thought-out promotions offering enough cash-back to get you over 100%, we'd calculate the Kelly number for a given opportunity -- the bankroll necessary to ride out hills and valleys in favorable situations.Spoiler: It's almost always 3-4x the value of a royal flush. So you needed $12-16k if you were playing a $1-per-coin game with a 1% edge at a pretty good clip.And what do you earn with perfect play in that situation? The princely sum of around $30 an hour.\n \nreply",
      "I would like to understand in detail what you just wrote.\"$1 per coin game\" is this a game where you put in $1 to play and get paid either $2 or $0 with 50-50 probability (0 expected).And the what does it mean %1 edge? Does it mean the probabilities are such that the expected payout is 1c per coin flip?\n \nreply",
      "The Kelly criterion is almost never used as-is because it is very sensitive to probability of success, which is hard to know accurately and in many cases, dynamically changing. This is easy to see in an Excel spreadsheet. Changing the probability by even 0.01 percent can vastly shift the results. The article calls this out in the last paragraph.The article mentions fractional Kelly is a hedge. But what fraction is optimal to use? That is also unknowable.Finance folks, correct me if I\u2019m wrong, but the Kelly Criterion is rarely used in financial models but is more a rule of thumb that says roughly if you have x $ and probability p, in a perfect world you should only bet y amount. But in reality y cannot be determined accurately because p is always changing or hard to measure.\n \nreply",
      "I am not sure what you mean by \"never used as is.\"The Kelly criterion is an optimization of capital growth (its logarithm) method/guide. Not using it doesn't change its correctness.But yes you need to know the advantage/the edge you have. Like with pricing methods eg for European options for Black Scholes you need to know the volatility and there is no way to know it, you estimate. This is where all the adjusting for bias and ML comes in.\n \nreply",
      "But do you calibrate p (say through estimation) and then apply the Kelly criterion in your portfolio?I don\u2019t think it is used in this way. It swings too much with a given p.\n \nreply",
      "You calibrate for a reasonable distribution of p and use that to estimate (Monte Carlo, etc.) expected gain, optimizing your investment based on that. With this technique your estimate will probably end up somewhere around the common heuristics.\n \nreply",
      "Here's a link to a bigger graph for the Blackjack Scenario:https://github.com/obrhubr/kelly-criterion-blackjack/blob/ma...I think it shows that Blackjack is not even theoretically winnable over time if you have to pay for information on the count in the form on minimum bets. The ideal case it that you bet $0.49 for every $1,000 in your investment pool when the count is extraordinarily high.Even if you hack the casino's cameras so you know the count without having to be at the table, your reward is a growth rate that is very low per hand.\n \nreply"
    ],
    "link": "https://obrhubr.org/kelly-criterion",
    "first_paragraph": "In a fictional casino which offers even odds on a fair coin toss game, how much of your money should you invest? If you said anything other than 0, you\u2019re leaving broke at the end of the night.If you want to know how much to invest every flip, you should apply the Kelly Criterion. It\u2019s a way of calculating the optimal fraction of your capital to invest in order to maximise growth over a long series of bets.This post was inspired by Entropic Thoughts incredible series on the Kelly Criterion.The expected value of a bet E[X]E[X]E[X] doesn\u2019t make sense in the real world. Betting all your money on a razor thin edge might be worth it in theory, but in reality you\u2019re as likely to lose and what are you going to invest with then?Let\u2019s take the example of a simple even odds game in which you invest half your money every turn. If you win, you get one and a half times your wealth, if you lose, you still have half your wealth. The expected value is 1, and thus in theory, playing an infinite number "
  },
  {
    "title": "Wayland Apps in WireGuard Docker Containers (procustodibus.com)",
    "points": 30,
    "submitter": "justinludwig",
    "submit_time": "2024-10-17T22:36:38.000000Z",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41874511",
    "comments": [
      "I do the same X + Wayland + PulseAudio socket mounted inside a (Podman, not Docker) container thing for sandboxing GUI programs like Steam, so that they do not have access to any host resources (especially the filesystem, which Steam has a reputation for not handling well :) ) unless I specifically allow it.\n \nreply",
      "Are you willing to share any of your code, especially for Steam?  I'd love to do this as well but had a hell of a time getting X/Wayland and the GPU all mounted in.   Gave up after a short time (have too many projects already) and just used the Flatpak, but I'd love to fully containerize it.\n \nreply",
      "https://news.ycombinator.com/item?id=34634854My current one is quite a bit different (based on Debian instead of Ubuntu, additional steps to make VR work, and some other changes) but the parts related to sockets etc are the same.\n \nreply",
      "This is wonderful!  I wish I could upvote this 10 times.  This clearly took a huge amount of work to write and also to verify (which they clearly did!), and I hope OP knows how much I recognize and appreciate that!This is exactly what I wish we got more from blog posts.  It covers all the things for a real world complex yet simplified (as much as possible without negating the value of the tutorial by skipping important steps) and does some really cool things like run GUI apps in containers by passing in Wayland display socket (and a serious GUI app - an RDP client connecting to a remote machine over the wg tunnel, and a browser (Firefox) with audio!), access the host SSH agent, set up a real-world wireguard tunnel that does IP forwarding, etc.OP, I hadn't heard of Custodibus before, but it sounds useful and I love that there's a GPL community version.  I'll be testing it out and you may have also won yourself a customer, gatewayed from this blog post :-)\n \nreply",
      "First, obligatory: Bingo:) (All the cool new tech in one title)But super cool; there's something really appealing about creating what I would call thin clients in containers - this should even make it easy to have, say, multiple browsers open, each on a different network.\n \nreply",
      "This is content marketing meant to showcase/get folks using the procustodibus docker images, FYI.\n \nreply",
      "Yes fair to point out, there is some of that, but it is genuinely very good content.  I typically hate marketing-masquerading-as-tech stuff, but if it were all like this, I'd have no problem whatsoever.  There is little to nothing here that is fluff or distraction for marketing purpose, and there's no purchase necessary to follow the whole post.  This seems written by a nerd who knows and loves what they do, and that happens to be work-related\n \nreply"
    ],
    "link": "https://www.procustodibus.com/blog/2024/10/wayland-wireguard-containers/",
    "first_paragraph": "Running WireGuard in a Docker container can be a convenient way to isolate a WireGuard network from the rest of a system. We\u2019ve covered a variety of different patterns for using WireGuard in containers in the past; in this article we\u2019ll dive deep into one particular pattern: using GUI (Graphical User Interface) Linux applications inside Docker containers to access remote sites through WireGuard.We\u2019ll build on the core \u201cContainer Network\u201d technique covered previously, where we use a shared network namespace to allow other containers to access the WireGuard network of a dedicated WireGuard container. In this case, we\u2019ll build and run several custom containers with a couple of GUI applications, allowing their GUIs to be used seamlessly as part of the container host\u2019s Wayland display\u2009\u2014\u2009while still being able to access remote servers through the isolated WireGuard network of the WireGuard container.We\u2019ll work our way up to running a full-fledged Firefox browser with video and audio in a con"
  },
  {
    "title": "Inkscape 1.4 Released (inkscape.org)",
    "points": 201,
    "submitter": "s1291",
    "submit_time": "2024-10-13T19:14:30.000000Z",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=41830699",
    "comments": [
      "The more I learn about the SVG spec, the more I understand the rationale of some of the UI decisions inkscape made, and the more impressed I am by how they implemented advanced techniques like shape union and intersection, clipping and masking.\n \nreply",
      "Care to elaborate? I'm curious.\n \nreply",
      "From the little I know about SVG, I wish there was an open source alternative to Inkscape that didn't support standard SVG but used a proprietary format instead.Almost everything you need to create vector art, SVG doesn't support.Multiple outlines in a single shape? No. Varying thickness in an outline? No. Rounded corners on arbitrary vertices? No. Non-destructive boolean operations? No. I'm not even sure SVG supports paragraphs.Many of these Inkscape implements as live filters, which are saved as SVG extensions in the XML .svg file that nobody but Inkscape can properly load.SVG is ridiculously bad as a creation format. It's a good format to export to, but as a backend and it's just insane. It's like using a single PNG file as a backend for your multi-layer 128bpp raster project.I use Inkscape a lot but I can't help but notice that the best vector art illustration come from Affinity Designer, Corel Draw, and Adobe Illustrator. If you compare the quality of artwork made with proprietary tools to those made with Inkscape, it's very clear that Inkscape severely limits what artists can achieve. You can easily create complex illustrations in other tools that would be a nightmare to manage in Inkscape. Just compare how you clip something in Inkscape to how you do it in Affinity. It's ridiculous how different the two workflows are.\n \nreply",
      "There is Cenon:https://cenon.info/which runs well in Mac OS and Linux and for the basics has the basic vector editing capabilities which folks would expect.\n \nreply",
      "Are you creatively crippled by not being able to create multiple outlines on a single shape on a file format that can be viewed in almost any device from here to eternity at no cost? Cause you know Michelangelo didn't use procreate in a iPad...do you?\n \nreply",
      "And the cavemen drawing on walls before Michelangelo didn't have paintbrushes, complex pigments and cathedrals to paint on? Heaven forbid we make better tools.Considering those operations are available in other vector art tools that aren't constrained by directly using SVG as the fundamental editing format it seems like a reasonable complaint.\n \nreply",
      "Use Krita for art.\n \nreply",
      "Krita is not for vector art.\n \nreply",
      "Inkscape has its UI quirks but is really quite a fantastic tool for people who make things. It's my go-to tool for anything that looks like a 2D vector image or plot. I even use it to design vinyl motorcycle emblems: https://blog.bityard.net/articles/2022/June/diy-vinyl-cut-mo...\n \nreply",
      "I love Inkscape. I\u2019ve been using it for 20 years. But it boggles my mind how it\u2019s still so horribly laggy on macOS. At least they got rid of the Xquartz dependency though.\n \nreply"
    ],
    "link": "https://inkscape.org/news/2024/10/13/inkscape-launches-version-14-powerful-new-accessib/",
    "first_paragraph": "\u2764\ufe0f Help us make Inkscape awesome! \u2764\ufe0fEnglishEnglishDeutschFran\u00e7aisHrvatskiItalianoEspa\u00f1olPortugu\u00easPortugu\u00eas Brasileiro\u010desky\u0420\u0443\u0441\u0441\u043a\u0438\u0439\u0627\u0644\u0639\u0631\u0628\u064a\u0651\u0629\u65e5\u672c\u8a9e\u7b80\u4f53\u4e2d\u6587\u7e41\u9ad4\u4e2d\u6587\ud55c\uad6d\uc5b4IndonesiaLog inRegisterOct. 13, 2024, 6:44 p.m.After months of waiting, we are finally ready to unbox the latest version of Inkscape... meet 1.4, the Geek edition, where accessibility and customization reign.Inkscape project developers, most of them volunteer contributors from countries around the world, have been plugging away behind the scenes on new features, improving current ones, bug fixes and setting the stage for the arrival of GTK 4.Let\u2019s dig into some of the new and improved features that enable more customization and better accessibility in Inkscape in a cool, geeky sort of way. Inkscape Power Users, this one\u2019s for you!The Inkscape 1.4 Filter Gallery dialog is your new entry point into the world of filters. Head to the Filters menu to find it and your favorites more easily, with previews by category or by typing key words in t"
  },
  {
    "title": "Industrious Dice (mathenchant.wordpress.com)",
    "points": 82,
    "submitter": "082349872349872",
    "submit_time": "2024-10-17T17:32:40.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41871729",
    "comments": [
      "That is the nerdiest thing I\u2019ve ever seen and it\u2019s appropriate that he was wearing a top hat while presenting it.However, the point of dice is typically not so you can count the numbers but so others can count them. People sitting at a table with you cannot see \u201cup\u201d, they can only see from an angle and so these dice while mathematically cool are completely impractical. Great example of white tower design.\n \nreply",
      "I'm (pleasantly) surprised to see this on the front page of HN!If anyone really wants to nerd out on the rhombic triacontahedral die, my proof of uniqueness is at https://s3.boskent.com/rhombic-triacontahedron-die/uniquenes...I first discovered the result computationally, using a program written in https://sentient-lang.org/, before finding the \u2018human\u2019 proof described in that PDF.\n \nreply",
      "This is glorious. What a world we live in.How can we make a die that functions as a d6, but has \"less pips\". An elegant dodecahedron as the solution. Less pips but more sides. Not an economic solution, but I love that these problems are being solved.\n \nreply",
      "Such a waste of faces :). Give a tetrahedron's faces 0,1,2, and 4 pips and throw it into a v-shaped groove so that it lands on an edge. (This is also a solution to numbering the corners of a cube).\n \nreply",
      "This would be a fun video to send to your DM before showing up with these dice.\n \nreply",
      "Oh no a boulder fell on your character. 200 points of crush damage.\n \nreply"
    ],
    "link": "https://mathenchant.wordpress.com/2024/10/17/industrious-dice/",
    "first_paragraph": "I\u2019m a professional mathematician. That means somebody pays me to do math. I\u2019m also a recreational mathematician. That means you might have to pay me to get me to stop.Wearing my recreational mathematician hat \u2013 quite literally, as you\u2019ll see \u2013 I gave a talk earlier this year on some newfangled dice that do the same sorts of jobs as old-fashioned dice but with fewer pips (\u201cpips\u201d being the technical name for all those little black dots).Fewer pips? Why would anyone on earth care about that? Dice manufacturers certainly don\u2019t; drilling the pips and coloring them in isn\u2019t a major expense. But I\u2019m not an applied mathematician. I\u2019m a pure/recreational mathematician, and I\u2019m allowed to care about anything I choose to. When I choose well, I find something new and interesting.FEWER PIPSThe standard die (called a d6 in the gaming community) has one job: to generate a random number between 1 and 6. The d6 accomplishes this job in a straightforward fashion by having 1, 2, 3, 4, 5, and 6 pips on it"
  },
  {
    "title": "Tubeworms live beneath the planetary crust around deep-sea vents (economist.com)",
    "points": 57,
    "submitter": "marban",
    "submit_time": "2024-10-17T17:41:38.000000Z",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=41871812",
    "comments": [
      "There's a theory that life actually originated not directly through photosynthesis based life, but originally from a very constant source of energy - the earth's crust - Hyperthermophile archaea - using non-oxygen based metabolism which migrated to the surface where photosynthesis evolved and took over as the core energy source.All laid out in Paul Davies' book - fascinating read: \nhttps://www.simonandschuster.com/books/The-Fifth-Miracle/Pau...\n \nreply",
      "Regarding Davies' book, what are the first four miracles that the title is referencing?\n \nreply",
      "Similar to Nick Lane's work!\n \nreply",
      "Actually this is not a theory. Photosynthesis came millions of years later than life. Plants are evolved from animals, not the other way around. Basic animals are less evolved than basic plants.\n \nreply",
      "Plants and animals evolved from different lineages of eukaryotic organisms. They share a common ancestor, but plants did not evolve from animals. Plants evolved from green algae, while animals evolved from colonial protists.I also take exception with the concept of \"more\" or \"less\" evolved. Do you mean \"complexity\"?\n \nreply",
      "He is right though that, \"Photosynthesis came millions of years later than life.\" And the parent post's claim, \"There's a theory that life actually originated not directly through photosynthesis based life,\" misrepresents that it is a commonly held view that life originated not directly through photosynthesis based life. It is generally understood that life predates photosynthesis.\n \nreply",
      "The study is here:https://www.nature.com/articles/s41467-024-52631-9Lots of cool pictures if you like oceanography stuff.\n \nreply",
      "It includes the actual photos of the animals in the subseafloor crust:https://www.nature.com/articles/s41467-024-52631-9/figures/2https://www.nature.com/articles/s41467-024-52631-9/figures/3\n \nreply",
      "https://archive.is/I23NT - mirroredI won't pretend to be a biologist, so forgive me if this is na\u00efve, but this does feel like it's at least within the realm of possibility of working similarly on Europa, right?   As in a non-zero chance at least.\n \nreply",
      "It would be bold to declare it impossible. We know so little about abiogenesis. There might be a critical ingredient or condition that Earth had which Europa lacks.Or maybe not. Europa\u2019s ocean could be teeming with life.\n \nreply"
    ],
    "link": "https://www.economist.com/science-and-technology/2024/10/16/tubeworms-live-beneath-the-planetary-crust-around-deep-sea-vents",
    "first_paragraph": ""
  }
]