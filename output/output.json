[
  {
    "title": "AI World Clocks (brianmoore.com)",
    "points": 642,
    "submitter": "waxpancake",
    "submit_time": "2025-11-14T18:35:22 1763145322",
    "num_comments": 253,
    "comments_url": "https://news.ycombinator.com/item?id=45930151",
    "comments": [
      "hi, I made this. thank you for posting.I love clocks and I love finding the edges of what any given technology is capable of.I've watched this for many hours and Kimi frequently gets the most accurate clock but also the least variation and is most boring. Qwen is often times the most insane and makes me laugh. Which one is \"better?\"reply",
      "If you're keeping all the generated clocks in a database, I'd love to see a Facemash style spin-off website where users pick the best clock between two options, with a leaderboard. I want to know what the best clock Qwen ever made was!reply",
      "We might on to creating a new crowd-ranked LLM benchmark here.reply",
      "Yes! Please do thisreply",
      "This is honestly the best thing I've seen on HN this month. It's stupid, enlightening... funny and profound and the same time. I have a strong temptation to pick some of these designs and build them in real life.I applaud you for spending money to get it done.reply",
      "Nice job! Maybe let users click an example to see the raw source (LLM output)reply",
      "I really like this. The broken ones are sometimes just failures, but sometimes provide intriguing new design ideas.reply",
      "This same principle is why my favorite image generation model is the earlier models from 2019-2020 where they could only reliably generate soup. It's like Rorschach tests, it's not about what's there, it's about what you see in them. I don't want a bot to make art for me, sometimes I just want some shroom-induced inspirational smears.reply",
      "I really miss that deepdream aesthetic with the dogs eyes popping up everywhere.reply",
      "Why is this different per user? I sent this to a few friends and they all see different things from what i'm seeing, for the same time..?reply"
    ],
    "link": "https://clocks.brianmoore.com/",
    "first_paragraph": "Every minute, a new clock is displayed that has been generated by nine different AI models.Each model is allowed 2000 tokens to generate its clock. Here is its prompt:Created by Brian Moore. You can also follow him on Instagram. Idea inspired by Matthew Rayfield.Generating AI Clocks..."
  },
  {
    "title": "Has Google solved two of AI's oldest problems? (generativehistory.substack.com)",
    "points": 145,
    "submitter": "scrlk",
    "submit_time": "2025-11-11T13:52:15 1762869135",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=45887262",
    "comments": [
      "I really hope they have because I\u2019ve also been experimenting with LLMs to automate searching through old archival handwritten documents. I\u2019m interested in the Conquistadors and their extensive accounts of their expeditions, but holy cow reading 16th century handwritten Spanish and translating it at the same time is a nightmare, requiring a ton of expertise and inside field knowledge. It doesn\u2019t help that they were often written in the field by semi-literate people who misused lots of words. Even the simplest accounts require quite a lot of detective work to decipher with subtle signals like that pound sign for the sugar loaf.> Whatever it is, users have reported some truly wild things: it codes fully functioning Windows and Apple OS clones, 3D design software, Nintendo emulators, and productivity suites from single prompts.This I\u2019m a lot more skeptical of. The linked twitter post just looks like something it would replicate via HTML/CSS/JS. Whats the kernel look like?reply",
      "I'm skeptical that they're actually capable of making something novel.   There are thousands of hobby operating systems and video game emulators on github for it to train off of so it's not particularly surprising that it can copy somebody else's homework.reply",
      "Doing something novel is incredibly difficult through LLM work alone. Dreaming, hallucinating, might eventually make novel possible but it has to be backed up be rock solid base work. We aren't there yet.The working memory it holds is still extremely small compared to what we would need for regular open ended tasks.Yes there are outliers and I'm not being specific enough but I can't type that much right now.reply",
      "I remain confused but still somewhat interested as to a definition of \"novel\", given how often this idea is wielded in the AI context. How is everyone so good at identifying \"novel\"?For example, I can't wrap my head around how a) a human could come up with a piece of writing that inarguably reads \"novel\" writing, while b) an AI could be guaranteed to not be able to do the same, under the same standard.reply",
      "Generally novel either refers to something that is new, or a certain type of literature.  If the AI is generating something functionally equivalent to a program in its training set (in this case, dozens or even hundreds of such programs) then it by definition cannot be novel.reply",
      "This is quite a narrow view of how the generation works. AI can extrapolate from the training set and explore new directions. It's not just cutting pieces and gluing together.reply",
      "Because if it's not in the training set it means the machine might not totally be a machine, and as we all know, only magical loafs of skull meat can transcend the mechanical nature of machines.reply",
      "This is a worthless comment. Please stop making it. Thanks!reply",
      "why would you admit on the internet that you fail the reverse turing test?reply",
      "Because I'm an LLM and you are tooreply"
    ],
    "link": "https://generativehistory.substack.com/p/has-google-quietly-solved-two-of",
    "first_paragraph": ""
  },
  {
    "title": "SSL Configuration Generator (ssl-config.mozilla.org)",
    "points": 52,
    "submitter": "smartmic",
    "submit_time": "2025-11-14T22:15:04 1763158504",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=45932798",
    "comments": [
      "In a similar spirit there is also a site to scan security headers of any site [1] and another to verify the TLS settings from the Mozilla SSL Configuration Generator [2] and a git repo with code to scan sites from the command line [3] useful if the site is not reachable on the internet or automated scans to HTML reports.[1] - https://securityheaders.com/[2] - https://www.ssllabs.com/ssltest/[3] - https://github.com/testssl/testssl.shreply",
      "Why are we still using the term \"SSL\" anywhere? It feels immediately like someone forgot the last 10 years of tech.reply",
      "SSL was developed by Netscape in the 90s and evolved into TLS. Netscape Navigator essentially evolved into Mozilla.\"They've\" been at it from the beginning, so it somehow seems understandable that Mozilla has a lot of \"SSL\" momentum or carryover.reply",
      "The main answer is a lot of the software on that page predates SSLs deprecation and people (sysadmins especially, because they wrote some bash script 20 years ago and want it to keep working) like backwards compatibility.reply",
      "I think the bigger answer is certificate vendors won't stop using the term.reply",
      "I tend to expand TLS thread-local storage, so SSL is less confusing for me.reply",
      "This looks like something that's been around forever, but it's the first time I've seen it. xkcd://{{derive_from_context}}It's a great idea. I've created (or copied) at least half of these output formats, a few of which I remember being annoyingly difficult to surface from the project docs.But in the moment today, it's mostly interesting to see the different ways of saying the same things in various configuration languages. And thinking that this might be why so many people with different brains find the technology world so obtuse and off-putting.The joke's on them, of course. We like it this way! (Never wrestle with a pig...)reply"
    ],
    "link": "https://ssl-config.mozilla.org/",
    "first_paragraph": ""
  },
  {
    "title": "HipKittens: Fast and furious AMD kernels (stanford.edu)",
    "points": 72,
    "submitter": "dataminer",
    "submit_time": "2025-11-14T02:27:20 1763087240",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=45923188",
    "comments": [
      "Full disclosure, we have a contract with AMD to get Llama 405B training on MI350X on MLPerf.Things are turning around for AMD. If you have an AMD card, go to pytorch.org, click Linux+ROCm and install PyTorch. 3 years ago, this was hopeless. Today, most mainline things work. I ran nanochat on MI300X and it just worked. I think that's true about MI350X now too. The MI350X machine is stable.They are clearly behind NVIDIA, nobody doubts that. And a lot of investment into software will be required to catch up. But 2 years ago they seemed hopeless, now they don't. Things take time.For training, it's NVIDIA and Google in first. AMD in second. And nobody in third. Intel and Tenstorrent are not remotely close. Huawei examples segfaulted. Groq gave up selling chips. Cerebras isn't available anywhere. Trainium had a 5 day wait time to get one instance and I lost interest.reply",
      "One thing I don't understand about Nvidia\u2019s valuation is that right now a small number of algorithms have 'won,' such as Transformers. The data is very important. Compared to the past where customized code was much more common, such as modeling code and HPC, the ecosystem was very important and it was almost impossible to implement all CUDA and related code.Competitors now only need to optimize for a narrow set of algorithms. If a vendor can run vLLM and Transformers efficiently, a massive market becomes available. Consequently, companies like AMD or Huawei should be able to catch up easily. What, then, is Nvidia\u2019s moat? Is InfiniBand enough?\"reply",
      "Infiniband is being replaced with UEC (and it isn't needed for inference). For inference there is no moat and smart players are buying/renting AMD or Google TPUs.reply",
      "Do you have evidence for this? I don\u2019t think Nvidia is switching to Ultra Ethernet, just adding it to the product line-upreply",
      "I didn't know you can you buy Google TPUs now?reply",
      "The vast amount of CUDA libraries for anything you can think of. I think there\u2019s where they have the biggest leverage.reply",
      "To rephrase the OP's point:  transformers et al are worth trillions.   All the other CUDA uses are worth tens or hundreds of billions.   They've totally got that locked up, but researchers is a smaller market than video games.reply",
      "AI is going to be so ubiquitous, something principled and open is going to supersede cuda at some point, as HTML5 did for Flash. CUDA isn't like an x86 vs ARM situation where they can use hardware dominance for decades, it's a higher level language, and being compatible with a wide range of systems benefits NVIDIA and their competitors. They're riding out their relative superiority for now, but we're going to see a standards and interoperability correction sometime soon, imo. NVIDIA will drive it, and it will gain them a few more years of dominance, but afaik nothing in their hardware IP means CUDA compatibility sacrifices performance or efficiency. They're also going to want to compete in the Chinese market, so being flexible about interoperability with their systems gains them a bit of market access that might otherwise be lost.There's a ton of pressure on the market to decouple nvidia's proprietary software from literally everything important to AI, and they will either gracefully transition and control it, or it will reach a breaking point and someone else will do it for (and to) them. I'm sure they've got finance nerds and quants informing and minmaxing their strategy, so they probably know to the quarter when they'll pivot and launch their FOSS, industry leading standards narrative (or whatever the strategy is.)reply",
      "The thing the \"just optimize AI\" crowd misses is that this isn't like optimizing a programming language implementation, where even the worst implementation is likely only 100x slower than a good implementation.AI is millions of times slower than optimal algorithms for most things.reply",
      "You'd think AMD would swing in on something like this and fund it with the money needed to succeed.  I have no knowledge of it but my guess is no, AMD never misses an opportunity to miss an opportunity - when it comes to GPUs and AI.reply"
    ],
    "link": "https://hazyresearch.stanford.edu/blog/2025-11-09-hk",
    "first_paragraph": "Nov 11, 2025 \u00b7 8 min readWilliam Hu, Drew Wadsworth, Chris R\u00e9, Simran AroraTeam: William Hu, Drew Wadsworth, Sean Siddens, Stanley Winata, Daniel Fu, Ryan Swann, Muhammad Osama, Christopher R\u00e9, Simran Arora\nLinks: Arxiv | CodeAI is gated by hardware. We think that opening up AI\u2019s compute landscape is one of the most important problems to be working on right now. Building towards this goal, we present HipKittens: SoTA AMD kernels and a collection of opinionated programming primitives to make AMD kernel dev easier!Named after AMD's CUDA equivalent, called HIP.While AI has largely used a single hardware vendor to get to its current stage, AMD GPU hardware now offers state-of-the-art peak compute and memory bandwidth. However, this performance is locked away from AI workflows due to the lack of mature AMD software.Table 1: Hardware overview. Peak memory and compute speeds for the latest generation GPU platforms.The AMD software ecosystem includes AITER, a high performance AI kernel library"
  },
  {
    "title": "A race condition in Aurora RDS (hightouch.com)",
    "points": 187,
    "submitter": "theanomaly",
    "submit_time": "2025-11-14T18:20:08 1763144408",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=45929921",
    "comments": [
      "This article seems to indicate that manually triggered failovers will always fail if your application tries to maintain its normal write traffic during that process.Not that I'm discounting the author's experience, but something doesn't quite add up:- How is it possible that other users of Aurora aren't experiencing this issue basically all the time?  How could AWS not know it exists?- If they know, how is this not an urgent P0 issue for AWS? This seems like the most basic of basic usability features is 100% broken.- Is there something more nuanced to the failure case here such as does this depend on transactions in-progress? I can see how maybe the failover is waiting for in-flight transactions to close and then maybe hits a timeout where it proceeds with the other part of the failover by accident.  That could explain why it doesn't seem like the issue is more widespread.reply",
      ">  How is it possible that other users of Aurora aren't experiencing this issue basically all the time? How could AWS not know it exists?If it's anything like how Azure handles this kind of issue, it's likely \"lots of people have experienced it, a restart fixes it so no one cares that much, few have any idea how to figure out a root cause on their own, and the process to find a root cause with the vendor is so painful that no one ever sees it through\"reply",
      "An experience not exclusive to cloud vendors :) Even better when the vendor throws their hands up cause the issue is not reliably repro'able.That was when I scripted away a test that ran hundreds of times a day on a lower environment, attempting repro. As they say, at scale, even insignificant issues become significant. I don't remember clearly, I think it was a 5-10% chance that the issue triggered.At least confirming the fix, which we did eventually receive, was mostly a breeze. Had to provide an inordinate amount of captures, logs, and data to get there though. Was quite the grueling few weeks, especially all the office politics laden calls.reply",
      "I've had customers with load related bugs for years simply because they'd reboot when the problem happened. When dealing with the F100 it seems there is a rather limited number of people in these organizations that can troubleshoot complex issues, that or they lock them away out of sight.reply",
      "It is a tough bargain to be fair, and it is seen in other places too. From developers copying out their stuff from their local git repo, recloning from remote, then pasting their stuff back, all the way to phone repair just meaning \"here's a new device, we synced all your data across for you\", it's fairly hard to argue with the economic factors and the effectiveness of this approach at play.With all the enterprise solutions being distributed, loosely coupled, self-healing, redundant, and fault-tolerant, issues like this essentially just slot in perfectly. Compound this with man-hours (especially expert ones) being a lot harder to justify for any one particular bump in tail latency, and the equation is just really not there for all this.What gets us specifically to look into things is either the issue being operationally gnarly (e.g. frequent, impacting, or both), or management being swayed enough by principled thinking (or at least pretending to be). I'd imagine it's the same elsewhere. The latter would mostly happen if fixing a given thing becomes an office political concern, or a corporate reputation one. You might wonder if those individual issues ever snowballed into a big one, but turns out human nature takes care of that just \"sufficiently enough\" before it would manifest \"too severely\". [0]Otherwise, you're looking at fixing / RCA'ing / working around someone else's product defect on their behalf, and giving your engineers a \"fun challenge\". Fun doesn't pay the bills, and we rarely saw much in return from the vendor in exchange for our research. I'd love to entertain the idea that maybe behind closed doors the negotiations went a little better because of these, but for various reasons, I really doubt so in hindsight.[0] as delightfully subjective as those get of coursereply",
      "If I had a nickel for every time I had to explain that rebooting a database server is usually the wrong choice I would have quite a fortune.reply",
      "Azure yes, I'd expect this and the restart would take many minutes. \nBeen there done that.AWS this is surprisingreply",
      "Theoretically you're supposed to assign lower prio to issues with known workarounds but then there should also be reporting for product management (which assigns weight by age of first occurrence and total count of similar issues).Amazon is mature enough for processes to reflect this, so my guess for why something like this could slip through is either too many new feature requests or many more critical issues to resolve.reply",
      "I'm surprised this hasn't come up more often too. When we worked with AWS on this, they confirmed there was nothing unique about our traffic pattern that would trigger this issue. We also didn't run into this race condition in any of our other regions running similar workloads. What's particularly concerning is that this seems to be a fundamental flaw in Aurora's failover mechanism that could theoretically affect anyone doing manual failover.reply",
      "> - How is it possible that other users of Aurora aren't experiencing this issue basically all the time? How could AWS not know it exists?I know that there is no comparison in the user base, but a few years ago I ran into a massive Python + MySQL bug that:1. made SELECT ... FOR UPDATE fail silenty\n2. aborted the transaction and set the connection into autocommit modeThis basically a worst case scenario in a transactional system.I was basically screaming like a mad man in the corner but no one seemed to care.Someone contacted me months later telling me that they experienced the same problem with \"interesting\" consequences in their system.The bug was eventually fixed but at that point I wasn't tracking it anymore, I provided a patch when I created the issue and moved on.https://stackoverflow.com/questions/945482/why-doesnt-anyone...reply"
    ],
    "link": "https://hightouch.com/blog/uncovering-a-race-condition-in-aurora-rds",
    "first_paragraph": "Enterprise-ready platform featuresBy teamBy industryFor marketingFor advertisingFeaturedLearn about the benefits of a Composable CDP and how it compares to a traditional CDP solutionAll integrationsPopular sourcesPopular destinationsPopular extensionsExploreDocumentationGet startedFeaturedRead real reviews from Hightouch customersNov 11, 2025Much of the developer world is familiar with the AWS outage in us-east-1 that occurred on October 20th due to a race condition bug inside a DNS management service. The backlog of events we needed to process from that outage on the 20th stretched our system to the limits, and so we decided to increase our headroom for event handling throughput. When we attempted that infrastructure upgrade on October 23rd, we ran into yet another race condition bug in Aurora RDS. This is the story of how we figured out it was an AWS bug (later confirmed by AWS) and what we learned.The Hightouch Events product enables organizations to gather and centralize user behav"
  },
  {
    "title": "Show HN: A visual guide to learning Jujutsu (JJ) (excalidraw.com)",
    "points": 5,
    "submitter": "anavid7",
    "submit_time": "2025-11-15T00:32:04 1763166724",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://excalidraw.com/#json=kMtNOJfH_UUOzBqt7WXx9,cyuXonQjb-Kor72f0F5YXg",
    "first_paragraph": ""
  },
  {
    "title": "Structured Outputs on the Claude Developer Platform (API) (claude.com)",
    "points": 85,
    "submitter": "adocomplete",
    "submit_time": "2025-11-14T19:04:23 1763147063",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=45930598",
    "comments": [
      "I feel like this is so core to any LLM automation it was crazy that anthropic is only adding it now.I built a customized deep research internally earlier this year that is made up of multiple \"agentic\" steps, each focusing on specific information to find. And the outputs of those steps are always in json and then the input for the next step. Sure you can work you way around failures by doing retries but its just one less thing to think about if you can guarantee that the random LLM output adheres at least to some sort of structure.reply",
      "Prior to this it was possible to get the same effect by defining a tool with the schema that you wanted and then telling the Anthropic API to always use that tool.I implemented structured outputs for Claude that way here: https://github.com/simonw/llm-anthropic/blob/500d277e9b4bec6...reply",
      "We've been running structured outputs via Claude on Bedrock in production for a year now and it works great. Give it a JSON schema, inject a '{', and sometimes do a bit of custom parsing on the response. GGNice to see them support it officially; however, OpenAI has officially supported this for a while but, at least historically, I have been unable to use it because it adds deterministic validation that errors on certain standard JSON Schema elements that we used. The lack of \"official\" support is the feature that pushed us to use Claude in the first place.It's unclear to me that we will need \"modes\" for these features.Another example: I used to think that I couldn't live without Claude Code \"plan mode\". Then I used Codex and asked it to write a markdown file with a todo list. A bit more typing but it works well and it's nice to be able to edit the plan directly in editor.Agree or Disagree?reply",
      "Before Claude Code shipped with plan mode, the workflow for using most coding agents was to have it create a `PLAN.md` and update/execute that plan. Planning mode was just a first class version of what users were already doing.reply",
      "I don't think the tool input schema thing does that inference-time trick. I think it just dumps the JSON schema into the context, and tells the model to conform to that schema.reply",
      "Same, but it\u2019s a PITA when you also want to support tool calling at the same time.\n Had to do a double call: call and check if it will use tools. If not, call again and force the use of the (now injected) return schema tool.reply",
      "So, so much this.Structured outputs are the most underappreciated LLM feature. If you're building anything except a chatbot, it's definitely worth familiarizing yourself without them.They're not too easy to use well, and there aren't that much resources on the internet explaining how to get the most out of them you can.reply",
      "I have had fairly bad luck specifying the JSONSchema for my structured outputs with Gemini. It seems like describing the schema with natural language descriptions works much better, though I do admit to needing that retry hack at times. Do you have any tips on getting the most out of a schema definition?reply",
      "Always have a top level object for one.But also Gemini supports contrained generation which can't fail to match a schema, so why not use that instead of prompting?reply",
      "Constrained generation makes models somewhat less intelligent. Although it shouldn't be an issue in thinking mode, since it can prepare an unconstrained response and then fix it up.reply"
    ],
    "link": "https://www.claude.com/blog/structured-outputs-on-the-claude-developer-platform",
    "first_paragraph": ""
  },
  {
    "title": "No Leak, No Problem \u2013 Bypassing ASLR with a ROP Chain to Gain RCE (modzero.com)",
    "points": 13,
    "submitter": "todsacerdoti",
    "submit_time": "2025-11-14T23:39:36 1763163576",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://modzero.com/en/blog/no-leak-no-problem/",
    "first_paragraph": "November 10, 2025 \u2014 by Michael ImfeldAfter my previous post on ARM exploitation, where we crafted an exploit for a known vulnerability, I decided to continue the research on a more modern IoT target. In this follow-up post, I will take you through building a considerably more complex binary exploit. We will explore the path from firmware extraction and analysis to the discovery of a previously unknown vulnerability and its exploitation. Follow along as we build an ARM ROP chain to bypass ASLR without an address leak, and achieve unauthenticated RCE.I examined the IN-8401 2K+, an IP camera from the German manufacturer INSTAR. It\u2019s a modern networked surveillance camera that exposes a web-based user interface for configuration and live view. As I later found this particular model shares its firmware with other devices from INSTAR\u2019s 2K+ and 4K series. According to Shodan1 there are roughly 12,000 INSTAR devices visible on the public internet.Before we can meaningfully hunt for vulnerabili"
  },
  {
    "title": "'No One Lives Forever' turns 25 and you still can't buy it legitimately (techdirt.com)",
    "points": 146,
    "submitter": "speckx",
    "submit_time": "2025-11-14T16:31:26 1763137886",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=45928492",
    "comments": [
      "NOLF is actually source-available [0][1][2], and it has been since not that long after its original release.There's also a community-driven project [3] keeping it playable on modern hardware - however, it hasn't seen any activity in several years.If you haven't played or heard of NOLF before, I highly encourage checking it out. It's a fantastic title, even after all these years.0: https://web.archive.org/web/20020217233624/http://pc.ign.com...1: https://web.archive.org/web/20010720053220/http://noonelives...2: https://github.com/osgcc/no-one-lives-forever3: https://github.com/haekb/nolf1-modernizerreply",
      "So you can't buy it, but you can play it, and the source is available. Is this really a problem? I know the article mentions this in passing, but preservation & the ability to actually play a 25 year old game is more important than its capitalization, IMO.reply",
      "Well, no, you can't play it because the source code doesn't include assets like the 3d models and textures and levels and sound files. You need to acquire those some other way if you want to build a playable version of the game.It's like GZDoom, you have to supply your own copy of DOOM.WADreply",
      "I hope you aren't suggesting the only way to play the game is to build it yourself first. This is not the case.reply",
      "No he's stating that getting the executable is the easy part.reply",
      "That isn't at all what they are saying.\nThey are saying that you need to provide all the game assets. Exactly like you do if you want to play the original Doom with modern source ports.\nSince the game is not available to buy, this means either pulling those assets from an original retail copy, or pirating them.reply",
      "Since the game is not available to buy, this means either pulling those assets from an original retail copy, or pirating them.Even if you don't want to pirate it, there are lots of copies for multiple platforms available to buy just on eBay. \u00af\\_(\u30c4)_/\u00afreply",
      "> preservation & the ability to actually play a 25 year old game is more important than its capitalization> Even if you don't want to pirate it, there are lots of copies for multiple platforms available to buy just on eBay.This feels like a contradictory position.On the one hand the important thing is the preservation and availability of a work. On the other hand it's okay if the it is only available as 20+ year old used copies and pirated copies.And any preservation or restoration project is under the shadow of 3 companies (Warner Bros., Activision, and 20th Century Fox) which have all recently \"complained that they may have rights to [NOLF] and may sue over it\"reply",
      "That a company should be able to profit from something they made 20 years ago (and didn't touch since) feels wrong.reply",
      "Except that you can get FreeDOOM as a replacement, even for PWADs:https://freedoom.github.ioGet a daily build.reply"
    ],
    "link": "https://www.techdirt.com/2025/11/13/no-one-lives-forever-turns-25-you-still-cant-buy-it-legitimately/",
    "first_paragraph": "\n\n\t\t\t\tCopyright\t\t\t\nOne of my favorite things in all of professional sports is the unofficial holiday referred to as \u201cBobby Bonilla Day.\u201d The short version of it is that Bonilla played for the New York Mets decades ago and eventually bought out his contract in 2000 when they decided they were done with him. Rather than pay the $5.9 million buyout of the contract up front, the team instead made the bonkers decision to negotiate a deferred payment schedule for that amount with 8% interest over the course of 25 years. The result is that the Mets will be paying Bonilla $1.2 million per year every July 1st, starting in 2011 and ending in 2035. And if you can\u2019t make sense of the math on that one, it\u2019s because you aren\u2019t aware that the Mets ownership was one of Bernie Madoff\u2019s many victims, which is why they had to defer the payments.November 10th is not Bobby Bonilla Day. But it should be named \u201cLet Us Play No One Lives Forever, You Assholes Day.\u201d The classic spy-shooter turned 25 on that dat"
  },
  {
    "title": "All praise to the lunch ladies (bittersoutherner.com)",
    "points": 119,
    "submitter": "gmays",
    "submit_time": "2025-11-14T19:54:58 1763150098",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=45931403",
    "comments": [
      "Indeed.Occasionally I will see posted the beautiful school lunches given to children in many European countries.  Nutritious, appetizing, made from scratch.These lunch ladies are the ones fighting to be allowed to do the same things for the children in their communities in the USA.  But getting ham strung by the whims of federal politics and the crippling fear that someone somewhere might be given something for free they could have paid for themselves.More power to the Lunch Ladies.reply",
      "The view from the other side: NeverSeconds.[1]Each day in 2012-2014, a middle school girl in Scotland took a picture of her school lunch and wrote a review on her blog, including number of hairs and insects. The headmaster of the school told her to stop taking pictures of her lunches. So she published a note, \"Goodbye\". That got some small publicity. Then the local town council backed up the headmaster. More publicity. Politicians became involved. National press coverage. Coverage in Wired.\n\"Time to fire the dinner ladies\" article in a Scottish tabloid.\nWorldwide press coverage. BBC interviews. Girl wins \"Public Campaigner of the Year award\". Headmaster in trouble.[1] https://en.wikipedia.org/wiki/NeverSecondsreply",
      "Hah, this is great to read even now. It\u2019s nice that these little bits of the internet are still up 11 years later for me to enjoy.reply",
      "So this is interesting but I would hardly call it \u201cthe other side\u201d. This isn\u2019t a battle between lunch ladies and students.Even here the girl was not asking for them to stop serving the food. Rather she said they should serve more and also improve it.> She added: \u201cI'd like them to serve more, and maybe let some people have seconds if they want to ... and not serve stuff that's a wee bit disgusting.\u201dhttps://web.archive.org/web/20240418175610/https://www.teleg...reply",
      "The blog in question, right when posting seemed to pick up: https://neverseconds.blogspot.com/2012/05/reply",
      "Wikipedia: \"number of hairs\"You: \"number of hairs and insects\"Citation, please?reply",
      "\"Someone somewhere might be given something they don't need.\"Sad and incredible how much of US politics is summed up with just that one statement.reply",
      "The rhetoric you see in some places about how social assistance is used on hair weaves says something about the underlying reasons for much of this concern.reply",
      "Remember the only reason we have school lunch programs in the US at all is because the Black Panthers started a free breakfast program for black children in the 70s and the government wanted to undermine the political and propaganda power the Black Panthers had gained through that and other social programs. So the government created its own, then Reagan underfunded it.reply",
      "No, that is not true.  The first school lunch programs started with private initiatives in the 1890s.  The first major federal program for student lunches was the National School Lunch Program enacted in 1946.  That has since been updated several times:  the Child Nutrition Act in 1966, the Child Care Food Program in 1975, etc.reply"
    ],
    "link": "https://bittersoutherner.com/issue-no-12/all-praise-to-the-lunch-ladies",
    "first_paragraph": "Better South / Better WordBlessed are the women who watch over America\u2019s children.November 4, 2025Granny won me over with the government cheese. As a child, maybe 4 or 5 years old, when I\u2019d visit her on occasional Sundays in Blue Ridge, Georgia, she\u2019d slice me off a little treat \u2014 an orange rectangle from a brown cardboard box in the refrigerator. We would sit around her kitchen table, where she held court with my aunts by telling stories and making plans for canning vegetables. Sometimes the aunts smoked cigarettes, which they\u2019d quickly stamp out when my preacher-grandfather came around the corner. Nevermind that my snack was processed and inexpensive, a generic type of Velveeta. In those days at Granny\u2019s, sitting with my cheese and the grown-ups in our rural mountain town, I might as well have been tasting Camembert on the banks of the Seine.\u00a0Nevermind, too, the Mason jars of homemade soup on her shelves, a kaleidoscope of summer\u2019s bounty \u2014 tomatoes, okra, corn \u2014 put up and waiting t"
  },
  {
    "title": "Manganese is Lyme disease's double-edge sword (northwestern.edu)",
    "points": 118,
    "submitter": "gmays",
    "submit_time": "2025-11-14T16:51:03 1763139063",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=45928709",
    "comments": [
      "I'm seeing comments jumping to conclusions about taking manganese supplements or trying to starve yourself of manganese. These are dangerously wrong interpretations of the article.Any interventions would have to be targeted directly at the B. burgdorferi to disrupt their internal regulation of manganese. It's a long shot used to make this research discovery sound more impressive, not an actual cure.Your own body uses manganese for critical processes like your metabolism, critical brain functionality, and generating important antioxidants in your mitochondria (MnSOD, the same one mentioned inside of Lyme in the article).Your body also regulates manganese absorption and excretion. Manganese deficiency is extremely rare outside of genetic conditions or other medical problems which interfere with this regulation. You can't really starve yourself of manganese by adjusting your diet or even by periods of fasting.So if you're reading this and thinking you could defeat Lyme by starving yourself of manganese or overdosing on manganese, don't. That's not what this article is saying.reply",
      "I agree that we should not simply self-treat by supplements or starving ourselves.But you are dead wrong that interventions would need to be directly targeted at B. burgdorferi.The standard and effective treatment for TB back in the 1950s was a combination therapy with Streptomycin, Isoniazid (INH), and PAS. The purpose of PAS was to create a low manganese environment in the body, which put stress on Mycobacterium tuberculosis - the bacteria that causes TB. This stress did not kill the bacteria by itself, but it did make it more vulnerable to the rest of the treatment. Because of this treatment, we have a lot of data showing how well people do with low manganese for a period of 1-2 years. (That was the time that this treatment required.) It wasn't pleasant (in particular it came with nausea), but it was definitely survivable.If low manganese really does stress B. burgdorferi, then a similar combination is worth trying today. Better yet, this combination would not require the development of a new drug that needs FDA approval. It can be tried using only drugs that have been long approved, and which are already part of standard medical practice. (Granted, PAS is no longer used for TB. But it is the standard treatment for an excess of manganese.)reply",
      "> The purpose of PAS was to create a low manganese environment in the body,Do you have a source for this?I searched, but this recent paper on the mechanism of action for para-Aminosalicylic Acid (PAS) doesn't even mention manganese. It says it targets Dihydrofolate Reductase pathways: https://pmc.ncbi.nlm.nih.gov/articles/PMC5395024/Searching for manganese and TB leads me to papers showing that manganese is an essential cofactor for Isoniazid's anti-TB action: https://pubmed.ncbi.nlm.nih.gov/31319159/ but nothing about inducing low manganese states would be helpful or intentional.So I don't think I'm dead wrong at all. Unless you have some sources, I don't think inducing manganese deficiency is actually the mechanism of action for PAS.> we have a lot of data showing how well people do with low manganese for a period of 1-2 years. (That was the time that this treatment required.) It wasn't pleasant (in particular it came with nausea), but it was definitely survivable.Again, do you have any source for this? Preferably a source that indicates what manganese levels were reduced to during treatment?The side effects are likely due to the 3 drugs in combination which have their own side effects, not low manganese (if it occurred).EDIT: This commenter was making the same claim down thread and admitted they couldn't find a source for their claim: https://news.ycombinator.com/item?id=45932379 It seems like they're making assumptions and presenting it as scientific fact.reply",
      "\"cofactor is a non-protein chemical compound or metallic ion that is required for an enzyme to function as a catalyst.\"reply",
      "I don\u2019t recall the chemical, but there was one mentioned on Everything is Tuberculosis. Someone discovered that aspirin makes TB metabolize more oxygen. Someone found a chemical with the opposite effect, suppressing instead of exciting the same pathway. Based on you\u2019re description I don\u2019t believe it was PAS though.reply",
      "I have heard that forensic analysis can see a distinct sufficient enough difference in bone manganese levels to identify the diet of a deceased person. Vegetarian diets end up with excess Mn stored in the bones. Like calcium, it\u2019s needed and water soluble so you\u2019ve gotta store it for a rainy day.reply",
      "this sort of case presentation re manganese brain toxicity pops up from time to time too:https://pmc.ncbi.nlm.nih.gov/articles/PMC4515672/reply",
      "Some of the comments here are the kind of stuff that makes you lose faith in humanity.reply",
      "> Any interventions would have to be targeted directly at the B. burgdorferiAlcohol suspension tincture of the following antibacterial herbs together, which target Lyme's various coinfections:a. Cryptolepsis sanguinolentab. Polygonum cuspidatum\n(aka: Japanese knotweed)c. Artemisia annua\n(aka: Sweet wormwood)d. Uncaria tomentosa\n(aka: Cat\u2019s claw)Begin with one drop two times per day, increasing to tolerance/under advisement of your ND/MD, or wellness consultant.reply",
      "Make sure to draw blood with leeches twice a week for the best effect, but only after burying a lock of your hair at midnight in the garden.reply"
    ],
    "link": "https://news.northwestern.edu/stories/2025/11/manganese-is-lyme-diseases-double-edge-sword",
    "first_paragraph": "For decades, Lyme disease has frustrated both physicians and patients alike. Caused by the corkscrew-shaped bacterium Borrelia burgdorferi, the infection, if left untreated, can linger for months, leading to fever, fatigue and painful inflammation.\u00a0In a new study, Northwestern University and Uniformed Services University (USU) scientists have uncovered a surprising \u2014 and ironic \u2014 vulnerability in the hardy bacterium. By exploiting this vulnerability, researchers could help disarm\u00a0B. burgdorferi, potentially leading to new therapeutic strategies for Lyme disease.\u00a0The Northwestern and USU team discovered that manganese, which helps shield B. burgdorferi against its host\u2019s immune system, is simultaneously also a crack in its armor. If B. burgdorferi is either starved of or overloaded with manganese, the bacteria become highly vulnerable to the host\u2019s immune system or treatments they would otherwise resist.\u00a0The study was published today (Nov. 13) in the journal mBio.\u00a0\u201cOur work shows that m"
  },
  {
    "title": "Show HN: Tiny Diffusion \u2013 A character-level text diffusion model from scratch (github.com/nathan-barry)",
    "points": 90,
    "submitter": "nathan-barry",
    "submit_time": "2025-11-10T15:13:55 1762787635",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=45876742",
    "comments": [
      "This is really neat.I noticed the diffusion-process.py demo was using matplotlib in a window, but I figured it would be cute if it used a terminal UI instead - so I had Claude Code convert it to use curses. Code and demo GIF here: https://gist.github.com/simonw/9033ebd8dd17b4c0ad101ddda7a54...reply",
      "Fun project, easy to understand and nice looking results, everything one could ask for! I played around with it locally, did some optimizations of low hanging fruits without making it much more complicated, and was gonna send over a PR. But then I noticed there is no license attached to the project. What are your plans regarding the licensing for this?reply",
      "Hey, I\u2019ll add the MIT licenses later today!reply",
      "The basic MLP block in this model uses a ReLU^2 activation function (x <- ReLU(x)^2).  That seems to be copied from the nanochat project, and it's not present in nanoGPT.  Is there some documentation on the choice of this activation function?reply",
      "Looks fun, thanks for sharing.\nI see you're implementing game of life sampling, what's the reasoning for using this logic?reply",
      "There is also this one that was released in October: https://github.com/kuleshov/char-mdlmreply",
      "I'm curious: has there been any work done on generating embedding vectors instead of discrete tokens via diffusion? What would that look like? Please point me to some references. Thanks!reply",
      "Why do these text diffusion demos always look like the number of allowed tokens is fixed for a specific unfilled region?Is this the case?Ie. if the region only has four tokens(here characters) but calculates the best word is \u201cforget\u201d does it just abandon the best fit or truncate it to fit?Are there text diffusion models with lax infill directives?reply",
      "I suppose the exact same constraint applies to image diffusion models. There's a limited space that can be filled, and at some point, the space must be the primary selector/constraint.reply",
      "Yes, this is the case. During training, the model will get a sequence of text (ex, 512 tokens long) with a percentage of them masked out (with a special <MASK> token). It learns how to unmask those tokens to construct the original text.In the case that you mentioned, if we had 4 <MASK> tokens in a row, all we are doing for decoding is predicting what those 4 tokens should be.Generally, this does not seem to be a significant problem, as there are usually multiple ways to express an idea in varying lengths. Also, with confidence-aware parallel decoding, it can usually avoid the scenario you mentioned, as focusing on decoding the highest confident tokens will generally avoid such scenarios with a well trained model.reply"
    ],
    "link": "https://github.com/nathan-barry/tiny-diffusion",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A character-level language diffusion model trained on Tiny Shakespeare\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A character-level language diffusion model for text generation. The model is a modified version of the nanochat gpt implementation and is trained on Tiny Shakespeare! It is only 10.7 million parameters, so you can try it out locally!The file training.py puts the weights in weights/diffusion_model.pt. The sample and animation files load the model from this file.Currently, the weights are already provided for you! It took me around half an hour to train this model for 20,000 steps on 4xA100s. But if you want to retrain the model again, run:To generate a continuous stream of output (currently 30 context lengths), run:To see the diffusion proces"
  },
  {
    "title": "Go's Sweet 16 (go.dev)",
    "points": 86,
    "submitter": "0xedb",
    "submit_time": "2025-11-14T22:33:15 1763159595",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=45932962",
    "comments": [
      "I know they say that your programming language isn't the bottleneck, but I remember sitting there being frustrated as a young dev that I couldn't parse faster in the languages I was using when I learned about Go.It took a few more years before I actually got around to learning it and I have to say I've never picked up a language so quickly. (Which makes sense, it's got the smallest language spec of any of them)I'm sure there are plenty of reasons this is wrong, but it feels like Go gets me 80% of the way to Rust with 20% of the effort.reply",
      "The nice thing about Go is that you can learn \"all of it\" in a reasonable amount of time: gotchas, concurrency stuff, everything. There is something very comforting about knowing the entire spec of a language.I'm convinced no more than a handful of humans understand all of C# or C++, and inevitably you'll come across some obscure thing and have to context switch out of reading code to learn whatever the fuck a \"partial method\" or \"generic delegate\" means, and then keep reading that codebase if you still have momentum left.reply",
      "This is also what I like about JS, except it's even easier than Go. Meanwhile Python has a surprising number of random features.reply",
      "ECMAScript is an order of magnitude more complicated than Go by virtually every measure - length of language spec, ease of parsing, number of context-sensitive keywords and operators, etc.reply",
      "Just so we're on the same page, this is the current JS spec:https://262.ecma-international.org/16.0/index.htmlI don't agree. (And frankly don't like using JS without at least TypeScript.)reply",
      "I think JS is notoriously complicated: the phrase \u201cthe good parts\u201d has broad recognition among programmers.reply",
      "The Javascript world hides its complexity outside the core language, though.  JS itself isn't so weird (though as always see the \"Wat?\" video), but the incantations required to type and read the actual code are pretty wild.By the time you understand all of typescript, your templating environment of choice, and especially the increasingly arcane build complexity of the npm world, you've put in hours comparable to what you'd have spent learning C# or Java for sure (probably more).  Still easier than C++ or Rust though.reply",
      "Language can be bottleneck if there's something huge missing from it that you need, like how many of them didn't have first class support for cooperative multitasking, or maybe you need it to be compiled, or not compiled, or GC vs no GC. Go started out with solid greenthreading, while afaik no major lang/runtime had something comparable at the time (Java now does supposedly).The thing people tend to overvalue is the little syntax differences, like how Scala wanted to be a nicer Java, or even ObjC vs Swift before the latter got async/await.reply",
      "> I'm sure there are plenty of reasons this is wrong, but it feels like Go gets me 80% of the way to Rust with 20% of the effort.I don't see it. Can you say what 80% you feel like you're getting?The type system doesn't feel anything alike, I guess the syntax is alike in the sense that Go is a semi-colon language and Rust though actually basically an ML deliberately dresses as a semi-colon language but otherwise not really. They're both relatively modern, so you get decent tooling out of the box.But this feels a bit like if somebody told me that this new pizza restaurant does a cheese pizza that's 80% similar to the Duck Ho Fun from that little place near the extremely tacky student bar. Duck Ho Fun doesn't have nothing in common with cheese pizza, they're both best (in my opinion) if cooked very quickly with high heat - but there's not a lot of commonality.reply",
      "> I don't see it. Can you say what 80% you feel like you're getting?I read it as \u201c80% of the way to Rust levels of reliability and performance.\u201d That doesn\u2019t mean that the type system or syntax is at all similar, but that you get some of the same benefits.I might say that, \u201cC gets you 80% of the way to assembly with 20% of the effort.\u201d From context, you could make a reasonable guess that I\u2019m talking about performance.reply"
    ],
    "link": "https://go.dev/blog/16years",
    "first_paragraph": "Common problems companies solve with GoStories about how and why companies use GoHow Go can help keep you secure by defaultThe official Go language specificationA complete introduction to building software with GoReference documentation for Go's standard libraryLearn what's new in each Go releaseTips for writing clear, performant, and idiomatic Go codeVideos from prior eventsMeet other local Go developersLearn and network with Go developers from around the worldThe Go project's official blog.Get help and stay informed from Go\n      Austin Clements, for the Go team\n      14 November 2025\n      This past Monday, November 10th, we celebrated the 16th anniversary of Go\u2019s\nopen source\nrelease!We released Go 1.24 in February and Go 1.25 in\nAugust, following our now well-established and dependable release\ncadence. Continuing our mission to build the most productive language platform\nfor building production systems, these releases included new APIs for building\nrobust and reliable software, sig"
  },
  {
    "title": "Record settler attacks in West Bank opening up rifts within Israel (bbc.com)",
    "points": 5,
    "submitter": "tartoran",
    "submit_time": "2025-11-15T00:54:26 1763168066",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.bbc.com/news/articles/cwykze63r2xo",
    "first_paragraph": "The marks of the attack on Hamida Mosque, near Deir Istiya in the occupied West Bank, are still scattered on the ground outside. Charred furniture, lecterns and smoky curls of carpet are piled around the entrance - its guts emptied, and debris cleared, in time for Friday prayers.Dozens of men arrived for the prayers in a show of defiance - their backs turned towards the scorched and blackened wall.The imam here, Ahmad Salman, told the BBC the attack on Thursday was a message from Jewish settlers, amid a wave of settler violence across the West Bank.\"The message they want to send is that they can reach anywhere - into cities, into villages, that they can kill civilians and burn houses and mosques.\"\"I feel it in my soul,\" he said. \"It's not right to touch places of prayer, wherever they are.\"But there was a message here, too, for Israel's regional military chief - scrawled in Hebrew on the mosque's exterior wall: \"We're not afraid of you, Avi Bluth.\"Spiralling settler attacks here over t"
  },
  {
    "title": "Mentra (YC W25) Is Hiring: Head of Growth to Make Smart Glasses Mainstream (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-11-14T21:00:25 1763154025",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/mentra/jobs/2YbQCRw-make-smart-glasses-mainstream-head-of-growth",
    "first_paragraph": "Building the open source smart glasses operating system.Mentra is building the operating system for smart glasses. Smart glasses will empower humans to be more than ever before. Use cases like subtitles for the deaf, proactive AI that during conversations, and POV streaming enhance our thinking and communication.Mentra\u2019s mission is to build universal interfaces between mind and machine.We\u2019re a team of passionate builders in San Francisco and Shenzhen building the world\u2019s best smart glasses. We believe that the best future for computing is open, user-empowering, and cross-compatible.We\u2019re sitting on the most transformative technology since the iPhone and we need a Head of Growth to help us tell our story and show the world what smart glasses can do for them.The RoleWe\u2019re hiring a Head of Growth to bring smart glasses to millions of people.Success looks like this: Mentra is what people think of when they hear \u201csmart glasses\u201d. Thousands of devs in February building apps on MentraOS. Dozen"
  },
  {
    "title": "The disguised return of EU Chat Control (reclaimthenet.org)",
    "points": 505,
    "submitter": "egorfine",
    "submit_time": "2025-11-14T17:54:07 1763142847",
    "num_comments": 217,
    "comments_url": "https://news.ycombinator.com/item?id=45929511",
    "comments": [
      "> According to Breyer, the existing voluntary system has already proven flawed, with German police reporting that roughly half of all flagged cases turn out to be irrelevant.A failure rate of only 50% is absurdly good for a system like this. If we have to:> Imagine your phone scanning every conversation with your partner, your daughter, your therapist, and leaking it just because the word \u2018love\u2019 or \u2018meet\u2019 appears somewhere.then apparently either there are so many perpetrators that regular conversations with partners etc. are about as common as crime, or such regular conversations don't have such a high risk of being reported after all.I don't think chat surveillance is a good idea. But please use transparent and open communication. Don't manipulate us just like the enemy does.reply",
      "It is probably a reference to the report mentioned in this article from September https://reclaimthenet.org/germany-chat-control-false-reports...  According to the Federal Criminal Police Office (BKA), 99,375 of the 205,728 reports forwarded by the US-based National Center for Missing and Exploited Children (NCMEC) were not criminally relevant, an error rate of 48.3%. This is a rise from 2023, when the number of false positives already stood at 90,950.\n\nIndeed 50% false positive rate sounds surprisingly good, but this is under the \"voluntary scheme\" where Meta/Google/MS etc are not obligated to report. Notably missing from the article is the total number of scanned messages to get down to 200k reports. To my knowledge, since it's voluntary, they can also report only the very highest confidence detections. If the Danish regime were to impose reporting quotas the total number of reports would rise. And of course -- these are reports, not actually convictions.Presumably the actual number of criminals caught by this would remain constant, so the FP rate would increase. Unless of course, the definition of criminal expands to keep the FP rate low...reply",
      "The right to privacy is enshrined in the European Convention on Human Rights, article 8 [0].It escapes me how politicians can repeatedly attempt to violate this.[0] https://fra.europa.eu/en/law-reference/european-convention-h...reply",
      "\u201d2 There shall be no interference by a public authority with the exercise of this right EXCEPT such as is in accordance with the law and is necessary in a democratic society in the interests of national security, public safety or the economic well-being of the country, for the prevention of disorder or crime, for the protection of health or morals, or for the protection of the rights and freedoms of others.\u201dAre we reading the same thing?This linked statement clearly authorizes invasion of privacy by public authorities, in the name of any of the very vaguely listed reasons \u2013 as long as there\u2019s some law to allow it.reply",
      "Mass surveillance has already been ruled to be in contravention of the Human Rights act:https://en.wikipedia.org/wiki/Article_8_of_the_European_Conv...>A 2014 report to the UN General Assembly by the United Nations' top official for counter-terrorism and human rights condemned mass electronic surveillance as a clear violation of core privacy rights guaranteed by multiple treaties and conventions and makes a distinction between \"targeted surveillance\" \u2013 which \"depend[s] upon the existence of prior suspicion of the targeted individual or organization\" \u2013 and \"mass surveillance\", by which \"states with high levels of Internet penetration can [] gain access to the telephone and e-mail content of an effectively unlimited number of users and maintain an overview of Internet activity associated with particular websites\". *Only targeted interception* of traffic and location data in order to combat serious crime, including terrorism, is justified, according to a decision by the European Court of Justice.[23]reply",
      "The loophole there is \"targeted\" so they'll declare that Son of Chat Control is to be targeted.reply",
      "Yeah the whole thing is full with these loopholes.  Your rights are rights only as long as we wish at some point to add laws that inhibit them.reply",
      "It's weird how \"rights\" went from \"the government can't do X to you\" to \"the government can force private actors to do Y (but these rules don't apply to us).\"reply",
      "Basically a useless document.reply",
      "The way it's written and the way ECHR court works, the government has to actually argue it's way, not just say \"national secirity\".ECHR court however can't repeal the law, only fine the governmemt for actual violation of convention rights.reply"
    ],
    "link": "https://reclaimthenet.org/the-disguised-return-of-the-eus-private-message-scanning-plot",
    "first_paragraph": ""
  },
  {
    "title": "GEN-0 / Embodied Foundation Models That Scale with Physical Interaction (generalistai.com)",
    "points": 5,
    "submitter": "jackdoe",
    "submit_time": "2025-11-05T10:25:14 1762338314",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://generalistai.com/blog/nov-04-2025-GEN-0",
    "first_paragraph": ""
  },
  {
    "title": "Nothing impossible happens (oxonianreview.com)",
    "points": 3,
    "submitter": "hhs",
    "submit_time": "2025-11-15T00:39:50 1763167190",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.oxonianreview.com/articles/nothing-impossible-happens",
    "first_paragraph": ""
  },
  {
    "title": "Xqerl \u2013 Erlang XQuery 3.1 Processor (zadean.github.io)",
    "points": 32,
    "submitter": "smartmic",
    "submit_time": "2025-11-11T09:48:05 1762854485",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=45885677",
    "comments": [
      "Hasn't been touched in 3 years: https://github.com/zadean/xqerlreply",
      "This is stale. BaseX is an active equivalent.https://basex.org/reply",
      "Cool. Elixir dev here but less familiar with XML (other than html). When would this be useful? Like any common usecases?reply",
      "This looks cool, Im quite uninformed about xml databases and xquery though, and I had foolishly assumed I had quite a broad exposure to tech stacks.Whats this stuff used for?reply",
      "I use XQuery to transform XML data. Whatever can be done with XSLT can also be done in XQuery. It is a functional language and, unlike XSLT, it is supported by more tools for newer versions (XSLT > 1.0 is only supported by Saxon, as far as I know). Overall, it feels much more modern and ergonomic for querying and transforming XML. Best of all: XQuery 3.1 supports JSON natively \u2014 I have also adopted it for JSON in some ETL pipelines.Check Wikipedia for more information: https://en.wikipedia.org/wiki/XQueryreply"
    ],
    "link": "https://zadean.github.io/xqerl/",
    "first_paragraph": "Erlang XQuery 3.1 Processor and XML DatabaseCheck out the Getting Started sectionxqerl is a self-contained XQuery 3.1 processor and XML database written in Erlang.xqerl is being actively developed and is not yet to a stable release. Changes can occur without notice. If you save data with it, that data may not be compatible with the most recent version of this repository in the master branch.The first stable release will be coming soon, but isn\u2019t quite there yet.It is passing 100% of 30,895 test cases it runs. 1,823 other cases that test optional features or unsupported specification versions are skipped.\nMost of the test cases run are from the W3C QT3 test suite for XPath and XQuery.\nOthers are from the EXPath test suite and the Update Facility test suite for version 1.0.The modules statically available to XQuery code in xqerl are documented in the xqerl documentationThere is no cool GUI or web interface. If you need that, you may want to try out one of the other XQuery processors out "
  },
  {
    "title": "Winamp clone in Swift for macOS (github.com/mgreenwood1001)",
    "points": 177,
    "submitter": "hyperbole",
    "submit_time": "2025-11-14T12:44:07 1763124247",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=45926224",
    "comments": [
      "I was not a fan of WinAmp in its heyday because I thought all the \"skins\" sucked.Wow, have times changed. I look at this screenshot now: https://raw.githubusercontent.com/mgreenwood1001/winamp/refs...and think about how usable this looks. Buttons are demarcated clearly. The scrub bar is big enough to grab. Everything is legible.UI sucks now.Meanwhile... seeing the lyrics in that shot makes me wonder if WinAmp supports karaoke playback...I guess the original did through plug-ins. Hm, maybe I'll take a shot at adding it to this one.reply",
      "Been running Foobar 2000 for macOS for a year, but this is pretty in a retro way, I guess.https://www.foobar2000.org/mac<- the least bollocks-infested media player on macOS since about, oh, September 2000.reply",
      "vlc..?reply",
      "It's a shame this too doesn't play/pause with space bar.. like Spotify, drives me nuts.reply",
      "Man, seeing the visualizations here reminded me of how great it was to load up some music in Winamp (downloaded via soulseek), turn on the geiss visualizer, and get stoned.reply",
      "Geiss source is available now. Maybe it should be ported :) https://github.com/geissomatik/geissreply",
      "milkdrop and project m, those were the days.Why aren\u2019t these really a thing anymore? Does anyone know any non-shit way to get nice visuals from apple music or spotify or whatever these days?reply",
      "If you look at [1] you can see some derivations from Milkdrop/Project M.There were a lot of other, good visual plugins and software. VJ software, specifically, but also Libvisual just abstracts input and output, therefore allowing you to use all of these (supported) visualization plugins on any supported media player. It isn't much developed anymore these days, but this is the correct way forward.Looking at the actors in Livisual [3] G-Force is decent but also a couple may be missing from earlier Libvisual releases. You may also like Lemuria [4]. Winamp's AVS is also FOSS [5].[1] https://en.wikipedia.org/wiki/MilkDrop[2] https://github.com/Libvisual/libvisual[3] https://github.com/Libvisual/libvisual/tree/master/libvisual...[4] https://github.com/dr-ni/lemuria-2.1.1[5] https://en.wikipedia.org/wiki/Advanced_Visualization_Studioreply",
      "There are some visualizers in the Mac App Store. I'm using Ferromagnetic right now and like it well enough. There are still visualizers in Apple Music left over from the iTunes days but they're kind of lame.reply",
      "I stumbled onto one years ago by accident, maybe an Easter egg or something. I came back to my computer (Mac) after several hours of iTunes playback to see a hitherto unknown visualization running, with fairly primitive-looking graphics by today's standards. It was not any of the visualizations available in iTunes at the time.I filed a bug on it with Apple and they got back to me asking how the hell I had invoked this, because they'd never seen it before. Never did get to the bottom of it.reply"
    ],
    "link": "https://github.com/mgreenwood1001/winamp",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Winamp clone in swift for OS/X\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A native macOS application that recreates the classic Winamp experience for playing MP3 and FLAC audio files.ReleasesIf you enjoy using Winamp macOS and would like to support its development, consider buying me a coffee:Support on Buy Me a Coffee\ud83c\udfb5 MP3 and FLAC playback support\ud83c\udfa8 Winamp-inspired UI\ud83d\udcdd Playlist management / M3U\u23ef\ufe0f Full playback controls (play, pause, stop, next, previous)\ud83d\udcca Spectrum analyzer visualization\ud83c\udf9a\ufe0f 10-band equalizer\ud83d\udd0d File browser with drag-and-drop supportMultiple oscilliscope visualizationsMilkdrop (click on the icon in the main app) - supports "
  }
]