[
  {
    "title": "Black Hat Rust (github.com/skerkour)",
    "points": 40,
    "submitter": "Eavolution",
    "submit_time": "2024-12-08T23:49:26 1733701766",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42361793",
    "comments": [
      "There's a book like these for a bunch of modern languages; I think \"Black Hat Python\" started the trend, like 10-15 years ago.\n \nreply",
      "I feel as though buying a book like this is admission that you don't have what it takes to do black hat work. Good if it's just out of curiosity though.\n \nreply",
      "Is there a preview of the content beyond a short synopsis of each chapter?\n \nreply"
    ],
    "link": "https://github.com/skerkour/black-hat-rust",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Applied offensive security with Rust - https://kerkour.com/black-hat-rust\n\n\nWhile the Rust Book does an excellent job teaching What is Rust, a book about Why and How to Rust was missing.Whether in movies or mainstream media, hackers are often romanticized: they are painted as black magic wizards, nasty criminals, or, in the worst cases, as thieves with a hood and a crowbar.\nIn reality, the spectrum of the profile of the attackers is extremely large, from the bored teenager exploring the internet to sovereign State's armies as well as the unhappy former employee.What are the motivations of the attackers? How can they break seemingly so easily into any network? What do they do to their victims?\nWe will put on our black hat and explore the world of offensive security, whether it be cyber attacks, cybercrimes, or cyberwar.\nScanners, exp"
  },
  {
    "title": "Show HN: A portable hash map in C (github.com/e-dant)",
    "points": 79,
    "submitter": "e-dant",
    "submit_time": "2024-12-08T20:05:25 1733688325",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=42359949",
    "comments": [
      "I recently coded a linear-probing hash map in C and I highly recommend you to use fuzz tests. These evolve naturally from unit tests: next step table unit tests, next step property test, next step fuzzing, all steps are incremental, hence easy.Having a fuzz test was in-va-lu-ab-le. I caught several bugs right there. The delete function was particularly tricky.I ended up with two fuzz tests as my hash table has a key feature: convergence. Having same contents, it would have exactly same bits in the buffer. In other words, it is independent of the insertion/deletion order. For this, I added another fuzz test. I would add a third one if I  realize there is an important invariant I did not fuzz test. That is not much work, but so much useful!https://github.com/gritzko/librdx/blob/master/abc/fuzz/HASH....https://github.com/gritzko/librdx/blob/master/abc/fuzz/HASHd...P.S. In your case, I recommend clang's libfuzzer with ASAN.https://llvm.org/docs/LibFuzzer.html#fuzzer-usage\n \nreply",
      "fuzz testing vs HN-popular-post testing, go!\n \nreply",
      "Row 100 of hm_put() clears all contents of the item struct, thus losing the pointer to where the previous value was stored. But then row 107 needs this pointer to pass it to realloc().Additionally, in case of overwrite, the memory previously allocated for the key is leaked.All in all, I  don't think row 100 is really needed, and removing it wouldn't do any harm.Finally, deletes are hard in hash maps. Either you decide that deletes are not allowed, or you implement them with tombstones or re-insertions. A half-backed solution is not an option.Hope these suggestions help you.\n \nreply",
      "A bug, I believe: If you \"put\" three colliding strings A and then B and then C, and then \"delete\" B, you won't be able to find C anymore.\n \nreply",
      "Good catch! Yes, that looks like a bug :)\n \nreply",
      "Considering there seems to be at least a one memory bug (hm_put/key from another comment), I would strongly recommend running the tests in valgrind or similar if you haven't already. Doing C without it usually ends in some kind of disaster for me.\n \nreply",
      "If you\u2019re interested in this, I wrote a blogpost on a simple c hash table without deletion.https://www.davidpriver.com/c-hash-table.html\n \nreply",
      "Thanks for sharing. Simplicity is a good thing.In order to speed it up by reducing the number of malloc() calls, it may be worth adding a simple arena memory allocation measure: by allocating one larger block (e.g. 1 MB) initially and then doubling the memory size each time you run out, all malloc()/calloc() calls can become local salmagundi_alloc() calls that are just macro invocations that return an arena buffer pointer and also increment said pointer as a side effect.I also recommend you have a look at Chris Hanson's book \"C: Interfaces and Implementations\", which has a few neat C API tricks that your code could benefit from (e.g. for reducing name space pollution, for avoiding null pointer argument errors, API method naming etc.).\n \nreply",
      "I suggest improving the probing a little.  Something like  idx = (idx + 1) % map->cap;\n\nbecomes  iterCount++;\n  idx = (idx + iterCount) % map->cap;\n \nreply",
      "It could be improved even more, performance wise. The potentially expensive modulo could be avoided entirely with an if statement. Or, only use powers of 2 for the capacity, and then you can also use bit wise ops\n \nreply"
    ],
    "link": "https://github.com/e-dant/salmagundi",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A small, portable, linear probing hash map\n      A small, portable, linear-probing hash map in C.\n        A small, portable, linear probing hash map\n      "
  },
  {
    "title": "How to measure frequency response of a speaker at home (crabman.me)",
    "points": 27,
    "submitter": "philip-b",
    "submit_time": "2024-12-08T21:49:45 1733694585",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=42360898",
    "comments": [
      "You need a calibrated measurement microphone to do this for real. Otherwise the microphone\u2019s frequency response will skew the results.\n \nreply",
      "You can check whether responses differ without a calibrated microphone.But regardless here the methodology is very weak, just playing a sine sweep with a spectrum recorder open and eyeballing the frequency magnitudes.\n \nreply",
      "Not just that but the FRF calculation is slightly complex. You need to take into account windowing function, amplitude correction factor, sampling rate and block size of each measurement and %overlap\u2026 leakage is a very important thing in signal processing and spectral analysis. Also you need an anechoic environment to capture this, because you would be also capturing room reflections and characteristics of room acoustics.\n \nreply",
      "I've always wondered... is there some way to mathematically \"solve\" for this with multiple microphones and multiple speakers?Like with 2 of each, or 3 of each, where you play the same waveform through every possible pair of speaker and microphone, you can solve some kind of system of matrix equations to determine the only possible combination of responsiveness at each device at each frequency?Or do you just need a reference microphone with known characteristics, period, end of story, because math can't do it?(Obviously from a practical perspective you want the reference microphone... I'm just curious about in theory.)\n \nreply",
      "Yes, multiple microphones is how microphones can be calibrated in the first place. You make a particular kind of microphone that also functions as a speaker, with certain testable assumptions about how they work. Then you point one at the other and vice versa. The result is a reference microphone that can then be used to calibrate other microphones.You don't do it every day, which is why an outfit like Bruel & Kjaer can charge a lot for their gear. ;-)\n \nreply",
      "what if you move the microphones and speakers at varying but precise speeds so that doppler shift can be used to shift frequencies? you could play a tone on the speaker, shift the relative velocity (spin the microphone really fast?) and calibrate a frequency range of the microphone. with a calibrated mic frequency range, you can now calibrate that range of the speaker. repeat. each calibration step is going to accumulate error. to be clear, not a practical solution, but fun to theorize.\n \nreply",
      "I believe it's hardly different from trying to deduce perfect distances from multiple rulers of dubious precision: you need to compare them to one of extreme precision. Arranging 4 rulers into a perfect square proves that they have equal lengths, but you still don't know their offset from standard length.However, if you ignore tolerances and assume that every microphone of a given model number has equal response, then it's simply a matter of having that known response information available, similar to a hypothetical brand of ruler being known for coming up short.\n \nreply",
      "> but you still don't know their offset from standard length.But that's fine for microphones -- the question here isn't to determine their absolute volume, which is of course unsolvable. It's to determine the relative \"volume\" (response) at each frequency. It's the shape of the curve that matters, not its offset.And again, I'm not looking for a practical solution (like getting the info from a manufacturer) -- I'm just curious about it in theory. If it's inherently solvable or not.\n \nreply",
      "This isn't solvable. Each loudspeaker and microphone has its own frequency response and will always measure the product of any two of them. This does not result in a unique solution for any single frequency response, even when you know the clean source signal. There is always a degree of freedom of how much each device in a pairing contributes to the final response.\n \nreply",
      "iPhone mics are consistent enough to be used for most purposes.  Apple provides the correction curves and they are used by apps like Audiotools\n \nreply"
    ],
    "link": "https://crabman.me/does-soundcore-motion-sound-different-via-aux-in-and-bluetooth-and-how-to-measure-frequency-response-at-home/",
    "first_paragraph": "Short answer: no, Soundcore Motion+ sounds the same via bluetooth and aux-in.Today I noticed that my awesome bluetooth speaker Anker Soundcore Motion+ sounds kind of shitty. There is an Android app by Anker Soundcore with EQ settings and some EQ presets. I connected my phone to the speaker and the app showed that the preset \"Bass Off\" is turned on:\n\n\n\nI tested different EQ presets on \"Levitating\" by Dua Lipa (Youtube Music, Music video on Youtube). The song is fantastic, and I've been listening to it on repeat these last few days. The music video is fantastic too and so, so beautiful except for the rap part which I don't like. I found some guy recommending these EQ settings:\n\n\n\nI tried them and I liked them more than any of the presets. They give Motion+ a high energy dance kind of vibe. I think they might be bad for working or chilling with music in the background because I think I might get tired from the intense sound. \"Bass Off\" might be better for that use case but we'll see. I wo"
  },
  {
    "title": "JSON5 \u2013 JSON for Humans (json5.org)",
    "points": 108,
    "submitter": "rickcarlino",
    "submit_time": "2024-12-08T21:29:05 1733693345",
    "num_comments": 97,
    "comments_url": "https://news.ycombinator.com/item?id=42360681",
    "comments": [
      "I think it allows for too much. I was glad that JSON only supports double-quoted strings. It is a feature that removes discussions about which quotes to use. Or even whether to use quotes at all (we still need them for keys with colons or minus in it, so what gives?).The only thing that JSON is really missing are comments and trailing commas. I use JSONC for that. It's what VSC uses for the config format and it works.\n \nreply",
      "> The only thing that JSON is really missing are comments and trailing commas.The reason JSON doesn't have comments [1]:    I removed comments from JSON because I saw people were using them to hold parsing directives, a practice which would have destroyed interoperability. I know that the lack of comments makes some people sad, but it shouldn't.\n\n    Suppose you are using JSON to keep configuration files, which you would like to annotate. Go ahead and insert all the comments you like. Then pipe it through JSMin before handing it to your JSON parser.\n\n[1] http://archive.today/8FWsA\n \nreply",
      "JWCC literally stands for JSON With Commas and Comments.JWCC is also what Tailscale call HuJSON, as in \"JSON for Humans\", which as amusingly also what json5 claims to be.https://github.com/tailscale/hujson\n \nreply",
      "> The only thing that JSON is really missing are comments and trailing commas. I use JSONC for that.YAML[0] supports JSON formatted resources and octothorpe ('#') comments as well.  I didn't see anything in the spec specifically allowing for trailing commas however.Here is an exemplar using the Ruby YAML module:  #!/usr/bin/ruby\n  \n  require 'yaml'\n  \n  \n  puts YAML.load(\n    %/\n      # YAML is a strict superset of JSON, which\n      # means supporting octothorpe end-of-line\n      # comments is supported in JSON formatted\n      # YAML if and only if the content is multi-line\n      # formatted as well (like this example).\n      {\n        # This is valid YAML!\n        \"foo\" : \"bar\"\n      }\n    /\n    )\n  \n0 - https://yaml.org/spec/1.2.2/\n \nreply",
      "The problem of yaml is that it allows too much. It allows unquoted strings, and those can be interpreted by the parser as numbers, timestamps, booleans, etc. This is a source of many fooguns.Use of indentation to denote nesting can sometimes be an anti-feature, too, because while using that the format does not provide a way to make certain that the entire stream has been read (parens balanced). This may lead to problems or even exploits.Pure JSON is so painful for human consumption though, I willingly choose yaml if it's the only alternative.JSON5 may indeed be a sweet spot between human-friendliness and lack of nasty surprises.\n \nreply",
      "As I mentioned in a reply to a peer comment, the problems you describe regarding YAML appear to be about the commonly used format most of us think of and the totality of the YAML feature set.What is illustrated above is the definition of a specification-compliant YAML resource strictly using JSON constructs + octothorpe end-of-line comments.Does this usage mitigate the concerns you have identified?\n \nreply",
      "The problem is that self-restraint only takes you so far. Typos exist. Human mistakes exist. Machine errors exist. Malicious inputs exist.A good parser does not just accept the inputs you find valid, but also rejects inputs you deem invalid. Running a linter that would report or amend all the footgun-wielding features of yaml before parsing is tanamount to running another parser. Then why bother :)\n \nreply",
      "Whilst YAML is an option, if the choice is between having the unnecessary extra features of JSON5 or YAML, JSON5 seems like the clear winner.Allowing multiple types of quotes may be an unnecessary feature but it is a clear lesser evil compared to the mountain of footguns that YAML brings with it.\n \nreply",
      "How does defining a YAML resource strictly in terms of well-formed JSON + octothorpe comments introduce \"the mountain of footguns that YAML brings with it\"?\n \nreply",
      "It doesn\u2019t, quoting strings does solve almost all issues, but it does leave potential footguns for the future.If you don\u2019t enforce it, in the future the \u201csubset of YAML\u201d property might get weaker, especially if someone else is modifying the config.If you treat config files the same as code, then using a safe subset of YAML is the same as using a safe subset of C. It is theoretically doable, but without extensive safeguards, someone will eventually slip up.\n \nreply"
    ],
    "link": "https://json5.org/",
    "first_paragraph": ""
  },
  {
    "title": "Buffer Overflow Risk in Curl_inet_ntop and Inet_ntop4 (hackerone.com)",
    "points": 38,
    "submitter": "sprawl_",
    "submit_time": "2024-12-08T22:31:26 1733697086",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42361299",
    "comments": [
      "I feel sorry for the maintainers having to spend their energy disproving the validity of these AI generated reports. Daniel Stenberg blogged about this issue earlier: https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-f...Open source burnout is already real, I hope the volume of the AI slop security reports stays manageable.\n \nreply",
      "Yeah, these are awful.  This one, for example, just flags that strcpy can overflow, but ignores that there is a buffer-size check on the immediately preceding line.  Must be infuriating to deal with nonsense like this.\n \nreply",
      "I can kinda understand the motive for carpet bombing an issue tracker with AI slop hoping for a hit, but then to whine about unprofessional responses is really too much. Time to unplug the chatbot.\n \nreply",
      "Not to mention that the first couple of responses were very professional. At some point you just have to call a spade a spade, or not suffer fools, or whatever idiom you prefer.\n \nreply",
      "The complaint sounds AI-generated as well, like the rest of the comments from that user.\n \nreply",
      "Wow, in the future we will point to this bogosity and say it is why we can't have good things.\n \nreply"
    ],
    "link": "https://hackerone.com/reports/2887487",
    "first_paragraph": ""
  },
  {
    "title": "1,600 days of a failed hobby data science project (lellep.xyz)",
    "points": 35,
    "submitter": "millimacro",
    "submit_time": "2024-12-08T21:29:31 1733693371",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42360685",
    "comments": [
      "Some very weird things in this.1. The title makes it sound like the author spent a lot of time on this project. But really, this mostly consisted of noting down a couple of URLs per day. So maybe 5 min / day = ~130h spent on the project. Let's say 200h to be on the safe side.2. \"Get first analyses results out quickly based on a small dataset and don\u2019t just collect data up front to \u201canalyse it later\u201d\" => I think this actually killed the project. Collecting data for several years w/o actually doing anything doesn't with it is not a sound project.3. \"If I would have finished the project, this dataset would then have been released\"  ==> There is literally nothing stopping OP from still doing this. It costs maybe 2h of work and would potentially give a substantial benefit to others, i.e., turn this project into a win after all. I'm very puzzled why OP didn't do this.\n \nreply",
      "yep I spent more time on duolingo for 600+ day streak and can barely speak spanish.\n \nreply",
      "Duolingo is a pretty bad tool for learning a language, it's good to make you feel like you're learning though.\n \nreply",
      "That seems to be a pattern\n \nreply",
      "It is because you never really practice talking with Duolingo. I am quite good at reading French now, though.\n \nreply",
      "> I am quite good at reading French now, though.If you are, that's actually quite an achievement and good. If you're talking about French outside of Duolingo, that is.I do not normally hear of people getting to reading fluency through Duolingo.\n \nreply",
      "Duolingo used to have a really good feature where you read through and collaboratively-translated texts, but they shut it down years back.\n \nreply",
      "Point number 2. is super important for non-hobby projects. Collect a bit of data, even if you have to do it manually at first and do a \"dry run\" / first cut of whatever analysis you're thinking of doing so you confirm you're actually collecting what you need and what you're doing is even going to work. Seeing a pipeline get built, run for like two months and then the data scientist come along and say \"this isn't what we needed\" was complete goddamn shitshow. I'm just glad I was only a spectator to it.\n \nreply",
      "I don't speak the language so maybe what you're scraping isn't in this list, but why manual when they seem to have comprehensive RSS feeds? [1]Automating this part should have been day 1.[1] https://www.tagesschau.de/infoservices/rssfeeds\n \nreply",
      "I\u2019m not sure I would call this a failure.. more just something you tried out of curiosity and abandoned. Happens to literally everyone. \u201cFailed\u201d to me would imply there was something fundamentally broken about the approach or the dataset, or that there was an actual negative impact to the unrealized result. It\u2019s very hard to finish long-running side projects that aren\u2019t generating income, attention, or driven by some quasi-pathological obsession. The fact you even blogged about it and made HN front page qualifies as a success in my book.> If I would have finished the project, this dataset would then have been released and used for a number of analyses using Python.Nothing stopping you from releasing the raw dataset and calling it a success!> Back then, I would have trained a specialised model (or used a pretrained specialised model) but since LLMs made so much progress during the runtime of this project from 2020-Q1 to 2024-Q4, I would now rather consider a foundational model wrapped as an AI agent instead; for example, I would try to find a foundation model to do the job of for example finding the right link on the Tagesschau website, which was by far the most draining part of the whole project.I actually just started (and subsequently \u2014-abandoned\u2014- paused) my own news analysis side project leveraging LLMs for consolidation/aggregation.. and yeah, the web scraping part is still the worst. And I\u2019ve had the same thought that feeding raw HTML to the LLM might be an easier way of parsing web objects now. The problem is most sites are privy to scraping efforts and it\u2019s not so much a matter of finding the right element but bypassing the weird click-thru screens, tricking the site that you\u2019re on a real browser, etc\u2026\n \nreply"
    ],
    "link": "https://lellep.xyz/blog/failed-data-science-project.html",
    "first_paragraph": "by Martin Lellep\u2b50 I spent >1,600 days working on a data science project that then failed because I lost interest. This article is to cope\nwith the failure and maybe help you (and me) to finish successful data science projects by summarising\na few learnings into a checklist, see below.Nobody really likes to speak about failures. The same holds true for failed data science projects.\nIn this text, I document my most recent data science project which I worked on for 1,600 days -\ndays that I won\u2019t get back despite the project failing.\nUltimately, it is important to communicate about failed projects similarly to successful projects\nas those failed ones are the ones that help us to acquire scar tissue (thanks Andrej) which makes us better data science\npractitioners. And the latter is what we should all strive\u00a0for!Table of\u00a0Contents:After completing a substantial hobby data analysis project involving 1.5 million Nextbike\ndatapoints, I wanted to explore a different data modality: text. While my "
  },
  {
    "title": "The Rules of Programming (2023) (therulesofprogramming.com)",
    "points": 42,
    "submitter": "davikr",
    "submit_time": "2024-12-08T20:13:08 1733688788",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42360008",
    "comments": [
      "As programmers we are ingrained to look further than the problem at hand. We try to see the bigger picture, solve problems in holistic ways if possible.Often this can lead to over-engineering, creating more corner cases and ambiguity in requirements and reduction of test coverage. That is a trap to lok out for.On the other hand it also can lead to better understanding of the problem space, increase understandability, and less need for later refactoring.Just stating, 'don't look further than the problem you are required to solve' is not an excellent general rule.\n \nreply",
      "Yeah, it's a real challenge to come up with low resolution rules/heuristics. That becomes much harder when you're tailoring your message to different communities / expertise levels.I agree with you, but I also get where the author is coming from. Sometimes simple guard rails for new devs is a lot better than ultra detailed nuance that leaves them without a simple path forward.In my experience I've witness horrible examples of both extremes. Overgeneralized yet poor solutions, and (often duplicated) hyper specific solutions. Both typically from less experienced folks. I think more communication and mentoring would really have helped more there.\n \nreply",
      "I don\u2019t think it makes sense to not think of generality options.Often that helps us see a problem in more ways. Come at it from different directions. Generalizing mentally is map discovery,But when it comes to implementation, any code that is there to enable unused generality is unused and unnecessary code. Any unused freedom of interface increases the chance of unintentional misuse or sleeper bugs.The number of ways unnecessary code or loose constraints can be unhelpful is unlimited.When it comes to optimizing, testing, maintaining, it is optimal to have the narrowest mission possible.\u2014The exception is when designing a platform or library, with open ended reuse. Then value can genuinely be increased with greater applicability.Then there will be generality vs. focused tradeoffs whose resolution will be very context dependent. On the subject matter and its potential market/users.\n \nreply",
      "The trick is not to stop at the birds-eye view but to see that one small change that is actually required from up high and dive back down.\n \nreply",
      "I believe this is the type of book that I'd like to skim to see what it has to offer rather than just blindly buy it. This is how interpret some of those points:* As simple as possible, but no simpler -> Don't get into fancy stuff like e.g: design patterns just because you learnt or know them? Same for other techniques depending your language and facilities? Don't use things just for using them.* Let your code tell its own story -> Use verbs for functions and methods, nouns for variables and classes so code is understood with minimum effort as is being read?* Generalization takes three examples -> Sure, first you write a solution, then copy paste it if needed elsewhere as you didn't expect to be reused, third time make an abstraction (function(s), method(s), etc) as it popped up once again?* A good name is the best documentation -> Picking reasonably good names for all kind of identifiers will make code self-document and understand?* Sometimes you just need to hammer the nails -> Sometimes you need to be pragmatic and get a thing done, maybe not in the best possible way?* Code that isn't running doesn't work -> Remove all commented/dead code from a codebase as not only running but might also generate confusion to other people?I do not want to diminish the content of the book in any way nor sound arrogant, but in the past I've seen similar titles and they weren't offering that much to what I already knew at the time.\n \nreply",
      "The list of rules covered can be found in the book description on the purchase links, like: https://bookshop.org/p/books/the-rules-of-programming-how-to...\n \nreply",
      "\"The rules in this book include:    As simple as possible, but no simpler\n\n    Let your code tell its own story\n\n    Localize complexity\n\n    Generalization takes three examples\n\n    Work backward from your result, not forward from your code\n\n    The first lesson of optimization is don't optimize\n\n    A good name is the best documentation\n\n    Bugs are contagious\n\n    Eliminate failure cases\n\n    Code that isn't running doesn't work\n\n    Sometimes you just need to hammer the nails\n\"Sounds quite solid - as guidelines. My only rule for programming is, that the result is correct and usable.\n \nreply",
      "My arbitrary rule from recent experience is this: you do not need to lint your JSON by compiling and then running a Serde-based Rust application as part of your CI/CD pipeline for every single commit, when the project is entirely Python and Ansible for systems deployment.\n \nreply",
      "There are several books that commonly get recommended for all around general programming knowledge (Pragmatic Programmer, A Philosophy Of Software Design, etc) Curious how this is any different!\n \nreply",
      "Philosophy of Software Design had the most impact on my general naming and structuring. Just some really great advice in a sub 200 page book\n \nreply"
    ],
    "link": "https://www.therulesofprogramming.com",
    "first_paragraph": "The Rules of Programming were born of exasperation.I\u2019d spent about a decade running programming teams at Microsoft, then cofounded the video game company Sucker Punch in 1997. Both companies have been successful\u00ad\u2014in large part because of their ability to recruit and develop top-notch programming teams.At Sucker Punch, that\u2019s led to a 25-year run of successful games. The three Sly Cooper games, which let kids of all ages experience the thrilling life of the master raccoon thief Sly Cooper and his pals. The five inFamous games, which gave gamers superpowers and the choice to use them for good or evil. And our magnum opus, Ghost of Tsushima, where gamers play a lone samurai fighting back against the 1274 invasion of Japan.A big part of the recruiting strategy at both Microsoft and Sucker Punch has been hiring smart young programmers, then training them in the ways of professional developers. This practice has been undeniably successful, but it also leads to a particular flavor of frustrat"
  },
  {
    "title": "Chuck E. Cheese's animatronics band bows out (ieee.org)",
    "points": 86,
    "submitter": "pseudolus",
    "submit_time": "2024-12-03T11:18:34 1733224714",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=42305006",
    "comments": [
      "Following Dolli Dimples nightmare decent into booze and drugs and Jasper T. Jowls repeated arrests for excessive drooling, the wheels really came off. Pasqually ended up in an psych ward after an acute psychotic break, Crusty the Cat contracted rabies under mysterious circumstances, and Chuck himself has never been seen after his crypto pump and dump scheme.\n \nreply",
      "Call Peter Jackson!  \"Meet the Feebles\" needs a sequel.\n \nreply",
      "https://www.sj-r.com/story/news/local/2024/05/28/illinois-ch...Apparently 5 stores nationwide are being allowed to keep the animatronics.\n \nreply",
      "For the curious, they are: Los Angeles, CA; Nanuet, NY; Springfield, IL; Pineville, NC; and Hicksville, NY.\n \nreply",
      "I\u2019ll take this opportunity to plug the YouTube videos of animatronics super fan Jenny Nicholson.  Her videos on the Star Wars hotel: https://youtu.be/T0CpOYZZZW4?si=8bzPpb_9kPaTsTto and the theme park Evermore: https://youtu.be/L9OhTB5eBqQ?si=utwaOeBFRpOQMStx are peak YouTube content.\n \nreply",
      "Jenny Nicholson is one of the best YouTubers, incredibly thorough research, and one of the funniest people on the platform. I just wish she posted more.\n \nreply",
      "Her Star Wars hotel video was effectively just her talking to a camera for four hours (2 hours at 2x speed), occasionally sharing a photo or clip, and somehow  it was genuinely compelling viewing. Really impressive.\n \nreply",
      "Good riddance. I was always so creeped out by the band as a kid. Just hustle it up so I can get back to Skee-Ball and Smokin\u2019 Token, sheesh!\n \nreply",
      "I would have expected animatronics to become more popular after Five Nights at Freddy's, not less. But I've never seen a store with animatronics in my country, so I don't really know how kids feel about them.\n \nreply",
      "Idk, parents took kids to Chuck E. Cheese for the (at the time seemingly) wholesome appeal. Having an extremely popular and visible IP point out how creepy animatronic animals are is not gonna make parents want to take their kids to Chuck E. Cheese more. Nobody wants to take their kids to an \u201cedgy food and entertainment place\u201d, that\u2019s not a thing. I think this is a great textbook example of \u201cThere is such a thing as bad publicity.\u201d\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/chuck-e-cheese-animatronics",
    "first_paragraph": "The December 2024 issue of IEEE Spectrum is here!Charles \u201cEntertainment\u201d Cheese and friends will soon sing their last song Allison Marsh, a professor at the University of South Carolina, is currently a Fellow at the Linda Hall Library for Science, Technology, and Engineering.Chuck E. Cheese is preparing to retire the animatronics from nearly all of its 600 or so locations by the end of 2024.\n\tWhen I was eight years old, I won a coloring contest that earned me a free birthday party at my hometown Chuck E. Cheese. We don\u2019t have any photos from the event because, as my mother recalls, it was absolute mayhem. Kids were running from room to room playing video games and Skee-Ball. The adults couldn\u2019t corral anyone for pizza and cake. And then there was the show: The animatronic rat Charles \u201cEntertainment\u201d Cheese and the Pizza Time Players entertained\u2014or terrified\u2014attendees with their songs and corny banter.\n\n\tThat may have been the last time I entered a Chuck E. Cheese pizzeria. And yet, whe"
  },
  {
    "title": "How much do I need to change my face to avoid facial recognition? (gizmodo.com)",
    "points": 110,
    "submitter": "pseudolus",
    "submit_time": "2024-12-08T14:38:21 1733668701",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=42357372",
    "comments": [
      "I had a similar thought last time I was in an airport for an international flight and instead of scanning my boarding pass and looking at my passport they just let everyone walk through and as you passed the door it would tell you your seat number.When I was in Mexico I filed a report with the airport after an employee selling timeshares was overly aggressive and grabbed my arm and try to block me from leaving.  Quickly they showed me a video of my entire time with all my movements at the airport so they could pinpoint the employee.Like the article says I think it is just a matter of time until such systems are everywhere. We are already getting normalized to it at public transportation hubs with almost 0 objections. Soon most municipalities or even private businesses will implement it and no one will care because it already happens to them at the airport, so why make a fuss about it at the grocery store or on a public sidewalk.\n \nreply",
      "> and no one will care because it already happens to them at the airport, so why make a fuss about it at the grocery store or on a public sidewalk.You may be overestimating how many unique/different people travel through airports, especially more than once or twice to notice the tracking. People who travel once or twice total in their life by air, (are usually easy to spot), far more concerned with getting through a confusing hectic situation then noticing or even knowing that using facial recognition is new and not simply a special thing (because 9/11). And, the majority of Americans have travelled to zero or one country, last time I saw numbers on it. That country is usually Mexico or Canada where they drive (or walk).I think once it starts trying to hit close to home where people have a routine and are not as stressed by a new situation and have the bandwidth to--at a minimum--take a pause, will ask questions about what is going on.\n \nreply",
      "> Quickly they showed me a video of my entire time with all my movements at the airport so they could pinpoint the employee.This is just as interesting as it is creepy, but that's the world we live and this is hacker news. So, how quickly was was quickly. You made your report, they get the proper people involved, and then they show you the video. How much time passed before you were viewing the video?For someone that plays with quickly assembling an edited video from a library of video content using a database full of cuepoints, this is a very interesting problem to solve. What did the final video look like? Was it an assembled video with cuts like in a spy movie with the best angles selected in sequence? Was it each of the cameras in a multi-cam like view just starting from the time they ID'd the flight you arrived on? Did they draw the boxes around you to show the system \"knew\" you?I'm really curious how dystopian we actually are with the facial recognition systems like this.\n \nreply",
      "This tech isn't new. My company uses Axis cameras and Axis has some pretty advanced video analytics software https://www.axis.com/en-us/products/analyticsIt records the license plates of all cars entering and leaving the parking lots. You can associate names to faces which we do for all employees and the system automatically records when people enter and leave buildings. You can even just tell it to find all people with a blue shirt in a particular camera in a time window. It can automatically detect people shouting.\n \nreply",
      "Those sorts of systems run in realtime. They neither know (or care) who you are. They work by identifying people and pulling out appearance characteristics (like blue coat/red hair/beard/etc) and hashing them in a database. After that, it's straightforward to track similar looking people via connected cameras, with a bit of human assistance.\n \nreply",
      "Here's a marketing video for a multi-camera tracking system which does just that.[1][1] https://www.youtube.com/watch?v=07inDETl3LQ\n \nreply",
      "Twenty (!) years ago I got home from a drug store shopping trip and realized I had been charged for some expensive items I didn't buy.  I called, they immediately found me on their surveillance recording, saw the items were actually bought by the previous person in line, and quickly refunded me.  No face recognition was involved (they just used the timestamp from my receipt), but the experience immediately made me a fan of video monitoring.\n \nreply",
      "I worked in a retail/pc repair place about 10 years ago. Boss phoned me one day to say X (customer) device is missing have I seen it? I immediately knew it had been stolen and who by. I was on my own in the shop, 10 minutes before closing and I had been busy for the previous hour so the device was in the front of the shop instead of stored away securely like they normally would be. I was able to find the video within about 30 seconds of getting in and pinpoint the guy. I actually recognised him and was able to tell the police where I saw him somewhat frequently (as I lived nearby too).Without it, I think all the gingers would have pointed at me rather than me being tired and making a mistake.\n \nreply",
      "I was talking with an employee at a grocery store, who told me that management one day decided to review the surveillance footage, and fired a bunch of employees who were caught pilfering.\n \nreply",
      "I had a friend who was a checker at a large local chain, and before shift one day he popped into the security office (he was friends with the head of security) to say hi, and they had every camera in the front of the store trained on the employee working the customer service desk.Someone got fired that day.\n \nreply"
    ],
    "link": "https://gizmodo.com/how-much-do-i-need-to-change-my-face-to-avoid-facial-recognition-2000533755",
    "first_paragraph": ""
  },
  {
    "title": "VictoriaLogs: A Grafana Dashboard for AWS VPC Flow Logs \u2013 Migrating from Grafan (co.ua)",
    "points": 23,
    "submitter": "todsacerdoti",
    "submit_time": "2024-12-08T20:00:29 1733688029",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42359905",
    "comments": [
      "Hey, I heard you liked JSON?\n \nreply",
      "JSON is the universal format for structured logs. It is supported by all the popular log collectors and shippers. It is natively supported by VictoriaLogs [1] together with other popular data ingestion formats for logs [2].[1] https://docs.victoriametrics.com/victorialogs/keyconcepts/#d...[2] https://docs.victoriametrics.com/victorialogs/data-ingestion...\n \nreply",
      "What\u2019s the price difference?\n \nreply",
      "VictoriaLogs author hereBoth Loki and VictoriaLogs are open source and free to use. But they have non-zero costs for the hardware they use and non-zero maintenance and operational costs.VictoriaLogs is much easier to configure and run properly than Grafana Loki. VictoriaLogs runs smoothly with default configuration. It consists of a single small executable, which stores the ingested logs to the local filesystem. It doesn't break during upgrades because of good backwards compatibility.Loki, on the other side, requires non-trivial configuration and tuning to run properly. This configuration breaks frequently during upgrades. Loki consists of many microservices, which aren't easy to configure and orchestrate. It stores data to S3 (or any other S3-compatible object storage). This brings an additional dependency, which isn't needed in most practical setups.While S3 storage is usually cheaper than block storage, the price difference isn't so big (2x) when using HDD-based block storage (VictoriaLogs is optimized for HDD). Also, IO operations at S3 usually requires additional costs, which are frequently overlooked when comparing S3 costs to block storage costs.Also, VictoriaLogs runs typical queries over logs at much faster speed than Grafana Loki. This is clearly shown in the linked  article.See also https://docs.victoriametrics.com/victorialogs/faq/#what-is-t...\n \nreply"
    ],
    "link": "https://rtfm.co.ua/en/victorialogs-a-grafana-dashboard-for-aws-vpc-flow-logs-migrating-from-grafana-loki/",
    "first_paragraph": ""
  },
  {
    "title": "Replace Philips Hue Automation with Home Assistant's (frankel.ch)",
    "points": 46,
    "submitter": "Tomte",
    "submit_time": "2024-12-08T17:15:13 1733678113",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42358358",
    "comments": [
      "If you're going down the HomeAssistant route I'd recommend ditching any proprietary hubs and getting a Zigbee dongle instead, I've been using the Sonoff Zigbee dongle and even though it's connected to the server, in a rack, in the garage (so thick breezeblock walls between it and the rest of the house) there are enough always on mesh nodes in the lights themselves that the network is steady. Granted, the Dongle itself isn't inside the enclosed rack, it's on a USB extension cable and mounted on the top.I've also gone the Zigbee2MQTT (ZQM) route instead of the ZHM built into HomeAssistant as it just supports a lot more, and a lot better in my experience.Once you're in the open world of Zigbee, you can also go the Ikea Tradfri route as well for bulbs that are a WHOLE lot cheaper.\n \nreply",
      "Zigbee is good, but for lights or anything else you really want to always work, I'd recommend going with something that also works independently of HomeAssistant and Internet access even if you then need a proprietary hub to integrate with HomeAssistant.  Lutron's Caseta system is what I went with.I've found HomeAssistant with Zigbee to be extremely reliable, but the idea that a botched software upgrade or failed VM could make it so I can't turn my lights on and off feels like a bit too much.  Caseta doesn't use an open protocol, but it does allow all your switches, remotes, lights, etc, to work totally independently of HomeAssistant or Internet/WiFi, and the hub allows integration with home automation or remote control.  I've played around with Philips Hue and other smart bulbs, but it feels too much like a toy rather than something I'd replace all of my lights with, and ultimately I ended up with an all Caseta light setup for my home.\n \nreply",
      "Also be aware that there are a couple different kinds of \"works without internet access\".One kind works without ever needing internet access (on the IOT device itself or on the app if it uses an app) except possibly when you want to install a firmware update and perhaps when first setting up the device.The other kind requires you to log in to an account from the IOT vendor, but doesn't actually need internet access to then use the device. The thing to watch out for with these is that sometimes the login has a time limit so you occasionally have to re-login. Or sometimes you have to re-login if the vendor's app updates.An example of the latter is some TP-Link smart plugs I have. I only use them from Apple Shortcuts, but it is still TP-Link's app controlling them underneath and occasionally the shortcut stops working until I open the TP-Link. When I do that I invariably find that I'm no longer logged in, and logging back in makes them work again.For lights in particular another thing to consider when choosing them is what they do on power up. Some let you set the behavior and remember that on the IOT device, typically offering some subset of these options: light off; light full on; light however it was when power was last lost; light on to a specific brightness and color.Some have one of those behaviors and you can't change it. Typically \"light full on\", because that means you can use it both as an ordinary bulb that you turn on and off from a regular light switch and as a fancy IOT light.For lights that you only occasionally need to dim or change color on that can be great. But for lights that you often want to turn on and off remotely so you need to leave the switch on all the time it gets really annoying because every time you get a power outage or often even a significant power flicker they turn off and come back full on.\n \nreply",
      "Why are Lutron Caseta or RadioRA any different than a locally-hosted Home Assistant installation with an attached Z-Wave or Zigbee radio?Why is \"work[s] totally independently of Home Assistant\" a desirable property?https://www.zwaveoutlet.com/pages/z-wave-associationshttps://www.silabs.com/documents/public/application-notes/AP...\n \nreply",
      "Q: > Why is \"work[s] totally independently of Home Assistant\" a desirable property?A: > the idea that a botched software upgrade or failed VM could make it so I can't turn my lights on and off feels like a bit too much. Caseta doesn't use an open protocol, but it does allow all your switches, remotes, lights, etc, to work totally independently of HomeAssistant or Internet/WiFi\n \nreply",
      "With zigbee you can \u201cbind\u201d devices together, so that their interactions work without needing the hub to intervene. I bound my IKEA buttons to my IKEA lights with my homeassistant controller (with some difficulty) so that even when the controller is offline the buttons will still work.\n \nreply",
      "I agree, this is the way. If you do this, remember to install the devices on their final location and only then attempt to pair, so the device pairs to the closest appropriate router.\n \nreply",
      "You can use IKEA tr\u00e5dfri with Philips Hue. It\u2019s a bit annoying to pair but once that\u2019s done it just works, at least it has for me.\n \nreply",
      "Have gone this route and exposed a variety of manufacturers devices to HomeKit through HA. Been surprised by the reliability. 3 years in.\n \nreply",
      "I second all of this. I went with the little blue stick from HA and things have been great.\n \nreply"
    ],
    "link": "https://blog.frankel.ch/home-assistant/3/",
    "first_paragraph": ""
  },
  {
    "title": "Mise: Dev tools, env vars, task runner (github.com/jdx)",
    "points": 216,
    "submitter": "ksec",
    "submit_time": "2024-12-07T07:21:40 1733556100",
    "num_comments": 123,
    "comments_url": "https://news.ycombinator.com/item?id=42347917",
    "comments": [
      "I started using mise back when it was still called rtx. I was a little annoyed by asdf's quirks and having it replicate that behavior while being faster and less intrusive in my shell configuration was great.Since then, mise has folded in two capabilities that I needed the most: Task Running and Env Vars.Overall, it has been a fantastic experience for me. I love how the developer has spent a lot of time ensuring compatibility with existing tools while still building future capabilities.I will add one thing that I knew I needed but couldn't find anywhere was added through the recent backends feature. I do a lot of trust and R development and there are dev tools that I need installed that I don't use as libraries, just the binaries. It was a problem making sure that those dependencies were installed in a new environment. Now, it's just so easy: I list those in my `mise.toml` file, and that ensures they are installed and installable.\n \nreply",
      "The biggest visible boost has been in my shell startup times. Buying a computer after 5 years with 4 times as many cores and it feeling just as sluggish because nvm and pyenv are parsing the same set of bash files reading from disk was not pleasant. Mise actually made me feel, I didn\u2019t just throw the money into a void\n \nreply",
      "I don't understand how people don't notice the massive tax they're paying by using nvm:    $ hyperfine \"~/.nvm/nvm.sh\" \"mise env\"\n\n    Benchmark 1: ~/.nvm/nvm.sh\n      Time (mean \u00b1 \u03c3):      1.722 s \u00b1  0.032 s    [User: 0.064 s, System: 0.112 s]\n      Range (min \u2026 max):    1.684 s \u2026  1.805 s    10 runs\n     \n    Benchmark 2: mise env\n      Time (mean \u00b1 \u03c3):      13.4 ms \u00b1   5.7 ms    [User: 10.0 ms, System: 21.3 ms]\n      Range (min \u2026 max):     9.4 ms \u2026  42.2 ms    29 runs\n      \n    Summary\n      mise env ran\n      128.14 \u00b1 53.94 times faster than ~/.nvm/nvm.sh\n\n100x is definitely something you'll noticeEDIT: for some reason in discord we're getting very conflicting results with this test. idk why, but maybe try this yourself and just see what happens.\n \nreply",
      "I prefer GitHub.com/tj/n. It's really nice.\n \nreply",
      "I notice. It's awful.\n \nreply",
      "I recently switched to Mise for all of my JS, ruby, python, and java sdk management needs, and I\u2019ve been delighted with it so far. Not having to install RVM, NVM, some toxic brew of python installers until I get a working python environment, and SDKMan has been such a breath of fresh air.\n \nreply",
      "`brew install uv` and no more python troubles occur\n \nreply",
      "`mise use uv`, there, I fixed it for you.Mise actually has a great integration with uv, like auto venv activation.\n \nreply",
      "I think uv has auto venv activation and workspaces and stuff, now that uv is the official successor of Rye?\n \nreply",
      "uv is its own thing, but direnv + `source .venv/bin/activate` is straightforward nowadays.Direnv has saved me so much pain nowadays\n \nreply"
    ],
    "link": "https://github.com/jdx/mise",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        dev tools, env vars, task runner\n      The front-end to your dev env.The following shows using mise to install different versions\nof node.\nNote that calling which node gives us a real path to node, not a shim.Install mise (other methods here):or install a specific a version:Hook mise into your shell (pick the right one for your shell):Install a runtime and set it as the global default:See mise.jdx.dev\n        dev tools, env vars, task runner\n      "
  },
  {
    "title": "Researchers use AI to turn sound recordings into street images (utexas.edu)",
    "points": 132,
    "submitter": "giuliomagnifico",
    "submit_time": "2024-12-01T16:40:26 1733071226",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=42289233",
    "comments": [
      "The word \"accurate\" in that headline is doing a LOT of work.Here's how the results were scored:\"Computer evaluations compared the relative proportions of greenery, building and sky between source and generated images, whereas human judges were asked to correctly match one of three generated images to an audio sample.\"So this is very impressive and a cool piece of research, but unsurprisingly not recreating the space \"accurately\" if you assume that means anything more than \"has the right amount of sky and buildings and greenery\".\n \nreply",
      "That confuses accurate with detailed. It can be accurate even if it only reports one bit, like greenery proportion \"low\" or \"high\".\n \nreply",
      "But it's not reporting one bit, it's generating a detailed (color!) photo. 100s of kilobits of made up garbage plus one accurate bit cannot reasonably be described as an \"accurate\" result.\n \nreply",
      "Ok, we've made the title less 'accurate' (and more accurate?) above. Thanks!\n \nreply",
      "You're correct, but I'm also curious how you could measure accuracy here. There isn't any easy way that I can think of.\n \nreply",
      "That's not an unreasonable question, however the larger point is that this sort of thing cannot be done perfectly accurately.This was established mathematically, answering an old 1966 question from famous mathematician Mark Kac: \"You can't hear the shape of a drum\" -- there isn't a unique answer even when allowed to use arbitrary test sounds.Wikipedia:\nhttps://en.wikipedia.org/wiki/Hearing_the_shape_of_a_drumArticle in American Scientist 1996 Jan-Feb:\nhttps://www2.math.upenn.edu/~kazdan/425S11/Drum-Gordon-Webb....\n \nreply",
      "I love this paper, but something I think is often missed when it comes up is that you CAN hear the shape of many drums if you restrict the shape space, for example with a prior of \"what a drum should look like\" \nZelditch proved spectral uniqueness for convex, fully connected, drums with some symmetry.\n \nreply",
      "You are totally right but \"convex\" is a very strong assumption (so strong that the shape is determined by its harmonics). Very strong.\n \nreply",
      "Aha, I had missed that! Thanks.\n \nreply",
      "If you add multiple hearing points, you massively constrain the space of possible drums. The question then becomes something like \"can you see the shape of a drum?\"Proof of concept: echolocation.\n \nreply"
    ],
    "link": "https://news.utexas.edu/2024/11/27/researchers-use-ai-to-turn-sound-recordings-into-accurate-street-images/",
    "first_paragraph": "AUSTIN, Texas \u2014\u00a0Using generative artificial intelligence, a team of researchers at The University of Texas at Austin has converted sounds from audio recordings into street-view images. The visual accuracy of these generated images demonstrates that machines can replicate human connection between audio and visual perception of environments.In a paper published in Computers, Environment and Urban Systems, the research team describes training a soundscape-to-image AI model using audio and visual data gathered from a variety of urban and rural streetscapes and then using that model to generate images from audio recordings.\u201cOur study found that acoustic environments contain enough visual cues to generate highly recognizable streetscape images that accurately depict different places,\u201d said Yuhao Kang, assistant professor of geography and the environment at UT and co-author of the study. \u201cThis means we can convert the acoustic environments into vivid visual representations, effectively transl"
  },
  {
    "title": "A Year of WordHopper \u2013 Modern DOS Game Development Retrospective (kokoscript.com)",
    "points": 15,
    "submitter": "thunderbong",
    "submit_time": "2024-12-01T14:17:37 1733062657",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://kokoscript.com/2024/015.html",
    "first_paragraph": "/usr/foxpeople/koko/site-root/2024/015.html - Netscape Navigator 4.76/usr/foxpeople/koko/site-root/2024/015.html02 Nov 2024Editor's note: I originally started writing this as part of a larger 1-year anniversary celebration for WordHopper. However, a combination of less free time + suddenly many more side projects to take care of pushed the anniversary out a bit, to the point where things will have to happen piecemeal for now. I decided the retrospective dev journal would be the best place to start, just to dust off the blog a bit :)At the start of 2023, I decided to set a resolution for myself: release a game project. Didn't matter how big or small, it had to be something.I rarely do New Year's resolutions. Hell, I didn't set one this year. I'd set similar gamedev-related goals for myself in years past, but they never stuck. So I gave up trying to hold myself to anything. And yet, little did I know I'd eventually end up fulfilling my 2023 resolution when I set it. Just... not in the wa"
  },
  {
    "title": "Derivative at a Discontinuity (alok.github.io)",
    "points": 46,
    "submitter": "yuppiemephisto",
    "submit_time": "2024-12-03T22:36:13 1733265373",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42312376",
    "comments": [
      "I really appreciated this piece. Thank you to OP for writing and submitting it.The thing that piqued my interest was the side remark that the Dirac delta is a \u201cdistribution\u201c, and that this is an unfortunate name clash with the same concept in probability (measure theory).My training (in EE) used both Dirac delta \u201cfunctions\u201d (in signal processing) and distributions in the sense of measure theory (in estimation theory). Really two separate forks of coursework.I had always thought that the use of delta functions in convolution integrals (signal processing) was ultimately justified by measure theory \u2014 the same machinery as I learned (with some effort) when I took measure theoretic probability.But, as flagged by the OP, that is not the case! Mind blown.Some of this is the result of the way these concepts are taught. There is some hand waving both in signal processing, and in estimation theory, when these difficult functions and integrals come up.I\u2019m not aware of signal processing courses (probably graduate level) in which convolution against delta \u201cfunctions\u201d uses the distribution concept. There are indeed words to the effect of either,- Dirac delta is not a function, but think of it as a limit of increasingly-concentrated Gaussians;- use of Dirac delta is ok, because we don\u2019t need to represent it directly, only the result of an inner product against a smooth function (i.e., a convolution)But these excuses are not rigorously justified, even at the graduate level, in my experience.*Separately from that, I wonder if OP has ever seen the book Radically Elementary Probability Theory, by Edward Nelson (https://web.math.princeton.edu/~nelson/books/rept.pdf). It uses nonstandard analysis to get around a lot of the (elegant) fussiness of measure theory.The preface alone is fun to read.\n \nreply",
      "I think you can get a generalisation of autodiff using this idea of \"nonstandard real numbers\": You just need a computable field with infinitesimals in it. The Levi-Civita field looks especially convenient because it's real-closed. You might be able to get an auto-limit algorithm from it by evaluating a program infinitely close to a limit. I'm not sure if there's a problem with numerical stability when something like division by infinitesimals gets done. Does this have something to do with how Mathematica and other CASes take limits of algebraic expressions?-----Concerning the Dirac delta example: I think this is probably a pleasant way of using a sequence of better and better approximations to the Dirac delta. Terry Tao has some nice blog posts where he shows that a lot of NSA can be translated into sequences, either in a high-powered way using ultrafilters, or in an elementary way using passage to convergent subsequences where necessary.An interesting question is: What does distribution theory really accomplish? Why is it useful? I have an idea myself but I think it's an interesting question.\n \nreply",
      "> I think this is probably a pleasant way of using a sequence of better and better approximations to the Dirac delta.That can give wrong answers because derivative of the limit is not always the limit of the derivative.When modeling phenomena with Dirac delta, I think the question becomes do I really need a discontinuity to have a useful model or can I get away with smoothening the discontinuity out.\n \nreply",
      "Thanks a bunch for pointing me towards Levi-Civita field. Where can I learn more ? Any pedagogic text ?\n \nreply",
      "See my code at the end. The Wikipedia article is pretty good too. I can send you more if you like.\n \nreply",
      "Found it, thanks.\n \nreply",
      "I've personally always thought of the Dirac delta function as being the limit of a Gaussian with variance approaching 0. From this perspective, the Heaviside step function is a limit of the error function. I feel the error function and logistic function approaches should be equivalent, though I haven't worked through to math to show it rigorously.\n \nreply",
      "All these would be infinitely close in the nonstandard characterization. I just picked logistic because it was easy and step is discontinuous so it shows off the approach\u2019s power. If I started with delta instead I would have done Gaussian and integrated that and ended up with erf.\n \nreply",
      "Hm. Back when I was working on game physics engines this might have been useful.In impulse/constraint mechanics, when two objects collide, their momentum changes in zero time. An impulse is an infinite force applied over zero time with finite energy transfer. You have to integrate over that to get the new velocity. This is done as a special case. It is messy for multi-body collisions, and is hard to make work with a friction model. This is why large objects in video games bounce like small ones, changing direction in zero time.I wonder if nonstandard analysis might help.\n \nreply",
      "The following is just my opinion:Integration can be done with its own special arithmetic: Interval arithmetic. I base this suggestion on the fact that this is apparently the only way of automatically getting error bounds on integrals. It's cool that it works.NSA does not work with a computable field so it's not directly useful. But at the end of the article, there's a link to some code that uses the Levi-Civita field, which is a \"nice\" approximation to NSA because it's computable and still real-closed. You might be able to do an \"auto-limit\" using it, in a kind of generalisation of automatic differentiation. This might for instance turn one numerical algorithm, like Householder QR, into another one, like Gaussian elimination, by taking an appropriate limit.I don't know if these two things interact well in practice: Levi-Civita for algebraic limits and interval arithmetic for integrals. They might! This might suggest rather provocatively that integration is only clumsily interpreted as a limit of some function. Finally tbh, I'm not sure if this is the best solution to the friction/collision detection problem you're describing.\n \nreply"
    ],
    "link": "https://alok.github.io/2024/09/28/discontinuous-derivative/",
    "first_paragraph": "The title may seem like a contradiction. How can you differentiate something that\u2019s not even continuous?The usual definition of the derivative of a function \\(f\\) at a point \\(a\\) is given by the limit:If \\(f\\) is differentiable at \\(a\\), then it is continuous at \\(a\\). But what if it\u2019s NOT even continuous? Then how the hell can it be differentiable?Consider the step function, also known as the Heaviside step function. The Heaviside step function, \\(H(x)\\), is defined as:What\u2019s its derivative? Forget the formal definition of the derivative for a moment, and just consider the step function and the intuitive idea of a derivative as a slope.Outside of \\(x = 0\\), the step function is flat. So the derivative should be 0 everywhere besides \\(x = 0\\).Look at the step function, left to right. At 0, supposing for a moment there is a derivative, then it can\u2019t be any standard number. It\u2019s not 0 since it\u2019s certainly not flat. It\u2019s not negative since it\u2019s increasing to the right. It\u2019s bigger than 1"
  },
  {
    "title": "Show HN: Cut the crap \u2013 remove AI bullshit from websites (streamlit.app)",
    "points": 197,
    "submitter": "muc-martin",
    "submit_time": "2024-12-08T10:59:39 1733655579",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=42356443",
    "comments": [
      "I bookmarked this comment a few months ago because I thought it was hilarious and increasingly accurate:It's approaching a very strange situation where people make overly wordy and bloated AI generated content and other people try to use AI to compress it back into useful pellets vaguely corresponding to the actual prompts used to generate the initial content. Which were the only bits anybody cared about in the first place.\nOne guy pays the AI to dig a hole, the other guy pays the AI to fill in the hole. Back and forth they go, raising the BNP but otherwise not accomplishing anything.https://news.ycombinator.com/item?id=41635079More seriously though; I wonder if/when we will reach a point at which asking for a Neuromancer-esque pr\u00e9cis summary video of a topic will replace the experience of browsing and reading various sources of information. My gut feeling is that it will for many, but not all scenarios, because the act of browsing itself is desirable and informative. For example, searching for books on Amazon is efficient but it doesn\u2019t quite replace the experience of walking through a bookstore.\n \nreply",
      "For things like reviews I usually get a lot more value from a quick manual scan than an AI overview of any given review. Summaries of many reviews could be useful but if there are, e.g., thousands of reviews, I find myself skeptical of how truly \"thorough\" or well-executed that AI summary is anyway.For \"how do I write a bash script that will do X\" the AI summary currently is way better than scanning a handful of StackOverflow tabs, already.It will be interesting to see how \"fresh\" things like that stay in the world of newer or evolving programming languages. This is one of the areas where I already see the most issues (methods that no longer exist, etc).\n \nreply",
      "W.Gibson and N.Stephenson have proven right for so many things, like we live in their books. I wouldn't be surprised if they got this one right also, and it sounds plausible.Buuut, then, still, my significant other loves watching Friends, which was released she was born, and is not rewinding. So it depends.\n \nreply",
      "> One guy pays the AI to dig a hole, the other guy pays the AI to fill in the hole. Back and forth they go, raising the BNP but otherwise not accomplishing anything.Not accomplishing anything would be better than what is actually happening. Like with the hole example, once you fill it back up there\u2019s a good chance you can still tell a hole was dug in that place.What does \u201cBNP\u201d stand for in this context?\n \nreply",
      "Could be a swede who meant \"GDP\" (BNP = BruttoNationalProdukten = Gross Domestic Product)\n \nreply",
      "Business needs profit\n \nreply",
      "Maybe GDP in german or dutch?\n \nreply",
      "It's BIP, Bruttoinlandsprodukt, in german\n \nreply",
      "What that comment is describing is already here. A colleague sent an email that was obviously AI-generated (bloated, repetitive, low signal-to-noise ratio). I guess he's quite new to the team and it's a sign of formality, but I really don't mind if you send me just the bullet-point notes... Why are we going through this encoding-decoding process? I think succinctness and low-noise writing will be treasured in the age of AI.\n \nreply",
      "If you look at that tech emails twitter account that shows emails from discovery in various legal things, this is basically what you see, just sentences of context with very little niceties.https://x.com/TechEmails\n \nreply"
    ],
    "link": "https://cut-the-crab.streamlit.app/",
    "first_paragraph": ""
  },
  {
    "title": "Good union types in Go would probably need types without a zero value (utcc.utoronto.ca)",
    "points": 7,
    "submitter": "ingve",
    "submit_time": "2024-12-03T06:21:39 1733206899",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://utcc.utoronto.ca/~cks/space/blog/programming/GoUnionTypesAndZeroValues",
    "first_paragraph": ""
  },
  {
    "title": "Zizmor would have caught the Ultralytics workflow vulnerability (yossarian.net)",
    "points": 66,
    "submitter": "campuscodi",
    "submit_time": "2024-12-08T10:34:49 1733654089",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=42356345",
    "comments": [
      "This post has left me wondering: what is zizmor? What is ultralytics? Are these words actually real or is someone having a stroke?Not all nerds know all projects so I decided to educate myself and followed OP\u2019s links to learn about Ultralytics:> Ultralytics YOLO11 is a cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions and introduces new features and improvements to further boost performance and flexibility.Ultralytics\u2019 readme doesn\u2019t explain what ultralytics is or does. Thankfully Zizmor\u2019s readme describes itself clearly:> zizmor is a static analysis tool for GitHub Actions. It can find many common security issues in typical GitHub Actions CI/CD setups.This isn\u2019t a critique on OP: I enjoyed reading about the vulnerability(ies!) you found and I learned a lot. I\u2019m just generally frustrated that so many readme files on GitHub fail to describe what the project actually does, Ultralytics being just one example.Have fun and keep hacking\n \nreply",
      "I wonder if Zizmor has anything to do with this NYC local notable: https://en.wikipedia.org/wiki/Jonathan_Zizmor\n \nreply",
      "I named it explicitly for Dr. Zizmor :-)https://github.com/woodruffw/zizmor#the-name\n \nreply",
      "I was legitimately wondering if Dr Zizmor made a pivot into cybersecurity\n \nreply",
      "YOLO is an ML architecture used for object detection and recognition and Ultralytics develops a version of YOLO.\n \nreply",
      "Why has CI for open-source projects become so difficult to secure? Where did we, collectively, go wrong?I suppose, it's probably some combination of: CI is configured in-band in the repo, PRs are potentially untrusted, CI uses the latest state of config on a potentially untrusted branch, we still want CI on untrusted branches, CI needs to run arbitrary code, CI has access to secrets and privileged operations.Maybe it's too many degrees-of-freedom creating too much surface area. Maybe we could get by with a much more limited subset, at least by default.I've been doing CI stuff in my last two day jobs. In contrast, we worked only on private repos with private collaborators, and we explicitly designated CI as trusted.\n \nreply",
      "It's a web of danger for sure. Configuring CI in-repo is popular (especially in the Gitlab world) and it's admittedly a low-friction way to at least get people to use config control for CI (or use CI for builds at all). I think the number of degrees of freedom is really a footgun.I remember early Gitlab runner use when I had a (seemingly) standard build for a docker image. There wasn't any obvious standard way to do that. There were recommendations for dind, just giving shell access, etc. There's so much customization that it's hard to decide what's safe for a protected/main branch vs. user branches.I don't have a solution. But I think it would be better if, by default, CI engines were a lot less configurable and forced users to adjust their repo and build to match some standard configurations, like:- Run `make` in a Debian docker image and extract this binary file/.deb after installing some apt packages- Run docker build . and push the image somewhere- Run go build in a standard golang containerAnd really made you dance a little more to do things like \"just run this bash script in the repo\". Restrict those kinds of builds to protected branches/special setups.Having the CI config in the same source control tree is dangerous and hard to secure. It would probably be better to have some kind of headless branch like Github pages that is just for CI config.\n \nreply",
      "> Maybe it's too many degrees-of-freedom creating too much surface area.I think this is essentially it: there's extraordinary demand for \"publicly dispatchable and yet safe\" CI/CD, despite those requirements being fundamentally in tension with each other.All things considered, I don't think GitHub has done the worst job here: the security model for GitHub Actions is mostly intuitive, so long as you stick to triggers like `push`, `pull_request`, etc. The problems only really begin when people begin to use triggers that (IMO) GitHub should never have added in the first place, like `pull_request_target` -- those triggers break the basic \"in repo privileged, out of repo unprivileged\" security assumption and cause the kinds of problems we're seeing here.\n \nreply",
      "I wonder about an alternative history where the default feature set is much smaller and much safer, and everything else is opt-in behind a flag, and the flags are prefixed with \"unsafe_\" or something. That would hopefully encourage people to look up the \"unsafe_allow_foobar\" docs before using it.\n \nreply",
      "(Author of this post.)If you\u2019re interested in how this went down, the timeline section[1] in particular is worth jumping to: my key takeaway is that this vulnerability was reintroduced, and that there\u2019s only limited evidence that the Ultralytics team have done a full revocation and rotation of all accounts and credentials that the attacker may have had access to.Given that, it\u2019s not inconceivable that a third round of backdoored packages will occur. I would recommend that people exercise extreme caution when installing the current versions; most users would probably be best served by pinning to an older version from before any indicators of compromise.[1]: https://blog.yossarian.net/2024/12/06/zizmor-ultralytics-inj...\n \nreply"
    ],
    "link": "https://blog.yossarian.net/2024/12/06/zizmor-ultralytics-injection",
    "first_paragraph": "\nDec 6, 2024\n\n    \u00a0 \u00a0\n\n    \n      \n        Tags:\n        \n        \n          oss,\n        \n          security\n\n    \n\n    \u00a0 \u00a0\n\n    \n  TL;DR: zizmor would have caught the vulnerability that caused this\u2026mostly.\nRead on for details.Important: I\u2019m writing this post in real time as I learn more about what\nhappened here. I\u2019ll be updating it throughout the day.EDIT: I\u2019ve reached the point here where I feel comfortable making\nsome inferences/conclusions. These are in the Conclusions\nsection.EDIT 2024-12-07: Today is the last day I\u2019ll be making updates to this\npost. The Conclusions are now fully updated, and I\u2019ve added\na rough (but comprehensive)\ntimeline of events as an appendix.Yesterday, someone exploited Ultralytics, which is a very popular\nmachine learning package for vision stuff\u2122. The attacker\nappears to have compromised Ultralytics\u2019 CI, and then pivoted to making a\nmalicious PyPI release (v8.3.41, now deleted1), which contained a crypto miner.It appears as though a subsequent release (v8"
  },
  {
    "title": "Qutebrowser: A keyboard-driven, Vim-like browser (github.com/qutebrowser)",
    "points": 101,
    "submitter": "AbuAssar",
    "submit_time": "2024-12-08T12:06:14 1733659574",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=42356668",
    "comments": [
      "Someone was triggered by the Nyxt post getting so much attention... =DI like Qutebrowser very much, though. Used it for a good spell and was very happy. I'd some bug I couldn't fix which was driving everything really bonkers, but I honestly did not investigate it that hard, I'd been using it for a while at that stage (over a year, I'd guess, anyway) and was ready to move on and try something different, so I solved that bug the old fashioned way.Nyxt scratches the same itch now, but moreso, and it has Common Lisp behind it, which is much more interesting [to me personally!] than Python.\n \nreply",
      "Must be the cutting-edge-pun-not-intended browser compeition day...\n \nreply",
      "I tried an extension once that provided these navigation shortcuts for all the links on a page. It was really convenient but then I was on an admin page for our team and accidentally hit a couple keys that pressed some random button. The page was full of buttons that had irreversible effects which were executed without confirmation. Of course that\u2019s an issue itself for the page but that\u2019s kept me from trying this again.The convenience those shortcuts provide also makes it concerningly easy to press something on accident. Much more likely than accidentally clicking something. Having extra leader keys or some other approach to reduce accidental presses would detract from the convenience\u2026Curious if anyone else has run into this or configured their setup in a way that maintains the convenience but reduces the accident likeliness. Holding a modifier key or adding leader keys actually does seem like I\u2019d go a long way in reducing accidents with minimal hit to effectiveness\n \nreply",
      "I've used the Vimium chromium extension for years and it has a keypress to activate the search links and you can also disable it per domain.\n \nreply",
      "With Vimium, you can toggle the type to navigate mode so that it doesn't invoke unwarranted shortcut\n \nreply",
      "I tried really hard with QB, and still use it for some tasks, but the lack of Ublock Origin makes browsing random sites horrible.  People say the builtin ad blockers are good enough; for me, they are not even remotely good enough :(\n \nreply",
      "I've had good results running alt-browsers behind Privoxy.https://www.privoxy.org/\n \nreply",
      "Florian Bruhin (AKA the-compiler, the author of qutebrowser) is one of the kindest and most dedicated open-source maintainers I've ever had the pleasure to interact with.I've used qutebrowser extensively in the past, and reported a few bugs, each of which has been met with interest and engagement. Some of them even uncovered bugs in the upstream software (e.g. QtWebEngine) which were reported there.I eventually stopped using it when YouTube ads became too invasive, and went back to Firefox + Vimium + uBlockOrigin. I sometimes miss the programmibility of qutebrowser, but Vimium at least gives me the basic Vim-like browsing features.\n \nreply",
      "<3\n \nreply",
      "I'd love to use this but a key problem seems to be that they don't get updated as soon as a security fix is released, which for browser engines is quite often...\n \nreply"
    ],
    "link": "https://github.com/qutebrowser/qutebrowser",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A keyboard-driven, vim-like browser based on Python and Qt.\n       A keyboard-driven, vim-like browser based on Python and Qt.\nwebsite | blog | FAQ | contributing | releases | installingqutebrowser is a keyboard-focused browser with a minimal GUI. It\u2019s based\non Python and Qt and free software, licensed under the GPL.It was inspired by other browsers/addons like dwb and Vimperator/Pentadactyl.qutebrowser\u2019s primary maintainer, The-Compiler, is currently working\npart-time on qutebrowser, funded by donations. To sustain this for a long\ntime, your help is needed! See the\nGitHub Sponsors page or\nalternative donation methods\nfor more information. Depending on your sign-up date and how\nlong you keep a certain level, you can get qutebrowser t-shirts, stickers and\nmore!\n\n\nSee the GitHub releases\npage for available downloads and the INSTALL fi"
  },
  {
    "title": "Insects rely on sounds made by distressed vegetation to guide reproduction (nytimes.com)",
    "points": 165,
    "submitter": "tintinnabula",
    "submit_time": "2024-12-07T21:42:13 1733607733",
    "num_comments": 145,
    "comments_url": "https://news.ycombinator.com/item?id=42353066",
    "comments": [
      "https://archive.ph/tPyz8",
      "Okay so months can pick up ultrasonic sounds, plants emit such sounds when stressed, and the moths prefer plants that aren't emitting stress signals to increase likelihood of offspring survival. Every part of that seems pretty amazing.\n \nreply",
      "And also makes complete sense given evolution.\n \nreply",
      "Distressed plants say \"feed me, Seymour\" and moths hate it.\n \nreply",
      "Yeah that\u2019s amazing! Plants and moths just co-evolving some fascinating and beautiful traits.That reminds me of this particularly beautiful section from one of the newer Cosmos episodes, on how insects perceive light reflected from flowers:https://youtu.be/YJL63kv2_xg\n \nreply",
      "Is the sound part real? What frequencies are used to communicate stress? Is this in range of anything I could connect to a raspberry pico or arduino? My flowers desperately need answers :D\n \nreply",
      "Hi,This is real! We started our startup based on this principle. Do note that these emissions do not occur often, think about up to 10-100 per hours in stress states.\nFor a small background read, read this (not our research): https://www.cell.com/cell/fulltext/S0092-8674(23)00262-3If you are interested I recommend using a MEMS microphone, sampling at 384 or 500 kHz and triggering at frequencies between 20-200 kHz.There is several people who have made these solutions for detecting bats using pico's:\nhttps://www.geeky-gadgets.com/raspberry-pi-bat-detector-17-0...If you want something off the shelf look into something like this:\nhttps://batsound.com/\n \nreply",
      "> Do note that these emissions do not occur often, think about up to 10-100 per hours in stress states.I think I must be misreading.  If one wants to detect these signals being emitted by plants, why is 10\u2013100 per hour not often?  I'd think that having to wait 6 minutes, or, to play it safe, even an hour would still be way more informative than finding out about the stress only when its effects were visible to the eye.\n \nreply",
      "That's perfect, thank you!\n \nreply",
      "They are not \u201ccommunicating\u201d stress. There\u2019s no active action by the plants.https://www.nytimes.com/2023/03/30/science/plant-sounds-stre...> To be clear, the sounds made by harried plants are not the same as the anxious mumbling you might utter if you have a big deadline at work. The researchers suspect the nervous, popping noise is instead a byproduct of cavitation, when tiny bubbles burst and produce mini-shock waves inside the plant\u2019s vascular system, not unlike what happens in your joints when you crack your knuckles.It\u2019s the equivalent of stepping on a twig and knowing how dry it was based on the sound of the snap it makes.\n \nreply"
    ],
    "link": "https://www.nytimes.com/2024/12/06/science/moths-hearing-plant-sounds.html",
    "first_paragraph": ""
  }
]