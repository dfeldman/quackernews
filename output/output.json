[
  {
    "title": "Remote code execution via MIDI messages (psi3.ru)",
    "points": 193,
    "submitter": "portasynthinca3",
    "submit_time": "2025-01-05T07:40:48 1736062848",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=42600349",
    "comments": [
      "> Now, we have to get a little philosophical here. In my eyes, RE is like a game of minesweeper. You start with an empty field not knowing the state of any of the cells, i.e. not knowing whether each individual cell contains a landmine or not. When you discover the state of a cell, you have the context to deduce the state of its neighbor cells. In minesweeper, you don\u2019t have a particular direction in which you progress. You never say \u201cIn this game of minesweeper, I want to go up no matter what\u201d, you just let the numbers nudge you in the direction that is the easiest to go in at the moment. I assert that this is also true for RE. Once you find out what a function or a variable does, you suddenly understand a little more about functions and variables that depend on the ones whose meaning you\u2019ve just inferred. It may be beneficial not to set any particular goal with an RE project, and instead letting the complex network of intertwined functions and variables guide you towards understanding the system as a whole.That's such a nice way to think about it. Maybe I should try giving RE a go again.\n \nreply",
      "I don\u2019t know RE but I love this sentiment. I think it\u2019s quite generalizable too.  So many things are like that. Just start somewhere. It really doesn\u2019t matter where. And what you find will guide your next steps. Eventually you\u2019ll have enough context to see a much bigger picture well before it\u2019s fully revealed.\n \nreply",
      "Of course it is SysEx. SysEx is to standard MIDI what inline assembler is to Python. A world of undocumented proprietary stuff lurks within just about every MIDI device !\n \nreply",
      "I wish it was somehow possible to perform a piece of music that would cause remote code execution. It\u2019d be so cool to plug in a MIDI keyboard, play an Am6,9/G# and have it open a terminal window with root access.\n \nreply",
      "Yeah, same thinking here. No standard, manufacturer-defined, everything-goes kind of messages.\n \nreply",
      "can't wait to see what sysEx hacks google will cram on chrome midi support they are building for the last couple years.\n \nreply",
      "WebMIDI already has SysEx support: https://developer.mozilla.org/en-US/docs/Web/API/Web_MIDI_AP...\n \nreply",
      "Great project, write-up, and sense of humor in the videos!> Using that part number I wasn\u2019t able to find any information about the chip online apart from an article that claimed it was based around a \u201cSuperH\u201d CPU core \u2013 an ISA that I\u2019ve encountered for the first time ever in that article.Also found in Sega 32x, Sega Saturn, and Sega Dreamcast! And some early Pocket PCs (turn-of-the-century handhelds running Windows CE) like the HP Jornada series, although most Pocket PCs were ARM-based.\n \nreply",
      "This is such a ludicrous premise, I'm amazed you pulled it off.You mention \"another packing optimization\". I'm wondering, how are you transferring frames? The dot matrix is eight 7x5 characters, i.e. 280 bits in total, which amounts to 40 7-bit groups per frame. You seem to be using twice that space in transmission, is it wasted on some control data or is the transmission just slightly suboptimal?\n \nreply",
      "Thanks!The dot matrix is actually eight 5x8 characters, or 320 bits in total. I'm packing those 320 bits into the the 4 bits per byte that are available to us in this shell protocol. Plus, another 9 bytes for the packet header and footer. Looks like I wrote 92 in the article, I must have miscalculated that.I'm not using the full 7 bits because figuring out a way to do so turned out to be way too hard for me, so I opted for a solution that is negligibly worse than the optimal one, in comparison to the original one.If you're wondering about the exact algorithm, consider checking these files out, but please keep in mind that I haven't cleaned the code up yet: https://github.com/portasynthinca3/swl01u/blob/master/fun/bi..., https://github.com/portasynthinca3/swl01u/blob/master/fun/ba...\n \nreply"
    ],
    "link": "https://psi3.ru/blog/swl01u/",
    "first_paragraph": ""
  },
  {
    "title": "Republishing My Simpsons Fan Site, Twenty Years Later (bingeclock.com)",
    "points": 45,
    "submitter": "zebomon",
    "submit_time": "2025-01-05T22:44:08 1736117048",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=42605707",
    "comments": [
      "Somehow, the (much less impressive) Star Trek fan site I created in 2000 when I was 13 is still online.I\u2019ve long since lost access to it but the freeservers mob I hosted it with have somehow kept the sites from way back then all around and online still to this day. It\u2019s a little painful and factually incorrect (I called the movie Generations a series!) but gives me a good laugh:\nhttp://stvoyager.iwarp.com/\n \nreply",
      "Excellent work, ^-KewLGuY-^. I'd say that's the most \"13-year-old in the 2000s\" nick ever, but that honor probably goes to xXSephiroth666Xx. Yours is up there though.Eric S. Raymond recently posted some xeets about how retrocomputing nostalgia is due, in part, to wistfulness for the Cambrian explosion in personal computers, where every little two-bit company comes up with their own wildly different design. The design space hadn't been fully explored yet, and the future seemed pregnant with endless possibility. Then as people figured out what worked and what didn't in the computer design space, the PC sorta won, and it made much more sense to build a PC clone and take advantage of the huge PC hardware and software ecosystem. Raymond predicts that a similar coalescing on proven designs will happen with 3D printers.Of course, ESR believes in the need for government slightly less than he believes in the need for redemption through the blood of Christ the Saviour, so he overlooks a critical forcing factor in this cycle of exploring the solution space followed by settling on proven designs: regulation. Cars were much cooler before the 1970s because the Clean Air Act was passed in the 1970s. There was an initial struggle period during which American autos shipped with anemic engines and features designed to compensate for lack of performance, until technologies like fuel injection became the norm, but again the automakers coalesced into a set of a few designs that both worked and fulfilled the obligations imposed by regulatory bodies... to the point where it's awful hard to tell a Toyota RAV-4 from a Honda CR-V just by looking.I think the internet has gone through a similar exploratory vs. coalescing phase. Back in the 90s and 2000s, HTML and PHP let you create anything, so people created everything. And threw it up on a server, and it was wonderful. So many individual corners of the web with their authors' own perspectives. Now... well, regulation is definitely coming but in the meantime there are things with the force of regulatory bodies you have to worry about. You HAVE to do https which means you need a certificate. You HAVE to have a CDN and CloudFlare protection or else you'll be slashdot-effected or DDoS'd to oblivion. You can't even run an email server anymore without jumping through the hoops it takes to convince major providers you're  not a spam farm. These are things you have to either think about yourself or pay someone to think about them for you. So the web has coalesced on a few best-practice designs and service providers. And most people just set up Wix or Shopify pages or Facebook groups anyway.And that's why the 90s/2000s web has such nostalgic power. We could do anything from our armchairs with a bit of HTML and maybe some programming and sysadmin skills. But those days are gone. Maybe we're better off for it.\n \nreply",
      "These are the best. Thank you. anyone have any xfiles sites?\n \nreply",
      "I tried to sign the guestbook but could not. Didn\u2019t expect it to work but would have been nice.Wish guestbooks were still a thing. Visiting my site to find a new message was always a treat.\n \nreply",
      "Ha ha thanks :) yeah the guest book was an external service. Along with the image based hit counter :)\n \nreply",
      "Resources like the Simpsons Archive aka SNPP, the episode capsules particularly, which are just a collection of lengthy text files written decades ago but filled with treasure trove of insights and searchable references/quotes, are one of the rare simple gems of the Internet that I hope last forever.\n \nreply",
      "I rehosted my Tolkien fanpage from 1999 or so: https://tolkien.stavros.ioI also have my personal website from back then somewhere.\n \nreply",
      "Tangential but timely: I haven't watched the Simpsons regularly in about 20 years. However, my internal clock still sounds an alarm every Sunday night about 15 mins before showtime.\n \nreply",
      ">I had more fun being creative online when the stakes were so low that it seemed that just by playing I had already won something.I\u2019ve been thinking about this on and off a lot these past years.I think part of it is that when your time has no value, nothing you choose to do is a waste.That\u2019s not to suggest your time needs to be worth nothing. But that you stop perceiving your time as having intrinsic value.  My kids succeed where I fail all the time. They\u2019ll spend hours on projects that have been done far better by other people already. But they just don\u2019t think about those facts. They\u2019re not relevant. Their time is not being valued in anything other than the feeling of \u201cI want to do this thing.\u201d\n \nreply",
      "Have you seen the Python Atlanta website ? https://pyatl.devI built it and it\u2019s pretty bad. Even with the power of the Wordpress template I managed to make a bad website. \nBut I spent too much time thriving for perfection. And this one sort of works which is better than a non existent site that might work better.Perfect is the enemy of done.\n \nreply"
    ],
    "link": "https://www.bingeclock.com/blog/post/republishing-my-simpsons-fan-site-twenty-years-later",
    "first_paragraph": ""
  },
  {
    "title": "Global Regulations Enabling 6 GHz Wi-Fi (wi-fi.org)",
    "points": 7,
    "submitter": "teleforce",
    "submit_time": "2025-01-06T00:57:28 1736125048",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.wi-fi.org/regulations-enabling-6-ghz-wi-fi",
    "first_paragraph": "Apply\u00a0NowLog inThe worldwide network of companiesthat brings you Wi-Fi\u00ae\n\nView Wi-Fi CERTIFIED\u2122 products by category\n\nAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5925-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5925-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5925-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdoptedConsidering5945-6425 MHz6425-7125 MHzAdo"
  },
  {
    "title": "SrsRAN: Open-Source 4G/5G (github.com/srsran)",
    "points": 52,
    "submitter": "gballan",
    "submit_time": "2025-01-05T21:27:25 1736112445",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=42605201",
    "comments": [
      "Official srsRAN project website:https://www.srslte.com/\n \nreply",
      "Could anyone more knowledgeable on the topic explain to what extent common wireless connectivity standards are open and feasible to implement for, say, a medium sized company? Apple has been working on a 5G modem for what feels like a billion years, but other standards seem to be more democratized.\n \nreply",
      "The big problem is patents and copyright. No common wireless standards are open. No wireless standards are feasible to implement. Seriously. It's that bad. Certainly a modern 4G/5G standard is complex from a hardware standpoint to implement - the way you usually do these is using a very powerful embedded DSP, which is also not open (Qualcomm Hexagon is the most reverse-engineered of these if you want to understand what's going on). But the thing that's holding Apple up is purely legal IMO.\n \nreply",
      "If I remember correctly, all the documentation needed to implement a 5G radio approaches 10,000 pages. It\u2019s not only insanely long and complicated  but there\u2019s a nasty path dependency with most of 4G which is why Intel and now Apple have such a hard time getting their radios to the finish line. Poaching a few Qualcomm or Broadcom employees with better salaries is one thing but without the cumulative expertise contained within the companies, it\u2019s almost impossible to bootstrap a new radio.\n \nreply",
      "Fabrice Bellard open sourced a 4G (LTE) base station.https://bellard.org/lte/\n \nreply",
      "Stuff for GSM/CDMA has been around for years, OpenBTS is the primary example.  This is the first I've heard of anything more modern/complicated being implemented.  From my understanding, a lot of the hard eng work is in the RF frontend and making it small/low power enough to fit in a phone for example.  OpenBTS got around this by using existing SRDs for their RF frontend.\n \nreply",
      "WiFi, Bluetooth and Zigbee has bunch of public specifications and knowledge about it to make it feasible. AFAIK, the specifications for 4G/5G is publicly available but extremely complex + you'd need licensing agreements, pay royalties, etc. So unless this imaginary company of yours have specialized expertise in all that, it seems unlikely to be feasible.\n \nreply",
      "What do you mean by implementing? Make your own radio chips, designed from the ground up? Or merely producing a networking device using chips from suppliers like Intel, TI, Broadcom, Qualcomm etc? Or the software side only?\n \nreply",
      "The availability of hardware seems semi moot, since afaik there's basically no way to get spectrum short of big national auctions.But now that T-Mobile is renegging their promise & not going to meet the minimum deployment size they promised, they have been saying the FCC should find a way to sell by area some of that spectrum sitting dormant in such a wide wide % of America (personally I think it makes their bid invalid & they should forefeit their bid for such egregious dirty lying).\nhttps://www.lightreading.com/5g/t-mobile-relinquishes-mmwave...I think some of the analog tv spectrum has some precedent for being sold per-area rather than nation wide, but I'm not sure how that's been going.In terms of hardware, there's some fascinating stuff. Facebook's SuperCell large-tower project showed awesome scale out possibility for large towers. Their Terragraph effort is spun out, and seems to have some solid customers using their hardware. Meta spun off their EvenStar 5G system, which has a strong presence at Open compute now.\nhttps://www.opencompute.org/projects/evenstar-open-radio-uni...But it's hard to tell how acquireable such a thing really is. There's plenty of existing nodes out there too. It is unclear to me though how acquireable such things really are- there not being an open market, since there's no usable spectrum feels like a conundrum for the market, even though these are extremely high volume amazingly integrated advanced wireless systems that you'd think would be visibly prolific.\n \nreply",
      "> The availability of hardware seems semi moot, since afaik there's basically no way to get spectrum short of big national auctions.You can run 5G in the unlicensed spectrum. AWS can rent you hardware for it: https://aws.amazon.com/private5g/ - it's $5k a month per site. I know a plant that switched to that because they couldn't get WiFi to work reliably for them.But even if you want to run within the licensed spectrum, local licenses for a couple of bands are cheap. I was involved in setting up a private network in the licensed spectrum around 10 years ago (based on https://aviatnetworks.com/ ), and a local site spectrum license was something ridiculously small (in the range of a hundred dollars).It's expensive if you want to do it nation-wide.\n \nreply"
    ],
    "link": "https://github.com/srsran",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          The srsRAN software suite is an open-source collection of 4G and 5G software radio applications from SRS. Applications are implemented in portable C++ with minimal third-party dependencies. Licensed under AGPLv3, srsRAN apps run on Linux with off-the-shelf compute and radio hardware.Visit the srsRAN Project Homepage to learn more!\n        Open source SDR 4G software suite from Software Radio Systems (SRS) https://docs.srsran.com/projects/4g\n      \n\n\nC++\n\n\n\n\n\n            3.5k\n          \n\n\n\n\n            1.2k\n          \n\n        Open source O-RAN 5G CU/DU solution from Software Radio Systems (SRS) https://docs.srsran.com/projects/project\n      \n\n\nC++\n\n\n\n\n\n            576\n          \n\n\n\n\n            195\n          \n\n            Open source O-RAN 5G CU/DU solution from Software Radio Systems (SRS) https://docs.srsran.com/projects/project\n\n         "
  },
  {
    "title": "Human study on AI spear phishing campaigns (lesswrong.com)",
    "points": 152,
    "submitter": "DalasNoin",
    "submit_time": "2025-01-05T13:40:43 1736084443",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=42601681",
    "comments": [
      "I made a purchase yesterday from Meta (Oculus). A few minutes after payment, I received an email asking to click to confirm it was me.It came from verify@verification.metamail.com, with alert@nofraud.com cc. All red flags for phishing.I googled it because it had all the purchase information, so unless a malicious actor infiltrated Meta servers, it has to be right. And it was, after googling a bit. But why do they do such things?i would expect better from Meta.\n \nreply",
      "> i would expect better from MetaI'm surprised you would expect better.Everything I hear about their processes, everything I experience as a user, says their software development is all over the place.Uploading a video on mobile web? I get the \"please wait on this site\" banner and no sign of progress, never completes. An image? Sometimes it's fine, sometimes it forgets rotation metadata. Default feed? Recommendations for sports teams I don't follow in countries I don't live in. Adverts? So badly targeted that I end up reporting some of them (horror films) for violent content, while even the normal ones are often for things I couldn't get if I wanted to such as a lawyer specialising in giving up a citizenship I never had. Write a comment? Sometimes the whole message is deleted *while I'm typing* for no apparent reason.Only reason I've even got an account is the network effect. If the company is forced to make the feed available to others, I won't even need this much.If they stopped caring about quality of their core product, what hope a billing system's verification emails?\n \nreply",
      "Yes, but to receive a message that is not from them after a transaction you just did with them is quite bad.\n \nreply",
      "Meanwhile every time I am expecting a package via USPS or DHL, without fail, I get a scam text message about my incoming package. I never get them when I am not expecting a package. This is using a variety of devices, web shops, etc. Somewhere along the way, there is a data stream being sold or leaked.\n \nreply",
      ">I never get them when I am not expecting a package.For what it's worth, I get scam messages claiming to be about usps, dhl, et cetera even when I'm not expecting a package. Recently, I have a couple claiming to be about a package failing to clear customs (but if I just pay a quick fee...).\n \nreply",
      "Looking at what No Fraud does [0], it sounds like Meta has either spun off the first party hardware store from their usual infra, or straight asked a third party to deal with it, and to insulate their main business they split the email domains.Most companies are already splitting domains for customer and corporate communication, that's a step in the same direction.While you're right it sounds fishy as hell, it's also mildly common IMO and understadable, especially when e-commerce is not the main business, and could be a reflection of how anti-phishing provisions are pushing companies to be a lot more protective of the email that comes from their main domain.[0] https://www.nofraud.com/faq/\n \nreply",
      "It's only understandable because no one has standards.If I talk to Peter, Paul has no business getting any information about that or discussing it with me, untl Peter introduces me to Paul.We teach our kindergarteners this rule!\n \nreply",
      "It's always infuriating getting email from Amazon or my bank \"here's signs of potential phishing emails/texts\" that doesn't include an exhaustive list of every email address and phone number that that organization will try to contact me from. That should be table stakes when it comes to phishing avoidance, and it's something that can only be done by the business, not the customer.Yes, like you say, there's always the chance that someone hijacked an official domain - that's where other things like a formal communication protocol (\"we will never ask for your password\", \"never share 2FA codes\", \"2FA codes are separate from challenge-response codes used for tech support\") and rules of thumb like \"don't click on shortened links\" come in. Defense in depth is a must, but the list of official addresses should be the starting point and it isn't.\n \nreply",
      "Al legit bank will NEVER legitimately call you, except to say \"call us back at the number on your card\" . Caller ID is not secure.\n \nreply",
      "Thanks for the correction!My bank doesn't tell me that. It's this kind of incompetence and lack of responsibility on their part that's leading to scams and phishing being so unnecessarily successful.\n \nreply"
    ],
    "link": "https://www.lesswrong.com/posts/GCHyDKfPXa5qsG2cP/human-study-on-ai-spear-phishing-campaigns",
    "first_paragraph": "TL;DR: We ran a human subject study on whether language models can successfully spear-phish people. We use AI agents built from GPT-4o and Claude 3.5 Sonnet to search the web for available information on a target and use this for highly personalized phishing messages. We achieved a click-through rate of above 50% for our AI-generated phishing emails.This post is intended to be a brief summary of the main findings, these are some key insights we gained:In this paper, we evaluate the capability of large language models to conduct personalized phishing attacks and compare their performance with human experts and AI models from last year. We include four email groups with a combined total of 101 participants: A control group of arbitrary phishing emails, which received a click-through rate (recipient pressed a link in the email) of 12%, emails generated by human experts (54% click-through), fully AI-automated emails 54% (click-through), and AI emails utilizing a human-in-the-loop (56% clic"
  },
  {
    "title": "Kakizome, Japanese way of new-years resolution (harimus.github.io)",
    "points": 40,
    "submitter": "NalNezumi",
    "submit_time": "2025-01-02T17:27:05 1735838825",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42576436",
    "comments": [
      "Few more fun facts:Elementary school students all write kakizome at the end of December. Within the school, each grade will write the exact same thing. They're hung in the halls for all to see. Hundreds of the exact same kakizome.Many people burn their kakizome mid-January during \"Dondoyaki.\"The posture, attention and care taken while writing Kakizome is one of the important points. Those, and the outcome of the characters themselves, are all taken into account.Unrelated, but Japan's officaily chosen Kanji for the year 2024 was \"\u91d1\" which means gold, or money, or heck, even Friday.\n \nreply",
      "The Chinese have a new-year\u2019s calligraphy tradition, too, written on red paper and hung on your door.  Of course, that\u2019s done on the Lunar new year, not the Solar one.Your description of New Year\u2019s as \u201clike Western Christmas\u201d is apt - I remember visiting one year, and shocked by how quiet everything was, and how many restaurants and attractions were closed. Everyone was at home with their family!  The January First festival at Senso-ji Temple was a unique spectacle, though - the sound of people donating hundreds of one-yen coins at once is really unique.\n \nreply",
      "That\u2019s because Japanese new year is Chinese (lunar) new year traditions. They moved the New Year\u2019s celebration to align with the Western calendar as part of the Meiji restoration, but kept the festivities the same.\n \nreply",
      "Last year even though I didn\u2019t have a theme, I made small changes in the way I live, tried to complete my 15 book goodreads challenge, started doing sports and improve myself professionally on my free time.This year started with pretty fundamental questions in the way I live and uncertainties about my future so deciding on a theme is very difficult. I can\u2019t answer those questions and don\u2019t know what I really want. I will try to put an effort into keeping the good habits I gained last year though.\n \nreply",
      "This is my second year picking a theme and I picked \"Revolution\", many things are (probably) going to be different 360 days from now for me!Fun read, it didn't occur to me that I could simply pick foreign words that are much more adept at explaining complex concepts briefly.\n \nreply",
      "I like this idea of setting a theme. It gives you a compass for if an action is in accordance to the theme or not.I still like to drill into the concrete quantitative details of how I\u2019m going to achieve the theme though.This year theme for me would be: Freedom.\n \nreply",
      "What was a bit disappointing to me is the author decided to gloss over the parts like getting fresh water from a well and having it purified at the temple.That's the parts I wanted more details on - it makes it interesting and more like a glance at a foreign and different culture.\n \nreply",
      "Japan does really have a wells that has pure water than is drinkable\n \nreply",
      "> couple of years ago, CGP Grey made a point about replacing the New Year resolution with the New Year theme.Yeah this year (really: mid December when the work year ended for us) we declared it the Year of Discovery. All it really is, is a thing my wife and I say to each other any time we\u2019re humming and hawing on a purchase or decision or uncertainty on what menu item to pick.  It\u2019s kind of become a running joke, and yet it\u2019s pretty effective.\n \nreply"
    ],
    "link": "https://harimus.github.io//2025/01/02/kakizome.html",
    "first_paragraph": "Firstly, Happy New Year! As a New Year tradition with my family, I usually go home to my parents and celebrate it the Japanese way. It has always given me a convenient excuse to leave early after the countdown. To my puzzled friends, I usually briefly describe it as \u201cJapanese New Year is like Western Christmas. You spend time with family.\u201d You eat specific foods, go to the temple to pray for a good year, etc*.Today, I thought it would be fun to share one common tradition Kakizome: \u66f8\u304d\u521d\u3081.CalligraphyLike many traditions, there are regional differences in the details. I think I\u2019m not too far off if I describe it as:First calligraphy written at the start of the year, often writing the aspiration or ambition one set up for the year.I won\u2019t go into the long traditional detail, such as using the first water from the well, purified at the temple, and for that reason, it is often done on the 2nd of January rather than the first\u2026. because I don\u2019t do it and I think (like many thing Zhen) many Japa"
  },
  {
    "title": "Show HN: LogLayer \u2013 Unified Logging for JavaScript (MIT Licensed) (loglayer.dev)",
    "points": 3,
    "submitter": "theogravity",
    "submit_time": "2025-01-06T00:52:24 1736124744",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://loglayer.dev/",
    "first_paragraph": "Unifies LoggingA layer on top of Javascript logging libraries to provide a consistent logging experience.Write logs with a fluid API that makes adding tags, metadata and errors simple.Use console logging when starting out, then switch to another logging provider later without changing your application code.Transform, enrich, and filter logs with plugins that lets you customize every aspect of your logging pipeline.Fan out logs to multiple logging libraries and cloud providers such as DataDog and New Relic at the same time."
  },
  {
    "title": "Reverse Engineering the Constants in the Pentium FPU (righto.com)",
    "points": 59,
    "submitter": "mef",
    "submit_time": "2025-01-05T19:34:18 1736105658",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42604350",
    "comments": [
      "Author here for your Pentium questions...\n \nreply",
      "Hello!  In your view, did the move to IEEE 754 floating-point make things easier or harder for CPU designers?\n \nreply",
      "My guess is that it made things both easier and harder. Harder in the sense that you couldn't just throw together floating point circuits; you had to deal with lots of special cases. But easier in the sense that the tricky design decisions were already made for you. And easier to test against a known standard.\n \nreply",
      "For what its worth, Intel was one of the major contributors to IEEE 754.  In a lot of ways the original 8087 behavior became an early IEEE 754 draft.\n \nreply"
    ],
    "link": "http://www.righto.com/2025/01/pentium-floating-point-ROM.html",
    "first_paragraph": ""
  },
  {
    "title": "Chip-8 Emulation Introduction (emulationonline.com)",
    "points": 12,
    "submitter": "thunderbong",
    "submit_time": "2025-01-03T06:48:59 1735886939",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42583204",
    "comments": [
      "I wrote an emulator in Python in college and recently redesigned and rewrote it in rust. It was a pretty fulfilling experience. I spent several weeks writing a long program just to get data to sufficiently test performance. After all was said and done, my rust emulator still ran the program so fast I could barely get enough samples for a flame graph.If anyone reading is working on a chip-8 emulator for the first time, a word of warning: for instructions that affect the vF register, be sure to check whether the register should be set before running the instruction but actually set it after. This is subtle but affects several popular roms.My test program if anyone wants to marvel at my inefficient assembly: \nhttps://github.com/dreary-dugong/fib8_benchmarkThere's some fun stuff in there though, animated graphics and self modifying code. Highly recommend hacking on chip-8.\n \nreply",
      "A common mistake when implementing a CHIP-8 emulator is to allow the nominally 12-bit \"I\" register to overflow, leading to out-of-bounds memory accesses. When the emulator is written in a memory-unsafe language like C, this can lead to an emulator escape exploit - I wrote about one here: https://www.da.vidbuchanan.co.uk/blog/bggp3.html\n \nreply",
      "Writing a chip8 emulator is a fun project\n \nreply"
    ],
    "link": "https://www.emulationonline.com/systems/chip8/intro/",
    "first_paragraph": ""
  },
  {
    "title": "Documenting an 1115 ft radio tower climb (jeffgeerling.com)",
    "points": 156,
    "submitter": "geerlingguy",
    "submit_time": "2025-01-02T20:02:18 1735848138",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=42578201",
    "comments": [
      "This video did the rounds many years ago now, still quite an uncomfortable watch especially when he gets to the top! I understand they don't allow 'free climbing' any more... https://www.youtube.com/watch?v=tgO4Gd4RhvM\n \nreply",
      "This makes me physically very uncomfortable to watch. What a thrill.\n \nreply",
      "Also a movie, Fall:https://www.imdb.com/title/tt15325794/\n \nreply",
      "I am afraid of heights. I had to go back halfway through going up the Eiffel tower.Jesus fuck this video has me on edge. I don't know what moved me to click that link, haha.These people have balls of tungsten, that's for sure.\n \nreply",
      "These people presumably aren\u2019t scared of heights, so I\u2019m not sure we can really comment on their balls\n \nreply",
      "People who work at heights usually have just enough fear of heights to not do something stupid. Those with no fear of heights tend to make fatal mistakes.Source: 35 years of climbing and 10 years of industrial rope access :-)\n \nreply",
      "I'd say their balls have a relative density in between bromine and tungsten. Uranium = customer service roles.\n \nreply",
      "He sort of touched on this, but an aspect of tower rigging that most people don\u2019t think about is how long it can take to climb a tower when you are the first one up with the line. It\u2019s absolutely exhausting work.Another side fact, wasps are attracted to building nests on the towers for some reason. I never knew if it was all the EM radiation being put off or just the heat.\n \nreply",
      "I used to do this and, for me, the time it took was entirely dependent on the gear I was provided and whether the climb was enjoyable. The gear isn\u2019t exactly what you think of when you think climbing gear and, frankly, it\u2019s infuriating. It might be manufactured by Petzl but the weight and utility are terrible relative to their alpine and mountaineering products. Hell, I was expected to wear work boots that were extremely heavy and climbed poorly. As far as scenery, everyone, myself included, would treat these climbs as climbs and would enjoy ourselves if the views were scenic. The work itself wasn\u2019t hard relative to the trips we were guiding during the climbing season.\n \nreply",
      "To what extent do people in this line of work feel fear as they do it? Is it mainly suitable for those rare people who either don\u2019t feel fear, or the less-rare people who are looking for a rush, or does it just become mundane after sufficient experience, so that really anyone can do it?\n \nreply"
    ],
    "link": "https://www.jeffgeerling.com/blog/2024/documenting-1115-ft-radio-tower-climb",
    "first_paragraph": ""
  },
  {
    "title": "Using watermarks to coordinate change data capture in Postgres (sequinstream.com)",
    "points": 54,
    "submitter": "misonic",
    "submit_time": "2025-01-03T03:28:26 1735874906",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.sequinstream.com/using-watermarks-to-coordinate-change-data-capture-in-postgres/",
    "first_paragraph": "In change data capture, consistency is paramount. A single missing or duplicate message can cascade into time-consuming bugs and erode trust in your entire system. The moment you find a record missing in the destination, you have to wonder: is this the only one? How many others are there?Sequin sends changes from Postgres to destinations like Kafka, SQS, and webhook endpoints in real-time. In addition to change data capture, we let you perform table state capture: you can have Sequin generate read messages for all the rows or a subset of rows from tables in your database. This lets you rematerialize all your Postgres data in your destination. Or recover from errors by replaying Postgres rows through your system.Because Postgres does not keep its WAL around indefinitely, we can't use the WAL to do a full table state capture. The WAL is only a partial tail of recent changes in the database. It's intended to send the latest changes to replicas.Instead, we can perform table state capture b"
  },
  {
    "title": "Extracting AI models from mobile apps (altayakkus.substack.com)",
    "points": 249,
    "submitter": "smoser",
    "submit_time": "2025-01-05T13:19:18 1736083158",
    "num_comments": 172,
    "comments_url": "https://news.ycombinator.com/item?id=42601549",
    "comments": [
      "This is cool, but only the first part in extracting a ML model for usage. The second part is reverse engineering the tokenizer and input transformations that are needed to before passing the data to the model, and outputting a human readable format.\n \nreply",
      "Would be interesting if someone could detail the approach to decode the pre-post processing steps before it enters the model, and how to find the correct input encoding.\n \nreply",
      "Boils down to \"use Frida to find the arguments to the TensorFlow call beyond the model file\"Key here is, a binary model is just a bag-of-floats with primitively typed inputs and outputs.It's ~impossible to write up more than what's here because either:A) you understand reverse engineering and model basics, and thus the current content is clear you'd use Frida to figure out how the arguments are passed to TensorFloworB) you don't understand this is a binary reverse engineering problem, even when shown Frida. If more content was provided, you'd see it as specific to a particular problem. Which it has to be. You'd also need a walkthrough by hand about batching, tokenization, so on and so forth, too much for a write up, and it'd be too confusing to follow for another model.TL;Dr a request for more content is asking for a reverse engineering article to give you a full education on modal inference\n \nreply",
      "This is a good comment, but only in the sense it documents a model file doesn't run the model by itself.An analogous situation is seeing a blog that purports to \"show you code\", and the code returns an object, and commenting \"This is cool, but doesn't show you how to turn a function return value into a human readable format\" More noise, than signal.The techniques in the article are trivially understood to also apply to discovering the input tokenization format, and Netron shows you the types of inputs and outputs.Thanks for the article OP, really fascinating.\n \nreply",
      "Just having the shape of the input and output are not sufficient, the image (in this example) needs to be normalized. It's presumably not difficult to find the exact numbers, but it is a source of errors when reverse engineering a ML model.\n \nreply",
      "Right, you get it: it's a Frida problem.\n \nreply",
      "If you can't fix this with a little help from chatgpt or Google you shouldn't be building the models frankly let alone mucking with other people's...\n \nreply",
      "I\u2019m a huge fan of ML on device. It\u2019s a big improvement in privacy for the user. That said, there\u2019s always a chance for the user to extract your model, so on-device models will need to be fairly generic.\n \nreply",
      "Maybe someday we will build a society where standing on the shoulders of giants is encouraged, even when they haven't been dead for 100 years yet.\n \nreply",
      "this would be yellow in https://en.wikipedia.org/wiki/Spiral_Dynamics but we are still a mix of orange and green.\n \nreply"
    ],
    "link": "https://altayakkus.substack.com/p/you-wouldnt-download-an-ai",
    "first_paragraph": ""
  },
  {
    "title": "The Maxwell-Heaviside Equations Explained by the Theory of Informatons (researchgate.net)",
    "points": 7,
    "submitter": "keepamovin",
    "submit_time": "2025-01-02T12:13:15 1735819995",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.researchgate.net/publication/382229137_The_Maxwell-Heaviside_Equations_Explained_by_the_Theory_of_Informatons",
    "first_paragraph": ""
  },
  {
    "title": "Corvus Robotics (YC S18) is hiring a Head of Software to help inventory drones",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-01-05T21:20:07 1736112007",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=42605143",
    "first_paragraph": ""
  },
  {
    "title": "How NAT Traversal Works (2020) (tailscale.com)",
    "points": 336,
    "submitter": "hhthrowaway1230",
    "submit_time": "2025-01-05T10:15:58 1736072158",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=42600846",
    "comments": [
      "This is an excellent article!The tribal knowledge seems to be that you shouldn't do TCP-based hole punching because it's harder than UDP. The author acknowledges this:> You can do NAT traversal with TCP, but it adds another layer of complexity to an already quite complex problem, and may even require kernel customizations depending on how deep you want to go.However, I only see marginally added complexity (given the already complex UDP flows). IMO this complexity doesn't justify discarding TCP hole punching altogether. In the article you could replace raw UDP packets to initiate a connection with TCP SYN packets plus support for \"simultaneous open\" [0].This is especially true if networks block UDP traffic which is also acknowledged:> For example, we\u2019ve observed that the UC Berkeley guest Wi-Fi blocks all outbound UDP except for DNS traffic.My point is that many articles gloss over TCP hole punching with the excuse of being harder than UDP while I would argue that it's almost equally feasible with marginal added complexity.[0] https://ttcplinux.sourceforge.net/documents/one/tcpstate/tcp...\n \nreply",
      "The existence of stateful firewalls, and the fact that most NAT filters are EDF rather than EIF means that simultaneous open (send) is necessary even for UDP.Hence the added complexity of doing a simultaneous open via TCP is fairly minor. The main complication is communicating the public mapping, and coordinating the \"simultaneous\" punch/open.  However that is generally needed for UDP anyway...One possible added complexity with TCP is one has to perform real connect() calls, rather than fake up the TCP SYN packet.  That is becase some firewalls pay attention to the sequence numbers.\n \nreply",
      "Yeah, I've gotten somewhat annoyed by the name of 'NAT traversal' for these methods. It seems to make some people think that cutting out NAT will lead to a beautiful world of universal P2P connections. But really, these methods are needed for traversing between any two networks behind stateful firewalls, which will pose a barrier to P2P indefinitely.Also, wouldn't it be easier for stateful firewalls to block simultaneous TCP open (intentionally or not)? With UDP, the sender's firewall must create a connection as soon as it sends off the first packet, even if that packet bounces off the other firewall: the timing doesn't have to be particularly tight. But with TCP, the firewall might plausibly wait until the handshake is complete before allowing incoming packets, and it might only allow the 3-way SYN/SYN-ACK/ACK instead of the simultaneous SYN/SYN/ACK/ACK.\n \nreply",
      "> But really, these methods are needed for traversing between any two networks behind stateful firewalls, which will pose a barrier to P2P indefinitely.That's true. The actual problem are symmetric NATs where every peer sees a different port number. This makes traditional NAT-traversal impossible and you have to resort to port guessing/scanning. See for example https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&d...\n \nreply",
      "People honestly thought for a while that devices behind a NAT were secured unless ports were specifically routed to them, hence the term \"nat hole punching\" was coined.You're probably right that it makes less sense from today's perspective\n \nreply",
      "Doesn't make sense. NAT hole punching requires you to execute on the target inside the NAT.If you are able to do that whatever security you got from NAT has been breached even before NAT hole punching enters the conversation.NAT will block unsolicited incoming connections, that is a great boon for security but obviously not a silver bullet for all network related security issues nor outgoing connections. That has never been a trope.\n \nreply",
      "I did just think of another drawback for TCP vs UDP punching that I think puts a major point in UDP's favour. It may have been touched on others already. But TCP would require the router to record connection state. This is bad because the table for routers is very small and some of these punching techniques are quite aggressive. Like the algorithm that tries to bypass symmetric NATs. If you're opening hundreds of TCP connections its possible you might even DoS the router. For UDP its plausible optimizations for state management would make it less likely that your punching would render the whole router inoperable. This is only speculation though.\n \nreply",
      "> If you're opening hundreds of TCP connections its possible you might even DoS the router.This was sometimes an issue for underpowered home/SOHO routers in the mid-2000s, but most modern routers have enough memory to support decently sized connection-tracking tables.In any case, both TCP and UDP require connection tracking; there's no inherent advantage to UDP.\n \nreply",
      "I think this is a really good point. As someone who has implemented TCP hole punching myself and now has a very good implementation for it I will say that obviously a major benefit of using TCP is you don't have to subsequently roll a poorman's TCP on-top of UDP once the hole is open. The other issue with TCP hole punching though is it looks very similar to a SYN flood compared to UDP packets. This may mean lower success rates for some networks. Though in practice I haven't seen much filtering so far.TCP hole punching is very fun. The way I do it is to use multiple NTP readings to compute a \"clock skew\" -- how far off the system clock is from NTP. Then the initiator sets a future meeting time that is relative to NTP. It honestly gets quite accurate. It even works for TCP hole punching between sockets on the same interface which is crazy if you think about it.The reason I wanted to support this strange, local-based punching mode is if it works that efficiently to be able to succeed in host-based punching then likely it will be fast enough to work on the LAN and Internet, too. My code is Python and my very first attempt at this was eye opening to say the least. Due to how timing-sensitive TCP hole punching is I was having failures from using Python with old-school self-managed sockets. I was using threading and a poormans event loop (based on my C socket experience)... which is ah... just not the way to do it in Python.The only way I could get that code to work was to ensure the Python process had a high priority so other processes on the system didn't deprioritize it and introduce lag between the punching attempts. That is how time-critical the code is (with an inefficient implementation.) My current implementation now uses a process pool that each has its own event loop to manage punching. I create a list of tasks that are distributed over time. Each task simply opens a connection that is reused from the same socket. I determined this code was the best approach (in Python anyway) after testing it on every major OS.You are right about TCP and UDP hole punching difficulty being similar. The main difficulty to both is the NAT prediction step. I haven't written code yet for symmetric NAT bypass but I am starting to see how I'd integrate it (or possibly write a new plugin for it.)\n \nreply",
      "Fascinatingly effective, but maybe I'm the only one getting the heebie-jeebies when someone suggests implementing this in production corp networks. Sure it's super convenient, but the thought of bypassing all traditional NATs and firewalls, and instead relying solely on a software ACL, seems super risky. Maybe I just don't understand how it works, but it seems that a bad actor getting access to a stray VM with Tailscale on it in, say, your AWS testing env, essentially has an clear path all the way into your laptop on the internal corp network, through the kernel, into user space and into the Tailscale ACL code as the sole arbiter of granting or blocking access. Would I even know someone unauthorized made it that far?\n \nreply"
    ],
    "link": "https://tailscale.com/blog/how-nat-traversal-works",
    "first_paragraph": "We covered a lot of ground in our post about How Tailscale\nWorks. However, we glossed over how we can get through NATs\n(Network Address Translators) and connect your devices directly to\neach other, no matter what\u2019s standing between them. Let\u2019s talk about\nthat now!Let\u2019s start with a simple problem: establishing a peer-to-peer\nconnection between two machines. In Tailscale\u2019s case, we want to set\nup a WireGuard\u00ae tunnel, but that doesn\u2019t really matter. The\ntechniques we use are widely applicable and the work of many people\nover decades. For example, WebRTC uses this bag of tricks to\nsend peer-to-peer audio, video and data between web browsers. VoIP\nphones and some video games use similar techniques, though not always\nsuccessfully.We\u2019ll be discussing these techniques generically, using Tailscale and\nothers for examples where appropriate. Let\u2019s say you\u2019re making your\nown protocol and that you want NAT traversal. You need two things.First, the protocol should be based on UDP. You can do NAT tr"
  },
  {
    "title": "Show HN: Struggle with CSS Flexbox? This Playground Is for You (yoavsbg.github.io)",
    "points": 269,
    "submitter": "yoav_sbg",
    "submit_time": "2025-01-05T09:02:01 1736067721",
    "num_comments": 95,
    "comments_url": "https://news.ycombinator.com/item?id=42600586",
    "comments": [
      "Having come from WPF with dotnet, XAML/WPF used to feel clunky and dated.However, web front-end feels very chaotic by comparison. I\u2019m still no expert, but my big gotchas are always div sizes ie min-max-fr height/width.With WPF you can size Grids as auto or \u201c*\u201d and things size dynamically - I\u2019ve grown to appreciate the WPF Grid and data binding.It also doesn\u2019t help that I find trial-and-error more helpful than css/html docs. The docs often feel tautological to me for some reason and it feels like there\u2019s too many ways to achieve the same thing. I definitely recognize this personal experience - YMMV\n \nreply",
      "In my opinion, flexbox is simple and makes a lot of sense. The problem is that its properties and values were named by a committee, so they aren't intuitive to anyone who wasn't involved in the long proceedings that led up to the spec being written. You try to remember which one is justify-content, which one is align-items, and so forth, and just give up and try everything until something seems to work.\n \nreply",
      "I have to visit https://css-tricks.com/snippets/css/a-guide-to-flexbox/ literally every time. There's a similar one for grid that's just as good.\n \nreply",
      "One trick is if you open the chrome css inspector, you can click an icon next to the display: flex rule and see iconographic representation of the various flex box properties, and click them to set them. Every page essentially becomes a playground\n \nreply",
      "My issue with flexbox is that I can't seem to memorize all the settings I need to get boxes within boxes and content to either fill a box or the box to surround the content.This is particular important on an SPA where I want the boxes to fill the screen but never overflow it. I manage eventually. I need to put the totally intuitive (sarcasm) min-width: 0, here and there, and a few other things here and there and eventually I get it.I feel like I should be able to make a few css classes to cover all of this but I have yet to figure it out for every case.\n \nreply",
      "It's mostly:- \"flex: 1 1 0px\" for fill available space- \"flex: 0 0 auto\" for sizes to contentAnd then arguably every flexbox item ought to have min-width (and/or min-height) set to 0 because flexbox has a \"min content sized\" automatic minimum size built-in, which is rarely what you want. But if the content isn't overflowing or can be compressed in some way then you can get away without this.\n \nreply",
      "One thing I don't like about flexbox is that align-items and justify-content switch what they do depending on the flex-direction.justify-content: center; with flex-direction: row; makes the element horizontally centered. But justify-content: center with flex-direction: column; makes the element vertically centered.\n \nreply",
      "It is impressive that Tailwind succeeded in making this even more confusing.justify-content: center -> justify-centeralign-items: center -> items-centerJust\u2026 why?\n \nreply",
      "There's a reason \"naming things\" is one of the great hard problems of programming. Especially when you have to name hundreds of things while developing i.e. a framework. Unless it's a solo pedantic developer creating the entire thing, inconsistencies will crop up, some names won't age well, some names don't quite capture the thing they are naming, etc.\n \nreply",
      "justify-content should be called main-axis. align-items should be called cross-axis.Once you understand this, all of flexbox becomes easy.\n \nreply"
    ],
    "link": "https://yoavsbg.github.io/css-flexbox-playground/",
    "first_paragraph": "Experiment with different flex properties to understand how they affect layout. Adjust the controls below to see changes in real-time and copy the generated CSS code."
  },
  {
    "title": "Axum 0.8 (tokio.rs)",
    "points": 102,
    "submitter": "minimaxir",
    "submit_time": "2025-01-01T18:18:48 1735755528",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=42567900",
    "comments": [
      "I really hope guide-level docs are on the roadmap for Axum. The current situation of \"here are some (third-party) blog posts and YouTube videos\" is not greatly encouraging. For reference:https://github.com/tokio-rs/axum?tab=readme-ov-file#getting-...https://github.com/tokio-rs/axum/blob/main/ECOSYSTEM.md#tuto...\n \nreply",
      "The API docs[1] often have a decent amount of guide level information on items within the library, but are perhaps lacking in the \"use this crate for ...\" type space. What specifically do you think is missing?[1]: https://docs.rs/axum/latest/axum/\n \nreply",
      "I've been dabbling with axum as of late and I agree the docs are relatively good.I think 2 things that are missing.- What you mention, \"use this for that\" sorts of guides.  The ecosystem is pretty good, but when you pull down axum you aren't getting something like Java's Spring framework.  Instead, you are getting something more like Javascript's expressjs.  That makes it a bit tricky to go through and track down which tower plugins you should be using.- \"How to structure your app\" sorts of guides.  Axum doesn't really force any sort of layout of design, which is good, but it's also not great in that it leaves that actual design up to the beginners imagination.  Something like \"Here's an example of a todo app with multiple users\" would do wonders in showing a recommended layout.  Covering how you should do DI, input validation, error handling, session management, module layout, testing.  All that sort of stuff would be really useful to have/see.\n \nreply",
      "I've enjoyed what I've done with Axum thus far. I ultimately opted to use Leptos on top of it, so I don't really use it directly at this point. But it's neat.For a long time, I used PHP and JS/TS for web projects. Now I'm using Rust with Axum/Tokio/Tower/Hyper (web server), Leptos (SSR using \"Islands\" flag, which also allows WASM generation for front end; JSX-like syntax), and Diesel (ORM and query builder that expects you define your schema using raw SQL). (I also leapt from DB2, MySQL and MariaDB to PostgreSQL)It's heaven.\n \nreply",
      "It's great, isn't it? I'm doing the same for my apps, with Rust as the backend with Axum and Diesel, except I'm using Flutter for the frontend and also flutter_rust_bridge for some Rust crates I want to use directly inside the Flutter frontend.I'm using Flutter as I'm making mobile apps primarily and I think it will take Rust based solutions a long time to get to feature and component parity with Flutter, it is simply a huge task to create a UI framework and component library from scratch, only a company like Google or Apple seem to be able to do so.\n \nreply",
      "How are you liking Leptos? I've been on the fence of trying Leptos vs Dioxus for a new project. They both seem great, but when I look for things like \"charts\" or \"plots\" or other components I don't see much support. Even though I am not a fan of TS I'm not sure if I really want to make those components myself.\n \nreply",
      "Absolutely a game changer. I'm using the same stack (minus Diesel) and I love that if it compiles it almost always works. Not so with JS/TS.With server functions (and of course client/server in the same codebase/language) I also finally get why anyone would be attracted to running JS/TS on the server side.\n \nreply",
      "The only hitch was figuring out how to get server side includes not to break the WASM compilation (the solution was adding #[cfg] and #[cfg_attr] guards around the diesel use and derive rules). Other than that, it just worked - it\u2019s so damn easy!I always thought WASM would be difficult to use. With Leptos, it\u2019s easier than JavaScript.\n \nreply",
      "> I love that if it compiles it almost always worksI'm going to dig in a bit here: What do you mean specifcally by this? It is quite the claim! I suspect it has to do with meaning there is a low likelyhood of crashing, e.g. no type errors at runtime. My skepticism is that that general statement implies more than this.\n \nreply",
      "Is it because the types and memory issues have been sorted out during the compile phase meaning code will \"run\" without crashing?  That doesn't mean the code will work (infinite loops, etc), but it will run, right?I've seen more than one Java program that will compile, but will throw a NullPointerError that gets unhandled.\n \nreply"
    ],
    "link": "https://tokio.rs/blog/2025-01-01-announcing-axum-0-8-0",
    "first_paragraph": "2025202420232022January 01, 2025Happy new year! \ud83c\udf89Today, we're happy to announce axum version 0.8. axum is an ergonomic\nand modular web framework built with tokio, tower, and hyper.This also includes new major versions of axum-core, axum-extra, and\naxum-macros.Here is a small selection of the most notable changes in this release:The path parameter syntax has changed from /:single and /*many to\n/{single} and /{*many}.There are many reasons for this change, but the most important one is that the\nold syntax was not allowing route definitions with leading : or *\ncharacters.This new syntax was introduced with our upgrade to matchit 0.8. It should\nfeel somewhat familiar from the format!() macro, and it's also the syntax\nthat is being used in OpenAPI descriptions. Escaping is done with double\nbraces, so if you want to match a literal { or } character, you can do so\nby writing {{ or }}.We understand that this is a breaking change for basically all axum users, but\nwe believe that it's better to "
  },
  {
    "title": "Supernovae evidence for foundational change to cosmological models (oup.com)",
    "points": 110,
    "submitter": "JumpCrisscross",
    "submit_time": "2025-01-01T15:53:42 1735746822",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=42566748",
    "comments": [
      "When I worked at arXiv one of my coworkers was a fresh astrophysics PhD who was cynical about the state of the field.  He thought that we didn't know what the hell was going on with accretion disks but that a few powerful people in the field created the impression that we did and that there was no dissent because it was so difficult to get established in the field.When I first saw the \u039bCDM model my first impression was that I'd didn't believe it,  it seemed bad enough to have dark matter that we didn't understand (though WIMPs and axions are plausible) but adding equally mysterious and physically unmotivated dark energy made it seem just an exercise in curve fitting.There have been a longstanding problem that the history of the universe and cosmological distance scale haven't made sense.https://medium.com/starts-with-a-bang/the-hubble-tension-sti...When I was getting my PhD in condensed matter physics I was going to the department colloquium all the time and seeing astrophysics talks about how some people thought the hubble constant was 40 km/s/Mpc and others thought it was 80 km/s/Mpc.  With timescape cosmology maybe they were both right.Another longstanding problem in astronomy is that since the 1970s it's been clear we have no idea of how supermassive black holes could have formed in the time we think the universe has existed.  With the JWST there are a flood of results that show the first 500 million years of the universe probably lasted a lot more than 500 million yearshttps://iopscience.iop.org/article/10.3847/2041-8213/ac9b22\n \nreply",
      "On the topic of early black hole growth I saw this released a couple of months ago, an early black hole apparently growing at 40x the Eddington limit 1.5 billion years after the big bang.https://chandra.si.edu/press/24_releases/press_110424.html> A super-Eddington-accreting black hole ~1.5 Gyr after the Big Bang observed with JWSThttps://www.nature.com/articles/s41550-024-02402-9\n \nreply",
      "Correct me if I'm wrong, but the term Eddington limit is a bit misleading as it does not describe some physical rate that cannot be exceeded. Lots of super Eddington objects are known.\n \nreply",
      "Here\u2019s an extended comment by another astrophysicst: https://telescoper.blog/2025/01/02/timescape-versus-dark-ene...The most important bit:> The new papers under discussion focus entirely on supernovae measurements. It must be recognized that these provide just one of the pillars supporting the standard cosmology. Over the years, many alternative models have been suggested that claim to \u201cfix\u201d some alleged problem with cosmology only to find that it makes other issues worse. That\u2019s not a reason to ignore departures from the standard framework, but it is an indication that we have a huge amount of data and we\u2019re not allowed to cherry-pick what we want.\n \nreply",
      "the thing is, this is not really an alternative model.  it's rather actually bothering to do the hard math based on existing principles (GR) and existing observations, dropping the fairly convincingly invalidated assumption of large scale uniformity in the mass distribution of the universe.if anything the standard model of cosmology should at this point be considered alternative as it introduces extra parameters that might be unnecessary.so yeah it's one calculation.  but give it time.  the math is harder.\n \nreply",
      "This has the same number of free parameters as LambdaCDM. Also this result only looks supernovae, i.e. low redshift sources. LambdaCDM is tested on cosmological scales.Very interesting, but \u201cmore work is needed\u201d.\n \nreply",
      "thats not the case, if, as is increasingly speculated, the lambda is not constant over time.  you figure two parameters for linear and three for a quadratic experience\n \nreply",
      "> dropping the fairly convincingly invalidated assumption of large scale uniformity in the mass distribution of the universe.The problem with that is then you need a mechanism that creates non-uniformly distributed mass.Otherwise, you are simply invoking the anthropic principle: \"The universe is the way it is because we are here.\"\n \nreply",
      "Calculation is harder in a world of functionally limitless compute is sort of interesting. Where do we go from here?\n \nreply",
      "Reading this as a layman, it looks like releasing \u039bCDM's cosmological principle [1] reveals the nontrivial temporal effects mass clusters have via general relativity. As a result, there could be empty regions of space in which billions of years more have elapsed than in e.g. a galaxy. This not only changes how we interpret supernova data (the acceleration isn't generally happening, but an artefact of looking through space which is older than our own), but may also negate the need for dark matter (EDIT: dark energy) and the meaning of a single age of our univese.(I'm also vaguely remembering a multi-universe model in which empty space inflates quicker than massed space.)[1] https://en.wikipedia.org/wiki/Cosmological_principle\n \nreply"
    ],
    "link": "https://academic.oup.com/mnrasl/article/537/1/L55/7926647",
    "first_paragraph": ""
  },
  {
    "title": "Duolicious \u2013 Open-source dating app (github.com/duolicious)",
    "points": 51,
    "submitter": "gewgelplex",
    "submit_time": "2025-01-05T22:49:03 1736117343",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=42605740",
    "comments": [
      "Oh no: https://knowyourmeme.com/memes/sites/duolicious-4chan-dating...The Know Your Meme article, linked from the post page, is the best anti-review for this app.\n \nreply",
      "> The Know Your Meme article, linked from the post page, is the best anti-review for this app.Not the 4chan screenshots used as testimonials on the app's own web site?\n \nreply",
      "I like the open source aspect, I've been looking for an ethical dating app for a long time, and based on the README it looks awesome! But then I clicked onto the site, and things did a 180, based on the edgy marketing copy on the landing page I don't think this is the site I'm looking for, as 'normie' as that might make me.> There\u2019s plenty of dating apps out there: Tinder, Bumble, OkCupid, Boo, Hinge. We think they\u2019re all great apps... For normies! But a terminally-online meme-enjoying degenerate like yourself needs something more. That\u2019s why we invented Duolicious!> Duolicious is the dating app that helps you find your Discord-lurking, Reddit-updooting, Nigerian-basketweaving-forum-posting, chronically-online soulmate. Our fun personality quiz helps you meet like-minded people, and shows you a new match for every answer you give, thanks to our fancy matching algorithm.\n \nreply",
      "Unfortunately, I don't think we're going to ever be getting an ethical dating app. It may be ethical as far as not charging users to connect, or not trying to keep users constantly staying single so they are always using and checking the app. Without that \"addiction\" potential, I think even a completely open dating app would fail miserably. If people were able to connect and move on quickly, there would be little reason for the app-creators to continue developing.I say this as someone that has spent the last few years wading through various dating apps, looking for a monogamous relationship. The best luck I've had with dating (after using Tinder, Hinge, Bumble, and Facebook Dating) has been finding local Facebook singles groups, and just chatting. I can be nervous and awkward, but I'm able to fake it in person, and online it's easy for me to have conversations with others about interests.Also, instead of trying to be a \"normie\" (although you didn't say you were doing this, so this may not apply), lean into what makes you unique and try to find the same or something compatible in someone else. Going through apps is not fun, but I have met a ton of different people that I don't think I ever would have interacted with if I hadn't gone through dating apps or chatting with strangers.To be clear, the language isn't \"fun\" for anyone that has dealt with any of the things they mention!\n \nreply",
      "I'm not sure what would constitute ethical versus not ethical exactly, but increasingly I've wondered if some governments will start supporting dating apps, if birthrates decline enough. Is that better than a private corporation app? Maybe or maybe not but it seems like it might change the \"ethical issue landscape\".Or maybe dating apps per se will fade away and dating functionality will just get folded into more general purpose apps and sites.\n \nreply",
      "I define ethical as an app that is designed to do its job as effectively as possible. That is to say, match the most compatible individuals without stupid retention games. The problem is, this isn\u2019t a good business model. I would fully support a state funded dating app (so long as the dating app wasn\u2019t actually controlled by the state because then it would just be weird)\n \nreply",
      "Ethical dating sites are possible and have existed. But they dfintiely can't exist in this current landscape. Like you said, an app who's goal is ultimately to stop people from using the app is not one that will get the funding needed to stand out from all the Match.com shell companies.> lean into what makes you unique and try to find the same or something compatible in someone else.This part is cultural though, and the fact is most people (regardless of gender) are not looking for \"unique\". Quite the contrary. I suppose that is a bit of why the \"normie\" nomenclature is not as far off as you first think.\n \nreply",
      "> If people were able to connect and move on quickly, there would be little reason for the app-creators to continue developing.If an open-source piece of tech is working as advertised, why would its devs continue working on a finished product?\n \nreply",
      "https://alovoa.com/ is open source.We thought for a while to use it to start our own dating up. But it is so hard to get off the ground...\n \nreply",
      "Oooh I like this one much more, I wonder how active it is..\n \nreply"
    ],
    "link": "https://github.com/duolicious",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          Duolicious is the world's most popular open-source dating app (measured by monthly active users). Duolicious has been featured on Mashable and Know Your Meme.The Duolicious app is available on Google Play, iOS and the web.Duolicious has a question bank containing over 2000 thoughtful and unique questions designed to help us gain authentic insight into your personality\u2014But you don't need to answer them all to find your perfect match! Right after your first response, Duolicious shows your best matches so far\u2014And the matches get better with every response you give. The questions are fun and easy-to-answer, while still giving the depth of insight Duolicious needs to match you with the right people. Our question bank covers a huge variety of topics, including values, faith, politics and sexual compatibility.As well as commonly used personality tr"
  },
  {
    "title": "Researchers design wearable tech that can sense glucose levels more accurately (uwaterloo.ca)",
    "points": 357,
    "submitter": "ndrwnaguib",
    "submit_time": "2025-01-05T02:12:13 1736043133",
    "num_comments": 145,
    "comments_url": "https://news.ycombinator.com/item?id=42599189",
    "comments": [
      "> Currently, diabetics must frequently prick their fingers or rely on invasive wearable patches with micro-needles to track their blood-sugar levelsType 1 diabetic here - for what it's worth, CGMs aren't particularly invasive. At least in comparison to the many many years of finger pricking! But a smart watch solution would be cool. (I actually do get my CGM readings on my smart watch, which is really nice!)I know Apple has also worked on this stuff in the past, but from what I remember the accuracy wasn't good enough to be safe for diabetics. I'd be really curious to see accuracy stats on this in comparison to Dexcom and Freestyle CGMs.I would definitely be excited to use something like this, but for me, the biggest quality of life improvements for me will be continued improvements with closed loop CGM + insulin pump systems.\n \nreply",
      "I don't use one or have diabetes but my understanding is that current CGMs measure interstitial glucose levels, which lag blood levels by up to 15 minutes. As a result, I believe those who require accurate spot measurements rather than just overall trends are still recommended to use finger stick tests.In the article, the researcher claims \"No other technology can provide this level of precision without direct contact with the bloodstream\", so it sounds like they're claiming it's better than existing CGMs in a way that might be clinically relevant. Not sure if that's plausible or whether they are directly measuring blood glucose rather than interstitial.\n \nreply",
      "Type 1 here, a 15 min lag is fine. The constant sampling especially overnight and the multiday graphs are what I love about CGM. I've always been in decent but loose control 6.7 to 7.1 A1C (longer term measurement). After a year w CGM I got to 6.5. Now last checkup I'm at 5.9, this ties my record from my first month on Lantus insulin, never repeated in 19 years until now. Also getting numbers on phone and checking number every 15 min while driving are amazing. The stock software for Dexcom and Freestyle are both abysmal. Both refuse to allow silent mode, Dexcom has a hard 6 hours left on sensor uninteruptable alarm, woke me up at 4 am, coustomer service had nothing to say, so Goodbye. I went back to Freestyle their handheld reader is silencable and I use a third party app called Juggluco for my Android phone. Sorry I've survived 42 years on human insulin I don't want software taking over my life w unsilencable alerts. Anyone w less than 10 or 20 years OK, but my brain has extra backup pathways and I'm still functionable down to 50 (very rare), and I can recognize dimished coordination and the emotional shifts that accompany dips. Plus I have life experience to know my low time of day and to watch w exertion.\n \nreply",
      "Not having to pay $50-100/mo for CGM patches would also be nice.\n \nreply",
      "Oh there will be a subscription, don\u2019t worry about that.\n \nreply",
      "But if they want to capture (or create, commercially) the market they\u2019ll probably price it closer to $20 or under.\n \nreply",
      "More likely is a dollar per day for T2 and higher for T1. The differentiator will be non-invasiveness, not price.\n \nreply",
      "Then they will get their lunch eaten when smartwatch / ring / etc companies ship it for free. Probably smarter to go for market share with affordable one-time costs and build revenue from conplementsry goods and services.\n \nreply",
      "Those might be really great for T2 though. I don\u2019t need to know the exact number just a ballpark number to know how I\u2019m doing. Having always had a bad relationship with food, I fall off way too easily without a CGM so for me, those things would be perfect.But also in times where we have the Libre 3 which is so tiny that you legit don\u2019t even notice it, a CGM on your wrist is not worth the loss of accuracy for T1 I guess (assuming your insurance pays for it).\n \nreply",
      "> but for me, the biggest quality of life improvements for me will be continued improvements with closed loop CGM + insulin pump systemsYou might find this interesting: \"A bi-hormonal fully closed loop system\"https://www.inredadiabetic.nl/en/home-english/\n \nreply"
    ],
    "link": "https://uwaterloo.ca/news/media/no-more-needles-tracking-blood-sugar-your-wrist",
    "first_paragraph": "Waterloo researchers design wearable tech that can sense glucose levels for diabetics more accurately than ever beforeImagine shrinking satellite technology that predicts the weather into a device that transmits vital information about the health of the person wearing it.University of Waterloo engineers have achieved this\u00a0technological feat to help people faced with\u00a0chronic health problems such as diabetes monitor their glucose levels.The Waterloo team\u2019s breakthrough addresses the major challenge of creating non-invasive, continuous glucose monitoring, essential for those managing diabetes.Currently, diabetics must frequently prick their fingers or rely on invasive wearable patches with micro-needles to track their blood-sugar levels. But the system designed by Dr. George Shaker, an adjunct associate professor at Waterloo\u2019s Department of Electrical and Computer Engineering, and his colleagues eliminates this need, thereby reducing pain, the risk of infection and improving people\u2019s qual"
  }
]