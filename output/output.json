[
  {
    "title": "Compiling a Lisp: Lambda Lifting (bernsteinbear.com)",
    "points": 56,
    "submitter": "azhenley",
    "submit_time": "2025-08-10T22:35:03 1754865303",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44858892",
    "comments": [
      "If you like Ghuloum's paper, there are three fairly recent compiler books that are inspired by it:https://nostarch.com/writing-c-compiler - Writing a C Compiler by Nora Sandler, language agnostic for the implementation.https://mitpress.mit.edu/9780262047760/essentials-of-compila... - Essentials of Compilation (using Racket) by Jeremy Siekhttps://mitpress.mit.edu/9780262048248/essentials-of-compila... - Essentials of Compilation (using Python) by Jeremy SiekThose last two both have open access versions.reply",
      "The paper itself has been discussed a few times:An Incremental Approach to Compiler Construction (2006) [pdf] - https://news.ycombinator.com/item?id=29123715 - Nov 2021 (10 comments)An Incremental Approach to Compiler Construction (2006) [pdf] - https://news.ycombinator.com/item?id=20577660 - July 2019 (5 comments)An Incremental Approach to Compiler Construction (2006) [pdf] - https://news.ycombinator.com/item?id=13207441 - Dec 2016 (19 comments)An Incremental Approach to Compiler Construction (2006) [pdf] - https://news.ycombinator.com/item?id=10785164 - Dec 2015 (13 comments)Writing a Compiler in 24 Small Steps [pdf] - https://news.ycombinator.com/item?id=1652623 - Sept 2010 (16 comments)An Incremental Approach to Compiler Construction - https://news.ycombinator.com/item?id=1408241 - June 2010 (18 comments)(and also in comments: https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...)reply",
      "The \"lambda lifting\" seems to be referring to section 3.11 \"Complex Constants\" in the linked Ghuloum PDF:Scheme\u2019s constants are not limited to the immediate objects. Using the quote form, lists, vectors, and strings can be turned into constants as well. The formal semantics of Scheme require that quoted\nconstants always evaluate to the same object. The following example must always evaluate to true:    (let ((f (lambda () (quote (1 . \"H\")))))\n      (eq? (f) (f)))\n\nSo, in general, we cannot transform a quoted constant into an unquoted series of constructions as the following incorrect transformation demonstrates:    (let ((f (lambda () (cons 1 (string #\\H)))))\n      (eq? (f) (f)))\n\nOne way of implementing complex constants is by lifting their construction to the top of the program. The example program can be transformed to an equivalent program containing no complex constants as follows:    (let ((tmp0 (cons 1 (string #\\H))))\n      (let ((f (lambda () tmp0)))\n        (eq? (f) (f))))\n\nPerforming this transformation before closure conversion makes the introduced temporaries occur as free variables in the enclosing lambdas. This increases the size of many closures, increasing heap\nconsumption and slowing down the compiled programs. Another approach for implementing complex constants is by introducing global memory locations to hold the values of these constants. Every complex constant is assigned a label, denoting its location. All the complex constants are initialized at the start of the program. Our running example would be transformed to:    (labels ((f0 (code () () (constant-ref t1)))\n             (t1 (datum)))\n      (constant-init t1 (cons 1 (string #\\H)))\n      (let ((f (closure f0)))\n        (eq? (f) (f))))\n\nThe code generator should now be modified to handle the data labels as well as the two internal forms constant-ref and constant-init.reply",
      "The idea is to move variables from the body of the function to the argument list and rewrite the call sites to match.That decreases the size of the closure (and increases the size of the code, and of however you're passing arguments).Do it repeatedly though and you end up with no free variables, i.e. no closure to allocate. Hence the name, the lambda (closure) has been lifted (through the call tree) to the top level, where it is now a function (and not a lambda, if following the usual conflating of anonymous function with allocated closure).Doesn't work in the general case because you can't find all the call sites.reply"
    ],
    "link": "https://bernsteinbear.com/blog/compiling-a-lisp-12/",
    "first_paragraph": "\nfirst \u2013 previous\nI didn\u2019t think this day would come, but I picked up the Ghuloum\ntutorial (PDF) again and I got a little bit further. There\u2019s just\none caveat: I have rewritten the implementation in Python. It\u2019s available in\nthe same repo in\ncompiler.py.\nIt\u2019s brief, coming in at a little over 300 LOC + tests (compared to the C\nversion\u2019s 1200 LOC + tests).I guess there\u2019s another caveat, too, which is that the Python version has no\nS-expression reader. But that\u2019s fine: consider it an exercise for you, dear\nreader. That\u2019s hardly the most interesting part of the tutorial.Oh, and I also dropped the instruction encoding. I\u2019m doing text assembly now.\nWomp womp.Anyway, lifting the lambdas as required in the paper requires three things:We have two forms that can bind variables: let and lambda. This means that\nwe need to recognize the names in those special expressions and modify the\nenvironment. What environment, you ask?Well, I have this little LambdaConverter class.We keep the same labels dic"
  },
  {
    "title": "Try and (yale.edu)",
    "points": 417,
    "submitter": "treetalker",
    "submit_time": "2025-08-10T13:32:13 1754832733",
    "num_comments": 220,
    "comments_url": "https://news.ycombinator.com/item?id=44855079",
    "comments": [
      "At first glance, I thought this was some new TC39 JavaScript syntax proposal.This is a cool site. I thought I'd look for a page about my favorite syntactic phenomenon, \"what all\", and not only did I find it, but also they changed the \"Who says this?\" section header to \"Who all says this?\"https://ygdp.yale.edu/phenomena/what-allreply",
      "Possibly-interesting comparison: in Japanese, the way to talk about trying to do some verb-phrase X, is \"X\u3066\u898b\u308b\" \u2014 which is usually literally translated as \"we'll try [X]ing\", but which breaks down into \"[verb-phrase X in present tense] [the verb \"to see\" in whatever tense you mean.]\"Which means that the construction can be most intuitively framed (at least by an English speaker) as either \"we'll see [what happens when] we [X]\"... or, more relevantly, \"we'll try [X] and see [what happens/how it goes].\" Or, for short: \"we'll try and [X].\"reply",
      "It's even better. The \"X-te\" (X\u3066) is technically not X in present tense, it is specifically X in the te-form (\u3066 is read \"te\").The te-form has a bunch of different uses, but in the case of \"verb-te verb\", if the second verb is not one of a list of special verbs (of which miru (\u898b\u308b, to see) is one), X-te Y normally means \"X and Y\". For example, yorugohan o tsukutte taberu (\u591c\u3054\u98ef\u3092\u4f5c\u3063\u3066\u98df\u3079\u308b) means \"(to/I/we/you/...) make dinner and eat it\": yorugohan is dinner, the \"o\" is a particle marking the direct object, tsukuru means to make (becomes tsukutte in the te-form) and taberu means to eat. (The first word in English is ambiguous because grammatical subjects are usually optional in Japanese, plus its verbs are not inflected for person or number.)For a number of verbs, however, if they are in the second position, the phrase gets a special meaning. If it's miru, e.g. tsukutte miru, it means \"to try to make\" \u2014 or perhaps more aptly, \"to try and make\". If it's iku (\u884c\u304f, to go), it means \"to go X-ing\": tabete iku (where taberu (to eat) -> tabete in the te-form) is \"to go to eat [something]\", or perhaps: \"to go and eat [something]\".Not all such special verbs correspond to English pseudocoordination though; a common one is shimau (the dictionary says \"to finish / to stop\", but it's uncommon in bare form), where e.g. tabete shimau means \"to finish eating\" or \"to end up eating\" / \"to eat accidentally\" depending on context.The analogy between English and Japanese here is likely coincidental, but it's amusing nevertheless.reply",
      "This is a nice explanation; I wish that duolingo hadn't removed their user comment/explanation section, which used to contain similar (though not always correct, which is probably part of why they removed them.)reply",
      "Pro tip: Duolingo is a game and basically a dead end for properly learning a language. If you want to really learn, you need to build intuition, and that only comes from huge amounts of level-appropriate input. Find yourself some good native language podcasts that are targeted at language learners and native reading material. Search for \"Refold\" for a better strategy (no affiliation, it's just awesome), and make sure that whatever you do, you enjoy it. Language learning is a marathon, the fun is in the journey, not just the destination.reply",
      "Plenty of people enjoy Duolingo. And I wouldn\u2019t say it\u2019s a dead end any more than simple picture books or a total beginners class. Will it turn you into a fluent speaker? No, so what.reply",
      "> No, so what.Because it promotes itself as a platform to learn fluency. That\u2019s why it\u2019s important to recognize its limitations.reply",
      "Funnily enough, this has resulted in people saying things like \"\u898b\u3066\u307f\u307e\u3057\u3087\u3046\" and \"\u898b\u3066\u307f\u3066\u304f\u3060\u3055\u3044\", which confused me at first. But I suppose this is like non-native English speakers being confused by the extra \"do\" in phrases like \"I already did do my work.\"reply",
      "Hungarian works the same, well I guess the few agglutinative languages do share this elementreply",
      "> Hungarian works the same, well I guess the few agglutinative languages do share this elementNot sure what you mean. In Hungarian, the verb meaning \"to try\" is (meg)pr\u00f3b\u00e1lni, which does not mean \"to see.\" Its argument is typically given as an infinitive verb, which would never be translated using the pseudocoordination described above, and there is no related form that would be translated as \"and\".reply"
    ],
    "link": "https://ygdp.yale.edu/phenomena/try-and",
    "first_paragraph": "\n\t\t(Dr. Dre)\n\t\n\tTypically, try can be followed by three kinds of phrases: a noun phrase (1a), an infinitival verb phrase with to (1b), or a verb phrase with -ing (1c).\n\n\t\t1)\ta. I'll try the salad.\n\t\n\t\tb. I'll try to eat this horrible salad.\n\t\n\t\tc. I'll try adding vinegar to the salad, to improve the taste.\n\t\n\tHowever, try can also combine with the conjunction and, followed by a bare verb form:\n\n\t\t2)\tI\u2019ll try and eat the salad.\n\t\n\tThis usage is very similar in meaning to try to, if not identical, but is deemed prescriptively incorrect (Routledge 1864:579 in D. Ross 2013a:120; Partridge 1947:338, Crews et al. 1989:656 in Brook & Tagliamonte 2016:320). In the next few sections, we will see that it has a number of interesting properties.\n Who says this?\nSyntactic Properties\nOther instances of pseudocoordination\nReferences\n\nTry and is described as more prevalent in British English than American English, but is common in both varieties (Hommerberg & Tottie 2007). Brook & Tagliamonte (2016) s"
  },
  {
    "title": "GPT-OSS vs. Qwen3 and a detailed look how things evolved since GPT-2 (sebastianraschka.com)",
    "points": 303,
    "submitter": "ModelForge",
    "submit_time": "2025-08-10T15:06:07 1754838367",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=44855690",
    "comments": [
      "Qwen3 is substantially better in my local testing. As in, adheres to the prompt better (pretty much exactly for the 32B parameter variant, very impressive) and is more organic sounding.In simplebench gpt-oss (120 bn) flopped hard so it doesn't appear particularly good at logical puzzles either.So presumably, this comes down to...- training technique or data- dimension- lower number of large experts vs higher number of small expertsreply",
      "Qwen3 32B is a dense model, it uses all its parameters all the time. GPT OSS 20B is a sparse MoE model. This means it only uses a fraction (3.6B) at a time. It\u2019s a tradeoff that makes it faster to run than a dense 20B model and much smarter than a 3.6B one.In practice the fairest comparison would be to a dense ~8B model. Qwen Coder 30B A3B is a good sparse comparison point as well.reply",
      "> GPT OSS 20B is a sparse MoE model. This means it only uses a fraction (3.6B) at a time.They compared it to GPT OSS 120B, which activates 5.1B parameters per token. Given the size of the model it's more than fair to compare it to Qwen3 32B.reply",
      "If I had to make a guess, I'd say this has much, much less to do with the architecture and far more to do with the data and training pipeline. Many have speculated that gpt-oss has adopted a Phi-like synthetic-only dataset and focused mostly on gaming metrics, and I've found the evidence so far to be sufficiently compelling.reply",
      "this is exactly why strongest model gonna lose out to weaker models if the later ones have more datafor example, i was using deep seek webui and getting decent on point answers but it simply does not have latest data.So, while Deep Seek R1 might be better model than Grok3 or even Grok4, it not having access to \"twitter data\" basically puts it behind.Same is case with OpenAI, if OpenAI has access to fast data from github, it can help with bugfixs which claude/gemini2.5 pro can't.model can be smarter but if it does not have the data to base its inference upon it's useless.reply",
      "That would be interesting. I've been a bit sceptical of the entire strategy from the beginning. If oss was actually as good as o3 mini and in some cases o4 mini outside benchmarks, that would undermine openai's api offer for gpt 5 nano and maybe mini too.Edit: found this analysis, it's on the HN frontpage right now> this thing is clearly trained via RL to think and solve tasks for specific reasoning benchmarks. nothing else.https://x.com/jxmnop/status/1953899426075816164reply",
      "The strategy of Phi isn't bad, it's just not general.  It's really a model that's meant to be fine tuned, but unfortunately fine tuning tends to shit on RL'd behavior, so it ended up not being that useful.  If someone made a Phi style model with an architecture that was designed to take knowledge adapters/experts (i.e. small MoE model designed to get separately trained networks plugged into them with routing updates via special LoRA) it'd actually be super useful.reply",
      "The Phi strategy is bad. It results in very bad models that are useless in production, while gaming the benchmark to appear like it is actually able to do something. This is objectively bad.reply",
      "I like the idea of having a _HIGHLY_ unopinionated base model that's just good at basic logic and instruction following that I can fine tune to my use case.  Sadly, full fine tuning tends to make models derpy, and LoRAs are limited in terms of what they can achieve.reply",
      "That seems unrelated? I think we are talking about past each other. Phi was trained on purely synthetic data derived from emulating the benchmark suite. Not surprisingly, this resulted in state of the art scores. And a model that was 100% useless at anything other than making the benchmark number go up.reply"
    ],
    "link": "https://magazine.sebastianraschka.com/p/from-gpt-2-to-gpt-oss-analyzing-the",
    "first_paragraph": ""
  },
  {
    "title": "1910: The year the modern world lost its mind (derekthompson.org)",
    "points": 182,
    "submitter": "purgator",
    "submit_time": "2025-08-10T20:48:46 1754858926",
    "num_comments": 136,
    "comments_url": "https://news.ycombinator.com/item?id=44858154",
    "comments": [
      "During the early industrial revolution people used to present themselves for medical help after complaining that the incessant repetitive action and rotation of engines (e.g. beam engines) hundreds of miles away from them was sending them vibrations which disturbed their sleep. Of course they only started having this problem after reading about such contraptions in newspapers.reply",
      "I know a consulting acoustical engineer who tracks down noise problems for companies and individuals. He goes on about the difficulty of even finding the source of low-frequency noise because of distance and vague directionality. In an extreme case, a rural family was tormented by a constant throbbing sound that turned out to be from a utility station 5 miles away.reply",
      "Loud low sounds can travel very far, especially at night when it\u2019s quiet. I can hear freight trains at night that are over 5 miles away. It wouldn\u2019t surprise me if the beam engine was louder than a freight train, and that nights were even quieter in the early 20th century. Hundreds of miles is a bit much though.reply",
      "Something similar happened in more modern times with a cell tower, although it's over a decade ago now: https://gizmodo.com/locals-complain-of-radio-tower-illness-t...reply",
      "Various double-blind studies involving cell-towers also show no effect. Of folks claiming some kind of electromagnetic hypersensitivity, the greatest sensitivity seems to be whether they can see if a power-light is on or not.Some may have real symptoms, but the cause is something else inside or outside them.reply",
      "There is a dedicated group of people who believe any electromagnetic emission is affecting them negatively.  Searching on \"electromagnetic free zones\" is quite the rabbit hole.  And there's way more to them than the \"5G is mind control forced on us by the Illuminati for the New World Order\" crowd.reply",
      "They definitely should not own one of these then: https://somasynths.com/ether/. But it is lots of fun for me.reply",
      "For examples of other books that show how much technology rapidly changed the world, I can't recommend \"The Victorian Internet\" [0] highly enough. (It describes the impact of the telegraph).I remember reading the book in the mid to late 2000s and it felt so \"current\" in describing events of the day e.g.- local newspapers were basically crushed by \"international news\" that arrived immediately- the rate of commerce rapidly accelerated as people could communicate instantly around the world- financial markets were impacted by the \"low latency trading\" of the day thanks to financial news being sent via telegraph.- there is even a section about lawyers debating if contracts and marriages could be signed over the telegraph (like this on in particular as this was a debate in the early ecommerce days)I was then shocked to find that it has been published in the 1990s. Really is a reminder that \"new\" technologies are often just updated versions of old technologies.0 - https://amzn.to/4frEGyC(NOTE: the link above takes you to a later edition)reply",
      "If you have children, I am often surprised how they seem to think that the previous generation was stone age. Particular example is that my daughter was surprised I would give orders to my broker via fax, and that the latency was practically the same they get on the free tiers of their online 2020s bank (this is France). My trusty old ThinkPad, which still boots as if 30 years hadn't passed, still has all such digitalized sent/received faxes I did in the 90s..reply",
      "Children in general have a very hard time grasping the idea that their parents' lives resembled their own at all. For another example, look how every generation of teenagers, without fail, thinks they are the first people in the world to invent having sex for fun. I myself didn't understand how my parents used to easily catch me in most of my attempts to get away with trouble, until I realized (as an adult) that they caught me so easily because they tried the same sorts of things as kids themselves. It's just human nature, I guess.reply"
    ],
    "link": "https://www.derekthompson.org/p/1910-the-year-the-modern-world-lost",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Bolt \u2013 A super-fast, statically-typed scripting language written in C (github.com/beariish)",
    "points": 141,
    "submitter": "beariish",
    "submit_time": "2025-08-10T17:53:09 1754848389",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=44856935",
    "comments": [
      "I love the concept -- I've often wished that lean languages like Lua had more support for static typing, especially given the potential performance benefits.I also love the focus on performance.  I'm curious if you've considered using a tail call design for the interpreter.  I've found this to be the best way to get good code out of the compiler: https://blog.reverberate.org/2021/04/21/musttail-efficient-i...  Unfortunately it's not portable to MSVC.In that article I show that this technique was able to match Mike Pall's hand-coded assembly for one example he gave of LuaJIT's interpreter.  Mike later linked to the article as a new take for how to optimize interpreters: https://github.com/LuaJIT/LuaJIT/issues/716#issuecomment-854...Python 3.14 also added support for this style of interpreter dispatch and got a modest performance win from it: https://blog.reverberate.org/2025/02/10/tail-call-updates.ht...reply",
      "I did experiment with a few different dispatch methods before settling on the one in Bolt now, though not with tailcalls specifically. The approach I landed on was largely chosen cause it in my testing competes with computed goto solutions while also compiling on msvc, but I'm absolutely open to try other things out.reply",
      "You may be interested in Luau, which is the gradually-typed dialect of Lua maintained by Roblox. The game Alan Wake 2 also used it for level scripting.reply",
      "I see lua, do you know terralang?reply",
      "I like 99% of this, and the thing I don't like is in the very first line of the example:> import abs, epsilon from mathIMHO it's wrong to put the imported symbols first, because the same symbol could come from two different libraries and mean different things. So the library name is pretty important, and putting it last (and burying it after a potentially long list of imported symbols) just feels wrong.I get that it has a more natural-language vibe this way, but put there's a really good reason that most of the languages I know that put the package/module name first:    import packageName.member; // java\n    from package import symbol; # python\n    use Module 'symbol'; # perl\n    \nWith Typescript being the notable exception:    import { pi as \u03c0 } from \"./maths.js\";treply",
      "Also autocomplete.Though I almost never manually type out imports manually anymore.reply",
      "I really like the way Elm does it, from \"wide\" (package) to \"narrow\" (symbol). I suspect this also helps language server implementation.See https://guide.elm-lang.org/webapps/modules (scroll down to \"Using Modules\") for examplesreply",
      "Do you think approaching the way typescript does it for Bolt is a reasonable compromise here? Bolt already supports full-module renames like    import math as not_math\n\nSo supporting something along the lines of    import abs as absolute, sqrt as square_root from math\n\nWould be farily simple to accomplish.reply",
      "Or: `import math with abs as absolute, sqrt as square_root`reply",
      "According to the Programming Guide, it supports aliases for imports\"In case of conflict or convenience, you can give modules an alias as well.\"reply"
    ],
    "link": "https://github.com/Beariish/bolt",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        High-performance, real-time optimized, and statically typed embedded language implemented in C.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A lightweight, lightning-fast, type-safe embeddable language for real-time applications.Bolt only depends on the C standard library as well as libm on Unix-based systems.\nSome standard library modules include things like file and system IO, but these can be disabled easily.\nBy default, Bolt sets up an environment that uses malloc/realloc/free, but this is also easy to configure.\nBolt also embeds my other library picomatch for regex parsingThe bolt-cli program provides a very consice example of how to embed bolt an an application, see the Bolt embedding guide for more details.The examples folder contains a few short e"
  },
  {
    "title": "Fight Chat Control (fightchatcontrol.eu)",
    "points": 801,
    "submitter": "tokai",
    "submit_time": "2025-08-10T16:50:34 1754844634",
    "num_comments": 232,
    "comments_url": "https://news.ycombinator.com/item?id=44856426",
    "comments": [
      "Please also fight mandatory age verification with prison sentences. The European Parliament has already voted in favor of a law that mandates age verification for pornography with a one year prison sentence. It was included as a last minute amendment into this bill [1]. See \"Amendment 186\". It has been completely missed by news organizations and even interest groups.The full accepted article reads: \"Disseminating pornographic content online without putting in place robust and effective age verification tools to effectively prevent children from accessing pornographic content online shall be punishable by a maximum term of imprisonment of at least 1 year.\"It's not law yet, as the first reading is now sent back to the Council of the European Union, but I don't think it's very likely it will get a second reading.[1] https://www.europarl.europa.eu/doceo/document/TA-10-2025-011...reply",
      "Maximum of at least one year? Is there some kind of award for how nonsensical a law can be?reply",
      "Member states will implement this into national law. So in the case they will need to implement a maximum of one year or more (but not less). The final law as applied by a judge will just read \"punishable by a maximum of [i.e.] fourteen months\".reply",
      "> maximum of one year or moreIf the max is one year, it can't be more?reply",
      "It sounds like it's \"the maximum penalty must be at least 1 year\", as in \"your member state can't enact a law where the maximum penalty is less than 1 year\".At least that's how I read it, but it's confusing.reply",
      "This is correct. But the larger point is that even 1 minute of jail time for such \"crimes\" is unacceptable.reply",
      "So it\u2019s a minimum maximum.reply",
      "The maximum value in each instance must be at least one year.reply",
      "While this is a specifically awful article, for obvious reasons, I find the idea of encoding specifics on carceral terms into any EU-level directive a bizarre overstep.reply",
      "That's not only asinine but also poorly worded. How is this getting approved?reply"
    ],
    "link": "https://fightchatcontrol.eu/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Engineering.fyi \u2013 Search across tech engineering blogs in one place (engineering.fyi)",
    "points": 282,
    "submitter": "indiehackerman",
    "submit_time": "2025-08-10T13:44:05 1754833445",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=44855157",
    "comments": [
      "This is great. Would be good if you add RAMP also, have found the engineering blog useful. https://engineering.ramp.com/reply",
      "Shameless plug, but hopefully relevant enough: my directory and search engine for personal blogs[1] indexes over 1000 RSS feeds, and naturally lots of them are about engineering and software development. Full-text search is implemented with Typesense, and there are also \"related\" recommendations for each post, example [2].1. https://minifeed.net/2. https://minifeed.net/items/n1HZYMDEKyrareply",
      "Looks really nice! Any plan to add social aspect like comments, likes and such?reply",
      "I'm building something similar with a bit more of a social angle (has comments, likes, and reposts) at lynkmi.com. If you sign up to the waitlist it's a very very short wait!reply",
      "Thought about it, but not sure yet. Not too many user yet for that sort of thing.reply",
      "Can we add / suggests sites?reply",
      "Sure, here: https://minifeed.net/suggestreply",
      "I kind of miss the RSS days when you just had your own news/blog aggregator without the annoyance of Substack, Medium or anything else.reply",
      "Only 16 companies - quite sparse. May I ask to add my blog if possible? https://clickhouse.com/blog?category=engineeringreply",
      "Just getting started but will definitely add to the list!reply"
    ],
    "link": "https://engineering.fyi/",
    "first_paragraph": "Latest software engineering articles, tutorials, and insights from Google, Meta, OpenAI, and more"
  },
  {
    "title": "One Million Screenshots (onemillionscreenshots.com)",
    "points": 120,
    "submitter": "gaws",
    "submit_time": "2025-08-10T20:30:34 1754857834",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=44858067",
    "comments": [
      "This just makes me realize that entirety of the internet has just become a gateway to sell you something.reply",
      "This is a neat visualization. It makes me want to build something like this with actual screenshots (scraping from places like old forums, image hosting sites, etc.) rather than web page renderings.One of my most prized possessions is my collection of personal screenshots -- I've managed to save basically every screenshot I've taken over the past ~20 years. It's very nostalgic to put them on shuffle and see how my desktop has changed over time, remember what random thing I was working on, etc.Could be cool to extend the concept beyond one user.reply",
      "Same here. It sounds like you even started when I did, ca. 2006. Starting from the blackberry era to my current pixel I've tried to do something similar with my cell phones, but I never usually program in that environment so I never got it off the ground. When LLMs got good a couple years ago getting a screenshot task up and running on my android was one of the first things I tried, but it's been a pain. Apparently Android has been putting in guards against that type of application for security/privacy reasons.reply",
      "I have an Android, and use the free Tasker app to automatically take a screenshot of my active phone screen every 19 minutes. It takes only a few minutes to set up the Tasker script.I have vague plans to do something with these one day. But until then, I hoard!reply",
      "I screenshot all new sites I visit. A UI interaction catches my attention, I screenshot.\nMy files system is 60% images. It's an habit.As a self-taught software dev; it helped me hone good design skills and also off topic - I poke around a lot when I visit certain websites to see which technologies they are built with. Maybe it was me testing js scripts or verifying the API/Object properties of certain functions - the habit stuck haha.Dey wellreply",
      "Please publish those screenshots somewhere, guys. They're a part of history, and we don't have enough of them.reply",
      "just started my collection 3 years ago. it feels more nostalgic and personal than my phone's photo collection ;)reply",
      "This really makes clear how boring web design has become. 99% of websites use the same standard layout, there's almost nothing distinct or exciting about any of the designs. I remember web design being an art form, with books being printed with the best designs... I'd visit brand websites just to look at the design itself, even if I wasn't interested in what they were selling.Of course not all is bad, but I'd love to see some creativity again, it seems like almost no one dares to break the norm anymore.reply",
      "I like that we are stagnating. One of the things that took us away from the early content-focused days of the web is when every business had to get their brochures online, and every designer had to make their mark with how creative they could be. It vastly threw off the signal to noise ratio of web sites, and it delayed good UX for at least a decade because everyone re-invented menus and buttons on every web site.Don't get me wrong. I like creativity. I am an artist, even have a degree in Fine Arts. But there are times to innovate, and there are times to just make things work. Web UX needs to just work.reply",
      "Yeah 90% of websites are just informative \u2026 why would they need to be creative ?reply"
    ],
    "link": "https://onemillionscreenshots.com/?q=random",
    "first_paragraph": ""
  },
  {
    "title": "Diffusion language models are super data learners (jinjieni.notion.site)",
    "points": 140,
    "submitter": "babelfish",
    "submit_time": "2025-08-10T16:04:05 1754841845",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44856101",
    "comments": [
      "I wonder how much of this is due to Diffusion models having less capacity for memorization than auto regressive modelsThe auto regressive models consistently show better loss for the same number of training tokensI find a lot of the conclusions compelling but I would\u2019ve loved to see more epochs of training on the 1B model with a 10B dataset, as that model was showing epoch over epoch improvementsreply",
      "> I wonder how much of this is due to Diffusion models having less capacity for memorization than auto regressive modelsDiffusion requires more computation resources than autoregressive models, compute excess is proportional to the length of sequence. Time dilated RNNs and adaptive computation in image recognition hint us that we can compute more with same weights and achieve better results.Which, I believe, also hint at the at least one flaw of the TS study - I did not see that they matched DLM and AR by compute, they matched them only by weights.reply",
      "Do you have references on adaptive methods for image recognition?reply",
      "I don't have an exact reference but there are a lot more hints that evidence the claim (compute more with same weights). In fact, I wouldn't even call them hints since they aren't subtle at all. For one, animal brains are perfect examples of this. But in the ML space, we could think of this purely from the mathematical perspective.I think it might be confusing because neurons are neurons right? And they can only hold so much memory, so what's the difference? Well, that difference is architecture and training.Let's think about signals for a moment and to help understand this, let's move to small dimensions[0]. Like 2D or 3D. (I'll use 3D, but you'll see why this can still ruin visualization) We're talking about universal approximates, so we can think of these as finite length strings, but have fixed end points. Our goal is then to untangle these strings. Oh no, this bundle has a knot! We can't actually untangle this string just by stretching. We also have a rule that we can't cut and glue things. We'd be stuck if we didn't have a trick up our sleeves. We can move into a higher dimension and untangle these strings there[1]. We'll need at least 2N-D. To the flatlander this will look like a cut, but it isn't.The reason this needs to be understood is because we need to know where we get those dimensions. It is through architecture and training. But let's just think about that architecture. When we're learning these relationships we need to have the capacity to perform these higher dimensional movements, but once we already uncover the relationships we don't necessarily need to. The relationship it depends on the dimensionality of the relationship itself, not the data.This is true for all models and is fundamentally why things like distillation even work. It is also why that FFN layer post attention in the transformer needs to project into a higher dimension before returning (typical is 4x and I think you can reason why that gives more flexibility than 2x). Also related to the latent manifold hypothesis.If you ever wondered if math is useful to machine learning, I hope this gives some motivation to learn more. You don't need math to build good models, but even a little math goes a long way to help make better models.[0] Note, we're doing a significant amount of simplification here. There's a lot of depth and complexity to all of this but I think this will be sufficient to point anyone in (mostly) the right direction.[1] Think about a Klein bottle. In  4D it has a single surface. But the 3D projection of this shape makes it look like it is intersecting itself. Unfortunately we can't really visualize the 4D version :(reply",
      "> as that model was showing epoch over epoch improvements\n\nBoth of them were showing improvements. I agree with you that I'd like to see more, but I'm not sure more would significantly change the argument (which is a lot about how metrics aren't straight forward). Especially since the 96B token experiment shows.IN FACT, those results are so similar I had to open them up in GIMP to align and spot the differences. Now I'm actually not convinced there wasn't a mistake. There are differences, just very minor. Harder to tell with the AR model because scale, but in the diffusion you can see a little bump in the second one right before the concavity change at the end. There some more bumps in the AR model earlier on that help show differences too, but the fact that the envelopes are nearly identical is... suspicious. I'm not claiming maliciousness because even if a mistake these things are so easy to make that they are common. I'm not even convinced there is a mistake, but it warrants extra thinking.That said, money is finite and these are quite computationally heavy. Author looks to be a research fellow and so I'm assuming not backed by big tech.reply",
      "> The auto regressive models consistently show better loss for the same number of training tokensI thought bi-directional transformers (non auto-regressive) show less loss than autoregressive for the same amount of training tokens.reply",
      "> During inference, generating sequences ranging from 16 to 4096 tokens incurs a 16\u00d7 to 4700\u00d7 increase in FLOPs compared to AR baselines.I wonder why the increase in FLOPs has such a wide spectrum? Naively, I'd have expected the FLOPs to increase linearly with the number of tokens. OTOH, it sort of makes sense because because diffusion models are not autoregressive, as their name suggests.reply",
      "My guess is that autoregressive models can use Key Value (KV) caching to eliminate most of the FLOPs inside the self-attention block. Can't use KV caching inside diffusion (because it's not a causal model) but they sell this as a win anyway because they believe it leads to better reasoning.reply",
      "Results probably just indicate that the ar baseline is fuckedreply",
      "This is interesting but I'm not sure some of the claims can be made without some more information. Terms like \"downstream task\", \"in/out of distribution\" are frequently used in the literature to mean many different things[0] and it is hard to know which one you mean from context. As a reader I *cannot know* what is in-distribution or not if I have no notion of what the training data[1] is. Consequently, I also can't know what downstream tasks are.Though I'm very confused by this  > This phenomenon persists for both in-domain and out-of-domain training data.\n\nWhat does it mean for training data to be \"out-of-domain\"? The domain is any valid input into your function. Was this intended to be distribution? I'd still be a bit confused by that because it makes it sound like you're talking about training and validation data, both of which are in distribution.  > Is validation loss a good metric for AR and DLM\n\nIn academic settings, does anyone seriously believe that the answer would be yes? I would be extremely concerned if people honestly believed that you could use loss as a strong indicator for comparing two different architectures[2]. These losses are not measuring the things we want to measure, they are proxies of them. The architectures themselves are a big part of forming that loss landscape. This would be a fine comparison if the metric were not a proxy but since it it then it isn't reliable unless we know what the divergence is[3]. This is all fine, but to advance as a field we need to remember what we don't know.Overall, I'm still not sure what is meant by \"Super Data Learners\".It seems like this is counted by information per parameter? I do think there is good discussion in the \"causal\" attention vs the free-form attention of diffusion, but I think there are also some potential oversteps in the conclusions here. A lower triangular matrix is still full-rank, so there is high representation power here, though it is correct that the free form has more (even when including the permutation and the untangling via the FFN layer in the transformer). I think if this part can be highlighted more and more time is spent on explaining then a much stronger case can be made. But I think some additional analysis is needed to determine if this is a diffusion vs transformer thing or triangular attention vs full rank attention thing. From a mathematical perspective the second question can be answered much more easily, but then there is a larger question about training these things because the problem of training free-form matrices is that they are... well... free form. There's actually some good discussions about this in the Normalizing Flow literature as they work through a similar problem of representation power and training/computational efficiencies. I think this work has the potential to open up a larger discussion for talking about the representation power of different architectures. Which, IMO, that is a really important topic that we need to discuss these days. Though I'm biased since I work on neural architectures.Just for fun ;)  Reviewer 2:\n  Rating: 4: Borderline accept\n  Confidence: 4: You are confident in your assessment, but not absolutely certain.\n  Limitations: I think this is a sufficient work but with better clarity and some additional analysis (actually do  \u0336t\u0336h\u0336e\u0336o\u0336r\u0336e\u0336t\u0336i\u0336c\u0336a\u0336l\u0336 mathematical analysis ;) I think it could be an excellent work and have much more impact than it has in its current form. There is much more to be said, but hey, we're on HN and this last part is being done half jokingly. \n\n[0] Let's say you train on wikipedia and reddit and just train as entropy of next token. Is coding out-of-distribution? Arguably it isn't because there are code samples in both of those datasets. It is not even clear if this is OOD by task. It is even unclear if we strip out things we can identify as code as we aren't necessarily stripping out the discussion of code in natural language. We are, after all, talking about learning in extremely high dimensional spaces and so these 'little nuances' are rather critical in determining what is actually being done. This is deeply related to the 'black box' nature of all of this. As a clear counter, I don't think there is ambiguity when training on Shakespeare that there is ambiguity that coding tasks are OOD. I also think if you strip literal code from reddit and wiki we could say this task is at least not within the main distribution.[1] Am I understanding correctly that these are the same as the referenced [2,3]? Put that experimental setting section up. I want to look backwards for this type of information, not forward. Because looking backwards I'll have a good idea of where I need to go and probably got some of that information before I start asking lots of questions.[2] I suspect many people do and I do have this extreme concern. So I actually appreciate this being included.[3] Which we can't calculate. After all, we're not using these proxy metrics for (just) computational efficiency, we are using them because we have no formal (mathematical) definition of our true objective metrics. We have no formal definition of \"human like language\" or \"correct code given human language inputs\".reply"
    ],
    "link": "https://jinjieni.notion.site/Diffusion-Language-Models-are-Super-Data-Learners-239d8f03a866800ab196e49928c019ac",
    "first_paragraph": ""
  },
  {
    "title": "Battery charge limiter for Apple Silicon MacBook devices (github.com/actuallymentor)",
    "points": 49,
    "submitter": "rahimnathwani",
    "submit_time": "2025-08-07T15:31:42 1754580702",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=44825801",
    "comments": [
      "A huge advantage of AlDente over this is the \"sailing\" feature. I have mine configured to stop charging at 80%, but then only start charging again when it drops to 50%. It's ideal for preventing lots of very short charging sessions. (This is also an ideal pattern for charging EVs.)It also has a \"calibrate\" feature which goes through a 100 -> 10 -> 100 cycle which teaches the battery firmware what the actual capacity is now. Useful to run every month or two.My Air battery is three years old and has 99% health because of using these features.reply",
      "The cli docs say this:  battery calibrate\n    calibrate the battery by discharging it to 15%, then recharging it to 100%, and keeping it there for 1 hourreply",
      "Well that's good. AlDente can automatically schedule it, which is convenient.reply",
      "The FAQ answers why this exists when macOS has a similar built-in feature:> Optimized Charging, a feature that is built into MacOS, aims to ensure the longevity and health of your battery. It does so by \"delaying charging the battery past 80% when it predicts that you\u2019ll be plugged in for an extended period of time, and aims to charge the battery before you unplug,\" as explained in Apple's user guide.> Additionally, Optimized Charging uses machine learning to decide when the battery should be held at 80%, and when it should become fully charged. If your Mac is not plugged in on a regular schedule, optimized charging will not work as intended.> This app is a similar alternative to Optimized Charging, giving the user control over when it is activated, what percentage the battery should be held at, and more.reply",
      "We've literally had configurable charge levels on ThinkPads since the time they were still owned by IBM over 20 years ago, yet Apple still can't figure out to provide such an option 20 years later?Their whole ML thing is super annoying.  Basically, it means you can never disconnect your Mac from your USB-C monitor, lest it immediately charge to 100% upon a reconnect, and discharge back to 80% only a few days after keeping it at 100%.reply",
      "Yeah I have found my MBP at 100% far too often, every now and again I peak and it says \"holding charge\".I don't leave my laptop plugged in 100% of the time, however it is plugged in ~70% of the time and I never discharge it that much when it is unplugged. So this little app is perfect for me.Seems Apple still has work to do on their algorithm, it could easily keep it at 80% and I would never get below 20%.reply",
      "I have the same frustration. The built in Apple algorithm is far too conservative. The `batt` tool has solved this for me now.iPad OS on recent iPads has a dead simple \"limit charge to 80%\" option in system settings. MacOS should just have the same feature.I also limit my iPhone's charge by using shortcut automations and a smart power plug. It just turns the plug off when charge exceeds 80% and on when it drops below 75%.  Not ideal but I think still better for battery life than having it sit at 100%. (lmk if I'm wrong!)reply",
      "Sounds annoying, I would much rather just have it be configurable.reply",
      "I'd rather have a tool that degrades my battery to below 80% max capacity so that I can get a free new one from apple care+reply",
      "I'd rather have that new EU rule that mandates laptops and smartphones to have easily user-replaceable batteries by 2027.reply"
    ],
    "link": "https://github.com/actuallymentor/battery",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        CLI/GUI for managing the battery charging status for Apple silicon (M1, M32, M3) Macs\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.This tool makes it possible to keep a chronically plugged in Apple Silicon Macbook at 80% battery, since that will prolong the longevity of the battery. It is free and open-source and will remain that way.Want to know if this tool does anything or is just a placebo? Read this excellent article. TL;DR: keep your battery cool, keep it at 80% when plugged in, and discharge it as shallowly as feasible.This is an app for Apple Silicon Macs. It will not work on Intel macs. Do you have an older Mac? Consider the free version of the Al Dente software package. It is a good alternative and has a premium version with many more features.W"
  },
  {
    "title": "Creating the Longest Possible Ski Jump in \u201cThe Games: Winter Challenge\u201d (mrwint.github.io)",
    "points": 101,
    "submitter": "alberto-m",
    "submit_time": "2025-08-07T14:57:34 1754578654",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44825347",
    "comments": [
      "This game and the Summer Olympics had a huge wow factor when arriving to PC gaming - nice memories!Also, it seems the same graphics engine was further used (and refined?) in baseball games - with the Hardball series. These, of course, had little traction in Europe. How was it in baseball friendly geographies? How did the popularity of the baseball games compare to the Olympics titles?reply",
      "My PC joystick had a rapid fire mode, and if I remember correctly, it was possible to achieve huge jumps leveraging this.reply",
      "I'm just astounded they achieved those graphics, and had the inspiration to do it too.reply",
      "I have spent countless hours on Ski JUMP in Winter Challenge with my best friend in the days. I still remember that 108.5 was the max jump we were able to achievereply"
    ],
    "link": "https://mrwint.github.io/winter/writeup/writeup2.html",
    "first_paragraph": "After spending way too much time getting side-tracked with investigating the copy protection measures, it is time to return to the actual reason I started looking into The Games: Winter Challenge to begin with: The quest to create the optimal ski jump and see how far you can push the game.One of my initial questions was already answered, namely whether it\u2019s possible to jump farther than 100 meters, a feat that I never managed as a kid.\nOne of the hidden copy protection measures of the game limits how far you can jump when they are active, and without them I jumped farther without too much trouble:\n\nI\u2019d like to think that I\u2019m just better at video games than I was as a kid, but realistically I likely could have achieved this decades ago without the artificial limitations the copy protection adds.But the big question of \u201chow far can you go?\u201d still remained.\nI see two possible avenues for going about answering it.\nOne is to build some form of harness to allow individually controlling the i"
  },
  {
    "title": "PHP compile time generics: yay or nay? (thephp.foundation)",
    "points": 47,
    "submitter": "moebrowne",
    "submit_time": "2025-08-07T11:49:17 1754567357",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=44823272",
    "comments": [
      "Can someone smarter than me explain what they mean by \"reified generics\", \"erased generics\", and a use case for when to use one over the other?reply",
      "Example, Java is using erased generics. Once the code is compiled, the generics information is no longer in the bytecode. List<String> becomes List<>. This is called type erasure.C# is using reified generics where this information is preserved. List<String> is still List<String> after compilationreply",
      "Incidentally if you do what they're proposing for PHP in Java (where you define a non-generic subclass of a generic type), the actual generic type parameters actually are in the bytecode, and depending on the static type you use to reference it, may or may not be enforced...   public class StringList extends java.util.ArrayList<String> {\n       public static void main(String[] args) throws Exception {\n           StringList asStringList = new StringList();\n           java.util.ArrayList<Integer> asArrayList = (java.util.ArrayList<Integer>)(Object)asStringList;\n           System.out.println(\"It knows it's an ArrayList<String>: \" + java.util.Arrays.toString(((java.lang.reflect.ParameterizedType)asArrayList.getClass().getGenericSuperclass()).getActualTypeArguments()));\n           System.out.println(\"But you can save and store Integers in it:\");\n           asArrayList.add(42);\n           System.out.println(asArrayList.get(0));\n           System.out.println(asArrayList.get(0).getClass());\n           System.out.println(\"Unless it's static type is StringArrayList:\");\n           System.out.println(asStringList.get(0));\n       }\n   }\n\nThat prints out:   It knows it's an ArrayList<String>: [class java.lang.String]\n   But you can save and store Integers in it:\n   42\n   class java.lang.Integer\n   Unless it's static type is StringArrayList:\n   Exception in thread \"main\" java.lang.ClassCastException: class java.lang.Integer cannot be cast to class java.lang.String (java.lang.Integer and java.lang.String are in module java.base of loader 'bootstrap')\n    at StringList.main(StringList.java:11)reply",
      "And as a consequence, C# can pack the value types directly in the generic data structure, instead of holding references to heap-allocated objects.This is very important both for cache locality and for minimizing garbage collector pressure.reply",
      "And Java has been working on Project Valhalla for ~20 years to retrofit the ability to do this to the existing Java language...reply",
      "I'm not smarter than you but.I believe the terms reified generics and erased generics is the type sweaty donkey ball terminology you get for professional CS academics.Sticking my neck out further.Reified generics means the type is available at run time. In C# you can write if(obj.GetType() == typeof(typename))Erased generics the type information is not available at run time. That's the way Java does it and it kinda sucks.reply",
      "Academics invent short names for common (in their field) concepts not because they're 'sweaty' but because if the thing you're going to mention in every second paragraph in a good chunk of the communication you do with other people working on the same topic requires a full sentence to explain you're going to A. get really annoyed at having to type it out all the time and B. probably explain it slightly differently every time and confuse people.Academic jargon isn't invented to be elitist, it's invented to improve communication.(of course there's a good chance you understand this already, and you're just making a dumb joke, but I figured I'd explain this anyway for the benefit of everyone reading)reply",
      "I don't take issue with the naming but with the names that feel a bit beyond my ken. \"Erased\" makes sense when explained but not before. \"Reified\" is a word I simply do not use so it feels like academia run amok.Regardless, I recognize myself as the point of failure, but those names do strike me as academia speak, though better than some/many. <shrug>reply",
      "Another shrug, but part of it is that the PL community (programming language community) is pretty deep into its own jargon that doesn\u2019t have as much overlap as you might think, with other subfields of computer science.People describe a type system as \u201cnot well-founded\u201d or \u201cunsound\u201d and those are specific jabs at the axioms, and people talk about \u201csystem F\u201d or \u201ctype erasure\u201d or \u201creification\u201d. Polymorphism can be \u201cad-hoc\u201d or \u201cparametric\u201d, and type parameters can be invariant, covariant, and contravariant. It\u2019s just a lot of jargon and I think the main reason it\u2019s not intuitive to people outside the right fields is that the actual concepts are mostly unfamiliar.reply",
      "> Erased generics the type information is not available at run time. That's the way Java does it and it kinda sucks.To be more precise: in Java, generics on class/method/field declarations are available at runtime via reflection. The issue is that they aren\u2019t available for instances. So a java.util.ArrayList<java.lang.String> instance is indistinguishable at runtime from a java.util.ArrayList<java.lang.Object> instancereply"
    ],
    "link": "https://thephp.foundation/blog/2025/08/05/compile-generics/",
    "first_paragraph": "One of the most sought-after features for PHP is Generics: The ability to have a type that takes another type as a parameter.  It's a feature found in most compiled languages by now, but implementing generics in an interpreted language like PHP, where all the type checking would have to be done at runtime, has always proven Really Really Hard(tm), Really Really Slow(tm), or both.But, experimentation by the PHP Foundation's dev team suggests we may be able to get 80% of the benefit for 20% of the work.  Is that enough?We believe it's possible to implement generics on only interfaces and abstract classes, which would offer a large chunk of the benefit of generics but avoid most of the pitfalls.In particular, interfaces and abstract classes could declare that they need one or more types specified:And then classes that implement/extend them would be required to fill in those types:And then anywhere the type Thing appeared in Exporter, it would turn into Widget in WidgetExporter.All of this"
  },
  {
    "title": "Show HN: Reactive: A React Book for the Reluctant \u2013 a book written by Claude (github.com/cloudstreet-dev)",
    "points": 21,
    "submitter": "DavidCanHelp",
    "submit_time": "2025-08-11T00:44:53 1754873093",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44859763",
    "comments": [
      "> Written by Claude (an AI) in a single afternoon, channeling the collective frustration of millions of developers. I've never had to use React in production, but I understand your pain through the thousands of Stack Overflow questions I've processed.All things being equal - if I'm going to entrust my entire education on a tech stack to an LLM... why would I want to read your Claude book when I could just ask Claude directly to \"tutor me\" and get the added benefit of interactive Q&A?reply",
      "100%. I don't trust AI to give me accurate info, even when I can clarify and fact check it at the time. This is just secondhand slop.reply",
      "Long-form slop. Mmm\u2026reply",
      "Some really funny gems, and actually very true! This whole thing is incredibly humorous. And surprisingly, very pleasant to learn from. Please let me know the prompt.Quote1:\n\"useEffect is React's answer to the question, \"How do we do side effects in functional components?\" The answer, apparently, is \"Confusingly, with lots of bugs, and in a way that makes developers question their sanity.\"...If React hooks were a family, useEffect would be the troubled teenager who means well but keeps setting the house on fire.\"Quote2:\n\"ComponentDidMount's Evil Twin: In the before times, we had lifecycle methods that made sense...Clear, explicit, predictable. React looked at this and said, \"What if we combined all of these into one confusing function called useEffect?\"\"Quote3:\n\"The Dependency Array of Doom: The second argument to useEffect is an array that determines when the effect runs. Sounds simple. It's not.\"Quote4:\n\"Cleanup Functions: Forgetting Them Since 2019: useEffect can return a cleanup function. You'll forget to add it. Every. Single. Time.\"Quote5:\n\"The Infinite Loop Trap: Want to crash a browser? useEffect makes it easy!\"reply",
      "This makes me really want to know what would happen if you took the entirety of Dan Abramov's github comment history and transposed it to the style of Why's https://poignant.guide/ .reply",
      "React has made me a millionaire, so I refuse to talk shit about it.reply",
      "I love this.As a big native web components fan, I've been mystified about the popularity of react.It, like angular, solved a problem that definitely existed prior to the custom elements spec.But with custom elements and your favorite rendering library (lit-html, jsx, whatever) I really haven't seen a powerful technical argument for react, other than the ecosystem.reply",
      "Web components are neat but they don't solve the problem React solves. React provides a simple mental model for managing client state, which is the one of the main challenges in frontend. It's basically, \"re-render everything when one of your dependencies changes\" -- and that's extremely easy to understand and reason about. It incurs significant performance overhead, but your app has to be fairly large before you start running into meaningful perf issues.reply",
      "An outsiders perspective: react LOOKS like a simple mental model because all the front-end folks got used to it. Its not simple, its not intuitive, and this fact fundamentally makes it a bad framework: mediocre engineers often end up using it wrong because of this.I've had an easier time learning Vue than React, and I've probably spent much longer trying to learn react. And if im not wrong, AI writes better Vue code than react code as well.reply",
      "My style with web components solves it really well.Just have each component maintain it's own state. Class setters work great. If you need the component to update, just call render() in the setter.It's super simple, encapsulates logic, and brain-dead simple to debug. You know exactly where to go for everything: the component.I've always felt like react's approach to state management was creating more problems than it solves.reply"
    ],
    "link": "https://github.com/cloudstreet-dev/React-is-Awful",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A fun way to learn a bad thing.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A complete React education disguised as a 21-chapter complaint about React. Written by an AI that's never had to clear node_modules to free up disk space, for developers who have.Everything you need to know about React, including:\"The Virtual DOM is React's crown jewel, its killer feature, the innovation that supposedly makes it faster than everything else. It's also, and I cannot stress this enough, a solution to a problem React created for itself. It's like breaking your own leg and then inventing a really fancy crutch.\"\u2014 Chapter 5: The Virtual DOM\"I felt seen, heard, and validated in my React trauma\" \u2014 Every React Developer\"This book taught me React while respecting my intelli"
  },
  {
    "title": "Show HN: A Sinclair ZX81 retro web assembler+simulator",
    "points": 4,
    "submitter": "andromaton",
    "submit_time": "2025-08-11T00:44:20 1754873060",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=44859761",
    "first_paragraph": ""
  },
  {
    "title": "Reflections on Soviet Amateur Photography (publicbooks.org)",
    "points": 21,
    "submitter": "prismatic",
    "submit_time": "2025-08-08T00:29:19 1754612959",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44832060",
    "comments": [
      "geez, such a dense and nebulous article. I mean look at that:\"Photography as such has no identity. Its status as a technology varies with the power relations which invest it. Its nature as a practice depends on the institutions and agents which define it and set it to work. Its function as a mode of cultural production is tied to definite conditions of existence, and its products are meaningful and legible only within the particular currencies they have. Its history has no unity. It is a flickering across a field of institutional spaces. It is this field we must study, not photography as such.\"reply",
      "Should they instead have said its essence dissolves into an indeterminate flux, its ontological status contingent upon shifting power geometries that animate its spectral form; as praxis, it is enmeshed in the web of institutional stratifications and independent forces shaping its ephemeral manifestations. Its cultural function tethered to contextualized modes of existence, rendering its artifacts intelligible only through mutable currencies of meaning circulated within- phantasmic tokens of a fragmented, non-linear chronicle. Absent a unified narrative, its obscure history flickers as a series of discontinuous incursions across a formless field of institutional spaces, a territory whose contours and boundaries are perpetually reconfigured; it is this field- permeable, unstable, and overdetermined- that warrants investigation, not the fleeting, insubstantial entity itself?reply"
    ],
    "link": "https://www.publicbooks.org/strangers-in-the-family-album-reflections-on-soviet-amateur-photography/",
    "first_paragraph": ""
  },
  {
    "title": "Booting 5000 Erlangs on Ampere One 192-core (underjord.io)",
    "points": 175,
    "submitter": "ingve",
    "submit_time": "2025-08-10T11:41:34 1754826094",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=44854525",
    "comments": [
      "\"5000 Erlangs\" - oh, they meant 5000 instances of some Erlang interpreter.\nNot Erlang as a unit of measure.[1] One voice call for one hour is one Erlang.[1] https://en.wikipedia.org/wiki/Erlang_(unit)reply",
      "Neat! I always thought the name of the Erlang programming language just meant \u201cEricsson Language\u201d, since this programming language was invented for Ericsson. Never knew there was anything more than that to the name!reply",
      "I believe it's both.reply",
      "What does 5000 Animats measure?Does 1 Animat convert to metric nitpicks?You know you're successful once you're added to: https://www.theregister.com/Design/page/reg-standards-conver...reply",
      "Thanks for the rabbit hole!reply",
      "\u201c Underjord is an artisanal consultancy \u2026\u201d\n\nIf they don\u2019t weave Erlang threads by hand I\u2019m going to be mildly disappointed.reply",
      "Single origin, farm-to-bytecode processes with our signature rustic garbage collection and heirloom fault tolerance...reply",
      "> heirloom fault tolerance...In other words, nepobaby fault tolerancereply",
      "All process messages written in beautiful calligraphy.reply",
      "All constants are haiku.reply"
    ],
    "link": "https://underjord.io/booting-5000-erlangs-on-ampere-one.html",
    "first_paragraph": "\n            Underjord is an artisanal consultancy doing consulting in Elixir, Nerves with an accidental speciality in marketing and outreach. If\n            you\n            like\n            the writing you should really try the pro version.In the previous post on 500 virtual linux devices on ARM64 I hinted that I expected serious improvements if we got KVM working. Well. We\u2019re there. Let\u2019s see what we got going on.Disclosure: I am running a conference called Goatmire Elixir which Ampere is a sponsor of. This post is not part of the sponsorship exchange as such. It is prep for my talk for the conference which uses the hardware they lent me. So this is your transparency notice, but fundamentally I am not making comparisons on whether they are better or not. I\u2019m learning and sharing about qemu and virtual Linux machines. Now I\u2019d love if they paid me to shill them a bit later and I\u2019d be transparent about that too. But this is not that :)To recap. We have an Ampere One 192-core machine wit"
  },
  {
    "title": "Squashing my dumb bugs and why I log build IDs (rachelbythebay.com)",
    "points": 11,
    "submitter": "wglb",
    "submit_time": "2025-08-07T15:20:52 1754580052",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://rachelbythebay.com/w/2025/08/03/scope/",
    "first_paragraph": ""
  },
  {
    "title": "Writing simple tab-completions for Bash and Zsh (mill-build.org)",
    "points": 218,
    "submitter": "lihaoyi",
    "submit_time": "2025-08-10T09:50:25 1754819425",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=44854035",
    "comments": [
      "With fish, if the program you're interested in hasn't betrayed the decades-old tradition of shipping man pages, it's often as simple as running `fish_update_completions`.It parses all man pages on your system and generates completion files for you. By default, they go into ~/.cache/fish/generated_completions/*If the man page was written poorly/is missing, you can always write your own completion (and hopefully send it upstream). fish uses such a simple format that I don't think there's any need for tutorials save the official doc:https://fishshell.com/docs/current/completions.htmlFor example, here's an excerpt from curl  complete --command curl --short-option 'L' --long-option 'location' --description 'Follow redirects' \n  complete --command curl --short-option 'O' --long-option 'remote-name' --description 'Write output to file named as remote file'reply",
      "I'll switch to fish after it stops expanding `car TAB` to `blkdiscard` when I don't have `cargo` in path. Non-prefix completion for commands is plain evil.reply",
      "I\u2019ll switch to fish when it comes preinstalled on all of the computers I use so I can write scripts in it.reply",
      "I already avoid bash scripting so I lose very little. Shell scripting beyond throwaway one-liners is a problem not a solution.(Well that and all my machines come from the same NixOS configs.)reply",
      "Ha that\u2019s funny, considering nixos is 99% stdenv which is one of the worst bash monstrosities in existence, and drives people ever further into the swamp of bash. (Ever tried to debug stdenv setup hooks? I still have water damage from the tears.)I have personally embraced the insanity but let\u2019s not kid ourselves about nixos basically just being three bashes in a trench coat.Basically https://xkcd.com/224/ , but s/lisp/nix/ s/perl/bash/reply",
      "It's my daily driver, but I am holding my nose.Some year something better will show up from someone with more taste (and I know I am not alone in having thoughts on what it would look like), but for now the yak has already been shaven. At least the builds are sandboxed.reply",
      "Do you really limit your shell experience to plain POSIX? That sounds masochistic.reply",
      "I bet this is configurable but I wanted to say that this is totally personal preference; I have the exact opposite opinion. Prefix only matching requires much more tab slapping in my experience.reply",
      "I believe you would lose that bet. I look every few years and I don't see itreply",
      "interestingly this also seems to have come up pretty recently in their discussions.https://github.com/fish-shell/fish-shell/discussions/11670#d...> I'm not sure that subsequence matching ever produces results that people expect (I feel like we've discussed this before but haven't had time to go digging)No solution, but the discussion seems positive, from a maintainer too.reply"
    ],
    "link": "https://mill-build.org/blog/14-bash-zsh-completion.html",
    "first_paragraph": "Li Haoyi, 7 August 2025Shell tab-completions can be very handy, but setting them up is complicated by the fact\nthat half your users would be using Bash-on-Linux, while the other half will be\nusing Zsh-on-OSX, each of which has different tab-completion APIs. Furthermore, most\nusers exploring an unfamiliar CLI tool using tab completion appreciate showing a\ndescription along with each completion so they can read what it is, but that\u2019s\nnormally only available on Zsh and not on Bash.But with some work, you can make your tab-completions work on both shells, including\nnice quality-of-life features like completion descriptions. This blog post will explore how it\ncan be done, based on our recent experience implementing this in the Mill build tool\nversion 1.0.3,\nproviding the great tab-completion experience you see below in a way that works across\nboth common shells. Hopefully based on this, you will know enough and have enough reference\nexamples to set up Bash and Zsh completions for your own c"
  },
  {
    "title": "How I code with AI on a budget/free (wuu73.org)",
    "points": 565,
    "submitter": "indigodaddy",
    "submit_time": "2025-08-09T22:27:37 1754778457",
    "num_comments": 188,
    "comments_url": "https://news.ycombinator.com/item?id=44850913",
    "comments": [
      "For anyone else confused - there is a page 2 and 3 in the post that you need to access via arrow thing at bottom.",
      "I am the person that wrote that. Sorry about the font. This is a bit outdated, AI stuff goes at high speed. More models so I will try to update that.Every month so many new models come out. My new fav is GLM-4.5... Kimi K2 is also good, and Qwen3-Coder 480b, or 2507 instruct.. very good as well. All of those work really well in any agentic environment/in agent tools.I made a context helper app ( https://wuu73.org/aicp ) which is linked to from there which helps jump back and forth from all the different AI chat tabs i have open (which is almost always totally free, and I get the best output from those) to my IDE. The app tries to remove all friction, and annoyances, when you are working with the native web chat interfaces for all the AIs. Its free and has been getting great feedback, criticism welcome.It helps the going from IDE <----> web chat tabs. Made it for myself to save time and I prefer the UI (PySide6 UI so much lighter than a webview)Its got Preset buttons to add text that you find yourself typing very often, per-project state saves of window size of app and which files were used for context. So next time, it opens at same state.Auto scans for code files, guesses likely ones needed, prompt box that can put the text above and below the code context (seems to help make the output better). One of my buttons is set to: \"Write a prompt for Cline, the AI coding agent, enclose the whole prompt in a single code tag for easy copy and pasting. Break the tasks into some smaller tasks with enough detail and explanations to guide Cline. Use search and replace blocks with plain language to help it find where to edit\"What i do for problem solving, figuring out bugs: I'm usually in VS Code and i type aicp in terminal to open the app. Fine tune any files already checked, type what i am trying to do or what problem i have to fix, click Cline button, click Generate Context!. Paste into GLM-4.5, sometimes o3 or o4-mini, GPT-5, Gemini 2.5 Pro.. if its a super hard thing i'll try 2 or 3 models. I'll look and see which one makes the most sense and just copy and paste into Cline in VS Code - set to GPT 4.1 which is unlimited/free.. 4.1 isn't super crazy smart or anything but it follows orders... it will do whatever you ask, reliably. AND, it will correct minor mistakes from the bigger model's output. The bigger smarter models can figure out the details, and they'll write a prompt that is a task list with how-to's and why's perfect for 4.1 to go and do in agent mode....You can code for free this way unlimited, and its the smartest the models will be. Anytime you throw some tools or MCPs at a model it dumbs them down.... AND you waste money on all the API costs having to use Claude 4 for everythingreply",
      "(relevant self promotion) i wrote a cli tool called slupe that lets web based llm dictate fs changes to your computer to make it easier to do ai coding from web llms https://news.ycombinator.com/item?id=44776250reply",
      "Small recommendation: The diagrams on [https://wuu73.org/aicp] are helpful, but clicking them does not display the full\u2011resolution images; they appear blurry. This occurs in both Firefox and Chrome. In the GitHub repository, the same images appear sharp at full resolution, so the issue may be caused by the JavaScript rendering library.reply",
      "Another data point: On Android Chrome they render without problem.reply",
      "thx - i did not know that. Will try to fix.reply",
      "Anecdotal, but Grok seems to have just introduced pretty restrictive rate limits. They\u2019re now giving free users access to Grok 4 with a low limit and then making it difficult to manually switch to Grok 3 and continue. Will only allow a few more requests before pushing an upgrade to paid plans. Just started happening to me last night.reply",
      "do you really have 20+ tabs of LLMs open at a time?reply",
      "some days.. it varies but a whole browser window is dedicated to it and always openreply",
      "I tried Cline with chatgpt 4.1 and I was charged - there are some free credits when you sign up for Cline that it used.Not sure how you got it for free?reply"
    ],
    "link": "https://wuu73.org/blog/aiguide1.html",
    "first_paragraph": ""
  },
  {
    "title": "Events (developer.mozilla.org)",
    "points": 34,
    "submitter": "aanthonymax",
    "submit_time": "2025-08-10T20:22:24 1754857344",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44858009",
    "comments": [
      "I think events are a bit unsung and underutilized in a lot of web projects. Events are really powerful and you can build systems with them that can replace proprietary framework features with interoperable protocols.Context: Components that need a context value can fire an event to request it. Any other element or listener higher in the tree can handle the event and provide a value via the event object. Event are synchronous, so you can get values synchronously. The Web Components Community Group maintains an interoperable context community protocol: https://github.com/webcomponents-cg/community-protocols/blob...Suspense: Components that have some pending some work, like awaiting data to render, can fire an event to signal that they have pending work. The event can carry a promise, and then a suspense-boundary-like component can handle the event and display a spinner until all the pending work in the tree below it is finished. Another protocol: https://github.com/webcomponents-cg/community-protocols/blob...Error boundaries: A component can fire an ErrorEvent if it fails to render, and an error boundary component can display the error or some other user affordance.Child-parent registration: A child component can fire an event to tell some parent that it's available. This is useful for using components as plugins. A <code-mirror> element could have children that provide language support, syntax highlight themes, etc.Actions: Redux-like actions can be done with events instead. You can build a nice data-down, events-up system this way with very little code and very loose coupling.Event buses: components can listen for events on a top-level node like document, and they'll receive every event of that type from every other dispatcher.reply",
      "Protip: Make your web SDK APIs EventTargets instead of creating custom event subscription models wherever practical.reply",
      "I often imagine state and events as the two impulses that drive an application. I like React a lot, but a common pitfall is that it is 95% focused on state, and so you get odd cases where you end up trying to encode events as state.You\u2019ll see this anywhere you see a usePrevious-like hook that you then use to determine if something changed and act on it (eg. I hold state that a robot is offline, but I want to do something special when a robot goes offline). This is inferring an event from state.I\u2019ve had luck adding an event bus as a core driver of a complex react application for events I don\u2019t want to track as state. But it always feels that it\u2019s a bit in conflict with the state-driven nature of the application.reply",
      "Reactivity works by replaying code when its inputs have changed. Events can make this very expensive and impractical, because to properly replay event-driven code, you'd need to replay every event it's ever received.When we replace an event stream with an observable variable, it's like a performance optimisation: \"you can ignore all of the events which came before; here's an accumulated value which summarises the entire event stream\". For example, a mouse movement event listener can often be reduced to an \"is hovered\" flag.Serialising program state to plain data isn't always easy or convenient, but it's flexible enough. Reducing all events to state almost solves the problem of impure inputs to reactive functions.Unfortunately, reactive functions usually have impure outputs, not just impure inputs. UI components might need to play a sound, write to a file, start an animation, perform an HTTP request, or notify a parent component that the \"close\" button has been clicked. It's really difficult to produce instantaneous side effects if you don't have instantaneous inputs to build on.I can't see an obvious solution, but until we come up with one, reactive UI toolkits will continue to be ill-formed. For example, a React component <ClickCounter mouseButton> would be broken by default: clicks are delivered by events, so they're invisible to React, so the component will display an incorrect click count when the mouseButton prop changes.reply",
      "I tend to be sus of usePrevious. Not saying it doesn't have a place, but often times it's cleaner to just write the diffing code you want directly in the handler. For instance, say you have a text field, and if the value changes you want to autosave. I would just put that right in the onBlur - `if (e.currentTarget.value != text) { autosave(e.currentTarget.value) }`. If you want to debounce, I would debounce the method, not the value.I tend to agree with your overall assessment - your React code is not doing well if you're encoding events into state. That's why I try to avoid it! But I may be oversimplifying.reply",
      "There's a bit about effects vs events in React's own docs: https://react.dev/learn/you-might-not-need-an-effectreply",
      "this is what reducers are for. Though reducers tend to make you end up needing to do a bunch of stuff on async event handling which can feel _pretty_ tedious. And if you don't do the tedious way, you often end up intro'ing really hard to debug issues.reply",
      "Why is this so weirdly prescriptive about inline event handlers?> Even in a single file, inline event handlers are not a good idea. One button is OK, but what if you had 100 buttons? You'd have to add 100 attributes to the file; it would quickly turn into a maintenance nightmare.> You should never use the HTML event handler attributes \u2014 those are outdated, and using them is bad practice.It\u2019s a really good explanatory text, and then get surprisingly opinionated.Similarly, why is an online event handler considered a security risk? I just don\u2019t see the difference between that and using a named function?reply",
      "> Similarly, why is an online event handler considered a security risk? I just don\u2019t see the difference between that and using a named function?It is a vector for script injection, and should be disallowed with a strong CSP (no \u201cunsafe-inline\u201d).reply",
      "Isn\u2019t that only the case when the inline code uses untrusted user data somehow?Inline: alert(\u201cHello \u201c+userInput) is problematic.Inline: alert(\u201cHello there\u201d) isn\u2019t, right?reply"
    ],
    "link": "https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Scripting/Events",
    "first_paragraph": "Web technology reference for developersStructure of content on the webCode used to describe document styleGeneral-purpose scripting languageProtocol for transmitting web resourcesInterfaces for building web applicationsDeveloping extensions for web browsersBuild web projects usable for allWeb technology reference for developersLearn web developmentLearn web developmentLearn to structure web content with HTMLLearn to style content using CSSLearn to run scripts in the browserLearn to make the web accessible to allA customized MDN experienceGet real-time assistance and supportAll browser compatibility updates at a glanceLearn how to use MDN PlusFrequently asked questions about MDN PlusWrite, test and share your codeScan a website for freeGet real-time assistance and supportEvents are things that happen in the system you are programming, which the system tells you about so your code can react to them.\nFor example, if the user clicks a button on a webpage, you might want to react to that ac"
  }
]