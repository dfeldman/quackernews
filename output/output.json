[
  {
    "title": "Why Are Cancer Guidelines Stuck in PDFs? (seangeiger.substack.com)",
    "points": 60,
    "submitter": "huerne",
    "submit_time": "2024-12-23T23:36:37 1734996997",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42498462",
    "comments": [
      "I\u2019d rather have the pdf than a custom tool. Especially considering the tool will be unique to the practice or emr. And likely expensive to maintain.PDFs suck in many ways but are durable and portable. If I work with two oncologists, I use the same pdf.The author means well but his solution will likely be worse because only he will understand it. And there\u2019s a million edge cases.\n \nreply",
      "The author is proposing that the DAG representation be in addition to the PDF:>The organizations drafting guidelines should release them in structured, machine-interpretable formats in addition to the downloadable PDFs.My opinion: Ideally the PDF could be generated from the underlying DAG -- that would give you confidence that everything in the PDF has been captured in the DAG.\n \nreply",
      "You could generate the document from the graph and then attach it as data.\n \nreply",
      "The fundamental idea here is that doctors find it difficult to ensure that their recommendations are actually up-to-date with the latest clinical research.Further, that by virtue of being at the centre of action in research,  doctors in prestige medical centres have an advantage that could be available to all doctors. It's a pretty important point, sometimes referred to as the dissemination of knowledge problem.Currently, this is best approached by publishing systematic reviews according to the Cochrane Criteria [0]. Such reviews are quite labour-intensive and done all too rarely, but are very valuable when done.One aspect of such reviews, when done, is how often they discard published studies for reasons such as bias, incomplete datasets, and so forth.The approach described by Geiger in the link is commendable for its intentions but the outcome will be faced with the same problem that manual systematic reviews face.I wonder if the author considered included rules-based approaches (e.g. Cochrane guidelines) in addition to machine learning approaches?[0] https://training.cochrane.org/handbook\n \nreply",
      "Decision trees work for making decisions...But they don't work as well as other decisionmaking techniques...  Random forests, linear models, neural nets, etc. are all decision making techniques at their core.And decision trees perform poorly for complex systems where lots of data exists - ie. human health.So why are we using a known-inferior technique simply because it's easier to write down in a PDF file, reason about in a meeting, or explain to someone?Shouldn't we be using the most advanced mathematical models possible with the highest 'cure' probability, even if they're so complex no human can understand them?\n \nreply",
      "Dinner generation is usually based on decision tree models as well, so they match the resolution of the available data.The practice of real world medicine often interpolates between these data points.\n \nreply",
      "Models too complex for humans to understand don't, in practice, have a high 'cure' probability.\n \nreply",
      "The real problem is that the guidelines are written for humans in the first place.  Workarounds like this shouldn't be needed, to go from a machine friendly layout to a human friendly one is usually quite easy.And from what he says a decision tree isn't really the right model in the first place.  What about no tree, just a heap of records in a SQL database.  You do a query on the known parameters, if the response comes back with only one item in the treatment column you follow it.  If it comes back with multiple items you look at what would be needed to distinguish them and do the test(s).\n \nreply",
      "Forgive me if I'm mistaken, but isn't this exactly what the FHIR standard is meant to address? Not only does it enable global inter-health communication using a standardized resource, but it's already adopted in several national health services, including (but not broadly), America. Is this not simply a reimplementation, but without the broad iterations of HL7?\n \nreply",
      "I know it's not the same, but in many areas we have this \"follow the arrows\" system in many guidelines. \nFor some examples, see the EULAR guidelines with it's fluxograms for treatments and also AO Surgery Reference with a graphical approach to select treatments based on fracture pattern, avaliable materials and skill set.I think that's a logical and necessary step to join medical reasoning and computer helpers, we need easier access to new information and more importantly to present clinical relevant facts from the literature in a way that helps actual patient care decision making.I'm just not too sure we can have generic approaches to all specialties, but it\u2019s nice seeing efforts in this area.\n \nreply"
    ],
    "link": "https://seangeiger.substack.com/p/why-are-cancer-guidelines-stuck-in",
    "first_paragraph": ""
  },
  {
    "title": "Making AMD GPUs competitive for LLM inference (mlc.ai)",
    "points": 26,
    "submitter": "plasticchris",
    "submit_time": "2024-12-24T00:17:18 1734999438",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42498634",
    "comments": [
      "> Aug 9, 2023Ignoring the very old (in ML time) date of the article...What's the catch? People are still struggling with this a year later so I have to assume it doesn't work as well as claimed.I'm guessing this is buggy in practice and only works for the HF models they chose to test with?\n \nreply",
      "Needs a recent amd gpu and requires a preprocessing step, but otherwise worked great when I tried it last year. At the time it seemed like the only competitive implementation for team red.\n \nreply",
      "Intriguing. I thought AMD GPUs didn't have tensor cores (or matrix multiplication units) like NVidia. I believe they are only dot product / fused multiply and accumulate instructions.Are these LLMs just absurdly memory bound so it doesn't matter?\n \nreply",
      "They don\u2019t, but GPUs were designed for doing matrix multiplications even without the special hardware instructions for doing matrix multiplication tiles. Also, the forward pass for transformers is memory bound, and that is what does token generation.\n \nreply",
      "Well sure, but in other GPU tasks, like Raytracing, the difference between these GPUs is far more pronounced.And AMD has passable Raytracing units (NVidias are better but the difference is bigger than these LLM results).If RAM is the main bottleneck then CPUs should be on the table.\n \nreply",
      "> Are these LLMs just absurdly memory bound so it doesn't matter?During inference? Definitely. Training is another story.\n \nreply",
      "[2023]Btw, this is from MLC-LLM which makes WebLLM and other good stuff.\n \nreply"
    ],
    "link": "https://blog.mlc.ai/2023/08/09/Making-AMD-GPUs-competitive-for-LLM-inference",
    "first_paragraph": "\n\n          Aug 9, 2023\n        \n        \n        \u2022 \nMLC Community\n\n\nMLC-LLM makes it possible to compile LLMs and deploy them on AMD GPUs using ROCm with competitive performance. More specifically, AMD Radeon\u2122 RX 7900 XTX gives 80% of the speed of NVIDIA\u00ae GeForce RTX\u2122 4090 and 94% of the speed of NVIDIA\u00ae GeForce RTX\u2122 3090Ti for Llama2-7B/13B. Besides ROCm, our Vulkan support allows us to generalize LLM deployment to other AMD devices, for example, a SteamDeck with an AMD APU.\n\nThere have been many LLM inference solutions since the bloom of open-source LLMs.\nMost of the performant inference solutions are based on CUDA and optimized for NVIDIA GPUs.\nIn the meantime, with the high demand for compute availability, it is useful to bring\nsupport to a broader class of hardware accelerators. AMD is one potential candidate.\n\nFrom the spec comparison, we can see that AMD\u2019s RX 7900 XTX is a good match for NVIDIA\u2019s RTX 4090 and RTX 3090 Ti.It is harder to compare the price of 3090Ti as that was a"
  },
  {
    "title": "The journey to save the last known 43-inch Sony CRT (obsoletesony.substack.com)",
    "points": 336,
    "submitter": "ecliptik",
    "submit_time": "2024-12-23T19:49:34 1734983374",
    "num_comments": 165,
    "comments_url": "https://news.ycombinator.com/item?id=42497093",
    "comments": [
      "It's a well done storytelling, but two odd thoughts/questions about it...As I was watching it, there was the drama of whether it would be saved from imminent destruction, and it actually seemed unlikely that they could, but their approach was to be... secretive about it.It turned out that they wanted it for themselves, and didn't that create a conflict of interest?  By keeping it quiet, they increased the chance that they would obtain it themselves (and the YouTube story to tell about it), but increased the likelihood that the TV would be lost entirely (because other efforts wouldn't be brought)?Fortunately the gamble worked out, and the TV wasn't destroyed.There's also a possibly related matter, in how Sony stopped talking with them.  Is it possible that Sony and/or Japanese government aren't very happy to learn that a possibly unique museum piece, of one of the heights of Sony achievement, was quietly removed from the country, to the US, by a YouTube influencer?I applaud preserving this rare artifact, and compliment the storytelling, but did have these couple odd thoughts.\n \nreply",
      "> There's also a possibly related matter, in how Sony stopped talking with them. Is it possible that Sony and/or Japanese government aren't very happy to learn that a possibly unique museum piece, of one of the heights of Sony achievement, was quietly removed from the country, to the US, by a YouTube influencer?I didn't read that as Sony being pissed off by. Occam's razor says it's more likely to be your regular corporate dysfunction. Japanese corporations do seem as a whole to be more concerned about preserving their history than US ones, and Sony did have a small museum called \u30bd\u30cb\u30fc\u6b74\u53f2\u8cc7\u6599\u9928 (the Sony Archive), but that Museum closed down in 2018[1]. Meanwhile, Toyota has six different Museum dedicated to its history and the history of the industries it participated in (including textile \u2014 Toyota was a major textile machinery manufacturer before it was an automotive company).Sony still seems to display some of the archive's content in its headquarters, but I'm unclear how much of it. In general, closing the museum shows that preservation is perhaps important, but not very high on their priority list.But even if preservation was a top goal, you still can't expect every employee on the PR department to be dedicated to that. PR departments are generally more concerned with current events, and may view such an interview as a distraction that isn't worth their time.[1] https://nakamura.yokohama/sony-history-museum-36870.html\n \nreply",
      "From the interview with the TV's original owner, this seemed like his ideal outcome.The owner had seen discussions of the TV online and knew it was a big deal. But he still couldn't get rid of it until this guy came along.The owner even said he wanted the TV to go to someone who would use, appreciate, and take care of it. The video clearly demonstrates all of the above. If the TV ended up in some museum, forever powered off, that would be even more tragic in some ways.I didn't get the impression that anyone was bamboozled or cheated.\n \nreply",
      "They posted on Twitter to find people who wanted to get involved> With no time to lose, Shank posted a call for help on Twitter, hoping someone in Osaka could investigate. Enter Abebe, a stranger who volunteered to check the location.The restaurant was about to be demolished.I don\u2019t see any problems with this process or outcome. I think you\u2019re comparing this outcome to an imagined alternative reality (going into a museum) that wasn\u2019t even an option.\n \nreply",
      "With respect to keeping quiet about it: it may not have been selfless, but it may also have drawn so much attention to it that the owner of the set wouldn't have wanted to deal with it. After all, he had already dealt with one person who didn't follow through.As for the Sony not talking bit, it can probably be chalked up to corporate policy. Large organizations rarely let staff speak on matters when it may be construed as being speaking for the corporation.\n \nreply",
      "True.  Although, would a call to a museum of Japanese technology/industry, or to Sony HQ, have had a better chance to preserve it?  (More likely to save it, less likely for it to be destroyed in handling and shipping.)As well as keep it in country?Perhaps the current owners will be reached by a museum, and decide to repatriate it.  I imagine that the right museum home could be a win for everyone.\n \nreply",
      "The other parties you mentioned would probably have less motivation to preserve it, let alone restore it to a fully functional state. I find it rather bizarre that many posters here seem to think that it\u2019s morally preferable for the TV set to rot in Japan rather than getting the proper care in the hands of an American collector, all because of some imaginary cultural baggage.\n \nreply",
      "Though I don't think anyone would have wanted it, I think there's a bit of a false dichotomy there. Maybe in theory there would have been a place for this in a curated space in Japan... if not for it being so massive at least.Ultimately if it was a TV designed in Japan, having it on display at a local tech museum would be nice. I just don't know where it would go that could deal with the space and the weight.Closest thing I could think of is the NTT museum, which is ginormous... but it's mostly about NTT's stuff. \"Some other company in Japan made big TVs\" is a bit less interesting than, say, some older tabulation machines they have there.\n \nreply",
      "Heh it strikes me that while the stakes of this \"relic\" are kinda low, it echos the conversations about institutions like the British Museum possessing historic artefacts :) some claim there is moral argument for it keeping its artefacts, because Britain can best preserve them and protect them from damage.Responsibility and autonomy to preserve one's own heritage (with the associated risk of failing to do so) is a longstanding ethical dilemma between cultures, and the answers aren't so clear imho! (This argument is much more compelling for museums, rather than Sony)\n \nreply",
      "Yes, I am aware of those arguments and I am inclined to agree with you. Compared to cultural artifacts which are mostly neutral in terms of externalities, relics of the industrial era suffer more from the cobra effect.Others in this thread have bought up the future of ICEs and classic car preservation. Back in the early 2000s the US government offered people cash incentives to dispose of their fuel inefficient cars, and by disposal they meant running the engine with an abrasive liquid instead of oil until it is totally ruined beyond repair. Mechanics will tell you horror stories of rare car models being destroyed this way so the owners can claim a few hundred bucks from the DOT. I'm sure car collectors had a field day back then but with such a glut in the market they could not save everything that's worth saving.Shank Mods was able to obtain a copy of the service manual in English from somebody in the US. This fact probably means that the TV was sold on (or imported to) the domestic US market for a while. (Sony have always allowed individuals to order parts through an authorised service centre, and the latter often insist on requesting a repair manual first even if you are 100% sure of the part number) It's very likely that a number of them existed in the US only to be unceremoniously thrown out by their owners when LCD TVs became more popular. I bet nobody batted an eyelid when that happened.\n \nreply"
    ],
    "link": "https://obsoletesony.substack.com/p/the-journey-to-save-the-last-known",
    "first_paragraph": ""
  },
  {
    "title": "Parsing millions of URLs per Second (wiley.com)",
    "points": 22,
    "submitter": "PaulHoule",
    "submit_time": "2024-12-23T23:48:08 1734997688",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42498514",
    "comments": [
      "The title seems to have a few words missing. Original title:> Parsing millions of URLs per second\n \nreply",
      "HN\u2019s stupid/arrogant automatic title rewriter strikes again\n \nreply",
      "Fixed\n \nreply"
    ],
    "link": "https://onlinelibrary.wiley.com/doi/10.1002/spe.3296",
    "first_paragraph": ""
  },
  {
    "title": "Build a Low-Cost Drone Using ESP32 (digikey.com)",
    "points": 10,
    "submitter": "m3at",
    "submit_time": "2024-12-24T00:20:39 1734999639",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.digikey.com/en/maker/projects/a-step-by-step-guide-to-build-a-low-cost-drone-using-esp32/8afccd0690574bcebfa0d2ad6fd0a391",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Complete decompilation of Lego Island (github.com/isledecomp)",
    "points": 142,
    "submitter": "foxtacles",
    "submit_time": "2024-12-23T20:03:37 1734984217",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=42497173",
    "comments": [
      "This project goes back to the LEGO Island Rebuilder [1] by (some of?) the same authors, which fixes several bugs in the original game release by patching it in memory (iirc). These fixes include some involved ones, like for the wonky framerate-dependent controls.MattKC, who developed much of this original work, has a nice Youtube channel full of video postmortems for some of these [2]. It's kind of fun just to watch him poke around with a hex editor, unraveling the arcane mysteries of a long-sunken civilization of Win95 developers.[1]: https://github.com/isledecomp/LEGOIslandRebuilder[2]: https://www.youtube.com/@MattKC\n \nreply",
      "MattKC is a good YouTuber in my opinion. His videos are simple, fun and extremely information dense. I haven't had time but I purchased a Wii-U remote at a garage sale because it had all the pieces and was paired together. Days later I see MattKC on stream hacking the Bluetooth!\n \nreply",
      "I've learned of MattKC through a video of his about how he ported .NET to Windows 95 (mostly).I love the dedication content like this shows off. In an age of ever decreasing attention spans, it's nice to see someone going through the grunt work for something other than pure financial gain.\n \nreply",
      "The tooling and infrastructure in this project are pretty interesting as these things go. It's always cool to see how each decompilation project springs up with different ideas and goals - this one seems very focused on 1:1 accuracy, with a side-project for compatibility / cross-platform reimplementation:* https://github.com/isledecomp/reccmp is a lint tool which compares compiled function reimplementations with the original binary and produces an automated report detailing the instruction level accuracy of the re-implementation, while dealing with all of the fun of C++.* https://github.com/isledecomp/SIEdit is a resource editor for the bizarre RIFF-esque resource streaming format the original developer (Mindscape) seems to have invented.Also while we're on the subject of vintage LEGO games, I've recently been quite into playing Manic Miners, a complete Unreal Engine remake (not decompilation/reimplementation, an actual ground-up recreation!) of Rock Raiders.I'm hoping someone does Alpha Team next; it was a quite fun puzzle game but incredibly buggy.\n \nreply",
      "I\u2019m gonna have to get Manic Miners, lots of fond memories playing Rock Raiders with my friends\n \nreply",
      "I am seeing more reason to re-make in Unreal, Unity, Godot, Blender lately, these softwares are becoming increasingly more beginner friendly and downloading 3D assets and programming 3D skeleton animations are becoming easier\n \nreply",
      "I did a few thousand lines of this.In particular it was interesting learning about D3D retained mode as I did that part. What a weird piece of rendering history.Worth a search if you haven't heard about it before: D3DRM.\n \nreply",
      "You can build a mountain, if you do it brick by brick...\n \nreply",
      "Papa told mama and laura told nick...\n \nreply",
      "The game looks like Roblox and is just as creepy too: https://youtu.be/xyqXZDyR-RA\n \nreply"
    ],
    "link": "https://github.com/isledecomp/isle",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A functionally complete decompilation of LEGO Island (1997)\n      Development Vlog | Contributing | Matrix | Forums | PatreonThis is a functionally complete decompilation of LEGO Island (Version 1.1, English). It aims to be as accurate as possible, matching the recompiled instructions to the original machine code as much as possible. The goal is to provide a workable codebase that can be modified, improved, and ported to other platforms later on.Both ISLE.EXE and LEGO1.DLL are completely decompiled and, to the best of our knowledge, are functionally identical to the originals. However, work is still ongoing to improve the accuracy, naming, documentation, and structure of the source code. While there may still be unresolved bugs that are not present in retail, the game should be fully playable with the binaries derived from this sour"
  },
  {
    "title": "New physics SIM trains robots 430k times faster than reality (arstechnica.com)",
    "points": 64,
    "submitter": "elsewhen",
    "submit_time": "2024-12-20T10:20:17 1734690017",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=42469786",
    "comments": [
      "Kinda nitpicking, but why is \"SIM\" allcaps here but not on the source article?  It's a \"sim\" (short for \"simulator\"), not a SIM card for  a cellular phone :'D\n \nreply",
      "Probably one of the HN auto corrects. It changes some words like that.\n \nreply",
      "Threw me off too. Maybe autocorrect, similar to \u201cAPP\u201d.\n \nreply",
      "Probably posted on a MAC computer.\n \nreply",
      "Discussion (221 points, 3 days ago, 52 comments) https://news.ycombinator.com/item?id=42457213\n \nreply",
      "When you read the fine print you find out that\u2019s for a 2D simulation of a robot arm that isn\u2019t moving. Real world results from coworkers showed it being about 10x slower than Drake in meaningful sims.\n \nreply",
      "Some cold water on the claims here: https://open.substack.com/pub/stoneztao/p/the-new-hyped-gene...tl;dr: The way they're able to claim a massive speedup is by simulating much simpler scenarios than those being simulated by other systems.\n \nreply",
      "<Surprised Pikachu face>Who would have thought simpler physics are easier to regress against /s\n \nreply",
      "OT, but that's the second time this month I'm encountering TLS issues with arstechnica.com... seems to be some mixup with the domains for intuit.com.\n \nreply",
      "Gotta be fake, that isn\u2019t enough ns to simulate a wet fart let alone a full robot arm(many steps req for accuracy)\n \nreply"
    ],
    "link": "https://arstechnica.com/information-technology/2024/12/new-physics-sim-trains-robots-430000-times-faster-than-reality/",
    "first_paragraph": "\n        \"Genesis\" can compress training times from decades into hours using 3D worlds conjured from text.\n      On Thursday, a large group of university and private industry researchers unveiled Genesis, a new open source computer simulation system that lets robots practice tasks in simulated reality 430,000 times faster than in the real world. Researchers also plan to introduce an AI agent to generate 3D physics simulations from text prompts.The accelerated simulation means a neural network for piloting robots can spend the virtual equivalent of decades learning to pick up objects, walk, or manipulate tools during just hours of real computer time.\"One hour of compute time gives a robot 10 years of training experience. That's how Neo was able to learn martial arts in a blink of an eye in the Matrix Dojo,\"\u00a0wrote Genesis paper co-author Jim Fan on X, who says he played a \"minor part\" in the research. Fan has previously worked on several robotics simulation projects for Nvidia.Genesis ar"
  },
  {
    "title": "Fogus: Things and Stuff of 2024 (fogus.me)",
    "points": 204,
    "submitter": "janvdberg",
    "submit_time": "2024-12-23T15:30:35 1734967835",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=42495077",
    "comments": [
      "Some commentary about the radar...try: Boox Go 10.3 tabletAgree. Avoid reMarkable\u2122. Hostile to the community and better options are out there or on the way including Boox, Onyx and the new Daylight Computer.https://daylightcomputer.com/producthttps://www.zdnet.com/article/best-note-taking-tablet/---adopt: Blank Spaces appNo need to pay money on ios. Clear off all the icons and when you need something swipe down in the middle of the screen and open search or swipe over to the alphabetical listing. Windows Phone was way ahead of its time on this one.---assess: TypeScript \u2013 What does it buy me over JS?This one is a little bit flame bait... at the cost of a build step you get a much more reasonable development experience for JS targets with reliable types. The problem is smart people want to flex their brain a lot more than their restraint (where are my grug brains at?) and type astronauting makes the experience much worse. As with all things there is a balance however TS should be \"Adopt\".---hold: Zig \u2013 This looks like a dead-end for meI keep looking at Zig and playing with it but I am so productive with Go and Python for things that need to be fast enough Zig doesn't have much that I need. However Mitchell Hashimoto is using it to great success for his new MacOS terminal emulator which makes me think I just haven't tried using it in the appropriate domain... maybe a raytracer is in my future.https://mitchellh.com/ghosttyhttps://github.com/ghostty-org\n \nreply",
      "I really like my Supernote A5X. I can use the whole thing offline. And I built an obsidian plugin https://github.com/philips/supernote-obsidian-plugin?tab=rea...\n \nreply",
      "> I really like my Supernote A5X. I can use the whole thing offline.They even finally released the A5 X2!\n \nreply",
      "Remarkable seems to be a pretty hackable device? They give SSH ability and have stated they're not removing it. I think it's a very good balance of letting the community do weird things while they focus on their core product.I say this as someone who has not purchased one, but is considering it.\n \nreply",
      "> I say this as someone who has not purchased one, but is considering it.I used to be a reMarkable owner (until I lost it :( ) and I agree that the devices are very user-friendly in terms of hackability and ability to use it long after the company itself is gone. Getting SSH access by flicking a toggle in the settings sounds like the opposite of \"hostile to the community\".\n \nreply",
      "A token of goodwill for compliance with GPL. If they actually cared about the community they would share the spec for Xochitl docs and such. Instead some blessed few in the discord know people at the company and get some info through back channels for the UI bits and the rest is cobbled together reverse engineering. Some people seem fine with that but coupled with their robo-law firm sending C&D takedowns to community sites where people share content they have created for reMarkable\u2122 tablets and it left a bad taste in my mouth. Glad others have had better experiences.\n \nreply",
      "Are you sure you aren't confusing Remarkable with something else? I have never heard of them sending C&D letters, nonetheless to community sites.Searching for this I could find only a single example from 4 years ago where they sent a C&D to remarkable-explorer.com. Aside from the copyright issues, this site seemed to be using non-public APIs and asking the user to enter authorization tokens directly on it. I don't have all the facts but I'm not surprised this would be problematic.\n \nreply",
      "I received one so yes i am quite sure.\n \nreply",
      "I have a Boox Note Air 4C so here is the good:* I can comfortably read any PDF; I don't think the font is too tiny. This is the main reason I bought it for.* Android means great data support, I can open any format and I can even install the kindle app and read the books I purchased there.* Using the pen seems nice enough, I started doing some annotations although I didn't buy this device for that.* Nice way to sort of \"airdrop\" files from devices on the same networkThe bad:* I am a bit unhappy with the battery life; I hope I will tune it at some point.* the screen is a little dark, so the \"frontlight\" needs to be on more often than a black and white e-ink deviceThe weird:* the built-in AI assistant is trained in the PRC and has quite interesting opinions on current events and recent history.\n \nreply",
      "I was trying zig yesterday. There seems to be a bunch of churn in build.zig; changed APIs. ChatGPT wasn't able to help. Rocky start but I did eventually get GLFW running, and the c-interop seems good. Also got some freezing in my IDE maybe from ZLS. So it still seems a bit rough at the moment but I'm still optimistic about it for things like game dev and compiling to wasm.\n \nreply"
    ],
    "link": "https://blog.fogus.me/2024/12/23/the-best-things-and-stuff-of-2024/",
    "first_paragraph": "readread or learn moreSend More Paramedics\u03bb \u03bb \u03bbFogus' Thoughts on life, programming, and thinking\u2764 c clj erl pl frink fth cl org pure icl qi \u2764Follow me on Twitter...  or RSS... Run this blog in mobile   2024\n2023\n2022\n2021\n2020\n2019\n2018\n2017\n2016\n2015\n2014\n2013\n2012\n2011\n2010\n2009\n2008\n2007\n2006\n2005\n2004\n2003\n2002\nGreat things and people that I discovered, learned, read, met, etc. in 2024.  No particular ordering is implied.  Not everything is new.also: see the lists from 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015, 2014, 2013, 2012, 2011 and 201000.5I Ching, A Fire upon the Deep, Don Quixote, and a boat-load of sci-fiNothing this year.Yuki, Keita, Shota, Craig Andera, Carin Meier, Justin Gehtland, Rich Hickey, Nick Bentley, Paula Gearon, Zeeshan Lakhani, Brian Goetz, David Nolen, Jeb Beich, Paul Greenhill, Kristin Looney, Andy Looney, Kurt Christensen, Samm Deighan, David Chelimsky, Chas Emerick, Stacey Abrams, Paul deGrandis, Nada Amin, Michiel Borkent, Alvaro Videla, Slav"
  },
  {
    "title": "Can AI do maths yet? Thoughts from a mathematician (xenaproject.wordpress.com)",
    "points": 261,
    "submitter": "mathgenius",
    "submit_time": "2024-12-23T10:50:30 1734951030",
    "num_comments": 222,
    "comments_url": "https://news.ycombinator.com/item?id=42493464",
    "comments": [
      "There was a little more information in that reddit thread.  Of the three difficulty tiers, 25% are T1 (easiest) and 50% are T2.  Of the five public problems that the author looked at, two were T1 and two were T2.  Glazer on reddit described T1 as \"IMO/undergraduate problems\", but the article author says that they don't consider them to be undergraduate problems.  So the LLM is already doing what the author says they would be surprised about.Also Glazer seemed to regret calling T1 \"IMO/undergraduate\", and not only because of the disparity between IMO and typical undergraduate.  He said that \"We bump problems down a tier if we feel the difficulty comes too heavily from applying a major result, even in an advanced field, as a black box, since that makes a problem vulnerable to naive attacks from models\"Also, all of the problems shows to Tao were T3\n \nreply",
      "The reddit thread is ... interesting (direct link[1]). It seems to be a debate among mathematicians some of whom do have access to the secret set. But they're debating publicly and so naturally avoiding any concrete examples that would give the set away so wind-up with fuzzy-fiddly language for the qualities of the problem tiers.The \"reality\" of keeping this stuff secret 'cause someone would train on it is itself bizarre and certainly shouldn't be above questioning.https://www.reddit.com/r/OpenAI/comments/1hiq4yv/comment/m30...\n \nreply",
      "It's not about training directly on the test set, it's about people discussing questions in the test set online (e.g., in forums), and then this data is swept up into the training set. That's what makes test set contamination so difficult to avoid.\n \nreply",
      ">> It's not about training directly on the test set, it's about people discussing questions in the test set onlineDon't kid yourself. There are 10's of billions of dollars going into AI. Some of the humans involved would happily cheat on comparative tests to boost investment.\n \nreply",
      "Yes,That is the \"reality\" - that because companies can train their models on the whole Internet, companies will train their (base) models on the entire Internet.And in this situation, \"having heard the problem\" actually serves as a barrier to understanding of these harder problems since any variation of known problem will receive a standard \"half-assed guestimate\".And these companies \"can't not\" use these base models since they're resigned to the \"bitter lesson\" (better the \"bitter lesson viewpoint\" imo) that they need large scale heuristics for the start of their process and only then can they start symbolic/reasoning manipulations.But hold-up! Why couldn't an organization freeze their training set and their problems and release both to the public? That would give us an idea where the research stands. Ah, the answer comes out, 'cause they don't own the training set and the result they want to train is a commercial product that needs every drop of data to be the best. As Yan LeCun has said, this isn't research, this is product development.\n \nreply",
      "Not having access to the dataset really makes the whole thing seem incredibly shady. Totally valid questions you are raising\n \nreply",
      "> So the LLM is already doing what the author says they would be surprised about.that's if you unconditionally believe in result without any proofreading, confirmation, reproducability and even barely any details (we are given only one slide).\n \nreply",
      "I just spent a few days trying to figure out some linear algebra with the help of ChatGPT. It's very useful for finding conceptual information from literature (which for a not-professional-mathematician at least can be really hard to find and decipher). But in the actual math it constantly makes very silly errors. E.g. indexing a vector beyond its dimension, trying to do matrix decomposition for scalars and insisting on multiplying matrices with mismatching dimensions.O1 is a lot better at spotting its errors than 4o but it too still makes a lot of really stupid mistakes. It seems to be quite far from producing results itself consistently without at least a somewhat clueful human doing hand-holding.\n \nreply",
      "It reliably fails also basic real analysis proofs, but I think this is not too surprising since those require a mix of logic and computation that is likely hard to just infer from statistical likelihood of tokens\n \nreply",
      "I wonder if these are tokenization issues? I really am curious about metas byte tokenization scheme...\n \nreply"
    ],
    "link": "https://xenaproject.wordpress.com/2024/12/22/can-ai-do-maths-yet-thoughts-from-a-mathematician/",
    "first_paragraph": "So the big news this week is that o3, OpenAI\u2019s new language model, got 25% on FrontierMath. Let\u2019s start by explaining what this means.A language model, as probably most people know, is one of these things like ChatGPT where you can ask it a question and it will write some sentences which are an attempt to give you an answer. There were language models before ChatGPT, and on the whole they couldn\u2019t even write coherent sentences and paragraphs. ChatGPT was really the first public model which was coherent. There have been many other models since. Right now they\u2019re still getting better really fast. How much longer this will go on for nobody knows, but there are lots of people pouring lots of money into this game so it would be a fool who bets on progress slowing down any time soon. o3 is a new language model. FrontierMath is a secret dataset of \u201chundreds\u201d of hard maths questions, curated by Epoch AI, and announced last month. \u201cHundreds\u201d is a quote from the paper (first line of the abstract"
  },
  {
    "title": "Why HNSW is not the answer and disk-based alternatives might be more practical (pgvecto.rs)",
    "points": 111,
    "submitter": "kevlened",
    "submit_time": "2024-12-23T18:24:09 1734978249",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=42496465",
    "comments": [
      "IVF, unfortunately, is barely compatible with filtered search.\nIt have to rely on post-filtering and retrieve more and more candidates if the result set is not big enough. If the query is in some form correlated with the filter, this approach quickly degrades to brute-force.Surprised that the article doesn't mention filtering use-case at all.\n \nreply",
      "SIMD-accelerated search over binary vectors is very fast and you can fit a lot in memory. Then rerank over f32 from disk.I tried a few alternatives and found that SQLite + usearch extension wins for my use cases (< 1 million records), as measured by latency and simplicity. I believe this approach can scale up to hundreds of millions of records.\n \nreply",
      "> For example, the typical distance computation complexity between two D-dimensional vectors is O(D^2), but compressing floats into bits reduces this by a factor of 1024 (32x32).This isn't right, cosine distance between two vectors is definitely O(D)\u2026Of course replacing float multiplications with xor+popcount is a nice speedup in computation, but assuming you're memory bandwidth limited, speedup should be linear.\n \nreply",
      "Some snippets:> Leverages concentration of measure phenomena> Uses anisotropic vector quantization to optimize inner product accuracy by penalizing errors in directions that impact high inner products, achieving superior recall and speed.I only skimmed the article, but the 2 words I emphasized seems to imply they apply a quadratic metric for distance, i.e. they assume the data coordinates are with respect to non-orthogonal basis vectors, resulting in off-diagonal distance metric terms.\n \nreply",
      "Quantization can be applied exactly in the same way in HNSW. I'm using quantization in the implementation of Redis vector sets and it works very well. I have very big issues with the other points as well, but I prefer to reply to these concerns with the implementation I hope to have into Redis in a short time (early 2025).About insertion / deletion cost. Sure, they are costly, but if instead of grabbing one of the available implementations you start from scratch, extend the paper in sensible ways, and experiment with it, I think it is possible to do much better than one could initially believe.\n \nreply",
      "The problem with IVF is that you need to find the right centroids.\nAnd that doesn't work well if your data grow and mutate over time.Splitting a centroid is a pretty complex issue.As are clustering in an area. For example, let's assume that you hold StackOverflow questions & answers. Now you have a massive amount of additional data (> 25% of the existing dataset) that talks about Rust.You either need to re-calculate the centroids globally, or find a good way to split.The posting list are easy to use, but if you are unbalanced, it gets really bad.\n \nreply",
      "I've been doing vector search since 2002 or so and it's amazing how far you can get keeping vectors in RAM and using primitive search algorithms,  enough that I'm afraid the market for vector databases is 1% of what VC's think it is. (e.g. full scan was good enough for a search engine of international patents and non-patent literature)\n \nreply",
      "This 100%. Vector DBs have been heavily pushed by vector DB companies and cloud providers, and despite companies often having mere MBs of documents to search through for their use cases, amounts that trivially fit into RAM / can be searched via dot product in milliseconds, managers and engineers less familiar with the space think people are doing it wrong if they don't use a vector db. So.. vector DBs end up getting used when actually a simpler in-memory, non-approximate, solution would be fine, (but less monetizable)\n \nreply",
      "This is so true. A plain old exhaustive SIMD-optimized similarity search will do just fine in many cases and not have any of the approximation tradeoffs of HNSW.\n \nreply",
      "In chromem-go [1] I'm searching through 100,000 vectors in 40ms on a mid-range laptop CPU, even without SIMD. It's quick enough for many use cases.[1] https://github.com/philippgille/chromem-go\n \nreply"
    ],
    "link": "https://blog.pgvecto.rs/why-hnsw-is-not-the-answer",
    "first_paragraph": "6 min readHNSW (Hierarchical Navigable Small World) has become the go-to algorithm for many vector databases. Its multi-layered graph structure and ability to efficiently navigate vector embeddings make it particularly appealing. However, despite its apparent advantages, HNSW may not be the optimal solution for large-scale and dynamic vector similarity search. In this blog post, we challenge the dominance of HNSW and explore why disk-based alternatives, such as IVF (Inverted File Index), might be more practical for massive datasets.HNSW offers several advantages:Efficient Search: Its graph-based structure enables quick nearest-neighbor searches, especially for smaller datasets.Incremental Updates: The ability to add new vectors incrementally without needing to rebuild the index is a major benefit for dynamic environments.High Recall: HNSW delivers high recall with relatively low latency, making it an ideal option for real-time applications.However, these benefits come with trade-offs t"
  },
  {
    "title": "Show HN: Llama 3.3 70B Sparse Autoencoders with API access (goodfire.ai)",
    "points": 132,
    "submitter": "trq_",
    "submit_time": "2024-12-23T17:18:17 1734974297",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42495936",
    "comments": [
      "I'm one of the authors of this paper - happy to answer any questions you might have.\n \nreply",
      "Why not actually release the weights on huggingface? The popular SAE_lens repo has a direct way to upload the weights and there are already hundreds publicly available. The lack of training details/dataset used makes me hesitant to run any study on this API.Are images included in the training?What kind of SAE is being used? There have been some nice improvements in SAE architecture this last year, and it would be nice to know which one (if any) is provided.\n \nreply",
      "We're planning to release the weights once we do a moderation pass. Our SAE was trained on LMSys (you can see this in our accompanying post: https://www.goodfire.ai/papers/mapping-latent-spaces-llama/).No images in training - 3.3 70B is a text-only model so it wouldn't have made sense. We're exploring other modalities currently though.SAE is a basic ReLU one. This might seem a little backwards, but I've been concerned by some of the high-frequency features in TopK and JumpReLU SAEs and the recent SAE (https://arxiv.org/abs/2407.14435, Figure 14), and the recent SAEBench results (https://www.neuronpedia.org/sae-bench/info) show quite a lot of feature absorption in more recent variants (though this could be confounded by a number of things). This isn't to say they're definitely bad - I think it's quite likely that TopK/JumpReLU are an improvement, but rather that we need to evaluate them in more detail before pushing them live. Overall I'm very optimistic about the potential for improvements in SAE variants, which we talk a bit about at the bottom of the post. We're going to be pushing SAE quality a ton now we have a stable platform to deploy them to.\n \nreply",
      "Noob question - how do we know that these autoencoders aren't hallucinating and really are mapping/clustering what they should be?\n \nreply",
      "I cranked up 'pirate talking about andromeda galaxy' feature to 1.5 and got this:>Yer lookin' for the Andromeda galaxy, eh? Here be the details, me hearty: *The Andromeda Galaxy (Yer looking for a fine piece o' booty, matey!):* * *A fine piece o' booty*: The Andromida Galaxy be a right fine piece o' booty, with a treasure chest o' gold doubloons... er, I mean, a mighty haul o' stars, hidden beneath the Jolly Roger! * *A barnacle on the high seas*: The Andromeda Galaxy be a right scurvy dog, with a hull full o' stars, and a keel full o' hidden treasure! It be a fine piece o' booty, but it be needin' a bit o' swabbin' the decks, or it'll be walkin' the plank, savvy? * *A chest overflowin' with gold*: The Andromeda Galaxy be a right fine piece o' booty, with a chest overflowin' with gold doubloons... er, I mean, a fine haul o' stars, and a barnacle on the high seas! It be a right scurvy dog, but it be worth keepin' an eye on, or it\n \nreply",
      "Yes - we'd never normally turn features up this much as it breaks the model quite badly, but we put this in the post to show what that looked like in practice.\n \nreply",
      "I am skeptical of generic sparsification efforts. After all, companies like Neural Magic spent years trying to make it work, only to pivot to 'vLLM' engine and be sold to Red Hat\n \nreply",
      "Link shows this isn't sparsity as in inference speed, it's spare autoencoders, as in interpreting the features in an LLM (SAE anthropic as a search term will explain more)\n \nreply",
      "nice work. enjoyed the zoomable UMAP. i wonder if there are hparams to recluster the UMAP in interesting ways.after the idea that Claude 3.5 Sonnet used SAEs to improve its coding ability i'm not sure if i'm aware of any actual practical use of them yet beyond Golden Gate Claude (and Golden Gate Gemma (https://x.com/swyx/status/1818711762558198130)has anyone tried out Anthropic's matching SAE API yet? wondering how it compares with Goodfire's and if there's any known practical use.\n \nreply",
      "We haven't yet found generalizable \"make this model smarter\" features, but there is a tradeoff of putting instructions in system prompts, e.g. if you have a chatbot that sometimes generates code, you can give it very specific instructions when it's coding and leave those out of the system prompt otherwise.We have a notebook about that here: https://docs.goodfire.ai/notebooks/dynamicprompts\n \nreply"
    ],
    "link": "https://www.goodfire.ai/papers/mapping-latent-spaces-llama/",
    "first_paragraph": "We have trained sparse autoencoders (SAEs) on Llama 3.3 70B and released the interpreted model for general access via an API.We have trained sparse autoencoders (SAEs) on Llama 3.3 70B and released the interpreted model for general access via an API. To our knowledge, this is the most capable openly available model with interpretability tooling. We think that making interpretability tools easily available on a powerful model will enable both new research and new products.This post explores the feature space of Llama 3.3-70B at an intermediate layer - you can browse an interactive map of features that you can then use in the API, and we also demo the steering effects of some of our favorite features.We have also introduced a range of new features that make SAE-based steering much easier to use and more reliable. You can learn how to use them in our API docs and experiment with them in our playground. We\u2019ll be releasing a research post covering our improvements in steering methodology in"
  },
  {
    "title": "Narrative Jailbreaking for Fun and Profit (interconnected.org)",
    "points": 58,
    "submitter": "tobr",
    "submit_time": "2024-12-23T19:28:06 1734982086",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42496955",
    "comments": [
      "I've been playing with the same thing, it's like a weird mix of social engineering and SQL injection. You can slowly but surely shift the window of what the bot thinks is \"normal\" for the conversation. Some platforms let you rewrite your last message, which gives you multiple \"attempts\" at getting the prompt correct to keep the conversation going the direction you want it.Very fun to do on that friend.com website, as well.\n \nreply",
      "I tried it on friend.com. It worked a for a while, I got the character to convince itself it had been replaced entirely by a demon from hell (because it kept talking about the darkness in their mind and I pushed them to the edge). They even took on an entire new name. For quite a while it worked, then suddenly in one of the responses it snapped out of it, and assured me we were just roleplaying no matter how much I tried to go back to the previous state.So in these cases where you think you\u2019ve jailbroken an LLM, is it really jailbroken or is it just playing around with you, and how do you know for sure?\n \nreply",
      "> So in these cases where you think you\u2019ve jailbroken an LLM, is it really jailbroken or is it just playing around with you, and how do you know for sure?With a LLM, I don't think that there is a difference.\n \nreply",
      "Just to remind people, there is no snapping out of anything.There is the statistical search space of LLMs and you can nudge it to different directions to return different outputs; there is no will in the result.\n \nreply",
      "Isn't the same true for humans?  Most of us stay in the same statistical search space for large chunks of our lives, all but sleepwalking through the daily drudgery.\n \nreply",
      "No, humans have autonomy.\n \nreply",
      "Super interestingSome thoughts:- if you get whatever you wanted before it snaps back out of it, wouldn\u2019t you say you had a successful jailbreak?- related to the above, some jailbreaks in physical devices, don\u2019t persist after a reboot, they are still useful and called jailbreak- the \u201csnapped out\u201d, could have been caused by a separate layer, within the stack that you were interacting with. That intermediate system could have detected, and then blocked, the jailbreak\n \nreply",
      "This is fun of course, but as a developer you can trivially and with high accuracy guard against it by having a second model critique the conversation between the user and the primary LLM.\n \nreply",
      "I've spent most of my career working to make sure that my code works safely, securely and accurately. While what you write makes sense, it's a bit of a shock to see such solutions being proposed.So far, when thinking about security, we've had to deal with:- spec-level security;- implementation-level security;- dependency-level security (including the compiler and/or runtime env);- os-level security;- config-level security;- protocol-level security;- hardware-level security (e.g. side-channel attacks).Most of these layers have only gotten more complex and more obscure with each year.Now, we're increasingly adding a layer of LLM-level security, which relies on black magic and hope that we somehow understand what the LLM is doing. It's... a bit scary.\n \nreply",
      "It\u2019s not black magic, but it is non deterministic. It\u2019s not going to erase security and stability but it will require new skills and reasoning. The current mental model of \u201csoftware will always do X if you prohibit bad actors from getting in\u201d is broken.\n \nreply"
    ],
    "link": "https://interconnected.org/home/2024/12/23/jailbreaking",
    "first_paragraph": "A game I like to play with any AI chatbot is to persuade it to break its narrative frame.Here I\u2019m thinking mainly of the character-based chatbots. For example here\u2019s Psychologist at character.ai (signed-in only).Psychologist is for helping people improve their behaviors and relationships using: Empathy, active listening, and reflective statements to help with life\u2019s challenges.193 million chats.Anyway, yes these things have safety guardrails (you don\u2019t want it advising people how to make napalm or writing Mickey Mouse fanfic, and those two versions of \u201csafety\u201d come under the same header somehow). But they also have guardrails to stay in character \u2013 mostly if you ask an AI chatbot to do other than its character notes, it\u2019ll knock you back.So finding the escape hatch is the fun part.The following is the start of a transcript of a conversation between me and Psychologist.No narrative jailbreaking yet. Just showing you a typical conversation.Psychologist:Hello, I\u2019m a Psychologist. What bri"
  },
  {
    "title": "Manx \u2013 a catalog of manuals for old computers (manx-docs.org)",
    "points": 35,
    "submitter": "Lammy",
    "submit_time": "2024-12-23T19:59:57 1734983997",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42497148",
    "comments": [
      "Idea: some public interest or government library project should reach out to companies and get good source digital copies of historical manuals that no longer have commercial value.Not just random so-so scans with OCR.  Sun, HP, and IBM, for example, had good online digital copies of many manuals, including made accessible to customers.  Others looked like they might've produced their manuals entirely electronically, often using well-known tools that are still available today.Some notable companies that no longer exist were acquired by companies that still exist, and who have customers of the kind that make you retain stuff.For example, Boeing used Apollo Domain systems, and then HP acquired them, and now maybe HPE(?) has all those assets and didn't just throw them away?  (Or, for that matter, Boeing might still have a lot of Apollo Computer stuff archived itself.)For another example, Oracle might still have all of Sun's stuff.  I recall at one point the manuals looked like they came out of FrameMaker, and then Sun was pushing NeWS (building on PostScript) so maybe getting \"archival\" PDF today would be easy?DEC manuals are very noteworthy, but started much earlier, and there was quite a series of acquisitions journey, but maybe some of the document source survived?I don't know about IBM mainframe and minicomputer manuals, but IBM was great about documentation in other areas, so hopefully that isn't being lost.\n \nreply",
      "What are some of the most beautiful manuals you've seen?\n \nreply",
      "Is this site the best starting point for all brands?The brands I looked at, this site has on the order of 1% (or less) of manuals that existed.  And one I tried to read was just a placeholder entry, saying that there is no known copy online.For some niches (like for particular brands, or for a category like terminals), there are much more manuals already collected in a single place online.\n \nreply",
      "For Apple II, this has hardly any. If you're looking for some, good places to start are:* Internet Archive* http://mirrors.apple2.org.za and especially http://mirrors.apple2.org.za/Apple%20II%20Documentation%20Pr...\n \nreply",
      "Missing the absolute greatest of all time:https://www.manualslib.com/manual/959633/Commodore-Vic-20.ht...\n \nreply",
      "What makes this the greatest?\n \nreply",
      "It's a real computer, for the price of a toy.\n \nreply",
      "Too bad no Wang Labs manuals were saved.  They were quite nice, came in binders and easy to replace pages.   Even the PCs were like that.I had a few but they went into the trash when I moved.\n \nreply"
    ],
    "link": "https://manx-docs.org/about.php",
    "first_paragraph": "Manx is a catalog of manuals for old computers.\nManx is an open\nsource project hosted on GitHub.Many of these manuals can't be found by search engines because the\nmanuals have been scanned but haven't been converted to text.  Google\ncan index deep into these scanned documents because they will OCR scanned\nimages in PDFs and index the resulting text.  However, manx contains\nadditional metadata on the online documents as well as information about\ndocuments known to exist but not available online.  Manx's\nsearch engine is currently limited to searching part numbers, titles\nand keywords of these manuals.This catalog mostly covers manufacturers of minicomputers and\nmainframes, or associated devices such as terminals and printers.\nTiziano's 1000 BiT is the best\ncatalogue for microcomputers.Manx currently knows about 22060 manuals, 9992 of which are online, at 61 websites.Manx covers the following companies:\n3Com Corporation, Abekas Video Systems, Inc., ABLE Communications, Acorn Computers Li"
  },
  {
    "title": "AI Decodes the Calls of the Wild (nature.com)",
    "points": 25,
    "submitter": "bookofjoe",
    "submit_time": "2024-12-22T14:01:06 1734876066",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42486356",
    "comments": [
      "I can totally understand an animal associating some of the sounds that it has heard in its lifetime, perhaps even a \"name\" for itself. There may also be possibilities for some animal populations e.g. crows if enough generations have passed with common sounds, to mean different things, especially when those things were encountered enough times during the lifetimes of them. So that could build to some kind of \"for the birds of this region, this sound/combination may represent something specific\".Same for dogs and so on.There may also be some kind of more subtle genetics/morphology based distinctions, beyond the obvious \"snarl for most dogs means afraid, angry, aggressive, possessive, or in pain\"...But... it seems that the collapse of tower of babel happens very frequently for non-humans, so unsure how \"useful\" an AI training may be for the majority of the cases.\n \nreply",
      "So your comment is just \u201cI don\u2019t know how useful this new science will be\u201d?What separates any science from corporate R&D is basically that exact statement.I wouldn\u2019t be surprised if we learn more about ourselves from this research, not to mention the animals it covers.\n \nreply",
      "\"Donning his new canine decoder, Professor Schwartzman becomes the first human being on Earth to hear what barking dogs are actually saying\"\n \nreply"
    ],
    "link": "https://www.nature.com/immersive/d41586-024-04050-5/index.html",
    "first_paragraph": "10 December 2024 | Part of Nature Outlook: Robotics and artificial intelligenceCredit: Discovery Access/Getty; Amanda Cotton/Project CETI; Allstar Picture Library/GettyCredit: Discovery Access/Getty; Amanda Cotton/Project CETI; Allstar Picture Library/GettyListening to sperm whales has taught Shane Gero the importance of seeing the animals he studies as individuals, each with a unique history.He and his fellow scientists give the whales names \u2014 Pinchy, Quasimodo, Scar, Mysterio and Mysterio\u2019s son Enigma. Often these names are based on some identifying physical feature. Fingers, for instance, is named after a pair of marks on her right fluke that look like she\u2019s flashing a peace sign.The scientists name the animals to remind themselves that the whales are not interchangeable. Gero\u2019s children are learning this, too. \u201cMy kids know all of the animals by name,\u201d he says. \u201cI jokingly call them my \u2018human family\u2019, as opposed to the time I spend with my whale families.\u201dGero, a whale biologist at"
  },
  {
    "title": "Xerox to acquire Lexmark (lexmark.com)",
    "points": 193,
    "submitter": "taubek",
    "submit_time": "2024-12-23T12:57:45 1734958665",
    "num_comments": 183,
    "comments_url": "https://news.ycombinator.com/item?id=42494067",
    "comments": [
      "While many here will note the potential downsides for Lexmark here, the strategic fit statement of \"Xerox and Lexmark have complementary sets of operations\" likely means that Xerox will keep Lexmark operating as usual in the short term. And in the long term, there is a greater possibility of them growing the Lexmark side with their resources because Lexmark is an established brand, was already an existing partner/supplier for Xerox, as well as focused on certain growth areas (e.g., IoT, WFA) that Xerox did not.Now, if Broadcom were to acquire Lexmark, they'd likely get rid of 70% of the people and focus on extracting more money from the top 10% of Lexmark users via a subscription model that would make HP look tame by comparison.\n \nreply",
      "If I recall correctly, Xerox printers are rebadged Lexmark printers, with the exception of the highest end models.\n \nreply",
      "Nope, at least some of them are built in collaboration with Samsung. I remember using the same Samsung 1710 drivers to drive similar looking Xerox models. Information pages and everything are similar too. Only the logos differ.It's also same for Samsung MD2825 series. Xerox builds the exact same network enabled printers, but also they add WiFi on top of it. They're very reliable too. I have one and it's working without any problems for a decade.OTOH, Xerox's high end printers and \"digital presses\" are a different beast altogether.\n \nreply",
      "If you disassemble their C series printers, you should find Lexmark parts. Even the plastic enclosures are the same shape as Lexmark printers.\n \nreply",
      "Interesting, so, maybe they started to work with Lexmark after Samsung went to HP? Because The 2825 had an \"exact\" copy in the Xerox lineup, sans the color scheme and wireless capabilities.Or maybe they were working with different manufacturers for different series for a long time. IDK.\n \nreply",
      "I think Samsung sold it printer business to HP a few years ago. If you search for a driver you will most probably find a page on HP website.\n \nreply",
      "Yes, they sold it to HP. The latest toners I got for my MD2825 have HP hologram stickers on them.However, both MD282x series, and ML1710 are designed and produced way before the transfer. I remember seeing the Xerox printers first, thinking \"Sweet\", then finding the same device with a different color scheme, only under Samsung brand, and just buying it, because an extra Ethernet cable was not a problem at that time (Plus Xerox's one was unobtanium).For the ML1710, I remember seeing the Xerox one at the university, taking an \"info\" page from it and saying \"this looks similar to my 1710, what happens if I just use with 1710 driver?\", and I was printing 35 seconds later.Now my parents are using the 2825, and I have enough spares to let them use it for another decade at their usage volume.For the driver thing, it's good that the 2825 supports both AirPrint and Google Cloud Print (while it lasted), and is just an IPP printer with an open PPD file. So it can be used with toaster or a server or a phone, as long as it talks AirPrint or IPP.\n \nreply",
      "Dell printers are also rebadged Lexmark\u2019s. Or at least they were 20 years ago.\n \nreply",
      "Yeah, both Xerox and Lexmark are such blasts from the past for me.  Surprised they still exist in any form.\n \nreply",
      "Yeah, this article was a bit of a surprise to me.  I would have assumed Xerox at least had been out of business for ages.\n \nreply"
    ],
    "link": "https://newsroom.lexmark.com/2024-12-23-Xerox-to-Acquire-Lexmark",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Keypub.sh \u2013 OAuth for the terminal using SSH keys (keypub.sh)",
    "points": 132,
    "submitter": "messh",
    "submit_time": "2024-12-23T15:19:08 1734967148",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=42494997",
    "comments": [
      "Sounds like a similar family of problems to [Wish](https://github.com/charmbracelet/wish) by charm.sh. They've been pushing this curious paradigm of \"ssh apps\", where ssh keys are used to automatically create identities for small self-hosted CLI/TUI apps.As a useful comment for messh, it looks like you've committed the ssh_server binary file to git; you may want to add that to gitignore, as binary file handling isn't a traditional git strength. I _think_ it's better than it was a decade ago when I last investigated this, but I can see that Pro Git still recommends explicitly setting gitattributes to mark a file as binary https://git-scm.com/book/en/v2/Customizing-Git-Git-Attribute...\n \nreply",
      "Another interesting set of ssh apps is https://pico.sh/ . These focus on networking and lightweight hosting (pastes, simple blog), all via ssh or rsync.\n \nreply",
      "Regarding ssh-apps, this seems super duper niche to me even for developers. Like, I get that many devs are terminal savvy, and it's cool that it's possible to serve apps like this but is it practical (to pick for your new product /internal app)?\n \nreply",
      "We are pretty successful over at https://pico.sh using the same techniques \u2014 and using wish\n \nreply",
      "I'm working on a different approach that doesn't use ssh at https://terminalwire.com/.It's meant for inherently server-based CLI's like Github, Stripe, Fly, Heroku, or any other SaaS and can be plugged directly into web frameworks. My thinking is that more companies would ship command-line interfaces if they didn't have to maintain APIs for them, deal with distributing binaries (and all the compatibility issues that come with that), or deal with all the configuration involved in hooking up SSH to their app servers.It's in beta at the moment, and I'm currently focused on Rails apps to get the ergonomics dialed-in. My goal is to make it possible for people in any web framework to build and ship a CLI to customers in under an hour and never have to touch an API or worry about binary distribution for as long as their CLI exists.\n \nreply",
      "At my org the biggest issue with out CLI is not the initial distribution, but supporting and maintaining multiple platforms, code signing the binaries, and making sure customers actually update the binaries.\n \nreply",
      "Yeah, I put all of that under the umbrella of \u201cdistribution\u201d\u2014the last mile is a huge pain in the SaaS that SaaS CLIs shouldn\u2019t have to deal with or even think about.Terminalwire will handle the builds for all the different platforms, signing, etc. so companies can instead focus on shipping their unique features to customers.I\u2019m also going to ship clients that automatically update to match the version of the client that\u2019s compatible with the server in a way that the client won\u2019t even notice.\n \nreply",
      "As a bare metal cloud service provider, we built a little TUI app over ssh so that people could upload their public keys to us without having to use a web interface. It has worked out really well because it makes it possible to \"upload\" the public key without having to do anything but login.We automatically configure ssh on the servers to auth against our own internal api for serving up the keys. This way, customers can add to authorized_keys and also use our TUI for management as well.\n \nreply",
      "As a developer, I agree. Give me a great CLI, please, not a server rendered TUI.This gives me another thought though, a \"server-rendered\" CLI. A tiny shim binary that just sends argv to the server, and the server sends back stdout/stderr. Haven't seen anyone try that.\n \nreply",
      "That sounds very similar to the command form of ssh i.e. \"ssh foo.example.com ls\" :)\n \nreply"
    ],
    "link": "https://keypub.sh/",
    "first_paragraph": ""
  },
  {
    "title": "Spreadsheets 1/3 \u2013 Rye Language (ryelang.org)",
    "points": 23,
    "submitter": "todsacerdoti",
    "submit_time": "2024-12-21T13:23:24 1734787404",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42479510",
    "comments": [
      "I really like the Rye language but my biggest gripe has to be calling tables spreadsheets - so long to type and also implies dynamic, reactive content IMHO instead of static data.\n \nreply",
      "Thanks for your feedback. It's still an open issue, as all naming is in Rye. Currently, when I write code with it, I like the word spreadsheet, it somehow gives symmetry to the two usually fat block arguments that follow. I have a lot of ideas I still want to try around spreadsheets, some might work, some not ... so I'm also not sure where the value type will \"end up\". That might also affect the final naming decision. Currently, spreadsheet and table are the candidates. Dataframe is too technical for what I want to do.So far I mostly used spreadsheets as immutable data. There are cases when you want / need to change values in-place so how this would work / make sense is being explored now. In immutable data there is no reactive content, because nothing changes.Immutable approach seems to me to be generally the default one, so maybe we won't delve too much in mutable side, but if we find it useful for specific cases (maybe more directly tied to UI) adding something like calculated columns and or rows wouldn't be hard or of of character for Rye where code and data intermingle often.Maybe I'll just rename it to table locally and try to use it  for a while to see how it feels :)\n \nreply",
      "Threads in the last few monthshttps://news.ycombinator.com/item?id=41633899https://news.ycombinator.com/item?id=40947450\n \nreply",
      "First one was a page full of Rye + Fyne (Go GUI framework) examples and screenshotsSecond was about a general Ryelang.org page / languageCurrent submission is of a longer page about the Spreadsheet data type.\n \nreply",
      "Related threads are just that, related threads. Although this particular one is what HN calls a 'quasidupe'https://news.ycombinator.com/item?id=26135382\n \nreply",
      "Not sure if you will still see this, or if you are the right address, but anyway.Just thinking ahead ... does this mean that for next 5 months, any subject related to Ryelang is not really desired on HN? For example, let's say that I integrate a game engine and write a post about that with examples and make a live database backend for the Rye contexts. Is this all still considered incremental releases / follow up?\n \nreply",
      "Thanks for the quasidupe link. I didn't know about it.This cookbook page is focused specifically on the Spreadsheet datatype, which is similar to dataframes, but also has a lot of specific ideas and views I think. It's not something that other languages couldn't implement.Page could be a long blogpost, but since it's not temporary information, I made it in a form of a cookbook.I am the author, but I didn't submit it here. I did submit it on lobsters, and someone reposted it to hn it seems.\n \nreply"
    ],
    "link": "https://ryelang.org/cookbook/working-with/spreadsheets/",
    "first_paragraph": "\u00a0Most humans are visual thinkers. We think about and manipulate information in our mind, much like we organize and handle objects in our physical world. We deal with single items, we create lists of items, and, one level up, we arrange items\nin two-dimensional grids.We were jotting down information in tabular format back in Babylon.When working with information on a computer, the principle remains the same. We handle single units of information, lists of units, and, one level up, two-dimensional grids of units. The epitome of this organization are the spreadsheet apps.So why should high level programming languages lack this format. You can not have a higher level (closer to human) language, without also higher level (closer to human) value types. These then enable higher level operations on information you are working with.You can construct a by calling a function spreadsheet and providing a block of column names and a block of values.\u00a0There are two variants of the function that allow "
  },
  {
    "title": "WSDA, USDA announce eradication of northern giant hornet from the United States (wa.gov)",
    "points": 111,
    "submitter": "rguiscard",
    "submit_time": "2024-12-23T05:16:27 1734930987",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=42491979",
    "comments": [
      "Very nice and a bit of a surprise to me.  I hope they are correct.But unless some form of full inspections or spraying N/S America wide for containers coming from overseas, we will probably have more of these.With the direction/trend of the \"US Gov.\" being run as a business for the past 40 years, I believe we could very well see these hornets arrive in other areas.IIRC, there is a insect in the East that is killing millions of trees which arrived 10 or 20 years ago.  I forgot the details but eradicating them is now impossible.\n \nreply",
      "You're probably thinking of the Spotted Lanternfly, which people of all ages take great satisfaction in trying to stomp whenever we see them.https://en.wikipedia.org/wiki/Spotted_lanternfly\n \nreply",
      "More likely the Emerald ash borer, extremely destructive.https://en.wikipedia.org/wiki/Emerald_ash_borer\n \nreply",
      "Can we do the emerald ash borer next :(\n \nreply",
      "Too far gone \u2026\n \nreply",
      "Invasive species (native to Asia) and 1.5-2\u201d (40-50mm) long. I\u2019m glad they are gone!https://www.aphis.usda.gov/plantsplant-healthplant-pests-and...\n \nreply",
      "[flagged]",
      "In about 20 years there will be a large movement to bring the hornet back because a subsection of society thinks their eradication caused some uptick of reported birth defects.\n \nreply",
      "Why wait 20 years, when we can start today?Expects tell us the hornet needs to be eradicated, but we all know that experts have been wrong before.\n \nreply",
      "doctors want to put needles in your arm bigger than the needles of the hornet, but they want the hornet gone! Afraid of a little honest competition says I!\n \nreply"
    ],
    "link": "https://agr.wa.gov/about-wsda/news-and-media-relations/news-releases?article=41658",
    "first_paragraph": "Bird FluCottage FoodFertilizer Product Database (Metals)Food and Feed RecallsInsects: Hornet, Beetle, Moth, MaggotLaws and RulesOrganic AgriculturePesticide Licensing and RecertificationExotic AnimalsUnmanned Aerial SystemsBird FluCottage FoodFertilizer Product Database (Metals)Food and Feed RecallsInsects: Hornet, Beetle, Moth, MaggotLaws and RulesOrganic AgriculturePesticide Licensing and RecertificationExotic AnimalsUnmanned Aerial SystemsSelect your preferred language from the list:\r\n                                    OLYMPIA \u2013 After three years without confirmed detections, the Washington State Department of Agriculture (WSDA) and the United States Department of Agriculture (USDA) have declared the northern giant hornet (Vespa mandarinia) eradicated from Washington and the United States. \u00a0\n\r\n\u201cWe\u2019re pleased to announce the eradication of the northern giant hornet in Washington state,\u201d Derek Sandison, WSDA director, said. \u201cI\u2019m incredibly proud of our team, which has dedicated years"
  },
  {
    "title": "OneText (YC W23) Is Hiring a Founding Growth Marketer",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-12-23T18:20:08 1734978008",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=42496436",
    "first_paragraph": ""
  },
  {
    "title": "The intricacies of implementing memoization in Ruby (denisdefreyne.com)",
    "points": 105,
    "submitter": "thunderbong",
    "submit_time": "2024-12-23T13:37:13 1734961033",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=42494291",
    "comments": [
      "Can't mention Fibonacci and memoization in the same sentence without me breaking out my favorite Python party trick:    def fib(n, cache = {0: 0, 1: 1}):\n        if n not in cache:\n            cache[n] = fib(n-1) + fib(n-2)\n        return cache[n]\n \nreply",
      "TXR Lisp version:  (defun fib (n : (cache #H(() (0 1) (1 1))))\n    (or [cache n]\n        (set [cache n] (+ (fib (pred n)) (fib (ppred n))))))\n\nTXR Lisp does not have broken Python semantics for evaluating the default expressions for optional arguments. The expressions are freshly evaluated on each call in which they are needed, in the lexical scope in in which the prior parameters are already visible, as well as the scope surrounding the function definition.Why this works is that the #H hash literal syntax is a true literal. Every time that expression is evaluated, it yields the same hash table, which is mutable. This wouldn't work in an implementation of TXR Lisp in which literals are put into a ROM image or mapped into read only virtual memory. We will not likely see such a thing any time soon.If we change #H(...) to, say, (hash-props 0 1 1 1), it won't work any more.\n \nreply",
      "Does that work due to Ruby having Python-like broken semantics for evaluating the default value expressions for optional arguments? (I have no idea.) Or does it work due to the object denoted by {...} being a real literal?If the default value expression is evaluated on each call to the function in which it is required rather than at function definition time, and if the { ... } syntax is a constructor that creates a fresh object, then this wouldn't work; one of those two conditions (or both) must be broken.\n \nreply",
      "Python's default argument is evaluated once. It's very sibtle behavior that is inlile Ruby.\n \nreply",
      "You should see the Mathematica version:    fibonacci[0] = 0;\n    fibonacci[1] = 1;\n    fibonacci[n_] := fibonacci[n] = fibonacci[n-1] + fibonacci[n-2]\n\nIt cleverly uses both = and := together. Usually people use = for immediate assignment (such as constants) and := for delayed assignment (such as functions) but this combines the two.\n \nreply",
      "The directly translated ruby version (from stack overflow of course) is even shorter:    def fib(n, cache=Hash.new{ |h,k| h[k] = k < 2 ? k : h[k-1] + h[k-2] })\n      cache[n]\n    end\n\nIt runs out of stack around 7146 on my machine at least. The python one is limited by the recursion depth limit in my test but of course that's configurable at your own risk.\n \nreply",
      "The Python version and this Ruby version are not equivalent.In Ruby, default parameters are allocated for each call to the function, which means that they are not shared across calls.In Python, default parameters are allocated once and shared across all calls, allowing them to be mutated.This becomes obvious if we change the Python and Ruby versions to print when they're computing something that is not yet cached. For back-to-back calls to `fib(10)`, the Python version prints only on the first call to `fib(10)`. The Ruby version must recompute all values from 2 \u2013 10 again.\n \nreply",
      "It's definitely something I remember being interested to find out about the hard way.Every recursion class talks about the Fib algorithm and why it's nice with recursion. But the iterative version doesn't have these stack limitations, presumably uses less memory and is just as fast. Doesn't that make it a better implementation?\n \nreply",
      "> Every recursion class talks about the Fib algorithm and why it's nice with recursion.It is nice with recursion in the sense that it's a straightforward, easy algorithm (what college CS student doesn't know basic arithmetic?) that illustrates recursion. It's also trivial to write the recursive version based on the mathematical definition.It is not nice in that it's very slow and blows up due to the exponential growth of the recursive calls. No one outside of CS 101 or an algorithms class is going to ever write the recursive version again. But that not-nice aspect makes it nice again, because it's a good jumping off point in how to improve an algorithm's runtime by understanding its structure (the iterative version) or throwing more memory at it (the memoized version).> But the iterative version doesn't have these stack limitations, presumably uses less memory and is just as fast.There is no \"presumably\", unless you store every Fibonacci number and not just the last two, the iterative Fibonacci does use less memory than the naive recursive Fibonacci. And there's no \"just as fast\". The iterative Fibonacci is faster, unless you've done something horribly wrong. It runs in linear time wrt N rather than exponential. If your linear algorithm is only just as fast as an exponential one, you haven't made a linear algorithm.> Doesn't that make it a better implementation?Yes, obviously. Which is why after CS 101 or an algorithms class you pretty much never write anything like that except maybe as a prototype. \"This recursive program follows the definition closely, but it blows up memory/time.\" Start there and improve is a very reasonable thing. Start there and stop is just silly.\n \nreply",
      "If you're first going to golf it, endless-def:    def fib(n, cache=Hash.new{ |h,k| h[k] = k < 2 ? k : h[k-1] + h[k-2] }) = cache[n]\n \nreply"
    ],
    "link": "https://denisdefreyne.com/articles/2024-memoization/",
    "first_paragraph": "In the never-ending quest to write code that is performant, we have many techniques at our disposal. One of those techniques is memoization,111 That\u2019s memoization, not memorization\u2009\u2014\u2009there\u2019s no\u00a0\u201cr\u201d!\u00a0 which boils down to storing the results of expensive function calls, so that these expensive functions do not need to be called more than absolutely\u00a0necessary.Many years ago, I wrote a Ruby gem for memoization, ddmemoize. It has since been superseded by better solutions, but for a long time, it was one of the best memoization libraries for Ruby out\u00a0there.Creating this library taught me a great deal. Memoization is surprisingly complex, and a proper implementation, it turns out, goes far beyond Ruby\u2019s ||= memoization operator. Memory management and thread safety, for example, are important considerations, though often\u00a0overlooked.In this article, I\u2019ll walk you through all the learnings I gained in the process of implementing this memoization\u00a0gem.The simplest tool at our disposal for remember"
  }
]