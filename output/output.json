[
  {
    "title": "\"A Course of Pure Mathematics\" \u2013 G. H. Hardy (1921) [pdf] (gutenberg.org)",
    "points": 102,
    "submitter": "bikenaga",
    "submit_time": "2024-12-30T21:20:52 1735593652",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42553682",
    "comments": [
      "I read this book as a first-year undergrad. His style inspired me to go after rigour and proof and was a good start to serious mathematics. I always loved Hardy's work and Hardy and Wright's number theory text was also very nice through my PhD in algebra/number theory. I found Hardy's book much nicer than the contemporary calculus texts with irrelevant pictures and modern-day examples. Just straight math! Not for everyone, but it has classical, austere appeal for those who enjoy such things.\n \nreply",
      "Classical and austere, but not stilted. For instance...>>> We can state this more precisely as follows: if we take any segment BC on \u039b, we can find as many rational points as we please on BC.reads as a normal English sentence.As a student, I also preferred straight math. Proofs were what made math come alive for me. For applications of math, I had plenty of other sources such as physics, electronics, and programming, where the examples weren't forced.\n \nreply",
      "> As a student, I also preferred straight math. Proofs were what made math come alive for me. For applications of math, I had plenty of other sources such as physics, electronics, and programming, where the examples weren't forced.I guess the difference between us then is that I didn't care about applications.\n \nreply",
      "That's fair. Hardy himself was a zealot and in fact despised applications, writing that he hoped his work would never be put to extrinsic use, for then its value would become contingent on a particular stage of technological development.\n \nreply",
      "that's like studying medicine then not becoming a doctor\n \nreply",
      "Math can be an end unto itself. This can come as a bit of a surprise in our prevailing culture, which needs to justify the usefulness of everything. Also, it's possible for someone to study math as a liberal art, and develop the ability to do useful things with it on their own. My observation is that the people who grudgingly learned math as a means to an end, tend to forget most of it soon after graduating. This explains the widespread but paradoxical aversion to math among engineers.\n \nreply",
      "There are lots of medical researchers who don\u2019t treat patients.\n \nreply",
      "so like studying (human) biology and becoming a biologist\n \nreply",
      "Not becoming a patient-treating doctor.  Research doctors still matter a great deal in the field of medicine.\n \nreply",
      "It would be more useful to link to the Gutenberg page that shows links to the various formats:https://www.gutenberg.org/ebooks/38769\n \nreply"
    ],
    "link": "https://www.gutenberg.org/files/38769/38769-pdf.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Dumping Memory to Bypass BitLocker on Windows 11 (noinitrd.github.io)",
    "points": 170,
    "submitter": "supermatou",
    "submit_time": "2024-12-30T18:43:01 1735584181",
    "num_comments": 116,
    "comments_url": "https://news.ycombinator.com/item?id=42552227",
    "comments": [
      "I think you get the biggest advantage from BitLocker when you use TPM (PCR 7+11) with a PIN. That should mitigate the exploit because the FVEK should never be read without the PIN, and if BitLocker does it right (which I think it does) too many wrong PIN's results in the TPM going into dictionary attack lockout mode.Now I've been trying for months to do the same for Linux. There's systemd-cryptsetup/cryptenroll, but it's only for LUKS and I'm trying to encrypt a few sensitive directories on a super slow internal eMMC with fscrypt (keys for secure boot and /home). The TPM is _EXTREMELY_ hard to code for when things go beyond the basics:1. Bind to PCR 72. Bind to changing PCR 11 (changes whenever the kernel, init, cmdline etc. is updated)3. Use a PIN - but not the AuthValue, because I want to use the same authorization policy for resetting the DA lockout counter on login, and also have a long password/AuthValue for resetting the counter manually.4. Make it all work with PCR 11 signatures and public keys provided by systemd-stub.Maybe this isn't the right place to ask, but there's almost nothing but basic TPM guides out there, so if you're an expert I could really use your help. It's just for a personal project, but I'll write about it once I'm done - if I ever figure it out!\n \nreply",
      "Surely Windows keeps the FVEK in RAM regardless of whether the TPM requires a PIN to initially obtain it. Otherwise, wouldn't you need to enter your PIN every time a block from the disk needs decrypting? Not to mention the performance impact of calling the TPM on every disk operation.This attack reads the key from RAM, so I don't see how a TPM PIN would mitigate it.\n \nreply",
      "The point is that the TPM PIN prevents the attack if the system is powered off when the attacker obtains it.If the TPM doesn't have a PIN, this attack works even if the attacker obtains the system when it's powered off. They can start the computer, proceed to the Windows logon screen (that they can't get past and that hence prevents them from exfiltrating data from the running system), then just reset the computer and perform this attack to obtain the encryption key. This obviously doesn't work if the PIN prevents Windows from ever even starting.\n \nreply",
      "Correct, unless you're using a self-encrypting drive the FVEK sits in RAM once it's been released by the TPM during boot. The TPM is only a root of trust; for fast crypto operations without keeping the key in kernel memory you would need something like Intel SGX or ARM TrustZone.\n \nreply",
      "BitLocker no longer leverages SED by default due to vulnerabilities in drive manufactures firmware as of Sept 2019.> Changes the default setting for BitLocker when encrypting a self-encrypting hard drive. Now, the default is to use software encryption for newly encrypted drives. For existing drives, the type of encryption will not change.https://support.microsoft.com/en-us/topic/september-24-2019-...https://nvd.nist.gov/vuln/detail/CVE-2018-12037\n \nreply",
      "Holy crap.https://threadreaderapp.com/thread/1059435094421712896.htmlThis is amazing.> The encrypted SSD has a master password that\u2019s set to \u201c\u201dHN discussion here: https://news.ycombinator.com/item?id=18382975Original paper here: https://cs.ru.nl/~cmeijer/publications/Self_Encrypting_Decep...\n \nreply",
      "If you can short the reset pins while the computer is running and make it restart without losing power, then yes, I agree. But if you have to shut down to make your modifications, then you won't get past the PIN prompt.\n \nreply",
      "Why? It means you'll only get one shot at the attack, but nothing here is intrinsically prevented by using a TPM PIN (or even a non-TPM password, the attack doesn't depend on TPM-based Bitlocker in any way other than if the target machine is powered off or your first attempt fails)\n \nreply",
      "I wouldn't underestimate that a PIN prevents this attack on machines that are powered off.You can then go further up the chain with a UEFI settings password and no usb booting. If the password is hard to decrypt, then that's a pretty good approach.Then there's custom Secure Boot certificates that replaces the ones from MS. It'll work for Linux, not sure about BitLocker. But my Surface tablet doesn't even support custom sb certs.\n \nreply",
      "Might need most of PCRs 0-7.  Isn\u2019t PCR 4  used to measure the EFI executable booted by UEFI?Avoid GRUB, difficult to secure with it.Kernel updates will also be painful\u2026\n \nreply"
    ],
    "link": "https://noinitrd.github.io/Memory-Dump-UEFI/",
    "first_paragraph": "In this article I will demonstrate how to bypass BitLocker encryption on Windows 11 (version 24H2).\nThis was accomplished by extracting full volume encryption keys (FVEK) from memory using my tool Memory-Dump-UEFI.If an attacker has physical access to the device, they can potentially get access by \napruptly restarting the computer and dumping RAM from recently running instances of Windows. The captured\nmemory can be analyzed to locate sensitive information like FVEK keys.\nThis technique is not foolproof as the contents of RAM will rapidly degrade when power is cut off.\n\nThere are several techniques to mitigate this memory degradation, including cooling the RAM physically or using\nexternal power sources to maintain power delivery. In the case of this demo, I shorted the reset pins on the device\u2019s\nmotherboard, which causes the system to abruptly restart without losing power.Another potential issue is secure boot, which is a security standard that restricts what is allowed to run when\na d"
  },
  {
    "title": "I Wrote a Game Boy Advance Game in Zig (jonot.me)",
    "points": 44,
    "submitter": "tehnub",
    "submit_time": "2024-12-30T21:51:33 1735595493",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42553949",
    "comments": [
      "> I started using Linux five years ago, mainly because I couldn\u2019t figure out how to get Python working on WindowsWindows being by far the most dominant operating system from 97-2015 definitely exacerbated a dearth in knowledge among the young. In the early days internet access was not ubiquitous and shipping an operating system without even a primitive programming environment definitely lead to missed years of programming for me.I learned a lot about windows, lots of UIs and how the system was constructed somewhat, but no visual studio, no functioning compiler in base and the only interpreter being fucking batchfiles with no docs\u2026 come on\u2026\n \nreply",
      "windows 95 did come with Qbasic for MS-DOS. it wasn't the latest and greatest, but it did contribute to a moderately large online scene of kids making Qbasic games or Windows-like Qbasic GUIs for DOS.\n \nreply",
      "That's where I got started, copying basic code from the back of Boy's Life magazine, before I had a modem. I'm sure I'm not the only one here!\n \nreply",
      "When I was first getting started with programming in about 2008, I found it to be so unbelievably frustrating. Any tutorial I was following would invariably run into something that didn't work how it was supposed to. I would try to find some work around, and sort of would, but it would lead to other unforeseen issues down the line. I finally came across cygwin, and that sort of made things start to work.Eventually, though, I just installed a linux partition and literally never looked back. The entire ecosystem of everything I was learning at the time (Python, JS, PHP) was set up for unix. Things have improved over time, and obviously WSL is nice, but it's still a pain.\n \nreply",
      "This is really interesting. As an aside, someone has created a GBA toolchain for the Nim language as well. It's really cool seeing these projects for a variety of languages.https://github.com/exelotl/natu\n \nreply",
      "Interesting post. I wish it went deeper but I guess it's just a post-mortem.Related, I found this old post that goes into the basics of GBA coding [1]. It doesn't look nearly as bad as I expected. That said I'm sure performance might be the issue once you start having a few things going.If you have a good resource please let me know (I prefer C).Edit: also this library [2].[1] http://www.loirak.com/gameboy/gbatutor.php[2] https://www.coranac.com/tonc/text/toc.htm\n \nreply",
      "This was an interesting read, thanks.One nit on mobile (Firefox and Chrome, Android), your code blocks overflow the background instead of scrolling.\n \nreply",
      "in safari as well\n \nreply",
      "For the upper right quadrant, something like a Silicon Graphics might fit.\n \nreply"
    ],
    "link": "https://jonot.me/posts/zig-gba/",
    "first_paragraph": ""
  },
  {
    "title": "Beyond Gradient Averaging in Parallel Optimization (arxiv.org)",
    "points": 39,
    "submitter": "shinryudbz",
    "submit_time": "2024-12-30T22:24:51 1735597491",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42554209",
    "comments": [
      "> We show this technique consistently outperforms validation accuracy, in some cases by up to 18.2\\% compared to traditional training approaches while reducing the computation required nearly an order of magnitude because we can now rely on smaller microbatch sizes without destabilizing training.The accuracy improvement is great, but I'm really looking forward to the reduction in computation required!\n \nreply",
      "Yes it will allow stable training at much smaller batch sizes. Test it out and let us know if it works for your use case!\n \nreply",
      "As someone who only has a passing understanding of parallel training, I always found it wonderful that averaging gradients works at all. It seems non-intuitive to me.Pretty cool, imho, that there are finding better ways to train in parallel.\n \nreply",
      "Co-author here. Super excited to see this work posted on HN!Happy to answer questions.\n \nreply",
      "From a non-expert here (maybe a dumb question): does \u201cbatching\u201d affect quality in a similar way as averaging parallel batches?  (Like is there a difference between having a batch that is 10x the size versus averaging 10 batches that were calculated in parallel?)\n \nreply",
      "Here too!\n \nreply",
      "Is this the paper that the cohost of 'Last Week in AI' said was the paper of the quarter to read back to front?\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2412.18052",
    "first_paragraph": "The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy.Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "I keep turning my Google Sheets into phone-friendly webapps, and I can't stop (arstechnica.com)",
    "points": 9,
    "submitter": "cpeterso",
    "submit_time": "2024-12-30T06:25:01 1735539901",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arstechnica.com/gadgets/2024/12/making-tiny-no-code-webapps-out-of-spreadsheets-is-a-weirdly-fulfilling-hobby/",
    "first_paragraph": "\n        How I tackled takeout, spices, and meal ideas with spreadsheets and Glide.\n      It started, like so many overwrought home optimization projects, during the pandemic.My wife and I, like many people stuck inside, were ordering takeout more frequently. We wanted to support local restaurants, reduce the dish load, and live a little. It became clear early on that app-based delivery services like DoorDash and Uber Eats were not the best way to support local businesses. If a restaurant had its own ordering site or a preferred service, we wanted to use that\u2014or even, heaven forfend, call the place.The secondary issue was that we kept ordering from the same places, and we wanted to mix it up. Sometimes we'd want to pick something up nearby. Sometimes we wanted to avoid an entire category (\"Too many carbs this week, no pasta\") or try the newest places we knew about, or maybe a forgotten classic. Or just give me three places randomly, creative constraints, please\u2014it's Friday.At its core,"
  },
  {
    "title": "Jack Elam and the Fly in 'Once Upon a Time in the West' (au.dk)",
    "points": 50,
    "submitter": "chimpanzee",
    "submit_time": "2024-12-30T20:46:38 1735591598",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42553313",
    "comments": [
      "This is the beginning of a very good movie.  It is on my top 10 all-time best movies.  I watch it from time to time and see new things each time.I don't remember where I read the story, but it might have been in the DVD extras.  Henry Fonda grew a goatee and dyed his hair black before he flew to Spain for the start of filming.  When he got there and Leone saw him he screamed \"nooooo\" because he hired Fonda to be the baby-faced assassin.Also, aside from the visuals, the music in this film is probably the best match between music and video ever.  Ennio Morricone's soundtrack is pure genius.\n \nreply",
      "> the music in this film is probably the best match between music and video everI presume you're talking about the mood of the music matching with the video, but they match in another way as well. Undoubtedly you already know this, but I wanted to add for people who don't: the music was composed first, and was played during filming, allowing the actors to synchronize their movements with the music.The bit about Henry Fonda changing his appearance and Sergio Leone not agreeing with that: I think you're right it's on the DVD. There's a separate soundtrack with comments from various people while the movie is playing, and I /think/ it's in there somewhere, but I'm not 100% sure. They also talk about how Henry Fonda was very famous at the time, famous for playing the good guy. Seeing him playing the bad guys had quite a shocking effect on audiences, which was Leone's intention. A bit like Tom Hanks suddenly playing a vicious assassin (more relatable for people my age).\n \nreply",
      "The scene discussed:https://youtu.be/QML28YQBvycAnd the excellent scene that follows (after the train stops without any passengers departing, or so the gang thinks):https://youtu.be/uhYLfK8GSr0\n \nreply",
      "You brought two to many horses...\n \nreply",
      "Just adding another comment to say how brilliant this film is. So atmospheric, such great music, such a grand presentation of the wild west and it's demise. It makes other westerns feel half-baked.\n \nreply",
      "Such a fabulous movie. I searched, it's available on amazon prime in the us until Jan 1 it says(with limited interruptions...?).I want to see movies this great again - you can, but only with streaming. No CGI here but maybe a little syrup on Jack Elam's face ;-)\n \nreply",
      "The HDR on the 4k version of this movie is hideous.I'd recommend watching the disc in SDR mode.  It looked great that way.\n \nreply",
      "Interestingly, the AVForums review says HDR is the reason (if any) to prefer it. (\"WCG\" below is \"Wide Color Gamut\".)> The biggest reason for sticking with your purchase is probably the application of WCG and Dolby Vision HDR, with the image now a lush \u2014 but faithful \u2014 palette that enjoys those sun-burnt skin tones (a few pink lips look kinda odd on occasion, but for the most part it's well handled) dominating wood browns, dirty desert backgrounds and often stunning blue skies. Black levels are rich and deep, but don't swallow up all the shadow detail, and the film \u2014 in comparison to the old blu-ray \u2014 looks a whole lot more \"4K\" given what we've come to expect from the benefits of WCG and HDR, to the point where it'll likely end up being the default playback for those pot committed on this release.\n \nreply",
      "One of my all-time favorite movies.\n \nreply"
    ],
    "link": "https://pov.imv.au.dk/Issue_24/section_1/artc4A.html",
    "first_paragraph": "Introduction\r\nOne of the scenes most often singled out for special mention even in the briefest discussions of Once Upon a Time in the West, involves a fly and the legendary character actor Jack Elam, the wall-eyed heavy who was aptly described as:grizzled and stringy-haired and one of his eyes always seemed to be trying to roll around so it could look behind his head. He was the sort of shifty character who might shoot the family dog or dunk a bawling baby in hot water just for kicks. [1] In this film his character's name is \"Snakey,\" which suitably evokes the reptilian quality of the part.The extraordinary set-piece with the fly begins about six minutes into the opening credit sequence after the three gunmen, played by Elam, Woody Strode and Al Mulock, have taken over an isolated railroad station and are waiting for a train to arrive.Elam is seated in a rocking chair on the porch of the station. His face looks chronically unwashed and is covered with beard stubble. Having just been a"
  },
  {
    "title": "Lightstorm: Minimalistic Ruby Compiler (llvm.org)",
    "points": 13,
    "submitter": "eutropia",
    "submit_time": "2024-12-30T22:58:26 1735599506",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.llvm.org/posts/2024-12-03-minimalistic-ruby-compiler/",
    "first_paragraph": "LLVM Project News and Details from the TrenchesSome time ago I was talking about an ahead-of-time Ruby compiler.\nWe started the project with certain goals and hypotheses in mind, and while the original compiler is at nearly 90% completion, there are still those other 90% that needs to be done.In the meantime, we decided to strip it down to a bare minimum and implement just enough features to validate the hypotheses.Just like the original compiler we use MLIR to bridge the gap between Ruby VM\u2019s bytecode and the codegen, but instead of targeting LLVM IR directly, we go through EmitC dialect and targeting C language, as it significantly simplifies OS/CPU support. We go into a bit more details later.The source code of our minimalistic Ruby compiler is here: https://github.com/dragonruby/lightstorm.The rest of the article covers why we decided to build it, how we approached the problem, and what we discovered along the way.Our use case is pretty straightforward: we are building a cross-plat"
  },
  {
    "title": "Coding Font Selection 'Tournament' (daringfireball.net)",
    "points": 50,
    "submitter": "tosh",
    "submit_time": "2024-12-27T07:51:30 1735285890",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=42520601",
    "comments": [
      "Though it's not actually a vector font, I've always liked the aesthetics of Fixedsys. And I still do.\n \nreply",
      "The link to the tournament looks so much like a header (which I assumed would just be a permalink to the blog post that I am reading) that I spent a full minute looking for it\n \nreply",
      "Thank you!\n \nreply",
      "I don't think this was always owned by Typogramhttps://news.ycombinator.com/item?id=29010443https://news.ycombinator.com/item?id=29028660And to bypass the blogspam: https://www.codingfont.com/\n \nreply",
      "The Site is very slow on my Safari 17.6, Chrome and Firefox worked much better.\n \nreply",
      "Not that anyone asked, but after using and enjoying Inconsolata for the last decade I\u2019ve come to really love S\u00f6hne Mono in the last few months.Ref: https://klim.co.nz/retail-fonts/soehne-mono/\n \nreply",
      "Its so dependent on font size (or more accurately PPI) that its hard to pick. On my current monitor my favorite Berkely Mono looks thin and hard to read unless I bump up the size higher than I'd like. But drag it over to a Retina screen and it looks fantastic.\n \nreply",
      "I became an Iosevka convert this year. If there are things about it you don't like, you can likely build a custom variant that fixes those things. There are 54 variants for the zero character, for example. Pick your poison.\nhttps://typeof.net/Iosevka/\n \nreply",
      "I use it for a few years already. It is not an option in this game, right?I got Nanum Gothic Coding, but couldn\u2019t find a good site to compare it with Iosevka side by side to check if they are similar\n \nreply",
      "I mean, if it were, it would always win...\n \nreply"
    ],
    "link": "https://daringfireball.net/linked/2024/12/24/coding-font-selection-tournament",
    "first_paragraph": "By John\u00a0GruberDue \u2014 never forget anything, ever again.Via Jason Snell (back in October), who points first to this thread on Mastodon where a few of us posted about our preferences for the fonts we use for writing, and then describes this fun \u201ctournament\u201d from Typogram that lets you pick your favorite monospaced coding font from 32 choices. One limitation is that the only options are free fonts\u2009\u2014\u2009some of my favorite monospaced fonts aren\u2019t free and thus aren\u2019t included (e.g. Consolas,  Berkeley Mono, or Apple\u2019s SF Mono). Another limitation is that some of the fonts in the tournament just plain suck. But it\u2019s really pretty fun.It\u2019s also a good thing I procrastinated on linking to this for two months\u2009\u2014\u2009it\u2019s improved greatly in the weeks since Snell linked to it. The example code is now JavaScript, not CSS, which is a much better baseline for choosing a programming font. And there are some better font choices now.I highly recommend you disable showing the font names while you play, to avoi"
  },
  {
    "title": "LineageOS 22 Released (lineageos.org)",
    "points": 28,
    "submitter": "timschumi",
    "submit_time": "2024-12-31T00:12:29 1735603949",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42555066",
    "comments": [
      "I still buy devices based on the likelihood that they will be supported by LineageOS. Good to see them continuing along.\n \nreply",
      "Thanks for the link! LineageOS has kept my 7-ish year old Moto X4 working like a champ for most of the time I've had it! As long as it keeps working, I have no intention of getting another phone.\n \nreply",
      "Highly recommend the Samsung S5e Tablet with LineageOS. It\u2019s an amazing tablet for comics and light reading. Hard to beat its high res AMOLED display, incredibly light weight, and decent enough specs (I haven\u2019t personally seen slowdowns when using Lineage on a minimal install). Forgoing gapps gets you crazy standby time.Couple things to note is it doesn\u2019t have a headphone jack (it is legitimately that thin though) and you are required to use Windows to flash the device.\n \nreply",
      "Have I ever got a bigger paycheck I'd donate to them without hesitation. It's because of them (and formerly Cyanogenmod) I got to have my Xperia Z1 for 7+ years, and now this Xperia 1ii for 4 years, each of them were/are doing great because of it.Hope they keep going strong.\n \nreply"
    ],
    "link": "https://lineageos.org/Changelog-29/",
    "first_paragraph": ""
  },
  {
    "title": "Learning Solver Design: Automating Factorio Balancers (gianlucaventurini.com)",
    "points": 132,
    "submitter": "kolui",
    "submit_time": "2024-12-27T17:32:56 1735320776",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42524130",
    "comments": [
      "This is a cool article! And it lead me down the path to another cool factorio compsci paper called 'The steady-states of splitter networks' where they really go into the theoretical properties of the belts and splitters.But I can't help to feel that the following paragraph should be removed, since it really seems to be a bit  confused about the concepts of both Np-complete and NP-hard.> Finding a feasible solution is NP-hard because we can't do any better than start placing the components on a 2D grid and check if the properties are respected. Furthermore, finding the optimal solution (i.e., minimum number of components) is NP-complete because it will require enumerating all the possible solutions in order to find the best one.\n \nreply",
      "It's a classic undergraduate student mistake when learning computational complexity: \"this problem is really hard, but I can represent it as SAT - well, it is NP-hard!\". Whereas what you need is to represent SAT as an instance of your problem! Otherwise computing XOR of two bits would be NP-hard, as I can write a SAT formula to express it.\n \nreply",
      "> we can't do any better than start placing the components on a 2D grid and check if the properties are respectedThat specifically seems to be the bit where the explanation goes wrong. Proving that there's no easier method than brute forcing is a hard problem, not something to wave away as an exercise for the reader.\n \nreply",
      "Actually, you can wave it away as an exercise to the reader, you just need to be careful how you formulate it.Something like 'Frobbing the fnutz might be NP-hard.  The proof via reduction of SAT is left as an exercise for the reader.'Not very reader friendly, but at least you haven't said anything wrong.\n \nreply",
      "Even when you get the direction correct-- e.g. that you could encode an arbitrary SAT problem as an instance of your problem... that doesn't mean that in practice most instances of your problem can't be solved to an arbitrarily good approximation quickly or even solved optimally in a reasonable amount of time.  It only means that in the worst case there is no efficient optimal solution or good approximation.I've repeatedly encountered people using crappy solutions to problems because they read some result from complexity theory that made them think they couldn't do better. .. when in reality a slightly smarter algorithm does much better on average.Consider for example the min cover problem: You have a set of bit vectors and you want to find the minimum collection where at least one vector is true for every bit. (e.g. optimizing a collection of tests).  There is a simple greedy algorithm-- include the vector that covers the most yet-uncovered bits.  There is a proof that this algorithm achieves the best possible worst case approximation error.But in practice this is a useless result. Worst case approximation error is driven by pathological inputs.  It's easy to come up with modifications of the greedy algorithm that significantly improve the quality of the solutions on average (or at least do in the sorts of real problems I've applied it to).\n \nreply",
      "Yes, \"NP-complete\" is not correct on the author's part and neither is \"NP-hard.\" \"NP-hard\" is the author's intent since the problem is solvable using a SAT solver but presumably has no polynomial algorithm (so it is harder than P but not as hard as NP), but NP-hardness actually requires the other direction to be true: for a problem to be NP-hard, an oracle for the problem needs to be able to solve everything in NP. NP-complete is a stricter condition that requires NP-hardness but also requires that the problem be in NP.The author was missing the words \"in NP\" if they are talking about complexity.\n \nreply",
      "SAT solvers have also been thrown at the Factorio belt weaving problem (which has in-game reasons to maximize).https://youtube.com/watch?v=2NKK_2v4jiE&lc=Ugx5goGzTGz-z1g8t...Search:\u201c @Jodmangel\n2 weeks ago\nI wrote a quick script to find the longest belt weave with an SAT solver. It finds your 32-tile bridge, but also a 34-tile one:The circles are the \"external\" belts and the squares the 34 \"internal\" ones. No longer solutions exist (unless I messed up the script, obviously).\u201d\n \nreply",
      "So I started building a solver for satisfactory for someone.  Code is on GitHub if you are bored. It can do similar things, as well as finding optimal recipes and such (like some websites do) but I did it to speed up their app where their current solving of graphical models can be quite slow (20 minutes to solve a model)\nI've tried a lot of approaches as a result, including going down the same paths.The balancer issue is different in particular but in my experience, for this kind of problem, using z3 and cvc5 give much faster result than mnilp solvers or cp-sat. On smaller models they are all quite fast. But as it gets larger it's actually much faster for me to binary search an optimal objective through sat with z3 or cvc5 than it is to ask most nlp solvers to optimize it.  I haven't tried gurobi or cplex of course.But I expect this is because of their ability to do really effective incremental solving so that binary searching the objective is very efficient (z3 has an optimizer and soft constraints but they do not advertise it as supporting non linear logic and I can get it to hang on some models)Especially for this type of problem, I would consider using an SMT solver and seeing how it doesIf you stick with Clos networks, a homegrown solver using bdds is probably quite fast and wildly memory efficient.\n \nreply",
      "im a factorio noob so just checking some intuitions> Example of 4 x 4 na\u00efve Throughput-Limited belt balancer. This is not what we want.is this because a slowdown on belt #1 doesnt then get filled by belts 3 and 4? so this isn't a properly completely rebalancing system?> 4 x 4 Throughput-Unlimited belt balancer. This is what we want.but then this is weird too. the top left tunnel entrance thingy goes down and then immediately up again. why? maybe it tunnels all the way to the top right, in which case it has the same exact flaw as the first throughput limited example that we didnt want -  belts 3 and 4 dont get to redistribute their stuff to it if belt 1 dies.\n \nreply",
      "A mixer can run at the full speed of its input belts (ie given two full belts input, it will output two full belts).In the naive solution you are effectively allocating a single belt output from each layer-1 mixer, so the system will run at half throughput. But the fan-out to a pair of mixers in layer-3 does mean that your 4 output belts are balanced, which might be good enough in some cases - for example of downstream smelters have lower capacity than the theoretical 4-belt max throughput.\n \nreply"
    ],
    "link": "https://gianlucaventurini.com/posts/2024/factorio-sat",
    "first_paragraph": "I find declarative programming fascinating: we just model the problem, describe the result we want, and an \u201coracle\u201d (a.k.a. solver) conjures a solution for us. A lot of smart people spent decades building solvers for different problem classes, and I wanted an excuse to go and play with some of these solvers to learn optimization tricks along the way.In this post, I describe what I learned solving a toy flow optimization problem with MIP and SAT solvers. I picked belt balancing from the Factorio video game. It looks innocuous at first, but it's in reality NP-hard complexity. It's possible to solve by hand small versions, allowing us to check correctness, but it quickly becomes impossible to humanly solve even for medium size balancers that are very useful in the game. What the majority of players do is use pre-built online solutions. The game incentivizes sharing designs, called blueprints, as a string, and there's a thriving community that comes up with clever solutions.Let's define th"
  },
  {
    "title": "I made a tiny library for switches and sum types in Lua (github.com/alurm)",
    "points": 10,
    "submitter": "alurm",
    "submit_time": "2024-12-30T07:08:03 1735542483",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/alurm/lua-match",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Minimalistic sum types and switches for Lua\n      How? With a tagging function.A minimal usage example:For a more thorough example, see example.lua.License: MIT.\n        Minimalistic sum types and switches for Lua\n      "
  },
  {
    "title": "Tell HN: John Friel my father, internet pioneer and creator of QModem, has died",
    "points": 761,
    "submitter": "AaronFriel",
    "submit_time": "2024-12-30T18:11:47 1735582307",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=42551900",
    "comments": [
      "I worked with John for a few years in the 1990s. This was during the heyday of BBSes, when he joined our small team at Mustang Software after Mustang bought Qmodem. John moved to Bakersfield California (with his family, including OP!) to be with us. John left a few years later due to I think business differences with management.John was personable and full of joy. He always loved a good joke. I remember the parties (not wild, we were pretty tame back then) we would have around the pool at his place. He was generous with his time.The story of Qmodem itself was a bit different. Qmodem for DOS was a one-man shareware business and was John's pride and joy. It was clear that he poured everything into that program. It was finely tuned and just worked. Times were changing though, and people were calling for a Windows version. Unfortunately, John was not interested in learning Windows programming, so Scott Hunter (now at Microsoft), Dan Horn, and I built Qmodem for Windows. It was good, but it really never had the same level of polish that John's work did. It was \"Qmodem\" in name only.After John left Mustang he also left Bakersfield and I lost touch with him. I'm sure he continued to make the people around him smile. Thank you for your time and contributions, John.\n \nreply",
      "In the mid 1990's, as a teen, I once was hired to cold call a bunch of software companies to contribute to some non-profit, and I recall calling Mustang Software.That was 30 years ago. I don't know who I talked to, but they were not too happy to have me on the phone lol. Sorry if that was you. and OP sorry about your father. I recall QModem well.\n \nreply",
      "I had two floppies: MSDos & QModem. With those two I could use BBS's to get everything else.\n \nreply",
      "I'm so sorry for your loss.Your father's contributions are immeasurable. Just reading the word \"QModem\" gave me an instant flashback to my youth. QModem was my gateway to the outside world.I grew up way out in the country. I was the 80s and I was pretty isolated from technology and didn't even know anyone who cared about it at first. I started tinkering with our home PC, and I finally purchased a modem and figured out how to connect to BBSs. This changed my life. I had many sleepless nights as teenager, connecting everywhere I could. QModem was like a fancy car that drove me anywhere I wanted to go.I became obsessed with learning and tweaking things. AT commands, autoexec.bat, QModem scripting. Whatever I could figure out to get maximum performance and fast download speeds. Because of Qmodem, I could download games, text files, and even talk with other people. This moment in time defined my future. I knew right then what I wanted to do with my life.I owe thanks to your father and what he built for my wonderful career, and 40 years of enjoying technology. Without something as easy to learn and reliable as QModem, who knows what path my life would have taken.\n \nreply",
      "John helped get me and my college roommate started with Linux system administration and web development three decades ago. We both grew up in in the town in Iowa where John lived, and my roommate had met him around the time we went to college in the mid nineties. We were both nerdy engineering majors who had gotten exposed to Unix through our college dial-up shell accounts, and we had managed to scavenge together enough computer parts \u2014 an old 386 motherboard, a discarded hard drive that just needed a molex connector soldered back onto it, a spare floppy drive \u2014 to assemble a computer just barely capable of running Linux.I remember lugging it all over to John\u2019s basement where he helped us install Slackware Linux from a giant stack of 5 1/4 floppies he had.Later, when John was running up a dial-up ISP in town, he let us park that server at his ISP, so we had a full Linux server of our own connected to a T1 with its own public IP address, and where we had root access and could experiment with running our own web and email servers and other such things. Back then in dial-up days, having a Linux server of our own on the Internet seemed unbelievable, and I will always be deeply appreciative to John for that opportunity.\n \nreply",
      "Qmodem was my favorite comm program during the BBS days, and it still is today when working with vintage computers. It was just nice to use. Its scripting language was the first I used and I find myself wishing there was a Linux comm program with scripting that worked that well. Long distance calls were expensive so I used a Qmodem script to call BBSs each morning to download my email before school.Just the last several months I've been using Qmodem scripting to make thousands of modem calls over VoIP to test downloads to see which models and ATAs work best.After I jumped back into the vintage BBS world I've been keeping an eye out for anything Qmodem. I recently just picked up a Qmodem manual on ebay that I wanted to scan and archive, because it's pretty rare to see.Not too long ago I saw where John had posted to a FB group he was working on a new DOS version of Qmodem, my first interaction with him. I was excited to see it be worked on again and hoped to see the new version.  Sad to see him go.\n \nreply",
      "Huh, interesting.  Are you publishing the results of that testing somewhere?\n \nreply",
      "QModem allowed me to explore the wonderful world of BBSs before the Internet was a thing. Having access to BBSs gave me a leg up when I got to University and got access to the Internet. BBSs are what got me seriously interested in computers and helped me launch a career in software development.Your Dad's legacy will be writing the software that opened doors for many of us when computers used to be a walled garden and talking to another person on a computer was still a foreign concept for the general population. Condolences on the loss of of your father but hopefully you can take comfort in the fact his legacy made the world a better place for PC users.Just wanted to add, found this YouTube video of your father launching QModem on an old PC: https://www.youtube.com/watch?v=Gs7XZs6jOhc\n \nreply",
      "QModem and then Telix were a window through which I explored another world as a young teenager with a budget modem with shaky MNP compatibility. In that world I eventually found friends, a wealth of knowledge, and a career. So thanks JF. RIP.ATH0.\n \nreply",
      "The family of modem data transfer software back then had Kermit, xmodem, ymodem, zmodem, UUCP scripts, and pro-quality tools like QModem and Telix, as you mentioned. I'm sure I've left some other modem data transfer tools out. QModem had a certain polish and stability to it.\n \nreply"
    ],
    "link": "item?id=42551900",
    "first_paragraph": ""
  },
  {
    "title": "Cook: Colliding with the SHA prefix of Linux's initial Git commit (lwn.net)",
    "points": 11,
    "submitter": "2bluesc",
    "submit_time": "2024-12-30T22:49:33 1735598973",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42554420",
    "comments": [
      "There were some plans to migrate to SHA256, but somehow it still hasn't happened.The practical upshot is a git commit hash is not enough l to know you are distributing/executing the legitimate code, as opposed to a malicious doppelganger. This is particularly important for tools that rely on it for dependency management, local caches, etc.\n \nreply",
      "The is not a full git commit hash collision.  It has to do with a git note which only needs to matche a 12 character prefix of the git commit.\n \nreply",
      "Compatibility between remotes using one or the other hasn't arrived yet, and git doesn't want to break compatibility. But you can create SHA256 one's today. [0][0] https://lwn.net/Articles/898522/\n \nreply",
      "First twelve and last twelve characters are the same:    $ echo -n retr0id_662d970782071aa7a038dce6 | sha256sum\n    307e0e71a409d2bf67e76c676d81bd0ff87ee228cd8f991714589d0564e6ea9a  -\n    \n    $ echo -n retr0id_430d19a6c51814d895666635 | sha256sum\n    307e0e71a4098e7fb7d72c86cd041a006181c6d8e29882b581d69d0564e6ea9a  -\n\n* Via: https://news.ycombinator.com/item?id=38668893\n \nreply",
      "Relatedly: Kees's keynote on Linux security from a month ago was great: https://www.youtube.com/watch?v=orO8czP5Bxw\n \nreply"
    ],
    "link": "https://lwn.net/Articles/1003797/",
    "first_paragraph": "\n\n\n\tThis is not yet in the upstream Linux tree, for fear of breaking\n\tcountless other tools out in the wild. But it can serve as a test\n\tcommit for those that want to get this fixed ahead of any future\n\tcollisions (or this commit actually landing).\n\n\nLWN looked at commit-ID collisions a few\nweeks back.\n\n\n to post comments\n            \n\nLWN looked at commit-ID collisions a few\nweeks back.\n\n\n to post comments\n            \n\n\n\n\nTotally something Case would do\n\n Posted Dec 30, 2024 22:39 UTC (Mon)\n                               by mricon (subscriber, #59252)\n                              [Link] (2 responses)\n      \n\n\n\nWhen I first met Case, it was at a conference in San Diego, when he was plugging in a WiFi router he brought with him from home into an outlet in the hallway. His stated reason was to hope that the SSID is added to the Apple/Google tracking databases, so next time someone drives by his house in Portland and registers his home wifi signal, the tracker would be confused.\n\nAnyway"
  },
  {
    "title": "Curl-Impersonate (github.com/lexiforest)",
    "points": 362,
    "submitter": "jakeogh",
    "submit_time": "2024-12-30T09:18:38 1735550318",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=42547820",
    "comments": [
      "The same author also makes a Python binding of this which exposes a requests-like API in Python, very helpful for making HTTP reqs without the overhead of running an entire browser stack: https://github.com/lexiforest/curl_cffiI can't help but feel like these are the dying breaths of the open Internet though. All the megacorps (Google, Microsoft, Apple, CloudFlare, et al) are doing their damndest to make sure everyone is only using software approved by them, and to ensure that they can identify you. From multiple angles too (security, bots, DDoS, etc.), and it's not just limited to browsers either.End goal seems to be: prove your identity to the megacorps so they can track everything you do and also ensure you are only doing things they approve of. I think the security arguments are just convenient rationalizations in service of this goal.\n \nreply",
      "> I can't help but feel like these are the dying breaths of the open Internet thoughI agree with the over zealous tracking by the megacorps but this is also due to bad actors, I work for a financial company and the amount of API abuse, ATO, DDoS, nefarious bot traffic, etc. we see on a daily basis is absolutely insane\n \nreply",
      "But how much of this \"bad actor\" interaction is countered with tracking? And how many of these attempts are even close to successfull with even the simplest out of the box security practices set up?And when it does get more dangerous, is over zealous tracking the best counter for this?I've dealt with a lot of these threats as well, and a lot are countered with rather common tools, from simple fail2ban rules to application firewalls and private subnets and whatnot. E.g. a large fai2ban rule to just ban anything that attempts to HTTP GET /admin.php or /phpmyadmin etc, even just once, gets rid of almost all nefarious bot traffic.So, I think the amount of attacks indeed can be insane. But the amount that need over zealous tracking is to be countered, is, AFAICS, rather small.\n \nreply",
      "I can tell you about my experience with blocking traffic from scalpers bots that were very active during pandemic.All requests produced by those bots were valid ones, nothing that could be flagged by tools like fail2ban etc (my assumption is that it would be the same for financial systems).Any blocking or rate limiting by IP is useless, we saw about 2-3 requests per minute per IP, and those actors had access to ridiculous number of large CIDRs, blocking any IP caused it instantly replace it with another.blocking by AS number was also mixed bag, as this list growed up really quickly, most of that were registered to suspicious looking Gmail addresses. (I feel that such activity might own significant percentage of total ipv4 space)This was basically cat and mouse game of finding some specific characteristic in requests that matches all that traffic and filtering it, but the other side would adapt next day or on Sunday.aggregated amount of traffic was in range of 2-20k r/s to basically heaviest endpoint in the shop, with was the main reason we needed to block that traffic (it generated 20-40x load of organic traffic)cloudflare was also not really successful with default configuration, we had to basically challenge everyone by default with whitelist of most common regions from where we expected customers.So best solution is to track everyone and calculate long term reputation.\n \nreply",
      "I've learned that Akamai has a service that deals with this specific problem, maybe this might interest you as well: https://www.akamai.com/products/content-protector\n \nreply",
      "Blocking scalper bot traffic by any means, be it by source or certified identification seems a lost cause, i.e. not possible because it can always be circumvented. Why did you not have that filter at point of sale instead? I'm sure there are reasons, but to have a battery of captchas and a limit on purchases per credit card seems on the surface much more sturdy. And it doesn't require that everyone browsing the internet announce their full name and residential address in order to satisfy the requirements of a social score ...\n \nreply",
      "The product they tried to buy what not in stock anyways, but their strategy was to constantly try anyways, so in case it would become in stock they would be the first to get it.\nIt was all for guest checkout, so no address yet to validate nor credit card.\nBecause they used API endpoints used by the frontend we could not use any captcha at this place because of technical requirements.As stated before the main reason we needed to block it was volume of the traffic, you migh imagine identical scenario for dealing with DDoS attack.\n \nreply",
      "> Because they used API endpoints used by the frontend we could not use any captcha at this place because of technical requirementsA time sensitive hash validating each request makes it a bit harder for them without significant extra work on your part. Address sensitive is much more effective but can result in issues for users that switch between networks (using your site on the move and passing between workers networks, for instance).\n \nreply",
      "Disabling guest checkout would have been my weapon of choice or at least requiring the user to enter an email address to so that they are notified when the product becomes available.\n \nreply",
      "> Because they used API endpoints used by the frontend we could not use any captcha at this place because of technical requirements.That doesn't compute... Captcha is almost always used in such setups.It also looks like you could just offer an API endpoint which would return if the article is in stock or not, or even provide a webhook. Why fight them? Just make the resource usage lighter.I'm curious now though what the articles were, if you are at liberty to share?\n \nreply"
    ],
    "link": "https://github.com/lexiforest/curl-impersonate",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An active fork of curl-impersonate with more versions and build targets.\n      \nNoteThis is a (slightly) more active fork of curl-impersonate.\nDifferences include:A special build of curl that can impersonate the four major browsers: Chrome, Edge, Safari and Firefox(In progress). curl-impersonate is able to perform TLS and HTTP handshakes that are identical to that of a real browser.curl-impersonate can be used either as a command line tool, similar to the regular curl, or as a library that can be integrated instead of the regular libcurl. See Usage below.When you use an HTTP client with a TLS website, it first performs a TLS handshake. The first message of that handshake is called Client Hello. The Client Hello message that most HTTP clients and libraries produce differs drastically from that of a real browser.If the server uses HTT"
  },
  {
    "title": "Execution units are often pipelined (xoria.org)",
    "points": 140,
    "submitter": "ingve",
    "submit_time": "2024-12-27T09:02:47 1735290167",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=42520861",
    "comments": [
      "My favorite illustrations for the concepts discussed here (in an accessible form, not the processor optimization manuals) has long been [0].For me, this really makes working with a modern microprocessor a science, as anyone who has written benchmarks knows -- it's difficult to reason about the complex behaviour and performance cliffs without testing.Another excellent example of the weirdness has to be JVM anatomy quarks [1][0] https://www.lighterra.com/papers/modernmicroprocessors/[1] https://shipilev.net/jvm/anatomy-quarks/\n \nreply",
      "The first link is very nice, worth of a submission of its own.\n \nreply",
      "https://hn.algolia.com/?query=Modern%20Microprocessors%20%E2...\n \nreply",
      "For x86 cores this is visible in Agner Fog's instruction performance tables: https://agner.org/optimize/#manualsThe latency shows after how many cycles the result of an instruction can be consumed by another, while the throughput shows how many such instructions can be pipelined per cycle, i.e. in parallel.\n \nreply",
      "I believe the throughput shown in those tables is the total throughput for the whole CPU core, so it isn't immediately obvious which instructions have high throughput due to pipelining within an execution unit and which have high throughput due just to the core having several execution units capable of handling that instruction.\n \nreply",
      "That's true, but another part of the tables show how many \"ports\" the operation can be executed on, which is enough information to concluded an operation is pipelined.For example, for many years Intel chips had a multiplier unit on a single port, with a latency of 3 cycles, but an inverse throughput of 1 cycle, so effectively pipelined across 3 stages.In any case, I think uops.info [1] has replaced Agner for up-to-date and detailed information on instruction execution.---[1] https://uops.info/table.html\n \nreply",
      "Shame it doesn't seem to have been updated with Arrow Lake, Zen 5 and so on yet.\n \nreply",
      "Yes. In the past new HW has been made available to the uops.info authors in order to run their benchmark suite and publish new numbers: I'm not sure if that just hasn't happened for the new stuff, or if they are not interested in updating it.\n \nreply",
      "FWIW, there are two ideas of parallelism being conflated here.  One is the parallel execution of the different sequential steps of an instruction (e.g. fetch, decode, operate, retire).  That's \"pipelining\", and it's a different idea than decoding multiple instructions in a cycle and sending them to one of many execution units (which is usually just called \"dispatch\", though \"out of order execution\" tends to connote the same idea in practice).The Fog tables try hard show the former, not the latter.  You measure dispatch parallelism with benchmarks, not microscopes.Also IIRC there are still some non-pipelined units in Intel chips, like the division engine, which show latency numbers ~= to their execution time.\n \nreply",
      "I don't think anyone is talking about \"fetch, decode, operate, retire\" pipelining (though that is certainly called pipelinig): only pipelining within the execution of a instruction that takes multiple cycles just to execute (i.e., latency from input-ready to output-ready).Pipelining in stages like fetch and decode are mostly hidden in these small benchmarks, but are visible when there are branch misprediction, other types of flushes, I$ misses and so on.\n \nreply"
    ],
    "link": "https://blog.xoria.org/pipelining/",
    "first_paragraph": ""
  },
  {
    "title": "The Homa Network Protocol (lwn.net)",
    "points": 59,
    "submitter": "harporoeder",
    "submit_time": "2024-12-30T20:04:58 1735589098",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=42552887",
    "comments": [
      "Various previous discussions:It's time to replace TCP in the datacenter position paper  https://news.ycombinator.com/item?id=33401480 https://news.ycombinator.com/item?id=42168997Review of Homa protocol https://news.ycombinator.com/item?id=28204808Review of Linux implementation of Homa https://news.ycombinator.com/item?id=28440542TCP vs. RPC part 1 https://news.ycombinator.com/item?id=34871670 part 2 https://news.ycombinator.com/item?id=34871710 part 3 https://news.ycombinator.com/item?id=35228716\n \nreply",
      "For broader context: SCTP is already in the kernel, solves many of the same issues and has been used in mobile core networks for decades.\n \nreply",
      "At least looking from the outside, SCTP is also kind of stupid in places due to its telecom origins, e.g. you get only as many data streams as you negotiated for at the start of the connection[1], because we just can\u2019t let circuit switching go.[1] https://www.rfc-editor.org/rfc/rfc9260.html#name-sequenced-d...\n \nreply",
      "As I understand it, SCTP is still a TCP-like stream protocol with sender-driven congestion control (using packet drops or ECN as a signal) and multipathing to deal with in-network congestion, while HOMA is aimed at fast RPC (1 packet request, 1 packet response) for short messages and has receiver-driven congestion control to deal with incast congestion at the receiver.SCTP still has TCP-like slow start and other things that HOMA seeks to avoid.\n \nreply",
      "SCTP is message oriented and allows explicit control over how reliable a message is. You can run a TCP-like stream over it but it is not required. Slow-start is unfortunately a thing. SCTP was designed with lossy networks in mind, just like other long-range network protocols, not overprovisioned pseudo ethernet with DCB.\n \nreply",
      "The connection establishment in SCTP is so much more heavyweight that I wouldn't really put them in the same category\n \nreply",
      "I haven't heard of it, but wikipedia makes it sound interesting:https://en.wikipedia.org/wiki/Stream_Control_Transmission_Pr...\n \nreply",
      "Without regard to the detailed background, design or analysis, the approach of plucking a concern out of the Network/Data Link layer (prioritization / QoS) and moving it up to the Transport is a remarkably simple / clever start.At least that's how I picture the start of the study of such a design.\n \nreply",
      "Congestion control has always(ish) been in the transport layer.\n \nreply",
      "TCP congestion control is a disaster. Setting DCTCP slightly improves things but for big slow pipes it can be impossible to get near line rate. Congestion control's intent also differs from QoS/CoS. It's also a 'reactive' design rather than a constructive one, usually a bad sign. Not to mention that TCP is itself really complex and susceptible to receiver resource exhaustion.Still getting into the reading here, but making my intuition a little bit more explicit, it seems that at least the design, but possibly the implementation of Homa actually hinges on datacenter switches QoS queues being configured with a policy to explicitly respect the receiver-assigned priorities... cool!\n \nreply"
    ],
    "link": "https://lwn.net/SubscriberLink/1003059/41b1d2ea281b6779/",
    "first_paragraph": "\n\n\nWelcome to LWN.net\n\nThe following subscription-only content has been made available to you \nby an LWN subscriber.  Thousands of subscribers depend on LWN for the \nbest news from the Linux and free software communities.  If you enjoy this \narticle, please consider subscribing to LWN.  Thank you\nfor visiting LWN.net!\n\n\n\n\n\n\n           By Jonathan CorbetDecember 30, 2024\n           \nThe origins of the TCP and UDP network protocols can be traced back a full\n50\u00a0years.  Even though networks and their use have changed radically\nsince those protocols were designed, they can still be found behind most\nnetworking applications.  Unsurprisingly, these protocols are not optimal\nfor all situations, so there is ongoing interest in the development of\nalternatives.  One such is the Homa\ntransport protocol, developed by John Ousterhout (of Tcl/Tk and Raft fame, among other accomplishments),\nwhich is aimed at data-center applications.  Ousterhout is currently trying\nto get a\nminimal Homa implementation"
  },
  {
    "title": "Short Message Compression Using LLMs (bellard.org)",
    "points": 159,
    "submitter": "chunkles",
    "submit_time": "2024-12-26T19:06:33 1735239993",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=42517035",
    "comments": [
      "The way this works is awesome. If I understand correctly, it's like that, given (part of) a sentence, the next token really in the sequence will be one predicted by the model among the top scoring ones, so most next tokens can be mapped to very low numbers (0 if the actual next token it's the best token in the LLM prediction, 1 if it is the second best, ...). This small numbers can be encoded very efficiently using trivial old techniques. And boom: done.So for instance:> In my pasta I put a lot of [cheese]LLM top N tokens for \"In my pasta I put a lot of\" will be [0:tomato, 1:cheese, 2:oil]The real next token is \"cheese\" so I'll store \"1\".Well, this is neat, but also very computationally expensive :D So for my small ESP32 LoRa devices I used this: https://github.com/antirez/smaz2\nAnd so forth.\n \nreply",
      "I'm pretty sure it doesn't use ranking. That leaves a lot of performance on the table. Instead you would use the actual predicted token probabilities and arithmetic coding.\n \nreply",
      "I supposed it used arithmetic coding with the ranking bacause they have a distribution easy to exploit: zero more likely, one a bit less and so forth. What's your guess? Unfortunately Bellard is as smart as hermetic. We are here guessing what should be a README file.\n \nreply",
      "The model gives you a probability distribution over the tokens. You could use that directly with arithmetic coding, but there are ways to convert that to a distribution over e.g. the next byte instead which would improve efficiency further by removing the redundancy in alternative token encodings. ts_zip does this, and README says this works similar to ts_zip.EDIT: Hm, or maybe ts_zip uses just the token probabilities directly. I thought it was slightly more efficient about it.\"The language model predicts the probabilities of the next token. An arithmetic coder then encodes the next token according to the probabilities.\"\n \nreply",
      "Oh, that makes sense! So they use the probability of the next token itself. Thanks for clarifying. Also clever trick about the multiple potential tokens to represent the same text.\n \nreply",
      "If you are going to zip the resulting file, it may be useful to have a lot of 0s.If you are going to send the result as is,\n Huffman coding (with some escape for unusal words(?)) will be better. I think even better than the other method that forgets the probabilities and then tries to compresd it.\n \nreply",
      "Just to clarify: even storing ranking, here would likely produce good results, but not as good as storing the probability, since it exploits better the ability of arithmetic coding to store this fractional intervals. But here the fundamental trick is that the LLM can compress the \"next in sequence\" information in a distribution that is much better to compress than the initial data itself.\n \nreply",
      "This is especially true for instance when you have two or more tokens that are about equally likely, or one token that is virtually certain, which ranking would obscure.\n \nreply",
      "Indeed.\n \nreply",
      "This is very similar to how many compression schemes work. Look up Huffman coding to begin with.https://en.wikipedia.org/wiki/Huffman_coding\n \nreply"
    ],
    "link": "https://bellard.org/ts_sms/",
    "first_paragraph": "\nts_sms works similarly\nto ts_zip. It uses a specific padding system\ncompatible with arithmetic coding so that the message length does\nnot need to be explicitly encoded.\n"
  },
  {
    "title": "RubyConf 2024: Cloud Native Buildpack Hackday (and other Ruby deploy tools, too) (schneems.com)",
    "points": 40,
    "submitter": "mohdsyam",
    "submit_time": "2024-12-27T07:11:54 1735283514",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42520470",
    "comments": [
      "Hi HN . This is my post. Somewhat surprised to see it on the front page.This post was written for an in person hackday for RubyConf, but it links out to some async tutorials for using Cloud Native Buildpacks like these ones that are programmatically generated to guarantee consistency and correctness. https://github.com/heroku/buildpacks/tree/main/docs#useSince that event, we\u2019ve added 8 tutorials for using CNBs with .NET, Go, Java (Gradle), Java (Maven), Node.JS, PHP, Python, Ruby, and Scala.Let me know if you\u2019ve got questions on either using a CNB to build an OCI image or anything about libcnb.rs or our Rust stack for buildpack development.\n \nreply",
      "Thank you for your long time work in Ruby comunity <3\n \nreply",
      "You are welcome!The event yielded a few commits to the Ruby CNB, but none to any other deploy or build tools.I left my session open ended and that resulted in a fix to a surprisingly difficult to debug problem in syntax suggest (runtime syntax parsing error tool I maintain). Thanks to Andy for pairing with me on it over the session https://github.com/ruby/syntax_suggest/pull/232.Overall the in-person hackday was long, but fun and rewarding.\n \nreply",
      "You could write this whole article with `s/cloud native//` and none of its meaning would change. Cloud native is meaningless.\n \nreply",
      "It's literally part of the name of the technology. https://buildpacks.io/\n \nreply"
    ],
    "link": "https://www.schneems.com/rubyconf-2024-hackday/",
    "first_paragraph": "\n\n\n  \u2776 Author of How to Open\n    Source (.dev). A book to take you from coder to contributor.\n  \u2777 Creator of CodeTriage, a free service helping developers contribute to open\n  source.\n  \u2778 Core committer to ruby/ruby.\n  \u2779 Married to Ruby, literally.\n\n    \u00a9 Richard Schneeman\n  I\u2019ve spent the last decade+ working on Ruby deploy tooling, including (but not limited to) the Heroku classic and upcoming Cloud Native Buildpack. If you want to contribute to a Ruby deployment or packaging tool (even if it\u2019s not one I maintain), I can help. If you want to learn more about Cloud Native Buildpacks (CNBs) and maybe get a green square on GitHub (or TWO!), keep reading for more resources.Note: This post is for an in-person hackday event at RubyConf 2024 happening on Thursday, November 14th. If you found this but are away from the event, you can still follow along, but I won\u2019t be available for in-person collaboration.If you\u2019re new to Cloud Native Buildpacks, it\u2019s a way to generate OCI images (like docke"
  },
  {
    "title": "'Obelisks': New Class of Life Has Been Found in Human Digestive System (sciencealert.com)",
    "points": 318,
    "submitter": "unkeen",
    "submit_time": "2024-12-30T08:12:48 1735546368",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=42547489",
    "comments": [
      "Cool :) I'm a co-author on this. AMA.This is now a peer-reviewed paper, published last month in Cell [https://www.cell.com/cell/fulltext/S0092-8674(24)01091-2].Obelisks are part of a larger research program we're developing at the University of Toronto + collaborators, see also: Virus-Viroid Hybrids paper [https://www.nature.com/articles/s41467-023-38301-2] and the Zeta-Elements [https://www.nature.com/articles/s41586-021-04332-2].Computational biology is driving a revolutionary expansion of our understanding of Earth's biodiversity. I believe Zeta-elements, Ambiviruses, and Obelisks are just the beginning. If you're interested, our \"Laboratory for RNA-Based Lifeforms\" (University of Toronto) is hiring passionate developers/post-docs/graduate students [https://www.rnalab.ca].Edit: OK going to call it for now. I'll check in later today if there's any outstanding questions.\n \nreply",
      "How do you know that they aren't waste/intermediate products of some other cell, as opposed to being something that reproduces?\n \nreply",
      "How would they exist/maintain themselves without it's DNA counterpart?\n \nreply",
      "ah, have you shown that there is no matching DNA in either the host or any of the bacteria that the host has?\n \nreply",
      ">Obelisks form their own phylogenetic group without detectable similarity to known biological agents.ababaian, does this truly mean no similarity to any other sequences, even virus/viroid?That seems very exciting, since my understanding is that we see a lot of conservation within the known branches of life, and don't discover new ones often!Though perhaps it's more common to find totally novel virus/viroids? How often do we find truly novel biological agents at the sequence level?\n \nreply",
      "To the limits of where our understanding of how \"entities\" are connected to one another (homology). Yes, there's nothing like them. You could make an argument they are \"viroid-like\" and there's a deeper evolutionary connection between viroids/viruses/plasmids, but the information theory to formally establish such a connection is not sufficiently developed. It's a worthy scientific problem!Is it common to find new viruses/viroids/biological agents? Well it certainly is starting to feel that way to me.\n \nreply",
      "> You could make an argument they are \"viroid-like\" and there's a deeper evolutionary connection between viroids/viruses/plasmids, but the information theory to formally establish such a connection is not sufficiently developed.The way it is phrased, insufficiently developed information theory is rather surprising. Did you mean to write that not enough genome data has been collected to formally establish a link, or are you actually stating that we have all the data but as a species have not sufficiently developed the mathematical subdiscipline of probability, information theory ?I could follow the first, but the latter?EDIT: I now believe you meant neither but more something along the lines of: we probably have plenty of data, and usual information theory should suffice, but we simply havent exhaustively applied the tools to collate the information and make the implicitly available data more explicitly manifest.\n \nreply",
      "We certainly have the data, too much so actually. I should correct the statement to say, we have insufficiently developed _applied_ information theory.We know how to quantify homology, it just has not been applied to sufficient depth to the field of RNA/viroid evolution to resolve how much of an RNA element with extensive secondary structure, or ribozyme is evidence of a homology vs. convergence. And how could we resolve the two? It's easy with protein sequences, tricky with protein structures, but deep RNA evolution? That's a mystery.\n \nreply",
      "in simple terms, it seems these are just rod-shaped RNA plasmids that encode a couple proteins and exist without any kind of membrane or coating, does that seem right? is it that elucidated?\n \nreply",
      "Sure, in a redutionistic sense. In the same light \"Hepatitis Delta Virus\" is an RNA plasmid, yet it causes liver cancer in humans. I err on the side that the simplicity of the genetic system should not deceive us into thinking it's trivial. The next 12 months of discoveries is what makes this so exciting.\n \nreply"
    ],
    "link": "https://www.sciencealert.com/obelisks-entirely-new-class-of-life-has-been-found-in-the-human-digestive-system",
    "first_paragraph": ""
  },
  {
    "title": "How Well Do LLMs Generate Code for Different Application Domains? (arxiv.org)",
    "points": 46,
    "submitter": "belter",
    "submit_time": "2024-12-30T17:51:35 1735581095",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42551660",
    "comments": [
      "20 years ago, one of my professors pointed out during a review that \"benchmark is not research.\" Now I see literally everywhere benchmarks with very basic conclusions. I'm not criticizing this particular work, but such publications are low-effort unless they point to something new.\n \nreply",
      "Benchmarks aren\u2019t research, but research is 75% benchmarks of some kind, in my experience at least.Have to know where you are to know where to go, and once you know where to go and go there, well you have to know where you are!\n \nreply",
      "Your professor was wrong (and his H index would be low today): https://neurips.cc/Conferences/2024/CallForDatasetsBenchmark...\n \nreply",
      "Am I reading the example correctly? The prompt is the same size as the generated code, and likely more difficult to understand? Why would you use that? Why would you use anything that includes a \"TODO\"?-- ignoring what I would consider \"weird\" in the code, I assume that's just style.The prompt is:This function performs a forward pass for a model, incorporating conditioning and time step information.It randomly selects time steps, applies learned conditioning if applicable, and processes the inputs according to the model's conditioning \nrequirements.Finally, it computes and returns the loss for the given inputs and conditioning.The ground truth (am I correct, this is the expected answer?) is:  def forward(self, x, c, *args, **kwargs):\n     t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=self.device).long()\n     logging.info(f'Random timestep t generated with shape: {t.shape}')\n     if self.model.conditioning_key is not None:\n         assert c is not None\n         if self.cond_stage_trainable:\n             c = self.get_learned_conditioning(c)\n         if self.shorten_cond_schedule: # TODO: drop this option\n             tc = self.cond_ids[t].to(self.device)\n             c = self.q_sample(x_start=c, t=tc, noise=torch.randn_like(c.float()))\n     return self.p_losses(x, c, t, *args, **kwargs)\n \nreply",
      "If a new programming language is created in the future, how long would it take the LLM to become proficient in it for everyday use?\n \nreply",
      "I hate this kind of ephemeral research that will be outdated in a few months. Instead of analyzing \"why\" at a fundamental level LLMs can or cannot do something, researchers just show what current models are or are not capable of.And often times the results are not replicable either.\n \nreply",
      "> However, existing code generation benchmarks primarily focus on general-purpose scenarios, leaving the code generation performance of LLMs for specific application domains largely unknown. In this paper, we introduce a new benchmark, MultiCodeBench, to fill this gap.This is about the benchmark they're introducing, which would have real uses for all subsequent models.\n \nreply",
      "The potential utility in the research is not so much the results but the benchmark itself.I haven\u2019t read the whole thing so I can\u2019t really judge whether this specific benchmark is useful, but if it is, every time a new model comes out they can run the benchmark and breathlessly report its improved performance.\n \nreply",
      "Well, science moves. It is because of research like this is will be outdated.Great you enjoy more foundational work!\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2412.18573",
    "first_paragraph": "The arXiv Privacy Policy has changed. By continuing to use arxiv.org, you are agreeing to the privacy policy.Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  }
]