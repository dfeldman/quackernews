[
  {
    "title": "Betty White's shoulder bag is a time capsule of World War II (si.edu)",
    "points": 64,
    "submitter": "thunderbong",
    "submit_time": "2025-10-17T04:28:46 1760675326",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=45613327",
    "comments": [
      "Thanks for sharing this, really fascinating stuff. I\u2019m glad her estate is willing to donate these sorts of things.reply",
      "(2023)reply",
      "Alternatively 1941-1945reply",
      "Or, if World War-indexed, 2.reply"
    ],
    "link": "https://americanhistory.si.edu/explore/stories/betty-white-world-war-ii",
    "first_paragraph": "Due to the government shutdown, we are temporarily closed. Please check back for reopening updates.On December 31, 2021, the beloved actress Betty Marion White Ludden (1922\u20132021) passed away at 99 years old, weeks shy of her hundredth birthday. Countless tributes and condolences from around the country poured in, honoring her and remembering her vast legacy. Even the U.S. Army tweeted about her passing, noting how Betty White had served as a member of the American Women\u2019s Voluntary Services (AWVS) during World War II.This past year, our museum acquired White\u2019s AWVS uniform, which she had kept all these years. The uniform\u2019s accompanying shoulder bag arrived in the museum filled with artifacts of White\u2019s wartime experience. The bag and its contents are a perfect time capsule, providing insight into life on the home front for White, fellow AWVS members, and the young servicemen White encountered before becoming a famous entertainer.When the United States entered World War II in December 1"
  },
  {
    "title": "Claude Memory (anthropic.com)",
    "points": 364,
    "submitter": "doppp",
    "submit_time": "2025-10-23T16:56:07 1761238567",
    "num_comments": 195,
    "comments_url": "https://news.ycombinator.com/item?id=45684134",
    "comments": [
      "I don't use any of these type of LLM tools which basically amount to just a prompt you leave in place. They make it harder to refine my prompts and keep track of what is causing what in the outputs. I write very precise prompts every time.Also, I try not work out a problem over the course of several prompts back and forth. The first response is always the best and I try to one shot it every time. If I don't get what I want, I adjust the prompt and try again.reply",
      "Strong agree. For every time that I'd get a better answer if the LLM had a bit more context on me (that I didn't think to provide, but it 'knew') there seems to be a multiple of that where the 'memory' was either actually confounding or possibly confounding the best response.I'm sure OpenAI and Antropic look at the data, and I'm sure it says that for new / unsophisticated users who don't know how to prompt, that this is a handy crutch (even if it's bad here and there) to make sure they get SOMETHING useable.But for the HN crowd in particular, I think most of us have a feeling like making the blackbox even more black -- i.e. even more inscrutable in terms of how it operates and what inputs it's using -- isn't something to celebrate or want.reply",
      "I'm pretty deep in this stuff and I find memory super useful.For instance, I can ask \"what windshield wipers should I buy\" and Claude (and ChatGPT and others) will remember where I live, what winter's like, the make, model, and year of my car, and give me a part number.Sure, there's more control in re-typing those details every single time. But there is also value in not having to.reply",
      "I would say these are two distinct use cases - one is the assistant that remembers my preferences. The other use case is the clean intelligent blackbox that knows nothing about previous sessions and I can manage the context in fine detail. Both are useful, but for very different problems.reply",
      "Both of you are missing a lot of use cases. Outside of HN, not everyone uses an LLM for programming. A lot of these people use it as a diary/journal that talks back or as a Walmart therapist.reply",
      "Walmart therapist?reply",
      "Anecdotally, LLMs also get less intelligent when the context is filled up with a lot of irrelevant information.reply",
      "This is well established at this point, it\u2019s called \u201ccontext rot\u201d: https://research.trychroma.com/context-rotreply",
      "Yeah, though this paper doesn't test any standard LLM benchmarks like GPQA diamond, SimpleQA, AIME 25, LiveCodeBench v5, etc. So it remains hard to tell how much intelligence is lost when the context is filled with irrelevant information.reply",
      "If I find that previous prompts are polluting the responses I tell Claude to \"Forget everything so far\"BUT I do like that Claude builds on previous discussions, more than once the built up context has allowed Claude to improve its responses (eg. [Actual response] \"Because you have previously expressed a preference for SOLID and Hexagonal programming I would suggest that you do X\" which was exactly what I wanted)reply"
    ],
    "link": "https://www.anthropic.com/news/memory",
    "first_paragraph": ""
  },
  {
    "title": "How memory maps (mmap) deliver faster file access in Go (varnish-software.com)",
    "points": 60,
    "submitter": "ingve",
    "submit_time": "2025-10-23T21:56:07 1761256567",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=45687796",
    "comments": [
      "It looks suspicious at 25x. Even 2.5x would be suspicious unless reading very small records.I assume both cases have the file cached in RAM already fully, with a tiny size of 100MB. But the file read based version actually copies the data into a given buffer, which involves cache misses to get data from RAM to L1 for copying. The mmap version just returns the slice and it's discarded immediately, the actual data is not touched at all. Each record is 2 cache lines and with random indices is not prefetched. For the CPU AMD Ryzen 7 9800X3D mentioned in the repo, just reading 100 bytes from RAM to L1 should take ~100 nanos.The benchmark compares actually getting data vs getting data location. Single digit nanos is the scale of good hash tables lookups with data in CPU caches, not actual IO. For fairness, both should use/touch the data, eg copy it.reply",
      "doing these sorts of benchmarks is actually quite tricky. you must clear the page cache by allocating >1x physical ram before each attempt.moreover, mmap by default will load lazy, where mmap with MAP_POPULATE will prefetch. in the former case, reporting average operation times is not valid because the access time distributions are not gaussian (they have a one time big hit at first touch). with MAP_POPULATE (linux only), there is long loading delay when mmap is first called, but then the average access times will be very low. when pages are released will be determined by the operating system page cache eviction policy.the data structure on top is best chosen based on desired runtime characteristics. if it's all going in ram, go ahead and use a standard randomized hash table. if it's too big to fit in ram, designing a structure that is aware of lru style page eviction semantics may make sense (ie, a hash table or other layout that preserves locality for things that are expected to be accessed in a temporally local fashion.)reply",
      "> For the CPU AMD Ryzen 7 9800X3D mentioned in the repo, just reading 100 bytes from RAM to L1 should take ~100 nanos.I think this is the wrong order of magnitude.  One core of my Ryzen 5 3500U seems to be able to run memcpy() at 10 gigabytes per second (0.1 nanoseconds per byte) and memset() at 31 gigabytes per second (0.03 nanoseconds per byte).  I'd expect a sequential read of 100 bytes to take about 3 nanoseconds, not 100 nanoseconds.However, I think random accesses do take close to 100 nanoseconds to transmit the starting row and column address and open the row.  I haven't measured this on this hardware because I don't have a test I'm confident in.reply",
      "100 nanoseconds from RAM is correct.  Latency != bandwidth.  3 nanoseconds would be from cache or so on a Ryzen.  You ain't gonna get the benefits of prefetching on the first 100 bytes.reply",
      "Yes, my comment clearly specified that I was talking about sequential reads, which do get the benefits of prefetching, and said, \"I think random accesses do take close to 100 nanoseconds\".reply",
      "Yeah, 3.3ns is about 12 CPU cycles. You can indeed create a pointer to a memory location that fast!reply",
      "the downside is that the go runtime doesn't expect memory reads to page fault, so you may end up with stalls/latency/under-utilization if part of your dataset is paged out (like if you have a large cdb file w/ random access patterns).  Using file IO, the Go runtime could be running a different goroutine if there is a disk read, but with mmap that thread is descheduled but holding an m & p. I'm also not sure if there would be increased stop the world pauses, or if the async preemption stuff would \"just work\".Section 3.2 of this paper has more details: https://db.cs.cmu.edu/papers/2022/cidr2022-p13-crotty.pdfreply",
      "To me this indicates a limitation of the API. Cause you do want to maintain that the kernel can page out that memory under pressure while userspace accesses that memory asynchronously while allowing the thread to do other asynchronous things. There\u2019s no good programming model/OS api that can accomplish this today.reply",
      "There is no sensible OS API that could support this, because fundamentally memory access is a hardware API. The OS isn\u2019t involved in normal memory reads, because that would be ludicrously inefficient, effectively requiring a syscall for every memory operation, which effectively means a syscall for any operation involving data I.e. all operations.Memory operations are always synchronous because they\u2019re performed directly as a consequence of CPU instructions. Reading memory that\u2019s been paged out results in the CPU itself detecting that the virtual address isn\u2019t in RAM, and performing a hardware level interrupt. Literally abandoning a CPU instruction mid execution to start executing an entirely separate set of instructions which will hopefully sort out the page fault that just occurred, then kindly ask the CPU to go back and repeat the operation that caused the page fault.OS is only involved only because it\u2019s the thing that provided the handling instructions for the CPU to execute in the event of a page fault. But it\u2019s not in anyway actually capable of changing how the CPU initially handles the page fault.Also the current model does allow other threads to continue executing other work while the page fault is handled. The fault is completely localised to individual thread that triggered the fault. The CPU has no concept of the idea that multiple threads running on different physical core are in anyway related to each other. It also wouldn\u2019t make sense to allow the interrupted thread to someone kick off a separate asynchronous operation, because where is it going to execute? The CPU core where the page fault happened is needed to handle the actual page fault, and copy in the needed memory. So even if you could kick off an async operation, there wouldn\u2019t be any available CPU cycles to carry out the operation.Fundamentally there aren\u2019t any sensible ways to improve on this problem, because the problem only exists due to us pretending that our machines have vastly more memory than they actually do. Which comes with tradeoffs, such as having to pause the CPU and steal CPU time to maintain the illusion.If people don\u2019t like those tradeoffs, there\u2019s a very simple solution. Put enough memory in your machine to keep your entire working set in memory all the time. Then page faults can never happen.reply",
      "> There is no sensible OS API that could support this, because fundamentally memory access is a hardware API.Not only is there a sensible OS API that could support this, Linux already implements it; it's the SIGSEGV signal.  The default way to respond to a SIGSEGV is by exiting the process with an error, but Linux provides the signal handler with enough information to do something sensible with it.  For example, it could map a page into the page frame that was requested, enqueue an asynchronous I/O to fill it, put the current green thread to sleep until the I/O completes, and context-switch to a different green thread.Invoking a signal handler only has about the same inherent overhead as a system call.  But then the signal handler needs another couple of system calls.  So on Linux this is over a microsecond in all.  That's probably acceptable, but it's slower than just calling pread() and having the kernel switch threads.Some garbage-collected runtimes do use SIGSEGV handlers on Linux, but I don't know of anything using this technique for user-level virtual memory.  It's not a very popular technique in part because, like inotify and epoll, it's nonportable; POSIX doesn't specify that the signal handler gets the arguments it would need, so running on other operating systems requires extra work.im3w1l also mentions userfaultfd, which is a different nonportable Linux-only interface that can solve the same thing but is, I think, more efficient.reply"
    ],
    "link": "https://info.varnish-software.com/blog/how-memory-maps-mmap-deliver-25x-faster-file-access-in-go",
    "first_paragraph": "Varnish EnterpriseVarnish ProVarnish ControllerVarnish CacheVarnish Traffic RouterOne of the slowest things you can do in an application is making system calls. They're slow because you do have to enter the kernel, which is quite expensive. What should you do when you need to do a lot of disk I/O but you care about performance? One solution is to use memory maps.Memory maps are a modern Unix mechanism where you can take a file and make it part of the virtual memory. In Unix context, modern means that it was introduced in the 1980s or later. You have a file, containing data, you mmap it and you'll get a pointer to where this resides. Now, instead of seeking and reading, you just read from this pointer, adjusting the offset to get to the right data.To show what kind of performance you can get using memory maps, I've written a little Go library that allows you to read from a file using a memory map or a ReaderAt. ReaderAt will do a pread(), which is a seek/read combo, while mmap will just"
  },
  {
    "title": "/dev/null is an ACID compliant database (jyu.dev)",
    "points": 122,
    "submitter": "swills",
    "submit_time": "2025-10-23T21:28:02 1761254882",
    "num_comments": 65,
    "comments_url": "https://news.ycombinator.com/item?id=45687458",
    "comments": [
      "Best stack cloud providers don't want you to know about, /dev/null for db and https://github.com/kelseyhightower/nocode for the backend.reply",
      "WTF is going on with the issues and pull requests for that repo?reply",
      "The less substance there is to it, the easier it is to talk about.The Chinese comments (\"issues\") also seem to be the same kind of jokes as the English ones, \"no code means no bugs, perfect\", etc., from the few I tried getting translations of. I imagine this went viral on Chinese social media, which makes sense since it's the sort of joke that's easy to translate and doesn't depend on particular cultural assumptions or anything.reply",
      "In nocode you fix nothing and you don't change anything, that's why issues and pull requests are a mess, they literally cannot be dealt with by design.reply",
      "Had to see for myself, and yeah... that's a whole lot of chaos. I'm sure I'd get the joke if I could read Chinese though.reply",
      "They're using it to communicate in code to each other.reply",
      "Well they should stop that and start communicating in nocode instead.reply",
      "I've never had a single issue with any user after moving our databases to /dev/null.reply",
      "I've used /dev/null for exactly this purpose. I have output that needs to go somewhere, and I don't want to worry about whether that somewhere can handle it.Later on in deployment, it will go somewhere else. Somewhere that has been evaluated for being able to handle it.In that way, /dev/null is to storage what `true` is to execution - it just works.reply",
      "Bug free software is a pipe dream, but if there is anything I've never encountered any bugs with, /dev/null and true is certainly in the top 3.reply"
    ],
    "link": "https://jyu.dev/blog/why-dev-null-is-an-acid-compliant-database/",
    "first_paragraph": "Back  August 22, 2025 at 2 a.m.  /    /dev/null is web scale Operations are \"all or nothing.\"Anything you write to /dev/null disappears entirely. There's no partial write problem: it\u2019s either written (and discarded) or not written at all. \u2705The system transitions from one valid state to another./dev/null always stays in a consistent state (empty). No matter what you write, the invariant \"file contains nothing\" always holds. \u2705Concurrent transactions don\u2019t interfere with each other.Multiple processes can write to /dev/null at the same time, and their outputs never conflict, because nothing is ever stored. \u2705Once a transaction is committed, it remains so, even after crashes./dev/null \"durably\" commits your data into nothingness. After a crash or reboot, it still contains exactly what it always has: nothing. \u2705There is only 1 small problem though, it only comes with 0b of free storage. For more space, you will have to contact entreprise sales, which is actually just me!\n\u00a9 2025, Joey Yu. All r"
  },
  {
    "title": "React Flow, open source libraries for node-based UIs with React or Svelte (github.com/xyflow)",
    "points": 19,
    "submitter": "mountainview",
    "submit_time": "2025-10-23T23:33:28 1761262408",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/xyflow/xyflow",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        React Flow |\u00a0Svelte Flow - Powerful open source libraries for building node-based UIs with React (https://reactflow.dev) or Svelte (https://svelteflow.dev). Ready out-of-the-box and infinitely customizable.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\nPowerful open source libraries for building node-based UIs with React or Svelte. Ready out-of-the-box and infinitely customizable.React Flow \u00b7 Svelte Flow \u00b7 React Flow Pro \u00b7 DiscordThe xyflow repository is the home of four packages:Are you using React Flow or Svelte Flow for a personal project? Great! No sponsorship needed, you can support us by reporting any bugs you find, sending us scre"
  },
  {
    "title": "AI discovers a 5x faster MoE load balancing algorithm than human experts (adrs-ucb.notion.site)",
    "points": 34,
    "submitter": "melissapan",
    "submit_time": "2025-10-23T22:35:22 1761258922",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=45688236",
    "comments": [
      "i wonder how hard it is to get the setup for AI to evolve on?reply",
      "As an author of the blog, I'll note that this was one of the easiest applications of ADRS. Bowen, who was leading this effort, got things running within a day or two and the initial runs were with free Google credits! It was exciting to see how quickly these kinds of frameworks could be applied to real-world engineering and algorithmic challenges.reply",
      "did AI explain its thinking, or could it have just stumbled upon the solution without designing it or understanding why it worked? i.e. could it have just been a hallucination that happened to work?reply",
      "This is a great question! By analyzing the logs of OpenEvolve with the full model outputs, we observed how the AI got its ideas (seemed to be pulling from literature in the space) and how it tried to apply them. So in some sense, it \"reasoned\" about how to get better algorithms. And we saw this process proceed systematically via the ADRS framework to converge to a significantly better algorithmreply",
      "very interesting, thank you.reply",
      "Nice result, but the snake pattern is pretty obvious and intuitive even for a human who just glances over the problem. It kinda breaks if there is huge variance (if the top load expert is orders of magnitude higher than #2 it probably should just get its own GPU), but I'm not familiar enough with MoE to know if that's a realistic possibility.reply",
      "Thanks! In realistic workloads, the differences won\u2019t be orders of magnitude.I agree that this is a fairly simple problem. Experienced engineers\u2014or anyone who has faced similar challenges\u2014can quickly come up with such solutions. The key point, however, is that others might get stuck in their research simply because they don\u2019t realize these quick solutions exist (\u201cI don\u2019t know what I don\u2019t know\u201d). AI helps bridge that gap by making expert-level knowledge accessible to every researcher, allowing them to focus more on exploring the truly unknown parts.reply",
      "Alternate title: \u201cHuman experts discover a 5x faster MoE load balancing algorithm using AI\u201dreply"
    ],
    "link": "https://adrs-ucb.notion.site/moe-load-balancing",
    "first_paragraph": ""
  },
  {
    "title": "Can \u201csecond life\u201d EV batteries work as grid-scale energy storage? (volts.wtf)",
    "points": 101,
    "submitter": "davidw",
    "submit_time": "2025-10-23T18:15:45 1761243345",
    "num_comments": 114,
    "comments_url": "https://news.ycombinator.com/item?id=45685007",
    "comments": [
      "This is less useful than most people expected.   Redwood has been struggling because the expected battery turnover is not occurring.   EV batteries are lasting a long time, so they stay in the car are and not being recycled or reused in any quantity yet.If EV batteries last 20+ years in EV's, it'll be > 2040 before there are significant numbers of EV batteries available to recycle or reuse.https://www.geotab.com/blog/ev-battery-health/reply",
      "A lot of the early EV battery life projections were based on Nissan Leaf Gen 1. Which had a horrendous battery pack that combined poor choice of chemistry, aggressive usage and a complete lack of active cooling.When EVs with good battery pack engineering started hitting the streets, they outperformed those early projections by a lot. And by now, it's getting clear that battery pack isn't as much of a concern - with some of the better designs, like in early Teslas, losing about 5-15% of their capacity over a decade of use.reply",
      "I am a bit more concerned about batteries now as opposed to an year ago.We had this article from Elektrek [1] about battery issues in South Korea.  When I asked my local electric maintenance shop [2, sorry for the FB link], they said they have started seeing the same issue in Model 3s and Ys in Canada as well.  (They also said that it is too early to tell how common it would become)This may bode well for recycling since the issues is an unbalance, not the whole pack failing.[1] https://electrek.co/2025/10/14/tesla-is-at-risk-of-lossing-s...[2] https://www.facebook.com/groups/albertaEV/posts/248558844207...reply",
      "Tesla made powerwalls a product for a reason. They were supposed to come from outdated Tesla cars, but that never materialized. If it is materializing now, they already know what they are going to do.reply",
      "Don't forget that the original Leaf pack was only 24 kWh.  So if you assume a ~1000 full-equivalent-charge-cycles lifespan, then the large Gen2 62 kWh pack will live 2.5 times longer than an original 24 kWh pack.   If you average 3.5 miles/kWh, the 24 kWh battery will be expected to last somewhere around 84,000 miles.  While the 62 kWh pack will last for 217,000 miles.https://coolienergy.com/lfp-vs-nmc-batteries-the-science-beh...reply",
      "That's amazing good news for the environment, thank you I hadn't heard this.reply",
      "I'll defend the leaf a little.LiPo batteries were quiet expensive when it was initially released.  NiMH was really the only option in town.And with a lower energy density battery that's also heavier, adding a cooling system would have also added a bunch of weight to the already heavy car with a barely usable range of 100 miles.Gen 2, however, had no excuses.  They had every opportunity to add active cooling and they still decided to go with just air cooling.reply",
      "Every generation of the production Nissan Leaf has used lithium batteries. AFAIK no modern (~post-2000) mass-produced (>10k units sold) EV has ever used NiMH or lead-acid batteries.Edit: Checking Wikipedia to verify my information, I found out that Nissan actually sold a lithium-battery EV in 1997 to comply with the same 90s CARB zero-emissions vehicle mandate that gave us the GM EV-1: https://en.wikipedia.org/wiki/Nissan_R%27nessa#Nissan_Altrareply",
      "EVs no, but I think some Toyota hybrids (which are of course not even PHEVs) still use NiMH. Toyota tends to be very tight-lipped about their batteries and their sizes (or rather, lack thereof).reply",
      "Tends to be tight lipped??? It is in the catalog[1]! It is more that American consumers aren't tech obsessed than Toyota being reluctant to share.Even just looking at online media reports[2][3] clearly sourced from some exact same press event, it is obvious that US English equivalents are much lighter in content than Japanese versions. They're putting the information out, no one's reading it. It's just been the types of information that didn't drive clicks. Language barrier would have effects on it too, that Toyota is a Japanese company and US is an export market, but it's fundamentally the same phenomenon as citizen facing government reports that never gets read and often imagined as being \"hidden and withheld from public eyes\", just a communication issue.1: https://www.toyota.com/priuspluginhybrid/features/mpg_other_...2: https://www.motortrend.com/news/toyota-aqua-prius-c-hybrid-b...3: https://car.watch.impress.co.jp/docs/news/1339263.htmlreply"
    ],
    "link": "https://www.volts.wtf/p/can-second-life-ev-batteries-work",
    "first_paragraph": ""
  },
  {
    "title": "When is it better to think without words? (henrikkarlsson.xyz)",
    "points": 50,
    "submitter": "Curiositry",
    "submit_time": "2025-10-23T21:26:57 1761254817",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=45687441",
    "comments": [
      "This is one of those things that you don't really tend to think about (pun not intended!) until you experience a change in your thinking or meet someone who thinks like you do!> If we can avoid the compression step, and do the manipulations directly in the high-dimensional, non-linguistic, conceptual space, we can move much fasterWith my neurodivergent brain I've always conducted my thoughts in an \"uncompressed format\" and then eternally struggled to confine it all into words. Only then for people to misinterpret and question it. They might get caught up in the first sentence when the end of the paragraph is where you need to be!That's why when you meet someone who thinks like you the depth of conversation and thinking you can achieve together is vast and also incredibly liberating! Your no longer limited by words in same way.Since becoming ill I've suffered badly with brainfog. The cutesy name for a cruel experience. Sometimes there's no memories to draw on when your thinking, the cupboards are bare. You can't leap from thought to thought because they disappear before you get there or after like a cursed platformer. You might be able to grab hold of the thought but you can't reach inside or read it. It's all wrong somehow like when your suddenly convinced a word is spelt wrong even though you know it's right. You can't maintain focus long enough to finish your train of thought.Even that subconscious processing is affected I used to prime my brain with information all day and instead of waking up with the solution I'll wake up frustrated but not knowing why. Just the vague notion that I failed at something that used to come so easily.reply",
      "I don't have an \"inner monologue\" and don't think in words, only in images, but I've never experienced what this author is describing in terms of \"nonsense words\" or \"hand vibrations\".I was with some friends that were in a band together, and we got thinking about this topic, and ended up arranging ourselves from least verbal to most verbal. I was on one end, where all of my thoughts appear as emotions or images; on the other end was our bassist, who experienced his thoughts as fully formed sentences. He said when he's getting to a difficult passage in a song the words \"better focus here, don't mess up\" will ring out in his head. He also said he has fully dictated mental conversations with himself.I also read very quickly because I look at the shape of paragraphs and assemble the word-shapes into mental images and pick up meaning that way; high speed, but low comprehension. I struggle greatly to read philosophy because it's quite difficult to visualize. My wife reads slowly but hears every word in her head; her comprehension is much higher. I can do high comprehension reading by slowing down and looking at every word, but it feels like holding back an excitable dog.reply",
      "I needed that paragraph about reading. I think I absorb text in a similar way - not really \"sounding out words\", but somehow just absorbing concepts. Your explanation is a lot clearer than my hand-wavy rationalisation.It makes me not very good at anagram/word rearranging/finding games where you have to test for a large number of possibilities.reply",
      "A fellow less/non verbal thinker! I resonate with a lot of what you wrote. I can think in words, but it\u2019s not my default or most productive.I kind of understand what you mean about reading, I find I have to invest a lot of time to comprehend the same amount as others. If I encounter an unconventional style or shape of writing it\u2019s much harder.reply",
      "Been thinking a lot recently about what my thoughts look like. They definitely aren't words (though as I type this, I can imagine hearing myself think ahead to the end of the sentence). The best I can describe it is visualisations - whether that's images of maths notation, 3D rotating models, or a flow/map/block diagram.One pattern is that I'm a very prolific connection-forming machine.Exhibit A: The first thing that enters my mind for each word. \n(OnePlus One) (android pattern unlock) (Islamic State) (unit vector named t) (ich bin) (emoji-blood-type-A) (Latin etymology word root with verily) (https://prolificusa.com/) (New York Times Connections) (roll-forming, blow moulding, sheet metal stamping...) (\"my body is a machine\" meme)reply",
      "My wife was confounded when I told her I don't think in words. For her, it's a one to one correlation.She had assumed that all people think in this mode. I had assumed that all people think in \"thoughts\" and went through a separate step to articulate them.Made both of us aware of a difference in people.I don't feel vibrations or sensations though, and I definitely don't think in images. I only have a thought level, and it's very independent of any external presentation.reply",
      "Problem solving is a well-explored field in experimental psychology. TFA is a bit unfocused, making both some generally supported speculations and some traditional ideas that haven't been supported. A very good survey is the edited volume, The Psychology of Problem Solving (Davidson 2003).Although TFA doesn't refer to it by name, \"insight\" problem solving is when you are stuck on something and then suddenly realize the solution. The common explanation for being stuck is \"fixation\" on the wrong things. In agreement with TFA, there is indication that verbalization supports fixation more than visualization.reply",
      "When making visual art, I don\u2019t think in words. Shapes, colors, shading, perspective together turn into a final drawing; at no point do I translate this to words. I\u2019m not sure what trying to draw by thinking in words would even look like.Identifying and searching for morel mushrooms in the woods also feels largely nonverbal (although near a dying elm in late spring after a rain captures an essence of the idea, and those words provide a good starting point).Coding ends in \u201cwords\u201d, or at least some form of written language. But when I try to solve problems I do not think in words until it is time to put fingers to keyboard.Words are useful (I could not convey this comment otherwise), but they\u2019re not everything. It feels extremely difficult to convey my nonverbal thoughts through an inherently verbal medium like an HN comment. Perhaps to make a wordful analogy, the difficulty is like translating an idiom from one language to one of completely different context and origin.I don\u2019t deny that words do shape some of my thinking, but to me it\u2019s just one part of the whole stream of conscious.I\u2019m curious if anyone else feels this way about words?reply",
      "The question reminds me of a quote from Rilke: \"There is a depth of thought untouched by words, and deeper still a depth of formless feeling untouched by thought\".reply",
      "I've certainly noticed a bit of a pattern where programmers who can listen to podcasts or lyrics while they code (I can't; I rely too much on my verbal center for coding) can operate much faster and solve more complex problems than your average bear. They're rare, so I don't have enough data to feel certain, but I have a suspicion that sometimes they're forced into it by living in noisy environments where tuning out the words or thinking without them makes more sense.reply"
    ],
    "link": "https://www.henrikkarlsson.xyz/p/wordless-thought",
    "first_paragraph": ""
  },
  {
    "title": "Cheap DIY solar fence design (joeyh.name)",
    "points": 12,
    "submitter": "kamaraju",
    "submit_time": "2025-10-15T19:23:39 1760556219",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=45597198",
    "comments": [
      "I used 605W LONGi TOPCon panels for my vertical PV experiment.  If they are too tall, 440-450W JA or Jinko TOPCon panels are 176cm.Ditching the rails and bolting to the panel mounting holes with galvanized angle is a lot cheaper.reply",
      "Featured in his:Offgrid Electric Car (29 points, 6 months ago, 9 comments) https://news.ycombinator.com/item?id=43764598Aiming at December https://news.ycombinator.com/item?id=42412256reply",
      "A wider shot of the installation would help-the available pictures make it appear as if the panels are constantly going to be shaded.$1100 for mounting $1000 worth of panels does not seem terrible for something that anyone proficient with a hammer could accomplish.reply",
      "This is amazing, thank you. I love the use of Ironridge rails for mountingreply",
      "what are the current tariffs on solar panels?I've wanted to install home solar for years now.  It's difficult in my area.  At first, the salespeople would ghost me after learning I didn't want or need financing.  Then they lied about waived connection fees for use of a battery to sell power back to the utility during evening peak hours.  Then the Federal incentives vanished.  Now... the tariffs.So our approach is to remain in the bottom 2% of electicity consumption for our area.Stability in government is something we don't appreciate until it's gone.reply",
      "SignatureSolar has panels for $0.25/w. The tariffs are a nothing burger.If you're paying someone else to do it, the panels will likely be <10% of the cost.reply"
    ],
    "link": "https://joeyh.name/blog/entry/cheap_DIY_solar_fence_design/",
    "first_paragraph": "A year ago I installed a 4 kilowatt solar fence.\nI'm revisiting it this Sun Day, to share the design,\nnow that I have prooved it out.Solar fencing manufacturers have some good simple designs, but it's hard\nto buy for a small installation. They are selling to utility scale solar\nmostly. And those are installed by driving metal beams into the ground,\nwhich requires heavy machinery.Since I have experience with Ironridge rails for roof mount solar, I\ndecided to adapt that system for a vertical mount. Which is something it\nwas not designed for. I combined the Ironridge hardware with regular parts\nfrom the hardware store.The cost of mounting solar panels nowadays is often higher than the cost of\nthe panels. I hoped to match the cost, and I nearly did. The solar panels cost\n$100 each, and the fence cost $110 per solar panel. This fence was\nsignificantly cheaper than conventional ground mount arrays that I\nconsidered as alternatives, and made a better use of a difficult hillside\nlocation.I use"
  },
  {
    "title": "Populism Fast and Slow (josephheath.substack.com)",
    "points": 12,
    "submitter": "colonCapitalDee",
    "submit_time": "2025-10-23T22:43:15 1761259395",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://josephheath.substack.com/p/populism-fast-and-slow",
    "first_paragraph": ""
  },
  {
    "title": "Zram Performance Analysis (xeome.dev)",
    "points": 52,
    "submitter": "enz",
    "submit_time": "2025-10-23T19:58:12 1761249492",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45686280",
    "comments": [
      "This post\u2019s conclusions are odd. It has a bunch of extensive benchmarks showing that zstd is by far the worst performing across every metric except a slight increase in compression ratio and then says the conclusion is zstd is the best choice. Unless I\u2019m missing something in the data.reply",
      "In the first benchmark it gets a ratio of 4 instead of 2.7, fitting 36-40% more data with 75% more CPU.  It looks great.The next two show it fitting 20% more data with 2-3x the CPU, which is a tougher tradeoff but still useful in a lot of situations.The rest of the post analyzes the CPU cost in more detail, so yeah it's worse in every subcategory of that.  But the increase in compression ratio is quite valuable.  The conclusion says it \"provides the highest compression ratio while still maintaining acceptable speeds\" and that's correct.  If you care about compression ratio, strongly consider zstd.reply",
      "I have had similar experience, with ZFS zstd dropped IOPs and throughput by 2-4x compared to lz4! On a 64 core Milan server chip\u2026reply",
      "the context is missing.but for vps, where the cpu usage is extremely low and ram is expensive, it might make sense to sacrifice a little performance for more db cache maybe. can't say without more contextreply",
      "An alternative is zswap https://old.reddit.com/r/linux/comments/11dkhz7/zswap_vs_zra... which I believe, despite the name, can also compress RAM without hitting disk.reply",
      "It's only an alternative if you have a backing swap device. zram does not have this requirement, so (aside from using no compression) it's basically the only solution for some scenarios (e.g. using entire disk(s) for ZFS).reply",
      "Can't you use a ramdisk as your backing swap device?reply",
      "Using a ramdisk for zswap is basically just zram with extra steps.reply",
      "Extra steps are fine if the result works better.reply",
      "If you use hibernation, I think it also compresses your RAM image for potentially less wear and faster loading/savingreply"
    ],
    "link": "https://notes.xeome.dev/notes/Zram",
    "first_paragraph": "SearchSep 08, 2024Sep 08, 2024Aug 22, 2024 \u276f  \u276f Sep 03, 20235 min readZram is a kernel module that utilizes a compressed virtual memory block device allowing for efficient memory management. In this document we will analyze the performance of various compression algorithms used in Zram and their impact on the system. We will also discuss the effects of different page-cluster values on the system\u2019s latencies and throughput.The following table compares the performance of different compression algorithms used in Zram, in terms of compression time, data size, compressed size, total size, and compression ratio.Data from Linux Reviews:Data from u/VenditatioDelendaEst:Data from my raspberry pi 4, 2gb model:The table presents the performance metrics of different compression algorithms, including LZO, LZO-RLE, LZ4, and ZSTD. The metrics include throughput, compression ratio, and latency, which are important factors to consider for selecting the optimal compression algorithm.\n\nWe used a weighted"
  },
  {
    "title": "OpenAI acquires Sky.app (openai.com)",
    "points": 135,
    "submitter": "meetpateltech",
    "submit_time": "2025-10-23T17:04:17 1761239057",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=45684236",
    "comments": [
      "This is..disturbing.When a company uses acquisition as a strategy to develop features, it is stagnating. Maybe that's not the right word? At least it's past it's peak.Consider the efforts and costs of merging a new team with yours, getting different cultures and people to work together, integrating an entirely new code base with your own.Bigger and established companies take the risk and it does mostly pan out ok in the end. But, they generally tend to use this strategy going forward.Think of it this way, even with lots of capital on hand, will a company just poach/hire the other companies engineers or guy it out right for it's \"IP\"?I find it concerning because OpenAI's failure will have a cascading effect. And failure doesn't mean collapse, just a declining stock, an out-competed company. Its leadership must feel like they're big enough to where buying out the competition or to add new product lines is a good strategy, but they haven't (as far as I know) turned a healthy profit yet? They already have so many skeptics that claim OpenAI could never raise enough revenue to match its valuation.And it's not like they have any shortage of competition. Alphabet alone can play the acquisition game and win more readily. ChatGPT and Sora are great, but not they don't have enough of a difference for it to be a moat.I don't know, I just hope it isn't consultants and MBA's making decisions now over there.And Sky.app is for MacOS? Shouldn't they be locking in a stronger partnership with Apple and get a stake in Siri instead of competing against Siri and Apple Intelligence?I guess I just don't get business enough, I'm sure this all makes sense to entrepreneurs.reply",
      "Comes to prove that a great UI/UX can work wonders for users. This is what Alfred back in the day was dabbling with, except that Sky seems to have a modern natural language spin to it.reply",
      "I've personally known Ari, the guy behind Sky, since the mid 2000s when he was a frequent visitor to the forum insanelymac.com, back when OSx86 was a big deal. Even back then, he really stood out and I'm glad he's continuing to make waves.reply",
      "What IS Sky? Their landing page is just about the acquisition and I can't infer much from the OpenAI announcement.reply",
      "The 2nd paragraph in the article> Sky is a powerful natural language interface for the Mac. With Sky, AI works alongside you, whether you\u2019re writing, planning, coding, or managing your day. Sky understands what\u2019s on your screen and can take action using your apps.> We will bring Sky\u2019s deep macOS integration and product craft into ChatGPT, and all members of the team will join OpenAI.So it's probably a https://www.raycast.com/ competitorreply",
      "https://www.macstories.net/stories/sky-for-mac-preview/This is what you need to know.reply",
      "Not sure if you saw the demo video but the blue \"Trailer\" button at the bottom of their page pops it up to watch.https://sky.app/reply",
      "Thoroughly unimpressed. Every one of these assistant apps always go to \"send message/add something to calendar\".Hopefully the actual features and interoperability prove the ad wrong and there's a game changing UX behind it.reply",
      "I've yet to see a useful case for these AI browsers that is something other than a dead simple task.But when I browse the net, I'm not thinking about asking AI about the info on my screen. I can just read it?And by no means am I anti AI, I use it a bit for codingreply",
      "Clippy. It\u2019s Clippy\u2019s the whole way down.reply"
    ],
    "link": "https://openai.com/index/openai-acquires-software-applications-incorporated",
    "first_paragraph": ""
  },
  {
    "title": "Apple loses UK App Store monopoly case, penalty might near $2B (9to5mac.com)",
    "points": 165,
    "submitter": "thelastgallon",
    "submit_time": "2025-10-23T22:11:23 1761257483",
    "num_comments": 121,
    "comments_url": "https://news.ycombinator.com/item?id=45688006",
    "comments": [
      "Honest question, what do people think is a fair percentage? The platform development, app hosting, payment processing, and quality control is surely worth something.reply",
      "As long as Apple requires they make use of those services for me to install software on the computer I bought, and they prevent others from producing equivalent competing devices via patents (i.e. government granted monopolies), zero.It's not that it's not worth something, it's that they're abusing their patents and monopoly to extract further compensation after I already bought the device.reply",
      "You had the choice to buy another phone.reply",
      "When you plug in a non-Apple USB cable to charge your iPhone, or use a third-party phone case, or use Anker power bank .. do you wish you had none of these choices, but only use whatever Apple branded cables, and phonecase and power banks existed?If you want to buy Apple cables because you think it is better, sure - that's great. But preventing ugreen cables from working makes no sense.You shouldnt say 'buy a different phone' if you want to use ugreen cables.If you're a consumer, you should be on the side of more choice and more competition. If you're a Apple/Apple employee, you should 100% say what you just did :)reply",
      "Being on the side of the consumer means being on the side of the free market. If you don\u2019t like the charging options of an iPhone, don\u2019t buy an iPhone. If you don\u2019t like the OS of a Pixel, don\u2019t buy a Pixel. If the consumer is choosy and doesn\u2019t like the options available then there is a market opportunity for new entrants.reply",
      "The nature of a free market is that someone wins the competition, and the winner is then happy to figure out ways to prevent anyone from competing at all (this kind of action doesn't require a complete winner either, but I'm focusing on a thought experiment here).Ergo, if you care about maintaining a free market, then you care about limiting what kind of moves you can make in the free market, in order to preserve a free market. A truly free market with no rules has an end state where it is not a free market, more like a much more sophisticated version of the nobles of the land owning everything. So we declare many activities that make it difficult for others to compete that are not simply about manking a better product, \"anti-competitive\" and illegal.reply",
      "> If the consumer is choosy and doesn\u2019t like the options available then there is a market opportunity for new entrants.And if new entrants can't enter the market because the existing monopolies make it impractical, then what?reply",
      "This is the actual problem to be solved. The bureaucracy of forcing the hand of tech companies every time consumers scream loud enough is a shitty solution.reply",
      "And that is exactly the problem that is being solved. It's not about \"consumers screaming\", but companies, consumers and governments realizing that anti-competitive behavior is harming everybody except the gatekeeper. The solution is competition. Since Apple is such a great and innovative company, they surely won't be afraid of competing on merit.reply",
      "It just props up the monopoly. Appeased consumers have no reason to buy other products. There is no financial motive for Apple to do good because they can do bad until government forces their hand, and they have no reason to fear competition. It\u2019s an admission we\u2019re all at the mercy of Apple until daddy government steps in.reply"
    ],
    "link": "https://9to5mac.com/2025/10/23/apple-loses-uk-app-store-monopoly-case-penalty-might-near-2-billion/",
    "first_paragraph": "A landmark case in the UK concerning Apple\u2019s App Store practices has just been decided, with a London tribunal ruling against the company in a move that could cost Apple up to $2 billion.Sam Tobin writes at Reuters:Apple abused its dominant position by charging app developers unfair commissions, a London tribunal ruled on Thursday, in a blow which could leave the U.S. tech company on the hook for hundreds of millions of pounds in damages.The Competition Appeal Tribunal (CAT) ruled against Apple after a trial of the lawsuit, which was brought on behalf of millions of iPhone and iPad users in the United Kingdom.The CAT ruled that Apple had abused its dominant position from October 2015 until the end of 2020 by shutting out competition in the app distribution market and by \u201ccharging excessive and unfair prices\u201d as commission to developers. [\u2026]The case had been valued at around 1.5 billion pounds ($2 billion) by those who brought it. A hearing next month will decide how damages are calcula"
  },
  {
    "title": "PyTorch Monarch (pytorch.org)",
    "points": 311,
    "submitter": "jarbus",
    "submit_time": "2025-10-23T10:15:12 1761214512",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=45680237",
    "comments": [
      "Interesting - this seems to target a different layer than services like Tinker (https://thinkingmachines.ai/blog/announcing-tinker/). Monarch provides the infrastructure primitives while Tinker is a managed finetuning service. Could someone build something like Tinker on top of Monarch?reply",
      "Yup, there's stuff like https://pytorch.org/blog/introducing-torchforge/ on top of it nowreply",
      "\u201cService Adverbs - like \u2018route\u2019 and \u2018fanout\u2019\u201dGrammarians are going to be big angry here. Ain\u2019t an adverb in sight.reply",
      "Nice, so the open source equivalent now exists. Meta basically commoditized Tinker's($12B valuation) value prop by giving away the infra (Monarch) and the RL framework (TorchForge). Will be interesting to see how a managed service competes with free + open source at this layer.reply",
      "Apparently PyTorch oxidation has started.> Monarch is split into a Python-based frontend, and a backend implemented in Rust.Other than that, looks like a quite interesting project.reply",
      "Multiple sources say that it is an experimental framework around PyTorch, not a replacement. People will still get to enjoy a circular graph using std::shared_ptr with memory leaks.It's a pity they don't do a complete rewrite with a functional language as the driver.reply",
      "You might be looking for elixir/nx and axonhttps://github.com/elixir-nx/axonreply",
      "> It's a pity they don't do a complete rewrite with a functional language as the driver.It's open source, so seeing such an extension would be quite cool. There's much that could be done with native Rust actors and code that get maybe at what you want, but nothing precludes mixing PyTorch and other backends.For example, you could wrap a C++ inference engine as part of one of the actors generating data for other actors doing distributed training.reply",
      "Interesting, by the way, you can replicate the experience in Rust.reply",
      "Arc<T> has entered the chat.reply"
    ],
    "link": "https://pytorch.org/blog/introducing-pytorch-monarch/",
    "first_paragraph": "We now live in a world where ML workflows (pre-training, post training, etc) are heterogeneous, must contend with hardware failures, are increasingly asynchronous and highly dynamic. Traditionally, PyTorch has relied on an HPC-style\u00a0 multi-controller model, where multiple copies of the same script are launched across different machines, each running its own instance of the application (often referred to as SPMD). ML workflows are becoming more complex: pre-training might combine advanced parallelism with asynchrony and partial failure; while RL models used in post-training require a high degree of dynamism with complex feedback loops.\u00a0 While the logic of these workflows may be relatively straightforward, they are notoriously difficult to implement well in a multi-controller system, where each node must decide how to act based on only a local view of the workflow\u2019s state.We believe that the long-term sustainable way to address this is through a single controller programming model, in wh"
  },
  {
    "title": "Kaitai Struct: declarative binary format parsing language (kaitai.io)",
    "points": 75,
    "submitter": "djoldman",
    "submit_time": "2025-10-14T14:51:29 1760453489",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=45580795",
    "comments": [
      "Kaitai is absolutely one of my favorite projects.  I use it for work (parsing scientific formats, prototyping and exploring those formats, etc) as well as for fun (reverse engineering games, formats for DOSbox core dumps, etc).I gave a guest lecture in a friend's class last week where we used Kaitai to back out the file format used in \"Where in Time is Carmen Sandiego\" and it was a total blast.  (For me.  Not sure that the class agreed?  Maybe.)  The Web IDE made this super easy -- https://ide.kaitai.io/ .(On my youtube page I've got recordings of streams where I work with Kaitai to do projects like these, but somehow I am not able to work up the courage to link them here.)reply",
      "Kaitai is pretty nice. Hex editors with structure parsing support used to be more rare than they are now, so I've used https://ide.kaitai.io/ instead a few times.Also, the newest Kaitai release added (long awaited) serialization support! I haven't had a chance to try it out.https://kaitai.io/news/2025/09/07/kaitai-struct-v0.11-releas...reply",
      "Even if you don't want to use it since it is not as efficient as a hand-written specialized parser, Kaitai Struct gives a perfect way of documenting file formats. I love the idea and every bit of the project!reply",
      "I like using it for parsing structs but then intersperse procedural code in it for loops/containers, so not everything gets read into RAM all at once.reply",
      "I had a ton of fun using Kaitai to write an unpacking script for a video game's proprietary pack file format. Super cool project.I did NOT have fun trying to use Kaitai to pack the files back together. Not sure if this has improved at all but a year or so ago you had to build dependencies yourself and the process was so cumbersome it ended up being easier to just write imperative code to do it myself.reply",
      "Is the main difference from https://github.com/google/wuffs being that Kaitai is declarative?reply",
      "See https://github.com/google/wuffs/blob/main/doc/related-work.m...> Kaitai Struct is in a similar space, generating safe parsers for multiple target programming languages from one declarative specification. Again, Wuffs differs in that it is a complete (and performant) end to end implementation, not just for the structured parts of a file format. Repeating a point in the previous paragraph, the difficulty in decoding the GIF format isn't in the regularly-expressible part of the format, it's in the LZW compression. Kaitai's GIF parser returns the compressed LZW data as an opaque blob.Taking PNG as an example, Kaitai will tell you the image's metadata (including width and height) and that the compressed pixels are in the such-and-such part of the file. But unlike Wuffs, Kaitai doesn't actually decode the compressed pixels.---Wuffs' generated C code also doesn't need any capabilities, including the ability to malloc or free. Its example/mzcat program (equivalent to /bin/bzcat or /bin/zcat, for decoding BZIP2 or GZIP) self-imposes a SECCOMP_MODE_STRICT sandbox, which is so restrictive (and secure!) that it prohibits any syscalls other than read, write, _exit and sigreturn.(I am the Wuffs author.)reply",
      "They overlap, but none does strictly more than the other.Kaitai is for describing, encoding and decoding file formats. Wuffs is for decoding images (which includes decoding certain file formats). Kaitai is multi-language, Wuffs compiles to C only. If you wrote a parser for PNGs, your Kaitai implementation could tell you what the resolution was, where the palette information was (if any), what the comments look like and on what byte the compressed pixel chunk started. Your Wuffs implementation would give you back the decoded pixels (OK, and the resolution).Think of Kaitai as an IDL generator for file formats, perhaps. It lets you parse the file into some sort of language-native struct (say, a series of nested objects) but doesn't try to process it beyond the parse.reply",
      "Looking at that repo.. i have no clue how to get started.reply",
      "The top-level README has a link called \"Getting Started\".reply"
    ],
    "link": "https://kaitai.io/",
    "first_paragraph": "\n          0.11 released 2025-09-07\n\nA new way to develop parsers for binary structures.Declarative: describe the very structure of the data, not how you read or write itLanguage-neutral: write once, use in all supported languages: entry-level supportPacked with tools and samples: includes a compiler, an IDE, a visualizer and massive library of popular formatsFree & open source: feel free to use, modify and join the projectReading and writing binary formats is hard, especially if\n          it\u2019s an interchange format that should work across a multitude of\n          platforms and languages.\n        Have you ever found yourself writing repetitive,\n          error-prone and hard-to-debug code that reads binary data structures\n          from files or network streams and somehow represents them in memory for\n          easier access?\n        Kaitai Struct tries to make this job easier \u2014 you only have to\n          describe the binary format once and then everybody can use it from their\n       "
  },
  {
    "title": "Pyscripter \u2013 Open-source Python IDE written in Delphi (github.com/pyscripter)",
    "points": 44,
    "submitter": "peter_d_sherman",
    "submit_time": "2025-10-20T02:03:40 1760925820",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=45639618",
    "comments": [
      "This is Windows only.I wonder, why don't they use Lazarus (https://www.lazarus-ide.org/)? That would also make it cross-platform, and probably gain much more interest in the project.reply",
      "Lazarus was around 4 years old when the first version of Pyscripter was released.Porting to it, might be an option at some point, but changing compiler without breaking anything, is not a tiny task for Delphi things.I'd say the biggest roadblock would be JEDI which assumes Windows everything.https://wiki.freepascal.org/JVCL_Componentsreply",
      "No, not a good Idea. We did tons of efforts to achieve good multiplatform open source dev tools with exclusively FLOSS dependencies. Take dev-cpp as a remainder of what happens when people follow such path.And this is a comment I often link whenever I ser any news related to Delphi: https://news.ycombinator.com/item?id=37520509reply",
      "This is windows only, yes? I used Altium which is also Delphi I think and it's the only other software I've known to use it (though haven't extensively checked) and we need to just notreply",
      "A blast from the past! Pyscripter was definitely a top contender back in Python 2.3 days. Not sure when I stopped using it and why. Seems to be actively maintained. Will have to try again.reply",
      "Yes, I had it installed back in those days. I stopped using it because Notepad++ (quick check something without getting asked for permissions) plus VS Code (linting, refactoring, other small things) plus my pimped Code browser 4.9 (Zen-like Overview) do the things I need.reply",
      "And with LLM Support: OpenAI,  Gemini, DeepSeek, Grok and local LLM models  using Ollama.reply"
    ],
    "link": "https://github.com/pyscripter/pyscripter",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Pyscripter is a feature-rich but lightweight Python IDE\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.PyScripter is a free and open-source  Python Integrated Development\nEnvironment (IDE) created with the ambition to become competitive in\nfunctionality with commercial Windows-based IDEs available for other\nlanguages.\n\n        Pyscripter is a feature-rich but lightweight Python IDE\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error wh"
  },
  {
    "title": "Introduction to the concept of likelihood and its applications (2018) (sagepub.com)",
    "points": 12,
    "submitter": "sebg",
    "submit_time": "2025-10-23T22:52:15 1761259935",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://journals.sagepub.com/doi/10.1177/2515245917744314",
    "first_paragraph": ""
  },
  {
    "title": "Summary of the Amazon DynamoDB Service Disruption in US-East-1 Region (amazon.com)",
    "points": 399,
    "submitter": "meetpateltech",
    "submit_time": "2025-10-23T01:19:58 1761182398",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=45677139",
    "comments": [
      "I'm a tedious broken record about this (among many other things) but if you haven't read this Richard Cook piece, I strongly recommend you stop reading this postmortem and go read Cook's piece first. It won't take you long. It's the single best piece of writing about this topic I have ever read and I think the piece of technical writing that has done the most to change my thinking:https://how.complexsystems.fail/You can literally check off the things from Cook's piece that apply directly here. Also: when I wrote this comment, most of the thread was about root-causing the DNS thing that happened, which I don't think is the big story behind this outage. (Cook rejects the whole idea of a \"root cause\", and I'm pretty sure he's dead on right about why.)reply",
      "Great link, thanks for sharing. This point below stood out to me \u2014 put another way, \u201cfixing\u201d a system in response to an incident to make it safer might actually be making it less safe.>>> Views of \u2018cause\u2019 limit the effectiveness of defenses against future events.>>> Post-accident remedies for \u201chuman error\u201d are usually predicated on obstructing activities that can \u201ccause\u201d accidents. These end-of-the-chain measures do little to reduce the likelihood of further accidents. In fact that likelihood of an identical accident is already extraordinarily low because the pattern of latent failures changes constantly. Instead of increasing safety, post-accident remedies usually increase the coupling and complexity of the system. This increases the potential number of latent failures and also makes the detection and blocking of accident trajectories more difficult.reply",
      "That minimalist post mortem for the public is of what sounds like a Rube Goldberg machine and the reality is probably even more hairy.  I completely agree that if one wants to understand \"root causes\", it's more important to understand why such machines are built/trusted/evolved in the first place.That piece by Cook is ok, but largely just a list of assertions (true or not, most do feel intuitive, though).  I suppose one should delve into all those references at the end for details?  Anyway, this is an ancient topic, and I doubt we have all the answers on those root whys.  The MIT course on systems, 6.033, used to assign reading a paper raised on HN only a few times in its history: https://news.ycombinator.com/item?id=10082625 and https://news.ycombinator.com/item?id=16392223 It's from 1962, over 60 years ago, but that is also probably more illuminating/thought provoking than the post mortem.  Personally, I suspect it's probably an instance of a https://en.wikipedia.org/wiki/Wicked_problem , but only past a certain scale.reply",
      "I have a housing activism meetup I have to get to, but real quick let me just say that these kinds of problems are not an abstraction to me in my day job, that I read this piece before I worked where I do and it bounced off me, but then I read it last year and was like \"are you me but just smarter?\", like my pupils probably dilated theatrically when I read it like I was a character in Requiem for a Dream, and I think most of the points he's making are much subtler and deeper than they seem at a casual read.You might have to bring personal trauma to this piece to get the full effect.reply",
      "Oh, it's fine.  At your leisure.  I didn't mean to go against the assertions themselves, but more just kind of speak to their \"unargued\" quality and often sketchy presentation.  Even that Simon piece has a lot of this in there, where it's sort of \"by defenition of 'complexity'/by unelaborated observation\".In engineered systems, there is just a disconnect between on our own/small scale KISS and what happens in large organizations, and then what happens over time.  This is the real root cause/why, but I'm not sure it's fixable.  Maybe partly addressable, tho'.One thing that might give you a moment of worry is both in that Simon and far, far more broadly all over academia both long before and ever since, biological systems like our bodies are an archetypal example of \"complex\".  Besides medical failures, life mostly has this one main trick -- make many copies and if they don't all fail before they, too, can copy then a stable-ish pattern emerges.Stable populations + \"litter size/replication factor\" largely imply average failure rates.  For most species it is horrific.  On the David Attenborough specials they'll play the sad music and tell you X% of these offspring never make it to mating age.  The alternative is not the https://en.wikipedia.org/wiki/Gray_goo apocalypse, but the \"whatever-that-species-is-biopocalypse\".  Sorry - it's late and my joke circuits are maybe fritzing.  So, both big 'L' and little 'l' life, too, \"is on the edge\", just structurally.https://en.wikipedia.org/wiki/Self-organized_criticality (with sand piles and whatnot) used to be a kind of statistical physics hope for a theory of everything of these kinds of phenomena, but it just doesn't get deployed.  Things will seem \"shallowly critical\" but not so upon deeper inspection.  So, maybe it's not not a useful enough approximation.Anyway, good luck with your housing meetup!reply",
      "Another great lens to see this is \"Normal Accidents\" theory, where the argument is made that the most dangerous systems are ones where components are very tightly coupled, interactions are complex and uncontrollable, and consequences of failure are serious.https://en.wikipedia.org/wiki/Normal_Accidentsreply",
      "I'll admit i didn't read all of either document, but I'm not convinced of the argument that one cannot attribute a failure to a root cause simply because the system is complex and required multiple points of failure to fail catastrophically.One could make a similar argument in sports that no one person ever scores a point because they are only put into scoring position by a complex series of actions which preceded the actual point. I think that's technically true but practically useless. It's good to have a wide perspective of an issue but I see nothing wrong with identifying the crux of a failure like this one.reply",
      "Its extremely useful in sports. We evaluate batters on OPS vs RBI, and no one ever evaluated them on runs they happened to score. We talk all the time about a QB and his linemen working together and the receivers. If all we talked about was the immediate cause we'd miss all that.reply",
      "As a contractor who is on an oncall schedule. I have never worked in a company that treats oncall as a very serious business. I only worked in 2 companies that need oncall so I\u2019m biased. On paper, they both say it is serious and all SLA stuffs were setup, but in reality there is not enough support.The problem is, oncall is a full-time business. It takes full attention of the oncall engineer, whether there is an issue or not. Both companies simply treat oncall as a by-product. We just had to do it so let\u2019s stuff it into the sprint. The first company was slightly more serious as we were asked to put up a 2-3 point oncall task in JIRA. The second one doesn\u2019t even do this.Neither company really encourages engineers to read through complex code written by others, even if we do oncall for those products. Again, the first company did better, and we were supposed to create a channel and pull people in, so it\u2019s OKish to not know anything about the code. The second company simply leaves oncall to do whatever they can. Neither company allocates enough time for engineers to read the source code thoroughly. And neither has good documentation for oncall.I don\u2019t know the culture of AWS. I\u2019d very much want to work in an oncall environment that is serious and encourages learning.reply",
      "When I was an SRE at Google our oncall was extremely serious (if the service went down, Google was unable to show ads, record ad impressions, or do any billing for ads).  It was done on a rotation, lasted 1 week (IIRC it was 9AM-9PM, we had another time zone for the alternate 12 hours).  The on-call was empowered to do pretty much anything required to keep the service up and running, including cancelling scheduled downtimes, pausing deployment updates, stop abusive jobs, stop abusive developers, and invoke an SVP if there was a fight with another important group).We sent a test page periodically to make sure the pager actually beeped.  We got paid extra for being in the rotation.  The leadership knew this was a critical step.  Unfortunately, much of our tooling was terrible, which would cause false pages, or failed critical operations, all too frequently.I later worked on SWE teams that didn't take dev oncall very seriously.  At my current job, we have an oncall, but it's best effort business hours only.reply"
    ],
    "link": "https://aws.amazon.com/message/101925/",
    "first_paragraph": "\n\n\n\n\n\nSearchWe wanted to provide you with some additional information about the service disruption that occurred in the N. Virginia (us-east-1) Region on October 19 and 20, 2025. While the event started at 11:48 PM PDT on October 19 and ended at 2:20 PM PDT on October 20, there were three distinct periods of impact to customer applications. First, between 11:48 PM on October 19 and 2:40 AM on October 20, Amazon DynamoDB experienced increased API error rates in the N. Virginia (us-east-1) Region. Second, between 5:30 AM and 2:09 PM on October 20, Network Load Balancer (NLB) experienced increased connection errors for some load balancers in the N. Virginia (us-east-1) Region. This was caused by health check failures in the NLB fleet, which resulted in increased connection errors on some NLBs. Third, between 2:25 AM and 10:36 AM on October 20, new EC2 instance launches failed and, while instance launches began to succeed from 10:37 AM, some newly launched instances experienced connectivit"
  },
  {
    "title": "Armed police swarm student after AI mistakes bag of Doritos for a weapon (dexerto.com)",
    "points": 457,
    "submitter": "antongribok",
    "submit_time": "2025-10-23T18:09:37 1761242977",
    "num_comments": 283,
    "comments_url": "https://news.ycombinator.com/item?id=45684934",
    "comments": [
      "Sincere, and snarky summary:\"Omnilert\" .. \"You Have 10 Seconds To Comply\"-now targeting Black children!Q: What was the name of the Google AI Ethicist who was fired by Google for raising the concern that AI overwhelmingly negatively framed non-white humans as threats .. Timnit Gebruhttps://en.wikipedia.org/wiki/Timnit_Gebru#Exit_from_GoogleWe, as technologists, ARE NOT DOING BETTER. We must do better, and we are not on the \"DOING BETTER\" trajectory.We talk about these \"incidents\" with breathless, \"Wwwwellll if we just train our AI better ...\" and the tragedies keep rolling.Q2: Which of you has had a half dozen Squad Cars with Armed Police roll up on you, and treat you like you were a School Shooter? Not me, and I may reasonably assume it's because I am white, however I do eat Doritos.reply",
      "> Omnilert later admitted the incident was a \u201cfalse positive\u201d but claimed the system \u201cfunctioned as intended,\u201d saying its purpose is to \u201cprioritize safety and awareness through rapid human verification.\u201dIt just created a situation in which a bunch of people with guns were told that some teen had a gun.  That's a very unsafe situation that the system created, out of nothing.And some teen may be traumatized.  Again, unsafe.Incidentally, the article's quotes make this teen sound more adult than anyone who sold or purchased this technology product.reply",
      "https://www2.ljworld.com/news/schools/2025/aug/07/lawrence-s...Another false positive by one of these leading content filters schools use - the kid said something stupid in a group chat and an AI reported it to the school, and the school contacted the police. The kid was arrested, stripped searched, and held for 24 hours without access to their parents or counsel. They ultimately had to spend time in probation, a full mental health evaluation, and go to an alternative school for a period of time. They are suing Gaggle, who claims they never intended their system to be used that way.These kinds of false positives are incredibly common. I interviewed at one of their competitors (Lightspeed), and they actually provide a paid service where they have humans review all the alerts before being forwarded to the school or authorities. This is a paid addon, though.reply",
      "https://archive.is/DYPBL> Gaggle\u2019s CEO, Jeff Patterson, said in an interview that the school system did not use Gaggle the way it is intended. The purpose is to find early warning signs and intervene before problems escalate to law enforcement, he said.\n\u201cI wish that was treated as a teachable moment, not a law enforcement moment,\u201d said Patterson.It's entirely predictable that schools will call law enforcement for many of these detections. You can't sell to schools that have \"zero tolerance\" policies and pretend that your product won't trigger those policies.reply",
      "Exactly. In a saner world, we could use fallible AI to call attention to possible concerns that a human could then analyze and make an appropriate judgment call on.But alas, we don't live in that world. We live in a world where there will be firings, civil, and even criminal liability for those who make wrong judgments. If the AI says \"possible gun\", the human running things who alerts a SWAT team faces all upside and no downside.Hmm, maybe this generation's version of \"nobody ever got fired for buying IBM\" will become \"nobody ever got fired for doing what the AI told them to do.\" Maybe humanity is doomed after all.reply",
      "At least the current moment, the increasing turn to using autonomous weaponry against one\u2019s citizens - I don\u2019t think it says so much about humanity so much as the US. I think US foreign policy is a disaster but turning the AI-powered military against the citizenry does look like it\u2019s going to be quite successful, presumably because the US leadership is fighting an enemy incapable of defending itself. I think it\u2019s unsustainable though economically speaking. AI won\u2019t actually create value once it\u2019s a commodity itself  (since a true commodity has its value baked into its price). Rates of profit will continue to fall. The ruling class will become increasingly desperate in its search for growth. Eventually an economy that resorts to techno-fascism implodes. (Not before things turning quite ugly of course.)reply",
      "\"It wasn't used as directed\", says man selling Big Boom Fireworks to children.reply",
      "> They are suing Gaggle, who claims they never intended their system to be used that way.Yeah, there's a shop near me that sells bongs \"intended\" for use with tobacco only.reply",
      "The kid was arrested, stripped searched, and held for 24 hours without access to their parents or counsel. They ultimately had to spend time in probation, a full mental health evaluation, and go to an alternative school for a period of time.All he wanted was a Pepsi.  Just one Pepsi.  And they wouldn't give it to him.reply",
      ">...its purpose is to \u201cprioritize safety and awareness through rapid human verification.Oh look, a corporation refusing to take responsibility for literally anything. How passe.reply"
    ],
    "link": "https://www.dexerto.com/entertainment/armed-police-swarm-student-after-ai-mistakes-bag-of-doritos-for-a-weapon-3273512/",
    "first_paragraph": "Concerns over AI surveillance in schools are intensifying after armed officers swarmed a 16-year-old student outside Kenwood High School in Baltimore when an AI gun detection system falsely flagged a Doritos bag as a firearm.Taki Allen was hanging out with friends after football practice on October 20 when multiple police cars suddenly pulled up.\u201cIt was like eight cop cars that came pulling up for us,\u201d Allen told WBAL-TV 11 News. \u201cThey started walking toward me with guns, talking about \u2018Get on the ground,\u2019 and I was like, \u2018What?\u2019\u201d\u201cThey made me get on my knees, put my hands behind my back, and cuff me. Then they searched me and found nothing,\u201d he said.Allen was handcuffed at gunpoint. Police later showed him the AI-captured image that triggered the alert. The crumpled Doritos bag in his pocket had been mistaken for a gun.\u201cIt was mainly like, am I gonna die? Are they going to kill me? \u201cThey showed me the picture, said that looks like a gun, I said, \u2018no, it\u2019s chips.\u2019\u201dThe AI system behind "
  },
  {
    "title": "New updates and more access to Google Earth AI (blog.google)",
    "points": 124,
    "submitter": "diogenico",
    "submit_time": "2025-10-23T16:58:04 1761238684",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=45684155",
    "comments": [
      "> Bellwether, a moonshot at Alphabet's X, is using Earth AI to provide hurricane predictions insights for global insurance broker McGill and Partners. This enables McGill's clients to pay claims faster so homeowners can start rebuilding sooner.Hm, I'm quite skeptical about this claim.reply",
      "Seems plausible to me. It would allow them to start contracting CAT adjusters as soon as a hurricane is expected, before other insurers start bidding for them.Will this actually pay off for them? Who knows. But insurers are quite into ML for claims/underwriting these days, so I'd believe they're giving it a try.reply",
      "Wdym by 'bid for them'? Won't the MGA want to get rid of their contracts in an area that's about to be hit by a hurricane ASAP?reply",
      "You need a large workforce of adjusters to handle big events like a hurricane, but you don\u2019t need them all the time. So catastrophe adjusters are often independent contractors.Pay is good but hours are long, and you are often deployed far away from home.reply",
      "They want to pay adjusters and contractors the least amount possible - that's what they're bidding onreply",
      "More like booking them for the availability and likely a fixed non-hurricane-panic price.reply",
      "Could be a nice expensive contractor option for replacing the NOAA's public data that we lost. But it probably wont be picked up because it has to study the climate, which is a bad word now.reply",
      "You can totally create a private version of NOAA so long as you keep the messaging about insurance intelligence and never, ever speculate out loud about the causes of hurricanes. And if that's not enough, just do what Meta did and hire some shmuck like Robby Starbuck to signal that you're on the right team.reply",
      "I see the humor in this but you'd still need to operate your own satellites.reply",
      "What they want is for the government to run the satellites and provide the data on the taxpayers' dime, but only let private companies interpret that data so they can sell their forecastinghttps://www.cnn.com/2017/10/14/politics/noaa-nominee-accuwea... (note: old news)reply"
    ],
    "link": "https://blog.google/technology/research/new-updates-and-more-access-to-google-earth-ai/",
    "first_paragraph": "Oct 23, 2025\n          Built on decades of modeling the world, paired with Gemini\u2019s advanced reasoning, Earth AI is helping enterprises, cities and nonprofits with everything from environmental monitoring to disaster response.\n        When disasters strike, Google products like Search and Maps help billions of people make critical decisions to stay safe. Our flood forecasting information \u2014 now covering more than two billion people \u2014 provides life-saving forecasts before the most significant river floods. It's helped organizations like World Vision get drinking water and food to communities when they need it most. And during the devastating 2025 California wildfires, we provided crisis alerts with information from local authorities to 15 million people across Los Angeles while showing them where to find shelter in Google Maps. This is all made possible by our geospatial AI models, not only for floods and wildfires, but cyclones, air quality and many more.We recently introduced Google Ea"
  }
]