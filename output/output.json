[
  {
    "title": "Introducing tmux-rs (richardscollin.github.io)",
    "points": 585,
    "submitter": "Jtsummers",
    "submit_time": "2025-07-03T15:03:14 1751554994",
    "num_comments": 196,
    "comments_url": "https://news.ycombinator.com/item?id=44455787",
    "comments": [
      "This is a fantastic write-up of a truly monumental effort. I have huge respect for the author's persistence. The line \"Like gardening, but with more segfaults\" really resonates. It\u2019s this kind of deep-dive hobby project where you learn the most.The experience with `c2rust` is particularly interesting. It reminds me of a similar shift I saw years ago with automatic code translators between other languages. They're incredible for getting a project off the ground and proving feasibility, just as the author found, but you often end up with code that's completely \"un-idiomatic\" for the target language. The decision to throw it all away and do a manual port, while surely gut-wrenching, was the right call. You just can't automatically translate the intent of the original C code into safe, idiomatic Rust.The \"Interesting Bugs\" section gave me flashbacks. Bug #2, with the mismatched struct layout due to a missing `*`, is a classic FFI (Foreign Function Interface) nightmare. I once spent the better part of a week debugging a similar issue between C++ and C# where a single change in struct packing alignment was silently corrupting data downstream in very subtle ways. It's one of those bugs that makes you question your sanity. Finding that requires some serious debugging grit, so kudos to the author.This project is a great case study in the real-world challenges of modernizing critical infrastructure code. The author mentions the next big goal is to convert the codebase from `unsafe` to safe Rust. I'm really curious about the strategy for that.Refactoring away the raw pointers and complex control flow (like the `goto` patterns) into safe, idiomatic Rust without breaking everything seems like it would be even more challenging than the initial port. Will the approach be to introduce lifetimes and the borrow checker module-by-module? And what's the plan for the intrusive data structures? Replacing them with standard library collections like `BTreeMap` is the obvious choice, but I wonder if that will have performance implications that the original intrusive design was meant to avoid.In any case, amazing work. Thanks for sharing the journey in such detail. I'll be following this project on GitHub for sure.reply",
      "This announcement has my attention.I've been working on a Rust-based tmux session manager called rmuxinator (i.e. tmuxinator clone) for a few years now. It (mostly) works and been slow going because ... life but I've recently picked it back up to fix some bugs. One of the last new features I'd added was the ability to use rmuxinator as a library in other Rust programs. I'd like to try forking tmux-rs, adding rmuxinator as a dependency and seeing if it would ... just work as a way to start sessions using per-project config files. I'm definitely not advocating for adding rmuxinator upstream but it would be very nice to have this sort of session templating baked into the \"terminal multiplexer\" itself.The other interesting possibility I could foresee is doing things the other way around and having rmuxinator use tmux-rs as a library in order to setup and manage sessions instead of just dumping out shell commands -- which is fraught with edge cases. (Not sure if this is currently possible with tmux-rs, though.)Once I wrap up the bugfixes I'm currently working on, I may fork this project and give one or both of the above a try.Regardless, nice work by richardscollin!reply",
      "> You might be asking: why did you rewrite tmux in Rust? And yeah, I don\u2019t really have a good reason. It\u2019s a hobby project. Like gardening, but with more segfaults.I love this attitude. We don\u2019t necessarily need a reason to build new things. Who knows what will come out of a hobby project. Thanks to the author for the great write up!Also, my gardening is full of segfaults, coding a new project is definitely safer to my yard.reply",
      "Completely agree.  Not every project has to be out there to change the world.I recently rewrote `fzf` [1] in Rust.  Did I have any particular reason to do so?  No, not really, regular `fzf` is fine, but I thought it would be a fun excuse to learn how fuzzy search algorithms work and how to exploit the channels in Rust. It was fun.  There's no question that regular fzf is better but that wasn't the point, the point was to play with stuff and learn.[1] https://github.com/Tombert/rs-fzf-clonereply",
      "Nice, I do think fzf is a really good candidate for something that could be better if written in Rust. The fzy[1] C-rewrite is really fast, but I couldn't get it to give me as useful results when searching bash history.[1] jhawthorn/fzy: :mag: A simple, fast fuzzy finder for the terminal https://share.google/TBp3pVaFngBTfaFyOreply",
      "Yeah, I think Rust makes some sense, and I do think I've done a few clever things like getting a linear-time \"sort\" by exploiting the fact that there's a discrete and finite number of \"scores\" [1], and avoiding copies by taking the indexed values and explicitly moving them into the source channel to avoid extra copies [2].Someone smarter than me who is more familiar with TUI programming could almost certainly augment and improve what I wrote; I worked on it for as long as it was interesting to me.  I use it for my home-built program launcher thing Sway, though most people would probably get better results with real fzf.[1] https://github.com/Tombert/rs-fzf-clone/blob/main/src/helper...\n[2] https://github.com/Tombert/rs-fzf-clone/blob/main/src/proces...reply",
      "\"Gardening is the handiest excuse for being a philosopher.\"\n- Ray Bradbury, Dandelion Winereply",
      "I was about to post a snarky comment because I have a knee jerk reaction whenever someone implies a rust application is intrinsically better than C. Sometimes I forget people do things for fun.reply",
      "> Like gardening, but with more segfaults.interesting, I'm new to rust. what are you doing that necessitates using unsafe?reply",
      "A lot of things that C will let you do (even if you enter the realm of undefined behaviour) will simply not compile to C. As the author states, there are semantic differences between pointers and Rust's references.C pointers can have as many owners as you want, may be subjected to mathematical operations, and can be cast to any type without even an error message. The compiler will just assume you know what you're doing. If you enable enough compiler warnings, it might warn you, but C compilers don't generate a lot of those by default.Rust will let you only generate one mutable (exclusive) reference at a time. This means straight C to Rust ports simply don't compile.By switching to pointers, which work pretty much like their C equivalent, you can port the code much easier, but you do of course lose the benefits of Rust's safety mechanisms, because most pointer operations throw away all the safety guarantee that Rust provides.reply"
    ],
    "link": "https://richardscollin.github.io/tmux-rs/",
    "first_paragraph": "by Collin RichardsFor the 6 months or so I\u2019ve been quietly porting tmux from C to Rust. I\u2019ve recently reached a big milestone: the code base is now 100% (unsafe) Rust.\nI\u2019d like to share the process of porting the original codebase from ~67,000 lines of C code to ~81,000 lines of Rust (excluding comments and empty lines).\nYou might be asking: why did you rewrite tmux in Rust? And yeah, I don\u2019t really have a good reason. It\u2019s a hobby project. Like gardening, but with more segfaults.I started this project as a way of trying out C2Rust, a C to Rust transpiler. The tool was a little tricky to set up, but once it was running the generated output was a successful port of the tmux codebase in Rust.Despite the generated code working, it was basically unmaintainable and 3x larger than the original C. You wouldn\u2019t want to touch it with a 10 foot pole. Here\u2019s an example of the output:This snippet isn\u2019t that bad, but things can get a lot worse. My main concern was losing information from named cons"
  },
  {
    "title": "Flounder Mode \u2013 Kevin Kelly on a different way to do great work (joincolossus.com)",
    "points": 146,
    "submitter": "latentnumber",
    "submit_time": "2025-07-03T15:18:01 1751555881",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=44455933",
    "comments": [
      "Is this a story about Kevin Kelly or is this an autobiography? It purports to be the former but it's largely about the author's work history. It sort of gestures vaguely at being an interview with Kevin but there's only about four paragraphs in the entire article that contain quotes from him in response to things the author asked, and most of these are about his collection of knick-knacks.I kept on waiting for a series of questions that acted as springboards for long responses from Kelly that included him talking about the value of an approach to work that he calls \"flounder mode\" but they never came; the only appearance of \"flounder\" is in the title. It's an extended intro to an interview that never actually comes. You talked with Kelly all day and hooray, great for you meeting one of your idols! But you barely tell us a single thing he said.reply",
      "I first thought this is about Kevin Kelly. Then somewhere midway I thought I was reading an autobiography. It was only towards the latter half that I realized this is the author talking about Kevin Kelly and visiting his house.Even though the language is very simple, the writing is quite convoluted.reply",
      "it's an autobiography with the lens of \"here's how my philosophy of life has been influenced by kelly\". I found it more interesting than your summary led me to expect!reply",
      "If you want a list of quotes by Kevin Kelly, I'm sure they are just a Google search away. Sometimes, the reader has to do a little work - in this case, to determine what 'Flounder' means. Perhaps it means just that, which is to fumble around awkwardly, kinda like a fish out of water? It's kind of a murky word, and we don't really know how to use it in a sentence. It actually matches the whole tone of the article pretty well, especially when the author talks about how they may have made a huge mistake with their career by bouncing around and trying whatever seems interesting.reply",
      "K I thought I was crazy but you nailed it . What did I just readreply",
      "Just after I took on my new role, I wrote to Kevin Kelly and asked if I could meet him (I assumed he wouldn't know who I was, even though we've met informally, but he did). I wanted to talk to him about talking about how to be optimistic about technology. At my heart, I still remain positive about the contributions and opportunities of technology, but I've increasingly struggled to know how to convey, qualify or transmit that. He immediately accepted, I visited him in his tower, and we had a great, sprawling conversation. Like this author, he renewed my confidence in that framing, and the importance of it existing in the world. That single conversation has kept me going more than anything else over the last three or so years.I realise in reading this, that I never wrote after the fact to say thanks for that: so, thanks, KK, for everything.reply",
      "Since you're here, can I ask if you're still writing/publishing anywhere? Long-time fan.(Alternative comment: I think oblomovka's down).reply",
      "i am! oblomovka runs off a machine on my desk, which tends to crash whenever I walk out of my house, like today. However, this is an excellent notification that I'm now writing enough to maybe make it a bit more resilient.(For real dannyobrien completists, I also write small more regular email newsletter at https://buttondown.com/dannyob of my work within the Filecoin Extended Cinematic Universe (which includes IPFS, libp2p, iroh, Bluesky, Spritely Institute, Guardian Project, Internet Archive, Prelinger Archive, DWeb Community, Foresight Institute, EFF, Muckrock, etc see https://ffdweb.org/projects , https://fil.org/ecosystem-explorer , https://directory.plnetwork.io/projects?focusAreas=Digital+H...  ). It's pretty lowkey though.reply",
      "Many thanks for the links, I'll dig into them.> oblomovka runs off a machine on my desk, which tends to crash whenever I walk out of my houseYour essay on moving to the edge when everyone else is moving to the centre had a big effect on me at the time. I think it was prescient.reply",
      "though those crashes show the limitations!reply"
    ],
    "link": "https://joincolossus.com/article/flounder-mode/",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: K-Scale Labs (YC W24) \u2013 Open-Source Humanoid Robots",
    "points": 142,
    "submitter": "codekansas",
    "submit_time": "2025-07-03T16:44:18 1751561058",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=44456904",
    "comments": [
      "Is there any doc on\nthe hand? It looks surprisingly cheap.reply",
      "Congratulations on the launch! This is really cool.I'm not super active in the humanoid robot space anymore, however I did my PhD about 9 years ago in HRI.\nThat was the time of Boston Dynamics, DARPA robotics challenge, and Aldebaran's Pepper and Nao robots.You mentioned you are building everything open source. What happened with ROS and related projects? Do you build on top of that, or is that all super outdated that a reboot was needed?Another question I have is: why are you choosing a two-legged human over a four-legged one?My experiments with two legged robots were mostly bad. Not only did they fall basically all the time but they also had a big drift. So far, I have not seen any large improvements. But again, I might be very outdated.I always said to my colleagues. The main point stopping robots from picking up is a stable platform. And with the platform I mean walking.reply",
      "Eh. I think we got a bit nerd-sniped on some things and we ended up trying to build most of our stack ourselves. The control loop is just a pretty simple Rust loop for running ML models. ROS is kind of annoying to work with and the control loop is pretty simple so we just wrote it ourselves.For two legged - I think it will eventually be quite a bit cheaper, it's mostly a software problem to get them to be stable. RL based control has gotten much, much better. For example, I was talking to Trevor Blackwell a few weeks ago, and he was saying the IMU on the original Anybots robot was over $2k, whereas if you throw a noisy IMU into sim, you can get away with something basically from a cellphone. So yea, personally I'm a big believer in needing to solve the robotics intelligence problem, and once you solve that, humanoids will make the most sense as a form factor.reply",
      "I have some technical questions about feet.Human feet have metatarsophalangeal joints connecting the toes to the rest of the foot. But humanoid robots don't have these (at least, the vast majority don't). Why? These joints are very useful.Also, the bottom of the human foot is soft and has thousands of nerve endings. Can we really expect robots to get anywhere near human mobility performance without this level of compliance and sensory sophistication?reply",
      "Feet/ankles on humanoids are really hard mechanically. In many ways the kinematic requirements for the ankle are similar to a wrist, but while the wrist of a robot arm is the least-heavily-loaded, the ankle area can be the most heavily loaded. Humans get away with it by having most of the highly-stressed actuators in the lower leg, not the ankle itself, whereas many humanoid robots end up putting more of the actuators in the ankle assembly itself.In general, I think the best way to think about the differences between human muscles and robot actuators is that human muscles are simultaneously incredible in terms of strength and power density, and also incredibly fragile. Robot actuators are fairly robust, but comparatively poor. Humans are essentially falling apart at all times, but the repair mechanisms in the body do a good enough job that it doesn't matter (although you probably know someone with a \"career-disruptive/ending\" sports-related injury that shows these mechanisms have limits). Robotics is a long way away from making actuators that can be fixed online in such a process. Even cable stretching in cable-driven mechanisms remains hard to handle effectively, and that's one of the simplest types of mechanism wear.reply",
      "These are the kinds of comments that make comments worth reading. Thank you!reply",
      "This is a much better answer than minereply",
      "So, most humanoids you see that are relatively cost-effective are just \"humanoid\" in that they look like humans, but there are significant mechanical differences between them and real humans. It's almost always driven by the cost of manufacturing different components. A good example is the lead screw you see in the knee and ankle on Optimus - while it is more human-centric to have tendon-like actuation, it drives the price up quite a bit. Put differently, humans have a lot of specialization which is not great if you want to mass manufacture something.For walking, the most important thing is that the robot can be simulated well, so in our case, we tried to model the foot contact with the ground in simulation quite accurately. In fact, we found that force sensors in the foot probably help but they're not necessary in simulation, and we wanted to shave off anything that wasn't necessary. I am not sure how close we will get to human mobility - it's definitely a learning process - but you can get much further in simulation than you'd expect.reply",
      "What ML algorithms do you intend for full autonomy? Multi Modal LLMs for planning that control the robot by generating s.th. like code? Or s.th. that requires more learning from the environment?When I click \"get in touch\" on your github I just land on the website where I can buy the robot. Building the hardware for an autonomous robot is orders of magnitudes easier than the control. Do you think anyone with the capability do develop an autonomus robot will buy this and then just give you the code because its open source?reply",
      "My overall plan is basic joystick control -> VLA with RL -> self-supervised embodied representation -> end-to-end RL -> end-to-end control. I suspect there will be some very good multi modal models coming out in the next few years which we might use as base models, although more likely, we will adapt their techniques to work on data from our own robot.I agree that the hardware is easier than the software - I am a software guy, personally, but I felt that it was important to do the hardware first so at least we can have a baseline product which we can offer to people. I would personally like to work on this software problem (or rather, build a company to work on this problem), and this seems like the right way to go about funding working on this problem.reply"
    ],
    "link": "item?id=44456904",
    "first_paragraph": ""
  },
  {
    "title": "Manipulating trapped air bubbles in ice for message storage in cold regions (cell.com)",
    "points": 27,
    "submitter": "__rito__",
    "submit_time": "2025-06-30T10:15:52 1751278552",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44421490",
    "comments": [
      "This will be really useful after the nuclear winter.reply",
      "Can't wait to use the AWS version of this.reply",
      "Perhaps it will become their cheapest tier of Amazon Glacier?[1] https://aws.amazon.com/s3/storage-classes/glacierreply",
      "How did they come up with this idea?reply",
      "Is this article trying to milk an Ig Nobel Prize?If so, they\u2019re very talented at itreply"
    ],
    "link": "https://www.cell.com/cell-reports-physical-science/fulltext/S2666-3864(25)00221-8",
    "first_paragraph": ""
  },
  {
    "title": "AV1@Scale: Film Grain Synthesis, The Awakening (netflixtechblog.com)",
    "points": 158,
    "submitter": "CharlesW",
    "submit_time": "2025-07-03T16:34:51 1751560491",
    "num_comments": 127,
    "comments_url": "https://news.ycombinator.com/item?id=44456779",
    "comments": [
      "Ok, very cool. But I want Netflix to explain it related to Seinfeld, which at 10-12 feet looks fine, but up close looks insane. Blocky MJPEG + grain filter??It's not like we're on Pentium II processors anymore -- I can filter just about anything with ShaderGlass [0] on a shitty computer (and some of the CRT shaders like crt-hyllian-curvature are brilliant, especially on old shows like NewsRadio that only exist on DVD) .. and I'm shocked that Netflix doesn't just have this built into their Apple TV app or whatever. I'm shocked PLEX doesn't have it! (that I know of)I made a comment on a different post about imagining a world where local AI/LLM/whatever does some favorable processing for you, by you, on your device, of web content, to enhance your experience. I really believe media (streamers all the way down to open source devs) need to begin to incorporate whatever's out there that reduces friction and increases joy. It's all out there already! The heavy lifting has been done! Just make Family Matters look like how it looked when I was locking in on a Friday night for TGIF LOL[0] https://github.com/mausimus/ShaderGlassreply",
      "This fails to acknowledge that synthesized noise can lack the detail and information in the original noise.When you watch a high-quality encode that includes the actual noise, there is a startling increase in resolution from seeing a still to seeing the video. The noise is effectively dancing over a signal, and at 24 fps the signal is still perfectly clear behind it.Whereas if you lossily encode a still that discards the noise and then adds back artificial noise to match the original \"aesthetically\", the original detail is non-recoverable if this is done frame-by-frame. Watching at 24 fps produces a fundamentally blurrier viewing experience. And it's not subtle -- on old noisy movies the difference in detail can be 2x.Now, if h.265 or AV1 is actually building its \"noise-removed\" frames by always taking into account several preceding and following frames while accounting for movement, it could in theory discover the signal of the full detail across time and encode that, and there wouldn't be any loss in detail. But I don't think it does? I'd love to know if I'm mistaken.But basically, the point is: comparing noise removal and synthesis can't be done using still images. You have to see an actual video comparison side-by-side to determine if detail is being thrown away or preserved. Noise isn't just noise -- noise is detail too.reply",
      "Grain is independent frame-to-frame. It doesn't move with the objects in the scene (unless the video's already been encoded strangely). So long as the synthesized noise doesn't have an obvious temporal pattern, comparing stills should be fine.Regarding aesthetics, I don't think AV1 synthesized grain takes into account the size of the grains in the source video, so chunky grain from an old film source, with its big silver halide crystals, will appear as fine grain in the synthesis, which looks wrong (this might be mitigated by a good film denoiser). It also doesn't model film's separate color components properly, but supposedly that doesn't matter because Netflix's video sources are often chroma subsampled to begin with: https://norkin.org/pdf/DCC_2018_AV1_film_grain.pdfDisclaimer: I just read about this stuff casually so I could be wrong.reply",
      "People often assume noise is normal and IID but it usually isn't. It's s fine approximation but isn't the same thing, which is what the parent is discussing.Here's an example that might help you intuit why this is true.Let's suppose you have a digital camera and walk towards a radiation source and then away. Each radioactive particle that hits the CCD causes it to over saturate, creating visible noise in the image. The noise it introduces is random (Poisson) but your movement isn't.Now think about how noise is introduced. There's a lot of ways actually, but I'm sure this thought exercise will reveal to you how some cause noise across frames to be dependent. Maybe as a first thought, think about from sitting on a shelf degrading.reply",
      "> Grain is independent frame-to-frame. It doesn't move with the objects in the scene (unless the video's already been encoded strangely)That might seem like a reasonable assumption, but in practice it\u2019s not really the case. Due to nonlinear response curves, adding noise to a bright part of an image has far less effect than a darker part. If the image is completely blown out the grain may not be discernible at all. So practically speaking, grain does travel with objects in a scene.This means detail is indeed encoded in grain to an extent. If you algorithmically denoise an image and then subtract the result from\nthe original to get only the grain, you can easily see \u201cghost\u201d patterns in the grain that reflect the original image. This represents lost image data that cannot be recovered by adding synthetic grain.reply",
      "> If you algorithmically denoise an image and then subtract the result from the original to get only the grain, you can easily see \u201cghost\u201d patterns in the grain that reflect the original image. This represents lost image data that cannot be recovered by adding synthetic grain.The synthesized grain is dependent on the brightness. If you were to just replace the frames with the synthesized grain described in the OP post instead of adding it, you would see something very similar.reply",
      "The AR coefficients described in the paper are what allow basic modeling of the scale of the noise.> In this case, L = 0 corresponds to the case of modeling Gaussian noise whereas higher values of L may correspond to film grain with larger size of grains.reply",
      "> Grain is independent frame-to-frame. It doesn't move with the objects in the scene (unless the video's already been encoded strangely). So long as the synthesized noise doesn't have an obvious temporal pattern, comparing stills should be fine.Sorry if I wasn't clear -- I was referring to the underlying objects moving. The codec is trying to capture those details, the same way our eye does.But regardless of that, you absolutely cannot compare stills. Stills do not allow you to compare against the detail that is only visible over a number of frames.reply",
      "I think you've missed the point here: the noise in the originals acts as dithering, and increases the resolution of the original video. This is similar to the noise introduced intentionally in astronomy[1] and in signal processing[2].Smoothing the noise out doesn't make use of that additional resolution, unless the smoothing happens over the time axis as well.Perfectly replicating the noise doesn't help in this situation.[1]: https://telescope.live/blog/improve-image-quality-dithering\n[2] https://electronics.stackexchange.com/questions/69748/using-...reply",
      "Your first link doesn't seem to be about introducing noise, but removing it by averaging the value of multiple captures. The second is to mask quantizer-correlated noise in audio, which I'd compare to spatial masking of banding artifacts in video.Noise is reduced to make the frame more compressible. This reduces the resolution of the original only because it inevitably removes some of the signal that can't be differentiated from noise. But even after noise reduction, successive frames of a still scene retain some frame-to-frame variance, unless the noise removal is too aggressive. When you play back that sequence of noise-reduced frames you still get a temporal dithering effect.reply"
    ],
    "link": "https://netflixtechblog.com/av1-scale-film-grain-synthesis-the-awakening-ee09cfdff40b",
    "first_paragraph": ""
  },
  {
    "title": "Wind Knitting Factory (merelkarhof.nl)",
    "points": 72,
    "submitter": "bschne",
    "submit_time": "2025-07-03T20:28:57 1751574537",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=44458890",
    "comments": [
      "Knitting is programming. Read a knitting pattern and it's low level programming - knitters do not get enough credit.reply",
      "Same with weaving, especially the way symmetry is weft in.Jaccard looms are too general, too unconstrained. I like shaft looms more gratifying. Their restrictions make it more interesting.reply",
      "By that logic any instructions is programming and everyone on earth are programmers.reply",
      "Most recent archive of the website: https://web.archive.org/web/20250614200747/https://www.merel...reply",
      "This is delightfully weird, I love projects like this.reply",
      "I'm curious about how you 'harvest' a section of tube without it unraveling.Maybe cut it around, remove the little bits of yarn, then unravel a ways on purpose, and knit the unraveled yarn through the edge like a normal bind-off?reply",
      "Thread a flexible needle (usually called \"circular\") or a wire through a full row near the cut, unravel the remaining rows, then take a fine crochet hook to chain the loops together.Or just hem it, but that doesn't look like what she does.reply",
      "Circular knitting typically uses a technique called \"grafting\" or \"Kitchener stitch\" to close tubes seamlessly without unraveling - you'd temporarily secure stitches on holders, cut one strand, then use a tapestry needle to mimic the path of the yarn through the live stitches.reply",
      "They might be sergering the edges.reply",
      "I spent a couple of days building staircases inside a rope factory, kinda thing that I would just add a glass wall and put in a coffee shop, it's an odd thing to watch something solid materialise out of a intricate repetitive motion that happens ever so slightly faster that you can track.\ndifferent rig than the wind knitter but both I think are clasified as braidersreply"
    ],
    "link": "https://www.merelkarhof.nl/work/wind-knitting-factory",
    "first_paragraph": "Wind Knitting Factory\u2018Wind Knitting Factory\u2019 is a wind powered knitting machine that is attached to the facade of a building. The blades embrace more than a meter in diameter, and the wind that is cached by the mill drives the machine. Like that a long scarf gets knitted along the building downward. When it is windy the machine knits fast and with less wind the machine knits slowly. Buy them hereWind Knitting Factory\u2018Wind Knitting Factory\u2019 is a wind powered knitting machine that is attached to the facade of a building. The blades embrace more than a meter in diameter, and the wind that is cached by the mill drives the machine. Like that a long scarf gets knitted along the building downward. When it is windy the machine knits fast and with less wind the machine knits slowly.\u00a0WIND KNITTING FACTORY\u2018Wind Knitting Factory\u2019 is a wind powered knitting machine that is attached to the facade of a building. The blades embrace more than a meter in diameter, and the wind that is cached by the mill"
  },
  {
    "title": "You are what you launch: how software became a lifestyle brand (omeru.bearblog.dev)",
    "points": 15,
    "submitter": "freediver",
    "submit_time": "2025-07-01T09:16:43 1751361403",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://omeru.bearblog.dev/lifestyle/",
    "first_paragraph": ""
  },
  {
    "title": "Peasant Railgun (knightsdigest.com)",
    "points": 191,
    "submitter": "cainxinth",
    "submit_time": "2025-07-03T14:05:05 1751551505",
    "num_comments": 146,
    "comments_url": "https://news.ycombinator.com/item?id=44455222",
    "comments": [
      "I personally adore the Peasant Railgun and other such silly tropes generated by player creativity! Lateral problem solving can be one of the most fun parts of the DnD experience. However, these shenanigans often rely on overly convoluted or twisted ways of interpreting the rules that often don't pass muster of RAW (Rules As Written) and certainly not RAI (Rules As Intended) -- despite vociferous arguments by motivated players.\nAny DM who carefully scrutinizes these claims can usually find the seams where the joke unravels. The DnD authors also support DMs here when they say that DnD rules should not be interpreted as purely from a simulationist standpoint (whether physics, economy, or other) but exist to help the DM orchestrate and arbitrate combat and interactions.In the case of the Peasant Railgun, here are a few threads that I would pull on:\n* The rules do not say that passed items retain their velocity when passed from creature to creature. The object would have the same velocity on the final \"pass\" as it did on the first one.\n* Throwing or firing a projectile does not count as it \"falling\". If an archer fires an arrow 100ft, the arrow does not gain 100ft of \"falling damage\".Of course, if a DM does want to encourage and enable zany shenanigans then all the power to them!reply",
      "The underlying issue with TFA is that it's a player describing a thing they want to attempt - and then also describing whether the attempt succeeds, and what the precise result is.And that's... not D&D? I mean players could certainly attempt to have several people pass an object quickly with the Ready action, under RAW. But what happens next isn't \"the rod speeds up to such and such a speed\", it's \"the DM decides whether the peasants need to roll a dexterity check\" and so forth.And to me as a DM, that's why I find articles like TFA annoying. Not because it's confused about fall damage (though it is!), but because it's confused about who decides whether to apply fall damage!reply",
      "> And that's... not D&D?Some people are there because their life is not their own, and they want to live freely in the game; some people are there because their life is an exercise in control, and they want to play with the win conditions.Every table and game is unique. It\u2019s a microcosm of society that is simultaneously everything to anyone and yet no one thing to everyone. It\u2019s a way to directly engage with the Other via metaphor and indirection.This is D&D.https://www.youtube.com/watch?v=zng5kRle4FAreply",
      "It's actually a well-known (at least in my blog circles) problem with D&D. Everyone house-rules things to such an extent that the only thing that most tables have in common is how leveling up works, and which spells they use.reply",
      "Problem?RPGs facilitate group story telling, a shared experience.Friendliness comes from shared experience - whether it is the classic \"first date\" of \"dinner and a movie\" attempting to kickstart a lifelong relationship or a simple nod between bikers as they zip past each other in opposite directions.D&D provides a structure, making it a shared experience that everyone present can contribute to. And if the people of the group want to house rule a thing, that is a social thread right there.To apply external pressure to try to get rid of these house rules would be to try to undo an element of the social fabric of the group.It's not a problem. It's a strength.The only time it's a problem, is if the social group can't decide and accept/discard a house rule. That is a social issue for the group though, not a problem with D&D.And it kind of mirrors the many issues we as a society have with law-as-written and laws-as-intended.reply",
      "Rules lawyering as a concept wasn\u2019t invented at a D&D table, but the creation of the phrase almost certainly involved sitting at one.That\u2019s what separates good games and groups from each other: the collective suspension of disbelief as a shared goal. When everyone is in it for themselves, it rapidly devolves into Mary Sue wish fulfillment and power gaming, and as another deleted commenter mentioned, Calvinball. When everyone is in it together, it builds on itself and each other, and you get something like Dragonlance.https://en.wikipedia.org/wiki/Dragonlance> Dragonlance is a shared universe created by the American fantasy writers Laura and Tracy Hickman, and expanded by Tracy Hickman and Margaret Weis under the direction of TSR, Inc. into a series of fantasy novels. The Hickmans conceived Dragonlance while driving in their car on the way to TSR for a job interview. Tracy Hickman met his future writing partner Margaret Weis at TSR, and they gathered a group of associates to play the Dungeons & Dragons role-playing game. The adventures during that game inspired a series of gaming modules, a series of novels, licensed products such as board games, and lead miniature figures.reply",
      "You've missed my point - D&D has many forms, but they all involve a DM, who takes part in the game by making decisions and interpreting rules.TFA isn't that - it's somebody DMing for their own characters and then calling the (bizarre) decisions they made \"RAW\".reply",
      "Finding fun and unexpected rules interactions is certainly D&D. Finding obviously broken and unintended interactions that make no sense in-universe, purely as intellectual sport, is also D&D.Seriously expecting the DM to behave like a buggy video game and give you ultimate power because you found an exploitable glitch in the game mechanics is...well, that has also always happened in D&D, but it's hardly praiseworthy or in the spirit of things.reply",
      "Would I expect a DM to accept a peasant railgun? No.Would I love to play in a campaign where we are dungeon-crawling scientists who are investigating the theory that we are actually living in a poor simulation? Hell yeah. Just imagine your d&d university admissions departments working out that people somehow can be sorted precisely on a scale of -5 to +5 in terms of natural competency for any skill\u2026reply",
      "My take has always been:1. D&D mechanics, like all games, are a simplification of the real world using primitives like \"firing a bow\" and \"passing an item\" and \"downing a potion\"2. The real world is fractaly deep and uses primitives like \"plank length\" and \"quark spin\"3. Therefore there will always be places where the real world and the simplification don't line up.  Finding those gaps might be a fun meme, but it's not an exploit.  We play with the simplification's primitives, not the real-world physics'.reply"
    ],
    "link": "https://knightsdigest.com/what-exactly-is-the-peasant-railgun-in-dd-5e/",
    "first_paragraph": ""
  },
  {
    "title": "Kubernetes is a symptom, not a solution (andreafortuna.org)",
    "points": 16,
    "submitter": "gsky",
    "submit_time": "2025-07-04T00:42:27 1751589747",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44460288",
    "comments": [
      "> Docker is essentially a sandwich of disk images where you can shove absolutely anything, and then these images get executed by running whatever legacy software you\u2019ve crammed in there, regardless of how horrific or inconsistent it might be, with zero behavioral controls.Is this a problem with Docker, or a problem with people who use Docker? Without much controversy I feel this argument could be made about literally any abstract entity in society from `get_foo` to national institutions. Abstractions seem to be a necessary evil in corporative societies.Also, the article is way too short and meatless to provoke any real thoughts, and comes across as \"If you don't already know what Kubernetes is, just know that it's bad\". I don't see how that's going to sway anyone's opinion on anything.reply",
      "Maybe thought provoking. But sad to read ai garbage. It\u2019s easy to imagine a better world. But you also need to provide a way to reach it. \nFor example a lot of things are wrong with docker. But it enables us to run yesterday\u2019s software in the cloud. Tomorrow\u2019s software is not written yet.reply",
      "The post kind of mixes things up IMHO - kubernetes is fine I think but almost everything around it and the whole consulting business is the problem. You can run your single binary oci container and build it even without docker with a single config map with memory quota on 30 machines just fine.Take a look at the early borg papers what problem does it solves. Helm is just insane but you can use jsonnet that is modelled after Google's internal system.Only use the minimal subset and have an application that is actually build to work fine in that subset.reply",
      "how does jsonnet relate to Helm? It appears to be a template language.reply",
      "You can use it with tanka or kubecfg, argo and flux also have native support. You can also just render yaml and use kubectl applyreply"
    ],
    "link": "https://andreafortuna.org/2025/06/20/unpopular-opinion-kubernetes-is-a-symptom-not-a-solution",
    "first_paragraph": ""
  },
  {
    "title": "Poor Man's Back End-as-a-Service (BaaS), Similar to Firebase/Supabase/Pocketbase (github.com/zserge)",
    "points": 137,
    "submitter": "dcu",
    "submit_time": "2025-07-03T15:35:34 1751556934",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=44456135",
    "comments": [
      "Pocketbase is already the poor man's BaaS, and is minimalist compared to the two others mentioned.> Data stored in human-readable CSVsThe choice to not use a database when two near-perfect tiny candidates exist, and furthermore to choose the notorious CSV format for storing data, is absolutely mystifying. One can use their Wasm builds if platform-specific binaries offend.reply",
      "I just deployed a wasm built SQLite with FTS5 enabled and it\u2019s insane what it is capable of. It\u2019s basically elasticsearch entirely on the client. It\u2019s not entirely as robust as ES but it\u2019s like 80% of the way there, and I repeat, it runs on the client side on your phone or any other SQLite supported devicereply",
      "In 2025, pretending that a CSV can be a reasonable alternative to a database because it is \"smaller\" is just wild. Totally unconscionable.reply",
      "I use CSV files to run multiple sites with 40,000+ pages each. Close to 1mil pages totalSuper fastCan\u2019t hack me because those CSV files are stored elsewhere and only pulled on buildFree, ultra fast, no latency. Every alternative I\u2019ve tried is slower and eventually costs money.CSV files stored on GitHub/vercel/netlify/cloudflare pages can scale to millions of rows for free if divided properlyreply",
      "Can't argue with what works, but...All these benefits also apply to SQLite, but SQLite is also typed, indexed, and works with tons of tools and libraries.It can even be stored as a static file on various serving options mentioned above. Even better, it can be served on a per-page basis, so you can download just the index to the client, who can query for specific chunks of the database, further reducing the bandwidth required to serve.reply",
      "Just to be pedantic, SQLite is not really typed. I'd call them type-hints, like in Python. Their (bad IMHO) arguments for it: https://www.sqlite.org/flextypegood.htmlreply",
      "https://www.sqlite.org/stricttables.htmlreply",
      "A sibling comment posted a blind link whose contents address this, but (for the benefit of people who aren't likely to follow such links), recent versions of SQLite support STRICT tables which are rigidly typed, if you have a meed tor that instead of the default loose type affinity system.reply",
      "TBH this is why I've never messed with SQLite.If I want to bother with a SQL database, I at least want the benefit of the physical layer compressing data to the declared types and PostgreSQL scales down surprisingly well to lower-resource (by 2025 standards) environments.reply",
      "How exactly do you anticipate using Postgres on client? Or are you ignoring the problem statement and saying it\u2019s better to run a backend?reply"
    ],
    "link": "https://github.com/zserge/pennybase",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Poor man's Backend-as-a-Service (BaaS), similar to Firebase/Supabase/Pocketbase\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Poor man's Backend-as-a-Service (BaaS), similar to Firebase/Supabase/PocketbaseIt implements core backend features in less than 1000 lines of Go code, using only standard library and no external dependencies:Data stored in human-readable CSVs, one row per record. Data storage is append-only, with each update creating a new version of the record. The latest version is always used for reads. For faster lookups and updates, Pennybase maintains an in-memory index of the latest versions (offsets from the beginning of the CSV file).We agree that the first column in CSV is always the record ID, and the second column is the version number. "
  },
  {
    "title": "High-Fidelity Simultaneous Speech-to-Speech Translation (arxiv.org)",
    "points": 50,
    "submitter": "Bluestein",
    "submit_time": "2025-07-03T20:27:01 1751574421",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=44458877",
    "comments": [
      "For anyone else looking for examples: https://huggingface.co/spaces/kyutai/hibiki-samplesreply",
      "This is so cool. The future is cool!I wonder how it will work on languages that have different grammatical structure than french/english? Like Finno-Ugric languages which have sort of a Yoda speech to them. Edit: In Finno-Ugric languages words later on in a sentence can completely change the meaning. Will be interesting to look at.It's considerate of them to name it after my favourite whisky.reply",
      "The alignment between source and target is automatically inferred, basically by searching when the uncertainty over a given output word reduces the most once enough input words are seen. This is then lifted to the audio domain. In theory the same trick should work even with longer grammatical inversions between languages, although this will lead to larger delays. To be tested!reply",
      "It will interesting to see if it runs into issues in syntax of sentences. What am thinking of is specifically between Spanish and English, sentence structures often look completely different. How will this real time interpretation be affected?reply",
      "\"Hibiki currently only supports French-to-English translation.\"reply",
      "Link to repo: https://github.com/kyutai-labs/hibikireply",
      "Yandex Browser has been doing this for Russian for a while, if you go to YT it offers to translate to Russian, it does multiple speakers and voices from what I remember. Not sure if all the technicalities are the same.reply",
      "This is why I wonder about the value of language learning for reasons other than \u201cI\u2019m really passionate about it.\u201dWe are so close to interfaces that reduce the language barrier by a lot\u2026reply",
      "I don't know if you're multilingual, but some concepts are just legitimately easier to express in some languages; and the different grammatical structures that languages have can be useful for emphasising certain things, or to express subtle relationships between concepts.I'm not a particularly fluent speaker of Japanese and Russian, but I still find it helpful to drop into them sometimes when speaking with someone who understands them.reply",
      "It's not personal but I can't help myself to think that's such a sad post here. Reducing learning a different culture through language by plugging in an earbud. Is the battery is gone or your phone is stolen you realize you can't automate anything and that you've learned nothing. It's not about the tech if it works it's amazing it's like babelfish but it's so shallow to assume everything has some direct and simple \"value\" that can be replaced by some machine or even better some paid service. It's so common here. Is this an US thing?reply"
    ],
    "link": "https://arxiv.org/abs/2502.03382",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "CO2 sequestration through accelerated weathering of limestone on ships (science.org)",
    "points": 21,
    "submitter": "PaulHoule",
    "submit_time": "2025-07-03T23:31:03 1751585463",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44459980",
    "comments": [
      "Nuclear Explosions for Large Scale Carbon Sequestration:\nhttps://arxiv.org/abs/2501.06623\nseems more promising, I love that there is more research and interest in accelerated weatheringreply",
      ">(iii) ships moving at ~15 knots are water pumps themselves, overcoming the limitation of high energy demand in AWLi think there is a flaw in that logic.Btw, if doing it on ships is that great, why not build(repurpose) large [old] ships/barges by making them solar and/or wind powered and set them just to follow tradewinds and/or to just loiter in the tropical belt, mostly [semi]autonomously.reply",
      "That's a lot of power, you'd need a lot of solar/wind.\"Then just use batt...\"Yeah and then you have grid loss, more carbon emissions and a bunch of other issues.reply",
      "I thought for a moment ht this could be an argument for global trade. as it only reduces the CO2 output it is good but not carbon negative.reply",
      "In general, green-washing never truly confesses the scale of the problem. The data driven conclusion is exhausting every mine on every landmass would only buy another 5 to 7 years at most. Geoengineering is currently mostly BS idealism.The planet will be fine again in 30 thousand years or so, after the current population of psychotic primates go extinct.  It is ultimately a self-correcting problem regardless of what humans collectively choose to do. =3reply",
      "Would have been better if they put a few barrels of aquavit on deck.reply"
    ],
    "link": "https://www.science.org/doi/10.1126/sciadv.adr7250",
    "first_paragraph": ""
  },
  {
    "title": "An Algorithm for a Better Bookshelf (acm.org)",
    "points": 64,
    "submitter": "pseudolus",
    "submit_time": "2025-07-01T10:12:50 1751364770",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44432351",
    "comments": [
      "Aside from the topic, which is interesting in a nerdy, rabbit-hole way, I found it immensely calming that despite today's relentless, exhausting AI sonic boom, there are people working to optimize a 50-yr-old algorithm for doing something both mundane and very applicable. Maybe humanity is not doomed after all.reply",
      "But unfortunately HN comment threads are still about AI or about other comments even when the OP is not.reply",
      "> said Guy BlellochOh jeez now I have to read the rest.More people need to read Blellochs PH.D Thesis. Vector models for data-parallel computing. It's a mind blowing way to think of parallel computation.This is perhaps one of the best parallel programming / parallel data structures professors on the planet.------Awwww it's not so much about Blellochs work but I steady he's probably the guy ACM had to help explain and understand this new paper on the Bookshelf problem. Still great read though, but I was hoping for some crazy parallel programming application here.reply",
      "\"Their new algorithm adapts to an adversary\u2019s strategy, but on time scales that it picks randomly\"\"Even though many real-world data settings are not adversarial, situations without an adversary can still sometimes involve sudden floods of data to targeted spots, she noted.\"This is pretty neat. I bet this will find practical applications.reply",
      "Are \"adversaries\" broadly used in algorithm design? I've not seen that before. I'm used to edge cases and trying to break things, but an \"adversary\", especially white box, seems different.reply",
      "Yes. There is a whole sector of algorithm design called online algorithms dedicated to studying algorithms that must make decisions without complete information. A common analysis technique proves the \"competitive ratio\" of an algorithm by analyzing its worst case performance against an adversary. In fact, this article was the analysis of one particular online problem. For a simple introduction, you can check out \"the ski rental problem.\" More complex applications include things like task scheduling and gradient descent.Adjacent to this topic is algorithms for two-player games, like minimax, which depend on imagining an adversary that plays perfect counter moves.In a similar vein, in ML, there is a model called generative adversarial networks (GANs) in which 2 networks (a generator and discriminator) play a minimax game against each other, improving the capability of both models at once.reply",
      "It really depends on the particular group of algorithms. I'm only considering non-cryptographic algorithms here.As a general rule, any algorithm that involves a hash or a random/arbitrary choice has historically been based on \"assume no adversary\" and even now it has only advanced to \"assume an incompetent adversary\".By contrast, most tree-adjacent algorithms have always been vigilant against competent adversaries.reply",
      "Really??Quicksort, mergesort and heapsort are commonly analyzed with worst case / adversaries based decisions.I know that binary trees (especially red-black trees, AVL trees and other self balancing trees) have huge studies into adversaries picking the worse case scenario.And finally, error correction coding schemes / hamming distances and other data reliability (ex: CRC32 checks) have proofs based on the worst case adversary bounds.-------If anything, I'm struggling to think of a case where the adversary / worst case performance is NOT analyzed. In many cases, worst case bounds are easier to prove than average case... So I'd assume most people start with worst case analysis before moving to average case analysisreply",
      "I think there's a distinction between worst-case and adversarial behavior.For some types of problems, identifying worst-case behavior is straightforward. For example, in a hash table lookup the worst-case is when all keys hash to the same value. To me, it seems like overkill to think in terms of an intelligent adversary in that case.But in the problem described here, the worst-case is harder to construct. Especially while exploring the solution space given that slight tweaks to the solution can significantly change the nature of the worst-case. Thinking of it as adversarial implies thinking in terms of algorithms that dynamically produce the worst-case rather than trying to just identify a static worst-case that is specific to one solution. I can imagine that approach significantly speeding up the search for more optimal solutions.reply",
      "Yeah, this seems applicable to algorithmic management of fill factor in B+ tree based databases.reply"
    ],
    "link": "https://cacm.acm.org/news/an-algorithm-for-a-better-bookshelf/",
    "first_paragraph": ""
  },
  {
    "title": "Opening up \u2018Zero-Knowledge Proof\u2019 technology (blog.google)",
    "points": 225,
    "submitter": "doomroot13",
    "submit_time": "2025-07-03T17:36:13 1751564173",
    "num_comments": 136,
    "comments_url": "https://news.ycombinator.com/item?id=44457390",
    "comments": [
      "Anyone have a good explanation on the intuition of non-interactive zero-knowledge proofs? For example, I thought the \"paint-mixing\" analogy for Diffie-Hellman key exchange (https://en.wikipedia.org/wiki/Diffie\u2013Hellman_key_exchange#Ge...) really helped me handwave the math into \"mixing easy, unmixing hard\".https://blog.cryptographyengineering.com/2014/11/27/zero-kno... was a good intro for interactive ZK proofs but I haven't been able to find something for non-interactive ones.This blog post comparing ZK-STARKs to erasure coding is in the right flavor but didn't quite stick to my brain either: https://vitalik.eth.limo/general/2017/11/09/starks_part_1.ht...reply",
      "An intuitive explanation is that of proving you can find Waldo in a picture without revealing his exact location. Digital wallets can be interpreted as fancy signature schemes that operate on third-party issued commitments C instead of public keys that directly link users to their identities.A simple signature scheme is based on proof of knowledge PoK{x : pk = g^x}, which is transformed into a noninteractive variant via the Fiat-Shamir transformation, where the message is appended to the hash. Range proofs work similarly, with the simplest form being for a single bit: PoK{(b,r) : C = g^b * h^r & b(b\u22121)=0}. This proves that commitment C contains a bit b in {0,1} without revealing which value it is.Arbitrary ranges can then be constructed using the homomorphic properties of commitments. For an n-bit range, this requires n individual bit proofs. Bulletproofs optimize this to O(log n) proof size, enabling practical applications.The commitment C can be issued by a trusted third party that signs it, and the user can then prove certain properties to a service provider, such as age ranges or location zones (constructed from latitude and longitude bounds).A key challenge is that reusing the same commitment C creates a tracking identifier, potentially compromising user privacy.reply",
      "for explanation i've seen for the where's waldo analogy: imagine the single page of the where's waldo puzzle, and another giant piece of paper with the shape of waldo cut out of it.by providing a picture of waldo in the cut-out, you can prove you know where he is without providing the location. a zero knowledge proof.reply",
      "Plot twist: In addition to the cutout paper, the prover also brings their OWN picture of waldo, which they always place behind the cutout.reply",
      "everyone in this thread needs to read this paper: https://dl.acm.org/doi/abs/10.1145/3411497.3420225Where\u2019s Waldo as presented isn\u2019t even a proof of knowledgereply",
      "Is that \"Draw a Waldo with this outline\"?reply",
      "Imagine it isn't Waldo, but an unknown figure and you are only given the silhouette to find.  If you can draw what's within the silhouette or something, you've proven you've located it to high certainty without saying where.Say the whole image looked like noise and was generated from quantum measurements, and the coordinates to hash for the problem were generated with quantum measurements, and you were given the silhouette and the hash of the noise within to look for.  I could see it for proof of work: you could slide along a hashing window and prove you actually did work examining half the image on average or whatever.reply",
      "Thanks. So is it really different from \"what's (the hash of) word x on page y of the manual?\"?reply",
      "My colleague Amit made a simple video explanation about zkp with Wired. \nhttps://youtu.be/fOGdb1CTu5c?si=EyBQS92WyeduIpH-That doesn't explain the way this scheme works, but it's a nice start.reply",
      "This is what I was going to post. It helped me a lot by first giving a very intuitive understanding of the concept of ZKPs using the Where's Waldo/puffin-among-the-penguins example, but then also going deeper with the graph-coloring example.reply"
    ],
    "link": "https://blog.google/technology/safety-security/opening-up-zero-knowledge-proof-technology-to-promote-privacy-in-age-assurance/",
    "first_paragraph": "Jul 03, 2025\n          Code is now available.\n        Today, we open sourced our Zero-Knowledge Proof (ZKP) libraries, fulfilling a promise and building on our partnership with Sparkasse to support EU age assurance.Open sourcing these powerful cryptographic tools will make it much easier for private and public sector developers to build their own privacy-enhancing applications and digital ID solutions, meeting an urgent need.In layperson\u2019s terms, ZKP makes it possible for people to prove that something about them is true without exchanging any other data. So, for example, a person visiting a website can verifiably prove he or she is over 18, without sharing anything else at all.The goal of sharing ZKP with the open source and cryptography communities reflects our commitment to helping all parties in the ecosystem:The European Union\u2019s eIDAS Regulation set to take effect in 2026 encourages Member States to integrate privacy-enhancing technologies like ZKP into the European Digital Identi"
  },
  {
    "title": "Converge (YC S23) well-capitalized New York startup seeks product developers (runconverge.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-07-03T21:01:06 1751576466",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.runconverge.com/careers",
    "first_paragraph": "ProductIntegrationsResourcesCareersLog InBook a demoCareersLog InBook a demoBacked by Y Combinator  We are building the marketing measurement stack for online stores, allowing marketers to understand where their customers come from, cut unprofitable channels and scale what's working.$175k - $230k / 0.6% - 0.85% LocationNew York, NY, US Job TypeFull-timeExperience4+ yearsApply NowLearn MoreWe operate a >$1M ARR business with >180 customers with a team of just 5 people.Why you should care:You will not find a startup with the same level of product-market-fit where you can join as employee #6.We compete with Segment, Fivetran, Google Tag Manager, Rockerbox, Looker, just to name a few.Why you should care:Other startups give you ownership of a feature. At Converge, you get ownership over an entire product. Converge sees 33% of its users daily, while this is only 13% for the average SaaS company.Why you should care:Our customers will be excited by every feature you ship, and your impact will "
  },
  {
    "title": "Caching is an abstraction, not an optimization (buttondown.com/jaffray)",
    "points": 85,
    "submitter": "samuel246",
    "submit_time": "2025-07-01T10:42:46 1751366566",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=44432506",
    "comments": [
      "\"I think now caching is probably best understood as a tool for making software simpler\" - that's cute. Caching might be beneficial for many cases, but if it doesn't do one thing then this is simplifying software. There's that famous quote \"There are only two hard things in Computer Science: cache invalidation and naming things.\", and, sure, it's a bit ironical, but there's some truth in there.reply",
      "> There's that famous quote \"There are only two hard things in Computer Science: cache invalidation and naming things.\", and, sure, it's a bit ironical, but there's some truth in there.The joke form of this quote goes along the lines of:  There are only two hard things in Computer Science: cache \n  invalidation, naming things, and off-by-one errors.\n\n:-Dreply",
      "\"Two programs could have similar behaviour but structured very differently, the difference being that one utilizes caching as an abstraction and one explicitly has the concept of different tiers of storage.\"The author is comparing \"off-the-shelf\" caching with custom caching. They're coming from the assumption that you must be caching somehow and arguing that the word \"caching\" should be understood to mean only particular approaches to the general idea of caching. And obviously the whole point of the general idea is to optimize things.It's a rhetorical messreply",
      "Caching is simple, yes. The hard part is in the last word, invalidation. Even that is manageable for a single process. But as soon as you have multiple (threads / processes / nodes / data centers) updating the data, it does get quite complex, pretty fast.Likewise, naming things is simple as long as you alone, or a in a small team. But as soon as there are multiple organizations with all their own traditions, it gets tricky. Just witness the eternal flame wars about camelCase, PascalCase, snake_case, kebab-case, and UPPER_CASE. It is almost as hopeless culture clash as Emacs vs Vi vs PowerPoint...(I leave the off-by-one errors as an exercise for the reader)reply",
      "I'd say this is not the \"naming things\" that's hard. Beyond picking a common identifier format in the team, there are at least two dimensions that are much harder:- The language dimension - choice of words, that are good enough for the purpose, and not confusing. For example, \"Manager\" is as ambiguous as it gets, it can mean many thing, except we've been using it long enough that there's a more specific shape of meaning[0] for that word in code/program architecture contexts - so you still would use it instead of, say \"Coordinator\", which would raise all kinds of questions that \"Manager\" no longer does.- The epistemological dimension - whether the word you chose correctly names the concept you meant, and whether the concept you meant is actually the right one to describe the thing you're trying to describe. Ultimately, this is the hard thing at the root of philosophy. In practice, it manifests like e.g. choice between digging into some obscure branches of mathematics to correctly name the thing \"endofunctor\" or something, or calling it \"Square\" and saying \"fuck it, we'll clarify the exceptions in the comments\".--[0] - I mean \"more specific\" in the sense it's distinct from the other meanings and somewhat narrow - but still it's fuzzy as heck and you can't describe it fully in words; it's basically tacit knowledge.reply",
      "I try to name things descriptively in simple terms and often end up with NamesAboutThisLong, once they get too long i know the thing is doing too much and some refactoring is needed for readability.I also avoid letting the reader make assumptions. HasPlayerJumpedRecently is bad. What does recently mean? HasPlayerJumpedInLastTenMs is better, even if it's a bit long...Which highlights that it should probably be refactored into a more flexible value; MsSincePlayerLastJumped.If you arent assuming a time var wth Ms is milliseconds you aren't doing games dev so that one slides with me.reply",
      "I figured the naming issue is deciding how much context. A name might begin inside an organization but need to endure a wider area. If you make all names so long and context-free that they can work in any context, they become unwieldy. Also it can be hard to realize some of the implicit context and what needs to be differentiated with the name. Where server used to suffice, now you need server-a and server-b.reply",
      "If you have a system with \"slow storage\", caching is a way to optimize that to \"storage that is sometimes fast\".If you have a system with \"slow storage\" and \"fast storage\", caching is a way to abstract that away to just \"storage\".The author is arguing that the latter is the default way we should think about the concept of caching, which is a valid opinion to have.reply",
      "(You forgot off-by-1 errors.)All software has to name things, and count.  Caching (including invalidation) is best understood as a liability.  If you can foist it off on your CPU and OS and DB, good for you.  Programming whatever you're actually trying to get done is already hard enough.reply",
      "Off by 1-errors is not part of the original quote, but is just a later addon to make it funny.They also tend not to be very hard.reply"
    ],
    "link": "https://buttondown.com/jaffray/archive/caching-is-an-abstraction-not-an-optimization/",
    "first_paragraph": "I've always been told that caching is a tool to make software faster. That, given some careful considerations to consistency, caching makes it so that when you want to read a given piece of data, you don't have to go all the way back to some backend database or API server or SSD and can instead just read from some faster location like memory for the same data. Caching is thus a tool to improve performance.My feelings now are that that perspective on caching is wrong, or at least incomplete. Having worked on software recently chiefly concerned with moving data between object storage, disk, and memory, I think now caching is probably best understood as a tool for making software simpler.Something that always struck me as weird is, how come we have all these pre-baked caching algorithms, LRU, LFU, and so on. It seems like for my application I should have a much more fine-grained understanding of how things should work. Why am I outsourcing the understanding of my data to a generic \"policy"
  },
  {
    "title": "Where is my von Braun wheel? (angadh.com)",
    "points": 117,
    "submitter": "speckx",
    "submit_time": "2025-07-03T13:44:55 1751550295",
    "num_comments": 91,
    "comments_url": "https://news.ycombinator.com/item?id=44455022",
    "comments": [
      "It's crazy what we are doing with inflatables. Cargo ships with huge inflatable wing sails. The luxury catamaran MODX is bringing that down in size too. https://www.yachtingworld.com/news/modx-first-look-dual-infl...In space, NASA worked with Sierra Space to test their 300 cubic meter \"Orbital Reef\". The next go.is supposedly 500 m^3, about half the ISS size. Still seems way to small to spin though, I'd guess? Lockheed has their own inflatable hab station too. https://www.nasa.gov/humans-in-space/commercial-space/leo-ec...China launched and tested some kind of inflatable, just last fall. https://spacenews.com/china-quietly-tested-its-first-inflata...It seems like an obvious & amazing unmaterial leap, versus needing metal walls. If it works! Very fun having this history of rings post. Feels a little light on where we are though, what of promise is happening!reply",
      "Cargo ships have been powered by huge inflatable airfoils for at least thousands of years, possibly much longer than that.Inflatable structures in general are fantastic in theory: air or hydrogen is cheap, easy to put into the desired shape, and has immense compressive strength per gram, effectively unlimited.  Same for impact energy.  So you  can separate out the compressive and shock-absorbing parts of your structure from the tensile parts, and only pay for the tensile parts.  The main difficulty is recovery from rupture, especially in a space environment where not only don't you have a steady wind filling your sails, you have a limited, nonrenewable gas supply.  Well, and high compressive strength in a small space.reply",
      "(1) Assuming Starship makes it to orbit,  it enables a range of structures larger than the ISS but smaller than the O'Neill colonies.  A mission to Luna or Mars involves 12-20 launches of fuel tankers,  for the same cost you can put up a lot of mass to LEO.  A really flashy space hotel seems practical,  as would simulation environments for Lunar, Mars and Asteroidal technology development.(2) O'Neill colonies with large airspaces seem impractical because you'd need large amounts of nitrogen or some other inert gas:  you can find oxide rocks everywhere in space but pure oxygen environments aren't safe.  On the other hand,  the atmosphere for an LEO baby Bernal sphere would be about 15 Starship loads and probably worth it for the visual appeal.(3) The later work of O'Neill's students focused a lot on manufacturing.  The proposal to build large structures by vapor deposition of metals onto a balloon still looks feasible.  The solar power satellites shrank considerably in mass and it seemed that they could be built more practically from terrestrial materials.(4) Any space colonization effort runs into the problem that it needs to be self-sufficient in terms of manufacturing (especially Mars) which led Eric Drexler to go off and develop his vision of molecular assemblers.  Drexler's proposals haven't aged well but something equivalent that combines 3-d printing with flow chemistry, synthetic biology, fermentation and other technologies is probably possible -- and I think is the critical path.  That flashy space hotel,  however,  really is about rocketry and space assembly of large structures which really is the unique application of space manufacturing;  I don't think space manufacturing can ever be competitive for the terrestrial market but it can be competitive for things that can only be made in space.(5) Colonization of Ceres dominates all other space colonization opportunities in the solar system because there is no shortage of water and no shortage of nitrogen.  It seems possible to take the whole thing apart and build a colony with more floor space and a larger population than Earth.  You don't get the 0.2 cubic kilometers of ocean that we get,  but I think you can culture all the fish you can eat anyway.reply",
      "Ceres is very far away orbitally. It's three times further than Mars, but also has no braking atmosphere or gravity. If you send a payload to Ceres, that payload has 5 km/s of relative velocity that can only be zeroed out with rocket propulsion. (That's a lot).It's not coincidence the first Ceres orbiter was also a flagship prototype for advanced electric propulsion. It's a deceptively remote target.reply",
      "Granted.  I don't see it as a Muskian \"send 10,000,000 people and keep sending them supplies\" kind of thing but rather \"send 100 people,  1,000,000 eggs and the closest thing to a Drexler machine that we can make\" kind of thing.  The latter is what I think the BoM for a successful Mars colony looks like too.reply",
      "I'd imagine, given the rate of progress with AI and robots, the most practical would be to send robots ahead and have them build the infrastructure for some people to maybe visit later?reply",
      "I did an analysis of sending a factory sent to a carbonaceous chondrite asteroid that builds a factory factory which builds a solar sail factory that sends solar sails back to Earth-Sun L1 to counter climate change.The first thing in the decision tree is \"do you send a crew?\" and you're trading off the hard problem of teleoperating the thing (need a big advanced in autonomy) vs the hard problem of providing a habitat and liklihood that the crew doesn't come home.  So yeah,  sending bots ahead to build an environment is an option even on Mars.  I think Wall-E.If you're going that far though you might consider not sending intact humans at all and just sending the eggs and growing them out either artificially or in some other animal.(I see the Ceres thing as being on the line to interstellar colonization whereas I don't see Mars as such.  A likely intermediate step past that is doing something similar on an outer solar system or interstellar body,  say,  Titan or Pluto,  powered by D-D fusion.)reply",
      "I vaguely remember O'Neil's book talking about zero g manufacturing by welding together plates of Aluminium. Although I may be remembering some other work. Could we use an inflatable workshop to weld together cylindrical sections of a torus?  I can imagine sealing the end of the torus secrion and extruding it out the side of the inflatable. Very hazardous for the workers, I imagine.reply",
      "I had a back of the napkin design that was basically a sleeve that fitted over Starship and could be launched into orbit.  Those sleeves had angled ends that could then be bolted together in orbit to make a station with an octagon shape that could be spun at 2 or 3 rpm to get 1/2 Earth gravity.  Obviously still an enormous engineering challenge, but one that I think is solvable using today's tech.  Well, tomorrows tech, but nothing that requires a breakthrough in materials science or basic physics or anything like that.My plan was to fit the inside with huge water bags that would help to reduce cosmic radiation, provide thermal mass, and slow any micrometeorites that puncture the hull.  The water could be launched on cheaper rockets and transferred in orbit.  The water could also be pumped between sections to keep the wheel balanced.  The central hub area would be more of a challenge, probably having to be assembled (or at least unfolded) in orbit.Probably the biggest downside is that you wouldn't be able to spin it up until the entire structure was somewhat balanced, which means installing things like solar panels and radiators in pairs and the docking bit of the central hub would probably need to be on bearings so it can counter rotate to be effectively stationary or you wouldn't be able to dock more than 2 spacecraft at a time.  The ISS was built in sections over the course of decades, this would need to be built all in one go, which is a huge commitment.NASA's plans for two tethered stations (or one station and a counterweight) are probably more feasible, but much less cool.reply",
      "Starship feels like the ultimate engineering gamble, so many moving parts (literally) that getting it right might be as hard as building the habitats it\u2019s meant to launch.On nitrogen, I keep wondering: if in-space manufacturing matured, couldn\u2019t we generate atmosphere by cracking water for oxygen and synthesizing nitrogen analogues through hydrogen-based pathways? Or is Earth\u2019s air mix so specific that importing nitrogen stays unavoidable?reply"
    ],
    "link": "https://angadh.com/wherevonbraunwheel",
    "first_paragraph": "In 1962. There \u2014 that answers the clickbaity title right away.NASA had viable designs for rotating wheel space stations that could have given astronauts artificial gravity. Then, the Apollo program effectively killed them.While NASA\u2019s lunar focus delivered the historic moonshot, it dismantled a promising engineering effort at Langley Research Center that might have revolutionized human spaceflight. That decision set us on a half-century trajectory of small, zero-gravity stations that continue to plague astronauts with muscle atrophy, bone loss, and vision problems.Had NASA maintained its parallel pursuit of artificial gravity, we might now have permanent orbital settlements supporting deep space missions rather than the limited outposts we\u2019ve settled for. This historical pivot point matters today as commercial space companies contemplate artificial gravity again, potentially correcting a costly detour in humanity\u2019s path to becoming a spacefaring civilisation.Early space visionaries, su"
  },
  {
    "title": "Ubuntu 25.10 Raises RISC-V Profile Requirements (omgubuntu.co.uk)",
    "points": 58,
    "submitter": "bundie",
    "submit_time": "2025-07-01T08:32:19 1751358739",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=44431828",
    "comments": [
      "Seems like a tough call for operating systems to do this when things are moving so fast. With risc-v its probably better to be future looking given current limitations but if a lower spec risc-v exploded in popularity you miss out.Debian decided, probably very sensibly at the time, to set their minimum target for their 32 bit arm hardfloat distro to armv7. I guess hardly anyone used armv6 with hardware floating point apart from some obscure Broadcom chip. Then the original Raspberry Pi was released, moved an insane number of units, and Debian users would have been stuck with no floating point. Fortunately Mike Thompson recompiled Debian for armv6 with hardfloat and that Debian fork (Raspbian) ended up becoming the basis for the official Raspberry Pi OS.reply",
      "RVA23 is actually a decent ISA for linux machines for the long term, RVA20 was not.Presumably there's going to be some hardware releases later this year that Ubuntu has early knowledge of.Does this line up with what riscv android will also require?reply",
      "> RVA23 is actually a decent ISA for linux machines for the long term, RVA20 was not.This is setting it all up to happen again with whatever is found to be wrong with RVA23.reply",
      "RVA20 was missing generally expected features, RVA23 isntRVA30 is N+1, presumably we wont see shipping devices for that until the early 2030sreply",
      ">Does this line up with what riscv android will also require?AIUI both Google and Microsoft selected RVA23 as baseline.reply",
      "Seems unlikely.reply",
      "Can you write a kernel patch / driver to trap the unsupported instructions and provide software implementations?reply",
      "Rva20 lacks vector support and hypervisor instructions, among other things.You\u2019re welcome to put a ton of effort in for dogshit performance on a bunch or $35 SBCs but the rest of us will just upgradeAnd don\u2019t worry, some vendor won\u2019t come in and magically save you - fedora is eyeing rv22 as their baseline.reply",
      "The Linux Kernel has math coprocessor emulation (mainly floating point stuff) that can be enabled if your CPU doesn't include it. This was common with consumer CPUs in the 1990s and some embedded CPUs today.Link here, although I'm sure it existed well before 2.6.12https://www.kernelconfig.io/config_math_emulationreply",
      "Can you rephrase your answer in a way that isn't brutally and unnecessarily hostile?reply"
    ],
    "link": "https://www.omgubuntu.co.uk/2025/06/ubuntu-riscv-rva23-support",
    "first_paragraph": "Distro to focus on newer, more capable hardware going forwardCanonical is bullish in promoting Ubuntu for RISC-V devices, be it enthusiast-orientated hardware like DeepComputing\u2019s RISC-V tablet, single-board computers, or embedded equipment.But with a new long-term support (LTS) release looming, it\u2019s rethinking the kind of RISC-V hardware it wants to support going forward.A recent bug report filed against Ubuntu\u2019s upgrading tool confirmed a major change with regards to the RISC-V requirements for the upcoming Ubuntu 25.10 release \u2014 most existing RISC-V devices will not be able to run Ubuntu 25.10.How come?Ubuntu 25.10 plans to bumps its baseline RISC-V profile (RVA) from RVA20 to RVA23. It may sound like a small jump but it has a big impact since the bulk of RISC-V devices currently sold don\u2019t support it.An RVA (RISC-V Application) profile is a specification that outlines the vector processing capabilities a RISC-V system must have, so \u201csoftware can rely on the existence of a certain s"
  },
  {
    "title": "Postcard is now open source (contraption.co)",
    "points": 77,
    "submitter": "philip1209",
    "submit_time": "2025-07-03T16:38:02 1751560682",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=44456827",
    "comments": [
      "This looks great but delivery via Amazon SES is a problem. I'm an academic and I tried to set up a work newsletter like this with Listmonk recently, but SES rejected my request to relieve me of sandbox mode for unspecified 'security reasons'. Everything was set up properly, it was under a domain under my personal name, I gave links to my profile page on my university website, ample explanation about what I would do with it (one email ever few months), that I would be the only sender, but they rejected it. So in the end I've opted for a hosted solution... anyone else had similar issues?reply",
      "Postcard originally used Postmark. But, Postmark deliverability has been decreasing. And, for the open-source version, I wanted to simplify dependencies. So, I moved it to SES.  It works for small lists, but won't scale to massive ones.I welcome PRs to add additional sending providers - it wouldn't be onerous.reply",
      "Would be nice to have just send using sendmail or what ever smtp server we chose. This is HN, and some of us have already done ip warming and to avoid any big players, as they all drop/block emails without telling their users and are not be trusted for reliable communication.reply",
      "SMTP is a must. My advice is to never bother with proprietary mailer APIs - you will need to change providers sooner or later (sometimes on short notice, if your current provider temporarily suspended you on a false positive for example), which is much easier when you just need to swap the SMTP credentials vs implementing yet another proprietary API. Plus it makes local testing easier - there's no shortage of \"fake SMTP for development\" projects out there.Of course, tech bros don't want you to do it, as it reduces their vendor lock-in.reply",
      "That's fair, I can add smtp config.Really I was just concerned about configuration overload from too many options. Seems like SMTP is worth splitting out, though.reply",
      "I think SMTP is the way to go unless you're actually using specific proprietary mailer API features and there's no way to do the same via SMTP.Solution is:* SMTP by default* if you want, some setup examples of using third-party mail services using their SMTP endpoint (most offer one)Again you don't have to, it's an open-source project and you owe nothing to anyone. But if you fancy doing it, this is the way to go and will save headaches later.reply",
      "postmark is a garbage now. This is coming from a previous postmark advocate and moved to SES.SES is terrible in the past but now it is at least on-par if not better than postmark.Only issue with SES is setup can be tedious.reply",
      "What provider doesn\u2019t suck in this space?reply",
      "I actually had the same issue getting rejected for SES since I didn't have any reputation or something and ended up re-implementing the SES (and SNS) api for use with a regular IMAP/SMTP server, I intended to clean it up and open-source it but never got to it.reply",
      "While I admire social-network-friendly websites, I am afraid that performance is too bad to allow its use instead of a social network.Indeed it is so performance sensitive, that it has blocked my region.\nWould it not be better to get a static site generator from a standard Markdown posts, and thus assure it is both performant and accessible?reply"
    ],
    "link": "https://www.contraption.co/postcard-open-source/",
    "first_paragraph": ""
  },
  {
    "title": "AI for Scientific Search (arxiv.org)",
    "points": 87,
    "submitter": "omarsar",
    "submit_time": "2025-07-03T15:19:20 1751555960",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=44455950",
    "comments": [
      "I was hoping for this to announce a tool for research.Anyone know of the best way to do something like:\"Find most relevant papers related to topic XYZ, download them, extract metadata, generate big-picture summary and entity-relationship graph\"?Having a nice workflow for this would be the best thing since sliced bread for hobbyists interested in niche science topics.Recently found https://minicule.com which is free and lets you search + import, but it focuses more on \"concept-extraction\" than LLM synthesis/summary.reply",
      "Hi, I'm the creator of https://tatevlab.com. It does something similar + aiming to be something like a \"spotify\" for research papers (currently working on a feature to allow creating and sharing personal collections). It summarizes papers based on practical potential and you can find papers based on similarity. Feedback is welcome.reply",
      "A while ago, I started working on two R packages for creating 'living reviews': metawoRld and DataFindR, see https://andjar.github.io/metawoRld/articles/conceptual_overv... . You do the broad literature search yourself, but the idea is to use LLMs to select relevant studies and perform data extraction in a structured, reproducible manner. The extracted data is stored in a git repository for collaboration and version tracking, with automated validation and website generation for presenting results.reply",
      "\"Structured and Reproducable\"reply",
      "Check out https://elicit.com/reply",
      "Seems potentially useful, thanks! Only drawback I can see is the small number of papers provided by the free plan, but that's reasonable I suppose.reply",
      "I've been trying to tackle this exact problem. Current process is to use exa.ai to collect a wide breadth of research papers. Do a summarization pass and convert to markdown. Search for more specific terms then give the relevant papers/context to Gemini 2.5 pro and say give me a summary. Looking for very specific resources and to be honest it's been a terrible process :|reply",
      "Linking to a nearby thread in case this is helpful: https://news.ycombinator.com/item?id=44457928reply",
      "I built a public literature review search tool for some graduate student friends that became pretty popular in the Santa Barbara area. It actually does exactly what you are describing.It\u2019s not neural network based: it leverages hierarchical mixture models to give a statistical overview of the data. It lets you build these analysis graphs via search or citation networks.Example: https://platform.sturdystatistics.com/deepdive?search_type=e...reply",
      "This is genuinely incredible, tried it using a recent-ish paper on the pharmacology and mechanisms of the Androgen Receptor and my mind is blown:https://platform.sturdystatistics.com/deepdive?fast=1&q=http...reply"
    ],
    "link": "https://arxiv.org/abs/2507.01903",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  }
]