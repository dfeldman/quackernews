[
  {
    "title": "Ghostty 1.0 (ghostty.org)",
    "points": 846,
    "submitter": "matrixhelix",
    "submit_time": "2024-12-26T20:14:57 1735244097",
    "num_comments": 194,
    "comments_url": "https://news.ycombinator.com/item?id=42517447",
    "comments": [
      "<3 This has been a work of passion for the past two years of my life (off and on). I hope anyone who uses this can feel the love and care I put into this, and subsequently the amazing private beta community (all ~5,000 strong!) that helped improve and polish this into a better release than I ever could alone.Ghostty got a lot of hype (I cover this in my reflection below), but I want to make sure I call out that there is a good group of EXCELLENT terminals out there, and I'm not claiming Ghostty is strictly better than any of them. Ghostty has different design goals and tradeoffs and if it's right for you great, but if not, you have so many good choices.Shout out to Kitty, WezTerm, Foot in particular. iTerm2 gets some hate for being relatively slow but nothing comes close to touching it in terms of feature count. Rio is a super cool newer terminal, too. The world of terminals is great.I\u2019ve posted a personal reflection here, which has a bit more history on why I started this, what\u2019s next, and some of the takeaways from the past two years. https://mitchellh.com/writing/ghostty-1-0-reflection\n \nreply",
      "Looks really awesome.  I'm going to sound like I don't belong in the hipster terminal club, but the reason I shied away from some of the other terminals is the lack of tabs, which looks like yours has when I did a quick Google question/search.  (if wezterm and the like have them, I must have missed it or it wasn't obviously apparent in the settings how to achieve them).I know everyone will say but tmux and/or native multiplexing bla, but I'm kind of old school and only do screen remotely if needed, and I just like a lot of terminal tabs in my workflow with a quick mod left/right arrow to navigate between (and if native multiplexing in Ghostty is simple and easy I'd probably do some of that too). \n Perhaps this is why I've never left iterm2.\n \nreply",
      "Wezterm does have tabs, and their related keyboard shortcuts are configurable.See https://wezfurlong.org/wezterm/config/lua/keyassignment/Spaw... for a starting point in the config.\n \nreply",
      "Thanks!\n \nreply",
      "I also use tmux, but I love the native tabs of Konsole in KDE. I have Shift-Arrow configured to move between them, it is far more comfortable than the dual shortcuts needed by tmux, Ctrl-B to call tmux's attention then l (if I remember correctly) to get to the last tab.Konsole also has easy resizing of text and supports images in the console, you might like it.\n \nreply",
      "I just tried, \"tmux bind -n S-Left prev\"... works. Thank you, good idea. I now have 'S-Up switch-client -n' and 'S-Down last'\n \nreply",
      "We've got native tabs and splits on both macOS and Linux. :)WezTerm has tabs but they're not native UI elements.\n \nreply",
      "Right, I was admittedly too lazy to dig far enough with wezterm it appears.  Was looking for the button to click I guess.\n \nreply",
      "Quick correction: I currently use Wezterm on Linux and it has tabs. Alacritty does not for developer philosophical reasons.Looking forward to checking out Ghostty.\n \nreply",
      "Wezterm has tabs right out of the box and they are fully customizable, though I prefer tmux since I prefer to not have my data extinguished if I accidentally close the terminal :DWezTerm shines in ease and breadth of configurability due to using lua, so it's simple to have the theme change between light/dark depending on host OS theme.\n \nreply"
    ],
    "link": "https://ghostty.org/",
    "first_paragraph": ""
  },
  {
    "title": "The CAP theorem of Clustering: Why Every Algorithm Must Sacrifice Something (codingconfessions.com)",
    "points": 41,
    "submitter": "fagnerbrack",
    "submit_time": "2024-12-26T23:04:17 1735254257",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42518562",
    "comments": [
      "It's interesting idea but so I don't see it as a matter of tradeoffs since just the \"richness\" sounds undecidable by itself. I mean, dividing a set into \"things have low Kolmogorov complexity and things having high Kolmogorov complexity\" is definitely undecidable so \"any grouping that might make sense for your data\" seems impossible without any other requirements.\n \nreply",
      "The \"richness\" definition also seemed hand wavey to me so I looked at the referenced paper. The actual definition of \"richness\" of an algorithm is that for any arbitrary partition P of your original data (singletons, one cluster, etc), there is a distance function on the data, which when used in the clustering algorithm, produces P.\n \nreply",
      "A cute and thought-provoking theorem for sure, but arguably none of the three given criteria for clustering are well motivated, so the result is much less relevant than usually claimed.- scale-invariance: stretching data along some dimensions should not change clustering.This is clearly not true:  . . . (three well-spaced spots) may be reasonably seen as three clusters, whereas ||| (three nearby elongated bars) not.- richness: all groupings must be reachable.Also not quite true, both of the two cases: (1) all clusters are singleton points and (2) a single cluster that contains all points, mean the same: no useful cluster structure found. So it is enough if one of these groupings are reachable, and not both.- consistency: increasing inter-cluster differences and decreasing intra-cluster differences should not change clustering.Also not quite true: suppose we have 9 clusters:  . . .\n  . . .\n  . . .\n\nnow move the points so that the columns get further apart, at some point we will get:\n|  |  |, where 3 clusters are more reasonable.\n \nreply",
      "Actually, scale-invariance only refers to scaling all dimensions by the same scalar (this is more clearly specificed in the paper linked by the article, page 3). For arbitrary scaling on each coordinate, of course you're correct, it's impossible to have a clustering algorithm that is invariant for such transformations (e.g., the 6-point group ::: may look like either 2 or 3 clusters, depending on whether it's stretched horizontally or vertically).As for your last two points, I believe I agree! It seems that in the counterexample you give for consistency, some notion of scale-invariance is implicitly assumed -- perhaps this connection plays some role in the theorem's proof (which I haven't read).This reminds me a bit of Arrow's impossibility theorem for voting, which similarly has questionable premises.\n \nreply",
      "Sounds like Richness is an index in SQL terms.  Would you agree?\n \nreply"
    ],
    "link": "https://blog.codingconfessions.com/p/the-cap-theorem-of-clustering",
    "first_paragraph": ""
  },
  {
    "title": "Sub-pixel distance transform (2023) (acko.net)",
    "points": 94,
    "submitter": "ChadNauseam",
    "submit_time": "2024-12-26T20:48:01 1735246081",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42517685",
    "comments": [
      "Discussed at the time:Sub-pixel distance transform - https://news.ycombinator.com/item?id=36809404 - July 2023 (31 comments)\n \nreply",
      "> some of the established practice on generating SDFs from masks is incorrectSDFs are for some reason riddled with false beliefs. Earlier this year it drove me nuts to learn that boolean operations for SDFs are not correct\n \nreply",
      "How would you even do a boolean operation over two distances ?\n \nreply",
      "Inigo Quilez (who is basically the CEO of SDFs in my book) has a page on this: https://iquilezles.org/articles/interiordistance/.The goal isn't boolean operations over distances themselves, because as you point out that makes no sense. What you often want though is boolean operations over the surfaces the functions are returning the distance to. For example, you have one function that gives the distance to the surface of a sphere, and another that gives the distance to the surface of a cube, and you want to AND them, to get a function that gives you the distance to whichever surface is closer. That explanation probably doesn't make any sense, so just check out the page I linked which has some great visualizations.\n \nreply",
      "> boolean operations for SDFs are not correctThey're not?\n \nreply",
      "They return approximations which can be very slow to iterate over depending on how far off of the actual value they are.\n \nreply",
      "I mentioned it in another comment, but Inigo Quilez has a page on this: https://iquilezles.org/articles/sdfxor/.\n \nreply",
      "What do you mean by \"boolean operations for SDFs are not correct\"?\n \nreply",
      "Most of them are approximations instead of exact, so they can produce incorrect SDFs.\n \nreply",
      "I've not seen \"Grumpy wizards make toxic brew for the evil queen and jack\" before. Is suppose to be a pangram?I see no H.Edit: oh wow. I missed that one.\n \nreply"
    ],
    "link": "https://acko.net/blog/subpixel-distance-transform/",
    "first_paragraph": "This page includes diagrams in WebGPU, which has limited browser support. For the full\u00a0experience, use Chrome on Windows or Mac, or a developer build on other\u00a0platforms.In this post I will describe Use.GPU's text rendering, which uses a bespoke approach to Signed Distance Fields (SDFs). This was borne out of necessity: while SDF text is pretty common on GPUs, some of the established practice on generating SDFs from masks is incorrect, and some libraries get it right only by accident. So this will be a deep dive from first principles, about the nuances of subpixels.The idea behind SDFs is quite simple. To draw a crisp, anti-aliased shape at any size, you start from a field or image that records the distance to the shape's edge at every point, as a gradient. Lighter grays are inside, darker grays are outside. This can be a lower resolution than the target.Then you increase the contrast until the gradient is exactly 1 pixel wide at the target size. You can sample it to get a perfectly ant"
  },
  {
    "title": "A Tongue-in-Cheek Look Back at Broderbund's 'The Print Shop' (theprintshop.club)",
    "points": 12,
    "submitter": "mikerg87",
    "submit_time": "2024-12-26T23:53:52 1735257232",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42518808",
    "comments": [
      "I had The Print Shop Deluxe and remember thinking it was the future, and that we woull all be making our own holiday cards, signs, etc. in no time. Every holiday, I'm amazed that everyone I know (including me) is now back to using store-bought cards. I was surprised to just find out that there is a modern version, though it is Windows-only.\n \nreply",
      "I remember the Print Shop as a kid! Yah I guess specialization won out. We don't even have to see our holiday cards now. Upload a photoshopped picture and mail merge and start getting compliments from friends and family a week later.\n \nreply",
      "One of the most useful pieces of software of all time. You couldn't go far without seeing a mini banner made in Print Shop.\n \nreply",
      "Print Shop is what we used in my 1994 elementary school \"special topics\" class to do the student newspaper. One of the factoids was like, \"the world record for balancing golf balls on top of each other is 8\" and the person making that part of the paper inserted and visually stacked all 8 golf balls, and I remember thinking, \"this is so cool!\"What a world!\n \nreply",
      "The Print Shop and Bannermania have been extremely popular in Turkey in the 80\u2019s and 90\u2019s.\n \nreply"
    ],
    "link": "https://theprintshop.club/2021/07/12/a-tongue-in-cheek-look-back-at-broderbunds-the-print-shop/",
    "first_paragraph": "The Print Shop ClubIn the early 1980s, if you wanted posters to advertise a yard sale or a party, your options were pretty limited.You could get some blank sheets of paper and some crayons or felt markers for the whole do-it-yourself experience, which was cheap but unless you were a professional illustrator the results were bound to leave something to be desired, if not be downright embarrassing. Otherwise you could get the local printer to do it but it wasn\u2019t going to be very cost-effective, especially in such a small quantity. Each poster could end up running you the same price as a Big Mac \u2013 or even a whole Meal Deal \u2013 and with that kind of overhead it could make the whole yard sale endeavour smell much less appetizing. And so, usually it was back to the felt markers or whatever else you could find lying around the house, and being the tightwad you were you would not-so-happily contribute an additional indignity to the ever-growing mountain of your own personal shame, because you wa"
  },
  {
    "title": "Write Your Own Virtual Machine (2022) (jmeiners.com)",
    "points": 122,
    "submitter": "sebg",
    "submit_time": "2024-12-26T19:30:18 1735241418",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42517164",
    "comments": [
      "As a teenager I took an intro CS class at a community college, and the instructor had us design a simple cpu instruction set, and write our own VM and assembler that worked and let me write and run assembly programs. It was shockingly easy, and it was amazing how much is demystified computers for me.I feel like one could learn every level of computing this way- from designing a real cpu for a FPGA, to writing a simple OS and programs that run on it. This stuff is all shockingly simple if you just want it to work and don\u2019t need all of the extra performance and security modern computing needs.\n \nreply",
      "Our CS 101 class had such a system. Simple computer/assembler written in BASIC on the PDP.One of the assignments was to do a simple multiply (i.e. add in a loop).Rather than do that, my friend simply altered the program and created a new MUL command.The teacher was not amused.\n \nreply",
      "Teachers don't want extra work.My first 360 assembler class our first assignment: add two numbers, fault, print the crashdump and circle the answer to the ADD in the printout.I wrote an RPN calculator, had it do a series of calculations and print the result. Turned that in.The teacher wrote on it \"You have 24 hours to turn in the required assignment\"\n \nreply",
      "That sounds like a fun class! It sounds very similar to https://www.nand2tetris.org/ or Charles Petzold's book \"Code\".\n \nreply",
      "I think once you move from early fantasy CPUs to early CPUs in production such as 80286, the complexity immediately moves up drastically. IIRC it involves at least memory segmentation,  protected mode (MMU).\n \nreply",
      "True enough, but having designed a \u201cfantasy cpu\u201d gives you a better frame of reference for understanding the more complex features of a cpu (privilege levels, memory segmentation, virtual addresses, cache hierarchy, etc.)I often feel like those who haven\u2019t done the exercise of understanding the ISA of a \u201cfantasy cpu\u201d have a really hard time understanding those more advanced features.I guess all I am saying is that learning the \u201cfantasy cpu\u201d still has value even if everything else in the real world is more complex.Walking before running and all that.\n \nreply",
      "I've been doing some planning for a 24-bit fantasy CPU,  my plan is to make it pretty baroque.  For instance it has some instructions to do things like unpack UTF-8 strings into chars, do alpha compositing, etc.  The CPU part looks like a strange mainframe that didn't quite get built into the 1970s and it is coupled to a video system that would make a Neo-Geo blush.\n \nreply",
      "agreed! A fantasy CPU is good for the first project.\n \nreply",
      "80286 is the PHP of CPUs.A wonderfully different early CPU with plenty of existing software is the https://en.wikipedia.org/wiki/RCA_1802 which was a target of the https://en.wikipedia.org/wiki/CHIP-8 interpreter.\n \nreply",
      "the 80286 has its own problems/inessential complexityif you look at this from the riscv angle, moving from \"u-mode only vm that doesn't use paging under the hood\" to \"u+s-mode vm with sv39\" isn't an enormous jump in complexity imoi think i might teach it starting as like, \"sv21\" (page tables aren't nested), then pose real sv39 and the tree structure as the solution to making a sparse mapping over 512GiBthen moving on to the idea of having a TLB is simple, especially if students have already been introduced to hashtables\n \nreply"
    ],
    "link": "https://www.jmeiners.com/lc3-vm/",
    "first_paragraph": "By: Justin Meiners and Ryan PendletonView the final code and other resources in the GitHub repo.In this tutorial, I will teach you how to write your own virtual machine (VM) that can run assembly language programs, such as my friend\u2019s 2048 or my Roguelike. If you know how to program, but would like to gain a deeper understanding of what is going on inside a computer and better understand how programming languages work, then this project is for you. Writing your own VM may sound a little scary, but I promise that you will find it to be surprisingly simple and enlightening.The final code is about 250 lines of C (unix, windows).\nAll you need to know is how to read basic C or C++ and how to do binary arithmetic.Note: This tutorial is a literate program.\nThis means you are reading the source code right now!\nEach piece of code from the VM project will be shown and explained thoroughly, so you can be sure nothing is left out.\nThe final code was created by \u201ctangling\u201d the blocks of code togethe"
  },
  {
    "title": "A Tour of WebAuthn (imperialviolet.org)",
    "points": 146,
    "submitter": "caust1c",
    "submit_time": "2024-12-26T18:27:49 1735237669",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=42516800",
    "comments": [
      "There are some hairy edge cases during registration that many get wrong. (At least GitHub and google  had this bug) that if create() returns but the passkey never reaches the server due to bad networking conditions that your password manager thinks it can log in but the server never recorded the passkey for the user. Basically there is no transactionality and you can get in a split brain situation where your password manager and your server don't agree and it's very confusing for end users.https://github.com/w3c/webauthn/issues/2038They apparently came up with a fix for this using something called Signals API but I don't think any browser implemented that yet.Just wanted to highlight that this part of the UX is hairy and hard to get right\n \nreply",
      "Chrome on desktop did: https://developer.chrome.com/docs/identity/webauthn-signal-a...\n \nreply",
      "Looks like an amazing resource for webauthn. Currently diving into this so it comes at a nice time for me.But it's also great advertising against WebAuthn. Hard to believe that this kind of complexity is needed, but as with OpenID Connect it feels like enterprise  interests are running the ship, not end-users. Ease of implementation seems like a non-goal.\n \nreply",
      "It interested me how quickly all of my auth methods started to include \"pick the right one of three presented numbers\" tests after TOTP got widespread. I'm guessing there is some replay method which they wanted to prevent? This is distinct from in protocol large random value challenges, it must be to ensure a Hooman, or very numerate dog is actually present.\n \nreply",
      "Pick the right number is not secure (enough), unfortunately - MFA exhaustion leads to users hitting one of three at random in an attempt to \"make the notifications stop\" (that are, naturally, being spammed by the attacker with a password but no mfa).The attacker just has to spam them a few dozen times to get the victim to pick the right one at random and let the attacker in.This is why it's switched on good platforms to \"type in the number you see\", which mitigated this.\n \nreply",
      "TOTP codes are phishable and repayable in real-time - both via web (visiting the wrong site which asks for a TOTP and relays it within a few seconds), and via social engineering over the phone (give us one of the codes to prove it's you and we can keep your account safe).Adding number matching or similar helps ensure that the same user is initiating the session as is approving it - an issue when people discovered that Microsoft (among others) would do push messages to authenticate a login, and that users (if spammed late at night with constant requests), would often eventually hit allow to stop the notifications.\n \nreply",
      "I've always wanted to write a serverless OIDC provider/SAML IdP but got stymied by the WebAuthn standards, which don't seem to be written for normal people.  :(  But this e-book looks like it might have enough actual code interleaved with exposition to serve as more than just a high-level intro.\n \nreply",
      "Adam Langley is probably one of the most gifted teachers when it comes to explaining cryptography concepts.  Very clear, concise, precise, and makes it simple enough for me to follow without getting my neurons all knotted up.\n \nreply",
      "Agreed, I implemented TLS key pinning for a project at Okta using one of Adam's blog posts\n \nreply",
      "OIDC providers are surprisingly NOT complicated! I created one to implement single sign-on with AWS, and it ended up being only around 200 lines of code in Go. All you need to do is create a JSON blob that is signed by a public key that is known to the consumer of the IDP.I'll need to do a write-up for it.\n \nreply"
    ],
    "link": "https://www.imperialviolet.org/tourofwebauthn/tourofwebauthn.html",
    "first_paragraph": "This book was distributed at the FIDO Authenticate conference in\n2024. Its intended format was as a PDF, which you can find here.The following is the contents of the PDF converted to HTML.Adam Langley2024-12-23Passwords are rubbish.If you\u2019re reading this book then hopefully you\u2019re already on board\nwith this idea, but let\u2019s recap anyway.The typical practice with passwords is to remember a few different\nones and re-use them widely. (Password managers support generating\nrandom passwords, but people mostly don\u2019t.) Sites must store hashes of\nthese passwords to recognize them, but most passwords have too little\nentropy to resist brute-forcing when the hashes leak. (The website\nhaveibeenpwned.com now has records of about 13.5 billion accounts that\nhave been found in account database leaks from nearly 800 websites.)When a password database leaks, not only can any successfully cracked\npasswords be used immediately to sign in to that site but, because of\npassword re-use, those users\u2019 accounts on"
  },
  {
    "title": "A Simple ELF (4zm.org)",
    "points": 146,
    "submitter": "signa11",
    "submit_time": "2024-12-26T18:10:23 1735236623",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=42516697",
    "comments": [
      "I haven't done a proper write-up yet but this is my current technique for emitting minimal ELF files written in freestanding C:1. hand-written minimal ELF headers, with enough asm to do `_exit(main(argc, argv))`: https://github.com/DavidBuchanan314/kurl/blob/main/golfed/el... (currently only implemented for aarch64)2. \"Linux Syscall Support\" library for conveniently making raw syscalls from C: https://chromium.googlesource.com/linux-syscall-support/3. To avoid custom linker scripts (which I hate with a passion), I embed my hand-crafted ELF within a regular ELF, and slice it out at the end (using a python script). The \"container\" ELF is a regular full-fat ELF, potentially including working debug symbols, but the inner ELF has none of the cruft.Using this technique, I wrote a barely-functional TLS1.3 client that fits in ~3.5KB (see the rest of repo from the first link)\n \nreply",
      "The Linux kernel source tree has nolibc [1], a header-only C standard library implementation that is about as barebones and paper-thin as it gets and is the next step up from a pure freestanding environment as shown in this article. I've used it to create a tiny but working program that prints out the ASCII table [2] as part of my Ghidra extension test suite.[1] https://github.com/torvalds/linux/tree/master/tools/include/...[2] https://github.com/boricj/ghidra-delinker-extension/tree/mas...\n \nreply",
      "If you think this sort of thing is fun, you'll enjoy this: https://github.com/jcalvinowens/asmhttpd/blob/master/asmhttp...It's a webserver written in x86 assembler, which makes raw syscalls. It has no functions, and unmaps the stack so it uses only one 4KB page of memory at runtime.\n \nreply",
      "I love articles like this. If you want to see a tutorial on how you can take this a step further, by creating a tiny ELF file that runs on Linux, FreeBSD, NetBSD, and OpenBSD 7.3 then check out https://justine.lol/sizetricks/#elf\n \nreply",
      "I would also recommend the legendary Teensy Files:https://www.muppetlabs.com/~breadbox/software/tiny/They sparked my interest in ELF and freestanding programs.\n \nreply",
      "If anyone's interested, last year I replicated this exercise for an x86-64 Linux executable [0], and also golfed a Hello World as small as I could. I ended up using a little-known pattern (an ET_DYN executable with no interpreter, normally only used for the ld.so binary) to shave off more bytes than anyone else who had tried it, to the best of my knowledge.[0] https://tmpout.sh/3/22.html\n \nreply",
      "And Chris Wellons' \"A Magnetized Needle and a Steady Hand,\" detailing how to build an ELF implementation of 'true' using nothing more than 'echo' or 'printf': https://nullprogram.com/blog/2016/11/17/\n \nreply",
      "Huge fan of that blog and its author!\n \nreply",
      "For 32-bit x86 (i386 and i686), I've written a libc and a toolchain to.automate this: https://github.com/pts/minilibc686 . It can use mainstream free C compilers (GCC, Clang, OpenWatcom cc386, TinyCC and PCC) and assemblers (GNU as and NASM) out of the box.A printf-hello-world is about 1 KiB. A write-hello-world (syscalls only) is less than 200 bytes. Assembly programming skills not needed to use it.\n \nreply",
      "A while ago, I created an interactive explanation of the different parts of a minimal ELF file: https://scratchpad.avikdas.com/elf-explanation/elf-explanati...I wrote this page for my own compiler that I'm working on, but I think it would be a good complement to this article. Note that the page is not that great on mobile, the extra real estate on desktop really helps.\n \nreply"
    ],
    "link": "https://4zm.org/2024/12/25/a-simple-elf.html",
    "first_paragraph": "Let's write a simple program for Linux. How hard can it be? Well, simple is the opposite of complex, not of hard, and it is surprisingly hard to create something simple. What is left when we get rid of the complexity from the standard library, all the modern security features, debugging information, and error handling mechanisms?\u2022  \u2022  \u2022Let's start with something complex:Wait, what?! It doesn't look very complex, does it... Hmm, let's compile it and take a look:Still looks pretty simple, right? Wrong! While this might be familiar territory and easy to comprehend, the program is far from simple. Let's take a look behind the curtain.That's a lot of symbols! Actually, as far as symbol tables go, this one is quite modest. Any non-trivial program will have many more symbols, but still, what are they all for? We're just printing a string!We recognize our main function in the .text segment at address 0x1149. But where is the printf function?It turns out that for simple cases, where there is no"
  },
  {
    "title": "Write a Shell in C (2015) (brennan.io)",
    "points": 63,
    "submitter": "sebg",
    "submit_time": "2024-12-26T19:53:39 1735242819",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42517303",
    "comments": [
      "Honestly this was one of the most influential pieces of writing I've ever read. Back in the day this opened up a lot of the implementation details on interpreters and C for me. It quite literally helped \"get\" how programs are designed and written.I found this piece around eighth grade and I'm very glad I did! :-)\n \nreply",
      "For people who are interested in this stuff, I really recommend just getting a copy of Advanced Programming in the UNIX Environment and flipping through all (or most) of it. Pretty de-mystifying (and a good argument for caring about what OS you use!).Then you can pick up some book on shells (Effective Linux at the Command Line is one I'm going through right now), and you can piece a lot of it together.There's no magic, just a combo of decent ideas working together. But no single idea is hard to implement. Maybe just hard to come up with from scratch.\n \nreply",
      "Related. Others?Write a Shell in C - https://news.ycombinator.com/item?id=26126010 - Feb 2021 (80 comments)Write a Shell in C (2015) - https://news.ycombinator.com/item?id=13112589 - Dec 2016 (68 comments)Write a Shell in C - https://news.ycombinator.com/item?id=8907392 - Jan 2015 (8 comments)\n \nreply",
      "I wrote a toy shell last summer and this was one of the pieces I referred to most.Writing the beginnings of a shell is surprisingly easy. fork() and exec() do all the heavy lifting. I would recommend it as a great systems programming exercise.\n \nreply",
      "The glibc manual has a section about writing a job control shell: https://www.gnu.org/software/libc/manual/html_mono/libc.html...\n \nreply"
    ],
    "link": "https://brennan.io/2015/01/16/write-a-shell-in-c/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I've made a Monte-Carlo raytracer for glTF scenes in WebGPU (github.com/lisyarus)",
    "points": 87,
    "submitter": "lisyarus",
    "submit_time": "2024-12-26T17:24:28 1735233868",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42516433",
    "comments": [
      "Very cool. I did a similar project with wgpu in Rust - https://github.com/bezdomniy/Rengin\nnice to find your projects to see where I can improve!\n \nreply",
      "It's a mega-kernel, so you'll get poor occupancy past the first bounce. A better strategy is to shoot, sort, and repeat, which then also allows you to squeeze in an adaptive sampler in the middle.> // No idea where negative values come from :(I don't know, but:> newRay.origin += sign(dot(newRay.direction, geometryNormal)) * geometryNormal * 1e-4;The new origin should be along the reflected ray, not along the direction of the normal. This line basically adds the normal (with a sign) to the origin (intersection point), which seems odd.Poor's man way to find where the negatives come from is to max(0,...) stuff until you find it.\n \nreply",
      "> A better strategy is to shoot, sort, and repeatDo we have good sorting strategy whose costs are amortized yet? Meister 2020 (https://meistdan.github.io/publications/raysorting/paper.pdf) shows that the hard part is actually to hide the cost of the sorting.>  squeeze in an adaptive sampler in the middle.\nCan you expand on that? How does that work? I only know of adaptive sampling in screen space where you shoot more or less rays to certain pixels based on their estimated variance so far.\n \nreply",
      "> It's a mega-kernel, so you'll get poor occupancy past the first bounceSure! If you look into the to-do list, there's a \"wavefront path tracer\" entry :)> new origin should be along the reflected rayI've found that doing it the way I'm doing it works better for preventing self-intersections. Might be worth investigating, though.\n \nreply",
      "It probably works better when the reflected ray is almost tangent to the surface. But that should be an epsilon case.\n \nreply",
      "Do you have a link that runs in the browser?\n \nreply",
      "Nope, this project is desktop-only\n \nreply",
      "You should try building it with Emscripten. SDL2 is supported.\n \nreply",
      "> \"GPU \"software\" raytracer\"> WebGPU> this project is desktop-onlyBoss, I am confused, boss.\n \nreply",
      "I'm using WebGPU as a nice modern graphics API that is at the same time much more user-friendly and easier to use compared to e.g. Vulkan. I'm using a desktop implementation of WebGPU called wgpu, via it's C bindings called wgpu-native.My browser doesn't support WebGPU properly yet, so I don't really care about running this thing in browser.\n \nreply"
    ],
    "link": "https://github.com/lisyarus/webgpu-raytracer",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A software raytracing engine written in WebGPU\n      See more screenshots in the screenshots directory.This is a GPU \"software\" raytracer (i.e. using manual ray-scene intersections and not RTX) written using the WebGPU API. It expects a single glTF scene as input. It supports flat-colored and textured materials with albedo, normal, and material maps. It doesn't support refraction (yet).There are a bunch of test scenes in the test_scenes directory.It uses wgpu-native WebGPU implementation, and SDL2 to create a window to render to.To run the program, first build it (see instructions below), then run it with a single glTF scene in the command arguments. For example, if you've built the project in a build directory inside the project root, then you can run ./webgpu-raytracer ../test_scenes/bunny/bunny_100k.gltf.An optional second comman"
  },
  {
    "title": "Cognitive load is what matters (minds.md)",
    "points": 1560,
    "submitter": "zdw",
    "submit_time": "2024-12-22T22:18:12 1734905892",
    "num_comments": 653,
    "comments_url": "https://news.ycombinator.com/item?id=42489645",
    "comments": [
      "I've been thinking about the notion of \"reasoning locally\" recently. Enabling local reasoning is the only way to scale software development past some number of lines or complexity. When reasoning locally, one only needs to understand a small subset, hundreds of lines, to safely make changes in programs comprising millions.I find types helps massively with this. A function with well-constrained inputs and outputs is easy to reason about. One does not have to look at other code to do it. However, programs that leverage types effectively are sometimes construed as having high cognitive load, when it in fact they have low load. For example a type like `Option<HashSet<UserId>>` carries a lot of information(has low load): we might not have a set of user ids, but if we do they are unique.The discourse around small functions and the clean code guidelines is fascinating. The complaint is usually, as in this post, that having to go read all the small functions adds cognitive load and makes reading the code harder. Proponents of small functions argue that you don't have to read more than the signature and name of a function to understand what it does; it's obvious what a function called last that takes a list and returns an optional value does. If someone feels compelled to read every function either the functions are poor abstractions or the reader has trust issues, which may be warranted. Of course, all abstractions are leaky, but perhaps some initial trust in `last` is warranted.\n \nreply",
      "> A function with well-constrained inputs and outputs is easy to reason about.It's quite easy to imagine a well factored codebase where all things are neatly separated. If you've written something a thousand times, like user authentication, then you can plan out exactly how you want to separate everything. But user authentication isn't where things get messy.The messy stuff is where the real world concepts need to be transformed into code. Where just the concepts need to be whiteboarded and explained because they're unintuitive and confusing. Then these unintuitive and confusing concepts need to somehow described to the computer.Oh, and it needs to be fast. So not only do you need to model an unintuitive and confusing concept - you also need to write it in a convoluted way because, for various annoying reasons, that's what performs best on the computer.Oh, and in 6 months the unintuitive and confusing concept needs to be completely changed into - surprise, surprise - a completely different but equally unintuitive and confusing concept.Oh, and you can't rewrite everything because there isn't enough time or budget to do that. You have to minimally change the current uintuitive and confusing thing so that it works like the new unintuitive and confusing thing is supposed to work.Oh, and the original author doesn't work here anymore so no one's here to explain the original code's intent.\n \nreply",
      "> Oh, and the original author doesn't work here anymore so no one's here to explain the original code's intent.To be fair, even if I still work there I don't know that I'm going to be of much help 6 months later other than a \"oh yeah, I remember that had some weird business requirements\"\n \nreply",
      "Might I recommend writing those weird business requirements down as comments instead of just hoping someone will guess them six months down the line?\n \nreply",
      "So even if comments are flawlessly updated they are not a silver bullet. Not everyone are good at explaining confusing concepts in plain English so worst case you have confusing code and a comment that is 90% accurate but describe one detail in a way that doesn't really match what the code says.  This will make you question if you have understood what the code does and it will take time and effort to convince yourself that code is in fact deterministic and unsurprising.(but most often the comment is is just not updated or updated along with the code but without full understanding, which is what caused the bug that is the reason you are looking at the code in question)\n \nreply",
      "> So even if comments are flawlessly updated they are not a silver bullet.This \"has to be perfect in perpetuity or it is of no value\" mentality I don't find helpful.Be kind to FutureDev.  Comment the weird \"why\"s.  If you need to change it later, adjust the comment.\n \nreply",
      "Thing is, good documentation has to be part of the company's process. eg, a QA engineer would have to be responsible for checking the documentation and certifying it. Costs money and time.You can't expect developers, already working 60 hour weeks to meet impossible deadlines, to spend another 15 hours altruistically documenting their code.\n \nreply",
      "Any documentation at all > no documentation, 99 times out of 100. And requiring your people to work 60 hours/week is symptomatic of larger problems.",
      "Every line of documentation is a line of code and is a liability as it will rot if not maintained. That\u2019s why you should be writing self documenting code as much as possible that\u2019s obviates the need for documentation. But unlike code, stale/wrong doc will not break tests.Spending 15 hours documenting the code is something no leader should be asking of engineering to do. You should not need to do it. Go back and write better code, one That\u2019s more clear at a glance, easily readable, uses small functions written at a comparable level of abstraction, uses clear, semantically meaningful names.Before you write a line of documentation, you should ask yourself whether the weird thing you were about to document can be expressed directly in the name of the method of the variable instead. Only once you have exhausted all the options for expressing the concept in  code, then, only then, are you allowed to add the line of the documentation regarding it.",
      "Don't let perfect be the enemy of good.\"We don't write any documentation because we can't afford a dedicated QA process to certify it\" <- that's dumb.\n \nreply"
    ],
    "link": "https://minds.md/zakirullin/cognitive",
    "first_paragraph": "The logo image was taken from Reddit.It is a living document, last update: December 2024. Your contributions are welcome! There are so many buzzwords and best practices out there, but most of them have failed. We need something more fundamental, something that can't be wrong.Sometimes we feel confusion going through the code. Confusion costs time and money. Confusion is caused by high cognitive load. It's not some fancy abstract concept, but rather a fundamental human constraint. It's not imagined, it's there and we can feel it.Since we spend far more time reading and understanding code than writing it, we should constantly ask ourselves whether we are embedding excessive cognitive load into our code. Cognitive load is how much a developer needs to think in order to complete a task.When reading code, you put things like values of variables, control flow logic and call sequences into your head. The average person can hold roughly four such chunks in working memory. Once the cognitive lo"
  },
  {
    "title": "Gondwanaland: The search for a land before (human) time (australiangeographic.com.au)",
    "points": 37,
    "submitter": "bryanrasmussen",
    "submit_time": "2024-12-26T17:39:10 1735234750",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42516512",
    "comments": [
      "> \u201cThese rainforests were historically neglected by tourists and walkers in favour of supposedly more \u2018Australian\u2019 eucalypt forests,\u201dI don't think that's correct.  Lamington National Park, one of the mentioned rainforests, was gazetted in 1915 and has long been a mecca for walkers, tourists and bird watchers.  The O\u2019Reilly and Binna Burra guest houses have been there for almost 100 years.https://parks.desi.qld.gov.au/parks/lamington/about/centenar...\n \nreply",
      "Would humans be able to live on earth 400m years ago if we time travelled back to Gondwanaland, considering the 7x CO2 and hot tropical climate?\n \nreply",
      "Yes, sure. Just imagine being somewhere 5-10C warmer and a few hundred metres higher in elevation than where you are now.\n \nreply",
      "I do see significant change from our current dependence on fossil fuels, but for argument\u2019s sake, what\u2019s the best case scenario for global warming and climate change? Could we create a super verdant earth epoch? What probability do our most advanced climate models have for such an outcome? And what\u2019s the economic cost of moving coastal populations and those in high risk zones to new cities designed from ground up using the latest thinking in urban planning? What\u2019s the cost benefit from high one off relocation costs to long term gains from smarter cities?\n \nreply",
      "Thought this might be about Fastmail's Bron Gondwana\n \nreply",
      "I find geology's power fascinating.A person was once able to surmise from geological features that India was once part of Africa.(He was resoundingly mocked of course.)\n \nreply",
      "It is fascinating once we consider how little, both of technology and mobility scientists had in the past. To verify some little fact they had to wait months, years.\n \nreply",
      "Also, from the distribution of lemurs.  Before plate tectonics this lead to the idea of the sunken continent of Lemuria, which has since migrated into weird science fantasy stories.\n \nreply",
      "Ozs don't need to feel so isolated. Their continent is moving north towards China & will one day ram into it.\n \nreply",
      "https://archive.is/ewwb1\n \nreply"
    ],
    "link": "https://www.australiangeographic.com.au/topics/history-culture/2024/09/gondwanaland/",
    "first_paragraph": ""
  },
  {
    "title": "Differential Growth Addon for Blender (okunskiy.name)",
    "points": 245,
    "submitter": "kelseyfrog",
    "submit_time": "2024-12-26T04:41:31 1735188091",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=42513157",
    "comments": [
      "Blender is an amazing piece of software.A few years ago I asked myself \"Why spend hundreds of hours sucking at video games when I could spend the same time sucking at Blender?\"Since then I have spent many an enjoyable evening making terrible 3d models, some of which actually made it into a game. Apart from my lack of skill, there is no reason why somebody like me can't do world-class renders in a piece of software they downloaded for free. It isn't even that hard to use any more.\n \nreply",
      "I just recently had this revelation! I a full time software dev who has dabbled in game dev for years, but i\u2019ve always given up on ideas because i can\u2019t make \u201cgood\u201d art/assets. just a couple of months ago it dawned on me that i love inept/amateurish/DIY/outsider art in most other mediums (except writing maybe) and decided to just put time into to awkward crappy looking models. and i love them! now i\u2019m just trying to create a distinctive shambolic aesthetic for my tiny games. it\u2019s so freeing.\n \nreply",
      "\"distinctive shambolic aesthetic\", what a great phrase. I use the friend of every hack fraud - \"extreme stylization\" to cover a multitude of sins.Somebody actually nominated my interactive fiction game for a best graphics ribbon, which amused me no end.I have often thought that we spend too much time studying and trying to emulate the great artists, musicians, and writers. It is more productive to see what the mediocre talents are doing, how their works succeed, and try to copy their techniques. Even if you fail you will find your own voice and produce something distinctive.\n \nreply",
      "I agree - one of those bits of software you can't believe is free. I've also done some pretty terrible modelling, even my doughnuts suck.\n \nreply",
      "Those are the best kind!\n \nreply",
      "Maybe also check out this free Blender geometry nodes differential grown add-on from the brilliant Alex Martinelli\u2026https://www.blendernation.com/2023/07/25/differential-growth...\n \nreply",
      "I think a cool addition would be to add a light source, and inhibit growth when a vertex doesn't receives light.\n \nreply",
      "Maybe also to inhibit growth when exposed to a saline environment?If this were recreated in Blender\u2019s geo nodes these functions would be relatively easy to add using the raycast node.\n \nreply",
      "This is really cool, I'd echo other comments here that ask for a math explainer - I'd love to understand exactly what's going on under the hood.\n \nreply",
      "https://inconvergent.net/generative/differential-line/\n \nreply"
    ],
    "link": "https://boris.okunskiy.name/posts/blender-differential-growth",
    "first_paragraph": "Latest Release \u00b7 Tutorial VideoThere\u2019s something inexplicably fascinating about the shapes and patterns occurring in nature.People have always been attracted to organic forms, as is evidenced by an endless number of various design elements found in human craft and art since prehistoric times; the \u201cMother Nature\u201d has always been a source of inspiration and symbolism for people throughout the globe. The desire to contemplate and reflect upon the organic processes seems to be an inherent part of human nature.In search for beauty people have come up with a large number of tools and ways to produce organic patterns.Today I\u2019m proud to introduce my humble contribution to the generative art ecosystem \u2014 Differential Growth Addon for Blender. Fully in-line with Blender Manifesto, it\u2019s open source, completely free to use and built with tons of love.A few examples follow.If you like what you see, please feel free to grab the latest release from GitHub. The star \ud83c\udf1f is also a great way to show your a"
  },
  {
    "title": "Magnetic swarm intelligence of mass-produced, programmable microrobot assemblies (cell.com)",
    "points": 7,
    "submitter": "bookofjoe",
    "submit_time": "2024-12-26T21:43:47 1735249427",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.cell.com/device/fulltext/S2666-9986(24)00583-0?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2666998624005830%3Fshowall%3Dtrue",
    "first_paragraph": ""
  },
  {
    "title": "Thermodynamic model identifies how gold reaches Earth's surface (phys.org)",
    "points": 6,
    "submitter": "wglb",
    "submit_time": "2024-12-26T23:11:21 1735254681",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://phys.org/news/2024-12-thermodynamic-gold-earth-surface.html",
    "first_paragraph": ""
  },
  {
    "title": "Inverse Design of Complex Nanoparticle Heterostructures via DL on Graphs (chemrxiv.org)",
    "points": 10,
    "submitter": "pizza",
    "submit_time": "2024-12-26T21:04:51 1735247091",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://chemrxiv.org/engage/chemrxiv/article-details/6769dc3a81d2151a02b75ef6",
    "first_paragraph": ""
  },
  {
    "title": "A Minecraft server written in COBOL (github.com/meyfa)",
    "points": 259,
    "submitter": "notamy",
    "submit_time": "2024-12-26T03:59:54 1735185594",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=42513022",
    "comments": [
      "> Well, there are quite a lot of rumors and stigma surrounding COBOL. This intrigued me to find out more about this language, which is best done with some sort of project, in my opinion. You heard right - I had no prior COBOL experience going into this.I hope they'd write an article about any insights they gained. Like them, I hear of these rumors and stigma, and would be intrigued to learn what a new person to COBOL encountered while implementing this rather complex first project.\n \nreply",
      "One of the rumoured stigma is that the object-oriented flavour of COBOL goes by the unwieldy name of ADD ONE TO COBOL YIELDING COBOL.At least it doesn't have the unrumoured stigma of older FORTRANs, which ignored whitespace, allowing:    DO 10 I=1.10\n\nto silently compile an assignment:    DO10I = 1.10\n\ninstead of signalling an error for the syntax of the loop the flight software programmer had intended:    DO 10 I=1,10\n \nreply",
      "No one seems to have written a Minecraft server in FORTRAN yet... but I think your comment just gave some people here ideas.\n \nreply",
      "If you have to go to 1977 or prior to slag a language, there are tons of languages that will disappoint you.\n \nreply",
      "PL/I\n \nreply",
      "I would assess C++ has already outpaced PL/I complexity, and I do enjoy using C++.\n \nreply",
      "You can get a C++ compiler which is (more or less) correct,  I'm not sure that was ever quite true of PL/I.\n \nreply",
      "Yeah, I love these insights.If you are interested, here are insights from making a COBOL to C# compiler: https://github.com/otterkit/otterkit-cobol/issues/40I am now convinced that COBOL is just a high level assembler.\n \nreply",
      "This is Awesome.For my high school graduation project, I wrote a full COBOL system to automate soccer betting odds. Long past its prime, but my school hadn\u2019t quite caught up with the times.It was hilariously out of place, but I loved every line of it. There\u2019s something oddly satisfying about a language that whispers, \u201cRemember punched cards?\u201d as you type.\n \nreply",
      "I'm sure this is some kind of fallacy, but I feel I quite often see ostensibly impressive small side projects like this written in simple plain languages like C (or here COBOL). Every similar, e.g., Rust project I see seems almost non-functional despite having 10x the SLOC.My working theory is that simpler languages lend themselves to blueprinting ideas and getting something working even with an ugly messy codebase, whereas modern languages force you to write code that will last longer. Or maybe modern languages are just doing something wrong.\n \nreply"
    ],
    "link": "https://github.com/meyfa/CobolCraft",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A Minecraft server written in COBOL\n      \nA Minecraft server written in COBOL. It supports Minecraft 1.21.4 (the latest version at time of writing).The following features are already working:Note that blocks with multiple states, orientations, or interactive blocks require large amounts of specialized code\nto make them behave properly, which is way beyond the scope of this project.\nSome are supported, however:CobolCraft was developed using GnuCOBOL and is meant to be run on Linux.\nSupport for other operating systems such as Windows has not been tested.\nHowever, it is possible to use Docker for a platform-independent deployment.To deploy on Linux, make sure all prerequisites are installed:Then execute make to build, followed by make run to start a server on port 25565.Or, using Docker:To configure the server, edit the server.propert"
  },
  {
    "title": "Siyuan: Privacy-first, self-hosted personal knowledge management software (github.com/siyuan-note)",
    "points": 244,
    "submitter": "thunderbong",
    "submit_time": "2024-12-26T02:26:39 1735179999",
    "num_comments": 116,
    "comments_url": "https://news.ycombinator.com/item?id=42512713",
    "comments": [
      "Looks cool, but as I have been on this knowledge management / productivity journey like everybody. Here are my findings:If you are reasonably comfortable with computers / Unix.- You need to first rely on a directory structures, filenames, plaintext, lists and maybe markdown. Stick with a \"File over app\", Unix approach.- Try to sort things with universal concepts: locations, things, people, events, metrics, howtos. A bit like the 5Ws approach.- Leverage good Unix tools: unix commands, make/justfiles, (rip)grep, git, fzf, etc.- Do not try to solve the problem through the Web. Because you will end up trying to solve web problems instead of basic knowledge management and productivity issues.- The smartphone/touchscreen is a major problem, but as with the Web do not try to solve it. Use your file manager or even fzf in termux can be adapted to be reasonably usable on a touchscreen.Something I have been wondering about is the \"backlink\" feature. It would be cool to link items/notes together through references. \nWhat I would be looking for is a Unix tools that can scan my text files for references to other files in the hierarchy.\n \nreply",
      "I've been experimenting with Flatnotes (https://github.com/Dullage/flatnotes) for a while and really like the design. No notebooks or even folders, just a single directory with markdown files and decent search & tagging. It feels a lot like what happened to email when we gave up all the up-front structuring with deep hierarchies and just said index it and we'll find it when we need to.The project is just \"good enough\" for what I need, and aside from tiny bugs whenever I find a gap I can either work around it or live without. Constraints are a powerful motivator for both creativity and getting stuff done.\n \nreply",
      "Tagging is a strictly more powerful tool than hierarchies, at least with same amount tags vs directories/categories, because an item can be tagged using multiple different tags, but can only be in one directory, unless you create duplicates or symlinks or whatever.\n \nreply",
      "I find the opposite. Being forced to consider hierarchical categorisation leads to a more powerful system in practice. It helps me create a mental reference to the item being stored. And it often causes me to see a better way to form an item in the first place \u2014 eg maybe this note is really two notes, maybe this idea can actually just be discarded, etc. Or, on rare occasions, a new item doesn\u2019t fit anywhere (but is important) so I need to tweak the hierarchy itself \u2014 and that\u2019s a good thing, once in a while, as it can lead to creative insights about the domain as a whole.I\u2019ve found tagging systems usually become a kind of dark swamp where things go never to be seen again. The lack of structure means I have little memory of what\u2019s gone into the system, so I end up with too much duplication of ideas and inconsistency of style (mess). All this makes it uninviting and difficult to \u2018explore\u2019, so I don\u2019t use it much except as a dumping ground, and the swampiness compounds over time.\n \nreply",
      "Hierarchy doesn\u2019t make sense if you care about multiple dimensions, which I often do with notes.Sometimes I want to look at all notes relating to c++, sometimes everything related to a personal project. Directories don\u2019t support that without symlinking everything that mentions c++ into a folder for that.\n \nreply",
      "I really like tagging but somehow the concept could never become central to any filesystem:- I believe BeOS tried,- MS tried with WinFS but cancelled it in Windows Vista,- I am sure some cloud storage service bet on it but can't cite any.Actually tagging is probably mainly successful in cases where we can reliably automate the tagging such as email or photos.\n \nreply",
      "MacOS has had first-class support for file tagging for years: You can add arbitrary tags either from \u201cSave as\u201d dialogs or from Finder, and can then browse by tags in Finder or search through your file system filtered by tags.\n \nreply",
      "I like tagging for bookmarks in Firefox and derivatives of Firefox.\n \nreply",
      "This is exactly the conclusion I came to. I still use Obsidian for a lot of things, but I've developed my own task management software that uses plain text files and fzf for everything: https://codeberg.org/ngp/tskIt has worked great for me! That being said, sync and mobile usage is still a bit of a sore spot with it. It works beautifully with Termux, but I wish there was some way to slap a basic UI on top of a CLI application for mobile. Tk/Tcl is the closest but there's only options on Android (I'm mostly an iOS user) and even then it's not really ideal. For sync, I at least have a reasonable plan: IMAP4 or git-based sync. The roadmap and tasks for the project are tracked in-repo with itself, so it definitely works.\n \nreply",
      "If you want some windows-forms-esq app development, I highly recommend checking out Flutter Flow. It isn\u2019t exactly cheap, but I\u2019ve used it for some basic personal apps.\n \nreply"
    ],
    "link": "https://github.com/siyuan-note/siyuan",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A privacy-first, self-hosted, fully open source personal knowledge management software, written in typescript and golang.\n      \n\n\nRefactor your thinking\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u4e2d\u6587 | \u65e5\u672c\u8a9e\nSiYuan is a privacy-first personal knowledge management system, support fine-grained block-level reference and Markdown\nWYSIWYG.Welcome to SiYuan English Discussion Forum to learn more.Most features are free, even for commercial use.Some features are only available to paid members, for more details please refer to Pricing.It is recommended to give priority to installing through the application market on the desktop and mobile, so that you can upgrade the version with one click in the future.Mobile:Desktop:The easiest way to serve SiYuan on a server is to deploy it through Docker.The overall program is located under /opt/siyuan/, which is basically th"
  },
  {
    "title": "Cull Front: A new front end generator for Htmx and AlpineJS (cullfront.com)",
    "points": 18,
    "submitter": "limenleap",
    "submit_time": "2024-12-26T17:37:00 1735234620",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42516497",
    "comments": [
      "I like the idea of a separate tree, but would prefer something other than a child-list for building the tree.  I find building a graph with an outward-edge list (which is what this does) to be more error prone and less clear than a either the braces or indentation based approach that is more common; IMO the only advantage to an edge-list is to make circular graphs, which isn't needed here.[edit]Also, if you are going to have lists that will be edited a lot, don't require commas for separating items; splicing lists with only whitespace for separators is a much faster operation in many editors.\n \nreply",
      "Splitting code into multiple files and lowering cohesion is quite far from \"separation of concerns\". It makes changes, navigation and reasoning artificially harder. It's like tearing building blueprint into random pieces.\n \nreply",
      "I coded new kind of front-end generator. You can \"kaizen\" into your HTML frontend/website with at least 40% less typing. It allows separation of concerns and you can code using HTMX and AlpineJS (or equivalent tech) Been planning this for a long time -- finally coded it on Christmas day.   https://cullfront.com/   The website is sparse. But do read the documentation -- it explains everything. This is fresh off the oven. So kindly let me know your thoughts.\n \nreply",
      "This is awesome. Can't help but be reminded of linker step -> compiler step. Hm I wonder what the analogy of static versus shared libraries would feel like here. Or LD_PRELOAD ;)\n \nreply",
      "It is a Windows, no source provided executable. No idea what response you expected but it is what I expected ;)\n \nreply"
    ],
    "link": "https://cullfront.com",
    "first_paragraph": "Version 0.5Design front-end/sites like an architect, not a carpenter.\n\u00a9 Sabu Francis, 2024. All rights reserved. This is donation-ware.\n        If I raise at least $20,000 USD, I will definitely open-source this.\nDonate!DownloadDocumentationFeedbackLast release date: Dec 26, 2024"
  },
  {
    "title": "Ocular AI (YC W24) Is Hiring a Founding Backend Engineer ($120K to $200K, SF) (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-12-26T17:33:54 1735234434",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/ocular-ai/jobs/BFBHWQd-member-of-technical-staff-founding-backend-engineer",
    "first_paragraph": "Data engine for Generative AI, Computer Vision, and Enterprise AI.Ocular AI is the data annotation engine for Generative AI, Computer Vision, and Enterprise AI models.We help companies transform unstructured, multi-modal data into golden datasets to power generative AI, frontier models, and computer vision.Ocular Foundry is the most intuitive, data-centric, and fastest platform that lets you label, annotate, version, and deploy your data for training models. It also orchestrates your annotation jobs, improving collaboration with members and annotators.With Ocular Bolt, shift from humans in the loop to experts in the loop to supercharge your data labeling and annotation projects. Our global expert workforce ensures fast, accurate results\u2014no matter the scale or complexity of your data.In just 3 months, our small team of 3 (including founders) has achieved remarkable progress, making this an exceptional opportunity for you to join a fast-moving, well-funded startup backed by top investors"
  },
  {
    "title": "OpenAI is Visa \u2013 Buttering up the government to retain a monopoly (sherwood.news)",
    "points": 145,
    "submitter": "gpi",
    "submit_time": "2024-12-26T19:44:51 1735242291",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=42517260",
    "comments": [
      "Lol, visa had network effect.It also took a long time to build up such a network.Replacing all payment terminals is not easy. And as a customer I'm more likely to care of my card works and not care if I'm charged x% fee.The visa trick if any, was hiding the credit card fee and pushing it to merchants.\nWhether its a trick or not is hard to tell, for small businesses it was probably bad, but for a big business dealing with lots of cash is probably not cheap.\n \nreply",
      "Doesn't explain what regulations Visa pushed for and got which helped it maintain its monopoly. Would be helpful to have some concrete examples of what it did and what OpenAI is trying to do.The point of the article sounds plausible, but doesn't really present any evidence to support it.Also OpenAI in no way has a monopoly of the kind that Visa/MC has.\n \nreply",
      "> Also OpenAI in no way has a monopoly of the kind that Visa/MC has.I think this is misreading how literal the comparison is meant to be; Sherwood's running a bunch of \"OpenAI is X\" articles today. This is not about the massive duopoly which has been catastrophic for US payments, but about the way companies entrench themselves.> Doesn't explain what regulations Visa pushed for and got which helped it maintain its monopoly.Those details are in the linked WSJ article; https://www.wsj.com/finance/banking/visa-wanted-a-vast-empir...> but doesn't really present any evidence to support it.The main points of concern are mentioned; OpenAI is pushing for \"AI regulation\" that focusses on the nebulous \"doomsday\"/skynet scenarios, rather than any of the material harms of AI. The subtext of that is a straightforward \"you should ban anyone else building AI because only we can do it safely\".Similarly, OpenAI demanding it's investors not fund competitors is pretty ridiculous and explicitly trying to establish a monopoly.\n \nreply",
      "> I think this is misreading how literal the comparison is meant to be; Sherwood's running a bunch of \"OpenAI is X\" articles today.This is ... a useful piece of information with which to update our credulity of the narrative these articles are trying to present.\n \nreply",
      "https://sherwood.news/tech/what-companys-past-reveals-the-fu... provides more context as to what the articles are trying to achieve.\n \nreply",
      "The duopoly isn\u2019t really as problematic as the concept itself. Credit cards, where customers are bribed to insert a middleman into all transactions and suppliers are largely powerless to refuse it; are a plague. The switching costs of a consumer to a different credit card are small. The switching cost of a business saying they no longer allow certain payment types is potentially very painful.\n \nreply",
      "Credit cards are probably the most consumer friendly innovation ever \u2014 a product of the time they were developed. It was an era when the federal government functioned and the credit card operations were so problematic a heavy hand was required.Every supposedly better alternative adds margin for the supplier, increases the risk of fraud, and leaves the user with poor recourse due to the lack govnerment regulation.Adding a 3% overhead is cheap for the value. Let the suppliers be squeezed - it\u2019s tiny for big merchants and the little ones are bitching because they\u2019d rather lose sales than pay taxes.\n \nreply",
      "> Those details are in the linked WSJ article; https://www.wsj.com/finance/banking/visa-wanted-a-vast-empir...if you're trying to make a point in an article, summarize your evidence rather than link to a paywalled article that your readers may not be able to access\n \nreply",
      "Yea, I don't want to defend Visa, but a lot of their dominance came from network effects. Merchants want to accept Visa because it's what people have in their wallet. Customers want Visa because it's what merchants accept. That cycle keeps reinforcing itself.That's not to say that Visa hasn't worked toward favorable regulations, but the biggest problem with alternative payment networks (to Visa/MC/Discover/AMEX) is that most retailers don't take them which means most customers don't want to set them up. If most customers don't have those payment methods, there's little incentive for a merchant to setup those payment methods.With OpenAI, there isn't the same network effect. I don't care what LLM you're using or what LLM Walmart or anyone else is using. If Anthropic or Google start offering better/cheaper LLMs, companies can simply switch over. Maybe some integrations will need to be rewritten, but that's a lot easier than getting hundreds of millions of customers to sign up for something new. Plus, companies like Google are simply implementing the OpenAI API so that integrations don't have to be rewritten.By contrast, if another company launches a payment network, it isn't enough just to convince a company to switch. You need to convince millions of consumers to switch - which would require convincing enough companies to switch.\n \nreply",
      "> Yea, I don't want to defend Visa, but a lot of their dominance came from network effects.I think it's worth noting that VISA is also really doing a pretty good job. Like the cards work. Here in Europe they seem eager to adopt emerging technology and are willing to invest to maintain their dominance.There's a ton of not so consumer friendly backroom deals with kickbacks for the banks and stuff, but the core product is roughly what consumers desire. A card that works almost 100% of the time without any difficulty. While simultaneously implementing and adopting whatever weird regulations get passed into law.They are, in my opinion, doing a decent job.\n \nreply"
    ],
    "link": "https://sherwood.news/tech/openai-is-visa/",
    "first_paragraph": "Buttering up the government to retain a monopoly.OpenAI is on the verge of becoming the Visa of artificial intelligence. Visa\u2019s success wasn\u2019t just about building a payments network; it was about creating barriers that locked in customers and locked out competitors. And just as Visa faced threats from national payment networks and tech giants, OpenAI must contend with competitors like Google, Meta, and Amazon.In 1958, 60,000 Californians got a fully working credit card in the mail. It was the first unsolicited credit-card drop, and it led to massive fraud and delinquency problems. Bank of America, which ran the campaign, realized it had to build a payments network with account verification and fraud detection. The network it built and licensed to other banks eventually became Visa, which IPO\u2019d in 2008 at a $44 billion valuation. Today the company is worth about $600 billion.But in the 2010s Visa faced numerous threats to its core business. Digital providers like PayPal and well-capital"
  }
]