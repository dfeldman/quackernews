[
  {
    "title": "Show HN: I got laid off from Meta and created a minor hit on Steam",
    "points": 273,
    "submitter": "newobj",
    "submit_time": "2025-02-26T18:19:05 1740593945",
    "num_comments": 105,
    "comments_url": "https://news.ycombinator.com/item?id=43186406",
    "comments": [
      "Congratulations! I saw Yahtzee playing this a few weeks ago \u2014 seemed like a good time. The market is notoriously saturated right now, any wisdom on how you broke through with marketing/outreach? (Or was that entirely on the publisher?)\n \nreply",
      "200,000 units is a far cry from just a 'minor hit' - congratulations!During the project, what was the biggest instinct you had that was ultimately validated by its success, but still surprised you? What was a lesson you learned that you didn't expect? How was working with a publisher? What did they do right and what did they do wrong?\n \nreply",
      "Honest answer? Dancing stick figure guy on the title screen. I did it very early in the project, in a fugue state at 3am. It lingered and lingered there, with ppl wondering \"Is this real? Is this the actual title screen?\" and luckily by the end I think everyone had drank enough psychedelic koolaid to agree - stick figure man stays. The artist made some better art for his hands/feet, and that was that. He's divisive, but everybody at least remembers him :)Lesson learned that I didn't expect - hmm. Ah, one good one: I spent a LOT of time worrying about stuff being \"OP\" or degenerately good. Well, turns out, people like OP stuff, or degenerately good stuff, at least in single player score attack games. My biggest lesson learned on the project: people experience your game individually. If they find something broken, in their head, they are the one to have found something broken, and it feels good. You don't have to design for the entire community at once. Don't over-balance your game. Embrace the jank.\n \nreply",
      "> Embrace the jankLove this! I wish you would be been involved with the release team for Helldivers II.\n \nreply",
      "Did the dancing stick is Meta AI applied to some stick like this research paper ?https://ai.meta.com/blog/ai-dataset-animation-drawings/\n \nreply",
      "It's a stock animation from mixamo :P\n \nreply",
      "Stock assets: the first \u201cAI\u201d. Honestly still a better option than AI for most anything in game dev with a few workflow-oriented exceptions.\n \nreply",
      "The minute I read \u201cdancing stick figure\u201d I knew exactly what game we\u2019re talking about.I\u2019m not a stoner and am not really into stoner culture but I\u2019ve watched that figure dance for like 10 mins once, entranced by it.  I dunno what exactly it is, but it\u2019s just an absolute home run.I\u2019m not joking, I\u2019d pay for an app that\u2019s literally just that guy dancing to some music.\n \nreply",
      "My friend Joe from the Anime Sickos podcast talked Ballionaire up a lot and I'm looking forward to playing it, which would happen sooner if it were available on switch. Congrats on your success!\n \nreply",
      "Out of curiosity, what kind of margins do you get when you sell a game on Steam? Like, what percentage of a sale ends up in your bank account (pre-taxes).  Also, how do Steam sales affect that?Congrats on making a game to completion, and doubly so for making something that gets fairly popular.  Making a real game has been on my bucket list for about as long as I've known how to program, and I haven't completely given up on it, but I would need to make friends with someone who knows how to do art and music.\n \nreply"
    ],
    "link": "item?id=43186406",
    "first_paragraph": ""
  },
  {
    "title": "TypeScript types can run DOOM [video] (youtube.com)",
    "points": 844,
    "submitter": "franky47",
    "submit_time": "2025-02-26T15:05:02 1740582302",
    "num_comments": 231,
    "comments_url": "https://news.ycombinator.com/item?id=43184291",
    "comments": [
      "> \"It was a brutal year long journey of 18 hour days\" [to run doom in TypeScript types]This is some serious dedication for what at first blush may sound to many to be a completely unserious, or even useless, achievement. But I say to those people: a DOOM proof is just as worthy of praise as any other academic mathematical proof, and has the advantage of being verifiable by laymen.Congrats on this amazing achievement.\n \nreply",
      "> year long journey of 18 hour daysI couldn't do it, even if I had the talent. I have to work to get money!\n \nreply",
      "I don't thinks statements like this are meant to be read literally in American English.IE US English speakers always fond of telling me how they work X hours in a day, or they went N days without sleep. Which used to really impress me, until I realised \"wait... do they just exaggerate as matter of course\"? And then I realised - of course they do; these are people for whom every purchase is an \"upgrade\"; where a bicycle for commuting in a city is an \"urban assault vehicle\", rich creamery butter, rich creamery type systems, etc etc.So no, I sincerely doubt they actually worked 18 hour days for a year straight. I'm sure they worked hard, but it's just the way Americans talk.\n \nreply",
      "The does video starts off with some serious hyperbole (noted for anyone reading this comment before watching the video)\n \nreply",
      "So much hyperbole that I thought the entire video was a spoof on the practice of making a Doom proof until about a minute in, where I asked aloud to an empty room, \"Wait, this is real?\"Also, he forgot to credit the video itself, which has a really high production value!  Kudos all around!\n \nreply",
      "[flagged]",
      "The video will probably do pretty well, giving him some personal traction for his channel or reputation. Also because hackers gonna hack.\n \nreply",
      "It's obviously for the person who did it.\n \nreply",
      "what's with hn being filled with assholes lately?\n \nreply",
      "The amount of \u201cwhy would somebody waste their time with this\u201d comments is pretty surprising.This guy is a legend now. Every developer slack channel at my company is buzzing about it\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=0mCsluv5FXA",
    "first_paragraph": ""
  },
  {
    "title": "iMac G4(K) (jcs.org)",
    "points": 114,
    "submitter": "ingve",
    "submit_time": "2025-02-26T22:25:10 1740608710",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=43188971",
    "comments": [
      "It's wild that there was a feeling when that computer came out of \"this is the coolest computer design ever,\" and then the world moved past that.You can look at the iMac line and see that they moved to a more laptopy everything-in-the-screen design, which got rid of the base altogether.  But it's weird and sad that there was a \"best\" and then things that came after the best that were less fun, and two decades later we all still seem to feel that way.I suppose part of that was all the attention that shifted to touchscreen phones, and computers becoming thought of as practical work tools.\n \nreply",
      "What's wild to me is that Gen Z and Gen Alpha are basically computer illiterate by and large.The reason old computers were fun is because all the hip young millennials loved them for everything.  That has become much less the case as the younger generations do everything with a phone/tablet/or console.  Just surfing the internet for my generation was a chore that is hard for the younger generations to understand.\n \nreply",
      "> What's wild to me is that Gen Z and Gen Alpha are basically computer illiterate by and large.That's something I've realized as well. There was a time where typing was something more and more people could do, but not nobody cares/needs to learn how. The number of households that had at least one computer was something I thought would get to pretty much everyone, but now there are more and more people with the only compute device being their phone. Owning a computer seems to be an age indicator like wearing tube socks.\n \nreply",
      "At least Framework released a new DesktopAnd they tried to be fun with it!The 3D printed tiles on the front are a very cool idea and just perfect right now I think! :-)https://frame.work/au/en/desktop\n \nreply",
      "I also like the colored backs on the 12 inch laptop they announced\n \nreply",
      "Well, those wild/creative designs WERE the \"practical work tools\".  Check out the PowerMac G3, this thing looks totally colourful and silly but this was the most powerful machine Apple made at the time:  https://www.flickr.com/photos/lhutton/48688728841/  (also dang I still really want one, still haven't found a good deal on one lol)\n \nreply",
      "I owned a G3 that was the last beige box Apple made before that clear plastic Fisher Price looking unit. I didn't mind the colorful iMacs. In my mind, the iMacs were fun things and the colors were okay, but the towers were meant to be serious computers and fun is just not allowed or something moronic. Those towers were just something I never cared for with no real reason. Oh, and the hockey puck mouse that came out around that time. Yuck\n \nreply",
      "Looking at imac G3->G4->G5 each one was a huge step in design. I think the G4 stands out to me because the \"floating\" display was something I had never seen before.\n \nreply",
      "It's reported to be making a comeback with the upcoming HomePod that has screen that can rotate to follow your presence\n \nreply",
      "that's not creepy at all. why would that sound like a good idea that someone would want?\n \nreply"
    ],
    "link": "https://jcs.org/2025/02/26/imacg4k",
    "first_paragraph": "A year ago I tried using an M1 iMac for work duty but its 21\" screen took up too\n\t\t\t\t\t\tmuch room on my desk.\n\t\t\t\t\t\tAfter seeing\n\t\t\t\t\t\tSean's video on Action Retro\n\t\t\t\t\t\tabout putting an M4 Mac Mini inside an\n\t\t\t\t\t\tiMac G4,\n\t\t\t\t\t\tI thought I'd give it a try.The\n\t\t\t\t\t\tJuicy Crumb DockLite G4\n\t\t\t\t\t\treplaces the main logic board in a 17\" or 20\" iMac G4 and turns its built-in LCD\n\t\t\t\t\t\tinto an HDMI monitor.\n\t\t\t\t\t\tIt also uses the iMac's custom power supply and has a built-in audio amplifier\n\t\t\t\t\t\tto be able to drive the\n\t\t\t\t\t\tApple Pro speakers\n\t\t\t\t\t\tthat were available for the iMac G4.\n\t\t\t\t\t\tSwapping the boards is easy and completely reversible.I ordered the DockLite G4 but it was going to take a few weeks to get.\n\t\t\t\t\t\tIn the mean time, I needed to find a 17\" iMac G4 in good condition but not fully\n\t\t\t\t\t\tworking so that I wouldn't be sacrificing a working machine.\n\t\t\t\t\t\tI eventually found one on eBay and I paid nearly as much for shipping as the\n\t\t\t\t\t\tmachine itself.\n\t\t\t\t\t\tThe iMac uses a"
  },
  {
    "title": "Replace OCR with Vision Language Models (github.com/vlm-run)",
    "points": 137,
    "submitter": "EarlyOom",
    "submit_time": "2025-02-26T19:29:37 1740598177",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=43187209",
    "comments": [
      "It\u2019s an interesting idea, but still way too unreliable to use in production IMO. When a traditional OCR model can\u2019t read the text, it\u2019ll output gibberish with low confidence; when a VLM can\u2019t read the text, it\u2019ll output something confidently made up, and it has no way to report confidence. (You can ask it to, but the number will itself be made up.)I tried using a VLM to recognize handwritten text in genealogical sources, and it made up names and dates that sort of fit the vibe of the document when it couldn\u2019t read the text! They sounded right for the ethnicity and time period but were entirely fake. There\u2019s no way to ground the model using the source text when the model is your OCR.\n \nreply",
      "Thing is, the majority of OCR errors aren't character issues, but layout issues. Things like complex tables with cells being returned under the wrong header. And if the numbers in an income statement are one column off creates a pretty big risk.Confidence intervals are a red herring. And only as good as the code interpreting them. If the OCR model gives you back 500 words all ranging from 0.70 to 0.95 confidence, what do you do? Reject the entire document if there's a single value below 0.90?If so you'd be passing every single document to a human review, and might as well not run the OCR. But if you're not rejecting based on CI, then you're exposed to just as much risk as using an LLM.\n \nreply",
      "Having experience in this area, audit, legal, confidence intervals are essential. No, you don't end up \"passing every single document\" to human review. That's made up nonsense. But confidence intervals can pretty easily flag poorly OCR'd documents, and then yes they are done by human review.If you try to pitch hallucinations to these fields, they'll just choose 100% manual instead. It's a non-starter.\n \nreply",
      "How about calculating confidence in terms of which output regions are stable across the same input on multiple tries. Expensive, but the hallucinations should have more variable output and be fuzzier than higher confidence regions in averages.\n \nreply",
      "This is the main focus of VLM Run and typed extraction more generally. If you provide proper type constraints (e.g. with Pydantic) you can dramatically reduce the surface area for hallucination. Then there's actually fine-tuning on your dataset (we're working on this) to push accuracy beyond what you get from an unspecialized frontier model.\n \nreply",
      "An effective way that usually increases accuracy is to use an ensemble of capable models that are trained independently (e.g., gemini, gpt-4o, qwen). If >x% of them have the same output, accept it, otherwise reject and manually review\n \nreply",
      "Existing solutions like Tesseract already can embed text into the image, but I'm wondering if there's a way to combine LLM with Tesseract, so that LLMs can help correcting results and finding unidentified text, and finally still embed text back to the image\n \nreply",
      "We recently published an open source benchmark [1] specifically for evaluating VLM vs OCR. And generally the VLMs did much better than the traditional OCR models.VLM highlights:- Handwriting. Being contextually aware helps here. i.e. they read the document like a human would, interpreting the whole word/sentence instead of character by character- Charts/Infographics. VLMs can actually interpret charts or flow diagrams into a text format. Including things like color coded lines.Traditional OCR highlights:- Standardized documents (e.x. US tax forms that they've been trained on)- Dense text. Imagine textbooks and multi column research papers. This is the easiest OCR use case, but VLMS really struggle as the number of output tokens increase.- Bounding boxes. There still isn't really a model that gives super precise bounding boxes. Supposedly Gemini and Qwen were trained for it, but they don't perform as well as traditional models.There's still a ton of room for improvement, but especially with models like Gemini the accuracy/cost is really competitive.[1] https://github.com/getomni-ai/benchmark\n \nreply",
      "Saw your benchmark, looks great. Will run our models against those benchmark and share some of our learnings.As you mentioned there are a few caveats to VLMs that folks are typically unaware of (not at all exhaustive, but the ones you highlighted):1.  Long-form text (dense): Token limits of 4/8K mean that dense pages may go over limits of the LLM outputs. This requires some careful work to make them work as seamlessly as OCR.2. Visual grounding a.k.a. bounding boxes are definitely one of those things that VLMs aren't natively good at (partly because the cross-entropy losses used aren't really geared for bounding box regression). We're definitely making some strides here [1] to improve that so you're going to get an experience that is almost as good as native bounding box regression (all within the same VLM).  [1][1] https://colab.research.google.com/github/vlm-run/vlmrun-cook...\n \nreply",
      "I've been experimenting with vlm-run (plus custom form definitions), and it works surprisingly well with Gemini 2.0 Flash. Costs, as I understand, are also quite low for Gemini. You'll have best results with simple to medium-complexity forms, roughly the same ones you could ask a human to process with less than 10 minutes of training.If you need something like this, it's definitely good enough that you should consider kicking the tires.\n \nreply"
    ],
    "link": "https://github.com/vlm-run/vlmrun-cookbook/blob/main/notebooks/01_schema_showcase.ipynb",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          "
  },
  {
    "title": "Tom Stevenson on the deciphering of Linear Elamite (lrb.co.uk)",
    "points": 41,
    "submitter": "eynsham",
    "submit_time": "2025-02-26T21:39:31 1740605971",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43188537",
    "comments": [
      "https://web.archive.org/web/20250226213901/https://www.lrb.c...https://archive.ph/Obx04",
      "A very well written article. Of interest also is the story of the Mahoubian collection, see http://mahboubiancollection.com/life-and-works/art-robbery-i... its confiscation in New York and following trials.\n \nreply",
      "That is chilling...\n \nreply",
      "Related; A cryptanalytic decipherment of the Indus Scripthttps://www.academia.edu/78867798/A_cryptanalytic_decipherme...\n \nreply",
      "Many have claimed to have deciphered those symbols, but it's not even clear that it is a script, in the sense of a way to write a language.\n \nreply",
      "No mention of the hypothesis about Dravidian being descended from Elamite?\n \nreply",
      "Why? It's a fairly fringe theory with very little linguistic support.\n \nreply"
    ],
    "link": "https://www.lrb.co.uk/the-paper/v47/n04/tom-stevenson/beyond-mesopotamia",
    "first_paragraph": "London Review of BooksMore search OptionsBrowse by SubjectDecipherments\u200b of ancient scripts are often attributed, and sometimes misattributed, to individual scholars: Jean-Jacques Barth\u00e9lemy and the Phoenician alphabet, Champollion and Egyptian hieroglyphs, Magnus Celsius and Staveless Runes, Michael Ventris and Linear B, Edward Hincks and Akkadian cuneiform, Yuri Knorozov and Maya glyphs. These were undeniable intellectual achievements. They were also endeavours tinged with madness. How else could anyone persist with such fiendishly difficult work? The 11th-century Arabic text on decipherment, The Book of Mad Desire for the Knowledge of Written Symbols, grasped something of this fact. Decipherment has attracted more than its fair share of formidable scholars, enthusiastic amateurs and crackpots, all seeking connection with a lost past, or the power to make obscure symbols speak. Who wouldn\u2019t want to be woken in the middle of the night, as Simon Kimmins was by his flatmate Ventris, and"
  },
  {
    "title": "Show HN: LLM plays Pok\u00e9mon (open sourced) (github.com/adenta)",
    "points": 105,
    "submitter": "adenta",
    "submit_time": "2025-02-26T19:31:25 1740598285",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=43187231",
    "comments": [
      "Related ongoing thread:Claude Plays Pok\u00e9mon - https://news.ycombinator.com/item?id=43173825",
      "I just find it insane that we're bootstrapping reinforcement learning and world planning on top of basic next token prediction.I'm amazed that it works, but also amazed that this is the approach being prioritized.\n \nreply",
      "Pure RL NN 'solved' simple games like Pok\u00e9mon years ago. I think added challenge of seeing how well LLMs can generalize is a noble pursuit. I think games are a fun problem as well.Look how poorly Claude 3.7 is doing on Pokemon on Twitch right now.\n \nreply",
      "> Pure RL NN 'solved' simple games like Pok\u00e9mon years ago.Please link to said project. From my search of Google filtered to 2010-2020, it returns nothing outside of proofs-of-concept (e.g. https://github.com/poke-AI/poke.AI) that do not perform any better, or instead trying to solve Pokemon battles which are an order of magnitude easier.\n \nreply",
      "Maybe they are conflating the Starcraft success that Deepmind had with AlphaStar?\n \nreply",
      "Super cool to see this idea working. I had a go at getting an LLM to play Pok\u00e9mon in 2023, with openai vision. With only 100 expensive api calls a day, I shelved the project after putting together a quick POC and finding that the model struggled to see things or work out where the player was. I guess models are now better, but also looks like people are providing the model with information in addition to the game screen.https://x.com/sidradcliffe/status/1722355983643525427?t=dYMk...\n \nreply",
      "The vision models still struggle in my experience. I got around that by reading the RAM and describing all the objects positions on screen\n \nreply",
      "You can also directly pull in the emulation state and map back to game source code, and then make a script for tool use (not shown here): https://github.com/pret/pokemon-reverse-engineering-tools/bl... Well I see on your page that you already saw the pret advice about memory extraction, hopefully the link is useful anyway.\n \nreply",
      "Yeah, took a similar approach at https://github.com/adenta/fire_red_agent/blob/main/app/servi...\n \nreply",
      "Have you considered calling this bot \"intern bot\"? - Jay\n \nreply"
    ],
    "link": "https://github.com/adenta/fire_red_agent",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          This is my attempt at getting a large language model to play Pok\u00e9mon FireRed autonomously. My bot has rudementery capabilities to play the game, explore, battle, and respond to game events.To me, this is the future of TV. While building the bot, I felt like I was producing television more than I was programming a computer. Ultimately, I ran into some technical hurdles around programmatic input control, which led me to pause development.Watch the demo video.\nWatch the technical deep dive.I used RetroArch to run Pok\u00e9mon FireRed. I struggled with sending inputs programmatically. RetroArch has a UDP-based input system (RetroPad), but I couldn't get it to work reliably.Instead, I resorted to using OSA Script (AppleScript) to send keyboard events to the emulator, which meant the game had to be in focus. This was a huge limitation because it took o"
  },
  {
    "title": "Launch HN: Maritime Fusion (YC W25) \u2013 Fusion Reactors for Ships",
    "points": 133,
    "submitter": "jtcohen",
    "submit_time": "2025-02-26T16:32:46 1740587566",
    "num_comments": 155,
    "comments_url": "https://news.ycombinator.com/item?id=43185246",
    "comments": [
      "Greybeard former fusion founder here.  Wishing you guys all the luck in the world!  Email in profile in case you wish to chat.For all the naysayers, as a fusion startup, targeting the marine market is a good move.  They aren't even the first fusion startup to do so; IIRC Rostoker's group got their first major funding from the NRL. The marine market pays a premium for not having to refuel, and historically emerging energy technologies have early commercialization in ships.  This was true for fission in the 50s and for photovoltaic solar in the 70s/80s.Now, sure, they have to make power to be able to sell it.  But to build a reactor, you have to raise funds, and in order to raise funds you have to show that you can make money if you are successful at making power.  Explicitly aiming at a market that might actually pay for overpriced power shows their investors that there may be a valid business case.  That doesn't make fusion happen any easier, but you don't make any reactions without first building a reactor.You know, I'm sure these guys could work somewhere getting paid to get more people to click on stuff.  Instead they are taking a risk to do something that might be important.  Make no mistake: fusion founder is a tough gig.  There is no established off-ramp, and many fusion founders find that it's a job that can easily eat your career. I hope their plan B is in order, as well as their prenups and/or wills.  They are going off to fight a dragon that's eaten a lot of other people's careers, relationships and sanity.As an aside, it's nice to see someone working on a tokamak actually not being overly optimistic about wall heat flux. It's like somebody actually paid attention to Stacey or something ;)\n \nreply",
      "No naysayer here, just curious:- What does this bring to the table beyond marine fission power?- Why do they think they can make it cheaper than military fission marine power?\n \nreply",
      "There is at least the possibility that fusion power could eventually be viable for privately owned civilian merchant ships. Fission power is a non-starter in that market due to concerns (valid or not) over security, terrorism, proliferation, and meltdowns. Even if someone builds a new fission powered merchant ship it would be useless because many nations wouldn't allow it to enter their ports.Military fission power plants were never optimized for cost. They have always been hand built in tiny numbers with a focus on safety, durability, and maximal output.\n \nreply",
      "Aren't the products of fusion equally radioactive? I get that we all have the idea of helium being the main product, but don't you get a lot of tritium out of the process? It's not quite proliferation, but it's not non-radioactive either.\n \nreply",
      "Thank you very much !!! Really appreciate this :)\n \nreply",
      "\"Downtime for maintenance is part of normal operations, making this a far more forgiving early application of fusion, unlike the grid where every down hour is lost revenue.\"Planned maintenance, sure, but unplanned maintenance means the same lost revenue, plus you're stuck floating in the middle of the pacific ocean, possibly in need of parts or debugging expertise that only exists half a planet away or, for that matter, food.  It's certainly a good idea to find a niche to make market entry easier, but I would guess that reliability requirements are actually higher for ships than for microgrids.  Find some isolated town or island running off flaky diesel generators on shipped-in fuel and negotiate a reasonable SLA.This ignores, of course, the bigger problem: making fusion work at all at Q > 1.  If it were me, I'd work on solving that before worrying too much about optimizing market entry.  So far every single fusion effort has failed to clear that hurdle, and any effort on the other parts is wasted if you can't actually make power.\n \nreply",
      "The first ocean-going steamships still had sails - it took many years for steam power to fully displace sail. Presumably a new maritime power system, like fusion, would follow a similar pattern.https://en.wikipedia.org/wiki/Steamboat#Sea-_and_Ocean-going\n \nreply",
      "There is something very compelling about a fusion-powered ship also having sails.\n \nreply",
      "Let's be realistic, it would have a diesel engine as a plan B.But if you like sails: my pet hypothetical technology is wind-driven hydrogen tankers (or tankers for some other e-fuel derived from hydrogen) that sail out empty, then cruise around wherever there is plenty of wind. They'd have a turbine/generator setup driven by the water passing by and use the energy harvested there for filling the tank. Cruise around as long as it takes to nearly fill the tank then return to port (and fill the rest on the way back). There's a lot of oceans where systems like that could cruise around on. (same concept could also be used for desalonation, there it would not only be about energy but also about avoiding local brine concentrations)\n \nreply",
      "Re Q>1, isn't that just the reaction making more power as heat than you put in and you need something like Q>5 to use the heat to make steam to make electricity to run the thing?  (as in wikipedia https://en.wikipedia.org/wiki/Fusion_energy_gain_factor)\n \nreply"
    ],
    "link": "item?id=43185246",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Tach \u2013 Visualize and untangle your Python codebase (github.com/gauge-sh)",
    "points": 145,
    "submitter": "the1024",
    "submit_time": "2025-02-25T16:34:07 1740501247",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43174041",
    "comments": [
      "Really excited to see this project gain traction.> Note that this graph is generated remotely with the contents of your `tach.toml`Isn't shipping off parts of your codebase to a 3rd party without warning in the CLI a security risk? Or in regulatory environments you get audited that your code was only stored on properly vetted services which is why some sales cycles for AI coding assistant tools are so long. It would be kind of frustrating to have something like that happen and get set back on licensing, etc.Just from the video it doesn't seem like any sort of warning that you are shipping config files to your servers and the URL that you produced doesn't seem to have any authentication.Maybe i am misunderstanding that functionality, but it gives me pause to use it.\n \nreply",
      "Co-author here, fair question!In short, we want to make the visualization UX as smooth as possible, and this is best done with a web app. The URLs use UUIDs, and the contents being sent don't include literal source code, only module names and Tach configuration. We will also delete graphs by UUID on request, and have done so in the past.That said, we do try to be up-front about this, which is why that disclaimer exists, and when running this command on the CLI, you must supply an explicit `--web` argument to `tach show`. Otherwise, the default behavior is to generate a GraphViz DOT file locally.\n \nreply",
      "> we want to make the visualization UX as smooth as possiblestill doesn't explain why you need to ship the data to a third party> and this is best done with a web appdebatable. you could always write a GUI app. it's not that hard for such a self-contained projectthere would be _a lot_ to gain from having this run totally locally without any network access and leaking source code to third parties.\n \nreply",
      "Why not just let users run the web app locally? There's no reason it needs to be remote.Also, the mere fact that it sends any data, no matter what you say it contains is a non-starter at many places. And even module names can contain proprietary data.\n \nreply",
      "I can understand the frustration, but I think there are legitimate reasons to run this remotely.Tach is an installable Python package, shipping a full web app would have to come in a separate form factor and has significant maintenance implications. Given we are explicit about the remote app before anything is sent, require explicit opt-in, and we provide usable alternatives locally, we prioritize shipping a useful graph experience that is immediately usable.If you are at an enterprise that cannot tolerate this, then you can use a local viewer with either GraphViz DOT format or Mermaid which is generated by using `tach show` or `tach show --mermaid` respectively.\n \nreply",
      "I appreciate the attempt but the reasoning of \"it requires maintenance\" is entirely moot. You have to do this regardless. Its just whether or not you publish it open-source. You are still saying, internally, this is good enough for customers, when you push it out.This is a (very) thinly veiled attempt at a closed garden of sorts, IMHO. Its a \"clean\" excuse for not giving away the milk for free, but it falls short on actual reasoning.\n \nreply",
      "Looking at the license (MIT) we already got much more than what we paid for and the authors don't \"have to\" do anything but accept thanks of those who chose to be grateful for software they got for free.\n \nreply",
      "This. It's ridiculous how often people complain about the design of free software. If you don't like it, just don't use it! Use something else! Build your own! Or fork it to work in the way you described that you'd prefer - you can do that yourself if you really want since the source is available\n \nreply",
      "I am having an allergic reaction too, I don't see any reason this should exfiltrate any information from my machine.\n \nreply",
      "There are hundreds of \"full web apps\" on PyPI. What's special about yours?\n \nreply"
    ],
    "link": "https://github.com/gauge-sh/tach",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A Python tool to visualize + enforce dependencies, using modular architecture \ud83c\udf0e Open source \ud83d\udc0d Installable via pip \ud83d\udd27 Able to be adopted incrementally - \u26a1 Implemented with no runtime impact \u267e\ufe0f Interoperable with your existing systems \ud83e\udd80 Written in rust\n      \n\n\n\n\n\nTach is a Python tool to enforce dependencies and interfaces, written in Rust.Tach is inspired by the modular monolith architecture.DocsDiscordTach can enforce:Tach is:Tach will guide you through initial project setup.Run:After an introductory message, you will see a file tree interface allowing you to interactively configure your project.Use the arrow keys to navigate, and mark each module boundary with 'Enter'. You can mark all of your top-level Python packages, or just a few that you want to track.If your Python code lives below your project root, or if you are working in "
  },
  {
    "title": "The man who spent forty-two years at the Beverly Hills Hotel pool (1993) (newyorker.com)",
    "points": 130,
    "submitter": "zeveb",
    "submit_time": "2025-02-26T17:45:19 1740591919",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=43186050",
    "comments": [
      "https://archive.is/eRc3M",
      "> Then Irving would either walk back home to his wife and two childrenWhat the... he'd leave his wife at home with the kids while he hung out all day at the pool with \"magnificent-looking young women, full of theatrical drive\" and eat all his meals at the hotel?\n \nreply",
      "In those days you didn\u2019t get divorced, you \u201cstayed together\u201d for the children.So they were effectively separated most of those years.  Just informally so.\n \nreply",
      "Article summary:\n\u201c Irving V. Link spent 42 years at the Beverly Hills Hotel pool, where his meticulous daily routine of breakfast, sunbathing, and gin rummy became legendary. He was admired by hotel staff and Hollywood figures alike, symbolizing the timeless charm of a bygone era in Los Angeles. His life was deeply intertwined with the hotel\u2019s evolution, reflecting the glamour of old Hollywood and the shifting dynamics of its clientele. The hotel\u2019s closure by the Sultan of Brunei for renovations disrupted his routine and marked the end of an era. Link\u2019s personal narrative weaves together memories of luxury, business intrigue, and cultural transformation. Ultimately, his story is a poignant meditation on the inevitability of change and the enduring power of tradition.\u201d\n \nreply",
      "Summary of Romeo & Juliet: \u201cA few teenagers get way too dramatic about a crush and end up dead.\u201dMy point being that for a story like this the journey is more important than the destination.\n \nreply",
      ">Ultimately, his story is a poignant meditation on the inevitability of change and the enduring power of tradition.\n\nI wish, occasionally, AI would close with  >Ultimately, his story is a trite and shallow distraction which fails to leave a lasting impression upon the reader.\n\nThe article may indeed be a \"poignant meditation\" (I liked it personally). but when AI shoehorns the last sentence of every summary into this exact same sort of vaguely-positive cliche, it becomes worthless as an uncorrupted signal of real information.A fun experiment would be to ask your favorite AI   \"Find me a recent article that is not worth reading and has no worthwhile journalistic, philosophical, emotional, or any other kind of takeaways.\"\n\nThen (separately) ask it to summarize the article and see how it closes...\n \nreply",
      "Thanks I was just thinking I wish Firefox had a 1 paragraph summary button next to the reader button.  Then I came to comments and saw this.\n \nreply",
      "https://orbitbymozilla.com/\n \nreply",
      "It's built into Safari now too.\n \nreply",
      "(1993).   The hotel reopened in 1996 but Irving never returned.https://www.latimes.com/archives/la-xpm-1996-05-19-ls-5806-s...\n \nreply"
    ],
    "link": "https://www.newyorker.com/magazine/1993/02/22/beverly-hills-hotel-paradise-lost",
    "first_paragraph": "Until just a few weeks ago, no American seemed on better terms with fortune than Irving V. Link, who had spent most of the past half century playing gin rummy by the side of the pool at the Beverly Hills Hotel, in Los Angeles. For forty-two years, from the time he discovered the hotel, in 1950, until it closed, last December 30th, Irving\u2019s days had been as well ordered and as predictable as the Sun King\u2019s. At seven o\u2019clock every morning, wearing one of the many perfectly fitted tropical-weight suits that have been a special affection of his since a memorable day in the nineteen-thirties, he would stroll over from his house, in the lower reaches of Beverly Hills; enter the hotel under the long, sloping green-and-white striped awning that extended all the way from the driveway, above Sunset Boulevard, to the main entrance; turn right in the lobby; and arrive at the Polo Lounge. Often he and the hostess, Bernice Philbin, would be the first two people there, and they would have a polite co"
  },
  {
    "title": "Cross Views (moultano.wordpress.com)",
    "points": 113,
    "submitter": "moultano",
    "submit_time": "2025-02-26T18:19:28 1740593968",
    "num_comments": 91,
    "comments_url": "https://news.ycombinator.com/item?id=43186413",
    "comments": [
      "I prefer wigglegrams. If you're looking for an example - Wikipedia page has one from 1927[1]![1]: https://en.wikipedia.org/wiki/Wiggle_stereoscopy\n \nreply",
      "Thank you! I have not, to this day, have been able to see any Magic Eye/Cross Eyed or similar images. A wigglegram is immediately trivial.I'd probably most appreciate a layout with one frame on the left, the wigglegram in the middle, and the other frame on the right, so that I can get a sense of both the distances and the detail.\n \nreply",
      "Was going to say the same thing. Presenting stereo pairs has a lot of layout and resolution issues to say nothing of the fact that some people have stereo blindness to varying degrees (lazy eye is an extreme case).\nThe author is correct that stereo depth can greatly enhance an image, but a wigglegram does this at full resolution with no visual puzzle solving.\n \nreply",
      "I'm slightly suspicious that this comment was written by a bird.\n \nreply",
      "Since the advent of models like Depth Anything, you can now convert 2D images into this effect using them plus a bit of creative processing. Here's a non-technical overview that plugs some software and talks about the underlying models: https://www.owl3d.com/blog/2d-to-stereoscopic-3d-with-ai-dep...Bonus, I also found this real-time 3D-ifier for your screen: https://github.com/zjkhurry/stereopsis-anything\n \nreply",
      "I had to, hopefully you don't mind moultano!Same content, but all lined up and rendered the whole article in cross-view.You can now read the article and see the pictures while in cross-view.https://jasonjmcghee.github.io/you-should-make-cross-views-3...\n \nreply",
      "Now just need to duplicate the mouse cursor to be in 3D too!I also had to shrink the window as I couldn't manage the cross view on a widescreen :)\n \nreply",
      "Clever!\n \nreply",
      "This is very common in structural biology papers, where you need to make figure of complex 3D arrangements of atoms, but the figures must be printed in 2D. Typically using molecular modeling software, you find your view of choice. Then you rotate +- 0.5\u00b0 and render two images, and put those side by side as a stereo pair figure.It takes quite a bit of practice to see them well:https://spdbv.unil.ch/TheMolecularLevel/0Help/StereoView.htm...\n \nreply",
      "Thanks for that! It is quite impressive and I learned to see the 3D molecule on first try.I remember seeing something similar, but made of an array of dots (you did not know what was behind the doors until you see it by crossing your eyes)\n \nreply"
    ],
    "link": "https://moultano.wordpress.com/2025/02/24/you-should-make-cross-views/",
    "first_paragraph": "Ryan Moulton's ArticlesYour camera has the ability to take three dimensional photos. Your screen has the ability to display three dimensional photos. You\u2019ve probably never used either. This isn\u2019t a hidden feature of some new phone hardware release, it\u2019s a feature of your brain. All your brain needs to see in 3D is two pictures, and you can trick your brain into seeing 3D on a flat screen using just your eye muscles. I will teach you how. I\u2019ll also tell you why you should.Around a third of your brain is devoted to vision, and accordingly, it is amazing at it. From just the two small 2D images that are sent to your brain from the backs of your eyeballs, your brain reconstructs the entire 3D scene that you experience when you look around. Because your eyes are a few inches apart, they see two different views of the same scene, and those two views are all your brain needs. Distance causes objects to shift relative to each other when you see them from different angles. You can see this most"
  },
  {
    "title": "Put a data center on the moon? (ieee.org)",
    "points": 47,
    "submitter": "pseudolus",
    "submit_time": "2025-02-26T20:20:39 1740601239",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=43187759",
    "comments": [
      "> Some parts of the moon are permanently shadowed and therefore extremely cold, as low as -173 \u00b0C. This means that no energy or water would need to be expended to cool the data center.That doesn't sound right to me. If there's no air, then only black body radiation can be used to cool the data center. That means a massive radiator, a lot larger than a heat-to-air radiator+fan used on earth.\n \nreply",
      "They've got it all figured out, you just don't understand. Basically, the plan is:1. Put data on the moon2. ???3. ProfitFor more info, check out their promotional video: https://www.lonestarlunar.com/video\n \nreply",
      "This is as big a scam or waste as those solar mirror people. Throwing a USB stick out the lunar rover window and calling it a data center. Data centers usually do stuff other than sit in the dust.Feel free to invest though, perhaps if you feel good about  discarding hard drives on the moon I could interest you in space mirrors and for a low low price I'll lease you the spot where your harddrive lands for 100 years.\n \nreply",
      "A 1 meter square heat exchanger in a vacuum at 20C will emit about 1 kilowatt at -173C. So about as much as a small space heater per small panel. So a 1 megawatt datacenter would need about 300,000m^2 or 0.3 km^2 of surface area to cool it.But geothermal cooling would be great on the moon too. Run a pipe 2 meters under the lunar surface and it is -21C.I think the whole idea though is to make a low wattage space-stead so you can store copies of Moana out of reach of Disney cease and desist letters.\n \nreply",
      "> But geothermal cooling would be great on the moon too. Run a pipe 2 meters under the lunar surface and it is -21C.Isn't the moon geologically dead though - no water or geological movements?I worry this would just result in the ground absorbing the waste heat and eventually becoming too warm to effectively cool anything.  Especially because the ground itself would eventually still be limited by the rate of radiative cooling into space, right?\n \nreply",
      "You have to worry about changing the ground temperature even on earth FYI. When designing district heating/cooling systems with borehole fields, one of the things that you check for is to make sure that you don\u2019t inject too heat (or extract too much) seasonally - ideally it\u2019s roughly balanced so any drift year over year is small.Obviously things like the diffusivity (so conductivity, mass, density etc) of the ground matter a lot, as does the rate of heat exchange at the surface for it to reject (or absorb) heat to the environment.\n \nreply",
      "Right, I'm roughly aware that's a concern on Earth too which is why I was wondering.  How's the thermal conductivity of the moon?\n \nreply",
      "Looked up some papers, and seemingly super low compared to what I would have initially guessed - probably because it\u2019s porous/fluffy/sharp dust with lots of small voids/less compacted I\u2019m guessing. Like, orders of magnitude less than the ground on earth. Not my area of expertise though and was just cursorily skimming papers for values. Specific heat cap and density seem like what you would expect for any rocky materials.\n \nreply",
      "> geothermal cooling would be great on the moonSurely it's selenthermal cooling at that point.\n \nreply",
      "Conduction through the ground? Or run coolant through buried pipes. Just a pump; no significant energy to cool, just move the coolant.\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/data-center-on-the-moon",
    "first_paragraph": "Lonestar Data Holdings is sending a test mission, aiming to safeguard valuable data Dina Genkina is the computing and hardware editor at IEEE SpectrumLonestar's Freedom Data Center payload sits onboard Intuitive Machines' Athena lander for IM-2 before takeoff.Tomorrow, 26 February, SpaceX will launch a Falcon 9 rocket carrying an Intuitive Machines mission that will stay on the surface of the moon for approximately three weeks before returning to Earth. Among other things, the Intuitive Machines lander contains a mini data center, massing just 1 kilogram and containing 8 terabytes of SSD storage. This belongs to Lonestar Data Holdings and is part of a proof-of-concept mission meant to bring moon-based data centers closer to reality. The idea of putting a data center on the moon raises a natural question: Why? Lonestar\u2019s CEO Christopher Stott says it is to protect sensitive data from Earthly hazards.\u201cData centers, right? They\u2019re like modern cathedrals. We\u2019re building these things, they "
  },
  {
    "title": "Photographs of the Old West (cosmographia.substack.com)",
    "points": 97,
    "submitter": "merothwell",
    "submit_time": "2025-02-26T18:09:39 1740593379",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43186301",
    "comments": [
      "That\u2019s so sad that the vast majority of his photos were lost to the 1906 SF earthquake. Amazing photos that were preserved though.\n \nreply",
      "Just a warning, there's a fair number of nude children in these photos, may not want to open at work\n \nreply",
      "Sad but true. Normal is obscene now.\n \nreply",
      "It felt like I was there, in my head, for a brief and beautiful moment of time. What an incredible set of photos.\n \nreply",
      "There are Hopi people in those photos?.. advanced culture\n \nreply"
    ],
    "link": "https://cosmographia.substack.com/p/photographs-of-the-old-west",
    "first_paragraph": ""
  },
  {
    "title": "DARPA Large Bio-Mechanical Space Structures (sam.gov)",
    "points": 127,
    "submitter": "jfantl",
    "submit_time": "2025-02-26T17:19:29 1740590369",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=43185769",
    "comments": [
      "When reading these program announcements, it's important to keep in mind that the (unofficial?) mandate for a DARPA program officer is to fund proposals that lie in the boundaries of [Doesn't at face violate laws of physics, P(Success) = 0.2]. A program where the vast majority of aims were clearly successfully delivered would be a program that should have been funded by other government agencies.Of course, with R&D currently on the chopping block, we'll see if the same people that complain about NSF/NIH start coming for DARPA also...\n \nreply",
      "My reference point, the DARPA self driving challenge was in 2004. AlexNet was a sea change in image processing, which did not happen for another eight years.\n \nreply",
      "If they come for DARPA then we are all in deep shit because that means things are far worse than we could have imagined.\n \nreply",
      "In the words of Han Solo \u201cI don\u2019t know I can imagine quite a bit.\u201d\n \nreply",
      "like even more far-worse than the current far-worse?\n \nreply",
      "Things already are that bad, you\u2019re standing an inch beyond where the previous wave washed up to and saying \u201cwell if it gets here in the next few waves then suddenly we become in deep shit\u2019 while all around people are shouting at you about the existence of a concept called \u2018the tide\u2019. This is happening right now. fight back.\n \nreply",
      "> When reading these program announcements,I think DARPA projects often are not what they say they are. Admittedly this project is quite out there.> P(Success) = 0.2They themselves admit it's lower than this, which is not 'success' but successful outcomes to limited specs.\n \nreply",
      "Yeah, wouldn\u2019t P(success) = 0.2 be pretty fantastic for any highly experimental/speculative/moonshot research entity?\n \nreply",
      "I saw this at a DSO* presentation (\"Darpa's Darpa\") back in ~2018. Hope they've gotten some early traction, that was some of the least wild crap that was being presented.My company was pitching holographic cameras, and we weren't scifi enough. The investigator wanted to know if we could do hyperspectral 3D imaging from something the size of a sugar cube. (\"Uh, no?\" was our response.)* Defense Sciences Organization: https://www.darpa.mil/about/offices/dso\n \nreply",
      "> Seeing (sensing) the unseenI'm reading this as a soft signal that there's still a market for marinating wizards in salty brine.https://en.wikipedia.org/wiki/Stargate_Project_(U.S._Army_un...\n \nreply"
    ],
    "link": "https://sam.gov/opp/49c9fac62ef249f19cda8b436a095d3b/view",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Breakout with a roguelite/vampire survivor twist (lecaro.me)",
    "points": 233,
    "submitter": "lecarore",
    "submit_time": "2025-02-26T12:42:35 1740573755",
    "num_comments": 115,
    "comments_url": "https://news.ycombinator.com/item?id=43183131",
    "comments": [
      "Nice, I like the perk system. Played a few rounds. Quick thoughts:At first I didn't know that the coins were coins, it just looked like brick particles for visual effect. Maybe having a current coin counter or visual difference would've helped.Speaking of coins, there's a couple times when the ball and coins were too similar in color, making it hard to find the ball amid a mass of falling coins. Maybe this is by design, but some contrast between coin color and the ball would help.\n \nreply",
      "Both valid points. I colored the coins for two reasons : they are pretty and the perk \"coins stain bricks\" means that if a red coin hits a blue brick, that brick becomes blue (which helps with other perks like \"picky eater\" and \"color pierce\"). I think there could be a short text that changes once you perform the action, so \"click to start\", \"catch the ball\", \"catch the coins for score\", and \"clear all bricks\", then it would be gone once you finish the first level.\n \nreply",
      "The game is great and clearly a lot of thought has gone into polishing! CongratsFWIW it also took me a couple of levels to even realize how I was getting coins. A yellow glow around the coins or some shiny effect + clinky sounds would go a long way. The -2 +2 etc. callout numbers could also last longer on the page and just grow in size as they fade out? They were also quite hard to spot\n \nreply",
      "The -1 numbers are when your coin multiplier drops, that part isn't really explained or intuitive.  i'm not even sure of how to call it. It's the number of coins that will spawn when you break a brick, and is displayed on your puck. I guess if i displayed \" 2 x \" on the puck and made coins look like coins, everything would be a bit easier to understand.\n \nreply",
      "I rather enjoyed that I got to make the discovery that the particles were coins, moreover, I enjoyed dropping STRAIGHT into the game without having to read anything or press any buttons. Lastly, this worked flawlessly on my iPhone, bravo to the work you did to make that happen!\n \nreply",
      "Thank you. Making coins looks like coins doesn't require adding text, so i'll definitely do that. And yeah, it's not so easy to convey upgrades effect without text, but at the same time at that point you kind of want a bit of rest so reading is ok. I really dislike game that take forever to load and show pointless menus before letting you play.\n \nreply",
      "I had this same thought; maybe just CSS to make them glow / glint a little? Or make the edges golden? I agree there could be a bit of juice on the coins. Or possibly the noise could be a little more clink/coinish.\n \nreply",
      "Yes, i'll make coins look like coins, sound like them, and roll around. Then if you pick the \"coins stain bricks\" perk, they'll be colored like before, but by then you should already know what they are.\n \nreply",
      "Yes. Coins should all be gold and spin on edge (so they don't present as just circles). Colored halo or trail can match the origin brick color.\n \nreply",
      "Yes, will do, this is definitely the top thing to change\n \nreply"
    ],
    "link": "https://breakout.lecaro.me/",
    "first_paragraph": ""
  },
  {
    "title": "ForeverVM: Run AI-generated code in stateful sandboxes that run forever (forevervm.com)",
    "points": 115,
    "submitter": "paulgb",
    "submit_time": "2025-02-26T15:41:44 1740584504",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=43184686",
    "comments": [
      "I tried to do this myself about ~1.5 years ago, but ran into issues with capturing state for sockets and open files (which started to show up when using some data science packages, jupyter widgets, etc.)What are some of the edge cases where ForeverVM works and doesn't work? I don't see anything in the documentation about installing new packages, do you pre-bake what is available, and how can you see what libraries are available?I do like that it seems the ForeverVM REPL also captures the state of the local drive (eg. can open a file, write to it, and then read from it).For context on what I've tried: I used CRIU[1] to make the dumps of the process state and then would reload them. It worked for basic things, but ran into the issues stated above and abandoned the project. (I was trying to create a stack / undo context for REPLs that LLMs could use, since they often put themselves into bad states, and reverting to previous states seemed useful). If I remember correctly, I also ran into issues because capturing the various outputs (ipython capture_output concepts) proved to be difficult outside of a jupyter environment, and jupyter environments themselves were even harder to snapshot. In the end I settled for ephemeral but still real-server jupyter kernels where I via wrapper managed locals() and globals() as a cache, and would re-execute commands in order to rebuild state after the server restarts / crashes. This allowed me to also pip install new packages as well, so it proved more useful than simply static building my image/environment. But, I did lose the \"serialization\" property of the machine state, which was something I wanted.That said, even though I personally abanonded the project, I still hold onto the dream of a full Tree/Graph of VMs (where each edge is code that is executed), and each VM state can be analyzed (files, memory, etc.). Love what ForeverVM is doing and the early promise here.[1] https://criu.org/Main_Page\n \nreply",
      "Good insight! We also initially tried to use Jupyter as a base but found that it had too much complexity (like the widgets you mention) for what we were trying to do and settled on something closer to a vanilla Python repl. This really simplified a lot.We've generally prioritized edge case handling based on patterns we see come up in LLM-generated code. A nice thing we've found is that LLM-generated code doesn't usually try to hold network connections or file handles across invocations of the code interpreter, so even though we don't (currently) handle those it tends not to matter. We haven't provided an official list of libraries yet because we are actively working on arbitrary pypi imports which will make our pre-selected list obsolete.> Love what ForeverVM is doing and the early promise here.Thank you! Always means a lot from someone who has built in the same area.\n \nreply",
      "> I was trying to create a stack / undo context for REPLs that LLMs could use, since they often put themselves into bad states, and reverting to previous states seemed usefulThis is interesting! How did you end up achieving this? What tools are available for rolling back LLMs doing?\n \nreply",
      "I love this. Congrats on the launch. You all are always building something interesting\n \nreply",
      "Is it possible to reuse the same paused VM multiple times from the same snapshot?\n \nreply",
      "It's not exposed in the API yet, but it's very possible with the architecture and something we plan to expose. I am curious if you have a use case for that, because I've been looking for use cases! Being able to fork the chat and try different things in parallel is the motivating use case in my mind, but I'm sure there are others.\n \nreply",
      "The obvious use-case (to me) is to create an agent that relies on an interpreter with a bunch of pre-loaded state that's already been set up exactly a certain way \u2014 where that state would require a lot of initial CPU time (resulting in seconds/minutes of additional time-to-first-response latency), if it was something that had to run as an \"on boot\" step on each agent invocation.Compare/contrast: the Smalltalk software distribution model, where rather than shipping a VM + a bunch of code that gets bootstrapped into that VM every time you run it, you ship an application (or more like, a virtual appliance) as a VM with a snapshot process-memory image wherein the VM has already preloaded that code [and its runtime!] and is \"fully ready\" to execute that code with no further work. (Or maybe \u2014 in the case of server software \u2014 it's already executing that code!)\n \nreply",
      "Main use case for me would be RLAIF. Given a prompt, generation, and a code execution result - rank N alternative executions and execution results for DPO/other training patterns.In complex use cases like building a bi engineer, it\u2019s useful to persist state across multiple function calls within the same interpreter.\n \nreply",
      "Check out why Togerther.AI acquired CodeSandbox.\n \nreply",
      "Disclosure, I\u2019m an investor in Jamsocket, the company behind this\u2026 but I\u2019d be remiss if I didn\u2019t say that every time Paul and Taylor launch something they have been working on, I end up saying \u201cwoah.\u201d In particular, using ForeverVM with Clause is so fun.\n \nreply"
    ],
    "link": "https://forevervm.com/",
    "first_paragraph": "\nSecurely run AI-generated code in stateful sandboxes that run forever.\n\nForeverVM is a code execution API that allows you to securely run arbitrary Python code in a\n        remote sandbox and get back results.\n\nUnlike traditional code interpreters, ForeverVM does not have a concept of a  session after which state expires. Instead, ForeverVM uses memory snapshots to swap\n        idle machines to disk for as long as you want. This improves scalability and resource usage,\n        and means that applications and agents built on ForeverVM don't have to manage session lifecycles.\n\nOnce you have created a ForeverVM machine, you can interact with it through a REPL (read-eval-print loop) interface. ForeverVM will assign the machine to an available worker while it is actively\n        in use.\n\nWhen a sandbox is idle, its memory is snapshotted before it is \u201cdetached\u201d from the\n            worker.\n\nAs long as the sandbox remains inactive, it only consumes storage space, not compute or\n            m"
  },
  {
    "title": "Simulating Time in Square-Root Space (weizmann.ac.il)",
    "points": 10,
    "submitter": "EvgeniyZh",
    "submit_time": "2025-02-25T07:11:03 1740467463",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://eccc.weizmann.ac.il/report/2025/017/",
    "first_paragraph": "Under the auspices of the Computational Complexity Foundation (CCF)We show that for all functions $t(n) \\geq n$, every multitape Turing machine running in time $t$ can be simulated in space only $O(\\sqrt{t \\log t})$. This is a substantial improvement over Hopcroft, Paul, and Valiant's simulation of time $t$ in $O(t/\\log t)$ space from 50 years ago [FOCS 1975, JACM 1977]. Among other results, our simulation implies that bounded fan-in circuits of size $s$ can be evaluated on any input in only $\\sqrt{s} \\cdot poly(\\log s)$ space, and that there are explicit problems solvable in $O(n)$ space which require $n^{2-\\varepsilon}$ time on a multitape Turing machine for all $\\varepsilon > 0$, thereby making a little progress on the $P$ versus $PSPACE$ problem.Our simulation reduces the problem of simulating time-bounded multitape Turing machines to a series of implicitly-defined Tree Evaluation instances with nice parameters, leveraging the remarkable space-efficient algorithm for Tree Evaluatio"
  },
  {
    "title": "Writing a .NET Garbage Collector in C# \u2013 Part 1 (minidump.net)",
    "points": 26,
    "submitter": "mooreds",
    "submit_time": "2025-02-24T13:28:40 1740403720",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43159314",
    "comments": [
      "I'm very much looking up to NativeAOT on C#, being able to compile to native dlls is very attractive to me, as I'd love to do (offline) game modding. \nI currently use Rust and it works quite well, but it's never too late to wish for a more 'forgiving' language for smaller projects!\n \nreply",
      "Interesting. You and I are reasonably adjacent it seems like. I've been cooking up a pleasant way to enable modding support in games I make.I have this idea in my head that I want this system to work even all the way up to letting people host their own servers that run their own mods without allowing them the power to do nefarious things to the clients who connect. This means a scripting language layer, most commonly LUA. For a bunch of reasons, many are vibes based, I've decided to go with a lisp instead.After doing a bit of research I found this repo to use as a starting point.https://github.com/microsoft/schemyChecks all my boxes. Big ones being no new dependencies and not many lines of code. It took just a few minutes to get a handle on the whole thing end-to-end. I'm working right now on setting a little reflection metaprogramming that would expose any functions that I put an attribute above to the lisp layer.There's a few things to delete so it's safe to serialize over the wire, but it looks like it'll enable what I'm after. I hope I can trust my serializers :DWhat kinds of mods do you want to make?\n \nreply"
    ],
    "link": "https://minidump.net/2025-28-01-writing-a-net-gc-in-c-part-1/",
    "first_paragraph": ""
  },
  {
    "title": "Geometric Algebra (bivector.net)",
    "points": 7,
    "submitter": "agnishom",
    "submit_time": "2025-02-26T23:54:17 1740614057",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://bivector.net/",
    "first_paragraph": "for CGI, Vision and EngineeringCourses, PapersLibraries, CodeCheat-sheets, ToolsQuestions, AnswersGeometric Products\r\n\t\t\t\t        Clifford's Geometric Algebra enables a unified, intuitive and fresh perspective\r\n\t\t\t\t        on vector spaces, giving elements of arbitrary dimensionality a natural home.\r\n\t\t\t\t        \r\n\t\t\t\t\t\t\tThe Vector is an oriented, one dimensional\r\n\t\t\t\t\t\t\tquantity. Two $\\parallel$ Vectors multiply to a Scalar ($\\mathbb R$).\r\n\t\t\t\t\t\t\tTwo $\\perp$ vectors anti-commute ($e_1e_2=-e_2e_1$)\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\t\t\tThe Bivector is an oriented, two dimensional\r\n\t\t\t\t\t\t\tquantity. Bivectors naturally represent transformations.\r\n\t\t\t\t\t\t\tSimilarly, $n$ vectors combine into an $n$-vector.\r\n\t\t\t\t\t\t\t\r\n\t\t\t\t\tThe $n$-dimensional geometric algebra $\\mathbb R_{p,q,r}$ is constructed\r\n\t\t\t\t\tfrom $p$ positive, $q$ negative and $r$ null vectors\r\n\t\t\t\t\tcalled generators, written $\\bf e_i$  \r\n\t\t\t\t\t\r\n\t\t\t\t\t\t\tThe Scalars $\\mathbb R$ are included in \r\n\t\t\t\t\t\t\tthe algebras. every basis $n$-vector squares\r\n\t\t\t\t\t\t\tt"
  },
  {
    "title": "The FFT Strikes Back: An Efficient Alternative to Self-Attention (arxiv.org)",
    "points": 355,
    "submitter": "iNic",
    "submit_time": "2025-02-26T09:57:23 1740563843",
    "num_comments": 134,
    "comments_url": "https://news.ycombinator.com/item?id=43182325",
    "comments": [
      "Basically leverages convolution theorem[0]: expensive convolutions in direct space becomes simple multiplications in reciprocal space, and vice versa.Whereever you have a convolution operation on your data, transform them to the conjugate domain to turn it into multiplication.In other words, work in the domain that is natural to your data.[0] https://en.wikipedia.org/wiki/Convolution_theorem\n \nreply",
      "this is a great way to put it, that said, it was not obvious to me that the attention space (how it is structured in LLMs) is a frequency domain\n \nreply",
      "A cartoon:To form a coherent idea you need to coordinate a lot of tokens.  In other words, ideas are long-distance correlations between tokens.  Ideas are the long-wavelength features of streams of tokens.Is it exactly right? No.  But as a cartoon it can motivate exploring an idea like this.\n \nreply",
      "This is really a very interesting way of visualizing it.\n \nreply",
      "Right. This makes sense. But why Fourier space in particular. Why not, for example, a wavelet transform.\n \nreply",
      "Now you\u2019re talking efficiency\u2014-certainly a wavelet transform may also work.  But wavelets tend to be more localized than FTs.\n \nreply",
      "> Why not, for example, a wavelet transform.That is a great idea for a paper. Work on it, write it up and please be sure to put my name down as a co-author ;-)\n \nreply",
      "I like this. Anything that connects new synapses in my skull via analogy is a good post.\n \nreply",
      "Exactly.  Exploiting the structure of the matrix (e.g., it is well approximated by a circulant matrix) is natural if there is structure to exploit.  If everything in the preprint holds up, that might suggest some symmetries (e.g., approximate stationarity in time) in the data at hand.\n \nreply",
      "> In other words, work in the domain that is natural to your data.Why would multiplication be more \"natural\" to a domain than convolution, as opposed to just simpler to calculate?\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2502.18394",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "A new proposal for how mind emerges from matter (noemamag.com)",
    "points": 91,
    "submitter": "Hooke",
    "submit_time": "2025-02-26T07:27:50 1740554870",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=43181520",
    "comments": [
      "Articles like this annoy me: it seems to want to comment on philosophy of mind, but shows zero awareness of the classic debates in that discipline - materialism vs idealism vs dualism vs neutral monism, and the competing versions of each of those, e.g. substance dualism vs hylemorphic dualism, eliminativist vs reductionist/emergentist materialism, property dualism, epiphenomenalism, panpsychism, Chalmers\u2019 distinctions between different idealisms, such as realist vs anti-realist and micro-idealism vs macro-idealism\u2026Add to that the typical journalistic fault of forcing one to read through paragraph after paragraph of narrative before actually explaining what the thesis they are presenting is. I\u2019d much prefer to read a journal article where they state their central thesis upfront\n \nreply",
      "As a linguist, article like this also annoy me by the claims that \"X [whales, dolphins, parrots, crows...] uses language.\"  We have known since 1957 that there is a hierarchy of \"grammars\", with finite state \"languages\" being near the bottom, and transformational grammars at the top.  Human languages are certainly at a minimum at the context free phrase structure grammar level.  My point is that by using the word \"language\" loosely, almost anything (DNA codons, for example) can be considered to be a language.  But few if any other animals can get past the finite state level--and perhaps none gets even that far.And an article or book that uses the word \"communicate\" is even more annoying, since \"communicate\" seems to mean virtually anything.End of my rant...\n \nreply",
      "I bailed 10 words in and came to the comments to see if the article was worth reading. Thanks for confirming its a skip.\n \nreply",
      "Maybe the definition of what \"intelligence\" is could be sharpened by having a look at LLMs and \"traditional\" computer programs and asking what exactly the difference between the two is.Almost all the traditional criteria of intelligence - reasoning, planning, decisionmaking, memory etc - are exhibited pretty trivially by standard computer programs. Nevertheless no one would think of them as \"intelligent\" in the sense that humans or animals are.On the other hand, we now have LLMs, that sent the entire tech world into a multi-year frenzy, precisely because they appear to possess that human-like intelligence.And that is even though they perform worse than classical programs in some of the \"intelligence\" measures: For the first time, we have to worry that a computer program is \"bad at math\". They cannot reflect on past decisions and are physically unable to store long-term memories. And yet, we're much more likely to believe that an LLM is \"intelligent\" than a classical program.This makes me think that our formal decisions of \"intelligence\" (the ones that would also qualify fungal networks, swarms, cells, societies, etc) and what we intuitively look out for, are really two different things.\n \nreply",
      ">This makes me think that our formal [definitions] of \"intelligence\" [\u2026] and what we intuitively look out for, are really two different things.Just two? You can name so many more terms in this concept cloud, e.g.: personhood, moral agency, consciousness, self-awareness, processing power, wit, autonomy, feeling-and-experiencing capacity,  and so on\u2026 We don\u2019t seem to agree on what\u2019s separate from what, and yes, it would be useful.\n \nreply",
      "intelligence is a property of the species and the property of the individual, even unintelligent individuals (except for very pronounced extremes) still have the species property of intelligence.The species property of intelligence encompasses stupidity.\n \nreply",
      "I wouldn't say that's true at all for traditional computer programs. They're doing explicitly what they are designed to do, there is no adaptation/learning.\n \nreply",
      "How do you define adaptation and learning? What about say, an autoscaler which is programmed to just track the the load for every hour over the last week, and use the average of the last 7 days at 8am to pre-emptively auto-scale? Is that learning and adapting?Alternatively, neural networks are also just doing explicitly what they are designed to do\u2026 sure there is a larger computational graph with lots of operations, but it\u2019s all deterministic\u2026 backprop is not really much different on a procedural level than the simple fitting algorithm that I outlined above, in as much as it is just a specific well-defined algorithm or sequence of steps designed to compute some parameters from data.\n \nreply",
      "Code vs. data.The code needed create, train, and perform inference on a Transformer is quite short. How short depends on how you count the `import` statements in https://github.com/openai/gpt-2/blob/master/src/model.py and https://github.com/openai/gpt-2/blob/master/src/sample.py etc.Spreadsheets performing linear regression etc., \u2014 Do they learn? Sure!If you accept that Transformers adapt and learn then you must accept that a spreadsheet also does, because someone implemented GPT-2 in Excel: https://github.com/ianand/spreadsheets-are-all-you-needDo polymorphic computer viruses adapt? Border Gateway Protocol? Exponential backoff? Autocomplete? And that's aside from any algorithmic search results or \"social\" feeds, which are nothing but that.\n \nreply",
      "I am confused, a spreadsheet running the code for what a neural network does, sure. But a traditional computer program isn't just excel.\n \nreply"
    ],
    "link": "https://www.noemamag.com/a-radical-new-proposal-for-how-mind-emerges-from-matter/",
    "first_paragraph": ""
  }
]