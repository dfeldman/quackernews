[
  {
    "title": "Visual Basic 6 IDE recreated in C# (github.com/bandysc)",
    "points": 136,
    "submitter": "porterde",
    "submit_time": "2024-11-14T21:47:54 1731620874",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=42141587",
    "comments": [
      "Man, that 1995-2001 era Windows UI was like, peak Windows.It was so crisp and clean. Visual C++ and Visual Basic of the time were far from perfect, but they let you just get things done(tm)XP was right around the corner and it's been downhill from there.\n \nreply",
      "It's an awesomely inspirational vision, but within 2 minutes of trying it out I found it's lacking a lot of little features (at least on the web build)...  e.g:Ampersands in button labels don't create an accelerator (e.g. &Go does not underline the G).In true VB6 you could plop down a Label control and just start typing to change it's contents.  Here you have to focus on the input field first (and you can't just click the \"Caption\" heading, you have to click within the input column).  To maintain fidelity, one of the rows in the Properties grid should always be highlighted when a control is selected on the GUI designer (for Labels this defaulted to Caption, and I believe for controls without a specified default it defaulted to Name).When switching to a different control with a property matching the name of the currently selected one, VB6 would maintain the selection on that property.  This made it quick and easy to update for example the Tag property a bunch of controls in sequence with minimal clicks.Obviously the menus for Debugging, Save, Help, Add-ins, etc. are missing implementation.A working Build button that spits out an \"exectuable\" that runs in the browser would be killer!My nitpicks are born out of love ;-).\n \nreply",
      "> Ampersands in button labels don't create an acceleratorThis is a feature of the Windows common controls, not anything VB specific, so perhaps why it was missed.\n \nreply",
      "Nonetheless, a critical part of mimicking the VB6 developer experience.\n \nreply",
      "Certainly, not going to argue that.\n \nreply",
      "Oh my GOD I have to comment. This is how I learned to program as a kid.I found a copy of \"Write Your Own Adventure Programs\" (1983 - Usborne: https://colorcomputerarchive.com/repo/Documents/Books/Write%...) as a kid in my primary school's bookshelf. I remember the code was written in BASIC and my family didn't really own a computer back then.Fast forward a few years later I saw this \"Visual Basic\" thing and thought it would be similar ... it was, but only sort of. I had no book to learn from at first so I remember clicking through every single menu and button available to see what it did. Then I remember using our dialup to download every possible 3rd party VB form control and throwing them in a Form to see what they did. I don't know why I found this entertaining enough to keep doing it.Eventually by copy pasting and changing stuff I was able to write some basic \"homework helper\" programs: calculate the area of a circle and stuff like that. Soon after I tried to look up tutorials which taught me basic win32 programming to do things like have an icon in the status area next to the clock, and then hiding my window to run in the background and make annoying sounds so I could build a silly little prank program to install on my friend's computers which was fun but often would fail because they were missing some .dll file which wouldn't fit on the same floppy.It could be frustrating at times but also I feel so blessed to have lucked myself into learning programming this way and my parents pretty much just letting me do whatever I wanted to this expensive device that probably was not a small thing for us to afford at the time.Even tutorials felt more fun at the time, it'd be \"hypnoMan37's windows registry tutorial!!! HEyyeyeyy Guuyzs :-)))) gzgzgz to my irc channel #blabla on EFNet! so first you call RegistryCreateNewKey32(....\" because god knows I did not have an MSDN CD either.Learning via a code camp feels way more efficient but also so much more dry in comparison. I wonder if there isn't a substantial cost to boring the newbies to death.\n \nreply",
      "> Then I remember using our dialup to download every possible 3rd party VB form control and throwing them in a Form to see what they did. I don't know why I found this entertaining enough to keep doing it.Wow, that takes me back.  My local library also had a copy of \"Visual Basic How-To: The Definitive Vb3 Problem Solver\" and at some point I'd renewed my loan of it so many times they told me I couldn't anymore.  I remember building a working interface based on the \"Peanut Computer\" interface from the beginning of _Out of this World_.\n \nreply",
      "Ah those custom controls. Everything I wrote as a kid was beveled to the max.  Good times.\n \nreply",
      "This!I want my kids to do the same but are really unclear as to how this is done today without BASIC. I am not psyched about tools that help you merely build platformers with WYSIWYG.Any ideas?\n \nreply",
      "Esp32 with micropython?\n \nreply"
    ],
    "link": "https://github.com/BAndysc/AvaloniaVisualBasic6",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A recreation of the classic Visual Basic 6 IDE and language in C# with Avalonia\n      A recreation of the classic Visual Basic 6 IDE and language in C# using Avalonia.This is a fun, toy project with no commercial intent. All rights to the Visual Basic name, icons, and graphics belong to Microsoft Corporation.You'll generally need .NET 9.0, though you can modify Directory.Build.props to use .NET 8.0 if preferred (version 9.0 is required for the browser version).To build, simply run:If you encounter Antlr4 errors, this likely means the Antlr4BuildTasks library couldn't automatically download Java. Installing Java manually should resolve the issue.Publish both IDE project (AvaloniaVisualBasic.Desktop) and runtime (AvaloniaVisualBasic.Standalone):Now you can run ./bin/AvaloniaVisualBasic.Desktop.\n        A recreation of the classic Visu"
  },
  {
    "title": "MomBoard: E-ink display for a parent with amnesia (miksovsky.com)",
    "points": 1187,
    "submitter": "pabs3",
    "submit_time": "2024-11-14T12:20:40 1731586840",
    "num_comments": 146,
    "comments_url": "https://news.ycombinator.com/item?id=42135520",
    "comments": [
      "This is one of the few HN articles that have profoundly moved me. Such a beautiful and simple use of technology to make a clear and big improvement in someone's life.As a side note on his mother remembering that the tablet exists, it sounds like she has amnesia quite like Henry Molaison, a famous case study in neuropathology. He had very specific brain damage that seemingly stopped him forming new memories in the same way as OP's mother, but studies showed that he could remember some things, just not consciously. So for example he would have warm feelings towards people who'd been caring for him despite not remembering them, and would also pick up card games more and more quickly as he played them repeatedly despite saying he didn't remember the game. OP's mother remembering the tablet sounds very similar, particularly when paired with the feeling of being remembered and loved by her children.\n \nreply",
      "> but studies showed that he could remember some things, just not consciously.This reminds me of muscle memory. I can play pieces on the piano even though I don't actively remember the sheet music of them. My hands just \"know\" what to do. Funnily enough the moment I start actively thinking about certain passages that ability worsens by a lot.\n \nreply",
      "It's exactly the same when solving Rubik's Cubes.At the start it's all about carrying around notes full of picking the relevant condition depending on the current permutation/state of the cube then following the step by step algorithms on which sequence of steps to perform for that condition.Then you'll naturally realise that certain conditions happen a lot more than others and you'll start to remember the sequence of letters for each series of steps to perform.Over time you'll forget the letters and your fingers will just know the sequence to perform when you perceive that condition, kind of like typing a password without thinking about it.Eventually you'll be able to fit each condition and algorithm into your muscle memory and completely forget the series of letters that you used to memorise.Now I can barely explain how to solve a rubik's cube in-person. I just do it.\n \nreply",
      "Yes same for me on guitar. If I try to play something too slowly or if I really start thinking about what I'm doing it all falls apart.I think that's when you really know a piece, when you can play it incredibly slowly. Paradoxically it's easy to play quickly and just let your fingers play out their muscle memory, playing something really slowly is the challenge.\n \nreply",
      "I ran into this when teaching my son to tie his shoes. He now ties his shoes \u201cupside down\u201d from me, because I tied it from my perspective. It\u2019s surprisingly hard to tie shoes in slow motion, it took some practice by paying attention to myself tying shoes quickly.Now I\u2019m wondering if you can tell a kid is from an \u201ceven\u201d or \u201codd\u201d generation by which way they tie shoes\u2026\n \nreply",
      "My kid just figured it out, so generation parity can break\n \nreply",
      "It's like UK coins the new monarch face stamped on it faces the opposite direction compared to the previous one.\n \nreply",
      "My dad's left-handed and I'm right-handed, so I got to learn to tie in mirror image. That was helpful.\n \nreply",
      "Passwords also work this way.\n \nreply",
      "I remember a lecturer in undergrad psychology talking about this in the context of walking, and my walking felt really messy for a week, like when you start to become conscious of your breathing.\n \nreply"
    ],
    "link": "https://jan.miksovsky.com/posts/2024/11-12-momboard",
    "first_paragraph": "November 12, 2024Today marks two years since I first set up an e-ink display in my mom\u2019s apartment to help her live on her own with amnesia. The display has worked extremely well during those two years, so I\u2019m sharing the basic set-up in case others find it useful for similar situations.Note: unless you have specific experience caring for someone who has amnesia but not dementia, please do not offer care suggestions.In June 2022 the side-effects of a long surgery left my mom with permanent anterograde amnesia: she can no longer form new long-term memories. Memory isn\u2019t just one neurological system, so very occasionally she will able to remember certain types of things. But for the most part, if she hears or sees something, a few minutes later she will no longer remember it.To medical professionals her condition looks a lot like dementia \u2014 amnesia is a common symptom of dementia \u2014 but she doesn\u2019t have dementia. One difference is that (as I understand it) dementia is a progressive diseas"
  },
  {
    "title": "The letter \u2118: name and origin? (2017) (mathoverflow.net)",
    "points": 187,
    "submitter": "IdealeZahlen",
    "submit_time": "2024-11-14T16:28:30 1731601710",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=42137818",
    "comments": [
      "One thing I've always struggled with Math is keeping track of symbols I don't know the name of yet.Googling for \"Math squiggle that looks like a cursive P\" is not a very elegant or convenient way of learning new symbol names.I wish every proof or equation came with a little table that gave the English pronunciation and some context for each symbol used.It would make it a lot easier to look up tutorials & ask questions.\n \nreply",
      "As a first foot-hold I recommend highly \nhttps://detexify.kirelabs.org/classify.html(I think I saw there was a newer one, but don't remember how)You draw the symbol and get the TeX symbol name. I tried this one and it does give the right \\wp (which in this case is confusing and you'd have to look up more about why it's named that)But for classic ones, for instance the \"upside down A\" -> \"forall\" is very helpful and shakes newcomers to math syntax\n \nreply",
      "Feynman said that his students struggled with a reverse problem: how to know that \"harnew\", an important part in QM equations that the lecturer talks about, actually stands for h\u03bd.\n \nreply",
      "This is great, thank you! Would be even better if it had a little \"click here to hear it said out loud\" button.\n \nreply",
      "See also: <https://shapecatcher.com/>\n \nreply",
      "I can relate. Ages ago, before Safe Search and search result tailored to one\u2018s history and preferences, I was trying to figure out how to write that big union symbol (\u222a) in LaTeX and googled for Big Cup LaTeX. \nI got _very_ different and unexpected results.\n \nreply",
      "Googling guitar-related stuff is how I learned there\u2019s such a thing as c-string women\u2019s underwear & bathing suit bottoms, not just g-strings.That was, briefly, a real WTF moment.[edit] oh my god, of course that one didn\u2019t come from searching guitar topics, that makes no sense given the standard tuning. I\u2019m pretty sure I was googling strings in the C language when I hit that one, lol. I did probably accidentally land on \u201cg string\u201d after searching without thinking about what would obviously come up, when looking up guitar topics, and must have combined the two incidents in my memory.\n \nreply",
      "Haha - my favourite WTF Googling moment was when, as a callow youth first setting out in learning Javascript and HTML, I Googled \"How to get head\"\n \nreply",
      "This reminds me of the time when searching for \u201cc string\u201d would probably result in \u201cThe C Programming Language\u201d at number 1.\n \nreply",
      "That\u2019s what I get right now\n \nreply"
    ],
    "link": "https://mathoverflow.net/questions/278130/the-letter-wp-name-origin",
    "first_paragraph": ""
  },
  {
    "title": "In Memoriam: Thomas E. Kurtz, 1928\u20132024 (computerhistory.org)",
    "points": 57,
    "submitter": "1986",
    "submit_time": "2024-11-14T22:12:09 1731622329",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42141761",
    "comments": [
      "Like several others here, my first programming language was BASIC. For this we owe Kurtz a debt of gratitude.I know Dijkstra is famous for having said that we're mentally mutilated beyond hope of regeneration, but you know, I kinda think we didn't turn out half bad.\n \nreply",
      "I know literally zero working programmers who learned programming the way Dijkstra thought it should be taught \u2014 not even Dijkstra himself, as Donald Knuth once gently pointed out.Practically everybody in my generation started off with BASIC. On the other hand, at some point (when?), this practice stopped, and the newer generations turned out fine starting out with more civilized languages.\n \nreply",
      "Like most of the programmers of my generation, BASIC was the first language I learned.  BASIC was so pervasive in the 80s and 90s.  Nearly every computer came with a copy of some flavor of BASIC.  Even my 6th grade math textbook had an appendix with educational math games in the form of BASIC source code listings.So long and thanks for all the fish Dr. Kurtz!\n \nreply",
      "I ended up using multiple versions of basic because the various boot discs we had came with different versions. Off the top of my head I remember BASIC, BASICA, and QBASIC. Not that I remember the differences between the flavors any more.\n \nreply",
      "Why \"thanks.*fish\"? (regex, chill ;)I know it is a saying, have read it before, but would prefer to hear the explanation from a person rather than Google.\n \nreply",
      "Hitchhiker's guide to the galaxy\n \nreply",
      "To add to this, it is revealed in Hitchhikers that dolphins are super intelligent extraterrestrials. \"So long and thanks for all the fish\" is the superintelligent dolphins farewell to the last of earth/hummanity.\n \nreply",
      "Could we get a black bar for Dr. Kurtz, please?The legacy of BASIC on our industry can hardly be understated. The language and its mission at Dartmouth was innovative.BASIC had immeasurable secondary effects simply by being the first programming language so many new computer users were exposed to (particularly near the dawn of personal computers).Edit: I got sucked into some nostalgia.Here's the 1964 edition of the Dartmouth BASIC reference: http://web.archive.org/web/20120716185629/http://www.bitsave...It's really charming, and I think it gives you a bit of the feel for the time.(I also particularly like, on page 21, the statement \"TYPING IS NO SUBSTITUTE FOR THINKING\".)\n \nreply",
      "overstated\n \nreply",
      "Learning BASIC on a Commodore 64 as a teenager was a transformative experience. It allowed me to revive the excitement of playing Lego as a kid, but in a scalable way.Thank you, Dr. Kurtz.\n \nreply"
    ],
    "link": "https://computerhistory.org/blog/in-memoriam-thomas-e-kurtz-1928-2024/",
    "first_paragraph": "With deep sadness, we say goodbye to computer pioneer Thomas Kurtz.Thomas Eugene Kurtz (Feb. 22 1928\u2013Nov. 12, 2024) was an American mathematician, computer scientist and co-inventor, with John Kemeny, of the BASIC programming language and Dartmouth Timesharing System.In the early days of academic computing in the 1960s, there were no simple non-professional programming languages available for undergraduates. BASIC was aimed at this audience. To realize their vision, Kurtz and Kemeny concurrently developed the Dartmouth Timesharing System, allowing BASIC to be accessed by students around campus using Teletype terminals.Born in Oak Park Illinois, Kurtz graduated from Knox College in 1950, and received his PhD in mathematics from Princeton University in 1956. In 1951, Kurtz was fortunate in obtaining rare experience on a computer\u2014the pioneering SWAC machine created by the National Bureau of Standards and housed at UCLA. SWAC, the Standards Western Automatic Computer, was among the earlies"
  },
  {
    "title": "The Internet Gopher from Minnesota (abortretry.fail)",
    "points": 53,
    "submitter": "rbanffy",
    "submit_time": "2024-11-11T11:27:59 1731324479",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42106368",
    "comments": [
      "> At GopherCon 1993, it was announced that Gopher servers would need to pay for the privilege of using the protocol... Well, that didn\u2019t work out. People were angry and many felt betrayed. They weren\u2019t quiet about any of it either.> If one were to attempt to identify a single failure of Gopher in competition with the web, it would be the licensing costs. No such fee existed for the World Wide Web.This, a thousand times. I watched as this happened. The instant that announcement was made, gopher was finished. Gopher might have lost later as HTML kept adding features, but by the time those features were added to HTML, gopher had already lost.\n \nreply",
      "Similarly, Bertrand Meyer killed Eiffel by trying to charge money for the compiler, and missing the nascent OSS movement. Java was an inferior language in a few important ways but the compiler and runtime were free. He could not compete with both C++ and Java.A number of people in that era thought this was a fad and that business as usual would prevail.\n \nreply",
      "It seems to me that Gopher just failed to keep up with the times.  Embedding images into the page was a killer feature for HTML and Gopher was still doggedly text based because they were still supporting the VT100 users that had been the core userbase.  Plus the web went on to support text formatting, tables, and even eventually layout.The article isn't entirely correct about the early web being completely free.  Netscape was not free software, at least on paper.  In practice they didn't try to stop people from spreading it far and wide and I think the sales were somewhat modest despite being the core element of a technological revolution.  Also, I guess NCSA Mosiac was technically around, but it lacked enough features to make it a second class citizen compared to Netscape Navigator.\n \nreply",
      "Gopher was built for a pre-HAL world, where you couldn't just assume that every user had a graphics card that your software supported - hell, a lot of them might not have graphics at all. In that environment, lack of embedded multimedia was a selling point due to interoperability. If you had a computer and a phone line, you could access Gopher's primeval web. Graphics and sound be damned.For what it's worth, I have a copy of Netscape on a CD-ROM that came with a copy of PC/Computing sometime around 1994-1995. For those magazine subscribers, it was \"free\" if you squint a little.\n \nreply",
      "More than graphics card one needed an an ip address for the graphical web.\n \nreply",
      "There were ways around that, though I never found the experience to be worth the hassle. The Internet Adapter [1] was the one my shell account supported back in the mid-90s.[1] https://en.wikipedia.org/wiki/The_Internet_Adapter\n \nreply",
      "The world would be better off without most of that though. I want content not all the fluf and such.now get off my lawn!\n \nreply",
      "Gopher was a much more highly structured format. Even if they'd included inline images, they didn't really have a day 0 formatting or layout language that allowed for nesting. There were other locked in choices too, like using a 8 bit value for file type.\n \nreply",
      "I still possess a netscape cdrom which I bought at a store so very long ago.\n \nreply",
      "Not allowing embedded appearance-restricting stuff (such as image or stylesheets) is, in hindsight, what makes gopher great.And, conversely, the popular WWW crap.\n \nreply"
    ],
    "link": "https://www.abortretry.fail/p/the-internet-gopher-from-minnesota",
    "first_paragraph": ""
  },
  {
    "title": "Something weird is happening with LLMs and chess (dynomight.substack.com)",
    "points": 129,
    "submitter": "crescit_eundo",
    "submit_time": "2024-11-14T17:05:40 1731603940",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=42138289",
    "comments": [
      "I don't understand why educated people expect that an LLM would be able to play chess at a decent level.It has no idea about the quality of it's data. \"Act like x\" prompts are no substitute for actual reasoning and deterministic computation which clearly chess requires.\n \nreply",
      "This is a puzzle given enough training information. LLM can successfully print out the status of the board after the given moves. It can also produce a not-terrible summary of the position and is able to list dangers at least one move ahead. Decent is subjective, but that should beat at least beginners. And the lowest level of stockfish is lowest intermediate.I don't know really what level we should be thinking of here, but I don't see any reason to dismiss the idea.\n \nreply",
      "Question here is why gpt-3.5-instruct can then beat stockfish.\n \nreply",
      "PS: I ran and as suspected got-3.5-turbo-instruct does not beat stockfish, it is not even close\n\"Final Results: gpt-3.5-turbo-instruct: Wins=0, Losses=6, Draws=0, Rating=1500.00 stockfish: Wins=6, Losses=0, Draws=0, Rating=1500.00\"\nhttps://www.loom.com/share/870ea03197b3471eaf7e26e9b17e1754?...\n \nreply",
      "Maybe there's some difference in the setup because the OP reports that the model beats stockfish (how they had it configured) every single game.\n \nreply",
      "OP had stockfish at its weakest preset.\n \nreply",
      "Right, at least as of the ~GPT3 model it was just \"predict what you would see in a chess game\", not \"what would be the best move\". So (IIRC) users noted that if you made bad move, then the model would also reply with bad moves because it pattern matched to bad games. (I anthropomorphized this as the model saying \"oh, we're doing dumb-people-chess now, I can do that too!\")\n \nreply",
      "Yeah, that is the \"something weird\" of the article.\n \nreply",
      "my friend pointed out that Q5_K_M quantization used for the open source models probably substantially reduces the quality of play. o1 mini's poor performance is puzzling, though.\n \nreply",
      "Maybe I'm really stupid... but perhaps if we want really intelligent models we need to stop tokenizing at all? We're literally limiting what a model can see and how it percieves the world by limiting the structure of the information streams that come into the model from the very beginning.I know working with raw bits or bytes is slower, but it should be relatively cheap and easy to at least falsify this hypothesis that many huge issues might be due to tokenization problems but... yeah.Surprised I don't see more research into radicaly different tokenization.\n \nreply"
    ],
    "link": "https://dynomight.substack.com/p/chess",
    "first_paragraph": ""
  },
  {
    "title": "Daisy, an AI granny wasting scammers' time (virginmediao2.co.uk)",
    "points": 483,
    "submitter": "ortusdux",
    "submit_time": "2024-11-14T16:52:09 1731603129",
    "num_comments": 178,
    "comments_url": "https://news.ycombinator.com/item?id=42138115",
    "comments": [
      "The scam and spam call problem is really bad in Germany to this day. And has been for 10 years.A couple years ago I would sit at my desk thinking about a really hard problem in silence. The phone rings. Spam call. Every 30-180 minutes another one. If you now think turn the phone off, well not that easy as CEO of a business when people expect you to be reachable.It creamed my corn so much that I recorded my own voice samples as a senile \"Opa Denny\" (german grandpa Denny), modelled after Lenny. Complete with background ducks hanging out on the couch to Opas dismay, later in the call. It works on autopilot without interaction because on Asterisk, and with the largest German SIP provider at least, you can extract the calling peer identity from the SIP header. So I wrote a scoring system based on indicated number, black and whitelist regexs for number and for calling peer, greylist for the geographically surrounding number prefixes, etc. A legit mobile call would show up as number@t-mobile.de for example, while a spam call would say fakenumber@01012.com.Asterisk would record the call in wideband stereo, normalize the audio, and mail it to me as MP3 attachment. Funny for a while, but these days I just throw all such calls onto the mailbox. Since they need a real person to scam or create a sale, the call is finished right away.It works great to this day, because I never published it.\n \nreply",
      "I have both a German mobile number and landline number, and have never once received a scam and spam call on either in the 8 years I have been living in Germany. I guess it is a problem of having a public contact number on a website.\n \nreply",
      "Screen unknown callers to VM. Solved all my problems\n \nreply",
      "I simply don\u2019t answer calls that aren\u2019t in my contacts.\n \nreply",
      "> It creamed my corn so muchCome again?Edit:  I guess it is in urban dictionary, but my first thought was the last definition listed:https://www.urbandictionary.com/define.php?term=creams%20my%...\n \nreply",
      "Cream my corn again?\n \nreply",
      "This is cool when some independent hacker / artist does it as \"Lemmy\".When a big telecom does it, the second thing they do with it is to fuck up the spam detection so bad that every third phone call I make gets answered by \"Daisy\".And just think about it - why would a telecom need this tech? They can already drop the spam calls and stop routing calls from the bad actor telecoms who enable the spammers. They don't do that because they prefer to collect a few cents a call from them rather than serve their customers better. It's everyone else who needs this.\n \nreply",
      "They're not intercepting calls over their network from suspected bad actors; rather, they've created some phone numbers that always go to Daisy - see https://www.ispreview.co.uk/index.php/2024/11/virgin-media-o...\n \nreply",
      "Ah! So step 2 is wait for the spammers to automate blacklisting of Daisy phone numbers, and only then start rolling out a (paid) Daisy option to customers.Not connecting calls doesn't waste spammer money, but maybe Daisy does.If the big telco can find 10 righteous callers from a a bad actor telecom, they should keep routing the calls.\n \nreply",
      "Then, once the spammers have blacklisted the Daisy numbers, cycle those spam-free numbers to their customers and start a new batch of Daisy numbers.  This way, there is a constant flow of spammer free numbers being cycled into the pool.  Of course, everyone and their dog wants your phone number, so you will have to be careful who you give it to if you want it to stay spam-free.\n \nreply"
    ],
    "link": "https://news.virginmediao2.co.uk/o2-unveils-daisy-the-ai-granny-wasting-scammers-time/",
    "first_paragraph": ""
  },
  {
    "title": "Old Vintage Computing Research: Dusting Off Dreamcast Linux (oldvcr.blogspot.com)",
    "points": 28,
    "submitter": "rbanffy",
    "submit_time": "2024-11-14T20:31:07 1731616267",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "http://oldvcr.blogspot.com/2023/02/dusting-off-dreamcast-linux.html",
    "first_paragraph": "REWIND and PLAY\n\n\n\nNeed portability? Well, just load the disc into our handy dandy greymarket clone Treamcast with its built-in LCD display and don't tell Sega. You can take your Unix on the go with the car power adapter: if you can read the screen, now you can live the dream.\n\nBut jokes aside, Dreamcast Linux has something to teach later Johnny-come-latelies with a distro surprisingly well-adapted to its target platform, support for many peripherals, and an all-in-one batteries-included philosophy. Plus, it was one of the earliest Un*xy things for game consoles circa 2001, predating PlayStation 2 Linux by about a year or so, though PS2 Linux was at least Sony-official. (While at least one Linux purports to run on an O.G. PlayStation, this was a slightly later development.)\n\nSo I think there's enough noteworthy about it to merit dusting DC Linux off for a new generation to experience. We'll add a couple quality of life pieces to smooth out a few rough edges, but we won't remove anythin"
  },
  {
    "title": "OpenAI, Google and Anthropic are struggling to build more advanced AI (bloomberg.com)",
    "points": 357,
    "submitter": "lukebennett",
    "submit_time": "2024-11-13T13:28:51 1731504531",
    "num_comments": 406,
    "comments_url": "https://news.ycombinator.com/item?id=42125888",
    "comments": [
      "https://archive.ph/2024.11.13-100709/https://www.bloomberg.c...",
      "Question for the group here: do we honestly feel like we've exhausted the options for delivering value on top of the current generation of LLMs?I lead a team exploring cutting edge LLM applications and end-user features. It's my intuition from experience that we have a LONG way to go.GPT-4o / Claude 3.5 are the go-to models for my team. Every combination of technical investment + LLMs yields a new list of potential applications.For example, combining a human-moderated knowledge graph with an LLM with RAG allows you to build \"expert bots\" that understand your business context / your codebase / your specific processes and act almost human-like similar to a coworker in your team.If you now give it some predictive / simulation capability - eg: simulate the execution of a task or project like creating a github PR code change, and test against an expert bot above for code review, you can have LLMs create reasonable code changes, with automatic review / iteration etc.Similarly there are many more capabilities that you can ladder on and expose into LLMs to give you increasingly productive outputs from them.Chasing after model improvements and \"GPT-5 will be PHD-level\" is moot imo. When did you hire a PHD coworker and they were productive on day-0 ? You need to onboard them with human expertise, and then give them execution space / long-term memories etc to be productive.Model vendors might struggle to build something more intelligent. But my point is that we already have so much intelligence and we don't know what to do with that. There is a LOT you can do with high-schooler level intelligence at super-human scale.Take a naive example. 200k context windows are now available. Most people, through ChatGPT, type out maybe 1500 tokens. That's a huge amount of untapped capacity. No human is going to type out 200k of context. Hence why we need RAG, and additional forms of input (eg: simulation outcomes) to fully leverage that.\n \nreply",
      "> potential applications\n> if you ...\n> for example ...Yes there seems to be lots of potential. Yes we can brainstorm things that should work. Yes there is a lot of examples of incredible things in isolation. But it's a little bit like those youtube videos showing amazing basketball shots in 1 try, when in reality lots of failed attempts happened beforehand. Except our users experience the failed attempts (LLM replies that are wrong, even when backed by RAG) and it's incredibly hard to hide those from them.Show me the things you / your team has actually built that has decent retention and metrics concretely proving efficiency improvements.LLMs are so hit and miss from query to query that if your users don't have a sixth sense for a miss vs a hit, there may not be any efficiency improvement. It's a really hard problem with LLM based tools.There is so much hype right now and people showing cherry picked examples.\n \nreply",
      "> Except our users experience the failed attempts (LLM replies that are wrong, even when backed by RAG) and it's incredibly hard to hide those from them.This has been my team's experience (and frustration) as well, and has led us to look at using LLMs for classifying / structuring, but not entrusting an LLM with making a decision based on things like a database schema or business logic.I think the technology and tooling will get there, but the enormous amount of effort spent trying to get the system to \"do the right thing\" and the nondeterministic nature have really put us into a camp of \"let's only allow the LLM to do things we know it is rock-solid at.\"\n \nreply",
      "> \"let's only allow the LLM to do things we know it is rock-solid at.\"Even this is insanely hard in my opinion.  The one thing that you would assume LLM to excel at is spelling and grammar checking for the English language, but even the top model (GPT-4o) can be insanely stupid/unpredictable at times.  Take the following example from my tool:https://app.gitsense.com/?doc=6c9bada92&model=GPT-4o&samples...5 models are asked if the sentence is correct and GPT-4o got it wrong all 5 times.  It keeps complaining that GitHub is spelled like Github, when it isn't. Note, only 2 weeks ago, Claude 3.5 Sonnet did the same thing.I do believe LLM is a game changer, but I'm not convinced it is designed to be public-facing.  I see LLM as a power tool for domain experts, and you have to assume whatever it spits out may be wrong, and your process should allow for it.Edit:I should add that I'm convinced that not one single model will rule them all. I believe there will be 4 or 5 models that everybody will use and each will be used to challenge one another for accuracy and confidence.\n \nreply",
      "I do contract work on fine-tuning efforts, and I can tell you that most humans aren't designed to be public-facing either.While LLMs do plenty of awful things, people make the most incredibly stupid mistakes too, and that is what LLMs needs to be benchmarked against. The problem is that most of the people evaluating LLMs are better educated than most and often smarter than most. When you see any quantity of prompts input by  a representative sample of LLM losers, you quickly lose all faith in humanity.I'm not saying LLMs are good enough. They're not. But we will increasingly find that there are large niches where LLMs are horrible and error prone yet still outperform the people companies are prepared to pay to do the task.In other words, on one hand you'll have domain experts becoming expert LLM-wranglers. On the other hand you'll have public-facing LLMs eating away at tasks done by low paid labour where people can work around their stupid mistakes with process or just accepting the risk, same as they currently do with undertrained labor.\n \nreply",
      "> \"I see LLM as a power tool for domain experts, and you have to assume whatever it spits out may be wrong, and your process should allow for it.\"this gets to the heart of it for me.\nI think LLMs are an incredible tool, providing advanced augmentation on our already developed search capabilities. What advanced user doesnt want to have a colleague they can talk about their specific domain capacity with?The problem comes from the hyperscaling ambitions of the players who were the first in this space. They quickly hyped up the technology beyond want it should have been.\n \nreply",
      "Those Apple engineers stated in a very clear tone:- every time a different result is produced.- no reasoning capabilities were categorically determined.So this is it. If you want LLM - brace for different results and if this is okay for your application (say it\u2019s about speech or non-critical commands) then off you are.Otherwise simply forget this approach, and particularly when you need reproducible discreet results.I don\u2019t think it gets any better than that and nothing so far implicated it will (with this particular approach to AGI or whatever the wet dream is)\n \nreply",
      "There\u2019s another option here though. Human supervised tasks.There\u2019s a whole classification of tasks where a human can look at a body of work and determine whether it\u2019s correct or not in far less time than it would take for them to produce the work directly.As a random example, having LLMs write unit tests.\n \nreply",
      "(for reference: https://arxiv.org/pdf/2410.05229 )\n \nreply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai",
    "first_paragraph": "To continue, please click the box below to let us know you're not a robot.Please make sure your browser supports JavaScript and cookies and that you are not\n            blocking them from loading.\n            For more information you can review our Terms of\n                Service and Cookie Policy.For inquiries related to this message please contact\n            our support team and provide the reference ID below."
  },
  {
    "title": "My simple knowledge management and time tracking system (henrikwarne.com)",
    "points": 39,
    "submitter": "henrik_w",
    "submit_time": "2024-11-09T16:31:04 1731169864",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42095263",
    "comments": [
      "I really enjoy the obsidian daily notes feature for this [1]. It's a dedicated button to create a new note with a title of your choosing. I typically do YYYY-MM-DD d, so 2024-12-1 mon.I'm not sure about the time tracking though. Is this more for people working on contract for billing? I see the value in having the data but collecting the data seems difficult.[1] https://help.obsidian.md/Plugins/Daily+notes\n \nreply",
      "The task plugin for Obsidian allows tracking time to completion iirc. If you're billing hourly for clients or trying to use it as a stand-in for a stop-watch it could be useful. I personally don't use it though\n \nreply",
      "Org-mode!\nThere. I said it. Now this thread has the obligatory post.\n \nreply",
      "I too save information that may have future value in a textfile. I too am managing knowledge!\n \nreply",
      "I just use Logseq (+ syncthing for sync) with extensive tagging (thousands of tags added a year) + a random Pomodora app that keeps records and descriptions of each Pomadora. Simple and effective\n \nreply",
      "How do you manage having thousands of tags? What is your use case? I quite quickly moved away from them because I couldn't have a strict/normalised system for it. E.g., I would end up with #a, #as, #<synonym of a>, #parent/as, etc. After a while of this, it would either reduce to nothing better than keyword search, or the effort of keeping track of existing tags and the \"right\" tags would prevent me from tagging at all.\n \nreply",
      "for command lists i moved away from notes just create long and descriptive aliases on my shell rc file which i already move everywhere anyway.with the extra advantage of recalling them with tabtab instead of never remembering to read said notes :)\n \nreply",
      "What is that keyboard on the top image? Looks beautiful!\n \nreply",
      "Goldtouch Ergonomic Keyboard\n \nreply"
    ],
    "link": "https://henrikwarne.com/2024/11/09/my-simple-knowledge-management-and-time-tracking-system/",
    "first_paragraph": "I am using a very simple system for remembering commands and procedures, and for tracking what I work on. I have two plain text files called notes.txt and worktime.txt. In the notes file, I write down things that are important to remember. For example: various shell commands, steps when creating a new release, how to install and configure tools, company procedures for time reporting etc.In the worktime file, I write down the hours I worked that day, and what I worked on. I also have a python script that calculates the number of hours worked for the day and the week.In the past few years, I have started at four different companies. At each company, there are many things to remember. Which repositories do I clone? How do I build, test and deploy the system? How do I report time? The first time I do these things, I typically write down some notes about it. The next time, I can do it without asking anybody. If I do the task often enough, I will usually remember how to do it without having "
  },
  {
    "title": "Matrix Client Tutorial (uhoreg.gitlab.io)",
    "points": 4,
    "submitter": "whereistimbo",
    "submit_time": "2024-11-15T00:26:53 1731630413",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://uhoreg.gitlab.io/matrix-tutorial/index.html",
    "first_paragraph": "The basicsEnd-to-end encryptionAppendicesWarningThis book is a work in progress.  Most of the information that it contains\nshould be correct, but it is not complete.Welcome to the Matrix.  Matrix is an open protocol for\ndecentralised communication.  Matrix allows users on different servers to\ncommunicate with each other, similar to how people on different email servers\ncan email each other.This book is an introduction to creating a client using the Matrix\nClient-Server API.  It will show how to make HTTP\ncalls to a Matrix homeserver, and discuss issues that clients will need to\nconsider, such as reliability and security issues.  It does not attempt to be a\ncomprehensive guide to the entire Client-Server API, but will point you to the\nrelevant portions of spec for further details.You should read this book if:you are creating a Matrix library/SDK,you are writing a Matrix client without the use of a library/SDK, oryou want to get a better understanding of how Matrix works.If you are creat"
  },
  {
    "title": "AI makes tech debt more expensive (gauge.sh)",
    "points": 327,
    "submitter": "0x63_Problems",
    "submit_time": "2024-11-14T16:01:59 1731600119",
    "num_comments": 176,
    "comments_url": "https://news.ycombinator.com/item?id=42137527",
    "comments": [
      "> Companies with relatively young, high-quality codebases benefit the most from generative AI tools, while companies with gnarly, legacy codebases will struggle to adopt them. In other words, the penalty for having a \u2018high-debt\u2019 codebase is now larger than ever.This mirrors my experience using LLMs on personal projects. They can provide good advice only to the extent that your project stays within the bounds of well-known patterns. As soon as your codebase gets a little bit \"weird\" (ie trying to do anything novel and interesting), the model chokes, starts hallucinating, and makes your job considerably harder.Put another way, LLMs make the easy stuff easier, but royally screws up the hard stuff. The gap does appear to be widening, not shrinking. They work best where we need them the least.\n \nreply",
      "The niche I've found for LLMs is for implementing individual functions and unit tests. I'll define an interface and a return (or a test name and expectation) and say \"this is what I want this to do\", and let the LLM take the first crack at it. Limiting the bounds of the problem to be solved does a pretty good job of at least scaffolding something out that I can then take to completion. I almost never end up taking the LLM's autocompletion at face value, but having it written out to review and tweak does save substantial amounts of time.The other use case is targeted code review/improvement. \"Suggest how I could improve this\" fills a niche which is currently filled by linters, but can be more flexible and robust. It has its place.The fundamental problem with LLMs is that they follow patterns, rather than doing any actual reasoning. This is essentially the observation made by the article; AI coding tools do a great job of following examples, but their usefulness is limited to the degree to which the problem to be solved maps to a followable example.\n \nreply",
      "Can't tell you how much I love it for testing, it's basically the only thing I use it for. I now have a test suite that can rebuild my entire app from the ground up locally, and works in the cloud as well. It's a huge motivator actually to write a piece of code with the reward being the ability to send it to the LLM to create some tests and then seeing a nice stream of green checkmarks.\n \nreply",
      ">  I now have a test suite that can rebuild my entire app from the ground upWhat does this mean?\n \nreply",
      "Sorry, should have been more clear. Firebase is (or was) a PITA when I started the app I'm working on a few years ago. I have a lot of records in my db that I need to validate after normalizing the data. I used to have an admin page that spit out a bunch of json data with some basic filtering and self-rolled testing that I could verify at a glance.After a few years off from this project, I refactored it all, and part of that refactoring was building a test suite that I can run. When ran, it will rebuild, normalize, and verify all the data in my app (scraped data).When I deploy, it will also run these tests and then email if something breaks, but skip the seeding portion.I had plans to do this before but the firebase emulator still had a lot of issues a few years ago, and refactoring this project gave me the freedom to finally build a proper testing environment and make my entire app make full use of my local firebase emulator without issue.I like giving it my test cases in plain english. It still gets them wrong sometimes but 90% of the time they are good to go.\n \nreply",
      ">see a nice stream of green check marks.Please tell me this is satire.If not, I would absolutely hate to be the person that comes in after and finds a big stream of red xs every time I try to change something.\n \nreply",
      "I had Codeium add something to a function that added a new data value to an object.  Unbidden it wrote three new tests,  good tests.  I wrote my own test by cutting and pasting a test it wrote with a modification, it pointed out that I didn\u2019t edit the comment so I told it to do so.It also screwed up the imports of my tests pretty bad, some imports that worked before got changed for no good reason.  It replaced the JetBrains NotNull annotation with a totally different annotation.It was able to figure out how to update a DAO object when I added a new field.  It got the type of the field wrong when updating the object corresponding to a row in that database column even though it wrote the liquibase migration and should have known the type \u2014- we had chatted plenty about that migration.It got many things right but I had to fix a lot of mistakes.  It is not clear that it really saves time.\n \nreply",
      "Try using Cursor with the latest claude-3-5-sonnet-20241022.\n \nreply",
      "Unfortunately I \u201cthink different\u201d and use Windows.  I use Microsoft Copilot and would say it is qualitatively similar to codeium in quality, a real quantitative eval would be a lot of work.\n \nreply",
      "Cursor (cursor.com) is just a vscode wrapper, should work fine with Windows. If you're already in the AI coding space I seriously urge you to at least give it a go.\n \nreply"
    ],
    "link": "https://www.gauge.sh/blog/ai-makes-tech-debt-more-expensive",
    "first_paragraph": "There is an emerging belief that AI will make tech debt less relevant. Since it\u2019s getting easier to write code, and easier to clean up code, wouldn\u2019t it make sense that the typical company can handle a little more debt?The opposite is true - AI has significantly increased the real cost of carrying tech debt. The key impact to notice is that generative AI dramatically widens the gap in velocity between \u2018low-debt\u2019 coding and \u2018high-debt\u2019 coding.Companies with relatively young, high-quality codebases benefit the most from generative AI tools, while companies with gnarly, legacy codebases will struggle to adopt them. In other words, the penalty for having a \u2018high-debt\u2019 codebase is now larger than ever.If you\u2019ve tried tools like Cursor or Aider for professional coding, you know that their performance is highly sensitive to the complexity of the code you\u2019re working on. They provide a dramatic speedup when applying pre-existing patterns, and when making use of existing interfaces or module rel"
  },
  {
    "title": "SQLite Index Visualization (mrsuh.com)",
    "points": 178,
    "submitter": "mrsuh",
    "submit_time": "2024-11-14T10:51:24 1731581484",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42134964",
    "comments": [
      "Great effort!> By default, each SQLite table row has a unique rowId, which works like a primary key if one isn\u2019t explicitly defined.It actually uses rowid even if you have a primary key.You should try visualizing the primary key index for a WITHOUT ROWID table. Those indexes are my favourite> Both Indexes look similar, but the second Index, with fewer Pages, should be faster.Less nodes doesn\u2019t really mean \u201cfaster\u201d. The most important is the height of the tree.The second most important is what happens when you find your value in the index. Do you need to load the rest from a separate table(rowid)? Or is the data just there for you (without rowid)? Especially range queries (aka where 50<= col <=100)\n \nreply",
      "> Less nodes doesn\u2019t really mean \u201cfaster\u201d. The most important is the height of the tree.In isolation of a single access yes. But when frequently accessing an index overall size can be very important for cache hit rate.\n \nreply",
      "> I wanted to see how a database management system (DBMS) stores an index in both disk and memory, and how it searches through an Index...I chose SQLite for my experimentsSQLite is a bit of an outlier in how it handles...everything, but even more so in query processing. SQLite tends to favor simplicity over performance, which causes it to implement things differently than every other DB I've worked with. You have to understand - SQLite isn't competing with other databases. It's competing with JSON and XML files for persistent storage. This means that how it implements anything tells you practically nothing about how a real database would do something.\n \nreply",
      "> SQLite isn't competing with other databases. It's competing with JSON and XML files for persistent storageIt competes with both. its clearly used for local persistent storage. SO are quite a lot of other things. It also competes with other RDBMSes where a separate server process is not a requirement.That does mean it serves very different requirements, its just that its use case are a lot wider than just replacing JSON and XML files and similar.\n \nreply",
      "> It also competes with other RDBMSes where a separate server process is not a requirement.If you casually list off the top DB's either by usage or by recent hotness then almost all of them will have a server, but you'll also find they're basically all not embedded DB's with exception to RocksDB.\n \nreply",
      "SQLite is a real database engine. I guess what you mean is that SQLite is not competing with database servers.\n \nreply",
      "Meh, it isn't really too far off from the way other DBMS servers handle storage and indexes.  The principles are pretty identical (especially when sqlite operates in WAL mode).\n \nreply",
      "The term \"indexes\" serves both as the third-person singular present tense of the verb \"to index\" and as a plural noun form of \"index.\" In contrast, \"indices\" is the traditional plural form of \"index,\" particularly prevalent in mathematical and scientific contexts. While \"indexes\" is commonly used in general English, \"indices\" is often preferred in technical fields to maintain linguistic precision. Employing \"indices\" in such contexts helps distinguish between the action of indexing and the plural form of index, thereby enhancing clarity.\n \nreply",
      "FWIW, both are fine (https://www.nasdaq.com/articles/indexes-or-indices-whats-the...), and SQLite and PostgreSQL documentation (as two popular examples) use \"indexes\".\n \nreply",
      "Try pluralizing \"time series\". You won't get far.So what I've seen in Finland is people using \"time series\" for the plural and \"time serie\" for the singular.\n \nreply"
    ],
    "link": "https://mrsuh.com/articles/2024/sqlite-index-visualization-structure/",
    "first_paragraph": "After learning about indexes, I understood their basic structure, but I wanted to dig deeper \u2014 to explore the data structure, understand the algorithm, and learn how the index data is stored on disk.\nThe theory and actual implementation can differ, so I decided to explore this topic further.I wanted to see how a database management system (DBMS) stores an index in both disk and memory, and how it searches through an Index.\nI chose SQLite for my experiments:According to SQLite documentation, Indexes are stored in a B-Tree structure, which is a balanced tree where each node has multiple children.\nIt typically looks like this:To understand how SQLite stores Nodes, let\u2019s look at the Page and Cell structures.\nA Page (analog of a Node on SQLite) stores Cells data and has a link to its right child Page.\nA Cell contains Index data, a rowId, and a link to its left child Page.\nBy default, each SQLite table row has a unique rowId, which works like a primary key if one isn\u2019t explicitly defined.Her"
  },
  {
    "title": "PyPI now supports digital attestations (pypi.org)",
    "points": 128,
    "submitter": "miketheman",
    "submit_time": "2024-11-14T14:25:39 1731594339",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=42136375",
    "comments": [
      "I have a bit of uneasiness about how this is heavily pushing GitHub actions as the correct way to publish to PyPI. I had to check PEP740 to make sure it was not directly supported by Microsoft.> The generation and publication of attestations happens by default, and no changes are necessary for projects that meet all of these conditions: publish from GitHub Actions; via Trusted Publishing; and use the pypa/gh-action-pypi-publish action to publish.If you then click on \"The manual way\" it adds a big disclaimer:> STOP! You probably don't need this section; it exists only to provide some internal details about how attestation generation and uploading work. If you're an ordinary user, it is strongly recommended that you use one of the official workflows described above.Where the only official workflow is \"Use GitHub Actions\".I guess I am an idealist but as a maintainer this falls short of my expectations  for the openness of Python and PyPI.\n \nreply",
      "> Where the only official workflow is \"Use GitHub Actions\".The standard behind this (PEP 740) supports anything that can be used with Trusted Publishing[1]. That includes GitLab, Google Cloud, ActiveState, and can include any other OIDC IdP if people make a good case for including it.It's not tied to Microsoft or GitHub in any particular way. The only reason it emphasizes GitHub Actions is because that's where the overwhelming majority of automatic publishing traffic comes from, and because it follows a similar enablement pattern as Trusted Publishing did (where we did GitHub first, followed by GitLab and other providers).[1]: https://docs.pypi.org/trusted-publishers/\n \nreply",
      "I get that, that's why I didn't go \"This is Embrace Extend Extinguish\", but as constructive feedback I would recommend softening the language and to replace:> STOP! You probably don't need this section;In https://docs.pypi.org/attestations/producing-attestations/#t...Perhaps also add a few of the providers you listed as well?> The only reason it emphasizes GitHub Actions is because that's where the overwhelming majority of automatic publishing traffic comes fromGitHub being popular is a self-reinforcing process, if GitHub is your first class citizen for something as crucial as trusted publishing then projects on GitHub will see a higher adoption and become the de-facto \"secure choice\".\n \nreply",
      "> but as constructive feedback I would recommend softening the language and to replace:I can soften it, but I think you're reading it excessively negatively: that warning is there to make sure people don't try to do the fiddly, error-prone cryptographic bits if they don't need to. It's a numerical fact that most project owners don't need that section, since most are either using manual API tokens or are publishing via GitHub Actions.> Perhaps also add a few of the providers you listed as well?They'll be added when they're enabled. Like I said in the original comment, we're using a similar enablement pattern as happened with Trusted Publishing: GitHub was enabled first because it represents the majority of publishing traffic, followed by GitLab and the others.> GitHub being popular is a self-reinforcing process, if GitHub is your first class citizen for something as crucial as trusted publishing then projects on GitHub will see a higher adoption and become the de-facto \"secure choice\".I agree, but I don't think this is PyPI's problem to solve. From a security perspective, PyPI should prioritize the platforms where the traffic is.(I'll note that GitLab has been supported by Trusted Publishing for a while now, and they could make the publishing workflow more of a first class citizen, the way it is on GHA.)\n \nreply",
      "> I agree, but I don't think this is PyPI's problem to solve. From a security perspective, PyPI should prioritize the platforms where the traffic is.To me that's a bit of a weird statement, PyPI is part of the Python foundation, making sure that the project remains true to its open-source nature is reasonable?My concern is that these type of things ultimately play out as \"we are doing the right thing to limit supply chain attacks\" which is good an defendable, but in ~5 years PyPI will have an announcement that they are sunsetting PyPI package upload in favor of the trusted provider system. pip (or other tooling) will add warnings whenever I install a package that is not \"trusted\". Maybe I am simply pessimistic.That being said we can agree to disagree, I am not part of the PSF and I did preface my first comment with \"I guess I am an idealist\".\n \nreply",
      "> making sure that the project remains true to its open-source nature is reasonable?What about this, in your estimation, undermines the open-source nature of PyPI? Nothing about this is proprietary, and I can't think of any sane definition of OSS in which PyPI choosing to verify OIDC tokens from GitHub (among other IdPs!) meaningfully subverts PyPI's OSS committment.> PyPI package upload in favor of the trusted provider system. pip (or other tooling) will add warnings whenever I install a package that is not \"trusted\". Maybe I am simply pessimistic.Let me put it this way: if PyPI disables API tokens in favor of mandatory Trusted Publishing, I will eat my shoe on a livestream.(I was the one of the engineers for both API tokens and Trusted Publishing on PyPI. They're complementary, and neither can replace the other.)\n \nreply",
      "> What about this, in your estimation, undermines the open-source nature of PyPI?Absence of support for self-hosting, in the spirit of freedom 0 = OSD 5&6? Or, for that matter, for any provider whose code is fully open source?\n \nreply",
      "> Absence of support for self-hosting, or for that matter for any non-proprietary service?This has nothing to do with self-hosting, whatsoever. You can upload to PyPI with an API token; that will always work and will not do anything related to Trusted Publishing, which exists entirely because it makes sense for large services.PyPI isn't required to federate with the server in my basement through OpenID Connect to be considered open source.\n \nreply",
      "I'm with @belval on this one, it's ok to prioritize github, but people that want the standard to implement an alternative should not feel like they are doing something that may not be supported.It kinda feels like that right now.\n \nreply",
      "Again, to be clear: the standard does not stipulate GitHub or any other specific identity providers. The plan is to enable GitLab and the other Trusted Publisher providers in short order.This is exactly the same as Trusted Publishing, where people accused the feature of being a MSFT trojan horse because GitHub was enabled first. I think it would behoove everybody to assume the best intentions here and remember that the goal is to secure the most people by default.\n \nreply"
    ],
    "link": "https://blog.pypi.org/posts/2024-11-14-pypi-now-supports-digital-attestations/",
    "first_paragraph": "PyPI package maintainers can now publish signed digital attestations when\npublishing, in order to further increase trust in the supply-chain security of\ntheir projects. Additionally, a new API is available for consumers and\ninstallers to verify published attestations.Many projects have already begun publishing attestations, with more than 20,000\nattestations already published.This finalizes PyPI's support for PEP 740, and follows directly from previous\nwork to add support for Trusted Publishing, as well as the deprecation and\nremoval of PGP signatures.PyPI's support for digital attestations has three key advantages over regular\ncryptographic signatures, such as those provided by PGP:Much more detail is provided in a corresponding blog post by Trail of Bits:\nAttestations: a new generation of signatures on PyPI.For consumers and package installers wanting to perform verification, PyPI\ncurrently provides two ways to access digital attestations associated with a\ngiven file on PyPI:A new In"
  },
  {
    "title": "InspectMind AI (YC W24) Is Hiring for AI in Construction (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-11-14T21:00:51 1731618051",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/inspectmind-ai/jobs/rPuRKf1-software-engineer",
    "first_paragraph": ""
  },
  {
    "title": "The brain summons deep sleep for healing from life-threatening injury (nature.com)",
    "points": 158,
    "submitter": "gmays",
    "submit_time": "2024-11-10T03:47:48 1731210468",
    "num_comments": 80,
    "comments_url": "https://news.ycombinator.com/item?id=42098471",
    "comments": [
      "One thing that stuck with me from the book Stroke of Insight (memoir of brain scientist who has and recovers from stroke) was how intently she prioritized sleep when everyone else kept trying to drag her out of bed.In a more mundane context, I've been fortunate to organize my schedule such that I don't use an alarm to get up in the morning. So I can let my body figure out how much sleep I need.\n \nreply",
      "When my wife had our children, she (and I) were handed them, stuck in a room, then distrurbed for tests and briefings every 90 minutes for 3 days.How anyone can recover from something as savage as childbirth is beyond me. It is no small miracle that she was able to walk, let alone care for two new babies and herself (with my help, but there's only so much I can do to assist with breastfeeding or healing of major trauma).At one point I asked all the nurses to leave and not come back for 6 hours in very angry tones.\n \nreply",
      "The same thing happened to my mom in her 50s after 6 hour quadruple bypass surgery. They basically kept her awake for two days doing tests every hour after her surgery.  She eventually started hallucinating from lack of sleep.  It just seems so inhumane.\n \nreply",
      "This mirrors my experience as well. It's so weird. Give us a break!!\n \nreply",
      "This is standard hospital. Rest is the healer but they will not let you rest. Tests and loud noises, endlessly. It is quite insane.\n \nreply",
      "For new mothers, they want to check that they're still alive and haven't started silently bleeding out, in which case they soon won't be alive.\n \nreply",
      "I stayed in a nice suite in a hotel once and it was the same until I put the do not disturb sign on the doorIt was like they were obsessed with busy work, I couldn\u2019t tell if they didn\u2019t want me there or if this was VIP treatment to themIt was in another country\n \nreply",
      "We had to keep our daughter on a photocopier looking device for bilirubin as well as the tests. Nobody told me how common this is so I also got to enjoy a feeling of panic and dread while that was going on.Plus my boss kept calling me.\n \nreply",
      "Phototherapy is so scary looking, but the NICU nurses made it clear to my wife and I that everything was going to be fine. That said, seeing your newborn in that state after you just welcomed them to the world is a real brain blast of trauma. I still remember the feeling as you described: hollow dread and fear.\n \nreply",
      "\"Congratulations on your baby, but you have more important things to deliver\"\n \nreply"
    ],
    "link": "https://www.nature.com/articles/d41586-024-03491-2",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.AdvertisementMariana Lenharo is a news reporter for Nature based in New York City.You can also search for this author in PubMed\n\u00a0Google Scholar\nYou have full access to this article via your institution.Ample sleep after a heart attack dampens inflammation in the organ, aiding recovery.Credit: GettyImmune cells rush to the brain and promote deep sleep after a heart attack, according to a new study1 involving both mice and humans. This heavy slumber helps recovery by easing inflammation in the heart, the study found.The findings, published today in Nature, could help to guide care for people after a heart attack, says co-auth"
  },
  {
    "title": "A memory leak in Apple's Network Extension framework (obdev.at)",
    "points": 158,
    "submitter": "chmaynard",
    "submit_time": "2024-11-14T13:53:58 1731592438",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=42136136",
    "comments": [
      "I wish there was an independent unit test suite for operating systems and other proprietary software.The suite would run the most-used apps and utilities against updates and report regressions.So for example, the vast majority of apps on my Mac can't run, because they were written for early versions of OS X and OS 9, even all the way back to System 7 when apps were expected to still run on 4/5/6. The suite would reveal that Apple has a track record of de-prioritizing backwards compatibility or backporting bug fixes to previous OS versions.Edit: integration test suite\n \nreply",
      "You don\u2019t need to do anything special to \u201creveal\u201d that Apple doesn\u2019t prioritize backwards compatibility. That is very well known. For example, standard practice for audio professionals is to wait a year or more to upgrade MacOS, to give all the vendors a chance to fix what broke.\n \nreply",
      "Even 15 years ago the common knowledge was to never upgrade to major versions of Apple software, and wait for a .2 release, at least.However, these days it seems that even point releases only introduce new bugs in the rush to deliver late features, and rarely address any issues\n \nreply",
      "I have to disagree. Sequoia .0 was spectacularly broken and .1 is a very noticeable improvement.\u2026of course I\u2019d rather stay on Sonoma if I could go back in time\u2026\n \nreply",
      "Funnily enough, that\u2019s what the UNIX\u2122 certification is, in some\u2014much too limited for your purposes\u2014sense :) See also Raymond Chen\u2019s story of buying one of everything[1].[1] https://devblogs.microsoft.com/oldnewthing/20050824-11/?p=34...\n \nreply",
      "Huh? In service of what? There\u2019s not all that much inherently good about backwards compatibility, but you\u2019re really implying that deprioritising it is a misdeed. If I wanted to use an OS that prioritised backwards compatibility more than macOS, I\u2019d use Windows, and suffer through the downsides of that trade-off. I\u2019m happy using an OS that balances things in a way that\u2019s more in line with my priorities.\n \nreply",
      "Eh, I agree in a sense, but I'm also ok without the same level of backwards compatibility that Windows is beleaguered by. Every new version of Windows is little more than a thin veneer of whatever they think is a popular choice for UI design that year, and with that comes a clumsy amalgamation of hugely varying settings dialogs, the classic registry, all the goop. Meanwhile on macos, I don't expect very complex software to maintain perfect compatibility, but I can reasonably expect most of the stuff I use to carry forward 5+ years. Parallels and Omnifocus were the exceptions, but 1password from 2012 is still kicking, Data Rescue 3 somehow still works, I'm sure even Adobe CS6 would even though it's from the Carbon era.Just as well, although I loathe some of the choices Apple's made over the years, such as it's own Settings app, the overall UI would be pretty recognizable if me from 20 years ago found a time machine (pun intended). I recently bought a new mac, and it occurred to me that it feels basically like the E-Mac I used in middle school all those years ago, albeit with the occasional annoyance I wouldn't have been aware of then.\n \nreply",
      "meanwhile my Lulu alternative to littlesnitch is barely leaking anything after running for weeks:sudo leaks com.objective-see.lulu.extension | grep \"total leaked bytes\"\nPassword:\nProcess 851 is not debuggable. Due to security restrictions, leaks can only show or save contents of readonly memory of restricted processes.Process 851: 1086 leaks for 108576 total leaked bytes.\n \nreply",
      "base  sudo leaks at.obdev.littlesnitch.networkextension | grep \"total leaked bytes\"\nPassword:\nProcess 310 is not debuggable. Due to security restrictions, leaks can only show or save contents of readonly memory of restricted processes.Process 310: 314990 leaks for 967643488 total leaked bytes.Ouch!\n \nreply",
      "brett@algol \ue0b0 minikube / default \ue0b0 ~/Documents/misc \ue0b0 sudo leaks at.obdev.littlesnitch.networkextension | grep \"total leaked bytes\"\nPassword:\nProcess 43619 is not debuggable. Due to security restrictions, leaks can only show or save contents of readonly memory of restricted processes.Process 43619: 2194911 leaks for 6742615664 total leaked bytes.jesus.\n \nreply"
    ],
    "link": "https://obdev.at/blog/a-memory-leak-in-apples-network-extension-framework/",
    "first_paragraph": "Is it normal for the Little Snitch Network Extension to consume Gigabytes of memory? No it isn\u2019t.Unfortunately that\u2019s another new bug in the Network Extension framework of macOS. It\u2019s a memory leak in Apple\u2019s framework, which developers must use to create a firewall for the Mac. This bug first occurred in macOS 15.0 Sequoia.You can easily check if you are affected by this bug by running the leaks command in a Terminal window:On macOS 14 Sonoma you may get a hand full of leaks with a total of a few Kilobytes. That\u2019s OK (sort of). But on macOS 15 Sequoia this can easily grow to hundreds of Megabytes and more.Once again, we rely on Apple to fix this issue in a macOS update.This bug has already been reported to Apple (FB15552991), but if you are affected by this bug, feel free to send another report via Feedback Assistant (mentioning the existing report FB15552991). This might help Apple to find the cause of the issue and it increases the chance that Apple will prioritize the fix.For the t"
  },
  {
    "title": "Show HN: Windsurf \u2013 Agentic IDE (codeium.com)",
    "points": 45,
    "submitter": "fortenforge",
    "submit_time": "2024-11-13T17:09:27 1731517767",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42127882",
    "comments": [
      "Tbh while and after watching the video, I wasn't sure if the whole thing isn't just a parody of AI companies.\n \nreply",
      "Felt like I was watching Silicon Valley.\n \nreply",
      "Did you notice Russ Hanneman? It's supposed to be a play on SV.\n \nreply",
      "Any idea how Codeium is able to provide users with unlimited access to Sonnet and 4o for only $10 per month? I can easily blow through $10 in API credits from either of them. Is that price going to be sustainable?\n \nreply",
      "Of course it's not going to be sustainable.My idea: https://en.wikipedia.org/wiki/Predatory_pricing\n \nreply",
      "+ I guess it's not really fully unlimited\n \nreply",
      "I\u2019ve been using it the past few days. It\u2019s both magical and terrible. They do their own terminal management so you\u2019re fighting env issues that make no sense. It somehow spawns a terminal that can\u2019t find my installed version of node, so then it asks me to brew install one, but will this now screw up my system or no? It\u2019s an uncanny valley moment where it\u2019s close, but also not really there. Hopefully the team can quickly improve this UX and use the native terminal functionality as the foundation of how they interact with the system.\n \nreply",
      "I've been using Codeium's vscode extension (have also tried out vim & emacs 'extensions') and it's my favorite (out of the free ones - that is)the ctrl-shift-i for \"inline chat - sort of\", generate docstrings, control over context, I dunno, a couple small details that make it a little better.I don't know what model they use but it's quite fast and I don't personally notice an \"iq penalty\" although I'm sure there is one\n \nreply",
      "Which other extensions have you tried? I've been experimenting with Cline and Continue.dev recently. Continue seems to be the winner for now, but I may give Codeium and Windsurf a try.\n \nreply",
      "for the cynical folks, Codeium has been publishing blogposts with me on AI product thinking and its been remarkable to watch as someone with no vested interest:https://latent.space/p/enterpriseyes, they started with \"another copilot\", and had one of the best years in code for enterprise ai this year.here they are starting with \"another cursor\".see the pattern?\n \nreply"
    ],
    "link": "https://codeium.com/windsurf/",
    "first_paragraph": ""
  },
  {
    "title": "Upcoming Hardening in PHP (dustri.org)",
    "points": 7,
    "submitter": "mmsc",
    "submit_time": "2024-11-06T15:18:02 1730906282",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://dustri.org/b/upcoming-hardening-in-php.html",
    "first_paragraph": "In 2022, cfreal gave a talk at BlackAlps 2022\non Generic Remote Exploit Techniques For The PHP Allocator, And\n0days. I was there as\nwell, told him that it was\nridiculous that PHP's heap was such a soft target, and that I might do\nsomething about it eventually, if only to make PHP exploitation less dull.Two years later, I opened a\nmeta-issue on PHP's bug tracker,\nand (slowly) started to get to work. I was immediately joined by Arnaud Le\nBlanc on this endeavour, who actually did most\nof the work and was kind enough to ping-pong on reviews. Here's what we did so\nfar:We also took a stab at some non-heap-related techniques:All those cool things either have landed or will likely soon, so keep your PHP\nstack up to date. And as usual if you need more hardening, there is always\nSnuffleupagus. I find it fascinating that people are putting so much efforts optimizing\nexploitation techniques, yet ~nobody bothers fixing them, even if it only takes\na couple of lines of code and 20 minutes."
  },
  {
    "title": "Bootstrapping Alpine Linux without root (brixit.nl)",
    "points": 10,
    "submitter": "mooreds",
    "submit_time": "2024-11-11T14:02:06 1731333726",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42107146",
    "comments": [
      "> Creating a chroot in Linux is pretty easy: put a rootfs in a folder and run the sudo chroot /my/folder command. But what if you don't want to use superuser privileges for this?My very first thought is actually proot ( https://proot-me.github.io/ ), though that does have a performance hit.That said, once you're using unshare (which is a good idea), why not just use podman? Mostly the same under the hood, but does a bunch of this for you. And for this exact usecase I appreciate that there are tradeoffs but I personally would have built pmbootstrap out of Dockerfiles in the first place.\n \nreply",
      "What about user-mode Linux containers?\n \nreply"
    ],
    "link": "https://blog.brixit.nl/bootstrapping-alpine-linux-without-root/",
    "first_paragraph": "sudo chroot without sudo... and mostly without the chrootI do computer stuffMore posts by Martijn BraamCreating a chroot in Linux is pretty easy: put a rootfs in a folder and run the sudo chroot /my/folder command. But what if you don't want to use superuser privileges for this?This is not super simple to fix, not only does the chroot command itself require root permissions but the steps for creating the rootfs in the first place and mounting the required filesystems like /proc and /sys require root as well.In pmbootstrap the process for creating an installable image for a phone requires setting up multiple chroots and executing many commands in those chroots. If you have the password timeout disabled in sudo you will notice that you will have to enter your password tens to hundreds of times depending on the operation you're doing. An example of this is shown in the long running \"pmbootstrap requires sudo\" issue on Gitlab. In this example sudo was called 240 times!Now it is possible wi"
  }
]