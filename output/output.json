[
  {
    "title": "Firefly \u2018Blue Ghost\u2019 lunar lander touches down on the moon (cnn.com)",
    "points": 105,
    "submitter": "complexpass",
    "submit_time": "2025-03-02T09:31:50 1740907910",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=43228816",
    "comments": [
      "Here are the pictures it has taken so far:https://www.flickr.com/photos/fireflyspace/albums/7217772031...There's also a cool lunar flyover video taken during final deorbit.\n \nreply",
      "Flickr? Moon landing? What year is it?\n \nreply",
      "Thank you for sharing that link. That is exactly what I wanted to see.Greatly deserved kudos to the team!\n \nreply",
      "Congrats to everyone involved!I planned to watch the live stream but wasn't able to. The moment of successful landing was quite modest, only a mostly-static screen with telemetrics was shown to the public, but it absolutely felt magical. It feels like the moon is well within humankind's reach by now.Coincidentally, I found a copy of Uchu Kyodai (by Chuya Koyama) in my local library, and started reading it recently. It's fun to compare the perspectives from more than a decade ago, to the actual development we have right now, regarding space exploration.(This was posted to another thread, but I moved it here after I realized comments were moved)\n \nreply",
      "> It feels like the moon is well within humankind's reach by now.It has been for the last 65 years. ;)\n \nreply",
      "Yeah that's true, but I haven't really experienced the Apollo era personally. After the \"gap\" between the old space race, and the new race inspired by private space agencies, I do feel we are getting closer, to the moon at least.\n \nreply",
      "More info:- https://x.com/Firefly_Space/status/1896127381670367703- https://www.nasa.gov/news-release/touchdown-carrying-nasa-sc...\n \nreply",
      "Super cool.  This is one of those things you watch and just \"feels like the future\".  I know, we've been there before but it still feels like an awesome event.(someone go back to Venus, I know it's hard, but someone please)\n \nreply",
      "More discussion: https://news.ycombinator.com/item?id=43224107\n \nreply",
      "Thanks! Macroexpanded:Firefly Blue Ghost Mission 1 Lunar Landing - https://news.ycombinator.com/item?id=43224107 - March 2025 (40 comments)Blue Ghost Moon landing Sunday 3:30am EST using Earth GPS lock 238000 miles away - https://news.ycombinator.com/item?id=43222015 - March 2025 (3 comments)Nyx Space and Rust Power Firefly's Blue Ghost Lunar Landing - https://news.ycombinator.com/item?id=43217811 - March 2025 (1 comment)"
    ],
    "link": "https://www.cnn.com/science/live-news/moon-landing-blue-ghost-03-02-25/index.html",
    "first_paragraph": "\n            \u2022 A robotic lunar lander built by Texas-based company Firefly has successfully landed on the moon, touching down around 2:34 a.m. CT (3:34 a.m. ET).\n    \n            \u2022 The lander, called Blue Ghost, launched to orbit on a SpaceX rocket in January, spent some time in Earth\u2019s orbit and had been maneuvering toward the moon ever since.\n    \n            \u2022 Firefly has become only the second private-sector company ever to achieve a soft lunar landing. Several have failed in the past.\n    \n            \u2022 Firefly is carrying out this mission as a contractor under NASA\u2019s CLPS and Artemis programs, which aim to use robotic landers to scout the moon before humans return later this decade.\n    \nWe\u2019ve wrapped up our live coverage for the day. Read more about Blue Ghost\u2019s moon landing success here or scroll through the posts below to relive the event as it unfolded.\n\n            Perhaps the most difficult, nail-biting stretch of Blue Ghost\u2019s mission is over with. The vehicle is sitting on"
  },
  {
    "title": "Solarpunk (wikipedia.org)",
    "points": 60,
    "submitter": "nis0s",
    "submit_time": "2025-03-02T23:39:29 1740958769",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43236520",
    "comments": [
      "I truly love this aesthetic and it's vision of the future. Clean air, healthy food, empowered communities. Abundance without waste, progress without destruction, and equal opportunity without tyranny. This is the future that we should be developing software to enable. Instead, I'm frequently disappointed by the modern usages of software, which seem to cause excess waste, accelerate the destruction of our planet, and enable authoritarians. Maybe it's time to rethink what we're working towards.\n \nreply",
      "Becky Chambers\u2019 \u201cA Psalm for the Wild Built\u201d is a nice dose of solarpunk fiction if you need a pick-me-up: https://bookshop.org/p/books/a-psalm-for-the-wild-built-beck...(Chambers\u2019 entire body of work is just generally a nice cup of tea and a warm blanket for the soul in sci-fi form - the Wayfarers series starting with \u201cThe Long Way to a Small, Angry Planet\u201d is maybe the best collection of before-bed reading I\u2019ve ever found.)\n \nreply",
      "Future generations will probably look at our current housing and building design as barbaric and primitive. The fact that we build houses and skyscrapers covered in sunlight and place bricks instead of solar panels will dumbfound future generations. They will look at us and think \"Man, these idiots really didn't understand free energy was all around them.\"\n \nreply",
      "I miss like any form of social idealism.\n \nreply",
      "I try to remember that the USA is the same country that made the 90s Star Trek I grew up with a mainstream hit.\n \nreply",
      "I could use some optimistic takes on the future. I read the news if I want dystopian. In everyday life, I do some local work to try and make housing more abundant and less impactful, but it's a small piece of the puzzle.\n \nreply",
      "One thought that keeps popping into my head every time I see something solarpunk related - Solarpunk is proto Star Trek.It's the closest concept we have to that post scarcity utopia, albeit on a very small scale, and likely completely unsustainable for any decently sized chunk of the global population. But it makes me wonder what the best way to chart that progress would be, and what the present day equivalent for quality of life it would be best to aim at based on current levels of technology.\n \nreply",
      "Sustainability for large populations is kind've a cornerstone of solarpunk, alongside decentralization and horizontal power to empower individuals and communities against corporation and government control.There's a lot of discussion on how to implement solarpunk in the here and now over on the fediverse, like Lemmy, but a condensed version of short term goals tends to be:1. Switch to solar and wind on a mass scale, including personal solar such as the type described in low-tech magazine, combined with reducing energy use as much as is reasonable.2. Embrace permaculture urbanism, where energy and food production take place in cities. The most well researched proposal put forward is by the Edenicity project.3. Replace as many cars as possible by implementing more robust and far reaching public transport and bicycle infrastructure in urban and rural areas, more in line with the Netherlands.4. Build new societal structures that are bottom up through mutual aid, to wean ourselves off corporatism and consumerism, and to develop community independence.None of those objectives are too far fetched, and would lay the groundwork for even more positive change.\n \nreply",
      "I would also add that all of these would provide jobs, construction, high-level engineering, etc and any knock on benefit people with paying work contribute to their local/national economies would bring.\n \nreply",
      "It seems like Trek handwaved away or ignored a lot of the issues that weren't directly solved by replicators. Joseph Sisko's had a restaurant on earth. The idea of a guy who loves to cook for people having a place where anyone can walk in off the street, order from a menu, and eat for free is easy to envision. The problem comes when you start to think about how there's a very finite amount of physical space. Questions like who decided that he should have that property for his restaurant vs anyone else who wanted to do something with it just never come up.I'm interested in seeing Solarpunk grow that that we can see different people's ideas on how issues like this can be addressed without these fictional worlds  becoming dystopian.\n \nreply"
    ],
    "link": "https://en.wikipedia.org/wiki/Solarpunk",
    "first_paragraph": "Solarpunk is a literary and artistic movement, close to the hopepunk movement,[3] that envisions and works toward actualizing a sustainable future interconnected with nature and community.[4][5][6] The \"solar\" represents solar energy as a renewable energy source and an optimistic vision of the future that rejects climate doomerism,[7] while the \"punk\" refers to do it yourself and the countercultural, post-capitalist, and sometimes decolonial aspects of creating such a future.[8]\nAs a science fiction literary subgenre and art movement, solarpunk works to address how the future might look if humanity succeeded in solving major contemporary challenges with an emphasis on sustainability, human impact on the environment, and addressing climate change and pollution. Especially as a subgenre, it is aligned with cyberpunk derivatives, and may borrow elements from utopian and fantasy genres.[7]\nSolarpunk serves as a foil to the cyberpunk genre, particularly within the fashion industry.[9] Both "
  },
  {
    "title": "Gooey rubber that's slowly ruining old hard drives (downtowndougbrown.com)",
    "points": 80,
    "submitter": "zdw",
    "submit_time": "2025-03-02T22:11:39 1740953499",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=43235763",
    "comments": [
      "I used to cynically think that things breaking down over time was mostly a choice for built-in obsolescence. After doing some real physical product design though, I can say that it's really difficult to build things to last.\n \nreply",
      "Obsolescence doesn't exist because a comically evil mastermind designs things to break. It exists because capitalism favors profits over anything else.A lower quality component is cheaper than a higher quality one that would last longer, so that's what ends up being mass produced, and that's what you, as a product designer with no power over the entirety of the production pipeline, has to work with.\n \nreply",
      "Spending time in a company that designs and manufactures real products will cure anyone of this conspiracy theory. There\u2019s probably an exception for companies that don\u2019t have any warranty and don\u2019t have to suffer returns (e.g. the stuff you buy from Temu). Any company that has to build a reputation and suffer the economic consequences of warranty claims will not be doing anything to intentionally make their products break down over time.Once you\u2019re close to the engineering side of physical products you also realize how hard it would be to make products that break down precisely after the warranty period is up. Most failure modes get spread out over a very long time (years/decades). Attempts at intentional obsolescence would start cutting into your warranty period very easily.\n \nreply",
      "The cost of improved quality still need only offset the cost of returns within the warranty period and opinion on reasonable product lifetime though. At some point the cost of better quality will be greater than the profit margin a company is willing to accept and a consumer is willing to pay, but it\u2019s in the companies best interest to get that as close to a number that passes the pub test (e.g., an \u2018untentional\u2019 bug bricking the firmware the day after warrantee expires)I\u2019m not convinced some of my very expensive smart products aren\u2019t intentionally degrading over time, given fw is introducing more functional bugs.\n \nreply",
      "Do you think the fact that new cars have engines that are not rebuildable but only replaceable is just a coincidence? With every year car manufacturers get more insight in how and when things break, thus allowing the use of more plastic parts in the engine bay\n \nreply",
      "It's not a coincidence - new cars have turbochargers and electronic engine control that provide huge performance/efficiency gains and necessarily are harder to repair.Your average shitty 4-banger from the 80s or 90s is not remotely comparable to a new engine - in almost every respect (including reliability!) the new one is better.\n \nreply",
      ">it's really difficult to build things to lastA lot of depends on where your price point is. Do you compete with Temu or do you sell expensive things. People rarely expect cheap things to last, but if you don't compete on being the cheapest, than the product is expected to be made to last\n \nreply",
      "Rubber doesn't age well.I guess that we've all had some kind of gear that still works fine, but the rubber coating is all tacky and nasty, and leaves smears on your hand.I had to toss out a bunch of really good mice because of that.\n \nreply",
      "You can use isopropyl alcohol to remove the sticky nasty rubber and at least make the thing usable again.\n \nreply",
      "I had forgotten about Quantum hard drives.. I bought a Quantum harddrive in the 1990s for my mac like \"Tower Power Pro\".. It stopped working about a week after I got it with clicks.  The first clue something was amiss was the person on the phone stating \"thats a little early for it to fail\".  Got a replacement drive... 2 weeks later same issue.   I think they were bought out by someone.As I get older I wonder how may of my burned DVDs will still work.. My MiniDiscs still do as of this fall when I dusted them off (different technology).  I had heard of tv networks \"baking \" magnetic tapes to get the information off.[1]\nhttps://en.wikipedia.org/wiki/Sticky-shed_syndrome\n \nreply"
    ],
    "link": "https://www.downtowndougbrown.com/2025/03/the-gooey-rubber-thats-slowly-ruining-old-hard-drives/",
    "first_paragraph": "As part of my work toward an upcoming post about a lost piece of very obscure Mac history that has finally been found, I\u2019ve been playing around with old Apple-branded SCSI hard drives made by Quantum and Conner in the 1990s. What I\u2019m about to describe is already common knowledge in the vintage computing world, but I thought it would be fun to share my take on it anyway.What I\u2019m talking about is how a lot of these hard drives just refuse to work anymore. This is very common with old Quantum ProDrive models, like the LPS or the ELS. The drive spins up, you don\u2019t hear the expected pattern of click sounds at startup, and then after a few seconds, it spins back down.This Conner CP30175E drive has a similar problem, but it tries over and over again, playing a tone through the voice coil (I think) in between attempts.These particular hard drives shown in the videos are both about 160 MB in capacity and were commonly used in computers during the early-to-mid 1990s. You can see they have Apple "
  },
  {
    "title": "Smallpond \u2013 A lightweight data processing framework built on DuckDB and 3FS (github.com/deepseek-ai)",
    "points": 173,
    "submitter": "overflowcat",
    "submit_time": "2025-02-28T01:56:35 1740707795",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=43200793",
    "comments": [
      "We are seeing more and more specialized query engines.\nThis is a query engine specialized for training pipelines. It is not general purpose - it is for providing batches of training data at workers. It uses Ray for parallelization. The kind of queries you need are random reads (to implement shuffling across epochs), arrow support (zero copy to Pandas DataFrames), and efficient checkpointing.\n \nreply",
      "One thing I found peculiar is that for the GraySort benchmark it dispatches to Polars by default to do the actual sorting, not DuckDB: https://github.com/deepseek-ai/smallpond/blob/ed112db42af4d0....\n \nreply",
      "Related ongoing thread:Understanding Smallpond and 3FS - https://news.ycombinator.com/item?id=43232410also:DuckDB goes distributed? DeepSeek's smallpond takes on Big Data - https://news.ycombinator.com/item?id=43206964 (no comments there, but some people have been recommending that article)\n \nreply",
      "DuckDB itself is cool enough, especially when combined with SQLite and/or PostgreSQL, and now this. Thanks DeepSeek!\n \nreply",
      "May Data Engineering content keep on hitting front page HN!\n \nreply",
      "What does this do - what is the benefit over DuckDB, Polers etc?\n \nreply",
      "Mehdi just wrote about this. Mainly starting DAGs parallelism using Ray (core) and their filesystem 3FS. See https://mehdio.substack.com/p/duckdb-goes-distributed-deepse....\n \nreply",
      "I don't think you get any really benefits over duckdb unless your data is 10tb+ or you spin up 3FS (which seem challenging).\n \nreply",
      "If you want to checkout duckdb try QStudio. It's a free sql client with duckdb integrated: https://www.timestored.com/qstudio/help/duckdb-sql-editor. Disclaimer: I'm the main author.\n \nreply",
      "Big fan of QStudio! Thanks for building it!\n \nreply"
    ],
    "link": "https://github.com/deepseek-ai/smallpond",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A lightweight data processing framework built on DuckDB and 3FS.\n      \n\n\nA lightweight data processing framework built on DuckDB and 3FS.Python 3.8 to 3.12 is supported.For detailed guides and API reference:We evaluated smallpond using the GraySort benchmark (script) on a cluster comprising 50 compute nodes and 25 storage nodes running 3FS.  The benchmark sorted 110.5TiB of data in 30 minutes and 14 seconds, achieving an average throughput of 3.66TiB/min.Details can be found in 3FS - Gray Sort.This project is licensed under the MIT License.\n        A lightweight data processing framework built on DuckDB and 3FS.\n      "
  },
  {
    "title": "Speedrunners are vulnerability researchers, they just don't know it yet (zetier.com)",
    "points": 199,
    "submitter": "chc4",
    "submit_time": "2025-03-02T17:40:36 1740937236",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=43232880",
    "comments": [
      "The metaphor is a bit stretched for the purposes of content marketing a startup. The major difference between vulnerability researchers and the speedrunning community is that speedrunning is highly collaborative and open. There are massive speedrunning Discord communities for each game, and even before Discord existed, tricks and hacks were discovered iteratively just by many people watching other people do them often unintentionally and trying to figure out how they work (a common trend in every Summoning Salt video).Nintendo doesn't care if people find ACE in decade-old games (usually) and post decompiled versions of games on GitHub so people can find out how they tick, but vulnerability researchers can't do that unless they want to risk causing a legal shitstorm.\n \nreply",
      "Yes, the differences are substantial.\nIt's also worth noting that although some speedrunning may be akin to vulnerability research, the vast majority of speedrunners are \"only\" practicing and replicating exploits demonstrated by others. They're in different columns.\n \nreply",
      "> the vast majority of speedrunners are \"only\" practicing and replicating exploits demonstrated by othersSo they are red teamers :p\n \nreply",
      "In this analogy, they are only retesting things reported by a previous red team who did that target.\n \nreply",
      "They are script kiddies ;)\n \nreply",
      "Kind of, but even an average runner can experience a bug or refine a strategy through repeat practice, which they often share with the community through streamed runs or discords.You tend to have certain people who are more interested in glitch finding and spend most of their focus on that over actually running the game. Then you have TAS runners (often overlap with glitch hunters) who make TAS-only runs to determine what the absolute limit is in a game. Finally, you have the remaining 95% of the community, runners grinding the game over and over.Strategies from TAS often are repurposed by speedrunners, perhaps most famously in Mario 1 any%, where several strats used by top runners were once considered infeasible for humans.\n \nreply",
      "I knew that TAS meant \u201ca computer\u201d but for those, like me, who forgot/ didn\u2019t know, TAS stands for \u201ctool-assisted speedrun\u201d.\n \nreply",
      "Correct. TAS usually means to use a tool that lets them painstakingly play the game on a frame-by-frame basis (usually 1/60th of a second), each frame making the theoretically optimal input.\n \nreply",
      "Vulnerability research, in my experience, has been pretty collaborative and open - especially in the bug bounty space.\n \nreply",
      "I think if they're active in the speedrunning community, then they're already well aware of this! And for a fun additional example to add to this article, you can often find TAS'ers talking about arbitrary code execution. The legendary GDQ run of TASBot's alternate ending to OoT[0] utiziling an ACE exploit they found in that game absolutely blew me away.[0] https://youtu.be/PNbkv_DJ0f0?t=3112\n \nreply"
    ],
    "link": "https://zetier.com/speedrunners-are-vulnerability-researchers/",
    "first_paragraph": "Thousands of video game enthusiasts are developing experience in the cybersecurity industry by accident. They have a fun hobby, pouring over the details of their favorite games, and they don't know they could be doing something very similar\u2026 by becoming a vulnerability researcher.That probably requires some backstory, especially from a cybersecurity company's blog!Basically as soon as video games were released, people have been trying to beat them faster than their friends (or enemies) can. Gamers will do this for practically any game on the planet \u2013 but the most popular games, or the ones with the most cultural weight and cultish following, naturally end up with the fiercest competition. Speedrunners will run through their favorite game hundreds or thousands of times in order to get to get to the top of community-driven leaderboards for the fastest time\u2026 which puts incentives on that video game's community to find the absolute fastest way to clear the game, no matter how strange.\"Any "
  },
  {
    "title": "Hallucinations in code are the least dangerous form of LLM mistakes (simonwillison.net)",
    "points": 119,
    "submitter": "ulrischa",
    "submit_time": "2025-03-02T19:15:58 1740942958",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=43233903",
    "comments": [
      "My fear is that LLM generated code will look great to me, I won't understand it fully but it will work. But since I didn't author it, I wouldn't be great at finding bugs in it or logical flaws. Especially if you consider coding as piecing together things instead of implementing a well designed plan. Lots of pieces making up the whole picture but a lot of those pieces are now put there by an algorithm making educated guesses.Perhaps I'm just not that great of a coder, but I do have lots of code where if someone took a look it, it might look crazy but it really is the best solution I could find. I'm concerned LLMs won't do that, they won't take risks a human would or understand the implications of a block of code beyond its application in that specific context.Other times, I feel like I'm pretty good at figuring out things and struggling in a time-efficient manner before arriving at a solution. LLM generated code is neat but I still have to spend similar amounts of time, except now I'm doing more QA and clean up work instead of debugging and figuring out new solutions, which isn't fun at all.\n \nreply",
      "I do these things for this:- keep the outline in my head: I don't give up the architect's seat. I decide which module does what and how it fits in the whole system, it's contract with other modules etc.- review the code: this can be construed as negating the point of LLMs as this is time consuming but I think it is important to go through line by line and understand every line. You will absorb some of the LLM generated code in the process which will form an imperfect map in your head. That's essential for beginning troubleshooting next time things go wrong.- last mile connectivity: several times the LLM takes you there but can't complete the last mile connectivity; instead of wasting time chasing it, do the final wiring yourself. This is a great shortcut to achieve the previous point.\n \nreply",
      "The big argument against it is, at some point, there\u2019s a chance, that you won\u2019t really need to understand what the code does. LLMs writes code, LLMs write tests, you find bugs, LLM fixes code, LLM adds test cases for the found bug. Rinse and repeat.\n \nreply",
      ">My fear is that LLM generated code will look great to me, I won't understand it fully but it will work.puzzled. if you don't understand it fully, how can you say that it will look great to you, and that it will work?\n \nreply",
      "All of this. Could have saved me a comment [0] if I'd seen this earlier.When people talk about 30% or 50% coding productivity gains with LLMs, I really want to know exactly what they're measuring.[0] https://news.ycombinator.com/item?id=43236792\n \nreply",
      "> Just because code looks good and runs without errors doesn\u2019t mean it\u2019s actually doing the right thing. No amount of meticulous code review\u2014or even comprehensive automated tests\u2014will demonstrably prove that code actually does the right thing. You have to run it yourself!I would have stated this a bit differently: No amount of running or testing can prove the code correct. You actually have to reason through it. Running/testing is merely a sanity/spot check of your reasoning.\n \nreply",
      "I\u2019m not sure it\u2019s possible to have the full reasoning in your head without authoring the code yourself - or, spending a comparable amount of effort to mentally rewrite it.\n \nreply",
      "I tend to agree, which is why I\u2019m skeptical about large-scale LLM code generation, until AIs exhibit reliable diligence and more general attention and awareness, and probably also long-term memory about a code base and its application domain.\n \nreply",
      "Agree - case in point - dealing with race conditions. You have to reason thru the code.\n \nreply",
      "Well, what if you run a complete test suite?\n \nreply"
    ],
    "link": "https://simonwillison.net/2025/Mar/2/hallucinations-in-code/",
    "first_paragraph": "2nd March 2025A surprisingly common complaint I see from developers who have tried using LLMs for code is that they encountered a hallucination\u2014usually the LLM inventing a method or even a full software library that doesn\u2019t exist\u2014and it crashed their confidence in LLMs as a tool for writing code. How could anyone productively use these things if they invent methods that don\u2019t exist?Hallucinations in code are the least harmful hallucinations you can encounter from a model.The real risk from using LLMs for code is that they\u2019ll make mistakes that aren\u2019t instantly caught by the language compiler or interpreter. And these happen all the time!The moment you run LLM generated code, any hallucinated methods will be instantly obvious: you\u2019ll get an error. You can fix that yourself or you can feed the error back into the LLM and watch it correct itself.Compare this to hallucinations in regular prose, where you need a critical eye, strong intuitions and well developed fact checking skills to avoi"
  },
  {
    "title": "CSS Custom Functions are coming (bram.us)",
    "points": 40,
    "submitter": "Fudgel",
    "submit_time": "2025-03-02T22:52:35 1740955955",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=43236126",
    "comments": [
      "Thanks. Looks hideous.@function --light-dark(--light, --dark) {  result: var(--light);\n\n  @media (prefers-color-scheme: dark) {\n    result: var(--dark);\n  }\n}\n \nreply",
      "Looks decent to me, I understand they have to stay within the normal look of CSS. That function, other than nesting, could every well be parsed by a 20-year-old parser.\n \nreply",
      "Yeah, I couldn't believe it at first.If you're going to add imperative programming to CSS, just do it already. Hacking in conditionals in this way feels like a bad joke.\n \nreply",
      "These are closer to macros than functions, especially without css if(). It's nothing that you can't already do.\n \nreply",
      "Was https://en.wikipedia.org/wiki/JavaScript_Style_Sheets right all along?\n \nreply",
      "This is it. This is all I\u2019ve wanted in CSS for the last decade. In fact, I just wanted basic mixins without function-like behavior, but this gets me there.The comments here indicate that the article doesn\u2019t do much to explain what this does or why you\u2019d want it, but basically this gives you a way to reuse blocks of styles without needing to resort to e.g. utility classes or other hacks that get around specificity issues. The syntax doesn\u2019t help explain that.Shame about the syntax, but I\u2019m used to it at this point.\n \nreply",
      "Why stop there? Why not add interfaces, OO and design patterns while we're at it? Then CSS will be a \"real\" language.\n \nreply",
      "No worries, the web is already went wrong from the original purpose. Google is outdated itself. Better they update their own blog spot site layouts/functions before touching the web.\n \nreply",
      "This feels like a really bad idea, I hope it doesn't make it into the browser. CSS Houdini would be a better path to take.\n \nreply",
      "Today on \"everything that's wrong with modern web and more\"\n \nreply"
    ],
    "link": "https://www.bram.us/2025/02/09/css-custom-functions-teaser/",
    "first_paragraph": ""
  },
  {
    "title": "The Pentium contains a complicated circuit to multiply by three (righto.com)",
    "points": 188,
    "submitter": "Tomte",
    "submit_time": "2025-03-02T18:04:35 1740938675",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=43233143",
    "comments": [
      "\"This \u00d73 multiplier contains roughly 9000 transistors, a bit more than an entire Z80 microprocessor (1976). Keep in mind that the \u00d73 multiplier is a small part of the floating-point multiplier, which is part of the floating-point unit in the Pentium. Thus, this small piece of a feature is more complicated than an entire microprocessor from 17 years earlier, illustrating the incredible growth in processor complexity.\"That's the pace of performance growth that lead software to become bloated today; next year's performance improvements would cover up most of the sins of failure to think critically about algorithms and data flow context / locality.Today (as far as I've read) we're at the practical limit for what's reasonable to do with silicon semiconductor technology and our present understanding of physics.  The pendulum needs to swing the other direction; it's time for computers to work smarter not harder.\n \nreply",
      "> Today (as far as I've read) we're at the practical limit for what's reasonable to do with silicon semiconductor technology and our present understanding of physicsWe\u2019ve been at that limit for decades.\n \nreply",
      "The fabs propped up the corpse of Moore's Law by throwing mountains of cash at  expanding transistors into the third dimension: finFET, GAA, CFET, etc.  That has kept the party going a little while longer than it would have lasted but it's a one-time deal since are no more dimensions to expand into.\n \nreply",
      "\u2026but that\u2019s how it\u2019s always worked. Moore\u2019a law is dead, we\u2019re at the limit of everything, oh hey, Moore\u2019s lawn limps by again because someone did something clever.\n \nreply",
      "That's never how it worked. Moore's law was never dead. People are just endlessly confused about what Moore's law is.What ended was Dennard scaling around 2006. Roughly that frequency would keep going up as feature size went down. But because so many people are confused about what is what, you see a crappy muddled message.Moore's law has been going strong. It must end eventually, current predictions are that it will be in a decade or two.\n \nreply",
      "It's starting to get a bit old that whenever I see Moore's law mentioned, I'll usually also run into a spiel about how people have the wrong idea about what it actually refers to, and that it's holding up just fine. This is despite the gen-on-gen and year-on-year performance improvements of computer hardware very clearly tapering off in recent memory.Maybe debating what always-somehow-wrong law to cite should not be the focus? Like it's very clear to me that being technically correct about what Moore's law or the Dennard scaling refers to is leaps and bounds less important than the actual, practical computing performance trends that have been observable in the market.\n \nreply",
      "What we see in the market is caused by software bloat. Chips are gaining performance faster than ever in absolute terms.I think Moore\u2019s law should be avoided altogether when discussing progress in this area, because it\u2019s hard to understand the effects of doubling intuitively. Rice grains on chessboards and all that.One might think \u201dMoore\u2019s law is slowing down\u201d means progress was faster before and slower now, when it is in fact completely opposite.If you consider the 20 years between the intel 286 and the pentium 3, transistor count went from about 150 thousand to 10 million.Today (using the ryzen 5950 and 7950 as examples), we got 5 Billion more transistors in just 2 years.So in 2 years we added 500 times more transistors to our cpus than the first 20 years of \u201cprime Moore\u2019s law\u201d did.This enormous acceleration of progress is increasingly unnoticed due to even faster increases in software bloat, and the fact that most users aren\u2019t doing things with their computers where they can notice any improvements in performance.\n \nreply",
      "> Chips are gaining performance faster than ever in absolute terms.But this is not what I as a consumer end up seeing at all. Consider the RTX 5090. Gen-on-gen (so, compared to the 4090), for 20-30% more money, using 20-30% more power, you get 20-30% more raster performance. Meaning the generational improvement is 0, software nonwithstanding.\n \nreply",
      "It is ultimately a market effect, the technical specifics are not really important and are even conflated by industry insiders. See my sibling comment.\n \nreply",
      "Moore's law ends when the whole universe is a computer (which it already is).https://hasler.ece.gatech.edu/Published_papers/Technology_ov...Some view it as a doubling every 18 months, or a cost per transistor (this has gone up with the smallest nodes).It is roughly an exponential curve in the number of transistors we can use to make a \"thing\" with.It is both a capability (can we make things of a certain number of transistors) and is it economically viable  to build things of that size.You could stay at the current node size and halve the cost of that wafer every 18 months and you would still be on the same curve. But it is easier in a our economic system to decrease the node size, keeping the rest of the fixed wafer costs the same and get 2x or 4x the density on the same lines.If I get nerd sniped, I'd find the two video presentations one by Krste and another by Jim Keller where they unambiguously explain Dennard Scaling and Moore's Law in a way that is congruent with what I just said.\n \nreply"
    ],
    "link": "https://www.righto.com/2025/03/pentium-multiplier-adder-reverse-engineered.html",
    "first_paragraph": ""
  },
  {
    "title": "ACCESS.bus: The Forgotten USB Competitor (tedium.co)",
    "points": 25,
    "submitter": "PaulHoule",
    "submit_time": "2025-03-02T23:21:52 1740957712",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43236370",
    "comments": [
      "VGA/DVI/HDMI ports have an I2C interface (though DP tunnels I2C over AUX), which is normally used to read EDID information from monitors and control brightness, but on Linux (not Windows) you can control it as a general-purpose I2C bus, dump and even rewrite EEPROMs placed on the monitor bus. In theory you could even hook up a Nunchuk or Classic Controller to a display output (with level shifters if you want to run the Nunchuk at 5V off a 3.3V bus), and write a Linux driver to communicate with the peripheral and expose it as a game controller.\n \nreply",
      "The I2C part is something of an implementation detail -- it's only _really_ guaranteed to work as an EEPROM interface. It's usable on a lot of platforms, but again, not a guarantee.\n \nreply",
      "I2C is also extremely common for low-speed peripheral buses in embedded hardware (including computers) - some common applications are:- Small EEPROMs, often used for configuration data or small firmware blobs- MEMS sensors (accelerometers, gyroscopes, etc)- Small LCD/OLED displays (e.g. 128x64)- Configuration ports on devices which use other busses for bulk data (e.g. display drivers, audio codecs, etc).\n \nreply"
    ],
    "link": "https://tedium.co/2025/02/17/access-bus-i2c-usb-competitor-history/",
    "first_paragraph": ""
  },
  {
    "title": "API design note: Beware of adding an \"Other\" enum value (microsoft.com)",
    "points": 103,
    "submitter": "luu",
    "submit_time": "2025-02-27T10:47:31 1740653251",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=43193160",
    "comments": [
      "Rust has the \"non_exhaustive\" attribute that lets you declare that an enum might get more fields in the future. In practice that means that when you match on an enum value, you have to add a default case. It's like a \"other\" field in the enum except you can't reference it directly, you use a default case.IIRC a secret 'other' field (or '__non_exhaustive' or something) is actually how we did thing before non_exhaustive was introduced.\n \nreply",
      "Note that the stance of the OP here is broadly in agreement with what Rust does. His main objection is this:> The word \u201cother\u201d means \u201cnot mentioned elsewhere\u201d, so the presence of an Other logically implies that the enumeration is exhaustive.In Rust, because all enums are exhaustive by default and exhaustive matching is enforced by the compiler, there is no risk of this sort of confusion. And then the fact that his proposed solution is:> Just document that the enumeration is open-endedThe non_exhaustive attribute is effectively compiler-enforced documentation; users now cannot forget to treat the enum as open-ended.Of course, adding non_exhaustive to Rust was not without its own detractors; it usage for any given enum fundamentally means shifting power away from library consumers (who lose the ability to guarantee exhaustive matching) and towards library authors (who gain the ability to evolve their API without causing guaranteed compilation errors in all of their users (which some users desire!)). As such, the guidance is that it should be used sparingly, mostly for things like error types. But that's an argument against open-ended enums in general, not against the mechanisms we use to achieve those (which, as you say, was already possible in Rust via hacks).\n \nreply",
      "Maybe there should be a compiler option or function to assert that a match is exhaustive. If the match does not handle a defined case, it blows up.\n \nreply",
      "Rust already asserts that a match is exhaustive at compile time - if you don't include a branch for each option, it will fail to compile. This extends to integer range matching and string matching as well.It's just that with #[non_exhaustive], you must specify a default branch (`_ => { .. }`), even if you've already explicitly matched on all the values. The idea being that you've written code which matches on all the values which exist right now, but the library author is free to add new variants without breaking your code - since it's now your responsibility as a user of the library to handle the default case.\n \nreply",
      "Library users can force a compile error when new variants get added, using a lint from rustc. It's \"allow\" by default, so it's opt-in.https://doc.rust-lang.org/rustc/lints/listing/allowed-by-def...\n \nreply",
      "There is currently a missing middle ground in stable Rust, which is to lint on a missing variant rather than fail compilation. There's an unstable option for it, but it would be very useful for non-exhaustive enums where consumers care about matching against every known variant.You can practically use it today by gating on a nightly-only cfg flag. See https://github.com/guppy-rs/guppy/blob/fa61210b67bea233de52c... and https://github.com/guppy-rs/guppy/blob/fa61210b67bea233de52c...\n \nreply",
      "Couldn't clippy do that for you?\n \nreply",
      "Not at the moment. The unstable lint is implemented in rustc directly, not in clippy, though I guess it could move to clippy in the future.\n \nreply",
      "This is why language syntax is so important.Swift allows a \u2018default\u2019 enum case which is similar to other but you should use it with caution.It\u2019s better to not use it unless you\u2019re 110% sure that there will not be additional enums added in the future.Otherwise, in Swift when you add an additional enum case, the code where you use the enum will not work unless you handle each enum occurrence at it\u2019s respective call site.\n \nreply",
      "The better solution is to have two different \u201cdefault\u201d cases in the language, one that expresses handling \u201cfuture\u201d values (values that aren\u2019t currently defined), and one that expresses \u201cthe rest of the currently defined values\u201d. The \u201cfuture\u201d case wouldn\u2019t be considered for exhaustiveness checks.\n \nreply"
    ],
    "link": "https://devblogs.microsoft.com/oldnewthing/20250217-00/?p=110873",
    "first_paragraph": "Consider the following API:The idea here is that Widgets come in three flavors today, but we might add new flavors in the future, so we add an Other value to cover any future flavors.This is a problem.Suppose we do indeed add a new flavor Mint in the next version.What flavor should you report if somebody calls Get\u00adWidget\u00adFlavor and the widget is mint?If you return WidgetFlavor::Mint, then this will confuse code written with the Version\u00a01 API, because they expected to get Other for anything that isn\u2019t vanilla, chocolate, or strawberry. The word \u201cother\u201d means \u201cnot mentioned elsewhere\u201d, so the presence of an Other logically implies that the enumeration is exhaustive.On the other hand, you obviously should return WidgetFlavor::Mint because that\u2019s why you added the value to the enum in the first place!My recommendation is not to have an Other at all. Just document that the enumeration is open-ended, and programs should treat any unrecognized values as if they were \u201cOther\u201d. Any code that use"
  },
  {
    "title": "Geothermal power is a climate moon shot beneath our feet (newyorker.com)",
    "points": 169,
    "submitter": "pseudolus",
    "submit_time": "2025-03-02T19:33:21 1740944001",
    "num_comments": 164,
    "comments_url": "https://news.ycombinator.com/item?id=43234089",
    "comments": [
      "https://archive.ph/mkwrR",
      "2008 article on deep geothermal power plant.[1]\n2016 article on shutdown of plant.[2] \"The technology worked but unfortunately the cost of implementing the technology and also the cost of delivering the electricity that was produced to a market was just greater than the revenue stream that we could create.\"There's a group called DEEP which is trying to combine deep geothermal with fracking technology, to get better heat transfer. This creates small earthquakes as a side effect. They're working on that.[3]A startup called FERVO is still trying.[4]Shallow geothermal for building heat works fine, but it takes a lot of drilling just to get some heat.So far, nobody seems to have a profitable deep geothermal power operation.[1] https://e360.yale.edu/features/deep_geothermal_the_untapped_...[2] https://www.abc.net.au/news/2016-08-30/geothermal-power-plan...[3] http://deepgeothermal.org/home/[4] https://fervoenergy.com/\n \nreply",
      "Fervo isn't just trying, they are succeeding in bringing the drilling advances used in fracking, along with other innovation to get through the harder rocks typically encountered when not drilling for fossil fuels, to deliver dispatchable and storable energy. It's actually much better quality of power plant than nuclear because it can be scaled up and down throughout the day economically, whereas nuclear becomes even more uneconomic if it is forced to match the needs of the grid, and the reactors typically require far different designs than what is usually built (France has done a bit with this).I would bet on geothermal over nuclear in a second for future electricity generation. Its so much more promising, has a tech curve, and has far more innovation and advanced tech adoption.\n \nreply",
      ">  It's actually much better quality of power plant than nuclear because it can be scaled up and down throughout the day economically...It's not that nuclear reactors can't be built to vary their output. It's that nuclear power is almost all fixed cost. If the average power level over a year is 50%, the power cost doubles. Geothermal has similar economics.\n \nreply",
      "Not quite, with geothermal the storage is built into the system by simply limiting the intake, which builds pressure and can shift energy production throughout the day.The cost of enhanced geothermal is roughly the exact same cost as nuclear today (if you exclude the very high cost of failed build attempts for nuclear), and it shares similar economics of a very very low OpEx to CapEx ratio. However the economics differ massively in that enhanced geothermal is getting cheaper as we build more, but nuclear tends to get more expensive as we build more. Geothermal is a technology, nuclear is a monument.\n \nreply",
      "> Not quite \u2026\nThe cost of enhanced geothermal is roughly the exact same cost as nuclear \u2026 shares similar economics of a very very low OpEx to CapEx ratio.It can\u2019t be both not quire and the same.All else being equal, a five billion dollar geothermal plant running at 50% has the same problem as a five billion dollar nuclear plant running at 50%: where\u2019s my profit?Sure, load following is trivial with geothermal, but nuclear generally isn\u2019t trying to compete in that space, so we can discount the difference there.\n \nreply",
      "Unlike nuclear, that time running at 50% isn't thrown away capital expense, it is merely delayed power output that can be utilized with slightly higher turbine capacity, which is the cheaper part of the capex, and would be needed for higher power output anyway.For nuclear, adding thermal storage for time shifting would be the most equivalent to what's happening with geothermal storage, but with geothermal there's no additional capex or engineering needed.\n \nreply",
      "Geothermal isn't cheap. Trimming those fixed costs means siting on fault lines/earthquakes and higher opex (insurance).Fervo/Google got dogged for announcing their plant in UT because they avoided disclosures about the capacity [0]. It's more of a very small scale pilot of a couple MWs, but they buried key facts about the project assumedly on purpose due to lack of significance.[0] https://blog.google/outreach-initiatives/sustainability/goog...\n \nreply",
      "Fervo's initial demonstration project was next to an existing power plant in Nevada which previously failed to produce at it's stated capacity over time (Battle Mountain) so they were able to tie in extra MWt capacity to an existing ORC turbine.  Fervo's technology has to be located somewhat near existing traditional hydrothermal geothermal resources because it's the convection along an exiting fault for hundreds of thousands of years that produces an above background thermal gradient near enough to the surface for it to be economical.  That is true for their demonstration area in Utah which is located near the existing Blundel geothermal power plant in Milford Utah.\n \nreply",
      "Sure. Exposing these situational constraints and free benefits (third-party sunk costs) aligns with my stance.I don't agree with the above comment:> Fervo isn't just trying, they are succeeding\n \nreply"
    ],
    "link": "https://www.newyorker.com/news/the-lede/geothermal-power-is-a-climate-moon-shot-beneath-our-feet",
    "first_paragraph": "North Milford Valley, in western Utah, is home to dormant volcanoes, subterranean lava deposits, and smatterings of obsidian\u2014black volcanic glass\u2014that Paiute peoples once collected for arrowheads and jewelry. Scalding groundwater still bubbles to the surface in places. In such a landscape, you remember that the planet\u2019s hard exterior, where we spend our entire lives, is so thin that we call it a crust. Its superheated interior, meanwhile, burns with an estimated forty-four trillion watts of power. Milford was once a lead-, silver-, and gold-mining town, but when I visited the area on a sunny spring morning a scientist named Joseph Moore was prospecting for something else: heat.Heat mined from underground is called geothermal\u2014\u201cearth heat,\u201d in ancient Greek\u2014and can be used to produce steam, spin a turbine, and generate electricity. Until recently, humans have tended to harvest small quantities in the rare places where it surfaces, such as hot springs. Moore\u2019s mission, as a geologist at t"
  },
  {
    "title": "Schools reviving shop class (wsj.com)",
    "points": 118,
    "submitter": "bookofjoe",
    "submit_time": "2025-03-02T16:32:13 1740933133",
    "num_comments": 75,
    "comments_url": "https://news.ycombinator.com/item?id=43232087",
    "comments": [
      "I was very fortunate to be in middle school (ages 11 - 13) in the late 60s when shop classes were still going strong. Here's what I recall of our curriculum:6th grade: industrial drawing, hand tools, shop safety, home maintenance: replacing windows, wiring bulbs, switches and outlets, faucet installations. Basic fabrication with plastic, hammered metal forming and band sawing wood.7th & 8th grade: Metal: forge, lathe, welding (electric arc & acetylene), sheet metal (cutting, bending, punching, riveting, soldering) Wood: turning on lathe, table sawing, planing, routing, laminating, veneering, clamping, etcIn high school, all of the above plus architectural drawing, project management, metal machining, and fiberglass (mold design, making and part-making). Student projects included dune buggy car bodies, boats, water skis, furniture and all the usual (cutting boards, knife blocks, spice racks, etc.)In today's world, parents (and lawyers) might find it unsafe for boys (very few girls elected to take these classes) but in seven years of shop, I only recall one serious accident involving the loss of a finger tip.I went on to college major in Industrial Design and business then spent a career designing and producing projects for major consumer product company clients.\n \nreply",
      "The best advice I ever got (after my Kindergarten teacher telling me, \"Now young man, you should _never_ pass up the chance to go to the bathroom.\") was my shop teacher advising:>Before hitting the switch on a power tool, slowly count to 10 under your breath to yourself on your fingers, visualizing all the forces involved and planning out the entirety of your movement and how you will be moving the stock/tool, and considering what might go wrong and the results thereof and what will protect you (all guards should be in place and all suitable PPE worn) or where you should be positioned so as to avoid any potential projectile, reminding yourself that you want to be able to repeat that count in the same way when the tool is switched off.Sawstop wouldn't have a business model if all tablesaw accidents were tried by a jury of shop teachers.\n \nreply",
      "I don't get that advice from the kindergarten teacher. Can you explain please?\n \nreply",
      "Think before you act.\n \nreply",
      "Take your by own advice ;)Don\u2019t pass up a chance to pee is the advice in question.Which I\u2019d equate to; Better safe than sorry\n \nreply",
      "I think the return on investment is underplayed, it's not just what skills you graduate with, it's whether you find going to school at all rewarding. I was bored stiff in most of my classes, but having marching band to look forward to and the reward of traveling to different cities on the band bus kept me from completely checking out of school.Maybe another aspect missing from schools lacking shop is the sense that you're trustworthy enough to put in front of a potentially lethal machine, a little bit of self worth goes a long way.\n \nreply",
      "> Maybe another aspect missing from schools lacking shop is the sense that you're trustworthy enough to put in front of a potentially lethal machine, a little bit of self worth goes a long way.I have the distinct memory of this thought crossing my mind during orientation in shop classes. The instructor gave us the rundown of how to be safe and then he actually let us use cool machines without hovering around us every second of the period! The trust involved in that exercise was immense, and even kids who were the class clowns in other classes rose to the occasion and were responsible in shop class.I can only imagine how important this kind of experience would be for today's kids of the helicopter generation, many of whom would be receiving this type of trust to handle danger like an adult for perhaps the first time in their lives.\n \nreply",
      "This is why Sloyd woodworking is taught in northern European countries:>Students may never pick up a tool again, but they will forever have the knowledge of how to make and evaluate things with your hand and your eye and appreciate the labor of others.https://rainfordrestorations.com/category/woodworking-techni...\n \nreply",
      "As someone who was shoved and occasionally bullied while operating machines like belt saws... I'm not sure it was worth it.Perhaps with stop-saw like inventions it could be safer, if the patents ever expire so schools could actually afford them.\n \nreply",
      "All it takes is installing cameras and if anyone is caught up doing stupid shit the shoptime is over for them, permanently if it's anything serious.I remember one clown kid in my class back in the days put a hottish drillbit to another's kid neck acting like a cool spy or something like that (we were 14 years old, luckily got only a mild burn which healed quickly). The teacher punched him in the face, probably not with full force but it was not a soft slap either, and banned him from the shop for some time. No incidents after that.\n \nreply"
    ],
    "link": "https://www.wsj.com/us-news/education/high-school-shop-class-revival-24d7a525",
    "first_paragraph": ""
  },
  {
    "title": "Matt's Script Archive (1995) (scriptarchive.com)",
    "points": 62,
    "submitter": "huang_chung",
    "submit_time": "2025-03-02T20:06:41 1740946001",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=43234471",
    "comments": [
      "Another legendary throwback from that era:https://www.jmarshall.com/tools/cgiproxy/\n \nreply",
      "30 years since I posted that first script back in high school! Thanks for all the love (and some hate) since then. :) Let me know if you have any questions, I'll try to answer.\n \nreply",
      "Wow what a small world! When I was learning Perl in the early 2000s, I learned in part by copying and tweaking your scripts.Thanks for sharing these into the world. I found them a huge help.\n \nreply",
      "In 1998 the author of the biggest German HTML/CSS/JS tutorial installed WWWBoard to create a forum. In the 2000s it must have been the biggest web development forum in German-speaking countries. Today it is smaller, but still exists.Not on WWWBoard today, sorry. According to my memory the software lineage was something like WWWBoard \u2192 A custom selfwritten forum in Perl \u2192 A big rewrite into C, because server resources were spare for a while \u2192 Later a rewrite in Ruby on Rails \u2192 Today in Elixir.But the sensibility and the lineage of WWWBoard stayed with all the rewrites, as did the archive since 1998. The current forum is still by default threaded, in a way it gave it its identity in a world of bulletin boards.(I spend a lot of time there in the 2000s. Thanks!)\n \nreply",
      "That's interesting, thanks for sharing!\n \nreply",
      "I'm amazed that you created an HN account in 2014 but that this is your first comment. How did you resist the temptation to comment for so many years?\n \nreply",
      "I read the site (via hckrnews.com, prefer chronological ordering) nearly every day, and have for a long time.You may not be surprised at what being known for some of the worst code on the internet does for one's willingness to post things under one's own name. ;) That said, I have a different, older account that I have occasionally posted under when I can't resist temptation.\n \nreply",
      "I want to thank you for Matt's Script Archive.  I never actually used it, and I often had to help novice Perl programmers who'd gotten bad ideas from it and were writing terrible code, but in my book that's far better than if they had found the world of programming too forbidding to approach.  You're responsible for opening the world of programming to many people, and I appreciate that.\n \nreply",
      "heh, thanks! :) To be fair, the feedback has always been more positive than negative.\n \nreply",
      "I asked dang once and he said like 1% of visitors comment.\n \nreply"
    ],
    "link": "https://www.scriptarchive.com/",
    "first_paragraph": ""
  },
  {
    "title": "Kaspersky exposes hidden malware on GitHub stealing personal data (kaspersky.com)",
    "points": 31,
    "submitter": "01-_-",
    "submit_time": "2025-02-28T15:06:50 1740755210",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.kaspersky.com/about/press-releases/kaspersky-exposes-hidden-malware-on-github-stealing-personal-data-and-485000-in-bitcoin",
    "first_paragraph": "Kaspersky Global Research & Analysis Team (GReAT) discovered hundreds of open source repositories with multistaged malware targeting gamers and cryptoinvestors within a new campaign that was dubbed by Kaspersky as GitVenom. The infected projects include an automation instrument for interacting with Instagram accounts, a Telegram bot that enables the remote management of Bitcoin wallets and a crack tool to play the Valorant game. All of this alleged project functionality was fake, and cybercriminals behind the campaign stole personal and banking data and hijacked cryptowallet addresses from the clipboard. As a result of the malicious activity cybercriminals were able to steal 5 Bitcoins (around $485,000 at the time of investigation). Kaspersky detected the use of the infected repositories worldwide, with most cases in Brazil, Turkiye, and Russia.These repositories have\n        been stored on GitHub, a platform that allows developers to manage and share\n        their code, for several ye"
  },
  {
    "title": "Turning my ESP32 into a DNS sinkhole to fight doomscrolling (amanvir.com)",
    "points": 58,
    "submitter": "venusgirdle",
    "submit_time": "2025-02-28T10:39:01 1740739141",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=43204091",
    "comments": [
      "I deleted social media apps (IG, TikTok, Reddit, etc.) from my phone a few weeks ago (about two weeks ago perhaps).The only one that I wish could be deleted is YouTube (because of YT Shorts), which comes with every Android. For now, I've restricted my usage using the App Timers feature.WhatsApp Statuses sadly cannot be disabled. I wish I could fully delete WhatsApp for good[0]. Telegram Statuses feel wholesome. I admit I have a pet peeve with how Meta engineered WhatsApp after purchase.I'm not feeling any withdrawal symptoms of any sort. If everything continues to be like this, I'm looking forward to finishing 2025 like this. I've been looking at dumb phones, E-Ink ones seem promising, but not yet quite there. Maybe also drop in a dumb Casio watch.I did not delete my social media accounts, as I don't want anyone grabbing my public handles and wreaking havoc. I will always reserve these, even for leaving them empty.I'm fine with HN being my social media.--[0]: https://www.ivanmontilla.com/blog/goodbye-whatsapp\n \nreply",
      "I was never addicted to social media, but I used to be terribly addicted to YouTube. I tried various blockers, and none of that worked. In the end I told myself I'm going to quit for 1 month and see. It's a long enough period, where you can't just distract yourself with other things, but it's not long enough to feel like you're losing something. Not to preach, but it worked for me, and I've applied it successfuly in other places like eating habits. You commit to 1 thing at a time, and see if it makes your life better.\n \nreply",
      "> and I've applied it successfully in other placesThere is a positive effect to quitting without too many crutches or aids. Not so much that you learn how to do it, but that you realise that it can be done, it's not that bad and it will make your life better.\n \nreply",
      "I agree. If you need to set something up (like a DNS sinkhole) to trick yourself (and you know how to disable it to get back to scrolling), it'll take actual willpower to truly stop.\n \nreply",
      "> For the uninitiated, doomscrolling is essentially when one passively scrolls through endless feeds of content on social media until eventually stopping to realize that they've wasted the last five minutes of their life doing something entirely unproductive.This is wrong: https://en.wikipedia.org/wiki/Doomscrolling\"Doomscrolling or doomsurfing is the act of spending an excessive amount of time reading large quantities of news, particularly negative news, on the web and social media.\"In other words, doomscrolling is about scrolling the bad news, specifically. Like covid-19 or war.\n \nreply",
      "If you read the 2nd paragraph of the very article you cited, you'll also see it says:  \"Doomscrolling can also be defined as the excessive consumption of short-form videos or social media content for an excessive period of time without stopping.\"\n \nreply",
      "How's gonna work if the request is already cached or when using DNS over https?\n \nreply",
      "It won\u2019t. Especially when you use private relay on an iPhone, it won\u2019t use local DNS (except if the requested domain isn\u2019t found, it can probably still route local domain names?).\n \nreply",
      "Neat idea, but my takeaway is I had no idea that DNS also runs on UDP/53..   I always thought it was TCP only!  #TILThe author cites it as performance reasons, but at this scale, even the uplink to cloudflare, would be negligible, no?\n \nreply",
      "With 'normal' DNS, UDP with the default and TCP is used if the packet size becomes too large. There are other TCP-only variants such as DoT (DNS over TLS) and DoH (DNS over HTTPS).I don't think the performance would matter much with some basic caching (or even just OS-level caching), but there is limited memory in an ESP so maybe that is it. I have never noticed issues with DoT and DoH which are theoretically much heavier protocols.\n \nreply"
    ],
    "link": "https://amanvir.com/blog/turning-my-esp32-into-a-dns-sinkhole",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Prompting LLMs in Bash scripts (elijahpotter.dev)",
    "points": 21,
    "submitter": "chilipepperhott",
    "submit_time": "2025-02-27T19:46:55 1740685615",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://elijahpotter.dev/articles/prompting_large_language_models_in_bash_scripts",
    "first_paragraph": ""
  },
  {
    "title": "Why do we have both CSRF protection and CORS? (smagin.fyi)",
    "points": 96,
    "submitter": "smagin",
    "submit_time": "2025-03-02T15:32:46 1740929566",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=43231411",
    "comments": [
      "If I may attempt to summarize:CORS is a mechanism for servers to explicitly tell browsers which cross-origin requests can read responses. By default, browsers block cross-origin scripts from reading responses. Unless explicitly permitted, the response cannot be read by the requesting domain.For example, a script on evil.com might send a request to bank.com/transactions to try and read the victim's transaction history. The browser allows the request to reach bank.com, but blocks evil.com from reading the response.CSRF protection prevents malicious cross-origin requests from performing unauthorized actions on behalf of an authenticated user. If a script on evil.com sends a request to perform actions on bank.com (e.g., transferring money by requesting bank.com/transfer?from=victim&to=hacker), the server-side CSRF protection at bank.com rejects it (likely because the request because it doesn\u2019t contains a secret CSRF token).In other words, CSRF protection is about write protection, preventing unauthorized cross-origin actions, while CORS is about read protection, controlling who can read cross-origin responses.\n \nreply",
      "> In other words, CSRF protection is about write protection, preventing unauthorized cross-origin actions, while CORS is about read protection, controlling who can read cross-origin responses.I apologize for the length of the reply, I didn't have time to write a short one.  But to sum up, CSRF is about writes, while CORS protects both reads and writes, and they're two very different things.CSRF is a sort of \"vulnerability\", but really just a fact of the open web: that any site can create a form that POSTs any data to any other site.  If you're on forum.evil.com and click the \"reply\" button (or anything at all), that could instead POST a transfer request to your.bank.com, and if you happen to be logged in, it'll happen with your currently authenticated session.  When the bank implements CSRF protection, it ensures that a known token on the page (sometimes communicated through headers instead) is sent with the transfer.  If that token isn't present, or doesn't match what's expected, reject the request.  It ensures that only forms generated by bank.com will have any effect, and it works because evil.com can't use JS to read the content of the page from bank.com due to cross-origin restrictions.CORS on the other hand is an escape hatch from a different cross-origin security mechanism that browsers enable by default: that a script on foo.com cannot make requests to bar.com except for \"simple\" requests (the definition of which is anything but simple; just assume any request that can do anything interesting is blocked).  CORS is a way for bar.com to declare with a header that foo.com is in fact allowed to make such requests, and to drop the normal cross-origin blocking that would occur otherwise.  You only have to use CORS to remove restrictions: if you do nothing, maximum security is the default.  It's also strictly a browser technology: non-browser user agents do not need or use CORS and can call any API anytime.Fun fact: you don't need CSRF protection at all if your API is strictly JSON-based, or uses any content type that isn't one of the built-in form enclosure types.  The Powers That Be are talking about adding a json enclosure type to forms, but submitting it would be subject to cross-origin restrictions, same as it is with JS.\n \nreply",
      "> Fun fact: you don't need CSRF protection at all if your API is strictly JSON-based, or uses any content type that isn't one of the built-in form enclosure types. The Powers That Be are talking about adding a json enclosure type to forms, but submitting it would be subject to cross-origin restrictions, same as it is with JS.AFAIK, this is not totally accurate because the internet is a messy place. For example, the OAuth authorization code grant flow blesses passing the authorization code to the relying party (RP) in a GET request as a query parameter. The RP must protect against CSRF when receiving the authorization code.\n \nreply",
      "Ah yes, good catch.  That's what the `state` parameter is about, right?  But I'll weasel out and say that lack of a content type (being a GET) is one of the built-in types too ;)\n \nreply",
      "> It's a nice way to make an API \"public\", or would be if CORS supported a goddam wildcard for the host.I don't get what you mean. Access-Control-Allow-Origin supports a wildcard.  https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Ac...\n \nreply",
      "Also, nothing prevents you from checking the host server-side according to arbitrary logic and putting it into the CORS header dynamically.\n \nreply",
      "Yah you saw that before I edited it out, I realized that gripe was actually about the behavior of AWS API Gateway rather than CORS itself.  It hates the wildcard, or something, I can't even remember exactly what the issue was.  Thus did I zap it.\n \nreply",
      "To add to that:CORS is implemented by browsers based on standardized HTTP headers. It\u2019s a web-standard browser-level mechanism.CSRF protection is implemented server-side (plus parts of the client-side code) based on tokens and/or custom headers. It\u2019s an application-specific mechanism that the browser is agnostic about.\n \nreply",
      "Some additional color:CORS today is just an annoying artifact of a poorly conceived idea about domain names somehow being a meaningful security boundary.  It never amounted to anything more than a server asking the client not to do something with no mechanism to force the client to comply and no direct way for the server to tell if the client is complying.   It has never offered any security value, workarounds were developed before it even became a settled standard.  It's so much more likely to prevent legitimate use than protect against illegitimate use that browsers typically include a way to turn it off.With CSRF the idea is that the server wants to be able verify that a request from a client is one it invited (most commonly that a POST comes from a form that it served in an earlier GET).  It's entirely up to the server to design the mechanism for that, the client typically has no idea its happening (it's just feeding back to the server on a later request something it got from the server on a previous request).  Also notable is despite the \"cross-site\" part of the name it doesn't really have any direct relationship to \"sites\" or domains, servers can and do use the exact same mechanisms  to detect or prevent issues like accidentally submitting the same form twice.\n \nreply",
      "Regarding CSRF - how would I be authenticated to do actions on bank.com when I'm on evil.com?It seems like the problem is at the level of login information somehow crossing domain boundaries?What stops a script on evil.com from going to bank.com to get a CSRF token and then including that in their evil request?\n \nreply"
    ],
    "link": "https://smagin.fyi/posts/cross-site-requests/",
    "first_paragraph": "\n\n                about\n            \n\n\n                within means\n            \nWhy do we have both CSRF protection and CORS?\nMarch 1, 2025\nHello, Internet. I thought about cross-site requests and realised we have both CSRF protection and CORS and it doesn\u2019t make sense from the first glance. It does generally, but I need a thousand words to make it so.CSRF stands for Cross-Site Request Forgery. It was rather popular in the earlier internet but now it\u2019s almost a non-issue thanks to standard prevention mechanisms built into most of popular web frameworks. The forgery is to make user click on a form that will send a cross-site request. The protection is to check that the request didn\u2019t come from a third-party site.CORS stands for Cross-Origin Resource Sharing. It\u2019s a part of HTTP specification that describes how to permit certain cross-site requests. This includes preflight requests and response headers that state which origins are allowed to send requests.So, by default, are cross-origi"
  },
  {
    "title": "G\u00f6del's theorem debunks the most important AI myth \u2013 Roger Penrose [video] (youtube.com)",
    "points": 70,
    "submitter": "Lockal",
    "submit_time": "2025-03-02T18:31:33 1740940293",
    "num_comments": 144,
    "comments_url": "https://news.ycombinator.com/item?id=43233420",
    "comments": [
      "I'm really looking forward to the point where we can put 3d glasses on a person and give them a simulated reality that is indistinguishable from reality, but composed entirely of ML-driven identities.  We can already make photorealistic images on computers, produce convincing text, video, and audio, complex behavior, goal-seeking, etc, and one major trend in ML is combining all of those into models that could, in principle, run realtime inference.I don't worry about philosophical zombies, dualism, quantum conciousness, or anything like that.  I just want to get to the point past the uncanny valley- call it the spooky jungle- that cannot be distinguished from reality.\n \nreply",
      "I'm not sure about it makes sense to apply G\u00f6del's theorem to AI. Personally, I prefer to think about it in terms of basic computability theory:We think, that is a fact.Therefore, there is a function capable of transforming information into \"thinked information\", or what we usually call reasoning. We know that function exists, because we ourselves are an example of such function.Now, the question is: can we create a smaller function capable of performing the same feat?If we assume that that function is computable in the Turing sense then, kinda yes, there are an infinite number of turing machines that given enough time will be able to produce the expected results. Basically we need to find something between our own brain and the Kolmogorov complexity limit. That lower bound is not computable, but given that my cats understands when we are discussing to take them to the vet then... maybe we don't really need a full sized human brain for language understanding.We can run Turing machines ourselves, so we are at least Turing equivalent machines.Now, the question is: are we at most just Turing machines or something else? If we are something else, then our own CoT won't be computable, no matter how much scale we throw at it. But if we are then it is just matter of time until we can replicate ourselves.\n \nreply",
      "Many philosophical traditions which incorporate a meditation practice emphasize that your consciousness is distinct from the contents of your thoughts. Meditation (even practiced casually) can provide a direct experience of this.When it comes to the various kinds of thought-processes that humans engage in (linguistic thinking, logic, math, etc) I agree that you can describe things in terms of functions that have definite inputs and outputs. So human thinking is probably computable, and I think that LLMs can be said to be \u201dthink\u201d in ways that are analogous to what we do.But human consciousness produces an experience (the experience of being conscious) as opposed to some definite output. I do not think it is computable in the same way.I don\u2019t necessarily think that you need to subscribe to dualism or religious beliefs to explain consciousness - it seems entirely possible (maybe even likely) that what we experience as consciousness is some kind of illusory side-effect of biological processes as opposed to something autonomous and \u201creal\u201d.But I do think it\u2019s still important to maintain a distinction between \u201cthinking\u201d (computable, we do it, AIs do it as well) and \u201cconsciousness\u201d (we experience it, probably many animals experience it also, but it\u2019s orthogonal to the linguistic or logical reasoning processes that AIs are currently capable of).At some point this vague experience of awareness may be all that differentiates us from the machines, so we shouldn\u2019t dismiss it.\n \nreply",
      "> It's very difficult to find some way of defining rather precisely something we can do that we can say a computer will never be able to do. There are some things that people make up that say that, \"While it's doing it, will it feel good?\" or, \"While it's doing it, will it understand what it's doing?\" or some other abstraction. I rather feel that these are things like, \"While it's doing it, will it be able to scratch the lice out of it's hair?\" No, it hasn't got any hair nor lice to scratch from it, okay?> You've got to be careful when you say what the human does, if you add to the actual result of his effort some other things that you like, the appreciation of the aesthetic... then it gets harder and harder for the computer to do it because the human beings have a tendency to try to make sure that they can do something that no machine can do. Somehow it doesn't bother them anymore, it must have bothered them in earlier times, that machines are stronger physically than they are...- Feynmanhttps://www.youtube.com/watch?v=ipRvjS7q1DI\n \nreply",
      "What we have and AI don't are emotions. After all, that what animates us to survive and reproduce. Without emotions we can't classify and therefore store our experiences because there no reason to remember something which we are indifferent about. This includes everything not accessible by our senses. Our abilities are limited to what is needed for survival and reproduction because all the rest would consume our precious resources.\n \nreply",
      "We don\u2019t know that LLMs generating tokens for scenarios involving simulations of conscious don\u2019t already involve such experience. Certainly such threads of consciousness would currently be much less coherent and fleeting than the human experience, but I see no reason to simply ignore the possibility. To whatever degree it is even coherent to talk about the conscious experience of others than yourself (p-zombies and such), I expect that as AIs\u2019 long term coherency improves and AI minds become more tangible to us, people will settle into the same implicit assumption afforded to fellow humans that there is consciousness behind the cognition.\n \nreply",
      "The very tricky part then is to ask if the consciousness/phenomenological experience that you postulate still happens if, say, we were to compute the outputs of an LLM by hand\u2026 while difficult, if every single person on earth did one operation per second, plus some very complicated coordination and results gathering, we could probably predict a couple of tokens for an LLM at some moderate frequency\u2026 say, a couple of tokens a month? a week? A year? A decade? Regardless\u2026 would that consciousness still have an experience? Or is there some threshold of speed and coherence, or coloration that would be missing and result in failure for it to emerge?Impossible to answer.Btw I mostly think it\u2019s reasonable to think that there might be consciousness, phenomenology etc are possible in silicon, but it\u2019s tricky and unverifiable ofc.\n \nreply",
      "> would that consciousness still have an experience?If the original one did, then yes, of course. You're performing the exact same processing.Imagine if instead of an LLM the billions of people instead simulated a human brain. Would that human brain experience consciousness? Of course it would, otherwise they're not simulating the whole brain. The individual humans performing the simulation are now comparable to the individual neurons in a real brain. Similarly, in your scenario, the humans are just the computer hardware running the LLM. Apart from that it's the same LLM. Anything that the original LLM experiences, the simulated one does too, otherwise they're not simulating it fully.\n \nreply",
      "> I think that LLMs can be said to be \u201dthink\u201d in ways that are analogous to what we do. ... But human consciousness produces an experience (the experience of being conscious) as opposed to some definite output. I do not think it is computable in the same way.\"We've all been dancing around the basic issue: does Data have a soul?\" -- Captain Louvois. https://memory-alpha.fandom.com/wiki/The_Measure_Of_A_Man_(e...\n \nreply",
      "I for one (along with many thinkers) define intelligence as the extent to which an agent can solve a particular task. I choose the definition to separate it from issues involving consciousness.Both matter of course.\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=biUfMZ2dts8",
    "first_paragraph": ""
  },
  {
    "title": "Most IT companies fail to serve security.txt for RFC 9116 in 2025 (hartwork.org)",
    "points": 20,
    "submitter": "spyc",
    "submit_time": "2025-03-02T22:33:21 1740954801",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43235972",
    "comments": [
      "I really don\u2019t get why you would want to serve security.txt, it just invites an avalanche of automated spam.\n \nreply",
      "I serve this file for a fintech. If there is a legit vulnerability, I both want that report in my inbox for triage with as little friction as possible and I also want to be able to demonstrate that we made a best effort to receive that information from a good faith reporter. Is it work? Yes, of course, but that\u2019s part of the job (to defend the enterprise).\n \nreply",
      "Are these all IT companies? Mazda and Marantz certainly don't seem like they're IT companies.\n \nreply",
      "They all are shipping hardware with vulnerabilities.\n \nreply",
      "I\u2019m not really sure why the author made the limitation to \u201cIT Companies\u201d unless what they really mean is the IT organization within the companies. The security.txt seems like it should be utilized by any company that does business on the internet, much like having an abuse email address.\n \nreply",
      "If Uber or WeWork are tech companies, then I\u2019m sure people are willing to stretch meanings of other fields too\n \nreply",
      "I want to start off with that I do think the goal of this RFC is a laudable one, and anything that follows shouldn't be taken as a damnation of it. If you are on the fence if you should implement security.txt just do it.This article is a large nothing burger. \"I sampled 50 companies, most of which are on the internet because they have to be, and most didn't implement an IETF comment\". If these were mostly tech focused companies, or heck security companies, sure it would make sense to shame them, but if there is a vulnerability in Ford's website I would bet the impact is quite low. \nHell this is so poorly thought out I want to go try it on the top 100 websites by volume and maybe try and find a top 100 tech websites.\n \nreply"
    ],
    "link": "https://blog.hartwork.org/posts/companies-fail-to-serve-security-txt-rfc-9116/",
    "first_paragraph": "Free Software, Music, Chinese ChessI happen to maintain a public list of\ncompanies using libexpat in hardware,\nthough not complete by any means.\nLast time I tried mass-mailing companies about a security issue in April 2024.\nFinding the right contact for security was non-trivial and even failed in some cases.\nE.g. for Humax Digital I eventually gave up.It is needless to say that if your security contacts are too hard to find,\nthat says something about how urgently you want to fix security issues (or not).So I felt like re-checking how many of these 50 companies are serving\n/.well-known/security.txt (or the significantly less common /security.txt)\na la RFC 9116 in 2025.The sad answer is: 39 out of the 50 companies I tested do not, i.e. 78%.\nHere's who and where exactly I tested:If you work at a company that does not serve /.well-known/security.txt yet,\nplease fix it or share a link to https://securitytxt.org/\nwith a co-worker or management of yours so they can \u2014 thank you!\nSecurity\n"
  },
  {
    "title": "Imec demonstrates electrical yield for 20nm lines High NA EUV single patterning (imec-int.com)",
    "points": 18,
    "submitter": "pieterr",
    "submit_time": "2025-02-28T15:55:11 1740758111",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43207040",
    "comments": [
      "Aha, so \"2nm\" really means 20nm. Good to know.\n \nreply",
      "Generally the x um or y nm of a process refers to transistor dimensions (typically gate length), not metal. Minimum metal pitch is still a key dimension for the ability to build useful structures though, so advances like these are very useful.\n \nreply",
      "No, the gate length on most 5nm nodes is like 40nm or something. Since around 2008-ish, the \u201cprocess name\u201d and the size of any feature have rapidly diverged (even if you use some weird pointless metric like the size of a FinFET fin, nothing on 5nm measures 5nm).Ironically, prior to 2008 the process name was backwards the other way, for example 130nm process usually has something like 70nm gates.It\u2019s always really just been a marketing thing anyway, since the possible density of a given logic unit in a given manufacturers process will differ due to a huge number of factors.\n \nreply",
      "\"2nm node\" means \"one technology iteration after 4nm\". (Well, actually after 3nm, but let's not get even more into that nonsense)These numbers stopped having anything to do with the sizes of things a long time ago.\n \nreply",
      "It might be funny to use this as a software versioning scheme. (\"What do you mean the next version after v3 is 20A?\")\n \nreply"
    ],
    "link": "https://www.imec-int.com/en/press/imec-demonstrates-electrical-yield-20nm-pitch-metal-lines-obtained-high-na-euv-single",
    "first_paragraph": "Press releaseFirst electrical tests at 20nm pitch present a next milestone in validating the High NA extreme ultraviolet (EUV) patterning ecosystemLEUVEN (Belgium), February 24, 2025\u2014 This week at SPIE Advanced Lithography + Patterning, imec, a world-leading research and innovation hub in nanoelectronics and digital technologies, presents the first electrical test (e-test) results obtained on 20nm pitch metal line structures patterned after single-exposure High NA EUV lithography. Measurements on both serpentine and fork-fork metallized structures show good electrical yield, indicative of a low number of stochastic defects. The e-test results confirm the capability of the High NA EUV lithography scanner and its surrounding ecosystem to pattern lines/spaces at such a small dimension.In August 2024, imec was the first to present industry-relevant logic and DRAM structures patterned in a single High NA EUV lithography exposure step. As a next critical step, imec shows that metallized line"
  }
]