[
  {
    "title": "Open guide to equity compensation (github.com/jlevy)",
    "points": 253,
    "submitter": "mooreds",
    "submit_time": "2025-04-13T19:13:37 1744571617",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=43675126",
    "comments": [
      "As our 30 person startup has grown, I made a conscious decision to stop pitching stock options as a primary component of compensation.Which means the job offer still includes stock options, but during the job offer call we don\u2019t talk up the future value of the stock options. We don\u2019t create any expectation that the options will be worth anything.Upside from a founder perspective is we end up giving away less equity than we otherwise might. Downside from a founder perspective is you need up increase cash compensation to close the gap in some cases, where you might otherwise talk up the value of options.Main upside for the employee is they don\u2019t need to worry too much about stock options intricacies because they don\u2019t view them as a primary aspect of their compensation.In my experience, almost everyone prefers cash over startup stock options. And from an employee perspective, it\u2019s almost always the right decision to place very little value ($0) on the stock option component of your offer. The vast majority of cases stock options end up worthless.\n \nreply",
      "Even if the company has a successful exit lots of times the founders have different stock class than employees which allows them to cook the books in creative ways where employee stocks are devalued without affecting founder stocks.I personally went through a successful exit of a company where I was one of the early engineers and was privy to orchestrating the sale (working with potential buyers and consultants) and saw this happen.I now am granted stocks which are traded on the NYSE so nobody can cook the books without commiting securities fraud.\n \nreply",
      "One other trick I learned about and should warn others about - getting an offer for shares (an employee level %) where there is in fact no options pool and existing shares will be diluted for every new employee who joins the team. I got such an offer, and not only was this information not given to me until I asked about any events aside from funding rounds that would be dilutive, but it was presented as standard operating procedure.\n \nreply",
      ">getting an offer for shares (an employee level %) where there is in fact no options pool and existing shares will be diluted for every new employee who joins the teamHow's this different than if an option pool exists? The more people have options, the further the pie will be split up. Having an option pool or not doesn't change this.\n \nreply",
      "First, dilution should only be happening at funding events, not every time a new senior staff person is hired, and second the dilution should affect everyone equally\u2014 founders, execs, angels, VCs.It's super unfair to give an employee \"x shares\" that turn out on exit to be shares of a fixed pie that is different from the one the investors have their shares in.\n \nreply",
      "\"Cooking the books\" could mean many things but most people would interpret this as fraud. There are many exit scenarios that aren't fraud but rather stacks of preferential stock that get paid before common, who usually get paid last.What happened in your exit scenario?\n \nreply",
      "There's also just the case that a buyer is happy buying say 88% of the company and  having 12% (usually non-voting) shares lie with employees/former employees. Stock options are only really, truly worth anything if they IPO.\n \nreply",
      "Not since... I'm not sure the regulatory change, but if employees are able to sell back to the company or to private investors, resulting in cold hard cash in employee bank accounts, without the company going public, I'd say they are worth something. We can argue about how, without an IPO, the price isn't fairly decided upon, but having cold hard cash in the bank is nonetheless real.\n \nreply",
      "See my comment further down. Im not going to go into any more details than that as the details of the sale are not public.\n \nreply",
      "My read is that the poster felt that the accounting practices, which were likely legal and commonplace, violated implied contractual obligations.\n \nreply"
    ],
    "link": "https://github.com/jlevy/og-equity-compensation",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Stock options, RSUs, taxes \u2014 read the latest edition: www.holloway.com/ec\n\u2747\ufe0f This guide is now published on Holloway.\nRead it there for search, booksmarks/highlights, expert commentary, and PDF/EPUB download.Equity compensation is the practice of granting partial ownership in a company in\nexchange for work.\nIn its ideal form, equity compensation aligns the interests of individual employees with\nthe goals of the company they work for, which can yield dramatic results in team building,\ninnovation, and longevity of employment.\nEach of these contributes to the creation of value\u2014for a\ncompany, for its users and customers, and for the individuals who work to make it a\nsuccess.The ways equity can be granted as compensation\u2014including restricted\nstock, stock options, and restricted stock units\u2014are notoriously complex. Equity\ncompensation inv"
  },
  {
    "title": "Everything Wrong with MCP (sshh.io)",
    "points": 37,
    "submitter": "sshh12",
    "submit_time": "2025-04-13T23:53:35 1744588415",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43676771",
    "comments": [
      "I have read 30 MCP articles now and I still don\u2019t understand why we not just use API?\n \nreply",
      "I played around with MCP this weekend and I agree.  I just want to get a users X and then send X to my endpoint so I can do something with it.  I don't need any higher level abstraction than that.\n \nreply",
      "MCP is a dead end for chatbots. Building valuable workflows requires more than tool calling, most importantly, understanding the context of a conversation to adjust the tools dynamically.\n \nreply",
      "What does that have to do with MCP? Those sound like things you would build on a separate layer from MCP.\n \nreply",
      "Yeah, I don't feel comfortable downloading tiny server programs from random devs on the internet to give my LLM client apps extra \"tools\". I can LuLu or LittleSnitch regular apps but not these ones.\n \nreply",
      "isnt langchain doing the exact same thing? (sorry ai noob here)\n \nreply",
      "Langchain is one of many frameworks that implement the \"tool calling\" pattern, where LLM applications can request that a tool is run (eg \"search the web for X\" or \"execute this Python code\") and see the result of that.MCP is a standard for describing and exposing tools to LLM applications.So they're not the same category of thing. Langchain could implement aspects of the MCP specification, in fact it looks like they're doing that already: https://github.com/langchain-ai/langchain-mcp-adapters\n \nreply",
      "It's a common question!Related:\n> Tool-Calling - If you\u2019re like me, when you first saw MCP you were wondering \u201cisn\u2019t that just tool-calling?\u201d...Not everyone uses langchain nor does langchain cover some of the lower level aspects of actually connecting things up. MCP just helps standardize some of those details so any assistant/integration combo is compatible.Edit: +1 simonw above\n \nreply",
      "\"Authentication is tricky and so it was very fair that the designers chose not to include it in the first version of the protocol.\"No, it's not fair at all.\nYou can't add security afterwards like spreading icing on baked cake.\nIf you forgot to add sugar to the cake batter,\nthere's not enough buttercream in the world to fix it.\n \nreply",
      "I made a MCP server to access remote storage using any kind of protocols (S3, SFTP, FTP, .... ), and authentication was not a problem, you can check by yourself by pointing the mcp inspector to \"https://demo.filestash.app/sse\" and play around\n \nreply"
    ],
    "link": "https://blog.sshh.io/p/everything-wrong-with-mcp",
    "first_paragraph": ""
  },
  {
    "title": "NoProp: Training Neural Networks without Back-propagation or Forward-propagation (arxiv.org)",
    "points": 20,
    "submitter": "belleville",
    "submit_time": "2025-04-14T00:03:51 1744589031",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arxiv.org/abs/2503.24322",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Quick Primer on MCP Using Ollama and LangChain (polarsparc.com)",
    "points": 47,
    "submitter": "bswamina",
    "submit_time": "2025-04-13T21:43:36 1744580616",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43676084",
    "comments": [
      "In the case of MCPs, this post is indeed a quick primer. But from a coding standpoint, and despite the marketing that Agent/MCP development simplifies generative LLM workflows, it\u2019s a long coding mess that is hard to tell if it\u2019s even worth it. It\u2019s still the ReAct paradigm at a low level and if you couldn\u2019t find a case for tools then, nothing has changed other than the Agent/MCP hype making things more confusing and giving more ammunition to AI detractors.\n \nreply",
      "If you need to define and write the functions to calculate interest\u2026 what exactly is the llm bringing to the table here? I feel like I\u2019m missing something.\n \nreply",
      "The LLM is what decides which endpoint/tool to call (or none at all) in response to the user input.The original 2022 ReACT paper is still best explainer: https://arxiv.org/abs/2210.03629\n \nreply",
      "maybe some of these could be fit? https://python.langchain.com/docs/tutorials/\n \nreply",
      "MCP is great for when you\u2019re integrating tools locally into IDEs and such. It\u2019s a terrible standard for building more robust applications with multi-user support. Security and authentication are completely lacking.99% of people wouldn\u2019t be able to find the API keys you need to feed into most MCP servers.\n \nreply",
      "You are correct ... it is still early days IMHO ... will have to see how this evolves\n \nreply",
      "What, according to you, are some alternatives that exist or are in development that fill these gaps?\n \nreply"
    ],
    "link": "https://www.polarsparc.com/xhtml/MCP.html",
    "first_paragraph": ""
  },
  {
    "title": "Writing Cursor rules with a Cursor rule (adithyan.io)",
    "points": 29,
    "submitter": "adithyan_win",
    "submit_time": "2025-04-11T21:40:43 1744407643",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43658923",
    "comments": [
      "I have found Cursor to be frustrating and exhausting to work with, even with my rules file. When it works, it\u2019s like magic. But most of the time, it feels like working with a Jr. dev who has a bit of a concussion. Code review is wearying work, and using Cursor means you\u2019re doing a lot of code review. I have never once gotten into a flow state with it.That was a long preamble to this question: any senior devs out there (20+ years) who enjoy using Cursor? What\u2019s the trick?\n \nreply",
      "The trick I\u2019ve been using is to copy the entire codebase into a text prompt with Repo Prompt and feed that into Grok with a specific request on what feature / change I want. Paste that output into Cursor with Claude 3.7 and have it do the changes and compile/fix errors along the way.\n \nreply",
      "How long until such \"rules\" also become standardized (like we saw with MCP)? It feels redundant to have rules.cursorrules and rules.aiderrules where the rules content is the same. I predict companies will not only publish coding guidelines for their programmers, they'll publish these tiny coding rules for LLMs used in the company as well, so all code follows the same standards/idioms.\n \nreply",
      "I\u2019ve been using more and more AI tools in my development and getting a lot of mileage. Cursor is the latest one I\u2019ve adopted and it\u2019s impressive even without rules.I\u2019ll give this a try soon. Thanks for sharing!\n \nreply",
      "Does anyone have a variant on this meta rule file that isn't React specific?\n \nreply"
    ],
    "link": "https://www.adithyan.io/blog/writing-cursor-rules-with-a-cursor-rule",
    "first_paragraph": "Apr 10, 2025I spend most of my coding time in Cursor. It's a fantastic tool for LLM assisted coding.But coding with LLMs has a specific quirk: they possess strong contextual memory but lack episodic memory.In simpler words, they recall information within a single conversation but forget everything once a new chat session begins. No learnings from previous chats on how you like things. No accumulation of instituation quirks and knowledge.Think of it like working with a brilliant assistant who has amnesia. Every day, you repeat the same instructions:If you use Cursor often, this should sound familiar. You constantly nudge the AI back toward your project's standards and personal preferences.\nIf you're already nodding in agreement and (from the title) understand where I'm going with this, you probably just want the meta cursor rule template that I use. In that case, you can jump straight to The Plug-and-Play Meta-Cursor Rule.If you're still unsure what I'm talking about, I'll explain in mo"
  },
  {
    "title": "Docker Model Runner (docker.com)",
    "points": 16,
    "submitter": "kordlessagain",
    "submit_time": "2025-04-10T14:10:28 1744294228",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43643944",
    "comments": [
      "Looks exactly like ollama but built into Docker desktop? Anyone know of any differences?\n \nreply",
      "Aren't some of the ollama guys ex-Docker guys?\n \nreply",
      "They imply it should be somehow optimized for apple silicon, but, yeah, I don't understand what this is. If docker can use GPU, well, it should be able to use GPU in any container that makes use of it properly. If (say) ollama as an app doesn't use it properly, but they figured a way to do it better, it would make more sense to fix ollama. I have no idea why this should be a different app than, well, the very docker daemon itself.\n \nreply"
    ],
    "link": "https://www.docker.com/blog/introducing-docker-model-runner/",
    "first_paragraph": "ProductsMORE resources for developersDocker Desktop v4.40DevelopersMORE resources for developersIntroducing Docker Model RunnerDeliver Quickly. Build Securely. Stay Competitive.CompanyCompanyDocker Announces SOC 2 Type 2 Attestation & ISO 27001 CertificationProductsMORE resources for developersDocker Desktop v4.40DevelopersMORE resources for developersIntroducing Docker Model RunnerDeliver Quickly. Build Securely. Stay Competitive.CompanyCompanyDocker Announces SOC 2 Type 2 Attestation & ISO 27001 CertificationDeanna SparksGenerative AI is transforming software development, but building and running AI models locally is still harder than it should be. Today\u2019s developers face fragmented tooling, hardware compatibility headaches, and disconnected application development workflows, all of which hinder iteration and slow down progress.\u00a0\u00a0That\u2019s why we\u2019re launching Docker Model Runner \u2014 a faster, simpler way to run and test AI models locally, right from your existing workflow. Whether you\u2019re "
  },
  {
    "title": "Math 13 \u2013 An Introduction to Abstract Mathematics [pdf] (uci.edu)",
    "points": 88,
    "submitter": "ibobev",
    "submit_time": "2025-04-13T19:43:11 1744573391",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43675310",
    "comments": [
      "Math 13 was created by the late Howard Tucker as a traditional discrete mathematics course (the number was a deliberate joke).I took the course under Howard G. Tucker and I did have the impression this was a course not worth taking due to the low number. Turned out to be one of the most memorable classes. We went beyond the curricula in this document and had some fun exploring Hilbert Infinite Hotel and Peanos Axioms. Howard G. Tucker was probably the most memorable professor I had as he was veering in his 90s at the time he taught the course and was just so passionate about teaching.\n \nreply",
      "> and serving as the key prerequisite for upper-division courses such as abstract algebra, analysis, linear algebra & number theory.I was slightly taken aback by this phrasing in the preface as I was under the impression that undergrad math programs introduce foundations ASAP and typically start proof-based classes around end of freshman/start of sophomore.\n \nreply",
      "In the US, the standard course sequence (e.g. at a good state university) is two years of calculus, diffeqs, and linear algebra (all taught as on-paper computation) concurrently with a course in discrete mathematics. The discrete mathematics course often doubles as an introduction to proof (as is apparently the case at UCI). Year 3 typically covers proof-based analysis, algebra, and linear algebra and some electives. Year 4 is typically electives.At a fancy school, you can often take proof-based honors versions of Year 1-2 courses but you still may not get to skip over all of Year 3. Think: calculus using Spivak and real analysis using Rudin.At Harvard, you can take Math 55, which is essentially Year 3 above (plus complex analysis) in Year 1.\n \nreply",
      "Isn't that exactly what the sentence after the one you quoted encourages?\n \nreply"
    ],
    "link": "https://www.math.uci.edu/~ndonalds/math13/notes.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Shadertoys Ported to Rust GPU (rust-gpu.github.io)",
    "points": 18,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-12T09:01:29 1744448489",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://rust-gpu.github.io/blog/2025/04/10/shadertoys/",
    "first_paragraph": "We ported a few popular Shadertoy shaders over to Rust\nusing Rust GPU. The process was straightforward\nand we want to share some highlights.The code is available on GitHub.Rust GPU is a project that allows you to write code for\nGPUs using the Rust programming language. GPUs are typically programmed using\nspecialized languages like WGSL,\nGLSL,\nMSL,\nor\nHLSL.\nRust GPU changes this by letting you use Rust to write GPU programs (often called\n\"shaders\" or \"kernels\").These Rust GPU programs are then compiled into SPIR-V,\na low-level format that most GPUs understand. Since\nSPIR-V is the format Vulkan uses, Rust GPU makes it possible\nto integrate Rust-based GPU programs into any Vulkan-compatible workflow.For more details, check out the Rust GPU website or the\nGitHub repository.Sharing data between the CPU and GPU is common in shader programming. This often\nrequires special tooling or manual effort. Using Rust on both sides made this seamless:Note that on both the CPU and the GPU we are using t"
  },
  {
    "title": "I Bought a Mac (loganius.org)",
    "points": 3,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-14T01:11:19 1744593079",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://loganius.org/2025/04/i-bought-a-mac/",
    "first_paragraph": ""
  },
  {
    "title": "Writing my own dithering algorithm in Racket (amanvir.com)",
    "points": 117,
    "submitter": "venusgirdle",
    "submit_time": "2025-04-13T19:43:03 1744573383",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43675309",
    "comments": [
      "The square artifacts in the dithered image are caused by the distribution not doing second passes over the pixels already with error distributed, this is a byproduct of the \"custom\" approach the OP uses, they've traded off (greater) individual colour error for general picture cohesion.Me, I adjusted Atkinson a few years ago as I prefer the \"blown out\" effect: https://github.com/KodeMunkie/imagetozxspec/blob/master/src/...A similar custom approach to prevent second pass diffusion is in the code too; it is slightly different implementation - processes the image in 8x8 pixel \"attribute\" blocks, where the error does not go out of these bounds. The same artifacts occur there too but are more distinct as a consequence.\nhttps://github.com/KodeMunkie/imagetozxspec/blob/3d41a99aa04...Nb. 8x8 is not arbitrary, the ZX Spectrum computer this is used for only allowed 2 colours in every 8x8 block so this seeing the artifact on a real machine is less important as the whole image potentially had 8x8 artifacts anyway.\n \nreply",
      "The dithered images have the wrong brightness mapping.The reason is that the described approach will estimate the error correction term wrong as the input RGB value is non-linear sRGB.The article doesn't mention anything about this so I assume the author is oblivious to what color spaces are and that an 8bit/channel RGB value will most likely not represent linear color.This is not bashing the article; most people who start doing anything with color in CG w/o reading up on the resp. theory first get this wrong.And coming up with your own dither is always cool.See e.g. [1] for an in-depth explanation why the linearization stuff matters.[1] http://www.thetenthplanet.de/archives/5367\n \nreply",
      "Hi, OP here!Thank you so much for pointing this out! Just read the post you linked and did some of my own research on the non-linearity of sRGB - really fascinating stuff :)For now, I've acknowledged this limitation of my implementation so that any new readers are aware of it: https://amanvir.com/blog/writing-my-own-dithering-algorithm-...But I'll definitely revisit the article to add proper linearization to my implementation when I have the time. Thanks again for mentioning this!\n \nreply",
      "To some extent I think this comes down to a preference, like many things in dithering. If the black and white results look good, that may be the right answer!I've played with dithering tools that provide both options, and I prefer the output of the simple version..\n \nreply",
      "Haha, yeah I was kind of thinking that as well! Like with different error-diffusion patterns, one method may be more visually appealing than the other.Although, with either approach, I definitely feel that the fact that sRGB is non-linear should be acknowledged, and that\u2019s something I was completely unaware of. So, I\u2019m happy I learned something new today :)\n \nreply",
      "You're already 99% of the way there, you're just have the order of operations wrong.What you're doing is sRGB -> linear perceived luminance space -> sRGB (greyscale, where R=G=B) -> ditheringWhen you should be applying dithering in the linear perceived luminance space,  then covering the dithered image back into sRGB space.\n \nreply",
      "Are dithering patterns proportional in perceived brightness to a uniform grey for any percentage of set pixels?I can see them not being linearly proportional to a smooth perceptual grey gradient as the ratio of black to white changes, but I suspect it might change also with the clustering of light and dark at the same ratio.\n \nreply",
      "I did the same like 2 weeks ago. In Rust. ^^I'm still trying to improve it a little.  \nhttps://git.ache.one/dither/tree/?h=%f0%9f%aa%b5I didn't published it because it's hard to actually put dithered images on the web, you can't resize a dithered image. So on the web, you have to dither it on the fly. It's why, in the article, there is some artifacts in the images.\nI still need to learn about dithering.Reference: https://sheep.horse/2022/12/pixel_accurate_atkinson_ditherin...Cool links about dithering:\n - https://beyondloom.com/blog/dither.html  \n - https://blog.maximeheckel.com/posts/the-art-of-dithering-and...\n \nreply",
      "Why can't you resize it? Because of the filtering? You can turn that off in css, right?\n \nreply",
      "I am the author of the sheep.horse link above, although here[0] is an updated link.Even with filtering turned off you get slightly incorrect results, especially if you are resizing down where aliasing might completely ruin your image. Harsh black-and-white dithering is very susceptible to scaling artifacts.If you want pixel perfect dithering for the screen you are viewing the page on, you need to do it client side. Whether or not this is worth the bother is up to you.[0] https://sheep.horse/2023/1/improved_web_component_for_pixel-...\n \nreply"
    ],
    "link": "https://amanvir.com/blog/writing-my-own-dithering-algorithm-in-racket",
    "first_paragraph": ""
  },
  {
    "title": "Implementing DeepSeek R1's GRPO algorithm from scratch (github.com/policy-gradient)",
    "points": 67,
    "submitter": "xcodevn",
    "submit_time": "2025-04-13T18:33:05 1744569185",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/policy-gradient/GRPO-Zero",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          GRPO training with minimal dependencies. We implement almost everything from scratch and only depend on tokenizers for tokenization and pytorch for training.Group Relative Policy Optimization (GRPO) is an algorithm proposed by Deepseek for training large language models with reinforcement learning. The idea is simple: for each question, we randomly sample multiple answers. The advantage of an answer is then defined as the normalized reward. This gets rid of the value estimation network. In particular, we implement the following algorithm:$$\n\\begin{aligned}\n\\mu_i &\\leftarrow \\text{mean}(r_{i,1}, r_{i,2}, \\cdots, r_{i,M}) \\\\\n\\sigma_i &\\leftarrow \\text{std}(r_{i,1}, r_{i,2}, \\cdots, r_{i,M})\n\\end{aligned}\n$$$$A_{i,j}[t] \\leftarrow \\frac{r_{i,j} - \\mu_i}{\\sigma_i}$$$$\n\\nabla_\\theta \\log \\pi_\\theta(a_{i,j}[t]) \\cdot A_{i,j}[t]\n$$We are going to t"
  },
  {
    "title": "Show HN: I made a free tool that analyzes SEC filings and posts detailed reports (signalbloom.ai)",
    "points": 17,
    "submitter": "GodelNumbering",
    "submit_time": "2025-04-13T19:33:24 1744572804",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43675248",
    "comments": [
      "You might like edgartools by Dwight Gunning\n \nreply",
      "(Side note: would you mind emailing hn@ycombinator.com so I can explain how and why I edited your text here?)\n \nreply",
      "Done. Thank you!\n \nreply",
      "I was thinking of building exactly this type of thing here. This is great and I love the simple/minimalistic styled pages.Things I was also contemplating to implement you can freely steal:1. Giving a list of potential interesting investments - these could also be behind paywall.2. Summarize based on sectors to see where there's downturns coming - again maybe paywall this3. Connect with news-sites or twitter etc.. to see what is happening and what is the sentiment. This is a lot harder as you'll need to either scrape or pay to get that info.Best of luck\n \nreply"
    ],
    "link": "https://www.signalbloom.ai/news/",
    "first_paragraph": "Updated within minutes of release.Wilson Bank Holding Company (WBHC) announced robust first-quarter 2025 results, highlighted by significant year-over-year earnings per share growth and continued expansion of its balance sheet and ...Bruker Corporation (BRKR) reported preliminary first-quarter 2025 revenue that surpassed both internal expectations and market consensus, driven significantly by recent acquisitions while underlyin...Morgan Stanley reported exceptionally strong first-quarter 2025 results, driven by record performance in its Institutional Securities division, significantly outpacing analyst expectations and demo...Fastenal Company reported first-quarter 2025 results that met earnings expectations while slightly exceeding revenue consensus, driven primarily by growth in its contract customer segment amidst on...JPMorgan Chase & Co. reported first-quarter 2025 earnings that surpassed analyst expectations, buoyed by robust performance in its Commercial & Investment Bank and fa"
  },
  {
    "title": "Why Fennel? (fennel-lang.org)",
    "points": 188,
    "submitter": "behnamoh",
    "submit_time": "2025-04-13T15:37:05 1744558625",
    "num_comments": 77,
    "comments_url": "https://news.ycombinator.com/item?id=43673551",
    "comments": [
      "I do not understand the appeal of LISPy languages. I get that the parser is simple and elegant, but I believe the developer (of the compiler in this case) should serve the convenience of the user, not the other way around.Writing code like this is cumbersome and unnecessarily symbol heavy, and reading it isn't really nice as well.I'd rather have the language add that extra complexity into the parser than have me stare down these endless paretheses. Parsing something C-like is not that, hard, trust me, I've done it\n \nreply",
      "I do not understand the appeal of non-LISPy languages. I get that most people are used to reading it and that they are efficent, but I believe the developer (of the compiler in this case) should serve the convenience of the user, not the other way around.Writing code like this is combersome and unnecessarily symbol heavy, and reading it isn't really nice as well.I'd rather have the language add those extra parens into the parser than have me stare down these endless semi-colon, linebreaks or indentation. Parsing something Lisp-like is not that, hard, trust me, I've done it.\n \nreply",
      "This doesn't really resonate with people though, as most people are more familiar with C-style notation. Also:>Writing code like this is combersome and unnecessarily symbol heavyDoes not make sense in this context, as it mainly applies to Lisp-like languages that uses  parentheses heavily.\n \nreply",
      "Yeah was going to change that part too for something like \"Writing code like this is verbose and spans too many lines\", but then I just thought it'd be better if it sounded more like the parent comment.And I understand it doesn't resonate with most, I just wanted to highlight how the initial parent comment was very subjective and not very substantive, some people didn't take the joke so well, I guess it could've sounded a bit passive aggressive. I personally enjoy both C-like and Lisp-like syntaxes and languages, I do have a sweet spot for Forth tho.But back on topic, Fennel is a great language, working with Love and Fennel is really nice. And if the parentheses can seem off-putting for some, I'd highly encourage to give it a shot as you can quickly get past it and see how comfy it feels to have your statements properly demarkated.S-expr shine the most when working with XML-like structure. Spinneret[1] was the most fun I ever had working with HTML, every other templating engine feels subpar now that I have tasted that sweet nectar..[1] https://github.com/ruricolist/spinneret\n \nreply",
      "It's your comment that seems to add the least, because the majority agree with the OP. The point is that ergonomics is not as good, of course there are contrary opinions. The existence of a contrary and minority opinion doesn't detract from the point.\n \nreply",
      ">Does not make sense in this context, as it mainly applies to Lisp-like languages that uses parentheses heavily.I had read, some years back, that someone did an actual calculation / demonstration that showed that the number of symbol / punctuation characters in Lisp is actually less than in C-based languages, for a block of code with equal functionality in both languages.I don't have the reference handy. Someone here may know of it, and post it.\n \nreply",
      "I never got people\u2019s objections to the parentheses when the bottom of most js/ts files is a soup of three different flavors of closing bracket.  Even more \u201cfun\u201d in languages like PHP that make you sprinkle ceremonial semicolons into some parts to satisfy the compiler.  Hunting for the right brace is tedious, whereas in a lisp I just bounce on close paren til the open paren highlight is where I want it.\n \nreply",
      "It's obvious to anyone who is familiar with both.    (f x y)\n\nvs    f(x, y);\n\nNote the extra comma and semicolon. The only place this breaks down is for simple arithmetic expressions like (+ a b) vs a + b, which is trivial enough to ignore (and also goes back in favor of Lisp when you start having more operands).\n \nreply",
      "Let's be real in most situations it doesn't matter. One \"statement\" per line is bog standard. Whether that statement is surrounded by parens or ended in a semicolon isn't impactful for reading.LISP is only better when you add source code transformation (which is way easier with its source code looking like the transformed code). But then you introduce \"everyone can write their own syntax\" which is good and bad given the history of DSLs...\n \nreply",
      "<3\n \nreply"
    ],
    "link": "https://fennel-lang.org/rationale",
    "first_paragraph": "Fennel is a programming language that runs on the Lua runtime.The Lua programming language is an excellent and very underrated\ntool. Is it remarkably powerful yet keeps a very small footprint both\nconceptually as a language and in terms of the size of its\nimplementation. (The reference implementation consists of about nineteen\nthousand lines of C and compiles to 278kb.) Partly because it is so\nsimple, Lua is also extremely fast. But the most important thing about\nLua is that it's specifically designed to be put in other programs to\nmake them reprogrammable by the end user.The conceptual simplicity of Lua stands in stark contrast to other\n\"easy to learn\" languages like JavaScript or Python--Lua contains very\nclose to the minimum number of ideas needed to get the job done; only\nForth and Scheme offer a comparable simplicity. When you combine this\nmeticulous simplicity with the emphasis on making programs\nreprogrammable, the result is a powerful antidote to prevailing trends\nin technology"
  },
  {
    "title": "The dark side of the Moomins (newstatesman.com)",
    "points": 253,
    "submitter": "SebaSeba",
    "submit_time": "2025-04-13T13:15:57 1744550157",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=43672593",
    "comments": [
      "I'm not sure how tongue in cheek this was, but I assume it's serious. Either way, it's a fun and smart read.The article spots well the dark side of the moomins, but in my opinion goes too deep into it. My disagreements boil down to this: \"One of the oddest aspects of the Moomin phenomenon is how these complex tales of apocalypse, breakdown and disfunction have been consistently misread as cutesy celebrations of domestic life.\" Yes, all these things exist, but the point to me has always been that they are cutesy despite that! The stories paint a very typical family dynamic (at least of the time, at least in a Finnish swedish speaking family like Tove's), throws it into weirdest situations, and they all survive together thanks to, and despite, their dysfunctions. And Moominmamma is the most wholesome character ever, period.\n \nreply",
      "I've been listening to Moomin audiobooks and reading some of the books to my wife in recent years, and I started to spot some of the more adult/darker subtext in it (I'm still processing the one where the Moominpappa makes the entire family move to a lighthouse, and Moominmamma is desperately trying to cope with growing depression). Still, I have an answer for the author's conundrum, that's accurate for a significant fraction of the readerbase:> \"One of the oddest aspects of the Moomin phenomenon is how these complex tales of apocalypse, breakdown and disfunction have been consistently misread as cutesy celebrations of domestic life.\"It's actually really simple. Here in Poland, myself and my entire generation grew up watching the children cartoon adaptation of the Moomins. It was cute, it was happy, it had nice art and music, it was suitable for small children but engaging even to older ones, and it was aired when all kids would be watching[0]. This was our generation's intro to the Moomins, and it colored how we read the books.I imagine the case is similar all across Europe. A whole generation primed to read these stories as positive and light-hearted, because of a TV adaptation.--[0] - https://en.wikipedia.org/wiki/Wieczorynka - public TV (TVP1), every day at 19:00, just before the evening news slot. In times I grew up, watching this was pretty much a national tradition for any family with children.\n \nreply",
      "Light hearted? Suitable for small children? Are you kidding me.I'm in my mid-30's and still remember nightmares those stupid series gave me when I was in kindergarten. It was X-Files-tier scary (\"The X Files\" being other show aired by polish TV around same time), masquarading behind cute animations. How can anyone in their right mind call the episode where the Moomintroll swaps bodies with Stinky lighthearted and positive? What about the collection of monsters like Groke or Hattifnats? On some occasion I remember my parents would call me to get out from my room to watch the \"wieczorynka\" and I would pretend I can't hear and come out only as I hear the outro song starting, just to avoid whatever insane plot the Moomins would bring on me that time. I hate Moomins so much and wish could erase it from existence. Calling it \"cute and happy\" is like saying candybar with razorblade inside is delicious; technically true but not exactly an accurate description.\n \nreply",
      "i wonder what you'd think about Brothers Grimm's tales :) And in general children folk tales in many countries do contain strong violence, cruelty, torture, etc. if you'd focus on those details.\n \nreply",
      "> It was cute, it was happyMany episodes had darker undertones as well, especially those with the Groke[1] or hattifatteners. Tvtropes has a list[2].> The Groke was so horrifying in fact, that in Poland it caused a nation-wide fear in almost all children, some of which were even left traumatised for years, leading to some parents forbidding their children from watching Moomins, and some using the Groke as a Bogeyman to scare their children into good behavior. Any 90s or 2000s Polish kid will know how it felt.[1]: https://en.m.wikipedia.org/wiki/The_Groke[2]: https://tvtropes.org/pmwiki/pmwiki.php/NightmareFuel/TheMoom...\n \nreply",
      "I love the books, I have read them all to my kids, and I agree that I think the article takes its thesis too far.The books are strange tales. They have dark undertones. And sometimes the adults take actions that only someone with life experience would really understand (e.g. Moominpappa wanting to suddenly upend everything in the families life and move to an isolated island). But, my kids mostly pick up on the adventure and the friendships.I feel that the Moomins are like most media that is enjoyable by both children and parents in this way (e.g. Bluey, Pixar films, etc.).\n \nreply",
      "Based on your experience, what age do you think is ideal for introducing the books to kids?\n \nreply",
      "I started reading the novel stories when the kids were 3yo and 6yo. Both love them. My 3yo for the drawings mostly.There are a number of excellent picture book adaptations of stories that have been published too. But, we read those afterwards and obviously they aren\u2019t as enjoyable to me.Because this is HN: My tradition is to use my Inkpalm 5 and read them with the lights out at bedtime- we pass the reader around to look at pictures.\n \nreply",
      "Not the previous poster, but based on my own experience as a kid and also my kids I'd say age 5 is perfectly good age to introduce the books.As an adult you pick up on some the more serious themes but as a kid you just enjoy the story and the bit of danger and overcoming and the overall wholesomeness.\n \nreply",
      "While all the books have both humour and darkness, the early books are more whimsical and playful while the later books are more about loneliness, alienation, and loss.\n \nreply"
    ],
    "link": "https://www.newstatesman.com/culture/books/2025/04/dark-side-of-the-moomins-tove-jansson",
    "first_paragraph": "New Times, New Thinking.Tove Jansson\u2019s beloved stories, which turn 80 this year, are not cute: they are angry tales of apocalypse and breakdown.By\n                    Frances Wilson \u201cI could vomit over Moomintroll,\u201d Tove Jansson confided in her notebook in the late 1950s. A decade after the hippo-like creature with low self-esteem made his debut appearance in 1945, Scandinavian homes had become versions of Moominvalley, with Moomin-themed aprons, curtains, wallpaper and crockery, while department stores stocked Moomins modelled in marzipan, ceramic and white leather (Jansson drew the line at Moomin sanitary towels). This world of whimsy bore little relation to the Finnish artist\u2019s initial conception of the Moomintrolls.The Moomins and the Great Flood, the 60-page picture book not translated into English until 2005 and now celebrating its 80th anniversary, was written during the Winter War in 1939, when Russia\u2019s invasion of Finland left 300,000 Finns homeless. (The Moomin estate is mark"
  },
  {
    "title": "GeoDeep's AI Detection on Maxar's Satellite Imagery (marksblogg.com)",
    "points": 23,
    "submitter": "marklit",
    "submit_time": "2025-04-11T12:34:31 1744374871",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://tech.marksblogg.com/geodeep-maxar-ai-detection.html",
    "first_paragraph": "I have 15 years of consulting & hands-on build experience with clients in the UK, USA, Sweden, Ireland & Germany. Past clients include Bank of America Merrill Lynch, Blackberry, Bloomberg, British Telecom, Ford, Google, ITV, LeoVegas, News UK, Pizza Hut, Royal Mail, T-Mobile, Williams Formula 1, Wise & UBS. I hold both a Canadian and a British passport. My CV, Twitter & LinkedIn.\n      \nHome\n        | Benchmarks\n\n        | Categories\n\n            | Atom Feed\nPosted on Thu 10 April 2025  under Artificial IntelligenceGeoDeep is a Python package that can detect objects in satellite imagery. It's made up of 1,026 lines of Python and uses ONNX Runtime and Rasterio extensively.GeoDeep was written by Piero Toffanin, who is based in Florida and is the co-founder of OpenDroneMap. He also wrote LibreTranslate which I covered in a post a while back.Maxar is a satellite manufacturer and constellation operator. They run an open data programme and they often releases imagery from areas before and af"
  },
  {
    "title": "Exwm: Emacs X Window Manager (github.com/emacs-exwm)",
    "points": 77,
    "submitter": "tosh",
    "submit_time": "2025-04-13T17:08:49 1744564129",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=43674233",
    "comments": [
      "I created this custom keymap that goes well with EXWM: https://codeberg.org/hermitsings/Kmonad_ISO_keymap_for_minim...This is to reduce lateral wrist movement (to protect from Carpal Tunnel) and general finger movement. Just posting here if folks wanna check it out.\n \nreply",
      "I had a fun fling with EXWM, but having your window manager sharing its single-thread with emacs just doesn't really make any sense.\n \nreply",
      "If it seems interesting to you or you're experimenting with keyboard-driven tiling WMs, though, I would highly recommend this particular fling.\n \nreply",
      "Been using it for a couple of years, and in practice it does not cause me much trouble, at least not for me.\n \nreply",
      "The commonly accepted solution, if this is an issue for you, is to run two instances of Emacs: one to edit in, and one to run EXWM. The days of \"Eight Megs And Constantly Swapping\" are well behind us; one can easily afford to run two (or many more) emacsen. And it can't be that much more bloated than, say, kwin...\n \nreply",
      "I\u2019m surprised there aren\u2019t Emacs packages for the X server itself and a bootloader\u2026\n \nreply",
      "I played with this decades ago (maybe another Emacs based WM?).  It was fun for a while but I moved on.  I thought it was abandoned.I will need to give it another go and glad to see it back among the living :)\n \nreply",
      "Really enjoyed my time using EXWM. Had to move to Wayland for a number of reasons, and really miss it. KDE Plasma has been fantastic, but I do miss the integrated scripting environment. Ironically I now use a heavily frames-based Emacs set up, and eschew most of Emacs internal window management capabilities.\n \nreply",
      "Obligatory System Crafter videos:- https://www.youtube.com/watch?v=f7xB2fFk1tQ- https://www.youtube.com/watch?v=9gfKrrTtyOk\n \nreply",
      "Packaged as a Spacemacs layer => https://www.spacemacs.org/layers/LAYERS.html#exwm\n \nreply"
    ],
    "link": "https://github.com/emacs-exwm/exwm",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Emacs X Window Manager\n      EXWM (Emacs X Window Manager) is a full-featured tiling X window manager\nfor Emacs built on top of XELB.It features:Optional features:Please check out the\nscreenshots\nto get an overview of what EXWM is capable of, and the\nuser guide\nfor installation instructions and a detailed explanation of its usage.\n        Emacs X Window Manager\n      "
  },
  {
    "title": "How much oranger do red orange bags make oranges look? (alexanderell.is)",
    "points": 72,
    "submitter": "otras",
    "submit_time": "2025-04-13T16:02:28 1744560148",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=43673761",
    "comments": [
      ">First, the average pixel is not what I would expect it to be at allIt looks like the averaging was done in default sRGB color space, with:magick \"$f\" -resize 1x1 txt:-Downscaling should instead be done in a linear colorspace. Human vision is non-linear, but the filtering required for downscaling is equivalent to blurring, which is linear because it's done optically not within the retina or brain. Using ImageMagick:magick \"$f\" -colorspace RGB -resize 1x1 -colorspace sRGB txt:-Additionally, JPEG supports chroma subsampling, which is usually enabled by default. I don't know what sips does, but with these small files you might as well use PNG and avoid the risk of losing color information this way.This should produce results closer to human perception.\n \nreply",
      "Warning, always convert your colors to from sRGB to Linear RGB before doing any math on them, then convert them back to sRGB afterwards for displaying them.sRGB is the familiar color space you all know and love, it's what your display uses, and it's what has those RGB numbers between 0 and 255.  But it's not a linear color space.First think of values as being between 0 and 1 instead of 0 and 255.  To change sRGB to Linear, do X^2.2 (close to squaring the value).  To change Linear back to sRGB, do X^(1/2.2) (close to a square root).In Linear RGB, a value of 0.5 is halfway between black and white.  You can put a stripe or checkerboard pattern next to the color value, and it will appear to be the same brightness.  But in sRGB, a value of 0.5 is much darker.  Linear RGB of 0.5 is roughly equivalent to sRGB of 0.73.The actual method of conversion involves a complicated curve that isn't continuous, using X^2.2 is still an approximation.\n \nreply",
      "Even better, convert to HSL or CieLAB. RGB is not at all how our eyes see things.\n \nreply",
      ">The average pixel was not what I expected.The average pixel doesn't look correct because human vision does not interepret shadowed colors as different colors. We first guess at the shadows, and then do some kind of inverse mapping from the shaded color space to the illuminated one before we \"perceive a color\". This is why the black,blue/white,gold dress illusion exists.\n \nreply",
      "They really don\u2019t look all that different to my untrained eye - in fact I think it looks \u201cbetter\u201d without the bag. Maybe I\u2019m loco.\n \nreply",
      "I'm in the same camp. It definitely doesn't look more orange to me. If anything, it looks more brown.The unbagged oranges are more appealing.\n \nreply",
      "Taking another look, I think you're right! Particularly since the first orange is pretty orange already. I think the first example would have been better served with a yellower, less ripe orange to highlight the difference and the pull in the redder, riper direction from the bag.\n \nreply",
      "It makes sense that adding red adds red (in addition to the avocado sacks you mention, I think of lemons\u2019 yellow bags, limes\u2019 green bags, and the red packaging/shelf lining and pink-tinged light in the butcher\u2019s case)\u2014but those images really do look strangely exposed to me.Did you do exercise any specific control over the phone\u2019s camera?I wonder if the ring light might use the sort of general-market LEDs that underperform specifically at illuminating saturated reds and oranges in this range\u2026 see for examplehttps://www.canada.ca/en/conservation-institute/services/con...andhttps://indiecinemaacademy.com/are-leds-ruining-your-project...\n \nreply",
      "This was my immediate thought when I saw the ring light. Very very likely a CRI of 90 or below, which doesn\u2019t even weight much in red shades. Not uncommon to see 92 CRI with a R9 (red) score below 50% of sunlight or tungsten illumination.\n \nreply",
      "That's a good question, and I could easily see the camera settings (and the light) being a source of error here. Naively, I used the default iPhone camera with the same exposure for each one, then ended up manually removing some of the HDR settings from each one when they were showing up as way overexposed on my computer. Not exactly an advanced, scientific technique, and there was also a bright source of soft white light from the window next to the setup, which could have thrown off the automatic exposure.Another comment mentioned it, but I wonder if the overall effect would be more visible with yellower baseline oranges (or, as you mention, pale lemons and limes). Really interesting about the LEDs underperforming as well!\n \nreply"
    ],
    "link": "https://alexanderell.is/posts/orange/",
    "first_paragraph": "Look at this orange:Now look at this orange:It\u2019s the same orange.But, look how much more orange it looks with the red mesh on top of it:If you buy bags of oranges (at least at many places in the US), they frequently come in this red mesh bag. This bag\nmakes the\noranges look more orange. Oranger.Here\u2019s what that looks like at a local grocery store1:Ripe oranges are usually oranger, so this bag makes the oranges look better than they may actually be. Maybe the secret\nis to never buy bagged fruit, since it\u2019s harder to evaluate the quality of each orange.2This made me wonder \u2014 how does the bag change how we perceive the color?I thought this difference would be visible if we did some quick and tricky digital math: what if we had a picture of the\norange with and without the bag under the same light and camera conditions, then checked the average pixel?Here are the results from 11 different orange photos, with and without the mesh:There are a few interesting things here. First, the average pi"
  },
  {
    "title": "Lotka\u2013Volterra Equations (wikipedia.org)",
    "points": 35,
    "submitter": "ustad",
    "submit_time": "2025-04-10T19:28:05 1744313285",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43647275",
    "comments": [
      "Lotka\u2013Volterra equations -> Logistic function -> Logistic map -> Mandelbrot set for an interesting connection that might not be immediately apparent. The concepts all turn up around the same time once the line of inquiry becomes chaotic recursive systems.\n \nreply",
      "Volterra also contributed to materials science, more precisely with dislocations in crystals. Always amaze me how people in the past could make huge impact in totally different fields.\n \nreply",
      "A lot of people don't get further than Malthus, and don't realize that he was just the first pioneer. They think \"Malthus was wrong\", and don't realize the rabbit hole that opens up once you start treating population dynamics mathematically.\n \nreply",
      "For me, r/k selection applied to human behavior broke my mind.Once you see it, you can't unsee it. Be it dating or comparing cultural approaches to relationships, etc.\n \nreply",
      "Speaking of treating population dynamics mathematically\u2026 compartmental models are still some of my favorites https://pypi.org/project/epidemik\n \nreply",
      "on the one hand, yes ecology and math bio is cool. On the other, the demographic transition does not fall out of these models whatsoever. Humans decided to do something very weird for whatever reason.\n \nreply",
      "The actual population size during demographic transition looks very logistic-y. You'd be forgiven for thinking Verhulst applies. (though K is very much an empirical constant in that case, since you can't easily predict it from anything I don't think.)\n \nreply"
    ],
    "link": "https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations",
    "first_paragraph": "The Lotka\u2013Volterra equations, also known as the Lotka\u2013Volterra predator\u2013prey model, are a pair of first-order nonlinear differential equations, frequently used to describe the dynamics of biological systems in which two species interact, one as a predator and the other as prey. The populations change through time according to the pair of equations:\n\n\n\n\n\n\n\n\n\n\n\nd\nx\n\n\nd\nt\n\n\n\n\n\n\n=\n\u03b1\nx\n\u2212\n\u03b2\nx\ny\n,\n\n\n\n\n\n\n\nd\ny\n\n\nd\nt\n\n\n\n\n\n\n=\n\u2212\n\u03b3\ny\n+\n\u03b4\nx\ny\n,\n\n\n\n\n\n\n{\\displaystyle {\\begin{aligned}{\\frac {dx}{dt}}&=\\alpha x-\\beta xy,\\\\{\\frac {dy}{dt}}&=-\\gamma y+\\delta xy,\\end{aligned}}}\n\n\nwhere\nThe solution of the differential equations is deterministic and continuous. This, in turn, implies that the generations of both the predator and prey are continually overlapping.[1]\nThe Lotka\u2013Volterra system of equations is an example of a Kolmogorov population model (not to be confused with the better known Kolmogorov equations),[2][3][4] which is a more general framework that can model the dynamics of ecological systems wi"
  },
  {
    "title": "Unlocking Sudoku's Secrets (chalkdustmagazine.com)",
    "points": 17,
    "submitter": "amichail",
    "submit_time": "2025-04-11T16:06:55 1744387615",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43655409",
    "comments": [
      "I like Norvig's approach, I'm in the process of porting it to my Lisp.https://norvig.com/sudoku.htmlhttps://github.com/codr7/eli-java/blob/main/examples/sudoku....\n \nreply",
      "I\u2019ve implemented Norvig for a couple languages as a learning tool.One thing I do that he didn\u2019t before dropping to brute force though is the m squares with m possibilities check. If two squares in a row, column or group only have two possible values, then you can eliminate those possibilities from all of their siblings. Same for 3:3, 4:4 and 5:5.\n \nreply",
      "So the first solution seems like an obvious brute-force approach that definitely does not require any fancy graph theory. I have thought of this but never used it because it seems so tedious and like it defeats the point of the game.\n \nreply",
      "As someone who has played Sudoku every day for years, I find it fascinating that there\u2019s no need to unlock any secret. The beauty of Sudoku lies in exploring its simple rules, not in solving some hidden mystery.\n \nreply"
    ],
    "link": "https://chalkdustmagazine.com/features/unlocking-sudokus-secrets/",
    "first_paragraph": "Sara Logsdon looks to graph theory and abstract algebra for help on the puzzle page17 March 2025Sudoku has long captivated puzzle enthusiasts worldwide with its logical challenges and addictive nature. While it may seem like a simple game of numbers, beneath the surface lies a fascinating connection to the realm of mathematics. Graph theory and abstract algebra both play a crucial role in unravelling the intricacies of sudoku. Sudoku puzzles consist of a $9 \\times 9$ grid, divided into nine $3 \\times 3$ sub-grids called regions. The objective is to fill the grid with numbers from 1 to 9, ensuring that each row, column, and region contains every digit exactly once.In graph theory, a graph is a mathematical structure that comprises a set of vertices, or nodes, connected by edges. An area rich in mathematical questions, graph theory has a long history of famous thought-provoking problems. One of the most well-known of these problems is the vertex colouring problem: Given an undirected gra"
  },
  {
    "title": "Wasting Inferences with Aider (worksonmymachine.substack.com)",
    "points": 107,
    "submitter": "Stwerner",
    "submit_time": "2025-04-13T13:36:17 1744551377",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=43672712",
    "comments": [
      "For me, a team of junior developers that refuse to learn from their mistakes is the fuel of nightmares. I'm stuck in a loop where every day I need to explain to a new hire why they made the exact same beginner's mistake as the last person on the last day. Eventually, I'd rather spend half an hour of my own time than to explain the problem once more...Why anyone thinks having 3 different PRs for each jira ticket might boost productivity, is beyond me.Related anime: I May Be a Guild Receptionist, But I'll Solo Any Boss to Clock Out on Time\n \nreply",
      "One of the (many) differences between junior developers and LLM assistance is that humans can learn from their mistakes, whereas with LLMs it's up to you as the prompter to learn from their mistakes.If an LLM screws something up you can often adjust their prompt to avoid that particular problem in the future.\n \nreply",
      "It may not be as stupid as it sounds.Randomising LLM outputs (temperature) results is outputs that will always have some degree of hallucination.That\u2019s just math. You can\u2019t mix a random factor in and magically expect it to not exist. There will always be p(generates random crap) > 0.However, in any probabilistic system, you can run a function k times and you\u2019ll get an output distribution that is meaningful if k is high enough.3 is not high enough.At 3, this is stupid; all you\u2019re observing is random variance.\u2026but, in general, running the same prompt multiple times and taking some kind of general solution from the distribution isn\u2019t totally meaningless, I guess.The thing with LLMs is they scale in a way that actually allows this to be possible, in a way that scaling with humans can\u2019t.\u2026 like the monkeys and Shakespeare, there probably a limit to the value it can offer; but it\u2019s not totally meaningless to try it.\n \nreply",
      "> It may not be as stupid as it sounds.It is.> However, in any probabilistic system, you can run a function k times and you\u2019ll get an output distribution that is meaningful if k is high enough.This is the underlying flaw in this approach.  Attempting to use probabilistic algorithms to produce a singular verifiably correct result requires an external agent to select what is correct in the output of \"k times\" invocations.  This is a person capable of making said determination.> The thing with LLMs is they scale in a way that actually allows this to be possible, in a way that scaling with humans can\u2019t.For the \"k times\" generation of text part, sure.  Not for the determination of which one within k, if any, are acceptable for the problem at hand.EDIT: clarified \"produce a verifiably correct result\" to be \"produce a singular verifiably correct result\"\n \nreply",
      "I think this is an interesting idea, but I also somewhat suspect you've replaced a tedious problem with a harder, more tedious problem.Take your idea further. Now I've got 100 agents, and 100 PRs, and some small percentage of them are decent. The task went from \"implement a feature\" to \"review 100 PRs and select the best one\".Even assuming you can ditch 50 percent right off the bat as trash... Reviewing 50 potentially buggy implementations of a feature and selecting the best genuinely sounds worse than just writing the solution.Worse... If you haven't solved the problem before anyways, you're woefully unqualified as a reviewer.\n \nreply",
      "The linked article from Steve Yegge (https://sourcegraph.com/blog/revenge-of-the-junior-developer) provides a 'solution', which he thinks is also imminent - supervisor AI agents, where you might have 100+ coding agents creating PRs, but then a layer of supervisors that are specialized on evaluating quality, and the only PRs that a human being would see would be the 'best', as determined by the supervisor agent layer.From my experience with AI agents, this feels intuitively possible - current agents seem to be ok (thought not yet 'great') at critiquing solutions, and such supervisor agents could help keep the broader system in alignment.\n \nreply",
      ">but then a layer of supervisors that are specialized on evaluating qualityWhy would supervisor agents be any better than the original LLMs? Aren't they still prone to hallucinations and subject to the same limitations imposed by training data and model architecture?It feels like it just adds another layer of complexity and says, \"TODO: make this new supervisor layer magically solve the issue.\" But how, exactly? If we already know the secret sauce, why not bake it into the first layer from the start?\n \nreply",
      "Similar to how human brains behave, it is easier to train a model to select a better solution between many choices than to check an individual solution for correctness [1], which is in turn an easier task to learn than writing a correct single solution in the first place.[1] the diffs in logic can suggest good ideas that may have been missed in subsets of solutions.",
      "Just add a CxO layer that monitors the supervisors! And the board of directors watches the CEO and the shareholders monitor the board of directors. It's agents all the way up!\n \nreply",
      "This reads like it could result in \"the blind, leading the blind\". Unless the Supervisor AI agents are deterministic, it can still be a crapshoot. Given the resources that SourceGraph has, I'm still surprised they missed the most obvious thing, which is \"context is king\" and we need tooling that can make adding context to LLMs dead simple. Basically, we should be optimizing for the humans in the loop.Agents have their place for trivial and non-critical fixes/features, but the reality is, unless the agents can act in a deterministic manner across LLMs, you really are coding with a loaded gun.  The worst is, agents can really dull your senses over time.I do believe in a future where we can trust agents 99% of the time, but the reality is, we are not training on the thought process, for this to become a reality.  That is, we are not focused on the conversation to code training data. I would say 98% of my code is AI generated, and it is certainly not vibe coding. I don't have a term for it, but I am literally dictating to the LLM what I want done and have it fill in the pieces. Sometimes it misses the mark, sometimes it aligns and sometimes it introduces whole new ideas that I have never thought of, which will lead to a better solution.  The instructions that I provide is based on my domain knowledge and I think people are missing the mark when they talk about vibe coding, in a professional context.Full Disclosure: I'm working on improving the \"conversation to code\" process, so my opinions are obviously biased, but I strongly believe we need to first focus on better capturing our thought process.\n \nreply"
    ],
    "link": "https://worksonmymachine.substack.com/p/wasting-inferences-with-aider",
    "first_paragraph": ""
  }
]