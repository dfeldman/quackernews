[
  {
    "title": "We do not think Anthropic should be designated as a supply chain risk (twitter.com/openai)",
    "points": 260,
    "submitter": "golfer",
    "submit_time": "2026-02-28T21:24:16 1772313856",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=47200420",
    "comments": [
      "From that same X thread: Our agreement with the Department of War upholds our redlines [1]OpenAI has the same redlines as Anthopic based on Altman's statements [2]. However somehow Anthropic gets banished for upholding their redlines and OpenAI ends up with the cash?[1]: https://xcancel.com/OpenAI/status/2027846013650932195#m[2]: https://www.npr.org/2026/02/27/nx-s1-5729118/trump-anthropic...reply",
      "> more stringent safeguards than previous agreements, including Anthropic's.Except they are not \"more stringent\".Sam Altman is being brazen to say that.In their own agreement as Altman relays:> The AI System will not be used to independently direct autonomous weapons in any case where law, regulation, or Department policy requires human control> any use of AI in autonomous and semi-autonomous systems must undergo rigorous verification, validation, and testing> For intelligence activities, any handling of private information will comply with the Fourth Amendment, the National Security Act of 1947 and the Foreign Intelligence and Surveillance Act of 1978, Executive Order 12333, and applicable DoD directives> The system shall also not be used for domestic law-enforcement activities except as permitted by the Posse Comitatus Act and other applicable law.I don't think their take is completely unreasonable, but it doesn't come close to Anthropic's stance. They are not putting their neck out to hold back any abuse - despite many of their employees requesting a joint stand with Anthropic.Their wording gives the DoD carte blanch to do anything it wants, as long as they adopt a rationale that they are obeying the law. That is already the status quo. And we know how that goes.In other words, no OpenAI restriction at all.That is not at all comparable to a requirement the DoD agree not to do certain things (with Anthropic's AI), regardless of legal \"interpretation\" fig leaves. Which makes Anthropic's position much \"more stringent\". And a rare and significant pushback against governmental AI abuse.(Altman has a reputation for being a Slippery Sam. We can each decide for ourselves if there is evidence of that here.)reply",
      "Yep. It's the difference between \"Don't do these things, regardless of what the law says.\" and \"Do whatever you want, but please follow your own laws while you do it\".As Paul Graham said, \"Sam gets what he wants\" and \"He\u2019s good at convincing people of things. He\u2019s good at getting people to do what he wants.\" and \"So if the only way Sam could succeed in life was by [something] succeeding, then [that thing] would succeed\"reply",
      "Brings to mind the infamous line from Nixon:\"When the president does it, that means it is not illegal\".This was during the Frost/Nixon interviews, years after he had already resigned. Even after all that, he still believed this and was willing to say it into a camera to the American people. It is apparent many of the people pushing the excesses going on today in government share a shameless adherence to this creed.reply",
      "Easy way to summarize it:\n\"You're not allowed to do these things, except for all of the laws that allow you to do these things.\"reply",
      "It\u2019s a non-clause that is written to sound like they are doing something to prevent these uses when they aren\u2019t. \u201cYou are not allowed to do illegal things\u201d is meaningless, since they already can\u2019t legally do illegal things. Plus the administration itself gets to decide if it meets legal use.reply",
      "> except for all of the laws that allow you to do these things.It's even worse than that, because this administration has made it clear they will push as hard as possible to have the law mean whatever they says it means. The quoted agreement literally says \"...in any case where law, regulation, or Department policy requires human control\" - \"Department policy\" is obviously whatever Trump says it is (\"unitary executive theory\" and all that), and there are numerous cases where they have taken existing law and are stretching it to mean whatever they want. And when it comes to AI, any after-the-fact legal challenges are pretty moot when someone has already been killed or, you know, the planet gets destroyed because the AI system decide to go WarGames on us.reply",
      "Let me clear it upThe Trump administration acts cartoonish and fickle. They can easily punish one group, and then agree to work with another group on the same terms, to save face, while continuing to punish the first group. It doesn't have to make consistent sense. This is exactly how they have done with tariffs for example.Secondly, the terms are technically different because \"all lawful uses\" are preserved in this OpenAI deal, and it's just lawyering to the public. Really it was about the phrase \"all lawful uses\", internally at the DoD I'm sure. So the lawyers were able to agree to it and the public gets this mumbo-jumbo.I thought mass surveillance of Americans was unlawful by the DoD, CIA and NSA? We have the FBI for that, right? :)reply",
      "Sure, but OpenAI is also being disingenuous here pretending they\u2019re operating under the same principles Anthropic is. It\u2019s not and the things they\u2019re comfortable with doing Anthropic said they\u2019re notreply",
      "This implies that OpenAI must build and release and maintain a model without any safeguards, which is probably the big win and maybe something Anthropic never wants to do.reply"
    ],
    "link": "https://twitter.com/OpenAI/status/2027846016423321831",
    "first_paragraph": "We\u2019ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.Help Center\nTerms of Service\nPrivacy Policy\nCookie Policy\nImprint\nAds info\n      \u00a9 2026 X Corp.\n    "
  },
  {
    "title": "The Windows 95 user interface: A case study in usability engineering (1996) (acm.org)",
    "points": 139,
    "submitter": "ksec",
    "submit_time": "2026-02-28T22:19:36 1772317176",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=47200904",
    "comments": [
      "Steve Jobs is famous for his 1996 quote about Microsoft not having taste (https://www.youtube.com/watch?v=UiOzGI4MqSU).  I disagree; as much as I love the classic Mac OS and Jobs-era Mac OS X, and despite my feelings about Microsoft's monopolistic behavior, 1995-2000 Microsoft's user interfaces were quite tasteful, in my opinion, and this was Microsoft's most tasteful period.  I have fond memories of Windows 95/NT 4/98/2000, Office 97, and Visual Basic 6.  I even liked Internet Explorer 5.  These were well-made products when it came to the user interface.  Yes, Windows 95 crashed a lot, but so did Macintosh System 7.Things started going downhill, in my opinion, with the Windows XP \"Fisher-Price\" Luna interface and the Microsoft Office 2007 ribbon.reply",
      "I'll also give the opinion that Apple consistently creates some absolutely crap designs and when they do this, release something really really mind mindbogglingly stupid that it should be embarrassing they are instead met with applause on the \"amazing design\". It's a tiresome pattern repeated for decades now.eg. The 'breathing status light' that lit up the room at night due to extreme brightness which meant every macbook of the era had stickers or tape over the LED with endless Q&A's of \"How do i turn the annoying light off? You can't!\". This crap design was met by articles extolling the subtle sign wave and off white hue. I kid you not. https://avital.ca/notes/a-closer-look-at-apples-breathing-li...Apple today seem to have acknowledged their mistake here and taken away status lights completely (also a crappy design hailed as amazing since they've just gone to the other extreme) which highlights the fact that no matter what they do they're hailed as being amazing at design, even when it's contradictory from their own previous 'amazing designs'.Apple doesn't just get a pass on crappy design. It gets endless articles praising the virtues of everything they do even when, if you think about what they did for even a second you'd realize, \"that's actually just plain crap design\".reply",
      "I got no problem with that tiny LED or glowing apple logo personallyBut liquid glass and insane amount of bugs that arrived with it is killing me.reply",
      "Likely you experienced later gens where they toned it down. ~2010 it was one of the brightest LEDs you could purchase. As in they literally put a torch LED on the all white Intel macbooks of the era and it would shine through the laptop bags, pulsating.reply",
      "Maybe...reply",
      "Not Maybe, I owned a 2009 MBP. Everyone with a macbook from that period that I knew had the same issue, they were absurdly bright, you could not keep it anywhere near a bedroom without putting very thick tape over the light.It was a poorly thought out design of aesthetics over ergonomics.reply",
      "I recently had to get printing working for a family member on an Apple tablet.  I'm not an Apple jockey so it took me a while to sort out and I've being using computers since 1980 and consulting since 1995.You tap an icon that looks like the outline of a rectangle with an arrow pointing up.  Then you tap the name of the printer.  Then you tap another rectangle with an up arrow and then tap the word \"Print\".I may have got the precise steps wrong but it really is that abstruse to print something on a tablet.  Never mind that mDNS/Bonjour has done its thing - the steps to actually indicate that you want to print is frankly weird.What on earth is that box with an up arrow actually supposed to mean?  Why does the interface switch from icons to text?reply",
      "Android uses the 'share' icon to represent the same thing, which is maybe a little more legible, but still feels like shoving way too many actions under a confusing modal they shouldn't be in. Even worse when apps implement a custom share dialog.reply",
      "It's supposed to be the \"Share\" menu, but that stopped meaning anything very fast because they just crammed everything into it for lack of other UX for system services.Macs have the problem multiple times over, because now they have the normal menu bar and toolbar, and a Share menu that just gets arbitrary stuff dumped into by App Store apps, and the Services menu that shows up in some contexts but not others, and the Quick Actions menu that shows up in some contexts but not others, and some services can just add things directly to right click menus.reply",
      "> Microsoft Office 2007 ribbonRibbon also has a similar research behind it, just like Windows 95. For what they designed it, allowing beginners to discover all the functionality that's available, it works perfectly.I think most of the complaints from the tech circles are completely unfounded in reality. Many non-tech people and younger ones actually prefer using Ribbon. I also like it since it is very tastefully made for Office. 2010 was my favorite Office UI. It actually doesn't get rid of shortcuts either. Most of the Office 2003 ones were preserved to not break the workflow of power users.Where Ribbon doesn't work is when you take out the contextual activation out of it. Most companies copied it in a very stupid way. They just copied how it looks. The way it is implemented in Sibelius, WinDBG or PDFXChange is very bad.reply"
    ],
    "link": "https://dl.acm.org/doi/fullHtml/10.1145/238386.238611",
    "first_paragraph": ""
  },
  {
    "title": "Microgpt (karpathy.github.io)",
    "points": 18,
    "submitter": "tambourine_man",
    "submit_time": "2026-03-01T01:39:26 1772329166",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=47202708",
    "comments": [
      "What is the prime use casereply",
      "Looks like to learn how a GPT operates, with a real example.reply",
      "\u201cArt project\u201dreply"
    ],
    "link": "http://karpathy.github.io/2026/02/12/microgpt/",
    "first_paragraph": "Feb 12, 2026This is a brief guide to my new art project microgpt, a single file of 200 lines of pure Python with no dependencies that trains and inferences a GPT. This file contains the full algorithmic content of what is needed: dataset of documents, tokenizer, autograd engine, a GPT-2-like neural network architecture, the Adam optimizer, training loop, and inference loop. Everything else is just efficiency. I cannot simplify this any further. This script is the culmination of multiple projects (micrograd, makemore, nanogpt, etc.) and a decade-long obsession to simplify LLMs to their bare essentials, and I think it is beautiful \ud83e\udd79. It even breaks perfectly across 3 columns:Where to find it:The following is my guide on stepping an interested reader through the code.The fuel of large language models is a stream of text data, optionally separated into a set of documents. In production-grade applications, each document would be an internet web page but for microgpt we use a simpler example"
  },
  {
    "title": "Obsidian Sync now has a headless client (help.obsidian.md)",
    "points": 392,
    "submitter": "adilmoujahid",
    "submit_time": "2026-02-28T16:31:53 1772296313",
    "num_comments": 141,
    "comments_url": "https://news.ycombinator.com/item?id=47197267",
    "comments": [
      "Also new: Obsidian joins the CLI ganghttps://help.obsidian.md/cliI\u2019ve been having a lot of fun recently using AI CLIs with Obsidian. No plugins necessary because it\u2019s just a directory tree of markdown files.reply",
      "I've been using iCloud to sync Obsidian, and have consistently run into the problem that iCloud file container access needs full disk permissions that I don't want to give the agent (or Ghostty). Does everybody use Obsidian's paid sync instead or what? Or SyncThing?reply",
      "I gave up on iCloud sync.After the tenth time iCloud absolutely destroyed my vault\u2019s file layout and scattered copies of my files all over my iCloud Drive, I just gave up and shell out for paid sync now. It\u2019s fine. I don\u2019t mind paying for things I get actual value from.reply",
      "Definitely one of the biggest ROI is to pay for the sync. I regret all years I tried git-based alternatives (it's still useful to have it in git for backup, but not as the main syncing mechanism).reply",
      "I just pay for the sync.I like that I can have some vaults that sync to both my personal and work laptops and other vaults that only sync to one or the other.It\u2019s awfully convenient without any vendor lock in since I can just take my plain markdown files and leave anytime.reply",
      "Just pay for the sync. I used to juggle with git, rsync,  inotify etc and other toolsIts one of the few subscriptions where it actually feels like money well spentreply",
      "I was using SyncThing, and it worked, but any time you have an Obsidian vault open on two devices, or shortly after another, you're always thinking about if you're going to have to clean up a bunch of sync conflict files later. And that mental overhead is not worth saving $4/mo.The conflicts are never hard: it's like a git merge conflict where you just take the latest of every conflict block.reply",
      "I used to use SyncThing, then Dropbox, then iCloud. But then I just caved and paid for Obsidian Sync and it is the best money spent aside from Claude. I don't have to tinker with weird settings anymore or deal with sync issues, it just works.reply",
      "I can't wonder if that's by design to make it hard for a plugin to have it's own sync mechanism. Definitely not proof of this that I know of, but a thought.reply",
      "Obsidian is plain Markdown and JSON files.There can't be a will from the devs to make it hard to sync.It's just that unlike git or Dropbox or whatever, that are just generic \"syncing\" tools, Obsidian Sync has been built to provide the best experience with Obsidian.reply"
    ],
    "link": "https://help.obsidian.md/sync/headless",
    "first_paragraph": ""
  },
  {
    "title": "The happiest I've ever been (ben-mini.com)",
    "points": 330,
    "submitter": "bewal416",
    "submit_time": "2026-02-26T04:13:47 1772079227",
    "num_comments": 151,
    "comments_url": "https://news.ycombinator.com/item?id=47161759",
    "comments": [
      "In the nicest possible way, this is basically the oldest lesson there is.You weren\u2019t happy because you optimized your feelings or had the right opinions. You were happy because you stopped focusing on yourself and became responsible for other people. Six kids needed you, in the real world, every week. That kind of outward focus kills emptiness fast.Chasing happiness, moral righteousness, or political engagement just loops you back into your own head, helping people doesn\u2019t. Feeling good is a side-effect of being useful, not the goal.reply",
      "There\u2019s an entire generation of mostly childless adults who are shocked to find they enjoy contributing to others\u2019 happiness. I have friends like this, their only purpose in life is to have no responsibilities, FIRE, and never give to anyone but themselves. Seems like  \na terribly depressing way to live but pretty common in tech/upper middle class circles.reply",
      "> but pretty common in tech/upper middle class circles.It's common in some tech and upper middle class bubbles, but outside of some startups and a few VHCOL cities most of the 40+ people in tech I encounter have families.I think the mindset is most popular in internet bubbles like Reddit. Reddit went mainstream a decade ago and many people in their 30s and 40s grew up reading a lot of Reddit. Reddit cleaned up their popular subreddits list years ago, but for a while subreddits like r/childfree were constantly in everyone's default feeds. Redditors would talk about people who had kids as \"breeders\" as a derogatory term and treat them like they'd made terrible decisions with their lives.I didn't realize how much this carried over into the real world until my friends and I started having kids. I knew a few people who treated our decisions like we were making terrible mistakes and throwing our lives away. I still encounter people from younger generations who are confused when I say that I like spending time with my kids. They can't imagine how that would be enjoyable in any way. When you grow up with your chosen social media telling you that the smart people are maximizing their bank accounts, minimizing their responsibilities, and doing as little as possible to get there, they can't fathom how someone could be happy with kids.reply",
      "I am about to hit 40 soon and have an alternative take on all that. I agree reddit was and still is a very toxic echo chamber, but the rest of us who have avoided having kids shouldn't be lumped in with those people.I came from a big family and grew up somewhat poor watching remorseful adults who didn't recognize the gravity of bringing a life into this world, let alone several, basically drink themselves to death to cope.My social life is mostly offline and I enjoy helping people in any way I can, but I am fully aware of my own flaws. I find balance by being generous in what seems like a million other ways I might not have the energy or time for if I had a family. To each their own.reply",
      "Sure why not get trapped youself with responsibilities and work your life off making rich people even richer.reply",
      "People who want to be childless usually champion the importance of building strong community through friends and neighbors, just because they don\u2019t want kids doesn\u2019t mean they don\u2019t want to contribute to others\u2019 happiness lol. People wanting FIRE is a lot more to do with the current economy and wealth of useless or harmful jobs than kidsreply",
      "> People who want to be childless usually champion the importance of building strong community through friends and neighbors,This describes all of the childless people age 50 and older than I know.It does not describe the social media r/childfree mindset people I know at all. They have their bubble of friends they keep in touch with only when they feel like it but that's about it.There's a big difference between childless and r/childfree style people, though.> People wanting FIRE is a lot more to do with the current economy and wealth of useless or harmful jobs than kidsFIRE rose to popularity before this economy, though. It felt like peak FIRE was during ZIRP when it was easy to get a high paying tech job even if you barely had the skills for it. All the blogs and influencers made it sound so easy to just keep that going straight into early retirement as long as you continued living an austere lifestyle, which came with implied advice to avoid having kids.I followed several of the FIRE blogs and forums in the early days but had to stop reading after they started filling up with people convinced they could retire at age 36 with $1.2 million in the bank because they they lived frugally last year and decided they could keep coasting that way for another 50 years without their lifestyle changing. I remember reading a few disaster stories from people who thought they were doing leanFIRE with their spouse until their spouse grew up and realized they actually wanted kids and to be married to someone who had a little more ambition in life. I know these stories aren't what FIRE is supposed to be about in the theoretical optimal sense, but there were so many stories like this that the forums just felt like a sad place to be.reply",
      "I've read and posted to r/childfree and similar subs in the past, but I quickly came to realize that the people there are not your typical child-free people.They're mostly bitter anti-child people who rail against what they see as entitlements that parents get that non-parents don't. They derisively call parents petty and mean things like \"breeders\" and seem to be a very cynical bunch. I'm not saying their feelings are always ridiculous; certainly some of them have reasonable reasons for feeling the way they do. But they're a mostly-toxic, vocal minority.It really annoys me when people assume all (or even a significant number) of childfree people are like those reddit folks (not accusing you of that, just saying in general.And I don't get the automatic association between FIRE and childfree that some people are making here. Sure, FIRE is easier if you don't have kids, but IME the two groups are only loosely connected, at most.reply",
      "I think more than FIRE people should just focus on FI. You still have to do something with your day after becoming financially independent and a job is still one of many good ways to contribute to the community even if you don't technically need one. So retiring is an option but not the only one.On the other hand it remains quite confusing that after centuries of capital achieving vastly better results than labour people still keep going for labouring as their primary strategy. Building up a strong income-generating capital base is just common sense and it is an extremely good idea to have enough that you could technically avoid working if it made sense.reply",
      "> dont want to deal with kidsSomeone has to bring up the next generation, the no kids crowd want all the luxury of having the next generation without putting in the effort or spending the money.reply"
    ],
    "link": "https://ben-mini.com/2026/the-happiest-ive-ever-been",
    "first_paragraph": "February 25, 2026It was around January 2020. I became the head coach of a youth basketball team.I was a few months into my first job out of college, and I was feeling\u2026 empty. I couldn\u2019t explain why, so I set out to fill the void. I built side projects, went drinking with coworkers, and got really into the upcoming election. These all felt like things I should be doing as the yuppy I had just become, but the emptiness resided.Indiana loves its basketball, so it was easy for me to find a local gym to play pickup. I became friendly with the regulars and the staff. One day, the athletic director told me they were looking for a volunteer assistant basketball coach for the middle school league. Being a former camp counselor, the idea intrigued me. Unexpectedly, the \u201cassistant\u201d position became the \u201chead\u201d position, and I was quickly thrown into a clinic, where I had to draft all my players by the end of the session.Team drafted. 6 kids. 1 game per week. 2 practices per week. 14 parent emails ("
  },
  {
    "title": "Show HN: Xmloxide \u2013 an agent made rust replacement for libxml2 (github.com/jonwiggins)",
    "points": 25,
    "submitter": "jawiggins",
    "submit_time": "2026-02-28T23:44:41 1772322281",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=47201816",
    "comments": [
      "A comment on libxml, not on your work:\nFunny how so many companies use this library in production and not one steps in to maintain this project and patch the issues.\nWhat a sad state of affairs we are in.reply",
      "Yeah I agree, maintaining OS projects has been a weird thing for a long time.I know a few companies have programs where engineers can designate specific projects as important and give them funds. But it doesn't happen enough to support all the projects that currently need work, maybe AI coding tools will lower the cost of maintenance enough to improve this.I do think there are two possible approaches that policy makers could consider.1) There could probably be tax credits or deductions for SWEs who 'volunteer' their time to work on these projects.2) Many governments have tried to create cyber reserve corps, I bet they could designate people as maintainers of key projects that they rely on to maintain both the projects as well as people skilled with the tools that they deem important.reply",
      "> I do think there is something interesting to think about here in how coding agents like Claude Code can quickly iterate given a test suite.This is a point I've tried to advocate for a while. Specially to empower non coders and make them see that we CAN approach automation with control.Some aspects will be the classic unit or integration tests for validation.  Others, will be AI Evals [1] which to me could be the common language for product design for different families/disciplines who don't quite understand how to collaborate with each other.The amount of progress in a short time is amazing to see.- [1] https://ai-evals.io/reply",
      "Amazing work! I'd love to hear more details about your workflow with Claude Code.As a side note and this isn't a knock on your project specifically. I think the community needs to normalize disclaimers for \"vibe-coded\" packages. Consumers really need to understand the potential risks of relying on agent-generated code upfront.reply",
      "Yeah its a fair point. I wondered if it might be irresponsible to publish the package because it was made this way, but I suspect I'm not the first person to try and develop a package with Claude Code, so I think the best I can do is be honest about it.As for the workflow, I think the best advice I can give is to setup as many guardrails and tools as possible, so Claude and do as many iterations before needing any intervention. So in this case I setup pre-commit hooks for linting and formatting, gave it access to the full testing suite, and let it rip. The majority of the work was done in a single thinking loop that lasted ~3 hours where Claude was able to run the tests, see what failed, and iterate until they all passed. From there, there was still lots of iterations to add features, clean up, test, and improve performance - but allowing Claude to iterate quickly on it's own without my involvement was crucial.reply",
      "> arena-based tree with zero unsafe in the public APIWhy \"in the public API\"? Does this imply it's using unsafe behind the hood? If so, what for?reply",
      "Yeah I'm a bit confused because you can have an entirely unsafe code base with just the public interface marked as safe. No unsafe in the interface isn't a measure of safety at all.reply",
      "It is a measure of the intended level of care that the users of your interface have to take. If there's no unsafe in the interface, then that implies that the library has only provided safe interfaces, even if it uses unsafe internally, and that the interface exposed enforces all necessary invariants.It is absolutely a useful distinction on whether your users need to deal with unsafe themselves or not.reply",
      "How does it compare to the original in terms of source code size (number of lines of code?)reply",
      "It's significantly smaller. Because Rust doesn't require header files or memory management, xmloxide is ~40k lines while libxml2 is ~150k lines.reply"
    ],
    "link": "https://github.com/jonwiggins/xmloxide",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A pure Rust reimplementation of libxml2\n      \n\n\n\nA pure Rust reimplementation of libxml2 \u2014 the de facto standard XML/HTML parsing library in the open-source world.libxml2 became officially unmaintained in December 2025 with known security issues. xmloxide aims to be a memory-safe, high-performance replacement that passes the same conformance test suites.Parsing throughput is competitive with libxml2 \u2014 within 3-4% on most documents, and 12% faster on SVG. Serialization is 1.5-2.4x faster thanks to the arena-based tree design. XPath is 1.1-2.7x faster across all benchmarks.Parsing:Serialization:XPath:Key optimizations: arena-based tree for fast serialization, byte-level pre-checks for character validation, bulk text scanning, ASCII fast paths for name parsing, zero-copy element name splitting, inline entity resolution, XPath // step "
  },
  {
    "title": "Block the \u201cUpgrade to Tahoe\u201d Alerts (robservatory.com)",
    "points": 139,
    "submitter": "todsacerdoti",
    "submit_time": "2026-02-28T19:04:01 1772305441",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=47198977",
    "comments": [
      "I accidentally hit the wrong button a few weeks ago and upgraded to Tahoe. I didn't think it was that big a deal at the time, I'd just been putting it off.But having used it for a few weeks now I can confirm it is a strict downgrade over Sequoia for me. I use none of the new features it has introduced, and the changes to existing features are just worse.Some UI animations are slow and jittery - and this is on an M4 Pro. The Finder has gone from fine to janky once again, especially with horizontal scroll. The window corners and mouse interactions are indeed annoying (I'd assumed the many complaints were at least slight hyperbole). Left-aligned window titles are unbalanced and ugly. I've had weird (visual) app duplication issues with the Application smart-folder in the Dock. Cross-device copy-paste SEEMS to be more flaky than usual. And most petty of all I really don't like the new icons - especially the Trash icon for some reason.reply",
      "I did the same mistake a few weeks ago ; my company enforces security updates and I picked the Tahoe update instead of the security one. I told myself, what the hell, might as well give it a try!I wiped my computer and reinstalled Sequoia last week.reply",
      "Also Apple Music is much worse (harder to bring miniplayer, seek bar harder to use) and list of misfeatures goes on and on and onreply",
      "Good to know. My dad recently asked and I didn't know the pros/cons. I haven't upgraded but that's because I don't have a need to. He has a new Mac mini, and I thought it might make sense for him. But it sounds like it's not an upgrade, and is possibly a downgrade, especially if it will make things harder to find.reply",
      "> Some UI animations are slow and jittery - and this is on an M4 ProOn an M4 Pro! Pure planned obsecelence. Noticed it regularly with major MacOS releases. Nothing will convince me otherwise.reply",
      "I got an M5 and it unfortunately had Tahoe preinstalled. Out of the box, Quicklook is choppy. My non-Tahoe M1 is buttery smooth. I don't know how Apple managed to ruin a feature that's been running smoothly for decades.reply",
      "Yeah they should have bought the M5 Pro /sreply",
      "People with apple hardware quickly realize that they have too much moneyreply",
      "I have Tahoe on my work laptop and Sequoia on my personal desktop, and the thing that keeps me the most rooted on Sequoia is the padding. Everything on Tahoe is padded to hell and back. And the new tab design sucks so much. iTerm2 tabs look fucking terrible in it.reply",
      "they have really tried hard to make the entire OS less usable. I'm not an \"iToddler\", I paid for a Unix workstation and will not have lower information density forced onto me.reply"
    ],
    "link": "https://robservatory.com/block-the-upgrade-to-tahoe-alerts-and-system-settings-indicator/",
    "first_paragraph": ""
  },
  {
    "title": "Addressing Antigravity Bans and Reinstating Access (github.com/google-gemini)",
    "points": 201,
    "submitter": "RyanShook",
    "submit_time": "2026-02-28T13:50:13 1772286613",
    "num_comments": 171,
    "comments_url": "https://news.ycombinator.com/item?id=47195371",
    "comments": [
      "Way too risky to use Google services like this tied to your primary account. There\u2019s too much risk of cross damage. Imagine losing access to your Gmail because some Gemini request flags you as an undesirable.  The digital death sentence of losing access to your email with a company that notoriously has no way for the average human to contact a human is not worth the risk.reply",
      "> Way too risky to use Google services like this tied to your primary account.I would also avoid using the same credit card between accounts. I used a Venmo card for my chrome extension account as an extra layer of separation.reply",
      "Use a custom domain and don't use google for email.And if you do use your gmail address just forward it and start to transition to something else. With time everything of importance has been transferred.reply",
      "How do you even pull away from a Gmail address? I'm nearly twenty years into that service. Getting banned would be absolutely devastating...reply",
      "Use your own domain to sign up for a paid email service, provided by a company that focuses on email. I use Fastmail, but there are many other options.Set up forwarding in Gmail to your new address.Then, whenever you log in to a website or app with your Gmail, take a moment to change it to your new address. In a few weeks, most of your important accounts will be covered. In a few months, almost everything you still actively use will be done.I did this ~5 years ago and the only thing that still arrives at my Gmail is spam.reply",
      "Same here but ~8 years.You can mitigate/speed the process using your password manager too.I still use a filter in my email so that if something comes in under my Gmail, it gets a special tag that I can filter on and treat those as a todo list. Rarely happens beyond the occasional Google Meet connection.reply",
      "I did this but don't forward. Instead, every new email in Gmail I got would prompt me to go update that service's contact info for me.It probably doesn't matter, but it made me feel a little better because that way Google wouldn't have direct info on to which email/domain I transfered (ignoring other Gmail contacts that start emailing me at my new address(es) ).reply",
      "Solid advice, but I want to double, watch out for things you only log into once a year.Making a new local account on your machine is a good first step.reply",
      "For quite some time (approx 8 years) I've used an email forwarding (Blur, but any works) to avoid spam.This looks like perfect case for change of email, since lot of these accounts can be moved out from Gmail by changing the address that email is forwarded too.Looks like all this hassle with generating a new email for each service pays for the second time (by ease of changing the main mail), in addition to spam and privacy protection.reply",
      "^this is the way.You can buy a domain name for like $10 per year; I recommend getting it from porkbun.com.Cloudflare.com is good too, EXCEPT if you buy your domain from them, you'll be required to use their nameservers until and unless you transfer your domain elsewhere (which you won't be able to do for a while). Though to be fair, their free DNS is good and lots of people use it anyway. It makes email setup slightly more complicated, but it's still doable.Spaceship.com also has a pretty good reputation, but I think their customer service isn't as good, they're quite new, and they're owned by Namecheap (a bigger domain registrar with a much worse reputation).Whatever you do, DO NOT buy from GoDaddy. Do not even search for the domain you're considering on GoDaddy. Literally any option is better than GoDaddy.By far the most reliable TLD options are .com, .net, and .org. These will look relatively trustworthy for email, and the price stays very very stable from year to year. If you don't want to think about it, just get one of these. You can even still find single dictionary word domains for .org or .net relatively easily.Do not buy any domain marked \"premium\". This means the owner of the TLD can change the price at renewal as dramatically as they want, for any reason (e.g. if you have a website hosted at that domain that becomes popular). Your $20 per year domain might suddenly become a $300 or $3000 per year domain for no reason but greed, and you wouldn't be able to do anything about it.Non-premium nTLD's (.club, .horse, .rocks, .theater, etc) can increase quite dramatically in price, BUT the price is required to be set the same for all domains using that nTLD, so they can't target any individual person for having a successful website or whatever. Also, you can pre-buy up to 10 years, which locks in your price for those 10 years. I'd still not recommend them for a primary email, but it's better than buying a \"premium\" domain. Just be aware that the yearly price might unexpectedly increase in the future.Some country code TLD's are also good, but for email, probably stay away from the ones that spammers like to use.___Anyway, what I actually originally meant to comment about is: if you set up forwarding from gmail and don't check that account regularly anymore, I recommend setting up a gmail filter rule that forwards all your gmail spam to you (their regular forwarding setting leaves it out and just sends it to the gmail spam folder). It's a little annoying to have to re-flag some of the spam as spam in your new email, but gmail has a habit of marking non-spam as spam for me, and if you're not regularly checking that spam folder you can easily miss important email.reply"
    ],
    "link": "https://github.com/google-gemini/gemini-cli/discussions/20632",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n -\n           \n Over the past week, we saw reports from Gemini CLI users experiencing account disruptions. These were the result of a series of Antigravity bans rolled out to address violations of the Antigravity Terms of Service (ToS), specifically the use of 3rd party tools or proxies to access Antigravity resources and quotas.Because of the backend layer where abuse prevention occurs, bans for Antigravity usage also blocked access to Gemini CLI and Gemini Code Assist. We acknowledge the disruption this caused and are taking steps to restore access.In coordination with Antigravity we are conducting a system-wide automated unban for accounts recently flagged for breaking ToS. This means:Going forward if an account is flagge"
  },
  {
    "title": "Woxi: Wolfram Mathematica Reimplementation in Rust (github.com/ad-si)",
    "points": 249,
    "submitter": "adamnemecek",
    "submit_time": "2026-02-25T18:24:46 1772043886",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=47155526",
    "comments": [
      "My Bona fides: I've written my own Mathematica clone at least twice, maybe three times. Each time I get it parsing expressions and doing basic math, getting to basic calculus. Then I look up the sheer cliff face in front of me and think better of the whole thing.There is an architectural flaw in Woxi that will sink it hard. Looking through the codebase things like polynomials are implemented in the rust code, not in  woxilang. This will kill you long term.The right approach is to have a tiny core interpreter, maybe go to JIT at some point if you can figure that out. Then implement all the functionality in woxilang itself. That means addition and subtraction, calculus, etc are term rewriting rules written in woxilang, not rust code.This frees you up in the interpreter. Any improvements you make there will immediately show up over the entire language. It's also a better language to implement symbolic math in than rust.It also means contributors only need to know one language: woxilang.\nNo need to split between rust and woxilang.reply",
      "I noticed the same thing, having also written an interpreter for the Wolfram language that focused on the core rule/rewriting/pattern language.  At its heart it\u2019s more or less a Lisp-like language where the core can be quite small and a lot of the functionality built via pattern matching and rewriting atop that.  Aside from the sheer scale of WL, I ended up setting aside my experiments replicating it when I did performance comparisons and realized how challenging it would be to not just match WL in functionality but performance.Woxi reminds me of some experiments I did to see how far vibe coding could get me on similar math and symbolic reasoning tools.  It seems like unless you explicitly and very actively force a design with a small core, the models tend towards building out a lot of complex, hard-coded logic that ultimately is hard to tune, maintain, or reason about in terms of correctness.Interesting exercise with woxi in terms of what vibe coding can produce.  Not sure about the WL implementation though.(For context, I write compiler/interpreter tools for a living - have been for a couple decades)reply",
      "I\u2019ve personally had luck at correcting the complex one-off logic the agents produce with the right prompting.and when I say prompting, I just mean code review feedback. All of this is engineering management. I review code. I\u2019ll point out architectural flaws if they matter and I use judgement to determine if they matter. Code debt is a choice, and you can afford it in some situations but not others. We don\u2019t nit over style because we have a linter. Better documentation results in better contribution quality. etc.Agent coordination? Gastown? All I hear is organizational design and cyberneticsreply",
      "Mh, I thought about this a little and came actually to exactly the opposite conclusion: Implement as much as possible in Rust to get the fastest code possible. Do you have any more insights why this should not be possible / unsustainable?reply",
      "You have two distinct products 1) An interpreter 2) a math language.\nDon't write your math in some funny imperative computer language.Keep the interpreters surface area as small as possible. Do some work to make sure you can accelerate numeric, and JIT/compile functions down to something as close to native as you can.Wolfram, and Taliesin Beynon have both said Wolfram were working internally to get a JIT working in the interpreter loop. Keep the core small, and do that now while it's easy.Also, it's just easier to write in Mathematica. It's probably 10x smaller than the rust code:    f[x_Integer]:=13*x;\n    f::help:=\"Multiplies x by 13, in case you needed an easy function for that.\"\n\nEDIT: Another important thing to note is the people who really deeply know specific subjects in math won't be the best, or even good rust programmers. So letting them program in woxilang will give the an opportunity to contribute which they wouldn't have had otherwise.reply",
      "Symbolic manipulation?reply",
      "Switching out to an interpreted language has got to be anathema to a rewrite-it-in-Rust projectreply",
      "implementing addition in woxilang itself?? this gotta be terribly slow. am i missing something?reply",
      "Mathematica has symbolic and infinite-precision addition, so you can't automatically take advantage of obvious compiled code.reply",
      "What? Arbitrary precision arithmetic implemented in a compiled language will be faster than the alternative. This is no great mystery. The same is true of essentially all low-level symbolic or numerical math algorithms. You need to get to a fairly high level before this stops being true.reply"
    ],
    "link": "https://github.com/ad-si/Woxi",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Wolfram Language / Mathematica reimplementation in Rust (Wolfram oxidized)\n      An interpreter for the Wolfram Language powered by Rust.The initial focus is to implement a subset of the Wolfram Language\nso that it can be used for CLI scripting and notebooks.\nFor example:It has full support for Jupyter Notebooks including graphical output:TipTry it out yourself in our\nJupyterLite instance!Check out the CLI tests directory\nto see all currently supported commands and their expected output.\nAll tests must pass with Woxi and WolframScript.Also check out the functions.csv file\nfor a list of all Wolfram Language functions and their implementation status.Woxi runs faster than WolframScript as there is no overhead of starting a kernel\nand verifying its license.You can easily install it with Rust's cargo:If you want to build Woxi from source"
  },
  {
    "title": "H-Bomb: A Frank Lloyd Wright Typographic Mystery (inconspicuous.info)",
    "points": 8,
    "submitter": "mrngm",
    "submit_time": "2026-02-26T09:18:57 1772097537",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=47163779",
    "comments": [
      "I would not be surprised if  the manufactured letters and their installation was based on hand hand drawn letters.That it is not aesthetically obvious, suggests it was drawn that way and not a mistake. Good typography is subtle and bespoke typography even more so.reply",
      "The article makes clear that the orientation of the lettering has changed over time, which counts against the idea that what it is now necessarily reflects the original intent.reply",
      "I was more bothered by the extraneous word spacing on the second line, between \u201cand\u201d and \u201cthe.\u201d Is it just me?reply"
    ],
    "link": "https://www.inconspicuous.info/p/h-bomb-a-frank-lloyd-wright-typographic",
    "first_paragraph": ""
  },
  {
    "title": "Building a Minimal Transformer for 10-digit Addition (alexlitzenberger.com)",
    "points": 36,
    "submitter": "kelseyfrog",
    "submit_time": "2026-02-28T22:10:21 1772316621",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=47200828",
    "comments": [
      "Looks like a Tiny Analytic transformer, RNN is arguably a better choice if you are gonna handwire an architecture to mechanically do addition. Learning is about discovering the patterns and algorithm from data. Wiring a machine to follow a procedure defeats that purpose.reply",
      "it proves that the algorithm is embeddable in a bigger transformer of ~similar architecture.reply",
      "Related: https://news.ycombinator.com/item?id=36851494, discussion of https://www.evanmiller.org/attention-is-off-by-one.html (2023).reply",
      "I somewhat feel that using floating point arithmetic for what should be a symbol manipulation exercise is cheating. The deserialisation technique is interesting enough that I'm not really upset, though.> The codex solution reversed the order which makes sense for making carry logic easy, but it is less clean.That's the approach I'd have gone with. I've long been an advocate of little-endian numerical representations. That said, if there's a maximum number of digits, it's straightforward to implement the circuitry needed to do calculate the most-significant digit of the result in one go; and I somehow doubt the AI-generated solution really took advantage of the tricks that little-endian allows.> At some point I set claude code on some debugging to my surprise I don\u2019t recall it actually solving any of the bugs, it seemed much more concerned with \u201ccorrecting\u201d the funky things I was intentionally doing.It baffles me that somebody capable of this kind of work would find this surprising. The process that allows LLMs to find bugs in code is the same process that entreats them to \"correct\" such creativity: their understanding of the world begins and ends at statistical plausibility, and they cannot truly comprehend things (though they can do a very good job of pretending, given sufficient training data).reply",
      "symbol manipulation in transformers is fp arithmetic?reply",
      "What's the difference between comprehending and understanding in this context?reply"
    ],
    "link": "https://alexlitzenberger.com/blog/post.html?post=/building_a_minimal_transformer_for_10_digit_addition",
    "first_paragraph": ""
  },
  {
    "title": "Verified Spec-Driven Development (VSDD) (gist.github.com)",
    "points": 147,
    "submitter": "todsacerdoti",
    "submit_time": "2026-02-28T16:58:54 1772297934",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=47197595",
    "comments": [
      "Everything in this post stems from the assumption that you already know what you're doing, which is probably true for things you've built before. But I hope we can agree that you can't spec out something you have no clue how to build, let alone write the tests before you've even explored the boundaries of the problem space. That's completely unreasonable.My second point is that this approach is fundamentally wrong for AI-first development. If the cost of writing code is approaching zero, there's no point investing resources to perfect a system in one shot. What matters more is how fast you can explore the edges. You can now spin up five agents to implement five different versions of the thing you're building and simply pick the best one.In our shop, we have hundreds of agents working on various problems at any given time. Most of the code gets discarded. What we accept to merge are the good parts.reply",
      "Nothing of what you write here matches my experience with AI.Specification is worth writing (and spending a lot more time on than implementation) because it's the part that you can still control, fully read, understand etc. Once it gets into the code, reviewing it will be a lot harder, and if you insist on reviewing everything it'll slow things down to your speed.> If the cost of writing code is approaching zero, there's no point investing resources to perfect a system in one shot.THe AI won't get the perfect system in one shot, far from it! And especially not from sloppy initial requirements that leave a lot of edge (or not-so-edge) cases unadressed. But if you have a good requirement to start with, you have a chance to correct the AI, keep it on track; you have something to go back to and ask other AI, \"is this implementation conforming to the spec or did it miss things?\">  five different versions of the thing you're building and simply pick the best one.Problem is, what if the best one is still not good enough? Then what? You do 50? They might all be bad. You need a way to iterate to convergencereply",
      "This. Waterfall never worked for a reason. Humans and agents both need to develop a first draft, then re-evaluate with the lessons learned and the structure that has evolved. It\u2019s very very time consuming to plan a complex, working system up front. NASA has done it, for the moon landing. But we don\u2019t have those resources, so we plan, build, evaluate, and repeat.reply",
      "That \"first draft\" still has to start with a spec. Your only real choice is whether the spec is an actual part of project documentation with a human in the loop, or it's improvised on the spot within the AI's hidden thinking tokens.  One of these choices is preferable to the other.reply",
      "So, rollback and try again with the insight.AI makes it cheap to implement complex first drafts and iterations.I'm building a CRM system for my business; first time it took about 2 weeks to get a working prototype. V4 from scratch took about 5 hours.reply",
      "AI is also excellent at reverse engineering specs from existing code, so you can also ask it to reflect simple iterative changes to the code back into the spec, and use that to guide further development. That doesn't have much of an equivalent in the old Waterfall.reply",
      "are you intentionally being vague here becuase it's a HN comment and you can't be arsed going into detail?or do you literally type> Look at the git repo that took us 2 weeks, re-do it in another fresh repo... do better this time.I think you don't and that your response is intentional misdirection to pointlessly argue against the planning artifact approach.reply",
      "There\u2019s a real tension here.If you are vibe-coding, this approach is definitely going to kill you buzz and lose all the rapid iteration benefits.But if you are working in an existing large system, vibe coding is hard to bring into the core. So I think something more formal like OP is needed to reap major benefits from AI.reply",
      "This is just AI-written slop, but even if you're vibe coding and want to go for rapid iteration, you still benefit by having the AI write out a broad plan of what it's going to do and looking it over before telling it to implement it. One-shot vibe coding is totally worthless, but the more you're aware of what the AI is thinking about and ready to revise its plans, the better it can potentially do.reply",
      "If the price of code is zero then changing the spec also costs zero in terms of code and. This is what always was the problem with specs before. You'd write one, run it through the prover, write the code, then have to throw out the whole thing because there was a business case you didn't account for.Now the bottom 98% can be given to a robot with a clear success signal other than 'it looks about right'.reply"
    ],
    "link": "https://gist.github.com/dollspace-gay/d8d3bc3ecf4188df049d7a4726bb2a00",
    "first_paragraph": "\n        Instantly share code, notes, and snippets.\n      Verified Spec-Driven Development (VSDD) is a unified software engineering methodology that fuses three proven paradigms into a single AI-orchestrated pipeline:VSDD treats these not as competing philosophies but as sequential gates in a single pipeline. Specs define what. Tests enforce how. Adversarial verification ensures nothing was missed. AI models orchestrate every phase, with the human developer serving as the strategic decision-maker and final authority.Nothing gets built until the contract is airtight \u2014 and the architecture is verification-ready by design.The human developer describes the feature intent to the Builder. The Builder then produces a formal specification document for each unit of work. Critically, this phase doesn't just define what the software does \u2014 it defines what must be provable about it and structures the architecture accordingly.Step 1a: Behavioral SpecificationThe Builder produces the functional cont"
  },
  {
    "title": "Qwen3.5 122B and 35B models offer Sonnet 4.5 performance on local computers (venturebeat.com)",
    "points": 224,
    "submitter": "lostmsu",
    "submit_time": "2026-02-28T20:20:00 1772310000",
    "num_comments": 145,
    "comments_url": "https://news.ycombinator.com/item?id=47199781",
    "comments": [
      "If you're new to this: All of the open source models are playing benchmark optimization games. Every new open weight model comes with promises of being as good as something SOTA from a few months ago then they always disappoint in actual use.I've been playing with Qwen3-Coder-Next and the Qwen3.5 models since they were each released.They are impressive, but they are not performing at Sonnet 4.5 level in my experience.I have observed that they're configured to be very tenacious. If you can carefully constrain the goal with some tests they need to pass and frame it in a way to keep them on track, they will just keep trying things over and over. They'll \"solve\" a lot of these problems in the way that a broken clock is right twice a day, but there's a lot of fumbling to get there.That said, they are impressive for open source models. It's amazing what you can do with self-hosted now. Just don't believe the hype that these are Sonnet 4.5 level models because you're going to be very disappointed once you get into anything complex.reply",
      "Respectfully, from my experience and a few billions of tokens consumed, some opensource models really are strong and useful. Specifically StepFun-3.5-flash https://github.com/stepfun-ai/Step-3.5-FlashI'm working on a pretty complex Rust codebase right now, with hundreds of integration tests and nontrivial concurrency, and stepfun powers through.I have no relation to stepfun, and I'm saying this purely from deep respect to the team that managed to pack this performance in 196B/11B active envelope.reply",
      "What are you running that model on?reply",
      "I just use openrouter, it's free for now. But I would pay 30-100$ to use it 24/7.reply",
      "Ah, I thought you meant you were running it locally.reply",
      "All models are doing that. Not only the open source ones.I bet the cloud ones are doing it a lot more because they can also affect the runtime side which the open source ones can't.reply",
      "Are there any up-to-date offline/private agentic coding benchmark leaderboards?If the tests haven't been published anywhere and are sufficiently different from standard problems, I would think the benchmarks would be robust to intentional over optimization.Edit:\nThese look decent and generally match my expectations:https://www.apex-testing.org/reply",
      "\"When a measure becomes a target, it ceases to be a good measure.\"Goodhart's law shows up with people, in system design, in processor design, in education...Models are going to be over-fit to the tests unless scruples or practical application realities intervene. It's a tale as old as machine learning.reply",
      "It's not just the open source ones.The only benchmarks worth anything are dynamic ones which can be scaled up.reply",
      "Are you saying that the benchmarks are flawed?And could quantization maybe partially explain the worse than expected results?reply"
    ],
    "link": "https://venturebeat.com/technology/alibabas-new-open-source-qwen3-5-medium-models-offer-sonnet-4-5-performance",
    "first_paragraph": ""
  },
  {
    "title": "Deterministic Programming with LLMs (mcherm.com)",
    "points": 18,
    "submitter": "todsacerdoti",
    "submit_time": "2026-02-25T22:17:29 1772057849",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=47158834",
    "comments": [
      "At what point does this just wrap all the way back around to being genetic algorithms?I'm also reminded of the old software called Formulize, which could take in a set of arbitrary data and find a function that described it. http://nutonian.wikidot.com/reply",
      "If you extend this line of thinking a lot, given we traditionally author the software, everything kind of boils down to a genetic algorithm.reply",
      "> But like humans \u2014 and unlike computer programs \u2014 they do not produce the exact same results every time they are used. This is fundamental to the way that LLMs operate: based on the \"weights\" derived from their training data, they calculate the likelihood of possible next words to output, then randomly select one (in proportion to its likelihood).This is emphatically not fundamental to LLMs! Yes, the next token is selected randomly; but \"randomly\" could mean \"chosen using an RNG with a fixed seed.\" Indeed, many APIs used to support a \"temperature\" parameter that, when set to 0, would result in fully deterministic output. These parameters were slowly removed or made non-functional, though, and the reason has never been entirely clear to me. My current guess is that it is some combination of A) 99% of users don't care, B) perfect determinism would require not just a seeded RNG, but also fixing a bunch of data races that are currently benign, and C) deterministic output might be exploitable in undesirable ways, or lead to bad PR somehow.reply",
      "Deterministic output is incompatible with batching, which in turn is critical to high utilization on GPUs, which in turn is necessary to keep costs low.reply",
      "> The Solution is Code-Checking CodeI'm finding code falls into two categories. Code that produces known results and code that produces results that are not known. For example, creating a table with a pagination component with a backend that loads the first 30 rows ordered by date descending from the database on page 1 and the second set of 30 rows on page 2. We know what the code is supposed to output, we know what the result looks like. On the other hand, there is code that does statistical analysis on the 30 rows of data. This is different because we don't know what the result is.The known result code is easy to use an LLM with. I have a skill that will iterate with an OODA loop \u2014 observe, act, and validate. It will in the validate step take screenshots and even without telling it, it will query the database from the CLI, compare the rendered row data to the database data. It will more surprisingly make sure that all the components are responsive and render beautifully on mobile. I'm orders of magnitude past linting here which is solved with Biome.The statistical analysis is different. The only way I can know for sure of the result is by writing the code painstakingly by hand. The LLM will always produce specious lies. It will fabricate and show me what I want to see, not the truth. This is because until it is written manually by hand, there is no ground truth. In this case, there is no code checking code.reply",
      "this is a long article that doesn't say much at all. likely generated by AI?it goes on for ages just to reach the point of \"write the tests first\"reply",
      "How does writing tests, or in the new fashion, stealing tests from somewhere else make anything deterministic?LLMs really cause diminished reasoning, or in terms that LLM people might understand: Your minds have been quantized!reply",
      "soonreply"
    ],
    "link": "https://www.mcherm.com/deterministic-programming-with-llms.html",
    "first_paragraph": "\n      If, like me, you regularly read programming blogs (and you do, otherwise you wouldn't be\n      seeing these words), then you are well aware that our industry is currently deep in the\n      throes of a drastic change and more than half of all those blog articles are currently\n      involved in debating the best way for our industry to adapt to the advent of LLMs (large\n      language models) that are capable of writing code.\n    \n      Much has been said on the ethics of LLM coding, on the best approach for using it, and on\n      how to use AI agents effectively. In this essay, I would like to make one contribution to\n      this discussion: I would like to talk about how LLMs can be used in a deterministic way. I\n      am not trying to suggest this is the only way to use them, but I do think it is valuable to\n      think about it as one possible tool to use.\n    \n      Before I look at my own industry, I want to take a look at what people are doing in a\n      different area that "
  },
  {
    "title": "Werner Herzog Between Fact and Fiction (thenation.com)",
    "points": 65,
    "submitter": "Hooke",
    "submit_time": "2026-02-27T08:27:45 1772180865",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=47178051",
    "comments": [
      "If you are thinking about reading that book, consider the audio book that's read by Werner Herzog himself. I really enjoyed that one, not necessarily because I agree with everything but because I enjoy listening to his voice.reply",
      "Thank you, it's not on audible, where did you buy it?reply",
      "It doesn't appear to be there yet, but keep an eye on Libby, where you can borrow it using a library card, from your local library.For example, here's another Werner Herzog book: https://share.libbyapp.com/title/9611895reply",
      "I bought mine on audible.co.ukreply",
      "I bought it via https://libro.fm/audiobooks/9798217163595-the-future-of-trut..., I could select a local participating bookstore there and it went through them somehow. I choose them because it was DRM free.reply",
      "The Land of Silence and Darkness (1971) mentioned is streaming on Amazon Prime in the USA, amongst other streaming services:https://letterboxd.com/film/land-of-silence-and-darkness/reply",
      "\"Werner Herzog Eats His Shoe\" the 1979 documentary features that old wager with Eroll Morris.Herzog wagers that if his colleague produces \"Gates of Heaven,\" Werner would eat his leather boot.reply",
      "https://archive.is/uLxYireply",
      "I can no longer hear Werner Herzog\u2019s name without thinking of Sad Beige Clothes for Sad Beige Children.reply",
      "The article is hard to read, paywall notwithstanding, and tells us very little about Herzog's book other than that the critic didn't like it.I really appreciate Herzog as an artist. I think Grizzly Man is a unique piece of art, and Herzog's commentary is an integral part of it - original, and very worth listening to.Tonight I was planning to watch either Fitzcarraldo or Aguirre after having listened to Herzog on the Freakonomics podcast earlier this week. But after hearing about the book there, I was really put off by some of the things he said and concluded that the book would be a hard pass for me. Nothing persuaded me that he had anything interesting to add - neither rationally, nor aesthetically - about a topic which has been extensively covered by very diverse thinkers throughout the millennia.reply"
    ],
    "link": "https://www.thenation.com/article/culture/werner-herzog-future-truth/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Now I Get It \u2013 Translate scientific papers into interactive webpages (nowigetit.us)",
    "points": 186,
    "submitter": "jbdamask",
    "submit_time": "2026-02-28T13:29:36 1772285376",
    "num_comments": 99,
    "comments_url": "https://news.ycombinator.com/item?id=47195123",
    "comments": [
      "I also have a a scratch-my-own-itch project[1] that leverages an LLM as a core part of its workload. But it's so niche I could never justify opening it up to general use. (I haven't even deployed it to the web because it's easier to just run it locally since I'm the only user.)But it got me interested in a topic I have been calling \"token economization.\" I'm sure there's a more common term from it but I'm a newb to this tech. Basically, how to optimize the \"run rate\" for token utilization per request down.Have you taken a stab at anything along this vein? Like prompt optimization, and so on? Or are you just letting 'er rip and managing costs by reducing request volume? (Now that I've typed this comment out I realize there is so much I don't know about basic stuff with commercial LLM billing and so on.)[1] https://github.com/mattdeboard/itzuli-stanza-mcpedit:I asked Claude to educate me about the concepts I'm nibbling at in this comment. After some back-and-forth about how to fetch this link (??), it spit out a useful answer https://claude.ai/share/0359f6a1-1e4f-4ff9-968a-6677ed3e4d14reply",
      "I like the idea here, but the final product is just so far from what good interactive articles/explanations actually look like. E.g., this style of article:- https://mlu-explain.github.io/decision-tree/- any article from distill.pub- any piece from NYTreply",
      "That decision-tree page is killer!reply",
      "Well, i do not understand the concept.\nMaybe i am too used to read paper: read the abstract to get a digest of the results, read the intro to understand the problem, skip all the rest as it is too technical or only for benchmark.\nIn the app, i selected a few paper, as i did not know anything about the selecter paper, comparing frog A doing magic stuff is helpless. Yet, the interface is great, i think this can be improve for true understanding.reply",
      "I hear you.For me personally, the pain point is being interested in more papers than I can consume so I\u2019ve gotten into the habit of loading papers into LLMs as a way to quickly triage. This app is an extension of my own habit.I also have friends without scientific backgrounds who are interested in topics of research papers but can\u2019t understand them. The reason for the cutesy name, Now I Get It!, is because the prompt steers the response to a laypersonreply",
      "One can smell Claude's touch with these reactive teaching material. Not quite unexpected, every sane teacher uses Claude's artefacts to teach, but not all it spits is useful for convening knowledge.reply",
      "Someone processed a paper on designing kindergartens. Mad props for trying such a cool paper. Really interesting how the LLM designed a soothing color scheme and even included a quiz at the end.https://nowigetit.us/pages/9c19549e-9983-47ae-891f-dd63abd51...reply",
      "There is no chart or table in the original paper. Feels like the one in the LLM-generated page is probably hallucinated?reply",
      "If you mean the bar chart, then yea, it made a representational chart.The caption says, \"Conceptual illustration based on the paper's framework \u2014 higher quality environments lead to better outcomes across all domains.\"reply",
      "Thanks to everyone who tried this today and those who provided feedback. I really appreciate your time. Here are some stats:100 papers processed.Cost breakdown:LLM cost $64AWS cost $0.0003Claude's editorial comment about this breakdown, \"For context, the Anthropic API cost ($63.32) is roughly 200,000x the AWS infrastructure cost. The AWS bill is a rounding error compared to the LLM spend.\"Category breakdown:Computer and Information Sciences 41%Biological and Biomedical Sciences 15%Health Sciences 7%Mathematics and Statistics 5%Geosciences, Atmospheric, and Ocean Sciences 5%Physical Sciences 5%Other 22%There were a handful of errors due to papers >100 pages. If there were others, I didn't see them (but please let me know).I'd be interested in hearing from people, what's one thing you would change/add/remove from this app?reply"
    ],
    "link": "https://nowigetit.us",
    "first_paragraph": "Scientific articles, explained.Upload a scientific PDF and get back a shareable, interactive web page that explains it in plain language.Drop your PDF here, or click to browseWorks best with files under 10 MB"
  },
  {
    "title": "New evidence that Cantor plagiarized Dedekind? (quantamagazine.org)",
    "points": 110,
    "submitter": "rbanffy",
    "submit_time": "2026-02-25T17:28:33 1772040513",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=47154637",
    "comments": [
      "\u201cNoether, who was Jewish, fled from Germany to the U.S., where she died two years later from cancer\u201dIt wasn\u2019t two years, and it wasn\u2019t cancer. These details are unimportant to the (quite interesting) story, but the error is a sign that the author copies information from unreliable secondary sources, which puts the other facts in the article in doubt.I wrote to him about the error when the article first appeared, but received no reply.Noether\u2019s real story is recounted in https://amzn.to/3YZZB4W.reply",
      "I have an opinion about the editorial style of Quanta that I don't think it's popular here (judging by how often they get upvoted), but I think it's a symptom of that.They cover science, but the template they consistently follow is a vague title that oversells the premise and then an article filled with human-interest details and appeals to implications. This makes it easy for everyone to follow along and have an opinion, but I feel like science is a distant backdrop and never the actual subject.In this article, what's the one tidbit of scientific knowledge that we gain? Dedekind's and Cantor's work is described only in poetic abstractions (\"a wedge he could use to pry open the forbidden gates of infinity\"). When the focus is writing a gossip column for eloquent people, precision doesn't matter all that much.reply",
      "I find they are good at identifying interesting topics and writing articles that don't deliver. They remind me of Omni magazine (which I subscribed to at one point). The articles aren't even wrong.reply",
      "The articles are unreadable fluffreply",
      "I think your opinion is popular here. Quanta is, while better than nothing, universally disappointing. It seems like it would be much easier for them to do a better job -- write less vaguely, fact-check more, assume the reader is a bit more intelligent.reply",
      "I'm at the library so I checked your book. You said in there:> However, by October 1933, the issue was straightened out and she was aboard the Bremen, sailing for the United States.Since she died on 14 April 1935, it was 18 months rather than 2 years.That sounds like a rather pedantic correction on your part.That pedanticism is a bad sign and puts your \"correction\" about the cancer in doubt.reply",
      "Complications after surgery to remove a cancerous tumor?reply",
      "https://en.wikipedia.org/wiki/Emmy_NoetherIs the wikipedia page more or less correct or in need of editing in your view?\n(Given that you are probably the current world expert on Noether having written the book)reply",
      "Thank you!  After Benj Edwards and Kyle Orland's Ars Technica article they published using AI (while saying they didn't), and all the while their article was about an AI agent publishing a hit piece on Scott Shambaugh (matplotlib maintainer), I feel like I now assume journalists are using AI and things need to be fact-checked just as we do for our AI interactions.I appreciate hearing about details like this and getting the source directly.  I hope Kristina Armitage and Michael Kanyongolo from Quanta Magazine respond and you can update us!Scott's Blog on Hit Piece: https://theshamblog.com/an-ai-agent-published-a-hit-piece-on...\nArs Editor Note: https://arstechnica.com/staff/2026/02/editors-note-retractio...\nArs Retraction: https://arstechnica.com/ai/2026/02/after-a-routine-code-reje...reply",
      "It\u2019s not like journalists were very accurate before AI. Classic Gell-Mann amnesiareply"
    ],
    "link": "https://www.quantamagazine.org/the-man-who-stole-infinity-20260225/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesFebruary 25, 2026Kristina Armitage, Michael Kanyongolo/Quanta MagazineContributing WriterFebruary 25, 2026When Demian Goos followed Karin Richter into her office on March 12 of last year, the first thing he noticed was the bust. It sat atop a tall pedestal in the corner of the room, depicting a bald, elderly gentleman with a stoic countenance. Goos saw no trace of the anxious, lonely man who had obsessed him for over a year.Instead, this was Georg Cantor as history saw him. An intellectual giant: steadfast, strong-willed, determined to bring about a mathematical revolution over the clamorous objections of his peers.It was here, at the University of Halle in Germany, that Cantor launched his"
  },
  {
    "title": "The whole thing was a scam (garymarcus.substack.com)",
    "points": 619,
    "submitter": "guilamu",
    "submit_time": "2026-02-28T16:51:49 1772297509",
    "num_comments": 169,
    "comments_url": "https://news.ycombinator.com/item?id=47197505",
    "comments": [
      "How is elon differnt? Every billionaries is the same . grow up peoplereply",
      "In a closed society where everybody's guilty, the only crime is getting caught. In a world of thieves, the only final sin is stupidity.This HST quote seems severely outdated by now. They have already been caught, committed all the sins of stupidity and some more. All of it to the clapping mob of people who yearn for some kind of social revenge.And it\u2019s happening everywhere these last years.Who could possibly know we have so many wife beaters?reply",
      "Not a week goes by without me thinking \"what would HST have made of THIS fresh bullshit, if he were alive today\"reply",
      "The only human to authorize a nuclear attack\u2026reply",
      "Hunter Thompson?Not saying he wouldn't have banged on the button, for all he was worth, but no one in their right (or even severely sick) mind would ever let him near it.reply",
      "I've said it a million times, but I'll repeat it.There are a lot of conspiracy nuts like Alex Jones, and the amusing thing to me is that there is a conspiracy of elites who are exerting large amounts of unelected control of the government, and who are actively working to keep you down to enrich themselves, and it's not even a secret.We call these people \"billionaires\", and at this point they don't even bother hiding it.  Trump had a streamlined bribery system with his stupid cryptocurrency and being in charge of a publicly traded company while in office, Musk bought his way in so he could be in charge of a new department and start defunding any organization that has ever tried to investigate him, and there are hundreds of examples.Instead morons like Alex Jones will go on the radio and blame lizards or something, and then his listeners will take that and then start blaming Jews or Mexicans, while cheering on the actual conspiracy that's making their lives terrible.reply",
      "The only war is class war, but those at the top spend a lot of money creating new culture wars instead to keep us busy.reply",
      "\"With, without, And who'll deny it's what the fighting's all about?\"reply",
      "Not to mention trafficking and raping childrenreply",
      "Some people just don\u2019t want to hear it no matter what. Not because they are unusually stupid or inherently evil but because they feel severely hurt by the societal changes and left out. Anything that gives a hint of hope of reverting things to be the way they were is justified and no price is too high.They can steal as long as they are our thieves.To get through to these people you have to validate their deep fears. Not just say - shut up, you are stupid, vote for me.reply"
    ],
    "link": "https://garymarcus.substack.com/p/the-whole-thing-was-scam",
    "first_paragraph": ""
  },
  {
    "title": "MCP server that reduces Claude Code context consumption by 98% (mksg.lu)",
    "points": 236,
    "submitter": "mksglu",
    "submit_time": "2026-02-28T10:01:20 1772272880",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=47193064",
    "comments": [
      "Nice work.It strikes me there's more low hanging fruit to pluck re. context window management. Backtracking strikes me as another promising direction to avoid context bloat and compaction (i.e. when a model takes a few attempts to do the right thing, once it's done the right thing, prune the failed attempts out of the context).reply",
      "Agree. I\u2019d like more fine grained control of context and compaction. If you spend time debugging in the middle of a session, once you\u2019ve fixed the bugs you ought to be able to remove everything related to fixing them out of context and continue as you had before you encountered them. (Right now depending on your IDE this can be quite annoying to do manually. And I\u2019m not aware of any that allow you to snip it out if you\u2019ve worked with the agent on other tasks afterwards.)I think agents should manage their own context too. For example, if you\u2019re working with a tool that dumps a lot of logged information into context, those logs should get pruned out after one or two more prompts.Context should be thought of something that can be freely manipulated, rather than a stack that can only have things appended or removed from the end.reply",
      "Oh that's quite a nice idea - agentic context management (riffing on agentic memory management).There's some challenges around the LLM having enough output tokens to easily specify what it wants its next input tokens to be, but \"snips\" should be able to be expressed concisely (i.e. the next input should include everything sent previously except the chunk that starts XXX and ends YYY). The upside is tighter context, the downside is it'll bust the prompt cache (perhaps the optimal trade-off is to batch the snips).reply",
      "Good point on prompt cache invalidation. Context-mode sidesteps this by never letting the bloat in to begin with, rather than snipping it out after. Tool output runs in a sandbox, a short summary enters context, and the raw data sits in a local search index. No cache busting because the big payload never hits the conversation history in the first place.reply",
      "Yeah, the fact that we have treated context as immutable baffles me, it\u2019s not like humans working memory keeps a perfect history of everything they\u2019ve done over the last hour, it shouldn\u2019t be that complicated to train a secondary model that just runs online compaction, eg: it runs a tool call, the model determines what\u2019s Germaine to the conversion and prunes the rest, or some task gets completed, ok just leave a stub in the context that says completed x, with a tool available to see the details of x if it becomes relevant again.reply",
      "That's pretty much the approach we took with context-mode. Tool outputs get processed in a sandbox, only a stub summary comes back into context, and the full details stay in a searchable FTS5 index the model can query on demand. Not trained into the model itself, but gets you most of the way there as a plugin today.reply",
      "Is it because of caching? If the context changes arbitrarily every turn then you would have to throw away the cache.reply",
      "> For example, if you\u2019re working with a tool that dumps a lot of logged information into contextI've set up a hook that blocks directly running certain common tools and instead tells Claude to pipe the output to a temporary file and search that for relevant info. There's still some noise where it tries to run the tool once, gets blocked, then runs it the right way. But it's better than before.reply",
      "That's exactly what context-mode does for tool outputs. Instead of dumping raw logs and snapshots into context, it runs them in a sandbox and only returns a summary. The full data stays in a local FTS5 index so you can search it later when you need specifics.reply",
      "what i want is for the agent to initially get the full data and make the right decision based on it, then later it doesnt need to know as much about how it got there.isnt that how thinking works? intermediate tokens that then get replaced with the reuslt?reply"
    ],
    "link": "https://mksg.lu/blog/context-mode",
    "first_paragraph": ""
  },
  {
    "title": "747s and Coding Agents (carlkolon.com)",
    "points": 128,
    "submitter": "cckolon",
    "submit_time": "2026-02-27T17:22:00 1772212920",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=47182986",
    "comments": [
      "I am not sure how many other people on here are old enough to remember, but I first learned to program before I had the internet. I had to read books, and then if I was trying to figure out how to do something, I would have to figure out which book to look it up in, and then figure out where in the book to find it and how to apply it to my situation. It made me learn a ton, because I would have to read a lot of books to even know where to look; I had to do my own \u2018scraping and indexing\u2019.I remember as the internet took off and you could just search for things, I thought it made programming too easy. You never had to actually learn how it worked, you can just search for the specific answer and someone else would do the hard work of figuring out how to use the tools available for your particular type of problem.Over the years, my feelings shifted, and I loved how the internet allowed me to accomplish so much more than I could have trying to figure it all out from books.I wonder if AI will feel similar.reply",
      "I use AI for very little but I do like using it for stuff I'm just not very interested in  but have to get done.For programming, I don't like it. It's like a master carpenter building furniture from IKEA. Sure it's faster and he doesn't have to think very hard and the end result is acceptable but he feels lazy and after a while he feels like he is losing his skills.The best days of computing for me were what you remember. A computer was just a blank slate. You turned it on, and had a \">\" blinking on the screen. If you wanted it to do anything you had to write a program. And learning how to do that meant practice and study and reading... there were no shortcuts. It was challenging and frustrating and fun.reply",
      "All fair, but I think a different interpretation could be that AI allows you to vastly expand the scope of the possible, such to create a situation again where things are challenging and frustrating and fun.reply",
      "Most programmers don't like the fuzziness of AI, so things may be challenging and frustrating, but certainly not fun.reply",
      "So much AI moaning and groaning these days seems based on the idea that people have to be forced to do anything of value, even for themselves.It seems to imply a great deal of pessimism about human self-determination. Like, I can't be anything good unless there is an external mold pressing me into the good shape. And it can't be my choice because I would never choose anything good. I'll only do good things for myself if forced.Since AI is supposedly taking everybody's jobs and making it so we can choose never to better ourselves, maybe future governments will need to institute taskmasters to force us into regimens of physical and mental health and vigor. A whole new adult school system will have to be instituted.reply",
      "I've always felt a little odd saying, \"Back in my day we had to understand the cpu, registers, etc.\" It's a true statement, but doesn't help in any way. Is that stuff still worth knowing, IMHO? Yes. Can you create incredibly useful code without that knowledge today? Absolutely.reply",
      "There are some people who still know these things, and are able to use LLMs far more effectively than those who do not.I've seen the following prediction by a few people and am starting to agree with it: software development (and possibly most knowledge work) will become like farming. A relatively smaller number of people will do with large machines what previously took armies of people. There will always be some people exploring the cutting edge of thought, and feeding their insights into the machine, just how I image there are biochemists and soil biology experts who produce knowledge to inform decisions made by the people running large farming operations.I imagine this will lead to profound shifts in the world that we can hardly predict. If we don't blow ourselves up, perhaps space exploration and colonization will become possible.reply",
      "I think that tt's more likely at this point that we turn the depleting quantities of exploitable resources on this planet into more and more data centers and squander any remaining opportunity at space exploration/colonization at scale.reply",
      "If this happens to software development, this will happen to most mental jobs.reply",
      "> Can you create incredibly useful code without that knowledge today?You could do that without that knowledge back in the day too, we had languages that were higher level than assembler for forever.It's just that the range of knowledge needed to maximize machine usage is far smaller now. Before you had to know how to write a ton of optimizations, nowadays you have to know how to write your code so the compiler have easy job optimizing it.Before you had to manage the memory accesses, nowadays making sure you're not jumping actross memory too much and being aware how cache works is enoughreply"
    ],
    "link": "https://carlkolon.com/2026/02/27/engineering-747-coding-agents/",
    "first_paragraph": "A couple years ago, I was on the way back from a work trip to Germany. I had been upgraded to business class, and I sat next to a Belgian 747 pilot, probably in his fifties or sixties. We talked a fair bit about our careers. I had left the Navy and started professionally programming less than a year before. He had been a pilot since shortly after graduating university, and had flown the 747 for about twenty years. He had studied mechanical engineering at school, and he told me in great depth about the variable geometry jet turbines in modern aircraft, which could remain efficient across a wide altitude range.I expressed some jealousy about how well suited he was to his job. Clearly he was a geek for aircraft, and even though most airlines don\u2019t fly the 747 anymore, it is an incredible machine. He agreed that it was a privilege to fly the plane, but said wistfully:In this job, after a while, there\u2019s no improvement. You are no better today than you were yesterday.He said that by now, he "
  }
]