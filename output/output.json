[
  {
    "title": "Why fastDOOM is fast (fabiensanglard.net)",
    "points": 343,
    "submitter": "wicket",
    "submit_time": "2025-03-04T19:05:43 1741115143",
    "num_comments": 102,
    "comments_url": "https://news.ycombinator.com/item?id=43258709",
    "comments": [
      "> The MPV patch of v0.1 is without a doubt build 36 (e16bab8). The \"Cripy optimization\" turns status bar percentage rendering into a noop if they have not changed. This prevents rendering to a scrap buffer and blitting to the screen for a total of 2 fps boost. At first I could not believe it. I assume my toolchain had a bug. But cherry-picking this patch on PCDOOMv2 confirmed the tremendous speed gain.Good example of how the bottlenecks are often not where you think they are, and why you have to profile & measure (which I assume Viti95 did in order to find that speedup so early on). The status bar percentage?! Maybe there's something about the Doom arch which makes that relatively obvious to experts, but I certainly would've never guessed that was a bottleneck a priori.\n \nreply",
      "Example: \"Our app was mysteriously using 60% CPU and 25% GPU. It turned out this was due to a tiny CSS animation [of an equaliser icon]\"https://www.granola.ai/blog/dont-animate-height\n \nreply",
      "I remember Slack eating up my CPU when it had to display several animanted emojis at once. Use some 20+ emojis and the intel mb pro couldn't handle it. Luckily they knew and there was an option to disable the animation. Now I have no idea if they fixed it since or it is one of those things that was \"fixed\" by M1.Would like to see a write up on how it's even possible to achieve that when PCs from 20-30 years ago had no issue with such task.\n \nreply",
      "> Would like to see a write up on how it's even possible to achieve that when PCs from 20-30 years ago had no issue with such task.Electron.\n \nreply",
      "But that's just a browser, right? I'm pretty sure my browser in 2005 could display dozens of gifs. There must have been a series of decisions by devs to do it in some super convoluted way. I can see each emoji being an iframe with a full react app doing the animation. But even that should be fine? Maybe?\n \nreply",
      "It's \"just a browser\" in the same sense that the Linux kernel and GNU are \"just an operating system\".It's one of the most complex pieces of software - perhaps even human designed systems - ever to exist and we're using it to render a few polygons and drop shadows because the C++ committee made a bunch of mistakes decades ago so now our webdevs are mortally afraid of CMake and Qt/QML. Or GTK. Or whatever. Pretty much the only people that seem to put out native GUI tools in any significant quantity are Apple developers.The tradeoffs that Blink and V8 engineers have made to support the entirety of the internet and the morass of web development precludes efficient use of resources for simpler purposes, like rendering an animation. After all, there a billion React hooks and ad tracking scripts to optimize, otherwise bounce rates will increase.\n \nreply",
      "Why was the solution to optimize the animation instead of... using a static asset?\n \nreply",
      "We paid for the whole CSS spec and we're gonna use the whole CSS spec.\n \nreply",
      "This, but for everything wevdev-related in the past ten years.\n \nreply",
      "Because it provides an indication that the app is receiving your voice input?\n \nreply"
    ],
    "link": "https://fabiensanglard.net/fastdoom/index.html",
    "first_paragraph": ""
  },
  {
    "title": "ARC-AGI without pretraining (iliao2345.github.io)",
    "points": 191,
    "submitter": "georgehill",
    "submit_time": "2025-03-04T19:52:38 1741117958",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=43259182",
    "comments": [
      "I feel like extensive pretraining goes against the spirit of generality.If you can create a general machine that can take 3 examples and synthesize a program that predicts the 4th, you've just solved oracle synthesis. If you train a network on all human knowledge, including puzzle making, and then fine-tune it on 99% of the dataset and give it a dozen attempts for the last 1%, you've just made an expensive compressor for test-maker's psychology.\n \nreply",
      "If the machine can decide how to train itself (adjust weights) when faced with a type of problem it hasn\u2019t seen before, then I don\u2019t think that would go against the spirit of general intelligence. I think that\u2019s basically what humans do when they decide to get better at something, they figure out how to practice that task until they get better at it.\n \nreply",
      "In-context learning is a very different problem from regular prediction. It is quite simple to fit a stationary solution to noisy data, that's just a matter of tuning some parameters with fairly even gradients. In-context learning implies you're essentially learning a mesa-optimizer for the class of problems you're facing, which in the form of transformers means essentially means fitting something not that far from a differentiable Turing machine with no inductive biases.\n \nreply",
      "Exactly. That's basically the problem with a lot of the current paradigm, they don't allow true generalisation. That's why some people say there won't be any AGI anytime soon: https://www.lycee.ai/blog/why-no-agi-openai\n \nreply",
      "\"true generalisation\" isn't really something a lot of humans can do.\n \nreply",
      "the thing is LLMs don't even do the kind of generalisations the dumbest human can do.\nwhile simultaneously doing some stuff the smartest human probably can't\n \nreply",
      "Describes computers in general pretty well\n \nreply",
      "I think that most human learning comes from years of sensory input. Why should we expect a machine to generalize well without any background?\n \nreply",
      "Newborns (and certainly toddlers) seem to understand the underlying concepts for these things when it comes to visual/hepatic object identification and \"folk physics\":  A short list of abilities that cannot be performed by CompressARC includes:\n\n  Assigning two colors to each other (see puzzle 0d3d703e)\n  Repeating an operation in series many times (see puzzle 0a938d79)\n  Counting/numbers (see puzzle ce9e57f2)\n  Translation, rotation, reflections, rescaling, image duplication (see puzzles 0e206a2e, 5ad4f10b, and 2bcee788)\n  Detecting topological properties such as connectivity (see puzzle 7b6016b9)\n\nNote: I am not saying newborns can solve the corresponding ARC problems! The point is there is a lot of evidence that many of the concepts ARC-AGI is (allegedly) measuring are innate in humans, and maybe most animals; e.g. cockroaches can quickly identify connected/disconnected components when it comes to pathfinding. Again, not saying cockroaches can solve ARC :) OTOH even if orcas were smarter than humans they would struggle with ARC - it would be way too baffling and obtuse if your culture doesn't have the concept of written standardized tests. (I was solving state-mandated ARCish problems since elementary school.) This also applies to hunter-gatherers, and note the converse: if you plopped me down among the Khoisan in the Kalahari, they would think I was an ignorant moron. But it makes as much sense scientifically to say \"human-level intelligence\" entails \"human-level hunter-gathering\" instead of \"human-level IQ problems.\"\n \nreply",
      "> there is a lot of evidence that many of the concepts ARC-AGI is (allegedly) measuring are innate in humansI'd argue that \"innate\" here still includes a brain structure/nervous system that evolved on 3.5 billion years worth of data. Extensive pre-training of one kind or another currently seems the best way to achieve generality.\n \nreply"
    ],
    "link": "https://iliao2345.github.io/blog_posts/arc_agi_without_pretraining/arc_agi_without_pretraining.html",
    "first_paragraph": "\nBy Isaac Liao and Albert GuIn this blog post, we aim to answer a simple yet fundamental question:Can lossless information compression by itself produce intelligent behavior?The idea that efficient compression by itself lies at the heart of intelligence is not new (see, e.g., Hern\u00e1ndez-Orallo & Minaya-Collado, 1998; Mahoney, 1999; Hutter, 2005; Legg & Hutter, 2007). Rather than revisiting those theoretical discussions, we make a practical demonstration instead.In this work, we give evidence that lossless compression during inference time is sufficient to produce intelligent behavior, by developing a method purely based on compression that performs well on the ARC-AGI challenge, a dataset of IQ-test-like puzzles about inferring a procedure/rule from limited demonstrations. Crucially, our solution, which we name CompressARC, obeys the following three restrictions:Despite these constraints, CompressARC achieves 34.75% on the training set and 20% on the evaluation set\u2014processing each puzzl"
  },
  {
    "title": "Show HN: Bayleaf \u2013 Building a low-profile wireless split keyboard (graz.io)",
    "points": 501,
    "submitter": "sgraz",
    "submit_time": "2025-03-04T15:00:51 1741100451",
    "num_comments": 157,
    "comments_url": "https://news.ycombinator.com/item?id=43255529",
    "comments": [
      "This is the keyboard I\u2019ve been hoping Apple would make for years! I\u2019ve currently got a UHK 60 but would probably switch to this if I could buy it. Especially if it had the standard Apple keyboard layout so my fingers don\u2019t need to relearn things like arrow keys and cmd like when I switch between the UHK and MacBook keyboard.\n \nreply",
      "Me too. Low-profile is nicer to joints in the long run, and also makes me type faster due to low-travel switches. Bonus points if it has a little bit of negative tilt.In this regard, I found Microsoft Sculpt really good because it ticked all ergonomic boxes but it didn't require relearning. However, quality was a bit subpar, it didn't offer a wired option, and it has been discontinued. The entire lineup was actually sold to Incase, who are releasing it again soon.\n \nreply",
      "Yes. Agreed.\n \nreply",
      "Awesome! Looks like it accompanied an apple trackpad, super sleek.I'm also using nice!nanos in my projects, and they're great little devices. At this point I'd love there to be a good alternative using a dongle, though... I have a desktop PC that I want to use them with, and since they can't connect via Bluetooth at boot time, I always have to connect them to select a boot option and unlock my ZFS drive.Having an affordable or open source controller that can do split as well as nice!nanos, but also switch between Bluetooth and a dongle is like the holy grail to me. I'd instantly buy 10.\n \nreply",
      "Bravo! You have elevated a honed tool to a truly engaging artifact! I think the large challenge in design is mitigating the breaking point between ruthless efficiency and endearing novelty.I picked up a Let's Split v2[0] when it came out years ago and never soldered it up.. maybe it's time![0]https://shop.beekeeb.com/product/lets-split-v2-keyboard-pcb-...\n \nreply",
      "For next iteration, consider integrating trackpads?Moving to the mouse and back is pain enough that people go all-in on keyboard-only interfaces.I velcroed a trackpad to the middle of a Kinesis Advantage.  Now I use either hand for the mouse, and even stretch a finger or thumb to the pad without leaving the keys. The movement is little different from using the keyboard.But for split keyboard, you'd need one trackpad for each side, and in dimensions not readily available. hmm.\n \nreply",
      "I want a trackpads integrated into the keys. Under the J key a trackpad with low sensitifity, and under the K key a trackpad with high sensitivity.\n \nreply",
      "So happy to read this because I don't see it mentioned often enough.I have a ErgoDox EZ, and I still prefer using my Framework 13 (with Kanata![0]) because having my thumbs navigate the trackpad is so convenient even with a keyboard-driven setup.[0] https://github.com/jtroo/kanata\n \nreply",
      "I put a trackball (Kensington Expert Mouse) in between the keyboard halves.  With tenting it can nestle in quite close.\n \nreply",
      "Personal opinion, but I really don\u2019t get low-profile keyboards. I always need a foam cushion for my palms, which means that a normal profile always feels best for me. Low feels too low with a cushion, and yet still feels too high without one.\n \nreply"
    ],
    "link": "https://www.graz.io/articles/bayleaf-wireless-keyboard",
    "first_paragraph": ""
  },
  {
    "title": "Translating natural language to first-order logic for logical fallacy detection (arxiv.org)",
    "points": 161,
    "submitter": "ColinWright",
    "submit_time": "2025-03-04T17:36:23 1741109783",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=43257719",
    "comments": [
      "I'm pretty sure that the semantics of natural language are a lot more complex than can be accounted for by these seemingly very ad-hoc translations into comparatively straightforward FOL formulas, as are given in this paper.  A common approach for the understanding of NL semantics from a strictly formal POV is Montague semantics https://en.wikipedia.org/wiki/Montague_grammar https://plato.stanford.edu/entries/montague-semantics/ - even a cursory look at these references is enough to clarify the level of complexity that's involved.  Very loosely speaking one generally has to work with multiple \"modalities\" at the same time each of which, when understood from the POV of ordinary FOL, introduces its own separate notion of abstract \"possible worlds\" (representing, e.g. an agent's set of beliefs) and ways in which these \"worlds\" can relate to one another.  More complex cases will usually degenerate in some sort of very generic \"game semantics\" https://en.wikipedia.org/wiki/Game_semantics https://plato.stanford.edu/entries/logic-games/ where any given use of natural language is merely seen as a \"game\" (in the abstract strategic, game-theoretical sense) with its own set of possibly very ad-hoc 'rules'.  The philosopher Ludwig Wittgenstein https://en.wikipedia.org/wiki/Ludwig_Wittgenstein https://plato.stanford.edu/entries/wittgenstein/ gave quite a good description of both of these approaches (from a very na\u00efve approach based on a supposedly straightforward translation to some kind of abstract logic, to a far richer one based on notions of strategies and games) to a \"formal\" understanding of natural language, throughout his extensive philosophical inquiry.Which is to say, I'm not sure how this paper's results are generally expected to be all that useful in practice.\n \nreply",
      "Your argumets and links are interesting, I hope to study these materials some day.But.To be useful in practice the approach does not need to work in all cases of natural language usage. Even if works in some limited cases there may be useful applications.The authors evaluate their approach on two datasets. One is LOGIC consisting of learning examples of logical fallacies. The other is LOGICCLIMATE, consisting of logical fallacies collected from real world news articles about climate change.The datasets are here, if anyone is interested to see the type of natural language they try to adress currently:\nhttps://github.com/causalNLP/logical-fallacyI guess this csv contains the LOGICCLIMATE: https://github.com/causalNLP/logical-fallacy/blob/main/data/...So a possible practicle utility for the approach - spot individual wrong sentences in a long article and highlight them.Another real world example. I propose a solution at work, based on some statistics. And a colleague dismisses it by saying that there is a book \"6 Ways to Lie with Statistics\". If there was a smart assistant in the room who gently explained his logical fallacy to the colleague, it would save a lot of efforts for me and made the discusdion more productive. I doubt the difficulties you mention apply to this simple case.\n \nreply",
      "I've worked on classical NLP models for quite some time, and this indeed looks way too simple to be of any practical use. If you mention Montague, I'm going to refer you to \"Pedro owns a donkey,\" the poster kid sentence for Discourse Representation Theory. That's 1980s work, and for simple sentences it's already complicated beyond what the OP article suggests, and fails on anything remotely complex. I think it goes 2nd order the moment a complement is introduced (I think that ...).And even if you can translate a sentence into a predicate, you haven't begun understanding what lies behind all those predicates. E.g., \"Zelensky is ready to work under Trump's 'strong leadership' after 'regrettable' showdown.\" What good does it do to have that in FOP?[1] https://plato.stanford.edu/archIves/sum2011/entries/discours...\n \nreply",
      "Even beyond that you have a ton of pragmatics post-grice to deal with. Computing implicatures is complex and requires a lot of knowledge about context etc. The truth value of a statement and the 'truth value' of a speech act are pretty different things - not sure it's really feasible to convert between them.\n \nreply",
      "It looks like classic models of NLP semantics mostly punt on the \"logical\" point of view precisely due to these difficulties, and focus mostly on the more surface level problem of describing how each word of the source text correlates with a deeper description of the \"meaning\" of the text as a whole.  So it is simply assumed that the meaning of the text as a whole must be derived compositionally from the meaning of each part (usually described by a somewhat ad-hoc \"frame\" structure), but exactly what that entails in a \"logical\" sense is left unspecified.  UMR (Universal Meaning Representations) seems to be a typical example of such a system https://github.com/umr4nlp/umr-guidelines/blob/master/guidel... The expected use case seems to be something like building a common intermediate language for an automated translation system; individual meaning elements can then be \"mapped\" in a useful way, even across different languages, but there's not much interest apparently in \"inferring\" further knowledge from what one already has, or even on verifying that any given inference is valid (as proposed by OP).\n \nreply",
      "See also for example V.H. Dudman on the interpretation of \"If\" sentences: https://www.scribd.com/document/478756656/Dudman-1984-Condit...\n \nreply",
      "would be interesting if they had adversarial/null llms attempting the noisy nlp reductions as well. then one could make arguments about the sturdiness of the noisy bit.\n \nreply",
      "Text that is written in Natural Language is open to interpretation. There are many formal statements that can be said to interpret a given Natural Language text. Can we determine which formal representation is correct? What about most useful?The obvious answer to these questions is, \"no\". There is no such thing as a conclusive interpretation. If there was, then Natural Language wouldn't be ambiguous in the first place!So we're all doomed to constantly misinterpret each other forever, right? No? We humans use Natural Language all the time, and usually figure out what the other person actually means!? How do we do it? Are we all just really good at guessing?No, we have something better: context.Context exists both in and around Natural Language text. Context determines which formal meaning is used to interpret the text. If we don't know which context is appropriate, there may be clues in the text itself that help us construct one that is useful or correct.---I've been trying to work out an approach to language processing that interprets text into logical formalisms (arbitrary meaning). I call them \"Stories\". A Story is an arbitrary interpretation of text. A Story is never conclusive: instead it is used as arbitrary context to interpret the next text. I call this process \"Backstory\".We could even do the process backwards, and \"write\" an arbitrary formalism (meaning) in the same language/style/voice as a previously interpreted Story.Given enough example instances of Story, we should be able to read and write to each other through explicitly shared context. I call this process \"Empathizing\". I call my idea the Story Empathizer.I'm definitely out of my depth when it comes to the details, though...\n \nreply",
      "It could be useful for domains in which all or at least many problems are solvable (i.e., they can be stated and satisfied) with first-order logic.It could also be useful as a lower-level component of general-purpose systems that internally rely on chains of thought computed by sub-component LLMs.\n \nreply",
      "It wouldn't be useful if, as the parent comment is saying, it won't do a decent job of translating natural language.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2405.02318",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Launch HN: Enhanced Radar (YC W25) \u2013 A safety net for air traffic control",
    "points": 105,
    "submitter": "kristian1109",
    "submit_time": "2025-03-04T17:04:17 1741107857",
    "num_comments": 75,
    "comments_url": "https://news.ycombinator.com/item?id=43257323",
    "comments": [
      "> The latest system transcribes the VHF control audio at about ~1.1% WER (Word Error Rate), down from a previous record of ~9%.I'd be curious about what happens when the ASR fails. This is not the place to guess or AI-hallucinate. As a pilot, I can always ask \"Say Again\" over the radio if I didn't understand. ASR can't do that. Also, it would be pretty annoying if my readback was correct, but the system misunderstood either the ATC clearance or my readback and said NO.\n \nreply",
      "Good and fair questions.In the very short term, we're deploying this tech more in a post-operation/training role. Imagine being a student pilot, getting in from your solo cross country, and pulling up the debrief will all your comms laid out and transcribed. In this setting, it's helpful for the student to have immediate feedback such as \"your readback here missed this detail...\", etc. Controllers also have phraseology and QA reviews every 30 days where this is helpful. This will make human pilots and controllers better.Next, we'll step up to active advisory (mapping to low assurance levels in the certification requirements). There's always a human in the loop that can respond to rare errors and override the system with their own judgement. We're designing with observability as a first-class consideration.Looking out 5-10 years, it's conceivable that the error rates on a lot of these systems will be super-human (non-zero, but better than a human). It's also conceivable that you could actually respond \"Say Again\" to a speech-to-speech model that can correct and repeat any mistakes as they're happening.Of course, that's a long ways from now. And there will always be a human in the loop to make a final judgement as needed.\n \nreply",
      "One of the challenges I imagine you'll face as you move towards active advisory is that the more an alerting tool is relied upon, the more an absence of a flag from it is considered a positive signal that things are fine. \"I didn't hear from Enhanced Radar, so we don't need to worry about ___\" is a situation where a hallucinated silence of the alerting tool could contribute to danger, even if it's billed as an \"extra\" safety net.I imagine that aviation regulatory bodies have high standards for this - a tool being fully additive to existing tools does not necessarily mean that it's cleared for use in a cockpit or in an ATC tower, right? Do you have thoughts about how you'll approach this? Also curious from a broader perspective - how do you sell any alerting tool into a niche that's highly conscious of distractions, and of not just false positive alerts but false negatives as well?\n \nreply",
      "Yes, fair points. In talking to controllers, this has already come up. There are a few systems that do advisory alerting and controllers have expressed some frustration because each alert triggers a bunch of paperwork and they are not 100% relevant.There are lots of small steps on this ladder.The first is post-operational. You trigger an alert async and someone reviews it after the fact. Tools like this help bring awareness to hot spots or patterns of error that can be applied later in real time by the human controller.A step up from that is real-time alerting, but not to the main station controller. There's always a manager in the tower that's looking over everyone's shoulder and triaging anything that comes up. That person is not as focused on any single area as the main controllers. There's precedence for tools surfacing alerts to the manager, and then they decide whether it's worth stepping in. This will probably be where our product sits for a while.The bar to get in front of an active station controller is extremely high. But it's also not necessary for a safety net product like this to be helpful in real time.\n \nreply",
      "> Looking out 5-10 years, it's conceivable that the error rates on a lot of these systems will be super-human (non-zero, but better than a human). It's also conceivable that you could actually respond \"Say Again\" to a speech-to-speech model that can correct and repeat any mistakes as they're happening.This is effectively AGI.And I've not seen anyone reputable suggest that our current LLM track will get us to that point. In fact there is no path to AGI. It requires another breakthrough in pure research in an environment where money is coming out of universities.\n \nreply",
      "It isn't AGI, it is domain specific intelligence.\n \nreply",
      "AGI is a moving target, but agreed, lot's more research to be done.\n \nreply",
      "Thanks for that. It must be exciting to be applying software skills to aviation. Life goals!To me, speech to text and back seems like an incremental solution, but the holy grail would be the ability to symbolically encode the meaning of the words and translate to and from that meaning. People' phraseology varies wildly (even though it often shouldn't). For example, if I'm requesting VFR flight following, I can do it many different ways, and give the information ATC needs in any order. A system that can convert my words to \"NorCal Approach Skyhawk one two three sierra papa is a Cessna one seventy two slant golf, ten north-east of Stockton, four thousand three hundred climbing six thousand five hundred requesting flight following to Palo Alto at six thousand five hundred,\" is nice, but wouldn't it be amazing if it could translate that audio into structured data:    {\n    atc: NORCAL,\n    requester: \"N123SP\",\n    request: \"VFR\",\n    type: CESSNA_172,\n    equipment: [G],\n    location: <approx. lat/lon>,\n    altitude: 4300,\n    cruise_altitude: 6500,\n    destination: KPAO,\n    }\n\n...for ingestion into potentially other digital-only analysis systems. You could structure all sorts of routine and non-routine requests like this, and check them for completeness, use it for training later, and so on. Maybe one day, display it in real time on ATC's terminal and in the pilot's EFIS. With structured data, you could associate people's spoken tail numbers with info broadcast over ADS-B and match them up in real time, too. I don't know, maybe this already exists and I just re-invented something that's already 20 years old, no idea. IMO there's lots of innovation possible bringing VHF transmissions into the digital world!\n \nreply",
      "Who gave you our event schema!? ;)Kidding aside, yes, you're exactly right. We're already doing this to a large degree and getting better. Lots of our own data labeling and model training to make this good.\n \nreply",
      "Best of luck to you. Finally a Launch HN that's important, potentially life-saving work.\n \nreply"
    ],
    "link": "item?id=43257323",
    "first_paragraph": ""
  },
  {
    "title": "An Uneasy Propaganda Alliance (historytoday.com)",
    "points": 16,
    "submitter": "pepys",
    "submit_time": "2025-03-02T20:05:28 1740945928",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43234457",
    "comments": [
      "https://web.archive.org/web/20250225185829/https://www.histo...",
      "It says two films but the Japanese title for Daughter of the Samurai is \u65b0\u3057\u304d\u571f which means New Earth, so the two films appear to be the same one? I can't read the article because it's paywalledAnd wow, starring Setsuko Haraedit: I found this interesting review that explains how the Japanese title's release was adjusted for domestic audiences, so it is another version of the same film:> Harun Farocki's juxtaposition of the way American and Nazi propaganda films represent hands in Der Ausdruck der H\u00e4nde brings out that obsession of Fascist propaganda with the sexualisation of machinery, that is, through the act of touching and caressing\u2014something essentially passive and supervisory where the machine is almost worshipped for its power (yes, as a phallus). Crucially, what we must recognise here is the automated process in which the human is a mere appendage. Compare this to the portrait of skilled labourers in Allied propaganda, hands that truly work, hands that actually appear to belong to a human\u2014that creature who designs and builds, repairs and heals. So, why is this relevant to the German-Japanese co-production, Die Tochter des Samurai? First, what you will be struck by is the overwhelming emphasis on machinery\u2014automated machinery. It is a cosmopolitan story* with a central Japanese character, Teruo, who returns to his home after many years abroad being educated by Germans. But then there is also Setsuko Hara's character\u2014ah! the eternal virgin! Now we have the clash between quaint old Japan\u2014obviously dealt with in some of the most painfully 'non-exoticising' exoticised terms (yes, there is even a sequence in which Hara plays with deer in front of the Itsukushima Shrine; gag) where the camera acts like a brush dripping (and I mean fucking dripping) with the paint of romanticist slop\u2014and the ideals of 'the modern world', symbolised by the lack of free will, militarism, and the subjugation of Manchukuo (for the greater good, of course). Contemporary Japanese viewers must have found it really quite hilarious when they weren't furious about being condescended to; it's as if the makers just wanted to cram as many identifiably Japanese things into the movie without any mind as to how horribly they were distorting them. Ultimately, the film gets even worse once it edges into blood and soil territory, but we've all already given up hope by this point so it's hardly much of a let-down. The fact of the matter is contemporary Japanese people thought it abysmal, and that was even after Mansaku Itami had managed to get the film changed from Fanck's version for domestic release. I believe this was the version I saw, and I can hardly imagine how terrible the 'properly Nazi' one was. Perhaps my half-star rating is somewhat of an overstatement, but considering how much I respect and adore Japanese filmmaking during this troubled yet incredibly creative decade, I can't help but despise this film.> I say this without a single ounce of hyperbole: you will not find a Japanese propaganda film from the 40s which is even SLIGHTLY as vile as this.> In truth, the story is certainly not a work of cosmopolitanism (how could it be?), but insofar as Japan does have virtuous qualities (in the eyes of Fascists), cosmopolitanism must be presented first as the kind of initial stage in the overcoming of those unwanted traditions (already very much nonsense in every way).> Another note: it is important to remember that the notion of \u201cprogress\u201d always played a significant role in the authoritarian ideologies as a \u201creduction of historical time to an automatic and unthinking mechanism\u201d. Thus, this film focuses on automated machinery not only to load its idea of modernity with this image of the powerful machine working for the greater (read: Nazi) good but to also inextricably tie the automatic machine with history itself, i.e. to assert the absolute necessity of \u2018progress\u2019 and everything that it involves (the rape of China, the cultivation of land in Manchukuo, etc.)> One more thing on this note: it is essential to recognise the dangerous conflation of power and authority in authoritarian ideologies. A clear example in this film is the scene in which Sessue Hayakawa\u2019s character goes to the Kamakura Daibutsu to seemingly draw strength from it, described by one contemporary Japanese critic as treating great Buddhist statues \u201cas if they wielded an absolute power.\u201d There is nothing religious to this sequence; it is the perfect expression of the secular world and bourgeois man \u201cwhose life is completely determined by the category of usefulness, so that he desecrates everything he thinks about.\u201d (Del Noce) Hayakawa\u2019s character visits the statue in order to draw power from it, just as his son talks of Manchukuo as nothing more than land ready for cultivation, i.e. use. Traditions only have value when there is some specific use to them\u2014a belief as closely at home in Nazi Germany as it is the liberal technocratic world order.(RIP Harun Farocki)\n \nreply",
      "It appears there are actually two films. From https://www.mori.art.museum/english/contents/tokyo-berlin/ab...> Conflict between the two directors began almost at once. Itami was alarmed by the raw political intent of the film and by what he considered were the many misinterpretations of Japanese life. Fanck, however, refused all compromise, insisting that this first German-Japanese film collaboration had to have a clear, pro-Nazi message. It soon became obvious that the project would collapse if a compromise was not worked out.> It was \u2013 but in the most surprising manner - each director would make his own version of the picture. Fanck shot all of his scenes in the daytime. Itami, using the same sets and locations, shot his at night. Difficult as this was for them, it was even harder on the cinematographer, Richard Angst, who had to shoot both films, and on the actors who had to work all day and all night, and on the studio, where costs for the film doubled.\n \nreply"
    ],
    "link": "https://www.historytoday.com/archive/history-matters/uneasy-propaganda-alliance",
    "first_paragraph": "\nSubscriptionOffersGive a GiftSubscribeThe doomed film collaboration between Nazi Germany and Imperial Japan resulted in two very different features serving the same fascist agenda: The Daughter of the Samurai and The New Earth.\u00a0It was supposed to be a prestige project for Nazi Germany and Imperial Japan, a way to convince their people \u2013 and the world at large \u2013 that the newly signed Anti-Comintern Pact was more than empty words. To prove that both countries were indeed Br\u00fcderv\u00f6lker (brother nations), a German and a Japanese filmmaker would together create a film showing how the two nations aligned politically and culturally. So, in 1936, a German crew landed in Yokohama ready to make cinema history.To continue reading this article you need to purchase a subscription, available from only \u00a35.Start my trial subscription now\nIf you have already purchased access, or are a print & archive subscriber, please ensure you are\u00a0logged in.\nPlease email digital@historytoday.com if you have any prob"
  },
  {
    "title": "DARPA exploring growing bio structures of \"unprecedented size\" in microgravity (sam.gov)",
    "points": 103,
    "submitter": "Jimmc414",
    "submit_time": "2025-03-04T17:16:13 1741108573",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=43257473",
    "comments": [
      "Hilariously obvious that someone's pet project got tacked on there at the end. Kilometer wide structures please - or alternatively can you make us a tube of bio glue to fix punctures?\n \nreply",
      "Feedsto ck is the moon...its literally resources we don't have to transport into space if we use the moon.\n \nreply",
      "Whoever is doing DARPA\u2019s PR and, apparently GR, since I guess federal agencies have to do that now, deserves a raise.\n \nreply",
      "EP: Elon Pandering, an essential function for any agency these days.\n \nreply",
      "LOL as much as I disagree with Elon's current stint in government, this is probably among the most tame projects in DARPA's portfolio.\n \nreply",
      "doesn't sound very efficient to me\n \nreply",
      "what is GR?\n \nreply",
      "Guessing government relations, similar to PR being public relations.\n \nreply",
      "Yup. Lobbyists are outside your org. GR co\u00f6rdinates their messaging.\n \nreply",
      "Unrelated, but I appreciate the proper usage of the English umlaut\n \nreply"
    ],
    "link": "https://sam.gov/opp/426e5868fcf74dd4ada3768b00b09234/view",
    "first_paragraph": ""
  },
  {
    "title": "Satellogic's Open Satellite Feed (marksblogg.com)",
    "points": 184,
    "submitter": "marklit",
    "submit_time": "2025-03-04T15:56:58 1741103818",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43256349",
    "comments": [
      "This is amazing! Is there already a platform that records past imagery for places in the world for users to see what changed over time?\n \nreply",
      "https://www.usgs.gov/centers/eros/science/usgs-eros-archive-... has all of the unclassified US government satellites.\n \nreply",
      "Google Earth Pro has a \"historical image\" slider to go back to previous versions of an area\n \nreply",
      "https://eos.com/landviewer/europe/Yes, in fact (to paraphrase Mitch Hedberg), all satellites cameras produce past imagery.\n \nreply",
      "Planet, Maxar, and others, though costs are fairly high even for hobbyists.\n \nreply",
      "https://planetarycomputer.microsoft.com and it's free!Disclosure: I work at Microsoft on this.\n \nreply",
      "Man that's crazy, wonder if any stock traders use this data to make predictions or futures\n \nreply",
      "Yes, obviously, but more commodities than stocks.\n \nreply",
      "> commodities\"Fear and greed index\" ha didn't know about that\n \nreply",
      "You can use copernicus satellites for free which ive found generally have at least 5 or so pictures each month but the resolution isnt that high (>10M i think)\n \nreply"
    ],
    "link": "https://tech.marksblogg.com/satellogic-open-data-feed.html",
    "first_paragraph": "I have 15 years of consulting & hands-on build experience with clients in the UK, USA, Sweden, Ireland & Germany. Past clients include Bank of America Merrill Lynch, Blackberry, Bloomberg, British Telecom, Ford, Google, ITV, LeoVegas, News UK, Pizza Hut, Royal Mail, T-Mobile, Williams Formula 1, Wise & UBS. I hold both a Canadian and a British passport. My CV, Twitter & LinkedIn.\n      \nHome\n        | Benchmarks\n\n        | Categories\n\n            | Atom Feed\nPosted on Tue 04 March 2025  under GISSatellogic is a satellite designer, manufacturer and constellation operator. They were founded in 2010 and have offices in Argentina, Uruguay, Spain and the US.They launched three prototype Cube satellites between 2013 and 2014, using China and Russia as their launch partners.In 2016, they began launching ~38 KG, 10K-component, 51 x 57 x 82-cm NewSat microsatellites. These take around three months to build and are meant to last for three years in orbit. They've named the constellation of these "
  },
  {
    "title": "A Map of Python (fi-le.net)",
    "points": 41,
    "submitter": "fi-le",
    "submit_time": "2025-03-01T11:44:18 1740829458",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43218343",
    "comments": [
      "That is not an iteractive map. Google Chrome is the only piece of software which manages to bring my system to a halt, where the mouse then moves an 0.2 FPS.That map should have used a mapping server, possibly serving vector tiles.\n \nreply",
      "Are there any languages which have an hierarchical repository which is structured so that one can easily browse and find what one needs? Or, arriving where it ought to be, discover that it does not yet exist?CTAN seems pretty close, but is tightly focused on TeX, and CPAN is for Perl, not Python.\n \nreply",
      "Hackage has a categories system which can be used to browse through all Haskell packages [0]. Unfortunately the categories are unstandardised, so it\u2019s less useful than it could be \u2014 though the Flora project exists, which has improved the UI by standardising categories a bit [1].[0] https://hackage.haskell.org/packages/[1] https://flora.pm/categories\n \nreply"
    ],
    "link": "https://fi-le.net/pypi/",
    "first_paragraph": "February 28, 2025\nPyPi, the Python Software Foundation's package repo, counts over half a million open source projects. Since I use many of these every day, it seemed appropriate to get to know this set of packages better, and show some appreciation. The index website provides nice search and filtering, which is good when looking for something specific. Here though, we want to take a look at every package at once, to construct a visualization, and perhaps even discover some cool new packages.\n    \n      To visualize the set, then, we need to find out its structure. Luckily PyPi provides a nice JSON API (see here for numpy's entry for instance) and even luckier, there is a copy on BigQuery so that we don't have to bother the poor PyPi servers with >600,000 requests.\n    \n      One SQL query later, we have a .jsonl of all the metadata we want. So what metadata do we want? Since we want to uncover the internal structure of the dataset, we focus on the defining feature of open source and l"
  },
  {
    "title": "Show HN: Time travel debugging AI for more reliable vibe coding (nut.new)",
    "points": 65,
    "submitter": "bhackett",
    "submit_time": "2025-03-04T18:53:44 1741114424",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=43258585",
    "comments": [
      ">  it's amazing to use Claude to prompt an app into existence, and pretty frustrating when that app doesn't work right and Claude is all thumbs fixing the problem.Such an in interesting sentence. App that doesn't work doesn't seem like it's yet come into existence.This has been my (limited) experience so far. I haven't been able to get an AI/LLM to help me build an app. Even React apps it fails at. I have been able to get an LLM to help with coding questions similar to Stack Overflow questions though (though not always)\n \nreply",
      "lol agreed, also I\u2019m of the opinion that if you want a working app it\u2019s much more  frustrating to debug a heap of code generated by an AI than it is to build yourself (maybe with the help of AI, if you really need it). at least with the latter if you really built it yourself you understand all the components (to a certain abstraction point at least)\n \nreply",
      "If anyone is wondering why it looks like Bolt, it\u2019s because it\u2019s using Bolt.DIY, an open-source fork of Bolt (https://github.com/stackblitz-labs/bolt.diy). The catch is that it's still using WebContainers from StackBlitz, so it's not really possible to run it commercially. You need to get rid of WebContainers and find something different.\n \nreply",
      "Thanks, yeah we're really thankful to StackBlitz for open sourcing the early version of Bolt.new and to the Bolt.diy community for continuing to develop it.We don't have a commercial offering yet and are planning to migrate off WebContainers for the upcoming full stack features -- WebContainers show their limits pretty quickly in a full stack context (e.g. CORS issues) and we need observability into the server side of the app for full stack debugging.Regardless, our interests here are only lightly commercial.  We're not really developing Nut to drive revenue but to help us develop the debugging API and push forward the SOTA for AI development as effectively as we can.  That API is what we want to sell.\n \nreply",
      "Looks fun and it does create something - https://nut.new/chat/prince-of-persia-platform-gameI couldn't start the game though, but it seems runnable given some debugging. Great work!\n \nreply",
      "Thanks!  Unfortunately the chat links aren't shareable yet.  We're planning on adding this within the next couple weeks along with the other full stack features (database integration and easy deployment).\n \nreply",
      "Can you share the prompt you used to generate this game? (given chats aren't sharable)\n \nreply",
      "Hm, the link isn't working for me\n \nreply",
      "Just letting you know the about page has black text on a black background\n \nreply",
      "Can\u2019t expect too much reliability from the result of vibe coding.\n \nreply"
    ],
    "link": "https://nut.new",
    "first_paragraph": ""
  },
  {
    "title": "Who's Afraid of Tom Wolfe? (wustl.edu)",
    "points": 64,
    "submitter": "lermontov",
    "submit_time": "2025-03-04T18:04:16 1741111456",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=43258010",
    "comments": [
      "In Wolfe's \"Bonfire of the Vanities,\" the main character, a lawyer, described the line of prisoners going into the back of the courthouse as \"chow,\" as in chow for the system. I'll never forget that.Also, for anyone who grew up in Atl, Wolfe's book \"A Man In Full\" drips with the kind of delicious look-in-the-mirror satire home grown Southerners love.\n \nreply",
      "Can confirm. Grew up in suburban Atlanta during the period depicted, including getting caught in the first big Freaknic blowout he describes. It\u2019s so dead-on it made me homesick.\n \nreply",
      "the most dead-on part of the latter is when the main character is feeling a bit out of place at some meeting/hunting retreat in south Georgia and suddenly he remembers the cheat code: just talk about college football!\n \nreply",
      "My dad taught me this at an early age and it was 100% correct. If you pay attention to enough college football to hold a conversation, you can talk to just about any man in the southeast US.\n \nreply",
      "The other kind of football at the world cup level works globally.\n \nreply",
      "so what percentage of these men can be talked to because, while not liking football, they pay enough attention to college football in order to be able to hold a conversation with just about any man in the southeast US?\n \nreply",
      "Netflix did a fine rendition of this, I enjoyed the turns of speech and intrigue.\n \nreply",
      "I can't find this, are you referring to the 1990 movie?\n \nreply",
      "https://en.wikipedia.org/wiki/A_Man_in_Full_(miniseries)\nhttps://www.justwatch.com/us/tv-show/a-man-in-full\n \nreply",
      "Some of his better books in my opinion:-- https://en.wikipedia.org/wiki/The_Kandy-Kolored_Tangerine-Fl...-- https://en.wikipedia.org/wiki/The_Pump_House_Gang-- https://en.wikipedia.org/wiki/The_Painted_Word\n \nreply"
    ],
    "link": "https://commonreader.wustl.edu/c/whos-afraid-of-tom-wolfe/",
    "first_paragraph": "\nJeannette Cooperman \u00a0Tom Wolfe\u2019s books are being reissued, in homage, by Picador. But he would never put the news so blandly.WHOOSH! Off the press they come, slicked bright and hot, ready to be grabbed by woke undergrads in Lululemon who\u2019ve never heard of him but have a vague sense\u2014floated in between the clicks swipe-lefts and scrolled TikToks\u2014that he might be an Influencer\u2026.Ach. Wolfe would write his blurb far better, sweeping angst and desire into trends we have yet to name. He grasped the various ways we see and think, transcribed our slang, and spelled out the sounds that surround us. With a few choice words, he could nail a scene, a trend, or a decade. Sharply aware of class divisions, subcultures, and self-anointed elites, he pitted us against each other with such wit, we barely minded.I have spent my adult life grateful to this man for loosening and livening up journalism, freeing us from that damned \u201cinverted pyramid\u201d (which frontloads all the facts in an ugly crush on the ass"
  },
  {
    "title": "What a crab sees before it gets eaten by a cuttlefish (nytimes.com)",
    "points": 102,
    "submitter": "gk1",
    "submit_time": "2025-03-04T14:24:49 1741098289",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=43254995",
    "comments": [
      "Gift link with video, because a static archive doesn't do the opening video justice:https://www.nytimes.com/2025/03/03/science/cuttlefish-camouf...\n \nreply",
      "Thanks! I didn't realize the static archive was missing the video. These are better than what's on Santon's site.\n \nreply",
      "Here the link to the mp4 file (from my InternetDownloadManager)https://vp.nyt.com/video/2025/03/03/135038_1_03tb-cuttlefish...\n \nreply",
      "Damn that was quick the attackreminds me of Nope\n \nreply",
      "Defector did it better (and included the videos): https://defector.com/this-is-the-last-thing-you-see-before-y...\n \nreply",
      "I find cuttlefish normally very cute but dear god this is nightmare fuel.\n \nreply",
      "Defector is fantastic and Sabrina Imbler is an absolute treasure - gift link, to share the wealth: https://defector.com/this-is-the-last-thing-you-see-before-y...\n \nreply",
      "This article is so much better than the original NYT one. Great writing and no paywall.\n \nreply",
      "I was hoping the article would include a video, but there's a great 12 second clip on Matteo Santon's site: https://matteosanton.com/research/\n \nreply",
      "> I was hoping the article would include a videoIt has several videos.\n \nreply"
    ],
    "link": "https://www.nytimes.com/2025/03/03/science/cuttlefish-camouflage-huting-crabs.html",
    "first_paragraph": ""
  },
  {
    "title": "Solving SICP (lockywolf.wordpress.com)",
    "points": 69,
    "submitter": "todsacerdoti",
    "submit_time": "2025-03-04T17:58:30 1741111110",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=43257963",
    "comments": [
      "Kudos for finishing it. I\u2019ve gone on a similar quest with https://mk12.github.io/sicp, but I\u2019m still on chapter 3. I keep getting distracted by new ways of improving the website rather than making progress in the book.\n \nreply",
      "Great website! Hope you continue with it, love the layout\n \nreply",
      "Wonderful report! So now we know how long it takes to solve all of the problems: 729 hrs.SICP is hard to work through even if you're just reading but wow, the exercises are on another level! I wonder how it compares to, say, a physics or biology textbook\n \nreply",
      "SICP is a sprawling book. It's been rightly criticised; it is inaccessible without a strong maths and (electronic) engineering background, it's somewhat unfocused, and its code is archaic. But it blew my mind some 20 years ago when I worked through it over many train journeys. A more focused, more accessible book would be objectively better, but I think it would lose something. SICP, with its wild rambling through so many disparate topics, really did leave me feeling that I could make the computer do anything.\n \nreply",
      "Some of the SICP exercises use math and circuits as the \"business domain\" you are programming about, but you don't need independent knowledge of those topics to write the programs. The requirements are pretty well specified.I barely survived Calc 3 and have never taken an engineering course. I was fine.\n \nreply",
      "I found some of the exercises in building abstractions with procedures pretty inaccessible with implicit maths knowledge necessary.  From building abstractions with data onwards they become well spec'd and straightforward.\n \nreply",
      "the expression / circuit bridge in chapter 5 is timeless imo\n \nreply",
      "Is there a modern SICP book? I tried to go through it once, but immediately got stuck because my math/physics was so rusty that I would have to spend more time researching the background than actually solving the CS puzzle\n \nreply",
      "SICP was ported to JS though I'm not particularly keen on the result. https://sourceacademy.org/sicpjs/The code is convoluted, in my opinion, because it tries to hue too closely to the Scheme code in the original giving some unnatural looking JS code as a result. For example:  function member(item, x) {\n    return is_null(x)\n           ? null\n           : item === head(x)\n           ? x\n           : member(item, tail(x));\n  }\n\nThere are examples which have even more but that was the first one I came across clicking the TOC randomly. In Scheme it would be expressed something like this:  (define (member? item set)\n    (cond ((null? set) #f)\n          ((equal? item (car set)) #t)\n          (else (member item (cdr set)))))\n\nWhile the parens cause some brains to segfault, the structure of this (how each condition ties to each result) is clearer than that JS mess.\n \nreply",
      "https://cs.brown.edu/people/sk/ and search for books.Maybe reading this will help:https://cseducators.stackexchange.com/questions/7478/which-b...\n \nreply"
    ],
    "link": "https://lockywolf.wordpress.com/2021/02/08/solving-sicp/",
    "first_paragraph": "Various Thoughts This report is written as a post-mortem of a project that has, perhaps, been the author\u2019s most extensive personal project: creating a complete and comprehensive solution to one of the most famous programming problem sets in the modern computer science curriculum \u201cStructure and Interpretation of Computer Programs\u201d, by Abelson, Sussman, and Sussman (\\cite{Abelson1996}).  It measures exactly:  It suggests:  The solution is published online (the source code and pdf file):  This report (and the data in the appendix) can be applied immediately as:  Additionally, a time-tracking data analysis can be reproduced interactively in the org-mode version of this report. (See: Appendix: Emacs Lisp code for data analysis)    Programming language textbooks are not a frequent object of study, as they are expected to convey existing knowledge. However, teaching practitioners, when they face the task of designing a computer science curriculum for their teaching institution, have to base t"
  },
  {
    "title": "Should managers still code? (theengineeringmanager.substack.com)",
    "points": 117,
    "submitter": "blah2244",
    "submit_time": "2025-03-04T15:41:12 1741102872",
    "num_comments": 175,
    "comments_url": "https://news.ycombinator.com/item?id=43256113",
    "comments": [
      "I cant work for someone who doesn't understand what I do.An unused sword rusts in its sheathe.I remember working for a gent years ago, who was stressed out that my output was so low. He declared \"I started this business in my living room let me show you I can do any job in this building\"He came to my workspace, where I had 20 servers stacked on my workbench. He looked at them. Attached a single power cord. And then wandered off telling me he could definitely do the work if he wanted to.I dont think a manager of software engineers needs to code the application he manages, but he should be continually coding something to remain sharp.TBH one of my current clients produces hardware and software, medium to large enterprise with close to 200 staff. Their CEO can operate all their products, operate the machines that place chips on the circuit boards, operate the injection moulding machines, write SQL queries to pull data out of their CRM and write code. He tries his best not to do it, but he maintains the skills. That's the goal I reckon. Someone who understands the job all the way to the top.\n \nreply",
      "> I cant work for someone who doesn't understand what I do.But you already do. Unless you're working for a tiny startup, your CEO or the Board probably doesn't understand the specifics of your code.You can't run a large company by making every person super-involved in every detail. You have layers of abstraction that make it possible to reason about an org of hundreds or thousands of employees. The Board trusts the CTO to oversee technology. Your CTO trusts your director / VP / whatever to run a large chunk of it. That person delegates a smaller part of running the company to your boss.The whole point of each layer is to abstract away some of the underlying messiness. They exercise professional judgment for day-to-day operations and provide a clean interface that provides health signals, requests resources as needed, etc. And I think what many folks miss is that it doesn't stop with their boss. It stops with you! Your boss generally trusts you to make design and implementation decisions and is expecting you to provide a reasonable interface to that. If your boss has a reasonably-sized team but is spending their day writing code, then honestly, why are they in a management position to begin with?\n \nreply",
      ">If your boss has a reasonably-sized team but is spending their day writing codeThey dont need to spend all day writing code, they need to spend their nights and weekends making sure their skills dont rust.\n \nreply",
      "> they need to spend their nights and weekends making sure their skills dont rust.Life is more than work\n \nreply",
      "Specifics sure. I dont expect them to understand the specifics. I dont want them across every task.But I also dont want to (and currently dont have to) explain specific risks regarding what I do, I dont have to justify how long things take, because my management understands that. We speak the same language. Its glorious.I mean just comparing my clients that have relevant technical knowledge, vs the ones that dont, the clients that dont have that knowledge need \"meetings\" and \"catchups\" and immense email threads in the order of 10 times the ones that do understand. Thats measurable (to me) waste.Another observation of mine is that non technical people really have no ability to recruit and manage technical people. I have seen multiple businesses brought low because the \"technical\" person brought in to manage the \"technical\" side of the startup actually had NFI. Or when they do accidentally hire someone competant, their requests for resources or time are ignored, even when well justified. The non technical founder or CEO either has to trust someone (which fails a lot) or they dont trust someone (and thats even worse).\n \nreply",
      "> I remember working for a gent years ago, who was stressed out that my output was so low. He declared \"I started this business in my living room let me show you I can do any job in this building\"> He came to my workspace, where I had 20 servers stacked on my workbench. He looked at them. Attached a single power cord. And then wandered off telling me he could definitely do the work if he wanted to.Frankly, all this anecdote tells me is \"don't behave like a condescending asshole\". If he'd said the same thing but then managed to do some non-trivial aspect of your job for a few minutes, I think that would still have been a bad tactic. It's just as possible to have humility about skills you lack, and to lack humility about skills you've maintained.\n \nreply",
      "Normally I would have 12 or so desktops there.The server stacks were well above his height.He probably could have, in his day, wired up 20 odd desktops, got them going, and maybe shave 10 minutes off my batch time.But he really had nfi with the servers, the stacks were 2ft higher than him already, they all had dual power supplies, lots of idrac ports. He absolutely would have shamed himself if he kept going. And the reason he hired me was the ability to reason and read vendor documentation.They also take ages to boot compared to a desktop.So yes I think ALSO dont behave like a condescending asshole, but if he understood what I was doing he wouldnt have needed to leave his office and make a fool of himself anyway.\n \nreply",
      "I don\u2019t know man. Can Bezos code? Can he operate a forklift? Would he still even recognize Powerpoint if you opened it for him? At certain points things need to be let go of if you want to keep growing. Some managers might keep technical skills sharp, but I\u2019m not sure they\u2019re much better managers for it.\n \nreply",
      "On the flip side - I find it very understandable that one might not want to have ever worked at Amazon even in its early days and instead would prefer to work (or have worked) at a much smaller, engineering focused organization.\n \nreply",
      "Groups of companies, like Amazon, dont really make sense to me in abstract so I cant really comment.But whoever the head of AWS is should definitely have a grasp of fundamentals.\n \nreply"
    ],
    "link": "https://theengineeringmanager.substack.com/p/should-managers-still-code",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Open-source Deep Research across workplace applications (github.com/onyx-dot-app)",
    "points": 48,
    "submitter": "yuhongsun",
    "submit_time": "2025-03-03T15:18:22 1741015102",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=43242551",
    "comments": [
      "Onyx is as close as to magic you can get in this space. It just. Works.I can talk for literally hours about how good it is when you connect it to your company's Confluence or Jira or Slack or Google Drive or a ton of other things. At a scale of many tens of thousands of documents too.Their team is awesome too and completely tuned into exactly what their users need. And that it's open source is the cherry on top. No secret in how your data is being used.- An incredibly happy user looking forward to more from Onyx\n \nreply",
      "Amazing to hear from a happy user! Thanks for the kind words!\n \nreply",
      "Before sharing how it works, I want to highlight some of the challenges of a system like this. Unlike deep research over the internet, LLMs aren\u2019t able to easily leverage the built in searches of these SaaS applications. They each have different ways of searching for things, many do not have strong search capabilities, or they rely on their internal query language. There are also a ton of other signals that web search engines use that aren\u2019t available natively in the tools. Examples include: backlinks, clickthrough rates, etc. Additionally a lot of teams rely on internal terminology that is unique to them and hard for the LLM to search for. There\u2019s also the challenge of unifying the objects across all of the apps into a plaintext representation that works for the LLM.The best way we\u2019ve found to do this is to build a document index instead of relying on application native searches at query time. The document index is a hybrid index of keyword frequencies and vectors. The keyword component addresses issues like team specific terminology and the vector component allows for natural language queries and non-exact matching. Since all of the documents across the sources are processed prior to query time, inference is fast and all of the documents have already been mapped to an LLM friendly representation.There are also other signals that we can take into account which are applied across all of the sources. For example, the time that a document was last updated is used to prioritize more recent documents. We also have models that run at indexing time to label documents and models that run at inference time to dynamically change the weights of the search function parameters.\n \nreply",
      "The demo looked sharp but I am curious if you have done any formal evaluation of the quality of the results? For example, MRR and recall@k, even on a toy dataset? Seems like the quality of the generated responses will be highly dependent on the docs which are retrieved.\n \nreply",
      "We have a dataset that we use internally to evaluate our search quality. It's more representative of our use case since it contains Slack messages, call transcripts, very technical design docs, company policies which is pretty different from what embedding models are typically trained on.We checked the recall at 4K tokens (which was a pretty typical token limit of the previous generation of LLMs) and we were at over 94% recall for our 10K document set. We also added a lot of noise to it (Slack messages from public Slack workspaces) to get hundreds of thousands of documents but recall remained at over 90%.\n \nreply",
      "I am also interested in how to do eval on an open source corporate search system.  Privacy and information security make this challenging, right?\n \nreply",
      "On privacy and security, we are the only option (as far as I know) that you can connect up to all your company internal docs and have it be all processed locally to the deployment and stored at rest within the deployment.So basically you can have it completely airgapped from the outside world, the only tough part is the local LLM but there are lots of options for that these days.\n \nreply",
      "Cool product. Few Qs:- What would you say is the agentic approach's special sauce over a typical RAG pipeline, ie query->multi-query generation->HyDE->vector search->bm25 search->RRF->rerank->evaluate->(retry|refuse|respond) that differentiates the approach?- If a user has 20 services connected, how does the agent know how to call/search/traverse the information in the right order?- Do you have any internal evals on how well the different model affect the overall quality of output, esp for a \"deep search\" type of task? I have model-picker fatigue.- Do you plan to implement knowledge graphs in the future?\n \nreply",
      "Quite a lot to cover here! So in addition to the typical RAG pipeline, we have many other signals like learning from user feedback, time based weighting, metadata handling, weighting between title/content, and different custom deep learning models that run at inference and indexing time all to help the retrieval. But this is all part of the RAG component.The agent part is the loop of running the LLM over RAG system and letting it decide which questions it wants to explore more (some similarities to retry|refuse|respond I guess?). We also have the model do CoT over its own results including over the subquestions it generates.Essentially it is the deep research paradigm with some more parallelism and a document index backing it.How does the agent traverse the information: there are index-free approaches where the LLM has to use the searches of the tools. This gives worse results than approaches that build a coherent index across sources. We use the latter approach. So the search occurs over our index which is a central place for all the knowledge across all connected tools.Do you have any internal evals on how well the different model affect the overall quality of output, esp for a \"deep search\" type of task? I have model-picker fatigue: Yes, we have datasets that we use internally. It comprises of \"company type data\" rather than \"web type\" data (like short Slack messages, very technical design documents, etc.) comprising about 10K documents and 500 questions.For which model to use: it was developed primarily against gpt-4o but we retuned the prompts to work with all the recent models like Claude 3.5, Gemini, Deepseek, etc.Do you plan to implement knowledge graphs in the future? Yes! We're looking into customizing LLM based knowledge graphs like LightGraphRAG (inspired by, but not the same).\n \nreply",
      "Do you think this indexing architecture would bring benefits to general web research? If implemented like: planner, searches, index webpages in chunks, search in index, responseWould you ever extend your app to search the web or specialized databases for law, finance, science etc?\n \nreply"
    ],
    "link": "https://github.com/onyx-dot-app/onyx",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Gen-AI Chat for Teams - Think ChatGPT if it had access to your team's unique knowledge.\n      \nOpen Source Gen-AI + Enterprise Search.\n\n\n\n\n\n\n\n\n\n\n\n\nOnyx (formerly Danswer) is the AI platform connected to your company's docs, apps, and people.\nOnyx provides a feature rich Chat interface and plugs into any LLM of your choice.\nKeep knowledge and access controls sync-ed across over 40 connectors like Google Drive, Slack, Confluence, Salesforce, etc.\nCreate custom AI agents with unique prompts, knowledge, and actions that the agents can take.\nOnyx can be deployed securely anywhere and for any scale - on a laptop, on-premise, or to cloud.Deep research over your team's knowledge:Use Onyx as a secure AI Chat with any LLM:Easily set up connectors to your apps:Access Onyx where your team already works:To try it out for free and get started in "
  },
  {
    "title": "The Tinkerings of Robert Noyce by Tom Wolfe (1983) (esquire.com)",
    "points": 3,
    "submitter": "whoisstan",
    "submit_time": "2025-03-02T14:34:16 1740926056",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://classic.esquire.com/article/share/58ff278a-21da-4ee4-a446-b7f451b90275",
    "first_paragraph": "How the sun rose on the Silicon ValleyHow the sun rose on the Silicon ValleyIN 1948 THERE WERE seven thousand people in Grinnell, Iowa, including more than one who didn\u2019t dare take a drink in his own house without pulling the shades down first. It was against the law to sell liquor in Grinnell, but it was perfectly legal to drink it at home. So it wasn\u2019t that. It wasn\u2019t even that someone might look in through the window and disapprove. God knew Grinnell had more than its share of White Ribbon teetotalers, but by 1948 alcohol was hardly the mark of Cain it had once been. No, those timid souls with their fingers through the shade loops inside the white frame houses on Main Street and Park Street were thinking of something else altogether.They happened to live on land originally owned by the Congregational minister who had founded the town in 1854, Josiah Grinnell. Josiah Grinnell had sold off lots with covenants, in perpetuity, stating that anyone who allowed alcohol to be drunk on his p"
  },
  {
    "title": "Repairable Flatpack Toaster (kaseyhou.com)",
    "points": 785,
    "submitter": "t-3",
    "submit_time": "2025-03-03T21:19:56 1741036796",
    "num_comments": 240,
    "comments_url": "https://news.ycombinator.com/item?id=43246892",
    "comments": [
      "There's a video.[1]- Toast is toasted on one end, un-toasted at the other.- Control is just a timer, so the second time you use it twice in succession it will be hot at the start and will need a shorter time, which you have to figure out.Check out the Sunbeam Radiant Control Toaster (1949-1980), which is still considered the peak of toaster design.[2] It's repairable, too. Now replicating that would be a good project.[1] https://www.youtube.com/watch?v=jKbUNDPXCWk[2] https://www.theverge.com/22801890/sunbeam-radiant-control-to...\n \nreply",
      "[2] is remarkably interesting:- \"And that mechanism doesn\u2019t just wear out after nearly three-quarters of a century of use: there\u2019s a single screw underneath the crumb tray to adjust the tension of the wire, and it alone is enough to bring many aging toasters back to life.\"edit: There's other HN threads about it,https://news.ycombinator.com/item?id=29342936 (232 comments)https://news.ycombinator.com/item?id=38868753 (76 comments)\n \nreply",
      "In the photo of the Sunbeam, it's also got un-toasted areas\n \nreply",
      "The concept of things like this is excellent, and I don't think that even at massive scale that you could get the average consumer to go along with it, unfortunately. Even if this thing is 30% more expensive than a non-repairable toaster, I bet many consumers would pick the cheaper one, despite it probably not being the long term financially optimal decision. There are valid reasons for it, but even people with means would skip over this, I'd imagine.I know so many people in my life that can afford the better quality version of something, but instead opt for the cheaper, shittier version. When the shitty one dies, they get a new shitty one. I think it comes down to the short term impact of cost,which is a valid choice if the cost is the main constraint currently, but I repeatedly see this even in cases where the additional cost isn't an issue.My ranting aside, this is an incredibly cool project and I'd love things like this in my life. Partially for the fact it's repairable and better for the environment, but partially because it's just neat to have a modular version of your household appliances.\n \nreply",
      "> Even if this thing is 30% more expensive than a non-repairable toaster, I bet many consumers would pick the cheaper one, despite it probably not being the long term financially optimal decision.Toasters are so cheap that I can't imagine repairing them could be cost effective (ie \"financially optimal\") unless you assign no value to your time. A new, good-enough toaster costs in the ballpark of $30. I love taking things apart and fixing them, but if the repair involves figuring out the part I have to order or soldering anything, it will take far more than $30 of my time.This kind of project is for people who love to tinker. The economics do not make sense.\n \nreply",
      "Repairability is not necessarily a factor here. A better toaster may need less repair over its lifetime, and thus be more cost effective over its lifetime than a cheaper toaster that will break sooner and probably make worse toast while it works.Tangentially related: https://en.wikipedia.org/wiki/Boots_theory\n \nreply",
      ">I know so many people in my life that can afford the better quality version of something, but instead opt for the cheaper, shittier version. When the shitty one dies, they get a new shitty one.Where I once lived in the midwest this was called the 'Kame-apart mentality'.But I don't why this toaster can't cost more or less the same, and it comes with that non-purchasable accessory, bragging rights.\n \nreply",
      "My toaster broke a week ago. I tried repairing it and found out exactly what the post says: almost impossible without breaking it (or seriously bending parts just to take them apart). After realizing that I wouldn't be able to, I decided to buy a used one, but couldn't find any on offer around my area that looked in good enough shape. Ended up paying 25\u20ac for a new one, which will arrive by post any time soon. I find the whole experience extremely unsatisfying and would love more of this (repairable and self-assembly-able electric appliances).\n \nreply",
      "Having mended a few toasters in my time I salute this effort. Cheap toasters are very difficult to take apart and mend. The toasting mechanism on this one looks great.Cheap toasters only last a few years before dying. Usually because someone jams it up then clumsily unjams it while damaging the element.After going through a few toasters in quick succession I finally bought an expensive Dualit one. It's still going 25 years later. I changed the timer mechanism once which was a joy, and you can easily buy spare parts.The Dualit cost over 10 times more than the cheap toasters though. I don't regret that purchase though and it has actually saved me money over the years and made much less landfill.Funnily enough the toaster in this article looks quite like the Dualit. I don't suppose that is a coincidence!\n \nreply",
      "Dualit \"Classic\" toasters are the only toasters I'm aware of with heating elements that can be replaced. Every cheap toaster I've owned has died from the wire in one of the heating elements burning out. The only two toasters I'd buy these days are a Dualit or a vintage Sunbeam Radiant Control toaster. Dualit wins for the modern slot widths though.\n \nreply"
    ],
    "link": "https://www.kaseyhou.com/#/repairable-flatpack-toaster/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: ArchGW \u2013 An open-source intelligent proxy server for prompts (github.com/katanemo)",
    "points": 8,
    "submitter": "sparacha",
    "submit_time": "2025-03-04T21:14:56 1741122896",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/katanemo/archgw",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        AI-native (edge and LLM) proxy for agents. Move faster by letting Arch handle the pesky heavy lifting in building agentic apps -- \u26a1\ufe0f query understanding and routing, seamless integration of prompts with tools, and unified access and observability of LLMs. Built by the contributors of Envoy proxy.\n      Arch is an intelligent (edge and LLM) proxy designed for agentic applications - to help you protect, observe, and build agentic tasks by simply connecting (existing) APIs.Quickstart \u2022\nDemos \u2022\nBuild agentic apps with Arch \u2022\nUse Arch as an LLM router \u2022\nDocumentation \u2022\nContact\n\n\nArch Gateway was built by the contributors of Envoy Proxy with the belief that:Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and"
  },
  {
    "title": "The cost of Go's panic and recover (jub0bs.com)",
    "points": 102,
    "submitter": "todsacerdoti",
    "submit_time": "2025-03-01T08:19:11 1740817151",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=43217209",
    "comments": [
      "> panic and recover are best reserved for exceptional circumstances.You might go with Joshua Bloch and say exceptions are also best reserved for exceptional circumstances (which actually only means \"things aren't working as expected\"), that's why Go's authors used \"panic\" instead of \"throw\" or something similar, to make clear that it shouldn't be used where you might use exceptions in other languages. I mean, it's in the FAQ too: https://go.dev/doc/faq#exceptions\n \nreply",
      "You know why I hate exceptions most?When debugging be it C# or JS, neither the \"break on all exceptions\" or \"break on caught exceptions\" are useful on any app. One just hits random library shit, or whatever bloat is in the codebase all the time and the other won't break at all.But because exceptions are the control flow that is the only way to debug them (or do a human binary search)Not sure what go debugging is like but I imagine you can quickly work your way to the first err!=nil while debugging.\n \nreply",
      "I don't know about C#, but in my Java IDE when I set a breakpoint on an exception I can set a filter not only on the class being throw, but also on the class that catch it, the one that throws it and  the caller method, and to trigger only after another breakpoint is hit or it is the nth times it has been passed. With this you can make it trigger only when needed in a farly easy way\n \nreply",
      "It's the same for the mainstream debuggers for .NET.\n \nreply",
      "But if that class is thrown again and again it is less useful which I see in a lot of codebases.The go equivalent is \"catch the exception when it happens here\"A debugger feature for that would be nice. I guess it is a debugger concern not an exceptions issue per se.\n \nreply",
      "There is a `justMyCode` option even in VSC: https://code.visualstudio.com/docs/csharp/debugger-settings#...\n \nreply",
      "Well, \"break on exceptions\" can be very powerful when used correctly, i.e. when the scope is narrowed down. It should never be a flag that is turned on all the time -- that's guaranteed misery there.> quickly work your way to the first err != nil while debuggingI doubt you'll spend any less time debugging in Go. If you disagree, I'd love to see a \"side-by-side\" comparison for code that's functionally the same but written in both Go and JS, and see some explanations why it's easier in Go\n \nreply",
      "I've shipped code in JS, Python, C++, Java, Golang, and a few others. I can say with certainty Golang was the easiest to debug simply because if a layer could fail, it was explicitly obvious. Exceptions might come from a few layers deep, and you don't know that until one gets raised.\n \nreply",
      "> Not sure what go debugging is like but I imagine you can quickly work your way to the first err!=nil while debugging.How do you imagine that happening? I can\u2019t see another way then either stepping through your code or setting breakpoints on all the \u2018return nil, err\u2019 statements. You rarely, if ever, can use a \u2018watch variable\u2019 feature, because each function will have its own local \u2018err\u2019, and will have a new one on each invocation.If, instead of \u2018return buil, err\u2019, there\u2019s \u2018throw new\u2026\u2019 in such blocks, I don\u2019t see why you couldn\u2019t do the same things.\n \nreply",
      "That's very opposite from my experience in c++. Enabling break on throw in gdb or lldb always brings me exactly where I need to be no matter the OS / platform. But the software in c++ pretty much always adheres to \"exceptions only for exceptional circumstances\" and thankfully let them bubble up without rethrow \u00e0 la java, otherwise it would be absolutely terrible developer ux\n \nreply"
    ],
    "link": "https://jub0bs.com/posts/2025-02-28-cost-of-panic-recover/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Appstat \u2013 Process Monitor for Windows (pragmar.com)",
    "points": 71,
    "submitter": "pragmar",
    "submit_time": "2025-03-04T15:24:32 1741101872",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=43255855",
    "comments": [
      "procmon and process explorer from sysinternals are really good. and there is performance counters.\n \nreply",
      "Nice job!  I love the clean interface. Is this written in C#?\n \nreply",
      "Thanks, yeah it is C#/.net9 and WinUI3. I started with C#/WPF, but wanted to get it on the Windows Store and couldn't figure out that would work with WPF.\n \nreply",
      "I usually lean on Resource Monitor when I need this kind of info, but it's clunky - so this looks useful!\n \nreply",
      "Looks great. Thanks. One thing, maybe make it clear that it's free? I went looking for pricing especially when I saw the support link at the top.\n \nreply",
      "I realize now that the \"Support\" link is ambiguous. The price/free issue I'll think about how to make that clear, it's a good point. Going to wait for traffic to subside before making updates, but noted. Thanks\n \nreply",
      "Looks interesting, thanks!  Another one I like that hasn't been mentioned elsewhere in this thread is Process Hacker.\n \nreply",
      "This looks pretty cool. Thanks for sharing!\n \nreply",
      "So, yeah: I installed this, and was impressed, just because it's an .appx package. I mean, how do you even create those?Other than that: it did not immediately crypto-lock my laptop and/or ramp up my GPU mining F\u00fchrercoins, so that was good too.Other than that: I did not really see any metrics worth of attention, so I uninstalled the app again, which seemed to work fine as well.Thrilling stuff, I know...\n \nreply",
      "As an alternative, I use the free community-edition netdata -- love it at my job, and it works right out of the box on my personal windows and linux machines.https://www.netdata.cloud/pricing/(don't let the `.cloud` scare you off, they have a 100% free and functional local-only install)It's insanely powerful and with some configuration can persist the metrics in a local database.\n \nreply"
    ],
    "link": "https://pragmar.com/appstat/",
    "first_paragraph": "Monitor CPU, memory, disk, and thread metrics in real-time for running applications.\n                    Quickly identify resource bottlenecks, memory leaks, and performance spikes without\n                    interrupting your workflow. The graphical interface shows exactly what's happening\n                    when performance issues occur.Built for developers, appstat combines detailed monitoring with a clean interface. Select any running application to see its performance data instantly. Features include dark/light modes, always-on-top option, and exportable logs for team analysis.\nappstat is freeware.\n                    You can use appstat on any computer, including a computer in a commercial organization.\n                    There is no need to register or pay to use the software.\n                \n                    Windows ships with two process monitors included, Task Manager (taskmgr.exe) and Process Monitor (procmon.exe).                    \n                    Task Manager i"
  }
]