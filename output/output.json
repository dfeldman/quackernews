[
  {
    "title": "Google is dead. Where do we go now? (circusscientist.com)",
    "points": 469,
    "submitter": "tomjuggler",
    "submit_time": "2025-12-29T20:29:26 1767040166",
    "num_comments": 444,
    "comments_url": "https://news.ycombinator.com/item?id=46425198",
    "comments": [
      "I recently took someone to go and watch a hockey game. Been a little while but I personally played as a goalie myself.The person kept making the comment that she couldn't see/find the puck and it made it frustrating to watch.As a goalie, not being able to see the puck is pretty normal (especially with big bodies trying to screen you).What I told her was that what matters a lot more than where the puck is, is where it's going to be in about two seconds. But the next best thing is to know where the puck is now.If you can't see the puck then look at the players and as a last resort, look at the ref. 99% of the time they will be looking at the puck. Look where they're looking and soon enough it will appear.I think this applies very much to this whole Google question.The puck is gone (or on the way to the other side of the rink) and everyone is confused where it is or where it's going.Look where everyone is looking and you'll find your answer there. It may not be in the same form as Google adwords, but the game is the same. Leveraging attention.The tactics were different during the phonebook days (it was having your business start with the letter \"A\") as opposed to Google and will be different for the next thing as well.From what I can tell, everyone seems to be looking at chatbots and vertical, shortform video. Not sure how that plays out in terms of advertising, but in terms of the answer to this article's question, that seems like a good place to start.reply",
      "In my anecdotal experience, it's moved to private, trust-based channels: iMessage, WhatsApp, email, face-to-face interactions.  Our 30-year bender of putting our lives online and blurring the public and the private has finally ended: people don't want to be online, don't trust social media, don't really trust any media, and are living simple local lives with a small circle of friends that they get together with regularly in person.But then, my anecdotal experience may not be representative of most of the world.  Most of my friends have money, houses, kids, friends - all of which are, by the numbers, rarities these days.It's an interesting thought experiment to explore what it means if that actually is the new normal, and people are not consuming media or much of anything, or even if the people who are still addicted to social media are now tapped out and don't have any more disposable income left to spend.  Probably economic depression.  If everybody bought only what they needed and ignored all the advertisements, our present level of economic activity would plunge.reply",
      "I had a very interesting discussion with a friend today, where I was talking to her about the /r/golang thread about Rob Pike's comments to OpenAI and how the thread was full of bots talking with other bots. No idea why the density of bots was so high in that thread, it was kind of absurd to see.Then she said: \"I know nobody that comments on online forums. Nobody would ever comment to strangers on the internet. It's too dangerous.\"Took me a while to grasp what she meant with that, but I think she's right. Trust has eroded so much over the last two decades that most forums are either full of bots or full of annoyed and toxic people. It's very rare to find welcoming communities to newbies, and most of the ones I have discovered were offline connections.She also mentioned that all of her friends use private profiles only, because having public profiles is too dangerous because of stalkers.To me this sounded a bit absurd at first, but maybe that's a different perception on \"how to use\" the internet from a different younger generation that grew up post-socialmedia? My first contact with the internet was MIT opencourseware, her first contact was receiving dick pics at the age of 10 from assholes on the other side of the planet.I miss the old phpbb forum days when the most toxic comment was someone being snarky and derailing the discussion into \"did you use the search function?\"No idea how to fix the internet, maybe it's time to move to gopher or another protocol :-/reply",
      "But your friend is wrong. She does know at least one person who comments on online forums. I bet she knows more too.reply",
      "Most of the internet users are passive content consumers, and it\u2019s been the case since a long time ago. There's a post about it from 2019:https://bewilderbeast.org/2019/08/16/most-of-what-you-read-o...reply",
      "I know I self-censor a LOT.reply",
      "Thats just what the internet of the mid to late 90s was like.  People rarely used their real name, there were hundreds of forums, some private.  You could have different nicks on them.Nobody knew you were a dog on the internet[1] until the rise of Facebook and linking your real identity with an online identity.[1] https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_...reply",
      "They don't write on forums but they like or share a story. It's just more passive/consumer-minded.reply",
      "> No idea how to fix the internet, maybe it's time to move to gopher or another protocol :-/Fido and Usenet are still around. Kind-of. IMO google virtually killed that, too, when they started peddling google groups and did the classic embrace-extend-extinguish on the Usenet.reply",
      "And yet, here you are, posting ...BTW, I don't explicitly disagree with what you're saying, but it would be good to look at actual data instead of anecdata to know for sure, and the people who have the data are not telling ...reply"
    ],
    "link": "https://www.circusscientist.com/2025/12/29/google-is-dead-where-do-we-go-now/",
    "first_paragraph": ""
  },
  {
    "title": "MongoDB Server Security Update, December 2025 (mongodb.com)",
    "points": 21,
    "submitter": "plorkyeran",
    "submit_time": "2025-12-30T00:23:47 1767054227",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=46427920",
    "comments": [
      "Why did it take them 4 days between publishing a CVE for the vulnerability (Dec 19th) and posting a public patch (Dec 23rd)?reply",
      "In the US, the last two weeks of December can be slow due to the holiday season. I wouldn\u2019t be surprised if Mongo wasn\u2019t as staffed as usual.reply",
      "That's a good question. I suppose that posting the patch makes it incredibly obvious how to exploit the issue, so maybe they wanted to wait a little bit longer for their on-prem users who were slow to patch?reply",
      "1 day ago, 116 comments: https://news.ycombinator.com/item?id=46414475reply",
      "Who has mongo open to the internet?reply",
      "Ubisoft doesreply"
    ],
    "link": "https://www.mongodb.com/company/blog/news/mongodb-server-security-update-december-2025",
    "first_paragraph": "At MongoDB, protecting our customers\u2019 data is our highest priority. On December 12, 2025, the MongoDB Security Engineering team identified a security vulnerability, described in CVE-2025-14847, which impacts MongoDB Server. Within the security community, this vulnerability is informally referred to as \u201cMongobleed.\u201d This blog post outlines the situation, our immediate response, and the key insights we\u2019ve gathered so far. Security is an ongoing responsibility in modern software development for both software producers and consumers, and maintaining trust depends on how issues are identified, addressed, and communicated.\u00a0This patched security vulnerability in the MongoDB Server products (Community and Enterprise) is not a breach or compromise of MongoDB, MongoDB Atlas (our managed MongoDB Server offering), or our systems. To maintain the highest levels of security, customers and users are advised to use the latest versions of MongoDB\u2019s software that have been updated to address this vulner"
  },
  {
    "title": "Show HN: Stop Claude Code from forgetting everything (github.com/mutable-state-inc)",
    "points": 63,
    "submitter": "austinbaggio",
    "submit_time": "2025-12-29T22:30:25 1767047425",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=46426624",
    "comments": [
      "I'm not sure how many HN users frequent other places related to agentic coding like the subreddits of particular providers, but this has got to be the 1000th \"ultimate memory system\"/break-free-of-the-context-limit-tyranny! project I've seen, and like all other similar projects there's never any evidence or even attempt at measuring any metric of performance improved by it. Of course it's hard to measure such a thing, but that's part of exactly why it's hard to build something like this. Here's user #1001 that's been told by Claude \"What a fascinating idea! You've identified a real gap in the market for a simple database based memory system to extend agent memory.\"reply",
      "I struggle with these abstractions over context windows, esp when anthropic is actively focused on improving things like compaction, and knowing the eventual* goal is for the models to yave real memory layers baked in. Until then we have to optimize with how agents work best and ephemeral context is a part of that (they weren\u2019t RL\u2019d/trained with memory abstractions so we shouldn\u2019t use them at inference either). Constant rediscovery that is task specific has worked well for me, doesn\u2019t suffer from context decay, though it does eat more tokens.Otherwise the ability to search back through history is a valuable simple git log/diff or (rip)grep/jq combo over the session directory. Simple example of mine: https://github.com/backnotprop/rg_historyreply",
      "There is certainly a level where at any time you could be building some abstraction that is no longer required in a month, or 3.I feel that way too. I have a lot of these things.But the reality is, it doesn't really happen that often in my actual experience. Everyone is very slow as a whole to understand what these things mean, so far you get quite a bit of time just with an improved, customized system of your own.reply",
      "My somewhat naive heuristic would be that memory abstractions are a complete mistep in terms of optimization. There is no \"super claude mem\" or \"continual claude\" until there actually is.reply",
      "I tend to agree with you, however compacting has gotten much worse.So... it's tough. I think memory abstractions are generally a mistake, and generally not needed, however I also think that compacting has gotten so wrong recently that they are also required until Claude Code releases a version with improved compacting.But I don't do memory abstraction like this at all. I use skills to manage plans, and the plans are the memory abstraction.But that is more than memory. That is also about having a detailed set of things that must occur.reply",
      "I\u2019m interested to see your setup.I think planning is a critical part of the process. I just built https://github.com/backnotprop/plannotator for a simple UX enhancementBefore planning mode I used to write plans to a folder with descriptive file names. A simple ls was a nice memory refresher for the agent.reply",
      "I understand the use case for plannotator. I understand why you did it that way.I am working alone. So I am instead having plans automatically update. Same conception, but without a human in the mix.But I am utilizing skills heavily here. I also have a python script which manages how the LLM calls the plans so it's all deterministic. It happens the same way every time.That's my big push right now. Every single thing I do, I try to make as much of it as deterministic as possible.reply",
      "There are a quadrillion startups (mem0, langmem, zep, supermemory), open source repos (claude-mem, beads), and tools that do this.My approach is literally just a top-level, local, git version controlled memory system with 3 commands:- /handoff - End of session, capture into an inbox.md- /sync - Route inbox.md to custom organised markdown files- /engineering (or /projects, /tasks, /research) - Load context into next sessionI didn't want a database or an MCP server or embeddings or auto-indexing when I can build something frictionless that works with git and markdown.Repo: https://github.com/ossa-ma/double (just published it publicly but its about the idea imo)Writeup: https://ossa-ma.github.io/blog/doublereply",
      "Your approach essentially matches mine, but I call them plans. I agree with you that the other tools don't seem to add any value compared to this structure.I think at this point in time, we both have it right.reply",
      "The extention Cline has a \"memory bank\" feature. It's just a markdown you add as an instruction. Works well for me. Worked with agents.md as well so not just with the Cline extention. Pretty much the same idea.reply"
    ],
    "link": "https://github.com/mutable-state-inc/ensue-skill",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \nhttps://ensue.dev\n There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Get smarter alongside your AI.Your intelligence shouldn't reset every conversation. Ensue is a persistent knowledge tree that grows with you - what you learn today enriches tomorrow's reasoning.Every conversation with an LLM starts from zero. You explain context, re-establish preferences, repeat decisions you've already made. Your knowledge doesn't compound.Ensue changes that:Think of it as extended memory. When you ask about GPU inference, the LLM checks what you already know. When you make an architecture decision, it connects to past decisions in similar domains. Your accumulated knowledge becomes part of every conversation.Restart Claude Code. The skill will guide you through setup.Docs \u00b7 Dashboard \u00b7 Ho"
  },
  {
    "title": "Bye Bye Big Tech: How I Migrated to an Almost All-EU Stack (and Saved 500\u20ac/Year) (zeitgeistofbytes.com)",
    "points": 22,
    "submitter": "alexcos",
    "submit_time": "2025-12-29T23:50:06 1767052206",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=46427582",
    "comments": [
      "I\u2019m heavily invested in the Google ecosystem and nothing would make me happier than switching to a privacy-focused European alternative.However, the value of the Google Workspace mid-tier (approx. 15\u20ac) is hard to beat, I think. I get:- granular domain \\ email controls (blocklists, routing rules, etc.)\n- 2tb of google drive space\n- and now Gemini, which is quite niceIt\u2019s 2025, and I\u2019m still finding it impossible to leave :(reply",
      "For me its going from $0 to $15 a month using Proton which feels way to high. Im cutting proton and switching to Proton free tier for email and Backblaze for storage. Getting a little $100 pc to put in my draw to handle hosting all the stuff i need. My budget is around $10 a month to cover all the tech NEEDS. I think its doable but I will need to pay with my time to learn about/setup a foss stack. I'll also need to put some money aside to drop a donation to each project in the stack yearly.reply",
      "I Spend 0. I don't understand why anyone would need most of these services.reply",
      "> Blogging, Newsletter & Co.: Well, as you can see, I\u2019m writing on Substack. There are no alternatives except to host it entirely yourself, but that doesn\u2019t make sense to me right now.This is wrong. There are loads of alternatives, which I can't remember at the moment. AlternativeTo.net lists Hyvor Blogs (https://blogs.hyvor.com/), which isn't one of the ones I was familiar with and cannot vouch for, but serves as an existence proof. Does anyone know any better ones?reply",
      "Substack is both a blogging platform and a micro-social network with a feed and a subscriptions SaaS so really depends on what parts you want from it the mostreply",
      "boosty.to is a Substack alternative, outside of both the US and the EU.reply",
      "https://www.beehiiv.com/ is another one.reply"
    ],
    "link": "https://www.zeitgeistofbytes.com/p/bye-bye-big-tech-how-i-migrated-to",
    "first_paragraph": ""
  },
  {
    "title": "Geology of the Gulf of the Farallones National Marine Sanctuary (usgs.gov)",
    "points": 24,
    "submitter": "greesil",
    "submit_time": "2025-12-29T23:12:00 1767049920",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46427181",
    "comments": [
      "For us non-Californians:    Gulf of the Farallones is home to major shipping lines to the \n    Port of San Francisco, Port of Oakland, and Port of Richmondreply",
      "The Farallones are a group of islands about ~27 miles, pretty much due west of the Golden Gate Bridge. They're not huge but you can see them with the naked eye from the top of Mt Diablo about 50 miles away. There's a scientific research station on the largest one but due to their rocky coast (and environmental law) they're difficult or impossible to visit by boat.reply",
      "You can see them with the naked eye from most of the bay area coast, weather/smog permitting. My favorite is Point Reyes.reply",
      "Also, part of the City and County of San Francisco!reply",
      "Soon to be renamed The Gulf of Newsom.reply",
      "This is a fine submission, but if you want to say what you think is important about an article, please do it by adding a comment to the thread. Then your view will be on a level playing field with everyone else's: https://hn.algolia.com/?dateRange=all&page=0&prefix=false&so...(Submitted title was \"50,000 drums of radioactive wastes were dumped near the Farallones, 1946 to 1970\")reply",
      "that's cool we also have a few thousand drums of DDT off LA's shores. https://en.wikipedia.org/wiki/Toxic_ocean_dumps_off_Southern...This all comes from an era where the prevailing thought was the solution for pollution is dilution.reply",
      "Hey my dad used to wipe the stuff of tomatoes before eating them right off the vine.I\u2019m mostly ok, have the normal number of arms and legs. Only had one tumor, and just a few endocrine issues. Nothing major, it\u2019s all good.reply"
    ],
    "link": "https://pubs.usgs.gov/fs/farallones/",
    "first_paragraph": "                                     Coastal and Marine Geology Program\r > Geology of the Gulf of the Farallones National Marine Sanctuary             Dr. Herman Karl and colleagues. [larger version]   \"The geology and oceanography of the Farallones and surrounding area is atypical and complex. These factors complicate the process of understanding the environmental effects of man's influence such as the disposal of dredge spoils and radioactive wastes. Our goal is to assemble, in a non-crisis mode, geological information to support sound management decisions for any purpose.\"\r\r- Dr. Herman Karl, U.S. Geological Survey Considerable public attention has focused on the environmental stress in and around the Gulf of the Farallones National Marine Sanctuary (NMS). \rThe U.S. Geological Survey (USGS) provides geological information in support of studies related to proposed \rsiting of offshore areas for disposal of dredge spoils and to determining locations of barrels of radioactive waste. The"
  },
  {
    "title": "Parsing Advances (matklad.github.io)",
    "points": 27,
    "submitter": "birdculture",
    "submit_time": "2025-12-29T23:29:35 1767050975",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=46427376",
    "comments": [
      "Huh, that's a really interesting approach. I just wrote my first Pratt parser a month ago, and one of the most annoying things was debugging infinite loops in various places (I had both tokenizer bugs where no characters were consumed and parser bugs where a token was emitted but not advanced). It's doubly annoying in Zig, because the default test runner won't print out stdout at all, and won't print stderr unless the program terminates by itself (Ctrl + C doesn't print). I resorted to building the test and running it manually, or jumping into a debugger to figure out recursion issues. It's working now, but if (really when) I run into issues in the future I'll definitely add some helper functions to check emitting invariants.reply",
      "How about another way, which is memoization: at each position in the source code we never attempt to parse the same production more than once. This solves infinite looping as discussed by the author because the \u201cloop\u201d will be downgraded by the memoization to execute once. Of course I wouldn't literally use a while loop in code to represent the production. I would use a higher-level abstraction to indicate one-or-more or zero-or-more in the production; indeed I would represent productions as data not code.This also has another benefit of work sharing. A production like `A B | C B` will ensure that in case parsing A or C consumes the same number of characters, the work to parse B will be shared, despite not literally factoring the production into `(A | C) B`.reply",
      "That's a slick way, would you essentially have a second counter that you'd set to the current cursor whenever you use `.currentToken()` or something like that?reply"
    ],
    "link": "https://matklad.github.io/2025/12/28/parsing-advances.html",
    "first_paragraph": "\n          I find myself writing yet another toy parser, as one does during a\n          Christmas break. It roughly follows\n          Resilient LL Parsing Tutorial. Not because I need\n          resilience, but mostly because I find producing a syntax tree and a\n          collection of diagnostics a more natural fit for the problem than\n          bailing out on the first error.\n        \n          One practical pitfall with the approach is infinite loops/recursion.\n          Resilience sometimes means\n          not consuming a token, and, if you do that in a loop or a\n          Pratt recursive call, you\u2019ll get yourself an annoying to debug error:\n        \n          For a concrete example, you might parse function argument list using\n          code like this:\n        \n          The implicit contract here is that expression consumes at\n          least one token, even if there are errors in the source code. If\n          there\u2019s some token that makes expression bail without\n          consumi"
  },
  {
    "title": "100x (YC S22) Is Hiring a Founding Front End Engineer",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-12-30T01:00:03 1767056403",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=46428206",
    "first_paragraph": ""
  },
  {
    "title": "When someone says they hate your product (getflack.com)",
    "points": 90,
    "submitter": "jger15",
    "submit_time": "2025-12-29T19:30:40 1767036640",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=46424460",
    "comments": [
      "In my experience, haters are some of the most passionate users, if you can do even the smallest thing to demonstrate a desire to improve, they'll often be huge advocates over the medium term.I was working at a startup and we got some frustrating and hostile feedback from a user, I responded by acknowledging the issue and sending them a beta build that attempted to fix their issue. (it did not, but...)Just reaching out and trying to engage made an enormous difference. They ended up contributing significantly to isolating and fixing that specific bug and others in the future, and referring us a few customers to boot, if I remember correctly.reply",
      "You've not met a real hater if you think this, and should consider yourself very lucky. That was just a frustrated user.A real hater will obsessively use your product, yet simultaneously attempt to find any reason whatsoever to hate your product (or you), no matter how small, and be extremely vocal about it, to the point of founding new communities centered on complaining about you. Should you address the issue, they will silently drop that one from their regularly posted complaints and find or invent a new one. Any communication you send to them will be purposefully misinterpreted and combined with half truths and turned against you.Some of these people probably have genuine mental illnesses that makes them act like this.reply",
      "Just to be clear, this particular user didn't ever become a fountain of sweetness and light - they were pretty touchy and cranky at the best of times, if I remember right (it's been over a decade), but accepting them as they were let them become a contributor instead of toxic.Honestly I have thick enough skin that I'm happy to let them be themselves as long as we can reach a basis of professionalism and get a positive result.You're right that there are many people you can't reach, and trying is a waste of effort, but I think an appreciation for human dignity requires me to at least make the attempt, and sometimes you're rewarded.reply",
      "Yeah, which is why I think it's important to draw a line between a frustrated user (has genuine issues with his use of the product, can be turned by fixing them), a casual troll (reposts some bad feedback because he thinks it's funny) and a hater (malicious, bad faith, communication not recommended)reply",
      "Indeed. If someone hates your product, at least they care. Indifference is much harder to work with. My experience of dealing with haters:https://successfulsoftware.net/2024/02/25/it-might-be-a-good...reply",
      "Agreed, I\u2019ve experienced that myself. But I\u2019ve also experienced the opposite: the user who always complains, doesn\u2019t think things through, refuses to consider how their ideas would impact other users, doesn\u2019t follow instructions\u2026In some cases, had I had the power to do so, there are a few users who I\u2019d gladly have \u201cfired\u201d: offer a full refund in exchange for no more support.reply",
      "People hate because they care. There's some exceptions (like bandwagon hating), but the people who hate on something the most tend to be people who want to like the product.reply",
      "Exactly, they bought into the promise but the product didn't deliver. If a user expects your product to suck, you won't surprise (anger) them by being sucky.reply",
      "Thats because most complainers really need their egos soothed more than anything.reply",
      "Haters can be like bombs. You want to defuse them. Don't shake 'em. Don't drop 'em. Just render them safe. It's possible there's some gold in the ore; there might be, and if there is, accept it gratefully; but it's often hard to tell the constructive true-believer from the vindictive maniac. Your #1 job is to make it all inert, and to be able to walk away without an explosion destroying the business, social-media explosion or otherwise.reply"
    ],
    "link": "https://www.getflack.com/p/responding-to-negative-feedback",
    "first_paragraph": ""
  },
  {
    "title": "Static Allocation with Zig (nickmonad.blog)",
    "points": 155,
    "submitter": "todsacerdoti",
    "submit_time": "2025-12-29T16:07:27 1767024447",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=46422009",
    "comments": [
      "One key thing to understand about TigerBeetle is that it's a file-system-backed database. Static allocation means they limit the number of resources in memory at once (number of connections, number of records that can be returned from a single query, etc). One of the points is that these things are limited in practice anyways (MySQL and Postgres have a simultaneous connection limit, applications should implement pagination). Thinking about and specifying these limits up front is better than having operations time out or OOM. On the other hand, TigerBeetle does not impose any limit on the amount of data that can be stored in the database.=> https://tigerbeetle.com/blog/2022-10-12-a-database-without-d...It's always bad to use O(N) memory if you don't have to. With a FS-backed database, you don't have to. (Whether you're using static allocation or not. I work on a Ruby web-app, and we avoid loading N records into memory at once, using fixed-sized batches instead.) Doing allocation up front is just a very nice way of ensuring you've thought about those limits, and making sure you don't slip up, and avoiding the runtime cost of allocations.This is totally different from OP's situation, where they're implementing an in-memory database. This means that 1) they've had to impose a limit on the number of kv-pairs they store, and 2) they're paying the cost for all kv-pairs at startup. This is only acceptable if you know you have a fixed upper bound on the number of kv-pairs to store.reply",
      "Yes, very good point, thanks!As a tiny nit, TigerBeetle isn't _file system_ backed database, we intentionally limit ourselves to a single \"file\", and can work with a raw block device or partition, without file system involvement.reply",
      ">we intentionally limit ourselves to a single \"file\", and can work with a raw block device or partition, without file system involvementthose features all go together as one thing. and it's the unix way of accessing block devices (and their interchangeability with streams from the client software perspective)you're right, it's not the file system.reply",
      "That makes sense. For example, your redis instance will have fixed RAM, so might as well pre-allocate it at boot and avoid fragmentation.Memcached works similarly (slabs of fixed size), except they are not pre-allocated.If you're sharing hardware with multiple services, e.g. web, database, cache, the kind of performance this is targeting isn't a priority.reply",
      "> All memory must be statically allocated at startup. No memory may be dynamically allocated (or freed and reallocated) after initialization. This avoids unpredictable behavior that can significantly affect performance, and avoids use-after-free. As a second-order effect, it is our experience that this also makes for more efficient, simpler designs that are more performant and easier to maintain and reason about, compared to designs that do not consider all possible memory usage patterns upfront as part of the design.\n> TigerStyleIt's baffling that a technique known for 30+ years in the industry have been repackage into \"tiger style\" or whatever this guru-esque thing this is.reply",
      "Snide and condescending (or at best: dismissive) comments like this help no one and can at the extremes stereotype an entire group in a bad light.I think the more constructive reality is discussing why techniques that are common in some industries such as gaming or embedded systems have had difficulty being adopted more broadly, and celebrating that this idea which is good in many contexts is now spreading more broadly! Or, sharing some others that other industries might be missing out on (and again, asking critically why they aren't present).Ideas in general require marketing to spread, that's literally what marketing is in the positive (in the negative its all sorts of slime!). If a coding standard used by a company is the marketing this idea needs to live and grow, then hell yeah, \"tiger style\" it is! Such is humanity.reply",
      "Marketing is the thing that makes uninformed people adopt thing they don't need.I dont think we need marketing, but rather education, which is the actually useful way to spread information.If you think marketing is the way knowledge spreads, you'll end up with millions of dollars in your pocket and the belief that you have money because you're doing good, while the truth is that you have millions because you exploited others.reply",
      "Because garbage-collected languages are easier to teach and to use. So the low-level, low-resource or high-performance stuff is left to a handful of specialists - or \"insects\" according to Heinlein. Speaking of old things, this reminds me of one of Asimov's short stories, where someone who rediscovers mental calculus is believed to be a genius.reply",
      "> had difficulty being adopted more broadlyMost applications don\u2019t need to bother the user with things like how much memory they think will be needed upfront. They just allocate how much and when necessary. Most applications today are probably servers that change all the time. You would not know upfront how much memory you\u2019d need as that would keep changing on every release! Static allocation may work in a few domains but it certainly doesn\u2019t work in most.reply",
      "It's best to think of it as an entire spectrum from \"statically allocate everything  with compile time parameters\" to \"directly call the system allocator for every new bit of memory\". It's just a helpful way to separate the concerns of memory allocation from memory usage.What this article is talking about isn't all the way at the other end (compile time allocation), but has the additional freedom that you can decide allocation size based on runtime parameters. That frees the rest of the application from needing to worry about managing memory allocations.We can imagine taking another step and only allocating at the start of a connection/request, so the rest of the server code doesn't need to deal with managing memory everywhere. This is more popularly known as region allocation. If you've ever worked with Apache or Nginx, this is what they do (\"pools\").So on and so forth down into the leaf functions of your application. Your allocator is already doing this internally to help you out, but it doesn't have any knowledge of what your code looks like to optimize its patterns. Your application's performance (and maintainability) will usually benefit from doing it yourself, as much as you reasonably can.reply"
    ],
    "link": "https://nickmonad.blog/2025/static-allocation-with-zig-kv/",
    "first_paragraph": "Over the past few months I've been chipping away at a small Redis-compatible key/value server called\nkv. The goal is to have something (mostly) production-ready, while implementing\nonly a small subset of commands. The world doesn't necessarily need another key/value store, I'm just interested in\nimplementing it in Zig and learning about some new (to me) techniques for systems programming.One of those techniques is static memory allocation during initialization. The idea here is that all memory is requested\nand allocated from the OS at startup, and held until termination. I first heard about this while learning about\nTigerBeetle, and they reference it explicitly in their development style guide dubbed \"TigerStyle\".All memory must be statically allocated at startup. No memory may be dynamically allocated (or freed and reallocated)\nafter initialization. This avoids unpredictable behavior that can significantly affect performance, and avoids use-after-free.\nAs a second-order effect, it is "
  },
  {
    "title": "Flame Graphs vs Tree Maps vs Sunburst (2017) (brendangregg.com)",
    "points": 99,
    "submitter": "gudzpoz",
    "submit_time": "2025-12-27T11:30:40 1766835040",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=46401052",
    "comments": [
      "Personally, I find treemaps unmatched for disk space analysis. Specifically, I like to use the squarify layout algorithm, to NOT use the \"cushion gradient\" shading method, to use inset frames to convey depth visually, and to include filenames. This maximizes glanceable information density, for the use case of identifying large objects to delete to recover space.This is how the old spacemonger app worked, and I liked it so much I had to recreate it for Linux/Mac: https://github.com/alanbernstein/treemonger. My version still needs some work, but it's minimally useable.reply",
      "Treemaps are also good for profiling (see KCachegrind), they waste a lot less space than flamegraphs and the area-relationship is relatively well maintained.reply",
      "The treemap screenshot doesn't look correct. Nearly all charting libs (like Apache Echarts) will group nodes with a heading name, so not sure why they claim it would be hard to notice the \"drivers\" node. I guess in that screenshot, sure, but that looks like just a bad implementation of a treemap. Maybe this was the case back in 2017?Flame graphs I have a love/hate relationship with. The hierarchy is very useful, but the name and coloring can be very confusing and misleading. Most people I show them to think red == something bad, but the color is actually just for aesthetics.reply",
      "At an old startup attempt we once created a nested hierarchy metrics visualization chart that I later ended up calling Bookshelf Charts, as some of the boxes filled with with smaller boxes looked like a bookshelf (if you tilted your head 90 degrees). Something between FlameGraphs and Treemaps. We also picked \u201crandom\u201d colors for aesthetics, but it was interactive enough so you could choose a heat map color for the plotted boxes (where red == bad).The source code got lost ages ago, but here are some screenshots of bookshelf graphs applied to SQL plan node level execution metrics:https://tanelpoder.com/posts/sql-plan-flamegraph-loop-row-co...reply",
      "Treemap is the densest/most accurate information source on a per px basis. Flamegraphs are pretty good but with a fixed Y and variable X your box area is inaccurate, and it wastes a fair amount of plot space with the non-flame area. The sunburst chart is really pretty but bad from an information communication perspective.reply",
      "Flamegraphs are a really lovely tool for visualizing trees. Slightly related anecdote:A while ago I was experimenting with interactive exploration of (huge) Monte Carlo Tree Search trees. Inspired by file system visualization tools, my first attempts were also tree maps and sunburst graphs, but I ran into the same problems as in the article.I tried flamegraphs next with the following setup:- The number of visits in each node maps to the width and order of each bar (i.e., the most visited node was first and was the largest)- The expected value maps to the color of each bar.And then it was a perfect fit: it's easy to see what's going on in each branch at the first levels, and the deeper levels can be explored through drilling down.reply",
      "All of these suck. Use nested bar graphs like TreeSize and it\u2019s instantly obvious what your biggest hitter is for any particular nesting level.In lieu of that, a flame graph is tolerable. The polar coordinate one is very pretty garbage. EDIT: Use it when you want to mislead people with a flashy graph.reply",
      "All embeddings of hyperbolic space into eucleadean space suck. You can't preserve distances and areas between them. Trees live in a hyperbolic space so every visualization of trees on a screen will suck in some way.This simple math fact is the reason why all grand hyperlink projects from 1960 to 2010 couldn't work, e.g. Xanadu.Worse, in small examples with fewer than a hundred nodes it looks like it is a real improvement over linear text with jumps - we are after all now using _all_ the possible screen real estate.reply",
      "Ehhh. I think if you're trying to show the overall costs of something to someone that conclusion makes sense, but interactive flame graphs are the best way imo to look into things. Especially making use of sandwich views, which allow you to pivot the flame graph around some function to see callers and callees by cost.Edit: I'll keep this up to share my embarrassment, but I missed entirely that the article was about disk space. I admit I only looked at the pictures haha.reply",
      "Why do treemaps suck?reply"
    ],
    "link": "https://www.brendangregg.com/blog/2017-02-06/flamegraphs-vs-treemaps-vs-sunburst.html",
    "first_paragraph": "Brendan's site:06 Feb 2017Yesterday I posted about flame graphs for file systems, showing how they can visualize where disk space is consumed. Many people have responded, citing other tools and visualizations they prefer: du, ncdu, treemaps, and the sunburst layout. Since there's so much interest in this subject, I've visualized the same files here (the source for linux 4.9.-rc5) in different ways for comparison.Using FlameGraph (SVG):\n\nWhile you can mouse-over and click to zoom, at first glance the long labeled rectangles tell the big picture, by comparing their lengths and looking at the longest first:The drivers directory looks like it's over 50%, with drivers/net about 15% of the total. Many small rectangles are too thin to label, and, they also matter less overall. You can imagine printing the flame graph on paper, or including a screen shot in a slide deck, and it will still convey many high level details in not much space. Here's an example someone just posted to twitter.Using G"
  },
  {
    "title": "Vitest Browser Mode Guide (howtotestfrontend.com)",
    "points": 20,
    "submitter": "howToTestFE",
    "submit_time": "2025-12-25T00:02:29 1766620949",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://howtotestfrontend.com/resources/vitest-browser-mode-guide-and-setup-info",
    "first_paragraph": "Dec 2025 - updated with improvements\nthanks to Vladimir (@erus.dev on bsky)One of the most exciting developments in the last few years when it comes to testing is definitely Vitest Browser Mode . In this article I am going to tell you everything you need to know.And this is such a big change in the JS testing ecosystem - I believe that within a year or two, all frontend engineers will need to know what Vitest Browser Mode is just like we all have to at least be aware of Jest/Vitest test runners, Cypress/Playwright E2E tests etc.Good questions!This blog post is about Vitest Browser Mode - it is a special way of running tests within Vitest.If you are very new to all of this, check out my completely free 19 lessons on Vitest fundamentalsVitest Browser Mode combines several powerful features:This is different to running E2E (End to end) tests directly in Playwright.With Vitest browser mode we are still testing individual components by themselves. Just with a real browser. So all the web AP"
  },
  {
    "title": "List of domains censored by German ISPs (cuiiliste.de)",
    "points": 294,
    "submitter": "elcapitan",
    "submit_time": "2025-12-29T18:21:30 1767032490",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=46423566",
    "comments": [
      "39c3 talk about this tomorrow (in German, but usually available with English translation) https://fahrplan.events.ccc.de/congress/2025/fahrplan/event/...reply",
      "So it is a collection of the best pirate sites?reply",
      "No, it isn't so. It misses even the most notorious yet still private sitesreply",
      "It is to me, faved.reply",
      "We are condemned to, every time a list of blocked sites is posted, endure the \"hahaha this is great guys a list of pirate sites! bookmarked!!!!\" edgy comments.reply",
      "I don\u2019t know why you think this is an edgy comment, I\u2019m actually screenshotting it to take a look tomorrow at the links. I\u2019ve seen Anna archive and SCI hub which are extremely useful, if it helps finding more gems I\u2019m all for it !reply",
      "You're screenshotting URLs to type out?reply",
      "It read that way to me too. It's the familiar switcheroo/hoist by their own petard/ironic one-upping move, a routine as well known to the internet as ape behavior is to Jane Goodall.reply",
      "Well it's the truth \u00af \\ _ ( \u30c4 ) _ / \u00afreply",
      "Pretty much, yeah. Those they can't get to despite efforts.reply"
    ],
    "link": "https://cuiiliste.de/domains",
    "first_paragraph": ""
  },
  {
    "title": "Kidnapped by Deutsche Bahn (theocharis.dev)",
    "points": 929,
    "submitter": "JeremyTheo",
    "submit_time": "2025-12-29T12:24:00 1767011040",
    "num_comments": 836,
    "comments_url": "https://news.ycombinator.com/item?id=46419970",
    "comments": [
      "DB is weird. They seem to make their own rules and then run the game and \u201cdont tell the rules to anyone\u201d. I was on my way to catch a flight from Munich to my home (Madrid). I didn\u2019t knew that apparently at one point the train splits into two parts and the front part goes to the airport and the other part just goes to the nearby cattle farms and comes back in 3 hours.Google Maps - No idea\nCitymapper - what?\nEnglish announcement - nien.Thanks to an old lady, who told me that i needed to switch coaches to go the airport. Madre mia!!reply",
      "We took that train, realised when we got to the other end of the line that we hadn't gotten where we expected, then turned back to the place where it separates. Waited for the next advertised train to airport (it's signalled on the electronic board as two separate entries; yes, it says \"board whatever carriages for airport, and the rest for ...\", or at least I assume it did, as it was in German of course; but again, it literally shows up as two different trains). Train arrives, stays there for a while (it's a big train, so the part in front of us didn't move so we didn't realise it had already separated), then after like 5-6 minutes it leaves. Only as it starts moving I notice that a small electronic board on the side of the carriage said \"airport\". The notice board then changes and obviously \"both\" trains disappear.We were so lucky that we'd decided to go to the airport much earlier than we needed.And don't get me started on the ticketing machines not accepting Visa, Mastercard, or Amex at the central station in Munchen. Or the web ticketing interface which was at least as annoying as the train to use.reply",
      "I've never had trouble buying train tickets with a credit card in Germany. If I had to guess, your issue was that you were trying to use a card that didn't support chip-and-PIN or contactless payments.reply",
      "Two years back the S-bahn ticket machines at the aiport only supported chip+pin, not contactless. Had to open my banking app to figure out my pin code, as I wanted to use my corporate Amexreply",
      "> didn't support chip-and-PIN or contactless payments.As opposed to... swiping the card?Are there really cards out there that exclusively support that?reply",
      "Chip and signature, which often means just the chip without further authentication.EMV has multiple options. Many countries (including the US) chose the signature option for credit cards for convenience and use PINs only with debit cards. Before contactless payment apps became common, that was a major source of friction when using American credit cards in Europe.reply",
      "I'd argue we picked it for legacy reasons - Americans are not used to the chip/pin concept, and adopted EMV very late because of a variety of legacy reasons (massive installed base of mag stripe equipment, and systems to deal with the inherent slightly higher fraud).reply",
      "Very few Norwegian issued cards, if any, have a magnetic strip.  It's too easily cloned.reply",
      "Both my DNB and Nordea cards, as well as my personal and corporate Norwegian AMEX cards all have magnetic strip, and they\u2019ve all been issued somewhat recently.reply",
      "If this story was more than a few years ago it's plausible that the card didn't have a chip. I still have a VISA debit card without a chip, and it was issued only two years ago.Also chip-and-pin is mostly not enabled with American credit cards or card payment terminalsreply"
    ],
    "link": "https://www.theocharis.dev/blog/kidnapped-by-deutsche-bahn/",
    "first_paragraph": "Boring is Awesome | Co-Founder & CTO at UMHIf you live in Germany, you have been treated like livestock by Deutsche Bahn (DB). Almost all of my friends have a story: they traveled with DB, got thrown out in the middle of the night in some cow village, and had to wait hours for the next train.I have something better. I was kidnapped.December 24th, 2025. 15:30. Cologne Main Station, Platform 9 D-G.I am taking the RE5 (ID 28521) to my grandmother\u2019s house in Meckenheim. Scheduled departure: 15:32. Scheduled arrival in Bonn: 15:54. From there, the S23 to Meckenheim. A journey of 35 kilometers, or, in DB units, somewhere between forty-five minutes and the heat death of the universe.I wanted to arrive early to spend more time with her. My father, who lives near Troisdorf, was supposed to join us later.I board the train. It is twenty minutes late. I consider this early. At least the train showed up. In DB\u2019s official statistics, a train counts as \u201con time\u201d if it\u2019s less than six minutes late.1 C"
  },
  {
    "title": "A production bug that made me care about undefined behavior (gaultier.github.io)",
    "points": 102,
    "submitter": "birdculture",
    "submit_time": "2025-12-29T18:17:29 1767032249",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=46423521",
    "comments": [
      "Even calling uninitialized data \u201cgarbage\u201d is misleading. You might expect that the compiler would just leave out some initialization code and compile the remaining code in the expected way, causing the values to be \u201cwhatever was in memory previously\u201d.  But no - the compiler can (and absolutely will) optimize by assuming the values are whatever would be most convenient for optimization reasons, even if it would be vanishingly unlikely or  even impossible.As an example, consider this code (godbolt: https://godbolt.org/z/TrMrYTKG9):    struct foo {\n        unsigned char a, b;\n    };\n\n    foo make(int x) {\n        foo result;\n        if (x) {\n            result.a = 13;\n        } else {\n            result.b = 37;\n        }\n        return result;\n    }\n\nAt high enough optimization levels, the function compiles to \u201cmov eax, 9485; ret\u201d, which sets both a=13 and b=37 without testing the condition at all - as if both branches of the test were executed. This is perfectly reasonable because the lack of initialization means the values could already have been set that way (even if unlikely), so the compiler just goes ahead and sets them that way. It\u2019s faster!reply",
      "If you don't initialise a variable, you're implicitly saying any value is fine, so this actually makes sense.reply",
      "The difference is that it can behave as if it had multiple different values at the same time. You don't just get any value, you can get completely absurd paradoxical Schr\u00f6dinger values where `x > 5 && x < 5` may be true, and on the next line `x > 5` may be false, and it may flip on Wednesdays.This is because the code is executed symbolically during optimization. It's not running on your real CPU. It's first \"run\" on a simulation of an abstract machine from the C spec, which doesn't have registers or even real stack to hold an actual garbage value, but it does have magic memory where bits can be set to 0, 1, or this-can-never-ever-happen.Optimization passes ask questions like  \"is x unused? (so I can skip saving its register)\" or \"is x always equal to y? (so I can stop storing it separately)\" or \"is this condition using x always true? (so that I can remove the else branch)\". When using the value is an undefined behavior, there's no requirement for these answers to be consistent or even correct, so the optimizer rolls with whatever seems cheapest/easiest.reply",
      "Indeed, UB is literally whatever the compiler feels like. A famous one [1] has the compiler deleting code that contains UB and falling through to the next function.\"But it's right there in the name!\" Undefined behavior literally places no restrictions on the code generated or the behavior of the program. And the compiler is under no obligation to help you debug your (admittedly buggy) program. It can literally delete your program and replace it with something else that it likes.[1] https://kristerw.blogspot.com/2017/09/why-undefined-behavior...reply",
      "There are some even funnier cases like this one: https://gcc.godbolt.org/z/cbscGf8ssThe compiler sees that foo can only be assigned in one place (that isn't called locally, but could called from other object files linked into the program) and its address never escapes. Since dereferencing a null pointer is UB, it can legally assume that `*foo` is always 42 and optimizes out the variable entirely.reply",
      "To those who are just as confused as me:Compilers can do whatever they want when they see UB, and accessing an unassigned and unassiganble (file-local) variable is UB, therefore the compiler can just decide that *foo is in fact always 42, or never 42, or sometimes 42, and all would be just as valid options for the compiler.(I know I'm just restating the parent comment, but I had to think it through several times before understanding it myself, even after reading that.)reply",
      "> Compilers can do whatever they want when they see UB, and accessing an unassigned and unassiganble (file-local) variable is UB, therefore the compiler can just decide that *foo is in fact always 42, or never 42, or sometimes 42, and all would be just as valid options for the compiler.That's not exactly correct. It's not that the compiler sees that there's UB and decides to do something arbitrary: it's that it sees that there's exactly one way for UB to not be triggered and so it's assuming that that's happening.reply",
      "Although it should be noted that that\u2019s not how compilers \u201creason\u201d.The way they work things out is to assume no UB happens (because otherwise your program is invalid and you would not request compiling an invalid program would you) then work from there.reply",
      "Even the notion that uninitialized memory contain values is kind of dangerous. Once you access them you can't reason about what's going to happen at all. Behaviour can happen that's not self-consistent with any value at all: https://godbolt.org/z/adsP4sxMTreply",
      "Is that an old 'bot? because I noticed it was an old version of Clang, and I tried switching to the latest Clang which is hilarious: https://godbolt.org/z/fra6fWexMreply"
    ],
    "link": "https://gaultier.github.io/blog/the_production_bug_that_made_me_care_about_undefined_behavior.html",
    "first_paragraph": " \u23f4 Back to all articlesPublished on 2025-12-27Discussions: /r/programming, lobsters.Years ago, I maintained a big C++ codebase at my day job. This product was the bread winner for the company and offered a public HTTP API for online payments. We are talking billions of euros of processed payments a year.I was not a seasoned C++ developer yet. I knew about undefined behavior of course, but it was an abstract concept, something only beginners fall into. Oh boy was I wrong.Please note that I am not and never was a C++ expert, and it's been a few years since I have been writing C++ for a living, so hopefully I got the wording and details right, but please tell me if I did not.In this article I always say 'struct' when I mean 'struct or class'.So, one day I receive a bug report. There is this HTTP endpoint that returns a simple response to  inform the client that the operation either succeeded or had an error:orThe actual format was probably not JSON, it was probably form encoded, I cannot "
  },
  {
    "title": "Outside, Dungeon, Town: Integrating the Three Places in Videogames (2024) (keithburgun.net)",
    "points": 4,
    "submitter": "vector_spaces",
    "submit_time": "2025-12-30T00:54:34 1767056074",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://keithburgun.net/outside-dungeon-town-integrating-the-three-places-in-videogames/",
    "first_paragraph": "Videogames, at least the kind I\u2019m talking about (RPGs, adventure kinds of somewhat narrative videogames, Zelda games, Elden Ring, etc), have essentially three \u201cplaces\u201d:Of course, any time you try to boil down reality into a nice neat little categorization system like this, you\u2019re going to be missing a lot of details, but broadly speaking, I think this holds up pretty well. I\u2019m playing through Final Fantasy VII Rebirth now (which I am loving) and it\u2019s very clear in that game, whether you are in Outside, Dungeon or Town, pretty much at all times.Videogames are a language, and this pattern is an important building block in that language. It is kind of good that you know you\u2019re always safe in town. It is kind of good that you know what you\u2019re in for when entering a big scary difficult dungeon, and so on. So, I am not saying that we get rid of these designations, at all.What I would love, though, is some more messiness in how they are implemented. Kakariko Village from Ocarina of Time is on"
  },
  {
    "title": "All Delisted Steam Games (delistedgames.com)",
    "points": 184,
    "submitter": "Bondi_Blue",
    "submit_time": "2025-12-29T19:16:32 1767035792",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=46424262",
    "comments": [
      "About one of my favorite racing games of all time: \"The game could have been removed for a number of reasons, including the closure of developer Bizarre Creations in early 2011, but the most likely cause was expired licensing of the real-world cars featured in the game.\"[1]To me this is one of the most egregious examples of how licensing massively hurts consumers. The game is fully playable offline (and online with a patch) but cannot legally be sold because of an arbitrary restriction limiting the use of likeness of virtual cars in the game.[1] https://delistedgames.com/blur/reply",
      "This is the double edged sword of copyright, sometimes you want the artist to have control, sometimes you don't.reply",
      "+1 for Blur, great game, it's like Super Mario Kart for grown-ups.Too bad the only way to get it is by pirating it. But in these situations, doesn't piracy become morally acceptable?reply",
      "Wow this looks pretty rad, I wish I knew about it before! Having real cars in the game really makes it more fun to me. I dunno why, but playing racing games with a bunch of fake cars isn't as exciting (Super Mario Kart being an exception). It's especially fun when you see one of your cars, or a friend's car in the game.reply",
      "It becomes a moral imperative to pirate it and continue seeding it for others to also acquire, as a mean to help preserving something you cared about, apparently more than the owners of the IP/rights themselves care.reply",
      "The title track of the game, Smile by Crystal Method [0] is one of my all time favorites as a result of playing Blur.[0]: https://www.youtube.com/watch?v=_EbkSMPbj_Ireply",
      "oh yeah, I'm a fan of this game too. To my surprise, even though it's delisted I can still install it. That's certainly better than the alternative.reply",
      "I think you can install games that you bought (when they were available), even if they're delisted.reply",
      "yeah, that's the whole point, thye still let you install the games you bought because not doing so would open a huge can of worms and re-start the whole \"are you really buying games on steam or just renting them?\" discussion, which they are very keen on avoidingreply",
      "It's funny that 3 different Space Hulk games are here.I actually thought Space Hulk (2013) was amazing but it's hard for a developer to keep up the yearly license payments on any Warhammer franchise. So it's not available for purchase anymore. It got ~75% on reviews on release but i like the board game and it was true to the board game so i personally loved it. Link on the steam store (the site should have these) https://store.steampowered.com/app/242570/Space_Hulk/Fwiw if you have one of these games they are still in your Steam library. I still get to play the above game. I just can't easily play with others anymore nor can i suggest they purchase that game. I'm a little surprised it still runs fine given no updates but yay for backwards compatibility.In general a theme for lists like these are licensing. If a developer has to pay a franchise licensing fee it's going to stop being worthwhile at some point. Take note if you're a developer. It's hard to get visibility without being tied to a franchise (Eg. Larian had to do it with Baldurs Gate 3) but it'll cut into profits massively. Even Larian are never doing it again.reply"
    ],
    "link": "https://delistedgames.com/all-delisted-steam-games/",
    "first_paragraph": "Delisted GamesEven in the age of digital, nothing lasts foreverThis page gives you direct access to all 1,038 delisted Steam titles on the site. Below each title are the companies it relates to. An * in the title denotes a placeholder page that contains basic details.ChronoForge\nDecember 30, 2025\nREAD MORE\nREAD MORENBA 2K24 (online services)\nDecember 31, 2025\nREAD MORE\nREAD MOREChiyo\nDecember 31, 2025\nREAD MORE\nREAD MOREMing Imperial Guards\nDecember 31, 2025\nREAD MORE\nREAD MOREGravity Oddity, Guilt Battle Arena\nDecember 31, 2025\nREAD MORE\nREAD MOREApex Point (placeholder)\nDecember 31, 2025\nREAD MORE\nREAD MOREPandum Online shutdown\nDecember 31, 2025\nREAD MORE\nREAD MOREByte Cats\nDecember 31, 2025\nREAD MORE\nREAD MORE"
  },
  {
    "title": "Intelligence \u2013 A Mystery Investigation Game (intelligencegame.tech)",
    "points": 17,
    "submitter": "throw_a_grenade",
    "submit_time": "2025-12-25T21:03:28 1766696608",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://intelligencegame.tech/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Superset \u2013 Terminal to run 10 parallel coding agents (superset.sh)",
    "points": 64,
    "submitter": "avipeltz",
    "submit_time": "2025-12-23T19:52:30 1766519550",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=46368739",
    "comments": [
      "The real bottleneck isn\u2019t human review per se, it\u2019s unstructured review. Parallel agents only make sense if each worktree has a tight contract: scoped task, invariant tests, and a diff small enough to audit quickly. Without that, you\u2019re just converting \u201ctyping time\u201d into \u201creading time,\u201d which is usually worse. Tools like this shine when paired with discipline: one hypothesis per agent, automated checks gate merges, and humans arbitrate intent\u2014not correctness.reply",
      "Agreed. I generally see much better results for smaller, well-scoped tasks. Since there's very little friction to spinning up a worktree (~2s), I open one for any small tasks, something I couldn't do while working on a single branch.reply",
      "There is something you are not explaining (at least I couldn't find it, sorry if you do), but how do you manage apps states? Basically databases?Most of these agents solutions are focusing on git branches and worktrees, but at least none of them mention databases. How do you handle them? For example, in my projects, this means I would need ten different copies of my database. What about other microservices that are used, like redis, celery, etc? Are you duplicating (10-plicating) all of them?If this works flawlessly it would be very powerful, but I think it still needs to solve more issues whan just filesystem conflicts.reply",
      "Why aren\u2019t you mocking your dependencies? I should be able to run a microservice without 3rd party and it still work. If it doesn\u2019t, it\u2019s a distributed monolith.For databases, if you can\u2019t see a connection string in env vars, use sqlite://:memory and make a test db like you do for unit testing.For redis, provide a mock impl that gets/sets keys in a hash table or dictionary.Stop bringing your whole house to the camp site.reply",
      "Because the real thing is higher fidelity, but it can expensive to boot up many times.reply",
      "Higher fidelity?What does that mean in this context?What higher fidelity do you get with a real postgres over a SQLite in memory or even pglite or whatever.The point isn\u2019t you shouldn\u2019t have a database, the point is what are your concerns? For me and my teams, we care about our code, the performance of that code, the correctness of that code, and don\u2019t test against a live database so that we understand the separation of concerns between our app and its storage. We expect a database to be there. We expect it to have such and such schema. We don\u2019t expect it to live at a certain address or a certain configuration as that is the databases concern.We tell our app at startup where that address is or we don\u2019t. The app should only care whether we did or not, if not, it will need to make one to work.This is the same logic with unit testing. If you\u2019re unit testing against a real database, that isn\u2019t unit testing, that\u2019s an integration test.If you do care about the speed of your database and how your app scales, you aren\u2019t going to be doing that on your local machine.reply",
      "There is your idealization, and there is reality. Mocks are to be avoided. I reserve them for external dependencies.> What higher fidelity do you get with a real postgres over a SQLite in memory or even pglite or whateverYou want them to have the same syntax and features, to the extent that you use them, or you'll have one code path for testing and another for production. For example, sqlite does not support ARRAYs or UUIDs natively, so you'll have to write a separate implementation. This is a vector for bugs.reply",
      "You're right that sqlite doesn't support array's or uuid's natively. SQLite was only a suggestion on how one might go about separating your database engine concerns with your data layer concerns.If you fail to understand why this separation is important, you'll fail to reason with why you'd do it in the first place so continue building apps like it's 1999, tightly coupled and you need the whole stack to run your thing. God forbid you expand beyond just 1 team.reply",
      "pglite might be an option.reply",
      "Great question currently superset manages worktrees + runs setup/teardown scripts you define on project setup. Those scripts can install dependencies, transfer env variables, and spin up branching services.For example:\n\u2022 if you\u2019re using Neon/Supabase, your setup script can create a DB branch per workspace\n\u2022 if you\u2019re using Docker, the script can launch isolated containers for Redis/Postgres/Celery/etcCurrently we only orchestrate when they run, and have the user define what they do for each project, because every stack is different. This is a point of friction we are also solving by adding some features to help users automatically generate setup/teardown scripts that work for their projects.We are also building cloud workspaces that will hopefully solve this issue for you and not limit users by their local hardware.reply"
    ],
    "link": "https://superset.sh/",
    "first_paragraph": "Run dozens of Claude Code, Codex, or any other in parallel.Superset works with your existing tools. We provides parallelization and better UX to enhance your Claude Code, OpenCode, Cursor, etc.Launch multiple AI coding agents across different tasks. Work on features, fix bugs, and refactor code \u2014 all in parallel.Superset is agent-agnostic. Use Claude Code, OpenCode, Cursor, or any CLI-based coding tool. Switch between agents seamlessly.Each agent runs in its own isolated Git worktree. No merge conflicts, no stepping on each other's changes. Review and merge work when you're ready.Jump into your favorite editor with one click. VS Code, Cursor, Xcode, JetBrains IDEs, or any terminal \u2014 open worktrees exactly where you need them.\u00a9 2025 Superset. All rights reserved."
  },
  {
    "title": "Show HN: Aroma: Every TCP Proxy Is Detectable with RTT Fingerprinting (github.com/sakura-sx)",
    "points": 61,
    "submitter": "Sakura-sx",
    "submit_time": "2025-12-25T20:34:59 1766694899",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=46386878",
    "comments": [
      "This feels like something that\u2019s a neat claim and will work against simple setups, but less accurate for more complicated scenarios (eg Tor). Then you\u2019re really just relying on how accurate your knowledge of the proxies are.Also, the readme has slightly incorrect logic I think:> According to Special Relativity, information cannot travel faster than the speed of light. Therefore, if the round trip time (RTT) is 4ms, it's physically impossible for them to be farther than 2 light milliseconds away, which is approximately 600 kilometers.It calls out the 33% for fiber but ignores that there\u2019s not a straightline path between two points on the network and there could be wireless, cable, and DSL links somewhere on that hop.Also, the controlled variable here is latency, not distance. Thus you can always increase latency through buffering and therefor you could be made to appear further than you are. And that buffering need not even be intentional - your perceived distance estimate will vary based upon queuing delays in intermediary depending on time of day (itself a fingerprint if you incorporate time-aware measurements, but a source of error if you don\u2019t).Fingerprinting is hard and I dislike the framing that it\u2019s absolutely impossible to mask or that there\u2019s not false positive and false negative error rates with the fingerprint.reply",
      "About the straightline path I did think of that but apparently I forgot to address it when writing the README :pThe point I was trying to make is that if the RTT is low enough you can know the connection is being made from close, it's an upper bound, and making some assumptions you can get it lower, so it's not a way of knowing the exact distance but rather the max distance the connection can be made from. If someone is in Spain but they can't be more than 400km from Australia, something went terribly wrong somewhere heheIn hindsight I think the issue with my explanation is that I was trying to explain the differences when fingerprinting two different protocols, but ended up going for a TCP-only approach since Fastly wouldn't expose to me the data I needed for the TLS and HTTP RTT. But in theory fingerprinting with protocol RTT difference where one protocol is proxied and the other is impossible to bypass, but this is only the theory.I think I will edit the README in the future since I don't like how it turned out too much. Thanks for the feedback!By the way, it detects Tor, I tested it ;Dreply",
      "Do raw TCP proxies still get used often? I'd imagine most proxies you'd want to detect are full HTTP proxies and this formula won't detect those.I suppose it's possible botnets (\"residential proxies\") may get detected this way if they're using SOCKS to forward requests?Still, this looks like an interesting signal to add to a system like Anubis to increase the difficulty for suspicious traffic sources.This does very reliably detect TOR traffic, though you can just download a list of exit nodes if that's what you want.reply",
      "I think for stealth TCP proxies are more common since you can use your own TLS fingerprints and all of that, with something like an HTTP proxy you'd need to set up your requests to match with the TLS fingerprint that the proxy is using, although I guess the proxy could make the TLS look the same? There are other ways of detecting HTTP proxies like for example comparing with the RTT of websockets or something like that, the idea is that there will always be at least one thing with RTT from the proxy and at least the RTT for one thing from the client that must go trough the proxy, you measure the difference between the two and there you have it.reply",
      "The most common method of proxying with residential proxies is still CONNECT tunnels and from my tests it catches a resi-proxy about 50% of the time. More with tuning of the score thresholds.reply",
      "Every TCP proxy (that doesn't thwart this) is detectable :)Countermeasure: pick some min-RTT >= the actual client RTT (you can do this as a TCP proxy by measuring client ping). Measure server RTT and artificially delay responses to be >= min-RTT. This will require an added delay during the handshake and ACKs, but no added delay for the response payloads.Counter-countermeasure: the above may lead to TCP message types that don't make sense given a traditional TCP client state machine (e.g., delayed ACK would bundle ACK and PUSH but the system shows separate/simultaneous ACK and PUSH packets. Counter-counter-countermeasure is left to the reader.reply",
      "I think you could also compare with TLS handshake timings, delay for client hello among other things. And you could also compare it with HTTP RTT, not to mention that you can do TCP fingerprinting and compare it with the TLS and HTTP fingerprint of the browser, you can also measure the IP TTL and ping, among many other things... What I mean is that there are a ton of things that can be done on both sides, but any company with enough people working at this and enough servers will surely make something miles away from my proof of concept, and they also have a lot of traffic to know what's baseline data and what isn't.It's a complex but fun world we live in hehereply",
      "Neat demo. The unsettling part is how little signal you actually need: big CDNs and fraud teams already run much richer timing models than a simple min_rtt / rtt ratio. You can\u2019t spoof away the speed of light, only add latency or jitter, and that itself becomes a fingerprint once you have enough traffic and a few global PoPs to compare from. So this doesn\u2019t magically break L3 VPNs, but anyone relying on \u201cjust stick a TCP proxy in front and I\u2019m anonymous/in-region\u201d has been living with a pretty outdated threat model.reply",
      "Thank you! There are other ways of detecting L3 VPNs, but I wanted to start with proxies since they do most of the damage.reply",
      "The minimal explanation is that TCP is \"turned around\" at a dumb proxy, but upper-layer protocols may go further before being turned around. Which is trivially avoidable by delaying the TCP response with the same timing as the upper-layer protocol (and doing so to the protocol above that, etc.)reply"
    ],
    "link": "https://github.com/Sakura-sx/Aroma",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Every TCP Proxy Is Detectable With RTT Fingerprinting\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.ImportantA demo of Aroma detecting Cloudflare WARP (higher score is better):NoteI have to admit I was a bit surprised that Aroma was detecting WARP, since I thought it was a VPN, but apparently it acts like a UDP => TCP proxy. If Aroma doesn't detect your VPN, that's normal and means your VPN is doing Layer 3 proxying. If your VPN is detected it's doing Layer 4 proxying (some privacy VPNs do this on web ports for privacy reasons).If you want to check out Aroma for yourself, you can go to:https://aroma.global.ssl.fastly.net/.And you should see an \"allowed\" page if you are not using a TCP Proxy and a block page if you are using a proxy.If you want to get your "
  },
  {
    "title": "ManusAI Joins Meta (manus.im)",
    "points": 115,
    "submitter": "gniting",
    "submit_time": "2025-12-29T22:24:22 1767047062",
    "num_comments": 62,
    "comments_url": "https://news.ycombinator.com/item?id=46426534",
    "comments": [
      "This acquisition is a complete joke in China. From the very beginning, the company focused almost entirely on marketing. Then, after a few months, it fled China and relocated to Singapore. Now that it\u2019s been acquired by Meta, you could say it has finally fulfilled its mission.reply",
      "From their Wikipedia, because I had no idea who they were:\"Following Manus's launch in March 2025, Butterfly Effect raised $75 million in a funding round led by Benchmark at a valuation of approximately $500 million in April 2025.\"Half a billion a month after launch and acquisition before the end of the same year. Wild times.reply",
      "Yep, same. Bewildering amounts of silliness, all around.reply",
      "It's everywhere. https://www.reddit.com/r/ChatGPT/comments/1l8harj/its_not_ju...reply",
      "Kind of feels like they might have done it on purpose, just to \"trigger\" people and get more engagement. Feels like a lot of people are falling for it too, so I guess good for them.reply",
      "It\u2019s been very effective watermarking compared to some of the more complicated and seemingly unsuccessful methods that have been proposed.reply",
      "non tantum \u2026 sed etiam \u2026reply",
      "I\u2019m wondering why these companies are so hyped and valued at these astronomical levels. Honestly, nothing really impresses me enough to think, \u201cWow, this company actually deserves that kind of valuation\u201d.These valuations are to the point point that this looks too close to money laundering, just like buying art.reply",
      "I hear you, and mostly share the point of view, but that\u2019s what people were saying about the instagram valuation too.reply",
      "It's all very speculative and line keeps going up foreverreply"
    ],
    "link": "https://manus.im/blog/manus-joins-meta-for-next-era-of-innovation",
    "first_paragraph": ""
  }
]