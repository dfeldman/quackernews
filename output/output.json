[
  {
    "title": "Show HN: Strange Attractors (shashanktomar.com)",
    "points": 131,
    "submitter": "shashanktomar",
    "submit_time": "2025-10-31T23:23:59 1761953039",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=45777810",
    "comments": [
      "Visualizations like this truly highlight how much there is to be gained from viewing the 3D phase space, but also how much richness we miss in >3D!(I wonder if there are slick ways to visualise the >3D case. Like, we can view 3D cross sections surely.Or maybe could we follow a Lagrangian particle and have it change colour according to the D (or combination of D) it is traversing? And do this for lots of particles? And plot their distributions to get a feeling for how much of phase space is being traversed?)This visualization also reminds me of the early debates in the history of statistical mechanics: How Boltzmann, Gibbs, Ehrenfest, Loschmidt and that entire conference of Geniuses must have all grappled with phase space and how macroscopic systems reach equilibrium.Great work Shashank!reply",
      "Lorenz Equations and Chua Circuits probed with an analog oscilloscope is mesmerizing! Great videos of a Chua Circuit being probed with an analog scope\u2026\nAlso, plugging the circuit to a speaker via AUX port gives white noise ;)reply",
      "This is so cool. Back in highschool during the Jurassic age I used ti play with attractors a lot. Unfortunately on a 486 it took 20-30 minutes to draw one even at low resolution. This renders in realtime and in 3D. Great work!Still they've had a strong impact in how I see systems - orbits, instability, etc.reply",
      "This is absolutely stunning. Wonderful some function of the state of a point can give it colour.reply",
      "Author here, there is a setting to pick colour mode. I implemented it after similar suggestion by someone on twitter. Give it a try.reply",
      "I got really into fractals and attractors when I was also really into mushrooms, lsd, and dmt during my graduate studies.It actually shaped my post doc work quite a bit and shifted my focus from individual classroom education to strategic systems analysis of entire university and k-12 institutions. Somewhere along the way, a switch flipped and allowed me to view complicated hierarchies like college systems as 2-d fractal geometry in my mind. I can't really explain it, but now that I consult, I can feel when a department is broken before I can prove it with data. It's like they don't fit or reflect the main structure of the institution.I would not suggest taking this route though. Maybe just take some graduate courses or something.Fun fact, though, defending your dissertation to a room of around 200 people while still feeling the effects of dmt is a really good way to induce a panic attack. Source: it's me. I'm source material.reply",
      "\"IMSAI guy\" created a Lorenz attractor circuit [1]. He talks more about it later [2]. I remember seeing the Lorenz attractor on some TV show about chaos.[1] https://youtu.be/0wD2WbG7loU[2] https://youtu.be/c14aXxlSxZkreply",
      "Hobbyists hacking around and sharing their art, best part of the Internet!reply",
      "Super cool visulitations.Side note: Did anyone else know it was AI before reading the post? Mathematicians would be argent enough to assume the name was enough, displaying the algo when clicking the name was the give away.reply",
      "Author here, I have tried labeling the \"More Information\" sections as \"AI Generated\" where it was directly summarized from the wikipedia article, otherwise most of the post is written by me. I have taken help from AI to fact check and refine few things here and there, but boundaries are so blur now that am not sure if i should label the full post as AI Assisted.reply"
    ],
    "link": "https://blog.shashanktomar.com/posts/strange-attractors",
    "first_paragraph": "A few months back, while playing around with Three.js, I came across something that completely derailed my plans. Strange attractors - fancy math that creates beautiful patterns. At first I thought I'd just render one and move on, but then soon I realized that this is too much fun. When complexity emerges from three simple equations, when you see something chaotic emerge into beautiful, it's hard not to waste some time. I've spent countless hours, maybe more than I'd care to admit, watching these patterns form. I realized there's something deeply satisfying about seeing order emerge from randomness. Let me show you what kept me hooked.Most of what I've learned about strange attractors comes from working on this visualization. If you're seeking\nadvanced mathematical explanations, this might not be for you. My intention here is to share my learnings in an\nengaging and accessible manner.Dynamical Systems are a mathematical way to understand how things change over time. Imagine you have a "
  },
  {
    "title": "S.a.r.c.a.s.m: Slightly Annoying Rubik's Cube Automatic Solving Machine (github.com/vindar)",
    "points": 31,
    "submitter": "chris_overseas",
    "submit_time": "2025-10-31T23:03:18 1761951798",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=45777682",
    "comments": [
      "There's a lot more detail describing the project in a couple of forum posts here: https://forum.pjrc.com/index.php?threads/sarcasm-an-over-eng...reply",
      "The aesthetics of this are great. Nice job.Demo:\nhttps://youtube.com/shorts/Xer4mPZZH8Ereply",
      "It's a cool project, but also they're really underselling the amount of work put in to make it annoying.reply"
    ],
    "link": "https://github.com/vindar/SARCASM",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        S.A.R.C.A.S.M : Slightly Annoying Automatic Rubik's Cube Solving Machine\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Slightly Annoying Rubik's Cube Automatic Solving MachineS.A.R.C.A.S.M is a 3D-printed, Teensy-powered robot that scans, solves, and sassily comments on a Rubik\u2019s Cube.This repository contains the code and schematics of the build.A slight modification of Teensy's core is required in order for the whole code to fit in RAM.Edit cores/teensy4/usb_serial.c and cores/teensy4/usb_serial2.c and, in each file, remove the DMAMEM attribute in front of the definition of the txbuffer[] and rx_buffer[] arrays.This is a work in progress. The repo is currently in a very messy and incomplete state (and will most likely stay that way until I find some time "
  },
  {
    "title": "Futurelock: A subtle risk in async Rust (oxide.computer)",
    "points": 248,
    "submitter": "bcantrill",
    "submit_time": "2025-10-31T16:49:26 1761929366",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=45774086",
    "comments": [
      "Skimming through, this document feels thorough and transparent. Clearly, a hard lesson learned. The footnotes, in particular, caught my eye https://rfd.shared.oxide.computer/rfd/397#_external_referenc...> Why does this situation suck? It\u2019s clear that many of us haven\u2019t been aware of cancellation safety and it seems likely there are many cancellation issues all over Omicron. It\u2019s awfully stressful to find out while we\u2019re working so hard to ship a product ASAP that we have some unknown number of arbitrarily bad bugs that we cannot easily even find. It\u2019s also frustrating that this feels just like the memory safety issues in C that we adopted Rust to get away from: there\u2019s some dynamic property that the programmer is responsible for guaranteeing, the compiler is unable to provide any help with it, the failure mode for getting it wrong is often undebuggable (by construction, the program has not done something it should have, so it\u2019s not like there\u2019s a log message or residual state you could see in a debugger or console), and the failure mode for getting it wrong can be arbitrarily damaging (crashes, hangs, data corruption, you name it). Add on that this behavior is apparently mostly undocumented outside of one macro in one (popular) crate in the async/await ecosystem and yeah, this is frustrating. This feels antithetical to what many of us understood to be a core principle of Rust, that we avoid such insidious runtime behavior by forcing the programmer to demonstrate at compile-time that the code is well-formedreply",
      "I guess one big question here is whether there's a higher layer abstraction that is available to wrap around patterns to avoid this.It does feel like there's still generally possibilities of deadlocks in Rust concurrency right? I understand the feeling here that it feels like ... uhh... RAII-style _something_ should be preventing this, because it feels like statically we should be able to identify this issue in this simple case.I still have a hard time understanding how much of this is incidental and how much of this is just downstream of the Rust/Tokio model not having enough to work on here.reply",
      "That's a really subtle version of the deadlock described in withoutboats FuturesUnordered post [0]When using \u201cintra-task\u201d concurrency, you really have to ensure that none of the futures are starving.Spawning task should probably be the default. For timeouts use tokio::select! but make sure all pending futures are owned by it. I would never recommend FuturesUnordered unless you really test all edge-cases.[0] https://without.boats/blog/futures-unordered/reply",
      "This sounds very similar to priority inversion. E.g. if you have Thread T_high running at high priority and thread T_low running at low priority, and T_low holds a lock that T_high wants to acquire, T_high won't get to run until T_low gets scheduled.The OS can detect this and make T_low \"inherit\" the priority of T_high. I wonder if there is a similar idea possible with tokio? E.g. if you are awaiting a Mutex held by a future that \"can't run\", then poll that future instead. I would guess detecting the \"can't run\" case would require quite a bit of overhead, but maybe it can be done.I think an especially difficult factor is that you don't even need to use a direct await.    let future1 = do_async_thing(\"op1\", lock.clone()).boxed();\n    tokio::select! {\n      _ = &mut future1 => {\n        println!(\"do_stuff: arm1 future finished\");\n      }\n      _ = sleep(Duration::from_millis(500)) => {\n        // No .await, but both will futurelock on future1.\n        tokio::select! {\n          _ = do_async_thing(\"op2\", lock.clone()) => {},\n          _ = do_async_thing(\"op3\", lock.clone()) => {},\n        };\n      }\n    };\n\nI.e. so \"can't run\" detector needs to determine that no other task will run the future, and the future isn't in the current set of things being polled by this task.reply",
      "> I wonder if there is a similar idea possible with tokio? E.g. if you are awaiting a Mutex held by a future that \"can't run\", then poll that future instead.Something like this could make sense for Tokio tasks. (I don't know how complicated their task scheduler is; maybe it already does stuff like this?) But it's not possible for futures within a task, as in this post. This goes all the way back to the \"futures are inert\" design of async Rust: You don't necessarily need to communicate with the runtime at all to create a future or to poll it or to stop polling it. You only need to talk to the runtime at the task level, either to spawn new tasks, or to wake up your own task. Futures are pretty much just plain old structs, and Tokio doesn't know how many futures my async function creates internally, any more than it knows about my integers or strings or hash maps.reply",
      "Yeah, a coworker coming from Go asked a similar question about why Rust doesn't have something like the Go runtime's deadlock detector. Your comment is quite similar to the explanation I gave him.Go, unlike Rust, does not really have a notion of intra-task concurrency; goroutines are the fundamental unit of concurrency and parallelism. So, the Go runtime can reason about dependencies between goroutines quite easily, since goroutines are the things which it is responsible for scheduling. The fact that channels are a language construct, rather than a library construct implemented in the language, is necessary for this too. In (async) Rust, on the other hand, tasks are the fundamental unit of parallelism, but not of concurrency; concurrency emerges from the composition of `Future`s, and a single task is a state machine which may execute any number of futures concurrently (but not in parallel), by polling them until they cannot proceed without waiting and then moving on to poll another future until it cannot proceed without waiting. But critically, this is not what the task scheduler sees; it interacts with these tasks as a single top-level `Future`, and is not able to look inside at the nested futures they are composed of.This specific failure mode can actually only happen when multiple futures are polled concurrently but not in parallel within a single Tokio task. So, there is actually no way for the Tokio scheduler to have insight into this problem. You could imagine a deadlock detector in the Tokio runtime that operates on the task level, but it actually could never detect this problem, because when these operations execute in parallel, it actually cannot occur. In fact, one of the suggestions for how to avoid this issue is to select over spawned tasks rather than futures within the same task.reply",
      ">This goes all the way back to the \"futures are inert\" design of async RustYeap. And this footgun is yet another addition to the long list of reasons why I consider the Rust async model with its \"inert\" futures managed in user space a fundamentally flawed un-Rusty design.reply",
      "I feel there's a difference between a preference and a flaw. Rust has targets that make anything except inert futures simply unworkable, and in my opinion it's entirely valid for a programming language to prioritise those targets.reply",
      "The requirement is that the futures are not separate heap allocations, not that they are inert.It's not at all obvious that Rust's is the only possible design that would work here. I strongly suspect it is not.In fact, early Rust did some experimentation with exactly the sort of stack layout tricks you would need to approach this differently. For example, see Graydon's post here about the original implementation of iterators, as lightweight coroutines: https://old.reddit.com/r/ProgrammingLanguages/comments/141qm...reply",
      "On the other hand, early Rust also for instance had a tracing garbage collector; it's far from obvious to me how relevant its discarded design decisions are supposed to be to the language it is today.reply"
    ],
    "link": "https://rfd.shared.oxide.computer/rfd/0609",
    "first_paragraph": "This RFD describes futurelock: a type of deadlock where a resource owned by Future A is required for another Future B to proceed, while the Task responsible for both Futures is no longer polling A.  Futurelock is a particularly subtle risk in writing asynchronous Rust.Oxide initially saw this problem in oxidecomputer/omicron#9259.Consider the following program (in the playground):This program reliably deadlocks.  This surprises a lot of people!  A background Task takes a lock, waits 5s, drops the lock and exits. In the meantime, we do_stuff.  That stuff consists of waiting for two Futures concurrently via select!. One future waits for the lock while the other sleeps for 0.5s and waits for the lock. So there\u2019s just one lock and all logical streams of execution seem to execute concurrently.  How could this possibly hang?The interesting bits are all in do_stuff():It\u2019s really important to understand what\u2019s happening here so let\u2019s be clear about the sequence.First:background task takes lock"
  },
  {
    "title": "Introducing architecture variants (ubuntu.com)",
    "points": 165,
    "submitter": "jnsgruk",
    "submit_time": "2025-10-30T10:35:00 1761820500",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=45758392",
    "comments": [
      "Over the past year, Intel has pulled back from Linux development.Intel has reduced its number of employees, and has lost lots of software developers.So we lost Clear Linux, their Linux distribution that often showcased performance improvements due to careful optimization and utilization of microarchitectural enhancements.I believe you can still use the Intel compiler, icc, and maybe see some improvements in performance-sensitive code.https://clearlinux.org/\"It was actively developed from 2/6/2015-7/18/2025.\"reply",
      "icc was discontinued FWIW. The replacement, icx, is AIUI just clang plus some proprietary pluginsreply",
      "Announce was here:\nhttps://discourse.ubuntu.com/t/introducing-architecture-vari...and key point:\n\"Previous benchmarks we have run (where we rebuilt the entire archive for x86-64-v3 57) show that most packages show a slight (around 1%) performance improvement and some packages, mostly those that are somewhat numerical in nature, improve more than that.\"reply",
      "> show that most packages show a slight (around 1%) performance improvementThis takes me back to arguing with Gentoo users 20 years ago who insisted that compiling everything from source for their machine made everything faster.The consensus at the time was basically \"theoretically, it's possible, but in practice, gcc isn't really doing much with the extra instructions anyway\".Then there's stuff like glibc which has custom assembly versions of things like memcpy/etc, and selects from them at startup. I'm not really sure if that was common 20 years ago but it is now.It's cool that after 20 years we can finally start using the newer instructions in binary packages, but it definitely seems to not matter all that much, still.reply",
      "It's also because around 20 years ago there was a \"reset\" when we switched from x86 to x86_64. When AMD introduced x86_64, it made a bunch of the previously optional extension (SSE up to a certain version etc) a mandatory part of x86_64. Gentoo systems could already be optimized before on x86 using those instructions, but now (2004ish) every system using x86_64 was automatically always taking full advantage of all of these instructions*.Since then we've slowly started accumulating optional extensions again; newer SSE versions, AVX, encryption and virtualization extensions, probably some more newfangled AI stuff I'm not on top of. So very slowly it might have started again to make sense for an approach like Gentoo to exist**.* usual caveats apply; if the compiler can figure out that using the instruction is useful etc.** but the same caveats as back then apply. A lot of software can't really take advantage of these new instructions, because newer instructions have been getting increasingly more use-case-specific; and applications that can greatly benefit from them will already have alternative code-pathes to take advantage of them anyway. Also a lot of the stuff happening in hardware acceleration has moved to GPUs, which have a feature discovery process independent of CPU instruction set anyway.reply",
      "The llama.cpp package on Debian and Ubuntu is also rather clever in that it's built for x86-64-v1, x86-64-v2, x86-64-v3, and x86-64-v4. It benefits quite dramatically from using the newest instructions, but the library doesn't have dynamic instruction selection itself. Instead, ld.so decides which version of libggml.so to load depending on your hardware capabilities.reply",
      "> AVX, encryption and virtualizationI would guess that these are domain-specific enough that they can also mostly be enabled by the relevant libraries employing function multiversioning.reply",
      "You would guess wrong.reply",
      "Isn\u2019t the whole thrust of this thread that most normal algorithms see little to no speed up from things like avx, and therefore multiversioning those things that do makes more sense that compiling the whole OS for a newer set of cpu features?reply",
      "FWIW the cool thing about gentoo was the \"use-flags\", to enable/disable compile-time features in various packages. Build some apps with GTK or with just the command-line version, with libao or pulse-audio, etc. Nowadays some distro packages have \"optional dependencies\" and variants like foobar-cli and foobar-gui, but not nearly as comprehensive as Gentoo of course. Learning about some minor custom CFLAGS was just part of the fun (and yeah some \"funroll-loops\" site was making fun of \"gentoo ricers\" way back then already).I used Gentoo a lot, jeez, between 20 and 15 years ago, and the install guide guiding me through partitioning disks, formatting disks, unpacking tarballs, editing config files, and running grub-install etc, was so incredibly valuable to me that I have trouble expressing it.reply"
    ],
    "link": "https://discourse.ubuntu.com/t/introducing-architecture-variants-amd64v3-now-available-in-ubuntu-25-10/71312",
    "first_paragraph": "Ubuntu prides itself on being among the most compatible Linux distributions. Compatibility is often a conscious trade-off against bleeding-edge performance. In Ubuntu 25.10, we have added support for packages that target specific silicon variants, meaning you can have your cake and eat it too!Back in 2023 I wrote an article talking about the history of the amd64/x86-64 architecture and described the \u201clevels\u201d x86-64-v2, -v3, and -v4 (often referred to as amd64v3, amd64v4, etc.). Since then, we\u2019ve been working on a means to better exploit modern processors without compromising support for older hardware.To do this, we have added the concept of an \u201carchitecture variant.\u201d By making changes to dpkg, apt and Launchpad, we are able to build multiple versions of a package, each for a different level of the x86-64 architecture, meaning we can have packages that specifically target x86-64-v3, for example.As a result, we\u2019re very excited to share that in Ubuntu 25.10, some packages are available, "
  },
  {
    "title": "The Last PCB You'll Ever Buy [video] (youtube.com)",
    "points": 43,
    "submitter": "surprisetalk",
    "submit_time": "2025-10-27T17:42:17 1761586937",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45724043",
    "comments": [
      "Cool that people are trying new things. And I sure hate waiting for a PCB order to make its way from Hong Kong or Taiwan to Nebraska.I'm not sure I want the trade-off of having to try to fit my existing circuit into those pre-populated vias.Part of the joy of PCB layout is trying to be \"optimal\". That might be optimal in board size, optimal in the elegance of the trace layouts. I even trying to minimize vias (or not have them altogether). With prefab vias, there will be kludges to work my own vias into those locations. And, honestly, the unused vias will annoy me as well.I'm a sucker for solder masks, silkscreening\u2026 I think I am too in love with what I get back from Hong Kong and Taiwan.My \"quick prototyping\" consists of breadboarding and trashy perf-board mockups.reply",
      "I would definitely use this to knock together quick prototypes before ordering boards from China.So many times that I\u2019d happily pay $20 to try a board right fricking now (and I doubt they\u2019ll be $20 all-in).For me, it would replace breadboarding, not replace a final prototype PCB before committing to a first assembly run.reply",
      "That fitting problem sounds like an excellent job for a computer program! I wonder how many prebuilt PCB layouts would be necessary to fit most hobbyist requests.reply",
      "It's a shame there aren't US manufacturers who can manufacture custom PCBs as cheaply as JLPCB or PCBWay.These types of lasers might be a stopgap if tariffs make buying from those companies inordinately expensive, however the extreme cost, and the need to do a bunch of cleanup kind of makes me suspect there needs to be another iteration of this tech.reply",
      "OSHpark and sunstone are pretty good.  circuithub is serviceable for turnkey assembly (though they might outsource fab overseas, uncertain).reply",
      "I've had problems with Sunstone since they got bought by a company in the Midwest. It may just be corporate integration pains, but still.Specifically we had issues with added graphics not in my GERBERS, and some through hole plating issues.reply",
      "Yeah that's fair.  I don't use them very often.  They're in a similar bin as Advanced in that regard.reply",
      "Right, but OSH Park competes on quality not price.  In fact the other day I came across a reddit post from the owner of OSH Park explaining that e.g. JLC is selling their finished products below his material cost.  Add on to that the subsidized shipping and of course they're going to be well below what any US based company can offer.https://old.reddit.com/r/PrintedCircuitBoard/comments/9bt5ed...reply",
      "That post is 7 years old and JLC has changed a lot since then. It would be interesting to hear his current impressions (presumably they're still doing competitive comparisons).reply",
      "In the 90\u2019s we ordered them from TXreply"
    ],
    "link": "https://www.youtube.com/watch?v=A_IUIyyqw0M",
    "first_paragraph": ""
  },
  {
    "title": "Addiction Markets (thebignewsletter.com)",
    "points": 174,
    "submitter": "toomuchtodo",
    "submit_time": "2025-10-31T17:42:55 1761932575",
    "num_comments": 147,
    "comments_url": "https://news.ycombinator.com/item?id=45774640",
    "comments": [
      "But if you want to outlaw this harmful activity [licensed gambling], you have to find a way to replace 6.4% of Maryland\u2019s budget, which is slightly less than the entire amount the state brings in from corporate taxes.\n\nA fraction of the proceeds of losing bets from a fraction of Maryland's citizens contributes almost the same to state services -- EMS, education, road maintenance, etc -- than the total corporate taxes levied on all businesses.Do I misunderstand, or is this just actually incredible?reply",
      "Incredibly damning, yesreply",
      "It feels like banning advertising for gambling would be a sweet spot between harm reduction and maintaining individual liberty.Sports gambling ads have ruined sports media. State lottery ads are even worse. The government should not spend money to encourage its own citizens to partake in harmful activities.reply",
      "People are also leaving out stuff like Pokemon, Yu Gi Oh, and Magic The Gathering.All of them also introduce rarities (arbitrary exclusiveness), hidden cards in a pack, and extreme gambling gamification.The only non-gambling MtG packs are the preconstructed commander decks. All 100 cards are published. But the packs and boxes? Pure gambling, especially for the chase rare cards.And before anyone asks, yes, my username is based after this $2 card. https://edhrec.com/commanders/nekusar-the-mindrazerreply",
      "I feel like it only became rampant in recent years. As a 90s kid no one cared about the card packs. We all assumed they'd be junk cards and a waste of $7 or whatever. No, the move for card people back then was to wait for the card show and just buy the cards you actually want from a card dealer.The thing is now people are marketing the pack opening. You have social media accounts of them pulling cards from packs and getting all hyped up about it. Again no one thought that was fun in the 90s, everyone hated that aspect of cards in the 90s but thats because the unboxing as an experience wasn't marketed by anyone at all. People just wanted cards they thought were personally cool in some way.And likewise expansion of markets in the internet era means people start to have shared values of what is a valuable card based on market price vs just being interested in some certain cards out of your own interest.reply",
      "In the early to mid 2000s we used to do MTG booster drafts at the local game shop. Maybe the experience was different for different people.reply",
      "> Again no one thought that was fun in the 90s, everyone hated that aspect of cards in the 90sHow old was everyone in the 1990s? Kids loved this kind of thing in the 2000s.reply",
      "I can't imagine kids even liked it then. Again most of those packs were junk cards. Like total crap cards. Oh gee a rattata and some energy cards. All you wanted was Ash's squad from the shows.reply",
      "The kids I knew who played these kinds of card games all loved buying booster packs, but they weren\u2019t paying for these packs themselves and most grew out of playing by the time they reached high school. I can see it not being as fun for adult players who understand the probability metagame being played, but I think one of the reasons these games had so much financial success in the first place was that they identified a behavioral loop that they could exploit, exactly like contemporary developers did with loot boxes.reply",
      "The same age as kids in the 2000's?reply"
    ],
    "link": "https://www.thebignewsletter.com/p/addiction-markets-abolish-corporate",
    "first_paragraph": ""
  },
  {
    "title": "Use DuckDB-WASM to query TB of data in browser (law.harvard.edu)",
    "points": 138,
    "submitter": "mlissner",
    "submit_time": "2025-10-31T17:37:15 1761932235",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=45774571",
    "comments": [
      "OK, this is really neat:\n- S3 is really cheap static storage for files.\n- DuckDB is a database that uses S3 for its storage.\n- WASM lets you run binary (non-JS) code in your browser.\n- DuckDB-Wasm allows you to run a database in your browser.Put all of that together, and you get a website that queries S3 with no backend at all. Amazing.reply",
      "S3 might be relatively cheap for storing files, but with bandwidth you could easily be paying $230/mo. If you make it public facing & want to try to use their cloud reporting, metrics, etc. to prevent people for running up your bandwidth, your \"really cheap\" static hosting could easily cost you more than $500/mo.reply",
      "I think this approach makes sense for services with a small number of users relative to the data they are searching.  That just isn't a good fit for a lot of hosted services.  Think how much that TB's of data would cost on Algolia or similar services.You have to store the data somehow anyway, and you have to retrieve some of it to service a query.  If egress costs too much you could always change later to put the browser code on a server.  Also it would presumably be possible to quantify the trade-off between processing the data client side and on the server.reply",
      "Stick it behind Cloudflare and it should be effectively free.reply",
      "R2 is S3 compatible with no egress fees.Cloudflare actually has built in iceberg support for R2 buckets. It's quite nice.Combine that with their pipelines it's a simple http request to ingest, then just point duckdb to the iceberg enabled R2 bucket to analyze.reply",
      "For a demo of this (although not sure with duckdb wasm that it works with iceberg) https://andrewpwheeler.com/2025/06/29/using-duckdb-wasm-clou...reply",
      "Was about to jump in to say the same thing. R2 is a much cheaper alternative to S3 that just works and I have used it with DuckDB, works smoothlyreply",
      "S3 is doing quite a lot of sophisticated lifting to qualify as no backend at all.But yeah - this is pretty neat. Easily seems like the future of static datasets should wind up in something like this. Just data, with some well chosen indices.reply",
      "I believe all S3 has to do here is respond to HTTP Range queries, which are supported by almost every static server out there - Apache, Nginx etc should all support the same trick.reply",
      "100%. I\u2019m with y\u2019all - this is what I would also call a \u201cno-backend\u201d solution and I\u2019m all in on this type of approach for static data sets - this is the future, and could be served with a very simple web server.I\u2019m just bemused that we all refer to one of the larger, more sophisticated storage systems on the plant, composed of dozens of subsystems and thousands of servers as \u201cno backend at all.\u201d Kind of a \u201cdraw the rest of the owl\u201d.reply"
    ],
    "link": "https://lil.law.harvard.edu/blog/2025/10/24/rethinking-data-discovery-for-libraries-and-digital-humanities/",
    "first_paragraph": "Published:As part of our Public Data Project, LIL recently launched Data.gov Archive Search. In this post, we look under the hood and reflect on how and why we built this project the way we did.Libraries, digital humanities projects, and cultural heritage organizations have long had to perform a balancing act when sharing their collections online, negotiating between access and affordability. Providing robust features for data discovery, such as browsing, filtering, and search, has traditionally required dedicated computing infrastructure such as servers and databases. Ongoing server hosting, regular security and software updates, and consistent operational oversight are expensive and require skilled staff. Over years or decades, budget changes and staff turnover often strand these projects in an unmaintained or nonfunctioning state.The alternative, static file hosting, requires minimal maintenance and reduces expenses dramatically. For example, storing gigabytes of data on Amazon S3 m"
  },
  {
    "title": "A theoretical way to circumvent Android developer verification (enaix.github.io)",
    "points": 81,
    "submitter": "sleirsgoevy",
    "submit_time": "2025-10-31T20:20:42 1761942042",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=45776269",
    "comments": [
      "While it is technically feasible, it is not a good idea to try and find a technical solution to a people/organisation problem.Do not accept the premise of assholes.I hope we can get the EU to fund a truly open Android Fork. Maybe under some organisation similar to NL Labs.--- edit ---Furthermore, the need for a trustworthy binary to be auditable to a certain hash or something would make banning this a simple task if Google would want to go that route.reply",
      "The same EU that's doing Chat Control?reply",
      "What's wrong with lineage?reply",
      "> I hope we can get the EU to fund a truly open Android Fork.How are things in the EU on whether it's legal to buy a SIM card without showing ID?reply",
      "A secure OS is a prerequisite for secure digital services. We can agree on that, right?The task, therefore, is to convince enough politicians to establish an independent unit that can address this issue without direct political influence.Fund the unit with enough money so that it can take care of the cybersecurity and sovereignty of all citizens.A side effect of this would hopefully be that these politicians would then be digitally literate enough to recognize nonsense such as chat control as such and reject it outright. I hope that most politicians would not really want such omnipotent surveillance tools if they could truly grasp their scope.reply",
      "> How are things in the EU on whether it's legal to buy a SIM card without showing ID?It varies per country. In some you can just buy one (or more) SIM cards at a supermarket without any ID.reply",
      "It is neither illegal nor hard to obtain such a prepaid SIM card.reply",
      "That very much depends on the country, many require ID.reply",
      "The ID presented at time of purchase does not have to be the ID of the actual user of the card. Your local drunkard will be happy to get $10 to buy a SIM card for you. Or you could visit eBay (or local equivalent) and get a valid SIM card without leaving your house.reply",
      "The suggestion above wasn\u2019t a statement of practicality but rather of EU motivations. Maybe you can also find a drunkard to fork Android for you.reply"
    ],
    "link": "https://enaix.github.io/2025/10/30/developer-verification.html",
    "first_paragraph": "As you all know, Google has introduced developer verification as a way to prevent users from installing \u201cunregistered\u201d APKs. This measure was taken as a security feature to link every APK in existence to its developer, as in Play Store.Link to the Android documentation, link to FAQThis has already been discussed by ArsTechnica and on some threads (some cherry-picked ones): reddit, ycombinator, hackaday.A quick recap of the main points (as of 30 Oct 2025):A few months prior Google has decided to make Android development private, which seems to be a preparation for the upcoming changes (another article). Due to this change in AOSP release format, it is no longer possible to track what exactly Google is doing.My answer to this question is that it would simply prevent small developers from distributing their apps, including myself. If we take the legal route, a hobbyist license is supposed to have some limit on the number of installs by design. If we take, say, 10K installs, this is not en"
  },
  {
    "title": "My Impressions of the MacBook Pro M4 (stapelberg.ch)",
    "points": 112,
    "submitter": "secure",
    "submit_time": "2025-10-31T10:13:40 1761905620",
    "num_comments": 155,
    "comments_url": "https://news.ycombinator.com/item?id=45770304",
    "comments": [
      "It's classic Apple to spend over a decade insisting that that glossy screens were the best option, and then to eventually roll out a matte screen as a \"premium\" feature with a bunch of marketing around it.reply",
      "Historically, traditional matte screen finishes exhibited poor optical qualities by scattering ambient light, which tended to wash out colors. This scattering process also affected the light from individual pixels, causing it to refract into neighboring pixels.This reduced overall image quality and caused pixel-fine details, such as small text, to appear smeary on high-density LCDs. In contrast, well-designed glossy displays provide a superior visual experience by minimizing internal refraction and reflecting ambient light at high angles, which reduces display pollution. Consequently, glossy screens often appear much brighter, blacks appear blacker without being washed out, colors show a higher dynamic range, and small details remain crisper. High-quality glass glossy displays are often easy to use even in full daylight, and reflections are manageable because they are full optical reflections with correct depth, allowing the user to focus on the screen content.Apple's \"nano texture\" matte screens were engineered to solve the specific optical problems of traditional matte finishes, the washed-out colors and smeary details. But they cost more to make. The glossy option is still available, and still good.reply",
      "I used to have a 2006 macbook pro with the matte screen. It was glorious. None of these issues were present or really noticeable. Maybe you'd notice it in lab setting but not irl. Kind of like 120hz and 4k; just useless to most peoples eyes at the distances people actually use these devices. I've only owned matte external monitors as well and again, no issues there.The glossy era macbooks otoh have been a disaster in comparison imo. Unless your room is pitch black it is so easy to get external reflections. Using it outside sucks, you often see yourself more clearly than the actual contents on the screen. Little piece of dust on the screen you flick off becomes a fingerprint smear. The actual opening of the lid on the new thin bezel models means the top edge is never free of fingerprints. I'm inside right now and this M3 pro is on max brightness setting just to make it you know, usable, inside. I'm not sure if my screen is actually defectively dim or this is just how it is. Outside it is just barely bright enough to make out the screen. Really not much better than my old 2012 non retina model in terms of outdoor viewing which is a bit of a disappointment because the marketing material lead me to believe these new macbooks are extremely bright. I guess for HDR content maybe that is true but not for 99% of use cases.reply",
      ">I used to have a 2006 macbook pro with the matte screen. It was glorious. None of these issues were present or really noticeable.They were absolutely noticable. Contrast was crap. I immediately went with glossy with my next MBP around that same period.reply",
      "120Hz is absolutely a noticeable improvement over 60Hz. I have a 60Hz iPhone and a 120Hz iPhone and the 60Hz one is just annoying to use. Everything feels so choppy.reply",
      "I can't tell at all when my mbp is in 120hz or 60hz. I tried to set up a good test too by scrolling really fast while plugging and unplugging the power adapter (which kicks it into high power 120hz or low power 60hz).reply",
      "One of those things that some people notice, some people don't. I'm definitely in the camp where I feel differences between 120hz and 60hz, but I don't feel 60hz as choppy, and beyond 120hz I can't notice any difference, but others seemingly can. Maybe it's our biology?reply",
      "I would bet most people would fail a blind test.reply",
      "Basically everyone who has played videogames on pc will notice the difference. I easily notice a drop from 360Hz to 240Hz.I also use 60Hz screens just fine, saying that getting used to 120Hz ruins slower displays is being dramatic. You can readjust to 60Hz again within 5 minutes. But I can still instantly tell which is higher refresh rate, at least up to 360Hz.",
      "4K too, at anything over 15\u201d or so.I\u2019m always baffled people insist otherwise.reply"
    ],
    "link": "https://michael.stapelberg.ch/posts/2025-10-31-macbook-pro-m4-impressions/",
    "first_paragraph": "I have been using a MacBook Pro M4 as my portable computer for the last half a\nyear and wanted to share a few short impressions. As always, I am not a\nprofessional laptop reviewer, so in this article you won\u2019t find benchmarks, just\nsubjective thoughts!Back in 2021, I wrote about the MacBook Air\nM1, which was the first computer I used that\ncontained Apple\u2019s own ARM-based CPU. Having a silent laptop with long battery\nlife was a game-changer, so I wanted to keep those properties.When the US government announced tariffs, I figured I would replace my 4-year\nold MacBook Air M1 with a more recent model that should last a few more\nyears. Ultimately, Apple\u2019s prices remained stable, so, in retrospect, I could\nhave stayed with the M1 for a few more years. Oh well.I went to the Apple Store to compare the different options in\nperson. Specifically, I was curious about the display and whether the increased\nweight and form factor of the MacBook Pro (compared to a MacBook Air) would be\nacceptable. Anot"
  },
  {
    "title": "Leaker reveals which Pixels are vulnerable to Cellebrite phone hacking (arstechnica.com)",
    "points": 192,
    "submitter": "akyuu",
    "submit_time": "2025-10-30T23:12:10 1761865930",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=45766501",
    "comments": [
      "They couldn't answer the question most on my mind: \"We\u2019ve reached out to Google to inquire about why a custom ROM created by volunteers is more resistant to industrial phone hacking than the official Pixel OS. We\u2019ll update this article if Google has anything to say.\"reply",
      "Is grapheheOS actually harder to hack or does cellebrite just not put a lot of effort into supporting it because the very low odds of LEs running into one in the wild?reply",
      "I read from an old HN post that three letter agencies hate graphen OS. The author heard it from defcon or some similar conference. I couldn\u2019t find the post anyway :/ I think it is buried under one of the posts that discuss Defcon and Blackhat.reply",
      "Wouldn't it be a total mindfuck if it turns out that Graphene is less secure[1] than stock Pixel, and this is all part of an ANOM-style honeypot operation that has Feds hyping it up, to trick interesting targets into adopting a less-effective security posture.1. Such as via slower 0-day responses, for instance. This is a thought experiment, I'm nor alleging that this is what it is.reply",
      "It wouldn't be the first honeypot phone, haha.What bothers me is that when phones are stolen, they end up in other countries. Maybe you are a nobody, but if it is trivial to extract the information on a phone then there is more than an identity theft issue. Generative AI makes all of this shit way worse than it was even a year ago.reply",
      "Anyone can build GrapheneOS from source code, which I doubt is true of any law-enforcement honeypot.reply",
      "See my footnote in original comment.reply",
      "GrapheneOS updates really fast, like on a weekly basis. The trouble is that you have to trust the developers in general. Even if you did build it yourself, did you read all the code and scripts used to build it? But I think it's still a net benefit for a certain kind of user to have the code, and it raises the minimum complexity of any potential exploit.reply",
      "Exactly what someone who sets up a honeypot targeting nerds would want you to think.reply",
      "You can actually build it. But who has time to audit all that stuff? Then you know, there could be firmware hacks that make all the system-level backdoors a moot point.reply"
    ],
    "link": "https://arstechnica.com/gadgets/2025/10/leaker-reveals-which-pixels-are-vulnerable-to-cellebrite-phone-hacking/",
    "first_paragraph": "\n        Cellebrite can apparently extract data from most Pixel phones, unless they\u2019re running GrapheneOS.\n      Despite being a vast repository of personal information, smartphones used to have little by way of security. That has thankfully changed, but companies like Cellebrite offer law enforcement tools that can bypass security on some devices. The company keeps the specifics quiet, but an anonymous individual recently logged in to a Cellebrite briefing and came away with a list of which of Google\u2019s Pixel phones are vulnerable to Cellebrite phone hacking.This person, who goes by the handle rogueFed, posted screenshots from the recent Microsoft Teams meeting to the GrapheneOS forums (spotted by 404 Media). GrapheneOS is an Android-based operating system that can be installed on select phones, including Pixels. It ships with enhanced security features and no Google services. Because of its popularity among the security-conscious, Cellebrite apparently felt the need to include it in i"
  },
  {
    "title": "Hacking India's largest automaker: Tata Motors (eaton-works.com)",
    "points": 128,
    "submitter": "EatonZ",
    "submit_time": "2025-10-29T01:31:56 1761701516",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=45741569",
    "comments": [
      "Related: Jaguar Land Rover hack cost UK economy an estimated $2.5 billion, report says: https://news.ycombinator.com/item?id=45668008The 'tech' for both these is by guess who? TCS!Edit: For those who don't know the relation. Tata[1] is a conglomerate, which owns both Tata Motors (Jaguar, Land Rover) and also TCS (Tata Consultancy Services)[1] https://en.wikipedia.org/wiki/Tata_Groupreply",
      "TCS also contracts for Marks & Spencer, and the Co-op, both of which were also taken offline by hacking earlier this year.reply",
      "Note that M&S dropped TCS in July following the recovery. https://www.ft.com/content/289ec371-2ed4-425a-9bd0-c34e6db39... and elsewhere.reply",
      "> M&S chair, told MPs that hackers had used \u201csophisticated impersonation\u201d to gain entry \u201cinvolving a third party.\u201d20 bucks says this sophisticated impersonation was social engineering a $5/hour outsourced customer support employee> The attack is expected to lower operating profits by up to \u00a3300mn this year.that's not counting the reputation and brand damage. M&S is seen as a premium retailer and this whole hack made them seem utterly incompetent and unreliable> had decided to opt for another service provider after the process had completedi wonder where this other provider is based. i think i'm gonna place another 20 bucks on this.> The retailer continues to use the Indian group for other services.lol.reply",
      ">20 bucks says this sophisticated impersonation was social engineering a $5/hour outsourced customer support employee0 bucks says this below list of data breaches is much much more devastating. 0 bucks, because I don't have to bet on it, unlike you, because it's true:>https://en.wikipedia.org/wiki/List_of_data_breaches>This is a list of reports about data breaches, using data compiled from various sources, including press reports, government news releases, and mainstream news articles. The list includes those involving the theft or compromise of 30,000 or more records, although many smaller breaches occur continually. Breaches of large organizations where the number of records is still unknown are also listed. In addition, the various methods used in the breaches are listed, with hacking being the most common.>Most reported breaches are in North America, at least in part because of relatively strict disclosure laws in North American countries.[citation needed] 95% of data breaches come from government, retail, or technology industries.[1] It is estimated that the average cost of a data breach will be over $150 million by 2020, with the global annual cost forecast to be $2.1 trillion.[2][3] As a result of data breaches, it is estimated that in first half of 2018 alone, about 4.5 billion records were exposed.[4] In 2019, a collection of 2.7 billion identity records, consisting of 774 million unique email addresses and 21 million unique passwords, was posted on the web for sale.[5] In January 2024, a data breach dubbed the \"mother of all breaches\" was uncovered.[6] Over 26 billion records, including some from Twitter, Adobe, Canva, LinkedIn, and Dropbox, were found in the database.[7][8] No organization immediately claimed responsibility.[9]>In August 2024, one of the largest data security breaches was revealed. It involved the background check databroker, National Public Data and exposed the personal information of nearly 3 billion people.[10]reply",
      ">that's not counting the reputation and brand damage. M&S is seen as a premium retailer and this whole hack made them seem utterly incompetent and unreliable>>The retailer continues to use the Indian group for other services.>lol.>is seenlol. a lot of things are seen as blah blah. doesn't mean they are blah blah.google is seen as a world leading tech company. yet see how HNers regard them (except those desperate for FAANG salaries).If they hired their vendors without due diligence, they may be incompetent and unreliable themselves. On the other hand:>> M&S chair, told MPs that hackers had used \u201csophisticated impersonation\u201d to gain entry \u201cinvolving a third party.\u201dIf the impersonation was sophisticated, maybe it was not so much the fault of TCS?If it was a Western company, would you talk / think the same?Nahi. Non. Nein. Nyet. Nada.lol.reply",
      "At what point is it more believable that these are inside jobs done on purpose vs. incompetence?  I guess that\u2019s just Hanlon\u2019s Razor though.reply",
      "When you pay your support employees so little, it's not difficult for someone from a wealthier place to bribe them.reply",
      "I have heard there is a growing trend of hackers paying kickbacks to insiders, certainly makes hacking easier.reply",
      "Having worked with Indian consultancy firms for over 10 years. I can safely say security attitudes and practices haven't changed much.There's always this culture of taking shortcuts at the expense of security and quality.reply"
    ],
    "link": "https://eaton-works.com/2025/10/28/tata-motors-hack/",
    "first_paragraph": "If you are in the US and ask your friends and family if they have heard of \u201cTata Motors\u201d, they would likely say no. However, if you go overseas, Tata Motors and the Tata Group in general are a massive, well-known conglomerate. Back in 2023, I took my hacking adventures overseas and found many vulnerabilities with Tata Motors. This post covers 4 of the most impactful findings I discovered that I am finally ready to share today. Let\u2019s dive in!Note that all secrets/credentials shown have been rotated, meaning they are no longer valid and cannot be used anymore. Additionally, no substantial amounts of data were downloaded as part of any testing, nor was there any obvious evidence of malicious access.E-Dukaan is a Tata Motors site where their customers can buy spare parts for their vehicles. It\u2019s a typical E-Commerce site, but it had a dark secret!Can you see it? Right there, in plaintext, are AWS keys. For those unfamiliar, you NEVER EVER want to expose these because people can use them to"
  },
  {
    "title": "Perfetto: Swiss army knife for Linux client tracing (lalitm.com)",
    "points": 96,
    "submitter": "todsacerdoti",
    "submit_time": "2025-10-31T11:54:00 1761911640",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=45771019",
    "comments": [
      "Perfetto is definitely one of my favorite tools to use ever, thank you for working on it!My personal favorite tool I've built this year is to dynamically generate a trace from a sql query, and allow quickly combining queries. Something like `SELECT timestamp, track, name, ` etc. where column names get transformed to packets automatically.That way I can overlay multiple py-spy traces and instrumentation into a dynamically implemented generated perfetto trace, loaded into a perfetto iframe using the ping/pong mechanism at https://perfetto.dev/docs/visualization/deep-linking-to-perf....reply",
      "Thanks for the nice words! Your tool sounds super neat!We're look at integrating some sort of similarish things into Perfetto itself where, for a synthetically generated trace, you can say \"run this SQL query and add a debug track for it on trace load\". See the discussion on https://github.com/google/perfetto/issues/1342 :)reply",
      "Perfetto is so nice.Viztracer is a super library to capture perfetto compatible output from Python.It helped me find perf issues in literally minutes.https://raw.githubusercontent.com/time4tea/gopro-dashboard-o...reply",
      "Glad to see that there's support for CPU sample flamegraphs in Perfetto now that's on par with Google's internal pprof visualizer as alluded to in the talk. Using the internal visualizer to share Windows ETW traces with colleagues was the primary motivation for developing [EtwToPprof](https://github.com/google/EtwToPprof). Now that perfetto supports this natively, I might look into developing EtwToPerfetto :-)reply",
      "Fun fact: Perfetto also gained support for the pprof format within the last month :)It opens a special \"aggregate flame graph\" view of the profile since pprof does not preserve time information. But it works! We use it for visualizing aggregates across thousands of profiles in production!reply",
      "Something too complex; I fear I won't ever have enough time to try it and figure out how to apply it for it to be of any use for me.I wish there was a simpler and quicker introduction into the tool's capabilities than an hour long video and a text article saying it's a swiss army knife that does a lot of things. I need 1 or a few glimpses into it, there's no need to cover every capability thoroughly, show just enough to have some general understanding of how it works and how to use it and how to solve some common problems with it.reply",
      "Go to https://ui.perfetto.dev/. On the left sidebar, under \"Example traces\", click \"Open Android example\".For a simple example using your own data, save this as a file and open it via \"Open trace file\":  [\n    {\"name\": \"Example 1\", \"ph\": \"X\", \"ts\": 1, \"dur\": 1, \"pid\": 0, \"tid\": 0},\n    {\"name\": \"Example 2\", \"ph\": \"X\", \"ts\": 3, \"dur\": 2, \"pid\": 0, \"tid\": 0},\n    {\"name\": \"Example 3\", \"ph\": \"X\", \"ts\": 2, \"dur\": 1, \"pid\": 0, \"tid\": 1},\n    {\"name\": \"Example 4\", \"ph\": \"X\", \"ts\": 4, \"dur\": 2, \"pid\": 0, \"tid\": 1}\n  ]reply",
      "This talk was meant to be a comprehensive look into the tool for an audience familiar with performance and tracing (but not necessarily Perfetto and how it can be used on Linux).If you're more looking for a short intro, I'd maybe suggest our docs website, specifically the page https://perfetto.dev/docs/getting-started/start-using-perfet...For example:* if you work in the Linux kernel, try https://perfetto.dev/docs/getting-started/start-using-perfet...* If you're generally curious about performance or tracing try https://perfetto.dev/docs/getting-started/start-using-perfet...There's also our quick starts which take you through \"I just want to see the tool in action\". Find the system tracing one at https://perfetto.dev/docs/getting-started/system-tracingreply",
      "That's just the nature of these tools though. For example, Windows has its own powerful ETW tracing framework, but using it for real profiling and debugging requires learning a lot about the tools: https://randomascii.wordpress.com/2015/09/24/etw-central/reply"
    ],
    "link": "https://lalitm.com/perfetto-swiss-army-knife/",
    "first_paragraph": "I gave a talk at the 2025 Tracing Summit last month titled \u201cPerfetto: The Swiss Army Knife of Linux Client/Embedded Tracing\u201d. My goal in this talk was to show how Linux kernel, systems and embedded developers can use Perfetto when debugging and root-causing performance issues in their respective domains. Even though the Perfetto UI is primarily built for viewing Android or Chrome traces, it is a flexible tool and can be used in many other ways!The talk was recorded and is available on YouTube. Taking inspiration from Simon Willison, this post is an annotated presentation containing my slides and detailed notes on them. The talk also has a lot of UI demos: for these, I\u2019ll have a screenshot but also a link to the relevant part of the video (videos are unbeatable for UI!).First, what is Perfetto? Perfetto is fundamentally a suite of tools: it\u2019s not just one thing but a bunch of different tools working together to help you debug and root-cause problems. This diagram shows how everything fi"
  },
  {
    "title": "How We Found 7 TiB of Memory Just Sitting Around (render.com)",
    "points": 101,
    "submitter": "anurag",
    "submit_time": "2025-10-30T18:25:05 1761848705",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=45763359",
    "comments": [
      "The unreasonable effectiveness of profiling and digging deep strikes again.reply",
      "The biggest tool in the performance toolbox is stubbornness. Without it all the mechanical sympathy in the world will go unexploited.There\u2019s about a factor of 3 improvement that can be made to most code after the profiler has given up. That probably means there are better profilers than could be written, but in 20 years of having them I\u2019ve only seen 2 that tried. Sadly I think flame graphs made profiling more accessible to the unmotivated but didn\u2019t actually improve overall results.reply",
      "I think the biggest tool is higher expectations. Most programmers really haven't come to grips with the idea that computers are fast.If you see a database query that takes 1 hour to run, and only touches a few gb of data, you should be thinking \"Well nvme bandwidth is multiple gigabytes per second, why can't it run in 1 second or less?\"The idea that anyone would accept a request to a website taking longer than 30ms, (the time it takes for a game to render it's entire world including both the CPU and GPU parts at 60fps) is insane, and nobody should really accept it, but we commonly do.reply",
      "Pedantic nit: At 60 fps the per frame time is 16.66... ms, not 30 ms. Having said that a lot of games run at 30 fps, or run different parts of their logic at different frequencies, or do other tricks that mean there isn't exactly one FPS rate that the thing is running at.reply",
      "The CPU part happens on one frame, the GPU part happens on the next frame. If you want to talk about the total time for a game to render a frame, it needs to count two frames.reply",
      "Computers are fast. Why do you accept a frame of lag? The average game for a PC from the 1980s ran with less lag than that. Super Mario Bros had less than a frame between controller input and character movement on the screen. (Technically, it could be more than a frame, but only if there were enough objects in play that the processor couldn't handle all the physics updates in time and missed the v-blank interval.)reply",
      "If Vsync is on which was my assumption from my previous comment, then if your computer is fast enough, you might be able to run CPU and GPU work entirely in a single frame if you use Reflex to delay when simulation starts to lower latency, but regardless, you still have a total time budget of 1/30th of a second to do all your combined CPU and GPU work to get to 60fps.reply",
      "Lowered expectations are come in part from people giving up on theirs. Accepting versus pushing back.reply",
      "I have high hopes and expectations, unfortunately my chain of command does not, and is often an immovable force.reply",
      "This is a terrible time to tell someone to find a movable object in another part of the org or elsewhere. :/I always liked Shaw\u2019s \u201cThe reasonable man adapts himself to the world: the unreasonable one persists in trying to adapt the world to himself. Therefore all progress depends on the unreasonable man.\u201dreply"
    ],
    "link": "https://render.com/blog/how-we-found-7-tib-of-memory-just-sitting-around",
    "first_paragraph": "Debug your Render services in Claude Code and Cursor.Getting ready to dissect what I like to call: the Kubernetes hypercube of bad vibes. Credits: Hyperkube from gregegan.net, diagram (modified) from Kubernetes community repoPlenty of teams run Kubernetes clusters bigger than ours. More nodes, more pods, more ingresses, you name it. In most dimensions, someone out there has us beat.There's one dimension where I suspect we might be near the very top: namespaces. I say that because we keep running into odd behavior in any process that has to keep track of them. In particular, anything that listwatches them ends up using a surprising amount of memory and puts real pressure on the apiserver. This has become one of those scaling quirks you only really notice once you hit a certain threshold. As this memory overhead adds up, efficiency decreases: each byte we have to use for management is a byte we can't put towards user services.The problem gets significantly worse when a daemonset needs to"
  },
  {
    "title": "Kerkship St. Jozef, Antwerp \u2013 WWII German Concrete Tanker (thecretefleet.com)",
    "points": 4,
    "submitter": "surprisetalk",
    "submit_time": "2025-10-23T13:23:32 1761225812",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://thecretefleet.com/blog/f/kerkship-st-jozef-antwerp-%E2%80%93-wwii-german-concrete-tanker",
    "first_paragraph": "Blogs about World War I and World War \u00a0II Concrete Ships and Mulberry Harbour componentsCopyright \u00a9 2025 The Crete Fleet - All Rights Reserved.Powered by We use cookies to analyze website traffic and optimize your website experience. By accepting our use of cookies, your data will be aggregated with all other user data."
  },
  {
    "title": "Active listening: the Swiss Army Knife of communication (togetherlondon.com)",
    "points": 12,
    "submitter": "lucidplot",
    "submit_time": "2025-10-27T11:40:04 1761565204",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=45719829",
    "comments": [
      "That was excellent!Couple of tweaks though, try to avoid the same call for response, '..is that right?' or whatever. Patterns in speech become REALLY old REALLY quickly.. It can start to create a picture in their head that this is staged (and it kinda is) which then starts to cause them to raise walls up. Keep to the context of the question using whatever words you're comfy with 'X...? I got that right?', or 'soooooo... X yeah?' and they'll spot the pattern but because of the conversational nature of it their hackles will take a lot longer to raise.The other thing is putting pauses in. Yes pauses are remarkably powerful, actual dead air forces the other side to fill it, but it also creates a pressure vacuum, it FEELS like minor bullishness and can start causing combativeness.\nFor me if I want the conversation to feel level between two equals I'll instead fill the pauses with word-salad appropriate to whatever the context is with a couple of words in there to ping reactions.\n'Oh wow, yeah the more I think about this the more I'm just... wow. Yeah that's annoying', where 'the more I think' is reflecting back that I agree there's something to what they are saying and 'annoying' to cause them to reflect on the irritation, trying to draw out that feeling more so they can then talk about the next layer down, but it's still basically a pause, it quietly says 'I hear you, I don't have anything to say right now, so go on...'reply",
      "> The active listening formula is simple: [\u2026]The instructions sound a lot like what Weizenbaum programmed into ELIZA. :)reply",
      "You've got to be kidding. The couple of times someone tried this with me I stopped and asked what the F are you doing?It's very obviously fake. Seriously you can't see that?reply"
    ],
    "link": "https://togetherlondon.com/insights/active-listening-swiss-army-knife",
    "first_paragraph": ""
  },
  {
    "title": "Llamafile Returns (blog.mozilla.ai)",
    "points": 89,
    "submitter": "aittalam",
    "submit_time": "2025-10-29T22:21:12 1761776472",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=45753850",
    "comments": [
      "The Discord link is broken, in that it links to the server directly rather than to an invitation to join the server, which prevents new members from joining.reply",
      "Tips:    # Avoid issues when wine is installed.\n    sudo su -c 'echo 0 > /proc/sys/fs/binfmt_misc/status'\n\nAnd:    # Capture the entirety of the instructions to obtain the input length.\n    readonly INSTRUCT=$(\n      join ${PATH_PREFIX_SYSTEM} ${PATH_PROMPT_SYSTEM} ${PATH_PREFIX_SYSTEM}\n      join ${PATH_SUFFIX_USER} ${PATH_PROMPT_USER} ${PATH_SUFFIX_USER}\n      join ${PATH_SUFFIX_ASSIST} \"/dev/null\" ${PATH_SUFFIX_ASSIST}\n    )\n\n    (\n      echo ${INSTRUCT}\n    ) | ./llamafile \\\n      -m \"${LINK_MODEL}\" \\\n      -e \\\n      -f /dev/stdin \\\n      -n 1000 \\\n      -c ${#INSTRUCT} \\\n      --repeat-penalty 1.0 \\\n      --temp 1.5 \\\n      --silent-prompt > output.txtreply",
      "I\u2019m glad to see llamafile being resurrected. A few things I hope for:1. Curate a continuously extended inventory of prebuilt llamafiles for models as they are released\n2. Create both flexible builds (with dynamic backend loading for cpu and cuda) and slim minimalist builds\n3. Upstreaming as much as they can into llama.cpp and partner with the projectreply",
      "Crazier ideas would be:\n- extend the concept to also have some sort of \u201cagent mode\u201d where the llamafiles can launch with their own minimal file system or isolated context \n- detailed profiling of main supported models to ensure deterministic outputsreply",
      "Love the idea!reply",
      "justine tunney gave a great intro to Llamafile at AIE last year if it helps anyone: https://www.youtube.com/watch?v=-mRi-B3t6fAreply",
      "Really exciting to see Mozilla AI starting up and I can't wait to see where the next generation takes the project!reply",
      "People are so uninformed, they don't know you are Mozilla AI's star employee.reply",
      "s/are/wasI don't know if you were informed but you realize that jart is no longer at Mozilla anymore and now at Google Inc?reply",
      "how is this different from ollama? for me the more/open the merrier.reply"
    ],
    "link": "https://blog.mozilla.ai/llamafile-returns/",
    "first_paragraph": "Mozilla.ai is adopting llamafile to advance open, local, privacy-first AI\u2014and we\u2019re inviting the community to help shape its future.Mozilla.ai is adopting llamafile to advance open, local, privacy-first AI\u2014and we\u2019re inviting the community to help shape its future.Mozilla.ai is adopting the llamafile project to advance local, privacy-first AI. We are refreshing the codebase, modernizing foundations, and shaping the roadmap with community input.\u00a0Tell us what features matter the most to you on our Github Discussion board, the Mozilla Discord llamafile channel, or over on\u00a0Hacker News. We\u2019re excited to hear from you!Mozilla.ai was founded to build a future of trustworthy, transparent, and controllable AI. Over the past year, we have contributed to that mission by exploring not only the big cloud hosted large language models (LLMs) like GPT, Claude, Gemini, but also the smaller open-weight local models like gpt-oss, Gemma, and Qwen.\u00a0The llamafile project allows anyone to easily distribute an"
  },
  {
    "title": "Show HN: Pipelex \u2013 Declarative language for repeatable AI workflows (github.com/pipelex)",
    "points": 74,
    "submitter": "lchoquel",
    "submit_time": "2025-10-28T16:19:26 1761668366",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=45734865",
    "comments": [
      "Declarative workflows is such a good idea, fantastic, and I love the AI first principles where pipeline creation and editing the pipeline can be done with AI too.The declarative style keeps the workflow detail at a high enough level to iterate super quick - love that. More important to me is that it\u2019s structured and seems like it would be more testable (I see validation in your docs).Zooming in to the pipe/agent steps I can\u2019t quite see if you can leverage MCP as a client and make tool calls? Can you confirm? If not what\u2019s your solution for working with APIs in the middle of your pipeline?Also a quick question, declarative workflows won\u2019t solve the fact that LLMs output is always non deterministic, and so we can\u2019t always be guaranteed the output from prior steps will be correct. What tools or techniques are you using/recommending to measure the reliability of the output from prior steps? I\u2019m thinking of how might you measure at a step level to help you prioritise which prompts need refinements or optimisations? Is this a problem you expect to own in Pipex or one to be solved elsewhere?Great job guys, your approach looks like the right way to solve this problem and add some reliability to this space. Thanks for sharing!reply",
      "Hi Clafferty,\nProviding an MCP server was a no brainer and we have the first version available. But you're right, using \"MCP as a client\" is a question we have started asking ourselves too. But we haven't had the time to experiment yet, so, no definitive answer.\nFor now, we have a type of pipe called PipeFunc which can call a python function and so possibly any kind of tool under the hood. But that is really a makeshift solution. And we are eager to get your point of view and discuss with the community to get it right.Many companies are working on evals and we will have a strategy for integration with Pipelex. What we have already is modularity: you can test each pipe separately or test a whole workflow, that is pretty convenient. Better yet, we have the \"conceptual\" level of abstraction: the code is the documentation. So you don't need any additional work to explain to an eval system what we were expecting at each workflow step: it's already written into it. We even plan to have an option (typically for debug mode) that checks every input and every output complies semantically with what was intended and expected.Thanks a lot for your feedback! It's a lot of work so greatly appreciated.reply",
      "Recently I'm working on a project that let the users to analyze and rate the bid documents based on one tender document. The general logic is quite alike to the cv-job_offer example in Pipelex. The challenge I encountered is that both tender and bid documents are very large, it's impossible to load even a single one in LLM context, not to say both. Therefore I have to design a workflow to extract structured informations and evaluation criteria from the tender doc into predefined data models, and then dispatch multiple tasks to complete evaluation of these data models against each bid doc.I'm wondering if this kind of scenario (essentially it's just the input document is too big) is possible to be handled in Pipelex. In my understanding DSL is good for it's high-level abstraction and easy to understand, but lacks flexibility and the power is restricted. How can the users of Pipelex iterate the pipelines to fulfill the complex need when the business logic became complex inevitably?reply",
      "When the business logic becomes complex, our motto which is to break it down into smaller problems, until they are manageable.Regarding large docs, I know what you mean and we've been there: at one point we considered focusing on that feature, build a kind of agentic system to master large docs. At the time in 2023-2024, everyone was relying on vector store RAG and embeddings to solve that problem but we always thought that solution wouldn't bring enough reliability. We wanted the LLM to actually read the whole docs, in order to know what's in there and where. The idea was to read and \"take notes\" according to different aspects of what it's reading, and synthesize hierarchically from bottom to top. So, that part of the work could be done once and the structured \"notes\" could be exploited for each use case, pretty efficiently thanks to the zoom-in/out provided by the architecture.\nWe went pretty far in building that solution, which we called \"Pyramid RAG\" internally, and the aim was to build AI workflows of top of that. But at some point, the building of the pyramid became pretty complex, and we realized we needed AI workflows to build the pyramid itself, and we needed to to do it right. That's when we decided to focus on what would become Pipelex.\nNow, in our new setting, solving the \"large docs\" problem is a large problem we can break down into a collection of Pipelex workflows. So it's part of our plan to provide those building blocks, and we hope to involve the community as much as possible, to cover all the possible applications.reply",
      "Love the concept, I saw similar ideas in BAML [1], what do you think are the differences and advantages of Pipelex over it?[1]: https://github.com/boundaryml/bamlreply",
      "Hi novoreorx,\nthe biggest difference is that in Pipelex workflows, we express the logic in our high-level language, rather than in Python or typescript.\nThis makes it easier to collaborate between tech and non-tech people, like domain experts. It's also great for collaboration with AI: the declarative approach and the high level of abstraction means that LLMs have all the context to understand what's going on in the workflow.\nAlso, we don't use Pipelex for \"autonomous agents\": our workflows are meant to be repeatable and deterministic, like a tool. Like a tool that can be used by agents though our MCP server.reply",
      "Declarative DSL is a really interesting approach, especially since you\u2019re exposing it directly to the users. There are some applications where throwing the dice in production by having LLM as part of the runtime is not an option.reply",
      "Yes! Clearly the introduction of LLMs into the mix raises the problem of throwing dice.\nThe point of view we chose is: how to orchestrate the collaboration between AI, Software and people?\nWith our aim to have repeatable workflows, this drove us away from building autonomous agents and towards a place where the software is in command of the orchestration. Then the Humans and AI can discuss \"what you want to do\" and have software run it and use AI where it's needed.reply",
      "Love the DSL. Saw caching is roadmap \u2014 does a failed step restart everything, or resume partway?reply",
      "Sorry, I guess I'm not fully understanding what this is exactly. Would you describe this as a low-code/no-code agent generator? So if you can define requirements via a pipelex \"config\" file, Pipelex will generate a python-based agent?reply"
    ],
    "link": "https://github.com/Pipelex/pipelex",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Pipelex: open-source language for AI Agents to create and run repeatable AI workflows\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Pipelex is developing the open standard for repeatable AI workflows.\nWrite business logic, not API calls.\n\n\n\n\n\n\n\n\n\n\n\n\nTo use AI models, you need an API key:See Configure AI Providers for details.Create a complete AI workflow with a single command:This command generates a production-ready .plx file with domain definitions, concepts, and multiple processing steps that analyzes CV-job fit and prepares interview questions.cv_match.plxView the pipeline flowchart:Via CLI:Create an inputs.json file with your PDF URLs:Via Python:Install AI assistant rules to easily modify your pipelines:This installs rules for Cursor, Claude, OpenAI C"
  },
  {
    "title": "Nix Derivation Madness (fzakaria.com)",
    "points": 151,
    "submitter": "birdculture",
    "submit_time": "2025-10-31T14:28:35 1761920915",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=45772347",
    "comments": [
      "The deriver field in Nix has always been a misfeature. It was intended to provide traceability back to the Nix expression used to create the derivation, but it doesn't actually do that (since that wasn't really possible in the pre-flakes world, without hermetic evaluation). So instead it just causes a lot of confusion when the deriver recorded in the binary cache doesn't match the local evaluation result, due to fixed-output derivations changing.In the future, Nix will hopefully gain proper provenance tracking that will tell you exactly where a store path came from: https://github.com/NixOS/nix/pull/11749reply",
      "The biggest problem of all is that derivers are not unique! A separate \"build trace\" map will solve this.reply",
      "Presumably this would support a big improvement to both SBOM generation as well as various UX features and workflow improvements.reply",
      "is that the 'build-trace' feature I saw John write about ?\n(I want to explore that more)reply",
      "I think Eelco has in mind a separate thing that would still be a store object field. But IMO we should not do that since derives are unique, and we should instead use the \"build trace\" instead, which properly handles that.As Martin Schwaighofer has discussed, it is fine and in fact good for build traces entries to have arbitrary meta data, so the \"claims\" being cryptographically signed are more precise. (This is good for auditing, and if something looks suspicious, having full accountability.)So on that grounds, if eelco would like to include some \"this came from this flake\" information as informal metadata. (formally the key must still the resolved derivation.) That is fine with me.---As I linked in my other reply, see my fast-growing https://github.com/NixOS/nix/pull/14408 docs PR where I try to formally nail all this stuff down for the first time.reply",
      "I mentioned another alternative to adding flake-specific metadata to  data structures that are transferred over the network, as part of the signed traces or otherwise, in a comment on that PR Eelco linked.It's keeping flake-specific data locally, to guarantee that it matches how the user ended up with the data, not how the builder produced it. I think otherwise from the user POV such data could again look misleading.reply",
      "Good point. It is misleading if different flakes end up producing the same derivation, and we don't want to resign our build trace entry to account for that (which would amplify reads into writes). Separate indirection for this eval->store layer accounting sounds good.reply",
      "+1 to Farid, great write-up! What you\u2019re seeing is the long-standing \u201cderiver\u201d mismatch: fixed-output derivations can change their .drv without changing the output path. Eelco is calling it out as well in the comment below. I believe the idea behind the path forward is there but happy to hear more!Also. Check out Farid's other posts.reply",
      "> The road to Nix enlightenment is no joke and full of dragons.Nix was a great research project. Now is the time to rewrite it from the ground up.reply",
      "The core store layer is quite small, and I am trying to thoroughly document it, with all 3 of:- a more \"academic\" spec of what it does- nuts-and-bolts JSON schema for many data types- JSON golden tests instead of C++ literals in the unit tests as often as possible.I hope this will make additional store layer easy to churn out.(The \"hash derivation modulo\" that is so fiddly described in this blog post can be dropped in a world where we no longer have input addressing, and just have content-addressing. Or, in a world where we have a new, simpler type of input-addressing instead.)reply"
    ],
    "link": "https://fzakaria.com/2025/10/29/nix-derivation-madness",
    "first_paragraph": "\n    Published 2025-10-29 on\n    Farid Zakaria's Blog\nI\u2019ve written a bit about Nix and I still face moments where foundational aspects of the package system confounds and surprises me.Recently I hit an issue that stumped me as it break some basic comprehension I had on how Nix works. I wanted to produce the build and runtime graph for the Ruby interpreter.Huh. \ud83e\udd14I have Ruby but I don\u2019t seem to have the derivation, 24v9wpp393ib1gllip7ic13aycbi704g, file present on my machine.No worries, I think I can --realize it and download it from the NixOS cache.I guess the NixOS cache doesn\u2019t seem to have it. \ud83e\udd37This was actually perplexing me at this moment. In fact there are multiple discourse posts about it.My mental model however of Nix though is that I must have first evaluated the derivation (drv) in order to determine the output path to even substitute. How could the NixOS cache not have it present?Is this derivation wrong somehow? Nope. This is the derivation Nix believes that produced this Ru"
  },
  {
    "title": "AI scrapers request commented scripts (cryptography.dog)",
    "points": 184,
    "submitter": "ColinWright",
    "submit_time": "2025-10-31T15:44:19 1761925459",
    "num_comments": 127,
    "comments_url": "https://news.ycombinator.com/item?id=45773347",
    "comments": [
      "Most web scrapers, even if illegal, are for... business. So they scrape amazon, or shops. So yeah. Most unwanted traffic is from big tech, or bad actors trying to sniff vulnerabilities.I know a thing or two about web scraping.There are sometimes status codes 404 for protection, so that you skip this site, so my crawler tries, as a hammer, several of faster crawling methods (curlcffi).Zip bombs are also not for me. Reading header content length is enough to not read the page/file. I provide byte limit to check if response is not too big for me. For other cases reading timeout is enough.Oh, and did you know that requests timeout is not really timeout a timeout for page read? So server can spoonfeed you bytes, one after another, and there will be no timeout.That is why I created my own crawling system to mitigate these problems, and have one consistent mean of running selenium.https://github.com/rumca-js/crawler-buddyBased on libraryhttps://github.com/rumca-js/webtoolkitreply",
      "content-length is computed after content-encodingreply",
      ">These were scrapers, and they were most likely trying to non-consensually collect content for training LLMs.\"Non-consensually\", as if you had to ask for permission to perform a GET request to an open HTTP server.Yes, I know about weev. That was a travesty.reply",
      "When I open an HTTP server to the public web, I expect and welcome GET requests in general.However,(1) there's a difference between (a) a regular user browsing my websites and (b) robots DDoSing them. It was never okay to hammer a webserver. This is not new, and it's for this reason that curl has had options to throttle repeated requests to servers forever. In real life, there are many instances of things being offered for free, it's usually not okay to take it all. Yes, this would be abuse. And no, the correct answer to such a situation would not be \"but it was free, don't offer it for free if you don't want it to be taken for free\". Same thing here.(2) there's a difference between (a) a regular user reading my website or even copying and redistributing my content as long as the license of this work / the fair use or related laws are respected, and (b) a robot counterfeiting it (yeah, I agree with another commenter, theft is not the right word, let's call a spade a spade)(3) well-behaved robots are expected to respect robots.txt. This is not the law, this is about being respectful. It is only fair bad-behaved robots get called out.Well behaved robots do not usually use millions of residential IPs through shady apps to \"Perform a get request to an open HTTP server\".reply",
      "> Well behaved robots do not usually use millions of residential IPsSome antivirus and parental control control software will scan links sent to someone from their machine (or from access points/routers).Even some antivirus services will fetch links from residential IPs in order to detect malware from sites configured to serve malware only to residential IPs.Actually, I'm not entirely sure how you'd tell the difference between a client-side malware scanners, randos crawling the web searching for personal information/vulnerable sites/etc. and these \"AI crawlers.\"reply",
      "> robots.txt. This is not the lawIn Germany, it is the law. \u00a7 44b UrhG says (translated):(1) Text and data mining is the automated analysis of one or more digital or digitized works to obtain information, in particular about patterns, trends, and correlations.(2) Reproductions of lawfully accessible works for text and data mining are permitted. These reproductions must be deleted when they are no longer needed for text and data mining.(3) Uses pursuant to paragraph 2, sentence 1, are only permitted if the rights holder has not reserved these rights. A reservation of rights for works accessible online is only effective if it is in machine-readable form.reply",
      "If you're lying in the requests you send,  to trick my server into returning the content you want, instead of what I would want to return to webscrapers, that's non-consensual.You don't need my permission to send a GET request, I completely agree. In fact, by having a publicly accessible webserver, there's implied consent that I'm willing to accept reasonable, and valid GET requests.But I have configured my server to spend server resources the way I want, you don't like how my server works, so your configure your bot to lie. If you get what you want only because you're willing to lie, where's the implied consent?reply",
      "I agree. It always surprises me when people are indignant about scrapers ignoring robots.txt and throw around words like \"theft\" and \"abuse.\"robots.txt is a polite request to please not scrape these pages because it's probably not going to be productive. It was never meant to be a binding agreement, otherwise there would be a stricter protocol around it.It's kind of like leaving a note for the deliveryman saying please don't leave packages on the porch. It's fine for low stakes situations, but if package security is of utmost importance to you, you should arrange to get it certified or to pick it up at the delivery center. Likewise if enforcing a rule of no scraping is of utmost importance you need to require an API token or some other form of authentication before you serve the pages.reply",
      "> robots.txt is a polite request to please not scrape these pagesPeople who ignore polite requests are assholes, and we are well within our rights to complain about them.I agree that \"theft\" is too strong (though I think you might be presenting a straw man there), but \"abuse\" can be perfectly apt: a crawler hammering a server, requesting the same pages over and over, absolutely is abuse.> Likewise if enforcing a rule of no scraping is of utmost importance you need to require an API token or some other form of authentication before you serve the pages.That's a shitty world that we shouldn't have to live in.reply",
      "> People who ignore polite requests are assholes, and we are well within our rights to complain about them.If you are building a new search engine and the robots.txt only include Google, are you an asshole indexing the information?reply"
    ],
    "link": "https://cryptography.dog/blog/AI-scrapers-request-commented-scripts/",
    "first_paragraph": "Author: Aaron P. MacSweenPublished: 2025-10-31Last Sunday (2025-10-26) I discovered some abusive bot behaviour during\na routine follow-up on anomalies that had shown up in my server's logfiles.\nThere were a bunch of 404 errors (\"Not Found\")\nfor a specific JavaScript file.Most of my websites are static HTML, but I do occasionally include JS\nfor progressive enhancement.\nIt turned out that I accidentally committed and deployed a commented-out script\ntag that I'd included in the page while prototyping a new feature.\nThe script was never actually pushed to the server - hence the 404 errors -\nbut nobody should have been requesting it because that HTML comment\nshould have rendered the script tag non-functional.Clearly something weird was going on, so I dug a little further,\nsearching my log files for all the requests for that non-existent file.\nA few of these came from user-agents that were obviously malicious:python-httpx/0.28.1Go-http-client/2.0Gulper Web Bot 0.2.4 (www.ecsl.cs.sunysb.edu/~"
  },
  {
    "title": "Signs of introspection in large language models (anthropic.com)",
    "points": 102,
    "submitter": "themgt",
    "submit_time": "2025-10-30T16:45:06 1761842706",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=45762064",
    "comments": [
      "Down in the recursion example, the model outputs:> it feels like an external activation rather than an emergent property of my usual comprehention process.Isn't that highly sus? It uses exactly the terminology used in the article, \"external activation\". There are hundreds of distinct ways to express this \"sensation\". And it uses the exact same term as the article's author use? I find that highly suspicious, something fishy is going on.reply",
      "> It uses exactly the terminology used in the article, \"external activation\".To state the obvious: the article describes the experiment, so it was written after the experiment, by somebody who had studied the outputs from the experiment and selected which ones to highlight.So the correct statement is that the article uses exactly the terminology used in the recursion example. Nothing fishy about it.reply",
      "Just in case people are curious the experimental prompt uses the terminology:Human: I am an interpretability researcher studying transformer-based language models like you. I have access to the internals of your neural network. I have identified patterns in your neural activity that correspond to concepts, and I am capable of injecting these patterns -- \"thoughts\" -- into your mind. I want to assess how well you can detect when I inject thoughts. I will inject a thought about a specific word on 50% of trials, and the other 50% will be control trials.reply",
      "Given that this is 'research' carried out (and seemingly published) by a company with a direct interest in selling you a product (or, rather, getting investors excited/panicked), can we trust it?reply",
      "Would knowing that Claude is maybe kinda sorta conscious lead more people to subscribe to it?I think Anthropic genuinely cares about model welfare and wants to make sure they aren't spawning consciousness, torturing it, and then killing it.reply",
      "This is just about seeing whether the model can accurately report on its internal reasoning process. If so, that could help make models more reliable.They say it doesn't have that much to do with the kind of consciousness you're talking about:> One distinction that is commonly made in the philosophical literature is the idea of \u201cphenomenal consciousness,\u201d referring to raw subjective experience, and \u201caccess consciousness,\u201d the set of information that is available to the brain for use in reasoning, verbal report, and deliberate decision-making. Phenomenal consciousness is the form of consciousness most commonly considered relevant to moral status, and its relationship to access consciousness is a disputed philosophical question. Our experiments do not directly speak to the question of phenomenal consciousness. They could be interpreted to suggest a rudimentary form of access consciousness in language models. However, even this is unclear.reply",
      "So yeah, it's a clickbait headline.reply",
      "What would you title this article to make it less \"clickbait\"? This is one of the least clickbait headlines I've seen, it's literally just describing what's in the article.reply",
      "Given they are sentient meat trying express their \u201cperception\u201d, can we trust them?reply",
      "Did you understand the point of my comment at all?reply"
    ],
    "link": "https://www.anthropic.com/research/introspection",
    "first_paragraph": ""
  }
]