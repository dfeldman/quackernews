[
  {
    "title": "Make Ubuntu packages 90% faster by rebuilding them (gist.github.com)",
    "points": 76,
    "submitter": "jeffbee",
    "submit_time": "2025-03-18T23:55:17 1742342117",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=43406710",
    "comments": [
      "Note that if you do this then you will opt out of any security updates not just for jq but also for its regular expression parsing dependency onigurama. For example, there was a security update for onigurama previously; if this sort of thing happens again, you'd be vulnerable, and jq is often used to parse untrusted JSON.>  * SECURITY UPDATE: Fix multiple invalid pointer dereference, out-of-bounds write memory corruption and stack buffer overflow.(that one was for CVE-2017-9224, CVE-2017-9226, CVE-2017-9227, CVE-2017-9228 and CVE-2017-9229)\n \nreply",
      "Gentoo linux is essentially made specifically for people like this, to be able to optimize one\u2019s own linux rig for one\u2019s specific usecase.After initial setup, it\u2019s pretty simple and easy to use, I remember making a ton of friends at matrix\u2019s Gentoo Linux channel, was fun times.https://www.gentoo.org/Fun fact, initial ChromeOS was basically just custom Gentoo Linux install, I\u2019m not sure if they still use Gentoo Linux internally.\n \nreply",
      "Afaik the Gentoo based ChromeOS is being replaced by Android.\n \nreply",
      "So ChromeOS and also the OS for GKE are still basically built this way.\n \nreply",
      "(Well, rebuilding them with a different allocator that benchmarks well on their specific workflow.)\n \nreply",
      "Is it even known what workloads the glibc malloc is good for?\n \nreply",
      "Using all your memory on multi-threaded workflows.\n \nreply",
      "I\u2019m almost more amazed that someone figured out jq\u2019s syntax and got some use out of it.In all seriousness though, are you sure some of this isn\u2019t those blocks being loaded into some kind of file system cache the second and third times?How about if you rebooted and then ran the mimalloc version?\n \nreply",
      "The benchmarking tool being used in this post accounts for that using multiple runs for each invocation, together with a warmup run that is not included in the result metric.\n \nreply",
      "Ah missed that, sorry.\n \nreply"
    ],
    "link": "https://gist.github.com/jwbee/7e8b27e298de8bbbf8abfa4c232db097",
    "first_paragraph": "\n        Instantly share code, notes, and snippets.\n      You can take the same source code package that Ubuntu uses to build jq, compile it again, and realize 90% better performance.I use jq for processing GeoJSON files and other open data offered in JSON format. Today I am working with a 500MB GeoJSON file that contains the Alameda County Assessor's parcel map. I want to run a query that prints the city for every parcel worth more than a threshold amount. The program is.features[] | select(.properties.TotalNetValue < 193000) | .properties.SitusCityThis takes about 5 seconds with the file cached, on a Ryzen 9 9950X system. That seems a bit shabby and I am sure we can do better.What happens if you grab the jq source code from Launchpad, then configure and rebuild it with no flags at all? Even that is about 2-4% faster than the Ubuntu binary package.We are using hyperfine to get repeatable results. The jq program is being constrained on logical CPU 2, to keep it away from system interru"
  },
  {
    "title": "Two new PebbleOS watches (ericmigi.com)",
    "points": 1013,
    "submitter": "griffinli",
    "submit_time": "2025-03-18T15:59:27 1742313567",
    "num_comments": 353,
    "comments_url": "https://news.ycombinator.com/item?id=43400989",
    "comments": [
      "Eric, thank you. Lurking in the forum answering questions evokes people to share their opinion for satisfaction and dissatisfaction and often neglectes to evoke praise (proportionally). I am guilty of this too.So please have some well deserved praise for your work on this. We have gotten an open source wearable OS, purpose built hardware, R&D, a community, more pressure on Apple to be less of a gatekeeper, and something we can own in a crazy short timeframe. I hope you see this despite it being buried. Thank you, you glorious nerd.\n \nreply",
      "Can you go running with your watch and earphones and listen to music without a phone?\n \nreply",
      "> \"30 day battery life\"I've done the math and according to my calculations that's approximately 30X more battery life than an Apple Watch. Impressive!\n \nreply",
      "About 60 for me. I have to charge mine while working to get it to last a day :/\n \nreply",
      "You may have an app draining your battery. Was having the same issue with my watch, I deleted a few apps and all of the sudden my watch was better. I can\u2019t tell you what app was  because it was just luck. I was creating space on my phone when it happened.\n \nreply",
      "I have had an Apple Watch since the original and never had it that bad. I think something is wrong with your watch.\n \nreply",
      "That's common for me after three or four years.\n \nreply",
      "I charged my S6 last night - it\u2019s been running 22 hours - and it has 17% charge left. That\u2019s at about 4.5 years old.I don\u2019t run it at high screen brightness though.\n \nreply",
      "I'm pleased the pricing is so low. I did some math and if they're making 10k of these (not clear if that's each or all together), there's not a ton of money to be made.Assuming $100 average profit, that's a $2M for 20k watches. Given the work opportunities that the founder and other employees have, that's not a lot of money  for them to make in a year, and it comes with significant risk. Basically seems like this is a passion project, for which I am very grateful!\n \nreply",
      "$100 profit on a $150 watch would be crazy.  Rest of the post seems made up too.    I don't know where these numbers are coming from.  I'm genuinely confused.\n \nreply"
    ],
    "link": "https://ericmigi.com/blog/introducing-two-new-pebbleos-watches/",
    "first_paragraph": ""
  },
  {
    "title": "Apple restricts Pebble from being awesome with iPhones (ericmigi.com)",
    "points": 1128,
    "submitter": "griffinli",
    "submit_time": "2025-03-18T16:23:21 1742315001",
    "num_comments": 730,
    "comments_url": "https://news.ycombinator.com/item?id=43401245",
    "comments": [
      "I guess I\u2019ll take the contra here on messages integration \u2014 moving a message over BLE to untrusted hardware and worse accepting them back into iMessage is a massive, massive change in the security boundary and therefore security architecture and therefore security promises that apple makes on iMessage.I do not believe average smartwatch users understand what they\u2019d be doing if they got this. I do not believe vendors integrating with such a thing can do it safely, or even that all vendors integrating are good actors.One reason iMessage is less of a total cesspit than SMS is that the ecosystem is closed, and makes automation difficult. It used to be impossible nearly, and in that era we had almost no iMessage spam. Now it\u2019s difficult, and we have moderate iMessage spam. But adding hooks to make this automation easy, and worse, leave the trust environment as a feature is just wrong.\n \nreply",
      "This is cap. I worked on heads up glasses, and one of our issues was the lack of integration with Apple's iMessage ecosystem. Device makers are willing to go through several security measures, like deploying the MFi chips and certification. However, at best this gives you access to the notification system, not iMessage itself. You are able to respond to messages via the notification framework, but not integrate directly with iMessage even after taking all security and certification efforts. This isn't a security play. This is a walled garden play.\n \nreply",
      "As a user, I am totally fine with Apple restricting access to iMessage.  In fact, now that I read this, I want them to do this, thanks Apple.\n \nreply",
      "You can thank Apple for the Lightning connector and App Store too, for all the good it does everyone in the EU. If a company uses their power to prevent competition with their own products or services, the market's jurisdiction reserves the right to restore competition to their market and prevent the harms inherent to monopoly abuse.\n \nreply",
      "I probably dont get your sarcasm.  But I never had a problem with Lightning.  In the long run, I like the switch to USB-C... But when I got my first iPhone, USB-C wasn't invented yet, so...  Also, I like the AppStore for its reviews, and would actually NEVER activate an alternative appstore.  No need to weaken my security on purpose.  I know, its apparently an unpopular opinion here, but that is mostly because many people only comment with their dev hats on and are apparently unable to see things from user perspectives...\n \nreply",
      "To add: when apple switched to lightning they made a deal with hardware makers that they would support this for 10 years in order not to make all their hardware obsolete again.\nThey did eventually change it after exactly 10 years.\n \nreply",
      "Not because their software would inherently break by switching to a different USB connector, or even by using a converter dongle. Apple signed this agreement because Lightning had a hardcoded DRM protocol baked into it to force third-parties to pay licensing fees. Of course they demanded a 10 year support window, it was a licensing ruse to make manufacturers pay a price premium to use the USB featureset.https://en.wikipedia.org/wiki/MFi_Program\n \nreply",
      "Not everything has to be a \u2018i win, you lose\u2019. It can be a strategy and architecture where multiple parties get something out of it. In different ways.\n \nreply",
      "The 3rd parties are not getting anything out of it. You literally pay for access to a tech stack that has nothing better than you would be able to do with USB.\nI mean the other side of connection was USB so it was a necessity anyway.\nIf at least they upgraded the speed over the years, but nope stuck at USB 2.For a hardware project I looked briefly at the MFi terms and they just don't make any sense. This is why any good lightning cable was always more expensive (at least before you get some from China with contraband auth chips)Lightning is a major cash crab from Apple and revealed their actual playbook. Microsoft passed as a very bad players in the 90's but Apple is even worse.\nThe only people not accepting that are deranged fans.\n \nreply",
      "You could turn lightning connectors upside down and plug them in before you could do that with USB"
    ],
    "link": "https://ericmigi.com/blog/apple-restricts-pebble-from-being-awesome-with-iphones/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I made a tool to port tweets to Bluesky mantaining their original date (bluemigrate.com)",
    "points": 269,
    "submitter": "nols05",
    "submit_time": "2025-03-18T17:07:39 1742317659",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=43401855",
    "comments": [
      "Interesting tool, but I'm very surprised that they allow backdating posts.Backdating posts opens up a world of social engineering scams. You can create an account that appears to have predicted a lot of past events, sports scores, or stock prices with timestamps prior to those events occurring. The scam is to create an account that appears to have great stock advice or sports betting predictions and then charge people for it.\n \nreply",
      "I believe this is possible because of how the AT Protocol works. Bluesky shows a warning[1] on these posts and displays both times, but sorts them by the backdated time.[1]: https://bsky.app/profile/bluemigrate.com/post/3lc3r4fqen62l\n \nreply",
      "I think the reason it works that way is because they want strong guarantees for the future portability of your skeets. It's sort of a correction for Mastodon's reliance on server admins' goodwill.\n \nreply",
      ">skeetsI\u2019m cackling over here. How have I never heard this when people talk about blue sky?\n \nreply",
      "To the windoooooooooooooooooooow....\n \nreply",
      "nope. post here from 9/11 2001, no warning [0]. it's fine if they added a check recently to flag backdated posts, but there's no telling how many incorrectly-timed things went up before they added that ([0] is from about a year ago, fwiw). the whole early history of the platform is questionable, and it's just shoddy protocol design.[0] https://bsky.app/profile/lul4.bsky.social/post/3kgaesbxs7f25(if you work for bsky please don't add a flag to that, it's my favorite party trick)\n \nreply",
      "Looking at the JSON data in dev tools, it looks like there are separate `createdAt` and `indexedAt` fields, the latter of which was probably a later addition. For your\u2014likely pre-migration\u2014post, both are set to 9/11. On more recent posts, they're separate dates.\n \nreply",
      "That post does indeed predate bluesky tracking index times, I remember seeing it before they announced that change. I believe it was motivated by other migration services becoming popular. Forward-dating was fixed even earlier, I think, since it might allow people to \"pin\" their posts to the top of reverse-chronological feeds.Some of my favourite backdated posts are from the years 1776 and 1.\n \nreply",
      "More specifically the reason we didn\u2019t have an index time for that post was an architectural migration which lost our prior witness times. That was pretty early on. At this point we\u2019d take pains to preserve those timestamps, and I\u2019m fairly sure we will need to publish them for other folks to use at some point\n \nreply",
      "It'd be cool if they also verified the dates to get rid of the warning of honest backdated posts.\n \nreply"
    ],
    "link": "https://bluemigrate.com",
    "first_paragraph": ""
  },
  {
    "title": "SheepShaver is an open source PowerPC Apple Macintosh emulator (emaculation.com)",
    "points": 29,
    "submitter": "janandonly",
    "submit_time": "2025-03-16T10:32:02 1742121122",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43377998",
    "comments": [
      "I first saw SheepShaver at MacWorld Expo in San Francisco, a commercial product that enabled a Classic Mac environment on PowerPC-based BeOS hardware, the original BeBox.These days, if you are just curious or want to relive to glory days of Apple's rise and near-death of 1990s, it might be easier to run a hosted environment such as Infinite Mac.https://infinitemac.org/\n \nreply",
      "macintosh.js is an alternative that runs as an Electron app https://github.com/felixrieseberg/macintosh.js\n \nreply",
      "It's an Emscripten-compiled version of Basilisk II [1], which is closely related to SheepShaver. (The two emulators target different generations of Apple hardware - Basilisk does 68k CPUs, SheepShaver does PowerPC.)[1]: https://basilisk.cebix.net/\n \nreply",
      "If you need support for later versions of OS9, qemu at least works on 9.2 in my testing.And unlike SheepShaver, Netscape/IE seems to work fine in qemu for me.\n \nreply",
      "Might also be able to use the \"classic environment\" from older mac os versions (in an emulator)\n \nreply",
      "Time to fire up Tomb of the Taskmaker\n \nreply",
      "Here I thought it was a shearer emulator for aspiring farmers!\n \nreply"
    ],
    "link": "https://www.emaculation.com/doku.php/sheepshaver",
    "first_paragraph": "\n(page updated October 9, 2020)\n\nSheepShaver is an open source PowerPC Apple Macintosh emulator.  Using SheepShaver (along with the appropriate ROM image) it is possible to emulate a PowerPC Macintosh computer capable of running Mac OS 7.5.2 through 9.0.4.  Builds of SheepShaver are available for Mac OS X, Windows and Linux.\n\nSheepShaver is considered a good replacement for the Classic Environment which is not available in the most recent versions of Mac OS X. \n\nSetup guides for the Windows, Mac OS X and Linux builds of SheepShaver are available.\n\nWe also host a busy SheepShaver support forum.\n\nPlease note that SheepShaver requires users to supply a ROM image and a copy of Mac OS.\n\nSheepShaver began life in 1998 as a MacOS emulator for BeOS.  At that time, SheepShaver was a commercial product developed by Christian Bauer.  In 2002, following the commercial decline of Be, SheepShaver  was released as an open-source application.  Development at that time was driven by Gwenole Beauchesne,"
  },
  {
    "title": "Artificial Intelligence: Foundations of Computational Agents (artint.info)",
    "points": 18,
    "submitter": "rramadass",
    "submit_time": "2025-03-16T11:36:23 1742124983",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://artint.info/index.html",
    "first_paragraph": "David L. Poole & Alan K. Mackworthfoundations of computational agents\nArtificial Intelligence: Foundations of\n\t\t  Computational Agents, 3rd edition by\n\tDavid L. Poole and \n  \t\t\tAlan K. Mackworth,\t  Cambridge University Press\n\t\t\t2023, is a book about the\nscience of artificial intelligence (AI). It presents artificial\nintelligence as the study of\nthe design of intelligent computational agents. The book is structured\nas a textbook, but it is accessible to a wide audience of\nprofessionals and researchers.\nIn the last decades we have witnessed the emergence of artificial\nintelligence as a serious science and engineering discipline. This\nbook provides an accessible synthesis of the field aimed at undergraduate and\ngraduate students.\nIt provides a coherent vision of the foundations of the field as it is today. It\naims to provide that synthesis as an integrated science, in terms of a\nmulti-dimensional\ndesign space that has been partially explored. As with any science\nworth its salt,\nartificial"
  },
  {
    "title": "Karatsuba Matrix Multiplication and Its Efficient Hardware Implementations (arxiv.org)",
    "points": 65,
    "submitter": "emacs28",
    "submit_time": "2025-03-15T12:55:10 1742043310",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43372227",
    "comments": [
      "Would this work have the potential to speed up encoding/decoding of the PAR2 format[0]? This format is widely used to protect datasets against bitrot and small losses, but is held back because of the significant compute overhead when dealing with large datasets.[0] https://en.wikipedia.org/wiki/Parchive\n \nreply",
      "the govy uses specialized hardware that isn't sold on the market right? would something like this be useful in developing said hardware>?\n \nreply",
      "They're proposing \"new hardware architectures\" to take advantage of this idea.  Anybody with a background in GPU floating point math comment on how realistic this is?\n \nreply",
      "First author here. The hardware architectures are realistic - we developed & evaluated real example hardware implementations for them, validated on FPGA, and they achieved state-of-the-art ResNet performance in a deep learning accelerator system implementation compared to prior accelerators evaluated on similar FPGAs. See the associated accelerator system source code here:https://github.com/trevorpogue/algebraic-nnhwThe hardware architectures focused on in the paper are systolic array designs, an efficient type of hardware design for matrix multiplication (e.g., the Google TPU uses this), as opposed to more SIMD-like vector architectures like GPUs. It may be possible to extend the proposed KMM algorithm to other types of hardware architectures also in future work. Regarding floating point - this work is applicable for integer matrix multiplication acceleration, it may be possible to extend the concept to floating point data types in future work also.\n \nreply",
      "The paper is about integer multiplication, not float\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2501.08889",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "HTTrack Website Copier (httrack.com)",
    "points": 124,
    "submitter": "yamrzou",
    "submit_time": "2025-03-18T17:30:13 1742319013",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=43402149",
    "comments": [
      "I\u2019ve used it a few times to \u201csecure\u201d an old but relevant dynamic website site.  Like a site for a mature project that shouldn\u2019t disappear from the internet but it\u2019s not worth upgrading 5 year old code that wont pass our \u201ccyber security audit\u201d due to unsupported versions of php or rails so we just convert to a static site and delete the database.  Everything pretty much works fine on the front end, and the CMS functionality is no longer needed.  It\u2019s great for that niche use case.\n \nreply",
      "You could also do that with plain wget.\n \nreply",
      "Not sure about the context on why this is on HN but it surely put a smile on my face. Used to use it during 56K era when I just download everything and read it. Basically using it as RSS before RSS was a thing.\n \nreply",
      "Interestingly, the most recent commit and release in their github is from March 11 2025, so it's still clearly maintained.I remember using it, it must have been in 2012 or 2013, to automatically make static sites out of Wordpress. We had a bank department as a client who had a non negotiable requirement that they could use Wordpress to manage their site, along with an IT policy that absolutely forbade using Wordress (or PHP or MySQL or even Linux) on public facing servers. So we had an intranet only Wordpress site that got scraped 6 times a day and published as static html to an IT approved public Windows webserver.\n \nreply",
      "Used Teleport Pro myself back then.\n \nreply",
      "O wow, I have forgotten all about it, but I used it too! That and pavuk with it's regular expressions on the commandline.\nhttps://tenmax.wordpress.com/\n \nreply",
      "Yeah that memory.\n \nreply",
      "I've been using HTTrack for almost two decades to create static archives of a yearly website for an annual event.It doesn't do the job 100% but it's a start. In particular, HTTrack does not support srcset, so only the default (1x) pixel-density images were archived (though I manually edited the archives to inject the high pixel-density images, as well as numerous other necessary fix-ups).The benefit of the tool is fine control over the crawling process as well as which files are included. Included files have their URLs rewritten in the archived HTML (and CSS) to account for querystrings, absolute vs. relative URLs, external paths, etc.; non-included files also have their URLs rewritten to change relative to absolute links; thus, you can browse the static archive, and non-included assets still function if they are online at their original URL, even if the static archive is on local storage or hosted at a different domain than the original site.It was more work each year as the website gradually used script in more places, leading to more and more places I would need to manually touch-up the archive to make it browsable. The website was not itself an SPA, but contained SPAs on certain pages; my goal was to capture the snapshot of the initial HTML paint of these SPAs but not to have them functional beyond that. This was (expectedly) beyond HTTrack's capabilities.At least one other team member wanted to investigate https://github.com/Y2Z/monolith as a potential modern alternative.\n \nreply",
      "I used this all the time twenty years ago. Tried it out again for some reason recently, I think at the suggestion of ChatGPT (!), for some archiving, and it actually did some damage.I do wish there was a modern version of this that could embed the videos in some of my old blog posts so I could save them entire locally as something other than an HTML mystery blob. None of the archive sites preserve video, and neither do extensions like SingleFile. If you're lucky, they'll embed a link to the original file, but that won't help later when the original posts go offline.\n \nreply",
      "ArchiveBox is your friend. (When it doesn't hate you :)It's pretty good at archiving most web pages - it relies on SingleFile and other tools to get the job done. Depends on how you saved the video, but in general it works decently well.\n \nreply"
    ],
    "link": "https://www.httrack.com/",
    "first_paragraph": "\nInstalling HTTrack:\nGo to the download section now!\n\nFor help and questions:\nVisit the forum, \nRead the documentation, \nRead the FAQs,\nBrowse the sources\n\nHTTrack is a free (GPL, libre/free software) and easy-to-use offline browser utility.\nIt allows you to download a World \nWide Web site from the Internet to a local directory, building recursively all directories, getting HTML, \nimages, and other files from the server to your computer. HTTrack arranges the original site's relative \nlink-structure. Simply open a page of the \"mirrored\" website in your browser, and you can browse the site \nfrom link to link, as if you were viewing it online. HTTrack can also update an existing mirrored site, \nand resume interrupted downloads. HTTrack is fully configurable, and has an integrated help system.\n\nWinHTTrack is the Windows (from Windows 2000 to Windows 10 and above) release of HTTrack, and WebHTTrack the Linux/Unix/BSD release. See the download page.\n"
  },
  {
    "title": "Designing Electronics That Work (hscott.net)",
    "points": 142,
    "submitter": "teleforce",
    "submit_time": "2025-03-18T16:18:08 1742314688",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=43401179",
    "comments": [
      "I've begun playing around with \"hardware design\" recently and it's very humbling. I've been developing software for a long time, and I have a good amount of experience designing and making physical objects, both manually (well, with tools, but manually guided/used) and via digital means (mostly FDM).Making even a simple electronic device is a journey to say the least. The intersection of code and mechanism is a fascinating area to play in, but from PoC to Product, the amount of effort, expertise and iteration is hard to imagine until you try.Thanks for sharing your experience, looking forward to leafing through the pdf for some valuable insights.\n \nreply",
      "Many many years ago I got to hear the founders of Fitbit come in and give a lunchtime chat about their journey. It was utterly fascinating to hear all the challenges, as a software engineer, you never even think to consider. Things like their attempts to optimise the layout of components effectively doubled the production cost because it would require someone to flip the PCB. Or that the adhesive used to temporarily keep the case attached to a tiny spindle during assembly was slightly too tacky, the residue of which would many months later cause stress fractures on the case and a whole raft of warranty replacements.Hardware is hard.\n \nreply",
      "I had the same experience. Eventually I think the next time I'm going to try something extremely simple, like a button that triggers some pre-recorded noise.\n \nreply",
      "If you want your electronics to work:1. Read the datasheets for everything and follow all restrictions, like on safe operating area (SOA), in regard to current and ambient temperature and so on. Use appropriate heat sinks.2. Unless you have good reasons or confidence coming from somewhere, do not stray far from the example circuits in the datasheet. If they call for certain decoupling capacitors, have those. If something has a minimum and/or maximum load impedance, be in that limit (same as point 1).3. Do not design anything to depend on the performance of an individual part, in regard to some performance parameter that has lots of variance in mass production of those parts. This is particularly a problem for analog components; e.g. current gain of bipolar transistors and such.  In simulation, play with variances in part values to see how sensitive it is; you can choose tolerances accordingly. Maybe some resistors need only 5%.4. Good PCB layout and so on. Careful breadboard work. Proper soldering practices. Solid power supply circuits operating well within their capacity range. Proper grounding. Safety devices: fuses, diodes, etc.\n \nreply",
      "This is an interesting book. I've been in this space for years now and could easily see myself writing something like this, but I don't think it would look like this book.I really don't like to see things like any sort of recommendation for use of n-propyl bromide. That shit's neurotoxic. The people who can use it safely will already know about it, know someone who knows about it, or find it on their own. Anyone who finds out about nPB here should not be touching it.Unfortunately, many of the parts of the book that I've scanned are like that. There's a lot of prescription, not a lot of background/theory/underlying details, and no way to tell when the prescriptions are inapplicable or straight-up wrong. Which, often, they are: one of the hallmarks of deep experience is knowing when \"the rules\" are useful and when they're not, but what we have here is mostly rules. That will get your product out the door, I guess, but it's not going to level you up as an engineer, if that's what you're needing. Another example: stackups are discussed, but there's no mention of slash sheets, which is how you get things done cheaply and correctly. Specifying Rogers material for anything but the nastiest designs is just going to get your pockets drained and your Asian fab annoyed because they have to special order that. If you need it, sure, you need it... but can you get away with something more universal?And then there's things like this: \"Most SMPS datasheets will advise you on what\nbead to use and where to put it\". Hahahaha no they won't. And if they will, there's a decent chance they get it wrong. Ferrite beads are so useful and so much trouble that you can't trust an IC datasheet to get it right, even if they want to do the same things you want to do. Which they might not!If you're a more junior engineer trying to level up, give this one a look instead: Analog SEEKrets: https://www.eevblog.com/files/seekPDF.pdf\n \nreply",
      "I wonder if on the first page it says:Hardware is a money pit so be sure to be motivated by passion more than profit.I'm kidding, but only sort of.\n \nreply",
      "I own a hard copy of the book.  It's very valuable as a survey to speed run getting over \"Peak of Mt Stupid\", crossing \"Valley of Despair\", and beginning the climb of the \"Slope of Enlightenment\".\n \nreply",
      "I would really like to purchase a hard copy. The hero picture of the book is enticing. Looks like it's not available right now sadly.\n \nreply",
      "Nice work Hunter! I\u2019m starting a hardware side project so I\u2019ll definitely be giving the book a read. Hopefully it helps me avoid some of the common electronic pitfalls.\n \nreply",
      "You knocked it out of the park with the cover! I'll definitely be grabbing a physical copy because of that.\n \nreply"
    ],
    "link": "https://www.hscott.net/designing-electronics-that-work/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: \"Git who\" \u00e2\u20ac\u201c A new CLI tool for industrial-scale Git blaming (github.com/sinclairtarget)",
    "points": 90,
    "submitter": "weebst",
    "submit_time": "2025-03-18T20:20:09 1742329209",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=43404548",
    "comments": [
      "By the way, git blaming is really misunderstood by a lot of people; its NOT about who did it, its about which commit is to blame -- that's different.\n \nreply",
      "I'm pretty sure it's about who wrote the code.'git blame' is named after the subversion and CVS blame features that do the same thing. Subversion docs are clear that it's a snarky name and that 'svn praise' and 'svn annotate' are neutral synonyms.Perhaps someone familiar with CVS can comment on its history there since it seems to be the first source control to add it.EDIT: and one of the main reasons it's a useful feature is it tells you who to talk to to understand a piece of code, or to coordinate a roll back, or to do any other sort of communication. It probably matters more in a big company where code is changing frequently and you're unlikely to know everyone and what they're working on.\n \nreply",
      "> Subversion docs are clear that it's a snarky name and that 'svn praise' and 'svn annotate' are neutral synonyms.A few years ago, some Atlassian developer changed \"Blame\" in the BitBucket UI to \"Annotate\". I remember a lot of people being frustrated because they couldn't find \"blame\" anywhere and the change was never officially announced. It just happened one daySomeone opened a ticket with BitBucket about it which ended up drawing a lot of attention from frustrated users who couldn't find \"blame\", and their searches for it on Google led people to the ticket. Atlassian eventually responded saying that they made the change because \"blame\" sounds bad and can hurt people's feelings somehow (with no examples given of course, though ironically the dev who made the change certainly had hurt feelings after the upset masses had some choice words for the short-sighted decision. Though Atlassian doubled down and I believe closed the ticket without reverting the change, so the confusion remains, as far as I know)I don't think that they ever mentioned the Subversion/CVS parallel that was drawn to choose that name, so it was really confusing why that was selected. But this comment shed some light on that ancient incident\n \nreply",
      "> ironically the dev who made the change certainly had hurt feelings after the upset masses had some choice words for the short-sighted decision.Dev probably became the public face for a decision made by someone else (eg. Product owner, TL, whatever the business structure is in Atlassian)\n \nreply",
      "> EDIT: and one of the main reasons it's a useful feature is it tells you who to talk to to understand a piece of code, or to coordinate a roll back, or to do any other sort of communication. It probably matters more in a big company where code is changing frequently and you're unlikely to know everyone and what they're working on.It's actually a pretty awful feature because it misses so much context. I've been blamed before for changes which were technically my fault, but while my code was to spec, some unrelated part of the code I was interacting with was not (iirc it was some multi-threaded nonsense like a race condition or something).It was a super-stressful week of constantly having to defend my design decisions and white-boarding my thought process (think of the \"am I taking crazy pills?!?\" scene in Zoolander) as my senior coworker tried to gaslight and throw me under the bus.Maybe I've had a uniquely bad experience with it, but I've vowed to never use it (as a way to attribute `blame`). Code should be holistically understood and it's your job as a technical leader to know how the parts move, resolve issues without drama, and make sure your whole team is on the same page: this is a cohesive team, not an adversarial dick-measuring contest.\n \nreply",
      "That sounds like an awful workplace culture. I doubt the name of the git command is responsible, though.\n \nreply",
      "Isn't this sort of an inconsequential point? The commit still has one and only one author and that's almost certainly what I'm looking for so I know who to go ask questions about their code. I also use it to find the commit but less frequently.\n \nreply",
      "No, commits can be co-authored.And the committer and author don\u2019t even need to be the same!But the point, as I read it, is: what matters is the context, i.e. if a line is faulty, how did things look like when it wasn\u2019t faulty? The commit\u2019s content is more often more important than the committer, although the committer is useful because you can ask them if they\u2019re still around.\n \nreply",
      "On a small team I usually already know who wrote the code I'm reading, but it's nice to see if a block of code is all from the same point in time, or if some of the lines are the result of later bugfixing. It's also useful to find the associated pull request for a block of code, to see what issues were considered in code review, to know whether something that seems odd was discussed or glossed over when the code was merged in the first place.\n \nreply",
      "I find the GitHub blame view indispensable for this kind of code archeology, as they also give you an easy way to traverse the history of lines of code. In blame, you can go back to the previous revision that changed the line and see the blame for that, and on and on.I really want to find or build a tool that can automatically traverse history this way, like git-evolve-log.\n \nreply"
    ],
    "link": "https://github.com/sinclairtarget/git-who",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Git blame for file trees\n      git-who is a command-line tool for answering that eternal question:Who wrote this code?!Unlike git blame, which can tell you who wrote a line of code, git-who\ntells you the people responsible for entire components or subsystems in a\ncodebase. You can think of git-who sort of like git blame but for file\ntrees rather than individual files.This README contains comprehensive documentation. For an overview, see Who\nWill Maintain Vim? A Demo of Git\nWho.See releases.Building from source requires that you have Go, Ruby, and the rake Ruby gem\ninstalled. Note that these are only required when building from source; you\ncan download and run one of the binary releases without installing any of these\ntools.(In the following examples, git-who is invoked as git who. This will work\nautomatically as long as Git can find"
  },
  {
    "title": "Google to buy Wiz for $32B (reuters.com)",
    "points": 387,
    "submitter": "uncertainrhymes",
    "submit_time": "2025-03-18T12:18:29 1742300309",
    "num_comments": 592,
    "comments_url": "https://news.ycombinator.com/item?id=43398518",
    "comments": [
      "> Wiz has raised a total of $1.9 billion from a combination of venture capital funds and private investors> Wiz agreed to acquire Tel Aviv-based Raftt, a cloud-based developer collaboration platform, for $50 million in December 2023. In April 2024, the company acquired cloud detection and response startup, Gem Security, for around $350 million> Wiz was founded in January 2020 by Assaf Rappaport, Yinon Costica, Roy Reznik, and Ami Luttwak, all of whom previously founded Adallom.> Adallom was founded in 2012 by Assaf Rappaport, Ami Luttwak and Roy Reznik, who are former members of the Israeli Intelligence Corps\u2019 Unit 8200 and alumni of the Talpiot program.> Adallom was reportedly acquired by Microsoft for $320 million in July 2015> On March 18, 2025, Google announced an all-cash acquisition of Wiz for $32 billionHad never heard of Wiz until they posted the blog post about the DeepSeek database being public earlier this year.https://www.wiz.io/blog/wiz-research-uncovers-exposed-deepse...\n \nreply",
      "I never heard of them until they were purchased for $32 billion.\n \nreply",
      "Thats the kind of a company everyone wants to build in enterprise security.Incognito unicorns.There are many companies like these in security space. Another company I can think of is Rubrik. All these large security companies under the radar success.\n \nreply",
      "most people here are also in security and still haven't heard.It's more likely backroom kickbacks (and/or mossad) than invisible unicorn.\n \nreply",
      "Security is a big field. I\u2019m in the CSPM space and Wiz is a major player here, I actually had a bit of an existential crisis about what we were building when I first saw a demo of their platform.Most of their competitors, like Palo Alto, have a very convoluted offering from gluing together several acquisitions. Wiz is very cohesive with a much nicer API and great UX, which is very underrated in the security space imo.I have zero trust in Google\u2019s promise to keep supporting the tool for multiple clouds or maintain the high quality of product design that makes Wiz great. It\u2019s great for my job security, but I\u2019d call it a net loss for the industry.\n \nreply",
      "CSPM is very crowded space. There are quite some new and emerging providers. Wiz out of the scene opens up new opportunities.\n \nreply",
      "Opportunity for opportunity sake isn't a virtue if it gets rid of one of the few providers that was any good.\n \nreply",
      "If you're in security and you haven't at least heard of Wiz, I have doubts about what you actually do. I'm not saying you have to be a CSPM expert, but not even hearing about Wiz, when they are the largest CSPM, is somewhat concerning.\n \nreply",
      "I am in security for many years now, my main focus is reverse engineering (but I did many diverse things, including cryptography, some exploit development and the opposite, AV work, I did R&D in security automation and some development of security tools and engines).I never even looked at a CSPM, and from my point of view[1] CSPMs are a tool only relevant for a small part of security teams focused on enterprise cloud security. Today is the first time I heard of Wiz.edit Actually my partner works in policy/compliance/legal side of security, and I'm pretty sure she never heard of Wiz too.[1] I wrote this only to stress how different people in the same field can see things differently.",
      "> If you're in security and you haven't at least heard of Wiz, I have doubts about what you actually do.IT security a very wide field. For example, a lot of positions in IT security are actually about compliance (i.e. lots of documentation), and ensuring the rollout of all necessary application patches in the whole company.\n \nreply"
    ],
    "link": "https://www.reuters.com/technology/cybersecurity/google-agrees-buy-cybersecurity-startup-wiz-32-bln-ft-reports-2025-03-18/",
    "first_paragraph": ""
  },
  {
    "title": "Turkish university annuls Erdogan rival's degree, preventing run for president (reuters.com)",
    "points": 286,
    "submitter": "perihelions",
    "submit_time": "2025-03-18T20:31:22 1742329882",
    "num_comments": 119,
    "comments_url": "https://news.ycombinator.com/item?id=43404679",
    "comments": [
      "To add insult to injury, it could be the case\nthat Erdogan's degree is fake [1](I don't know of a single Turkish person NOT voting for him that thinks that \nhis degree is authentic)[1] https://en.wikipedia.org/wiki/Recep_Tayyip_Erdo%C4%9Fan_univ...\n \nreply",
      "From a brief reading of the wikipedia article you linked, I'm under impression that the accusations are baseless (given that there are - supposedly - witnesses and his former classmates that confirm his version, and apparently no whistleblowers that present a proof otherwise). The sources are in Turkish so I didn't consult them[1]. Is the article biased or omits some important context? Since you believe the degree is not authentic I assume you know about some things suggesting misconduct.[1] Yes, I could translate them, but I'm not prepared to go down this particular rabbit hole.\n \nreply",
      "Before the 2000s, depending on how overtly conservative you were and who was in govenenent (coups, counter-coups, and fits of \"democracy\" happened every couple years), you might not have been allowed to attend at all.An entire generation of women from conservative backgrounds couldn't attend university in Turkiye until the 2000s because of the hijab ban.Unsurprisingly, once conservative Turkish politicians like Erdogan took power, they came with vengeance. Didn't help that rural, working class, and certain ethnicities (Anatolian Turks, Kurds) were more conservative than others - go to Istanbul Airport sometime and count how many un-hijabed vs hijabed women work as the bathroom cleaning staff.Of course, those same conservative politicians then do the exact same shenanigans of corruption, power politics, and authoritarianism, and so the cycle continues.The intersectionality between class, religion, ideology, and ethnicity makes Turkish politics wonky.\n \nreply",
      "I am from Turkey and this really concerns me. If we don't protest this in the streets and fight back I am afraid we don't have any kind of law anymore.\n \nreply",
      "Isn't this just the latest cut in your democracy's death by a thousand cuts?\n \nreply",
      "Turkeys taken years, the us is speedrunning.\n \nreply",
      "It's a disrepectful comparison for Turkish nationals working hard to build democratic institutions.The US hasn't had the same history of coups, insurgencies, pogroms, massacres, censorship, corruption, etc.Making everything about the US is just rude.\n \nreply",
      "Why is it rude?Do you think Americans haven't worked hard to build democratic institutions?\n \nreply",
      "Seems like for much of the world?\n \nreply",
      "I'd add also a thousand bullets, a thousand tortures, a thousand rapes, and a thousand days in prison for having a different opinion and expressing it.\n \nreply"
    ],
    "link": "https://www.reuters.com/world/asia-pacific/istanbul-university-annuls-istanbul-mayor-imamoglus-diploma-over-irregularities-2025-03-18/",
    "first_paragraph": ""
  },
  {
    "title": "Nvidia Dynamo: A Datacenter Scale Distributed Inference Serving Framework (github.com/ai-dynamo)",
    "points": 72,
    "submitter": "ashvardanian",
    "submit_time": "2025-03-18T20:44:14 1742330654",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=43404858",
    "comments": [
      "Built in Rust for performance and in Python for extensibilityOmg, a team that knows how to selectively use tech as needed. Looking at the Rust web developers in corner.\n \nreply",
      "So this replaces triton for LLMs or?\n \nreply",
      "This is very narrowly focused on LLMs, whereas triton is still useful for running all kinds of ML models. In practice, Triton is a very poor choice for LLMs specifically because it has none of the required non negotiable features like KV caching built in.\n \nreply",
      "As someone who spent the better part of a year trying to get various Nvidia inference products to work _at all_ even with a direct line to their developers, I will simply say \"beware\".\n \nreply",
      "Just curious what your issues with Triton were. We've done OK with it using it to serve LLM models w/ a classifier head via HF Transformers pipeline & Flash Attention 2, as well as serving text generation models with the vLLM back-end.\n \nreply",
      "Triton is not that bad at all, considering the wide scope of systems it has to support (tensorrt, onnx, multiple generations of pytorch, cuda, python). It was much nicer than the old Torchserve project which was JVM based.\n \nreply",
      "Can you share some of your wisdom on setting up a scalable inference infrastructure?\n \nreply",
      "Use Ray Serve. https://docs.ray.io/en/latest/serve/index.html\n \nreply",
      "As someone who has run LLMs in production, using Ray is probably the worst idea. It's not optimized for language models, and is extremely slow. There's no KV-caching, model parallelism, and other basic table stakes features that are offered by Dynamo or other open source inference frameworks. Useful only if you have <1 QPS.Use SGLang, vLLM, or text-generation-inference instead.\n \nreply",
      "It really depends on the task. If you have 1 massive job, Ray sucks and doesn't provide table stakes. If you have 50M tiny jobs, Ray and kuberay is great and serves as the backbone of several billion dollar products.Good for the goose, good for the gander...\n \nreply"
    ],
    "link": "https://github.com/ai-dynamo/dynamo",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A Datacenter Scale Distributed Inference Serving Framework\n      \n\n| Guides | Architecture and Features | APIs | SDK |NVIDIA Dynamo is a high-throughput low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments. Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.The following examples require a few system level packages.\nRecommended to use Ubuntu 24.04 with a x86_64 CPU. See support_matrix.mdNoteTensorRT-LLM Support is currently available on a branchTo run a model and interact with it locally you can call "
  },
  {
    "title": "US appeals court rules AI generated art cannot be copyrighted (reuters.com)",
    "points": 424,
    "submitter": "rvz",
    "submit_time": "2025-03-18T18:17:33 1742321853",
    "num_comments": 320,
    "comments_url": "https://news.ycombinator.com/item?id=43402790",
    "comments": [
      "This is pretty much the exact same case as the monkey that took a photo. The photo is now in the public domain as the monkey cannot be an author of the photo and since the photographer didn't take the photo, neither is he the author. The US Copyright Office clarified that \"only works created by a human can be copyrighted under United States law, which excludes photographs and artwork created by animals or by machines without human intervention\". If you placed some food on a camera trigger and the animal reached for it, taking a photo in the process, that would likely be human intervention. I feel as if this applies to AI as well. A computer cannot be the author but as long as it was a human that told the computer to make the image or wrote the code that allowed the computer to generate the image on its own, then the human is the author.Trying to assign copyright to an AI is techno-futurist bullshit by trying to give legal presence to a piece of software. What's next? Shutting down an AI is murder? Give it a rest.\n \nreply",
      "I still can't believe the guy went to Indonesia, went into the monkeys' habitat, gained their trust, set up the camera on a tripod in a way the monkeys would have access to it, adjusted the focus/exposure to capture a facial close-up -- basically engineered the entire situation specifically for that outcome, and simply because he didn't physically hit the shutter he lost credit for the photo. Meanwhile I can open my phone's camera, spin around three times, take a photo of whatever the hell happens to be in its viewfinder and somehow that is sufficient human creativity to deserve copyright protection.\n \nreply",
      "It's not difficult to understand.Replace the monkey with a 2nd human, and it's obvious that \"the guy\" does not earn the copyright, it goes to the person who took the photo. If there was no person, then there is no copyright.The AI thing is no different. If I ask my human friend, \"please paint a picture using your vast knowledge and experience\", then my friend gets the copyright. Replace friend with AI; there is no person to assign the copyright, so there is no copyright. It doesn't default to me just because I asked for it.\n \nreply",
      "Who owns the copyright when you ask someone to take a photo of you using your phone in a tourist location? According to Wikimedia's legal analysis, it depends.[0] Furthermore, authorship and copyright are distinct.[0] https://meta.wikimedia.org/wiki/Wikilegal/Authorship_and_Cop...\n \nreply",
      "Oof, this gets into all sorts of weird legal grey areas.- All of our phones do a bunch of computational photography where AI tooling improves a photo in various ways. In that case, is any photo taken by a modern phone not copyrightable?- If it is copyrightable, what if someone uses an Img2Img tool or inpainting with something like Stable Diffusion (or Photoshop) in order to slightly modify an image. Is that no longer copyrightable?(FYI, my questions aren't directed at or attacking you -- just interesting hypotheticals.)\n \nreply",
      "In short, in situation 1 there is no issue. In situation 2, if the original image can be copyrighted, AI tooling to augment the image doesn\u2019t prevent copyright. The copyright offices guidance on the subject is a worthwhile read, since they detail out the difference between using AI as a tool to modify human authorship, vs the AI taking minimal input alone and generating a resulting image.\n \nreply",
      "\"Minimal input\" like pushing a button on a camera? Seems to me that is more minimal than some of the elaborate prompting it takes to get AI to output a desired image.\n \nreply",
      "> - If it is copyrightable, what if someone uses an Img2Img tool or inpainting with something like Stable Diffusion (or Photoshop) in order to slightly modify an image. Is that no longer copyrightable?The number 5 is not copyrightable, but if I take your short story and replace every space with the number 5 it's still subject to the original copyright.\n \nreply",
      "- All of our phones do a bunch of computational photography where AI tooling improves a photo in various ways. In that case, is any photo taken by a modern phone not copyrightable?On a related note, I believe it's just a question of time that in some high profile case (murder, rape, thief) direct photographic evidence of the perpetrator will have to be discarded, because it was taken with a smartphone and it's imposible to determine to which degree it was altered.\n \nreply",
      "Wouldn't they be derivative works of a copyrightable work?\n \nreply"
    ],
    "link": "https://www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/",
    "first_paragraph": ""
  },
  {
    "title": "Preview: Amazon S3 Tables and Lakehouse in DuckDB (duckdb.org)",
    "points": 116,
    "submitter": "hn1986",
    "submit_time": "2025-03-18T16:36:20 1742315780",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=43401421",
    "comments": [
      "This is pretty exciting. DuckDB is already proving to be a powerful tool in the industry.Previously there was a strong trend of using simple S3-backed blob storage with Parquet and Athena for querying data lakes. It felt like things have gotten pretty complicated, but as integrations improve and Apache Iceberg gains maturity, I'm seeing a shift toward greater flexibility with less SaaS/tool sprawl in data lakes.\n \nreply",
      "Yes - agree!  I actually wrote a blog about this just two days ago:May be of interest to people who:- What to know what DuckDB is and why it's interesting- What's good about it- Why for orgs without huge data, we will hopefully see a lot more of 's3 + duckdb' rather than more complex architectures and services, and hopefully (IMHO) less Spark!https://www.robinlinacre.com/recommend_duckdb/I think most people in data science or data engineering should at least try it to get a sense of what it can doReally for me, the most important thing is it makes it so much easier to design and test complex ETL because you're not constantly having to run queries against Athena/Spark to check they work - you can do it all locally, in CI, set up tests, etc.\n \nreply",
      "I have the same thoughts. However my impression is also that most orgs would choose eg databricks or something for the permission handling, web ui, ++ so what is the equivalent \u00abfull rig\u00bb with duckdb and S3 / blob storage?\n \nreply",
      "Yeah I think that's fair, especially from the 'end consumer of the data' point of view, and doing things like row-level permissions.For the ETL side, where often whole-table access is good enough, I find Spark in particular very cumbersome - there's more than can go wrong vs. DuckDB and it's  harder to troubleshoot.\n \nreply",
      "from the blog: \"This is a very interesting new development, making DuckDB potentially a suitable replacement for lakehouse formats such as Iceberg or Delta lake for medium scale data.\"I don't think we'll ever see this, honestly.excellent podcast episode with Joe Reis - I've also never understood this whole idea of \"just use Spark\" or you gotta get on Redshift.\n \nreply",
      "> excellent podcast episode with Joe Reis - I've also never understood this whole idea of \"just use Spark\" or you gotta get on Redshift.Can you link to the podcast episode?\n \nreply",
      "Funny, I read TFA and came to the comments to share exactly this recent blog post of yours. Big fan of your work, Robin!\n \nreply",
      "Ah nice - reading that made me feel good! Appreciate the feedback!\n \nreply",
      "if you're looking to try out duckdb + iceberg on AWS, we have a solid guide here: https://www.definite.app/blog/cloud-iceberg-duckdb-aws\n \nreply",
      "Does DuckDB just delegate the query to S3 Tables? or does it do anything in-engine with the data files?On thing that's missing in DuckDB is predicate pushdown for iceberg - see https://github.com/duckdb/duckdb-iceberg/issues/2Which puts it way behind the competition, performance wise.\n \nreply"
    ],
    "link": "https://duckdb.org/2025/03/14/preview-amazon-s3-tables.html",
    "first_paragraph": ""
  },
  {
    "title": "Amazon to kill off local Alexa processing, all voice requests shipped to cloud (theregister.com)",
    "points": 378,
    "submitter": "johnshades",
    "submit_time": "2025-03-18T17:27:46 1742318866",
    "num_comments": 100,
    "comments_url": "https://news.ycombinator.com/item?id=43402115",
    "comments": [
      "Years ago after getting one I was messing around in settings on Amazon's Alexa website and noticed a log of commands/messages sent to Alexa. I reviewed them and was horrified to see \"why does daddy always beat me\". Best to let your daughter win at Uno in this age of always-on connectivity. Or just unplug it, which is what I did.\n \nreply",
      "There's some important nuance here: All commands (after trigger/wake word) were sent to the cloud in the past anyway.The option to do some on-device processing came on later devices and, as I understand it, wasn't even enabled by default. Furthermore, on-device processing would still send the parsed commands to the cloud.The headline is vague, but it's misleading a lot of people into thinking that only now Amazon will start sending commands to the cloud. It's actually always been that way. I suspect the number of people who enabled on-device processing was very, very small.\n \nreply",
      "I'm shocked that not one single article I've found mentioned this incredibly obvious fact.  This has ALWAYS been the case and only a few select models ever offered the option to turn it off.  This change puts all devices on equal footing and behavior with the launch device.I don't love Amazon, but I love ginned up outrage over tech the author never bothered to understand even less.\n \nreply",
      "\"I don't love Amazon, but I love ginned up outrage over tech the author never bothered to understand even less.\"And 99% of Echo owners disagree with this. No one cares if a reporter mixed up \"amazon is starting to spy on you tomorrow\" vs \"amazon has been spying on you since the first echo was launched\". Only amazon would make an argument like \"yeah but we've been doing this for years now and no one made a big deal about it...\"\n \nreply",
      "> ginned upThe Sauron's Eye of public sentiment can only pay attention to one thing at a time. If you justify today on the basis that it wasn't paying attention yesterday, you can rationalize anything.\n \nreply",
      "Online news articles are not really a workable medium for real journalism or reporting\n \nreply",
      "I knew someone that used to work on the Alexa team on the language side of things.  She had an emotionally terrible few weeks at one stage, because she and her team had to brainstorm (working in conjunction with experts) on just about every possible way users might ask questions that indicate they're being abused, so that they could provide suitable responses.  Glad to have worked on it, but it was heart wrenching in many regards.\n \nreply",
      "[flagged]",
      "It sounds like you\u2019re subtly implying that GP was posting a copypasta?\n \nreply",
      "I understood it to mean that dads are just really great at Uno\n \nreply"
    ],
    "link": "https://www.theregister.com/2025/03/17/amazon_kills_on_device_alexa/",
    "first_paragraph": ""
  },
  {
    "title": "This is no world for an axolotl (elpais.com)",
    "points": 81,
    "submitter": "geox",
    "submit_time": "2025-03-15T16:26:51 1742056011",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=43373504",
    "comments": [
      "Reminds me of the delightfully strange short story by the Argentinian writer Julio Cort\u00e1zar:\u2018Axolotl\u2019 is narrated by a lonely man who regularly visits the local zoo, where he becomes fascinated by the axolotls in the aquarium. In time, he states that he, too, is an axolotl, and feels he has become one of them.https://ambystoma.uky.edu/teachers_materials/axolitbook/Axol...\n \nreply",
      "+1 really enjoyed the whole collection of short stories from Cortazar when I read it at uni.https://www.amazon.com/Bestiary-Selected-Stories-Julio-Cort%...\n \nreply",
      "Curiosity about the works of man >> curiosity about the \"works\" of \"God\"/\"Nature\"??? Ironic that this masterpiece is about an extreme form of the latter XD\n \nreply",
      "From the crowd source folks, here's the iNaturalist map on Axolotl (Ambystoma Mexicanum) [1][2][1] Species, Map, Observation Count: https://www.inaturalist.org/taxa/26777-Ambystoma-mexicanum[2] Actual Observations with Pictures: https://www.inaturalist.org/observations?verifiable=true&tax...Only six whole observations in the last decade.  Most near Mexico City.  Unfortunately, one of them's in the process of being eaten by a Clark's Grebe.\n \nreply",
      "Thanks to Minecraft and pester-power, we bought our son an axolotl some years ago on the condition he would look after it (figuring we'd end up looking after it anyway).And since they live a long time it's given us an out every time he asks for a new pet ;)\n \nreply",
      "Interesting, I had thought they were generally illegal to keep as pets, but I see now that that's only in some locations.\n \nreply",
      "https://archive.ph/FXjo6\n \nreply",
      "https://nextgenbiologics.com/index.html\n \nreply",
      "Unlocks full regeneration capabilities and still going extinct while your average lizard can only do it for half a tail and still thrives.\n \nreply",
      "Amphibians are sadly, more susceptible to environmental toxins than reptiles are. I think it\u2019s because their skin is more absorbent than reptile skin, but my biological knowledge is fairly limited.\n \nreply"
    ],
    "link": "https://english.elpais.com/eps/2025-03-15/this-is-no-world-for-an-axolotl.html",
    "first_paragraph": "Basilio Rodr\u00edguez casts his net with a masterful swing, launching it into the air before it falls, sinking into the water. He then smacks the two sides of the canal with a wooden pole. Fish emerge from their hiding places among the reeds and head straight into the net. When he pulls up the catch, his net reveals a tilapia and a couple of juvenile carp \u2014 not what he is looking for, which is axolotls, the strange Mexican amphibians teetering on the brink of extinction.The scientists accompanying him on the trajinera, or flat-bottomed boat, tally another zero in their field notebooks. Dawn is a magical time on the canals, suffuse with a fog reminiscent of Dublin that hangs over the water. An orange half-sun appears over the horizon. It is chilly here until light breaks over Mexico City\u2019s southern sky. Again and again, the nets come up empty.The axolotl, whose name comes from the Nahuatl language indigenous to the Mexico City area, is an amphibian so singular that it could well appear on t"
  },
  {
    "title": "A Tale of Four Kernels [pdf] (2008) (calpoly.edu)",
    "points": 34,
    "submitter": "pcfwik",
    "submit_time": "2025-03-18T20:25:27 1742329527",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43404617",
    "comments": [
      "I've always enjoyed the practical research and projects that happen at the CalPoly schools, my friends who attended always seemed to be doing some very neat hands-on work.Anecdotally, my occasional interactions with Linux kernel source code have always impressed me with how the project manage to effectively structure such a large C codebase. Until I look at FreeBSD code, which is even more impressively organized. Both of these projects have really helped me think about how to best organize huge complicated systems.\n \nreply",
      "I'm also curious about what impressed you. Most of my interactions with Linux code have been trawling through either crufty or just poorly-written subsystems/drivers because they're causing me problems, which I realise is a bit of a biased sample.\n \nreply",
      "If you're willing to share I'd be interested in hearing more about what you learned.  What is it about those two codebases that you've used to inform your own choices?The kernels are pretty sizeable and pretty specialized pieces of software so it's kinda fascinating that useful lessons for other projects could be extracted from it.\n \nreply",
      "Note that Diomidis is at AUEB, not CalPoly.\n \nreply",
      "Wow, this has been submitted exactly twice:  today -- and 17 years ago.[0]  (No comments then either, probably because there isn't too much to say? Even the work itself draws pretty tepid conclusions.)[0] https://news.ycombinator.com/item?id=194927\n \nreply"
    ],
    "link": "https://users.csc.calpoly.edu/~djanzen/courses/509S09/papers/FourKernels.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Shopkeeper (robinsloan.com)",
    "points": 22,
    "submitter": "herbertl",
    "submit_time": "2025-03-15T23:40:27 1742082027",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.robinsloan.com/newsletters/shopkeeper/",
    "first_paragraph": "Trespassers:The best time to estab\u00adlish alternative, non-algorithmic net\u00adworks of com\u00admu\u00adni\u00adca\u00adtion & affinity was five years\u00a0ago.The second best time is\u00a0today!Over the years, I\u2019ve dis\u00adtrib\u00aduted many zines through the mail. Those have been one-off productions, which is to say, pageants of minor chaos, always with the sense, as the last zine went out the door, of skid\u00adding into home\u00a0plate.For a while, I\u00a0have won\u00addered if I\u00a0could rec\u00adtify this, making dis\u00adtri\u00adb\u00adu\u00adtion via mail both (1) easy for me, & (2) reli\u00adable for you. I\u00a0know it\u2019s possible\u200a\u2014\u200awe\u2019ve been doing it for years with the olive oil company!So, that\u2019s all to say, I\u2019ve opened a little shop, which is today stocked with two\u00a0items:\nI\u2019m Robin Sloan, a fiction writer with wide-ranging interests, which I\u00a0capture here in my newsletter. This is an archived edition, originally transmitted in March 2025. You can sign up to receive future editions using the form at the bottom of the\u00a0page.\nMy goals here are\u00a0manifold:Make printing & dis\u00adtri"
  },
  {
    "title": "PeerTube v7.1 Is Out (joinpeertube.org)",
    "points": 137,
    "submitter": "voxadam",
    "submit_time": "2025-03-18T18:56:53 1742324213",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=43403377",
    "comments": [
      "I know this will come across as negative but design matters for something like this.Can't they afford $5K for websites and UI design?  Everything here looks absolutely terrible.Its a negative take but they're asking me to consider this as an alternative to YouTube - how it presents is critically important.Also, the website root should not talk about peertube, it should drop me into peertubeAnd a final gripe..... Can't they get a better domain than \"joinpeertube.org\" - really almost anything would be better.Sorry this is such a grumble but so many obvious self sabotaging obstacles to success.\n \nreply",
      "A sentence is not a paragraph.\n \nreply",
      "Do you have a more substantive reply to the user you\u2019re replying to? These are genuine observations/experiences. If you disagree or think they are misguided, then point them out.\n \nreply",
      "> .. improves support for Podcast 2.0, allowing users to subscribe to channels and play the video audio stream (if available) using classic podcast applicationsthat refers to https://podcasting2.org/podcast-namespaceA youtube channel url provides a rss link too, but it's not advertised much and you need a player that can extract the audio stream. I often yt-dl the audio from talks/interviews, but it could be easier.The v7 interface came out nice, for examples see https://instances.joinpeertube.org/instances?sort=-version&p...\n \nreply",
      "Kind of a pain to find but it's essentially\n`https://www.youtube.com/feeds/videos.xml?channel_id=UCY1kMZp...` and you swap out the channel ID.To find the channel ID:\n1. Visit the creator's page\n2. Click on `more` for the full description\n3. Scroll down to `Share Channel`\n4. Click and copy Channel IDA bit of a pain but I'm glad I know this now!\n \nreply",
      "a quick shortcut flow in a browser on the youtube channel page (a click below the video title):ctrl+u ctrl+f \"rss+x\" -> shows a click+copyable video.xml linkI understand people being pleased to learn this, for me the peertube announcement was learning about p2, as it's been around a few years already.alternateEnclosure is a real gem in the p2 rss spec, the thing that makes multiple channels and alternative formats/codecs/resolutions work.\n \nreply",
      "This bookmarklet will show the RSS feed URL in an alert window:Original Source: https://webapps.stackexchange.com/a/116549    javascript: (() => {\n\n    for (var arrScripts = document.getElementsByTagName('script'), i = 0; i < arrScripts.length; i++) {\n        if (arrScripts[i].textContent.indexOf('externalId') != -1) {\n            var channelId = arrScripts[i].textContent.match(/\\\"externalId\\\"\\s*\\:\\s*\\\"(.*?)\\\"/)[1];\n            var channelRss = 'https://www.youtube.com/feeds/videos.xml?channel_id=' + channelId;\n            var channelTitle = document.title.match(/\\(?\\d*\\)?\\s?(.*?)\\s\\-\\sYouTube/)[1];\n            alert('The rss feed of the channel \\'' + channelTitle + '\\' is:\\n' + channelRss);\n            break;\n        }\n    }\n\n    })();\n \nreply",
      "The rss feed provides a link that you can open in a web browser to play the video. You don't need a tool to extract it.\n \nreply",
      "Framasoft is really an amazing team. They are basically the reason I discovered FOSS when I was younger.The fact they are still here and supporting so many free services is a miracle.\n \nreply",
      "I like the idea of a decentralized Google free YouTube. But I find these posts about PeerTube, Frama, Mastodon, protocols, etc just very confusing. And it\u2019s hard to understand how everyday people can use this platform or it is even meant for that. Years after first hearing of this, it has gone nowhere.I know this is a negative take but does someone have an explanation or an understanding of whether this project means anything from a practical standpoint?\n \nreply"
    ],
    "link": "https://joinpeertube.org/news/release-7.1",
    "first_paragraph": "We're excited to release version 7.1 of PeerTube, which continues to evolve graphically, but also to simplify your discoverability! Let's take a closer look.Thanks to the work of La Coop\u00e9rative des Internets, the \"About\" pages of the platforms have been redesigned to make them even clearer and easier to access, with information such as a description of the platform, the terms of use, some key figures, the main rules in clear sentences, etc. We've had a lot of positive feedback and hope you like it too!\n Before redesign\n\n\n After redesign\nThe concept of platform federation is not always easy to explain, so why not take it one step at a time? That's what this new video component does by highlighting the address of the platform where the video is hosted. Clicking on it gives you an explanation of where the video comes from and you can get more information, such as seeing all the videos hosted on the remote platform.\n \nPodcasts are a very popular way of consuming content, so it's important "
  }
]