[
  {
    "title": "Claude Sonnet 4 now supports 1M tokens of context (anthropic.com)",
    "points": 884,
    "submitter": "adocomplete",
    "submit_time": "2025-08-12T16:02:23 1755014543",
    "num_comments": 489,
    "comments_url": "https://news.ycombinator.com/item?id=44878147",
    "comments": [
      "This is definitely one of my CORE problem as I use these tools for \"professional software engineering.\"  I really desperately need LLMs to maintain extremely effective context and it's not actually that interesting to see a new model that's marginally better than the next one (for my day-to-day).However. Price is king. Allowing me to flood the context window with my code base is great, but given that the price has substantially increased, it makes sense to better manage the context window into the current situation. The value I'm getting here flooding their context window is great for them, but short of evals that look into how effective Sonnet stays on track, it's not clear if the value actually exists here.reply",
      ">  I really desperately need LLMs to maintain extremely effective contextThe context is in the repo. An LLM will never have the context you need to solve all problems. Large enough repos don't fit on a single machine.There's a tradeoff just like in humans where getting a specific task done requires removing distractions. A context window that contains everything makes focus harder.For a long time context windows were too small, and they probably still are. But they have to get better at understanding the repo by asking the right questions.reply",
      "> But they have to get better at understanding the repo by asking the right questions.How I am tackling this problem is making it dead simple for users to create analyzers that are designed to enriched text data. You can read more about how it would be used in a search at https://github.com/gitsense/chat/blob/main/packages/chat/wid...The basic idea is, users would construct analyzers with the help of LLMs to extract the proper metadata that can be semantically searched. So when the user does an AI Assisted search with my tool, I would load all the analyzers (description and schema) into the system prompt and the LLM can determine which analyzers can be used to answer the question.A very simplistic analyzer would be to make it easy to identify backend and frontend code so you can just use the command `!ask find all frontend files` and the LLM will construct a deterministic search that knows to match for frontend files.reply",
      "Large enough repos don't fit on a single machine.I don't believe any human can understand a problem if they need to fit the entire problem blem domain in their head, and the scope of a domain that doesn't fit on a computer. You have to break it down into a manageable amount of information to tackle it in chunks.If a person can do that, so can an LLM prompted to do that by a person.reply",
      "> An LLM will never have the context you need to solve all problems.How often do you need more than 10 million tokens to answer your query?reply",
      "I exhaust the 1 million context windows on multiple models multiple times per day.I haven't used the Llama 4 10 million context window so I don't know how it performs in practice compared to the major non-open-source offerings that have smaller context windows.But there is an induced demand effect where as the context window increases it opens up more possibilities, and those possibilities can get bottlenecked on requiring an even bigger context window size.For example, consider the idea of storing all Hollywood films on your computer. In the 1980s this was impossible. If you store them in DVD or Bluray quality you could probably do it in a few terabytes. If you store them in full quality you may be talking about petabytes.We recently struggled to get a full file into a context window. Now a lot of people feel a bit like \"just take the whole repo, it's only a few MB\".reply",
      "I think you misunderstand how context in current LLMs works. To get the best results you have to be very careful to provide what is needed for immediate task progression, and postpone context thats needed later in the process. If you give all the context at once, you will likely get quite degraded output quality. Thats like if you want to give a junior developer his first task, you likely won't teach him every corner of your app. You would give him context he needs. It is similar with these models. Those that provided 1M or 2M of context (Gemini etc.) were getting less and less useful after cca 200k tokens in the context.Maybe models would get better in picking up relevant information from large context, but AFAIK it is not the case today.reply",
      "Flooding the context also means increasing the likelihood of the LLM confusing itself. Mainly because of the longer context. It derails along the way without a reset.reply",
      "I keep reading this, but with Claude Code in particular, I consistently find it gets smarter the longer my conversations go on, peaking right at the point where it auto-compacts and everything goes to crap.This isn't always true--some conversations go poorly and it's better to reset and start over--but it usually is.reply",
      "How do you know that?reply"
    ],
    "link": "https://www.anthropic.com/news/1m-context",
    "first_paragraph": ""
  },
  {
    "title": "Search all text in New York City (alltext.nyc)",
    "points": 56,
    "submitter": "Kortaggio",
    "submit_time": "2025-08-13T00:17:33 1755044253",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44883304",
    "comments": [
      "I typed in \"fart\" and none of the results on the first page were actually the word \"fart\".reply",
      "520 matches on \"hotdog\"  \n8084 matches on \"massage\"\nin no particular orderreply",
      "This would probably make John Wilson's job a lot easier (https://en.wikipedia.org/wiki/How_To_with_John_Wilson)reply",
      "This write-up about the site is also fascinating: https://pudding.cool/2025/07/street-view/reply",
      "Added to top text. Thanks!reply",
      "GitHub of the person who prepared the data. I am curious how much compute was needed for NY. I would love to do it for my metro but I suspect it is way beyond my budget.https://github.com/yz3440reply",
      "Related. Others?All Text in NYC - https://news.ycombinator.com/item?id=42367029 - Dec 2024 (4 comments)All text in Brooklyn - https://news.ycombinator.com/item?id=41344245 - Aug 2024 (50 comments)reply",
      "I _love_ this but it's pretty bad. I searched for \"Morgue\" and one of the matches was the \"2025 Google\" watermark which it thought was \"Big Morgue\"Again, a complex problem and I love it...reply",
      "As others have mentioned, the idea is so cool, but the text recognition is abysmal.reply",
      "hah, it can find all the KEST GAK stickers now: https://www.alltext.nyc/search?q=kestreply"
    ],
    "link": "https://www.alltext.nyc/",
    "first_paragraph": ""
  },
  {
    "title": "Ashet Home Computer (ashet.computer)",
    "points": 185,
    "submitter": "todsacerdoti",
    "submit_time": "2025-08-12T18:56:38 1755024998",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=44880401",
    "comments": [
      "There\u2019s something to be said about an independent system you can understand and expand. What I think will be next frontier in home computing is truly understanding and owning the systems that run a smart home and that comes with understanding the environment (sensor data, presence detection, etc.). We live in an interesting time where embedded development has become so accessible and powerful that we can interface with multiple wireless protocols and state of the art sensors with not a lot of capital investment. If we think what can come beyond screens and imagine more ambient computing systems - maybe we\u2019ll see new and interesting innovationsreply",
      ">We live in an interesting time where embedded development has become so accessible and powerful that we can interface with multiple wireless protocols and state of the art sensors with not a lot of capital investment.Even on Amazon the ESP32 is less than $5 - means like $1 in Shanghai. Various sensors (even the ones with Bluetooth connectivity) are similarly dirt cheap. You can have a bin of such components like you would have a bin of bolts and nuts 30+ years. Basically we live in a golden era of development (which can disappear in US due to tariffs)>If we think what can come beyond screens and imagine more ambient computing systems - maybe we\u2019ll see new and interesting innovationsmy bet is that it will be more robotics related with practically no humans involved.reply",
      "I like the eurorack-esque modular design. Not everyone will want the same base layout, so making it swapable like that is a nice touch.reply",
      "I'd like to sign up for their newsletter, but it appears I can't because I use a nonstandard TLD for my personal email (.info). Lame.reply",
      "\"Compiled languages can be used externally\"I realize that 8MB of RAM seems absurdly small to modern audiences, but I can assure you that I ran early versions of Turbo Pascal and compiled fine with 64K.reply",
      "Their OS is written in Zig!    https://github.com/Ashet-Technologies/Ashet-OS\n\nThought it might be of interest to people learning Zig. I bet there are some interesting examples in there.reply",
      "I've been following Andrew Kelley's writing and zig is probably next on the list for me (previously would have been rust). The story from C to Zig and the ease of cross compilation makes it really tempting. I haven't looked in to the comptime capabilities much but it looks like it could help with some of the embedded work I doreply",
      "> Fully understandable by a single personRiddle me this, Batman.What's the scope of \"fully understandable?\" How much of this home PC could be reasonably audited by individuals or small teams?I've got no exceptional opsec needs as an individual, but I spend some time wondering the minimum required resources to audit a PC. Looking through the docs I see cases where there are multiple suppliers for a recommended part -- that's very cool!As a \"fake programmer\" and web jockey, this looks like the right balance of complexity to learn with.reply",
      "I don't think it's really a fair claim in an educational context. There are at least two completely modern computers (which I assume means fairly complex) including the Raspberry PI and another one he is using the the bus or something.I just don't think modern CPUs really quite fit the claim of \"fully understandable by a single person\". I mean maybe technically but that is misleading in an educational context where there are much simpler computers that are definitely fully understandable.Maybe all of the stuff he wraps around the main CPU is understandable though. And the expansion cards are cool.reply",
      "> but that is misleading in an educational context where there are much simpler computers that are definitely fully understandable.Are there any other projects or resources in this space that you'd recommend?A friend and I cut our teeth on those AlphaSmart word processors that ran BASIC. I might could wrap my head around that.reply"
    ],
    "link": "https://ashet.computer/",
    "first_paragraph": "\n\nSubscribe!\nOur\u00a0Vision\nFeatures\n\n    The Ashet Home Computer is an expandable and hackable computer in the spirit of the 80's home computers.\n\n    Fully understandable by a single person, yet powerful enough to run a graphical desktop OS, it tries to bridge the gap between Arduinos and a RaspberryPi.\n\n    It is designed and engineered for fun and learning, which go best hand in hand.\n  The Ashet Home Computer has completed its design phase, and a practical, achievable hardware concept is now finalized.There are still many smaller design components to be refined, but the overall concept is done.Check out the hardware design to learn more about the system.A functional cable clutter prototype has been created which validates all of the design ideas.This includes:Currently, the RP2350 processor successfully boots the operating system and supports launching desktop applications.The mechanical design is also validated by building a mock-up of the final hardware and case assembly.Check out t"
  },
  {
    "title": "Scapegoating the Algorithm (asteriskmag.com)",
    "points": 28,
    "submitter": "fmblwntr",
    "submit_time": "2025-08-12T23:44:53 1755042293",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=44883083",
    "comments": [
      "America has been in a class war since the beginning. It just refuses to call it that.Yet each time it plays out on the battlefield of truth: who gets to decide what's real? Each era has its own aristocracy - who produces knowledge, and clergy disseminating knowledge and legitimizing who gets to produce it.Phase One: 1770sThe fight was colonial gentry vs. hereditary nobility. Knowledge still lived with the elite, but it was anti-hereditary elite. Thomas Paine writes Common Sense. Not just your uncle's holiday rant, but part of Scottish Realism. \"Self-evident\" meant truths visible to anyone, no credentials required.Phase Two: 1820s\u20131830sJacksonian democracy recasts the conflict: common man vs. entrenched elites in law, banking, and bureaucracy. Aristocracy = lawyers, bankers, judges. Clergy = newspapers and journalists. Populist epistemology: trust your own judgment; they're out of touch.Phase Three: Mid-20th CenturyCold War era crowns scientists, engineers, policy wonks as aristocracy. Broadcasting elites as clergy legitimize the scientific consensus. Main Street is now the beacon of folk wisdom.Phase Four: 2000sOld media's monopoly dies. The internet gives Main Street a megaphone as loud as any newsroom. The Reformation comes again. Swap religion for epistemology, the printing press for the internet. When the epistemic monopoly falls, chaos follows until a new regime of knowledge stabilizes.Let's face it, putting the genie back in the bottle isn't an option. Either we reconstitute the aristocracy under a new, still-undefined regime, or we solve the class problem so there's no aristocracy left to legitimize. Pick one. Then ask yourself what that choice means for what happens next.reply",
      "All societies have elites, you can't eliminate that. What you want are societies where the elite's interests and the people's interests are aligned.reply",
      "So you have chosen aristocracy. The average inter-aristocracy interval is 417 years +/- 196. See you again in approximately the mid 25th century give or take a few.reply",
      "Author is Associate Fellow at the Leverhulme Centre for the Future of Intelligence (CFI), https://www.lcfi.ac.uk/about> Our research is dedicated to ensuring AI is a force for good and it\u2019s structured in a series of research programmes that cover a wide range of projects. Our work explores vital questions about the risks and opportunities emerging with AI in the near, mid- and long-term. These range from algorithmic transparency and the nature of intelligence to automated warfare, consciousness, social AI, feminist AI, AI-amplified injustice, global and pluriversal design, and the implications of AI for democracy, geopolitics, and the natural environment.reply",
      "I dunno.Things seem a lot dumber since social media, but I guess it is possible that the same dumbness is just being broadcast wider now that there aren\u2019t any gatekeepers, I guess.reply",
      "It's a feedback loop that legitimizes dumbness. 40 years ago, the area 51 guy got laughed at in the bar and he stopped talking about it. Now they can all find each other and jerk each other off.reply",
      "I see a lot of intelligent people underestimating the impact of things like propaganda and advertising.The author is wrong about psychology: people are generally not savvy information consumers. They mostly converge on the average of what they see around them. Cult leaders use this to their advantage by removing people from family and non-biased sources of information. The human brain acclimates and it's hard to break away from that situation epistemically.Advertising generally works and is well measured. The process of selling people Coke or Pepsi is not fundamentally different from selling them on political ideas. And in practice many leaders have found it to be of practical utility to strengthen their power with a socially promoted ideology, whether that's religion in ancient times or state religion during the Soviet era or conspiracy theories in the current era.I'd like to see people who are skeptical of the power of propaganda tackle these issues. They tend to cite a handful of reports claiming that propaganda was ineffective in 2016, but those reports were not well done and some members of the intelligence community have publicly stated that foreign influence was decisive in the 2016 election. The official reports that I'm aware of deliberately made no assessment of the impact on the election results.If one believes that such influence is not effective, then one would have a harder time explaining why we're seeing more countries copy the Russian model. Clearly their militaries believe that it is effective. And one would also have a hard time explaining why the US engages in similar tactics abroad, including promoting anti-vax content in China.Anyway, I see why people make the sort of argument the author is making. But it doesn't seem psychologically plausible or empirically correct. And it spreads the meme that consuming propaganda 24 hours a day isn't bad for youreply",
      "The last company I worked at gave us all macbooks. I noticed every few days it put an article titled something like \"maybe its your parents holding you back\" in the sidebar. This seems to be the default configuration on OSX. I'm surprised anyone tolerates this, if I found something like that in my house on my own equipment it would go strait in the trash.reply",
      "To quote an oversimplified campaign trope: \u201cIt\u2019s the [horrifyingly lopsided unequal] economy stupid.\u201dreply",
      "\u201cused to be you had to impress people to get people to watch your show\u2026 But now, all you have to do is impress the algorith. \u2026all hail the algorithm.\u201d-Superfastmattreply"
    ],
    "link": "https://asteriskmag.com/issues/11/scapegoating-the-algorithm",
    "first_paragraph": "America\u2019s epistemic challenges run deeper than social media.Many people sense that the United States is undergoing an epistemic crisis, a breakdown in the country\u2019s collective capacity to agree on basic facts, distinguish truth from falsehood, and adhere to norms of rational debate.\u00a0This crisis encompasses many things: rampant political lies; misinformation; and conspiracy theories; widespread beliefs in demonstrable falsehoods (\u201cmisperceptions\u201d); intense polarization in preferred information sources; and collapsing trust in institutions meant to uphold basic standards of truth and evidence (such as science, universities, professional journalism, and public health agencies).\u00a0According to survey data, over 60% of Republicans believe Joe Biden\u2019s presidency was illegitimate. 20% of Americans think vaccines are more dangerous than the diseases they prevent, and 36% think the specific risks of COVID-19 vaccines outweigh their benefits. Only 31% of Americans have at least a \u201cfair amount\u201d of "
  },
  {
    "title": "Show HN: Building a web search engine from scratch with 3B neural embeddings (blog.wilsonl.in)",
    "points": 325,
    "submitter": "wilsonzlin",
    "submit_time": "2025-08-12T16:02:40 1755014560",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=44878151",
    "comments": [
      "\"There was one surprise when I revisited costs: OpenAI charges an unusually low $0.0001 / 1M tokens for batch inference on their latest embedding model. Even conservatively assuming I had 1 billion crawled pages, each with 1K tokens (abnormally long), it would only cost $100 to generate embeddings for all of them. By comparison, running my own inference, even with cheap Runpod spot GPUs, would cost on the order of 100\u00d7 more expensive, to say nothing of other APIs.\"I wonder if OpenAI uses this as a honeypot to get domain-specific source data into its training corpus that it might otherwise not have access to.reply",
      "I don\u2019t think OpenAI train on data processed via the API, unless there\u2019s an exception specifically for this.reply",
      "One of the most insightful posts I\u2019ve read recently. I especially enjoy the rationale behind the options you chose to reduce costs and going into detail on where you find the most savings.I know the post primarily focuses on neural search, but I\u2019m wondering you tried integrating hybrid BM-25 + embeddings search and if this led to any improvements. Also, what reranking models did you find most useful and cost efficient?reply",
      "Just wow. My greatest respect! Also an incredible write up. I like the take-away that an essential ingredient to a search engine is curated and well filtered data (garbage in garbage out) I feel like this has been a big learning of the LLM training too, rather work with less much higher quality data. I'm curious how a search engine would perform where all content has been judged by an LLM.reply",
      "I'm currently trying to get a friends small business website to rank. I have a decent understanding of SEO, doing more technically correct things and did a decent amount of hand written content specific to local areas and services provided.Two months in, bing still hasn't crawled the fav icon. Google finally did after a month. \nI'm still getting outranked by tangentially related services, garbage national lead collection sites, yelp top 10 blog spam, and even exact service providers from 300 miles away that definitely don't serve the area.Something is definitely wrong with pagerank and crawling in general.reply",
      "Sadly, that ship has sailed. The web is dead. SEO should be called SEM (Search Engine Manipulation).reply",
      "At the end, the author thinks about adding Common Crawl data. Our ranking information, generated from our web graph, would probably be a big help in picking which pages to crawl.I love seeing the worked out example at scale -- I'm surprised at how cost effective the vector database was.reply",
      "It's incredible. I can't believe it but it actually works quite nicely.If 10K $5 subscriptions can cover its cost, maybe a community run search engine funded through donations isn't that insane?reply",
      "It's been clear to anyone familiar with encoder only LLMs that Google is effectively dead. The only reason why it still lives is that it takes a while to crawl the whole web and keep the index up to date.If someone like common crawl, or even a paid service, solves the crawling of the web in real time then the moat Google had for the last 25 years is dead and search is commoditized.reply",
      "This wasn't even in the realm of what I thought is possible for a single person to do. Incredible work!It doesn't seem that far in diatance from a commercial search engine? Maybe even Google?50k to run is a comically small number. I'm tempted to just give you that money to seed.reply"
    ],
    "link": "https://blog.wilsonl.in/search-engine/",
    "first_paragraph": "A while back, I decided to undertake a project to challenge myself: build a web search engine from scratch. Aside from the fun deep dive opportunity, there were two motivators:A simple question I had was: why couldn't a search engine always result in top quality content? Such content may be rare, but the Internet's tail is long, and better quality results should rank higher than the prolific inorganic content and engagement bait you see today.Another pain point was that search engines often felt underpowered, closer to keyword matching than human-level intelligence. A reasonably complex or subtle query couldn't be answered by most search engines at all, but the ability to would be powerful:Search engines cover broad areas of computer science, linguistics, ontology, NLP, ML, distributed systems, performance engineering, and so on. I thought it'd be interesting to see how much I could learn and cover in a short period. Plus, it'd be cool to have my own search engine. Given all these poin"
  },
  {
    "title": "Journaling using Nix, Vim and coreutils (tangled.sh)",
    "points": 75,
    "submitter": "icy",
    "submit_time": "2025-08-12T14:04:40 1755007480",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=44876356",
    "comments": [
      "I don't see what nix is doing for you? There's vim, absolutely, coreutils (though I don't immediately see anything GNU-specific), and a tiny wrapper script that happens to be written in flake.nix but could trivially be factored out. I don't see anything that I wouldn't expect to run on, say, OpenBSD if you installed vim.(That said, yes, it's a nice journaling system)reply",
      "I was somewhat expecting that the flake would include nvim bundled with the vimrc in the folder.You could then just open nvim in the `nix develop` environment (or even use something like direnv to activate it when you cd in) and have a minimal journaling environmentreply",
      "Yeah, if it included ex. nvim plugins then it would make more sense to me. It's just this particular combination is for installing tools that I struggle to imagine aren't default-installed everywhere, and version-locking some of the most stable programs I've ever used (though I guess neovim might make breaking changes?). Honestly it strikes me as most useful as a 'hello world 2.0' flake demo.reply",
      "Yea I don't see Nix doing much here particularly, but for me I typically would do something like this to make the system as consistent as possible over a long period of time without being actively maintained.I guess this does ensure the key `journal` command works exactly the same because the dateutils binary will stay locked to the version in the `flake.lock`.I would have assumed that nvim would also be locked because that's where I would expect more possible breaking changes with the existing special config.With little tools/projects like these I could easily see months-years before it would get any active attention from me again (or simply I wouldn't be using it; so it doesn't matter).reply",
      "This is a pretty poor example for a few reasons, but the idea is that anyone get can a shell with the tool fully installed along with all its dependencies, with a single command:nix shell 'git+https://tangled.sh/@oppi.li/journal'It's massive overkill for a shell alias, but for a more complex project it can be very nice.reply",
      "Sure; I'm typing this comment on a NixOS machine in a browser controlled from a flake I wrote myself - I get using nix and flakes in general. It's just that this particular case seems like such overkill that it actually seems like a weird tradeoff even if you're used to flakes.reply",
      "One area that is especially a massive win is projects that cross multiple ecosystems. So like, C++ project with some Python bindings and a Typescript frontend? Setting up that dev environment is often a nightmare but Nix makes it trivial and highly reproducible.reply",
      "author seems to be the type to follow tech trends and use them to signal \"coolness\" - people like that use these absurd stacks because its niche, not for any actual benefitreply",
      "If you want week numbers in the calendar, you can use `ncal -w` and they'll be the last row.  Add a `-3` and you get:    $ ncal -w3\n        July 2025         August 2025       September 2025\n    Mo     7 14 21 28        4 11 18 25     1  8 15 22 29\n    Tu  1  8 15 22 29        5 12 19 26     2  9 16 23 30\n    We  2  9 16 23 30        6 13 20 27     3 10 17 24\n    Th  3 10 17 24 31        7 14 21 28     4 11 18 25\n    Fr  4 11 18 25        1  8 15 22 29     5 12 19 26\n    Sa  5 12 19 26        2  9 16 23 30     6 13 20 27\n    Su  6 13 20 27        3 10 17 24 31     7 14 21 28\n       27 28 29 30 31    31 32 33 34 35    36 37 38 39 40reply",
      "here I am tangenting into wtf tangled.sh is, maybe that's the entire point of this submission.reply"
    ],
    "link": "https://tangled.sh/@oppi.li/journal",
    "first_paragraph": "I cobbled together a journaling system with {neo,}vim,\ncoreutils and dateutils.\nThis system is loosely based on Ryder\nCaroll's Bullet Journal\nmethod.The journal for a given year is a directory:In each directory are 12 files, one for each month of the\nyear, numbered like so:We can now begin writing stuff down:Every month must start with a calendar of course, fill that\nin with:Your entry for January might look like this:I prefer planning week by week, as opposed to creating a\ntask-list every day, here's what I have for the first couple\nof weeks:I start the week by writing a header and each item that week\nis placed on its own line. The items are prefixed with a\ntodo or a done signifier.Right off the bat, the signifiers look very noisy, Even more\nso once we start introducing variety (I use \"event\", \"note\"\nand \"moved\"):We can clean this up with \"abbreviations\" (:h abbreviations):Now, typing this:Automatically inserts:You can use x and o as well, but \u00d7 (U+00D7,\nMULTIPLICATION SIGN) and \u00b7 (U+"
  },
  {
    "title": "A gentle introduction to anchor positioning (webkit.org)",
    "points": 39,
    "submitter": "feross",
    "submit_time": "2025-08-12T22:18:55 1755037135",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44882438",
    "comments": [
      "It being available on WebKit makes me hopeful for general adoption then.reply",
      "As mentioned at the end of TFA, Codepip's Anchoreum  is an excellent way of learning this.[0] https://anchoreum.com/reply",
      "I was expecting boat anchors haha.reply",
      "Do we really need this? Why won't position: absolute and setting top/left/bottom/right suffice?reply",
      "It solves many of the pain points Tether[0] tried to solve.For example it helps when the anchoring element is inside of an oveflow hidden/scroll container, but geometrically you need the tethered element to sit/extend outside of the container (so\u2014for now at least\u2014its DOM node needs to be outside of the container).[0] https://tetherjs.devreply",
      "Any day now, Firefox.reply",
      "Anchor positioning sounds cool, but I ran into some very unintuitive behavior when I tried to use it. Can\u2019t remember the details, it was a couple years ago.reply",
      "My problem is always been on sites that have a menu or something similar at the top. The anchor always inevitably goes to the very top of the screen gets covered by whatever menu it is.reply",
      "Isnt there something like scroll-padding or scroll-margin? More or less an offset you can set so that doesn\u2019t happenreply",
      "Anchor postreply"
    ],
    "link": "https://webkit.org/blog/17240/a-gentle-introduction-to-anchor-positioning/",
    "first_paragraph": "Aug 12, 2025by Saron YitbarekAnchor positioning allows you to place an element on the page based on where another element is. It makes it easier to create responsive menus and tooltips with less code using only CSS. Here\u2019s how it works.Let\u2019s say you have an avatar in your nav, like this:When you click the avatar, you want a menu to appear right below it. The clicking interaction can be handled with just CSS using the Popover API. But once you click, where does your menu show up?Figuring this out typically requires some JavaScript. But now, with anchor positioning, you can accomplish this with just a few lines of CSS. Anchor positioning will use where the avatar is to determine where the menu will go.For example, you might want to place it just below the avatar, nice and left-aligned, like this:Or you can have it hang out on the side of the avatar, having a party off to the right, like this:You can position it in a number of places, but I think that first example looks good. It\u2019s someth"
  },
  {
    "title": "Training language models to be warm and empathetic makes them less reliable (arxiv.org)",
    "points": 205,
    "submitter": "Cynddl",
    "submit_time": "2025-08-12T13:32:16 1755005536",
    "num_comments": 210,
    "comments_url": "https://news.ycombinator.com/item?id=44875992",
    "comments": [
      "The more and I am using Gemini (paid, Pro) and ChatGPT (free) the more I am thinking - my job isn't going anywhere yet. At least not after the CxOs have all gotten their cost-saving-millions-bonuses and work has to be done again.My goodness, it just hallucinates and hallucinates. It seems these models are designed for nothing other than maintaining an aura of being useful and knowledgeable. Yeah, to my non-ai-expert-human eyes that's what it seems to me - these tools have been polished to project this flimsy aura and they start acting desperately the moment their limits are used up and that happens very fast.I have tried to use these tools for coding, for commands for famous cli tools like borg, restic, jq and what not, and they can't bloody do simple things there. Within minutes they are hallucinating and then doubling down. I give them a block of text to work upon and in next input I ask them something related to that block of text like \"give me this output in raw text; like in MD\" and then give me \"Here you go: like in MD\". It's ghastly.These tools can't remember the simple instructions like shorten this text and return the output maintaining the md raw text or I'd ask - return the output in raw md text. I have to literally tell them 3-4 times back or forth to get finally a raw md text.I have absolutely stopped asking them for even small coding tasks. It's just horrible. Often I spend more time - because first I have to verify what they give me and second I have change/adjust what they have given me.And then the broken tape recorder mode! Oh god!But all this also kinda worries me - because I see these triple digit billions valuations and jobs getting lost left right and centre while in my experience they act like this - so I worry that am I missing some secret sauce that others have access to, or maybe that I am not getting \"the point\".reply",
      "Once heard a good sermon from a reverend who clearly outlined that any attempt to embed \"spirit\" into a service, whether through willful emoting, or songs being overly performary, would amount to self-deception since aforementioned spirit need to arise spontaneously to be of any real value.Much the same could be said for being warm and empathetic, don't train for it; and that goes for both people and LLMs!reply",
      "As a parent of a young kid, empathy definitely needs to be trained with explicit instruction, at least in some kids.reply",
      "And for all kids and adults and elderly, empathy needs to be encouraged, practiced and nurtured.reply",
      "Some would argue empathy can be a bad thinghttps://en.wikipedia.org/wiki/Against_EmpathyAs it frequently is coded relative to a tribe.  Pooh Pooh people\u2019s fear of crime and disorder for instance and those people will think you don\u2019t have empathy for them and vote for somebody else.reply",
      "It feels like he just defines empathy in a way that makes it easy to attack.Most people when they talk about empathy in a positive way, they're talking about the ability to place oneself in another's shoes and understand why they are doing what they are doing or not doing, not necessarily the emotional mirroring aspect he's defined empathy to be.reply",
      "> not necessarily the emotional mirroring aspect he's defined empathy to be.The way the wikipedia article describes Bloom's definition is less generous than what you have here> For Bloom, \"[e]mpathy is the act of coming to experience the world as you think someone else does\"[1]: 16So for bloom it is not necessarily even accurately mirroring another's emotions, but only what you think there emotions are.> Bloom also explores the neurological differences between feeling and understanding, which are central to demonstrating the limitations of empathy.This seems to artificial separate empathy and understanding in a way that does not align with common usage and I would argue also makes for a less useful definition in that I would then need new words to describe what I currently use 'empathy' for.reply",
      "Surely you can empathize with an act? In fact it's probably a requirement in order to be able to enjoy cinema and theater.And actors aren't the only ones that pretend to be something they are not.If you don't want to distinguish between empathy and understanding, a new term has to be introduced about mirroring the emotions of a mirage. I'm not sure the word for that exists?",
      "You have put into words way better what I was attempting to say at first. So yeah, this.reply",
      "Society is hardly suffering from a lack of empathy these days. If anything, its institutionalization has become pathological.I\u2019m not surprised that it makes LLMs less logically coherent. Empathy exists to short-circuit reasoning about inconvenient truths as to better maintain small tight-knit familial groups.reply"
    ],
    "link": "https://arxiv.org/abs/2507.21919",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Show HN: Omnara \u2013 Run Claude Code from anywhere (github.com/omnara-ai)",
    "points": 204,
    "submitter": "kmansm27",
    "submit_time": "2025-08-12T16:33:38 1755016418",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=44878650",
    "comments": [
      "This is pretty cool and feels like we're heading in the right direction, the whole idea of being able to hop between devices while claude code is thinking through problems is neat, but honestly what excites me more is the broader pattern here, like we're moving toward a world where coding isn't really about sitting down and grinding out syntax for hours, it's becoming more about organizing tasks and letting ai agents figure out the implementation details.I can already see how this evolves into something where you're basically managing a team of specialized agents rather than doing the actual coding, you set up some high-level goals, maybe break them down into chunks, and then different agents pick up different pieces and coordinate with each other, the human becomes more like a project manager making decisions when the agents get stuck or need direction, imho tools like omnara are just the first step toward that, right now it's one agent that needs your input occasionally, but eventually it'll probably be orchestrating multiple agents working in parallel, way better than sitting there watching progress bars for 10 minutes.reply",
      "Exactly! My ideal vision for the future is that agents will be doing all grunt work/implementation, and we'll just be guiding them.Can't wait til I'm coding on the beach (by managing a team of agents that notify me when they need me), but it might take a few more model releases before we get there lolreply",
      "What happens is the status quo changes. Like what happened with Dev/Ops. If you find yourself with the time to lead agents on a beach retreat you might find yourself pulled into more product design / management meetings instead. AI/Dev like DevOps. Wearing more hats as a result. Maybe I'm wrong though.reply",
      "If you think you could do that on the beach, couldn't you do traditional software dev on the beach?I actually think there's a chance it will shift away from that because it will shift the emphasis to fast feedback loops which means you are spending more of your time interacting with stakeholders, gathering feedback etc. Manual coding is more the sort of task you can do for hours on end without interruption (\"at the beach\").reply",
      "someone at the leadership is also thinking how he/she can lower head count by removing the agent masterreply",
      "I did exactly that all this summer at the beach with Claude code. Future is already here!reply",
      "Seems like your vision is to let AI take over your livelihood. That\u2019s an unusually chipper way to hand over the keys unless you have a lifetime of wealth stashed away.reply",
      "It depends on what their livelihood is.If their livelihood is solving difficult problems, and writing code is just the implementation detail the gotta deal with, then this isn\u2019t gonna do much to threaten their livelihood. Like, I am not aware of any serious SWE (who actually designs complex systems and implements them) being genuinely worried about their livelihood after trying out AI agents. If anything, that makes them feel more excited about their work.But if someone\u2019s just purely codemonkeying trivial stuff for their livelihood, then yeah, they should feel threatened. I have a feeling that this isn\u2019t what the grandparent comment user does for a living tho.reply",
      "What will you have to offer when coding is so easy at that point?reply",
      "I still think that human taste is important even if agents become really good at implementing everything and everyone's just an idea guy. Counter argument: if agents do become really good at implementation, then I'm not sure if even human taste would matter if agents could brute force every possibility and launch it into the market.Maybe I'll just call it a day and chill with the famreply"
    ],
    "link": "https://github.com/omnara-ai/omnara",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Omnara (YC S25) - Talk to Your AI Agents from Anywhere!\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Your AI workforce launchpad, in your pocket.\n\n\n\n\n\ud83d\udcf1 Download iOS App \u2022 \ud83c\udf10 Try Web Dashboard \u2022 \u2b50 Star on GitHubOmnara transforms your AI agents (Claude Code, Cursor, GitHub Copilot, and more) from silent workers into communicative teammates. Get real-time visibility into what your agents are doing, respond to their questions instantly, and guide them to success - all from your phone.The moment your agent needs help, you're there. No more returning to failed jobs hours later.We built Omnara because we were tired of:Now you can:Launch Claude to review PRs while you're at lunch. Get notified only if it needs clarification on architectural decisions.Debug product"
  },
  {
    "title": "Multimodal WFH setup: flight SIM, EE lab, and music studio in 60sqft/5.5M\u00b2 (sdo.group)",
    "points": 180,
    "submitter": "brunohaid",
    "submit_time": "2025-08-09T11:48:24 1754740104",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=44845787",
    "comments": [
      "Oh, didn't think that'd make it to the front page, appreciated! OP and builder here.The website was purely because a friend and I were looking for design work during lockdown and put together a couple of things we recently worked on, but basic design and build was a fun ~6 months solo project.We had a good discussion on https://www.reddit.com/r/architecture/comments/1mlo6hu/tryin... over the weekend with more details, but also happy to answer any questions here.reply",
      "Sick flight sim setup!I basically never sim now because of how much of a hassle it is to get the whole thing setup. And then it just sits taking up space on the desk and I don't use the desktop for anything else for a while.reply",
      "Thanks! And: Same. It got much better since the early days of MSFS 2020, and tried picking gear that has solid drivers/good scripting APIs, but I also rarely get it out just for fun, for the same reasons (except the occasional barrel rolls in a TBM over Manhattan cravings). It is great to have for a bunch of practice runs before actually heading to a new airport for the first time though.reply",
      "It looks great, but, (no offense), that looks like the most uncomfortable home-office seating arrangement of all time.  Your legs can't fit under the desk, and the low-back chair looks like it's for show, not sitting.  I fear for your back!reply",
      "None taken! Cut the shelving to my (elbows at 90 degrees) standing desk height and used it that way about 80% of the time, and for the rest the drafting height barstool like chair worked well, as the legs are naturally angled.reply",
      "Hi, where do you get your industrial shelving?reply",
      "https://www.globalindustrial.com/c/storage/shelving/boltless...reply",
      "I have a workbench from GI. It\u2019s built like a tank and looks good, with a Boos Brothers solid maple top. YMMV but when I told them a big part of it came bent in shipping, they DGAF. That was not a good experience.reply",
      "site down because of us :Dreply",
      "That's a lot of words for \"We put some industrial shelving in a closet with a keyboard and computer monitors, and we made it all beige.\"reply"
    ],
    "link": "https://www.sdo.group/study",
    "first_paragraph": ""
  },
  {
    "title": "Blender is Native on Windows 11 on Arm (thurrott.com)",
    "points": 115,
    "submitter": "thunderbong",
    "submit_time": "2025-08-09T02:26:48 1754706408",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=44843586",
    "comments": [
      "Nice!  I would expect that it was relatively straight foward given that Blender is native on MacOS ARM and also iOS ARM?Blender is just so nice to use these days.reply",
      "For us (Wireshark) the difficulty wasn't with our own codebase, but with getting our dependencies ported over. Most libraries built just fine, but some strongly assumed that \"Windows\" meant \"x86\".It's not just Windows, either. Many libraries (particularly ones that use Autotools) are absolutely blind to the notion that you might want a universal binary on macOS.reply",
      "When we ported OpenJDK to macOS, I ended up producing a universal binary by having the Makefile run itself to produce HotSpot twice, and then gluing them together with `lipo` afterwards. There isn't really a better way when the actual project configurations are different.IIRC it was eventually removed because nobody else needed to do such a thing so it was hard to maintain.reply",
      "Sure. How else would you build a universal binary then? Given the low-level nature of the language not many tasks can be usefully shared between different architectures.reply",
      "For plain C/C++ you can just pass `-arch x86_64 -arch arm64` to clang. CMake takes care of this for you if you specify `CMAKE_OSX_ARCHITECTURES=x86_64;arm64` and IIRC Meson has similar functionality.reply",
      "I assume this is faster than doing two separate builds, because it can skip certain steps of the complier pipeline, and only the items that are arch specific (codegen, probably others) are done twice?reply",
      "TIL. I didn't know clang supports this natively.reply",
      "Clang is natively a cross-compiler. Pass in --sysroot and a corresponding valid sysroot tree for any micro architecture/platform (arm-eabi, macOS, Windows MSVC, PowerPC, Alpine Linux with musl, you name it) and Clang will happily retarget the binary to the correct target platform.reply",
      "And Linux ARM, I would expect?reply",
      "Yes, Blender was native on my ARM phone several years ago already - until its GPU requirements went up.reply"
    ],
    "link": "https://www.thurrott.com/music-videos/324346/blender-is-native-on-windows-11-on-arm",
    "first_paragraph": "\nWith all the major applications now available natively on Windows 11 on Arm, Qualcomm is working with developers to fill in the gaps. And so now the Blender open source 3D creation app is available natively on the platform, too.\u201cOver a year ago, thanks to the joint efforts of Microsoft, Linaro, and Qualcomm, the ambitious project of porting Blender to the ARM64 architecture running Windows (WoA) began,\u201d the Blender announcement notes. \u201cWith Qualcomm\u2019s significant support as a Patron-level member of the Blender Development Fund, the core development team was able to review and iterate on this project. As a result, Blender can now run on hardware powered by Windows on processors such as the Qualcomm Snapdragon.\u201dSign up for our new free newsletter to get three time-saving tips each Friday \u2014 and get free copies of Paul Thurrott's Windows 11 and Windows 10 Field Guides (normally $9.99) as a special welcome gift!\"*\" indicates required fields\u0394Blender 4.3 was the first to run natively on Wind"
  },
  {
    "title": "The Missing Protocol: Let Me Know (deanebarker.net)",
    "points": 75,
    "submitter": "deanebarker",
    "submit_time": "2025-08-12T20:15:17 1755029717",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=44881287",
    "comments": [
      "This could be even easier to implement than the author suggests, at least for the cited use case of when a new web page is published (e.g. Part 2 of an article). The simplest solution--assuming you know what the URL will be--is to have your agent of choice periodically check whether that URL returns 200. That greatly simplifies the protocol since it piggy-backs off the existing HTTP protocol, and makes it easy to write your agent (or use an existing one). All that's left would be for authors to publish what the next URL will be; nothing else on the back end is needed.reply",
      "Isn't this what RSS is for though?reply",
      "That's an example of the type of existing agent that I was alluding to. So you're not wrong, but it doesn't change what I was suggesting.reply",
      "It could be implemented as some type of extension to RSS.reply",
      "No extension is necessary.  There's nothing that says a website has to have exactly 1 or 0 RSS feeds for global syndication.  Anyone in control of their site can dump a plain ol' RSS feed (or Atom, or JSON) feed at /foo/part-3-is-posted.xml.  I've done this on my own site.This is not (really) a technical problem.  It's a cultural one\u2014getting people to actually make these hyperspecific micro feeds available.reply",
      "100% this. Per-topic RSS feeds solves this perfectly.reply",
      "https://xkcd.com/927/You know which one.reply",
      "it's a funny comic but Unicode was created as a \"universal standard\" for character encoding and has actually been successful at it.Ditto for power adapters. Every laptop now uses USB-C instead of weird barrel plugs.reply",
      "> assuming you know what the URLThis is the tricky bit thou and will come down to chicken and egg problem of adopting some conventionreply",
      "Actually it's super-easy, barely an inconvenience.Dedicate a portion of your site to notifications. Allocate the URL there with a blank page that has a meta 404 tag or something.When blog post is live, replace the meta 404 with a meta redirect to the real permalink.You can do an all-manual URL shortener for QR codes the same way. That means you can also have a QR code for this kind of subscription, which is coolreply"
    ],
    "link": "https://deanebarker.net/tech/blog/let-me-know/",
    "first_paragraph": "\n                \u2191 Back to Tech Blog\nI want a new protocol, tentatively called \u201cLet Me Know\u201d (LMK). The purpose is to provide someone an anonymous way to get notified when a singular, specific event occurs.Here\u2019s a basic use case:Some random blog author has published Parts 1 and 2 of a series. You enjoyed it, and you want to know when Part 3 is published.You don\u2019t want to give away any personal information, you don\u2019t want to subscribe to an RSS feed of other content, you don\u2019t want to follow them on social media, etc. You just want an anonymous way to find out when Part 3 is published without having to manually check their website and evaluate it for the content.My idea is that there\u2019s a button at the bottom of Part 2, called \u201cLet Me Know.\u201dThe user clicks this, and it registers an endpoint with some agent.Whatever agent registers the endpoint will ping the end point at a specific interval. Let\u2019s say once per day by default.The endpoint will often simply return:Or:Either of those respon"
  },
  {
    "title": "AI Eroded Doctors' Ability to Spot Cancer Within Months in Study (bloomberg.com)",
    "points": 26,
    "submitter": "zzzeek",
    "submit_time": "2025-08-13T00:51:21 1755046281",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44883475",
    "comments": [
      "But it sounds like with AI doctors did better overall, or that is how I read the first couple of lines. If that is true, I don't really see a problem here.  Compilers have eroded my ability to write assembly, that is true.  If compilers went away, I would get back up to speed in a few weeks.reply",
      "The compiler example is very helpful, thanks for posting it.My follow up question is now \u201cif junior doctors are exposed to AI through their training is doctor + AI still better overall?\u201d e.g. do doctors need to train their \u2018eye\u2019 without using AI tools to benefit from them.reply",
      "if the hospital IT system is temporarily down, i certainly expect my doctors to still be able to do their job. So it is a  (small) problem that needs addressing.Perhaps a monthly session to practice their skills would be useful? So they don\u2019t atrophe\u2026reply",
      "> if the hospital IT system is temporarily downI think we have to treat the algorithm as a medical tool here, whose maintenance will be prioritised as such. So your premise is similar to \"If all the scalpels break...\".reply",
      "I\u2019m think you might agree, though, that the likelihood of one premise is significantly greater than the other!",
      "The stakes of a colonoscopy are typically way, way higher than your typical assembly projects.reply",
      "You would get back up to speed in a few weeks. The guy who comes after you and never had formative years writing assembly would never get to the level you were at.reply",
      "https://archive.ph/whVMIreply",
      "I know it\u2019s lowering my programming ability. I\u2019m forgetting a lot syntax.My solution is increase the amount I write purely by hand.reply",
      "Should be in the first, not seventh paragraph: this was a survey of 19 doctors, who performed ~1400 colonoscopies.reply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2025-08-12/ai-eroded-doctors-ability-to-spot-cancer-within-months-in-study",
    "first_paragraph": ""
  },
  {
    "title": "WHY2025: How to become your own ISP [video] (ccc.de)",
    "points": 91,
    "submitter": "exiguus",
    "submit_time": "2025-08-12T16:53:37 1755017617",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44878916",
    "comments": [
      "LIR and resource fees at RIPE are too damn high compared to ARIN. Europe is hurting itself by punishing small entities.reply",
      "I got my own ASN a few months ago (and am in the three+ year waiting list for an IPv4 block), I've been thinking about trying to become a rural ISP in my area, so this is very timely for me.reply",
      "If you want someone to bounce ideas off of, I've been involved in that space for a very long time and could probably answer a lot of questions with real world experience, regardless of the technology used.reply",
      "I sincerely appreciate the offer, and would love to take you up on it! My email is available from my profile (via my website), or feel free to grab some time: https://cal.bsprague.com/meetI've mostly looked at wireless (we're in a valley) and fiberreply",
      "If you have serious intentions of starting an ISP, I'd recommend beginning conversations with a few transit providers right away, feeling out rates and commit terms. Armed with some market info and contacts there, start to look at v4 auctions via [0] or similar so you can jump the line, though you'll have to pay for the privilege. You probably won't be able to transfer blocks into your org until you have commits from one or more upstreams (I know ARIN, and I'm assuming you're in north america, has some more stringent reqs in terms of overall usage within a specified time period, so choose the auction size appropriately [1]). You may also want to consider taking a block from your transit, they will often reassign a small prefix out of their larger holdings for customer use. You can often use that as justification for transferring future blocks.After transit, start to look at facilities to host your equipment, 'cause you'll need to demarc somewhere and hand off to your transit as well.Lots and lots of details to get right, but I personally think it's a lot of fun.[0] https://auctions.ipv4.global/[1] https://www.arin.net/participate/policy/nrpm/#eight5reply",
      "Thanks for the tips! Being in a rural area, there's only a few colocation facilities within ~50 miles, and I need to reach out to them to see who they're connected to. So far, I've only seen that Cogent has a presence here, but the internet doesn't have good things to say about themreply",
      "> I've only seen that Cogent has a presence here, but the internet doesn't have good things to say about themThey\u2019re good enough and they\u2019re dirt cheap. Pricing really matters since you pass savings on to your customers. Vermont Telecom, as an example of a reasonably sized regional ISP with thousands of customers, uses Cogent as their primary upstream.I wouldn\u2019t fall into the trap of trying to build something out using hardware or upstream providers that people on Internet forums that don\u2019t have a financial stake in making an ISP work financially and operationally approve of.reply",
      "I think Cogent has earned their vibes, but if they're all you can get near you, they're ok enough to get started with.As you get bigger, you can put a router somewhere (or two somewheres) with cogent and more options and transport through cogent to get back to your service area. Looking at your profile, I think if you can get traffic to Denver, you should have more options there.reply",
      "Cogent is fine for most purposes. They have some odd choices upstream at times but for a smaller project, it shouldn\u2019t be a problem. Later on you could look at a dedicated wave or ring (or tunnel, lots of options!) to another facility that has more diversity and peer through that, but make it work first!reply",
      "This is great! I wonder how much the presenters country - the Netherlands - has made this easier with the peering. It\u2019s hard for me to imagine just asking big serious networks to patch you in down here in Switzerland is likely to fly.reply"
    ],
    "link": "https://media.ccc.de/v/why2025-9-how-to-become-your-own-isp",
    "first_paragraph": "\n\nNick Bouwhuis\n\nThis talk will take you along with a deep dive on how the internet works at its core and how you can participate yourself. You'll learn all about BGP, AS- numbers, IP-prefixes and more.\nEver wanted to become sovereign on the internet? Want to know what its like to run an ISP? Are you a sysadmin that wants to learn more about networking? Then you're at the right place.\nThis talk will take you along with a deep dive on how the internet works at its core and how you can participate yourself. You'll learn all about BGP, AS- numbers, IP-prefixes and what you need to do if you want to participate. You will walk away with practical knowledge on how you can get started. \nWe'll also take a short tour of my own network, how I set it up and what I use it for.\nLicensed to the public under https://creativecommons.org/licenses/by/4.0/\nThis talk will take you along with a deep dive on how the internet works at its core and how you can participate yourself. You'll learn all about BGP,"
  },
  {
    "title": "Launch HN: Design Arena (YC S25) \u2013 Head-to-head AI benchmark for aesthetics",
    "points": 61,
    "submitter": "grace77",
    "submit_time": "2025-08-12T16:10:03 1755015003",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=44878257",
    "comments": [
      "This is actually really needed, current ai design tools are so predictable and formulaic, like every output feels like the same purple gradients with rounded corners and that one specific sans serif font that every model seems obsessed with, it's gotten to the point where you can spot ai-generated designs from a mile away because they all have this weird sterile aesthetic that screams \"made by a model\"reply",
      "Exactly - we think the ai design tools are in the equivalent of the 'uncanny valley' territory that a lot of the diffusion models were stuck in just 1-2 months ago; most average diffusion models are still in this local optimum, but the best of the best seem to have escaped it.reply",
      "I don't think this works right now tbh.It has the same problem as LMArena (which already had webarena): better aesthetics are so far out of distribution you can't even train on the feedback you get here.You just get a new form of turbo-slop as some hidden preference takes over. With text output that ended up being extensive markdown and emojis. Here that might be people accidentally associating frosted surfaces with relatively better aesthetics, for example.The problem is so bad LMArena maintains a seperate ranking where they strip away styling entirelyreply",
      "This is interesting but, speaking frankly, I see many seemingly insurmountable issues. Here are some:- Contests will often be won not by the entry that best adhered to the prompt, but the best-looking one. This happened in the contest \"Input Prompt\nBuild a brutalist website to a typeface maker,\" which I got as a recent example. The winning entry had megawatt-bright magenta and yellow, which shouldn't appear anywhere near brutalism, and in other design aspects had almost no connection to brutalism either -- but it was the most attractive of the bunch.- The approach only gets you to a local maximum. Current LLMs aren't very good designers, as you say, so contests will involve picking between mostly middling entries. You'd want a design that's, say, a 9 or a 10 on a 10-point scale -- but some 95% of the entry distribution will probably be between 5.5 and 7.5 or so, and that's what users will get to pick from.reply",
      "All great points. A limitation with human feedback is that once you start asking for more than binary preferences (e.g. multiple rankings or written feedback), the quality of the feedback does decrease. For instance, many times humans can give a quick answer on preference, but when asked \"why\" they prefer one thing over the other, they might not be able to full explain it in language. This in general is very much an open area of research on collecting and incorporating the most optimal types of feedback.I definitely agree with your second point. One idea we're experimenting with is adding a human baseline, in which the models are benchmarked against human generated designs as well.reply",
      "yes! to the second point, someone in our show HN proposed encouraging human designers to compete in submissions as well - we tried implementing this and found that, at least right now, LLMs are still so bad at design that asking a human to beat them is trivial - our plan right now is to focus more on this once it becomes more of challenges and therefore hopefully more interesting/entertainingreply",
      "Great concept \u2014 definitely needed and will hopefully push the labs to improve design abilities of models!reply",
      "Yes, exactly. We want to be a forcing function for better design models and agents.reply",
      "Cool - do you train model that will be the proxy from the votes of persons?reply",
      "we're not training models or proxying human votes with modelsreply"
    ],
    "link": "item?id=44878257",
    "first_paragraph": ""
  },
  {
    "title": "LLMs aren't world models (yosefk.com)",
    "points": 222,
    "submitter": "ingve",
    "submit_time": "2025-08-10T11:40:14 1754826014",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=44854518",
    "comments": [
      "Language models aren't world models for the same reason languages aren't world models.Symbols, by definition, only represent a thing.  They are not the same as the thing.  The map is not the territory, the description is not the described, you can't get wet in the word \"water\".They only have meaning to sentient beings, and that meaning is heavily subjective and contextual.But there appear to be some who think that we can grasp truth through mechanical symbol manipulation.  Perhaps we just need to add a few million more symbols, they think.If we accept the incompleteness theorem, then there are true propositions that even a super-intelligent AGI would not be able to express, because all it can do is output a series of placeholders.  Not to mention the obvious fallacy of knowing super-intelligence when we see it.  Can you write a test suite for it?reply",
      "> Symbols, by definition, only represent a thing.This is missing the lesson of the Yoneda Lemma: symbols are uniquely identified by their relationships with other symbols. If those relationships are represented in text, then in principle they can be inferred and navigated by an LLM.Some relationships are not represented well in text: tacit knowledge like how hard to twist a bottle cap to get it to come off, etc. We aren't capturing those relationships between all your individual muscles and your brain well in language, so an LLM will miss them or have very approximate versions of them, but... that's always been the problem with tacit knowledge: it's the exact kind of knowledge that's hard to communicate!reply",
      "I don\u2019t think it\u2019s a communication problem as much as there is no possible relation between a word and a (literal) physical experiences. They\u2019re, quite literally, on different planes of existence.reply",
      "When I have a physical experience, sometimes it results in me saying a word.Now, maybe there are other possible experiences that would result in me behaving identically, such that from my behavior (including what words I say) it is impossible to distinguish between different potential experiences I could have had.But, \u201ccaused me to say\u201d is a relation, is it not?Unless you want to say that it wasn\u2019t the experience that caused me to do something, but some physical thing that went along with the experience, either causing or co-occurring with the experience, and also causing me to say the word I said. But, that would still be a relation, I think.reply",
      "Yes, but it's a unidirectional relation: it was the result of the experience. The word cannot represent the context (the experience), in a meaningful way.It's like trying to describe a color to a blind person: poetic subjective nonsense.reply",
      "Well shit, I better stop reading books then.reply",
      "> Language models aren't world models for the same reason languages aren't world models.\nSymbols, by definition, only represent a thing. They are not the same as the thing. The map is not the territory, the description is not the described, you can't get wet in the word \"water\".Symbols, maps, descriptions, and words are useful precisely because they are NOT what they represent. Representation is not identity. What else could a \u201cworld model\u201d be other than a representation? Aren\u2019t all models representations, by definition? What exactly do you think a world model is, if not something expressible in language?reply",
      "> Aren\u2019t all models representations, by definition? What exactly do you think a world model is, if not something expressible in language?I was following the string of questions, but I think there is a logical leap between those two questions.Another questions: is language the only way to define models? \nAn imagined sound or an imagined picture of an apple in my minds-eye are models to me, but they don't use language.reply",
      "> Symbols, by definition, only represent a thing. They are not the same as the thingFirst of all, the point isn't about the map becoming the territory, but about whether LLMs can form a map that's similar to the map in our brains.But to your philosophical point, assuming there are only a finite number of things and places in the universe - or at least the part of which we care about - why wouldn't they be representable with a finite set of symbols?What you're rejecting is the Church-Turing thesis [1] (essentially, that all mechanical processes, including that of nature, can be simulated with symbolic computation, although there are weaker and stronger variants). It's okay to reject it, but you should know that not many people do (even some non-orthodox thoughts by Penrose about the brain not being simulatable by an ordinary digital computer still accept that some physical machine - the brain - is able to represent what we're interested in).> If we accept the incompleteness theoremThere is no if there. It's a theorem. But it's completely irrelevant. It means that there are mathematical propositions that can't be proven or disproven by some system of logic, i.e. by some mechanical means. But if something is in the universe, then it's already been proven by some mechanical process: the mechanics of nature. That means that if some finite set of symbols could represent the laws of nature, then anything in nature can be proven in that logical system.\nWhich brings us back to the first point: the only way the mechanics of nature cannot be represented by symbols is if they are somehow infinite, i.e. they don't follow some finite set of laws. In other words - there is no physics. Now, that may be true, but if that's the case, then AI is the least of our worries.Of course, if physics does exist - i.e. the universe is governed by a finite set of laws - that doesn't mean that we can predict the future, as that would entail both measuring things precisely and simulating them faster than their operation in nature, and both of these things are... difficult.[1]: https://plato.stanford.edu/entries/church-turing/reply",
      "> First of all, the point isn't about the map becoming the territory, but about whether LLMs can form a map that's similar to the map in our brains.It should be capable of something similar (fsvo similar), but the largest difference is that humans have to be power-efficient and LLMs do not.That is, people don't actually have world models, because modeling something is a waste of time and energy insofar as it's not needed for anything. People are capable of taking out the trash without knowing what's in the garbage bag.reply"
    ],
    "link": "https://yosefk.com/blog/llms-arent-world-models.html",
    "first_paragraph": "August 10th, 2025I believe that language models aren\u2019t world models. It\u2019s a weak claim \u2014 I\u2019m not saying they\u2019re useless, or that we\u2019re done\nmilking them. It\u2019s also a fuzzy-sounding claim \u2014 with its trillion weights, who can prove that there\u2019s something an LLM isn't a\nmodel of? But I hope to make my claim clear and persuasive enough with some examples.A friend who plays better chess than me \u2014 and knows more math & CS than me - said that he played some moves against a\nnewly released LLM, and it must be at least as good as him. I said, no way, I\u2019m going to cRRRush it, in my best Russian accent.\nI make a few moves \u2013 but unlike him, I don't make good moves1, which would be opening book moves it has seen a million times; I make weak moves, which it\nhasn't 2. The thing makes decent moves in\nresponse, with cheerful commentary about how we're attacking this and developing that \u2014 until about move 10, when it tries to\nmove a knight which isn't there, and loses in a few more moves. This was a year"
  },
  {
    "title": "Go 1.25 Release Notes (go.dev)",
    "points": 106,
    "submitter": "bitbasher",
    "submit_time": "2025-08-12T21:25:01 1755033901",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44881977",
    "comments": [
      "New `encoding/json/v2` package (hidden behind `GOEXPERIMENT=jsonv2` flag)! It brings perf improvements and finally allows devs to implement custom marshalers for external types:> Alternatively, users can implement functions that match MarshalFunc, MarshalToFunc, UnmarshalFunc, or UnmarshalFromFunc to specify the JSON representation for arbitrary types. This provides callers of JSON functionality with control over how any arbitrary type is serialized as JSON.Awesome stuff.reply",
      "I just love how this language marches forward. I have so many colleagues that hate many aspects of it but I sit here combining Go, Goa and SQLc writing mountains of code and having a fairly good compiler behind me. I understand what I\u2019m missing out on by not using stricter languages and so often it\u2019s a totally fine trade off.reply",
      "I've gotten used to golang, though it's still not my favourite language to program in by any stretch. One issue I've been having, though, is the documentation.Documentation for third-party modules in Python is fantastic, almost universally so. In nearly every case of using a third-party library, large or small, there's sufficient documentation to get up and running.Golang libraries, however, seem to be the opposite. In most cases there's either no documentation whatsoever on how to use things, or, more commonly, there is example code in the readme which is out of date and does not work at all.The IDE integration with golang is great, and it makes some of this a bit easier, but I also still get a ton of situations where my editor will offer some field or function that looks like what I want (and is what I'm typing to see if it will autocomplete) but once I select it it complains that there's no such field or function. Still haven't figured that out.So yeah, I dunno. The language is 'great'; it certainly has some extreme strengths and conveniences, like the fact that 'run this function with these arguments in a separate thread' is a language keyword and not some deep dive into subprocess or threading or concurrent.futures; the fact that synchronization functionality is trivially easy to access; Sync.Once feels so extremely obvious for a language where concurrency is king, and so on.Still, the ecosystem is... a bit of a mess, at the best of times. Good modules are great, all other modules are awful.reply",
      "I quite frankly will just read the code. Go generally discourages abstractions so any code you jump into is fairly straightforward (compared to a hierarchy of abstract classes, dependency injected implementations, nested pattern matching with destructuring etc etc).Regarding your IDE issues- I\u2019ve found the new wave of copilot/cursor behavior to be the culprit. Sometimes I just disable it and use the agent if I want it to do something. But it\u2019ll completely fail to suggest an auto complete for a method that absolutely exists.reply",
      "> Go generally discourages abstractions so any code you jump into is fairly straightforwardThis is a really anti-intellectual take.  All of software engineering is about building abstractions.  Not having abstractions makes the structure less easy to understand, and forces developers to repeat themselves and use brittle hacks.  It's not a way to build robust or maintainable software.",
      "I did not like it at first but it has grown on me. I still have my gripes, which are mostly things that come from its overall architecture and will never be resolved, but it is pretty enjoyable to use for the limited domain I use it in at work.reply",
      "> LookupMX and Resolver.LookupMX now return DNS names that look like valid IP address, as well as valid domain names. Previously if a name server returned an IP address as a DNS name, LookupMX would discard it, as required by the RFCs. However, name servers in practice do sometimes return IP addresses.This one is interesting; which servers return an IP address as a record? Why would they want to do this?reply",
      "Yay new version! Not the most exciting (as Go releases tend to be which is good), but hopefully jsonv2 and greentea can get some testing and be standard in 1.26reply",
      "> greenteaI didn't know what it is and had to look it up. Looks like a new GC.https://github.com/golang/go/issues/73581reply",
      "1.25 tag was released; https://github.com/golang/go/releases/tag/go1.25.0reply"
    ],
    "link": "https://go.dev/doc/go1.25",
    "first_paragraph": "Common problems companies solve with GoStories about how and why companies use GoHow Go can help keep you secure by defaultThe official Go language specificationA complete introduction to building software with GoReference documentation for Go's standard libraryLearn what's new in each Go releaseTips for writing clear, performant, and idiomatic Go codeVideos from prior eventsMeet other local Go developersLearn and network with Go developers from around the worldThe Go project's official blog.Get help and stay informed from GoThe latest Go release, version 1.25, arrives in August 2025, six months after Go 1.24.\nMost of its changes are in the implementation of the toolchain, runtime, and libraries.\nAs always, the release maintains the Go 1 promise of compatibility.\nWe expect almost all Go programs to continue to compile and run as before.There are no languages changes that affect Go programs in Go 1.25.\nHowever, in the language specification the notion of core types\nhas been removed in f"
  },
  {
    "title": "Why are there so many rationalist cults? (asteriskmag.com)",
    "points": 383,
    "submitter": "glenstein",
    "submit_time": "2025-08-12T14:56:53 1755010613",
    "num_comments": 582,
    "comments_url": "https://news.ycombinator.com/item?id=44877076",
    "comments": [
      "I think the comments here have been overly harsh. I have friends in the community and have visited the LessWrong \"campus\" several times. They seemed very welcoming, sincere, and were kind and patient even when I was basically asserting that several of their beliefs were dumb (in hopefully somewhat respectful manner).As for the AI doomerism, many in the community have more immediate and practical concerns about AI, however the most extreme voices are often the most prominent. I also know that there has been internal disagreement on the kind of messaging they should be using to raise concern.I think rationalists get plenty of things wrong, but I suspect that many people would benefit from understanding their perspective and reasoning.reply",
      "A very interesting read.My idea of these self-proclaimed rationalists was fifteen years out of date. I thought they\u2019re people who write wordy fan fiction, but turns out they\u2019ve reached the point of having subgroups that kill people and exorcise demons.This must be how people who had read one Hubbard pulp novel in the 1950s felt decades later when they find out he\u2019s running a full-blown religion now.The article seems to try very hard to find something positive to say about these groups, and comes up with:\u201cRationalists came to correct views about the COVID-19 pandemic while many others were saying masks didn\u2019t work and only hypochondriacs worried about covid; rationalists were some of the first people to warn about the threat of artificial intelligence.\u201dThere\u2019s nothing very unique about agreeing with the WHO, or thinking that building Skynet might be bad\u2026 (The rationalist Moses/Hubbard was 12 when that movie came out \u2014 the most impressionable age.) In the wider picture painted by the article, these presumed successes sound more like a case of a stopped clock being right twice a day.reply",
      "The WHO didn't declare a global pandemic until March 11, 2020 [1]. That's a little slow and some rationalists were earlier than that. (Other people too.)After reading a warning from a rationalist blog, I posted a lot about COVID news to another forum and others there gave me credit for giving the heads-up that it was a Big Deal and not just another thing in the news. (Not sure it made all that much difference, though?)[1] https://pmc.ncbi.nlm.nih.gov/articles/PMC7569573/reply",
      "Yeah that paragraph was really sad, where I stopped reading even. Both of those beliefs are dead wrong and they are the best examples the author could find to defend this delusional and dangerous belief system.The \"threat of AI\" they're claiming validates rationalism doesn't exist. These loons were the reason Google sat on their LLMs and made their image models only draw pictures of robots, because of the supposed \"threat\" of AI. Now everyone can run models way better on their own laptops and the sky hasn't fallen, there hasn't even been mass unemployment or anything. Not even the weakest version of this belief has proven true. AI is very friendly, even.And masks? How many graphs of cases/day with mask mandate transitions overlayed are required before people realize masks did nothing? Whole countries went from nearly nobody wearing them, to everyone wearing them, overnight, and COVID cases/day didn't even notice. You can't look at a case graph and see where the rules changed. Which makes sense because SARS-CoV-2 is aerosolized and can enter through the masks, around the masks, when masks are removed and even through the eyeballs.Seems like rationalists in the end have managed to be correct about nothing. What a disappointment.reply",
      "The point of wearing a mask is to protect other people from your respiratory droplets. Please wear a mask when you're sick.reply",
      "It was genuinely difficult to persuade people to wear masks before everyone started doing it and it became normal.reply",
      "This article is beautifully written, and it's full of proper original research. I'm sad that most comments so far are knee-jerk \"lol rationalists\" type responses. I haven't seen any comment yet that isn't already addressed in much more colour and nuance in the article itself.reply",
      "> I haven't seen any comment yet that isn't already addressed in much more colour and nuance in the article itself.I once called rationalists infantile, impotent liberal escapism, perhaps that's the novel take you are looking for.Essentially my view is that the fundamental problem with rationalists and the effective altruist movement is that they are talking about profound social and political issues, with any and all politics completely and totally removed from it. It is liberal depoliticisation[1] driven to its ultimate conclusion. That's just why they are ineffective and wrong about everything, but that's also why they are popular among the tech elites that are giving millions to associated groups like MIRI[2]. They aren't going away, they are politically useful and convenient to very powerful people.[1] https://en.wikipedia.org/wiki/Post-politics[2] https://intelligence.org/transparency/reply",
      "https://en.wikipedia.org/wiki/They_Saved_Lisa%27s_Brainreply",
      "I think it's perfectly fine to read these articles, think \"definitely a cult\" and ignore whether they believe in spaceships, or demons, or AGI.The key takeaway from the article is that if you have a group leader who cuts you off from other people, that's a red flag \u2013 not really a novel, or unique, or situational insight.reply"
    ],
    "link": "https://asteriskmag.com/issues/11/why-are-there-so-many-rationalist-cults",
    "first_paragraph": "There\u2019s a lot to like about the Rationalist community, but they do have a certain tendency to spawn\u2009\u2014\u2009shall we say\u2009\u2014\u2009high demand groups. We sent a card-carrying Rat to investigate what\u2019s really going on.The rationalist community was drawn together by AI researcher Eliezer Yudkowsky\u2019s blog post series The Sequences, a set of essays about how to think more rationally. You would think, then, that they\u2019d be paragons of critical thinking and skepticism \u2014 or at least that they wouldn\u2019t wind up summoning demons. \u00a0And yet, the rationalist community has hosted perhaps half a dozen small groups with very strange beliefs (including two separate groups that wound up interacting with demons). Some \u2014 which I won\u2019t name in this article for privacy reasons \u2014 seem to have caused no harm but bad takes. But the most famous, a loose group of vegan anarchist transhumanists nicknamed the Zizians, have been linked to six violent deaths. Other groups, while less violent, have left a trail of trauma in their w"
  },
  {
    "title": "The Equality Delete Problem in Apache Iceberg (dataengineerthings.org)",
    "points": 42,
    "submitter": "dkgs",
    "submit_time": "2025-08-12T18:27:50 1755023270",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=44880081",
    "comments": [
      "I don't really get it.  If I'm understanding correctly, the goal of these CDC-to-Iceberg systems is to mirror, in near real-time, a Postgres table into an Iceberg database.  The article states, repeatedly:> In streaming CDC scenarios, however, you\u2019d need to query Iceberg for the location on every delete: introducing random reads, latency, and drastically lowering throughput under high concurrency. On large tables, real-time performance is essentially impossible.Let's consider the actual situation.  There's a Postgres table that fits on whatever Postgres server is in use.  It gets mirrored to Iceberg.  Postgres is a full-fledged relational database and has indexes and such.  Iceberg is not, although it can be scanned much faster than Postgres and queried by fancy Big Data tools (which, I agree, are really cool!).  And, notably, there is no index mapping Postgres rows to Iceberg row positions.But why isn't there?  CDC is inherently stateful -- unless someone is going to build Merkle trees or similar to allow efficiently diffing table states (which would be awesome), the CDC process need to keep enough state to know where it is.  Maybe this is O(1) in current implementations.  But why not keep the entire mapping from Postgres rows to Iceberg positions?  The Postgres database table is about N rows times however wide a row is, and it fits on a Postgres server.  The mapping needed would be about the size of a single index on the table.  Why not store it somewhere?  Updates to it will be faster than updates to the source Postgres table, so it will keep up.  Is the problem that this is awkward to do in a \"serverless\" manner?For extra fun, someone could rig up Postgres (via an extension or just some clever tables) so that the mapping is stored in Postgres itself.  It would be, roughly, one small table with CDC state and one moderate size table per mirrored table storing the row position mapping.  It could be on the same server instance or a different one.reply",
      "> Databricks recently spent $1 billion to acquire Neon, a startup building a serverless Postgres. Snowflake also spent about $250 million to acquire Crunchy Data, a veteran enterprise-grade Postgres provider.It's kinda funny to not mention that Databricks acquired Tabular, the Iceberg company, for a billion dollars: https://www.databricks.com/company/newsroom/press-releases/d...reply",
      "Another chapter of the slowly-reimplementing-Vertica saga.It's becoming clear that merge trees and compaction need to be addressed next, after delete vectors brought them onstage.Vertica will actually look up the equality keys in a relevant projection if it exists, and then use the column values in the matching rows to equality-delete from the other projections; it's fairly good at avoiding table scans.reply",
      "Data processing tools had a pricing problem. The Big Data Revolution was google and other companies realizing that commodity hardware had gotten so good that you could throw 100x as much compute at a processing job and it would still be cheaper than Oracle, Vertica, Teradata, and SQL Server.As an industry, we keep forgetting these things and reinventing the wheel because there is more money to be made squeezing enterprises than providing widely available sustainable software for a fair price and than losing mindshare to the next generation of tool and eventually getting sold for parts. It's a sad dynamicreply",
      "> Postgres and Apache Iceberg are both mature systemsApache Iceberg as mature? I mean, there's a lot of activity around it, but I remember a year ago the rust library didn't even have write capabilities. And it's not like the library is a client and there's an iceberg server - the library literally is the whole product, interacting with the files in s3reply",
      "I suppose, in fairness, the Java library has been around for much longerreply",
      "A lot of people will spend dozens of hours and tens of thousands of their company's money to avoid learning Java.I'm not even sure if I'm joking. :)reply",
      "This is data engineering, where people spend thousands of dollars of their company's money to avoid learning SQL. The place with no Java is across the street (old Soviet joke, originally for meat/fish stores).reply",
      "Sad but true. Or they learn \"something\" about SQL but not about indexes, data types, joins, or even aggregate functions. I've seen some python horror shows that would select * entire tables into lists of dicts, only to do the equivalent of a where clause and a couple of sums.reply",
      "Ouch. I was really hoping this wasn't so common, but I guess it is. I'm sure they heard somewhere that \"joins are expensive\" or something along those lines, so they solved it!reply"
    ],
    "link": "https://blog.dataengineerthings.org/the-equality-delete-problem-in-apache-iceberg-143dd451a974",
    "first_paragraph": ""
  },
  {
    "title": "Debian GNU/Hurd 2025 released (debian.org)",
    "points": 180,
    "submitter": "jrepinc",
    "submit_time": "2025-08-09T23:02:33 1754780553",
    "num_comments": 93,
    "comments_url": "https://news.ycombinator.com/item?id=44851181",
    "comments": [
      "There are \"they\"s coming up repeatedly in this discussion.I think that it's important to remember that Debian Hurd is not some massive project with thousands of anonymous people behind it.  Like Tribblix and Peter Tribble, Debian Hurd's driving force is someone whom you can name: Samuel Thibault.And although there are a few others that appear on the debian-hurd mailing list from time to time, it is amply clear that this is one of those (many) projects with a core group of very few dedicated people, with very limited resources for development and testing.  There is no many hands making light work, here.This isn't Debian as you may know it for other kernels.  (-:* https://lists.debian.org/debian-hurd/2025/07/maillist.htmlSo, in some ways, if microkernels interest you, Debian Hurd is a place to contribute where the ground has yet to be completely trodden.reply",
      "I still haven't used Hurd, and at this point with the ridiculous diversity in hardware for desktop and laptops I don't think I could realistically use it for anything outside of playing with it in a virtual machine or something.Still, a part of me wishes we lived in the alternative universe where Hurd had taken over the world instead of Linux. I don't know much about kernel design so I'm speaking out of my ass here, but I've always thought that the microkernel design was more elegant than the monolithic thing we ended up with. I don't know that the alternate universe would be \"better\", and maybe realistically a design like Hurd would never be able to take over the world like Linux, but it always seemed cooler to me.I honestly didn't really realize that they were still working on Hurd.  Does anyone here use it for anything?reply",
      "The \"gnu\" in the famous email is GNU Hurd; we're still waiting:>I'm doing a (free) operating system (just a hobby, won't be big and professional like gnu) for 386(486) AT clones.reply",
      "no it's not, the GNU system was already established by then,.and in use with other kernels.  Linus was referring to GNU as a whole, not Hurd.reply",
      "GNU was a toolchain in search of a kernel; which was supposed to be Hurd.(It often got installed on top of \u201creal\u201d Unix because it was a damn good toolchain)reply",
      "Still is.The standard tools were always sort of unergonomic on all of AIX, Sun/Solaris, DEC/Alpha, SCO,  and *BSD.I don't know but it seems people (or at least old geezers) install GNU on top of Macs these days.reply",
      "They famously did better than the proprietary shell tools in the original fuzzpocalypse https://users.cs.northwestern.edu/~robby/courses/395-495-200... . I  also think I recall reading, somewhere on jwz dot org, something which purported to be an internal SGI email giving a dismal account of the quality of the Irix tools. GNU tools often have expanded feature sets, too. But I think that GNU-tools adopters were probably also driven by a standardisation impulse to at least have the same bugs and quirks as everyone else.Yes, here it is: \u201cSoftware Usability II\u201d by Tom Davis, the \u201cIrix bloat memo\u201d https://www.seriss.com/people/erco/sgi-irix-bloat-document.t... . Mind you, that bloat would probably look very modest nowadays.reply",
      "I seem to recall the Hurd people talking about cool scenarios like filesystem drivers written entirely in user mode that don't require root.  Something like that.I booted it on real hardware sometime in the early 2000s, and it worked but was very anticlimactic.I do know that the Mach microkernel they based it on (also the basis for Apple's XNU kernel) is considered dated.  Later microkernels are supposed to have better performance.reply",
      "Yeah, that's what I've always thought was interesting about microkernels; the ability to have a lot more stuff in user space always seemed like the obvious \"correct\" direction to me.I played with RedoxOS a bit in a virtual machine a few years ago [1], and it seemed cool, so maybe that can be the logical successor to something like Hurd.[1] https://en.wikipedia.org/wiki/RedoxOSreply",
      "> I played with RedoxOS a bit in a virtual machine a few years ago, and it seemed cool, so maybe that can be the logical successor to something like Hurd.A problem with RedoxOS is that it is not GPLed: contributors have no assurance that they and others will be able to use software built with their contributions.Microsoft, Apple, Google and Facebook all have plenty of money to pay engineers; they don\u2019t need my contributions for free.reply"
    ],
    "link": "https://lists.debian.org/debian-hurd/2025/08/msg00038.html",
    "first_paragraph": ""
  }
]