[
  {
    "title": "CSS @property and the new style (ryanmulligan.dev)",
    "points": 280,
    "submitter": "surprisetalk",
    "submit_time": "2024-09-04T18:13:51.000000Z",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=41448740",
    "comments": [
      "I saw the demo CSS and remembered why I stay away from frontend development.  So much for so little\n \nreply",
      "Wow, reading this, I can _feel_ my brain resist an unfamiliar concept. I recommend people read the MDN article linked to in the first sentence before moving onto the examples in the blog.I'll have to play around with @property myself to get a sense of how it works - knowing esoteric CSS features is a superpower if you've got a complex UI to implement but wanna minimize JS dependencies.\n \nreply",
      "After reading through the mdn article I'm hopelessly confused.Isn't that literally just css variables?werent they cascading too, so the variable could be \"overwritten\" via classes etc? \nIsn't that even how tailwind does bg-opacity etc?\n \nreply",
      "I think of them as effectively CSS variables with types and that can be animated.By default CSS variables can't be animated since it has no idea what unit it's animating between\n \nreply",
      "Critically, CSS custom properties are not evaluated by default until you use them. They're more akin to preprocessor substitution. Yes, this does mean that:   calc(var(--foo) * 2)\n\ncan have a different result than:   calc((var(--foo)) * 2)\n\nSince they're basically just strings, there's no way for the animation system to interpolate between different values. `@property` fixes this allowing the immediate evaluation of the value into a concrete value that _can_ be interpolated.\n \nreply",
      "well technically the selectors cascade, so that when you have a selector that overrides another one the variable value you set in that selector takes precedence, the cool thing being that the variable is of course not just set for its element but also the subtree under the element.Since there are lots of ways to do this kind of thing, pseudo selectors, attr function etc. the ability to do dynamic and complex things from CSS, or with just CSS and HTML combined is pretty big, but as a general rule if you want to do this kind of thing statefully it is probably best to do it in JS - maintaining what variable values are in play on a particular element by setting it that way.\n \nreply",
      "What's particularly interesting about @property is that you can associate custom rendering code.  I think this website does a pretty good job showing the powers: https://houdini.how/\n \nreply",
      "I have no idea how naive this question is... but here goes.Some privacy-conscious users disable JS, or use NoScript to selectively enable JS. My understanding is that this is (1) because JS engines are often themselves a source of vulnerabilities, (2) untrusted code execution might be risky in the face of speculation execution/access attacks.Do such users need to worry about either, or both, with such advanced, compute-y CSS primitives?\n \nreply",
      "What's absolutely amazing about that is how far people go to do everything in pure CSS, without Javascript, that they put Javascript inside their CSS.\n \nreply",
      "CSS is becoming ever more like a programming language. But you cannot debug it. So why not use a programming language instead where you can do that, and can do pretty much anything you want.\n \nreply"
    ],
    "link": "https://ryanmulligan.dev/blog/css-property-new-style/",
    "first_paragraph": "The @property at-rule recently gained support across all modern browsers, unlocking the ability to explicitly define a syntax, initial value, and inheritance for CSS custom properties. It seems like forever ago that CSS Houdini and its CSS Properties and Values API were initially introduced. I experimented sparingly over time, reading articles that danced around the concepts, but I had barely scratched the surface of what @property could offer. The ensuing demo explores what's possible in the next generation of CSS.Ever seen those sleek, attention-seeking, shiny call-to-action webpage elements? Waves of sites across the web, especially the ones marketing services and software urging for you to \"Upgrade your account\" or \"Sign up today,\" have discovered the look and latched on. I'm not here to knock it and admittedly think it's kind of fresh. I thought I'd give that style a try myself. Check out the result in the CodePen below.\n\n\nOpen CodePen demo\n\nThere's a ton to unpack in this demo. L"
  },
  {
    "title": "A Real Life Off-by-One Error (leejo.github.io)",
    "points": 76,
    "submitter": "leejo",
    "submit_time": "2024-09-01T21:47:42.000000Z",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=41420672",
    "comments": [
      "Not an off-by-one error\u2014at\nleast not in spirit. Interesting nonetheless.I expected the article to eventually answer this puzzle:> The competition started and got through a number of rounds. There were some comments about how the climber on the left always won.Near the end:> The kicker is that the out of place hold hasn\u2019t been used in a long time. The climbers have optimised their route such that it is skipped. The same happens to the fourth hold from the bottom. So either being in the wrong place is immaterial to the climbers\u2019 technique as long as they don\u2019t get in the way.So it seems like the error discovered by the article author should not have conferred any advantage to the climber on the left.Anyone who can shine light on this matter?\n \nreply",
      "The climbers had complained about an issue with the belay ropes on the right side that they also fixed.> A few of the climbers had said that the automatic belay ropes on the right hand lane did not feel right, so the cherry picker was replacing those and not the hold that I had noticed being out of place. The climbers had noticed something wasn\u2019t quite right, but hadn\u2019t said anything about the out of place hold.It was probably just two separate problems.\n \nreply",
      "It may not be a fencepost error, but I think it's still off by one.\n \nreply",
      "Great find!One comment on what the article says:> If this were actual code review the correct comment would be something like \u201cthis [piece] hasn\u2019t been used for years, it should be deleted\u201d. But this is something in physical space, and there would be arguments that removing it (them) means the route has changed, thus times are no longer comparable.Hmm, I think the correct analogy is rather a benchmark. Like code in a benchmarking tool or test, the whole climbing course does not serve any purpose, any actual goal, except to be completed as fast as possible.You wouldn't say \"these instructions should be deleted because branch prediction and speculative execution in recent years have made it so that total cycle count is the same without them\", for the reason stated ultimately after in the article already: That may not have been true in the past, and may change again in the future.\n \nreply",
      "> \"these instructions should be deleted because branch prediction and speculative execution in recent years have made it so that total cycle count is the same without them\"Then a new CPU architecture becomes popular, and spiders start winning every speed climbing event\n \nreply",
      "If you cross your eyes and look at the routes as if it were a single stereoscopic image overlaying one route on top of each other, the misplaced hold jumps out at you immediately.\n \nreply",
      "I tried this, and while I didn't have any difficulty establishing a stereoscopic view it didn't jump out for me at all. I perceived the blue line floating on top of the problem handhold, but the handhold seemed to be on the same plane as all the others. Knowing it was the problem one, I could use the stereoscopic view to see it, but without already knowing I don't think it would be apparent.This is odd to me since I've successfully used stereoscopy in the past to find small differences. For some reason, with this image, rather than causing a change in perceived z-level, my eyes fight for dominance and my left ends up winning.\n \nreply",
      "Good idea. I just tried that on the first image of the whole route (after zooming in a bit) and the misplaced hold looks like it's floating in space away from the wall.\n \nreply",
      "I just did it and it didn't jump out for me at all. Odd\n \nreply",
      "I usually find it easier to relax my eyes (focus too far rather than too close), and so the opposite occurred - most of the holds appeared to float in a single plane (slightly wavy perhaps due to lighting differences), while the incorrect hold was sunk further back.\n \nreply"
    ],
    "link": "https://leejo.github.io/2024/09/01/off_by_one/",
    "first_paragraph": "The Championnats d\u2019Europe d\u2019Escalade (climbing) in Villars-sur-Ollon has just finished. I couldn\u2019t make it to all the events, but did see the finals of the \u201cSpeed\u201d event. It\u2019s a series of head-to-head elimination races up a 15m tall wall, resulting in an eventual victor after enough rounds.Speed climbing is a bit like skateboarding at the Olympics: absolutely in no way a real representation of what it\u2019s like to do it for 99.99% of people who skate/climb, and apparently it\u2019s scoffed at by most of the community; but it\u2019s entertaining nonetheless to the layman, and brings spectators in so why not include it?I have a surface level knowledge of the competition, informed only by the fact that it has happened in the village for the last few years. I know that the route in speed climbing is always the same, to allow comparisons of timings across the years. There\u2019s probably a number of other factors that can\u2019t be controlled, like is the fact Villars is at 1,200m above sea level enough to make a"
  },
  {
    "title": "Dynamicland 2024 (dynamicland.org)",
    "points": 350,
    "submitter": "Pulcinella",
    "submit_time": "2024-09-04T17:02:14.000000Z",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=41448022",
    "comments": [
      "I had the good fortune of taking a field trip there in 2018.The video is a very good overview of the project.One interesting artifact of \"the real world simulates itself\" is version control.  At Dynamicland, each version of a program is a sheet of paper (with a unique set of fiducials along the edges).  If you want to edit a program, you grab a keyboard and point it at the program.  A text editor comes up; you make your changes, and hit commit.  When you do, it spits out a new piece of paper with your changes.  Put it in the view of the camera to use the new version.  Take it away and use the old paper to roll the change back.\n \nreply",
      "> with a unique set of fiducials along the edgesI suspect each piece of paper, if examined with a good enough camera, has a unique fingerprint, like a snowflake, and perhaps this could be used in the future for an \"Isomer Addressed Filesystem\". In other words, all pieces of paper ship with a UUID already, woven into their atoms.\n \nreply",
      "I would suggest instead convincing every printer manufacturer to embed in every printer a routine that encodes a unique identifier on every print and then reading that using more typical cameras.  The hard part has already been done.https://en.m.wikipedia.org/wiki/Printer_tracking_dots\n \nreply",
      "I'm pretty sure that I mentioned the printer tracking dots to the researchers at the lab and certainly mentioned DataGlyphs. So they were aware of alternatives. The trick is to get a workable system with cameras that have the resolution to pick out those details from a dozen feet away, as well as a software stack that can recognize them at ~60fps.The goal has always been to move away from the dots, you can see this in the progress report: https://dynamicland.org/2019/Progress_report/That said, and this is purely my opinion, the system works well enough as it is, and there is so much fun stuff to build on top of what works, that it's hard to prioritize a better object recognition system over the myriad of other interesting things to be done.\n \nreply",
      "I imagine it would very difficult to read these dots from a distance and dynamically.  I just mention it because most printed documents already have indentifiers printed on them that don't require seeing individual fibers.\n \nreply",
      "Ah, noted! With that in mind, did you know that those printer dots are what the team that won the 2011 DARPA Shredder Challenge used to win?https://en.wikipedia.org/wiki/DARPA_Shredder_Challenge_2011Fun fact: Otavio Good, who led the winning team, learned about the printer dots on this very site. As I recall, he said that the dots were like a map that let them reconstruct the shredded documents.\n \nreply",
      "Oh, that\u2019s why my HP inkjet refuses to print a black & white page when it\u2019s low on yellow.\n \nreply",
      "Woah! I never considered that until now. I'll bet you're right.\n \nreply",
      "I assume this hasn't been \"released\" yet, but still thought I'd ask if the source code for the operating system (or \"computing environment\", in Dynamicland-speak) is available anywhere and also if there yet exists any DIY hardware guides for building your own to play with at my own location (far from the Oakland/Berkeley Dynamicland facility).I believe the FAQ confirms that this is not possible at the moment:> Where can I get Realtalk?>> At present, Realtalk exists in Dynamicland spaces and in the spaces of our collaborators, where we can carefully grow and tend in-person communities of practice. In the short term, additional spaces will be started by people who have contributed significantly to an existing space and have internalized the culture and its values. Long term, we intend to distribute the ideas in the form of kits+games which will guide communities through building their own computing environments that they fully understand and control. Long long term, computing may be built into all infrastructure as electric light is today. This would also require an extensive network of educational support.\n \nreply",
      "There are some similar-ish systems with alpha-level install instructions: https://folk.computer/pilot\n \nreply"
    ],
    "link": "https://dynamicland.org/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: An open-source implementation of AlphaFold3 (github.com/ligo-biosciences)",
    "points": 155,
    "submitter": "EdHarris",
    "submit_time": "2024-09-04T17:44:17.000000Z",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=41448439",
    "comments": [
      "This seems really neat!DeepMind and AlphaFold are clearly moving in a closed-source direction, since they created Isomorphic Labs as a division of Alphabet essentially focused on doing this stuff closed source. In theory it seems nice for academic tools to have an open source version, although I'm not familiar enough with this field to point to a specific benefit of it.So what's your plan for the company itself, do you intend to continue working on this open source project as part of your business model, or was it more of a one-off? Your website seems very nonspecific about what exactly you intend to be selling.\n \nreply",
      "Our long term goal is to design enzymes for chemical manufacturing. We decided to build AlphaFold3 because we had seen how useful AlphaFold2 had been for the protein design field. No one else was building it fast enough for us, so we decided we should do it ourselves. We are committed to training and open-sourcing the full version with ligand and nucleic acid prediction capabilities as well since it is so useful for the biotech industry.\n \nreply",
      "Thanks for releasing this, I've been looking forward to a truly open version I can use in a commercial setting. What a way to launch the company!\n \nreply",
      "Thanks!\n \nreply",
      "Have you considered publishing your own paper about your implementation? It would make it easier to cite in the literature later on. Would major journals accept such a paper? I would assume they would if they really had questions about reproducibility.\n \nreply",
      "OpenFold, which was AlphaFold2's open-source implementation was published in Nature Methods. We will prepare a similar publication once the model is more mature and when we have a nice set of experiments showing the model's interesting properties.\n \nreply",
      "You probably want to change the name of this implementation as it's not truly AlphaFold3.  I wouldn't be surprised if you got a C&D from DM for using the name.\n \nreply",
      "Yes this is a good point. We are actively speaking with our counsel to check this. Thanks for flagging, though.\n \nreply",
      "I did a very brief stint on computational proteomics. That stuff is absolutely next level.\n \nreply",
      "Amazing! What kind of things did you work on?\n \nreply"
    ],
    "link": "https://github.com/Ligo-Biosciences/AlphaFold3",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open source implementation of AlphaFold3\n      This is Ligo's open-source implementation of AlphaFold3, an ongoing research project aimed at advancing open-source biomolecular structure prediction. This release implements the full AlphaFold3 model along with the training code. We are releasing the single chain prediction capability first and we will add ligand, multimer, and nucleic acid prediction capabilities once they are trained. Sign up for beta testing here.This repository is intended to accelerate progress towards a faithful, fully open-source implementation of AlphaFold3 for the entire biotech community to use freely.We find that the model training dynamics are quite fast. The following video is a sample from a model trained for 4,000 steps on 8 A100 GPUs for 10 hours without templates.Animation credits: Matthew ClarkThis pr"
  },
  {
    "title": "The Internet Archive has lost its appeal in Hachette vs. Internet Archive (courtlistener.com)",
    "points": 212,
    "submitter": "Signez",
    "submit_time": "2024-09-04T16:41:50.000000Z",
    "num_comments": 319,
    "comments_url": "https://news.ycombinator.com/item?id=41447758",
    "comments": [
      "Related URLs (from threads we merged hither) in case of interest:https://www.theverge.com/2024/9/4/24235958/internet-archive-...https://www.wired.com/story/internet-archive-loses-hachette-...https://finance.yahoo.com/news/major-book-publishers-defeat-...https://news.bloomberglaw.com/ip-law/internet-archive-digita...",
      "This has been playing out for many years. And it's all because Brewster Kahle decided that an overly broad interpretation of the Internet Archive's mission trumped the rights of authors and publishers, and the laws of the United States.When IA was asked to stop CDL - many times - he continued. The National Writers Union tried to open a dialogue as early as 2010 but was ignored:The Internet Archive says it would rather talk with writers individually than talk to the NWU or other writers\u2019 organizations. But requests by NWU members to talk to or meet with the Internet Archive have been ignored or rebuffed.https://nwu.org/nwu-denounces-cdl/When the requests to abandon CDL turned into demands, Kahle dug in his heels. When the inevitable lawsuits followed, and IA lost, he insisted that he was still in the right and plowed ahead with appeals.He also opened a new front in the court of public opinion. In his blog posts and interviews with U.S. media, Kahle portrays the court cases and legal judgements as a crusade against the Internet Archive and all librarians (see https://blog.archive.org/2023/12/15/brewster-kahle-appeal-st...). It's not. It's the logical outcome of one man's seemingly fanatical conviction against the law and the people who work very hard to bring new books into being.In addition, there has been real collateral damage to the many noble aspects of the Internet Archive. Legal fees and judgements have diverted resources away from the Wayback Machine, the library of public domain works, and other IA programs that provide real value to society. I truly hope the organization can survive.\n \nreply",
      "> In his many interviews with U.S. media, he portrays the court cases and legal judgements as a crusade against the Internet Archive and all librarians. It's not. It's the logical outcome of one man's seemingly fanatical conviction against the law and the people who work very hard to bring new books into being.If IA had won, IA would be hailed as a cultural hero. They hit and they missed. Claiming Brewster Kahle is against \"the people who work very hard to bring new books into being\" is unfair. The copyright goalposts have moved so far past where they were originally, the people who work very hard can be dead for decades and their works still in copyright, and by the time they are dead for 70 years, the copyright will probably be extended again.\n \nreply",
      "I agree with you about copyright, but the fact is that the IA never had a chance and we knew it years ago.The top comment on HN a week after their launch of the EL is critical [0], right at the moment when HN would be most expected to rally to their defense. By the time the lawsuit was actually starting to take shape most commenters had become very concerned for the fate of the IA [1]. This is on a forum that reliably champions freedom of information, but most of us knew even at the time that what they'd done was extremely unlikely to pass muster.The IA was never going to be hailed as a cultural hero because they stood no chance, and they are too valuable for other, unrelated reasons to make themselves a martyr. This never should have happened under the same legal entity as the web archive.[0] https://news.ycombinator.com/item?id=22731472[1] https://news.ycombinator.com/item?id=23485182\n \nreply",
      "The further you take a federal case the more precedent you create. The infinitesimal odds IA seemed to have at winning this case have to be weighed against the precedent they have created that may bind on future controlled digital lending cases with better facts. What IA did here wasn't costless.\n \nreply",
      "> The further you take a federal case the more precedent you create.Not really. This put a huge chilling effect on real attempts at CDL, which IA was not.\n \nreply",
      "I think we agree.\n \nreply",
      "> future controlled digital lending cases with better facts.Was anyone else doing anything? Or standing ready to do anything?\n \nreply",
      "I don't know, but anybody who wasn't doing anything and wasn't standing to do anything was more valuable to digital rights than the people who appealed this case to the 2nd Circuit, in that none of them actually damaged digital rights.\n \nreply",
      "Sure, but that's judging in hindsight. Then again, everyone here was saying how dumb a move this was before the trial even started, so...The payoff for winning would have been massive, but if the IA shuts down because of this, so will the cost for losing.\n \nreply"
    ],
    "link": "https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf",
    "first_paragraph": ""
  },
  {
    "title": "The first nuclear clock will test if fundamental constants change (quantamagazine.org)",
    "points": 150,
    "submitter": "beefman",
    "submit_time": "2024-09-04T16:23:34.000000Z",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=41447515",
    "comments": [
      "Let's assume they manage to make a nuclear clock out of this, with an Allan drift that's low enough to be useful. Once that's done, it'll take years of observation to measure any meaningful differences and gather enough data to notice something.Meanwhile, moving the height of anything a centimeter, the position of the moon, and a whole other host of noise sources have to be canceled out.I have no doubt this will be done... and it will be awe inspiring to hear it all told after the fact.While you're waiting... I found this really cool meeting documented on YouTube[1] that has the clearest explanation of how Chip Scale Atomic clocks work I've ever seen.I look forward to Chip Scale Optical Lattice clocks[1] https://www.youtube.com/watch?v=wHYvS7MtBok\n \nreply",
      "> Lots of nuclei have similar spin transitions, but only in thorium-229 is this cancellation so nearly perfect.\n> \n> \u201cIt\u2019s accidental,\u201d said Victor Flambaum(opens a new tab), a theoretical physicist at the University of New South Wales in Sydney. \u201cA priori, there is no special reason for thorium. It\u2019s just experimental fact.\u201d But this accident of forces and energy has big consequences....> Physicists have developed equations to characterize the forces that bind the universe, and these equations are fitted with some 26 numbers called fundamental constants. These numbers, such as the speed of light or the gravitational constant, define how everything works in our universe. But lots of physicists think the numbers might not actually be constant.Putting these things together, if the physical constants do change over time, then perhaps there really isn't anything special about thorium-229, it's just that it's the one where the electrical repulsion and strong nuclear forces balance out right now.  In a billion years maybe it would be some other element.  Maybe we're just lucky to be alive at a time when one of the isotopes of an existing element just happens to line up like this.Perhaps too there's an optimal alignment that will happen or has already happened when those forces exactly balance out, and maybe that would be an ideal time (or place, if these constants vary by location) to make precise measurements in the changes to these constants, much like a solar eclipse was an ideal opportunity for verifying that light is bent by gravity.\n \nreply",
      "Not a physicist, just a passionate layperson.AFAIK real practitioners choose their units such that a lot of things are unity: speed of light is 1 (hence E = M), h-bar is 1, etc.There are some numbers like the \u201cfine structure constant\u201d (which I think is tantalizingly close to 1/137) that do seem difficult if not impossible to derive from others.The pop-science explanation for this that a layperson like myself would know about is the \u201canthropic\u201d principal, they are such because only in such regimes would anyone ask the question.I don\u2019t know what real scientists think about this.\n \nreply",
      "You\u2019re assuming a monotonous linear change. It could be periodic or jumping between discontinuous values.\n \nreply",
      "Matter in other galaxies would behave differently from matter in the Milky Way if fundamental constants are not always true. I argue about this sometimes. Others keep stating that the wavelengths are equal, so everything else must be.\n \nreply",
      "I think the better way to ask this question is: how much large scale spatial variation can there be in the laws of physics so that the observable behavior doesn't contradict existing observations? As far as I remember, this has been studied, but I can't find a reference right now.\n \nreply",
      "wikipedia has a high level review of current constraints: https://en.wikipedia.org/wiki/Time-variation_of_fundamental_...    fine-structure constant: less than 10^\u221217 per year\n    gravitational constant: less than 10^\u221210 per year\n    proton-electron mass ratio: less than 10^\u221216 per year\n \nreply",
      "Well, if you think about it, on a large scale of the universe, our laws are helped by our mathematical inventions of dark matter and dark energy. So is there really dark matter and dark energy, or is our understanding of the laws of the universe incomplete?\n \nreply",
      "As I understand it, dark matter and dark energy are just placeholders for discrepancies between our current physical model and observations made by telescopes like Hubble and Kepler. This could mean either that our measurements are inaccurate, or that the model is incomplete. Honestly, I think that both are extremely likely.\n \nreply",
      "Dark matter (matter that has mass but does not interact in any other way) might be the literal solution. But there are also other suggestions (MOND is a big one).The https://en.m.wikipedia.org/wiki/Bullet_Cluster is pretty interesting.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/the-first-nuclear-clock-will-test-if-fundamental-constants-change-20240904/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesSeptember 4, 2024The discovery of a laser-controllable transition in the atomic nucleus of thorium-229 marks the dawn of the \u201cnuclear clock.\u201dNash Weerasekera for\u00a0Quanta MagazineStaff WriterSeptember 4, 2024At 11:30 one night in May 2024, a graduate student, Chuankun Zhang, saw a signal that physicists have sought for 50 years. As a peak rose from the static on his monitor at the research institute JILA in Boulder, Colorado, Zhang dropped a screenshot in a group chat with his three lab mates. One by one they hopped out of bed and trickled in. After several sanity checks to make sure that what they were looking at was real \u2014 a signal from a thorium-229 nucleus switching between two states, kn"
  },
  {
    "title": "Show HN: Laminar \u2013 Open-Source DataDog + PostHog for LLM Apps, Built in Rust (github.com/lmnr-ai)",
    "points": 19,
    "submitter": "skull8888888",
    "submit_time": "2024-09-04T22:52:19.000000Z",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41451698",
    "comments": [
      "Tough break for https://laminar.ohwg.net, I guess.\n \nreply",
      "Turns out there quite a few companies / projects named Laminar. I really like the name, couldn't buy a .com or .ai domain tho, so settled on lmnr.ai. But it's been growing on me.\n \nreply",
      "Lmnop would have had a ring to it with laminar ops!\n \nreply"
    ],
    "link": "https://github.com/lmnr-ai/lmnr",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Laminar - Open-source DataDog + PostHog for AI agents / RAG apps. Fast, reliable and insightful. Written in Rust \ud83e\udd80. YC S24.\n      \n\n  Think of it as DataDog + PostHog for LLM apps.Read the docs.This is a work in progress repo and it will be frequently updated.The easiest way to get started is with a generous free tier on our managed platform -> https://www.lmnr.aiStart local version with docker compose.This will spin up the following containers:First, create a project and generate a Project API Key. Then,To automatically instrument LLM calls of popular frameworks and LLM provider libraries just addIn addition to automatic instrumentation, we provide a simple @observe() decorator, if you want to trace inputs / outputs of functionsYou can send events in two ways:Note that to run an evaluate event, you need to crate an evaluator pipeli"
  },
  {
    "title": "SEC fines 6 major credit rating agencies over failure to keep electronic records (cnn.com)",
    "points": 65,
    "submitter": "rntn",
    "submit_time": "2024-09-04T22:53:15.000000Z",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41451707",
    "comments": [
      "xxx"
    ],
    "link": "https://www.cnn.com/2024/09/03/business/sec-fines-credit-rating-agencies-over-failure-electronic-records/index.html",
    "first_paragraph": "Markets \n\n\nHot Stocks \n\n\nFear & Greed Index \n\n\n\n            Latest Market News \n\n\n\n            Hot Stocks \n\n\nFollow:\n            The US Securities and Exchange Commission fined six major credit rating organizations a total of $49 million for their \u201csignificant failures\u201d to keep electronic communications.\n    \n            Moody\u2019s Investor Services and S&P Global Ratings agreed to pay the heftiest fines, a $20 million civil penalty each. Fitch Ratings agreed to pay $8 million, A.M. Best Rating Services agreed to pay $1 million, HR Ratings de M\u00e9xico, S.A. de C.V.\u00a0$250,000, and Demotech agreed to pay $100,000, respectively.\n    \n            The firms admitted to the facts in the SEC orders, which said they violated recordkeeping provisions of federal securities laws, the SEC said.\n    \n            For example, Moody\u2019s Ratings Employees \u2013 including at the senior level \u2013 were communicating about credit ratings activities via text messages and WhatsApp on their personal devices, according to "
  },
  {
    "title": "Undefined behavior in C is a reading error (2021) (yodaiken.com)",
    "points": 16,
    "submitter": "nequo",
    "submit_time": "2024-09-02T02:30:36.000000Z",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41422150",
    "comments": [
      "xxx"
    ],
    "link": "https://www.yodaiken.com/2021/05/19/undefined-behavior-in-c-is-a-reading-error/",
    "first_paragraph": ""
  },
  {
    "title": "Heavy Construction of a Sewage Pump Station \u2013 Ep 3 [video] (youtube.com)",
    "points": 35,
    "submitter": "Bluestein",
    "submit_time": "2024-09-01T18:52:45.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41419290",
    "comments": [
      "Pretty cool!One thing that fascinated me working for a sanitation district was that we had some huge pumping stations like this, but hiding in plain sight.There would be a metal vault cover in the sidewalk, it opens up to a stairwell, then you walk downstairs to a massive concrete wet well and pumping station under the street.I had no idea they were even there, but they are, especially in urban areas.It's a lot cheaper to build them above ground, but they did what they had to to move sewage.\n \nreply",
      "This series of construction videos is some of the most interesting content I've seen on the Practical Engineering (or in this case, also branded as Practical Construction) channel. Highly recommended to watch on Nebula.Keep up the great work, Grady!\n \nreply",
      "They are indeed great. There's something about the competence and skill with which the operators - each in his trade - go about their business, and how the miriad parts come together, that is fascinating.-\n \nreply",
      "This video series is one of the best pieces of content I\u2019ve watched on YouTube. If anyone has other similar recommendations then please share!\n \nreply",
      "This one was on HN earlier this year: https://www.youtube.com/watch?v=6AV2NcyX7pk(Construction of a pumped-energy-storage tunnel in Switzerland).\n \nreply",
      "Yeah his practical engineering is excellent as well.\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=Yd4yxionQpg",
    "first_paragraph": ""
  },
  {
    "title": "Kagi Assistant (kagi.com)",
    "points": 293,
    "submitter": "darthShadow",
    "submit_time": "2024-09-04T18:35:53.000000Z",
    "num_comments": 136,
    "comments_url": "https://news.ycombinator.com/item?id=41448985",
    "comments": [
      "To repeat myself from a recent HN thread:I've been using Kagi for a while (almost two years now!) and it's been nothing but excellent!Lenses are very useful (Reddit lens is on every second search), and I personally really like the AI features they are working on.The new more advanced assistant which is able to do searches, which can also be constrained to lenses, and lets you pick an arbitrary model, is excellent, and basically means I don't need a chatgpt/claude subscription, as Kagi covers it very well.All in all, great product which I'm happy to pay for.\n \nreply",
      "I really wanted to like Kagi, I'm onboard with paying for search, but I've had had a big issue with its speed when doing the trial to be honest, am I the only one bothered by this?Perhaps this is because I'm in Europe and it's faster in the US? A search request to Kagi seems to take around two seconds for me (shows as ~1s in the Kagi UI), it just feels really unpleasant compared to Google, I'm used to firing of a couple searches with different wording / terms and go through results quickly, feels like I'm being held back.Maybe I'm spoiled, but if I'm paying for search I would really like it to be at least on par with Google, the search result quality seems ok from what I can tell, lenses don't really make sense to me, they seem to filter out too many results I would have liked to actually see, but the customization like adjusting the rating of individual websites is fantastic.If they can manage to bring the speed to match that of Google, I'd be happy to pay for it I think.\n \nreply",
      "Interesting!!I'm not slamming you, or your experience or preferences.  That said, I find very little difference between 2 seconds and one second or less than that.Search taking a small fragment of time just isn't a big deal and I search sometimes many times per day.What is the gain for you that makes 2 seconds an exception to using the product?Just curious.  Peace, live well.\n \nreply",
      "I feel like search is probably one of the most common things I do with a computer, I would say I often search many times per minute if I\u2019m actively looking into some topic or issue.Because it\u2019s such a common action for me, it feels like such a strong regression to go 2/3 times slower than before.\n \nreply",
      "It doesn\u2019t seem intuitive at first but this is a well researched phenomenon.https://glinden.blogspot.com/2006/11/marissa-mayer-at-web-20...",
      "How bizarre. I'm not in the US either - I'm in New Zealand, and have been using Kagi since their beta I think and currently pay for Ultimate, and to me it's a lot faster than Google.The other day I was using someone else's computer and used Google, and my goodness, the results were just awful and ... bloated?\n \nreply",
      "I'm using it from NZ and Australia and found it blazing fast. No lower than Google certainly! I wonder if it'd be worth reaching out to Kagi support.\n \nreply",
      "UK user here, no speed issues at all\n \nreply",
      "Unfortunately I think Kagi only has old Reddit content now that Reddit only lets Google crawl them: https://news.ycombinator.com/item?id=41057033\n \nreply",
      "Kagi uses Google as one of its sources for search results so should be able to return the same reddit results as Google.\n \nreply"
    ],
    "link": "https://blog.kagi.com/announcing-assistant",
    "first_paragraph": "\n\n\n                    04 Sep, 2024\n                \n\nKagi has been thoughtfully integrating AI into our search experience, creating a smarter, faster, and more intuitive search. This includes Quick Answer which delivers knowledge instantly for many searches (can be activated by appending ? to the end of your searches), Summarize Page for the quick highlights of a web page, and even the ability to ask questions about a web page in your search results. And all of these features are on-demand and ready when you need them.Today we\u2019re excited to unveil the Assistant by Kagi.  A user friendly Assistant that has everything you want and none of the things you don\u2019t (such as user data harvesting, ads & tracking).  Major features include:Kagi Assistant has the ability to use Kagi Search to source the highest quality information meaning that its responses are grounded in the most up-to-date factual information while disregarding most \u201cspam\u201d and \u201cmade for advertising\u201d sites with our unique rankin"
  },
  {
    "title": "HIDman Adapting USB devices to work on old computers (github.com/rasteri)",
    "points": 5,
    "submitter": "CTOSian",
    "submit_time": "2024-09-02T15:06:30.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/rasteri/HIDman",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Adapting USB devices to work on old computers\n      HIDman is an open source device to allow the use of modern USB keyboards and mice on legacy PCs.Peripherals that support legacy PCs are becoming hard to find, especially for the very first PCs. This project aims to provide a simple cheap solution that will cover everything from the original IBM 5150 PC all the way up to modern computers that have PS/2 ports.You can connect many different combinations of USB devices to HIDman.The most obvious being to connect a keyboard to one USB port, and a mouse to the other one :Or, you could perhaps connect a wireless keyboard+mouse dongle to one port, and a game controller to the other :Hub support can be hit-and-miss. This is (mostly) not HIDman's fault - many modern hubs don't support low-speed USB devices properly.Configuration is provided "
  },
  {
    "title": "Show HN: Mem0 \u2013 open-source Memory Layer for AI apps (github.com/mem0ai)",
    "points": 111,
    "submitter": "staranjeet",
    "submit_time": "2024-09-04T16:01:40.000000Z",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=41447317",
    "comments": [
      "Congrats on the launch. Adding a memory layer to LLMs is a real painpoint. I've been experimenting with mem0 and it solves a real problem that I failed to solve myself, and we're going to use it in production.One question that I've heard a few times now: will you support the open source version as a first class citizen for the long term? A lot of open source projects with a paid version follow a similar strategy. They use the open source repo to get traction, but then the open source version gets neglected and users are eventually pushed to the paid version. How committed are you to supporting the open source version long term?\n \nreply",
      "Congrats!\nAPI looks easy to use.\nGraph memory feature is interesting, seems powerful. Curious if it works well in practice and if it can handle fuzzy/contradictory facts (which is a general problem for symbolic AI).\n \nreply",
      "Over time, I can imagine there's going to be a lot of sensitive information being stored. How are you handling privacy?\n \nreply",
      "We already support the feature of inclusion and exclusion of memories where the developer can control what things to remember vs not remember for their AI app/agent. For example, you can specify something like this:- Inclusion prompt: User's travel preferences and food choices\n- Exclusion prompt: Credit card details, passport number, SSN etc.Although we definitely think that there is scope to make it better and we are actively working on it. Please let us know if you have feedback/suggestions. Thanks!\n \nreply",
      "Congrats on the launch!I messed around with the playground onboarding...here's the output:With Memory\nMem0.ai\nI know that you like to collect records from New Orleans artists, and you enjoy running.Relevancy: 9/10Without Memory\nI don\u2019t have any personal information about you. I don\u2019t have the ability to know or remember individual users. My main function is to provide information and answer questions to the best of my knowledge and training. How can I assist you today?Relevancy: 4/10--It's interesting that \"With Memory\" is 9/10 Relevancy even though it is 100% duplication of what I had said. It feels like that would be 10/10.It's also interesting that \"Without Memory\" is 4/10 \u2014 it seems to be closer to 0/10?Curious how you thinking about calculating relevancy.\n \nreply",
      "This is why in my system I have more specific, falsifiable metrics: freshness, confidence, etc. which come together to create a fitness score at the surface-level, while still exposing individual metrics in the API.\n \nreply",
      "Could you speak to more about what the pricing is? With the current pricing page, it's hard to model costs against potential use cases.\n \nreply",
      "Congrats Taranjeet and Deshraj!So after using Mem0 a bit for a hackathon project, I have sort of two thoughts: 1. Memory is extremely useful and almost a requirement when it comes to building next level agents and Mem0 is probably the best designed/easiest way to get there.\n2. I think the interface between structured and unstructured memory still needs some thinking.What I mean by that is when I look at the memory feature of OpenAI it's obviously completely unstructured, free form text, and that makes sense when it's a general use product.At the same time, when I'm thinking about more vertical specific use cases up until now, there are very specific things generally that we want to remember about our customers (for example, for advertising, age range, location, etc.) However, as the use of LLMs in chatbots increases, we may want to also remember less structured details.So the killer app here would be something that can remember and synthesize both structured and unstructured information about the user in a way that's natural for a developer.I think the graph integration is a step in this direction but still more on the unstructured side for now. Look forward to seeing how it develops.\n \nreply",
      "Thanks yding! Definitely agree with the feedback here. We have seen similar things when talking to developers where they want:- Control over what to remember/forget\n- Ability to set how detailed memories should be (some want more detailed vs less detailed)\n- Different structure of the memories based on the use case\n \nreply",
      "This is great feedback. I've felt this too, and am working on something that I hope enables this in an intuitive way. I'd love to get your thoughts on what you'd find to be the ideal UX?\n \nreply"
    ],
    "link": "https://github.com/mem0ai/mem0",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The Memory layer for your AI apps\n      \n\n\n\n\nLearn more\n    \u00b7\n    Join Discord\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMem0 (pronounced as \"mem-zero\") enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. Mem0 remembers user preferences, adapts to individual needs, and continuously improves over time, making it ideal for customer support chatbots, AI assistants, and autonomous systems.\n\nNew Feature: Introducing Graph Memory. Check out our documentation.\nMem0 leverages a hybrid database approach to manage and retrieve long-term memories for AI agents and assistants. Each memory is associated with a unique identifier, such as a user ID or agent ID, allowing Mem0 to organize and access memories specific to an individual or context.When a message is added to the Mem0 using add()  method, the system extracts "
  },
  {
    "title": "Meticulous (YC S21) is hiring to eliminate E2E UI tests",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-09-04T21:02:36.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=41450775",
    "first_paragraph": ""
  },
  {
    "title": "Code Review Anxiety Workbook (gitbook.io)",
    "points": 25,
    "submitter": "mooreds",
    "submit_time": "2024-09-04T21:40:21.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41451168",
    "comments": [
      "That workbook is all about anxiety in general, which is fine, but there's almost nothing specifically to do with anxiety as it relates to code review.Here's my advice: Focus on whether the change actually solves the problem it's trying to solve.  Run the code; does it work?  What regressions could it cause? Is there any way it could be simpler?Along the way, you may notice style guide offences, or minor nitpicks.  It's good to take note of those things, but only raise those issues once you've addressed the fundamentals.At the end of the day, confidence comes from understanding.  So dig in and understand the context, understand the effects of the change, and give the best feedback you can to help get to the best solution.\n \nreply",
      "Good code review method, but that doesn't address the anxiety aspect, which is real.I always tried to treat and see it as a teaching and learning exercise and not make it accusatory or negative. As a reviewer, see it as an opportunity to teach others in good code practices. As a reviewee, see it as an opportunity to learn, not as a slam on you personally.Doesn't solve it completely, but it helps.\n \nreply",
      "Setting aside the addressing of anxiety and avoidance, a lot of good code review practice boils down to \"could/should/must\" and that it's good to call out these when you see them and label them appropriately, and when receiving a code review understand the difference between them.\n \nreply",
      "For those not feeling problematic levels of anxiety surrounding code reviews, I still found the sections of Step 4 to be very useful advice in general for how to give and receive code reviews well.\n \nreply",
      "I find the parallels of code review and how work gets reviewed in Investment Banking to be incredibly interesting, except the latter is the wild west in comparison. Wall Street can learn a lot here.\n \nreply",
      "I didn't know people get anxiety from code reviews these days. How far have we fallen as an industry?\n \nreply"
    ],
    "link": "https://developer-success-lab.gitbook.io/code-review-anxiety-workbook-1",
    "first_paragraph": ""
  },
  {
    "title": "sRGB Gamut Clipping (2021) (bottosson.github.io)",
    "points": 73,
    "submitter": "Brajeshwar",
    "submit_time": "2024-09-04T15:28:08.000000Z",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=41446916",
    "comments": [
      "It's a good generalization of several techniques. The main thing I want to know is this: how does it look with actual HDR exposures, not the synthetic ones made by \"increasing exposure and colorfulness significantly\"? We shouldn't choose a method based on how natural the result is, when there is a \"stretching\" step like this that is not at all natural.\n \nreply",
      "I think any kind of hard clipping approach which takes each pixel independently is going to necessarily create some significant artifacts, though as the examples here make clear, some directions of clipping work better than others. The most important part to preserve for the image to look reasonable is lightness contrast, as when it gets crunched away the image loses visible detail, and the better methods demonstrated in this post manage to save at least some lightness contrast. But all of the methods here end up blowing out / compressing away chroma contrast in some regions where it existed in the original image.What I'd like to see someone try is do is record the relative lightness and chroma, and (adaptation/context dependent) color relationships from the original image, and then try to preserve those to the extent practical even when bringing out-of-gamut colors into gamut. This will necessarily require modifying in-gamut colors to some extent as well.This is what good Photoshop users do when they manually adjust the color of an image from one display medium to another, but it involves some amount of careful conscious choice and skill.\n \nreply",
      "OMG, it's Mike Herf! I even linked your \"give me a gigabyte\" article randomly yesterday to someone complaining of an application using 1gb on his 64gb machine, and remember most of your website off by heart still, in particular the soft shadows / roundrects, all the way to random funny things like SreeD :) Thanks so much for the great articles <3\n \nreply",
      "I\u2019ve implemented[1] some of these algorithms into @texel/color, a modern JS color library, and it also supports gamut mapping to certain wide gamut color spaces (Display P3, Rec2020, Adobe 1998) rather than just sRGB.https://github.com/texel-org/colorMany popular color libraries (Colorjs.io, culori) attempt to match CSS gamut mapping spec, which is an order of magnitude slower than the approach in Ottosson\u2019s blog post, and also less accurate (CSS gamut mapping may not fall neatly on the gamut boundary).[1] \u201cPorted\u201d might be a better term as I used a combination of Ottosson\u2019s own JS OKHSL picker, Colorjs.io code, and Coloraide (Python), and adjusted it for performance, more gamuts, and smaller bundle sizes.\n \nreply",
      "In games it\u2019s common to have a tone mapping step [1] to map the HDR image to sRGB while maintaining pleasant colors.The exposure parameter is usually dynamically chosen by using the average brightness of a previous frame.[1]: http://filmicworlds.com/blog/filmic-tonemapping-operators/\n \nreply",
      "Those ideas fail for anyone with a modern screen, which goes far beyond sRGB and it's ancient 80 nits brightness. I doubt there's a phone, laptop, PC monitor, or TV made with such low limits now.\n \nreply",
      "Ah so that's why so many movies, shows and even videogames got so dark you can barely see a thing, unless you're viewing them on a relatively recent TV?\n \nreply",
      "That and overall poor color management practices. Most likely this will all get smoothed out as specs, knowledge, and ecosystems mature\n \nreply",
      "I haven't gone through the whole article, but it seems to be conflating chroma and saturation. If lightness of a color is scaled by a factor c, then chroma needs to be scaled by that same factor, or saturation won't be preserved, and the color will appear more vibrant then it should.\n \nreply",
      "Well, no, it's not straight up scaling.(Not directed at you) Color science is a real field, CAM16 addresses all of the ideas and complaints that anyone could have, and yet, because it's 400 lines of code, we are robbed of principled, grounded, color. Instead people reach for the grab bag of simple algorithmic tricks\n \nreply"
    ],
    "link": "https://bottosson.github.io/posts/gamutclipping/",
    "first_paragraph": "When doing image processing, rendering or converting between RGB color spaces, it is easy to end up with RGB values outside of the 0.0 to 1.0 range (or 0 to 255 for 8-bit colors). This normally means that it isn\u2019t possible to encode the color and it needs to be adjusted somehow before being displayed or encoded (scRGB is an example of an exception, and has a different range). The range of supported colors in a color spaces is referred to as a its gamut.Many of the colors outside the gamut are still valid colors, they just can\u2019t be encoded in the given color space. The colors that can\u2019t be encoded can be categorized as follows (for RGB color spaces without imaginary primaries):The simplest technique for dealing with colors outside the valid range is to simply clamp RRR, GGG and BBB individually. The simplicity of this makes the technique widespread, but unfortunately it has significant drawbacks and can lead to unpleasant color distortions.Here is an example of taking a photo and increa"
  },
  {
    "title": "DAGitty \u2013 draw and analyze causal diagrams (dagitty.net)",
    "points": 152,
    "submitter": "smartmic",
    "submit_time": "2024-09-04T09:10:02.000000Z",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41443493",
    "comments": [
      "I made the first version of this back in 2010, when Pearl's work on causal inference started impacting Epidemiology. A friend was an Epidemiologist and she told me about an MS-DOS program she was using to do something with graphs (https://pubmed.ncbi.nlm.nih.gov/20010223/); she found it painfully slow and wondered if I could \"make it more user-friendly\".I did my PhD in algorithms at the time and was intrigued when I started reading Greenland, Pearl, and Robins (https://pubmed.ncbi.nlm.nih.gov/9888278/) and then Pearl's \"Causality\". I soon found that it was not obvious at all how you could speed up that MS-DOS program, and it led to a paper at UAI in 2011 (https://arxiv.org/abs/1202.3764). I made dagitty as a demonstration that you could actually use the algorithms we developed in that paper, and it took off from there -- started with 10 users per day, growing to the hundreds and thousands as causal inference became more popular.It's now a bit dated, and I don't have as much time anymore to keep it \"fresh\" as I would like. But I am still grateful and amazed at about how many people I got to know due to this. Highlights included collaborating with Pearl himself on a solution manual for his book \"Causal Inference: A Primer\" when it first came out, and so many e-mails I got out of the blue from users all over the world. Just last summer I stayed at the house of the author of one of the builtin examples in dagitty.As these 14 years flew by, I now am happy to do play a small part in supporting the next generation of causal inference software -- if you're interested in causal inference, be sure to check out pgmpy.org, a Python library for Bayesian networks that includes several causal inference functions (https://arxiv.org/abs/2304.08639). Ankur, the author, did his PhD with me and will soon defend his thesis!Also, R users, be sure to check out ggdag, a great package by Malcolm Barrett that wraps dagitty functionality in a much nicer and tidyverse-compatible way.\n \nreply",
      "Nice to see this still going! we used daggity in a grad school stats class back in 2013. To the instructor's credit, we spent the first few weeks thinking about causal models before we got into any actual stats. (Put differently, a DAG is a nonparametric structural equation model [0], and the rest of the stats class was about different ways to parametrize those models.)[0] Pearl 2021: https://ftp.cs.ucla.edu/pub/stat_ser/r370.pdf\n \nreply",
      "I hate to ask this question.... but I've moved to a python shop after working in the tidyverse for years, and am unimpressed with the DAG visualization capabilities.  Does anyone have any recommendations for 1,000 plus node DAGs?I still miss R and tidy quite a bit, but polars at least gets closer.\n \nreply",
      "Any of the python network science libraries can handle a 1000 node directed graph no problem.Networkx visualizations are ugly out of the box but you can make the network look however you want. The best out of the box visualizations I think are a matter of taste and use case. Same with the layouts.In a more abstract sense, I think it is hard to not have a 1000 node network visualization not be a useless hairball unless the network is quite sparse.If you mean with do-calculus though I really have no idea.\n \nreply",
      "There are some tools for larger renderings. I've had success with Graphics but have you tried Gephi https://gephi.org/\n \nreply",
      "I can confirm Gephi handles 1000+ just fine: I used it to solve Adventure of Code problem.\n \nreply",
      "This is very cool -- well done!I would find a python port useful, as R is more of a special use case in my own workflows, but my use case shouldn't deter the authors.\n \nreply",
      "I work on a graph-based library and regularly generate DAGs for analysis and debugging.  I have been using graphviz/dot but it's just so damn frustrating.  You have to jump through hoops to get the layout right.  It would be nice if something as ubiquitous as graphviz had a dedicated rendering engine for DAGs which did moderately sane things like place root and tail nodes on the same rank without requiring me to figure out which nodes are and manually position them.\n \nreply",
      "What do you mean by root and tail nodes?\n \nreply",
      "Roots: Nodes with no dependencies.Tails: Nodes with no dependents.\n \nreply"
    ],
    "link": "https://dagitty.net/",
    "first_paragraph": "\n        DAGitty is a browser-based environment for creating, editing, and analyzing\n        causal diagrams (also known as directed acyclic graphs or causal Bayesian networks).\n        The focus is on the use of causal diagrams for minimizing bias in empirical\n        studies in epidemiology and other disciplines. For background information, see\n        the \"learn\" page.\n      \n\n\t\tLaunch DAGitty online in your browser.\n\t\t\n\n\t\t\tDownload DAGitty's source for offline use.\n\t\t\n\n\t\t\t\tLearn more about DAGs and DAGitty.\n\t\t\t\n\n\n\t\t\t\tThe R package \"dagitty\" is available on \n\t\t\t\tCRAN or \n\t\t\t\tgithub.\n\t\t\t\nDAGitty is developed and maintained by \n       Johannes Textor \n       (Institute for Computing and \n\t\tInformation Sciences,\n\tRadboud University, and \n\tMedical BioSciences department, Radboudumc,\n\tNijmegen, The Netherlands). \n\t\n\n\nMany algorithms\n\timplemented in DAGitty were developed in close collaboration with\n\tMaciej Li\u015bkiewicz \n\tand Benito van der Zander, University of L\u00fcbeck, Germany (see literat"
  },
  {
    "title": "Glue and Coprocessor Architectures (vitalik.eth.limo)",
    "points": 16,
    "submitter": "bpierre",
    "submit_time": "2024-09-02T12:04:18.000000Z",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41424746",
    "comments": [
      "Why does anybody still listen to Vitalik?\n \nreply",
      "because he\u2019s a good writer and typically has nuanced takes about a variety of topics?\n \nreply",
      "I'm out of the loop, why should he not be listened to? I know who he is. Going to take a guess: he's overpromised and undelivered on ETH?\n \nreply"
    ],
    "link": "https://vitalik.eth.limo/general/2024/09/02/gluecp.html",
    "first_paragraph": "Special thanks to Justin Drake, Georgios Konstantopoulos, Andrej Karpathy, Michael Gao, Tarun Chitra and various Flashbots contributors for feedback and review.If you analyze any resource-intensive computation being done in the modern world in even a medium amount of detail, one feature that you will find again and again is that the computation can be broken up into two parts:These two forms of computation are best handled in different ways: the former, with an architecture that may have lower efficiency but needs to have very high generality, and the latter, with an architecture that may have lower generality, but needs to have very high efficiency.To start off, let us look under the hood of the environment I am most familiar with: the Ethereum Virtual Machine (EVM). Here is the geth debug trace of a recent Ethereum transaction that I did: updating the IPFS hash of my blog on ENS. The transaction consumes a total of 46924 gas, which can be categorized in this way:EVM trace of an ENS h"
  },
  {
    "title": "What Is an Atomic Clock? (2019) (nasa.gov)",
    "points": 13,
    "submitter": "dinoqqq",
    "submit_time": "2024-09-04T21:37:33.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.nasa.gov/missions/tech-demonstration/deep-space-atomic-clock/what-is-an-atomic-clock/",
    "first_paragraph": "7 min readThe clock is ticking: A technology demonstration that could transform the way humans explore space is nearing its target launch date of June 24, 2019. Developed by NASA\u2019s Jet Propulsion Laboratory in Pasadena, California, the Deep Space Atomic Clock is a serious upgrade to the satellite-based atomic clocks that, for example, enable the GPS on your phone.Ultimately, this new technology could make spacecraft navigation to distant locations like Mars more autonomous. But what is an atomic clock? How are they used in space navigation, and what makes the Deep Space Atomic Clock different? Read on to get all the answers.Read more: Five Things to Know About NASA\u2019s Deep Space Atomic ClockTo determine a spacecraft\u2019s distance from Earth, navigators send a signal to the spacecraft, which then returns it to Earth. The time the signal requires to make that two-way journey reveals the spacecraft\u2019s distance from Earth, because the signal travels at a known speed (the speed of light).While i"
  },
  {
    "title": "Oakland's new school buses reduce pollution and double as giant batteries (grist.org)",
    "points": 66,
    "submitter": "rntn",
    "submit_time": "2024-09-04T20:58:28.000000Z",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=41450729",
    "comments": [
      "Became skeptical of the overall article at this line:>All the while, fiercer heat waves will require more energy-hungry air conditioning to keep people healthy. (Though ideally, everyone would get a heat pump instead.)Heat pumps and air conditioners are identical, with the sole difference being that the heat pump can _also_ function as a heater/furnace. Heat pumps are not more efficient than AC for cooling. If the concern is increasing heat waves and increasing need for cooling in the summer (as described), heat pumps provide no advantage.This is an extremely basic technical point. Combined with the overall tone of the article, this reads like a PR fluff piece about the company providing the vehicles.-edit in response to numerous comments- Yes, heat pumps are good (I have one in my home), and, as a repalcement for _total_ HVAC systems, can provide a pretty significant efficiency bump, and reduce emissions...but for the _specific_ case of increased cooling needs, they will not make _that problem_ more efficient or reduce emissions.In other words, the fact that heat waves are increasing and we need more cooling has zero impact on the efficiency ganes/carbon savings of heat pumps, which are entirely from replacing _heating_ systems. And if the writer had understood this point, then an extremely minor change to the sentence would have conveyed the point. Although honestly, it's so orthogonal to the overall thrust of the article that it would have been better omitted entirely, in my opinion.\n \nreply",
      "You can have heat pumps that don't use air as a medium.never heard of a ground source air conditioner.\n \nreply",
      "Author might be forgiven, considering the quality of available information online:> Heat pumps offer an energy-efficient alternative to furnaces and air conditioners> Because they transfer heat rather than generate heat, heat pumps can efficiently provide comfortable temperatureshttps://www.energy.gov/energysaver/heat-pump-systems> heat pumps tend to be more energy efficient than an AChttps://bkvenergy.com/blog/heat-pump-vs-central-air/Of course those sites don't cite a source. It's probably AI generated. Apparently this is a widespread confusion.My guess is they are comparing heat pump for both heating and cooling to conventional furnace/AC system, not just \"for cooling\" only.\n \nreply",
      "I can't say I agree with this author, but this problem goes back many years: https://www.treehugger.com/why-are-there-so-many-fist-pumps-...People seem to think heatpumps are some mystical woo-woo new-wave energy healing device or something like that. It's an air conditioner. That's it.\n \nreply",
      "Not in the sense most people use the word \"AC\" or air conditioner.If you mean it by what it actually does, it conditions the air to be cooler or warmer or have less relative humidity, then yes. In typical NA applications anyway if we are talking a specific kind (ones you hook up to potentially existing forced air system ducts or mini split types with in room units blowing conditioned air).We heat with our mini split in winter and we cool with it in summer. And I'm in Canada so it gets pretty cold in winter. And if I said we had our \"air conditioner\" running in winter people would look at me strange.\n \nreply",
      "Ground-water heat pumps can passively cool making them more efficient than traditional AC\n \nreply",
      "They don't claim heat pumps are more efficient than plain AC at cooling.  Their parenthetical remark about people should ideally get heat pumps, links to an article about why people should get heat pumps.  And why? Because they can have lower ghg emissions than natural gas furnaces and resistance heating through efficiency and the ability to use renewable electricity.Seems pretty clear they understand heat pumps.\n \nreply",
      "You're correct, but OP's misunderstanding stems from the fact that the parenthetical isn't just a tangent, it's a non sequitur. Humans tend to assume that an utterance is relevant to the topic at hand and in particular to the surrounding context [0].This parenthetical was inserted arbitrarily in order to plug an article that has little relationship to the surrounding text, and OP understandably interpreted it as though the writer thought it was relevant.[0] See the Gricean maxims: \"I expect a partner's contribution to be appropriate to the immediate needs at each stage of the transaction.\" https://en.wikipedia.org/wiki/Cooperative_principle\n \nreply",
      "> stems from the fact that the parenthetical isn't just a tangent, it's a non sequitur.It's not a non sequitur to point out a superior alternative like that. If air conditioning is on-topic, heat pumps are either on topic or a tangent.\n \nreply",
      "> All the while, fiercer heat waves will require more energy-hungry air conditioning to keep people healthy. (Though ideally, everyone would get a heat pump instead.)Juxtaposed with \"heat waves will require more energy-hungry air conditioning\", heat pumps are a non sequitur. A nonzero percentage of those energy-hungry air conditioners are actually heat pumps running in air conditioning mode.\"Everyone should get heat pumps instead\" of what? Instead of a heater. As OP says, heat pumps save no energy during the summer, so they're entirely irrelevant here in a \"though\" clause.\n \nreply"
    ],
    "link": "https://grist.org/transportation/oakland-electric-school-buses-battery-storage/",
    "first_paragraph": "\u0394A nonprofit, independent media organization dedicated to telling stories of climate solutions and a just future.\u0394The wheels on this bus do indeed go round and round. Its wipers swish. And its horn beeps. Hidden in its innards, though, is something special \u2014 a motor that doesn\u2019t vroom but pairs with a burgeoning technology that could help the grid proliferate with renewable energy.These new buses, developed by a company called Zum, ride clean and quiet because they\u2019re fully electric. With them, California\u2019s Oakland Unified School District just became the first major district in the United States to transition to 100 percent electrified buses. The vehicles are now transporting 1,300 students to and from school, replacing diesel-chugging buses that pollute the kids\u2019 lungs and the neighborhoods with particulate matter. Like in other American cities, Oakland\u2019s underserved areas tend to be closer to freeways and industrial activity, so air quality in those areas is already terrible compared"
  }
]