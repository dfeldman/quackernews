[
  {
    "title": "The Lost Japanese ROM of the Macintosh Plus (journaldulapin.com)",
    "points": 72,
    "submitter": "ecliptik",
    "submit_time": "2025-05-17T23:12:15 1747523535",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44017692",
    "comments": [
      "Coincidentally I had never heard of KanjiTalk until earlier this week when I stumbled across it on infinite mac.https://infinitemac.org/1996/KanjiTalk%207.5.3\n \nreply",
      "I'm the nerd that requested this be added to Infinite Mac, as there's a lot of great Japanese software. :) https://news.ycombinator.com/item?id=43607153\n \nreply",
      "The fact that this was machine translated was surprising as it was remarkably readable! Interesting how far that tech has come while I wasn\u2019t looking.\n \nreply",
      "LLMs are quite good at translation. You can even instruct them to use different linguistic styles and regional idioms.They are also quite good at translating poorly written and only semi coherent writing, which can be incredibly useful if the person you are communicating with is quite sloppy.\n \nreply",
      "To be clear, it's the original purpose of LLMs.The whole LLM scene today came about because context was really important to translations. The \"attention is all you need\" paper was by the Google Translation team as they came up with ideas to improve how to map context of words and carry them across in translations.At some point people started asking the translation to \"translate from English to English as if you're an AI assistant\".Anyway it shouldn't surprise anyone that LLMs are good at translation. The real surprise to everyone is how powerful translation engines that understood context could be!\n \nreply",
      "I read your comment after the article and didn't believe it. JP>EN is one of the trickiest pairs for MT and there are usually interesting phrases, understandable but distinctive, that would appear even if an actual human did it.\n \nreply",
      "It was originally written in french\n \nreply",
      "That makes sense, FR>EN is far easier and even Google Translate has been doing a decent job of that for a long time.\n \nreply",
      "[flagged]",
      "I understand what you're saying, but I wonder how many software products, particularly those from the early days of personal computing, have been lost to history due to nobody copying them before the media got deteriorated or destroyed.  Sure, there will always be copies of WordPerfect 5.1 and MS-DOS 6.22 floating around, legal and not-so-legal.  However, there is some old software that is difficult to find, often in situations where not many copies were sold.I wish our copyright laws (I'm in the United States) were more considerate of the needs of computer historians and retrocomputing enthusiasts.  95 years is much too long of a copyright term for software that gets obsolete after 10-20 years.  I can understand lengthy copyrights for video games, since they are works of art and since there is a lot of commercial value in old games.  However, would Mac OS 9 and Windows 98 being in the public domain threaten sales of modern Macs and Windows 11 licenses?  Would WordPerfect 5.1 for MS-DOS being in the public domain hurt Corel's business?  While I do believe it's possible to get licenses to old versions of Microsoft software through certain MSDN subscription programs, many software companies don't sell licenses of older software products.While I'm on the topic, there used to be a museum in Seattle named The Living Computer Museum where visitors could actually use old computers.  I went there in 2019 and had a wonderful time; it's sad that it didn't survive the COVID-19 pandemic.  I wonder, though, how much work (if any) was done with securing legal licenses for the software on these old computers, since I'd imagine that a museum would have a liability problem if it was caught using pirated software.  Given that the museum was founded by the late Paul Allen, it is likely that the museum may have worked out some agreements with the copyright holders of various software tools.  After all, it's not like the museum was reselling the software or the hardware.\n \nreply"
    ],
    "link": "https://www.journaldulapin.com/2025/05/17/the-lost-japanese-rom-of-the-macintosh-plus-which-isnt-lost-anymore/",
    "first_paragraph": " Accueil\n\nIf you look for information about the Macintosh Plus and its ROM, you\u2019ll usually find that the ROM has a capacity of 128 KB and that it exists in three revisions. But that\u2019s incorrect: there\u2019s a fourth ROM, 256 KB in size, which includes fonts for kanji (Japanese characters). And I found (and preserved) this ROM.\n\nI\u2019m Belgian, and the article was originally written in French before being translated automatically.I had talked about this mysterious ROM a few years ago. It\u2019s documented by Apple in some old documents, but without much detail. According to Apple, the ROM contains fonts for kanji in 12 and 18 points, and they are loaded at startup by KanjiTalk. On a regular Macintosh Plus, you need a floppy disk with the files, which slows down startup and uses some RAM, whereas on a Japanese Macintosh Plus, the font is in ROM and doesn\u2019t take up RAM. You also avoid loading files from a floppy disk, theoretically saving 6 seconds during startup. That\u2019s a conservative estimate, as w"
  },
  {
    "title": "Tornado warnings delayed because of DOGE cuts (mesoscalenews.com)",
    "points": 20,
    "submitter": "aaronbrethorst",
    "submit_time": "2025-05-18T01:18:52 1747531132",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.mesoscalenews.com/p/tornado-warnings-delayed-because",
    "first_paragraph": ""
  },
  {
    "title": "AniSora: Open-source anime video generation model (komiko.app)",
    "points": 36,
    "submitter": "PaulineGar",
    "submit_time": "2025-05-17T23:59:03 1747526343",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=44017913",
    "comments": [
      "We\u2019re so close to finally being able to generate our own Haruhi season 3\u2026 what a time to be alive.\n \nreply",
      ">Powered by the enhanced Wan2.1-14B foundation model for superior stability.Wan2.1 is great. Does this mean anisora is also 16fps?\n \nreply",
      "I tested this out with a promotional illustration from Neon Genesis Evangelion. The model works quite well, but there are some temporal artifacts w.r.t. the animation of the hair as the head turns:https://goto.isaac.sh/neon-anisoraPrompt: The giant head turns to face the two people sitting.Oh, there is a docs page with more examples:https://pwz4yo5eenw.feishu.cn/docx/XN9YdiOwCoqJuexLdCpcakSln...\n \nreply",
      "Says it's open source but I'm having trouble finding a link to weights and/or code?Looks incredibly impressive btw. Not sure it's wise to call it `AniSora` but I don't really know.\n \nreply",
      "https://huggingface.co/IndexTeam/Index-anisora\n \nreply",
      "Thanks!> This model has 1 file scanned as unsafe. testvl-pre76-top187-rec69.pthHm, perhaps I'll wait for this to get cleared up?\n \nreply",
      "This is not the first time I've heard of checkpoints being used to distribute malware. In fact, I've heard this was a popular vector from shady international groups.I wouldn't expect this from Bilibili's Index Team, though, given how high profile they are. It's probably(?) a false positive. Though I wouldn't use it personally, just to be safe.The safetensors format should be used by everyone. Raw pth files and pickle files should be shunned and abandoned by the industry. It's a bad format.\n \nreply",
      ">  Not sure it's wise to call it `AniSora` but I don't really know.Given that OpenAI call themselves \"Open\", I think it's great and hilarious that we're reusing their names.There was OpenSora from around this time last year:https://github.com/hpcaitech/Open-SoraAnd there are a lot of other products calling themselves \"Sora\" as well.It's also interesting to note that OpenAI recently redirected sora.com, which used to be its own domain, to sora.chatgpt.com.\n \nreply"
    ],
    "link": "https://komiko.app/video/AniSora",
    "first_paragraph": "The most powerful open-source animated video generation model presented by Bilibili. AniSora enables one-click video generation across diverse anime styles including series episodes, Chinese animations, manga adaptations, VTuber content, anime PVs, and more.Tap to upload or drag your image hereYour animation results will appear hereUpload an image and provide a prompt to get startedExplore a variety of AI-generated videos created with Bilibili's AniSora. Witness its capability to animate still images into dynamic anime and manga scenes, bringing your favorite characters and stories to life with smooth, coherent animation and rich detail. Discover the power of open-source AI in anime video creation.Input ImageOutput VideoModel: AniSora | Prompt: \"The figures in the picture are sitting in a forward moving car waving to the rear, their hair swaying from side to side in the wind\"Input ImageOutput VideoModel: AniSora | Prompt: \"In the video, five girls dance as the camera zooms in. They sin"
  },
  {
    "title": "Coding without a laptop: Two weeks with AR glasses and Linux on Android (holdtherobot.com)",
    "points": 405,
    "submitter": "mikenew",
    "submit_time": "2025-05-14T15:11:57 1747235517",
    "num_comments": 182,
    "comments_url": "https://news.ycombinator.com/item?id=43985513",
    "comments": [
      "Does anyone know if these glasses, or any other glasses, can be tried in-person and used on desktop? I'm legally blind, but have just enough vision to use a screen without a screen reader. The problem is I have to be about 6 inches from a 27 inch screen. I'm tall, and I'm almost bent in half to do it. It's been hell on my back and neck. I've only really made it work because I've modified so many things to get around it (i.e. customising Windows, Firefox, and so on).The part that makes it so tough is monitor arms come in standard sizes and are nowhere near long enough or extend far enough for me to sit comfortably. My dad modified my desk for me years ago to mount a monitor arm on wooden blocks, but it means I can't move the monitor much.Being able to wear glasses and ditch the monitor entirely would be a game changer for me. I know next to nothing about AR though, being as I assumed, perhaps wrongly, it isn't something that would work for me.Edit: Thank you for the replies. It means a lot. I've got some options to explore here now thanks to you.\n \nreply",
      "It sounds like we have a similar situation. I've been wondering if these kinds of glasses would work for me but it just seems like such a hassle to order a pair to try just to end up returning them if they don't work. I wish they were sold in a store that I could just walk into and try them for a minute.FWIW, I use a monitor arm that's mounted on the front left side of my desk (my dad also modified my desk so this would work) so I can pull it as close as I need. It does mean I can't push it back to a normal monitor distance but I'm the only one using my PC so that's not a problem. Oddly enough, I recently got cataract surgery so now I have a lens that makes me focus further away, but now text is too small to read at that distance so I have to use readers to focus closer and use the arm.. seems a little silly but it mostly works out.\n \nreply",
      "Glasses like these put the screen at a focal distance further than a monitor, closer to TV distance. Optics wise it\u2019s basically the same as VR, if a VR headset is easier to try.If your corrected vision needs stuff 6\u201d away, don\u2019t expect AR or VR to be a solution with current optics\n \nreply",
      "The pair I have (original xReal Air) include a glass insert that can be ground to your prescription. It's a thin piece of glass, I don't know exactly what kind of prescription can be put onto them, but it might be helpful.\n \nreply",
      "That is usually for very low prescriptions. Judging by the photos, I don't think you can use those blanks for much more than -2.\n \nreply",
      "This is what I've been worried about. I have lens implants so I already have a fixed focus as well. The combination of the two would likely be a problem.\n \nreply",
      "In a VR headset the virtual screen distance is set by the distance of the microdisplay from the lens in the headset.It's not crazy to think you could move the microdisplay position and get a virtual display at 6\". There might be other optical consequences (aberrations, change in viewable area) but in principle it can work.\n \nreply",
      "The microdisplays are usually fixed in place (and sometimes the display and optics are a single package), so it would likely be a bespoke solution.\n \nreply",
      "I'd be open to trying something like this. It might be the kind of simple solution that would work for me.\n \nreply",
      "Some ar glasses support adjustable focus, and others support custom prescription lenses.\n \nreply"
    ],
    "link": "https://holdtherobot.com/blog/2025/05/11/linux-on-android-with-ar-glasses/",
    "first_paragraph": ""
  },
  {
    "title": "FreeBASIC is a free/open source BASIC compiler for Windows DOS and Linux (freebasic.net)",
    "points": 39,
    "submitter": "90s_dev",
    "submit_time": "2025-05-17T22:47:55 1747522075",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44017592",
    "comments": [
      "This one emulates GW-BASIC as PC-BASIC so old BASIC programs for the IBM PC DOS systems can run on modern systems: https://robhagemans.github.io/pcbasic/FreeBASIC is like Microsoft's QuickBASIC.More BASIC Languages: https://www.thefreecountry.com/compilers/basic.shtml\n \nreply",
      "It really isn't - from the docs themselves:  FreeBASIC gives you the FreeBASIC compiler program (fbc or fbc.exe),\n  plus the tools and libraries used by it. fbc is a command line program\n  that takes FreeBASIC source code files (*.bas) and compiles them into\n  executables.  In the combined standalone packages for windows, the main\n  executable is named fbc32.exe (for 32-bit) and fbc64.exe (for 64-bit)\n\n\nThe magic of QuickBasic was that it was an editor, interpreter, and help system all rolled up into a single EXE file. Punch F5 and watch your BAS file execute line-by-line.\n \nreply",
      "Wasn't QBasic the interpreter as opposed to QuickBasic the compiler?\n \nreply",
      "It's been a long time, but my impression was that QuickBASIC had an interpreter and the ability to compile. Then later on, Microsoft bundled a more limited version called QBasic with later versions of MS DOS which lacked the compiler.But all of them (QBasic, QuickBASIC, Microsoft PDS, and even Visual Basic for DOS which almost nobody remembers sadly) had the editor, interpretative execution, and built-in help.\n \nreply",
      "I remember VB-DOS, and fondly too. It was magical. I think I used it even before VB3.\n \nreply",
      "This is what I recall too. QuickBasic was perhaps BASIC's answer to Turbo Pascal, a relatively lightweight but usable text based IDE. I knew some happy users.\n \nreply",
      "> The magic of QuickBasic was that it was an editor, interpreter, and help system all rolled up into a single EXE file. Punch F5 and watch your BAS file execute line-by-line.That's still how vscode works; F5 to debug and Ctrl-[Shift]-P like CtrlP.vim: https://code.visualstudio.com/docs/debugtest/debuggingFWICS,The sorucoder.freebasic vscode extension has syntax highlighting:\nhttps://marketplace.visualstudio.com/items?itemName=sorucode...There's also an QB64Official/vscode extension that has syntax highlighting and keyboard shortcuts: \nhttps://github.com/QB64Official/vscodere: how qb64 and C-edit are like EDIT.COM, and GORILLA.BAS:  \nhttps://news.ycombinator.com/item?id=41410427C-edit: https://github.com/velorek1/C-edit\n \nreply",
      "Rather, QB was the pico8 of the 1990s. Convenient, self-contained, mysterious, quasi-powerful, in-app help menu for the entire language and API, and a few built-in demo games.\n \nreply",
      "I tried QB64 a couple years ago, but IIRC it's still compiled as opposed to interpretative, e.g. you can't Ctrl-Break and drop into the current executing line of BASIC code unless they've radically changed how it works.\n \nreply",
      "> FreeBASIC is like Microsoft's QuickBASIC.Except that it doesn't emulate Microsoft's QuickBASIC, or ... ?\n \nreply"
    ],
    "link": "https://freebasic.net/",
    "first_paragraph": "\n          FreeBASIC is a free/open source (GPL), BASIC compiler for Microsoft Windows, DOS and Linux.\n        \nGet FreeBASIC\u00a0\n\n          When used in its \"QB\" language mode, FreeBASIC provides a high level of support for programs\n          written for QuickBASIC. Many programs written for QuickBASIC will compile and run in this mode\n          with no changes needed. However, for compilation in the FreeBASIC default language mode,\n          most substantial programs will require changes.\n        \n          FreeBASIC is a self-hosting compiler which makes use of the GNU binutils programming tools as\n          backends and can produce console, graphical/GUI executables, dynamic and static libraries.\n          FreeBASIC fully supports the use of C libraries and has partial C++ library support. This lets\n          programmers use and create libraries for C and many other languages. It supports a C style\n          preprocessor, capable of multiline macros, conditional compiling and file inc"
  },
  {
    "title": "Mystical (suberic.net)",
    "points": 151,
    "submitter": "mmphosis",
    "submit_time": "2025-05-17T18:21:18 1747506078",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=44016037",
    "comments": [
      "This has uses right? A prettier form of QR code? Would be a tad difficult to decode automatically but I definitely like the combination of aesthetics with logic.\n \nreply",
      "I call upon th\u0435 blood-moon goddess, for I have but one request. I've laid the altar, charged the crystals, the circle, I have blessed.  PLEASE boot this time.\n \nreply",
      "Knock the candle from scripture stack\n \nreply",
      "Couldn't think of any applications of this outside of doing actual magic. But this is awesome still!\n \nreply",
      "This must be the preferred programming language of the otherworldly main character of Aphyr's \"Xing the technical interview\" sequence of blog posts [1]. Would definitely deserve its own entry in the series.[1] https://aphyr.com/posts/354-unifying-the-technical-interview\n \nreply",
      "Reminds me of japanese anime Denn\u014d Coil, where kids would draw computer programs almost exactly like the author\u2019s on the floor and invoke them as some kind of enchantement. Highly recommend it!\n \nreply",
      "I loved that show. It showed how children deal with new technology different from how adults deal with it. It predated even google glass by half a decade.\n \nreply",
      "I should rewatch that. There\u2019s many shows that get worse over time, but I just don\u2019t think anything has changed in regards to DC. Even now it\u2019ll seem like pure magic, but just close enough to believable you might see it in your lifetime.Of course my lifetime has marched on relentlessly since I first saw it.\n \nreply",
      "I came here to say exactly the same thing! What a great show.\n \nreply",
      "More on chaos magick and sigil casting 101: https://archive.org/details/the-psychonaut-field-manual\n \nreply"
    ],
    "link": "https://suberic.net/~dmm/projects/mystical/README.html",
    "first_paragraph": "I wanted to make a programming language that resembled magical circles. This is more like a way to write PostScript that looks like a magical circle, but I will refer to it as Mystical in this document.The structure of Mystical is based on rings. These are circular bands of text and sigils, with an inner and outer border. The content of the main ring of a program starts at the rightmost (3:00) point and flow continues widdershins (counter-clockwise) both to respect postscript's angles and to reflect the assumption that these rings should be written from the outside.  Subsidiary rings start from their attachment point to their caller.There are three types of rings in Mystical:(Note that the entries in the dict image are in a different order than the PostScript text since dict insertion order is not preserved in PostScript.)When one of these structures appear inside a different structure, a small circle or dot at the inclusion point is connected to a line which leads to the subsidiary ri"
  },
  {
    "title": "Dead Stars Don\u2019t Radiate (johncarlosbaez.wordpress.com)",
    "points": 167,
    "submitter": "thechao",
    "submit_time": "2025-05-17T17:54:20 1747504460",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=44015872",
    "comments": [
      "> As Mark Twain said, \u201cA lie can travel around the world and back again while the truth is lacing up its boots.\u201d Actually he probably didn\u2019t say that\u2014but everyone keeps saying he did, illustrating the point perfectly.Well played.\n \nreply",
      "lol, I wrote a very similar comment here a few days ago:https://news.ycombinator.com/item?id=43964524It's true, that paper is nonsense.  There's not really much else to say.  Preprint servers sometimes publish the sort of stuff that wouldn't pass peer review.  (Remember that S.Korean \"superconductor\" from about two years ago!?)  The press should be cautious when writing about it.\n \nreply",
      "Although that paper even made it to PRL. I guess I should have written up some similar nonsense and sent it to PRL, might have improved my career chances.\n \nreply",
      ">  It would also mean that quantum field theory in curved spacetime can only be consistent if baryon number fails to be conserved! This would be utterly shocking.Is it really shocking (today)? I mean, isn't this a logical consequence of Hawking radiation for black holes? I thought we were shocked by this a long time ago, but now we're ok with it. The authors of the paper in question may very well be wrong in their calculations (I can't say), but this blog post doesn't smell good to me because of doubtful statements like these, passed off as so obviously true that you must be an idiot not to agree. That kind of emotional writing does not become someone whose profession should focus on scientific persuasion.From Wikipedia [0], itself citing Daniel Harlow, a quantum gravity physicist at MIT:> The conservation of baryon number is not consistent with the physics of black hole evaporation via Hawking radiation.[0] https://en.m.wikipedia.org/wiki/Baryon_number\n \nreply",
      ">That kind of emotional writing does not become someone whose profession should focus on scientific persuasion.What you'd probably prefer reading is one of the sources John Carlos Baez cites [0]:Comment on \u201cGravitational Pair Production and Black Hole Evaporation\u201d\nAntonio Ferreiro1, Jos\u00e9 Navarro-Salas, and Silvia PlaWhere they take the equation used in the paper, and outline how there is a better way than using that equation\"... is obtained to the lowest order in a perturbative expansion, while the standard way to obtain the non-perturbative Schwinger effect using the weak field approximation is to perform a resummation of all terms\"and how the one in the paper being critiqued can't handle situations arising from electromagnetic cases, much less the gravitational one properly.  These are the statements Baez makes but the cited paper gives in a much more professional tone and method.https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.13...\n \nreply",
      "I'm not sure what more you want from him, there are many papers and even a textbook linked?It's bloody John Baez, the man knows his stuff.On you actual point, it is shocking because its claimed that baryon number is not conserved without black holes getting involved\n \nreply",
      "Are you saying that when Baez referred to \"curved spacetime\" he was excluding black holes (because the paper was claiming that non--black-holes have Hawking radiation?) or are you saying something else?\n \nreply",
      "well he certainly mentions a result where if there is an everywhere timelike Killing vector field (+ some other assumptions) you can prove that Hawking radiation doesn't occur and that does not include for example the Schwarzschild solution because the Killing vector field partial/partial t becomes non-timelike on the horizon.So for example if you take a dead star in a vacuum with nothing else in the universe (and make certain technical assumptions) then you can prove that the star does not emit Hawking radiation. That's quite a strong result, and certainly does make the result seem shocking.\n \nreply",
      ">> if baryon number fails to be conserved! This would be utterly shocking.> Is it really shocking (today)?Moreover, there are a few experiments that try to measure the proton decay (that would break the baryon number conservation.) They are run on Earth, far away form any black hole. For now, all of them failed to find a decay, and the conclusion is that the half life of protons is at least 2.4E34 years. https://en.wikipedia.org/wiki/Proton_decay#Experimental_evid...I found an old article by quantamagazine explaining one of the experiment. It's a huge pool of very pure water and a lot of detectors. No black hole required. https://www.quantamagazine.org/no-proton-decay-means-grand-u... (HN discussion https://news.ycombinator.com/item?id=13201065 )\n \nreply",
      "Also, the Standard Model does allow nonconservation of baryon number, nonperturbatively.\n \nreply"
    ],
    "link": "https://johncarlosbaez.wordpress.com/2025/05/17/dead-stars-dont-radiate-and-shrink/",
    "first_paragraph": "Three guys claim that any heavy chunk of matter emits Hawking radiation, even if it\u2019s not a black hole:\u2022 Michael F. Wondrak, Walter D. van Suijlekom and Heino Falcke, Gravitational pair production and black hole evaporation, Phys. Rev. Lett. 130 (2023), 221502.Now they\u2019re getting more publicity by claiming this means that the universe will fizzle out sooner than we expected.  They\u2019re claiming, for example, that a dead, cold star will emit Hawking radiation, and thus slowly lose mass and eventually disappear!They admit that this would violate baryon conservation: after all, the protons and neutrons in the star would have to go away somehow!  They admit they don\u2019t know how this would work.  They just say that the gravitational field of the star will create particle-antiparticle pairs that will slowly radiate away, forcing the dead star to lose mass somehow to conserve energy.If experts thought this had even a chance of being true, it would be the biggest thing since sliced bread\u2014at least"
  },
  {
    "title": "Directory of MCP Servers (github.com/chatmcp)",
    "points": 85,
    "submitter": "saikatsg",
    "submit_time": "2025-05-17T19:14:56 1747509296",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=44016336",
    "comments": [
      "I\u2019ve been seeing MCP compared to extensions in web browsers. Which I find telling, since I wouldn\u2019t exactly say web extensions have been a great success - it\u2019s a pretty niche dev market, and the security posture remains pretty anxiety inducing\n \nreply",
      "We've built a version of this on steroids - not only a registry, but also one-click mcp hosting. Would love you eyeballs if you're into mcp: https://supermachine.ai\n \nreply",
      "There's some movement on https://github.com/modelcontextprotocol/registry> The MCP Registry service provides a centralized repository for MCP server entries. It allows discovery and management of various MCP implementations with their associated metadata, configurations, and capabilities.\n \nreply",
      "@ VS Code we've been collaborating on this and plan to ship initial support for registries in our next release.\n \nreply",
      "Is this like 10 years ago when you could find a Directory of GraphQL Servers?Seems silly in retrospect no?\n \nreply",
      "I wonder if there's a market for someone figuring out how to build monetization into MCP or something similar.Being able to offer a helpful API to the world and just getting paid whenever someone uses it would be really nice.At the moment you have to process the payment \"yourself\" (even if you use a third party for that), issue an API key, etc.\n \nreply",
      "I reckon the target market would have to be non-developers (because MCP servers are easily reproducible with LLMs, they even encourage it in the docs), and you wouldn't even mention MCP. Just have a list of tools which you can optionally enable in the chat client\n \nreply",
      "Here are a few more:- https://smithery.ai/- https://github.com/wong2/awesome-mcp-servers- http://mcp.so/servers- https://cursor.directory/mcpBut as mentioned above, there is an ongoing discussion for the Anthropic registry https://github.com/modelcontextprotocol/registry\n \nreply",
      "FYI https://mcp.so/ is the exact same thing as was posted. Not sure why they directed to the github instead of the actual site..\n \nreply",
      "So far, I\u2019ve catalogued over 6,000 MCP servers.If you\u2019re interested in the next layer beyond just discovering MCP servers, I\u2019ve been working on https://ninja.ai \u2014 an app store for AI assistants to connect to tools via MCP, without needing to touch the command line. Think one-click installs for pipes that let agents actually do things like triage email or book Ubers.Would love feedback if you\u2019re experimenting in this space too!\n \nreply"
    ],
    "link": "https://github.com/chatmcp/mcpso",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        directory for Awesome MCP Servers\n      a directory for Awesome MCP Servers.live preview: https://mcp.socreate a database with Supabaserun the sql file in data/install.sqlput a .env file in the root directorywith env variables:open http://localhost:3000 in your browser\n        directory for Awesome MCP Servers\n      "
  },
  {
    "title": "Proton threatens to quit Switzerland over new surveillance law (techradar.com)",
    "points": 257,
    "submitter": "taubek",
    "submit_time": "2025-05-17T14:59:10 1747493950",
    "num_comments": 142,
    "comments_url": "https://news.ycombinator.com/item?id=44014808",
    "comments": [
      "This law change died in the \"Vernehmlassung\" which is early in the process. It's dead with opposition from all sides of the political spectrum. It had no chance.https://www.inside-it.ch/vupf-revision-faellt-in-der-vernehm...\n \nreply",
      "It\u2019s odd people don\u2019t push for laws to prevent for these kinds of laws to keep bubbling up every few years.\n \nreply",
      "The law can't bind future lawmakers. That's a common feature of every legal system.Any legal system can pass a law saying \"we revoke this previous law\".\n \nreply",
      "This is what constitutions are for. When you have the support, you install a constitutional protection that says the government can't do this. Repealing the protection requires the same super-majority needed to pass it, so changing the law isn't just a matter of the tyrants needing to get back to 51% from 49%, they have to get from 33% to 67%.Then you layer these protections against multiple levels of government so they'd all have to be repealed together by separate legislatures before the government is allowed to do it, discouraging the attempt.\n \nreply",
      "Hah, I was going to say that sounded needlessly heavy handed.Then I checked what the Netherlands does and found that changing the constitution doesn\u2019t merely require you to get a majority, it also requires you to survive at least one election and keep that (super)majority before you can even begin.\n \nreply",
      "In Switzerland you can change the constitution with popular votes. That only requires for 50% of the voters to agree and half of the cantons.\n \nreply",
      "Then get half the voters to agree to make it two thirds. After you put the other protections in, naturally.\n \nreply",
      "You\u2019re arguing for massive changes to a very unique country with the oldest democracy in Europe. Unless you\u2019re Swiss, or have credentials related to Swiss law, I don\u2019t think you\u2019re arguing anything realistic.\n \nreply",
      "Countries can be as unique as they want to be, but they still need a system for preventing authoritarianism. The existing system is fine if it's effective and not fine if it isn't.\n \nreply",
      "Switzerland has been preventing authoritarianism since before it was cool.  Like, for 700 years. (With a brief interruption when they were invaded and overthrown by Napoleon.)  So their system for the first 600 of those 700 years was the best system for preventing authoritarianism; a lot of it survives today.\n \nreply"
    ],
    "link": "https://www.techradar.com/vpn/vpn-privacy-security/we-would-be-less-confidential-than-google-proton-threatens-to-quit-switzerland-over-new-surveillance-law",
    "first_paragraph": "If passed, new rules would require VPNs and messaging apps to identify and retain users' data\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nProton confirms the company will leave Switzerland if new controversial surveillance rules pass.Switzerland is considering amending its surveillance law, with experts warning against the risk to secure encryption and online anonymity in the country. Specifically, the amendment could require all VPN services, messaging apps, and social networks to identify and retain user data \u2013 an obligation that is now limited to mobile networks and internet service providers.The firm behind one of the best VPN and encrypted email services, Proton, is ready to fight back on behalf of the privacy of its over 100 million users. Other Swiss-based companies, like NymVPN, are also doing the same.TechRadar needs you! We want to know what you think about the world of VPNs. Whether you're a novice or a VPN pro, we w"
  },
  {
    "title": "GM Is Pushing Hard to Tank California's EV Mandate (wsj.com)",
    "points": 14,
    "submitter": "NN88",
    "submit_time": "2025-05-18T01:17:42 1747531062",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44018241",
    "comments": [
      "So isn't every other fossil fuel based transportation manf.20 years ago this would upset me a lot.Now I am resigned to the fact 2 or 3 generations from now people will live through a time that will make the mongol invasions look like a tea party ran by three 7 year old girls :(No stopping Climate Change now\n \nreply",
      "I am hopeful China\u2019s EV, battery, and renewables manufacturing machine steamrolls the world. Developed world fossil fuel and legacy auto will try to slow down the transition, so only overwhelming force solves for it.https://www.reuters.com/business/autos-transportation/byd-ai...https://about.bnef.com/blog/china-already-makes-as-many-batt...https://e360.yale.edu/features/china-renewable-energyCurrent US admin only has 3.6 years left.\n \nreply"
    ],
    "link": "https://www.wsj.com/business/autos/california-ev-mandate-auto-industry-64708033",
    "first_paragraph": ""
  },
  {
    "title": "Bike-mounted sensor could boost the mapping of safe cycling routes (newatlas.com)",
    "points": 29,
    "submitter": "yunusabd",
    "submit_time": "2025-05-14T11:27:52 1747222072",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=43983196",
    "comments": [
      "I was curious if the sensor would pick up other things like trees or other cyclist, but it seems like they accounted for that:> We then log a sensor events [sic] if the majority of cells in the sensor frame agree to the same value within a threshold parameter [...]. This ensures that sensor events are only logged when large objects like cars block the sensor\u2019s field-of-view , i.e., one or more small objects like branches or distance pedestrians in the sensor\u2019s field-of-view will not trigger this condition. While there is no guarantee that this approach strictly identifies cars, we empirically saw during testing that passing cyclists and pedestrians rarely satisfied this condition at the typical passing distance due to the wide field-of-view of the VL53L8.Also interesting that it's quite cheap to build:> The whole system can cost less than $25 [...]From the paper\nhttps://dl.acm.org/doi/10.1145/3706598.3713325\n \nreply",
      "So if I\u2019m in a protected bike lane with a row of parked cars to my left wouldn\u2019t it be flagging every parked car as a potential hazard?\n \nreply",
      "From the photos, there appears to be more than one sensor on the device which may be used to tell which direction the large object is coming from. Unless you were cycling backwards or mounted the device the wrong way around you shouldn't have any stationary cars passing you. Just a guess though.\n \nreply",
      "I don\u2019t know Seattle so I\u2019d be curious to know if the proximity and accident hotspots are also high traffic zones in general, whether they have a bike like (and how it\u2019s placed), and if the routes are even bike routes or just routes that riders comfortable jostling in traffic like me took. Comfortable riders may also skew the data by being willing to \u201clane split\u201d at red lights to pass stopped cars  rather than waiting at the back in lane.Having biked a lot in SF, my impression is the best protected bike lanes are on wide roads like Folsom/Howard, Fell/Oak, etc. where proximity isn\u2019t generally an issue, but I\u2019d expect intersections to be riskier due to higher car speeds. While cars passing on isn\u2019t an issue on the Wiggle with a critical mass of riders, on neighborhood streets where sharing the road is obligated the drivers can be scariest, especially in the Sunset. In NYC, an abundance of one lane, one way streets make controlling an entire street easier.The reality of city design at the moment is almost any bike route will require the sharing the road with cars at some point, usually at the start and end of a ride, because bike lane and \u201cbike route\u201d coverage is often poor in residential areas and business districts.\n \nreply",
      "I am willing to give it a good try  even if it's never perfect!I live in a major city and the increased traffic from scooters  almost feels like it could support a separate lane even if bikes didn't exist\n \nreply",
      "In my area there has been a program for years where you can sign up to mount a device like this to your bike for pretty much this exact same purpose. From memory it goes behind your seatpost thougho which seems less annoying.\n \nreply",
      "As a long-time cyclist and former bike courier, I think most of the proximity concerns are probably of my own doing. I wonder if the device somehow accounts for this.My initial reaction is that an accelerometer might be a better data-point, or combining this with accelerometer data.I'm working on the assumption that a smoother path means I am interacting less with traffic or other hazards.\n \nreply",
      "I\u2019m not sure how much that matters. You won\u2019t need to initiate close passes as often on a safer street.\n \nreply",
      "Given a choice between a street where the cars are stuck in 2km/hr traffic and I'm passing them with a less than foot (0.3m) gap, or a street with 70km/hr traffic where they're passing me with a 1 meter (3 foot) gap... the former feels a lot safer.Admittedly these streets aren't usually close together (either in time or space), but I've certainly biked on both.Still, imperfect data can be better than no data.\n \nreply",
      "I wonder if this can be predicted by a heat map of car crashes in your area. This  is based on my private hunch that car crashes are a predictor of bike crashes. After all, if a car can crash into another car, or a stationary object such as a tree or a building, then it can crash into another bike. And the causes may be similar: Speed and inattention.On such a map for my locale, the most crash-prone roads are exactly the ones that I instinctively avoid.\n \nreply"
    ],
    "link": "https://newatlas.com/bicycles/proxicycle-bicycle-sensor-safe-cycling-routes/",
    "first_paragraph": ""
  },
  {
    "title": "If nothing is curated, how do we find things (tadaima.bearblog.dev)",
    "points": 156,
    "submitter": "nivethan",
    "submit_time": "2025-05-17T15:51:05 1747497065",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=44015144",
    "comments": [
      "Good curation is amazing.When I first signed on to Netflix it worked me out and suggested a bunch of stuff that I love to this day.But then it ran out of stuff, or they borked the algorithm and now it sucks. And all its competitors suck.One thing I have noticed is that if you ask a human for a specific recommendation like \"Suggest me a novel like The Martian\" if they dont have a specific recommendation, you just get their favourite instead. Which makes reddit threads and similar completely useless. The signal to noise ratio is awful.\n \nreply",
      "I've been saying this forever!!  When I was a teen in the 90s, I got new music from the radio.  The music director picked 40ish songs a week and that's what we listened to.  I still like to listen to the radio for the curation.I even wrote a program to scrape the websites of my favorite radio stations (well the stations of my favorite music directors) and add the songs to a Spotify playlist.Whenever I meet a teenager today, one of the first things I ask them is \"what apps do you use most\", but the next thing I ask is \"how do you find new music\".The answer is usually something like \"I don't know, I just sort of find stuff I guess?\".  Some have said they follow influencer's playlists on YouTube or Spotify, which I guess is the new version of the music director?  Or they just get it from Spotify playlists.But what's missing is a shared cultural experience.  In the 90s, everyone at my school knew those 40 songs that the local stations played.  They might know other stuff too, but you couldn't avoid those top songs.  It's not the same today.  And it's the same problem for visual media.  We all knew the top movies at the theater, because it was the only place to see new movies.  And we all knew the top TV shows because they were only on four major networks.Kids don't have a shared cultural experience like I did.\n \nreply",
      "I am not sure if I agree.I feel like social media trough its amplification has lead to a global sync in topics and experiences.I\u2019d argue a kid growing up India or China shares much more culturally today with a western Kid than 30 years ago.Take the news for example. Last weeks it was tariffs. The entire world was talking about the same thing.To the contrary I feel like we are living more and more in the same global reality going from one headline to the next every week.\n \nreply",
      "I heavily disagree with this one. On first glance what you say feels true, but there are so many mega popular people now that you will never know of despite even being from the same country. People with dozens of millions of fans, selling out arenas doing multinational tours and you won\u2019t know them at all.But everyone knows Britney Spears, even if you were never in her target demographic. This sort of global fame now requires so much more to reach because of how many are really locked into hyper personalized online experiences. I used to be able to reference the latest big movie or show and people would know, now that\u2019s mostly turned into an explanation that the movie or show even came out and exists.\n \nreply",
      "Unfortunately not - I remember overhearing a conversation between neighbors after the Russian invasion in Ukraine - it was a glowing recommendation of Russia from one neighbor, the other neighbor worked there in the past and attempted to explain that this is not true - the Russia fan also attended the COVID is a conspiracy demonstrations here. East Germany. Also met multiple people in bars telling me they vote AfD after telling me conspiracy theories. Same but different thing in university context if you argue about identity politics with upper class students - no concept of class or economic realities - verbatim copy of US talking points. Everyone has their own reality. It's beyond scary. These are extremes but they are not unique.\n \nreply",
      "Not just headlines being shared, but culture is still being shared.Sure the shared cultural experience of being limited to a handful of TV channels is gone, but it's been replaced by a handful of streaming services.  The world has shared the Marvel Cinematic Universe and 800lb sisters and Taylor Swift.\n \nreply",
      "> 800lb sistersFirst time I hear of these. I now wish I had not looked them up (I did not think it would be so literal).(I also now realise that I cannot even remember how Taylor Swift sounds like, despite hearing about her quite frequently...)\n \nreply",
      "Nope you\u2019re wrong. Actually media has become hyperlocal.The whole world was talking about tariffs? Nope. They were talking whatever they saw on their personalised feed.\n \nreply",
      "> But what's missing is a shared cultural experienceThis is my problem with the proliferation of streaming platforms when it comes to movies and TV. We\u2019ve arguably got more and better content than we\u2019ve ever had. But I find myself far less motivated to watch it. I used to watch content anticipating the conversations I\u2019d have with friends and colleagues. Now, whenever we try to talk about it, it\u2019s 30 seconds of, \u201cHave you seen \u2026?\u201d \u201cNo, have you seen \u2026?\u201d \u201cNo.\u201d Until we give up and talk about something else.It\u2019s made me realize that the sharing it with others part was always my favorite part of listening/watching and, without that, I can\u2019t really become emotionally invested it the experience.\n \nreply",
      "I find that I've mostly made up for that part by participating in online discussions.But that leads to a different problem -- When Netflix drops an entire season of something, I feel like I have to have time to watch the whole thing, or I don't watch at all.  Because I don't want participate in the online discussion having seen less than everyone else.I end up watching the shows that drop one episode a week far more often than whole seasons at once.\n \nreply"
    ],
    "link": "https://tadaima.bearblog.dev/if-nothing-is-curated-how-do-we-find-things/",
    "first_paragraph": ""
  },
  {
    "title": "Palette lighting tricks on the Nintendo 64 (30fps.net)",
    "points": 180,
    "submitter": "ibobev",
    "submit_time": "2025-05-17T14:28:59 1747492139",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=44014587",
    "comments": [
      "Demo scene and work like this is impressive. Yet I can't help but notice that it tends toward simpler more empty scenes. The kind of stuff one might expect in the background or as only a part of a game mechanic. It's as if there's just not enough resources to really make complete experiences with most of the techniques.What I find more impressive are efforts like FastDoom or the various Mario-64 optimization projects which squeeze significantly better performance out of old hardware. Sometimes even while adding content and features. Maybe there is a connection between demo sceners and more comprehensive efforts?\n \nreply",
      "It's very impressive to see \"realistic\" graphics on the N64. The demo reminds me of \"ICO\" for the PS2.I've always wondered if it would be possible to create an SDK to abstract the N64 graphics hardware and expose some modern primitives, lighting, shading, tools to bake lighting as this demo does, etc. The N64 has some pretty unique hardware for its generation, more details on the hardware are here on Copetti.org:https://www.copetti.org/writings/consoles/nintendo-64/\n \nreply",
      "Note that the N64 was designed by SGI, And seeing as how influential SGI was for 3d graphics, I sort of assume the reverse, that the n64 probably has the most standard hardware of it's generation. I would be vaguely surprised if there was not an opengl library for it.However there is a large caveat, 1. you have to think of the system as a graphics card with a cpu bolted on. and 2. the graphics system is directly exposed.Graphics chip architecture ends up being a ugly hateful incompatible mess, and as such the vendors of said accelerators generally tend to avoid publishing reference documents for them, preferring to publish intermediate API's instead. things like OpenGL, DirectX, CUDA, Vulcan, mainly so that under the hood they can keep them an incompatible mess(if you never publish a reference, you never have to have hardware backwards compatibility, the up side is they can create novel designs, the down side is no one can use them directly) so when you do get direct access to them, as in that generation of game console, you sort of instinctively recoil in horror.footnote on graphics influence: OpenGL came out of SGI and nvidia was founded by ex SGI engineers.\n \nreply",
      "> that the n64 probably has the most standard hardware of it's generationThe Reality Coprocessor (or RCP) doesn't look like any graphics cards that previously came out of SGI. Despite the marketing, it is not a shrunk down SGI workstation.It approaches the problem in very different ways is actually more advanced in many ways. SGI workstations had strict fixed function pixel pipelines, but RCP's pixel pipeline is semi-programmable. People often call describe it as \"highly configurable\" instead of programmable, but it was the start of what lead to modern Pixel Shaders. RCP could do many things in a single-pass which would require multiple passes of blending on a SGI workstation.And later SGI graphics cards don't seem to have taken advantage of these innovations either. SGI hired a bunch of new engineers (with experience in embedded systems) to create the N64, and then once the project was finished they made them redundant. The new technology created by that team never had a chance to influence the rest of SGI. I get the impression that SGI was afraid such low-cost GPUs would cannibalise their high-end workstation market.BTW, The console looks most like a shrunk down 90s SGI workstation is actually Sony's Playstation 2. Fixed function pixel pipeline with a huge amount of blending performance to facilitate complex multi-pass blending effects. Though, SGI wouldn't have let programmers have access to the Vector Units and DMAs like Sony did. SGI would have abstracted it all away with OpenGL------------------But in a way, you are kind of right. The N64 was the most forwards looking console of that era, and the one that ended up the closest to modern GPUs. Just not for the reason you suggest.Instead, some of the ex-SGI employees that worked on the N64 created their own company called ArtX. They were originally planning to create a PC graphics card, but ended up with the contract to first create the GameCube for Nintendo (The GameCube design shows clear signs of engineers overcompensating for flaws in the N64 design). Before they could finish, ArtX were bought by ATI becoming ATI's west-coast design division, and the plans for a PC version of that GPU were scrapped.After finishing the GameCube, that team went on to design the R3xx series of GPUs for ATI (Radeon 9700, etc).The R3xx is more noteworthy for having a huge influence on Microsoft's DirectX 9.0 standard, which is basically the start of modern GPUs.So in many ways, the N64 is a direct predecessor to DirectX 9.0.\n \nreply",
      "The RCP was actually two hardware blocks, the RDP which as you say did the fixed function (but very flexible) pixel processing and the RSP which handled command processing and vertex transformation (and audio!).The standard api was pretty much OpenGL, generating in-memory command lists that could be sent to the RSP.However the RSP was a completely programmable mips processor (with simd instructions in parallel).One of my favorite tricks in the RDP hardware was it used the parity bits in the rambus memory to store coverage bits for msss\n \nreply",
      "> The standard api was pretty much OpenGLGood point. It is the software APIs are where you do see the strong SGI influence. It's not OpenGL, but it's clearly based on their experience with OpenGL. The resulting API is quite a bit better than other 5th gen consoles.It's only the hardware (especially RDP) that has little direct connection to other SGI hardware.\n \nreply",
      "Super Mario 64 has been decompiled an ported to GL 1.3.\n \nreply",
      "Shadow of the Colossus...\nhttps://www.youtube.com/watch?v=xMKtYM8AzC8\n \nreply",
      "That is very impressive for a PS2 game.\n \nreply",
      "And a sequel (prequel?) to ICO, from the same devs\n \nreply"
    ],
    "link": "https://30fps.net/pages/palette-lighting-tricks-n64/",
    "first_paragraph": ""
  },
  {
    "title": "Understanding Transformers via N-gram Statistics (arxiv.org)",
    "points": 41,
    "submitter": "pona-a",
    "submit_time": "2025-05-17T19:56:00 1747511760",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arxiv.org/abs/2407.12034",
    "first_paragraph": "Work on one of the world's most important websites and make an impact on open science.arXiv Is Hiring a DevOps EngineerHelp | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "How to have the browser pick a contrasting color in CSS (webkit.org)",
    "points": 139,
    "submitter": "Kerrick",
    "submit_time": "2025-05-17T16:26:44 1747499204",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=44015367",
    "comments": [
      "This is a great overview of the pros/cons of this. For those creating just a simple site, this is a solid easy way to have proper contrast.For those making anything at a production scale where you need wcag compliance however, I'd avoid this and leverage a proper semantic token layer. Semantic tokens will help both accelerate your dev cycle, and they'll help guarantee proper contrast ratios in a way that looks visually better than just switching your foreground layer to black or white. The great thing about a semantic token layer is they're extremely easy to theme, which means you get light/dark theming for very little additional cost. You can also create separate WCAG2 / APCA accessible themes, should your brand color be one of the ones that WCAG2 has issues with - will get you compliance while still providing a better visual contrast option.This is kind of my niche domain specialty - I run the variables/tokens stream at Figma, and I've worked on the dark mode implentation for both Figma and Atlassian. Happy to answer any questions about tokens/themes/accessible color.\n \nreply",
      "I don\u2019t disagree, in fact I absolutely agree but the last 2/3 just sounds like meaningless jibber jabber to make yourself look smart. I\u2019m not saying it\u2019s not true but it\u2019s word vomit.I like the feature but in a corporate site/application, you don\u2019t want to rely on this function because you cannot control what the result is going to be. For all I know, WebKit could fix some later bug or change something that changes the result color to something that I don\u2019t want.\n \nreply",
      "What do you mean by semantic tokens?This exact type of functionality has caused a major project a work on to use CSS in JS (for relative colors and contrast colors.I\u2019m glad to see this type of thing coming around the corner and look forward to it being widely available in a couple years.\n \nreply",
      "With regards to color on the web, semantic tokens refer to css variables that are named in a way that describes their use, ie:* bg-brand (this would be used whenever you need your brand color as a background)* text-danger (likely a red text color)* icon-warning-hover (likely a dark yellow-orange that's slightly different from icon-warning)Generally speaking, there are three \"levels\" of tokens: primitive, semantic, and component. Primitive tokens describe the value. In the case of color, this might be a color ramp. IE red/100, red/200, red/300. Semantic tokens reference primitive tokens. IE bg-brand might have its value set to blue/300. This layer is sometimes called a \"reference\" layer because of this, but I'm not a fan of that nomenclature since the component layer also references the semantic layer. The component layer is one that describes where in a component the token should be used, ie button-bg or button-text. I highly, HIGHLY recommend against using a component layer though in all but the most extreme multi-brand situation. If you aren't unilever, you should never use component tokens.\n \nreply",
      "Aren't there many, many schemes for naming tokens in design systems? Aren't you being a bit forward in presenting this as a general practice?https://medium.com/eightshapes-llc/naming-tokens-in-design-s...\n \nreply",
      "Not parent, but the generalization is true. There\u2019s usually a base layer (red/300, etc) and a more semantic layer (.text-danger).As your link covers, there\u2019s then a million different ways to implement/extend that based on whatever theming and systems you\u2019re implementing on top.\n \nreply",
      "This only works if you don\u2019t let users theme your site. If you do, then OPs approach works better.\n \nreply",
      "there is a way to do something close to this using lch:  --text: lch(from var(--bg) calc((49.44 - l) * infinity) 0 0);\n\nsource: https://til.jakelazaroff.com/css/swap-between-black-and-whit...\n \nreply",
      "I\u2019ve never seen any CSS function that has this call back style where you get parameters that you can modify. So interesting! Are there any other examples of this or is this unique to lch?\n \nreply",
      "This is \"relative color\" syntax, it works with a range of color spaces/color functions. The key is the \"from\" at the front. Here's the MDN documentation: https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_colors/...\n \nreply"
    ],
    "link": "https://webkit.org/blog/16929/contrast-color/",
    "first_paragraph": "May 13, 2025by Jen SimmonsHave you ever wished you could write simple CSS to declare a color, and then have the browser figure out whether black or white should be paired with that color? Well, now you can, with contrast-color(). Here\u2019s how it works.Imagine we\u2019re building a website or a web app, and the design calls for a bunch of buttons with different background colors. We can create a variable named --button-color  to handle the background color. And then assign that variable different values from our design system in different situations.Sometimes the button background will be a dark color, and the button text should be white to provide contrast. Other times, the background will be a lighter color, and the text should be black. Like this:Now, of course, we could use a second variable for the text color and carefully define the values for --button-color and --button-text-color at the same time, in pairs, to ensure the choice for the text color is the right one. But, on a large proje"
  },
  {
    "title": "Push Ifs Up and Fors Down (matklad.github.io)",
    "points": 363,
    "submitter": "goranmoomin",
    "submit_time": "2025-05-17T09:31:55 1747474315",
    "num_comments": 140,
    "comments_url": "https://news.ycombinator.com/item?id=44013157",
    "comments": [
      "My weird mental model: You have a tree of possible states/program flow. Conditions prune the tree. Prune the tree as early as possible so that you have to do work on fewer branches.Don\u2019t meticulously evaluate and potentially prune every single branch, only to find you have to prune the whole limb anyways.Or even weirder: conditionals are about figuring out what work doesn\u2019t need to be done. Loops are the \u201cwork.\u201dUltimately I want my functions to be about one thing: walking the program tree or doing work.\n \nreply",
      "Can I float an adjacent model? Classes are nouns, functions are verbs.\n \nreply",
      "I like to think of it completely differently: Functions are where you hide things, Classes are where you expose things.Functions to me are more about scoping things down than about performing logic. The whole program is about performing logic.\n \nreply",
      "http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom...\n \nreply",
      "And then at some point someone shows you how Classes can be verbs, and functions can be nouns, and your brain hurts for a while. You overuse that paradigm for a while, and eventually learn to find the appropriate balance of ideas.\n \nreply",
      "Haven\u2019t seen that yet after 25 years. It just always seems like lazy naming when this isn\u2019t followed. Maybe I missed something.\n \nreply",
      "I have to agree, particularly if you look at functions as pipelines: data/events go in, other data/events go out.If I had to hazard some kind of heuristic with 99% applicability, it'd be to always strive to have code with as few indentations (branches) as possible. If your code is getting too indented, those deep Vs are either a sign that your implementation has a strong mismatch with the underlying problem or you need to break things up into smaller functions.\n \nreply",
      "I remember being taught that in CS101 and still use it today 15 years later. It's a good and simple and easy to follow pattern\n \nreply",
      "Didn\u2019t the Apollo guidance computers work with VERB and NOUN?\n \nreply",
      "perfectly good models\n \nreply"
    ],
    "link": "https://matklad.github.io/2023/11/15/push-ifs-up-and-fors-down.html",
    "first_paragraph": "A short note on two related rules of thumb.\n            If there\u2019s an if condition inside a function, consider\n            if it could be moved to the caller instead:\n          \n            As in the example above, this often comes up with preconditions: a\n            function might check precondition inside and \u201cdo nothing\u201d if it\n            doesn\u2019t hold, or it could push the task of precondition checking to\n            its caller, and enforce via types (or an assert) that the\n            precondition holds. With preconditions especially, \u201cpushing up\u201d can\n            become viral, and result in fewer checks overall, which is one\n            motivation for this rule of thumb.\n          \n            Another motivation is that control flow and ifs are\n            complicated, and are a source of bugs. By pushing ifs\n            up, you often end up centralizing control flow in a single function,\n            which has a complex branching logic, but all the actual work is\n            deleg"
  },
  {
    "title": "ARMv9 Architecture Helps Lift Arm to New Financial Heights (nextplatform.com)",
    "points": 5,
    "submitter": "rbanffy",
    "submit_time": "2025-05-14T09:11:47 1747213907",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.nextplatform.com/2025/05/12/armv9-architecture-helps-lift-arm-to-new-financial-heights/",
    "first_paragraph": ""
  },
  {
    "title": "Espanso \u2013 Cross-Platform Text Expander Written in Rust (github.com/espanso)",
    "points": 52,
    "submitter": "kartikarti",
    "submit_time": "2025-05-14T14:11:46 1747231906",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=43984770",
    "comments": [
      "I found Espanso very useful, but some bugs made me move on to Raycast, BetterTouchTool, etc. for similar functionality. For example, if Espanso config file is on a cloud drive, it doesn't automatically sync or read the file upon reboot.I'm planning to move back to Espanso though, as Raycast is moving in the wrong direction with all the AI non-features.\n \nreply",
      "Can't you just write a startup script that waits 1 minutes after a reboot and then restarts the Espanso service to apply the freshly downloaded config?\n \nreply",
      "Anyone know how to change the default :date output to YYYY-MM-DD instead of MM/DD/YYYY on macOS?I\u2019ve tried the following in default.yml and reloading the config, but it\u2019s not working and Claude, Gemini, and myself are stumped :)  matches:  \n    - trigger: \":date\"  \n      replace: \"{{mydate}}\"  \n      vars:  \n        - name: mydate  \n          type: date  \n          params:  \n            format: \"%Y-%m-%d\"\n \nreply",
      "Solution: Edit the # Print the current date section in\u2026  /Users/$USER/Library/Application Support/espanso/match/base.yml\n\n\u2026to read:  # Print the current date\n  - trigger: \":date\"\n    replace: \"{{mydate}}\"\n    vars:\n      - name: mydate\n        type: date\n        params:\n          format: \"%Y-%m-%d\"\n \nreply",
      "I shell out to POSIX `date` on Linux and I believe also on Windows:    - trigger: \";tod\"\n      replace: \"{{mydate}}\"\n      vars:\n      - name: mydate\n        type: shell\n        params:\n          cmd: date --iso-8601\n \nreply",
      "Have been using it for some years now. On Linux at least, it's easy to install and maintain.The size of my snippets list is now a testament of its usefulness. On the appropriate context (an online meeting, for instance), it feels like a superpower.\n \nreply",
      "I\u2019m using it on KDE for quite some time now. It\u2019s very useful, but sometimes types too fast and eats keystrokes. Other than that it\u2019s flawless. Can recommend to anyone.\n \nreply",
      "Can you not configure the text speed?\n \nreply",
      "The single best way to insert emojis into text, I cannot function without this tool\n \nreply",
      "I\u2019ve been using this for about 6 months. Love it.\n \nreply"
    ],
    "link": "https://github.com/espanso/espanso",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Cross-platform Text Expander written in Rust\n      A cross-platform Text Expander written in Rust\n\n\nVisit the espanso website.A text expander is a program that detects when you type\na specific keyword and replaces it with something else.\nThis is useful in many ways:Visit the official documentation.If you need some help to setup espanso, want to ask a question or simply get involved\nin the community, you can join the official Subreddit\nor join the official Discord!espanso is a free, open source software developed in my (little) spare time.\nIf you liked the project and would like to support further development,\nplease consider making a small donation, it really helps :)Many people helped the project along the way, thank you to all of you!espanso was created by Federico Terzi\nand is licensed under the GPL-3.0 license.\n        Cross-pla"
  },
  {
    "title": "\u201cStreaming vs. Batch\u201d Is a Wrong Dichotomy, and I Think It's Confusing (morling.dev)",
    "points": 12,
    "submitter": "ingve",
    "submit_time": "2025-05-14T11:29:04 1747222144",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43983201",
    "comments": [
      "Streams have unknown size and may be infinite.Batches have a known size and it are not infinite.\n \nreply",
      "Maybe I'm using the wrong definitions, but I think that's backwards.Say you are receiving records from users and different intervals and you want to eventually store them in a different format on a database.Streaming to me means you're \"pushing\" to the database according to some rule. For example, wait and accumulate 10 records to push. This could happen in 1 minute or in 10 hours. You know the size of the dataset (exactly 10 records). (You could also add some max time too and then you'd be combining batching with streaming)Batching to me means you're pulling from the database. For example, you pull once every hour. In that hour, you get 0 records or 1000 records. You don't know the size and it's potentially infinite\n \nreply",
      "I work with batch oriented store and forward systems and they definitely push data in batches.\n \nreply",
      "If streaming is 5x as expensive as batch, that might be a factor worth considering.\n \nreply",
      "It's quite amazing how none of the comments have bothered reading the article, but are also commenting about something completely unrelated to its title.The article rightfully says that it's not a question of streaming OR batching, because you can stream batches.\n \nreply",
      "Because the author is lost in peculiarities of the systems he happens to work with that he is redefining the terms (see all the discussion around \"push\" and \"pull\"). That's gonna run into this problem.His problem is one of data transfer and a better fit for what hes looking for is probably \"polling\" versus \"interrupt\" driven.\n \nreply",
      "Streams -> optimized for latencyBatches -> optimized for efficiency\n \nreply",
      "streaming should be used exclusively for live data...if you keep things that way everything falls smoothly in place\n \nreply",
      "This gets messy though because the deeper you dig the more the word \"live\" loses meaning.\nIs \"live\" data something emitted within milliseconds? Seconds? Is it \"live\" if it\u2019s replayed from a buffer with minimal delay?\nReal-time systems aren\u2019t always real-time. Some \"live\" streams are just batched updates in disguise.\nYou blink and suddenly you\u2019re in temporal quantum soup.And once you push the boundaries\u2014high-frequency trading, deep space comms, even global-scale latency\u2014you run into the brick wall of physics.\nAt certain speeds and distances, simultaneity stops being objective.\nTwo observers won\u2019t agree on what \"just happened.\"\nCausality gets slippery. Streams bifurcate.At that point, \"live\" isn\u2019t just fuzzy\u2014it\u2019s frame-dependent.\nYou\u2019re not streaming reality anymore. You\u2019re curating a perspective.\n \nreply"
    ],
    "link": "https://www.morling.dev/blog/streaming-vs-batch-wrong-dichotomy/",
    "first_paragraph": "Often times, \"Stream vs. Batch\" is discussed as if it\u2019s one or the other, but to me this does not make that much sense really.Many streaming systems will apply batching too, i.e. processing or transferring multiple records (a \"batch\") at once,\nthus offsetting connection overhead, amortizing the cost of fanning out work to multiple threads,\nopening the door for highly efficient SIMD processing, etc., all to ensure high performance.\nThe prevailing trend towards storage/compute separation in data streaming and processing architectures\n(for instance, thinking of platforms such as WarpStream, and Diskless Kafka at large)\nfurther accelerates this development.Typically, this is happening transparently to users, done in an opportunistic way:\nhandling all of those records (up to some limit) which have arrived in a buffer since the last batch.\nThis makes for a very nice self-regulating system.\nHigh arrival rate of records: larger batches, improving throughput.\nLow arrival rate: smaller batches, "
  },
  {
    "title": "Weather Report from Saturn's Moon Titan (sci.news)",
    "points": 8,
    "submitter": "astroimagery",
    "submit_time": "2025-05-15T15:44:03 1747323843",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.sci.news/astronomy/titan-weather-13907.html",
    "first_paragraph": "Using data from the NASA/ESA/CSA James Webb Space Telescope and the Keck II telescope, astronomers found evidence of cloud convection in the northern hemisphere of Titan. Most of Titan\u2019s lakes and seas are located in that hemisphere, and are likely replenished by an occasional rain of methane and ethane. Webb also has detected a key carbon-containing molecule that gives insight into the chemical processes in Titan\u2019s complex atmosphere.These images of Titan, taken by Webb on July 11, 2023 (top row), and the Keck II telescope on July 14, 2023 (bottom row), show methane clouds (white arrows) appearing at different altitudes in Titan\u2019s northern hemisphere. Image credit: NASA / ESA / CSA / STScI / Keck Observatory.Titan is an intriguing world cloaked in a yellowish, smoggy haze. Similar to Earth, the atmosphere is mostly nitrogen and has weather, including clouds and rain.Unlike Earth, whose weather is driven by evaporating and condensing water, frigid Titan has a methane cycle.It evaporate"
  }
]