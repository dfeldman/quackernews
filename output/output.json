[
  {
    "title": "Moon (ciechanow.ski)",
    "points": 1459,
    "submitter": "todsacerdoti",
    "submit_time": "2024-12-17T17:26:26 1734456386",
    "num_comments": 131,
    "comments_url": "https://news.ycombinator.com/item?id=42443229",
    "comments": [
      "This is wonderful!!!  Generalizing here but we really do take the moon for granted.I bought a 'big ass telescope' a few years ago in an effort to bootstrap a hobby that I'd flirted with for decades but never really committed to.  It's a Celestron 11\" SCT and I really had no idea what I was getting into.  When I think of space I think of things that are really small in the night sky, planets, galaxies, nebula...(turns out most of them aren't *that* small and I overshot the targets I had in mind)I kept trying to photo galaxies and star clusters and all of these exotic things but had a bunch of trouble with tracking with long exposures.  Out of frustration I ended up just pointing it at the boring ol' moon to at least get used to the equipment and workflows.I fell in love with Luna.The magnification of this scope really allowed me to explore the surface in a way I never had before.  I got to know the 'map' and suddenly related to our celestial neighbor in a whole new way.  It was also the very first image I was actually not embarrassed to share - https://imgur.com/a/t9b1UugI since then improved my knowledge and technical skill but the month of the moon at the end of 2021 was really pretty spectacular for me.\n \nreply",
      "> turns out most of them aren't that smallI haven't realized Andromeda is 4x bigger than the Moon until I tried to take a picture of ithttps://mikkolaine.blogspot.com/2014/01/size-of-deep-sky-obj...\n(not my picture)\n \nreply",
      "It really is a great shot. I always daydream of showing today's technology to the great the great minds from centuries ago. Not sure why, but I do.\n \nreply",
      "I\u2019m sure it\u2019s different for everyone but I think it would just be the unbridled enthusiasm and love for the subject that they would show, the tidal dopamine surge of all the mysteries that have been unlocked, the validation of all the mysteries that remain.  It would be amazing.\n \nreply",
      "And I'm here for it! :D\n \nreply",
      "Similarly, I came to learn some selenography writing a \"voxel\" (well, ray-casting) web game ... where you shuttle about the moon from crater base to crater base.I became kind of fascinated with the craters, names of the craters (and history of those names), the \"dark-side\" and all the wild topology there. (Although I think I have tiles for the entire Moon, you don't have the fuel to get there.\n \nreply",
      "Did you publish it? Can we see?\n \nreply",
      "Welcome to the hobby (even if a few years late). Pretty much everyone has the same experience as you. You buy the telescope, and then realize you need to buy a telescope for your telescope to use as a guide scope for accurate tracking for longer exposures.However, those long exposures are much more likely to get photobombed by an airplane or satellite. So you're really better off taking shorter exposures with the highest ISO you can get away with, and then just stacking them.I have a much wider scope that I can do 30s exposures unguided before trailing starts to become noticeable. If you can get away with 15s, you'd be amazed at what you can achieve with newer sensors.Just some hints to help the disappointment at bay and maybe get you playing with the toys\n \nreply",
      "An 11\" SCT is a commitment to use. Do you have it on a permanent mount?\n \nreply",
      "No, but i did just get a wedge so I could start tinkering with polar alignment.I also bought a Seestar S50 last year and have been having an absolute blast with it.  Feels like a renaissance in astronomy is upon us.\n \nreply"
    ],
    "link": "https://ciechanow.ski/moon/",
    "first_paragraph": "In the vastness of empty space surrounding Earth, the Moon is our closest celestial neighbor.\nIts\u00a0face, periodically filled with light and devoured by darkness, has an ever-changing, but dependable presence in our skies.In this article, we\u2019ll learn about the Moon and its path around our planet, but to experience that journey first-hand, we have to enter the cosmos itself.Let\u2019s take a look at the Moon as seen from space in all its sunlit glory. You can drag it around to change your point of view, and you can also use the slider to control the date and time:In this convenient view, we can freely pan the camera around to see the Moon and its marvelous craters and mountains from various angles. Unfortunately, we don\u2019t have that freedom of motion in our daily experience \u2013 the Moon wanders on its own path across the daily and nightly skies.We can simulate these travels below, where you can see the current position of the Moon in the sky. You can drag that panorama around to adjust your viewi"
  },
  {
    "title": "We Built the Saturn V (2017) (smithsonianmag.com)",
    "points": 27,
    "submitter": "areoform",
    "submit_time": "2024-12-18T00:17:54 1734481074",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42446889",
    "comments": [
      "> At more than $100 million each (equivalent to $750 million today), they departed Earth, then fell in pieces into the ocean.Could you imagine the unit cost today, if we kept building Saturn V in an iteratively improving process? Even as an expendable rocket, the efficiencies from mass production and weight savings from miniaturizing avionics would have produced a very capable, affordable machine.\n \nreply",
      "We modernized and rationalized the Space Shuttle to make the SLS and each SLS costs > $4B.Building Saturn V's at low volume under the standard cost-plus arrangements that NASA uses with Boeing et al would result in steadily increasing costs.\n \nreply",
      "Should have (2017)I noticed that when it said at the start:> five giant F-1 rocket engines\u2014still the most powerful ever builtThis is no longer the case. The SpaceX Starship has the Saturn V beat nowdays.(Edit: I suppose the F-1 rocket engines still have the Raptor 2 engines beat, so the article is still correct. The Starship just has more engines than the Saturn V for more thrust)\n \nreply",
      "An individual F1 engine outperforms an individual Raptor 2/3.\n \nreply",
      "I just realized that after hitting post. Edited my comment.\n \nreply",
      "The line you quoted specifically says F-1 engine, not Saturn V rocket.\n \nreply",
      "[flagged]",
      "Please don\u2019t incite a culture war for no reason, the article has nothing to do with race or gender\n \nreply",
      "Username checks out...\n \nreply"
    ],
    "link": "https://www.smithsonianmag.com/air-space-magazine/we-built-saturn-v-180964759/",
    "first_paragraph": ""
  },
  {
    "title": "FastVideo: a lightweight framework for accelerating large video diffusion models (github.com/hao-ai-lab)",
    "points": 60,
    "submitter": "zhisbug",
    "submit_time": "2024-12-17T20:56:01 1734468961",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42445239",
    "comments": [
      "For anyone that wants to test the original (non-distilled) HunyuanVideo (which is an amazing model) we have 580p version taking under a minute and 720p version taking around 2.5-3 minutes in our playground: https://fal.ai/models/fal-ai/hunyuan-video (it requires github login & and is pay-per-use but new accounts get some free credits).\n \nreply",
      "Hugginface model and data link: https://huggingface.co/FastVideo\n \nreply",
      "Someone wrote the following comment then deleted it. I spent 30 minutes on my response and wanted to post it anyway. Apologies if the original comment was deleted by a mod, I hope this is OK to post.---QUOTE---My \"test\" for video generation turning movie making on its head is when a model can add the missing Tom Bombadil chapters to Peter Jackson's LOTR movies.Probably 20 - 30 minutes of HD, aesthetically synced, scripted etc with minimal editing after a detailed prompt and source material.Qualifier - the AI just has to follow the book script, third party tools ok to use for lip syncing and audio :)I said 5 years away last year.Feels like it might be more like 1 - 2 years.What do you think?---END QUOTE---My response:I think we're getting into diminishing returns territory with this AI stuff. These video/image generators are impressive but they don't \"understand\" physical reality and probably never will without a breakthrough. You can see this in the demo videos, the best looking ones are glorified still images and the worst are whenever something physical happens, like the lemon being picked up or the guy eating cereal. These examples may get better, but I really doubt they'll ever look like real unaltered camera footage without adding an understanding of how our physical reality works into the model somehow.For the script generation, Fellowship of the Ring is not a movie script and requires serious interpretation and planning to be converted into one. Especially if you want it to fit into Jackson's films at all. If nothing else the dialog and frequency of songs/poetry are very different. The current text generators aren't really capable of that kind of planning yet, but I wouldn't be surprised if there's a screenwritten treatment of that chapter floating around on the internet somewhere, or at least bits of one. It has certainly ingested The Fellowship of the Rings, and plenty of screenplays plus the books they were based on. So maybe chatgpt can make a convincing script. I asked the free version and got some dialog that seems fine, but absolutely no scene direction at all. I'm willing to believe that was either an issue with my prompting or something that can be fixed in 5 years. So at least the script may be possible.As for converting it into an actual piece of film, I don't think that's currently possible without a breakthrough on planning. There's a reason these video demos aren't usually very long, it's because they aren't good at scene changes. People's faces change, rooms change shape, etc. Maybe that can be fixed through engineering, but film editing is hard. It's not easy to plan and chain together shots in a way that gives a proper sense of physical reality while conveying everything a scene needs to.Take a look at Dan Olsen's video analyzing the editing of Suicide Squad[1]. That movie was edited by a trailerhouse and it shows. A big issue is that the scenes and shots don't flow together very well - it's edited like a bunch of separate shots and scenes rather than a coherent whole. As a result it's generally considered one of the worst films big budget ever made. And from my (admittedly limited) understanding/playing around with these generators, they aren't even remotely close to being able to do the type of planning needed to pull that kind of editing off, much less something on the level of Jackson's adaptation. Again I could be wrong but it really seems like another \"Attention is All You Need\" level breakthrough to get there.So I'd say no, I don't think we'll get what you describe, at least not at any level of quality, in 1-2 years. 5 years sounds more realistic but I really believe we'd need another huge breakthrough to get there, and those are hard to come by. Assuming one will happen in any given time period seems foolish. But a lot of smart people are working on that, so maybe we'll get it. But I don't think we'll even get there in 10 years with just engineering improvements on the current stuff. Scientific progress isn't linear.Yours and a lot of other predictions about AI stuff really remind me of how all the futurists in the 50's thought we'd be able to freeze and unfreeze humans in a few short years. They thought that because it's actually really easy to do that with hamsters, but it turns out scaling the process up isn't so easy (Tom Scott has a good video tangentially related to this[2]). I think a lot of people are standing near the top of the steep part of a sigmoid curve and saying \"Wow look how far we've come in just 3 years! The next 3 years are going to be insane!\" When in reality we just have a long plateau of minor improvements in front of us. But who knows, maybe that next breakthrough is right around the corner.[1]: https://www.youtube.com/watch?v=mDclQowcE9I\n[2]: https://www.youtube.com/watch?v=2tdiKTSdE9Y\n \nreply",
      "Does the distillation done here have a large impact on quality compared to the original \"slow\" models?\n \nreply",
      "We need videocards with lots of memory. Give me a 4080 with 192gb. I would be happy. We really need AMD to come up with new cards to wake up NVidia and start some fierce competition\n \nreply",
      "It's not really feasible to scale GDDR-based designs that big. The 5090 is expected to have 32GB which probably means the workstation variant will have 64GB, but that's the limit of the conventional GPU memory architecture for now. HBM is fast and high capacity but prohibitively expensive, and LPDDR is cheap and high capacity but relatively slow, so there's no free lunch to be had.\n \nreply",
      "What would it take to have a unified memory architecture to rival Apple's ? Is it theoretically possible with PC motherboards and GPUs that sit in card slots of some form?\n \nreply",
      "NVIDIA Jetson?\n \nreply"
    ],
    "link": "https://github.com/hao-ai-lab/FastVideo",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        FastVideo is an open-source framework for accelerating large video diffusion model.\n      FastVideo is a lightweight framework for accelerating large video diffusion models.\n    \ud83e\udd17 FastMochi | \ud83e\udd17 FastHunyuan  | \ud83d\udd0d  Discord \nFastVideo currently offers: (with more to come)Dev in progress and highly experimental.Fast-Hunyuan comparison with original Hunyuan, achieving an 8X diffusion speed boost with the FastVideo framework.Comparison between OpenAI Sora, original Hunyuan and FastHunyuanThe code is tested on Python 3.10.0, CUDA 12.1 and H100.We recommend using a GPU with 80GB of memory. To run the inference, use the following command:You can also inference FastHunyuan in the official Hunyuan github.Our distillation recipe is based on Phased Consistency Model. We did not find significant improvement using multi-phase distillation, so we ke"
  },
  {
    "title": "OpenAUTH: Universal, standards-based auth provider (openauth.js.org)",
    "points": 54,
    "submitter": "jacobrussell",
    "submit_time": "2024-12-16T01:17:23 1734311843",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42427169",
    "comments": [
      "> While OpenAuth tries to be mostly stateless, it does need to store a minimal amount of data (refresh tokens, password hashes, etc). However this has been reduced to a simple KV store with various implementations for zero overhead systems like Cloudflare KV and DynamoDB. You should never need to directly access any data that is stored in there.Written like someone who's never actually maintained an identify provider used in B2B contract work. You will inevitably come into contact with people who cannot make things work on their side and are doing things so unexpectedly that logging is insufficient to track down the error. Sooner or later you will need to look at the data actually in storage to figure out what your customers who are threatening to cancel their contract are doing wrong.I've been there. Many times.\n \nreply",
      "KV Stores aren't magical... and you do need to store this data somewhere.So what's different between this (or any of these new-aged Auth services) and something else more traditional? If anything, these new-age services make it easier to access your data if you need to, since you often control the backing database unlike auth0, etc.Both DynamoDB and Cloudflare KV are queriable.I guess I don't understand the negativity in your comment. If anything, your complaint sounds like an issue you and your team cooked up on your own.\n \nreply",
      "I don\u2019t think it\u2019s the architecture or technology the commenter is reacting to, it\u2019s this line: \u201cYou should never need to directly access any data that is stored in there.\u201dStatements like that are a huge red flag that the designers of the product are not particularly experienced with operating this type of system at meaningful scale.\n \nreply",
      "Eh, the technology stack they discuss is directly accessible, though.I read this as an advertisement, meaning if everything it working well you don't need to manage the database. Which is probably how it works 99% of the time in fairness.\n \nreply",
      "If the creators of a system are blas\u00e9 enough to imagine you\u2019ll neither need nor want to manage or query the underlying data storage, then they\u2019re telegraphing enormous naivet\u00e9 and inexperience.\n \nreply",
      "Can we not call any authentication scheme/protocol/service starting with \"Open\" and even \"O\" anymore? We already have OAuth, OATH, OpenID, OpenIDConnect, and Okta; it's getting out of hand.\n \nreply",
      "\"Auth\" is also super overloaded. OP is an authentication or AuthN tool which is not the same nor does it encompass authorization or AuthZ. I'm partial to using the terms \"identity\" and \"permissions\" instead.\n \nreply",
      "Cool project!OAuth-based auth providers are nice, but they can have a weakness. When you have just one app, OAuth can be overkill: protocol is complex, and users suffer jarring redirects\u00b9.This is not surprising, because OAuth / OIDC is fundamentally designed for (at least) three parties that don't fully trust each other: user, account provider and an app\u00b2. But in a single app there are only two parties: user and app itself. Auth and app can fully trust each other, protocol can be simpler, and redirects can be avoided.I'm curious what OpenAUTH authors think about it.\u00b9 Except for Resource Owner Password Credentials (ROPC) grant type, but it's no longer recommended: https://datatracker.ietf.org/doc/html/draft-ietf-oauth-secur...\u00b2 In addition, OAuth is mostly designed for and by account providers, and follows their interests more than interests of app developers.\n \nreply",
      "https://www.keycloak.org/ is pretty great too, if you need a little more.\n \nreply",
      "Good for them for trying! I've been in the auth space for a few years and am surprised that a stateless AWS lambda for doing the exchange. (At least I haven't seen any.) So it is nice to see some serverless innovation.Thoughts from a quick scan:- They support PKCE (yay!)- They suggest storing access tokens in localstorage (boo!)- They support JWKS (yay!)\n \nreply"
    ],
    "link": "https://openauth.js.org/",
    "first_paragraph": "While there are many open source solutions for auth, almost all of them are libraries that are meant to be embedded into a single application. Centralized auth servers typically are delivered as SaaS services - eg Auth0 or Clerk.OpenAuth instead is a centralized auth server that runs on your own infrastructure and has been designed for ease of self hosting. It can be used to authenticate all of your applications - web apps, mobile apps, internal admin tools, etc.It adheres mostly to OAuth 2.0 specifications - which means anything that can speak OAuth can use it to receive access and refresh tokens. When a client initiates an authorization flow, OpenAuth will hand off to one of the configured adapters - this can be third party identity providers like Google, GitHub, etc or built in flows like email/password or pin code.Because it follows these specifications it can even be used to issue credentials for third party applications - allowing you to implement \"login with myapp\" flows.OpenAut"
  },
  {
    "title": "Includeable minimal operating system for C++ (includeos.org)",
    "points": 61,
    "submitter": "we-do-not-sow",
    "submit_time": "2024-12-17T21:29:52 1734470992",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=42445508",
    "comments": [
      "What's with the recommendation for a YouTube MP3 converter near the bottom? There seems to be no technological relation so I can only guess the author got paid to include it, but you're legally supposed to disclose if something is a paid ad\n \nreply",
      "Is it a legal requirement? I thought it (disclaiming ads) was something one did to avoid the proverbial pitchforks and nothing more.\n \nreply",
      "I found the linked page very confusing, the whole page just say some generic unikernel stuffsThis page is much better, telling me how it is different/interesting \nhttps://www.includeos.org/technology.html\n \nreply",
      "This seems very interesting!But... \"So IncludeOS can compile C and C++ applications natively. Currently, these are the only programming languages supported. We\u2019ll add support for other language runtimes in 2019.\"Last blog update is 2019. Is the project still alive?edit: github shows recent activity, so it is encouraging.\n \nreply",
      "I've seen this come up here and elsewhere before, always very cool! I always wonder who's actually using it for production workloads, in what context, etc.It feels like so much of the world focuses on docker images that alternatives are pretty hard to get going.\n \nreply",
      "Isn't this what's more typically called a unikernel?EDIT: I see, their GH page actually uses this term, but this landing page does not.\n \nreply",
      "Pretty cool way to turn x86es into embedded machines.\n \nreply",
      "Checkout https://osdev.orgAnd actually, x86 started life as an embedded processor :)\n \nreply",
      "Amazing how we've come full circle. Type II hypervisors treat VM guests as processes, so is it any wonder we've developed ways to develop them as processes? A paravirtualized VM is just a process with a different (and arguably better) system call interface.\n \nreply",
      "Very cool.\n \nreply"
    ],
    "link": "https://www.includeos.org/",
    "first_paragraph": "IncludeOS allows you to run your application in the cloud without an operating system. IncludeOS adds operating system functionality to your application allowing you to create performant, secure and resource efficient virtual machines.IncludeOS applications boot in tens of milliseconds and require only a few megabytes of disk and memory.[View on Github]\n[Chat on Slack]\n[Tell me more]To run a service with IncludeOS on Linux or macOS you do not need to install IncludeOS, however you need to install a few dependencies depending on the service you will run. You can start by trying out our simplest hello_world service. For this service you will need the following dependencies.With the above dependencies you should be able to build an application within minutes.buffett.onlinesongdonkey.aiThe hello world booted service should look like this:For detailed instructions see the GitHub README. Once installed we suggest looking at and booting a few of the demo-examples to familarize yourself with t"
  },
  {
    "title": "The XOR Texture (lodev.org)",
    "points": 6,
    "submitter": "doener",
    "submit_time": "2024-12-18T00:43:24 1734482604",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://lodev.org/cgtutor/xortexture.html",
    "first_paragraph": ""
  },
  {
    "title": "Voxon: Real time interactive volumetric holograms (voxon.co)",
    "points": 107,
    "submitter": "lastdong",
    "submit_time": "2024-12-14T00:26:13 1734135973",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=42413574",
    "comments": [
      "This device is a volumetric display, similar in product placement (if not exactly the same illumination technology) to the volumetric dome display from Actuality Systems about 20 years ago.Volumetric displays have their place, but they can't display general occlusion of far objects by near objects. That restricts their application to non-photorealistic scenes that often look like clouds of points.Since occlusion is one of our strongest depth senses (much stronger than stereopsis), that's a significant restriction.Big spinny things are also hard to scale.While other autostereoscopic display technologies like the parallax barrier displays from Looking Glass Factory give up the ability to walk around the scene, they work with no moving parts and can display photorealistic scenes (either synthetic or photographic).Again, different display technologies have their place, but volumetric displays have historically struggled to compete in the 3D display market.\n \nreply",
      "So, they show mostly correct applications: CAD / 3D-modeling work, schematic visualizations, etc.Also, for an individual seated user, it's relatively easy to adjust the direction of gaze, and do occlusion at the rendering level, giving a rough idea of occlusion. They even show it in one of the segments of the video on the product page (with some color balls).\n \nreply",
      "Occlusion could be done with head tracking for one observer (not both eyes though); but defeats the point.  I'm guessing AR glasses will work for much of this.\n \nreply",
      "It's neat and all but I can't help being skeptical that, beyond certain narrowly specific use cases, volumetric displays like this will measurably increase actual utility enough to be worth the increased cost, size, weight, power and complexity. I'm assuming \"utility\" here to be something like \"usefully actionable increased comprehension of a 3D object or terrain\".My reasoning is that the human visual system already has a bunch of neural wetware that's evolved to be really good at turning visual cues like highlights, shadows, reflections, specularity, depth of field, etc from a 2D scene into an internal 3D representation. When you add extra cues over time like object/light source motion, moving POV and parallax it gets even better. And all those cues are already \"free\" with common 2D displays + motion. Adding a bit of additional hardware to 2D commodity displays enables things like stereo binocular views from 3D glasses, head tracking and interactive control which further deepen scene comprehension at only slightly more cost, space and complexity. That's a lot of pre-existing, cheaper, easier alternatives that are as good as volumetric displays for most use cases and nearly as good for the remaining use cases.Beyond a few specialty use cases, research labs and military trials, I suspect the majority of these displays will be deployed as a novelty to attract attention or as social signaling (eg trade show booths, high-end retail, corporate hospitality, etc). Unfortunately, those kinds of use cases tend to have a shelf life only about as long as the novelty and high early adopter prices last.\n \nreply",
      "It competes with many different things.On one hand there are light field displays like https://lookingglassfactory.com/ not to mention plain stereoscopic displays as in the Nintendo 3DS and maybe someday synthetic hologram displays that do the same thing as the light field displays except using a wave interpretation of light as opposed to a ray.Then there are various headsets such as the MQ3, Vision Pro (basically VR with some video passthrough) and the other kind such as Hololens, Magic Leap that have an optical combiner.For that matter you can make a 3-d print of an object that you want to inspect.Practically they stand or fall together on being able to exchange content,  there is no \"3d economy\" unless I can make a model with some standard format and view it with all of those displays.\n \nreply",
      "It feels like this is the barrier to that 3D economy.  The width of an iphone is approximately the interpupil distance of an average adult, moving one camera to the other side would make stereoscopic image/video capture a widespread capability.  It just lacks an application.\n \nreply",
      "The latest iPhones can already do stereoscopic image and video capture for viewing in the Vision Pro. It works pretty well.\n \nreply",
      "Here's a cool (mostly) 3D-printed realization of a similar concept: https://www.youtube.com/watch?v=pcAEqbYwixU\nThe author just released the mechanical assembly as .step file (https://github.com/AncientJames/VortexParts), and plans on releasing the firmware in the near future.\nAnd yes, it can run Doom!\n \nreply",
      "These seem fine for ads and signage. Some airports have them above the TSA checkpoints.  But can\u2019t see how useful they would be for using this as a display to view complex 3d objects.\n \nreply",
      "I came across this similar DIY build on YT recently - https://www.youtube.com/watch?v=pcAEqbYwixUThe tech is interesting but I can't see the practical uses just yet :)\n \nreply"
    ],
    "link": "https://www.voxon.co",
    "first_paragraph": "ProductsPartner ProgramDevelopersContactFAQMoreVoxon\u2019s VLED technology creates real time interactive volumetric holograms using millions of points of light floating in 3D space. Captivating and immersive, these holograms can be viewed from 360 degrees so everyone can experience them from their own perspective. \u00a0What was once imagined in science fiction is now a reality. Welcome to the future of entertainment, communication and data visualization.The VX2 is Voxon\u2019s next generation volumetric hologram technology - the result of years of engineering innovation and technological development.\u00a0\u200bCompatible with standard 3D file formats and workflows, with the VX2 you can begin showcasing interactive volumetric holograms today.The VX2-XL delivers an unparalleled volumetric experience, with increased visual clarity and a larger display area that enables immersive, high-impact holographic content. Designed for commercial use, the VX2-XL is ideal for environments that require captivating, shared "
  },
  {
    "title": "Launch HN: Langfuse (YC W23) \u2013 OSS Tracing and Workflows to Improve LLM Apps (github.com/langfuse)",
    "points": 162,
    "submitter": "mdeichmann",
    "submit_time": "2024-12-17T13:43:29 1734443009",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=42441258",
    "comments": [
      "(unsolicited review) we've been happy adopters of LangFuse at AINews (https://smol.ai/news). ive been tracking the llm ops landscape (https://www.latent.space/p/braintrust) for a while and its very nice to have an open source solution that is so comprehensive and intuitive!reflections/thoughts on where this field goes next:1. i wonder if there are new ops solutions for the realtime apis popping up2. retries for instructor like structured outputs mess up the traces, i wonder if they can be tracked and collapsible3. chatgpt canvas like \"drafting\" workflows are on the rise (https://www.latent.space/p/inference-fast-and-slow) and again its noisy to see in a chat flow4. how often do people actually use the feedback tagging and then subsequently finetuning? i always feel guilty that i dont do it yet and wonder when and where i should.\n \nreply",
      "appreciate your constructive feedback!> i wonder if there are new ops solutions for the realtime apis popping upThis is something we have spent quite some time on already, both on designs internally and talking to teams using Langfuse with realtime applications. IMO the usage patterns are still developing and the data capturing/visualization needs across teams is not aligned. What matters: (1) capture streams, (2) for non-text provide timestamped transcript/labels, (3) capture the difference between user-time and api-level-time (e.g. when catching up on a stream after having categorized the input first).We are excited to build support for this, if you or others have ideas or a wishlist, please add them to this thread: https://github.com/orgs/langfuse/discussions/4757> retries for instructor like structured outputs mess up the traces, i wonder if they can be tracked and collapsibleGreat feedback. Being able to retroactively downrank llm calls to be `debug` level in order to collapse/hide them by default would be interesting. Added thread for this here: https://github.com/orgs/langfuse/discussions/4758> chatgpt canvas like \"drafting\" workflows are on the rise (https://www.latent.space/p/inference-fast-and-slow) and again its noisy to see in a chat flowCan you share an example trace for this or open a thread on github? Would love to understand this in more detail as I have seen different trace-representations of it -- the best yet was a _git diff_ on a wrapper span for every iteration.> how often do people actually use the feedback tagging and then subsequently finetuning? i always feel guilty that i dont do it yet and wonder when and where i should.Have not seen finetuning based on user-feedback a lot as the feedback can be noisy and low in frequency (unless there is a very clear feedback loop built into the product). More common workflow that I have seen: identify new problems via user feedback -> review them manually -> create llm-as-a-judge or other automated evals for this problem -> select \"good\" examples for fine-tuning based on a mix of different evals that currently run on production data -> sanitize the dataset (e.g. remove PII).Finetuning has been more popular for structured output, sql generation (clear feedback loop / retries at run-time if the output does not work). More teams fine-tune on all the output that has passed this initial run-time gate for model distillation without further quality controls on the training dataset. They usually then run evals on a test dataset in order to verify whether the fine-tuned hits their quality bar.\n \nreply",
      "Congrats Marc! We've been using Langfuse for about 6-months for our LLMOps tooling. While its SDKs are limited to python and typescript, their openapi specification is pretty easy to implement in any language.The team behind it is amazing, and their product being OSS is one of the reasons we chose it. But it just keeps getting better.We're incidentally only using part of the product because we've implemented most of these new features, prompt caching, execution etc in our app. But with the API you can decide what parts are core to your business logic and outsource the parts you don't want to deal with to Langfuse.I appreciate that its not an opionated product.\n \nreply",
      "Thanks for the feedback.Being unopinionated and API-first has been a core design decision. We want to build the building blocks that everyone needs while acknowledging that most Langfuse users are very sophisticated teams that have a clear idea of what they want to achieve. Over time we will build more abstractions for common workflows to make it easier to get started but new features will always start API-first.More on this here: https://langfuse.com/why\n \nreply",
      "Been using Langfuse OSS for almost 15 months from the start. By far the best solution. No dark patterns found in other projects such as Portkey.\n \nreply",
      "All core features are fully open-source and identical to those in Langfuse Cloud, with no limitations on capabilities or scalability (e.g. all v3 infrastructure changes).We also offer some optional commercial add-on features that can help iterate faster or support very large teams using Langfuse. However, these features are entirely optional and we do our best to be transparent about this across our docs.\n \nreply",
      "A happy Langfuse customer here!We've been building an agent platform and some of our customers wanted someway to exfil OTEL traces to their own setup. Initially we tried building our own but then realised Languse does exactly what we needed doing. So we offered it as a first class integration, (and started using it internally).Great product, and hope you guys continue to improve it!\n \nreply",
      "Thanks! Really enjoyed working with you maintainers of other projects to help them offer more native LLM observability and evaluation to their users/communities. There is a lot that goes into making the observability/eval part scalable/useful and requirements change on a weekly basis with new advancements. Same applies to other projects and it makes a lot of sense to integrate.Overview of community integrations: https://langfuse.com/docs/integrations/overviewPackages that depend on Langfuse: https://langfuse.com/faq/all/packages-depending-on-langfuse\n \nreply",
      "Looks cool! I\u2019d love to see a simple embedding/sharing tool for an LLM playground to share with the non-tech team so they can try it. Is that something Langfuse could do?Also, some typos you want to review on the site: https://triplechecker.com/s/655511/langfuse.com\n \nreply",
      "Been using it. Happy customer. It gave me sanity into otherwise very complex LLM infrastructure. We spend 60k+ every month on LLM calls, so having the backbone to debug when things go haywire has helped a lot.\n \nreply"
    ],
    "link": "https://github.com/langfuse/langfuse",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83e\udea2 Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets. Integrates with LlamaIndex, Langchain, OpenAI SDK, LiteLLM, and more. \ud83c\udf4aYC W23 \n      Managed deployment by the Langfuse team, generous free-tier (hobby plan), no credit card required.\u00bb Langfuse Cloud\u2192 Learn more about deploying locallyLangfuse is simple to self-host and keep updated. It currently requires only a single docker container and a postgres database.\n\u2192 Self Hosting InstructionsTemplated deployments: Railway, GCP, AWS, Azure, Kubernetes and othersYou need a Langfuse public and secret key to get started. Sign up here and find them in your project settings.Note: We recommend using our fully async, typed SDKs that allow you to instrument any LLM application with any underlying model. They are available in Python "
  },
  {
    "title": "Dline: A tool that presents important data in the form of a calendar in terminal (github.com/jazz-it)",
    "points": 12,
    "submitter": "thunderbong",
    "submit_time": "2024-12-14T10:06:57 1734170817",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42415953",
    "comments": [
      "Sweet mercy it's all shell scripts. What an impressive nightmare.\n \nreply",
      "Why?\n \nreply",
      "The UI lookr great, but I have the same question. What is the workflow / use case for this?\n \nreply",
      "when your life is confined to SSH\n \nreply"
    ],
    "link": "https://github.com/jazz-it/dline",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A tool that presents important data in the form of a calendar directly within your terminal.\n       dLine is a versatile command-line tool that presents important data in the form of a calendar directly within your terminal. It monitors critical dates, simplifies event addition via APIs, and calculates timespans for various event types.Designed for developers, dLine streamlines event management and schedule navigation without requiring you to leave the terminal.It's the default View and is named for its automated processes that operate in the background, independent of user input.Static View:\nWhen you run dline -m yyyy/mm, it enters Static View mode. Unlike the more dynamic counterpart, Static View remains stationary, making it ideal for users who simply require a monthly calendar. In this mode, the calendar displays events for the "
  },
  {
    "title": "Show HN: I built an open-source data pipeline tool in Go (github.com/bruin-data)",
    "points": 121,
    "submitter": "karakanb",
    "submit_time": "2024-12-17T16:40:31 1734453631",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=42442812",
    "comments": [
      "Hi Burak, thanks for posting! We're looking for a tool in this space and i'll take a look.Does Bruin support specifying and visualizing DAGs? I didn't see that in the documentation via a quick look, but I thought to ask because you may use different terminology that can be a substitute.\n \nreply",
      "Interesting, I've been looking for a system / tool that acknowledges that a dbt transformation pipeline tends to be joined-at-the-hip with the data ingestion mode....As I read through the documentation, Do you have a mode in ingstr that lets you specify the maximum lateness of a file? (For late-arriving rows or files or backfills) I didn't see it in my brief read through.https://bruin-data.github.io/bruin/assets/ingestr.htmlReminds me a bit of Benthos / Bento / RedPanda Connect (in a good way)Interested to kick the tires on this (compared to, say, Python dlt)\n \nreply",
      "great point about the transformation pipeline, that's a very strong part of our motivation: it's never \"just transformation\", \"just ingestion\" or \"just python\", the value lies in being able to mix and match technologies.as per the lateness: ingestr itself does the fetching itself, which means the moment you run it it will ingest the data right away, which means there's no latency there. in terms of loading files from S3 as an example, you can already define your own blob pattern, which would allow you to ingest only certain files that fit into your lateness criteria, would this fit?in addition, we will implement the concept of a \"sensor\", which will allow you to wait until a certain condition is met, e.g. a table/file exists, or a certain query returns true, and continue the pipeline from there, which could also help your usecase.feel free to join our slack community, happy to dig deeper into this and see what we can implement there.\n \nreply",
      "Burak - one wish I've had recently is for a \"py data ecosystem compiler\", specifically one which allows me to express structures and transformations in dbt and Ibis, but not rely on Python at runtime. [Go|Rust]+[DuckDB|chDB|DataFusion] for the runtime. Bruin seems very close to the mark! Following.\n \nreply",
      "hey, thanks for the shoutout!I love the idea, effectively allowing going towards a direction where the right platform for the right job is used, and it is very much in line with where we are taking things towards. Another interesting project in that spirit is sqlframe: https://github.com/eakmanrq/sqlframe\n \nreply",
      "Congrats Burak, I can tell a lot of work has gone into this. If I may recommend, a comparison of this project with similar other/state-of-the-art projects would be really good to have in your documentation set for others to understand how your approach differs from them.\n \nreply",
      "It\u2019s pretty remarkable what Bruin brings together into a single tool / workflow.If you\u2019re doing data analytics in Python it\u2019s well worth a look.\n \nreply",
      "thanks a lot for the kind words, James!\n \nreply",
      "Why there is not MySQL integration? Will you plan to add it? MySQL is very popular.\n \nreply",
      "Congrats on the launch!  Since this is Go have you considered using CUE or looked at their flow package?  Curious how you see it relating or helping with data pipelines.\n \nreply"
    ],
    "link": "https://github.com/bruin-data/bruin",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Build data pipelines with SQL and Python, ingest data from different sources, add quality checks, and build end-to-end flows.\n      \n\nBruin is a data pipeline tool that brings together data ingestion, data transformation with SQL & Python, and data quality into a single framework. It works with all the major data platforms and runs on your local machine, an EC2 instance, or GitHub Actions.Bruin is packed with features:Please see the installation instructions here.Join our Slack community here.Take a look at our quickstart guide here.\n        Build data pipelines with SQL and Python, ingest data from different sources, add quality checks, and build end-to-end flows.\n      "
  },
  {
    "title": "Ad: An Adaptable Text Editor (github.com/sminez)",
    "points": 3,
    "submitter": "xelxebar",
    "submit_time": "2024-12-18T00:37:06 1734482226",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/sminez/ad",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        an adaptable text editor\n        ad (pronounced A.D.) is an attempt at combining a modal editing interface of likes of vi\nand kakoune with the approach to extensibility of Plan9's Acme. Inside of ad text is\nsomething you can execute as well as edit.It is primarily intended as playground for experimenting with implementing various text editor\nfeatures and currently is not at all optimised or feature complete enough for use as your main\ntext editor.That said, if this sounds like something you might find interesting then please to take a\nlook and see what you think! For now there isn't a whole lot of user facing documentation so\nyou will need to read through the source code to learn about what is and is not implemented.ad is stable enough and feature complete enough that you can try it out and see what you\nthink. That said, there is cu"
  },
  {
    "title": "A quick look at OS/2's builtin virtualization (uninformativ.de)",
    "points": 84,
    "submitter": "zdw",
    "submit_time": "2024-12-14T05:06:19 1734152779",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42414817",
    "comments": [
      "A neat thing in Warp (I don't know if it was also pre-Warp) was that when it booted if it didn't have an OS/2 driver for the hard disk it would create a v86 task that would take over the state of the BIOS and it would then use BIOS INT 13h calls to access the disk.That meant you could install and use it on a PC with a disk controller that OS/2 did not recognize out of the box as long as that controller provided BIOS INT 13h support.\n \nreply",
      "> Windows 3 also uses virtualization for its DOS boxes, but this is \"internal\" to Windows. OS/2, on the other hand, exposes this entire functionality to the user.What does this mean? It looks wrong. Of course Windows exposes virtualization to users, otherwise they would not be able to run anything on DOS boxes. That's the entire point, and that's why virtualization is used. Because the difference between a \"DOS program\" and \"real mode operating system\" is, due to how such a thin layer DOS is, practically zero. So each DOS box is a full VM emulating everything from VGA to floppy, because your average DOS program is very likely going to access them directly.The same test program happily runs in a Win95 DOS box.. or even a Windows 10 one. This is not a special OS/2 feature, it's a requirement for running a DOS box.\n \nreply",
      "In OS/2, you can run any version of DOS, or even multiple different versions at the same time, and I think possibly any real-mode OS that doesn't do anything too crazy with the hardware.In Windows, you are limited to the version of DOS that Windows is running on. Windows does not expose the ability to run any other version of DOS or other OS; nor does Windows API expose any of its virtualization functionality that would be useful in doing so.\n \nreply",
      "And so you can on any other DOS box, including Windows ones. That is, again, a necessary requirement of a DOS box: you have to emulate a full (real mode) PC. Every DOS box is its separate VM, so it couldn't care less if you run different versions of DOS on different instances. For example, you can run FreeDOS, and even real mode Windows 3 itself on a 9x DOS box. You can do int13h disk access from a DOS box and completely wreck your disks. This is _required_ by any minimally effective DOS box, otherwise FDISK wouldn't work!\nKeyboard, mouse, even sound have to be emulated as if they're were real devices, too. Otherwise, your fancy \"DOS\" game (that happens to call practically no DOS interrupts) would not work .As I was saying, there's practically no difference between a DOS program and a real mode operating system. How would the VM manager notice you weren't running (MS)DOS, much less care?> Windows does not expose the ability to run any other version of DOS or other OS; nor does Windows API expose any of its virtualization functionality that would be useful in doing so.You really do not need _any_ functionality to boot another OS from DOS. It's one int 19h away -- or copy the bootloader in memory and jump to it. It's a shorter program than the vga.com program used in this article.In fact, the moment you run the author's vga.com on a DOS box, even from command.com, you are effectively no longer running DOS: you have already bootstrapped your own non-DOS operating system on a Windows DOS box.If you want to be nitpicky, it's likely your \"non-DOS\" OS has to keep certain DOS structures in the usual places, specially if you want to use e.g. host filesystem level accesses (not full disk), but this will most definitely also be the case for a OS/2 DOS box.\n \nreply",
      "As some added context, that is probably[1] true for any Windows version that uses v86 (which implies at least a 386 and enhanced mode windows), not so much for any earlier, non-enhanced Windows, or any Windows running on anything less than a 386.In those, a DOS box is relatively far from a \"separate VM\".But the same would apply to OS/2.[1] I say \"probably\" because I haven't verified the limitations that Window may apply on its v86 tasks. It's at least possible that there's some tight integration between the DOS version that Windows is \"running on\" (which remained a thing for any non-NT-based Windows, including 95,98,me) and the \"DOS inside the DOS box\". Which, yes, would limit what software you can run, but then so does for example the need of protected mode DOS software to use DPMI/VCPI to be able to run in a DOS box, already. Some games just would not run in DOS boxes, that's why you could still boot \"DOS mode\" in Win95 and later. It's also possible that there is tight integration between Windows and the DOS box in other ways that also adds limitations.\n \nreply",
      "OS/2 was pretty boss. I could fuzz test multiple DOS apps while running two Windows 3.1 sessions that communicated over a null modem cable.\n \nreply",
      "Os/2 Warp had support for windows 3.x virtualization, so little surpise for me. Also IBM developed virtualizaion tenchnology (like LPAR) long time ago: https://en.wikipedia.org/wiki/Logical_partition\n \nreply",
      "Yes, one of its marketing highlights were \"a single Windows app won't crash the whole OS\" as that was before Windows 95 came out. IIRC, some Windows apps even ran faster under OS/2.\n \nreply",
      "If IBM had given OS/2 to their mainframe division to develop (and hired someone to design a better GUI, with much better icons - these things matter), I think it could have been a hit. I was using hypervisor stuff on VM/CMS in the early 1980s and it worked flawlessly (fun to run a vm inside a vm at the time). Of course, you need the hardware to support it, and IBM were too slow on using the latest Intel chips, and should probably have developed their own.\n \nreply",
      "VM/CMS wasn't known for its great GUI though. So, the reason OS/2 GUI looked bad might actually be because mainframe guys were too involved with its design. OS/2 had few remarkable VM/CMS characteristics that I could remember, including intricate, hierarchical error codes prefixing every error message like \"HPL1001A: File not found\", and favoring upper-case on file names and configuration files.Not to mention that OS/2 came with XEDIT and REXX which were cornerstones in VM/CMS.\n \nreply"
    ],
    "link": "https://www.uninformativ.de/blog/postings/2024-12-13/0/POSTING-en.html",
    "first_paragraph": "blog \u00b7 git \u00b7 desktop \u00b7 images \u00b7 contact2024-12-13A while ago, someone on the fediverse mentioned \"OS/2's virtualization\nfeatures\" to me. I don't remember who it was, sorry. I had the chance to\ntake a look at this today.For maximum dramatic effect, I'm going to use the oldest version of OS/2\nthat I own, which is OS/2 2.1 from 1993:There is this feature called \"DOS from drive A:\":You can insert a bootable DOS floppy and then run that DOS in a new\nwindow.Since this is called \"DOS from drive A:\", surely this is something\nDOS-specific, right? Maybe only supports MS-DOS or even only PC DOS?Far from it, apparently.Let's write a little DOS program first:I used NASM on Linux to create a .COM file:Running this in DOSBox on Linux looks like this:So it draws something like\nthe XOR texture\nin VGA mode 13.Now, this program is actually not \"a DOS program\". It runs in real-mode\nand only uses BIOS functions, specifically\nINT 10 to change the\nvideo mode and then it just assumes that the VGA memory is av"
  },
  {
    "title": "CRDTs and Collaborative Playground (cerbos.dev)",
    "points": 37,
    "submitter": "emreb",
    "submit_time": "2024-12-17T20:16:38 1734466598",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.cerbos.dev/blog/crdts-and-collaborative-playground",
    "first_paragraph": "At Cerbos, we specialize in simplifying complex authorization logic to empower developers with the tools to implement secure, scalable, and maintainable access control systems. Our mission is to streamline the development of robust access policies, making it easier for teams to define who can do what in their applications.One of the tools we offer is a collaborative IDE and testing environment we nicknamed the \"Playground\" (because access control should be a joy, not a chore). The Playground is a fully integrated collaborative IDE with built-in testing that provides feedback in real-time, and easily integrates into your GitOps workflow! We're very proud of it, but rather than spending too much time bragging, I'm going to deep-dive into a very particular word from the spiel before: \"collaborative\".We saw real value in building the environment with collaboration in mind\u2014both for efficiency in authoring policies and also as a tool for sharing knowledge or educating others (pair-programmin"
  },
  {
    "title": "Network protocols for anyone who knows a programming language (2017) (destroyallsoftware.com)",
    "points": 49,
    "submitter": "jmstfv",
    "submit_time": "2024-12-16T20:01:21 1734379281",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.destroyallsoftware.com/compendium/network-protocols?share_key=97d3ba4c24d21147",
    "first_paragraph": "The network stack does several seemingly-impossible things.\nIt does reliable transmission over our unreliable networks, usually without any detectable hiccups.\nIt adapts smoothly to network congestion.\nIt provides addressing to billions of active nodes.\nIt routes packets around damaged network infrastructure, reassembling them in the correct order on the other side even if they arrived out of order.\nIt accommodates esoteric analog hardware needs, like balancing the charge on the two ends of an Ethernet cable.\nThis all works so well that users never hear of it, and even most programmers don't know how it works.In the old days of analog telephones, making a phone call meant a continuous electrical connection from your phone to your friend's.\nIt was as if a wire were run directly from you to them.\nThere was no such wire, of course \u2013 the connection was made through complex switching systems \u2013 but it was electrically equivalent to a single wire.There are too many Internet nodes for it to wo"
  },
  {
    "title": "Show HN: Atlas of Water Science via generative AI (webapp.csiro.au)",
    "points": 5,
    "submitter": "benl_c",
    "submit_time": "2024-12-16T23:13:14 1734390794",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42436556",
    "comments": [
      "Nice looking site!Has the code been open-sourced - how could I recreate this visualation for other keywords?\n \nreply",
      "The backend is still a mess of code, so no. It's not too hard to do though. The prompt I used extract location is\"The text provided are enviornmental science papers. They often (but not always) will include references to locations where this science is relevant, for example a study might be of soil around a small town, in this case the town would be the relevant location, extract all locations that are relevant or the subject of the science done, do not extract any locations that are related to the location of or institutions, organisations, or laboratories. So for example exclude the location of government departments and CSIRO laboratories. If there are no relevant locations, please return an empty array. Each location should be extracted in a form suitable for calling the Nominatim geocode API in Python via geopy. Also, extract out a short context string that describes the context in which this location is referenced. Please provide the output in JSON format.\"Then I passed it through both Nominatum and Google Geocoder. Google worked better.One thing that didn't work great in the prompt above was excluding the location of places where the authors worked. They sometimes got included anyway.\n \nreply",
      "> One thing that didn't work great in the prompt above was excluding the location of places where the authors worked. They sometimes got included anyway.Have you tried adding the institutions as an explicit property in the JSON response and just ignoring the second list?I\u2019ve had much better luck with having LLMs explicitly choose a different label when working with similar types of entities than asking the LLM to exclude them via prompting. This way you can also spot ambiguity if the LLM add a location to both arrays.\n \nreply",
      "I have not done that but I like that strategy not just for this use case but as a general idea for replacing exclusion with finer grained categorisation. One thing I did do is use a regex to preprocess the papers to remove bibliographies which were a really big source of noise. In titles of referenced papers there would often be a mention of location that was not directly relevant to the paper itself.The Atlas is also trying to answer the question \"Can we build inaccurate and incomplete systems with LLMs that are still useful?\".\n \nreply"
    ],
    "link": "https://wateratlas.webapp.csiro.au/",
    "first_paragraph": "Welcome to the Atlas of Open Water Security Science. This map visualizes open access papers by CSIRO water security staff since 2010.This is an initial 3 month trial version. Locations and context are extracted from papers using AI and may contain inaccuracies or biases. Use with caution.This interactive map visualizes the geographical distribution of open access water science extracted from publications by CSIRO's Water Security Program since 2010. This is an initial 3 month trial version.\n       Use the slider to explore how the research has evolved, with publications appearing in blue with a white highlight as they are published. \n       Toggle the heatmap to see areas of concentrated research activity.Click on any publication to see its details, including authors and links to the full text. Locations and context are extracted from publications using generative AI. The context describes how the location is relevant to the science in the publication.To learn more about how we are inn"
  },
  {
    "title": "How I used linear algebra to build an interactive diagramming editor (medium.com/ivan.ishubin)",
    "points": 220,
    "submitter": "binshu",
    "submit_time": "2024-12-17T06:10:26 1734415826",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=42438767",
    "comments": [
      "Transformation matrices were popularized by Adobe PostScript in the 1980s. SVG heavily borrows from PostScript imaging model. See links below for PostScript's use of 2D matrices:https://personal.math.ubc.ca/~cass/graphics/text/old.pdf/las...https://scientificgems.wordpress.com/2014/11/28/mathematics-...\n \nreply",
      "Popularised by Adobe?Don\u2019t you just learn transformation matrices in algebra?\n \nreply",
      "You learn matrix multiplication in algebra, not its application to do affine transforms in 2D graphics.\n \nreply",
      "I started learning rotations, translations, scaling, shears using matrices in high school.Affine transforms are apparently attributed to Mobius and Gauss. That\u2019s like the 1700s.What is vector based 2D graphics if not a direct application of geometry? Were we not using well known maths results when 2D graphics was first implemented on a computer?\n \nreply",
      "Cool, hadn't heard of Schemio before!  https://schem.io/Very slick look and feel :DAnd it doesn't boast about it, but it's open source https://github.com/ishubin/schemio\n \nreply",
      "Thanks! Schemio is open-sourced with the exception of the backend part of https://schem.io. But the frontend code is completely open and you can even host your own server. Although in that case it would simply use a file system as a storage, so no database and no user management.\n \nreply",
      "Is it possible to use programmatically? Basically I've been wanting to create an HDL diagram (for FPGA development) from source code to visualise the block interactions. It would be great to have a bit of interaction with the blocks that are created. No other tool I've seen can really do what's wanted.\n \nreply",
      "Do you mean diagrams as code? something like PlantUML https://pdf.plantuml.net/1.2020.22/PlantUML_Language_Referen... ?If that's what you mean, then no. I do have plans to work on this in the future, but I am not sure when I'll get the time for that.Or do you mean just generating a diagram and posting it to Schemio programatically? This is possible, but it's not documented.All diagrams are stored in JSON by the way and the structure is quite straightforward, so it shouldn't be too difficult to generate it yourself\n \nreply",
      "Do you mean that there are two servers:1. a basic open source one you can self-host,2. and another closed-source one with accounts and other features that schem.io uses?And (I'm just thinking out loud, and don't want to encourage any development as I am not a real user) is there a server-less embeddable version that perhaps just saves/loads locally with a javascript API for use in other apps?\n \nreply",
      "Yes, but there is more than that.\nActually there are 6 types of deployments of Schemio1. Self-hosted, there is even a docker container available (https://hub.docker.com/r/binshu/schemio/tags). It does not have authorization and user-management, stores all diagrams on a file system. But it allows you to run server in write and read-only mode2. https://schem.io - a service for collaborative editing and sharing of diagrams. This is obviously a closed-source for now and it uses the open-source frontend of Schemio3. Schemio as a js library. Although I am not really releasing it to npm, just hadn't the time to work this out. But there is an option to build a js lib that lets you use Schemio as a Vue component. That's actually how I made it work on https://schem.io4. https://schemio.app - Google Drive based frontend. All your diagrams are stored on Google Drive. Obviously you cannot share your diagrams, as they are only available to you. This is completely open-sourced and you can even build it yourself with npm5. Static deployment. If you use option 1, you can export all of your diagrams into a static deployment and even host it on Github pages.6. Standalone player of Schemio that lets you embed a single diagram on your website\n \nreply"
    ],
    "link": "https://medium.com/@ivan.ishubin/how-i-used-linear-algebra-to-build-an-interactive-diagramming-editor-and-why-matrix-math-is-d5bd552f2e8d",
    "first_paragraph": ""
  },
  {
    "title": "Crunch \u2013 a Scheme compiler with a minimal runtime (more-magic.net)",
    "points": 167,
    "submitter": "sjamaan",
    "submit_time": "2024-12-17T12:18:05 1734437885",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=42440767",
    "comments": [
      "For Common Lispers such as myself, who are vaguely aware of developments in the Scheme space: the most important difference between CRUNCH and Chicken appears to be that, while both compile down to C/object code, CRUNCH is additionally targeting a statically-typed subset of Scheme.Opinion: this is great. The aversion of Lispers to static types is historical rather than intrinsic and reflects the relative difference in expressiveness between program semantics and type semantics (and runtime vs tooling) for much of computing. Now that types and tools are advancing, static Lisps are feasible, and I love that.\n \nreply",
      "I don't believe it's not intrinsic. A lot of the reason why Lispers may be averse to static types is because of the perceived inflexibility it can induce into the system. Lisp programmers don't want to be told what to do, especially by the compiler. Some CLs like SBCL have allowed some form of inference through the standard type declarations in the language. This leads me to believe that the 'right thing' in the case of Lisp is a combination of dynamicity and some stronger typing features that can be applied during the optimization stage. The dynamic nature and ease of use of Lisp relative to its performance is one of its greatest assets: it would be nearsighted to try and sacrifice that--a good Lisp programmer can optimize the important parts of his programs such that they're comparable to or even outperform their equivalents in other more ``high-performance'' languages. With that being said, these developments might bring us closer to a ``sufficiently smart compiler'' that could make that latter stage mostly unnecessary.\n \nreply",
      "I want static types in a higher level assembly language for systems programming. That's because I want to work with machine-level representations, in which there are no spare bits for indicating type at run-time (moreover, using such a language, we can design a type system with such bits, in any way we please).I don't want static types in a high level language.It's just counterproductive.We only have to look at numbers to feel how it sucks. If we divide two integers in Common Lisp, if the division is exact, the object that comes out is an integer. Otherwise we get a ratio object.  Or if we take a square root of a real, we get a complex number if the input is negative, otherwise real.This cannot be modeled effectively in a static system. You can use a sum type, but that's just a greenspunned ad hoc dynamic type.\n \nreply",
      "I don't think it makes sense to conflate Lispers to Schemers. I've programmed in both languages but have a stronger affinity for Scheme partially because semantically it is less flexible and more \"staticy\" than Lisp. Philosophically, the languages tend to attract different personalities (to the extent that the highly fragmentary Scheme world can be characterized).\n \nreply",
      "> Now that types and tools are advancing, static Lisps are feasible, and I love that.Haven't that been feasible for a pretty long time already? Judging by how well-received (or not) they've been, it seems there isn't much demand for it. Things like clojure.spec and alike (compile-time + run-time typing) seems much more popular, but isn't static.\n \nreply",
      "There isn\u2019t much demand for Lisps in general.\n \nreply",
      "I think given the sheer amount of them that is demonstrably false\n \nreply",
      "Many have been created, but how many have significant usage?\n \nreply",
      "People make a lot as their side projects through the easy parsing, what software is being made with them? (besides the usual hacker news backend response)\n \nreply",
      "What are the main differences between OcamML and a statically typed Lisp?\n \nreply"
    ],
    "link": "https://www.more-magic.net/posts/crunch.html",
    "first_paragraph": "Hi, I'm Peter Bex, a Scheme and free software enthusiast from the Netherlands.  See my user page on the CHICKEN wiki or my git server for some of my projects.NOTE: This is another guest post by Felix Winkelmann, the founder and one of the current maintainers of CHICKEN Scheme.Hi! This post is about a new project of mine, called \"CRUNCH\", a compiler for a statically typed subset of  the programming language Scheme, specifically, the R7RS (small) standard.The compiler runs on top of the CHICKEN Scheme system and produces portable C99 that can then be compiled and executed on any platform that has a decent C compiler.So, why another Scheme implementation, considering that there already exists such a large number of interpreters and compilers for this language? What motivated me was the emergence of the PreScheme restoration project, a modernisation of \"PreScheme\", a statically typed compiler for Scheme that is used in the Scheme48 implementation. The original PreScheme was embedded into S"
  },
  {
    "title": "SeleniumBase: Python APIs for web automation and bypassing bot-detection (github.com/seleniumbase)",
    "points": 69,
    "submitter": "seleniumbase",
    "submit_time": "2024-12-16T17:34:05 1734370445",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42433199",
    "comments": [
      "I've been working with scrapers quite a lot. I started with python requests, then to scrapy, then selenium, then selenium via undetected_chromedriver, and once that started being detected during a chrome update about a year ago, I've switched over to seleniumbase. It got by undetected, but to get it working with pre-downloaded drivers, I had to look into the code. I have never, and I mean never, in all my python years, seen such a horrible mess of code. We are talking 1000lines long methods, with 20-30 different flags and branches Just horrible. I have since switched to Playwright, which seems to be also undetected, and offers a much saner interface.\n \nreply",
      "SeleniumBase modifies the webdriver so that it doesn't get detected when used alongside the CDP stealth mode and methods. It'll download chromedriver for you. Not sure what you mean by the multiple branches, as there's just the primary one. What 1000-line methods are you referring to? By \"flags\", do you mean the different command-line options available? As for Playwright, they aren't undetected: See https://github.com/microsoft/playwright/issues/23884#issueco... - \"Playwright is an end-to-end testing framework, where we expect you test on your own environments. Bypassing any form of bot protection is not something we can act on. Thanks for your understanding.\" On the contrary, SeleniumBase is OK with bypassing bot detection: https://github.com/seleniumbase/SeleniumBase/blob/master/exa...\n \nreply",
      "Not the commenter, but \u201cmultiple branches\u201d in this context is referring to if/else statements in the code, not source-control branches.  Similarly, \u201cflags\u201d is referring to function arguments like a boolean \u201cis_original.\u201d  More generally, they are just saying that the code has long, complicated, bug-prone functions.That said, I just spent a few minutes browsing the SeleniumBase repro, and honestly it didn\u2019t seem that unusual to me.  Would be interested in seeing a specific example of what the commenter had in mind.\n \nreply",
      "Not sure if you have explored rolling captcha solving services into your code. Its easy as fuck and you can do it in a few lines of code. Check out DeathByCaptcha or AntiCaptcha. It's like $2.99 per 1,000 successfully solved captchas.I guess my point is, you dont have to be undetected nor write 1000 lines of code to scrape or do whatever you are needing to do always. Saved me a ton of headaches and time when captchas are involved.\n \nreply",
      "SeleniumBase is free, open-source, can bypass CAPTCHAs with a few lines of code, and it works from the free tier of GitHub Actions.\n \nreply",
      "It cant bypass all captchas and thats what im talking about.\n \nreply",
      "According to live demos seen in https://www.youtube.com/watch?v=Mr90iQmNsKM, it'll bypass Cloudflare, Akamai, Shape Security, DataDome, Incapsula, Kasada, and PerimeterX.\n \nreply",
      "Okay, and? DeathByCaptcha can bypass all of those + all other captchas.Write a ton of code or just roll in a solving service API. Ez decision and save a ton of time + get to scraping faster.\n \nreply",
      "With SeleniumBase, you can bypass CAPTCHAs with one line of code:\n`sb.uc_gui_click_captcha()`\n \nreply",
      "It's like you're not even reading what he wrote.\n \nreply"
    ],
    "link": "https://github.com/seleniumbase/SeleniumBase",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Python APIs for web automation, testing, and bypassing bot-detection.\n      All-in-one Browser Automation Framework:Web Crawling / Testing / Scraping / Stealth    \n\ud83d\ude80 Start |\n\ud83c\udff0 Features |\n\ud83c\udf9b\ufe0f Options |\n\ud83d\udcda Examples |\n\ud83c\udf20 Scripts |\n\ud83d\udcf1 Mobile\n\n\ud83d\udcd8 APIs |\n \ud83d\udd20 Formats |\n\ud83d\udd34 Recorder |\n\ud83d\udcca Dashboard |\n\ud83d\uddfe Locales |\n\ud83d\udcbb Farm\n\n\ud83c\udf96\ufe0f GUI |\n\ud83d\udcf0 TestPage |\n\ud83d\udc64 UC Mode |\n\ud83d\udc19 CDP Mode |\n\ud83d\udcf6 Charts |\n\ud83c\udf10 Grid\n\n\ud83d\udc41\ufe0f How |\n\ud83d\ude9d Migrate |\n\ud83d\uddc2\ufe0f CasePlans |\n\u267b\ufe0f Template |\n\ud83e\uddec Hybrid |\n\ud83d\ude8e Tours\n\n\ud83e\udd16 CI/CD |\n\ud83d\udd79\ufe0f JSMgr |\n\ud83c\udf0f Translator |\n\ud83c\udf9e\ufe0f Presenter |\n\ud83d\udec2 Dialog |\n\ud83d\uddbc\ufe0f Visual\n\nSeleniumBase is the professional toolkit for web automation activities. Built for testing websites, bypassing CAPTCHAs, enhancing productivity, completing tasks, and scaling your business.\ud83d\udcda Learn from over 200 examples in the SeleniumBase/examples/ folder.\ud83d\udc19 Note that UC Mode / CDP Mode (Stealth Mode) have their own ReadMe files.\u2139"
  },
  {
    "title": "A pilot crashed a full passenger jet into the bay, didn't lose his job (2021) (sfgate.com)",
    "points": 85,
    "submitter": "Stratoscope",
    "submit_time": "2024-12-17T18:40:00 1734460800",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=42443987",
    "comments": [
      "I once ran a stop sign, and nearly hit a car. They pulled up next to me, rolled down their window (I had stopped at my home) and were about to unleash who knows what kinds of profanities at me, and I just said \"That was totally my fault. I didn't see the stop sign. I'm sorry.\"They stopped dead in their tracks, shrugged and nodded, and left. Owning mistakes is an extremely powerful tool when used correctly.\n \nreply",
      "Also, aviation accident investigations aren't really about blame but about future prevention. Even if the outcome is pilot error, it's more about preventing how this error happened in the future than to punish the pilot. Because nobody (well.. almost nobody, think GermanWings) does this on purpose. Either training, information overload, disorientation etc. And also the cooperation of the pilots is paramount. That doesn't really work if they're getting themselves in trouble.Having said that I don't think a current NTSB investigation would take \"i f--ed up\" for an answer. They'd want to know why and how. But those were very different times.\n \nreply",
      "Also it's extremely rare to find no pilot error. The regulations broadly say \"pilot must get acquaintanced with all aspects regarding flight safety\" intentionally, so pilot could not say \"I didn't know\" -- must have known.\n \nreply",
      "True but these days it's very very hard to know everything actively. There's just so very much.It's understandable when a pilot forgets about that one obscure button that's only used in some edge case only happening on one in 100.000 flights.These days being a pilot is a lot like being a system engineer especially since the dedicated flight engineer position is gone. Yet also requiring the spatial awareness and manual skills of flying. I'm often surprised how well it still goes with the complexity of modern aircraft.\n \nreply",
      "But sometimes the pilot followed correct procedure, and the correct procedure was to blame. In those instances the procedure is changed.\n \nreply",
      "Yes or the correct procedure was not correctly written up in the flight manual, not trained on, too hard to find in a pinch etc. Or the situation was so complex it was hard to identify which procedure applied.\n \nreply",
      "I really wish this wasn't the shocking revelation it is, but holy fuck, a ton of people just refuse to do this.I've done it all my life, personal and professional. I will (not happily, but I will) explain how I fucked up, and why. But similar to your experience, this catches people completely off guard. They don't expect it and I know why, because in my interactions in turn with people who also, categorically, fucked up: they will NEVER admit it. Most people will die on the hill of not just owning a simple fucking mistake and it's so bonkers to witness. Like... it's fine. You're human. You made a human error. Just like... acknowledge it so we can get on with whatever?\n \nreply",
      "I can't think of many better ways to demonstrate to your colleagues and corporate overlords that you are worthy of their trust than to readily hold up your hands if you've screwed up.So long as you're not so incompetent that you're repeatedly doing stupid stuff or cynically causing issues so that you can make yourself look virtuous by owning up, of course.\n \nreply",
      "In corporate context, admitting exernally-facing liability too easily violates executives' fiduciary responsibility to shareholders. For incentives aligning, need to figure out how to unravel that beasty.\n \nreply",
      "On the contrary, I think it can be sold as a PR win: Think about how many companies torch customer goodwill by making a bad decision and then doubling and tripling down on it for months (before backpedaling and losing a ton of customers anyways).\n \nreply"
    ],
    "link": "https://www.sfgate.com/sfhistory/article/san-francisco-historic-plane-crash-asoh-defense-16319360.php",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Adventures in OCR (medusis.com)",
    "points": 61,
    "submitter": "bambax",
    "submit_time": "2024-12-17T17:00:54 1734454854",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=42443022",
    "comments": [
      "OCR to original structure is a really fun problem! I did something similar in an internship for newspapers pre-LLM Vision models, and it ended up being a bunch of interval problems re-aligning and formatting the extracted text. Found that Azure's OCR model was the most accurate by bounding box, which helped a lot.Funny how vision models would almost be able to one-shot it, modulo some hallucination issues. Some of the research back then ~2020 was starting to use vision models for layout generations.\n \nreply",
      "Author take one the LLM approach for first pass:> Trying to get LLMs with vision to properly identify zones also were found to be slow and unreliable, and the risk of hallucinated results is unacceptable, especially as a first step. Non-deterministic systems may be fine for creative projects, but not here. (Once we have a reliable reference we can then play with LLMs and if necessary, control the results by measuring the distance to the source.)He tried it for fixing footnotes and the result went \"classic LLM\":> It was a complete flop. Using OpenRouter, I tested over 200 models. More than 70% couldn't even count the footnotes right, but that wasn't the worst part.The \"best\" models just made stuff up to meet the requirements. They lied in three ways:Basic (stupid) lies: wrong counts but claiming they matched ('foonotes: 5, references: 3, match: true')\nBetter lies: claiming they placed references when they hadn't\nPremium lies: making up new text to attach footnotes to when they weren't sure where they went (against explicit instructions in the prompt never to do that)\n \nreply",
      "Oh wow! I've worked on turning PAIP (Paradigms of Artificial Intelligence Programming) from a book into a bunch of Markdown files, but that's \"only\" about a thousand pages long, compared to the roughly 27000 pages long of all those volumes. I have advice, possibly helpful, possibly not.Getting higher quality scans could save you some headaches. Check the Internet Archive. Or, get library copies, and the right camera setup.Scantailor might help; it lets you semi-automate a chunk of things, with interactive adjustments. I don't know how its deskewing would compare to ImageMagick. The signature marks might be filtered out here.I wrote out some of my process for handling scans here - https://github.com/norvig/paip-lisp/releases/tag/v1.2 . I maybe should blog about it.If you get to the point of collaborative proofreading, I highly recommend Semantic Linefeeds - each sentence gets its own line. https://rhodesmill.org/brandon/2012/one-sentence-per-line/ I got there by:* giving each paragraph its own line* then, linefeed at punctuation, maybe with quotation marks and parentheses? It's been a while\n \nreply",
      "You are right that the quality of the scans is paramount! Unfortunately I don't have access to the physical books and have to work with the scans as they are (they're not good). But I will look at Scantailor, it looks interesting.For now I reconstruct paragraphs in html but I could do markdown just as well (where paragraph breaks are marked by double line breaks, and single line breaks don't count).Collaborative proofreading would be cool but it would require some way of properly tracking who wrote what, and I'm not sure what to use or if I should build a simple system from scratch. Do you have recommendations?\n \nreply",
      "You could upload the books to the Internet Archive and let their OCR pipeline take a try.  It is (or at least was) written around Abbyy.  Results weren't great but they were a start.I wonder what eventually happened with Ocropus which was supposed to help with page segmentation.  I was a bit disappointed to see that this article used Google Vision as its OCR engine.  I was hoping for something self hosted.\n \nreply",
      "The book is being worked on here https://fr.wikisource.org/wiki/Livre:Saint-Simon_-_M%C3%A9mo... already (volume 1 of 20).  Not the same edition as what OP is working with, but it's a start.\n \nreply",
      "That edition (the Ch\u00e9ruel edition) is the first integral edition of the M\u00e9moires. It's been OCRed a long time ago and has been available in text form for 20+ years. But it has almost no footnotes.The edition I'm working on here, the \"Boislisle\", is completely different thanks of the richness and coverage of its footnotes (but the main text should be almost identical).\n \nreply",
      "If it's public domain, you can create a new record for it on Wikisource once you think it's ready for the human touch. This is the purpose of Wikisource though, taking the messy automated OCR, and allowing volunteers to correct/proofread/format everything.\n \nreply",
      "Well, in my experience Google Vision is far, far ahead of Tesseract.\n \nreply",
      "\"A very crude method would be to remove the last line every 16 pages but that would not be very robust if there were missing scans or inserts, etc. I prefer to check every last line of every page for the content of the signature mark, and measuring a Levenshtein distance to account for OCR errors.\"I'm curious: did you also check whether the signature mark was indeed found every 16 pages? Were there any scans missing?Great project btw!\n \nreply"
    ],
    "link": "https://blog.medusis.com/38_Adventures+in+OCR.html",
    "first_paragraph": ""
  }
]