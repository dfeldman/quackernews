[
  {
    "title": "ProofOfThought: LLM-based reasoning using Z3 theorem proving (github.com/debarghag)",
    "points": 188,
    "submitter": "barthelomew",
    "submit_time": "2025-10-04T18:34:23 1759602863",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=45475529",
    "comments": [
      "I had a surprising interaction with Gemini 2.5 Pro that this project reminds me of. I was asking the LLM for help using an online CAS system to solve a system of equations, and the CAS system wasn't working as I expected. After a couple back and forths with Gemini about the CAS system, Gemini just gave me the solution. I was surprised because it's the kind of thing I don't expect LLMs to be good at. It said it used Python's sympy symbolic computation package to arrive at the solution. So, yes, the marriage of fuzzy LLMs with more rigorous tools can have powerful effects.reply",
      "Just like humans... we are not so good at hard number crunching, but we can invent computers that are amazing at it. And with a lot of effort we can make a program that uses a whole lot of number crunching to be ok at predicting text but kind of bad at crunching hard numbers. And then that program can predict how to create and use programs which are good at number crunching.reply",
      "Maybe the number crunching program the text generation program creates will, with enough effort become good at generating text, an will in turn make another number crunching computer and then\u2026reply",
      "Watch the movie \u201cThe Thirteenth Floor\u201dreply",
      "I love this kind of thought. Thanks.reply",
      "Parent post is talking about symbolic manipulation, not rote number crunching, which is exactly what we're supposed to be good at and machines are supposed to be bad at.reply",
      "We do plenty of number crunching all the time, just not consciously.Like the inverse kinematics required for your arm and fingers to move.reply",
      "I\u2019d argue we aren\u2019t solving those inverse kinematics / kinetics via \u201cnumber crunching\u201d - but rather that our neuromuscular systems are analog. Which I don\u2019t usually call that \u201cnumber crunching\u201d in the sense current computers \u2026 compute.reply",
      "As a psychologist, I completely agree. It absolutely is NOT number crunching. Analog computation is primary and dominant in animals. It has to be, for so many reasons. I continue to be amazed at how much IT people do NOT grasp human and animal IT. And that, I would argue, is why so many IT folks keep talking about our supposedly approaching human intelligence in technology. If they really understood human intelligence the absurdity of that statement would keep them quiet. An elegant, artful puppet is still a puppet, and without the personal history context and consciousness we possess, not to mention a vast complex of analogue computation functionality we rely upon, that puppet will only ever be a clever number-cruncher. We are so much more.reply",
      "Neurons aren't crunching numbers for inverse kinematics.reply"
    ],
    "link": "https://github.com/DebarghaG/proofofthought",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \"Proof of thought: Neurosymbolic program synthesis allows robust and interpretable reasoning\" published Sys2Reasoning Workshop NeurIPS 2024\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.LLM-based reasoning using Z3 theorem proving.The system has two layers:Most users should use the high-level API.See examples/ directory for complete examples including Azure OpenAI support.\n        \"Proof of thought: Neurosymbolic program synthesis allows robust and interpretable reasoning\" published Sys2Reasoning Workshop NeurIPS 2024\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "A comparison of Ada and Rust, using solutions to the Advent of Code (github.com/johnperry-math)",
    "points": 198,
    "submitter": "andsoitis",
    "submit_time": "2025-10-04T15:10:49 1759590649",
    "num_comments": 128,
    "comments_url": "https://news.ycombinator.com/item?id=45473861",
    "comments": [
      "Ada has some really good ideas which its a shame never took off or got used outside of the safety critical community that mostly used it. The ability to make number types that were limited in their range is really useful for certain classes of bugs. Spark Ada was a relatively easy substandard to learn and apply to start to develop software that was SIL 4 compliant.I can't help but feel that we just went through a huge period of growth at all costs and now there is a desire to return, after 30-years of anything goes, to trying to make software that is safer again. Would be nice to start to build languages based on all the safety learnings over the decades to build some better languages, the good ideas keep getting lost in obscure languages and forgotten about.reply",
      "Nim was inspired by Ada & Modula, and has subranges [1]:  type\n    Age = range[0..200]\n\n  let ageWorks = 200.Age\n  let ageFails = 201.Age\n\nThen at compile time:  $ nim c main.nim\n  Error: 201 can't be converted to Age\n\n[1] https://nim-lang.org/docs/tut1.html#advanced-types-subrangesreply",
      "I know quite some people in the safety/aviation domain that kind of dislike the subranges, as it inserts run-time checks that are not easily traceable to source code, thus escaping the trifecta of requirements/tests/source-code (which all must be traceable/covered by each other).Weirdly, when going through the higher assurance levels in aviation, defensive programming becomes more costly, because it complicates the satisfaction of assurance objectives. SQLite (whiches test suite reaches MC/DC coverage which is the most rigorous coverage criterion asked in aviation) has a nice paragraph on the friction between MC/DC and defensive programming:https://www.sqlite.org/testing.html#tension_between_fuzz_tes...reply",
      "Ideally, a compiler can statically prove that values stay within the range; it's no different than proving that values of an enumeration type are valid. The only places where a check is needed are conversions from other types, which are explicit and traceable.reply",
      "If you have    let a: u8 is 0..100 = 1;\n    let b: u8 is 0..100 = 2;\n    let c = a + b;\n\nThe type of c could be u8 in 0..200. If you have holes in the middle, same applies. Which means that if you want to make c u8 between 0..100 you'd have to explicitly clamp/convert/request that, which would have to be a runtime check.reply",
      "In your example we have enough information to know that the addition is safe. In SPARK, if that were a function with a and b as arguments, for instance, and you don't know what's being passed in you make it a pre-condition. Then it moves the burden of proof to the caller to ensure that the call is safe.reply",
      "But obviously the result of a + b is [0..200], so an explicit cast, or an assertion, or a call to clamp() is needed if we want to put it back into a [0..100].Comptime constant expression evaluation, as in your example, may suffice for the compiler to be able to prove that the result lies in the bounds of the type.reply",
      "How does this work for dynamic casting? Say like if an age was submitted from a form?I assume it\u2019s a runtime error or does the compiler force you to handle this?reply",
      "If you're using SPARK, it'll catch at compile time if there's ever a possibility that it would fit within that condition. Otherwise it'll throw an exception (constraint_error) during runtime for you to catch.reply",
      "What happens when you add 200+1 in a situation where the compiler cannot statically prove that this is 201?reply"
    ],
    "link": "https://github.com/johnperry-math/AoC2023/blob/master/More_Detailed_Comparison.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Newton: physics simulation engine built upon NVIDIA Warp (github.com/newton-physics)",
    "points": 46,
    "submitter": "skilled",
    "submit_time": "2025-10-01T16:57:11 1759337831",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=45440071",
    "comments": [
      "Is this related to the Newton Dynamics physics engine? https://newtondynamics.com/reply",
      "Heh, that was my first thought too and it doesn't look like it's related.? The nvidia dudes could have done some minimal amount of googling to pick a name that causes less confusion.reply",
      "No> Newton extends and generalizes Warp's (deprecated) warp.sim module, and integrates MuJoCo Warp as its primary backend.It\u2019s MuJoco GPU Edition. Nothing new or improved.reply",
      "I think this is a step in the right direction, but I really dislike the Pythonification of everything. After using IsaacSim/IsaacLab for work, I'm convinced that Python is not the right tool for the job.Developers inevitably write slow, error filled code when dealing with Python and working with the type annotations can be a pain.Happy there's something to replace PhysX for robotics, and I do really like MuJoCo's API, but really wish we could get some good C/C++ APIs.Apart from the language, NVIDIA doesn't seem to be great when dealing with software. IsaacSim and IsaacLab have so many bugs, are incredibly slow, and hard to debug. We spend so many hours on my team findings bugs for IsaacSim, it's just a pain. On version 5.0 and still feels like beta software.Also IsaacSim's relience on USD to hold the scene structure and update prims makes it so hard to program for. USD isn't really performant when trying to generate a large amount of scenes. And the USD interface stops working completly when simulation starts on IsaacLab. I hope Newton goes a different route, and has less of a reliacne on USD. IMO USD should just be used as an interchange format, rather than how you actually represent the scene and properties internally. I much prefer that approach, which Unreal Engine seems to support.Lastly, my god the names in this field are terrible. USD (Googling becomes a pain sometimes), Newton (Already another engine), Warp (literally the name of the architecture and a way to write Python GPU kernels, wtf).reply",
      "Years ago there was PhysX... how does this compare?reply",
      "This will eventually replace PhysX, some of its developers are working on Newton Physics. Newton Physics has multiple solvers, including MuJoCo-Warp and is easier to customize and extend.reply"
    ],
    "link": "https://github.com/newton-physics/newton",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An open-source, GPU-accelerated physics simulation engine built upon NVIDIA Warp, specifically targeting roboticists and simulation researchers.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\nThis project is in active beta development. This means the API is unstable, features may be added or removed, and breaking changes are likely to occur frequently and without notice as the design is refined.Newton is a GPU-accelerated physics simulation engine built upon NVIDIA Warp, specifically targeting roboticists and simulation researchers.Newton extends and generalizes Warp's (deprecated) warp.sim module, and integrates\nMuJoCo Warp as its primary backend. Newton emphasizes GPU-based computation, OpenUSD support, differentiability, and user-defined extensibility"
  },
  {
    "title": "Blog Feeds (blogfeeds.net)",
    "points": 91,
    "submitter": "stevedsimkins",
    "submit_time": "2025-10-04T19:08:46 1759604926",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=45475808",
    "comments": [
      "> The idea is to create another page on your blog that has all the RSS feeds you're subscribed to. By keeping this public and always up to date, someone can visit your page, find someone new and follow them. Perhaps that person also has a feeds page, and the cycle continues until there is a natural and organic network of people all sharing with each other. So if you have a blog, consider making a feeds page and sharing it! If your RSS reader supports OPML file exports and imports, perhaps you can share that file as well to make it easier to share your feeds.This is usually called a \"blogroll\", which has the advantage of being much less ambiguous/overloaded than \"feeds\".reply",
      "I had a very similar idea. I\u2019m glad someone implemented it.reply",
      "I thought about a similar problems because I always find really interesting blogs (mostly on HN) but I don't have a real place to store them, so they get lost when I close the tab. I can save them in the favorites but I'm not used to check favorites regularly.Feeds are a tangent solution because they give you only the new stuff. Feeds transform blogs into social media platforms where what matter is the new fresh content, ready to \"feed\" the algorithm. But blogs and personal sites are different. High quality content is usually written in a single article, maybe in the past, and it will not be shown on your feed.Actually I judge a blog on what's already written in there, so I want to read more articles but maybe just not right now. If I add the blog to my RSS reader I would only read future content.Another patch to this problem is Instapaper. I can save there the most interesting articles and read them later, but the entire-blog view is missing.I would like to have a way (platform) where I can save a blog and read all/some articles, with a standard formatting (custom blogs are nice but not always comfortable to read) and not having a default sorting for recent articles.reply",
      "I've tried a few solutions and have landed on just storing them in an unordered list in a markdown filereply",
      "I sometimes use reeder but its UI isn\u2019t quite right for me. But there\u2019a a fair amount of options out there.reply",
      "> If I add the blog to my RSS reader I would only read future content.Why? All the old articles are there as well.reply",
      "Instapaper and Feedly work for me. Instapaper is the main thing and Feedly a thing I check occasionally for the blogs I love.reply",
      "i\u2019ve tried a paid Instapaper plan a few times but always end up leaving because their reader view very regularly misses entire sections of articlesreply",
      "I write on my blog, but I am not sure who I am writing for. Which is fine, because in the end I write for myself. Years ago you would get comments, posts would get linked (remember pingbacks?). Maybe as time progressed I started writing more niche things that reach nobody, or maybe that web started disintegrating. Hope it comes back, but I will not hold my breath. I will keep posting though.reply",
      "Some people have been following my blog for over 10 years. The only reason I know is because someone decided to email me on a random Tuesday. You'd be surprised what you find when you look through your logs.reply"
    ],
    "link": "https://blogfeeds.net",
    "first_paragraph": "Tired of social media?Keep doom scrolling through addicting feeds?Miss the days when the web was just about connecting with people and their thoughts or ideas?We believe there's an answer to that problem, and it's calledNo this isn't another platform.\n            You don't sign up here.\n          You just write what's on your mind, respond to an idea, post a recipe, or share a photo. It's blogs, but perhaps not in the way you would normally think of blogs.It just takes three things to participate:Starting a blog is actually a lot simpler than what you're probably thinking. This doesn't have to be some well polished highly viewed monetization machine, or even something professional or formal. It's just a simple website where you can casually talk about whatever you want to talk about! It can be long, short, a list of small things, or just a quote. It should be how you talk with other people in your own life, or how you communicate with the outside world. It should be you on a page. Here"
  },
  {
    "title": "XiangShan Vector Floating-Point Unit Design (xiangshan.cc)",
    "points": 25,
    "submitter": "camel-cdr",
    "submit_time": "2025-10-04T22:02:28 1759615348",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://docs.xiangshan.cc/projects/design/en/latest/backend/VFPU/",
    "first_paragraph": ""
  },
  {
    "title": "Space Mission Options for Reconnaissance and Mitigation of Asteroid 2024 YR4 (arxiv.org)",
    "points": 10,
    "submitter": "bookofjoe",
    "submit_time": "2025-10-04T23:42:55 1759621375",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arxiv.org/abs/2509.12351",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Matrix Core Programming on AMD GPUs (salykova.github.io)",
    "points": 29,
    "submitter": "skidrow",
    "submit_time": "2025-10-04T21:22:11 1759612931",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://salykova.github.io/matrix-cores-cdna",
    "first_paragraph": "\nSep 30, 2025\n      \u2022 Amanzhol Salykov, Andy Luo, Carlus Huang, Peng SunTL;DR In this blog post, we walk through how to use Matrix Cores in HIP kernels, with a focus on low-precision data types such as FP16, FP8, and FP4, as well as the new family of Matrix Core instructions with exponent block scaling introduced in the AMD CDNA\u21224 architecture. Through code examples and illustrations, we provide the necessary knowledge to start programming Matrix Cores, covering modern low-precision floating-point types, the Matrix Core compiler intrinsics, and the data layouts required by the Matrix Core instructions. The blog post is also available on ROCm Blogs.Matrix multiplication is an essential part of AI and HPC workloads. The AMD CDNA\u2122 architecture features special-purpose hardware, the Matrix Cores, to accelerate matrix fused-multiply-add (MFMA) operations defined as D:=A*B+C. Please note that MFMA instructions are often used to update a matrix in-place (=accumulation) so that D=C and C:=A*B+"
  },
  {
    "title": "Probiotics Finder (probioticfinder.org)",
    "points": 14,
    "submitter": "cubefox",
    "submit_time": "2025-10-04T23:34:13 1759620853",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.probioticfinder.org/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Run \u2013 a CLI universal code runner I built while learning Rust (github.com/esubaalew)",
    "points": 58,
    "submitter": "esubaalew",
    "submit_time": "2025-10-04T18:34:13 1759602853",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=45475528",
    "comments": [
      "If someone is interested in pursuing this approach further, there exist a polyglot task runner named 'just' [1].[1] https://github.com/casey/just?tab=readme-ov-file#shebang-rec...reply",
      "I am very intrested why you choose to write such a tool. i normaly have a hand full of shell scripts doing the work, but surly i have to know the used language befor i call the script. Can you explain the motivation?reply",
      "The idea is similar to IPython, which provides an interactive interface for programming languages. The motivation isn't about building a massive CLI tool\u2014it's about questioning why we need a separate REPL for each language when we could use a single command-line interface that lets us switch between languages on the fly.reply",
      "Isn't the whole point of a shebang line that scripts can identify for themselves what language/runner they want to be executed via?reply",
      "Yeah, this seems to me to be comparable to something like `/usr/bin/env` or even agnostic language package managers like asdf in terms of trying to provide an abstraction over having to manually define where to find the toolchain to use for a given script. There's a pretty well-established pattern at this point of alternate takes for common CLI tools being written in Rust that bring something interesting to the table at the cost of compatibility with the older existing tool, so even if this one might or might not pan out into being useful for enough people, I think it's totally reasonable to try to come up with a new way of doing things.It's also not incredibly uncommon for people to run scripts that they haven't written themselves (like via the almost universally reviled but still somewhat common `curl <...> | bash` installation pattern). It probably would be better if things didn't get installed like this, but if it's going to happen, it might be nice to have the scripts written in something less annoying than shell so that the authors could at least use the same language for the installation script that they do for writing the software itself.reply",
      "Yes, that's exactly the point. What I'm trying to do is:  \n1. Use Rust because it's fast.  \n2. Make REPLs universal, so we don't need separate REPLs for different languages.  \n3. And third\u2014though not a new idea\u2014is to create better abstractions, like allowing print statements without requiring a main function, and accessing variables without explicitly printing them.reply",
      "How much time are you saving for each invocation? My 10 year old laptop invokes /usr/bin/env in less time than an HTTPS handshake.reply",
      "> exposes a unified REPL experience with commands like :help, :lang, and :quit.Those sound similar to \"magic commands\" in IPython and Jupyter?There is not yet a \nJupyter-xeus Rust kernel which would make it really easy to support Rust in JupyterLite in WASM on an .edu Chromebook and in JupyterLab: https://news.ycombinator.com/item?id=43354177> jupyter_console is the IPython REPL for non-ipykernel jupyter kernels. [like evcxr]> This magic command logs IPython REPL input and output to a file:  %logstart -o example.log.py\n\nhttps://news.ycombinator.com/item?id=25923123 ,Here's how to support something  like _repr_html_() and IPython.display.display() with evcxr_jupyter: https://github.com/evcxr/evcxr/blob/main/evcxr_jupyter/READM...I'm not sure what the pros and cons of evcxr_repr, jupyter_console + evcxr_jupyter, and Run are?reply",
      "As a small note, Swift is a compiled language. It uses LLVM as a backend, same as Rust and Clang (C/C++/ObjC). It's currently listed under \"Web & typed scripting\".reply",
      "You're right\u2014and the same applies to Kotlin. Swift is more like Rust, C, and C++ in that it compiles directly to machine code. So yes, Swift is currently listed under the wrong category.As for Kotlin, it could reasonably be placed under either \"Web & scripting\" or \"Compiled,\" depending on how it's used. Since Kotlin can also compile to JavaScript, its classification depends on the context. If we're talking about Android development, then Kotlin is clearly a compiled systems language.To clarify: Swift is a compiled, statically typed systems language, much like Rust, C++, or Go. Its core toolchain (swiftc) compiles code into native binaries.reply"
    ],
    "link": "https://github.com/Esubaalew/run",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Universal multi-language runner and smart REPL written in Rust.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\nPolyglot command runner & smart REPL that lets you script, compile, and iterate in 25+ languages without touching another CLI.\n\n\n\n\n\n\nBuilt in Rust for developers who live in multiple runtimes. run gives you a consistent CLI, persistent REPLs, and batteries-included examples for your favorite languages.All release assets are published on the GitHub Releases page, including macOS builds for both Apple Silicon (arm64) and Intel (x86_64). Pick the method that fits your platform:Installs the run binary from the run-kit crate. Updating? Run cargo install run-kit --force.This formula is published as a standalone file on each release; it isn\u2019t part of the"
  },
  {
    "title": "How to inject knowledge efficiently? Knowledge infusion scaling law for LLMs (arxiv.org)",
    "points": 65,
    "submitter": "PaulHoule",
    "submit_time": "2025-10-04T17:18:07 1759598287",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=45474900",
    "comments": [
      "Interesting work, but I think the interpretation may be a bit overstated. The authors claim that injecting too much factual \"knowledge\" during pretraining causes models to collapse \u2014 performance drops below the baseline once knowledge frequency crosses a threshold.The problem is how they inject it. Their \u201cknowledge\u201d isn\u2019t natural language; it\u2019s templated Wikidata triples like \"X is the capital of Y.\" That\u2019s a super low-entropy, highly repetitive distribution. When you cram enough of that into a fixed token budget, you\u2019re not really teaching the model more facts \u2014 you\u2019re just destroying linguistic diversity and skewing the token statistics.In real pretraining or domain adaptation scenarios, \u201cknowledge\u201d tends to appear in richer, more varied contexts. The practical takeaway isn\u2019t \"don\u2019t add too much domain data,\" but rather \"don\u2019t overrepresent any single format or narrow syntactic pattern\" The issue seems more about representation homogeneity than about factual density itself.reply",
      "I'm sure there's other work, I came across this in the Physics of Language Model paper[1] on knowledge extraction.Essentially they found that by presenting the knowledge in a single, fixed way, the model is trained to reproduce that exact sequence of tokens, rather than \"internalizing\" the knowledge.By varying the sentences, the model instead manages to separate out the knowledge, so to speak. This in turn drastically improves how well they can extract that knowledge later.[1]: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5250633reply",
      "Doesn't this then support the claim that LLMs aren't building world models - where even linguistically simple factual statements should help expand and refine that model - and reenforce the idea that they are still just next token predictors?reply",
      "There's no inductive bias for a world model in multiheaded attention. LLMs are incentivized to learn the most straightforward interpretation/representation of the data you present.If the data you present is low entropy, it'll memorize. You need to make the task sufficiently complex so that memorisation stops being the easiest solution.reply",
      "My read is that token prediction requires a more general model to predict more varied tokens, which makes it something closer to a world model. After all, in principle, there's a point where the optimal \"token predictor\" really is backed by a world model. (Now is that model feasible to find? unclear!)reply",
      "I wish the authors calculated a plot of model size (number of params) vs number of triples it can hold before the memory collapse happens.It's hard to map the frequency of knowledge injection to a real world understanding of \"how much knowledge\" can a 4B param model hold?reply",
      "There is a study that gives a rule of thumb of ~2 bits per param for a model's memorization capacity: https://arxiv.org/abs/2404.05405reply",
      "Seems they have replicated Gardner's work, without mentioning it, \"Maximum Storage Capacity in Neural Networks\" (1987), which established that the storage capacity of a neural network is about 2N (2 bits per parameter)reply",
      "I had no idea about this. Thanks for sharingreply",
      "Elizabeth Gardner for those looking.reply"
    ],
    "link": "https://arxiv.org/abs/2509.19371",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Self-hosting email like it's 1984 (maxadamski.com)",
    "points": 173,
    "submitter": "xmx98",
    "submit_time": "2025-10-04T14:53:32 1759589612",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=45473730",
    "comments": [
      "(had to dug my comment from under a flagged parent)I self-hosted for well over 20 years, I did not throw the towel and I do not plan to. Self-hosting is a sign of pride. Neither my government nor my Prime Minister nor even my Ministry of Interior or Foreign Ministry can host their own email.Last time I checked, only State Security self-hosted.I was probably lucky, but I rarely had delivery problems. The last one was a couple years ago with Microsoft swallowing my emails and it was due to the combination of a fairly old exim and a TLS certificate verification quirk at *.protection.outlook.com. I found a fix in the form of a configuration option somewhere on SO.In all fairness, there is very little maintenance involved, and whenever I have to do maintenance work, I take the opportunity to learn something new. Like this year, I decided to finally replace my aging Debian jessie setup by Arch Linux, and I rewrote all cron jobs as systemd timers.I must admit that when I send a really important email, I check the mail server log if it went off without errors, but this does not bother me as checking logs manually once in a while is a good thing anyway.Lastly, a piece of advice: treat self-hosting like a hobby and learn to enjoy it.Oh and the very last thing: the person who designed Exim configuration for Debian deserves a special place in hell for all the hours wasted. If you set up Exim on Debian, just figure out how to use the upstream exim config and adapt it to your needs.reply",
      "My first email usage was at University, pre-WWW. After that I briefly used some ISP email service, but that was on a time of very limited storage and POP only accounts, so I started hosting my own email even before having an always-on internet connection, using a relay and dynamic DNS to receive email when online. Now a days, I use a small VPS to route and receive email, but final destination and storage is on my home server. Over the years, I had, like others here, to ask Outlook and other providers to unblock my IP or domain, but it has been rare.I really don\u2019t want to live in a world where only two or three companies run email for the entire world, and this is my little act of resistance.reply",
      "outlook.com keeps sending me dmarc reports with failed dkim... while every single other provider gives pass to all domains. at this point I don't even care anymore.why Microsoft is so crappy?reply",
      "They want you to use outlook.reply",
      ">  I decided to finally replace my aging Debian jessie setup by Arch Linux, and I rewrote all cron jobs as systemd timers.Man, I wish I had 1% of the motivation I had 20 years ago to do something like this, before all the full time job, wife and child.reply",
      "Stuff to keep you busy is always there, you can control what you spend the rest of the time on.reply",
      "> treat self-hosting like a hobby and learn to enjoy it.This is why I have stepped away from a lot of my self hosting.  I have turned my attention/time elsewhere.  Apparently though the time/money balance is shifting a bit again, so it may be worth it to go back.My biggest hesitance to self hosting email specifically is dealing with spam.  What does that look like these days and do you have any pointers to share?reply",
      "I use a combination of DNSBL and SpamAssassin. Nowadays Rspamd is supposed to be better than SpamAssassin, but SpamAssassin has served me well enough so far, and I haven't gotten around to trying out Rspamd. When a spam email gets past SpamAssassin, I copy it to a special folder, which gets processed by a cron job to train SpamAssassin on it (sa-learn).Overall the mail server is very low maintenance. I had to add SPF and DMARC a couple years ago (DKIM isn't necessary) and integrate TLS with letsencrypt (just a few lines in a config file), and sometimes a Debian upgrade requires reviewing the configuration (several years apart as well). There's really not that much to do.reply",
      "rspamd is my go to solution.  Out of the box you get a lot of protection.  I use Exim as my MTA but I suggest you use Postfix if you are starting from scratch, only because you will find a lot more write ups on it.The biggest issue is getting an IP address which is not in the banned lists.  IP reputation is key along with SPF and do not send spam!In the UK a \"business\" static IP address is sometimes/usually/probably/might be OK.  If you are unfortunate then it is already in the lists and you can check that out at point of sign up.You might look into IPv6 too.  I managed to do the Hurricane Electric IPv6 email thing on my home connection for a laugh.  That was a few years ago.  It seems I need to do something more to get to Guru status.reply",
      "I\u2019m not sure that there is any pre made product for this, but I\u2019ve been playing around with LLMs to identify spam, or just generally sorting emails for you. And even the self hosted models seem to be pretty good at classifying emails even without external information like spam blacklists or IP reputation.reply"
    ],
    "link": "https://maxadamski.com/blog/2025/10/email.html",
    "first_paragraph": "\nSelf-hosting an email server is useful for automating tasks like mailing lists, newsletters, or email verification APIs.\n\nThe elephant in the room is real-world deliverability. With self-hosting you risk not receiving mail or someone missing your mail. I accept this for my personal projects, but you may not. Keep this in mind.\n\nFor me the selling point of self-hosting is that it\u2019s practically free. If you\u2019re already self-hosting a website, installing some extra packages on your server and just a bit of your time is all that\u2019s required. Mail takes very little storage and the software is light, so you\u2019re unlikely to significantly change energy consumption or disk usage.\n\nFor the longest time, I perceived self-hosting email as too difficult, but after doing it for one of my projects, I can say it\u2019s not much harder or more time-consuming than configuring some email SaaS.\n\nI changed my goals a bit to make the setup easier though. Self-hosting a multi-user webmail looks heavy and is more in"
  },
  {
    "title": "Clavier: An FPGA-based mechanical keyboard with USB hub and comms interfaces (github.com/lsartory)",
    "points": 60,
    "submitter": "zdw",
    "submit_time": "2025-10-01T17:05:38 1759338338",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=45440180",
    "comments": [
      "As somebody who regularly tinkers, debugs, and programs microcontrollers at my desk. I just realized how handy having UART/SPI/I2C headers right there would be. Obviously I already have them like right there but to have them right there there would be great.reply",
      "After a few dumb accidents involving header pins, I've come to the conclusion that exposed male header pins on my desk are a hazard.reply",
      "How about the risk of frying the MCU?reply",
      "Is the benefit of the FPGA here that you can program the whole stack? Like a kind of super-charged QMK based board?reply",
      "Because you can? It looks like a great project for getting started with nontrivial FPGA design.Programming-wise I'd say full FPGA is less useful than QMK. Doing a direct 1:1 mapping from key inputs to USB HID report isn't too bad to do in an FPGA, but dynamic behavior like macros, layers, leader keys, mod tap, auto shift, and so on are significantly easier to implement in a regular programming language. If you want flexibility you're basically forced to have your FPGA run a soft core, so at that point why not go for a regular MCU?In theory you could make an argument for lower latency, but that doesn't really apply when you're limited by USB 2's 1000Hz polling rate while some off-the-shelf MCU-based keyboards use USB 3 for 8000Hz polling.reply",
      "Well the project description seems to hint at to their motivation:> 1000 Hz polling rate> No multiplexing, no ghosting> FPGA-based, VHDL only, no ALUIt looks like a pure HW 'described' keyboard with no running software meaning it is fully parallel (plus some serialization when reaching the USB device/interface).So arguably on top of true parallelism the only ceiling for the latency of the whole thing will be the clock period configured in the design and the physics and electrical behaviour of the switches themselves + circuitry.Probably someone who enjoys working close to hardware and wants to optimize performance.reply",
      "The FPGA is a Lattice LFE5U-25F, about $20https://www.digikey.com/en/products/detail/lattice-semicondu...reply",
      "Or about $5 on LCSC.reply",
      "I'm curious as to why it doesn't have USB 3.0 ports. Do they take too much power? Too much space?reply",
      "USB 3 is significantly more complicated to implement, and the hub chips are quite a bit more expensive. Hardware-wise it would've become by far the hardest part of this board.USB 2, on the other hand, is fairly trivial. You almost have to try to get it wrong - especially when you are not concerned about certification.reply"
    ],
    "link": "https://github.com/lsartory/Clavier",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An FPGA-based mechanical keyboard with an integrated USB hub and communication interfaces\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Clavier (French for \u2018keyboard\u2019) is an FPGA-based mechanical keyboard with an integrated USB hub, and numerous communication interfaces (JTAG, SPI, I\u00b2C, UART).It's the coffee key.\nUse it to lock your computer and go have a break.It can also be long-pressed for 5 seconds to reset the FPGA.The PCB has 4 layers and requires no unusual capabilities to produce.\nIt is however not easy to assemble by hand mostly due to 0402 passives and the FPGA in BGA packaging.A PDF version of the schematics is available here, for convenience: PCB/doc/clavier.pdf.An OpenSCAD version of the housing was created first and is fine for 3D printing.\nT"
  },
  {
    "title": "Borehole Oscillators (gregegan.net)",
    "points": 9,
    "submitter": "sohkamyung",
    "submit_time": "2025-10-04T23:02:32 1759618952",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.gregegan.net/SCIENCE/Borehole/Borehole.html",
    "first_paragraph": "There is a simple thought experiment in Newtonian gravity:  drill a thin radial borehole all\nthe way through a solid ball of uniform density, and drop a test particle into the hole,\nstarting from rest at the very top.  What happens?The result is that the particle (blue, in the image on the left) falls all the way\nthrough the borehole, comes to a halt at the opposite end, then falls back,\nundergoing \nsimple harmonic motion (the same kind of motion as an idealised\nversion of a weight bouncing on the end of a spring) with exactly the same period as another\ntest particle (red) orbiting the ball in a circular orbit that grazes the surface.On this page, we will start by proving that result, but then we will also look\nat radial motion in the vacuum around the ball in Newtonian gravity, and examine how\nthese systems work in General Relativity \u2014 featuring the famous Schwarzschild\nsolution, but starring its much less famous cousin, the second Schwarzschild\nsolution!A solid ball of radius r and u"
  },
  {
    "title": "Mathematical Models/Algorithms for Optimization of Lego Construction Problems [pdf] (dtu.dk)",
    "points": 6,
    "submitter": "felineflock",
    "submit_time": "2025-10-01T15:16:44 1759331804",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://backend.orbit.dtu.dk/ws/portalfiles/portal/236623063/PhD_Thesis_Torkil_Kollsker.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Earth was born dry until a cosmic collision made it a blue planet (sciencedaily.com)",
    "points": 200,
    "submitter": "amichail",
    "submit_time": "2025-09-30T16:54:43 1759251283",
    "num_comments": 179,
    "comments_url": "https://news.ycombinator.com/item?id=45427972",
    "comments": [
      "This could mean in the Drake equation ne -number of planets capable of life- is very small.  A planet has to be hit with a comet big enough to deliver a large amount of water but not so big or fast to destroy it.  And be in the Goldilocks zone of the star.  Also the mass of the planet would play a part - gravity of more massive ones would be more likely to capture a comet.  But again, too massive and I could see that hampering life.reply",
      "The Drake Equation is filled with assumptions, like life must appear on a planet in the Goldilocks zone of a star. The whole equation has only one datapoint to extrapolate from. Tweak the equation's parameters and it will predict universes that only have one civilization per galaxy or worse! We have no way of knowing what those parameters are because we haven't seen other examples.A major reason we are interested in Europa is because it might have underground oceans. Hypothetically, through tidal forces with Jupiter, the moon's core is hot enough to create oceans under the ice crust. Combined with hydrothermal vents you have the possibility for deep sea life similar to our own deep oceans. The Drake Equation does not predict this possibility.reply",
      "The Goldilocks zone doesn't enter the Drake equation at all.As a reminder, this is the equation: https://en.wikipedia.org/wiki/Drake_equation#EquationIt makes very few assumptions.reply",
      "The equation itself makes no assumptions. But anyone trying to calculate something with it must.The last five factors in the equation will be filled in by assumptions based entirely on one data point, life on Earth. From your link:  ne = the average number of planets that can potentially support life per star that has planets.\n  fl = the fraction of planets that could support life that actually develop life at some point.\n  fi = the fraction of planets with life that go on to develop intelligent life (civilizations).\n  fc = the fraction of civilizations that develop a technology that releases detectable signs of their existence into space.\n  L = the length of time for which such civilizations release detectable signals into space.\n\nCan you define any one of those without assumptions, in a scientifically proven way?reply",
      "One approach is to give each variable a probability distribution. The greater our uncertainty about possible values, the wider the bell curve.Drexler and colleagues did that, and found \"a substantial probability that we are alone in our galaxy, and perhaps even in our observable universe (53%\u201399.6% and 39%\u201385% respectively). \u2019Where are they?\u2019 \u2014 probably extremely far away, and quite possibly beyond the cosmological horizon and forever unreachable.\"https://arxiv.org/abs/1806.02404reply",
      "A probability distribution describes how likely different outcomes are.\nIt requires multiple observations or an assumed model that can represent variability.",
      "It actually adds excessive structure.The underlying model is just:N*fHow many planets are there, and what proportion of them have detectable life?The f does not have to be structured as fl->fi->fc, although we can see why you'd assume that kind of structure. It's simple to calculate the PI(series) when the model is just a funnel. Like the Million Dollar Money Drop gameshow.But you could imagine a more complex model of probabilities that branches and merges. There could be events on the bayesian tree that amplify downstream events. For instance, suppose there is some pathway that if reached will leave certain minerals that future civilizations could use. This has happened already on earth at least once: lignin bearing plants could not be easily digested for a long time, and that led to coal formation during the carboniferous period.You could imagine many such potential trees, but we only have one iteration.reply",
      "It does assume that life must be associatable with a planet. It's a plausible assumption, but you could also hypothetically have life develop on a star itself or its remnants, comets, clouds of interstellar gas. Maybe even something more exotic than that (dark matter? some weird correlated statistical properties of the quantum foam?)reply",
      "About forty years ago I read a terrific book about life forms that live on a star. Maybe Starquake was it called? Did to the abundance of energy on the surface of a star, they live their lives a million times faster than humans. Thus for both them and the humans who discover them, communication is difficult. I think the humans push these life forms to develop civilization, which from the human's perspective had them go from primitive animals into sophisticated beings of technology past their own in something like a day.reply",
      "That's \"Dragon's Egg\" by Robert L. Forward, a classic Sci-fi story:https://annas-archive.org/md5/4c381ac344506d10037fc8e7747098...The cheela lived on the surface of a neutron star, and they lived faster because the nuclear physics that powered their metabolism are far faster than the chemical and mechanical physics that power our own.reply"
    ],
    "link": "https://www.sciencedaily.com/releases/2025/09/250928095654.htm",
    "first_paragraph": "After the formation of the Solar System, it took a maximum of three million years for the chemical composition of the Earth's precursor to be completed. This is shown by a new study by the Institute of Geological Sciences at the University of Bern. At this time, however, there were hardly any elements necessary for life such as water or carbon compounds on the young planet. Only a later planetary collision probably brought water to Earth, paving the way for life.Earth is so far the only known planet on which life exists -- with liquid water and a stable atmosphere. However, the conditions were not conducive to life when it formed. The gas-dust cloud from which all the planets in the Solar System formed was rich in volatile elements essential for life, such as hydrogen, carbon and sulphur. However, in the inner Solar System -- the part closest to the Sun, where the four rocky planets Mercury, Venus, Earth and Mars and the asteroid belt are located today -- these volatile elements could "
  },
  {
    "title": "Microsoft 365 Copilot is a commercial failure (perspectives.plus)",
    "points": 23,
    "submitter": "jukkan",
    "submit_time": "2025-10-04T19:39:00 1759606740",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=45476045",
    "comments": [
      "I still think there's a potential niche for 365 Copilot in its boringness.At work (not a tech company), there's an ongoing, slow, 365 rollout. The people who participate in the rollout are not technical in any way, but they all love it because they're not regular ChatGPT/Claude users, either. In a way, the restricted feature-set of Copilot compared to ChatGPT helps them, they're overwhelmed enough by Copilot. \nIT loves 365 because it's so risk-averse. No big jumps, no surprises, clearly defined data and risk policies.I think if they drill down into the boring, slow, predictable, they will capture the market of risk-averse non-tech companies, not people.I've tried building agents using 365 for our internal documents and they're OK for basic stuff (what's in what document where - max 20 documents only!!), but langchain/RAG/whatever are a million times more powerful.reply",
      "We use it in finance for the reasons above. Microsoft actually just added GPT 5 to Copilot so it\u2019s much better than it used to be. I\u2019ve used it to help write scripts in VBA and it\u2019s really good for my use cases. Before GPT 5 it was worse than useless.reply",
      "Boring doesn\u2019t bring in the billions and billions in stock thoughreply",
      "Oh that's true. If AI is a bubble, and if it implodes, then MS might be the only AI place left standing if it can get its product into all of the non-tech companies in the world.reply",
      "0% chance.  The MIT 95% study showed that the tools are good, integration and process is the problem.  There's a ton of work for people that can come into a company and set up a bespoke AI control plane/orchestration, the tooling needs to evolve a little bit so this can be a sane, repeatable business though.reply",
      "Unsurprising. I tried it probably a year ago. I asked it what meetings were in my calendar for the day and it couldn\u2019t even tell me that. To add insult to injury, they wanted an annual commitment with up front payment at the time.reply",
      "Many other recent Microsoft products are below average. I'm thinking Teams, Outlook, Windows 11. Azure and Office are better.I guess they spend their money on sales and licensing and not on developing good products now?reply",
      "well also it's all tied together. no shuffling contracts for slack, email, etc.reply",
      "8 million active users after almost 2 years from making the $30pupm license available. Less than 2% of Microsoft 365 paying customers choosing to pay extra for Copilot. It's not difficult to see why Microsoft themselves have stopped reporting on AI revenue, as well as not disclosing any official numbers on M365 Copilot sales. Luckily, a source leaked these figures for Ed Zitron to report in his newsletter.reply",
      "Part of the reason is Microsoft's borgy/corpo-confusing service levels.I have a paid 365 account and couldn't determine from logging in or account info screens if I was on paid or just the freemium version with my 365 planIn testing out what I did have access to with Copilot, it was incredibly bad compared to ChatGPT or Claude, so I decided not to pay for Copilot whenever I see an ad for it.reply"
    ],
    "link": "https://www.perspectives.plus/p/microsoft-365-copilot-commercial-failure",
    "first_paragraph": ""
  },
  {
    "title": "OpenAI's hunger for computing power has Sam Altman dashing around the globe (wsj.com)",
    "points": 45,
    "submitter": "doener",
    "submit_time": "2025-10-04T22:14:29 1759616069",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=45477192",
    "comments": [
      "https://archive.md/OnsLK",
      "Too big to fail is the goal. If the world is powered by openai but it aint making a profit in 2028 they can just put their \"were a utility like water\" facemask on and get bailed out.reply",
      "At least in the USA, I think if consumers realized their power bills going up every year are tied to these new data centers, there would be more opposition to data centers going up politically.\nhttps://apnews.com/article/electricity-prices-data-centers-a...\nI don't know if the electricity markets work differently in other countries.reply",
      "Taxpayers subsidize data centers in many other ways. These are prestige projects for politicians, so they often get long-term tax breaks and other preferential treatment.I think it's part vanity, part a misunderstanding about the economic benefits of a datacenter (which are nearly nil, as they employ very few people and produce nothing for the local market), and part just a desire to score brownie points with wealthy corporations, which might mean donations, campaign support, or other perks for the politician who makes it happen.reply",
      "That\u2019s a fun trope but it\u2019s a terrible outcome for shareholders.reply",
      "Which means it will be made into a terrible outcome for everyone.reply",
      "shareholders like a business that can never fail...reply",
      "Good.reply",
      "What is their angle with this?Surely SamA doesn\u2019t actually think that they\u2019ll more than 20x their compute in a few years? I\u2019m sure the researchers there would love to do more research, with more compute, faster, but 20+x growth is not a practical expectation.Is the goal here to create a mad rush to build data centers, which should decrease their costs with more supply? Do they just want governments to step in and to help somehow? Is it part of marketing/hype? Is this trying to project confidence to investors on future revenue expectations?reply",
      "Surely SamA doesn\u2019t actually think that they\u2019ll more than 20x their compute in a few years?If their goal is to train say, a 100T model on the whole youtube dataset they will need 20000x more compute. And that would be my goal if I were him.reply"
    ],
    "link": "https://www.wsj.com/tech/ai/openai-sam-altman-asia-middle-east-7b660809",
    "first_paragraph": ""
  },
  {
    "title": "Unchecked and Unaccountable: How DOGE Jeopardizes Americans' Data (senate.gov)",
    "points": 19,
    "submitter": "defrost",
    "submit_time": "2025-10-04T23:30:16 1759620616",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.hsgac.senate.gov/media/dems/peters-report-finds-that-doge-continues-to-operate-unchecked-likely-violating-federal-privacy-and-security-laws-and-putting-the-safety-of-americans-personal-information-in-danger/",
    "first_paragraph": "WASHINGTON, D.C. \u2013\u00a0U.S. Senator Gary Peters (D-MI), Ranking Member of the Homeland Security and Governmental Affairs Committee, released a report revealing that the Trump Administration\u2019s Department of Government Efficiency (DOGE) is operating outside federal law, with unchecked access to Americans\u2019 personal data. Staff investigations and whistleblower accounts show how DOGE personnel at the Social Security Administration (SSA), the General Services Administration (GSA), and the Office of Personnel Management (OPM) are working without any accountability to agency leadership, Congressional oversight, or the public.\u00a0Peters\u2019 report includes multiple whistleblower disclosures that DOGE staff have copied Americans\u2019 sensitive Social Security and employment data into a cloud database without any verified security controls, likely a serious violation of cybersecurity and privacy laws that puts the information at risk of being stolen by cybercriminals. One individual\u2014previously fired from a pri"
  },
  {
    "title": "Paged Out Issue #7 [pdf] (pagedout.institute)",
    "points": 227,
    "submitter": "todsacerdoti",
    "submit_time": "2025-10-04T10:38:06 1759574286",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=45472319",
    "comments": [
      "Reminds me of PoC||GTFO.Loads of fun in this and in that. And does indeed make me sometimes question if I know anything about programming (in a good way:)reply",
      "This was a joy to read on a lovely Saturday morning. The Sound hacking  one was incredibly interesting. I\u2019d love to hear the waveform! Also, note to self, don\u2019t use shit chinese cameras\u2026reply",
      "Page 55 is particularly brilliant, where the author roots a camera just by playing a carefully crafted sound at it.Reminds me of when we used to load programs off of audio cassette tapes back in the day. Also it, somewhat obliquely, reminds me of BLIT by David Langford.reply",
      "My first computer was a Tandy CoCo TRS-80 with an audio cassette tape. Just yesterday I was using AI to formulate a plan to create graphics for a BASIC program.I don\u2019t know if I\u2019ll build something, because there might not be much point, but I sure have a lot of nostalgia for these old systems.reply",
      "Page 58*reply",
      "This is brilliant idea, well executed, and god darn it's using some pretty art. It's a shame reading it from a pdf though, and the print on demand options are quite pricey. I'd gladly subscribe to get this kind of thing in the mail though.reply",
      "> shame reading it from a pdf though,What makes it such a shame? It's full color, properly formatted, and nothing is missing. Looks beautiful on my color e-ink device.reply",
      "Mailed printed subscriptions for a decent price are somewhere on our TODO list. First we want to make it available for free on more events (like conferences, demoparties, etc).reply",
      "You can subscribe https://groups.google.com/forum/#!forum/pagedout-notificatio... (link from the bottom of the page https://pagedout.institute/)reply",
      "I think gp meant a physical/print copy in the snail mailreply"
    ],
    "link": "https://pagedout.institute/download/PagedOut_007.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Thunderscan: A clever device transforms a printer into a scanner (2004) (folklore.org)",
    "points": 135,
    "submitter": "dtgriscom",
    "submit_time": "2025-10-04T12:16:37 1759580197",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=45472765",
    "comments": [
      "I stumbled across the article about the ThunderScan in about 2012 when looking for info about ImageWriter II upgrades, and have been slightly obsessed ever since. It's such a brilliant idea - a higher resolution scanner, that was far lower in cost than its competitors, achieved by reusing the paper transport that most customers already had.I'm lucky enough to own two working ThunderScans now (and one third one that I needed the software driver from). They work exactly as advertised, and it's a joy to see them zip across the page, digitising line by line.The software by Hertzfeld is another joy to use. The scrolling, which Hertzfeld calls \"inertial scrolling\" in that article, is now familiar to us all who have used touchscreen devices. It's funny to think that the feature that wowed so many at the 2007 iPhone launch actually existed all the way back in 1984, designed by one of the key creators of the Macintosh.I wish there were more creative hacks like this - I just know that if a company tried to do something similar today, the printer manufacturer would instantly roll out an update to break this functionality.reply",
      "I wonder why the system didn't caught on and why it's not used today by manufacturers of multi-functional printers. Seems like a huge opportunity to use the existing paper handling mechanism - with an autofeeder, a feature most flatbeds lack! - and get a  more compact device.The entire device consists of a single, cheap CMOS image sensor, a lens focused at a fixed distance and a RGB led. Everything else, stitching the resulting scanbands, correcting for mechanical and optical distortions, etc. is all in software. The native optical resolution you could expect from, say, a 1080x720 px sensor would be something like 2400 DPI.The only downside i can think is that you can't scan IDs, passports etc. and the location near the inkjet head tends to get dirty.reply",
      "Canon tried with some Bubblejet printers, like BJC4300. It needed three passes per line (R,G,B) slow and lower quality.I think also it was expensive, since I wanted to get it, but failed to find it.OTOH, a 10 year old HP multifunction can scan things at 600DPI in acceptable quality and detail, in a very reasonable amount of time.If you want to go compact, but fast, there's Kodak Alaris' \"i\" series scanners which can scan both sides at the same time. Scan time is ~4 seconds per double sided A5 page at 600DPI, and less than a second for ~200 DPI.That thing zips, but is not cheap.reply",
      "You can get cheap, compact scanners that just feed the paper through instead of laying it on a flat pane of glass. Almost the same thing except not multifunctional and with a page width sensor instead of one that would scan back and forth.reply",
      "100,000 units sold, software royalty of $7.50 a unit -- I make that a little over $2M in today's money. Not bad for what seems to have been about two months work.reply",
      "When I first saw the $7.50 royalty, I was thinking he\u2019d make a decent payday as long as they sell 10K-20K of the things. Very surprised they sold 100K seems like a lot for the mid-80s for a relatively niche Mac accessory.reply",
      "Everyone with a Mac had an ImageWriter\n printer; the scanner attachment was, by far, the cheapest way to add scanning capability. Many people bought them to add the capability, not because they needed them already.A little later, the LaserWriter printer became the first generally affordable laser printer. But it was affordable only if you were rich or had a business case for it. The sub-thousand dollar laser printer took quite a few more years.reply",
      "That really is the dream, isn\u2019t it. To find work that is interesting, impactful, that you are uniquely qualified to do, and to be compensated handsomely for it.It was probably easier to come by in 1987. Nowadays if you have a unique idea in computing, there\u2019s 40 years\u2019 worth of computing professionals around to step in and take the job.reply",
      "IIRC, one of the 8-bit Atari magazines had an article describing a similar setup back in the mid/later 80s.  Basically, put a photoresistor in a shroud (I used the cap from a Bic pen and some electrical tape), attach it to the dot matrix print head and wire it to the Atari joystick port's analog/paddle input.  Place a bright light over the printer.  Then the software told the printer to move the print head back and forth while it read the port value.  The image quality was terrible but it was a fun project.reply",
      "Neat! I remember this thing from when I was a kid. We didn't have an Imagewriter printer so it wasn't an option for me. Having a scanner back in those days would have been amazing.There is a nice reverse engineering of the Thunderscan here: https://beefchicken.com/retro/thunderscan/reply"
    ],
    "link": "https://www.folklore.org/Thunderscan.html",
    "first_paragraph": "The first project that I worked on for Apple after starting in August 1979 was writing low level software for the Silentype printer (see What Hath Woz Wrought), a cute, inexpensive thermal printer for the Apple II, that was based on technology licensed from a local company named Trendcom.  In typical Apple fashion, we improved on Trendcom's design by replacing their relatively expensive controller board with a much simpler one that relied on the microprocessor in the Apple II to do most of the dirty work."
  }
]