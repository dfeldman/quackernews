[
  {
    "title": "You might not need WebSockets (hntrl.io)",
    "points": 73,
    "submitter": "hntrl",
    "submit_time": "2025-04-11T22:27:16 1744410436",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=43659370",
    "comments": [
      ">> If it wasn\u2019t, we couldn\u2019t stream video without loading the entire file firstI don't believe this is correct. To my knowledge, video stream requests chunks by range and is largely client controlled. It isn't a single, long lived http connection.\n \nreply",
      "I believe that's standard for Netflix, etc, but is it also true for plain webms and mp4s in a <video> tags? I thought those were downloaded in one request but had enough metadata at the beginning to allow playback to start before the file is completely downloaded.\n \nreply",
      "Yes it is true.Browsers talking to static web servers use HTTP byte ranges requests to get chunks of videos and can use the same mechanism to seek to any point in the file.Streaming that way is fast and simple. No fancy technology required.For MP4 to work that we you need to render it as fragmented MP4.\n \nreply",
      "Seconded, ive done a userland 'content-range' implementation myself. of course there were a few ffmpeg specific parameters the mp4 needed to work right still\n \nreply",
      "The long answer is \"it depends on how you do it\" unsurprisingly video and voice/audio are probably the most different ways that you can \"choose\" to do distribution\n \nreply",
      "Correct\n \nreply",
      "It's a minor point in the article, but sending a RequestID to the server so that you get request/response cycles isn't weird nor beyond the pale.It's pretty much always worth it to have an API like `send(message).then(res => ...)` in a serious app.But I agree. The upgrade request is confusing, and it's annoying how your websocket server is this embedded thing running inside your http server that never integrates cleanly.Like instead of just reusing your middleware that reads headers['authorization'] from the websocket request, you access this weird `connectionParams` object that you pretend are request headers, heh.But the idiosyncrasies aren't that big of a deal (ok, I've just gotten used to them). And the websocket browser API is nicer to work with than, say, EventSource.\n \nreply",
      "It's a good well worn tactic. You list in very high detail every single step of any process you don't like. It makes that process seem overly complex, then you can present your alternative and it sounds way simpler.For example, making a sandwich: You have to retrieve exactly two slices of bread after finding the loaf in the fridge.  Apply butter uniformly after finding the appropriate knife, be sure to apply about a 2.1mm level of coating.  After all of that you will still need to ensure you've calibrated the toaster!\"\n \nreply",
      "On the other hand, we're doing the worse tactic of getting held up on the first tiny subheader instead of focusing on the rest of a decent article.Also, their alternative is just a library. It's not like they're selling a SaaS, so we shouldn't be mean spirited.\n \nreply",
      "Pretty much. In this case, WebSockets is simpler to implement than HTTP2; it's closer to raw TCP, you just send and receive raw packets... It's objectively simpler, more efficient and more flexible.It's a tough sell to convince me that a protocol which was designed primarily for resource transfer via a strict, stateless request-response mode of interaction, with server push tacked on top as an afterthought is simpler than something which was built from the ground up to be bidirectional.\n \nreply"
    ],
    "link": "https://hntrl.io/posts/you-dont-need-websockets/",
    "first_paragraph": ""
  },
  {
    "title": "A 32-bit processor made with an atomically thin semiconductor (arstechnica.com)",
    "points": 142,
    "submitter": "PaulHoule",
    "submit_time": "2025-04-08T13:08:49 1744117729",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=43621378",
    "comments": [
      "I suspected that this was the case when they mentioned adding \"one bit at a time\" -- the CPU design that they implemented is Olof Kindgren's SERV [0], a tiny bit-serial risc-v CPU/soc (award-winning, of course).From [1]:> Olof Kindgren> 5th April 2025 at 10:59 am> It\u2019s a great achievement, but I\u2019m of course a little sad to see that it\u2019s not mentioned anywhere that Wuji is just a renaming of my CPU, SERV. They even pasted in block diagrams from my documentation.[0] https://github.com/olofk/serv[1] https://www.electronicsweekly.com/news/business/2d-32-bit-ri...\n \nreply",
      "They do mention SERV in their references (38).https://www.nature.com/articles/s41586-025-08759-9Sadly I can't access the full article right now.\n \nreply",
      "That sort of copying without attribution should be considered outright misconduct; it certainly would be in academia.\n \nreply",
      "Huh? This is a paper published in Nature, and it does cite Olof Kindgren and SERV in the references: https://www.nature.com/articles/s41586-025-08759-9#Bib1The paper itself is behind a paywall so I can't see it, but it looks from the references like they provided proper attribution.It's unfortunate that some of the articles around it don't mention that, but it seems like the main point of this is discussing the process for building the transistors, and then showing that can be used to build a complete CPU, not the CPU design itself which they just used an off-the-shelf open source one, which is designed to use a very small number of gates.\n \nreply",
      "Thanks to the Archive.org link, we can see that indeed they link directly to the SERV github in reference 38:    38. Kindgren, O. et al. SERV - The SErial RISC-V CPU. GitHub http:/github.com/olofk/serv (2020).\n \nreply",
      "> The paper itself is behind a paywall so I can't see ithttps://archive.org/details/s41586-025-08759-9\n \nreply",
      "That's China for you.\n \nreply",
      "I'm still waiting for that inkjet printer that can print transistors.https://www.nature.com/articles/s41598-017-01391-2\n \nreply",
      "Has anyone tried to replicate this? Seems like it would be very useful for amateur makers/hackers were it not for the $23k printer cost (no idea for the cost of the discussed silver ink). But surely someone crazy had access to one and tried or has tried to replicate on a cheaper printer? I figure HN has a decent chance of helping find said persons?\n \nreply",
      "It's possible that the inkjet printed transistor is both replicable and impractical for building a full microprocessor.The inkjet transistor article says \"A total of 216 devices were tested with a yield of greater than 95%, thus demonstrating the true scalability of the process for achieving integrated systems.\" But 95% yield on the transistor level implies vanishingly low yield at the device level when you need thousands of transistors to build a full microprocessor.Even the new MoS2 microprocessor discussed in the Ars article wasn't fabricated all at once. It was built up from sub-components like shift registers containing fewer transistors, then those components were combined to make a full microprocessor. See for example \"Supplementary Fig. 7 | Yield analysis of wafer-level 8-bit registers.\" in the supplementary information:https://static-content.springer.com/esm/art%3A10.1038%2Fs415...The yield of 8-bit registers, each consisting of 144 transistors, can reach\n71% on the wafer.\n \nreply"
    ],
    "link": "https://arstechnica.com/science/2025/04/researchers-build-a-risc-v-processor-using-a-2d-semiconductor/",
    "first_paragraph": "\n        It's slow and inefficient, but the semiconductor is only one molecule thick.\n      On Wednesday, a team of researchers from China used a paper published in Nature to describe a 32-bit RISC-V processor built using molybdenum disulfide instead of silicon as the semiconductor. For those not up on their chemistry, molybdenum disulfide is a bit like graphene: a single molecule of MoS2 is a sheet that is only a bit over a single atom thick, due to the angles between its chemical bonds. But unlike graphene, molybdenum disulfide is a semiconductor.The material has been used in a variety of demonstration electronics, including flash storage and image sensors. But we've recently figured out how to generate wafer-scale sheets of MoS2 on a sapphire substrate, and the team took advantage of that to build the processor, which they call RV32-WUJI. It can only add single bits at a time and is limited to kilohertz clock speeds, but it is capable of executing the full RISC-V 32-bit instruction "
  },
  {
    "title": "Fedora change aims for 99% package reproducibility (lwn.net)",
    "points": 304,
    "submitter": "voxadam",
    "submit_time": "2025-04-11T13:40:26 1744378826",
    "num_comments": 136,
    "comments_url": "https://news.ycombinator.com/item?id=43653672",
    "comments": [
      "The real treasure was the friend I found along the wayhttps://github.com/keszybz/add-determinism\n \nreply",
      "I kind of wonder if this or something similar could somehow nullify timestamps so you could compare two logfiles...further would be the ability to compare logfiles with pointer addresses or something\n \nreply",
      "A different but more powerful method of ensuring reproducibility is more rigorous compilation using formally verifiable proofs.That\u2019s what https://pi2.network/ does. It uses K-Framework, which is imo very underrated/deserves more attention as a long term way of solving this kind of problem.\n \nreply",
      "Another thing I'd love to see is more statically linked binaries. Something like Python, for instance, is a nightmare to install and work with\n \nreply",
      "I think general consensus is against you. Fedora packaging policy [1]:> Packages including libraries should exclude static libs as far as possible (eg by configuring with --disable-static). Static libraries should only be included in exceptional circumstances. Applications linking against libraries should as far as possible link against shared libraries not static versions.[1]: https://docs.fedoraproject.org/en-US/packaging-guidelines/\n \nreply",
      "What do you mean with \u201ca nightmare to install and work with\u201d exactly?\n \nreply",
      "nice to see they're in this too.https://news.opensuse.org/2025/02/18/rbos-project-hits-miles...\n \nreply",
      "> For example, Haskell packages are not currently reproducible when compiled by more than one threadDoesn't seem like a big issue to me. The gcc compiler doesn't even support multithreaded compiling. In the C world, parallelism comes from compiling multiple translation units in parallel, not any one with multiple threads.\n \nreply",
      "As a user of fedora what does this actually get me? I mean I understand it for hermetic builds but why?\n \nreply",
      "Reproducible builds can improve software quality.If we believe we have a reproducible build, that's constitutes a big test case which gives us confidence in the determininism of the whole software stack.To validate that test case, we actually have to repeat the build a number of times.If we spot a difference, something is wrong.For instance, suppose that a compiler being used has a bug whereby it is relying on the value of an unitialized variable somewhere. That could show up as a difference in the code it generates.Without reproducible builds, of course there are always differences in the results of a build: we cannot use repeated builds to discover that something is wrong.(People do diffs between irreproducible builds anyway. For instance, disassemble the old and new binaries, and do a textual diff, validating that only some expected changes are present, like string literals that have embedded build dates.  If you have reproducible builds, you don't have to do that kind of thing to detect a change.Reproducible builds will strengthen the toolchains and surrounding utilities. They will flush out instabilities in build systems, like parallel Makefiles with race conditions, or indeterminate orders of object files going into a link job, etc.\n \nreply"
    ],
    "link": "https://lwn.net/Articles/1014979/",
    "first_paragraph": "\nWithout subscribers, LWN would simply not exist.  Please consider\n       signing up for a subscription and helping\n       to keep LWN publishing.\nThe effort to ensure that open-source software is reproducible has been\ngathering steam over the years, and gaining traction with major Linux\ndistributions. Debian, for example, has been working toward reproducible\nbuilds for more than a decade; it can now\nproduce official\nlive CDs of the current stable release that are \nreproducible. Fedora started on the path much later, but it has\nprogressed far enough that the project is now considering a change\nproposal for the Fedora\u00a043 development cycle, expected to be\nreleased in October, with a goal of\nmaking 99% of Fedora's package builds reproducible. So far, reaction\nto the proposal seems favorable and focused primarily on how to\nachieve the goal\u2014with minimal pain for packagers\u2014rather than whether to attempt it.The Reproducible Builds project defines a\nbuild as reproducible if \"given the same sou"
  },
  {
    "title": "Once lush Sahara was home to a surprisingly unique group of humans (sciencealert.com)",
    "points": 59,
    "submitter": "gmays",
    "submit_time": "2025-04-10T13:16:25 1744290985",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=43643467",
    "comments": [
      "I love this reconstruction of green Sahara map:https://www.flickr.com/photos/cchurchili/40921572803/\n \nreply",
      "So this is only loosely related to the posted article, but I found the \"great green wall\" project from the U.N. to be super interesting. It makes me wonder if the same concepts can (and should?) be applied to other deserts, such as the American midwest.https://www.youtube.com/watch?v=4xls7K_xFBQ\n \nreply",
      "Big bold projects by African dictators to leapfrog the economy has a truly atrocious track record. UN involvement makes it even worse.That said, if it will work long term in some of the countries, that would be great news.I'm glad that it's still possible to destroy an ecosystem in order to replace it with something better. That would never fly in the US. We also have no need to produce more food, and our deserts are mostly beloved natural wonders.\n \nreply",
      "One of the few cases were indigenous were not replaced by neolithic newcomers but simply adopted their technology\n \nreply",
      "I believe current evidence is that the Berber peoples have been in North Africa at least 12,000 years.\n \nreply",
      "If you find that interesting, read about the African Humid Period: https://en.wikipedia.org/wiki/African_humid_periodThe present day situation is fascinating: https://en.wikipedia.org/wiki/African_humid_period#Present-d... : there is an ongoing \"greening\" which seems caused by global warming and CO2 increases!However, a 2003 study estimated only 45% of the Sahara could be covered by vegetation, and a 2022 study found that it may not be sufficient to start another AHP: it just \"lowers the threshold for orbital changes to induce Sahara greening\"\n \nreply"
    ],
    "link": "https://www.sciencealert.com/once-lush-sahara-was-home-to-a-surprisingly-unique-group-of-humans",
    "first_paragraph": ""
  },
  {
    "title": "Erlang's not about lightweight processes and message passing (2023) (stevana.github.io)",
    "points": 195,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-11T15:50:49 1744386649",
    "num_comments": 102,
    "comments_url": "https://news.ycombinator.com/item?id=43655221",
    "comments": [
      "The amazing thing about Erlang and the BEAM is it's depth of features. To the OP the Behaviour/Interface of Erlang is their biggest take away. For me I believe it is how you require far far less development resources to build complex systems than you would require in any other language (provided comparable experience in both stacks). And for many the lightweight processes and programming model.OTP itself has so much in it. We've been working on compiling Elixir to run on iOS devices. Not only can we do that through the release process but through using the ei library provided in Erlang we can compile a Node in C that will interface with any other Erlang node over a typical distributed network as you would for Erlang, Elixir, Gleam, etc... furthermore there is a rpc library in Erlang where from C we can make function calls and interface with our Elixir application. Yes, the encoding/decoding has an overhead and FFI would be faster but we're still way within our latency budget and we got this stood up in a few days without even have heard of it before.The larger point here is that Erlang has been solving many of the problems that modern tech stacks are struggling with and it has solved for scale and implementation cost and it solved these problems decades ago. I know HN has a bit of a click-bait love relationship with Erlang/Elixir but it hasn't translated over to adoption and there are companies that are just burning money trying to do what you get out of the box for free with the Erlang stack.\n \nreply",
      "Adding to this, the primitives erlang, and descendants, give you are very easy to work with, and therefore very easy to test.Take GenServer. The workhorse of most BEAM systems. Everything it does it basically just calling various functions with simple parameters. So you can test it just by call l calling those functions and manually passing parameters to it, and asserting on its output. No need to set up complex testing systems that are capable of dealing with asynchronous code, no need to handle pauses and wait for coffee to finish running in your tests. It's something a lot of juniors tend to miss, but it's liberating when figured out\n \nreply",
      "I went from a company that used Elixir in the backend to one that uses Nodejs.I had gone in neutral about Nodejs, having never really used it much.These projects I worked on were backend data pipeline that did not even process that much data. And yet somehow, it was incredibly difficult to isolate exactly the main bug. Along the way, I found out all sorts of things about Nodejs and when I compare it with Elixir/Erlang/OTP, I came to the conclusion that Node.js is unreliable by design.Don't get me wrong. I've done a lot of Ruby work before, and I've messed with Python. Many current-generation language platforms are struggling with building reliable distributed systems, things that the BEAM VM and OTP platform had already figured out.\n \nreply",
      "Elixir never performs all to well in microbenchmarks. Yet in every application I've seen Elixir/Erlang projects compared to more standard Node, Python, or even C# projects and the Elixir one generally has way better performance and feels much faster even under load.Personally I think much of it is due to async being predominant in Node and python. Async seems much harder than actor or even threading for debugging performance issues. Sure it feels easier to do async at first. But async leads to small bloat adding up and makes it very difficult to debug and track down. It makes profiling harder, etc.In BEAM, every actor has its own queue. It's trivial to inspect and analyze performance blockages. Async by contrast puts everything into one giant processing queue. Plus every function call in async gets extra overhead added. It all adds up.\n \nreply",
      "I'd appreciate an in-depth write-up about deficiencies you found in Node and how Erlang fixes them\n \nreply",
      "> I know HN has a bit of a click-bait love relationship with Erlang/Elixir but it hasn't translated over to adoption and there are companies that are just burning money trying to do what you get out of the box for free with the Erlang stack.Do you or the community have a sense why that is?\n \nreply",
      "Elixir is \"bad\" because it is not a friendly language for people who want to be architecture astronauts at the code level (you can definitely be an architecture astronaut at the process management level but that's a very advanced concept).  And a lot of CTOs are architecture astronauts.\n \nreply",
      "Not just that, but there is no giant gorilla backing BEAM. Google pushes Go and Java, Microsoft node and c#\n \nreply",
      "That's the opposite of my experience. I tend to get those \"architect astronauts\" in teams using other languages platforms, and the folks I work with Erlang or Elixir tend to be  pragmatic and willing to dig down the stack to troubleshoot problems.\n \nreply",
      "That's what I wrote!  (Read the first three words with a heap of sardonicism). Edited to add quotes around bad\n \nreply"
    ],
    "link": "https://stevana.github.io/erlangs_not_about_lightweight_processes_and_message_passing.html",
    "first_paragraph": "I used to think that the big idea of Erlang is its lightweight\nprocesses and message passing. Over the last couple of years I\u2019ve\nrealised that there\u2019s a bigger insight to be had, and in this post I\u2019d\nlike to share it with you.Erlang has an interesting history. If I understand things correctly,\nit started off as a Prolog library for building reliable distributed\nsystems, morphed into a Prolog dialect, before finally becoming a\nlanguage in its own right.The goal seemed to have always been to solve the problem of building\nreliable distributed systems. It was developed at Ericsson and used to\nprogram their telephone switches. This was sometime in the 80s and 90s,\nbefore internet use become widespread. I suppose they were already\ndealing with \u201cinternet scale\u201d traffic, i.e.\u00a0hundreds of millions of\nusers, with stricter SLAs than most internet services provide today. So\nin a sense they were ahead of their time.In 1998 Ericsson decided to ban all use of Erlang1.\nThe people responsible for devel"
  },
  {
    "title": "Blue Prince is a roguelike puzzle masterpiece (mssv.net)",
    "points": 101,
    "submitter": "adrianhon",
    "submit_time": "2025-04-09T01:27:48 1744162068",
    "num_comments": 62,
    "comments_url": "https://news.ycombinator.com/item?id=43628070",
    "comments": [
      "After playing the game for 10+ hours and dropping it out of sheer frustration, I came to the conclusion that I must have been playing a vastly different game than the people praising it.The first hour was great. I was constantly encountering new rooms and solving puzzles. The many times where the game decided to give me nothing but rooms leading to dead ends was annoying, but I still had things to explore in the next run so it didn't matter that much.\nAfter that first hour, the game became a slog. I encountered the same rooms, solved the same two puzzles for resources and was constantly praying for the RNG to give me something new.\nThere is some RNG manipulation, but not enough to mitigate the boring part of the game.\nThere are a few interesting overarching puzzles, but most of them are wrapped in multiple layers of RNG.For example, for one puzzle you need a specific item that randomly spawns, use it in a room that randomly spawns which you need to unlock with another room that also randomly spawns.\nIt took me 6 hours for the game to give me a run where I got all three of those things in a single run.\nThe reward? Some resources that I have next to no use for and some clues that I can only experiment with if the RNG deems me worthy.I have absolutely no idea where the praise for the game comes from. Maybe this game is perfect for those who are really into roguelites, but for me personally it just feels like the game is wasting my time for no reason at all.\n \nreply",
      "I generally have the same frustration with roguelites as you seem to: every time I start a run, it feels like I'm gambling whether I'll have any fun at all. A bad seed or start can mean losing in ways that feel unfair or boring, like in balatro if you get a bunch of bad hands and bad jokers, you struggle through rounds and hands until you either lose or get an interesting combination. I don't need that kind of gambling in my life when there's tons of games out there where I know I will have fun.E: I still quite like Balatro - when it works it's a blast. I'll also still try out Blue Prince because people I respect seem to like it.\n \nreply",
      "One common mantra about most roguelites is that every run can be a successful run if you play your cards right. Some will be harder, in others you\u2019ll become unstoppable, but the general idea is that once you get good enough you should be able to win runs. I\u2019m not sure if this holds and is extremely dependent on how balanced the game is, but I think it\u2019s a sane way to approach the genre since it pushes you to improve and generally becomes a rule once you become good enough at some of the games.\n \nreply",
      "One of the key differences between rogue lites and rogue likes is meta progression. In most roguelites you're able to unlock things and get more powerful for future runs. In roguelikes you always have the same starting rng. I definitely agree with you that it's all up to the game to balance the progression through both unlocks and skill improvement so it's not entirely rng. But I also don't think many put much effort into \"every run is solvable\". Especially for roguelikes.\n \nreply",
      "I've played for about an hour and agree with your assessment.  I still have it installed but I doubt I will revisit it.I've switched to South of Midnight and it's amazing.  Not everyone's type of game - and certainly not a puzzle game - but the graphics, music, story, and gameplay combine to make it one of the best games I've played in a long, long time.\n \nreply",
      "I'm about 8 hours in and really enjoying it, but I feel like I can see this in my future. For now I have so many puzzles/threads going that even if one doesn't work on a run because of RNG I'm still making progress somewhere else, but I could see that drying up a bit as I solve more things and want to focus on something specific.The puzzles for resources you mention are by far the worst part for me. I really wish there were a way to say \"I get it, I know how to solve simple logic puzzles and do basic arithmetic, just give me the stuff\".\n \nreply",
      "I've played about an hour and am getting the feeling I won't see it through to an ending.For anyone wanting a non-RNG puzzler set around a large building I highly recommend  https://en.wikipedia.org/wiki/Lorelei_and_the_Laser_Eyes\n \nreply",
      "Having played both of these games I agree that Lorelei stands out as a sort of foil for blue prince. And my opinion is that that is a huge endorsement of blue prince. Lorelei\u2019s puzzles felt so inelegant and largely detached from the ideas being explored. Felt like a logic puzzle book, with some esoteric story stuff on top that just did not keep me interested.Blue prince\u2019s rng is quite well thought out imo. Once you pick up on some of the unwritten rules about the room drafting system and start building strategies around what to prioritize and how to adjust your goals, it starts feeling a lot like many other popular card-based strategy games.There are weak points, for sure, and your contrasting it with Lorelei makes sense. But Lorelei\u2019s puzzles felt so plain and unchallenging. I like that blue prince is keeping me on my toes.\n \nreply",
      "> solved the same two puzzles for resourcesI'm eager to play more, but this is something that was a worry already an hour in. The logic puzzle I did was good enough and seems like it can be generated procedurally well enough, the \"math\" puzzle I did wasn't. There's more than that, right?> and some clues that I can only experiment with if the RNG deems me worthy.And on top of that, it's hard to know if those clues actually will matter in other runs. I found a safe code in one run. If it takes three runs before the RNG decides the room with the safe will be there, will the code be randomized? I've been trying to avoid spoilers so it's hard to know what matters.\n \nreply",
      "I was also sad to hear about how much RNG is in the game, that is a detractor to what seems like a well put together experience otherwise. If you wanted to give something else a try, and have a PC, I made a first-person puzzle game that's (hopefully) more akin to Antichamber and the puzzle bits of Outer Wilds, called Chroma Zero. There's a demo on steam if you just want to dip your toe in. https://store.steampowered.com/app/3121470/Chroma_Zero/\n \nreply"
    ],
    "link": "https://mssv.net/2025/04/07/a-puzzle-designer-on-blue-prince-a-roguelike-puzzle-masterpiece/",
    "first_paragraph": "\u00b7\u00b7Playstation, Xbox,\u00a0 PC, Steam Deck$29.99 (releasing April 10)DogubombBlue Prince is a startlingly original puzzle game that marries compulsive roguelike mechanics with exceptional art and storytelling at an incredible scale.\u00a0It begins with your arrival at the Mount Holly estate, a sprawling mansion owned by the late Herbert S. Sinclair. You\u2019re his grandnephew and if you can find the 46th room of the building, you\u2019ll receive it all.Now, some will say you should play this game completely blind \u2013\u00a0in effect, that you should skip their review. It\u2019s true that there is an intense delight in discovering the world and mechanics of Blue Prince, and if you want to preserve that in its entirety, you should return here later. But before you leave, I can reassure you of two things.\u00a0First, there are no jump scares or horror in Blue Prince. No twitch reflexes are required, nor any platforming, and there\u2019s zero time pressure. To be fair, I\u2019ve only played it for twenty hours; it\u2019s possible these thing"
  },
  {
    "title": "Intentionally Making Close Friends (2021) (neelnanda.io)",
    "points": 77,
    "submitter": "fi-le",
    "submit_time": "2025-04-08T06:54:36 1744095276",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43619032",
    "comments": [
      "Related (Nov 2022 - 307 comments): https://news.ycombinator.com/item?id=33774353\n \nreply",
      "I used to wait for people to talk to me. But now I try first, and it works!\n \nreply"
    ],
    "link": "https://www.neelnanda.io/blog/43-making-friends",
    "first_paragraph": "One of the greatest sources of joy in my life are my close friends. People who bring excitement and novelty into my life. Who expose me to new experiences, and ways of seeing the world. Who help me learn, point out my blind spots, and correct me when I am wrong. Who I can lean on when I need support, and who lean on me in turn. Friends who help me grow more into the kind of person I want to be.I am especially grateful for this, because up until about 4 years ago, I didn\u2019t have any close friends in my life. I had friends, but struggled to form real emotional connections. Moreover, it didn\u2019t even occur to me that I could try to do this. It wasn\u2019t that I knew how to form close friends but was too anxious to try, rather, \u2018try to form close friendships\u2019 was a non-standard action, something that never even crossed my mind. And one of my most life-changing experiments was realising that this was something I wanted, and actually trying to intentionally form close friends.\u00a0It\u2019s easy to slip int"
  },
  {
    "title": "A recent study suggests that insects branched out from crustaceans (smithsonianmag.com)",
    "points": 65,
    "submitter": "Carrok",
    "submit_time": "2025-04-11T20:19:39 1744402779",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=43658093",
    "comments": [
      "I'm so used to seeing the \"fish crawling onto the shore\" cartoon of evolution that I assumed the branching always went that way - land creatures are branchoffs of sea creatures. But surely this is oversimplified - are there examples in the other direction, where a branching occured in land animals and one branch then returned to the sea?\n \nreply",
      "I think all marine mammals fit this, right?\n \nreply",
      "Yes. And for a non animal example, there's sea grass, which evolved from land grasses.\n \nreply",
      "Sea grass is a monocot but belongs to a different order (Alismatales) than true grass (Poales).\n \nreply",
      "Thanks for the correction. Interesting\n \nreply",
      "And for an animal but non-mammal example, there are penguins.\n \nreply",
      "Sea snakes, as well.\n \nreply",
      "Mangroves are aquatic trees that evolved from regular land trees.\n \nreply",
      "Whales.https://baleinesendirect.org/en/discover/life-of-whales/morp...\n \nreply",
      "Also ichthyosaurs' ancestors were terrestrial reptiles, though the whole branch is now extinct.\n \nreply"
    ],
    "link": "https://www.smithsonianmag.com/science-nature/you-might-think-of-shrimp-as-bugs-of-the-sea-but-a-remarkable-discovery-shows-the-opposite-bugs-are-actually-shrimp-of-the-land-180986303/",
    "first_paragraph": ""
  },
  {
    "title": "AI Coding and the Peanut Butter and Jelly Problem (iamcharliegraham.substack.com)",
    "points": 31,
    "submitter": "tylerg",
    "submit_time": "2025-04-11T21:26:36 1744406796",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=43658794",
    "comments": [
      "This video shows the peanut butter and jelly problem in action: https://youtu.be/cDA3_5982h8?si=xIQpzNTvhRcGY4Nb\n \nreply",
      "This is actually no different than for humans once you get past the familiar.  It's like the famous project management tree story: https://pmac-agpc.ca/project-management-tree-swing-storyIf anything, LLMs have surprised at much better they are than humans in understanding instructions for text based activities.  But they are MUCH worse than humans when it comes to creating images/videos.\n \nreply",
      "Didn't know they did the PB&J thing at Harvard. I remember doing that in the 3rd grade or thereabouts.\n \nreply",
      "Anyone here see the CS50 peanut butter and jelly problem in person?\n \nreply",
      "Not in that course, but I've done it at a \"STEM\" day; it's just about the most fun I've ever had teaching.\n \nreply",
      "That's awesome.I got the sense the professor liked it a ton too. In the videos of this on YouTube you can see the professor really enjoying watching it all go down.It still is so memorable.\n \nreply",
      "I had a middle school art teacher do it in roughly 1995.\n \nreply",
      "Funny to see, I used this exact analogy a few weeks ago regarding AI\n \nreply",
      "Okay, but like.If you do have that skill to communicate clearly and describe the requirements of a novel problem, why is the AI still useful? Actually writing the code should be relatively trivial from there. If it isn't, that points to a problem with your tools/architecture/etc. Programmers IMX are, on average, far too tolerant of boilerplate.\n \nreply",
      "Once you've got to a detailed specification, LLMs are a lot faster at correctly typing code than you are.\n \nreply"
    ],
    "link": "https://iamcharliegraham.substack.com/p/ai-coding-and-the-peanut-butter-and",
    "first_paragraph": ""
  },
  {
    "title": "Datastar: Web Framework for the Future? (chrismalek.me)",
    "points": 166,
    "submitter": "1659447091",
    "submit_time": "2025-04-11T16:53:20 1744390400",
    "num_comments": 81,
    "comments_url": "https://news.ycombinator.com/item?id=43655914",
    "comments": [
      "As you escape the React/JSX intoxification, you can drop the XML syntax.It took us a while back in the day after the XHTML arc, but for sure it'll be ok.I know this looser SGML universe might feel a little kooky, but trust me it wears baggy trousers, rocks gifs with a hard g and offers great <hugs>.  <thank><you>\n  <nothankyou/>\n \nreply",
      "Reading tfa I kept wondering \"is this yet another framework where every click is a server round trip?\" Judging by the demos\u00b9, the answer is yes?If this is \"the Future\", I'm branching off to the timeline where local-first wins.\u00b9. https://data-star.dev/examples/click_to_edit\n \nreply",
      "Our free shared fly.io was not built to handle hackernews.  We are looking into alternatives but in the mean time checkout https://andersmurphy.com/2025/04/07/clojure-realtime-collabo... as it's the same tech but on a slight better machine.\n \nreply",
      "If you want a solid demo of what you can do with datastar. You can checkout this naive multiplayer game of life I wrote earlier in the week. Sends down 2500 divs every 200ms to all connected cliends via compressed SSE.https://example.andersmurphy.com/\n \nreply",
      "Is sending 10,000 divs/sec the right solution for this problem, or is this an \"everything looks like a nail\" solution?\n \nreply",
      "This is a Wirth's Law solution - the reasoning goes: \"computers are fast enough to deal with it, so why not?\"\n \nreply",
      "But, you can learn a lot doing dumb stuff. I learnt a lot about compression.If you go to google chrome and throttle the site to 3G it will still run fine.Rendering on the server like this will be faster for low end devices than rendering on the client (as the client doesn't have to run or simulate the game). It just gets raw HTML it has to render.Effectively, the bulk of the work on the client will be done by the browser native rendering code and native compression code.The other thing that might not be obvious. Is #brotli compression is not set to 11, it's set to 5 so similar CPU cost to gzip. But, the compression advantage comes from compressing the SSE stream. Tuning the shared window size cost memory on client and server but gives you a compression ratio of 150-250:1 (vs 30:1), at the cost of 263kb on both server on client (for context gzip has a fixed window of 32kb). This not only saves bandwidth and make the game run smoothly on 3G it also massively reduces CPU cost on both client and server. So it can run on lower end devices than a client heavy browser app.So server driven web apps are better for low end devices. The same way you can watch YouTube on a low end phone but not play some games.\n \nreply",
      "I'm am not of that opinion at all.  I'm all about optimization but then people will say \"that's not how web pages are made\".  Can't win opinions but can say, Datastar is not the bottleneck.  You send as much, as often as you choose.\n \nreply",
      "It's deliberately naive. But brotli and a tuned compression window over SSE means it gets 150-250:1 compression ratio, combined with Datastar rendering speed and you can get away with it.The reason it's naive is although you can use datastar to drive SVG, a canvas or even a game engine the minute you do people think you are doing magic game dev sorcery and dismiss your demo. I wanted to show that your average crud app with a bunch of divs is going to do just fine.I break it down in this post.https://andersmurphy.com/2025/04/07/clojure-realtime-collabo...\n \nreply",
      "Wow, I've never done multiplayer GoL. Simple yet addictively fun. LONG LIVE THE ORANGE CIVILIZATION!!edit: damn, purple civilization got hands\n \nreply"
    ],
    "link": "https://chrismalek.me/posts/data-star-first-impressions/",
    "first_paragraph": "Datastar\nis a new hypermedia\nframework that makes building real-time web applications simpler and more efficient. It prioritizes server-side logic, uses \u201csignals\u201d for automatic UI updates, and leverages Server-Sent Events for lightning-fast performance. If you\u2019re looking for a streamlined alternative to traditional JavaScript frameworks or HTMX, Datastar\nis worth exploring.However, it requires that you approach web development with a fresh perspective, embracing server-driven architecture and reactive programming.I\u2019ve been diving into hypermedia\nlately looking at frameworks and libraries to build a new product and to help quickly create proof of concepts and web tools for clients.HTMX at the time of writing was getting basically all the attention in the Hypermedia world. It demos really well and the examples are great. However, this article is NOT about HTMX.I believe hypermedia and HTMX offer a promising direction, but when I tried to develop a new product using HTMX, I felt stuck due"
  },
  {
    "title": "Adobe deletes Bluesky posts after backlash (petapixel.com)",
    "points": 185,
    "submitter": "bookofjoe",
    "submit_time": "2025-04-11T14:01:06 1744380066",
    "num_comments": 275,
    "comments_url": "https://news.ycombinator.com/item?id=43653885",
    "comments": [
      "Adobe is the one major company trying to be ethical with its AI training data and no one seems to even care. The AI features in Photoshop are the best around in my experience and come in handy constantly for all sorts of touchup work.Anyway I don't really think they deserve a lot of the hate they get, but I do hope this encourages development of viable alternatives to their products. Photoshop is still pretty much peerless. Illustrator has a ton of competitors catching up. After Effects and Premiere for video editing are getting overtaken by Davinci Resolve -- though for motion graphics it is still hard to beat After Effects. Though I do love that Adobe simply uses JavaScript for its expression and scripting language.\n \nreply",
      "> Adobe is the one major company trying to be ethical with its AI training data and no one seems to even care.It's because nobody actually wants that.Artists don't like AI image generators because they have to compete with them, not because of how they were trained. How they were trained is just the the most plausible claim they can make against them if they want to sue OpenAI et al over it, or to make a moral argument that some kind of misappropriation is occurring.From the perspective of an artist, a corporation training an AI image generator in a way that isn't susceptible to moral or legal assault is worse, because then it exists and they have to compete with it and there is no visible path for them to make it go away.\n \nreply",
      "Most artists would prefer not to compete with an AI image generator that has been trained on their own artwork without their permission, for obvious reasons.\n \nreply",
      "That's exactly the moral argument Adobe is taking away from them, and the same argument has minimal economic relevance because it's so rare that a customer requires a specific individual artist's style.\n \nreply",
      "> Adobe is the one major company trying to be ethical with its AI training data and no one seems to even care.It's sad that it's funny that you think Adobe is motivated by ethical consideration.\n \nreply",
      "They don't have to be motivated by ethics. I'm fine with them grudgingly doing ethical things because their customer base is all artists, many of whom would look for an alternative product.\n \nreply",
      "You are fine with it, of course, because you're reasonable. But OP's claim was that Adobe is \"trying to be ethical with its AI training data and no one seems to even care\" as if we're meant to give special consideration to a company for doing the only economically sensible thing when most of its customers are artists.\n \nreply",
      "The great thing about loudly painting Adobe with the brush of \"ethical AI training\" (regardless of why they're doing it) is that the backlash will exponentially bigger if/when they do something that betrays that label. Potentially big enough to make them reverse course. It's not much, but it's something.\n \nreply",
      "Probably want to look good to their customer base - artists\n \nreply",
      "Where did the poster say they think Adobe is motivated by that? They said Adobe is operating that way.\n \nreply"
    ],
    "link": "https://petapixel.com/2025/04/10/adobe-deletes-bluesky-posts-after-furious-backlash/",
    "first_paragraph": ""
  },
  {
    "title": "Dev Tools Honeytrap: Why We Can't Stop Building Tools Nobody Buys (substack.com)",
    "points": 22,
    "submitter": "lunarcave",
    "submit_time": "2025-04-11T23:37:45 1744414665",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43659876",
    "comments": [
      "[flagged]",
      "Could you please stop posting unsubstantive comments and flamebait? You've unfortunately been doing it repeatedly. It's not the curious conversation that this site is supposed to be for, and in fact destroys what it is for.If you wouldn't mind reviewing https://news.ycombinator.com/newsguidelines.html and taking the intended spirit of the site more to heart, we'd be grateful. Note this one: \"Please don't fulminate.\"\n \nreply"
    ],
    "link": "https://substack.com/home/post/p-161145826",
    "first_paragraph": ""
  },
  {
    "title": "Key principles on in-game virtual currencies in the EU (tiendil.org)",
    "points": 34,
    "submitter": "speckx",
    "submit_time": "2025-04-11T20:52:39 1744404759",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=43658420",
    "comments": [
      "Although it is painted relatively negative in the article, I feel it's a good thing. Of course, EU is known for its overregulation, but consumer rights are not to be neglected.\n \nreply",
      "Most \u201cEU overregulation\u201d is just consumer regs being painted in a bad light for American consumers, so the Us govt won\u2019t imitate it.EU banning most forms of GMOs was once considered wild over regulation.\n \nreply",
      "I kind of wonder if \"overregulation\" and \"unionization\" are two terms carefully chosen to be negative by corporate interests?\n \nreply",
      "> \"The price in real-world currency must always be displayed next to the price in in-game currency.\"how would that work? Basically all games use a discount scheme were the price for X of ingame currency depends on how many tokens/gold/coins you buy.\n \nreply",
      "Yes but part-of the point of those discounts is to obfuscate the value of that currency when you are spending it.This is like nutritional information on food, it will be \"bad\" for some companies if there is transparency.\n \nreply",
      "Price means price without discount.\n \nreply",
      "Ah, so we can display the in-game amount, along with it the full-price you would have paid without the discount, and the \u201csavings\u201d because you bought more and oh look how much more you save when you buy more!They\u2019re gonna need a rule for that.\n \nreply",
      "Of course that is how it should be done, but that is least-likely to be implemented by the greedy games industry, is it? They'll interpret it differently as with \"cost when saving the most by our fancy bundles\".\n \nreply",
      "Then EU will fine them with fines that draw blood.\n \nreply",
      "What about showing the actual real amount that that particular user paid for those tokens?\n \nreply"
    ],
    "link": "https://tiendil.org/en/posts/eu-key-principles-on-in-game-virtual-currencies",
    "first_paragraph": "Last month, the Consumer Protection Cooperation Network, in coordination with the European Commission, released interesting guidelines on the implementation of in-game currencies.The document does not have the status of a law; it is a recommendation for interpreting existing EU consumer protection laws regarding computer games. As I understand it, each country decides separately whether to follow these recommendations or not.I have mixed feelings towards such regulations.On one hand, the nonsense that goes on in free-to-play games (especially mobile ones) should have been stopped a long time ago. From my ethical position, I fully support attempts to bring order there.On the other hand, regulations always complicate life for small and medium businesses and have little effect on large companies. The larger the company, the easier it is for it to ignore regulations.In the following text, I'll list the main theses of the document, speculate on how these recommendations should be implemente"
  },
  {
    "title": "Bilinear interpolation on a quadrilateral using Barycentric coordinates (gpuopen.com)",
    "points": 109,
    "submitter": "mariuz",
    "submit_time": "2025-04-11T15:25:13 1744385113",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=43654912",
    "comments": [
      "This is one of those things that feels like a broken/half-assed/oversimplified implementation got completely proliferated into the world a long time ago and it took several years for the right person to do a full-depth mathematical analysis to reveal what we should've been doing all along. Similar to antialiasing and sharpening, texture filtering, color spaces and gamma correction, etc.It reminded me of this article specifically: https://bgolus.medium.com/the-best-darn-grid-shader-yet-727f...\n \nreply",
      "For someone who wrote textured triangles on a 386:First rule of computer graphics: lieSecond rule of computer graphics: lieThird rule of computer graphics: lie\n \nreply",
      "The fact that triangles have proliferated is not due to half-assery. Hardware can rasterize them very quickly, and a triangle can have only one normal vector. Quads can be non-planar. It's true that quads are nice for humans and artists though!As an aside, Catmull-Clark subdivision has been around since 1978, which, as a first step, breaks an arbitrary polyhedron into a mesh of quadrilaterals.\n \nreply",
      "It's not so much that triangles are the primitive, as much as our logic for combining multiple triangles into a mesh and texturing, lighting, and deforming them in continuous ways clearly has some gaps. It's definitely not an easy problem and it's a fun exercise to see how various silicon innovations unlocked increasingly accurate solutions, and what corners needed to be cut to hit 30fps back in the day.\n \nreply",
      "Yeah, I don't think triangles will go away anytime soon. And, sometimes they're even preferred in certain cases by artists (think creases on jeans).\n \nreply",
      "It's quite astonishing how complicated it is to draw lines in 3D graphics. As a novice it was a little unbelievable that the primitives for drawing lines was effectively limited to a solid screen-space pixel wide line. Want to draw a 2 pixel wide line? Do it yourself with triangles.\n \nreply",
      "Ironically, back in the OpenGL 2.0 days, it was a lot easier to do things like this.\n \nreply",
      "Well, technically the API is still available pretty much everywhere (be it directly or via a wrapper library) and most hardware still has support for drawing lines, so it is still easy in current days to do things like this too :-P.I'm using it all the time when i want to draw lines in 3D.(though as far as lines and OpenGL is concerned i remember reading ages ago that not even SGI's implementation had full support for everything OpenGL was supposedly able to do)\n \nreply",
      "The API still exists, but in most implementations things like line styles and thickness are no longer supported.\n \nreply",
      "For most workflows this is a non-issue. When texturing a triangle mesh, the distortions are baked into the texture map, so no seams are visible at the quad diagonals.\n \nreply"
    ],
    "link": "https://gpuopen.com/learn/bilinear-interpolation-quadrilateral-barycentric-coordinates/",
    "first_paragraph": "\u0141ukasz Izdebski, PhD, is a Developer Technology Engineer at AMD\u2019s Game Engineering, focusing on optimization of game engine rendering features. His research interests include animation, geometry modelling, and differential geometry.In computer graphics, we rarely encounter continuous data. We often work with digital data, and in the context of geometric modeling, this means we typically work with polygon meshes rather than procedural surfaces like B\u00e9zier patches. The most popular technique for constructing digital three-dimensional objects in dedicated modeling software is polygon modeling. The result of the creation phase is a set of polygons (mesh), where the polygons in the mesh can share vertices and edges with other polygons.Although users can create various types of surfaces (e.g., non-manifold), the most common surface is the topological 2-manifold. In short, a 2-manifold is a mathematical concept in topology, where the space locally resembles the Euclidean plane in \\mathbb{R}^2"
  },
  {
    "title": "Modern 6502 (mikekohn.net)",
    "points": 73,
    "submitter": "ingve",
    "submit_time": "2025-04-11T18:01:33 1744394493",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43656609",
    "comments": [
      "The W65C265S is a delightful chip, and I highly encourage anyone curious about playing with 8-bit (/16-bit)processors to pick up board like the ...SXB mentioned here. I do wish that WDC's tools were more open and less Windows-specific, but the chip can easily run 65C02/65C816 code output from any of the open tools, and it's (mostly) well-documented.I hope that educational institutions are also using WDC's chips/boards, to help make sure that they stay around for years to come. I do wish that I could easily get my hands on a Mensch Computer.\n \nreply",
      "There is also the Olimex 6502 only $30EURThe Neo6502 has USB keyboard host and HDMI/DVI output.https://www.olimex.com/Products/Retro-Computers/Neo6502/open...\n \nreply",
      "> I ended up mounting one of them on the side of the door at the entrance to my house for spiritual protection.\n \nreply",
      "Cute, basically a Mezuzah. https://en.wikipedia.org/wiki/Mezuzah\n \nreply",
      "Oh definitely a Mezuzah. Right down to the angling (although the Sephardic practice is to position it straight up and down).\n \nreply",
      "I think you're fully protected from Terminator and Bender.Neither will dare to attack your residence.\n \nreply",
      "I never knew they tried to extend the 6502 ISA to 32 bits.\n \nreply"
    ],
    "link": "https://www.mikekohn.net/micro/modern_6502.php",
    "first_paragraph": "\nPosted: March 27, 2016Updated: April 16, 2016Introduction\nA few years ago while searching for electronic parts, I stumbled on the\nWestern Design Center W65C02\nprocessor.  Even though it's in a DIP packaging, which makes it easy for\na hobbyist like me to breadboard, it would still have required RAM and\nother chips to make it useful.  Considering this chip was the first processor\nI learned to program on, the 6502 is more like a religious thing for me\nso I got two of them.  I ended up mounting one of them on the side of the\ndoor at the entrance to my house for spiritual protection.\n\n\nA few years later while doing my daily hackaday.com\nreading, I discovered the\nW65C265SXB\nboard, a modern microcontroller with a 6502 (actually 65C816) at its core.\nI did a really good job resisting buying one for a while, but eventually\ngave in.  To put this board to use I decided to put up this page\nwith 3 small projects (added a 4th more recently)\nto show off some things that can be done with this\nnewer 65"
  },
  {
    "title": "Bonobos use a kind of syntax once thought to be unique to humans (newscientist.com)",
    "points": 129,
    "submitter": "docmechanic",
    "submit_time": "2025-04-07T15:51:21 1744041081",
    "num_comments": 95,
    "comments_url": "https://news.ycombinator.com/item?id=43612835",
    "comments": [
      "> Now we have evidence that both chimps and bonobos have syntax, it is inevitable that this capacity for compositionality was inherited from our last common ancestor, says Leroux. \u201cThey just showed, unambiguously, that this core building block is evolutionary ancient and at least 7 million years old, and maybe even older.\u201dThis is not true at all.  It's like saying that tool construction must be >300 million years old because both chimpanzees and New Caledonian crows make tools.  Things can be invented or discovered multiple times by different species.  It might be inherited from a common source, but it might not.\n \nreply",
      "Reinforcing my strongly held belief that what fundamentally sets humans apart isn't spoken language, or tools, or any of that, but rather the fact we write down what we know, then make those writings available to future generations to build on. We're a species distinguished from all others by our information-archival and -dissemination practices. We're an archivist species, a librarian species. Homo archivum. In my opinion.\n \nreply",
      "If that were the case, then you would expect isolated groups of humans who never developed a writing system to be significantly different from \"homo archivum\", but we know that's not true.We also know that groups without writing systems were historically able to adopt writing systems rather quickly, which is, I think, rather good evidence that writing is a technology, not a point of speciation.Going back to Ancient Greece, Socrates didn't even believe in the effectiveness of writing for communication of knowledge. My poetry professor used to spend some time on this, because it's intimately tied to the art of poetry. He would cite a number of studies showing our emotional responses are intimately tied to our language processing, and that humans are wired to emotionally respond to, and remember, stories.Even before writing, oral histories were passed down for many generations. For an extreme example, see: https://www.sapiens.org/language/oral-tradition/ .I won't pretend to know what makes us human, but ultimately I believe it has to be rooted in something neurological, not technological.\n \nreply",
      ">If that were the case, then you would expect isolated groups of humans who never developed a writing system to be significantly different from \"homo archivum\", but we know that's not true.I'm not sure I understand why this would necessarily be what you would expect. I would say it's entirely the other way around. If we have some sort of favorable evolutionary circumstances that predispose us to turn into archivists, that might be at the frontier of the outer limits of the capability we're able to reach, so it might only show up in certain pockets or subsets of our overall population. Getting there would still hinge on favorable probabilities and circumstances that might only obtain in a small percentage of cases.As for Socrates, I must confess I am rather smitten with him as a historical figure and as a philosopher, but for the many great things that Socrates is, I don't think he's a reliable authority for the evolutionary history of humanity writ large. I suspect that you're entirely right that oral traditions are more emotionally resonant and powerful than written traditions. But don't think there's any logical fallacy or contradiction in supposing that nevertheless a written tradition could emerge in parallel with oral traditions.I suppose I do agree with your end point though, which is that I'm not sure that a disposition towards the writing can be pointed to as like a singular thing that's at the essence of what it is to be human. In fact, I would say that that very question is kind of romanticized and abstract in a way that doesn't make clear contact with our scientific understanding and therefore is kind of a malformed question. But I don't have to agree with that form of question to nevertheless believe that our capability to put language into a written form had rather transcendent consequences for us as a species.\n \nreply",
      "> If we have some sort of favorable evolutionary circumstances that predispose us to turn into archivistsIntelligence - predicting the future rather than reacting to the present - unlocks the possibility of communicating about the future rather than just the present (basic animal calls - predator alerts, intimidation threats, mating calls, etc), which means the message can have value in the future if stored and transmitted (unlike a predator alert which is useless if not delivered in the moment).It seems that writing, or proto-writing (drawings become symbolic glyphs?), probably developed before message carrying/sending, which then becomes the big capability unlock - the ability to send/spread information and therefore for humans to become a \"collective intelligence\" able to build upon each other's discoveries.It's interesting why some groups of humans never culturally developed along this path though - aboriginees and forest peoples who have no written language. Is it because of their mode of life, or population density perhaps? Cultural isolation? Why have these groups not found the utility for written language?Apparently as recently as 1800 global literacy rate was only around 10% - perhaps just a reflection that in the modern world you can passively benefit from the products of our collective intelligence without yourself being part of the exchange, or perhaps a reflection that desire for information is not the norm for our species - more for the intelligentsia?!\n \nreply",
      "> I won't pretend to know what makes us human, but ultimately I believe it has to be rooted in something neurologicalIn terms of intelligence, yes, but in terms of what we've achieved then \"technology\" such as writing/archiving certainly has made a massive difference, else we'd be limited to what could be built by passing down oral history and skills passed from one generation to the next, much like Aboriginal Australians.I suspect that the neurological (& vocal) differences that make us more intelligent than other apes are likely extremely few - more like \"fine tuning\" differences than anything major.\n \nreply",
      "The question is whether or not cultures that had no writing systems were limited to the same level of intelligence and/or development that other primates exhibit.Given that with exception of an interesting knot-encoded (Quipu) system for some period of the Inca empire, the entire human population of the Americas (at least 15-20% of the total human population) fits this description, the answer seems to be \"no\". These cultures built huge cities (among the largest in the world at the time), used sophisticated irrigation schemes, ceramics technology and more.\n \nreply",
      "...but is there another species that writes things down for other individuals in their species to reference?\n \nreply",
      "I think that's exactly the right question and the answer is pretty clear that there is no comparison. I do understand that there's a little bit of something going on with water-based mammals like orcas and dolphins being able to teach certain skills to their young and so there's a notion of intergenerational knowledge there. But we're just a different order of magnitude in terms of our capability of transmitting intergenerational knowledge and it's not even close. It's almost disappointing because there's no interesting question of comparison between us and other species.As I mentioned in another comment, I'm skeptical of the questions that imply a kind of species essentialism, suggesting that there's such a thing as a one particular trait that distinctly makes us human. I think the real answer to questions like that are vast convergences of immense clusters of facts relating to our evolutionary history and our morphology and so on. I don't think there's any like one single thing. But I do think in comparison to other species a rather elegant way of distinguishing this is to put to our written traditions which as far as I know don't really have any precedent. And if that doesn't blow you away in terms of how miraculous and special are evolutionary trajectory is, I don't suspect anything would. But the important thing is that you don't need a species essentialism to be impressed with who and what we are.\n \nreply",
      "Ants, but that\u2019s a whole other discussion around what constitutes writing.Which is why people look into specific elements of language not just huge generalizations.\n \nreply"
    ],
    "link": "https://www.newscientist.com/article/2474993-bonobos-use-a-kind-of-syntax-once-thought-to-be-unique-to-humans/",
    "first_paragraph": "AdvertisementThe way bonobos combine vocal sounds to create new meanings suggests the evolutionary building blocks of human language are shared with our closest relativesBy Sophie Berdugo\n                                    3 April 2025\n                                                                    A female bonobo at Kokolopori Bonobo Reserve in the Democratic Republic of the CongoLukas Bierhoff, Kokolopori Bonobo Research ProjectA female bonobo at Kokolopori Bonobo Reserve in the Democratic Republic of the CongoLukas Bierhoff, Kokolopori Bonobo Research ProjectBonobos combine their calls in a complex way that forms distinct phrases, a sign that this type of syntax is more evolutionarily ancient than previously thought.Human language, often described as the hallmark of our species, is made up of many different building blocks. One core block is syntax, where meaningful units are combined into longer sequences, like words into sentences. This is made possible through compositionali"
  },
  {
    "title": "Why I Program in Lisp (funcall.blogspot.com)",
    "points": 236,
    "submitter": "ska80",
    "submit_time": "2025-04-11T08:26:14 1744359974",
    "num_comments": 212,
    "comments_url": "https://news.ycombinator.com/item?id=43651576",
    "comments": [
      "Good article. Funnily enough the throw away line \"I don't see parentheses anymore\". Is my greatest deterrent with lisp. It's not the parens persay, it's the fact that I'm used to reading up to down and left to right. Lisp without something like the clojure macro ->, means that I am reading from right to left, bottom to top - from inside out.If i programmed enough in lisp I think my brain would adjust to this, but it's almost like I can't full appreciate the language because it reads in the \"wrong order\".\n \nreply",
      "Been programming in Lisp for a while. The parents disappear very quickly. One trick to accelerate it is to use a good editor with structural editing (e.g., paredit in Emacs or something similar). All you editing is done on balanced expressions. When you type \u201c(\u201c, the editor automatically inserts \u201c)\u201d with your cursor right in between. If you try to delete a \u201c)\u201d, the editor ignores you until you delete everything inside and the \u201c(\u201c. Basically, you start editing at the expression level, not so much at the character or even line level. You just notice the indentation/shape of the code, but you never spend time counting parentheses or trying to balance anything. Everything is balanced all the time and you just write code.\n \nreply",
      "> It's not the parens persay, it's the fact that I'm used to reading up to down and left to right. Lisp without something like the clojure macro ->, means that I am reading from right to left, bottom to top - from inside out.I\u2019m not certain how true that really is.  This:    foo(bar(x), quux(y), z);\n\nlooks pretty much identical to:    (foo (bar x) (quux y) z)\n\nAnd of course if you want to assign them all to variables:    int bar_x = bar(x);\n    char quux_y = quux(y);\n    \n    return foo(bar_x, quux_y, z);\n\nis pretty much the same as:    (let ((bar-x (bar x))\n          (quux-y (quux y)))\n      (foo bar-x quux-y z))\n\nFWIW, \u2018per se\u2019 comes from the Latin for \u2018by itself.\u2019\n \nreply",
      "One of the awesome things about LISP is it encourages a developer to think of programs as an AST[0].One of the things that sucks about LISP is - master it and every programming language is nothing more than an AST[0].:-D0 - https://en.wikipedia.org/wiki/Abstract_syntax_tree\n \nreply",
      "The lisp is harder to read, for me. The first double paren is confusing.    (let (bar-x (bar x))\n         (quux-y (quux y)))\n    (foo bar-x quux-y z)\n\nWhy is the second set of parens necessary?The nesting makes sense to an interpreter, I'm sure, but it doesn't make sense to me.Is each top-level set of parens a 'statement' that executes? Or does everything have to be embedded in a single list?This is all semantics, but for my python-addled brain these are the things I get stuck on.\n \nreply",
      "I am not a Lisp expert by any stretch, but let's clarify a few things:1. Just for the sake of other readers, we agree that the code you quoted does not compile, right?2. `let` is analogous to a scope in other languages (an extra set of {} in C), I like using it to keep my variables in the local scope.3. `let` is structured much like other function calls. Here the first argument is a list of assignments, hence the first double parenthesis (you can declare without assigning,in which case the double parenthesis disappears since it's a list of variables, or `(variable value)` pairs).4. The rest of the `let` arguments can be seen as the body of the scope, you can put any number of statements there. Usually these are function calls, so (func args) and it is parenthesis time again.I get that the parenthesis can get confusing, especially at first. One adjusts quickly though, using proper indentation helps.I mostly know lisp trough guix, and... SKILL, which is a proprietary derivative from Cadence, they added a few things like inline math, SI suffixes (I like that one), and... C \"calling convention\", which I just find weird: the compiler interprets foo(something) as (foo something). As I understand it, this just moves the opening parenthesis before the preceding word prior to evaluation, if there is no space before it.I don't particularly like it, as that messes with my C instincts, respectively when it comes to spotting the scope. I find the syntax more convoluted with it, so harder to parse (not everything is a function, so  parenthesis placement becomes arbitrary):    let( (bar-x(bar(x))\n         quux-y(quux(y)))\n    foo(bar-x quux-y z)\n    )\n \nreply",
      "The let construct in Common Lisp and Scheme supports imperative programming, meaning that you have this:  (let variable-bindings statment1 statement2 ... statementN)\n\nIf statementN is reached and evaluates to completion, then its value(s) will be the result value(s) of let.The variable-bindings occupy one argument position in let. This argument position has to be a list, so we can have multiple variables:  (let (...) ...)\n\nWithin the list we have about two design choices: just interleave the variables and their initializing expressions:  (let (var1 value1\n        var2 value2\n        var3 value3)\n    ...)\n\n\nOr pair them together:  (let ((var1 value1)\n        (var2 value2)\n        (var3 value3)\n    ...)\n\nThere is some value in pairing them together in that if something is missing, you know what. Like where is the error here?  (let (a b c d e) ...)\n\nwe can't tell at a glance which variable is missing its initializer.Another aspect to this is that Common Lisp allows a variable binding to be expressed in three ways:  var\n  (var)\n  (var init-form)\n\nFor instance  (let (i j k (l) (m 9)) ...)\n\nbinds i, j and k to an initial value of nil, and m to 9.Interleaved vars and initforms would make initforms mandatory. Which is not a bad thing.Now suppose we have a form of let which evaluates only one expression (let variable-bindings expr), which is mandatory.   Then there is no ambiguity; we know that the last item is the expr, and everything before that is variables. We can contemplate the following syntax:  (let a 2 b 3 (+ a b)) -> 5\n\nThis is doable with a macro. If you would prefer to write your Lisp code like this, you can have that today and never look back. (Just don't call it let; pick another name like le!)If I have to work with your code, I will grok that instantly and not have any problems.In the wild, I've seen a let1 macro which binds one variable:  (let1 var init-form statement1 statement2 ... statementn)\n \nreply",
      "> Why is the second set of parens necessary?it distinguishes the bindings from the body.strictly speaking there's a more direct translation using `setq` which is more analogous to variable assignment in C/Python than the `let` binding, but `let` is idiomatic in lisps and closures in C/Python aren't really distinguished from functions.\n \nreply",
      "You\u2019re right!    (let (bar-x quux-y)\n      (setq bar-x (bar-x)\n            quux-y (quux y))\n      (foo bar-x quux-y z))\n\nI just wouldn\u2019t normally write it that way.\n \nreply",
      "The code is written the same way it is logically structured. `let` takes 1+ arguments: a set of symbol bindings to values, and 0 or more additional statements which can use those symbols. In the example you are replying to, `bar-x` and `quux-y` are symbols whose values are set to the result of `(bar x)` and `(quux y)`. After the binding statement, additional statements can follow. If the bindings aren't kept together in a `[]` or `()` you can't tell them apart from the code within the `let`.\n \nreply"
    ],
    "link": "http://funcall.blogspot.com/2025/04/why-i-program-in-lisp.html",
    "first_paragraph": "\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Unorthodox opinions on computer science and programming.Lisp is not the most popular language.  It never was.  Other\n  general purpose languages are more popular and ultimately can do\n  everything that Lisp can (if Church and Turing are correct).  They\n  have more libraries and a larger user community than Lisp does.\n  They are more likely to be installed on a machine than Lisp is.Yet I prefer to program in Lisp.  I keep a Lisp REPL open at all\n  times, and I write prototypes and exploratory code in Lisp.  Why do\n  I do this?  Lisp is easier to remember, has fewer limitations and hoops you\n  have to jump through, has lower \u201cfriction\u201d between my\n  thoughts and my program, is easily customizable, and, frankly, more\n  fun.Lisp's dreaded Cambridge Polish notation is uniform and\n  universal.  I don't have to remember whether a form takes curly\n  braces or square brackets or what the operator precedency is or some\n  weird punctuated syntax that was invented for no good reason. "
  },
  {
    "title": "But what if I want a faster horse? (exotext.com)",
    "points": 1192,
    "submitter": "saeedesmaili",
    "submit_time": "2025-04-11T11:39:18 1744371558",
    "num_comments": 528,
    "comments_url": "https://news.ycombinator.com/item?id=43652723",
    "comments": [
      "For any given thing or category of thing, a tiny minority of the human population will be enthusiasts of that thing, but those enthusiasts will have an outsize effect in determining everyone else's taste for that thing. For example, very few people have any real interest in driving a car at 200 MPH, but Ferraris, Lamborghinis and Porsches are widely understood as desirable cars, because the people who are into cars like those marques.If you're designing a consumer-oriented web service like Netflix or Spotify or Instagram, you will probably add in some user analytics service, and use the insights from that analysis to inform future development. However, that analysis will aggregate its results over all your users, and won't pick out the enthusiasts, who will shape discourse and public opinion about your service. Consequently, your results will be dominated by people who don't really have an opinion, and just take whatever they're given.Think about web browsers. The first popular browser was Netscape Navigator; then, Internet Explorer came onto the scene. Mozilla Firefox clawed back a fair chunk of market share, and then Google Chrome came along and ate everyone's lunch. In all of these changes, most of the userbase didn't really care what browser they were using: the change was driven by enthusiasts recommending the latest and greatest to their less-technically-inclined friends and family.So if you develop your product by following your analytics, you'll inevitably converge on something that just shoves content into the faces of an indiscriminating userbase, because that's what the median user of any given service wants. (This isn't to say that most people are tasteless blobs; I think everyone is a connoisseur of something, it's just that for any given individual, that something probably isn't your product.) But who knows - maybe that really is the most profitable way to run a tech business.\n \nreply",
      "\"Shoving content into the faces of an indiscriminating userbase\" maximizes eyeball time which maximizes ad dollars. Netflix's financials are a bit more opaque but I think that's the key driver of the carcinisation story here, the thing for which \"what the median user wants\" is ultimately a proxy.Likewise, all social media converges on one model. Strava, which started out a weirder platform for serious athletes, is now is just an infinity scroll with DMs [0]I do however think that this is an important insight:> This isn't to say that most people are tasteless blobs; I think everyone is a connoisseur of something, it's just that for any given individual, that something probably isn't your product.A lot of these companies probably were founded by people who wanted to cater to connoisseurs, but something about the financials of SaaS companies makes scaling to the ad-maximizing format a kind of destiny.[0] https://www.nytimes.com/2023/12/05/style/strava-messaging.ht...\n \nreply",
      "I think your link is broken (missing the l in html) and should point here: https://www.nytimes.com/2023/12/05/style/strava-messaging.ht...\n \nreply",
      "> \"Shoving content into the faces of an indiscriminating userbase\" maximizes eyeball time which maximizes ad dollarsI mean that's not really the case for paid services without ads like Netflix. They lose money the more you watch. Ideally you'd continue to pay for the subscription but never watch anything.\n \nreply",
      ">Ideally you'd continue to pay for the subscription but never watch anything.There's a good planet money episode about the economy of gyms. Many really want members, not users. But members who never used would (eventually) cancel. So some had massage chairs in reception or free pizza slice tuesdays to keep the people who rarely came to work out feeling like they were still using the gym, forgetting it was just for a slice of pizza...If there's nothing on netflix people will cancel netflix. So you want them to watch a few exclusive shows a year so they feel like they got their money's worth, while not actually costing netflix much.\n \nreply",
      "> So you want them to watch a few exclusive shows a year so they feel like they got their money's worth, while not actually costing netflix much.No, that's not what the strategy is and they're quite open about it - the strategy is to maximize user consumption for every user, because that keeps them subscribed. I think a lot of people think that they use sophisticated analytics and machine learning etc to decide what to greenlight, but they don't. They use the judgment (and politics, and egos) of Hollywood studio executives (and often the same Hollywood execs that a few years ago were employed in \"legacy\" media). Although I will grant that they've been innovative in producing/distributing international content, this is really just globalization and labor arbitrage (it is cheaper produce content not in Hollywood, that's not news - they just spend the extra $$$ localizing international content to different global target distribution markets but again, this flow has happened forever, it's just typically been Hollywood -> localization -> foreign market rather than foreign production -> localization -> Anglophone market).Where analytics and ML does come into play is deciding which things out of their enormous catalogue they push to individual users at any one time - that process is highly reactive, individualized, dynamic - that's why strange and seemingly random media become big hits on Netflix while being largely ignored by the commentariat, and vice versa, why series with dedicated fanbases don't get renewed (the analytics tell you that, despite the apparent success, further investment will not improve user engagement with the platform by enough to be worth the spend).\n \nreply",
      "There were people who only had HBO subscriptions to watch the new season of Westworld. Given they merged with Cinemax I\u2019m not sure if that worked out for them. But there were also Apple+ subscriptions just to watch Ted Lasso. And I begrudgingly got Prime to watch the Expanse.But when I bought the full seasons it was from Apple. I\u2019m sure Bezos still ended up with most of that money but at least some of it went to Apple instead.\n \nreply",
      "> Ideally you'd continue to pay for the subscription but never watch anything.I think that\u2019s Netflix\u2019s actual goal: deliver nothing anyone wants to watch, but keep on promising the possibility of something one might want to watch in the future.Which reminds me, we really need to cancel our subscriptions.\n \nreply",
      "We immediately cancel our subscription as soon as we subscribe for services like Netflix, Disney+ etc, where you keep the service for the month. It's thankfully really easy to susbcribe and unsubscribe these days, so doing it this way means we never unknowingly renew. Must have saved us hundreds of pounds by now.\n \nreply",
      "Same here. I never subscribed to Netflix or Disney+ for the intended purpose of continually paying for it in perpetuity - it was always to watch the one show I want (in <1mo) and then immediately kill it.\n \nreply"
    ],
    "link": "https://rakhim.exotext.com/but-what-if-i-really-want-a-faster-horse",
    "first_paragraph": ""
  },
  {
    "title": "Pinball Brothers \u00e2\u20ac\u201c A Swedish-Italian Pinball Company (pinballbrothers.com)",
    "points": 3,
    "submitter": "Tommix11",
    "submit_time": "2025-04-09T05:29:59 1744176599",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43629158",
    "comments": [
      "Those are cool machines, but I think their website would be better if they focused on that instead of making you click several times to see them.\n \nreply",
      "I had no idea they existed until this morning. They are sadly being hit hard by tariffs as reported by Swedish media.\n \nreply"
    ],
    "link": "https://www.pinballbrothers.com/",
    "first_paragraph": ""
  },
  {
    "title": "Vacheron Constantin breaks the world record for most complicated wristwatch (hodinkee.com)",
    "points": 51,
    "submitter": "bookofjoe",
    "submit_time": "2025-04-11T22:26:41 1744410401",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=43659365",
    "comments": [
      "I\u2019ve never heard of this company but according to the video below, they\u2019re large enough to have a huge building.How do these economics work? I\u2019m guessing they\u2019re a maker of very expensive low volume products. But are there that many buyers?https://www.hodinkee.com/articles/video-vacheron-constantin-...Same with Richard Mille. Never heard of them but they\u2019re rich enough to sponsor the Ferrari F1 team.\n \nreply",
      "They are both extremely well-known luxury watch manufacturers. The fact that you haven\u2019t heard of them has nothing to do with them, it just means you\u2019re not into luxury watches.\n \nreply",
      "To give you an idea of margins:- A real Rolex dive watch costs $5k-15k.- A similar Swiss-made dive watch from\n a less famous brand costs $2k-4k.- A similar Japanese-made dive watch from a famous brand costs $500-1000.- A Chinese-made replica/fake Rolex, mechanically identical to a real one, and only distinguishable by an expert under high magnification, costs about $400-800.- There are some low-volume watches that are sold for 4-6 figure sums to repeat buyers. Richard Mille in particular has done one-offs for celebrities in the range of 7-8 figures.As you can imagine you don't need a high volume with margins that large.\n \nreply",
      "Richard Mille is well known to anyone interested in watches, especially very rich people. You probably haven\u2019t heard of Jacob & Co? Or maybe you\u2019ve heard of Hublot? It\u2019s the same story with Loro Piana when it comes to clothing, and Koenigsegg or Pagani when it comes to cars.In certain circles, all of these brands are as common as Nike or Mercedes are to the general public.\n \nreply",
      "If you're interested in the functioning of mechanical watches, they're amazing:https://ciechanow.ski/mechanical-watch/Previously on HN in 2022: https://news.ycombinator.com/item?id=31261533\n \nreply",
      "Thanks! Macroexpanded:Mechanical Watch (2022) - https://news.ycombinator.com/item?id=38591084 - Dec 2023 (163 comments)Mechanical Watch - https://news.ycombinator.com/item?id=31749299 - June 2022 (1 comment)Mechanical Watch - https://news.ycombinator.com/item?id=31261533 - May 2022 (413 comments)\n \nreply",
      "There's also a neat one about the process of making mechanical watches,https://watchesbysjx.com/2017/05/portrait-masahiro-kikuno-ja... (\"Masahiro Kikuno, Japanese Independent Watchmaker\")https://news.ycombinator.com/item?id=14610110 (108 comments)https://news.ycombinator.com/item?id=19011880 (98 comments)\n \nreply",
      "If only my software were valued by number of complications...Everything about the high end \"movement\" scene rubs me the wrong way (I had a friend into it), but most of all, the pompous terminology.\n \nreply",
      "in the B2B SAAS world these are called \"features\" or \"integrations\".Software with the most integrations and features is usually ends up being the most preferred solution\n \nreply",
      "software does have tail recursion.This might be more like wrist recursion.EDIT: I wonder if a nixie wristwatch would be a middle ground?\n \nreply"
    ],
    "link": "https://www.hodinkee.com/articles/introducing-vacheron-constantin-les-cabinotiers-solaria",
    "first_paragraph": "\n        The fastest and most secure way to protect the watches and jewelry you love.\n      \n        We've minimized the paperwork and maximized protection, so you can stop worrying about your watches and jewelry and focus on enjoying them.\n      \n        In most cases, you'll get a personalized quote in seconds and your policy kicks in immediately.\n      \n        Wherever you are on planet Earth, your watches and jewelry are protected. Rest easy and travel safely.\n      \n        If you suffer a covered loss, there's no deductible and no gimmicks. Ever.\n      \n        Each of your watches and jewelry is covered up to 150% of the insured value (up to the total value of the policy).\n      \n          The fastest and most secure way to protect the watches and jewelry you love.\n        \n          We've minimized the paperwork and maximized protection, so you can stop worrying about your watches and jewelry and focus on enjoying them.\n        \n            In most cases, you'll get a personal"
  }
]