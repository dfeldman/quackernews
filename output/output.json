[
  {
    "title": "Ten Years of JSON Web Token and Preparing for the Future (self-issued.info)",
    "points": 59,
    "submitter": "mooreds",
    "submit_time": "2025-05-25T23:05:36 1748214336",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44092102",
    "comments": [
      "I love JWTs between servers. Between servers and clients, you just end up remaking cookies/sessions. Strictly my experience/opinion. Glad to hear from others.\n \nreply",
      "Cookies are only controlled by the server but obviously can be negotiated for with a secret.  JWTs have a mutual secret component built in and far cooler sounding ... stuff.  So both ends have to trust the other and prove it with JWT and when cookies are in play, you takes your chances - you can use mutual TLS to get the same trust that JWT gives.I have a web app that I'm doing sysops for which ended up with both.  The web devs insisted on JWT and cough \"forgot\" about the auth bearer bit in the header because their API didn't use it.  I ended up amending and recompiling an Apache module for that but to be fair, they will support it in the next version so I can revert my changes.  A few db lookups in the Apache proxy JWT module I'm using and you have your claims.On the front of that lot you have Apache session cookies generated when auth succeeds against a PrivacyIDEA instance - ie MFA.I suppose we have cookies for authN and JWT for authZ.  Cookies could do both and apart from session I'm not too familiar but it looks like claims would require multiple cookies where JWT does it all in one.\n \nreply",
      "you cant generally reuse cookies across domains, because browser controls which domain receive which cookie. Also cookies are not cryptographically signed and thus easily forgeable by the client/browser.JWTs on the other hand allow to be used across domain, so that you can use JWT issued by your IDP on one domain, to be trusted on another domain. crypto signature helps in verifying integrity of data.sessions are usually tied to a single backend/application server. Its hard to reuse a session data across different apps.JWTs on the other hand allow sharing session data across different app servers/microservices.\n \nreply",
      "\"Also cookies are not cryptographically signed and thus easily forgeable by the client/browser.\"My Apache webby thingies quite happily dole out encrypted cookies:https://httpd.apache.org/docs/2.4/mod/mod_session_crypto.htm...Your notes on cross site issues are also described there.JWTs are mutually shared secret passable with nobs on - you can store loads of data in them.  Cookies are more one shot and one piece of data.\n \nreply",
      "> It\u2019s often said that one sign of a standard having succeeded is that it\u2019s used for things that the inventors never imagined.It's certainly a sign of something's utility and versatility, for sure. Congrats.\n \nreply",
      "If you go back and search hacker news for any article involving JWTs or OAuth you\u2019ll find hundreds of comments of circular arguments over what a JWT is and is not. People never seem to be able to separate the two.\n \nreply",
      "I still don't really understand them. The last time I used them was for a client probably in 2016 or 2018, and I forgot everything I learned about them. But they have an RFC so that's pretty cool.\n \nreply"
    ],
    "link": "https://self-issued.info/?p=2708",
    "first_paragraph": "By Mike JonesOn May 25, 2025In Claims, Cryptography, IETF, JSON, OAuth, OpenID, SpecificationsTen years ago this week, in May 2015, the JSON Web Token (JWT) became RFC 7519.  This was the culmination of a 4.5 year journey to create a simple JSON-based security token format and underlying JSON-based cryptographic standards.  The full set of RFCs published together was:It\u2019s certainly the case that we co-designed JWT and its underpinnings with OpenID Connect, while also attempting to create general-purpose, widely useful standards.  Given the adoption that\u2019s ensued, it seems that we succeeded.As I wrote in my post JWTs helping combat fraudulent and unwanted telephone calls, \u201cIt\u2019s often said that one sign of a standard having succeeded is that it\u2019s used for things that the inventors never imagined.\u201d  I\u2019m gratified that this applies to JWT and the related specifications.  As was written in the post Essential Moments in the OAuth and OpenID Connect Timeline, it\u2019s now hard to imagine an onlin"
  },
  {
    "title": "Open Source Society University \u2013 Path to a free self-taught education in CS (github.com/ossu)",
    "points": 189,
    "submitter": "saikatsg",
    "submit_time": "2025-05-25T17:06:55 1748192815",
    "num_comments": 86,
    "comments_url": "https://news.ycombinator.com/item?id=44089150",
    "comments": [
      "You can definitely make the self-taught path work. I'm proof of that and have been working in industry for over 20 years. However, what I will say is the following: there are certain companies and roles which you will never be able to access. These are often times the best roles, best companies, have the most money, etc. A degree isn't just the time spent studying and knowledge -- you can do that part yourself. What's more valuable is the network and access to the alumni network of others who will hire you into their company just because you went to the same school as them. It's a big club and you won't be in it if you decide to self-study. That's the cold, hard truth.So what's left for someone self-taught with no degree? You are left with all the jobs the others don't want. You'll be flipping through the crazies, outright scams, poorly capitalized companies, or places that are already in a state of distress. VERY rarely you will find a real job that you can plan to stay at for any length of time. You WILL be paid less, and you're more likely to get taken advantage of. You will have a harder time getting multiple offers at once, because your overall demand is lower. So that erodes your position in the market and over time it will feel like you're on a completely different tract financially. You will need to work twice as hard, because finding a new job is much harder, even if you're good. You will constantly be doubted, by first yourself and imposter syndrome and next by those around you who have degrees. Make one mistake and the consequences are that much more dire.It's better than nothing, but if you have the opportunity to go to school (I didn't), do it over the self-taught route.\n \nreply",
      "I don\u2019t mean to discount your personal experience, but I\u2019m 100% self taught, and I\u2019ve worked at some bougie megacorps, unicorns and startups of varying degrees of maturity.I\u2019ve never felt like doors have been closed or that others doubt me because of my lack of education. I\u2019ve interviewed at Google and Citadel, had an offer from Meta, etc. It doesn\u2019t feel like anyone has denied me opportunities outright.I make north of $200k/year cash plus the equity and perks at an early stage startup. I\u2019ve been through two exits so far. Nothing outrageous but I\u2019m rich by most peoples standards. It doesn\u2019t feel like lack of schooling has impacted me financially.I did start programming and doing the startup thing at 19, so maybe the early start was an advantage. I could just be mind numbing lucky. But, from my point of view, warning the up and coming youngin\u2019s off the self taught path is a disservice.\n \nreply",
      "> from my point of view, warning the up and coming youngin\u2019s off the self taught path is a disservice.Hard disagree on this. It\u2019s true there are a lot of successful people in the industry with no degree, or (like myself) with a non-CS degree. And I agree with you that the OP\u2019s claim that there\u2019s a ceiling for those people is overstated. But just because it was possible to have a successful start in the industry 10 or 20 years ago that way doesn\u2019t mean it\u2019s good advice now to tell 18 year olds that skipping the degree and self studying is a good idea. The job market is exceptionally tough currently for entry level engineers and not likely to get better, due to the end of ZIRP and AI productivity gains. Companies who have that rare entry-level position open can take their pick from a large pool of candidates. They will naturally prioritize people with a CS degree from a top school because without previous work experience that is the best signal they have to sort the deluge of resumes.I still think software engineering is a good career choice for a smart kid, but it\u2019s not the magic ride to prosperity it was 10 years ago. I would hesitate now to recommend any path into it except the top-school CS degree route. Sure, there will be exceptions, but you will have a vastly easier time if you follow that path.\n \nreply",
      "> due to the end of ZIRP and AI productivity gains.I think you're missing the mark with this analysis.If you go back to the original dot com bubble it was as much of a hardware bubble as a software one. Same thing with the mobile bubble. The AI bubble we are in has NOTHING to do with productivity and everything to do with hardware.  I, as a software engineer am not going to come up with a product that can compete with any of the major players without a massive capital investment.Meanwhile, the price to play as a software engineer is also driven by high costs. AWS, for better or worse is the model and the go to, and it is NOT cheap by any measure. Its pricing model looks more like the iPhone and less like an efficient market. AWS is MOST of amazons profit margins. It makes tech companies more like franchisee renting the location for their fast food joint and less like independent entities.The thing is there are TONS of gaps in the software marketplace that need filled. These are companies that are going to be in the 2-3 million a year range and capable of being run by a small team (think ~5 people). Nothing that would appeal to the ycombinator set. You don't need Kubernetes, Kafka, or high performance bleeding edge Rust or massive Autoscaling to run these services. They are never going to get huge, and in fact they offer enough room to start another company of the same scale if one is ambitious and wants to diversify.Does your average 18 year old know this? No, because most people who write code for a living don't seem to know where these gaps are. Do the math on what it takes to make 100k a year at 10 bucks a month... add a zero for a million, multiply by 3 for \"small team\"... The number is shockingly small.Does your average 19 year old have the chops to figure this out? No, because 20 and 30 something laid off software engineers can't seem to figure it out either, even ones with \"top degrees\".That doesn't mean that there isn't a path for the sharp young kid to \"skip school\" and go directly into industry. That path is open source. A history of strong contributions and being smart is going to build a better network than any CS degree ever would/will... However if you can do both, open source and a degree (from anyplace) you're even better off! The same could be said for working at Fedex, Walmart or Costco while you get a cs degree from anyplace and seeking a job in a corporate office after. You have a set of experiences that make you invaluable as a contributor.Lastly, no one talks about the bad guys. There are plenty of scammers and thieves abusing technical skills who lack formal education and do well for themselves. If we're going to remove all the options and only have a narrow path, will we end up with more criminals and fewer contributors? This is sort of why \"Russian hackers\" is one of the givens in the industry (crime did/does pay well).I still think software engineering is a good career choice for a smart kid, but you have to bring more to the table than just code if you want to prosper!\n \nreply",
      "As a somewhat accomplished self taught outlier as well, my perspective is slightly different.While it's absolutely possible to no have a degree and succeed in megacorp, don't discount the randomness (luck) involved in getting the right experience and meeting the right people at the right time of your career (and aligning with market demands).Please don't hear this as \"you didn't work hard to get to where you are\". I certainly believe that folks like us, self taught, are able to work hard and teach ourselves what's needed to get to the next level because we cannot rely on credentials to carry us. A lot of things still need to go right for us to be successful, more so than folks with formal education, especially in the early stages of our careers.\n \nreply",
      "Perhaps in the US 20 years ago it was more attainable. Self taught in the UK is pretty tough, I lucked out getting a real engineering job at 19 in London, then I went into contracting which was great money. Now I\u2019m working at a startup which I think has a solid team, but even with a decade+ of experience I\u2019ve never even gotten a call back for roles at Google, Meta or the like.Did interview with apple once for a low rate contracting role, pretty sure I gave them a superior architecture for their solution in the interview and they took it and ran with it, didn\u2019t hear back.I\u2019ve had a heavy interest in finance since a young teenager but haven\u2019t really be able to land an interview there either.I\u2019m genuinely considering getting a degree, I guess at 28 it\u2019s not too late, though I feel I\u2019ve wasted a lot of time.\n \nreply",
      "I know friends in a similar boat.Ultimately you can get very far if you are naturally talented technically and socially.But if you are normal like most of us, you are lacking in one or more areas and going to school (or attending conferences or maintaining a popular resource) can be one of those ways to shore up one of your \u201cless natural\u201d skills, but no step is strictly required and not everything works for everyone.\n \nreply",
      "Indeed, going to school for a degree in a programming related field (Computer Science, Computer Engineering, Software Development; whatever) is also much more likely to leave you with a broad knowledge about topics in the field (different algorithms, things worth considering when developing code/architecture, etc). Yes, you can achieve that same level of knowledge with self-study, but a lot of (most) people won't; because it requires going above and beyond for most self-study \"curriculum\".\"But if you are normal like most of us\", you'll wind up a more well rounded developer with a college education.\n \nreply",
      "\u201cThe Federal Reserve Bank of New York released data on unemployment rates for recent college graduates (ages 22 to 27).\nThe bank found that philosophy had an unemployment rate of 3.2%, less than computer science\u2019s 6.1%, though computer science was more highly compensated.\u201dhttps://www.entrepreneur.com/business-news/college-majors-wi...\n \nreply",
      "Unemployment vs underemployment I believe is the missing item here.https://www.newyorkfed.org/research/college-labor-market#--:... - this is the source, and has both unemployment and underemployment.CS has a 6.1% unemployment rate and a 16.5% underemployment rate.Philosophy has is at 3.2% unemployment and a 41.2% underemployment rate.The philosophy major doesn't have their sights set on a $150k new grad salary at a big tech company out of college.  They're flipping burgers or working as a business person somewhere.This can be seen on various reddit computer science related career advice spots where people are holding out for the perfect software development job for years rather than getting a job somewhere.  They're sending out (poorly crafted) resumes by the hundreds to jobs that their resume gives no indication that they're qualified for (or even read the posting) and ignoring the \"we want to hire someone with some work ethic - bagging groceries and having a supervisor who can say that 'yes, Pat shows up on time each day sober'\" is something is useful.They're refusing to consider help desk roles - and when they do apply for those roles, its with a resume that points out how they're skilled at JavaScript and have published a module to npm.They're refusing to apply to the job at state government that lists $650,000 - $80,000 for entry level position because that's not the job they saw themselves getting.The CS majors are holding out and not getting jobs that are \"beneath\" them.  The philosophy majors are getting any job that pays the bills.\n \nreply"
    ],
    "link": "https://github.com/ossu/computer-science",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83c\udf93 Path to a free self-taught education in Computer Science!\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n  Path to a free self-taught education in Computer Science!\n\n\n\n\n\nThe OSSU curriculum is a complete education in computer science using online materials.\nIt's not merely for career training or professional development.\nIt's for those who want a proper, well-rounded grounding in concepts fundamental to all computing disciplines,\nand for those who have the discipline, will, and (most importantly!) good habits to obtain this education largely on their own,\nbut with support from a worldwide community of fellow learners.It is designed according to the degree requirements of undergraduate computer science majors, minus general education (non-CS) requirements"
  },
  {
    "title": "Plwm \u2013 An X11 window manager written in Prolog (github.com/seeker04)",
    "points": 144,
    "submitter": "jedeusus",
    "submit_time": "2025-05-25T17:41:11 1748194871",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=44089424",
    "comments": [
      "Does someone know a tutorial or something which explains how to get from \"tutorial Prolog\" to \"real project Prolog\", because that's not look anything like tutorial Prolog.Prolog seems interesting, but any time I tried to do anything more than toy examples on my own, I got infinite recursion, unsolvable problems.\n \nreply",
      "I played with Prolog just a little long time ago, and I can't shake off the feeling that Prolog is basically a prank that went too far to be stopped. It requires a way of thinking that is compatible with neither how computers work, nor how maths works.\n \nreply",
      "But it sort of is maths.\n \nreply",
      "I'm hoping one day someone will write a window-manager service for Wayland that replaces the compositor API with a protocol. To once again enable window managers to be implemented in any language, regardless of it having a Wayland/compositor library.\n \nreply",
      "I wish more things were protocols instead of APIs.\n \nreply",
      "Could you explain the difference?\n \nreply",
      "A protocol defines a set of primitives and their interactions, along with prescriptions where necessary, but is otherwise pretty loose generally. Especially in a Postels law world. APIs tend to be highly prescriptive with a highly specific interface and a lot of black box.Think of the difference between an IETF RFC on say SMTP vs an email API - the RFC describes how clients and servers for mail routing interact through an almost dialog, while a typical email API has highly structured interfaces.  Another wat to cut it is an API can be tested as it has inputs and return values dependent on those, while a protocol you can generally only assert compliance with the specification of the protocol.People often assert protocols have something to so with RPC of some sort but that\u2019s not true. Many language support protocols, which can be very similar to interfaces, but don\u2019t have anything to do with OOP, etc. In language protocols it\u2019s slightly different than network/IPC protocols but the intent is similar.\n \nreply",
      "They're both poorly defined, but what I think GP meant is they want something that you use something like a socket instead of FFI to interface with. You need an extra data description layer for a 'protocol' in this context because you can't rely on something like the C data model and calling convention as a given.\n \nreply",
      "I'm not the most knowledgeable, but a protocol talks to another process through a specific format.I personally think its more powerful than writing a new process to replace and existing.My favorite example is an X11 windows manager implementing in about 18 lines of python.Obviously there's dependencies to talk to the X server, but the power of a protocol comes from any program written in any la gage communicate with existing code.\n \nreply",
      "A protocol is like the line at Subway where an api is a bar & restaurant.\n \nreply"
    ],
    "link": "https://github.com/Seeker04/plwm",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An X11 window manager written in Prolog\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\nTable of Contentsplwm is a highly customizable X11 dynamic tiling window manager written in Prolog.Main goals of the project are: high code & documentation quality; powerful yet easy customization; covering most common needs of tiling WM users; and to stay small, easy to use and hack on.Powered by SWI-PrologDependencies:On Ubuntu 22.04, easiest way to install them is:$ sudo apt install xorg-dev swi-prologRun:$ make && sudo make installBy default, this will install plwm to /usr/local/bin/. The location can be adjusted in the Makefile.Add the following line to the end of your ~/.xinitrc:exec plwmThen simply use the command startx in tty.For example, to automate this after"
  },
  {
    "title": "Lottie is an open format for animated vector graphics (lottie.github.io)",
    "points": 250,
    "submitter": "marcodiego",
    "submit_time": "2025-05-25T14:45:47 1748184347",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=44088216",
    "comments": [
      "Lottie for me is sadness.I love the idea, it's really cool that you can generate the animations from what animators already use, but boy, the implementation of it is very disappointing.The format is probably one of the worst choices they could do for a use case like this - it's JSON, for something that is usually a bunch of numbers and perfect fit for more compact binary format. This JSON can reference external files, so the animation is  either- a folder with bunch of files (sub pictures)\\- or those files are inlined in the JSON as base64- or it's just a single file, which turns out to be a zipped folder of this amalgamation.If you imagine loading this on the web, you have to load absolutely enormous SDK (which is not very actively maintained and isn't very well size optimized), and then loading the animation either means loading a bunch of files separately, or loading a single file but processing it through multiple different parsers in multiple passes (JSON, base64, png, lottie, zip). If you use the .lottie file, you have to include zip decompresser in the JS bundle (.lottie player, which is a different library, also uses 2MB wasm blob, not sure why).It took me a while to squash the footprint of this craziness in our app and I'm glad we don't use it in a hot path, because this is just crazy - it's  supposed to be this little cherry on top for special occasions, but it's by far the heaviest part of the codebase. I had to manually tweak tose animations, run them through some optimizers, fixup weird path and inlining issues, fixed issue with those exporters turning vectors to png, all sorts of stuff.On top of that, the browser doesn't survive playing more than a few of them reliably at the same time (especially on lower end devices), because turns out (who would have guessed?) - animating stuff with JS and DOM is not quite performant.I kinda want to try a weekend project to turn these into optimized svg sprites and try to play them with a CSS transision, see if this makes it more bearable.\n \nreply",
      "100% what you said. One thing I ran into as well was that horrid after effects -> Lottie workflow. Many layers and styles also just don\u2019t work when you export them, so you have to explain to motion designers which features they\u2019re allowed to use and which they aren\u2019t, which a lot of time they\u2019re not thrilled about.In many cases just rendering a video and binding playback to interaction is much more lightweight and less work-intensive than using Lottie.I\u2019ve heard about Rive before and a lot of the choices they make seem to be exact fixes for the issue of Lottie. I haven\u2019t worked with it yet however, so YMMV.\n \nreply",
      "I haven't worked with Rive either, but those I've known who did have seemed pretty over the moon about it, fwiw.\n \nreply",
      "Rive players are open source, so I assume the format is too?\n \nreply",
      "Nice! Had no idea it was open source\n \nreply",
      "Yes, so is the runtime and the renderer (per their website)\n \nreply",
      "Or worse! You get handed off something unrealistic that won\u2019t compile to lottie but \u201cclient has signed off\u201d\n \nreply",
      "I worked in a company, where webapp bundle was 8 megs (so close to 2 megs compressed). Upon brief investigation turned out that it was lottie library (~2 megs) + 4 animations, all of which were shown only to first time users.Managed to get rid of two animations, and put another two together with lottie thing istelf into lazy loading. Still, I consider that battle lost rather than won, because I couldn't really convince the designer or other developer why having 8 megs for a bundle is a bad thing.\n \nreply",
      "the browser doesn't survive playing more than a few of them reliably at the same timeIn contrast, around the turn of the century there were plenty of webpages stuffed full of annoying animated Flash ads, which as irritating as they were, managed to work well enough on the typical single-core CPU of the time.\n \nreply",
      "Even in the mid-2000s, when most PCs had 512MB - 1GB RAM, you could build complex 3D animations in Flash that ran flawlessly across multiple browser engines including IE6, with nothing more than a plugin.\n \nreply"
    ],
    "link": "https://lottie.github.io/",
    "first_paragraph": "Lottie animations are typically created using Adobe After Effects, and they can include complex animations, motion graphics, and interactive elements. Once an animation is created, it can be exported as a Lottie JSON file. This JSON file contains all the information needed to recreate the animation, including keyframes, easing curves, and layer information.Vector Graphics are resolution-independent images created from geometric shapes like curves and lines rather than a grid of pixelsTweening is the process of animating graphics where the animator defines shape properties at specific keyframes and the frames between those are interpolated automatically.A mature and robust ecosystem of players, creation tools, libraries and free assets. Trusted and used by thousands of companies to enrich their user experience.Lottie is an open standard based on the JSON format, allowing for ease of transfer over the web and manipulation with existing tools.Lottie Animation Community (LAC), a non-profit"
  },
  {
    "title": "Ask HN: What are you working on? (May 2025)",
    "points": 122,
    "submitter": "david927",
    "submit_time": "2025-05-25T19:36:58 1748201818",
    "num_comments": 377,
    "comments_url": "https://news.ycombinator.com/item?id=44090387",
    "comments": [
      "I'm working on Finzz; I like investing but was struggling with doom-scrolling across various platforms to find things that were relevant to me. So I created Finzz which on-demand creates a multi host audio podcasts focused specifically on my stock portfolio and investment goals. I tell it the reasons behind why I hold these stocks and it tries to keep me honest to these goals and suggest rough actions from time to time.https://finzz.xyzHere's a sample if you are wondering what its like:\nhttps://finzz.xyz/shared/rnl-oO955IPZN6Ux78E-l8DC\n \nreply",
      "An open-source, self-hostable app for sending out newsletter to your friends and families. I'm mostly making it for myself because I want to share what I've been up to and family photos, without uploading it to Facebook or whatnot.At the moment, the flow goes like this:1. During the week, write posts for things that have happened.2. Posts can be assigned to groups. (family, friends etc).3. At the end of the week (or month), the app automatically creates a newsletter for each group by pulling posts assigned to each group. Add some final touches yourself and send it off!4. Every newsletter will come with a link to download all images.I'm trying to design it to be as old people friendly as possible which meant making the experience as simple as it can get. This made me settle on email newsletters. Emails are ubiquitous, have been around and will be around for a while. It's easy to sign up and things are just pushed to you instead of having to go to another app.Another thing I want is multilingual support as my family is Korean my in-laws are not.I'm hoping to get an MVP working this week and get some testing done with my own parents and in-laws.\n \nreply",
      "Are you self-hosting the email?\n \nreply",
      "No, it will have to be a third-party provider. Currently using Amazon SES, but will be easy to replace with another email provider.\n \nreply",
      "I've been working on an offheap allocator for Go.In contrast to the popular arena based allocators (which target quickly allocating/freeing short lived per-request allocations), I am targeting an allocator for build very large in-memory dbs or caches with almost no garbage collection cost.There's a little no-gc string interner package in there as well.https://github.com/fmstephe/memorymanagerIt's somewhat on pause right now as I have just started a new job. (but it's a very fun project, nerdy joy)\n \nreply",
      "I've been working on a programing language to read and write Excel spreadsheets.\nOr more accurately I've been writing a custom programming language and porting my library to it, so I can transpile it out to other languages.Currently it is being transpiled to C++ and C#https://github.com/NumberDuck/NumberDuck-CPlusPlushttps://github.com/NumberDuck/NumberDuck-CSharp\n \nreply",
      "I recently quit my salary job after 16 years and am consulting in nuclear engineering now. I have a few passion projects that I'm working on (between the somewhat substantial consulting work that came out of the woodwork):- Nuclear Reactor Starter Kit --- an open source set of procedures, processes, templates, and maybe even some IT advice that should help newcomers start companies with nuclear quality assurance programs easily and quickly while also making a new format in which nuclear companies can share lessons learned in efficiency.- Reactor Database --- similar to the iaeas PRIS but focused on reactor development rather than power reactors. Will include nuclear startup company tracking with details gleaned from statements and maybe extrapolated where necessary from simple simulations. Will include things like fuel cost and licensing progress. This way people can more easily separate vaporware from real nuclear, and keep track of promises vs delivery.\n \nreply",
      "Very nice! I ejected from the nuclear industry almost a decade ago and have played around in Healthcare/IoT/Oil&Gas/Finance software tech, but I'd love to figure out how to apply these skills to nuclear energy somehow.Also - love whatisnuclear.com!  About 10 years ago, I tried my hand at creating a generalized JS-based viz system (see examples in https://github.com/ahd985/ssv), but could never figure out a market/path forward for it.\n \nreply",
      "Sounds very interesting! How did you get into this industry initially?\n \nreply",
      "I wanted to do energy stuff and happened to be at a college that had a nuclear engineering dept. The peer advisor told me to take a class in the dept and I loved it.\n \nreply"
    ],
    "link": "item?id=44090387",
    "first_paragraph": ""
  },
  {
    "title": "Choose tools that make you happy (borretti.me)",
    "points": 27,
    "submitter": "zdw",
    "submit_time": "2025-05-22T05:24:56 1747891496",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44059023",
    "comments": [
      "I just like to use simple tools I understand where I can extend anytimes I like instead of tools that's complex and always morphing whether I like it to or not. Most tools brings in a new thing I may like, while reinventing 95% of things I already use. A truly lateral tool that just bring in something new and useful is rare (LSP in text editors). And  most of these are protocol based instead of feature based.\n \nreply",
      "> The general form being: why Obscure Thing is better than Popular Thing. And always the justification is purportedly rational and technical. And always, always, it is complete sophistry.Is the author scoping the piece, to say that this piece is speaking only of the subset of posts claiming obscure-thing-better-than-popular-thing that are sophistry?Or is the author asserting that all posts claiming obscure-thing-better-than-popular-thing are sophistry?\n \nreply",
      "My interpretation is that as engineers, we attempt to justify all of our choices through purely rational means. However, as humans, we cannot really make said choices without also being at least somewhat influenced by our subjective affections.Perhaps I'm stretching the author's message, but at least I believe that the argument extends to all engineering conclusions. The author's call is that we acknowledge this subjective side.Essentially, true engineering is about tradeoffs, there is no X that is objectively better than Y in all circumstances and contexts.\n \nreply",
      "I'm describing the set of posts that jointly satisfy:- The thesis is \"tool X is superior to (Y, Z, ...)\" or \"X is a modern/practical choice\".- The argument is purported to be technical and rational.- The arguments are fallacious and do not stand to rational scrutiny.Where you can reasonably think that the author's actual reasons are affective, and they are trying to make rational arguments by backward-chaining from the conclusion and failing.\n \nreply",
      "As with most things, there is a happy medium here. Ditching poetry for the new and shiny uv made my day-to-day experience an order of magnitude better, especially because I had to introduce Python to an existing monorepo. Being able to inline dependencies as Python comments made it possible for a completely non-technical person at my company to run an AI-generated script that used Pandas with just one CLI command. Had we picked poetry, I would have to spend half a day setting up a proper Python environment on his machine.You can also go too far and pick a JS web framework with 17 users that hasn't been battle-tested in production. You'll then waste time solving problems that have already been solved by users of React/Vue/Svelte instead of shipping working code.\n \nreply",
      "> Emacs is a Gnostic cult. And you know what? That\u2019s fine. In fact, it\u2019s great. It makes you happy, what else is needed? You are allowed to use weird, obscure, inconvenient, obsolescent, undead things if it makes you happy. We are all going to die.There\u2019s a handful of things like Emacs and APL/J/K that HN introduced to me a decade ago that actively reduce my productivity \u2014 and I don\u2019t need your explanations for how I\u2019m using them wrong. They\u2019re, to me, like a good book I\u2019ve already read but keep rereading in-place of books I haven\u2019t read. The reduced productivity is fine because we\u2019re some unknown time away from nuclear war or falling down the stairs.\n \nreply",
      "Letting software engineers use their favourite tools, even if those tools are suboptimal, is a way to make your engineers happier without paying them anymore.it may cost you more in slower development times.\n \nreply"
    ],
    "link": "https://borretti.me/article/you-can-choose-tools-that-make-you-happy",
    "first_paragraph": "On Hacker News and Lobsters I often see blog posts with titles like:The general form being: why Obscure Thing is better than Popular Thing. And always the justification is purportedly rational and technical. And always, always, it is complete sophistry. Why?Because people make technical decisions, in part, for affective reasons. They choose a technology because it feels good, or comfortable, or because it\u2019s what they know. They choose obscure tech as a form of sympathetic magic, like the guy who uses NetBSD on a ThinkPad to feel like a William Gibson protagonist. They choose obsolete languages, like Lisp or Smalltalk, because they think of the heroic age of Xerox PARC, and they want to feel connected to that tradition. They find tools whose vibes align with theirs: Ada says \u201cslow, conservative, baroque\u201d while Rust says \u201cfast-paced, unproven, parvenu\u201d. They use Emacs because they read that Neal Stephenson essay and they feel VS Code is for normies and Emacs is Gnostic.But many people ca"
  },
  {
    "title": "Chomsky on what ChatGPT is good for (2023) (chomsky.info)",
    "points": 127,
    "submitter": "mef",
    "submit_time": "2025-05-25T17:07:58 1748192878",
    "num_comments": 167,
    "comments_url": "https://news.ycombinator.com/item?id=44089156",
    "comments": [
      "The level of intellectual engagement with Chomsky's ideas in the comments here is shockingly low. Surely, we are capable of holding these two thoughts: one, that the facility of LLMs is fantastic and useful, and two, that the major breakthroughs of AI this decade have not, at least so far, substantially deepened our understanding of our own intelligence and its constitution.That may change, particularly if the intelligence of LLMs proves to be analogous to our own in some deep way\u2014a point that is still very much undecided. However, if the similarities are there, so is the potential for knowledge. We have a complete mechanical understanding of LLMs and can pry apart their structure, which we cannot yet do with the brain. And some of the smartest people in the world are engaged in making LLMs smaller and more efficient; it seems possible that the push for miniaturization will rediscover some tricks also discovered by the blind watchmaker. But these things are not a given.\n \nreply",
      "As much as I think of Chomsky - his linguistics approach is outside looking in, ie observational speculation compared to the last few years of LLM based tokenization semantic spaces, embedding, deep learning and mechanistic interpretation, ie:Understanding Linguistics before LLMs:\u201cWe think Birds fly by flapping their wings\u201dUnderstanding Linguistics Theories after  LLMs:\u201cUnderstanding the physics of Aerofoils and Bernoulli\u2019s principle  mean we can replicate what birds do\u201d\n \nreply",
      "The fact that we have figured out how to translate language into something a computer can \"understand\" should thrill linguists. Taking a word (token) and abstracting it's \"meaning\" as a 1,000-dimension vector seems like something that should revolutionize the field of linguistics. A whole new tool for analyzing and understanding the underlying patterns of all language!And there's a fact here that's very hard to dispute, this method works. I can give a computer instructions and it \"understands\" them in a way that wasn't possible before LLMs. The main debate now is over the semantics of words like \"understanding\" and whether or not an LLM is conscious in the same way as a human being (it isn't).\n \nreply",
      "Restricted to linguistics, LLM's supposed lack of understanding should be a non-sequitur. If the question is whether LLMs have formed a coherent ability to parse human languages, the answer is obviously yes. In fact not just human languages, as seen with multimodality the same transformer architecture seems to work well to model and generate anything with inherent structure.I'm surprised that he doesn't mention \"universal grammar\" once in that essay. Maybe it so happens that humans do have some innate \"universal grammar\" wired in by instinct but it's clearly not _necessary_ to be able to parse things. You don't need to set up some explicit language rules or generative structure, enough data and the model learns to produce it. I wonder if anyone has gone back and tried to see if you can extract out some explicit generative rules from the learned representation though.Since the \"universal grammar\" hypothesis isn't really falsifiable, at best you can hope for some generalized equivalent that's isomorphic to the platonic representation hypothesis and claim that all human language is aligned in some given latent representation, and that our brains have been optimized to be able to work in this subspace. That's at least a testable assumption, by trying to reverse engineer the geometry of the space LLMs have learned.\n \nreply",
      "Can LLMs actually parse human languages? Or can they react to stimuli with a trained behavioral response? Dogs can learn to sit when you say \"sit\", and learn to roll over when you say \"roll over\". But the dog doesn't parse human language; it reacts to stimuli with a trained behavioral response.(I'm not that familiar with LLM/ML, but it seems like trained behavioral response rather than intelligent parsing. I believe this is part of why it hallucinates? It doesn't understand concepts, it just spits out words - perhaps a parrot is a better metaphor?)\n \nreply",
      "It can have a sensible conversation with you, follow your instructions, do math and physics, and write code that performs the task you described in English. Some models can create pictures and videos matching the description you gave them, or write descriptions of a video from you.In 2023, Microsoft released a paper saying GPT4 could do things like tell you how to stack a random collection of unrelated variously-shaped objects so they don't fall over. Things have come a long way since then.Try out one of the advanced models, and see whether you think it understands concepts.\n \nreply",
      "Dogs out of all creatures probably actually do have some parsing going on for human language. They learn it like we do, picking up context from the environment, actions, tone, facial expressions, body language, etc.You can say 'what's that' in many different ways and a clever dog will react differently for each, even if it's the first time it's heard you say 'what's that?' In a scared tone it'll still react differently while knowing what you're asking.They even do the cute head tilt when they're struggling to understand something.I think people vastly underestimate the power of wetware and think animals and us are separated by a chasm, but I think it's a relatively small leap.We base so much of our understanding of other creatures intelligence on their ability to communicate with us or express things in the ways we do. If elephants judged humans on their ability to communicate in infrasound to speak their names (yes they have names for each other) they'd wouldn't think too highly of us.Sidenote but the latest I've heard is that elephants like us because they think we are cute.\n \nreply",
      ">Can LLMs actually parse human languages?IMHO, no, they have nothing approaching understanding. It's Chinese Rooms[1] all the way down, just with lots of bell and whistles. Spicy autocomplete.1. https://en.wikipedia.org/wiki/Chinese_room\n \nreply",
      "Actually, the LLMs made me realize John Searle\u2019s \u201cChinese room\u201d doesnt make much senseBecause languages have many similar concepts so the operator inside the Chinese room can understand nearly all the concepts without speaking Chinese.And the LLM can translate to and from any language trivially, the inner layers do the actual understanding of concepts.\n \nreply",
      "Go ask the operator of a Chinese room to do some math they weren't taught in school, and see if the translation guide helps.The analogy I've used before is a bright first-grader named Johnny.  Johnny stumbles across a high school algebra book.  Unless Johnny's last name is von Neumann, he isn't going to get anything out of that book.  An LLM will.So much for the Chinese Room.\n \nreply"
    ],
    "link": "https://chomsky.info/20230503-2/",
    "first_paragraph": ""
  },
  {
    "title": "Writing your own CUPS printer driver in 100 lines of Python (2018) (pretix.eu)",
    "points": 141,
    "submitter": "todsacerdoti",
    "submit_time": "2025-05-25T15:52:48 1748188368",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=44088682",
    "comments": [
      "https://gimp-print.sourceforge.io/ which uses CUPS helped me resurrect an old Canon printer for which the company refused to provide updated drivers on macOS.I was about to throw it in the recycling/trash, but I just couldn't accept that a perfectly fine hardware was crippled because the software was not updated to work on the latest macOS versions. Perplexity pointed me to Gutenprint and it worked wonderfully! The only thing that doesn't work is the scanner functionality.\n \nreply",
      "I bought VueScan in 2014 specifically for a Canon scanner, looks like it's still around: https://www.hamrick.com/\n \nreply",
      "Many years ago I remember Windows support vanished on a bunch of printers at the 32 to 64 bit transition. That was around the time I learned how printing on Linux and BSD worked, to save a printer or two.\n \nreply",
      "Did you try http://sane-project.org for the scanner part? They have support for some Canons, maybe you're lucky?\n \nreply",
      ">Unfortunately, CUPS sends us grayscale values and our printer only supports pixels that are either fully black or white. Since we do not want to drop grayscale values compeltely, we want to apply Dither.CUPS can send black-and-white 1 bit data, dithered. It's just a matter of proper option in a PPD file. It could also handle rotation by itself.Other than that, pretty good and accurate article! I bet you can write the driver (filter) even in <50 lines of Python code :P\n \nreply",
      "Ideally don't buy a thermal printer at all. The paper usually contains BPA. You found one that says BPA free? Yep they switched to BPS. Also toxic and harmful to reproductive health.If you absolutely must - use a European supplier - both are banned there for thermal paper.\n \nreply",
      "However, the license of the BOCA driver forbids using their driver to control printers of other vendors.Since this is a printer, I interpret those the same way as \"you're not allowed to use third-party ink\": I don't care.\n \nreply",
      "Oh!Take a look at EPSON printer driver, which prohibits you from:1. Sharing the printer you own with anyone else unless they agree to the license of the driver (incl. business setup)2. Sharing the printer over the internet unconditionally, because this allows to use the driver for people who did not agree to the license3. Incorporating the driver in any \"revenue generating product or service\"https://download.ebz.epson.net/la/linux/inkjet_for_linux.htm...1.    Grant of License.[\u2026] provided that the Software is used (i) only in a single location (e.g., a home or office or place of business), or in the case of a mobile device, on a Device owned or otherwise controlled by you, and (ii) only in connection with Epson Hardware owned by you. You may allow other users of the Epson Hardware connected to your network to use the Software, provided that you shall ensure that such users use the Software only in accordance with this Agreement. You agree to be responsible for and indemnify Epson for liabilities incurred as a consequence of use by such users.3.    Other Rights and Limitations.[\u2026] Further, you agree not to place the Software onto or into a shared environment accessible via a public network such as the Internet or otherwise accessible by others outside the single location referred to in Section 1 above.You may not rent, lease, distribute, lend the Software to third parties or incorporate the Software into a revenue generating product or service.\n \nreply",
      "Personally, I don't either. But if you're a business, you probably need to care even if you don't want to.\n \nreply",
      "Enforceability of EULAs has always been a rather open-ended question.\n \nreply"
    ],
    "link": "https://behind.pretix.eu/2018/01/20/cups-driver/",
    "first_paragraph": "In version 1.8 of pretix, we introduced shipping\nmanagement as a new feature for the pretix Hosted and Enterprise editions. With this plug-in, you can choose not to\ndeliver your tickets to your visitors as a downloadable file, but to send them via snail mail instead. Of course,\nyou can just download those tickets as regular-sized PDF files, print them out and ship them, but the feature is\nusually most interesting if you want to send out high-quality tickets that look good e.g. in a gift wrapping under\na christmas tree or pinned to a wall as a souvenier of the event.For this purpose, you will need a thermal ticket printer as well as suitable ticket paper. Last year, I took a closer\nlook at this market and tested devices from two of the major ticket printer vendors: The BOCA Lemur\nas well as the Practical Automation uITL+2003CF model.\nIn our test, the printing quality of both printers was very similar. The uITL+ is missing a network port in contrast to the \nBOCA Lemur, but the uITL+ feat"
  },
  {
    "title": "Lisping at JPL (2002) (flownet.com)",
    "points": 110,
    "submitter": "adityaathalye",
    "submit_time": "2025-05-22T08:31:36 1747902696",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=44059994",
    "comments": [
      "Author here.  This pops up on HN regularly, which I'm happy to see, but it's pretty dated at this point.  Here is a more recent update:https://blog.rongarret.info/2023/01/lisping-at-jpl-revisited...And, as always, AMA.\n \nreply",
      "you mention compiling down Lisp code. Did that come with many restrictions in the end result for how you were coding systems? Or would you basically write lisp \"as-is\" and get decent results?\n \nreply",
      "I'm not sure what you mean by \"compiling down Lisp code.\"  Can you elaborate?  That phrase doesn't appear in either article.\n \nreply",
      "Can you comment on the relation been a live programming environment (no separate \"staged\" compilation. There is always a dev environment, the REPL, in a deployment), and dynamic types?The typing available in CL, is it like Python type hints in that they don't affect the meaning of a program whatsoever?\n \nreply",
      "Type declarations in ANSI CL are promises you make to the compiler in order to allow it to generate faster code.  The compiler can also use this information to generate compile-time warnings and errors, but it is not required to.  This makes CL's native compile-time type system good for making your code fast, not so much for making it reliable.  But it's straightforward to layer a proper modern type checker on top of CL, and in fact this has been done.  It's called Coalton:https://coalton-lang.github.io/IMHO this is the Right Answer: types when you want/need them, dynamism when you don't.  It seems like a no-brainer to me.  I've never understood why so many people think it has to be one or the other.  It seems to me like arguing over whether the window on the bike shed should be on the left or the right.  If there is disagreement over this, just put in two windows!\n \nreply",
      "Are you still writing lisp at JPL or NASA, or as a hobbyist?\n \nreply",
      "I left JPL in 2004, never to return :-)  I'm mostly retired now but I have a part-time consulting gig that uses CL for developing a bespoke custom chip design tool.\n \nreply",
      "While I was at Amazon, just before AWS, the entire internal network was monitored by a Lisp agent. I'm not sure if that is still true but it was kind of secret, and the internal wiki (only a few sentences) that documented its existence was removed with no deletion record.Right before my position was outsourced to an entire remote overseas team, we had rolled out AAA* which conceivably cut out any unauthorized automated agents from the loop.* https://www.geeksforgeeks.org/what-is-aaa-authentication-aut...\n \nreply",
      "I also worked on a team at Amazon that did (still does to this day, as far as I know) lisp development. A system that was responsible for automated customer support workflows. And it had a visual programming environment for solutions architects. I worked on the Java backend of that.\n \nreply",
      "Tells one of my all-time favourite stories.> 1994-1999 - Remote Agent> Debugging a program running on a $100M piece of hardware that is 100 million miles away is an interesting experience. Having a read-eval-print loop running on the spacecraft proved invaluable in finding and fixing the problem. The story of the Remote Agent bug is an interesting one in and of itself.\n \nreply"
    ],
    "link": "https://flownet.com/gat/jpl-lisp.html",
    "first_paragraph": "\n\nThis is the story of the rise and fall of Lisp at the Jet Propulsion\nLab as told from my personal (and highly biased) point of view.  I am\nnot writing in my official capacity as an employee of JPL, nor am I in\nany way representing the official position of JPL.  (This will become\nrather obvious shortly.)\n1988-1991 - The Robotics Years\n\nI came to JPL in 1988 to work in the Artificial Intelligence group on\nautonomous mobile robots.  Times were different then.  Dollars flowed\nmore freely from government coffers.  AI Winter was just beginning, and\nit had not yet arrived at JPL.  (Technology at the Lab tends to run a\nfew years behind the state of the art :-) \n\nJPL at the time was in the early planning stages for a Mars rover\nmission called Mars Rover Sample Return (MRSR).  In those days space\nmissions were Big, with a capital B.  The MRSR rover was to weigh nearly\na ton.  The mission budget was going to be in the billions of dollars\n(which was typical in those days).\n\nAgainst this backdrop"
  },
  {
    "title": "Claude 4 System Card (simonwillison.net)",
    "points": 540,
    "submitter": "pvg",
    "submit_time": "2025-05-25T06:06:39 1748153199",
    "num_comments": 212,
    "comments_url": "https://news.ycombinator.com/item?id=44085920",
    "comments": [
      "I just published a deep dive into the Claude 4 system prompts, covering both the ones that Anthropic publish and the secret tool-defining ones that got extracted through a prompt leak. They're fascinating - effectively the Claude 4 missing manual: https://simonwillison.net/2025/May/25/claude-4-system-prompt...\n \nreply",
      "Truly fascinating, thanks for this.What I find a little perplexing is when AI companies are annoyed that customers are typing \"please\" in their prompts as it supposedly costs a small fortune at scale yet they have system prompts that take 10 minutes for a human to read through.\n \nreply",
      "Hah, yeah I think that \"please\" thing was mainly Sam Altman flexing about how many users ChatGPT has.Anthropic announced that they increased their maximum prompt caching TTL from 5 minutes to an hour the other day, not surprising that they are investigating effort in caching when their own prompts are this long!\n \nreply",
      "What I find fascinating is that people still take anything Scam Altman says seriously after his trackrecord of non-stop lying, scamming and bllsh*tting right in people's faces for years.I can't really think of anything interesting or novel he said that wasn't a scam or lie?Let's start by observing the \"non-profit's\" name...\n \nreply",
      "I assume that they run the system prompt once, snapshot the state, then use that as starting state for all users. In that sense, system prompt size is free.EDIT: Turns out my assumption is wrong.\n \nreply",
      "Huh, I can't say I'm on the cutting edge but that's not how I understand transformers to work.By my understanding each token has attention calculated for it for each previous token. I.e. the 10th token in the sequence requires O(10) new calculations (in addition to O(9^2) previous calculations that can be cached). While I'd assume they cache what they can, that still means that if the long prompt doubles the total length of the final context (input + output) the final cost should be 4x as much...\n \nreply",
      "This is correct. Caching only saves you from having to recompute self attention on the system prompt tokens, but not from the attention from subsequent tokens, which are free to attend to the prompt.\n \nreply",
      "My understanding is that even though it's quadratic, the cost for most token lengths is still relatively low. So for short inputs it's not bad, and for long inputs the size of the system prompt is much smaller anyways.And there's value to having extra tokens even without much information since the models are decent at using the extra computation.\n \nreply",
      "To be fair OpenAI had good guidelines on how to best use chatgpt on their github page very early on. Except github is not really consumer facing, so most of that info was lost in the sauce.\n \nreply",
      "Link?\n \nreply"
    ],
    "link": "https://simonwillison.net/2025/May/25/claude-4-system-card/",
    "first_paragraph": "System Card: Claude Opus 4 & Claude Sonnet 4. Direct link to a PDF on Anthropic's CDN because they don't appear to have a landing page anywhere for this document.Anthropic's system cards are always worth a look, and this one for the new Opus 4 and Sonnet 4 has some particularly spicy notes. It's also 120 pages long - nearly three times the length of the system card for Claude 3.7 Sonnet!If you're looking for some enjoyable hard science fiction and miss Person of Interest this document absolutely has you covered.It starts out with the expected vague description of the training data:Claude Opus 4 and Claude Sonnet 4 were trained on a proprietary mix of publicly available information on the Internet as of March 2025, as well as non-public data from third parties, data provided by data-labeling services and paid contractors, data from Claude users who have opted in to have their data used for training, and data we generated internally at Anthropic. Anthropic run their own crawler, which th"
  },
  {
    "title": "Trading with Claude, and writing your own MCP server (dangelov.com)",
    "points": 35,
    "submitter": "dangelov",
    "submit_time": "2025-05-22T12:59:34 1747918774",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44061614",
    "comments": [
      "I also did this a few months ago using a custom MCP server I built for the Alpaca API, the yfinance MCP server, and a reddit MCP server, and the \"sequential thinking\" mcp server. I hade claude write a prompt that combined them all together  starting with checking r/pennystocks for any news, looking up the individual ticker symbols with alpaca and yfinance, checking account balance and making a trade only if a very particular set of criteria was met. I used claude code instead of desktop so that I could run it as a cron job, and it all works! I mostly built it to see if I could, not for any financial gain. I had it paper trading for a few months and it made a 2% profit on 100k. I really think someone that knows more about trading could do quite well with a setup like this, but it's not for me.\n \nreply",
      "Did you benchmark it against holding the same value in S&P 500 or similar ETF over the same period?\n \nreply",
      "I\u2019ve been doing this as well it also works well when you hook it up to Edgar or feed in investor relations documents or earnings transcripts. You can extract a lot of data at scale for regressions using small models with few shot prompts running locally.\n \nreply",
      "What do you mean by \"regressions\"?\n \nreply",
      "Great writeup! I was just working at Alpaca --- if you're interested in using Alpaca via MCP (or another way of integrating with LLMs), reach out with your usecase and I'd be happy to put you in touch with the right people.\n \nreply",
      "I recently built an MCP server in Go too, so the use cases and implementation guide were very helpful, thank you.\n \nreply",
      "Sometimes Go can get under my skin. \nThe MCP SDK makes you jump through all these hoops to configure tools according to a JSON schema, but when it comes to handling the actual request you need to deal with parsing everything again out of a `map[string]any`. It's such a pain to need to reach for codegen all the time.\n \nreply",
      "Go is pretty miserable for dealing with JSON compared to Python\n \nreply",
      "Interesting, Go is actually a language I tend to reach for when dealing with JSON.\n \nreply",
      "Yikes! I can only imagine an LLM hallucinating my portfolio to zero.\n \nreply"
    ],
    "link": "https://dangelov.com/blog/trading-with-claude/",
    "first_paragraph": "Ever wanted to check on your portfolio and trade some stocks directly with Claude? Well you\u2019re in luck.In November 2024, Anthropic open-sourced MCP (Model-Context Protocol) to standardize the way AI assistants interact with other tools. This standardization allows AI assistants to seamlessly integrate with various tools and platforms, enhancing their capabilities and usability. Since then, it\u2019s been growing in popularity and adoption, slowly becoming a key component in the development of AI-powered tools and applications.While the original version had some support for remote MCP servers, it was somewhat complicated to implement and did not see widespread adoption. So, as a natural evolution to the original MCP, they released the 2025-03-26 version with support for OAuth 2.1 authorization and replaced the HTTP+SSE transport with \u201cStreamable HTTP\u201d transport.Perhaps most importantly, all of this only worked in Claude Desktop - till now. A few days ago, they added \u201cIntegrations\u201d to Claude,"
  },
  {
    "title": "Koog, a Kotlin-based framework to build and run Al agents in idiomatic Kotlin (github.com/jetbrains)",
    "points": 45,
    "submitter": "prof18",
    "submit_time": "2025-05-22T07:40:23 1747899623",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44059657",
    "comments": [
      "I\u2019m a Kotlin dev, and Koog feels like a breath of fresh air being able to spin up agents with a typesafe, Kotlin-native DSL is really nice. The magic for me is the ability to swap between OpenAI, Anthropic, or your own Llama with zero friction. Plus, the smart history compression already looks like it\u2019ll save a ton on tokens, and the streaming + persistent memory hooks look nice too! Can\u2019t wait to dig in and see how it holds up in a real project!\n \nreply",
      "Why does this say Al, not AI?  I have AI filtered in my adblock.  Not cool VERY NOT COOL..\n \nreply",
      "Maybe you should put some AI in your Adblock so it works better.\n \nreply"
    ],
    "link": "https://github.com/JetBrains/koog",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Koog is a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\nKoog is a Kotlin-based framework designed to build and run AI agents entirely in idiomatic Kotlin. It lets you create agents that can interact with tools, handle complex workflows, and communicate with users.Key features of Koog include:The LLM providers and platforms whose LLMs you can use to power your agent capabilities:To help you get started with AI agents, here is a quick example:Currently, the framework supports the JVM and JS targets.On JVM, JDK 17 or higher is required to use the framework.Add dependencies to the build.gradle.kts file:Make sure that you have mavenCentral() in the list of repositori"
  },
  {
    "title": "Design Pressure: The Invisible Hand That Shapes Your Code (hynek.me)",
    "points": 133,
    "submitter": "NeutralForest",
    "submit_time": "2025-05-25T13:51:55 1748181115",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=44087844",
    "comments": [
      "Great talk, there's a lot I can relate to in here.I find this topic difficult to navigate because of the many trade-offs. One aspect that wasn't mentioned is temporal. A lot of the time, it makes sense to start with a \"database-oriented design\" (in the pejorative sense), where your types are just whatever shape your data has in Postgres.However, as time goes on and your understanding of the domain grows, you start to realize the limitations of that approach. At that point, it probably makes sense to introduce a separate domain model and use explicit mapping. But finding that point in time where you want to switch is not trivial.Should you start with a domain model from the get-go? Maybe, but it's risky because you may end up with domain objects that don't actually do a better job of representing the domain than whatever you have in your SQL tables. It also feels awkward (and is hard to justify in a team) to map back and forth between domain model, sql SELECT row and JSON response body if they're pretty much the same, at least initially.So it might very well be that, rather than starting with a domain model, the best approach is to refactor your way into it once you have a better feel for the domain. Err on the side of little or no abstraction, but don't hesitate to introduce abstraction when you feel the pain from too much \"concretion\". Again, it takes judgment so it's hard to teach (which the talk does an admirable job in pointing out).\n \nreply",
      "Pretty naive question, but what differentiates a \"domain model\" from these more primitive data representations? I see the term thrown around a lot but I've never been able to grok what people actually mean.By domain model do you mean something like what a scientist would call a theory? A description of your domain in terms of some fundamental concepts, how they relate to each other, their behaviour, etc? Something like a specification?Which could of course have many possible concrete implementations (and many possible ways to represent it with data). Where I get confused with this is I'm not sure what it means to map data to and from your domain model (it's an actual code entity?), so I'm probably thinking about this wrong.\n \nreply",
      "A quick example can be found with date. You can store it in ISO 8601 string and often it makes more sense as this is a shared spec between systems. But when it comes to actually display it, there's a lot of additional concerns that creep in such as localization and timezones. Then you need to have a data structure that split the components, and some components may be used as keys or parameters for some logic that outputs the final representation, also as a string.So both the storage and presentation layer are strings, but they differs. So to reconcile both, you need an intermediate layer, which will contains structures that are the domain models, and logic that manipulate them. To jump from one layer to another you map the data, in this example, string to structs then to string.With MVC and CRUD apps, the layers often have similar models (or the same, especially with dynamic languages) so you don't bother with mapping. But when the use cases becomes more complex, they alter the domain layer and the models within. So then you need to add mapping code. Your storage layers may have many tables (if using sql), but then it's a single struct at the domain layer, which then becomes many models at the presentation layer with duplicate information.NOTEThat's why a lot of people don't like most ORM libraries. They're great when the models are similar, but when they start to diverge, you always need to resort to raw SQL query, then it becomes a pain to refactor. The good ORM libraries relies on metaprogramming, then they're just weird SQL.\n \nreply",
      "ORM libraries have Value conversion functionality for such trivial examples\nhttps://learn.microsoft.com/en-us/ef/core/modeling/value-con...\n \nreply",
      "Not really. It's all about the code you need to write. Instead of wrangling the data structures you get from the ORM which is usually similar to maps and array of maps. You have something that makes the domain logic cleaner and clear. Code for mapping data are simple, so you just pay the time price for writing them in exchange for having maintainable use case logic.\n \nreply",
      "My understanding is, a database model is one that is fully normalized - design tables to have no redundant/repeated piece of information. You know, the one they teach you when you study relational DBs.In that model, you can navigate from anywhere to anywhere by following references.The domain model, at least from a DDD perspective, is different in at least a couple of ways: your domain classes expose business behaviours, and you can hide certain entities as such.For example, imagine an e-commerce application where you have to represent an order.In the DB model, you will have the `order` table as well as the `order_line` table, where each row of the latter references a row of the former. In your domain model, instead, you might decide to have a single Order class with order lines only accessed via methods and in the form of strings, or tuples, or whatever - just not with an entity. The Order class hides the existence of the order_line table.Plus, the Order class will have methods such as `markAsPaid()` etc, also hiding the implementation details of how you persist this type of information - an enum? a boolean? another table referencing rows of `order`? It does not matter to callers.\n \nreply",
      "For me domain model means capturing as much information about the domain you are modeling in the types and data structures you use. Most of the time that ends up meaning use Unions to make illegal states unrepresentable. For example, I have not seen a database native approach to saving union types to databases. In that case using another domain layer becomes mandatory.For context:\nhttps://fsharpforfunandprofit.com/posts/designing-with-types...\n \nreply",
      "To me domain model is an Object-Oriented API through which I can interact with the data in the system.  Another way to interact would be direct SQL-calls of course, but then users would need to know about how the data is represented in the database-schema. Whereas with an OOP API, API-methods return instances of several multiple model-classes.The way the different classes are associated with each other by method calls makes evidednt a kind of \"theory\" of our system, what kind of objects there are in the system what operations they can perform returning other types of objects as results and so on.  So it looks much like a \"theory\" might in Ecological Biology, m ultiple species interacting with each other.\n \nreply",
      "You can model this \"theory\" in the database itself.\n \nreply",
      "There are certainly times I would love to see a presentation like this reformatted as an article.I tried pulling out the Youtube transcript, but it was very uncomfortable to read with asides and jokes and \"ums\" that are all native artifacts of speaking in front of a crowd but that only represent noise in when converted to long written form.\n \nreply"
    ],
    "link": "https://hynek.me/talks/design-pressure/",
    "first_paragraph": "Ever had this weird gut feeling that something is off in your code, but couldn\u2019t put the finger on why? Are you starting your projects with the best intentions, following all best practices, and still feel like your architecture turns weird eventually?So far, I\u2019ve held it at PyCon US 2025 in Pittsburgh, USA.Slides on SpeakerDeck.(Sorry for the literal throat-cleaning in the video \u2013 I lost my voice the night\nbefore and worked on fumes and Fisherman\u2019s Friends.)Some of the material was referred to directly in the talk but landed on the cutting floor due to time constraints.They all are highly recommended reading/watching for the topic of software design writ large, though.This article argues against async primitives in languages because it causes you to have two different types of functions that behave differently. I don\u2019t fully agree, but I find it interesting to apply this logic to classes.Arguably, ORM classes and, to a much lesser degree, Pydantic classes, behave very differently than"
  },
  {
    "title": "Show HN: DaedalOS \u2013 Desktop Environment in the Browser (github.com/dustinbrett)",
    "points": 120,
    "submitter": "DustinBrett",
    "submit_time": "2025-05-25T16:06:12 1748189172",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=44088777",
    "comments": [
      "I made one of these years ago, much less polished but broadly similar.From that perspective you have done well to avoid discouragement.  Most of the feedback I received was negative.  Worse was that the negative feedback was not related to my implementation but arguing that I should not try at all.If you do keep working on this project for the rest of your life, I commend you.I kind of got split between making a client only version (all data client side), a file storage server where all brains are client side but persistent data is on a server, or a direct Linux login (open real shell on browser.  Linux executables can connect to a socket to open windows on the browser and provide a UI similar to how X11 does, only with a much smarter UI host)In recent years I have been doing a few experiments working on the areas that were difficult.  So many things have been added to browsers since I started, I can't recall exactly how long ago that was but I remember boot2gecko adding features that I needed.Recently I have been experimenting with launching web workers which asks for an API and is given a MessagePort with code to construct functions that translate to messages.   That way all of the desktop features can be provided as permissions with some auditing theoretically(but unimplemented) available.\n \nreply",
      "Wow - indeed. I see you made something like this already back in 2012. Impressive: https://github.com/Lerc/notanos That is more than 13 years ago when websockets where about to become generally available. Impressive!Don't be discouraged by people that argue what you should or should not do. The world is full with people with their own agenda or that simply have a too narrow view of how their world should operate.\n \nreply",
      "Reminds me a bit of Sun's network computer (JavaStation) back in the day. Based on JavaOS. It was an idea to get Java on the map but it had very obvious issues.The main thing I remember about that... s...l...o...w... :P\nThe other thing I remember: Shit cool hardware. As expected from Sun. They were the cool kids before Apple were cool, along with SGI.But of course computers are not what they used to be these days.\n \nreply",
      "This is amazing - well done, and indeed runs oh-so smooth - even on mobile!I see that the browser is somewhat limited as most sites try to prevent 'embedding'. However, we have a solution where we can proxy any web content in such a way to still allow you to embed it: https://www.webfuse.com/use-case/embed-unembeddable-contentLmk if you would like to try this out and I can help you set this up.\n \nreply",
      "It would be \u20ac529 /month for 20 users but wouldn't they need to possibly support way more users than that? I wish we had a client-side solution that could infinitely scale beyond having users run their own node.js proxy.\n \nreply",
      "I had a conversation on an irc room I created called #globaltetrahedron using two browser windows on my $40 cracked screen phone.Worked flawlessly and is a fantastic experience. I hope Microsoft is scared of the efficiency of your experience.\n \nreply",
      "This is really impressive and surprisingly visually close to Explorer, especially the font rendering and the button hover effects. I also started poking around to see how the animated wallpaper was done and the custom devtools were a nice surprise too. I don't know how much Microsoft cares about people ripping Windows icons, but directly using icons from Facebook Messenger, VLC, VSCode, Chromium, etc might be more of a concern if it starts to get more attention.\n \nreply",
      "This looks awesome.  As soon as I saw Synology's DSM I realized the browser would be a fantastic place for a desktop environment, but they only built half of it - then left it mostly untouched anyway.\n \nreply",
      "Just magical! It's so realistic that I had to remind myself that it was a website and not a VM!The nuances you've captured across so many different interfaces must've taken you a long time!\n \nreply",
      "Much deeper and works better than anything like it, at least from what I\u2019ve seen around the web. And that\u2019s only from my phone. Very well doneI even got quake to run, haven\u2019t tried connecting a keyboard yet.\n \nreply"
    ],
    "link": "https://github.com/DustinBrett/daedalOS",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Desktop environment in the browser\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Desktop environment in the browser\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Show HN: Zli \u2013 A Batteries-Included CLI Framework for Zig (github.com/xcaeser)",
    "points": 64,
    "submitter": "caeser",
    "submit_time": "2025-05-25T16:52:14 1748191934",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=44089054",
    "comments": [
      "Looks nice! Some thoughts:  const now = ctx.flag(\"now\", bool); // type-safe flag access\n\nThis is type-safe, but only at run time. Since your flags are (or could be) known at compile time, it would be nice to have this throw a compile error if the type is invalid.Or even better - fully lean into comptime and generate a struct so you can use field access without specifying a type:  const now = ctx.flag.now;\n \nreply",
      "Cool name - I bet it sounds great with an American/Canadian accent. Using the UK/Australia/NZ accent, it's pronounced \"zed-ell-aye\", so I didn't grok it instantly like most of the audience here would.\n \nreply",
      "\u201cZee\u201d is getting more popular especially with gen Z (unintended) who were raised with more widespread access to American media, social or otherwise. Like many Commonwealth countries, most of Canada uses \u201czed\u201d, however.\n \nreply",
      "What is a \u201cCLI framework\u201d?\n \nreply",
      "It takes care of the CLI argument parsing, command routing, and help formatting.I recently wrote a CLI manually, thinking, CLIs are so simple why would you need a framework? At the end of writing it, I had just ended up writing my own CLI framework anyway. It gets tedious without one, even though none of the things the framework does are particularly complicated.\n \nreply",
      "Related: https://stackoverflow.com/q/79454372/7758804\n \nreply",
      "Looks like a good zig argparse lib.How do you like Zig compared to TypeScript? What would you like to see improved?\n \nreply",
      "zig is amazing.\ni am legit more productive in zig.as Andrew (zig creator) said, zig makes you understand how computers work.\n \nreply",
      "Will zig include a rustimport similar to cimport ?\n \nreply",
      "Haven't tried it but there's build.crab https://github.com/akarpovskii/build.crab\n \nreply"
    ],
    "link": "https://github.com/xcaeser/zli",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        \ud83d\udcdf Zig command-line interfaces made easy. A blazing fast CLI framework. Build ergonomic, high-performance command-line tools with zig.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A blazing-fast, zero-cost CLI framework for Zig. The last one you will ever use.Build modular, ergonomic, and high-performance CLIs with ease.\nAll batteries included.\n\n\n\ud83e\uddf1 Each command is modular and self-contained.\ninspired by Cobra (Go) and clap (Rust).See docs.md for full usage, examples, and internals.Add to your build.zig:MIT. See LICENSE. Contributions welcome.\n        \ud83d\udcdf Zig command-line interfaces made easy. A blazing fast CLI framework. Build ergonomic, hig"
  },
  {
    "title": "Writing a Self-Mutating x86_64 C Program (2013) (ephemeral.cx)",
    "points": 75,
    "submitter": "kepler471",
    "submit_time": "2025-05-25T17:00:26 1748192426",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=44089106",
    "comments": [
      "I had a great experience writing self modified programs is a single instruction programming game SIC-1: https://store.steampowered.com/app/2124440/SIC1/\n \nreply",
      "It's impressive how well laid out the content in this article is. The spacing, tables, and code segments all look pristine to me, which is especially helpful given how dense and technical the content is.\n \nreply",
      "I often think this could maybe allow fantastic runtime optimisations. I realise this would be hardly debuggable but still..\n \nreply",
      "It sometimes can, but you then have to balance the time spent optimizing against the time spent actually doing whatever you were optimizing.Also on modern chips you must wait quite a number of cycles before executing modified code or endure a catastrophic performance hit. This is ok for loops and stuff, but makes a lot of the really clever stuff pointless.The debuggers software breakpoints _are_ self-modifying code :)\n \nreply",
      "I used GNU lightning library once for such optimisation. I think it was ICFPC 2006 task. I had to write an interpreter for virtual machine. Naive approach worked but was slow, so I decided to speed it up a bit using JIT. It wasn't a 100% JIT, I think I just implemented it for loops but it was enough to tremendously speed it up.\n \nreply",
      "Programs from the 80s-90s are likely to have such tricks. I have done something similar to \"hardcode\" semi-constants like frame sizes and quantisers in critical loops related to audio and video decompression, and the performance gain is indeed measurable.\n \nreply",
      "> \"hardcode\" semi-constantsYou mean you somehow avoided a load. But what if the constant was already placed in a register ? Also how could you pinpoint the reference to your constant in the machine code ? I'm quite profane about all this.\n \nreply",
      "> Also how could you pinpoint the reference to your constant in the machine code?Not OP, but often one uses an easily identifiable dummy pattern like 0xC0DECA57 or 0xDEADBEEF which can be substituted without also messing up the machine code.\n \nreply",
      "If you\u2019re willing to parse object files (a much easier proposition for ELF than for just about anything else), another option is to have the source code mention the constants as addresses of external symbols, then parse the relocations in the compiled object. Unfortunately, I\u2019ve been unable to figure out a reliable recipe to get a C compiler to emit absolute relocations in position-independent code, even after restricting myself to GCC and Clang for x86 Linux; in some configurations it works and in others you (rather pointlessly) get a PC-relative one followed by an add.\n \nreply",
      "All the registers were already taken.You use a label.\n \nreply"
    ],
    "link": "https://ephemeral.cx/2013/12/writing-a-self-mutating-x86_64-c-program/",
    "first_paragraph": "2013 December 29\u201cWhy would you ever want to write a program that changes its code while it\u2019s running? That\u2019s a horrible idea!\u201dYes, yes it is. It\u2019s a good learning experience though. This is not something you would ever do outside of exploring a curiosity.Self-mutating/self-modifying programs aren\u2019t useful for a whole lot. They make for difficult debugging, the program becomes hardware dependent, and the code is extremely tedious and confusing to read unless you are an expert assembly programmer. The only good use for self-mutating programs in the wild I know of is as a cloaking mechanism for malware. My goal is purely academic so I venture into nothing of the sort here.Warning: This post is heavy on x86_64 assembly of which I am no expert. A fair amount of research went into writing this and it\u2019s possible (almost expected) that mistakes were made. If you find one, send an email so that it may be corrected.The first step of writing a self-mutating program is being able to change the cod"
  },
  {
    "title": "CAPTCHAs are over (in ticketing) (pretix.eu)",
    "points": 112,
    "submitter": "pabs3",
    "submit_time": "2025-05-25T00:37:08 1748133428",
    "num_comments": 157,
    "comments_url": "https://news.ycombinator.com/item?id=44084677",
    "comments": [
      "I can\u2019t claim I\u2019m the first one to think about this, but every time Ticketmaster shows up on HN I keep coming back to this idea:Sell the tickets with regressive price based on time. Sales starts say 2 months before event, initial price is truly exorbitant, say one million dollars. Price decreases linearly down to zero (or true cost price). At any point, people can see current price and the seats left.Now every potential spectator is playing a game of chicken: the more you wait, the lower the price, but also lower are the chances that you\u2019ll have a ticket. That would capture precisely the maximum amount of dollars that each person is willing to pay for it.This idea sounds extremely greedy, because it is, so I can\u2019t fathom that no one ever pitched this in a Ticketmaster board meeting.My idea, however, was a bit less greedy. Once you sold the last ticket, that would be your actual (and fair) price-per-ticket for the concert, and everyone would be refunded the difference. You\u2019ll never know how low it will go, so you shouldn\u2019t overpay and hope it will lower later. I\u2019m pretty sure Ticketmaster will skip this last part if they decide to implement this.There are multiple issues with my idea, it\u2019s elitist, promotes financial risks on cohorts poorly capable to bear them, etc etc, but it will definitely fix the scalpers problem. Pick your poison.\n \nreply",
      "The scalper problem is a mispricing problem: Scalpers are just arbitrageurs because ticket prices are artificially very low.If you want to fix that, you need to ask yourself \"why are ticket prices artificially very low?\" first. The answer probably isn't \"artists/venues like leaving money on the table\".\n \nreply",
      "I think a significant portion is that artists like leaving money on the table. being perceived as greedy can cause reputational harm significantly greater than the increased ticket revenues that the market will bear.\n \nreply",
      "What is it then?\n \nreply",
      "My guess: Empty seats look bad and and pricing fans out of concerts may hurt fan relations, even losing them completely.Also concerts are mainly for the artist to make money. Traditionally they're getting fucked by record labels, making very little on sales of media. Concerts is when you're actually getting paid. It thus being a somewhat less corporate process to decide ticket prices can mean that they just charge as much as they need and want, not as much as they can. Artists are generally considered to be a polar opposite to the \"short-term-profit-maximizing\" crowd.\n \nreply",
      "That's a Dutch auction: https://en.wikipedia.org/wiki/Dutch_auction.I agree that reverse auctions would be a simple solution the current scalper problem. If demand outweighs supply, scalpers drive up the prices toward their economic equilibrium anyway, making ticket prices just as \"unfair\" to the poor, but with additional problems of trust...\n \nreply",
      "That's not actually a Dutch Auction.  Sounds more like the \"eBay ascending uniform-price mechanism\".  (From the same Wikipedia article)\n \nreply",
      "This is a similar idea to a second price auction, but in reverse.Everyone puts in their maximum price they're willing to pay, and the lowest price that fills the seats is what people pay.The advantage to this model is that there is no financial risk to overpaying.Of course with an open bid continuous auction there are problems with bid shading (manipulating the auction by posting prices mostly meant to influence other bidders), but it's overall economically very close to your idea.\n \nreply",
      "Auctions work great for price discovery. Check this out:https://community.intercoin.app/t/intercoin-applications-auc...also:https://community.intercoin.app/t/applications-of-intercoin-...\n \nreply",
      "> but it will definitely fix the scalpers problemNobody wants to fix the scalpers problem because, to the Ticketmaster monopoly, scalpers aren't a problem.  The Ticketmaster monopoly values known, consistent, derisked revenue over possible lottery ticket windfalls with the possibility of complete wipeout.  Scalpers do exactly that.Scalpers are only a problem to fans.  And scalpers are only a problem online because they can wipe out the entire ticket base.  The \"solution\" is to introduce offline friction to the problem--anything which requires a person to show up and buy only a limited number of tickets.  Unfortunately, that introduces a lot of uncertainty into the system instead of guaranteed cash flow and the business side finds that to be anathema.However, the real solution is to bust up the Ticketmaster monopoly.  If each of the individual actors (ticket sales, venue owner, performers) have to operate independently and have to de-risk at each point, scalpers become an enemy to be neutralized.I also have a completely unjustified suspicion that scalping is hiding a lot of money laundering so lots of people have vested interest in it continuing.\n \nreply"
    ],
    "link": "https://behind.pretix.eu/2025/05/23/captchas-are-over/",
    "first_paragraph": "One of the issues in ticketing is that many events have much more demand for tickets than they can supply.\nObviously, this is a good problem to have (better than empty halls), but it attracts certain types of bad actors trying to get as many tickets as possible in order to resell them (\u201cticket scalping\u201d).\nWhile this is possible of course just by buying tickets like a regular customer, many of them use computer programs (\u201cbots\u201d) to enhance either their chance of claiming a ticket or their scale of operation by buying more tickets.The naive economic solution to the problem would be raising ticket prices step by step until it is no longer attractive for scalpers to resell your ticket, because the original price of the ticket is already the maximum that people are willing to pay, creating an economic equilibrium.\nMost organizers, including for-profit organizations, do not want to choose this option due to ethical concerns or concerns about community building.Therefore, whenever this topic "
  },
  {
    "title": "Advice to Tenstorrent (github.com/geohot)",
    "points": 31,
    "submitter": "lexoj",
    "submit_time": "2025-05-25T21:37:59 1748209079",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=44091410",
    "comments": [
      "I'm doing my PhD in ML shit. Before that I was a systems programming guy, lots of C++, bit of CUDA, big fan of Rust. On the side I'm obsessed with RISC-V. Own a couple of boards. I made a stupid little cuda-like-compiler on top of the RISC-V vector extensions, just for fun.What I'm saying is, tensorrent couldn't find a more excitable third-party developer if they grew one in a lab. And you know what? I can't make heads or tails out of all their various abstractions. I've tried! I've read the docs, I've read the examples, I've gone to meetups. I think OP is right that \"one more abstraction bro\" probably doesn't solve the problem.At a guess, the problem isn't a technical one, it is an organizational one. They don't have anybody to stand in for me, or devs like me (eg dumb people). There is no product leadership on the API design. Just a lot of really brilliant engineers obsessively tuning for their own usecases, unwilling to ever trade-off a hit in performance or expressivity for readability or writeability.\n \nreply",
      "Has geohot done anything since the original iphone jailbreak?The ventures he has started (I can think of tinygrad and comma ai) all seem like half finished tech demos.\n \nreply",
      "He's the founder of comma.aiEdit: you edited your comment after I told you he made comma.ai.Bit dishonest, but whatever, I wouldn't describe comma.ai as a \"half finished tech demo\" but you're allowed to your own opinion about it.\n \nreply",
      "I thought George was going to save AMD. Now he's saving tenstorrent? Busy guy!\n \nreply",
      "Don't forget he was also going to save Twitter but noped out after a few weeks.\n \nreply",
      "Maintaining and improving existing software sure is boring and often thankless compared to starting flashy new projects where you get to make and understand all the major decisions up front.\n \nreply",
      "geohot has a loud mouth ... but he has earned the cred and walks the walk.I wish there was a thousand more geohots than all the mediocre middle-managers at AMD or tenstorrent; or people who have never done anything beyond posting snarky comments in online forums.\n \nreply",
      "> geohot has a loud mouth ... but he has earned the credSadly, I think geohot is an example of someone who earned some cred for impressive accomplishments in the past and then tried to cash in that cred over and over again in unrelated future domains.His brief and very public flame out at Twitter after mysteriously abandoning another project and the bold claims about his AMD work that never really translated to anything have really detracted from whatever past \u201ccred\u201d he built up. I really hope he can find a new niche and succeed, but until then it might be time to lie low on social media and avoid throwing more mud.\n \nreply",
      ">geohot has a loud mouth ... but he has earned the cred>I think geohot is an example of someone who earned some cred for impressive accomplishments in the past [...]Huh? Yeah, that's what I wrote.\n \nreply",
      "> Huh? Yeah, that's what I wrote.You cut out the part of my post where I made my point.Earning \u201ccred\u201d for past accomplishments doesn\u2019t give someone a free pass forever to be a loud mouth.\n \nreply"
    ],
    "link": "https://github.com/geohot/tt-tiny",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        tiny code to access tenstorrent blackhole\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        tiny code to access tenstorrent blackhole\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Denmark to raise retirement age to 70 (telegraph.co.uk)",
    "points": 286,
    "submitter": "wslh",
    "submit_time": "2025-05-25T16:34:28 1748190868",
    "num_comments": 717,
    "comments_url": "https://news.ycombinator.com/item?id=44088957",
    "comments": [
      "This is truly sad. As a Swede I fear my country may follow suite. The retirement age in Sweden used to be 65 and now it's 67.Looking at older people around me, most lead a much less active life after 75. So, if we were lucky we used to have some 10 good years of doing whatever we wanted before old age and age-related diseases start affecting us so much we become limited to a much smaller world. But now we have maybe eight years and if we follow Denmark, five years.I think if you've put in 40-45 years for the man, you should be allowed to have some good 10 years for yourself. Travel, play golf, cross a continent in a camper or climb a mountain.\n \nreply",
      "There is nothing sad about this. Mandatory pensions are not a vacation sponsored by the government but a way to provide for those who can't provide for themselves.If you were born in the 70s, you should have known for most of your adult life that your normal retirement age is likely going to be around 70. The demographic situation is not new, the solutions have been discussed extensively since at least the 90s, and countries that take the situation seriously have implemented several pension reforms since then.You are not going to be as wealthy in retirement as you are now, at least not on the mandatory pension alone. Your health is probably not going to be as good. If you live in Sweden, you should have plenty of vacation. If you think you would enjoy travel, golf, or climbing a mountain, you should do it now. It will probably be easier and more affordable now than in retirement, which may never come.\n \nreply",
      "I guess this comes down to whether you view what you get back for devoting most of a life to work as a negotiated agreement with government or as a one way street.\n \nreply",
      "\"From each according to his ability, to each according to his needs.\" That socialist principle has always been the essence of the Nordic model. While the Nordic countries chose regulated markets over actual socialism, they embraced that part of socialism.As a citizen, your moral duty is to contribute when you can. If too many people fail to do that, the system falls apart. In exchange, the government evens the burden between different stages of life and between people in different situations. You live your life now, the government takes what it needs, and it provides for you when your needs exceed your ability.Also, as small democratic countries with limited ambitions outside their borders, the Nordic system of governance is supposed to be more \"by the people, for the people\" than it has ever been in the US. You don't negotiate agreements with the government, but you take responsibility for making things work. If too many citizens fail to do that, the system falls apart.\n \nreply",
      "Isn't democracy the negotiation part?\n \nreply",
      "Yes.Those that came before you negotiated on their own behalf, how badly to loot your future.Now you must do the same..",
      "Back when it was first introduced, it was based on life expectancy and few were expected to live beyond retirement age. [1][1] https://www.theatlantic.com/business/archive/2014/10/how-ret...\n \nreply",
      "Turns out retirement is just an illusion to convince you to give your best years for the system.\n \nreply",
      "Humans need a constant supply of resources and shelter to survive. There is no \"system\" which avoids this inconvenient fact. In the absence of any \"system\" at all, you would still need to constantly work for survival - and in fact you'd just die as soon as you were no longer able to do so due to illness or injury much less old age.In other words if there were no \"system\" there would be no such concept as \"retirement\" in the first place.We all wish that we could spend our best years doing whatever we want. That doesn't mathematically work out, though. European social safety nets are pretty damn generous all things considered. Plenty of vacation days, especially compared to the US.  It's not like it's impossible to use those well during your \"best years\".\n \nreply",
      "Sure. But given automation we need a lot less labor than 100 years ago.Some studies suggest (sorry am mobile right now, don\u2019t have links) in the US automation can produce the average persons essentials entirely.But we still were taught growing up to put on the show of going to work. At great resource cost and ecological destruction now threatening everyone in deference to memes of long dead laborers and rich who would often be able to shoot anyone that didn\u2019t work hard enough without repercussion.We do not live in the 1900s or even 1800s.And how much stuff? New 80\u201d TVs and iPhones every year?We\u2019ve been conditioned by salesmen who also probably didn\u2019t produce anything but emotional demand. Sure let\u2019s keep living in the Newspeak of the rich media class, and ossified politicians; we\u2019ve always been at war with line go down.Your same old copy paste \u201cdon\u2019t rock the boat\u201d euphemism is thought ending nonsense. It\u2019s capitulation not discovery of options.\n \nreply"
    ],
    "link": "https://www.telegraph.co.uk/world-news/2025/05/23/denmark-raise-retirement-age-70/",
    "first_paragraph": "\n\t\t\tScandinavian country set to have highest retirement age in Europe as controversial vote in parliament leads to public outcry\n\t\tCopy linktwitterfacebookwhatsappemailCopy linktwitterfacebookwhatsappemailCopy linktwitterfacebookwhatsappemailCopy linktwitterfacebookwhatsappemailDenmark will raise its retirement age to 70 by 2040, the highest in Europe, after a controversial vote in parliament.The increase in retirement age was approved in the country\u2019s legislature, with 81 votes in favour and 21 against.The age of retirement has been tied to life expectancy in Denmark \u2013 currently 81.7 years \u2013 since 2006, with the government raising the threshold every five years.Under the Danish system, the retirement age will rise from 67 to 68 in 2030, and then 69 in 2035, and finally to 70 in 2040. The retirement age of 70 will only apply to Danes born after Dec 31, 1970.Mette Frederiksen, the Danish prime minister, has admitted that the sliding scale for retirement is not sustainable, and that a ne"
  },
  {
    "title": "Tariffs in American History (hillsdale.edu)",
    "points": 85,
    "submitter": "smitty1e",
    "submit_time": "2025-05-24T11:02:22 1748084542",
    "num_comments": 119,
    "comments_url": "https://news.ycombinator.com/item?id=44080237",
    "comments": [
      "There's an excellent book by economist Michael Hudson called \"America's Protectionist Takeoff\" that discusses how the US used tariffs to promote certain industries in order to compete on the world stage. It was part of Alexander Hamilton's American System. Friedrich List, the German economist that wrote \"The National System of Political Economy\", used the American System to advocate for the same policies in Germany. Germany eventually adopted these policies and became an economic powerhouse themselves. Likewise, Meiji Japan went so far as to adopt the ideas of Friedrich List's economic policies, which resulted in them becoming a great power in a generation.Tariffs can work, but only if they are targeted towards certain industries/sectors. They can't just be slapped across the board and be expected to work properly. Furthermore, they must be attached to certain KPIs such as exports (i.e., the ability to effectively compete on the international market). Joe Studwell's \"How Asia Works\" argues that Japan, Korea, and Taiwan all used tariffs and subsidies to promote their own \"national champions\". In turn, they forced those companies export their products rather than just sell domestically in order to compete. If they didn't meet those export targets, those companies were cut off from state support. Ha Joon Chang, a Korean developmental economist, likens this to raising a child: you spend their initial formative years supporting them until they are able to support themselves without your help.\n \nreply",
      "The last thing Trump's tariffs could be described as is targeted industrial policy. They are intentionally a sledge-hammer. They are intentionally emotional. Intentionally full of jingoistic rhetoric and victimhood rhetoric.Sadly there has been zero discussion of doing targeted industrial policy (like China's) in the US.  The irony is that Trump's approach benefits China tremendously.\n \nreply",
      "A sober approach to promoting the redevelopment of production industry in America would likely involve some tariffs and could make a lot of sense.But, yeah, the current American approach is anything but sober.\n \nreply",
      "There's been tons of discussion and several actual laws - IRA, CHIPS etc.A large part of why you're seeing the Trump insanity is because there's increasingly little connection between reality (ie CHIPS, IRA) and people's perception (ie your comment)\n \nreply",
      "What seems to be lost in these discussions is how the American system rides on global respect for American IP, and that this respect for IP is part of the whole global trade system.With global trade falling apart, this respect for IP is in grave danger. Robust IP protections contributed significantly to America's wealth.The short-sighted focus on tariffs and re-shoring manufacturing completely neglects the whole balance and will damage America's position long-term.\n \nreply",
      "> Robust IP protections contributed significantly to America's wealth.Quite the opposite, the US didn't enforce IP protections during the first few years of industrialization, exactly because they were stealing IP from England.\n \nreply",
      "I should clarify that I meant \"recently\". The US has exported extended copyright laws and other IP protections world-wide for their own benefit.\n \nreply",
      "You do realize that that was irrelevant long ago? That context has nothing to do with modern international trade.\n \nreply",
      "Ok, so when the US steals it's irrelevant, but when the situation is the opposite now is relevant??\n \nreply",
      "Why is hypocrisy brought up here? We are talking about national prosperity. Obviously what was beneficial to the US when it was a fledgling state is different than today\n \nreply"
    ],
    "link": "https://imprimis.hillsdale.edu/tariffs-in-american-history/",
    "first_paragraph": ""
  }
]