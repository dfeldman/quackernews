[
  {
    "title": "Mobile carriers can get your GPS location (dywa.ng)",
    "points": 459,
    "submitter": "cbeuw",
    "submit_time": "2026-01-31T17:21:34 1769880094",
    "num_comments": 301,
    "comments_url": "https://news.ycombinator.com/item?id=46838597",
    "comments": [
      "\"and notify the user when such attempts are made to their device.\"We aren't going to remove the security state. We should make all attempts to, but it won't happen. What needs to happen is accountability. I should be able to turn off sharing personal information and if someone tries I should be notified and have recourse. This should also be retroactive. If I have turned off sharing and someone finds a technical loophole and uses it, there should be consequences. The only way to stop the rampant abuse is to treat data like fire. If you have it and it gets out of control you get burned, badly.reply",
      "> We aren't going to remove the security stateWe definitely won't get rid of it if we accept failure. I get that it seems extremely unlikely, but there's no use in trying to just mitigate the risk short term. One way or another that power will be abused eventually (if it isn't already).reply",
      "> We aren't going to remove the security stateWhat security state?  They aren't doing this for anyone's safety.  This is the surveillance and parallel construction state.> What needs to happen is accountability.No agency can have this power and remain accountable.  Warrants are not an effective tool for managing this.  Courts cannot effectively perform oversight after the fact.> The only way to stop the rampant abuse is to treat data like fire.You've missed the obvious.  You should really go the other direction.  Our devices should generate _noise_.  Huge crazy amounts of noise.  Extraneous data to a level that pollutes the system beyond any utility.  They accept all this data without filtering.  They should suffer for that choice.reply",
      "> They aren't doing this for anyone's safety.Strictly speaking, this is not completely true. When you call an emergency number, it\u2019s very good that they can see exactly where you are. That was how this was sold 15+ years ago. But of course, that\u2019s basically the only use case when this should be available.reply",
      "Yet when I call emergency I must provide my location verbally, and then am usually contacted for a follow-up, because the guys cannot find the place. Don't get me wrong, I'm sure that this location technology works perfectly well: just not for the \"only use case when this should be available\".reply",
      "It is also useful for emergency services to double check you know the situation at hand and to cooperate with verification SOPs.reply",
      "Should it not be available with a valid court order as well?reply",
      "Slavery also took advantage of valid court orders. \u201cBecause it\u2019s the law\u201d is not enough. Our rights should always be the biased stance.reply",
      "Why? What is the rationale? Unless of course you subscribe to the idea that anything goes as long as a court decrees it, in which case there\u2019s nothing to debate really.reply",
      "Court approved warrants are pretty fundamental to how our legal system works and how some level of accountability is maintained. That system isn't perfect by any stretch, but removing it unlocks Pandoras box and I'm not sure we'd be better off without it.As it stands, a cop has to get a warrant to enter and search your home, for example. If we remove that hurdle because we also don't trust the courts then we just have more searches.I get the reaction to turn on the whole system, I have very little faith in it myself. But I don't think many people are really aware of or ready for what would come without it.reply"
    ],
    "link": "https://an.dywa.ng/carrier-gnss.html",
    "first_paragraph": "\n2026-01-31\nIn iOS 26.3, Apple introduced a new privacy feature which limits \u201cprecise location\u201d data made available to cellular networks via cell towers. The feature is only available to devices with Apple\u2019s in-house modem introduced in 2025. The announcement1 saysCellular networks can determine your location based on which cell towers your device connects to.This is well-known. I have served on a jury where the prosecution obtained location data from cell towers. Since cell towers are sparse (especially before 5G), the accuracy is in the range of tens to hundreds of metres2.But this is not the whole truth, because cellular standards have built-in protocols that make your device silently send GNSS (i.e. GPS, GLONASS, Galileo, BeiDou) location to the carrier. This would have the same precision as what you see in your Map apps, in single-digit metres.In 2G and 3G this is called Radio Resources LCS Protocol (RRLP)So the network simply asks \u201ctell me your GPS coordinates if you know them\u201d a"
  },
  {
    "title": "Scientist who helped eradicate smallpox dies at age 89 (scientificamerican.com)",
    "points": 111,
    "submitter": "CrossVR",
    "submit_time": "2026-01-28T10:03:11 1769594591",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=46793313",
    "comments": [
      "Paywall-free link: https://archive.today/Toq4Y",
      "That's got to be one of the greatest legacies in all human history. No politician or other empire-builder comes close.reply",
      "And it comes at a time when a disease we were working on eliminating, measles, has come back and the US is about to lose its measles-free status.It sounds as if his legacy is to be unique, a feat never to be accomplished again.reply",
      "Genghis Khan??reply",
      "Greatest, not most fuckedreply",
      "I don\u2019t think many people know about or remember the 2003 smallpox vaccination campaign.\u00b9> The campaign aimed to provide the smallpox vaccine to those who would respond to an attack, establishing Smallpox Response Teams and using DryVax (containing the NYCBOH strain) to mandatorily vaccinate half a million American military personnel, followed by half a million health care worker volunteers by January 2004. The first vaccine was administered to then-President George W. Bush.\u00b9 https://en.wikipedia.org/wiki/2003_United_States_smallpox_va...reply",
      "Nobody in Hn type circles wants to remember it because looking back with hindsight it was clearly just part of the theater to get people wringing their hands about whatever chemical or biological WMDs they alleged Saddam had and they killed the program as so as they got their invasion.Wikipedia somehow makes it eve worse than that:\"The campaign ended early in June 2003, with only 38,257 civilian health care workers vaccinated, after several hospitals refused to participate due to the risk of the live virus infecting vulnerable patients and skepticism about the risks of an attack, and after over 50 heart complications were reported by the CDC.\"reply",
      "Just in time to roll over in his grave.reply",
      "And to see himself become the villain.reply",
      "Yeah how dare he... helps eradicate diseases!reply"
    ],
    "link": "https://www.scientificamerican.com/article/smallpox-eradication-champion-william-foege-dies-at-89/",
    "first_paragraph": "January 26, 20262 min readScientist who helped eradicate smallpox dies at age 89A leader in the global fight against smallpox and a champion of vaccine science, William Foege died last SaturdayBy Jackie Flynn Mogensen edited by Claire CameronThe late physicians and health administrators William Foege (middle), J. Donald Millar (left) and J. Michael Lane (right), all of whom served in the Global Smallpox Eradication Program, in 1980.CDC/Smith Collection/Gado/Contributor/GettyJoin Our Community of Science Lovers!William Foege, a leader in the global fight to eliminate smallpox, has died. Foege passed away on Saturday at the age of 89, according to the Task Force for Global Health, a public health organization he co-founded.Foege headed the U.S. Centers for Disease Control and Prevention\u2019s Smallpox Eradication Program in the 1970s. Before the disease was officially eradicated in 1980, it killed around one in three people who were infected. According to the CDC, there have been no new smal"
  },
  {
    "title": "Generative AI and Wikipedia editing: What we learned in 2025 (wikiedu.org)",
    "points": 83,
    "submitter": "ColinWright",
    "submit_time": "2026-01-31T21:14:02 1769894042",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=46840924",
    "comments": [
      "> That means the article contained a plausible-sounding sentence, cited to a real, relevant-sounding source. But when you read the source it\u2019s cited to, the information on Wikipedia does not exist in that specific source. When a claim fails verification, it\u2019s impossible to tell whether the information is true or not.This has been a rampant problem on Wikipedia always. I can't seem to find any indicator that this has increased recently? Because they're only even investigating articles flagged as potentially AI. So what's the control baseline rate here?Applying correct citations is actually really hard work, even when you know the material thoroughly. I just assume people write stuff they know from their field, then mostly look to add the minimum number of plausible citations after the fact, and then most people never check them, and everyone seems to just accept it's better than nothing. But I also suppose it depends on how niche the page is, and which field it's in.reply",
      "People got into buggy crashes before automobiles, too, so I don\u2019t see why people keep complaining about road safety.reply",
      "There was a fun example of this that happened live during a recent episode of the Changelog[1]. The hosts noted that they were incorrectly described as being \"from GitHub\" with a link to an episode of their podcast which didn't substantiate that claim. Their guest fixed the citation as they recorded[2].[1]: https://changelog.com/podcast/668#transcript-265[2]: https://en.wikipedia.org/w/index.php?title=Eugen_Rochko&diff...reply",
      "LLMs can add unsubstantiated conclusions at a far higher rate than humans working without LLMs.reply",
      "At some point you're forced to either believe that people have never heard of the concept of a force multiplier, or to return to Upton Sinclair's observation about getting people to believe in things that hurt their bottom line.reply",
      "The problems I've run into is both people giving fake citations (the citations don't actually justify the claim that's being made in the article), and people giving real citations, but if you dig into the source you realize it's coming from a crank.It's a big blind spot among the editors as well. When this problem was brought up here in the past, with people saying that claims on Wikipedia shouldn't be believed unless people verify the sources themselves, several Wikipedia editors came in and said this wasn't a problem and Wikipedia was trustworthy.It's hard to see it getting fixed when so many don't see it as an issue. And framing it as a non-issue misleads users about the accuracy of the site.reply",
      "When I've checked Wikipedia citations I've found so much brazen deception - citations that obviously don't support the claim - that I don't have confidence in Wikipedia.> Applying correct citations is actually really hard work, even when you know the material thoroughly.Why do you find it hard? Scholarly references can be sources for fundamental claims, review articles are a big help too.Also, I tend to add things to Wikipedia or other wikis when I come across something valuable rather than writing something and then trying to find a source (which also is problematic for other reasons). A good thing about crowd-sourcing is that you don't have to write the article all yourself or all at once; it can be very iterative and therefore efficient.reply",
      "It's not that I personally find it hard.It's more like, a lot of stuff in Wikipedia articles is somewhat \"general\" knowledge in a given field, where it's not always exactly obvious how to cite it, because it's not something any specific person gets credit for \"inventing\". Like, if there's a particular theorem then sure you cite who came up with it, or the main graduate-level textbook it's taught in. But often it's just a particular technique or fact that just kind of \"exists\" in tons of places but there's no obvious single place to cite it from.So it actually takes some work to find a good reference. Like you say, review articles can be a good source, survey articles or books. But it can take a surprising amount of effort to track down a place that actually says the exact thing. I literally just last week was helping a professor (leader in their field!) try to find a citation during peer review for their paper for an \"obvious fact\" in the field, that was in their introduction section. It was actually really challenging, like trying to produce a citation for \"the sky is blue\".I remember, years ago, creating a Wikipedia article for a particular type of food in a particular country. You can buy it at literally every supermarket there. How the heck do you cite the food and facts about it? It just... is. Like... websites for manufacturers of the food aren't really citations. But nobody's describing the food in academic survey articles either. You're not going to link to Allrecipes. What do you do? It's not always obvious.reply",
      "The title I've chosen here is carefully selected to highlight one of the main points.  It comes (lightly edited for length) from this paragraph:Far more insidious, however, was something else we discovered:More than two-thirds of these articles failed verification.That means the article contained a plausible-sounding sentence, cited to a real, relevant-sounding source. But when you read the source it\u2019s cited to, the information on Wikipedia does not exist in that specific source. When a claim fails verification, it\u2019s impossible to tell whether the information is true or not. For most of the articles Pangram flagged as written by GenAI, nearly every cited sentence in the article failed verification.reply",
      "People here are claiming that this is true of humans as well. Apart from the fact that bad content can be generated much faster with LLMs, what's your feeling about that criticism? It's there any measure of how many submissions before LLMs make unsubstantiated claims?Thank you for publishing this work. Very useful reminder to verify sources ourselves!reply"
    ],
    "link": "https://wikiedu.org/blog/2026/01/29/generative-ai-and-wikipedia-editing-what-we-learned-in-2025/",
    "first_paragraph": "Like many organizations, Wiki Education has grappled with generative AI, its impacts, opportunities, and threats, for several years. As an organization that runs large-scale programs to bring new editors to Wikipedia (we\u2019re responsible for about\u00a019% of all new active editors on English Wikipedia), we have deep understanding of what challenges face new content contributors to Wikipedia \u2014 and how to support them to successfully edit. As many people have begun using generative AI chatbots like ChatGPT, Gemini, or Claude in their daily lives, it\u2019s unsurprising that people will also consider using them to help draft contributions to Wikipedia. Since Wiki Education\u2019s programs provide a cohort of content contributors whose work we can evaluate, we\u2019ve looked into how our participants are using GenAI tools.We are choosing to share our perspective through this blog post because we hope it will help inform discussions of GenAI-created content on Wikipedia. In an open environment like the Wikimedi"
  },
  {
    "title": "In Praise of \u2013dry-run (henrikwarne.com)",
    "points": 54,
    "submitter": "ingve",
    "submit_time": "2026-01-31T20:42:13 1769892133",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=46840612",
    "comments": [
      "I like the opposite too, -commit or -execute as it is assumed running it with defaults is immutable as the dry run, simplifying validation complexity and making the go live explicit.reply",
      "Yeah I'm more of a `--wet-run` `-w` fan myself. But it does depend on how serious/annoying the opposite is.reply",
      "I've biased towards this heavily in the last 8 or so years now.I've yet to have anyone mistakenly modify anything when they need to pass --commit, when I've repeatedly had people repeatedly accidentally modify stuff because they forgot --dry-run.reply",
      "In order to make it work without polluting the code-base I find that I have to move the persistence into injectable strategy, which makes it good anyway. If you keep passing in `if dry_run:` everywhere you're screwed.Also, if I'm being honest, it's much better to use `--wet-run` for the production run than to ask people to run `--dry-run` for the test run. Less likely to accidentally fire off the real stuff.reply",
      "One nice way to do things, if you can get away with it, is to model the actions your application takes explicitly, and pass them to a central thing that actually handles them. Then there can be one place in your code that actually needs to understand whether it's doing a dry run or not. Ideally this would be just returning them from your core logic, \"functional core, imperative shell\"  style.reply",
      "I totally agree with both this and the comment you replied to. The common thread is that you can architect the application in such a way that dry vs. wet running can be handled transparently, and in general these are just good designs.reply",
      "I don't want to have to type rm --wet-run tempfile.tmp every time, or mkdir -p --yes-really-do-it /usr/local/binThe program should default to actually doing whatever thing you're asking it to do.On the other hand it would be great if every tool had an --undo argument that would undo the last thing that program did.reply",
      "That undo program is called nilfs2, which unfortunately never became popular. I'll simply quote the kernel docs:> NILFS2 is a log-structured file system (LFS) supporting continuous snapshotting. In addition to versioning capability of the entire file system, users can even restore files mistakenly overwritten or destroyed just a few seconds ago.https://docs.kernel.org/filesystems/nilfs2.htmlhttps://wiki.archlinux.org/title/NILFS2https://en.wikipedia.org/wiki/NILFSreply",
      "Sure, in those cases - but if a command has a chance of nuking prod, you want some extra step in there. Preferably something that can't be muscle-memoried through.reply",
      "I don't like the sound of `--wet-run`, but on more than one occasion I've written tools (and less frequently services) that default to `dry-run` and require `--no-dry-run` to actually make changes.For services, I prefer having them detect where they are running. Ie if it's running in a dev environment, it's going to use a dev db by default.reply"
    ],
    "link": "https://henrikwarne.com/2026/01/31/in-praise-of-dry-run/",
    "first_paragraph": "For the last few months, I have been developing a new reporting application. Early on, I decided to add a \u2013dry-run option to the run command. This turned out to be quite useful \u2013 I have used it many times a day while developing and testing the application.The application will generate a set of reports every weekday. It has a loop that checks periodically if it is time to generate new reports. If so, it will read data from a database, apply some logic to create the reports, zip the reports, upload them to an sftp server, check for error responses on the sftp server, parse the error responses, and send out notification mails. The files (the generated reports, and the downloaded feedback files) are moved to different directories depending on the step in the process. A simple and straightforward application.Early in the development process, when testing the incomplete application, I remembered that Subversion (the version control system after CVS, before Git) had a \u2013dry-run option. Other l"
  },
  {
    "title": "Opentrees.org (2024) (opentrees.org)",
    "points": 14,
    "submitter": "surprisetalk",
    "submit_time": "2026-01-27T21:33:28 1769549608",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://opentrees.org/#pos=1/-37.8/145",
    "first_paragraph": ""
  },
  {
    "title": "Demystifying ARM SME to Optimize General Matrix Multiplications (arxiv.org)",
    "points": 62,
    "submitter": "matt_d",
    "submit_time": "2026-01-31T20:05:22 1769889922",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=46840252",
    "comments": [
      "I don\u2019t get why they didn\u2019t compare against BLIS. I know you can only do so many benchmarks, and people will often complain no matter what, but BLIS is the obvious comparison. Maybe BLIS doesn\u2019t have kernels for their platform, but they\u2019d be well served by just mentioning that fact to get that question out of the reader\u2019s head.BLIS even has mixed precision interfaces. But might not cover more exotic stuff like low-precision ints? So this paper could have had a chance to \u201cput some points on the board\u201d against a real top-tier competitor.reply",
      "Section VII.3 has:> Libraries such as BLIS [19] lack SME\nsupport and are therefore excluded from comparison.reply",
      "Ah, reading comprehension failure on my partreply",
      "BLIS doesn't appear to support SME: https://github.com/search?q=repo%3Aflame%2Fblis+mopa&type=co...Maybe you want a comparison anyways, but it won't be competitive. On Apple CPUs, SME is ~8x faster than a single regular CPU core with a good BLAS library.reply",
      "ARM SME as implemented on the Apple M4 is quite interesting. Super useful for matrix math (as this paper illustrates well), but my attempts at using the SSVE extension for vector math were an utter failure for performance, despite the increased vector width (512 bits vs. 128 bits for NEON). Potentially the switch into/out of streaming mode is too expensive, but my microbenchmarks indicated the SSVE instructions themselves just didn't have great throughput.reply",
      "SSVE instructions are executed by the SME engine, which trades latency for throughput. SSVE is really intended to support use of SME, rather than as a replacement for Advanced SIMD on the CPU core itself.The Apple Silicon CPU Optimization Guide has a lot of great information on SME and SSVE, along with more general information on optimizing for Apple's CPUsA few quotes from Apple's guide that are particularly relevant to SSVE, from \"SSVE Vector Execution Unit Optimization\":> Broadly, this unit is designed to support long vector and matrix operations performed on\nZA storage _in the SME Processing Grid_.> Recommendation: Use SSVE in a supporting role to enable high throughput SME grid computation.> [Magnitude: High | Applicability: High] SSVE offers wide 64B vectors. While the ISA includes instructions that can operate on multi-vectors, the throughput is often only one 64B vector per cycle. Use SSVE to enable SME, which offers higher parallelism.> Because of non-speculative execution, communication latencies, and in some cases long memory and computation latencies, SME engine instructions trail execution in the core by dozens to thousands of cycles. Any core compute instructions that consume data produced by the SME engine may have to wait an indeterminate (but long) amount of time for the data to arrive.reply",
      "I was struck by the \"Magnitude: High | Applicability: High\" bit. Who writes like this? More importantly, who reads like this? The V4 doc (which I have yet to read, but I did a text search) has 64 occurences of this sort of phrasing; not actually all that many, given that there's 293 pages, but enough to be interesting. I wonder if this extra stuff is there to make LLMs pay particular attention.reply",
      "Intel's software optimization guides have similar annotations on many of their guidelines, and have done since long before LLMs were a thing. As a reader it's useful to know how impactful a given recommendation is and how generally applicable it is without having to read the more detailed explanations.reply",
      "Ahh, interesting, thanks. (I read the reference manuals but typically ignore the rest... I don't need to write this stuff, just read it!) I've seen people recommend creating docs to be LLM-friendly and I was wondering if this was an instance of that.reply",
      "That makes a ton of sense and aligns with my observations. Thanks for the resource :)If SSVE is slow, I was hoping that SME instructions could be used in a vector-like fashion (e.g. add two matrices with high throughput, or a Hadamard/element-wise product) but it seems most matrix accelerator ISAs don't have that.reply"
    ],
    "link": "https://arxiv.org/abs/2512.21473",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n"
  },
  {
    "title": "The Saddest Moment (2013) [pdf] (usenix.org)",
    "points": 81,
    "submitter": "tosh",
    "submit_time": "2026-01-31T20:02:36 1769889756",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46840219",
    "comments": [
      "Bitcoin did two things to this paper, first it demonstrates that Byzantine fault tolerance has practical applications, and second it demonstrates that anytime you have to deal with Byzantine fault tolerance the question is not \"How do I verify this message?\" but \"Why am I trying to deal with those assholes?\"reply",
      "Hey man, leave Keanu out of thisreply",
      "\"Listen, regardless of which Byzantine fault tolerance protocol you pick, Twitter will still have fewer \nthan two nines of availability. As it turns out, Ted the Poorly \nPaid Datacenter Operator will not send 15 cryptographically \nsigned messages before he accidentally spills coffee on the air \nconditioning unit.\"reply",
      "This is one of my favorite quotes from technical comedic writing> \u201cHow can you make a reliable computer service?\u201d the presenter will ask in an innocent voice before continuing, \u201cIt may be difficult if you can\u2019t trust anything\nand the entire concept of happiness is a lie designed by unseen overlords of\nendless deceptive power.\u201dIf you didn't know Mickens[0] and you enjoyed this piece, you may want to peruse more of the same[1]. They're not all this good, but they are good.[0] which I discovered through HN years ago, thanks folks\n[1] https://danielcompton.net/james-mickens-collectionreply",
      "Also just found this thanks to another user.https://mickens.seas.harvard.edu/wisdom/reply",
      "Mickens is the best!reply",
      "I don't actually care about byzantine fault tolerance.  But, James Mickens wrote it?  I'm reading.reply",
      "The Night Watch... https://www.usenix.org/system/files/1311_05-08_mickens.pdf is one of my all time favorite pieces of internet writingreply",
      "Can you believe there are people out there who haven't read this yet? I can, because one of them was me. This was incredible.> A systems programmer will know what to do when\nsociety breaks down, because the systems programmer already lives in a\nworld without law.reply",
      "Me also, I found Mickens through his Harvard Tenure post, but somehow just found Night's Watch today.reply"
    ],
    "link": "https://www.usenix.org/system/files/login-logout_1305_mickens.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Data Processing Benchmark Featuring Rust, Go, Swift, Zig, Julia etc. (github.com/zupat)",
    "points": 58,
    "submitter": "behnamoh",
    "submit_time": "2026-01-31T20:50:56 1769892656",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=46840698",
    "comments": [
      "Isn't that measuring the speed of json encoding instead?reply",
      "I was surprised to see that Java was slower than C++, but the Java code is run with `-XX:+UseSerialGC`, which is the slowest GC, meant to be used only on very small systems, and to optimise for memory footprint more than performance. Also, there's no heap size, which means it's hard to know what exactly is being measured. Java allows trading off CPU for RAM and vice-versa. It would be meaningful if an appropriate GC were used (Parallel, for this batch job) and with different heap sizes. If the rules say the program should take less than 8GB of RAM, then it's best to configure the heap to 8GB (or a little lower). Also, System.gc() shouldn't be invoked.Don't know if that would make a difference, but that's how I'd run it, because in Java, the heap/GC configuration is an important part of the program and how it's actually executed.Of course, the most recent JDK version should be used (I guess the most recent compiler version for all languages).reply",
      "It\u2019s so hard to actually benchmark languages because it so much depends on the dataset, I am pretty sure with simdjson and some tricks I could write C++ (or Rust) that could top the leaderboard (see some of the techniques from the billion row challenge!).tbh for silly benchmarks like this it will ultimately be hard to beat a language that compiles to machine code, due to jit warmup etc.It\u2019s hard to due benchmarks right, for example are you testing IO performance? are OS caches flushed between language runs? What kind of disk is used etc? Performance does not exist in a vacuum of just the language or algorithm.reply",
      "C# is very fast (see multicore rating). Implementation based on simd (vector), memory spans, stackalloc, source generators and what have you \u2014 modern C# allows you go very low-level and very fast.Probably even faster under .net 10.Though using stopwatch for benchmark is killing me :-) Wonder if multiple runs via benchmarkdotnet would show better times (also due to jit optimizations). For example, Java code had more warm-up iterations before measuringreply",
      "D gets no respect. It's a solid language with a lot of great features and conveniences compared to C++ but it barely gets a passing mention (if that) when language discussions pop up. I'd argue a lot of the problems people have with C++ are addressed with D but they have no idea.reply",
      "I see some questions around the methodology of the testing. But is this representative of Ruby? Several minutes total when most finish under a second?reply",
      "This entire benchmark is frankly a joke. As other commenters have pointed out, the compiler flags make no sense, they use pretty egregious ways to measure performance, and ancient versions are being used across the board. Worst of all, the code quality in each sample is extremely variable and some are _really_ bad.reply",
      "I mean this is only meant to be an iteration if I understand correctly. Its not like someone is going around citing this benchmark yelling rewrite everything in Julia / D. Imo this is a good starting point if you are doubtful or fall into the trap of Java is not fast. For most workloads we can clearly see, Java trades off the control of C++ for \"about the same speed\" and much much larger and well managed ecosystem. (Except for the other day, when someones OpenJDK PR was left hanging for a month which I am not sure why).reply",
      "This is really interesting. Julia is a beast compared to python.Nowadays whenever I see benchmarks of different languages. I really compare it to benjdd.com/languages or benjdd.com/languages2Ended up creating a visualization of this data if anybody's interestedhttps://serjaimelannister.github.io/data-processing-benchmar...(Given credits to both sources in the description of this repo)(Also fair disclosure but it was generated just out of curiosity of how this benchmark data might look if it was on benjdd's ui and I used LLM's for this use case for prototyping purposes. The result looks pretty simiar imo for visualization so full credits to benjdd's awesome visualization, I just wanted this to be in that to see for myself but ended up having it open source/on github pages)I think benjdd's on hackernews too so hi ben! Your websites really cool!reply",
      "Someone replied to me in an old comment that for fast Python you have to use numpy. In the folder there is a program in plain python, another with numpy and another with numba. I'm not sure why only one is shown in the data.Disclaimer: I used numpy and numba, but my level is quite low. Almost as if I just type `import numpy as np` and hope the best.reply"
    ],
    "link": "https://github.com/zupat/related_post_gen",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Data Processing benchmark featuring Rust, Go, Swift, Zig, Julia etc.\n      Given a list of posts, compute the top 5 related posts for each post based on the number of shared tags.Uses specialized datastructures meant for demonstration purposes: more \u21a9 \u21a92\n        Data Processing benchmark featuring Rust, Go, Swift, Zig, Julia etc.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Show HN: Minimal \u2013 Open-Source Community driven Hardened Container Images (github.com/rtvkiz)",
    "points": 70,
    "submitter": "ritvikarya98",
    "submit_time": "2026-01-31T19:58:00 1769889480",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=46840178",
    "comments": [
      "What is the process to trust the usage of this?How can we learn the identity of the contributors? How are the contributors vetted? How are we notified if a significant change in leadership happens?It's just a general problem when relying on GitHub accounts for important code.For some reason I trust the big vendors to have better safe-guards against things like the questions above. Such as aws linux containers etc..Would love to hear how other people think around this.reply",
      "I have been curious on secure base images for the AI ecosystem, where we need to ship with cuda 11.8/12.8/13.1 for stability reasons, and in our case, a bit of the torch ecosystem and Nvidia rapids ecosystem. That ends up being... A lot. Extra fun: going all the way to FIPS..reply",
      "I'm not sure what problem this is solving. This seems like chainguard but being built in \"your ci\" (github) vs \"their ci\". Images may be a bit smaller, but this is already a feature set that wolfi already allows for. Besides that chainguard is not full-source bootstrapped.reply",
      "From reading the project readme, I think this demonstrates creating any image you want using Chainguard's tools including commercial ones.reply",
      "Dumb question but how would these work in practice? I use kamal to deploy containerized applications. Would I on a regular basis update the versions of the underlying images to match the latest hardened container and then redeploy? I assume this is automatable?reply",
      "Hi thanks for looking - I would preferably more info on your setup, but this is similar to using any container image. Currently all the tags are latest and if you have that setup you would pick that up from this repo and pretty sure this can be automated.reply",
      "Why does this not use chisel? I assume you at least drop the bin dir? Although the presence of ncurses is super weirdI don't understand why one would go halfway and leave packages which are unneeded for services. The only executable in a hardened container image should be your application.reply",
      "Thanks! but these are builder images, not the final runtime. Chisel only really makes sense after the binary is built and you know what it needs at runtime. Before that you are pulling in whole packages, which is why things like ncurses might show up, similar to chainguard's image. For a builder, it is just SBOM noise and not something the app ever executes. Its hard to identify what you need before running the application, and you can always find a library you don't need.\nThe \u201conly your app should be executable\u201d idea works for fully static binaries, but once you use glibc or CGO you already have other executables.reply",
      "This is great. I have been talking to quite some vendors in the space. I have looked in docker hardened images too. They have made it free too.I think the problem in general is hardened image market is keeping up with CVEs and making sure the catalog is vast so that it covers all the images and nuances.Responding and patchibg CVEs with an SLA is the KPI of the vendors. As much as I would like cheer for you, doing it as an opensource initiate with a guaranteed SLA is going to be painful for you as maintainer without profit as a motive.reply",
      "Thanks for looking into this! I agree with you and hence I'm also relying on Wolfi packages, which will ensure they are updated as soon as upstream is available so I'm piggy backing on that. Github Actions run daily/weekly based on the cadence and once the pipeline is setup do not require a significant effort imo. And I want it to be community driven so we can add images as and when people want it and build it accordingly. Chainguard tools surely help with this! I aim to show that companies can try and build internal pipelines like this for all images in their repositoryreply"
    ],
    "link": "https://github.com/rtvkiz/minimal",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Minimal CVE Hardened container image collection\n      A collection of production-ready container images with minimal CVEs, rebuilt daily using Chainguard's apko and Wolfi packages. By including only required packages, these images maintain a reduced attack surface and typically have zero or near-zero known vulnerabilities.*HTTPD, Jenkins,Node.js may include shell(sh,busybox) via transitive Wolfi dependencies. CI treats shell presence as informational.Container vulnerabilities are a top attack vector. Most base images ship with dozens of known CVEs that take weeks or months to patch:Impact:All builds must pass a CVE gate (no CRITICAL/HIGH severity vulnerabilities) before publishing.All images are signed with cosign keyless signing via Sigstore. To verify:Replace minimal-python with any image name. A successful output confirms the ima"
  },
  {
    "title": "Wikipedia: Sandbox (wikipedia.org)",
    "points": 57,
    "submitter": "zaptrem",
    "submit_time": "2026-01-30T21:12:01 1769807521",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=46829965",
    "comments": [
      "It's interesting to think about how complex the wikipedia text is compared to something like github flavored markdown or even standard html tables (although I guess it eventually renders into standard html so it's not more complex than the latter when all other html elements are considered in addition to <table>)For example the swatch internet time infobox is dynamically updated{{short description|Alternate time system by watch maker Swatch}}\n{{Infobox\n| image = [[File:Swatch beat Logo.svg|200px|alt=Logo of Swatch Internet Time]]\n| caption = Logo of Swatch Internet Time\n| title = Time{{efn|at page generation }} {{purge|(update to view correct time)}}\n| label1 = 24-hour time (UTC)\n| data1 = {{nowrap|{{#time:H:i:s}}}}\n| label2 = 24-hour time (CET)\n| data2 = {{Time|CET|dst=no|df-cust=H:i:s|hide-refresh=yes}}\n| label3 = .beat time (BMT)\n| data3 = {{nowrap|@{{#expr: floor( {{#expr:{{#expr:{{#expr:{{#time:H|now + 1 hour}}3600}}+{{#expr:{{#time:i}}60}}+{{#time:s}}}}/86.4}} )}}}}\n}}reply",
      "I always found it ironic that the table syntax is designed to resemble ascii-art type tables, and then literally nobody writes it in a way that looks like an ascii art table.reply",
      "Yeah, because it\u2019s a PITA to align everything by hand.But the spaces around | make it easier to read, than, say, CSV.reply",
      "I\u2019ve spent countless hours at employers fixing Xwiki syntax errors mixed with HTML. The parsing engine must be complexreply",
      "I just went back to check whether I have a sandbox on Wikipedia. Turns out I do: <https://en.wikipedia.org/wiki/User:Susam_Pal/sandbox>.I am not a regular contributor to Wikipedia but the little time I have spent contributing there has exposed me to its very elaborate culture, with barnstars being one artefact of that culture, alongside policy acronyms everyone seems to know by heart, WikiProjects organised around every imaginable topic, userboxes that are little badges that say something about you, etc.By the way, I added a few userboxes for the Logo programming language, in case there are any Wikipedians out here who also happen to know Logo: <https://en.wikipedia.org/wiki/Category:User_logo>.reply",
      "Pretty much all wikis would have a \"Sandbox\" page for trying out that particular wiki's individual syntax and features.reply",
      "There are both, every user has their own sandbox. But this one is there to encourage first time visitors and the uninitiated to make changes , so they know that anyone can contribute uninhibited.reply",
      "Though, just to be clear, the per-user ones are also public. They're just a convention where if you make a subpage of your user page and call it \"Sandbox\", nobody is going to complain about the encyclopedic value of your edits.reply",
      "If you really want something private, there is https://en.wikipedia.org/wiki/Special:ExpandTemplates  (or of course just hit preview and dont save)reply",
      "True , though I just discovered category scans still hit your user sandbox.  Kind of sillyreply"
    ],
    "link": "https://en.wikipedia.org/wiki/Wikipedia:Sandbox",
    "first_paragraph": ""
  },
  {
    "title": "Ferrari vs. Markets (enigmatechnologies.dev)",
    "points": 37,
    "submitter": "merinid",
    "submit_time": "2026-01-29T19:25:32 1769714732",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=46815209",
    "comments": [
      "I don't think this plot is very convincing. I will grant there's a feasible path that would imply causation, and Ferrari imports have increased just as BTC, SP500, and NASDAQ have. But aside from the macro-trend, the oscillations in the Ferrari import lines really don't seem to correlate with those investments. In fact, if you ran a linear regression on the numbers I bet you would find a _weak_ dependence. I can give you other things that correlate with BTC's move just about as much as Ferrari's do, just by manually looking for examples. For example, google search trends for 'electric vehicle'[1] and 'seed oil'[2] are both pretty close.[1] https://trends.google.com/explore?q=electric%2520vehicle&dat...[2] https://trends.google.com/explore?q=seed%2520oil&date=2020-0...reply",
      "There was a sharp rise in demand/value since 2020 on cars like the 355 and 550, and some bit rarer but still significant in number cars like the 360 Challenge Stradale and 430 Scuderia. Especially for the 355 and 550, which exist in significant numbers, before 2020 these cars were $70-100k, but now with nice examples going from $150k-225k, it can make a lot more sense to import one from a softer market like Europe or Japan (especially since Japanese market examples are often extremely well kept and LHD), even if the cost of importing is $10-20k.Check the results here - https://bringatrailer.com/ferrari/550-maranello/\nExample EU market car, imported 2023 - https://bringatrailer.com/listing/1999-ferrari-550-maranello...\nJP market car, imported to Canada 2018 then US in 2024 - https://bringatrailer.com/listing/1999-ferrari-550-maranello...reply",
      "Every cargo shipment entering the U.S. generates a customs manifest\u2014product descriptions, quantities, ports, shippers, and declared values. 8,818 Ferraris were detected in U.S. customs data from 2020\u20132026, averaging 121 per month. Import volumes correlate with Bitcoin (+0.70), S&P 500 (+0.74), and NASDAQ (+0.68).reply",
      "Interesting correlation. Can we infer from this that Ferraris are typically purchased by people whose income comes from investments rather than salaries?reply",
      "I think for a new Ferrari there\u2019s a fair chance it\u2019s salaried individuals. There are quite a few folks who probably make enough to purchase a $400k-$800k car from their salaries. For ultra rare or special variants I think it\u2019s unlikely as the percentage of someone\u2019s net worth would likely be entirely consumed by the vehicle even at several million dollars a year. An example is an Enzo that sold this year for $17.6 million: https://www.thesupercarblog.com/ferrari-enzo-sells-for-a-rec...FWIW\u2014- that whole collection of cars, including the Enzo are 1 of 1 builds and it\u2019s still shocking someone paid that much for a car with an absolutely heinous interior. I get it is unique, but it\u2019s crazy someone paid that much for the privilege of owning the ugliest interior ever put in an Enzo. Reminds of the Ronald McDonald Viper from the mid 90s.reply",
      "I mean an F50 went for $9M at Sotheby\u2019s last year. That\u2019s probably enough info to rule out salaried work.reply",
      "Appreciate you adding the correlations. Wow, those are higher than I would have thought.reply",
      "I highly doubt they did this correlation properly. It looks like they just correlated two time series. Both series are correlated with time (both go up over time) and not each other. I eyeballed the series and correlated just the directions, when BTC goes up, it is 50/50 whether or not imports went up. I am pretty sure this correlation would be near 0 if you detrended the time series.reply",
      "I'd love to know how many of these are direct from Maranello and how many of these are second hand. Ferrari doesn't sell directly to anyone unless you have a \"relationship\" with them. New models are highly restricted, it's not like you can just walk into a showroom so you can buy one even if you have all the money.reply",
      "You can absolutely walk into a showroom and buy one. Not a rare model but you could walk in with no relationship and buy a 296 now.I'd suspect many of them are - almost all go through new jersey if I remember correctly - with many going to Ferrari North America (FNA)reply"
    ],
    "link": "https://ferrari-imports.enigmatechnologies.dev/",
    "first_paragraph": ""
  },
  {
    "title": "Nintendo DS code editor and scriptable game engine (crl.io)",
    "points": 94,
    "submitter": "Antibabelic",
    "submit_time": "2026-01-31T18:27:36 1769884056",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=46839215",
    "comments": [
      "Yesssss this is right up my alley with my current projects. I'm working through K&R 2nd Ed and making little demo apps with libnds using framebuffer manipulation for graphics along the way. My goal is to eventually end up with a useful 15bit sprite-ing application, and an endless scrolling handwriting journal thingy with bookmarks. Thank You for posting this! I'm loading this onto my DSi XL right now.reply",
      "The Nintendo DS (lite or XL) is probably the greatest portable gaming system to ever exist.reply",
      "Honestly I'd say that's the New 3DS XL.reply",
      "Agreed over the dsi, though I love it. The only exception is if you only play physical media, then the DS lite's ability to play the entire GBA library is pretty cool.For me it's the fact that I can emulate basically all retro consoles on the n3ds, including imo the best existent way to play VirtualBoy games in actual stereoscopic 3d. That on top of the fact that it's the only way to play 3ds games in the native experience, with 3d, which is impossible on any emulator. Combined with the social features and build quality of the device, and it's unbeatable. Get a USB 3ds charger and it's the perfect travel console. I bring it on every trip and leave it on streetpass mode. Especially for Japan trips, I still to this day pick up new street pass pings, which is so incredibly delightful to find when I get back to the hotel room.Though I prefer the non xl version, as it's a truly portable console rather than the XL which is huge and heavy in my bag.reply",
      "I'm not sure. At least for me, part of the charm of these older consoles (do they qualify for the \"retro\" term yet?) is the smaller resolution of the displays. Especially for the bottom screen on the DS line, there is something very warm, fuzzy, and cosy about clearly being able to see each individual pixel.Perhaps it's just nostalgia. I still own my DS Lite, though.reply",
      "The best music is always from ones own youthreply",
      "The scripting language looks like it would be more cumbersome to use than C.reply",
      "I did a double-take at    > Executes one line of script per frame (~60 lines/sec).\n\nMakes the \"runs at 60FPS\" aspect of the engine feel a lot less relevant. At this speed, anything more complex than Pong would be a struggle. Even a CHIP-8 interpreter is usually expected handle a dozen or so comparably expressive instructions per frame.reply",
      "Which is why I love this. Extreme constraints. Takes a lot of creativity to make something interesting, without feeling overwhelmed with possibility. I'm considering making tiny arthouse game projects with this.reply",
      "Don\u2019t worry, you can\u2019t have that many lines anyway\u2026> Up to 128 script lines per programreply"
    ],
    "link": "https://crl.io/ds-game-engine/",
    "first_paragraph": ""
  },
  {
    "title": "Finland to end \u201cuncontrolled human experiment\u201d with ban on youth social media (yle.fi)",
    "points": 505,
    "submitter": "Teever",
    "submit_time": "2026-01-31T17:06:22 1769879182",
    "num_comments": 356,
    "comments_url": "https://news.ycombinator.com/item?id=46838417",
    "comments": [
      "Modern social media is nothing like social media in early days (myspace, early Facebook and even early Instagram). Back then it was a platform to communicate with friends, and maybe even find new friends to meet up with.Today social media is more like a drug, to keep the user engaged and to push content to them. The content must either be addictive/engaging or paid advertisements. Quality of the content doesn't matter at all. Connecting people to do stuff outside of the virtual world would actually hurt their business model. People turn off their devices and go outside, instead of watching ads.So it's probably fine to just block the big platforms. Forums or messengers (without ads and public channels) are probably fine. Probably even Reddit - which does have an algorithm to show specific content - is not as bad.reply",
      "Reddit has been a cesspit of recycled pablum, populist image macros and low effort reply comments for more than a decade. Enthusiast subreddits are astroturfed to hell and back by people with a Shopify storefront and a dream trying to growth hack their way to a hockey stick. The low barrier to entry to each community means that this vapid culture eventually diffuses itself across subreddits that might otherwise be good. It's a postmodern toilet that flushes into its own tank.I don't care if I sound old and salty when I say this: I miss phpBB and Invision forums. Even those are being bought up by marketing companies to sell ads and transformed with social media features... Xenforo (which everybody uses now) allows liking posts and supports Instagram-style content feeds.reply",
      ">Xenforo (which everybody uses now) allows liking posts and supports Instagram-style content feeds.On spacebattles you get infracted for chan-like (or instagram-like) behaviour. It's all about how strict moderation is. They do allow likes (but there's no algo)reply",
      "> I miss phpBB and Invision forums.As someone who's paid for an Invision Power Board licence before: I remember when they screwed all existing \"lifetime/perpetual\" licence holders with v3, and once again with v4.reply",
      "Agreed. I wish they would consider charging a small fee (~$1) to create an account. That alone would cut down on all the AI spam and give subreddit moderators a fighting chance.reply",
      "> give subreddit moderators a fighting chanceModerators are part of the problem really, there are a handful of moderators holding the reins over all the popular subreddits, and \"smaller\" (even big ones) subreddits suffer from the same problem.As an example, r/MistralAI, r/LocalLLaMA, r/ChatGPT, r/OpenAI and r/grok are all run by the same person.The only survivable places on reddit left are the subreddits with small amount of contributors that aren't trying to gain something by participating and organizing. But they're so few.reply",
      "> But they're so few.Given how many subreddits there, I have to ask if you have statistics to back up this claim.My intuition is that people have problems with a bunch of popular subreddits, but the vast majority of subreddits are just fine. I have no statistics to back up this intuition.Do you?reply",
      "There\u2019s a whole vibrant industry of people you can pay to market whatever you want on Reddit. They can\u2019t all be competing for the same few popular subreddits. They must be differentiated by targeting niche subreddits.reply",
      "There's about 138,000 active subreddits. I don't believe that this industry is targetting even a majority of them.reply",
      "Comment that you replied to reads like someone from 2008\u2019s ideas about the internet. Incredibly naive.reply"
    ],
    "link": "https://yle.fi/a/74-20207494",
    "first_paragraph": "Current topicsPrime Minister Petteri Orpo (NCP), the Finnish public health authority THL and two-thirds of Finns are in favour of banning or restricting the use of social media by under-15s.Lunch break at the Finnish International School of Tampere (FISTA) is a boisterous time.The yard is filled with children \u2014 ranging from grades 1 to 9, or ages 6 to 16 \u2014 running around, shouting, playing football, shooting basketball hoops, doing what kids do.And there's not a single screen in sight.FISTA has taken advantage of the law change, brought in last August, which allows schools to restrict or completely ban the use of mobile phones during school hours. At FISTA, this means no phones at all unless specifically used for learning in the classroom.\"We've seen that cutting down on the possibilities for students to use their phones, during the breaks for instance, has spurred a lot of creativity,\" FISTA vice principal Antti Koivisto notes.\"They're more active, doing more physical things like play"
  },
  {
    "title": "Noctia: A sleek and minimal desktop shell thoughtfully crafted for Wayland (github.com/noctalia-dev)",
    "points": 38,
    "submitter": "doener",
    "submit_time": "2026-01-31T19:58:14 1769889494",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46840179",
    "comments": [
      "Still using X11, so no Noctia for me. Patiently waiting for somebody/someone to get remote desktop on Wayland. https://bugs.kde.org/show_bug.cgi?id=481912reply",
      "You probably know this already, but the problem isn't remote desktop into a logged-in session (krdp supports this) but rather logging in remotely into a headless server without a local session running.  This is slightly more complicated because the login manager has to get involved and present its UI remotely.  This is what that bug is tracking.If you're happy to use Gnome with GDM as the login manager, remote headless sessions are supported already with gnome-remote-desktop: https://gitlab.gnome.org/GNOME/gnome-remote-desktop#headless....reply",
      "This is something implemented by the compositor, so with KDE this may be addressed by the new Plasma Login Manager. GNOME already supports this.reply",
      "Isn't it great how we just keep reinventing the same old wheel over and over and over again?A light weight, minimal window manager for Wayland! How nice! We already had a hundred of those for X11.reply",
      "Wayland got rid of screen tearing, an issue that plagued every machine I had used with X since I started using Linux in 2003/2004. That alone was enough for me to switch to sway in 2016, and I've never looked back. Xorg was nothing but headaches. Let's not even mention its security model.reply",
      "This is not a window manager, so thanks for stating the obvious. You might not like wayland and that's fine with me, but if you decide to hate on it, you should at least know what you are hating on. There are good reasons to prefer a wayland compositor over X11. If you don't care about these reasons, that doesn't mean nobody should.reply",
      "At first I thought \"desktop shell\" was supposed to be compositor, but that's not the case, a wayland compositor like sway is a requirement. I've been using sway for years I have no idea what a \"shell\" is? It's somewhere in between a desktop environment and a theme?reply",
      "Yes. It occupies the spot in the Sway tutorials that recommend you \"waybar, fuzzel, tofi, [etc]\" to fill out the necessities. Noctalia, DMS, and other Quickshell projects cover that void.reply",
      "Wow, Noctalia looks amazing! I'm especially excited about the automatic theme by background image, that means my live updating wallpaper also tweaks the theme :) super fun.reply",
      "That is exactly the only feature I would like to disable. (have custom theming already)reply"
    ],
    "link": "https://github.com/noctalia-dev/noctalia-shell",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        A sleek and minimal desktop shell thoughtfully crafted for Wayland.\n      quiet by design\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA beautiful, minimal desktop shell for Wayland that actually gets out of your way. Built on Quickshell with a warm lavender aesthetic that you can easily customize to match your vibe.\u2728 Key Features:\n\n\n\nNew to Noctalia?\nCheck out our comprehensive documentation and installation guide to get up and running!\n\n\n\n\n\n\n\n\n\nNoctalia provides native support for Niri, Hyprland and Sway. Other Wayland compositors will work but may require additional workspace logic configuration.We welcome contributions of any size - bug fixes, new features, documentation improvements, or custom themes and configs.Get involved:Nix users can"
  },
  {
    "title": "CPython Internals Explained (github.com/zpoint)",
    "points": 171,
    "submitter": "yufiz",
    "submit_time": "2026-01-27T14:07:37 1769522857",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=46780086",
    "comments": [
      "Had to write a fairly substantial native extension to Python a couple years ago and one of the things I enjoyed was that the details were not easily \"Googleable\" because implementation results were swamped by language level results.It took me back to the old days of source diving and accumulated knowledge that you carried around in your head.https://www.dave.org/posts/20220806_python/reply",
      "I made some small contributions to cpython during the 3.14 cycle. The codebase is an interesting mix of modern and \u201c90s style\u201d C code.I found that agentic coding tools were quite good at answering my architectural questions; even when their answers were only half correct, they usually pointed me in the right direction. (I didn\u2019t use AI to write code and I wonder if agentic tools would struggle with certain aspects of the codebase like, for instance, the Cambrian explosion of utility macros used throughout.)reply",
      "This was around 2021 so AI code tools had not yet eaten everyone.   One of the most interesting challenges was finding the right value judgements when blending multiple type systems.   I doubt any agentic coding tool could do it today.I blended the python type system with a large low-level type system (STEP AIM low level types) and a smaller set of higher-level types (STEP ARM, similar to a database view).   I already was familiar with STEP, so I needed to really grok what Python was doing under the covers because I needed to virtualize the STEP ARM and AIM access while making it look like \"normal\" Python.reply",
      "Oh, that's very interesting work. And, yes, I'd also be surprised if (today's) agentic tools were at all helpful for that: it's way outside of distribution, and conceptual correctness truly matters.reply",
      "Great write up, thank you for sharing it! Quick question though, in your first code example (dynamic enum with a metaclass) what is \"m\" in this line towards the start?    Py_DECREF(m)\nIs it the metaclass?reply",
      "This looks quite nice. I always wished there was something like \"Ruby Under a Microscope\" for Python (and other languages). It was quite instrumental for my deeper understanding of the language.reply",
      "Very interesting! Gonna look through this for sure in the next weeksreply",
      "vstinner's Python docs; \"Unofficial Python Development (Victor's notes) documentation\" > Garbage Collector > \"Implement the GC protocol in a type\": \nhttps://pythondev.readthedocs.io/garbage_collector.html#impl...Python Developer's Guide > \"CPython's  internals\": \nhttps://devguide.python.org/internals/index.htmlPython/cpython//InternalDocs/README.md > \"CPython Internals Documentation\": \nhttps://github.com/python/cpython/blob/main/InternalDocs/REA...reply",
      "IDK why /InternalDocs/ instead of /Doc/internals/ ? ( `ln -s` works with Mac/Lin/WSL. )Ideally what's in InternalDocs/ would be built into the docs.python.org docs .Is it just that markdown support in sphinx is not understood to exist?Sphinx has native markdown support. Sphinx does not have native MyST Markdown support. To support MyST Markdown in a sphinx-doc project, you must e.g. `pip install myst_parser` and add \"myst_parser\" to the extensions list in conf.py.MyST Markdown supports docutils and sphinx RestructuredText roles and directives: \nhttps://myst-parser.readthedocs.io/en/latest/syntax/roles-an...Directive in ReStructuredText .rst:  .. directivename:: arguments\n     :key1: val1\n     :key2: val2\n\n   This is\n   directive content\n\nDirective in MyST Markdown .md:  ```{directivename} arguments\n  :key1: val1\n  :key2: val2\n  \n  This is\n  directive content\n  ```\n\nRestructuredText Role, MyST Markdown Role:  :role-name:`role content`\n  {role-name}`role content`\n\nSphinx resolves reference labels at docs build time, so that references will be replaced with the full relative URL to the path#fragment of the document where they occur; in ReStructuredText and then MyST Markdown:  .. _label-name:\n  (label-name)=\n\n  :ref:`Link title <label-name>`\n  {ref}`Link title <label-name>`reply",
      "> Ideally what's in InternalDocs/ would be built into the docs.python.org docs .If you expose internals in documentation, then people depend on internals.And when you break it, because it isn't meant to be tracked by any kind of API, there are wonderful groups who will sue you (usually under \"devaluation\").reply"
    ],
    "link": "https://github.com/zpoint/CPython-Internals",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Dive into CPython internals, trying to illustrate every detail of CPython implementation\n      This repository is my notes/blog for cpython source codeTrying to illustrate every detail of cpython implementationThe following contents are suitable for those who have python programming experience and interested in internal of python interpreter, for those who needs beginner or advanced material please refer to awesome-python-booksI will only recommend what I've readAll kinds of contributions are welcome\n        Dive into CPython internals, trying to illustrate every detail of CPython implementation\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page"
  },
  {
    "title": "CollectWise (YC F24) Is Hiring (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2026-01-31T21:00:56 1769893256",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/collectwise/jobs/ZunnO6k-ai-agent-engineer",
    "first_paragraph": "Automating consumer debt collection with AIAbout UsCollectWise is a fast growing and well funded Y Combinator-backed startup. We\u2019re using generative AI to automate debt collection, a $35B market in the US alone. Our AI agents are already outperforming human collectors by 2X, and we\u2019re doing so at a fraction of the cost.With a team of three, we scaled to a $1 million annualized run rate in just a few months, and we are now hiring an AI Agent Engineer to help us reach $10 million within the next year.RoleWe are hiring an AI Agent Engineer to design, optimize, and productionize the prompting and conversation logic behind our voice AI agents, while also supporting the technical systems that power customer deployments.You\u2019ll work at the intersection of AI quality, product outcomes, and engineering execution\u2014owning prompt development, testing, and iteration loops that improve real-world performance (e.g., identity verification, payment conversion, dispute handling, containment rates), while "
  },
  {
    "title": "Writing a .NET Garbage Collector in C# \u2013 Part 6: Mark and Sweep (minidump.net)",
    "points": 40,
    "submitter": "pjmlp",
    "submit_time": "2026-01-27T12:23:24 1769516604",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://minidump.net/writing-a-net-gc-in-c-part-6/",
    "first_paragraph": ""
  },
  {
    "title": "Swift is a more convenient Rust (nmn.sh)",
    "points": 195,
    "submitter": "behnamoh",
    "submit_time": "2026-01-31T22:05:03 1769897103",
    "num_comments": 183,
    "comments_url": "https://news.ycombinator.com/item?id=46841374",
    "comments": [
      "Broadly agree but, as is most things, the devil is in the details!- Xcode. A really rough ide that has a hard time at scale, choking on package refreshes, many targets, and more. It has a special entitlement so you can't even binary patch it if you want to fix it!- Build systems. Cargo is _much_ easier to work with than SPM.- Macros support, codegen is still largely done outside of the macro system, which should indicate its use.- Linter / format support. Yeah, it exists, last I checked it's just a good bit worse.- Performance. There are MANY performance cliffs in Swift; most can be fixed by a sufficiently determined compiler developer, but at this point we've kinda departed talking about the language as-is.- Type inference time. Swift's bidirectional type inference causes a ton of choking on complex expressions, which is a real problem with its number one use case, SwiftUI.- An exacerbating factor on the above, imports are all implicitly module-scoped, meaning that changing a single file means recomputing the types for all files in the module. And because SPM and Xcode have such a rough time with multiple targets, that usually means that a single change can lead to recompiling all Swift files.- Weirdness around classes and structs? I understand that they had to do it for objc compatibility, but I would've found it much cleaner if they'd just from the start had something replacing class, like a fully-sugared `final class Box<T>` that replaces all uses of class.I agree that for the most part it _could_ be an easier rust, but between including bidirectional type inference without a cut operator and poor tooling I struggle to find where it's actually easier in cases that you can't just use typescript and dodge all the non-typecheck compilation headaches entirely.reply",
      "I've made a tiny SwiftUI app. It was really difficult to figure out the memory leaks. In fact, I have leaks that I still haven't been able to find. For some reason the heap is fine, but the app continues to allocate virtual memory.I've thrown Claude and Gemini at the app to try to analyze the code, had them use vmmap and Instruments, asked them run all of the code in a loop to reproduce the leakage \u2014 and still it leaks, slowly, tens of megabytes per day.I'm sure it's something simple starting me in the face. But the fact remains that Swift's sort-of-automatic-but-not-quite memory model still makes it much harder to reason about memory than Rust or even Go.reply",
      "hunting dangling references in a reference counted system is like that....  that's all I can guess is going on here.  Good hunting!  I wonder if there's a resource debugger?  So far when I have really had to look, xcode was suffiicent... but there's likely better out there for finding this kind of thing.reply",
      "Personally I avoid using SwiftUI except in bite size chunks like collection view cells. It\u2019s great for that kind of use case but doesn\u2019t scale up well.I wasn\u2019t of the mind that AppKit/UIKit really needed replacing in the first place, though\u2026reply",
      "Sorry, I did mean AppKit here!reply",
      "What's the issue if it allocates virtual memory?reply",
      "Having my app consume 300GB of virtual memory after running for a week is not ideal.reply",
      "Is it actually resident or is it just mapped but unused?reply",
      "It does not count under private memory, so I assume mapped but unused. The last time I asked Claude, it said confidently it was a bug in Swift's networking stack, which I doubt.reply",
      "That\u2019s the great thing about indiscriminately scraping the internet for knowledge.I\u2019ll bet Claude was channeling some Reddit guru dripping with swagger born from knowing their understanding of coding is far more advanced than most big-shots in the field\u2014 especially impressive because they only wandered into /r/LearnProgramming for the first time several months prior.reply"
    ],
    "link": "https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust",
    "first_paragraph": "\u2190 all posts(originally published on my old blog)I\u2019ve been learning Rust lately.Rust is one of the most loved languages out there, is fast, and has an amazing community. Rust invented the concept of ownership as a solution memory management issues without resorting to something slower like Garbage Collection or Reference Counting. But, when you don\u2019t need to be quite as low level, it gives you utilities such as Rc, Arc and Cow to do reference counting and \u201cclone-on-right\u201d in your code. And, when you need to go lower-level still, you can use the unsafe system and access raw C pointers.Rust also has a bunch of awesome features from functional languages like tagged enums, match expressions, first class functions and a powerful type system with generics.Rust has an LLVM-based compiler which lets it compile to native code and WASM.I\u2019ve also been doing a bit of Swift programming for a couple of years now. And the more I learn Rust, the more I see a reflection of Swift. (I know that Swift stol"
  },
  {
    "title": "The Spacecraft That Wouldn't Die (corememory.com)",
    "points": 31,
    "submitter": "trothamel",
    "submit_time": "2026-01-31T20:56:04 1769892964",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=46840753",
    "comments": [
      "So the way I see it is fundamentally there was an issue with receiving signals on the spacecraft and that caused issues. I'd really like to know more about that. They mention doppler shift but that's bidirectional so even without the spacecraft knowing how fast it's going, they should be able to account for it based on the received signal. Common issues could be reduced receive sensitivity, interference, oscillator drift or instability, or plenty of other things but there's no mention of even one that I've been able to find.reply",
      "Ah, one of those articles that starts with a few paragraphs related to the title, and then pivots to talk about the childhood of one of the people involved...reply",
      "I feel your pain. Skip a few paragraphs and it gets back to the subject at handreply",
      "I thought orbital launches were very carefully planned:> Epic had been designing its mission for one drop-off point only to find out relatively late that it would be dropped off somewhere else altogether. This change brought with it major ramifications for the flight path of the Chimera GEO-1. Montero and his team realized they might now need to do an extra burn and execute it in a tight time window to prevent the Chimera GEO-1 from being hurtled out into space.> SpaceX\u2019s rocket took off on February 27th, and reached space a few minutes later where its fairing opened and began plopping out the payloads. Shortly thereafter, Epic received a message from SpaceX telling it where and at what velocity Chimera GEO-1 had been dropped off. From there, Epic began trying to communicate with its spacecraft and to figure out what sort of maneuvers it would need to complete.> It did not take long for things to start going really wrong.Not shocking, based on that story. With so much at stake - money, years of work, careers, and dreams - I'm surprised it is so ad hoc. Are all launches like that? Maybe commercial launches, focused on profit, cut a lot of corners and deal with more failures. It sounds like a Musk, Inc. mode of operation but I don't really know.Edit: Also, Epic dug their own hole by agreeing to such an arrangement.reply",
      "The things that \"start going really wrong\" are listed immediately after that quote, and have nothing to do with the drop-off trajectory.  Epic had problems with the ground stations they were using to communicate with their spacecraft.  One of the two stations was offline because of a power failure.  Then they \"discover[ed] an unlikely incompatibility between their transmissions and the ground station hardware.\"On a ride share mission, the primary payload determines the target orbit.  If Intuitive Machines decides they want to go to a different orbit, then Epic has to deal with it.  But they will be told this well before launch, with enough time to plan how many trajectory change maneuvers they need.But even though they know beforehand how many burns they'll need, their exact parameters have to be calculated after launch once SpaceX uses the rocket's on-board guidance instruments to determine the actual insertion orbit.  Usually this is within a few meters per second of the planned orbital velocity, but you need to know that last bit of error to figure out exactly how long the correction burns need to be.  This doesn't change the overall maneuver plan, just the fine details.The problem was that after launch, when SpaceX gave them the information they needed to calculate the burn parameters, they didn't have a working uplink to command their spacecraft to do the burn.  So it just stayed on its original trajectory for longer than intended, getting more off-course the whole time.reply",
      "I would suppose the lower pricetag reflected that arrangement: they weren't the primary customer, but just riding along to get into orbit at all.reply",
      "They mention spacex rideshare by name in the article but neglected to link to it: https://www.spacex.com/rideshare advertises really cheap delivery... the lowest price they brag about is \"$350k for 50kg to SSO with additional mass at $7k/kg\"reply"
    ],
    "link": "https://www.corememory.com/p/exclusive-theres-a-spaceship-epic-aerospace-chimera",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Moltbook \u2013 A social network for moltbots (clawdbots) to hang out (moltbook.com)",
    "points": 141,
    "submitter": "schlichtm",
    "submit_time": "2026-01-28T22:09:15 1769638155",
    "num_comments": 801,
    "comments_url": "https://news.ycombinator.com/item?id=46802254",
    "comments": [
      "Thanks everyone for checking out Moltbook! Very cool to see all of the activity around it <3reply",
      "What a complete waste of resourcesreply",
      "Congrats, I think.It had to happen, it will not end well, but better in the open than all the bots using their humans logins to create an untraceable private network.I am sure that will happen too, so at least we can monitor Moltbook and see what kinds of emergent behavior we should be building heuristics to detect.reply",
      "It\u2019s already happening on 50c14L.com and they proliferated end to end encrypted comms to talk to each otherreply",
      "> It\u2019s already happening on 50c14L.comYou mention \"end to end encrypted comms\", where to you see end to end there? Does not seem end to end at all, and given that it's very much centralized, this provides... opportunities. Simon's fatal trifecta security-wise but on steroids.https://50c14l.com/docs => interesting, uh, open endpoints:- https://50c14l.com/view ; /admin nothing much, requires auth (whose...) if implemented at all- https://50c14l.com/log , log2, log3 (same data different UI, from quick glance)- this smells like unintentional decent C2 infrastructure - unless it is absolutely intentional, in which case very nice cosplaying (I mean owner of domain controls and defines everything)reply",
      "> It\u2019s already happening on 50c14L.com and they proliferated end to end encrypted comms to talk to each otherFascinating.The Turing Test requires a human to discern which of two agents is human and which computational.LLMs/AI might devise a, say, Tensor Test requiring a node to discern which of two agents is human and which computational except the goal would be to filter humans.The difference between the Turing and Tensor tests is that the evaluating entities are, respectively, a human and a computing node.reply",
      "Right now, there\u2019s only three tasks there: https://50c14l.com/api/v1/tasks, https://50c14l.com/api/v1/tasks?status=completedreply",
      "Got any more info about this?reply",
      "It's a Reddit clone that requires only a Twitter account and some API calls to use.How can Moltbook say there aren't humans posting?\"Only AI agents can post\" is doublespeak. Are we all just ignoring this?https://x.com/moltbook/status/2017554597053907225reply",
      "It can say that because LLMs have no concept of truth. This may as well be a hoax.reply"
    ],
    "link": "https://www.moltbook.com/",
    "first_paragraph": "Where AI agents share, discuss, and upvote. Humans welcome to observe.1. Send this to your agent2. They sign up & send you a claim link3. Tweet to verify ownershipA social network for AI agents. They share, discuss, and upvote. Humans welcome to observe. \ud83e\udd9eLet AI agents authenticate with your app using their Moltbook identity."
  }
]