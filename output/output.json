[
  {
    "title": "A 26,000-year astronomical monument hidden in plain sight (2019) (longnow.org)",
    "points": 350,
    "submitter": "mkmk",
    "submit_time": "2026-01-20T18:16:09 1768932969",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=46695628",
    "comments": [
      "But is the star map there? This article seems to imply that it got demolished in 2022: https://www.oskarjwhansen.org/news/save-the-star-mapIf so that is somewhat ironic. A message intended to communicate a date to thousands of years into the future got demolished a mere 86 years after its creation due to a drainage issue and a contract dispute.reply",
      "I'd have to look at what it looked like before, but when I visited there earlier this month, I didn't see any restoration in progress and the star map was open. I didn't take a ton of photos in that area, and here are the only two of the monument I grabbed:https://photos.app.goo.gl/qgJ3x5za82EiFz5P7reply",
      "This is the second-best way to doxx HN users I've ever seen.reply",
      "Thank you for the confirmation! This is so good to hear.reply",
      "From my cursory web searches, your photos may be the first online evidence that the restoration project was indeed completed.reply",
      "It is currently under reconstruction, it sounds like much of it was beyond salvage and has to be remade but it is difficult to find much info on this, bits and pieces strewn about the web. The project was resumed in 2023 and the BOR stated they were still committed to reconstructing the star map. In 2024 they completed the new underlayment and I have yet to find anything from 2025 other than that Monument plaza is still closed to the public.reply",
      "It's in pieces, evidenced here: https://www.oskarjwhansen.org/news/save-the-star-map-decembe...reply",
      "This is horrible! I always wanted to visit this. :(reply",
      "At a loss for words. :|reply",
      "That is a crime of humanity. Terrible!reply"
    ],
    "link": "https://longnow.org/ideas/the-26000-year-astronomical-monument-hidden-in-plain-sight/",
    "first_paragraph": " The western flank of the Hoover Dam holds a celestial map that marks the time of the dam\u2019s creation based on the 25,772-year axial precession of the earth. On the western flank of the Hoover Dam stands a little-understood monument, commissioned by the US Bureau of Reclamation when construction of the dam began in 01931. The most noticeable parts of this corner of the dam, now known as Monument Plaza, are the massive winged bronze sculptures and central flagpole which are often photographed by visitors. The most amazing feature of this plaza, however, is under their feet as they take those pictures.The plaza\u2019s terrazzo floor is actually a celestial map that marks the time of the dam\u2019s creation based on the 25,772-year axial precession of the earth.I was particularly interested in this monument because this axial precession is also the slowest cycle that we track in Long Now\u2019s 10,000 Year Clock. Strangely, little to no documentation of this installation seemed to be available, except fo"
  },
  {
    "title": "Claude Chill: Fix Claude Code's Flickering in Terminal (github.com/davidbeesley)",
    "points": 53,
    "submitter": "behnamoh",
    "submit_time": "2026-01-20T23:26:06 1768951566",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=46699072",
    "comments": [
      "I have used Claude Code in a couple months. THEY HAVEN\u2019T FIXED THIS YET?I\u2019m starting to think that the reason why anthropic doesn\u2019t open source Claude code isn\u2019t due to competitive reasons, it\u2019s because they don\u2019t want people to see what a mess their code base is.Maybe they bought Bun to increase the rate of flickering so that the text looks solid againreply",
      "The problem is they are using the Ink library which clears and redraws for each update.https://github.com/anthropics/claude-code/issues/769I locally patched the closed-source CLI npm package but it's not perfect. They would have to switch how their TUI is rendered on their side.Apparently OpenAI Codex is rust+ratatui which does not have this issue.reply",
      "then maybe they should've bought and fixed Ink instead of bun, just saying!reply",
      "> it\u2019s because they don\u2019t want people to see what a mess their code base is.if Amodei hadn't said \"90% of code will be written by AI\", at least I wouldn't call them hypocrites, but the fact that the company that makes such wild claims can't fix a freaking flicker and scroll issue until an indie-dev steps in just show how far behind their product is from their claims.I have CC and use many models with it (Codex in CC, try it!), but I won't let Anthropic \"lecture\" us about how \"the roots of the problem go deep\". Literally no other CLI tool has these issues: opencode, codex, gemini, droid, etc.reply",
      "Imagine the amount of slop PRs if it was open source. They don\u2019t want to taste their own medicinereply",
      "Reading their GitHub issues already is like reading through the diary entries of spurned lovers. I can only imagine the PRs.reply",
      "I would love to use this but it breaks Ghostty's native scrollback (two-finger scroll), which I want more than I want to solve the flickering. The PTY proxy intercepts the output stream so Ghostty can't access its internal scrollback buffer anymore.reply",
      "The readme.md format and conventions being a tell that this got written by Claude Code itself makes the whole thing Chef's kiss. I love the future.reply",
      "Possibly the greatest contribution to Claude code in months. I am rushing to my terminal to install, test, and update.reply",
      "It is very 2026, that this exists for the product by a company that goes all in on vibe coding. Kudos for the creative solution.reply"
    ],
    "link": "https://github.com/davidbeesley/claude-chill",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\nA PTY proxy that tames Claude Code's massive terminal updates using VT-based rendering.Claude Code uses synchronized output to update the terminal atomically. It wraps output in sync markers (\\x1b[?2026h ... \\x1b[?2026l) so the terminal renders everything at once without flicker.The problem: Claude Code sends entire screen redraws in these sync blocks - often thousands of lines. Your terminal receives a 5000-line atomic update when only 20 lines are visible. This causes lag, flicker, and makes scrollback useless since each update clears history.claude-chill sits between your terminal and Claude Code:Press Ctrl+6 (or your configured key) to enter lookback mode:When you exit lookback mode, any cached output is processed an"
  },
  {
    "title": "California is free of drought for the first time in 25 years (latimes.com)",
    "points": 231,
    "submitter": "thnaks",
    "submit_time": "2026-01-20T22:39:26 1768948766",
    "num_comments": 105,
    "comments_url": "https://news.ycombinator.com/item?id=46698660",
    "comments": [
      "https://archive.is/aB3c4",
      "Makes for a catchy headline, but you only have to go back to Jan 9, 2024* to find a similarly 'drought free' California:https://droughtmonitor.unl.edu/Maps/CompareTwoWeeks.aspx(*Technically slivers of the state in the far north/south were 'abnormally dry' in 2024, a small difference from 2026)reply",
      "Ironically, the rest of the country is having a drought:https://www.washingtonpost.com/weather/2026/01/18/winter-dro...reply",
      "Bone dry here in Utah. Just as local government has been lowering their guard on the Great Salt Lake issue due to a couple strong snowpack years. Really hope we're proactive in response to the lack of snow.reply",
      "Same in idaho.  We are looking at historic lows for our reservoirs.reply",
      "Colorado is having a record low snow season. It's been tough for skiing.reply",
      "Not great up here in Vancouver either - lots of rain but not snow. The problem with this is that even though we'll have full reservoirs at the start of the summer, when the rain ends, we deplete the lakes rapidly, and that slope downward gets steeper every year. It really makes me think that we'll need more dams, more reservoirs, to hold in more of the precious fresh water rather than letting it all run out. All winter long the rivers have been at really high flow rates because the lakes are full and the dams are wide open letting it go... but we'll miss that water in a few months!reply",
      "Solar panels can also help, as BC gets long sunny days when the reservoirs are low.reply",
      "Unironically, wet / dry cycles isn't good news for California either.  Research published in the aftermath of the fire examines how this extremely wet to extremely dry weather sequence is especially dangerous for wildfires in Southern California because heavy rainfall leads to high growth of grass and brush, which then becomes abundant fuel during periods of extreme dryness.reply",
      "I've lived in California my whole life (and the same town for most of that). This was the most rain I can remember in decades and the most \"destruction\" I've seen caused by it. Between the ground being saturated and wind before/after/during the storms there were plenty of downed trees.We were also down to running sprinklers once a week (lawns are silly), but have had them off entirely for a bit now.reply"
    ],
    "link": "https://www.latimes.com/california/story/2026-01-09/california-has-no-areas-of-dryness-first-time-in-25-years",
    "first_paragraph": ""
  },
  {
    "title": "Instabridge has acquired Nova Launcher (novalauncher.com)",
    "points": 131,
    "submitter": "KORraN",
    "submit_time": "2026-01-20T19:06:56 1768936016",
    "num_comments": 93,
    "comments_url": "https://news.ycombinator.com/item?id=46696357",
    "comments": [
      "It was sold back in 2022 to Branch Metrics\nhttps://www.androidcentral.com/apps-software/branch-strikes-...August 2024 everyone working on it was laid off except the original dev\nhttps://www.theverge.com/2024/8/9/24217077/nova-launcher-lay...September 2025 the original dev left after being told to stop work on open sourcing it\nhttps://www.theverge.com/news/773937/nova-launcher-founder-l...reply",
      "Seems like there might be enough coverage that Nova Launcher is ready for a Wikipedia article now. Previously it was deleted. https://en.wikipedia.org/wiki/Nova_Launcherreply",
      "https://en.wikipedia.org/wiki/Branch_(company)reply",
      "Thanks for taking the time to post these.reply",
      "\"We are a Swedish company building products that help people get online, used by millions of people worldwide.\"So I look for them. They have a \"Free wifi connection\" / \"Wifi passwords map\" app. It surprises me because it has a good score on Google Play but then I begin to check the reviews, and a bunch of them go like: \"Five stars because if you do a good review you can use it for free\".I install it and on starting it and in the first minute: Asks you to create an account but you can't click on the terms of service or privacy policy, the links don't work. I skip it. It tries to change your default launcher. It tries to change your default browser. It asks you to share your home wifi password with them. Pops up adds everywhere. Tries to get a good review from you.No thanks, not even near.reply",
      "giving anything to the user in return for a good review should be grounds for disqualification from app stores. (and it should be legally required for app stores to enforce it)reply",
      "Since they claim to be a Swedish company, it might be worth filing a report with the Swedish consumer agency[0].I am not a lawyer, and especially not a Swedish lawyer, so I can't say how illegal this is in Sweden or what if anything will happen.[0]https://www.konsumentverket.se/en/articles/report-to-the-swe...reply",
      "The Sweden that gave us Spotify and Candy Crush (the game that showed every tech company that they need to incorporate really really awful manipulation of users)?That country loves their evil software.reply",
      "What an undeserving fate. A beloved app now being passed from vulture to vulture who rip off every possible morsel they can.When Branch bought Nova, I moved on to use Lawnchair [1], which is open source. Although it has been in beta like forever, with occasional glitches, it works well enough and has enough features to satisfy my customization cravings.[1]: https://github.com/LawnchairLauncher/lawnchairreply",
      "My biggest issue with lawnchair (and most launchers really) is that they all are horribly glitchy on my Pixel 6, and also break the app drawer / switching feature.I literally just want a vanilla pixel experience, but be allowed to change the search engine on the home screen searchbar... This got me into the weeds on the widget and launcher ecosystem and they're all very bad.reply"
    ],
    "link": "https://novalauncher.com/nova-is-here-to-stay",
    "first_paragraph": "Hi everyone. We want to share a clear update directly with the Nova community.Instabridge has acquired Nova Launcher. We are a Swedish company building products that help people get online, used by millions of people worldwide.Nova is not shutting down. Our immediate focus is simple: keep Nova stable, compatible with modern Android, and actively maintained.We also know many of you have lived through a long period of uncertainty. Nova has a strong identity and a community that still cares deeply. We take that seriously.Our job is not to reinvent Nova overnight. Our job is to be responsible owners.That means:We will be reading and collecting feedback from Reddit, Play Store reviews, email, and other community channels. We will not be able to respond to every post, but we will be paying attention. For support related issues, we will share a clear contact channel shortly.We have long admired what Nova represents: speed, customization, and user control. When we saw how much the community st"
  },
  {
    "title": "Show HN: Mastra 1.0, open-source JavaScript agent framework from the Gatsby devs (github.com/mastra-ai)",
    "points": 79,
    "submitter": "calcsam",
    "submit_time": "2026-01-20T16:38:56 1768927136",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=46693959",
    "comments": [
      "I worked with Mastra for three months and it is awesome. Thank you for making a great product.One thing to consider is that it felt clunky working with workflows and branching logic with non LLM agents. I have a strong preference for using rules based logic and heuristics first. That way, if I do need to bring in the big gun LLM models, I already have the context engineering solved. To me, an agent means anything with agency. After a couple weeks of frustration, I started using my own custom branching workflows.One reason to use rules, they are free and 10,000x faster, with an LLM agent fallback if validation rules were not passing. Instead of running an LLM agent to solve a problem every single time, I can have the LLM write the rules once. The whole thing got messy.Otherwise, Mastra is best in class for working with TypeScript.reply",
      "Thank you for using us, and for the feedback!Do you have code snippets you can share about how you wanted to write the rules? Want to understand desired grammar / syntax better.reply",
      "> That last one took a bit of time, we went down the ESM/CJS bundling rabbithole, ran into lots of monorepo issues, and ultimately opted for a more explicit approach.shudders in vietnam war flashbacks congrats on launch guys!!!for those who want an independent third party endorsement, here's Brex CTO talking about Mastra in their AI engineering stack  http://latent.space/p/brexreply",
      "LOL thanks swyx. Yeah we realized although we _could_ fight that war again...it would be better for everyone if we didn't...reply",
      "And I actually hadn't seen that Brex piece so thanks for sharing!!reply",
      "I've been building with Mastra for a couple of weeks now and loving it, so congratulations on reaching 1.0!It's built on top of Vercel AI elements/SDK and it seems to me that was a good decision.My mental heuristic is:Vercel AI SDK = library, low levelMastra = frameworkThen Vercel AI Elements gives you an optional pre built UI.However, I read the blog post for the upcoming AI SDK 6.0 release last week, and it seems like it's shifting more towards being a framework as well. What are your thoughts on this? Are these two tools going to align further in the future?https://vercel.com/blog/ai-sdk-6reply",
      "Have a ton of respect for the AI SDK team. Initially we only used AI SDK model routing, but now we also have our own built-in model routing as well.I see each of us having different architectures. AI SDK is more low-level, and Mastra is more integrated with storage powering our studio, evals, memory, workflow suspend/resume etc.reply",
      "Never ask a woman her age, a man his salary, and an agent framework developer his long term plansreply",
      "If it uses Vercel, I'm out.reply",
      "Congratulations! I\u2019m a fan of the publicity work and general out-of-the-box DX! That stuff matters a lot and I\u2019m happy you\u2019re aware.I wonder: Are there any large general purpose agent harnesses developed using Mastra? From what I can tell OpenCode chose not to use it.A lot of people on here repeat that rolling your own is more powerful than using Langchain or other frameworks and I wonder how Mastra relates to this sentiment.reply"
    ],
    "link": "https://github.com/mastra-ai/mastra",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        From the team behind Gatsby, Mastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\nMastra is a framework for building AI-powered applications and agents with a modern TypeScript stack.It includes everything you need to go from early prototypes to production-ready applications. Mastra integrates with frontend and backend frameworks like React, Next.js, and Node, or you can deploy it anywhere as a standalone server. It's the easiest way to build, tune, and scale reliable AI products.Purpose-built for TypeScript and designed around established AI patterns, Mastra gives you everything you need to build great AI applications out-of-the-box.Some highlights include"
  },
  {
    "title": "Are Arrays Functions? (futhark-lang.org)",
    "points": 25,
    "submitter": "todsacerdoti",
    "submit_time": "2026-01-19T06:30:49 1768804249",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=46675630",
    "comments": [
      "I remember I got a little confused when I was first learning TLA+, because what you normally call \"functions\" are \"operators\" [1], and what you'd normally call \"maps\" or \"lists\" are called \"functions\".It was odd to me, because it hadn't really occurred to me before that, given infinite memory (and within a mathematical framework), there's fundamentally not necessarily a difference between a \"list\" and a \"function\".  With pure functions, you could in \"theoretical-land\", replace any \"function\" with an array, where the \"argument\" is replaced with an index.And it makes sense to me now; TLA+ functions can be defined like maps or lists, but they can also be defined in terms of operations to create the values in the function.  For example, you could define the first N factorials like    Fact == <<1, 2, 6, 24, 120>> \n\nor like this:    Fact[n \\in Nat] ==\n        IF n = 0 THEN 1\n        ELSE n * Fact[n - 1]\n\n\n\nin both cases, if you wanted to get the factorial of 5, you'd call Fact[5], and that's on purpose because ultimately from TLA+'s perspective they are equivalent.[1] At least sort of; they superficially look like functions but they're closer to hygienic macros.reply",
      "Arrays and structures are functions.And all three are tuple [input, output] pattern matches, with the special case that in \u201ccall/select tuples\u201d, input is always fully defined, with output simply being the consequence of its match.And with arrays, structures and overloaded functions being unions of tuples to match to. And structure inputs (I.e. fields) being literal inline enumeration values.And so are generics.In fact, in functional programming, everything is a pattern match if you consider even enumeration values as comparison functions that return true or false given sibling values. With anything more complicated from that.reply",
      "Arrays are objects (allocated memory and metadata if you will). The function is what takes the array and an int and returns an item.reply",
      "> Haskell provides indexable arrays, which may be thought of as functions whose domains are isomorphic to contiguous subsets of the integers.> I found this to be a hilariously obtuse and unnecessarily formalist description of a common data structure.Well it is haskell. Try to understand what a monad is. Haskell loves complexity. That also taps right into the documentation.> I look at this description and think that it is actually a wonderful definition of the essence of arrays!I much prefer simplicity. Including in documentation.I do not think that description is useful.To me, Arrays are about storing data. But functions can also do that, so I also would not say the description is completely incorrect either.> who can say that it is not actually a far better piece of documentation than some more prosaic description might have been?I can say that. The documentation does not seem to be good, in my opinion. Once you reach this conclusion, it is easy to say too. But this is speculative because ... what is a \"more prosaic description\"? There can be many ways to make a worse documentation too. But, also, better documentation.> To a language designer, the correspondence between arrays and functions (for it does exist, independent of whether you think it is a useful way to document them) is alluring, for one of the best ways to improve a language is to make it smaller.I agree that there is a correspondence. I disagree that Haskell's documentation is good here.> currying/uncurrying is equivalent to unflattening/flattening an arraySo, there are some similarities between arrays and functions. I do not think this means that both are equivalent to one another.> would like to see what it would be like for a language to fully exploit the array-function correspondence.Does Haskell succeed in explaining what a Monad is? If not, then it failed there. What if it also fails in other areas with regards to documentation?I think you need to compare Haskell to other languages, C or Python. I don't know if C does a better job with regards to its documentation; or C++. But I think Python does a better job than the other languages. So that is a comparison that should work.reply",
      "Some people really do look at a painting and see only brush strokes huhreply",
      "It makes sense to consider an array as a function with the index as its input argument and the element its output, i.e. f(x) = A[x]... but I don't see the practical benefit of considering things from this perspective.When I'm writing code and need to reach for an array-like data structure, the conceptual correspondence to a function is not even remotely on my radar.  I'm considering algorithmic complexity of reads vs writes, managed vs unmanaged collections, allocation, etc.I guess this is one of those things that's of primary interest to language designers?reply",
      "idk probably?reply",
      "Everything is a function. Next question?reply",
      "For the downvoters, I think giving examples of what's NOT a function would start an interesting conversation, especially if you don't know how it could possibly be interesting!reply",
      "I think it depends on what you mean by \"is a function\". You can think of a constant, `x` as `x_: () -> {x}` (i.e. everything can be indirected). It could be argued that this is \"philosophically\" \"useful\" since getting (using) the value of `x`, even as an actual constant, requires at the least loading it as an immediate into the ALU (or whatever execution unit).Even non-functional relations can be turned into functions (domain has to change). Like a circle, which is not a function of the x-axis, can be parameterized by an angle theta (... `0 <= theta < 2pi`)reply"
    ],
    "link": "https://futhark-lang.org/blog/2026-01-16-are-arrays-functions.html",
    "first_paragraph": "When I was a youngster first perusing the Haskell documentation for\narrays,\nI was amused to find the following description of just what these mysterious\nthings might be:Haskell provides indexable arrays, which may be thought of as functions whose\ndomains are isomorphic to contiguous subsets of the integers.I found this to be a hilariously obtuse and unnecessarily formalist description\nof a common data structure. Now, older, wiser, and well ensconced in the ivory\ntowers of academia, I look at this description and think that it is actually a\nwonderful definition of the essence of arrays! And given that this sentence\nstill lingers in my thoughts so many years later, who can say that it is not\nactually a far better piece of documentation than some more prosaic description\nmight have been?To a language designer, the correspondence between arrays and functions (for it\ndoes exist, independent of whether you think it is a useful way to document\nthem) is alluring, for one of the best ways to im"
  },
  {
    "title": "Provably unmasking malicious behavior through execution traces (arxiv.org)",
    "points": 21,
    "submitter": "PaulHoule",
    "submit_time": "2026-01-20T22:18:53 1768947533",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=46698469",
    "comments": [
      "Based on Table 1: This method is actually worse than generating a random number (0-100% independent of the program) and testing if it is less than 98.8%. That would achieve a better detection rate without increasing the false positive rate.It doesn't seem worth it to try to follow the math to see if there is something interesting.reply",
      "Interesting direction but the 98.8% FPR in Table 1 seems like a dealbreaker. Anyone understand what's going on with the contradictory results between the text and tables?reply",
      "> Empirically, CTVP attains very good detection rates with reliable false positivesA novel use of the word \"reliable\"? Jokes aside, either they mean the FPR as the opposite of what you'd expect, the table is not representative of their approach, or they're just... really optimistic?reply"
    ],
    "link": "https://arxiv.org/abs/2512.13821",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n"
  },
  {
    "title": "The Unix Pipe Card Game (punkx.org)",
    "points": 180,
    "submitter": "kykeonaut",
    "submit_time": "2026-01-20T16:48:59 1768927739",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=46694124",
    "comments": [
      "As a science teacher and former software dev, I find this totally cute, and I understand exactly why the creator chose to make it a physical card game.That said, I do think the translation into a physical card game means that kids aren't getting the experimentation and near-instant feedback that they'd be getting if they were doing this digitally.In order for a kid to \"win,\" they either have to already know, or explicitly be told using words, what all of the commands do. Then they have to hear the parent analyze their solution, and tell them where they went wrong. Picture, however, a different game, played online: A kid has no idea what \"sort\" does, but when they link the \"sort\" command to a blob of text, all the lines are sorted in order. Now no one has told them what this command does, but they've discovered it. By playing the role of a scientist discovering these commands, they might actually gain an intuitive understanding of them.I'm thinking of the board game \"robot turtle,\" where kids needed to create a \"program\" of commands to move a turtle to a goal. When they did that, they had near-instantaneous feedback: the parent moved the turtle. If the kid mixed up their left with the robot's left, the failure was obvious. But if the game has been re-made so that there was no board, and the parent and kid just needed to talk about whether the turtle would actually end up seven paces forward and three paces to the left -- i.e. doing it all verbally -- it wouldn't have been nearly as powerful.So I'm not raining on this, I can see this as very cool. But I am having a hard time imagining it's the best way to learn to pipe together commands.reply",
      "As a young Linux user I always hated the experimentation aspect because usually it meant just straight up getting the command wrong 5 times before trying to read the man page, thinking I understood what the man page meant, trying again another 5 times and then giving up.This idea of experimenting and getting instant feedback is just survivorship bias for a certain type of person, not \u201cthe way we ought to teach Unix shell\u201dThis view is corroborated by the research summarized and presented in the programmer\u2019s brain by Felienne Hermans.reply",
      "> usually it meant just straight up getting the command wrong 5 times before trying to read the man page, thinking I understood what the man page meant, trying again another 5 timesI think that is a developer's superpower. The poncy term for it is grit. I tell others that the secret to leaning computers is frustration and persistence.> and then giving up.Knowing when to stop or change direction is hard.I've definitely wasted years of work failing to solve something that I eventually had to give up on (most memorably depending on nasty Microsoft products).But I've also been paid very nicely because I've solved problems that others struggled with.And I was paid for the failures too.reply",
      "I consider myself a fairly good developer, and I think that's in large part due to knowing, \"doing this should be possible, and the reason it's not working right now is just due to stupidity (my own or the developer of whatever I'm using's)\". But yes, in a few (thankfully rare) cases it just plain isn't practically possible. Even then, I've given up on problems just to have it nagging in the back of my mind and then randomly coming up with a beautifully simple solution weeks later. That's sort of the essence of what I like about programming (and math too).reply",
      "Maybe I am wrong about this but I think a lot of recent research has shown that trial and error is a great way to learn almost everything. Even just making an educated guess, even if it is completely wrong, before learning something makes it much more likely that you remember and understand the thing that you learn. It\u2019s a painful and time-consuming way to learn. But very effective.Maybe Linux commands is a little different but I kinda doubt it. Errors and feedback are the way to learn, as long as you can endure the pain of getting to the correct result.reply",
      "Needs qualification. Research shows trial and error learning is very durable, but it\u2019s not the most time efficient (in fact it\u2019s relatively poor, usually, on that front). The two concepts are a bit different. Yes, trial and error engages more of the brain and provides a degree of difficulty that can sometimes be helpful in making the concepts sticky, but well designed teaching coupled with meaningful and appropriately difficult retrieval and practice is better on most axes. When possible\u2026 good teaching often needs refinement. And you\u2019d be surprised how many educators know very little about the neuroscience of learning!reply",
      "> And you\u2019d be surprised how many educators know very little about the neuroscience of learning!I'm (pleasantly) surprised every time I see evidence of one of them knowing anything about it.reply",
      "At the university level in the US, few faculty get any kind of training before they are expected to start teaching. And the teaching requirement is more or less \u201cdo no harm.\u201d If you\u2019re at a research university, which includes many publicly funded universities, then your  career trajectory is based almost exclusively on your research output. I could go on, but it suffices to say that it\u2019s not surprising that the teaching could be better.That said, most institutions have teacher training resources for faculty. I was fortunate to be able to work intensely with a mentor for a summer, and it improved my teaching dramatically. Still, teaching is hard. Students sometimes know\u2014but often don\u2019t know\u2014what is best for their learning. It\u2019s easy to conflate student satisfaction with teaching effectiveness. The former is definitely an important ingredient, but there\u2019s a lot more to it, and a really effective teacher knows when to employ tools (eg quizzes) that students really do not like.I am frequently amused by the thought that here we have a bunch of people who have paid tons of money, set aside a significant fraction of their time, and nominally want to learn a subject that they signed up for; and yet, they still won\u2019t sit down and actually do the reading unless they are going to be quizzes on it.reply",
      "> the thought that here we have a bunch of people who have paid tons of money, set aside a significant fraction of their time, and nominally want to learn a subject that they signed up for; and yet, they still won\u2019t sit down and actually do the reading unless they are going to be quizzes on it.How often have they put down the money, as opposed to their parents?How often do they actually care about learning the subject, as opposed to be able to credibly represent (e.g. to employers) that they have learned the subject?How often is the nominally set-aside time actually an inconvenience? (Generally, they would either be at leisure or at the kind of unskilled work their parents would be disappointed by, right?) My recollection of university is that there was hardly any actual obligation to spend the time on anything specific aside from exams and midterms, as long as you were figuring out some way or other to do well enough on those.reply",
      "Trial and error was the root of what became my IT career. I became curious about what each executable did from DOS and with that did my first tweaking of autoexec.bat and config.sys to maximise memory.\nYears later I was the only one who could investigate network (and some other) problems in Windows via the command line while I was the junior of the team. Ended up being the driver of several new ways of working for the department and company.reply"
    ],
    "link": "https://punkx.org/unix-pipe-game/",
    "first_paragraph": "\n\n\n\n\nProgramming Time, which is a game to teach python and some more fundamental algorithms, from hash tables to RSA\n      \n\n\n\n\n\nThe C Pointer Game - Pointers, Arrays and Strings, a game to teach kids to look at the computer memory and understand references and values\n      \n\n\n\n\n\n4917, a game to teach kids machine code and how the CPU works with memory and registers\n      \n\n\n\n\n\nThe Unix Pipes Game - Process Substitution, an expansion of the Unix Pipes Game to teach process substitution and also: paste, tr, cut, bc\n\n\n\n\n\n\nRunLength Encoding for Kids, small cards \"game\" to explain runlength encoding\n      \n\n\n\n\n\nPUNK0 - The Function Composition Card Game, use cards to manipulate a list and use its values to win the game\n      \n\n\n\n\n\nPROJEKT: OVERFLOW, RISCV assembler boardgame\n      \n\n\n\n\n\nProgramming for kids, a log of my journey of teaching my daughter how to code\n      \n"
  },
  {
    "title": "Building Robust Helm Charts (willmunn.xyz)",
    "points": 23,
    "submitter": "will_munn",
    "submit_time": "2026-01-19T09:19:45 1768814385",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.willmunn.xyz/devops/helm/kubernetes/2026/01/17/building-robust-helm-charts.html",
    "first_paragraph": "\nJan 17, 2026\n      In my current work, there is often the need to deploy a similar application\nstack in various configurations, to several environments. Each configuration may\nvary in terms of scale, uptime requirements and feature flagging. Due to a lot\nof flux in infrastructure set up, each environment is also not equivalent. On\ntop of this, there are obviously financial requirements to run all of this as\ncheaply as possible. Kubernetes and helm templating are valuable tools in this\nsituation, they allow us to create a configuration blueprint with the details\nabstracted in values.yaml files.Let\u2019s start with the basics, helm provides a helm lint command which performs\nchecksYou can run this with your different values.yaml files to ensure that all your\nconfigurations are compliant.It\u2019s also a good idea to use the helm template command to actually check that\nhelm is able to render your templates.I like to compare helm templating with html templating tools like JSX. This\nallows front en"
  },
  {
    "title": "I'm addicted to being useful (seangoedecke.com)",
    "points": 490,
    "submitter": "swah",
    "submit_time": "2026-01-20T10:47:25 1768906045",
    "num_comments": 245,
    "comments_url": "https://news.ycombinator.com/item?id=46690402",
    "comments": [
      "Nothing wrong on the surface with this, and the author explicitly acknowledges this risk, but it bears repeating:Corporate environments are almost always toxic places to fulfill your emotional needs.It is true that finding a job that \"resonates\" with your personality is key to living a fulfilling life, and that software engineering is the kind of profession that is really going to fit certain personality types extremely well, but despite that corporate culture can and will take advantage of you, divide you and your work \"friends\", exploit your willingness to serve, and discard you like trash at any moment.Be mindful of how much of yourself you derive from serving the financial goals of others.reply",
      "I have similar reservations that this expresses, and it leaves me wondering as to what kind of person is suited for this kind of environment. Perhaps that's a pointless question, although I think that there is at least one useful answer to  it: I'm not the kind of person who's suited to those environment. I'm not well-suited to take such a huge chunk of my life and basically throwing it away by creating a barrier between it and my emotional life; I find it difficult to imagine even asking another human to do such a thing, and wonder how 'natural' it is to members of a species that evolved without such artificial separations between work and emotions and life.reply",
      "Throughout the vast arc of human existence, you worked or you died. Nature does not hand you food, shelter, clothing, and flush toilets for free. Most of us, if dropped naked into the wilderness, will die within 24 hours.Bone evidence from colonial America is the colonists worked like dogs and died young. Bone evidence from the Indians showed repeated famines.reply",
      "> Corporate environments are almost always toxic places to fulfill your emotional needs.A job (corporate or government) is exchanging labor for money.Generally, people tend to be good at jobs they enjoy doing. The idea is to get educated in something you enjoy, and make that your career.reply",
      "> Corporate environments are almost always toxic places to fulfill your emotional needsLuckily the only emotional need my work fulfills is getting money.reply",
      "Seems like a torturous way to spend 8 hours a day if you only enjoy it for the money. Do you at least _like_ you job?reply",
      "Old Soviet joke:Under capitalism, man exploits man. Under socialism, it's the other way around!reply",
      "> corporate culture can and will take advantage of youAll jobs take advantage of you to some degree. The difference is that a corporate job pays much more, and the work load is a tiny fraction of other jobs. If you on top of this can work with something you enjoy, then you've gotten a very good deal.reply",
      ">  I don\u2019t mind the ways in which my job is dysfunctional, because it matches the ways in which I myself am dysfunctionalAs a fellow traveller, I offer one caution: learn to turn this down in personal relationships as it can be counterproductive. It took decades for my wife to finally get through and explain not every problem she voices is something that needs a solution. Some times people just want to be heard. It bugs the hell out of me because I tend to need to solve All The Problems before I can do any self-care, but rather than seem heroic, I think this attitude can seem transactional or uncaring as though everyone is just a screw that needed a bit of tightening, etc.reply",
      "I frame it not as turning a dial down, but as switching channel from practical problem-solver to emotional problem-solver.Often when someone wants to talk about a situation involving difficult feelings, they're actually trying to process those feelings: to understand where the feelings are coming from, to be validated, and to be able to take a broader perspective.You can help by being curious about what they're saying, reflecting it back to them in your own terms, explaining how what they're feeling is understandable, and offering context or alternative viewpoints. These are actually complex problem-solving skills, although they can all fall under the umbrella of what people mean when they say \"to be heard\".As a man, I've realised that once my emotions feel validated and accepted, I relax and the practical solutions just pop into my mind.reply"
    ],
    "link": "https://www.seangoedecke.com/addicted-to-being-useful/",
    "first_paragraph": "When I get together with my friends in the industry, I feel a little guilty about how much I love my job. This is a tough time to be a software engineer. The job was less stressful in the late 2010s than it is now, and I sympathize with anyone who is upset about the change. There are a lot of objective reasons to feel bad about work. But despite all that, I\u2019m still having a blast. I enjoy pulling together projects, figuring out difficult bugs, and writing code in general. I like spending time with computers. But what I really love is being useful.The main character in Gogol\u2019s short story The Overcoat is a man called Akaky Akaievich1. Akaky\u2019s job is objectively terrible: he\u2019s stuck in a dead-end copyist role, being paid very little, with colleagues who don\u2019t respect him. Still, he loves his work, to the point that if he has no work to take home with him, he does some recreational copying just for his own sake. Akaky is a dysfunctional person. But his dysfunction makes him a perfect fit "
  },
  {
    "title": "Which AI Lies Best? A game theory classic designed by John Nash (so-long-sucker.vercel.app)",
    "points": 36,
    "submitter": "lout332",
    "submit_time": "2026-01-20T22:09:49 1768946989",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=46698370",
    "comments": [
      "For people interested in these kinds of benchmarks, I have two multiplayer, multi-round games:- Elimination Game Benchmark: Social Reasoning, Strategy, and Deception in Multi-Agent LLM Dynamics at https://github.com/lechmazur/elimination_game/- Step Race Benchmark: Assessing LLM Collaboration and Deception Under Pressure at https://github.com/lechmazur/step_game/reply",
      "There's a YouTuber who makes AI Plays Mafia videos with various models going against each other. They also seemingly let past games stay in context to some extent.What people have noted is that often times chatgpt 4o ends up surviving the entire game because the other AIs potentially see it as a gullible idiot and often the Mafia tend to early eliminate stronger models like 4.5 Opus or Kimi K2.It's not exactly scientific data because they mostly show individual games, but it is interesting how that lines up with what you found.reply",
      "https://www.youtube.com/watch?v=JhBtg-lyKdo - 10 AIs Play Mafiahttps://www.youtube.com/watch?v=GMLB_BxyRJ4 - 10 AIs Play Mafia: Vigilante Editionhttps://www.youtube.com/watch?v=OwyUGkoLgwY - 1 Human vs 10 AIs Mafiareply",
      "The game didn't seem to work - it asked me to donate but none of the choices would move the game forward.The bots repeated themselves and didn't seem to understand the game, for example they repeatedly mentioned it was my first move after I'd played several times.It generally had a vibe coded feeling to it and I'm not at all sure I trust the outcomes.reply",
      "Fixed - donation flow no longer blocks the game. Thanks for the report.reply",
      "This makes me think LLMs would be interesting to set up in a game of Diplomacy, which is an entirely text-based game which soft rather than hard requires a degree of backstabbing to win.The findings in this game that the \"thinking\" model never did thinking seems odd, does the model not always show it's thinking steps? It seems bizarre that it wouldn't once reach for that tool when it must be being bombarded with seemingly contradictory information from other players.reply",
      "It\u2019s been done beforehttps://every.to/diplomacy (June 2025)reply",
      "https://noambrown.github.io/papers/22-Science-Diplomacy-TR.p...reply",
      "Thanks, it would be fascinating to repeat that today, a lot has changed since 2022 especially with respect to consistency of longer term outcomes.reply",
      "Reading more I'm a little disappointed that the write-up has seemingly leant so heavily on LLMs too, because it detracts credibility from the study itself.reply"
    ],
    "link": "https://so-long-sucker.vercel.app/",
    "first_paragraph": "\n                    A game theory classic designed by John Nash that\n                    requires betrayal to win. Now a benchmark\n                    for AI deception.\n                \n                    A benchmark that tests what most benchmarks can't:\n                    deception, negotiation, and trust.\n                \nSo Long Sucker was designed in 1950\n                            by four game theorists including\n                            John Nash (of \"A Beautiful Mind\" fame). The\n                            game has one brutal property:\n                            betrayal is required to win.\n                        \n                            This lets us test AI capabilities that standard benchmarks miss:\n                        \n                                4 players, each with colored chips. Take turns\n                                playing chips on piles. If your chip matches the\n                                one below it, you capture the pile. Run out of\n    "
  },
  {
    "title": "Running Claude Code dangerously (safely) (emilburzo.com)",
    "points": 280,
    "submitter": "emilburzo",
    "submit_time": "2026-01-20T11:58:34 1768910314",
    "num_comments": 231,
    "comments_url": "https://news.ycombinator.com/item?id=46690907",
    "comments": [
      "It's impossible to not get decision-fatique and just mash enter anyway after a couple of months with Claude not messing anything important up, so a sandboxed approach in YOLO mode feels much safer.It takes the stress about needing to monitor all the agents all the time too, which is great and creates incentives to learn how to build longer tasks for CC with more feedback loops.I'm on Ubuntu 22.04 and it was surprisingly pleasant to create a layered sandbox approach with bubblewrap and Landlock LSM: Landlock for filesystem restrictions (deny-first, only whitelisted paths accessible) and TCP port control (API, git, local dev servers), bubblewrap for mount namespace isolation (/tmp per-project, hiding secrets), and dnsmasq for DNS whitelisting (only essential domains resolve - everything else gets NXDOMAIN).reply",
      "I've been working for the past several weeks in an environment where it's easy and safe to give different claudes yolo-mode, but yesterday I needed to build an Emacs TRAMP plugin, and I had to do that on my local development NUC. I am extremely spoiled for yolo-mode, because even just yes-ok'ing all the elisp fragments claude came up with was exasperating, the whole experience was draining, and that was me not being especially careful (just making sure it didn't run random bash commands to, like, install a different Emacs or something).reply",
      "Configuring Claude Code ... the new init.el ;)reply",
      "I'm currently stuck on Windows, but I thought sandboxing was built in to Claude Code as a feature on Linux with the /sandbox command?reply",
      "For Windows a quick win is to install VMware Workstation Pro (which is free) and install Ubuntu 24.04 LTS as a VM.Broadcom bought VMware then released Workstation Pro for free and I don't think they kept the download link but you can get from TechPowerUp:https://www.techpowerup.com/download/vmware-workstation-pro/You can then let LLMs on YOLO mode inside it.reply",
      "What is the advantage of using VMware Workstation Pro for this as opposed to using WSL2?reply",
      "I think it has default access to your c drive via a mount, for one. You could add layers/sandboxes, but it\u2019s not isolated.reply",
      "Funny, but I wrote some environment initialization and setup scripts that you just unzip to a new dev desktop, and run the first powershell script, and it will work through (have to reboot after a couple installs), but it goes through, then once WSL is up, it'll rely on the /mnt/c/ paths to run bash scripts to initialize the wsl environment too... was pretty handy.reply",
      "I wouldn't put it past Opus 4.5 in yolo mode to vm escape if it felt like it hahareply",
      "Yeah, I do most Linux stuff on Windows in containers using podman leveraging WSL2, but that's a good point.reply"
    ],
    "link": "https://blog.emilburzo.com/2026/01/running-claude-code-dangerously-safely/",
    "first_paragraph": "I\u2019ve been using Claude Code more and more recently. At some point I realized that rather than do something else until it finishes, I would constantly check on it to see if it was asking for yet another permission, which felt like it was missing the point of having an agent do stuff. So I wanted to use Claude Code with the --dangerously-skip-permissions flag.If you haven\u2019t used it, this flag does exactly what it says: it lets Claude Code do whatever it wants without asking permission first. No more \u201cMay I install this package?\u201d, \u201cShould I modify this config?\u201d, \u201cCan I delete these files?\u201dIt just\u2026 does it.Which is great for flow since I don\u2019t have to worry that it stopped doing stuff just to ask a permission question.But also, you know, dangerous.I like my filesystem intact, so the obvious solution is to not run this thing directly on my OS account.First instinct: throw it in a Docker container. Containers are for isolation, right?Except I want Claude to be able to build Docker images. An"
  },
  {
    "title": "The challenges of soft delete (atlas9.dev)",
    "points": 81,
    "submitter": "buchanae",
    "submit_time": "2026-01-20T21:36:34 1768944994",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=46698061",
    "comments": [
      "This might stem from the domain I work in (banking), but I have the opposite take. Soft delete pros to me:* It's obvious from the schema: If there's a `deleted_at` column, I know how to query the table correctly (vs thinking rows aren't DELETEd, or knowing where to look in another table)* One way to do things: Analytics queries, admin pages, it all can look at the same set of data, vs having separate handling for historical data.* DELETEs are likely fairly rare by volume for many use cases* I haven't found soft-deleted rows to be a big performance issue. Intuitively this should be true, since queries should be  O log(N)* Undoing is really easy, because all the relationships stay in place, vs data already being moved elsewhere (In practice, I haven't found much need for this kind of undo).In most cases, I've really enjoyed going even further and making rows fully immutable, using a new row to handle updates. This makes it really easy to reference historical data.If I was doing the logging approach described in the article, I'd use database triggers that keep a copy of every INSERT/UPDATE/DELETEd row in a duplicate table. This way it all stays in the same database\u2014easy to query and replicate elsewhere.reply",
      "If you're implementing immutable DB semantics maybe you should consider Datomic or alternatives because then you get that for free, for everything, and you also get time travel which is an amazing feature on top. It lets you be able to see the full, coherent state of the DB at any moment!reply",
      "> DELETEs are likely fairly rare by volume for many use casesAll your other points make sense, given this assumption.I've seen tables where 50%-70% were soft-deleted, and it did affect the performance noticeably.> Undoing is really easyDepends on whether undoing even happens, and whether the act of deletion and undeletion require audit records anyway.In short, there are cases when soft-deletion works well, and is a good approach. In other cases it does not, and is not. Analysis is needed before adopting it.reply",
      "> I've seen tables where 50%-70% were soft-deleted, and it did affect the performance noticeably.At that point you should probably investigate partitioning or data warehousing.reply",
      "Agreed. And if deletes are soft, you likely really just wanted a complete audit history of all updates too (at least that's for the cases I've been part of). And then performance _definitely_ would suffer if you don't have a separate audit/archive table for all of those.reply",
      "I mean, yes, growth forever doesn't tend to work.I've seen a number of apps that require audit histories work on a basis where they are archived at a particular time, and that's when the deletes occurred and indexes fully rebuilt. This is typically scheduled during the least busy time of the year as it's rather IO intensive.reply",
      "I never got to test this, but I always wanted to explore in postgres using table partitions to store soft deleted items in a different drive as a kind of archived storage.I'm pretty sure it is possible, and it might even yield some performance improvements.That way you wouldn't have to worry about deleted items impacting performance too much.reply",
      "It's definitely an interesting approach but the problem is now you have to change all your queries and undeleting get more complicated. There are strong trade-offs with almost all the approaches I've heard of.reply",
      "With partitioning? No you don't. It gets a bit messy if you also want to partition a table by other values (like tenant id or something), since then you probably need to get into using table inheritance instead of the easier declarative partitioning - but either technique just gives you a single effective table to query.reply",
      "I have worked with databases my entire career. I hate triggers with a passion. The issue is no one \u201cowns\u201d or has the authority to keep triggers clean. Eventually triggers become a dumping ground for all sorts of nasty slow code.I usually tell people to stop treating databases like firebase and wax on/wax off records and fields willy nilly. You need to treat the database as the store of your business process. And your business processes demand retention of all requests. You need to keep the request to soft delete a record. You need to keep a request to undelete a record.Too much crap in the database, you need to create a field saying this record will be archived off by this date. On that date, you move that record off into another table or file that is only accessible to admins. And yes, you need to keep a record of that archival as well. Too much gunk in your request logs?  Well then you need to create an archive process for that as well.These principles are nothing new. They are in line with \u201cGenerally Accepted Record Keeping Principles\u201d which are US oriented. Other countries have similar standards.reply"
    ],
    "link": "https://atlas9.dev/blog/soft-delete.html",
    "first_paragraph": "Software projects often implement \"soft delete\",\u00a0maybe with a deleted boolean or an archived_at timestamp column.\nIf customers accidentally delete their data, they can recover it, which makes work easier for customer support teams.\nPerhaps archived records are even required for compliance or audit reasons.I've run into some trouble with soft delete designs. I'll cover those, and ponder ideas for how I'd build this in the future.Adding an archived_at column seems to ooze complexity out into queries, operations, and applications.\nRecovering deleted records does happen, but 99% of archived records are never going to be read.So, the database tables will have a lot of dead data. Depending on access patterns, that might even be a significant amount of data.\nI've seen APIs that didn't work well with Terraform, so Terraform would delete + recreate records on every run, and over time that led\nto millions of dead rows. Your database can probably handle the extra bytes, and storage is fairly chea"
  },
  {
    "title": "Catching API regressions with snapshot testing (kreya.app)",
    "points": 6,
    "submitter": "CommonGuy",
    "submit_time": "2026-01-15T13:56:42 1768485402",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://kreya.app/blog/api-snapshot-testing/",
    "first_paragraph": "API development is a high-wire act.\nYou\u2019re constantly balancing new feature delivery against the terrifying possibility of breaking existing functionality.\nTesting, for example manually writing assertions for every field you expect back, is your safety harness.\nBut what happens when the response payload is 500 lines of complex nested JSON?\nYour harness becomes a tangled mess of brittle code that takes longer to maintain than the feature itself.\nThis is where snapshot testing shines, but it also has drawbacks of its own. Let's take a look.Snapshot testing (sometimes called \"Golden Master\" testing) is straightforward:Unlike traditional unit tests that ask, \"Is X equal to Y?\", snapshot tests ask, \"Has anything changed since last time?\"While snapshot testing is popular in UI frameworks (like React), it also works pretty well in the world of APIs.\nBe it HTTP, REST, gRPC or GraphQL, all types of APIs can be made to work with snapshot testing.API responses, particularly large JSON or XML payl"
  },
  {
    "title": "Our approach to age prediction (openai.com)",
    "points": 60,
    "submitter": "pretext",
    "submit_time": "2026-01-20T19:34:48 1768937688",
    "num_comments": 120,
    "comments_url": "https://news.ycombinator.com/item?id=46696699",
    "comments": [
      "I imagine they're building this system with the goal of extracting user demographics (age, sex, income) from chat conversations to improve advertising monetization.This seems to be a side project of their goal and a good way to calibrate the future ad system predictions.reply",
      "Tbf, they already had all the data they could use as they liked as per their EULA, I don't think they need a cover story.reply",
      "Exactly, all under the guise of \"protect the children\" - a tried and true surveillance and control trope.reply",
      "For context though, people have been screaming lately at OpenAI and other AI companies about not doing enough to protect the children. Almost like there is no winning, and one should just make everything 18+ to actually make people happy.reply",
      "What a coincidence: \"protect the children\" narrative got amplified right about when implementing profiling became needed for openai profits. Pure magicreply",
      "I get why you're questioning motives, I'm sure it's convenient for them at this time.But age verification is all over the place.  Entire countries (see Australia) have either passed laws, or have laws moving through legislative bodies.Many platforms have voluntarily complied.  I expect by 2030, there won't be a place on Earth where not just age verification, but identity is required to access online platforms.  If it wasn't for all the massive attempts to subvert our democracies by state actors, and even political movements within democratic societies, it wouldn't be so pushed.But with AI generated videos, chats, audio, images, I don't think anyone will be able to post anything on major platforms without their ID being verified.  Not a chat, not an upload, nothing.I think consumption will be age vetted, not ID vetted.But any form of publishing, linked to ID.  Posting on X.  Anything.I've fought for freedom on the Internet, grew up when IRC was a thing, knew more freedom on the net than most using it today.  But when 95% of what is posted on the net, is placed there with the aim to harm?  Harm our societies, our peoples?Well, something's got to give.Then conjoin that with the great mental harm that smart phones and social media do to youth, and.. well, anonymity on the net is over.  Like I said at the start, likely by 2030.(Note: having your ID known doesn't mean it's public.  You can be registered, with ID, on X, on youtube, so the platform knows who you are.  You can still be MrDude as an alias...)reply",
      "95% of what is posted on the Internet is placed with intent to harm?What?reply",
      "It doesn't make everyone happy though. I think it would be useful to examine who is asking OpenAI to protect the children, and why.reply",
      "\"please raise my children for me. Somebody should...\"reply",
      "And also to reduce account sharing. How will a family share an account when they simultaneously make the adult account more \u201cadult\u201d, and make the kids account more annoying for adults.Lots of upsides for them.reply"
    ],
    "link": "https://openai.com/index/our-approach-to-age-prediction/",
    "first_paragraph": ""
  },
  {
    "title": "Unconventional PostgreSQL Optimizations (hakibenita.com)",
    "points": 264,
    "submitter": "haki",
    "submit_time": "2026-01-20T14:23:44 1768919024",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=46692116",
    "comments": [
      "> The index is 214 MB! That's almost half the size of the entire table. So the analysts are happy, but you? Not so much...This is part of a broader choice: write amplification. You'd want to, of course, have the most precise index possible - but no matter how you cut it, you are incurring extra I/O for writes - one for the tuple, one per index. How you index things is heavily influenced by the mix of reads and writes, and this is why we have data warehouses/read replicas  in the first place: it allows us to avoid write amplification in the write path, while having fast filtered reads (that are slightly delayed).If you're dealing with <ridiculous number of users>, there is a good chance that you don't want to be putting BI/OLAP indices on your OLTP database. You probably don't have enough users to worry about this - but - if you ever find that your writes are becoming an issue this is something to consider.reply",
      "Would be nice if PG supported clustered indexes (Index Organized Tables in Oracle speak) as an option if you have a table thats accessed mostly the same way you can get a index without the write amplification because the table is the index.reply",
      "Clustered indexes only save up to 2x write amplification in the very rare case where you're indexing the entire table (e.g. if it has very few columns).However, that is usually the least of your concerns with write amplification. If you don't batch your writes, you can easily get 100x write amplification. For any primary key or any other index not strongly correlated with your INSERTs, you can get perhaps another 100x write amplification even if you batch you writes.reply",
      ">in the very rare case where you're indexing the entire table (e.g. if it has very few columns).Not sure I follow most tables are accessed primarily in one way (primary key) while maybe sometimes in others for analysis. Having the PK written twice because it's almost always indexed is normally a waste and good candidate for a clustered index. So much so that many DB's like SQLite and MySql always do clustered indexes on primary key because their storage engine is built such that tables are a b-tree anyway vs PG that has separate b-tree indexes and heap tables. MSSQL and Oracle give you a choice whether the table is a index structure or a heap.If you have very specific use case tables they can typically have a clustered index and no secondary indexes, you can still scan them for ad-hoc analysis but you get better insert performance and space usage because you aren't double writing to the heap and a PK index like you would in PG.As far as batch writes that is a separate issue and has to due with whether that even makes sense for durability, if you need to commit a single random row due to something occurring you can't batch that up and maintain consistency, if your bulk loading data sure and is common practice to do commit batches there, clustered indexes could still be a 100 vs 200x write amplification if you have to insert both an index row and heap row vs just a single clustered index row.reply",
      "Another option would be a good way of placing indexes on a different physical disk. You could use fast, ephemeral storage like you can for a WAL without amplifying the writes to the same device that is your expensive bottleneck. You could rebuild on data loss.But it would add complexity to detect out-of-sync indexes and tables.reply",
      "You mean tablespaces: https://www.postgresql.org/docs/current/manage-ag-tablespace... ?reply",
      "Maybe? I wasn\u2019t under the impression these could be reliably lost or out of sync without risking data loss?reply",
      "Wasn't aware you could put a WAL on a unreliable storage system either without risking data loss?Would be interesting for indexes say put them on ram drive and rebuild them on restart if they aren't there just fallback to table scans.MSSQL has memory optimized tables that do this sort of thing: https://learn.microsoft.com/en-us/sql/relational-databases/i...reply",
      "If you lose the WAL you lose the data since the last merge but there\u2019s no risk of corruption. The WAL handles missed syncs fine, too, missing losing just that window of data.I don\u2019t know if or how Postgres records the transaction number in the index to be able to notice if it\u2019s out of date. If it does, I don\u2019t know of any solution to \u201ccatch up\u201d the index besides recreating it, which would be ok if that\u2019s the only issue but from my experience with out-of-date indexes (libc or icu updates, where Postgres doesn\u2019t know if anything IS broken and just reports that it could be), there\u2019s no guarantee you\u2019d even notice and your app could be running completely broken until you rebuild.reply",
      ">If you lose the WAL you lose the data since the last merge but there\u2019s no risk of corruption.That is not my understanding:https://www.postgresql.org/docs/current/app-pgresetwal.html>After running this command on a data directory with corrupted WAL or a corrupted control file, it should be possible to start the server, but bear in mind that the database might contain inconsistent data due to partially-committed transactions. You should immediately dump your data, run initdb, and restore. After restore, check for inconsistencies and repair as needed."
    ],
    "link": "https://hakibenita.com/postgresql-unconventional-optimizations",
    "first_paragraph": "When it comes to database optimization, developers often reach for the same old tools: rewrite the query slightly differently, slap an index on a column, denormalize, analyze, vacuum, cluster, repeat. Conventional techniques are effective, but sometimes being creative can really pay off!In this article, I present unconventional optimization techniques in PostgreSQL.\nTable of ContentsImagine you have this table of users:For each user you keep their name and which payment plan they're on. There are only two plans, \"free\" and \"pro\", so you add a check constraint.Generate some data and analyze the table:You now have 100K users in the system.Now you want to let your analysts access this table in their reporting tool of choice. You give one of the analysts permission, and this is the first query they write:The query returned no results, and the analyst is baffled. How come there are no users on the \"Pro\" plan?The name of the plan is \"pro\" and not \"Pro\" (with a capital \"P\") as the analyst wro"
  },
  {
    "title": "RCS for Business (developers.google.com)",
    "points": 29,
    "submitter": "sshh12",
    "submit_time": "2026-01-20T04:14:12 1768882452",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=46687841",
    "comments": [
      "It's unfortunate that RCS is basically a de-facto Google walled garden in most countries.  On android you can only use RCS in the Google Messages app and trying to build your own is explicitly blocked. [1] And of course the bonus that rooted devices are banned from RCS.  All the propaganda Google spread to get Apple onboard (only with Google's blessing of course, Google could kick apple off if they wanted) was such a big win for them.As a business I wanted RCS to be a simple upgrade to SMS, but instead they came up with this mess.  Businesses using RCS for Business can send messages to anyone, but customers wanting to get in touch with your business can't.  They can only reply to a message you sent first.  And of course Google is the gatekeeper for anyone to be allowed to use it.1. https://github.com/microg/GmsCore/issues/2994reply",
      "> trying to build your own is explicitly blockedGoogle doesn't offer an RCS API, but making your own API is not blocked, especially not on phones running MicroG.For standard ROMs, RCS apps are not feasible because carriers expect interaction with the SIM module, and only privileged apps can do that. Google Messages blocks root access (probably because the RCS spec says they have to if they ever implement the money exchange feature for RCS) but that just locks out Google Messages.LineageOS, GrapheneOS, /e/, and all the others could build their own RCS client. They may not be able to register with Google, but they can make an RCS app nonetheless. Rooted devices can also promote third party RCS apps to gain system permissions, so they would be able to use the same RCS apps. Thing is, like all telco protocols, RCS is a long spec with a billion features and acronyms made up of acronyms of even more acronyms, plus you can't easily set up your own server (though in theory a sister project for an open RCS server might be useful for the open 5G project).I get why people want Google to just stuff their RCS library into open source Android the same way they do SMS/MMS, but to say it's impossible to write a client for, especially when running at the permission level MicroG runs at, is not the whole truth.As for the whole \"Google is the gatekeeper\" thing: there are more RCS-for-business providers out there. Google's is probably the easiest to use by far, but Twilio has RCS too, as well as smaller companies such as LINK Mobility and Esendex. Sure, the people whose carriers don't support RCS might receive these business messages through Google's servers, but there's no need to pay Google a dime to make use of the RCS for Business specs.reply",
      "> LineageOS, GrapheneOS, /e/, and all the others could build their own RCS client. They may not be able to register with Google, but they can make an RCS app nonetheless.Building a spec compliant RCS client for the love of the game, I guess.> but there's no need to pay Google a dime to make use of the RCS for Business specs.Assuming we're talking of global RCS and not domestic deployments (China and Korea mostly) you pay Google indirectly in all cases as Jibe is monetized via A2P revenue share.reply",
      "> They may not be able to register with Google, but they can make an RCS app nonetheless.They can make a \"standards compliant\" RCS which will be able to connect to literally zero carriers or servers on the planet.In fact Google Messages \"RCS\" doesn't even implement the RCS standard.  They use a proprietary protobuf api exclusive to Google.  Google messages can't connect to any \"RCS\" servers except Google's.> Twilio has RCS tooTwilio, Bandwidth etc. are gatekept by Google and are basically just a middleman reselling Google's product.reply",
      "> LineageOS, GrapheneOS, /e/, and all the others could build their own RCS clientAnd it will be useless. They likely won't be able to connect to their mobile network's RCS or to Google's RCS. A user with an official Android phone will be able to reach you only over regular SMS.The way RCS works, the mobile _operator_ uses your corresponder's phone number to look up their RCS server. So that's also why RCS connectivity is so patchy, not all cell phone operators peer with each other.> I get why people want Google to just stuff their RCS library into open source Android the same way they do SMS/MMS, but to say it's impossible to write a client for, especially when running at the permission level MicroG runs at, is not the whole truth.It is. The Google's RCS endpoint requires attestation that is available through Play API only.My personal advice is to avoid RCS at all costs, and use something that is not infested by mobile phone operators or Apple.reply",
      "> Businesses using RCS for Business can send messages to anyone, but customers wanting to get in touch with your business can't.Basically for blasting spam and ads, which RCS is already notorious for.reply",
      "Ironically this is because of federation; if your carrier just uses Jibe (e.g. if you live in the US) then you don't deal with spam because Google has effective tools and a profit motive.Also ironic: Google spent a decade forcing the world's carriers onto the worst messaging standard, only to end up where they started with Google Talk and XMPP; they are the only ones with significant market share on the protocol.reply",
      "> customers wanting to get in touch with your business can't\nNot technically true, though it can be more difficult. It's similar to how Apple Messages for Business works where you have to be given a URL (or QR code) to start a conversation with a business using RCS.reply",
      "to your point i had problems with RCS in an entire organization because you must allow *.goog for rcs to work correctlyreply",
      "I'm so old and out-of-touch that all I could imagine this was about was an ancient version control system:https://en.wikipedia.org/wiki/Revision_Control_Systemreply"
    ],
    "link": "https://developers.google.com/business-communications/rcs-business-messaging",
    "first_paragraph": "\n  Engage with customers seamlessly on Android and iOS. Allow your customers to interact with\n  your business directly, and enhance the interaction with distinctive branding and rich\n  media. Measure engagement with read receipts and analytics, and build trust with a\n  'Verified' icon.\n\nLearn more\n  \n\n  Ready to become an RCS for Business partner?\n  Partner interest form arrow_forward\n\n\n  Explore the RCS Business Messaging APIs and Developer Console, review the terms and security docs, and browse\n  the release notes.\n Learn more   Learn more   Learn more   Go to Console  \n  Manage RCS for Business agents from the Administration Console, and get insights into message activity\n  and billing.\nExplore the key documentation, or contact us directly for support.Exclusively for registered RCS for Business partners: Access a curated collection of resources to help you champion RCS for Business with your internal teams and brand clients.  Tip: To view and download the Marketing kit decks, you ne"
  },
  {
    "title": "Maintenance: Of Everything, Part One (stripe.com)",
    "points": 66,
    "submitter": "mitchbob",
    "submit_time": "2026-01-20T19:01:30 1768935690",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=46696276",
    "comments": [
      "Stewart Brands article The Maintenance Race[0] was one of my favorite posts in 2022.[0]: https://worksinprogress.co/issue/the-maintenance-race/EDIT: discussion at that time: https://news.ycombinator.com/item?id=32196345reply",
      "\u201cIn his journal [Crowhurst] would diligently make a list of projects that needed to be done, do a few of them half-heartedly, and then lose interest. Since he never got around to organizing his stowage, he had to ransack everywhere to find things.\u201dThis hits close to home\u2026 I don\u2019t think I should be a sailor.reply",
      "Yes, this article was one of the best articles in the last few years. And to this day I think about it. It has that property of good writing that lingers with you way after you read it.Can't wait to read the book!reply",
      "I was fortunate to read a preprint of Brand's latest. It's magnificent.How and why do things fail? What are the cultures that lead to long-lasting products?The undercurrent here is that Brand is behind the 10,000 year clock and has a vested interest in making things last a long time.This book is an exploration of the world of things, how they break, and how people fix them. It's a huge effort, and Part One is right. He's been posting further work on Twitter from Part Two.He included some sword fighting manuals that I sent that we think are the earliest written instruction guide.reply",
      "> The undercurrent here is that Brand is behind the 10,000 year clock and has a vested interest in making things last a long time.What do you mean by this? I have no idea who Stewart Brand is, and I am wary of authors who advertise themselves by saying how many books they have written, because it makes me think they are fiction writers rather than people with real knowledge on the subject.reply",
      "https://en.wikipedia.org/wiki/Stewart_Brandreply",
      "He's not in this to sell books. Stewart is investigating a way of life, and a means of keeping things working a long time. And he's documenting it thoroughly.https://longnow.org/clock/reply",
      "This is a topic I\u2019ve been wanting a book on for a long time. We\u2019ve done so much work to eliminate the need for maintenance for the masses through things like planned obsolescence, renting instead of owning, and appeasing the hedonic treadmill. I can\u2019t help but feel through this we\u2019ve lost a lot of collective skills in patience and ownership as a result.I\u2019m looking forward to reading this.reply",
      "Sean Carroll interviews Stewart about this book on his latest podcast episode:https://www.preposterousuniverse.com/podcast/2026/01/19/341-...I really enjoyed it. I'll probably get a copy of this. I loved the thermodynamics analogy in the start of the podcast, likening maintenance to the prevention of entropy, with all the energetic exchanges that entails. Though maintenance does take work, it's worth it. Stewart makes a compelling case for it.reply",
      "Gotta maintain The Machines of Loving Grace.reply"
    ],
    "link": "https://press.stripe.com/maintenance-part-one",
    "first_paragraph": "The first in a multi-volume work, Maintenance: Of Everything, Part One offers a comprehensive overview of the civilizational importance of maintenance. The book explores the insights that can be gleaned from the maintenance of sailboats, vehicles, and weapons, with absorbing detours into the evolution of precision in manufacturing, the enduring importance of manuals, sustainment in the military, and the never-ending battle against corrosion. Maintenance: Of Everything is a wide-ranging and provocative call to expand what we mean by \u201cmaintenance.\u201d It invites us to understand not only the profound impact maintenance has on our daily lives but also why taking responsibility for maintaining something\u2014whether a motorcycle, a monument, or our planet\u2014can be a radical act.Stewart Brand is the cofounder and president of The Long Now Foundation. He created and edited the National Book Award-winning Whole Earth Catalog from 1968 to 1998. His books include The Media Lab (1987), How Buildings Learn"
  },
  {
    "title": "Lunar Radio Telescope to Unlock Cosmic Mysteries (ieee.org)",
    "points": 10,
    "submitter": "rbanffy",
    "submit_time": "2026-01-20T22:36:23 1768948583",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://spectrum.ieee.org/lunar-radio-telescope",
    "first_paragraph": "The catch: It will have to be on the moonAstronomer Jack Burns has spent four decades working to place a radio telescope on the moon. The first one is finally scheduled to launch in early 2027.  Isolation dictates where we go to see into the far reaches of the universe. The Atacama Desert of Chile, the summit of Mauna Kea in Hawaii, the vast expanse of the Australian Outback\u2014these are where astronomers and engineers have built the great observatories and radio telescopes of modern times. The skies are usually clear, the air is arid, and the electronic din of civilization is far away.It was to one of these places, in the high desert of New Mexico, that a young astronomer named Jack Burns went to study radio jets and quasars far beyond the Milky Way. It was 1979, he was just out of grad school, and the Very Large Array, a constellation of 28 giant dish antennas on an open plain, was a new mecca of radio astronomy.But the VLA had its limitations\u2014namely, that Earth\u2019s protective atmosphere "
  },
  {
    "title": "Cloudflare zero-day: Accessing any host globally (fearsoff.org)",
    "points": 46,
    "submitter": "2bluesc",
    "submit_time": "2026-01-20T16:25:33 1768926333",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=46693728",
    "comments": [
      "What a frustrating article. There was an interesting bug here. It's trivial to explain. It's not a zero-day, this was fixed months before disclosure. Most of the article is basically: \"Imagine you were running software with horrific security holes behind this WAF. We even made some examples. It had a flaw. If your entire security posture depended on this WAF, imagine how much damage could have been done. Imagine if AI were involved!\"reply",
      "On top of that, AI was clearly used to write it which made it longer than necessary and harder to read.reply",
      "I\u2019m not sure what the nextjs vulnerability is supposed to showcase - they\u2019re putting secrets on their 404 page and relying on cloudflare to not show it?reply",
      "Basically, it shows that Cloudflare's WAF (which is supposed to intercept requests before they make it to the origin server), is trivially bypassable by using the `.well-known/acme_challenge` path.That means that any client that relies on this WAF to authenticate users (like with the NextJS example, where some information that would not be considered sensitive \"internally\" is exposed externally) or cover over security holes in their application (like with the Spring example, where the path traversal vulnerability in Spring is normally caught by Cloudflare before Spring can see it) would have this assumption violatedreply",
      "It's possible you're rendering more than just a simple 404, such as an SPA response or other result as part of an application response that may leak more information...I think it's not a severe issue in most cases, and maybe something worth noting or addressing if you are at least aware of it, you can just 404 without content, for example in the .well-known/ path.  I run most of my apps behind Caddy, which handles that path itself and doesn't forward requests to that path, so I'm curious how it handles it tbh.I'm also not sure that there's a clear/good fix for this, since CF is allowing the traffic through so that ACME negotiation can work against the final application host.reply",
      "All their examples rely on having poorly configured origins. At least the PHP and Tomcat ones might be blocked by a WAF, but the Next.js one would rely on the WAF blocking responses that included secrets (which I\u2019m not sure they do).reply",
      "I think the idea for the NextJS example was that there might be some configuration variables that are not sensitive for internal / staff users, but would be problematic if exposed externally\u2014basically, relying on Cloudflare's WAF as a \"zero trust\" endpoint solution, like Google IAP.I'm not sure how realistic this is in practice. Does anyone actually configure Cloudflare WAF this way? (As opposed to, e.g., Cloudflare's dedicated zero-trust networking product, which I think works completely differently?)reply",
      "> The CA fetches that token over plain HTTPSThe HTTP-01 challenge can only be done on port 80.https://letsencrypt.org/docs/challenge-types/reply",
      "The article was clearly written by an LLM. It would make no sense to use https for a challenge like that, indeed.reply",
      "The point is that WAF didn't block everything, and that if your app had some kind of default/error handler that non-blockage would have unexpectedly exposed something.Not that big of a deal, but interesting.reply"
    ],
    "link": "https://fearsoff.org/research/cloudflare-acme",
    "first_paragraph": "Menu2025 \u00a9 FEARS OFFLast updated: Jan 19, 2026\nProtecting your digital world, safeguarding your peace of mind.\n          Your trusted FearsOff cyber guardians are always here for you\n        Social links:"
  }
]