[
  {
    "title": "Quill OS \u2013 an open-source, fully-functional standalone OS for Kobo eReaders (quill-os.org)",
    "points": 65,
    "submitter": "Curiositry",
    "submit_time": "2025-12-16T00:22:41 1765844561",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=46283016",
    "comments": [
      "This is very timely, as I recently purchased a Kobo device. One painpoint has been syncing sideloaded books between my phone and Kobo. I am using Readest sync with KOReader but I'd love to see a more seamless solution. Hoping that Quill can offer some sort of sync in the future.reply",
      "KOReader has built in Progress Sync, which works well for the purpose.reply",
      "By OS I take it this includes a kernel and is a full replacement of the native Kobo OS (Nickel)? If so, then I wonder if it's possible to get Kobos to boot directly into KOReader.reply",
      "We should fully own what we buy, things like this are essentialreply",
      "I don't see anything about libby/overdrive support which isn't surprising but is unfortunate.Integration with libraries is the killer feature of ereaders IMOreply",
      "I love the idea of OverDrive but I've yet to have success with it. Either the book I'm interested in isn't available or it's unavailable for weeks. I don't have a ton of time to read or to drop what I am reading when something becomes available, so I usually just wind up buying the book if I'm really excited about it.Granted, my library is not part of a major city's system but it's also not what I'd call a small one. I'd be curious to know how NYC or Chicago compare, as those are where people I know have had very positive experiences with these options.reply",
      "What works for me with overdrive is using holds and then when it comes available, if I'm not ready to read I let someone skip ahead of me. That way I'm still next in line but it gives me a few days until someone else finishes the book and then it pings me again.reply",
      "If you read one book a quarter then yeah it\u2019s not for you. If you read one book a week you can queue up fifty good books and wait for that one to come available at some point in the year.reply",
      "I'd love to see this on the Aura HDreply",
      "Love my jailbroken kindle, but would love a full replacement OS like this.reply"
    ],
    "link": "https://quill-os.org/",
    "first_paragraph": "Here are some of Quill OS' features:\n\n\t\t\t\t\tFully integrated KoBox X11 subsystem\n\t\t\t\t\tePUB, PDF, picture and plain text display support\n\t\t\t\t\tVersatile configuration options for reading\n\t\t\t\t\tmuPDF rendering engine for ePUBs and PDFs\n\t\t\t\t\tWi-Fi support and web browser\n\t\t\t\t\tEncrypted storage with EncFS\n\t\t\t\t\tFast dictionary & local storage search\n\t\t\t\t\tDark mode\n\t\t\t\t\tFull factory reset option if needed\n\t\t\t\t\tSeamless update process\n\t\t\t\t\tVNC viewer app\n\t\t\t\t\tSearch function\n\t\t\t\t\t10 built-in fonts\n\t\t\t\t\tAuto-suspend\n\t\t\t\t\tLock screen/passcode\n\t\t\t\t\tUser-friendly experience\n\t\t\t\t\n\n\t\t\t\t\tFully integrated KoBox X11 subsystem\n\t\t\t\t\tePUB, PDF, picture and plain text display support\n\t\t\t\t\tVersatile configuration options for reading\n\t\t\t\t\tmuPDF rendering engine for ePUBs and PDFs\n\t\t\t\t\tWi-Fi support and web browser\n\t\t\t\t\tEncrypted storage with EncFS\n\t\t\t\t\tFast dictionary & local storage search\n\t\t\t\t\tDark mode\n\t\t\t\t\tFull factory reset option if needed\n\t\t\t\t\tSeamless update process\n\t\t\t\t\tVNC viewer app\n\t\t\t\t\tSearch func"
  },
  {
    "title": "Fix HDMI-CEC weirdness with a Raspberry Pi and a $7 cable (johnlian.net)",
    "points": 167,
    "submitter": "jlian",
    "submit_time": "2025-12-15T21:37:09 1765834629",
    "num_comments": 85,
    "comments_url": "https://news.ycombinator.com/item?id=46281060",
    "comments": [
      "I wrote a program in Golang to control my a/v setup. Included within are small pkgs to control Linux CEC and LIRC devices (ioctl/read/write) as well a pkg for LG TV commands over serial port. Link here: https://github.com/EBADBEEF/tvmanOne really useful thing when getting started was to use `cec-ctl -M` to monitor the CEC traffic live. Like the author, I used the v4l-utils commands to interact with CEC but eventually got frustrated with them and rewrote my program in in Go!I have found CEC to be flaky and hard to work with. I had to turn off CEC on my TV because it breaks everything, almost randomly switching inputs and turning on and off devices.reply",
      "Modern AV stuff is insane.  I have no interest in taking it up as a hobby.  I have an xbox, a TV, and a pair of bookshelf speakers.  How am I supposed to get the audio to the speakers without a bulky expensive receiver box?  Luckily, I have one of the last remaining TVs with a headphone jack.  I don't use a remote for any of it.Side note:  Sometimes the TV doesn't come on when you press its power button.  After a tremendous amount of experimentation, I determined this was because the \"brain\" was on, but the backlight was not.  Power cycling it blind usually fixes it.  That's harder than it sounds though because you have to navigate the menu blind using short and long button presses with the one button.  But I'm scared to try a new TV, because then I'm going to have to figure out how to get audio out of the TV.It seems like AV stuff used to be so simple.  Now the simplest scenarios seem to require more and more knowledge about arcane connection standard interactions and network topology.  Ugh.reply",
      "TVs seem to expect you to use HDMI-ARC to return sound to the receiver or soundbar.  I wonder if there's any HDMI-ARC to audio dongles out there?reply",
      "That little headphone jack is seriously driving bookshelf speakers to a reasonable volume? If it works it works but that doesn't sound right, unless these are actually self-powered speakers with their own amplifiers inside. I'd really like to know the details because this sounds crazy.Also, I collect a lot of old receivers and speakers. It's really not that complicated and the basics have been the same since the 70s and 80s. Any flatscreen TV made in the past 20 years typically has a TOSLINK output which will be compatible with receivers stretching back to the 80s - I have my LG C1 connected to some 90s Marantz receiver this way. Any old receiver you find on Facebook Marketplace for $20 will typically suffice here as long as you check for the TOSLINK port first, but you do need a separate actual amplifier somewhere along the line to drive a speaker larger than a pair of headphones unless the speaker has its own amp built-in.I find all this stuff fun so my own setup has that chained to a series of other receivers acting as subwoofer amplifiers as well as using the pre-amp output to drive a Mesa Baron tube amplifier/Acoustat electrostats I was gifted, but most people don't need anything so complex.reply",
      "The jack is not driving the bookshelf speakers.  They're active.  They have their own internal amps.  It's simple if you use a receiver.  If someone can point me to a receiver that's more like 4 inches than 18 inches, then I'd consider that a solution.  Receivers are big boxes as far as I've seen.  I don't have space.  Or maybe I don't want to make space.reply",
      "It sounds like your speakers work for you then. On a modern TV without a headphone jack you would probably be served perfectly well by bluetooth speakers that sync to the TV. Though I'm surprised if a 3.5mm output is really that uncommon, because I just bought an LG C1 a few years ago and it has one. You can also find a small bluetooth receiver that would output to a headphone jack at WalMart.reply",
      "Have a look at Fosi Audio. I'm currently using a BT30D to drive the passive speakers from an old Samsung integrated amplifier+receiver+2014-era \"Smart TV\" type system that died. It only has 1 analog input and Bluetooth, but it looks like they have other products in a similar form factor that can take multiple inputs (e.g. the P4 Mini). I was skeptical but needed something cheap to drive those speakers and am quite impressed.reply",
      "Some of the bigness is just tradition and buyer expectation (big = expensive). But also, modern AVRs are like 1000W devices amplifying 7, 9, even 11 channels of passives. That\u2019s a lot of componentry and corresponding heat to shed\u2014 if you open one of those up, it\u2019s not just empty space in there like an NES cartridge or something.reply",
      "https://www.sonos.com/en-us/shop/ampSonos makes this specifically. Has an RCA and HDMI input, along with being a Sonos device for streaming audio.The only downside is the price.reply",
      "Apart from Sonos in general being awful[1][2], their web site seems to be pretty bad, too. Not only is there a modal \"subscribe to our newsletter\" box in that link, there's also a separate modal cookie warning which blocks the modal newsletter box. It's like frustrating users is core to their mission.1: https://news.ycombinator.com/item?id=426837532: https://news.ycombinator.com/item?id=21895086reply"
    ],
    "link": "https://johnlian.net/posts/hdmi-cec/",
    "first_paragraph": "For years I treated HDMI-CEC like a house spirit: sometimes helpful, mostly temperamental, never fully understood. My living-room stack is straightforward: Samsung TV on ARC (NOT eARC - story for another day), Denon AVR-X1700H hidden in a closet, Apple TV plus a bunch of consoles connected to the receiver, and a Raspberry Pi 4 already doing Homebridge duty. When it comes to CEC, the Apple TV handles it like a dream, but every console behaves like it missed the last week of CEC school. They wake the TV, switch the input, then leave the Denon asleep so I\u2019m back to toggling audio outputs manually.I documented the media closet build-out separately, so if you want the full wiring tour (and the before/after photos), start there.With the media closet, rewiring everything to the TV wasn\u2019t an option and disabling CEC wasn\u2019t viable (Apple TV works and it gets the most use). My first instinct was to lean on traditional automation stacks: HomeKit scenes to chain \u201cTV on\u201d into \u201creceiver on\u201d or watta"
  },
  {
    "title": "Ideas Aren't Getting Harder to Find (asteriskmag.com)",
    "points": 23,
    "submitter": "mitchbob",
    "submit_time": "2025-12-16T00:34:35 1765845275",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=46283129",
    "comments": [
      "My apologies for being off-topic, but it's been a long time since a website made my jaw drop with its design. So simple, nothing extra, beautiful. The images and illustrations carry it so well. Also, there are multiple cover images per issue and a random one is shown on each page visit. And the typography-- I love everything about it. Makes me miss web dev.edit: the typography combo is different for every article whaaatreply",
      "Edward Tufte strikes againreply",
      "I\u2019m working on it.reply",
      "Idea doesn't matter. Execution doesn't matter. Only social connections matter. I've seen both sides. I know what it's like to be in a privileged environment and also in a depleted environment. The exact same behavior, exact same product which can easily bring you huge amounts of money in one environment, might bring you nothing in the other.I had multiple conversation with a mainstream cutting edge LLM recently where I basically give it my career summary and it basically turns into a conspiracy theorist and starts telling me about the ways in which the system is rigged and basically stops giving me any advice; implying that there is nothing I can do.reply",
      "Would love a link to the convo to see whar you\u2019re talking about.. but understand it would be too revealing.reply",
      "TLDR; monopolism or quasi monopolism is holding back innovation at a country scale notable enough to begin changing the two century long GDP trend of 2%?reply"
    ],
    "link": "https://asteriskmag.com/issues/12-books/ideas-arent-getting-harder-to-find",
    "first_paragraph": "For half a decade we\u2019ve been worrying that ideas are getting harder to find. In fact, they might just be harder to sell.Fifty years ago, productivity growth in advanced economies began to slow down. Productivity growth \u2014 the component of GDP growth that is not due to increases in labor and capital \u2014 is the primary driver of rising incomes. When it slows, so does economic growth as a whole. This makes it an urgent trend to understand. Unfortunately, the most popular explanation for why it\u2019s happening might be wrong.The most widely endorsed reason productivity growth has faltered is that we are running out of good ideas. As this narrative has it, the many scientific and technology advances responsible for driving economic growth in the past were low-hanging fruit. Now the tree is more barren. Novel advances, we should expect, are harder to come by, and historical growth may thus be difficult to sustain. In the extreme, this may lead to the end of progress altogether.\u00a0This story began in "
  },
  {
    "title": "Nature's many attempts to evolve a Nostr (squishy.computer)",
    "points": 109,
    "submitter": "fiatjaf",
    "submit_time": "2025-12-10T23:54:34 1765410874",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=46225803",
    "comments": [
      "Reading the comments below make me feel like I should maybe be expected to already know what nostr is. But anyway, I don't and reading this article, it felt like it just suddenly cut off at the end.It explained all the traditional approaches, which are all able to help discoverability and shareability of data between servers, and then says \"the solution is relays\" and then describes something that doesn't seem to be relaying anything. It sounds like a single dumb, untrusted message store on a single server that doesn't relay anything anywhere. It even specifically says \"Relays don\u2019t talk to each other, and users only need to join a small number of relays to gain autonomy\u2014at least two, and certainly less than a dozen\".Not sure where the less than a dozen relay bit comes from. Are they expecting clients to do all the relaying between the relays? If so, wouldn't you get every relay getting pummeled by a load of clients simultaneously, all trying to push the same message. It sounds like the complete opposite of what you actually want.  The article seems to just stop short at exactly the point when it should say how what they're proposing actually works.reply",
      "Nowadays a NOSTR \"relay\" isn't exactly a relay any longer, is it?Should likely be called a \"database server\" since it's main purpose is to host user data and perform queries over it. A relay is something connecting two devices and makes a best effort to get out of their way.Nevertheless: NOSTR is the most exciting social network that I've seen in the past 20 years. The concept of owning the keys without a blockchain associated enables not just decentralization, it also permits a complete offline functioning to login, view private messages and so much more that isn't possible from any other popular social network predecessor.reply",
      "One of nature's many attempts to evolve an atproto. (We are of course all evolving, and the destination is yet to be discovered)reply",
      "I've been looking at that for quite some time, even met teams members developing the product. Sorry to say: both are fundamentally different technologies and philosophies.NOSTR \"accounts\" are meant to trivially generated and used outside the context of micro-blogging. That is the reason for being popular, the npub becomes a signature that validates texts and there is value in that.AT always feels like mastodon meets RSS with US-centric political moderation on top.reply",
      "I wouldn't write ATProto off as just microblogging, there are a bunch of interesting (and exciting depending on your POV) apps out there that _aren't_ microblogging apps.  To name a few:* https://stream.place* https://tangled.org* https://www.germnetwork.com/* https://slices.network/* https://smokesignal.events/* https://www.graze.social/reply",
      "I'll check them later. Thank you for the list.reply",
      "P2P with end-to-end encryption over relays existed in 2001 (e.g. Groove, Mojo Nation) and wasn't invented by Nostr.Nostr is so simple because it handwaves away the fact that everybody seems to use the same small set of relays and there's nothing stopping them from censoring the network. I'm also not aware of any incentives for the relay operators either.reply",
      "This exactly. Worth mentioning that \"censoring\" can occur in any of a number of ways; blocking select traffic, slowing select traffic, \"forgetting\" specific nodes, redirecting other nodes at will, performing MITM attacks (if the protocol isn't secure), etc etc.Also, beyond just no positive incentives, there are nontrivial negatives... they're hubs for an entire network, which can be a lot of traffic and bandwidth if peers are sharing anything other than text. That's a potentially significant cost for literally just being a dumb router. The idea of charging for this doesn't make sense... you don't choose a router, it's automatic based on location, so there's no incentive for quality. That ends up being a race to the bottom, which there's no room for arbitrage; prices are driven down to near-zero profit.Abuse-wise, the model is fundamentally flawed. Economically, the idea kinda works so long as hub traffic is low enough to be swallowed in background noise for whoever manages the hub. Beyond that the model breaks pretty quickly.reply",
      "Email is currently more decentralized than Nostr is in practice.reply",
      "You are correct that it existed well before, the difference is that it was always complicated to use. Heck, we have been able to send PGP emails since almost 30 years ago.The innovative concept is that npub/nsec along with sending notes is trivially simple. The content does not need to encrypted, there is a huge value on publishing clear text messages that are crypto-verifiable. You also didn't had this feature on groove and others. I'd argue that NOSTR has indeed pioneered them into mainstream.reply"
    ],
    "link": "https://newsletter.squishy.computer/p/natures-many-attempts-to-evolve-a",
    "first_paragraph": ""
  },
  {
    "title": "\u201cAre you the one?\u201d is free money (owenlacey.dev)",
    "points": 156,
    "submitter": "samwho",
    "submit_time": "2025-12-12T06:47:45 1765522065",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=46241500",
    "comments": [
      "They have an example that calculates the expected information gained by truth booths and all of the top ones are giving more than one bit. How can this be? It is a yes/no question a max of 1 bit should be possiblereply",
      "The author defines one \u201cbit\u201d as ruling out half the remaining options.So a yes might rule out 75% of remaining options (for example) which provides 2 bits of information.reply",
      "We have to make a distinction between \"expected information gain\" vs \"maximum information gain\". An answer of \"yes\" generally gains >1 bit, but an answer of \"no\" generally gains <1 bit, and the average outcome ends up <1. It is impossible for a single yes/no question to have an expected gain of >1; the maximum possible is precisely 1.reply",
      "The total probabilities add up to 1. But I\u2019m not following how that relates to the average bits.Despite summing to 1, the exact values of P(true) and P(false) are dependent on the options which have previously been discounted. Then those variables get multiplied by the amount of information gained by either answer.reply",
      "It is definitional, which I mean in the strictest mathematical sense: the information content of a result is directly derived from how \u201cunexpected\u201d it is.A result which conveys 2 bits of information should occur with 25% expected probability. Because that\u2019s what we mean by \u201ctwo bits of information.\u201dreply",
      "The article states \"Suppose we have calculated the expected information gained by potential truth booths like below: Expected information: 1.60 bits ...\" This is impossible because of the general fact in information theory that (p(true) * bits_if_true) + (p(false) * bits_if_false) <= 1. If they had said \"Suppose we have calculated the maximum information gained...\", then 1.6 bits would be valid. They said \"expected information\" though, so 1.6 bits is invalid.reply",
      "Because when it's true, you also learn about any prior match ups involving those two people.reply",
      "That's not how information works.  Learning more from one outcome than the other decreases the probability of that outcome occurring, so the expected information  (which is the sum of the outcome probability times the outcome information for each of the two possible outcomes) is always less than or equal to one.If all you can get is a \"true\" or \"false\" you expect, at most, one bit of information.reply",
      "Right - but coming back to the original question, if I'm not mistaken, the explanation is that the blogpost is measuring information gained from an actual outcome, as opposed to _expected_ information gain. An example will help:Say you're trying to guess the number on a 6-sided die that I've rolled. If I wanted to outright tell you the answer, that would be 2.58 bits of information I need to convey. But you're trying to guess it without me telling, so suppose you can ask a yes or no question about the outcome. The maximum of the _expected_ information add is 1 bit. If you ask \"was it 4 or greater?\", then that is an optimal question, because the expected information gain is min-maxed. That is, the minimum information you can gain is also the maximum: 1 bit. However, suppose you ask \"was it a 5?\". This is a bad question, because if the answer is no, there are still 5 numbers it could be. Plus, the likelihood of it being 'no' is high: 5/6.  However, despite these downsides, it is true that 1/6 times, the answer WILL be yes, and you will gain all 2.58 bits of information in one go. The downside case more than counteracts this and preserves the rules of information theory: the _expected_ information gain is still < 1 bit.EDIT: D'oh, nevermind. Re-reading the post, it's definitely talking about >1 bit expectations of potential matchings. So I don't know!reply",
      "It's not a yes/no per contestent, it's per edge between contestants.  There are n(n-1)/2 of these.A true answer for a potential match is actually a state update for all of the (n-1) edges connecting either contestant, that's 2(n-2) edges that can be updated to be false.  Some of these may already be known from previous rounds' matchups but that's still more than a single binary.reply"
    ],
    "link": "https://blog.owenlacey.dev/posts/are-you-the-one-is-free-money/",
    "first_paragraph": "OK, so this is niche.One of my wife's guilty pleasures is reality TV, usually ones centred around dating - the more American, the better. By extension, I absorb some of this noise and I'm happy to admit I can sometimes get invested.At one point, she was (let's face it, we were) watching a show called \"Are you the one?\" on MTV. I'm going to show you how this game is pretty much free money.Consider a group of equal numbers of men & women:Each contestant has exactly one perfect match of the opposite sex that is pre-determined for them, as represented by the colours. Click the \"Match\" button to pair up the contestants correctly. Crucially, they don't initially know who their perfect match is. If the group can correctly guess all the perfect matches, they win a cash prize of $1M.You probably have the follow up question of how the perfect matches are calculated, which is a great question. In short: dunno, it's black-boxed, but let's just say \"science\"? How this is calculated isn't really the"
  },
  {
    "title": "Understanding Carriage (seths.blog)",
    "points": 15,
    "submitter": "herbertl",
    "submit_time": "2025-12-11T00:11:32 1765411892",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=46225950",
    "comments": [
      "I'm excited to see some spin on this get incorporated into the next season of The Studio.reply",
      "It's fun to note that Netflix started producing its own content as a hedge if Hollywood studios start withdrawing their content.Haha.reply"
    ],
    "link": "https://seths.blog/2025/12/understanding-carriage/",
    "first_paragraph": "Or try my new AI-powered search bot\nSubscribe\nHave you thought about subscribing? It's free.\nseths.blog/subscribe\nThe announcement of the planned Netflix acquisition of Warner Bros, one of the last remaining major studios, is shedding light on a key issue we often overlook when thinking about culture, creativity and creation.Carriage is the term for the method that books, movies, TV shows and other media get from the producers to the public. It\u2019s about who controls user access to the medium.Until recently, bookstores were a largely open system. Any publisher had a chance to get any book into any bookstore, sometimes with prime placement and promotion.Radio stations offered carriage to record labels. When labels tried to bribe the program directors (\u2018payola\u2019) the power of this carriage was clear and the practice was banned. Even so, major record labels had power because they, and they alone, had a chance to get a record heard and played.Throughout the 1930s, film production in the US wa"
  },
  {
    "title": "Essential Semiconductor Physics [pdf] (nanohub.org)",
    "points": 106,
    "submitter": "akshatjiwan",
    "submit_time": "2025-12-13T18:19:51 1765649991",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=46256643",
    "comments": [
      "It turns out that this is a part of an entire series of textbooks focused on semiconductors.  https://www.worldscientific.com/series/neelnsAs the editors note, this series is meant to be an intellectual successor to the Semiconductor Electronics Education Committee (SEEC) books that were published in the 1960s.reply",
      "The best class I took in EE school was the 400 level course on this material.Mathematically had us working from Schr\u00f6dinger to LEDs and Transistors over the course of 4 months. Changed my whole perspective on shit.reply",
      "Prof. Lundstrom is a giant in semiconductors and it\u2019s exciting to see him publish this book.reply",
      "A few years ago I took his course on thermoelectricity and really liked his way of teaching. The videos were short and to the point and yet gave me all that I needed to know about the topic.Here's the link in case anyone s interestedhttps://youtube.com/playlist?list=PLtkeUZItwHK5y6qy1GFxa4Z4R...reply",
      "As someone unfamiliar with this field, I'm amazed at how readable this is. Must be a great professor.reply"
    ],
    "link": "https://nanohub.org/resources/43623/download/Essential_Semiconductor_Physics.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Umbrel \u2013 Personal Cloud (umbrel.com)",
    "points": 132,
    "submitter": "oldfuture",
    "submit_time": "2025-12-15T19:27:08 1765826828",
    "num_comments": 75,
    "comments_url": "https://news.ycombinator.com/item?id=46279187",
    "comments": [
      "I am uninterested in purchasing proprietary hardware running a proprietary operating system that'll work (maybe) for some amount of time. Sure, it's technically self hosted. But you can't extend it (without their proprietary app store). It doesn't seem like you can write your own apps without registering, or side load them. Details are extremely thin on the site, so let me know if I'm wrong.Hell, all the compelling software isn't even theirs! They're just running other OSS apps, and god knows whether you'll be able to manage or upgrade it.Arguably, this is the worst of all worlds: you're paying the overhead of closed hardware, running closed software that you don't control, and sort of just crossing your fingers that they don't pull the rug out from underneath you. You'd be infinitely better off buying a comparable NUC and spending an afternoon loading up Docker on it. Shit like this is genuinely insulting to the demographic of folks who should be the target audience.reply",
      "In what way is the proprietary? It looks to be just a PC box running OSS apps?reply",
      "Have things changed drastically? I have an Umbrel instance running on an x86 server at home. When I installed it, it was fully open source, open API, and free.reply",
      "A decade of \u201cpersonal cloud box\u201d attempts has shown that the hard part isn\u2019t the hardware, it\u2019s the long-term social contract. Synology/WD/My Cloud/etc all eventually hit the same wall: once the company pivots or dies, you\u2019re left with a sealed brick that you don\u2019t fully control, holding the most irreplaceable thing you own: your data. If you\u2019re going to charge an Apple-like premium on commodity mini-PC hardware, you really have to over-communicate what happens if Umbrel-the-company disappears or changes direction: how do I keep using this thing in 5\u201310 years without your cloud, your app store, your updates?The interesting opportunity here isn\u2019t selling a fancy N100 box, it\u2019s turning \u201cself-hosted everything\u201d into something your non-technical friend could actually live with. That\u2019s mostly about boring stuff: automatic off-site backup that isn\u2019t tied to one vendor, painless replacement/restore if the hardware dies, and clear guarantees about what runs locally vs phoning home. If Umbrel leans into being forkable and portable across generic hardware, it has a shot at being trusted infrastructure instead of just another pretty NAS that people regret once the marketing site goes dark.reply",
      "Don't forget the user experience needs to be seamless. We bubble ourselves to this as tech fluent folks on HN, but the seamless quality needs to be on par or better with Google Drive, iCloud drive, Google / iCloud Photos etc.Ability to share, good default security, and seamless integration with the things people care about.If this device can't automatically backup a phone wirelessly and without my interaction, it will be a poor proposition to most people.We would all have been better off fiercely advocating for open protocols for all this stuff first (forced interop), but technologists have not wanted to wade into that in a sustained, en masse wayreply",
      "Sorry, isn't this running an open-source OS? The header has a link to a github with a non-commercial license[0].If so, couldn't you just use the OS on non-premium-priced mini-PC hardware and never have to worry about them locking you out of your box? I guess maybe it's concerning if you're being forced to update by the OS? I've never actually run a system like that, but was considering umbrel OS (didn't actually know about the hardware until this post), so if I'm being naive about something, it's in earnest.[0] https://github.com/getumbrel/umbrelreply",
      "A non-commercial license prevents it from being open-source, and I think already constitutes extremely clear communication about what will happen to users when Umbrel goes bankrupt: they will be stranded, because the license doesn't allow another company to step up and take over maintenance the way an open-source license would.reply",
      "these companies - if they are so afraid of an OSI approved license - should put certain conditions into their that trigger when they go out of business and the IP gets releasedreply",
      "I run umbrel in a VM . For non fiat finops stuff.I also run Cloudron on a VPS.I wish both of those solutions had more mindshare. They save me so much time and effort. Especially Cloudron!reply",
      "I\u2019m not worried about \u201ccan I, personally, keep this thing running?\u201d so much as \u201cwhat is the long-term story for the kind of person who buys a turnkey appliance\u201d.Yes, Umbrel OS is on GitHub and you can already run it on generic NUCs / Pi etc. That\u2019s great. But the value prop of the hardware is the whole bundle: curated apps, painless updates, maybe remote access, maybe backups. If Umbrel-the-company pivots or withers, the repo still being there under a non-commercial license doesn\u2019t guarantee ongoing maintenance, an app store, or support. And the NC clause is exactly what makes it hard for someone else to step in and sell a fully supported forked \u201cUmbrel but maintained\u201d box to non-technical users. So for people like you and me, sure, we can just install it elsewhere; for the target audience of an expensive plug-and-play box, the long-term social contract is still the fragile part.reply"
    ],
    "link": "https://umbrel.com",
    "first_paragraph": "Umbrel HomeumbrelOSApp StoreCareersUmbrel HomeumbrelOSApp StoreCareersYour cloud. In your Your cloud. In your Your cloud. In your home.home.home.Store your files, download and stream media, run a Bitcoin node, and more \u2014 all in your home.Store your files, download and stream media, run a Bitcoin node, and more \u2014 all in your home.Store your files, download and stream media, run a Bitcoin node, and more \u2014 all in your home.The all-new Umbrel HomeYour data, finally home.Now with up to 4TB of SSD storage for everything that matters.Buy nowWatch the announcementThe all-new Umbrel HomeYour data, finally home.Now with up to 4TB of SSD storage for everything that matters.Buy nowWatch the announcementThe all-new Umbrel HomeYour data, finally home.Now with up to 4TB of SSD storage for everything that matters.Buy nowWatch the announcementUmbrel HomeNEWPlug-and-play home cloud.Buy nowLearn moreumbrelOSThe ultimate OS for running your own home cloud.Learn moreUmbrel HomeNEWPlug-and-play home cloud.B"
  },
  {
    "title": "A kernel bug froze my machine: Debugging an async-profiler deadlock (questdb.com)",
    "points": 50,
    "submitter": "bluestreak",
    "submit_time": "2025-12-15T20:52:35 1765831955",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=46280465",
    "comments": [
      "Great article! Just yesterday I watched a Devoxx talk by Andrei Pangin [1], the creator of async-profiler where I learned about the new heatmap support. To many folks it might not sound that exciting, until you realise that these heatmaps make it much easier to see patterns over time. If you\u2019re interested there\u2019s a solid blog post [2] from Netflix that walks through the format and why it can be incredibly useful.[1]: https://www.youtube.com/watch?v=u7-S-Hn-7Do[2]: https://netflixtechblog.com/netflix-flamescope-a57ca19d47bbreply",
      "Thanks for the kind words!Heatmaps are amazing for pattern spotting. I also use them when hunting irregular hiccups or outliers. More people should know about this feature.reply",
      "Author here. I've always been kernel-curious despite never having worked on one myself. Consider this either a collection of impractical party tricks or a hands-on way to get a feel for kernel internals.reply",
      "Question, isn't this a bug?\n   static enum hrtimer_restart perf_swevent_hrtimer(struct hrtimer *hrtimer)\n   {\n   -   if (event->state != PERF_EVENT_STATE_ACTIVE)\n   +   if (event->state != PERF_EVENT_STATE_ACTIVE ||\n   +       event->hw.state & PERF_HES_STOPPED)\n           return HRTIMER_NORESTART;The bug being that the precedence of || is higher than the precedence of != ?\nConsider writing it\n   if ((event->state != PERF_EVENT_STATE_ACTIVE) ||\n       (event->hw_state & PERF_HES_STOPPED))This coming from a person who has too many scars from not parenthesizing my expressions in conditionals to ensure they work the way I meant them to work.reply",
      "Wow, someone is actually reading the article in detail, that's a good feeling!\nIn C, the != operator has higher precedence than the || operator. That said, extra parentheses never hurt readability.reply",
      "Which language(s?) have || before !=/==?reply",
      "Likely they're confusing it with bitwise OR, since in C, a | b == c parses as a | (b == c), causing widespread pain.reply",
      "I'm glad to hear I'm not alone. Due to the nature of what I do, I'm often accumulating ~800-900GB of Docker images and volumes on my machine, sometimes running 20-30 containers at once starting/stopping them concurrently. Somehow, very rarely, but still quite often (once every couple of weeks) - it leads to a complete deadlock somewhere inside of the kernel due to some crazy race condition that I'm absolutely in no way able to reliably reproduce.reply",
      "It's much tougher when it's so hard to reproduce. Perhaps the NMI watchdog could help? https://docs.kernel.org/admin-guide/lockup-watchdogs.htmlreply",
      "Great debugging effort.Now, with the complexity (MLoCs!) of the Linux kernel, this is definitely not the only bug to be found in there.This is why Linux is just an interim kernel for these use cases in which we still cannot use seL4[0].0. https://sel4.systems/reply"
    ],
    "link": "https://questdb.com/blog/async-profiler-kernel-bug/",
    "first_paragraph": "Interested in QuestDB use cases?Interested in QuestDB use cases?I've been a Linux user since the late 90s, starting with Slackware on an underpowered AMD K6.\nOver the years I've hit plenty of bugs, but the last decade has been remarkably stable - until a kernel bug started\nfreezing my machine whenever I used async-profiler.I'm not a kernel developer, but I found myself poking around kernel source code to understand the problem better and\nfigure out what was going on under the hood.I was about to start an investigation of latency spikes in QuestDB reported by a user. To do that, I wanted to use the async-profiler to capture CPU heatmaps.However, when I tried to attach the profiler, my machine froze completely. It did not respond to any\nkeys, it was impossible to switch to a terminal, it did not respond to SSH. The only way to recover was to hard\nreboot it. I tried to start QuestDB with the profiler already configured to start at launch - the same result, a frozen machine almost immediat"
  },
  {
    "title": "The Bob Dylan Concert for Just One Person (flaggingdown.com)",
    "points": 14,
    "submitter": "NaOH",
    "submit_time": "2025-12-16T00:18:58 1765844338",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.flaggingdown.com/p/the-bob-dylan-concert-for-just-one",
    "first_paragraph": ""
  },
  {
    "title": "Ford kills the All-Electric F-150 (wired.com)",
    "points": 146,
    "submitter": "sacred-rat",
    "submit_time": "2025-12-15T21:46:53 1765835213",
    "num_comments": 202,
    "comments_url": "https://news.ycombinator.com/item?id=46281182",
    "comments": [
      "This is a shame. Coworker got a Lightning and he loves it. He doesn't tow with it but he does field work for fiber optic stuff, usually back home every day. Runs his computers, tools, ventilation for going down manholes, he even powered a sump pump from it, without needing to haul a generator.  \nThe hybrid truck can now do the same, but it's a really nice truckreply",
      "I expected the \"T word\" to come out in the article, however this fails to address any of the practical reasons it isn't a good replacement for the value-engineered F-150:* The price isn't right for small businesses. These trucks are quite expensive* They're difficult to repair. A regular F-150 is designed to be repaired; these things are designed like iPhones to be disposable.* Parts availability is scarce, contrasted with a regular F-150 (even junkyards are full of spare parts, that aren't software constrained)* They're loaded with useless/barely-functional interior electronics that are poor copies of Tesla* They're bloated with parts that don't need to exist (excessive exterior accent lighting, badges, over-complicated blinkers)Oddly enough, single-charge range issues are pretty much non-existent (for non-towing applications).reply",
      "> The price isn't right for small businesses. These trucks are quite expensiveThey definitely aimed for the luxury market, like Rivian. Who knows how successful they would've been if they aimed for mid-range like Scout. That's the market they claimed to be entering when they started taking reservations. They also could've offered a fleet ready version without the luxury features, but must've decided not to.>  They're difficult to repairHow so? They are far simpler to maintain than a normal F-150. They're new so they do have parts issues for the electronic components, I'm sure, but I think that's a fair trade-off. In any case, I don't think offering a hybrid version makes the vehicles easier to maintain or repair. If anything it's the opposite.> Parts availability is scarce, contrasted with a regular F-150 (even junkyards are full of spare parts, that aren't software constrained)I thought one of the advantages of the F-150 was that most parts were shared with the standard F-150? The battery and motors, maybe not.reply",
      "They also could've offered a fleet ready version without the luxury features, but must've decided not to.They did offer a fleet version.. the \"Pro\".reply",
      "I mean, what do we expect from this brainless company that promised a $20k Maverick and let the stealerships mark it up to over $40k?reply",
      "Ford announced the Maverick, it got so much excitement that it sold out and dealerships sold for over MSRP. So in their infinite wisdom they... didn't make more mid range trucks. Ill never understand these guys.reply",
      "Significant portions of the body and interior were not shared with general F-150 models... At least those parts most likely to be damaged in minor accidents... imagine having your work truck in the shop for 2-3 months for want of a corner light fixture.reply",
      "Yeah, that's definitely a no-go. I think you'd see that with any new model, however. I once had a Ducati in the shop for 4-5 months just waiting on a wheel because it was a new model.reply",
      "I think the bigger issue is parts availability over the repairability issue... from what I understand, these have been quite reliable but parts for Ford's EVs have been backordered as much as months, where having a \"work truck\" down for months is an intolerable position.The cost is also kind of crazy between inflated factory and dealer pricing as much as $20k over sticker price.  Yeah, there was some early demand, but over-charging really cooled that and the demand overall.I'm with you on some of the interior features, they're cool, but the overall inflated price is just too much.  On the flip side, the Chevy \"Work Truck\" is kinda too far the other direction imo.Similar on the more complex exterior, though I actually like it, it's not practical for its' prescibed purpose.  If Ford could create a stripped down EV equivalent to Chevy's \"Work Truck\" at even 50% higher cost, I think it would do very well.  They're very good for in-city use in terms of range on a charge, it's definitely good enough for most general tradecraft use, but the bloat and pricing really drag it down.  Much like most cars in general these days.Pretty much the only interesting new car I've seen this year was the Hundai Palasade, which IMO was just a good value for what it is.  Kind of disappointing to see Nissan drop the Titan line.  While I'd prefer to buy American brands, the fact that is that I don't think they deliver on overall value or reliability as well as competing brands.  And it gets muddied further with foreign brands with US assembly and American brands now owned or otherwise operated or significantly built outside the US.reply",
      "I mean the biggest issue is that \u201ctrucks\u201d like F-150 are actually used because of US tax system that exempts such massive vehicles from emmision taxes because they are work trucks. They are pretty ineffective work vehicles but some people just love them as a symbol.That symbolism goes completely against electric/green vehicles. In other words - people who buy F-150 would never buy electric vehicle and people who are looking for electric truck for work wouldn't buy F-150.reply"
    ],
    "link": "https://www.wired.com/story/ford-kills-electric-f-150-lightning-for-hybrid/",
    "first_paragraph": "Ford is once again shifting its electric vehicle manufacturing plans, a response to a year that\u2019s been tough for the powertrain technology that\u2019s still making waves overseas but has seen domestic government support cut and customer enthusiasm weaken.Instead of planning to make enough electric vehicles to account for 40 percent of global sales by 2030\u2014as it pledged just four years ago\u2014Ford says it will focus on a broader range of hybrids, extended-range electrics, and battery-electric models, which executives now say will account for 50 percent of sales by the end of the decade. The automaker will make hybrid versions of almost every vehicle in its lineup, the company says.The company will no longer make a large all-electric truck, Ford executives told reporters Monday, and will repurpose an electric vehicle plant in Tennessee to build gas-powered cars. The next generation of Ford\u2019s all-electric F-150 Lighting will instead be an extended-range electric vehicle, or EREV, a plug-in hybrid"
  },
  {
    "title": "JetBlue flight averts mid-air collision with US Air Force jet (reuters.com)",
    "points": 103,
    "submitter": "divbzero",
    "submit_time": "2025-12-15T22:48:56 1765838936",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=46281944",
    "comments": [
      "The US could issue a notice of an Alert Area where military operations are in progress AND could coordinate with Dutch airspace authorities.US AWACS has the capability to identify civilian aircraft and route military traffic well clear of civil traffic.reply",
      "Why was the Air Force plane\u2019s transponder turned off? This is negligence that almost killed a plane full of people and endangered a national security operation. Outrageous.reply",
      "Common sense would dictate that a military aircraft conducting military operations off the coast of a hostile nation tend to not want to broadcast their position to the world. So not outrageous, just unfortunate. It's extremely common.reply",
      "On the other side it is perfectly visible on radar (and can be heard (and with jet having its own characteristic signature it can be tracked even by WWII microphone array like they did back then) and visible in binoculars from large distance in nice Caribbean weather),  so it is hiding only from civilians. Security by obscurity kind of.reply",
      "Because it\u2019s flying near Venezuela, who we\u2019re currently fucking with militarily.reply",
      "we wouldn\u2019t be doing that, we voted for President that will end all the wars, not start new onesreply",
      "Thank you for buying my bridge, no refunds asked and zero money back downreply",
      "If you thought you were, you were tricked.reply",
      "I think your sarcasm detector needs calibrating.",
      "Nicolas, Uday, and Qusay Maduro have 48 hours to leave Venezuela. Until then, we have not launched a special military operation.reply"
    ],
    "link": "https://www.reuters.com/world/americas/jetblue-flight-averts-mid-air-collision-with-us-air-force-jet-2025-12-15/",
    "first_paragraph": ""
  },
  {
    "title": "Chafa: Terminal Graphics for the 21st Century (hpjansson.org)",
    "points": 99,
    "submitter": "birdculture",
    "submit_time": "2025-12-15T18:16:34 1765822594",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=46278208",
    "comments": [
      "I learned about Chafa when I found a video editor that runs in the command line with keyboard control - vic - it just lets you insert split markers and when you exit the video is sliced up into the portions. I really like the low-fi nature of scrobbling through the video, it has low brain overhead.https://github.com/wong-justin/vicreply",
      "I use chafa extensively, and it really is the best tool for terminal graphics in my opinion.I use it as a fallback option for terminals without proper terminal graphics support in my TUI Jupyter client, euporie.There are Python bindings available: https://github.com/GuardKenzie/chafa.pyreply",
      "And JS bindings: https://github.com/hectorm/chafa-wasmAnd I'm half-working on Rust bindings...reply",
      "Author of the JS bindings here. I also have a browser demo: https://ansi-o-matic.molinero.devreply",
      "> and it really is the best tool for terminal graphics in my opinionNot sixel or kitty graphics?reply",
      "One of the really cool things about chafa is that it has both sixel and kitty graphic renderers! (and iterm2 images as well) So you can output kitty if the terminal supports it, but fall back to ascii if it doesn\u2019t.reply",
      "What interests me about it is the unicode mosaic output format that looks higher quality than the usual upper half block or braille character approaches without needing to support a special protocol.reply",
      "Setting aside the usual compatibility issues with those things.. neither are available from your buildbot. Also while Jupyter does supports images other notebooking ecosystems may not, and anyway you need a file whereas chafa can work with streams.reply",
      "i'm curious do you work entirely with a terminal and no desktop?Chafa looks cool, i'd feel cool using it when i use a terminal but if really wanted to see an image id just open it in a image viewer.reply",
      "Previously in 2022 (97 points, 31 comments) https://news.ycombinator.com/item?id=32797681reply"
    ],
    "link": "https://hpjansson.org/chafa/",
    "first_paragraph": "The premier UX of the 21st century just got a little better: With chafa,\n  you can now view very, very reasonable approximations\n  of pictures and animations in the comfort of your\n  favorite terminal emulator. The power of ANSI X3.64 compels you!You can get fair results by using only U+2580 (upper half\nblock). Other terminal graphics packages do this, and so can Chafa\nwith chafa\u00a0--symbols\u00a0vhalf. However, Chafa\nuses more symbols by default, greatly improving quality.\nThere are more examples in the gallery!\n\nSome of the features are discussed in a series of blog posts:\nChafa will print a help text if run without arguments, or with chafa --help.\nIt also comes with a man page displayable with man chafa.The gallery contains examples of how command-line options can\nbe used to tweak the output.There is C API documentation for application developers.Erica Ferrua Edwardsd\u00f3ttir is developing Python bindings that allow Chafa to be used in Python programs. These are documented on their own site.H"
  },
  {
    "title": "In Defense of Matlab Code (runmat.org)",
    "points": 65,
    "submitter": "finbarr1987",
    "submit_time": "2025-12-12T20:13:26 1765570406",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=46248294",
    "comments": [
      "There's also Julia.Earlier in my career, I found that my employers would often not buy Matlab licenses, or would make everyone share even when it was a resource needed daily by everyone. Not having access to the closed-source, proprietary tool hurt my ability to be effective. So I started doing my \"whiteboard coding\" in Julia and still do.reply",
      "Precisely; today Julia already solves many of those problems.It also removes many of Matlab's footguns like `[1,2,3] + [4;5;6]`, or also `diag(rand(m,n))` doing two different things depending on whether m or n are 1.reply",
      "I don't think Julia really solves any problems that aren't already solved by Python. Python is sometimes slower (hot loops), but for that you have Numba. And if something is truly performance critical, it should be written or rewritten in C++ anyway.But Julia also introduces new problems, such as JIT warmup (so it's not really suitable for scripting) and is still not considered trustworthy:https://yuri.is/not-julia/reply",
      "> I don't think Julia really solves any problems that aren't already solved by Python.But isn't the whole point of this article that Matlab is more readable than Python (i.e. solves the readability problem)? The Matlab and Julia code for the provided example are equivalent[1]: which means Julia has more readable math than Python.[1]: Technically, the article's code will not work in Julia because Julia gives semantic meaning to commas in brackets, while Matlab does not. It is perfectly valid to use spaces as separators in Matlab, meaning that the following Julia code is also valid Matlab which is equivalent to the Matlab code block provided in the article.    X = [ 1 2 3 ];\n    Y = [ 1 2 3;\n          4 5 6;\n          7 8 9 ];\n    Z = Y * X';\n    W = [ Z Z ];reply",
      "This snippet is also cleaner than one in article and more in spirit. Also the image next to whiteboard has a no-commas example.reply",
      "> Python is sometimes slower (hot loops), but for that you have NumbaThis is a huge understatement. At the hedge fund I work at, I learned Julia by porting a heavily optimized Python pipeline. Hundreds of hours had gone into the Python version \u2013 it was essentially entirely glue code over C.In about two weeks of learning Julia, I ported the pipeline and got it 14x faster. This was worth multiple senior FTE salaries.  With the same amount of effort, my coworkers \u2013 who are much better engineers than I am \u2013 had not managed to get any significant part of the pipeline onto Numba.> And if something is truly performance critical, it should be written or rewritten in C++ anyway.Part of our interview process is a take-home where we ask candidates to build the fastest version of a pipeline they possibly can. People usually use C++ or Julia. All of the fastest answers are in Julia.reply",
      "Sometimes slower? No, always slower. And no one wants to deal with the mess that is creating an interface with C or C++. And I wouldn\u2019t want to code in that either, way too much time, effort, headache.reply",
      "As your comment already hints at, using Python often ends up a hodgepodge of libraries and tools glued together, that work for their limited scope but show their shaky foundations any time your work is outside of those parts. Having worked with researchers and engineers for years on their codebases, there is already too much \"throw shit at the wall and see what sticks\" temptation in this type of code (because they'd much rather be working on their research than on the code), and the Python way of doing things actively encourages that. Julia's type hierarchies, integrated easy package management, and many elements of its design make writing better code easier and even the smoother path.> I don't think Julia really solves any problems that aren't already solved by Python.I don't really need proper furniture, the cardboard boxes and books setup I had previously \"solved\" the same problems, but I feel less worried about random parts of it suddenly buckling, and it is much more ergonomic in practice too.reply",
      ">I don't think Julia really solves any problems that aren't already solved by Python.You read the article that compares MATLAB to Python? It's saying MATLAB, although some issues exist, still relevant because it's math-like. GP points out Julia is also math-like without those issues.reply",
      "In Julia, you explicitly need to still reason about and select GPU drivers + manage residency of tensors; in RunMat we abstract that away, and just do it for you. You just write math, and we do an equivalent of a JIT to just figure out when to run it on GPU for you.Our goal is to make a runtime that lets people stay at the math layer as much as possible, and run the math as fast as possible.reply"
    ],
    "link": "https://runmat.org/blog/in-defense-of-matlab-whiteboard-style-code",
    "first_paragraph": "The issue was never the syntax\u2014it was the runtime. Why readable math still matters in a world aided by LLM-assisted code generationIf you look at the most preferred language list on any Stack Overflow developer survey, you will usually find MATLAB hovering near the bottom. It sits there alongside VBA and COBOL, often dismissed by modern software engineers as a dinosaur. You have probably seen the memes: complaints about license manager errors, the massive install size, or the feeling that it is a language strictly for \"old-school academics.\u201dThe world has moved toward open source, containerization, and agile cloud deployments. In that context, a closed ecosystem feels restrictive.But if you walk into the R&D departments of top aerospace, automotive, or medical device companies, MATLAB is still everywhere. It isn't there because these engineers don't know better. It is there because, for a specific type of work\u2014linear algebra, signal processing, and control theory\u2014MATLAB did one thing be"
  },
  {
    "title": "Avoid UUID Version 4 Primary Keys in Postgres (andyatkinson.com)",
    "points": 332,
    "submitter": "pil0u",
    "submit_time": "2025-12-15T10:08:02 1765793282",
    "num_comments": 367,
    "comments_url": "https://news.ycombinator.com/item?id=46272487",
    "comments": [
      "A prime example of premature optimization.Permanent identifiers should not carry data. This is like the cardinal sin of data management. You always run into situations where the thing you thought, \"surely this never changes, so it's safe to squeeze into the ID to save a lookup\". Then people suddenly find out they have a new gender identity, and they need a last final digit in their ID numbers too.Even if nothing changes, you can run into trouble. Norwegian PNs have your birth date (in DDMMYY format) as the first six digits. Surely that doesn't change, right? Well, wrong, since although the date doesn't change, your knowledge of it might. Immigrants who didn't know their exact date of birth got assigned 1. Jan by default... And then people with actual birthdays on 1 Jan got told, \"sorry, you can't have that as birth date, we've run out of numbers in that series!\"Librarians in the analog age can be forgiven for cramming data into their identifiers, to save a lookup. When the lookup is in a physical card catalog, that's somewhat understandable (although you bet they could run into trouble over it too). But when you have a powerful database at your fingertips, use it! Don't make decisions you will regret just to shave off a couple of milliseconds!reply",
      "> Norwegian PNs have your birth date (in DDMMYY format) as the first six digits. Surely that doesn't change, right? Well, wrong, since although the date doesn't change, your knowledge of it might. Immigrants who didn't know their exact date of birth got assigned 1. Jan by default... And then people with actual birthdays on 1 Jan got told, \"sorry, you can't have that as birth date, we've run out of numbers in that series!\"To me, what your example really shows is the problem with incorrect default values, not a problem with encoding data into a key per se. If they'd chosen a non-date for unknown values, maybe 00 or 99 for day or month components, then the issue you described would disappear.But in case, the intention for encoding a timestamp into a UUID isn't for any implied meaning. It's both to guarantee uniqueness with a side effect that IDs are more or less monotonically increasing. Whether this is actually desirable depends on your application, but generally if the application is as a indexed key for insertion into a database, it's usually more useful for performance than a fully random ID as it avoids rewriting lots of leaf-nodes of B-trees. If you insert a load of these such keys, it forms a cluster on one side of the tree that can the rebalance with only the top levels needing to be rewritten.reply",
      ">To me, what your example really shows is the problem with incorrect default values, not a problem with encoding data into a key per se. If they'd chosen a non-date for unknown values, maybe 00 or 99 for day or month components, then the issue you described would disappear.You still have that problem from organic birthdays and also the problem of needing to change ids to correct birth dates.reply",
      "To add to that, birthdays can clump, just like any seemingly \"random\" data.reply",
      "Not significantly.  For actual births, a couple holidays have very low rates but clumping into much higher rates happens on no dates.reply",
      "A million dots scattered randomly over a graph can all land on the exact same coordinate if it\u2019s truly random.What most people intuit as random is some sort of noise function that is generally dispersed and doesn\u2019t trigger the pattern matching part of their brainreply",
      "> A million dots scattered randomly over a graph can all land on the exact same coordinate if it\u2019s truly random.It won't happen though.  0.00000000% chance it happens even once in a trillion attempts.> What most people intuit as random is some sort of noise function that is generally dispersed and doesn\u2019t trigger the pattern matching part of their brainYes, people intuit the texture of random wrong in a situation where most buckets are empty.  But when you have orders of magnitude more events than buckets, that effect doesn't apply.  You get pretty even results that people expect.reply",
      "> It won't happen though. 0.00000000% chance it happens even once in a trillion attempts.It has the same odds as any other specific configuration of randomly assigned dots. The overly active human pattern matching behavior is the only reason it would be treated as special.reply",
      ">It has the same odds as any other specific configuration of randomly assigned dotsWhich doesn't change anything in practice, since it having \"the same odds as any other specific configuration\" ignores the fact that more scattered configurations are still far more numerous than it (or even from ones with more visual order in general) taken all together.>The overly active human pattern matching behavior is the only reason it would be treated as special.Nope, it's also the fact that it is ONE configuration, whereas all the rest are much much larger number. That's enough to make this specific configuration ultra rare in comparison (since we don't compare it to each other but to all others put together).reply",
      "Entropy says it's special.  If you have a million dots and 10,000 coordinates, you have 10,000 ways for all the dots to land in the same coordinate, and a zillion kavillion stupillion ways to have somewhere near 100 dots in each coordinate.reply"
    ],
    "link": "https://andyatkinson.com/avoid-uuid-version-4-primary-keys",
    "first_paragraph": "\n\n\n\nSoftware Engineer, Author, Consultant\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOver the last decade, when working on databases with UUID Version 41 as the primary key data type, these databases have usually had bad performance and excessive IO.UUID is a native data type in Postgres stored as binary data. Various UUID versions are in the RFC. Version 4 has mostly random bits, obfuscating information like when the value was created or where it was generated.Version 4 UUIDs are easy to generate in Postgres using the gen_random_uuid()2 function since version 13 (released in 2020).I\u2019ve learned there are misconceptions about UUID Version 4, and sometimes these are the reasons users pick this data type.Because of the poor performance, misconceptions, and available alternatives, I\u2019ve come around to a simple position: Avoid UUID Version 4 for primary keys.My more controversial take is to avoid UUIDs in general, but I understand there are some legitimate reasons for them without practical alternatives.As a database"
  },
  {
    "title": "Cosmic-ray bath in a past supernova gives birth to Earth-like planets (science.org)",
    "points": 78,
    "submitter": "toomuchtodo",
    "submit_time": "2025-12-15T17:01:42 1765818102",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=46277090",
    "comments": [
      "Why is it said that it takes a supernova to make elements heavier than iron? You're not going to get iron-iron fusion, but what about proton-iron fusion or similar?  Also, we can make reactors here on earth that convert Thorium into Uranium, and we can also make plutonium in a proper reactor. We mustn't confuse reactions useful for power production with reactions for element production right? Why can't a regular star produce some heavy elements?reply",
      "\u201cElements heavier than iron, up to bismuth, are primarily produced via the s-process (slow neutron capture) in low to medium-mass stars during their later evolutionary stages.The remaining and heaviest elements (beyond iron and bismuth) are formed through explosive events: core-collapse supernovae generate elements between neon and nickel, while the r-process (rapid neutron capture) in supernovae and, predominantly, neutron star mergers creates elements like uranium and thorium, dispersing them into the interstellar medium for planetary formation.\u201dFrom https://www.astronomy.com/science/the-universes-guide-to-cre...reply",
      "I think you're right that heavier elements can be made, it's just energy negative to do so. But without a nova they would never leave the inside of the star to find their way into a new planet.reply",
      "But they do leave.  Stars not large enough to go supernova do still form planetary nebulas when the more gradually lose their outer layers to space.  Only the core is left behind to form a white dwarf.  This will be the Sun's eventual fate.reply",
      "Wouldn't the heavier elements generally sink to the core and the outer layers be composed of the lighter ones?reply",
      "No, gravitational segregation like that is a very slow process and would be overwhelmed by any convection.  In Earth's atmosphere, for example, it doesn't occur until very high altitude (80 km or so) where diffusion is fast enough to overcome mixing.reply",
      "I mean it's not hard to do  spectrometry on said nebula, and I don't think there is near enough heavier matter detected there.reply",
      "s-process elements (including radioactive ones like technetium) are detected in the spectra of the stars where the process occurs, which means they are right out at the \"surface\".reply",
      "The Universe coalesced into hydrogen and helium from a quark-gluon plasma soon after the Big Bang. It's kind of staggering the sequence of events that occurred afterwards to bring us here.As many of us know, the fusion in stars produces elements as heavy as iron. It then takes explosions of those stars to scatter those elements into space, ultimately bringing them into the protoplanetary disc of a new star, such that it can form a planet in the right zone. That star then needs to live long enough and the system needs to be stable enough to produce complex life.But it gets worse because we obviously have elements heavier than iron. So stars of a sufficient size need to form such that when the stars die they do so in an even more violent fashion. The core needs to collapse into neutronium and the resultant supernova can produce heavier elements. They also come from neutron star mergers.So all the uranium we have on Earth came from such an event. Because of the nuclear decay chain we can estimate when this uranium was made and IIRC that's somewhere between 80 and 200 million years before the Earth formed.So this all had to happen sufficiently close to the Sun and that material had to be captured in the Sun's protoplanetary disc. We needed the right combination of elements to form a protective magnetic field and produce enough but not too much heat.We're going to keep discovering mechanisms like this and the importance of particular isotopes, events and things like how amino acids seem to form relatively easily (given the right elements are present), which itself is a consequence of CNO fusion.But also why did the Sun form at all? It has to be in a nebula of largely hydrogen and helium and something had to trigger that like the shock wave from a nearby supernova or neutron star or black hole merger.It's kind of why I think sentient life is incredibly rare.reply",
      "> But also why did the Sun form at all?I don't understand the question. There must have been a cloud of gas big and dense  enough to provide the mass for the solar system.Once that exists gravity does the rest, right?> all the uranium we have on Earth came from such an eventThat must mean the Sun also has its fair share of that Uranium? Or maybe more of it, since the heavy elements were more drawn to the center of the solar system?reply"
    ],
    "link": "https://www.science.org/doi/10.1126/sciadv.adx7892",
    "first_paragraph": ""
  },
  {
    "title": "Secret Documents Show Pepsi and Walmart Colluded to Raise Food Prices (thebignewsletter.com)",
    "points": 158,
    "submitter": "connor11528",
    "submit_time": "2025-12-15T21:24:06 1765833846",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=46280887",
    "comments": [
      "Bigger the company the more power they have to dictate the purchasing price from producers and the cost for consumers. This is not just in the food industry it is also in retail such as Amazon.Companies like Kroger are so big they dictate the purchase prices from farms. The farmers were better off in the past with multiple competitors creating a bidding war. Same with consumers, products had to be priced right to win their business.A company I work for had to give free engineering labor in millions of dollars to get access to one of the largest retailers in the USA. Too big not-to-do-business-with harms everyone except the retailer.reply",
      "> Bigger the company the more power they have to dictate the purchasing price from producers and the cost for consumers.That wasn't always true. The Robinson-Patman Act made it illegal to give preferential treatment to large retailers specifically in order to prevent what we're seeing with walmart and amazon today. The US just stopped enforcing the law (and also anti-trust laws that would have protected local/small businesses) so here we are. At any point the US could decide that enough is enough and fix the situation but we'd probably have to make it actually illegal for corporations to bribe government officials before it stands a chance of happening.reply",
      "It used to be illegal to bribe. Used to... Make a law impossible to enforce, and you suddenly transform the act to a totally legal one, at the expense of people losing trust in the system (specifically the U.S. Supreme Court and Congress). And at some point, the system breaks.reply",
      "But Robert Bork and the Chicago School of Economics and Ronald Reagan and the Republican Party assured me that mergers and trusts were good for me! Look, the companies even have self-serving rationalizations scribbled with crayons on butcher paper saying the same thing!Seriously, though: I cannot believe how high and how far these utterly dogshit arguments flew without pushback and the amount of damage that consolidation has done to the American Experiment. The best time to get a Lina Khan in the FTC was 40 years ago but the second best time was 4 years ago. I just hope the next president picks up the project... though I'm sure the (by then) trillionaires will do everything in their power to stop that from happening.reply",
      "Complaint: https://storage.courtlistener.com/recap/gov.uscourts.nysd.63...reply",
      "Something like this has been going on in the restaurant world since seemingly forever. When I worked at a pizza joint (40-some years ago) we only served Pepsi drinks.I was young and dumb enough then not to know that, for example, 7-Up and Sprite were not independent soft-drinks. I assumed every flavor of soda was its own company. I soon started to notice the drink pattern based on whether they had Coke or Pepsi. Those two owned all the other flavors\u2014and they each had their own variant of the other's.I was told too by management that we only bought Pepsi drinks. Again, native me thought, \"Why not have both Coke and Pepsi and let the customer decide?\" I am not sure whether there was a pricing issue that prevented management from buying both\u2014like the loss of a discount for going Coke-only or whatever.Of course you always saw signage, etc. around the restaurant with Pepsi logos (or Coca-Cola logos at other restaurants) so you knew there were gifts in other forms that one of the two would entice the owner with.What a slow growing up I have gone through since then. It seems like the kind of thing they ought to teach in primary education.reply",
      "The deals for this type of product positioning occur quite high up in the chain.To give an example Yum! brands (KFC, Pizza Hut, Taco Bell, etc) was formed as a subsidiary of PepsiCo. Although PepsiCo has divested from Yum, their pre-existing relationship is why these restaurants only serve Pepsi's soft drinks.Deal-making is also why you see patterns like this emerge in other places such as convenience stores that only sell beverages from the Coca-cola company (i.e. higher volume sales from just one supplier yields a better discount than splitting sales across multiple suppliers).\nIt's relatively rarer to see more than one beverage supplier at a restaurant, club or convenience outlet.reply",
      "Ha, the University where I work signed an exclusive agreement to only sell Pepsi products on campus. I'm sure there was some kickback money given to people here to push it through.reply",
      ">I'm sure there was some kickback money given to people here to push it through.Why? Is it that hard to imagine pepsi doing it in an above-board way, eg. giving a discount to the university directly?",
      "My wife's university has a totally egregious contract which is exclusive to a food provider for cafeteria food and event catering.If you want to, say, have a student group sell cookies or whatever, the provider has to approve and you have to pay to host it.The contract is for 10 years.  No freaking way somebody signed off on that without money under the table.reply"
    ],
    "link": "https://www.thebignewsletter.com/p/secret-documents-show-pepsi-and-walmart",
    "first_paragraph": ""
  },
  {
    "title": "Upcoming Changes to Let's Encrypt Certificates (letsencrypt.org)",
    "points": 233,
    "submitter": "schmuckonwheels",
    "submit_time": "2025-12-15T19:30:22 1765827022",
    "num_comments": 200,
    "comments_url": "https://news.ycombinator.com/item?id=46279241",
    "comments": [
      "The certificate lifetime decrease, to 45 days, was discussed in: https://news.ycombinator.com/item?id=46117126This isn't LE's decision: a 47 day max was voted on by the CA/Browser Forum.https://www.digicert.com/blog/tls-certificate-lifetimes-will...https://cabforum.org/2025/04/11/ballot-sc081v3-introduce-sch...https://groups.google.com/a/groups.cabforum.org/g/servercert... - public votes of all members, which were unanimously Yes or Abstain.IMO this is a policy change that can Break the Internet, as many archived/legacy sites on old-school certificates may not be able to afford the upfront tech or ongoing labor to transition from annual to effectively-monthly renewals, and will simply be shut down.And, per other comments, this will make LE the only viable option to modernize, and thus much more of a central point of failure than before.But Let's Encrypt is not responsible for this move, and did not vote on the ballot.reply",
      "It will make ACME the only viable option. I believe there is a second free ACME CA and other CAs will likely adopt ACME if they want to stay relevant.Ideally, this will take less ongoing labor than annual manual rotations, and I'd argue sites that can't handle this would have been likely to break at the next annual rotation anyways.If they have certificates managed by hosters, the hosters will deal with it. If they don't, then someone was already paying for the renewal and handling the replacement on the server side, making it much more likely that it will be fixed.reply",
      "I'm quite surprised the CA/Browser Forum went for this.Nobody's paying for EV certificates now browsers don't display the EV details. The only reason to pay for a certificate is if you're rotating certificates manually, and the 90 day expiry of Lets Encrypt certificates is a hassle.If the CA/Browser Forum is forcing everyone to run ACME clients (or outsource to a managed provider like AWS or Cloudflare) doesn't that eliminate the last substantial reason to give money to a CA?reply",
      "The CA/BF has a history of terrible decisions, for example 2020's \"Baseline Requirements for the Issuance and Management of Publicly-Trusted Code Signing Certificates\".Microsoft voted for it, and now they are basically the only game in town for cloud signing that is affordable for individuals. The Forum needs voting representatives for software developers and end users or else the members will just keep enriching themselves at our expense.reply",
      "My case, I have to manage a portal for old tvs and those don\u2019t accept the LE root certificate since they changed a couple of years ago. Unfortunately the vendor is unable to update the firmware with new certificates and we are soldreply",
      "Yeah that LE root certificate change broke our PROD for about 25% of traffic when it happened. Everyone acts like we control our client's cert chains. Clients don't look at the failure and think \"our system is broken - we should upgrade\". They look at the connection failure and think \"this vendor is busted - might as well switch to someone who works\". I switched away from LE to the other free ACME provider for our public-facing certs after that.reply",
      "Roots for all CAs are going to be rotating much more frequently now. Looking to be every 5 years.reply",
      "Sounds like planned obsolescence if devices stop working after 5 years or less.reply",
      "I'd be interested in hearing more - do you have a source for this?Seems to me CAs have intermediate certificates and can rotate those, not much upside to rotating the root certificates, and lots of downsides.reply",
      "Chrome root policy, and likely other root policies are moving toward 5-years rotation of the roots, and annual rotation of issuing CAs. \nCross-signing works fine for root rotation in most cases, unless you use IIS, then it becomes a fun problem.reply"
    ],
    "link": "https://community.letsencrypt.org/t/upcoming-changes-to-let-s-encrypt-certificates/243873",
    "first_paragraph": "Let\u2019s Encrypt is introducing several updates to the certificates we issue, including new root certificates, the deprecation of TLS client authentication, and shortening certificate lifetimes. To help roll out changes gradually, we\u2019re making use of ACME profiles to allow users to have control over when some of these changes take place. For most users, no action is required.Let\u2019s Encrypt has generated two new Root Certification Authorities (CAs) and six new Intermediate CAs, which we\u2019re collectively calling the \u201cGeneration Y\u201d hierarchy. These are cross-signed from our existing \u201cGeneration X\u201d roots, X1 and X2, so will continue to work anywhere our current roots are trusted.Most users get certificates from our default classic profile, unless they\u2019ve opted into another profile. This profile will switch to the new Generation Y hierarchy on May 13 2026. These new intermediates do not contain the \u201cTLS Client Authentication\u201d Extended Key Usage due to an upcoming root program requirement. We hav"
  },
  {
    "title": "\u201cSuper secure\u201d messaging app leaks everyone's phone number (ericdaigle.ca)",
    "points": 508,
    "submitter": "e_daigle",
    "submit_time": "2025-12-15T19:23:51 1765826631",
    "num_comments": 239,
    "comments_url": "https://news.ycombinator.com/item?id=46279123",
    "comments": [
      "> What\u2019s going on in that user object? The pin field seems suspiciously related to the PIN we were asked to input after creating our accountThis might be the fault of opt-out serialization library (by default it serializes the whole object and you need to manually opt-out fields from it). So a programmer adds a field, forgets to add opt-out annotation and voil\u00e0.Or they are just using plain JS dicts on the server and forgot to remove the key before using it in a response.> The vulnerability they\u2019re talking about was presented in a paper by researchers at the University of Vienna.This vulnerability (mapping phone numbers to user id via rendevouz API) is old and was exploited in 2016 in Telegram [1] and allowed Iranian govt to build a phone book of 15M Telegram users. The paper also mentions that the vulnerability was known in 2012, still not fixed.[1] https://telegram.org/blog/15million-reutersreply",
      "> This might be the fault of opt-out serialization library (by default it serializes the hole object and you need to manually opt-out fields from it). So a programmer adds a field, forgets to add opt-out annotation and voil\u00e0.In a previous job, on my first audit of the code, I spotted such vulnerabilities pretty much everywhere.Developers simply need to stop using these libraries.reply",
      "This is such a common issue I've seen in so many API backends, where sensitive fields on a record are getting sent to the client and no one notices because it's invisible in the UI.reply",
      "The fact that the PIN is leaked is bad enough, but it also happens to be plaintext. This is a password. It should not be stored unhashed, and it should be hashed with strong algorithms.reply",
      "It\u2019s a 6 digit pin. Doesn\u2019t seem worthwhile to hash. What are the best practices here? I\u2019m not surereply",
      "This is why signal\u2019s encrypted phone number lookup system is so cool. The server uses a bitwise xor when querying for numbers using hardware encrypted ram. The result is that even if you\u2019re examining the machine at the most basic levels you can\u2019t tell the difference between a negative or positive hit for the phone number unless you\u2019re the phone requesting the api.Obviously ratelimiting is a separate and important issue in api management.The thing about building secure systems is that there are a lot of edges to cover.reply",
      "I don't think it's cool at all, a secure messaging app should not require personal/tracking identifiers like phone numbers in the first place.reply",
      "The sad part is, that's what's keeping Signal safe from spam.Also, average Joe is not using proxy to hide the IP-address of their device so they leak their identity to the server anyway. Signal is not keeping those logs so that helps.Messaging apps cater to different needs, sometimes you need only content-privacy. It's not a secret you're married to your partner and you talk daily, but the topics of the conversation aren't public information.When you need to hide who you are and who you talk to (say Russian dissident group, or sexual minorities in fundamentalist countries), you might want to use Tor-exclusive messaging tools like Cwtch. But that comes at a near-unavoidable issue of no offline-messaging, meaning you'll have to have a schedule when to meet online.Signal's centralized architecture has upsides and downsides, but what matters ultimately is, (a) are you doing what you can in the architectural limitations of the platform (strong privacy-by-design provides more features at same security level), and (b), are you communicating the threat model to the users so they can make informed decision whether the applications fits their threat model.reply",
      "If you intend to use SMS (phone numbers) as a resource constraint (sign up requires 'locking up' a resource that is worth at least a few cents) then at least you can offer a ZKP system where the 'consumed' phone number is not tied to an account. You could also offer to accept cryptocurrency for this function - call it a donation.That Signal did none of those things implies that privacy was not their objective. Only secure communications was.It's possible that the reason behind their anti-privacy stand is strategic, to discourage criminal use which could be used as a vector of attack against them. Doesn't change the fact that Signal is demonstrably anti-privacy by design.reply",
      "If you wanted to keep it safe from spam, you'd use a proof-of-work scheme using a memory-hard hash function like scrypt, or a Captcha, or an invite-code system like lobste.rs or early Gmail.  Signal's architects already knew that when they started designng it.reply"
    ],
    "link": "https://ericdaigle.ca/posts/super-secure-maga-messaging-app-leaks-everyones-phone-number/",
    "first_paragraph": "Neither of us had prior experience developing mobile apps, but we thought, \u201cHey, we\u2019re both smart. This shouldn\u2019t be too difficult.\u201dOnce upon a time, in the distant memory that is 2023, a new instant messaging app called Converso was launched. Converso made some pretty impressive claims about its security: it claimed to implement state of the art end-to-end encryption, to collect no metadata, and to use a decentralized architecture that involved no servers at all. Unfortunately, security researcher crnkovi\u0107 did some basic reverse engineering and traffic analysis and found all of these claims to be completely baseless, with Converso collecting plenty of metadata on every message and using a third-party E2EE provider to store messages on bog standard centralized servers. Even more unfortunately, crnkovi\u0107 also found that Converso implemented the (perfectly functional if used properly) Seald E2EE service in such a way that encrypted messages\u2019 keys could be derived from publicly available i"
  },
  {
    "title": "We are discontinuing the dark web report (support.google.com)",
    "points": 91,
    "submitter": "satertek",
    "submit_time": "2025-12-15T14:56:02 1765810562",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=46275316",
    "comments": [
      "I found the info not actionable because it wouldn\u2019t say what actual values were posted.I have a common name Gmail account. The password is rather complex and I would be surprised if it leaks as only I and Google know it. However, I would get reports that it\u2019s on the dark web with blanked out password values. So I never knew if they actually compromised or just something else.They would also report when some random site that used my Gmail address as user id was on the darknet that I don\u2019t care about. I don\u2019t care if my fidofido account is leaked. I never use it and if I did, then I would reset.I think if the data were useful Google would have kept this up.I bet they keep tracking though, just keep the reports internal.reply",
      "I never got the Google dark web reports, but my credit card used to send me reports constantly saying that my email address was 'found on the darkweb.' Okay, that's not useful information. If it showed me if there were associated passwords, that might be helpful, but just saying my address was found on the darkweb is meaningless. My email address is public information.The worst part is, it was an email address I hadn't used in about 10 years, and they wouldn't let me take it out of the report.reply",
      "Well you could change the email address you use for the financial services only, and keep it secret. Then it would be harder to impersonate you.reply",
      "I might be misremembering this but FWICR on Chrome it would link your saved passwords with the dark web report, and automatically recommend you change any account that had the same password as the \"pwned\" account found in the dark net. Was pretty useful.reply",
      "While this was a free service and thus Google is under no obligation to continue offering this service, this is still quite sad. They could have atleast bundled it for some tier of Google One paid subscription.reply",
      "It was as inactionable and useless as the ones that ID.me or whatever sends. Also calling it Dark Web report always felt super insincere. It had nothing to do with the \"dark web\", that just served a way to make it sound cooler and more hackery. Aren't we talking about something that's equivalent to HaveIBeenPwned?reply",
      "Discover (Card/Bank) also announced recently that they are stopping their dark web report service. I wonder if they just used Google, or if it's a coincidence...reply",
      "dark web reports in general, seem to be a funnel for paid \"security\" and monitoring services, VPNs AV suites, typically you review your passwords for strength and redundancy, then you are redirected to buy some service, that ultimately looks like a data hoover, and put everything in a cloud scheme.  now we have AI and FOMO to hook and reel in, seemingly more effective than darkweb boogeymen for adoption and revenue.reply",
      "HTTP response dumps from the Tor dark web: https://rnsaffn.com/zg4/reply",
      "I set it up for an old Google account that has been breached. It did a relatively good job, but HIBP has more data in my experience, albeit it mainly looks at emails, whereas Google's report can do lookups by full name, address, and phone number. I think it was useful, but did not get enough love to be like a second HIBP.reply"
    ],
    "link": "https://support.google.com/websearch/answer/16767242?hl=en",
    "first_paragraph": "We are discontinuing the dark web report, which was meant to scan the dark web for your personal information. The key dates are:While the report offered general information, feedback showed that it didn't provide helpful next steps. We're making this change to instead focus on tools that give you more clear, actionable steps to protect your information online. We'll continue to track and defend you from online threats, including the dark web, and build tools that help protect you and your personal information.We encourage you to use the existing tools we offer to strengthen your security and privacy, including:We encourage you to also use Results about you. This tool helps you find and request the removal of your personal information from Google Search results, like your phone number and home address. Learn more about tips to help you stay safe online.On February 16, 2026, all data related to dark web report will be deleted. You can also delete your data ahead of time. After you delete"
  }
]