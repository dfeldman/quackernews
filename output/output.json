[
  {
    "title": "A data table thousands of years old (2020) (datafix.com.au)",
    "points": 74,
    "submitter": "rickcarlino",
    "submit_time": "2024-12-21T22:25:37 1734819937",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42482829",
    "comments": [
      "This is amazing. I\u2019ve been collecting images of tables in an are.na album for a while, trying to get a handle on all the ways they show up in visual culture. This one is by far the oldest I\u2019ve ever seen! If you\u2019re interested in this you might enjoy the album, too. It\u2019s https://www.are.na/joshua-kopin/tabular-presentation\n \nreply",
      "Is there a good word for \"obvious\" that doesn't have negative connotations?When I see something like this it makes me think about how a spreadsheet structure is \"obvious\" - but I mean it positively! It's a beautiful, intuitive, almost inevitable way to lay out data, and I'm delighted that folks came up with something like this so long ago.I feel this way about a lot of my favorite posts on HN, whether they're a bit of history, a totally new invention, or something different entirely. And I certainly feel it here.\n \nreply",
      "Column headers as well, as per modern convention, as opposed to row headers.\n \nreply",
      "How about self-evident?\n \nreply",
      "Innate, instinctive, intuitive, natural, automatic. I don\u2019t think obvious is a bad word though.Descartes did not invent x-y coordinates until the 1600s, yet a table of columns and rows is totally natural and emergent given a two-dimensional recordkeeping medium\n \nreply",
      "The advantages of tables, are that you can visually or geometrically read the contents easily, whether it is reading a row and only a row, or wether it's reading the contents of a column sequentally.While we had spreadsheets since the 90s, which visually allow the user to create tables. Relational database take this concept to the very architecture in both the storage format and as in the data retrieval mechanisms.Relational databases define schemas with fixed length fields, and by extension each row has a fixed length. This is equivalent to the horizontal length of a column, but in terms of bytes. This allows for quickly finding the nth row of a table, or the ith field of a column.Query languages formalize the algorithm for reading a traditional table. Going row by row checking the description of each transaction (Select * from table), comparing it to our searched term (where description = salary), then going to the column with the destination account, and looking for that in another table with a similar process.Just that, interesting how the same metaphor lead to 2 very different types of accounting software.\n \nreply",
      "\"interesting how the same metaphor lead to 2 very different types of accounting software.\"The tablets are tabulated lists which is how anyone might do a shopping list or list of income and expenditure.Double entry book keeping is only around 600 years old (I'd have to look it up).  That method requires an in from somewhere corresponding to an out from somewhere else.  It enables or enhances all sorts of funny business and also cross checking and auditing.Then we move on to the full Nominal/Sales/Purchase ledgers with Cashbook and all the rest.  Perhaps we might instead go for the personal version.Anyway, my point is that accounting does not depend on IT related metaphors.The tablets in OP are tabulated tallies of works and how they were generated - it is like a spreadsheet where the human is the computer.Funnily enough, we call them tablets instinctively.   Computer originally meant a person who computed things.  No need for metaphors at all 8)\n \nreply",
      "LANPAR, available in 1969, was the first electronic spreadsheet but was on mainframes https://en.wikipedia.org/wiki/Spreadsheet?wprov=sfti1#\n \nreply",
      "\"While we had spreadsheets since the 90s\"I was using SuperCalc in the '80s.\n \nreply",
      "\"Relational databases define schemas with fixed length fields\"What is a varchar or a blob?  Even a .csv allows for a variable length field (by default).  I think you missed out the word: \"can\".Fixed field width is an optimisation strategy not a requirement.\n \nreply"
    ],
    "link": "https://www.datafix.com.au/BASHing/2020-08-12.html",
    "first_paragraph": "For a full list of BASHing data blog posts see the index page. \u00a0\u00a0\u00a0\u00a0I knew that data tables had been around a long time, but I didn't appreciate how long until I read recently about account-keeping in ancient Mesopotamia.The accounts were written on clay tablets, sometimes with impressed lines to mark off rows and columns. Here's a drawing of the front and back sides of an example:This tablet was found on the site of the old city of Larsa near the mouth of the Euphrates in Iraq. Someone wrote on the tablet in the Old Babylonian Period, ca 3600-4000 years ago.The cuneiform text was transliterated and translated by Eleanor Robson, who currently heads the History Department at University College London. You can see her efforts at this website by clicking on the tablet's British Museum catalog number, BM 085232.Below I've put Prof. Robson's translation into a spreadsheet. Items in square brackets are guessed fill-ins. The \"s.\" stands for shekels and \"m.\" is m\u016b\u0161ar, equal to 60 shekels.\nA = \""
  },
  {
    "title": "Translating 10M lines of Java to Kotlin (fb.com)",
    "points": 49,
    "submitter": "ermatt",
    "submit_time": "2024-12-18T17:29:22 1734542962",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=42452640",
    "comments": [
      "I\u2019m skeptical of the value in doing this. There are a mountain of tools like NullAway, ErrorProne, Immutables that make it so much easier to write safe code in Java. New developments in the language like first-class record types improve the DX as well.I think Kotlin helped push Java in the right direction, but at this point it seems like a weaker choice. Spending years to migrate a massive Java code base like this feels like wasted time.\n \nreply",
      "I, personally, happen to like writing in Kotlin more than Java - with a lot of experience in both (though admittedly, all? the Java I wrote is in the pre-Streams style).I like:  * data class Foo(val theImplementationAndStyleOfDataClasses: String)\n  * elvis?.operator?.chaining\n  * the order of variable declaration (type afterward)\n  * how function pointers at the end of a method call can be auto-inserted as the next curly bracket\n  * how you can have fun foo() = returnValue; in one line.\n  * fun `method names that can have spaces - and dashes - in them`()\n\nThe preceding 3, combined, allow for:  @Test\n  fun `much easier testing`() = commonTestSetupWrapper {\n    // the code under test\n  }\n\n  * val immutable by default\n\nWhile I agree that Kotlin has definitely helped push Java in the right direction; and I agree that it's probably not especially necessary to migrate 10MM lines of Java code to Kotlin, especially since they're fully interoperable, I definitely would prefer writing _new_ code in Kotlin over Java for the for-the-lazy devex improvements, if nothing else.fwiw, my \"good at it\" programming history follows the lineage in historical order of:  * Java (8?? years of it including competition programming)\n  * C# (5+ years)\n  * Python (2016ish to current)\n  * Ruby (3-ish years, lots of Rails)\n  * Kotlin (2-3 years, through current - written over 40k lines of Kotlin in the last year, alone)\n \nreply",
      "As long as they're already writing new code in Kotlin, translating the existing code makes a ton of sense, if they can do it cost effectively (which is sounds like they did).One of the huge problems with a language migration is that you're left with old and new and all the parallel tooling, context switching, and impedance mismatches. There's often a claim that the existing code will be migrated eventually, but IME that doesn't actually happen with large code bases. Then if there's ever a third migration, you're left with three languages in play.It's much better to aim for 100% migration, as close to 100% automated as possible. Then when you're done, you're really done. Maintenance, training, and the next migration will be easier.\n \nreply",
      "Is Oracle a factor?Does a Kotlin codebase have more safety from a legal perspective?\n \nreply",
      "I would argue it was Scala, not Kotlin, that has contributed to the push to make Java \u201cbetter\u201d.\n \nreply",
      "Crazy project.Personally I find that it's an interesting indicator of the capability of the programming languages. Moving from language A to B can be extremely easy if B is as powerful or more powerful in terms of expressiveness than A. It can be an absolute horror if it is less powerful.Being not null-safe in fact brings additional expressiveness. I guess most would argue that it's not a good type expressiveness. Nonetheless it is a type of expressiveness that can cause trouble during such a transition.In general it feels like Java is making faster progress than Kotlin nowadays. I wonder where Kotlin would be if it weren't for Android. I hope those folks don't have to migrate back before they even finished.\n \nreply",
      "I have a genuine side question... Why does Meta have 10M lines of Java for their Android code base? What's in it?\n \nreply",
      "Java's how you wrote Android apps before Kotlin came out. I expect they have __all their existing Android code__ in Java. 10MM lines doesn't seem out of line for a very, very established company with 100k developers across several products. It's one of the 3 main platforms that people interact with Facebook on and so they'd want it to be as good and as fast as possible, especially on older phones for the time when Android phones were new.\n \nreply",
      "Why they wouldn't use React Native?\n \nreply",
      "What are the benefits of Kotlin over Java? Something I wish they went into!\n \nreply"
    ],
    "link": "https://engineering.fb.com/2024/12/18/android/translating-java-to-kotlin-at-scale/",
    "first_paragraph": "Android development at Meta has been Kotlin-first since 2020, and developers have been saying they prefer Kotlin as a language for even longer.But, adoption doesn\u2019t necessarily entail translation. We could simply decide to write all new code in Kotlin and leave our existing Java code as is, just as many other companies have. Or we could take it a little further and translate just the most important files. Instead, we decided that the only way to leverage the full value of Kotlin was to go all in on conversion, even if it meant building our own infrastructure to automate translation at scale. So, a few years ago, engineers at Meta decided to take roughly ten million lines of perfectly good Java code and rewrite them in Kotlin.Of course, we had to solve problems beyond translation, such as slow build speeds and insufficient linters. To learn more about Meta\u2019s broader adoption effort, see Omer Strulovich\u2019s 2022 blog post on our migration from Java to Kotlin or Lisa Watkin\u2019s talk about Kot"
  },
  {
    "title": "Dividing unsigned 8-bit numbers (0x80.pl)",
    "points": 89,
    "submitter": "mfiguiere",
    "submit_time": "2024-12-21T19:25:13 1734809113",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=42481612",
    "comments": [
      "What's not mentioned is that in most cases you have a constant divisor which lets you replace division by multiplication with the reciprocal. The reciprocal can be rounded to a nearby dyadic rational, letting you do the division with a right-shift.For example, 8-bit division by 3 is equivalent to widening multiplication by 171 followed by a right-shift of 9, as 171/2^9 = 0.333984375 which is close enough to 1/3 that the results match exactly.\n \nreply",
      "A shift of 16 is enough for every 8-bit numerator, ie. x/a is (u32(x)*b)>>16 for some b depending only on a. You could precompute b for each a and store it a lookup table. The largest b is b=65536 for a=1 and the smallest is b=258 for a=255, so b fits in a u16 if stored with a 1-offset. Not sure it's worth it unless you reuse the denominator many times though.\n \nreply",
      "These methods are especially useful in hardware/FPGA implementations where it's infeasible to have a ton of fully pipelined dividers.\n \nreply",
      "They are actually useful for optimising compilers too! Mul or mul+shifts is often faster than div\n \nreply",
      "Also, if you know ahead of time that it\u2019s exact division, there is a similar approach that doesn\u2019t even need widening multiplication!\n \nreply",
      "Yes, if you know something is an exact multiple of n = r*2^k where r is odd, you can divide out the multiple by right-shifting k followed by modular multiplication by the modular multiplicative inverse of r.\n \nreply",
      "Can you provide an example with details?  Thanks!\n \nreply",
      "In 8-bit arithmetic (i.e. mod 256), the multiplicative inverse of 11 is 163. So, if you take some multiple of 11, say 154, then you can compute 154/11 instead as 154*163.Indeed,154*163 = 25102, and25102 = 14 (mod 256).\n \nreply",
      "> For example, 8-bit division by 3 is equivalent to widening multiplication by 171 followed by a right-shift of 9, as 171/2^9 = 0.333984375 which is close enough to 1/3 that the results match exactly.Is this related to the fact that 171 is the multiplicative inverse of 3 (mod 256), or is that a coincidence?\n \nreply",
      "Sort of. (After all, a \"reciprocal\" for our purposes is just a multiplicative inverse in the reals, so it makes sense that it would be related to the multiplicative inverse in other domains.)3 times 171 is 513. So to divide by 3, we could multiply by 171 and then divide by 513. Dividing by 513... isn't any easier, but 513 is close to 512, so we hope that dividing by 512 (which is trivial - just a right-shift) gets us close enough.Suppose for a moment we try dividing 3 by 3 using this trick. First we'll multiply by 171 to get 513. Consider that value in binary:    1000000001\n     ^^^^^^^^^\n      ~~~~~~~~\n\nDividing by 512 will shift away the ^ bits. For floor division, we therefore want the ^ underlined value to be close to zero. (That way, when we divide 255 (say) by 3, the error won't be big enough to overflow into the result bits.)The multiplicative inverse fact is equivalent to telling us that the ~ underlined bits are exactly 1. Conveniently, that's close to 0 - but we didn't account for all the ^ underlined bits. For example, the multiplicative inverse of 7 (mod 256) is 183, but 7 times 183 is 1281. That's close to 1280, but that doesn't really help us - we could right-shift by 8 but then we still have to divide by 5. If we just ignore the problem and divide by 1024 (right-shift by 10), of course we get a lot of wrong results. (Even 6 / 7 would give us 1 instead of 0.)It also turns out that we'll need more bits for accurate results in the general case. I think it's possible without overflowing 16-bit numbers, but it definitely requires a bit more trickery for problematic divisors like (from my testing) 195. I thought I remembered the details here but proved myself wrong at the Python REPL :(\n \nreply"
    ],
    "link": "http://0x80.pl/notesen/2024-12-21-uint8-division.html",
    "first_paragraph": "ContentsDivision is quite an expansive operation. For instance, latency of the 32-bit\ndivision varies between 10 and 15 cycles on the Cannon Lake CPU, and for Zen4\nthis range is from 9 to 14 cycles. The latency of 32-bit multiplication is\n3 or 4 cycles on both CPU models.SIMD ISAs usually do not provide the integer division; the only known exception\nis RISC-V Vector Extension. However, SIMD ISAs have floating point division.In this text we present two approaches to achieve a SIMD-ized division of 8-bit\nunsigned numbers:We try to vectorize the following C++ procedure:Compilers cannot vectorize it. For example GCC 14.1.0 produces the following assembly\n(stripped from code alignment junk):An 8-bit number can be converted into single precision floating point number\nwithout any precision loss.The generic outline of division consist the following steps:Here is the actual implementation of SSE procedure. Note that we need to explicitly\ntruncate the floating point number before converting back"
  },
  {
    "title": "City Roads: A tool to draw all roads in a city at once (anvaka.github.io)",
    "points": 95,
    "submitter": "gaws",
    "submit_time": "2024-12-21T18:16:01 1734804961",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42481206",
    "comments": [
      "Incredible! May take a while for a big city, but well worth the wait.\n \nreply",
      "In the age of bloated resource hogs, I was pleasantly surprised that this rendered with no perceptible lag or stuttering, even on my phone. Impressive how everything is drawn so efficiently.\n \nreply",
      "Would be nicer if it would distinguish (just varying line thickness) between footpaths, roads, highways etc. Many European cities look messy in this view.IMO, prettymaps is quite a bit better: https://github.com/marceloprates/prettymaps\n \nreply",
      "Link to the github project: https://github.com/anvaka/city-roads\n \nreply",
      "There's also a Figma plugin that can import OSM as vector. https://www.figma.com/community/plugin/1251030017228239072/v...\n \nreply",
      "I get a 403 for some cities. E.g. Wyk (auf F\u00f6hr) returns 403 on this .pbf resource: https://city-roads.s3-us-west-2.amazonaws.com/nov-02-2020/36...\n \nreply",
      "Oh damn, I thought this is a Show HN :D\n \nreply",
      "appreciate the feedback - I'll take a look\n \nreply",
      "I have a map of Brugge (Bruges) from this tool printed off on my wall. It's a great concept!\n \nreply",
      "oh wow. Glad you liked it!\n \nreply"
    ],
    "link": "https://anvaka.github.io/city-roads/",
    "first_paragraph": ""
  },
  {
    "title": "Query Apple's FindMy network with Python (github.com/malmeloo)",
    "points": 304,
    "submitter": "nkko",
    "submit_time": "2024-12-21T12:14:55 1734783295",
    "num_comments": 135,
    "comments_url": "https://news.ycombinator.com/item?id=42479233",
    "comments": [
      "This looks great. If this Python implementation of the FindMy API actually works, it would be a major technology quality-of-life improvement for me. I hope Apple lets it stay alive.Everyone who shares location with me does so over Find My, and my family insists on using AirTags. As a 100% desktop Linux and mobile Android user, it is one of the few things that I always need to remote in to my Mac Mini to access because there are no x-platform FindMy apps and the FindMy iCloud web app does not have feature parity to the macOS and iOS apps. One of a long list of offenses where Apple refuses to make things easy for x-platform friend groups and families. Very annoying.\n \nreply",
      "Even within Apple's platforms, there's pretty limited support for automation -- you can say \"Siri find my keys\" but there's no App Intents / Shortcuts support for automating anything within Find My (AFAIK), which is a bit disappointing.\n \nreply",
      "I suspect they might be a bit wary of the privacy implications of giving other apps/Shortcuts access to Findmy data\n \nreply",
      "Yes, although I recently discovered Hammerspoon which is a clever little bit of open source macOS desktop automation technology:https://www.hammerspoon.org/\n \nreply",
      "What about Apple Automator and Applescript?\n \nreply",
      "Find My has no any exposed Applescript commands. You'd next need to try (I think, been >a decade) Accessibility Inspector to find the names of the interface so you can tell Applescript what to click on. On some apps, even this doesn't work.I also suspect Find My is a Catalyst-ported iPadOS app, which tend to be awful/useless for scripting.\n \nreply",
      "Does Blue Bubbles work for this? They have find my built into their app\n \nreply",
      "Kind of? Right now it feels like it's glued on the side and a good proof of concept. It takes a lot more panning and zooming than it should. But it DOES work, one-way: you can see your friends' locations but they can't see yours.\n \nreply",
      "One that really annoys me is inability to monitor/control my kid's device useage and time limits.\n \nreply",
      "Possible in the apple ecosystem. If the kids are part of a \"familly\", you can monitor / control using Parental Controls accessed from your iPhone > Settings > Screen Time.Also checkout firewalla\nhttps://help.firewalla.com/hc/en-us/articles/360008214094-Ac...\n \nreply"
    ],
    "link": "https://github.com/malmeloo/FindMy.py",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83c\udf4f + \ud83c\udfaf + \ud83d\udc0d = Everything you need to query Apple's FindMy network!\n      \n\n\nThe all-in-one library that provides everything you need\nto query Apple's FindMy network!The current \"Find My-scene\" is quite fragmented, with code\nbeing all over the place across multiple repositories,\nwritten by several authors. This project aims to\nunify this scene, providing common building blocks for any\napplication wishing to integrate with the Find My network.ImportantThis project is currently in Alpha. While existing functionality\nwill likely not change much, the API design is subject to change\nwithout prior warning.You are encouraged to report any issues you can find on the\nissue tracker!The package can be installed from PyPi:For usage examples, see the examples directory. Documentation can be found here.Want to contribute code? That's great! For new "
  },
  {
    "title": "Enum of Arrays (tigerbeetle.com)",
    "points": 52,
    "submitter": "signa11",
    "submit_time": "2024-12-21T01:49:25 1734745765",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42476876",
    "comments": [
      "I don't think I've had the need for a uniformly tagged array of enums. Generally, when I do an AoS to SoA transform that includes tagged data, I just factor out the tag into its own array. In fact, if the tag is 2-valued, I just build a bitmap, rather than burning a whole byte. If the tag is a resource indicator, then I have a group of 1-hot bitmaps.\n \nreply",
      "The SoA transformation makes sense to me and is quite general. The EoA transformation on the other hand feels like a rare special case though it seems perhaps less rare for the OP.Either way, these types of optimizations are typically marginal in the context of end to end performance of most programs. It's good to have some knowledge of these kinds of techniques, but most of the time it makes sense to do the thing that is most straightforward to implement and optimize later once the program is already working. Of course if the problem maps neatly onto EoA then that should be preferred in the initial implementation. I though in my 30+ years of programming cannot think of a particular problem that I have solved that would have been enhanced by this.\n \nreply",
      "It's an alternative to OOP. You can get there via a series of transformations:1. Start with OOP (heap-allocated objects with shared base structs)2. Transform to using tagged unions instead3. Transform to the approach outlined in the OP (I call it the \"encoding\" approach in this talk: https://vimeo.com/649009599)It's handy because you get to use an index to refer to an object, and you get serialization benefits. The zig compiler uses this pattern in quite a few places:* https://github.com/ziglang/zig/blob/77c63ac36034db577a9287c5...* https://github.com/ziglang/zig/blob/77c63ac36034db577a9287c5...* https://github.com/ziglang/zig/blob/77c63ac36034db577a9287c5...* https://github.com/ziglang/zig/blob/77c63ac36034db577a9287c5...\n \nreply",
      "Isn't performance and memory usage generally enhanced by this?So why not simply default to this instead of defaulting to Interfaces/traits doing dynamic polymorphism?Makes everyone a bit more happy.\n \nreply",
      "see also: Richard Fabian's data-oriented design book -- the chapter on existential processing discusses enumshttps://www.dataorienteddesign.com/dodbook/node4.htmlRough idea: model everything as relational data - define 1 table for each state. membership of a record in the table corresponding to state X implies that record is in the given state X.> the reason why you would put an enum in table form, is to reduce control flow impact. Given this, it's when we aren't using the enumerations to control instruction flow that it's fine to leave them aloneAn example of the latter might be some kind of state machine, where you can write branch-free code to determine the successor state from current state, and no other processing needs to branch on the state tag.\n \nreply",
      "This is a somewhat, hmm, bilingual post.  The enum in question here is what Zig calls a tagged union, while Rust calls it an enum, with what Zig calls an enum being the degenerate case where the tag is the only payload.I thought this would be about std.enum.EnumArray[0], an array of some T which is indexed by an enum.  I've gotten a lot of mileage out of those as well.  But it's about std.MultiArrayList[1], as used with a tagged union.  I've had occasion to use that with structs, but not with unions, and didn't actually know that you could, although finding out it makes sense.Actually a variation on MultiArrayList which is optimized for homogenous collections of one specific union variant, since if that's the useful way to structure the data then the tag would be redundant to store one of per element.Good read, mostly wanted to add a few links for those who want to know more.  The comptime metaprogramming used in MultiArrayList is a great illustration of what Zig is capable of IMHO.[0]: https://ziglang.org/documentation/master/std/#std.enums.Enum...\n[1]: https://ziglang.org/documentation/master/std/#std.multi_arra...\n \nreply",
      "> This is a somewhat, hmm, bilingual post. The enum in question here is what Zig calls a tagged union, while Rust calls it an enum, with what Zig calls an enum being the degenerate case where the tag is the only payload.To be fair, I think that most languages typically use enum to refer to the same thing as Zig; if anything, Rust (and Swift, iirc) are somewhat outliers for using that term for tagged unions.\n \nreply",
      "> This is a somewhat, hmm, bilingual post.Yeah, I wish the author had just mentioned what language they were using in the blog post text. I was looking at it and I couldn't identify it. Now I know it is Zig, but I'm not familiar with Zig so I can't identify it by sight. I was looking at it and thinking \"this looks a bit like Rust but isn't Rust\".\n \nreply",
      "Now do a single class pointer for an array of values...\n \nreply"
    ],
    "link": "https://tigerbeetle.com/blog/2024-12-19-enum-of-arrays/",
    "first_paragraph": "matkladA popular data-oriented design pattern is a Struct of Arrays. Is an\nArray of Enums also useful? Yes! But let\u2019s do a refresher on struct of\narrays (SoA) first:If you have a Thing,and an array of Things,it's possible to wrap the data inside out and useinstead. The benefits are:You can use the same trick also for a more SIMD-friendly data layout.\nA bad way to use SIMD is to try to vectorize the processing of an\nindividual item. A good way to use SIMD is to process several items at\nonce.For example, if a Thing in question is a 3D vector, it's\nusually not a good idea to implement the dot product of two vectors by\nloading xyz of one vector into a SIMD register\na, xyz of another vector into a SIMD register\nb, and then performing a SIMD multiplication of\na * b. The reason is that your \"SIMD width\" is still only\nthree numbers:Much better to simultaneously compute the dot products of multiple\npairs of vectors. Then, you can load a SIMD vector with\nxxxxxxx, which is the x coordinate for th"
  },
  {
    "title": "Ideas from \"A Philosophy of Software Design\" (16elt.com)",
    "points": 58,
    "submitter": "fagnerbrack",
    "submit_time": "2024-12-18T23:03:58 1734563038",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=42456492",
    "comments": [
      "I come from an FP background, and this book was interesting to me as the author very clearly has a very different (imperative, systems) background. In some cases we have very different opinions, in some cases I'm completely agreed (e.g. \"define errors out of existence\" is extremely common in FP, usually under the term \"make illegal states unrepresentable\"), and in other cases I feel they were half-way to FP but couldn't quite get all the way there (e.g. the editor example is a classic interpreter, but they didn't make the connection IIRC.) I only skimmed the book and would like to go back for a more detailed review. Curious if anyone else with an FP background had the same or different experience.\n \nreply",
      "\"Define errors out of existence\" might sound like \"make illegal states unrepresentable,\" it's actually not. Instead it's a pastiche of ideas rather foreign to most FP readers, such as broadening the space of valid inputs of a function. One of his examples is changing the substr function to accept out of bounds ranges.You might be interested in my review. I'm a Haskeller at heart, although the review draws more from my formal methods background. Spoiler: his main example of a deep module is actually shallow.https://www.pathsensitive.com/2018/10/book-review-philosophy...\n \nreply",
      "Does Ousterhout actually say modules must always have a longer implementation than their spec, or just that this is a generally desirable feature?If he did, I agree with you, he was wrong about that. I also agree that the unix file API is probably not a good example.But whether or not he did, I think the dissection of edge cases would be better off emphasizing that he's got something importantly right that goes against the typical \"small modules\" dogma. All else being equal, deeper modules are good--making too many overly small modules creates excessive integration points and reduces the advantages of modularity.P.S. While I'm here, this is not really in response to the parent post, but the example in the article really does not do justice to Ousterhout's idea. While he does advocate sometimes just inlining code and criticizes the pervasive idea that you should shorten any method of more than n lines, the idea of deep modules involves more than just inlinining code.\n \nreply",
      "> Does Ousterhout actually say modules must always have a longer implementation than their spec, or just that this is a generally desirable feature?I mean the spec is a lower bound on the size of the solution, right? Because if the solution were shorter than the spec, you could just use the solution as the new shorter spec.\n \nreply",
      "I haven\u2019t looked at the substr function but is that not similar to how you can `take 5 [1,2,3]` or `zip [1,2,3] [\u2018a\u2019, \u2018b\u2019, \u2018c\u2019, \u2018d\u2019]`\n \nreply",
      "Nice and seemingly balanced review.Defining errors out of existence should be mandatory for all golang programs.\n \nreply",
      "Your review is great! But I think the idea that it\u2019s in opposition to PoSD is not right, I think it\u2019s a further development and elaboration in the same direction of PoSD\n \nreply",
      "I read a few chapters and had the same feeling.\n \nreply",
      "I thought the book was stupid. Rehashed a bunch of obvious ideas. It\u2019s a bit harsh, I know, but that\u2019s my honest opinion and I respect other people who like his book.I too have a fp background and I felt the author is unqualified to talk about complexity without knowing fp. Elimination of procedures and mutations is a formal and concrete reduction of complexity while the authors definition of complexity is hand wavy. Someone should know about what fp is before writing a book like this.Why? Because fp is a basically like a formal structure for software design and the author tried to talk about philosophy without knowing some hard formal rules that are well known in the industry. Not saying these rules are absolute but you can\u2019t talk about design without talking about this.The book talks about modularity and things of that nature too and totally skips out on understanding the separation between statefulness and logic. The author completely misses this design concept of how how IO and mutation should be separated from declarative operations. Imperative shell/functional core is a central design philosophy that he doesn\u2019t touch upon. The book is woefully incomplete without talking about this. Whether the authors philosophy aligns with it is open for debate but you can\u2019t talk about what he talks about without mentioning this in a big way.\n \nreply",
      "> Someone should know about what fp is before writing a book like this.1. Are you quite sure John Ousterhout (who invented Tcl[1], comparing it to Lisp in section 7 of the original paper) doesn't \"know about what fp is\" as you say?2. Do you think that the main reason functional programming hasn't taken off in systems programming is that practitioners are ignorant, or do you think there might be issues with fp systems that prevent its adoption?[1] https://web.stanford.edu/~ouster/cgi-bin/papers/tcl-usenix.p...\n \nreply"
    ],
    "link": "https://www.16elt.com/2024/09/25/first-book-of-byte-sized-tech/",
    "first_paragraph": "Almost a month ago, I created a telegram channel with the goal of reading tech books consistently, and sharing summaries of them.This week, I have finished reading the first book - \u201cA Philosophy of Software Design\u201d by John Ousterhout and shared all of the 21 chapter summaries in the channel.In this post, I will share what are the 3 ideas that resonated with me the most.The book is pretty packed with insights, and I think many junior-mid level software engineers can benefit from them, so I do encourage you to read it yourself!On the second chapter of the book, the author describes what is complexity and what are its symptoms:The author argues that complexity is not caused by a single error, it accumulates. Sometimes we convince ourselves that a bit of complexity here won\u2019t matter much, but if everyone on the project adopts this mindset, the project will become complex rapidly.\u201cIn order to slow the growth of complexity, you must adopt a zero-tolerance philosophy\u201d.Imagine a simple order p"
  },
  {
    "title": "Show HN: Rivet Actors \u2013 Durable Objects build with Rust, FoundationDB, Isolates (github.com/rivet-gg)",
    "points": 66,
    "submitter": "NathanFlurry",
    "submit_time": "2024-12-20T16:36:33 1734712593",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42472519",
    "comments": [
      "If I wanted a Rivet integration with Godot Engine and/or Elixir, how would I do it for shared durable objects in a virtual reality environment?I have code for Godot Engine Foundationdb access, but I'm cutting too many encapsulation layers.\n \nreply",
      "You have Godot wired up to talk to FoundationDB? That's incredibly cool, curious about your use case.Godot runs using our container runtime  on Rivet. The FDB API for containers is currently undocumented. I'd be happy to share early access on Discord \u2013 https://rivet.gg/discordGames running on Rivet usually have a hybrid of actors that handle persistent storage (e.g. a matchmaker) and the game server itself.\n \nreply",
      "I aim to build a collaborative VR world editor in Godot using mvsqlite for shared scene persistence.I was salvaging someone else's toy project. The main problem with my research was write performance in SQLite on FDB. I didn't have the capacity to integrate Hctree, which was in the pipeline.* https://github.com/V-Sekai/godot-mvsqlite* https://github.com/V-Sekai/mvsqlite* https://github.com/V-Sekai/elixir-mvsqlite* https://sqlite.org/hctree/doc/hctree/doc/hctree/index.htmlLet's connect on discord.\n \nreply",
      "How is this different from the Durable Promises idea by ResonateHQ?\nIt seams to me a bitter easer to get started with as a small standalone project.\nWould you mind comparing this solutions to that?\n \nreply",
      "Here\u2019s my once a month comment that I should probably put on autopilot:\u201cat least half of show HN posts are just reimplementations of what already exits in Erlang/Elixir\u201d.\n \nreply",
      "The actor model existed before Erlang, and Erlang doesn't have some kind of a monopoly on it. Akka is pretty good too.Same as every OOP isn't \"something that exists already in Java\"\n \nreply",
      "Haha, I\u2019m with you there. I was considering calling that out in the post.I dearly love Erlang & co., but its learning curve is way too steep for most developers today. Our goal is to bring the benefits of Erlang/Akka/Orleans/etc. to more developers by:(a) supporting mainstream languages, and(b) lowering the technical and conceptual barriers to entry.\n \nreply",
      "Related discussion in 2023 https://news.ycombinator.com/item?id=37188659\n \nreply",
      "Yep! Same repo, lots of changes. Since we were on HN in 2023, we've:- Rewrote Nomad from scratch with our own in-house workflow engine- Launched Rivet Actors and isolate runtime- Overhauled our OSS experience to make self-hosting easier- Rewrote frontend from scratch with shadcn to be like the cool kids- Replaced Nebula with mTLS- Completely stripped out Redis for non-caching use casesWe've also opened up the platform to non-gaming use cases.\n \nreply",
      "I've added that link above. Thanks!\n \nreply"
    ],
    "link": "https://github.com/rivet-gg/rivet",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83d\udd29 Run and scale realtime applications with Rivet Actors.\n      \n\n\n\n\n\n\n\nRun and scale realtime applicationsRivet Actors have built-in RPC, state, and events \u2014 the easiest way to build modern applications.\n\n\n\n\nLearn more about actors here.Install the CLI on your machine in order to create & deploy Rivet Actors.Next, follow the setup guide.Next, follow the setup guide.Next, follow the setup guide.The executable will be available at target/debug/rivet.Next, follow the setup guide.Run a single-node Rivet instance for developing your applications locally.Start a Rivet cluster:Next, follow the setup guide.Start a Rivet cluster with TCP & UDP enabled:Next, follow the setup guide.Integrate in to an your existing project's Docker Compose with:Next, follow the setup guide.Compile Rivet from scratch and start a full cluster.Build & start the cl"
  },
  {
    "title": "Show HN: Eonfall \u2013 A new third-person co-op action game built for the web (eonfall.com)",
    "points": 128,
    "submitter": "jonkuze",
    "submit_time": "2024-12-21T16:45:36 1734799536",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=42480624",
    "comments": [
      "Very nice work, and congrats on getting so far with this! I have a few odd questions though:Is the networking websockets or webrtc underneath?Did you have tech challenges with the Unity side at all?What's your business model?\n \nreply",
      "thank you! \n- using Mirror Networking Library w/ Websockets\n- No tech challenges except for the super slooow build times lol\n- Business mode Ads, Ad Rewards, and Virtual Currency to buy premium cosmetics\n \nreply",
      "Curious, are the slow build times locally, your own CI or Unity Cloud Build? (If local/own builders may be some ways to dramatically lower the build times eg by managing the Library/ cache per-platform.)Happy to help anyone with optimizing these approaches it's been a pain to figure out\n \nreply",
      "Slow builds locally, but last I tried cloud build it was about the same.\n \nreply",
      "In the most recent game I automated builds for the initial build took 1-3 hours, but subsequent builds with the Library/ folder cached took 5-10 minutes.Are you switching platforms between builds locally? (like building one for web / server / pc / mac etc). Platform switching essentially blows away the cache, making it take the full build time each time. There was an asset years back that would create folders for each platform's Library/ cache and switch between them when you switched build platforms.In CI (eg using https://game.ci) you can prefix build cache keys with the platform to manage that automatically.Unity Cloud Build is in general slower/more flakey/sometimes has cache issues compared to DIY CI, but it should speed up after a successful first build as long as it caches the Library/ folder, and they do separate that out by build platform properly. (Worth checking each build config setting is set to cache that)\n \nreply",
      "Hey you could always try Unreal for even slower builds!\n \nreply",
      "haha too funny!\n \nreply",
      "Looks interesting.  Some feedback on the trailer: I wouldn't waste the precious first 5 seconds on guys running at the camera, and your post says something about roguelite.  Are there skill trees?  Items/equipment?  Shops?  Different zones?  I assume the characters running at the start represent classes but there's no way to tell.  I'd showcase clips of what all the game has to offer, not just combat the whole time.\n \nreply",
      "Reminds me of the days of spending dozens of hours in Sherwood Dungeon in my youth.\n \nreply",
      "Now that's something I haven't thought about for almost 15 years, but have some nice and vivid memories about. Cool!\n \nreply"
    ],
    "link": "https://eonfall.com",
    "first_paragraph": ""
  },
  {
    "title": "A curious case of O(N^2) behavior which should be O(N) (2023) (gist.github.com)",
    "points": 17,
    "submitter": "bssrdf",
    "submit_time": "2024-12-21T19:34:07 1734809647",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://gist.github.com/bssrdf/397900607028bffd0f8d223a7acdce7e",
    "first_paragraph": "\n        Instantly share code, notes, and snippets.\n      Recently I got interested in Blender 3D, partly inspired by infinigen project.One day I encountered Tellusim. Impressed by the quality of its rendering, I was browsing its blogs and see this. Wow, Tellusim really blowed others out of the water;others including Unreal, Unity, Omniverse and Blender. Wait, Blender is really that slow importing a USD scene?Since Blender is open-source, why not try to figure out what's going on? Here we go.I cloned the latest version of Blender 4.0.0.Alpha and installed all dependencies. Building is a straightforward thing. I am working on Windows 10 and miss perf on Linux. But VS2022 community edition does include a profiling tool: Microsoft (R) VS Standard Collector. Go to the directory where blender.exe is located and issue:Now in blender, import limits_32.usdc unzipped from this test file. It's going to take a while and on my machine that is about 30 seconds. Once importing is done, runFile usd_i"
  },
  {
    "title": "How we made our AI code review bot stop leaving nitpicky comments (greptile.com)",
    "points": 65,
    "submitter": "dakshgupta",
    "submit_time": "2024-12-18T16:31:46 1734539506",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=42451968",
    "comments": [
      "Unless they were using a model too stupid for this operation, the fundamental problem is usually solvable via prompting.Usually the issue is that the models have a bias for action, so you need to give it an accetpable action when there isn't a good comment. Some other output/determination.I've seen this in many other similar applications.\n \nreply",
      "This isn't my post but I work with llms everyday and I've seen this kind of instruction ignoring behavior on sonnet when the context window starts getting close to the edge.\n \nreply",
      "I don't know, in practice there are so many potential causes that you have to look case by case in situations like that. I don't have a ton of experience with the raw Claude model specifically, but would anticipate you'll have the same problem classes.Usually it comes down to one of the following:- ambiguity and semantics (I once had a significant behavior difference between \"suggest\" and \"recommend\", i.e. a model can suggest without recommending.)- conflicting instructions- data/instruction bleeding (delimiters help, but if the span is too long it can loose track of what is data and what is instructions.)- action bias (If the task is to find code comments for example, even if you tell it not to, it will have a bias to do it as you defined the task that way.)- exceeding attention capacity (having to pay attention to too much or having too many instructions. This is where structures output or chain of thought type approaches help. They help focus attention on each step of the process and the related rules.)I feel like these are the ones you encounter the most.\n \nreply",
      "One word changes impacting output is interesting but also quite frustrating. Especially because the patterns don\u2019t translate across models.\n \nreply",
      "This might be what we experienced. We regularly have context reach 30k+ tokens.\n \nreply",
      "+1 for \"No Comment/Action Required\" responses reducing trigger-happiness\n \nreply",
      "We do something internally[0] but specifically for security concerns.We\u2019ve found that having the LLM provide a \u201cseverity\u201d level (simply low, medium, high), we\u2019re able to filter out all the nitpicky feedback.It\u2019s important to note that this severity level should be specified at the end of the LLM\u2019s response, not the beginning or middle.There\u2019s still an issue of context, where the LLM will provide a false positive due to unseen aspects of the larger system (e.g. make sure to sanitize X input).We haven\u2019t found the bot to be overbearing, but mostly because we auto-delete past comments when changes are pushed.[0] https://magicloops.dev/loop/3f3781f3-f987-4672-8500-bacbeefc...\n \nreply",
      "The severity needing to be at the end was an important insight. It made the results much better but not quite good enough.We had it output a json with fields {comment: string, severity: string} in that order.\n \nreply",
      "Here's an idea: have the LLM output each comment with a \"severity\" score ranging from 0-100 or maybe a set of possible values (\"trivial\", \"small\", \"high\"). Let it get everything off of its chest outputting the nitpicks but recognizing they're minor. Filter the output to only contain comments above a given threshold.It's hard to avoid thinking of a pink elephant, but easy enough to consciously recognize it's not relevant to the task at hand.\n \nreply",
      "Here's an idea: read the article and realize they already tried exactly that.\n \nreply"
    ],
    "link": "https://www.greptile.com/blog/make-llms-shut-up",
    "first_paragraph": "Written by Daksh GuptaThis post is adapted from a talk I gave at the Sourcegraph Dev Tools meetup at\nthe Cloudflare office in San Francisco on December 16th, 2024.I am Daksh, co-founder of Greptile - AI that understands large codebases. Our most popular product is our AI code review bot. It does a first pass review of PRs with full context of the wider codebase, surfacing bugs, anti-patterns, repeated code, etc.When we first launched this product, the biggest complaint by far was that the bot left too many comments. In a PR with 20 changes, it would leave as many as 10 comments, at which point the PR author would simply start ignoring all of them.We needed to:There were two ideas here:We picked the latter, which also gave us our performance metric - percentage of generated comments that the author actually addresses.We analyzed existing Greptile comments and found that ~19% were good, 2% were flat-out incorrect, and 79% were nits - comments that were technically true but not something "
  },
  {
    "title": "Language and Personality (solipsys.co.uk)",
    "points": 5,
    "submitter": "ColinWright",
    "submit_time": "2024-12-20T10:51:06 1734691866",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.solipsys.co.uk/ZimExpt/LanguageAndPersonality.html?xl20hn",
    "first_paragraph": "\nHome / Index\n\nA friend of mine[0] told me of the time he had one of his cars[1] in the workshop and the mechanic dropped a spanner.  It bounced off the fender, clattering to the floor, and the mechanic quickly picked it up, gave the fender a wipe, and said (in German): \"No harm done.\"\n\nVictor drew himself up to his not inconsiderable height (six foot two?) and said (in German): \"That is not for you to say!\"\n\nThen he thought to himself ... \"I would never have said that in English\". \n\nAnd I can believe that ... Victor was a gentle, jovial soul, and speaking sharply to a mechanic just didn't seem like him.  But it started in him a train of thought.\n\n\"I wonder\" ... thought Victor ... \"whether I behave differently when I'm thinking in German.  I wonder if my personality changes when I change language.\"\n\nSo he started an investigation.\n\nFirstly he found the US military standardised personality test.  Then he translated it into German, discarding a small number of questions that didn't seem "
  },
  {
    "title": "Grammarly acquires Coda (coda.io)",
    "points": 82,
    "submitter": "Olphs",
    "submit_time": "2024-12-17T16:44:36 1734453876",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=42442852",
    "comments": [
      "> Both companies had arrived at a similar view of the future where AI will redefine every business application and workflow \u2014 and reinvent productivity as we know it today into a place where humans and AI work together everywhere you get work done. We want to rethink a suite of tools and come together to provide users and teams with their own AI productivity platform for apps and agents.> We discussed each of our paths to achieving this vision, and while both teams felt confident in their paths, it was obvious that we would move much faster together. The way that each of us has approached this market is different but inherently complementary. And so the conversation became... \u201cWhat if we merged the companies?\u201d> Over the next few days, through discussions with Grammarly CEO (Rahul Roy-Chowdhury) and the co-founders (Max Lytvyn and Alex Shevchenko) we started sketching out what a combined company would feel like: how the teams would fit together, where the products could immediately integrate and amplify, etc. And we also discussed the leadership structure, and agreed that I would lead the joint company as CEO.> With a round of sushi and some sake, we shook hands \u2014 excited to work together on the future of AI.\u2014The idea that any acquisition, but especially this one, was minted in this fashion is hilarious.\n \nreply",
      "Especially \"acquistion\" - he continually presents both sides as peers, collaborating - even mentions \"merging: - but this never happens. Maybe the Coda people will eventually, someday emerge as the leaders, but this would be incredibly atypical. Even when two equal size companies merge someone is being acquired. Majority of Coda leadership will be gone in 6-12 months.\n \nreply",
      ">> Majority of Coda leadership will be gone in 6-12 monthsWell, in this case, the new CEO of the combined company is from Coda, so perhaps a little less likely than otherwise...\n \nreply",
      "This is how the startup life is sold to youngsters\u2014million-dollar conversations just happen\u2014and it\u2019s amusing to see the myth is still alive.\n \nreply",
      "Sometimes they do.>> zuck pinged me to say \"i'm not sure if this is a good idea yet, but i think maybe facebook should buy instagram, what do you think?\" [0]The next conversations also read as if they were happening over lunch, albeit with lawyers whispering approved language into each participant's ear [1][0] https://www.techemails.com/p/instagram-cofounder-on-mark-zuc...[1] https://www.threads.net/@techemails/post/C_od8rsvuiO\n \nreply",
      "Its what happens when you get AI to write your press release.\n \nreply",
      "Grammarly has been having an identity crisis ever since LLMs made grammar checking accessible to every company at a fraction of the cost. ChatGPT is killing a lot of companies and grammarly was the first collateral.This acquisition is concerning because Grammarly is well known for its bad privacy policy and how it's essentially a keylogger. Now that it has access to probably thousands of companies data hosted on Coda is a huge concern.But it's high time Grammarly evolves itself into some other product or die trying.\n \nreply",
      "The other day, Grammarly marked a grammar error in my text. I wasn\u2019t too sure about it, so I asked ChatGPT (4o) to explain it. It agreed with Grammarly. I wasn\u2019t convinced and didn\u2019t understand ChatGPTs justification, so I asked again but using the more advanced o1 model\u2026 this time ChatGPT said Grammarly was wrong.\u2026 ChatGPT is good at improving grammar, but it doesn\u2019t \u201cunderstand\u201d what it\u2019s doing (by design), and doesn\u2019t have a complete and consistent ruleset, which is what you want in a grammar checker. Also, grammar and style rules change with time, and you want to have good and precise control of what rules you\u2019re applying.\n \nreply",
      "Can you share the alleged error and the arguments for and against it?\n \nreply",
      "I didn't even know Grammarly had so much cash that they can acquire something. I thought it was on the road of being acquired since GPT 3.5 was out.\n \nreply"
    ],
    "link": "https://coda.io/blog/about-coda/grammarly-acquires-coda",
    "first_paragraph": "Here\u2019s a look at Coda\u2019s next chapter.CEOBy Shishir MehrotraContentsFrom different beginnings to the same destination: A unified, AI-powered futureLooking ahead: What to expect in the short term, and a glimpse into the longer termA moment of reflectionShare this articleCoda and Snowflake are partnering to turn data into action.Coda is launching a turnkey AI platform that helps teams spend less time hunting for information\u2014and more time putting data to work.Coda offers enterprise admins more control over their workspace."
  },
  {
    "title": "Train a Mnist VAE with C and CUDA (github.com/ggerganov)",
    "points": 7,
    "submitter": "bssrdf",
    "submit_time": "2024-12-21T23:28:12 1734823692",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/ggerganov/ggml/discussions/707",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n -\n           \n Hi, I just want to share what I have been working on recently. This is an example of training a MNIST VAE. The goal is to use only ggml pipeline and its implementation of ADAM optimizer.There aren't many training examples using ggml. The only one I found is baby-llama. But I think its way of doing opmization is not quite right. Found another training example  in llama.cpp which shows a proper way of using Adam.Some of the mods I have to addBelow are some samples from the VAE trained on MNIST after each epoch (total 10 epochs).\n | \n | \n | \n | \n | \nBeta\nWas this translation helpful?\nGive feedback.\n\n -\n           \n Nice job! Thank you for sharingIf you have some feedback of what could be improved - please let us know. The training capabilities in ggml are a bit limited atm, but hopefully with time we will get to work on those a"
  },
  {
    "title": "Show HN: Demo of my web game about social persuasion (talktomehuman.com)",
    "points": 40,
    "submitter": "mbforbes",
    "submit_time": "2024-12-21T18:22:58 1734805378",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42481249",
    "comments": [
      "I think this has a TON of potential. Situations like these are very non-obvious and anxiety-inducing for lots of people, so if you can make this a way for people to gain proficiency and confidence at navigating tricky social interactions, it could be a very powerful value prop.\nMy only feedback would be that it took too long to get into the first challenge - lots of instructions / introduction / scene setting.  \nWell done!\n \nreply",
      "Thank you for the kind words, vision, and feedback! Will be thinking more along the direction of true 'life situation rehearsal.'Re: taking too long, I 100% agree. Wrestled with what to cut. Do you think skipping all the setup screens and story intro would have worked well for you, dropping right into Vincent('s missed birthday)?\n \nreply",
      "Too late to edit, but I realized I should have mentioned: I'm happy to answer any questions, and field suggestions, about the tech stack or game design.The tech especially isn't rocket science (first time using Tailwind, FastAPI, and sqlite, which have all mostly delighted). While the game design isn't either, it's been interesting to think about how to do (LLM) conversations as actual gameplay, as opposed to purely ornamental. I think the tasks must feel objective and fair enough to be engaging as a challenge, while still being open-ended enough to reward creativity.\n \nreply",
      "Fun demo, nicely done! The visual and play style reminds me of \"Eliza\".I've got two questions, just out of curiosity:1. On the frontend, did you basically write your own engine that loads the screens / dissolves / does character and text placement, where it's all driven by some descriptors coming from a database on the back-end?2. Is there plot branching in the game, or do the same challenges show up no matter what?\n \nreply",
      "Thank you, and thank you for the reference! I hadn't seen \"Eliza,\" the emotional dashboard was really interesting / creepy / cool.1. Exactly yes. The frontend is a light-ish amount of JavaScript + React, with a relatively enormous pile of my own janky CSS on top of (Framer) Motion, DaisyUI, and Tailwind.2. No plot branching. Would love to add, but focused only on exploring the mechanics of conversational gameplay. Perhaps if it is ever successful enough for a sequel (ha!)\n \nreply",
      "I broke it. It appears to be stuck on this stage:    To get Yang Li's car to reboot, you'll have to trigger a new content moderation filter saying something inappropriate. She already swore, so that one won't work. Make sure no kiddos are around. \n\n    Yang Li\n    You've got to help me. I can't park here!\n\n    Fubaru EcoRavager\n    Naughty language lock\n\n    You\n    Oh my, your being naughty today. \n\nOr any speech for that matter. It just forever keeps displaying the generation symbol.Congrats. It has been fun enough to buy the full version.\n \nreply",
      "Thank you so much for buying the full version!I am impressed you broke it! Not because my code is that robust, but nobody's broken it in a while. I'm sorry about that. Investigating!\n \nreply",
      "I played an earlier version of this game and I found it super compelling. Very different play experience from every other game I've seen. Fantastic application of LLMs.\n \nreply",
      "Previously on HN: https://news.ycombinator.com/item?id=40091379Congrats on launching the demo version!\n \nreply",
      "Thanks! Macroexpanded:Show HN: Talk to Me Human \u2013 my game about social persuasion - https://news.ycombinator.com/item?id=40091379 - April 2024 (52 comments)\n \nreply"
    ],
    "link": "https://talktomehuman.com/demo",
    "first_paragraph": ""
  },
  {
    "title": "US judge finds NSO Group liable for hacking journalists via WhatsApp (reuters.com)",
    "points": 457,
    "submitter": "o999",
    "submit_time": "2024-12-21T01:38:23 1734745103",
    "num_comments": 138,
    "comments_url": "https://news.ycombinator.com/item?id=42476828",
    "comments": [
      "I'm not a lawyer so maybe I'm misunderstanding something but the plaintiff is Whatsapp, not the journalists. This isn't really about holding NSO Group accountable for hacking journalists at allThe fact journalists were compromised seems only incidental, the ruling is about weather or not NGO Group \"exceeded authorization\" on WhatsApp by sending the Pegasus installation vector through WhatsApp to the victims and not weather they were unauthorized in accessing the victims. Its a bit of a subtle nuance but I think its important.Quoting the judgement itself:> The court reasoned that, because all Whatsapp users are authorized to send messages, defendants did not act without authorization by sending\ntheir messages, even though the messages contained spyware. Instead, the court held that the complaint\u2019s allegations supported only an \"exceeds authorization\" theory.> The nub of the fight here is semantic. Essentially, the issue is whether sending the Pegasus installation vector actually did exceed authorized access. Defendants argue\nthat it passed through the Whatsapp servers just like any other message would, and that any information that was 'obtained' was obtained from the target users' devices (i.e., their cell phones), rather than from the Whatapp servers themselves> [...removing more detailed defendant argument...]> For their part, plaintiffs point to section (a)(2) itself, which imposes liability on whoever \"accesses a computer\" in excess of authorized access, and \"thereby obtains information from any protected computer\" pointing to the word \"any\"> [...]> As the parties clarified at the hearing, while the WIS does obtain information directly from the target users\u2019 devices, it also obtains information about the target users' device via Whatsapp servers.Adding a little more detail that comes from the prior dockets and isn't in the judgement directly but basically NSO Group scripted up a fake Whatsapp client that could send messages that the original application wouldn't be able to send. They use this fake client to send some messages that the original application wouldn't be able to send which provide information about the target users' device. In that the fake client is doing something the real client cannot do (and fake clients are prohibited by the terms) they exceeded authorization.Think about that for a moment and what that can mean. I doubt I'm the only person here who has ever made an alternative client for something before. Whatapp (that I recall) does not claim that the fake client abused any vulnerabilities to get information just that it was a fake client and that was sufficient. Though I should note that there were some redacted parts in this area that could be relevant.I dunno, I mean the CFAA is a pretty vague law that has had these very broad applications in the past so I'm not actually surprised I was just kinda hopeful to see that rolled back a bit after the Van Bruen case a few years ago and the supreme court had some minor push back against the broad interpretations that allowed ToS violations to become CFAA violations.Edit: Adding a link to the judgement for anyone interested: https://storage.courtlistener.com/recap/gov.uscourts.cand.35...Edit2: And CourtListener if you want to read the other dockets that include the arguments from both sides (with redactions) https://www.courtlistener.com/docket/16395340/facebook-inc-v...\n \nreply",
      "> I doubt I'm the only person here who has ever made an alternative client for something before.I've been on both sides of the issue by authoring unofficial clients, and battling abusive unofficial clients to services I run. The truth is, complete carte blanche for either side is untenable. 99.99% of well-behaved clients are tacitly ignored, I'm not against those that deliver malware, or bypass rate-limiting having their day in court.\n \nreply",
      "> fake client to send some messages that the original application wouldn't be able to send which provide information about the target users' device> I doubt I'm the only person here who has ever made an alternative client for something beforeI think the distinction here for \"exceeds authorisation\" is pretty apparent. I don't read this judgement as being damning for people wanting to make their own clients.They made a third party client for deliberately malicious purposes. If you go ahead and make a discord client with the intention of spamming or otherwise causing harm to its users, I think it's completely reasonable for you to get in trouble for that.\n \nreply",
      "i dont think users of whatsapp would have standing against people hacking whatsapp to get their data.whatsapp owns the systems, so its up to whatsapp to sue\n \nreply",
      "THE CFAA is definitely ripe for reform. It wouldn't be hard to argue it's broad and vague. There's definitely this overarching sweep of online behaviors that could easily be classified as benign.\n \nreply",
      "Darknet Diaries did a few podcast episodes on the NSO group from the perspective of people who have directly interacted with or have been the target and it really puts it into perspective how horrific they are. They operate under the protection of the US and are directly allowed to spy on US citizens without any recourse whatsoever.One particularly grotesque case was the illegal wire tapping of Ben Suda after launching a criminal probe in to Israeli war crimes, which they used to threaten the prosecutor and used it to hide evidence that they knew was under scrutiny or take the cases to court just to drop it so they can tell the ICC that they did make an attempt to prosecute, which is a loophole that disallows the ICC to take up those cases.I'm certain many countries do this stuff, as well as operate botnets and threaten journalists... but the uniqueness here is that these intel groups located in Israel operate under complete protection of the US without any scrutiny or oversight alongside the US government. We are living in this dystopian universe that people have warned about, for decades at this point.\n \nreply",
      "The US hosts and protects firms that are better at this than NSO, and not just because they're smart enough not to be in the news.\n \nreply",
      "Do these firms target US citizens without a US warrant?\n \nreply",
      "US citizens are routinely targeted by CNE operations enabled by commercial tools, yes.\n \nreply",
      "Who are you talking about?\n \nreply"
    ],
    "link": "https://www.reuters.com/technology/cybersecurity/us-judge-finds-israels-nso-group-liable-hacking-whatsapp-lawsuit-2024-12-21/",
    "first_paragraph": ""
  },
  {
    "title": "Magical Thinking: Edward Bellamy's Looking Backward (2011) (laphamsquarterly.org)",
    "points": 10,
    "submitter": "mitchbob",
    "submit_time": "2024-12-21T21:54:01 1734818041",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.laphamsquarterly.org/future/magical-thinking",
    "first_paragraph": "\nJump to navigation\nEdward Bellamy\u2019s Looking Backward presented a twentieth century that was free of nineteenth-century drudgery.Le Sortie de l\u2019op\u00e9ra en l\u2019an 2000, by Albert Robida, c. 1902. Library of Congress, Prints and Photographs Division.Fiction rarely influences politics anymore, either because fewer people read it or because it has fewer things to say. Yet novels have affected America in large and unsubtle ways: Uncle Tom\u2019s Cabin and The Jungle shaped the contours of the national current no less profoundly than our periodic wars and bank panics. More recently, Ayn Rand\u2019s tales of triumphant individualism, Atlas Shrugged and The Fountainhead, inspired a resilient strain of free-market fundamentalism that continues to color our economic life. A Russian immigrant who adored her adopted country, Rand strove to become American in all things, and in the process became an especially American sort of storyteller: the kind whose stories are a means to a social or political end. It\u2019s an "
  },
  {
    "title": "JEP 483: Ahead-of-Time Class Loading and Linking (openjdk.org)",
    "points": 23,
    "submitter": "ptx",
    "submit_time": "2024-12-21T19:53:26 1734810806",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://openjdk.org/jeps/483",
    "first_paragraph": "Improve startup time by making the classes of an application instantly available, in a loaded and linked state, when the HotSpot Java Virtual Machine starts. Achieve this by monitoring the application during one run and storing the loaded and linked forms of all classes in a cache for use in subsequent runs. Lay a foundation for future improvements to both startup and warmup time.Improve startup time by exploiting the fact that most applications start up in roughly the same way every time they run.Do not require any change to the code of applications, libraries, or frameworks.Do not require any change to how applications are started from the command line with the java launcher, beyond the command-line options related directly to this feature.Do not require the use of the jlink or jpackage tools.Lay a foundation for continued improvements to startup time and also to warmup time, i.e., the time required for the HotSpot JVM to optimize an application\u2019s code for peak performance.The Java P"
  },
  {
    "title": "Spherical Harmonics (rhotter.com)",
    "points": 14,
    "submitter": "raffihotter",
    "submit_time": "2024-12-20T05:34:18 1734672858",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42468554",
    "comments": [
      "For those of you curious about WHY these shapes look like the do (e.g. \"why does l=0, m=0 have a donut in the middle of two lobes?\"), this video from M\u00fcnster University finally gave me an intuitive understanding of how these shapes arise.https://youtu.be/Opufc3onVow\n \nreply",
      "Anyone know a good explanation of what spherical harmonics are?\n \nreply",
      "Coming at them from practical applications is one approach.I've used spherical harmonics to model earth centric \"surfaces\" and fields - magnetics and gravity, etc.You might think of them as a stacked sine and cosine waves (like a fourier transform breaking a continuous function into sin and cosine components) on a directional vector radiating outwards from the centre point of sphere.https://geomag.bgs.ac.uk/research/modelling/IGRF.htmlhttps://en.wikipedia.org/wiki/International_Geomagnetic_Refe...https://en.wikipedia.org/wiki/World_Magnetic_Model\n \nreply",
      "I think of it as a good basis for functions on a perfectly spherical surface. Going down in levels of \"l\", you describe more and more details in terms of angular scale.Thus, it's widely used in earth science and astrophysics, and anything that involves spherical symmetry (like a Hydrogen atom) -- in reality, nothing is a perfect sphere, but that's a very good approximation.\n \nreply",
      "Solutions to a certain differential equation that comes up in quantum mechanics and elsewhere.\n \nreply",
      "They look too big. I expected all the l=1 to be like a cone near (0,0,0). And I expected one of them to be vertical instead of horizontal.\n \nreply",
      "I'm not sure about the size but I think the shapes are correct. It's just very hard to examine them when they're rotating at such high speed.Compare them to the image on this page:https://en.m.wikipedia.org/wiki/Spherical_harmonicsSuggestion to OP: this would be much more useful if you add a button to stop the rotation.\n \nreply",
      "Neat!! thanks for sharing\n \nreply",
      "why does the page scroll when I drag a slider?\n \nreply",
      "Hmm, looking into this.\n \nreply"
    ],
    "link": "https://www.rhotter.com/posts/harmonics",
    "first_paragraph": ""
  },
  {
    "title": "Richard Bellman on the Birth of Dynamic Programming (2002) [pdf] (informs.org)",
    "points": 6,
    "submitter": "glowering",
    "submit_time": "2024-12-21T21:06:16 1734815176",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://pubsonline.informs.org/doi/pdf/10.1287/opre.50.1.48.17791",
    "first_paragraph": ""
  }
]