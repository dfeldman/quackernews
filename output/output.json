[
  {
    "title": "OpenAI are quietly adopting skills, now available in ChatGPT and Codex CLI (simonwillison.net)",
    "points": 86,
    "submitter": "simonw",
    "submit_time": "2025-12-12T23:30:19 1765582219",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=46250332",
    "comments": [
      "It\u2019s impressive how every iteration tries to get further from pretending actual AGI would be anywhere close when we are basically writing library functions with the worst DSL known to man, markdown-with-english.reply",
      "Literally yesterday we had a post about GPT-5.2, which jumped 30% on ARC-AGI 2, 100% on AIME without tools, and a bunch of other impressive stats. A layman's (mine) reading of those numbers feels like the models continue to improve as fast as they always have. Then today we have people saying every iteration is further from AGI. It really perplexes me is how split-brain HN is on this topic.reply",
      "One classic problem in all ML is ensuring the benchmark is representative and that the algorithm isn\u2019t overfitting the benchmark.This remains an open problem for LLMs - we don\u2019t have true AGI benchmarks and the LLMs are frequently learning the benchmark problems without actually necessarily getting that much better in real world. Gemini 3 has been hailed precisely because it\u2019s delivered huge gains across the board that aren\u2019t overfitting to benchmarks.reply",
      "I think really more than anything it\u2019s become clear that AGI is an illusion. There\u2019s nothing there.  It\u2019s the mirage in the desert, you keep waking towards it but it\u2019s always out of reach and unclear if it even exists.So companies are really trying to deliver value.  This is the right pivot.  If you gave me an AGI with a 100 IQ, that seems pretty much worthless in today\u2019s world.  But domain expertise - that I\u2019ll take.reply",
      "This might be actually be better in a certain way: if you change a real customer-facing API then customers will complain when you break their code. An LLM will likely adapt. So the interface is more flexible.But perhaps an LLM could write an adapter that gets cached until something changes?reply",
      "Yes. Prompt engineering is like a shittier verson of writing a VBA app inside Excel or Access.Bloat has a new name and its AI integration. You thought Chrome using GB per tab was bad, wait until you need a whole datacenter to use your coding environment.reply",
      "> Prompt engineering is like a shittier verson of writing a VBA app inside Excel or Access.Sure, if you could use VBA to read a patient's current complaint, vitals, and medical history, look up all the relevant research on Google Scholar, and then output a recommended course of treatment.reply",
      "The difference between prompting a coding agent and VBA is that with VBA you have to write and test and iterate on the code yourself.reply",
      "Gemini seems to be firmly in the lead now. OpenAI doesn't seem to have the SoTA. This should have bearing on whether or not LLMs have peaked yet.reply",
      "I had a bunch of fun writing about this one, mainly because it was a great excuse to highlight the excellent news about K\u0101k\u0101p\u014d breeding season this year.(I'm not just about pelicans.)reply"
    ],
    "link": "https://simonwillison.net/2025/Dec/12/openai-skills/",
    "first_paragraph": "12th December 2025One of the things that most excited me about Anthropic\u2019s new Skills mechanism back in October is how easy it looked for other platforms to implement. A skill is just a folder with a Markdown file and some optional extra resources and scripts, so any LLM tool with the ability to navigate and read from a filesystem should be capable of using them. It turns out OpenAI are doing exactly that, with skills support quietly showing up in both their Codex CLI tool and now also in ChatGPT itself.I learned about this from Elias Judin this morning. It turns out the Code Interpreter feature of ChatGPT now has a new /home/oai/skills folder which you can access simply by prompting:Create a zip file of /home/oai/skillsI tried that myself and got back this zip file. Here\u2019s a UI for exploring its content (more about that tool).So far they cover spreadsheets, docx and PDFs. Interestingly their chosen approach for PDFs and documents is to convert them to rendered per-page PNGs and then p"
  },
  {
    "title": "macOS 26.2 enables fast AI clusters with RDMA over Thunderbolt (developer.apple.com)",
    "points": 264,
    "submitter": "guiand",
    "submit_time": "2025-12-12T20:41:38 1765572098",
    "num_comments": 134,
    "comments_url": "https://news.ycombinator.com/item?id=46248644",
    "comments": [
      "I follow the MLX team on Twitter and they sometimes post about using MLX on two or more joined together Macs to run models that need more than 512GB of RAM.A couple of examples:Kimi K2 Thinking (1 trillion parameters): https://x.com/awnihannun/status/1986601104130646266DeepSeek R1 (671B): https://x.com/awnihannun/status/1881915166922863045 - that one came with setup instructions in a Gist: https://gist.github.com/awni/ec071fd27940698edd14a4191855bba...reply",
      "For a bit more context, those posts are using pipeline parallelism. For N machines put the first L/N layers on machine 1, next L/N layers on machine 2, etc. With pipeline parallelism you don't get a speedup over one machine - it just buys you the ability to use larger models than you can fit on a single machine.The release in Tahoe 26.2 will enable us to do fast tensor parallelism in MLX. Each layer of the model is sharded across all machines. With this type of parallelism you can get close to N-times faster for N machines. The main challenge is latency since you have to do much more frequent communication.reply",
      "What's the network topology for RDMA over TB5? Trying to figure out how they'd support more than 2 macs.This is nice. But if you can keep it on GPU, do absolutely everything you can to do that. For example the 32G VRAM RTX 5090's internal on card memory bandwidth equates to over 14 terabits per second. So for whatever you're doing:First prize by far is on GPU. 14 Tbps.\nSecond prize is Infiniband NDR at 400 Gbps. \nThird prize is multi GPU on board where the PCIe bus is the limiter at 248 Gbps. (Fast Ram is 1.1 Tbps so not a limiting factor)So 80 Gbps isn't great, but it's fine for tinkering.Infiniband NDR is 400 Gbps direct RDMA into GPU memory with 1 to 2 microseconds latency. You begin to understand that Nvidia's real strength is being a networking company that has fast GPUs. You can move data that a cuda kernel on one machine is working on to a kernel on a totally different machine without doing a device to host transfer. You're transferring from device to device at 400 Gbps with 1ns latency.Yeah I know this is not the same market, but it's fun to contemplate.reply",
      "> The main challenge is latency since you have to do much more frequent communication.Earlier this year I experimented with building a cluster to do tensor parallelism across large cache CPUs (AMD EPYC 7773X have 768mb of L3). My thought was to keep an entire model in SRAM and take advantage of the crazy memory bandwidth between CPU cores and their cache, and use Infiniband between nodes for the scatter/gather operations.Turns out the sum of intra-core latency and PCIe latency absolutely dominate. The Infiniband fabric is damn fast once you get data to it, but getting it there quickly is a struggle. CXL would help but I didn't have the budget for newer hardware. Perhaps modern Apple hardware is better for this than x86 stuff.reply",
      "But that's only for prefilling right? Or is it beneficial for decoding too (I guess you can do KV lookup on shards, not sure how much speed-up that will be though).reply",
      "No you use tensor parallelism in both cases.The way it typically works in an attention block is: smaller portions of the Q, K and V linear layers are assigned to each node and are processed independently. Attention, rope norm etc is run on the node-specific output of that. Then, when the output linear layer is applied an \"all reduce\" is computed which combines the output of all the nodes.EDIT: just realized it wasn't clear -- this means that each node ends up holding a portion of the KV cache specific to its KV tensor shards. This can change based on the specific style of attention (e.g., in GQA where there are fewer KV heads than ranks you end up having to do some replication etc)reply",
      "I usually call it \"head parallelism\" (which is a type of tensor parallelism, but paralllelize for small clusters, and specific to attention). That is what you described: sharding input tensor by number of heads and send to respective Q, K, V shard. They can do Q / K / V projection, rope, qk norm whatever and attention all inside that particular shard. The out projection will be done in that shard too but then need to all reduce sum amongst shard to get the final out projection broadcasted to every participating shard, then carry on to do whatever else themselves.I am asking, however, is whether that will speed up decoding as linearly as it would for prefilling.reply",
      "Right, my comment was mostly about decoding speed. For prefill you can get a speed up but there you are less latency bound.In our benchmarks with MLX / mlx-lm it's as much as 3.5x for token generation (decoding) at batch size 1 over 4 machines. In that case you are memory bandwidth bound so sharding the model and KV cache 4-ways means each machine only needs to access 1/4th as much memory.reply",
      "Oh! That's great to hear. Congrats! Now, I want to get the all-to-all primitives ready in s4nnc...reply",
      "Even if it wasn't outright beneficial for decoding by itself, it would still allow you to connect a second machine running a smaller, more heavily quantized version of the model for speculative decoding which can net you >4x without quality lossreply"
    ],
    "link": "https://developer.apple.com/documentation/macos-release-notes/macos-26_2-release-notes#RDMA-over-Thunderbolt",
    "first_paragraph": "Please turn on JavaScript in your browser and refresh the page to view its content."
  },
  {
    "title": "GNU Unifont (unifoundry.com)",
    "points": 150,
    "submitter": "remywang",
    "submit_time": "2025-12-12T20:57:34 1765573054",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=46248859",
    "comments": [
      "We use GNU Unifont in Solvespace for the text window/property browser. It's built right into the executable. This turned out to be amazingly useful. Some people have CJK stuff in their designs and it \"just works\" on all platforms. I was also looking into hole annotations in CAD and was pleased to see the symbols for counter-bore and counter-sink are both already there in unifont.You can see unifont in the experimental web version here: https://cad.apps.dgramop.xyz/reply",
      "Wow, the web version is neat in its simplicity! Thank you for the work on Solvespace. It's far and away my favorite MCAD program and always my first go-to when I need to crank out a quick fixture to test PCBs. It's really so pleasant and easy to work with as long as my geometry is relatively basic (which it almost always is given my limited scope of work with mechanical design). I'm sorry I don't have any comments on the relevant topic of the fonts, just was excited to see Solvespace mentioned.reply",
      "+1; thanks from another satisfied user. I have an annual SOLIDWORKS plan, but SolveSpace is my go-to for quick stuff. It makes CAD fun. There is a clarity of design behind the software that gives it a zen-like feel.reply",
      "That's such a cool effect from just the choice of font. (Though I guess there are countless human hours spent on unifont and unicode as a whole)But I love the idea that even if your bronze age CAD guy wrote all the solid names in Linear A, no problem!reply",
      "Why does every GNU web page look like 1996? This actually matters. Even stripping the page down and removing any styling would make it look more trustworthy less like an abandoned project.Perhaps a GNU style could be something we could help fund?reply",
      "Shouldn't the first sentence on that website describe what GNU Unifont actually is?  I guess it's a single copyleft font designed to have coverage of all (or nearly all?) unicode code points?reply",
      "Well, the second and the third sentence describe very precisely what Unifont is:\"This page contains the latest release of GNU Unifont, with glyphs for every printable code point in the Unicode Basic Multilingual Plane (BMP). The BMP occupies the first 65,536 code points of the Unicode space, denoted as U+0000..U+FFFF.\"This is suitable as a last resort font, which should display any character for which no match was found in the other available fonts.This is normally preferable to a last resort font that just displays the number of a character not available in your preferred fonts.reply",
      "No mention there of the fact that this is a bitmap font. I think that's kind of important.reply",
      "Indeed. Plus basic facts like: is it serif or sans? Proportional or monospace? Designed for GUI interfaces, terminals, or print? I still don't know.Just showing a single screenshot of it in its intended use would go a long way.I clicked on one of the charts and had no idea if the font itself was bitmap, or if it had just been rendered at a tiny size without antialiasing.reply",
      "Note that \"nearly all\" isn't \"all\". I have some side project that require rendering of very uncommon CJK characters, and Unifont does not display them as expected. (For that project, I used https://kamichikoichi.github.io/jigmo/ which was the font that was most complete in terms of CJK glyphs )Unifont seems to have about the same glyph coverage as my system default CJK font (unfortunately I don't know what it is).reply"
    ],
    "link": "https://unifoundry.com/unifont/index.html",
    "first_paragraph": "\n      GNU Unifont is part of the GNU Project.\n      This page contains the latest release of\n      GNU Unifont, with glyphs for every printable code point\n      in the Unicode Basic Multilingual Plane (BMP).\n      The BMP occupies the first 65,536 code points of the Unicode space,\n      denoted as U+0000..U+FFFF. There is also growing coverage of the\n      Supplementary Multilingual Plane (SMP), in the range U+010000..U+01FFFF,\n      and of Michael Everson's ConScript Unicode Registry (CSUR) with\n      Rebecca Bettencourt's Under-CSUR additions.\n    \n      A user has asked if GNU Unifont can be used with commercial\n      (non-free) software.  The answer is yes.  The GNU Font Embedding\n      Exception and the SIL OFL allow for that.  See the next section\n      for details.  The main purpose of the licensing is to require\n      derivative fonts that others create to be released to the public\n      under the same licensing terms, not to prohibit the use of those\n      fonts with certain "
  },
  {
    "title": "Rats Play DOOM (ratsplaydoom.com)",
    "points": 173,
    "submitter": "ano-ther",
    "submit_time": "2025-12-12T20:15:58 1765570558",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=46248323",
    "comments": [
      "The year is 2034. Countless attempts at re-producing the sophisticated wetware of the brain have failed. Modeling research has proved unfruitful, with the curse of dimensionality afflicting every attempt at breaking the walls of general intelligence. With only a few million of capital left, and facing bankruptcy, they knew that only one option remained.\"Bring me the rats.\"reply",
      "Douglas Adams would point out that this is just why the rats already trained us to play DOOM.reply",
      "The mice, actually; the rats are never mentioned.reply",
      "finally somebody gets it.reply",
      "As an evolutionary cousin of a rat, the half-second delay after firing my weapon and the response would make me want to eat my whiskers.This would completely kill any potential reward (and replace it with the opposite, frustration) you're trying to train me with, please fix immediately.reply",
      "One of the most important traits of intelligence is understanding and appreciating delayed reward.I saw a gambler win the jackpot. He was really excited and started gathering up all the chips he'd won. Why he was so excited to win a bunch of plastic chips, I'll never know. What's so great about plastic chips? Why was his brain so excited when all he was doing was gathering plastic chips? ...A half-second delay doesn't mean your brain can't learn to make the precursor feel good.reply",
      "Lol you are correct! At least training them becomes smoother the faster you administer reward. Learning happens at different timescales in the brain, and immediate feedback (about <300 ms) yields the most reliable neural updates.reply",
      "I absolutely love this!# Suggestion:You really should release parts as parametric or at least the source files. I see everything is an STL and STLs are just a pain to work with. Suppose we want to try with mice? Or what about my cat? I do not expect just scaling in my slicer is going to end up with a good result, I'll need to redo everything from scratch. But parametric parts? That gives us a lot faster iteration. That gives you a lot faster iteration too! I highly recommend taking that approach when designing and I find it is worth it more often than not.Could you add cost estimates to the BOM? These never need to be accurate but I always find it helpful when estimating a project. You're just saving people from the time it takes to click every single link and throw them into a calculator. And informs people very quickly what to innovate on to drive costs down. (Sorry, BOMs without cost estimates are a big pet peeve of mine)# Questions:- Do the rats enjoy playing Doom?- Are there specific games the rats like to play?I've never thought about what types of videogames other animals would enjoy, but damn if you didn't just open Pandora's Box here. I actually think we could learn a lot about them (and even their specific personalities) from this question. It gives a whole other level of refinement than just knowing what my cat's favorite toys and games are...And also, thanks for open sourcing this! I'm excited to see what comes of it!reply",
      "Gonna be honest here, I've worked on this for so long, so many iterations, lots of versions for each 3D part, software and all, at this point I just wanted to publish everything I had and do it fast. And you are totally right, publishing without parametric source files was a mistake, I'll upload everything I have shortly, prices included. Note: mice require smaller setups and that just leads to the redesign of most parts - smaller ball, ball driver, lever with weaker springs... training cats prompts for a larger ball, same issue. VR setups for cats though would be super cool!On this setup my rats were only habituated, they did not end up playing Doom. Even habituation seamed super slow, they were a year old when I started it. On the previous setup though, when they learnt to run on the ball and how that influences their reward, they got hooked. I believe they enjoy not just the reward, they get a sense of how their actions influence the game and they like that. They would run on the ball so much at some point they wouldn't even bother drinking all the juice and it was just dripping on the setup.No idea what they would best like to play. It needs to be a first person game though, that's what they are able to understand how to handle, it's more natural to them.Thank you for taking the time to give feedback! I also hope pet VRs become a thing and people can connect with their pets virtually too!reply",
      "Oh, I hope you don't take this as me being upset. I'm super happy and totally get the motivation. I a fan of the adage \"better to do something half assed than no assed\" (not that this is half-assed). Just wanted to make the comment to help drive motivation and let you know there's a demand. Releasing the sources could really help too just so people don't have to work with the mesh.But on the rat part, that is super interesting! I was suspecting they might not like Doom because shooting a gun might be such a foreign concept to them that it breaks immersion. But it seems like you say they like running around in the simulated environment? (Time for Cheeze-Doom? lol)Again, super cool and thank for releasing things! This is that crazy stuff I just love to see people exploring.reply"
    ],
    "link": "https://ratsplaydoom.com/",
    "first_paragraph": "We built a complete VR setup from scratch to let rats play DOOM. The system includes a motion-tracked treadmill ball, a panoramic headset, an input trigger, and a reward circuit. All hardware and software components are open sourced, including 3D-printable designs, circuit diagrams, firmware, and control software.The first version (v1) was built in New York by Viktor, who trained rats to walk through a corridor in DOOM using a simpler rig. That version was featured on Vice and PC Gamer. After moving back home, the project was paused. Public interest reignited development, leading to v2, a more advanced and modular version built in collaboration with electrical engineer S\u00e1ndor Makra. Akos Blaschek later assisted significantly in documenting the project for open-sourcing, aiming to enable others to replicate and build upon this work. Key metallic components were designed and sourced in collaboration with SZURWIN KFT.We reached the point of rat habituation but didn\u2019t start training. Our r"
  },
  {
    "title": "Show HN: I made a spreadsheet where formulas also update backwards (victorpoughon.github.io)",
    "points": 54,
    "submitter": "fouronnes3",
    "submit_time": "2025-12-11T18:00:55 1765476055",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46234734",
    "comments": [
      "In Excel you have goal seek for this functionality. I believe it does some form of numerical solving of the equation system.Good for every situation when you need to solve equations!In the context of using spreadsheets I think about solving simple financial or maybe  construction/mechanical design problems where you don\u2019t want to solve it manually or program it and a spreadsheet is a quick and useful interface.reply",
      "The first example on the main page has a formula with two variables being updated from changing one value.  The immediate question I have is if I change the output, where does the extra degree of freedom come from on the inputs?  Does one stay locked in place?  Unclear.I am a huge fan of the concept though.  It's been bugging me for years that my spreadsheet doesn't allow editing text fields after filtering and sorting them down to the subset I want.  I have to go all the way back to the mess of unsorted  input rows to actually edit them.reply",
      "This is really cool! It's like Excel's goal seek but can also handle the case of arbitrary input cells. Goal seeek can only handle one input and one output cell.But how do you handle the case where multiple variables can be changed? If multiple input cells is the key difference from Goal seek, i think some more rigor should be placed into the algorithm heree.g. setting A1 + B1 and wanting the result to be 5. Currently it bumps both A1 and B1 equally. What's the thought process behind this?reply",
      "Yeah. The UI could have a lock icon to set, eg B1 should stay fixed and then only A1 would change.reply",
      "It supports this. If you type # before a number, like #5, it's made constant.reply",
      "A bidirectional formula is also known as an integrity constraint in databases (plus some triggers for restoring the constraint upon updates)!reply",
      "Wow!  See the classic https://en.wikipedia.org/wiki/TK_Solverreply",
      "Hm? I don't get it.What's the point of calculating backwards non-invertible operations such as addition? Isn't the result just arbitrary?reply",
      "They said this:> Even a normal spreadsheet is fairly complex beast. But the novel thing about bidicalc is the backwards solver. Mathematically, updating a spreadsheet \"backward\" is a (potentially underdetermined) root finding problem, because we are trying to find a vector of unknowns  such that , where F is the function computed by the cells formulas, and G is the objective value entered in the cell. Note that F is not necessarily a single formula, but the result of composing an upstream graph of cells into a single function.> The actual root-finding solver is a custom algorithm that I made. It a general purpose algorithm that will find one root of any continuous-almost-everywhere function for which a complete syntactic expression is known. It uses a mix of continuous constraint propagation on interval union arithmetic , directional Newton's method and dichotomic search. It is of course limited by floating point precision and available computation time.But that really doesn't answer your question. I see no reason why the solver wouldn't decide every time it had a two-variable summation that ADD(X+Y) doesn't reverse to X=-90 and Y=100.reply",
      "I made this mostly as a fun challenge :)You are right that there is some arbitrariness involved when picking a solution, however it's a bit more subtle than that.Let's say our problem has N free variables.Step 1 is finding the subset of R^N that is the solution to the root finding problem. If this subset is a point, we are done (return that point). Note that if there is no solution at all bidicalc should correctly report it.Step 2 is if the solution subset is not a point. Then there is multiple (maybe even an infinity of) solutions, and picking one is indeed arbitrary.reply"
    ],
    "link": "https://victorpoughon.github.io/bidicalc/",
    "first_paragraph": "In any normal spreadsheet, when you change values that are the input to some formulas, the outputs are automatically updated:Could it also work the other way? What if you could also change the output, and have the inputs be updated to match the formula?For the past few months I've been obsessed really curious about this idea. But there were so many questions:Ok, now let's just skip to the good part! Today I'm happy to introduce:Variables A simple number entered in a cell is a variable: 1.0. It may be changed by the solver.Constant A number prefixed by a hash # is a constant. It will not be changed by the solver.Text Cells can be in text mode. To input text, wrap in double quotes: \"Distance (km)\".Formula Formulas can be entered in a cell (the traditional = prefix is optional), for example:The result of formulas will be automatically updated when an input they depend on changes. This is the usual forward update.The magic of bidicalc is that once a formula has been computed, you can chang"
  },
  {
    "title": "Show HN: Tiny VM sandbox in C with apps in Rust, C and Zig (github.com/ringtailsoftware)",
    "points": 61,
    "submitter": "trj",
    "submit_time": "2025-12-12T22:02:14 1765576934",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=46249538",
    "comments": [
      "I suppose this is in the same realm as what some people are trying to do with WASM, creating a common execution environment? This is built on RISC-V instead though. I wish I knew more about the limitations/capabilities of each approach, but in any case a future where applications are built for a common VM seems like something we've been building to for a while, the modern web being the closest we've come.reply",
      "See https://opensource.googleblog.com/2025/11/secure-by-design-f...This looks like it has a smaller code footprint at least. I'm not sure RISC-V is a very good target for this sort of thing. E.g. decoding the immediates in software is going to be very slow, whereas in hardware it's fast.But on the other hand it is a stable target and can be configured to be a lot simpler than WASM.reply",
      "Thanks for the link, Wasefire looks interesting. I suspect that their design goals are very different to mine. https://github.com/ringtailsoftware/uvm32?tab=readme-ov-file...reply",
      "\"Just add rats\" https://github.com/ringtailsoftware/uvm32/tree/main/apps/zig...reply"
    ],
    "link": "https://github.com/ringtailsoftware/uvm32",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Minimalist, dependency-free virtual machine sandbox for microcontrollers and other resource-constrained devices. Single C file, no dynamic memory allocations, asynchronous design, pure C99\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.uvm32 is a minimalist, dependency-free virtual machine sandbox designed for microcontrollers and other resource-constrained devices. Single C file, no dynamic memory allocations, asynchronous design, pure C99.On an STM32L0 (ARM Cortex-M0+) the required footprint is under 4KB flash/1KB RAM.uvm32 is a RISC-V emulator, wrapped in a management interface and provided with tools to build efficient code to run in it.Although based on a fully fledged CPU emulator, uvm32 is intended for executing custom script like logic, not for simu"
  },
  {
    "title": "Capsudo: Rethinking Sudo with Object Capabilities (ariadne.space)",
    "points": 33,
    "submitter": "fanf2",
    "submit_time": "2025-12-12T21:42:04 1765575724",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=46249337",
    "comments": [
      "You don't need to elevate privileges if you give things the right privileges from the start.Sudo is just a hack to avoid setting up proper capabilities / permissions in the first place.reply",
      "I am the owner and only user of the computer. Does that mean I should run everything with root? Of course not. It\u2019s simply better to start with little privileges and then elevate when needed. Using any additional privileges should be an intentional act. I also do it the other way: reduce my privileges via sudo -u nobody.reply",
      "The root account shouldn't exist either. Having god accounts is a bad idea security wise. Instead everything should follow the principle of least privilege.reply",
      "That's functionally equivalent to using sudo but only allowing a certain shell script that's a wrapper for what needs to be done by a given user (to avoid the whole syntax mess). But somehow with more boilerplate.reply",
      "If I'm a user who's been given access to run such a wrapper script via sudo, how do I further delegate that access?reply",
      "You can probably use a copy of sudo owned by a non-root user, but I can't say I've ever tried that. You can also just write another setuid shell script.reply",
      "Every time somebody wants to do something in Linux and they mention Objects, I turn around and go the other way.These people still do not understand why that userspace became so powerful and so useful.I also think that's the \"solution\", which is to craft a new optional userspace experience that leaves traditional unix strings and pipes alone. It's not for me, but I'm sure many would like it. I mean, look at PowerShell on Linux :/reply"
    ],
    "link": "https://ariadne.space/2025/12/12/rethinking-sudo-with-object-capabilities.html",
    "first_paragraph": "Follow @ariadne on Micro.blog.I hate sudo with a passion.  It represents everything I find offensive about the modern Unix security model:I could go on, but hopefully you get the point.  Alpine moved to doas as the default privilege escalation tool several years ago, in Alpine 3.15, because of the large attack surface that sudo brings due to its design.Systems built around identity-based access control tend to rely on ambient authority: policy is centralized and errors in the policy configuration or bugs in the policy engine can allow attackers to make full use of that ambient authority.  In the case of a SUID binary like doas or sudo, that means an attacker can obtain root access in the event of a bug or misconfiguration.What if there was a better way?  Instead of thinking about privilege escalation as becoming root for a moment, what if it meant being handed a narrowly scoped capability, one with just enough authority to perform a specific action and nothing more?  Enter the object-c"
  },
  {
    "title": "Go is portable, until it isn't (simpleobservability.com)",
    "points": 18,
    "submitter": "khazit",
    "submit_time": "2025-12-07T11:17:42 1765106262",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=46180911",
    "comments": [
      "I ran into this issue when porting term.everything[0] from typescript to go. I had some c library dependencies that I did need to link, so I had to use cgo. \nMy solution was to do the build process on alpine linux[1] and use static linking[2]. This way it statically links musl libc, which is much friendlier with static linking than glibc.\nNow, I have a static binary that runs in alpine, Debian, and even bare containers.Since I have made the change, I have not had anyone open any issues saying they had problems running it on their machines. (Unlike when I was using AppImages, which caused  much more trouble than I expected)[0] https://github.com/mmulet/term.everything \nlook at distribute.sh and the makefile to see how I did it.[1]in a podman or docker container[2] -ldflags '-extldflags \"-static\"'reply",
      "Once you use CGO, portability is gone. Your binary is no longer staticly compiled.This can happen subtley without you knowing it. If you use a function in the standard library that happens to call into a CGO function, you are no longer static.This happens with things like os.UserHomeDir or some networking things like DNS lookups.You can \"force\" go to do static compiling by disabling CGO, but that means you can't use _any_ CGO. Which may not work if you require it for certain things like sqlite.reply",
      "You can definitely use CGO and still build statically, but you do need to set ldflags to include -static.reply",
      "You can even cross-compile doing that.reply",
      "Yes, indeed, I do.reply",
      "There are at least a couple of ways to run SQLite without CGO.reply",
      "I think the standard answer here is modernc.org/sqlite.reply",
      "Interesting that it uses the C API to collect journals. I would\u2019ve thought to just invoke journalctl CLI. On platforms like macOS where the CLI doesn\u2019t exist it\u2019s an error when you exec, not a build time error.reply",
      "This seems to imply that Go's binaries are otherwise compatible with multiple platforms like amd64 and arm64, other than the issue with linking dynamic libraries.I suspect that's not true either even if it might be technically possible to achieve it through some trickery (and why not risc-v, and other architectures too?).reply",
      "Of course you still need one binary per CPU architecture. But when you rely on a dynamic link, you need to build from the same architecture as the target system. At that point cross-compiling stops being reliable.reply"
    ],
    "link": "https://simpleobservability.com/blog/go-portable-until-isnt",
    "first_paragraph": "We thought Go would give us a single, portable agent binary for every Linux distro. Turns out\u2026 not exactly. But also, kind of yes.This post kicks off a series about the traps we fell into while building a cross-platform server monitoring agent.First, some theory. simob is our open source server monitoring agent that powers the Simple Observability platform. We like to think of it as a passive sensor, not a long running program or daemon. Because in the real world a passive sensor does not come with a long list of requirements. It\u2019s small, self contained and can fit inside the existing system. That is the same goal we have for simob: a lightweight standalone binary with no requisites or external dependencies.The same idea also applies to how we wanted to ship it. We wanted a project that you can compile from source on your development machine and run anywhere across your infrastructure. No complicated pipelines. No third party build services. Just a simple build that produces a portable"
  },
  {
    "title": "Ensuring a National Policy Framework for Artificial Intelligence (whitehouse.gov)",
    "points": 55,
    "submitter": "andsoitis",
    "submit_time": "2025-12-11T23:56:10 1765497370",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=46239076",
    "comments": [
      "Is it me or does this seem like naked corruption at its worst? These tech CEOs hang out at the White House and donate to superfluous causes and suddenly the executive is protecting their interests. This does nothing to protect working US citizens from AI alien (agents) coming to take their jobs and displace their incomes.reply",
      "> This does nothing to protect working US citizens from AI alien (agents) coming to take their jobs and displace their incomes.Where did you get the idea that banning new technology that could eliminate jobs is even remotely an American value?Going back to the Industrial Revolution the United States has been 100% gas pedal all the time on innovation and disruption,  which has in turn created millions of jobs that didn't exist before and led to the US running the world's largest economy.reply",
      "It\u2019s corruption out in plain sightreply",
      "That's lobbying simplified, no need to pay lobbyist.reply",
      "This is a tribute system, way past lobbying. Lobbying is cheap, Senators can be bought off for 5-figure sums. CEOs pay lobbyists so they don't have to meet with them personally. What's happening now involves CEOs appearing at political events and lobbying the president personally, to the tune of millions of dollars in declared \"donations\" for \"ballroom construction\", in exchange for security guarantees for their business empires.reply",
      "It is definitely naked corruption. Lobbying was always around, but I would say that with this administration things are a lot more transactional and a lot more in the open. Companies like Palantir and Anduril and others are being gifted contracts all over the place - that\u2019s money we taxpayers are losing.reply",
      "> protect working US citizens from AI alien (agents) coming to take their jobs and displace their incomesSo where is this coalition that\u2019s organized to actually make this real?Software engineers are allergic to unionization (despite the recent id win) and 100% of capital owners (this is NOT business owner and operators I\u2019m talking about LPs and Fund Managers) are in support of labor automation as a priority, the same people also run every government and overwhelmingly select the politicians available to vote for, so who will fund and lead your advocacy?reply",
      "Just another step towards Russian style naked oligarchy.reply",
      "You aren't missing anything. This is oligarchic capture of the government.reply",
      ">This does nothing to protect working US citizens from AI alien (agents) coming to take their jobs and displace their incomes.from what I've been observing in the past three years, the Venn diagram of pro-immigration folx and anti-AI folx is pretty much a single circle.reply"
    ],
    "link": "https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/",
    "first_paragraph": "By the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered:Section 1.\u00a0 Purpose.\u00a0 United States leadership in Artificial Intelligence (AI) will promote United States national and economic security and dominance across many domains.\u00a0 Pursuant to Executive Order 14179 of January 23, 2025 (Removing Barriers to American Leadership in Artificial Intelligence), I revoked my predecessor\u2019s attempt to paralyze this industry and directed my Administration to remove barriers to United States AI leadership.\u00a0 My Administration has already done tremendous work to advance that objective, including by updating existing Federal regulatory frameworks to remove barriers to and encourage adoption of AI applications across sectors.\u00a0 These efforts have already delivered tremendous benefits to the American people and led to trillions of dollars of investments across the country. \u00a0But we remain in the earliest days of this technological rev"
  },
  {
    "title": "Security issues with electronic invoices (secvuln.info)",
    "points": 73,
    "submitter": "todsacerdoti",
    "submit_time": "2025-12-12T20:28:41 1765571321",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=46248470",
    "comments": [
      "This talk seems set out to prove that \"XML is Bad\". Yes XML-DSig isn't great with XPaths, but most of these attack vectors has been known for 10 years. There is probably a reason why the vulnerabilities found where in software not commonly used, e.g. SAP. Many of the things possible with XML and UBL simply isn't available in protobuf, json. How would you digitally sign a Json document and embed the signature in the document?The article nor the talk appear to reference the XML standard that EN 16931 is built upon: Universal Business Language, https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=... - which is freely available. Examples can be found here: https://github.com/Tradeshift/tradeshift-ubl-examples/tree/m... . It is a good standard and yes it's complex, but it is not complicated by accident. I would any day recommend UBL over IDOC, Tradacom, EDIFACT and the likes.reply",
      "-----BEGIN PGP SIGNED MESSAGE-----Hash: SHA1> How would you digitally sign a Json document and embed the signature in the document?Embedding a signature into the same file is easy enough.-----BEGIN PGP SIGNATURE-----Version: GnuPG v0.9.7 (GNU/Linux)iEYEARECAAYFAjdYCQoACgkQJ9S6ULt1dqz6IwCfQ7wP6i/i8HhbcOSKF4ELyQB1oCoAoOuqpRqEzr4kOkQqHRLE/b8/Rw2k\n=y6kj-----END PGP SIGNATURE-----reply",
      "If one has a reproducible JSON serializer, then one can add a signature to any JSON object via serializing the object, signing that and then adding the resulting signature to the  original object.This avoids JSON-inside-JSOn and allows to pretty-print the original object with the signature.reply",
      "Other answers are good.  One more that you could do is put the JSON document inside a container (A zip archive for example).  Then your document can effectively be    invoice.inv (zip archive)\n    \u2514- payload.json\n    \u2514- signature.asc\n\nThis has the benefit of adding more opportunities for many json documents within the archive.It's effectively what the Java jar is.reply",
      "dont unzip an untrusted payloadreply",
      "Unless you are worried about something like a gzip bomb, I don't see why this is an issue.  A lot of formats are effectively just zips.  The xlsx, odf, etc for example.  It's a pretty common format style.It helps to have a well defined expected structure in the archive.reply",
      "> How would you digitally sign a Json document and embed the signature in the document?Presumably the same way you accomplish the thing in xml:    { \u201csignature\u201d: \u201c\u2026\u201d, \u201cpayload\u201d: \u2026 }reply",
      "What was unclear in that article is that the XML is usually embedded in the invoice. For instance, Factur-X is the mandatory format in Germany, and it's a PDF which contains a metadata block with a XML EN16931 content.This XML will usually not be read by the companies that pay the invoice. For instance, in France by the end of 2027, every business will have to send e-invoices, but never directly to the real recipient. The business sends the invoice to a registered go-between, which will ask a national platform for the address of the recipient's go-between, etc. So, only those official go-between companies will have to securely parse the XML.BTW, in 2022 when the French government decided to make e-invoicing mandatory, it announced that it would develop a national unique go-between platform. Two years later, it dropped that part of the project and announced that there would be an official list of private platforms. So, by the end of 2026 or 2027, every French business will have to select one of the 112 platforms and buy a subscription. It give the State more control, but for small businesses it means higher costs and complexity.reply",
      "Aside from the security issue, it seems like an awful idea for a government (or governments, in this case) to say 'hey, you need to follow this standard for invoicing. But also, you have to pay to see the entire standard'.. almost feels like extortion a bitreply",
      "The right to access standards that have been incorporated-by-reference into law is still being established by various countries' court systems.For example, in the USA https://www.rcfp.org/briefs-comments/astm-v-upcodes-inc/This is an especially hot topic in the EU in medical device regulations: https://www.bsigroup.com/en-GB/insights-and-media/insights/b...reply"
    ],
    "link": "https://invoice.secvuln.info/",
    "first_paragraph": "This page provides supplementary material for a presentation given at the German OWASP\nDay 2025\n(Presentation Slides).With the eInvoicing Directive (2014/55/EU), the European\nUnion introduced \u201cstandardized\u201d electronic invoices in XML format. Increasingly,\ninstitutions and businesses in EU member states will be required to support these\nelectronic invoices.While machine-readable invoices are, in general, a good idea, there are various issues\nwith the EU\u2019s approach, including needless complexity, a lack of true standardization\n(multiple syntaxes and various sub-formats), and a tendency to use technologies with\ninherent security problems.Due to a combination of unfortunate design decisions, implementing software for\nelectronic invoices is likely to be affected by security flaws if no countermeasures are\nimplemented.The XML format is known to have inherent security flaws, the most dangerous ones being\nXXE vulnerabilities (XML eXternal Entity injection).XXE vulnerabilities often allow the e"
  },
  {
    "title": "50 years of proof assistants (lawrencecpaulson.github.io)",
    "points": 27,
    "submitter": "baruchel",
    "submit_time": "2025-12-12T23:26:26 1765581986",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=46250309",
    "comments": [
      "> In 1994, came the Pentium with its FDIV bug: a probably insignificant but detectable error in floating-point division. The subsequent product recall cost Intel nearly half a billion dollars. John Harrison, a student of Mike\u2019s, decided to devote his PhD research to the verification of floating-point arithmetic.No mention of the effort by Boyer and Moore, then at their Computational Logic, Inc., to do a formal verification of the AMD FPU for the AMD5K86TM. The AMD chip shipped with no FDIV bug. [1][1] https://dl.acm.org/doi/abs/10.1109/12.713311reply",
      "I wish he had just said 50 years of LCF, since he even mentions automath in the article but that was but that was late 60sreply"
    ],
    "link": "https://lawrencecpaulson.github.io//2025/12/05/History_of_Proof_Assistants.html",
    "first_paragraph": "05 Dec 2025Crackpots ranging from billionaire Peter Thiel to random YouTube influencers claim that science has been stagnating for the past 50 years. They admit that computing is an exception: they don\u2019t pretend that my personal 32GB laptop is not an advance over the 16MB mainframe that served the whole Caltech community when I was there. Instead they claim that advances in computing were driven solely by industrial research, quite overlooking the role of academia \nand government funding\nin pushing the VLSI revolution, RISC processor design, networking, hypertext, virtual memory and indeed computers themselves. As for the industrial research,\nmost of it came from just two \u201cblue sky\u201d institutes \u2013 Bell Labs \nand Xerox PARC \u2013 that closed a long time ago. \nLCF-style proof assistants are a world away from mainstream computing,\nso let\u2019s look at 50 years of progress there.The first instance of LCF was Stanford LCF, developed by Robin Milner in 1972, but it was not an LCF-style proof assistant"
  },
  {
    "title": "Freeing a Xiaomi humidifier from the cloud (0l.de)",
    "points": 23,
    "submitter": "stv0g",
    "submit_time": "2025-12-12T06:17:28 1765520248",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=46241368",
    "comments": [
      "On a tangent note: don\u2019t use ultrasonic humidifiers. Unless distilled water is used, they create a shit-ton of pm2.5 particles.Use evaporative humidifiers (just disks with myriads of small notches for water to cling on and a fan): https://us.smartmiglobal.com/pages/smartmi-evaporative-humid...reply",
      "The best solution I've found a few years ago is one Venta LW 45 for every 30 m\u00b2 of space. That's enough to run them on the lowest speed while maintaining acceptable humidity and CO\u2082 levels.Higher speeds are too noisy. Smaller machines evaporate less.For sub-zero outside temperatures, it's necessary to add at least 5 g of water to each cubic metre of air coming from outside.The recommended ventilation rate of 30 m\u00b3/h per person requires to evaporate 4 liters of water per day.reply",
      "> Use evaporative humidifiersYou don't have to buy one either. A suspended wet towel with a fan blowing on it will work very well. If you want to get fancy, have the last inch or two of the towel sitting in a tray of water.reply",
      "But then I have to buy the towel and the fan, the tray, something to suspend the towel at the right height \u2026reply",
      "Alec from Technology Connections also has a great video comparing humidifiers herehttps://www.youtube.com/watch?v=oHeehYYgl28reply",
      "Distilled water isn\u2019t strictly necessary. I use mine with purified water with a reverse osmosis purifier. I periodically test the TDS of the water to confirm it is low. It\u2019s fine.reply",
      "That Smartmi model seems to have toxic IoT in it.I'm currently using the Vornado EV100 non-IoT evaporative humidifier, and my only complaints are relatively minor, as humidifiers go (consumable wick, fan noise, insanely bright blue LEDs). https://www.vornado.com/shop/humidifiers/evaporative/ev100-e...reply",
      "You don\u2019t need to connect it \u2014 works completely offline.Also no consumable parts there: just plastic disks which you clean with couple of spoons of citric acid dissolved in water from time to time.reply",
      "Couldn't you just use vinegar?reply"
    ],
    "link": "https://0l.de/blog/2025/11/xiaomi-humidifier/",
    "first_paragraph": "I recently moved into a new apartment which I used as an opportunity to make our home a little smarter.\nAs a big open source supporter I built my smart home platform with Home Assistant of course.Unfortunately, there are still far too few products that are directly compatible with Home Assistant.\nEspecially in the area of humidifiers where I only found products that rely on a proprietary app or cloud from the manufacturer.\nSomething that I would like to avoid at all costs.\nFor one thing, such dependence is a certain form of planned obsolescence, as the product becomes useless as soon as the app loses its compatibility with new smartphone operating system versions or the manufacturer\u2019s cloud is no longer operated.Therefore, it was important for me to find a smart humidifier that integrates directly with my Home Assistant setup.\nTo achieve this goal, I identified two options:I decided to use the second approach, because it required less effort, since I would have had to implement my own "
  },
  {
    "title": "SQLite JSON at full index speed using generated columns (dbpro.app)",
    "points": 309,
    "submitter": "upmostly",
    "submit_time": "2025-12-12T13:25:19 1765545919",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=46243904",
    "comments": [
      "It is also possible to encode JSON documents directly as a serialized B-tree. Then you can construct iterators on it directly, and query internal fields at indexed speeds. It is still a serialized document (possible to send over a network), though now you don't need to do any parsing, since the document itself is already indexed. It is called the Lite\u00b3 format.Disclaimer: I am working on this.https://github.com/fastserial/lite3reply",
      "This is super cool! I've always liked Rkyv (https://rkyv.org) but it requires Rust which can be a big lift for a small project. I see this supports binary data (`lite3_val_bytes`) which is great!reply",
      "Thank you. Having a native bytes type is non-negotiable for any performance intensive application that cannot afford the overhead of base64 encoding. And yes, Rkyv also implements this idea of indexing serialized data. The main differences are:1) Rkyv uses a binary tree vs Lite\u00b3 B-tree (B-trees are more cache and space efficient).2) Rkyv is immutable once serialized. Lite\u00b3 allows for arbitrary mutations on serialized data.3) Rkyv is Rust only. Lite\u00b3 is a 9.3 kB C library free of dependencies.4) Rkyv as a custom binary format is not directly compatible with other formats. Lite\u00b3 can be directly converted to/from JSON.I have not benchmarked Lite\u00b3 against Rust libraries, though it would be an interesting experiment.reply",
      "That second point is huge \u2013 Rkyv does have limited support for in-place mutation, but it is quite limited!If you added support for running jq natively, that would be very cool. Lite\u00b3 brings the B-trees, jq brings the query parser and bytecode, combined, you get SQLite :Preply",
      "Yes, in fact the name Lite\u00b3 was chosen because it is lighter than SQLite.I thought about implementing something like jq or JSON query, and this is very possible. It is like sending a mini-database that can be queried at speeds thousands of times faster than any JSON library is able to parse.One interesting effect of being a zero-copy format is that the 'parsing speed' can exceed the memory bandwidth of the CPU, since to fulfill a query you do not actually need to parse the entire dataset. You only walk the branches of the tree that are actually required.I've talked to some other people that have also shown interest in this idea. There doesn't really seem to exist a good schemaless single-file format that supports advanced queries. There is only SQLite and maybe HDF5.reply",
      "Would love a Rust implementation of this.reply",
      "I love SQLite and this is in no way I'm making a point devaluing SQLite, Author's method is excellent approach to get analytical speed out of SQLite. But I am loving DuckDB for similar analytical workloads as it is built for such tasks.  DuckDB also reads from single file, like SQLite and DuckDB process large data sets at extreme speeds. I work on my macbook m2 and I have been dealing with about 20 million records and it works fast, very fast.Loading data into DuckDB is super easy, I was surprised :SELECT \n    avg(sale_price), \n    count(DISTINCT customer_id) \n FROM '/my-data-lake/sales/2024/*.json';and you can also load into a JSON type column and can use postgres type syntax \ncol->>'$.key'reply",
      "Whoa. Is that first query building an index of random filesystem json files on the fly?reply",
      "It's not an index, it's just (probably parallel) file readsThat being said, it would be trivial to tweak the above script into two steps, one reading data into a DuckDB database table, and the second one reading from that table.reply",
      "duckdb is super fast for analytic tasks, especially when u use it with visual eda tool like pygwalker. it allows u handles millions of data visuals and eda in seconds.but i would say, comparing duckdb and sqlite is a little bit unfair, i would still use sqlite to build system in most of cases, but duckdb only for analytic. you can hardly make a smooth deployment if you apps contains duckdb on a lot of platformreply"
    ],
    "link": "https://www.dbpro.app/blog/sqlite-json-virtual-columns-indexing",
    "first_paragraph": "We absolutely love SQLite here at DB Pro. You'd be hard-pressed to find anyone who actively dislikes it. Sure, it has limitations, and I do mean limitations, not weaknesses. SQLite can absolutely be used in production when it's deployed properly and tuned with care.SQLite has also seen something of a resurgence over the past few years. From being forked into projects like libSQL and Turso, to powering popular backend frameworks such as PocketBase, it\u2019s clearly having a moment again.As I said though, we love it. It even powers the local database inside DB Pro itself. For our use case, there really isn\u2019t a better alternative.Because we\u2019ve been using SQLite in anger over the past three months, we\u2019ve learnt a huge amount about it, including plenty of things we didn\u2019t know before.So I\u2019m planning to write a short series of blog posts covering some of the cooler, more interesting features and nuances of SQLite that we\u2019ve discovered along the way. This is the first of those posts.First of all."
  },
  {
    "title": "4 billion if statements (2023) (andreasjhkarlsson.github.io)",
    "points": 586,
    "submitter": "damethos",
    "submit_time": "2025-12-06T15:34:26 1765035266",
    "num_comments": 162,
    "comments_url": "https://news.ycombinator.com/item?id=46174114",
    "comments": [
      "This is time efficient* but rather wasteful of space.The best way to save space is to use a Bloom Filter.If we capture all the even numbers, that would sadly only give us \"Definitely not Even\" or \"Maybe Even\".But for just the cost of doubling our space, we can use two Bloom filters!So we can construct one bloom filter capturing even numbers, and another bloom filter capturing odd numbers.Now we have \"Definitely not Even\" and \"Maybe Even\" but also \"Definitely not Odd\" and \"Maybe Odd\".In this manner, we can use the \"evens\" filter to find the odd numbers and the \"odds\" filter to find the even numbers.Having done this, we'll be left with just a handful of unlucky numbers that are recorded as both \"Maybe even\" and \"Maybe odd\". These will surely be few enough in number that we can special case these in our if/else block.The filters as a first-pass will save gigabytes of memory!reply",
      "> But for just the cost of doubling our space, we can use two Bloom filters!We can optimize the hash function to make it more space efficient.Instead of using remainders to locate filter positions, we can use a mersenne prime number mask (like say 31), but in this case I have a feeling the best hash function to use would be to mask with (2^1)-1.reply",
      "This produced strange results on my ternary computer. I had to use a recursive popcnt instead.reply",
      "this is my new favorite comment on this cursed websitereply",
      "How is this time efficient at all? It takes upwards of 40 seconds to compute on large 32bit values.It's a joke post with some interesting bits and details.reply",
      "It's a constant number of lookups, and all good Computer Scientists know that it is therefore an O(1) algorithm.It is hard to imagine better efficiency than O(1)!Indeed we could improve it further by performing all evaluations even when we find the answer earlier, ensuring it is a true Constant Time algorithm, safe for use in cryptography.reply",
      "> This is time efficient* but rather wasteful of space.You're saying that the blog's solution is time efficient. Which it is not. Your solution may be O(1) but it is also not efficient. As I'm sure you are aware.I can tell you a practical solution which is also O(1) and takes up maybe 2 or 3 instructions of program code and no extra memory at all.`x & 1` or `x % 2 != 0`This blog post was taking a joke and running with it. And your comment is in that spirit as well, I just wanted to point out that it's by no means time efficient when we have 2s or 1s complement numbers which make this algorithm trivial.reply",
      "You need to read their entire comment as a joke.reply",
      "I guess I should have been more clear that I was just pointing out the obvious in case some confused reader missed the joke.lolreply",
      "Which was also obvious, but maybe also needed pointing out, which says something about online discussion.  Something obvious, probably.reply"
    ],
    "link": "https://andreasjhkarlsson.github.io//jekyll/update/2023/12/27/4-billion-if-statements.html",
    "first_paragraph": "\nDec 27, 2023\n      I recently stumbled upon this screenshot while researching social media on the train. Of course, it was followed by a cascade of spiteful comments, criticizing this fresh programmer\u2019s attempt to solve a classical problem in computer science. The modulus operation.Now, in a world where AI is replacing programmers by the minute, taking their jobs and revolutionizing the way we think about code, maybe we should be more open to the thoughts of the fresh new blood of the industry? In fact, the above code is a perfect example of a time-memory tradeoff. You\u2019re trading off your time and at the same time, the computers memory and time as well! Truly a marvelous algorithm!So I went to work to explore this idea of checking if a number is odd or even by only using comparisons to see how well it works in a real world scenario. Since I\u2019m a great believer in performant code I decided to implement this in the C programming language as it\u2019s by far the fastest language on the planet "
  },
  {
    "title": "Motion (YC W20) Is Hiring Senior Staff Front End Engineers (ashbyhq.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-12-12T21:00:54 1765573254",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jobs.ashbyhq.com/motion/715d9646-27d4-44f6-9229-61eb0380ae39",
    "first_paragraph": ""
  },
  {
    "title": "Sick of smart TVs? Here are your best options (arstechnica.com)",
    "points": 97,
    "submitter": "fleahunter",
    "submit_time": "2025-12-12T12:51:40 1765543900",
    "num_comments": 115,
    "comments_url": "https://news.ycombinator.com/item?id=46243655",
    "comments": [
      "For a hacker news article, it misses the crucial option - hacking a smart TV! I have LG OLED jailbroken using rootmy.tv, it was pretty trivial. It's basically a linux computer with a huge screen, you can customize it, SSH into it, map any commands to the remote, etc.Before I only used monitor, simple DP/HDMI input is all I wanted. But being able to take full control of the tv and connect it with other devices in the house I would normally get Rpi for is pretty convenient!reply",
      "As a Plex user I'd recommend a used last-gen game console as a TV source.  In my AV room upstairs I've had an XBOX ONE S for a long time and more recently I got a PS4 Pro for the spare room downstairs -- both at Gamestop.  I have some games for both of them but I am more likely to game on Steam, Steam Deck or mobile.Every Android-based media player I've had tried just plain sucks,  the NVIDIA Shield wasn't too bad but at some point the controller quit charging.  You can still get a game console with a built-in Blu-Ray player too and it's nice to have one box that does that as well as being an overpowered for streaming.I have a HDHomeRun hooked up to a small antenna pointed at Syracuse which does pretty well except for ABC,  sometimes I think about going up on the roof and pointing the small one at Binghamton and pointing a large one at Syracuse but I am not watching as much OTA as I used to.  It's nice though being able to watch OTA TV on either TV, any computer,  tablets, phones, as well as the Plex Pass paying for the metadata for a really good DVR side-by-side with all my other media.As for TVs I go to the local reuse center and get what catches my eye,  my \"monitor\" I am using right now is a curved Samsung 55 inch,  I just brought home a plasma that was $45 because I always wanted a plasma.  I went through a long phase where people just kept dropping off cheap TVs at my home,  some of which I really appreciated (a Vizio that was beautifully value engineered) and some of which sucked.  [1][1] ... like back in the 1980s everybody was afraid someone would break into your home and take your TV but for me it is the other way aroundreply",
      "What I'd really like is a TV with DisplayPort. How is this not a thing? IIRC you cannot buy a display with DP that's larger than 45 inches, give or take - they just don't exist. I think this is really weird. Like, I'd pay an extra $100 for that port, but I'm just not allowed to have it.reply",
      "As far as I am aware, after having done exhaustive research on this, its licensing costs and popularity. Display port simply isn't popular enough. The vast majority of TV manufacturers (not brands mind you, many white label their manufacturing to different brands) also make monitors, and adoption of HDMI across both tvs and monitors not only was much higher, it was overall cheaper in cost since you could share the same components across lines. This being driven by cheaper licensing costs for accessory manufacturers (like blu ray players).Its also easier to implement, if I recall correctlyThis is the essential core of it, as I have come to understand it anyway.reply",
      "I absolutely love my Aorus 48\" OLED-type display (w/ DisplayPort).I tried a 48\" TFT-type television (attempting use as a computer display) and the refresh rate just wasn't there, along with typical backlight splotching (but it cost a fifth as much, so...).My only caution is OLED can experience burn-in (unlike the smaller Aorus 45\" using a VA-type panel), but it is otherwise a much better experiencereply",
      "New Hisense TVs have USB-C DisplayPort support. Pretty cool, but realistically I don't see how it's different from HDMI from a usefulness standpoint.Edit: It is cool I can plug my phone or laptop into the TV with one cable, no adapters, and get some power as well. For some reason it didn't work with my Steam Deck which was strange.reply",
      "I think it helps with the HDMI 2.1 licensing bullshit.reply",
      "I saw some giant TV on LTT recently which has a DP port.reply",
      "I tried to buy a good 32 inch tv. This is also hard. I need up going a little matter and even then, the utterly trash built in speakers frustrate the hell out of me.reply",
      "Why would you want such a thing? HDMI 2.1 does HDR 4k @ 120hz without compression. The entire TV ecosystem uses HDMI. If you want to connect a PC to a TV they always have at least 1 HDMI out, and some have a couple.reply"
    ],
    "link": "https://arstechnica.com/gadgets/2025/12/the-ars-technica-guide-to-dumb-tvs/",
    "first_paragraph": "\n      Sick of smart TVs? Here are your best options.\n    Smart TVs can feel like a dumb choice if you\u2019re looking for privacy, reliability, and simplicity.Today\u2019s TVs and streaming sticks are usually loaded up with advertisements and user tracking, making offline TVs seem very attractive. But ever since smart TV operating systems began making money, \u201cdumb\u201d TVs have been hard to find.In response, we created this non-smart TV guide that includes much more than dumb TVs. Since non-smart TVs are so rare, this guide also breaks down additional ways to watch TV and movies online and locally without dealing with smart TVs\u2019 evolution toward software-centric features and snooping. We\u2019ll discuss a range of options suitable for various budgets, different experience levels, and different rooms in your home.This is a dumb TV guide, but first, let\u2019s briefly highlight the best recommendation for most people: Take your TV offline and plug in an Apple TV box.An Apple TV lets you replace smart TV softwa"
  },
  {
    "title": "Building small Docker images faster (hootr.club)",
    "points": 23,
    "submitter": "steinuil",
    "submit_time": "2025-12-12T10:23:23 1765535003",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=46242700",
    "comments": [
      "I've seen so many devs not know that things like multi stage even exists.Multi gigabyte containers everywhere.reply",
      "I always like finding people advocating for older sage knowledge and bringing it forward for new audiences. That said, as someone who wrote a book about Docker and has lived the full container journey I tend to skip the containerized build all together. Docker makes for great packaging. But containerizing ever step of the build process or even just doing it in one big container is a bit extra. Positioning it as a build scripting solution was silly.reply",
      "I\u2019m inclined to agree with you about not building containers. That said, I find myself going around in circles. We have an app that uses a specific toolchain version, how do we install that version on a build machine without requiring an SRE ticket to update our toolchain?Containers nicely solve this problem. Then your builds get a little slow, so you want to cache things. Now your docker file looks like this. You want to run some tests - now it\u2019s even more complicated. How do you debug those tests? How do those tests communicate with external systems (database/redis). Eventually you end up back at \u201clet\u2019s just containerise the packaging\u201d.reply",
      "Depending on how the container is structured, you could have the original container as a baseline default, and then have \"enhanced\" containers that use it as a base and overlay the caching and other errata to serve that specialized need.reply",
      "Agree. Using a container to build the source that is then packaged as a \"binary\" in the resulting container always seemed odd to me. imho we should have stuck with the old ways : build the product on a regular computer. That outputs some build artifacts (binaries, libraries, etc). Docker should take those artifacts and not be hosting the compiler and what not.reply",
      "If anything the build being in a container is the more valuable bit, though mainly because the container usually more repeatable by having a scripted setup itself. Though I dunno why the build and the host would be the _same_ container in the end.reply"
    ],
    "link": "https://sgt.hootr.club/blog/docker-protips/",
    "first_paragraph": "Published by steen on 2025-12-12 tagged #dockerI've been tasked (more or less) with building the first Go service at $DAYJOB, which is almost exclusively a Python shop. Why Go of all languages? Well, some of my coworkers are big fans of the gopher, it's an easy language, it's attached to one of the big companies, and it's much faster than Python, so I feel more comfortable pushing for this rather than Rust or (sadly) Nix.The project that recently fell onto my lap is basically RCE-as-a-service, and it just so happens that one of the few languages that I would feel comfortable letting users execute remotely on our servers has a Go implementation, which is as good an excuse as any to take a break from the usual snekslop.I still haven't convinced anybody here to get on the Nix train, so after a short stint of building the project and the OCI images with a recursive cycle of Make and Nix, I breathed a heavy sigh and dropped it for Docker and Docker Compose, which is what we generally use he"
  },
  {
    "title": "Pg_ClickHouse: A Postgres extension for querying ClickHouse (clickhouse.com)",
    "points": 67,
    "submitter": "spathak",
    "submit_time": "2025-12-10T17:14:39 1765386879",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=46220411",
    "comments": [
      "The name of the project is a reference to P. G. Wodehouse[0] for those unaware.[0] https://www.gutenberg.org/ebooks/author/783reply",
      "Hmm, no.It\u2019s just like all the other postgres extensions named \u201cpg_foo\u201d, and the clear and obvious choice for \u201cfoo\u201d in this case is \u201cclickhouse\u201d.Unless this is some bad joke that has flown over my head.reply",
      "I will never un-see it now, tbhreply",
      "\"I am never wrong, sir\" -onedognightreply",
      "LOLreply",
      "Added to https://github.com/Olshansk/postgres_for_everything.reply",
      "This is nice because there are a lot of clickhouse fdw implementations and none of them are well maintained from what I can tell.reply",
      "Appreciate you chiming in! We evaluated almost all the FDWs and landed on clickhouse_fdw (built by Ildus) as the most mature option. However, it hadn\u2019t been maintained since 2020. We used it as the base, and the goal is to take it to the next level.Our main focus is comprehensive pushdown capabilities. It was very surprising to see how much the Postgres FDW framework has evolved over the years and the number and types of hooks it now provides for push down. This is why we decided to lean into FDW than build an extension bottoms up. But we may still do that within pg_clickhouse for a few features, wherever FDW framework becomes a restriction.We\u2019ve made notable progress over the last few months, including support for pushdown of custom aggregations and SEMI JOINs/basic subqueries. Fourteen of twenty-two TPCH queries are now fully pushdownable.We\u2019ll be doubling down to add pushdown support for much more complex queries, CTEs, window functions, and more. More on the future here -  https://github.com/ClickHouse/pg_clickhouse?tab=readme-ov-fi...\nAll with the goal of enabling users to build fast analytics from the Postgres layer itself but still using the power of ClickHouse!reply",
      ">All with the goal of enabling users to build fast analytics from the Postgres layer itself but still using the power of ClickHouse!That would be incredible! So many times I want to reach for ClickHouse but whatever company I'm at has so much inertia built into PG. Pleease add CTE support.And yes I'm aware of PeerDB or whatever that project is called. This is still or even more helpful.reply",
      "You're replying to the CEO of PeerDB. We recognize CDC is only one tool in the integration toolbox, which is why we're prioritizing thisreply"
    ],
    "link": "https://clickhouse.com/blog/introducing-pg_clickhouse",
    "first_paragraph": "Use casesIndustriesOver the last year, we\u2019ve noticed a strong pattern in customers who\u2019ve migrated their analytics workloads to ClickHouse Cloud: After self-hosted ClickHouse, PostgreSQL is the most common source of migrations. ClickPipes made data replication and migrations easy for these use-cases. However, we found that users still face significant challenges migrating queries and application code from PostgreSQL to ClickHouse. To address this, a few months ago we started looking into ways to simplify and reduce the time required to migrate analytical queries from PostgreSQL to ClickHouse.Today, we\u2019re pleased to release pg_clickhouse v0.1.0, an Apache 2-licensed PostgreSQL extension to transparently execute analytics queries on ClickHouse directly from PostgreSQL.Download pg_clickhouse from:Or kick the tires by spinning up a Docker instance:Consider starting with the tutorial, or watch Sai run through the tutorial in the video below.Consider the common case where an organization bui"
  },
  {
    "title": "Home Depot GitHub token exposed for a year, granted access to internal systems (techcrunch.com)",
    "points": 184,
    "submitter": "kernelrocks",
    "submit_time": "2025-12-12T18:23:21 1765563801",
    "num_comments": 115,
    "comments_url": "https://news.ycombinator.com/item?id=46247000",
    "comments": [
      ">When reached by TechCrunch on December 5, Home Depot spokesperson George Lane acknowledged receipt of our email but did not respond to follow-up emails asking for comment. The exposed token is no longer online, and the researcher said the token\u2019s access was revoked soon after our outreach.>>We also asked Lane if Home Depot has the technical means, such as logs, to determine if anyone else used the token during the months it was left online to access any of Home Depot\u2019s internal systems. We did not hear back.As soon as they realized that the researcher had contacted \"the media\", they probably escalated internally to their legal team before anyone else, who told them to shut up.The response, if one ever comes, will be a communication dense in lawyer-speak that admits no fault whatsoever.reply",
      "I mean you can't fault them for that approach.Obviously we would all like a full post mortem from the home dept side, but in today's litigious shareholder-value-driven world their response is the correct one.reply",
      "I've accidentally pushed a personal PAT(ro) to both Github and gist because of poor hygiene in personal projects, both times Github dropped the PAT and notified me.reply",
      "Yeah I'm impressed they even managed to publish a personal token. My experience with GitHub's automated token recognition has also been positive (tho the tokens were never of any consequence)reply",
      "Man, a year to grab all the Home Depot 2x4s you want! Someone could have built a sphere with those.reply",
      "I don't know how well lumber holds up to the bottom of the oceanreply",
      "Pretty good actually. With the salt, lack of oxygen and pressure it can last quite a long time.reply",
      "it's easy to scan for publicly known services, really difficult to understand if a random string that says key somewhere is actually a random internal api keyreply",
      "which is why a lot of services  now prefix they keys with a fixed string like pat_, sk_,reply",
      "\"Open Source Home Depot\" has a nice ring to itreply"
    ],
    "link": "https://techcrunch.com/2025/12/12/home-depot-exposed-access-to-internal-systems-for-a-year-says-researcher/",
    "first_paragraph": "\n\n\t\tLatest\t\n\n\n\t\tAI\t\n\n\n\t\tAmazon\t\n\n\n\t\tApps\t\n\n\n\t\tBiotech & Health\t\n\n\n\t\tClimate\t\n\n\n\t\tCloud Computing\t\n\n\n\t\tCommerce\t\n\n\n\t\tCrypto\t\n\n\n\t\tEnterprise\t\n\n\n\t\tEVs\t\n\n\n\t\tFintech\t\n\n\n\t\tFundraising\t\n\n\n\t\tGadgets\t\n\n\n\t\tGaming\t\n\n\n\t\tGoogle\t\n\n\n\t\tGovernment & Policy\t\n\n\n\t\tHardware\t\n\n\n\t\tInstagram\t\n\n\n\t\tLayoffs\t\n\n\n\t\tMedia & Entertainment\t\n\n\n\t\tMeta\t\n\n\n\t\tMicrosoft\t\n\n\n\t\tPrivacy\t\n\n\n\t\tRobotics\t\n\n\n\t\tSecurity\t\n\n\n\t\tSocial\t\n\n\n\t\tSpace\t\n\n\n\t\tStartups\t\n\n\n\t\tTikTok\t\n\n\n\t\tTransportation\t\n\n\n\t\tVenture\t\n\n\n\t\tStaff\t\n\n\n\t\tEvents\t\n\n\n\t\tStartup Battlefield\t\n\n\n\t\tStrictlyVC\t\n\n\n\t\tNewsletters\t\n\n\n\t\tPodcasts\t\n\n\n\t\tVideos\t\n\n\n\t\tPartner Content\t\n\n\n\t\tTechCrunch Brand Studio\t\n\n\n\t\tCrunchboard\t\n\n\n\t\tContact Us\t\nA security researcher said Home Depot exposed access to its internal systems for a year after one of its employees published a private access token online, likely by mistake. The researcher found the exposed token and tried to privately alert Home Depot to its security lapse but was ignored for several weeks.\u00a0The exposure is now fixed after TechCrunc"
  },
  {
    "title": "String theory inspires a brilliant, baffling new math proof (quantamagazine.org)",
    "points": 107,
    "submitter": "ArmageddonIt",
    "submit_time": "2025-12-12T16:23:10 1765556590",
    "num_comments": 102,
    "comments_url": "https://news.ycombinator.com/item?id=46245622",
    "comments": [
      "Posting the paper: https://arxiv.org/abs/2508.05105reply",
      "It's 2025, if you want to publish grand claims, and you're initially the only one who understands your own proof, publish a machine readable proof in say MetaMath's .mm format.reply",
      "You say that like it\u2019s even remotely feasible at the frontier of mathematics and not a monumental group effort to turn even established proofs into such.Most groundbreaking proofs these days aren\u2019t just cross-discipline but usually involve one or several totally novel techniques.All that to say: I think you\u2019re dramatically underestimating the difficulty involved in this, EVEN if the author(s) were a(n) expert(s) in machine readable mathematics, which is highly UNlikely given that they are necessarily (a) deep expert(s) in at LEAST one other field.reply",
      "One doesn't need to be an expert in machine readable mathematics, to understand how to formalize it to a machine readable form.If one takes the time to read the free book accompanying the metamath software, and re implements it in about a weekend time, you learn to understand how it works internally. Then playing around a little with mmj2 or so you quickly learn how to formalize a proof you understand. If you understand your own proof its easy to formalize it. One doesn't need to be \"an expert in machine readable mathematics\".reply",
      ">You say that like it\u2019s even remotely feasible at the frontier of mathematics and not a monumental group effort to turn even established proofs into such.Is it really known to be the frontier as long as its not verified? I would call the act of rigorous verification the acknowledgement of a frontier shift.Consider your favorite dead-end in science, perhaps alchemy, the search for alcahest, the search for the philosophers stone, etc. I think nobody today would pretend these ideas were at the frontier, because today it is collectively identified as pseudoscience, which failed to replicate / verify.If I were the first to place a flag on some mountain, that claim may or may not be true in the eyes of others, but time will tell and others replicating the feat will be able to confirm observation of my flag.As long as no one can verify my claims they are rightfully contentious, and as more and more people are able to verify or invalidate my claims it becomes clear if I did or did not move the frontier.reply",
      "> You say that like it\u2019s even remotely feasible at the frontier of mathematics and not a monumental group effort to turn even established proofs into such.people on hn love making these kinds of declarative statements (the one you responded to, not yours itself) - \"for X just do Y\" as a kind of dunk on the implied author they're responding to (as if anyone asked them to begin with). they absolutely always grossly exaggerate/underestimate/misrepresent the relevance/value/efficacy of Y for X. usually these declarative statements briskly follow some other post on the frontpage. i work on GPU/AI/compilers and the number of times i'm compelled to say to people on here \"do you have any idea how painful/pointless/unnecessary it is to use Y for X?\" is embarrassing (for hn).i really don't get even get it - no one can see your number of \"likes\". twitter i get - fb i get - etc but what are even the incentives for making shit up on here.reply",
      "Do selection dynamics require awareness of incentives? I would think that the incentives merely have to exist, not be known.On HN, that might be as simple as display sort order -- highly engaging comments bubble up to the top, and being at the top, receive more attention in turn.The highly fit extremes are -- I think -- always going to be hyper-specialized to exploit the environment. In a way, they tell you more about the environment than whatever their content ostensibly is.reply",
      "It feels good to be smarter than everyone else. You see your upvotes and that's good enough for an ego boost. Been there, done that.I wish we were a bit more self-critical about this, but it's a tough problem when what brings the community together in the first place is a sense of superiority: prestigious schools, high salaries, impressive employers, supposedly refined tastes. We're at the top of the world, right?reply",
      "HN is frequently fodder for satire on other forums. Nobody thinks HN users have \"refined tastes\", or even that they are \"smart\" for that matter.reply",
      "> prestigious schools, high salaries, impressive employers, supposedly refined tastes. We're at the top of the world, right?Being pompous and self obsessed requires none of those things.reply"
    ],
    "link": "https://www.quantamagazine.org/string-theory-inspires-a-brilliant-baffling-new-math-proof-20251212/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesDecember 12, 2025Kristina Armitage/Quanta MagazineStaff WriterDecember 12, 2025In August, a team of mathematicians posted a paper claiming to solve a major problem in algebraic geometry \u2014 using entirely alien techniques. It instantly captivated the field, stoking excitement in some mathematicians and skepticism in others.The result deals with polynomial equations, which combine variables raised to powers (like y = x or x2 \u2212 3xy = z2). These equations are some of the simplest and most ubiquitous in mathematics, and today, they\u2019re fundamental to lots of different areas of study. As a result, mathematicians want to study their solutions, which can be represented as geometric shapes like curves"
  }
]