[
  {
    "title": "Copilot broke audit logs, but Microsoft won't tell customers (pistachioapp.com)",
    "points": 109,
    "submitter": "Sayrus",
    "submit_time": "2025-08-20T00:18:00 1755649080",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=44957454",
    "comments": [
      "Wait, copilot operates as some privileged user (that can bypass audit?), not as you (or better, you with some restrictions)That can\u2019t be right, can it?reply",
      "> That can\u2019t be right, can it?https://knowyourmeme.com/memes/james-franco-first-timereply",
      "Brilliant.reply",
      "lol.  I\u2019ve avoided MS my entire (30+ year) career.  Every now and then I\u2019m reminded I made the right choice.reply",
      "Sure sounds like, for Microsoft, an audit log is optional when it comes to cramming garbage AI integrations in places they don't belong.reply",
      "No, it accesses data with the users privilege.reply",
      "A better title would be: Microsoft Copilot isn't HIPAA compliantA title like this will get it fixed faster.reply",
      "It already is fixed -- the complaint is that customers haven't been notified.reply",
      "Hard to count the number of things that can go wrong by relying directly on an LLM to manage audit/activity/etc. logs.What was their bug fix? Shadow prompts?reply",
      "I'm very sceptical of using shadow prompts (or prompts of any kind) as an actual security/compliance control or enforcement mechanism. These things should be done using a deterministic system.reply"
    ],
    "link": "https://pistachioapp.com/blog/copilot-broke-your-audit-log",
    "first_paragraph": "Explore our core features of the fully-automated admin platform.Tailored simulations to meet the unique requirements of each user.Scenario-driven learning experiences with immediate feedback.New or existing Pistachio Partner? Log into the Partners Hub here.Find quick answers to all your frequently asked questions.Read the latest Pistachio team posts, from updates to cybersecurity insights.Explore our video library for a platform tour, onboarding help, and more.Like most tech companies, Microsoft is going all-in on AI. Their flagship AI product, Copilot (in all its various forms), allows people to utilize AI in their daily work to interact with Microsoft services and generally perform tasks. Unfortunately, this also creates a wide range of new security problems.On July 4th, I came across a problem in M365 Copilot: Sometimes it would access a file and return the information, but the audit log would not reflect that. Upon testing further, I discovered that I could simply ask Copilot to be"
  },
  {
    "title": "How to Draw a Space Invader (muffinman.io)",
    "points": 97,
    "submitter": "abdusco",
    "submit_time": "2025-08-19T22:41:16 1755643276",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44956915",
    "comments": [
      "Interesting, it takes a lot of imagination to do itreply",
      "This is one of the best mobile experiences I\u2019ve had reading an article.reply",
      "I\u2019m surprised and impressed that it built a vector that it rasterized.I wonder how well you can do by having a pseudo-random kernel walk and then mirroring it.reply",
      "If you refresh the page the invader that gets generated as you read changes.reply",
      "This would be awesome as a random avatar generator!reply",
      "Awesome!reply"
    ],
    "link": "https://muffinman.io/blog/invaders/",
    "first_paragraph": "Posted in JavaScript \u00b7 14 minutes readThis is an interactive article. To fully experience it, you'll need to turn JavaScript on.I recently made the Space Invader Generator for Creative Coding Amsterdam code challenge. I made it for fun of course... and galactic domination too! You can see how it looks below and in this post I'll show you how it works using an interactive animation.Here are a few invaders it can generate:While showing friends how it works, I realized the process would look great animated. So I decided to write another interactive blog post. I'll give you some background first, but if you are eager to see the process, feel free to jump straight to the interactive part.I was working on a new version of Rayven, my vector 3D renderer. Sometimes I get stuck working on tools - they turn into never-ending projects and I never actually use them to create something. At some point I became aware of this pattern, and I think I've gotten better at wrapping projects up, releasing th"
  },
  {
    "title": "Tiny microbe challenges the definition of cellular life (nautil.us)",
    "points": 26,
    "submitter": "jnord",
    "submit_time": "2025-08-19T23:18:48 1755645528",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://nautil.us/a-rogue-new-life-form-1232095/",
    "first_paragraph": "Art+ScienceBiology + BeyondCosmosCultureEarthLifeMindOceanOne QuestionQuanta AbstractionsRewildingScience at the Ballot BoxScience Philanthropy AllianceSpark of ScienceThe Animal IssueThe Climates IssueThe Kinship IssueThe PortholeThe Reality IssueThe Rebel IssueWomen in Science & Engineering\nA tiny microbe discovered by accident challenges the definition of cellular life\nA tiny microbe discovered by accident challenges the definition of cellular life\nThe full Nautilus archive\n\u2022\neBooks & Special Editions\n\u2022\nAd-free reading\nScientists recently discovered a microbe with one of the tiniest genomes on Earth. More surprising, the creature is almost entirely dependent on its host: Its genes don\u2019t support any of the functions of metabolism, one of the key processes of life. As such, it challenges fundamental notions of what it means to be a living organism.The discovery was \u201cpure serendipity,\u201d says Takuro Nakayama, an evolutionary microbiologist at the University of Tsukuba in Japan. Takayama "
  },
  {
    "title": "How we exploited CodeRabbit: From simple PR to RCE and write access on 1M repos (kudelskisecurity.com)",
    "points": 487,
    "submitter": "spiridow",
    "submit_time": "2025-08-19T15:55:15 1755618915",
    "num_comments": 163,
    "comments_url": "https://news.ycombinator.com/item?id=44953032",
    "comments": [
      "I cancelled my coderabbit paid subscription, because it always worries me when a post has to go viral on HN for a company to even acknowledge an issue occurred. Their blogs are clean of any mention of this vulnerability and they don't have any new posts today either.I understand mistakes happen, but lack of transparency when these happen makes them look bad.reply",
      "https://www.coderabbit.ai/blog/our-response-to-the-january-2...reply",
      "The LLM tics are strong in this writeup:\"No manual overrides, no exceptions.\"\"Our VDP isn't just a bug bounty\u2014it's a security partnership\"reply",
      "Wow, you hit a nerve with that one. There have been some quick edits on the page.Another:> Security isn't just a checkbox for us; it's fundamental to our mission.reply",
      "They delved deep and spent a whole 2 minutes with ChatGPT 4o getting those explanations and apologies in play.reply",
      "That\u2019s the part that makes me laugh. If you\u2019re going to try to pass of ChatGPT as your own work at least pay for the good modelreply",
      "Absolutely. In my experience every AI startup is full of AI maximalists. They use AI for everything they can - in part because they believe in the hype, in part to keep up to date with model capabilities. They would absolutely go so far as to write such an important piece of text using an LLM.reply",
      "For anyone following along in the comments here. Code Rabbit's CEO posted some of the details today, after this post hit HN.The usual \"we take full responsibility\" platitudes.reply",
      "I\u2019m sure an \u201cintern\u201d did it.reply",
      "I would love to know the acceptable version.reply"
    ],
    "link": "https://research.kudelskisecurity.com/2025/08/19/how-we-exploited-coderabbit-from-a-simple-pr-to-rce-and-write-access-on-1m-repositories/",
    "first_paragraph": "Kudelski Security ResearchThe Latest News from Research at Kudelski SecurityIn this blog post, we explain how we got remote code execution (RCE) on CodeRabbit\u2019s production servers, leaked their API tokens and secrets, how we could have accessed their PostgreSQL database, and how we obtained read and write access to 1 million code repositories, including private ones.This blog post is a detailed write-up of one of the vulnerabilities we disclosed at Black Hat USA this year. The details provided in this post are meant to demonstrate how these security issues can manifest and be exploited in the hopes that others can avoid similar issues. This is not meant to shame any particular vendor; it happens to everyone. Security is a process, and avoiding vulnerabilities takes constant vigilance. Note: The security issues documented in this post were quickly remediated in January of 2025. We appreciate CodeRabbit\u2019s swift action after we reported this security vulnerability. They reported to us tha"
  },
  {
    "title": "D2 (text to diagram tool) now supports ASCII renders (d2lang.com)",
    "points": 196,
    "submitter": "alixanderwang",
    "submit_time": "2025-08-19T18:14:41 1755627281",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=44954524",
    "comments": [
      "Hello fellow devs. Just wanted to share a new feature we added this morning, though it's very alpha stage (already someone's filed a github issue for it hah)If you want to skip the blog post and poke around directly: \nhttps://play.d2lang.com/?script=qlDQtVOotFLIyFTwSEzOTi1S8Est...For a bigger example:\nhttps://play.d2lang.com/?script=rJJBjtswDEX3OgWBrm2kzU4Feoru...reply",
      "So from TFA it just downscales from ELK?  Do I have to specify ELK for this to work, or will it automagically enable if I try to output a .txt?  (Really I'm just curious becasue I use ELK already for most of my d2 diagrams).reply",
      "It switches to ELK: https://github.com/terrastruct/d2/blob/master/d2cli/main.go#...reply",
      "I thought your playground wasn't working as it renders black text on black background. Maybe I have darkmode enabled or something. Other renderers work, but ascii is invisible.reply",
      "Ah right, forgot to test the update with dark mode. Thanks for letting me know!edit: fixedreply",
      "This is awesome.I hadn't heard of D2, but I love the idea that I can create my charts directly in Neovim in the terminal to get a rough draft, and do a final render with a pretty picture.I will be playing with this shortly.reply",
      "D2 already supports a live-updating HTTP server serving a live-updating .svg, so if you tile a browser with vim, you can already get live-updates.I discovered D2 about a year ago, and I use it for all of my diagrams now.reply",
      "Yeah but that doesn't feel nearly as nerdy and cool :)There's a sort of elegance to ASCII rendering.reply",
      "I typically use Moondraw for ASCII diagrams but this is pretty great for when you're already in Vim.reply",
      "I maintain a list of browser based text to diagram tools (which I have shared a number of times here). I recently realised that the online version of D2 does NOT work solely in browser, diagram's are generated  by backend servers.Can D2 work in browser by itself? Does the extension mentioned in the post work offline? (lots of tools do)reply"
    ],
    "link": "https://d2lang.com/blog/ascii/",
    "first_paragraph": "In the latest release of D2 (0.7.1), we introduce ASCII outputs.Any output file with extension txt will use the ASCII renderer to write to it.Here is an example of their rendering from the D2 Vim extension. The user opens a .d2 file and opens a preview window, which updates upon every save.Perhaps the most useful place for ASCII diagrams is in the source code comments. Small\nsimple diagrams next to functions or classes can serve to be much clearer than describing\na flow.Here again the Vim extension demonstrates a functionality to write some d2 code and\nreplace the selection with the ASCII render.The default character set of ASCII renders is unicode, which has nicer box-drawing\ncharacters. If you'd like true ASCII for maximum portability, you can specify this with\nthe flag --ascii-mode=standard.Note that the ASCII renderer should be considered in alpha stage. There will be many\ncorner cases, areas of improvements, and outright bugs. If you enjoy using it, we'd\nappreciate you taking the "
  },
  {
    "title": "Drunken Bishop (2023) (factorcode.org)",
    "points": 35,
    "submitter": "todsacerdoti",
    "submit_time": "2025-08-19T21:48:30 1755640110",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44956581",
    "comments": [
      "It's been a while but I can't get past the first image. I keep wanting to kill the orcs and grab all those spellbooks and gems, while keeping a wary eye on the elemental. (Although since this is obviously the Elemental Plane of Air, my ascension kit should let me handle it easily enough.)reply",
      "How universal are roguelike character mappings? Is there some central bit of knowledge that all the developers refer to to decide whether 'b' should be a bear or a beholder?reply",
      "Time to cast Dispel Evilreply"
    ],
    "link": "https://re.factorcode.org/2023/08/drunken-bishop.html",
    "first_paragraph": "Factor: the language, the theory, and the practice.Sunday, August 27, 2023\n#math\nThe OpenSSH project is a widely available tool for\nworking with the SSH protocol in\na variety of ways on a variety of operating systems. Their project description\nstates:OpenSSH is the premier connectivity tool for remote login with the SSH\nprotocol. It encrypts all traffic to eliminate eavesdropping, connection\nhijacking, and other attacks. In addition, OpenSSH provides a large suite of\nsecure tunneling capabilities, several authentication methods, and\nsophisticated configuration options.One of the interesting features that it contains is a method of visualizing\npublic key fingerprints\nto allow a user to more easily see that a key has changed by examining a visual\noutput that looks something like this:This is the Drunken Bishop\nalgorithm,\na variant of a technique called random art that was originally described in\nthe paper Hash Visualization: a New Technique to improve Real-World\nSecurity. You can see\nmor"
  },
  {
    "title": "Physically Based Rendering in Filament (google.github.io)",
    "points": 12,
    "submitter": "indigo945",
    "submit_time": "2025-08-18T11:34:18 1755516858",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://google.github.io/filament/Filament.md.html#overview",
    "first_paragraph": ""
  },
  {
    "title": "Emacs as your video-trimming tool (xenodium.com)",
    "points": 179,
    "submitter": "xenodium",
    "submit_time": "2025-08-19T16:22:01 1755620521",
    "num_comments": 95,
    "comments_url": "https://news.ycombinator.com/item?id=44953316",
    "comments": [
      "This is impressive, but (and probably because I'm not the intended audience for this post) I don't get it, I kind of want to get it though. With \"it\" I mean making Emacs do X, where X is something far from editing text files. It always seems to me like playing Doom on a pregnancy test. Sure you can do it, sure it's impressive, but should you?n.b. I'm a C# developer that has accepted my fate and use Visual Studio to earn a living, though I've made sure I know my tool, flaws and merits, better than most developers I've met/worked with. My first job as a programmer was writing C++ code in Emacs and can't remember anything negative about that experience (other than getting used to ctrl+x, ctrl+s for saving and, by reflex, doing the same in Excel, and losing a big part of the document that I had just selected to move, because Excel couldn't undo past last save).Reading the (at the time I'm writing this) 13 comments on this post I see mentions of at least three lightweight programs that does this. What other than \"the mountain is there\" makes someone think Emacs would be the tool for this? As a Resolve user I know what tool I'd reach for even if using a multi GB, Hollywood grade, non linear editor, compositor and color grader for trimming a short video clip is about as ridiculously overpowered as using a sledge hammer to press a key (and I did exactly that just a few days ago).Like I said, I'm most likely not \"getting it\", on multiple levels. Please educate me, why would I use Emacs for this or any of the page upon page of \"strange\" use cases you find if you search for \"Emacs\" here on HN. I know Emacs is a powerful editor but I can't for the life of me understand why I would use it to trim video clips.reply",
      "Emacs is weird. I think it changed something in my brain. Before Emacs, I never thought I would ever try controlling video playback from my editor. \"Just why?\" I probably would've said. I never thought I'd be trying to get the text from the active tab in my browser. Or search through my browser history. Or OCR the content of my clipboard, or control my WM. Dang, before Emacs, it didn't even occur to me to try to type just about any text in my text editor - which now makes absolute sense - why would I ever bother typing in my browser window, Slack, Zoom, or email client?In Emacs, I have all the tools I need for dealing with text - thesaurus, spell-checking, definition and etymology lookup, search engines, translation, LLMs, etc. Why, oh why, wouldn't I ever try typing anything longer than two words in anything else?Like, for example, while typing this very comment, I may come across a thought: \"I think I already made a similar comment some time ago, let me find it...\" What would a regular user do? They'd switch to the browser, navigate to HN, scroll to the bottom, type search query, lookup on the page, jump to the next, keep paging until they find it, copy, switch back, paste... What would an experienced Emacs user do? They'd search for it without ever leaving their editor, grab the stuff from the buffer and paste it - all within just a few keystrokes. Or if I need to find a url in my browser history - I'd just search for it and insert in-place - two keystrokes+search query.It's not just faster - it is profoundly satisfying and liberating. It gives you the feeling of being in control. You don't have to deal with the quirks of specialized apps; you don't need to memorize tons of their specific keybindings; it gives you a straight path to extracting or injecting plain text.That's why those who never made a wholehearted attempt to use Emacs just never get it. And those who have, never can understand why others don't even try to recognize the value.reply",
      "I hear stories like this and I can kind of see the proposition. But I\u2019d be more eager to, somehow, see a long-running example of it all at work.  I think I\u2019m not so skeptical  about what it can do, but somewhat skeptical that it\u2019s actually as much of a paradigm shift as some describe it to be. I wonder if oftentimes it falls in the enjoyable hobby category of, \u201cI just really enjoy upgrading my workshop.\u201dreply",
      "It is indisputably not a hobby, at least for me, personally it ain't. I've been coding long enough to see a difference between \"oh, what a nice gimmick\" and \"how the fuck would I even do that, if I didn't know this way existed...\". Long. My first programming language was Sinclair BASIC. The second PL I learned was Pascal. I picked up a few more over the years. I'm not trying to show off, nor am I claiming to be an outstanding programmer - I'm neither great nor terrible. I'm just saying I've been doing this shit for a long time, that's all.It isn't a hobby, because Vim and Emacs allow me to perform in a way that I consider far more enjoyable, productive and satisfactory than I ever had before them. That is of course on a personal empirical basis - I cannot promise them having the same effect on anyone else.In my opinion, after many years using many different tools, techniques, ideas and methodologies, frameworks, approaches, systems, platforms, workflows, philosophies, paradigms, strategies, practices, concepts, models, theories, and experiments, I personally find these two to be exactly the paradigm shift \u2014 in comparison to my prior experience when I didn't have them.But let me be more specific - the paradigm shift I see is not in Emacs or Neovim as tools themselves. The paradigm shift I sense is in the grand ideas behind these tools - modal navigation and Lisp.I honestly don't know why more people don't gravitate towards these ideas. Perhaps, because these ideas are kind of like 'meditation' - people say one can only experience the mind shift after practicing it for some time. I wouldn't know - I never practiced mediation for long. And that time required to see the shift can differ for every person - some may grok it quickly, for some, it may take decades without ever even clicking.Also, you're wrong about \"upgrading one's workshop\" - it's a misconception that longtime Emacs users constantly have to tweak their configs. My config for example is pretty stable; I often make changes to it not because I have no choice, but because the task at hand calls for it. I write a lot of Lisp because it's an instrument for achieving specific goals and solving specific puzzles - work for which I get paid real amounts of real money. I get paid to use Emacs, not the opposite. So, no: definitely not a hobby.reply",
      "I do like having access to stuff while doing similar stuff. Perhaps I'm just a little too lazy to learn that stuff while still getting paid to know other stuff. And I do have just about every tool/feature you mentioned, just not in a single user interface.I guess the path to Emacs was more of a possibility/probability earlier in my career and I might find it later but for now I'll alt+tab to the browser and/or open a new tab when I need to look up any etymology and stick to navigating around Visual Studio like a pro while they still pay me to do it.reply",
      "The nice thing with emacs is that you can do as much or as little as you want with it. For me it started with basic text editing, then doing some git stuff with magit, then realizing emacs has wonderful capabilities around notetaking and to-do management in org-mode.Like you, though, I work in orgs that are very Windows heavy, so I tend to use it more for my personal stuff rather than in my day jobreply",
      "Yeah I know some folks who only really use it for basic text editing and org-mode notetaking. I know writers who only use it to write. I know coders who only use it to code. etc.reply",
      "Emacs is the WeChat of Gnu/Linux.reply",
      "How are you integrating with things like HN or your browser history?reply",
      "I'm glad you asked:https://www.youtube.com/watch?v=ud3Gmxg5UZg - Browsing Reddit and HackerNews In Emacs (7 minutes).If you don't want to watch it:https://github.com/thanhvg/emacs-hnreader - for browsing HN.https://github.com/thanhvg/emacs-reddigg - for browsing Reddit.https://github.com/agzam/consult-hn - for searching through HN.https://github.com/agzam/browser-hist.el - for browser history.reply"
    ],
    "link": "https://xenodium.com/emacs-as-your-video-trimming-tool",
    "first_paragraph": ""
  },
  {
    "title": "CRDT: Text Buffer (madebyevan.com)",
    "points": 60,
    "submitter": "skadamat",
    "submit_time": "2025-08-19T19:38:45 1755632325",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44955459",
    "comments": [
      "This is a pretty good description of RGA (Replicated Growable Array). Which is a list & text CRDT that works pretty well in practice. Automerge used to use this algorithm for text editing, before moving across to FugueMax.This algorithm has another obscure downside: It has interleaving problems if you insert items backwards. If two users do a series of inserts in reverse order, their inserts will get interleaved in a weird, unpredictable way. Eg, if I type \"aaaaa\" (as a series of prepended inserts) and you type \"bbbb\" in the same way, we can end up with \"ababababa\" or \"aabbabbaa\" some combination like that. We generally want CRDTs to be non-interleaving - so, \"aaaaabbbb\" or \"bbbbaaaaa\" should be the only possible results.This problem is fixed by FugueMax, described in \"The Art of the Fugue\" paper[1]. If you're thinking of implementing a text CRDT, I recommend starting there. Fuguemax is a tiny change from RGA. We swap out the sequence numbers for a \"right parent\" pointer and the problem goes away. Coincidentally, the algorithm is also a 1 line change away from Yjs's CRDT algorithm.And its really not that complicated. Most of the complexity in the fuguemax paper comes about because - like with RGA - they describe the algorithm in terms of inserts into a tree. If you ask me, this is a mistake. The algorithm is simpler if you primarily think of it as inserts into a list. (Thanks Kevin Jahns for this insight!) I programmed Fuguemax up live on camera a few months ago like this. You can fit a simple reference implementation of fuguemax in ~200 lines of code[2]. (The video is linked from the readme in that repository. In the video I explain the algorithm and all the code along the way).[1] https://arxiv.org/abs/2305.00583[2] https://github.com/josephg/crdt-from-scratch/blob/master/crd...reply",
      "(2024)reply"
    ],
    "link": "https://madebyevan.com/algos/crdt-text-buffer/",
    "first_paragraph": "\n    Collaboratively editing strings of text is a common desire in peer-to-peer applications. For example, a note-taking\n    app might represent each document as a single collaboratively-edited string of text.\n  \n    The algorithm presented here is one way to do this. It comes from a family of algorithms called\n    CRDTs, which I will not describe\n    here. It's similar to the approaches taken by popular collaborative text editing libraries such as\n    Yjs and Automerge.\n    Other articles have already been written about these similar approaches (see the\n    references section below), but this article also has a nice interactive visualization of\n    what goes on under the hood.\n  \nThe algorithm:\n\n        Each character is assigned a unique identifier consisting of site (the identifier of the creator)\n        and clock (a site-specific integer that is incremented after every operation) as well as a\n        (possibly null) parent pointer to a previous character.\n      \n        To insert "
  },
  {
    "title": "Without the futex, it's futile (h4x0r.org)",
    "points": 231,
    "submitter": "eatonphil",
    "submit_time": "2025-08-19T13:53:42 1755611622",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=44951563",
    "comments": [
      "Windows gained a WaitForMultipleObjects, which Linux 5.16 (end 2021) aped with a new Futex2.\nhttps://www.phoronix.com/news/Linux-5.16-sys_futex_waitvThere's been a nice stream of improvements to futex2 since.NUMA support (finally landing!),\nhttps://www.phoronix.com/news/FUTEX2-NUMA-Small-Futex\nhttps://www.phoronix.com/news/FUTEX2-Improvements-Linux-6.16 (see also this fantastic recent submission on NUMA in general, absolutely critical performance stuff, https://news.ycombinator.com/item?id=44936575)Io_uring support in 6.7 (2024), (with a nice write up on it speeding up postgresql aio),\nhttps://www.phoronix.com/news/IO_uring-FUTEX-Linux-6.7Small requeue and single wait additions in 6.7,\nhttps://www.phoronix.com/news/Linux-6.7-Locking-FUTEX2reply",
      "Windows did not gain a WaitForMultipleObjects, it had it since the first Windows NT, more than 30 years ago.While WaitForMultipleObjects was an advantage of Windows NT over UNIX, it was nothing new. IBM PL/I had an equivalent function already in 1965, almost 30 years before Windows NT.The \"wait\" function of IBM PL/I was actually the model for the UNIX \"wait\", but the UNIX function was extremely simplified and much weaker than its model, like it was also the case with the many features inherited by UNIX from Multics. Unfortunately, many decades had to pass until the descendants of UNIX began to gain features comparable in sophistication with those of the ancestors of UNIX.However the Microsoft WaitForSingleObject and WaitForMultipleObjects did not have an efficient implementation, which is why they had to add WaitOnAddress, the equivalent of Linux futex.It is true however that the Linux futex had and still has some annoying limitations, like the size of only 32 bits of the futex value, instead of 64 bits, and the fact that it is possible to wait only on a single event. Using atomic bit operations on the futex value it is actually possible to wait on multiple events, though not in the most efficient way. However here is where the 32-bit size of the futex value becomes annoying.Therefore the work that attempts to combine the advantages of \"futex\" with some of the advantages of WaitForMultipleObjects is very welcome.However this does not ape Windows, but it just reimplements techniques that are much older than the Microsoft company, which were well known more than a half of century ago.reply",
      ">However the Microsoft WaitForSingleObject and WaitForMultipleObjects did not have an efficient implementation, which is why they had to add WaitOnAddressWaitForSingle/MultipleObjects wait for kernel objects, similiar to poll. WaitOnAddress is lightweight synchronization, equivalent to futex. Windows doesn't have something like WaitForMultipleAddresses. futex_waitv was used by Wine patches because they implement NT kernel objects in userspace, and there were some semantic differences that made it hard to represent them as eventfds.PS: But using futexes to emulate kernel objects breaks security boundaries of a process. That's why it was never merged into upstream Wine, and NTSYNC was developed.reply",
      "That's very interesting history, thanks.I agree with Linux still only supporting 32-bit futexes is a bit baffling. The only reason the width matters is for the race condition check, but that's a huge reason. I'd want to have the option to wait on values as wide as whatever the underlying hardware supports, at least!reply",
      "The futex width matters if you implement your own waiting on multiple events, with one bit per event. The events can be signaled with atomic bit operations.reply",
      "Ideally the value should be two words -- 16 bytes on 64-bit systems.reply",
      "Emm, what? Why? If you mean two processor words, which I gather from what you are saying, then I think you are already in the space of full memory barriers.In that case, why not just say, ideally it would be 256K words, or whatever?reply",
      "Because mainstream modern architectures (practically speaking, x86-64-v2+ and ARMv8+) give you[1] a two-word compare-and-swap or LL/SC.[1] https://ibraheem.ca/posts/128-bit-atomics/reply",
      "One thing to add here, I've enjoyed reasonably extensive support for `atomic_compare_exchange_strong()` and the `_explicit` variant for quite a long time (despite the need for the cache line lock on x86).But, last I checked (the last release, early last year) MUSL still does not provide a 128 bit version, which is disappointing, and hopefully the AVX related semantics changes will encourage them to add it? :)reply",
      "Because there are apps that use two-word pass/return-by-value values internally, so it'd be convenient.reply"
    ],
    "link": "https://h4x0r.org/futex/",
    "first_paragraph": "Pick your topicPhil Eaton\u2019s book club is starting\nThe Art of Multiprocessor Programming, 2nd Edition\n, which is a very well regarded textbook, and pretty recently updated (2021). I\u2019ve even heard of a couple of authors.I\u2019ve done a lot of concurrent programming, and have always felt like I\u2019ve still got plenty to learn, so I was excited for the topic. So far, what I\u2019ve learned is that I would never recommend this book, despite any merits.Academia certainly struggles to find the right balance between teaching foundational principles and practical information. Being this book is explicitly targeting fourth-year undergraduates and grad students, it should definitely cover the fundamentals, right?So how the heck could it not cover the futex??The name sure sounds like \u201cmutex\u201d, and that is where the name comes from: \u201cfast, user space mutex\u201d. But, it isn\u2019t really, it\u2019s a building block for concurrency primitives that ushered in a modern world of concurrent performance that makes System V (sysv) "
  },
  {
    "title": "Show HN: OpenAI/reflect \u2013 Physical AI Assistant that illuminates your life (github.com/openai)",
    "points": 46,
    "submitter": "Sean-Der",
    "submit_time": "2025-08-19T19:48:38 1755632918",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=44955576",
    "comments": [
      "Somewhere in here there's a joke about how many tokens it takes to turn on a lightbulb.reply",
      "It deserves a minor rewrite of the Black Mirror episode Fifteen Million Merits where people do menial labor like folding laundry and washing dishes to earn tokens so that their LLM will dispense their toothpaste and send Studio Ghibli stylized birthday cards to their friends.reply",
      "inb4: When sama and co talk about UBI, they mean a variation of it based around a memecoin tethered/indexed on (tik)tokens.reply",
      "https://en.wikipedia.org/wiki/World_(blockchain)reply",
      "Probably 1,000 for the system prompt, 400 for the audio speech-to-text, 8 for the query, 180 for the thinking, 12 for the tool call, 33 for the response with a useless follow-up questionreply",
      "All to achieve something that could be done with a Raspberry Pi. You could do all this locally too.https://gist.github.com/mgarratt/afb3b57a08e2eb2479eb6083a86...https://www.xda-developers.com/ollama-ai-comparison-raspberr...https://www.xda-developers.com/raspberry-pi-voice-assistant-...https://www.youtube.com/watch?v=o1sN1lB76EAreply",
      "I also have been working with Daily on https://github.com/pipecat-ai/pipecat-esp32I see so much potential if I can make hardware hacking + WebRTC easy. Not just for AI assistants but security cameras + robotics. If anyone has questions/ideas/feedback here to help :)reply",
      "what is Daily?reply",
      "https://www.daily.co/You can use it to build lots of different real-time communication projects. Conferencing, Send your audio/video to GPU servers for AI, broadcasting and lots more.It\u2019s a super fun space to be inreply",
      "Are there any cool demos that use daily I can explore?reply"
    ],
    "link": "https://github.com/openai/openai-reflect",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Physical AI Assistant that illuminates your life\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.CautionThis is a demo/hackathon project. This code is provided as-is without any warranty or guarantees.\nIt has not been extensively reviewed for security, reliability, or fitness for any purpose.\nUse at your own risk.Reflect is a hardware AI Assistant that was built during a OpenAI hackathon.\nCurrently it is built to target espressif devices, but we hope to expand\nits capabilites if users find it useful. The following were some of the\nideas/inspirations during the project.video demonstration of the device.We hope to expand this list. Reflect was written for a specific device to start, but if it is useful we want to add more.The device creates a WiFi Access Point"
  },
  {
    "title": "Candle Flame Oscillations as a Clock (cpldcpu.com)",
    "points": 243,
    "submitter": "cpldcpu",
    "submit_time": "2025-08-16T07:49:51 1755330591",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=44921195",
    "comments": [
      "In the late 1980s I did an electrical engineering internship in a coal-fired power station over summer vacation. The gas furnace igniters ran continuously, but how do you detect presence or absence of burner flames against semi-apocalyptic background of ignited pulverised coal dust being air-blasted into the furnace? Have a little window and photosensor pointing at the burner flame and FFT. No spectral component spike at xHz (IIRC x ~= 13? -- it's a burner flame, underlying dynamics not same as for candle wick) --> ringing alarms, flashing lights.reply",
      "What was the preferred way of doing FFT at that time?reply",
      "hasn't the preferred way been Cooley-Tukey consistently since 1965?https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algor...reply",
      "Bingo. We certainly learned about Cooley-Tukey in undergrad back then. That power station was 100% Hitachi Heavy Industries turnkey. The control rooms had Hitachi mainframe and some minicomputers running proprietary real time OS (I guess). These were the days when the video controller for a colour industrial process control raster display CRT was a waist-high cabinet. So you'd transduce the flicker and then transmit it via analogue current loop to a rack in the control room annex, convert back to voltage, A/D it... and crunch the FFT on one of the control room computers. Something like that. Cheap distributed compute just wasn't a thing at the time.reply",
      "this is so cool, thanks for sharing :)reply",
      "From the article:> A fascinating fact is that the oscillation frequency is rather stable at ~9.9Hz as it mainly depends on gravity and diameter of the flame.This reminds me of when I first heard about Dolbear's law by which you can get an approximate measurement of the air temperature using the number of chirps per minute from a cricket.https://en.wikipedia.org/wiki/Dolbear%27s_lawreply",
      "Very interesting article from the same guy where he reverse engineers the randomness of a flicker LED.https://cpldcpu.com/2013/12/08/hacking-a-candleflicker-led/reply",
      "> Now, it\u2019s a curious thing that we try to emulate the imperfections of candles. After all, candle makers have worked for centuries (and millennia) on optimizing candles NOT to flicker?This reminds me of teenage me circa 1990 exploring electric guitar distortion and having an interesting conversation w/ my dad, who'd done a pretty serious paper on eliminating audio distortion as part of his CSEE degree from MIT.reply",
      "I was today years old when I learned that the frequency of a flicker candle flame is ~9.9Hz :-)reply",
      "That is awesome. And I am so sad an individual that my first thought was of a software plug-in that would use this frequency to generate realistic candle-flicker effects.reply"
    ],
    "link": "https://cpldcpu.com/2025/08/13/candle-flame-oscillations-as-a-clock/",
    "first_paragraph": "Tim's BlogTodays candles have been optimized for millenia not to flicker. But it turns out when we bundle three of them together, we can undo all of these optimizations and the resulting triplet will start to naturally oscillate. A fascinating fact is that the oscillation frequency is rather stable at ~9.9Hz as it mainly depends on gravity and diameter of the flame.\u00a0We use a rather unusual approach based on a wire suspended in the flame, that can sense capacitance changes caused by the ionized gases in the flame, to detect this frequency and divide it down to 1Hz.Candlelight is a curious thing. Candles seem to have a life of their own: the brightness wanders, they flicker, and they react to the faintest motion of air.There has always been an innate curiosity in understanding how candle flames work and behave. In recent years, people have also extensively sought to emulate this behavior with electronic light sources. I have also been fascinated by this and tried to understand real candl"
  },
  {
    "title": "AGENTS.md \u2013 Open format for guiding coding agents (agents.md)",
    "points": 67,
    "submitter": "ghuntley",
    "submit_time": "2025-08-20T00:15:03 1755648903",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=44957443",
    "comments": [
      "This should've been an .agents\u00b9 with an index.md.For tiny, throwaway projects, a monolithic .md file is fine. A folder allows more complex projects to use \"just enough hierarchy\" to provide structure, with index.md as the entry point. Along with top-level universal guidance, it can include an organization guide (easily maintained with the help of LLMs).  index.md\n  \u251c\u2500\u2500 auth.md\n  \u251c\u2500\u2500 performance.md\n  \u251c\u2500\u2500 code_quality\n  \u251c\u2500\u2500 data_layer\n  \u251c\u2500\u2500 testing\n  \u2514\u2500\u2500 etc\n\nIn my experience, this works loads better than the \"one giant file\" method. It lets LLMs/agents add relevant context without wasting tokens on unrelated context, reduces noise/improves response accuracy, and is easier to maintain for both humans and LLMs alike.\u00b9 Ideally with a better name than \".agents\", like \".codebots\" or \".context\".reply",
      "Been using a similar setup, with so far pretty decent results. With the addition of having a short explanation for each file within index.mdI've been experimenting with having a rules.md file within each directory where I want a certain behavior. Example, let us say I have a directory with different kind of services like realtime-service.ts and queue-service.ts, I then have a rules.md file on the same level as they are.This lets me scaffold things pretty fast when prompting by just referencing that file. The name is probably not the best tho.reply",
      "I am developing a coding agent that currently manages and indexes over 5,000 repositories. The agent's state is stored locally in a hidden `.agent` directory, which contains a configuration folder for different agent roles and their specific instructions.\nThen we've a \"agents\" folder with multiple files, each file has<Role> <instruction>Agent only reads the file if its role is defined there.Inside project directory, we've a dot<coding agent name> folder where coding agents state is stored.Our process kicks off with an `/init` command, which triggers a deep analysis of an entire repository. Instead of just indexing the raw code, the agent generates a high-level summary of its architecture and logic. These summaries appear in the editor as toggleable \"ghost comments.\" They're a metadata layer, not part of the source code, so they are never committed in actual code. A sophisticated mapping system precisely links each summary annotation to the relevant lines of code.This architecture is the solution to a problem we faced early on: running Retrieval-Augmented Generation (RAG) directly on source code never gave us the results we needed.Our current system uses a hybrid search model. We use the AST for fast, literal lexical searches, while RAG is reserved for performing semantic searches on our high-level summaries. This makes all the difference. If you ask, \"How does authentication work in this app?\", a purely lexical search might only find functions containing the word `login` and functions/classes appearing in its call hierarchy. Our semantic search, however, queries the narrative-like summaries. It understands the entire authentication flow like it's reading a story, piecing together the plot points from different files to give you a complete picture.It works like magic.reply",
      "We're in a transition phase today where agents need special guidance to understand a codebase that go beyond what humans need. Before long, I don't think they will. I think we should focus on our own project documentation being comprehensive (e.g. the contents of this AGENTS.md are appropriate to live somewhere in our documentation), but we should always write for humans.The LLM's whole shtick is that it can read and comprehend our writing, so let's architect for it at that level.reply",
      "It's not just understanding the codebase, it's also stylistic things, like \"use this assert library to write tests\", or \"never write comments\", or \"use structured logging\". It's just as useful --- more so even --- on fresh projects without much code.reply",
      "... most of which would also be valuable information to communicate when onboarding new devs.reply",
      "Yeah I agree. I think the best place for all this lives in CONTRIBUTING.md which is already a standard-ish thing. I've started adding it even to my private projects that only I work on - when I have to come back in 3 or 4 months, I always appreciate it.reply",
      "If there were already a universal convention on where to put that stuff, then probably the agents would have just looked there. But there's not, so it was necessary to invent one.reply",
      "Reality is just that people neglected onboarding docs until LLM-based coding agents put them in a position to directly benefit from having more knowledge of the codebase explicitly written down.",
      "One of the most common usages I see from colleagues is to get agents to write the comments so you can go full circle. :)reply"
    ],
    "link": "https://agents.md/",
    "first_paragraph": "A simple, open format for guiding coding agents,used by over 20k open-source projects.Think of AGENTS.md as a README for agents: a dedicated, predictable place to provide the context and instructions to help AI coding agents work on your project.README.md files are for humans: quick starts, project descriptions, and contribution guidelines.AGENTS.md complements this by containing the extra, sometimes detailed context coding agents need: build steps, tests, and conventions that might clutter a README or aren\u2019t relevant to human contributors.We intentionally kept it separate to:Give agents a clear, predictable place for instructions.Keep READMEs concise and focused on human contributors.Provide precise, agent-focused guidance that complements existing README and docs.Rather than introducing another proprietary file, we chose a name and format that could work for anyone. If you\u2019re building or using coding agents and find this helpful, feel free to adopt it.Your agent definitions are compa"
  },
  {
    "title": "How Figma\u2019s multiplayer technology works (2019) (figma.com)",
    "points": 108,
    "submitter": "redbell",
    "submit_time": "2025-08-16T11:41:02 1755344462",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=44922362",
    "comments": [
      "Linear's write ups / talks on real-time sync are also very good, if a bit old now.1. https://www.youtube.com/watch?v=WxK11RsLqp4&t=2169s2. https://linear.app/now/scaling-the-linear-sync-engineAlso see this overview of related tech here:3. https://gist.github.com/pesterhazy/3e039677f2e314cb77ffe3497...And c.f. automerge from ink & switch:4.https://automerge.org/blog/reply",
      "Just to say if you're interested in this kind of tech and are in the Bay Area, Sync Conf [0] just announced [1] its initial speaker lineup today and Arushi Bandi from Figma is one of the speakers.[0]: https://syncconf.dev\n[1]: https://x.com/sync_conf/status/1957818840777122293reply",
      "Doesn\u2019t Google docs and MS 365 have very similar tech?reply",
      "https://github.com/croquet/croquet makes all of this dead simple, without the need for any backend code/servers/databases/CRDTs &etchttps://multisynq.io if you want a worldwide reflector network.reply",
      "This is still a hard problem today. Some hard tech was built for this. I'm excited for a world where this is more accessible and less hardcore than something like CRDTs (in terms of accessibility).How have others noticed the world shifting in the past 6 years?reply",
      "There are now a few sync engines that tackle this problem. Rocicorp Zero, Electric SQL, and one or two others. By no means a crowded space, but there are options now.edit: links  https://zero.rocicorp.dev/\n  https://electric-sql.com/reply",
      "Sharedb/racer solved this like 10yrs ago. You get synchronized snapshots, conflict resolition, diffs, change tracking..reply",
      "I know Liveblocks.io has been making this very easy and accessible over the last few years. They recently introduced AI, and are promoting that of course, but as I understand it multiplayer collaboration (https://liveblocks.io/multiplayer-editing) is their meat and potatoes.Not affiliated with Liveblocks, just aware of its existence.reply",
      "There were some additional posts regarding the topic by same guy. \nhttps://hachyderm.io/@evanwInnovators like him, are very rare.reply",
      "Elixir's Phoenix LiveView + PubSub covers a lot of these bases out of the box.reply"
    ],
    "link": "https://www.figma.com/blog/how-figmas-multiplayer-technology-works/",
    "first_paragraph": ""
  },
  {
    "title": "AnduinOS (anduinos.com)",
    "points": 73,
    "submitter": "TheFreim",
    "submit_time": "2025-08-19T18:42:25 1755628945",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=44954823",
    "comments": [
      "I made it half way down the page before I realized this wasn\u2019t \u201cArduinOS\u201d.I can\u2019t be the only one.reply",
      "Yeah, I clicked expecting it to be some madman who made a multitasking kernel for Arduino. What I actually got wasn't nearly as exciting.reply",
      "Same. Now, however: https://news.ycombinator.com/item?id=44955159reply",
      "Thanks. That's what I was hoping this was as I also mis-read it.reply",
      "Same but then I saw \"only 2 GB image\"reply",
      "At first I thought it must have been a typo\u2026reply",
      "https://en.wikipedia.org/wiki/List_of_Arduino_boards_and_com...Some of them are powerful enough that they could probably run a full desktop Linux comfortably.reply",
      "That's what I thought too at firstreply",
      "That\u2019s some mentally-induced bad keming right there.reply",
      "I think it's more of a parafoveal processing effect in contextual word recognition.reply"
    ],
    "link": "https://www.anduinos.com/",
    "first_paragraph": "AnduinOS is a custom Ubuntu-based Linux distribution that offers a familiar and easy-to-use experience for anyone moving to Linux.Smaller image, friendly interface, unbeatable performance, safe and secure.\n            The ISO is just 2.0GB in size. Similar to Ubuntu, it is simple to install and can meet your daily needs without additional configuration or complicated operations.The GNOME-based desktop environment have beautiful interfaces and human-computer interactions that fit user habits, allowing you to quickly get started with AnduinOS without too much learning cost.Privacy is no longer optional. It's essential. AnduinOS is designed to gather nothing from you. We don't track you. We don't profile you. We don't target you. You remain anonymous to the system.AnduinOS is based on Ubuntu's package base. It's compatible with most of the apt packages from Ubuntu. It's a perfect combination of experience and ecology.AnduinOS is an open-source project. Following the GPL-v3 license, you ca"
  },
  {
    "title": "Why Semantic Layers Matter (and how to build one with DuckDB) (motherduck.com)",
    "points": 88,
    "submitter": "secondrow",
    "submit_time": "2025-08-19T16:49:15 1755622155",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=44953575",
    "comments": [
      "Impressive! An entire article about semantic layers, artfully avoids ever defining what a semantic layer is.Let me take a swipe at it: a semantic layer helps express queries and their results in terms the end-consumers will care about / prefer to reason in, instead of whatever extremely correct and efficient atrocities the database nerds came up with.Did I get that right?reply",
      "Sounds good to me! Semantic layers help expose a more user-friendly view of the data, so it is easier to ask business questions and get accurate results. More technically, it brings modularity and reusability to SQL. Things like joins, aggregate functions, and dimensional expressions are encapsulated as new fields/objects. Typically this logic is rendered at query time rather than pre-computed and materialized. The advantage of that is more flexible iteration and composability. In essence they are highly glorified SQL templating engines.reply",
      "I love a semantic layer as much as the next guy...Pivoting a decent sized BI shop toward using one instead of splashing the same SQL all over the place is *tough*. It's one of those: \"the analyst could have been building important report for director and you want them to create re-usable logic??? we'll do that later, get report done now. Just copy/paste that SQL over here\"This is how you end up with the the 1000 model, \"the numbers don't match up\", hot mess situations that gain momentum and are hard to slow down.reply",
      "That tracks. The semantic layer is like a capital investment that pays off over time. So it can be hard to justify the initial investment if people don't grok the payoff.reply",
      "this is why I liked Looker. The only way to build reports was from the semantic layer which was easy to use and built into the BI.we took the same approach when we started https://www.definite.app/.reply",
      "The flip side is, you often don\u2019t know what needs to be reusable until you\u2019ve had some iterations. Wrong abstractions can be way worse, and also gain their own momentum.reply",
      "The problem is that often these quick or maybe not reusable are written in such a haste that there's no breadcrumbs left to do the right thing whenever you are done getting that urgent thing out (most likely never because \"everything is urgent\" :( )reply",
      "Yeah, I think it's great that there are ARD formats and you can access bytes via low level s3 like protocol. This enables interesting tools like DuckDB which can abstract away some stuff, and be fastish and \"serverless\". However, clearly there is also some kind of marketing hype train and jargon built around it, and it seems like a concerted movement to displace some other \"boring\" and \"uncool\" products and technologies. I actually think it's great to displace proprietary services with open formats and protocols. I hope it takes out \"data lakes\" and co, but I'd love to keep MVC and not invent completely new terms, APIs and ORMs, for things that have been working fine, for a long time.reply",
      "Is a \"semantic layer\" nothing more than a fancy name for a SQL VIEW in a NoSQL?reply",
      "No, it's more than that.Semantic Layer is about decomposing views into dimensions and aggregates, then letting downstream apps/users compose their own views on top without having to redefine/re-calculate business level metrics.This makes data analyis more flexible than sql views which are hardcoded on particular groupings.reply"
    ],
    "link": "https://motherduck.com/blog/semantic-layer-duckdb-tutorial/",
    "first_paragraph": "Authors of 5 O'Reilly Books are Speaking at Small Data SFJoin Us2025/08/19 - 21 min readMany ask themselves, \"Why would I use a semantic layer? What is it anyway?\" In this hands-on guide, we\u2019ll build the simplest possible semantic layer using just a YAML file and a Python script\u2014not as the goal itself, but as a way to understand the value of semantic layers. We\u2019ll then query 20 million NYC taxi records with consistent business metrics executed using DuckDB and Ibis. By the end, you\u2019ll know exactly when a semantic layer solves real problems and when it\u2019s overkill.It's a topic that I'm passionate about as I've been using semantic layers within a Business Intelligence (BI) tool for over twenty years, and only recently have we gotten full-blown semantic layers that can sit outside of a BI tool, combining the advantages of a logical layer with sharing them across your web apps, notebooks, and BI tools. With a semantic layer, your revenue KPI or other complex company measures are defined onc"
  },
  {
    "title": "How to Scale Your Model: How to Think About GPUs (jax-ml.github.io)",
    "points": 17,
    "submitter": "matt_d",
    "submit_time": "2025-08-19T22:17:38 1755641858",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jax-ml.github.io/scaling-book/gpus/",
    "first_paragraph": "Part 12 of How To Scale Your Model (Part 11: Conclusion | The End)We love TPUs at Google, but GPUs are great too. This chapter takes a deep dive into the world of NVIDIA GPUs \u2013 how each chip works, how they\u2019re networked together, and what that means for LLMs, especially compared to TPUs. This section builds on Chapter 2 and Chapter 5, so you are encouraged to read them first.A modern ML GPU (e.g. H100, B200) is basically a bunch of compute cores that specialize in matrix multiplication (called Streaming Multiprocessors or SMs) connected to a stick of fast memory (called HBM). Here\u2019s a diagram:Each SM, like a TPU\u2019s Tensor Core, has a dedicated matrix multiplication core (unfortunately also called a Tensor CoreThe GPU Tensor Core is the matrix multiplication sub-unit of the SM, while the TPU TensorCore is the umbrella unit that contains the MXU, VPU, and other components.), a vector arithmetic unit (called a Warp SchedulerNVIDIA doesn't have a good name for this, so we use it only as the"
  },
  {
    "title": "Custom telescope mount using harmonic drives and ESP32 (svendewaerhert.com)",
    "points": 262,
    "submitter": "waerhert",
    "submit_time": "2025-08-19T09:46:27 1755596787",
    "num_comments": 96,
    "comments_url": "https://news.ycombinator.com/item?id=44949895",
    "comments": [
      "Amazing project and write up, very good timing too! I\u2019ve been into amateur astronomy since I was 13, owning a few telescopes and spending many hours with family at star parties.This week I pulled out our big Meade 10\u201d SCT and our small Meade 4\u201d Newtonian to show my 7yo son the moon and Saturn from my parents Bortle 8 backyard. It was wonderful seeing his awe and surprise, and the fact that my parents were there to see it too.That 10\u201d SCT is on an old fork mount which is motorized but has no GOTO capabilities at all. I\u2019ve also gone down the rabbit hole of researching mount options, thinking I could just buy my way out of it. However, as much as I like the idea of GOTO, a big part of the fun is finding the objects. So I\u2019ve never been able to pull the trigger. I did buy a ZWO 585MC though, I\u2019ve always wanted a dedicated cooled camera.That said, we have lost way too many hours to trying to find objects. The Telrad isn\u2019t always enough!I\u2019ve been looking into using my 3D printer and electronics know-how to build my way out of this. I was even thinking of swapping the motors for NEMA 17 steppers.Then I stumbled upon PiFinder, and I think this project is going to be the exact balance of automation and Push-to guidance that I would like.https://www.pifinder.io/It\u2019s a wonderful hobby and I think the latest in 3D printing and PCB manufacturing does mean we\u2019re going to be able to solve a lot of these problems soon.reply",
      ">However, as much as I like the idea of GOTO, a big part of the fun is finding the objects.I love reading this because it shows how different people are and how much room there is in the hobby for different interests.  I am grateful for goto mounts specifically because finding the object is one of my least favorite parts of it. :Dreply",
      "Thanks! If you hook your ZWO up to Kstars/EKOS you can use plate-solving in software to find out exactly where your scope is pointed at and then adjust accordingly.reply",
      "From the blog: \"Not surprising once you understand that slewing to a target significantly increases the number of pulses per second sent to the motors, and everything became just too much to handle for our little ESP32.\"A hobby application of mine involves driving multiple steppers at high-ish frequencies, following sigmoid curves precisely and no tolerance for glitches, because the mass and the cost of the device(s) is too great to risk any failure in pulse output, and there is no feedback, so I must not suffer \"missed\" steps, glitches, etc.  The big hammer that solves this is obviating the MCU core (ARM or otherwise,) in motion control and using timer peripherals with DMA.Ultimately, I ended up turning to STM32G4 MCUs because of the ACT (advanced control timer) peripheral.  These timers can generate arbitrary waveforms using DMA in a relatively simple manner: the ARM core and its code/RTOS/whatever can suffer whatever overload, priority inversion, sleep mode, etc. happens to emerge, and the timers are unaffected.Today I would consider using RP2350 and the PIO peripheral, which is also capable of achieving this, I believe.ESP32 has its MCPWM peripheral, but I determined that with MCPWM you can't do the sort of arbitrary acceleration/deceleration profiles I needed in a 100% \"core-free\" manner without either a.) cascading timers or b.) using interrupts.  The former is, comparatively speaking, complex[1], and the later gets you back into the MCU core, and possible glitches[2].  With the ST ACT peripheral, the problem is self contained to one timer per motor: simple and straightforward.  At least one of their MCUs has three of those timers (G474, in larger packages, for example.)The other way to go is specialized motor driver ICs.  Analog Devices, by way of their Trimanic line of devices and low cost breakout boards, has great products there, widely used with 3D printers, CNC and similar.  The driver software is much more complex than my simple ACT peripheral solution, however.[1] I know it's possible and others have done it.  The ST peripheral is far easier to get working and get right, if you can deal with CMSIS and the ST reference manual.[2] I know about interrupt priorities.  I also know about code evolution, bugs and other ways that dealing in interrupt priorities can get fragile.reply",
      "OnStepX is very much pulse based as far as I understand it. I haven't encountered offloading techniques like you mentioned yet. Since both motors support (multiturn) positon modes, it should be possible to completely forego the pulsebased approach and only drive the motors using regular (and less frequent in comparison to pulses) position instructions over CANBUS. I spent some time reading the code in OnStepX to understand how to implement it in this way but hooking it up in pulsemode was just too easy to get started.reply",
      "> it should be possible to completely forego the pulsebased approach and only drive the motors using regular (and less frequent in comparison to pulses) position instructionsSince that capability is present, it's probably worth your while to apply it.  Good motion control is hard, but important.  Unnecessary vibration due to phase noise in the pulse train is an example of the subtleties that matter at high frequency.  Excessive force generated when moving large masses can prematurely wear drive components and, over time, backlash increases and you get precision and repeatability problems.  Well managed motion control will mitigate these things.reply",
      "One tiny nit on this amazing project / write up. He mentions that the traces have to be extra wide to support 24V. In truth though, the higher voltage means lower current, which means if anything the traces can be less wide. The size of the traces is determined by the current they carry, the voltage determines how much space must be between the traces (but it\u2019s unlikely to be an issue at these voltages).reply",
      "The IPC-2221A[1] specification standard, should have all the sizes/voltages/current for trace widths etc.[1] https://www-eng.lbl.gov/~shuman/NEXT/CURRENT_DESIGN/TP/MATER...reply",
      "Good catch and explanation!reply",
      "I've been using freeCAD for about 3 years now. Looking at what he was able to make with it blows my mind. I love freeCAD, but I don't think I've ever been so continuously frustrated by a piece of softwarereply"
    ],
    "link": "https://www.svendewaerhert.com/blog/telescope-mount/",
    "first_paragraph": "TL;DR \u2192A few years back, I developed an interest in astrophotography thanks to YouTubers like Nebula Photos. Armed with an OM System OM-5 and a 15-140mm Olympus lens, I managed some decent shots of the Orion Nebula from a tripod by taking 300 pictures with a 2-second exposure time and stacking them in Siril.Knowing I could achieve better results with tracking, I bought a Move Shoot Move tracker for around \u20ac200. It delivered longer exposures, but finding targets and achieving proper polar alignment remained challenging. I spent countless hours researching proper telescope mounts with GOTO and tracking capabilities, coming close to pulling the trigger on units ranging from \u20ac1,200 to \u20ac4,000. For a hobby I was still exploring, that investment always felt like a leap too far.Late 2024 I randomly came across this YouTube video about custom PCB design in my feed, and I was hooked immediately.With a decent collection of microcontroller boards, the idea of ditching messy breadboards for clean, "
  },
  {
    "title": "Fast Type-Aware Linting in Oxlint (oxc.rs)",
    "points": 14,
    "submitter": "manniL",
    "submit_time": "2025-08-18T09:35:33 1755509733",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://oxc.rs/blog/2025-08-17-oxlint-type-aware",
    "first_paragraph": "AppearanceOxlint Type-Aware PreviewOxlint v1.0 StableOxlint BetaMinifier AlphaOxlint v0.10 ReleaseTransformer AlphaOxlint Import Plugin AlphaOxlint General AvailabilityBoshenProject LeadauvredtsgolintCamMemberCameronCoreWe're thrilled to announce type-aware linting in oxlint!The long-awaited no-floating-promises and related rules are here.This preview release aims to engage with the community for collaboration and discussion by documenting our decision process and technical details.If oxlint is already configured, install oxlint-tsgolint and run oxlint with the --type-aware flag:If oxlint is not configured but you want to see no-floating-promises in action:We expect to see, for example:Please visit our usage guide for more configuration options.Our testing shows that repositories which previously took a minute to run with typescript-eslint now complete in less than 10 seconds.This is achieved by leveraging typescript-go, the 10x faster TypeScript written in Go.Using projects from oxlin"
  },
  {
    "title": "The joy of recursion, immutable data, & pure functions: Making mazes with JS (jrsinclair.com)",
    "points": 50,
    "submitter": "jrsinclair",
    "submit_time": "2025-08-18T07:57:30 1755503850",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44938354",
    "comments": [
      "Kind of amusing and maybe telling that this article about implementing an algorithm functionally begins by explaining it in an iterative, mutational fashion.reply",
      "If you enjoyed that, I have a blog post on generating mazes in Haskell (from over a decade ago!). The algorithm is very similar, but the code is written using \"inductive graphs\" and the post is really more of an intro to working with graphs in a purely functional style.https://jelv.is/blog/Generating-Mazes-with-Inductive-Graphsreply",
      "I'm slightly horrified by the memory leak that's casually introduced without even a remark as to the potential to cause a problem. I can't tell if I'm more horrified by the cavalier attitude or the fact that JavaScript makes having a global registry the only easy way to use an object of an arbitrary type as a key to Map.But at the very least, if you're going to memoize immutable values, please do it in a way that allows garbage collection. JavaScript has WeakRef and FinalizationRegistry. (Why it doesn't provide the obvious WeakCache built on those is a mystery, though.)The issues won't be visible on a toy example like making mazes a few hundred elements across, but if you use these techniques on real problems, you absolutely need to cooperate with the garbage collector.reply",
      "Probably better to use an LRU cache rather than weak maps.reply",
      "No because then you lose the ability to compare objects for equality.reply",
      "Nice animation on the maze building algo.I remember trying to use Immutable.js back in the day. It's probably pretty great with Typescript these days, but I remember it was kinda hell with vanilla JS back then since I'd accidentally do things like assign `thing.foo = 42` instead of `thing.set('foo', 42)` and I'd comb through the code to see why it wouldn't work, and I remember not knowing when I had a JS object or a Record. All things fixed by Typescript, of course.reply",
      "I\u2019m still sad that JS doesn\u2019t have tail call optimization. I\u2019ve always wondered why. Is it hard to implement?reply",
      "If my memory serves right, the browser vendors couldn't agree on the implementation.On the one hand, allowing any function to be eligible for TCO means that the developer won't know if the code was optimized or not. A trivial change can easily convert a fast function to one that blows the stack. Additionally, every function created- or at least every named function- would need to be analyzed, causing a performance hit for everyone, even those who never write a recursive function in their lives.On the hand, some argued that TCO eligibility should be explicitly opt-in with some sort of keyword or annotation. If a function so annotated did not end up being a valid target for TCO, the script would not compile, similar to a syntax error. This is an even more harsh failure mode than the implicit version, but would have been easier to identify.I vaguely recall chrome devs generally being in favor of explicit annotations, and Safari implicit. I could be completely wrong on this, and I don't think anyone was particularly enthused about the trade-offs either way.reply",
      "People are too addicted to automatic stack traces for mainstream languages to optimize away stack frames.reply",
      "It does if you use JavaScriptCore (Safari, other Webkit browsers, Bun).reply"
    ],
    "link": "https://jrsinclair.com/articles/2025/joy-of-immutable-data-recursion-pure-functions-javascript-mazes/",
    "first_paragraph": "This post is based on a talk I presented at Web Directions Summit, 2024.Let\u2019s start by addressing the elephant in the room. Why the heck am I talking about making mazes?Normally, I try to be practical when I\u2019m writing or speaking. I want to give people tools they can use to make their coding lives better. So, I try to discuss things like creating DOM elements and processing JSON data. Because those things are practical. I would rather not waste people\u2019s time on things they\u2019re not going to use.But, mazes, they\u2019re not so practical.Unless you\u2019re working in game development, it\u2019s unlikely that you\u2019re going to need a maze in your web app. So, in that sense, knowing how to build a maze is useless. You\u2019re never going to use it.However, the nice thing about generating mazes is that they\u2019re a challenge. A challenge that\u2019s not too big, and not too small. You see, an issue I often have is that people ask me for \u2018real world\u2019 examples. But the trouble with \u2018real world\u2019 examples is that they\u2019re comp"
  }
]