[
  {
    "title": "Project ideas to appreciate the art of programming (codecrafters.io)",
    "points": 101,
    "submitter": "vitaelabitur",
    "submit_time": "2025-12-30T22:47:36 1767134856",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=46439027",
    "comments": [
      "Build something intentionally small and complete a tiny tool or protocol you can understand end-to-end. The satisfaction comes from clarity, constraints, and finishing the whole arc, not scale.reply",
      "I\u2019ll plug my series of project ideas that have also been discussed here on HN over the years: Challenging programming projects every programmer should tryhttps://austinhenley.com/blog/challengingprojects.htmlreply",
      "I've seen your list before and find it much easier to appreciate than the OP tbh. It is very concise, the descriptions actually describe what one might learn or struggle with and each project comes with resources to get started with (One day i might even get around to doing one of these ;)The OP very much comes off to me as a \"here are 100 books you need to read before you die\" recommendation porn type of post where the author has done none of the things listed.reply",
      "The OP link feels like a list you scroll until you see something that interests you, and you jump on that. An ideaboard.The link in this chain feels like a mini-curriculum. AKA \"you do all these 7 things and you'll probably become very good at any job\". a decent university will probably have you do 4-5 out of these projects (making a spreadsheet program is truly a huge feat, though).They both have some use, but different use cases in my eyes.reply",
      "Agreed this is more appealing to read and visually look through even.reply",
      "As part of undergrad we had to implement space invaders on a Zync FPGA so you got to choose which bits you did in hardware and what was in software. It was a blast seeing what people came up with as you could do \u201cextras\u201d that gave you bonus points. Someone built a simple microphone frequency analysis block so you could go left, right, and fire by playing notes on a recorder.reply",
      ">on a Zync FPGA so you got to choose which bits you did in hardware and what was in software.You mean verilog vs block diagram, or did those boards have like a microcontroller too for more normal software?reply",
      "Some of these could take a day, like random tree / forest.Others are easily within the scope / size of a undergrad final project. Or even a masters degree thesis.reply",
      "I see comments suspecting this list is AI-generated. That might be true.\nBut ironically, the practice of \"building from scratch\" is the best antidote to AI dependency.Writing from Japan, we call this process \"Shugyo\" (austere training).\nA master carpenter spends years learning to sharpen tools, not because it's efficient, but to understand the nature of the steel.Building your own Redis or Git isn't about the result (which AI can give you instantly). It is about the friction. That friction builds a mental model that no LLM can simulate.Whether this post is marketing or not, the \"Shugyo\" itself is valid.reply",
      "You really can't help mentioning you write your comment from Japan in most of your comments for some reason.Not that it's my business that whether you were actually born and raised in Japan or an immigrant/expat. Just a random observation and that I don't think you have any less point without mentioning itConsidering your account age, it's a bit of bot smell if you ask mereply"
    ],
    "link": "https://codecrafters.io/blog/programming-project-ideas",
    "first_paragraph": "Many developers want to start a side project but aren't sure what to build. The internet is full of ideas that are basic and dull.Here's our list of 73 project ideas to inspire you. We have chosen projects that teach a lot and are fun to build.Build a BitTorrent client that can download files using the BitTorrent protocol. You can start with single-file torrents. This is a great way to learn how P2P networking works.Read the official BitTorrent specification here.Build a program that solves Wordle. This can be a great lesson on information theory and entropy. You'll also get hands-on experience at optimizing computations.This YouTube video will get you started.Implement Optimal Transport from scratch to morph one face into another while preserving identity and structure. You'll apply linear programming to a real problem.Here are some OT resources and a paper which proposes a solution.Create a spreadsheet with support for cell references, simple formulas, and live updates. You'll learn "
  },
  {
    "title": "A faster heart for F-Droid. Our new server is here (f-droid.org)",
    "points": 260,
    "submitter": "kasabali",
    "submit_time": "2025-12-30T18:36:37 1767119797",
    "num_comments": 108,
    "comments_url": "https://news.ycombinator.com/item?id=46436409",
    "comments": [
      "> this server is physically held by a long time contributor with a proven track record of securely hosting services. We can control it remotely, we know exactly where it is, and we know who has access.I can\u2019t be the only one who read this and had flashbacks to projects that fell apart because one person had the physical server in their basement or a rack at their workplace and it became a sticking point when an argument arose.I know self-hosting is held as a point of pride by many, but in my experience you\u2019re still better off putting lower cost hardware in a cheap colo with the contract going to the business entity which has defined ownership and procedures. Sending it over to a single member to put somewhere puts a lot of control into that one person\u2019s domain.I hope for the best for this team and I\u2019m leaning toward believing that this person really is trusted and capable, but I would strongly recommend against these arrangements in any form in general.EDIT: F-Droid received a $400,000 grant from a single source this year ( https://f-droid.org/2025/02/05/f-droid-awarded-otf-grant.htm... ) so now I\u2019m even more confused about how they decided to hand this server to a single team member to host in unspoken conditions instead of paying basic colocation expenses.reply",
      "The OSU Open Source Lab gives machines to groups in their datacenter: https://osuosl.org/services/hosting/It has hosted quite a few famous services.reply",
      "Which famous services?I doubt OSU is going to host F-Droid.  It doesn't even sound like F-Droid would want them to host it.reply",
      "Yup.  But the same can happen in shared hosting/colo/aws just as easily if only one person controls the keys to the kingdom.  I know of at least a handful of open source projects that had to essentially start over because the leader went AWOL or a big fight happened.That said, I still think that hosting a server in a member's house is a terrible decision for a project.reply",
      ">  if only one person controls the keys to the kingdomTrue, which is why I said the important parts need to be held by the legal entity representing the organization. If one person tries to hold it hostage, it becomes a matter of demonstrating that person doesn\u2019t legally have access any more.I\u2019ve also seen projects fall apart because they forgot to transfer some key element into the legal entity. A common one is the domain name, which might have been registered by one person and then just never transferred over. Nobody notices until that person has a falling out and starts holding the domain name hostage.reply",
      "> a $400,000 grantIDK if they could bag this kind of grant every year, but isn't this the scale where cloud hosting starts to make sense?reply",
      "You have two options. Colo if you still want physical access to your devices, or cloud, where you get access to nothing beyond some online portals.reply",
      "Colo is when you want to bring your own hardware, not when you want physical access to your devices. Many (most?) colo datacenters are still secure sites that you can't visit.reply",
      "Every colo I've visited has a system for allowing physical access for our equipment, generally during specific operating hours with secure access card.reply",
      "I've only ever seen that at data centers that offer colo as more of a side service or cater to little guys who are coloing by the rack unit.  All of the serious colocation services I've used or quoted from offer 24/7 site access.Basically anywhere with cage or cabinet colocation is going to have site access, because those delineations only make sense to restrict on-site human access.reply"
    ],
    "link": "https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html",
    "first_paragraph": "Donations are a key part of what keeps F-Droid independent and reliable and\nour latest hardware update is a direct result of your support. Thanks to\ndonations from our incredible community, F-Droid has replaced one of its\nmost critical pieces of infrastructure, our core server hardware. It was\noverdue for a refresh, and now we are happy to give you an update on the new\nserver and how it impacts the project.This upgrade touches a core part of the infrastructure that builds and\npublishes apps for the main F-Droid repository. If the server is slow,\neverything downstream gets slower too. If it is healthy, the entire\necosystem benefits.This server replacement took a bit longer than we would have liked. The\nbiggest reason is that sourcing reliable parts right now is genuinely\nhard. Ongoing global trade tensions have made supply chains unpredictable,\nand that hit the specific components we needed. We had to wait for quotes,\nreview, replan, and wait again when quotes turned out to have unexpec"
  },
  {
    "title": "FediMeteo: A \u20ac4 FreeBSD VPS Became a Global Weather Service (dragas.net)",
    "points": 221,
    "submitter": "birdculture",
    "submit_time": "2025-12-30T19:21:48 1767122508",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=46436889",
    "comments": [
      "This is awesome! Small projects like this that take off are fun to read.Maybe I'm imaging it but FreeBSD really seems to have far less bloat than Linux distros and better latency. I just setup a $4/mo FreeBSD VM on Vultr with 1G RAM and 1vCPU and it's only using 12% of RAM with Caddy. A VM with 4GB of RAM and 4 vCPUs could serve a lot of traffic.I'm wanting to create a personal blogging with a retro BBS-like web app with a text first interface with a multi-threaded Nim server + sqlite. I'm sure something exists already but it'd more for my own tinkering. No containers, no async, no javascript libraries. Just a small 4MB binary and FreeBSD. This posts encourages me on the FreeBSD route!reply",
      "For Linux this will vary between distributions and configurations. For example, based on some testing I did today using mkosi [1] (for reasons unrelated to this discussion), a bare-bones Fedora 43 installation uses about 130 MiB of RAM, while a Debian installation uses a little more than 100 MiB.IIRC last time I tried a bare-bones FreeBSD installation it used about the same amount of memory, maybe a little more based on how ZFS is set up.[1]: https://github.com/systemd/mkosireply",
      "ZFS will happilly (and intentionally) gobble up available RAM for ARC. On my 64GB system, ARC is using 42.4GB, but this memory is quickly reclaimable if it's needed. That said, I had very bad experiences trying to run ZFS on an underprovisioned system.reply",
      "Unbloated distros exist, Alpine is one example. I was taken aback how snappy it is. Does everything without any undue delay. Merely logging in via SSH feels quicker as you don't have to wait a second for the prompt like on Ubuntu. apk is also super fast.reply",
      "Alpine is really good for servers.Man I love alpine even though I don't use it so much but alpine does hold a special place in my heart for some reason (and i think the reasons are good)Tinycore is another one which holds a special place in my heart, partially because its the most no BS simple alpine-like os that I have seen which is rather focused on the consumer side, so you can get GUI systems super quickly and minimalist.The minimalist tinycore iso with gui and terminals ran on 21-40 MB :) let that sink inThey showed as 0.0% or 0.1% on my 8 gig computer.I used tinycore to take my really old laptop which my brother used to game on mostly and was super dead, it was a dell mini pc with intel atom 1 gig of ram 32 bit, probably 10-15 years oldI ran tinycore on it with no problem and ended up with wifi access and then even ran modern firefox browser and ended up even running a website like https://pomodorokitty.com/ on itMan,do i love them both.I genuinely just wanted to create a service which could just boot tinycore gui servers in the browser perhaps via novnc for people to play with but I seriously wondered who might pay for the projectOh btw oops forget that you can already do that by just downloading the iso of tinycore and then going to copy.sh/v86In fact that inspired me to create the project but one of the issues of copy.sh/v86 is that its ephemeral and runs directly in your browser so if you close it whereas I thought of having a mini-server-like tinycore where I can get a gui mini server and can quickly open/close it with terminal and even heck modern browsers.Everyone should try out tinycore just once imo. The simplicity of 21 MB is mind boggling to me. Makes one really wonder what bloat really is I suppose, definitely a fun experience.Oh also I love alpine because I ran it in my phone using UserLand and I loved it although running python in alpine was a bit of mess on my phone and I think I ended up doing some wizard magic or something using g-compat in the end as well to run it. Although I think termux is pretty good and even better than UserLand in this context because UserLand runs emulated where Termux doesn't I guess but not sure.reply",
      "If you liked tinycore check this one \nhttps://smolbsd.org/reply",
      "True Alpine is pretty snappy. I don't like using it as muslc has given me headaches before. Arch is faster generally too but not as much. Maybe there's something with systemd stuff.reply",
      "One could probably use VoidLinux or Gentoo with glibc I suppose if one might want leaner than arch but more heavier than archAlthough VoidLinux's iso size I think is larger than ArchLinux or something which doesn't make that much sense but I don't really know but both are good references to check out.reply",
      "Thank you!reply",
      "BTW, how do you feel about ActivityPub in general?reply"
    ],
    "link": "https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/",
    "first_paragraph": "Notice: This site works best with JavaScript enabled, but all content is accessible without it. Skip to main contentWeather has always significantly influenced my life. When I was a young athlete, knowing the forecast in advance would have allowed me to better plan my training sessions. As I grew older, I could choose whether to go to school on my motorcycle or, for safety reasons, have my grandfather drive me. And it was him, my grandfather, who was my go-to meteorologist. He followed all weather patterns and forecasts, a remnant of his childhood in the countryside and his life on the move. It's to him that I dedicate FediMeteo.The idea for FediMeteo started almost by chance while I was checking the holiday weather forecast to plan an outing. Suddenly, I thought how nice it would be to receive regular weather updates for my city directly in my timeline. After reflecting for a few minutes, I registered a domain and started planning.The choice of operating system was almost automatic. T"
  },
  {
    "title": "Show HN: 22 GB of Hacker News in SQLite (dosaygo.com)",
    "points": 316,
    "submitter": "keepamovin",
    "submit_time": "2025-12-30T17:01:59 1767114119",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=46435308",
    "comments": [
      "Don't miss how this works. It's not a server-side application - this code runs entirely in your browser using SQLite compiled to WASM, but rather than fetching a full 22GB database it instead uses a clever hack that retrieves just \"shards\" of the SQLite database needed for the page you are viewing.I watched it in the browser network panel and saw it fetch:  https://hackerbook.dosaygo.com/static-shards/shard_1636.sqlite.gz\n  https://hackerbook.dosaygo.com/static-shards/shard_1635.sqlite.gz\n  https://hackerbook.dosaygo.com/static-shards/shard_1634.sqlite.gz\n\nAs I paginated to previous days.It's reminiscent of that brilliant SQLite.js VFS trick from a few years ago: https://github.com/phiresky/sql.js-httpvfs - only that one used HTTP range headers, this one uses sharded files instead.The interactive SQL query interface at https://hackerbook.dosaygo.com/?view=query asks you to select which shards to run the query against, there are 1636 total.reply",
      "A read-only VFS doing this can be really simple, with the right API\u2026This is my VFS:\nhttps://github.com/ncruces/go-sqlite3/blob/main/vfs/readervf...And using it with range requests:\nhttps://pkg.go.dev/github.com/ncruces/go-sqlite3/vfs/readerv...And having it work with a Zstandard compressed SQLite database, is one library away:\nhttps://pkg.go.dev/github.com/SaveTheRbtz/zstd-seekable-form...reply",
      "Is there anything more production grade built around the same idea of HTTP range requests like that sqlite thing? This has so much potentialreply",
      "Yes \u2014 PMTiles is exactly that: a production-ready, single-file, static container for vector tiles built around HTTP range requests.I\u2019ve used it in production to self-host Australia-only maps on S3. We generated a single ~900 MB PMTiles file from OpenStreetMap (Australia only, up to Z14) and uploaded it to S3. Clients then fetch just the required byte ranges for each vector tile via HTTP range requests.It\u2019s fast, scales well, and bandwidth costs are negligible because clients only download the exact data they need.https://docs.protomaps.com/pmtiles/reply",
      "That's neat, but.. is it just for cartographic data?I want something like a db with indexesreply",
      "PMTiles is absurdly great software.reply",
      "I know right! I'd never heard of HTTP Range requests until PMTiles - but gee it's an elegant solution.reply",
      "There was a UK government GitHub repo that did something interesting with this kind of trick against S3 but I checked just now and the repo is a 404. Here are my notes about what it did: https://simonwillison.net/2025/Feb/7/sqlite-s3vfs/Looks like it's still on PyPI though: https://pypi.org/project/sqlite-s3vfs/You can see inside it with my PyPI package explorer: https://tools.simonwillison.net/zip-wheel-explorer?package=s...reply",
      "I recovered it from https://archive.softwareheritage.org/browse/origin/directory... and pushed a fresh copy to GitHub here:https://github.com/simonw/sqlite-s3vfsThis comment was helpful in figuring out how to get a full Git clone out of the heritage archive: https://news.ycombinator.com/item?id=37516523#37517378Here's a TIL I wrote up of the process: https://til.simonwillison.net/github/software-archive-recove...reply",
      "Doing all this in an hour is such a good example of how absurdly efficient you can be with LLMs.reply"
    ],
    "link": "https://hackerbook.dosaygo.com",
    "first_paragraph": ""
  },
  {
    "title": "A Vulnerability in Libsodium (00f.net)",
    "points": 199,
    "submitter": "raggi",
    "submit_time": "2025-12-30T17:24:57 1767115497",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=46435614",
    "comments": [
      "This also affected the PHP library, sodium_compat. https://github.com/FriendsOfPHP/security-advisories/pull/756I'm planning to spend my evening checking every other Ed25519 implementation I can find to see if this check is missing any where else in the open source ecosystem.reply",
      "I found several libraries that simply didn't implement the check, but none that implemented in incorrectly in the same way as the vulnerability discussed above.If you didn't receive an email from me, either your implementation isn't listed on https://ianix.com/pub/ed25519-deployment.html, I somehow missed it, or you're safe.reply",
      "Thank you for your work on free software.reply",
      "Thank you for your work on open source.reply",
      "I've been iterating on sodium bindings in Lean4 for about four months, and now that I've gotten to Ristretto255 I can see why the author is excited about its potential. Ristretto is a tightly designed API that allows me to build arbitrary polynomials on Curve25519 and I've been having a blast tinkering and experimenting with it! If the author by chance reads this, just want to say thank you for your work!reply",
      "You have a public repo of this?reply",
      "Yes: https://github.com/rj-calvin/sodiumThe bindings are set and have a monadic interface, but there's some abstractions that still need refining/iterating: mostly I want to be able to formalize keyboard input and eventually build a tactic framework for zero-knowledge proofs.reply",
      "Subtle but important bug. This is a good example of how \u201cis valid\u201d checks in crypto are rarely as simple as they sound. Accepting points outside the prime-order subgroup can quietly undermine higher-level assumptions, even if no immediate exploit is obvious. Also a reminder that low-level primitives tend to be reused far more widely than intended, so small validation gaps can have surprisingly large blast radii.reply",
      "Do note thought that X25519 and Ed25519 were designed so they wouldn\u2019t need those checks at all.  It\u2019s only when you\u2019re trying to design fancier protocols on top of Curve25519 or Edwards25519 that you can run into subgroup issues.And for those use cases, I personally try my best to just reproject everything back into the prime order subgroup whenever possible.  Monocypher has a number of such fancy functions:  crypto_x25519_dirty_fast()\n  crypto_x25519_dirty_small()\n  crypto_elligator_map()\n  crypto_elligator_rev()\n  crypto_elligator_key_pair()\n\nThe dirty functions explicitly produce public keys that cover the entire curve, so that random such keys are truly indistinguishable from random when converted with `crypto_elligator_rev()`.  But instead of just removing the clamp operation, I instead add random low-order point, so that when we later use the point in an X25519 key exchange, the shared secret is exactly the same as it would have been for a genuine X255119 key.That\u2019s where I thank DJB for designing a key exchange protocol that project the shared secret to the prime order subgroup, even when the public key it processes is not.  The original intent may have been to make checks easier (low order keys all end up yielding zero), but a nice side effect is how it enabled a nice API for Mike Hamburg\u2019s Elligator2.> Accepting points outside the prime-order subgroup can quietly undermine higher-level assumptions, even if no immediate exploit is obvious.If on the other hand we can prove that all computed results are low-order-component-independent (as is the case for X25519), then we know for sure we\u2019re safe.  In the end, Ristretto is only really needed when we can\u2019t tweak the protocol to safely reproject to the prime order subgroup.Don\u2019t get me wrong, having a prime order group abstraction does help.  But if someone is qualified to design a protocol that may require this, they\u2019re qualified to try and make it work with a non-trivial cofactor as well \u2014 that, or prove it cannot be done.reply",
      "If you work for a big company, consider trying to get Frank sponsored by your company.reply"
    ],
    "link": "https://00f.net/2025/12/30/libsodium-vulnerability/",
    "first_paragraph": "Libsodium is now 13 years old!I started that project to pursue Dan Bernstein\u2019s desire to make cryptography simple to use. That meant exposing a limited set of high-level functions and parameters, providing a simple API, and writing documentation for users, not cryptographers. Libsodium\u2019s goal was to expose APIs to perform operations, not low-level functions. Users shouldn\u2019t even have to know or care about what algorithms are used internally. This is how I\u2019ve always viewed libsodium.Never breaking the APIs is also something I\u2019m obsessed with. APIs may not be great, and if I could start over from scratch, I would have made them very different, but as a developer, the best APIs are not the most beautifully designed ones, but the ones that you don\u2019t have to worry about because they don\u2019t change and upgrades don\u2019t require any changes in your application either. Libsodium started from the NaCl API, and still adheres to it.These APIs exposed high-level functions, but also some lower-level fun"
  },
  {
    "title": "Zpdf: PDF text extraction in Zig \u2013 5x faster than MuPDF (github.com/lulzx)",
    "points": 109,
    "submitter": "lulzx",
    "submit_time": "2025-12-30T19:57:10 1767124630",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=46437288",
    "comments": [
      "74910,74912c187768,187779\n  < [Example 1: If you want to use the code conversion facetcodecvt_utf8to output tocouta UTF-8 multibyte sequence\n  < corresponding to a wide string, but you don't want to alter the locale forcout, you can write something like:\\237 D.27.21954\n                                                                                                                                \\251ISO/IECN4950wstring_convert<std::codecvt_utf8<wchar_t>> myconv;\n  < std::string mbstring = myconv.to_bytes\\050L\"Hello\\134n\"\\051;\n  ---\n  >\n  > [Example 1: If you want to use the code conversion facet codecvt_utf8 to output to cout a UTF-8 multibyte sequence\n  > corresponding to a wide string, but you don\u2019t want to alter the locale for cout, you can write something like:\n  >\n  > \u00a7 D.27.2\n  > 1954\n  >\n  > \u00a9 ISO/IEC\n  > N4950\n  >\n  > wstring_convert<std::codecvt_utf8<wchar_t>> myconv;\n  > std::string mbstring = myconv.to_bytes(L\"Hello\\n\");\n\nIs indeed faster but output is messier. And doesn't handle Unicode in contrast to mutool that does. (Probably also explains the big speed boost.)reply",
      "In my experience with parsing PDFs, speed has never been an issue, it has always been a matter of quality.reply",
      "I tried a small PDF and got a memory error. It's definitely much faster than MuPDF on that file.reply",
      "fixed.reply",
      "Yeah, sorry for confusion. When said Unicode, meant foreign text rather (just) the unescaped symbols, e.g. Greek. At one random Greek textbook[0], zpdf output is (extract | head -15):  01F9020101FC020401F9020301FB02070205020800030209020701FF01F90203020901F9012D020A0201020101FF01FB01FE0208 \n  0200012E0219021802160218013202120222 0209021D0212021D012E013202200222000301FA021A0220021C022002160213012E0222000F000301F90206012C\n\n  020301FF02000205020101FC020901F90003020001F9020701F9020E020802000205020A \n  01FC028C0213021B022002230221021800030200012E021902180216021201320221021A012E00030209021D0212021D012E013202200222000301FA021A0220021C022002160213012E0222000F000301F90206012C \n \n  0200020D02030208020901F90203020901FF0203020502080003012B020001F9012B020001F901FA0205020A01FD01FE0208 \n  020201300132012E012F021A012F0210021B013202200221012E0222 0209021D0212021D012E013202200222000301FA021A0220021C022002160213012E0222000F000301F90206012C \n\nThis for entire book. Mutool extracts the text just fine.[0]: https://repository.kallipos.gr/handle/11419/15087reply",
      "sorry, I haven't yet figured out non-latin with tounicode references.reply",
      "Lol, but there's 100 competitors in the PDF text extraction space, some are multi million dollar industries: AWS textract, ABBY PDFreader, PDFBox, I think you may be underestimating the challenge here.reply",
      "I built a PDF text extraction library in Zig that's significantly faster than MuPDF for text extraction workloads.~41K pages/sec peak throughput.Key choices: memory-mapped I/O, SIMD string search, parallel page extraction, streaming output. Handles CID fonts, incremental updates, all common compression filters.~5,000 lines, no dependencies, compiles in <2s.Why it's fast:  - Memory-mapped file I/O (no read syscalls)\n  - Zero-copy parsing where possible\n  - SIMD-accelerated string search for finding PDF structures\n  - Parallel extraction across pages using Zig's thread pool\n  - Streaming output (no intermediate allocations for extracted text)\n\nWhat it handles:  - XRef tables and streams (PDF 1.5+)\n  - Incremental PDF updates (/Prev chain)\n  - FlateDecode, ASCII85, LZW, RunLength decompression\n  - Font encodings: WinAnsi, MacRoman, ToUnicode CMap\n  - CID fonts (Type0, Identity-H/V, UTF-16BE with surrogate pairs)reply",
      "What kind of performance are you seeing with/without SIMD enabled?From https://github.com/Lulzx/zpdf/blob/main/src/main.zig it looks like the help text cites an unimplemented \"-j\" option to enable multiple threads.There is a \"--parallel\" option, but that is only implemented for the \"bench\" command.reply",
      "I have now made parallel by default and added an option to enable multiple threads.I haven't tested without SIMD.reply"
    ],
    "link": "https://github.com/Lulzx/zpdf",
    "first_paragraph": ""
  },
  {
    "title": "OpenAI's cash burn will be one of the big bubble questions of 2026 (economist.com)",
    "points": 163,
    "submitter": "1vuio0pswjnm7",
    "submit_time": "2025-12-30T21:44:07 1767131047",
    "num_comments": 194,
    "comments_url": "https://news.ycombinator.com/item?id=46438390",
    "comments": [
      "AI is going to be a highly-competitive, extremely capital-intensive commodity market that ends up in a race to the bottom competing on cost and efficiency of delivering models that have all reached the same asymptotic performance in the sense of intelligence, reasoning, etc.The simple evidence for this is that everyone who has invested the same resources in AI has produced roughly the same result. OpenAI, Anthropic, Google, Meta, Deepseek, etc. There's no evidence of a technological moat or a competitive advantage in any of these companies.The conclusion? AI is a world-changing technology, just like the railroads were, and it is going to soon explode in a huge bubble - just like the railroads did. That doesn't mean AI is going to go away, or that it won't change the world - railroads are still here and they did change the world - but from a venture investment perspective, get ready for a massive downturn.reply",
      "There is a pretty big moat for Google: extreme amounts of video data on their existing services and  absolutely no dependence on Nvidia and it's 90% margin.reply",
      "I have yet to be convinced the broader population has an appetite for AI produced cinematography or videos. Independence from Nvidia is no more of a liability than dependence on electricity rates; it's not as if it's in Nvidia's interest to see one of its large customers fail. And pretty much any of the other Mag7 companies are capable of developing in-house TPUs + are already independently profitable, so Google isn't alone here.reply",
      "It's in Nvidia's interest to charge the absolute maximum they can without their customers failing. Every dollar of Nvidia's margin is your own lost margin. Utilities don't do that. Nvidia is objectively a way bigger liability than electricity rates.reply",
      "If you think they are going to catch up with Google's software and hardware ecosystem on their first chip, you may be underestimating how hard this is. Google is on TPU v7. meta has already tried with MTIA v1 and v2. those haven't been deployed at scale for inference.reply",
      "I don't think many of them will want to, though. I think as long as Nvidia/AMD/other hardware providers offer inference hardware at prices decent enough to not justify building a chip in-house, most companies won't. Some of them will probably experiment, although that will look more like a small team of researchers + a moderate budget rather than a burn-the-ships we're going to use only our own hardware approach.reply",
      "Well, anthropic just purchased a million TPUs from Google because even with a healthy margin from Google, it's far more cost effective because of Nvidia's insane markup. That speaks for itself. Nvidia will not drop their margin because it will tank their stock price. it's half of the reason for all this circular financing - lowering their effective margin without lowering it on paper.reply",
      "The video data is probably good for training models, including text models.reply",
      "And yes, all their competitors are making custom chips. Google is on TPU v7. absolutely nobody is going to get this right on the first try among their competitors - Google didn't.reply",
      "Bigger problem for late starts now is that it will be hard to match the performance and cost of Google/Nvidia.  It's an investment that had to have started years ago to be competitive now.reply"
    ],
    "link": "https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026",
    "first_paragraph": ""
  },
  {
    "title": "Electrolysis can solve one of our biggest contamination problems (ethz.ch)",
    "points": 121,
    "submitter": "PaulHoule",
    "submit_time": "2025-12-30T18:08:32 1767118112",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=46436127",
    "comments": [
      "Uses DMSO (by-product of paper production processes) as solvent. It's pretty nasty. All industrial processes wind up with nasty, and this may be swapping a less tractable and nastier problem for a well understood DMSO handling problem.reply",
      "DMSO is a solvent that is is absorbed directly through the skin. Jello Biafra was wrong though, if you mix it with lemon juice and pour it on your hand, you will not sense the taste of lemons in your mouth. You will taste garlic. Try it and see.https://genius.com/Dead-kennedys-dmso-lyricsI\u2019m not sure what happens when you mix it with LSD. Again, try it and see.reply",
      "Wait up. They propose to convert DDT trapped in the soil to benzene trapped in the soil?  Is not benzene also a toxic and persistent soil pollutant (it is) where the typical remediation is to excavate the bad soil and landfill it? (it is)https://www.waterboards.ca.gov/water_issues/programs/gama/do...There was an old lady who swallowed a fly, she didn\u2019t know why.reply",
      "They're not leaving it in the soil. The benzene is extracted as a useful byproduct.reply",
      "Yes, they are leaving it in the soil. Prove me wrong with data. It says nothing at all about extracting the waste benzene they created from the soil, neither in the linked article nor in the complete paper, which i did read.  The paper specifically describes an in-situ process.   If it were economically beneficial to extract benzene from contaminated soil for industrial use, we would already be doing that with the tens of thousands of existing benzene contaminated sites, not creating more of them.reply",
      ">  neither in the linked article nor in the complete paper, which i did read.I'm having trouble finding the paper, can you link please?reply",
      "Courtesy of another poster down-thread.https://ethz.ch/content/dam/ethz/special-interest/chab/organ...reply",
      "DDT is still sprayed today, indoors, in Africa and Asia to control for mosquitos, including in India.https://www.sciencedirect.com/science/article/pii/S254251962...reply",
      "This looks very promising! Efficiently dehalogenizing toxins, preserving their carbon \"skeletons\" to be repurposed for valuable (nontoxic) industrial chemicals, creating NaCl (table salt) as a byproduct... seems full of win to me. Here's hoping...reply",
      "Benzene is quite toxic.  The EPA classifies benzene as a known human carcinogen for all routes of exposure. And their method leaves it buried it in the soil.  It is not a valuable industrial chemical when it is in the soil, it is a pollutant.reply"
    ],
    "link": "https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html",
    "first_paragraph": ""
  },
  {
    "title": "Sabotaging Bitcoin (dshr.org)",
    "points": 71,
    "submitter": "zdw",
    "submit_time": "2025-12-30T20:53:59 1767128039",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=46437876",
    "comments": [
      "The Eyal & Sirer paper is pretty interesting - they basically point out that there is actually some game theory involved in when miners should reveal that they mined a block to compete most effectively with their fellows. If a pool can set up a situation where they mine a block and wait X seconds to reveal it, they can force other miners to waste X seconds of has power and gain an advantage.It looks like a result with complex implications - eg, maybe making it impossible for new miners to set up unless they have a meaningful advantage in operating costs instead of just parity with the entrenched players. It is hard to tell because market reality is a mess but if there is a meaningful strategic choice to be made beyond simply announcing a block when it is mined then there is a lot of room for weird equilibriums even if the paper's specific analysis turns out to have flaws.reply",
      "Isn't this the same thing as saying \"if everyone just agrees that a dollar bill is actually just a piece of paper, USD becomes worthless\"? Albeit at a smaller scalereply",
      "I don't think it is the same thing. Everyone agrees that mining the next block is valuable.reply",
      "TIL: https://ccaf.io/cbnsi/cbeci - quite horrifying!EDIT:  For comparison: https://gridwatch.co.uk/reply",
      "Since when is incentivizing low cost renewable energy horrifying?reply",
      "Because every unit of electricity causes climate change and burns resources (even renewable sources of electricity - they just burn them slower). From a societal point of view we are dumping huge amounts of electricity and resources into a hole to accomplish nothing that couldn\u2019t be accomplished with a database and a trusted third party at a billionth of the cost (or less).The vast majority of transactions are speculation on what other people might pay for a bitcoin (i.e., a line on a spreadsheet). And even then, that speculation and trading often occurs on secondary markets which rely on trusted third parties - thus rendering the entire ordeal even more pointless.reply",
      "Better shoot down the sun then.",
      "My first link shows that Bitcoin consumes roughly 40GW and my second link shows that the UK roughly does too.There are a lot of ifs and buts here ... but the amount of power used to support the BT mechanism worldwide is roughly the same as the power consumption of the entirety of the UK.reply",
      "[flagged]",
      "Unless your intent isn't making the world a better place in some sort of meaningful way, learn about things and find something to care about that you can affect that actually matters. Bitcoin or AI or whatever is not worth your time. Do something real.If we ever get to the point where bitcoin or what people are doing on servers is the most pressing problem in the world worthy of our outrage, I will cheer you on.\"Anon yells at cloud\" isn't worth anyone's effort or time.reply"
    ],
    "link": "https://blog.dshr.org/2025/12/sabotaging-bitcoin.html",
    "first_paragraph": "I'm David Rosenthal, and this is a place to discuss the work I'm doing in Digital Preservation.\nPost a Comment\n"
  },
  {
    "title": "Mitsubishi Diatone D-160 (1985) (audio-database.com)",
    "points": 15,
    "submitter": "anigbrowl",
    "submit_time": "2025-12-29T02:08:08 1766974088",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=46416674",
    "comments": [
      "\"The Hitch Hiker's Guide to the Galaxy notes that Disaster Area, a plutonium rock band from the Gagrakacka Mind Zones, are generally held to be not only the loudest rock band in the Galaxy, but in fact the loudest noise of any kind at all. Regular concert goers judge that the best sound balance is usually to be heard from within large concrete bunkers some thirty-seven miles from the stage, whilst the musicians themselves play their instruments by remote control from within a heavily insulated spaceship which stays in orbit around the planet - or more frequently around a completely different planet. [...] Many worlds have now banned their act altogether, sometimes for artistic reasons, but most commonly because the band's public address system contravenes local strategic arms limitations treaties.\"(The Restaurant at the End of the Universe, Douglas Adams)reply",
      "> It seems that the unit with the unusual size of 160 cm had a lot of difficulty in the characteristic test.\nAt the Koriyama Test at the Koriyama Factory was carried out in the measurement room at first, but it was stopped because fluorescent lamps on the ceiling fell due to vibration. It seems that the characteristic test was carried out at the ground in the factory premises.> The outdoor test seemed to have a negative impact on the neighborhood. At a distance of about 100m from the speaker, it was felt as sound, but at a distance of more than that, it was transmitted as vibration and earth rumbling instead of audible sound. Within a radius of 2 km from the factory, there were damages such as vibrations like earthquakes and earth rumbling, and sound of walls and windows.reply",
      "Very sceptical that a 3kW speaker can cause \"earthquake like vibrations with a radius of 2km\".reply",
      "I can't help but think it would be fun to try to verify the claim, though.reply",
      "Fun?  Sure.  It is indeed fun to play with big speakers.Direct-radiating bass reproduction is all about displacement, and the area of the piston (cone) is certainly a factor of that.  More tends to be...  well, more.And this mysterious speaker (which there seems to be no color photos of, despite the 1981 date) has a radiating area of perhaps about 2 square meters.That's around the same as qty. 18 of 18\" woofers.It's easy to find collections of way, way more than that.  People even charge money to hear them;  they're on the ground between the stage and the crowd barrier at any big rock show.  :)reply",
      "wowiereply"
    ],
    "link": "https://audio-database.com/MITSUBISHI-DIATONE/diatonesp/d-160-e.html",
    "first_paragraph": "* Made-to-order (delivery date : 4 months)Approx. \u00a5 30,000,000 (released in 1985)A woofer system using the largest woofer unit of Diatone developed in 1980.The unit is equipped with PW 1600 which is a 160 cm cone type woofer.A honeycomb diaphragm is used for the diaphragm. Aluminum alloy is used for the honeycomb core and CFRP (carbon fiber reinforced plastic) is used for the skin material to realize weight reduction. The weight of the diaphragm is reduced to 3 kg even though it is a super large woofer.We have also adopted a field coil for the magnetic circuit. At the design stage, when calculated using permanent magnets, the weight exceeds 800 kg even if a strong magnet is used. Therefore, we have decided to use a field coil to reduce the weight. This coil uses electric wires for train motors, and the field coil alone weighs 400 kg.A high heat-resistant bobbin is used for the voice coil to achieve high input resistance.Since the frame cannot be cast as a single unit, four parts are as"
  },
  {
    "title": "Loss32: Let's Build a Win32/Linux (loss32.org)",
    "points": 202,
    "submitter": "akka47",
    "submit_time": "2025-12-29T19:09:08 1767035348",
    "num_comments": 302,
    "comments_url": "https://news.ycombinator.com/item?id=46424173",
    "comments": [
      "This might offend some people but even Linus Torvalds thinks that the ABI compatibility is not good enough in Linux distros, and this is one of the main reasons Linux is not popular on the desktop. https://www.youtube.com/watch?v=5PmHRSeA2c8&t=283sreply",
      "To quote a friend; \"Glibc is a waste of a perfectly good stable kernel ABI\"reply",
      "Kind of funny to realize, the NT kernel ABI isn\u2019t even all that stable itself; it is just wrapped in a set of very stable userland exposures (Win32, UWP, etc.), and it\u2019s those exposures that Windows executables are relying on. A theoretical Windows PE binary that was 100% statically linked (and so directly contained NT syscalls) wouldn\u2019t be at-all portable between different Windows versions.Linux with glibc is the complete opposite; there really does exist old Linux software that static-links in everything down to libc, just interacting with the kernel through syscalls\u2014and it does (almost always) still work to run such software on a modern Linux, even when the software is 10-20 years old.I guess this is why Linux containers are such a thing: you\u2019re taking a dynamically-linked Linux binary and pinning it to a particular entire userland, such that when you run the old software, it calls into the old glibc. Containers work, because they ultimately ground out in the same set of stable kernel ABI calls.(Which, now that I think of it, makes me wonder how exactly Windows containers work. I\u2019m guessing each one brings its own NTOSKRNL, that gets spun up under HyperV if the host kernel ABI doesn\u2019t match the guest?)reply",
      "IIRC, Windows containers require that the container be built with a base image that matches the host for it to work at all (like, the exact build of Windows has to match). Guessing that\u2019s how they get a \u2018stable ABI\u2019.\u2026actually, looks like it\u2019s a bit looser these days. Version matrix incoming: https://learn.microsoft.com/en-us/virtualization/windowscont...reply",
      "The ABI was stabilised for backwards compatibility since Windows Server 2022, but is not stable for earlier releases.reply",
      "> Kind of funny to realize, the NT kernel ABI isn\u2019t even all that stable itselfThis is not a big problem if it's hard/unlikely enough to write a code that accidentally relies on raw syscalls. At least MS's dev tooling doesn't provide an easy way to bypass the standard DLLs.> makes me wonder how exactly Windows containers workI guess containers do the syscalls through the standard Windows DLLs like any regular userspace application. If it's a Linux container on Windows, probably the WSL syscalls, which I guess,  are stable.reply",
      "> NT kernel ABI isn\u2019t even all that stable itselfCan you give an example where a breaking change was introduced in NT kernel ABI?reply",
      "https://j00ru.vexillium.org/syscalls/nt/64/(One example: hit \"Show\" on the table header for Win11, then use the form at the top of the page to highlight syscall 8c)reply",
      "The syscall numbers change with every release: https://j00ru.vexillium.org/syscalls/nt/64/reply",
      "Apparently there are 3 kinds of Windows containers, one using HyperV, and the others sharing the kernel (like Linux containers)https://thomasvanlaere.com/posts/2021/06/exploring-windows-c...reply"
    ],
    "link": "https://loss32.org/",
    "first_paragraph": "The future of the Linux desktop can look like this:Let's build it! I'd just like to interject for a moment. What you're referring to as Linux, is in fact, Win32/Linux, or as I've recently taken to calling it, loss32 Win32 plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning system made useful by WINE, the ReactOS userland, and other vital system components comprising a full OS as defined by Microsoft.\n\nOkay, but seriously what is this?\nA dream of a Linux distribution where the entire desktop environment is Win32 software running under WINE. A completely free and open-source OS where you can just download .exe files and run them, for the power user who isn't necessarily a Unixhead, or just for someone who thinks this sounds fun.\n\nIsn't this just ReactOS?\nReactOS tries to reimplement the Windows NT kernel, and that has always been its Achilles heel, holding it back from a hardware compatibility and stability standpoint. The lo"
  },
  {
    "title": "Honey's Dieselgate: Detecting and tricking testers (vptdigital.com)",
    "points": 106,
    "submitter": "AkshatJ27",
    "submit_time": "2025-12-30T21:59:35 1767131975",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=46438522",
    "comments": [
      "I used to work for an ad tech company (which I know already makes me the devil to some around here), and even I think that they crossed a line with this. A lot of industry terms are coded in corporate speak to make them sound better (think \"revealed preferences\" or \"enabling personalization\"), but I would genuinely like to know what the engineers thought when doing design reviews for a \"selective stand down\" feature. There doesn't seem to be a legit way to spin it.Making a product to explicitly skirt agreements while working for a corporation is ... a choicereply",
      "Original MegaLag video: https://www.youtube.com/watch?v=qCGT_CKGgFEYou'd think that if you were an engineer building and maintaing a system like this, you'd have an \"are we the baddies?\" moment, but guess not.reply",
      "For context, Ben Edelman the author of the blog post was in the video at https://youtu.be/qCGT_CKGgFE?t=1980Their personal site is also linked in the video description https://www.benedelman.org/honey-detecting-testers/reply",
      "The original site is down for me, so going based on the app I was thinking it was about the actual edible Honey product, not Honey the discount coupon thing.reply",
      "It started as a clone of the camelcamelcamel Amazon price history site and got kicked out by Amazon for abusing the system. It pivoted to a coupon site and started sucking down user data with the plugin when PayPal paid $4Bil CASH. Honey cost me affiliate marketing commissions.reply",
      "Archived link: https://web.archive.org/web/20251230214339/https://vptdigita...reply",
      "there's something seriously wrong with this archived link. It's not staying still for one moment. It's constantly twitching and the text scrolls to weird positions. It's unreadable because of this.Is it the archive at fault or is the original webpage this way?reply",
      "It constantly reloads for me (Firefox.)  Just hit X which replaces the reload button while the page is loading and it will stop.reply",
      "Disable JavaScript, reason #99e99.Works for me here, and in 90% of the cases where someone complains of annoying page behaviour (cookie banners, revenue optimizations, subscription solicitations, \"click here to ...\", paywalls, ads, et alii ad nauseam).Seriously, just disable JavaScript on unknown/untrusted/undeserving sites. It makes the web tolerable.reply",
      "ah well... this is a first for me where I need to disable JS. Thanks!reply"
    ],
    "link": "https://vptdigital.com/blog/honey-detecting-testers/",
    "first_paragraph": "MegaLag\u2019s December 2024 video introduced 18 million viewers to serious questions about Honey, the widely-used browser shopping plug-in\u2014in particular, whether Honey abides by the rules set by affiliate networks and merchants, and whether Honey takes commissions that should flow to other affiliates.\u00a0 I wrote in January that I thought Honey was out of line.\u00a0 In particular, I pointed out the contracts that limit when and how Honey may present affiliate links, and I applied those contracts to the behavior MegaLag documented. \u00a0Honey was plainly breaking the rules.As it turns out, Honey\u2019s misconduct is considerably worse than MegaLag, I, or others knew.\u00a0 When Honey is concerned that a user may be a tester\u2014a \u201cnetwork quality\u201d employee, a merchant\u2019s affiliate manager, an affiliate, or an enthusiast\u2014Honey designs its software to honor stand down in full.\u00a0 But when Honey feels confident that it\u2019s being used by an ordinary user, Honey defies stand down rules.\u00a0 Multiple methods support these conclu"
  },
  {
    "title": "Toro: Deploy Applications as Unikernels (github.com/torokernel)",
    "points": 118,
    "submitter": "ignoramous",
    "submit_time": "2025-12-30T17:09:57 1767114597",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=46435418",
    "comments": [
      "Projects like this and Docker make me seriously wonder where software engineering is going. Don't get me wrong, I don't mean to criticize Docker or Toro in parcicular. It's the increasing dependency on such approaches that bothers me.Docker was conceived to solve the problem of things \"working on my machine\", and not anywhere else. This was generally caused by the differences in the configuration and versions of dependencies. Its approach was simple: bundle both of these together with the application in unified images, and deploy these images as atomic units.Somewhere along the lines however, the problem has mutated into \"works on my container host\". How is that possible? Turns out that with larger modular applications, the configuration and dependencies naturally demand separation. This results in them moving up a layer, in this case creating a network of inter-dependent containers that you now have to put together for the whole thing to start...  and we're back to square one, with way more bloat in between.Now hardware virtualization. I like how AArch64 generalizes this: there are 4 levels of privilege baked into the architecture. Each has control over the lower and can call up the one immediately above to request a service. Simple. Let's narrow our focus to the lowest three: EL0 (classically the user space), EL1 (the kernel), EL2 (the hypervisor). EL0, in most operating systems, isn't capable of doing much on its own; its sole purpose is to do raw computation and request I/O from EL1. EL1, on the other hand, has the powers to directly talk to the hardware.Everyone is happy, until the complexity of EL1 grows out of control and becomes a huge attack surface, difficult to secure and easy to exploit from EL0. Not good. The naive solution? Go a level above, and create a layer that will constrain EL1, or actually, run multiple, per-application EL1s, and punch some holes through for them to still be able to do the job\u2014create a hypervisor. But then, as those vaguely defined \"holes\", also called system calls and hyper calls, grow, won't so the attack surface?Or in other words, with the user space shifting to EL1, will our hypervisor become the operating system, just like docker-compose became a dynamic linker?reply",
      "I see a number of assumptions in your post which I find not matching my view of the picture.Containers arose as a way to solve the dependency problems created by traditional Unix. They grow from tools like chroot, BSD jails, and Solaris Zones. Containers allow to deploy dependencies that cannot be simultaneously installed on a traditional Unix host system. it's not a UNIX architecture limitation but rather a result of POSIX + tradition; e.g. Nix also solves this, but differently.Containers (like chroot and jail before them) also help ensure that a running service does not depend on the parts of the filesystem it wasn't given access to. Additionally, containers can limit network access, and process tree access.These limitations are not a proper security boundary, but definitely a dependency boundary, helping avoid spaghetti-style dependencies, and surprises like \"we never realized that our ${X} depends on ${Y}\".Then, there's the Fundamental Theorem of Software Engineering [1], which states:  \"We can solve any problem by introducing an extra level of indirection.\" So yes, expect the number of levels of indirection to grow everywhere in the stack. A wise engineer can expect to merge or remove a some levels here and there, when the need for them is gone, but they would never expect that new levels of indirection should stop emerging.[1]: https://en.wikipedia.org/wiki/Fundamental_theorem_of_softwar...reply",
      "To be honest, I've read your response 3 times and I still don't see where we disagree, assuming that we do.I've mostly focused on the worst Docker horrors I've seen in production,  extrapolating that to the future of containers, as pulling in new \"containerized\" dependencies will inevitably become just as effortless as it currently is with regular dependencies in the new-style high-level programming languages. You've primarily described a relatively fresh, or a well-managed Docker deployment, while admitting that spaghetti-style dependencies have become a norm and new layers will pile up (and by extension, make things hard to manage).I think our points of view don't actually collide.reply",
      "We do not disagree about the essence, but rather in accents. Some might say that sloppy engineers were happy to pack their Ruby-Goldbergesque deployments into containers. I say that even the most excellent and diligent engineers sometimes faced situations when two pieces of software required incompatible versions of a shared library, which depended on a tree of other libraries with incompatible versions, etc, and there's a practical limit of what you can and should do with bash scripts and abuse of LD_PRELOAD.Many of the \"new\" languages, like Go (16 years), Rust (13 years), or Zig (9 years) just can build static binaries, not even depending on libc. This has both upsides and downsides, especially with security fixes. Rebuilding a container to include an updated .so dependency is often easier and faster than rebuilding a Rust project.Docker (or preferably Podman) is not a replacement for linkers. It's an augmentation to the package system, and a replacement for the common file system layout, which is inadequate for modern multi-purpose use of a Unix (well, Linux) box.reply",
      "I see, you're providing a complementary perspective. I appreciate that, and indeed, Docker isn't always evil. My intention was to bring attention to the abuse of it and compare it to virtualization of unikernels, which to me appears to be on a similar trajectory.As for the linker analogy, I compared docker-compose (not Docker proper) to a dynamic linker because it's often used to bring up larger multi-container applications, similar to how large monolithic applications with plenty of shared library dependencies are put together by ld.so, and those multi-container applications can be similarly brittle if developed under the assumption that merely wrapping them up in containers will assure portability, defeating most of Docker's advantages and reducing it to a pile of excess layers of indirection. This is similar to the false belief that running kernel-mode code under a hypervisor is by itself more secure than running it as process on top of a bare-metal kernel.reply",
      "Containers got popular at at time when there were an increasingly number of people that were finding it hard to install software on their system locally - especially if you were, for instance, having to juggle multiple versions of ruby or multiple versions of python and those linked to various major versions of c libraries.Unfortunately containers have always had an absolutely horrendous security story and they degrade performance by quite a lot.The hypervisor is not going away anytime soon - it is what the entire public cloud is built on.While you are correct that containers do add more layers - unikernels go the opposite direction and actively remove those layers. Also, imo the \"attack surface\" is by far the smallest security benefit - other architectural concepts such as the complete lack of an interactive userland is far more beneficial when you consider what an attacker actually wants to do after landing on your box. (eg: run their software)When you deploy to AWS you have two layers of linux - one that AWS runs and one that you run - but you don't really need that second layer and you can have much faster/safer software without it.reply",
      "I can understand the public cloud argument; if the cloud provider insists on you delivering an entire operating system to run your workloads, a unikernel indeed slashes the amount of layers you have to care about.Suppose you control the entire stack though, from the bare metal up. (Correct me if I'm wrong, but) Toro doesn't seem to run on real hardware, you have to run it atop QEMU or Firecracker. In that case, what difference does it make if your application makes I/O requests through paravirtualized interfaces of the hypervisor or talks directly to the host via system calls? Both ultimately lead to the host OS servicing the request. There isn't any notable difference between the kernel/hypervisor and the user/kernel boundary in modern processors either; most of the time, privilege escalations come from errors in the software running in the privileged modes of the processor.Technically, in the former case, besides exploiting the application, a hypothetical attacker will also have to exploit a flaw in QEMU to start processes or gain further privileges on the host, but that's just due to a layer of indirection. You can accomplish this without resorting to hardware virtualization. Once in QEMU, the entire assortment of your host's system calls and services is exposed, just as if you ran your code as a regular user space process.This is the level you want to block exec() and other functionality your application doesn't need at, so that neither QEMU nor your code ran directly can perform anything out of their scope. Adding a layer of indirection while still leaving user/kernel, or unikernel/hypervisor junction points unsupervised will only stop unmotivated attackers looking for low-hanging fruit.reply",
      "> Suppose you control the entire stack though, from the bare metal up. (Correct me if I'm wrong, but) Toro doesn't seem to run on real hardware, you have to run it atop QEMU or Firecracker.Some unikernels are intended to run under a hypervisor or on bare metal. Bare metal means you need some drivers, but if you have a use case for a unikernel on bare metal, you probably don't need to support the vast universe of devices, maybe only a few instances of a couple types of things.I've got a not production ready at all hobby OS that's adjacent to a unikernel; runs in virtio hypervisors and on bare metal, with support for one NIC. In it's intended hypothetical use, it would boot from PXE, with storage on nodes running a traditional OS, so supporting a handful of NICs would probably be sufficient. Modern NICs tend to be fairly similar in interface, so if the manufacturer provides documentation, it shouldn't take too long to add support at least once you've got one driver doing multiple tx/rx queues and all that jazz... plus or minus optimization.For storage, you can probably get by with two drivers, one for sata/ahci and one for nvme. And likely reuse an existing filesystem.reply",
      "> In that case, what difference does it make if your application makes I/O requests through paravirtualized interfaces of the hypervisor or talks directly to the host via system calls?Hypervisors expose a much smaller API surface area to their tenants than an operating system does to its processes which makes them much easier to secure.reply",
      "That is a artifact of implementation. Monolithic operating systems with tons of shared services expose lots to their tenants. Austere hypervisors, the ones with small API surface areas, basically implement a microkernel interface yet both expose significantly more surface area and offer a significantly worse guest experience than microkernels. That is why high security systems designed for multi-level security for shared tenants that need to protect against state actors use microkernels instead of hypervisors.reply"
    ],
    "link": "https://github.com/torokernel/torokernel",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        This repository contains the source code of toro unikernel\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Toro is a unikernel dedicated to deploy applications as microVMs. Toro leverages on virtio-fs and virtio-vsocket to provide a minimalistic architecture.You can try Toro by running the HelloWorld example using a Docker image that includes all the required tools. To do so, execute the following commands in a console (these steps require you to install before KVM and Docker):If these commands execute successfully, you will get the output of the HelloWorld example.\nYou can also pull the image from dockerhub instead of building it:You can sha"
  },
  {
    "title": "Reverse Engineering a Mysterious UDP Stream in My Hotel (2016) (gkbrk.com)",
    "points": 168,
    "submitter": "bayesnet",
    "submit_time": "2025-12-23T15:21:55 1766503315",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=46366010",
    "comments": [
      "Related. Others?Reverse engineering a mysterious UDP stream in my hotel (2016) - https://news.ycombinator.com/item?id=34912300 - Feb 2023 (179 comments)Reverse engineering a mysterious UDP stream in my hotel (2016) - https://news.ycombinator.com/item?id=26633792 - March 2021 (86 comments)Reverse Engineering a Mysterious UDP Stream in My Hotel (2016) - https://news.ycombinator.com/item?id=16197436 - Jan 2018 (15 comments)Reverse Engineering a Mysterious UDP Stream in My Hotel - https://news.ycombinator.com/item?id=11744518 - May 2016 (181 comments)reply",
      "It's just as good in 2026 - 2d. Imagine Santa delivering his goods and hearing a mysterious UDP stream and wondering, \"Is my supply chain being disrupted?\", only to then realize that it was just the owners' TV spying on him after it was left on standby instead being completely turned off.reply",
      "Archive link as it seems the site is down: https://archive.is/afYvQreply",
      "This is the kind of curiosity that leads to the most interesting findings. Hotels are a perfect storm of shared networks, opaque vendor integrations, and \u201cit just works\u201d assumptions. A mysterious UDP stream could be anything from Chromecast-style discovery to IPTV control or some half-documented vendor heartbeat. What\u2019s usually more revealing than the payload is the pattern: broadcast vs unicast, frequency, and who responds. Also a good reminder of how much ambient network noise we\u2019re all swimming in without noticing.reply",
      "Author here, hi :^)reply",
      "Hi! Do you happen to have that elevator music saved? I'm curious what it sounded like.reply",
      "I had it saved, but it was 3-4 computers ago. I don't think I still have it, and if I did I wouldn't know where.Aside from the article, I only found these scripts on my disk related to this project.listen_2046.py and send_2046.pyhttps://gist.github.com/gkbrk/445929a854051203ee31afc7495c5a...reply",
      "Thank you for writing one of my favorite blog posts of all time! I am curious: What is your favorite thing you\u2019ve written?reply",
      "Since you appear to be Turkish what's your favourite Turkish food that is poorly known outside of the country? Also don't miss https://subseacables.blogspot.com/2025/12/fully-diverse-100g...reply",
      "\"poorly known outside the country\" rules out the main foods I like.I love a good Kuymak [1] though, I think that's not too well known.[1]: https://en.wikipedia.org/wiki/Kuymakreply"
    ],
    "link": "https://www.gkbrk.com/hotel-music",
    "first_paragraph": ""
  },
  {
    "title": "Escaping containment: A security analysis of FreeBSD jails [video] (ccc.de)",
    "points": 48,
    "submitter": "todsacerdoti",
    "submit_time": "2025-12-30T19:15:05 1767122105",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://media.ccc.de/v/39c3-escaping-containment-a-security-analysis-of-freebsd-jails",
    "first_paragraph": "\n\nilja and\nMichael Smith\n\nFreeBSD\u2019s jail mechanism promises strong isolation\u2014but how strong is it really?\nIn this talk, we explore what it takes to escape a compromised FreeBSD jail by auditing the kernel\u2019s attack surface, identifying dozens of vulnerabilities across exposed subsystems, and developing practical proof-of-concept exploits. We\u2019ll share our findings, demo some real escapes, and discuss what they reveal about the challenges of maintaining robust OS isolation.\nFreeBSD\u2019s jail feature is one of the oldest and most mature OS-level isolation mechanisms in use today, powering hosting environments, container frameworks, and security sandboxes. But as with any large and evolving kernel feature, complexity breeds opportunity. This research asks a simple but critical question: If an attacker compromises root inside a FreeBSD jail, what does it take to break out?\nTo answer that, we conducted a large-scale audit of FreeBSD kernel code paths accessible from within a jail. We systematica"
  },
  {
    "title": "Non-Zero-Sum Games (nonzerosum.games)",
    "points": 325,
    "submitter": "8organicbits",
    "submit_time": "2025-12-30T11:42:55 1767094975",
    "num_comments": 168,
    "comments_url": "https://news.ycombinator.com/item?id=46432311",
    "comments": [
      "One thing I have always thought was missing in game theory (and it is probably there but I just haven't looked hard enough) is a mathematical framework for how to build trust to increase the infinite payout for everyone. If in the decision making the idea of an offering is added in then it brings up the possibility of gauging trust and building trust so that future actions can capture more value until an optimal infinite policy is attained. So, for instance, I look at all my possible options and I choose one based on how much I trust the other party AND how much I want to increase that trust in the future. So I give them an offering, select an option that gives them a little more but at a cost to me, to prove that I am willing to increase trust. If they reciprocate then I loose nothing and the next offering can be bigger. If they don't then I gained knowledge and my next offering is smaller. Basically, this is like tit for tat but over time and intended to get to the optimal solution instead of the min max solution. Clearly I'm not a mathematician, but I bet this could be refined to exact equations and formalized so that exact offerings could be calculated.reply",
      "With an optimal way of determining fair splitting of gains like Shapley value[0] you can cooperate or defect with a probability that maximizes other participants expected value when everyone act fairly.The ultimatum game is the simplest example; N dollars of prize to split, N/2 is fair, accept with probability M / (N /2) where M is what's offered to you; the opponents maximum expected value comes from offering N/2; trying to offer less (or more) results in expected value to them < N/2.Trust can be built out of clearly describing how you'll respond in your own best interests in ways that achieve fairness, e.g. assuming the other parties will understand the concept of fairness and also act to maximize their expected value given their knowledge of how you will act.If you want to solve logically harder problems like one-shot prisoners dilemma, there are preliminary theories for how that can be done by proving things about the other participants directly.  It won't work for humans, but maybe artificial agents.  https://arxiv.org/pdf/1401.5577[0] https://en.wikipedia.org/wiki/Shapley_valuereply",
      "Thanks. I'll take a look!reply",
      "There's certainly academic work about game theory and reputation. Googling \"reputation effects in repeated games\" shows some mentions in university game theory courses. There's also loads of work about how to incentivizing actors to be truthful (e.g. when reviewing peers or products).Signaling theory (in evolutionary biology) might also be vaguely related.reply",
      "This is the TCP backoff algorithm, specifically the slow start to find the optimal bandwidth. In your analogy, it would find the optimal amount that a person is willing to reciprocate.Not only does this algorithm exist, but we're using it to communicate right now!https://en.wikipedia.org/wiki/TCP_congestion_controlreply",
      "I have noticed this algorithm in many places which is why I think it is a missing piece in game theory and why formalizing it could be powerful. People use this instinctively in their interactions with others and algorithms (like the one you pointed out) have been created using the basic concept so a formalization of the math is likely in order. Consider the question of how big the offering should be. What if all parties are actually getting the optimum result, what mechanism stops the increase/why? Does it stop? Could this lead to both parties paying the other larger and larger sums forever? It is a fun thing to think about at least.reply",
      "Yes, this is AIMD and it's well formalised and understood.reply",
      "For those reading this far into the thread, here is a reference to AIMD [1]. Reading through, there is cross-over in the idea but I don't think it 100% covers things. A good starting point to look at though.[1] https://www.geeksforgeeks.org/computer-networks/aimd-algorit...reply",
      "Look into cooperative game theory. If I remember correctly, trust is modelled as a way of exchanging information and influencing the probabilities that other players place on your next actionreply",
      "Nature already solved that and implemented it. It's all around us with relationships. Not just among humans. They typically last over a single interaction. Especially if you don't ignore the rules of the game.But the game theory of nature also leaves room for other sort of players to somehow win over fair play. I thought this was a bug but over time realised it is a feature, critical to making players as a whole stronger. Without it there would be no point for anyone to be creative.If you can solve the issue and make a playbook so that everyone do tic for tac, it won't take long for a bad actor to exploit it, then more, then you are back to where we are now.reply"
    ],
    "link": "https://nonzerosum.games/",
    "first_paragraph": "Hi, I'm Non-Zero-Sum James, your companion on this exploration of win-win games and how they are essential for a better future. Each week we'll explore a new aspect of game theory, moral philosophy, ethical economics and artificial intelligence\u2014looking to solve the complex problems we face in our world together.All the posts are connected through the lens of non-zero-sum games, but they fall into a few broad categories. You can start your journey with whatever appeals to you:Your thoughts and contributions are welcome. Share, debate, and co-create in the comments."
  },
  {
    "title": "Professional software developers don't vibe, they control (arxiv.org)",
    "points": 106,
    "submitter": "dpflan",
    "submit_time": "2025-12-30T20:06:46 1767125206",
    "num_comments": 149,
    "comments_url": "https://news.ycombinator.com/item?id=46437391",
    "comments": [
      "This is pretty recent - the survey they ran (99 respondents) was August 18 to September 23 2025 and the field observations (watching developers for 45 minute then a 30 minute interview, 13 participants) were August 1 to October 3.The models were mostly GPT-5 and Claude Sonnet 4. The study was too early to catch the 5.x Codex or Claude 4.5 models (bar one mention of Sonnet 4.5.)This is notable because a lot of academic papers take 6-12 months to come out, by which time the LLM space has often moved on by an entire model generation.reply",
      "I knew in October the game had changed. Thanks for keeping us in the know.reply",
      "Thanks Simon - always quick on the draw.Off your intuition, do you think the same study with Codex 5.2 and Opus 4.5 would see even better results?reply",
      "Depends on the participants. If they're cutting-edge LLM users then yes, I think so. If they continue to use LLMs like they would have back in the first half of 2025 I'm not sure if a difference would be noticeable.reply",
      "I'm not remotely cutting edge (just switched from Cursor to Codex CLI, have no fancy tooling infrastructure, am not even vaguely considering git worktrees as a means of working), but Opus 4.5 and 5.2 Codex are both so clearly more competent than previous models that I've started just telling them to do high-level things rather than trying to break things down and give them subtasks.If people are really set in their ways, maybe they won't try anything beyond what old models can do, and won't notice a difference, but who's had time to get set in their ways with this stuff?reply",
      "I mostly agree, but today, Opus 4.5 via Claude code did something pretty dumb stuff in my codebase\u2014 N queries where one would do, deep array comparison where a reference equality check would suffice, very complex web of nested conditionals which a competent developer would have never written, some edge cases where the backend endpoints didn\u2019t properly verify user permissions before overwriting data, etc.It\u2019s still hit or miss. The product \u201cworked\u201d when I tested it as a black box, but the code had a lot of rot in it already.Maybe that stuff no longer matters. Maybe it does. Time will tell.reply",
      "I have had a lot of success lately when working with Opus 4.5 using both the Beads task tracking system and the array of skills under the umbrella of Bad Dave's Robot Army. I don't have a link handy, but you should be able to find it on GitHub. I use the specialized skills for different review tasks (like Architecture Review, Performance Review, Security Review, etc.) on every completed task in addition to my own manual review, and I find that that helps to keep things from getting out of hand.reply",
      "I don't think they generally one-shot the tasks; but they do them well enough that you can review the diff and make requests for changes and have it succeed in a good outcome more quickly than if you were spoon-feeding it little tasks and checking them as you go (as you used to have to do).reply",
      "As someone who\u2019s responsible for some very clean codebases and some codebases that grew over many years, warts and all, I always wonder if being subjected to large amounts of not-exactly-wonderful code has the same effect on an LLM that it arguably also has on human developers (myself included occasionally): that they subconsciously lower their normally high bar for quality a bit, as in \u201ewell there\u2018s quite some smells here, let\u2019s go a bit with the flow and not overdo the quality\u201c.reply",
      "What's the difference between using llms now vs the first half of 2025 among the best users?reply"
    ],
    "link": "https://arxiv.org/abs/2512.14012",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n"
  },
  {
    "title": "Quality of drinking water varies significantly by airline (foodmedcenter.org)",
    "points": 12,
    "submitter": "azinman2",
    "submit_time": "2025-12-31T00:03:50 1767139430",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=46439769",
    "comments": [
      "This is bad advice:\u00ab Do not wash your hands in the bathroom; use alcohol-based hand sanitizer containing at least 60% alcohol instead. \u00bbAlcohol only kills some pathogens. Notably, it does not kill norovirus. If the water has coliform bacteria, you should wash your hands with soap and water and then use the alcohol hand sanitizerreply",
      "Worth a listen to this podcast: https://pjvogt.substack.com/p/wait-should-i-not-be-drinking-...reply",
      "WTF is with these AI slop header images... does the author actually think an image of a woman crumpling a cup into her face against a backdrop of airplane parts is not going to distract from the post?reply"
    ],
    "link": "https://foodmedcenter.org/2026-center-for-food-as-medicine-longevity-airline-water-study/",
    "first_paragraph": ""
  },
  {
    "title": "Everything as code: How we manage our company in one monorepo (kasava.dev)",
    "points": 174,
    "submitter": "benbeingbin",
    "submit_time": "2025-12-30T20:05:42 1767125142",
    "num_comments": 164,
    "comments_url": "https://news.ycombinator.com/item?id=46437381",
    "comments": [
      "This is sort of a whole product, but it\u2019s hardly managing the whole company. Financials? HR? Contracts? Pictures of the last  team meeting?It just looks like a normal frontend+backend product monorepo, with the only somewhat unusual inclusion of the marketing folder.reply",
      "It's worth noting with a few clicks from the linked article, you can find that this company is (at least according to LinkedIn) a single person. Which explains how the whole company can fit into a repo. But also makes you question how valuable the \"insights\" here are, like obviously a single-person project should be using a monorepo...reply",
      "Ah, so \"our\" company is referring to \"me and Claude\"? Actually. Claude might be a pretty good co-founder. Half the job is therapy conversations anyway. :)reply",
      "Yes but AI! AI!reply",
      "Not even infrastructure as code is in the repository from what one can see.reply",
      "i am actually eagerly waiting for someone to show the real-deal: actually everything in a github repo, including 'artfiacts', or atleast those artifacts which can't be reconstructed from the repo itself.maybe they could be encrypted, and you could say \"well its everything but the encryption key, which is owned in physical form by the CEO.\"theres a lot of power i think to have everything in one place. maybe github could add the notion of private folders? but now thats ACLs... probably pushing the tool way too far.reply",
      "https://dev.azure.com/byteterrace/Koholint/_git/Azure.Resour...How close do you think this is? Deploys everything but the actual backend/frontend code.reply",
      "At a previous job we put compilers and standard libraries in version control, with custom tooling to pull the right version for what you need.We used p4 rather than git though.reply",
      "maybe they could be encrypted, and you could say \"well its everything but the\n    encryption key, which is owned in physical form by the CEO.\"\n\nI don't see how this is any different from most projects where keys and the like are kept in some form of secrets manager (AWS services, GHA Secrets, Hashi Vault, etc.).reply",
      "I am a huge monorepo supporter, including \"no development branches\".However there's a big difference between development and releases. You still want to be able to cut stable releases that allow for cherrypicks for example, especially so in a monorepo.Atomic changes are mostly a lie when talking about cross API functions, i.e. frontend talking to a backend. You should always define some kind of stable API.reply"
    ],
    "link": "https://www.kasava.dev/blog/everything-as-code-monorepo",
    "first_paragraph": "Generate PRDs from simple descriptionsAI writing help with @kasava mentionsGoals, decisions, and analyticsAST-aware code searchScreenshots to production codeAI-generated docs that stay in syncContext-aware codebase assistantOne-click capture with AI analysisVisual automation for your toolsLast week, I updated our pricing limits. One JSON file. The backend started enforcing the new caps, the frontend displayed them correctly, the marketing site showed them on the pricing page, and our docs reflected the change\u2014all from a single commit.No sync issues. No \"wait, which repo has the current pricing?\" No deploy coordination across three teams. Just one change, everywhere, instantly.At Kasava, our entire platform lives in a single repository. Not just the code\u2014everything:This isn't about abstract philosophies on design patterns for 'how we should work.' It's about velocity in an era where products change fast and context matters.AI is all about context. And this monorepo is our company\u2014not ju"
  },
  {
    "title": "The British empire's resilient subsea telegraph network (subseacables.blogspot.com)",
    "points": 161,
    "submitter": "giuliomagnifico",
    "submit_time": "2025-12-30T13:10:56 1767100256",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=46432999",
    "comments": [
      "I always have to recommend Mother Earth, Mother Board by Neal Stephenson[1] if the thought of undersea cables sounds at all interesting. I'll also second andyjohnson0's recommendation of The Victorian Internet[2] - it blew my mind how much of modern digital culture existed on telegraphs prior to voice.[1] https://www.wired.com/1996/12/ffglass/[2] https://news.ycombinator.com/item?id=46433901reply",
      "https://archive.is/rs7Vqreply",
      "An interesting book on the subject of telegraph networks is The Victorian Internet by Tom Standage [1]. As well as the technical and commercial drivers, it also describes how the telegraph forced people to confront concepts like simultaneity, information being distinct from its physical medium, privacy, early approaches to encryption, etc. A fascinating book.[1] https://en.wikipedia.org/wiki/The_Victorian_Internetreply",
      "The GBP/USD currency pair is still known just as \"the cable\".Aside from all its other uses: the telegraph gave a way to synchronize clocks.  And accurate time is accurate measurement of distance.> [...] The latest determination in 1892 is due to the cooperation of the McGill College Observatory at Montreal, Canada, with the Greenwich Observatory.  [...] The final value for the longitude of the Harvard Observatory at Cambridge, as adjusted in June, 1897, is 4h 44m 31s.046 \u00b10s.048.-- https://adsabs.harvard.edu/full/1897AJ.....18...25S71.12936 W; give or take about 2 metres: https://www.bing.com/maps/?v=2&cp=42.38148%7E-71.12936&style...reply",
      "One of the major uses for the telegraph was the first funds transfers that could happen quicker than moving paper (or bullion) from one location to another. London banks would telegraph correspondent banks in India, Australia, etc.This essentially doubled the capital intensity of international trade since the goods had to move in one direction but the money could be sent instantaneously in the other.reply",
      "That book led me to Gutta Percha, the plastic-like coating on the wires used in these cables which was quite the innovation and made this all possible. Vulcanized rubber was the other option but performed poorly in cables and was harder to work with.https://atlantic-cable.com/Article/GuttaPercha/The above is a fascinating and depressing history of the Gutta Percha factory that made all these cables, after joining with the cable company that supplied the actual wires. There's an 1853 travelogue piece embedded here of an author visiting the factory, where he notes in the worst parts of the factory where boiling and heat are applied, it was staffed with boys who barely made more than a dollar a week. By boys I thought it was slang for young men then I realized 1850s England was heavily using child labor.Those cables are the product of child labor, like much of the Victorian age's industrial and textile output. Children often made up significant portions of factory workforces, sometimes 25-50% in certain textile sectors, with many under 14. I wish the stories of child labor were better told and more prominent. This abuse and exploitation of children gets quite whitewashed during this age and its nice to see it acknowledged, albeit briefly.reply",
      "At least in the UK the fact that the Victorians and others used a lot of child labour is well and widely known.Blake wrote the poem The Chimney Sweeper about boys sold into the trade long before the 1850s and Elizabeth Barrett Browning published The Cry of the Children in Blackwood's magazine in 1843.  Charles Kingsley used his The Water Babies to question child labour and England's treatment of the poor in general in 1862-3.No one with any pretensions to knowledge of those times can claim not to know about child labour.reply",
      "I imagine the percent of people who know these telegram cables were made by children is a very low percentage.reply",
      "Oh wow will definitely give that book a read, very interesting.reply",
      "I've recommended that book on this board before. If you read it, I'd be curious about how you think it hits now, because part of its interest - I'd say insightfulness, at the time, but it now might risk anachronistic \"charm\" - was noting similar emergent behaviors between telegraph operators and early internet adopters. The technical content won't have dated, but the social parts may have.reply"
    ],
    "link": "https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html",
    "first_paragraph": "\nBlog is devoted to educating readers about the subsea cable industry with a particular focus on recent events and new submarine cable projects. Ideal for those in the industry who wants breaking news on outages, new projects, and general industry trends. Roderick Beck worked as a sales contractor for Hibernia Atlantic and helps buyers procure capacity and providers make sales. \nThe British empire had largely completed its Red Line cable network by 1902. This network allowed news and messages to be delivered in a few minutes or several hours at most depending on the message queue's length. It spanned the globe and formed a network ring so traffic could be routed in the opposite direction in case of disruption. It was, as Dr. Michael Delaunay has argued, a highly resilient network. Besides the ring configuration, the network relied on multiple cables between any pair of given end points to ensure uptime. The British military believed it would be impossible for an enemy to cut enough cab"
  }
]