[
  {
    "title": "Valve releases Team Fortress 2 game code (github.com/valvesoftware)",
    "points": 852,
    "submitter": "davikr",
    "submit_time": "2025-02-18T19:57:17 1739908637",
    "num_comments": 207,
    "comments_url": "https://news.ycombinator.com/item?id=43094260",
    "comments": [
      "This is good for modding but don't be misled, this is the TF2-specific code which sits on top of the still-closed-source Source engine. For example you couldn't port TF2 to a new platform with this, at least not without reimplementing Source or wrangling it into working with one of the leaked Source codebases and dealing with the legal fallout of that.\n \nreply",
      "Hard to understand their stance on keeping Source closed. It is not an exciting engine to work with in any way. There are at least 3 major open source alternatives today, way more powerful and easier to work with (O3DE, Godot, Wicked). Only people that have been involved with Source in the past decades would enjoy working with it.The community around the engine is vibrant and well-versed in the caveats of the Source workflow. With a GPL release, just like Carmack did with id tech, the amount of creative projects from indies would sky rocket. No longer bound by obscure deals.\n \nreply",
      "Most in-house game engines built after a certain point use a non-trivial amount of third party code, including console stuff which is under strict NDA, so it's a huge hassle to open source them. Most iterations of the Source engine use Havok physics for example.IdTech probably was only open sourced because Carmack pushed for it, but it helps that IdTech of that vintage was all in-house code exclusively targeting the PC. I think the only thing they had to cut out for legal reasons was the patented shadowing algorithm in Doom 3.\n \nreply",
      "Id were using a 3rd party sound library for Doom to handle the nitty-gritty aspects of DOS sound hardware, so the open source release was based on the linux port of Doom. People had to port it back to DOS.They couldn't release the windows port of Doom either, as that had been done by Microsoft, and would therefore include Microsoft copyrighted code.With Quake, Id did their own windows port, so it was possible to release the source code for winquake.\n \nreply",
      "The wording used in the release notes was:> The bad news: this code only compiles and runs on linux. We couldn't release the dos code because of a copyrighted sound library we used (wow, was that a mistake -- I write my own sound code now), and I honestly don't even know what happened to the port that microsoft did to windows.> Still, the code is quite portable, and it should be straightforward to bring it up on just about any platform.It seems like they just didn't have immediate access to the code for the Windows version. The DOS source code eventually leaked a couple years ago along with the code to the Mac port of Doom. https://archive.org/details/doom-mac-source\n \nreply",
      "Fun fact: Gabe Newell built the original WinDoom port, and led the team that built Doom95!\n \nreply",
      "To be clear, Robert Hess was the primary engineer on WinDoom, Newell was the team lead.\n \nreply",
      "That IS a fun fact.\n \nreply",
      "> as that had been done by Microsoft, and would therefore include Microsoft copyrighted code.How does that follow? Normally copyright would transfer to the company paying for it.\n \nreply",
      "It all depends on how the contract between Microsoft and Id was worded.\n \nreply"
    ],
    "link": "https://github.com/ValveSoftware/source-sdk-2013/commit/0759e2e8e179d5352d81d0d4aaded72c1704b7a9",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          There was a problem hiding this comment.\n      The reason will be displayed to describe this comment to others. Learn more.\n    \ud83d\ude32\n\n\n\n\n\n\n\n\n\n    Sorry, something went wrong.\n  There was a problem hiding this comment.\n      The reason will be displayed to describe this comment to others. Learn more.\n    we are so back\n\n\n\n\n\n\n\n\n\n    Sorry, something went wrong.\n  There was a problem hiding this comment.\n      The reason will be displayed to describe this comment to others. Learn more.\n    Nice job, pardner\n\n\n\n\n\n\n\n\n\n    Sorry, something went wrong.\n  There was a problem hiding this comment.\n      The reason will be displayed to describe this comment to others. Learn more.\n    holy guacamole\n\n\n\n\n\n\n\n\n\n    Sorry, something went wrong.\n  There was a problem hiding this comment.\n      The reason will be displayed to describe this comment to others. Lea"
  },
  {
    "title": "Meta announces LlamaCon, its first generative AI dev conference on April 29 (meta.com)",
    "points": 43,
    "submitter": "thoughtpeddler",
    "submit_time": "2025-02-19T00:18:52 1739924332",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43096922",
    "comments": [
      "Can you imagine how many LinkedIn thought leaders are going to be in attendance? Perhaps the greatest gathering of minds since the Manhattan Project.\n \nreply",
      "Super thrilled about all the cross-functional synergies and ROI-optimized deliverables poised to disrupt the status quo and elevate the strategic framework.\n \nreply",
      "Can't wait to delve into it!\n \nreply",
      "\"Super thrilled about all the cross-functional synergies ...\"Could you explain what that means - please?\n \nreply",
      "It\u2019s just fluff\n \nreply",
      "... whoosh ...\n \nreply",
      "More macro-focused myself, I like to zoom out on Q3 and Q4 dividends to pump the OKRs in sales for higher money:product ratios. I'm so excited to help you guys solve the hardest problems in engineering, together!\n \nreply",
      "\"At LlamaCon, we\u2019ll share the latest on our open source AI developments to help developers do what they do best: build amazing apps and products, whether as a start-up or at scale.\"Strangely enough, I can work quite well without your help.  I've been doing it professionally for 35 odd years.  I'm \"just\" an engineer - no capital E - I simply studied Civil Engineering at college and ended up running an IT company and I'm quite good at IT.What I would really like to see is really well indexed documentation written by people ie an old school search engine.  Google used to do that and so did Altavista, back in the day.I do not need or want a plethora of trite simulacra web sites dripping with AI wankery at every search term.\n \nreply",
      "Great!  Maybe I can finally learn what I'm suppose to be using generative AI for to be more productive.  I'll be tuning in and spinning up whatever models/tools they suggest, but the longer this tech wave occurs the more confident I am that gen-ai is going to tally up to be an at-most 3% lift on global productivity.\n \nreply",
      "I wish they called it llamarama...\n \nreply"
    ],
    "link": "https://www.meta.com/blog/connect-2025-llamacon-save-the-date/",
    "first_paragraph": ""
  },
  {
    "title": "A year of uv: pros, cons, and should you migrate (bitecode.dev)",
    "points": 148,
    "submitter": "bertdb",
    "submit_time": "2025-02-18T21:09:19 1739912959",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=43095157",
    "comments": [
      "A very well written article! I admire the analysis done by the author regarding the difficulties of Python packaging.With the advent of uv, I'm finally feeling like Python packaging is solved. As mentioned in the article, being able to have inline dependencies in a single-file Python script and running it naturally is just beautiful.  #!/usr/bin/env -S uv run\n  # /// script\n  # dependencies = ['requests', 'beautifulsoup4']\n  # ///\n  import requests\n  from bs4 import BeautifulSoup\n\nAfter being used to this workflow, I have been thinking that a dedicated syntax for inline dependencies would be great, similar to JavaScript's `import Module from 'package-name';` syntax. Python promoted type hints from comment-based to syntax-based, so a similar approach seems feasible.> It used to be that either you avoided dependencies in small Python script, or you had some cumbersome workaround to make them work for you. Personally, I used to manage a gigantic venv just for my local scripts, which I had to kill and clean every year.I had the same fear for adding dependencies, and did exactly the same thing.> This is the kind of thing that changes completely how you work. I used to have one big test venv that I destroyed regularly. I used to avoid testing some stuff because it would be too cumbersome. I used to avoid some tooling or pay the price for using them because they were so big or not useful enough to justify the setup. And so on, and so on.I 100% sympathize with this.\n \nreply",
      "One other key part of this is freezing a timestamp with your dependency list, because Python packages are absolutely terrible at maintaining compatibility a year or three or five later as PyPI populates with newer and newer versions. The special toml incantation is [tool.uv] exclude-newer:  # /// script\n  # dependencies = [\n  #   \"requests\",\n  # ]\n  # [tool.uv]\n  # exclude-newer = \"2023-10-16T00:00:00Z\"\n  # ///\n\nhttps://docs.astral.sh/uv/guides/scripts/#improving-reproduc...This has also let me easily reconstruct some older environments in less than a minute, when I've been version hunting for 30-60 minutes in the past. The speed of uv environment building helps a ton too.\n \nreply",
      "Agreed. I did the exact same thing with that giant script venv and it was a constant source of pain because some scripts would require conflicting dependencies. Now with uv shebang and metadata, it\u2019s trivial.Before uv I avoided writing any scripts that depended on ML altogether, which is now unlocked.\n \nreply",
      "Well, big fan of uv.But... the 86GB python dependency download cache on my primary SSD, most of which can be attributed to the 50 different versions of torch, is testament to the fact that even uv cannot salvage the mess that is pip.Never felt this much rage at the state of a language/build system in the 25 years that I have been programming. And I had to deal with Scala's SBT (\"Simple Build Tool\") in another life.\n \nreply",
      "I don't think pip is to blame for that. PyTorch is sadly an enormous space hog.I just started a fresh virtual environment with \"python -m venv venv\" - running \"du -h\" showed it to be 21MB. After running \"venv/bin/pip install torch\" it's now 431MB.The largest file in there is this one:  178M ./lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n\nThere's a whole section of the uv manual dedicated just to PyTorch: https://docs.astral.sh/uv/guides/integration/pytorch/\n \nreply",
      "I use uv pip to install dependencies for any LLM software I run. I am not sure if uv re-implements the pip logic or hands over resolution to pip. But it does not change the fact that I have multiple versions of torch + multiple installations of the same version of torch in the cache.Compare this to the way something like maven/gradle handles this and you have to wonder WTF is going on here.\n \nreply",
      "uv implements its own resolution logic independently of pip.Maybe your various LLM libraries are pinning different versions of Torch?Different Python versions each need their own separate Torch binaries as well.At least with uv you don't end up with separate duplicate copies of PyTorch in each of the virtual environments for each of your different projects!\n \nreply",
      "> Different Python versions each need their own separate Torch binaries as wellFound this the hard way. Something to do with breakage in ABI perhaps. Was looking at the way python implements extensions the other day. Very weird.\n \nreply",
      "> Something to do with breakage in ABI perhaps. Was looking at the way python implements extensions the other day. Very weird.Yes, it's essentially that: CPython doesn't guarantee exact ABI stability between versions unless the extension (and its enclosing package) intentionally build against the stable ABI[1].The courteous thing to do in the Python packaging ecosystem is to build \"abi3\" wheels that are stable and therefore don't need to be duplicated as many times (either on the index or on the installing client). Torch doesn't build these wheels for whatever reason, so you end up with multiple slightly different but functionally identical builds for each version of Python you're using.TL;DR: This happens because of an interaction between two patterns that Python makes very easy: using multiple Python versions, and building/installing binary extensions. In a sense, it's a symptom of Python's success: other ecosystems don't have these problems because they have far fewer people running multiple configurations simultaneously.[1]: https://docs.python.org/3/c-api/stable.html\n \nreply",
      "My use of python is somewhat recent. But the two languages that I have used a lot of - Java and JS - have interpreters that were heavily optimized over time. I wonder why that never happened with python and, instead, everyone continues to write their critical code in C/Rust.I am planning to shift some of my stuff to pypy (so a \"fast\" python exists, kind of). But some dependencies can be problematic, I have heard.\n \nreply"
    ],
    "link": "https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should",
    "first_paragraph": ""
  },
  {
    "title": "Kafka at the low end: how bad can it get? (broot.ca)",
    "points": 47,
    "submitter": "alexwebr",
    "submit_time": "2025-02-18T21:01:02 1739912462",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=43095070",
    "comments": [
      "Kafka for small message volumes is one of those distinct resume-padding architectural vibes.\n \nreply",
      "The kafka protocol is a distributed write ahead log. If you want a job queue you need to build something on top of that, it\u2019s a pretty low level primative.\n \nreply",
      "What do people recommend?Especially for low levels of load, that doesn't require that the dispatcher and consumer are written in the same language.\n \nreply",
      "Until you hit scale, the database you're already using is fine. If that's Postgres, look up SELECT FOR UPDATE SKIP LOCKED. The major convenience is here - aside from operational simplicity - is transactional task enqueueing.For hosted, SQS or Google Cloud Tasks. Google's approach is push-based (as opposed to pull-based) and is far and above easier to use than any other queueing system.\n \nreply",
      "Cloud Tasks is one of the most undervalued tools in the GCP ecosystem, but mostly because PubSub gets all the attention. I've been using it since it was baked in the AppEngine and love it for 1-to-1 queues or delayed job handling.\n \nreply",
      "Famious last words. There are database as a queue antipattern warnings about this.\n \nreply",
      "Why is that an anti-pattern? Databases have added `SKIP LOCKED` and `SELECT FOR UPDATE` to handle these use cases. What are the downsides?\n \nreply",
      "Can you elaborate? I guess it has to do with connection pooling?\n \nreply",
      "SQS, Azure Service Bus, RabbitMQ, ActiveMQ, QPID, etc\u2026 any message broker that provides the competing consumer pattern. though I\u2019ll say having managed many of these message brokers myself, it\u2019s definitely better paying for a managed service. They\u2019re a nightmare when you start running into problems.\n \nreply",
      "If you're using .NET I have to plug\nhttps://particular.net/\nNservicebus from particular.net. It's great at abstracting away the underlying message broker and provides an opinionated way to build a distributed system.\n \nreply"
    ],
    "link": "https://broot.ca/kafka-at-the-low-end.html",
    "first_paragraph": "17 Feb 2025There is oft-quoted advice that Kafka does poorly as a job queue. I\u2019ve experienced\nthis myself, and I wanted to formalize it a bit.I\u2019ll use the common architecture of a Web application submitting\nbackground jobs to workers via Kafka (for example, to generate a PDF of some\nreport).  Except for the use of Kafka in this role, this is common in Web\napplications, and (speaking from experience!) when Kafka is already deployed,\nthere is an impulse to use it instead of deploying yet-another queue system.Note: when Queues for Kafka (KIP-932) becomes\na thing, a lot of these concerns go away. I look forward to it!What I want to characterize here is the worst-case \u201cunfairness\u201d of jobs being\nassigned to workers. There are many other reasons to not use Kafka as a job\nqueue, but this unfairness is (in my view) the strongest reason. In most\nqueues, you put work into the queue and every worker\u2026 well, works until all\nthe work is done. It sound obvious, but that\u2019s the raison d\u2019\u00eatre for these\nt"
  },
  {
    "title": "Show HN: Scripton \u2013 Python IDE with built-in realtime visualizations (scripton.dev)",
    "points": 321,
    "submitter": "nightcraft",
    "submit_time": "2025-02-18T14:57:09 1739890629",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=43090214",
    "comments": [
      "I am a robotics engineer/scientist and I do shit ton of visualization of all kind of high-fidelity/high-rate data, often in a streaming setting - time series at a few thousand Hz, RGB/depth images from multiple cameras, debugging my models by visualizing many layer outputs, every augmentation, etc.For a long time, I had my own observability suite - a messy library of python scripts that I use for visualizing data. I replaced all of them with rerun (https://rerun.io/) and if you are someone who think Scipton is exciting, you should def try rerun too!I use cursor/vscode for my development and add a line or two to my usual workflows in python, and rerun pops up in it's own window. It's a simple pip installable library, and just works. It's open source, and the founders run a very active forum too.Edit: One slightly related tid-bit that might be interesting to HN folks. rerun isn't that old, and is in active development, with some breaking changes and new features that come up every month. And it means that LLM are pretty bad at rerun code gen, beyond the simple boilerplate. Recently, it kind of made my life hell as all of my interns refuse to use docs and try using LLMs for rerun code generation and come to me with a messy code spaghetti. It's both sad and hilarious. To make my life easier, I asked rerun folks to create and host machine readable docs somewhere and they never got to it. So I just scrape their docs into a markdown file and ask my interns to paste the docs in their prompt before they query LLMs and it works like a charm now.\n \nreply",
      "Thanks for the shoutout!We did recently add an export for LLMs[1], but weren't quite confident in how the big models handled it. The biggest issue we kept running into was that it would prefer using older APIs over the latest ones. I tested it just now with ChatGPT, and it seems to be doing a lot better!\nThe export is kept up-to-date with the latest contents of our docs, which update every release. Sometimes a bit more frequently, if we're doing drive-by doc fixes.For convenience, here's a GPT pre-loaded with the file: https://chatgpt.com/g/g-674702fde5948191a810bdf73370b6eb-rer...[1]: https://rerun.io/llms.txt\n \nreply",
      "I am impressed by the AI integration and simplicity of Data Formulator from Microsoft Research which runs one click in a Codespace so can't be much easier to get started throwing things together.https://github.com/microsoft/data-formulator\n \nreply",
      "For magnet levitation project I am dumping data to a csv on a rpi and then reading it over ssh onto matplotlib on my desktop. It works but it choppy. Probably because of the ssh.Could I drop rerun into this to improve my monitoring?https://youtube.com/shorts/Y1LGSMFisDc\n \nreply",
      "Yes! Rerun can definitely make your life a lot easier!Rerun natively supports the server and the viewer being on different devices (https://rerun.io/docs/reference/sdk/operating-modes). In your case, in the script you are dumping data into csv, I'd add the relevant lines to log data to rerun.On the desktop side, you can spawn a viewer that can listen to the stream and visualize it.\n \nreply",
      "Just a note: ReRun works out-of-the box for a number of uses, but I ended up switching to my own (simple, visualization-oriented) engine based on WGPU and EGUI (ReRun uses both of those as well), so I had better control over the camera, visualizations, snapshots etc.\n \nreply",
      "Wow I hadn't seen rerun before, this thing is amazing!\n \nreply",
      "> So I just scrape their docs into a markdown file and ask my interns to paste the docs in their prompt before they query LLMs and it works like a charm now.Huh.  Nice hack.  I may have to give that a try for some of the more obscure stuff I deal with.> Recently, it kind of made my life hell as all of my interns refuse to use docs and try using LLMs for rerun code generation and come to me with a messy code spaghetti. It's both sad and hilarious.I'm really agog at this.  Do your interns understand that if they're just an LLM prompt injector, their job can be done by anybody?  I haven't bumped into this yet, but I think your reaction was a lot more positive than mine would have been.I know that I certainly wouldn't be rehiring any interns that gave me that kind of grief.\n \nreply",
      "I am not the hiring manager, and unfortunately a lot of interviews and hiring decisions happen at org level or at my manager level. These are mostly sophomores/juniors - folks who went through school in post-COVID, post-LLM era with a lot of virtual classes.I tried my best to explain it to them, and nudge them to using docs. I did live debugging sessions with them to try and 'teach' them how to use docs. Ultimately, it was taking away too much of my time for little to no return. I only started working in the industry like a month ago and it's my first time having interns that I didn't pick (back in school, I had undergad research assistants that I interviewed/selected, and they were all excellent) - still learning the ropes.\n \nreply",
      "I've been doing Python development for a long time, since when 2.4 was the hottest thing.I've used the language for all sorts of things: web apps, web APIs, GUI tools, image manipulation, data processing and visualization, some data science, machine learning more recently.I've used many IDEs over the years, currently on PyCharm.Just to qualify the feedback.Pros:- It looks very pretty.- Some nice time saving features.Cons:- Mac only.- Subscription business model.- Having to tie the code to the IDE.Any one of the con's would be a deal breaker for me.Overall I'm not sure what the target market is. Maybe I'm just too used to having free and/or libre tooling.\n \nreply"
    ],
    "link": "https://scripton.dev",
    "first_paragraph": "Version 1.1.0 \u2014 Release NotesVisualize in realtime directly from your Python scripts \u2014 no\u00a0notebooks, servers, or\n                browsers required.Visualizations are displayed in a dedicated\n                    tab right within the IDE.\n                Scripton includes built-in plotting toolkits that expose the capabilities of Plotly\n                and\n                Observable\n                    Plot directly to Python.\n            No installation is necessary \u2014 these libraries are automatically\n                available when executing in Scripton.For more details, check out the Scripton plotting documentation for Lyra\n                (toolkit for Plotly) and Orion\n                (toolkit for Observable Plot).\n            \n                Scripton's architecture combines high-performance interprocess communication for low\n                latency and high throughput on the backend, while leveraging GPU-accelerated rendering to\n                deliver real-time visualizations.\n    "
  },
  {
    "title": "Grim Fandango Puzzle Document (1996) [pdf] (jmac.org)",
    "points": 32,
    "submitter": "krykp",
    "submit_time": "2025-02-16T19:13:15 1739733195",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43070744",
    "comments": [
      "I loved the first and last page...[first]\n\"This report, by its very length, defends itself against the risk of being read.\" -Winston Churchill[last]\n\"To protect this document, please restrict your fallen tears of joy to this box. Thank you!\"\n \nreply",
      "It is honestly one of my favorite documents. With the thought put behind it, it is of no surprise the game was such a well crafted masterpiece.Most software work tends to move away from this kind of ... I don't want to say documentation, we have better documentation tools than ever, more-so a level of writing in general that is more 'human', be it written documents at length or well commented code.Another one is `The Sims` https://news.ycombinator.com/item?id=43064273I recall a Warcraft III one I once saw, that went into technical details on the tooling/scripting packaged with the game. That was another great document too, but I don't have it :)\n \nreply"
    ],
    "link": "http://gameshelf.jmac.org/2008/11/13/GrimPuzzleDoc_small.pdf",
    "first_paragraph": ""
  },
  {
    "title": "XOR (greenend.org.uk)",
    "points": 208,
    "submitter": "mariuz",
    "submit_time": "2025-02-18T10:02:30 1739872950",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=43087944",
    "comments": [
      "If anyone's inner CSS eye is twitching, open DevTools (F12 most of the time) and fix the weirdly centered figures and captions so its actually under the text with the following rules (click the + on the right in Chrome/Brave where the CSS is)```\ndiv.flexcontainer {\n    justify-content: unset;\n}figcaption {\n    text-align: left;\n}\n```\n \nreply",
      "My favourite cursed XOR trick that I think wasn't mentioned is XOR doubly-linked lists. https://en.m.wikipedia.org/wiki/XOR_linked_listInstead of each node storing the next- and previous-pointers separately, store a single pointer which is the XOR of the two. Which is obviously an invalid pointer. But when iterating, XOR the previous node's pointer with the combined pointer to get the next node's pointer, and so on. You can iterate this way in both directions. Feels illegal. :)\n \nreply",
      "Feels like the kind of tricks we pulled in the \"640K ought to be enough for anyone\" era. I would discourage such antics today.\n \nreply",
      "Storage can be further reduced if we think that, with a 64-bit processor, probably a 32-bit address space is enough for most applications (that require less than 4 GB of RAM).Maybe we can go even deeper with 16-bit near/relative pointers. Perhaps data-oriented design fits well in this situation? With blocks of 64k elements and uint16 indices to address elements inside of them.\n \nreply",
      "If anyone is wondering, this is the same Simon Tatham as in Simon Tatham's Portable Puzzle Collection. If you're unfamiliar and ever find yourself offline and bored, they're worth checking out.I know I burnt many hours in high school playing them.https://www.chiark.greenend.org.uk/~sgtatham/puzzles/\n \nreply",
      "And also the same Simon Tatham who wrote PuTTYhttps://www.chiark.greenend.org.uk/~sgtatham/putty/\n \nreply",
      "But you forgot! It's also a 3-wise independent linear hashing function! Which means it can be used for probabilistically approximately uniform sampling and counting of solutions to boolean functions. This is super-duper useful. We use it to build counters that give probabilistic, but proven, counts. I explained the idea here in more understandable terms [1].Basically, it halves the solution space approximately correctly each time. So you keep on adding them, until you have say, 10 solutions. Then you multiply the 10 with 2^k, where k is the number of XORs you added. That's it! So cool, no? And it's super-scalable, because it haves it each time, so you'll get to, say, 10 pretty quick!Some research papers are here [2,3]. I work on this, the tools are here [4,5]. In the last model counting competition, it dominated all other competitors, when combined with an exact counter, slides of the competition here [6].[1] https://www.msoos.org/2018/12/how-approximate-model-counting...\n[2] https://arxiv.org/abs/1306.5726\n[3] https://www.cs.toronto.edu/~meel/Papers/cav20-sgm.pdf\n[4] https://github.com/meelgroup/approxmc\n[5] https://github.com/meelgroup/unigen\n[6] https://mccompetition.org/assets/files/2024/MC2024_awards.pd...\n \nreply",
      "My XOR trick for implementing undo/redo in an Android bitmap painting app, back when apps couldn't use more than about 16MB of memory:- When the user paints a stroke on the canvas, store the \"canvas before painting\" XORed against the \"canvas after the painting\" to create an undo/redo \"patch\".- To undo the stroke, XOR the patch against the canvas. To redo, XOR the same patch.- To further optimize, the patch only needs to cover the area of the stroke, and you can PNG compress it.\n \nreply",
      "One of my favorite XOR stories is from Bryan Cantrill (of Oxide, Joyent, and Sun) in this presentation [0] and this video [1].To avoid clicking a link: When he was at Sun, he was chatting with a coworker (Roger Faulkner) about the lack of logical XOR in C. Faulkner said it was because you couldn't short circuit it, and Brian thought that was wild. Then Roger emailed Dennis Ritchie to ask and he confirmed it was what Faulkner had said.That stories gets me every time! First of all, it's very funny and well delivered by Cantrill, but it's also just so incredible that they could ask the man himself.[0] https://speakerdeck.com/bcantrill/oral-tradition-in-software...[1] https://www.youtube.com/watch?v=4PaWFYm0kEw\n \nreply",
      "C does have a logical XOR, it's the `!=` operator. Unlike other logical operators, it requires the arguments to be normalized to a single truth value. It plays nicely with C's convert-to-boolean operator `!!`.\n \nreply"
    ],
    "link": "https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/xor/",
    "first_paragraph": "[Simon Tatham, 2025-02-14]Recently I was called on to explain the \u2018XOR\u2019 operator to\n      somebody who vaguely knew of its existence, but didn\u2019t have a\n      good intuition for what it was useful for and how it\n      behaved.For me, this was one of those \u2018future shock\u2019 moments when you\n      realise the world has moved on. When I got started in computers,\n      you had to do low-level bit twiddling to get anything very\n      interesting done, so you pretty much couldn\u2019t avoid\n      learning about XOR. But these days, to a high-level programmer,\n      it\u2019s much more of an optional thing, and you can perfectly well\n      not know much about it.So I collected some thoughts together and gave a lecture on\n      XOR. Slightly to my own surprise, I was able to spend a full\n      hour talking about it \u2013 and then over the course of the next\n      couple of weeks I remembered several other things I could\n      usefully have mentioned.And once I\u2019d gone to the effort of collecting all those\n      "
  },
  {
    "title": "One year after switching from Java to Go (glasskube.dev)",
    "points": 84,
    "submitter": "pmig",
    "submit_time": "2025-02-18T16:55:22 1739897722",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=43092003",
    "comments": [
      "Going back to first principles, nominal typing is what I miss most with Go. I get the utility of structs + interfaces + structural typing, but most of the time there is more benefit in declaring that a type nominally implements an interface when that is the intention. Code is far easier to read and understand that way, both for developers and tooling.I suppose exclusively structural typing would be more acceptable if Go supported _real_ interface composition, like Scala with traits or true delegation via the manifold project[1] for Java. But that's missing as well e.g., does not inherently fix the Self problem, etc.Considering Go's initial goal, which was IIRC a better systems language, then yeah, sure it's an improved C. But now that Go is routinely compared with Java/Kotlin and friends, I personally don't see it, particularly wrt the type system, to be taken seriously as a Java contender. Shrug.1. https://github.com/manifold-systems/manifold/blob/master/man...\n \nreply",
      "Are you aware of the trick of \"var _ foo.RequiredInterface = myType{}\" to make the compiler enforce that a struct implements a given interface?Is what you seek a nicer syntax for this or does what you speak of bring something more feature wise?At least IntelliJ IDEs will always make it clear what interfaces all your structs implement.\n \nreply",
      "> But there are obviously work around solutions in the Go ecosystem. It uses the Context ctx, which we pass around functions in order to juggle data around in the application.Man. This works. The context API allows/enables it. But I\u2019d really recommend against passing data to functions via context. The biggest selling point of Go to me is that I can usually just look at anyone\u2019s code and know what it\u2019s doing, but this breaks down when data is hidden inside a context. Dependency injection is entirely possible without using the context package at all, interfaces are great for it.\n \nreply",
      "I hit this point in tfa and had the same comment. Please don\u2019t pass things around in a Comtext.  Maybe stash a slog logger in there, but that\u2019s about it.I made the switch to Go a few years ago. For those who are on a similar journey as the author, or the author himself, I suggest spending time with the Go standard library and tools written by Rob Pike and Russ Cox to get a handle on idiomatic Go.It\u2019s clear the author still thinks in Java, not go. Saying Context ctx for example instead of ctx context.Context.  Also DI, which is arguably not necessary at all in Go given how elegantly interfaces work.I spent quite a lot of time using wire for DI in go only to really study the code it was generating and realizing it truly is code I would normally just write myself.Edit:Regarding stack traces, it turns out you don\u2019t need them. I strongly suggest a top level error handler in Go combined with a custom error struct that records the file and line the error was first seen in your code. Then wrap the error as many times as you want to annotate additional lines as the error is handled up to the top level, but only that first point in our own code is what actually matters nearly all of the time.\n \nreply",
      "This comment is about a very minor part of what you said, but isn\u2019t the whole point of a DI framework to write code you\u2019d have written anyway to save you time?\n \nreply",
      "FWIW the internal Google style guide says to not pass anything via Context unless you _really_ know what you're doing and why. Things that make sense: security tokens and tracing. Things that don't make sense: almost everything else.\n \nreply",
      "Context is just thread local storage aka dynamic scoping aka global variables.It is useful for some things, particularly middleware that needs to cross API boundaries.https://www.felesatra.moe/blog/2019/12/01/transiting-apis\n \nreply",
      "I long for a deep article about the same topic. The real, core difference between Java and Go for backend is declarative vs imperative coding styles.This one, as typical for such articles, repeats typical secondary talking points and even makes similar mistakes. For example it conflates the concept of DI with specifics of implementation in some frameworks.Yes there are older Java frameworks that do runtime magic. But both new Java apps and well designed Go services use compile time dependency injection as a way of achieving dependency inversion.\n \nreply",
      "Which of these languages is declarative? Aren't they both imperative?\n \nreply",
      "Maybe Java when using decorators?\n \nreply"
    ],
    "link": "https://glasskube.dev/blog/from-java-to-go/",
    "first_paragraph": "We are the creators of the Glasskube Open-Source Package Manager for Kubernetes and offering a comprehensive yet easy to use software distribution platform.I always told people memory is cheap, black magic is OK and efficiency doesn't matter in most cases, but boy, how wrong was I...My Java journey started back in 2011 (14 years ago - wow) when I started studying computer science at the Vienna University of Technology.\nUsing editors like jEdit and compiling my Java programs by hand with the command line.\nMy first \"major\" applications were Java Swing GUI applications and \"old school\" web applications with JSP and Servlets.Professionally, I started writing Java code in 2016 when I joined a company that was developing a Java-based web application.\nIt used the classic stack: Java, Spring Boot, Hibernate, and a PostgreSQL database.\nI always loved all the Spring features like Dependency Injection, Spring Security, and Spring Data JPA.\nYes, the application took half a minute to boot up and co"
  },
  {
    "title": "HP Acquires Humane's AI Software (humane.com)",
    "points": 70,
    "submitter": "colesantiago",
    "submit_time": "2025-02-18T22:15:05 1739916905",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=43095811",
    "comments": [
      "> Ai Pin will still allow for offline features like battery level> https://support.humane.com/hc/en-us/articles/34243204841997-...The only feature they could think of was \u201cbattery level\u201d? That\u2019s hilarious\n \nreply",
      "> Device Timeline: Your Ai Pin will continue to function normally until 12pm PST on February 28, 2025. After this date, it will no longer connect to Humane\u2019s servers, and .Center access will be fully retired.> Device Features: Your Ai Pin features will no longer include calling, messaging, Ai queries/responses, or cloud access.For a $700 device that was on the market for less than a year, that is a not a stellar way to treat your customers. Fortunately it seems there were very few of those.[0] https://support.humane.com/hc/en-us/articles/34374173951373-...\n \nreply",
      "> We understand this transition may be difficultYou have to be a right knob to describe this as a \u201ctransition\u201d\n \nreply",
      "What customers?> Humane\u2019s daily returns are outpacing saleshttps://www.theverge.com/2024/8/7/24211339/humane-ai-pin-mor...\n \nreply",
      "It\u2019s The Verge.  Don\u2019t believe anything they publish.\n \nreply",
      "I have this regulation idea:If the hardware requires software that is not available for self service, then the customer is entitled for full refund at any time.In other words if the hardware is just an accessory for providing service through software then the money the user pays for the hardware should be considered a refundable deposit.\n \nreply",
      "You should propose it!  I hear the CFPB is looking for new ways to protect consumers.\n \nreply",
      "Unfortunately the CFPB is in the process of being eliminated.\n \nreply",
      "I believe that was the joke.\n \nreply",
      "Hey taxes are MY MONEY and I need that 2 cents back (so I can be scammed hundreds of dollars by corporations that no longer need to comply with the CFPB)\n \nreply"
    ],
    "link": "https://humane.com/media/humane-hp",
    "first_paragraph": "An important note to our customers about your Ai Pin. Please read it here\u202618 February 2025|Humane NewsPalo Alto, CA, February 18, 2025 \u2013 HP Inc. (NYSE: HPQ) announced a definitive agreement to acquire key AI capabilities from Humane, including their AI-powered platform Cosmos, highly skilled technical talent, and intellectual property with more than 300 patents and patent applications. The acquisition advances HP\u2019s transformation into a more experience-led company.\u00a0\"This investment will rapidly accelerate our ability to develop a new generation of devices that seamlessly orchestrate AI requests both locally and in the cloud,\" said Tuan Tran, President of Technology and Innovation at HP. \"Humane\u2019s AI platform Cosmos, backed by an incredible group of engineers, will help us create an intelligent ecosystem across all HP devices from AI PCs to smart printers and connected conference rooms. This will unlock new levels of functionality for our customers and deliver on the promises of AI.\"\u00a0Th"
  },
  {
    "title": "Launch HN: Promptless (YC W25) \u2013 Automatic updates for customer-facing docs",
    "points": 52,
    "submitter": "prithvi2206",
    "submit_time": "2025-02-18T17:30:39 1739899839",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=43092522",
    "comments": [
      "Very needed! I\u2019ve worked on platform teams and API docs were always rushed last second to push out a release\u2014-but in many ways they are the product.Another pain point was creating guides/examples for integrating 3rd party tools. Could be worth exploring\n \nreply",
      "For sure. It can be challenging to inculcate a culture of treating docs as a product, but since great docs can drive revenue growth and bad docs can increase churn, it's a very important mindset.In terms of creating guides/examples for third-party tools, do you have a particular use-case in mind? e.g. if you're something like Zapier with hundreds of connections?\n \nreply",
      "Re: 3rd party integrations, think glue code for enterprise platforms (I previously worked on the developer platform at Shopify).For example, a guide to integrate Shopify's Storefront API with Sanity CMS. These are usually a marketing/product thing more than developer docs... and almost always become obsolete after the next release and forgotten about.Would've loved to generate a bunch of these guides and then automatically keep them up-to-date with code examples, and help serve both purposes for growth and developer docs.\n \nreply",
      "Can it be attached to Discord? One of the most annoying things I find is the loss of precious info in there. Even when channels are not removed or entire servers disappear, the search is so bad that no one (...) bothers and just re-asks.\n \nreply",
      "Exactly the right use-case. Discord has been requested a couple of times, and is coming soon! Happy to reach out when it's available.\n \nreply",
      "I'm curious, does it get triggered when a PR is opened or when it is merged?  Because if it is when it is opened, updates to the PR could still get made which I assume would cause updates to the doc changes.  Also, what if 2 PRs are opened at the same time?  What if a PR is opened but never merged?\n \nreply",
      "Great questions! It is possible to get Promptless to run only when PRs are merged, or when commits are made on `main`, but pretty much everyone wants the doc updates to be drafted when PRs are opened, because they'd like to review the doc updates in parallel (i.e. before it's actually released). If two PRs are created at the same time, Promptless will review them separately (and potentially create two docs PRs, if both have customer-facing impact).Honestly, some of these workflow points are areas that we're probably going to adjust and add more configuration around. For example, some folks with very high commit velocity are asking for a \"daily digest\" docs PR from Promptless instead of individual docs PRs.\n \nreply",
      "Why not have a flow that automatically adds/updates stuff to the PR itself?\n \nreply",
      "If you're asking about when there are new commits on the source code after a PR is opened, yes that's what happens! It just updates the existing docs branch.If you're asking if Promptless should just add doc updates to the same PR as the code PR, that's definitely an option, but people tend to just want them separate both because it fits better with their workflows and it's less contingent on CI/CD processes, if that makes sense.\n \nreply",
      "This is really cool, congrats on launch!I am curious how you prevent private data from getting leaked to the auto-generated public docs. I imagine this problem does not exist in open source projects, but would become an issue if not everything discussed in company's private messenger should be used as context for generating docs.\n \nreply"
    ],
    "link": "item?id=43092522",
    "first_paragraph": ""
  },
  {
    "title": "Are LLMs able to play the card game Set? (github.com/vnglst)",
    "points": 23,
    "submitter": "vnglst",
    "submit_time": "2025-02-15T10:28:55 1739615335",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43057465",
    "comments": [
      "Since you can train an LLM to play chess from scratch, I would not be surprised if you could also train one to play Set. I might experiment with it tomorrow.https://adamkarvonen.github.io/machine_learning/2024/01/03/c...\n \nreply",
      "Woah, what's going on?? I've always played Set with stripey cards, is this a custom deck or did they change it at some point???This is wildly disconcerting to me\n \nreply",
      "This is definitely a custom/knock-off deck. Not only are the stripes not stripey, the capsules are now ovals and the diamonds are now rectangles.\n \nreply",
      "FYI: Card 8's transcription is different than the image. In the image 5, 8, 12 is a Set but the transcription says Card 8 only has 2 symbols which removes that Set.\n \nreply",
      "Not only that, but 2,6,7 is also a set but not included in the results\n \nreply",
      "Set is a card game where players have to identify sets of three cards from a layout of 12. Each card features a combination of four attributes: shape, color, number, and shading. A valid set consists of three cards where each attribute is either the same on all three cards or different on each. The goal is to find such sets quickly and accurately.Though this game is a solved computer problem \u2014 easily tackled by algorithms or deep learning \u2014 I thought it would be interesting to see if Large Language Models (LLMs) could figure it out.\n \nreply",
      "If you think this is fun, try to see how it garbles predicate logic.\n \nreply",
      "I am increasingly concerned that these new reasoning models are thinking.\n \nreply",
      "I still think that we\u2019re at much greater risk of discovering that human thinking is much less magical, than we are of making a machine that does magical thinking.\n \nreply",
      "No problem.  Just redefine \"thinking\".\n \nreply"
    ],
    "link": "https://github.com/vnglst/when-ai-fails/tree/main/playing-set",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          Set is a card game where players have to identify sets of three cards from a layout of 12. Each card features a combination of four attributes: shape, color, number, and shading. A valid set consists of three cards where each attribute is either the same on all three cards or different on each. The goal is to find such sets quickly and accurately.Though this game is a solved computer problem \u2014 easily tackled by algorithms or deep learning \u2014 I thought it would be interesting to see if Large Language Models (LLMs) could figure it out.Here's the prompt:Here\u2019s what the game looks like:There\u2019s a shorthand notation for describing the attributes of a card. For instance, the card in the top left corner of the image above can be described as O2RS, meaning it has two solid red ovals.Here\u2019s the full definition of the notation:Using this notation, any d"
  },
  {
    "title": "Pi-hole v6 (pi-hole.net)",
    "points": 350,
    "submitter": "tkuraku",
    "submit_time": "2025-02-18T18:31:36 1739903496",
    "num_comments": 184,
    "comments_url": "https://news.ycombinator.com/item?id=43093328",
    "comments": [
      "I set up pi-hole recently after hearing about it for years. I was kind of surprised at a lack of really basic features (imo):There isn't any kind of \"dry run\" or \"phantom\" mode, where requests are not actually blocked, but appear marked in the log UI as \"would be blocked\". This is super important because I want to see all the things my home network is doing that would be blocked before I actually hit the big red button. I want to fix up the allow/denylist before going live.It's also not possible (or not clear) how to have different behavior for different clients. For my \"smart tv\" which I begrudgingly have to allow on my network occasionally for software updates, I want to treat it with the strictest possible list. But for my phone, I don't want that same list. There's a concept of \"groups\" so perhaps this is user error on my part, but the UI does not make this clear.\n \nreply",
      "> It's also not possible (or not clear) how to have different behavior for different clientsThere's a menu item for that: Clients.  You create a group, add a client to that group, and configure blocking for that group.  To have what you want, you create a group that has just one client in it.\n \nreply",
      "It's slightly more complicated. What you are suggesting works if (1) you are using Pi-hole as a DHCP server or (2) all your devices are individually configured to use the Pi-hole IP address for DNS resolution. What's more likely though is that you just point your router's DNS setting to Pi-hole, and in that case there is only one client on the Pi-hole dashboard - your router.\n \nreply",
      "> What's more likely though is that you just point your router's DNS setting to Pi-hole, and in that case there is only one client on the Pi-hole dashboard - your router.That depends entirely on what capabilities your router has.Many routers have a setting for the DNS info they give to clients via DHCP, which would mean every client is indeed using PiHole directly for DNS resolution.Other less capable routers, only have a setting for which upstream DNS server(s) the router should use, which of course isn't going to allow you to do anything with PiHole's group stuff.But an easy solution is simply to disable the DHCP server on the router, and simply use what is built-in to PiHole. It uses dnsmasq behind the scenes, and as DHCP servers go, it's pretty capable and configurable. This is how I use PiHole on my own network, and have done for years now (with some customised dnsmasq config, because I have strong preferences about my network setup and services).Most routers do nothing particularly special regarding DHCP anyhow, so no big deal to just turn it off, and use PiHole's stuff.FWIW, and tangent to these specific points, my upgrade to the new PiHole 6 earlier today was pretty smooth \u2014 with the exception of it defaulting to having its dashboard on port 8080 instead of my previous 80. Plus I had to tweak a couple of settings to ensure it loads my custom dnsmasq config. But no deal breakers at all.\n \nreply",
      "And if your gateway device is configurable enough you can ban or redirect port 53 requests (DNS) to whatever machine you would like to use to serve up resolution.\n \nreply",
      "It works for me and I don't use Pi-Hole as a DHCP server or have any of my devices individually configured.  I have my router acting as a DHCP server and have it tell clients to use my Pi-hole for DNS.  Some routers' default firmwares don't let you do this, but most OpenWRT and Tomato and the like should.\n \nreply",
      "I haven't tried Pi-Hole yet but is there a package for OpenWrt which could offer functionalities equivalent to Pi-Hole?I already run OpenWrt on x86 hardware so I have plenty of RAM and disk.\n \nreply",
      "Using clients and groups works fine for me. I'm able to block youtube on my kids' devices, but allow it on others. I have pihole running in a container without being my dhcp server.\n \nreply",
      "Not all routers proxy DNS; many have DHCP settings so you can give the pi-hole\u2019s address as DNS server to clients via DHCP.I imagine this is how it\u2019s usually done. There\u2019s no reason to double proxy.\n \nreply",
      "I think [1] is quite irrelevant to be honest. Blocking DNS isn't a destructive operation. I've been using pi-hole for years and I simply block everything and cherry-pick a few exceptions here and there when something breaks. I only had to really troubleshoot maybe 3-4 times in years, and half of that were related to the fact I worked for companies that had domains blocked.\n \nreply"
    ],
    "link": "https://pi-hole.net/blog/2025/02/18/introducing-pi-hole-v6/",
    "first_paragraph": "\u00a0We\u2019re excited to announce the general release of Pi-hole v6!We\u2019ve integrated a new REST API and embedded web server directly into the pihole-FTL binary. This eliminates the need for lighttpd and PHP, reducing the installation footprint and boosting performance. The new API also offers server-side pagination for the query log, ensuring a faster and more responsive interface.As lua has been embedded into the pihole-FTL binary for some time now, we have been able to leverage this to rewrite the web interface.Pi-hole v6 introduces support for subscribed allowlists (Otherwise known as \u201cAntigravity\u201d). These lists work in much the same way as blocklists, but they\u00a0allow\u00a0domains instead of\u00a0denying themWe\u2019ve streamlined configuration management by consolidating multiple settings files into a single, richly commented toml file, making it easier to manage and understand your settings. If you are migrating from v5, your existing configurations will be migrated automatically into this file. It can "
  },
  {
    "title": "Migraine is more than a headache \u2013 a rethink offers hope (nature.com)",
    "points": 61,
    "submitter": "rntn",
    "submit_time": "2025-02-18T15:47:25 1739893645",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=43090857",
    "comments": [
      "I've suffered from migraines all my life. It worsened as I've gotten older. One day long attacks turned into three day long attacks. Then turned into five day long attacks. I've taken various preventatives and abortives over the years to varying success. It runs in my family so I never thought to see a neurologist for them. A couple years ago I had a bad string of them and my medicine wasn't really touching it, so I finally decided to see a headache specialist. The doctor very quickly got me started one of these anti-CGRP medications.Almost immediately, I dropped to 0-1 attacks a month, and when they do happen they are both less painful and my other medicine knocks them out fast.Literally life changing.\n \nreply",
      "I got my first migraine in my early teens. I was over at a friend's house and we were playing in the basement on a summer day, then went outside where the sun reflected off a window into my eyes.It would start with a shimmering pattern obstructing my vision where the bright light was, which would grow into a c shape and get bigger until it surrounded my vision and then faded away. About 15 min after the shimmering pattern faded the blistering pain would start and last for about 5 hours, with lingering light sensitivity until the next day.I later realized that something about a rapid change in brightness (from dark to bright) would trigger them for me.Another time was triggered by a high school shop teacher lighting a welding torch.The best way to relieve the pain I found was to turn out all the lights and dunk my head in cold water, which I discovered eventually in desperation for relief.I would only get them every few months, but when I did I would be pretty useless for most of the day. I stopped getting them in my early 20s. No idea why, but I am grateful. They sucked!\n \nreply",
      "I sometimes get shimmering patterns which I think they call visual migraine or https://en.wikipedia.org/wiki/Scintillating_scotoma but thankfully mine don't go on to migraine proper. They often seem set of by a bright light outside the center of vision like I'm reading a book with sunlight coming in from 45 degrees.\n \nreply",
      "Exactly the same trigger here. I had one just the other day at the pub. Sitting outside, under shade, but to my left was a bright spot. It\u2019s weird how I can sense it arriving ... something about the quality of my vision subtly changes, and there it is.Fortunately for me it isn\u2019t accompanied by a headache. It\u2019s just really unsettling. At least now I\u2019ve learned to recognise them and I just try to chill out while it does its thing.(FWIW, also a tremendous consumer of caffeine here. But this was at 17:00, a good 5 hours after my last cup.)\n \nreply",
      "I've had fewer than a dozen episodes starting last year. Luckily, like you, I have scintillating scotoma without headache. I haven't noticed a trigger--they're just spontaneous. A couple of years before, I had a couple of episodes of binocular diplopia (https://www.yalemedicine.org/conditions/double-vision). Dunno if they're related.\n \nreply",
      "I've mentioned this before in previous HN threads about scintillating scotomas, but it's worth repeating: in my case, the issue was entirely due to excessive caffeine consumption. When I got them frequently I was sometimes consuming upwards of 450mg/day, when I cut intake way down they disappeared entirely, and when I occasionally fall off the wagon and have way too much that's when they come back.\n \nreply",
      "Yep, I realized mine were caused by looking out the window while I brushed my teeth in the morning.  One day it was really bright outside and really dark inside and the migraine started almost immediately.  More than a year and I keep the blinds drawn while I'm in the bathroom in the morning and not a single migraine!\n \nreply",
      "That feels pretty similar to my story. I always put it down to some kind of puberty changes.\n \nreply",
      "Yes! At least some migraines are caused by whatever second-order effect there is from hormonal changes.\n \nreply",
      "I started having migraines at 8 years of age, several a week. This persisted all through my life till 42 years later, I had a blood pressure emergency where I ended up in ER with 190/100 blood pressure. Thankfully, it never repeated and was never diagnosed but as a consequence I was put on Olmesartan, a blood pressure medication that relaxes the blood vessels. Eventually, the dose was reduced to the lowest, 5mg, once a day, to which I added 240mg magnesium glycinate, which they sell in Costco. I have been mostly migraine free since for several years and ones I do get are mild compared to before.My cardiologist, who prescribed the blood pressure medication, is mystified saying that while beta blockers are a migraine prevention medication, olmesartan isn't a beta blocker and maybe it was just my (mild) hypertension which needed to be treated. I doubt that I had hypertension when I was 8 but I'm just thankful that decades of pain have come to an end.\n \nreply"
    ],
    "link": "https://www.nature.com/articles/d41586-025-00456-x",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.AdvertisementFred Schwaller is a freelance writer based in Berlin.You can also search for this author in PubMed\n\u00a0Google Scholar\n Illustration: Aleksandra Czud\u017cakAndrea West remembers the first time she heard about a new class of migraine medication that could end her decades of pain. It was 2021 and she heard a scientist on the radio discussing the promise of gepants, a class of drug that for the first time seemed to prevent migraine attacks. West followed news about these drugs closely, and when she heard last year that atogepant was approved for use in the United Kingdom, she went straight to her physician. West had endur"
  },
  {
    "title": "Converge (YC S23) is hiring engineer #2 in NYC (gem.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-02-18T21:00:58 1739912458",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jobs.gem.com/converge/am9icG9zdDreA6I3WJ4ZJ1Yx_WHS5zKP",
    "first_paragraph": ""
  },
  {
    "title": "File Pilot: A file explorer built for speed with a modern, robust interface (filepilot.tech)",
    "points": 81,
    "submitter": "vjekoslav",
    "submit_time": "2025-02-18T16:24:01 1739895841",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=43091466",
    "comments": [
      "Please, I beg you dear developer, replace my stupid MacOS finder with your superpowers!\n \nreply",
      "There are a few good Finder alternatives for macOS, including Path Finder, ForkLift, Commander One, and Double Commander (FOSS).\n \nreply",
      "Windows only? Why would I use (buy) this over DirectoryOpus? \nThat said would love to see it on Linux.\n \nreply",
      "The top of the homepage says File Pilot was made from scratch (so I'd expect inherently less technical debt than something that's been around since the 90's). Comparing its screenshots to Directory Opus, it looks less cluttered, or at least slightly different. The interface looks like it adheres to the Windows 11 design style a little more, versus Directory Opus's screenshots looking like Windows 8-10.If I used Windows regularly, I'd probably appreciate having another option, just as I appreciate (and even take for granted) the ability to switch between various options on Linux.\n \nreply",
      "On the other hand, 35 years of cruft also represents 35 years of accumulated knowledge about what people want from a file manager. So one should not dismiss Directory Opus based upon a few screenshots.Fresh blood is certainly a good thing though. I am just arguing that we should not dismiss something based upon its age or cosmetics.(Directory Opus is one of the few things that I miss while using Linux.)\n \nreply",
      "I prefer to use Win10 and probably move to Linux after that, so the interface doesn't match the rest of my OS. It's incredibly fast though.But speaking of technical debts, I couldn't open a UNC path ( \\\\nas\\share\\ ). Opening a network share mounted to a drive letter worked fine though.\n \nreply",
      "Rather poetically, this C software in 2025 segfaults on launch. I would file a GitHub issue if this was open source, but alas, nope.\n \nreply",
      "Looks great. I ran a test browsing a folder of pdfs but it does not look like File Pilot likes previwing pdfs with Acrobat set as default pdf viewer; no preview/thumbnail shown for pdfs.\n \nreply",
      "Please make a mac version.\n \nreply",
      "There has been for many years now: https://binarynights.com/\n \nreply"
    ],
    "link": "https://filepilot.tech/",
    "first_paragraph": "Engineered entirely from scratch for light-speed performance, featuring a modern and robust interface.\r\n\t\t\t\tBeta v0.2.8 | 1.8 MB |\n Windows 7+ (64-bit)\r\n\t\t\tCrafted for seamless performance, delivering results in the blink of an eye. Never wait on your files again.From panels and tabs to context menus and command palette, everything can be searched and accessed using both mouse and keyboard.Customize color themes, optimize hotkeys, and save and switch between layouts.Available in Free BetaCore features that make finding, inspecting, and managing files feel second nature.Create your perfect setup with any panel layout and open folders in new tabs, all easily arranged with simple drag and drop.View flattened folder hierarchies, including entire drives, in milliseconds. Perform fuzzy searches and filter by file extensions.Quickly peek into file contents, including text, images, or even other folders, without leaving the program.Interactively rename multiple files at once, with options to g"
  },
  {
    "title": "Alice Hamilton Waged a One-Woman Campaign to Get the Lead Out of Everything (smithsonianmag.com)",
    "points": 8,
    "submitter": "Hooke",
    "submit_time": "2025-02-18T23:22:22 1739920942",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.smithsonianmag.com/innovation/how-alice-hamilton-waged-one-woman-campaign-get-lead-out-everything-180985960/",
    "first_paragraph": ""
  },
  {
    "title": "My LLM codegen workflow (harper.blog)",
    "points": 267,
    "submitter": "lolptdr",
    "submit_time": "2025-02-18T19:33:32 1739907212",
    "num_comments": 84,
    "comments_url": "https://news.ycombinator.com/item?id=43094006",
    "comments": [
      "That lonely/downtime section at the end is a giant red flag for me.It looks like the sort of nonproductive yak-shaving you do when you're stuck or avoiding an unpleasant task--coasting, fooling around incrementally with your LLM because your project's fucked and you psychologically need some sense of progress.The opposite of this is burnout--one of the things they don't tell you about successful projects with good tools is they induce much more burnout than doomed projects. There's a sort of Amdahl's Law in effect, where all the tooling just gives you more time to focus on the actual fundamentals of the product/project/problem you\u2019re trying to address, which is stressful and mentally taxing even when it works.Fucking around with LLM coding tools, otoh, is very fun, and like constantly clean-rebuilding your whole (doomed) project, gives you both some downtime and a sense of forward momentum--look how much the computer is chugging!The reality testing to see if the tool is really helping is to sit down with a concrete goal and a (near) hard deadline. Every time I've tried to use an LLM under these conditions it just fails catastrophically--I don't just get stuck, I realize how basically every implicit decision embedded in the LLM output has an unacceptably high likelihood of being wrong, and I have an amount of debug cycles ahead of me exceeding the time to throw it all away and do it without the LLM by, like, an order of magnitude.I'm not an LLM-coding hater and I've been doing AI stuff that's worked for decades, but current offerings I've tried aren't even close to productive compared to searching for code that already exists on the web.\n \nreply",
      "It sounds like LLMs are the new futzing with emacs configuration.\n \nreply",
      "Absolutely LLMs are great for greenfield projects. They can get you to a prototype for a new idea faster than any tool yet invented. Where they start to break down, I find, is when you ask it to make changes/refactors to existing code and mature projects. They usually lack context, so they doesn't hesitate to introduce lots of extra complexity, add frameworks you don't need, and in general just make the situation worse. Or if they get you to some solution it will have taken so long that you might as well have just done the heavy lifting yourself. LLMs are still no substitute for actually understanding your code.\n \nreply",
      "The first part of this, where you told it to ask YOU questions, rather than laboriously building prompts and context yourself was the magic ticket for me.  And I doubt I would have stumbled on that sorta inverse logic on my own.  Really great write up!\n \nreply",
      "This is the key to a lot of my workflows as well. I'll usually tack some form of \"ask me up to 5 questions to improve your understanding of what I'm trying to do here\" onto the end of my initial messages. Over time I've noticed patterns in information I tend to leave out which has helped me improve my initial prompts, plus it often gets me thinking about aspects I hadn't considered yet.\n \nreply",
      "Frankly getting used to doing this may help our communication with other engineers as well.\n \nreply",
      "promo from L5->L7 confirmed.\n \nreply",
      "The big question is, which level will be replaced by GPT first?\n \nreply",
      "Indeed!The example prompts are useful. They not only reduced the activation energy required for me to start installing this habit in my personal workflows, but also inspired the notion that I can build a library of good prompts and easily implement them by turning them into TextExpander snippets.P.S.: Extra credit for the Insane Clown Posse reference!\n \nreply",
      "I add something like \u201cask me any clarifying questions\u201d to my my initial prompts. For larger requests, it seems to start a dialogue of refinement before providing solutions.\n \nreply"
    ],
    "link": "https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/",
    "first_paragraph": ""
  },
  {
    "title": "Nuclear fusion: WEST beats the world record for plasma duration (cea.fr)",
    "points": 230,
    "submitter": "mpweiher",
    "submit_time": "2025-02-18T19:26:33 1739906793",
    "num_comments": 203,
    "comments_url": "https://news.ycombinator.com/item?id=43093939",
    "comments": [
      "I wonder if many of the stars in the sky are from groups that almost nailed containment and stability on their Tokamak.\n \nreply",
      "The Sun consumes a mass equivalent of a mount Everest worth of hydrogen via fusion to shine for just an hour (or thereabouts if I did my math right :), I'm sure someone will tell me soon if not). For perspective, this amount of energy is more than enough to power the Earth's current electrical usage for over a billion years.That's all before getting into how a containment failure doesn't imply \"and then everything nearby just started a self sustaining fusion chain reaction\" anyways.\n \nreply",
      "Seems implausible. The fusion presumably wouldn\u2019t keep going if it breached the walls.Also, to be bright enough that we would see it from here as a star, I imagine it would require enough material that one might as well just let gravity do the job rather that use a Tokamak?Maybe there are efficiency gains that are large enough that it wouldn\u2019t actually require as much material as a star? I wouldn\u2019t guess so though.\n \nreply",
      "> This was a 25% improvement on the previous record time achieved with EAST, in China, a few weeks previouslyI applaud this nuclear arms race. 22 minutes is really impressive for a technology that\u2019s always been \u201c20 years away\u201d. I think I will do a deep dive on the technical challenges of fusion.\n \nreply",
      "Related?Nuclear fusion: New record set at Chinese reactor EAST https://news.ycombinator.com/item?id=42917662 03-feb-2025China's artificial sun burns for 1000 secs, creates record in fusion research https://news.ycombinator.com/item?id=42854306 28-jan-2025\n \nreply",
      "From the announcement, \"1,337 seconds: that was how long WEST, a tokamak run from the CEA Cadarache site in southern France and one of the EUROfusion consortium medium size Tokamak facilities, was able to maintain a plasma for on 12 February. This was a 25% improvement on the previous record time achieved with EAST, in China, a few weeks previously.\"1,337-second burn.\n \nreply",
      "Lots of leet scientists there, in all seriousness. CEA is my alma mater, though I worked on quantum computing, not fusion.\n \nreply",
      "how many more seconds did they push it to hit 133t xD\n \nreply",
      "Considering it's fusion we're talking about, 1,337 seconds is about as arbitrary as 1,000 seconds. On a 24-hour clock, 13:37 is 1:37pm. 137 is the fine-structure constant or \u03b1. Who knows what they're actually capable of. A second more at this point would be pointless.\n \nreply",
      "I wonder how much of an effect this kind of truly international (not in the same 'bloc') competition will have on budgets and speed of progress. Cold war tech race, etc.It should be a good time to be an engineer.\n \nreply"
    ],
    "link": "https://www.cea.fr/english/Pages/News/nuclear-fusion-west-beats-the-world-record-for-plasma-duration.aspx",
    "first_paragraph": "\r\n                                        To access all features of this site, you must enable Javascript. Here are the instructions for enabling Javascript in your web browser.\r\n                                    \r\n                                                From research to industry\r\n                                            The French Alternative Energies and Atomic Energy Commission (CEA) is a key player in research, development and innovation.Discover the main research areas on which the CEA works.\u200bFind the latest scientific and institutional news of the CEA.The CEA publishes various scientific and technical periodicals and videos. Through them, you can discover the CEA\u2019s major research topics and the latest technological innovations produced by its laboratories.Press release | Energies | Fusion through magnetic containment | Nuclear fusion\u200bOn 12 February, the CEA\u2019s WEST machine was able to maintain a plasma for more than 22 minutes. In doing so, it smashed the previous rec"
  },
  {
    "title": "Tensor evolution: A framework for fast tensor computations using recurrences (arxiv.org)",
    "points": 37,
    "submitter": "matt_d",
    "submit_time": "2025-02-18T18:55:31 1739904931",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43093610",
    "comments": [
      "This is neat! I've been thinking about how to best express recursion with diagrams for tensorgrad (https://github.com/thomasahle/tensorgrad) and this might just be it.So much computation these days are done on tensors, mostly for easy parallelism reasons. But we can't get completely rid of recursion. Great to have work like this making them more computationally compatible!\n \nreply",
      "> Tensor Evolution (TeV)Oh no, I'm never not going to read this as \"tera-electron Volts\". I wish they picked a different acronym!\n \nreply",
      "lol who is interested in this on hn? this has nothing to do with frameworks or training or inference or whatever. this is purely about \"when can i infer statically XYZ property about tensor constants in a program\". mind you, small tensor constants, because this thing is effectively performing actual tensor arithmetic and you don't want slow tensor arithmetic in your compiler.also FYI they're not magically calculating closed form solutions to recurrence relations here (that's not possible) - they're basically just iterating the loop arithmetic.\n \nreply",
      "> lol who is interested in this on hn?I\u2019m guessing lots of people who are on HN. I\u2019ll go with - me for one. Guessing I\u2019m not alone.Remember - it\u2019s a big world. Lots of POVs.\n \nreply",
      "I am. Why would you assume otherwise?\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2502.03402",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "South Korean regulator accuses DeepSeek of sharing user data with ByteDance (bbc.com)",
    "points": 152,
    "submitter": "devonnull",
    "submit_time": "2025-02-18T20:29:16 1739910556",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=43094651",
    "comments": [
      "Some missing context is that the data is shared via the DeepSeek app's use of ByteDance analytics/configuration frameworks. So not a backroom deal where DeekSeek handed over the chat history for its user base, but rather ongoing analytics data being sent from the DeepSeek mobile app.Here's the SecurityScoreCard article that brought attention to this: https://securityscorecard.com/blog/a-deep-peek-at-deepseek/#...Besides the usual analytics data (device metadata, user behavior, app performance, errors, etc), it's possible raw chat data is being shared as well, but it's not a smoking gun.\n \nreply",
      "We analyzed the iOS app[1] and observed similar traffic as well as a number of basic security issues (hardcoded encryption keys, use of 3DES and some traffic over HTTP).[1] https://www.nowsecure.com/blog/2025/02/06/nowsecure-uncovers...\n \nreply",
      "So Deepkseek is not sharing more data than most advertising-funded apps in the world?\n \nreply",
      "Only if they were breaking the law too.\n \nreply",
      "Yeah they act holier than thou when someone else takes data but then turn around and do it themselves, I think that's called hypocrisy. Besides, once data goes to your ISP its gone, aren't we better off just limiting data that we want to keep private?\n \nreply",
      "Interesting, but I don't think those details will be ameliorative to the people who are concerned (e.g. U.S. Congress).In fact, I wonder if it may further underscore their concerns, given that it surfaces the interconnectedness between all of these firms.\n \nreply",
      "Yep.No one cares about the details. (Heck, I'd be willing to wager good money that the politicians and most of their staffers don't even understand the details). In the end, it's just one more reason that Chinese models will not be legal in the US in the near future.\n \nreply",
      "> it's just one more reason that Chinese models will not be legal in the US in the near futureThis isn't about the model, it's about the mobile app.The open source model weights are different from the website and the app. The model cannot track you.Not just Congress, even techies can be confused about these things.\n \nreply",
      "Yes, exactly, what the guy above was saying is that they're just looking for excuses to keep people from using the Chinese thing.\n \nreply",
      "Protectionism can be dumb, if competition from china is decimation the US LLM market, making the cheaper better competitors illegal sounds like sound advice to someone like trump, probably?\n \nreply"
    ],
    "link": "https://www.bbc.com/news/articles/c4gex0x87g4o",
    "first_paragraph": "South Korea has accused Chinese AI startup DeepSeek of sharing user data with the owner of TikTok in China.\"We confirmed DeepSeek communicating with ByteDance,\" the South Korean data protection regulator told Yonhap News Agency.The country had already removed DeepSeek from app stores over the weekend over data protection concerns.The Chinese app caused shockwaves in the AI world in January, wiping billions off global stock markets over claims its new model was trained at a much lower cost than US rivals such as ChatGPT.Since then, multiple countries have warned that user data may not be properly protected, and in February a US cybersecurity company alleged potential data sharing between DeepSeek and ByteDance.DeepSeek's apparent overnight impact saw it shoot to the top of App Store charts in the UK, US and many other countries around the world - although it now sits far below ChatGPT in UK rankings.In South Korea, it had been downloaded over a million times before being pulled from App"
  }
]