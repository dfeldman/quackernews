[
  {
    "title": "Vibechart (vibechart.net)",
    "points": 591,
    "submitter": "datadrivenangel",
    "submit_time": "2025-08-07T21:36:45 1754602605",
    "num_comments": 128,
    "comments_url": "https://news.ycombinator.com/item?id=44830684",
    "comments": [
      "There are versions of both these charts with more plausible numbers and bar sizes in the \"evaluation\" section of the announcement post:https://openai.com/index/introducing-gpt-5/So, maybe this is just sloppiness and not intentionally misleading. But still, not a good look when the company burning through billions of dollars in cash and promising to revolutionize all human activity can't put together a decent powerpoint.reply",
      "This is what eating your own dog food looks like when you are selling dog food.reply",
      "That's not really a fair comparison.  Dog food has nutritive value.reply",
      "Is this the moment the bubble pops (at least for OpenAI)?GPT-5 has to be one of the most underwhelming releases to date, and that's fresh on the heels of the \"gift\" of GPT-OSS.The hottest news out of OpenAI lately is who Mark Zuckerberg has added to Meta's \"Superintelligence\" roster.reply",
      "The gift of GPT-OSS that is actually Phireply",
      "GPT-5 models are actually great models for the API, the nano model is finally good enough to handle complex structured responses and it's even cheaper than GPT-4.1-nano.reply",
      "Saved. Thanks for that belly laugh.reply",
      "People at OpenAI are the top of their field.  It is not sloppiness in this crowd.reply",
      "People at the top of their field can be deeply sloppy at times.reply",
      "I mean it in the kindest way, but scientists might be the sloppiest group I've worked with (on average, at least). They do amazing work, but they're willing to hack it together in the craziest ways sometimes. Which is great in a way. They're very resourceful and focused on the science, not necessarily the presentation or housekeeping. That's fine.reply"
    ],
    "link": "https://www.vibechart.net/",
    "first_paragraph": ""
  },
  {
    "title": "GPT-5 (openai.com)",
    "points": 1405,
    "submitter": "rd",
    "submit_time": "2025-08-07T17:00:21 1754586021",
    "num_comments": 1686,
    "comments_url": "https://news.ycombinator.com/item?id=44826997",
    "comments": [
      "It is frequently suggested that once one of the AI companies reaches an AGI threshold, they will take off ahead of the rest. It's interesting to note that at least so far, the trend has been the opposite: as time goes on and the models get better, the performance of the different company's gets clustered closer together. Right now GPT-5, Claude Opus, Grok 4, Gemini 2.5 Pro all seem quite good across the board (ie they can all basically solve moderately challenging math and coding problems).As a user, it feels like the race has never been as close as it is now. Perhaps dumb to extrapolate, but it makes me lean more skeptical about the hard take-off / winner-take-all mental model that has been pushed.Would be curious to hear the take of a researcher at one of these firms - do you expect the AI offerings across competitors to become more competitive and clustered over the next few years, or less so?reply",
      "It's also worth considering that past some threshold, it may be very difficult for us as users to discern which model is better.  I don't think thats what's going on here, but we should be ready for it.  For example, if you are an ELO 1000 chess player would you yourself be able to tell if Magnus Carlson or another grandmaster were better by playing them individually? To the extent that our AGI/SI metrics are based on human judgement the cluster effect that they create may be an illusion.reply",
      "> For example, if you are an ELO 1000 chess player would you yourself be able to tell if Magnus Carlson or another grandmaster were better by playing them individually?No, but I wouldn't be able to tell you what the player did wrong in general.By contrast, the shortcomings of today's LLMs seem pretty obvious to me.reply",
      "Actually, chess commentators do this all the time. They have the luxury of consulting with others, and discussing + analyzing freely. Even without the use of an engine.reply",
      "Anyone more than ~300 points below the players can only contribute to the discussion in a superficial capacity thoughreply",
      "the argument is for in the future, not nowreply",
      "The future had us abandon traditional currency in favor of bitcoin, it had digital artists being able to sell NFTs for their work, it had supersonic jet travel, self driving or even flying cars. It had population centers on the moon, mines on asteroids, fusion power plants, etc.I think large language models have the same future as supersonic jet travel. It\u2019s usefulness will fail to realize, with traditional models being good enough but for a fraction of the price, while some startups keep trying to push this technology but meanwhile consumers keep rejecting it.reply",
      "I've seen this take a lot, but I don't know why because it's extremely divorced from reality.Demand for AI is insanely high. They can't make chips fast enough to meet customer demand. The energy industry is transforming to try to meet the demand.Whomever is telling you that consumers are rejecting it is lying to you, and you should honestly probably reevaluate where you get your information. Because it's not serving you well.reply",
      "Even if models keep stagnating at roughly the current state of the art (with only minor gains), we are still working through the massive economic changes they will bring.Unlike supersonic passenger jet travel, which is possible and happened, but never had much of an impact on the wider economy, because it never caught on.reply",
      "Cost was what brought supersonic down. Comparatively speaking, it may be the cost/benefit curve that will decide the limit of this generation of technology. It seems to me the stuff we are looking at now is massively subsidised by exuberant private investment. The way these things go, there will come a point where investors want to see a return, and that will be a decider on wether the wheels keep spinning in the data centre.That said, supersonic flight is yet very much a thing in military circles \u2026reply"
    ],
    "link": "https://openai.com/gpt-5/",
    "first_paragraph": ""
  },
  {
    "title": "Cursed Knowledge (immich.app)",
    "points": 121,
    "submitter": "bqmjjx0kac",
    "submit_time": "2025-08-07T23:34:52 1754609692",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=44831704",
    "comments": [
      "I loved this the moment I saw it. After looking at an example commit[1], I love it even more. The cursed knowledge entry is committed alongside the fix needed to address it. My first instinct is that every project should have a similar facility. The log is not just cathartic, but turns each frustrating speedbump into a positive learning experience. By making it public, it becomes both a tool for both commiseration and prevention.1 - https://github.com/savely-krasovsky/immich/commit/aeb5368602...reply",
      "The '50 extra packages' one is wild. The author of those packages has racked up a fuckload of downloads. What a waste of total bandwidth and disk space everywhere. I wonder if it's for clout.reply",
      "The maintainer who this piece of \u201ccursed knowledge\u201d is referencing is a member of TC39, and has fought and died on many hills in many popular JavaScript projects, consistently providing some of the worst takes on JavaScript and software development imaginable. For this specific polyfill controversy, some people alleged a pecuniary motivation, I think maybe related to GitHub sponsors or Tidelift, but I never verified that claim. I dare not speak his name, lest I incur the wrath of various influential JavaScript figures who are friends with him, and possibly keep him around like that guy who was trained wrong as a joke in Kung Pow: Enter the Fist. In 2025, I\u2019ve moderated my opinion of him; he does do important maintenance work, and it\u2019s nice to have someone who seems to be consistently wrong in the community, I guess.reply",
      "It's probably a clout thing, or just a weird guy (Hanlon's Razor), but a particularly paranoid interpretation is that this person is setting up for a massive, multi-pronged software supplychain attack.reply",
      "The author is almost certainly ljharb.reply",
      "It does raise the idea of managed backward compatibility.Especially if you could control at install time just how far back to go, that might be interesting.Also an immediately ridiculous graph problem for all but trivial cases.reply",
      "> npm scripts make a http call to the npm registry each time they run, which means they are a terrible way to execute a health check.Is this true? I couldn\u2019t find another source discussing it. That would be insane behavior for a package manager.reply",
      "> Some phones will silently strip GPS data from images when apps without location permission try to access them.That's no curse, it's a protection hex!reply",
      "I have no idea what that means but to me it looks like it works as designed.reply",
      "A ward evenreply"
    ],
    "link": "https://immich.app/cursed-knowledge/",
    "first_paragraph": ""
  },
  {
    "title": "Flipper Zero dark web firmware bypasses rolling code security (rtl-sdr.com)",
    "points": 135,
    "submitter": "lq9AJ8yrfs",
    "submit_time": "2025-08-07T21:10:42 1754601042",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=44830408",
    "comments": [
      "Tons of the rolling key systems on the market are based on KeyLoq, and keyloq is a fairly well designed system with a big lynch pin.It has something called a 'manufacturer key', which needs to be available to any device that allows field pairing of remotes. If that manufacturer key is known, it only takes two samples from an authenticator to determine the sequence key.Absent the manufacturer key, jamming+replay attacks work, but brute forcing a sequence key is generally prohibitively costly.However, since any receiver that supports field programming needs the magic \"manufacturer key\", one could purchase such a unit, and may be able to extract said key.reply",
      "This is why keyless \"start button\" functions on cars is a bad idea.The old approach of keyfob to unlock the car and a real key for the ignition is safer.Having multiple levels of security is good.However, having worked in the car security industry many years ago, I discovered that car manufacturers actually like it when their customer's cars are stolen - Insurance payouts often result in another sale.reply",
      "I sometimes imagine how much of this could be avoided if the communication signals weren't (a) broadcast or (b) a imperceptible to humans.If it an electrical contact in the door handle, it would be very difficult for anyone to monitor or inject other signals.If the signals were audible sound, you'd know when someone was jamming it.In practice, my number one use of a fob from a remote distance is locking, rather than unlocking, and those two operations don't have the equivalent security risk.reply",
      "> In practice, my number one use of a fob from a remote distance is locking, rather than unlocking, and those two operations don't have the equivalent security risk.Wouldn't the risk be the same if the same rolling code keys was used for both locking and unlocking?I would be surprised if automotive manufacturers used separate rolling code keys for locking and unlocking.reply",
      "Why are so many car manufacturers incapable of using cryptography properly?reply",
      "Car manufacturers are like automation/control manufacturers; they existed before cybersecurity and never caught up to the pace. If you ever audited any SCADA system, you will see nightmares. For cars, some new models of popular brands (not specifying any), you can access the CANbus from the headlight where you can reprogram the ECM to your new key. It's that simple to \"own\" a modern car.reply",
      "PREACH!Currently sitting in a control room at a greenfield manufacturing facility trying to describe why even VLANning the control network would be a good idea to some controls engineers who want a plant-wide subnet for all PLCs that will be remotely supported by 6 different vendors.  The struggle is realreply",
      "Loosely aware a controller manufacturer who wanted a bluetooth/wifi based password recovery utility with a fixed or predictable recovery key.They were asked what their exposure would be if someone walked into a datacenter and used their phone to disable all the airconditioning systems.reply",
      "Do they want the passwords for all their systems to match so they don't need to remember as many?reply",
      "My suspicion is that they want all the passwords on this site to match the one they use with all their other customers too.Saves money on password management.reply"
    ],
    "link": "https://www.rtl-sdr.com/flipperzero-darkweb-firmware-bypasses-rolling-code-security/",
    "first_paragraph": ""
  },
  {
    "title": "Historical Tech Tree (historicaltechtree.com)",
    "points": 277,
    "submitter": "louisfd94",
    "submit_time": "2025-08-07T19:24:49 1754594689",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=44829185",
    "comments": [
      "This 2D map is hard to explore since it's so sparse. I have to follow lines to find each thing, since it's 99% empty void. Is there a snap to next item hotkey? Am I just doing it wrong?reply",
      "Obviously something of this magnitude will have blindspots. This tech tree seems to be vastly underselling the impact of advances in metallurgy and precision machining. As well as most of what you might call \"basic science\".This leads to e.g. the Gas Turbine just appearing out of nowhere, not depending on any previous technologyreply",
      "They tried to define what they mean by technology [1], but they seemingly gave up on it partway through. Had they followed it consistently, they would have excluded certain cultural-practice-based technologies like nixtamalization that made the list.The inconsistent definition and the pretty large gaps leads to a lot of oddness. Just look at how sparse anything related to textiles is. \"Clothing\" just gets one \"invention\" in 168k B.P., even though a t-shirt and an arctic jacket are obviously very different technologies. New world agriculture is similarly strange. Nodes appear from nowhere and lead nowhere, presumably because there are implicit \"nature\" edges they didn't want to represent as technology.[1] https://www.hopefulmons.com/p/what-counts-as-a-technologyreply",
      "Feel like if you're doing something like this you should just basically maximalize your definition. The fun here is seeing all the nodes, obviously!Maybe then you get into arguments about whether the dependencies were \"required\", but there it's more or less resolvable by relying on what \"actually\" happened rather than the minimal tree (which is its own exercise)reply",
      "> Had they followed it consistently, they would have excluded certain cultural-practice-based technologies like nixtamalization that made the list.This is an interesting example. It's a technology that's very important for staying alive, but not one that you'd expect to contribute to any kind of progress. It's just something you have to do to corn before eating it.reply",
      "They are expecting suggestions for this work in progress.https://www.historicaltechtree.com/about#contributingreply",
      "A lot of those things are incremental improvements that build onto each other, like refining an alloy by a few % many times over to end up with something entirely different.How would one determine what is sufficiently different to deserve a node?But 100% agree, incremental improvements are the vast majority of advances.reply",
      "My particular interest is in screw cutting lathes, and it appears that the Wikipedia entry[1] (on which this seems to be based) was off by about 25 years (1775 instead of 1800), and thus copied to this work. I've let the folks at Wikipedia know.[1] https://en.wikipedia.org/wiki/Screw-cutting_lathereply",
      "Interesting. On that note, Da Vinci's design (which I was fortunate enough to see a replica of at a local museum) was also very clever, being suited not only for screw cutting but also screw origination, as it could make new screws more accurately than the two leadscrews in the machine itself, and swap them out to improve its own accuracy. But I suppose it doesn't extend that date even further back because it wasn't a general purpose lathe, it could only cut screws.reply",
      "Making sure you've seen this youtube channel, which is excellent: https://www.youtube.com/@machinethinkingreply"
    ],
    "link": "https://www.historicaltechtree.com/",
    "first_paragraph": ""
  },
  {
    "title": "GPT-5: Key characteristics, pricing and system card (simonwillison.net)",
    "points": 432,
    "submitter": "Philpax",
    "submit_time": "2025-08-07T17:46:18 1754588778",
    "num_comments": 186,
    "comments_url": "https://news.ycombinator.com/item?id=44827794",
    "comments": [
      "It's cool and I'm glad it sounds like it's getting more reliable, but given the types of things people have been saying GPT-5 would be for the last two years you'd expect GPT-5 to be a world-shattering release rather than incremental and stable improvement.It does sort of give me the vibe that the pure scaling maximalism really is dying off though. If the approach is on writing better routers, tooling, comboing specialized submodels on tasks, then it feels like there's a search for new ways to improve performance(and lower cost), suggesting the other established approaches weren't working. I could totally be wrong, but I feel like if just throwing more compute at the problem was working OpenAI probably wouldn't be spending much time on optimizing the user routing on currently existing strategies to get marginal improvements on average user interactions.I've been pretty negative on the thesis of only needing more data/compute to achieve AGI with current techniques though, so perhaps I'm overly biased against it. If there's one thing that bothers me in general about the situation though, it's that it feels like we really have no clue what the actual status of these models is because of how closed off all the industry labs have become + the feeling of not being able to expect anything other than marketing language from the presentations. I suppose that's inevitable with the massive investments though. Maybe they've got some massive earthshattering model release coming out next, who knows.reply",
      "The quiet revolution is happening in tool use and multimodal capabilities. Moderate incremental improvements on general intelligence, but dramatic improvements on multi-step tool use and ability to interact with the world (vs 1 year ago), will eventually feed back into general intelligence.reply",
      "Completely agree. General intelligence is a building block. By chaining things together you can achieve meta programming. The trick isn't to create one perfect block but to build a variety of blocks and make one of those blocks a block-builder.reply",
      "lol that's what they tell their investors I hope people don't actually believe this though.reply",
      "Can you please make your substantive points thoughtfully? Thoughtful criticism is welcome but snarky putdowns and onliners, etc., degrade the discussion for everyone.You've posted substantive comments in other threads, so this should be easy to fix.If you wouldn't mind reviewing https://news.ycombinator.com/newsguidelines.html and taking the intended spirit of the site more to heart, we'd be grateful.reply",
      "> It does sort of give me the vibe that the pure scaling maximalism really is dying off though\n\nI think the big question is if/when investors will start giving money to those who have been predicting this (with evidence) and trying other avenues.Really though, why put all your eggs in one basket? That's what I've been confused about for awhile. Why fund yet another LLMs to AGI startup. Space is saturated with big players and has been for years. Even if LLMs could get there that doesn't mean something else won't get there faster and for less. It also seems you'd want a backup in order to avoid popping the bubble. Technology S-Curves and all that still apply to AIThough I'm similarly biased, but so is everyone I know with a strong math and/or science background (I even mentioned it in my thesis more than a few times lol). Scaling is all you need just doesn't check outreply",
      "I started such an alternative project just before GPT-3 was released, it was really promising (lots of neuroscience inspired solutions, pretty different to Transformers) but I had to put it on hold because the investors I approached seemed like they would only invest in LLM-stuff. Now a few years later I'm trying to approach investors again, only to find now they want to invest in companies USING LLMs to create value and still don't seem interested in new foundational types of models... :/I guess it makes sense, there is still tons of value to be created just by using the current LLMs for stuff, though maybe the low hanging fruits are already picked, who knows.I heard John Carmack talk a lot about his alternative (also neuroscience-inspired) ideas and it sounded just like my project, the main difference being that he's able to self-fund :) I guess funding an \"outsider\" non-LLM AI project now requires finding someone like Carmack to get on board - I still don't think traditional investors are that disappointed yet that they want to risk money on other types of projects..reply",
      "> I guess funding an \"outsider\" non-LLM AI project now requires finding someone like Carmack to get on board\n\nAnd I think this is a big problem. Especially since these investments tend to be a lot cheaper than the existing ones. Hell, there's stuff in my PhD I tabled and several models I made that I'm confident I could have doubled performance with less than a million dollars worth of compute. My methods could already compete while requiring less compute, so why not give them a chance to scale? I've seen this happen to hundreds of methods. If \"scale is all you need\" then shouldn't the belief that any of those methods would also scale?reply",
      "I'm pretty curious about the same thing.I think a somewhat comparable situation is in various online game platforms now that I think about it. Investors would love to make a game like Fortnite, and get the profits that Fortnite makes. So a ton of companies try to make Fortnite. Almost all fail, and make no return whatsoever, just lose a ton of money and toss the game in the bin, shut down the servers.On the other hand, it may have been more logical for many of them to go for a less ambitious (not always online, not a game that requires a high player count and social buy-in to stay relevant) but still profitable investment (Maybe a smaller scale single player game that doesn't offer recurring revenue), yet we still see a very crowded space for trying to emulate the same business model as something like Fortnite. Another more historical example was the constant question of whether a given MMO would be the next \"WoW-killer\" all through the 2000's/2010's.I think part of why this arises is that there's definitely a bit of a psychological hack for humans in particular where if there's a low-probability but extremely high reward outcome, we're deeply entranced by it, and investors are the same. Even if the chances are smaller in their minds than they were before, if they can just follow the same path that seems to be working to some extent and then get lucky, they're completely set. They're not really thinking about any broader bubble that could exist, that's on the level of the society, they're thinking about the individual, who could be very very rich, famous, and powerful if their investment works. And in the mind of someone debating what path to go down, I imagine a more nebulous answer of \"we probably need to come up with some fundamentally different tools for learning and research a lot of different approaches to do so\" is a bit less satisfying and exciting than a pitch that says \"If you just give me enough money, the curve will eventually hit the point where you get to be king of the universe and we go colonize the solar system and carve your face into the moon.\"I also have to acknowledge the possibility that they just have access to different information than I do! They might be getting shown much better demos than I do, I suppose.reply",
      "I'm pretty sure the answer is people buying into the scaling is all you need argument. Because if you have that framing then it can be solved through engineering, right? I mean there's still engineering research and it doesn't mean there's no reason to research but everyone loves the simple and straight forward path, right?  > I think a somewhat comparable situation is in various online game platforms\n\nI think it is common in many industries. The weird thing is that being too risk adverse creates more risk. There's a balance that needs to be struck. Maybe another famous one is movies. They go on about pirating and how Netflix is winning but most of the new movies are rehashes or sequels. Sure, there's a lot of new movies, but few get nearly the same advertising budgets and so people don't even hear about it (and sequels need less advertising since there's a lot of free advertising). You'd think there'd be more pressure to find the next hit that can lead to a few sequels but instead they tend to be too risk adverse. That's the issue of monopolies though... or any industry where the barrier to entry is high...  > psychological hack\n\nWhile I'm pretty sure this plays a role (along with other things like blind hope) I think the bigger contributor is risk aversion and observation bias. Like you say, it's always easier to argue \"look, it worked for them\" then \"this hasn't been done before, but could be huge.\" A big part of the bias is that you get to oversimplify the reasoning for the former argument compared to the latter. The latter you'll get highly scrutinized while the former will overlook many of the conditions that led to success. You're right that the big picture is missing. Especially that a big part of the success was through the novelty (not exactly saying Fortnite is novel via gameplay...). For some reason the success of novelty is almost never seen as motivation to try new things.I think that's the part that I find most interesting and confusing. It's like an aversion of wanting to look just one layer deeper. We'll put in far more physical and mental energy to justify a shallow thought than what would be required to think deeper. I get we're biased towards being lazy, so I think this is kinda related to us just being bad at foresight and feeling like being wrong is a bad thing (well it isn't good, but I'm pretty sure being wrong and not correcting is worse than just being wrong).reply"
    ],
    "link": "https://simonwillison.net/2025/Aug/7/gpt-5/",
    "first_paragraph": "7th August 2025I\u2019ve had preview access to the new GPT-5 model family for the past two weeks (see related video) and have been using GPT-5 as my daily-driver. It\u2019s my new favorite model. It\u2019s still an LLM\u2014it\u2019s not a dramatic departure from what we\u2019ve had before\u2014but it rarely screws up and generally feels competent or occasionally impressive at the kinds of things I like to use models for.I\u2019ve collected a lot of notes over the past two weeks, so I\u2019ve decided to break them up into a series of posts. This first one will cover key characteristics of the models, how they are priced and what we can learn from the GPT-5 system card.Let\u2019s start with the fundamentals. GPT-5 in ChatGPT is a weird hybrid that switches between different models. Here\u2019s what the system card says about that (my highlights in bold):GPT-5 is a unified system with a smart and fast model that answers most questions, a deeper reasoning model for harder problems, and a real-time router that quickly decides which model to us"
  },
  {
    "title": "Cursor CLI (cursor.com)",
    "points": 160,
    "submitter": "gonzalovargas",
    "submit_time": "2025-08-07T20:53:54 1754600034",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=44830221",
    "comments": [
      "I wonder when all of them will adopt AGENT.md and stop using gemini.md/claude.md/crush.md/summary.md/qwen.mdhttps://agent.md [redirect -> https://ampcode.com/AGENT.md]\nhttps://agent-rules.orgreply",
      "FWIW at least with Claude and Jules on a project I have a decent setup where I put all of the real content in an agents.md and then use \u201c@agents.md\u201d in CLAUDE.md. If all of the tools supported these kinds of context references in markdown it wouldn\u2019t be that hard to have a single source of truth for memory files.reply",
      "Every time I\u2019ve ever read a {CLAUDE|GEMINI|QWEN}.md I\u2019ve thought all this information could just be in CONTRIBUTING.md instead.reply",
      "Yes! I want an option to always add README.md to the context; It would force me to  have a useful, up to date document about how to build, run, and edit my projects.reply",
      "I just wish the AGENTS.md standard wasn't a single file. I have a lot of smaller context documents that aren't applicable to every task, so I like to throw them into a folder (.ai/ or .agents/) and then selectively cat them together or tell the agent to read them.reply",
      "That's a more obvious (but less fun) name than what I've been using: ROBOTS.md with symlinks.reply",
      "https://ampcode.com/AGENT.md#migrationthey also suggest using symlinks for nowreply",
      "Yep, that's a peeve of mine. I've resorted to using AGENT.md, and aliasing Claude, Gemini, etc to a command that calls them with an initial instruction to read that file. But of course they will forget after some time.The whole agentic coding via CLI experience could be much improved by:- Making it easy to see what command I last issued, without having to scroll up through reams of output hunting for context\n- Making it easy to spin up a proper sandbox to run sessions unattended\n- Etc.Maybe for code generation, what we actually need is a code generator that is itself deterministic but uses AI, instead of AI that does code generation.reply",
      "I think most of them provide an option to change the default file, but it'll be really good if they all can switch to AGENT.md by defaultTill then you can also use symlinksthere are issues opened in some repos for this- Support \"AGENT.md\" spec + filename \u00b7 Issue #4970 \u00b7 google-gemini/gemini-clihttps://github.com/google-gemini/gemini-cli/issues/4970#issu...reply",
      "https://github.com/anthropics/claude-code/issues/1091Here for Claudereply"
    ],
    "link": "https://cursor.com/cli",
    "first_paragraph": "\u00a9 2025 Made by AnysphereProductHomePricingFeaturesEnterpriseBugbotDownloadsStudentsResourcesDocsBlogForumChangelogCompanyAnysphereCareersCommunityCustomersLegalTermsSecurityPrivacySOC 2 Certified\u00a9 2025 Made by AnysphereSOC 2 Certified"
  },
  {
    "title": "OpenAI's new open-source model is basically Phi-5 (seangoedecke.com)",
    "points": 168,
    "submitter": "emschwartz",
    "submit_time": "2025-08-07T18:59:46 1754593186",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=44828884",
    "comments": [
      "I saw a bunch of people complaining on Twitter about how GPT-OSS can't be customized or has no soul and I noticed that none of them said what they were trying to accomplish.\"The main use-case for fine-tuning small language models is for erotic role-play, and there\u2019s a serious demand.\"Ah.reply",
      "Want a good use case?I am playing around with interactive workflow where the model suggests what can be wrong with a particular chunk of code, then the user selects one of the options, and the model immediately implements the fix.Biggest problem? Total Wild West in terms of what the models try to suggest. Some models suggest short sentences, others spew out huge chunks at a time. GPT-OSS really likes using tables everywhere. Llama occasionally gets stuck in the loop of \"memcpy() could be not what it seems and work differently than expected\" followed by a handful of similar suggestions for other well-known library functions.I mostly got it to work with some creative prompt engineering and cross-validation, but having a model fine-tuned for giving reasonable suggestions that are easy to understand from a quick glance, would be way better.reply",
      "Porn is always the frontier.It's a well-understood self-contained use-case without many externalities and simple business models.What more, with porn, the medium is the product probably more  than the content. Having it on home-media in the 80s was the selling point. Getting it over the 1-900 phone lines or accessing it over the internet ... these were arguably the actual product. It might have been a driver of early smart phone adoption as well. Adult content is about an 80% consumption on handheld devices while the internet writ large is about 60%.Private tunable multi-media interaction on-demand is the product here.Also it's a unique offer.  Role playing prohibited sexual acts can be done arguably victim free.There's a good fiction story there... \"I thought I was talking to AI\"reply",
      "even if it is victim free, it can affect mental health in a way that a consumer will be more compelled to do a criminal act and create a real victim.let's say you publish a Steam game how to be a school shooter and shoot kids, wouldn't that lead to real school shootings ?who can definitely say that computer generated content about criminal behavior, won't lead to real crime with real victims?https://en.wikipedia.org/wiki/Active_Shooterreply",
      "I view it more like methadone.Let's be specific: Rape, incest, necrophilia, bestiality, and pedophila ideation.I think we can all agree (1) these are harmful, anti-social behaviors that we do not want in our society, (2) people don't choose to have these desires, (3) most people who have them have no desire to actually traumatize others, (4) people who have these struggle with it.I've long called these \"sexual handicaps\".These environments would allow that type of engagement without any harm.Now given all this, I am not a psychologist and do not know if that's part of how someone unfortunate enough to have those inclinations can deal with it healthily.But if it is, now it exists and hopefully we can see less of it in the real world. I'm all for harm reduction.reply",
      "Who can say that it does?reply",
      "1, Porn. 2 Military.reply",
      "The firmer is a lot more nimble and the procurement processes of your customers are easier to navigate.reply",
      "There's something Freudian about the idea that the more you can customize porn, the more popular it is. That, despite the impression that \"all men want one thing\", it turns out that men all want very different and very oddly specific things. Imbuing somrthing with a \"magical\" quality that doesnt exist is the origin of the term \"fetish\". Its not about the raw attractive preference for a particular hair color; its a belief in the POWER of that hair color.reply",
      "oh it's wildly different. About 15 years ago I worked on a porn recommendation system. The idea is that you'd follow a number of sites based on likes and recommendations and you'd get an aggregated feed with interstitial ads.So I started with scraping and cross-reference, foaf, doing analysis. People's preferences are ... really complex.Without getting too lewd, let's say there's about 30-80 categories with non-marginal demand depending on how you want to slice it and some of them can stack so you get a combinatoric.In early user testing people wanted the niche and found the adventurous (of their particular kind) to be more compelling. And that was the unpredictable part. The majoritarian categories didn't have stickiness.Nor did these niches have high correlation. Someone could be into say, specific topic A (let's say feet), and correlating that with topic B (let's say leather) was a dice roll. The probabilities were almost universally < 10% unless you went into majoritarian categories (eg. fit people in their 20s).People want adventure on a reservation with a very well defined perimeter - one that is hard to map and different for every person.So the value-add proposition went away since it's now just a collection of niche sites again.Also, these days people have Reddit accounts reserved for porn  where they do exactly this. So it was built after all.reply"
    ],
    "link": "https://www.seangoedecke.com/gpt-oss-is-phi-5/",
    "first_paragraph": "OpenAI just released its first ever open-source1 large language models, called gpt-oss-120b and gpt-oss-20b. You can talk to them here. Are they good models? Well, that depends on what you\u2019re looking for. They\u2019re great at some benchmarks, of course (OpenAI would never have released them otherwise) but weirdly bad at others, like SimpleQA.Some people really like them. Others on Twitter really don\u2019t. From what I can tell, they\u2019re technically competent but lack a lot of out-of-domain knowledge: for instance, they have broad general knowledge about science, but don\u2019t know much about popular culture. We\u2019ll know in six months how useful these models are in practice, but my prediction is that these models will end up in the category of \u201cperforms much better on benchmarks than on real-world tasks\u201d.In 2024, Sebastien Bubeck led the development of Microsoft\u2019s open-source Phi-series of models2. The big idea behind those models was to train exclusively on synthetic data: instead of text pulled fro"
  },
  {
    "title": "GPT-5 for Developers (openai.com)",
    "points": 343,
    "submitter": "6thbit",
    "submit_time": "2025-08-07T17:06:39 1754586399",
    "num_comments": 184,
    "comments_url": "https://news.ycombinator.com/item?id=44827101",
    "comments": [
      "Between Opus aand GPT-5, it's not clear there's a substantial difference in software development expertise. The metric that I can't seem to get past in my attempts to use the systems is context awareness over long-running tasks. Producing a very complex, context-exceeding objective is a daily (maybe hourly) ocurrence for me. All I care about is how these systems manage context and stay on track over extended periods of time.What eval is tracking that? It seems like it's potentially the most imporatnt metric for real-world software engineering and not one-shot vibe prayers.reply",
      "At my company (Charlie Labs), we've had a tremendous amount of success with context awareness over long-running tasks with GPT-5 since getting access a few weeks ago. We ran an eval to solve 10 real Github issues so that we could measure this against Claude Code and the differences were surprisingly large. You can see our write-up here:https://charlielabs.ai/research/gpt-5Often, our tasks take 30-45 minutes and can handle massive context threads in Linear or Github without getting tripped up by things like changes in direction part of the way through the thread.While 10 issues isn't crazy comprehensive, we found it to be directionally very impressive and we'll likely build upon it to better understand performance going forward.reply",
      "I am not (usually) photosensitive, but the animated static noise on your websites causes noticable flickering on various screens I use and made it impossible for me to read your article.For better accessibility and a safer experience[1] I would recommend not animating the background, or at least making it easily togglable.[1] https://developer.mozilla.org/en-US/docs/Web/Accessibility/G...reply",
      "Removed- sorry, and thank you for the feedback.reply",
      "Love your responsiveness here!Edited to add: I am, in fact, photosensitive (due to a genetic retinal condition), and for my eyes, your site as it is very easy to read, and the visualizations look great.reply",
      "Thank you!Love that you included the judge prompts in your article.reply",
      "Please let me know what you would like to see more of. Evals are something we take serious, I think this post was ok enough given our constraints, but I'd like to produce content people find useful and I think we can do a lot better.reply",
      "Nice,reply",
      "I concur. Awful UIreply",
      "> Producing a very complex, context-exceeding objective is a daily (maybe hourly) ocurrence for me. All I care about is how these systems manage context and stay on track over extended periods of time.For whatever reason Github's Copilot is treated like the redheaded stepchild of coding assistants. Even through there are Anthropic, OpenAI, and Google models to choose from. And there is a \"spaces\"[0] website feature that may be close to what you are looking for.I got better results for testing some larger task using that than I did through the IDE version. But have not used it much. Maybe others have more experience with it. Trying to gather all the context and then review the results was taking longer than doing it myself; having the context gathered already or building it up over time is probably where its value is.[0] https://docs.github.com/en/copilot/concepts/spacesreply"
    ],
    "link": "https://openai.com/index/introducing-gpt-5-for-developers",
    "first_paragraph": ""
  },
  {
    "title": "Encryption made for police and military radios may be easily cracked (wired.com)",
    "points": 124,
    "submitter": "mikece",
    "submit_time": "2025-08-07T18:30:04 1754591404",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=44828504",
    "comments": [
      "Kevin Mitnick figured out how to get around police radio encryption in the 90's. From 'Ghost in the Wires':\n\"Whenever I heard any hiss of communication, I\u2019d hold down my Transmit button. That would send\nout a radio signal on the same exact frequency, which would jam the signal.\nThen the second agent wouldn\u2019t be able to hear the first agent\u2019s transmission. After two or three tries back and forth, the agents would get\nfrustrated with the radio. I could imagine one of them saying something like, \u201cSomething\u2019s wrong with the radio. Let\u2019s go in the clear.\u201d\nThey\u2019d throw a switch on their radios to take them out of encryption mode, and I\u2019d be able to hear both sides of the conversation! Even today\nI\u2019m amused to remember how easy it was to work around that encryption without even cracking the code.\"reply",
      "That is the most 90s story I've heard. Nowadays you'd be shot.reply",
      "It's an odd story, since until pretty recently most North American police radio was plaintext to begin with.reply",
      "I should have said FBI radio encryption. I wonder if the technique would still work today...reply",
      "Not IAreply",
      "What's IA?reply",
      "The local PD in my area has/had the laptops in their vehicles set to ad-hoc mode, and each broadcast static MAC addresses in the open, and could simply be looked up on the Wigle database. At about 100-yards, you could pick up the broadcast on any phone, and it would be trivial for someone to deduce that you could setup an active monitor w/ alerts for when these specific MAC addresses were present in a designated area, let alone what a distributed monitoring/alert effort would be capable of...reply",
      "For anyone who's curious, the closest equivalent in the US is P25[1] or \"Project 25\". And if you're wondering, yes, P25 systems have been known to have their own share of vulnerabilities of various sorts. My favorite one[2] is the one that lets an attacker force a P25 radio to broadcast tokens \"on demand\" allow you to (theoretically, with the right receiving setup and software) track the location of P25 radios more or less in real-time.And on a related note, for anyone who is interested in listening in on any local P25 transmissions, you can do so in a fairly inexpensive manner, using an RTL-SDR dongle and the Open Source op25[3] software package. No listening to encrypted traffic, but IME, many (maybe most) public safety agencies keep most of their traffic in the clear. More so for fire/ems traffic. Law enforcement is more likely to be encrypted, but even then, I find that many jurisdictions only encrypt a small number of channels, like maybe a dedicated vice/narc squad channel, SWAT team channel, etc. General LE dispatch and tac channels are still in the clear in many areas.[1]: https://en.wikipedia.org/wiki/Project_25[2]: https://www.reddit.com/r/tacticalgear/comments/1f4d5dr/psa_p...[3]: https://github.com/boatbod/op25reply",
      "I wonder if it would be illegal to employ this method. Tracking law enforcement isn\u2019t explicitly illegal, right?reply",
      "It's an active attack (requires you to transmit traffic to trick the radio into sending the response beacons) so at the very least you'd almost certainly be in violation of some FCC regs. So the charge might not be \"tracking law enforcement\" but rather would be \"illegally transmitting on a public safety frequency without a license\" or something along those lines. And if somebody got caught doing this, I'm reasonably sure they'd find a way to pile on a few more charges as well.And note that since it is an active attack that requires the attacker to transmit, it opens up the possibility of the attacker giving up their own location in turn.My take is that it's fun to think about, but largely lacking in real world applicability in most situations.reply"
    ],
    "link": "https://www.wired.com/story/encryption-made-for-police-and-military-radios-may-be-easily-cracked-researchers-find/",
    "first_paragraph": "Two years ago, researchers in the Netherlands discovered an intentional backdoor in an encryption algorithm baked into radios used by critical infrastructure\u2013as well as police, intelligence agencies, and military forces around the world\u2013that made any communication secured with the algorithm vulnerable to eavesdropping.When the researchers publicly disclosed the issue in 2023, the European Telecommunications Standards Institute (ETSI), which developed the algorithm, advised anyone using it for sensitive communication to deploy an end-to-end encryption solution on top of the flawed algorithm to bolster the security of their communications.But now the same researchers have found that at least one implementation of the end-to-end encryption solution endorsed by ETSI has a similar issue that makes it equally vulnerable to eavesdropping. The encryption algorithm used for the device they examined starts with a 128-bit key, but this gets compressed to 56 bits before it encrypts traffic, making"
  },
  {
    "title": "Hubble catches sharpest image yet of 3I/ATLAS (skyatnightmagazine.com)",
    "points": 11,
    "submitter": "anigbrowl",
    "submit_time": "2025-08-07T23:54:21 1754610861",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44831843",
    "comments": [
      "Neat! I haven't been keeping super close tabs on 3I/ATLAS. Was it identified as a comet early or is this a recent development?reply",
      "> 3I/ATLAS was discovered on 1 July 2025 ... Initial observations of 3I/ATLAS were unclear on whether 3I/ATLAS is an asteroid or a comet ... observations on 2 July 2025 by the Deep Random Survey (X09) at Chile, Lowell Discovery Telescope (G37) at Arizona, and Canada\u2013France\u2013Hawaii Telescope (T14) at Mauna Kea showed a marginal coma with a potential tail-like elongation 3 arcseconds in angular length, which indicated the object is a comet.https://en.wikipedia.org/wiki/3I/ATLASSo, a day or so after its official discovery, maybe a week after its \"pre-discovery\"reply"
    ],
    "link": "https://www.skyatnightmagazine.com/news/hubble-3i-atlas-july-2025",
    "first_paragraph": "Iain ToddThe Hubble Space Telescope has captured the sharpest image yet of interstellar comet 3I/ATLAS, which is currently passing through our Solar System.Observations by Hubble have enabled astronomers to better estimate the size of the comet's nucleus, which is made of dust and ice.Hubble managed to capture a dust plume being ejected by the comet, as well as a glimpse of a dust tail streaming away from its nucleus.3I/ATLAS is one of only three interstellar visitors ever observed passing through our Solar System, the other two being 1I/\u02bbOumuamua, discovered in 2017, and 2I/Borisov, discovered in 2019.These objects originate from deep space and make a brief detour through our Solar System, then continue on their journey across the cosmos.Comet 3I/ATLAS (2025) was discovered by the Asteroid Terrestrial-impact Last Alert System (ATLAS) on 1 July 2025, when it was 675 million kilometres from the Sun.Hubble's image, captured on 21 July 2025, follows an earlier Gemini North Telescope image"
  },
  {
    "title": "Windows XP Professional (win32.run)",
    "points": 295,
    "submitter": "pentagrama",
    "submit_time": "2025-08-07T13:58:25 1754575105",
    "num_comments": 175,
    "comments_url": "https://news.ycombinator.com/item?id=44824539",
    "comments": [
      "How can you tell that any Windows or Mac clone UI is a re-implementation? Easy: try to move your mouse diagonally into the Send To menu after letting it pop up. If the send-to menu closes as you mouse over the item into the submenu, it's a clone. If the menu stays up even if you brush over another menu item, it's either real or a Good Clone. :)For the fun history, @DonHopkins had a thread a few years back:https://news.ycombinator.com/item?id=17404345reply",
      "I love reading about old UI interface guidelines, and how much research was done to make it useful to the user.Now it's all about how to make it useful to the company.<YOUR FILES ARE NOT BACKED UP, WOULD YOU LIKE TO TURN ON ONEDRIVE?><Yes> <Maybe later>Anyway, the links in that post have deteriorated.Here's the link to Raymond Chen's blog: https://web.archive.org/web/20190218080905/https://blogs.msd... (shame on MS for redirecting you to another page when showing you a 404, which make it harder to find the original URL).Updated link to Raymond Chen's blog, where the comments have been 'retired': https://devblogs.microsoft.com/oldnewthing/20080619-00/?p=21...And the 2 imgur links (same issue with the redirecting...):https://web.archive.org/web/20230509182201/https://i.imgur.c...andhttps://web.archive.org/web/20230507201645/https://i.imgur.c...reply",
      "There was an economies of scale back then with OS-level UI components.If Microsoft spent money on UX research that improved its UI controls, it would benefit a lot of people. Essentially the cost of that research was bore by all application developers.The problem now? Every company is designing their own UI components. Every company has to bear the cost of UX research individually. It\u2019s a lot of wheel re-inventing. UX easily takes a backseat.reply",
      "Are UI libraries no longer a thing?reply",
      "As a side note: With the Internet (and myself) getting older and older, I appreciate the effort of the Internet Archive more and more. So many links I was able to revive thanks to a cached version. So many of my own works I was able to retrieve. It's a blessing, and not praised enough.(Only ignorant fools would start to fight it.)reply",
      "I could tell instantly in the loading screen because the three blocks in the progress bar move smoothly across it.reply",
      "Man nothing drives me further up the wall than when a nice progress indicator with discrete segments gets animated with a lazy `to { rotate(360deg); }` etc[1]. It is my molehill to die on[1] https://cdn.dribbble.com/userupload/41647820/file/original-8...reply",
      "You know talking about progress bars, it takes a lot of confidence to program a linear progress bar. You think you know when loading will be complete and think you know can break down the incremental progress made during loading.Instead we get these spinning wheels that are like \"maybe in the future this wheel will stop and we will have a return value.\" No confidence whatsoever.I know this is true because Apple tries to implement progress bars in IOS like real chads. But their progress bars are just fake. They are a cheap animation all the way up to 90% and just stop moving until the progress is actually complete which could be 5 seconds of 90% and 40 seconds of the last 10%. So they think they are chad but lie.reply",
      "> I know this is true because Apple tries to implement progress bars in IOS like real chads.Back in The Day, Mac OS X Tiger just faked it by measuring how long it took to boot to LoginWindow, writing that number of seconds to a file, and displaying the next boot's progress indicator as a percentage of that time.Power words: `/usr/libexec/WaitingForLoginWindow` and `/var/db/loginwindow.boottime`- https://daringfireball.net/misc/2005/04/tiger_details#waitin...- https://web.archive.org/web/20060427030025/http://www.macosx...- https://arstechnica.com/gadgets/2005/05/397/- https://web.archive.org/web/20060506092123/http://www.macosx...reply",
      "There's also the \"Achilles and the tortoise\" solution where the progress bar consumes the remaining 80% of unclaimed space in each iteration.reply"
    ],
    "link": "https://win32.run/",
    "first_paragraph": ""
  },
  {
    "title": "Benchmark Framework Desktop Mainboard and 4-node cluster (github.com/geerlingguy)",
    "points": 136,
    "submitter": "geerlingguy",
    "submit_time": "2025-08-07T17:49:49 1754588989",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=44827862",
    "comments": [
      "I've ran a comparison benchmark for the smaller models https://gist.github.com/mhitza/f5a8eeb298feb239de10f9f60f841...Comparing it against the RTX 4000 SFF Ada (20GB) which is around $1.2k (if you believe the original price on the nvidia website https://marketplace.nvidia.com/en-us/enterprise/laptops-work...). Which I have access to on a Hetzner GEX44.I'm going to ballpark it between 2.5-3x faster than the desktop. Except for the tg128 test, where the difference is \"minimal\" (but I didn't do the math).reply",
      "The whole point of these integrated memory designs is to go beyond that 20 GB VRAM.reply",
      "Thanks for the excellent writeup. I'm pleasantly surprised that ROCm worked as well as it did \u2014 for the price these aren't bad for LLM workloads and some moderate gaming. (Apple is probably still the king of affordable at-home inference, but for games... Amazing these days but Linux is so much better.)reply",
      "I switched to Fedora Sway as my daily driver nearly two years ago.  A Windows title wasn\u2019t working on my brand new PC.  I switched to Steam+Proton+Fedora and it worked immediately.  Valve now offers a more stable and complete Windows API through Proton than Microsoft does through Windows itself.reply",
      "for those who are already in the field and doing these things - if I wanted to start running my own local LLM.. should I find an Nvidia 5080 GPU for my current desktop or is it worth trying one of these Framework AMD desktops?reply",
      "The short answer is that the best value is a used RTX 3090 (the long answer being, naturally, it depends).  Most of the time, the bottleneck for running LLMs on consumer grade equipment is memory and memory bandwidth.  A 3090 has 24GB of VRAM, while a 5080 only has 16GB of VRAM.  For models that can fit inside 16GB of VRAM, the 5080 will certainly be faster than the 3090, but the 3090 can run models that simply won't fit on a 5080.  You can offload part of the model onto the CPU and system RAM, but running a model on a desktop CPU is an enormous drag, even when only partially offloaded.Obviously an RTX 5090 with 32GB of VRAM is even better, but they cost around $2000, if you can find one.What's interesting about this Strix Halo system is that it has 128GB of RAM that is accessible (or mostly accessible) to the CPU/GPU/APU.  This means that you can run much larger models on this system than you possibly could on a 3090, or even a 5090.  The performance tests tend to show that the Strix Halo's memory bandwidth is a significant bottleneck though.  This system might be the most affordable way of running 100GB+ models, but it won't be fast.reply",
      "Used 3090s have been getting expensive in some markets.  Another option is dual 5060ti 16 gig.  Mine are lower powered, single 8 pin power, so they max out around 180W.  With that I'm getting 80t/s on the new qwen 3 30b a3b models, and around 21t/s on Gemma 27b with vision.  Cheap and cheerful setup if you can find the cards at MSRP.reply",
      "Just a point of clarification. I believe the 128GB Strix Halo can only allocate up to 96GB of RAM to the GPU.reply",
      "If you think the future is small models (27B) get Nvidia; if you think larger models (70-120B) are worth it then you need AMD or Apple.reply",
      "I wonder how much MoE will disrupt this. qwen3:30b-a3b is pretty good even on pure CPU, but a lot smarter than a 3B parameter model. If the CPU-GPU bottleneck isn't too tight, a large model might be able to sustainably cache the currently active experts in GPU RAM.reply"
    ],
    "link": "https://github.com/geerlingguy/ollama-benchmark/issues/21",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Testing the Framework Desktop - AMD Ryzen AI Max+ 395 with Radeon 8090S. (Four pre-production units were shipped to me for local cluster testing).Initial tests (above) were run using 2.5 Gbps Ethernet interconnect.I later changed to 5 Gbps using a NICGIGA switch, and racked it in a black T1 mini rack shipped by DeskPi, along with four of their currently-in-prototype Framework Desktop mini rack trays. Mini rack build showcase here.I also tested Thunderbolt node-to-node interconnects, but could only get 10 Gbps over TB4 using thunderbolt0/thunderbolt1 interfaces).For more benchmarks (focusing on CPU, GPU, disk, net, etc.), see:All my automation for testing is in the Beowulf AI Cluster repo."
  },
  {
    "title": "Building Bluesky comments for my blog (natalie.sh)",
    "points": 265,
    "submitter": "g0xA52A2A",
    "submit_time": "2025-08-07T15:56:01 1754582161",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=44826164",
    "comments": [
      "Interesting article!  I always enjoy reading how people build and maintain their independent personal websites.  This post starts with the \"Comment System Problem\" and mentions four possible solutions, but I think there's a fifth that has worked well for me.After spending too much time fiddling with third-party comment systems, I ended up building my own [1].  It's pretty barebones, just does what I need, and nothing more.Each comment is written to a text file for manual review, so I don't have to worry about spam, cross-site scripting, or irrelevant comments.  I usually check them on weekends and add them to my blog.Comments are stored as plain HTML files, and my static site generator [2] builds the site along with the comment pages [3].  So in a way, it's also a static comment pages generator.This setup doesn't meet the five attributes (no infra, rich content, real identity, etc.) in the second section of the article, so it wouldn't suit the author's needs, but it has worked quite well for me.  I've been using it for at least four years (perhaps much longer, since my old PHP website did something similar), and I've been quite happy with it.[1] https://github.com/susam/susam.net/blob/main/form.lisp[2] https://github.com/susam/susam.net/blob/main/site.lisp[3] https://susam.net/comments/reply",
      "Taking comments via a (n email) form, which you then manually add under the article's html/markdown is nice.reply",
      "That's what I do, except I skip the form and just provide my email address at the bottom of each post.reply",
      "I like your solution - I think it is perfectly fine for a low traffic blog.Personally I find comments not worth the bother and purposely did not include them on my site. My blog is an expression of my personality and the idea of other peoples words appearing on my pages seems weird to me.I know people enjoy feedback, which is why I have taken to emailing bloggers whose work I enjoy instead of leaving meaningless comments.reply",
      "kind of like \"letters to the editor\" in newspapers (:reply",
      "I wish Bluesky would reveal their full idea on how they\u2019re going to monetise. All this chatter how they\u2019re different because they have this super complicated architecture always comes short of revealing what happens when they start charging for things.reply",
      "Bluesky is very useful to store information on users' existing accounts.I'm currently building a review system for my open source Web map https://cartes.app, based on Bluesky. Not trivial though, you have to create a lexicon and maintain a DB based on the Bluesky stream.reply",
      "You can go pretty far without your own DB. Depends on the types of queries you need to make. For my project[1], I was able to use getRecord[2] for a lot of the data that needed fetching on the client-side.1 - https://scrapboard.org/2 - https://docs.bsky.app/docs/api/com-atproto-repo-get-recordreply",
      "Wait, what? Please don't do that, use mangrove.reviews instead please. They use clear CC-BY-SA licenses; MapComplete.org uses itBluesky _will_ enshittify sooner or laterreply",
      "Mangrove has almost nothing in its DB, no news for years, and a broken website.Better go with my own DB.Or use a network with a well-designed protocol, a hosted service, 30 million users, a social graph, moderation...reply"
    ],
    "link": "https://natalie.sh/posts/bluesky-comments/",
    "first_paragraph": ""
  },
  {
    "title": "Achieving 10,000x training data reduction with high-fidelity labels (research.google)",
    "points": 44,
    "submitter": "badmonster",
    "submit_time": "2025-08-07T21:11:20 1754601080",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44830418",
    "comments": [
      "> in production traffic only very few (<1%) ads are actually clickbaitThat's a fascinating claim, and it does not align with my anecdotal experience using the web for many years.reply",
      "Not quite the same thing but some non-negligable percentage of ads I see on Facebook are outright scams which purport to be selling musical instruments at a 'markdown'. First guitars supposedly from the Sam Ash bankruptcy sales linking to an obvious fake site and more lately 'free' giveaways of high end Gibson acoustic guitars. When I've reported them I got the feedback that it didn't violate community standards, but my insta account got perma-banned when I posted the original of a song on youtube from 1928 on a thread which started with a cover from 30 years ago. That was considered spam.reply",
      "Smart scammers should know that peopel know if something is too good to be true (\"free Gibson} etc), it is probabaly fake. But people keep clicking, for what it's worth.reply",
      "I had that reaction as well, but consider: clickbait is such because it takes more work (emotional or logical) to reject it than an ad which is merely not relevant to you. Thus, your (and my) recall of ads is probably biased towards clickbait, and we overestimate its prevalence.reply"
    ],
    "link": "https://research.google/blog/achieving-10000x-training-data-reduction-with-high-fidelity-labels/",
    "first_paragraph": "We strive to create an environment conducive to many different types of research across many different time scales and levels of risk.Our researchers drive advancements in computer science through both fundamental and applied research.We regularly open-source projects with the broader research community and apply our developments to Google products.Publishing our work allows us to share ideas and work collaboratively to advance the field of computer science.We make products, tools, and datasets available to everyone with the goal of building a more collaborative ecosystem.Supporting the next generation of researchers through a wide range of programming.Participating in the academic research community through meaningful engagement with university faculty.Connecting with the broader research community through events is essential for creating progress in every aspect of our work.August 7, 2025Markus Krause, Engineering Manager, and Nancy Chang, Research Scientist, Google AdsA new active l"
  },
  {
    "title": "Infinite Pixels (meyerweb.com)",
    "points": 214,
    "submitter": "OuterVale",
    "submit_time": "2025-08-07T13:12:42 1754572362",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44824056",
    "comments": [
      "Firefox simply ignores height declarations that resolve to a value greater than exactly 17895697px. What\u2019s this value? Just a smidgeon under 2\u00b3\u2070 sixtieths of a pixel, which is Firefox\u2019s layout unit. (It\u2019s the last integer before 2\u00b3\u2070 sixtieths, which is 17,895,697.06\u0305 pixels, 4\u204460 more.) I presume Firefox is using a 32-bit signed integer, and reserving another bit for something else, maybe overflow control.Five years ago, Firefox would ignore any CSS declarations resolving like that, but somewhere along the way it changed so that most things now clamp instead, matching WebKit-heritage behaviour. But height is not acting like that, to my surprise (I though it was).WebKit-heritage browsers use a 1\u204464 pixel layout unit instead. Viewed in that light, the 2\u00b2\u2075 \u2212 1 pixels is actually 2\u00b3\u00b9 \u2212 1 layout units, a less-surprising number.IE had the same behaviour as Firefox used to, but with a much lower limit, 10,737,418.23 pixels (2\u00b3\u2070 \u2212 1 hundredth pixels), which was low enough to realistically cause problems for Fastmail, all you needed was about 200,000 messages in a mailbox. I\u2019ve written about that more a few times, https://news.ycombinator.com/item?id=42347382, https://news.ycombinator.com/item?id=34299569, https://news.ycombinator.com/item?id=32010160.reply",
      "Firefox's units are quite smart, actually. 60 is divisible by 3, 4, 5 and 6, so they are quite future-proof for the future when we'll have the displays with devicePixelRatio = 6.reply",
      "For those curious, in WebKit, this stems from the use of the LayoutUnit (https://github.com/WebKit/webkit/blob/main/Source/WebCore/pl...) for most computed length values. LayoutUnits use a fixed point representation where the smallest unit is 1/64 of a pixel. https://trac.webkit.org/wiki/LayoutUnit is a bit old, but has some good information on the topic.reply",
      "This 2^25-1 pixel limit makes perfect sense - with 1/64 pixel precision, that's exactly 2^31-1 layout units (the max value of a signed 32-bit integer).reply",
      "So only slightly related Netscape used to assume the layout during load was infinite and would resolve features to their size as the sizes are known, which meant usually nothing showed until everything was loaded in a world of div and tables.IE4 did the opposite and assumed everything was sized zero and filled sizes as they become known. this allowed them to load objects and render them as the page objects load appearing to be substantially faster at loading than Netscape.Early engineering decisions like this can make or break a company. Not saying this was the only challenge Netscape had, but it was one that really drove the need to build the Gecko layout engine. Despite some wildly misleading yet famous blogs written by a Microsoft engineer discussing what happened internally at Netscape that he couldn\u2019t possibly know about and basically got totally upside down and self serving \u2026\u2026reply",
      "> Chrome and Safari both get very close to 225-1 (33,554,431), with Safari backing off from that by just 3 pixels, and Firefox by 31.Typo, the last browser in this sentence should be \"Chrome\", right?reply",
      "As noted by another comment here [0], when you use a virtual DOM/canvas based \"infinite\" data grid such as Glide Data Grid [1] or TanStack Virtual [2], you get the performance/usability of native scrollbars because under the hood, both of those libraries create scrollable DIVs with a very large height. ie, you're scrolling a big empty div, and a viewport into the \"infinite\" grid is actually drawn in the canvas.But this does fall apart for very very large grids, as you get close to the height limit described in this article.For a project that I'm working on, I ended up re-implementing scrollbars, but it's super janky - and even more so on mobile where you lose the \"flick\"/inertia/momentum touch gestures (or you have to re-implement them at your peril).Are there any good tricks/libraries to tackle this? Thanks![0] https://news.ycombinator.com/item?id=44825028[1] https://github.com/glideapps/glide-data-grid[2] https://tanstack.com/virtual/latestreply",
      "Since it seems unlikely that a single scroll gesture passes the threshold, and also the  scrollbar thumb probably is invisible (either intentionally or due to the extreme height): maybe an \"infinite scroll\" paginated stack of virtual lists would be enough? I mean a dumb \"load more\" implementation that swaps out the main container once you reach the end/start of each \"item\" (virtual lists themselves)?If that doesn't help, maybe check out this fun post (no native scrolling experience):https://everyuuid.comhttps://eieio.games/blog/writing-down-every-uuid/reply",
      "great point re: Nolen's site -- I've collab'ed with him on https://eieio.games/blog/talk-paper-scissors/, I should have remembered that! :-)it's not crazy to stack virtual lists... at that point, I might also just see that the user is near/at the end of the list, and just swap out the content completely and place them back at scrolling position y:0 or somethingfor sure, I shouldn't make perfect the enemy of good here. thanks for the ideas!reply",
      "Oh, I'm glad i wasn't talking past you :) that uuud site and the post about it was genius, and haha, I didn't check the RPS-via-phone number app yet.Sounds equally fun! Just like the uuid one, also seems very worth bookmarking for a fitting momentreply"
    ],
    "link": "https://meyerweb.com/eric/thoughts/2025/08/07/infinite-pixels/",
    "first_paragraph": "I was on one of my rounds of social media trawling, just seeing what was floating through the aether, when I came across a toot by Andy P that said:Fun #css trick:\n\r\nwidth: calc(infinity * 1px);\r\nheight: calc(infinity * 1px);\u2026and I immediately thought, This is a perfect outer-limits probe! By which I mean, if I hand a browser values that are effectively infinite by way of  theinfinity keyword, it will necessarily end up clamping to something finite, thus revealing how far it\u2019s able or willing to go for that property.The first thing I did was exactly what Andy proposed, with a few extras to zero out box model extras:Then I loaded the (fully valid HTML 5) test page in Firefox Nightly, Chrome stable, and Safari stable, all on macOS, and things pretty immediately got weird:\u2020 height / widthChrome and Safari both get very close to 225-1 (33,554,431), with Safari backing off from that by just 3 pixels, and Chrome by 31.\u00a0 I can\u2019t even hazard a guess as to why this sort of value would be limite"
  },
  {
    "title": "How to sell if your user is not the buyer (founderlabs.io)",
    "points": 149,
    "submitter": "mooreds",
    "submit_time": "2025-08-07T15:09:02 1754579342",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=44825491",
    "comments": [
      "I'll tell you how not to do it.Require me to give you my contact information just to download something. Have sales people blow up my phone and/or email and ignore polite brush-offs. Keep reaching out to me periodically with requests to have a meeting about how you product can help me.I don't have buying power, but I do have bitching power and your product will wind up getting bad-mouthed by the whole team eventually. And when the engineer asks us for recommendations, guess what we tell him?Lookin' at you, Veeam, AWS, and Keyence.reply",
      "IT Manager here, and deal with this almost weekly at this point. I'll add to your list of how not to do it - ignore my brush-offs and start email blasting others on my team or within the company to get around me. Quick way to get your domain blocked all together.Also please don't make me sit through a demo just to get a quote. If I want a full demo I'll ask for it, and I need to know pricing first before even considering going any further. I've probably already researched your product, maybe even did a trial if available - I don't need to sit through any number of sales pitches, just give me the numbers.reply",
      "I fairly recently got to switch sides on this. I never take sales calls or want to get on demos as a developer ... but I moved roles a bit and needed to join some calls with the reps at my company for a product I now manage. It has no public pricing.I was surprised by how much the people who show up for demos seemed to like them and have good relationships with their reps. They thank us for saving them a lot of time they would have spent reading docs and marketing materials to learn the specific things that applied to them, or for us talking about roadmap stuff they don't get to see in the public materials.Sometimes the price is a surprise to them and it needs a bit of context. Customers who are used to buying software this way seem to read between the lines really well and ask suitable questions about discounts or whatever, when they are  surprised by pricing. Often we are able to make something work at a different price than the typical quote, or we can connect the dots so that the rationale is more clear, or the value requires some customization to be done.My reps tell me this sorta thing is difficult over email, that nobody makes $10k+ purchases without talking to somebody, so if we can't get you on a call the deal falls over.So I dunno. I'm not a big fan of the requirement for calls really, but I can understand why reps don't just throw quotes around without some conversation.reply",
      "I've come to the opinion now that if something in sales doesn't make sense, you're probably not the target market. Sure _I_ don't want to have a demo with no price guarantees, but I'm not the target market - big companies with dedicated purchasing teams and big lists of requirements are. And those companies write big, ongoing cheques. So in some ways the obscure pricing and convoluted sales process is doing it's job which is qualifying good customers and diverting bad customers (people like me)reply",
      "Appreciate the other perspective. I'll even admit there's been cases where the demos have been useful and sparked other questions, but in those cases I hadn't heard of the product before or was coming in blind.Most of my cases now (and I may be an outlier), I'm looking at something because I both have a need and someone I know recommended it or uses it so I'm already familiar, but at that point it's not so much a sales process and more so \"I already know I want this, and I already have the budget and approval, let's get this buying process over with as quick as possible.\"reply",
      "Are you selling to developers?In my experience, non developer audiences like demos. Developers tend to like to try things out on their own, maybe with a little tech support.reply",
      "Adding Auth0/Okta to the list. Funny enough I had buying power and budget for it, and was gonna ask a Senior engineer to look into it, but the calls got so crazy that I just soured on it.reply",
      "Same experiencereply",
      "Same. Very annoying and manipulative.reply",
      "Love the idea of \"bitching power\"; basically anti-\"word of mouth\". Even if you make something freely available, your sales/marketing/GTM folks can hurt your company's name by being too aggressive.You should contact to people how they want to be contacted, not how you'd want to be contacted.It's a difficult incentive design problem though.reply"
    ],
    "link": "https://writings.founderlabs.io/p/how-to-sell-if-your-user-is-not-the",
    "first_paragraph": ""
  },
  {
    "title": "Open music foundation models for full-song generation (map-yue.github.io)",
    "points": 69,
    "submitter": "selvan",
    "submit_time": "2025-08-04T10:46:02 1754304362",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=44784090",
    "comments": [
      "Something interesting... the first 10 seconds or so of the \"Death Growl\" example[1] is basically copied verbatim from \"Ov Fire And The Void\" by Behemoth.More specifically, I think the part that seems copied is at 2:13 of the original[2], as it leads into a solo-ish bit which in the AI version sounds similar still, but goes on to do its own thing:[1] https://map-yue.github.io/music/moon.death_metal.mp3[2] https://youtu.be/vAmnsKKrt9w?t=133reply",
      "> Additionally, our memorization-effect experiments in Section 11 demonstrate that our design maintains creativity without plagiarizing, even under strong training set conditioning.https://arxiv.org/html/2503.08638v1#S11reply",
      "Funny because since the Blurred Lines lawsuit you can be infringing for using the same chord progression.reply",
      "That decision was ridiculous. It's pretty obvious that the Robin Thicke song is a $1.50 Great Value version of \"Got To Give It Up\" because of the aesthetic similarities but they have nothing to do with each other melodically or harmonically... \"Blurred Lines\" sounds like I V with a walk at the end whereas \"Got To Give It Up\" is more like a I IV V. The vocal melodies aren't the same nor is the bass. They have different arrangements. The percussion isn't the same.The only things they have in common are vibes (in the contemporary sense, not vibraphones). Two dudes singing about sex in falsetto at 120bpm over prototypical R&B/funk elements isn't special. If that's the bar for copyright infringement then 99% of the popular music canon is illegally-derivative. Marvin Gaye was a singular talent but that doesn't mean that his heirs should be able to collect money every time somebody plays an electric piano bassline and sings about making whoopie in alto II.reply",
      "The youtube link is suddenly not available any more (at least in the UK)reply",
      "Does Shazam think it is the same?reply",
      "Very nice. Anyone know of projects that aren't tackling the full-song problem but rather instrument parts/loops/stems/acapellas? I'd like something that's more like \"infinite AI Loopcloud/Splice\" most of these full-song models don't do well to be asked for individual parts in my experience (though I will have to try it with this one).reply",
      "This gets discussed a lot but unfortunately there's just not much out there around this.The closest thing I've seen is virtual drummers in Logic X which will follow along with the structure of your song and generate a percussive accompaniment. It's no substitute for a real drummer but it's serviceable.reply",
      "https://suno.com/studio-waitlist \nJust a waitlist so far, but looks like this is the direction suno is goingreply",
      "Yeah... I hope this is what their plan is with that, but I'm not entirely certain.reply"
    ],
    "link": "https://map-yue.github.io/",
    "first_paragraph": "Multimodal Art Projection\u9999\u6e2f\u79d1\u6280\u5927\u5b66We tackle the task of long-form music generation\u2014particularly the challenging lyrics-to-song\nproblem\u2014by introducing YuE (\u4e50), a family of open foundation models based on the LLaMA2\narchitecture. Specifically, YuE scales to trillions of tokens and generates up to five minutes of\nmusic while maintaining lyrical alignment, coherent musical structure, and engaging vocal\nmelodies with appropriate accompaniment. It achieves this through: (1) track-decoupled nexttoken prediction to overcome dense mixture signals, (2) structural progressive conditioning\nfor long-context lyrical alignment, and (3) a multitask, multiphase pre-training recipe to\nconverge and generalize. In addition, we redesign the in-context learning technique for\nmusic generation, enabling versatile style transfer (e.g., converting Japanese city pop into\nan English rap while preserving the original accompaniment) and bidirectional generation.\nThrough extensive evaluation, we demonstrate that YuE ma"
  },
  {
    "title": "How AI conquered the US economy: A visual FAQ (derekthompson.org)",
    "points": 171,
    "submitter": "rbanffy",
    "submit_time": "2025-08-07T10:12:54 1754561574",
    "num_comments": 155,
    "comments_url": "https://news.ycombinator.com/item?id=44822665",
    "comments": [
      ">Without AI, US economic growth would be meager.The assumption here is that, without AI, none of that capital would have been deployed anywhere. That intuitively doesn't sound realistic. The article follows on with:>In the last two years, about 60 percent of the stock market\u2019s growth has come from AI-related companies, such as Microsoft, Nvidia, and Meta.Which is a statement that's been broadly true since 2020, long before ChatGPT started the current boom.  We had the Magnificent Seven, and before that the FAANG group. The US stock market has been tightly concentrated around a few small groups for a decades now.>You see it in the business data. According to Stripe, firms that self-describe as \u201cAI companies\u201d are dominating revenue growth on the platform, and they\u2019re far surpassing the growth rate of any other group.The current Venn Diagram of \"startups\" and \"AI companies\" is two mostly concentric circles. Again, you could have written the following statement at any time in the last four decades:> According to [datasource], firms that self-describe as \u201cstartups\u201d are dominating revenue growth on the platform, and they\u2019re far surpassing the growth rate of any other group.reply",
      "I think it's more likely the assumption is you'd expect a far more diversified market. If we're really in a situation where the rational, good reasons move is to effectively ignore 98% of companies, that doesn't say good things about our economy (verging on some kind of technostate). You get into weird effects like \"why invest in other companies\" leading to \"why start a company that will just get ignored\" leading to even more consolidation and less dynamism.reply",
      "1. People aren't going to take on risk and deploy capital if they can't get a return.2. If people think they can get an abnormally high return, they will invest more than otherwise.3. Whatever other money would've got invested would've gone wherever it could've gotten the highest returns, which is unlikely to have the same ratio as US AI investments - the big tech companies did share repurchases for a decade because they didn't have any more R&D to invest in (according to their shareholders).So while it's unlikely the US would've had $0 investment if not for AI, it's probably even less likely we would've had just as much investment.reply",
      "> it's probably even less likely we would've had just as much investment.I doubt it.  Investors aren't going to just sit on money and let it lose value to inflation.On the other hand, you could claim non-AI companies wouldn't  start a new bubble, so there'd be fewer returns to reinvest, and that might be true, but it's kind of circular.reply",
      "Correct - that's why you'd put it in Treasuries which have a positive real return for the first time in ~25 years - or, as I mentioned elsewhere - invest it somewhere else if you see a better option.reply",
      "Which is an even better argument when you look at how yields have been behaving. AI is sucking the air out of the room.reply",
      "From a certain macro perspective, of no one is going to beat the Treasury, where is the Treasury going to get that money?reply",
      "they\u2019ll print it of course :)reply",
      "> 1. People aren't going to take on risk and deploy capital if they can't get a return.> 2. If people think they can get an abnormally high return, they will invest more than otherwise.Sounds like a good argument for wealth taxes to limit this natural hoarding of wealth absent unreasonably good returns.reply",
      "Why is it \"unlikely\" that the alternative is not US investment by these US companies?The big US software firms have the cash and they would invest in whatever the market fad is, and thus, bring it into the US economy.reply"
    ],
    "link": "https://www.derekthompson.org/p/how-ai-conquered-the-us-economy-a",
    "first_paragraph": ""
  },
  {
    "title": "Touch Mapper \u00e2\u20ac\u201c open-source 3D printed tactile maps for the visually impaired (touch-mapper.org)",
    "points": 15,
    "submitter": "speckx",
    "submit_time": "2025-08-04T13:25:54 1754313954",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://touch-mapper.org",
    "first_paragraph": ""
  }
]