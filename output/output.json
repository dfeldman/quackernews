[
  {
    "title": "Intel's $475M error: the silicon behind the Pentium division bug (righto.com)",
    "points": 97,
    "submitter": "gslin",
    "submit_time": "2024-12-28T21:48:31 1735422511",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42535071",
    "comments": [
      "Author here if anyone has Pentium questions :-)My Mastodon thread about the bug was on HN a few weeks ago, so this might seem familiar, but now I've finished a detailed blog post. The previous HN post has a bunch of comments: https://news.ycombinator.com/item?id=42391079\n \nreply",
      "Great article and analysis as always, thanks! Somewhat crazy to remember that a (as you argue) minor CPU erretum made world wide headlines. So many worse ones out there (like you mention from Intel) but others as well, that are completely forgotten.For the Pentium, I'm curious about the FPU value stack (or whatever the correct term is) rework they did. It's been a long time, but didn't they do some kind of early \"register renaming\" thing that had you had to manually manage doing careful fxchg's?\n \nreply",
      "> Intel's whitepaper claimed that a typical user would encounter a problem once every 27,000 years, insignificant compared to other sources of error such as DRAM bit flips.> However, IBM performed their own analysis,29 suggesting that the problem could hit customers every few days.I bet these aren\u2019t as far off as they seem. Intel seems to be considering a single user, while I suspect IBM is thinking in terms of support calls.This is a problem I\u2019ve had at work. When you process a 100 million requests a day the one in a billion problem is hitting you a few times a month. If it\u2019s something a customer or worse a manager notices, they ignore the denominator and suspect you all of incompetence. Four times a month can translate into \u201call the time\u201d in the manner humans bias their experiences. If you get two statistical clusters of three in a week someone will lose their shit.\n \nreply",
      "No, IBM's estimate is for a single user. IBM figures that a typical spreadsheet user does 5000 divides per second when recalculating and does 15 minutes of recalculating a day. IBM also figures that the numbers people use are 90 times as likely to cause an error as Intel's uniformly-distributed numbers. The result is one user will have an error every 24 days.\n \nreply",
      "Ah.The other failure mode that occurred to me is that if a spread sheet is involved you could keep running the same calc on a bad input for months or even years when aggregating intermediate values over units of time. A problem that happens every time you run a calculation is very different from one that happens at random. Better in some ways and worse in others.\n \nreply",
      "That's also a clearly flawed analysis, because the numbers mostly don't change between re-computations of the spreadsheet cell values!E.g.: Adding a row doesn't invalidate calculations for previous rows in typical spreadsheet usage. The bug is deterministic, so repeating successful calculations over and over with the same numbers won't ever trigger the bug.\n \nreply",
      "What an interesting and utterly dedicated analysis. Thank you so much for all your work analysing the silicon and sharing your findings. I particularly like how you\u2019re able to call out Intel on the actual root cause, which their PR made sound like something analogous to a trivial omission. But, in fact, was less forgivable and more blameworthy, ie they stuffed up their table generation algorithm.\n \nreply",
      ">Smith posted the email on a Compuserve forum, a 1990s version of social media.I hate how this sentence makes me feel.\n \nreply",
      "Another great article from Ken. I remember this particularly because the first PC that I bought with my own money had an affected CPU. Prior to this era I hadn't been much interested in PCs because they couldn't run \"real\" software. But Windows NT changed that (thank you Mr. Cutler), and Taiwanese sourced low cost motherboards made it practical to build your own machine, as many people still do today. Ken touched on the fact that it was easy for users to check if their CPU was affected. I remember that this was as easy as typing a division expression with the magic numbers into Excel. If MS had released a version of Excel that worked around the bug, I suspect fewer users would have claimed their replacement device!\n \nreply",
      "Didn't Intel have floating point division issues more recently as well?\n \nreply"
    ],
    "link": "https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html",
    "first_paragraph": ""
  },
  {
    "title": "Apple Photos phones home on iOS 18 and macOS 15 (lapcatsoftware.com)",
    "points": 302,
    "submitter": "latexr",
    "submit_time": "2024-12-28T19:22:30 1735413750",
    "num_comments": 221,
    "comments_url": "https://news.ycombinator.com/item?id=42533685",
    "comments": [
      "\"I don't understand most of the technical details of Apple's blog post\"I do:- Client side vectorization: the photo is processed locally, preparing a non-reversible vector representation before sending (think semantic hash).- Differential privacy: a decent amount of noise is added the the vector before sending it. Enough to make it impossible to reverse lookup the vector. The noise level here is \u03b5 = 0.8, which is quite good privacy.- OHTTP relay: it's sent through a 3rd party so Apple never knows your IP address. The contents are encrypted so the 3rd party never doesn't learn anything either (some risk of exposing \"IP X is an apple photos user\", but nothing about the content of the library).- Homomorphic encryption: The lookup work is performed on server with encrypted data. Apple can't decrypt the vector contents, or response contents. Only the client can decrypt the result of the lookup.This is what a good privacy story looks like. Multiple levels of privacy security, when any one of the latter 3 should be enough alone to protect privacy.\"It ought to be up to the individual user to decide their own tolerance for the risk of privacy violations.\" -> The author themselves looks to be an Apple security researcher, and are saying they can't make an informed choice here.I'm not sure what the right call is here. But the conclusion \"Thus, the only way to guarantee computing privacy is to not send data off the device.\" isn't true. There are other tools to provide privacy (DP, homomorphic encryption), while also using services. They are immensely complicated, and user's can't realistically evaluate risk. But if you want features that require larger-than-disk datasets, or frequently changing content, you need tools like this.\n \nreply",
      "I appreciate the explanation.  However, I think you do not address the main problem, which is that my data is being sent off my device by default and without any (reasonable) notice.  Many users may agree to such a feature (as you say, it may be very secure), but to assume that everyone ought to be opted in by default is the issue.\n \nreply",
      "I'm not sure I agree -- asking users about every single minor feature is (a) incredibly annoying, and (b) quickly causes request-blindness in even reasonably security-conscious users. So restraining the nagging for only risky or particularly invasive things makes sense to me.Maybe they should lump its default state into something that already exists? E.g. assume that if you already have location access enabled for Photos (it does ask!), you've already indicated that you're okay with something about this identifying being sent to Apple whenever you take a picture.My understanding is that Location Services will, among other things, send a hash of local WiFi network SSIDs and signal strengths to a database Apple maintains, and use that to triangulate a possible position for you. This seems loosely analogous to what's going on here with the compute-a-vector thing.\n \nreply",
      "> Maybe they should lump its default state into something that already exists?It could be tied to iCloud Photos, perhaps, because then you already know that your photos are getting uploaded to Apple.\n \nreply",
      "I think it does address the main problem. What he is saying is that multiple layers of security is used to ensure (mathematically and theoretically proved) that there is no risk in sending the data, because it is encrypted and sent is such a way that apple or any third party will never be able to read/access it (again, based on theoretically provable math) . If there is no risk there is no harm, and then there is a different need for \u2018by default\u2019, opt in/out, notifications etc.The problem with this feature is that we cannot verify that Apple\u2019s implementation of the math is correct and without security flaws. Everyone knows there is security flaws in all software, and this implementation is not open (I.e. we cannot review the code, and even if we could review code we cannot verify that the provided code was the code used in the iOS build). So, we have to trust Apple did not make any mistakes in their implementation.\n \nreply",
      "Your second paragraph is exactly the point made in the article as the reason why it should be an informed choice and not something on by default.\n \nreply",
      "As someone with a background in mathematics I appreciate your point about cryptography.  That said, there is no guarantee that any particular implementation of a secure theoretical algorithm is actually secure.\n \nreply",
      "There is also no guarantee that Apple isn't lying about everything.They could just have the OS batch uploads until a later point e.g. when the phone checks for updates.The point is that this is all about risk mitigation not elimination.\n \nreply",
      "I\u2019m stealing your information.Hey! That\u2019s wrong.But I promise I won\u2019t do anything wrong with it.Well ok then.\n \nreply",
      "This is still a very dishonest representation of what\u2019s actually happening."
    ],
    "link": "https://lapcatsoftware.com/articles/2024/12/3.html",
    "first_paragraph": "This morning while perusing the settings of a bunch of apps on my iPhone, I discovered a new setting for Photos that was enabled by default: Enhanced Visual Search. (I manually disabled it before taking the screenshot below.)This setting is also new to Photos on macOS Sequoia, and enabled by default.Oddly, this new feature has mostly gone unmentioned in the Apple news media, according to Google. Moreover, it has also mostly gone unmentioned by Apple itself, according to Google. There appear to be only two relevant documents on Apple's website, the first of which is a legal notice about Photos & Privacy:The second online Apple document is a blog post by Machine Learning Research titled Combining Machine Learning and Homomorphic Encryption in the Apple Ecosystem and published on October 24, 2024. (Note that iOS 18 and macOS 15 were released to the public on September 16.)Of course, this user never requested that my on-device experiences be \"enriched\" by phoning home to Cupertino. This ch"
  },
  {
    "title": "NASA, Axiom Space Change Assembly Order of Commercial Space Station (nasa.gov)",
    "points": 27,
    "submitter": "mzs",
    "submit_time": "2024-12-26T18:33:21 1735238001",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.nasa.gov/humans-in-space/nasa-axiom-space-change-assembly-order-of-commercial-space-station/",
    "first_paragraph": "3 min readIn coordination with NASA, Axiom Space modified its planned assembly sequence to accelerate its ability to operate as a viable free-flying space station and reduce International Space Station reliance during assembly.NASA awarded Axiom Space a firm-fixed price, indefinite-delivery, indefinite-quantity contract in January 2020, as the agency continues to open the space station for commercial use. The contract provides insight into the development of at least one habitable commercial module to be attached to the space station with the goal of becoming a free-flying destination in low Earth orbit prior to retirement of the orbiting laboratory in 2030.The initial Axiom Space plan was to launch and attach its first module, Habitat 1, to the space station, followed by three additional modules.Under the company\u2019s new assembly sequence, the Payload, Power, and Thermal Module will launch to the orbiting laboratory first, allowing it to depart as early as 2028 and become a free-flying "
  },
  {
    "title": "Fish 4.0: The Fish of Theseus (fishshell.com)",
    "points": 249,
    "submitter": "jdxcode",
    "submit_time": "2024-12-28T22:07:15 1735423635",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42535217",
    "comments": [
      "Congrats to the fish team!  Great writeup with lots of interesting detail.I wonder if this is the biggest project that has moved from C++ entirely to Rust (or maybe even C to Rust?)  It probably has useful lessons for other projects.If I'm reading this right, it looks like fish was not released as a hybrid C++ / Rust program, with the autocxx-generated bindings.  There was a release during that time, but it says \"fish 3.7 remains a C++ program\" [1]It sounds like they could have released if they wanted to, but there was a last stage of testing that didn't happen until the end.Some people didn't quite get the motivation for adding C++ features to Rust [2], and vice versa, to enable inter-op.  But perhaps this is a good case study.It would be nice if you could just write new Rust code in a C++ codebase, without writing/generating bindings, and then throwing them away, which is mentioned in this post.---Also the #1 gripe with Rust seems to be that it supports version detection, not feature detection.But feature detection is better for distros, web browsers, and compilers:Feature Detection Is Better than Version Detection - https://github.com/oils-for-unix/oils/wiki/Feature-Detection...Version/name detection is why Chrome and IE pretend to be Mozilla, and why Clang pretends to be GCC.  Feature detection (e.g. ./configure and eval() ) doesn't cause this problem![1] https://github.com/fish-shell/fish-shell/releases[2] e.g. https://news.ycombinator.com/from?site=safecpp.org\n \nreply",
      "I remember switching from bash to zsh a few years back and thinking I was the bees knees. After the switch trying other shells seemed like bike-shedding because, I mean, what more could a shell? Then I got a new computer and decided to start from scratch with my tooling and downloaded fish. I was shocked how it instantly made zsh feel cumbersome and ancient.Heartily recommend others give it a try as a daily driver for a couple of weeks. I liken it to Sublime Text: an excellent \u201cout of the box\u201d tool. Just the right amount of features, with the option to add more if you want. But you also don\u2019t feel like your missing out if you keep it bare bones. A great tool in and of itself.\n \nreply",
      "Interesting, I went the other way about 7 years ago - switched from fish to zsh (initially with oh-my-zsh). The interactive experience was similar enough on both shells, and the performance was great on fish and okay-ish on zsh, but two things won me over:1. With zsh, I can copy-paste some bash snippet and in 99% of cases it will just work. Aside of copy-pasting from StackExchange, I also know a lot of bash syntax by heart by now, and can write some clever one-liners. With zsh, I didn't need to learn everything from scratch. (I guess this matters less now that you can ask AI to convert a bash one-liner into fish one-liner?)2. For standalone scripts... well, I think it's best to reach for a proper programming language (e.g. Python) instead of any shell language, but if I had to use one, I would pick bash. Sure, it has many footguns, but I know them pretty well. And fish language is also not ideal - e.g. IIRC it doesn't have an equivalent of `set -e`, you have to add `; or return 1` to each line.\n \nreply",
      "> The one goal of the port we did not succeed in was removing CMake.> That\u2019s because, while cargo is great at building things, it is very simplistic at installing them. Cargo wants everything in a few neat binaries, and that isn\u2019t our use case. Fish has about 1200 .fish scripts (961 completions, 217 associated functions), as well as about 130 pages of documentation (as html and man pages), and the web-config tool and the man page generator (both written in python).Our issue for this is https://github.com/rust-lang/cargo/issues/2729Personally, I lean away from Cargo expanding into these use cases and prefer another tool being implemented on top. I've written more about this at https://epage.github.io/blog/2023/08/are-we-gui-build-yet/\n \nreply",
      "(hi Ed!)I would definitely love to see Cargo have the ability to do this -- it means that `cargo install --locked` stays as a viable approach. It probably won't apply to fish, but I think being able to run a post-install command from the binary you just installed would suffice for my needs.\n \nreply",
      "> The one platform we care about a bit that it does not currently seem to have enough support for is Cygwin, which is sad, but we have to make a cut somewhere.> We\u2019re also losing Cygwin as a supported platform for the time being, because there is no Rust target for Cygwin and so no way to build binaries targeting it. We hope that this situation changes in future, but we had also hoped it would improve during the almost two years of the port. For now, the only way to run fish on Windows is to use WSL.I understand, but this is indeed incredibly sad.  To this day I still use Cygwin, and in fact prefer it to WSL depending on what I'm doing.  Cygwin is an incredible project that is borderline miraculous for what it accomplished and provides.  Without Cygwin I may not have any sanity left.  I can't exude enough love for the Cygwin team.Hopefully rust will support cygwin as a build target in the future!\n \nreply",
      "> it is often better to use if cfg!(...) instead of #[cfg(...)] because code behind the latter is eliminated very earlyMy experience with this is the other way around, especially if you have crates tied to that feature.The cfg! is a marco that compiles to true/false, so whatever is inside of the if guard needs to compile regardless.E.g.:Cargo.toml    [features]\n    default = []\n    my_feature = [\"deps:feature_dependency\"]\n\n    [dependencies]\n    feature_dependency = \"1.0.0\"\n\nAnd in code:    if cfg!(feature = \"my_feature\") {\n        feature_dependency::something::Something::invoke();\n    }\n\nThis will fail if you compile without `my_feature`.\n \nreply",
      "That was the point. The paragraph is talking about how errors only show up in some configurations, leading to \u201cworks for me\u201d behavior for some of the devs. When you can get away with cfg!, you are more confident that it will at least compile regardless of the config being checked.\n \nreply",
      "Really happy to see this, such a mammoth effort by the team and everyone else involved.I switched over from zsh about four years ago and my config went from several hundred lines to a handful with just one plugin (fzf.fish).It just works how I expect it to and I can't imagine changing again any time soon.\n \nreply",
      "Is fish better than Zsh?\n \nreply"
    ],
    "link": "https://fishshell.com/blog/rustport/",
    "first_paragraph": "About two years ago, our head maintainer @ridiculousfish opened what quickly became our most-read pull request:Truth be told, we did not quite expect that to be as popular as it was.\nIt was written as a bit of an in-joke for the fish developers first, and not really as a press release to be shared far and wide.\nWe didn\u2019t post it anywhere, but other people did, and we got a lot of reactions.Observant readers will note that the PR was a proposal to rewrite the entirety of fish in Rust, from C++.Fish is no stranger to language changes - it was ported from pure C to C++ earlier in its life,\nbut this was a much bigger project, porting to a much more different language that didn\u2019t even exist when fish was started in 2007.Now that we\u2019ve released the beta of fish 4.0, containing 0% C++ and almost 100% pure Rust, let\u2019s look back to see what we\u2019ve learned, what went well, what could have gone better and what we can do now.We\u2019re writing this so others can learn from our experience, but it is our "
  },
  {
    "title": "AnkiAIUtils: Flashcards+AI Illustrations, Explanations, Mnemonics etc. \u2013 FOSS (github.com/thiswillbeyourgithub)",
    "points": 44,
    "submitter": "Ey7NFZ3P0nzAe",
    "submit_time": "2024-12-28T21:30:34 1735421434",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42534931",
    "comments": [
      "Very cool. I actually built an app called \"Johnny Mnemonic\" around 5 years ago that generated a mnemonic sentence given a list of terms when I was studying for my EMT license. At the time I leveraged a simple n-gram markov model that I based off the publicly available Cornell Movie script database.I added a couple settings like word order(matters: colors of the rainbow, doesn't matter: bones of the skull), anagram vs sentence, etc. At the time the biggest difficulty wasn't necessarily generating a coherent sentence - it was ensuring the \"novelty\" of the mnemonic. The less surprising the less likely its going to stick.Fun little tidbit - by adding a \"NSFW\" flag - I made it so the markov chain would heavily weight racy/saucy/lewd words. End result, VERY VERY evocative mnemonics that were completely and utterly incapable of being shared.Demo:https://www.youtube.com/watch?v=MTAbVBOMdbk\n \nreply",
      "Hi hn,I am nearly at the end of medical school so it is time I publish and \"advertise\" my open source scripts/apps for anki!Here's the pitch:Anki AI Utils is a suite of AI-powered tools designed to automatically improve cards you find challenging. Whether you're studying medicine, languages, or any complex subject, these tools can:- Explain difficult concepts with clear, ChatGPT-generated explanations.- Illustrate key ideas using Dall-E or Stable Diffusion-generated images.- Create mnemonics tailored to your memory style, including support for the Major System.- Reformulate poorly worded cards for clarity and better retention.Key Features:- Adaptive Learning: Uses semantic similarity to match cards with relevant examples.- Personalized Memory Hooks: Builds on your existing mnemonics for stronger recall.- Automation Ready: Run scripts daily to enhance cards you struggled with.- Universal Compatibility: Works across all Anki clients (Windows, Mac, Linux, Android, iOS).Example:For a flashcard about febrile seizures, Anki AI Utils can:- Generate a Dall-E illustration of a toddler holding a teacup next to a fireplace.- Create mnemonics like \"A child stumbles near the fire, dances symmetrically, has one strike, and fewer than three fires.\"- Provide an explanation of why febrile seizures occur and their diagnostic criteria.Call for Contributors:This project is battle-tested but needs help to become a polished Anki addon. If you\u2019re a developer or enthusiast, join us to make these tools more accessible!Check out my other projects on GitHub: [Anki AI Utils](https://github.com/thiswillbeyourgithub)Transform your Anki experience with AI\u2014because learning should be smarter, not harder.\n \nreply",
      "I used to be heavy Anki user but I find the setup a little hard to follow.The image generation can do with ComfyUI integration. This will expand the illustration options beyond stable diffusion. It will also allow for more options within stable diffusion too.I might raise a PR tomorrow if I have the time.\n \nreply",
      "Thanks for the interest! The idea was to fully automate the process of creating illustrations for the failed cards of the day based on few shot prompting alone, indeed adding support for external API like ComfyUI would help a lot. Maybe especially for finetunes on specific subjets I guess?\n \nreply",
      "I'm a simple man, I see Anki, I upvote\n \nreply"
    ],
    "link": "https://github.com/thiswillbeyourgithub/AnkiAIUtils",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        AI-powered tools to enhance Anki flashcards with explanations, mnemonics, illustrations, and adaptive learning for medical school and beyond\n      A powerful suite of AI-powered tools to enhance your Anki flashcard learning experience by automatically improving cards you struggle with, tested through medical school. For example think of it like this: every time you fail a card you get a ChatGPT explanation, a Dall-E illustration, mnemonics, etc but supporting your own mnemonics.Check out my other Anki and AI related projects on my GitHub profile!Those scripts make it so that every failed note will automatically have new fields containing explanations, mnemonics, and illustrations. This is done in a way that respects your own mnemonics, can even use the major system, and has many more features.This collection of scripts is the culmin"
  },
  {
    "title": "EmacsConf 2024 Notes (sachachua.com)",
    "points": 245,
    "submitter": "JNRowe",
    "submit_time": "2024-12-28T14:22:30 1735395750",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=42531217",
    "comments": [
      "> EmacsConf feels like a nice, cozy get-together where people share the cool things they've been working on and thinking about.Emacsconf was indeed executed great this year, and nice and cozy were my feelings too. It's interesting to compare and contrast the ambience between Emacsconf and that of the other editors' like neovim conf and the release \"parties\" of Visual Studio Code and Jetbrains.\n \nreply",
      "I wouldn't believe how well it was run if I wasn't there. Sacha is a powerhouse, the amount of code she wrote in elisp to make this conference happen with the quality it did is just amazing.Thanks Sacha!\n \nreply",
      "What was different about it compared to the neovim conf?\n \nreply",
      "People can't seem to find an exit.\n \nreply",
      "Wow, that's actually hilarious!! :D\n \nreply",
      "I had no idea that there was a NeovimConf!  It's kind of a shame that it's so low in the search rankings that searching directly for it seemed to turn up only hits for Neovim configuration files, so I hope that I may be forgiven for linking here: https://neovimconf.live .\n \nreply",
      "honestly the community Emacs has really sets it apart, and it's a piece of software where the GPL makes sense and shines and this is super clear in the Emacs community.It gives me hope for the longevity of the editor, and indeed, in the short ten years I've been a casual user it has only gotten better.Long live the Emacs community\n \nreply",
      "I loved browsing the emacsconf videos this year, really nicely presented, and such cool stuff happening. Still have lots to watch, but so far in particular the infrastructural and UI type stuff seemed amazing, there's loads happening! Favourites included:https://emacsconf.org/2024/talks/casual/ -- Charles Choi designing UIs for human beings rather than octopuses (this jibe is meant fondly, I am a happy octopus)https://emacsconf.org/2024/talks/literate/ -- Howard Abram, literate programminghttps://emacsconf.org/2024/talks/gypsum/ -- Emacs and emacs lisp clone in Guilehttps://emacsconf.org/2024/talks/rust/ -- Rune, an experimental Emacs core in Rusthttps://emacsconf.org/2024/talks/julia/ -- lovely talk about the synchronicity between Julia and Emacshttps://emacsconf.org/2024/talks/guile/ -- Robin Templeton relaunches Guile-Emacs!https://emacsconf.org/2024/talks/mcclim/ -- eh, this talk accepted questions from lambdaMOO?\n \nreply",
      "There was supposed to be one talk about an attempt to re-vitalize a Guile-powered Emacs. I am not sure if it's in there somewhere or not (but I haven't looked yet).I imagine Emacs gaining native compilation capability took some pressure off that. But the appeal of scripting Emacs in languages other than Elisp still has some appeal, I think. Scheme or Lua would very nice for that purpose.EDIT: There it is - https://emacsconf.org/2024/talks/guile/\n \nreply",
      "I think just having a proper runtime for elisp would be great...I am a guile person, but even if the Emacs folks would only allow elisp on guile it would still be a win.\n \nreply"
    ],
    "link": "https://sachachua.com/blog/2024/12/emacsconf-2024-notes/",
    "first_paragraph": "\n[2024-12-28 Sat]: Added talk and Q&A count, added note about BBB max simultaneous users, added note about BBB, added thanks\n\nThe videos have been uploaded, thank-you notes\nhave been sent, and the kiddo has decided to play\na little Minecraft on her own, so now I get to\nwrite some quick notes on EmacsConf 2024.\n\nServer configuration:\n\nYouTube livestream stats:\n\nWe did early acceptances again this year. That was\nnice. I wasn't sure about committing longer\nperiods of time early in the scheduling process,\nso I usually tried to nudge people to plan a\n20-minute video with the option of possibly doing\nmore, and I okayed longer talks once we figured\nout what the schedule looked like.\n\nThere were 82 days between the call for proposals\nand the CFP deadline, another 49 days from that to\nthe video target date, and 29 days between the\nvideo target date and EmacsConf. It felt like\nthere was a good amount of time for proposals and\nvideos. Six videos came in before or on the target\ndate. The rest tric"
  },
  {
    "title": "Where can you go in Europe by train in 8h? (chronotrains.com)",
    "points": 379,
    "submitter": "vortex_ape",
    "submit_time": "2024-12-28T11:43:15 1735386195",
    "num_comments": 283,
    "comments_url": "https://news.ycombinator.com/item?id=42530332",
    "comments": [
      "About 20 years ago, I visited most of Europe\u2019s major cities over the course of a two-month trip, traveling primarily by night train. Each overnight ride saved me the cost of a hostel or guesthouse, and I\u2019d arrive in a new city each morning feeling refreshed because of the train\u2019s sleeping accommodations.There used to be a similar service between Toronto and Montreal (both directions), where the train would pause for several hours midway so passengers would arrive at around 7:30 a.m. well-rested.I\u2019ve taken that route as well, and it\u2019s remarkable how much you see while traveling by train. You pass through countless towns, villages, and beautiful scenery\u2014experiences you simply can\u2019t get from flying.\n \nreply",
      "\"I\u2019d arrive in a new city each morning feeling refreshed because of the train\u2019s sleeping accommodations.\"Aeh, where were you travelling? Many countries did not have sleeper trains. Don't get me wrong. I did the same, travelling at night in trains, and it saved me a night in a hotel. But I did not arrive well rested, I arrived train wrecked.\n \nreply",
      "I traveled by sleeper train in india,in 2010. They had beds, but every time I woke up, there were 3-4 Indian dudes that had come into our cabin and climbed on my bed to get some shut eye.It wasn't threatening or anything, just a wild experience and insightful lesson in cultural differences\n \nreply",
      "I spent a couple weeks travelling by train across Europe a few years ago on an Interrail pass. I found sleeper cabins were generally pretty comfortable, though you do have to pay extra for them.If you were just sleeping in a seat then yes I can believe you felt awful the next day.\n \nreply",
      "There's a map to prove you wrong. I counted 26 from the UK to Turkey and from that bit of Spain to Ukraine (a different gauge doesn't mean you can have nighttrains). The solid lines have sleeper wagons. Which are useless anyways if you are taller than 190cm. https://back-on-track.eu/night-train-map/Actually Spain seems to have more to offer according to this map http://www.night-trains.com/europe/edit: Nope, Spain is pretty almost void of night trains https://en.wikipedia.org/wiki/Trenhotel\n \nreply",
      "20 years ago was quite a different story.  Before low cost airlines, mobiles, and almost before the euro\u2026I did a similar trip in the late 90s. Not 20 stays in train, but well above 10. Paris-Madrid, Rome-Paris, Bordeaux-Paris, to name a few.\n \nreply",
      "20 years ago?\n \nreply",
      "Yes. It was called Interrail. You had to have an EU Passport to buy this ticket. And be below 26 years of age. I think it still exits.\n \nreply",
      "It still exists: https://www.interrail.eu/You don't have to be younger than 26 to buy one, not anymore, but it is cheaper if you are. If you are a EU citizen, it gets you free, unlimited travel by train in most European countries. If you are not a EU citizen, there is the Eurail pass that is similar.But that's the theory. In practice there are important limitations:- You can't use it in your home country, except for a single round trip: in and out.- If you make a reservation, you will have to pay reservation fees, and many long-distance and high-speed trains only have reserved seats.- Not all seats are available to pass owners, if you want to travel in these seats, you will have to pay full price.And considering that the pass itself is not that cheap, you really have some planning to do to see if it is worth it. In many cases, it isn't.\n \nreply",
      "Or no planning at all, as I did 26 years ago. Meet some people in a cafe in Paris, agree to all go to Amsterdam for 2 days, grab your bag and then find a hostel when you arrive. I spent 2 months without knowing where I was going to wake up the following day.No mobiles, only lifeline home being a pay phone call every week.Not the same stores in every city as it is today.Life was beautiful back then and we did not know it.\n \nreply"
    ],
    "link": "https://www.chronotrains.com/en",
    "first_paragraph": "This map shows you how far you can travel from each station in Europe in less than 8 hours.Hover your mouse on the map to see the isochrones from that city, search for a station, or click on one of the examples below.Traveling by train in Europe offers a blend of speed, convenience, and scenic beauty. Whether you're planning a quick getaway or an extended tour, our interactive map helps you find the best destinations reachable with any time budget around any city in Europe.Efficiency: High-speed trains connect major cities, reducing travel time significantly compared to other modes of transportation.Comfort: Enjoy spacious seating, onboard amenities, and the ability to move freely during your journey.Sustainability: Trains are an eco-friendly alternative, helping reduce your carbon footprint.A: The map is based on estimated travel times from Deutsche Bahn data, but actual times may vary. Always check the latest schedules before traveling.A: Yes, the map is a great tool for planning ext"
  },
  {
    "title": "I automated my job application process (daviddodda.com)",
    "points": 262,
    "submitter": "paul-tharun",
    "submit_time": "2024-12-28T15:26:31 1735399591",
    "num_comments": 413,
    "comments_url": "https://news.ycombinator.com/item?id=42531695",
    "comments": [
      "I'm seeing a lot of back in forth in the comments between hiring managers and employees discussing who is more responsible for the current situation, but from the perspective of someone looking for a job what should I be doing?I've been pretty aggressively looking for a job for the past six months or so. I have 10+ years of professional software dev experience so I've mostly been looking at senior dev positions. I haven't used LLMs at all in my resume, cover letters, etc. I only apply to jobs that I believe I meet the requirements for and that I would likely accept if given an offer. How do I signal that 1) I am a real person 2) I really do have the job experience and skills listed on my resume, and 3) I really am interested in the specific job I'm applying for. Because doing this my hit rate has been abysmal. I've had maybe 10-12 initial phone screens (never an issue, I easily make it past these). Past that I've had maybe 3-4 interviews that get into the later rounds. From that I've had zero offers.So why should I keep doing what I'm doing when it's getting me nowhere? Why shouldn't I switch to an automated \"shotgun\" approach that applies me to as many jobs as possible to which I vaguely fit the requirements? The only other way I've seen suggested to signal that I'm a real person with real experience is to know someone in the company who can vouch for me (which I almost never do).\n \nreply",
      "I was hiring manager for 3 positions about 4 months ago and the amount of fake applications out there was mind boggling to me. I would say 90% were either entirely fake or had the exact same generated ai text. It got so bad that we started only looking at resumes that had a working LinkedIn link.Also after so many bad resumes I started being very forgiving for the ones that didn't fully match the job requirements if they had something in them that made it seem like a real person, e.g. a personal hobby section. I think a lot of people discourage writing that but I argue it makes you stand out in an ocean of fake and copy pasted junk.\n \nreply",
      "And that's not even enough: A few weeks ago I had to interview someone who had what appeared to be a realistic profile. Everything that came out of their mouth was from chatGPT It was suspicious, but the ruse became clear when they shared the wrong screen, so we could see his prompt, and how everything we said was being read in.At this point every remote internet checklist has to include checks for humanity, because the percentage of straight out fakes is too high. Even the questions to ask me at the end were GPT provided.\n \nreply",
      "Anyone affected by this and in the US might consider calling or writing to their congressman. The time to do that is now when the demand is high to bolster jobs but low for excessive laws. Nobody innocent is going to be wronged if this is made into a crime or otherwise regulated to put a stop to.The fake job applicants are only siphoning resources from the economy at the high expense of all other parties involved. The ones who are getting screwed the most are the applicants, some of whom are concerned about making ends meet and getting auto-rejected constantly despite decades of experience. No one should stand for it.\n \nreply",
      "If I didn't know better I'd think this was satire. As far as I can tell the advocacy is for either companies to be empowered to sue people who apply to work with them (seems like madness) or to set up a situation where the government enforcement arm pro-actively goes out and harasses unemployed job seekers. Either way that sounds like a recipe for disaster for unemployed persons.\n \nreply",
      "AI has made hiring especially in technical industry an absolute shit show. I agree with parent comment that ideally government could do something about it but agree with you on how would you even do that. Maybe if they required all the job board companies like indeed and glassdoor and LinkedIn to properly vet candidates else those companies would be fined, but it's hard to imagine a solution that doesn't also hurt unemployed legit human beings\n \nreply",
      "Start every interview asking the candidate how many rs are in strawberry.\n \nreply",
      "Apparently outdated, ChatGPT 3.5 answers correctly here.\n \nreply",
      "Try raspberry?  Both fail for me, but I'm not a paid user.",
      "I left LinkedIn years ago, because everyone and their dog was copying my entire profile.I was happy for that info to go to potential employers, but not to random company and its canine friend.Then MS bought LI and I was so glad I'd left years ago already.I've seen one of two places have mandatory URL fields for LinkedIn profiles.One of the impressions I've been getting is that if you do not fit exactly into an recruitment agencies process, you're DoA, and I have begun to suspect the only work they do is look at LinkedIn.\n \nreply"
    ],
    "link": "https://blog.daviddodda.com/how-i-automated-my-job-application-process-part-1",
    "first_paragraph": "Photo by Ricky  Kharawala on Unsplash7 min readLook, I'll be honest - job hunting sucks.It's this soul-crushing cycle of copying and pasting the same information over and over again, tweaking your resume for the 100th time, and writing cover letters that make you sound desperate without actually sounding desperate.But here's the thing: repetitive tasks + structured process = perfect automation candidate.So I did what any sane developer would do - I built a system to automate the whole damn thing. By the end, I had sent out 250 job applications in 20 minutes. (The irony? I got a job offer before I even finished building it. More on that later.)Let me walk you through how I did it.Think about it - every job application follows the same basic pattern:Find job postingCheck if you're qualifiedResearch company (let's be real, most people skip this)Submit resume + cover letterWait... and wait... and wait...It's like a really boring video game where you do the same quest over and over, hoping "
  },
  {
    "title": "Joco almost died at launch. Now, it's a lifeline for e-bike delivery riders (techcrunch.com)",
    "points": 33,
    "submitter": "PaulHoule",
    "submit_time": "2024-12-26T16:59:40 1735232380",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42516268",
    "comments": [
      "I find it really frustrating that the NYC DOT fought their original business model in order to protect Lyft\u2019s monopoly. I had assumed that Lyft\u2019s monopoly was on the right to use DOT\u2019s street space for their program (which at least makes sense), but it feels like a bike rental service operating on private property should not be the DOT\u2019s jurisdiction.The argument was essentially \u201cwe need to give Lyft a monopoly because that\u2019s the only way they would invest in the system\u201d, but the fact that Joco had a structural disadvantage (no public space) and was still willing to enter the market is a sign that we could have a competitive market without giving it all away to Lyft.\n \nreply",
      "I don\u2019t fully understand these kind of businesses especially in the \u201ctech\u201d space. I wonder if they paid for this article but I honestly don\u2019t see the growth in these companies. They can be great businesses but not ones that would be posting in TechCrunch.\n \nreply",
      "To your credit, it wouldn't be the first time TC did a pay-for-play.Also, TC has been beyond irrelevant for years.Now, it's even worse.  It's a negative-signal attached to all those desperate enough to use it.\n \nreply",
      "Not all tech businesses have to be hyperscalers slave to investor profit seeking\n \nreply",
      ">> life cycle of the new Segway bikes is three to five years....then I guess it's promptly thrown off a bridge into the river. The idea that a bicycle lasts 3 years, even with hard, year-round riding, is from the disposable tech consumer mindset. A well maintained commuter bike - not an expensive one - lasts 10+ years. These aren't really bicycles, but computerized, electric mopeds.\n \nreply",
      "It's about mileage, not age. A chain is good for maybe 2000 miles - a commuter might get a year or two out of it, but a courier or serious roadie could wear it out in a matter of weeks. The same basic equation applies to wheel rims, bearings, cassettes, chainrings and (in the case of e-bikes) batteries and motor-gearbox units. If you're changing those parts often enough, eventually something will strip or seize badly enough to write off the frame. Most casual cyclists will never experience it, but an aluminium frame will inevitably succumb to fatigue cracking around the bottom bracket after a few tens of thousands of miles, no matter how well it's cared for.Three to five years is incredibly good for a bike that's potentially being ridden all day, every day under very harsh conditions.\n \nreply",
      "I am not really convinced that 3-5 years is not a reasonable useful life. You are comparing one person owner bike to an electric bike ridden throughout the day but all sorts of people. Maybe it gets trashed and maybe it gets broken down and recycled parts where possible.\n \nreply",
      "It seems likely that the miles put on a \"commuter bike\" used for commuting twice a day for 10 years are within shouting distance of the miles put on a bike used for several hours of deliveries every day for 3 years.The company is incentivized to get the most out of their investment.  If the bikes can be maintained economically by staff mechanics, they will be \u2014 and these vehicles ought to be simple enough devices for mechanics to squeeze a long life out of them.If there's a difference, it would be in the lack of an ownership mindset by the riders: they might abuse them akin to how drivers abuse rental cars.\n \nreply",
      "A well maintained commuter bike is ridden twice a day during those 10+ years.\n \nreply"
    ],
    "link": "https://techcrunch.com/2024/11/30/joco-almost-died-at-launch-now-its-a-lifeline-for-e-bike-delivery-riders-and-a-profitable-business/",
    "first_paragraph": "\n\n\t\tLatest\t\n\n\n\t\tAI\t\n\n\n\t\tAmazon\t\n\n\n\t\tApps\t\n\n\n\t\tBiotech & Health\t\n\n\n\t\tClimate\t\n\n\n\t\tCloud Computing\t\n\n\n\t\tCommerce\t\n\n\n\t\tCrypto\t\n\n\n\t\tEnterprise\t\n\n\n\t\tEVs\t\n\n\n\t\tFintech\t\n\n\n\t\tFundraising\t\n\n\n\t\tGadgets\t\n\n\n\t\tGaming\t\n\n\n\t\tGoogle\t\n\n\n\t\tGovernment & Policy\t\n\n\n\t\tHardware\t\n\n\n\t\tInstagram\t\n\n\n\t\tLayoffs\t\n\n\n\t\tMedia & Entertainment\t\n\n\n\t\tMeta\t\n\n\n\t\tMicrosoft\t\n\n\n\t\tPrivacy\t\n\n\n\t\tRobotics\t\n\n\n\t\tSecurity\t\n\n\n\t\tSocial\t\n\n\n\t\tSpace\t\n\n\n\t\tStartups\t\n\n\n\t\tTikTok\t\n\n\n\t\tTransportation\t\n\n\n\t\tVenture\t\n\n\n\t\tEvents\t\n\n\n\t\tStartup Battlefield\t\n\n\n\t\tStrictlyVC\t\n\n\n\t\tNewsletters\t\n\n\n\t\tPodcasts\t\n\n\n\t\tVideos\t\n\n\n\t\tPartner Content\t\n\n\n\t\tTechCrunch Brand Studio\t\n\n\n\t\tCrunchboard\t\n\n\n\t\tContact Us\t\nOn a September morning in 2024, two Jonathan Cohens \u2014 one from the Rockaways in Queens, the other from London \u2014 stood in an empty 15,000-square-foot parking garage near Hudson Yards in New York City. As they walked over chipped yellow lines, they explained how the space would help Joco, their shared e-bike startup for delivery workers, continue to scale.\u201cWe\u2019re "
  },
  {
    "title": "The Gambler Who Cracked the Horse-Racing Code (bloomberg.com)",
    "points": 57,
    "submitter": "sebg",
    "submit_time": "2024-12-26T19:39:39 1735241979",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=42517234",
    "comments": [
      "British magician Darren Brown aired a TV special called \"The System\" revealing a foolproof method which allowed him to provide the name of the winning horse to a lucky person who randomly responded to his newspaper advertisement in time for that person to bet on the race and win. He continued doing this with that person for six more races over six consecutive weeks - with that person betting their own money and winning each time, beating astronomical odds and winning quite a large sum. The bets were real, legally placed in advance on televised races at regulated betting parlors and the person really randomly responded to the ad without knowing Brown beforehand. For the last race Brown and the person met at the race track but for all the prior races Brown didn't even know when or where the person would place their bet. He really had no involvement or even contact, other than sending the name of the horse to bet on via email once a week.Of course, it's (sort of) a very clever trick. All is revealed in the show (now on Brown's YouTube channel at https://www.youtube.com/watch?v=jR970Y10WNw). I showed it to my kid who had recently asked me about a state lottery billboard claiming \"Someone has to win!\" and it proved to be an entertainingly effective answer as well as providing some good ways to think critically about gambling propositions.\n \nreply",
      "I heard about a similar trick once in the framework of a scam, which may be the same (I'm not willing to watch this much youtube for the payoff), where out of the 1,000 people that reached out for answers to a 50/50 bet of some sort, they provided 50% of them one answer, and 50% the other. Out of the 50% that won, they provided 50% one answer and 50% another. Leading to a situation where eventually you had a small group of people who had received correct \"lottery\" or whatever answers five or six times in a row, priming them to believe the scammer had some major advantage. Then the scammer charged that last group of 15 or 30 some large amount of money to receive the last answer, and so on with the winners of that bet.\n \nreply",
      "yeah - this one was very popular in seasonal sports like football.\n \nreply",
      "Is a binary search involved in this \"gambling system\"?\n \nreply",
      "Here are two papers referenced in the article. This one inspired Bill Benterhttps://gwern.net/doc/statistics/decision/1986-bolton.pdfAnd Bill Benter wrote this one in 1995 describing his systemhttps://gwern.net/doc/statistics/decision/1994-benter.pdf\n \nreply",
      "There is this classichttps://www.amazon.com/Dr-Beat-Racetrack-William-Ziemba/dp/0...His idea is that the odds (on the tote board) to win can be used to make a more accurate predictor for winning place and show than the place and show odds on the board.  What you notice is that maybe two times a day at the track you find a horse which is favored to win and the show bet pays almost as much as the win bet and you place a Kelly-sized bet on that one.I've found a few opportunities of that sort at the local harness racing track.\n \nreply",
      "Could survivor bias be a more likely explanation than a good system? I mean among a large pool of people systematically betting on horse racing, a few are likely to have winning outcomes.\n \nreply",
      "It's closer to a hedge fund finding asymmetries (e.g., under/over valued odds by bookmakers, bulk buying strategies when phone buying is turned off, etc.) plus some structural benefits (e.g., HK was a gambler's dream. Winnings were exempt from taxation! And the \"pit boss\" for the horse-racing scene wasn't kicking them out.)These don't apply to all horse-racing scenes.These advantages emerge, but get competed away.Look at how the protagonists here were in black jack card counting teams. They do make money until they get blacklisted.\n \nreply",
      "If you have a large bankroll and a relationships with track staff etc, past posting would be an available system.Or to put it another way, social engineering is usually a more reliable hack than technical means. I mean his  card counting at blackjack was a team sport.Hedge funds trade on inside information because making money is the goal. Not style points.\n \nreply",
      "Definitely not luck. Bill runs with the same crowd that wrote the bible on advantage play (James Grosjean, etc).  They are exceptionally talented.\n \nreply"
    ],
    "link": "https://www.bloomberg.com/news/features/2018-05-03/the-gambler-who-cracked-the-horse-racing-code",
    "first_paragraph": "To continue, please click the box below to let us know you're not a robot.Please make sure your browser supports JavaScript and cookies and that you are not\n            blocking them from loading.\n            For more information you can review our Terms of\n                Service and Cookie Policy.For inquiries related to this message please contact\n            our support team and provide the reference ID below."
  },
  {
    "title": "EU law mandating universal chargers for devices comes into force (france24.com)",
    "points": 110,
    "submitter": "belter",
    "submit_time": "2024-12-28T21:20:35 1735420835",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=42534851",
    "comments": [
      "So... (looks over the shoulder) ... what do you guys think about omitting 5k1 pull-up resistors on CC1/CC2 pins?\n \nreply",
      "If you leave those off you won't get any power sent to your device.\n \nreply",
      "If you connect it to a USB A with an adapter it will work, right?\n \nreply",
      "Recently bought an ipad mini 6th gen and I notice that although it seems to have a USB-C charge port, if you use a regular old USB-C to USB-A cable and wall-wart it only charges to 75%. You have to use the apple-supplied USB-C (at both ends) cable to charge to 100%. Not sure what is going on there exactly but it seems like malicious compliance.\n \nreply",
      "Or as this hasn\u2019t been widely reported something else is going on\u2026Try different chargers, there\u2019s a lot of defective hardware out there.  Also it\u2019s at 80%, but there\u2019s a setting on iPhones and possibly iPads etc  that avoids charging to 100% to preserve long term battery life if you\u2019re going to leave the device plugged in long term.\n \nreply",
      "I don\u2019t know about iPads, but my iPhone shows a message when the delayed charge thing is active. I think it\u2019s even one of those always on notifications you can\u2019t swipe away.\n \nreply",
      "I charge my iPad Mini with a variety of chargers, all the way to 100%. None of my cables are from Apple, only some of my (USB-C) chargers are not from Apple.\n \nreply",
      "Are you sure it is because of the cable? By default Apple devices only charge to 80% when you plug them in and then do the final 20 later around when they anticipate you are going to unplug it.\n \nreply",
      "It\u2019s likely that your wall-wart doesn\u2019t provide enough watts to fully charge your iPad mini, and/or that there\u2019s some reason the USB-A side of that cable isn\u2019t adequate for what the iPad mini needs.If you want to test, consider trying with a non-Apple wall-wart for which the rated wattage is  equal to or greater than the one which Apple provides with your iPad mini and which uses a USB-C connection rather than a USB-A one. If it comes with a USB-C to USB-C cable, use that, otherwise get one that supports USB-C PD and enough watts to match the iPad mini\u2019s needs.\n \nreply",
      "That can't be the explanation.  Batteries use fewer watts as they get close to full.\n \nreply"
    ],
    "link": "https://www.france24.com/en/europe/20241228-eu-law-mandating-universal-chargers-for-devices-comes-into-force",
    "first_paragraph": ""
  },
  {
    "title": "My history with Forth and stack machines (2010) (yosefk.com)",
    "points": 73,
    "submitter": "homebrewer",
    "submit_time": "2024-12-28T16:34:24 1735403664",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42532157",
    "comments": [
      "I'll agree with a lot of his critiques, but one of his small ones that surprisingly echoed a lot of frustration was the dictum to prefer small definitions.> Quoting Chuck Moore:> Forth is highly factored code. I don't know anything else to say except that Forth is definitions. If you have a lot of small definitions you are writing Forth. In order to write a lot of small definitions you have to have a stack.It seemed like apologetics and a making a virtue out of necessity, given the fact that I don't have the capability to do stack acrobatics in my head live. The only way to be able to read a function in my head, without taking a pencil to paper _was_ small functions. But I found that clashed with the ways some algorithms and procedures naturally expressed themselves in longer multi-step style, and actually ending up being more verbose and tangled with multiple top-level definitions.It turns out that local variables that compile to C-style indirect (SP + i) accesses are only mildly more expensive than stack acrobatics, but still gave the flexibility of Forth-style metaprogramming. [1]Ultimately, the author's points about the \"Forth philosophy\" but not Forth-the-language itself (and extremely spare code) ring true to me.Given my limitations, life is too short to work to have as minimalist an implementation as you'd like, and to desire to have a interactive development environment in <128k. For me, it's hard enough to implement the \"subject\" that I'm programming algorithmically/data-driven-ly/amortizing-computation-ly efficiently.[1] https://www.novabbs.com/devel/article-flat.php?id=26347&grou...\n \nreply",
      "It's easier to approach Forth as assembly-like than C-like.That is, why are you factoring the code to use the stack when you have globals?(Mumble mumble structured program, recursion, reuse)If you move towards a global-first approach(which is what Chuck Moore seems to have moved towards, from anecdote), what changes is that you can substitute the word defining the variable for another word, later down the line, that adds the context, indirection and error handling you need. The mechanism can be added without changing how the word is being used, and you can still write a divide-and-conquer kind of algorithm in this way, it's just more classically imperative in style, with more setting of mutable global temporaries and every byte of bookkeeping directly accounted for.Part of the minimalist freedom in Forth is that it is agnostic to whether you're using the stack or the dictionary. If you want the word to be unambiguously about a particular space in memory it makes sense to define it first in terms of \"it accesses this static location\" instead of \"it consumes three things on the stack and shuffles them around and indirects one to a memory location and adds the other two\", because that inclines all the words to be about the stack. Take the primitive approach - the one that maps well to assembly - first and see how far it goes. You stay in control of how you're extending the language that way. C preempts that because the compiler hides the stack manipulation, so the semantics of the function will default towards locals, and then further extension is guided around fitting it into that.(And it's true that the compiler gets you to an answer faster, and black-boxes the interface, so you can use code without reading code - and that is coming at the expense of precision around details like this. Forth is probably not the right way, if it's Conway's law that you're up against.)\n \nreply",
      "In most assembly languages, accessing local variables on the stack is easy, plus you have multiple registers for temporary data. Forth feels extremely limiting compared to that.On an architecture without those features, like the 6502, Forth may be a good idea, and possibly faster than C - but only if it's compiled to machine code with some peephole optimizations, so that e.g. \"MY-VAR 123 C!\" translates into \"LDA #123 ; STA MY-VAR\", instead of a naive implementation where the address and constant would first be pushed onto the stack.And any more complicated optimizations would probably require first \"decompiling\" the Forth code back into a higher level of abstraction. It's practically the same as assembler macros otherwise.\n \nreply",
      "I appreciate Yossi's plain honesty in this article, and it's a fun and interesting read; I've read it before.I can relate to, but not endorse, designing a CPU and dialect for an interesting language you've never properly used.  This turned out to be very painful, and Yossi argues convincingly that it is essentially not practical to use Forth at all, debating Jeff Fox's position.  However, there is some evidence[1] that Forth actually might be practical, and it certainly seemed to have a niche in the 80's.Yossi made some errors I've seen among new Forth programmers.  A lot of people, before writing real programs, think Forth is like lisp from another universe.  They visualise Forth primarily as a sort-of functional, concatenative, highly refactor-focused language.  They likewise tend to throw out all the normal Forth defining words and use Forth as 'lisp without parentheses'.  They try and put all their data on the stack, 'point-free', rather than using variables.  And often their projects eventually devolve into C envy, every line with stack comments and equivalent C code to help, as shown in the article.But go look at real, working, classic Forth code, of which there is much, and you'll see that there is a prevailing style that's easy to read and not actually that 'smart', or 'academic'.  No more than 1-2 stack items need to be mentally 'juggled' for 99% of code, lots of variables and buffers are used whenever it's easier.  Yes the classic variables are 'global', but it doesn't matter if the relevant code isn't recursing or touched in interrupts, and is only used by a cluster of related words.  Newer Forths do have local variables, in spite of Jeff Fox's disapproval!The classic code I'm talking about matches what I think Jeff Fox is trying to coerce you towards.  Ultimately I disagree with Yossi's views because I think if he had actually tried to implement what Jeff Fox proposes, and got some practice first on a more realistic project, he would have had a much better shot.  It's impressive how well the project turned out in spite of the approach, and how Yossi wrote a backend for his architecture in a week: a testament to both his skills and LLVM's design; but it's worth reflecting as engineers how arrogant (yet relatable) it is to make a CPU and compiler for a language you've never properly used.[1] https://www.hardware-x.com/article/S2468-0672(22)00025-6/ful...\n \nreply",
      "I think that \"Good Forth programmers arrange things so that they flow on the stack\" has analogs in other languages.  For example, arranging things in J so that short tacit expressions naturally provide the functions you need.\n \nreply",
      "I feel like Forth will always have a place in embedded contexts. And it's a good language to start with when learning how to write interpreters/compilers.The second you start building higher level apps in Forth, you lose most of its advantages from my experience.While usable as an in-app scripting language, I would pick Lisp any day.\n \nreply",
      "The opinion that Forth doesn't climb the abstraction ladder well is popular, but I'd be tempted to qualify it as a misconception.My own attempt[1] at a Forth that climbs that ladder is, I think, a good counter example. In my opinion, its HAL compares favorably to, for example, SBCL's native code compiler. Its almost-C compiler compares favorably to, I think, Tiny CC.This misconception stems, I think, from the fact that you can very well reap the rewards of Forth in a low level environment without needing to \"think in Forth\". For example, by mastering immediate mechanics.Someone who hasn't invested the effort to twist their mind to Forth-think will, yes, end up having troubles climbing the abstraction ladder.This is not unlike, I think, \"macro heavy\" lisp, which many lispers actively avoid. But at the same time, much of lisp's power comes from it.[1]: http://duskos.org/\n \nreply",
      "You want to be truly amazed, check out Newell\u2019s IPL-V, which is a machine language for a stack machine, developed in the 1950s and used to implement the first AIs. It had every idea n Lisp except the parens.\n \nreply",
      "I have ported Forth to a dozen small microcontrollers and my experience\nwriting much of the bootstrap code in Forth tells me that you are better off\ncoding Forth in a \"vertical\" style (ie one word per line with stack picture \ncomments), rather than the terse \"horizontal\" code of \"everything on one line\"\nthat many of the folks using Forth (including @yosefk, the author) seem to prefer.Given how close Forth is to assembly (seen from an implementer's point of view)\nit makes sense to write Forth in a \"vertical\" style which reflects the\n\"vertical\" style in which assembly code is written. This has the advantage that\nthe \"stack picture comments\" on each line of code can stand in for Hoare triplets\nso that the code and its - I'll call it - \"proof\" can be written hand in hand\nat the same time.This is how all of the Forth code that I've written in\nhttps://github.com/romforth/romforth is structured.It does make the code appear less compact though so you are not going to win\nany code golf prizes.\n \nreply",
      "Is there any editor/IDE support for stack state visualisation?A text display with an auto pretty printed view would serve people who like both code styles well.A newline per stack reducing operation with the next line indented by stack depth would make it close to your style and could be quite automatic.\n \nreply"
    ],
    "link": "https://yosefk.com/blog/my-history-with-forth-stack-machines.html",
    "first_paragraph": "September 10th, 2010My VLSI tools take a chip from conception through testing. Perhaps 500 lines\nof source code. Cadence, Mentor Graphics do the same, more or less. With how much source/object\ncode?\u2013 Chuck Moore, the inventor of ForthThis is a personal account of my experience implementing and using the Forth programming language and the stack machine\narchitecture. \"Implementing and using\" \u2013 in that order, pretty much; a somewhat typical order, as will become apparent.It will also become clear why, having defined the instruction set of a processor designed to run Forth that went into\nproduction, I don't consider myself a competent Forth programmer (now is the time to warn that my understanding of Forth is just\nthat \u2013 my own understanding; wouldn't count on it too much.)Why the epigraph about Chuck Moore's VLSI tools? Because Forth is very radical. Black Square kind of radical. An approach to\nprogramming seemingly leaving out most if not all of programming:...Forth does it differently. "
  },
  {
    "title": "Finding and exploiting hidden features of Animal Crossing's NES emulator (jamchamb.net)",
    "points": 11,
    "submitter": "networked",
    "submit_time": "2024-12-28T22:22:20 1735424540",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jamchamb.net/2018/07/11/animal-crossing-nes-emulator-hacks.html",
    "first_paragraph": "\n      \n      \n      July 11, 2018\n    While looking for ways to activate the developer menus left over in Animal Crossing,\nincluding the NES emulator game selection menu, I found an interesting feature that exists\nin the original game that was always active, but never used by Nintendo.\nIn addition to the NES/Famicom games that can be obtained in-game, it was possible to\nload new NES games from the memory card.\nI was also able to find a way to exploit this ROM loader to patch custom code and data into\nthe game, allowing for code execution via the memory card.The normal NES games that you could obtain in Animal Crossing each came as an individual\nfurniture piece that appeared as an NES console with a single game box on top of it.\nWhen you placed the item in your house and interacted with it, it would only play that one game.\nPictured below are the Excitebike and Golf items.There was also a generic \u201cNES Console\u201d item that did not feature any of the built-in games.\nYou could buy this item"
  },
  {
    "title": "Libero \u2013 A Programmer's Tool and Code Generator (1997) (imatix-legacy.github.io)",
    "points": 30,
    "submitter": "leonry",
    "submit_time": "2024-12-28T20:03:28 1735416208",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42534090",
    "comments": [
      "Ok I was intrigued for a moment and wondered why the page looks so damn old. Last update 1997 :)\n \nreply",
      "I've built something similar that uses CUE + text/template rather than visual programming. Like libero, iteration is important and hof let's you modify the generated code and the design for the automated code as many times as you like.https://github.com/hofstadter-io/hof\n \nreply",
      "Doesn't seem possible to install for Windows:https://imatix-legacy.github.io/pub/libero/bin/lrmswin.zipis 404 and not available on archive.org:https://web.archive.org/web/20240000000000*/https://imatix-l...If someone could get it running (and generating Python code) it might be very interesting.\n \nreply",
      "It is not exactly the same, and it is a shameless plug, but I work on a code/config generation tool.I'd be interested in hearing about your use-case and whether something like https://jwdevantier.github.io/htt/quick-start/ ( https://github.com/jwdevantier/htt ) would let you solve your issue?\n \nreply",
      "I wasn't sure if the project in question would be useful.Interestingly, it looks as if your project would directly apply to the current step of my current project: getting from a Python core in OpenPythonSCAD to wrapping it in OpenSCAD code --- if there was enough code to it to make automation make sense, and if the whole tool stack was stable enough for that to make sense.Mostly I was researching this for:https://github.com/IndiePython/myappmaker-sdd\n \nreply",
      "curl -LO https://github.com/imatix-legacy/libero/raw/master/pub/bin/lrmswin.zip\n  unzip -l lrmswin.zip\n  Archive:  lrmswin.zip\n  Length      Date    Time    Name\n  ---------  ---------- -----   ----\n   336659  06-16-1997 09:51   lrwin.exe\n    83008  06-09-1997 12:42   lwproc.dll\n     8910  12-29-1996 12:48   lrmesg.txt\n \nreply",
      "Thanks!Since it also includes vbrun300.dll I suspect this is a bit too old to run on a current system.\n \nreply",
      "libero is a racist/fascist newspaper in italy.\n \nreply"
    ],
    "link": "https://imatix-legacy.github.io/libero/index.htm",
    "first_paragraph": "\n\nWelcome To Libero\nDownloading Libero\nLibero Documentation\n\nLiberetto - The Libero Fanzine\n\nRecent Changes to Libero\nLibero Credits\nLinks to Other Pages\n\n\n1.v.(latin) \"I free\", from liberare;\r\n2.n.(french) Go-fer for football (soccer) team, keeps things\r\nmoving during matches;3.n. Brand of diapers in Europe.\r\n\"Liber-o\" is pronounced like English \"liber-ty\" or\r\nFrench \"liber-t\u00e9\".\r\n\r\nAre you a programmer?  Do you sincerely want to write better programs?\r\nThen take a look at Libero, a free software tool from iMatix.\r\n\r\nHow do I use Libero?\n\nDesign your program visually as a state diagram;\r\nChoose your programming language;\r\nGenerate a framework for your program;\r\nFill-in the framework to get from rapid prototype to working program;\r\nRepeat until your program is perfect.\r\n\nWhat Languages can I use?\n\nANSI C\nPHP\nJava\nC++\nPerl\nAwk\nUNIX shells - Korn shell, BASH,\r\nBourne shell, C shell\nRexx\nMS Visual Basic\nMS Test Basic\nCOBOL\nPL/SQL\nMS 80x86 Assembler\n\r\n  ... with open-ended support for other"
  },
  {
    "title": "Numbers Are Leaves (christo.sh)",
    "points": 181,
    "submitter": "nodar-d",
    "submit_time": "2024-12-26T14:23:30 1735223010",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=42515315",
    "comments": [
      "A more compact and beautiful relation exists between integers and finite rooted trees exist, imo.David W. Matula found a correspondence between trees and integers using prime factorization, and reported it in 1968 in SIAM:\n\"A Natural Rooted Tree Enumeration by Prime Factorization\", SIAM Rev. 10, 1968, p.273 [1]Others have commented on it before, search the web for Matula NumbersI independently found this relation when working on a bar code system that was topologically robust to deformation. I wrote a document that explained this relation here[2].I created an interactive javascript notebook that draws related topological diagrams for numbers. [3][1] http://williamsharkey.com/matulaSIAM.png[2] https://williamsharkey.com/integer-tree-isomorphism.pdf[3] https://williamsharkey.com/MatulaExplorer/MatulaExplorer.htm...\n \nreply",
      "Sorry - I believe I am off topic as this is not relevant given:\"This indirectly enforces the idea that sets cannot have duplicate elements, as set membership is defined purely by the presence or absence of elements. For example:\"So there is a constraint on what sort of trees are allowed in this -forrest- which would preclude most finite rooted trees.\n \nreply",
      "From [2]:> EG: 165 = P5 * P3 * P1Shouldn\u2019t the last component be P2 (= 3)?\n \nreply",
      "> I think a fair thing to ask is if the force-directed layout engine is uniquely responsible for the leaf-like structure and this has nothing to do with the Von Neumann ordinals themselves.> To check this I generated some Collatz trees and they ended up looking like microbes. I think it's safe to say the answer is no.\"Uniquely responsible\" seems to be doing too much work. These structures are reminiscent of dendritic fractals coming about from diffusion-limited aggregation in electrochemical deposition[1], which is a transitional phenomenon with a phase diagram (molar concentration of the electrolyte vs voltage) There is a sweet spot in the middle where you get intricate dendritic crystals: outside of that you get smooth layers or big blobs / spikes without much internal structure.I suspect it is primarily the modeling of the forces which is responsible for the behavior, with the topological structure of the tree somewhat indirectly corresponding to the chemical and electrical parameters. I am by no means an expert but it seems likely to me that these von Neumann dendrites vs the structure of Collatz trees is a fairly shallow relationship: lots of trees with similar graph-theoretic properties to the von Neumann trees would also demonstrate the leaf-like fractals, but with no meaningful relationship to the natural numbers. But it would be interesting to make this more precise.[1] https://en.wikipedia.org/wiki/Diffusion-limited_aggregation\n \nreply",
      "> I would like to understand why numbers looks like leaves1st of all they don't. The graph doesn't look like pinnatids or palmatids. There is some resemblance of an alternating disposition of leaves, but that's not the shape of the leaf itself but the distribution of them, and it's a stretch.Secondly, I'll take the generous interpretation of the question which is, why the graph looks mathematically like leaves, and not a question of biological impact, whatever resemblance is a coincidence which brings us toThird, OP is playing a game with numbers with no objective  goal (yes all maths is this, but this is straight up chmess), there is no ultimate meaning to be derived of it.\n \nreply",
      "I think the last point doesn't really hold its own in any way. Many discoveries throughout history have started from someone just playing around with an idea, toying with it at first, but eventually becoming obsessed. The thing is, there's no way to tell beforehand. It might be a toy with no ultimate use or meaning, or it might lead to something entirely novel somewhere down the line. That's why play, in a very broad sense, is a core part of science and invention.\n \nreply",
      "If 1 out of 10 chmessicians discover something useful, the discoverer had good taste and deserves credit.There is no insurance redistributing credit amongst all of the pointless searches.The guys who invented imaginary numbers or eigenvectors weren't just throwing darts at a board and got \"lucky\".\n \nreply",
      "abstraction for abstraction\u2019s sake? pure abstraction? abstracted abstraction?\n \nreply",
      "I'm not really sure what to say to this, other than watch this video and apply similar thinking to this problem: https://www.youtube.com/watch?v=EK32jo7i5LQThe leaf structure itself doesn't really have anything to do with ZF set theory or Von Neumann ordinals, other than supplying the inspiration for the base structure. Same way prime numbers don't generate the spirals in the video, all numbers do. So leave the ordinals out of this, experiment with different tree construction methods and you might uncover something cool about trees (but not necessarily about set theory)\n \nreply",
      "I think people will like the following tangent.https://en.m.wikipedia.org/wiki/Benacerraf%27s_identificatio...In the philosophy of mathematics, Benacerraf's identification problem is a philosophical argument developed by Paul Benacerraf against set-theoretic Platonism and published in 1965 in an article entitled \"What Numbers Could Not Be\". Historically, the work became a significant catalyst in motivating the development of mathematical structuralism.The identification problem argues that there exists a fundamental problem in reducing natural numbers to pure sets. Since there exists an infinite number of ways of identifying the natural numbers with pure sets, no particular set-theoretic method can be determined as the \"true\" reduction.What Numbers Could Not Behttps://youtu.be/H5SocLNkT9M?si=Fk2Hmpw3yOtDW7GS\n \nreply"
    ],
    "link": "https://www.christo.sh/numbers-are-leaves/",
    "first_paragraph": ""
  },
  {
    "title": "Analyzing North Korean Malware (medium.com/henrique4win)",
    "points": 34,
    "submitter": "supitto",
    "submit_time": "2024-12-26T17:47:47 1735235267",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42516568",
    "comments": [
      "Developers should be required to add flags to allow reading/writing to disk. i.e. choose \u2014-insecure-disk\u2014access or \u2014-allow-read=/myappI hate the idea of making things a tiny bit more difficult for beginner developers,  but what is the alternative?\n \nreply",
      "I like the interface of OpenBSD's `pledge` and `unveil`:https://awesomekling.github.io/pledge-and-unveil-in-Serenity...\n \nreply",
      "Same post from their own blog: https://team-bytesized.github.io/articles/malware/beavertail...\n \nreply"
    ],
    "link": "https://medium.com/@henrique4win/analyzing-north-korean-malware-95dc3325d943",
    "first_paragraph": ""
  },
  {
    "title": "38C3: Blinkencity, radio controlling street lamps and power plants [video] (ccc.de)",
    "points": 5,
    "submitter": "aunderscored",
    "submit_time": "2024-12-28T23:02:41 1735426961",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42535622",
    "comments": [
      "I can imagine how this went:- We have this protocol to switch the streetlights remotely by modulating a signal on the main - but that's needing expensive hardware and it's cumbersome. Can't we just sent that over radio instead?- There is all this decentralized renewable energy generation, we need a way to switch that off remotely if there is an overload in the grid - hey, we already have that hardware for swtiching streetlamps, let's just use that!Of course encrption was never a concern and now anyone could remotely turn off / on power generation. But for that to cause real trouble, you'd need coordinated action that would require something like a state level actor.\n \nreply",
      "Saw this in person, awesome look at street lamp control and then walking that all the way up to \"oops we figured out a way to attack the European power grid\"\n \nreply"
    ],
    "link": "https://media.ccc.de/v/38c3-blinkencity-radio-controlling-street-lamps-and-power-plants",
    "first_paragraph": "\n\nFabian Br\u00e4unlein and\nLuca Melette\n\nA significant portion of Europe's renewable energy production can be remotely controlled via longwave radio. While this system is intended to stabilize the grid, it can potentially also be abused to destabilize it by remotely toggling energy loads and power plants. \nIn this talk, we will dive into radio ripple control technology, analyze the protocols in use, and discuss whether its weaknesses could potentially be leveraged to cause a blackout, or \u2013 more positively \u2013 to create a city-wide Blinkenlights-inspired art installation.\nWith three broadcasting towers and over 1.3 million receivers, the radio ripple control system by *EFR (Europ\u00e4ische Funk-Rundsteuerung) GmbH* is responsible for controlling various types of loads (street lamps, heating systems, wall boxes, \u2026) as well as multiple gigawatts of renewable power generation (solar, wind, biogas, \u2026) in Germany, Austria, Czechia, Hungary and Slovakia. \nThe used radio protocols Versacom and Semagyr, "
  },
  {
    "title": "That's not an abstraction, that's a layer of indirection (fhur.me)",
    "points": 530,
    "submitter": "fagnerbrack",
    "submit_time": "2024-12-25T05:06:58 1735103218",
    "num_comments": 212,
    "comments_url": "https://news.ycombinator.com/item?id=42506984",
    "comments": [
      "The best way to achieve a good abstraction is to recall what the word meant before computer science: namely, something closer to generalization.In computing, we emphasize the communicational (i.e. interface) aspects of our code, and, in this respect, tend to focus on an \"abstraction\"'s role in hiding information. But a good abstraction does more than simply hide detail, it generalizes particulars into a new kind of \"object\" that is easier to reason about.If you keep this in mind, you'll realize that having a lot of particulars to identify shared properties that you can abstract away is a prerequisite. The best abstractions I've seen have always come into being only after a significant amount of particularized code had already been written. It is only then that you can identify the actual common properties and patterns of use. Contrarily, abstractions that are built upfront to try and do little more than hide details or to account for potential similarities or complexity, instead of actual already existent complexity are typically far more confusing and poorly designed.\n \nreply",
      "Yes, abstraction and generalization are properties you'd rather look for the second time around. Someone was already warning about this 25 years ago [1]:You have a boring problem and hiding behind it is a much more interesting problem. So you code the more interesting problem and the one you've got is a subset of it and it falls out trivial. But of course you wrote ten times as much code as you needed to solve the problem that you actually had.Ten times code means ten times cost; the cost of writing it, the cost of documenting it, it the cost of storing it in memory, the cost of storing it on disk, the cost of compiling it, the cost of loading it, everything you do will be ten times as expensive as it needed to be. Actually worse than that because complexity increases exponentially.This person did his own CAD software from scratch in order to make custom chips [2].[1] https://www.ultratechnology.com/1xforth.htm[2] https://en.wikipedia.org/wiki/Charles_H._Moore\n \nreply",
      "Have you ever looked at how useless Chuck Moore's stuff is? Like, the chip designs are of the type \u201c384 independent Forth chips with tiny amounts of RAM and mediocre interconnects, and if you want to actually do anything with them, you'll need to use 128 of them to program your own DDR3 controller\u201d. Or, he demonstrates how awesome Forth is by showing that you can do \u201cthe guts of a disk driver\u201d in five lines, except that it's the dog-slow PIO mode.It turns out that if you can just change the problem statement, then sure, you can write very simple things. But if you have a real problem to solve (and you can't just say \u201cno, I want to solve a simpler problem\u201d), the Chuck Moore way of thinking doesn't really produce, well, good solutions. It simply doesn't scale to anything large, and not everything can be made small.https://yosefk.com/blog/my-history-with-forth-stack-machines... (2010) is a fairly interesting experience from someone on the outside trying to work in the same way. It\u2026 didn't work that well.\n \nreply",
      "I did some work with his Greenarrays chip as a student. It was very limited and awkward to use but it could also operate on absurdly low energy, with very low overhead for waking up or almost completely powering down. At some point, we had a demo running some simple signals processing code off a homemade bleach battery, and I wouldn't be surprised if you could make something work off a bunch of lemons too.This was over a decade ago (yikes) and I don't remember the exact numbers, but I do remember it used substantially less power than a comparable MSP430 microcontroller.That seems pretty useful and impressive to me, especially given it was created by a very small team with limited funding.\n \nreply",
      "IMHO that is a failed example of \"Chuck Moore's stuff\". \nHe went down a rabbit hole to an extreme level because that's what he does. \nHis earlier CPU experiments like the 4016 and Shboom were excellent examples of ultra-RISC architectures.The thing Chuck explored, related to abstraction, which I don't see much in conventional machines was reducing calling overhead. (1 cycle call and intrinsic return on many instructions ie: free return)Some of the decisions we make today have a lot to do with what happens at the hardware level when we add abstraction. It just costs more than we are prepared to pay so it is avoided ... but for the wrong reason.\n \nreply",
      "I wrote a little chess engine in Python that plays at least elo 1400 using alpha-beta search with the goal of making it simple and pedagogical,  trying to outdo Lisp.  I am thinking about making it talk XBoard,  removing the experimental stuff,  then posting it to GitHub just as a nice example.I think though if I want to get more into chess programming I'm going to switch to a faster language.\n \nreply",
      "Useless?Like the RTX2000 which landed on a comet kind of useless?Or do you mean some other kind of useless.  Maybe the controlling radio telescopes kind of useless.  That must be it.\n \nreply",
      "Harris RTX2000 is a 8Mhz machine with 16-bit data-path, paged program memory, and 1MB addressable memory. This is really an example of \"small machine\".Philae had to choose this CPU because there are very few rad-hard low-power CPUs available (and it's not even that low power by modern standarts, 5 mA/MHz), but I am sure they'd choose something bigger if they could.As for radio telescope, I am not sure which ones are you talking about, but those environments are not particularly challenging compared to spaceflight, so those run whatever hardware designers like. I am sure some of them used  to run tiny 16-bit CPUs, but I'd be surprised to hear new designs run something that old.\n \nreply",
      "> Like the RTX2000 which landed on a comet kind of useless?Yeah, in 1983 he designed a chip that was further developed by others for space usage.> Maybe the controlling radio telescopes kind of useless.Yeah, which he did in 1970.Note a pattern here? That this design paradigm holds up pretty well in a primitive computing world when things are simple and demands are low, and is thoroughly useless to keep on promoting today?\n \nreply",
      "What have you accomplished that is noteworthy or useful?We could use a point of comparison here.\n \nreply"
    ],
    "link": "https://fhur.me/posts/2024/thats-not-an-abstraction",
    "first_paragraph": "If you've ever worked on refactoring or improving performance in a software system, you've probably run into a particular frustration: abstraction-heavy codebases. What looks like neatly organized and modularized code often reveals itself as a labyrinth, with layers upon layers of indirection. The performance is sluggish, debugging is a nightmare, and your CPU seems to be spending more time running abstractions than solving the actual problem. This leads us to an important realization: not all abstractions are created equal. In fact, many are not abstractions at all\u2014they're just thin veneers, layers of indirection that add complexity without adding real value.An abstraction is only as good as its ability to hide the complexity of what lies underneath. Think of a truly great abstraction, like TCP. TCP helps us pretend that we have a reliable communication channel, even though it's built on top of an unreliable protocol, IP. It takes on the complexity of error correction, retransmission,"
  },
  {
    "title": "The Unicon Programming Language (sourceforge.net)",
    "points": 65,
    "submitter": "andsoitis",
    "submit_time": "2024-12-28T15:55:46 1735401346",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42531874",
    "comments": [
      "I stumbled upon Unicon because I installed the noweb [1] literate programming system from scratch some time ago. It uses Icon as an (optional) dependency to create cross-references during the weaving process. The fallback is based on Awk, but inferior in features. Anyway, if you have read this far, you should check out noweb and of course (Un)Icon.[1] https://github.com/nrnrnr/noweb\n \nreply",
      "Oh silly me who read unicorn language for a long time before getting it\u2026\n \nreply",
      "Some days ago I tried to install from the PPA repository, but it appears Ubuntu jammy derivatives are not supported yet. Is there a PPA update estimate?I read Python stole its generators from Icon. Being an enthusiastic user of the itertools module, was curious to see how do generators work on Unicon/Icon.\n \nreply",
      "Check out section 1.8 from this manual: http://www2.cs.uidaho.edu/~jeffery/unicon/ub.pdf#page30\n \nreply",
      "Seems pretty excellent for an old jalopy.\n \nreply",
      "Add XFT support and this language would be cool to have a fast RAD development with easy crosscompilation.\n \nreply",
      "> Add XFT support and this language would be cool to have a fast RAD development with easy crosscompilation.What is \"XFT support\" in this context?\n \nreply"
    ],
    "link": "https://btiffin.users.sourceforge.net/up/unicon.html",
    "first_paragraph": "Index\nUniconUnicon, Unified extended Icon, by Clinton Jeffery, Shamim Mohamed,\nJafar Al Gharaibeh, Ray Pereda, Robert Parlett, and team.PDF available at UniconProgramming.pdfIcon, an iconoclastic programming language. The design of Icon was led by\nDr. Ralph Griswold at the University of Arizona, starting in 1977, as a\nstructured successor to SNOBOL and refinement of SL5. Icon includes a\nrich set of datatypes and operators, generators, goal directed evaluation with\nimplicit backtracking, text scanning, integrated graphics, and other\ncomplementary very high level features.  The design facilitates powerfully\nconcise, yet surprisingly readable program source code. All with an admirable\nperformance profile.Unicon extends the feature set of Icon by adding classes, a POSIX\nlayer, networking, and a host of other modern development productivity\nenhancements. Development of Unicon is led by Clinton Jeffery.examples/introductory.icnExample run:And that is the Hello, world program for Unicon, proo"
  },
  {
    "title": "Should more of us be moving to live near friends? (architecturaldigest.com)",
    "points": 542,
    "submitter": "Geekette",
    "submit_time": "2024-12-26T09:23:08 1735204988",
    "num_comments": 400,
    "comments_url": "https://news.ycombinator.com/item?id=42514105",
    "comments": [
      "Coming from a Latin American the idea of re-starting your life across the country for college and then again for work (multiple times sometimes) while away from family and friends is very foreign.A lot of the conversation around modern American youth feeling isolated, lacking socialization and not building strong relationships seems that stem from this drive.Another thing that\u2019s really weird and related is another recurring theme in the American ethos: the cultural shame that comes with living \u201cat home\u201d or staying in the same small town for your whole life. Somehow they made it so living close to your family and friends for your 20s-30s  and maybe forever means you\u2019re a \u201closer\u201d.\n \nreply",
      "In Anglo cultures kids aren't usually moving away from home until they are at least ~18 years old. This is not a factor in teenagers feeling isolated. Suburbia and the decline of third places probably play a far greater role in this demographic.It's a common trope on here to lament on how the Anglo cultures don't value family ties strongly enough. I'd argue not overly valuing family ties has been a big competitive advantage of the Anglo cultures for centuries, eg. moving for opportunity (improved social mobility), ability to connect with outsiders, couple pairing across cultural/geographical boundaries, prerequisite to a high trust society, etc.What really needs to happen is we need to figure out ways of facilitating friend formation/maintenance in this brave new world of the internet and atheism. We are going to need some new social technologies to really combat this.One interesting recent social technology out of china https://www.scmp.com/news/people-culture/china-personalities...\n \nreply",
      "> In Anglo cultures kids aren't usually moving away from home until they are at least ~18 years old. This is not a factor in teenagers feeling isolated.But it\u2019s more than a single generation thing. If you live for 18 years in a family that has only recently put down roots in a new place, you won\u2019t have family around, unlikely to have as many family friends around, etc. Community will likely be sparse and colder.You essentially get a generational social debt put onto kids, over and over. It appears that cohesion is lost, pro-social behaviour decreases, focus on less social activity increases, and so on.\n \nreply",
      "In the American South community is as easy as picking a church and going to your kids public school sporting events.Are there problems, of course, like all societies. But it's easy and it works.\n \nreply",
      "Same thing works in Philadelphia.\n \nreply",
      "> It's a common trope on here to lament on how the Anglo cultures don't value family ties strongly enough. I'd argue not overly valuing family ties has been a big competitive advantage of the Anglo cultures for centuries, eg. moving for opportunity (improved social mobility), ability to connect with outsiders, couple pairing across cultural/geographical boundaries, prerequisite to a high trust society, etc.That line of reasoning is just plain sad. It boils down to \"everyone might be miserable, but someone else is getting rich so it's good.\"What makes it specially sad is how anglo culture's economic advantage spawns from the outcome of WW2, not this misplaced sense of sacrifice.\n \nreply",
      "\"anglo cultures\" already had quite a lead before WW2, hard to miss that the previous superpower was the British Empire. The outcome of WW2 elevated America, there's no relationship there to broader anglo culture.Quite a stretch to jump to \"everyone might be miserable\". Immigration from Latin American and other non-anglo countries is on a scale where it shapes American and British domestic politics, difficult to conclude that those immigrants are searching for the misery of anglo cultures that they can't find at home.\n \nreply",
      "> \"anglo cultures\" already had quite a lead before WW2, hard to miss that the previous superpower was the British Empire.I think you're trying too hard to muddy the waters by creating a definition for \"anglo\" that does not match reality or any use of the term.https://en.wikipedia.org/wiki/Anglo-AmericansEven within \"European Americans\", nearly half has an ethnic origin that is classified as German, not English.Another important aspect is immigration and naturalization. The bulk of high-skilled R&D specialists who turned the US into the technological powerhouse that it is aren't exactly Mayflower descendants. It's immigrants and first- and second-generation. So it's very hard to argue about \"Anglo\" thins with the extreme reliance on immigration and descendent of immigrants to play the roles that made all this progress possible.\n \nreply",
      "A few points:- German and other NW European cultures share the family atomization characteristic of Anglo-Americans- Anglo as a term stems from England. England is named for the Angles, a Scandinavian/Germanic tribe that invaded Britain a long time ago. The term Anglo-American reflects the seminal English influence on American culture.- The English and their descendant culture, America, basically invented the modern economic world and it predates WWII by a long time.The idea that WWII is why America is on top is a-historical.\n \nreply",
      "The word \"anglo\" is so fraught that I think it's probably less useful to try to argue about what it means than it would be to just leave it alone.I'm actually here to point out that the U.S. had the world's largest GDP as early as 1890, or as late as 1913, depending on your source of data and how it's estimated. So, WWII isn't the origin of that. We can now argue about whether GDP is a good indicator, but before doing that I'd ask for a better one (with historical data) to be suggested.https://en.wikipedia.org/wiki/Angus_Maddison_statistics_of_t...\n \nreply"
    ],
    "link": "https://www.architecturaldigest.com/story/should-more-of-us-be-moving-to-live-near-friends",
    "first_paragraph": "25 years ago, Toby Rush and his friend group at Kansas State University received some valuable advice from elder mentors that would shape their entire adult lives. \u201cThey gave us this thought that resonated so profoundly: Go ask any 80-year-old who\u2019s lived a good life to reflect on what really mattered, and almost every single one of them will say it\u2019s not the car, it\u2019s not the house, not where I live, the job title, or the amount of money I made,\u201d he recalls. \u201cIt\u2019s people, the relationships. Their challenge to us was to invest often and deeply over a long period of time in the treasure we\u2019re going to care the most about, and we\u2019d be the wealthiest people in the world.\u201d Today, he and his friends are all neighbors. In their enclave of the Kansas City metro area, they share a lawnmower, a pool, casual babysitting duties, a text thread for grocery borrowing dubbed \u201cWho\u2019s Got an Egg?,\u201d and effortless swaths of their lives together that would likely have been impossible if not for an intenti"
  }
]