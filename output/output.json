[
  {
    "title": "Netflix's Media Production Suite (netflixtechblog.com)",
    "points": 27,
    "submitter": "MattSayar",
    "submit_time": "2025-04-01T01:02:33 1743469353",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43541759",
    "comments": [
      "The tech is cool, but it seems like the main result of having such a pipeline is that Netflix has been able to produce an incredible amount of low-effort schlock that mostly lacks soul and artistic merit.\n \nreply",
      "Having a dozen different VFX departments using different file transfer methods like FTP seems like a nightmare. But then I realized that the banks do this, and probably worse.There's one that uses Gmail to exchange documents (not financial, but important nonetheless) and uses the read receipt to determine if it has ingested the data. Replaying ingestion is marking unread.\n \nreply",
      "The only part of that that seems crazy to me is the Gmail part. I\u2019d want to control the mail server.\n \nreply",
      "This is a sign they need deep reform and good management. Many such cases in technology these days.\n \nreply"
    ],
    "link": "https://netflixtechblog.com/globalizing-productions-with-netflixs-media-production-suite-fc3c108c0a22",
    "first_paragraph": ""
  },
  {
    "title": "Go Optimization Guide (goperf.dev)",
    "points": 134,
    "submitter": "jedeusus",
    "submit_time": "2025-03-31T20:29:58 1743452998",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=43539585",
    "comments": [
      "Every perf guide recommends to minimize allocations to reduce GC times, but if you look at pprof of a Go app, GC mark phase is what takes time, not GC sweep. GC mark always starts with known live roots (goroutine stacks, globals, etc) and traverse references from there colouring every pointer. To minimize GC time it is best to avoid _long living_ allocations. Short lived allocations, those which GC mark phase will never reach, has almost neglible effect on GC times.Allocations of any kind have an effect on triggering GC earlier, but in real apps it is almost hopeless to avoid GC, except for very carefully written programs with no dependenciesm, and if GC happens, then reducing GC mark times gives bigger bang for the buck.\n \nreply",
      "Are you including in this analysis the amount of time/resources it takes to allocate? GC isn't the only thing you want to minimize for when you're making a high performance system.\n \nreply",
      "You might wanna look at a system profiler too, pprof doesn't show everything.\n \nreply",
      "Aren't allocations themselves pretty expensive regardless of GC?\n \nreply",
      "Go allocations aren't that bad. A few years ago I benchmarked them at about 4x as expensive as a bump allocation. That is slow enough to make an arena beneficial in high allocation situations, but fast enough to not make it worth it most of the time.\n \nreply",
      "No. If you have a moving multi generational GC, allocation is literally just an increment for short lived objects.\n \nreply",
      "Additionally...- https://go101.org/optimizations/101.html- https://github.com/uber-go/guideI wish this content existed as a model context protocol (MCP) tool to connect to my IDE along w/ local LLM.After 6 months or switching between different language projects, it's challenging to remember all the important things.\n \nreply",
      "Additionally...\n- https://www.uber.com/en-AU/blog/how-we-saved-70k-cores-acros...This has saved Uber a lot of money on compute (I'm one of the devs). If your compute fleet is large and has memory to spare (stateless), performing dynamic GOGC tuning to tradeoff higher memory utilization for fewer GC events will save quite a lot of compute.\n \nreply",
      "Embedding those docs in your MCP server takes about 5 seconds with mcp-go's AddResource methodhttps://github.com/mark3labs/mcp-go/blob/main/examples/every...\n \nreply",
      "GOMEMLIMIT has saved me a number of times.  In containerized production, it's nice, because sometimes jobs are ephemeral and don't even do enough allocations to hit the memory limit, so you don't spend any time in GC.  But it's saved me the most times in CI where golangci-lint or govulncheck can't complete without running out of memory on a kind-of-large CI machine.  Set GOMEMLIMIT and it eventually completes.  (I switched to nogo, though, so at least golangci-lint isn't a problem anymore.)\n \nreply"
    ],
    "link": "https://goperf.dev/",
    "first_paragraph": "The Go App Optimization Series is a collection of technical articles aimed at helping developers write faster, more efficient Go applications. Whether you're building high-throughput APIs, microservices, or distributed systems, this series offers practical patterns, real-world use cases, and low-level performance insights to guide your optimization efforts.While Go doesn\u2019t expose as many knobs for performance tuning as languages like C++ or Rust, it still provides plenty of opportunities to make your applications significantly faster. From memory reuse and allocation control to efficient networking and concurrency patterns, Go offers a pragmatic set of tools for writing high-performance code.We focus on concrete techniques with mesurable impact you can apply immediately\u2014covering everything from core language features to advanced networking strategies.In this first article, we explore a curated set of high-impact performance patterns every Go developer should know:Each pattern is ground"
  },
  {
    "title": "JEP draft: Prepare to make final mean final (openjdk.org)",
    "points": 153,
    "submitter": "mfiguiere",
    "submit_time": "2025-03-31T19:35:51 1743449751",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=43538919",
    "comments": [
      "Hmm, not a bad approach.I think the one thing that'd be nice is if I could somehow tell the JVM from a class that this class is open for final mutation rather than needing special flags passed into the JVM or special manifests in the Jar.  It's often pretty clear to me, as a dev, what I when I need something to have final mutation (generally only with serialization objects).For example,    @FinalMutatableByReflection\n    class Foo {\n      final String bar;\n    }\n\nThat'd allow me to transition code by just adding an annotation where it needs to be while also getting the benefit that final is really final everywhere else in code that isn't working with serialization.\n \nreply",
      "They actually have a very similar proposal in the draft already:    The sun.reflect.ReflectionFactory class only supports deserialization of objects whose classes implement java.io.Serializable\n\nThat is, you'll still be able to mutate final fields using the ReflectionFactory class, as long as that class inherits from Serializable\n \nreply",
      "I know this isn\u2019t the most relevant but to see the sun namespace still exists gives me a small amount of joy\n \nreply",
      "Back in the '90s I used to consider sun.xxx the cooler version of Java.\n \nreply",
      "The issue is that many essential libraries and tools rely on setting internal final fields. I assume that's why the options around this have remained open-ended.The problem with these various \"integrity by default\" options is that, in most cases, granting access to one effectively grants access to all. For instance, JNI, agent libraries, and JPMS options can each be used to bypass restrictions, making the separation between them largely illusory. Integrity, as framed here, is ultimately binary.The unfortunate reality of the \"integrity by default\" crusade is that applications relying on libraries and tools that modify internals will continue to do so. The JDK hasn\u2019t filled any gaps\u2014it has only made an already delicate situation worse.\n \nreply",
      "Not in my experience. I run my applications with default integrity, and when i hit a problem, i find out what caused it, and fix it. Often it's just a matter of upgrading a library to a newer version which doesn't do naughty reflective things, or changing some config to stop it doing so, or changing our own code. We had a serialisation library which did deep reflection to be slightly more efficient at serialising BigDecimal; there was a system property to turn that off, so i set it. We had code doing deep reflection into JMX to get the current PID; i changed it to use ProcessHandle instead. My colleague wrote a little test data library which does some horrific things; i might delete it and adopt Instacio instead.I think there's only one case where i ended up relaxing integrity, and i'm hoping that's temporary - it will take more time to fix than i was willing to spend.\n \nreply",
      "First, it's not a \"crusade\" but the steps necessary to deliver the features Java's users demand. Second, the prevalence of the use of JDK internals has dropped drastically, and demonstrably so. For example, many programs broke before internals were encapsulated during the upgrade from 8 to 9; 99% of the causes were libraries relying on internals, which had changed. Access to internals was closed off in JDK 16, although, as you say, it can be selectively allowed. And yet, between JDK 17 and JDK 23, changes of similar magnitude to the JDK internals caused nearly no upgrade problems. Upgrading the JDK now is smoother and easier than it's been in the last two decades. Why? Because there's been a large reduction in libraries' access to internals.I think Java's handling of this transition compares very favourably to how other languages have handled similar transitions from some old model to a new one (or evolution in general) in terms of balancing the needs of both old and new projects.\n \nreply",
      "I've written my fair share of nasty reflexive code for testing or for abusing libraries, but I don't think I've ever overwritten final fields in this way. Private fields, sure. But not final.Sounds like a good evolution to me.\n \nreply",
      "I'm 100% onboard with this. My thought was how are they going to make Serialization work, but looks like they thought of that.I was trying to think of an edge case with JsonB or JAXB that would be affected by this... but generally those frameworks have told you for quite awhile not to do stupid stuff like:```\n@Getter\npublic class HelloMessage {\n  @JsonbProperty\n  private final String helloMessage;\n}\n```I can't think of any frameworks offhand that do this.\n \nreply",
      "Brian Goetz, chief architect of Java, once posted a \"what they think I do\" vs. \"what I actually\" do tweet. If I remember correctly, 25% - 50% of the \"what I actually do\" category was something like \"get angry at serialization.\"So I think it's safe to say \"what about serialization?\" is always going to be asked.\n \nreply"
    ],
    "link": "https://openjdk.org/jeps/8349536",
    "first_paragraph": "Issue warnings about uses of deep reflection to mutate final fields. The warnings aim to prepare developers for a future release that ensures integrity by default by restricting final field mutation; this makes Java programs safer and potentially faster. Application developers can avoid both current warnings and future restrictions by selectively enabling the ability to mutate final fields where essential.Java developers rely on final fields to represent immutable state. Once assigned in a constructor (for final instance fields) or in a class initializer (for static final fields), a final field cannot be reassigned; its value, whether a primitive value or a reference to an object, is immutable. The expectation that a final field cannot be reassigned in far-flung parts of the program, whether deliberately or accidentally, is often crucial when developers reason about correctness. Furthermore, many classes exist only to represent immutable state, so records were introduced in JDK 16 to p"
  },
  {
    "title": "A deliberate practice app for guitar players who want to level up (captrice.io)",
    "points": 47,
    "submitter": "adityaathalye",
    "submit_time": "2025-03-29T03:27:31 1743218851",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43512470",
    "comments": [
      "Aw man this is great timing. I\u2019m just getting back into guitar for the millionth time. I\u2019ll definitely try this out tonight\n \nreply",
      "There is something very very nice about the layout and the setup for this application. I can't quite put my finger on it but they got something right.\n \nreply",
      "It took me about 5 minutes to understand what this is doing.For anyone else confused, it doesn't listen to you play, it just logs your use of the metronome and provides tabs.IMO the app would be cooler if it was simply the metronome app on a page. And if you want to track which song you are working on, then just add the ability to label a session. Could have a different mode for people who want it over videos, but usually when I'm practicing, I know the tab and am not watching a video while I practice.\n \nreply",
      "I never quite got the setup right, but Rocksmith seemed to live up to the promise of \"guitar hero on a real guitar\".  It came out during a time when spending my free time tinkering with computers became much more important than tinkering with guitars.\n \nreply",
      "Though I haven\u2019t used this app I do plan on trying it out when I get my guitars back. I\u2019m impressed at the effort, the resources, and the giving it free for the sake of spreading joy in music.The guitar is a difficult instrument to learn, especially in the beginning phases. After 30 years it\u2019s a conversation I have frequently - people try and give up a lot. If this can help some folks stick with it and become better understanding and practiced with their instrument, I hope that happens again and again and again. Every generation needs guitarists, as it\u2019s the instrument of expressive rebellion the world round.Great share and a Bill and Ted EXCELLENT weedly weedly weee!\n \nreply",
      "This looks super cool. I love projects like this. Going to give it a try!\n \nreply",
      "Anyone have recommendations for similar Android apps?\n \nreply",
      "If you have a web browser on your android, you could try this one.\n \nreply",
      "Love it! Def going to use this.\n \nreply"
    ],
    "link": "https://www.captrice.io/",
    "first_paragraph": "\n        Practice using a smart metronome that captures metrics and\n        turns them into actionable insights; paired with an effective\n        practice method focusing on speed, endurance, accuracy, and\n        adaptability.\n      \n      Though Captrice aims for sustained progress, a 30 minutes\n      practice session is enough to see the difference in your\n      playing.\n    \n      An ergonomic metronome, easily operated using keyboard\n      shortcuts while playing guitar\n    \n      Build your repository of exercises. Organize them into\n      collections\n    \n      Embed guitar tablature and music notation in exercises for\n      quick reference\n    \n      Get access to a library of exercises covering speed-building\n      drills, finger independence exercises, warmup routines and\n      more.\n    \n      Track your progress and get actionable insights through\n      beautiful, intuitive visualizations\n    \n      Export/Import functionality to share exercises with\n      your friends, stu"
  },
  {
    "title": "Charlie Javice convicted of defrauding JPMorgan in $175M startup sale (apnews.com)",
    "points": 25,
    "submitter": "ilamont",
    "submit_time": "2025-03-28T20:55:50 1743195350",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43509733",
    "comments": [
      "Is \"under 30\" in \"the Forbes 30 under 30\" their age, or the likely upper bound of their prison sentences?\n \nreply",
      "Related discussion- https://news.ycombinator.com/item?id=35441211\n \nreply",
      "The best and the brightest.\n \nreply",
      "I think this current crop of 20-somethings learned something terrible.\n \nreply",
      "Luckily for her, pardons are on sale now.\n \nreply",
      "Bad decision.> Javice asked an \u201coutside data scientist\u201d to fabricate a list of customers when the bank asked for proof of Frank\u2019s user data, -NBCIf they had 3 million fake accounts and didn\u2019t catch the fraud, then they were in on it.It\u2019s a great deal. If the company does well, everyone wins. If it doesn\u2019t, then you already know you can claim fraud.At that point it\u2019s not fraud.\n \nreply",
      "How exactly do you think JPM would benefit from fake customers???\n \nreply",
      "Pardon inbound\n \nreply",
      "Forbes 30 Under 30!\n \nreply"
    ],
    "link": "https://apnews.com/article/charlie-javice-convicted-fraud-jp-morgan-783cb7b089f6ab5d814c4c0984f0302b",
    "first_paragraph": ""
  },
  {
    "title": "The Guardian flourishes without a paywall (nymag.com)",
    "points": 158,
    "submitter": "bookofjoe",
    "submit_time": "2025-03-29T00:31:27 1743208287",
    "num_comments": 65,
    "comments_url": "https://news.ycombinator.com/item?id=43511529",
    "comments": [
      "https://archive.ph/xBA7x",
      "I was hoping this article went deeper into the Guardian's somewhat unusual ownership model, because I find it interesting and would love to learn more.The Guardian is owned by (and I think largely funded by?) a trust that was intentionally set up in a way to ensure no commercial interest could interfere with the paper. How well it achieved that goal is, of course, debatable, but it has survived nearly a century in that form.\n \nreply",
      "Yes, The Scott Trust.You can read more about it here:https://www.theguardian.com/the-scott-trust\n \nreply",
      "Here's how this happened as I understand it.The original founder of the guardian, Taylor, ran it like a business. While today journalism struggles to make money, in the 1800s news was lucrative.In his will, Taylor carved out a sweetheart deal (right of first refusal) to sell the paper to CP Scott, a progressive Liberal politician, and also his nephew.After running the paper for many years, CP Scott's will named his two sons to inherit. Both of whom worked as editors on the daily.In a freak turn of events, both CP Scott and one of the sons died within a few months. The remaining son was concerned about paying double for the hefty inheritance tax at the time (\"death tax\").The death tax could be so large as to force a sale of the paper, to create liquidity to cover the tax. I guess it was a tax on unrealized gains!The remaining son, John, cleverly found a workaround to avoid the silly death tax: by renouncing his ownership and transferring the business to a Trust. Since he worked at the paper as editor, giving up ownership was a clever tradoff that actually gave him de facto tenure as editor, by making his day job more stable.This is all to say: the guardian became a nonprofit-like trust at a point in time it was already a stable business, with capital to self-finance.This was not a case of a independently wealthy businessman creating a foundation to create a paper from scratch (like many created universities).The Scott trust was created by journalists for journalists, at a unique point in time where journalists had money to self-finance. Motivated not by some idealistic vision but by a more practical desire to avoid a hefty tax on unrealized gains.\n \nreply",
      ">>> The Scott trust was created by journalists for journalists, at a unique point in time where journalists had money to self-financeWhere is the trust created by coders for coders at a time uniquely profitable for coders?\n \nreply",
      "Honestly things like this can also be an argument FOR crazy high death taxes.Something similar happened in a history podcast I heard about Porche, which is still owned by the original family. At one point, germany told them their tax on ownership gains is 90%. So instead, they decided they would just re-invest into the business R&D to write off the taxes instead. That gave us the invention of Porche's Racing team. source: https://www.acquired.fm/episodes/porsche-with-doug-demuro\n \nreply",
      "You can get unintended consequences from this, like forcing the increase of nepotism. If you look at South Korea, for instance, the Chaebol, despite facing some of the highest inheritance taxes in the world, still have a grip on power.How? You keep the kids in management, you encourage lots of cross holdings between corporations so that even though the kids\u2019 share falls, you enforce power through social contracts in the upper strata of classes that is horrible for shareholders and innovation as a society.That said Porsche indeed is an exceptional company in many ways in both the innovative end as well as their holdings structure.\n \nreply",
      "They exist? This is called FOSS and some outfits are even able to offer paid employment.\n \nreply",
      "One can imagine trusts devoted to open source. (They probably exist in some form.) But that probably means that modest amounts of money are distributed to a vanishingly small number of coders based on, likely, the preferences of some executive director.In general, it's fairly clear that jobs for open source developers is generally more effective than charity of various kinds which is subject to change at any time.",
      "And of course, there's always wikipedia:https://en.wikipedia.org/wiki/Scott_Trust_LimitedBozo could easily establish a similar trust to support the Wash Post in perpetuity. But clearly he has other motives.\n \nreply"
    ],
    "link": "https://nymag.com/intelligencer/article/how-the-guardian-us-flourishes-without-a-paywall.html",
    "first_paragraph": "Things you buy through our links may earn Vox Media a commission.\n              Save this article to read it later.\n              \n\n\n\n\n\n              Find this story in your account\u2019s \u2018Saved for Later\u2019 section.\n              \n\n\n\n\nThere was a time in media when having a billionaire owner was an asset. For many outlets, this is still the case, particularly those publishing super-secretive group chats of powerful government officials who seem eager to trample on the rights of the press. But for others, like the Washington Post and the Los Angeles Times, both of which have seen their benefactors bend a knee to Donald Trump and sacrifice the integrity of their newspapers in the process, ownership has become a problem. A problem that the Guardian US, the American arm of the British newspaper, has exploited.\u201cAll around us, media organizations have begun to capitulate,\u201d editor Betsy Reed writes in the current fundraising appeal at the bottom of each Guardian article. \u201cThe Guardian has neither "
  },
  {
    "title": "The demoscene as a UNESCO heritage in Sweden (goto80.com)",
    "points": 521,
    "submitter": "robin_reala",
    "submit_time": "2025-03-31T10:39:57 1743417597",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=43533362",
    "comments": [
      "It's 12 years old now, but I am still extremely impressed by this 64k intro https://geidav.wordpress.com/2013/04/14/making-of-turtles-al... and also by this 4k intro https://www.youtube.com/watch?v=_YWMGuh15nE :)And overall this website is extremely interesting with tutorials and code and great explanations https://iquilezles.org/\n \nreply",
      "Really interesting to read about this! That's wonderful validation for a vital digital culture and its heritage.As the creator of Glicol (https://glicol.org/), based in Oslo and working in the digital arts space, I'm always fascinated by how different countries foster creative technology. Sweden's approach in recognizing the demoscene this way is particularly encouraging.It makes me reflect on the pathways to support here in Norway. While academic environments can be very supportive (as my previous supervisors have been), navigating the broader public arts funding structures for newer digital art forms sometimes feels more challenging, especially perhaps for those working outside of long-established networks.Seeing Sweden's success in formally recognizing this kind of digital heritage is genuinely inspiring and offers food for thought.\n \nreply",
      "As a scener since the early 90s, I'm thrilled with these announcements. Personally, what I'd like to see come of it is an increase in the amount of academic studies of the scene at the intersection of art, technology, and anthropology. A careful study of the scene, what makes it unique, how it bleeds into other adjacent scenes (and what those are), sub-scenes, core elements of demoscene art and tech, all those things would be really interesting.They've all been written about by sceners in the past, but I think more outside observations would be enlightening. As a demoscener, you know what is scene and what isn't, and basically how it works. But I've found it nearly impossible to succinctly explain it to non-sceners without sounding like I'm crazy, or making it up, or giving them a very wrong understanding of core demo elements (e.g. \"so it's all about doing things in small sizes?\")One leg up, the scene has done a very good job archiving information about scene groups, sceners, scene productions, and sub-scene productions, giving future researchers a lot of information to start from.\n \nreply",
      "Here is the official announcement (in Swedish): https://levandekulturarv.se/forteckningen/element/demoscenen\n \nreply",
      "Hastily thrown together translation, because I thought it captured the hacker mindset so well:> A fundamental driver of the demo scene is to make a machine, such as a computer, do something it has not done before. This could mean, for example, creating a tailor-made program for a particular type of machine. Technically, it is about exploiting the capabilities of the machine in an efficient and novel way.It's sad to think that the computing devices our newer generations are growing up with are trying their best to shoot down this exact use case; making the device do things no one made it do before.Instead, everything is locked down in the name of safety, and people loosing out on the ability of just having fun by modifying devices we already own.\n \nreply",
      "I think the demoscene is what it is: a treasure, a heritage.I was/still a part of it, but essentially, every demo evolved into a video during the 90th.A shift came with the more powerful machines, especially on PC.C64, Amiga 500 - technical prowess was necessary for certain optical illusions; the video illusion stems from hacks. This reversed.I think that this is ok. Device hacking is now the new old low-code hacking.Today's demoscene is also totally meta. From fighting emulators to accepting to utilizing was quite a ride.The massively impressive demos of today on C64 or Amiga are a testament to the heritage they capitalize on. Here and there, a minor tweak or final secret was finally totally understood; differences between serial numbers of C64 were a thing, too - and that's it.I am impressed by what has been done and achieved in the early days by machine code on C64 during the 80th.Massive influence was also time. The Scandinavians find a cool thing to do during the winter months and hack for days and nights - hardly anyone would do this today.There was no harddisk, code revisioning. Compiling took time, and saving the stuff on disk was a tedious procedure during debugging. Printed Assembler code etc.Today, you can dump the most elaborate code and data on emulators within seconds, all well compiled and checked - it is a wonder. IDEs, etc., are standard.Even back then, some elite coders used cross-development platforms, such as Amiga and C64, to deal with the burden of memory and slow compile times on C64.But the thing is that you had to develop the tools yourself. An advantage of this scale was earned.Anyway, it was a fantastic time. Copy parties, puberty, trash talk - and, to be honest, a lot of doxxing and mobbing in retrospect.I am glad I was part of the scene from 1987 to 1994 and attended Venlo and other infamous Copy parties.Greetings from Beastie Boys/C64\n \nreply",
      "I don\u2019t know, real-time graphics programming is and has always been about hacks. Today it\u2019s perhaps not often hardware-level hacks, but the ethos is still \u201ccheat as much as you can, and then some more for good measure\u201d.\n \nreply",
      "Not really - graphics cards are now powerful enough to ray-trace every pixel every frame, if you are doing it with a reasonable SDF instead of a huge bag of triangles.\n \nreply",
      "Meh, real-time reflectance functions are still going to be all sorts of approximations. To say nothing about stuff like real global illumination. And SDFs are really nifty but a function that represents a complex, detailed, non-stylized/cartoony scene such as those in modern games is not going to be fast to evaluate.\n \nreply",
      "Not to mention other aspects of the overall visual experience, eg, everything about scene dynamics, object interactions, etc. A bigger compute budget is always welcome.\n \nreply"
    ],
    "link": "https://www.goto80.com/the-demoscene-as-a-unesco-heritage-in-sweden",
    "first_paragraph": "Mar 31, 2025 | ramblingsThe demoscene has become a national UNESCO-heritage in Sweden, thanks to an application that Ziphoid and me did last year. This has already happened in several European countries, as part of the international Art of Coding initiative to make the demoscene a global UNESCO heritage. I think this makes plenty of sense, since the demoscene is arguably\u00a0the oldest creative digital subculture around. It has largely stuck to its own values and traditions throughout the world\u2019s technological and economical shifts, and that sort of consistency is quite unusual in the digital world.The main idea of the demoscene is to compete with productions that maximize a certain hardware, but that\u2019s not what all demosceners like to do. My demogroup Hack n\u2019 Trade for example, cares more about making weird stuff, and there are plenty of other groups like that. Some demosceners don\u2019t release anything at all, but might do important work to keep the scene alive (BBS-trading, organizing part"
  },
  {
    "title": "Notes on the Pentium's microcode circuitry (righto.com)",
    "points": 108,
    "submitter": "leotravis10",
    "submit_time": "2025-03-31T18:35:37 1743446137",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=43538192",
    "comments": [
      "I'm surprised the microcode ROM and format hasn't been dumped already. Is anyone working on this?EDIT: The later Atom processors were dumped, are there any similarities?[1] https://x.com/_markel___/status/1262697756805795841[2] https://github.com/chip-red-pill/glm-ucodeEDIT 2: Some Pentium Pro disassembly work: https://pbx.sh/pentiumii-part2/\n \nreply",
      "There are some people working on the 386 microcode. Dumping the Pentium microcode ROM from the die photos would be straightforward (but tedious). The hard part is to figure out what all the bits mean.\n \nreply",
      "Any ideas if the mask ROM is scrambled? Apparently the P6 doesn't have a direct mask ROM : microcode relationship.https://github.com/peterbjornx/p6tools\n \nreply",
      "The Pentium's ROM appears to be slightly scrambled (see footnote 6 in my article). ROMs are often a bit permuted for electrical reasons. For example, instead of columns ordered ABABABAB..., they will be ordered ABBAABBA... and then the A and B select lines can be shared by two columns. But the columns in the Pentium appear to be permuted in an irregular way. I'm not sure if this was for obfuscation or if automated layout software decided this was better.\n \nreply",
      "I'm curious if the register you see near the microcode ROM is potentially hooked up to MSRs -- it could potentially be a read or write buffer.https://www.cs.cmu.edu/~ralf/papers/highmsr.html> To the left of the MAR is a 32-bit register that is apparently unrelated to the microcode ROM, although I haven't determined its function.\n \nreply",
      "That register could be a Model-Specific Register; I haven't looked at it closely enough to see what it does. The Pentium is very complicated with 3.1 million transistors, so my reverse-engineering of it is essentially bits and pieces here and there.\n \nreply",
      "Author here for your Pentium questions :-)\n \nreply",
      "Hi Ken,Nice article. While reading I remembered that I watched some time ago the Oral History of Gary Davidian and he was quite bit involved with microcoding. And if I were you I would try asking him if he could be able to give you some ideas where to get more information about microcode workings and development.Here are links to that interview, if you have time to watch it. It's in two parts.- https://www.youtube.com/watch?v=l_Go9D1kLNU- https://www.youtube.com/watch?v=MVEKt_H3FsICheers,:-) riku\n \nreply",
      "This is the Gary Davidian of the Classic MacOS PPC nanokernel, no? I wish I've had as much fun work as he's had in his career.\n \nreply",
      "> If you have enough time, you can extract the bits from the ROM by examining the silicon and seeing where transistors are present.I'm curious if this is a better way than somehow scanning the ROM electronically? Asking based on my very shallow understanding of how ROM works in this situation, although I did read the bit about M1, M2, and M3 lines/contacts.[edit: I also read about the testing circuitry, that \"runs through each address,\" but it's unclear if this is an auto feature running without being asked at startup, or if there is some way to tap into / intercept this functionality from outside.]\n \nreply"
    ],
    "link": "https://www.righto.com/2025/03/pentium-microcde-rom-circuitry.html",
    "first_paragraph": ""
  },
  {
    "title": "MLB says Yankees\u2019 new \u201ctorpedo bats\u201d are legal and likely coming (thelibertyline.com)",
    "points": 205,
    "submitter": "cf100clunk",
    "submit_time": "2025-03-31T15:27:03 1743434823",
    "num_comments": 316,
    "comments_url": "https://news.ycombinator.com/item?id=43536146",
    "comments": [
      "I think it's quite cool (disclaimer: I am indeed a dirty Yankees fan)Hitting is really hard. If you feel up to it, and can find a public batting cage near you that has a fast pitch machine (usually maxes out 75-85mph which is 20+ mph less than your typical MLB fastball), give it a shot. When you hit the ball away from the sweet spot, especially on the parts closer to your hands, it really freaking hurts and throws off subsequent swings.If the few players who are using this bat tend to hit that spot naturally, it makes a lot of sense to modify the bat to accommodate it, within the rules like they've done here. Hitting is super, super difficult especially today with how far we're pushing pitchers. Love seeing them try to innovate.Plus, reminder, most of the team isn't using it. Judge clobbered the ball that day with his normal bat. Brewer's pitching is injured, and the starter that day was a Yankee last year and the team is intimately familiar with his game.\n \nreply",
      "I play golf. I write about golf. I genuinely love golf. Over the last 50 years, we have slowly broken the game of golf by allowing incremental technological advancements -- just like this -- that make it easier to do something that is hard, that is making it easier to hit the sweet spot.I am sending a grave warning to baseball fans here from the future that you will arrive at by following this road.Golf used to be a finesse game with moments of power. Now everyone is swinging out of their shoes on every shot, and the strategy of the game has reached Nash equilibrium where you basically want to hit the ball as hard as you can at every opportunity, despite any strategic element on the course.Professional baseball is always what I point to when I talk about what we've lost. You don't need the most optimized equipment to enjoy the game, in fact, ultimately, you don't even want it. Just use simply, standardized equipment, accept the limitations of that equipment, and enjoy a simple game, where strategy can be used to overcome the limitations of equipment. The best thing that the MLB ever did was reject aluminum bats.\n \nreply",
      "Don\u2019t you already want to hit the baseball as hard as you can at every opportunity?  Just with the caveat that you need to develop skill with using a one-size-fits-all bat?  Is bunting and going for balls that big of a deal currently, that a player who could rock one into left field would decide not to?Surely any strategy around loading up bases to stack the deck for your strongest hitter remains, it seems like this levels between hitters more than from hitter to pitcher?\n \nreply",
      "There\u2019s some consensus though that currently, pitching has evolved much faster than batting due to advances like Trackman and deeper understanding of the relationship between biomechanics, pitch tunneling, spinrate/flight path/movement, and so on. In conjunction with that has been a shift towards \u201cTTO\u201d (three true outcomes - HR/BB/K) on the offensive side, which is a statistically motivated perspective that batting for average is suboptimal. In short, you would rather have a lower BA and a higher home run rate even if it means a higher K rate, since home runs (and 2Bs) are so significantly more valuable than singles, and fly outs are also much more valuable than ground outs (or really, less bad) due to the opportunities for sac flies and the risk of double plays. TTO tho is also partly a response to the elevated pitching capabilities - velocity and spin.This is all just to say that batters are falling behind and there\u2019s an argument that it hurts the on-field product from an entertainment perspective since balls in play are what we ultimately watch for - if torpedo bats make it more likely that players can bat for higher averages by barreling up the ball more consistently, it will be good for the game.Other alternative proposals include lowering the mound (famously done in the 60s), adjusting the ball (eg lower seams, which makes it harder for pitchers to generate spin and makes the same spin rates less effective), and so on.One good (bad?) thing is that to some extent pitchers are starting to reach a biomechanical wall, evidenced by the greatly increased rates of Tommy John surgery, though that is partly also an effect of better surgical techniques and recovery times.Point is - it\u2019s complicated.\n \nreply",
      "I don't disagree with any of this, I'm just saying that we know where this goes. It's just an arms races if you let it become one. If the pitching is getting too good, make it harder to pitch.>In short, you would rather have a lower BA and a higher home run rate even if it means a higher K rate, since home runs (and 2Bs) are so significantly more valuable than singles, and fly outs are also much more valuable than ground outs (or really, less bad) due to the opportunities for sac flies and the risk of double plays.Again, I see this as the tail wagging the dog. It's easy to point to home runs as entertaining, but they a ultimately rather boring. For die hard fans, you want more hits that end up in play, with more strategy, and more opportunity for mistakes and drama. You're not going to get that from home run derbies.Again, I know it's complicated, but ultimately, most sports organizations face an extremely complicated paradigm. It's fun to follow complicated sports where anything can happen, but it's hard to follow the same sports if you're not already into them. The way you solve this is to make the sports incredibly accessible so people visit games easily and cheaply as entertainment. The American sports system doesn't allow this because there is no relegation system, and so the fan bases are too large to allow the game to be accessible to most people. You end up making decisions that make television more watchable, and by making things \"important\" by \"breaking records.\" This ultimately dilutes the game because it makes breaking records less relevant over time.We've got to the point in golf where someone setting an all time PGA scoring record is basically a yawn-fest, because everyone knows they're not playing the same game.\n \nreply",
      ">The American sports system doesn't allow this because there is no relegation systemA few years ago a friend of mine from the UK made the observation that American Football would benefit greatly from a relegation system... every season I have the same reaction. By about the 4th week of the season, the NFL bifurcates into legitimate contenders and everybody else. You end up with Thursday nights and late season games that nobody gives a shit about because it's gonna be a blowout. For that matter - the last 2-3 weeks of the season the playoffs are already set, so half the league has no reason to even play - and the quality of the product on the field matches this. Some kind of two-tier system would go a long way to fix this, and might also help with the larger problem of the bridge between the college and pro games. At the moment, the NFL is maybe the only league that doesn't really have a \"minor league\" or development league - its the colleges, and between NIL and the portal system, colleges aren't necessarily producing pro-ready players.\n \nreply",
      "They're never going to change this, it's the reason NFL franchises have such massively inflated valuations. Same w/ basketball + IPL franchises, very little downside risk to the earning power of the franchise.\n \nreply",
      "There\u2019s 17 games\u2026 not 170.Any given Sunday.\n \nreply",
      "Yes, and the league produced a better product when it was 14 and 16 games a season - week 17 is painful to watch.\n \nreply",
      "There\u2019s minor leagues all over the USA.  It\u2019s pretty cheap to go to a baseball game if it\u2019s not MLB.  And even MLB if your not picky on where you sit and the game time\n \nreply"
    ],
    "link": "https://thelibertyline.com/2025/03/30/yankees-new-torpedo-bat/",
    "first_paragraph": "You score 20 runs, hit 9 bombs, and people start asking questions. That\u2019s exactly what happened to the Yankees on Saturday after they revealed the \u201ctorpedo bat\u201d during their demolition of the Milwaukee Brewers. Yes, the Yankees have a literal genius MIT Physicist, Lenny (who is the man), on payroll. He invented the \u201cTorpedo\u201d barrel. It brings more wood \u2013 and mass \u2013 to where you most often make contact as a hitter. The idea is to increase the number of \u201cbarrels\u201d and decrease misses. pic.twitter.com/CsC1wkAM9GAnthony Volpe and Jazz Chisholm Jr. used it. Both went deep. The bat is thicker in the area where they make the most contact, basically moving the \u201csweet spot\u201d lower than the typical barrel. Think more mass where it matters. Less guessing, more barreled-up baseballs.I\u2019m not sure if I like where this is going.Remember when kids started coming to the local baseball field with those big-barreled whiffle ball bats instead of your classic yellow ones?I\u2019m not sure making a custom bat with"
  },
  {
    "title": "Honey has now lost 4M Chrome users after shady tactics were revealed (9to5google.com)",
    "points": 418,
    "submitter": "tantalor",
    "submit_time": "2025-03-31T18:28:03 1743445683",
    "num_comments": 215,
    "comments_url": "https://news.ycombinator.com/item?id=43538113",
    "comments": [
      "Related. Others?PayPal Honey extension has again \"featured\" flag in Chrome web store - https://news.ycombinator.com/item?id=43298054 - March 2025 (177 comments)LegalEagle is suing Honey [video] - https://news.ycombinator.com/item?id=42581108 - Jan 2025 (10 comments)uBlock Origin GPL code being stolen by team behind Honey browser extension - https://news.ycombinator.com/item?id=42576443 - Jan 2025 (444 comments)Show HN: Open-source and transparent alternative to Honey - https://news.ycombinator.com/item?id=42535274 - Dec 2024 (10 comments)Exposing the Honey Influencer Scam [video] - https://news.ycombinator.com/item?id=42483500 - Dec 2024 (86 comments)Amazon says browser extension Honey is a security risk, now that PayPal owns it - https://news.ycombinator.com/item?id=22016031 - Jan 2020 (6 comments)\n \nreply",
      "Have a friend high up at one of the \u201cBig 3\u201d in this space.The entire business model is predicated on injecting themselves as the last click for attribution even when they weren\u2019t remotely responsible for the conversion. Cool business, but can\u2019t keep going on forever without someone catching on.\n \nreply",
      "I remember when this was called cookie stuffing, and eBay even sent a guy to jail for doing it with their affiliate program. That\u2019s the same eBay that owned PayPal, which now owns Honey\u2026\n \nreply",
      "It's totally different you see. This time the fraud was done by a faceless corporation maximizing shareholder returns so this is just an exercise in free speech by an immortal, in the same vein as running an unlicensed lottery.\n \nreply",
      "Kind of like how most spyware is now called \u201cemployee monitoring tools\u201d. This stuff used to be frowned upon but now I guess the narrative has changed.\n \nreply",
      "Considering eBay also had management that harassed people by mailing them live spiders and dead pig fetuses... https://www.nbcnews.com/news/us-news/ebay-pay-3-million-empl...\n \nreply",
      "Wow, the former Senior Director of Safety and Security was sent to prison for 57 months! That's some great work by eBay.https://www.justice.gov/usao-ma/pr/final-defendant-ebay-cybe...\n \nreply",
      "Interesting, I found an article about it: https://www.businessinsider.com/shawn-hogan-sentenced-in-eba...\n \nreply",
      "Yeah he was also the owner of DigitalPoint if anyone remembers that forum and era.\n \nreply",
      "Now they can just avoid paying for affiliate links for anyone who has honey installed\n \nreply"
    ],
    "link": "https://9to5google.com/2025/03/31/honey-extension-users-dropped-chrome-march-2025/",
    "first_paragraph": "Late last year the popular Chrome extension Honey (owned by PayPal) was revealed for employing a few shady tactics, and the extension has since lost around 4 million users on Google\u2019s browser alone.To recap the situation thus far, Honey has amassed millions of users over the past several years on the promise of finding coupon codes for various online stores. The free extension saw wide advertisements and was eventually purchased by PayPal in 2020 for $4 billion.In December 2024, a video on YouTube by the channel MegaLag exposed Honey for two shady practices. The first was how the extension took advantage of affiliate codes. Honey has always used affiliate programs to subsidize its service, but the video revealed that the extension would hijack these programs \u2013 removing affiliate codes from other refferers such as online creators and website \u2013 even if it didn\u2019t have coupon codes or cash back to offer in return. The practice was working behind the scenes with businesses to control which "
  },
  {
    "title": "Launch HN: Augento (YC W25) \u2013 Fine-tune your agents with reinforcement learning",
    "points": 62,
    "submitter": "lmeierhoefer",
    "submit_time": "2025-03-31T17:29:04 1743442144",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43537505",
    "comments": [
      "I tell you what I don't like, the game y'all are playing with billing of Slack users:  Where do you want to access #ext-customers?\n    The organization you select is where you\u2019ll find this channel in Slack. Admins will get a chance to review everything before you start collaborating.\n    Tip: Add this Slack Connect channel to the organization that\u2019s already connected with P2P Industries, or where you have similar channels.\n \nreply",
      "I'm confused - what's this?\n \nreply",
      "I want to make sure I am understanding this.If I have an application that uses OpenAI models then this service can act as a proxy between the my application and the actual OpenAI service. It logs all of the requests that get sent to the OpenAI api. At some later time, I can go through and choose a subset of the API calls and mark them (I'm guessing as good or bad) and these get converted into a training set. I then have to create a value function as its own API that I run on my own servers somewhere (like fly.io). Then I start a training run, which I assume will use some open source AI model to regenerate responses to the training set derived from my initial OpenAI api calls. It then takes the generated responses from that open source model, sends them to my value function api which scores them, and then uses that score to apply some RL magic to the base open source model. At the end of this process I have an open source model that has been RL trained based on the captured api calls as well as the scoring from the value function.I suppose the argument here is, a RL trained open source model will perform your task better than the base OpenAI model. So your target market is, people already using OpenAI api, they have the desire and funds to experiment with RL, they have the capability of defining a value function, they are able to sift through their api calls to identify the ones that aren't performing well and isolate them, and they are willing to swap out their OpenAI model with an open source model that is RL trained if it can be shown it is more accurate.I would guess this market exists and the need is real. Defining a value function is much easier than building the infrastructure to RL a variety of open source models. So someone who wants to do this may appreciate paying for someone else who has already set up the infrastructure. And they don't want to host their own model (their already paying for OpenAI model hosting) so maybe they have no problem paying you for inference as well.Whether or not this succeeds as a business really depends on how effective RL is for the clients you find. There are two paths here, RL is wildly successful and therefore so are you. Or RL fine-tuning is unable to keep up with foundation model advancements and clients will learn it is better to wait it out on the big fellas rather than go through the time-consuming and costly process.\n \nreply",
      "Wow! Thanks for taking the time to think through it. Yes, you are exactly right! I couldn\u2019t have described Augento better than this myself. We actually want to make writing a reward function completely optional and build some RLHF (Reinforcement Learning from Human Feedback) loop soon. One of our long-term goals is to bring the cost of RL down so the barrier of entry to fine-tuning big models is not as high as it currently is.\n \nreply",
      "I agree with you that the market exists and, as a result, solutions to this problem also exist in abundance. The most difficult part about a building a product like the one presented here is making something super generic that works for a wide swath of use cases. If you simplify the stack to more bespoke/custom approach, the build burden decreases exponentially.For the folks who are already technical in this vertical, especially ones that leverage a low cardinality architecture (one or two models, small subset of tasks, etc), this type of thing is quite easy to build yourself first as a working prototype and then only slightly more difficult to productionize & automate.I have some in-house infra that does similar work: monitors inputs and outputs from models, puts them in a UI for a human to score/rank, preps a DPO dataset for training, kicks off training run. The total amount of calendar time I spent from prototype to production was roughly two person weeks. Changing the human intervention mechanism to an automated reward function would be an hour or two worth of work. If I had to make this work for all types of users, tasks, and models \u2014 no shot I'd have the time personally to pull that off with any reasonable velocity.With that said, having a nice UI with great observability into the whole process is a pretty big value-add to get out of the box as well.(EDIT: for clarity, not affiliated all with the OP project/org)\n \nreply",
      "This looks great.I have a few questions. 1. I'm assuming by the pricing it's \"serverless\" inference, what's the cold-start time like? 2. Any idea on inference costs?Also just to reiterate what others say but the option of exporting weights would definitely make it more appealing (although it sounds like that's in the roadmap).\n \nreply",
      "This is a good problem to solve for. But making this closed source makes it a bad choice for us to use.And the other aspect as someone already specified is it seems to only work with single agent workflows.\n \nreply",
      "We could open-source (parts of) our platform. What specifically would you like to see open-sourced?\nWe thought about developing this into a piece of software you can run in your own cloud (for compliance and security) but at the moment this makes the GPU economics really difficult and would probably be only interesting/relevant to big enterprises.\nAnyway, we're definitely curious to hear if anyone has interesting applications for an open-source version of Augento!\n \nreply",
      "Why does it being open-source matter for this particular use case?\n \nreply",
      "Also I think if I'd use your product, I'd like to be able to host the model elsewhere in case I don't like the platform anymore :)\n \nreply"
    ],
    "link": "item?id=43537505",
    "first_paragraph": ""
  },
  {
    "title": "Turso SQLite Offline Sync Public Beta (turso.tech)",
    "points": 164,
    "submitter": "charlieirish",
    "submit_time": "2025-03-31T15:10:39 1743433839",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=43535943",
    "comments": [
      "It'd be nice if the post went into how conflict resolution will (?) work because that's the hard part here and the main selling point imo.\n \nreply",
      "A lot of offline sync projects just drop data on conflict and pretend it didn't happen. It's the salesman job to divert your questions about it.I found another blogpost from turso where they say they offer 3 options on conflict: drop it, rebase it (and hope for no conflict?) and \"handle it yourself\".Writing an offline sync isn't hard. Dealing with conflicts is a PITA.https://turso.tech/blog/introducing-offline-writes-for-turso...\n \nreply",
      "Conflict resolution can't work in a general sense.How you reconcile many copies of the same record could depend on time of action, server location, authority level of the user, causality between certain business events, enabled account features, prior phase of the moon, etc.Whether or not offline sync can even work is very much a domain specific concern. You need to talk to the business about the pros & cons first. For example, they might not like the semantics regarding merchant terminals and offline processing. I can already hear the \"what if the terminal never comes back online?\" afternoon meeting arising out of that one.\n \nreply",
      "I would say this is why server-authoritative systems that allow for custom logic in the backend for conflict resolution work well in practice (like Replicache, PowerSync and Zero - custom mutators coming in beta for the latter). Predefined deterministic distributed conflict resolution such as CRDT data structures work well for certain use cases like text editing, but many other use cases require deeper customizability based on various factors like you said.\n \nreply",
      "Server-authoritative conflict resolution kind of mirrors my thinking as well, having resolution work like multiplayer net code, where the client and server may or may not attempt to resolve recent conflicts, but server has the final say on state. Just not sure how this plays out when a client starts dropping conflicting data because the server says so...\n \nreply",
      "Yes, exactly. https://www.gabrielgambetta.com/client-side-prediction-serve...\n \nreply",
      "CRDT falls flat for rich text editing though. So many nasty edge cases and nobody has solved them all, despite their claims.\n \nreply",
      "have you tried loro\n \nreply",
      "https://loro.dev/\n \nreply",
      "CFRDT (Conflict Free Replicated Data Types) can absolutely reconcile many-writers situations. There are a number of these systems, and they all have their own rules around that replication (sometimes very complicated rules that are hard to reason about). As long as you can live inside those rules, and accept that they are going to have sharp corners that don't quite make sense for your use case, then you can get a virtually free lunch there.But living inside of those rules (and sometimes just understanding those rules) can be a big ask in some situations, so you have to know what you are doing.\n \nreply"
    ],
    "link": "https://turso.tech/blog/turso-offline-sync-public-beta",
    "first_paragraph": "Mar 31, 2025We're excited to announce that Turso Offline Sync is now available in public beta!Your applications can continue functioning seamlessly, even when disconnected from the internet. Local database operations can proceed normally, with automatic sync occurring once connectivity is restored.Historically, SQLite has been a database that excels at running local, embedded databases, because the database is just a file. For mobile devices, this means on-device databases.Turso takes advantage of this with Embedded Replicas \u2014 your local embedded databases, on-device or server can now be kept in sync with your Turso Cloud database, and any changes are propagated to all replicas.Until today, our sync was unidirectional: while you can always read from the database, even if offline, writes happen directly to the Cloud, and are propagated later.This has two consequences:With today's announcement, the local database will be able to accept writes that are as fast as a file, work offline, and"
  },
  {
    "title": "KOReader: Open-Source eBook Reader (github.com/koreader)",
    "points": 51,
    "submitter": "charleshan",
    "submit_time": "2025-03-31T19:52:29 1743450749",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43539103",
    "comments": [
      "KOReader is an amazing program that has progressed at amazing speed over the past few years, particularly when it comes to the user interface. (It can still be overwhelming, because of the sheer number of features, but it is much better organized.)To give you an idea of how different it is from commercial products: it actually tracks reading in a useful way. It shows a chart of how long you have spent on each page, so you can figure out which parts of a book you have not yet read. That is really useful when jumping around technical books. If you are interested in tracking your general reading habits, there are handy views that shows which books you have read and when you read them (either by time of day or across a month).As for reading PDFs, well, eInk has its limitations and KOReader does it's best to work around them. If you want to read a multicolumn paper on a small screen, you can configure it to go down one column then right back to the top of the next column. If you want there to be overlap between the screens when panning, you can configure that. You can also have it display which parts were overlapping, so you don't get lost when it displays the next part.There is tonnes of other stuff in there. I just mentioned those two because I use them the most. Overall I would say it feels like KOReader was designed by people who want an amazing reading experience, rather than by people trying to sell novels.\n \nreply",
      "Got this on my Kindle after the jailbreak came out in January. It's fantastic, especially the OPDB index + self hosted calibre-web means I can just download an epub on any device, drop it on a webpage, then search it on KOReader immediately. I did not want to use USB or Amazon's plumbing to transfer, so this is great. Tons of customization over the built-in reader.\n \nreply",
      "I am looking forward to the macOS release. I use it on my Supernote, Inkpalm 5 and my kids Kindle.Koreader is wonky in places. But, like vi and bash, you get used to the wonkiness and it works well enough for the job and is everywhere.\n \nreply",
      "Almost as worthy as a non-YC-backed-YC-backed piece of shit startup that defrauded PayPal and everyone else for years. Suck a dick if you didn\u2019t already subscribe to ChatGPT Pro cuz you have been marked for AIDS, I will lick Honey off your inner loins while retards like MKUltra fuckin suck a dick for crack live 100#\n \nreply",
      "KOReader is the best ereader.\n \nreply",
      "And it works on Android too. Even for devices that aren't e-ink, I prefer KOReader to anything else.\n \nreply",
      "I used this for many years on a rooted Kobo. It was great. being able to curate my own rss feeds and have them auto fetched over wifi from calibre to the e-reader, no algorithm involved, was a glimpse at how things could have been.\n \nreply",
      "Pretty keen to try one day, a quick question for anyone who has installed it is what does it do to the battery life of the device its installed on?is it the same, better or worse and by how much?\n \nreply",
      "What device? I haven\u2019t noticed an issue on android devices. On my rooted kindle it is a bit less battery but I haven\u2019t measured it.\n \nreply"
    ],
    "link": "https://github.com/koreader/koreader",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An ebook reader application supporting PDF, DjVu, EPUB, FB2 and many more formats, running on Cervantes, Kindle, Kobo, PocketBook and Android devices\n      \n\n\n\n\n\nDownload \u2022\nUser guide \u2022\nWiki \u2022\nDeveloper docsportable: runs on embedded devices (Cervantes, Kindle, Kobo, PocketBook, reMarkable), Android and Linux computers. Developers can run a KOReader emulator in Linux and MacOS.multi-format documents: supports fixed page formats (PDF, DjVu, CBT, CBZ) and reflowable e-book formats (EPUB, FB2, Mobi, DOC, RTF, HTML, CHM, TXT). Scanned PDF/DjVu documents can also be reflowed with the built-in K2pdfopt library. ZIP files are also supported for some formats.full-featured reading: multi-lingual user interface with a highly customizable reader view and many typesetting options. You can set arbitrary page margins, override line spacing and ch"
  },
  {
    "title": "LLM Workflows then Agents: Getting Started with Apache Airflow (github.com/astronomer)",
    "points": 68,
    "submitter": "alittletooraph2",
    "submit_time": "2025-03-31T18:32:28 1743445948",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=43538164",
    "comments": [
      "this is really cool!That said, my impression is that Airflow is a really dated choice for a greenfield project. There isn't a clear successor though. I looked into this recently, and was quickly overwhelmed by Prefect, Dagster, Temporal, and even newer ones like Hatchet and HamiltonMost of these frameworks now have docs / plugins / sister libraries geared around AI agentsIt would be really helpful to read a good technical blog doing a landscape of design patterns in these different approaches, and thoughts on how to fit things together well into a pipeline given various quirks of LLMs (e.g. nondeterminism).This page is a good start, even if it is written as an airflow-specific how-to!\n \nreply",
      "Dated doesn\u2019t mean bad (usually the opposite in my experience!) What issues do you have with Airflow?\n \nreply",
      "Here's my problems with MWAA (amazon hosted airflow.) I have about 100 dags which maxes out the scheduler thread. Airflow parses all the files every minute so it's always parsing around 94% cpu. I could run a second scheduler thread if I coordinate with my SRE team and get the terraform deployed...it's really tedious.Related possibly, my dags get kill -9 for no apparent reason. The RAM usage is not that high, maybe 2gb out of 8gb system RAM in use. No reason is given in the logs.I am trying to switch to dagster, not because it's awesome, but because it hasn't crashed randomly on me.\n \nreply",
      "This space is honestly a mess. I did an in depth survey around 1.5 yrs ago and my eventual conclusion was just to build with airflow.You either get simplicity with the caveate that your systems need to perfectly align.Or you get complexity but will work with basically anything (airflow).\n \nreply",
      "Would be interested to know what drawbacks you found with Dagster or Prefect.\n \nreply",
      "Truthfully have been a little skeptical of how many workloads will actually need \u201cagents\u201d vs doing something totally deterministic with a little LLM augmentation. Seems like I\u2019m not the only one that thinks the latter works a lot of the time!\n \nreply",
      "I'm looking into using LLM calls inside SQL Triggers to make agents / 'agentic' workflows. Having LLM powered workflows can get you powerful results and are basically the equivalent of 'spinning up' an agent.\n \nreply",
      "Know of any online examples of the same?\n \nreply",
      "This is about workflows that use AI, but it lead me to actually think of the inverse - has anyone experimented with AI agents defining and iterating upon long-running workflows?\n \nreply",
      "Extremely bearish on existing tools solving agentic workflows well. If anyone, it will be temporal. Airflow and the like simply were not designed for high dynamic execution, and so have all sorts of annoyances that will make them lose.\n \nreply"
    ],
    "link": "https://github.com/astronomer/airflow-ai-sdk",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An SDK for working with LLMs and AI Agents from Apache Airflow, based on Pydantic AI\n      This repository contains an SDK for working with LLMs from Apache Airflow, based on Pydantic AI. It allows users to call LLMs and orchestrate agent calls directly within their Airflow pipelines using decorator-based tasks. The SDK leverages the familiar Airflow @task syntax with extensions like @task.llm, @task.llm_branch, and @task.agent.To get started, check out the examples repository here, which offers a full local Airflow instance with the AI SDK installed and 5 example pipelines. To run this locally, run:If you don't have the Astro CLI installed, run brew install astro (or see other options here).If you already have Airflow running, you can also install the package with any optional dependencies you need:Note that installing the package "
  },
  {
    "title": "The <select> element can now be customized with CSS (chrome.com)",
    "points": 352,
    "submitter": "tosh",
    "submit_time": "2025-03-31T09:11:47 1743412307",
    "num_comments": 139,
    "comments_url": "https://news.ycombinator.com/item?id=43532830",
    "comments": [
      "The fact that I'm disproportionally excited about this probably dates me as an early 2000s web developer. But since selects can do things that you simply cannot recreate in HTML, e.g. have options drop downs that extend outside the viewport boundaries, makes this a really helpful feature.Now, do autocompletes and tag selectors next...\n \nreply",
      "I doubt it'll still be able to do those things. From the article:>Using base-select loses a number of features and behaviors:>    The <select> doesn't render outside the browser pane.>    It doesn't trigger built-in mobile operating system components.I have mixed feelings about it. Mobile users, get ready for poorly optimized select elements. On the other hand it reduces the need for javascript for styling forms, which is good\n \nreply",
      "> The <select> doesn't render outside the browser pane. ... It doesn't trigger built-in mobile operating system components.To me, this is intrinsically what makes a <select> a <select>. Styling is great, but without these features, this doesn't really bring anything new to the table\n \nreply",
      "Thanks to humanity, supporting this is a surefire ticket to someone figuring out how to phish credentials through a <select> element.\n \nreply",
      "For the record, there's already a bunch of custom select-a-like replacement elements out there; I'm partial to select2. The main reason for this is that selects don't come with what we used to call \"combobox\" features; there's no type-ahead completion, and you can't lazy-load options from a larger data source because of that.My main gripe is the loss of rendering outside the browser pane. To be clear, we already don't have that on mobile at all; if you've ever used an iPad with Stage Manager you'll note how popovers - all of them, including native apps - are neatly conformed to the bounds of the containing window. Pop-over menus are supposed to break the window pane, but they don't, for reasons I don't quite understand but can guess rhyme with the word \"security\".\n \nreply",
      "\"It doesn't trigger built-in mobile operating system components.\" Is that part of the spec? I can see Apple deviating from that implementation.\n \nreply",
      "I'm not sure about this. It could break the positioning / sizing / box CSS properties.That would require rendering arbitrary HTML in the native widget, outside the browser. And I think that would require putting WebKit in the native widget. Or, to maintain a \"copy\" of the widget that looks like the native one but uses WebKit to render things. Seems annoying to maintain.(And there are the security concerns mentioned by the other comments)\n \nreply",
      "Mobile users are the majority of users by far. Do web designers really make their sites hostile to most of their users? (I suspect the answer is yes)\n \nreply",
      "That's fair, but I assume that is the initial implementation. Surely, over time, browser vendors will want to make the full spectrum of select functionality available consistently.\n \nreply",
      "I don't think browsers will ever let web code affect things outside the viewport because scammers would cook up some truly zany things with that power.\n \nreply"
    ],
    "link": "https://developer.chrome.com/blog/a-customizable-select",
    "first_paragraph": "\n\n\n\n\n \n            Adam Argyle\n          \n\n\n\nX\n\n\n\n\nGitHub\n\n\n\n\nGlitch\n\n\n\n\nHomepage\n\n\n\n\n\n\n\n\n\n  Published: March 24, 2025\n\n\n  Published: March 24, 2025\nFrom Chrome 135, web developers and designers can finally unite on an accessible, standardized and CSS styleable <select> element on the web. This has been many years in the making, many hours of engineering and collaborative specification work, and the result is an incredibly rich and powerful component that won't break in older browsers.Here's a video of customized selects using these new features:If you've been following along closely, you'll notice a few spec names and features have changed since Una's request for community feedback. Luckily, if you worked from that post and are interested in what's changed, Una's also got you covered.There's also shiny new documentation on MDN for customizable select, packed with details.A new CSS property appearance: base-select that puts the <select> element into a new, configurable and styleable st"
  },
  {
    "title": "Show HN: I made a little puzzle game about a rogue chess knight (rakhim.org)",
    "points": 81,
    "submitter": "freetonik",
    "submit_time": "2025-03-29T14:02:53 1743256973",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=43515622",
    "comments": [
      "Very nice. I think it would be more fun/challenging if you were unable to move to a position where an opponent piece can take your knight. Also some explanation would be nice, at first I thought I had to avoid other pieces and reach the end in the least amount of moves.\n \nreply",
      "I just played for a few minutes and loved it. Chess variants can sometimes take too long to understand the rules so this was great (excellent ux). I think I'd have liked it a bit more if you get captured (lose and restart) when you move on a square that's being attacked (rather than losing a point).I also enjoyed how it got a bit harder as the levels went on. And also how a stray pawn/piece might act as a hint (i.e. to capture on that square) - a bit like how side scrolling and adventure games might leave a trail of rings/bananas/collectables to guide the player along a desired path where it otherwise may not be obvious.\n \nreply",
      "This could use a bit more explanation. For instance:How many points and how many bonus moves do you get for a capture? Does it depend on what you capture? (It looks like it's one bonus move whatever you capture, but more points for more valuable pieces; 1 for a pawn, 3 for a bishop, so I'll guess it's 5 for a rook and 9 for a queen.)Does \"Beware of attackers!\" mean (1) you aren't allowed to move the knight to a square that's attached, (2) you will get some points deducted when you do, or (3) nothing, it's just flavour-text? (It looks like it's #2, a loss of one point each time you move to a square that's attacked.)The instructions don't mention the \"clean board\" bonus; I think they should.I'd write it something like this:Complete each level by reaching the target within the given number of moves.Each piece you capture gives you one more move, and points according to the value of the piece.You lose one point any time you move to a square that's attacked.Your score for the level is the number of moves you had spare at the end, times the number of points you earned. Double if you captured all the pieces!(... Except that it looks as if there's some further \"streak\" mechanic, which I haven't tried to figure out the details of.)If that's too long, put it behind a clicky-button, and just say \"Get your knight to the target square. Earn points for getting there quickly without being attacked, and capturing pieces on the way.\" plus a button labelled something like \"Full rules\".Maybe make the notification when you capture a piece say something like \"+3 points / +1 move\"?If the levels get fairly crowded then it might be expensive to get the computer to find the best possible score, but it shouldn't be hard to make it find a pretty good score. You could present that, either at the start or after the user finishes the level, as a target, and congratulate them when they meet or even beat it.\n \nreply",
      "Way back when Flash was a thing, one of the teachers at my kiddo's school started a chess club. They never played a full game of chess, but other games that taught the kids how to move the pieces and not burden them with the strategy of a full game. I decided to try to turn a few of those into Flash based games. It was fun making each of the pieces with the rules limiting their movement which became a game on its own just to show where pieces could go or not. Then adding more pieces to start playing the games. I never worked it up to the point of having player vs computer though. Glad to see other people also thinking chess based games could be made without needing a vs computer as well.I think this game would be perfect for a young kids chess club. Nice job!\n \nreply",
      "This was fun.  I played for a few minutes and like how there seem to be multiple ways to play the game-1. just get through the level and not worry about losing points2. get through the level without losing any points but not worrying about clearing all the pieces3. absolute perfection where you clear all the pieces without losing any pointsThis flexibility makes it good for serious players but also kids/casual players.  Great job!\n \nreply",
      "there is more. the number of moves left at the end is a multiplier for your points, so try to get through the level with a minimum number of moves while maximizing points by capturing high value pieces and also find streaks where you capture multiple pieces in a row.i love looking at a board and try to figure out the best order of moves to get the most points.not that i am very good at it, but it's fun and addictive.\n \nreply",
      "You\u2019re standing in notable footsteps, one of Alexei Pajitnov\u2019s follow-ups to Tetris was a similar game. https://en.wikipedia.org/wiki/Knight_Move\n \nreply",
      "Playing on my phone. Got to just under 12,000 before I got a txt and when I went back to the game it had restarted.Two things that would be nice.  Show the optimal score possible for any level, with a single puzzle mode (maybe puzzle of the day) to replay to try and achieve the best score on a single level.A more significant penalty for moving into unsafe squares.  Perhaps losing moves rather than points.  An increasing penalty for second and third hit might mitigate the just blunder your way through approach.I felt like I was in no danger of losing, but if it had a strongger penalty for being hit I think I would hit a limit in a reasonable amount of time.\n \nreply",
      "Great game, I enjoyed it! Reminds me of echo chess, using the chess pieces for movement means it's really easy to pick up.I noticed a potential bug (Firefox on Android) - I can pick up extra points by capturing, capturing again, then quickly moving back to the first capture square. I get the points as if it was another capture, even though there is no piece there anymore.Edit: actually, I can quickly move back and forth for infinite points (and combo)\n \nreply",
      "4872 first game.  I got all the pieces on every level except the first because I didn't realize you could.  Pretty fun and I don't even play chess.  Are the levels designed by hand or generated?\n \nreply"
    ],
    "link": "https://knightride.rakhim.org/",
    "first_paragraph": "Reach the target to win.\n            Capture pieces for points and bonus moves.\n            \n            Level score = points \u00d7 moves left.\n            \n            Beware of attackers!\n        \u2b50 Your High Score: 0 \u2b50Made by Rakhim D.\n            Points earned: 0\n\n            Moves left: \u00d71\n\n            Clean board bonus: \u00d71\nLevel score: 0\u2b50 Running total: 0 \u2b50You ran out of moves!Final score: 0High score: 0"
  },
  {
    "title": "It\u2019s not mold, it\u2019s calcium lactate (2018) (thephcheese.com)",
    "points": 313,
    "submitter": "ilikepi",
    "submit_time": "2025-03-31T14:49:42 1743432582",
    "num_comments": 195,
    "comments_url": "https://news.ycombinator.com/item?id=43535688",
    "comments": [
      "I spent a couple of months in Switzerland for a project and supermarkets there often have this booth that me and my friends referred to as the \"Kingdom of Cheese\".The Kingdom of Cheese is a climate-controlled enclave with just cheese - the person there is happy to help you decide because they know you'll be back eventually as indeed the products there have those crystals.\n \nreply",
      "Back eventually? I'd personally set up a little tent in the foyer and live there year 'round, like an increasingly portly mouse.\n \nreply",
      "At that point just call it Redwall Abbey!\n \nreply",
      "I\u2019ve always loved the crunch in a good Gouda, and it\u2019s really fun to read some details about tyrosine crystals that cause it.\n \nreply",
      "Like adding acid to fake sourdough\u2026\n \nreply",
      "How long until cheese makers start adding the crunchy crystals to give the appearance of quality without the actual quality?\n \nreply",
      "This happens already, at least it does in the UK. Most cheaper brands of \u201cextra mature\u201d supermarket cheddar have added crystals. I don\u2019t actually mind that much - I do think it is a genuinely slightly more enjoyable product with the crystals.\n \nreply",
      "There are also fake ways of accelerating aging to create this effect, like the Old Amsterdam cheeses you\u2019ll find in the Netherlands. That particular brand has a lot of fake qualities to it that creates these effects.\n \nreply",
      "Is \"fake\" really the right word here if people get the flavor, nutrition, and texture they want? I don't really give a damn if they figured out a way to bypass aging to achieve this.\n \nreply",
      "The article says that the crystals don't affect the taste or scent. The crystals are a signal that you have a good cheese, but not the cause of a good cheese. Adding them to a bad cheese won't make it a good cheese, so in that sense I'd call it a fake.There is some gray area in that they affect the texture, which is a part of the whole experience. But that's again mostly signaling--we like the crunch because we associate it with good cheeses, not because there's anything inherently better about it.There are some interesting philosophical questions here. If you put a fake label on some wine, and people perceive it as higher quality than it is, is it really fake? On one hand, obviously yes. And yet there was a real effect on the perceived quality.\n \nreply"
    ],
    "link": "https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold",
    "first_paragraph": "The PhCheeseCheese so Smart it Has a DegreeTwo weeks ago, one of my best friends and ex-cheese comrades, Chelsea, brought our old mentor/boss-lady, the illustrious Kim Martin, into the shop. Neither of them had visited us before, and it was pretty exciting to show them around our little corner of the co-op.As they were getting ready to leave, Chelsea pulled me aside and silently pointed at a quarter-wheel of aged Gouda on display in the back of the case, tapping the side of it to show me that it was all white.\u201cIt\u2019s not mold,\u201d I announced without skipping a beat. \u201cIt\u2019s calcium lactate.\u201dThis is something I actually have to write on the scale label when we wrap wedges of the cheese for sale, because people are inherently put off by a sheet of white on an otherwise butterscotch-orange cheese.After all, most people are familiar with white, wispy molds growing on the outside of cheese\u2014either as the well-manicured coif of a bloomy-rind cheese or as errant growths on the cut face of half-eaten"
  },
  {
    "title": "James Webb Space Telescope reveals that most galaxies rotate clockwise (smithsonianmag.com)",
    "points": 277,
    "submitter": "instagraham",
    "submit_time": "2025-03-31T10:31:39 1743417099",
    "num_comments": 240,
    "comments_url": "https://news.ycombinator.com/item?id=43533306",
    "comments": [
      "> The same solo author (a computer scientist) has made many similar claims based on a variety of datasets. Often coming to completely contradictory conclusions. Some of these claims have been followed up by astronomers, who found errors in his analysis and poor statistical tests. His claims have been discussed in this sub before. Independent studied have found no significant evidence of anisotropy.https://academic.oup.com/mnras/article/534/2/1553/7762193https://ui.adsabs.harvard.edu/abs/2021ApJ...907..123I/abstra...https://ui.adsabs.harvard.edu/abs/2017MNRAS.466.3928H/abstra...>Take his claims about JWST as an example. In 2024 he wrote a paper about some early data, claiming to find more galaxies rotating with the Milky Way. He claimed based on a sample of just 34 galaxies that the signal was significant. Now he has looked at a wider dataset of the same area, which should allow him to verify his analysis. But it shows exactly the opposite, more anti. So he writes a paper saying this new result is definitely significant but doesn't reflect on the fact he has written two papers which contradict each other. He has failed to reproduce his own result. The take away is that his results are not as significant as he claims. He's also looking at a tiny area, and nearby galaxies can have correlated spins. He doesn't take this into account either. There are multiple JWST fields in different directions he could examine in different directions to test his claims, there are two JADES fields, but he only publishes one.>I do wish the MNRAS editors would take measures to stop publishing low quality claims like this without more robust review. If you look at the text, it\u2019s largely repeating results from his old papers. There\u2019s very little discussion of the new results.source: https://www.reddit.com/r/cosmology/comments/1ja9i53/the_dist...\n \nreply",
      "Thank you. That's a shame, it was a cool-sounding story, just unlikely enough to sound plausible.\n \nreply",
      "The author is also a proponent of tired light theory, which has been thoroughly refuted.\n \nreply",
      "Wow and not even 24 hours after Trump takes aim at the Smithsonian.*) The article is from March 17.\n \nreply",
      "Is this just word association, or you saying there\u2019s some notable connection here?\n \nreply",
      "If I was an editor at the Smithsonian, I'd be worried about peddling bogus theories for clicks at a time my employer is under scrutiny from the government.  Apparently, they are not worried though, which astonishes me, hence my comment.\n \nreply",
      "Out of all of the things, this government is scrutinizing, factual, accuracy, and quality of reasoning don\u2019t seem to be of particular importance.\n \nreply",
      "Potentially a very dumb question, but seeing the difference between cyclones and hurricane on earth (clock-wise, anti-clock-wise)...Does it mean that we are, potentially, on one of two poles(?) of the observable universe, if we're observing most galaxies around us rotating a certain way?\n \nreply",
      "Dumber question: would a galaxy that appears to spin clockwise appear to spin counter-clockwise when viewed from the other side? Does this imply that the real question is why galaxies' relative orientations seem to favor more spinning in one direction than the other?\n \nreply",
      "> when viewed from the other side?Nobody has done it so far. We have only theories and hypothesis.\n \nreply"
    ],
    "link": "https://www.smithsonianmag.com/smart-news/james-webb-space-telescope-reveals-that-most-galaxies-rotate-clockwise-180986224/",
    "first_paragraph": ""
  },
  {
    "title": "AI agents: Less capability, more reliability, please (sergey.fyi)",
    "points": 301,
    "submitter": "serjester",
    "submit_time": "2025-03-31T14:45:35 1743432335",
    "num_comments": 191,
    "comments_url": "https://news.ycombinator.com/item?id=43535653",
    "comments": [
      "Yeah, the \"book a flight\" agent thing is a running joke now - it was a punchline in the Swyx keynote for the recent AI Engineer event in NYC: https://www.latent.space/p/agentI think this piece is underestimating the difficulty involved here though. If only it was as easy as \"just pick a single task and make the agent really good at that\"!The problem is that if your UI involves human beings typing or talking to you in a human language, there is an unbounded set of ways things could go wrong. You can't test against every possible variant of what they might say. Humans are bad at clearly expressing things, but even worse is the challenge of ensuring they have a concrete, accurate mental model of what the software can and cannot do.\n \nreply",
      "> The problem is that if your UI involves human beings typing or talking to you in a human language, there is an unbounded set of ways things could go wrong. You can't test against every possible variant of what they might say.It's almost like we really might benefit from using the advances in AI for stuff like speech recognition to build concrete interfaces with specific predefined vocabularies and a local-first UX.  But stuff like that undermines a cloud-based service and a constantly changing interface and the opportunities for general spying and manufacturing \"engagement\" while people struggle to use the stuff you've made. And of course, producing actual specifications means that you would have to own bugs.  Besides eliminating employees, much interest in AI is all about completely eliminating responsibility.  As a user of ML-based monitoring products and such for years.. \"intelligence\" usually implies no real specifications, and no specifications implies no bugs, and no bugs implies rent-seeking behaviour without the burden of any actual responsibilities.It's frustrating to see how often even technologists buy the story that \"users don't want/need concrete specifications\" or that \"users aren't smart enough to deal with concrete interfaces\".  It's a trick.\n \nreply",
      "> concrete interfaces with specific predefined vocabularies and a local-first UXAn app? We don\u2019t even need to put AI in it, turns out you can book flights without one.\n \nreply",
      "Tech won't freeze in place exactly where it's at today even if some people want that, and even if in some cases it actually would make sense.  And.. if you advocate for this I think you risk losing credibility.  Especially amongst technologists it's better to think critically about structural problems with the trends and trajectories.  AI is fine, change is fine.. the question now is really more like why and what for and in the interest of whom.  To the extent models work locally, we'll be empowered in the end.Similarly, software eating the world was actually pretty much fine, but SaaS is/was a bit of a trap.  And anyone who thought SaaS was bad should be terrified about the moats and platform lock-in that billion dollar models might mean, the enshittification that inevitably follows market dominance, etc.Honestly we kinda need a new Stallman for the brave new world, someone who is relentlessly beating the drum on this stuff even if they come across as anticorporate and extreme.  An extremist might get traction, but a call to preserve things as they are probably cannot / should not.\n \nreply",
      "Perhaps the solutions(s) needs to be less focusing on output quality, and more on having a solid process for dealing with errors.  Think undo, containers, git, CRDTs or whatever rather than zero tolerance for errors. That probably also means some kind of review for the irreversible bits of any process, and perhaps even process changes where possible to make common processes more reversible (which sounds like an extreme challenge in some cases).I can't imagine we're anywhere even close to the kind of perfection required not to need something like this - if it's even possible.  Humans use all kinds of review and audit processes precisely because perfection is rarely attainable, and that might be fundamental.\n \nreply",
      "The biggest issue I\u2019ve seen is \u201ccontext window poisoning\u201d, for lack of a better term. If it screws something up it\u2019s highly prone to repeating that mistake. It then makes a bad fix that propagates two more errors, the says, \u201cSure! Let me address that,\u201d repeating to poorly fix those rather than the underlying issue (say, restructuring code to mitigate.)It is almost impossible to produce a useful result, far as I\u2019ve seen, unless one eliminates that mistake from the context window.\n \nreply",
      "I really really wish that LLMs had an \"eject\" function - as in I could click on any message in a chat, and it would basically start a new clone chat with the current chat's thread history.There are so many times where I get to a point where the conversation is finally flowing in the way that I want and I would love to \"fork\" into several directions from that one specific part of the conversation.Instead I have to rely on a prompt that requests the LLM to compress the entire conversation into a non-prose format that attempts to be as semantically lossless as possible; this sadly never works as in ten did [sic].\n \nreply",
      "Google UI supports branching and delete someone recently made a blog post about how great it is\n \nreply",
      "which Google UI?\n \nreply",
      "You can use LibreChat which allows you to fork messages: https://www.librechat.ai/docs/features/fork\n \nreply"
    ],
    "link": "https://www.sergey.fyi/articles/reliability-vs-capability",
    "first_paragraph": "Stay connected and receive new blog posts in your inbox.I\u2019d love to hear from you.\u00a9 2025 Sergey Filimonov. All rights reserved."
  },
  {
    "title": "In the 1980s we downloaded games from the radio (newslttrs.com)",
    "points": 262,
    "submitter": "spzb",
    "submit_time": "2025-03-28T22:14:33 1743200073",
    "num_comments": 141,
    "comments_url": "https://news.ycombinator.com/item?id=43510393",
    "comments": [
      "I definitely had cassette based games on the TRS-80, but most of the \"wireless\" transmission in my youth was via BASIC printed in the back of computer magazines. You had to type in the entire app yourself. I did this for basically every app they listed. Sometimes it was like tax prep software, but I didn't care, even though I was like 9 at the time. Yes, it took a very long time. Yes, you could easily introduce typos and bugs.\n \nreply",
      "This is what I had to do.   It was probably beneficial.   I was pretty young.. 10-12?   My dad is also an engineer and would help me debug the programs after I typed them in, teaching me BASIC as we went.   I wasn't necessarily able to understand it all but it probably built me a foundation for programming no different than introducing children to a 2nd language earlier rather than later.There were also books I checked out of the library.  These sometimes presented additional difficulties as we didn't have a computer powerful enough to take advantage of everything in the book, or had a completely wrong environment.I must have been weirdly motivated but in some way I think this was better than the way everything is spoonfed and easy for kids today if they want it?   My son is not motivated the same way, it's just too easy to go over to a game or something else that's less challenging.   Quite a few of my friends who also became software engineers/computer scientists had a very similar experience in the late 80s and early 90s.\n \nreply",
      "Sometimes the typos were in the magazine itself, and you wouldn't figure out the problem with the code you triple-checked you typed in properly until the errata in next month's issue :)\n \nreply",
      "My exact memory. When you did finally get everything correct, the program could take 15 minutes to load from the cassette tape. I remember upgrading my Commodore 64 with a floppy disk and loading programs in 2 minutes (which felt instantaneous by comparison).\n \nreply",
      "I never had a tape deck, and was constantly flustered by \u201cpress play on tape\u201d messages.\n \nreply",
      "The compiler/interpreter couldn\u2019t even tell you what line the error was on!You\u2019d just get a big error message for the whole program.\n \nreply",
      "After a while, magazines like Commodore Run and Compute started including a short program that would checksum each line as you entered it, so you could check that against a checksum in the magazine. Of course, you had to get that program typed in correctly first before you could use it to enter others.\n \nreply",
      "My favorite was the \"TYPO II\" (\"Type Your Program Once\") application, which was part of every Antic! Magazine program listing:https://www.atarimagazines.com/v3n9/TYPOII.html\nhttps://www.atarimagazines.com/antic/This was wrapper around the BASIC interpreter that printed out a 2-character checksum of each entered code line.The magazine printing also had an associated 2-character checksum for each line.  Your job: make sure the checksums matched.As a teenager who only had cassette-based storage (couldn't afford a disk drive) and was addicted to typing in programs from Antic! and ANALOG magazines, this was a lifesaver.(ANALOG's checksum program wasn't quite as convenient, and, IIRC, required a disk drive?)\n \nreply",
      "I took a look at the listing[1] and looks like it contains unprintable characters, maybe they were ASCII art of some sort?The checksum algorithm is fairly simple: line 32150 sums the products of all character positions and character codes, and lines 32160-32180 does a modulus to convert them to printable characters.  The multiply-by-position bit is clever because it allows the checksum to flag transposed characters.  ISBN-10 uses a similar scheme[2].[1] https://www.atarimagazines.com/software/displayfile.php?file...[2] https://en.wikipedia.org/wiki/ISBN#ISBN-10_check_digits\n \nreply",
      "I naturally went down a rabbit hole to see if I could find why those characters weren't printing properly.https://www.atarimania.com/mags/pdf/Antic_Vol_7_No_4.pdfOn p. 31, you can see the intended characters.I now remember that Atari actually had their own variant of ASCII, called ATASCII:https://en.wikipedia.org/wiki/ATASCIIAtari 8-bits were actually really cool computers, in that they let you do things like redefine character sets entirely (to create custom character sets to effectively create tile-based displays), play with display-list interrupts, etc.\n \nreply"
    ],
    "link": "https://newslttrs.com/yes-in-the-1980s-we-downloaded-games-from-the-radio/",
    "first_paragraph": "So there I was, minding my own business, doom-scrolling my way through Facebook posts when I happened upon one that hit me straight in the nostalgia. A photo of a 1980s home computer, a cassette player and some tapes. The text underneath proclaimed \"In the 1980s, people could download video games from radio broadcasts by recording the audio onto cassette tapes. These tapes could then be played on computers to load the games\". I nodded sagely to myself as I remembered doing just that.Then I started to read the comments underneath and people were flat-out denying that this had ever happened. The reply guys broadly fell into two camps: the \"I have never heard of this, therefore it never happened\" and the over confident \"expert\" saying things like \"this would be technically impossible due to some fancy sounding words I've heard like 'hertz', 'compression' and 'frequency shift keying', therefore it never happened\".Just to make sure I was in a spluttering rage the page itself was titled \"Unb"
  }
]