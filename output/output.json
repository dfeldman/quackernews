[
  {
    "title": "Bolt3D: Generating 3D Scenes in Seconds (szymanowiczs.github.io)",
    "points": 63,
    "submitter": "jasondavies",
    "submit_time": "2025-03-19T22:30:56 1742423456",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=43417932",
    "comments": [
      "Show. Us. The. Wireframes!Every single time a new \"Generate 3D\" thing appears, they never show the wireframes of the objects/scenes up front, always you need to download and inspect things yourself. How is this not standard practice already?Not displaying the wireframes at all, or even offer sample files so we could at least see it ourselves, just makes it look like you already know that the generated results are unusable...\n \nreply",
      "My understanding is that it is not mesh, it\u2019s Gaussian Splatting. There are tools to convert Splats into mesh though.\n \nreply",
      "Yeah, but isn't still the expected outcome to end up with actual 3D objects, not point clouds? Or did people start integrating point clouds into their 3D workflows already? Besides for stuff like volumes and alike, I think most of us are still stuck working with polygons for 3D.\n \nreply",
      "They usually don't show the material channels either, which I assume is because there aren't any, so the lighting in the demo is effectively baked into the asset itself.\n \nreply",
      "splats don't have wireframes, and they have an embedded webgpu viewer in the linked page.\n \nreply",
      "Is anything like this available locally yet?\n \nreply",
      "Here's the repo: https://github.com/szymanowiczs/splatter-imageApparently you can clone and run the demo locally.  But wasn't clear at a glance how much is local and what hardware required.\n \nreply",
      "Isn't it generating in the browser using webgpu?\n \nreply"
    ],
    "link": "https://szymanowiczs.github.io/bolt3d",
    "first_paragraph": "\n                        Given one or more input images, we generate multi-view Splatter Images.\n                        To do so, we first generate the scene appearance and geometry using a multi-view diffusion\n                        model.\n                        Then, Splatter Images are regressed using a Gaussian Head.\n                        3D Gaussians from multiple Splatter Images are combined to form the 3D scene.\n                    \n                                Click on the images below to render 3D scenes in real-time in your browser.\n                            \n                            Bolt3D can accept variable number of input images.\n                            Our model adheres to conditioning when it is available and generates unobserved\n                            scene regions without any reprojection or inpainting mechanisms.\n                        \n                            The key to generating high-quality 3D scenes with a latent diffusion model is our"
  },
  {
    "title": "How fast the days are getting longer (joe-antognini.github.io)",
    "points": 418,
    "submitter": "antognini",
    "submit_time": "2025-03-19T16:13:20 1742400800",
    "num_comments": 148,
    "comments_url": "https://news.ycombinator.com/item?id=43413935",
    "comments": [
      "The writer had to attend a standup with a colleague in Norway to realize this and write an article. Funnily enough, as a Muslim I get reminded about this annually during Ramadan, which is right now.First of Ramadan this year coincided with March 1, and it was a 12:45 hours of fasting from the first light of dawn to sunset at my \n location, also near Los Angeles. Today it's going to be 13:15 hours long, and by the time last of Ramadan rolls in around the end of March, it will be 13:37 hours.Ramadan is observed following the lunar calendar, which is shorter than solar- based calendars by about 10 days. A winter Ramadan is short and easy in the northern hemisphere and we will have the shortest days in 2031. 2047 it's going to be middle of summer, so the hardest.In case you ask, well what about places where sun does not set? When do you have your Suhoor (meal before dawn) and iftar (breakfast meal at sunset)? Opinions differ, but people usually follow the more realistic time of sunrise and sunset at a reference location. My brother in law was in Sweden few years back and he used the time of Mecca as reference.\n \nreply",
      "Living among Muslim and Catholic people in a time of simultaneous Lent and Ramadan, I first read \"How the Fast Days are getting longer\" and thought \"How true, how true\".\n \nreply",
      "As a middle-aged human I first read \"How the Fast Days are getting longer\" as some kind of ironic commentary with the actual meaning being \"how fast the days are getting shorter\".\n \nreply",
      "So you have to plan your daily routine around the rules of Ramadan, and their interpretation differ by your location and from year to year?\n \nreply",
      "Yeah. Just trivial Muslim problems.Yesterday I had a flight from San Jose to LA. I didn't really plan for Ramadan when I booked the flight. I was scheduled to land at LAX at 6.45pm, about 25 minutes before iftar LA time. The plan was to land, have something light at the terminal then drive 1 hour back to my place.Well the flight got delayed about 25 minutes. It was going to land about 10 minutes after sunset. I was debating whether to buy something to eat before boarding. But then I can't have the tray open and eat when the plane is landing. I ended up breaking fast in the LAX terminal but around 30 minutes after I originally planned to.Its really nice flying during sunset though, the pink sky around LA was gorgeous.\n \nreply",
      "Depending on the specific school of fiqh that the commenter follows, he could have also been totally fine not fasting at all if traveling more than 80 km beyond his home.https://www.google.com/search?client=firefox-b-e&channel=ent...\n \nreply",
      "Yes! You should also look into how pro athletes handle the logistics of fasting and competing (eg Kyrie, Mo Salah, and many others).\n \nreply",
      "I saw some things recently about how Hakeem Olajuwon fasted during Ramadan and generally his performance was just as good during Ramadan as during the rest of the season, which is really impressive.\n \nreply",
      "My routine changes depending on location and the year anyway.\n \nreply",
      "Solar calendar user, meet lunar calendar user.\n \nreply"
    ],
    "link": "https://joe-antognini.github.io/astronomy/daylight",
    "first_paragraph": "March 30, 2023Here in the northern hemisphere the vernal equinox just passed and the days are\nquickly getting longer.  One of my colleagues lives in Stavanger, Norway.  Our\nteam\u2019s semi-weekly standup is at 6:30pm his time, so I\u2019ve been accustomed to\nseeing the window in his background be pitch black for the past six months.\nBut from one meeting to the next, his window went from pitch black to bright.\nThis led me to think about a basic astronomy question I had never given much\nthought to before \u2014 just how fast do the days get longer?  When Spring comes\nand the days are getting longer, how many extra minutes of sunlight do we get\nfrom one day to the next?  So I built a little interactive graph that shows how\nthe length of the day changes as a function of latitude, along with how it\nchanges from one day to the next:The vertical dashed lines represent the various solstices and equinoxes.  As\nexpected, for northern latitudes the longest day is on the summer solstice and\nthe shortest on the "
  },
  {
    "title": "DESI Opens Access to the Largest 3D Map of the Universe Yet (lbl.gov)",
    "points": 29,
    "submitter": "gnabgib",
    "submit_time": "2025-03-19T23:08:08 1742425688",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://newscenter.lbl.gov/2025/03/19/desi-opens-access-to-the-largest-3d-map-of-the-universe-yet/",
    "first_paragraph": ""
  },
  {
    "title": "The Continuing Crisis, Part IX: Inside the NIH Now (science.org)",
    "points": 45,
    "submitter": "etiam",
    "submit_time": "2025-03-19T23:09:34 1742425774",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=43418192",
    "comments": [
      "Much too quiet here on HN on this postScience underpins technology, people.If you want to see the US rapidly lose its place in the tech world over the next decade, this is a great way to go about it.\n \nreply",
      "Yes of course.The problem is what can be done? The usual arrangement of letter writing or donating and voting is just more of the same cycle.I'm not by any means in favor of what's going on, but some steam has to be let out of the system. And the real problem is trust in our institutions. What can be done about that?\n \nreply",
      "My thoughts exactly. I certainly have throes of people on Facebook complaining about this, but what shall I, the individual, do about this?I have my causes to which I devote great time and personal effort, but if I stopped my life for every minor disaster I would spend my life shaking my fist at my computer.I quite like my life and I don\u2019t intend to spend it getting rage baited by never-ending news cycles.Give me an action to take, not an emotion to feel.\n \nreply",
      "How old are you? What is happening now at the NSF and NIH will knock the US off its technological perch in less than 15 to 20 years. We are already fighting to maintain an edge as it is.What this means to you personally and other tech workers is that many of the well-paying tech jobs will be going elsewhere.\n \nreply",
      "Mass protests and non-violent civil disobedience.  I hope that we don't reach a point where going beyond that is required.\n \nreply",
      "Yes, civil disobedience. Get into \u2018Good trouble\u2019\n \nreply",
      "The post war scientific edifice is being shattered in a monumental act of vandalism.It\u2019s not just defunding childhood cancer research, but also dismantling the very idea of agency in the broader society. Science and basic research are worth pursuing. And the cost is a  pittance.\n \nreply",
      "The oligarchs can\u2019t stand to see a single dollar go to a legit purpose though.\n \nreply",
      "No, the oligarchs can't stand seeing a single dollar go to the poor, and when one is a billionaire, everyone else is poor.\n \nreply",
      "It is worth mentioning that China is heavily investing in biotechnology and they are getting genuinely good at the more commodified parts of the industry. This blog post [1] is long and aimed at a biotech expert audience, but one summary line that stands out is that \"the drug industry is having its own DeepSeek Moment\" [2].To that end, I believe that this is the time to invest in the US biotechnology ecosystem so that we remain competitive with China. The ongoing crisis at the NIH is antithetical to this goal, as Derek Lowe's blog posts describe.[1] https://centuryofbio.com/p/commoditization\n[2] https://www.wsj.com/health/pharma/the-drug-industry-is-havin...\n \nreply"
    ],
    "link": "https://www.science.org/content/blog-post/continuing-crisis-part-ix-inside-nih-now",
    "first_paragraph": ""
  },
  {
    "title": "AI Blindspots \u2013 Blindspots in LLMs I've noticed while AI coding (ezyang.github.io)",
    "points": 290,
    "submitter": "rahimnathwani",
    "submit_time": "2025-03-19T16:48:32 1742402912",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=43414393",
    "comments": [
      "This highlights a thing I've seen with LLM's generally: they make different mistakes than humans. This makes catching the errors much more difficult.What I mean by this is that we have thousands of years of experience catching human mistakes. As such, we're really good at designing systems that catch (or work around) human mistakes and biases.LLM's, while impressive and sometimes less mistake-prone than humans, make errors in a fundamentally different manner. We just don't have the intuition and understanding of the way that LLM's \"think\" (in a broad sense of the word). As such, we have a hard time designing systems that account for this and catch the errors.\n \nreply",
      "This is, I think, a better way to think about LLM mistakes compared to the usual \"hallucinations\". I think of them as similar to human optical illusions. There are things about the human visual cortex (and also other sensory systems, see the McGurk Effect [0]), that, when presented with certain kinds of inputs, will consistently produce wrong interpretations/outputs. Even when we are 100% ware of the issue, we can't prevent our brains from generating the incorrect interpretation.LLMs seem to have similar issues along dramatically different axes, axes that humans are not used to seeing these kinds of mistakes; where nearly no human would make this kind of mistake and so we interpret it (in my opinion incorrectly) as lack of ability or intelligence.Because these are engineered systems, we may figure out ways to solve these problems (although I personally think the best we will ever do is decrease their prevalence), but more important is probably learning to recognize the places that LLMs are likely to make these errors, and, as your comment suggests, design work flows and systems that can deal with them.[0] https://youtu.be/2k8fHR9jKVM\n \nreply",
      "> I think of them as similar to human optical illusions.What we call \"hallucinations\" is far more similar to what we would call \"inventiveness\", \"creativity\", or \"imagination\" in humans than anything to do with what we refer to as \"hallucinations\" in humans\u2014only they don't have the ability to analyze whether or not they're making up something or accurately parameterizing the vibes. The only connection between the two concepts is that the initial imagery from DeepDream was super trippy.\n \nreply",
      "Hallucinating is fine but overconfidence is the problem. But I heard it's not an easy problem to solve.\n \nreply",
      "Unfortunately, in the system most of us work in today, I think overconfidence is an intelligent behavior.\n \nreply",
      "I find it extremely dumb to see overconfident people that really have nothing special about them or are even incompetent. These people are not contributing positively to the system, quite on the contrary.\n \nreply",
      "But being like that can get you elected.\n \nreply",
      "In what country?\n \nreply",
      "Quite a few :(",
      "But we don't work for the system, fundamentally, we work for ourselves, and the system incentivizes us to work for it by aligning our constraints: if you work that direction, you'll get that reward.Overconfident people ofc do not contribute positively to the system, but they skew the system reward's calculation towards them: I swear I've done that work in that direction, where's my reward ?In a sense, they are extremely successful: they managed to do very low effort, get very high reward, help themselves like all of us but at a much better profit margin, by sacrificing a system that, let's be honest, none of us care about really.Your problem maybe, is that you swallowed the little BS the system fed you while incentivizing you: that the system matters more than yourself, at least at a greater extent than healthy ?And you see the same thing with AI: these things convince people so deeply of their intelligence that it blew to such proportion that NVidia is now worth trillions. I had a colleague mumbling yesterday that his wife now speaks more with ChatGPT than him. Overconfidence is a positive attribute... for oneself.\n \nreply"
    ],
    "link": "https://ezyang.github.io/ai-blindspots/",
    "first_paragraph": "Blindspots in LLMs I\u2019ve noticed while AI coding. Sonnet family emphasis. Maybe I will eventually suggest Cursor rules for these problems.This site is made with Hugo \u0295\u2022\u1d25\u2022\u0294 Bear."
  },
  {
    "title": "LLM Agents Are Simply Graph \u2013 Tutorial for Dummies (zacharyhuang.substack.com)",
    "points": 47,
    "submitter": "zh2408",
    "submit_time": "2025-03-19T21:29:13 1742419753",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=43417511",
    "comments": [
      "I follow Mr. Huang, read/watch his content and also plan to use PocketFlow in some cases. A preamble, because I don't agree with this assessment. I think agents as nodes in a DAG workflow is _an_ implementation of an agentic system, but is not the systems I most often interact with (e.g. Cursor, Claude + MCP).Agentic systems can be simply the LLM + prompting + tools[1]. LLMs are more than capable (especially chain-of thought models) to breakdown problems into steps, analyze necessary tools to use and then executing the steps in sequence. All of this is done with the model in the driver seat.I think the system described in the post need a different name. It's a traditional workflow system with an agent operating on individual tasks. Its more rigid in that the workflow is setup ahead of time. Typical agentic systems are largely undefined or defined via prompting. For some use cases this rigidity is a feature.[1 https://docs.anthropic.com/en/docs/build-with-claude/tool-us...\n \nreply",
      "Let me clarify: this tutorial focuses on the technical internal implementation of the agent (e.g., OpenAI agent, Pydantic AI, etc.), rather than the UI/UX of the agent-based products that end users interact with.\n \nreply",
      "The newest generation of agents[0] aren't implemented this way; the model itself is trained to make decisions and a plan of action rather than an explicitly programmed workflow tree.[0] https://openai.com/index/computer-using-agent/\n \nreply",
      "I think you\u2019re referring to function calling: https://platform.openai.com/docs/guides/function-callingThis still returns a string. You need to explicitly program the branch to the right function. For example, check out how OpenAI Agents, released a week ago, rely on a workflow: https://github.com/openai/openai-agents-python/blob/48ff99bb...\n \nreply",
      "No I'm referring to the newest generation of agentic models one of which I linked to. These are not fully released but it is where the newest generation of research is headed.\n \nreply",
      "That remains to be seen. Manus, a standard agent built with Claude 3.7, outperforms o3 agentic model on the GAIA benchmark.\n \nreply",
      "It's hard for me to comment on something not open sourced\n \nreply",
      "That's what I am talking about as well. The low-level implementation of an agent isn't necessarily a rigid graph, and I'd actually argue its explicitly not this.\n \nreply",
      "The current implementations of Agents, e.g., OpenAI agents released last week, are based on graph (workflow): https://github.com/openai/openai-agents-python/blob/48ff99bb...Not sure about Cursor you mentioned as its agent is not open sourced.\n \nreply",
      "Hey folks! I just posted a quick tutorial explaining how LLM agents (like OpenAI Agents, Pydantic AI, Manus AI, AutoGPT or PerplexityAI) are basically small graphs with loops and branches. For example:OpenAI Agents: for the workflow logic: https://github.com/openai/openai-agents-python/blob/48ff99bb...Pydantic Agents: organizes steps in a graph: https://github.com/pydantic/pydantic-ai/blob/4c0f384a0626299...Langchain: demonstrates the loop structure: https://github.com/langchain-ai/langchain/blob/4d1d726e61ed5...If all the hype has been confusing, this guide shows how they actually work under the hood, with simple examples. Check it out!https://zacharyhuang.substack.com/p/llm-agent-internal-as-a-...\n \nreply"
    ],
    "link": "https://zacharyhuang.substack.com/p/llm-agent-internal-as-a-graph-tutorial",
    "first_paragraph": ""
  },
  {
    "title": "Muons used to test the condition of a road bridge in Estonia (err.ee)",
    "points": 132,
    "submitter": "Fethbita",
    "submit_time": "2025-03-16T12:05:53 1742126753",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=43378358",
    "comments": [
      "https://en.wikipedia.org/wiki/Luis_Walter_AlvarezAlvarez proposed muon tomography in 1965 to search the Egyptian pyramids for unknown chambers. Using naturally occurring cosmic rays, his plan was to place spark chambers, standard equipment in the high-energy particle physics of this time, beneath the Pyramid of Khafre in a known chamber. By measuring the counting rate of the cosmic rays in different directions the detector would reveal the existence of any void in the overlaying rock structure.[48]\n \nreply",
      "They were indeed able to do this after all [1], and found some unknown voids.[1] https://spectrum.ieee.org/muon-imaging-finds-hidden-chamber-...\n \nreply",
      "At least one was confirmed to indeed be exist - quite fascinating.One day hopefully we can find out if the remaining giant looking open area exists too!\n \nreply",
      "Muons were also recently on hackaday. DIY ground penetrating radar ...Building A DIY Muon Tomography Device For About $100https://hackaday.com/2025/02/26/building-a-diy-muon-tomograp...\n \nreply",
      "Also on HN,https://news.ycombinator.com/item?id=43195525 (\"A $100 DIY muon tomographer (ieee.org)\", 20 days ago, 45 comments)\n \nreply",
      "Here is an example used in the mining industry. I heard them present at a NASA/USGS conference last month regarding in situ resource ultilization: https://ideon.ai/\n \nreply",
      "I did not know this was a thing!https://en.wikipedia.org/wiki/Muon_tomography\n \nreply",
      "Neutrons can be used for these things as well. The advantage, say from x-rays, is attenuation is not by material density, where all metals will just look dark, but by thermal neutron absorption cross section. So boron might be dark, but metals won't be.Muons are much nicer as you don't have to carry a neutron source around with you.> However, if anyone is now thinking of standing under the bridge to get their body scanned, they shouldn't bother. First, they'd have to stand still for an hour, and second, the security patrol would be there within minutes.Security patrol will come and bother you if you hand around the bridge for a few minutes?\n \nreply",
      "> Security patrol will come and bother you if you hand around the bridge for a few minutes?There\u2019s a land war in Europe. Hundreds of thousands have lost their lives during the past few years. There have been cases of sabotage against the Baltic states as well as the Nordic states. Things are pretty grim there and lurking around basic infrastructure pretty much guarantees a talk with the police.\n \nreply",
      "Plus Estonia in particular is 200km away from St Petersberg, and 800km from Moscow. They are all but guaranteed to succumb to Russian expansion if allowed to continue unchecked.\n \nreply"
    ],
    "link": "https://news.err.ee/1609634600/muons-used-to-test-the-condition-of-a-road-bridge-in-estonia",
    "first_paragraph": ""
  },
  {
    "title": "fd: A simple, fast and user-friendly alternative to 'find' (github.com/sharkdp)",
    "points": 524,
    "submitter": "tosh",
    "submit_time": "2025-03-19T11:44:17 1742384657",
    "num_comments": 222,
    "comments_url": "https://news.ycombinator.com/item?id=43410692",
    "comments": [
      "Big sharkdp fan. Ty you for making awesome software that i use DAILY.bat, fd, hexyl, hyperfineI'm going to take this moment to remind all of you well-paid engineers that if we each spread $10 a month sponsoring talented software makers like sharkdp the Internet would be a better place.So many great little tools out there and we should try to support an ecosystem for them.\n \nreply",
      "bat, fd, and hyperfine are all by the same person??? That's incredible, I love all of these utilities.\n \nreply",
      "Seems like David Peter works at Astral now, as does Andrew Gallant (ripgrep).It's a dream team for rust cli tools over there.\n \nreply",
      "I owe hours of my life to Andrew Gallant aka BurntSushi's xsv. Nothing else tries to handle splitting long files into N-row chunks [1]. I was using the command line utility, but that's his wrapper around his rust-csv library. So if you need CSV parsing in rust, I strongly recommend this library.[1] rows included linebreaks so your standard sed/head/tail/something-from-coreutils approach would not work.\n \nreply",
      "I have spent a lot of hours looking at `watch \"xsv select ... | xsv table\"`.\n \nreply",
      "Not that there is necessarily that much churn in csv processing, but last I looked, the xsv repo has not received much maintenance for a while.\n \nreply",
      "This is an active fork: https://github.com/dathere/qsv\n \nreply",
      "IIRC it was just deprecated in nixpkgs for this reason\n \nreply",
      "When software is feature complete, fast and working correctly, what is it exactly you expect to change?\n \nreply",
      "I mean there are 131 open issues and some 30+ PRs, so clearly people have some desire for change.No criticism to the author. He is way more productive than I will ever be, but xsv does appear to be on the back burner. Open source means the author can spend their time how they like and I am entitled to nothing.\n \nreply"
    ],
    "link": "https://github.com/sharkdp/fd",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A simple, fast and user-friendly alternative to 'find'\n      \n\n[\u4e2d\u6587]\n[\ud55c\uad6d\uc5b4]fd is a program to find entries in your filesystem.\nIt is a simple, fast and user-friendly alternative to find.\nWhile it does not aim to support all of find's powerful functionality, it provides sensible\n(opinionated) defaults for a majority of use cases.Installation \u2022 How to use \u2022 TroubleshootingFirst, to get an overview of all available command line options, you can either run\nfd -h for a concise help message or fd --help for a more detailed\nversion.fd is designed to find entries in your filesystem. The most basic search you can perform is to\nrun fd with a single argument: the search pattern. For example, assume that you want to find an\nold script of yours (the name included netflix):If called with just a single argument like this, fd searches the current dir"
  },
  {
    "title": "Database management in a single PHP file (github.com/vrana)",
    "points": 14,
    "submitter": "ustad",
    "submit_time": "2025-03-17T09:30:02 1742203802",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/vrana/adminer",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Database management in a single PHP file\n      Adminer is a full-featured database management tool written in PHP.\nIt consists of a single file ready to deploy to the target server.\nAdminer Editor offers data manipulation for end-users.https://www.adminer.org/If downloaded from Git then run: git submodule update --initThere are several plugins distributed with Adminer and there are also many user-contributed plugins linked from https://www.adminer.org/plugins/.\nTo use a plugin, simply upload it to adminer-plugins/ next to adminer.php. You can also upload plugins for drivers (e.g. elastic.php) here.Some plugins require configuration. To use them, create a file adminer-plugins.php. You can also specify the loading order here.\n        Database management in a single PHP file\n      "
  },
  {
    "title": "Looking Ahead at Intel's Xe3 GPU Architecture (chipsandcheese.com)",
    "points": 74,
    "submitter": "ryandotsmith",
    "submit_time": "2025-03-19T20:31:13 1742416273",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=43416961",
    "comments": [
      "Looking ahead is challenging. Intel launched the B580 on December 13th, and it sold out within hours. We're still waiting on a restock.\n \nreply",
      "I hope this means they're going to continue to invest in the GPU line.  Competition is good.\n \nreply",
      "Where do they get all this information about things like registers? I thought GPU ISAs were treated like trade secrets?\n \nreply",
      "Intel and AMD GPUs have public documentation and open source drivers.\n \nreply",
      "It seems these chips have all sort of hardcoded and heuristic knowledge literally baked into them. Disappointing.Why can't AI come up with some kind of fast universal computation machine that doesnt have the need for the siliconized version of ifdefs?\n \nreply",
      "Yep, the crowning achievement of machine complexity in recent human history is easily generalized in computational efficacy by effectively markov chain chatbots that were trained on project Gutenberg, reddit comments, and github python and javascript repos.\n \nreply",
      "theres lots of ai other than llms\n \nreply",
      "Do you mean FPGAs?Because fixed silicon inevitably has fixed \"baked in\" choices.\n \nreply",
      "AI doesn't \"create\", it \"modifies\" existing data.\n \nreply",
      "Isn't a collage a creative work?\n \nreply"
    ],
    "link": "https://chipsandcheese.com/p/looking-ahead-at-intels-xe3-gpu-architecture",
    "first_paragraph": ""
  },
  {
    "title": "Orpheus-3B \u2013 Emotive TTS by Canopy Labs (canopylabs.ai)",
    "points": 22,
    "submitter": "Zetaphor",
    "submit_time": "2025-03-19T22:26:39 1742423199",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://canopylabs.ai/model-releases",
    "first_paragraph": ""
  },
  {
    "title": "Fine-tune Google's Gemma 3 (unsloth.ai)",
    "points": 132,
    "submitter": "tomdekan",
    "submit_time": "2025-03-19T16:34:45 1742402085",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=43414235",
    "comments": [
      "I'm interested to know if anyone is using fine-tuning to train a model on proprietary or in-house codebases and documentation.RAG solutions seem to have their limitations, and fine-tuning might be a more effective approach.How much effort is required to  turn code into something one can use for fine-tuning?\n \nreply",
      "I\u2019ve actually found the opposite. At work, we went from a fine-tuned model to a RAG system for internal and external documentation and a generic coding-focused model for code.Fine tuning against in-house code seems like a small gain over a base model and search. It\u2019s unlikely your code is unique and special and big enough that it\u2019s hard to get results from a base model. You\u2019ll be pinned to a certain version of a certain model, and you won\u2019t be able to upgrade to future models nearly as quickly. Of course, you\u2019re also fighting time again on each commit changing the code unless you continually fine tune it.A RAG model might still struggle with a super vague question like \u201cwhere does the foo cal bar with bax set\u201d but it\u2019s unlikely that this would work for fine tuning as well. This is where static code search by symbols really should be used.\n \nreply",
      "RAG definitely is helpful! Fine-tuning imo is extremely powerful but it's still relatively alchemy - technically gpt4, Claude any large model is a finetune of a base model! Reasoning finetuning is also very powerful!Tbh the hardest part is the lifecycle - ie new data, updating, serving etc - that seems to be the biggest issue\n \nreply",
      "Well, why not both? If you've already got a tuned model why not use RAG on that to get even better results? It already knows the big picture, it just needs the details so it doesn't have to hallucinate them.\n \nreply",
      "Yes RAG combined is pretty cool! Fyi I'm planning to add optimized RAG directly into unsloth as well!\n \nreply",
      "We see a lot of this in large orgs! The main issue imo is actually the selection of chat templates - there's a lot of people who use a template for finetuning then totally forget to use it for finetuning.A lot of financial, legal and health companies do fine-tuning! Reasoning finetuning via GRPO is also very powerful since you don't need any cot data in between! Just inputs and outputs!\n \nreply",
      "I would like to see more knowledgeable people with experience talk about this.Is it just a matter of assembling Q/A pairs like: \u201cWhat\u2019s class X?\u201d, \u201cclass X { \u2026 }\u201dDo you really need to do this training on the base model instead, which means you have to fine tune chat on it afterward?How does this work?\n \nreply",
      "Yes qa pairs does work - I found training your dataset concatted with general datasets to work well!\n \nreply",
      "I've not done fine tuning on code bases but I have done other fine tuning.You will generally get better results when you fine-tune the base model on your data.Since you still want to use it with the chat template in the end, you fine-tune the base model with the chat template with your specific data.From there you'll have a lora that knows your data alright, but still doesn't really work for chatting.You take that lora, merge it with the base model. Let's call this the stage model.Then you use mergekit to merge the base model with both the stage model and the chat model. I used the TIES merge method in the past. Now you have your final model.I use vLLM for inference, and needed access to multiple fine tunes on only a single set of hardware. So from that point I go and take the base model and my final model and extract a new lora. I also take the base model and chat model and extract another lora for that. Then I load up vLLM with the base model and as many of the fine tune loras I need + the chat lora.The only time this hasn't worked is if the chat model adds a bunch of new tokens on top of the base model. If I remember right there was an issue with thatThis has worked well for me in the past.\n \nreply",
      "Yes!! The trick is the merging of models weights!!\n \nreply"
    ],
    "link": "https://unsloth.ai/blog/gemma3",
    "first_paragraph": ""
  },
  {
    "title": "The Lost Art of Research as Leisure (kasurian.com)",
    "points": 447,
    "submitter": "altilunium",
    "submit_time": "2025-03-19T10:09:15 1742378955",
    "num_comments": 244,
    "comments_url": "https://news.ycombinator.com/item?id=43410061",
    "comments": [
      "I read a fair amount and I actually do research as leisure all the time, but I can\u2019t stand these elitist and unoriginal think pieces about how much better and cooler this person\u2019s habits are than yours.>> for the leisurely researcher, self-study must include the discipline\u2019s foundational textsI feel like this person has some kind of dark academia aesthetic fetish that they need to hold onto to feel superior to everyone else.I actually deeply agree with the advice in the OP around curiosity but personally I end up implementing it in a totally different way than they do.Lately I\u2019ve found that LLMs are an amazing tool for this free-floating \u201cresearch\u201d- for example \u201cSummarize the top three theories about why suburbs exist and who said them\u201d. The LLM as open ended semantic search engine / research tool is an amazing way to figure out the topology of a subject you want to dive deeper into.I usually work my way down a content ladder from there to podcasts, wikipedia and finally to books.The idea that somehow civilization is ending because of our media consumption habits and that \u201creading source material\u201d will save us comes off as more an aesthetic fantasy than a real-world complaint about today\u2019s culture.I was around before the internet and I\u2019m so thankful that so much more information is accessible now than it was when there were only books.\n \nreply",
      ">> I feel like this person has some kind of dark academia aesthetic fetish that they need to hold onto to feel superior to everyone else.The older I get, the more I'm convinced that people do this less to actually feel superior to others and more as a desperate act of establishing an identity, ANY identity, to simply feel seen and validated in spite of just being yet another person on the planet. This uniquely-human trait seems to run counter to the natural order, where spotted leopards, panthers, elephants, myriad birds all just exist and go about their lives, despite their objective, innate individualities.We are curious creatures lol\n \nreply",
      "Plenty of animals go out of their way to be seen. If it\u2019s a pretty bird it\u2019s most likely a male bird.Animals at play do appear to show off to each other. Orcas wear salmons as hats as if it was a fast fashion trend.I don\u2019t think humans are unique in this regard at all.\n \nreply",
      "These observations are interpretations of behavior viewed through human eyes. (What\u2019s the concept of a \u201chat\u201d to an orca?)Perhaps we interpret their behavior this way because it is our behavior.\n \nreply",
      "As someone who's had quite a few dealings with animals (the family business is a horse farm) my interpretation is that human psychology is basically animal psychology with a \"language instinct\" bolted on as a peripheral.You might very well misinterpret an animal's experience or motives but it is not just mistaken \"anthropomorphism\" but could just be the same kind of misunderstanding you might have about another person's experience or motives.From time to time I see a paper proving that horses or dogs could do something that people who work with horses or dogs always believed they could do or that some bird or mammal has a \"theory of mind\" -- I believe all birds and mammals have a pretty good \"theory of mind\",  it's just hard to do an experiment to prove it.We've had a cardinal that has been coming to our window for a few years that we can't agree on naming \"bad bird\" or \"noisy bird\" that sets up a nest a few yards from a bird feeder and spends all day fighting it's own reflection in the glass.  My interpretation,  which could be wrong,  is that it believes it is a very successful bird that has found an excellent nesting spot and finds meaning in its life by fighting off \"competition\" for its nest -- certainly it does not need to spend a lot of energy foraging and has the time and energy to peck at the window all day.\n \nreply",
      "> I believe all birds and mammals have a pretty good \"theory of mind\", it's just hard to do an experiment to prove itOur pet bird (sun conure) actively tries to lie and mislead when he's doing something naughty. Like he will go into the pantry to steal treats and quickly fly out pretending he wasn't in there when he hears you approaching.This indicates he has some theory of mind. He has to understand there's a difference between what he knows and what we know, otherwise he wouldn't try to hide or obscure his actions.And yes there is research showing/arguing that birds have theory of mind --> https://core.ac.uk/download/pdf/144146926.pdf\n \nreply",
      "I used to have a cat like this. He loved to drink out of the toilet bowl, which he knew he wasn't supposed to do. I would hear him lapping up the water and as I approached the bathroom he would quickly exit, almost but not quite running so as to not look too guilty, head held low and giving me a side eye like he was trying to see if I knew what he was doing in there.",
      "Sun conjures are so smart this makes me smile :)\n \nreply",
      "How do you know the bird just isn't entertaining itself with its own reflection.\n \nreply",
      "The same way you don't know if other humans are even conscious. Empathy.https://en.wikipedia.org/wiki/Problem_of_other_minds\n \nreply"
    ],
    "link": "https://kasurian.com/p/research-as-leisure",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Modernbanc (YC W20) \u2013 Modern and fast accounting software",
    "points": 80,
    "submitter": "gregorygev",
    "submit_time": "2025-03-19T16:50:05 1742403005",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=43414405",
    "comments": [
      "Watching QuickBooks increase in price while decreasing in quality year by year, I keep wondering when the market will finally start to break. I hope this is your break, good luck! I think \"QuickBooks, without the popup ads\" is already a good enough pitch to me.\n \nreply",
      "Appreciate it! We love to hear this! I've been hearing a lot about QBO popup ads recently\n \nreply",
      "Looks nice. I am in finance and have developed reporting/querying tools for accounting teams. The most important thing is catering to Excel. That's just the way it is. What I mention below might already exist and if it does that's great, you're on the right track.1. The ability to input a list of cost centers/accounts and export all journal entries to Excel is a requirement2. An Excel add-in is a better selling point than the built-in spreadsheet feature.\n \nreply",
      "1 is supported\n2 it's a fair point, I think something for us to keep in the back of our mind as we grow.\n \nreply",
      "2 isn't a \"fair point\". It's... basically just correct. With respect, you just don't want to hear it.\n \nreply",
      "Fair point, Excel is the standard, and we\u2019re not trying to replace it. But an embedded sheet lets us do things that an add-in just can\u2019t, like asking AI a question and having it generate a full sheet with supporting data instantly. The experience won't be the same if you have to open that sheet in excel instead of seeing it embedded in the app.We think that\u2019s a powerful complement to Excel, not a replacement. And of course, exporting to Excel/Google Sheets is always an option.\n \nreply",
      "Counterpoint: the product vision that is already on display here is going in a great direction, and colocating a spreadsheet with your accounting app is a great idea. I love the idea of being freed from having to use excel for particular aspects of my accounting flow. You've got the export. People that want to keep their painful workflows can be masochistically happy.This is clearly not an attempt to replace Excel, it's an attempt to accomplish a set of use cases in a better way than clunky export-import flows.The in-app sheets look great, keep going!\n \nreply",
      "I think you can do that in an excel spreadsheet.\n \nreply",
      "You can play Doom in an Excel spreadsheet.\n \nreply",
      "You can probably have an AI agent using a model running in excel playing doom in excel.\n \nreply"
    ],
    "link": "item?id=43414405",
    "first_paragraph": ""
  },
  {
    "title": "Introduction to Deep Learning (CMU) (cmu.edu)",
    "points": 8,
    "submitter": "yamrzou",
    "submit_time": "2025-03-19T23:12:45 1742425965",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://deeplearning.cs.cmu.edu/./S25/index.html",
    "first_paragraph": "In-Person Venue: Giant Eagle Auditorium, Baker Hall (A51)\nAutolab \nPiazza\n\nAutolab \nPiazza\n\n                    \u201cDeep Learning\u201d systems, typified by deep neural networks, are increasingly taking over all the AI\n                    tasks, ranging from language understanding, speech and image recognition, to machine translation,\n                    planning, and even game playing and autonomous driving. As a result, expertise in deep learning is \n                    fast changing from an esoteric desirable to a mandatory prerequisite in many advanced academic \n                    settings, and a large advantage in the industrial job market.\n                 In this course we will learn about the basics of deep neural networks, and their applications to\n                    various AI tasks. By the end of the course, it is expected that students will have significant \n                    familiarity with the subject, and be able to apply Deep Learning to a variety of tasks. They will \n    "
  },
  {
    "title": "The Defer Technical Specification: It Is Time (thephd.dev)",
    "points": 62,
    "submitter": "mattjhall",
    "submit_time": "2025-03-16T14:20:13 1742134813",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43379265",
    "comments": [
      "The author takes great care to rebut a common theme among objections to the proposal - \u201cthis isn\u2019t necessary if you just write code better\u201d. I am reminded of this fantastic essay:> If we flew planes like we write code, we\u2019d have daily crashes, of course, but beyond that, the response to every plane crash would be: \u201conly a bad pilot blames their plane!\u201d> This doesn\u2019t happen in aviation, because in aviation we have decided, correctly, that human error is an intrinsic and inseparable part of human activity. And so we have built concentric layers of mechanical checks and balances around pilots, to take on part of the load of flying. Because humans are tired, they are burned out, they have limited focus, limited working memory, they are traumatized by writing executable YAML, etc.> Mechanical processes are independent of the skill of the programmer. Mechanical processes scale, unlike berating people to simply write fewer bugs.(https://borretti.me/article/introducing-austral#goals)\n \nreply",
      "> The central idea behind defer is that, unlike its Go counterpart, defer in C is lexically bound, or \u201ctranslation-time\u201d only, or \u201cstatically scoped\u201d. What that means is that defer runs unconditionally at the end of the block or the scope it is bound to based on its lexical position in the order of the program.The only reasonable way for defer to behave. Function scoped never made sense to me given the wasted potential. The demonstration with loop and mutex being a good one.\n \nreply",
      "yeah, I've always just extracted the loop body into a new function as a result\n \nreply",
      "Regarding the statements on golang's defer:  \"the defer call is hoisted to the outside of the for loop in func work\"\n\nAstonishing.  Add that to the list of golang head scratchers.  That is one of the biggest \"principle of least astonishment\" violations I've ever seen.Disclaimer: Not a golang hater.  Great language.  Used it myself on occasion, although I remain a golang neophyte.  Put away the sharp objects.\n \nreply",
      "I love the Principle of Least Astonishment, but I first encountered it in the Ruby book and I gave up reading it halfway through because I kept thinking, \"He and I have very different definitions of astonishing...\"\n \nreply",
      "In a way that makes sense though, once you're at a level where you can not only write Ruby, but write books about Ruby, surely very few things would astonish you.\n \nreply",
      "It's incredibly ugly but you could sort of hack in a smaller-scoped defer using anonymous functions: https://go.dev/play/p/VgnprcObPHz\n \nreply",
      "Another cool difference between this and Go\u2019s \u2018defer\u2019, is that it doesn\u2019t allocate memory on the heap. Go\u2019s \u2018defer\u2019 does and it has a small performance cost compared to just calling the .release() or whatever yourself\u2026 shrugsAt least this was the case last I did benchmarks of my Go code. Dno if they changed that.\n \nreply",
      "Does go\u2019s defer allocate on the heap? I thought it would only do that if necessary.\n \nreply",
      "I know they implemented an optimization back in go 1.13. Not sure if that will help.https://github.com/golang/proposal/blob/master/design/34481-...\n \nreply"
    ],
    "link": "https://thephd.dev/c2y-the-defer-technical-specification-its-time-go-go-go",
    "first_paragraph": "\n      \n      \n      March 15, 2025\n    After the Graz, Austria February 2025 WG14 Meeting, I am now confident in the final status of the defer TS, and it is now time.Time for me to write this blog post and prepare everyone for the implementation blitz that needs to happen to make defer a success for the C programming language. If you\u2019re smart and hip like Navi who wrote the GCC patch, the maintainer of slimcc who implemented defer from the early spec and found it both easy and helpful, and several others who are super cool and great, you can skip to the (DRAFT) ISO/DIS 25755 - defer Technical Specification and get started! But, for everyone else\u2026For the big brain 10,000 meter view, defer \u2e3a and the forthcoming TS 25755 \u2e3a is a general-purpose block/scope-based \u201cundo\u201d mechanism that allows you to ensure that no matter what happens a set of behavior (statements) are run. While there are many, many more usages beyond what will be discussed in this article, defer is generally used to cover "
  },
  {
    "title": "Is Dark Energy Getting Weaker? New Evidence Strengthens the Case (quantamagazine.org)",
    "points": 11,
    "submitter": "pseudolus",
    "submit_time": "2025-03-19T22:50:24 1742424624",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43418069",
    "comments": [
      "In my bizarro completely unscientific visualization it makes sense.Say you have a waterbed made out of very stretchy material. It's bound by a hard frame, but the sides of the frame can slowly expand if enough pressure is applied. Without anyone on the bed, the system is in steady-state. The sides can just barely hold the waterbed bladder without expanding.Now let's say a bunch of kids jump onto the waterbed. They make indentations in the surface which cause them to roll towards each other (gravity) but also the waterbed is trying to repel them (dark energy).The extra force of the kids put on the waterbed's surface causes the sides of the waterbed to slowly expand. As the waterbed expands, the repellent force lessens and the expansion slows until it hits steady-state again (or the kids get bored and go outside to play).Since the universe has no hard edge, it could be there is no steady-state, but the repellent force causing it to expand just gets weaker and weaker over time as matter gets more and more diluted.I guess all this hinges on whether it's matter causing the repellent force, or if it just exists outside of matter.\n \nreply",
      "I\u2019ve had metaphysical conversations with people who bring up that the universe is expanding at a faster rate and our ultimate result is to be all alone, with no hope for communicating with other potential civilizations. It\u2019s a sobering reality and makes you question things.And if that turns out to be false, we need to remember the need to be humble and stop pretending we know everything!\n \nreply",
      "If other civilizations are like ours, I have zero faith in them surviving long enough after becoming technologically advanced to communicate with each other.\n \nreply",
      "Is Betteridge\u2019s Law really a law? Some say it might be!I\u2019ll give this a pass because this is a question that is capital-H hard to answer with certainty, so a shift in probability is newsworthy.\n \nreply",
      "I think a question in the headline is fine when the answer is not known. And of course this one even includes to answer the headline with the question. In this case, the question is useful for framing the topic discussed.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/is-dark-energy-getting-weaker-new-evidence-strengthens-the-case-20250319/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesMarch 19, 2025A flight through the Dark Energy Spectroscopic Instrument\u2019s new map of millions of galaxies.\u00a0The map has allowed cosmologists to chart billions of years of cosmic expansion.DESI CollaborationStaff WriterMarch 19, 2025Last spring, a team of nearly 1,000 cosmologists announced that dark energy \u2014 the enigmatic agent propelling the universe to swell in size at an ever-increasing rate \u2014 might be slackening. The bombshell result, based on the team\u2019s observations of the motions of millions of galaxies combined with other data, was tentative and preliminary. Today, the scientists report that they have analyzed more than twice as much data as before and that it points more strongly to "
  },
  {
    "title": "Show HN: Codemcp \u2013 Claude Code for Claude Pro subscribers \u2013\u00a0ditch API bills (github.com/ezyang)",
    "points": 84,
    "submitter": "ezyang",
    "submit_time": "2025-03-13T18:29:19 1741890559",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=43356016",
    "comments": [
      "It'd be really nice if the AI providers just discounted API tokens against your subscriptions so they were in-effect just pre-paying for (ideally a discounted) set amount of tokens.\n \nreply",
      "This requires an MCP-compliant client, for which Claude Desktop seems to be the main (or only?) choice.Note that Claude Desktop can be run on Linux using https://github.com/aaddrick/claude-desktop-debian, which repackages the Windows version to run on Linux (it's an Electron app, so it just needs to stub out the native interface, which seems mostly for cosmetic things).It would be really nice though if the web versions of Claude, ChatGPT, etc. added MCP support directly: this should be achievable with help from a WebExtension and a native binary to proxy messages from the WebExtension to the MCP server.It should also be possible to write such a WebExtension by a third-party (that injects messages in the conversation), although it's possible the LLM companies might block it.\n \nreply",
      "I can report that I tried this setup (Claude Desktop on Linux + codemcp) on the Rust uutils repo asking it to add a \"--repeat\" option to cat to repeat the output N times (without telling it anything else), and it has generated a commit that looks plausible, correctly locating the implementation file and unit test file and changing them in an apparently correct way (other than mangling a commit just before the code changing \\\\n to \\n).It did require to manually enter \"continue\" in Claude's chat (and to approve the use of codemcp at the start), but it otherwise did everything automatically.It seems to work.codemcp automatically produces and commits a single git commit which also contains commit hashes for a bunch of other commits that contain a subset of the changes.\n \nreply",
      "Cline is another client. They even have a marketplace of MCP server extensions which you can use with Cline or Claude Desktop. https://cline.bot/mcp-marketplace\n \nreply",
      "You can build your own MCP client https://modelcontextprotocol.io/quickstart/clientYou will need an ANTHROPIC_API_KEY though.\n \nreply",
      "Related ongoing thread:Hacking Your Own AI Coding Assistant with Claude Pro and MCP - https://news.ycombinator.com/item?id=43410866\n \nreply",
      "Hey there, excited first time user here.\nThanks for creating this!I started playing around with it yesterday evening. Running Claude Desktop under manjaro linux with some tweaks, I did managed to activate codemcp.As I am also quite new with mcp and how to proper use the protocol in tools, I am not sure I did everything correct. I did also install filesystem, git, github and sequential-thinking along side.However, git will not work. The addition of the mcp git server might not be needed? But without it, it did also not workHowever, what it has done so far is mind blowing. I did create a long query the other day about a project idea. This generated a road map, detailed implementation instruction, guidlines, all that is needed to complete the problem. I let it Claude Desktop read in the files with help of codemcp.Claude Dekstop have been working for multiple hours before I seem to have hot some kind of limit. I now get the message to type continue, but it always start the with the same task.And what it has been created is awesome. The frontend is nearly finished, but it lacked to create the startup code first. \nOverall I am blow away what I can do with mcp and esp. with this small lib the author has created here. Code quality is good and event though I had multiple limits, where I needed to type continue, the code is logically make sense. Really good!I also do not yet know how I can continue a old session.P.S.\n@anthropic, If you are reading this. I really do not want to abuse your service. Please, instead of giving me no answer, or beeing stuck in an infinite loop, give me a proper return code and a error, that I reached my limit for the next X minutes or so. I would really love this\n \nreply",
      "I'm surprised you managed to get Desktop running on Linux lol.  You don't need the filesystem/git MCPs alongside codemcp; in fact, it's better not to have them so that Claude consistently uses' codemcp's equivalents to do edits. I'm not sure why codemcp's built-in git support did not work; you can probably find out more by looking in .codemcp/codemcp.log.If you need to start a new chat, it works just fine. Tell Claude what's happened so far and what you want it to do. You can also ask Claude to summarize the old conversation, that's how /compact in claude code works too.\n \nreply",
      "I am using Windsurf and consistently running low Flex credits and was looking into MCP for local file editing.Would be interested in hearing what you learned creating Codemcp, how you find MCP as a protocol, and something else that you found interesting doing your project.\n \nreply",
      "So I have liked the Claude Pro style rate limiting over credits that refresh monthly but mostly because I only get snatches of 1-2 hours while I am on baby leave so I never actually get rate limited. As for learnings, I put a lot of them in my AI Blindspots blog, cuz I did most of codemcp's dev with LLMs\n \nreply"
    ],
    "link": "https://github.com/ezyang/codemcp",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Coding assistant MCP for Claude Desktop\n      Make Claude Desktop a pair programming assistant by installing codemcp.  With\nit, you can directly ask Claude to implement features, fix bugs and do\nrefactors on a codebase on your computer; Claude will directly edit files and\nrun tests.  Say goodbye to copying code in and out of Claude's chat window!codemcp offers similar functionality to other AI coding software (Claude Code,\nCursor, Cline, Aider), but it occupies a unique point in the design space:It's intended to be used with Claude Pro, Anthropic's $20/mo subscription\noffering.  Say goodbye to giant API bills.  (Say hello to time-based rate\nlimits.)It's built around safe agentic AI by providing a limited set of tools\nthat helpful, honest and harmless LLMs are unlikely to misuse, and enforcing\nbest practices like use of Git version c"
  },
  {
    "title": "OpenAI's o1-pro now available via API (platform.openai.com)",
    "points": 68,
    "submitter": "davidbarker",
    "submit_time": "2025-03-19T22:25:14 1742423114",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=43417885",
    "comments": [
      "This is their first model to only be available via the new Responses API - if you have code that uses Chat Completions you'll need to upgrade to Responses in order to support this.Could take me a while to add support for it to my LLM tool: https://github.com/simonw/llm/issues/839\n \nreply",
      "It shouldn't be too bad. The responses API accepts the same basic interface as the chat completion one.\n \nreply",
      "Even the basic interface is different, actually - \"input\" vs \"messages\", no \"max_completion_tokens\" nor \"max_tokens\". That said, changing those things is quite easy.\n \nreply",
      "Oh interesting. I thought they were going to have forward compatibility with Completions. Apparently not.\n \nreply",
      "It does. There are two endpoints. Eventually, all new models will only be in the new endpoint. The data interfaces are compatible.\n \nreply",
      "Pricing: $150 / 1M input tokens, $600 / 1M output tokens. (Not a typo.)Very expensive, but I've been using it with my ChatGPT Pro subscription and it's remarkably capable. I'll give it 100,000 token codebases and it'll find nuanced bugs I completely overlooked.(Now I almost feel bad considering the API price vs. the price I pay for the subscription.)\n \nreply",
      "Remarkably capable is a good description.Shameless plug: One of the reasons I wrote my AI coding assistant is to make it easier to get problems into o1pro.  https://github.com/jbellis/brokk\n \nreply",
      "I wonder what the input/output tokens will be priced at for AGI.\n \nreply",
      "They won't. Your use cases won't be something the AI can't do itself, so why would they sell it to you instead of replace you with it?AGI means the value of a human is the same as an LLM, but the energy requirements of a human are higher than those of an LLM, so humans won't be economical any more.\n \nreply",
      "As far as I'm concerned, all of the other models are a waste of time to use in comparison. Most people dont know how good this model is\n \nreply"
    ],
    "link": "https://platform.openai.com/docs/models/o1-pro",
    "first_paragraph": ""
  },
  {
    "title": "The Collective Ambition Behind Odysseus, a Game-Changing Sci-Fi Larp (mssv.net)",
    "points": 72,
    "submitter": "adrianhon",
    "submit_time": "2025-03-19T17:34:43 1742405683",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=43414992",
    "comments": [
      "The web site of this LARP has good video.[1] They did a very good job on this.\nHere's the prep material for players.[2] It's intense. 48 hours with no breaks.It's hard to scale location-based entertainment. \nDisney tried the Galactic Starcruiser themed hotel, but it was a dud. Too expensive - $5000 or so for 2.5 days. It was a LARP dumbed down to Disney park customer level.\nLots of mini-games, not much coordinated activity.That's about how this sort of thing usually goes. Keeping everybody on script in coordinated activity is tough. I was involved with steampunk conventions, pre-COVID. Those took elaborate prep, but there was no all-player coordinated event.The US has some events like this. Wasteland Weekend. The Society for Creative Anachronism. Military reenactment groups.[1] https://www.odysseuslarp.com/[2] https://www.odysseuslarp.com/blog\n \nreply",
      "There are immersive theater-type events that can scratch the same itch, although they tend to focus much less on participation than LARP events like this. The Starcruiser is probably much closer to poorly-executed immersive theater than live action roleplaying. Really well done immersive theater can be incredible - Sleep No More in NYC is one of the most mindblowing experiences I've ever had (although it closed earlier this year). Legitimately felt like I was stepping into a David Lynch movie every time I went. It only had limited, somewhat improvised audience participation with the actors.In my experience, the best immersive theater experiences find very clever ways to make the atmosphere work. In Sleep No More and other Punchdrunk shows, all of the guests are given masquerade masks to wear, the venue is fogged, and the lighting is dim. The dim and foggy atmosphere hides stuff that would otherwise take you out of the dreamlike 1920s noir setting of the show - that the other guest walking next to you is wearing a graphic tee, for example. The masks cast the audience as a shuffling horde of vengeful spirits haunting the characters for the sins they commit throughout the show - so when you see a big crowd following a character, it doesn't instantly feel at odds with the setting the way I imagine seeing a 5 year old in a Pokemon t shirt on the Starcruiser would.\n \nreply",
      "Obligatory link to the Jenny Nicholson Galactic Starcruiser review[0] since there's really no better overview of the experience.[0]https://www.youtube.com/watch?v=T0CpOYZZZW4\n \nreply",
      "I\u2019m the OP; I went to the Starcruiser later in its run and had a very different experience. Here\u2019s my writeup: https://mssv.net/2023/08/07/star-wars-galactic-starcruiser/\n \nreply",
      "Thanks for linking this, that was a fantastic read.\n \nreply",
      "That video lives rent-free in my head.\n \nreply",
      "Because I see people asking, some groups that do things like this in the US:https://reverie.studio/https://grimmoire.productions/https://www.journeysandtales.net/https://www.drachenfest.us/https://www.jackalope-larp.com/https://www.sinkingshipcreations.com/https://larpcoop.regfox.com/shirefolkOr at lower production values:https://makeascenemn.org/en/http://www.interactiveliterature.org/NEILhttps://2025.beconlarp.com/\n \nreply",
      "I would desperately love to do something like this. Either as a participant or as an organizer. Honestly, if anyone wants help in my local area (denmark) or remote help organizing web stuff or part design/3d sculpting for 3d printers id be happy to donate some time.I had heard of similar things in the UK, fantasy stuff. and also Evermore park in the US which was like an even more ambitious theme-park sized one that had a continuous ongoing story.\n \nreply",
      "\"Nordic Larp\" and the Knutepunkt (https://en.wikipedia.org/wiki/Knutepunkt) conference is close to you. I worked with a guy who organized an earlier battlestar galactica larp: https://petterkarlsson.se/2013/03/19/the-monitor-celestra-ba... and they do things like - rent a medieval castle and larp courtly drama, etc.I'm in the US and they don't do this kind of thing often, but if you're interested by Odyssesus then nordic larp scene will totally be your jam, and honestly I'm jealous.If there's anyone in Seattle doing this kind of thing, say something!\n \nreply",
      "You should look into the Artemis Spaceship Simulator: https://www.artemisspaceshipbridge.com/#/\n(also on Steam)While not nearly as extensive as what's in the article, it's a first step achievable with a small group of friends.\n \nreply"
    ],
    "link": "https://mssv.net/2025/03/19/the-collective-ambition-behind-odysseus-a-game-changing-sci-fi-larp/",
    "first_paragraph": "\u00b7\u00b7Last year, hundreds of players inhabited a spaceship on the run, scrambling to keep one step ahead of the enemy. The sci-fi larp Odysseus was inspired by Battlestar Galactica\u2019s \u201c33\u201c, but where that episode only lasted 45 minutes, Odysseus\u2019 players worked, fought, ate, and slept in-game for fifty non-stop hours.Odysseus is widely recognised as one of the most accomplished larps (live action role playing games) of all time and is the subject of an exhibition at the Finnish Museum of Games. Originally mounted in 2019 for three sold out runs, Odysseus returned in 2024 for another three runs. Over two hundred volunteers worked on the larp, using \u20ac190,000 to transform an elementary school into a sprawling spaceship complete with mess hall, bar, ops room, science and medical bays, jail, and hangar.The gameplay and story design was equally ambitious. Custom open source software was written to power Odysseus\u2019 combat and engineering hyperdrive jumps, RFID-scanners, internal message board, and "
  }
]