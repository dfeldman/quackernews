[
  {
    "title": "Sierpi\u0144ski Triangle? In My Bitwise and? (lcamtuf.substack.com)",
    "points": 91,
    "submitter": "guiambros",
    "submit_time": "2025-05-10T21:42:55 1746913375",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43949238",
    "comments": [
      "I\u2019d like to share some little demos here.Bitwise XOR modulo T: https://susam.net/fxyt.html#XYxTN1srN255pTN1sqDBitwise AND modulo T: https://susam.net/fxyt.html#XYaTN1srN255pTN1sqN0Bitwise OR modulo T: https://susam.net/fxyt.html#XYoTN1srN255pTN1sqDN0SWhere T is the time coordinate. Origin for X, Y coordinates is at the bottom left corner of the canvas.You can pause the animation anytime by clicking the \u2018\u25a0\u2019 button and then step through the T coordinate using the \u2018\u00ab\u2019 and \u2018\u00bb\u2019 buttons.\n \nreply",
      "Munching squares!\n \nreply",
      "Gorgeous!\n \nreply",
      "Just a heads up, all (binary?) logical operators produce fractals. This is pretty well-known[1].[1] https://icefractal.com/articles/bitwise-fractals/\n \nreply",
      "The change rate in binary notation is fractal.\n \nreply",
      "Here's a possibly-too-highbrow explanation to complement the nice simple one in the OP.\"As everyone knows\", you get a Sierpinski triangle by taking the entries in Pascal's triangle mod 2. That is, taking binomial coefficients mod 2.Now, here's a cute theorem about binomial coefficients and prime numbers: for any prime p, the number of powers of p dividing (n choose r) equals the number of carries when you write r and n-r in base p and add them up.For instance, (16 choose 8) is a multiple of 9 but not of 27. 8 in base 3 is 22; when you add 22+22 in base 3, you have carries out of the units and threes digits.OK. So, now, suppose you look at (x+y choose x) mod 2. This will be 1 exactly when no 2s divide it; i.e., when no carries occur when adding x and y in binary; i.e., when x and y never have 1-bits in the same place; i.e., when x AND y (bitwise) is zero.And that's exactly what OP found!\n \nreply",
      "Try this one liner pasted into a Unix shell:  cc -w -xc -std=c89 -<<<'main(c){int r;for(r=32;r;)printf(++c>31?c=!r--,\"\\n\":c<r?\" \":~c&r?\" `\":\" #\");}'&&./a.*\n\nIt used to be cooler back when compilers supported weird K&R style C by default. I got it under 100 characters back then, and the C part was just 73 characters. This version is a bit longer but works with modern clang. The 73-character K&R C version that you can still compile today with GCC is:  main(c,r){for(r=32;r;)printf(++c>31?c=!r--,\"\\n\":c<r?\" \":~c&r?\" `\":\" #\");}\n \nreply",
      "Instructions unclear, machine rooted. :p\n \nreply",
      "Hey, at least it's not doing `curl | bash` like some people's installers do. It's only 109 characters, you can review that right? :-P\n \nreply",
      "Very cool! This basically encodes a quad-tree of bits where every except one quadrant of each subquadrant recurses on the parent quad-tree.The corresponding equivalent of functional programming would be Church bits in a functional quad-tree encoding \\s.(s TL TR BL BR). Then, the Sierpinski triangle can be written as (Y \\fs.(s f f f #f)), where #f is the Church bit \\tf.f!Rendering proof: https://lambda-screen.marvinborner.de/?term=ERoc0CrbYIA%3D\n \nreply"
    ],
    "link": "https://lcamtuf.substack.com/p/sierpinski-triangle-in-my-bitwise",
    "first_paragraph": ""
  },
  {
    "title": "Observations from people watching (skincontact.substack.com)",
    "points": 53,
    "submitter": "jger15",
    "submit_time": "2025-05-10T22:32:01 1746916321",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=43949542",
    "comments": [
      "The author is projecting a lot into the hearts and minds of strangers, based on limited or indeed no interaction with them. These are not scientific observations in any sense. What does the author do to confirm or refute her psychological theories about others? She's very good at telling stories, but these stories feel like fiction, not hard fact.\n \nreply",
      "I used to have similar concerns as you \u2014 how can anyone truly know what other people are like? Unless we\u2019re doing research with the scientific method, we can only speculate unscientifically, right? Without science, what we say is just our belief, not established fact.But how do you explain people who intuitively understand things? Mathematicians, for example, intuitively understand math. Psychologists and experienced authors intuitively understand people. We gain intuition through education and experience, which in turn improve our understanding and sensitivity towards the truth. Expert mathematicians, for example, _can_ have a good sense of whether a theorem is true before they prove it. And in general, people who possess scientific knowledge can intuitively know things.I do agree with your intent, though \u2014 we need to possess humility about the accuracy of our beliefs. The author can\u2019t factually know what other people feel and think without asking them.But we also owe some deference to wisdom. Being wise is like being an expert darts players: you\u2019re better able to throw darts into the bulls-eye than most people. If we develop a wisdom worth trusting, we should trust it.\n \nreply",
      "Maybe she can throw some percentages into her next article on human interaction to make HN happy\n \nreply",
      "Sure, the words she uses to represent her observations is a reflection of her self; in that she describes it in a more creatively descriptive way than, say, a scientist in a laboratory. It's observation, not research; but it's also not judgment which is where I find projection lives.Under that I see someone whose job it is to be keenly observant and to notice these things, otherwise she wouldn't be a very good wedding painter. It probably helps that she seems to be passionate about observing people. Why have someone paint your wedding if the painter isn't able to understand and observe the nuances of human interactions going on?\n \nreply",
      "> it's also not judgmentI disagree. The observations start to become extremely judgmental at around #8 and following.> Why have someone paint your wedding if the painter isn't able to understand and observe the nuances of human interactions going on?Do you think the wedding painter is paid to reproduce the naked reality of the situation, if that happens to be contrary to what the couple wants to see and preserve on canvas forever?\n \nreply",
      "In the extreme, a perception can be very interesting even if it\u2019s delusional.\n \nreply",
      "Delusional Wedding Paintings, coming soon from your neighborhood LLM!\n \nreply",
      "Damn, even the prestigious Journal of Scientific Facts is using LLMs to write its rejections.\n \nreply",
      "She's an artist. It's her job to be slightly irrational. Overall she seems kind.\n \nreply",
      "And how often the artists arrived before the scientists.\n \nreply"
    ],
    "link": "https://skincontact.substack.com/p/21-observations-from-people-watching",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Xenolab \u2013 Rasp Pi monitor for my pet carnivourus plants (github.com/blackrabbit17)",
    "points": 62,
    "submitter": "malux85",
    "submit_time": "2025-05-10T20:58:27 1746910707",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=43948945",
    "comments": [
      "I need this! I am struggling to grow carnivorous plants in New Zealand. I think I am giving them what they supposedly need but I just can\u2019t win.\n \nreply",
      "Where abouts in NZ are you? I'm currently based in Wellington and my Venus fly traps, sundew, and pitcher plants seem to be doing quite well on the windowsill.\n \nreply",
      "Just to reiterate what's already been said - don't use tap water. We have a carnivorous plant expert/dealer local to us and he just collects and uses rainwater, as he says tap water will kill them.Simple waterbutt attached to the drain pipe off the guttering and you get infinite free water for them\n \nreply",
      "Water butt (noun) - British: a large container for collecting or storing a liquid (such as rainwater)This is so much better than \"rain barrel\".\n \nreply",
      "Depends on your tap water. Hetch Hetchy water has worked perfectly for me for years.\n \nreply",
      "Its the water. I have a ro/DI system and use that water. All of the cool low nutrients species have been living for years no problem.\n \nreply",
      "If it\u2019s the water, could it help to let it stand for a while? I do that to get rid of the chlorine.\n \nreply",
      "Many American cities use chloramine, which requires something like Sodium thiosulfate, but then you're left with Ammonia, which may or may not be desired.\n \nreply",
      "I think it's something in our water, I have to give them purified water which I buy.\n \nreply",
      "I had two carnivorous plants so far, but they all died after 3 months or so. I need to learn how to better care for them, cause I think they are so cool.\n \nreply"
    ],
    "link": "https://github.com/blackrabbit17/xenolab",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A monitoring station for carnivorous flora.\n      The Xenolab Rasp Pi Monitor is a cutting-edge, semi-autonomous biosurveillance module engineered for the precise care and observation of exotic carnivorous flora.It's just past 8AM so it's about 50% though simulated sunrise.Main features:I wanted to have some fun with 3D printing and electronics, which gets me away from my normal day job running Atomic Tessellator (https://atomictessellator.com). There are lots of aspects of this project that are wildly impractical and over-engineered and done just for fun.I'm really new at CAD, this was my first time. It's ok, you can laugh at my designs.I used the wonderful tinkercad.com because I found that to be the most intuitive.Model FileModel FileSetting up the RASP Pi 5s and testing some sensorsFresh from the 3D printer!Coated in black becau"
  },
  {
    "title": "US vs. Google amicus curiae brief of Y Combinator in support of plaintiffs [pdf] (courtlistener.com)",
    "points": 320,
    "submitter": "dave1629",
    "submit_time": "2025-05-10T14:15:56 1746886556",
    "num_comments": 536,
    "comments_url": "https://news.ycombinator.com/item?id=43945820",
    "comments": [
      "I'm not sure people understand what the consequences of taking away Google's ad revenue is. If a large enough bank goes under, it takes out not just the bank, but huge sectors of the economy, affecting many more businesses and jobs. That's why the government bailed out the banks when they failed.The same will happen when Google loses its ad revenue. Google is an ad company. By opening up all its trade secret data, it loses its advantage. That will make it lose its core revenue. The end result will be Google collapsing entirely within a few years. Then those component parts people are talking about \"opening up\" will be gone too.Here's a small number of things that will die when Google dies. Can you imagine how the world will be affected when these go away?  - Google Maps\n  - Google Mail\n  - Google Drive\n  - Google Docs\n  - Google Groups\n  - Google Forms\n  - Google Cloud\n  - Google OAuth\n  - Google Search\n  - Google Analytics\n  - Chrome\n  - Android\n  - Android Auto\n  - Fitbit\n  - Google Fi\n  - Google Fiber\n  - Google Flights\n  - Google Translate\n  - Google Pay\n  - Waymo\n\nIn the best case, killing these will force consumers to move to Apple. You wanna talk monopoly? You haven't seen anything yet.Apple has no alternative for much of the Business-focused products, so that will take considerable time for companies to adopt alternatives. But in the meantime, the world will become pretty broken for a lot of companies that depend on these tools. This  will affect many more people than just Google's direct users. The whole web will shrink, and huge swaths of the worldwide economy will disappear. Businesses closing, lost jobs, shrinking economies, lack of services.There are plenty of parties who want to see Google lose or take part of its businesses. But if it's not done extremely carefully, there's a very large stack of dominoes that are poised to fall.\n \nreply",
      "> If a large enough bank goes under, it takes out not just the bank, but huge sectors of the economy, affecting many more businesses and jobs. That's why the government bailed out the banks when they failed.That is why the banks should have been broken up into smaller banks long before we reached that point, and it is why Google should have been broken up long ago.  The only way to prevent the situation you describe is to never allow any single entity to become so important to so many people.It's like planting a tree.  The best time to break up a big company is twenty years ago (before it became so big).  The second-best time is now.\n \nreply",
      "Smaller banks aren't competitive with larger (global) banks.\n \nreply",
      "Smaller anything isn't competitive with larger anything, because the larger guys can always price-dump and bundle their way to full market dominance.That's why we need anti-trust in the first place.\n \nreply",
      "It's important to try and de-googleify your life if only so you don't get caught up in making such an exaggerated sky-is-falling point. All of these could literally vanish tomorrow and the world would go on, they all have their alternatives, some of them arguably superior. For some, the near term pain would be greater than for others -- even just on my personal level I'd be caught with my pants down for email, because while I have over the years moved a lot of email addresses to something at my own domain name, I haven't done it for all of them, and I'd still need to update the forwarding to not-google. Not a huge deal though. A big one you didn't even list that's more important than several you did combined is Youtube, but again there are alternatives.The world would change, but I think quite a bit less than you seem to think. To put it another way, the world was undeniably changed by Google, but the change has been done, and they're no longer necessary to keep the biggest changes from reverting. (I'd be more worried about SBCL development if google flights' backend couldn't find a new home -- the product itself has tons of competition + just going directly to airlines.)In actual reality, of course, these things don't disappear overnight, making the pain of switching much, much less for businesses and individuals heavily dependent on some of these things. Even if \"google collapsing within a few years\" was likely (they have something like a third or more of annual operating expenses saved as cash on hand), a few years is more than enough time. If a business can migrate off of Salesforce or SAP (it can be expensive and time consuming but you can do it!), it can migrate off these.\n \nreply",
      "Yeah. It\u2019s also hard to overstate how many incredible engineers work at Google. Many - perhaps most of them are doing very low value work of adding marginal features nobody cares about to mature products. And in many cases doing so at a glacial pace. Every year thousands of brilliant engineers add ~1m lines of code to Google chrome. And almost nobody notices or cares. As browsers get faster, companies respond by adding more bloat to their websites.If Google suddenly went out of business and 5% of xooglers started companies, we would see a gigantic burst of innovation in computing.\n \nreply",
      "I am sure there are many capable people working at Google, but the exaggerating of their skill level needs to stop. Some leet coder doesn't necessarily deliver better designed systems than any another engineer. And with that, the cult of believing in whiteboard coding interviews also needs to go away.\n \nreply",
      "I\u2019ve worked there. They certainly aren\u2019t all geniuses. But there are a huge number of brilliant engineers there - many of whom spend their lives schleping protobufs around for a fat paycheck.It\u2019s not the whiteboard interviews that makes that possible. It\u2019s the prestige (especially from a few years ago), job security and salary. And the opportunity to work with other smart people. Google has an excellent talent pool.\n \nreply",
      "This list is very telling. Instead of a healthy marketplace of companies competing to sell their software and services, we end up with one monopolist who gives away mediocre products and in return taxes everything you buy (in the form of ad spending), and then annoys you with the same ads. How is this a desirable outcome?\n \nreply",
      "This is a very ungrateful and childish perspective. It assumes that these things exist out of thin air rather than things google has created. Products don\u2019t just appear, they\u2019re built. Nothing is stopping someone from usurping google. Ever hear of oracle, intel, xerox, blackberry or Microsoft?\n \nreply"
    ],
    "link": "https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1300.1.pdf",
    "first_paragraph": ""
  },
  {
    "title": "A critical look at MCP (raz.sh)",
    "points": 324,
    "submitter": "ablekh",
    "submit_time": "2025-05-10T14:37:59 1746887879",
    "num_comments": 189,
    "comments_url": "https://news.ycombinator.com/item?id=43945993",
    "comments": [
      "> the documentation is poorly written (all LLM vendors seem to have an internal competition in writing confusing documentation).This is almost certainly because they're all using LLMs to write the documentation, which is still a very bad idea. The MCP spec [0] has LLM fingerprints all over it.In fact, misusing LLMs to build a spec is much worse than misusing them to avoid writing good docs because when it comes to specifications and RFCs the process of writing the spec is half the point. You're not just trying to get a reasonable output document at the end (which they didn't get anyway\u2014just try reading it!), you're trying to figure out all the ways your current thinking is flawed, inadequate, and incomplete. You're reading it critically and identifying edge cases and massaging the spec until it answers every question that the humans designing the spec and the community surrounding it have.Which means in the end the biggest tell that the MCP spec is the product of LLMs isn't that it's somewhat incoherent or that it's composed entirely of bullet lists or that it has that uniquely bland style: it's that it shows every sign of having had very little human thought put into it relative to what we'd expect from a major specification.[0] https://modelcontextprotocol.io/specification/2025-03-26\n \nreply",
      "DeepSeek's documentation has a different problem, which is that there are spelling errors and weird grammatical constructions everywhere:\"DeepSeek API does NOT constrain user's rate limit. We will try out best to serve every request. However, please note that when our servers are under high traffic pressure, your requests may take some time to receive a response from the server. During this period, your HTTP request will remain connected, and you may continuously receive contents in the following formats...\"The documentation is still mostly easy to read, so it doesn't *really\" matter, but I always thought this was bizarre. I mean, I get the language barrier reading manuals from Chinese products off of Amazon or whatever, but this is a company that does nothing but work with language all day long, and even at one point had the world's leading English-speaking language model. Shouldn't they be able to produce professional-looking documentation without spelling and grammatical errors?\n \nreply",
      "What\u2019s the problem? Can you point out a specific thing you would change from that quote?\n \nreply",
      "Maybe the first sentence? I am guessing they meant \"DeepSeek API does not enforce any rate limit on users.\" would be more appropriate._Constraining the rate 'limit'_ seems like incorrect usage - but it is an a easy mistake to make in a first draft. Review should have caught it.\n \nreply",
      "Certainly a shame if true, there are some really sharp folks at Anthropic and this is an important building block in the emerging ecosystem.\n \nreply",
      "In my experience AI startups are AI maximalists. They use AI for everything they can. AI meeting summarizations, AI search (Perplexity), AI to write code and contracts, AI to perform SEO, AI to recruit candidates, etc. So I 100% believe they would use AI to write specs.\n \nreply",
      "So many bullet points in the documentation!\n \nreply",
      "I can't say whether the original spec was written with AI assistance, but having a cursory look through the commit history [0] it doesn't look like they're just blatantly auto-generating the docs. The git history indicates that they do think about the spec and manually update the docs as the spec changes.[0] https://github.com/modelcontextprotocol/modelcontextprotocol...\n \nreply",
      "I get the distinct feeling the spec was created by llm too. As with the doc, every evidence hints at it.Makes great IPO to tell investor most tour product are already created be averaging out the most likely outcome\n \nreply",
      "It had not occurred to me that the AI coding vendors are basically positively motivated to themselves produce code that is not documented. They want code that is comprehensible to AIs but actively not comprehensible to humans. Then you need their AIs to manipulate it.AI code as the biggest \"lock you in the box\" in programming history. That takes rather a lot of the luster out of it....They'd better be right that they can get to the point that they can fully replace programmers in about two years, otherwise following this siren song will, well, demonstrate why I chose \"siren song\" as my metaphor. If AI code produces big piles of code that are simply incomprehensible to humans, but then the AIs can't handle it either, they'll crash out their own market by the rather disgusting mechanism of killing all their customers, precisely because the customers consumed their service.\n \nreply"
    ],
    "link": "https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp",
    "first_paragraph": "\"MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI\napplications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP\nprovides a standardized way to connect AI models to different data sources and tools.\"\u2015 AnthropicI would like for this to turn out to be a skill issue on my part, and hope that I'm missing something.During the past month,MCP (Model Context Protocol), which would enable\nLLMs to become agents and interact with the world, has really been blowing up. The idea is straightforward: let's standardize an\nAPI for LLM/Agents to interact with the world and how to inform the LLM/Agent about it.Things are moving really fast, and IBM recently released their own \"orthogonal standard\" to MCP\ncalled Agent Communication Protocol (ACP), followed closely by Google\nannouncing Agent2Agent (A2A).MCP Servers and Clients are being built and published daily, and can be "
  },
  {
    "title": "For $595, you get what nobody else can give you for twice the price (1982) [pdf] (computerhistory.org)",
    "points": 115,
    "submitter": "indigodaddy",
    "submit_time": "2025-05-10T18:05:09 1746900309",
    "num_comments": 77,
    "comments_url": "https://news.ycombinator.com/item?id=43947630",
    "comments": [
      "I was just a little kid then, and the C64 was a neat micro, but today I can see some questionable things about their comparison matrix in the ad.Obviously, they are comparing to only the high-end competitors (e.g., Atari 800 but not the 400, and no TI 99/4A which also used their own chips like Commodore touted as a selling point, nor the TRS-80 Color Computer that was intended for home use unlike the Model III business computer).  Buyers who knew the real set of alternatives, at and below the C64's price point, might question why they need 64KB RAM, when the popular lower-priced competitors not shown in the table also did fine games and Basic programming (the main uses of home computers) while costing less money.Then there's structuring \"TV Output\" as a feature of the C64, which they say the TRS-80 Model III doesn't have.  But that's because the TRS-80 has an integrated display monitor, while the C64 includes no display in that price comparison.I don't know what \"'Smart' Peripherals\" are.  But that IBM PC defined industry standard peripheral interfaces for years.The competitors also had obvious strengths not shown.  Want your word processor to be in crisp 80-column text?  A real spreadsheet program?  Math coprocessor?  Better graphics?  Option to upgrade to a hard disk drive?\n \nreply",
      "There was a specific reason with the TI: Tramiel was still smarting over how they screwed him with calculator chips. Meanwhile, their home computer unit was suffering millions of dollars in losses due to greedy mismanagement and the VIC-20 was driving the 99/4A into the ground as a practical loss leader. As far as Tramiel was concerned, even acknowledging the 99/4A's existence was too good for them.Payback, as they say, is a b*tch.\n \nreply",
      "Paperclip (word processor) had an 80 column preview mode, which showed your text in hi-res 80 columns. It seemed like magic at the time and made ten year old me feel like I was performing serious business.\n \nreply",
      "I don't know what \"'Smart' Peripherals\" are.They are computers\u2026for example the C64\u2019s floppy drive had its own CPU. This was also typical for printers\u2026in fact it still is.\n \nreply",
      "The disk drive uses a serial protocol and it actually has 8k of RAM and a 6502 CPU.There's no drive controller in the C64, you send serial commands to the drive and it answers.Due to a hardware bug on the CIA on the 64, the protocol is much slower than it should, which was corrected in later computers, but they messed up with the graphics and a bunch of stuff.\n \nreply",
      "One of Woz's major accomplishments with the Apple II was driving a floppy drive entirely in software from the host computer's CPU, which made the floppy drive and its controller much cheaper.\n \nreply",
      "... and much faster. Like *30 times* faster. Even had the hardware bug juancn and classichasclass discuss not existed with the C64, the Disk II is still much faster.It's flabbergasting how good Woz's designs were. Almost on a whim, he with the Disk II did something no one anywhere in Silicon Valley\u2014anywhere in the world\u2014was doing. Forget about IBM, HP, Shugart, Tandon. Just within Commodore and Tandy, Apple's direct 1977 competitors, there were abundant human and engineering resources to come up with a fast, inexpensive, and reliable floppy drive and controller; Chuck Peddle at Commodore was certainly no average engineer. And yet, Commodore was still unable to do this in 1984.Whether one believes in the reality of the existence of the \"10X developer\", it's hard not to see what Woz did between 1976 and 1978\u2014Integer BASIC, Apple II color graphics, and Disk II\u2014as proof that such a being can exist, even if (as I have written elsewhere) that brilliance straddled the line between optimized and overoptimized. <https://news.ycombinator.com/item?id=41685888>\n \nreply",
      "Actually, the hardware bug was in the VIC-20's 6522 VIA; the CIA 6526 shift register fixes the bug. The (chief) problem on the 64 was the VIC-II stealing processor cycles.\n \nreply",
      ">Due to a hardware bug on the CIA on the 64, the protocol is much slower than it shouldIf that were true then carts like Fastload wouldn't work using the same hardware and same cabling, to load programs many times faster than the stock C64 code.The C64 ROM code worked, but slowly. This was also true for the built-in serial routines. When I got a 2400bps modem for my C64, the computer couldn't keep up, there was garbage coming through,I couldn't upload or download, and it was caused by the slow ROM serial code. I hacked my favorite terminal program with my own assembly language bit-banged serial driver, and then the 2400bps modem worked flawlessly. The same is true for the slow disk drive serial code. To my knowledge, that wasn't caused by any flaw in the hardware, it was just slow driver code.Everyone I knew had a Fastload cartridge, but I was in \"the scene\", so maybe not the average user back then.https://www.lemon64.com/forum/viewtopic.php?t=58317\n \nreply",
      "And Atari, though this is acknowledged in the matrix.Bob Russell once observed the 1541 was the best computer Commodore ever made.\n \nreply"
    ],
    "link": "https://s3data.computerhistory.org/brochures/commodore.commodore64.1982.102646264.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Why the Apple II Didn't Support Lowercase Letters (2020) (vintagecomputing.com)",
    "points": 40,
    "submitter": "colinbartlett",
    "submit_time": "2025-05-10T21:15:04 1746911704",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=43949056",
    "comments": [
      "Back in 1978, I made my own keyboard for a single board 6800 computer I designed, also because I could not afford a keyboard.I went to a surplus store and bought an EBCDIC keyboard for a couple bucks. I unsoldered all the keys from the circuit board. I took a plastic board, and using the old circuit board, drilled holes in it. Inserted the keys in the holes, and then wired it up in an 8x8 grid pattern. The two 8 bits gave 64 possible keys, which was enough, connecting those to an I/O port enabled recognizing which key was down.It worked fine as long as you were careful not to press more than one key at a time.I don't recall what I did with that computer. It's all gone, including the design notebook for it.\n \nreply",
      "Could the code subtract out the previous key for two overlapping key presses, or was it a very strict one at a time?\n \nreply",
      "Many keyboards at the time could not do N-key rollover, including mine :-)Subtracting wouldn't work, as more than one combination of keys would produce the same 16 bits of signal.\n \nreply",
      "No, no, I didn't say N, I said two.If you're holding one key, you have 1 bit set on each bank.  If you press a second key, you now have an additional row bit and/or an additional column bit.  You can tell what the new key is unambiguously.  If it's still one bit on an axis then that bit is correct.  If it's two bits then the new bit is correct.You only get problems when you have three keys held at the same time, or if multiple keys change state simultaneously.\n \nreply",
      "Consider a grid:    -+-+-- A\n     | |\n    -+-+-- B\n     | |\n     C D\n\nThe keys AC and BD pressed simultaneously are indistinguishable from BC and AD.\n \nreply",
      "Yes, I mentioned the timing.But allowing for one key and then a second key before you release the first one is a pretty big improvement for natural typing.",
      "If I had to guess, the sixty or so diodes required for an NKRO matrix might have blown the money budget for the project, about like trying to do that kind of work in an interrupt handler would blow the cycle budget for any interesting program even had it been possible. Typing more slowly is free.Hard to say. I would need to look up component prices for a few years prior to my birth, and it would take me a few minutes to find that archive of 70s Radio Shack catalogs again - though I believe it was actually posted here, so. Of course anyone serious enough to be building an entire computer in those days, brilliant keyboard hack and all, probably wouldn't be sourcing a jellybean part like 1N400x signal diodes one by each...\n \nreply",
      "The keys I used weren't jellybean. They were excellent keys. They were in the surplus bin because EBCDIC keyboards were already obsolete by then.I had very little money at the time, and scrounged for parts.\n \nreply",
      "By \"jellybean\" I meant the sort of small signal diodes one might use to prevent aliasing in a keyboard matrix. I know where I'd have gone to get those in my twenties, but not really how I'd have afforded that many for one project, even at the (very) small discount they might have given me on an order of that size.Unfortunately, now that I've finally reached a point of being able to really effectively use such a resource as that store, in its place now stands a Sonic drive-in. So it goes.\n \nreply",
      "> So my TV Terminal, for accessing the ARPAnet, was uppercase only.I never realized that the most influential personal computer was specifically designed to access what would later become the internet.  That's astounding.(The first internetworking experiments that I can find records of were done as part of the ARPANet project, and some of the protocols and even many of the port numbers we use today in TCP/IP are from ARPANet.)I also had no idea that Woz had built his own CPU out of discrete logic in 01970.  I still haven't done that myself 55 years later!\n \nreply"
    ],
    "link": "https://www.vintagecomputing.com/index.php/archives/2833/why-the-apple-ii-didnt-support-lowercase-letters",
    "first_paragraph": "[Editor\u2019s Note: I recently asked Steve Wozniak via email about why the original Apple II did not support lowercase letters. I could have guessed the answer, but it\u2019s always good to hear the reason straight from the source. Woz\u2019s response was so long and detailed that I asked him if I could publish the whole thing on VC&G. He said yes, so here we are. \u2013Benj]In the early 1970s, I was very poor, living paycheck to paycheck. While I worked at HP, any spare change went into my digital projects that I did on my own in my apartment. I was an excellent typist. I was proficient at typing by touch using keypunches with unusual and awkward special characters \u2014 even though some used two fingers of one hand.I saw a friend typing on a teletype to the six computers on the early ARPAnet. I had to have this power over distant computers too. After building many arcade games on computers, how to build it was obvious to me instantly. I\u2019d create a video generator (as with the arcade games) and display text"
  },
  {
    "title": "Pope Leo XIV: \"AI poses new challenges re: human dignity, justice and labour\" (vatican.va)",
    "points": 124,
    "submitter": "90s_dev",
    "submit_time": "2025-05-10T19:20:03 1746904803",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=43948130",
    "comments": [
      "The relevant quote:> In our own day, the Church offers to everyone the treasury of her social teaching in response to another industrial revolution and to developments in the field of artificial intelligence that pose new challenges for the defense of human dignity, justice and labor.I don't think he's suggesting that AI is inherently bad, but that (like any tool) it can be abused by those with wealth and power in a way that violates human dignity.In fact, one of the problems the previous Pope Leo warned about in \"Rerum Novarum\" was not just the intentional abuse of power through technological advances but the unintentional negative consequences of treating industry as a good in itself, rather than a domain that is in service to human interests.For those who are interested in how this social teaching informed economic systems, check out the concept of distributism, popularized by Hilaire Belloc and G.K. Chesterton.\n \nreply",
      "So I think there are a few subtle things packed into the Pope's statement.First: A lot of Catholic morality derives from the postulate that man was specially made by God and \"in God's image\" which gives man an inherent, unique-among-all-creation dignity.  Because of this, the church is very sensitive to anything which diminishes the \"specialness\" of man, as they fear it will undermine people's reasons for treating each other with respect.  Its part of the reason why they were initially anti-heliocentrism (man wasn't at the center of the universe) and anti-evolution (man wasn't specially created) before coming around due to overwhelming evidence.  The pope is concerned that AI falls into this category of \"challenge to human dignity\" because it gives the sense that man's cognitive abilities are not unique.Second: A lot of Catholic theology regarding the soul is driven by god-of-the-gaps style reasoning.  Indeed, if you look back at Thomas Aquinas's writings on the soul with a modern bio understanding, its painfully clear that his conception of the \"soul\" is just his attempt at understanding metabolism without any solid physics or chemistry.  Obviously no one today says that the soul is in charge of the \"locomotion\" of living things, but up until very recently the one last bastion of unexplained behavior where the religious could justify their belief in the soul was the intellect.  AI is a direct assault on this final motte, as it is concrete evidence that many of the \"intellectual\" outputs of the soul could, at least in principle, have a naturalistic explanation.  (There was plenty of evidence of the intellect being fully naturalistic prior to AI, but it wasn't the kind of irrefutable \"here's a fully natural thing that does the thing you said natural things couldn't do\" evidence).Aquinas: https://www.newadvent.org/summa/1078.htm\n \nreply",
      "> the church is very sensitive to anything which diminishes the \"specialness\" of manNo, it just claims that human souls are created differently than animal souls, and therefore have different properties. It defends this with the same kind of zeal that you defend a round earth with, and for the same reasons.> as they fear it will undermine people's reasons for treating each other with respectI didn't realize the members and minds of the Catholic Church were so united in motive!> anti-evolution (man wasn't specially created)Come on, you know the Catholic Church has never taught this.> A lot of Catholic theology regarding the soul is driven by god-of-the-gaps style reasoning Indeed, if you look back at Thomas Aquinas's writings on the soul with a modern bio understanding--He's one Catholic theologian, even if eminent, out of hundreds who are just as eminent. Why single him out? Where does the Bible say Aquinas is infallible? What a strange strawman.\n \nreply",
      "> The pope is concerned that AI falls into this category of \"challenge to human dignity\" because it gives the sense that man's cognitive abilities are not unique.While this concern certainly exists to some extent in the Church, and may be somewhere in the Pope's thoughts, his explicit comparison to the Industrial Revolution and Rerum Novarum's response to it, and to it as a threat not only to human dignity but also to justice and labor, indicates that a\u2014arguably the\u2014major concern is for it as a potential occasion of and force for material mistreatment.\n \nreply",
      ">A lot of Catholic theology regarding the soul is driven by god-of-the-gaps style reasoning.Can you elaborate on how you arrived at this conclusion? There are multiple Popes that have rejected \u201cgod-of-the-gaps\u201d explanations instead invoking the idea that science helps one learn more about God, not as a rationale for invoking God where we are ignorant.\n \nreply",
      "I did elaborate, in that very post.I read Aquinas and realized that the whole ancient conception of a soul is tied together with the ancient concept of vitalism.  Within vitalism you need something to explain why living matter is different than non-living matter, and that something is the presence of a soul!  Hey presto, add a few layers of philosophy and divine revelation and you arrive at the Christian immortal soul.(In this case \"god of the gaps\" does not refer to the Catholic God himself, but instead it refers specifically to the concept of the soul)\n \nreply",
      "Modern physics and biology really do not conflict with the classical Aristotelian-Thomistic conception of the soul but only describe in further detail the operations of the body.The immateriality of the intellect is included there. Aquinas would say it is only the intellect that can understand a universal concept, which is itself immaterial. This is a qualitative, not a quantitative difference from the capabilities of AI. It is really the reductionists who are guilty of 'woo' here.\n \nreply",
      "I won't deny that there are watered down versions of the Thomistic soul that are agnostic with respect to the physicality or super-naturality of things like digestion, but Aquinas himself is quite clear:> The lowest of the operations of the soul is that which is performed by a corporeal organ, and by virtue of a corporeal quality. Yet this transcends the operation of the corporeal nature; because the movements of bodies are caused by an extrinsic principle, while these operations are from an intrinsic principle; for this is common to all the operations of the soul; since every animate thing, in some way, moves itself. Such is the operation of the \"vegetative soul\"; for digestion, and what follows, is caused instrumentally by the action of heat, as the Philosopher says (De Anima ii, 4).That is to say: we cannot explain things like digestion \"naturally\" as we would require an \"external principle\" that does not exist for living things, instead because they \"move themselves\" they require a super-natural explanation, i.e. the soul.Indeed, Aquinas puts the following as a potential object, which he rebuts> Objection 1: It would seem that the parts of the vegetative soul are not fittingly described\u2014namely, the nutritive, augmentative, and generative. For these are called \"natural\" forces. But the powers of the soul are above the natural forces. Therefore we should not class the above forces as powers of the soul.> On the contrary, The Philosopher says (De Anima ii, 2,4) that the operations of this soul are \"generation, the use of food,\" and (cf. De Anima iii, 9) \"growth.\"\n \nreply",
      "Thomism is very overrated, people seem to lean on it because it sounds smart, and maybe it was for its time, but it relies entirely on Aristotelianism, and such systematic metaphysical philosophies are only as good as the physics they base themselves on, and Aristotle's physics were garbage (not entirely his fault).\n \nreply",
      "The idea of humans having no soul is terrifying, essentially we would all just be p-zombies, functioning entirely as an organic machine does, but with no real truly conscious experience.\n \nreply"
    ],
    "link": "https://www.vatican.va/content/leo-xiv/en/speeches/2025/may/documents/20250510-collegio-cardinalizio.html",
    "first_paragraph": "ADDRESS OF HIS HOLINESS POPE LEO XIV\n TO THE COLLEGE OF CARDINALSSaturday, 10 May 2025[Multimedia]_______________Thank you very much, Your Eminence. Before taking our seats, let us begin with a prayer, asking the Lord to continue to accompany this College, and above all the entire Church with this spirit, with enthusiasm, but also with deep faith. Let us pray together in Latin.Pater noster\u2026 Ave Maria\u2026In the first part of this meeting, there will be a short talk with some reflections that I would like to share with you. But then there will be a second part, a bit like the opportunity that many of you had asked for: a sort of dialogue with the College of Cardinals to hear what advice, suggestions, proposals, concrete things, which have already been discussed in the days leading up to the Conclave.Dear Brother Cardinals,I greet all of you with gratitude for this meeting and for the days that preceded it. Days that were sad because of the loss of the Holy Father Pope Francis and demanding "
  },
  {
    "title": "Reverse engineering the 386 processor's prefetch queue circuitry (righto.com)",
    "points": 113,
    "submitter": "todsacerdoti",
    "submit_time": "2025-05-10T16:23:06 1746894186",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=43946824",
    "comments": [
      "Author here. I hope you're not tired of the 386... Let me know if you have any questions.\n \nreply",
      "I'll never tire of any analysis you do. But if you are taking requests, I'd love two chips.The AMD 29000 series, a RISC chip with many architectural advances that eventually morphed into the K5.And the Inmos Transputer, a Forth like chip with built in scheduling and networking, designed to be networked together into large systems.https://en.wikipedia.org/wiki/AMD_Am29000https://en.wikipedia.org/wiki/Transputer\n \nreply",
      "Those would be interesting chips to examine, if I ever get through my current projects :-)\n \nreply",
      "If you are doing requests, I'd love to see the M68k series analyzed.\n \nreply",
      "Another vote for the 68000 series :)\n \nreply",
      "So Epictronics recently looked at the 386SX, the version with the 16bit external bus, which was slower than the 286 at the same clock. What changed between that and this? Was the major difference the double clock hit on fetch? Or did it have a shorter prefetch queue as well like the 8088?\n \nreply",
      "Never!\n \nreply",
      "At what number of layers is it difficult to reverse engineer a processor from die photos? I would think at some point, functionality would be too obscured to able to understand the internal operation.Do they ever put a solid metal top layer?\n \nreply",
      "I've been able to handle the Pentium with 3 metal layers. The trick is that I can remove metal layers to see what is underneath, either chemically or with sanding. Shrinking feature size is a bigger problem since an optical microscope only goes down to about 800 nm.I haven't seen any chips with a solid metal top layer, since that wouldn't be very useful. Some chips have thick power and ground distribution on the top layer, so the top is essentially solid. Secure chips often cover the top layer with a wire that goes back and forth, so the wire will break if you try to get underneath for probing.\n \nreply",
      "Interesting! What is the reason of 800nm limit? I have successfully photographed my own designs down to 130nm with optical microscobes, though not with metal layer removal. The resolution isn't perfect but fearures were clearly visible.\n \nreply"
    ],
    "link": "http://www.righto.com/2025/05/386-prefetch-circuitry-reverse-engineered.html",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: LoopMix128 \u2013 Fast C PRNG (.46ns), 2^128 Period, BigCrush/PractRand Pass (github.com/danielcota)",
    "points": 32,
    "submitter": "the_othernet",
    "submit_time": "2025-05-10T21:25:21 1746912321",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=43949134",
    "comments": [
      "I'd be very interested to see a state-size capacity analysis in the style of PCG- if you make cut down versions of your generator with reduced state size, say by reducing the word size of all three words of state, how low can you go while still passing PractRand/BigCrush? This gives a much better idea of how \"close\" to danger you are than simply passing.Basically any generator with a 192 bit state can pass BigCrush/PranctRand- even known terrible ones like middle square!https://www.pcg-random.org/posts/too-big-to-fail.html\n \nreply",
      "MurmurHash/SMHasher author here. While I don't doubt this passes BigCrush etc, I do find it very surprising that it does.The state update function is effectively \"a = rotate(a, constant) + b; b = rotate(b, constant) + constant;\" and the output derivation is \"output = (a + b) * constant\".That update function is _barely_ nonlinear, and the output derivation is linear. The output would probably be slightly better as \"(a ^ b) * constant\".The slow_loop thing to guarantee 2^128 period is probably not needed - anyone with an application that cares about a period that high is probably going to choose a more robust generator (a few rounds of hardware-accelerated AES in counter mode is your best bet there)The use of the Z3 prover is neat and I should read up on that more.\n \nreply",
      "I'm not sure that the claim \"the mix function is injective\" is sufficient to support the claim \"The period is at least 2^128\". If the mix is reversible then it forms a permutation on 2^192, but that does not imply that it forms a single cyclic permutation.For example, if f(0) = 1 and f(1) = 0, even if the rest of f's domain is injective the period of f is still only 2 when the initial value is 0 or 1.\n \nreply",
      "I wasn't able to analyze the cyclic behavior of the mix directly, but for the purpose of minimal period only fast_loop and slow_loop are used (as a 128bit counter).\n \nreply",
      "Hello!  Awesome work on your hashing by the way!When iterating I first tried to make fast_loop as random as possible by trying all possible rotational values and then having each option tested in PractRand 1000 times from 256M to 8GB.  There was a wide range of performance by rotation.  47 was the best (for the GR constant) and resulted in the most tests being passed.  The goal was a stronger than normal core for the PRNG that could feed actively into mix.I found the multiplication to be necessary for passing PractRand and BigCrush with the state mixing as posted.I had a variant which assigned mix as rotate(mix,constant) + (mix^fast_mix).  That would pass cleanly with mix directly outputted (with no multiplication) - but I couldn\u2019t get Z3 prover to show injectivity so I decided to go with the posted route.\n \nreply",
      "From the Github repo: \"Created by Daniel Cota after he fell down the PRNG rabbit-hole by circumstance.\" I understand how that can happen.Wondering how this PRNG compares to PCG PRNGs that also claim to be \"simple fast space-efficient statistically good algorithms\" and \"hard to predict\" [0].In any case, it's good to see the excellent work being accomplished in this space.[0] https://www.pcg-random.org/\n \nreply",
      "I just added PGC64 to benchmark.c in the Github.  PCG64 speed looks to be about the same as xoroshiro128++.\n \nreply",
      "Yes, indeed it is. While these PRNGs are all pretty decent, improvements are always welcome. Most impressive is the utter simplicity of the algorithms, including LoopMix128. Definitely makes it easy to incorporate high-quality PRNG functionality in applications.\n \nreply",
      "Also interesting to include PCG for comparison.\n \nreply",
      "Just added to benchmark.c in the Github.  Performance is comparable to xoroshiro128++.\n \nreply"
    ],
    "link": "https://github.com/danielcota/LoopMix128",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A very fast 64-bit PRNG with a 2^128 period, proven injectivity, passing BigCrush & PractRand (32TB).\n      This repository contains LoopMix128, an extremely fast pseudo-random number generator (PRNG) with a guaranteed period of 2^128, proven injectivity, and clean passes in both BigCrush and PractRand (32TB). It is designed for non-cryptographic applications where speed and statistical quality are important.(Note: The code above shows the core logic. See implementation files for full seeding and usage examples.)Thanks to the proven injectivity of the 192 bit state of LoopMix128, parallel streams can be implemented as follows:As running BigCrush and PractRand can behave differently depending on initial seeded states, PractRand was also run multiple times from 256M to 8GB using varied initial seeds (seeding with SplitMix64). Below ar"
  },
  {
    "title": "Fandom Sells Giant Bomb to Independent Creators (about.fandom.com)",
    "points": 6,
    "submitter": "minimaxir",
    "submit_time": "2025-05-11T00:00:14 1746921614",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://about.fandom.com/news/fandom-sells-giant-bomb-to-independent-creators",
    "first_paragraph": "Gaming Content Creators & Long-Time Giant Bomb Staff Jeff Bakalar & Jeff Grubb Taking Full Ownership & Operations of the Gaming Media BrandNews Announced on Stage During Giant Bomb Panel at PAX East ConferenceSan Francisco, CA - May 10, 2025 - Fandom, the world\u2019s largest fan platform, is selling Giant Bomb to long-time Giant Bomb staff and gaming content creators Jeff Bakalar and Jeff Grubb. Financials of the deal were not disclosed. Giant Bomb\u2019s programming, which was paused in order to work out the terms of this deal, will resume as quickly as possible. More details will be communicated soon by Giant Bomb\u2019s new owners. Statement from Fandom\u201cFandom has made the strategic decision to transition Giant Bomb back to its independent roots and the brand has been acquired by longtime staff and content creators, Jeff Bakalar and Jeff Grubb, who will now own and operate the site independently. Fans are at the core of everything we do at Fandom and we\u2019re committed to not only serving them but a"
  },
  {
    "title": "Comparison of C/POSIX standard library implementations for Linux (etalabs.net)",
    "points": 87,
    "submitter": "smartmic",
    "submit_time": "2025-05-10T14:55:52 1746888952",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=43946149",
    "comments": [
      "My own perf comparison: when I switched from Fil-C running on my system\u2019s libc (recent glibc) for yololand to my own build of musl, I got a 1-2% perf regression. My best guess is that it\u2019s because glibc\u2019s memcpy/memmove/memset are better. Couldn\u2019t have been the allocator since Fil-C\u2019s runtime has its own allocator.\n \nreply",
      "What's Fil-C? Okay, found it myself, looks cool: https://github.com/pizlonator/llvm-project-deluge/What's yoyoland? All I can find is an amusement park in Bangkok, and some 1990s-era communication software for Classic Mac OS: https://www.macintoshrepository.org/39495-yoyo-2-1\n \nreply",
      "The Fil-C stack is composed of :- Userland: the place where you C code lives. Like the normal userland you're familiar with, but everything is compiled with Fil-C, so it's memory safe.- Yololand: the place where Fil-C's runtime lives. Fil-C's runtime is about 100,000 lines of C code (almost entirely written by me), which currently has libc as a dependency (because the runtime makes syscalls using the normal C functions for syscalls rather than using assembly directly; also the runtime relies on a handful of libc utility functions that aren't syscalls, like memcpy).So Fil-C has two libc's. The yololand libc (compiled with a normal C compiler, only there to support the runtime) and the userland libc (compiled with the Fil-C compiler like everything else in Fil-C userland, and this is what your C code calls into).\n \nreply",
      "When I was working with Envoy Proxy, it was known that perf was worse with musl than with glibc.  We went through silly hoops to have a glibc Envoy running in an Alpine (musl) container.\n \nreply",
      "Interesting! Will you stick around with the musl build? And if so, why?\n \nreply",
      "Not sure but in likely to because right now I to use the same libc in userland (the Fil-C compiled part) and yololand (the part compiled by normal C that is below the runtime) and the userland libc is musl.Having them be the same means that if there is any libc function that is best implemented by having userland call a Fil-C runtime wrapper for the yololand implementation (say because what it\u2019s doing requires platform specific assembly) then I can be sure that the yololand libc really implements that function the same way with all the same corner cases.But there aren\u2019t many cases of that and they\u2019re hacks that I might someday remove. So I probably won\u2019t have this \u201clibc sandwich\u201d forever\n \nreply",
      "That table is unfortunately quite old. I can't personally say what have changed, but it is hard to put much confidence in the relevance of the information.\n \nreply",
      "Yeah, also it doesn't compare actual implementations, just plain checkboxes. I'm aware of two specific substantial performance regressions for musl: exact floating point printing (it uses Dragon4 but implemented it way slower than it could have been) and memory allocator (for a long time it didn't any sort of arena like pretty much every modern allocator---now it does with mallocng though).\n \nreply",
      "No cosmopolitan, pity.\n \nreply",
      "It really ought to lead with the license of each library. I was considering dietlibc until I got to the bottom - GPLv2. I am a GPL apologist and even I can appreciate that this is a nonstarter; even GNU's libc is only LGPL!\n \nreply"
    ],
    "link": "https://www.etalabs.net/compare_libcs.html",
    "first_paragraph": "A project of Eta Labs.\n\nThe table below and notes which follow are a comparison of some of\nthe different standard library implementations available for Linux,\nwith a particular focus on the balance between feature-richness and\nbloat. I have tried to be fair and objective, but as I am the author\nof musl, that may have\ninfluenced my choice of which aspects to compare.\n\nFuture directions for this comparison include detailed performance\nbenchmarking and inclusion of additional library implementations,\nespecially Google's Bionic and other BSD libc ports.\n\n\n\nBloat comparison\nmusluClibcdietlibcglibc\n\nComplete .a set\n426k\n500k\n120k\n2.0M \u2020\n\nComplete .so set\n527k\n560k\n185k\n7.9M \u2020\n\nSmallest static C program\n1.8k\n5k\n0.2k\n662k\n\nStatic hello (using printf)\n13k\n70k\n6k\n662k\n\nDynamic overhead (min. dirty)\n20k\n40k\n40k\n48k\n\nStatic overhead (min. dirty)\n8k\n12k\n8k\n28k\n\nStatic stdio overhead (min. dirty)\n8k\n24k\n16k\n36k\n\nConfigurable featureset\nno\nyes\nminimal\nminimal\n\n\nBehavior on resource exhaustion\nmusluCl"
  },
  {
    "title": "Eagle Hunters of Kyrgyzstan (atavist.com)",
    "points": 17,
    "submitter": "gmays",
    "submit_time": "2025-05-07T00:51:01 1746579061",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43911152",
    "comments": [
      "I spent a month in Kyrgyzstan last year and also went to the world nomad games. You do see quite a few eagle hunters around the place offering their birds to pose with tourists for tips. People seem to be pretty into it. They put the bird on the person's arm, blindfolded, and encourage them to we their arm up and down so the bird has to flap its wings to maintain balance.Overall I really liked Kyrgyzstan. Definitely a simpler kind of place but just well enough developed to feel comfortable. Amazing opportunities for hiking if you're comfortable just making up you own route with no trail to follow.\n \nreply",
      "Nice pictures, but everthing else was a bit disapointing, so I am going to nitpick.For example I did not learn, what they actually hunt. I initialy assumed by the title they hunt eagles, but they hunt with eagles, but no word of their prey or anything of how they hunt or where the eagle helps with the hunt.I assume by letting the eagle fly to go look for bigger prey and then circeling around that area so the hunter goes there with his rifle.But nothing about that.And one of the titles broke the long word of outdoorsmen into\"outdoorsmen\"Not sure if anyone think that is cool(I assume a bug, on desktop it is not broken), but I literally cannot read like this.\n \nreply",
      "The third sentence of the article states:\" They had spent the past two decades hunting jackals and foxes together, often traveling in Talgar\u2019s run-down Volkswagen Golf, a modern replacement for a horse.\"And then a picture caption adds:\"The Taigan is a breed of sight hound native to Kyrgyzstan. They are used to flush prey, such as foxes, on a hunt.\"\n \nreply",
      "It's falconry with eagles instead. The bird actually catches the prey, no guns involved. The dogs flush out the prey and drive it into a position where the bird can get it. The human trains the animals and manages the hunt.Here's a video about a Texas falconer demonstrating the general process. \nhttps://youtu.be/tWp7XcPc1gg\n \nreply"
    ],
    "link": "https://magazine.atavist.com/the-eagle-hunters-of-kyrgyzstan-world-nomad-games/",
    "first_paragraph": "The Atavist MagazinePublished April 2025In the spring of 2021, Talgar Shaybyrov embarked on a heartbreaking journey. For twenty years, Talgar had hunted with a golden eagle he called Tumara. The two lived at nearly 6,000 feet above sea level, in the quiet town of Bokonbaevo, Kyrgyzstan, where guesthouses and yurt camps line the shore of Issyk Kul, the world\u2019s second-largest saltwater lake. They had spent the past two decades hunting jackals and foxes together, often traveling in Talgar\u2019s run-down Volkswagen Golf, a modern replacement for a horse. Now Talgar was ready to return Tumara to the wilderness, as was the custom among eagle hunters. Doing so allows the birds a chance to mate and be free as they near the end of their long lives. \u201cI have spent so many years with her,\u201d Talgar told me. \u201cI hope she will enjoy her freedom.\u201d\u00a0Kyrgyzstan\u2019s eagle hunters, or burkutchu, carry on a long-standing tradition. For centuries, hunting with an eagle was essential to the region\u2019s nomadic lifestyle"
  },
  {
    "title": "Embracer Games Archive is preserving 75000 video games and needs contributions (embracergamesarchive.com)",
    "points": 143,
    "submitter": "draugadrotten",
    "submit_time": "2025-05-10T11:19:39 1746875979",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=43944789",
    "comments": [
      "From their FAQ> Can I visit the archive?> The archive is for everyone, and we welcome all inquiries. However, we prioritize requests that support gaming culture, gaming history, and the games industry. /../ While the archive is not open to the public, we hope /../The archive is for everyone, but it's only for these groups of people, and it's also not open to the public... Yikes.I'd much rather support initiatives that actually make the games and software required to run them open to the public, like GOG.com and Internet Archive. This feels like a one-way transaction - society puts games in, society gets nothing back.\n \nreply",
      "Better off going to 'myabandonware' which provides games you simply cannot buy anywhere. No nonsense, just games.\n \nreply",
      "This is how most archives work. You can't just have a stroll around for the craic. And there's no point really, because it's not a museum \u2013 most people would be bored quite fast, unless you have a specific reason.\n \nreply",
      "Exactly, and you shouldn't have to visit the archive to play its games in the first place. That's why I mentioned IA and GOG.com in particular - both let you download games remotely.\n \nreply",
      "An archive of physical media serves a very different purpose from a bunch of computers loaded with the games from those media that are available to be played. It's kind of like a film vault that stores original movie film, vs. a place like YouTube that lets you play copies of those movies. And playing the game is not the same as examining and handling the original media (CD/tape/cartridge/manual/inserts/box).Sure, archives often permit you to actually view their original media in person, but that's not always part of their mission. Sometimes the best they'll do is give you copies for a fee. Other times they may lend their original media (or sometimes copies) to qualified entities (spoiler alert: not everybody qualifies). There really is no single \"right\" way for this to work.\n \nreply",
      "why not process digital backups and allow anyone donating to the archive to request those digitally?\n \nreply",
      "That takes time and effort, and has legal implications that the archive might not want to deal with.\n \nreply",
      "That's like saying that a digital scan of the book of Kells is identical to the authentic object.\n \nreply",
      "It is. I have very little respect for artists with sentimentality over such trivial bullshit. Speaking as someone who makes games. The jewel case doesn't matter.It detracts from the thing-itself, like a showroom car that travels everywhere in a hermetically sealed container. That's not a car anymore, it's waste. Just because it gets driven 5 miles a year doesn't change shit. If someones spending money to preserve my games, I'd rather it'd just be a tarball in a well maintained magnetic tape vault available on-line than some aristocratic funko pop collection for a tiny amount of people to pog at in person.\n \nreply",
      "The issue here is that a picture of a book is not a book, a copy of a game is the same game. Barring people with excellent and well-adjusted monitors looking at uncompressed images, the pics we see are (potentially excellent, but still) approximations of the original.With software the notion of an original is meaningless though.\n \nreply"
    ],
    "link": "https://embracergamesarchive.com/",
    "first_paragraph": ""
  },
  {
    "title": "Adventures in Imbalanced Learning and Class Weight (andersource.dev)",
    "points": 28,
    "submitter": "andersource",
    "submit_time": "2025-05-08T13:41:23 1746711683",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43926029",
    "comments": [
      "Nice writeup.\nF1, balanced accuracy, etc. In truth it depends on your problem and what a practical \"best\" solution is, especially in imbalanced scenarios, but Matthews Correlation Coefficient (MCC) is probably the best comprehensive and balanced blind go-to metric, because it guarantees that more portions of the confusion matrix are good [0,1].I made a quick interactive, graphical exploration to demonstrate this in python [2].[0]: https://biodatamining.biomedcentral.com/articles/10.1186/s13...[1]: https://biodatamining.biomedcentral.com/articles/10.1186/s13...[2]: https://www.glidergrid.xyz/post-archive/understanding-the-ro...\n \nreply",
      "MCC also generalizes to multi-class well. I wish it had a better name though. It seems like F1 score has better marketing\n \nreply",
      "Insane how tricky imbalanced stuff gets- I always end up second guessing my metrics  tbh.  You think there's ever such thing as a \"right\" number for real world junk or is it just endless tradeoffs?\n \nreply",
      "I read the article and the take away is that class weights and stratified sampling did not help for the OPs problem.\n \nreply"
    ],
    "link": "http://andersource.dev/2025/05/05/imbalanced-learning.html",
    "first_paragraph": "\nMay 5, 2025\n      A few months ago I was working on an image classification problem with severe class imbalance - the positive class was much rarer than the negative class.As part of the model tuning phase, I wanted to explore the impact of class imbalance and try to mitigate it. A popular \u201coff-the-shelf\u201d solution to imbalance is weighting classes in inverse\nproportion to their frequency - which didn\u2019t yield an improvement. This happened to me several times in the past, and other than basic intuition I couldn\u2019t trace the theory of where this weighting comes from (maybe I didn\u2019t try hard enough).So, I decided to finally try to reason about class weighting in an imbalanced setting from first principles. What follows is my analysis. The TL;DR is that for my problem, I was convinced that class weighting probably doesn\u2019t matter too much.It\u2019s an interesting analysis and was a fun rabbit-hole to dive into, but makes a lot of assumptions and I\u2019d be careful not to overgeneralize from this.\\(\\n"
  },
  {
    "title": "The State of SSL Stacks (haproxy.com)",
    "points": 19,
    "submitter": "zdw",
    "submit_time": "2025-05-07T04:06:10 1746590770",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43912164",
    "comments": [
      "I have no idea this happened, but after reading this article my main takeaway was that OpenSSL shot themselves in the foot. Is this a fair assessment? I mean the excessive locking just stands out to be ill-advised for this performance-sensitive piece of code.\n \nreply",
      "> implement sophisticated core-awareness strategies that maximize single-node efficiency by distributing cryptographic workloads across all available CPU coresLLM slop?\n \nreply",
      "This whole article reads like it was generated from an LLM prompt yeah\n \nreply"
    ],
    "link": "https://www.haproxy.com/blog/state-of-ssl-stacks",
    "first_paragraph": "HAProxy's website uses cookies. By proceeding, you consent to our cookie usage. Please see our Privacy Policy and Cookie Policy for cookie usage details and instructions on how to disable cookies.HAProxyConf 2025 - Register today!In this hands-on webinar, we'll demonstrate how to transform HAProxy into a sophisticated AI-aware gateway using Stream Processing Offload Engine (SPOE).\n                        Manage, secure, and observe all your application traffic \u2014 in any environment \u2014 with a unified platform.\n                    \n                        Enterprise-class features, services, and premium support.\n                    \n                        Manage all of your HAProxy Enterprise instances from a single, graphical interface or directly through its API.\n                    \n                        A globally distributed application delivery network, or ADN, with turnkey services at massive scale.\n                    \n                        Powerful plug-and-play appliance. Pe"
  },
  {
    "title": "Arduino is at work to make bio-based PCBs (arduino.cc)",
    "points": 25,
    "submitter": "PaulHoule",
    "submit_time": "2025-05-08T15:30:30 1746718230",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.arduino.cc/2025/04/22/arduino-is-at-work-to-make-bio-based-pcbs/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Code Claude Code (github.com/rvca212)",
    "points": 94,
    "submitter": "sean_",
    "submit_time": "2025-05-10T14:47:12 1746888432",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=43946066",
    "comments": [
      "Fun project with a nice compact code base. Agreed that ad-hoc scripting agents can be very powerful.Aider has had support for scripting [0] in python or via the command line for a long time.I made a screencast [1] recently that included ad-hoc bash scripting aider as part of the effort to add support for 130 new programming languages. It may give a flavor for how powerful this approach can be.[0] https://aider.chat/docs/scripting.html[1] https://aider.chat/docs/recordings/tree-sitter-language-pack...\n \nreply",
      "Paul!!!I first made a scripting tool of aider that I didn't open source: (https://cloudcoding.ai)Scripting with aider gives lower level control but this is also its shortcoming to why I prefer scripting Claude code.Claude code is like a better architect mode and people want higher and higher levels of abstraction away from the coding and more towards the vibing.\n \nreply",
      "Is \"Code Claude Code\" a play on \"Bob Loblaw\"?https://arresteddevelopment.fandom.com/wiki/Bob_Loblaw\n \nreply",
      "I\u2019d guess Run Forest Run.\n \nreply",
      "Or for the younger generation Go Diego Go\n \nreply",
      "Ha! I prefer this one\n \nreply",
      "I was on Go Dogs Go!\n \nreply",
      "I never heard of Bob Loblaw, so no.It's more a play on the phrase 'Code the thing that Codes the thing'\n \nreply",
      "If anyone else was curious to see the source, it\u2019s hard to find due to the name collision on Google.Here it is - https://github.com/RVCA212/codesys\n \nreply",
      "Building a product brewed in the alchemy of current-day LLMs is how we end up with new langchains.\n \nreply"
    ],
    "link": "https://github.com/RVCA212/codesys",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          A Python SDK for interacting with the Claude CLI tool.the most effective way I've found of using this sdk is by mimicing my actual workflow with claude code which I've found extremely effective.the workflow is simple: plan the task by exploring the codebase, then implement the planParameters:Run Claude with the specified prompt.Parameters:Returns:Run Claude with specific allowed tools.Parameters:Returns:MIT"
  },
  {
    "title": "Microsoft Teams will soon block screen capture during meetings (bleepingcomputer.com)",
    "points": 114,
    "submitter": "josephcsible",
    "submit_time": "2025-05-10T19:39:57 1746905997",
    "num_comments": 176,
    "comments_url": "https://news.ycombinator.com/item?id=43948291",
    "comments": [
      "LOL\nAnother stupid feature (enforced by regulations/law/policies) that has no real world use, besides making us users angry :-(Like Google collecting all of our location history for their own usage, but not allowing us to see it via web anymore (only on mobiles), or having the android dialer not allowing us to record our own phone conversation (easily circumvented), or movie/music/game publishers not allowing us to backup our own media\u2026 you get the point.All these are due to laws and regulations that are there to protect the big companies and don\u2019t take into consideration users and the common sense ;-)\n \nreply",
      "> All these are due to laws and regulations that are there to protect the big companies and don\u2019t take into consideration usersThis feature is not due to laws and regulations.The user in this case is the presenter who clicks the button to enable screenshot protection on their meeting. This is Microsoft trying to deliver a feature their users want, not laws and regulations making them do something their users don\u2019t want.\n \nreply",
      "But it\u2019s literally the dumbest feature ever.  There\u2019s absolutely nothing preventing a user from pulling out their phone and taking a picture of any slide they want. Or having a camera recording the whole session out of view of their webcam.It is security theater at its peak.\n \nreply",
      "There are two kinds of people in the world, those who completely misunderstand the value of friction, and those who depend on friction too heavily; GP clearly falls into the former group.This feature provides value because it increases friction. It won't stop really determined and motivated users from leaking, but it'll make leaks, especially accidental leaks / those due to hacks, a lot less common.The same applies to DRM, \"security by obscurity\", social media post editing / deletion, dark patterns, loss leaders, promotions and coupons, the list is endless.If your user is a perfectly rational being with infinite time and infinite tech savviness, the proverbial \"spherical cow\", those features make 0 sense. Just like spherical cows, though, those users don't actually exist, and so friction matters.That doesn't mean friction is infinite, though. It's too easy to overestimate it and fall into the trap of thinking that \"users won't bother doing this, it doesn't matter if this combination of actions loses us money, it's too bothersome\", and then get very surprised very quickly.\n \nreply",
      "It's not pure security theater, there are a few clear gains for those who care about such things:* Naive screencaps are much less traceable to the leaker than a naive photo is. Yes, someone can strip out EXIF data, but we've seen over and over again that they generally don't. And even without EXIF a naive framing on the photo is more likely to expose information about the location or identity of the person who took it.* A photo of a webinar is going to (barring serious postprocessing) look much less official and be less legible than a screenshot, so the use cases for illicit captures are going to be fewer. Few people are going to try to take a phone photo of the top-secret meeting and use the slide in their next team all-hands, but many might forget the rules and than snap a screenshot really quickly for later use.* Just having the ability to block the easy method of screen captures helps avoid cases where the person doing the capturing isn't actively malicious, just ill-informed. If a normal employee attempts a screenshot and is reminded they're not supposed to do that, they're not going to pull out their phone to take a photo, they're going to say \"oops\" and move on.Yeah, there are threat models that won't be stopped here, but most of corporate InfoSec is wrapped up in protecting against pretty lame threat models that would benefit from this\u2014mostly uninformed/ignorant employees screwing up without intending to be a threat.\n \nreply",
      "> Yeah, there are threat models that won't be stopped hereLike running windows in a VM or using an HDMI capture card.  And are they going to break running teams meetings when using moonlight etc. with this?  If you are OBS capturing during the meeting does it get blacked out or just breaks your recording?\n \nreply",
      "You don't need to elaborate on mechanisms for bypassing because you're already imagining a threat actor that is out of scope.This is primarily about blocking accidental leaks by regular employees who were asked to not record but ignored it. This kind of reuse of content happens all the time in companies of any significant size and isn't entirely stopped by simple requests or watermarks. This tool gives companies one more option to protect against this very lame and boring but also very real threat.\n \nreply",
      "And also gives legal teams more foundation to stand on, bypassing this isn't trivial so it shows real intent\n \nreply",
      "Nah, this would stop a lot of threats.I'm an example of that threat. I'm a freelancer who often has video calls with new clients. Sometimes I surreptitiously screen cap demos or presentations. It would be very difficult to use a phone that way without breaking the conversational flow.Other supposed workarounds would require much more preplanning. Like I'd need to know that there was something worth capturing.\n \nreply",
      "RDP into computer that has meeting running and then screenshot from the external computer running RDP .\n \nreply"
    ],
    "link": "https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-will-soon-block-screen-capture-during-meetings/",
    "first_paragraph": ""
  },
  {
    "title": "How much information is in DNA? (dynomight.substack.com)",
    "points": 51,
    "submitter": "crescit_eundo",
    "submit_time": "2025-05-08T17:42:33 1746726153",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=43928942",
    "comments": [
      "The article massively undersells the information content of the genome in several key ways. A non-comprehensive list of these (before my morning coffee forgive me) includes:- DNA methylation (https://en.wikipedia.org/wiki/DNA_methylation)- Interactions of alleles (what article refers to as the \"two versions of each base pair\")- Duplications, deletions, inversions, and other structural variations (https://www.genome.gov/genetics-glossary/Structural-Variatio...)- Physical proximity interactions in 3-dimensional space (https://cmbl.biomedcentral.com/articles/10.1186/s11658-023-0...)- Combinatorial effect (massive) of different alleles in complex systemsOverall, it's not sensible to compare a linear sequence of bits, like a CD (sibling comment) or DVD (the article), to the linear sequence of the genome and conclude that their information content, based on length alone, is in any way comparable.\n \nreply",
      "You put my reaction to this in much more educated terms. I\u2019ve always felt that thinking of DNA as bits was a bit simplistic. Just because we store information as bits it doesn\u2019t mean that nature does.Not that it means they can\u2019t be right, but the author also doesn\u2019t seem to have any particular expertise in genetics. Their ideas need to survive a lot more criticism by people who know what they\u2019re talking about before you could start to see them as convincing.\n \nreply",
      "He does mention structual interactions as well as duplications/deletions/inversions. I would argue methylation is more like an annotation of DNA and not part of the DNA itself, but that's a matter of opinion.In the end, the author literally says: \"nobody knows\". Yes, you cannot compare a linear sequence of bits to a macromolecule that interacts structurally with its environment, and the author does not make that claim. The question he tries to answer is: how much data is needed to re-create a similar macromolecule that interacts in a similar way. His main point, in which you both agree: only the exons are surely not enough because the encoded proteins are just a (small?) part of how DNA interacts.\n \nreply",
      "Exons are almost like functions where as a gene is almost like a class definition. In different tissues in the body a gene might be alternatively spliced to lead to different protein isoforms. In effect, making use of only a subset of available functions in the class depending on certain input parameters or how the class is called.\n \nreply",
      "This is a Star Trek version of the subject, in that it is pure technobabble which happens to mention a few real terms.\n \nreply",
      "I find that even if this just provides a lower bound it is still an interesting piece of information.\n \nreply",
      "But all of those emergent effects are accounted for in the DNA sequence [1], so the estimate is fine.1. Maaaaybe you could make a case for DNA methylation, but that still requires some DNA signatures so ...\n \nreply",
      "A much more detailed and thoughtful (and peer reviewed) take on the same question from my colleague Jussi Taipale: https://www.embopress.org/doi/full/10.15252/embj.201696114\n \nreply",
      "> But mitochondrial DNA is tiny so I won\u2019t mention it again.Which is a bummer because it is circular.  There is also a point on the strand where two separate genes overlap.  The end of one has the same code as the beginning of another.So even DNA has it's own native compression scheme.\n \nreply",
      "Information can only be defined with respect to states where you 1. Can tell (or could in theory tell) the difference and 2. Care about the difference between states. The differences you care about, and the ones you don't, are baked in whenever you use any definition of information.It doesn't matter much, unless you use it to sneak in what you think we should care about, or use it to make philosophical arguments whose circularity is carefully hidden.\n \nreply"
    ],
    "link": "https://dynomight.substack.com/p/dna",
    "first_paragraph": ""
  }
]