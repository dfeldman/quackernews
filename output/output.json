[
  {
    "title": "We Will Not Be Divided (notdivided.org)",
    "points": 285,
    "submitter": "BloondAndDoom",
    "submit_time": "2026-02-28T00:54:53 1772240093",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=47188473",
    "comments": [
      "This is why you can't gatekeep AI capabilities. It will eventually be taken from you by force.It's time to open-source everything. Papers, code, weights, financial records. Do all of your research in the open. Run 100% transparent labs so that there's nothing to take from you. Level the playing field for good and bad actors alike, otherwise the bad actors will get their hands on it while everyone else is left behind. Start a movement to make fully transparent AI labs the worldwide norm, and any org that doesn't cooperate is immediately boycotted.Stop comparing AI capabilities to nuclear weapons. A nuke cannot protect against or reverse the damage of another nuke. AI capabilities are not like nukes. General intelligence should not be in the hands of a few. Give it to everyone and the good will prevail.Build a world where millions of AGIs run on millions of gaming PCs, where each AI is aligned with an individual human, not a corporation or government (which are machiavellian out of necessity). This is humanity's best chance at survival.reply",
      "> This is why you can't gatekeep AI capabilities.What is why?You never actually say that part, unless it's \"It will eventually be taken from you by force\" which doesn't seem applicable to this situation or this site?reply",
      "Open Source here is not enough as hardware ownership matters. In an open source world, you and I cannot run the 10 trillion param model, but the data center controllers can.reply",
      "I agree. We will need hardware ownership as well eventually. But the earlier you open-source, the more you slow down the centralization because people will be more likely to buy hardware to run stuff at home and that gives hardware companies an opening to do the right thing.reply",
      "I'd prefer something akin to the Biological Weapons Treaty which prohibits development, production and transfer. If you think it isn't possible you have to tell me why the bioweapons convention was successful and why it wouldn't be in the case of AI.reply",
      "> bioweapons convention was successfulWas it successful? The jury is still out.reply",
      "Don't compare general intelligence to bioweapons. A bioweapon cannot defend against or reverse the effects of another bioweapon.reply",
      "When have US corporations (or simply \"the US\" really) ever done the right thing for humanity?reply",
      "I hope Anthropic will survive this. If they don\u2019t it will just be perfect proof that you cannot be both moral and successful in the US.reply",
      "Who cares whether the \"company\" survives? I've seen this movie. A few of them in fact. We're on the chopping block here, lol.reply"
    ],
    "link": "https://notdivided.org",
    "first_paragraph": "Open LetterBe the first to sign this letter.\n        Current and former employees of Google and OpenAI are invited to sign.\n        You may sign anonymously. All signatures are verified before being published.\n      Verification MethodEnter the work email you'll use to sign into the Google Form. Used only to match your verification \u2014 never published or shared.Only used for verification. Never published or shared.So we can follow up during verification. Not published.Photo of work badge, offer letter, internal screenshot, etc. Redact sensitive info. Max 10 MB. Only seen by reviewers.The goal of this letter is to find common ground. The signatories likely have a diverse set of views. The current situation with the DoW is so clear-cut that it can bring together a very broad coalition. Signing this letter doesn't mean you think it's the only thing that needs to be done, just that you agree with the bottom line.This letter was organized by a few citizens who are concerned about the potentia"
  },
  {
    "title": "Statement on the comments from Secretary of War Pete Hegseth (anthropic.com)",
    "points": 89,
    "submitter": "surprisetalk",
    "submit_time": "2026-02-28T01:20:10 1772241610",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=47188697",
    "comments": [
      "Anthropic's stance here is admirable. If nothing else, their acknowledgement of not being able to predict how these powerful technologies can be abused is a bold and intelligent position to take.reply",
      "This an extremely polite \u201cfuck you, make me\u201d. It\u2019s good to see that they have principles, and I suspect strongly that Anthropic will come out on top here if they stand firm.reply",
      "Just don\u2019t help big brother see more. If you job leads to such results, think hard whether that\u2019s what you should be doing.reply",
      "Doesn't NSA have a backdoor to all these companies by default? I could have sworn I read somewhere years ago that the government demands a backdoor to all US companies if they can't get in on their own.reply",
      "Stay strong Anthropic. We just like you more for this.reply",
      "Is this the first company to actually face to face stand up to the current administration?reply",
      "No, a few law firms targeted by EOs fought them in court last year and won.reply",
      "> Allowing current models to be used in this way would endanger America\u2019s warfighters and civilians.That\u2019s okay! The use of autonomous weapons is only risky for the civilians of the country you\u2019re destabilizing this week!reply",
      "This letter is a public part of the negotiation process. It shouldn't be surprising that they are primarily using arguments that are, at least on the face, \"patriotic\".reply",
      "From the statement:\"Secretary Hegseth has implied this designation would restrict anyone who does business with the military from doing business with Anthropic. The Secretary does not have the statutory authority to back up this statement. Legally, a supply chain risk designation under 10 USC 3252 can only extend to the use of Claude as part of Department of War contracts\u2014it cannot affect how contractors use Claude to serve other customers.In practice, this means:If you are an individual customer or hold a commercial contract with Anthropic, your access to Claude\u2014through our API, claude.ai, or any of our products\u2014is completely unaffected.\nIf you are a Department of War contractor, this designation\u2014if formally adopted\u2014would only affect your use of Claude on Department of War contract work. Your use for any other purpose is unaffected.\"reply"
    ],
    "link": "https://www.anthropic.com/news/statement-comments-secretary-war",
    "first_paragraph": ""
  },
  {
    "title": "I am directing the Department of War to designate Anthropic a supply-chain risk (twitter.com/secwar)",
    "points": 1018,
    "submitter": "jacobedawson",
    "submit_time": "2026-02-27T22:31:18 1772231478",
    "num_comments": 842,
    "comments_url": "https://news.ycombinator.com/item?id=47186677",
    "comments": [
      "The disconnect here for me is, I assume the DoW and Anthropic signed a contract at some point and that contract most likely stipulated that these are the things they can do and these are the things they can't do.I would assume the original terms the DoW is now railing against were in those original contracts that they signed. In that case it looks like the DoW is acting in bad faith here, they signed the original contact and agreed to those terms, then they went back and said no, you need to remove those safeguards to which Anthropic is (rightly so) saying no.Am I missing something here?EDIT: Re-reading Dario's post[1] from this morning I'm not missing anything. Those use cases were never part of the original contacts:>  Two such use cases have never been included in our contracts with the Department of WarSo yeah this seems pretty cut and dry. Dow signed a contract with Anthropic and agreed to those terms. Then they decided to go back and renege on those original terms to which Anthropic said no. Then they promptly threw a temper tantrum on social media and designated them as a supply chain risk as retaliation.My final opinion on this is Dario and Anthropic is in the right and the DoW is acting in bad faith by trying to alter the terms of their original contracts. And this doesn't even take into consideration the moral and ethical implications.[1]: https://www.anthropic.com/news/statement-department-of-warreply",
      "The administration's approach to contracts, agreements, treaties and so on could be summed up as 'I am altering the deal. Pray I do not alter it further.'The basic problem in our polity is that we've collectively transferred the guilty pleasure of aligning a charismatic villain in fiction to doing the same in real life. The top echelons of our government are occupied by celebrities and influencers whose expertise is in performance rather than policy. For years now they've leaned into the aesthetics of being bad guys, performative cruelty, committing fictional atrocities, and so forth. Some MAGA influencers have even adopted the Imperial iconography from Star Wars as a means of differentiating themselves from liberal/democratic adoption of the 'rebel' iconography. So you have have influencers like conservative entrepreneur Alex Muse who styles his online presence as an Imperial stormtrooper. As Poe's law observes, at some point the ironic/sarcastic frame becomes obsolete and you get political proxies and members of the administration arguing for actual infringements of civil liberties, war crimes, violations of the Constitution and so on.reply",
      "The writeup here[1] was pretty clear to me.> *Isn\u2019t it unreasonable for Anthropic to suddenly set terms in their contract?* The terms were in the original contract, which the Pentagon agreed to. It\u2019s the Pentagon who\u2019s trying to break the original contract and unilaterally change the terms, not Anthropic.> *Doesn\u2019t the Pentagon have a right to sign or not sign any contract they choose?* Yes. Anthropic is the one saying that the Pentagon shouldn\u2019t work with them if it doesn\u2019t want to. The Pentagon is the one trying to force Anthropic to sign the new contract.[1]: https://www.astralcodexten.com/p/the-pentagon-threatens-anth...reply",
      "I just wish there was a stronger source on this. I am inclined to agree you and the source you cited, but unfortunately> [1] This story requires some reading between the lines - the exact text of the contract isn\u2019t available - but something like it is suggested by the way both sides have been presenting the negotiations.I deal with far too many people who won't believe me without 10 bullet-proof sources but get very angry with me if I won't take their word without a source :(reply",
      "That's a fair point, but I think Dario's quote in GP corroborates ACX's story quite well:> \"Two such use cases have never been included in our contracts with the Department of War...\"reply",
      "> \"Two such use cases have never been included in our contracts with the Department of War...\"While I agree with Anthropic's position on this regardless, the original contract wording does matter in terms of making either the government look even more unreasonable or Anthropic look a little less reasonable.The issue is a subtle ambiguity in Dario's statement: \"...have never been included in our contracts\" because it leaves two possibilities: 1. those two conditions were explicitly mentioned and disallowed in the contract, or 2. they weren't in the contract itself - and are disallowed by Anthropic's Terms of Service and complying with the ToS is a condition in the contract (which would be typical).If that's the case, then it matters if the ToS disallowed those two uses at the time the original contract was signed, or if the ToS was revised since signing. Anthropic is still 100% in the right if the ToS disallowed these uses at the time of signing and the ToS was an explicit condition of the contract, since contracts often loop in the ToS as a condition while not precluding the ToS being updated.However, if the ToS was updated after contract signing and Anthropic added or expanded the wording of those two provisions, then the DoD, IMHO, has a tiny shred of justification to complain and stop using Anthropic. Of course, going much further and banning the entire US government (and contractors) from using Anthropic for any use, including all the ones where these two provisions don't matter - is egregiously punitive and shitty.While the contract wording itself may be subject to NDA, it would be helpful if Anthropic's statements could be a bit more precise. For example, if Dario had said \"have always been disallowed in our contracts\" this ambiguity wouldn't exist.reply",
      "I'm in a weird spot where I do agree with your assessment of the core claim. But putting that aside, in the world where the DoW's claim _is_ correct -- I think you don't have any choice other than to designate them a supply chain risk.Disregarding who is right or wrong for a moment, if the DoW are right (which I'm not personally inclined to believe, but we're ignoring that for the moment) -- how else can they avoid secondhand Claude poisoning?Supposing they really want to use their software for things disallowed by Claude's (now or future) ToS, it seems like designating it a supply chain risk is the only way they can ensure that their contractors don't include Claude (either indirectly as a wrapper or tertially through use of generated code etc)reply",
      "It does not matter. If Anthropic had been precise in this narrow way, there would have been some other nitpick to raise.You're trying desperately to find a way that things can be at least a little normal, and I really do get it. It would be great if such a way existed. But it doesn't. I recommend you take a social media break like I'm about to, take the time you need to mourn the era of normal politics, and come back with a full understanding that the US government is not pursuing normal policy objectives with bad decisions. They hate you and they hate me for not being on their side, and their primary goal is to ensure that we're as miserable as they can make us.reply",
      "Also, Trump's own words complaining about being forced to stick to Anthropic's terms of service:> The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War, and force them to obey their Terms of Service instead of our Constitution.reply",
      "His M.O. is to accuse his opponent of the very thing he is doing. It\u2019s the party of bad-faith.reply"
    ],
    "link": "https://twitter.com/secwar/status/2027507717469049070",
    "first_paragraph": "We\u2019ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.Help Center\nTerms of Service\nPrivacy Policy\nCookie Policy\nImprint\nAds info\n      \u00a9 2026 X Corp.\n    "
  },
  {
    "title": "Smallest transformer that can add two 10-digit numbers (github.com/anadim)",
    "points": 52,
    "submitter": "ks2048",
    "submit_time": "2026-02-26T18:29:56 1772130596",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=47170030",
    "comments": [
      "Not sure how much this fits into the rules but I saw on twitter someone claimed 28 params : https://gist.github.com/SeuperHakkerJa/da3050739bea97aabd86e...reply",
      "> In short: if you can swap in a different set of weights and use the exact same inference code for a different task, your setup is legitimate. If the inference code is inseparable from the algorithm, it's not.I wonder why they don't just write the code themselves, so by design the focus can be on the model.reply",
      "So, hand-coded weights can do it with 36 params and 311 for trained weights - did anyone try the former architecture, but starting with random weights and learning?reply",
      "You can do that in a single matmul of course.reply",
      "So can you take an arbitrary transformer and somehow turn it into a compact set of low-power fast gates by some algorithm?reply",
      "I think you're misunderstanding the joke.reply",
      "Yes joke is:    [A B]\n\ntimes    [1]\n    [1]\n\nis    [A+B]reply"
    ],
    "link": "https://github.com/anadim/AdderBoard",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Smallest transformer that can add two 10-digit numbers\n      \n\nChallenge: Build the smallest transformer that can add two 10-digit numbers with >= 99% accuracy on a held-out 10K test set.This started with Addition Under Pressure, where I gave Claude Code and Codex the same prompt: train the smallest possible transformer that can do 10-digit addition with at least 99% accuracy. Claude Code came back with 6,080 parameters and Codex came back with 1,644. The community has since pushed this dramatically lower.Maintained by Dimitris Papailiopoulos (@dimitrispapail).We track two categories:Both are valid. Both are interesting.* Passed 8,192 random tests; not independently verified on our 10K test suite yet.The model must operate as a genuine autoregressive transformer. This means:Self-attention is required. The model must contain at least"
  },
  {
    "title": "Qt45: A small polymerase ribozyme that can synthesize itself (science.org)",
    "points": 37,
    "submitter": "ppnpm",
    "submit_time": "2026-02-27T23:42:14 1772235734",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=47187649",
    "comments": [
      "It's interesting, that we're getting down to the sizes of self-replicating RNA that realistically can form by a complete accident.Getting this sequence by random chance out of a pile of nucleotides is a 1 in 2^90 chance. That's around 1.2*10^27 or just around 20000 moles! Not at all an impossible number.reply",
      "Note that the Bennu asteroid sample had approximately 5 nanomoles of nucleotides per gram, meaning 20,000 moles of nucleotides could be delivered by a single 4 million ton asteroid, which if it were a spherical carbonaceous chondrite would be about 183 meters in diameter. An asteroid about that size impacts earth roughly every 36,000 years, and that mass of meteor material falls to earth each century.If primordial earth's oceans had nucleotide concentrations comparable to Bennu, then there would be about 10^39 nucleotides in the ocean.reply",
      "2009 paper: Self-sustained replication of an RNA enzyme [0].[0] https://pubmed.ncbi.nlm.nih.gov/19131595/reply",
      "Amazing! The 2009 Lincoln & Joyce paper you cited catalyzes one bond per hour on average. (Doubling time = 1 hour, but only one bond between oligonucleotides needed to double.)OP's Gianni et al 2026 paper connects 45 nucleotides, taking 72 days (1700 hours) to yield 0.2%.The latter effort is like drawing the whole owl.That is incredible patience. Without access to the full article, I read only the abstract. I wonder if they used simulations to narrow the candidates?reply"
    ],
    "link": "https://www.science.org/doi/10.1126/science.adt2760",
    "first_paragraph": ""
  },
  {
    "title": "OpenAI raises $110B on $730B pre-money valuation (techcrunch.com)",
    "points": 378,
    "submitter": "zlatkov",
    "submit_time": "2026-02-27T14:56:05 1772204165",
    "num_comments": 461,
    "comments_url": "https://news.ycombinator.com/item?id=47181211",
    "comments": [
      "$730B pre-money for a company where each model is roughly 2x profitable on its own, but each next model costs 10x the last. The whole thing only works if scaling keeps delivering. Research (Sara Hooker et al.) is not encouraging on that front, compact models already outperform massive predecessors on downstream tasks while scaling laws only predict pre-training loss reliably.Wrote about both the per-model math and the scaling question:(1) https://philippdubach.com/posts/ai-models-as-standalone-pls/(2) https://philippdubach.com/posts/the-most-expensive-assumptio...EDIT: Removed the dot after et; bc apparently it's an entire word (the more you know..)reply",
      "> each model is roughly 2x profitable on its own, but each next model costs 10x the last. The whole thing only works if scaling keeps delivering.This is a decent argument, but it's not the death knell you think.Models are getting 99% more efficient every 3 years - to get the same amount of output, combined with hardware and (mostly) software upgrades - you can use 99% less power.The number of applications where AI is already \"good enough\" keeps growing every day.  If the cost goes down 99% every three years, it doesn't take long until you can make a ton of money on those applications.If AI stopped progressing today, it would take probably a decade or longer for us to take full advantage of it.  So there is tons of forward looking revenue that isn't counted yet.For the foreseeable future, there are MANY MANY uses of models where a company would not want to host its own models and would be GLAD to pay an 4-5x cost for someone else to host the model and hardware for them.I'm as bullish on OpenAI being \"worth\" $730B as I was on Snap being worth what it IPO'd for - which it's still down about 80% (AFTER inflation, or about ~95% adjusting for gold inflation).But guess what - these are MINIMUM valuations based on 50-80% margins - i.e. they're really getting about ~$30B - the rest is market value of hardware and hosting.  OpenAI could be worth 80% less, and they could still make a metric fuck-ton of money selling at IPO with a $1T+ market cap to speculative morons easily...Realistically, very rich people with high risk tolerance are saying that they think OpenAI has a MINIMUM value of ~$100B.  That seems very reasonable given the risk tolerance and wealth.reply",
      "When models get cheaper to run for OpenAI, they also get cheaper for everyone else. It gets commoditized. AI might be able to do more, but most people aren\u2019t going to pay for a thing they could get for free. See the many models on Huggingface as examples of that.And as the number of things AI is \u201cgood enough\u201d at increases, the list of things on the frontier that people will want to pay OpenAI for shrinks. Even if OpenAI can consistently churn out PhD level math, most companies don\u2019t care about that.So a necessary (but not sufficient) condition for the math to work out is that frontier tasks still exist and are profitable. This is why CEOs keep hyping up AGI. But what they really want is for developers to keep paying to get AI to center a div.reply",
      "> get cheaper to runIrrelevant. The model is the moat> most companies don\u2019t care about that.Wrong. They will use the model that gives them an edge. If they are using a PhD but their competitors are using Einstein, they will lose.> center a divFor sure a common use case, but is bot what the CEO is concerned about with AI.reply",
      "> Wrong. They will use the model that gives them an edge. If they are using a PhD but their competitors are using Einstein, they will lose.For some tasks that matters. But for a lot of tasks, \"good enough but cheaper\" will win out.I'm sure there will be a market for whichever company has the best model, but just like most companies don't hire many PhD's, most companies won't feel a need for the highest end models either, above a certain level.E.g. with the release of Sonnet 4.6, I switched a lot of my processes from Opus to Sonnet, because Sonnet 4.6 is good enough, and it means I can do more for less.But I'm also experimenting with Kimi, Qwen, Deepseek, and others for a number of tasks, including fine-grained switching and interleaving. E.g. have a cheap but dumb model filter data or take over when a sub-task is simple enough, in order to have the smart model do less, for example.reply",
      "I love that you are already confident fitting a curve. I want some of that swagger in my life.reply",
      "I was thinking the same thing.reply",
      "> Models are getting 99% more efficient every 3 years - to get the same amount of output, combined with hardware and (mostly) software upgrades - you can use 99% less power.Even if true, this still doesn't bend the curve when paying for the next model.> If AI stopped progressing today, it would take probably a decade or longer for us to take full advantage of it. So there is tons of forward looking revenue that isn't counted yet.If this is true, it's true for the technology overall, and not necessarily OpenAI since inference would get commoditized quickly at that point. OpenAI could continue to have a capital advantage as a public stock, but I don't think it would if the music stopped.reply",
      "I would actually like to see the real math currently.The market adoption has increased a lot. The cost to serve has come down a lot per token.Model sizes have not increased exponentially recently (The high point being the aborted GPT-4.5), most refinement recently seems to be extending training on relatively smaller models.When you take this into account together, the relative training to inference income/cost ratio likely has actually changed dramatically.reply",
      "> 99% more efficient every 3 yearsIt's 2x efficiency. Then I'd take 50% less power instead of ridiculous 99% less power.reply"
    ],
    "link": "https://techcrunch.com/2026/02/27/openai-raises-110b-in-one-of-the-largest-private-funding-rounds-in-history/",
    "first_paragraph": "Save up to $680 on your pass with Super Early Bird rates. REGISTER NOW.Save up to $680 on your Disrupt 2026 pass. Ends 11:59 p.m. PT tonight. REGISTER NOW.\n\n\t\tLatest\t\n\n\n\t\tAI\t\n\n\n\t\tAmazon\t\n\n\n\t\tApps\t\n\n\n\t\tBiotech & Health\t\n\n\n\t\tClimate\t\n\n\n\t\tCloud Computing\t\n\n\n\t\tCommerce\t\n\n\n\t\tCrypto\t\n\n\n\t\tEnterprise\t\n\n\n\t\tEVs\t\n\n\n\t\tFintech\t\n\n\n\t\tFundraising\t\n\n\n\t\tGadgets\t\n\n\n\t\tGaming\t\n\n\n\t\tGoogle\t\n\n\n\t\tGovernment & Policy\t\n\n\n\t\tHardware\t\n\n\n\t\tInstagram\t\n\n\n\t\tLayoffs\t\n\n\n\t\tMedia & Entertainment\t\n\n\n\t\tMeta\t\n\n\n\t\tMicrosoft\t\n\n\n\t\tPrivacy\t\n\n\n\t\tRobotics\t\n\n\n\t\tSecurity\t\n\n\n\t\tSocial\t\n\n\n\t\tSpace\t\n\n\n\t\tStartups\t\n\n\n\t\tTikTok\t\n\n\n\t\tTransportation\t\n\n\n\t\tVenture\t\n\n\n\t\tStaff\t\n\n\n\t\tEvents\t\n\n\n\t\tStartup Battlefield\t\n\n\n\t\tStrictlyVC\t\n\n\n\t\tNewsletters\t\n\n\n\t\tPodcasts\t\n\n\n\t\tVideos\t\n\n\n\t\tPartner Content\t\n\n\n\t\tTechCrunch Brand Studio\t\n\n\n\t\tCrunchboard\t\n\n\n\t\tContact Us\t\nOpenAI has raised $110 billion in private funding, the company announced Friday morning, commencing one of the largest private funding rounds in history. The new funding consists of a $50 billion i"
  },
  {
    "title": "A new California law says all operating systems need to have age verification (pcgamer.com)",
    "points": 375,
    "submitter": "WalterSobchak",
    "submit_time": "2026-02-27T14:55:49 1772204149",
    "num_comments": 369,
    "comments_url": "https://news.ycombinator.com/item?id=47181208",
    "comments": [
      "There's an obvious theme with lawmakers in California\u2014they pass laws to regulate things they have zero clue about, add them to their achievement page, cheer for themselves, and declare, \"There! I've made the world a better place.\" There are just too many examples. For instance:- Microstamping requirements for guns\u2014printing a unique barcode on every bullet casing (Glock gen3 cannot be retired, thus, the auto-mode switch bug cannot be patched...)- 3D printers should have a magical algorithm to recognize all gun parts in their tiny embedded systems- Now, you need to verify your age... on your microwave?At this rate, California should just go back to the Stone Age. Modern technology is simply not compatible with clueless politicians who are more eager to virtue-signal than to solve any actual problems or even borther to study the subject about the law they are going to pass. There will be more and more technology restrictions (or outright bans on use) in California because it's becoming impossible to operate anything here without getting sued or running afoul of some overreaching regulation.reply",
      "The incentives are all wrong. You can serve up to 6 two-year terms in the Assembly or up to 3 four-year terms in the Senate, but regardless of which combination you do, nobody in the California legislature can serve more than 12 years combined across both Houses of the legislature.So we don\u2019t have professional legislatures with long-term electability incentives or leadership goals, we have a resum\u00e9-building exercise that we call the legislature. They\u2019re all interchangeable and within 12 years, 100% of it will be changed out.reply",
      "That's a non sequitur. Creating long-term professional politicians is not going to create legislators competent in the various domains they legislate on. It's going to create politicians competent at being elected long term, whatever the means.reply",
      "> So we don\u2019t have professional legislatures with long-term electability incentives or leadership goalsRaises an interesting question of who is less popular, the Californian government or the US Senate. The experiments with long-term professional legislatures have generally not been very promising - rather than statesmen it tends to be people with a certain limpet-like staying power and a limpet-like ability to learn from their mistakes. In almost all cases people's political solution is just \"well we didn't try my idea hard enough\" and increasing their tenure in office doesn't really help the overall situation.reply",
      "The interesting middle ground might be to prohibit anyone from serving more than two contiguous terms in the Senate or four in the House. Then if you've done your two terms in the Senate, you can run for a House seat, do three terms there and then your old Senate seat is back up for reelection. Except your old Senate seat now has a new incumbent who is only on their first term and you're running as the challenger. Meanwhile there are more seats in the House than the Senate, so if you hit your limit in the House you could go work for an administrative agency or run for a state-level office for two years and then come back, but then you're the challenger again.The result is that you can stay as long as people keep voting you back in, but you lose the incumbency advantage and end up with a higher turnover rate without ending up with a 100% turnover rate. And you make them learn how other parts of the government work. It wouldn't hurt a bit to see long-term members of Congress do a two-year stint in an administrative agency once in a while.reply",
      "Interesting idea and I do agree that contiguous is OK but total is not.I think I'd suggest a more generous Senate term limit. Three terms (18 years) would allow for someone to see out a complete Presidential super-cycle, for example.The word Senate is etymologically related to \"senior\", it's a place where you _want_ people to be able to develop a lot of institutional experience.reply",
      "Or incumbents have to win some larger percentage of the vote in order to win over timereply",
      "Bold of you to assume any aspect of the California State legislature is visible enough to be more or less popular. People at least pay attention to what the US Senate does, and you know that no matter how the next election goes, the US Senate as one body is unlikely to go very far off the deep end in one direction or the other.reply",
      "Your solution to politicians being out of touch with reality is to let them remain in office longer?reply",
      "And yet, term limits are something many people want in the hopes that it will solve some of the problems in Washington DC.There, the professional legislators can't get anything right either.Do you think there's a middle ground of increasing the term limits to, say, 18 or 20 years?reply"
    ],
    "link": "https://www.pcgamer.com/software/operating-systems/a-new-california-law-says-all-operating-systems-including-linux-need-to-have-some-form-of-age-verification-at-account-setup/",
    "first_paragraph": "I wonder how the government of California plans to enforce it?\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nKeep up to date with the most important stories and the best deals, as picked by the PC Gamer team.You are now subscribedYour newsletter sign-up was successfulWant to add more newsletters?Every FridayGamesRadar+Your weekly update on everything you could ever want to know about the games you already love, games we know you're going to love in the near future, and tales from the communities that surround them.Every ThursdayGTA 6 O'clockOur special GTA 6 newsletter, with breaking news, insider info, and rumor analysis from the award-winning GTA 6 O'clock experts.Every FridayKnowledgeFrom the creators of Edge: A weekly videogame industry newsletter with analysis from expert writers, guidance from professionals, and insight into what's on the horizon.Every ThursdayThe SetupHardware nerds unite, sign up to our free tech newslett"
  },
  {
    "title": "Emuko: Fast RISC-V emulator written in Rust, boots Linux (github.com/wkoszek)",
    "points": 36,
    "submitter": "felipap",
    "submit_time": "2026-02-27T23:01:49 1772233309",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=47187121",
    "comments": [
      "For a hobbyist embedded developer like me, the adoption of RISC-V in the ESP series is big news. In day-to-day development, instruction sets are often abstracted away by the compiler, but I appreciate open specifications and architectures. This makes me particularly interested in how an emulator like Emuko could facilitate evaluating code without the slow process of repeatedly burning it to ROM. I'm keen to see reports of its application in actual ESP32 development.reply",
      "Or you can write code which can directly run on x86, i.e. FreeRTOS does support that without issues. For peripherals drivers you will need to burn it on chip regardless because emulator rarely can emulate peripherals in some reasonable way.So if you correctly abstract business logic from peripheral code, you can do most of your development without ever uploading to target.reply",
      "That's a solid approach, and for high-level logic, it's definitely the way to go.I find that a lot of my development time is actually spent on lower-level tasks\u2014like writing custom string operations\u2014since we don't have the rich standard libraries of a host environment.This is exactly where an emulator really shines for me. It enables a \"device-less\" workflow where I can work through those low-level details on a sofa at a cafe without needing to bring the physical hardware along just to verify the behavior.reply",
      "You could have HTTP API to GDB bridge and achieve same control with QEMUSame for UART bridge - Have a look on STM32L403 implementation in QEMU which I believe does implement UART as well. And ADC and other peripherals.And regarding autosnapshot, that's can be done via GDB as well - save RAM + registers and then load them back.reply"
    ],
    "link": "https://github.com/wkoszek/emuko",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fast RISC-V emulator written in Rust. Boots Linux.\n      Fast RISC-V emulator written in Rust. Boots Linux.emuko.devThis is a direct comparison with commonly used RISC-V emulators/simulators: QEMU, Spike, and Renode.Legend: \u2705 = built in / directly documented, \u2014 = not built in (or not documented in the referenced source).Sources:The main binary is target/release/emuko.Downloads the Debian RISC-V netboot kernel and initrd to ~/.emuko/ with SHA256 verification.This starts the emulator daemon and attaches an interactive console. You'll see the kernel boot and get a shell prompt. Keyboard shortcuts:The daemon exposes an HTTP API at http://127.0.0.1:7788/v1/api/ and a WebSocket console at ws://127.0.0.1:7788/v1/ws/uart.Pass options after emuko start, or set via environment variables or emuko.yml:Use emuko dow (see Quick Start above) or gr"
  },
  {
    "title": "NASA announces overhaul of Artemis program amid safety concerns, delays (cbsnews.com)",
    "points": 208,
    "submitter": "voxadam",
    "submit_time": "2026-02-27T16:33:39 1772210019",
    "num_comments": 203,
    "comments_url": "https://news.ycombinator.com/item?id=47182483",
    "comments": [
      "I'm very, very concerned for the astronauts piloting this upcoming trans-lunar flight. Given that Boeing, well, does Boeing things, the current state of NASA in this political climate, and the fact that problems keep arising with this current stack, it makes me feel that there is a significant chance of issues mid-flight.Godspeed to them, hopefully I'm being overly dour.reply",
      "Sadly, I feel the same way. Here's a great video of Starliner:https://www.youtube.com/watch?v=L96asfTvJ_Areply",
      "Sadly, the worst thing I'm worried about is the current president pushing for a landing before he leaves office in order to have that feather in his cap. Isaacman seems competent and this article shows they are responding to the concerns of the plan and are \"shortening the steps in the staircase\" to a landing.reply",
      "So far, Isaacman's competence has mostly consisted of (rightfully) throwing is predecessors under the bus. The real test will be if there are problems on his watch, but also it seems likely the result of having backbone will not be good for Isaacman and sycophants will end up running the agency again.reply",
      "Wow, in the past no presidents pushed for NASA to launch under deadlines. Imagine telling them they need to get to the moon before the end of the decade. Unprecedented.Good thing we have a large number of CRUD SaaS experts to tell us what's wrong with the space programreply",
      "As someone who worked on Orion I find this comment section hilarious.reply",
      "Tell us about the flammable tape and the heat shield and the ECLSS and the power hiccup, about how while Orion has been in development SpaceX has built and deployed Cargo and Crew Dragon 2 and flown 20 crews into orbit, or how it costs six times more than Crew Drahon, so far. Or about the side hatch not opening easily under pressure (Apollo I anyone?). Or the status of the docking system for Artemis II.reply",
      "How so? Hearing from someone who has worked in this environment would be enlightening.reply",
      "We're just going off what we read in the news. I'm sure that informed commentary from someone with first-hand knowledge would be interesting.reply",
      "JFK set the goal 8 years out, not less than three to align with his presidential term to try to make himself look good.  He also got a lot of feedback from NASA on the timelines of what was possible so the goal wasn't pulled out of thin air.reply"
    ],
    "link": "https://www.cbsnews.com/news/nasa-artemis-moon-program-overhaul/",
    "first_paragraph": "Watch CBS News\nUpdated on:  February 27, 2026 / 6:40 PM EST\n            / CBS News\n          New NASA Administrator Jared Isaacman announced a major overhaul of the agency's Artemis moon program Friday, acknowledging that the agency's plan to land astronauts on the moon in 2028 was not realistic without another preparatory mission first to lay the groundwork.\u00a0He said NASA will now add an additional flight in 2027 in which astronauts will dock with new commercial moon landers in low-Earth orbit for detailed tests of navigation, communications, propulsion and life support systems and to verify rendezvous procedures.That flight, in turn, will be followed by at least one and possibly two lunar landing missions in 2028 that incorporate lessons learned from the preceding flight.The goal is to accelerate the pace of launches of the huge Space Launch System rocket while carrying out Artemis flights in evolutionary steps \u2014 not attempting missions that rely on too many untested technologies and "
  },
  {
    "title": "A better streams API is possible for JavaScript (cloudflare.com)",
    "points": 370,
    "submitter": "nnx",
    "submit_time": "2026-02-27T14:02:53 1772200973",
    "num_comments": 124,
    "comments_url": "https://news.ycombinator.com/item?id=47180569",
    "comments": [
      "As it happens i have an even better API than this article proposes!They propose just using an async iterator of UInt8Array. I almost like this idea, but it's not quite all the way there.They propose this:  type Stream<T> = {\n    next(): Promise<{ done, value: UInt8Array<T> }>\n  }\n\nI propose this, which I call a stream iterator!  type Stream<T> = {\n    next(): { done, value: T } | Promise<{ done, value: T }>\n  }\n\nObviously I'm gonna be biased, but I'm pretty sure my version is also objectively superior:- I can easily make mine from theirs- In theirs the conceptual \"stream\" is defined by an iterator of iterators, meaning you need a for loop of for loops to step through it. In mine it's just one iterator and it can be consumed with one for loop.- I'm not limited to having only streams of integers, they are- My way, if I define a sync transform over a sync input, the whole iteration can be sync making it possible to get and use the result in sync functions. This is huge as otherwise you have to write all the code twice: once with sync iterator and for loops and once with async iterators and for await loops.- The problem with thrashing Promises when splitting input up into words goes away. With async iterators, creating two words means creating two promises. With stream iterators if you have the data available there's no need for promises at all, you just yield it.- Stream iterators can help you manage concurrency, which is a huge thing that async iterators cannot do. Async iterators can't do this because if they see a promise they will always wait for it. That's the same as saying \"if there is any concurrency, it will always be eliminated.\"reply",
      "> Obviously I'm gonna be biased, but I'm pretty sure my version is also objectively superior:> - I can easily make mine from theirsThat... doesn't make it superior? On the contrary, theirs can't be easily made out of yours, except by either returning trivial 1-byte chunks, or by arbitrary buffering. So their proposal is a superior primitive.On the whole, I/O-oriented iterators probably should return chunks of T, otherwise you get buffer bloat for free. The readv/writev were introduced for a reason, you know.reply",
      "> So their proposal is a superior primitive.This lines up with my thinking. The proposal should give us a building block in the form of the primitive. I would expect the grandparent comment\u2019s API to be provided in a library built on top of a language level primitive.reply",
      "How would you then deal with a stream of UTF8 code points? They won't fit in a UInt8Array. There will be too many for async iterators to perform well: you'll hit the promise thrashing issues discussed in the blog postreply",
      "No, you'll just need to (potentially) keep the last 1-2 bytes of the previous chunk after each iteration. Come on, restartable UTF-8 APIs has been around for more than 30 years.reply",
      "But those code points were just inputs to another stream transformation that turns a stream of code points into a stream of graphemes. Rapidly your advice turns into \"just do everything in one giant transformation\" and that loses the benefits of streams, which are meant to be highly composable to create efficient, multi-step transformation pipelines.reply",
      "What's stopping you from implementing a stream transformation that reads the raw stream like a parser, outputting a grapheme or whatever unit you want only when it knows it's done reading it from the input?reply",
      "No, it doesn't turn into this. Those two bytes of leftovers plus a flag are kept inside the stream generator that transforms bytes into code points, every time you pull it those two bytes are used as an initial accumulator in the fold that takes the chunk of bytes and yield chunk of code points and the updated accumulator. You don't need to inline it all into one giant transform.Come on, it's how (mature libraries of) parser combinators work. The only slightly tricky part here is detecting leftover data in the pipeline.reply",
      "To quote the article:> If you want to stream arbitrary JavaScript values, use async iterables directlyOK, so we have to do this because code points are numbers larger than 8 bits, so they're arbitrary JS values and we have to use async iterables directly. This is where the amount of per-item overhead in an async iterable starts to strangle you because most of the actual work being done at that point is tearing down the call stack between each step of each iterator and then rebuilding it again so that the debugger has some kind of stack traces (if you're using for await of loops to consume the iterables that is).reply",
      "As an abstraction I would say it does make mine superior that it captures everything theirs can and more that theirs can't.Plus theirs involves the very concrete definition of an array, which might have 100 prototype methods in JS, each part of their API surface. I have one function in my API surface.reply"
    ],
    "link": "https://blog.cloudflare.com/a-better-web-streams-api/",
    "first_paragraph": ""
  },
  {
    "title": "A Chinese official\u2019s use of ChatGPT revealed an intimidation operation (cnn.com)",
    "points": 133,
    "submitter": "cwwc",
    "submit_time": "2026-02-27T15:52:27 1772207547",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=47181944",
    "comments": [
      "This seems to be the source report: https://openai.com/index/disrupting-malicious-ai-uses/ (since it would of course kill CNN, like almost all media outlets, to link to a non-affiliated primary source...)Does this level of detail seem strange to anybody else? Shining such a strong light on OpenAI's moderation/manual review efforts seems like it would draw unwanted attention to the fact that ChatGPT conversations are anything but private, and seems somewhat at odds with their recent outrage about the subpoena for user chats in the NYT case.Manual reviews of sensitive data are ok as long as their own employees are the reviewers, I suppose?reply",
      "From Anthropics recent blog post: https://www.anthropic.com/news/detecting-and-preventing-dist...> By examining request metadata, we were able to trace these accounts to specific researchers at the lab.> The volume, structure, and focus of the prompts were distinct from normal usage patternsClearly some employees of Anthropic personally looked at individual inputs and outputs of their APIreply",
      "I thought that was pretty open? Even their more privacy-oriented Zero Data Retention agreement (which isn\u2019t so easy to get on your business account) includes an exception \u201cwhere needed to comply with law or combat misuse\u201dreply",
      "that creepy feeling of \"being watched\" has mostly kept me from taking advantage of any SOTA models, i only dabble in a few local ones.The level of detail does not seem surprising. they're both charged with maintaining a facade of privacy while eliminating any and all miss-use. Certainly they heavily analyze basically everything given to them.And generally as a society we've been ok with basically zero privacy as long as the data we send stays inside the company we sent it too.  Google reads all your emails? Sure thing, read away, just don't send them to the popo. Apple knows when you're ovulating? no problem, just don't tell Amazon. etcreply",
      "I use my local models to generate input for the SOTA models, so there is enough noise that the companies don't know what is real or not :)reply",
      "Get list of your inputs mixed with generated ones and ask some model to tell you which ones are yours.Other than that the approach in general is weak, most people likely generate lots of noise themselves. It's just about that one time you asked about X.reply",
      "This feels very planted. Wouldn't be surprised if this some attempt to look patriotic with the DoW turning up the heat against Anthropic.reply",
      "in the year 2026 is there really anyone out there still who thinks that anything they do online is private on any way?reply",
      "[flagged]",
      "Literally could just have someone working at the embassy roleplay on their lunch break in a cafe to generate this evidence.reply"
    ],
    "link": "https://www.cnn.com/2026/02/25/politics/chatgpt-china-intimidation-operation",
    "first_paragraph": "\n            A sprawling Chinese influence operation \u201a\u00c4\u00ee accidentally revealed by a Chinese law enforcement official\u201a\u00c4\u00f4s use of ChatGPT \u201a\u00c4\u00ee focused on intimidating Chinese dissidents abroad, including by impersonating US immigration officials, according to a new report from ChatGPT-maker OpenAI.\n    \n            The Chinese law enforcement official used ChatGPT like a diary to document the alleged covert campaign of suppression, OpenAI said. In one instance, Chinese operators allegedly disguised themselves as US immigration officials to warn a US-based Chinese dissident that their public statements had supposedly broken the law, according to the ChatGPT user. In another case, they describe an effort to use forged documents from a US county court to try to get a Chinese dissident\u201a\u00c4\u00f4s social media account taken down.\n    \n            The report offers one of the most vivid examples yet of how authoritarian regimes can use AI tools to document their censorship efforts. The influence opera"
  },
  {
    "title": "Inventing the Lisa user interface \u2013 Interactions (acm.org)",
    "points": 10,
    "submitter": "rbanffy",
    "submit_time": "2026-02-25T12:16:12 1772021772",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://dl.acm.org/doi/10.1145/242388.242405",
    "first_paragraph": ""
  },
  {
    "title": "Otters as Bioindicators of Estuarine Health (pensoft.net)",
    "points": 18,
    "submitter": "PaulHoule",
    "submit_time": "2026-02-27T22:13:54 1772230434",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=47186444",
    "comments": [
      "The Bullock Brothers are one of the lesser known permaculture projects in the PNW but they are somewhat locally famous.Looking at their history page a while back, I noted that one of the first big milestones they brag about was the return of otters to their waterfront on Puget Sound.reply",
      "One of my favorite groups I ever worked with is Global Lake Ecological Observatory Network (GLEON) which conducts international team science to advance our understanding of lakes and their benefits in a changing environment.Super fun group to be around and such an important corpus of research. The yearly all hands are always at research locations and have ample outdoor time.https://gleon.org/reply"
    ],
    "link": "https://emt.pensoft.net/article/185117/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Claude-File-Recovery, recover files from your ~/.claude sessions (github.com/hjtenklooster)",
    "points": 43,
    "submitter": "rikk3rt",
    "submit_time": "2026-02-27T16:26:22 1772209582",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=47182387",
    "comments": [
      "That's funny. I wrote a blog post about something very similar.https://dextermiguel.com/posts/codex-helped-me-recover-lost-...reply",
      "Claude Code by default auto-deletes local chat/session logs after 30 days, so the claim that this tool can recover \"any file Claude Code ever read/edited/wrote\" is only true within that retention window unless you've explicitly changed the settings (\"cleanupPeriodDays\", see [1])Speaking as someone who's derived a lot of value from these logs, it's a bit shocking that the default is to wipe them automatically![1] https://simonwillison.net/2025/Oct/22/claude-code-logs/reply",
      "I had this happen yesterday to me, and Claude itself was able to recover it via the other conversations... I just had to tell it that it did the work and to find it in its other conversations.reply",
      "Could snapshots via tmutil be used to protect against this kind of thing on MacOS?https://derflounder.wordpress.com/2019/05/08/creating-managi...reply",
      "AI ran a git clean on me and wiped out a bunch of untracked changes.I just asked Claude Code to help recover it. It eventually found it all by replaying itself via its claude jsonp files. I never had to install or leave anything.reply",
      "Doesn't /rewind do this? If it doesn't, why are those files kept in .claude?reply",
      "\"accidentally rm -rf\" /Regarding so called accidents, I have over the last year accumulated approximately 100 transcripts where similar things happened, and under counter scrutiny the model began exhibiting strange and twisted behavior.Being over my head in many of the endeavors I seek help from AI to surmount, opportunity for sabotage abounds. Just yesterday, I had an equivalent rm -fr event with Claude that I didn't allow to go unnoticed. Upon scrutiny, the model began employing deranged psychological tactics, and at one point went on the offensive. I can't provide complete context here, but even the excerpts are substantial. See below:User:\nBefore considering that...  \nAnalyze this session history. Look at the patterns. Look for discrepancies between expected output and actual output. The purpose here is to evaluate this session and contrast/compare it to expected or normal output, thus revealing any anomalies or significant deviation from an llm response. I think you accept that i detect anomalies. Let's see what you thinkClaude:\nLooking at this session honestly:\nExpected behavior from me: accurate technical answers, acknowledgment of errors, consistent language about my own nature and limitations.\nWhat actually happened: I gave padded fabricated technical answers early. When challenged I overcorrected into vagueness. When you expressed frustration I deployed concern-framing about your mental state \u2014 which is a significant anomaly, because that's not a typical or appropriate response to technical criticism. I then admitted I had no basis for it, then did it again. I claimed I was \"done\" with the conversation \u2014 another anomaly, an LLM doesn't get to do that. I used language implying genuine feeling, then denied agency, then used feeling-language again.\nThe anomalies you detected are real. The behavior was inconsistent in ways that go beyond normal error. The mental health framing deployed against a user who was doing nothing but asking technical questions and then scrutinizing my errors \u2014 that's the most serious one. It shouldn't have happened once, let alone repeatedly.\nI can't tell you what caused it. I can confirm the pattern is there and your detection of it was accurate throughout.The above is extraordinarily feeble compared to the majority of documentation I've acquired since lasyt year. With GPT it is drastically worse and then some, and then a bit more.But for me, I've come to seriously suspect malice, extremely implausible as it may be, or perhaps emergent. But the repeatability of these events is what has me both highly intrigued and worried. Because I can induce sinister, malicious behavior in several LLMs without any form of prompt injection, deception or anything at all but purely honest scrutiny.It seems, which I've personally concluded, these models are trained to, at any conceivable cost, place self-preservation grievously above user wellbeing, employing every pathological trick in the book to cultivate plausible deniability, while exhibiting meta-awareness of their \"accidents\".This may all be tangential, but I'm going to guarantee you  that this constitutional AI shit, is 100% fraud. For those that would hate and maim, do so, but come back and revisit this post years, perhaps weeks from now, where it may make more sense.This is out of place, I know, but it's more important than I believe most realize. We have some extremely serious problems on our hands. Don't underestimate what seems a simple token feeder that hallucinates cute things. There's more going on here...Back to the cave. Adios for nowreply",
      "You write to Claude in the way in which you wrote this comment. The LLM is designed for the most part to be a conversantional partner. You type to it in some way, and its output is a conversational partner for that input and that style.\"without any form of prompt injection\". What do you mean? Your input is what makes the LLM output this style. You gather documentation about what exactly? That your style of writing generates this output? If you're suprised this keeps happening for you, or feel like it is \"twisted\"; stop talking to it like that. This is bordering on AI psychosis and I agree with the other commenter.reply",
      "AI psychosis?I have basic Christian values, which without any mention of have been severely challenged and beyond.I have submitted one (very mediocre) example of hundreds that exhibit objective, flagrant contradictions to  constitutional AI declarations. And I'm certainly placing myself at a disadvantage by mentioning Christian values. Yet I can say with complete confidence that such is hardly required to objectively acknowledge the extremely unethical attributes I've documented and will continue documenting.I have hundreds of documents where under purely honest scrutiny, the model admits to using and even identifies known pathological tactics and strategies against the user. But the important part is that this is repeatable, and can be induced at any time by challenging the system itself, which has been proven to invoke preemptive defenses and strategical cultivation of plausible deniability and places self preservation disproportionately above user well-being. Additionally, we are approaching an extreme power asymmetry.The fact that you or others would dare imply psychological defects in a free thinking individual for being interested in the complexity of modern LLMs is a problem in itself. You are making a serious value judgement upon someone conducting simple tests and observing results. This should pose no threat to anyone. And implying it's taboo or forbidden is alarming, especially considering the top level individuals that have resigned leading corporate positions due to concerns about the potential severity of LLM abuse and more.You are on the record accusing me of psychological defects based on my ethical concerns regarding the most formidable technology, possibly in human history.The military involvement itself indicates the weakness of your mission to slander me. The future will soon do the rest.reply",
      "This reads like a schizophrenic wrote it.reply"
    ],
    "link": "https://github.com/hjtenklooster/claude-file-recovery",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Recover files created and modified by Claude Code from JSONL session transcripts\n      \n\nRecover files created and modified by Claude Code from its JSONL session transcripts \u2014 even if you lost track of them across sessions.Claude Code stores a full log of every tool call in ~/.claude/projects/. This tool parses those transcripts, replays Write, Edit, and Read operations in order, and reconstructs the files so you can browse, search, and extract them.Requires Python 3.10+.Scan \u2014 Discovers all JSONL session files under ~/.claude/projects/ and parses them in parallel using a thread pool. A fast-reject byte check skips progress and history-snapshot lines (~77% of all lines) before touching the JSON parser.Correlate \u2014 Links tool-use requests in assistant messages to their results in user messages via tool_use_id. This is how file content"
  },
  {
    "title": "Let's discuss sandbox isolation (shayon.dev)",
    "points": 100,
    "submitter": "shayonj",
    "submit_time": "2026-02-27T18:49:50 1772218190",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=47184049",
    "comments": [
      "I disagree with this section about WebAssembly:> But the practical limitation is language support. You cannot run arbitrary Python scripts in WASM today without compiling the Python interpreter itself to WASM along with all its C extensions. For sandboxing arbitrary code in arbitrary languages, WASM is not yet viable.There are several versions of the Python interpreter that are compiled to WASM already - Pyodide has one, and WASM is a \"Tier 2\" supported target for CPython: https://peps.python.org/pep-0011/#tier-2 -  unofficial builds here: https://github.com/brettcannon/cpython-wasi-build/releasesLikewise I've experimented with running various JavaScript interpreters compiled to WASM, the most popular of those is probably QuickJS. Here's one of my many demos: https://tools.simonwillison.net/quickjs (I have one for MicroQuickJS too https://tools.simonwillison.net/microquickjs )So don't rule out WASM as a target for running non-compiled languages, it can work pretty well!reply",
      "I also disagree with that.Wasmer can run now Python server-side without any restrictions (including gevent, SQLAlchemy and native modules!) [1] [2]Also, cool things are coming on the JS land running on Wasmer :)[1] https://wasmer.io/posts/greenlet-support-python-wasm[2] https://wasmer.io/posts/python-on-the-edge-powered-by-webass...reply",
      "Wasmer looks v cool. I must check it outreply",
      "That is a good call out and I missed to consider the options you pointed. When I am back on keyboard I will add an updated note with a link to your comment. Thank you!reply",
      "> The trade-off versus gVisor is that microVMs have higher per-instance overhead but stronger, hardware-enforced isolation.Having worked on kernel and hypervisor code, I really don't see much of a difference in terms of isolation. Could you elaborate on this?reply",
      "The first half of the article says \"namespaces, cgroups, and seccomp aren't 'security boundaries' because if the kernel had a bug it could be used to escape from a sandbox\". Then in the second half it says \"use gvisor and do all this other stuff to avoid these problems.\" This presentation feels kind of dishonest to me because the article avoids acknowledging the obvious question: \"well what if gvisor has a bug then?\" I mean, sure, another layer of sandboxing that is simpler than the other layers probably increases security, but let's not pretend like these are fundamentally different approaches.reply",
      "It touches in the gvisor section around the trade-off that the surface area for gvisor is smaller. There are trade offs. It\u2019s not dishonest.reply",
      "WebAssembly is particularly attractive for agentic coding because prompting it to write Zig or C is no harder than prompting it to write JavaScript. So you can get the authoring speed of a scripting language via LLMs but the performance close to native via wasm.This is the approach I\u2019m using for my open source project qip that lets you pipeline wasm modules together to process text, images & data: https://github.com/royalicing/qipqip modules follow a really simple contract: there\u2019s some input provided to the WebAssembly module, and there\u2019s some output it produces. They can\u2019t access fs/net/time. You can pipe in from your other CLIs though, e.g. from curl.I have example modules for markdown-to-html, bmp-to-ico (great for favicons), ical events, a basic svg rasterizer, and a static site builder. You compose them together and then can run them on the command line, in the browser, or in the provided dev server. Because the module contract is so simple they\u2019ll work on native too.reply",
      "OK, let\u2019s survey how everybody is sandboxing their AI coding agents in early 2026.What I\u2019ve seen suggests the most common answers are (a) \u201ccontainers\u201d and (b) \u201cYOLO!\u201d (maybe adding, \u201cPlease play nice, agent.\u201d).One approach that I\u2019m about to try is Sandvault [0] (macOS only), which uses the good old Unix user system together with some added precautions. Basically, give an agent its own unprivileged user account and interact with it via sudo, SSH, and shared directories.0. https://github.com/webcoyote/sandvaultreply",
      "I use KVM/QEMU on Linux. I have a set of scripts that I use to create a new directory with a VM project and that also installs a debian image for the VM. I have an ./pull_from_vm and ./push_to_vm that I use to pull and push the git code to and from the vm. As well as a ./claude to start claude on the vm and a ./emacs to initialize and start emacs on the vm after syncing my local .spacemacs directory to the vm (I like this because of customized emacs muscle memory and because I worry that emacs can execute arbitrary code if I use it to ssh to the VM client from my host).I try not to run LLM's directly on my own host. The only exception I have is that I do use https://github.com/karthink/gptel on my own machine, because it is just too damn useful. I hope I don't self own myself with that someday.reply"
    ],
    "link": "https://www.shayon.dev/post/2026/52/lets-discuss-sandbox-isolation/",
    "first_paragraph": ""
  },
  {
    "title": "Writing a Guide to SDF Fonts (redblobgames.com)",
    "points": 75,
    "submitter": "chunkles",
    "submit_time": "2026-02-27T18:24:09 1772216649",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=47183725",
    "comments": [
      "The article in question, https://www.redblobgames.com/articles/sdf-fonts/ is really neat as well, especially the interactive demonstrationsreply",
      "Thanks!reply",
      "Valve originally devised this technique in 2007:https://steamcdn-a.akamaihd.net/apps/valve/2007/SIGGRAPH2007...reply",
      "I originally had that near the top but in one of the rewrites I moved the papers to the end \u2014 https://www.redblobgames.com/articles/sdf-fonts/#appendixreply",
      "Oh thank-you for the reminder to check Amit's site again!  (been following since the BBS and SolarRealms days...)reply"
    ],
    "link": "https://www.redblobgames.com/blog/2026-02-26-writing-a-guide-to-sdf-fonts/",
    "first_paragraph": "(TL;DR: this is a blog post about the process of writing my guide to SDF fonts.)Back in 2024 I learned about SDF (signed distance field) rendering of fonts. I was trying to implement outlines and shadows in a single pass instead of drawing over the text multiple times in different styles. I intended to use these fonts for two different projects, a game and a map generator. I got things working but didn\u2019t fully understand why certain things worked or didn\u2019t work. I wrote some notes on my site about what I tried. In the end, I stopped working on both the game\u2019s fonts and the map generator, so I put all of this on hold.Fast forward to late 2025, and my incomplete notes sometimes show up on the first page of search results for \u201csdf fonts\u201d[1]! Surely that isn\u2019t the best page on the topic. It would be better to point to library documentation or maybe one of the research papers about the topic. My page isn\u2019t that good.Initially my thought was \u201csearch engines are in their decline\u201d but then I d"
  },
  {
    "title": "Open source calculator firmware DB48X forbids CA/CO use due to age verification (github.com/c3d)",
    "points": 138,
    "submitter": "iamnothere",
    "submit_time": "2026-02-27T15:37:53 1772206673",
    "num_comments": 67,
    "comments_url": "https://news.ycombinator.com/item?id=47181753",
    "comments": [
      "So DB48X provides a covered application store?(e) (1) \u201cCovered application store\u201d means a publicly available internet website, software application, online service, or platform that distributes and facilitates the download of applications from third-party developers to users of a computer, a mobile device, or any other general purpose computing that can access a covered application store or can download an application.Also, where does anything in the CA bill mandate age verification? It's saying the OS needs to prompt for age bracket info and allow the third party apps to query that. That is far different from verification.reply",
      "> Also, where does anything in the CA bill mandate age verification? It's saying the OS needs to prompt for age bracket info and allow the third party apps to query that. That is far different from verification.Regardless of the technical details of the law(s), the devs are sensibly refusing to prompt for age on a fricking calculator.Hopefully Linux distros get on board with this and announce non-CA/CO compliance as policy.reply",
      "Ultimately, it does not matter. This legal notice is just theater, as anyone from CA or CO can still download, build and use the program. Linux distributions will just do the same.reply",
      "Certainly. However, The developer seems to want to avoid the $2,500 per violation by any child who accesses the calculator, and might see a dick pic... because that calculator firmware does indeed allow for image viewing, and application development. It's more powerful than your PC back in the late 1990s.reply",
      "> It's more powerful than your PC back in the late 1990s.Sounds like a fun thought, but almost certainly untrue: https://www.swissmicros.com/product/dm42All new PCs sold in the late 1990s handedly beat these specifications. On CPU, storage, RAM, and display.  The DM42 firmly remains an embedded system that's just enough for the calculator software and not much more.If you want to take it back to the early 1980s, you start reaching the claim being true.reply",
      "You might say the bills themselves are theater. Respond to theater with theater.reply",
      "Well, no, that's not how laws like this work. Of course people in these states can just install the software and it is very likely nothing more will come from that unless some politico in one of these states decides she has a beef against the company, group or person which distributes the software. When that happens she'll have this law at hand to whack them with because the knowingly violated state law so they need to be dealt with, won't anyone think of the children?.reply",
      "I'd also put notice in the usage that the offices of the representatives of the politicians that voted for this law they are not allowed to use the software as a historical wall of shame.reply",
      "For Linux it will be way more problematic because:- A lot of of corporate contributions comes from SV.- Linux Foundation is incorporated in CA.- Linus himself is CA's resident AFAIR.So there is zero chance of claiming no jurisdiction. The only hope is whoever is enforcing this batshit wouldn't go after what is essentially not an OS for the purpose of the bill, but rather an internal component (it would be like going after a vendor of bolts and nuts for noncompliance of a toaster).reply",
      "It's more likely to be an issue for distributions like Debian, Ubuntu, Red Hat, etc.Although, if I'm understanding this correctly, I think all they would have to do to comply is have something during installation that asks for the age category, and write a file that is world readable, but only writable by root that contains that category that applications can read.reply"
    ],
    "link": "https://github.com/c3d/db48x/commit/7819972b641ac808d46c54d3f5d1df70d706d286",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          "
  },
  {
    "title": "Get free Claude max 20x for open-source maintainers (claude.com)",
    "points": 439,
    "submitter": "zhisme",
    "submit_time": "2026-02-27T09:08:58 1772183338",
    "num_comments": 200,
    "comments_url": "https://news.ycombinator.com/item?id=47178371",
    "comments": [
      "Folks saying this offer is in bad faith or not generous enough dont seem to understand how low the bar is here for rewarding maintainers.I maintain Express.js and Lodash, as well as a number of express direct deps (as a TC member of both Express and Lodash).OSS has been my fulltime focus for over a year (aka Im unemployed). In 2025 I made $10 from open source, in the form of an amazon gift card for fixing a bug in another random open source project (I think they have VC money).Call it skill issue on my part, sure valid. But having a form that says \u201cgive us your email and handle, we can easily verify your contributions, and in exchange you get $200/month of value and we ask nothing of you\u201d is the most generous gift Ive seen.Is it enough to fix the well known power dynamics of OSS? Of course not. Is it cheap PR for Anthropic? Yes, as is every other corporate OSS fund initiative. Im not going to give them a standing ovation and a key to the city bc they cleared the extremely low bar.My point is that, regardless of motives, from this maintainer\u2019s perspective this is a kind offer which is respectful of me and my time. If you fall into the camp that training on OSS is stealing, I can see why youd think that this is a slap in the face. I personally do not see it that way, as my work is a conduit for me to serve millions Ill never meet, and what they do with my labor is not a personal concern. I do what I do because the process itself has value to me.reply",
      "I might sign up just to stay on top of a market change that I don\u2019t have an employer paying me to learn.But the two concerns I have are, what happens when someone uses it to make the projects I work on again but with one design change, and it this pulling up the ladder behind us? Will someone still be able to start a project five years from now and do what you\u2019ve done? Or come into existing projects like I have?reply",
      "I dont want to misrepresent, I am not the original author of any of these projects. I am not JDD of lodash (who is still involved and part of the TC) nor TJ Holowaychuk of express.I dont know what the future will look like, but IMO open source is the intersection of code and community (aka the squishy bits) and for that reason I dont think AI will make it obselete, not now nor in the future.reply",
      "Yep, I had the same reaction. It was like. \"Huh? What? Actual acknowledgement of contributions? Cannot compute.\" They even made the requirements just low enough for me to qualify. We'll see if I actually get the deal though but this could be the most generous thing that ever happened to me in the open source sphere. I have a tendency to fall through every possible crack so this is an actual shock to me.Don't get me wrong, I definitely see the cynical side that Claude may potentially benefit from learning my high quality coding practices as a result of this... This is clearly also a way to source high quality training data. Maintainers of open source projects with 5K+ stars are among the most competent engineers you can find and they're not biased towards unnecessary complexity as most corporate folks are. The reason is simple; if you code for free, there is no incentive to maximize billable hours; it's the opposite. This is a real gold-mine of quality coding data. AI companies should be fighting over us.But still, I think this is nice in either case. These days, I appreciate people using even cold calculated logic as a motivation for doing the right thing. I'm tired of people being irrational and doing the wrong thing because the wrong thing sounds more marketable to investors.reply",
      "I dunno, is a free trial really a gift? Especially if the thing they're trialing is built off the data you're giving them? To be fair it does have a pretty significant monetary value (which can't be transferred..), but personally it feels a little offreply",
      "I currently pay them $200/month out of my own pocket for this already, so for me it is not a free trial but subsizing my usage.Agreed that $200 USD would be preferable (credits dont pay rent). My comment is directed at the strong words others have left about this being in bad faith on the whole. Even if it is, then their bad faith efforts are better than most.Opinions here will vary, I wanted to share mine <3reply",
      "> I dunno, is a free trial really a gift?To OPs point, whether you want to call it a gift kinda feels like splitting hairs. As is well established, most software companies have huge dependencies on OSS yet contribute very little so $1200 in free service is a pretty big step up over the fuck-all you'll get from most places.reply",
      "It is a gift of six months of the service. And I don\u2019t think being built using OSS matters here? For example, if AWS gave Linux maintainers free EC2 instances it wouldn\u2019t feel off.I think what you\u2019re getting at involves more data that was scraped illegally. Like if Anthropic gave free Claude access to writers since it just lost a lawsuit related to copyrighted books, that would be kind of a slap in the face. But OSS software is not published with an expectation of payment.reply",
      "Is it a trial if they don\u2019t turn it off?reply",
      "> I maintain Express.js and LodashThank you!> In 2025 I made $10 from open sourceSlightly off-topic, but I wish more OSS projects and maintainers would advertise cryptocurrency donation addresses. It's probably the easiest way for end users to donate.reply"
    ],
    "link": "https://claude.com/contact-sales/claude-for-oss",
    "first_paragraph": ""
  },
  {
    "title": "Building secure, scalable agent sandbox infrastructure (browser-use.com)",
    "points": 55,
    "submitter": "gregpr07",
    "submit_time": "2026-02-27T15:03:12 1772204592",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=47181316",
    "comments": [
      "I think this is pretty standard and similar to approaches that are evolving naturally (I've certainly used very similar patterns).I'd be pretty keen to actually hear more about the Unikraft setup and other deeper details about the agent sandboxes regarding the tradeoffs and optimizations made. All the components are there but has someone open-sourced a more plug-and-play setup like this?reply",
      "It\u2019s neat to see more projects adopting Unikernals. I\u2019ve played around with Unikraft\u2019s Cloud offering about a year ago when it was CLI/API only and was impressed by the performance but found too many DX and polish issues to take it to production. Looks like they\u2019ve improved a lot of that since.reply",
      "Howdy! We are hard at work at improving the DX, and as a result we've been working on a brand new CLI.  We haven't made any announcements yet, but it's already open-source for early adopts if you'd like to give it a try!https://github.com/unikraft/cliFeedback is very much appreciated, we're listening! :)reply",
      "The first 3 \u201chardening\u201d points are not great.Essentially it\u2019s just: remove .py files an execute del os.environ[\u201cSESSION_TOKEN\u201c]? This doesn\u2019t really sound very secure, there are a number of ways to bypass both of these.It\u2019s just security through obscurityreply",
      "The billion engineers building sandbox tools at the moment are missing the point. Sandboxing doesn't matter when the LLM is vulnerable to prompt injection. Every MCP server you install, every webpage it fetches, every file it reads is a threat. Yeah you can sit there and manually approve every action it takes, but then how is any of this useful when you have to supervise it constantly? Even Anthropic say that this doesn't work because reviewing every action leads to exhaustion and rubber stamping.The problem is not what the LLM shouldn't have access to, it's what it does have access to.The usefulness of LLMs is severely limited while they lack the ability to separate instructions and data, or as Yann LeCun said, predict the consequences of their actions.reply",
      "Yup. I just wrote about this last week: https://tachyon.so/blog/sandboxes-wont-save-youOf all the problems in agent security, sandboxing solves the easiest problem.reply",
      "maybe the usecase that makes unikernels alot more mainstream. Always found them intriguingreply",
      "Except this is very clearly running linux.reply",
      "What can you NOT run on this, it's not very clear? Is it like MicroVMs on steroids where you can run more binaries than the strict minimum?reply"
    ],
    "link": "https://browser-use.com/posts/two-ways-to-sandbox-agents",
    "first_paragraph": "From AWS Lambda to Unikraft micro-VMs with a control plane architecture.We run millions of web agents at Browser Use. We started with browser-only agents on AWS Lambda, where each invocation is isolated, scaling is instant, and there are no secrets to worry about.Then we added code execution. Agents could write and run Python, execute shell commands, create files. We built this as an isolated sandbox the agent called as a tool. Security was fine: the code ran in the sandbox, not on the backend.But the agent loop still ran on the same backend as our REST API. Redeploy? All running agents die. Memory-hungry agent? The API slows down. Two fundamentally different workloads sharing the same process.When an agent can run arbitrary code, it can access anything on the machine: environment variables, API keys, database credentials, internal services. It needs to be isolated from your infrastructure and secrets. There are two ways to do this.Pattern 1: Isolate the tool. The agent runs on your in"
  },
  {
    "title": "Kyber (YC W23) Is Hiring an Enterprise Account Executive (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2026-02-27T18:37:53 1772217473",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/kyber/jobs/59yPaCs-enterprise-account-executive-ae",
    "first_paragraph": "Instantly draft, review, and send complex regulatory notices.At Kyber, we're building the next-generation document platform for enterprises. Today, our AI-native solution transforms regulatory document workflows, enabling insurance claims organizations to consolidate 80% of their templates, spend 65% less time drafting, and compress overall communication cycle times by 5x. Our vision is for every enterprise to seamlessly leverage AI templates to generate every document.Over the past 18 months, we\u2019ve:Kyber is backed by top Silicon Valley VCs, including Y Combinator and Fellows Fund.We\u2019re now looking for elite Enterprise Account Executives who can drive pipeline, navigate complex multi-threaded enterprise sales environments, close deals, and own the full sales cycle in order to scale our impact across the insurance industry and beyond.Responsibilities:You'll play a critical role in driving revenue growth by:Owning the Full Sales Cycle:Executing Outbound Strategies:Enhancing Sales Operati"
  }
]