[
  {
    "title": "Prism (openai.com)",
    "points": 425,
    "submitter": "meetpateltech",
    "submit_time": "2026-01-27T18:03:10 1769536990",
    "num_comments": 261,
    "comments_url": "https://news.ycombinator.com/item?id=46783752",
    "comments": [
      "I know many people have negative opinions about this.I'd also like to share what I saw. Since GPT-4o became a thing, everyone who submits academic papers I know in my non-english speaking country (N > 5) has been writing papers in our native language and translating them with GPT-4o exclusively. It has been the norm for quite a while. If hallucination is such a serious problem it has been so for one and half a year.reply",
      "I've heard that now that AI conferences are starting to check for hallucinated references, rejection rates are going up significantly. See also the Neurips hallucinated references kerfuffle [1][1]: https://statmodeling.stat.columbia.edu/2026/01/26/machine-le...reply",
      "Translation is something Large Language Models are inherently pretty good at, without controversy, even though the output still should be independently verified. It's a language task and they are language models.reply",
      "Previously, this existed as crixet.com [0]. At some point it used WASM for client-side compilation, and later transitioned to server-side rendering [1][2]. It now appears that there will be no option to disable AI [3]. I hope the core features remain available and won\u2019t be artificially restricted. Compared to Overleaf, there were fewer service limitations: it was possible to compile more complex documents, share projects more freely, and even do so without registration.On the other hand, Overleaf appears to be open source and at least partially self-hostable, so it\u2019s possible some of these ideas or features will be adopted there over time. Alternatively, someone might eventually manage to move a more complete LaTeX toolchain into WASM.[0] https://crixet.com[1] https://www.reddit.com/r/Crixet/comments/1ptj9k9/comment/nvh...[2] https://news.ycombinator.com/item?id=42009254[3] https://news.ycombinator.com/item?id=46394937reply",
      "I'm curious how it compares to Overleaf in terms of features? Putting aside the AI aspect entirely, I'm simply curious if this is a viable Overleaf competitor -- especially since it's free.I do self-host Overleaf which is annoying but ultimately doable if you don't want to pay the $21/mo (!).I do have to wonder for how long it will be free or even supported, though. On the one hand, remote LaTeX compiling gets expensive at scale. On the other hand, it's only a fraction of a drop in the bucket compared to OpenAI's total compute needs. But I'm hesitant to use it because I'm not convinced it'll still be around in a couple of years.reply",
      "Overleaf is a little curious to me. What's the point? Just install LaTeX. Claude is very good at manipulating LaTeX documents and I've found it effective at fixing up layouts for me.reply",
      "In my circles the killer features of Overleaf are the collaborative ones (easy sharing, multi-user editing with track changes/comments). Academic writing in my community basically went from emailed draft-new-FINAL-v4.tex files (or a shared folder full of those files) to basically people just dumping things on Overleaf fairly quickly.reply",
      "collaboration is the killer feature tbh. overleaf is basically google docs meets latex.. you can have multiple coauthors editing simultaneously, leave comments, see revision history, etc.a lot of academics aren't super technical and don't want to deal with git workflows or syncing local environments. they just want to write their fuckin' paper (WTFP).overleaf lets the whole research team work together without anyone needing to learn version control or debug their local texlive installation.also nice for quick edits from any machine without setting anything up. the \"just install it locally\" advice assumes everyones comfortable with that, but plenty of researchers treat computers as appliances lol.reply",
      "To add to the points raised by others, \"just install LaTeX\" is not imo a very strong argument. I prefer working in a local environment, but many of my colleagues much prefer a web app that \"just works\" to figuring out what MiKTeX is.reply",
      "I can code in monospace (of course) but I just can't write in monospace markup. I need something approaching WYSIWIG. It's just how my brain works -- I need the italics to look like italics, I need the footnote text to not interrupt the middle of the paragraph.The visual editor in Overleaf isn't true WYSIWIG, but it's close enough. It feels like working in a word processor, not in a code editor. And the interface overall feels simple and modern.(And that's just for solo usage -- it's really the collaborative stuff that turns into a game-changer.)reply"
    ],
    "link": "https://openai.com/index/introducing-prism",
    "first_paragraph": ""
  },
  {
    "title": "430k-year-old well-preserved wooden tools are the oldest ever found (nytimes.com)",
    "points": 348,
    "submitter": "bookofjoe",
    "submit_time": "2026-01-27T15:46:29 1769528789",
    "num_comments": 196,
    "comments_url": "https://news.ycombinator.com/item?id=46781530",
    "comments": [
      "430,000 years? Am I reading this headline correctly? (since the site seems to have fallen victim to the HN-hug-of-death). That seems wildly further back than I understood humans to have tools, or even homo sapiens to have existed.ETA: Today I learned I had a much much larger gap in knowledge than I thought I did. Thanks to everyone for the information and links!reply",
      "Tools predate homo sapiens (which emerged about 300 kYA) by millions of years. The first stone industry - Oldowan - is at least two million years old and might be as old as three million. They predate what we call \u201carchaic humans\u201d by a long time.Even this evidence of woodworking is largely unremarkable. We\u2019ve got phytolith [1] and microwear [2] studies showing unambiguous evidence of woodworking going back at least 1.5 million years. Wood tools just don\u2019t survive very long, so this find is most notable for its preservation.[1] https://www.sciencedirect.com/science/article/abs/pii/S00472...[2] https://www.sciencedirect.com/science/article/abs/pii/S00472...reply",
      "> Even this evidence of woodworking is largely unremarkable .... this find is most notable for its preservation.This somewhat contradicts the subheading, no?> The finding, along with the discovery of a 500,000-year-old hammer made of bone, indicates that our human ancestors were making tools even earlier than archaeologists thought.reply",
      "That subheading is complete nonsense and I can't think of a single charitable reading of that sentence that in any way makes sense. Archaeologists have known that our ancestors have been making tools for over a million years since the Acheulean industry was  conclusively dated in the 1850s. It took half a century for archaeologists to figure that out after William Smith invented stratigraphy. Scientists didn't even know what an isotope was yet.The original paper's abstract is much more specific (ignore the Significance section, which is more editorializing):> Here, we present the earliest handheld wooden tools, identified from secure contexts at the site of Marathousa 1, Greece, dated to ca. 430 ka (MIS12). [1]Which is true. Before this the oldest handheld wooden tool with a secure context [2] was a thrusting spear from Germany dated ~400kYA [3]. The oldest evidence of woodworking is at least 1.5 million years old but we just don't have any surviving wooden tools from that period.[1] https://www.pnas.org/doi/10.1073/pnas.2515479123[2] This is a very important term of art in archaeology. It means that the artefact was excavated by a qualified team of archaeologists that painstakingly recorded every little detail of the excavation so that the dating can be validated using several different methods (carbon dating only works up to about 60k years)[3] https://humanorigins.si.edu/evidence/behavior/getting-food/o...reply",
      "Well, today I learned something! Thanks for the information, I guess I know which rabbit hole I'm going down today.reply",
      "Just edited to add two paper citations for the phytoliths and microwear studies. Have fun! It\u2019s a deep rabbit hole largely ignored by popsci publications so there\u2019s lots to explore.reply",
      "As you seem knowledgeable of this topic and it is super interesting, any books you would recommend that gives a good broad overview of all of this?reply",
      "I don\u2019t read popsci but if you\u2019re interested in a rigorous treatment I\u2019d recommend The Human Career by Klein which has the broad overview and The Human Past edited by Scarre which is more of a textbook.I mostly just read the papers as they are published but I\u2019ve heard good things about those two books (they\u2019re on my reading list but I haven\u2019t read enough to form an opinion)reply",
      "Thanks! I'll add them to my reading list for today. Its going to be interesting, I can already tell.reply",
      "To put it into perspective, we did not invent fire.reply"
    ],
    "link": "https://www.nytimes.com/2026/01/26/science/archaeology-neanderthals-tools.html",
    "first_paragraph": ""
  },
  {
    "title": "Rust\u2019s Standard Library on the GPU (vectorware.com)",
    "points": 67,
    "submitter": "justaboutanyone",
    "submit_time": "2026-01-24T04:49:02 1769230142",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=46741150",
    "comments": [
      "Are there any details around how the round-trip and exchange of data (CPU<->GPU) is implemented in order to not be a big (partially-hidden) performance hit?e.g. this code seems like it would entirely run on the CPU?    print!(\"Enter your name: \");\n    let _ = std::io::stdout().flush();\n    let mut name = String::new();\n    std::io::stdin().read_line(&mut name).unwrap();\n\nBut what if we concatenated a number to the string that was calculated on the GPU or if we take a number:    print!(\"Enter a number: \");\n    [...] // string number has to be converted to a float and sent to the GPU\n    // Some calculations with that number performed on the GPU\n    print!(\"The result is: \" + &the_result.to_string()); // Number needs to be sent back to the CPU\n\n\nOr maybe I am misunderstanding how this is supposed to work?reply",
      "Why are you assuming that this is intended to be performant, compared with code that properly segregates the CPU- and GPU-side? It seems clear to me that the latter will be a win.reply",
      "I feel like the title is a bit misleading. I think it should be something like \"Using Rust's Standard Library from the GPU\". The stdlib code doesn't execute on the GPU, it is just a remote function call, executed on the CPU, and then the response is returned. Very neat, but not the same as executing on the GPU itself as the title implies.reply",
      "> For example, std::time::Instant is implemented on the GPU using a device timerThe code is running on the gpu there. It looks like remote calls are only for \"IO\", the compiled stdlib is generally running on gpu. (Going just from the post, haven't looked at any details)reply",
      "I think it fits quite well. Kind of like the rust standard lib runs on the cpu this does partially run on the gpu. The post does say they fall back on syscalls but for others there a native calls on the gpu itself such as Instant. The same way the standard lib uses syscalls on the cou instead of doing everything in processreply",
      "I'm confused about this: As the article outlines well, Std Rust (over core) buys you GPOS-provided things. For example:  - file system\n  - network interfaces\n  - dates/times\n  - Threads, e.g. for splitting across CPU cores\n\nThe main relevant one I can think which applies is an allocator.I do a lot of GPU work with rust: Graphics in WGPU, and Cuda kernels + cuFFT mediated by Cudarc (A thin FFI lib). I guess, running Std lib on GPU isn't something I understand. What would be cool is the dream that's been building for decades about parallel computing abstractions where you write what looks like normal single-threaded CPU code, but it automagically works on SIMD instructions or GPU. I think this and CubeCL may be working towards that? (I'm using Burn as well on GPU, but that's abstracted over)Of note: Rayon sort of is that dream for CPU thread pools!reply",
      "The GPU shader just calls back to the CPU which executes the OS-specific function and relays the answer to the GPU side.  It might not make much sense on its own to have such strong coupling, but it gives you a default behavior that makes coding easier.reply",
      "Can I execute FizzBuzz and DOOM on GPU?reply",
      "How different is it from rust-gpu effort?UPDATE: Oh, that's a post from maintainers or rust-gpu.reply"
    ],
    "link": "https://www.vectorware.com/blog/rust-std-on-gpu/",
    "first_paragraph": "GPU code can now use Rust's standard library. We share the implementation approach and what this unlocks for GPU programming.At VectorWare, we are building the first\nGPU-native software company. Today, we are excited to\nannounce that we can successfully use Rust's standard library from GPUs. This milestone\nmarks a significant step towards our vision of enabling developers to write complex,\nhigh-performance applications that leverage the full power of GPU hardware using\nfamiliar Rust abstractions.This post is a preview of what we've built. We're preparing our work for potential\nupstreaming and will share deeper technical details in future posts.Rust's standard library is organized as a set of\nlayered abstractions:A defining feature of Rust is that layers 2 and 3 are optional. Code can opt out of\nstd via the #![no_std] annotation, relying only on core and, when needed, alloc.\nThis makes Rust usable in domains such as\nembedded,\nfirmware, and\ndrivers, which lack a traditional operating sys"
  },
  {
    "title": "A few random notes from Claude coding quite a bit last few weeks (twitter.com/karpathy)",
    "points": 318,
    "submitter": "bigwheels",
    "submit_time": "2026-01-26T21:09:19 1769461759",
    "num_comments": 329,
    "comments_url": "https://news.ycombinator.com/item?id=46771564",
    "comments": [
      "> It's so interesting to watch an agent relentlessly work at something. They never get tired, they never get demoralized, they just keep going and trying things where a person would have given up long ago to fight another day. It's a \"feel the AGI\" moment to watch it struggle with something for a long time just to come out victorious 30 minutes later.Somewhere, there are GPUs/NPUs running hot. You send all the necessary data, including information that you would never otherwise share. And you most likely do not pay the actual costs. It might become cheaper or it might not, because reasoning is a sticking plaster on the accuracy problem. You and your business become dependent on this major gatekeeper. It may seem like a good trade-off today. However, the personal, professional, political and societal issues will become increasingly difficult to overlook.reply",
      "This quote stuck out to me as well, for a slightly different reason.The \u201ctenacity\u201d referenced here has been, in my opinion, the key ingredient in the secret sauce of a successful career in tech, at least in these past 20 years. Every industry job has its intricacies, but for every engineer who earned their pay with novel work on a new protocol, framework, or paradigm, there were 10 or more providing value by putting the myriad pieces together, muddling through the ever-waxing complexity, and crucially never saying die.We all saw others weeded out along the way for lacking the tenacity. Think the boot camp dropouts or undergrads who changed majors when first grappling with recursion (or emacs). The sole trait of stubbornness to \u201ckeep going\u201d outweighs analytical ability, leetcode prowess, soft skills like corporate political tact, and everything else.I can\u2019t tell what this means for the job market. Tenacity may not be enough on its own. But it\u2019s the most valuable quality in an employee in my mind, and Claude has it.reply",
      "There is an old saying back home: an idiot never tires, only sweats.Claude isn't tenacious. It is an idiot that never stops digging because it lacks the meta cognition to ask 'hey, is there a better way to do this?'. Chain of thought's whole raison d'etre was so the model could get out of the local minima it pushed itself in. The issue is that after a year it still falls into slightly deeper local minima.This is fine when a human is in the loop. It isn't what you want when you have a thousand idiots each doing a depth first search on what the limit of your credit card is.reply",
      "> it lacks the meta cognition to ask 'hey, is there a better way to do this?'.Recently had an AI tell me this code (that it wrote) is a mess and suggested wiping it and starting from scratch with a more structure plan. That seems to hint at some meta cognition outlinesreply",
      "Haha, it has the human developer traits of thinking all old code is garbage, failing to identify oneself as the dummy who wrote this particular code, and wanting to start from scratch.reply",
      "It's like NIH syndrome but instead \"not invented here today\". Also a very human thing.reply",
      "Metacognition As A Service, you say?reply",
      "I mean, not always. I've seen Claude step back and reconsider things after hitting a dead end, and go down a different path. There are also workflows, loops that can increase the likelihood of this occurring.reply",
      "This is a major concern for junior programmers. For many senior ones, after 20 (or even 10) years of tenacious work, they realize that such work will always be there, and they long ago stopped growing on that front (i.e. they had already peaked). For those folks, LLMs are a life saver.At a company I worked for, lots of senior engineers become managers because they no longer want to obsess over whether their algorithm has an off by one error. I think fewer will go the management route.(There was always the senior tech lead path, but there are far more roles for management than tech lead).reply",
      "That's just sad. Right when I found love in what I do, my work has no value anymore.reply"
    ],
    "link": "https://twitter.com/karpathy/status/2015883857489522876",
    "first_paragraph": "We\u2019ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.Help Center\nTerms of Service\nPrivacy Policy\nCookie Policy\nImprint\nAds info\n      \u00a9 2026 X Corp.\n    "
  },
  {
    "title": "Time Station Emulator (github.com/kangtastic)",
    "points": 91,
    "submitter": "FriedPickles",
    "submit_time": "2026-01-27T20:35:34 1769546134",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=46786183",
    "comments": [
      "\u201cOne of the higher-frequency harmonics inevitably created by any real-world DAC during playback will then be the original fundamental, which should leak to the environment as a short-range radio transmission via the ad-hoc antenna formed by the physical wires and circuit traces in the audio output path.\u201dSometimes I think I\u2019m a smart guy\u2026and then I read of people doing shit like this.reply",
      "Van Eck Phreaking dates back to 1982, which used CRTs, and if you're aware of that, it's not an insurmountably huge logical leap to realize that modern hardware can be exploited the same way (thanks to greater sensitivity in receiving devices).https://en.wikipedia.org/wiki/Van_Eck_phreakingreply",
      "Came here to say this, I literally can't believe this works.It's like a couple of years ago where someone showed a proof of concept of turning a HDD into a microphonereply",
      "This certainly looks impressive but it\u2019s a bit misleading to say it works on \u201calmost any phone\u201d when it doesn\u2019t work on iPhone (which only allows mobile Safari)reply",
      "I once programmed my TI-84 calculator to do exactly this! The only missing thing was a circuit to convert the audio jack output voltage into the needed form for an antenna. I had the CS know-how but no EE know-how, so I never got it to work. It was fun to dream about confusing my high school's clocks though. (Sadly, the other obstacle was that the clocks only listened for the signal overnight, which improved their chances of detecting the weak broadcast out of far-away Colorado.)reply",
      "> audio jackThat's a serial port, except when you're playing Bad Applereply",
      "You can apparently lock shopping trolleys using the same kind of principle - https://www.tmplab.org/2008/06/18/consumer-b-gone/And https://www.youtube.com/watch?v=LmSyb0kBvGEreply",
      "He kind of buried the lede, there's another MP3 to unlock them.reply",
      "Shame there's no video demonstrating it working. It's a fun idea but without a demo, I'm left wondering about the efficacy.reply",
      "I wasn't able to get this to work on a Pixel 8 in Chrome/Firefox on a JP region clockreply"
    ],
    "link": "https://github.com/kangtastic/timestation",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Synchronize most radio-controlled (\"atomic\") clocks and watches using almost any phone or tablet\n      Time Station Emulator turns almost any phone or tablet into a low-frequency\nradio transmitter broadcasting a time signal that can synchronize most\nradio-controlled (\u201catomic\u201d) clocks and watches.Real time signal broadcasts are limited in geographic range and notoriously\nprone to interference in urban areas, so many such clocks end up never actually\nusing their self-setting functionality. Time Station Emulator may allow\nsetting such clocks when/where a suitable signal is not otherwise available.The hard requirements of note are browser WebAssembly support and DAC support\nfor \u226544.1 KHz PCM. Almost any device running a browser from \u22652019 should\nwork.However, as of early 2024, Safari on iOS and Firefox on Android have\nmultiple breaking "
  },
  {
    "title": "Lennart Poettering, Christian Brauner founded a new company (amutable.com)",
    "points": 220,
    "submitter": "hornedhob",
    "submit_time": "2026-01-27T18:57:15 1769540235",
    "num_comments": 295,
    "comments_url": "https://news.ycombinator.com/item?id=46784572",
    "comments": [
      "Hi, Chris here, CEO @ Amutable. We are very excited about this. Happy to answer questions.",
      "This seems like the kind of technology that could make the problem described in https://www.gnu.org/philosophy/can-you-trust.en.html a lot worse. Do you have any plans for making sure it doesn't get used for that?reply",
      "I'm Aleksa, one of the founding engineers. We will share more about this in the coming months but this is not the direction nor intention of what we are working on. The models we have in mind for attestation are very much based on users having full control of their keys. This is not just a matter of user freedom, in practice being able to do this is far more preferable for enterprises with strict security controls.I've been a FOSS guy my entire adult life, I wouldn't put my name to something that would enable the kinds of issues you describe.reply",
      "> I've been a FOSS guy my entire adult life, I wouldn't put my name to something that would enable the kinds of issues you describe.Until you get acquired, receive a golden parachute and use it when realizing that the new direction does not align with your views anymore.But, granted, if all you do is FOSS then you will anyway have a hard time keeping evil actors from using your tech for evil things. Might as well get some money out of it, if they actually dump money on you.reply",
      "So far, that's a slick way to say not really. You are vague where it counts, and surely you have a better idea of the direction than you say.Attestation of what to whom for which purpose? Which freedom does it allow users to control their keys, how does it square with remote attestation and the wishes of enterprise users?reply",
      "Thanks, this would be helpful. I will follow on by recommending that you always make it a point to note how user freedom will be preserved, without using obfuscating corpo-speak or assuming that users don\u2019t know what they want, when planning or releasing products. If you can maintain this approach then you should be able to maintain a good working relationship with the community. If you fight the community you will burn a lot of goodwill and will have to spend resources on PR. And there is only so much that PR can do!Better security is good in theory, as long as the user maintains control and the security is on the user end. The last thing we need is required ID linked attestation for accessing websites or something similar.reply",
      "that\u2019s great that you\u2019ll let users have their own certificates and all, but the way this will be used is by corporations to lock us out into approved Linux distributions. Linux will be effectively owned by RedHat and Microsoft, the signing authority.it will be railroaded through in the same way that systemD was railroaded onto us.reply",
      "Thanks for the reassurance, the first ray of sunshine in this otherwise rather alarming thread. Your words ring true.It would be a lot more reassuring if we knew what the business model actually was, or indeed anything else at all about this. I remain somewhat confused as to the purpose of this announcement when no actual information seems to be forthcoming. The negative reactions seen here were quite predictable, given the sensitive topic and the little information we do have.reply",
      "Can I build my own kernel and still use software that wants attestation?reply",
      "This is extremely bad logic. The technology of enforcing trusted software is without inherent value good or ill depending entirely on expected usage. Anything that is substantially open will be used according to the values of its users not according to your values so we ought instead to consider their values not yours.Suppose you wanted to identify potential agitators by scanning all communication for indications in a fascist state one could require this technology in all trusted environments and require such an environment to bank, connect to an ISP, or use Netflix.One could even imagine a completely benign usage which only identified actual wrong doing alongside another which profiled based almost entirely on anti regime sentiment or reasonable discontent.The good users would argue that the only problem with the technology is its misuse but without the underlying technology such misuse is impossible.One can imagine two entirely different parallel universes one in which a few great powers went the wrong way in part enabled by trusted computing and the pervasive surveillance enabled by the capability of AI to do the massive and boring task of analyzing a massive glut of ordinary behaviour and communication + tech and law to ensure said surveillance is carried out.Even those not misusing the tech may find themselves worse off in such a world.Why again should we trust this technology just because you are a good person?reply"
    ],
    "link": "https://amutable.com/about",
    "first_paragraph": ""
  },
  {
    "title": "Try text scaling support in Chrome Canary (joshtumath.uk)",
    "points": 73,
    "submitter": "linolevan",
    "submit_time": "2026-01-27T19:20:24 1769541624",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=46784977",
    "comments": [
      "Good problem to solve, but this particular solution is a fast path to hell for everyone involved.You just can't scale text size independently of layout and interface.  The size of the text is fundamentally related to the structural layout of the page.  The number of columns, the size of images, the relative placement of buttons and UI elements -- it's all inextricably tied to the size of the text.Good news is that we already have a solution for this: responsive design, aka page zoom.  Every serious site already gracefully handles a wide range of viewport widths.  When you zoom in, you are simply simulating a narrower viewport width.  This type of constraint and flexibility is already well tested.  Zooming in makes the text bigger.  And, zooming in makes the layout adapt to a single column when that's all that will fit.  It all works harmoniously together, because we test and accommodate for all viewport sizes, which is the same as all zoom levels.The proposal at hand to scale text alone is bad for everyone.  Developers now have a geometric set of permutations to test.  What about an ultra-wide viewport with large text?  What about a small viewport with large text?  What about a wide viewport with small text?  It's so much that it won't make business sense to invest in all of the testing, and all of the design and implementation work to accommodate all of the cases.  And so, it will be bad for end users who will set their text size to their preference, and then find that actually usability and readability are now worse.In the end the answer is simple: when users set their text size to be larger in the OS, browser vendors should increase the default zoom in browsers.  This is already how it works on Windows, and it is definitely the best path to happiness for all.reply",
      "That's the testing matrix we have to do for iOS and Android apps today. The screen sizes don't go all the way up to ultrawide, but 13\" iPad (portrait and landscape) down to 4\" iPhone Mini, at every \"Dynamic Type\" display setting is required.It's not that tough, but there can be tricky cases.reply",
      "This is supporting something that already exists for native phone apps. My phone has separate options for display size and text size.And so I have it set to have smaller buttons but still a normal-size font.reply",
      "In addition, desktop Firefox has had support for \"zoom text only\" for about 20 years or so (can be enabled in settings). It works fine.Don't know about mobile, probably works there too.reply",
      "Seriously.Browsers originally had text zoom -- only text zoom -- until page zoom was invented, I can't remember by which browser. And then page zoom quickly became the \"main\" zoom mechanism across all browsers because it was obviously so much better -- icons, layout, everything adjusted together. (And for those who remember, when there was only text zoom, it was a common practice/workaround to define everything in em rather than px, precisely to \"fake\" page zoom with text zoom.)I'm baffled by the idea of trying to bring text zoom back. Just no, a million times. We tried it. It was bad.reply",
      "After reading it, I'm still left asking why browsers can't do this for the user on mobile as well. User preferences should be respected by default and not require an opt-in step from the webmaster of all parties.I tried using a bunch of zoom on my most frequented sites and they mostly worked just fine. At my day job everything is tested to work at 200% zoom as a baseline.I really don't think we should bend over backwards to cater to accessibility offenders such as LinkedIn.reply",
      "Most any site should work with zoom. This is about the scale of the text separate from the level of the zoom. The latter breaks a lot of sites because many common layouts assume the layout space for the text will always grow along with the text, as seen in zoom.reply",
      "What we need on mobile is the ability to pinch zoom on images to scale the page and pinch zoom on text with font scaling. This needs to work universally without depending on developers to include a CSS magic incantation. It's already ridiculous that a user agent will refuse to zoom at all because of the page design.reply",
      "> how do we get large text to scale at a lower rate than body text. It's great that the body text can scale up from 16px to 32px, but does heading text need to scale up from 32px to 64px? It's already huge. If you have any thoughts, please do let me know!Android 14 has this in non-linear text scaling -> To prevent large text elements on screen from scaling too large, the system applies a nonlinear scaling curve.https://developer.android.com/about/versions/14/features#non...reply",
      "As someone whose eyesight is getting worse, thank you for helping make this happenreply"
    ],
    "link": "https://www.joshtumath.uk/posts/2026-01-27-try-text-scaling-support-in-chrome-canary/",
    "first_paragraph": ""
  },
  {
    "title": "Doing the thing is doing the thing (softwaredesign.ing)",
    "points": 217,
    "submitter": "prakhar897",
    "submit_time": "2026-01-27T06:17:46 1769494666",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=46776155",
    "comments": [
      "The \"doing it badly\" principle changed everything for me. I spent weeks planning the perfect architecture for some automation tools I was building. Then I just... stopped planning and built the ugly version that solved my own pain point.What surprised me was how much the ugly first version taught me that planning never could. You learn what users actually care about (often not what you expected), which edge cases matter in practice, and what \"good enough\" looks like in context.The hardest part is giving yourself permission to ship something you know is flawed. But the feedback loop from real usage is worth more than weeks of hypothetical architecture debates.reply",
      "\"Doing it badly is doing the thing.\"This one works for me, and I've learned it from a post on HN. Whenever I feel stuck or overthink how to do something, just do it first - even with all the flaws that I'm already aware of, and if it feels almost painful to do it so badly. Then improve it a bit, then a bit, then before I know it a clear picture start to emerge... Feels like magic.reply",
      "\"Everything worth doing is worth doing badly.\"Got me through many a rough spot.reply",
      "it fits well enough into another frame - make it work, then make it pretty, then make it fastif youre worried about doing it well, youre a step or two ahead of where you need to bereply",
      "My two favorite bits of wisdom in this vein:Dan Harmon's advice on writer's block: https://www.reddit.com/r/Screenwriting/comments/5b2w4c/dan_h...>You know how you suck and you know how everything sucks and when you see something that sucks, you know exactly how to fix it, because you're an asshole. So that is my advice about getting unblocked. Switch from team \"I will one day write something good\" to team \"I have no choice but to write a piece of shit\" and then take off your \"bad writer\" hat and replace it with a \"petty critic\" hat and go to town on that poor hack's draft and that's your second draft.\"The Gap\" by Ira Glass: https://www.reddit.com/r/Screenwriting/comments/c98jpd/the_g...>Your taste is why your work disappoints you... it is only by going through a volume of work that you will close that gap, and your work will be as good as your ambitions.*reply",
      "I miss Harmontown dearly. He was always dropping solid-gold wisdom like this in the middle of otherwise borderline-incoherent rants.reply",
      "Except you do this in a corporate setting and they will stop you the second it works. And then you are stuck maintaining a barely working version forever.I learned this the bad way, but now I just lie and say it doesn't work until it's good enough for mereply",
      "^^^ THIS ... If what you're building is useful, showing someone a prototype too early can cause the whole company to rush you to deploy.reply",
      "Everyone's threshold is different. I aspire to \"move fast and break things\", but more often than not, I obsess over the rough edges.reply",
      "\"When in doubt, use brute force.\"reply"
    ],
    "link": "https://www.softwaredesign.ing/blog/doing-the-thing-is-doing-the-thing",
    "first_paragraph": "NOTICE: Currently exploring full-time and contract rolesThinking about doing the thing is not doing the thing.Dreaming about doing the thing is not doing the thing.Visualizing success from doing the thing is not doing the thing.Waiting to feel ready to do the thing is not doing the thing.Talking about doing the thing is not doing the thing.Explaining the thing to others is not doing the thing.Arguing online about the thing is not doing the thing.Announcing that you\u2019ll start the thing is not doing the thing.Listening to podcasts about doing the thing is not doing the thing.Watching tutorials about doing the thing is not doing the thing.Reading threads about how others did the thing is not doing the thing.Planning the perfect system for the thing is not doing the thing.Buying tools for the thing is not doing the thing.Reorganizing your workspace for the thing is not doing the thing.Feeling guilty about not doing the thing is not doing the thing.Being \u201cbusy\u201d instead of doing the thing is "
  },
  {
    "title": "SoundCloud Data Breach Now on HaveIBeenPwned (haveibeenpwned.com)",
    "points": 148,
    "submitter": "gnabgib",
    "submit_time": "2026-01-27T17:11:39 1769533899",
    "num_comments": 77,
    "comments_url": "https://news.ycombinator.com/item?id=46782930",
    "comments": [
      "I went through and deleted a bunch of accounts a while ago, SoundCloud being one of them. It looks like I don't show up in the breach. It's nice to know SoundCloud actually deleted my data, I'm never totally sure what happens on the backend.reply",
      "Only 20% of accounts were breached, so that's an optimistic conclusion.reply",
      "In theory, it's a legal requirement based on GDPR and CCPA as well as many other new digital rights laws across Europe and many states in the USA. SoundCloud is probably big enough to do that correctly otherwise e.g. the GDPR penalty is a highish percentage of the company's total revenue which gives the laws a good amount of \"teeth\".reply",
      "For some services, like Anthropic/Claude's stubborn refusal to let you remove your payment method, deleting isn't even an option.reply",
      "\"The data involved consisted only of email addresses and information already visible on public SoundCloud profiles\".So they've scraped public data. Why care?reply",
      "Hackers stole information of 29.8M accounts (~20% of users).  SoundCloud is downplaying the data beyond email address as \"publicly available\", but the data wasn't scraped.  \"Profile statistics\" aren't public either.  Their main response[0], seems to focus on passwords and payment details being the only risky data. They even imply email addresses are public.> no sensitive data was taken in the incident.The data involved consisted only of email addresses and information already visible on public SoundCloud profiles (not financial or password data)[0]: https://soundcloud.com/playbook-articles/protecting-our-user...reply",
      "If the email addresses were visible on public profile pages in what sense are they not public?reply",
      "Email addresses are not visible on public soundcloud profiles. You can test this yourself.I read the statement to be \"emails plus public information\"reply",
      "Maybe the two public data points weren't connected before?I don't use SoundCloud, but if profiles didn't have contact information like Email Address on them then it could be meaningful to now connect those two dots.Like, 'Hey look, Person A, who is known to use email address X, kept Lost Prophets as one of their liked artists even after 2013!'reply",
      "Yeah or this: https://news.ycombinator.com/item?id=26386418SoundCloud is a weird place, people in entertainment have certain strong incentives. They figured out who I am, figured out all the email addresses I have, jacked the account attached to my SoundCloud, stole my account. I still to this day, don't know how they pwned my email (tfa was on but it didn't trigger suspicious activity it let them login without triggering it, no clue how they got the password either and the password is secure enough that it's too hard to brute force, and it's not in a pwned db). Based on what was in my soundcloud inbox when I got access again, someone paid a fair amount to have this done... and now I have to go change my email again I suppose.reply"
    ],
    "link": "https://haveibeenpwned.com/Breach/SoundCloud",
    "first_paragraph": ""
  },
  {
    "title": "Xfwl4 \u2013 The Roadmap for a Xfce Wayland Compositor (alexxcons.github.io)",
    "points": 263,
    "submitter": "pantalaimon",
    "submit_time": "2026-01-27T13:25:53 1769520353",
    "num_comments": 205,
    "comments_url": "https://news.ycombinator.com/item?id=46779645",
    "comments": [
      ">The goal is, that xfwl4 will offer the same functionality and behavior as xfwm4 does...I wonder how strictly they interpret behavior here given the architectural divergence?As an example, focus-stealing prevention. In xfwm4 (and x11 generally), this requires complex heuristics and timestamp checks because x11 clients are powerful and can aggressively grab focus. In wayland, the compositor is the sole arbiter of focus, hence clients can't steal it, they can only request it via xdg-activation. Porting the legacy x11 logic involves the challenge of actually designing a new policy that feels like the old heuristic but operates on wayland's strict authority model.This leads to my main curiosity regarding the raw responsiveness of xfce. On potato hardware, xfwm4 often feels snappy because it can run as a distinct stacking window manager with the compositor disabled. Wayland, by definition forces compositing. While I am not concerned about rust vs C latency (since smithay compiles to machine code without a GC), I am curious about the mandatory compositing overhead. Can the compositor replicate the input-to-pixel latency of uncomposited x11 on low-end devices or is that a class of performance we just have to sacrifice for the frame-perfect rendering of wayland?reply",
      "(xfwl4 author here.)> I wonder how strictly they interpret behavior here given the architectural divergence?It's right there in the rest of the sentence (that you didn't quote all of): \"... or as much as possible considering the differences between X11 and Wayland.\"I'll do my best.  It won't be exactly the same, of course, but it will be as close as I can get it.> As an example, focus-stealing prevention.Focus stealing prevention is a place where I think xfwl4 could be at an advantage over xfwm4.  Xfwm4 does a great job at focus-stealing prevention, but it has to work on a bunch of heuristics, and sometimes it just does the wrong thing, and there's not much we can do about it.  Wayland's model plus xdg-activation should at least make the focus-or-don't-focus decision much more consistent.> I am curious about the mandatory compositing overhead. Can the compositor replicate the input-to-pixel latency of uncomposited x11 on low-end devices or is that a class of performance we just have to sacrifice for the frame-perfect rendering of wayland?I'm not sure yet, but I suspect your fears are well-founded here.  On modern (and even not-so-modern) hardware, even low-end GPUs should be fine with all this (on my four-year-old laptop with Intel graphics, I can't tell the difference performance-wise with xfwm4's compositor on or off).  But I know people run Xfce/X11 on very-not-modern hardware, and those people may unfortunately be left behind.  But we'll see.reply",
      "One thing to keep in mind is that composition does not mean you have to do it with vsync, you can just refresh the screen the moment a client tells you the window has new contents.reply",
      "At least they are honest regarding the reasons, not a wall of text to justify what bails down to \"because I like it\".Naturally these kinds of having a language island create some attrition regarding build tooling, integration with existing ecosystem and who is able to contribute to what.So lets see how it evolves, even with my C bashing, I was a much happier XFCE user than with GNOME and GJS all over the place.reply",
      "You know that all the Wayland primitives, event handling and drawing in gnome-shell are handled in C/native code through Mutter, right ?\nThe JavaScript in gnome-shell is the cherry on top for scripting, similar to C#/Lua (or any GCed language) in game engines, elisp in Emacs, event JS in QtQuick/QML.It is not the performance bottleneck people seem to believe.reply",
      "I can dig out the old GNOME tickets and related blog posts...Implementation matters, including proper use of JIT/AOT toolchains.reply",
      ">I can dig out the old GNOME tickets and related blog posts...That's the easiest way you can win any argument on gnome. You're going straight for the nuclear option.reply",
      "It has been the case that stalls in the GJS land can stall the compositor though, especially if it's during a GC cycle.reply",
      "Compositor overhead even with cheapo Intel laptop graphics is basically a non-issue these days.  The people still rocking their 20 year old thinkpads might want to choose something else, but besides that kind of user I don't think it's worth worrying too much about.reply",
      "> Can the compositor replicate the input-to-pixel latency of uncomposited x11 on low-end devices or is that a class of performance we just have to sacrifice for the frame-perfect rendering of wayland?I think this is ultimately correct. The compositor will have to render a frame at some point after the VBlank signal, and it will need to render with it the buffers on-screen as of that point, which will be from whatever was last rendered to them.This can be somewhat alleviated, though. Both KDE and GNOME have been getting progressively more aggressive about \"unredirecting\" surfaces into hardware accelerated DRM planes in more circumstances. In this situation, the unredirected planes will not suffer compositing latency, as their buffers will be scanned out by the GPU at scanout time with the rest of the composited result. In modern Wayland, this is accomplished via both underlays and overlays.There is also a slight penalty to the latency of mouse cursor movement that is imparted by using atomic DRM commits. Since using atomic DRM is very common in modern Wayland, it is normal for the cursor to have at least a fraction of a frame of added latency (depending on many factors.)I'm of two minds about this. One, obviously it's sad. The old hardware worked perfectly and never had latency issues like this. Could it be possible to implement Wayland without full compositing? Maybe, actually. But I don't expect anyone to try, because let's face it, people have simply accepted that we now live with slightly more latency on the desktop. But then again, \"old\" hardware is now hardware that can more often than not, handle high refresh rates pretty well on desktop. An on-average increase of half a frame of latency is pretty bad with 60 Hz: it's, what, 8.3ms? But half a frame at 144 Hz is much less at somewhere around 3.5ms of added latency, which I think is more acceptable. Combined with aggressive underlay/overlay usage and dynamic triple buffering, I think this makes the compositing experience an acceptable tradeoff.What about computers that really can't handle something like 144 Hz or higher output? Well, tough call. I mean, I have some fairly old computers that can definitely handle at least 100 Hz very well on desktop. I'm talking Pentium 4 machines with old GeForce cards. Linux is certainly happy to go older (though the baseline has been inching up there; I think you need at least Pentium now?) but I do think there is a point where you cross a line where asking for things to work well is just too much. At that point, it's not a matter of asking developers to not waste resources for no reason, but asking them to optimize not just for reasonably recent machines but also to optimize for machines from 30 years ago. At a certain point it does feel like we have to let it go, not because the computers are necessarily completely obsolete, but because the range of machines to support is too wide.Obviously, though, simply going for higher refresh rates can't fix everything. Plenty of laptops have screens that can't go above 60 Hz, and they are forever stuck with a few extra milliseconds of latency when using a compositor. It is unideal, but what are you going to do? Compositors offer many advantages, it seems straightforward to design for a future where they are always on.reply"
    ],
    "link": "https://alexxcons.github.io/blogpost_15.html",
    "first_paragraph": "We, the Xfce team are excited to share some great news!After careful consideration, we\u2019ve decided on a meaningful way to use the generous donations from our community: funding longtime Xfce core developer Brian Tarricone to create xfwl4, a brand-new Wayland compositor for Xfce.This initiative will utilize a significant portion of the project\u2019s donated funds, but we believe it\u2019s an important investment in Xfce\u2019s future.The goal is, that xfwl4 will offer the same functionality and behavior as xfwm4 does, or as much as possible considering the differences between X11 and Wayland. Using xfwl4 should feel just like using xfwm4 on X11. We even plan to reuse the existing xfwm4 configuration dialogs and xfconf settings to ensure a seamless transition.Xfwl4 will not be based on the existing xfwm4 code. Instead, it will be written from scratch in rust, using smithay building blocks.The first attempt at creating an Xfce Wayland compositor involved modifying the existing xfwm4 code to support both"
  },
  {
    "title": "AI2: Open Coding Agents (allenai.org)",
    "points": 117,
    "submitter": "publicmatt",
    "submit_time": "2026-01-27T17:17:54 1769534274",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=46783017",
    "comments": [
      "\u201cStrong closed-weight coding agents like Devstral Small 2 are an important point of comparison.\u201dDevstral Small 2 is an open-weights model: https://huggingface.co/mistralai/Devstral-Small-2-24B-Instru...reply",
      "Claims in the article are incorrect. They conveniently ignore Meta CWM models, which are open-sourced [1] and open-weight [2] and are at 65% SWE-bench verified (with TTS) and 54% pass@1 and the same size (32B dense). So claims like \"surpassing prior open-source state-of-the-art coding models of comparable sizes and context lengths\" and conveniently leaving out the previous OSS SOTA out of your eval tables are ... sketch.[1]https://github.com/facebookresearch/cwm\n[2]https://huggingface.co/facebook/cwmreply",
      "Hey! These are great observations. So first, while TTS can improve performance, we wanted to evaluate the raw capability of our model. This meant generating only one rollout per evaluation instance, which follows other papers in the space like SWE-smith and BugPilot. In addition, TTS adds extra inference cost and is reliant on how rollouts are ranked, two confounding factors for deployable models where memory and inference speed are extremely important.Following that line of reasoning, context length is another very large confounding factor. Longer context lengths improve performance - but also result in enormous increases in KV cache size and memory requirements. We decide to control for this in our paper and focus at the 32K context length for 32B size models, a context length that already pushes the bounds of what can be \"deployable\" locally.Still, we evaluate at 64K context length using YARN and are able to outperform CWM's 54% performance (non TTS), which it achieves using 128K context, a substantial increase over what we use. This is also pretty significant because we only ever train at 32K context, but CWM trains for a full 128K.reply",
      "The difference is that the Allen Institute models have open training data, not just open code and weights. Meta doesn't share the training data you would need to reproduce their final models. For many uses open-weight models are nearly as good, but for advancing research it's much better to have everything in the open.reply",
      "Reading their paper, it wasn't trained from scratch, it's a fine tune of a Qwen3-32B model. I think this approach is correct, but it does mean that only a subset of the training data is really open.reply",
      "The linked open weight disallows commercial, and is only licensed for research purposereply",
      "Great work! Really respect AI2. they open source everything. The model, the weights, the training pipeline, inference stack, and corpusreply",
      "One claim in article is definitely very wrong or at least needs to be narrowed. Claude is the only closed agent harness and there are about two dozen open ones. Many models may be closed, but when people say agent they are generally referring to the harness, not the underlying model.reply",
      "The ahmadyan comparison is fair. Meta's CWM models hitting 65% vs SERA's 54% is a meaningful gap.But the interesting number here isn't accuracy. It's the $400 to reproduce top open-source performance. That's the part that matters for teams building internal tooling.We've been running agents on proprietary codebases at work. The pain isn't model quality. It's customization. Most off-the-shelf agents don't understand your repo structure, your conventions, your test patterns. If you can fine-tune a 32B model on your own codebase for a few hundred dollars, that changes the economics completely.But codebases changes everyday, so finetuning will have to be continuously done!Probably not worth it versus something like Claude Code.Curious whether anyone's tried this on non-Python codebases. Most SWE-Bench stuff is Python-heavy.reply",
      "The fine-tuning overhead is definitely a factor, but for smaller shops the hard constraint is usually inference VRAM. Running a 32B model locally or on a rented GPU is surprisingly expensive if you aren't saturating it. Even at 4-bit quantization you are looking at dual 3090s or an A6000 to get decent tokens per second. The $400 training cost is impressive but the hosting bill is what actually kills the margin compared to per-token APIs.reply"
    ],
    "link": "https://allenai.org/blog/open-coding-agents",
    "first_paragraph": "January 27, 2026Ai2Over the past year, coding agents have transformed how developers write, test, and maintain software. These systems can debug, refactor, and even submit pull requests\u2014fundamentally changing what software development looks like. Yet despite this progress, most coding agents share the same constraints: they're closed, expensive to train, and difficult to study or adapt to private codebases.Ai2 Open Coding Agents change that. Today we\u2019re releasing not just a collection of strong open coding models, but a training method that makes building your own coding agent for any codebase \u2013 for example, your personal codebase or an internal codebase at your organization \u2013 remarkably accessible for tasks including code generation, code review, debugging, maintenance, and code explanation.Closed models haven't seen your internal code, so they don't know it\u2014custom data pipelines, internal APIs, specific org conventions, and so on. Training on your private data teaches them, but gener"
  },
  {
    "title": "FBI is investigating Minnesota Signal chats tracking ICE (nbcnews.com)",
    "points": 530,
    "submitter": "duxup",
    "submit_time": "2026-01-27T17:32:05 1769535125",
    "num_comments": 652,
    "comments_url": "https://news.ycombinator.com/item?id=46783254",
    "comments": [
      "With all the predatory tech Palantir has produced, it won't take more than a few minutes for FBI to start taking actions, IF they had anything tangible.This is just an intimidation tactic to stop people talking (chatting)reply",
      "I'm never sure why people assume that Palantir is magically unlike the overwhelming majority of tech startups/companies I've worked at: vastly over promising what is possible to create hype and value while offering things engineering knows will never really quite work like they're advertised.To your point, but on a larger scale, over hyping Palantir has the added benefit of providing a chilling effect on public resistance.As a former government employee I had the same reaction to the Snowden leaks: sure the government might be collecting all of this (which I don't support), but I've never seen the government efficiently action on any data they have collected.Incompetence might be the greatest safety we have against a true dystopia.reply",
      "Because Snowden, agree with him or not, showed us that reality blew away our imagination.It may feel normal now, but back then, serious people, professionals, told us that the claims just were not possible.Until we learned that they were.reply",
      "Until that moment, the general sentiment about the government and the internet is that they are too incompetent to do anything about it, companies like Microsoft/Apple/Google/Snapchat are actually secure so lax data/opsec is okay, etc.Meanwhile, the whole time, communications and tech companies were working hand in hand with the government siphoning up any and all data they could to successfully implement their LifeLog[1] pipe dream.[1] https://en.wikipedia.org/wiki/DARPA_LifeLogreply",
      "dont worry lifelog was cancelled in 2004 according to that wiki. Phew!reply",
      "Which claims? HN around that time was taking anything and everything and declaring it conclusively proved everything else.I honestly have no god damn clue what was actually revealed by the Snowden documents - people just say \"they revealed things\".reply",
      "Why are you asking here, versus going to Google and reading the original article from The Guardian? Or the numerous Wikipedia links that are on this page?reply",
      "that takes effort :)reply",
      "Because saying \"experts said things were impossible and then Snowden\" could mean literally anything. Which experts, what things?Like I said: I've read a ton of stuff, and apparently what people are sure they read is very different to what I read.reply",
      "You can read about PRISM, Upstream, FAIRVIEW, STORMBREW, NSA Section 215 (PATRIOT Act) in a lot of places. But essentially they collected all call records and tapped the Internet backbone and stored as much traffic as they could. It\u2019s not all automatic but it\u2019s overly streamlined given the promises of court orders. Which were rubber stamped.reply"
    ],
    "link": "https://www.nbcnews.com/tech/internet/fbi-investigating-minnesota-signal-minneapolis-group-ice-patel-kash-rcna256041",
    "first_paragraph": "BREAKING: Man tries to spray Rep. Ilhan Omar with an unknown substance during a Minneapolis town hall news AlertsThere are no new alerts at this timeFBI Director Kash Patel said Monday that he had opened an investigation into the Signal group text chats that Minnesota residents are using to share information about federal immigration agents\u2019 movements, launching a new front in the Trump administration\u2019s conflict there with potential free speech implications.Patel said in an interview with conservative podcaster Benny Johnson that he wanted to know whether any Minnesota residents had put federal agents \u201cin harm\u2019s way\u201d with activities such as sharing agents\u2019 license plate numbers and locations.\u201cYou cannot create a scenario that illegally entraps and puts law enforcement in harm\u2019s way,\u201d he said in the interview, which was posted to YouTube.The investigation quickly drew skepticism from free speech advocates who said the First Amendment protects members of the public who share legally obta"
  },
  {
    "title": "Amazon closing its Fresh and Go stores (yahoo.com)",
    "points": 149,
    "submitter": "trenning",
    "submit_time": "2026-01-27T15:41:14 1769528474",
    "num_comments": 370,
    "comments_url": "https://news.ycombinator.com/item?id=46781444",
    "comments": [
      "Doesn\u2019t surprise me.  I frequently shop at Amazon Fresh in store and it\u2019s a mediocre experience. It\u2019s a poorly run store with no visible manager making sure things are in order. You constantly have to work around employees fulfilling online orders and they aren\u2019t helpful.  I always find expired groceries/produce on the shelf so I have to spend a lot of extra time inspecting each item.  The only reason I put up with their nonsense is that some of their prices are insane and they have easy returns, for example $0.85 for a box of Barilla pasta. They actually don\u2019t accept returns in store and just refund you automatically in the app (Returnless returns).  It\u2019s pretty silly and rife for abuse.I also found a loophole with the Amazon.com return grocery credit.  The systems are separate for the $10 off $40 coupon and you just scan a QR code in the store to get it. It  turns out you can just take a photo of their QR code and reuse it over and over again.reply",
      "I feel like they artificially made their prices super low for the last couple years and intentionally operated at a loss as a business tactic to force out competition and kill off local grocery stores.  There were instances of their prices being lower than Walmart or other budget stores.  The avocados were $0.25 each and carrots were half price of ones in Safeway, even ground beef was weirdly cheap.  One time as a comparison I put the same items in my cart for Amazon fresh and Walmart and it was $21 at Amazon fresh and $36 at Walmart.  WAY cheaper than Instacart too.reply",
      "> operated at a loss as a business tactic to force out competition and kill off local grocery storesWouldn't surprise me. I know a guy who invented a device for truckers that became ubiquitous in truck stops across the US. This would've been like 2014.He refused to sell on Amazon, so Amazon duped his product and sold it at something crazy, like half price, until he agreed to list (at which point they dropped their competing product)reply",
      "Such tactics sound\u2026 illegalreply",
      "Haven\u2019t you heard? Laws don\u2019t apply to companiesreply",
      "And I thought corporations are people, my friend.reply",
      "Why am I seeing this?reply",
      "Illegal in what way? They are not allowed to set prices lower than competitors or raise them at any time?reply",
      "Predatory pricing is illegal in the US, but difficult to prosecute under the existing laws.reply",
      "What is \u201cpredatory pricing\u201d vs. \u201cpricing\u201d?reply"
    ],
    "link": "https://finance.yahoo.com/news/amazon-closing-fresh-grocery-convenience-150437789.html",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: One Human + One Agent = One Browser From Scratch in 20K LOC (emsh.cat)",
    "points": 142,
    "submitter": "embedding-shape",
    "submit_time": "2026-01-27T13:13:56 1769519636",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=46779522",
    "comments": [
      "This is a notably better demonstration of a coding agent generated browser than Cursor's FastRender - it's a fraction of the size (20,000 lines of Rust compared to ~1.6m), uses way fewer dependencies (just system libraries for rendering images and text) and the code is actually quite readable - here's the flexbox implementation, for example: https://github.com/embedding-shapes/one-agent-one-browser/bl...Here's my own screenshot of it rendering my blog - https://bsky.app/profile/simonwillison.net/post/3mdg2oo6bms2... - it handles the layout and CSS gradiants really well, renders the SVG feed icon but fails to render a PNG image.I thought \"build a browser that renders HTML+CSS\" was the perfect task for demonstrating a massively parallel agent setup because it couldn't be productively achieved in a few thousand lines of code by a single coding agent. Turns out I was wrong!reply",
      "I think most people would agree that this is much more superior than Cursor's \"browser\" from an engineering perspective -- it doesn't do much but does it well, as you pointed out.What it tells me is that \"effectively using agents\" can be much more important than just throwing tokens at a problem and see what comes out. I myself have completely deleted several small vibe-coded projects without even going over the code, because what often happens is that, two days after the code is generated, I realize that I was solving the wrong problem or using the wrong approach.A coding agent doesn't care. It most likely just does whatever you ask it to do with no pushback. While in some cases it's worth using them to validate an idea, often you dig a deeper hole for yourself if you go down a wrong path in the first place.reply",
      "Yeah, I agree with all of what you wrote, how these are used seems (to me) to be more important than how they're built. If you don't know software engineering, a software engineering agent isn't suddenly gonna make you one, but someone who already knows the craft, can be very effective with one.Amplifiers, rather than replacements. I think the community at large still thinks LLMs and agents are gonna be \"replacing\" knowledge, which I think is far from the truth.reply",
      "I think the human + agent thing absolutely will make a huge difference. I see regularly that Claude can totally off piste and eventually claw itself back with a proper agent setup but it will take a lot of time if I don't spot it and get it back on track.I have one project Claude is working on right now where I'm testing a setup to attempt to take myself more out of the loop, because that is the hard part. It's \"easy\" to get an agent to multiply your output. It's hard to make that scale with your willingness to spend on tokens rather than with your ability to read and review and direct.I've ended up with roughly this (it's nothing particularly special):- Runs a evaluator that evaluates the current state and assigns scores across multiple metrics.- If a given score is above a given threshold, expand the test suite automatically.- If the score is below a given threshold, spawn a \"research agent\" that investgates why the scores don't meet expectations.- The research agent delivers a report, that is passed to an implementation agent.- The main agent re-runs the scoring, and if it doesn't show an improvement on one or more of the metrics, the commit is discarded, and notes made of what was tried, and why it failed.It takes a bit of trial and error to get it right (e.g. \"it's the test suite that is wrong\" came up early, and the main agent was almost talked into revising the test suite to remove the \"problematic\" tests) but a division sort of like this lets Claude do more sensible stuff for me. Throwing away commits feels drastic - an option is to let it run a little cycle of commit -> evaluate -> redo a few times before the final judgement, maybe - but it so far it feels like it'll scale better. Less crap makes it into the project.And I think this will work better than to treat these agents as if they are developers whose output costs 100x as much.Code so cheap it is disposable should change the workflows.So while I agree this is a better demonstration of a good way to build a browser, it's a less interesting demonstration as well. Now that we've seen people show that something like FastRender is possible, expect people to experiment with similarly ambitious projects but with more thought put into scoring/evaluation, including on code size and dependencies.reply",
      "> I think the human + agent thing absolutely will make a huge difference.Just the day(s) before, I was thinking about this too, and I think what will make the biggest difference is humans who posses \"Good Taste\". I wrote a bunch about it here: https://emsh.cat/good-taste/I think the ending is most apt, and where I think we're going wrong right now:> I feel like we're building the wrong things. The whole vibe right now is \"replace the human part\" instead of \"make better tools for the human part\". I don't want a machine that replaces my taste, I want tools that help me use my taste better; see the cut faster, compare directions, compare architectural choices, find where I've missed things, catch when we're going into generics, and help me make sharper intentional choices.reply",
      "For some projects, \"better tools for the human part\" is sufficient and awesome.But for other projects, being able to scale with little or no human involvement suddenly turns some things that were borderline profitable or not possible to make profitable at all with current salaries vs. token costs into viable businesses.Where it works, it's a paradigm shift - for both good and bad.So it depends what you're trying to solve for. I have projects in both categories.reply",
      "Personally I think the part where you try to eliminate humans from involvement, is gonna lead to too much trouble, being too inflexible and the results will be bad. It's what I've seen so far, haven't seen anything pointing to it being feasible, but I'd be happy to be corrected.reply",
      "It really depends on the type of tasks. There are many tasks LLMs do for me entirely autonomously already, because they do it well enough that it's no longer worth my time.reply",
      "To me I really like how embedding shapes took things in his own hands and actually built it. It really proved a point at such a scale where I don't think any recent example can point to.It's great to see hackernews be so core part of it haha.> I thought \"build a browser that renders HTML+CSS\" was the perfect task for demonstrating a massively parallel agent setup because it couldn't be productively achieved in a few thousand lines of code by a single coding agent. Turns out I was wrong!I do wonder if tech people from future/present are gonna witness this as a goliath vs david story. 20k 1 human 1 agent beats 5 million$ 1.6 millions loc browser changing how even the massive AI users/pioneers at the time thought about the use of AILooks like I have watched some documentaries recently but why do I feel like a documentary about this whole thing can be created in future.But also, More and more I am feeling like AI is an absolute black box, nobody knows how to do things but we are all kind of doing experiments with it and seeing what sticks (like how we now have definitive proof that 1 human 1 agent > many agents no human in the loop)And this is when we are 1 month in 2026, who knows what other experiments and proofs happen this year to find more about this black box, and about its usefulness or not.Simon, it would be interesting if you could read the thread of predictions of 2026 thread in hn each month or quaterly to see how many people were wrong or right about AI as we figure out more things perhaps.reply",
      "I set some rules for myself: three days of total time, no 3rd party Rust crates, allowed to use commonly available OS libraries, has to support X11/Windows/macOS and can render some websites.After three days, I have it working with around 20K LOC, whereas ~14K is the browser engine itself + X11, then 6K is just Windows+macOS support.Source code + CI built binaries are available here if you wanna try it out: https://github.com/embedding-shapes/one-agent-one-browserreply"
    ],
    "link": "https://emsh.cat/one-human-one-agent-one-browser/",
    "first_paragraph": "\n        2026-01-27\n      Just for the fun of it, I thought I'd embark on a week-long quest to\ngenerate millions of tokens and millions of lines of source code to\ncreate one basic browser that can render HTML and CSS (no JS tho), and\nhopefully I could use this to receive even more VC investments.But then I remembered that I have something even better: a human\nbrain! It is usually better than any machine at coordinating and\nthinking through things, so let's see if we can hack something together,\none human brain and one LLM agent brain!Demonstration of\none-agent-one-browser running with a bunch of different websites on\nLinux/X11The above might look like a simple .webm video, but it's actually a\nhighly sophisticated and advanced browser that was super hard to build,\nencoded as pixels in a video file! Wowzers.For extra fun when building this, I set these requirements for myself\nand the agent:So with these things in mind, I set out on the journal to build a\nbrowser \"from scratch\". I started"
  },
  {
    "title": "Show HN: Fuzzy Studio \u2013 Apply live effects to videos/camera (ulyssepence.com)",
    "points": 22,
    "submitter": "ulyssepence",
    "submit_time": "2026-01-27T15:16:34 1769526994",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=46781090",
    "comments": [
      "Hah this is the 3rd fun app like this I've seen lately. I really like yours!I also built one! In mine you can compose effects using a graph, I've gotten carried away and now I keep wanting to bring more TouchDesigner concepts into it. It's far off, but so much fun! The best feedback on these kinds of apps is if you put it in camera mode and on a TV, and let a kid dance around in front of it.https://vester.si/motion/I hope you don't mind if I steal some of you nice ideas for myself :)reply",
      "So much fun and beautifully implemented.I wish there was a way to use the output/preview as a virtual camera in Meet, Zoom etc. I could drive my colleagues potty with some of these :)reply",
      "Yeah iOS is no good for camera. UX is also a little hard to process on phones. Keep going!reply",
      "I couldn't play w/ it because it doesn't allow selecting the correct camera on macosreply",
      "FWIW, I was able to select a Logitech USB webcam on my Mac mini running Sequoia.reply",
      "I spent more time on Potion Seller than I'd like to admit. Great project!!reply"
    ],
    "link": "https://fuzzy.ulyssepence.com/",
    "first_paragraph": ""
  },
  {
    "title": "Thief of $90M in seized U.S.-controlled crypto is gov't contractor's son (web3isgoinggreat.com)",
    "points": 166,
    "submitter": "pavel_lishin",
    "submit_time": "2026-01-27T21:54:29 1769550869",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=46787521",
    "comments": [
      "So much of the government is like this, they will hire some connected guy to manage something in a slightly competent manner.Just learned that the federal government has long term leases on office buildings that congressmen have a financial interest in. More disappointment.reply",
      "To be clear: the crypto in question wasn't managed in even a slightly competent manner.  It was literally embezzled.reply",
      "It was embezzled in a slightly competent manner. Not very competently.reply",
      "And he has been and continues to make fun of the investigators, publicly mocking investigators and sending small amounts from the fraudulent wallets to investigators.Crazy worldreply",
      "If he \"invests\" some of his funds ... could get a pardon.reply",
      "with that dirtbag, anybody can get a pardon - even illegal immigrants and all they need is a dollarreply",
      "He\u2019s reaping what he saw. Things aren\u2019t looking good for him nor his father, a lesson both of them will painfully learn from. Father career is possibly over.reply",
      "> Things aren\u2019t looking good for him nor his father, a lesson both of them will painfully learn fromYou\u2019re a hell of an optimist.I\u2019d say that it\u2019s just as likely that the pardon sharpie is being readied, just as soon as the super PAC donation clears.reply",
      "Put it into Trump's coin as a donationreply",
      "Trump already rug pulledreply"
    ],
    "link": "https://www.web3isgoinggreat.com/single/lick-theft",
    "first_paragraph": "...and is definitely not an enormous grift that's pouring lighter fluid on our already smoldering planet.Created by Molly White. Subscribe to her newsletter for weekly recaps.zachxbt has alleged that \"Lick\" is a man named John Daghita. After reporting Daghita's identity, \"Lick\" appeared to try to scrub his Telegram account, then dusted zachxbt's public crypto wallet from one of the theft addresses.Daghitia is reportedly the son of Dean Daghita, the owner of Command Services & Support (CMDSS). In October 2024, CMDSS landed a contract with the US Marshals to manage seized crypto assets, which is still active. After zachxbt linked the younger Daghita to his father and CMDSS, CMDSS also scrubbed its online presence. Around that time, Lick began trolling zachxbt again, and later sent 0.6767\u00a0ETH (~$1,900) of the stolen funds to zachxbt.CMDSS' website boasts that they are \"a proven provider of mission-critical services to the Department of Defense and Department of Justice\".Text is licensed u"
  },
  {
    "title": "I made my own Git (tonystr.net)",
    "points": 331,
    "submitter": "TonyStr",
    "submit_time": "2026-01-27T10:55:37 1769511337",
    "num_comments": 149,
    "comments_url": "https://news.ycombinator.com/item?id=46778341",
    "comments": [
      "Nice work! On a complete tangent, Git is the only SCM known to me that supports recursive merge strategy [1] (instead of the regular 3-way merge), which essentially always remembers resolved conflicts without you needing to do anything. This is a very underrated feature of Git and somehow people still manage to choose rebase over it. If you ever get to implementing merges, please make sure you have a mechanism for remembering the conflict resolution history :).[1] https://stackoverflow.com/questions/55998614/merge-made-by-r...reply",
      "I remember in a previous job having to enable git rerere, otherwise it wouldn't remember previously resolved conflicts.https://git-scm.com/book/en/v2/Git-Tools-Rererereply",
      "Rerere is dangerous and counterproductive - it tries to give rebase the same functionality that merge has, but since rebase is fundamentally wrong it only stacks the wrongness.reply",
      "Cherry-picks being \"fundamentally wrong\" is certainly an interesting git take.reply",
      "I believe rerere is a local cache, so you'd still have to resolve the conflicts again on another machine. The recursive merge doesn't have this issue \u2014 the conflict resolution inside the merge commits is effectively remembered (although due to how Git operates it actually never even considers it a conflict to be remembered \u2014 just a snapshot of the closest state to the merged branches)reply",
      "Would be nice if centralized git platforms shared rerere cachesreply",
      "The recursive merge is about merging branches that already have merges in them, while rerere is about repeating the same merge several times.reply",
      "On recursive merging, by the author of mercurialhttps://www.mercurial-scm.org/pipermail/mercurial/2012-Janua...reply",
      "New to me was discovering within the last month that git-merge doesn't have a merge strategy of \"null\": don't try to resolve any merge conflicts, because I've already taken care of them; just know that this is a merge between the current branch and the one specified on the command-line, so be a dutiful little tool and just add it to your records.  Don't try to \"help\".  Don't fuck with the index or the worktree.  Just record that this is happening.  That's it.  Nothing else.reply",
      "What does that even mean? There already is reset hard.reply"
    ],
    "link": "https://tonystr.net/blog/git_immitation",
    "first_paragraph": ""
  },
  {
    "title": "TikTok settles just before social media addiction trial to begin (bbc.com)",
    "points": 127,
    "submitter": "ourmandave",
    "submit_time": "2026-01-27T20:38:22 1769546302",
    "num_comments": 132,
    "comments_url": "https://news.ycombinator.com/item?id=46786237",
    "comments": [
      "Fundamentally, I think having a source of \"free dopamine\" on tap is not going to do any good. If I can get distracted from my real world tasks anytime, anywhere, the immediate incentives to work on real things disappear. Effectively, one can get stuck in a local minimum.I don't know how to solve it, but personally I've chosen to block as many feeds/algorithms as I can, so I have to make a conscious decision to search for something (making it just as hard as making the conscious decision that I'm likely putting off). The only feeds I have right now are the FT and Hacker News. Everything else is just a blank home screen with a search bar.reply",
      "> If I can get distracted from my real world tasks anytime, anywhere, the immediate incentives to work on real things disappear. Effectively, one can get stuck in a local minimum.> I don't know how to solve it, ...> but personally I've chosen to block as many feeds/algorithms as I can, ...I think you solved it :) (at least, for yourself)There are many things \"out there\" that are addictive and distracting and thus unhealthy, but we all have to find some way to overcomereply",
      "This is what drugs and alcohol can become if not used in moderation.Once we have the AI holodeck (the full-sensory interactive, possibly multiplayer one), can you only imagine?TikTok is only the punch card phase of this. TikTok may as well be black and white television. Just imagine what we might have in twenty years.Maybe this is why we haven't found alien life. If their biologies have attention mechanisms like ours, maybe they automate highs and turn inward instead of outward. (I do like that better than AGI gray goo taking over galaxies.)reply",
      "Agreed, AI/VR definitely offers nightmarish opportunities.At least drugs/alcohol are self limiting: you have to meet your dealer, go to a store, eventually run out of money...TikTok/Reels/Shorts are free, infinite, and in your pocket on a device you're now forced to use in daily life (bank/2fa/messaging apps).reply",
      "I 100% agree with the premise that TikTok is addictive and even dangerous to consume in large amounts (that's why I don't consume it at all).But I feel the exact same about cheeseburgers. Should I be able to sue McDonalds if I let my kid eat 100 of them in one sitting?Again, I get the danger here, and I don't like TikTok as a whole. I just don't really know where the line is between something that the parent is allowing kids to do (like spending a billion hours on TikTok), versus something they have no control over (like a company badly constructing a car seat, or similar).reply",
      "> But I feel the exact same about cheeseburgers.The problem with analogies to things like cheeseburgers, gambling, drugs, cigarettes, etc., is:1. Availability -- you have to go somewhere to acquire/participate in these things*2. Cost -- you have to have money to spend. That is, it's not something you can consume/participate in for free -- you have to have money to spend.* Gambling is theoretically freely available via gambling apps. But still comes at a cost.With social media, anybody can do it for unlimited amounts of time, and for free. All you need is a phone/laptop/desktop with internet access -- which nearly every person on the planet has.Addiction + Free + Widely available = Destructionreply",
      "To your points I would add the following difference between TikTok on the one hand and cheeseburgers, drugs, cigarettes, etc. on the other.3. Targeting -- even under the (debatable) premise that they are intentionally designed to be addictive, cheeseburgers, drugs and cigarettes do not actively target each addict by optimising their properties to their individual addiction.If I am addicted to smoking, the tobacco industry does indeed try to keep me hooked, among other things by offering me many flavours and alternatives. However, the cigarettes I personally consume are not constantly adjusting their formula, appearance and packet design specifically to satisfy my tastes and desires.reply",
      "Yes. Target the algorithms, not the method of delivery. Hacker news also counts as social media, but here we all are seeing the same feed on the same site with minimal (if not zero) tracking to try and extract info  from the audience.Even a first step of requiring transparency in the algorithms would quickly shatter this stronghold on people's minds.reply",
      "Indeed. In fact, you may notice I explicitly left out gambling from the list of 'non targeted' addictions. The reason for that is that the delivery methods for gambling cover the whole gamut from zero to fully personalised targeting, and I didn't want that to distract from the point.reply",
      "case in point: lots of places have lots of restrictions (either through legislation or just industry norms, usually a combination of both) about advertising for alcohol or tobacco.And those efforts seem effective to me, at least anecdotally. I don't feel particularly bad about those restrictions either.reply"
    ],
    "link": "https://www.bbc.com/news/articles/c24g8v6qr1mo",
    "first_paragraph": "TikTok has reached a settlement to avoid it being involved in a landmark social media addiction trial - a matter of hours before jury selection was due to begin in California.The plaintiff, a 20-year-old woman identified by the initials KGM, alleges the design of platforms' algorithms left her addicted to social media and negatively affected her mental health.\"The parties are pleased to have reached an amicable resolution of this dispute,\" the Social Media Victims Law Center said of the TikTok settlement, adding the terms were confidential.The defendants now include Meta - which owns Instagram and Facebook and YouTube parent Google. Snapchat settled with the plaintiff last week. The named social media companies have said the plaintiff's evidence falls short of proving they are responsible for alleged harms such as depression and eating disorders.The case going to trial marks a distinct shift in how the US legal system treats tech firms, which face mounting claims that their products le"
  },
  {
    "title": "The First Eighteen Lines of the Waste Land (1989) (yalereview.org)",
    "points": 24,
    "submitter": "benbreen",
    "submit_time": "2026-01-23T22:02:52 1769205772",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46738578",
    "comments": [
      "I've been fascinated with The Waste Land ever since junior year of high school, when my creative writing teacher saw a copy of it on my desk and said \"why do you have that, you'll never understand it\". (I mean, fair enough.)This is interesting backstory! My perception of the poem is that it's sort of a fractal of backstory and that everywhere you look you find 2000-word articles on its historical antecedents, from Eliot's life, from the history of Europe, from friends of his lost in the war, &c.There's a whole book on this that's very similar to the article:https://www.amazon.com/Waste-Land-Biography-Poem/dp/03932402...If you're bored, you can also kick back and bounce sections of it off Claude or GPT5 (or both and have them argue with each other).I wonder how directly you can connect Ludwig to the Fisher King.reply",
      "Anyone who liked this article and like (or are curious about) the poem should check out the great Fiona Shaw's reading of it [1].You can find recordings by many fine actor such as John Gielgud, Alec Guinness, and many others, and they tend to be dull, monotonous affairs. Shaw is very different. She's is an incredible actress, and since the 1990s she's been perfecting the poem as a kind of one-woman show where she reads it as the voices of many characters, which is what the poem (as I understand it) is.[1] https://youtu.be/lPB_17rbNXkreply",
      "Have you ever listened to Eliot reading it? Just the worst. \"Apreel is the crewellest month...\"My thing here though is: this is awesome, Shaw's reading, but is it right? I feel like she's trying to make a coherent character reading at times out of passages deliberately written not to have a clear narrator.(I write this in the spirit of every thread needing a certain titration of not knowing what the hell they're talking about, as an invitation to those who do, and that inviting cluelessness is the purpose I serve here.)reply",
      "> I will show you fear in a handful of dustthis gets quoted often as well. Always a fan of TS Eliot. The musical Cats didn't do his book justice, but stillreply",
      "That article is fantastically well written. What a trip.reply",
      "Checkout BOOMTOWN game of you liked wasteland. It's a hidden complex game.reply",
      "Anyone else play wasteland on the apple II? Would have been around '88. Not sure what the link is about.reply",
      "It's about the poem by T.S. Eliot.https://en.wikipedia.org/wiki/The_Waste_Landreply"
    ],
    "link": "https://yalereview.org/article/hecht-eliot-waste-land",
    "first_paragraph": ""
  },
  {
    "title": "Hypercubic (YC F25) Is Hiring a Founding SWE and COBOL Engineer (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2026-01-27T18:50:50 1769539850",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/hypercubic/jobs",
    "first_paragraph": "AI to maintain and modernize COBOL.Hypercubic is an AI-native maintenance and modernization platform for COBOL and mainframes.We help enterprises understand and preserve their mission-critical legacy systems. About 70% of the Fortune 500 companies still rely on them to run their core business applications in banking, insurance, telecom, airlines, retail, and more.These systems, originally built in the 1960s\u201390s, still power trillions in global infrastructure today but have become increasingly opaque as original developers retire or leave the workforce.We're laying the foundation to autonomously maintain and modernize these legacy systems to future-proof the backbone of the global economy.Learn more at hypercubic.ai\u00a9 2026 Y Combinator"
  }
]