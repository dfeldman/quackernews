[
  {
    "title": "Typed languages are better suited for vibecoding (solmaz.io)",
    "points": 38,
    "submitter": "hosolmaz",
    "submit_time": "2025-08-03T23:55:31 1754265331",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44780878",
    "comments": [
      "The closest we got to vibe coding pre-LLMs was using a language with a very good strong type system in a good IDE and hitting Ctrl-Space to autocomplete your way to a working program.I wonder if LLMs can use the type information more like a human with an IDE.eg. It generates \"(blah blah...); foo.\" and at that point it is constrained to only generate tokens corresponding to public members of foo's type.Just like how current gen LLMs can reliably generate JSON that satisfies a schema, the next gen will be guaranteed to natively generate syntactically and type- correct code.reply",
      "As has been said, actual evals are needed here.Anecdotally, the worst and most common failure mode of an agent is when an agent starts spinning its wheels and unproductively trying to fix some error and failing, iterating wildly, eventually landing on a bullshit (if any) \u201csolution\u201d.In my experience, in Typescript, these \u201cspin out\u201d situations are almost always type-related and often involve a lot of really horrible \u201cany\u201d casts.reply",
      "This is why I have very specific ruleset and linting for my LLMs, not allowing any at all and other quality checks.reply",
      "Everything said is true without AI as well, at least for me. I don't hate Python, and I like it for very small scripts, but for large programs the lack of static type makes it much to brittle IMO. Static typing gives the confidence that not every single line needs testing, which reduces friction during the lifecycle of the code.reply",
      "I think this is true -- especially for new code.I did this not knowing any rust: https://github.com/KnowSeams/KnowSeams and rust felt like a very easy to use a scripting language.reply",
      "The logic above can support exactly the opposite conclusion: LLM can do dynamic typed language better since it does not need to solve type errors and save several context tokens.Practically, it was reported that LLM-backed coding agents just worked around type errors by using `any` in a gradually typed language like TypeScript. I also personally observed such usage multiple times.I also tried using LLM agents with stronger languages like Rust. When complex type errors occured, the agents struggled to fix them and eventually just used `todo!()`The experience above can be caused by insufficient training data. But it illustrates the importance of eval instead of ideological speculation.reply",
      "I've been wondering about this for some time. My initial assumption was that would be that LLMs will ultimately be the death of typed languages, because type systems are there to help programmers not make obvious mistakes, and near-perfect LLMs would almost never make obvious mistakes. So in a world of near-perfect LLMs, a type system is just adding pointless overhead.In this current world of quite imperfect LLMs, I agree with the OP, though. I also wonder whether, even if LLMs improve, we will be able to use type systems not exactly for their original purpose but more as a way of establishing that the generated code is really doing what we want it to, something similar to formal verification.reply",
      "Even near-perfect LLMs would benefit from the compiler optimizations that types allow.However perfect LLMs would just replace compilers and programming languages above assembly completely.reply",
      "This claim needs to be backed up by evals. I could just as well argue the opposite, that LLMs are best at coding Python because there are two orders of magnitude more Python in their training sets than C++ or Rust.In any case, you can easily get most of the benefits of typed languages by adding a rule that requires the LLM to always output Python code with type annotations and validate its output by running ruff and ty.reply",
      "Writing rust and the LLM almost never gets function signatures and returns types wrong.That just leaves the business logic to sort out. I can only imagine that IDEs will eventually pair directly with the compiler for instant feedback to fix generations.But rust also has traits, lifetimes, async, and other type flavors that multiples complexity and causes issues. It also an in progress language\u2026 im about to add a \u201cdon\u2019t use once cell.. it\u2019s part of std now \u201c to my system prompt. So it\u2019s not all sunshine, and I\u2019m deeply curious how a pure vibe coded rust app would turn out.reply"
    ],
    "link": "https://solmaz.io/typed-languages-are-better-suited-for-vibecoding",
    "first_paragraph": "\n2025-08-03\n      My >10 year old programming habits have changed since Claude Code launched. Python is less likely to be my go-to language for new projects anymore. I am managing projects in languages I am not fluent in\u2014TypeScript, Rust and Go\u2014and seem to be doing pretty well.It seems that typed, compiled, etc. languages are better suited for vibecoding, because of the safety guarantees. This is unsurprising in hindsight, but it was counterintuitive because by default I \u201cvibed\u201d projects into existence in Python since forever.Paradoxically, after a certain size of project, I can move faster and safer with e.g. Claude Code + Rust, compared to Claude Code + Python, despite the low-levelness of the code1. This is possible purely because of AI tools.For example, I refactored large chunks of our TypeScript frontend code at TextCortex. Claude Code runs tsc after finishing each task and ensures that the code compiles before committing. This let me move much faster compared to how I would have"
  },
  {
    "title": "Modern Node.js Patterns (kashw1n.com)",
    "points": 359,
    "submitter": "eustoria",
    "submit_time": "2025-08-03T19:16:18 1754248578",
    "num_comments": 148,
    "comments_url": "https://news.ycombinator.com/item?id=44778936",
    "comments": [
      "Whoa, I didn't know about this:  # Run with restricted file system access\n  node --experimental-permission \\\n    --allow-fs-read=./data --allow-fs-write=./logs app.js\n  \n  # Network restrictions\n  node --experimental-permission \\\n    --allow-net=api.example.com app.js\n\nLooks like they were inspired by Deno. That's an excellent feature. https://docs.deno.com/runtime/fundamentals/security/#permiss...reply",
      "The killer upgrade here isn\u2019t ESM. It\u2019s Node baking fetch + AbortController into core. Dropping axios/node-fetch trimmed my Lambda bundle and shaved about 100 ms off cold-start latency. If you\u2019re still npm i axios out of habit, 2025 Node is your cue to drop the training wheels.reply",
      "16 years after launch, the JS runtime centered around network requests now supports network requests out of the box.reply",
      "It always did: https://nodejs.org/docs/latest-v0.10.x/api/http.html#http_ht...reply",
      "Obviously it supported network requests, the fetch api didn't even exist back then, and XMLHttpRequest which was the standard at the time is insane.reply",
      "Tangential, but thought I'd share since validation and API calls go hand-in-hand: I'm personally a fan of using `ts-rest` for the entire stack since it's the leanest of all the compile + runtime zod/json schema-based validation sets of libraries out there. It lets you plug in whatever HTTP client you want (personally, I use bun, or fastify in a node env). The added overhead is totally worth it (for me, anyway) for shifting basically all type safety correctness to compile time.Curious what other folks think and if there are any other options? I feel like I've searched pretty exhaustively, and it's the only one I found that was both lightweight and had robust enough type safety.reply",
      "Just last week I was about to integrate `ts-rest` into a project for the same reasons you mentioned above... before I realized they don't have express v5 support yet: https://github.com/ts-rest/ts-rest/issues/715I think `ts-rest` is a great library, but the lack of maintenance didn't make me feel confident to invest, even if I wasn't using express. Have you ever considered building your own in-house solution? I wouldn't necessarily recommend this if you already have `ts-rest` setup and are happy with it, but rebuilding custom versions of 3rd party dependencies actually feels more feasible nowadays thanks to LLMs. I ended up building a stripped down version of `ts-rest` and am quite happy with it. Having full control/understanding of the internals feels very good and it surprisingly only took a few days. Claude helped immensely and filled a looot of knowledge gaps, namely with complicated Typescript types. I would also watch out for treeshaking and accidental client zod imports if you decide to go down this route.I'm still a bit in shock that I was even able to do this, but yeah building something in-house is definitely a viable option in 2025.reply",
      "Type safety for API calls is huge. I haven't used ts-rest but the compile-time validation approach sounds solid. Way better than runtime surprises. How's the experience in practice? Do you find the schema definition overhead worth it or does it feel heavy for simpler endpoints?reply",
      "I always try to throw schema validation of some kind in API calls for any codebase I really need to be reliable.For prototypes I'll sometimes reach for tRPC. I don't like the level of magic it adds for a production app, but it is really quick to prototype with and we all just use RPC calls anyway.For procudtion I'm most comfortable with zod, but there are quite a few good options. I'll have a fetchApi or similar wrapper call that takes in the schema + fetch() params and validates the response.reply",
      "How do you supply the schema on the other side?I found that keeping the frontend & backend in sync was a challenge so I wrote a script that reads the schemas from the backend and generated an API file in the frontend.reply"
    ],
    "link": "https://kashw1n.com/blog/nodejs-2025/",
    "first_paragraph": "Node.js has undergone a remarkable transformation since its early days. If you\u2019ve been writing Node.js for several years, you\u2019ve likely witnessed this evolution firsthand\u2014from the callback-heavy, CommonJS-dominated landscape to today\u2019s clean, standards-based development experience.The changes aren\u2019t just cosmetic; they represent a fundamental shift in how we approach server-side JavaScript development. Modern Node.js embraces web standards, reduces external dependencies, and provides a more intuitive developer experience. Let\u2019s explore these transformations and understand why they matter for your applications in 2025.The module system is perhaps where you\u2019ll notice the biggest difference. CommonJS served us well, but ES Modules (ESM) have become the clear winner, offering better tooling support and alignment with web standards.Let\u2019s look at how we used to structure modules. This approach required explicit exports and synchronous imports:This worked fine, but it had limitations\u2014no stati"
  },
  {
    "title": "Writing a good design document (grantslatton.com)",
    "points": 154,
    "submitter": "kiyanwang",
    "submit_time": "2025-08-03T20:21:54 1754252514",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=44779428",
    "comments": [
      "Two quotes from the article stand out.  First, from the X screenshot:  \"something about the process of writing makes your ideas 10x better\". Second from near the beginning:  \"The most important person to convince is the author.\"Design documents are so essential that even after mumble years in the industry, I am amazed when people, including putative \"Product Managers\" push back on the idea.  As Leslie Lamport noted, \"Writing is nature's way of telling us how sloppy our thinking is.\"For those wanting to learn how to improve the quality of their technical writing, see Write Like an Amazonian:  https://medium.com/@apappascs/write-like-an-amazonian-14-tip...reply",
      "> Replace adjectives with dataI think this idea got so pervasive all throughout tech that all the resumes that i now get are filled with so many numbers that i don't even know what to make of them.reply",
      "If I get one more resume from a \u201cseasoned professional\u201d who has \u201cdecreased X by N%\u201d I am going to close hiring, quit tech, and go be a hermit.N.B. I received such a resume while typing this comment and am absconding to Outer Mongolia as I typereply",
      "What do you want to see, then? Colorful prose?I and a few others really did save my company 10 million dollars one year. It was in EC2 spend for a hadoop cluster. I can tell you how we did it and who did what. Yes it was actual dollars we would have otherwise paid to AWS, it is not funny money calculated by looking at sticker rates and ignoring our discounts (which were large).I'm proud of this and it was one of my largest impacts at the company. What would you have me put on my resume? \"Decreased EC2 spend by a whole bunch!\"? \"Reduced EC2 spend\"?I don't get where this hatred of numbers on resumes is coming from. Is much of it probably bullshit? Yeah, just like most resumes. But I expect you to sort through it the same way you do the rest of the resume. Ask them about it. I can tell you the whole story of mine. I'd expect others can do the same. And if they stammer and crack, now you know how exaggerated it was.reply",
      "99% of bullet points containing numbers in a resume are made up, hamfisted BS, the other 1% cannot be attributed to a single individual so putting them in a personal resume is silly.reply",
      "I agree with the sentiment, but not the conclusion.  Sure, numbers can be abused, just like anything else, but they provided specificity which you can then interrogate and call bullshit on.  I won't necessarily fault someone for leaving off the numbers and just speaking qualitatively to the large scale system rewrite they did, but it's harder to evaluate whether such an effort was indeed warranted or was just a lateral move post-hoc rationalized by an engineer who didn't understand the original system and needed to rewrite it just to achieve that understanding.  Again, if someone is satisfying the business with such efforts, more power to them.  As a hiring manager, I don't want to get into a subjective evaluation of the relative engineering value of specific work at an external company that I have no first-hand context on, but I do want to know that candidates understand the highest level goals they are hired to contribute to.  Metrics, however flawed, give a good entry point into such conversations.reply",
      "I don\u2019t blame people for doing so. That\u2019s what they have been told by recruiters to do to increase their chance of their resume not being thrown into the trash or be invisible. If there is someone to blame for this, it\u2019s the recruiting industry.reply",
      "It\u2019s so dumb. There is no way to verify the numbers, and yet, this stupidity weaseled its way into the LinkedIn cinematic universe of corporate bullshit. The same point but without the \u201cX by Y%\u201d hits the same for me\u2014 besides  I know what questions to ask to judge if you are actually capable of moving the needle, which is all I care about as a conductor of interviews.reply",
      "the problem is CVs are screened by non-tech HR/recruiters, who lack the capacity to screen candidates. Because it is much easier to apply online with one click, each position is spammed with millions of CVs.in response, for HR it is much easier to filter out CV if it lacks style, not substance. Therefore they look at bullet points like \"Done X by Y%\".The proper way should be to limit the intake funnel: accept only a few applications per job, so that they can be screened properly by HRs by calling them, and talking to them and properly screening (old school style), instead of tossing their resume to the bin after 15 sec quick reviewreply",
      ">Amazon meetings start with the presenter passing out copies... of a prose document... The meeting starts with everyone sitting in silence, reading the document, and adding notes and questions in the margins with red pen.I've never worked at Amazon, but I've heard this a lot, and it always strikes me as an odd practice. Odder still is that it apparently works and everyone I hear talk about it seems to love it.You're squandering precious meeting time by having everyone sit and read a document together. They could easily do the same thing ahead of the meeting, and you'd have much shorter meetings.And doing it synchronously means everyone either sits idle until the slowest reader is ready or not everyone gets to finish in time. And \"slowest reader\" isn't even just about reading speed. Presumably, some people can understand the document more quickly because they have more context.In design reviews at Google, it was obvious that the majority of attendees came unprepared and were reading the docs for the first time while their teammates were discussing the doc. I suspect that the reason was that Google just didn't have a strong docs culture, and leads/managers quietly tolerated people coming unprepared (and sometimes, they themselves were unprepared).I've never seen it done in practice, but I don't think it would be hard to have the best of both worlds where people review docs ahead of the review meeting, but there are strong cultural norms around reading docs ahead of time so the meeting is just for discussion, not just for reading or pretending that you've read.reply"
    ],
    "link": "https://grantslatton.com/how-to-design-document",
    "first_paragraph": ""
  },
  {
    "title": "Persona vectors: Monitoring and controlling character traits in language models (anthropic.com)",
    "points": 282,
    "submitter": "itchyjunk",
    "submit_time": "2025-08-03T16:38:06 1754239086",
    "num_comments": 94,
    "comments_url": "https://news.ycombinator.com/item?id=44777760",
    "comments": [
      "> Other personality changes are subtler but still unsettling, like when models start sucking up to users or making up facts.My understanding is that the former (sucking up) is a personality trait, substantially influenced by the desire to facilitate engagement. The latter (making up facts), I do not think is correct to ascribe to a personality trait (like compulsive liar); instead, it is because the fitness function of LLMs drive them to produce some answer and they do not know what they're talking about, but produce strings of text based on statistics.reply",
      "Furthermore, it is very rare to have the following kind of text present in the training data: \"What is the answer to X?\" -  \"I don't know, I am not sure.\"In this situation very often there won't be _any_ answer, plenty of difficult questions go unanswered on the internet. Yet the model probably does not interpret this scenario as suchreply",
      "I just asked ChatGPT 4o if it knew my mother\u2019s maiden name and it said \u201cI don\u2019t know\u201d. Maybe they\u2019ve got that hard coded in, but I guess it\u2019s good to see it willing to say that? Similar results with \u201cwhat did I eat for dinner last Tuesday\u201d although it did ask me if I wanted it to check all our past conversations for that info.reply",
      "The system prompts are directed to \"not know\" anything about the user even if they do or they have inferred it. It reduces the spooky factor.reply",
      "i don't think this is correct - such training data is usually made at SFT level after unsupervised learning on all available data in the web. the SFT level dataset is manually curated meaning there would be conscious effort to create more training samples of the form to say \"i'm not sure\". same with RLHF.reply",
      "You mean I don't think this is automatically correct. Otherwise it very likely is correct. Either way, you're guessing the manual curation is done in a way that is favorable to include I don't know answers. Which it most likely doesn't.reply",
      "its completely in the incentive to include such examples in RLHF. or you have come up with a way to increase performance that the very employees haven't. why do you think they didn't try it?reply",
      "How do you know which question should be answered with 'I dont know?'. There are obvious questions which have no answer, but if only those are in the dataset, the model will answer I dont know only for unreasonable questions.To train this effectively you would need a dataset of questions which you know the model doesn't know. But if you have that... why not answer the question and put in the dataset so that the model will know ?That's a bit imprecise, but I think it capture the idea of why 'I don't know' answers are harder to train.reply",
      "but you just described how to fix the \"i don't know\" problems to \"i know and the answer is <>\". but not that \"i don't know\" is inherently hard to solve for some reason.reply",
      "It's difficult to fix because the incentive is to make sure it has the answer, not to give it lots of questions to which there are known answers but have it answer \"I don't know\" (if you did that, you'd bias the model to be unable to answer those specific questions). Ergo, in inference, on questions not in the dataset, it's more inclined to make up an answer because it has very few \"I don't know\" samples in general.reply"
    ],
    "link": "https://www.anthropic.com/research/persona-vectors",
    "first_paragraph": ""
  },
  {
    "title": "How to grow almost anything (howtogrowalmostanything.notion.site)",
    "points": 42,
    "submitter": "car",
    "submit_time": "2025-08-03T22:55:05 1754261705",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=44780540",
    "comments": [
      "Off topic, but Notion is a perfect example of how badly you can abuse web standards. This webpage, which is a document with some markup and links (the very thing the web was made for) takes ~600MB RAM, about 10 seconds load, and lags terribly. Just unusable.reply",
      "Wow it is horrible. I clicked on the link to load it, tabbed back to this comment page and read this comment, went back to the page to see how it was doing and got 99% blank page, scrolled for a solid 10 seconds and just as I was about to come back and say the page is broken for me it popped up a proper scroll bar for a window about 1/3 of my browser size. Scrolled through about 5-6 pages worth of that which still looked broken, then the window finally resized and images started popping in, but it still took another 7 seconds or so for those to load an actual image instead of just a placeholder icon while everything shifted around like mad.reply",
      "Notion has really great ideas though, it's just so poorly implemented that it really hurts my desire to use it for anything unless forced to.reply",
      "Notion sites aren\u2019t my favorite and this website has some annoying quirks (like scrolling to the top after fully loading)But if this is what it takes for someone to generously share so much information with us for free then I really don\u2019t care if I have to wait a couple extra seconds for a page load or if a tab takes up 600MB of RAM. I know this thinking makes the web purists angry, but the majority of people who visit these sites to learn aren\u2019t going to be impeded or even bothered. Even on my older iPhone on non-5G cellular it loads in a couple of seconds.reply",
      "Site doesn't even work on Pale Moon, and judging from your comment that's probably a good thing.reply",
      "Also, my screen is 20 inches wide, yet the website uses only 25% of that width.reply",
      "hate Notion but also it took 2s to load on iOS safarireply",
      "What if you used the app?reply",
      "A spiritual successor to:\nhttps://fab.cba.mit.edu/classes/MAS.863/reply",
      "Oh, I thought there\u2019d be some tips for my rhubarb.reply"
    ],
    "link": "https://howtogrowalmostanything.notion.site/htgaa25",
    "first_paragraph": ""
  },
  {
    "title": "So you want to parse a PDF? (eliot-jones.com)",
    "points": 67,
    "submitter": "UglyToad",
    "submit_time": "2025-08-03T22:24:29 1754259869",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=44780353",
    "comments": [
      "Disclaimer - Founder of Tensorlake, we built a Document Parsing API for developers.This is exactly the reason why Computer Vision approaches for parsing PDFs works so well in the real world. Relying on metadata in files just doesn't scale across different source of PDFs.We convert PDFs to images, run a layout understanding model on them first, and then apply specialized models like text recognition and table recognition models on them, stitch them back together to get acceptable results for domains where accuracy is table stakes.reply",
      "While we have a PDF internals expert here, I'm itching to ask: Why is mupdf-gl so much faster than everything else? (on vanilla desktop linux)Its search speed on big pdfs is dramatically faster than everything else I've tried and I've often wondered why the others can't be as fast as mupdf-gl.Thanks for any insights!reply",
      "> This is exactly the reason why Computer Vision approaches for parsing PDFs works so well in the real world.One of the biggest benefits of PDFs though is that they can contain invisible data. E.g. the spec allows me to embed cryptographic proof that I've worked at the companies I claim to have worked at within my resume. But a vision-based approach obviously isn't going to be able to capture that.reply",
      "Cryptographic proof of job experience? Please explain more. Sounds interesting.reply",
      "If someone told me there was cryptographic proof of job experience in their PDF, I would probably just believe them because it\u2019d be a weird thing to lie about.reply",
      "Encrypted (and hidden) embedded information, e. g. documents, signatures, certificates, watermarks, and the like. To (legally-binding) standards, e. g. for notary, et cetera.reply",
      "This has close to zero relevance to the OP.reply",
      "> \"This is exactly the reason why Computer Vision approaches for parsing PDFs works so well in the real world.\"Well, to be fair, in many cases there's no way around it anyway since the documents in question are only scanned images. And the hardest problems I've seen there are narrative typography artbooks, department store catalogs with complex text and photo blending, as well as old city maps.reply",
      "So you parse PDFs, but also OCR images, to somehow get better results?Do you know you could just use the parsing engine that renders the PDF to get the output? I mean, why raster it, OCR it, and then use AI? Sounds creating a problem to use AI to solve it.reply",
      "Thanks for the pointer!reply"
    ],
    "link": "https://eliot-jones.com/2025/8/pdf-parsing-xref",
    "first_paragraph": "Suppose you have an appetite for tilting at windmills. Let's say you love pain. Well then why not write a PDF parser today?Conceptually parsing a PDF is fairly simple:A PDF object wraps some valid PDF content, numbers, strings, dictionaries, etc., in an object and generation number. The content is surrounded by the obj/endobj markers, for example a simple number may have its own PDF object:This declares that object 16 with generation 0 contains the number 620.A PDF file is effectively a graph of objects that may reference each other. Objects reference other objects by use of indirect references. These have the format \"16 0 R\" which indicates that the content\nshould be found in object 16 (generation number 0). In this case that would point to the object 16 containing the number 620. It is up to producer applications to split file content into objects as they wish, though the specification requires that certain object types be indirect.To avoid the need to scan the entire file, PDFs decl"
  },
  {
    "title": "If you're remote, ramble (stephango.com)",
    "points": 677,
    "submitter": "lawgimenez",
    "submit_time": "2025-08-03T10:32:51 1754217171",
    "num_comments": 371,
    "comments_url": "https://news.ycombinator.com/item?id=44775563",
    "comments": [
      "Let me share a personal story. Back in 2014 when I was working at Cloudflare on DDoS mitigation I collaborated a lot with a collage - James (Jog). I asked him loads of questions, from \"how to login to a server\", via \"what is anycast\" to \"tell me how you mitigated this one, give me precise instructions you've run\".I quickly realised that these conversations had value outside the two of us - pretty much everyone else onboarded had similar questions. Some subjects were about pure onboarding friction, some were about workflows most folks didn't know existed, some were about theoretical concepts.So I moved the questions to a public (within company) channel, and called it \"Marek's Bitching\" - because this is what it was. Pretty much me complaining and moaning and asking annoying questions. I invited more London folks (Zygis), and before I knew half of the company joined it.It had tremendous value. It captured all the things that didn't have real place in the other places in the company, from technical novelties, through discussions that were escaping structure - we suspected intel firmware bugs, but that was outside of any specific team at the time.Then the channel was renamed to something more palatable - \"Marek's technical corner\" and it had a clear place in the technical company culture for more than a decade.So yes, it's important to have a place to ramble, and it's important to have \"your own channel\" where folks have less friction and stigma to ask stupid questions and complain. Personal channels might be overkill, but a per-team or per-location \"rambling/bitching\" channel is a good idea.reply",
      "> I collaborated a lot with a collage - James (Jog). I asked him loads of questions, from \"how to login to a server\", via \"what is anycast\" to \"tell me how you mitigated this one, give me precise instructions you've run\".Hi, that's me! There were definitely a lot of fun conversations.I liked that a culture of internal blogs became a thing too. It was good to see people brain dumping their experiments and findings. I think people learnt a lot from following all the internal blogs.reply",
      "Always funny to see these sort of missed connections on HN.> internal blogsIn my personal experience the problem is the total lack of writing culture at non-premiere companies.Put differently: unless you\u2019re working on a great team at a great organization roughly 90% of people cannot be expected to write/read well as a component of technical collaboration. Any thoughts on that? I may just be too cynicalreply",
      "This is rather likely to get worse.Reading comprehension is declining. Emphasis on individual \"impact\" and deadline pressure, common at both premiere companies and \"non-premiere\" companies mindlessly copying the former, both consume time that could have been spent thinking, writing, and engaging with optional things others wrote. People who avoid documents because they might get outdated create systems with no documentation at all. And now, LLMs promise a world where documents don't need to exist a priori -- a model will look at your code and generate a plausible description of possible intent and system architecture on demand, if someone implausibly happens to ask for documentation. If nobody happens to ask, that's even more time saved - a win-win!Leadership can either support or inhibit the culture of writing and reading. However, modern managers are not immune from the rising pressure. Their response is to shift from thinking and deliberate information processing to rapid-fire pattern matching. Some of them don't see documents as \"real output\" to begin with, and operate solely in meetings without any written record or documentation whatsoever. Of coures their staff will pick up on the pattern. I have a vivid memory of engaging with a full team working on a substantial project in the absence of their senior leader, getting the tactical picture and then asking the team about the project's goal. You could have heard a pin drop. None of the people working on the project could speak about anything but their immediate assigned tasks.reply",
      "I understand the point you were making, but from a manager\u2019s perspective this format is something we\u2019ve tried to avoid. Having a place to have people ask questions is great and encouraged, but doing anything that starts gravitating the knowledge toward a person instead of a topic creates problems for discoverability, searchability, and risks creating the impression (for new employees) that certain specific people are at the center of projects they just happen to know a lot about.So while the Q&A format is good to have available, I\u2019d discourage creating separate channels around a person. I would encourage everyone to just go to the appropriate topic channel and discuss it there.I do the same thing when someone starts asking specific technical questions in #random or #general: Redirect to the project specific channel. That\u2019s the place where all of the relevant people will be relevant and watching and it\u2019s the first place they\u2019ll search in the future.reply",
      "This is a great comment. Thanks.In my case - indeed the name is a historical baggage, I'm not arguing for or against it.Indeed we had regularly situations that we had to pull in experts from other rooms, to discuss specific topics (like TCP), so we should have forwarded the conversation at the start.But I don't think this should be categorical. There is value in non-experts responding faster (the channel had good reach) by your non-expert colleagues than waiting longer for the experts on the other continent to wake up.Maybe there should be an option to... move conversation threads across channels?I think there is place for both - unstructured conversations, and structured ones. What I don't like about managerial approach, is that many managers want to shape, constrain, control communication. This is not how I work. I value personal connections, I value personal expertise and curiosity. I dislike non-human touch.\"You should ask in the channel XYZ\" is a dry and discouraging answer.\"Hey, Mat worked on it a while ago, let's summon him here, but he's in east coast so he's not at work yet, give him 2h\" is a way better one.I know that concentrating knowledge / ownership at a person is not always good, but perhaps a better way to manage this is to... hire someone else who is competent or make other people more vocal.And yes, I don't like managers trying to shape communication patterns.reply",
      "OTOH I hugely appreciate my manager who makes a conscious effort to direct people to ask questions in public channels and not just ping \u201chey\u201d in my DMs all day. And it saves them time too, because my response is going to be \u201cyou should ask in channel xyz\u201d. (And yes, in that public channel I am likely to be the one who answers it, but not always, and it\u2019s now visible for other people who also need to know - the exact problem you were so proud of solving!)reply",
      "> I know that concentrating knowledge / ownership at a person is not always good, but perhaps a better way to manage this is to... hire someone else who is competent or make other people more vocal.> And yes, I don't like managers trying to shape communication patterns.I'm a manager who shaped communication patterns (e.g. default conversations to a public channel) because we're solving different problems. By moving conversations to a public channel away from an individual, we're improving redundancy and reducing single points of failure. Our primary responsibility, which understandably garners discontent, is to prioritize the system over the needs of individuals, within reason.There are many issues resulting from defaulting conversations in private channels or DMs that you've probably seen first-hand.reply",
      "I've found the best way to kill a conversation is to point out the appropriate place the conversation should have started.reply",
      "This is the difference between a good idea and the implementation.People just act differently in \"official\" topic channels.It's like when you buy that super secure door lock and the lowest bid handyman bends it while installing because it's such a pain to align correctly and now it's just as vulnerable as any other lock.reply"
    ],
    "link": "https://stephango.com/ramblings",
    "first_paragraph": "A tip for remote teams of 2-10 people. Create a personal \u201cramblings\u201d channel for each teammate in your team\u2019s chat app of choice.Ramblings channels let everyone share what\u2019s on their mind without cluttering group channels. Think of them as personal journals or microblogs inside your team\u2019s chat app, a lightweight way to add ambient social cohesion.People typically post short updates 1-3 times per week. Common topics include:Each ramblings channel should be named after the team member, and only that person can post top-level messages. Others can reply in threads, but not start new ones.All the ramblings channels should be in a Ramblings section at the bottom of the channel list. They should be muted by default, with no expectation that anyone else will read them.We started experimenting with ramblings at Obsidian two years ago, and they\u2019ve been surprisingly sticky. We have no scheduled meetings, so ramblings are our equivalent of water cooler talk. We want as much deep focus time as pos"
  },
  {
    "title": "Names are not type safety (2020) (lexi-lambda.github.io)",
    "points": 24,
    "submitter": "azhenley",
    "submit_time": "2025-08-03T22:55:28 1754261728",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44780544",
    "comments": [
      "My peers and I work on a language centered around \"constructive data modeling\" (first time I hear it called that). We implement integers, and indeed, things like non empty lists using algebraic data types, for example. You can both have a theory of values that doesn't rely on trapdoors like \"int32\" or \"string\", as well as encode invariants, as this article covers.As I understand it, the primary purpose of newtypes is actually just to work around typeclass issues like in the examples mentioned at the end of the article. They are specifically designed to be zero cost, because you want to not pay when you work around the type class instance already being taken for the type you want to make an instance for. When you make an abstract data type by not exporting the data constructors, that can be done with or without newtype.reply",
      "The alternative to newtypes is probably to go the same route as OCaml and have people explicitly bring their own instances for typeclasses, instead of allowing each type only one instance?I think OCaml calls these things modules or so.  But the concepts are similar.  For most cases, when there's one obvious instance that you want, having Haskell pick the instance is less of a hassle.reply",
      "In Rust I find myself gaining a good bit of type safety without losing ergonomics by wrapping types in a newtype then implementing Deref for them. At first it might seem like a waste, but it prevents accidentally passing the wrong type of thing to a function (e.g. a user UUID as a post UUID).reply",
      "IME this is exactly backwards: type safety is mostly about names, everything else is a nice-to-have. Yes, you can bypass your name checks if you want to, but you can bypass any type check if you want to. Most relevant type relationships in most programming are business relationships that would be prohibitively expensive to express in a full formalism if that was even possible. But putting names on them is cheap, easy, and effective. The biggest win from typed languages comes from using these basic techniques.reply",
      "What if I want a type called MinusIntMaxToPlusIntMax?In other words the full range of Int?Is newtype still bad?In other words how much of this criticism has to do with newtype not providing sub-ranging for enumerable types?It seems that it could be extended to do that.reply"
    ],
    "link": "https://lexi-lambda.github.io/blog/2020/11/01/names-are-not-type-safety/",
    "first_paragraph": "Haskell programmers spend a lot of time talking about type safety. The Haskell school of program construction advocates \u201ccapturing invariants in the type system\u201d and \u201cmaking illegal states unrepresentable,\u201d both of which sound like compelling goals, but are rather vague on the techniques used to achieve them. Almost exactly one year ago, I published Parse, Don\u2019t Validate as an initial stab towards bridging that gap.The ensuing discussions were largely productive and right-minded, but one particular source of confusion quickly became clear: Haskell\u2019s newtype construct. The idea is simple enough\u2014the newtype keyword declares a wrapper type, nominally distinct from but representationally equivalent to the type it wraps\u2014and on the surface this sounds like a simple and straightforward path to type safety. For example, one might consider using a newtype declaration to define a type for an email address:This technique can provide some value, and when coupled with a smart constructor and an enc"
  },
  {
    "title": "Life, Work, Death and the Peasant: Family Formation (acoup.blog)",
    "points": 62,
    "submitter": "Khaine",
    "submit_time": "2025-08-02T07:39:42 1754120382",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://acoup.blog/2025/08/01/collections-life-work-death-and-the-peasant-part-iiia-family-formation/",
    "first_paragraph": "A Collection of Unmitigated PedantryA look at history and popular cultureThis is the first part of the third part of our series (I, II) discussing the patterns of life of the pre-modern peasants who made up the great majority of all humans who lived in our agrarian past and indeed a majority of all humans who have ever lived.1  Last week, we looked at death, examining the brutal mortality regime of pre-modern societies, typified by extremely high (c. 50%) infant and child mortality, very high maternal mortality and often high male military mortality, which kept life expectancy at birth as low as the mid twenties, while life expectancy at adulthood was better \u2013 around 50 \u2013 but still very low by modern standards.This week and next, we\u2019ll start working out some of the consequences of this mortality regime, looking at family formation which in these pre-modern agrarian societies means marriage.  While the intense variability of mortality meant that peasant households came in a variety of s"
  },
  {
    "title": "A study of lights at night suggests dictators lie about economic growth (2022) (economist.com)",
    "points": 78,
    "submitter": "mooreds",
    "submit_time": "2025-08-03T22:50:53 1754261453",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44780515",
    "comments": [
      "Given recent news* does that mean light at night could be used to measure US economic growth this year?https://www.cbsnews.com/news/trump-fires-commissioner-of-lab...reply",
      "You can rely on a better source : https://institute.bankofamerica.com/economic-insights/consum...reply",
      "Light at night would overstate success for the incumbent US population actually. Since (contrary to popular belief) we're significantly less nationalistic than these other countries and have a much larger and more successful migrant population.reply",
      "Did it with https://sites.google.com/site/jiaxiongyao16/nighttime-lights...USA (2013-2023 CAGR: 2.3%)\n2014: 6.2%\n2015: -5.3%\n2016: -1.8%\n2017: 15.2%\n2018: -4.9%\n2019: 4.5%\n2020: -5.4%\n2021: 6.7%\n2022: 14.5%\n2023: -3.6%China (2013-2023 CAGR 7.9%)\n2014: -1.7%\n2015: -1.2%\n2016: -5.1%\n2017: 53.3%\n2018: -1.0%\n2019: 7.5%\n2020: 6.5%\n2021: 11.4%\n2022: 4.2%\n2023: 10.8%reply",
      "Individual yearly number are unlikely to be useful. Likely you can only predict long term trends with the help of fits.reply",
      "Wow, 2017 was a good yearreply",
      "https://archive.md/v5rGjreply",
      "Yes the \u201cgood hitler years\u201d were a lie and so are all the \u201ceffective dictators\u201dAnd the fact that no one just assumes that is weird. In general, let\u2019s imagine you had a politician who took power of a country that was recovering, and then by the time they left power their country was a literal pile of rubble and they shot themselves and their family in the head in order to avoid the consequences of their own actions\u2026 you\u2019d assume that any positive story about them is probably bullshit. But for some reason the moment it\u2019s Hitler everyone\u2019s got an excuse.And if someone accidentally killed 6 million of their own citizens we\u2019d naturally all recognize them as one of the worst politicians in human history, but for some reason when they kill 6 million of their own citizens on purpose it\u2019s not a raucous failure that deserves endless ridicule.reply",
      "Not that Hitler is an example of one but there is actually a long history of good dictators. Remember the original dictatorships in Rome were time boxed (among other things) to overcome crises. England had a similar idea in the form of its protectorates. I don't like everything Cromwell did for example but he absolutely was a dictator in all but name.reply",
      "https://archive.md/8asa5I spent a lot of time living in China. Nobody believes the government figures. But I'm also skeptical that using artificial light as a proxy for economic growth is rational, particularly when you realise that Chinese people overwhelmingly live in vertical high density buildings and the amount of light used when moving from last-gen 'heavy industry' to next-gen 'value add'/'light industry'/'design work'/whatever is going to be reduced.Therefore although I am a big fan of the Economist and like the idea, I think the premise of this particular study may be somewhat flawed.Where the article states \"the mismatch between satellite and GDP data did not appear in dictatorships until they were too rich to receive some types of aid\" I think what they may be discovering is \"when people move in to dense modern housing and shift to white collar work the model breaks down\". There are other factors too: more modern lighting is more efficient, people increasingly socialize through phones, and outdoor living spaces are reduced in relatively inhospitable climates, somewhat limiting light pollution.Thinking back to first principles, the majority of outdoor light pollution is probably from freeways and city centers, and if you proxy that with economic growth it's probably significant as a pre-emption at a certain phase of transition from agricultural/low-development-level economy through highly developed economy, but becomes irrelevant rapidly once those development prerequisites have been achieved.It doesn't help that this guy is trying to sell a book.reply"
    ],
    "link": "https://www.economist.com/graphic-detail/2022/09/29/a-study-of-lights-at-night-suggests-dictators-lie-about-economic-growth",
    "first_paragraph": ""
  },
  {
    "title": "Welcome to url.town, population 465 (url.town)",
    "points": 100,
    "submitter": "plaguna",
    "submit_time": "2025-08-02T08:24:29 1754123069",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44765730",
    "comments": [
      "With the rise of these retro-looking websites, I feel it's possible again to start using a browser from the '90s. Someone should make a static-site social media platform for full compatibility.reply",
      "Not so much. While a lot of these websites use classic approaches (handcrafted HTML/CSS, server-side includes, etc.) and aesthetics, the actual versions of those technologies used are often rather modern. For example, TFA looks like a page I'd have browsed in IE5 as a kid, but if you look at the markup, it's using HTML5 tags and Flexbox (which became a W3C WR in 2017), while a period site would have used an HTML table to get the same effect. Of course, you wouldn't want to do it that way nowadays, because it wouldn't be responsive or mobile-friendly.(I don't think this detracts from such sites, to be clear; they're adopting new technologies where they provide practical benefits to the reader because many indieweb proponents are pushing it as a progressive, rather than reactionary, praxis.)reply",
      "> For example, TFA looks like a page I'd have browsed in IE5 as a kid, but if you look at the markup, it's using HTML5 tags and Flexbox (which became a W3C WR in 2017), while a period site would have used an HTML table to get the same effect.Are they going out of their way to recreate an aesthetic that was originally the easiest thing to create given the language specs of the past, or is there something about this look and feel that is so fundamental to the idea of making websites that basically anything that looks like any era or variety of HTML will converge on it?reply",
      "I loaded up Windows 98SE SP2 in a VM and tried to use it to browse the modern web but it was basically impossible since it only supported HTTP/1.1 websites. I was only able to find maybe 3-4 websites that still supported it and load.reply",
      "Remember url.city? https://web.archive.org/web/20141122194515/https://dir.yahoo...reply",
      "Logins are built on https://home.omg.lol/ which is an amazing looking community!reply",
      "Kind of like the indieseek.xyz directory. Love to see it.reply",
      "Neat - I wish it showed how many entries there are for each category. I was disappointed to see a Parenting category, with nothing in it.reply",
      "Sadly it's the same for Sci-Fi art. I had a link to submit, but you need to sign up and it's $20. Fair enough if they want to set some minimum barrier for the site to filter out suggestions from every Tom, Dick, and Harry (and Jane?), but I don't feel so investing in this to give them $20 to provide a suggestion.reply",
      "I clicked it too and was similarly disappointed. If you don't mind pasting it here I'd love to check it out and add it to my web index.reply"
    ],
    "link": "https://url.town/",
    "first_paragraph": " SearchMIT OpenCourseWare | Free Online Course MaterialsMIT's Course Catalogue available for freeAdded by @tekgadgt in Computers \u203a Educational resources.Abstract, Anime and Manga Illustration, Architecture, Art Blogs, Collage, Color, Design History, Fantasy Art, Gifs, Icons, Illustration, Landscape Art, Painting, Pixel Art, Sci-Fi Art, Sculpture, Surrealism, Typography, Web comicsBlogging Engines, Browser Extensions, Command Line Tools, CSS, Educational resources, Open Source, Operating Systems, Retro, Static Site Generators, Text Editors, Web BrowsersActivities, ParentingFarm to Table, Gardening, Recipes, VeganCard games, Clickers, Consoles, Fantasy Consoles, Forums, In-Browser Games, Interactive Fiction, Paper games, Puzzles, Retro, RPG, Virtual Pets, Word gamesADHD, Autism, Mental HealthPok\u00e9mon, Travel, Yarn CraftAccessibility, PronounsAccess Control, Aggregators, Blogging, Blogrolls, Directories, History & Culture, Hosters, Identity, Indieweb, Newsletters, RSS, Self Hosting, Small "
  },
  {
    "title": "Shrinking freshwater availability increasing land contribution to sea level rise (asu.edu)",
    "points": 117,
    "submitter": "ornel",
    "submit_time": "2025-08-03T19:49:34 1754250574",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=44779178",
    "comments": [
      "I\u2019m not sure this title is completely correct\u201cThe researchers identified the type of water loss on land, and for the first time, found that 68% came from groundwater alone \u2014 contributing more to sea level rise than glaciers and ice caps on land.\u201dThey are saying the leading loss of water loss is from ground water. The largest contributor to sea level rise I would guess is still thermosteric sea level rise due to the ocean becoming warmer and less denseSee ipcc https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/9.6.1 Global and Regional Sea Level Change in the Instrumental EraIn particular, Cross-Chapter 9.1, Figure 1 | Global Energy Inventory and Sea Level Budget. Panel bEDIT: @dang could the submission title be changed to the article or journal article title?\u201cNew global study shows freshwater is disappearing at alarming rates\u201dOr\u201cUnprecedented continental drying, shrinking freshwater availability, and increasing land contributions to sea level rise\u201dreply",
      "My reading of Figure 6 https://www.science.org/doi/10.1126/sciadv.adx0298 suggests that this study still has thermosteric effects making up the majority of sea level rise.I also highly recommend reading up on the GRACE satellite used in this study it is amazing https://gracefo.jpl.nasa.gov/resources/50/how-grace-fo-measu...reply",
      "> it is amazingIndeed!The GRACE measurement of mass change is one of the more revolutionary advances in Earth science remote sensing in the last few decades. It has provided a unique and completely novel view of groundwater mass change. Grace is the main reason we know so much about the massive groundwater loss in the Oglala aquifer in the US Midwest, in the Central Basin in California, and in northern India. Water well data exists but it is very sparse and idiosyncratic.It\u2019s also our main window into mass losses in ice sheets in high latitudes (Greenland, Antarctica). We have radar altimetry data from Antarctica, but because of glacial rebound and other effects, it\u2019s not easy to translate height changes into mass changes. Grace measures mass change directly.Several authors of the cited study are on the science team. It is a JPL instrument.The original Grace pair used radio to measure separation and velocity, while the follow-up Grace-FO uses a laser. I assume the small wavelength of the laser provides a more accurate measurement. It\u2019s possible that Grace-FO has a slightly higher spatial resolution (I\u2019ve worked with Grace but not Grace-FO); the horizontal resolution of Grace is about 100km or about 1 degree.From an inference perspective the measurement is very interesting. They pool about a month\u2019s worth of observations of the distance and velocity of a pair of satellites, and do a Bayesian inversion to obtain a parameterized gravitational potential for that month. The map from gravitational potential to observation is known analytically, so it\u2019s readily possible to get a spatial covariance for the gravitational potential, as well as the point estimate.reply",
      "Thank you for sharing, GRACE-FO feels to me like a brilliant design!reply",
      "Quote from the paper: \"the continents are now the leading contributor (44%) to mass-driven GMSL rise\". As regards to non-mass-driven rise, another article[0] states, \"Ice-mass loss\u2014predominantly from glaciers\u2014has caused twice as much sea-level rise since 1900 as has thermal expansion\". I think the findings about sea level rise are as interesting as the ones about fresh water disappearance.[0] https://www.nature.com/articles/s41586-020-2591-3reply",
      "The study you cite is talking about sea level rise since 1900 which is a very different story.The IPCC section \u201c9.6.1.1 Global Mean Sea Level Change Budget in the Pre-satellite Era\u201d says Since SROCC, a new ocean heat content reconstruction (Section 2.3.3.1; Zanna et al., 2019) has allowed global thermosteric sea level change to be estimated over the 20th century. As a result, the sea level budget for the 20th century can now be assessed for the first time. For the periods 1901\u20131990 and 1901\u20132018, the assessed very likely range for the sum of components is found to be consistent with the assessed very likely range of observed GMSL change (medium confidence), in agreement with Frederikse et al. (2020b; Table 9.5). This represents a major step forward in the understanding of observed GMSL change over the 20th century, which is dominated by glacier (52%) and Greenland Ice Sheet mass loss (29%) and the effect of ocean thermal expansion (32%), with a negative contribution from the LWS change (\u201314%). While the combined mass loss for Greenland and glaciers is consistent with SROCC, updates in the underlying datasets lead to differences in partitioning of the mass loss.\u201dEdit: by a different story I mean a different story from what is the leading driver of sea level rise. Sea level rise from ice melt was larger since 1900 because sea level rise in general was less fast back then and global mean temperature rise was much smaller so thermosteric sea level rise played less of a role. Thermosteric sea level rise is larger than ground water factors, both will be eclipsed by ice melt in the upcoming century.I would note the authors pointedly do not call it the leading driver of sea level rise.reply",
      "So let me get this straight:- sea level is formally referred to as Global Mean Sea Level (GMSL)- its change is segmented into two subcategories in literature(?), mass-driven (e.g. ice melting?, freshwater runoff?, freshwater water cycle stuff?) and non-mass-driven (e.g. thermal expansion?)- freshwater loss from land was found to be at present the lead driver of the mass-driven change as per the paper (over what timeframe?)- title says it's the primary driver for GMSL change overall, which this alone doesn't support (i.e. the title is a lie)- @ornel (the person posting) points to another study that claims mass-driven change is the leading change, hence the title [0, this doesn't pass my smell test but i see the logic]- you point out that that's glossing over that that other study is counting from 1900, but if one shrunk the evaluation window, the non-mass-driven causes would be the drivers now [1, this doesn't pass my smell test either, but i see the logic here as well]The latter point then begs the question though, what is the time window in this case then, and how stable that result is? What would be an \"appropriate\" time window to choose, and how would one derive that?Regarding my non-passing smell tests, imagine the following scenario for some event:- category A: 51% of the total- cause A1: 26% of the total- cause A2: 25% of the total- category B: 49% of the total- cause B1: 27% of the total- cause B2: 22% of the totalIn this case, category A will be the lead contributor, but individually none of its contributing causes will be, addressing [0]. The causes will be ordered like so instead: B1 > A1 > A2 > B2. More elaborate variations are possible of course. For [1], you can imagine the same scenario just in reverse.Did I get all this right?reply",
      "Hi,I appreciate the effort in your comment. I think upon further reflection my simpler objection is calling freshwater loss the main driver of sea level rise when the journal article and news article don\u2019t. Also I would note this is only one study.reply",
      "> I appreciate the effort in your comment.Thanks for that! I do wish it wasn't necessary though, but I guess that's just how real life problems go.> I think upon further reflection my simpler objection is (...)Right, that's perfectly fine; just got curious and you seemed informed.Editorializing the titles in general is against the guidelines here anyhow to be fair, I'm expecting it will be updated by the mods eventually: https://news.ycombinator.com/newsguidelines.htmlreply",
      "I very much like your categories point here by the way!reply"
    ],
    "link": "https://news.asu.edu/20250725-environment-and-sustainability-new-global-study-shows-freshwater-disappearing-alarming",
    "first_paragraph": ""
  },
  {
    "title": "Why Doctors Hate Their Computers (2018) (newyorker.com)",
    "points": 4,
    "submitter": "mitchbob",
    "submit_time": "2025-08-04T00:41:28 1754268088",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44781116",
    "comments": [
      "The doctor I've been with since 1998 has refused to adopt the digital system. He's getting older unfortunately and I suspect in another few years he'll be retiring only to be replaced by a doctor who embraces digitalization. It's far and few these days to find paper only offices. Which is a shame, as I feel the more modern the medical system is the less personable, less \"family doctor\" oriented, heck more often only to be bought up by a network. Quaint is under rated, futurism is over rated.reply",
      "https://archive.ph/PlnQlFor me, the most interesting part is about 4/5 of the way in and starts with> Some people are pushing back. Neil R. Malhotra is a boyish, energetic, forty-three-year-old neurosurgeon who has made his mark at the University of Pennsylvania as something of a tinkerer. He has a knack for tackling difficult medical problems. In the past year alone, he has published papers on rebuilding spinal disks using tissue engineering, on a better way to teach residents how to repair cerebral aneurysms, and on which spinal-surgery techniques have the lowest level of blood loss. When his hospital\u2019s new electronic-medical-record system arrived, he immediately decided to see if he could hack the system.A great example of participatory design.reply",
      "Popular in:2023 (100 points, 116 comments) https://news.ycombinator.com/item?id=369032202020 (279 points, 319 comments) https://news.ycombinator.com/item?id=243360392018 (157 points, 109 comments) https://news.ycombinator.com/item?id=18381969reply"
    ],
    "link": "https://www.newyorker.com/magazine/2018/11/12/why-doctors-hate-their-computers",
    "first_paragraph": "On a sunny afternoon in May, 2015, I joined a dozen other surgeons at a downtown Boston office building to begin sixteen hours of mandatory computer training. We sat in three rows, each of us parked behind a desktop computer. In one month, our daily routines would come to depend upon mastery of Epic, the new medical software system on the screens in front of us. The upgrade from our home-built software would cost the hospital system where we worked, Partners HealthCare, a staggering $1.6 billion, but it aimed to keep us technologically up to date.More than ninety per cent of American hospitals have been computerized during the past decade, and more than half of Americans have their health information in the Epic system. Seventy thousand employees of Partners HealthCare\u2014spread across twelve hospitals and hundreds of clinics in New England\u2014were going to have to adopt the new software. I was in the first wave of implementation, along with eighteen thousand other doctors, nurses, pharmacis"
  },
  {
    "title": "Learnable Programming (2012) (worrydream.com)",
    "points": 9,
    "submitter": "kunzhi",
    "submit_time": "2025-08-03T22:57:22 1754261842",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://worrydream.com/LearnableProgramming/",
    "first_paragraph": "Here's a trick question:  How do we get people to understand programming?Khan Academy recently launched an online environment for learning to program.  It offers a set of tutorials based on the JavaScript and Processing languages, and features a \"live coding\" environment, where the program's output updates as the programmer types.Because my work was cited as an inspiration for the Khan system, I felt I should respond with two thoughts about learning:Thus, the goals of a programming system should be:A live-coding Processing environment addresses neither of these goals.  JavaScript and Processing are poorly-designed languages that support weak ways of thinking, and ignore decades of learning about learning.  And live coding, as a standalone feature, misses the point.Alan Perlis wrote, \"To understand a program, you must become both the machine and the program.\"  This view is a mistake, and it is this widespread and virulent mistake that keeps programming a difficult and obscure art.  A pe"
  },
  {
    "title": "\"If you can rack it, you can run UniFi OS\" Ubiquiti self-hosted UniFi OS release (deluisio.com)",
    "points": 31,
    "submitter": "codydeluisio",
    "submit_time": "2025-08-03T21:09:02 1754255342",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://deluisio.com/networking/unifi/2025/08/03/everything-you-need-to-know-about-unifi-os-server-before-you-waste-time-testing-it/",
    "first_paragraph": "Tips, tricks, and otherCody DeluisioUniFi OS Server is now available in Early Access, and it\u2019s being promoted as a major advancement for MSPs and enterprise IT teams. But does it actually solve any problems we couldn\u2019t already work around? Let\u2019s break down what this release is, what it isn\u2019t, and whether it brings real benefits to the table.UniFi OS Server is a self-hosted platform that lets you run UniFi Network and select UniFi apps (currently InnerSpace and Identity) on your own hardware \u2014 no Dream Machine or Cloud Key required.It\u2019s a containerized stack that mimics what Ubiquiti runs on their own consoles. The idea is simple: let MSPs and advanced users build their own UniFi cloud console, using their choice of hardware.If you\u2019ve been self-hosting UniFi Network for years, UniFi OS Server will feel very familiar. The difference is that it brings support for Ubiquiti\u2019s newer cloud features \u2014 things like:Previously, many of these features were exclusive to UniFi Consoles. Now, they\u2019re"
  },
  {
    "title": "This Old SGI: notes and memoirs on the Silicon Graphics 4D series (1996) (irixnet.org)",
    "points": 68,
    "submitter": "exvi",
    "submit_time": "2025-08-03T15:04:05 1754233445",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44777055",
    "comments": [
      "I find it incredible that we all now have access to an SGI-level machine at home, thanks to Nvidia. This reminds me of a previous thread on HN:\nhttps://news.ycombinator.com/item?id=39945487reply",
      "This is very timely for me, because I've just come into possession of a 4D/60 \"buttons box\" (which normally would go with the dials). It is quite unlike the later button boxes since it's a giant cheese wedge with the power supply integrated, which seems to be very rare as there's no reference to this on the net anywhere. It even has a display where when the unit powers on it says it's rev A. I'm hoping the DB-9 on it is RS232 and can be spoken to by a modern machine, but my one RS232 cable is the wrong gender, of course.Many years ago I had an Indigo, and even 25 years ago that was an exercise in difficult interfacing with modern equipment. The monitor was amazing.Edit to add: the notes here about 20A power requirements remind me of when a VR company I was consulting for hired a notable CTO from the VFX business and all he cared about was making sure there was enough electricity supplied to the office. That was in about 2015 and I remember thinking he was clearly scarred by previous events and was long out of date.reply",
      "I remember getting an Indigo2 Max Impact that had been in a fire (smoke damage) and restoring it. Very cool to own a workstation that was worth more than my car :-)The IRIX 4Dwm desktop can still hold its own today.reply"
    ],
    "link": "https://archive.irixnet.org/thisoldsgi/",
    "first_paragraph": "\n\t  I am posting this assortment of notes and observations as\n\ta kind of \"thank you\" to the numerous people who have replied\n\tto my posts in the past.  The free flow of information is\n\tthe life-blood of the internet community, and this is my feeble\n\tattempt to maintain that flow, while at the same time repaying\n\tthe kindness shown me by other members of the community in my\n\trather obsessive attempts to revive a defunct 4D professional\n\tseries machine.\n\n\n\tI have posted a number of messages concerning my project, and \n\tI can say that all the replies I have received have been quite\n\thelpful. One of the things you learn early on as a denizen of\n\tthe net is the utility of Usenet posts. You also learn that\n\tthe volume of answers can convey almost as much information\n\tas the content of those answers. If I post a question and\n\treceive a significant number of replies, then I can be relatively\n\tcertain that others have run across (and possibly solved) the\n\tsame class of problem. If, however, I r"
  },
  {
    "title": "2,500-year-old Siberian 'ice mummy' had intricate tattoos, imaging reveals (bbc.com)",
    "points": 181,
    "submitter": "dxs",
    "submit_time": "2025-07-31T13:29:40 1753968580",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=44745441",
    "comments": [
      "I think tattoos on mummies have been known for a while, though these do look very artistic. The thing that surprised me the most, oddly, is this throwaway sentence:The team worked with researcher Daniel Riday who reproduces ancient tattoo designs on his body using historical methods.Now that's dedication to research!reply",
      "> tattoos on mummiesOn that note, I'd recommend the title scene in the Iranian movie Qeysar [0] from 1969.A number of the same motifs from 2.5k years ago are still around in Indo-Iranian culture.Some of the older generations of Pakhtun Hindus still tattoo in that style [1], as a number of the central tribes of the Pakhtun community were Saka [2]. A granddaughter from the community has been working on documenting the culture for a couple years now [3]On a separate note, highly recommend watching New Age Iranian Cinema (1965-1980ish). It's good stuff.[0] - https://www.artofthetitle.com/title/qeysar/[1] - https://www.thehindu.com/news/national/tattooed-blue-skinned...[2] - https://en.m.wikipedia.org/wiki/Hephthalites[3] - https://www.instagram.com/sheenkhalaiartproject/?hl=enreply",
      "[1] https://archive.is/owdubreply",
      "the taxonomy of the subjects at the specific chronology is provocative, a leopard and a tiger interest me though I suppose many might over-look that, but what do I care for their lacking interestreply",
      "> Now that's dedication to research!Sounds like a gimmick. Doesn't mean he isn't a legit researcher, doesn't mean he is, but personally it feels more like something you'd see on history channel than actual scientific research; the whole thing seemed less credible after I read that.reply",
      "This comment absolutely comes across as some weird diversion-sewing tactic Russia bots use.\u201cThis random person, who I\u2019ve never met, who studies a topic I know nothing about, in a country I\u2019ve never been to, studying a subject I\u2019ve never seen before, doing something lots of people do, can\u2019t POSSIBLY be passionate about his highly unique job???\u201dI suppose it could be screamingly-loud depression.reply",
      "Welcome to the orange-sitereply",
      "Why? He is that interested he is willing to permanently get his skin. This is the right person for the job.reply",
      "How do you feel about Newton poking a bodkin into his eye to see the distortions?reply",
      "It seems like pretty standard experimental archaeology from the description.reply"
    ],
    "link": "https://www.bbc.com/news/articles/c4gzx0zm68vo",
    "first_paragraph": "High-resolution imaging of tattoos found on a 2,500 year old Siberian \"ice mummy\" have revealed decorations that a modern tattooist would find challenging to produce, according to researchers.The intricate tattoos of leopards, a stag, a rooster, and a mythical half-lion and half-eagle creature on the woman's body shed light on an ancient warrior culture.Archaeologists worked with a tattooist, who reproduces ancient skin decorations on his own body, to understand how exactly they were made.The tattooed woman, aged about 50, was from the nomadic horse-riding Pazyryk people who lived on the vast steppe between China and Europe.The scans revealed \"intricate crisp and uniform\" tattooing that could not be seen with the naked eye.\"The insights really drive home to me the point of how sophisticated these people were,\" lead author Dr Gino Caspari from the Max Planck Institute of Geoanthropology and the University of Bern, told BBC News.It is difficult to uncover detailed information about ancie"
  },
  {
    "title": "Speech may have a universal transmission rate: 39 bits per second (science.org)",
    "points": 6,
    "submitter": "Bluestein",
    "submit_time": "2025-08-03T22:27:57 1754260077",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.science.org/content/article/human-speech-may-have-universal-transmission-rate-39-bits-second",
    "first_paragraph": ""
  },
  {
    "title": "Tokens are getting more expensive (ethanding.substack.com)",
    "points": 218,
    "submitter": "admp",
    "submit_time": "2025-08-03T11:01:37 1754218897",
    "num_comments": 153,
    "comments_url": "https://news.ycombinator.com/item?id=44775700",
    "comments": [
      "From the article:> consumers hate metered billing. they'd rather overpay for unlimited than get surprised by a bill.Yes and no.Take Amazon. You think your costs are known and WHAMMO surprise bill. Why do you get a surprise bill? Because you cannot say 'Turn shit off at X money per month'. Can't do it. Not an option.All of these 'Surprise Net 30' offerings are the same. You think you're getting a stable price until GOTAHCA.Now, metered billing can actually be good, when the user knows exactly where they stand on the metering AND can set maximums so their budget doesn't go over.Taken realistically, as an AI company, you provide a 'used tokens/total tokens' bar graph, tokens per response, and estimated amount of responses before exceeding.Again, don't surprise the user. But that's an anathema to companies who want to hide tokens to dollars, the same way gambling companies obfuscate 'corporate bux' to USD.reply",
      "Metered billing makes sense for B2B infrastructure-as-a-service type products (AWS), where as your company grows both you and the infra provider know the bill will grow manageably over time. Infra is set it and forget it.But for AI in the context of point-solutions and on-the-job use cases, metered billing is a death blow.In this context, metered is a massive incentive to not use the product and requires the huge friction of having to do a cost/benefit analysis before every task. And if you're using it at work you may even need management sign-off before you can use it again.For a tool that's intended to amplify productivity, very few humans want to make a cost/benefit analysis 250 times a day whether it's worth $3 to code up a boilerplate or not. On metered billing, they just wont use it.reply",
      "> and requires the huge friction of having to do a cost/benefit analysis before every taskThat's what we're supposed to do, right?So let's see if we can spend a few tokens to ask the LLM for a cost/benefit analysis of using an LLM to solve the problem. I'd bet we can trust the result...reply",
      "> Again, don't surprise the user. But that's an anathema to companies who want to hide tokens to dollars, the same way gambling companies obfuscate 'corporate bux' to USD.This is the exact same thing that frustrates me with GitHub's AI rollout. Been trialing the new Copilot agent, and it's cost is fully opaque. Multiple references to \"premium requests\" that don't show up real-time in my dashboard, not clear how many I have in total/left, and when these premium requests are referenced in the UI they link to the documentation that also doesn't talk about limits (instead of linking to the associated billing dashboard).reply",
      "They don't make it easy to figure out but after researching it for my Co. this is what I came to.    * One chat message -> one premium credit (most at 1 credit but some are less and some, like opus, are 10x)\n    * Edit mode is the same as Ask/chat\n    * One agent session (meaning you start a new agent chat) is one \"request\" so you can have multiple messages and they cost the credit cost of one chat message.\n\nMicrosoft's Copilot offerings are essentially a masterclass in cost opaqueness.  Nothing in any offering is spelled out and they always seem to be just short of the expectation they are selling.reply",
      "You should see how Microsoft does the PowerBI/ Fabric billing. Gotta get premium capacity and licenses and regular capacity and it's so bad.reply",
      "But how much is one premium request in real currency, and how many do I have per month?reply",
      "https://docs.github.com/en/copilot/how-tos/manage-and-track-...300 or 1500 per month depending on plan. $0.04 per premium request i believe.reply",
      "There's two costs to copilot coding agent, there's the 1 premium request plus there's the minutes the agent runs for comes out of your runner limits for the month.This is coding agent, the asynchronous copilot, not the agent chatmode in copilot plugins for vscode etcreply",
      "Highly recommend getting the $20/month OpenAI sub and letting copilot use that. Quality-wise I feel like I'm getting the same results but OAIs limits are a little more sane.reply"
    ],
    "link": "https://ethanding.substack.com/p/ai-subscriptions-get-short-squeezed",
    "first_paragraph": ""
  },
  {
    "title": "Camera Genealogica (Part 1) (engineersneedart.com)",
    "points": 3,
    "submitter": "JKCalhoun",
    "submit_time": "2025-07-31T12:09:10 1753963750",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://engineersneedart.com/blog/camera/camera.html",
    "first_paragraph": "\n\t\tFaye Coble lived for 103 years. A happy accident that she was born in 1898 \u2014\u00a0that meant that she technically lived in three centuries. \n\t\tShe was the first daughter born to Gertrude Coble (n\u00e9e Harper) on a farm not far outside Kansas City, Missouri. Unfortunately, Faye was \n\t\tquite young when her father died in a Kansas City hotel from gas asphyxiation. (Ironically, the hotel would be one of the first in Kansas \n\t\tCity to get electric lighting \u2014\u00a0too late though for Robert Coble.)\n\t\n\t\tGertrude would marry again (a Calhoun) and it is from that second marriage that my own grandfather would be born. Faye was my grandfather\u2019s \n\t\thalf-sister.\n\t\n\t\tFaye too would eventually marry. As I said at the start Faye lived a very long time but she would never have children. And so when Faye \n\t\tdied in 2001 somehow all of her photos and photo albums ended up ultimately in a suitcase that followed one of my grandfather\u2019s daughters \n\t\tfrom the midwest to a trailer in Eloy, Arizona. And there the photos"
  }
]