[
  {
    "title": "CSS Grid Lanes (webkit.org)",
    "points": 226,
    "submitter": "frizlab",
    "submit_time": "2025-12-19T22:13:06 1766182386",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=46331586",
    "comments": [
      "Props to the Safari team. They surprised us all when they suddenly shot to the top of interop-2025 this Octoberhttps://wpt.fyi/interop-2025reply",
      "I didn't realize it was tracked like this, but I have noticed that as of iOS 26, Safari has gotten a huge number of great web features. It has WebGPU of course, but many small things like fixing up missing parts of the OPFS API that make it actually usable now. Now they even have the field-sizing CSS property [0], fixing imo the most glaring ommission from CSS: the inability to make text input boxes grow to fit the input text![0]: https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/P...reply",
      "> They surprised us all when they suddenly shot to the top of interop-2025 this OctoberNot all of us were surprised; some of us have been watching the Safari team shipping the latest HTML and CSS features for a few years now.reply",
      "Fascinating tracker. So we started 2025 with nearly every browser under 80% and ending the year with every browser with >98% interop? That's a lot of amazing work done by a lot of teams. Incredible!reply",
      "Just to clarify the meaning of the measurement, it doesn't mean they're 98% interoperable across everything, it's across the specific set of goals for 2025. (Which is still really good!)I think they realized that shipping the features out of sync meant nobody could use them until all browsers adopted them, which took years, so now they coordinatereply",
      "This seems like a bit of a trend with Safari. Around big releases Apple will announce how Safari is the best at X, but other times of the year it gets a lot of flack. I assume this is due to Safari\u2019s more traditional release schedule vs other browsers continuously shipping feature updates.reply",
      "Cool stuff they're working on tends to take a very long time to reach customers' hands compared to other browsers. Just compare the \"stable\" and \"experimental\" graphs on wpt.fyi for Safari.I can't think of a single good reason why they don't adopt an \"evergreen\" 4/6-week update model except Not Invented Here syndrome or \"it's not Apple-like, we prefer the OS team (and therefore Marketing) dictating our release schedule, users be damned\".It's an own-goal for no reason.reply",
      "I hope they add WebTransport support soon.reply",
      "This is not all that surprising. While the Chrome team is out there evangelising things like WebPCIe or whatever, Safari's been shipping features clients actually want, like blurred backgrounds for years before anyone else.reply",
      "This is exciting to see! I just used Masonry for a project this past week. While it works quite well and is pretty performant, it is pretty hacky using absolute positioning, wanting to know the aspect ratios of objects beforehand for smoother layout, and having to recalculate everything on resize. I'm looking forward to having a generally available native option one of these days.reply"
    ],
    "link": "https://webkit.org/blog/17660/introducing-css-grid-lanes/",
    "first_paragraph": "Dec 19, 2025by Jen Simmons, Brandon Stewart, and Elika EtemadIt\u2019s here, the future of masonry layouts on the web! After the groundwork laid by Mozilla, years of effort by Apple\u2019s WebKit team, and many rounds debate at the CSS Working Group with all the browsers, it\u2019s now clear how it works.Introducing CSS Grid Lanes.Try it today in Safari Technology Preview 234.Let\u2019s break down exactly how to create this classic layout.First, the HTML.Let\u2019s start by applying display: grid-lanes to the main element to create a Grid container ready to make this kind of layout. Then we use grid-template-columns to create the \u201clanes\u201d with the full power of CSS Grid.In this case, we\u2019ll use repeat(auto-fill, minmax(250px, 1fr)) to create flexible columns at least 250 pixels wide. The browser will decide how many columns to make, filling all available space.And then, gap: 16px gives us 16 pixel gaps between the lanes, and 16 pixel gaps between items within the lanes.That\u2019s it! In three lines of CSS, with zero"
  },
  {
    "title": "Mistral OCR 3 (mistral.ai)",
    "points": 376,
    "submitter": "pember",
    "submit_time": "2025-12-18T15:01:10 1766070070",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=46313390",
    "comments": [
      "From a tweet: https://x.com/i/status/2001821298109120856> can someone help folks at Mistral find more weak baselines to add here? since they can't stomach comparing with SoTA....> (in case y'all wanna fix it: Chandra, dots.ocr, olmOCR, MinerU, Monkey OCR, and PaddleOCR are a good start)reply",
      "I've worked on document extraction a lot and while the tweet is too flippant for my taste, it's not wrong. Mistral is comparing itself to non-VLM computer vision services. While not necessarily what everyone needs, they are a very different beasts compared to VLM based extraction because it gives you precise bounding boxes, usually at the cost of larger \"document understanding\".Its failure mode are also vastly different. VLM-based extraction can misread entire sentences or miss entire paragraphs. Sonnet 3 had that issue. Computer vision models instead will make in-word typos.reply",
      "Why not use both? I just built a pipeline for document data extraction that uses PaddleOCR, then Gemini 3 to check + fix errors. It gets close to 99.9% on extraction from financial statements finally on par with humans.reply",
      "This is The Way. Remember AI doesn't have to replace existing solutions but can tactfully supplement it.",
      "after clicking on your link I browsed twitter for a minute and damn that place has become weird (or maybe it always was?)reply",
      "As someone who has been on Twitter since 2007, it\u2019s radically changed in the last few years to the point of being unrecognizable.reply",
      "I'd want to see a comparison with Qwen 3 VL 235B-A22B, which is IME significantly better than MinerU.reply",
      "there has been so many open source OCR in the last 3 months that would be good to compare to those especially when some are not even 1B params and can be run on edge devices.- paddleOCR-VL- olmOCR-2- chandra- dots.ocrI kind of miss there is not many leaderboard sections or arena for OCR and CV and providers hosting those. Neglected on both Artificial Analysis and OpenRouter.reply",
      "Someone posted a project here about a month ago where they compare models in head-to-head matchups similar to llmarenahttps://www.ocrarena.ai/leaderboardHasn't been updated for Mistral but so far gemeni seems to top the leaderboard.reply",
      "OCR developers from decades past must be slapping their foreheads now that it seems users will wait a whole minute per page and be happy.reply"
    ],
    "link": "https://mistral.ai/news/mistral-ocr-3",
    "first_paragraph": "Achieving a new frontier for both accuracy and efficiency in document processing.  Just had dinner. Did not get home until nearly 8 pm. as I am now very busy at the office. Westcott came today and is trying to raise money at last minute. I have to hand over balance of work to the liquidators & also finish off books before shipping them to N. York tomorrow. Glad to say it rained heavily the whole day yesterday, which kept things quiet politically, but of course, it was rotten getting to office back. Went to bed at 9-20 pm. I am not going out tonight. Will martial law, but things look better today as the teams are running & the P.O. is open & I can post this tomorrow. Will be out all day tomorrow as I have invited 6 Chinese & Mr Westcott to tiffin. Will go to Eddie's Cafe on Broadway as I believe it is good & has music. At 6 pm. I am invited to a Chinese dinner which M. H. is giving at his home for me. I bought some socks to-day & studs for shirt. Just thought on - I gave your empty ear-"
  },
  {
    "title": "Garage \u2013 An S3 object store so reliable you can run it outside datacenters (deuxfleurs.fr)",
    "points": 449,
    "submitter": "ibobev",
    "submit_time": "2025-12-19T15:40:03 1766158803",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=46326984",
    "comments": [
      "Half-OT:Does anyone know a good open source S3 alternarive that's easily extendable with custom storage backends?For example, AWS offers IA and Glacier in addition to the defaults.reply",
      "Copy/paste from a previous thread [0]:We\u2019ve done some fairly extensive testing internally recently and found that Garage is somewhat easier to deploy in comparison to our existing use of MinIO, but is not as performant at high speeds. IIRC we could push about 5 gigabits of (not small) GET requests out of it, but something blocked it from reaching the 20-25 gigabits (on a 25g NIC) that MinIO could reach (also 50k STAT requests/s, over 10 nodes)I don\u2019t begrudge it that. I get the impression that Garage isn\u2019t necessarily focussed on this kind of use case.---In addition:Next time we come to this we are going to look at RustFS [1], as well as Ceph/Rook [2].We can see we're going to have to move away from MinIO in the foreseeable future. My hope is that the alternatives get a boost of interest given the direction MinIO is now taking.[0]: https://news.ycombinator.com/item?id=46140342[1]: https://rustfs.com/[2]: https://rook.io/reply",
      "They explicitly say that top performance is not a goal: \u00abhigh performances constrain a lot the design and the infrastructure; we seek performances through minimalism only\u00bb (https://garagehq.deuxfleurs.fr/documentation/design/goals/)But it might be interesting to see where the time is spent. I suspect they may be doing fewer things in parallel than MinIO, but maybe it's something entirely different.reply",
      "I wouldn\u2019t use rook if you solely want S3. It is a massively complex system which you really need to invest in understanding or else your cluster will croak at some point and you will have no idea on how to fix it.reply",
      "IS there a better solution for self-healing S3 storage that you could recommend? I'm also curious what will make a rook cluster croak after some time and what kind of maintenance is required in your experience.reply",
      "Not used it yet, but RustFS sounds like it has self healinghttps://docs.rustfs.com/troubleshooting/healing.htmlreply",
      "ceph?reply",
      "Please also consider including SeaweedFS in the testing.reply",
      "Looks interesting for something like local development. I don't intend to run production object storage myself, but some of the stuff in the guide to the production setup (https://garagehq.deuxfleurs.fr/documentation/cookbook/real-w...) would scare me a bit:> For the metadata storage, Garage does not do checksumming and integrity verification on its own, so it is better to use a robust filesystem such as BTRFS or ZFS. Users have reported that when using the LMDB database engine (the default), database files have a tendency of becoming corrupted after an unclean shutdown (e.g. a power outage), so you should take regular snapshots to be able to recover from such a situation.It seems like you can also use SQLite, but a default database that isn't robust against power failure or crashes seems suprising to me.reply",
      "If you know of an embedded key-value store that supports transactions, is fast, has good Rust bindings, and does checksumming/integrity verification by default such that it almost never corrupts upon power loss (or at least, is always able to recover to a valid state), please tell me, and we will integrate it into Garage immediately.reply"
    ],
    "link": "https://garagehq.deuxfleurs.fr/",
    "first_paragraph": "An S3 object store so reliable you can run it outside datacentersMade for redundancyEach chunk of data is replicated in 3 zonesWe made it lightweight and kept the efficiency in mind:We ship a single dependency-free binary that runs on all Linux distributionsWe are sysadmins, we know the value of operator-friendly softwareWe do not have a dedicated backbone, and neither do you,\n              so we made software that run over the Internet across multiple datacenters\n          We worked hard to keep requirements as low as possible:\n        \n          We built Garage to suit your existing infrastructure:\n        \n          Garage implements the Amazon S3 APIand thus is already compatible with many applications.\n        \n          Garage leverages insights from recent research in distributed systems:\n        Garage has benefitted multiple times from public funding:\n          \n2021-2022: NGI POINTER provided funding for 3 full-time employees for one year\n2023-2024: NLnet / NGI0 Entrust provi"
  },
  {
    "title": "TP-Link Tapo C200: Hardcoded Keys, Buffer Overflows and Privacy (evilsocket.net)",
    "points": 218,
    "submitter": "sibellavia",
    "submit_time": "2025-12-19T18:19:32 1766168372",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=46329038",
    "comments": [
      "I'm a little frustrated with articles like this that scattershot their critique by conflating genuine failures with problems that even FAANGs struggle with.In particular, I don't love it when an article attacks a best practice as a cheap gotcha:\"and this time it was super easy! After some basic reversing of the Tapo Android app, I found out that TP-Link have their entire firmware repository in an open S3 bucket. No authentication required. So, you can list and download every version of every firmware they\u2019ve ever released for any device they ever produced\"That is a good thing - don't encourage security through obscurity! The impact of an article like this is as likely to get management to prescribe a ham-handed mandate to lock down firmware as it is to get them to properly upgrade their security practices.reply",
      "I think maybe you\u2019re reading this wrong. Reverse-engineering blog posts like this are just a fun and instructive way of telling the story of how someone did a thing. Having written and read a bunch of these in the past myself, I found this one to be a great read!Edit: just want to add, the \u201chow I got the firmware\u201d part of this is also the least interesting part of this particular story.reply",
      "> I found out that TP-Link have their entire firmware repository in an open S3 bucket.Nobody tell them about Linux!reply",
      "I didn't notice a negative tone at all when he talked about the firmwares being publicly hosted. You did?reply",
      "Yes, heavily, because of the use of adjectives and repeating the points.Here, I'll emphasize the words that elicit the tone:> After some basic reversing of the Tapo Android app, I found out that TP-Link have their entire firmware repository in an open S3 bucket. No authentication required. So, you can list and download every version of every firmware they\u2019ve ever released for any device they ever produced: [command elided] The entire output is here, for the curious. This provides access to the firmware image of every TP-Link device - routers, cameras, smart plugs, you name it. A reverse engineer\u2019s candy store.Highlighting (repeatedly) the ease and breadth of access is a basic writing technique to illustrate the weakness of a security system.reply",
      "To me the phrasing seems objective. Making your binaries available to the public is good (though source would be better).Replace [firmware] with [random popular GitHub repo] and nobody would blink. Replace [firmware] with [customer email address] and it would be a legal case. Differentiating here is important.reply",
      "Yep, I think it should always be that way, firmwares should be always available.reply",
      "I didnt really interpret that as a particular criticism reallyreply",
      "I think this kind of critique often leans too hard on \u201csecurity through obscurity\u201d as a cheap punchline, without acknowledging that real systems are layered, pragmatic, and operated by humans with varying skill levels. An open firmware repository, by itself, is not a failure. In many cases it is the opposite: transparency that allows scrutiny, reproducibility, and faster remediation. The real risk is not that attackers can see firmware, but that defenders assume secrecy is doing work that proper controls should be doing anyway.What worries me more is security through herd mentality, where everyone copies the same patterns, tooling, and assumptions. When one breaks, they all break. Some obscurity, used deliberately, can raise the bar against casual incompetence and lazy attacks, which, frankly, account for far more incidents than sophisticated adversaries. We should absolutely design systems that are easy to operate safely, but there is a difference between \u201csimple to use\u201d and \u201csafe to run critical infrastructure.\u201d Not every button should be green, and not every role should be interchangeable. If an approach only works when no one understands it, that is bad security. But if it fails because operators cannot grasp basic layered defenses, that is a staffing and governance problem, not a philosophy one.reply",
      "I\u2019m beginning to think maybe I\u2019m the only one that read this whole thing. The firmware storage isn\u2019t the security through obscurity problem being talked about here. The hardcoded TLS private key definitely is though. And yes, it deserves shaming\u2026 terrible practice leads to terrible outcomes. Nobody is surprised that this is coming from tp-link at this point though.reply"
    ],
    "link": "https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/",
    "first_paragraph": "Hi friends and welcome to the last post for this year! Whenever someone asks me how to get started with reverse engineering, I always give the same advice: buy the cheapest IP camera you can find. These devices are self-contained little ecosystems - they have firmware you can extract, network protocols you can sniff, and mobile apps you can decompile. Chances are, you\u2019ll find something interesting. At worst, you\u2019ll learn a lot about assembly and embedded systems. At best, you\u2019ll find some juicy vulnerability and maybe learn how to exploit it!I own several TP-Link Tapo C200 cameras myself. They\u2019re cheap (less than 20 EUR from Italy), surprisingly stable, and I genuinely like them - they just work. One weekend, I decided just for fun to take my own advice. The Tapo C200 has been around for a while and has had a few CVEs discovered and more or less patched over the years, so I honestly wasn\u2019t expecting to find much in the latest firmware. However, I wanted to use this chance to perform so"
  },
  {
    "title": "A Better Zip Bomb (bamsoftware.com)",
    "points": 79,
    "submitter": "kekqqq",
    "submit_time": "2025-12-19T21:34:10 1766180050",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=46331216",
    "comments": [
      "The fact that ZIP files include the catalog/directory at the end is such nostalgia fever. Back in the day it meant that if you na\u00efvely downloaded the file, a partial download would be totally useless. Fortunately, in the early 2000s, we got HTTP's Range and a bunch of zip-aware downloaders that would fetch the catalog first so that you could preview a zip you were downloading and even extract part of a file! Good times. Well, not as good as now, but amusing to think of today.reply",
      "> ... a partial download would be totally useless ...no, not totally. The directory at the end of the archive points backwards to local headers, which in turn include all the necessary information, e.g. the compressed size inside the archive, compression method, the filename and even a checksum.If the archive isn't some recursive/polyglot nonsense as in the article, it's essentially just a tightly packed list of compressed blobs, each with a neat, local header in front (that even includes a magic number!), the directory at the end is really just for quick access.If your extraction program supports it (or you are sufficiently motivated to cobble together a small C program with zlib....), you can salvage what you have by linearly scanning and extracting the archive, somewhat like a fancy tarball.reply",
      "Partial zip shouldn't be totally useless and a good unzip tool should be able to repair such partial downloads. In addition to catalog at end zip also have local headers before each file entry. So unless you are dealing with maliciously crafted zip file or zip file combined with something else,  parsing it from start should produce identical result. Some zip parsers even default to sequential parsing behavior.This redundant information has lead to multiple vulnerabilities over the years. As having redundant information means that a maliciously crafted zip file with conflicting headers can have 2 different interpretations when processed by 2 different parsers.reply",
      "Debian's `unzip` utility, which is based off of Info-ZIP but with a number of patches, errors out on overlapping files, though not before making a 21 MB file named `0` - presumably the only non-overlapping file.    unzip zbsm.zip\n    Archive:  zbsm.zip\n      inflating: 0\n    error: invalid zip file with overlapped components (possible zip bomb)\n\nThis seems to have been done in a patch to address https://nvd.nist.gov/vuln/detail/cve-2019-13232https://sources.debian.org/patches/unzip/6.0-29/23-cve-2019-...reply",
      "Yep, these kinds of format shenanigans are increasingly rejected for security reasons. Not zip bombs specifically, but to prevent parser mismatch vulnerabilities (i.e. two parser implementations decompressing the same zip file to different contents, without reporting an error).reply",
      "I wonder if there's any reverse zip-bombs? e.g. A realy big .zip file, takes long time to unzip, but get only few bytes of content.Like bomb the CPU time instead of memory.reply",
      "Isn't that mathematically impossible?reply",
      "Previously discussed in 2019, https://news.ycombinator.com/item?id=20352439Someone shared a link to that site in a conversation earlier this year on HN.  For a long time now, I've had a gzip bomb sitting on my server that I provide to people that make a certain categories of malicious calls, such as attempts to log in to wordpress, on a site not using wordpress.  That post got me thinking about alternative types of bombs, particularly as newer compression standards have become ubiquitous, and supported in browsers and http clients.I spent some time experimenting with brotli as a compression bomb to serve to malicious actors: https://paulgraydon.co.uk/posts/2025-07-28-compression-bomb/Unfortunately, as best as I can see, malicious actors are all using clients that only accept gzip, rather than brotli'd contents, and I'm the only one to have ever triggered the bomb when I was doing the initial setup!reply",
      "In one of my previous jobs, I got laid off in the most condescending way, only to be asked days later by my former boss to send her some documents. If only I knew about this then...reply",
      "You have bigger enemies more worthy of that personal risk. This comment bewilders me a bit.reply"
    ],
    "link": "https://www.bamsoftware.com/hacks/zipbomb/",
    "first_paragraph": "\nDavid Fifield\ndavid@bamsoftware.com\n\n2019-07-02\nupdated 2019-07-03, 2019-07-05, 2019-07-06, 2019-07-08,\n2019-07-18, 2019-07-20, 2019-07-22, 2019-07-24,\n2019-08-05, 2019-08-19, 2019-08-22, 2019-10-14,\n2019-10-18, 2019-10-30, 2019-11-28,\n2020-07-28, 2021-01-21, 2021-02-02,\n2021-05-03, 2021-07-29,\n2023-05-18\n\n\nThis article shows how to construct a\nnon-recursive zip bomb\nthat achieves a high compression ratio by\noverlapping files inside the zip container.\n\"Non-recursive\" means that it does not rely on\na decompressor's recursively unpacking zip files nested within zip files:\nit expands fully after a single round of decompression.\nThe output size increases quadratically in the input size,\nreaching a compression ratio of over 28\u00a0million\n(10\u00a0MB \u2192 281\u00a0TB)\nat the limits of the zip format.\nEven greater expansion is possible using\n64-bit extensions.\nThe construction uses only the most common compression algorithm, DEFLATE,\nand is compatible with most zip parsers.\n\nPresentation video\n\n\u0420\u0443\u0441\u0441\u043a\u0438\u0439 \u043f\u0435\u0440\u0435"
  },
  {
    "title": "8-bit Bol\u00e9ro (linusakesson.net)",
    "points": 166,
    "submitter": "Aissen",
    "submit_time": "2025-12-19T11:38:54 1766144334",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=46324702",
    "comments": [
      "According to a possibly apocryphal story from the premiere performance, a woman was heard shouting that Ravel was mad. When told about this, Ravel is said to have remarked that she had understood the piece.\n\nhttps://en.wikipedia.org/wiki/Bol%C3%A9roreply",
      "And, Ravel did eventually go mad. There's a lot of discussion about whether the recurring patterns in the song had something to do with his neurological condition.https://bigthink.com/high-culture/bolero-ravel-dementia-2/reply",
      "That Commodore C64 accordion made me laugh.Ah it's called The Commodordion https://linusakesson.net/commodordion/index.phpreply",
      "It's kind of incredible!A direct youtube link for the lazy: https://www.youtube.com/watch?v=o6z5__6rP58reply",
      "And don't miss the Qweremin:https://linusakesson.net/qweremin/Brilliant.reply",
      "For anyone wanting to know, the keyboard layout is that of a chromatic button accordian [0] [1].I guess there's a C64 \"executable\" that he's made available but no source so I don't know what the exact keymapping is. I did find a few different resources that show the layout in action [2] [3].[0] https://www.youtube.com/watch?v=xwsZ41pA_Vo&t=58s[1] https://en.wikipedia.org/wiki/Chromatic_button_accordion[2] https://okathira-dev.github.io/client-web-api-sandbox/button...[3] https://www.rmwinslow.com/tones/reply",
      "> 0 regretsThat's the most important number in stores like this one.reply",
      "Yes! Linus must really burn himself up, conceiving and executing masterworks like this! But saying \"0 regrets\" hopefully means he hasn't lost motivation for his next crazy project!reply",
      "It\u2019s probably not a coincidence that the climax starts at 13:37.reply",
      "Ha! I almost posted this here but I thought maybe I was posting too many music videos on HN.I am part of the LOAD \"*\", 8, 1 generation, and this is really freaking cool.One of the funniest things in the video is the variety of neck tie configurations, one for each part.reply"
    ],
    "link": "https://linusakesson.net/music/bolero/index.php",
    "first_paragraph": "I perform Maurice Ravel's Bol\u00e9ro on a variety of homemade\n8-bit instruments.This project took me a bit over half a year to finish.I hope you'll enjoy the video as much as I enjoyed making it! There are many\nlittle details that I'll let you discover on your own.\n\nIt was fun to put my tools and methods to the test with this huge\nundertaking. When I started out I had no idea if my mixing and video-editing\nprocess would work at this scale, but it turned out to only need a few tweaks\nhere and there.\nThe nine instruments are: The Qweremin (breadbin / regular\u00a0C64C\n/ dark\u00a0C64C), Qwertuoso\n(breadbin), the Paulimba, the Tenor\u00a0Commodordion, the Family\u00a0Bass (albeit not as a bass\nthis time), my still unnamed floppy-drive noise instrument (1541\n/ 1541-II), the C=TAR, the Chipophone, and a newcomer: NES timpani.\nThe timpani sound is based on the famous NES staircase triangle wave. But\nthere is no register for controlling its volume, and yet we can hear an\nenvelope with a release phase. To achieve thi"
  },
  {
    "title": "Amazon will allow ePub and PDF downloads for DRM-free eBooks (kdpcommunity.com)",
    "points": 534,
    "submitter": "captn3m0",
    "submit_time": "2025-12-19T10:03:38 1766138618",
    "num_comments": 278,
    "comments_url": "https://news.ycombinator.com/item?id=46324078",
    "comments": [
      "I\u2019d advise anyone buying e-books on Amazon to think it through carefully. My account was banned recently because, years ago, I ordered two paper books that Amazon said would be split into two shipments. Both books arrived without any issues, but later Amazon refunded me for one of them, claiming that one package never arrived. This happened 4\u20135 years ago.Apparently, during a recent review, they decided this counted as fraud and banned my account. As a result, I can no longer log in and lost access to all my Kindle e-books. They also remotely wiped my Kindle, so my entire library is gone. I appealed the decision, but I\u2019ve been waiting for over six months with no resolution.reply",
      "A friend of mine received a double shipment for a $300 order. Being honest, he contacted customer service to arrange a return. Everything seemed fine until a few days later when he noticed they had also refunded his original payment. He reached out again to let them know, and they said they\u2019d just recharge his card. Apparently, that transaction failed (no clear reason why), and without any warning, they banned his account, wiping out his entire Kindle library in the process. Amazon works wonderfully right up until it fails spectacularly.reply",
      "I wonder just like retailers are required to account for local sales taxes (I know it is not that clear cut), there should be some enforcement mechanism to settle disputes locally. Setup an agency which \"legally\" provides support for google, Amazon, and all those unreachable entities. Provides local jobs as well as quick grievance redressal. Maybe something like consumer protection agency but not federal, maybe at least one per county maybe more depending on the population.Edit - I don't mind paying for the service. Maybe charge everyone $99 to file a case to avoid everyone piling on, but it helps resolve most egregious ones, and fee could be refunded at the agency's discretion.reply",
      "I can't speak for how effective the process is, but this is the idea behind the EU/UK GPSR's Authorised Representative framework - though not exactly local (that would be excessive, since GPSR also applies to much smaller sellers too)reply",
      "I hope it works better than the EU DSA dispute resolution, which I've heard multiple accounts of youtube just ignoring.reply",
      "Some kind of court, for small claims?reply",
      "Just need to outlaw binding arbitrationreply",
      "Amazon will reimburse arbitration fees if you win making it a cheaper option for consumers than small claims court.reply",
      "Two problems with that argument: 1) Amazon would also have to reimburse small claims court fees if you win, and 2) arbitration is worse for the consumer in pretty much every other way.reply",
      "\"If\".[Edit, because one-word replies are uncivilized: one reason to be suspicious about binding arbitration is that the company against whom you'll be pleading is a repeat customer of that arbitration service. It's a non-transparent / non-public process, so it's hard to have confidence is fair, and over which we (ie, the public) have no influence if it were not.]reply"
    ],
    "link": "https://www.kdpcommunity.com/s/article/New-eBook-Download-Options-for-Readers-Coming-in-2026?language=en_US",
    "first_paragraph": ""
  },
  {
    "title": "GotaTun \u2013 Mullvad's WireGuard Implementation in Rust (mullvad.net)",
    "points": 537,
    "submitter": "km",
    "submit_time": "2025-12-19T11:16:23 1766142983",
    "num_comments": 112,
    "comments_url": "https://news.ycombinator.com/item?id=46324543",
    "comments": [
      "I definitely noticed the performance boost on my Pixel 8, for some reason it seems to really not like wireguard-go, it struggled to pull even 100mbps, maybe something unoptimized on Google's custom hardware. With the new GotaTun version I can pull 500mbps+, though unfortunately it also seems to have introduced a bug that randomly prevents the phone from entering a deep sleep state, so occasionally my battery will randomly start draining at 10x normal speed if I have it enabled until I reboot.reply",
      "I'm surprised by this comment. I have wireguard on 24/7 on my shitty Samsung A5 and it lasts forever. By comparison the Pixel 8 is a beast. Sounds like an Android bug more than wireguard.reply",
      "Pixel 6 here. Vanilla wireguard app. It sucks the life out of my phone and nearly halves the already half-life battery (thanks Google for your crappy OEM producers!)reply",
      "Thank samsung for their shitty modems in the pixels.However, there\u2019s going to be a large discrepancy for all devices on battery usage based on whether VPN is on wifi or cellular, and additionally when on cellular how close to the tower they are. I live near cell edge and VPN\u2019s roast my batts on cellular no matter the make, in city it\u2019s almost not noticeable to have VPN on. Better to use wifi when far from towers, cellular more efficient if it\u2019s strong signal.reply",
      "What app are you using?reply",
      "It's just called WireGuard, by the \"WireGuard Development Team\" off google play.reply",
      "Pretty sure thats the c implementation not the go onereply",
      "AFAIK the C implementation is a kernel module that's not shipped in stock Android releases. The WireGuard Android app uses that module when available, but otherwise uses wireguard-go.reply",
      "Good knowledge here, was unaware of this feature of the app. Would there be any case of the app defaulting to the wireguard kernel module if it's not included by any OEM Android release? I would assume that means most users are actually running wireguard-go.reply",
      "I hope so.reply"
    ],
    "link": "https://mullvad.net/en/blog/announcing-gotatun-the-future-of-wireguard-at-mullvad-vpn",
    "first_paragraph": "December 19, 2025 Features\u00a0App\u00a0GotaTun is a WireGuard\u00ae implementation written in Rust aimed at being fast, efficient and reliable.GotaTun is a fork of the BoringTun project from Cloudflare. This is not a new protocol or connection method, just WireGuard\u00ae written in Rust. The name GotaTun is a combination of the original project, BoringTun, and G\u00f6tatunneln, a physical tunnel located in Gothenburg. We have integrated privacy enhancing features like DAITA & Multihop, added first-class support for Android and used Rust to achieve great performance by using safe multi-threading and zero-copy memory strategies.Last month we rolled it out to all our Android users, and we aim to ship it to the remaining platforms next year.Our mobile apps have relied on wireguard-go for several years, a cross-platform userspace implementation of WireGuard\u00ae in Go. wireguard-go has been the de-facto userspace implementation of WireGuard\u00ae to this date, and many VPN providers besides Mullvad use it. Since mid-2024"
  },
  {
    "title": "Graphite is joining Cursor (cursor.com)",
    "points": 169,
    "submitter": "fosterfriends",
    "submit_time": "2025-12-19T15:57:01 1766159821",
    "num_comments": 196,
    "comments_url": "https://news.ycombinator.com/item?id=46327206",
    "comments": [
      "Imo Cursor did had the first mover advantage by making the first well known AI coding agent IDE. But I can't help but think they have no realistic path forward.As someone who is a huge IDE fan, I vastly prefer the experience from Codex CLI compared to having that built into my IDE, which I customize for my general purposes. The fact it's a fork of VSCode (or whatever) will make me never use it. I wonder if they bet wrong.But that's just usability and preference. When the SOTA model makers give out tokens for substantially less than public API cost, how in the world is Cursor going to stay competitive? The moat just isn't there (in fact I would argue its non-existent)reply",
      "Yeah, hard disagree on that one, based on recent surveys, 80-90% of developers globally use IDEs over CLIs for their day-to-day work.I was pretty worried about Cursor's business until they launched their Composer 1 model, which is fine-tuned to work amazingly well in their IDE. It's significantly faster than using any other model, and it's clearly fine-tuned for the type of work people use Cursor for. They are also clearly charging a premium for it and making a healthy margin on it, but for how fast + good it's totally worth it.Composer 1 + now eventually creating an AI native version of GitHub with Graphite, that's a serious business, with a much clearer picture to me how Cursor gets to serious profitability vs the AI labs.reply",
      "As the other commenter stated, I don't use CLIs for development. I use VSCode.I'm very pro IDE. I've built up an entire collection of VSCode extensions and workflows for programming, building, customizing build & debugging embedded systems within VSCode. But I still prefer CLI based AI (when talking about an agent to the IDE version).> Composer 1My bet is their model doesn't realistically compare to any of the frontier models. And even if it did, it would become outdated very quickly.It seems somewhat clear (at least to me) that economics of scale heavily favor AI model development. Spend billions making massive models that are unusable due to cost and speed and distill their knowledge + fine tune them for stuff like tools. Generalists are better than specialists. You make one big model and produce 5 models that are SOTA in 5 different domains. Cursor can't do that realistically.reply",
      "> My bet is their model doesn't realistically compare to any of the frontier models.I've been using composer-1 in Cursor for a few weeks and also switching back and forth between it, Gemini Flash 3, Claude Opus 4.5, Claude Sonnet 4.5 and  GPT 5.2.And you're right it's not comparable. It's about the same quality of code output of the aforementioned models but about 4x as fast. Which enables a qualitatively different workflow for me where instead of me spending a bunch of time waiting on the model, the model is waiting on me to catch up with its outputs. After using composer-1, it feels painful to switch back to other models.I work in a larg(ish) enterprise codebase. I spend a lot of time asking it questions about the codebase and then making small incremental changes. So it works very well for my particular workflow.Other people use CLI and remote agents and that sort of thing and that's not really my workflow so other models might work better for other people.reply",
      "Does it have some huge context window? Or is it really good at grep?The Copilot version of this is just fucking terrible at suggesting anything remotely useful about our codebase.I've had reasonable success just sticking single giant functions into context and asking Sonnet 4.5 targeted questions (is anything in this function modifying X, does this function appear to be doing Y) as a shortcut for reading through the whole thing or scattershot text search.When I try to give it a whole file I actually hit single-query token limits.But that's very \"opt-in\" on my part, and different from how I understand Cursor to work.reply",
      "It is really good at grep and will make multiple grep calls in parallel.And when I open it in the parent directory of a bunch of repos in our codebase, it can very quickly trace data flow through a bunch of different services. It will tell me all the files the data goes through.It's context window is \"only\" 200k tokens. When it gets near 200k, it compresses the conversation and starts a new conversation..... which mostly works but sometimes it has a bit of amnesia if you have a really long running conversation on something.reply",
      "> It is really good at grep and will make multiple grep calls in parallel.How does that work? Multiple agents grepping simultaneously?reply",
      "Probably something closer to ripgrep, if not actually ripgrep.reply",
      "composer 1 has been my most used model the past few months. but i only use it to execute plans that i write with the help of larger, more intelligent models like opus 4.5. composer 1 is great at following plan instructions so after some careful time providing the right context and building a plan, it basically never messes up the implementation. sometimes requires a few small tweaks around the edges but overall a fantastic workflow that's so delightfully fastreply",
      "OP isn't saying to do all of your work in the terminal; they're saying they prefer CLI-based LLM interfaces. You can have your IDE running alongside it just fine, and the CLIs can often present the changes as diffs in the IDEs too.reply"
    ],
    "link": "https://cursor.com/blog/graphite",
    "first_paragraph": "The way developers write code looks different than it did a few years ago. But reviewing those changes, merging them safely, and collaborating on them has increasingly become the bottleneck for building production-grade software.The team at Graphite has spent the past few years thinking deeply about these workflows and have built a code review platform used by hundreds of thousands of engineers at top engineering organizations. The boundary between where you write code and where you collaborate on it feels increasingly arbitrary, and there's a lot we think we can build by collapsing that distance.We are excited to announce that Graphite has entered into a definitive agreement to be acquired by Cursor.Graphite will continue to operate independently with the same team and product. Over the coming months, we'll explore connecting the two products in ways that we hope will feel natural: tighter integrations between local development and pull requests, smarter code review that learns from b"
  },
  {
    "title": "Brown/MIT shooting suspect found dead, officials say (washingtonpost.com)",
    "points": 92,
    "submitter": "anigbrowl",
    "submit_time": "2025-12-19T03:19:59 1766114399",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=46321947",
    "comments": [
      "I work on campus (very very close to the engineering building) and I previously lived near Brookline. So all of this hits home.But what got me was the tipster who blew wide open the case is reportedly a homeless Brown graduate who lived in the basement of the engineering building (a la South Korean film Parasite). It made me so sad but also not surprised, that building does have a single occupancy bathroom with showers; and no keycard access was needed in the evening until 7pm.So it made sense to me that he or she would've used that building for shelter and comfort. Also it didn't boggle my mind at all that a Brown grad (from the picture, the tipster looked like a artistic Brown student vs. the careerist type) would be homeless - given that I known many of my classmates who have a certain personality, brilliant but also idealistic/uncompromising that made them brittle unfortunately in a society that rewards conformity, settling and stability.I can't get over the fact that two Brown student whom presumably have fallen on the wayside of society have chosen two different paths, (1) the homeless guy who still perseveres even in the basement of Barrus & Holley for 15 years a la Parasite after 2010 graduation but still has the situational awareness and rises to the occasion to give the biggest tip to the Providence Police, (2) the other guy who harbors so much resentment over a course of 25 years to plan a trip from Florida to gun down innocent kids who are 18 and 19 and his classmate when they were 18 and 19 year old.reply",
      "But resentment over what? I haven't seen anything on this.reply",
      "This article was helpful:https://www.nytimes.com/2025/12/19/us/mit-professor-shooting...https://archive.is/qypozreply",
      "That definitely doesn't explain things. It appears the motive is still unknown(But I did find this article better than the WaPo one)reply",
      "This whole post is filled with a ridiculous amount of unfounded assumptions.reply",
      "\"...the tipster who blew wide open the case is reportedly a homeless Brown graduate who lived in the basement of the engineering building...\" Where did you read this?reply",
      "https://kfanplus.iheart.com/content/2025-12-19-homeless-man-...It was posted on a Fox News affiliate. He won't get the reward, because he called 911 rather than the tipline.reply",
      "FWIW, The New York Post video on this said he will get the reward.reply",
      "That doesn't surprise me at all.Makes me furious, but it doesn't surprise me.reply",
      "I assume he will also no longer be able to live in the engineering hall basement.  Beyond personal moral satisfaction, coming forward only means sacrifice.But a number of people have lost their lives, which keeps the scale of the tipster's personal losses in perspective.  A terrible event all around.reply"
    ],
    "link": "https://www.washingtonpost.com/nation/2025/12/18/brown-university-shooting-person-of-interest/",
    "first_paragraph": ""
  },
  {
    "title": "Qwen-Image-Layered: transparency and layer aware open diffusion model (huggingface.co)",
    "points": 60,
    "submitter": "dvrp",
    "submit_time": "2025-12-19T03:24:26 1766114666",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=46321972",
    "comments": [
      "Qwen-Image-Layered is a diffusion model that, unlike most SOTA-ish models out there (e.g. Flux, Krea 1, ChatGPT, Qwen-Image) it's (1) open-weight (unlike ChatGPT Image or Nano Banana) and Apache 2.0; and has 2 distinct inference-time features: (i) it's able to understand the alpha channel of images (RGBA, as opposed to RGB only) which makes it able to generate transparency-aware bitmaps; and (ii), it's able to understand layers [1]\u2014this is how most creative professionals work in software like Photoshop or Figma, where you overlay elements into a single file, such as a foreground and a background.This is the first model by a main AI research lab (the people behind Qwen Image, which is basically the SOTA open image diffusion model) with those capabilities afaik.The difference in timing for this submission (16 hours ago) is because that's when the research/academic paper got released\u2014as opposed to the inference code and model weights, which just got released 5 hours ago.---Technically there's another difference, but this mostly matters for people who are interested in AI research or AI training. From their abstract: \u201c[we introduce] a Multi-stage Training strategy to adapt a pretrained image generation model into a multilayer image decomposer.\u201d which seems to imply that you can adapt a current (but different) image model to understand layers as well, as well as a pipeline to obtain the data from Photoshop .PSD files.reply",
      "See also:- Paper page: https://huggingface.co/papers/2512.15603- Model page: https://huggingface.co/Qwen/Qwen-Image-Layered- Quantized model page: https://huggingface.co/QuantStack/Qwen-Image-Layered-GGUF- Blog URL: https://qwenlm.github.io/blog/qwen-image-layered/ (404 at the time of writing this comment, but it'll probably release soon)- GitHub page: https://github.com/QwenLM/Qwen-Image-Layeredreply",
      "I\u2019m still not clear if it\u2019s going to deliver the unique layers to you?If you set a variable layers of 5 for example will it determine what is on each layer, or do I need to prompt that?And I assume you need enough VRAM because each layer will be effectively a whole image in pixel or latent space\u2026 so if I have a 1MP image, and 5 layers I would likely need to be able to fit a 5MP image in VRAM?Or if this can be multiple steps, where I wouldn\u2019t need all 5 layers in active VRAM, that the assembly is another step at the end after generating on one layer?reply",
      "The linked GitHub readme says it outputs a powerpoint file of the layers.reply",
      "...of all the possible formats, it outputs.. a powerpoint presentation..? What.reply",
      "Lol, right?!?! I would've expected sequential PNGs followed by SVGs once the model improved.reply",
      "That's what the example code at https://old.reddit.com/r/StableDiffusion/comments/1pqnghp/qw... generates.  You get 0.png, 1.png ... n.png, where n= the requested number of layers-1.It'll drop a 600W RTX 6000 to its knees for about a minute, but it does work.reply",
      "I saw some people at a company called Pruna AI got it down to 8 seconds with Cloudflare/Replicate, but I don't know if it was on consumer hardware or an A100/H100/H200, and I don't know if the inference optimization is open-source yet."
    ],
    "link": "https://huggingface.co/papers/2512.15603",
    "first_paragraph": "Qwen-Image-Layered decomposes images into semantically disentangled RGBA layers using a diffusion model, enabling independent editing of each layer and improving decomposition quality and consistency.Recent visual generative models often struggle with consistency during image editing due to the entangled nature of raster images, where all visual content is fused into a single canvas. In contrast, professional design tools employ layered representations, allowing isolated edits while preserving consistency. Motivated by this, we propose Qwen-Image-Layered, an end-to-end diffusion model that decomposes a single RGB image into multiple semantically disentangled RGBA layers, enabling inherent editability, where each RGBA layer can be independently manipulated without affecting other content. To support variable-length decomposition, we introduce three key components: (1) an RGBA-VAE to unify the latent representations of RGB and RGBA images; (2) a VLD-MMDiT (Variable Layers Decomposition M"
  },
  {
    "title": "Performance Hints (2023) (abseil.io)",
    "points": 48,
    "submitter": "danlark1",
    "submit_time": "2025-12-19T17:14:42 1766164482",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=46328274",
    "comments": [
      "This formatting is more intuitive to me.  L1 cache reference                   2,000,000,000 ops/sec\n  L2 cache reference                   333,333,333 ops/sec\n  Branch mispredict                    200,000,000 ops/sec\n  Mutex lock/unlock (uncontended)      66,666,667 ops/sec\n  Main memory reference                20,000,000 ops/sec\n  Compress 1K bytes with Snappy        1,000,000 ops/sec\n  Read 4KB from SSD                    50,000 ops/sec\n  Round trip within same datacenter    20,000 ops/sec\n  Read 1MB sequentially from memory    15,625 ops/sec\n  Read 1MB over 100 Gbps network       10,000 ops/sec\n  Read 1MB from SSD                    1,000 ops/sec\n  Disk seek                            200 ops/sec\n  Read 1MB sequentially from disk      100 ops/sec\n  Send packet CA->Netherlands->CA      7 ops/secreply",
      "Your version only describes what happens if you do the operations serially, though. For example, a consumer SSD can do a million (or more) operations in a second not 50K, and you can send a lot more than 7 total packets between CA and the Netherlands in a second, but to do either of those you need to take advantage of parallelism.If the reciprocal numbers are more intuitive for you you can still say an L1 cache reference takes 1/2,000,000,000 sec. It's \"ops/sec\" that makes it look like it's a throughput.An interesting thing about the latency numbers is they mostly don't vary with scale, whereas something like the total throughput with your SSD or the Internet depends on the size of your storage or network setups, respectively. And aggregate CPU throughput varies with core count, for example.I do think it's still interesting to think about throughputs (and other things like capacities) of a \"reference deployment\": that can affect architectural things like \"can I do this in RAM?\", \"can I do this on one box?\", \"what optimizations do I need to fix potential bottlenecks in XYZ?\", \"is resource X or Y scarcer?\" and so on. That was kind of done in \"The Datacenter as a Computer\" (https://pages.cs.wisc.edu/~shivaram/cs744-readings/dc-comput... and https://books.google.com/books?id=Td51DwAAQBAJ&pg=PA72#v=one... ) with a machine, rack, and cluster as the units. That diagram is about the storage hierarchy and doesn't mention compute, and a lot has improved since 2018, but an expanded table like that is still seems like an interesting tool for engineering a system.reply",
      "The reason why that formatting is not used is because it\u2019s not useful nor true. The table in the article is far more relevant to the person optimizing things. How many of those I can hypothetically execute per second is a data point for the marketing team. Everyone else is beholden to real world data sets and data reads and fetches that are widely distributed in terms of timing.reply",
      "Your suggestion confuses latency and throughput. So it isn't correct.For example, a modern CPU will be able to execute other instructions while waiting for a cache miss, and will also be able to have multiple cache loads in flight at once (especially for caches shared between cores).Main memory is asynchronous too, so multiple loads might be in flight, per memory channel. Same goes for all the other layers here (multiple SSD transactions in flight at once, multiple network requests, etc)Approximately everything in modern computers is async at the hardware level, often with multiple units handling the execution of the \"thing\". All the way from the network and SSD to the ALUs (arithmetic logic unit) in the CPU.Modern CPUs are pipelined (and have been since the mid to late 90s), so they will be executing one instruction, decoding the next instruction and retiring (writing out the result of) the previous instruction all at once. But real pipelines have way more than the 3 basic stages I just listed. And they can reorder, do things in parallel, etc.reply",
      "I'm aware of this to an extent. Do you know of any list of what degree of parallelization to expect out of various components? I know this whole napkin-math thing is mostly futile and the answer should mostly be \"go test it\", but just curious.I was interviewing recently and was asked about implementing a web crawler and then were discussing bottlenecks (network fetching the pages, writing the content to disk, CPU usage for stuff like parsing the responses) and parallelism, and I wanted to just say \"well, i'd test it to figure out what I was bottlenecked on and then iterate on my solution\".reply",
      "I prefer a different encoding: cycles/opBoth ops/sec and sec/op vary on clock rate, and clock rate varies across machines, and along the execution time of your program.AFAIK, Cycles (a la _rdtsc) is as close as you can get to a stable performance measurement for an operation.  You can compare it on chips with different clock rates and architectures, and derive meaningful insight.  The same cannot be said for op/sec or sec/op.reply",
      "Unfortunately, what you'll find if you dig into this is that cycles/op isn't as meaningful as you might imagine.Most modern CPUs are out of order executors. That means that while a floating point operation might take 4 cycles to complete, if you put a bunch of other instructions around it like adds, divides, and multiplies, those will all finish at roughly the same time.That makes it somewhat hard to reason about exactly how long any given set of operations will be.  A FloatMul could take 4 cycles on it's own, and if you have    FloatMul\n    ADD\n    MUL\n    DIV\n\nThat can also take 4 cycles to finish.  It's simply not as simple as saying \"Let's add up the cycles for these 4 ops to get the total cycle count\".Realistically, what you'll actually be waiting on is cache and main memory.  This fact is so reliable that it underpins SMT.  It's why most modern CPUs will do that in some form.reply",
      "Your critique applies to measuring one or a handful of instructions. \nIn practice you count the number of cycles over million or billion instructions. CPI is very meaningful and it is the main throughput performance metric for CPU core architects.reply",
      "I agree that what you're saying is true, but in the context of my comment, I stand by the statement that cycles/op is still a more meaningful measurement of performance than seconds.---Counter-nitpick .. your statement of \"if you put a bunch of other instructions around it\" assumes there are no data dependencies between instructions.In the example you gave:    FloatMul\n    ADD\n    MUL\n    DIV\n\nSure .. if all of those are operating on independent data sources, they could conceivably retire on the same cycle, but in the context of the article (approximating the performance profile of a series of operations) we're assuming they have data dependencies on one another, and are going to be executed serially.reply",
      "I\u2019ve seen this list many many times and I\u2019m always surprised it doesn\u2019t include registers.reply"
    ],
    "link": "https://abseil.io/fast/hints.html",
    "first_paragraph": "HomeAboutDocsTipsBlogCommunityHomeAboutC++ GuideBlogTipsCommunityJeff Dean,\nSanjay GhemawatOriginal version: 2023/07/27, last updated: 2025/12/16Expand all details\nCollapse all detailsOver the years, we (Jeff & Sanjay) have done a fair bit of diving into\nperformance tuning of various pieces of code, and improving the\nperformance of our software  has been important from the very earliest days of Google, since it\nlets us do more for more users. We wrote this document as a way of identifying\nsome general principles and specific techniques that we use when doing this sort\nof work, and tried to pick illustrative source code changes (change lists, or\nCLs) that provide examples of the various approaches and techniques. Most of the\nconcrete suggestions below reference C++ types and CLs, but the general\nprinciples apply to other languages. The document focuses on general performance\ntuning in the context of a single binary, and does not cover distributed systems\nor machine learning (ML) hardwar"
  },
  {
    "title": "Show HN: TinyPDF \u2013 3kb pdf library (70x smaller than jsPDF) (github.com/lulzx)",
    "points": 108,
    "submitter": "lulzx",
    "submit_time": "2025-12-18T18:59:33 1766084373",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=46316968",
    "comments": [
      "It's definitely far easier to emit a controlled, useful subset of PDF than it is to parse PDF documents. I wrote a small PDF library for the Decker ecosystem that just focuses on bitmaps and page layout; roughly 4kb and 135 LoC.docs/demos: https://beyondloom.com/decker/pdf.htmlbrowsable source: https://github.com/JohnEarnest/Decker/blob/main/examples/dec...reply",
      "Only supports ASCII characters, which is part of the trick here. As soon as you need more Unicode (even just typographic quote characters and such), you\u2019ll need significantly more logic. Also no bold, italics, etc.reply",
      "Back in the day I needed PDF export for some client thing. I can't remember if I was using pdfjs or jspdf. I do however remember that it was many thousands of lines of code, and yet, I had to lay out the lines of text on the page manually.My page layout code was like 50 lines of code. And I remember thinking... OK they already wrote 8,000 lines of code... They couldn't have added 50 more?!400 lines though. Respect. I will take a proper look at this when I recover from burnout :)reply",
      "While not quite as small as 3kb, I recently found this incredible library called html-to-image that's only 300kb. It clones whatever subtree of your document you want to a <foreignObject> inside an svg which then allows it to output canvas, png, svg, pdf, blob, jpeg, etc. Even more impressively is that it handles custom fonts, pseudo-elements, computed styles and more.https://github.com/bubkoo/html-to-imageIt's probably the most impressive and seamless experience I've had with converting HTML to pdfs/images so I just wanted to sing its praises herereply",
      "Great exercize, but for most use cases - people will continue reaching for jsPDF.I think if you have a markdown->PDF function included, where I can send in markdown and get PDF, that would solve quite many needs, and would be useful.reply",
      "I have added it!reply",
      "Wow you\u2019re not kidding. That was fast.https://github.com/Lulzx/tinypdf/commit/961e6b602f19e125f210...reply",
      "HTML -> PDF was also a use case I've used previously FYIreply",
      "So essentially - it only works with Latin script? Because without fonts, every other script is NOT going to render.reply",
      "3KB is wild. What features did you intentionally leave out to get this small?reply"
    ],
    "link": "https://github.com/Lulzx/tinypdf",
    "first_paragraph": ""
  },
  {
    "title": "Rust's Block Pattern (notgull.net)",
    "points": 115,
    "submitter": "zdw",
    "submit_time": "2025-12-19T04:56:13 1766120173",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=46322391",
    "comments": [
      "I have one better: the try block pattern.https://doc.rust-lang.org/beta/unstable-book/language-featur...reply",
      "Can this just be done as a lambda that is immediately evaluated?  It's just much more verbose.    let x = (|| -> Result<i32, std::num::ParseIntError> {\n         Ok(\"1\".parse::<i32>()?\n          + \"2\".parse::<i32>()?\n          + \"3\".parse::<i32>()?)\n    })();reply",
      "I want that stabilized so bad but it's not been really moving forward.reply",
      "There's some active work recently on fixing blocking issues, e.g.:https://github.com/rust-lang/rust/pull/148725https://github.com/rust-lang/rust/pull/149489reply",
      "I was not a fan when I first saw it but I'm becoming desperate to have it the more Rust I write.reply",
      "#![feature(try_blocks)]You only live once.reply",
      "I've tried it recently, from memory error inference wasn't that great through it.reply",
      "One of the first things I tried in Rust a couple of years ago coming from Haskell. Unfortunately it's still not stabilized :(reply",
      "Now that is pretty cool.reply",
      "Why does this need special syntax? Couldn't blocks do this if the expression returns a result in the end?reply"
    ],
    "link": "https://notgull.net/block-pattern/",
    "first_paragraph": "The world's number one source of notgullJohn Nunley  \u00b7  December 18, 2025Here\u2019s a little idiom that I haven\u2019t really seen discussed anywhere, that I think makes Rust code much cleaner and more robust.I don\u2019t know if there\u2019s an actual name for this idiom; I\u2019m calling it the \u201cblock pattern\u201d for lack of a better word. I find\nmyself reaching for it frequently in code, and I think other Rust code could become cleaner if it followed this pattern.\nIf there\u2019s an existing name for this, please let me know!The pattern comes from blocks in Rust being valid expressions. For example, this code:\u2026is equal to this code:\u2026which is, in turn, equal to this code:Let\u2019s say you have a function that loads a configuration file, then sends a few HTTP requests based on that config file.\nIn order to load that config file, first you need to load the raw bytes of that file from the disk. Then you need to parse\nwhatever the format of the configuration file is. For the sake of having a complex enough program to demon"
  },
  {
    "title": "PBS News Hour West to go dark after ASU discontinues contract (statepress.com)",
    "points": 17,
    "submitter": "heavyset_go",
    "submit_time": "2025-12-19T23:59:53 1766188793",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure",
    "first_paragraph": ""
  },
  {
    "title": "Language Immersion, Prison-Style (2017) (themarshallproject.org)",
    "points": 7,
    "submitter": "johnny313",
    "submit_time": "2025-12-14T21:08:44 1765746524",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.themarshallproject.org/2017/12/14/my-do-it-yourself-language-immersion-prison-style",
    "first_paragraph": "\n    Where the culture was Hispanic, \u2018Me llamo Morgan\u2019 got me started.\n  This article was published in collaboration with Vice.I always knew high school Spanish would come in handy one day. I just didn't think that day would come in a federal prison.Fact: I am a white woman in my 20s. Three years of Spanish, one semester in college, and one protracted journey into drug addiction led me to this particular juncture. (I am serving a 60-month sentence for conspiracy to distribute heroin.)Before arriving here at F.C.I. (Federal Correctional Institution) Dublin in Northern California, I already knew its racial composition would be very different from what I was used to in my hometown of Portland, Ore.\u2014which sees itself as a racially and culturally diverse bastion of tolerance but is actually the whitest major city in America. I was prepared to be in the minority for the first time in my life.But I never could have predicted how few Americans I would find in an American prison.Almost as soon "
  },
  {
    "title": "NOAA deploys new generation of AI-driven global weather models (noaa.gov)",
    "points": 84,
    "submitter": "hnburnsy",
    "submit_time": "2025-12-17T22:32:19 1766010739",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=46306497",
    "comments": [
      "These are available on Weatherbell[1] (which requires a subscription) now except for the HGEFS ensemble model which I'm guessing will probably be added later.  AIGFS is on tropical tidbits which should be free for some stuff[5]. I believe some of the research on this is mentioned in these two[2][3] videos from NOAA weather partners site.  They also talk about some of the other advances in weather model research.One of the big benefits of both the single run (AIGFS) and ensemble (AIGEFS) models is the speed and (less) computation time required.  Weather modeling is hard and these models should be used as complementary to deterministic models as they all have their own strengths and weaknesses.  They run at the same 0.25 degree resolution as the ECMWF AIFS models which were introduced earlier this year and have been successful[4].Edit: Spring 2025 forecasting experiment results is available here[6].[1] https://www.weatherbell.com/[2] https://www.youtube.com/watch?v=47HDk2BQMjU[3] https://www.youtube.com/watch?v=DCQBgU0pPME[4] https://www.ecmwf.int/en/forecasts/dataset/aifs-machine-lear...[5] https://www.tropicaltidbits.com/analysis/models/[6] https://repository.library.noaa.gov/view/noaa/71354/noaa_713...reply",
      "Really exciting to see NOAA finally make some progress on this front, but the AIGFS suite likely won't outperform ECMWF's AIFS suite any time soon. The underlying architecture between AIFS and GraphCast/AIGFS is pretty similar (both GNNs), so there won't likely be a model-level improvement. And most of ECMWF's edge lies in its superior 4DVar data assimilation process. AIGFS is still being initialized on NOAA's hybrid 4DEnVar assimilation process as far as I understand it, which is still not as good as straight up 4DVar unfortunately.reply",
      "I've seen the Microsoft Aurora team make a compelling argument that weather is an interesting contradiction of the AI-energy-waste narrative. Once deployed at scale, inference with these models is actually a sizable energy/compute improvement over classical simulation and forecasting methods. Of course it is energy intensive to train the model, but the usage itself is more energy efficient.reply",
      "Obviously much simpler Neural Nets, but we did have some models in my domain whose role was to speed up design evaluation.Eg you want to find a really good design. Designs are fairly easy to generate, but expensive to evaluate and score. Understand we can quickly generate millions of designs but evaluating one can take 100ms-1s. With simulations that are not easy to GPU parallelize. We ended up training models that try to predict said score. They don\u2019t predict things perfectly, but you can be 99% sure that the actual score designs is within a certain distance of said score.So if normally you want to get the 10 best design out of your 1 million, we can now first have the model predict the best 1000 and you can be reasonably certain your top 10 is a subset of these 1000. So you only need to run your simulation on these 1000.reply",
      "And an LLM can be more energy efficient than a human -- and that's precisely when you should use it because that's what technology is for.reply",
      "It's definitely interesting that some neural nets can reduce compute requirements, but that's certainly not making a dent on the LLM part of the pie.reply",
      "Sam Altman has made a lot of grandiose claims about how much power he's going to need to scale LLMs, but the evidence seems to suggest the amount of power required to train and operate LLMs is a lot more modest than he would have you believe. (DeepSeek reportedly being trained for just $5M, for example.)reply",
      "I saw a claim that DeepSeek had piggybacked off of some aspect of training that ChatGPT had done, and so that cost needed to be included when evaluating DeepSeek.This training part of LLMs is still mostly Greek to me, so if anyone could explain that claim as true or false and the reasons why, I\u2019d appreciate itreply",
      "This jumped out at me as well - very interesting that it actually reduces necessary compute in this instancereply",
      "The press statement is full of stuff like this:\"Area for future improvement: developers continue to improve the ensemble\u2019s ability to create a range of forecast outcomes.\"Someone else noted the models are fairly simple.My question is \"what happens if you scale up to attain the same levels of accuracy throughout? Will it still be as efficient?\"My reading is that these models work well in other regions but I reserve a certain skepticism because I think it's healthy in science, and also because I think those ultimately in charge have yet to prove reliable judges of anything scientific.reply"
    ],
    "link": "https://www.noaa.gov/news-release/noaa-deploys-new-generation-of-ai-driven-global-weather-models",
    "first_paragraph": ""
  },
  {
    "title": "The FreeBSD Foundation's Laptop Support and Usability Project (github.com/freebsdfoundation)",
    "points": 134,
    "submitter": "mikece",
    "submit_time": "2025-12-19T14:56:05 1766156165",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=46326519",
    "comments": [
      "So, is there a laptop that has good support for FreeBSD support out of the box?My requirements are: suspend/resume, being able to drive a 5K monitor over USB-C, wifi.I found https://wiki.freebsd.org/Laptops but I don't know how up-to-date it is.reply",
      "We\u2019ve been working with Ed and team at FreeBSD on this, and have a document showing what works currently on Framework Laptops: https://github.com/FrameworkComputer/freebsd-on-frameworkreply",
      "Small correction: the AX211 card in the Framework 12 is able to connect to networks, not just scan. What you're missing is that a bunch of the Wi-Fi firmware blobs were removed from the base system between FreeBSD 14.2 and 14.3, and since 14.3 came out in June 2025 I assume that's what was tested. An upgrade from 14.2 to 14.3 would also have kept working, just not a fresh install of 14.3 or 15.0.A user needs some other working network connection first. I used my Android phone's USB tethering \u2014 all that takes is a quick `dhclient ue0`. Then one can run `fwget` to get the firmware that will make the Wi-Fi work fully: https://man.freebsd.org/cgi/man.cgi?fwget%288%29Source: very happy Framework 12 owner (currently dual-booting Windows 11 Enterprise and FreeBSD 15.0 + Wayland + KDE) :)reply",
      "This is great. I've been checking on it periodically. I'm using the Framework 13 Ryzen AI 300 and the Framework Desktop so not quite there yet. Interested in taking FreeBSD for a spin when the support is there.reply",
      "I mean some of that is even hard to get with Linux tbh especially sleep.reply",
      "I can't speak to it driving a monitor over USB-C as I don't use one, but I'm currently running 15.0-RELEASE on a refurbished Dell Latitude 7280 that has worked flawlessly out of the box so far.Somebody else did a nice writeup [0] on their experience with FBSD on the same laptop.[0] https://adventurist.me/posts/00352reply",
      "FreeBSD status on Apple Silicon, https://wiki.freebsd.org/AppleSiliconreply",
      "The table lists very limited support for M1 and not even lists newer variants! I guess it was only to be expected, asahi Linux also has challenges and of course FreeBSD has less eyeballs than Linuxreply",
      "Linux is pretty much good to go on M1 or even M2 now. No joy on anything newer than that though.reply",
      "(random anecdote) My first and last experience with FreeBSD laptop was trying to use 3.x (!) on a Dell Inspiron 3500 (PII-350 maybe?), no sound modules were precompiled or included or whatever. Took about 3 days for `make world` to finally finish rebuilding... and then sound still not work. Red Hat 6.x \"just worked\" in all regards.reply"
    ],
    "link": "https://github.com/FreeBSDFoundation/proj-laptop",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The FreeBSD Foundation's Laptop Support and Usability Improvements project aims to deliver a package of improved or new FreeBSD functionality that, together, will ensure that it runs well \u201cout of the box\u201d on a broad range of personal computing devices.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Latest UpdatesProject RoadmapWork in ProgressWork DoneExplore scope by area of functionalityLaptop and Desktop Working Group - (community owned)Join the Desktop mailing listFoundation blog about the Laptop ProjectWe have created discussion threads in the Desktop mailing list for key areas of the project:[FF-laptop-LSU] Power Discussion Thread[FF-laptop-LSU] Hardware Discussion Thread[FF-laptop-LSU] Audio Discussion Thread[FF-laptop-LSU] Graphics Discussion Thread"
  },
  {
    "title": "Believe the Checkbook (robertgreiner.com)",
    "points": 117,
    "submitter": "rg81",
    "submit_time": "2025-12-19T15:51:30 1766159490",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=46327133",
    "comments": [
      "> The bottleneck isn\u2019t code production, it is judgment.It always surprises me that this isn't obvious to everyone. If AI wrote 100% of the code that I do at work, I wouldn't get any more work done because writing the code is usually the easy part.reply",
      "I'm retired now, but I spent many hours writing and debugging code during my career. I believed that implementing features was what I was being paid to do. I was proud of fixing difficult bugs.A shift to not writing code (which is apparently sometimes possible now) and managing AI agents instead is a pretty major industry change.reply",
      "Anything you do with AI is improved if you're able to traverse the stack.  There's no situation where knowing how to code won't put you above peers who don't.It's like how every job requires math if you make it far enough.reply",
      "Well you should be surprised by the number of people who do not know this. Klarna is probably the most popular example where the CEO was all about creating more code, then fired everyone before regrettingreply",
      "I think it depends on the sort of work you do. We had some hubspot integration which hadn't been touched for three years break. Probably because someone at hubspot sunset their v1 api a few weeks too early... Our internal AI tool that I've build my own agents on updated our data transfer service to use the v3 api. It also added typing, but kept the rather insane way of delivering the data since... well... since it's worked fine for 3 years. It's still not a great piece of software that runs for us. It's better now than it was yesterday though and it'll now go back to just delivering business value in it's extremely imperfect form.All I had to do was a two line prompt, and accept the pull request. It probably took 10 minutes out of my day, which was mostly the people I was helping explaining what they thought was wrong. I think it might've taken me all day if I had to go through all the code and the documentation and fixed it. It might have taken me a couple of days because I probably would've made it less insane.For other tasks, like when I'm working on embedded software using AI would slow me down significantly. Except when the specifications are in German.reply",
      "At my company doubling the writing-code part of software projects might speed them up 5%. I think even that\u2019s optimistic.Imperfectly fixing obvious problems in our processes could gain us 20%, easy.Which one are we focusing on? AI. Duh.reply",
      "Lots of people have good judgement but don't know the arcane spells to cast to get a computer to do what they want.reply",
      "I'll stare at a blank editor for an hour with three different solutions in my head that I could implement, and type nothing until a good enough one comes to mind that will save/avoid time and trouble down the road. That last solution is not best for any simple reason like algorithmic complexity or anything that can be scraped from web sites.reply",
      "No shade on your skills, but for most problems, this is already false; the solutions have already been scraped.All OSS has been ingested, and all the discussion in forum like this about it, and the personal blog posts and newsletters about it; and the bug tracking; and theh pull requests, and...and training etc. is only going to get better and filtering out what is \"best.\"reply",
      "A vast majority of the problems I\u2019m asked to solve at work do not have open-source code I can simply copy or discussion forums that already decided the best answer. Enterprise customers rarely put that stuff out there. Even if they did, it doesn\u2019t account for the environment the solution sit in, possible future integrations, off-the-wall requests from the boss, or knowing that internal customer X is going to want some other wacky thing, so we need to make life easy on our future selves.At best, what I find online are basic day 1 tutorials and proof on concept stuff. None of it could be used in production where we actually need to handle errors and possible failure situations.reply"
    ],
    "link": "https://robertgreiner.com/believe-the-checkbook/",
    "first_paragraph": "AI companies talk as if engineering is over. Their acquisitions say the opposite.Anthropic\u2019s AI agent was the most prolific code contributor to Bun\u2019s GitHub repository, submitting more merged pull requests than any human developer. Then Anthropic paid millions to acquire the human team anyway. The code was MIT-licensed; they could have forked it for free. Instead, they bought the people.Everyone\u2019s heard the line: \u201cAI will write all the code; engineering as you know it is finished.\u201dBoards repeat it. CFOs love it. Some CTOs quietly use it to justify hiring freezes and stalled promotion paths.The Bun acquisition blows a hole in that story.Here\u2019s a team whose project was open source, whose most active contributor was an AI agent, whose code Anthropic legally could have copied overnight. No negotiations. No equity. No retention packages.Anthropic still fought competitors for the right to buy that group.Publicly, AI companies talk like engineering is being automated away. Privately, they dep"
  },
  {
    "title": "The pitfalls of partitioning Postgres yourself (hatchet.run)",
    "points": 46,
    "submitter": "abelanger",
    "submit_time": "2025-12-16T18:21:21 1765909281",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=46292148",
    "comments": [
      "Ha, what a coincidence. Just today I was reading a three year old Stackoverflow discussion about this [1].It prompted Laurenz to submit the documentation patch that is cited in the article. In the discussion of the patch itself, people seem to conclude that it's a good improvement to the docs, but that the behaviour itself is a bit of a footgun. [2][1]: https://stackoverflow.com/questions/73951604/autovacuum-and-...[2]: https://www.postgresql.org/message-id/Y8cQJIMFAe7QT73/%40mom...reply",
      "I mentioned this towards the bottom of the post, but to reiterate: we're extremely grateful to Laurenz for helping us out here, and his post on this is more than worth checking out: https://www.cybertec-postgresql.com/en/partitioned-table-sta...(plus an interesting discussion in the comments of that post on how the query planner chose a certain row estimate in the specific case that Laurenz shared!)The other thing I'll add is that we still haven't figured out:1. An optimal ANALYZE schedule here on parent partitions; we're opting to over-analyze than under-analyze at the moment, because it seems like our query distribution might change quite often.2. Whether double-partitioned tables (we have some tables partitioned by time series first, and an enum value second) need analyze on the intermediate tables, or whether the top-level parent and bottom-level child tables are enough. So far just the top-level and leaf tables seem good enough.reply",
      "I'd consider myself pretty familiar with postgres partitioning, and even worked with systems that emulated partitioning through complex dynamic SQL through stored procs before it was supported natively.But TIL, I didn't realize you could do multiple levels of partitioning in modern postgres, found this old blog post that touches on it https://joaodlf.com/postgresql-10-partitions-of-partitions.h...Something that stresses me is the number of partitions - we have some weekly partitions that have a long retention period, and whilst it hasn't become a problem yet, it feels like a ticking time bomb as the years go on.Would a multi level partitioning scheme of say year -> week be a feasible way to side step the issues of growing partition counts?reply",
      "They didn\u2019t say why they didn\u2019t use the built-in partitioning system.reply",
      "They are using the built-in partitioning. They just ran into one of the \"you gotta know this\" pitfalls.reply"
    ],
    "link": "https://hatchet.run/blog/postgres-partitioning",
    "first_paragraph": "(not a hatchet job on Postgres partitioning - we do actually like it)If you dive deep into Hatchet's codebase these days, you might get the impression that we don't know what we're doing. In particular, for a seasoned Postgres user, this method might stand out to you:This method goes through a handful of our Postgres tables and runs ANALYZE <table_name>; , seemingly at random.Yes, we do have autovacuum enabled on our databases (and we expect users who are self-hosting to have it enabled as well), which means that tables are autoanalyzed after they get autovacuumed. Why are we manually running analyze on our tables all the time?While there are a bunch of ways in which we don't know what we're doing, this particular bit of code comes from a hard-won set of production incidents, and some nuances of Postgres's autoanalyze implementation.For some background, Hatchet is a durable queue, built on top of Postgres, which offers useful features for running complex background jobs, like workflows"
  }
]