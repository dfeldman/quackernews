[
  {
    "title": "CARA \u2013 High precision robot dog using rope (aaedmusa.com)",
    "points": 381,
    "submitter": "hakonjdjohnsen",
    "submit_time": "2025-07-23T17:38:20 1753292300",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=44661846",
    "comments": [
      "I've watched and re-watched Aaed's videos on the capstan drive, it's great stuff. High speed, high torque, compliance, effectively no backlash. It's fascinating to watch a legit engineering mind at work.reply",
      "I recently found his videos also.  It's one of those things that gets my mind bubbling with ideas for things I want to make, never enough time to do them all though (and this breadboard beside me is asking for attention)It does make me wonder about the algorithm,   Quite a lot of things I find on Youtube turn up on HN a week or two later.  I'm not sure if this is an indicator of the effectiveness or failure of the algorithm.  It is definitely succeeding in finding videos popular with some people and showing it to more who might share that interest.   The question is, are the things I (and consequently many others of similar interests) see the best of all there is, or a subset of the excellent videos out there that happen to get noticed.I sometimes find channels that are years old with a goldmine of good information. That suggests that there is more good stuff out there than what I see.  Were they just unlucky that I didn't see them before?  Am I lucky to be seeing them now?  It also might be that it is not luck but the algorithm has arbitrarily decided that the video has some special factor that requires promotion or that I have passed some arbitrary threshold of perceived character development that makes me supposedly now interested in such things.reply",
      "\"back in the day\", we used capstans to drive film (movie) rolls around the scanning aparatus. Both high speed and precise without backlash. Great stuff. Somehow I always thought maybe lack of high torque is the issue more people aren't using them or wear and tear.. but, apparently not?reply",
      "He's easily one of my favorite content creators. Ofc, there are much better engineers, domain experts or more entertaining people on youtube, but he strikes a very enjoyable balance.I wanted to start writing a list of other tech related, pop-sci and industrial-design Youtubers I kinda enjoy, but noticed just how many channels I'm subscribed to... If there's any interest, I'll drop it, just tell me. Meanwhile I have some filtering and sorting to do.reply",
      "I am interested. I love these builder channels.reply",
      "I haven't watched the one about the dog, but the one with the initial explication of capstan drives [0] was excellent. I've been dreaming about it for the last year, especially since about the same time another person started working with the da Vinci robot actuators which use cables to generate find motion.0. High Precision Speed Reducer Using Rope: https://www.youtube.com/watch?v=MwIBTbumd1Q1. Building a DIY Surgical Robot\n https://www.youtube.com/watch?v=d_8rHKrwr-Qreply",
      "I watched this last week and my jaw was on the floor. He's both a great technician, and he has the personality to make it interesting. He walked through his testing strategy far enough that you could understand his methodology and the thought process behind it, but didn't belabor it by making us watch it all. Banger!reply",
      "Amazing presentation! - somebody hire this kid asaphttps://www.aaedmusa.com/reply",
      "I'm going to tell my 12 year old that when he leaves education he wants something like this on his personal web site:\"CARA (Capstans Are Really Awesome) is my latest quadrupedal robot, following ZEUS, ARES, and TOPS. Built over the course of a year, CARA is easily my most dynamic and well-designed quadruped yet.\"reply",
      "That would be a terrible path for someone with this extreme level of demonstrated talent, motivation, and follow-through.Much better for someone to fund a startup run by him.reply"
    ],
    "link": "https://www.aaedmusa.com/projects/cara",
    "first_paragraph": "CARA (Capstans Are Really Awesome) is my latest quadrupedal robot, following ZEUS, ARES, and TOPS. Built over the course of a year, CARA is easily my most dynamic and well-designed quadruped yet. Unlike most quadrupeds, CARA doesn\u2019t use any gears or pulleys. Instead, her joints are driven by rope through capstan drives. CARA is also the second quadruped ever to use capstan drives, following Stanley. If you\u2019re unfamiliar with how capstan drives work, I\u2019ve made a 20-minute video \u2014 High Precision Speed Reducer Using Rope \u2014 that explains everything you need to know. CARA builds directly on what I covered in that video. Capstan drives offer several advantages: zero backlash, high torque transparency, low inertia, low cost, and quiet operation. These qualities make them an ideal speed reducer for robotics. The starting point of this project was figuring out how to achieve an exact 8:1 gear ratio with the capstan drives. In my capstan drive video, I designed all the drives to have an 8:1 gear"
  },
  {
    "title": "I drank every cocktail (aaronson.org)",
    "points": 104,
    "submitter": "colinprince",
    "submit_time": "2025-07-23T23:56:25 1753314985",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=44665373",
    "comments": [
      "For those that are getting into cocktails, by far the best piece of advice I can give is: know when the quality of ingredients matter and when they don\u2019t. If it\u2019s a very sugary/salty drink, or people are smoking, or already drunk, most people won\u2019t care, but for a lot of cocktails the ingredients make a massive difference. The best bang for your buck is Carpano Antica, a sweet vermouth with real complexity to it; the worst value is high end vodka.reply",
      "> worst value is high end vodka.For mixing, definitely.   If you're drinking it straight, the subtle complexity of a good vodka is nice.reply",
      "Do you have a ranked list of items that pay off to spend a bit more versus doesn\u2019t matter?reply",
      "> First semester that year, I took a Beverage Management class, which was ostensibly about managing bars, but it was no secret that everyone took it because of its tasting component.Is this breadth of topics common for the American higher educational system or did the author go to a special university?reply",
      "At the very largest universities there is a really really wide variety of programs and courses.  For example here's a course catalog where a search for 'intro' returns 3500 different courses. \nhttps://classes.osu.edu/#/?q=intro&client=class-search-ui&ca...\nYou can see the variety, from \"Introduction to the Army and Critical Thinking\" to \"Introductory Meat Science\"This breadth is typical of the very largest universities in the U.S.reply",
      "The University of Illinois at Urbana-Champaign is something of a \"special\" university...reply",
      "If you wanna run thru this list and get a tally, I quickly created this lovable app: https://cocktail-checkered-log.lovable.app/. I'm at 68/102!reply",
      "Does this maintain state if navigate away ?reply",
      "Yes, the site seems to save the checked cocktails into Local Storage (you can click some, and in your browser's inspection tools you can check. Eg. in Firefox > Inspect > Storage > Local Storage, there's a key with \"cocktail-tracker\").I've checked and closing/reopening works (of course locally only, no incognito tabs, etc...)reply",
      "Such a fun and entertaining read. I'd never suggest someone give up a software career to become a food writer, but I'd love to read more of OP's writing as he pursues these goals.reply"
    ],
    "link": "https://aaronson.org/blog/i-drank-every-cocktail",
    "first_paragraph": "\n\u2190 Back to Blog\nThe International Bartenders Association, or IBA, maintains a list of official cocktails, ones they deem to be \u201cthe most requested recipes\u201d at bars all around the world. It\u2019s the closest thing the bartending industry has to a canonical list of cocktails, akin to the American Kennel Club\u2019s registry of dog breeds or a jazz musician\u2019s Real Book of standards.The IBA official cocktail list is the kind of list that has its own Sporcle quiz and its own Wikipedia article\u2014an \u201cIBA official cocktail\u201d label even christens the top of each cocktail\u2019s own Wikipedia infobox:As of 2025, there are 102 IBA official cocktails, and as of July 12, 2025, I\u2019ve had every one of them.The journey has taken me to some interesting places, and now that it\u2019s done, I have a little story to tell for each cocktail. I\u2019m not gonna tell you all 102 stories, but I do want to debrief the experience. Drinking all 102 cocktails turned out to be unexpectedly tricky, and for reasons you\u2019ll soon understand, I mig"
  },
  {
    "title": "BGP Tools (bgp.tools)",
    "points": 6,
    "submitter": "RGBCube",
    "submit_time": "2025-07-24T01:12:14 1753319534",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44665815",
    "comments": [
      "This tool looks really good.  It seems like soon ASN level bot-curbing will become common.reply",
      "Pretty zany.reply"
    ],
    "link": "https://bgp.tools/",
    "first_paragraph": ""
  },
  {
    "title": "The Promised LAN (tpl.house)",
    "points": 238,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-23T17:24:32 1753291472",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=44661682",
    "comments": [
      "Heh, of all arguably-valid definitions of \"LAN Party\" I think this one is as far away from mine as you can get.Traditional LAN party: Everyone brings their computers to one place to connect via a LAN, where they play games, swap files, demo stuff to each other, etc.My LAN party: All my friends come over to my house and use the computers that I have already set up for them. Nobody brings their own. The point is to interact face-to-face, with video games as a catalyst. Swapping files and demos doesn't really happen since nobody brought their own computer. (My house: https://lanparty.house)The Promised LAN Party: The LAN is extended, virtually, across multiple houses, so that the participants can play games, swap files, and demo stuff without actually leaving home. It's arguably no longer \"local\" but functionally it enables the same activities as a LAN party, other than the face-to-face interaction part.I wonder who gets told their definition is \"wrong\" more. :)reply",
      "This is a pretty amazing setup!  I think in 2025 I would definitely prefer something like this.  However, I think back in \"the day\" part of what made LAN parties fun was that everyone's PC was so individualized.  I remember all of my high school friends and I coming of age and building our PCs.  I helped a lot of my friends build their PCs and we all chose different things (such as the amount of RGB LEDs, which I thought were tacky...).  I remember a friend of a friend had a water cooling system and I was so excited about checking it out.  Also, things like the desktop wallpaper you chose, etc, contributed to this.  There was something very magical about it all.  Lugging our PCs to each others houses was a real labor of love.reply",
      "And a real risk of a shattered CRT screen! I remember carting my bougie 17\u201d Viewsonic around in the back of my Hyundai Excel and wondering if it would pick up a crack along the voyage\u2026reply",
      "4K LCD displays can be delicate as well and prone to cracking. I always worry when I am moving one.reply",
      "Back in the hayday of lan parties in like 1995-1997 my only monitor was a absolute boulder of a 21\" viewsonic (this is pre flatscreen or rather pre decent flatscreens, you could get like 15-17s but they were expensive and absolute trash). One night coming home from the bars, half drunk, in an alley my friend and I found an abandoned (maybe..) horizontal-able handtruck. Made the lan party load unload so much better.reply",
      "The Promised LAN is a bit of a WAN party, but I would say that \"LAN party\" can certainly be assumed to include virtual LANs.I'm even willing to say that a get-together of friends in the same location playing the same online game (perhaps using laptops / handhelds / tablets / smartphones / etc.) still fits the spirit of the LAN party, even though it might technically be over a WAN. (Former LAN game series like Diablo have evolved in this direction, for better or worse, and MMOs were always in this space. It's still a blast to play them with people in the same room.)The best LAN party is the one that you are part of.reply",
      "That website was a very fun read :) what a cool place and so awesome to have so many friends to play with.This line made me chuckle:> I suggested to Jade: Should we move to Austin? Jade initially said no, because she wanted our kids to benefit from Palo Alto's school district. At the time, it was rated #12 in the nation. But, looking closer at the rankings revealed a surprise: The Eanes school district in Austin was #8. When I showed this to Jade, she changed her mind.Could tell your wife was Chinese without even seeing the name. Chinese parents will made radical housing decisions for their children, even just to move from #12 to #8, lol. Love this.reply",
      "Big fan of both your LAN houses! One thing I noticed is that you don't seem to have any art/pictures/decorations on any of your walls. Is that an intentional choice?reply",
      "At the time the pictures were taken, we hadn't gotten around to populating the walls much. Now we've hung up a lot of our kids' art, nicely framed. Amusingly a lot of it looks sort of like abstract modern art, like Jackson Pollock or Rothko, enough so to confuse guests. :)reply",
      "Abstract modern art seems to have some things in common with some kids' art: focus on materials, color, texture, perception; and representational art may focus on symbolism rather than realistic rendering. There's also an authenticity to art that is created for personal expression without worrying what other people will think about it.It's hard to capture three dimensional physical art in two dimensions and/or digitallly, even more so when the art is abstract. The context and interaction with the physical environment can also be important.reply"
    ],
    "link": "https://tpl.house/",
    "first_paragraph": "\nThe Promised LAN is a closed, membership only network of friends that operate\na 24/7 always-on LAN party, running since 2021. The vast majority of\ndocumentation is maintained on the LAN, but this website serves to give\ninterested folks, prospective members or friends an idea of what the Promised\nLAN is, and how it works.\n      \nFor background on why we started the lan, what we hope to achieve, and how we\napproach the social-technical dynamics, we have\nposted a Manifesto to encourage more\nsimilarly structured LANs. It is worth reading this before moving on.\nThe social and technical aspects are intertwined here.\n      \nEach Promised LAN segment connects to the Backbone network, since each LAN\nconnecting to every other LAN quickly becomes unmaintainable, even with a small\nnumber of segments -- individual dynamic IPs change, keying material exchanges,\nnegotiating a cipher suite; it gets hard! As a result, we have all LANs connect\nto the closest backbone node, and traffic is routed through"
  },
  {
    "title": "Parsing Protobuf like never before (mcyoung.xyz)",
    "points": 147,
    "submitter": "ibobev",
    "submit_time": "2025-07-17T10:09:48 1752746988",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=44591605",
    "comments": [
      "There are two ways to look at this.First is that, if the parsing library for your codec includes a compiler, VM, and PGO, your codec must be extremely cursed and you should take a step back and think about your life.Second is that, if the parsing library for your codec includes a compiler, VM, and PGO, your codec must be wildly popular and adds enormous value.reply",
      "If you want to do something several hundreds of billions of times per day, you probably want to do it very efficiently.reply",
      "> In other words, a UPB parser is actually configuration for an interpreter VM, which executes Protobuf messages as its bytecode.This is kind of confusing, the VM is runtime crafted to parse a single protobuf message type and only this message type? The Second Futamura Projection, I suppose...Or the VM is designed specifically around generic protobuf messages and it can parse any random message but only if it's a protobuf message?I've been working on the design of a similar system but for general binary parsing (think bison/yacc for binary data) and hadn't even considered doing data over specialized VM vs. bytecode+data over general VM. Honestly, since it's designed around 'maximum laziness' (it just parses/verifies and creates metadata over the input so you only pay for decoding bytes you actually use) and I/O overhead is way greater than the VM dispatching trying this out is probably one of those \"premature optimization is the root of all evil\" cases but intriguing none the less.reply",
      "I think I can shed some light on this, as the creator and lead of upb.Calling a Protobuf Parser an \"interpreter VM\" is a little bit of rhetorical flourish.  It comes from the observation that there are some deep structural similarities between the two, which I first observed in an article a few years back: https://blog.reverberate.org/2021/04/21/musttail-efficient-i...> It may seem odd to compare interpreter loops to protobuf parsers, but the nature of the protobuf wire format makes them more similar than you might expect. The protobuf wire format is a series of tag/value pairs, where the tag contains a field number and wire type. This tag acts similarly to an interpreter opcode: it tells us what operation we need to perform to parse this field\u2019s data. Like interpreter opcodes, protobuf field numbers can come in any order, so we have to be prepared to dispatch to any part of the code at any time.This means that the overall structure of a protobuf parser is conceptually a while() loop surrounding a switch() statement, just like a VM interpreter.The tricky part is that the set of \"case\" labels for a Protobuf parser is message-specific and defined by the fields in the schema.  How do we accommodate that?The traditional answer was to generate a function per message and use the schema's field numbers as the case labels.  You can see an example of that here (in C++): https://github.com/protocolbuffers/protobuf/blob/f763a2a8608...More recently, we've moved towards making Protobuf parsing more data-driven, where each field's schema is compiled into data that is passed as an argument to a generic Protobuf parser function.  We call this \"table-driven parsing\", and from my read of the blog article, I believe this is what Miguel is doing with hyperpb.The trick then becomes how to make this table-driven dispatch as fast as possible, to simulate what the switch() statement would have done.  That question is what I cover at length in the article mentioned above.reply",
      "Really great. I wonder, for the \"types encoded as code\" approach, is there any benefit to fast paths for data with fields in ascending order? For some json parsers with types encoded as code I have observed some speedup from either hard-coding a known key order or assuming keys in some order and providing a fallback in case an unexpected key is encountered. For users who are stuck with protobuf forever because of various services using it and various data being encoded this way, the historical data could plausibly be canonicalized and written back in large chunks when it is accessed, so that one need not pay the entire cost of canonicalizing it all at once. But of course the icache concerns are still just as bad.reply",
      "This kind of \"expected next field\" optimization has a long history in protobuf, but results are mixed.The generated code in C++ used to check for the expected next field before falling back to the switch() (example here: https://github.com/protocolbuffers/protobuf/blob/460e7dd7c47...) but this was removed in 2016 when load tests found that it hurt more than it helped.One tricky part of making this optimization work is making a good guess about what the next field should be.  Miguel's article alludes to this:> Each field specifies which fields to try next. This allows the compiler to perform field scheduling, by carefully deciding which order to try fields in based both on their declaration order and a rough estimation of their \u201chotness\u201d, much like branch scheduling happens in a program compiler. This avoids almost all of the work of looking up the next field in the common case, because we have already pre-loaded the correct guess.> I haven\u2019t managed to nail down a good algorithm for this yet, but I am working on a system for implementing a type of \u201cbranch prediction\u201d for PGO, that tries to provide better predictions for the next fields to try based on what has been seen before.One delightful thing about the tail-call parser design is that the CPU's branch predictor effectively takes over the job of guessing.  With a tail call parser, the dispatch sequence ends up looking like this:    cmp    QWORD PTR [rdi+0x8],rsi               # Bounds check\n    jbe    .fallback\n    movzx  r10d,WORD PTR [rsi]                   # Load two bytes of tag\n    mov    eax,r10d\n    and    eax,0xf8\n    mov    r9,QWORD PTR [rcx+rax*2]              # Load table data\n    xor    r9,r10\n    mov    rax,QWORD PTR [rcx+rax*2+0x8]         # Load field parser function\n    jmp    rax                                   # Tail call to field parser\n\nThat \"jmp rax\" instruction is an indirect branch that can be predicted by the CPU.  The CPU effectively guesses for us!And unlike any kind of guess we might have performed ahead-of-time, the branch predictor will constantly adapt to whatever patterns it is seeing in the data.  This is good, because statically guessing ahead-of-time is hard.reply",
      "> This kind of \"expected next field\" optimization has a long history in protobufYou could probably even trace the history of the idea all the way to Van Jacobson\u2019s 30-instruction TCP fastpath[1]. Or to go a bit closer, I\u2019ve found that an interpreter for a stack+accumulator VM (which, compared to the pure stack option, is prone to blowing up the bytecode count and thus dispatch cost with the constant PUSH-accumulator instructions) goes significantly faster if you change the (non-shared) dispatch from  return impl[*pc](pc, ...);\n\nto  if (*pc == PUSH) {\n      do_push(...); pc++;\n  }\n  return impl[*pc](pc, ...);\n\nwhich feels somewhat analogous to the next-field optimization and avoids polluting the indirect branch predictor with the very common PUSH predictions. (It\u2019s still slower than not having those PUSHes in the first place.)[1] https://www.pdl.cmu.edu/mailinglists/ips/mail/msg00133.htmlreply",
      "> More recently, we've moved towards making Protobuf parsing more data-driven, where each field's schema is compiled into data that is passed as an argument to a generic Protobuf parser function. We call this \"table-driven parsing\", and from my read of the blog article, I believe this is what Miguel is doing with hyperpb.Everything old is new again, I guess\u2014one of the more advertised changes in Microsoft COM as it was maturing (circa 1995) was that you could use data-driven marshalling with \u201cNDR format strings\u201d (bytecode, essentially[1,2]) instead of generating C code. Shortly after there was typelib marshalling (format-compatible but limited), and much later also WinRT\u2019s metadata-driven marshalling (widely advertised but basically completely undocumented).Fabrice Bellard\u2019s nonfree ASN.1 compiler[3] is also notable for converting schemas into data rather than code, unlike most of its open-source alternatives.I still can\u2019t help wondering what it is, really, that makes the bytecode-VM approach advantageous. In 1995, the answer seems simple : the inevitable binary bloat was unacceptable for a system that needs to fit into single-digit megabytes of RAM; and of course bytecode as a way to reduce code footprint has plenty of prior art (microcomputer BASICs, SWEET16, Forth, P-code, even as far back as the AGC).Nowadays, the answer doesn\u2019t seem as straightforward. Sure, the footprint is enormous if you\u2019re Google, but you\u2019re not Google (you\u2019re probably not even Cloudflare), and besides, I hope you\u2019re not Google and can design stuff that\u2019s actually properly adapted to static linking. Sure, the I$ pressure is significant (thinking back to Mike Pall\u2019s explanation on why he didn\u2019t find a baseline JIT to be useful), but the bytecode interpreter isn\u2019t going to be a speed demon either.I don\u2019t get it. I can believe it\u2019s true, but I don\u2019t really feel that I get it.[1] https://learn.microsoft.com/en-us/windows/win32/rpc/rpc-ndr-...[2] https://gary-nebbett.blogspot.com/2020/04/rpc-ndr-engine-dce...[3] https://bellard.org/ffasn1/reply",
      "Based on what I know about the structure of protobufs internally and without having looked deep into what UPB is doing... I'd guess it could probably be a stack machine that treats (byte)+ as opcodes. Most of the time I'd think of it as parser -> AST -> bytecode, but I think the \"grammar\" of protobufs would allow your parser to essentially emit terminals as they're parsed straight to the VM as instructions to execute.reply",
      "In the couple days since I posted my confusion (threads merged or something) I consulted the daffy robots and figured out how it all works. Also had them come up with a design document for \"a specialized compiler and virtual machine architecture for parsing Protocol Buffer messages that achieves significant performance improvements through a novel compilation pipeline combining protobuf-specific AST optimization, continuation-passing style transformations, and tail call interpreter execution.\"Interesting times we live in...reply"
    ],
    "link": "https://mcyoung.xyz/2025/07/16/hyperpb/",
    "first_paragraph": "Historically I have worked on many projects related to high-performance Protobuf, be that on the C++ runtime, on the Rust runtime, or on integrating UPB, the fastest Protobuf runtime, written by my colleague Josh Haberman. I generally don\u2019t post directly about my current job, but my most recent toy-turned-product is something I\u2019m very excited to write about: hyperpb.Here\u2019s how we measure up against other Go Protobuf parsers. This is a subset of my benchmarks, since the benchmark suite contains many dozens of specimens. This was recorded on an AMD Zen 4 machine.Throughput for various configurations of hyperpb (colored bars) vs. competing parsers (grey bars). Each successive hyperpb includes all previous optimizations, corresponding to zerocopy mode, arena reuse, and profile-guided optimization. Bigger is better.Traditionally, Protobuf backends would generate parsers by generating source code specialized to each type. Naively, this would give the best performance, because everything woul"
  },
  {
    "title": "Neil Armstrong's customs form for moon rocks (2016) (uc.edu)",
    "points": 241,
    "submitter": "ajuhasz",
    "submit_time": "2025-07-23T15:37:40 1753285060",
    "num_comments": 165,
    "comments_url": "https://news.ycombinator.com/item?id=44660437",
    "comments": [
      "These things were mainly publicity stunts. The supposed biohazard quarantine for returning Apollo astronauts was a theater performance, too.https://www.livescience.com/space/the-moon/the-apollo-moon-l... (\"The Apollo moon landing was real, but NASA's quarantine procedure was not\")https://www.nytimes.com/2023/06/09/science/nasa-moon-quarant... (\"A review of archives suggests that efforts to protect Earth from contamination by any organism brought back from the lunar surface were mostly for show\")reply",
      "My father was one of the scientific Principal Investigators (PIs) who analyzed the Apollo 11 lunar samples, back in 1969. Flipping through some of his notes from back then, it sounds as if a rotating assortment of bureaucrats injected themselves into the chain-of-custody with weird and embarrassing effects. To wit:Some Agriculture Department folks decided that their legal authority to quarantine soil samples brought into the U.S. applied to lunar soils, too. They insisted on building a three-week quarantine facility with slivers of lunar samples, exposed to \"germ-free mice born by cesarean section.\" Only after the mice survived this ordeal was it safe to release the fuller batch of samples.Another character insisted that the aluminum rock boxes be sealed, while on the moon, with gaskets of indium (soft, rare metal) which would deform to create a very tight seal. The geochemists on earth protested, in vain, that this procedure would ruin their hopes of doing any indium analysis of the samples themselves, shutting down an interesting line of research. No luck in changing the protocol. Turns out that the indium seals didn't work, and the rock boxes reached the earth-based quarantine facilities with normal air pressure anyway.There's more silliness about trying to keep the lunar samples in a hard vacuum while designing rigidly mounted gloves that could be used to manipulate/slice/divide the samples without breaking the vacuum. Maybe we know today how to sustain flexible gloves in such an environment. We didn't, back then.reply",
      "> They insisted on building a three-week quarantine facility with slivers of lunar samplesThere was a ton of money flowing in for space and it was the big new thing of the future. Makes sense other agencies would try to insert themselves and try to seem relevant to the new popular thing in the news and latch themselves onto any future spending/authority.reply",
      "Yep, government bureaucracy has always been horribly corrupt, incompetent, and self-serving, unfortunately.reply",
      "The actual claims of the paper are not that this was 'for show', but that NASA considered the risks unlikely and prioritized the more likely risks to the astronauts lives. I see how the authors got to 'so it was all for show', but it simply isn't true.There is plenty of evidence that the risk was taken seriously (regulations and treaties surrounding the issue, ICBC activities in the years prior to launch, the expense on things the public would never have known about, medical and biological testing done for the first three missions, NASA's openness with the ICBC about the imperfection of the system and the existence of contingency plans...).reply",
      "On one of the Apollo documentaries (I can't remember which one), the astronauts joked that it was the least effective quarantine ever; they talked about how there was a stream of ants going in and out of the Airstream they were in.reply",
      "They quarantined in an Airstream van? That's hilarious. Very 1960sFound the wiki https://en.wikipedia.org/wiki/Mobile_quarantine_facilityreply",
      "You can go look at one up close at the Udvar-Hazy Center in VA. I highly recommend a visit there if you are in the area and interested in aerospace stuff. They've got a ton of amazing exhibits.reply",
      "A stream of ants would not necessarily render a quarintine ineffective.reply",
      "If you're protecting against the possibility of an unknown hypothetical pathogen that can survive on the moon, but which you have no specific reason to think favours or disfavours any randomly selected Earth life, you want something that can at the very least stop ants.reply"
    ],
    "link": "https://magazine.uc.edu/editors_picks/recent_features/armstrong/moonrocks.html",
    "first_paragraph": "If you have ever traveled overseas, then returned to the U.S., you likely filled out a \u201ccustoms declaration\u201d form on the airplane:\n\u201cAre you bringing with you: plants, food, animals, soil, disease agents, cell cultures or snails? Declare all articles that you have acquired and are bringing into the United States.\u201d\nWho would have guessed the regulations would have been enforced so rigorously in 1969 when three men returned to the U.S. from a rather long business trip \u2013 to the moon and back. After more than 477,000 miles roundtrip, they had to file and sign a \u201cGeneral Declaration\u201d for the items they acquired on the trip \u2014 specifically, \u201cmoon rock and moon dust samples.\u201d\nThe flight number was typed in as \u201cApollo 11,\u201d and the departure point was listed as \u201cMoon\u201d with arrival at Honolulu, Hawaii, U.S.A.\nThe Declaration of Health section, asks travelers to list: \"Any other condition on board which may lead to the spread of disease.\u201d The answer was \u201cTo be determined.\u201d\n(First-man-on-the-moon an"
  },
  {
    "title": "AI overviews cause massive drop in search clicks (arstechnica.com)",
    "points": 78,
    "submitter": "jonbaer",
    "submit_time": "2025-07-23T19:50:12 1753300212",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=44663227",
    "comments": [
      "Conversely, it's useful to get an immediate answer sometimes6 months ago, \"what temp is pork safe at?\" was a few clicks, long SEO optimised blog post answers and usually all in F not C ... despite Google knowing location ... I used it as an example at the time of 'how hard can this be?'First sentance of Google AI response right now: \"Pork is safe to eat when cooked to an internal temperature of 145\u00b0F (63\u00b0C)\"reply",
      "Google's search rankings are also the thing driving those ridiculous articles to the top, which is the only reason so many of them get written...reply",
      "Not only that, it includes a link to the USDA reference so you can verify it yourself. I have switched back to google because of how useful I find the RAG overviews.reply",
      "The link is the only useful part, since you can\u2019t trust the summary.Maybe they could just show the links that match your query and skip the overview. Sounds like a billion-dollar startup idea, wonder why nobody\u2019s done it.reply",
      "Safe Temperatures for PorkPeople have been eating pork for over 40,000 years. There\u2019s speculation about whether pork or beef was first a part of the human diet.(5000 words later)The USDA recommends cooking pork to at least 145 degrees.reply",
      "It\u2019s only useful if you can trust it, and you very much cannot.I know you can\u2019t necessarily trust anything online, but when the first hit is from the National Pork Board, I\u2019m confident the answer is good.reply",
      "The overviews are also wrong and difficult to get fixed.Google AI has been listing incorrect internal extensions causing departments to field calls for people trying to reach unrelated divisions and services, listing times and dates of events that don't exist at our addresses that people are showing up to, and generally misdirecting and misguiding people who really need correct information from a truth source like our websites.We have to track each and every one of these problems down, investigate and evaluate whether we can reproduce them, give them a \"thumbs down\" to then be able to submit \"feedback\", with no assurance it will be fixed in a timely manner and no obvious way to opt ourselves out of it entirely. For something beyond our consent and control.It's worse than when Google and Yelp would create unofficial business profiles on your behalf and then held them hostage until you registered with their services to change them.reply",
      "I particularly hate when the AI overview is directly contradicted by the first few search results.reply",
      "Fun. I have people asking ChatGPT support question about my SaaS app, getting made up answers, and then cancelling because we can\u2019t do something that we can. Can\u2019t make this crap up. How do I teach Chat GPT every feature of a random SaaS app?reply",
      "I was at an event where someone was arguing there wasn't an entry fee because chatgpt said it was free (with a screenshot of proof) then asked why they weren't honoring their online price.reply"
    ],
    "link": "https://arstechnica.com/ai/2025/07/research-shows-google-ai-overviews-reduce-website-clicks-by-almost-half/",
    "first_paragraph": "\n        The Pew Research Center analysis shows how hard AI is hitting web traffic.\n      Google's search results have undergone a seismic shift over the past year as AI fever has continued to escalate among the tech giants. Nowhere is this change more apparent than right at the top of Google's storied results page, which is now home to AI Overviews. Google contends these Gemini-based answers don't take traffic away from websites, but a new analysis from the Pew Research Center says otherwise. Its analysis shows that searches with AI summaries reduce clicks, and their prevalence is increasing.Google began testing AI Overviews as the \"search generative experience\" in May 2023, and just a year later, they were an official part of the search engine results page (SERP). Many sites (including this one) have noticed changes to their traffic in the wake of this move, but Google has brushed off concerns about how this could affect the sites from which it collects all that data.SEO experts have"
  },
  {
    "title": "Tesla Q2 2025 Update [pdf] (tesla.com)",
    "points": 18,
    "submitter": "bratao",
    "submit_time": "2025-07-24T01:18:29 1753319909",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44665845",
    "comments": [
      "The buried lede I hadn't seen in any headlines on the business news websites: 89% decrease in free cash flow. Ooofreply",
      "And this is *before* the regulatory credits went away 3 weeks ago, and *before* 7500$ / car subsides go away end of September. In Q3 Tesla will start seriously bleeding money.reply",
      "Who would have thought that alienating yoyr target market could impact sales??I hope the purchase of twitter and the subsequent leverage he has on politics and government is worth it. /sreply"
    ],
    "link": "https://www.tesla.com/sites/default/files/downloads/TSLA-Q2-2025-Update.pdf",
    "first_paragraph": ""
  },
  {
    "title": "US AI Action Plan (ai.gov)",
    "points": 180,
    "submitter": "joelburget",
    "submit_time": "2025-07-23T15:28:58 1753284538",
    "num_comments": 182,
    "comments_url": "https://news.ycombinator.com/item?id=44660323",
    "comments": [
      "I love how practically all goals in this Action Plan are directed towards incentivizing AI usage\u2026 except for the very last one, which specifically says to \u201cCombat Synthetic Media in the Legal System\u201d.Given that LLMs, for instance, are all about creating synthetic media, I don\u2019t know how this last goal can be reconciled with the others.reply",
      "I mean...one (common and [I can't believe I'm saying this] reasonable) take is that the only thing that matters is getting to AGI first. He who wields that power rules the world.reply",
      "Won't it be funny when someone finally gets to AGI and they realize it's about as smart as a normal person and they spent billions getting there? Of course you can speculate that it could improve. But what if something inherent in intelligence has a ceiling and caused it to be a super intelligent but mopey robot that just decides \"why bother helping humans\" and just lazes around like the pandas at the zoo.reply",
      "One can be sure regulatory capture is rarely in the public interest.=3reply",
      "> Update Federal procurement guidelines to ensure that the government only contracts with frontier large language model (LLM) developers who ensure that their systems are objective and free from top-down ideological biasIf foundation model companies want their government contracts renewed, they are going to have to make sure their AI output aligns with this administration's version of \"truth\".reply",
      "We are going to literally have Big Brother. Wtfreply",
      "Bias: when the model says things I don't agree with.Unbiased: when the model says only things I agree with.It's telling when xAI has to force their model into being aligned with their world view with mixed success. It seems to imply that OpenAI/Anthropic are less manually biased than the people accusing them of wokeness presumed.reply",
      "> It seems to imply that OpenAI/Anthropic are less manually biased than the people accusing them of wokeness presumed.Duh. When is that ever not the case?reply",
      "> Encourage Open-Source and Open-Weight AIIt's good to see this, especially since they acknowledge that open weights is not equal to open source.reply",
      "I wonder how this intersects with their interest in \"unbiased\" models. Scare quotes because their concept of unbiased is scary.reply"
    ],
    "link": "https://www.ai.gov/action-plan",
    "first_paragraph": "HomeAction PlanEducationPresidential ChallengeAmerica is in a race to achieve global dominance in artificial intelligence (AI). Winning this race will usher in a new era of human flourishing, economic competitiveness, and national security for the American people. Recognizing this, President Trump directed the creation of an AI Action Plan in the early days of his second term in office. Based on the three pillars of accelerating innovation, building AI infrastructure, and leading in international diplomacy and security, this Action Plan is America\u2019s roadmap to win the race.America must have the most powerful AI systems in the world, but we must also lead the world in creative and transformative application of those systems. Ultimately, it is the uses of technology that create economic growth, new jobs, and scientific advancements. America must invent and embrace productivity enhancing AI uses that the world wants to emulate. \u00a0Achieving this requires the Federal government to create the"
  },
  {
    "title": "Building better AI tools (hazelweakly.me)",
    "points": 241,
    "submitter": "eternalreturn",
    "submit_time": "2025-07-23T14:56:31 1753282591",
    "num_comments": 148,
    "comments_url": "https://news.ycombinator.com/item?id=44659921",
    "comments": [
      "This is a confusing piece. A lot of it would make sense if Weakly was talking about a coding agent (a particular flavor of agent that worked more like how antirez just said he prefers coding with AI in 2025 --- more manual, more advisory, less do-ing). But she's not: she's talking about agents that assist in investigating and resolving operations incidents.The fulcrum of Weakly's argument is that agents should stay in their lane, offering helpful Clippy-like suggestions and letting humans drive. But what exactly is the value in having humans grovel through logs to isolate anomalies and create hypotheses for incidents? AI tools are fundamentally better at this task than humans are, for the same reason that computers are better at playing chess.What Weakly seems to be doing is laying out a bright line between advising engineers and actually performing actions --- any kind of action, other than suggestions (and only those suggestions the human driver would want, and wouldn't prefer to learn and upskill on their own). That's not the right line. There are actions AI tools shouldn't perform autonomously (I certainly wouldn't let one run a Terraform apply), but there are plenty of actions where it doesn't make sense to stop them.The purpose of incident resolution is to resolve incidents.reply",
      "There's no AI tool today that will resolve incidents to anyone's satisfaction. People need to be in the loop not only to take responsibility but to make sure the right actions are performed.reply",
      "Nobody disputes this. Weakly posits a bright line between agents suggesting active steps and agents actually performing active steps. The problem is that during incident investigations, some active steps make a lot of sense for agents to perform, and others don't; the line isn't where she seems to claim it is.reply",
      "Understood. To your example about the logs, my concern would be be that the AI chooses the wrong thing to focus on and people decide there\u2019s nothing of interest in the logs, thus overlooking a vital clue.reply",
      "You wouldn't anticipate using AI tools to one-shot complex incidents, just to rapidly surface competing hypotheses.reply",
      "Lost in a bit of the discourse around anomaly detection and incident management is that not all problems are equal. Many of them actually are automatable to some extent. I think the issue is understanding when something is sufficiently offloadable to some cognitive processor vs. when you really do need a human engineer involved. To your point, yes, they are better at detecting patterns at scale \u2026 until they\u2019re not. Or knowing if a pattern is meaningful. Of course not all humans can fill these gaps either.reply",
      "It's not a confusing piece if you don't skip/ignore the first part. You're using her one example and removing the portion about how human beings learn and how AI is actively removing that process. The incident resolution is an example of her general point.reply",
      "I feel pretty comfortable with how my comment captures the context of the whole piece, which of course I did read. Again: what's weird about this is that the first part would be pretty coherent and defensible if applied to coding agents (some people will want to work the way she spells out, especially earlier in their career, some people won't), but doesn't make as much sense for the example she uses for the remaining 2/3rds of the piece.reply",
      "It makes perfect sense for that case too. If you let AI do the whole job of incident handling (and leaving aside the problem where they'll get it horribly wrong), that also has the same problem of breaking the processes by which people learn. (You could make the classic \"calculator\" vs \"long division\" argument here, but one difference is, calculators are reliable.)Also:> some people will want to work the way she spells out, especially earlier in their careerIf you're going to be insulting by implying that only newbies should be cautious about AI preventing them from learning, be explicit about it.reply",
      "You can simply disagree with me and we can hash it out. The \"early career\" thing is something Weakly herself has called out.I disagree with you that incident responders learn best by e.g. groveling through OpenSearch clusters themselves. In fact, I think the opposite thing is true: LLM agents do interesting things that humans don't think to do, and also can put more hypotheses on the table for incident responders to consider, faster, rather than the ordinary process of rabbitholing serially down individual hypothesis, 20-30 minutes at a time, never seeing the forest for the trees.I think the same thing is probably true of things like \"dumping complicated iproute2 routing table configurations\" or \"inspecting current DNS state\". I know it to be the case for LVM2 debugging\u2020!Note that these are all active investigation steps, that involve the LLM agent actually doing stuff, but none of it is plausibly destructive.\u2020 Albeit tediously, with me shuttling things to and from an LLM rather than an agent doing things; this sucks, but we haven't solved the security issues yet.reply"
    ],
    "link": "https://hazelweakly.me/blog/stop-building-ai-tools-backwards/",
    "first_paragraph": "I\u2019ve been reading this week about how humans learn, and effective ways of transferring knowledge. In addition, I\u2019ve also had AI in the back of my mind, and recently I\u2019ve come to the realization that not only is our industry building AI tools poorly, we\u2019re building them backwards. Which, honestly, is really depressing to me because there is so much unrealized potential that we have available\u2013is it not enough that we built the LLMs unethically, and that they waste far more energy than they return in value? On top of that, it doesn\u2019t take that much extra effort to build the tooling in a way that facilitates how humans work together; the tooling could be built to improve our capabilities by making everybody more effective, rather than by deskilling critical reasoning loops for practitioners. Here\u2019s how that might look.First: How we learn. My favorite (evidence backed) theory on how humans learn is Retrieval Practice.The short of it is that humans don\u2019t really learn when we download info in"
  },
  {
    "title": "Major rule about cooking meat turns out to be wrong (seriouseats.com)",
    "points": 216,
    "submitter": "voxadam",
    "submit_time": "2025-07-23T19:02:46 1753297366",
    "num_comments": 172,
    "comments_url": "https://news.ycombinator.com/item?id=44662757",
    "comments": [
      "The article actually doesn't refute the idea of resting meat to retain the juices. In fact, it supports it. It just provides a reason for why this works which is perhaps different than conventional wisdom.Retaining the juices in the meat has to do with the temperature at which the meat is cut. Resting allows the temperature to drop, which creates less pressure, so the juices aren't forced out of the meat nearly as strongly.The title is click-bait. The major rule is correct, not wrong. But, now we know a little bit more about why this rule works.> As the meat rests (and therefore cools) that vapor pressure decreases, and so does the juice loss. It's not about reabsorption or thickening as the juices cool, which is another common explanation that's been offered over the years. It's simply about pressure. Control for final internal temperature, and\u2014rested or not\u2014the juice loss is the same.reply",
      "The article categorically refutes the idea that resting is important for juiciness but that's not the same as saying resting will not improve juice retention. Proof that a relationship once though to be causal is not is a pretty big deal, and the conventional wisdom is wrong.As a counterexample: let's say the only things I care about are juiciness of the center of the cut of meat and the time it takes me to make it. By the conventional wisdom I'd have to rest the meat, adding time, but now we know that I could simply keep cooking the meat for longer, since that will raise the center temp faster, and then cut it immediately after cooking.Or another scenario: if I know the precise internal temperature for my preferred level of juiciness, I know exactly what temperature to set a sous vide to.reply",
      "\"Resting allows the temperature to drop, which creates less pressure, so the juices aren't forced out of the meat nearly as strongly.\"I was always under the impression that if you pull your meat at let's say 128, resting it will bring the internal temperature up, finishing at like 132-134. Is this wrong?reply",
      "Well, yes, as soon as you take meat off the heat, temperature continues to raise for some time, but it starts dropping off during the rest period.I cook til 125F, take it off, let it rest, cut. I have a probe that measures it in multiple points, allowing it to more accurately estimate core and surface temperature.There are so many cases like this in cooking because no one bothered to actually test validate science as long as it produced claimed results (i.e. juicy steak in this case)reply",
      "Overall the steak is cooling (as the outside air is cooler). At the centre of the steak the temperature will go up first (as heat from the outside of the steak which has been in contact with the pan transfers in) then down again.reply",
      "Unless I\u2019m mistaken (and that\u2019s quite possible!), this should be trivial to test. Sous vide some meat for an overly long time to a precise temperature, then cut each piece at set intervals.reply",
      "If you sous vide for a long time, the entirety of the steak will be at the same temperature, while pan searing cooks the outside to a higher temperature than the inside, which results in the core temperature going up a few degrees during resting.reply",
      "\"I was always under the impression that if you pull your meat at let's say 128\"Please state units.  In en_GB (at least) \"pulling your meat\" is ... ambiguous.reply",
      "Off topic, and please forgive the way my mind works, but having read your comment I couldn't help thinking that the interpretive ambiguity would be resolved if the unit stated was \"pulls\" per minute (128 ppm while vigorous, is still plausible).reply",
      "In steak/chop sized pieces,  carry-over cooking of the center finishes very quickly. If you get a really fast probe thermometer like a thermapen, you can watch it in real time. The entire piece will have cooled sufficiently after common resting times (e.g. 10 minutes.)reply"
    ],
    "link": "https://www.seriouseats.com/meat-resting-science-11776272",
    "first_paragraph": ""
  },
  {
    "title": "The Big OOPs: Anatomy of a Thirty-Five Year Mistake (computerenhance.com)",
    "points": 104,
    "submitter": "SerCe",
    "submit_time": "2025-07-19T03:23:41 1752895421",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=44612313",
    "comments": [
      "Entertaining. The presenter obviously doesn't like the class hierarchy to correspond to the domain model. He seems to think that this was an essential feature of OOP, supported by some quotations by Smalltalk exponents. But not even the Smalltalk world could agree on what OOP actually is (just compare the statements by Kay with the actual architecture of Smalltalk-76ff) and as quickly as Smalltalk lost its significance, there is no need to mention it further. I would rather look at a reputable industry organization such as IEEE, which even publishes its own standards and best practices, what OOP is about. E.g. the OOP Milestone (see https://ethw.org/Milestones:Object-Oriented_Programming,_196...) which names Simula 67 the first OO language, specifies OO as \"the combination of three main features: 1) encapsulation of data and code 2) inheritance and late binding 3) dynamic object generation.\" No mention of the class hierarchy should correspond to the domain model. So maybe we should just not mix up a programming paradigm with how it is used by some folks in practice? The fact that the loudest proponents of a paradigm are not usually those who apply it in practice remains true even today. Takes far less than 2.5 hours to state.reply",
      "He literally gives extensive primary source citations to show that the originators of OOP presented this class-domain correspondence as the correct way to think about and do OOP. Bjarne Stroustrup is not just some random guy.reply",
      "> He literally gives extensive primary source citations to show that the originators of OOP presented this class-domain correspondenceIn case of Dahl/Nygaard it seems logical since their work focus was on simulation. Simula I was mostly a language suited to build discrete-event simulations. Simula 67, which introduced the main features we subsume under \"Object-Orientation\" today, was conceived as a general-purpose language, but still Dahl and Nygaard mostly used it for building simulations. It would be wrong to conclude that they recommended a class-domain correspondence for the general case.> Bjarne Stroustrup is not just some random guySure, but he was a Simula user himself for distributed systems simulation during his PhD research at Cambridge University. And he learned Simula during his undergraduate education at Aarhus, where he also took lectures with Nygaard (a simulation guy as well). So also here, not surprising that he used examples with class-domain correspondence. But there was also a slide in the talk where Stroustrup explicitly stated that there are other valid uses of OO than using it for modeling domains.reply",
      "Is it fair to blame all of OOP for C++?reply",
      "yes, because java and c# (and others, python to a certain extent) basically copied it.  even ruby, which at its core is about \"message passing\" sure does a hell of a lot to hide that and make it feel c++ ish. i would bet at least 25% of ruby practitioners arent aware that message passing is happening.reply",
      "at least python gives the flexibility to opt out of OOP, whereas in java, literally everything is an Objectreply",
      "that's why i said \"to a certain extent\" for python!!reply",
      "Maybe not fair, but it\u2019s pretty normal for people to assess paradigms based on their most popular implementations.reply",
      "Did you actually watch it? He talks A LOT more about Simula and C++ than Smalltalk. He goes back to the original sources: Kristen Nygaard and Bjarne Stroustrup. Seems odd to focus on Smalltalk when that\u2019s not what the talk was about.reply",
      "The presentation was recently discussed at:https://news.ycombinator.com/item?id=44596554 [video] (37 comments)This current posted link is an article by Casey Muratori with supplementary material on topics to explore further.- Early History of Smalltalk- History of C++- Development of the Simula Languages- Origins of the APT Language for Automatically Programmed Toolsreply"
    ],
    "link": "https://www.computerenhance.com/p/the-big-oops-anatomy-of-a-thirty",
    "first_paragraph": ""
  },
  {
    "title": "Lumo: Privacy-first AI assistant (proton.me)",
    "points": 78,
    "submitter": "pentagrama",
    "submit_time": "2025-07-23T10:22:42 1753266162",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=44657556",
    "comments": [
      "Because of legal uncertainty around Swiss government proposals(new window) to introduce mass surveillance \u2014 proposals that have been outlawed in the EU \u2014 Proton is moving most of its physical infrastructure out of Switzerland. Lumo will be the first product to move.This is the funniest thing ever.Jurisdictional safeguards have always been snake oil. Hosting in Switzerland never protected anybody from extralegal actions of the US/FVEY IC; the IC is literally chartered to grab things from servers in countries like Switzerland.reply",
      "Interested to see where they move. Switzerland has been considered the standard base of operations for privacy companies. Many companies including Proton used it as part of their branding.reply",
      "Even more ironic is how few actual legal protections are afforded to foreign nationals: the majority of Switzerland-based service users such as PM. They actually do not deserve respect due to blatant abuse of this tired and wrong motif to sell ineffectual products.reply",
      "> Jurisdictional safeguards have always been snake oil.The lore persists from thepiratebay's stand against copyright enforcers (basing themselves from countries like Sweden)?> the IC is literally chartered to grab things from servers in countries like Switzerlandtbf, even if Switzerland might not be it, just like tax havens, there has to be colo havens? Before the AI hype, VCs (I mean, engs) did try to ram down web3 / decentralised tech (like helium, golem, storj/filecoin), but I guess those didn't catch on with these mainstream VPN/privacy types.reply",
      "The best colo haven if you're worried about US IC interference is the US. As tptacek noted above, things like due process apply to the US government's interactions with US entities. There are entire slices of the US IC apparatus whose lens is pointed internationally and where far fewer protections apply.reply",
      "Is there due process for people being accused of terrorism, treason, etc.?reply",
      "Yes.reply",
      "Is sealand still a thing?reply",
      "> Lumo\u2019s code is open source, meaning anyone can see it\u2019s secure and does what it claims to.No link to source code in the article. GitHub search also doesn\u2019t show any source code for Lumo.On a bright side, using the search on Lumo support page with a keyword \u201cgithub\u201d suggests an article on how to circumvent international sanctions to pay for their services from within Russia:\nhttps://proton.me/support/pay-russiareply",
      "I asked Lumo:> Is Lumo open source?>> I'm not sure if Lumo is open source. Let me check the official information about Lumo to confirm this.>> Based on the information provided in the Lumo FAQ, Lumo is not open source. The models powering Lumo are open-source large language models (LLMs) that have been optimized by Proton, but Lumo itself is a proprietary product developed by Proton.I think this is a bit of an accidentally correct confabulation - I can't find that in any Lumo faq - but it seems consistent with Proton overall; afaik they don't open source any server side/service code?reply"
    ],
    "link": "https://proton.me/blog/lumo-ai",
    "first_paragraph": "Secure your communications with encrypted email.Keep your online activity secure and private.Organize your photos and files with secure cloud storage.Organize your schedule privately.Protect your online identity with an encrypted password manager.Transact Bitcoin privately with an encrypted self-custody wallet.The AI where every conversation is confidential.Shield your inbox from spam and phishing with an email alias service.A secure digital notes app that protects your notes.Protect your business with end-to-end encryption and compliance-ready security.Proton stands for privacy. Always has, always will.Meet the people building a better internet.Defending freedom through tech is why we exist.Seeking talented people to take Proton to the next level.We've always been guided by the Proton community.Join the fight to make the internet a better place.Everyone is welcome to inspect our code. We're open.Our non-profit model puts people before profit.Move to Proton in just a few clicks with Ea"
  },
  {
    "title": "Seven Sisters eclipse will temporarily block stars from view (discovermagazine.com)",
    "points": 15,
    "submitter": "Bluestein",
    "submit_time": "2025-07-20T08:16:26 1752999386",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.discovermagazine.com/the-sciences/the-seven-sisters-eclipse-will-temporarily-block-stars-from-view",
    "first_paragraph": "The Seven Sisters Eclipse occurs when the moon in its waning crescent phase moves across the Pleiades and blocks the stars from view.The event is not rare and has taken place every month since September 2023. The July 2025 event will occur on July 20 in the early hours of the day. The Pleiades contain more than a thousand young stars bound together by gravity, the brightest of which can be viewed with the naked eyeOn July 20, 2025, stargazers across much of the U.S. and Canada will be able watch as the moon in its waning crescent phase moves across the Pleiades (or Seven Sisters), temporarily obstructing the stars from view.The event will occur in the early hours and to witness the moon in action, one can look towards the eastern horizon, ensure a clear line of sight, and avoid bright lights as much as possible. \u201cNo telescope or binoculars will be needed, and the darker your viewing location (the fewer city lights around you) the better your view will be, though both objects can be see"
  },
  {
    "title": "I made Tinder but it's only pictures of my wife and I can only swipe right (trytender.app)",
    "points": 300,
    "submitter": "risquer",
    "submit_time": "2025-07-23T22:53:27 1753311207",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=44664873",
    "comments": [
      "Brilliant.Question: the TOS references tender.love domain, why did you go with trytender.app for the landing page?reply",
      "This is the best post I have ever seen on this site.reply",
      "Does my wife also get this so she can be on the other side? Nevermind... I don't need the sad reality of her trying to swipe left and telling me she thinks the app is broken.reply",
      "I swiped but your wife didn't match. What gives?reply",
      "Very cute. Congrats on the launch.reply",
      "Amazing, is there a plan to add comment and a pickup line features?reply",
      "No, you can share a pic with with your partner by swiping up but I don\u2019t really plan on adding anything new - the plan is actually to open source it and anyone can add anything they wantreply",
      "But how are you going to monetize? Are you looking to raise? Moat seems low to me tbh... ;)This is great. Props for making something fun.reply",
      "Also, where are the AI features? What's your AI strategy? And how much tracking data do you generate and sell?More seriously, thank you for creating this, it's refreshing and fun.reply",
      "Add a button that generates more pics of his wife. Could monetize that too.reply"
    ],
    "link": "https://trytender.app/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: TheProtector \u2013 Linux Bash script for the paranoid admin on a budget (github.com/ihategivingausername)",
    "points": 71,
    "submitter": "lotussmellsbad",
    "submit_time": "2025-07-23T18:37:48 1753295868",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44662497",
    "comments": [
      "I love this implementation approach.At first glance I questioned your choice of bash over something like Python, but you're right - bash is everywhere and every competent Linux admin knows how to use it. There's a zillion unprotected Linux servers out there where this would be very handy.In terms of next steps, it might be worth documenting more about the notification framework and some simple examples of how we might use it. I can see you've mentioned integrations with email, Slack and webhooks in the tech paper, but I can't spot anything about how to use themCongratulations on a really worthy projectreply",
      "I would probably delete the self_update function[0] if I were to use this, otherwise this is cool!https://github.com/IHATEGIVINGAUSERNAME/theProtector/blob/ma...reply",
      "Would love to see the prompts used. I can tell from the formatting etc this is AI built, nothing wrong with that.reply",
      "This is great. I'm currently trying to use Linux more due to Recall but in terms of security I'm just not sure what I'm doing most of the time. I suppose I should go read a book about it. Any suggestions on that front? Anyway, a tool like this (if trustworthy) would go a long way to helping me in this area. Also I do like that its in bash and not compiled.reply",
      "Neat, but isn't packing all this stuff into a bash script overkill? You can pretty easily install and configure some good tools (i.e. crowdsec, rkhunter, ssh tarpit or whatever) to cover each of the categories rather than have a bunch of half-measures.Also, you're calling this TheProtector, but internally it seems to be called ghost sentinel?> local update_url=\"https://raw[dot]githubusercontent[dot]com/your-repo/ghost-se...\"reply",
      "Congratulations on your release! That packs a lot of functionality in a surprisingly small and readable (and thus auditable) shell script. Great work!One thing though: I can imagine you being rather anonymous (no real name, new HN account, new GitHub account) might make people a bit nervous around a security tool. You probably have good reasons for that, but if not.. you might want to reconsider and take credit?reply",
      "Really cool and interesting, good work.reply",
      "Thanks for all the comments and feedback - the one I run is plugged - has a brain - and can hook - Ill update in a few days with some of the features - if curious and I run a handle name because it would not take much to be morereply",
      "I really like the simplicity. I have added it to a test server and will see how it goes.\nCongrats on releasing your project.reply",
      "Was this made with LLMs?reply"
    ],
    "link": "https://github.com/IHATEGIVINGAUSERNAME/theProtector",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Linux Bash Script for the Paranoid Admin on a Budget - real-time monitoring and active threat response\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Linux Bash Script for the Paranoid Admin on a Budget - real-time monitoring and active threat responseLinux security tool for the paranoid on a budget - not perfect but better than mostTheProtector is comprehensive security monitoring for Linux systems. Built for DEfense OnlyTheProtector monitors your Linux system in real-time and actively responds to threats:Real-time Monitoring:Active Threat Response:Advanced Detection:Management Interface:Ubuntu/Debian:CentOS/RHEL/Fedora:Arch Linux:TheProtector works immediately without configuration. To customize:Key Settings:Malware and Rootkits:Network Attacks:System Com"
  },
  {
    "title": "What to expect from Debian/Trixie (michael-prokop.at)",
    "points": 200,
    "submitter": "exiguus",
    "submit_time": "2025-07-23T13:27:38 1753277258",
    "num_comments": 120,
    "comments_url": "https://news.ycombinator.com/item?id=44659019",
    "comments": [
      "I've been running testing/trixie since the end of 2023 or so.  (I generally always run testing, but stick with stable for ~6 months after stabilization, in order to avoid lots of package churn in new-testing.)It's been what I expect from Debian: boring and functional.  I've never run into an issue where the system wouldn't boot after an update (I usually update once every 2-4 weeks when on testing), and for the most part everything has worked without the need to fix broken packages or utter magic apt incantations.Debian has always been very impressive to me.  They're certainly not perfect, but what they can do based on volunteers, donations, and sponsors, is amazing.reply",
      "This is exactly why I use Debian when I install Linux. I want something that will keep chugging along, yet may not have the most cutting edge software. I can take my time with the system, and know that it is solid.If I need newer software that isn't in their package repository, I understand that I have the ability to compile what I need, or at least make an active decision to modify my system to run what I want. Basically, the possibility of instability is a conscious choice for me, which I do sometimes take.reply",
      "This could be me. I do the same, and i already plan to update to Forky at the beginning of 2026.reply",
      "i been running unstable since 2004 or so. i think it broke only once when I skipped year of updatesreply",
      "Looking forward to the release.I use Debian Stable on almost all the systems I use (one is stuck on 10/Buster due to MoinMoin). I installed Trixie in a container last week, using an LXC container downloaded from linuxcontainers.org [1].Three things I noted on the basic install :1) Ping didn't work due to changed security settings (iputils-ping) [2]2) OpenSSH server was installed as systemd socket\nactivated and so ignored /etc/ssh/sshd_config*. Maybe this is something specific to the container downloaded.3) Systemd-resolved uses LLMNR as an name lookup alternative to DNS and pinging a firewalled host failed because the lookup seemed to be LLMNR accessing TCP port 5355. I disabled LLMNR.Generally, Debian version updates have been succesful with me for a few years now, but I always have a backup, and always read the release notes.[1] https://linuxcontainers.org[2] https://www.debian.org/releases/trixie/release-notes/issues....reply",
      "> 2) OpenSSH server was installed as systemd socket activated and so ignored /etc/ssh/sshd_config.sshd still reads /etc/ssh/sshd_config at startup. As far as I know, this is hard-coded in the executable.What Debian has changed happens before the daemon is launched: the service is socket activated.\nSo, _if you change the default port of sshd_ in its config, then you have to change the activation:- either enable the sshd@service without socket activation,- or modify the sshd.socket file (`systemctl edit sshd.socket`) which has the port 22 by default.Since Debian already have a environment file (/etc/default/ssh), which is loaded by this service, the port could be set in a variable there and loaded by the socket activation. But then it would conflict with OpenSSH's own files. This is why I've always disliked /etc/default/ as a second level of configuration in Debian.reply",
      "systemd-resolved is an effing nightmare when combined with network-manager. these two packages consistently manage to stomp all over DNS resolution in their haste to be the one true source of name resolution. i tried enabling systemd-resolved as part of an effort to do dns over https and i end up with zero dns. i swear that /etc/resolv.conf plus helper scripts is more consistent and easy.reply",
      "It\u2019s why I always say in the typical \u201csystemd bad\u201d threads that systemd the init system is great, it\u2019s the systemd-* everything else\u2019s that give it a bad name.I want systemd nowhere fucking near my NTP or DNS config.reply",
      "Thank god you can enable and disable each of these components in complete isolation, so you don't suffer any kind of lock-in from systemd.reply",
      "fighting your distro in practice is a total nightmare.reply"
    ],
    "link": "https://michael-prokop.at/blog/2025/07/20/what-to-expect-from-debian-trixie-newintrixie/",
    "first_paragraph": "\u00a0\u00a0Debian v13 with codename trixie is scheduled to be published as new stable release on 9th of August 2025.I was the driving force at several of my customers to be well prepared for the upcoming stable release (my efforts for trixie started in August 2024). On the one hand, to make sure packages we care about are available and actually make it into the release. On the other hand, to ensure there are no severe issues that make it into the release and to get proper and working upgrades. So far everything is looking pretty well and working fine, the efforts seemed to have payed off. :)As usual with major upgrades, there are some things to be aware of, and hereby I\u2019m starting my public notes on trixie that might be worth for other folks. My focus is primarily on server systems and looking at things from a sysadmin perspective.As usual start at the official Debian release notes, make sure to especially go through What\u2019s new in Debian 13 + issues to be aware of for trixie (strongly recommend"
  },
  {
    "title": "Vintage Macintosh Programming Book Library (2017) (vintageapple.org)",
    "points": 11,
    "submitter": "todsacerdoti",
    "submit_time": "2025-07-24T00:53:45 1753318425",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44665704",
    "comments": [
      "Ooof, I still have entirely too many of those on paper. OTOH, when you need obsolete computer reference to do some bug fixes, they can be hard to find...reply",
      "Super cool.It's also neat to have some vintage, non-programming books about Apple culture. Tog on Interface by Bruce Tognazzani is one example.reply",
      "Edward Tufte books as well.It's nice to have PDF versions, but I'm not giving up my Inside Macintosh volumes.reply",
      "Applaud the preservation effort.Please consider an ipfs mirror of the site.reply",
      "That'd be awesome. And mirror to internet archive so that it's available by torrent too.reply",
      "Apple's own documentation really seems to have rotted. Of course it might help if Apple cared more about compatibility so that apps wouldn't break every year...reply"
    ],
    "link": "https://vintageapple.org/macprogramming/index_year.html",
    "first_paragraph": ""
  },
  {
    "title": "Jitsi privacy flaw enables one-click stealth audio and video capture (zimzi.substack.com)",
    "points": 43,
    "submitter": "zielmicha",
    "submit_time": "2025-07-23T20:31:16 1753302676",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44663684",
    "comments": [
      "Maybe my Mac is set to be paranoid, but can you share video without being asked to give the mic and camera permission to operate? I chat with jitsi all the time and have to give jitsi explicit permission to use the mic/camera each time.reply",
      "Not that I use Jitsi, but I suddenly feel more embarrassed about my number of open tabs. Some other exploit could have silently been launched long ago.reply",
      "Is this understood to be new? I think I got hit with this quite a long time ago.(As in during the pandemic -- long ago in vuln times.)I am willing to discuss it, off the record, if someone provides their signal information.reply",
      "Can someone describe the feature that this is used for? I struggle to think of any valid reason for automatic joining with audio/video like that.reply",
      "Does this apply even for iframes, or not?reply",
      "Generally no - cross origin iframes don't allow camera/audio by default. Even if the toplevel site allows it (via https://developer.mozilla.org/en-US/docs/Web/API/HTMLIFrameE...), user still needs to grant permissions to toplevel site. Of course you can still use window.open and top.location.href in the iframe and use the same trick as in the article.reply"
    ],
    "link": "https://zimzi.substack.com/p/jitsi-privacy-flaw-that-enables-one",
    "first_paragraph": ""
  },
  {
    "title": "Checklists are hard, but still a good thing (utcc.utoronto.ca)",
    "points": 90,
    "submitter": "zdw",
    "submit_time": "2025-07-20T15:51:15 1753026675",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=44626359",
    "comments": [
      "When business approach me asking for automating a business process, I usually ask them to do the process in manual steps and create check lists for it. The check lists force them to think it through and are the agreed upon steps to perform the process. After they do it by hand for a while and find out where the pain points are, we can then automate. Since the check lists are already in place, automation is really easy.reply",
      "Checklists are criminally underused in most industries. It's a testament to how great they work when looking at highly-antifragile contexts: aviation, military, etc., where a mistake can (and often does) cost lives.The problem is that to use them broadly, you also need to implement operational-level changes. So if I made a startup that helped build checklists, the problem would not just be selling the software (which everyone has to do), but also convincing executives that checklists (even moreso than to-do lists) are worth investing in. The friction a checklist brings, at least in non-ultra-risk-averse verticals, might not be worth it.reply",
      "Heck, they're underused in general. Checklists to pack for vacation. Checklists for \"what did I mean to do this weekend\". Checklists for \"here's what we need to run the volunteer dinner this organization I belong to does weekly\". Checklists for \"things to check before my presentation\".I'm nowhere near as obsessed with them as that may make me sound; by temperament I'm definitely a go-with-the-flow sort of guy... which is perhaps exactly why I make sure to use them in certain important places. Go-with-the-flow has its strengths but also its weaknesses. Selective augmentation with checklists means I can often end up with the best of both worlds between that and being \"detail oriented\" for important tasks.I have been called \"detail oriented\" a few times in my professional career, and I sort of laugh to myself because it is absolutely and utterly untrue. I'm not detail oriented in the slightest. It's all offloaded to the computer, with my unit tests, checklists, and such. I just know I need that augmentation and am quite aggressive about getting it precisely because I know I need it.reply",
      "> Checklists to pack for vacationI often have to travel for work. Sometimes I have a fair bit of notice in advance and sometimes I don't. In either case, checklists are super handy for me. I generally use either Apple Notes or Obsidian for these (previously Emacs org-mode but it's less convenient for the \"add an item from your phone\" case than the other options).For the \"notice in advance\" case, I'll start a packing checklist pretty much the moment I know I have to travel and I'll immediately write down just a sentence or two about the purpose/objective of the trip and add any special things I might need (e.g. a Saleae logic analyzer for debugging or a GoPro for documenting). As things get discussed and the trip gets closer I'll keep adding things to the list.For the \"not much advanced notice\" case, I'll look back at previous checklists to find one that has a similar objective and basically just copy it wholesale and tweak. Super super useful keeping those old checklists around, even if they're only 80% correct for the next trip.reply",
      "checklists do wonders for my anxiety.too often i'll have a sudden thought about \"oh, i need to make sure to fix X\" or \"I cant forget to pack Y before the trip\". My options to deal with those sudden thoughts are:1. Do it immediately, which isn't always possible2. Do it later, which means that I'll obsessively stress out about it because \"what if I forget to do it? I need to make sure this stays at the forefront of my mind at all times.\"3. Put it on a checklist and give myself permission to stop thinking about it until its time to do itreply",
      "This is one of the key concepts of \"Getting Things Done\". Getting tasks and information out of your head so you can actually focus on what you want to accomplish or need to do. GTD has a lot more to it, but this is around 80-90% of it with the rest being implementation details. When you get the idea, as you have, you can start reflecting and trialing different systems to see what specifically works for you and in what contexts.reply",
      "This is a very-HN way of describing it, but one way I conceptualize my list-making is memoization/function caching.My brain already went through the hard work of figuring out what to do, so I should cache that result in the todo list. later I can do a quick O(1) lookup of what do and use all of my focus on doing that.reply",
      "\"The mind is for having ideas, not holding them.\"\n-- David Allen, author of Getting Things Done.reply",
      "I often use a checklist version for travel packing, where every item simply goes after each other with a checkbox, instead of usual checklist with every new item going on new line.reply",
      "The travel checklist goes with me on the trip and serves to answer three more questions: (1) Am I bringing back everything I took, (2) what did I not use on the trip, and (3) what should I have brought (i.e. add it to the checklist after the trip has started)?I take the list for a completed trip and use it to plan the next trip of a like nature. It has been very helpful.reply"
    ],
    "link": "https://utcc.utoronto.ca/~cks/space/blog/sysadmin/ChecklistsAreHardButGood",
    "first_paragraph": " You're probably reading this page because you've attempted to\naccess some part of my blog (Wandering\nThoughts) or CSpace, the wiki thing it's\npart of. Unfortunately whatever you're using to do so has a HTTP\nUser-Agent header value that is too generic or otherwise excessively\nsuspicious. Unfortunately, as of early 2025 there's a plague of\nhigh volume crawlers (apparently in part to gather data for LLM\ntraining) that behave like this. To reduce the load on Wandering Thoughts I'm experimenting with\n(attempting to) block all of them, and you've run into this.  All HTTP User-Agent headers should clearly identify what they\nare, and for non-browser user agents, they should identify not just\nthe software involved but also who specifically is using that software.\nAn extremely generic value such as \"Go-http-client/1.1\"\nis not something that I consider acceptable any more. "
  }
]