[
  {
    "title": "Higher-kinded bounded polymorphism in OCaml (2021) (okmij.org)",
    "points": 40,
    "submitter": "tinyspacewizard",
    "submit_time": "2024-07-28T21:40:47",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41096187",
    "comments": [
      "Unreadable. Code font is too small.\n \nreply",
      "\"Please don't complain about tangential annoyances\u2014e.g. article or website formats, name collisions, or back-button breakage. They're too common to be interesting.\"https://news.ycombinator.com/newsguidelines.html\n \nreply"
    ],
    "link": "https://okmij.org/ftp/ML/higher-kind-poly.html",
    "first_paragraph": "OCaml does not support higher-kinded polymorphism directly: OCaml type\nvariables range over types rather than type constructors, and type\nconstructors may not appear in type expressions without being applied\nto the right number of arguments.  Nevertheless, higher-kinded\npolymorphism is expressible in OCaml\u00a0-- in fact, in several, more or\nless cumbersome ways. The less cumbersome ways are particularly less\nknown, and kept being rediscovered. This page summarizes the different\nways of expressing, and occasionally avoiding, higher-kinded\npolymorphism. They are collected from academic papers and messages on\nthe caml-list spread over the years\u00a0-- and adjusted to fit the story\nand differently explained.\n\u00a0This remarkably concise summary is worth expounding upon, to\ndemonstrate how (bounded) higher-kinded polymorphism tends to\narise. The example introduced here is used all throughout the page.\nSumming up numbers frequently occurs in practice; abstracting from\nconcrete numbers leads to a functi"
  },
  {
    "title": "tolower() with AVX-512 (dotat.at)",
    "points": 43,
    "submitter": "fanf2",
    "submit_time": "2024-07-28T20:38:59",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=41095790",
    "comments": [
      "just for giggles: http://www.unicode.org/Public/3.1-Update1/CaseFolding-4.txt\n \nreply",
      "While we're having fun with that:    # Capitalising an eszett changes the string length.\n    >>> \"stra\u00dfe\".upper()\n    'STRASSE'\n    \n    # If you don't specify the locale, round-trip upper/lower case\n    # messes up the dotless i used in turkic languages.\n    >>> '\u0131'.upper().lower()\n    'i'\n \nreply",
      "Heh, thank goodness I don\u2019t have to deal with all that! This code is ascii-only because it arose from working on the DNS. There are other protocols that are ascii-case-insensitive so it turns up a lot in the hot path of many servers.\n \nreply",
      "This is presumably Rust's u8::to_ascii_lowercase rather than C's tolower since tolower is locale sensitive (which you don't care about) and has Undefined Behaviour (because of course it does it's a C function and who cares about correctness)Or possibly u8::make_ascii_lowercase which is the same function but with in-place mutation.\n \nreply",
      "Note for the first example which transforms the German ma\u00dfe to MASSE that the German language has an uppercase Eszett as well: \u1e9eThis is as of now not widely deployed and few fonts support it, but in theory it is there now.\n \nreply",
      "There is a difference between strings used internally, usually as IDs, and text entered by a human. For the former you'd always use straight ASCII in 8-bit encoding, for the latter ... things get difficult. A straightforward example are DNS addresses - they can technically contain almost any Unicode, but that is always converted to a very limited subset of ASCII for actual DNS resolution, which in turn is case-insensitive.There are of course things like programming languages with case-insensitive identifiers that support all human writing systems in Unicode. If that's what you're dealing with, you have my condolences.\n \nreply",
      "For what it\u2019s worth, with IDNs you\u2019re still going to do a kind of case folding using stringprep before doing the query, and that isn\u2019t really better than the table GP linked. ASCII-only case-insensitive matching is indeed a thing, but it\u2019s usually mutually exclusive with (non-programmer) user-entered data.\n \nreply",
      "> Finally, we do a masked add. We pass c twice: bytes from the first c are copied to the result when is_uppper is false, and when is_upper is true the result is c + to_upper.Is that an error in the post ? Shouldnt it do the addition when is_upper is false and copy the same when it is true ?\n \nreply",
      "The operation is `tolower`Capital a is 0x40, lowercase is 0x60.The addition of 0x20 needs to happen when is_upper is true.\n \nreply",
      "Mask add looks neat! I wish there was a way to directly manipulate AVX512's mask registers in .NET intrinsics but for now we have to live with \"recognized idioms\".For anyone interested, the author's core loop in ASM is as compiled by GCC    .L3:\n        vmovdqu8        zmm0, ZMMWORD PTR [rcx+rax]\n        vmovdqa64       zmm1, zmm0\n        vpcmpb  k1, zmm0, zmm4, 5\n        vpcmpb  k0, zmm0, zmm3, 2\n        kandq   k1, k1, k0\n        vpaddb  zmm1{k1}, zmm0, zmm2\n        vmovdqu8        ZMMWORD PTR [rdi+rax], zmm1\n        add     rax, 64\n        cmp     rax, r8\n        jne     .L3\n\nuiCA (CQA/MAQAO) (https://uica.uops.info/, make sure to pick CQA + Ice Lake) says it achieves nice 32B/cycle on Ice Lake. If you multiply by say 3 to match 3 GHz, this gives us almost 96 GiB/s assuming memory access is not a bottleneck (it always is in such algorithms).But this seems not as close to optimal utilization as it could be. Using Clang instead yields much better, nicely unrolled result with better instruction selection.    .LBB0_9:\n        vmovdqu64       zmm3, zmmword ptr [rsi]\n        vmovdqu64       zmm5, zmmword ptr [rsi + 64]\n        vmovdqu64       zmm6, zmmword ptr [rsi + 128]\n        add     rdx, -512\n        vpaddb  zmm4, zmm3, zmm0\n        vpcmpltub       k1, zmm4, zmm1\n        vpaddb  zmm4, zmm5, zmm0\n        vpaddb  zmm3 {k1}, zmm3, zmm2\n        vpcmpltub       k1, zmm4, zmm1\n        vpaddb  zmm4, zmm6, zmm0\n        vpaddb  zmm5 {k1}, zmm5, zmm2\n        vmovdqu64       zmmword ptr [rcx], zmm3\n        vpcmpltub       k1, zmm4, zmm1\n        vmovdqu64       zmmword ptr [rcx + 64], zmm5\n        vmovdqu64       zmm5, zmmword ptr [rsi + 192]\n        vpaddb  zmm6 {k1}, zmm6, zmm2\n        vmovdqu64       zmmword ptr [rcx + 128], zmm6\n        vmovdqu64       zmm6, zmmword ptr [rsi + 256]\n        vpaddb  zmm4, zmm5, zmm0\n        vpcmpltub       k1, zmm4, zmm1\n        vpaddb  zmm4, zmm6, zmm0\n        vpaddb  zmm5 {k1}, zmm5, zmm2\n        vpcmpltub       k1, zmm4, zmm1\n        vmovdqu64       zmmword ptr [rcx + 192], zmm5\n        vmovdqu64       zmm5, zmmword ptr [rsi + 320]\n        vpaddb  zmm6 {k1}, zmm6, zmm2\n        vmovdqu64       zmmword ptr [rcx + 256], zmm6\n        vmovdqu64       zmm6, zmmword ptr [rsi + 384]\n        vpaddb  zmm4, zmm5, zmm0\n        vpcmpltub       k1, zmm4, zmm1\n        vpaddb  zmm4, zmm6, zmm0\n        vpaddb  zmm5 {k1}, zmm5, zmm2\n        vpcmpltub       k1, zmm4, zmm1\n        vmovdqu64       zmmword ptr [rcx + 320], zmm5\n        vmovdqu64       zmm5, zmmword ptr [rsi + 448]\n        vpaddb  zmm6 {k1}, zmm6, zmm2\n        add     rsi, 512\n        vmovdqu64       zmmword ptr [rcx + 384], zmm6\n        vpaddb  zmm4, zmm5, zmm0\n        vpcmpltub       k1, zmm4, zmm1\n        vpaddb  zmm5 {k1}, zmm5, zmm2\n        vmovdqu64       zmmword ptr [rcx + 448], zmm5\n        add     rcx, 512\n        cmp     rdx, 63\n        ja      .LBB0_9\n\nThis extracts more impressive 42.67B/c, I don't think even L2 cache can sustain such a throughput, but it's nice to know that medium length strings get up/downcased in about the same time it takes light from your screen to reach your cornea.The core for short lengths there is one instruction less:    .LBB0_5:\n        vmovdqu64       zmm3, zmmword ptr [rsi + rcx]\n        vpaddb  zmm4, zmm3, zmm0\n        vpcmpltub       k1, zmm4, zmm1\n        vpaddb  zmm3 {k1}, zmm3, zmm2\n        vmovdqu64       zmmword ptr [rax + rcx], zmm3\n        add     rcx, 64\n        cmp     r8, rcx\n        jne     .LBB0_5\n\nSome months ago I wrote a similar ASCII in UTF-8 upcase/downcase implementation in C#: https://github.com/U8String/U8String/blob/main/Sources/U8Str...(the unrolled conversion for below vectorization lengths is required as short strings dominate most codebases so handling it fast is important - the switch compiles to jump table and then branchless fall-through to return)For now it goes as wide as 256b as it already saturates e.g. Zen 3 or 4 which have only 256x4 SIMD units (even though Zen 4 can do fancy 512b shuffles natively and has very good 512b implementation). The core loop compiles to compact       G_M48884_IG05:\n              vmovups  ymm3, ymmword ptr [rdi+rax]\n              vpaddb   ymm4, ymm3, ymm1\n              vpcmpgtb ymm4, ymm2, ymm4\n              vpand    ymm4, ymm4, ymm0\n              vpor     ymm3, ymm4, ymm3\n              vmovups  ymmword ptr [rsi+rax], ymm3\n              add      rax, 32\n              cmp      rax, rdx\n              jbe      SHORT G_M48884_IG05\n\nSide by side with C ones: https://godbolt.org/z/Td83zarPcI believe you can also achieve similar with 3-instruction conversion with AVX512 with vpternlogd, as when I had access to AVX512 hardware, this is what .NET optimized it to for 256b width + AVX512VL, but strangely enough I can't make it do so for 512b width right now.You may notice failed SWAR attempt for switch dispatch case and I was wondering what kind of license your posts are distributed under? (gave up on it back then because per-element fall-through was already fast enough, but if yours passes the test suite, I'd love to use it haha)\n \nreply"
    ],
    "link": "https://dotat.at/@/2024-07-28-tolower-avx512.html",
    "first_paragraph": "A couple of years ago I wrote about tolower() in bulk at speed using\nSWAR tricks. A couple of days ago I was interested by Olivier\nGiniaux\u2019s article about unsafe read beyond of death, an\noptimization for handling small strings with SIMD instructions, for a\nfast hash function written in Rust.I\u2019ve long been annoyed that SIMD instructions can easily eat short\nstrings whole, but it\u2019s irritatingly difficult to transfer short\nstrings between memory and vector registers. Oliver\u2019s post caught my\neye because it seemed like a fun way to avoid the problem, at least\nfor loads. (Stores remain awkward!)Actually, to be frank, Olivier nerdsniped me.Reading more around the topic, I learned that some SIMD instruction\nsets do, in fact, have useful masked loads and stores that are\nsuitable for string processing, that is, they have byte granularity.\nThey are:ARM SVE, which is available on recent big-ARM Neoverse cores, such\nas Amazon Graviton, but not Apple Silicon.AVX-512-BW, the bytes and words extension"
  },
  {
    "title": "Show HN: A football/soccer pass visualizer made with Three.js (statsbomb-3d-viz.vercel.app)",
    "points": 72,
    "submitter": "carlos-menezes",
    "submit_time": "2024-07-28T20:45:17",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41095839",
    "comments": [
      "Great interface. Maybe provide a direct example, if I want to change to something else, I will find the raw json myself through the guidance you provided.After loading it, I don\u2019t quite understand why you use threejs. Because you also use a heat map to show the height of the pass. The passing route on whoscored seems more intuitive.\n \nreply",
      "What do the colors mean? I assume this is complete passes only, not intercepted ones? How about displaying some heatmap of passes instead of individual vectors for a different view? Have you considered denoting the direction of the pass with a dot for the start/end or an arrow if not too busy? Is there any indication of the speed of the pass? How about summary stats for each player, team, etc? # of passes, average speed, % complete, how concentrated vs. distributed they are over the squad, which players receive the ball most/least often, which players receive the ball from most players/fewer players, same for positions (individually or grouped by defenders/midfielders/attackers)OK, I'll stop brainstorming :-) Cool visualization!\n \nreply",
      "This is cool, thanks for sharing it. Any chance you could add a time-based animation? I'd love to see a game play out, maybe with some fading colors.Also, I wonder what the best way to get insights out of this data is -- feels like exploration is the first step, but adding value on top would be really great.\n \nreply",
      "Very interesting! Also, never heard about statsbomb.\nCrazy how much data can now be gleaned from a simple football game.\n \nreply",
      "I don't know how you decide the colors for the lines, but when I filter by a team and a specific player I need to search for the lines as they are basically invisible.\n \nreply",
      "Would love if there was a way to instantly see an example urlLike a \u201ctry example button\u201dLower friction to test\n \nreply",
      "You can use the \"Load Default\" button!\n \nreply",
      "Maybe rename it to \"Load an Example\" or something. Not a clear name.\n \nreply",
      "Agreed. Fixed! Thank you.\n \nreply",
      "This is great to see.. A few friends do a lot of player statistics and analytics for fun mostly and this would be an amazing addition. Any documentation on what the week process went and challenges that you ran into?\n \nreply"
    ],
    "link": "https://statsbomb-3d-viz.vercel.app/",
    "first_paragraph": ""
  },
  {
    "title": "LeanDojo: Theorem Proving in Lean Using LLMs (leandojo.org)",
    "points": 51,
    "submitter": "aseg",
    "submit_time": "2024-07-28T22:34:36",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41096486",
    "comments": [
      "I wonder if they could integrate with the reinforcement learning approach from AlphaProof (this week). Having an IMO silver level proof copilot would pretty neat!\n \nreply",
      "I wish someone could do a cost analysis of how much compute could replicate alphaproof. Alphazero was replicated in open source, hopefully this will be too!\n \nreply",
      "Useful context: https://en.m.wikipedia.org/wiki/Lean_(proof_assistant) - \"Lean is a proof assistant and a functional programming language. It is based on the calculus of constructions with inductive types. \"\n \nreply"
    ],
    "link": "https://leandojo.org/",
    "first_paragraph": "We introduce Lean Copilot for LLMs to act as copilots in Lean for proof automation, e.g., suggesting tactics/premises and searching for proofs. Users can use our model or bring their own models that run either locally (w/ or w/o GPUs) or on the cloud.Top right: LeanDojo extracts proofs in Lean into datasets for training machine learning models. It also enables the trained model to prove theorems by interacting with Lean's proof environment.Top left: The proof tree of a Lean theorem \\(\\forall n \\in \\mathbb{N},~\\texttt{gcd n n = n}\\), where \\(\\texttt{gcd}\\) is the greatest common divisor. When proving the theorem, we start from the original theorem as the initial state (the root) and repeatedly apply tactics (the edges) to decompose states into simpler sub-states, until all states are solved (the leaf nodes). Tactics may rely on premises such as \\(\\texttt{mod_self}\\) and  \\(\\texttt{gcd_zero_left}\\) defined in a large math library. E.g., \\(\\texttt{mod_self}\\) is an existing theorem \\(\\for"
  },
  {
    "title": "How simultaneous multithreading works under the hood (codingconfessions.com)",
    "points": 174,
    "submitter": "rbanffy",
    "submit_time": "2024-07-28T15:35:14",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=41093916",
    "comments": [
      "A grossly over-simplified argument for SMT that resonated with me was that it could keep a precious ALU busy while a thread stalls on a cache miss.I gather in the early days the LPDDR used on laptops was slower too and since cores were scarce so this was more valuable there. Lately, though, we often have more cores than we can scale with and the value is harder to appreciate. We even avoid scheduling work on a shared with an important thread to avoid cache-contention because we know the single-threaded performance will be the bottleneck.A while back I was testing Efficient/Performance cores and SMT cores for MT rendering with DirectX 12; on my i7-12700K I found no benefit to either: just using P-cores took about the same time to render a complex scene as P+SMT and P+E+SMT. It's not always a wash, though: on the Xbox Series X we found the same test marginally faster when we scheduled work for SMT too.\n \nreply",
      "> on the Xbox Series X we found the same test marginally faster when we scheduled work for SMT too.This makes sense, the Series X has GDDR RAM, and so has substantially worse latency than DDR/LPDDR. SMT can help cover that latency, and the higher GDDR bandwidth mitigates the higher memory bandwidth needed to feed both threads.\n \nreply",
      "Rendering is one of the scenarios which was either same or slower with SMT since the beginning. This is because rendering is already math heavy, and your FPU is always active, esp. dividers (which is always the most expensive operation for processors).SMT shines while waiting for I/O or doing some simple integer stuff. If both your threads can saturate the FPU, SMT is generally slower because of the extra tagging added to the data inside the CPU to note what belongs where.\n \nreply",
      "If you're waiting for IO, you're likely getting booted off the processor by the OS anyway. SMT is most useful when your code doesn't have enough instruction-level parallelism but is still mostly compute bound.\n \nreply",
      "I believe \"I/O\" here is referring to data movement between DRAM and registers. Not drives or NICs.\n \nreply",
      "But the way you make rendering embarrassingly parallel is the way you make web servers parallel; treat the system as a large number of discrete tasks with deadlines you work toward and avoid letting them interact with each other as much as possible.You don\u2019t worry about how long it takes to render one frame of a digital movie, you worry about how many CPU hours it takes to render five minutes of the movie.\n \nreply",
      "Intel\u2019s hyperthreading is really a write pipe hack.It\u2019s not so much cache misses as allowing the core to run something else while the write completes.This is why some code scales poorly and other code achieves near linear speed ups.\n \nreply",
      "Why would the core have to wait for the write to complete?A core stalls on a write only if the store buffer is full. As hyper threads share the write buffer, SMT makes store stalls more likely, not less ( but still unlikely to be the bottleneck).\n \nreply",
      "At this point, especially with backside power, I wonder how much cache stalls on one processor result in less thermal throttling both on that processor and neighboring ones.Maybe we should just be letting these procs take their little naps?\n \nreply",
      "This leads, in the extreme, to the idea of a huge array of very simple cores, which I believe is something that has been tried but never really caught on.\n \nreply"
    ],
    "link": "https://blog.codingconfessions.com/p/simultaneous-multithreading",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I built an open-source tool to make on-call suck less (github.com/opslane)",
    "points": 115,
    "submitter": "aray07",
    "submit_time": "2024-07-27T13:53:58",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=41086620",
    "comments": [
      "> It reduces alert fatigue by classifying alerts as actionable or noisy and providing contextual information for handling alerts.grimace faceI might be missing context here, but this kind of problem speaks more to a company\u2019s inability to create useful observability, or worse, their lack of conviction around solving noisy alerts (which upon investigation might not even be \u201cjust\u201d noise)! Your product is welcome and we can certainly use more competition in this space, but this aspect of it is basically enabling bad cultural practices and I wouldn\u2019t highlight it as a main selling point.\n \nreply",
      "Yeah, thats fair feedback. The main aim was to reduce the alert fatigue for on-call engineers and provide a way to get insight into the alerts at the end of the on-call shift.This way there is data to make a case that certain alerts are noisy (for various reasons) and we should strive to reduce the time spent dealing with these alerts. Fixing some of them might be as easy as deleting them but for others might need dedicated time working on them.\n \nreply",
      "Big fan of this direction. The architecture resonates! The base lining is interesting, I'm curious how you think about that, esp for bootstrapping initially + ongoing.We are working on a variant being used more by investigative teams than IT ops - so think IR, fraud, misinfo, etc - which has similarities but also domain differences. If of interest to someone with an operational infosec background (hunt, IR, secops) , and esp US-based, the Louie.AI team is hiring an SE + principal here.\n \nreply",
      "Nice job and congratulations on building this! It looks like your copy is missing a word in the first paragraph:> Opslane is a tool that helps (make) the on-call experience less stressful.\n \nreply",
      "derp, thanks for catching. It has been fixed!\n \nreply",
      "In my current workplace (BigCo), we know exactly what's wrong with our alert system. We get alerts that we can't shut off, because they (legitimately) represent customer downtime, and whose root cause we either can't identify (lack of observability infrastructure) or can't fix (the fix is non-trivial and management won't prioritize).Running on-call well is a culture problem. You need management to prioritize observability (you can't fix what you can't show as being broken), then you need management to build a no-broken-windows culture (feature development stops if anything is broken).Technical tools cannot fix culture problems!edit: management not talking to engineers, or being aware of problems and deciding not to prioritize fixing them, are both culture problems. The way you fix culture problems, as someone who is not in management, is to either turn your brain off and accept that life is imperfect (i.e. fix yourself instead of the root cause), or to find a different job (i.e. if the culture problem is so bad that it's leading to burnout). In any event, cultural problems cannot be solved with technical tools.\n \nreply",
      "I work on a team which runs hyper critical infra on all production machines at BigCo and have the same experience as you.The problem are not the alerts \u2014 the alerts actually are catching real problems \u2014 the problem is the following:1. The team is understaffed so sometimes spending a few days root causing an alert is not prioritized\n2. When alerts are root caused sometimes the work to fix the root cause is not prioritized\n3. A culture on the team which allows alerts to go untriaged due to desensitization.Our headcount got reduced by ~40% and \u2014 surprise surprise \u2014 reliability and on-call got much worse. Senior leadership has made the decision that the  cost cuts are worth the decreased reliability so nothing is going to change.The job market is rough so people put up with this for now.\n \nreply",
      "Start putting together conference bridges for \"P1 customer outages\" and have someone who is responsible for calling the developers, PMs, scrum masters, managers, etc. on the team and getting them all on at 1 AM to fix it.\n \nreply",
      "we as an industry need to have engineering management types realize that we cannot prioritize roadmap to the complete detriment of reliability\n \nreply",
      "If your org claims to be \"customer obsessed\" then reframe your alerts as what their impact to customers are.  Don't say \"elevated 502 errors\" say \"customers couldn't encountered errors X times.\"\n \nreply"
    ],
    "link": "https://github.com/opslane/opslane",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Reducing alert fatigue for on-call engineers\n      \n\n\nDemo - Slack\nOpslane is a tool that helps make the on-call experience less stressful.It reduces alert fatigue by classifying alerts as actionable or noisy and providing contextual information for handling alerts.Opslane uses a modular architecture designed for efficient alert processing and seamless integration with existing tools:Here's a high-level overview of the Opslane architecture:We use a flexible data model so that we can support multiple integrations. Currently, Opslane supports Datadog.\n        Reducing alert fatigue for on-call engineers\n      "
  },
  {
    "title": "Italy's Sun Motorway (2021) (domusweb.it)",
    "points": 46,
    "submitter": "simonebrunozzi",
    "submit_time": "2024-07-28T16:27:11",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41094197",
    "comments": [
      "I have traveled all around Europe by car and the autostrada del sole is an unmatched engineering marvel in the old continent.Italian geography is complex. There's a reason the allied forces took way longer from Naples to Milan than from Normandy to Berlin despite heavily outnumbering the Germans.I was always super proud of the quality and maintenance of Italian highways. Somewhere around the turn of the century I stopped feeling as proud because maintenance started lacking and other countries that I visited (eastern Europe) has also built some very good roads.One thing to notice though is that the highways are expensive.From Rome to Milan in a small car you're paying around 60\u20acs in tolls.That's not a small price, especially as it is way higher than 15 day passes for all highways in some other central European countries.\n \nreply",
      "Depends. We just had a bridge collapse and kill 42 people with it. So it depends. It\u2019s not all sunshine and rainbows\n \nreply",
      "I did point out that from 20 years there seems not to be the same maintenance that we had.Anyway the ponte Morandi is not part of the autostrada del sole.\n \nreply",
      "On a tangential note, Italian food on the Italian highways at the \u201cAutogrill\u201d chain (gas stations and food joints along the route) is better than 90% of \u201cItalian\u201d restaurants in the USA.\n \nreply",
      "Is there a variant of Godwin's law where an internet discussion always lead to people criticising the USA, regardless of subject?\n \nreply",
      "Weirdly I found that most of the restaurants I ate at in Italy were level with or worse than the Italian restaurants in Melbourne, Australia. I think part of it was just that it's hard to find the good ones vs the average/bad ones in Italy while Italian restaurants in Australia tend to all be targeting higher end food.The Autogrill ones were not terrible but not particularly good. Mostly just stale sandwiches with good quality ingredients.\n \nreply",
      "Italy has become a den of tourist traps. I ate terribly there despite my Italian is still good enough that the locals thought I was a native Roman (I lived there as a teen)\n \nreply",
      "Thats unsurprising. \"Italian\" food in America isn't and the Autogrill is excellent.\n \nreply",
      "The Sun Motorway between Bologna and Florence is double, as the article says: there is the original road (now called \"panoramica\") and the new super-direct (\"direttissima\", also called Variante di Valico).The old road is still interesting to see, even though it's in worse conditions and it takes a longer time to cross. Give it a try on your next Italian road trip!\n \nreply",
      "Never knew it was a thing until a couple of summers ago our train from Florence to Como was delayed by like 3 hours, so we canceled the tickets, rented a nice little black Fiat 500 and drove. I was enjoying the sights all the way through as is tradition in Italy (and the old continent in general), but if I recall correctly there was a point on the road where we could choose to take the \"Panoramica\" route and wow, did it pay off. I will forever treasure that little unplanned experience.\n \nreply"
    ],
    "link": "https://www.domusweb.it/en/architecture/gallery/2021/07/16/the-sun-motorway-is-65-years-old-a-short-story-of-an-extraordinary-infrastructure.html",
    "first_paragraph": "Discover the Domus summer special.News, projects, archives, and insights.Aglio Viaduct, 1962. Courtesy Archivio Storico Autostrade per l\u2019ItaliaGoccioloni Viaduct, 1959. Courtesy Archivio Storico Autostrade per l\u2019ItaliaA gallery under construction, 1959. Courtesy Archivio Storico Autostrade per l\u2019ItaliaBologna-Florence, 1960. Courtesy Archivio Storico Autostrade per l\u2019ItaliaBagnaia Viaduct, 1960. Courtesy Archivio Storico Autostrade per l\u2019ItaliaBologna-Florence, opening, 1960. Courtesy Archivio Storico Autostrade per l\u2019ItaliaMassa viaduct and gallery, 1962. Courtesy Archivio Storico Autostrade per l\u2019ItaliaConstruction of the bridge on the Tiber, 1963. Courtesy Archivio Storico Autostrade per l\u2019ItaliaBologna-Florence. Courtesy Archivio Storico Autostrade per l\u2019ItaliaAutostrada del Sole. Courtesy Quattroruote / Editoriale DomusAutostrada del Sole. Courtesy Quattroruote / Editoriale DomusAutostrada del Sole. Courtesy Quattroruote / Editoriale DomusAutostrada del Sole. Courtesy Quattroruote"
  },
  {
    "title": "Show HN: CeLLama \u2013 Single cell annotation with local LLMs (github.com/celvoxes)",
    "points": 89,
    "submitter": "celltalk",
    "submit_time": "2024-07-28T12:56:55",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=41092862",
    "comments": [
      "Can anyone explain how an LLM is useful here? The clustering is done traditionally right? Then the llm is given the centroids and asked to give a label? Assumption being that the llm corpus already contained some mapping from gene up/down regulations to clusters of differentiation?\n \nreply",
      "Yes, it basically automates the cell type annotation process, plus gives a reasoning for the label.\n \nreply",
      "How easy is it to check the results of cell annotations for mistakes?Is it easy for a person to do, and this will save them a bunch of time getting a baseline? Or could this lead to a bunch of mislabeled data?\n \nreply",
      "Users of these kinds of tools should check that their marker genes are associated with the labelled cell types.  There are known markers for many cell types across multiple organisms.\n \nreply",
      "It still not 100% accurate but it should be useful for baseline annotations.\n \nreply",
      "I'm surprised that this is using plain llama3.1 rather than a fine-tune. Have you checked the accuracy of the results on the common benchmarks? Also, given it provides just the answers just based on the up/down lists, (or did I miss something?) isn't that something that could be extracted into a more efficient lookup with only a 2d grid of weights? (Or 3d if we there are group-of-genes effects)\n \nreply",
      "I don\u2019t have any benchmarking yet, but any help is appreciated. We do have fine-tuned model for anyone interested.\n \nreply",
      "This is looks very cool and extremely useful; where can I get hands on the fine-tuned model?\n \nreply",
      "Do you have any benchmark comparisons to e.g. the CellTypist corpus?\n \nreply",
      "No, but the help is appreciated!\n \nreply"
    ],
    "link": "https://github.com/CelVoxes/ceLLama",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Cell type annotation with local Large Language Models (LLMs) - Ensuring privacy and speed with extensive customized reports\n      ceLLama is a streamlined automation pipeline for cell type annotations\nusing large-language models (LLMs).ceLLama is ideal for quick and preliminary cell type checks!NoteCheck the tutorial for Scanpy example.To install ceLLama, use the following command:Download Ollama.Select your preferred model. For instance, to run the Llama3 model, use\nthe following terminal command:This initiates a local server, which can be verified by visiting\nhttp://localhost:11434/. The page should display \u201cOllama is running\u201d.Load the required libraries and data:Identify cluster markers:Run ceLLama:TipIncrease temperature to diversify outputs. Set different\nbase_prompt to customize annotations.Transfer the labels:Generate detaile"
  },
  {
    "title": "50th anniversary of Vannevar Bush's passing (thetech.com)",
    "points": 3,
    "submitter": "ricksunny",
    "submit_time": "2024-07-28T22:47:28",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://thetech.com/2024/07/11/anniversary-vannevar-bush-passing",
    "first_paragraph": "An approaching anniversary date of former MIT Chairman and Dean of Engineering Dr. Vannevar Bush prompts me to write today. As his sole biographer has just highlighted in IEEE Spectrum, this Friday will mark 50 years since the Jun. 28, 1974 passing of this individual whose footprint looms large on global history [1].\u00a0Two decades into a business-technical career since graduating provide me the perspective to take stock of the engineering institution I trained in, leading inevitably to studying Vannevar Bush's undeniable influence on that institution. The recent Oppenheimer film, which featured Bush in blink-and-you\u2019ll-miss-it cameos, also piqued interest. What I learned about the man at once impressed, intrigued, but also dismayed me for reasons that will become clear below.It seems most Institute stakeholders (going by the responses of fellow alums I have spoken with on it) know as little about who Vannevar Bush was as I did at the outset of my studying. Nor are they aware of the enorm"
  },
  {
    "title": "How to debug your battery design (github.com/ionworks)",
    "points": 268,
    "submitter": "tomtranter",
    "submit_time": "2024-07-28T01:39:06",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=41090658",
    "comments": [
      "> If you collect 3 different data points changing each thing one at a time (original design, some number higher, some number lower) whilst keeping everything else constant (usually a good scientific approach) that's 320 possible combinations of changes!There is an entire field of statistics (Design of Experiments) where one of the first lessons you learn on day one is how one-factor-at-a-time testing is one of the most inefficient ways you can test something. It\u2019s usually only done out of ignorance to better methods by those with little to no formal statistical training.An experiment designed by someone who is well versed in modern experimental design methods would not take billions of runs to optimize\u2014a sequential design that first screens out factors to those that matter (basic Pareto principle) followed by a response surface design or a GP model surrogate to optimize the response would likely be on the order of hundreds (possibly thousands) of runs. This is basic industrial experimentation\u2014see \u201cDesign and Analysis of Experiments\u201d by Douglas C. Montgomery for a nice introductory textbook.\n \nreply",
      "Yes completely agree. This is one of the things that PyBaMM doesn't do for you out of the box. I could have extended the article in many ways to cover all the optimizations you could do both with the physical battery or the model. Thanks for sharing the text book. I think my point which I should have stated more clearly was that maybe for smaller design spaces this might not be a bad approach but with batteries the space is huge. I co-authored a paper on optimally reaching the Pareto front using the and problem as an example actually. may be interesting reading for anyone else coming to this area. https://www.sciencedirect.com/science/article/abs/pii/S03062... Happy to share the pdf with anyone who wants to read the whole thing\n \nreply",
      "Related topic there is this example combining PyBaMM and pints for sensitivity analysis. Which should definitely be done first before delving straight into a DOE https://github.com/pints-team/electrochem_pde_model\n \nreply",
      "> one of the first lessons you learn on day one is how one-factor-at-a-time testing is one of the most inefficient ways you can test somethingIsn't that just called unit testing?\n \nreply",
      "Completely unrelated concept: unit testing is part of a regression testing framework while OFAT is a (almost always suboptimal) test strategy for designed experiments.See:https://en.m.wikipedia.org/wiki/One-factor-at-a-time_method\n \nreply",
      "I\u2019ve been on a journey to learn a bit about battery tech by building my own \u201csolar generator\u201d. Terrible name, but something like a jackery or blue yeti.I acquired 4 lithium iron phosphate cells along with a bms, solar charge controller and various doodads.I had to learn about balancing the cells, wiring, etc. it\u2019s been a bit of a rabbit hole for sure.I ended up building 1.2kwh battery for powering my fridge  and lights while camping. For less than half the price of an equivalent off the shelf unit. Of course it has taken an enormous amount of learning, but that\u2019s free.One the more interesting revelations to me, is how much I under appreciated industrial design before. On the first glance a device like a battery pack is a square box with a couple of outlets but I\u2019ve certainly had a difficult time making it look nice. Internal component wiring is also an interesting challenge.\n \nreply",
      "My senior design project for mechanical engineering was swapping lead acid batteries in an electric skateboard for nickel metal hydride (2008 lithium battery prices were not within a college budget).It gave me a new found appreciation for battery tech and I still feel a bit like they\u2019re incomprehensible magic boxes.My proudest part of the project was: we didn\u2019t have money for high end voltage or current recording devices and the amps of the thing was quite high. I zip tied a volt meter and an analog current gauge to a piece of plywood, then we mounted a 2x4 at a 90 degree angle and attached a camera to that. We used that setup to take video when we were riding. It let us correlate the time and other units together. By watching the video and manually recording the results into a spreadsheet.Not fast or high precision but it worked well and most importantly was within budget.\n \nreply",
      "Now that we have DMMs that have QR code displays you don't need to manually transcribe. All joking aside, I have generated telemetry data and displayed via a QR code for exactly this application. Documenting here as prior art so it can't be patented.A system and method for displaying time series data from any data-generating device as a Quick Response (QR) code, enabling efficient data extraction from video recordings. This invention facilitates the capture and analysis of time series data without manual transcription across a wide range of applications.\n \nreply",
      "Can you publish details (or a link thereto) to solidify the prior art?  IIRC, not only the fact of success but also the methods used must be published to establish prior art.One of the best ways to do this may be to file a Provisional Patent application.  It costs $100, and is a write-up of the outline and methods/technology used.  The patent office does nothing but leave it in a drawer.  If you file a proper patent application referencing it within 365 days, then it becomes part of the new patent and holds your priority date.  If you don't then the contents of the Provisional Patent app becomes public domain - now fully and authoritatively documented public domain.\n \nreply",
      "Nice! I love the simple approach like the story which I'm not sure if it's true or not that NASA spent $$$ developing an ink pen that would work in zero-g and the Russians used a pencil.\n \nreply"
    ],
    "link": "https://github.com/ionworks/how-to-debug-your-battery",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A guide on how to understand the performance of your battery with modelling and improve it\n      [ N.B I have edited the title to emphasize this is more a theoretical exploration of battery design than practical advice to fix your hardware issues - sorry to disappoint those coming for the latter ]Picture the scene, you're an engineer at an electric vehicle company and your boss comes to you and says: \"Jeremy we've got a problem!\" (your name is Jeremy by the way) \"It's these damn batteries, there's just too many of them in the car and it's weighing us down but we really want our customers to be able to drive 400 miles without having to stop and charge!\" - What do you do? How do you debug your battery? It's a black box of magic right?!? Wrong. Use simulation.It seems like there's no good solution in the market today. Batteries are eit"
  },
  {
    "title": "The irrational hungry judge effect revisited (2023) (cambridge.org)",
    "points": 189,
    "submitter": "fzliu",
    "submit_time": "2024-07-28T07:35:11",
    "num_comments": 138,
    "comments_url": "https://news.ycombinator.com/item?id=41091803",
    "comments": [
      "I believe the original studies were shown to be faulty because they didn\u2019t account for the fact that the cases were ordered. Less severe cases were seen first, which meant the more severe cases (ie those with more severe penalties) were shown later.\u201cDanziger etal. rely crucially on the assumption that the order of the cases is random and, thus, exogenous to the decision-making process. This assumption has been forcefully challenged. For a short and very critical reply in PNAS, Keren Weinshall-Margel and John Shapard analyzed the data of the original study\u2014as well as other self-collected data\u2014and conducted additional interviews with the court personnel involved.Footnote  51 They point out that the order of the cases is not random: The panel tries to deal with all cases from one prison before a break, before then moving to the cases of the next prison after a break. Most importantly, though, requests from prisoners who are not represented by a lawyer are typically dealt with at the end of each session. So, prisoners without legal representation are less likely to receive a favorable decision compared to those with legal representation.Footnote  52 Additionally, lawyers often represent several inmates and decide on the order in which the cases are presented\u2014it might well be possible that they start with the strongest cases\u201d[1] Chatziathanasiou, K., 2022. Beware the lure of narratives:\u201chungry judges\u201d should not motivate the use of \u201cartificial intelligence\u201d in law. German Law Journal, 23(4), pp.452-464.\n \nreply",
      "> the fact that the cases were ordered. Less severe cases were seen first, which meant the more severe cases (ie those with more severe penalties) were shown later.Isn't that order creating a bias for the judge? Should the cases be randomized instead?\n \nreply",
      "Yes, in the words of the linked paper it injects exogenous decision making. In other words, the decision is based on more than just the judge so we can\u2019t conclude the discrepancy is due to the judge\u2019s personal bias.\n \nreply",
      "Yeah thats the original point but I think he means aside from that, the order itself also drops a suggestion to the judge as to the nature of the case before hearing it.The order itself might be injecting a subconscious bias to the judge.\n \nreply",
      "That\u2019s good point. The authors of the original papers the \u201chungry judge\u201d idea also did work on what they call \u201cpriming\u201d which would include what you suggest. I don\u2019t know if that has been replicated though.\n \nreply",
      "Maybe? I don\u2019t think the severity of a case is unknown to the judge, though, even with random ordering.\n \nreply",
      "If they are ordered by severity, with the most severe coming just before lunch, the implication is the harsher sentencing is due to the ordering rather than the hunger pangs of the judge. Ie the hunger thesis is a spurious correlation.\n \nreply",
      "I wonder if this butts up against the fourth and fifteenth amendments, which touch on due process and justice not being delayed unnecessarily.Randomness introduces inefficiency which implies delay\n \nreply",
      ">Randomness introduces inefficiency which implies delayThat assumes that the previous arrangement, in the form of sequential escalation, was a pre-existing state of nature that came at no cost of effort. And that randomness has to be introduced after the fact, at a new and extra cost.But I think if cases were ordered without any specifically intended sequence of any kind, that starting point would be closer to randomness than the currently existing escalation. So randomness would cost less, not more.\n \nreply",
      ">Randomness introduces inefficiencyWhat does that even mean in this context? \nThe amount of cases to be processed doesn't change regardless of the order, and the amount of time and attention directed toward each shouldn't either, otherwise you have a much bigger issue.\n \nreply"
    ],
    "link": "https://www.cambridge.org/core/journals/judgment-and-decision-making/article/irrational-hungry-judge-effect-revisited-simulations-reveal-that-the-magnitude-of-the-effect-is-overestimated/61CE825D4DC137675BB9CAD04571AE58",
    "first_paragraph": "Last updated 10th July 2024: Online ordering is currently unavailable due to technical issues. We apologise for any delays responding to customers while we resolve this. For further updates please visit our website https://www.cambridge.org/news-and-insights/technical-incidentWe use cookies to distinguish you from other users and to provide you with a better experience on our websites. Close this message to accept cookies or find out how to manage your cookie settings.\nPublished online by Cambridge University Press:\u00a0\n01 January 2023Danziger, Levav and Avnaim-Pesso (2011) analyzed legal rulings of Israeli parole boards concerning the effect of serial order in which cases are presented within ruling sessions. They found that the probability of a favorable decision drops from about 65% to almost 0% from the first ruling to the last ruling within each session and that the rate of favorable rulings returns to 65% in a session following a food break. The authors argue that these findings pro"
  },
  {
    "title": "Show HN: I made a tool to receive alerts when answers change (alertfor.com)",
    "points": 66,
    "submitter": "saran945",
    "submit_time": "2024-07-28T13:55:02",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=41093161",
    "comments": [
      "A public demo of some kind is necessary. I saw nothing that was available to view without registration. This made me lose interest very quickly.Even a quick screenshot would be better than nothing.\n \nreply",
      "Made a quick video/demo and added in the home page. Hope this helps to understand the product.\n \nreply",
      "my bad, Sure, will make one and upload soon. I did not expect this much interest.\n \nreply",
      "I went and looked up the library I didn't know and learned a lot.A demo would be nice too but I might not have done that otherwise.\n \nreply",
      "Some public Alerts would be cool to showcase the idea. Potentially publicly visible alerts could be free.A generic version of https://istheshipstillstuck.com/\n \nreply",
      "Typically users prefer to have their Queries private, may be I should add public/private flag, and make all public alerts as searchable/free to follow. Thank you for suggestion.\n \nreply",
      "That's your Premium tier right there\n \nreply",
      "The page would benefit a lot from an example or two.\"Who is the current NBA champion?\"\"How many MPs do the Toddies have?\"\n \nreply",
      "I linked to my tweet from home page - https://x.com/saran945/status/1815053542610067487it has some advanced usage examples. you are right, I will add some sample questions at home page. Thank you.\n \nreply",
      "X only shows the single linked tweet, not the thread or comments, to users that are not logged in. It's not a good way to share information on the web anymore, if it ever was.\n \nreply"
    ],
    "link": "https://www.alertfor.com/",
    "first_paragraph": "\nAsk a Question: Submit your detailed query. \nTrack the Answer: Alertfor finds the most relevant answer on the web.\nStay Updated: Receive continuous updates whenever the answer changes.\n\n\n            Create account\n          \n\n            Sign In\n          \n\n\n            Demo/Tweet\n          \n\n          Free During Beta.\n          \n\n\nQuestions Asked : 131\n            \n\nAlerts Created: 848\n            \n\nTealme \u2014 Copyright 2024"
  },
  {
    "title": "FurtherAI (YC W24) is hiring founding software engineers in the Bay Area (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-07-28T21:01:15",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/furtherai/jobs/YZZvimn-founding-software-engineer",
    "first_paragraph": "AI workforce for insurance industryAs the founding software engineer at FurtherAI, you'll play a pivotal role in building the core product while also spearheading efforts to ensure scalability, optimize performance, and continuously improve the product to meet evolving needs and challenges.This is an in-person role based in San Francisco, CA. Remote exception (within USA) can be given for exceptional candidates.LLMs are great at getting 80% of the work done but are notoriously difficult to go from 80% \u2192 100%. We incorporate various technical and product strategies to tame these nondeterministic creatures.Tech challengesProduct challengesAt FurtherAI, we are building a workforce of AI Teammates to automate insurance workflows. These AI Teammates can practically automate any insurance workflow involving processing unstructured documents, data entry into internal systems or web portals, or even making phone calls.Our core mission is to answer a critical question: Can AI be made as reliabl"
  },
  {
    "title": "Microsoft technical breakdown of CrowdStrike incident (microsoft.com)",
    "points": 194,
    "submitter": "nar001",
    "submit_time": "2024-07-28T19:55:42",
    "num_comments": 204,
    "comments_url": "https://news.ycombinator.com/item?id=41095530",
    "comments": [
      "> We plan to work with the anti-malware ecosystem to take advantage of these integrated features to modernize their approach, helping to support and even increase security along with reliability.> Providing safe rollout guidance, best practices, and technologies to make it safer to perform updates to security products.> Reducing the need for kernel drivers to access important security data.They are being as diplomatic as they can, but it's definitely a slap to CS. Read as \"they don't know how to roll things out, they need guidance on basic QA practices, we'll happily teach them...\". Then, they list a set of facilities running in user-mode to avoid needing to run as many things in kernel mode.I would be interested what the water cooler discussion about CS was like inside Microsoft. Especially in teams needed to respond to customers about \"Your windows OS is broken, our hospital patients are suffering...\".\n \nreply",
      "this isnt even the first time its happened.  Crowdstrike has killed an OS every month for the past four months.At this point they are a threat actor.  if you havent kicked their amateur-hour software out of your infrastructure by now, chances are good senior management and engineering have at least considered it formally.https://en.wikipedia.org/wiki/CrowdStrike#Severe_outage_inci...\n \nreply",
      "That incident list is damning.  Is senior leadership asleep at the wheel, or how can this many incidents possibly happen every 30 days for months on end?  If leadership really cared, they'd make sure post-mortems and other best practices are in place to reduce the frequency.Unfortunately, the executive disconnect isn't new.  It's actually uncommon that they care about the reality for end users and customers (which is antithical to my entire ethos, hence why I get paid the medium bucks).  Why bother waking up and going to work everyday unless you are contributing in some way to sustaining a better future for everyone?  It's actually great for marketing and it's already going to be a tough 100+ years from today for our children, even with our collective care.P.s. People can be so selfish, it kind of breaks my brain but not really.  Have you seen the CO2 emissions visualization from NASA this week?'Tremendous' NASA Video Shows CO2 Spewing from US into Earth's Atmosphere https://www.newsweek.com/nasa-video-carbon-dioxide-co2-emiss...It's concerning.. and caught no traction.. http://news.ycombinator.com/item?id=41064029\n \nreply",
      "I can tell you they\u2019re quite unhappy about it. Have a friend working there who frustratedly says it wasn\u2019t their fault every-time it comes up. Which is quite often and at every social occasion since.\n \nreply",
      "but it's kind of their fault? they designed the api that way, they decided what can be done in userland and what must be done via kernel. they at least _allowed_ it to happen every time.\n \nreply",
      "> they designed the api that way, they decided what can be done in userland and what must be done via kernelThey didn\u2019t have much of a choice - it is very hard to get adequate performance with real-time filesystem filtering without doing it in kernel mode. Not aware of any other mainstream OS which succeeds at that.And they kind of had to provide this feature, since they\u2019ve supported it since forever (antivirus vendors were already doing it back in the days of MS-DOS and Windows 3.x/9x/Me), and there is a lot of market demand for it. It is easy for Linux to say \u201cno\u201d when it never has had support for it (in official kernels)But, as the blog post points out, it sounds like CrowdStrike is doing a lot of stuff in kernel mode that could be done in user mode instead - whether due to laziness or lack of investment or lack of sophistication of their product architects> they at least _allowed_ it to happen every timeMicrosoft, in allowing third party code to be loaded into their kernel, is no different from other major OS kernels, such as Linux or Apple XNU.Apple is (increasingly) the most restrictive about this, and a lot of people criticise them for it.Even Linux imposes some restrictions-which kernel symbols to export (at all or as GPL-only)\u2014although of course being open source, you can circumvent all restrictions by changing the code and recompiling\n \nreply",
      "Mac and Linux run EDRs in userspace without an issue. No one here has an excuse or no choice.\n \nreply",
      "Linux these days tends to use eBPF which isn't really in userspace per-se.\n \nreply",
      "eBPF is like the Twilight Zone. I'm in kernel space but, I'm not.\n \nreply",
      "eBPF is Linux denying the fact that it's turning into a microkernel and that Linus was wrong.\n \nreply"
    ],
    "link": "https://www.microsoft.com/en-us/security/blog/2024/07/27/windows-security-best-practices-for-integrating-and-managing-security-tools/",
    "first_paragraph": "Windows is an open and flexible platform used by many of the world\u2019s top businesses for high availability use cases where security and availability are non-negotiable.To meet those needs:In this blog post, we examine the recent CrowdStrike outage and provide a technical overview of the root cause. We also explain why security products use kernel-mode drivers today and the safety measures Windows provides for third-party solutions. In addition, we share how customers and security vendors can better leverage the integrated security capabilities of Windows for increased security and reliability. Lastly, we provide a look into how Windows will enhance extensibility for future security products.CrowdStrike recently published a Preliminary Post Incident Review analyzing their outage. In their blog post, CrowdStrike describes the root cause as a memory safety issue\u2014specifically a read out-of-bounds access violation in the CSagent driver. We leverage the Microsoft WinDBG Kernel Debugger and se"
  },
  {
    "title": "A man's brain is like a little empty attic (1887) (virginia.edu)",
    "points": 23,
    "submitter": "yamrzou",
    "submit_time": "2024-07-28T20:21:43",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41095697",
    "comments": [
      "Related:The brain is a closet (2009) \u2014 https://news.ycombinator.com/item?id=34831330\n \nreply",
      "Useful for a specialist in a job that changes little and is always on demand.\n \nreply",
      "Not related but funny:Men's Brains and Women's Brains with Mark Gungor (Nothing Box)\nhttps://youtu.be/SZ6mVumHY9I?si=vWEyWbKcai0tW3CH\n \nreply",
      "But is that true? Do new facts elbow out the old ones?\n \nreply",
      "The wise man deliberately inhibits learning in order to not forget what he already knows?Sounds unwise.\n \nreply",
      "Sherlock Holmes is a fictitious character that also makes use of investigative techniques such as phrenology and tobacco ash species identification, make what you will out of that.\n \nreply",
      "\"What's the name of a bird?\"https://youtu.be/ga_7j72CVlc?t=18\n \nreply"
    ],
    "link": "http://metaphors.iath.virginia.edu/metaphors/17736",
    "first_paragraph": "\"You see,  he explained, I consider that a man's brain originally is like a little empty attic, and you have to stock it with such furniture as you choose.\"\u2014 Doyle, Arthur Conan (1859-1930)The Mind is a Metaphor is authored by Brad Pasanek, Assistant Professor of English, University of Virginia."
  },
  {
    "title": "The Ridgeway: The 5k-year-old pathway that's Britain's oldest road (bbc.com)",
    "points": 89,
    "submitter": "andsoitis",
    "submit_time": "2024-07-24T13:47:44",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41057088",
    "comments": [
      "Interestingly (to me), I learned about the \"ridgeway\" just a few days ago, from Jim Leary's episode on the \"History Rage\" podcast, where historians vent about popular historical misconceptions.For the Ridgeway in particular, the claim from the podcast is that there is in fact no archaeological evidence that this was a prehistoric routeway, nor that it was a single coherent long-distance entity. The claim is that it appears this way because highland areas and ridges are better preserved, because they're generally not cultivated and are less subject to erosion, so the whole thing is just a selection effect.Discussion starts around 39:25 in the podcast[1]Jim Leary has a book about this, \"Footmarks: A Journey into our Restless Past\"[2].To be fair, I personally am ill-equipped to assess the claim, and it does look like an interesting place to ramble. The linked article also, to continue being fair, does not call it a road, they limit themselves to calling it a \"prehistoric trackway\", which may well be defensible.[1] https://www.historyrage.com/episodes/episode/69e607e6/histor...[2] https://uk.bookshop.org/p/books/footmarks-a-journey-into-our...\n \nreply",
      "It's a nice place to walk, either way.I walked part of the way about (oh dear) twenty years ago and arrived in Stonehenge for the summer solstice bash. That was fun.\n \nreply",
      "The Ordnance Survey route, map, and landmarks https://getoutside.ordnancesurvey.co.uk/guides/the-ridgeway/\n \nreply",
      "I also found it in OpenStreetMap: https://www.openstreetmap.org/relation/8879 Makes it much easier to zoom in.\n \nreply",
      "I was just coming here to question how the article doesn\u2019t include a map.\n \nreply",
      "Nice to see something from my home area on HN!  I think it's a bit of a stretch to say it heads diagonally though.  It meanders rather a lot.\n \nreply",
      "Looks great for bikepacking.\n \nreply",
      "The King Alfred's Way bikepacking route [1] includes part of the Ridgway. I planned to do this last summer, but didn't get chance, and I'm not really fit at the moment enough having barely cycled since last summer, but maybe I'll get around to doing this next year. It does look like a great route though.[1] https://www.cyclinguk.org/king-alfreds-way\n \nreply",
      "More on King Alfred and The Ridgeway:https://www.youtube.com/watch?v=KqS_ev58MRg#t=2m45s\n \nreply",
      "I bike packed this route with a good friend 2 years ago and had an absolutely amazing time. Neither of us were super fit but we managed it comfortably in 4 days (although our route planning left a little to be desired - 90 miles in one day along the Ridgeway was a mistake).The Ridgeway itself was arguably the most challenging part of King Alfred's way - a couple of large climbs, plus large sections of very rocky terrain made it tough going at points.Overall though, a beautiful route and I would highly recommend it!\n \nreply"
    ],
    "link": "https://www.bbc.com/travel/article/20240723-the-ridgway-hike-the-5000-year-old-pathway-thats-britains-oldest-road",
    "first_paragraph": "Walk in the footsteps of Celtic druids, Saxon kings and Victorian poets on an 87-mile prehistoric trackway that cuts across the chalk hills of southern England.It was 10:00 before I saw another person, a lone dog walker in the vicinity of Barbury Castle, an Iron Age hill fort that sits commandingly atop a rise on the Ridgeway, an 87-mile prehistoric trackway widely recognised as Britain's oldest road.I'd set off more than two hours earlier from Avebury in Wiltshire, revelling in my newfound solitude while, at the same time, finding it increasingly difficult to believe that I was walking through such a densely populated region. From the backseat of a car, England's southern counties resemble an untidy muddle of motorways, high streets and housing estates. But up on the chalky heights of the North Wessex Downs, I was being treated to an infinitely more tranquil view.As I progressed north-east along the rounded ridgetops, I gazed out over distant villages, bushy hedgerows and rolling gree"
  },
  {
    "title": "Back to our roots (honnibal.dev)",
    "points": 93,
    "submitter": "saeedesmaili",
    "submit_time": "2024-07-28T09:32:35",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41092168",
    "comments": [
      "The bit that sticks out in the story is this:Justin and Sebasti\u00e1n left the company with the transition to investmentObviously a ton of context is missing but if you are planning to stake the future of your company on a product that had until now been developed by these two gentlemen why weren't they going to be part of that future?One thing I have grown an appreciation for over the years is the power of very small teams, i.e groups of less than ~4 or so. When you have a very small number of very capable people you can paper over a lot of deficiencies.Overall though a very realistic view into what it's like trying to scale up a startup. If it's any consolation most of them blow up just like this, don't feel bad if this is a pattern you recognise from your past - it's just how it is. The game is hard and failure is expected, scale ups are by far the most vulnerable time in a companies history and yet you need multiple of them to \"make it\" and each one is completely different from the last.\n \nreply",
      "wow what a candid, and humble take! Really impressive. Lots to be learned here.However, one thing I am curious about is how their VC investor, SignalFire, is ok with this \"back to it's roots\" terminus. Do they still own the same amount of the company as before?\n \nreply",
      "There is some info on Honnibal's Twitter (https://x.com/honnibal/status/1813650728222880157):Delip Rao: Curious how do you go back from VC funded to bootstrapped? Did you return money to investors? And were they okay with just that? Regardless, I am happy you are doing more lib dev.  You have very good taste.Matthew Honnibal: There's no change in ownership, it's just that we don't have any more VC money to spend --- so the operating reality is like it was before. We think it's helpful to explain this.Delip Rao: So if you consult and do other stuff as Explosion to bring money in, you have to pay distribution of the profits to the shareholders on your cap table?Matthew Honnibal: If we ever pay a dividend, all shareholders will get some, (and the VCs have liquidation preferences that mean they'd take a larger share than their ownership until the money is paid back). But we're some distance away from dividends -- we'd pay ourselves a salary from consultingDelip Rao: That's right. I am surprised your VCs were okay with this arrangement. Usually, they nudge the company towards an acquihire in such situations.\n \nreply",
      "The title is a little misleading. They raised $6 million from SignalFire (who also invested in Grammarly) for 5% of the company [1]. As SignalFire retains that shareholding, they are not less independent (nor more) than that have been in the past couple of years. They are just not looking for more investment and so are more \"independent-minded\".I used SpaCy quite expensively pre-2020. It still has a lot of great uses, and more predictable than LLM models. But now many NLP tasks that seemed near impossible, or required a lot of expensive annotated training data (which their product Prodigy is used for)  can now be coded in very little time with LLMs.[1] https://explosion.ai/blog/weve-sold-5-percent-of-explosion\n \nreply"
    ],
    "link": "https://honnibal.dev/blog/back-to-our-roots",
    "first_paragraph": "For most of Explosion\u2019s life we\u2019ve been a very small company, running off revenues. In 2021 that changed, and we became a slightly less small company running off venture capital. We\u2019ve been unable to make that configuration work, so we\u2019re back to running Explosion as an independent-minded self-sufficient company. We\u2019re going to stay small and not look for any more venture capital. spaCy and Prodigy will continue.We have an announcement post up on the company blog that lays out what this means for our various projects, but I know people will also want to know more about the how and why. These things are easier to talk about from a personal perspective, so I decided to make a separate post.Starting spaCy and founding ExplosionI started work on spaCy in 2014. Before I started I had been researching syntactic parsers during my PhD and as a post-doc, and I saw that the Python ecosystem really didn\u2019t have an NLP toolchain suitable for most companies. The largest companies like Google or Micr"
  },
  {
    "title": "StreamPot: Run FFmpeg as an API with fluent-FFmpeg compatibility, queues and S3 (github.com/streampot)",
    "points": 126,
    "submitter": "thunderbong",
    "submit_time": "2024-07-28T04:09:04",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=41091163",
    "comments": [
      "Seeing the need for polling the job status is off putting, especially for a js api that already is using async. If you _need_ to use polling, at least provide a convenience method I can just await. Better yet, add some signaling to the http api via eventsource or something.\n \nreply",
      "Thank you! We do have one - `runAndWait`. I will shortly update the docs and I agree that using SSE would be more efficient than polling. Will add that next!\n \nreply",
      "Long polling would be cool!\n \nreply",
      "Highly prefer and recommend websocket connections for polling. This is what I ended up doing for my side project's video encoding needs[1]. It lets me get silky smooth progress indicators on multiple encoding resolutions at once.[1] https://github.com/jjcm/nonio-video-cdn/blob/master/route/en...\n \nreply",
      "Do you mean over* polling (instead of polling)? Polling (repeatedly asking the server) and pushing (the server telling you directly) are two different things; polling over WebSocket seems sort of weird.\n \nreply",
      "This is great, I don't have a concrete use-case right now but can definitely see myself returning to this in the future. One thing that would be handy is having a way to either accept a ffmpeg cli command, or convert from a cli command to the typescript syntax. My experience with ffmpeg if you often do a lot of copying and pasting of commands from documentation or random guides, it'd save a bit of time if you didn't need to transcribe the commands into streampot's syntax.\n \nreply",
      "Jack from StreamPot here. So happy to see it shared here. We'd love you to try it out and give us any feedback or requests.\n \nreply",
      "Somebody please bring fully functional ffmpeg to Android via F-Droid please, one which is not compiled against /storage/emulated/0/ like Termux, etc, are.  Many users rely on multiple profiles and don't run anything in the primary profile.  I know of nothing right now like this.  No FFshare doesn't work for purpose as outlined.Bonus if all of Termux can be fixed for secondary Android profiles,\n \nreply",
      "Looks really cool. I've thought about building a business around ffmpeg myself. Btw, your self hosting link is broken.\n \nreply",
      "Thanks! Oops, good spot. Updated it. \nThis is where it was supposed to go https://docs.streampot.io/installation.html\n \nreply"
    ],
    "link": "https://github.com/StreamPot/StreamPot",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Run ffmpeg as an API with fluent-ffmpeg compatibility, queues and S3 storage.\n      NoteStreamPot is still in the early stages of development, we would appreciate your feedback.StreamPot is a project that provides scaffolding for transforming media in your app (e.g. trimming a video, stripping the audio from a video, transcoding a video from mp4 to webp).We are building this because an increasing number of projects are transforming media as part of their workflow.If you want a no-setup way to run this, check out StreamPot.Visit the Installation (server) page for self-hosting instructions.\nIf you'd like to use the hosted version, please sign up and give it a try.Note: You should only run this from your server.This project is heavily reliant on the amazing work of the ffmpeg and fluent-ffmpeg teamsIf you want to use StreamPot in your "
  },
  {
    "title": "Counting Lines of Code (andrewpwheeler.com)",
    "points": 4,
    "submitter": "apwheele",
    "submit_time": "2024-07-24T17:18:57",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://andrewpwheeler.com/2022/12/14/counting-lines-of-code/",
    "first_paragraph": "Was asked recently about how many lines of python code was in my most recent project. A simple command line check, cd into your project directory and run:(If on windows, you can download the GOW tools to be able to use these same tools by default available on unix/mac.) This will include whitespace and non-functional lines (like docstrings), but that I think is ok. Doing this for my current main project at Gainwell, I have about 30k lines of python code. Myself (and now about 4 other people) have been working on that code base for nearly a year.For my first production project at (then) HMS, the total lines of python code are 20k, and I developed the bulk of that in around 7 months of work. Assuming 20 work days in a month, that results in around 20000/140 ~ 143 lines of code per workday. I did other projects during that time span, but this was definitely my main focus (and I was the sole developer/data scientist). I think that is high (more code is not necessarily better, overall code "
  },
  {
    "title": "Intel N100 Radxa X4 First Thoughts (bret.dk)",
    "points": 195,
    "submitter": "geerlingguy",
    "submit_time": "2024-07-27T22:51:57",
    "num_comments": 168,
    "comments_url": "https://news.ycombinator.com/item?id=41089911",
    "comments": [
      "At $60 - its able to run anything x86, plus hardware transcoding and a cpu about 3x more powerful than a RPI 5,  not sure why anyone would even want a raspberry pi.  Not to mention the built in 2.5G nic with PoE and m.2 slot.   Adding a PoE and m.2 hats on a raspberry pi would add another $25-40 to the price. Hope they ramp up production on these Radxa boards.Edit: another source with better image of the form factor. It might actually fit a raspberry case.https://www.cnx-software.com/2024/07/19/radxa-x4-low-cost-cr...\n \nreply",
      "The Radxa X4 is already sold out and pulled from listings by the manufacturer. I expect massive markups for awhile just the RPi 5.\n \nreply",
      "The issue with a raspberry case is that N100 Radxa boards have the N100 on the bottom. That's where the heatsink has to go.\n \nreply",
      "According to your link, this board doesn't have built-in PoE, but requires an \"optional hat\". It links to a \"currently unavailable\" listing on Amazon, without any price info.However, I agree that if it costs as much as a RPI, it looks really great.\n \nreply",
      "the product page seems to indicate it has built in PoE https://radxa.com/products/x/x4/\n \nreply",
      "> the 40-pin GPIO header handled through a Raspberry Pi RP2040 microcontroller.This part would be a reason why: very low GPIO throughput since you're limited to what can be shoved through serial and it all has to be must be manually processed by the extremely slow RP2040. The main upside with something like a Pi 4 is that it has zero overhead access to it via kernel api, so you can pipe hilarious amounts of data through its pins or address i2c devices directly from python with existing libraries for almost every sensor, etc.The Pi 5 using it through a PCIe southbridge is quite a lot worse, especially since it broke all compatibility and it still can't even drive even a simple WS2812 led strip yet a year after release. They've thrown away the last 10 years of community support and development since the layout was standardized with the Pi 2.\n \nreply",
      "RO2040 isn\u2019t slow - it\u2019s literally one of the fastest on the market. It\u2019s a dual core microcontroller that can easily run both cores at 133-250+ MHz.https://github.com/Wren6991/PicoDVIThe GPIO on RPi is not very useful for precision work and you\u2019re limited to using SPI (usually to talk to an auxiliary microcontroller). The GPIO on RP2040 is so good that you can use it as 24 channel 100Msps logic analyzer in a pinch.https://github.com/gusmanb/logicanalyzer\n \nreply",
      "i've done the rant many times before [1] but frankly rpi has almost never made sense.  there were always things like the ECS Liva/Liva X for $100-125 that were fully-featured, for roughly the same price as a rpi once you consider all the shit you'll need to get that $45 computer booted up.  The Liva (and similar booksizes/net-tops, and similar things like AM1 platform from AMD) benefited hugely from using standard drivers and standard BIOS versus a massive amount of early ARM jank (the early RPi days a lot of things were actually soft-float, let alone niceties like UEFI!).the best argument for rpi has always been the combination of GPIO and linux.  But that's a double-edged sword too, because linux isn't really very good at hard-realtime.  And you can always just get a Bus Pirate or similar tool for doing just plain GPIO.  And nowadays the ESP32 has basically completely displaced it for a lot of those sorts of \"GPIO glue\" roles.If you didn't need that, like if you just wanted a low-power fileserver or HTPC... the x86 stuff was better, because it actually worked reliably, at roughly the same price.  Like literally just go buy an off-lease mini-tower or USFF mini-pc for $10 from a surplus store, even.This goes doubly when you consider all the problems with the early rpi.  Like basically it uses USB 2.0 (unidirectional 500mbps) as a system bus... but it also dropped USB packets under load due to bugs in the firmware[0], that nobody outside the Pi foundation could address because Broadcom didn't release the documentation for like 5 years.[0] https://github.com/raspberrypi/firmware/issues/19[1] https://news.ycombinator.com/item?id=40701297\n \nreply",
      "What I've ways felt was a major advantage for Raspberry Pi compared to all of the other SBCs is that the Pi actually got regular updates. Maybe other SBC manufacturers started doing that too since I first got my hands on a Pi, but it definitely didn't use to be the case.The ECS Liva would cost me \u20ac200 (\u20ac278 when avoiding webshops that look like scams) without memory. An RPi5B is \u20ac88. I don't think I'll get more than twice the use out of an ECS Liva if all I want to run is Pihole.And remember, the point of the Raspberry Pi was not to bring a cheap, high performance computer to prototypers. It was created to aid schools in teaching kids about computers. They've changed their tune ever since just about everyone with a computer project started buying out their reserves, but making things easy for professionals was not part of the plan from the start.If you have cheap access to better computers, make good use of that! I still find the RPi to be competitive for cheap, low-power compute, though.\n \nreply",
      "I partly agree, the RPi Zero W is my ideal small physical computer with a full OS. Running it only from the overlay filesystem (to keep those terrible SD cards from becoming corrupted). Pi-Hole I run from a docker container on a fanless NUC-a-like. But for anything that needs GPIO, the Zero W is great (nice that this Radxz has a RP2040 built in to cover that).\n \nreply"
    ],
    "link": "https://bret.dk/intel-n100-radxa-x4-first-thoughts/",
    "first_paragraph": ""
  }
]