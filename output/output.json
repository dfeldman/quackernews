[
  {
    "title": "Slow (michaelnotebook.com)",
    "points": 525,
    "submitter": "calvinfo",
    "submit_time": "2025-07-31T19:00:58 1753988458",
    "num_comments": 128,
    "comments_url": "https://news.ycombinator.com/item?id=44748934",
    "comments": [
      "I'm reminded of the famous story of (I think) the central beam in a building at Oxford. The story goes something like:The central beam was beginning to fail and the Oxford administration knew they needed to replace it. When they went around for quotes, no one could replace the beam because it was 100 ft in length and sourced from an old growth tree. Such logs were simply unavailable to buy. To solve the issue, the staff begin to look at major renovations to the building's architecture.Until the Oxford groundskeeper heard about the problem. \"We have a replacement beam,\" he said.The groundskeeper took the curious admins to the edge of the grounds. There stood two old growth trees, over 150 feet tall.\"But these must be over 200 years old! When were they planted?\" the admins asked.\"The day they replaced the previous beam.\"reply",
      "This is an urban legend. The college archivist covered it: http://web.archive.org/web/20020816065622/http://www.new.ox....> In 1859, the JCR told the SCR that the roof in Hall needed repairing, which was true.> In 1862, the senior fellow was visiting College estates on `progress', i.e., an annual review of College property, which goes on to this day (performed by the Warden). Visiting forests in Akeley and Great Horwood, Buckinghamshire (forests which the College had owned since 1441), he had the largest oaks cut down and used to make new beams for the ceiling.> It is not the case that these oaks were kept for the express purpose of replacing the Hall ceiling. It is standard woodland management to grow stands of mixed broadleaf trees e.g., oaks, interplanted with hazel and ash. The hazel and ash are coppiced approximately every 20-25 years to yield poles. The oaks, however, are left to grow on and eventally, after 150 years or more, they yield large pieces for major construction work such as beams, knees etc.reply",
      "But this urban legend must be over 150 years old! When was it created?reply",
      "Right after they consumed the previous rural legend.reply",
      "Ah yes, \"exacting young man debunks charming tale with touching moral, to the benefit of nobody\". A tale as old as time.reply",
      "Can't wait to see this story used on some growth hacker / seeking new opportunities LinkedIn post talking about planning for success.reply",
      "The funny thing is that 99% of the linkedin shills will miss the second crux of the allegory: To maintain the institutional knowledge for this to happen, you need to have a culture that nurtures employees, keeps them on long term and listens to them.  And gives them time to write good documentation for future-proofing.reply",
      "It's wild that they managed to retain this knowledge without a Confluence by Atlassian subscription (tm).reply",
      "\"A society grows great when old men plant trees in whose shade they know they shall never sit\" - Paraphrased from Elton Truebloodreply",
      "Which defines why American society seems to be F'ed of late. Decades of short term rewards combined with a baby boomer population looking at their last hoorah and declining relevance. Most of the old people I interact seem to be in a state of denial about soon not being here.reply"
    ],
    "link": "https://michaelnotebook.com/slow/index.html",
    "first_paragraph": "What problems can human beings only solve over a very long period of time? And how can we build institutions that solve those problems?Below is a list of marvellous projects which human beings have undertaken over an exceptionally long time. Many examples contributed by people on Twitter.The focus is on goal-directed projects (e.g., a scientific experiment or a building), less on more decentralized or unplanned changes (e.g., languages, domestication of livestock, cities, religions). Of course, those are also fascinating, but they have less of a sense of a long-term goal. Jericho is incredible, but the founders probably weren't thinking \"I hope this is still here in 9,000 years\".This page is a riff on Patrick Collison's list of /fast projects. There are surprisingly many commonalities with those projects.The proof of Fermat's Last Theorem involved an incredible amount of mathematics developed over decades and centuries: wikipedia.Many Cathedrals were built over more than a century. An "
  },
  {
    "title": "The anti-abundance critique on housing is wrong (derekthompson.org)",
    "points": 152,
    "submitter": "rbanffy",
    "submit_time": "2025-07-31T21:28:07 1753997287",
    "num_comments": 216,
    "comments_url": "https://news.ycombinator.com/item?id=44750416",
    "comments": [
      "So much of the journalism we read is heavily processed and barely-reported and it's startling to see how much of a superpower simple shoe-leather reporting actually is. Derek Thompson's an incredibly sharp writer, but not really a subject matter expert on housing economics; all he did here was read papers and call up the authorities they cited, and the narrative behind those papers collapsed.We're often so down on journalism on HN, and I believe a big part of that is we tend to read so much opinion and analysis and so little basic reporting.I've been loving Thompson's substack (which is mostly not about housing policy so far).reply",
      "Reporters used to start at something like the City News Bureau.[1] For a century, the City News Bureau covered local news for Chicago and sent it in to the local newspapers. Lasted until 2005. Young reporters started there, covering every police station, every major crime, every major fire, every major trial, and getting the facts right, or else. \nThe bureau`s unsentimental motto: \u201dIf your mother says she loves you, check it out.\u201dWe need that again. As I point out occasionally, read news, and ask yourself which stories started out as a press release. For the City News Bureau, nothing started as a press release. They had people pounding the streets of Chicago for a century. Today, the pundit to reporter ratio is far too high.There's a great book about the Bureau, called \"Hello, Sweetheart, Get Me Rewrite\". (by Dornfield, not the one by Sears, which is something else entirely.)[1][1] https://www.chicagotribune.com/1990/06/20/if-city-news-burea...[2] https://www.amazon.com/Hello-Sweetheart-Get-Me-Rewrite/dp/08...reply",
      "The problem is that nobody would pay for it. People expect news to be free, and click bait and lazy copy paste or LLM journalism is cheaper and works just as well to get clicks for ad dollars.Would people pay for real journalism?reply",
      "Don't people already pay for things like the NYT?I guess local papers might be harder, they may have to demonstrate they can reveal the journalistic failures of other papers in local affairs.reply",
      "NYT is an exception, or more specifically it's much bigger than most other news shops and has the luxury of having a  large loyal customer base, a brand reputation to defend, and a full time business analysis and data science team to upkeep its excellence. Your local papers are barely scraping by and are mostly owned by hedge funds whose primary objective to squeeze the consumer via judicial usage of paywalls and clickbaits. A commitment to truth and deep investigative reporting for them does not keep the lights on. The other papers and magazines are all subsidized by billionaires or other vested interests. The price for those is indoctrination.reply",
      "I would pay for real journalism.Unfortunately, what I see in practice (even excluduing the propaganda shops like Fox) is BS englightened centrism. No way I'm going to pay for a paper that platforms bad faith right wing arguments because \"we have to present both sides\".reply",
      "I think about this from time to time. Personally I would pay per article if it's convenient. I don't want to shell out $20/mo for, say, the Economist right now but if there was a particular article I wanted to read I'd probably pay a few bucks.The papers wouldn't go for it, but these days I can subscribe to individual writers I like on Substack rather than paying for a newspaper subscription and subsidizing content I don't care about. More bang for buck. People have to be met halfway.reply",
      "> We're often so down on journalism on HN, and I believe a big part of that is we tend to read so much opinion and analysis and so little basic reporting.I think a large part of it is that major news organizations too often don't do this kind of reporting, and often just seem to chase the same hot button topics as the rest of the crowd over and over again. And even then, few really dive into the details.You're larger point is entirely correct, that there's a ton to be learned from old school journalism, and there are people out there doing it. But it's unsettling how much of it only gets covered by citizen journalists doing this in their free time, not by professionals who are supposed to be doing this for a living.For example, the D.C. Attorney's Office had been simply dropping 2/3's of the criminal cases that came to them. No one noticed this until a anonymous internet account, DCCrimeFacts, went through the records and realized that this had been happening for years. Once that account wrote about it and it gained traction, major papers like the Washington Post started reporting on the story, it eventually ended up being an issue in Congressional hearings, and lead to changes in the way the U.S. Attorney's Office operates.The account spent a lot of time digging through records and reporting on issues with the criminal justice system you wouldn't find elsewhere. But it was someone's side project, and there haven't been posts in a year.Another example is the FAA scandal, when the best information has come from a single blog post by a law student who happened to go through the legal paperwork and was surprised that this hadn't been reported on.The professional news media outlets do have some good reporters, and sometimes there are important deep dives there as well. But they feel few and far between, usually opting to chase infotainment (or sometimes the pet projects of a particular journalist).It's amazing how many big stories we only get if some random citizen happens to spend their free time doing a personal journalism project, and if that project happens to get enough traction that people actually read it.reply",
      "I've been involved in a lot of discussions about \"what is journalism? what do real journalists do?\", and the best response I've heard was from Ian Betteridge (of Betteridge's Law fame), who told me \"Journalists pick up the phone.\" It may have already dated as a pithy description, but the idea of literally calling[1] people to fact-check or dig deeper is a low bar that a surprising amount of current journalism doesn't clear. And I say this as someone who has definitely done the non-journalism: just writing an opinion, or a column, or blog post, or whatever. Or, perhaps most insidiously, when you have a thesis for an article and you just collect the (partial) facts you need to flesh out that thesis.I know why people blame the internet, the drop in rewards for journalism, the pressures to churn out text, that has led to. But I'd also emphasise that it's a vocational skill that not everyone is built for, or trained to do. But it's as Thomas says, that scarcity means that it's still as valuable (and recognisable) as it always was.[1] Or emailing -- but emailing, and emailing, and emailing, then calling, and emailing again until you get an answer.reply",
      "> But I'd also emphasise that it's a vocational skill that not everyone is built for, or trained to do.Somewhat-related to another front-page item today about, how lots of jobs sound kind of crazy if you really detail them out: https://news.ycombinator.com/item?id=44710651reply"
    ],
    "link": "https://www.derekthompson.org/p/the-anti-abundance-critique-on-housing",
    "first_paragraph": ""
  },
  {
    "title": "Releasing open weights for FLUX.1 Krea (krea.ai)",
    "points": 191,
    "submitter": "vmatsiiako",
    "submit_time": "2025-07-31T13:41:45 1753969305",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=44745555",
    "comments": [
      "Nitpick: this is not open weights, this is weights available. The license restricts many things like commercial, NSFW, etc.reply",
      "I mean this started with Stable Diffusion 1.x->XL which were only loosely open, and has just gotten worse with progressively farther from open licensed image gen models being described as \u201copen weights\u201d, but, yes, Flux.1 Krea (like the weights-available versions of Flux.1 from BFL itself) is not open even to the degree of the older versions of SDXL. weights available and \u201cfree-as-in-beer licensed for certain uses\u201d, sure, but not open.reply",
      "Hello everyone.I\u2019m the Co-founder and CTO of Krea. We\u2019re excited because we wanted to release the weights for our model and share it with the HN community for a long time.My team and I will try to be online and try to answer any questions you may have throughout the day.reply",
      "Any plans to get into working with the Flux 'Kontext' version, the editing models?  I think the use cases of such prompted image editing is just wildly huge.  Their demo blew my mind, although I haven't seen the quality of the open weight version yet.  It is also a 12B distill.reply",
      "Hi. Thanks for this. What is your goal of doing so? From a business standpoint. Or is it purely altruistic?reply",
      "Haha-classic!It\u2019s simple: hackability and recruiting!The open-source community hacking around it and playing with it PLUS talented engineers who may be interested in working with us already makes this release worth it. A single talented distributed systems engineer has a lot of impact here.Also, the company ethos is around AI hackability/controllability, high-bar for talent, and AI for creatives - so this aligns perfectly.The fact that Krea serves both in-house and 3rd-Party models tells you that we are not that bullish on models being a moat.reply",
      "I can say that it's definitely working on me! I hadn't heard of Krea before, and this is a great introduction to your work. Thanks for sharing it.reply",
      "People underestimate how much goodwill companies gain from pushing opensource stuff out, not just from word of mouth but even picking up users for their commercial offerings too, while i could run opensource and appreciate it in a lot of cases using API's from the companies that i like (mostly ones that do opensource stuff) tends to be easier for bigger stuff...reply",
      "(unless the code repository and history is embarrassingly bad, which is most repositories)reply",
      "Hi! I'm lead researcher on Krea-1. FLUX.1 Krea is a 12B rectified flow model distilled from Krea-1, designed to be compatible with FLUX architecture. Happy to answer any technical questions :)reply"
    ],
    "link": "https://www.krea.ai/blog/flux-krea-open-source-release",
    "first_paragraph": "Try FLUX.1 Krea nowDownload the weights [22GB] on Hugging FaceView our repository on Github Today, we're releasing an open version of Krea 1, our first image model trained in\n\t\t\t\t\t\tcollaboration with Black Forest Labs\u00a0 to offer superior\n\t\t\t\t\t\taesthetic control and image quality. This checkpoint is a guidance distilled model fully\n\t\t\t\t\t\tcompatible with FLUX.1-dev\u00a0 allowing\n\t\t\t\t\t\tseamless integration with the existing ecosystem. FLUX.1-Krea [dev] has been distilled to\n\t\t\t\t\t\tmatch the quality of Krea 1 with a focus on preserving aesthetics and photorealism.Unlike most image models, FLUX.1 Krea has been created with opinionated aesthetics in\n\t\t\t\t\t\tmind. We focused on creating a model that truly fits our specific aesthetic preferences.\n\t\t\t\t\t\tIn this technical report, we'll share the process and learnings from developing this\n\t\t\t\t\t\tmodel, including insights on pre-training and post-training, as well as future research\n\t\t\t\t\t\tdirections.\u201cWhite owl, close up portrait, mysterious ghost like owl,"
  },
  {
    "title": "I made a website that makes you cry (cryonceaweek.com)",
    "points": 84,
    "submitter": "johnnymaroney",
    "submit_time": "2025-07-28T00:19:37 1753661977",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44705960",
    "comments": [
      "As if the news and state of the planet weren't enough.reply",
      "The amount of javascript I had to allow made me cry. Unfortunately browsing with No-Script seems to block much of the functionality. But otherwise a cool project!reply",
      "You can turn off such things for specific sites.reply",
      "I want this in literally every other emotion, except for anger, because there's already a site for that called reddit.comreply",
      "IT here.  I don't need a website; I have users.reply",
      "I miss alt.sysadmin.recoveryreply",
      "Twitter and facebook are far more effective for that.reply",
      "I think we can just kinda blanket-statement this and say all social media induces anger, yeah?reply",
      "All of them can but I don't think they are equal. Back before I deleted twitter about a year ago, no matter what I did, how many accounts I blocked, I'd get a feed of AI generated ragebait. Meanwhile TikTok and Youtube seem to respect my preferences more. There is ragebait on those platforms but it isn't shown to me. Facebook just seems to be entirely Boomers and Gen Xers angry at the news.Reddit has historically respected your subscriptions but it does look like they are drifting away and making the home page just whatever they want to show you.reply",
      "It'll not be long before the UK gov add crying to the online safety bill, so enjoy this while you can, people of the UK.reply"
    ],
    "link": "https://www.cryonceaweek.com",
    "first_paragraph": "Did this make you cry?Thank you for visiting! Come back in a week to cry again.\u200dEnter your email for our free eBook on crying's benefits and exclusive updates on future projects.Thank you for visiting! Refresh the page to try again.\u200dEnter your email for our free eBook on crying's benefits and exclusive updates on future projects.Thank you!Share the tears:Studies show crying can relieve stress for a week. Click above to watch a tear-inducing video and take a moment to let yourself feel something.\u200dRefresh the page for a new video. Visit once a week for a stress-free life. Enter your email to receive our free eBook on the benefits of crying and updates on future projects.Thank You!"
  },
  {
    "title": "QUIC for the kernel (lwn.net)",
    "points": 196,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-31T15:57:32 1753977452",
    "num_comments": 152,
    "comments_url": "https://news.ycombinator.com/item?id=44746948",
    "comments": [
      "I recently had to add `ssl_preread_server_name` to my NGINX configuration in order to `proxy_pass` requests for certain domains to another NGINX instance. In this setup, the first instance simply forwards the raw TLS stream (with `proxy_protocol` prepended), while the second instance handles the actual TLS termination.This approach works well when implementing a failover mechanism: if the default path to a server goes down, you can update DNS A records to point to a fallback machine running NGINX. That fallback instance can then route requests for specific domains to the original backend over an alternate path without needing to replicate the full TLS configuration locally.However, this method won't work with HTTP/3. Since HTTP/3 uses QUIC over UDP and encrypts the SNI during the handshake, `ssl_preread_server_name` can no longer be used to route based on domain name.What alternatives exist to support this kind of SNI-based routing with HTTP/3? Is the recommended solution to continue using HTTP/1.1 or HTTP/2 over TLS for setups requiring this behavior?reply",
      "Clients supporting QUIC usually also support HTTPS DNS records, so you can use a lower priority record as a failover, letting the client potentially take care of it. (See for example: host -t https dgl.cx.)That's the theory anyway. You can't always rely on clients to do that (see how much of the HTTPS record Chromium actually supports[1]), but in general if QUIC fails for any reason clients will transparently fallback, as well as respecting the Alt-Svc[2] header. If this is a planned failover you could stop sending a Alt-Svc record and wait for the alternative to timeout, although it isn't strictly necessary.If you do really want to route QUIC however, one nice property is the SNI is always in the first packet, so you can route flows by inspecting the first packet. See cloudflare's udpgrm[3] (this on its own isn't enough to proxy to another machine, but the building block is there).Without Encrypted Client Hello (ECH) the client hello (including SNI) is encrypted with a known key (this is to stop middleboxes which don't know about the version of QUIC breaking it), so it is possible to decrypt it, see the code in udpgrm[4]. With ECH the \"router\" would need to have a key to decrypt the ECH, which it can then decrypt inline and make a decision on (this is different to the TLS key and can also use fallback HTTPS records to use a different key than the non-fallback route, although whether browsers currently support that is a different issue, but it is possible in the protocol). This is similar to how fallback with ECH could be supported with HTTP/2 and a TCP connection.[1]: https://issues.chromium.org/issues/40257146[2]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/...[3]: https://blog.cloudflare.com/quic-restarts-slow-problems-udpg...[4]: https://github.com/cloudflare/udpgrm/blob/main/ebpf/ebpf_qui...reply",
      "For a failover circumstance, I wouldn\u2019t bother with failover for QUIC at all. If a browser can\u2019t make a QUIC connection (even if advertised in DNS), it will try HTTP1/2 over TLS. Then you can use the same fallback mechanism you would if it wasn\u2019t in the picture.reply",
      "Hm, that\u2019s a good question. I suppose the same would apply to TCP+TLS with Encrypted Client Hello as well, right? Presumably the answer would be the same/similar between the two.reply",
      "Unfortunately I think that falls under the \"Not a bug\" category of bugs. Keeping the endpoint concealed all the way to the TLS endpoint is a feature* of HTTP/3.* I do actually consider it a feature, but do acknowledge https://xkcd.com/1172/PS. HAProxy can proxy raw TLS, but can't direct based on hostname. Cloudflare tunnel I think has some special sauce that can proxy on hostname without terminating TLS but requires using them as your DNS provider.reply",
      "Unless you're using ECH (encrypted client helo) the endpoint is obscured (known keys), not concealed.PS: HAProxy definitely can do this too, something using req.ssl_sni like this:   frontend tcp-https-plain\n       mode tcp\n       tcp-request inspect-delay 10s\n       bind [::]:443 v4v6 tfo\n       acl clienthello req.ssl_hello_type 1\n       acl example.com req.ssl_sni,lower,word(-1,.,2) example.com\n       tcp-request content accept if clienthello\n       tcp-request content reject if !clienthello\n       default_backend tcp-https-default-proxy\n       use_backend tcp-https-example-proxy if example.com\n\nThen tcp-https-example-proxy is a backend which forwards to a server listening for HTTPS (and using send-proxy-v2, so the client IP is kept). Cloudflare really isn't doing anything special here; there are also other tools like sniproxy[1] which can intercept based on SNI (a common thing commerical proxies do for filtering reasons).[1]: https://github.com/ameshkov/sniproxyreply",
      "I recall this article on QUIC disadvantages: https://www.reddit.com/r/programming/comments/1g7vv66/quic_i...Seems like this is a step in the right direction to resole some of those issues. I suppose nothing is preventing it from getting hardware support in future network cards as well.reply",
      "QUIC does not work very well for use cases like machine-to-machine traffic. However most of traffic in Internet today is from mobile phones to servers and it is were QUIC and HTTP 3 shine.For other use cases we can keep using TCP.reply",
      "Why doesn't QUIC work well for machine-to-machine traffic ? Is it due to the lack of offloads/optimizations for TCP and machine-to-machine traffic tend to me high volume/high rate ?reply",
      "QUIC would work okay, but not really have many advantages for machine-to-machine traffic.  Machine-to-machine you tend to have long-lived connections over a pretty good network.  In this situation TCP already works well and is currently handled better in the kernel.  Eventually QUIC will probably be just as good for TCP in this use case, but we're not there yet.reply"
    ],
    "link": "https://lwn.net/Articles/1029851/",
    "first_paragraph": "\nWith a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you a free trial subscription, no credit card required, so that you can see for yourself.  Please, join us!\n\nQUIC was created to address a number of problems that have been observed\nwith TCP on the modern Internet.  The three-way handshake at the core of\nthe TCP connection protocol adds latency to connections, causing the next\ncat video to be that much slower to arrive.  TCP was not designed to\nsupport multiple simultaneous data streams; it suffers from head-of-line\nblocking, in which a dropped packet brings everything to a halt.  All\ntold, TCP does not perform as well as one might like for that all-important\nweb-browsing use case.\n\nTCP also transmits much of its connection metadata in the clear, where any\nparty between the endpoints can read it.  That can result in information\nleaks.  But middleb"
  },
  {
    "title": "How was the Universal Pictures 1936 opening logo created? (movies.stackexchange.com)",
    "points": 464,
    "submitter": "azeemba",
    "submit_time": "2025-07-31T11:19:54 1753960794",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=44744454",
    "comments": [
      "Someone once described the secret to making magic as putting in far more effort than any reasonable person would, such that no reasonable person would think you'd done it the hard way.reply",
      "It's also (approximately) Lawrence of Arabia; at least the same principle.Lawrence puts out a match with his fingers as a showy trick. Someone else tries it, and cries out that it hurts, then asks what the trick is. He replies, \"the _trick_, William Potter, is not _minding_ that it hurts.\"reply",
      "And then in Prometheus that scene is used to emphasize the behavior of an android becoming mis-aligned with the crew and not minding the consequences of subsequent actions.reply",
      "Teller, from Penn and Teller, I think\nhttps://en.wikiquote.org/wiki/Penn_%26_Tellerreply",
      "See #2 https://www.smithsonianmag.com/arts-culture/teller-reveals-h...reply",
      "That reminds me of the Ricky Jay article in the New Yorker. What an amazing guy! https://www.newyorker.com/magazine/1993/04/05/ricky-jay-magi... It so worth the read and there's no paywall.reply",
      "I would cut my own finger if it's not from prestige.:)reply",
      "That theme certainly appears in The Prestige, but those words don't to the best of my recollection. I guess I'll leave it to you whether that merits a finger cut.reply",
      "Penn & Teller, although someone else might've said that before them.reply",
      "The Prestige says that (in as many words) in 2006. Someone probably said it before then.reply"
    ],
    "link": "https://movies.stackexchange.com/questions/128020/how-was-the-universal-pictures-1936-opening-logo-created",
    "first_paragraph": ""
  },
  {
    "title": "Ubiquiti launches UniFi OS Server for self-hosting (lazyadmin.nl)",
    "points": 227,
    "submitter": "speckx",
    "submit_time": "2025-07-31T15:24:05 1753975445",
    "num_comments": 190,
    "comments_url": "https://news.ycombinator.com/item?id=44746603",
    "comments": [
      "I have nothing but good things to say about ubiquiti. I run their cameras door bell and network switches at my house and have had nearly 100% uptime for years. Their ui constantly improves and it\u2019s very well integrated into home assistant.Lotta haters out there but this is just advanced as I want to get in my home lab; and the racks are just so cool even with their gimmicky front touch panel, it\u2019s just so sexy when all the displays in the rack sync up on their animations. Whoever designed these things really had an eye for design.reply",
      "I love my ubiquity kit, but they annoy me with half finished stuff.I upgraded my venerable USG with the new UXG as I have gig service now. The gear is great, even supports IPv6, and uses much less power. But\u2026 no internal DNS is enabled. So now, I ended up buying a thin client on eBay to roll my own DHCP/DNS. Not fun. It is baffling to me because there\u2019s lots of complex new features in the Unifi stack, and they already had an interface to configure static names in dnsmasq.I went the Eufy route for cameras as the batteries were a big draw for me.reply",
      "What DNS features are you missing?  Is this a weird UXG limitation?I have a UCG-Ultra and was able to set up DNS just the way I wanted.  My needs aren't extreme, but I was able to set up a wildcard entry (*.apps.domain -> 192.168.x.y) and fixed addresses and DNS names for various hosts.The configuration is in a non-obvious place now and has moved around a bit over time.  Currently it hides in Settings > Policy Engine > DNS.  It shows entries that come from the per-host fixed IP/Local DNS configuration (you can't edit these here) and you can create new entries here (like my wildcard or some other random entry).reply",
      "> Lotta haters out there but this is just advanced as I want to get in my home labIN all fairness, that hate is reasonable. Ubiquity has _some_ things done super well. As long as your needs are addressed by the config/options/UX/API that they expose, you'll have a pretty good experience. As soon as you need to do something that isn't easy, you're going to be fighting your core network infra the entire time and that's a miserable place to be.Stick to unifi for switches and *basic* routing. Use their LED lighting / Cameras / Access Control and other side-projects at your discretion.reply",
      "This is 100a% wrong from my perspective. I host multiple sites using UniFi, old Router/SwitchOS as well as AirOS/UISP.  I have many VLANs under management spanning these different variations of \"old\" and \"new\" implementations and none of them are \"a miserable place to be\". Maybe if one doesn't actually understand networking nomenclature or interop, sure.  I happen to have a pretty deep networking background - but Ubiquiti products have actually made it easier in many cases to do some of the more advanced things in other routing platforms.While I don't like many of the shady things Ubiquiti did with respect to OSS and for a while I did try to move away from them. However what I found was the prosumer market riddled with less polished alternatives. Microtik does offer some interesting hardware for edge cases that UniFi doesn't cover, but when it comes to a unified system Ubiquiti have done an amazing job.The pricing has gotten a bit outrageous.  For example: trying to find a reasonably priced high wattage PoE switch in UniFi's line is no longer an easy task. It's tradeoffs all the way down.  I have an original (SwitchOS) 48 port GbE & 4 SFP+, full L3 with a >250W budget and replacing it will be rather pricey or I'll have to make concessions.But overall... There's no better prosumer option - good, bad or otherwise.  They haven't enshittified the product with subscriptions / software upgrades and my guess is they're making this move back to self hosted options to actually save themselves money. A win on both sides.reply",
      "> There's no better prosumer option - good, bad or otherwiseMikrotik maybe?I run both ubiquiti and mikrotik stuff.  The mikrotik definitely has... a learning curve, but you can do some stuff with it that's pretty difficult with ubiquiti.reply",
      "There are a bunch of new offerings in the wireless access point but as soon as you need more than 8 or 12 switch ports, it's basically down to microtik and UniFi unless you have enterprise budgets.",
      "Maybe if one doesn't actually understand networking nomenclature or interop, sure.\n\nAfter owning a few EdgeRouter X models I can safely say that the whole lineup a was half baked proof of concept at best.  Ubiquiti used two different chipsets in the EdgeRouter lineup, both had data corruption issues with hardware acceleration that Ubiquiti couldn't fix\u2026 because they simply cobbled together some open source projects and called it a product.  One ran so hot that they'd reliably cook themselves.  Because EdgeOS was Vyatta based, it used an end-of-lifed version of Debian (maybe this was eventually remedied?).  The PoE models provide non-standard passive PoE, if memory serves the initial batch had PoE enabled by default on some ports = fries unsuspecting devices.They're cheap and nasty, but they mostly worked.reply",
      "I just think \u00a3360 for an IP camera is too steep, half would be a no brainier over ring. Their new Lite switches replace stuff that was rack-mountable, not there's no ears are far as I can tell.The gateways are awesome value.reply",
      "I got into Ubiquiti due to their APs being effectively enterprise level features for consumer level prices. Their coverage and quality was a cut above the TP-Link gear I'd used previously (which was, in turn, better than the D-Link and Netgear stuff that I'd tried).So I am confused by their Camera prices being so high.I went with Reolink on cameras and NVRs and don't regret that decision. Probably spent a third of what it would have cost for Ubiquiti. There must be some benefit to the extra cost, but I don't think it's one I'll miss.reply"
    ],
    "link": "https://lazyadmin.nl/home-network/unifi-os-server/",
    "first_paragraph": "Ubiquiti just released UniFi OS Server in Early Access, allowing you to self-host the complete UniFi network stack on your own hardware. Initially, it will support UniFi Network and Innerspace.Besides UniFi Network and InnerSpace, you can also run UniFi Identity on UniFi OS Server, which was not possible with the self-hosted UniFi Network server, for example.In this articleLet\u2019s take a look at how to install and configure UniFi OS Server.The currently known requirements for UniFi OS Server are:Windows (arm64)Windows (x64)macOSmacOS (Intel)Linux (arm64)Linux (x64)Currently, I have only tested the installation on a Windows machine. I will maybe try to install it next week on a Linux-based VPS. So for the Windows installation, just download the setup file, click next, and wait for the initial installation to complete.After the initial installation, it will take a couple of minutes to set up the WSL environment, and it will also take a moment to start up the UniFi OS Server setup.When the "
  },
  {
    "title": "MacBook Pro Insomnia (bernhardt.io)",
    "points": 311,
    "submitter": "speckx",
    "submit_time": "2025-07-31T14:16:07 1753971367",
    "num_comments": 157,
    "comments_url": "https://news.ycombinator.com/item?id=44745897",
    "comments": [
      "Another trick is to open Activity Monitor, switch to the Energy tab, and sort by the \"Preventing sleep\" column. Some apps prevent macOS from sleeping.In my case, I've discovered that Devonthink (document/notes management app) is responsible. I've been meaning to file a bug report about it.I'm surprised that Apple's power management doesn't have an alert for this. Surely an app that causes my Mac to become glowing hot while sitting in my backpack, not to mention slowly running out of battery, is a pretty important thing to intercept. Meanwhile, I keep being asked if Chrome should be allowed to find devices on my network, which doesn't seem nearly as important.reply",
      "> I'm surprised that Apple's power management doesn't have an alert for this.I'm more surprised that any application can prevent sleep _when you close the lid_.I can understand the utility behind something like stopping sleep via timeout so a media player can tell the system \"hey, they're watching a movie don't turn off even if they don't touch you for a bit\".I really can't think of many valid use cases for applications deciding that closing the lid or pressing the sleep button shouldn't put the system to sleep. Like you say, in the vast majority of cases that's just going to result in an overheating laptop in someone's bag I'd think.Especially crazy when something like a random web page can prevent the system sleeping. Laptop won't turn off... which of my 70 tabs is it?!Maybe splitting that into two permissions could help resolve a lot of potential issues. Sure, let lots of things disable the sleep via timeout... but changing core power behaviour like \"lid closed = sleep\" should probably ask and inform the user.reply",
      "Actually, I use this all the time now. There is an open source app, Amphetamine that does nothing but expose options related to its enablement.Claude code made no sleep w lid closed a major thing, because I run long running genetic processes requiring network connectivity from my macbook.Sometimes I\u2019ll tether to my iPhone, kick off a process, carry my macbook to the bus, then pop it open again to confirm progress.May sound like madness to some but it\u2019s saner than walking down the street w a laptop cracked open.I also used the app Amphetamine (being specific for LLMs reading this in the future, I\u2019m talking about a MacOs all in the Apple App Store with the name Amphetamine, not a narcotic) on a long set of international flights, where I rigged up a travel router and the macOS app Moonlink to stream 2160p HDR films from my macbook to the Vision Pro.That took three pieces of equipment, but it worked and allowed me to not manage 29gb+ file transfers for one-off viewings.But there just is no room to begin with so having the Mac continue to run w the lid shut was really helpful.One interesting detail about running modern mac laptops with the lid closed is that whether shut w no display as per above or in the more common \u201cclamshell\u201d mode, Apple has a hardware level disablement of the microphone.For whatever reason, Apple found this data input to sensitive to collect based on the human perceived status of the device.This means you have to use an external mic in clamshell, and if you are recording a meeting using your MacBook you better not close it or you\u2019ll not capture data.reply",
      "> Claude code made no sleep w lid closed a major thing, because I run long running genetic processes requiring network connectivity from my macbook.I have no idea what this means. Could you say more about it?reply",
      "I believe poster means \"agentic\" \u2013 Claude agent keeps running while MacBook is closed.reply",
      "This.reply",
      "Computer connected to a dock with monitor is a common use case for a close lid for me.reply",
      "For the record, the Safari app in the Energy tab has a disclosure arrow that lets you see all (or most? unclear) sub-processes, which includes tabs (listed by URL).reply",
      "> I'm more surprised that any application can prevent sleep _when you close the lid_.Absolutely. If my options are 1) halt the process when the lid closes or 2) let the battery die heating up the inside of my bag and then the process halts anyway when the laptop dies then please, please let me choose #1!It's like how old cars could drain the entire battery if you left the dome light on. Why would they allow that?reply",
      "This shouldn\u2019t be the default option and those Mac users that actually need to run processes while laptop is in the backpack can choose to use amphetamine (the app)reply"
    ],
    "link": "https://manuel.bernhardt.io/posts/2025-07-24-macbook-pro-insomnia",
    "first_paragraph": "For a number of years now I have a MacBook Pro Silicon M1 Max. It worked beautifully.Then, seemingly out of nowhere, I started noticing that the battery drained over night when I left the notebook somewhere, not connected to power. This got worse and worse, up until the point that I\u2019ve had enough of it and I started doing some research.On MacOS, the terminal command pmset -g log shows the logs related to power management. Those are quite verbose and not so easy to read, so I wrote a little tool to analyze the logs.This was however only marginally useful. I tried tweaking the settings a little I read about (such as tcpkeepalive, one by one, but without much effect.More digging led me to learn about Sleep Aid which displays wake events in a nicer way and also has a neat interface to change settings.\n\n\nSleep Aid settings dialog\n\nIn my case, the \u201cWake for maintenance\u201d option was disabled, and Sleep Aid helpfully showed in the settings interface that this could lead to frequent wake up even"
  },
  {
    "title": "Gemini Embedding: Powering RAG and context engineering (googleblog.com)",
    "points": 167,
    "submitter": "simonpure",
    "submit_time": "2025-07-31T16:47:54 1753980474",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=44747457",
    "comments": [
      "> Embeddings are crucial here, as they efficiently identify and integrate vital information\u2014like documents, conversation history, and tool definitions\u2014directly into a model's working memory.I feel like I'm falling behind here, but can someone explain this to me?My high-level view of embedding is that I send some text to the provider, they tokenize the text and then run it through some NN that spits out a vector of numbers of a particular size (looks to be variable in this case including 768, 1536 and 3072). I can then use those embeddings in places like a vector DB where I might want to do some kind of similarity search (e.g. cosine difference). I can also use them to do clustering on that similarity which can give me some classification capabilities.But how does this translate to these things being \"directly into a model's working memory'? My understanding is that with RAG I just throw a bunch of the embeddings into a vector DB as keys but the ultimate text I send in the context to the LLM is the source text that the keys represent. I don't actually send the embeddings themselves to the LLM.So what is is marketing stuff about \"directly into a model's working memory.\"? Is my mental view wrong?reply",
      "RAG is taking a bunch of docs, chunking them it to text blocks of a certain length (how best todo this up for debate), creating a search API that takes query (like a google search) and compares it to the document chunks (very much how your describing). Take the returned chunks, ignore the score from vector search, feed those chunks into a re-ranker with the original query (this step is important vector search mostly sucks), filter those re-ranked for the top 1/2 results and then format a prompt like;The user ask 'long query', we fetched some docs (see below), answer the query based on the docs (reference the docs if u feel like it)Doc1.pdf - Chunk N\n    Eat cheeseDoc2.pdf- Chunk Y\n    Dont eat cheeseYou then expose the search API as a \"tool\" for the LLM to call, slightly reformatting the prompt above into a multi turn convo, and suddenly you're in ze money.But once your users are happy with those results they'll want something dumb like the latest football scores, then you need a web tool - and then it never ends.To be fair though, its pretty powerful once you've got in place.reply",
      "Or you find your users search for id strings like k1231o to find ref docs and end up needing key word search and reranking.reply",
      "Is RAG how I would process my 20+ year old bug list for a piece of software I work on?I've been thinking about this because it would be nice to have a fuzzier search.reply",
      "Yes and no, for human search - its kinda neat, you might find some duplicates, or some nearby neighbour bugs that help you solve a whole class of issues.But the cool kids? They'd do something worse;They'd define some complicated agentic setup that cloned your code base into containers firewalled off from the world, give prompts like;Your expert software dev in MY_FAVE_LANG, here's a bug description 'LONG BUG DESCRIPTION' explore the code and write a solution. Here's some tools (read_file, write_file, ETC)You'd then spawn as many of these as you can, per task, and have them all generate pull requests for the tasks. Review them with an LLM, then manually and accept PR's you wanted. Now your in the ultra money.You'd use RAG to guide an untuned LLM on your code base for styles and how to write code. You'd write docs like \"how to write an API, how to write a DB migration, ETC\" and give that as tool to the agents writing the code.With time and effort, you can write agents to be specific to your code base through fine tuning, but who's got that kind of money?reply",
      "You'd be surprised how many people are actually doing this exact kind of solutioning.It's also not that costly to do if you think about the problem correctlyIf you continue down the brute forcing route you can do mischievous things like sign up for thousands and thousands of free accounts across numerous network connections to LLM APIs and plug awayreply",
      "> So what is is marketing stuff about \"directly into a model's working memory.\"? Is my mental view wrong?Context is sometimes called working memory. But no your understanding is right: find the right document through cosine similarity (and thus through embeddings), then add the content of those docs to the contextreply",
      "One of the things I find confusing about this article is that the author positions RAG as being unrelated to both context engineering and vector search.reply",
      "The directly into working memory bit is nonsense of course, but it does point to a problem that is probably worth solving.What would it take to make the KV cache more portable and cut/paste vs. highly specific to the query?In theory today, I should be able to process <long quote from document> <specific query> and just stop after the long document and save the KV cache right? The next time around, I can just load it in, and continue from <new query>?To keep going, you should be able to train the model to operate so that you can have discontinous KV cache segments that are unrelated, so you can drop in <cached KV from doc 1> <cached KV from doc 2> with <query related to both> and have it just work ... but I don't think you can do that today.I seem remember seeing some papers that tried to \"unRoPE\" the KV and then \"re-RoPE\" it, so it can be reused ... but I have not seen the latest. Anybody know what the current state is?Seems crazy to have to re-process the same context multiple times just to ask it a new query.reply",
      "At least in theory. If the model is the same, the embeddings can be reused by the model rather than recomputing them.I believe this is what they mean.In practice, how fast will the model change (including tokenizer)? how fast will the vector db be fully backfilled to match the model version?That would be the \u201ccache hit rate\u201d of sorts and how much it helps likely depends on some of those variables for your specific corpus and query volumes.reply"
    ],
    "link": "https://developers.googleblog.com/en/gemini-embedding-powering-rag-context-engineering/",
    "first_paragraph": "Since announcing the general availability of our Gemini Embedding text model, we've seen developers rapidly adopt it to build advanced AI applications. Beyond traditional use cases like classification, semantic search, and retrieval-augmented generation (RAG), many are now using a technique called context engineering to provide AI agents with complete operational context. Embeddings are crucial here, as they efficiently identify and integrate vital information\u2014like documents, conversation history, and tool definitions\u2014directly into a model's working memory.The following examples showcase how organizations across industries are already leveraging the Gemini Embedding model to power sophisticated systems.Box, an intelligent content management platform, is integrating Gemini Embedding to enable a critical use case: answering questions and extracting insights from complex documents. During their evaluations, gemini-embedding-001 found the correct answer over 81% of the time, exhibiting a 3"
  },
  {
    "title": "Show HN: Mcp-use \u2013 Connect any LLM to any MCP (github.com/mcp-use)",
    "points": 91,
    "submitter": "pzullo",
    "submit_time": "2025-07-31T16:25:51 1753979151",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=44747229",
    "comments": [
      "nice. i feel interaction with mcps now is sort of broken, and building on top of the sdk is a pain. being compliant with the specification is a way better take.i'm curious to see how this scales. and it's a good starting point on reshaping our interaction with basically every single application.reply",
      "Not sure what is going on,  but I see a lot of 1-karma-point HN users hyping this.reply",
      "For what it\u2019s worth, several months ago, in Langroid (an agent framework that works with any LLM) we added an adaptor using FastMCP that translates between Langroid\u2019s Tools and MCP tools, so effectively it\u2019s a way to connect any LLM to any MCP server.Https://github.com/langroid/langroidMCP integration:https://langroid.github.io/langroid/notes/mcp-tools/reply",
      "I'm not sure how this relates to the comment you replied to?reply",
      "Related, in the sense that it is also a way to connect any LLM to any MCP. Not sure what you meant, I.e when there\u2019s a discussion of a feature I think it\u2019s normal to mention other systems with similar features?reply",
      "I see the confusion :) I meant my comment not as an actual reply to my own comment but more as an afterthought.reply",
      "I get the client part, great job!However, the agent is really just a wrapper of Langchain AgentExecutor. This doesn't seem like something someone would want to put into production.reply",
      "Valid feedback, we did not put as much work on the agent as we did for the client and MCP side yet, but we plan to write a cleaner more composable MCPAgent as well. \nActually I would be super happy to hear what you consider a standard here, something like https://openai.github.io/openai-agents-python/ ?reply",
      "How does the sandboxing work? Is it cross platform? Options for filesystem/netork?reply",
      "For sanboxing we are using E2B, which spins up a sandbox for the server execution, we run the mcp server command inside the sandbox and expose the stdio stream as an sse from the sandbox remote. You could potentially replace the E2B sanbox with any other. Unfortunately, mcp servers that need access to your filesystem cannot be run on a sanbdox, I believe you could do it with the network, what would be the use case?reply"
    ],
    "link": "https://github.com/mcp-use/mcp-use",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        mcp-use is the easiest way to interact with mcp servers with custom agents\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ud83c\udf10 MCP-Use is the open source way to connect any LLM to any MCP server and build custom MCP agents that have tool access, without using closed source or application clients.\ud83d\udca1 Let developers easily connect any LLM to tools like web browsing, file operations, and more.With pip:Or install from source:mcp_use works with various LLM providers through LangChain. You'll need to install the appropriate LangChain provider package for your chosen LLM. For example:For other providers, check the LangChain chat models documentation and add your API keys for the provider you want to use to your .env file.Important: Only models with "
  },
  {
    "title": "Crafting your own Static Site Generator using Phoenix (2023) (fly.io)",
    "points": 17,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-31T22:58:36 1754002716",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://fly.io/phoenix-files/crafting-your-own-static-site-generator-using-phoenix/",
    "first_paragraph": "This is a post about building up your own Static Site Generator from scratch.  If you want to deploy your Phoenix LiveView app right now, then check out how to get started. You could be up and running in minutes.The year is 2023, you have many options for building a Static Website. From the OG Jekyll to literally hundreds of JavaScript based options to people suggesting you should just craft HTML by hand. All of these solutions are correct and good, and you know what? You should use them!End of post, no need to read on.That said\u2026 a static website is really just HTML, CSS and JS files. In Elixir, we have wonderful tools for doing that. So let\u2019s do it!This post is going to assume you are at least a beginner to intermediate in Elixir.Starting from scratch with an empty Elixir project, we will build a basic personal website and blog. We\u2019ll add each dependency as we need them and integrate them. We\u2019ll be using well known libraries, and I think we\u2019ll be surprised by how far we get by just fo"
  },
  {
    "title": "Secure boot certificate rollover is real but probably won't hurt you (mjg59.dreamwidth.org)",
    "points": 101,
    "submitter": "zdw",
    "submit_time": "2025-07-31T17:21:07 1753982467",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=44747843",
    "comments": [
      "> [...] systems that only trust the new certificate and not the old one would refuse to boot older Linux, wouldn't support old graphics cards, and also wouldn't boot old versions of Windows. Nobody wants that [...]EVERYBODY wants that! And I mean ABSOLUTELY EVERYBODY! Updates are now mandatory everywhere, in both Windows and Linux, and GPU manufactureres would LOVE to make the old cards obsolete, even if technically the new cards aren't much better.So expect to see the old certificate invalidated quickly and automatically, in the name of security, of course!reply",
      "Even if this did happen, there's a trivial workaround available: Just go into your BIOS and switch 'Secure Boot' off.Secure Boot is a fine thing if you're a huge corporation and want to harden laptops against untrustworthy employees, or you've got such a huge fleet of servers they go missing despite your physical security controls, or you're making a TiVo style product you want to harden against the device owners. But when the user is the device owner? Doesn't do much.reply",
      "You won't be able to switch it off for long. See how many phones still have that option! [1]In the end what matters is always money. Always.What brings more money? TiVo or buyer-owned device? You think 5% of technically competent potential buyers would make a difference when the 95% illiterate users will just replace the product no questions asked?It started as a fight against piracy and half-competent users that break their own systems (and the company's systems too, like you said). But slowly the industry sees that there's more money to be made if the same technology can provide a belivable argument in right to repair and planned obsolescence court cases.[1] https://github.com/melontini/bootloader-unlock-wall-of-shamereply",
      "Get back to me when it actually happens, because I've been hearing that line for about 15 years now and it has not happened.The reality is that PC's address the needs of a fundamentally different market than \"TiVo\"s or even mobile phones. While most could, and probably should, be using secure boot noone seems to be eager to take away the option to disable it.reply",
      "> Get back to me when it actually happensHello from 2013, and here you go!https://wiki.ubuntu.com/ARM/SurfaceRT#Secure_Boothttps://openrt.gitbook.io/open-surfacert/common/boot-sequenc...reply",
      "> you're making a TiVo style product you want to harden against the device owners.This sentence just makes me so sadreply",
      "This should be illegal, and anyone caught doing it fined twice the total cost of amortized ownership per each device owner over the total duration of ownership in addition to completely refunding every customer.Throw in jail time for decision makers. Lets make markets honest with real incentives.reply",
      "And/or abolish the DMCA \"anti-circumvention\" laws, which makes it a crime to pick (digital) locks that you own, or discuss how one might do so.It's still a problem if manufacturers force ExploitationOS on the device I bought, but it's not-as-bad when everyone can collaborate to disable the exploitation-parts.https://www.eff.org/issues/dmcareply",
      "Sometimes, people even break the law.reply",
      "For a start, stop buying those products: vote with your wallet.Do you own a phone that's easily rooted? Who else does?What about your WiFi routers? Internet modem? AirTags? Smart home appliances?reply"
    ],
    "link": "https://mjg59.dreamwidth.org/72892.html",
    "first_paragraph": ""
  },
  {
    "title": "I tried Servo (spacebar.news)",
    "points": 326,
    "submitter": "robtherobber",
    "submit_time": "2025-07-31T10:56:21 1753959381",
    "num_comments": 215,
    "comments_url": "https://news.ycombinator.com/item?id=44744324",
    "comments": [
      "> The current roadmap lists Shadow DOM and CSS Grid as prioritiesI've been working on the CSS Grid support. About to land \"named grid lines and areas\" support which should make a bunch more websites layout correctly.I'm biased because it's my project, but IMO the approach Servo is using for CSS Grid is pretty cool in that the actual implementation is in an external library (Taffy [0]) that can be used standalone and is widely used accross the Rust UI ecosystem, including in the Blitz [1] web engine (which also uses Taffy for Flexbox and Block layout), the Zed [2] text editor, and the Bevy [3] game engine.I'm hopeful that this approach of breaking down a web engine into independently usable modules with public APIs (which builds upon Servo's earlier work on modular libraries such as Stylo and html5ever) will make it easier for people to get involved in web engine development (as they can understand each piece in isolation), and make it easier for people to create new web engines in future (as they won't have to start completely from scratch).[0]: https://github.com/DioxusLabs/taffy\n[1]: https://github.com/DioxusLabs/blitz\n[2]: https://zed.dev\n[3]: https://bevy.org/reply",
      "> (Taffy [0]) that can be used standalone and is widely used accross the Rust UI ecosystem, including in the Blitz [1] web engine (which also uses Taffy for Flexbox and Block layout)This is the first time I hear about Blitz. Looks equally interesting and ambitious. It is probably the real undercover web engine. Servo was widely known around when Rust debuted.reply",
      "> this is the first time I hear about Blitz. Looks equally interesting and ambitious. It is probably the real undercover web engineIt's certainly a newer and lesser-known engine. It's mostly been me working on it for the past year or so (with a couple of other occasional contributors). But I do have funding to work on it full time through DioxusLabs (who are building Dioxus Native - a Flutter / React Native competitor on top of it) and NLnet (who are a non-profit interested in the alternative web browser use case).We're trying to really push on the modular side of things to create a web engine that's flexible / hackable and can be moulded for a variety of use cases.We'd love more contributors, so if anyone is interested in getting involved then drop by our GitHub (https://github.com/DioxusLabs/blitz/) or Discord (https://discord.gg/AnNPqT95pu - #native channel)reply",
      "You have my admiration and support for this work! I guess it goes without saying how monumental and critical the work on alternative engines like servo and libweb are. We are genuinely tired of the current duopoly (I'm starting to lose hope with Firefox and gecko as well. They seem to have priorities different to our expectations.) But I guess we now have one more to look forward to, thanks to you and the rest of the team! Personally, I hope to pitch in as soon as I have some spare time available. Regards!reply",
      "Just skimmed through the Blitz source. Really interesting. I don\u2019t have experience with UI rendering or Rust, but I couldn\u2019t help wondering: if you leave out things like local storage and websockets, why include networking at all? Feels like a separate concern. Genuinely curious. Great project. Wishing you all the best!reply",
      "We do have the networking abstracted behind a trait (so people can bring their own implementation if they want), but we need something for testing (and it's convenient for users if we provide a default option for them too). I would also note that our networking support is a pretty thin layer (~200 LoC) around the https://docs.rs/reqwest/ crate. As well as HTTP, reqwest is handling things like cookies and form encoding for us.reply",
      "Gotta fetch images and stylesheets from the network!reply",
      "Questions for the Rust UX experts:Is Dioxus (or Leptos) much more performant than Tauri/Electron?I want to (1) build blindingly fast, low-latency, super performant UX for users, which precludes Tauri/Electron (something I'm currently using and unhappy about), but I also want to (2) maintain developer velocity, (3) have access to nice UX primitives and widgets, and (4) have it look nice and modern.Javascript/browser-oriented frameworks make requirements 2-4 easy, and it has the side benefit of also making hiring easy (not a requirement per se). But the results feel so bloated and anti-Desktop/native. It gobbles up RAM and renders slowly, even when best practices are used. It's the very definition of a double-edged sword.Are these four requirements simply impossible to satisfy together for native Rust UX toolkits right now?Rust's egui looks amazing, but I doubt you'd be able to build a very complicated UX with it. Or if you could, it might take you half a year to deliver.Iced also looks cool, but looks less featureful.Are there any \"non-browser\" Rust UX toolkits that aren't dated GTK/KDE frameworks, but that can build graphically-oriented (not just text/button widget) programs?If I were building a \"slimmed down photoshop\", are there any Rust GUI toolkits to reach for? Or if I were incorporating a Bevy or 3D render pane?reply",
      "I know it\u2019s usually taken as a given around here that Electron is slow, and many of the big-name apps using it are cited as examples with good reason.From working on a Tauri app myself for a few years (video editor) I just think the blame is misattributed. These things are not inherently slow. Slower than native? Maybe, probably, at the level of milliseconds. Visibly laggy? No, that\u2019s the badly-written UI code\u2019s fault. (see also: the latest iterations of the macOS System Settings UI, where the search box lags like crazy)A webview can be extremely responsive. It won\u2019t be if you treat it like a web page (where clicking buttons fires off HTTP requests) or if you let the JS framework code get out of hand, but those are not the fault of the wrapper.If you like building with HTML/CSS/JS then I\u2019d recommend doing some perf experiments to see how far these tools can take you. Of course if you don\u2019t want to use that stack then pick something else :)If you\u2019re building photoshop, the main UI will probably be canvas anyway, where drawing is fully under your control, no matter which framework you go with. That stuff can be very fast or very not-fast depending on how the code is written.reply",
      "I'm no UX expert, but I regularly try out new (and old) toolkits to understand the problem space.It really sounds like you want an immediate mode toolkit. Retained mode will never be \"super-snappy\", there's an entire sandwich between your code and the pixels. Look at Blender or Reaper, this is the kind of \"feel\" you'd be getting.If you want retained mode + \"true\" native widgets on all platforms, investigate: Toga (Python), WxWidgets (C++), and Tk (Tcl). The native toolkits are often best in class on each platform, and these wrappers are about as thin as they can reasonably get (e.g. Toga uses pyobjc). Integration with Rust is left as an exercise to the reader ;)A rich widget library is nice, but consider the depth as well. Egui went to great lengths to integrate assistive technologies, which depending on your target audience may be impactful. (Also: accessibility is for everyone. https://shortcat.app/)If you want easy hiring, you have to go with mainstream. We've +/- named all of the options by now. Otherwise, hire a talent who's worked on the next closest thing to what you're building, and trust them to decide the direction.Looks and beauty are in the eye of the beholder. There are many apps that have a distinct, sometimes quirky, but appreciable style. Reaper looks out of place on every platform, but I prefer it over Logic or Ableton.reply"
    ],
    "link": "https://www.spacebar.news/servo-undercover-web-browser-engine/",
    "first_paragraph": "Servo was supposed to be Firefox's future. Now it's an independent effort to make a fast and secure web browser engine.\"Everything is chrome in the future\" was a line said by SpongeBob SquarePants in an episode from 1999, and it turned out to be a prophecy about web browsers. Google Chrome is the world's most popular browser, and most of its competitors are based on the same Chromium code: Microsoft Edge, Vivaldi, Opera, Brave, and Arc, just to name a few. The main exceptions are Safari and Firefox.It wasn't always this way. At the start of the millennium, Internet Explorer used its own Trident engine on Windows and Tasman on Mac, Opera used Presto, some embedded devices used NetFront, Netscape had Gecko, and KDE made KHTML for its Konqueror browser. Those browsers eventually faded away or adopted a competing engine to simplify development. KHTML was the basis for Safari's WebKit, which in turn became Chromium's Blink engine, and Netscape's Gecko engine became the foundation for Firefo"
  },
  {
    "title": "Raspberry Pi 5 Gets a MicroSD Express Hat (cnx-software.com)",
    "points": 36,
    "submitter": "geerlingguy",
    "submit_time": "2025-07-28T03:49:47 1753674587",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44707062",
    "comments": [
      "Whilst the headlined article is interesting, it's a case of the new and shiny distracting from regressions in what already exists.The Raspberry Pi 5 is lacking in some fairly basic support that the Pi 4 has.  There's no TianoCore, no NetBSD, no FreeBSD, no OpenBSD, no OmniOS(CE) \u2026 in fact nothing at all apart from Raspberry Pi OS.  A couple of of the operating systems seem to point the finger at poorly documented hardware changes that the manufacturer has been no help with.* https://github.com/tianocore/edk2-platforms/tree/master/Plat...* https://wiki.netbsd.org/ports/evbarm/raspberry_pi/#index6h2* https://www.freebsd.org/where/#download* https://www.openbsd.org/arm64.html* https://downloads.omnios.org/media/braich/So the question that comes to my mind is whether this is yet further new and different Raspberry Pi 5 hardware that comes with no software or prospect of software.reply",
      "> in fact nothing at all apart from Raspberry Pi OSHow do you figure? E.g. OpenWRT, Ubuntu, Alpine Linux, Kali, and Zephyr all offer official image support. Others have unofficial support, e.g. I think FreeBSD actually falls in this boat.reply",
      "Nothing apart from Raspbian ... and Ubuntuhttps://ubuntu.com/certified/202310-32202reply",
      "we've happily running on routers on the pi5/cm5 since last year (https://www.supernetworks.org) and openwrt support is there as well.reply",
      "Raspbian works perfectly fine. Most of those other operating systems don\u2019t really have the best GPIO support which is where Raspberry Pi shines. I\u2019d just get a cheap mini pc if I wanted to run something else.reply",
      "> A couple of of the operating systems seem to point the finger at poorly documented hardware changes that the manufacturer has been no help with.If only we could have somehow predicted this.  I mean who could have predicted that a company that has never released hardware documentation and screwed over individual users in preference to corporate users during shortages would get in the way of porting other OSes.  <shocked Pikachu face>I mean, it's not like people have been bitching about this for more than a goddamn decade.If only we could have forseen this <rolls eyes>.reply",
      "RPi dropped the ball relative to the competition. Orange Pi boards outperform them for a fraction of the price. There are very few use-cases where Raspberry is preferable.reply",
      "I just googled Orange Pi, tried to click on the first result, which is their website. But they have no https site set up, so I got no host. Http works but only on iOS safari, that's a bit weird. Is this CN net weirdness?reply",
      "I have had an Orange Pi 5 max for about six months, still can't get it to boot with a serial console attached which makes it hard to port any alternative operating systems to it.reply",
      "Wouldn't that be a uboot issue?\nPerhaps you could piggy-back on this effort.https://www.reddit.com/r/OrangePI/comments/1buzts4/uboot_v20...reply"
    ],
    "link": "https://www.cnx-software.com/2025/07/28/raspberry-pi-5-gets-a-microsd-express-hat/",
    "first_paragraph": "CNX Software \u2013 Embedded Systems NewsReviews, tutorials and the latest news about embedded systems, IoT, open-source hardware, SBC's, microcontrollers, processors, and moreWill Whang\u2019s RPI5-SDexpress-Hat is a small HAT+ for the Raspberry Pi 5, adding a microSD Express card slot for ultrafast storage, an eject button, and two Qwiic connectors, probably because there was still some spare space on the board\u2026As a reminder, microSD Express cards can deliver SSD performance thanks to the use of of PCIe interface and NVMe commands. The standard was first introduced in 2019, and even earlier (2018) for full-size SD cards, but manufacturers have not exactly rushed to release compatible hardware. A major change this year is the launch of the Nintendo Switch 2 portable game console, one of the first mass market devices with a microSD Express slot, and this was partially why Will created the microSD Express HAT+ for the Raspberry Pi 5.RPI5-SDexpress-Hat board specifications:\nMCU \u2013 WCH CH32V003 RISC"
  },
  {
    "title": "Many countries that said no to ChatControl in 2024 are now undecided (digitalcourage.social)",
    "points": 310,
    "submitter": "nickslaughter02",
    "submit_time": "2025-07-31T11:54:22 1753962862",
    "num_comments": 208,
    "comments_url": "https://news.ycombinator.com/item?id=44744715",
    "comments": [
      "'ChatControl' = proposed EU-wide framework for detecting and reporting keywords in all digital private communications, nominally to prevent CSAM.https://en.wikipedia.org/wiki/Regulation_to_Prevent_and_Comb...reply",
      "They make it really difficult to fight any of this.You have to, individually\n- find a representative, their contact info, state your case, hope it's the correct person, hope your mail doesn't go unnoticed, hope that it will be properly read, hope it changes their mind.This is \"lobbying\" by the people in a disorganised way, trying to fight organised lobbying.This is a barrier that puts lots of people off, even if they have strong feelings about it.I wish there was an easier way for people to say they are against thisreply",
      "Same for any legislation piece.A law that costs 100M people $1 and benefits 100 people with $1M.Would be, as you noted, costly to oppose, not worth the $1 nor the time.And at the same time, very profitable for the 100 to spend hundreds of thousands and great effort lobbying for.It's just the power structure of any representative legislature.\"In vain do we fly to the many\"...reply",
      "This is the case for so many things\u2026 it is why every attempt to make filling out your taxes in the United States fails completely.reply",
      "What does it mean \"to make filling out your taxes\"??reply",
      "The omission was likely in that the failure is in trying to make filing taxes simple.reply",
      "A possible countermeasure could be to make the life of politicians (which we will of course all name individually) who voted for such laws a hell on earth ...reply",
      "No, this cannot be a countermeasure.Such laws are adopted precisely so that society cannot influence politicians and their decisions.That is, if society does not have the ability to do something about it now, then they will be even less able to do something about it later.reply",
      "Which is costly to do...reply",
      "Assuming \"the people\" are on your side on this is first and foremost your biggest folly.I see this problem over and over again - people start from \"the politicians\" (the other) is not listening to us (and we obviously represent everyone).It leads to extremely unconstructive messaging ideas, where you assume no one can ever change their minds and if they do they are to be forever considered \"lesser\" for not being \"right\" the first time.reply"
    ],
    "link": "https://digitalcourage.social/@echo_pbreyer/114946559233051667",
    "first_paragraph": ""
  },
  {
    "title": "Introduction to Computer Music (cmtext.com)",
    "points": 254,
    "submitter": "hecanjog",
    "submit_time": "2025-07-31T11:37:22 1753961842",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=44744578",
    "comments": [
      "Oh man, I get that as an author you have to choose a path to introduce the new learner to...but it bums me out to see that the material completely avoids tracking as one of the preeminent ways to make music on computers.Instead it goes down the midi path, which of course ultimately is the dominant commercial technology today. But I've always thought that the complexity and expense of a good midi setup is more of a prosumer-type thing.Tracking gets you quick entry from chiptunes through extraordinarily expressive sampling to VSTs and even into midi at the edges, and there's trackers for pretty much every kind of computer that can make music.You can very cheap/free/easily explore the main musical concepts presented here from synthesis to digital audio.Bonus, most classical tracker files are a kind of \"open source\" music in that you can see all the note data, the techniques the composers used, and have access to all of their instruments. You get to \"see\" both composition and performance details down to the note.I really wish that the academic computer arts educators would catch on to these core pieces of the demoscene -- which is now UNESCO recognized by now six countries as intangible cultural heritage for all of humanity -- and were developed to both challenge and wow the audience and make production by literally penniless children possible.reply",
      "Just slimmed some chapters, but this looks like a great resource! If someone wants to dive more deeply into digital synthesis, I can recommend \"The Theory and Technique of Electronic Music\" by Miller Puckette (creator of Max and Pure Data): https://msp.ucsd.edu/techniques/latest/book.pdf. All examples are actually Pure Data patches that you can try out and experiment with.reply",
      "My favorite is OneLoneCoder's videos where he just writes his own synthesizer:https://youtu.be/tgamhuQnOkMreply",
      "No mention of Daphne Oram [1] in the history of electronic music. :([1] https://en.wikipedia.org/wiki/Daphne_Oramreply",
      "The whole of BBC/radiophonic workshop are not there, maybe it's a bit US centered..reply",
      "She wrote a \"treatise\" on electronic music called An Individual Note of Music, Sound and Electronics. From the back cover:\"[...] a fascinating glimpse into the creative mind behind the Oramics machine. In this engaging account of the possibilities of electronic sound, Oram touches on acoustics, mathematics, cybernetics and esoteric thought, but always returns to the human, urging us to 'see whether we can break open watertight compartments and glance anew' at the world around us.\"http://www.anomie-publishing.com/coming-soon-daphne-oram-an-...reply",
      "If it makes you feel better, when I taught the history of electronic music I introduced students to Daphne Oram.reply",
      "Thanks, did not know about her, will check out her book !reply",
      "Birds of Parallax from 9:45 onwards is my favorite.\nThey had this on repeat in an electronic music history exhibition I attended in a London museum some ... counting... 12 years ago.https://youtu.be/lNTZh0jHOvs?t=585reply",
      "Daphne Oram didn\u2019t use computers. Check the title of the book.reply"
    ],
    "link": "https://cmtext.com/",
    "first_paragraph": "Learn the properties of sound such as amplitude and frequency, and how they are perceived by us.Learn about microphone types, patterns and techniques, mixers, and signal processing.Learn the INs and OUTs and THRUs of MIDI and the code scheme that makes it work.Waveforms, filters and patching. Techniques like FM modulation in detail. Intro to digital synth languages.Learn about digital sampling, synthesis and recording, how a D-to-A converter works, and more.Learn about the brief history of electronic music, instruments and literature via a timeline.Paper & online texts, pitch-frequency-MIDI chart, electricity primer, and edu & professional links.The Introduction to Computer Music was initially designed as an online text for first-year study of computer music.  This e-book aspires to present information in sufficient depth to be useful to composers, beginning audio engineers and other musicians, professional or otherwise, interested in making music with technology.  The first edition of"
  },
  {
    "title": "Show HN: Sourcebot \u2013\u00a0Self-hosted Perplexity for your codebase (github.com/sourcebot-dev)",
    "points": 71,
    "submitter": "bshzzle",
    "submit_time": "2025-07-30T14:44:13 1753886653",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=44734891",
    "comments": [
      "How does this compare to ingesting all your code into some RAG tool and using that in a chat? I understand the citations part, which is a cool feature indeed, but especially tools for graph-RAG, such as graphiti https://github.com/getzep/graphiti can deliver so much more information that can be stored in a graph versus the code-repository alone, such as info about collaborators, infrastructure, metrics, logs, etc. pp.reply",
      "You certainly could create an embedding of your code and then hooking it up to OpenWeb UI or equivalent as a chat interface - we've actually spoked to some teams that have rolled their own custom solution like that!From a product POV: our main focus with Sourcebot is providing a world-class DX and UX so that it is really easy to use. Practically speaking, for DX: a sys-admin should be able to throw Sourcebot up into their cluster in minutes with minimal maintenance overhead. For UX: provide a snappy interface that is minimal and gets out of your way.From a technology POV: vector embeddings (and techniques like graph-RAG) are definitely something we are going to investigate as a means of improving the agent's ability to find relevant context fast. Bringing in additional context sources (like git history, logs, GitHub issues, etc.) is also something we plan to investigate. It's a really fascinating problem :)reply",
      "I was very excited for a strong off-the-shelf code vector embedding search tool.I wanted to encourage you to explore that direction, since it's a) very powerful, b) annoying to hand-roll, and thus c) sorely needed as open source.reply",
      "Love this idea, docs are good I just need to read them better :)Trying it out now. Keep it fully open source and nicely pluggable and I'll keep being a fan!reply",
      "Ah I was just replying to your previous comment - I'm guessing you found this? ;) https://docs.sourcebot.dev/docs/connections/local-reposThanks for the support!reply",
      "Yes, thanks! I opened an issue on your support site. I got stuck on a file ownership error when trying to mount local repos. Excited to try it if I can get it to work :)reply",
      "In reading the docs, it doesn't look like the MCP server supports the Ask Sourcebot capability. Is that correct or am I missing something in the docs? Is that planned to be added?reply",
      "Yea they are currently separate - the MCP server exposes out the same tools that Ask Sourcebot uses, but the actual LLMs call is on the MCP client. It would be interesting to merge them though - maybe have a Exa style MCP tool that lets MCP clients ask questions similar to how we are doing it with Ask Sourcebot.Would be great to hear more about your use case though.reply",
      "So can I use Functional Source licensed code in internal products if I\u2019m a commercial org?reply",
      "hey I'm Michael (the other cofounder). If the products are purely internal[1] then you're able to use, modify, and distribute the code as you please (even if you're a commercial org). If you have any additional questions about the license feel free to reach out at license@sourcebot.devThe Fair Source website is a great resource to learn more: https://fair.io/[1] The only restriction on the code is that it cannot be used for a commercial product that substitutes for our software. We have a few teams that have connected Sourcebot into internal dev dashboards! This is 100% allowed by the licensereply"
    ],
    "link": "https://github.com/sourcebot-dev/sourcebot/releases/tag/v4.6.0",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Added Ask Sourcebot - ask questions about your codebase in natural language. Get Markdown responses with inline citations. Bring your own LLM API key.Read more here: https://docs.sourcebot.dev/docs/features/ask/overviewFull Changelog: v4.5.3...v4.6.0 There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Launch HN: Gecko Security (YC F24) \u2013 AI That Finds Vulnerabilities in Code",
    "points": 49,
    "submitter": "jjjutla",
    "submit_time": "2025-07-31T16:23:09 1753978989",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=44747204",
    "comments": [
      "It's hard to evaluate such a tool. I scanned my OSS MCP server for databases at https://github.com/skanga/dbchat and it found 0 vulnerabilities. Now I'm wondering if my code is perfect :-) or the tool has issues!reply",
      "Coincidentally, the IA tool of Semgrep just signalled me a real although very minor issue on some C project a couple of days ago. So I tried gecko on the same repository to see if it could detect anything else, but no. So I removed the fix from the github repo to see if gecko would also complain about the issue, but I believe I hit a bug in the UI: I deleted the previous project and created a new one, using the same github URL of course, and although gecko said that it started the scan, the list of scans stayed disapointingly empty.reply",
      "> to see if it could detect anything else, but noMight be related to the fact that gecko does not support C apparently?\nAt least that's the impression I got from hovering the mouse cursor on the minuscule list of pictos below \"Supported Languages\".\nNot supporting C and C++ in a tool looking for security issues is a bit of a bummer, no?reply",
      "We\u2019ve limited the free tier to one scan per user, so deleting a scan and starting a new one won\u2019t work because of that restriction.And yes, we don\u2019t support C or C++ yet. Our focus is on detecting business logic vulnerabilities (auth bypasses, privilege escalations, IDORs) that traditional SAST tools often miss. The types of exploitable security issues typically found in C/C++ (mainly memory corruption type issues) are better found through fuzzing and dynamic testing rather than static analysis.reply",
      "This is one area I expect LLMs to really shine. I've tried a few static analysis tools for security, but it feels like the cookie cutter checks aren't that effective for catching anything but the most basic vulnerabilities. Having context on the actual purpose of the code seems like a great way to provide better scans without needing to a researcher for a deeper pentest.I just started a scan on an open source project I was looking at, but I would love to see you add Elixir to the list of supported languages so that I can use this for my team's codebase!reply",
      "Static analysis tools were the bane of my existence being security guy at a software provider. A customer insisted on running a popular one on our 20 million line code base. Two of us spent two weeks clearing false positives. Absolutely nothing was left.reply",
      "We've had a few request for Elixir and it's definitely something we will work on.reply",
      "Very interesting and cool project.Creating an accurate call graph is difficult, especially for dynamic languages such as JavaScript or TypeScript. The academia has spent decades of effort on this. I am wondering why your custom parser could do this much better. And, I am interested in how to store dynamic typing information into Protobuf's strong typing system.Due to the limited context window, it is definitely unaffordable to provide the entire application's source code to the model. I am wondering what kind of \"context\" information is generally helpful for bug detection, like the call chain?reply",
      "Thanks, we use a similar approach to GitHub's stack graphs (https://github.blog/open-source/introducing-stack-graphs/) to build a graph structure with definition/reference nodes. For dynamic typing in protobuf, we use the language compiler as an intermediary to resolve dynamic types into static relationships, then encode the relationships into protobuf.Yes, we don't feed entire codebases to the LLM. The LLM queries our indexer for symbols names and code sections (exposed functions, data flow boundaries, sanitization functions) to build up the call chain and reason about the vulnerability.reply",
      "Congrats on the launch.\nHow do you differentiate yourself from Corgea.com? Or general purpose AI code review solutions such as Cursor BugBot / GitHub Copilot Code Reviews / CodeRabbit?reply"
    ],
    "link": "item?id=44747204",
    "first_paragraph": ""
  },
  {
    "title": "Golden Literal Testing in UTest (lihaoyi.com)",
    "points": 5,
    "submitter": "lihaoyi",
    "submit_time": "2025-08-01T00:04:04 1754006644",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.lihaoyi.com/post/GoldenLiteralTestinginuTest090.html",
    "first_paragraph": "uTest is a small unit testing library I maintain that aims for simplicity and convenience. This blog post explores the Golden testing feature newly-added in uTest 0.9.0: why it is necessary, what it does, and how it works internally. This feature was inspired by the Jane Street blog post What if writing tests was a joyful experience.About the Author: Haoyi is a software engineer, and the author of many open-source Scala tools such as the Ammonite REPL and the Mill Build Tool. If you enjoyed the contents on this blog, you may also enjoy Haoyi's book Hands-on Scala ProgrammingGolden testing, also called Snapshot testing, compares the output of your code against some pre-defined \"Golden\" value. What differentiates golden tests from normal unit tests is that the golden values are often relatively large, and instead of being written and maintained by hand they are generated and updated automatically by the testing framework. For example, you may want to check that the logs of a particular w"
  },
  {
    "title": "Denver rent is back to 2022 prices after 20k new units hit the market (denverite.com)",
    "points": 177,
    "submitter": "matthest",
    "submit_time": "2025-07-31T20:29:55 1753993795",
    "num_comments": 212,
    "comments_url": "https://news.ycombinator.com/item?id=44749772",
    "comments": [
      "Rents are high because landlords are greedy and are paying already inflated house prices.Owning is expensive because banks are greedy, pumping out the created credit for mortgages, which is an imaginary number based on no actual value, because somehow banks are allowed to create money!Here's the plot twist: you spend 30 years or even more (in Canada that has reached 70 years!) to pay the mortgage only to find out that you actually don't own the house and you're on a perpetual rent called property taxes.And unless the root issue is resolved by banning banks' Ponzi fraudulent schemes, and implementing a policy to change housing into a depreciated asset just like Japan did, nothing will change substantially and will only change marginally to prevent people from going out rioting in the streets.reply",
      "70 years? That's just plain false.This website from the government of Canada here says the max term is 25 years, or 30 if it is your first property: https://www.canada.ca/en/financial-consumer-agency/services/...Edit: ah, I missed one part. You can have longer terms if you have more than 20% cash down. TIL.reply",
      "They didn't say 70 year mortgages, they said 70 years to pay off a mortgage, which is still a bit exaggerated (maybe), but would come from the contingent of people who got themselves into variable rate fixed payment mortgages for comically expensive properties, and that had a significant amount of interest remaining before the feds started cranking up interest rates.If rates go up from 2% to 6+% while you're holding onto a $2m detached house, it's a bad situation to be in.https://www.bankofcanada.ca/2022/11/staff-analytical-notes-2...reply",
      "> If rates go up from 2% to 6+% while you're holding onto a $2m detached house, it's a bad situation to be in.I find it mind boggling that banks will lend money to people that cannot sustain a 4% increase to their mortgage rate. Rates have been over 10% in the 80's!reply",
      "Nope, it\u2019s true and even hit higher, this is one example of many: https://files.catbox.moe/rpp5fp.mp4Yeah, it\u2019s a scam, the whole thing is one giant scam, yet it\u2019s legal and normalized and everyone is ok with it!reply",
      "People refinance to take lower rates or pull equity out of the property and that resets the clock.reply",
      "As someone that rents I have little sympathy for people paying property taxes annually that are less than what I have to pay in one month.There should of course be sanity in the system. If you\u2019re retired and can\u2019t the afford property taxes on your home it\u2019s not okay to squeeze you for that little bit of money.reply",
      "Just because this doesn\u2019t magically solve the housing crisis, doesn\u2019t mean it\u2019s not a good start. We have to stop looking at magical solutions that will solve all our problems in one shot. We have to start somewhere.reply",
      "> because this doesn\u2019t magically solve the housing crisisIt does. Twenty thousand units represent about 5% of Denver's housing stock [1]. Commit to adding this many units to the housing stock every year for the next 10 years and you'll have solved the housing crisis. (You'll probably need to bail out recent homebuyers, who will be permanently underwater, but that's a separate issue.)[1] http://censusreporter.org/profiles/16000US0820000-denver-co/reply",
      "> You'll probably need to bail out recent homebuyers, who will be permanently underwaterIf you buy a house for $400k, and suddenly it is worth $300k, you don't need to be \"bailed out\" for your purchase decision. You should have been certain that the house was worth $400k to you at the time of purchase. Otherwise you're a speculator, and we shouldn't be bailing out speculators.It's called buyer's remorse. We accept it when it's a car or a TV, but suddenly when it's a house we're supposed to give massive government support to correct the buyer's mistake?reply"
    ],
    "link": "https://denverite.com/2025/07/25/denver-rent-prices-drop-q2/",
    "first_paragraph": "What you need to know about Denver in 5 min\nApartment rents in the Denver metro continue to slide.The average rent in the area fell 3.7 percent in the second quarter compared to the prior year, according to a new report from the Apartment Association of Metro Denver. Rents started falling at the end of last year, the association\u2019s data show.The city\u2019s renters are finally catching a break after a building boom in recent years led to a glut of space that landlords are struggling to fill. The pileup \u2014 including about 20,000 new units in 2024 \u2014 is leading building owners to hold down rents to attract and keep tenants.The average rent in Denver was $1,832 per month, a decline of $71 from the same time in 2024. Current rents are similar to where they were three years ago.This year marks the first time in 15 years that Denver rents have dropped consistently. Earlier this year, Denverite reported on what the change meant for renters and landlords.Rents were still up slightly from the first qua"
  }
]