[
  {
    "title": "Easy RISC-V (dramforever.github.io)",
    "points": 145,
    "submitter": "todsacerdoti",
    "submit_time": "2025-10-27T20:57:12 1761598632",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=45726192",
    "comments": [
      "Having learned assembly with the book \"Computer Organization And Design\" from Patterson and Hennessy, it really shows how much RISC-V takes from MIPS. After all they share some of the people involved in both ISAs and they have learned from the MIPS mistakes (no delay slots!). Basically if you come from a MIPS the assembly is very very similar, as it was my case.Now that book is also available with a RISC-V edition, which has a very interesting chapter comparing all different RISC ISAs and what they do differently (SH, Alpha, SPARC, PA-RISC, POWER, ARM, ...),...However I've been exploring AArch64 for some time and I think it has some very interesting ideas too. Maybe not as clean as RISC-V but with very pragmatic design and some choices that make me question if RISC-V was too conservative in its design.reply",
      "Instructions are more easily added than taken away. RISC-V started with a minimum viable set of instructions to efficiently run standard C/C++ code. More instructions are being added over time, but the burden of proof is on someone proposing a new instruction to demonstrate what adding the instruction costs and how much benefit it brings and in what real-world applications.reply",
      "My memory is a bit fuzzy but I think Patterson and Hennessy\u2018s \u201cComputer Architecture: A Quantitative Approach\u201d had some bits that were explicitly about RISC-V, and similarities to MIPS. Unfortunately my copy is buried in a box somewhere so I can\u2019t get you any page numbers, but maybe someone else remembers\u2026reply",
      "My copy sure doesn't ... it was published in 1992, almost 20 years before anyone got an idea to make a new ISA called \"RISC-V\".reply",
      "> However I've been exploring AArch64 for some time and I think it has some very interesting ideas too. Maybe not as clean as RISC-V but with very pragmatic design and some choices that make me question if RISC-V was too conservative in its design.Not enough people reflect on this, or the fact that it's remarkably hazy where exactly AArch64 came from and what guided the design of it.reply",
      "AArch64 came from AArch32. That's why it keeps things like condition codes, which are a big mistake for large out-of-order implementations.  RISC-V sensibly avoid this by having condition-and-branch instructions instead.  Otherwise, RISC-V is conservative because it tries to avoid possibly encumbered techniques. But other than that it's remarkably simple and elegant.reply",
      "Afair, AArch64 was basically designed by Apple for their A-series iPhone processors, and pushed to be the official ARM standard. Those guys really knew what they were doing and it shows.reply",
      "Yeah the problem with having flags is demonstrated by multiple very high performance implementations of arm64 and x86, while risc-v has exactly zero.reply",
      "> That's why it keeps things like condition codes, which are a big mistake for large out-of-order implementations. RISC-V sensibly avoid this by having condition-and-branch instructions instead.Respectfully, the statement in question is partially erroneous and, in far greater measure, profoundly misleading. A distortion draped in fragments of truth remains a falsehood nonetheless.Whilst AArch64 does retain condition flags, it is not simply because of \u00abAArch32 stretched to 64-bit\u00bb, and condition codes are not a \u00abbig mistake\u00bb for large out-of-order (OoO) cores. AArch64 also provides compare-and-branch forms similar to RISC-V, so the contrast given is a false dichotomy.Namely:  \u2013 \u00abAArch64 came from AArch32\u00bb \u2013 historically AArch64 was a fresh ARMv8-A ISA design that removed many AArch32 features. It has kept flags, but discarded pervasive per-instruction predication and redesigned much of the encoding and register model;\n\n  \u2013 \u00abFlags are a big mistake for large OoO\u00bb \u2013 global flags do create extra dependencies, yet modern cores (x86 and ARM) eliminate most of the cost with techniques such as flag renaming, out-of-order flag generation and using instruction forms that avoid setting flags when unnecessary. As implemented in high-IPC x86 and ARM cores, it shows that flags are not an inherent limiter;\n\n  \u2013 \u00abRISC-V avoids this by having condition-and-branch\u00bb \u2013 AArch64 also has condition-and-branch style forms that do not use flags, for example:\n\n  1) CBZ/CBNZ xN, label \u2013 compare register to zero and branch;\n\n  2) TBZ/TBNZ xN, #bit, label \u2013 test bit and branch.\n\nCompilers freely choose between these and flag-based sequences, depending on what is already available and the code/data flow. Also, many arithmetic operations do not set flags unless explicitly requested, which reduces false flag dependencies.Lastly, but not least importantly, Apple\u2019s big cores are among the widest, deepest out-of-order designs in production, with very high IPC and excellent branch handling. Their microarchitectures and toolchains make effective use of:  \u2013 Flag-free branches where convenient \u2013 CBZ/CBNZ, TBZ/TBNZ (see above);\n\n  \u2013 Flag-setting only when it is free or beneficial \u2013 ADDS/SUBS feeding a conditional branch or CSEL;\n\n  \u2013 Advanced renaming \u2013 including flag renaming \u2013 which removes most practical downsides of a global NZCV.reply",
      "Thanks LLMreply"
    ],
    "link": "https://dramforever.github.io/easyriscv/",
    "first_paragraph": "(Last updated: 2025-10-27 14:51)(Emulators disabled version)This page is not designed to be used on a narrow screen or without\nCSS. If you\u2019re having issues using the emulator, try the emulators disabled version.An interactive introduction to RISC-V assembly programming, by dramforever.Interested in the code? Want to report an issue? Check out the GitHub\npage: https://github.com/dramforever/easyriscvInspired by Easy\n6502 by Nick Morgan, this is a quick-ish introductory tutorial to\nRISC-V assembly programming. This tutorial is intended for those with a\nbasic familiarity with low level computer science concepts, but\nunfamiliar with RISC-V. If you\u2019re curious about RISC-V, I hope this will\nbe a good start to your journey to learning about it.RISC-V (pronounced \u201crisk-five\u201d), as its name suggests, is RISC\n(Reduced instruction set computer) architecture. Having started its\nlife at UC Berkerley, RISC-V has bred a lively community of students,\nresearchers, engineers and hobbyists working on soft"
  },
  {
    "title": "10M people watched a YouTuber shim a lock; the lock company sued him \u2013 bad idea (arstechnica.com)",
    "points": 761,
    "submitter": "Brajeshwar",
    "submit_time": "2025-10-27T12:42:42 1761568962",
    "num_comments": 290,
    "comments_url": "https://news.ycombinator.com/item?id=45720376",
    "comments": [
      "If you don't know him already, I highly recommend videos by LockPickingLawyer \u2014 he routinely destroys bogus claims of various companies within seconds. It's quite entertaining to see how little security you actually get from most locks.I wonder if anybody tried suing him\u2026reply",
      "LPL owns Covert Instruments, who employs McNally, the YouTuber who got sued in this case. Probably not a coincidence that Covert Instruments wasn't named in the lawsuit.reply",
      "I wonder if McNally knows a lawyer familiar with lock picking ;-)reply",
      "Oh sweet never knew there was a connection between LPL and McNally - I just notice they always cut their shims from cans the same wayreply",
      "There aren't that many ways to cut a shim from a can that work and don't take excessive effort. It's a rounded hook shape, with a handle piece trimmed so you don't cut yourself.reply",
      "In addition I've seen LPL refer to \"my friend Trevor McNally\" in a couple of videos.reply",
      "That explains so much. Done to well for a goof channel, eclectic assortment of skills (\"tactical garden trowel\" vs fully equipped metal shop vs perfect video production), all fat trimmed off the videos.I kinda want tvtropes to put a name on his slapstick humor. It's like looking over the shoulder of that weird uncle that seems to live in an entirely different world.reply",
      "> Probably not a coincidence that Covert Instruments wasn't named in the lawsuitWhat's the non-coincidence?reply",
      "That they avoided naming the lawyer or the lawyer's company in their bogus lawsuit and instead only named the non-lawyer.reply",
      "He can still defend his employee, right?reply"
    ],
    "link": "https://arstechnica.com/tech-policy/2025/10/suing-a-popular-youtuber-who-shimmed-a-130-lock-what-could-possibly-go-wrong/",
    "first_paragraph": "\n      It\u2019s still legal to pick locks, even when you swing your legs.\n    \u201cOpening locks\u201d might not sound like scintillating social media content, but Trevor McNally has turned lock-busting into online gold. A former US Marine Staff Sergeant, McNally today has more than 7 million followers and has amassed more than 2 billion views just by showing how easy it is to open many common locks by slapping, picking, or shimming them.This does not always endear him to the companies that make the locks.On March 3, 2025, a Florida lock company called Proven Industries released a social media promo video just begging for the McNally treatment. The video was called, somewhat improbably, \u201cYOU GUYS KEEP SAYING YOU CAN EASILY BREAK OFF OUR LATCH PIN LOCK.\u201d In it, an enthusiastic man in a ball cap says he will \u201cprove a lot of you haters wrong.\u201d He then goes hard at Proven\u2019s $130 model 651 trailer hitch lock with a sledgehammer, bolt cutters, and a crowbar.Naturally, the lock hangs tough.An Instagram us"
  },
  {
    "title": "Claude for Excel (claude.com)",
    "points": 443,
    "submitter": "meetpateltech",
    "submit_time": "2025-10-27T16:09:22 1761581362",
    "num_comments": 336,
    "comments_url": "https://news.ycombinator.com/item?id=45722639",
    "comments": [
      "What is with the negativity in these comments? This is a huge, huge surface area that touches a large percentage of white collar work. Even just basic automation/scaffolding of spreadsheets would be a big productivity boost for many employees.My wife works in insurance operations - everyone she manages from the top down lives in Excel. For line employees a large percentage of their job is something like \"Look at this internal system, export the data to excel, combine it with some other internal system, do some basic interpretation, verify it, make a recommendation\". Computer Use + Excel Use isn't there yet...but these jobs are going to be the first on the chopping block as these integrations mature. No offense to these people but Sonnet 4.5 is already at the level where it would be able to replicate or beat the level of analysis they typically provide.reply",
      "Having wrangled many spreadsheets personally, and worked with CFOs who use them to run small-ish businesses, and all the way up to one of top 3 brokerage houses world-wide using them to model complex fixed income instruments... this is a disaster waiting to happen.Spreadsheet UI is already a nightmare. The formula editing and relationship visioning is not there at all. Mistakes are rampant in spreadsheets, even my own carefully curated ones.Claude is not going to improve this. It is going to make it far, far worse with subtle and not so subtle hallucinations happening left and right.The key is really this - all LLMs that I know of rely on entropy and randomness to emulate human creativity. This works pretty well for pretty pictures and creating fan fiction or emulating someone's voice.It is not a basis for getting correct spreadsheets that show what you want to show. I don't want my spreadsheet correctness to start from a random seed. I want it to spring from first principles.reply",
      "I don't think tools like Claude are there yet, but I already trust GPT-5 Pro to be more diligent about catching bugs in software than me, even when I am trying to be very careful. I expect even just using these tools to help review existing Excel spreadsheets could lead to a significant boost in quality if software is any guide (and Excel spreadsheets seem even worse than software when it comes to errors).That said, Claude is still quite behind GPT-5 in its ability to review code, and so I'm not sure how much to expect from Sonnet 4.5 in this new domain. OpenAI could probably do better.reply",
      "> That said, Claude is still quite behind GPT-5 in its ability to review code, and so I'm not sure how much to expect from Sonnet 4.5 in this new domain. OpenAI could probably do better.It\u2019s always interesting to see others opinions as it\u2019s still so variable and \u201cvibe\u201d based. Personally, for my use, the idea that any GPT-5 model is superior to Claude just doesn\u2019t resonate - and I use both regularly for similar tasks.reply",
      "I also find the subjective nature of these models interesting, but in this case the difference in my experiences between Sonnet 4.5 and GPT-5 Codex, and especially GPT-5 Pro, for code review is pretty stark. GPT-5 is consistently much better at hard logic problems, which code review often involves.I have had GPT-5 point out dozens of complex bugs to me. Often in these cases I will try to see if other models can spot the same problems, and Gemini has occasionally but the Claude models never have (using Opus 4, 4.1, and Sonnet 4.5). These are bugs like complex race conditions or deadlocks that involve complex interactions between different parts of the codebase. GPT-5 and Gemini can spot these types of bugs with a decent accuracy, while I\u2019ve never had Claude point out a bug like this.If you haven\u2019t tried it, I would try the codex /review feature and compare its results to asking Sonnet to do a review. For me, the difference is very clear for code review. For actual coding tasks, both models are much more varied, but for code review I\u2019ve never had an instance where Claude pointed out a serious bug that GPT-5 missed. And I use these tools for code review all the time.reply",
      "My first job out of uni was building a spreadsheet infra as code version control system after a Windows update made an eight year old spreadsheet go haywire and lose $10m in a afternoon.Spreadsheets are already a disaster.reply",
      "I know you probably can't share the details, but if you can I (and I'm sure all of us) would love to hear themreply",
      "It's interesting that you mention disaster; there is at least one annual conference dedicated to \"spreadsheet risk management\".[1][1] https://eusprig.org/reply",
      "Compared to what? Granted, Excel incidents are probably underreported and might produce \"silent\" consequential losses. But compared to that, for enterprise or custom software in general we have pretty scary estimates of the damages. Like Y2K (between 300-600bn) and the UK Postal Office thing (~1bn).reply",
      "Excel spreadsheets ARE custom software, with custom requirements, calculations, and algorithms. They're just not typically written by programmers, have no version control or rollback abilities, are not audited, are not debuggable, and are typically not run through QA or QC.reply"
    ],
    "link": "https://www.claude.com/claude-for-excel",
    "first_paragraph": ""
  },
  {
    "title": "Iroh-blobs (iroh.computer)",
    "points": 28,
    "submitter": "janandonly",
    "submit_time": "2025-10-27T23:28:13 1761607693",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=45727557",
    "comments": [
      "Iroh is fantastic.I\u2019ve been intending to play with it more, it\u2019s given me so many little project ideas that otherwise would be a painreply",
      "[insert yet another comment about having short product introductions at the top pf blog posts]From their docs page:> Iroh lets you establish direct peer-to-peer connections whenever possible, falling back to relay servers if necessary. This gives you fast, reliable connections that are authenticated and encrypted end-to-end using QUIC.reply",
      "and iroh-blobs: provides blob and blob sequence transfer support for iroh. It implements a simple request-response protocol based on BLAKE3 verified streaminghttps://www.iroh.computer/proto/iroh-blobsreply",
      "How does the use case differ from e.g. Tailscale?reply",
      "Or zenoh?reply"
    ],
    "link": "https://www.iroh.computer/blog/iroh-blobs-0-95-new-features",
    "first_paragraph": "Iroh-blobs 0.95 contains a number of significant new features that are worth explaining in detail. There are several new features that are useful for blobs users and also for iroh users in general.Let's start with a feature that is essential for blobs itself, but can also be useful for many other protocols.There is a new connection pool in util::connection_pool. This is useful whenever you have a protocol that has to talk to a large number of endpoints while keeping an upper bound of concurrent open connections. In blobs, this is used whenever you use the downloader to orchestrate blobs downloads from multiple providers.Iroh connections are relatively lightweight, but even so you don't want to keep thousands of them open at the same time. But opening a new connection every time you do a small exchange with a peer is very wasteful. The ConnectionPool gives you an API to deal with these tradeoffs.Let's first look at basic usage:get_or_connect will try to get an existing connection from t"
  },
  {
    "title": "JetKVM \u2013 Control any computer remotely (jetkvm.com)",
    "points": 255,
    "submitter": "elashri",
    "submit_time": "2025-10-27T16:44:17 1761583457",
    "num_comments": 138,
    "comments_url": "https://news.ycombinator.com/item?id=45723159",
    "comments": [
      "Provenance and trust are relevant for a remote KVM.But I can't find any information on their Web site about who runs the JetKVM company, not even a partial name or handle of anyone, nor even what country they are in.  Which seems odd for how much this product needs to be trusted.Searching elsewhere, other than the company Web site... Crunchbase for JetKVM shows 2 people, who it says are based in Berlin, and who also share a principal company, BuildJet, which Crunchbase says is based in Estonia.  The product reportedly ships from Shenzhen.  BuildJet apparently is a YC company, but BuildJet's Web site has very similar lack of info identifying anyone or their location, again despite the high level of trust required for this product.Are corporate customers who are putting these products into positions of serious trust -- into their CI, and remote access to inside their infrastructure -- doing any kind of vetting?  When the official Web sites have zero information about who this is, are the customers getting the information some other way, before purchasing and deploying?If these people are still running the companies, why aren't they or anyone else mentioned on the company Web sites?  That would be helpful first step for trust for corporate use.  So its absence is odd.reply",
      "If you do this sort of thing often, I'd love to chat further. I'm basically trying to automate this sort of manual research around companies with a library of deep research APIs.Had a show HN last week that seemed to go under the radar: https://news.ycombinator.com/item?id=45671087We launched corporate hierarchy research and working on UBO now. From the corporate hierarchy standpoint, it looks like the Delaware entity fully owns the Estonian entity. Auto generated mermaid diagram from the deep research:  graph TD\n    e1[BuildJet, Inc.]-->|100%, 2022-12-16|e2[Buildjet O\u00dc]reply",
      "Looks like you have a potentially great business for corporate compliance, if you can answer with plausibly high confidence (or indemnify?).I only occasionally research companies, and it's from an engineering&product perspective, aside from corporate ownership compliance.  (For example, I was asked to vet a little-known company as a prospective partner, for building our cloud infrastructure atop theirs.  One of the first rapid low-cost, high-value things I could do, besides looking at their docs and trying their demos, was to skim through the history of business news about them.)reply",
      "Interesting. That's actually where we started. We were doing automated research on vendors from a TPRM perspective and looking for data points around organizational security / reputation. Examples - if the company had been hacked before / how they responded, do they have a CISO, nth party vendors, are they SOC2 / FedRAMP certified, etc. Basically, predictors of risk / stability.We realized the underlying business graph was the bottleneck though, so that's been our focus for some time. With that in place, we're now coming full circle on the risk research standpoint.On your comment about confidence / liability, we're actually having conversations around that now and getting feedback. First step is exposing all the research and evidence directly to build trust, which is what we're doing now for the new corporate hierarchy system.reply",
      "If you want to feature a governance structure infamously hard to get right and impressive to use as an demo, IKEA/Ingka would be an good example.reply",
      "Good idea! I picked a random California Ikea entity (IKEA US RETAIL LLC) and ran it through the system. Here's the output - current goal is to get to ultimate parent.## Summary\nIKEA US RETAIL LLC is a limited liability company. It is wholly owned by IKEA Holding U.S., Inc., and ultimately controlled by Stichting INGKA Foundation, a Dutch foundation that owns Ingka Group.## Graph  graph TD\n    e2[IKEA Property, Inc.]-->e1[IKEA US RETAIL LLC]\n    e3[IKEA Holding U.S., Inc.]-->e1[IKEA US RETAIL LLC]\n    e4[Ingka Holding B.V.]-->e3[IKEA Holding U.S., Inc.]\n    e4[Ingka Holding B.V.]-->e4[Ingka Holding B.V.]\n    e5[Stichting INGKA Foundation]-->|100%, 1982|e4[Ingka Holding B.V.]\n\nThis is the permalink to the deep research result: https://savvyiq.ai/playground/entity-hierarchy/siq_31ro4EDce...reply",
      "This guy on YouTube made several videos reviewing these and also doing some WireShark analysis, also on NanoKVM.Personally I'd never use these on an interned facing network. But they can still be handy for local only.https://m.youtube.com/watch?v=yHhdTRVvDFU&pp=0gcJCQYKAYcqIYz...reply",
      "i got nanokvm pro desktop a couple of days ago. looks like what was before is no more now. i run tcpdump for a while, the only outbound connections are ntpreply",
      "I think products like JetKVM are targeting hobbyists and small outfits; corporations who aren't on a public cloud are using stuff like idrac, ilo, or dedicated rackmount KVM hardware.reply",
      "Thanks, needed a good laugh.Putting a BMC or KVM on the Internet is hilariously unwise.No need worry about dodgy remote desktop software \u2014 the attackers will be able to back door the firmware!(Yes, iLO verifies firmware signatures\u2026 but yes they\u2019ve had horrific vulnerabilities, worse than nightmares).reply"
    ],
    "link": "https://jetkvm.com/",
    "first_paragraph": "High-definition 1080p video at 60 FPS with 30-60 millisecond latency, using efficient H.264 encoding. Smooth mouse and keyboard action transfer for responsive remote interaction.Optional remote management via our open-source JetKVM Cloud using WebRTC. Privacy-first design with opt-in cloud access that provides secure and fast direct connections, even behind the most restrictive NAT environments, with our STUN and TURN servers.JetKVM is built on a robust Golang foundation and powered by Linux for adaptability and transparency. Whether you're a seasoned developer or an enthusiastic tinkerer, you can easily modify or fine-tune the software using familiar tooling and straightforward SSH uploads.Combining a Go-based backend with a React-powered WebRTC dashboard. Perfect for forking, submitting new features, fixing bugs, or customizing local streaming and control.Our cloud-hosted management interface is fully open source. Delve into our secure remote connection orchestration or fork it to bu"
  },
  {
    "title": "Simplify your code: Functional core, imperative shell (googleblog.com)",
    "points": 162,
    "submitter": "reqo",
    "submit_time": "2025-10-25T07:07:59 1761376079",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=45701901",
    "comments": [
      "Even large companies are still grasping at straws when it comes to good code. Meanwhile there are articles I wrote years ago which explain clearly from first principles why the correct philosophy is \"Generic core, specific shell.\"I actually remember early in my career working for a small engineering/manufacturing prototyping firm which did its own software, there was a senior developer there who didn't speak very good English but he kept insisting that the \"Business layer\" should be on top. How right he was. I couldn't imagine how much wisdom and experience was packed in such simple, malformed sentences. Nothing else matters really. Functional vs imperative is a very minor point IMO, mostly a distraction.reply",
      "> Even large companies are still grasping at straws when it comes to good codeProbably many reasons for this, but what I've seen often is that once the code base has been degraded, it's a slippery slope downhill after that.Adding functionality often requires more hacks. The alternative is to fix the mess, but that's not part of the task at hand.reply",
      "I've seen it many times. And then every task takes longer than the last one, which is what pushes teams to start rewrites. \n\"There's never enough time to do it right, but always time to do it again.\"reply",
      "These are great and succinct, yours and your teammate\u2019s.I still find myself debating this internally, but one objective metric is how smoothly my longer PTOs go:The only times I haven\u2019t received a single emergency call were when I left teammates a a large and extremely specific set of shell scripts and/or executables that do exactly one thing. No configs, no args/opts (or ridiculously minimal), each named something like run-config-a-for-client-x-with-dataset-3.ps1 that took care of everything for one task I knew they\u2019d need. Just double click this file when you get the new dataset, or clone/rename it and tweak line #8 if you need to run it for a new client, that kind of thing.Looking inside the scripts/programs looks like the opposite of all of the DRY or any similar principles I\u2019ve been taught (save for KISS and others similarly simplistic)But the result speaks for itself. The further I go down that excessively basic path, the more people can get work done without me online, and I get to enjoy PTO. Anytime i make a slick flexible utility with pretty code and docs, I get the \u201cany chance you could hop on?\u201d text. Put the slick stuff in the core libraries and keep the executables dumbreply",
      "Yes I feel that when to apply certain techniques is frequently under-discussed. But I can't blame people for err-ing on the side of 'do everything properly' - as this makes life more pleasant in teams.\nAlthough I think if you squint, the principle still applies to your example. The further you get from the 'core' of your platform/application/business/what-have-you, the less abstract you need to be.reply",
      "I\u2019d love to know more, do you have any links to your articles?reply",
      "\"Specific on the surface, generic underneath\" (Medium paywalled): https://medium.com/tech-renaissance/generic-internals-specif...reply",
      "> The more specific, the more brittle. The more general, the more stable. Concerns evolve/decay at different speeds, so do not couple across shearing layers. Notice how grammar/phonology (structure) changes slowly while vocabulary (functions, services) changes faster....> Coupling across layers invites trouble (e.g. encoding business logic with \u201cintuitive\u201d names reflecting transient understanding). When requirements shift (features, regulations), library maintainers introduce breaking changes or new processor architectures appear, our stable foundations, complected with faster-moving parts, still crack!https://alexalejandre.com/programming/coupling-language-and-...reply",
      "Bertrand Meyer suggested another way to consider this that ends up in a similar place.For concerns of code complexity and verification, code that asks a question and code that acts on the answers should be separated. Asking can be done as pure code, and if done as such, only ever needs unit tests. The doing is the imperative part, and it requires much slower tests that are much more expensive to evolve with your changing requirements and system design.The one place this advice falls down is security - having functions that do things without verifying preconditions are exploitable, and they are easy to accidentally expose to third party code through the addition of subsequent features, even if initially they are unreachable. Sun biffed this way a couple of times with Java.But for non crosscutting concerns this advice can also be a step toward FC/IS, both in structuring the code and acclimating devs to the paradigm. Because you can start extracting pure code sections in place.reply",
      "Command-Query Separation is the term for that. However, I find this statement odd:> having functions that do things without verifying preconditions are exploitableWhy would you do this? The separation between commands and queries does not mean that executing a command must succeed. It can still fail. Put queries inside the commands (but do not return the query results, that's the job of the query itself) and branch based on the results. After executing a command which may fail, you can follow it with a query to see if it succeeded and, if not, why not.https://en.wikipedia.org/wiki/Command%E2%80%93query_separati...reply"
    ],
    "link": "https://testing.googleblog.com/2025/10/simplify-your-code-functional-core.html",
    "first_paragraph": "Is your code a tangled mess of business logic and side effects? Mixing database calls, network requests, and other external interactions directly with your core logic can lead to code that\u2019s difficult to test, reuse, and understand. Instead, consider writing a functional core that\u2019s called from an imperativ\u200b\u200be shell.Separating your code into functional cores and imperative shells makes it more testable, maintainable, and adaptable. The core logic can be tested in isolation, and the imperati\u200b\u200bve shell can be swapped out or modified as needed. Here\u2019s some messy example code that mixes logic and side effects to send expiration notification emails to users:// Bad: Logic and side effects are mixedfunction sendUserExpiryEmail(): void {\u00a0\u00a0for (const user of db.getUsers()) {\u00a0\u00a0\u00a0\u00a0if (user.subscriptionEndDate > Date.now()) continue;\u00a0\u00a0\u00a0\u00a0if (user.isFreeTrial) continue;\u00a0\u00a0\u00a0\u00a0email.send(user.email, \"Your account has expired \" + user.name + \u201c.\u201d);\u00a0\u00a0}}A functional core should contain pure, testable busines"
  },
  {
    "title": "Pyrex catalog from from 1938 with hand-drawn lab glassware [pdf] (cmog.org)",
    "points": 265,
    "submitter": "speckx",
    "submit_time": "2025-10-27T15:04:05 1761577445",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=45721801",
    "comments": [
      "I love the hand-drawn illustrations, but I really love the typography.Does anyone know which fonts (or, probably more importantly, which modern-day equivalents) are used to get this feeling?reply",
      "For the body copy, I think it's a version of Rockwell. [0] It fits the time, as well as the lower case \"g\" always looks quirky to me in rockwell-flavours. Stubby tail + serif on top. The heft on the headings also matches Rockwell Extra Bold with a couple tiny variations. Plus, just simply... slab serifs.Things working against that are:- % is wrong. That really looks like a different typeface all together. Not unheard of, might be worth seeing if it matches any other monotype fonts.- Bolded headings have some differences. Rockwell Extra Bold should still have circular tittles, but unless it's a scanning artifact, the few lowercase \"i\" examples I can find in those headings seem to be square.- The Rockwell favour in the tables is tweaked, with no descenders and uses tabular digits. This is pretty common, but the digital copies of Rockwell I have laying around don't have those exact forms... doesn't really say much when we're talking about what specific hot-metal type casts did monotype sell them 90-odd years ago.---On the title pages (like page 13), my best guess is Memphis. [1] The R is wrong for Rockwell, but also the lower a in \"Brand\" is totally wrong for Memphis, and the quote is totally different. Going to take lunch, and possibly come back to this in a bit because now I'm intrigued haha.[0] https://en.wikipedia.org/wiki/Rockwell_(typeface)\n[1] https://en.wikipedia.org/wiki/Memphis_(typeface)reply",
      "Comment got deleted, but Gallatin isn't the title page font. That was a digital font released in 2019, which is meant to look like Memphis with a two storey a. https://fontsinuse.com/typefaces/128627/gallatinThat does mention that Linotype had a Memphis flavour with a two-storey \"a\" though... so maaaaaybe it is Memphis! Most likely their Rockwell typeface was also supplied from Linotype in that case, probably under a different name.reply",
      "Agreed, the design is really strikingly beautiful.The typography is part of this, but I suspect you may also be undervaluing how much the overall design contributes here. The layout, use of whitespace, use of different fonts and sizes to convey hierarchy. It's just really good design made with care and attention by a skilled practitioner.reply",
      "It's not precisely the same but you may enjoy Berkeley Mono: https://neil.computer/notes/introducing-berkeley-mono/I enjoy using it for reading and writing code.reply",
      "That's a nice font but... pricey.reply",
      "This catalog is by Corning. Randomly, they have an absolutely incredible museum called The Corning Museum of Glass https://home.cmog.org/ located about 5 hours drive from New York City.reply",
      "You might notice that this link isn't from Corning. It's from the Corning Museum of Glass' excellent libraryreply",
      "Old tool catalogs have similarly great illustrationshttps://archive.org/details/stanley-catalogue-34-1929/page/6...reply",
      "Machine tool manuals too: https://motolab.ru/SIP%20MP-1/reply"
    ],
    "link": "https://exhibitdb.cmog.org/opacimages/Images/Pyrex/Rakow_1000132877.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Go beyond Goroutines: introducing the Reactive paradigm (samuelberthe.substack.com)",
    "points": 50,
    "submitter": "samber",
    "submit_time": "2025-10-20T14:04:53 1760969093",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=45644066",
    "comments": [
      "The supposedly bad example is perfectly readable to anyone familiar with Go. A bit of refactoring into first class functions, and you'd have an easy to read, idiomatic, easy to test, well typed code base with obvious places to adjust useful behaviors like concurrency limits.Meanwhile the samber/ro example is incomplete (Subscribe(...)?), and the source includes some weird stuff: https://github.com/samber/ro/blob/22b84c8296c01c4085e8913944...Not to mention heaps of reflection and panics: https://github.com/samber/ro/blob/22b84c8296c01c4085e8913944...The functionality and expressiveness might be fantastic, but I would evaluate it very carefully before use.reply",
      "I like how he kept \"tabs\" (and display it as 9 spaces) to make it as ugly as possible for the bad example, then proceed to use 4 spaces for the other examples.reply",
      "I\u2019ve come to believe that a direct implementation of something in the language is, where possible, more readable and maintainable in the long term.Libraries that enable terse seemingly magical things tend to just hide a lot and make code harder to read. You end up having to become an expert in what amounts to a DSL on top of the language.reply",
      "i like reactive programming in other languages but it is at odds with Go's philosophy of simplicity and avoiding big abstractionsreply",
      "I think this article does an alright job selling ro over RxGo, but doesn\u2019t really explain why using a reactive library is better than plain go. The channel/goroutine example is fine, as they say, but they hand wave how this will fall apart in a more complex project. Conversely, their reactive example is mapping and filtering an 4 item array and handwave how the simplicity will remain no matter the size of the codebase.I\u2019ve worked in a few complex projects that adopted reactive styles and I don\u2019t think they made things simpler. It was just as easy to couple components with reactive programming as it was without.reply",
      "It's really tough to read through a text where you can't go more than a few sentences without having something be described as *an adjective, a second adjective, and a third adjective*. Just let the code example speak for itself, man.Speaking of the code examples, I am not convinced at all. The supposedly bad example is idiomatic and understandable to me, and I have a much better idea of what's going on than in the supposedly good examples. It contains the kind of constructions I expect to see when working on a Go codebase, and it will be easier to modify correctly for another Go developer coming in later. Please, work with the language instead of forcing it to wear a programming paradigm it doesn't like.reply",
      "It has to be AI generated or at least edited right? The reliance on bulleted lists. The endless adjectives and declarations. ...but also the subtle... well not exactly errors, but facts I think are open to dispute?Such as:> Together, these tools make Go perfect for microservices, real-time systems, and high-throughput backends.Real-time systems?! I have never heard of anyone using Go for realtime systems because of its GC and preemptive scheduler. Seems like the sort of thing an LLM would slip in because it sounds good and nails that 3 item cadence.> Built on top of Go channels \u2192 broken backpressure.But then the example is about ordering. Maybe I'm being pedantic or missing the specific nomenclature the ReactiveX community uses, but backpressure and ordering are different concerns to me.Then the Key Takeaways at the end just seems like an LLMism to me. It's a short article! Do we really need another 3 item list to summarize it?I'm not anti-LLM, but the sameness of the content it generates grates on me.reply",
      "I'm curious if someone could chime in on the state of adoption of these these Rx libraries in other language's ecosystems.My poor memory seems to recall them gaining traction ~10 years ago, but they've fallen hard off my radar.My fear with adopting a library like this for Go is actually that it might end up being very unfriendly to the profiler once bottlenecks start occurring.reply",
      "I use rxjs day in day out for my oss work (eg: https://github.com/mickael-kerjean/filestash/blob/master/pub...)\nIt's quite common to see job description where I live (Sydney) with rxjava but reactive libs are a bit of a niche thing mostly because it takes a bit of time to be proficient at it + not many people talk about it but it's not sexyreply",
      "it's used extensively in java and it would be my first choice when starting a java project. I don't think I'd use it in Go though.reply"
    ],
    "link": "https://samuelberthe.substack.com/p/go-beyond-goroutines-introducing",
    "first_paragraph": ""
  },
  {
    "title": "Yet Another Year with Decker (beyondloom.com)",
    "points": 17,
    "submitter": "RodgerTheGreat",
    "submit_time": "2025-10-19T16:19:35 1760890775",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "http://beyondloom.com/blog/unionstate3.html",
    "first_paragraph": "Today is Decker\u2019s third birthday, and that means we\u2019re well due for another periodic summary of progress, reviewing changes between version 1.44 and 1.60:By far the most impactful change this year was the introduction of DeckRoman, a carefully-selected subset of Unicode which allows Decker to represent and display text from a wide range of non-English languages, including French, Spanish, German, Polish, Portuguese, Hungarian, and Romanian. Decker ships with a variety of bitmapped fonts which support the complete DeckRoman character set as well as a new and improved Font Editor Deck with tools that make it easy to add the new diacritics and special characters.By popular demand, Decker has also gradually expanded support for color (which includes animated patterns, for fans of the <blink> tag):Importing images now respects the \u201cColor\u201d setting in the \u201cStyle\u201d menu, either applying a 1-bit Atkinson Dither or posterizing color images to Decker\u2019s 16-color palette. Want to customize the palet"
  },
  {
    "title": "Why Busy Beaver hunters fear the Antihydra (benbrubaker.com)",
    "points": 140,
    "submitter": "Bogdanp",
    "submit_time": "2025-10-27T16:56:04 1761584164",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=45723359",
    "comments": [
      "The best current lower bound for BB(6) is 2\u2191\u21912\u2191\u21912\u2191\u21919 (google \"Knuth Up Arrow\" if this makes no sense), a number so inconceivably large it gives me the willies.In particular, this means that in going from BB(5) to BB(6), you have already crossed the line where the actual busy beaver TM can no longer be simulated step by step in the lifetime of our universe (or a googol lifetimes of our universe for that matter).It really is mind bending how fast this function grows.reply",
      "One of the curiosities about this function is that computing BB(748) is independent of ZFC.https://scottaaronson.blog/?p=4916reply",
      "The record's been lowered since then, I should note.  At least down into the 600s, I've seen claims of down in the 400s.  But I haven't really kept up with this.reply",
      "The BB function does grow mind bendingly fast. The machine running for 2\u2191\u21912\u2191\u21912\u2191\u21919 steps is one of the 4^12*23836540 = 399910780272640 differently behaving 6-state machines [1].A similarly fast growing function is the functional busy beaver [3]. Among all 77519927606 closed lambda terms of size <= 49 bits, there is one whose normal form size exceeds the vastly larger Graham's Number [3].Several beaver fans believe that BB(7) might exceed Graham's Number as well, which struck me as unlikely enough to offer a $1k bet against it, the outcome of which will be known in under a decade.[1] https://oeis.org/A107668[2] https://oeis.org/A333479[3] https://en.wikipedia.org/wiki/Graham%27s_numberreply",
      "> It really is mind bending how fast this function grows.While the BB function is obviously a well-defined function over the integers, I find it helpful to think of it as a function over qualitatively heterogeneous items\u2014such as stones, bread toasters, mechanical watches, and computers. The key idea is to view the underlying computing devices not as \u201ca little more powerful\u201d than the previous ones, but as fundamentally different kinds of entities.reply",
      "> best current lower boundWell is there a best current UPPER bound, or at least a \"probvious\" one?reply",
      "I think finding an upper bound is basically just as difficult as finding the actual value itself, since both would require proving that all of the programs which run longer than that will run forever. That's why we can say BB(x) grows faster than any computable function. Being able to compute BB(x) algorithmically or any faster growing function would let you solve the halting problemreply",
      "There is no general procedure for computing upper bounds on busy beaver numbers (this can be proven). We haven't even come close to enumerating all of the interesting six-state Turing machines, so right now we don't even have a wild guess for an upper bound on BB(6).reply",
      "That was a really well written article. I think even somebody who had never heard of a Turing Machine could probably have gotten a pretty reasonable quick understanding of roughly what BB(5) and BB(6) are and how the Antihydra works and its greater mathematical/historical context. That's hard to do, good job!reply",
      "TLDR; As BB(n) gets larger, they can encode more random walk style problems that have a stop condition related to the position of the random walk. Proving that such a condition is unlikely may be easy, but proving it never occurs is very difficult.reply"
    ],
    "link": "https://benbrubaker.com/why-busy-beaver-hunters-fear-the-antihydra/",
    "first_paragraph": ""
  },
  {
    "title": "Rust cross-platform GPUI components (github.com/longbridge)",
    "points": 463,
    "submitter": "xvilka",
    "submit_time": "2025-10-27T09:44:18 1761558258",
    "num_comments": 199,
    "comments_url": "https://news.ycombinator.com/item?id=45719004",
    "comments": [
      "This looks to be one of the most complete Rust UI creates (in terms of available widgets/components), but unfortunately has almost no usage (yet). I do see their docs are coming along now. Another very complete one is fyrox-ui used by the fyrox game engine: https://crates.io/crates/fyrox-ui. Again, not really used/known outside of fyrox.The Rust UI scene is maturing, but the most popular options (iced, egui, dioxus, slint, etc.) aren't even the most complete component-wise atm as far as I can tell.UPDATE: This honestly looks incredible and makes huge strides in the Rust UI landscape. You can run an impressive widget gallery app here showing all their components:https://github.com/longbridge/gpui-component/tree/main/crate...Just \"cargo run --release\"reply",
      "> but unfortunately has almost no usagegpui itself is spun out of the zed editor, so I'd say it probably has more real-world usage than the majority of rust UI cratesreply",
      "Oh thats why it looked so familiar.I actually tried to create a UI kit using zed's code for a personal project, but gave up.nice to see I was not the only one with the idea and it can get some usage now. \nThe example app looks awesome.reply",
      "As of August 2025, Zed had 150K monthly active users. That was before it supported Windows; the number is much higher now (although not publicly reported).I'd be very surprised to learn that any other Rust UI crate has more real-world usage than GPUI!Source:https://sequoiacap.com/article/partnering-with-zed-the-ai-po...reply",
      "users is a finicky metric. When Palia came out, a game you most likely have never heard of, I wrote a desktop installer for it with Druid, which a few million people downloaded and used to install and run Palia. Only a handful of people worked on this codebase, maybe three or four while I was there, but principally me and one other engineer.The more salient metrics would be things like how many people know how to use the framework, the variety of use-cases its good for solving, how easy it is to hire or get help with it, etc. As for Druid, Druid is already officially unmaintained, its core developer having moved on to work on Xilem instead. (my experience, for the record, was positive, I very much enjoyed working with Druid.)reply",
      "Iirc Cosmic Desktop uses Icedreply",
      "Kraken seems to have a desktop application for trading made in Iced as well.I wonder if there are more Cosmic Desktop + Kraken desktop users than Zed Editor users?reply",
      "GPUI yes, but I'm not so sure about GPUI Component which is what I assumed the parent was talking about.reply",
      "I don't know that it's all that meaningful to discuss the component library as if it were its own UI framework. None of the other rust UI frameworks have distinct component libraries with distinct usage data eitherreply",
      "Fyrox is such a blackpill for me (makes me doubt the Rust gamedev scene), because Fyrox appears to be the most mature Rust game engine, but nobody uses it or cares about it. Instead everyone is excited about the Entity-Component-System in Bevy, but once all the rough edges of Bevy are smoothed out, people excited about the ECS are going to realize they don't actually want to make art, or create game mechanics, they were just excited about a neat system (and in fairness, ECS is neat), but they never really wanted to do the things required for a game.reply"
    ],
    "link": "https://github.com/longbridge/gpui-component",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n\n\n\n\n            Couldn't load subscription status.\u00a0\n             \nRetry\n\n\n\n There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Rust GUI components for building fantastic cross-platform desktop application by using GPUI.\n      \n\n\n\n\n                Couldn't load subscription status.\n                 \nRetry\n\n\n\n There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.  UI components for building fantastic desktop applications using GPUI.Here is the first application: Longbridge Pro, built using GPUI Component.We built multi-theme support in the application. This feature is not included in GPUI C"
  },
  {
    "title": "Are these real CVEs? VulDB entries for dnsmasq rely on replacing config files (seclists.org)",
    "points": 16,
    "submitter": "JawsofDeath",
    "submit_time": "2025-10-27T22:35:00 1761604500",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=45727137",
    "comments": [
      "Why does it matter? I know the answer and this is a philosophical complaint, but the purpose of CVE is simply to make sure that people are talking about the same bug, not as a certification of importance or impact.In this particular case, the poster is complaining that 3 CVEs were assigned for memory corruption vulnerabilities reachable only from the dnsmasq configuration file. I didn't read carefully, but the presumption that config file memory corruption bugs aren't vulnerabilities is problematic, because user input can find its way into configurations through templating; it depends on how innocuous the field triggering the bug is.reply",
      "I suspect the big problem here is thinly-stretched volunteer maintainers.I am very sympathetic to the idea that all memory corruption bugs should be fixed systematically, whether or not they're exploitable. It works well for OpenBSD. And, well, I wouldn't have leaned into Rust so early if I wasn't a bit fanatic about fixing memory corruption bugs.But at the same time, a lot of maintainers are stretched really thin. And many pieces of software choose to trust some inputs, especially inputs that require root access to edit. If you want to take user input and use it to generate config files in /etc, you should plan to do extremely robust sanitization. Or to make donations to thinly-stretched volunteer maintainers, perhaps.reply",
      "CVEs, however, do get scored according to CVSS, and they are often extremely hostile and live in fantasy land.CVEs also cannot be denied by projects, and are often used as an avenue of harassment towards open source projects.I agree with the poster on that mailing list, this is not, nor should be, a CVE. At no point can you edit those files without being root.reply",
      "Is that not a problem with how people are using CVEs, scoring them and attaching value to them rather than whether a CVE should be assigned itself. A CVE is simply a number and some data on a vulnerability so that the community knows they are all talking about the same issueEven if you need to be root to edit the files, it still is a deviation from the design or reasonably expected behaviour or that interface, so is still a bug and should still get a CVE. It should either be fixed or failing that documented as 'wont fix' and on the radar of anyone building an application. Someone building the next plesk or cpanel or similar management system should at least know about filtering their input and not allowing it to get to the dangerous config file.Can't the project release a statement saying that the bug writeup is low quality and unable to be reproduced? Anyone ignoring that without question and using it as evidence that the project is bad without proof is putting way too much value in CVEs and the fault is their ownreply",
      "If someone can template in data, it's a lot easier to just set \"dhcp-script=/arbitrary/code\"If the person templating isn't validating data, then it's already RCE to let someone template into this config file without careful validation.... Also, this is a segfault, the chance anyone can get an RCE out of '*r = 0' for r being slightly out of bounds is close to nil, you'd need an actively malicious compiler.While CVE's in theory are \"just a number to coordinate with no real meaning\", in practice a \"Severity: High\" CVE will trigger a bunch of work for people, so it's obviously not ideal to issue garbage ones.reply",
      "Maybe we should issue a CVE for company vulnerability response processes that blindly take CVSS scoring as input without evaluating the vulnerability.reply",
      "Like I said, it depends on the configuration field. But people saying \"you have to be root to change this configuration\" are missing the point.If the argument is \"CVSS is a complete joke\", I think basically every serious practitioner in the field agrees with that.reply",
      "Vulnerabilities can and often are chained together.While the relevant configuration does require root to edit, that doesn\u2019t mean that editing or inserting values to dnsmasq as an unprivileged user doesn\u2019t exist as functionality in another application or system.There are frivolous CVEs issued without any evidence of exploitability all the time. This particular example however, isn\u2019t that. These are pretty clearly qualified as CVEs.The implied risk is a different story, but if you\u2019re familiar with the industry you\u2019ll quickly learn that there are people with far more imagination and capacity to exploit conditions you believe aren\u2019t practically exploitable, particularly in highly available tools such as dnsmasq. You don\u2019t make assumptions about that. You publish the CVE.reply",
      ">that doesn\u2019t mean that editing or inserting values to dnsmasq as an unprivileged user doesn\u2019t exist as functionality in another application or system.The developer typically defines its threat model. My threat model would not include another application inserting garbage values into my application's config, which is expected to be configured by a root (trusted) user.The Windows threat model does not include malicious hardware with DMA tampering with kernel memory _except_ maybe under very specific configurations.reply",
      "> The developer typically defines its threat model.Is this the case? As we're seeing here, getting a CVE assigned does not require input or agreement from the developer. This isn't a bug bounty where the developer sets a scope and evaluates reports. It's a common database across all technology for assigning unique IDs to security risks.The developer puts their software into the world, but how the software is used in the world defines what risks exist.reply"
    ],
    "link": "https://seclists.org/oss-sec/2025/q4/79",
    "first_paragraph": ""
  },
  {
    "title": "AI can code, but it can't build software (bytesauna.com)",
    "points": 98,
    "submitter": "nreece",
    "submit_time": "2025-10-27T23:41:32 1761608492",
    "num_comments": 65,
    "comments_url": "https://news.ycombinator.com/item?id=45727664",
    "comments": [
      "This is a good headline. LLMs are remarkably good at writing code. Writing code isn't the same thing as delivering working software.A human expert needs to identify the need for software, decide what the software should do, figure out what's feasible to deliver, build the first version (AI can help a bunch here), evaluate what they've built, show it to users, talk to them about whether it's fit for purpose, iterate based on their feedback, deploy and communicate the value of the software, and manage its existence and continued evolution in the future.Some of that stuff can be handled by non-developer humans working with LLMs, but a human expert needs who understands code will be able to do this stuff a whole lot more effectively.I guess the big question is if experienced product management types can pick up enough coding technical literacy to work like this without programmers, or if programmers can pick up enough enough PM skills to work without PMs.My money is on both roles continuing to exist and benefit from each other, in a partnership that produces results a lot faster because the previously slow \"writing the code\" part is a lot faster than it used to be.reply",
      "> LLMs are remarkably good at writing code.Just this past weekend, I've designed and written code (in Typescript) that I don't think LLMs can even come close to writing in years. I have a subscription to a frontier LLM, but lately I find myself using like 25% of the time.At a certain level the software architecture problems I'm solving, drawing upon decades of understanding about maintainable, performant, and verifiable design of data structures and types and algorithms, are things LLMs cannot even begin to grasp.At that point, I find that attempting to use an LLM to even draft an initial solution is a waste of time. At best I can use it for initial brainstorming.The people saying LLMs can code are hard for me to understand. They are good for simple bash scripts and complex refactoring and drafting basic code idioms and that's about it.And even for these tasks the amount of hand-holding I need to do is substantial. At least Gemini Pro/CLI seems good at one-shot performance, before its context gets poisonedreply",
      "I find LLMs most helpful when I already have half of the answer written and need them to fill in the blanks.\"Take X and Y I've written before, some documentation for Z, an example W from that repo, now smash them together and build the thing I need\"reply",
      "Can you maybe give an example you\u2019ve encountered of an algorithm or a data structure that LLMs cannot handle well?In my experience implementing algorithms from a good comprehensive description and keeping track of data models is where they shine the most.reply",
      "Example (expanding on [1]): I want to design a strongly typed fluent API interface to some role/permissions based authorization engine functionality. Even knowing how to shape the fluent interface so that is powerful but intuitive, as strongly typed as possible but also and maintainable, is a deep art.One reason I know LLM can't come close to my design is this: I written something that works (that a typical senior engineer might write), but the is not enough. I have evaluated it critically (drawing on my experience with long lived software), rewritten it again to better meet the targets above, and repeated this process several times. I don't know what would make an LLM go: now that kind of works, but is this the most intuitive, well typed, and maintainable design that there could be?1. https://news.ycombinator.com/item?id=45728183reply",
      "Converting an algorithm implementation from recursive to iterative: it got the concept broadly right, but was quite bad at making the logic actually match up, often refusing to fix mistakes or reverting fixes two edits later. Still a positive experience though, since it was fixable issues and reduced the amount of tedious copies I had to typereply",
      "Did you have it write tests and give it the ability to iterate & validate its implementation without you in the loop?Anything less is setting it up for failure...reply",
      "Yes, but it got 99% of those then got stuck on why the others made no sense to itreply",
      "> The people saying LLM can code are hard for me to understand.Just today, I spent an hour documenting a function that performs a set of complex scientific simulations. Defined the function input structure, the outputs, and put a bunch of references in the body to function calls it would use.I then spent 15 minutes explaining to the free version of ChatGPT what the function needs to do both in scientific terms and in computer architecture terms (e.g. what needed to be separated out for unit tests). Then it asked me to answer ~15 questions it had (most were yes/no, it took about 5 min), then it output around 700 lines of code.It took me about 5 minutes to get it working, since it had a few typos. It ran.Then I spent another 15 minutes laying out all the categories of unit tests and sanity tests I wanted it to write. It produced ~1500 lines of tests. It took me half an hour to read through them all, adjusting some edge cases that didn't make sense to me and adjusting the code accordingly. And a couple cases where it was testing the right part of the code, but had made valiant but wrong guesses as to what the scientifically correct answer would be. All the tests then passed.All in all, a little over two hours. And it ran perfectly. In contrast, writing the code and tests myself entirely by hand would have taken at least a couple of entire days.So when you say they're good for those simple things you list and \"that's about it\", I couldn't disagree more. In fact, I find myself relying on them more and more for the hardest scientific and algorithmic programming, when I provide the design and the code is relatively self-contained and tests can ensure correctness. I do the thinking, it does the coding.reply",
      "> Just today, I spent an hour documenting a function that performs a set of complex scientific simulations. Defined the function input structure, the outputs, and put a bunch of references in the body to function calls it would use.So that's... math. A very well defined problem, defined very well. Any decent programmer should be able to produce working software from that, and it's great that ChatGPT was able to help you get it done much faster than you could have done it yourself. That's also the kind of project that's very well suited for unit testing, because again: math. Functions with well defined inputs, outputs, and no side-effects.Only a tiny subset of software development projects are like that though.reply"
    ],
    "link": "https://bytesauna.com/post/coding-vs-software-engineering",
    "first_paragraph": "October 27, 2025Have you noticed that quite a few people are looking for technical cofounders\nor CTOs right now? I, for one, get a surprising amount of these queries; most\nof them along the lines of \u201chey, I have this vibe-coded app, would you like to\nmake it production-ready\u201d. I have sort of a profile for these people. Think\nsomeone who knows their business but has always lacked the technical skills to\nmake their ideas happen \u2014 a legal counsel, perhaps, or an account manager.Why would these people need me? That's what I've thought about a little bit,\nand I think there is an important signal here: What is it exactly that they\ncan\u2019t get done with GenAI alone? This is something everyone is trying to\nunderstand, right? Everyone wants to know what these models can do. Or, to be a\nlittle blunt, everyone wants to know which jobs are soon to become obsolete.\nThe fact that I get these requests says something about software engineering. I\nmean, if software engineering was automated, no one would"
  },
  {
    "title": "MCP-Scanner \u2013 Scan MCP Servers for vulnerabilities (github.com/cisco-ai-defense)",
    "points": 103,
    "submitter": "hsanthan",
    "submit_time": "2025-10-27T17:18:39 1761585519",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=45723699",
    "comments": [
      "At Snyk, we've been working on this for a while. Here's our flagship open source project consolidating a lot of the MCP risk factors we've discovered over the last year or so into actionable info: https://github.com/invariantlabs-ai/mcp-scanreply",
      "Would you want to share how/why it's different from the submission, since you're making a comment here?reply",
      "I believe one of the main differences is that our scanner looks for toxic flows between mcp endpoints regarding how they interact with one another. Unless I'm missing something, the Cisco tool does not support this.Our research lab discovered this novel threat back in July: https://invariantlabs.ai/blog/toxic-flow-analysis and built the tooling around it. This is an extremely common type of issue that many people don't realize (basically, when you are using multiple MCP servers that individually are safe, but together can cause issues).reply",
      "I have seen a bunch of demos of this, often building on top of open standards like the SAFE-MCP MITRE ATT&CK analysis https://github.com/SAFE-MCP/safe-mcpIn general, the only way to make sure MCPs are safe is to limit which connections are made in an enterprise settingreply",
      "The MCP landscape is a huge frothing septic tank. Go on, try to create a simple MCP server that is protected by a password and connect it to ChatGPT or Claude. Or even the one that uses your local SSO system for authentication.I tried and failed after about 3 days of dealing with AI-slop-generated nonsense that has _never_ been worked. The MCP spec was created probably by brainless AI agents, so it defines two authentication methods: no authentication whatsoever, and OAuth that requires bleeding-edge features (dynamic client registration) not implemented by Google or Microsoft.The easiest way for that right now is to ask users to download a random NodeJS package that runs locally on their machines with minimal confinement.reply",
      "Had an almost identical experience. Even if you don\u2019t need anything with auth, no one has yet made an mcp that wasn\u2019t ultimately worse or the same as a cli but with a lot more song and dance. Security is also a bit of a joke when half the time it\u2019s installing docker and phoning home. I wanted to like mcp and vend out remote mcp but this spec is not ready.reply",
      "I'm still confused as to how mcp is better that say a Fastapi endpoint and it's generated swagger docs?reply",
      "In the cases I\u2019ve tried building/integrating they are the same thing\u2026I think the only difference is the statefulness of the request. HTTP is stateless, but MCP has state? Is this right?I haven\u2019t seen many use cases for how to use the state effectively, but I thought that was the main difference over a plain REST API.reply",
      "My understanding is that it can upgrade to an SSE connection so a persistent stream. Also for interprocess communication you usually prefer a persistent connection. All that to reduce communication overheads. The rationale also is that an AI agent may trigger more fine-grained calls than a normal program or a UI, as it needs to collect information to observe the situation and decide next move (lot more get requests than usual for instance).reply",
      "Using SSE was far too inconvenient in theory despite that being how nearly all of the MCP that gained traction was working, so instead the spec was switched to being better in theory but very inconvenient in practice:https://blog.fka.dev/blog/2025-06-06-why-mcp-deprecated-sse-...There are a million \"why don't you _just_ X?\"  hypothetical responses to all the real issues people have with streamable http as implemented in the spec, but you can't argue your way into a level of ecosystem support that doesn't exist. The exact same screwup with oAuth too, so we can see who is running the show and how they think.It's hard to tell if there is some material business plan Anthropic has with these changes or if the people in charge of defining the spec are just kind of out of touch, have non-technical bosses, and have managed to politically disincentivize other engineers from pointing out basic realities.reply"
    ],
    "link": "https://github.com/cisco-ai-defense/mcp-scanner",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n\n\n\n\n            Couldn't load subscription status.\u00a0\n             \nRetry\n\n\n\n There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Scan MCP Servers for vulnerabilities\n      \n\n\n\n\n                Couldn't load subscription status.\n                 \nRetry\n\n\n\n There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A Python tool for scanning MCP (Model Context Protocol) servers and tools for potential security vulnerabilities. The MCP Scanner combines Cisco AI Defense inspect API, YARA rules and LLM-as-a-judge to detect malicious MCP tools.The MCP Scanner provides a comprehensive solution for scann"
  },
  {
    "title": "Show HN: Dlog \u2013 Journaling and AI coach that learns what drives wellbeing (Mac) (dlog.pro)",
    "points": 25,
    "submitter": "dr-j",
    "submit_time": "2025-10-27T17:14:34 1761585274",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=45723646",
    "comments": [
      "I love the vision. From what I can tell, you're building something that I think should exist and we have the technology for now. I think we need a place to put our 3, 5, 10 year goals, and some kind of process to keep us on track for that. And it's so personal, of course the LLM aspect needs to be local-only.One concern I have is that I think I will need more than an empty \"add Journal entry\" nudge or prompt. I think I would want what a real coach would do/say. Something like, \"How's the meditation/exercise/calling friends/making stuff going?\"reply",
      "I'm a bit intimidated by the long list of things this app is trying to do.Is it a project management tool? If so, how do I share everything with my team? Project management tools are defined by their collaboration and workflow features.Is it a journaling tool? If so I absolutely don't want my team in the tool, and so can't use it for project management. How does it encourage me to do better journaling and build the habit?Is it a wellbeing tool? How well does that work if I don't put my project management in there? If I can't use it for half the stuff it's intended that I will, then it might be of limited use.Is it a coaching tool? Why would I want to use an AI coach over a mentor or human coach?Is the AI required? I have no idea how many tokens I'd need to use something like this? Do I need a million a day or a million a year? (When coding I tend to use ~10-50m input tokens per session, will this cost $500 per day to use?) If the AI features are optional, what is the product without it?Overall my feedback is that there's a lot here, and I think the product needs a much clearer story. The copy on the site is long and rambling and needs a lot of tightening up. Personality is good, but in moderation.reply",
      "First comment: I freaking love your privacy policy. Seriously. Great job!Second: I haven't downloaded it yet because my itsatrap.gif warning bells are going off about pricing. On a scale of free to kidney, what are we looking at here? Is this going to be priced for end users, or will it look closer to an enterprisey kind of plan?reply",
      "Hey kstrauser, thanks for the first comment!Can you let me know what would reduce the warning bells regarding the itsatrap.gif? Like, what gave you that impression? Really need to get this right.For general users it's free for 14 days with 10K free tokens; then its 1.99 per month at the moment.However, if you or HN readers that DM me or email me with the email they register with, I'll give a free perpetual license so there's no monthly fee; and add 1 million tokens.Thanks again for the feedback, I'm glad you liked the privacy policy! :))reply",
      "Oh! That's pretty reasonable. It's just that I've seen so many slick looking tools that go for waaaaaaayyyyy more than I'd ever personally consider paying for them, like \"use AI to sort your CD collection for only $29.95 per month! For only a cup of coffee a day, you could have perfect sorting!\"Do you support Bring Your Own Key (BYOK)? If I'm the first to ask, I'm 100% certain I won't be the last. That a standard question we get from our own customers.reply",
      "OMG that's ridiculous. I will definitely look closely at integrating BYOK. Do you have an app that uses BYOK?reply",
      "That might've been an exaggerated example, but only a little! I've seen lots of tools add AI as a feature and immediately jack their prices.Sure, lots of apps do that. For example, Zed (https://zed.dev/docs/ai/llm-providers) has a subscription plan but alternatively will let you plug in your own key and then provide the same features free of charge.reply",
      "Also, I added the pricing to the home page; hopefully this reduces those warning bells! Thanks so much, I hadn't considered that that would be a barrier.reply",
      "Should include systems requirements on the download - I got a grumpy MacOS message about needing to do an OS update to run it. It's not a big deal but little frictional hiccups like that results in invisible abandonment.reply"
    ],
    "link": "https://dlog.pro/",
    "first_paragraph": "Built on a decade of research. Dlog learns your personality, standards and constraints, then recommends precise steps to increase resources, strengthen character and raise well-being.You answer a baseline survey about your personality, character, resources, and well-being. Every journal and project you add is scored against that same survey. Then, Dlog\u2019s AI applies regressions and structural equation modelling to map how one change drives another (e.g., habits, people or traits influencing mood, progress or resourcesBut it\u2019s not just numbers. Dlog also runs a narrative analysis, tying those stats back to your own diary quotes. From this analysis Dlog\u2019s Coach suggests an array of highly personalised and context aware recommendations, that you can take into consideration when maximising your productivity and well-being.The survey that you take when you start using the coach spans the four rings and acts as your baseline. Future journals and projects are scored against the baseline. Regre"
  },
  {
    "title": "Tags to make HTML work like you expect (jim-nielsen.com)",
    "points": 389,
    "submitter": "FromTheArchives",
    "submit_time": "2025-10-27T10:01:12 1761559272",
    "num_comments": 209,
    "comments_url": "https://news.ycombinator.com/item?id=45719140",
    "comments": [
      "Fun fact: both HN and (no doubt not coincidentally) paulgraham.com ship no DOCTYPE and are rendered  in Quirks Mode. You can see this in devtools by evaluating `document.compatMode`.I ran into this because I have a little userscript I inject everywhere that helps me copy text in hovered elements (not just links). It does:[...document.querySelectorAll(\":hover\")].at(-1)to grab the innermost hovered element. It works fine on standards-mode pages, but it's flaky on quirks-mode pages.Question: is there any straightforward & clean way as a user to force a quirks-mode page to render in standards mode? I know you can do something like:document.write(\"<!DOCTYPE html>\" + document.documentElement.innerHTML);but that blows away the entire document & introduces a ton of problems. Is there a cleaner trick?reply",
      "I wish `dang` would take some time to go through the website and make some usability updates. HN still uses a font-size value that usually renders to 12px by default as well, making it look insanely small on most modern devices, etc.At quick glance, it looks like they're still using the same CSS that was made public ~13 years ago:https://github.com/wting/hackernews/blob/5a3296417d23d1ecc90...reply",
      "Shameless plug: I made this userstyle to make HN comfortable to handle both on desktop and mobile. Minimal changes (font size, triangles, tiny bits of color), makes a huge difference, especially on a mobile screen.https://userstyles.world/style/9931/reply",
      "Thanks for that, it works well, and I like the font choice! Though personally I found the font-weight a bit light and changed it to 400.reply",
      "Setting aside the relative merits of 12pt vs 16pt font, websites ought to respect the user's browser settings by using \"rem\", but HN (mostly[1]) ignores this.To test, try setting your browser's font size larger or smaller and note which websites update and which do not. And besides helping to support different user preferences, it's very useful for accessibility.[1] After testing, it looks like the \"Reply\" and \"Help\" links respect large browser font sizes.reply",
      "I trust dang a lot; but in general I am scared of websites making \"usability updates.\"Modern design trends are going backwards. Tons of spacing around everything, super low information density, designed for touch first (i.e. giant hit-targets), and tons of other things that were considered bad practice just ten years ago.So HN has its quirks, but I'd take what it is over what most 20-something designers would turn it into. See old.reddit Vs. new.reddit or even their app.reply",
      "There's nothing trendy about making sure HN renders like a page from 15 years ago should. Relative font sizes are just so basic they should count as a bug fix and not \"usability update\".reply",
      "Overall I would agree but I also agree with the above commenter. It\u2019s ok for mobile but on a desktop view it\u2019s very small when viewed at anything larger than 1080p. Zoom works but doesn\u2019t stick. A simple change to the font size in css will make it legible for mobile, desktop, terminal, or space\u2026 font-size:2vw or something that scales.reply",
      "It\u2019s not ok for mobile. Misclicks all around if you don\u2019t first pinch zoom to what you are trying to click.reply",
      "Indeed, the vast majority of things I've flagged or hidden have been the accidental result of skipping that extra step of zooming.reply"
    ],
    "link": "https://blog.jim-nielsen.com/2025/dont-forget-these-html-tags/",
    "first_paragraph": "I was watching Alex Petros\u2019 talk and he has a slide in there titled \u201cIncantations that make HTML work correctly\u201d.This got me thinking about the basic snippets of HTML I\u2019ve learned to always include in order for my website to work as I expect in the browser \u2014 like \u201cHey I just made a .html file on disk and am going to open it in the browser. What should be in there?\u201dThis is what comes to mind:<!doctype html>\n<html lang=\"en\">\n<meta charset=\"utf-8\">\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0\">\nWhy each?doctype<!doctype html>\nWithout <!doctype html>, browsers may switch to quirks mode, emulating legacy, pre-standards behavior. This will change how calculations work around layout, sizing, and alignment.<!doctype html> is what you want for consistent rendering. Or <!DOCTYPE HTML> if you prefer writing markup like it\u2019s 1998. Or even <!doCTypE HTml> if you eschew all societal norms. It\u2019s case-insensitive so they\u2019ll all work.html lang<html lang=\"en\">\nDeclare the document"
  },
  {
    "title": "Finding My Rhythm Again (jeremydaly.com)",
    "points": 6,
    "submitter": "qianli_cs",
    "submit_time": "2025-10-21T04:03:13 1761019393",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://jeremydaly.com/finding-my-rhythm-again/",
    "first_paragraph": "In April of 2025, my heart threw an unexpected exception.I was 46, healthy, and active. I ran regularly. I ate reasonably well. I stayed busy. Too busy, maybe. When I started feeling short of breath walking up a flight of stairs, I thought I might have pneumonia or some sort of upper respiratory infection. I had refereed three youth soccer games in the near-freezing, early-spring rain the day before. Now I felt completely run down, like I was dragging an invisible weight.I happened to have my annual physical already scheduled for later that week. After hearing my symptoms, my doctor ran an EKG. I sat alone in the exam room for a few minutes. She returned with a somber look on her face and I knew she had bad news. Both my grandfathers and my father died of heart attacks (two in their early 60s, my paternal grandfather in his early 40s). We had discussed my family history for years, but I naively hoped that my heart was the exception. Then she told me I was in AFib.Atrial fibrillation. A"
  },
  {
    "title": "When 'perfect' code fails (marma.dev)",
    "points": 41,
    "submitter": "vinhnx",
    "submit_time": "2025-10-27T14:19:30 1761574770",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=45721302",
    "comments": [
      "> When we called the isOwner function, it returned a Promise even though our function signature did not specify it as an async function. Our synchronous-looking function was invisibly converted into an async function. This meant it no longer returned a boolean, it returned a Promise.Oh God.reply",
      "I'll be down voted by JavaScript lobby for saying this but I'll still say this.Never use JavaScript on the server side. The amount of bugs that can happen is insane. JavaScript is just a specification with varying implementations across various versions.A proper language like Java, Go, or  Rust ensures that your code will have fewer logical bugs of this type.https://ashishb.net/tech/javascript/reply",
      "this issue was caused by a framework that's trying to do too much, relying on \"magic\" interfaces to supposedly reduce developer burden. the function is very unambiguously written and the language did nothing wrongI also support using whatever language you and your team prefer when you can. that's the glory of backend: no restrictions on what you can run. but sometimes you need to write client software, and those are strictly easier to manage in the platform's native tongue: Swift, Kotlin, JS, and so onreply",
      "My jaw dropped.reply",
      "This reminds me of functions that rely on properties, but the properties could, themselves, be functions (in Swift, we call them \"computed properties,\" and they are indistinguishable, on the outside, from stored properties).C++ can also have a lot of tripwires, from overloaded operators (same with Swift, but people don't overload operators very often, in Swift. They compute properties, all the time, though).reply",
      "This is why you should:- Write functional tests, not unit tests- Not use compilers or other systems that do a lot of black magic (like changing the type signature of your functions (!))reply",
      "I almost never write single function unit tests. There's usually some subset of the codebase that's self contained that makes sense to be the \"unit\" you're testing, but it's almost always a handful of functions with a clear entry point.My general rule is to never mock or remove anything that has no side effects from the execution path of a test, even if it's some utility function that's already tested in isolation in its own test suite - trying to isolate every little bit of behaviour to be tested separately is just a bunch of extra work for questionable benefit.I still call these tests \"unit tests\", and I think a lot of people do also. But there are the dogmatic people to whom only a test covering a single function with all dependencies mocked out is a true unit test.reply",
      "It also helps to not use languages with truthy / falsey values.reply",
      "I think you're looking for `import 'server-only'` and not \"use server\";. Use server exposes functions as endpoints to the client. I.e. they are simply obfuscated api endpoints without boilerplate. Their main use is for mutations such as a form submission from the client.Since pages are, by default, SSR, you don't need to have the server call out to itself to run an endpoint to check permissions. Instead, the server should just run the function.I'm pretty sure Next does some behind the scenes black magic optimizations and doesn't actually make an API request over the wire, but it's still running through some layer of abstractions (causing it to be async) to run the function when instead it could simply be a synchronous function if implemented properly.These abstractions make sense if you know how to use them properly, but I honestly blame Nextjs for the whole server action confusion. I remember when they first came out and seeing how almost every single question on /r/nextjs was about being confused about server actions. All these footguns and confusion to avoid some boilerplate... I'm not sure if they've improved it since, but I've moved to Svelte and haven't looked back.reply",
      "Yes you are right and after our learning we changed the code to not use `use server` anymore for this kind of operations.The documentation and tooling definitely got better and I don't think that such a situation is possible with the latest versions.I just hope that some people who are still running the specific Next.js version won't fall into this as we did.reply"
    ],
    "link": "https://marma.dev/articles/2025/when-perfect-code-fails",
    "first_paragraph": ""
  },
  {
    "title": "Solving regex crosswords with Z3 (nelhage.com)",
    "points": 56,
    "submitter": "atilimcetin",
    "submit_time": "2025-10-21T17:17:02 1761067022",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.nelhage.com/post/regex-crosswords-z3/",
    "first_paragraph": "\n\n      Oct 21, 2025\n    \nFor a while now, I\u2019ve been fascinated by Z3 and by SMT solving more broadly. While on pat leave recently, I was reminded of the existence of regular-expression crossword puzzles, and allowed myself to get nerdsniped by writing a Z3-backed solver.I expected to spend perhaps an afternoon cranking out a quick solver; I ended up getting sucked into understanding and debugging Z3 performance, and learning far more about Z3 and about SMT than I expected. In this post, I\u2019ll describe my approach and my initial solver, and then dive into some of the improvements and variations I explored.All of my code is available on github, if you want to follow along or check out my final results.To briefly recap: A regular-expression crossword consists of a grid of (unknown) characters, which are to-be-determined. These characters are constrained by a set of given regular expressions, which must match a given row or column, once filled in. I chose to solve the regexle variant, spec"
  },
  {
    "title": "Image Dithering: Eleven Algorithms and Source Code (2012) (tannerhelland.com)",
    "points": 49,
    "submitter": "Bogdanp",
    "submit_time": "2025-10-24T19:38:44 1761334724",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=45698323",
    "comments": [
      "It is surprisingly difficult to get really crisp dithering on modern displays, you have to do it on the client to match 1-1 the user\u2019s display. Notice that the pre-rendered examples on this page actually look a little blurry if you magnify them. This is not really a problem unless you really want the crispness of the original Mac screen.A few years ago I got annoyed with this and made a little web-component that attempts to make really sharp 1-bit dithered images by rendering the image on the client to match whatever display device the user has.https://sheep.horse/2023/1/improved_web_component_for_pixel-...reply",
      "One of my favorite modern dithering methods is blue-noise dithering (see Figure 3b):\nhttps://developer.nvidia.com/blog/rendering-in-real-time-wit...The only catch is that generating blue noise is a roughly O(n^2) algorithm. Its not feasible to be generated on the fly, so in practice you just pregenerate a bunch of blue-noise textures and tile them.If you google 'pregenerated blue noise' you find plenty of them:\nhttps://momentsingraphics.de/BlueNoise.htmlreply",
      "O(n^2) where n is what? If it's the number of pixels, you have to touch those anyway, no?Why can't you create blue noise from walking a Hilbert curve and placing points randomly with a minimum and maximum threshold?reply",
      "Something I think about sometimes is how it's usually more important to maintain shape rather than color. For example, in the first 2 images on the page, quantizing the pink hearts results in some pink, white, and grey. An error diffusion alg will result in pink speckled with white and grey, whereas it might be preferable to have a solid pink that's slightly off color but has no speckles.Are there existing techniques that do this sort of thing? I'm imagining something like doing a median filter on the image, run clustering on the pixels in the colorspace, and then shift/smudge clusters towards \"convenient\" points in the colorspace, e.g. the N points of the quantized palette and the N^2 points halfway between each pair. Then a partial-error-diffusion alg like atkinson smooths out the final result.reply",
      "Dithering has similar importance in digital audio. Dithered 8-bit audio sounds way better than non-dithered (harsh artifacts are replaced with tolerable white noise, and quiet details are preserved). Higher end digital equipment even applies dithering to high-bit samples, as do plug-ins in digital audio workstations.reply",
      "I use a Photoshop plugin for complex dithering (DITHERTONE Pro [0] -- this is NOT AN AD lol, I'm not the creator, just a happy customer and visual nerd)I'm only dropping it in here because the marketing site for the plugin demonstrates a lot of really interesting, full-color, wide spectrum of use-cases for different types of dithering beyond what we normally assume is dithering.[0] https://www.doronsupply.com/product/dithertone-proreply",
      "(2012) Popular in2016 (199 points, 61 comments) https://news.ycombinator.com/item?id=118863182017 (125 points, 53 comments) https://news.ycombinator.com/item?id=15413377reply",
      "The major dithering algorithm that's missing from this list is blue-noise dithering.  This is very similar to \"ordered dithering\"; you can think of ordered dithering as either thresholding the pixel values with a different threshold value on each pixel, following a regular pattern, or as adding a different offset value to each pixel, following a regular pattern, and thresholding the result with a constant threshold.  Blue-noise dithering replaces the regular pattern with a random pattern that's been high-pass filtered.  This has all the advantages of ordered dithering, in particular avoiding \"crawling\" patterns during animation, but avoids the repetitive patterns and line artifacts it introduces.https://nelari.us/post/quick_and_dirty_dithering/ is the best quick introduction to the technique that I've seen.  There's a more comprehensive introduction at https://momentsingraphics.de/BlueNoise.html.  https://bartwronski.com/2016/10/30/dithering-part-three-real... also demonstrates it, comparing it to other dithering algorithms.Ulichney introduced blue noise to dithering in 01988 as a refinement of \"white-noise dithering\", also known as \"random dithering\", where you just add white noise before thresholding: https://cv.ulichney.com/papers/1988-blue-noise.pdf.  Ulichney's paper is also a pretty comprehensive overview of dithering algorithms at the time, and he also makes some interesting observations about high-pass prefiltering (\"sharpening\", for example with Laplacians).  Error-diffusion dithering necessarily introduces some low-pass filtering into your image, because the error that was diffused is no longer in the same place, and high-pass prefiltering can help.  He also talks about the continuum between error-diffusion and non-error-diffusion dithering, for example adding a little bit of noise to your error-diffusion algorithm.But Ulichney is really considering blue noise as an output of conventional error-diffusion algorithms; as far as I can tell from a quick skim, nowhere in his paper does he propose using a precomputed blue-noise pattern in place of the white-noise pattern for \"random dithering\".  That approach has really only come into its own in recent years with real-time raytracing on the GPU.An interesting side quest is Georgiev and Fajardo's abstract \"Blue-Noise Dithered Sampling\" from SIGGRAPH '16 http://web.archive.org/web/20170606222238/https://www.solida..., sadly now memory-holed by Autodesk.  Georgiev and Fajardo attribute the technique to the 02008 second edition of Lau and Arce's book \"Modern Digital Halftoning\", and what they were interested in was actually improving the sampling locations for antialiased raytracing, which they found improved significantly when they used a blue-noise pattern to perturb the ray locations instead of the traditional white noise.  This has a visual effect similar to the switch from white to blue noise for random dithering.  They also reference a Ulichney paper from 01993, \"The void-and-cluster method for dither array generation,\" which I haven't read yet, but which certainly sounds like it's generating a blue-noise pattern for thresholding images.Lau, Arce, and Bacca Rodriguez also wrote a paper I haven't read about blue-noise dithering in 02008, saying, \"The introduction of the blue-noise spectra\u2014high-frequency white noise with minimal energy at low frequencies\u2014has had a profound impact on digital halftoning for binary display devices, such as inkjet printers, because it represents an optimal distribution of black and white pixels producing the illusion of a given shade of gray,\" suggesting that blue-noise dithering was already well established in inkjet-land long before it became a thing on GPUs.Maxime Heckel has a nice interactive WebGL demo of different dithering algorithms at https://blog.maximeheckel.com/posts/the-art-of-dithering-and..., with mouse-drag orbit controls, including white-noise dithering, ordered dithering, and blue-noise dithering.  Some of her examples are broken for me.It's probably worth mentioning the redoubtable https://surma.dev/things/ditherpunk/ and the previous discussion here: https://news.ycombinator.com/item?id=25633483.reply",
      "It's also worth to mention noise-based dithering - where some noise pattern is added atop of the image and then rounding is performed. Usually some sort of blue noise is used for this approach.reply",
      "Agreed - blue noise dithering is very commonly used in computer graphics because it\u2019s cheap and great, but it might be worth mentioning that it\u2019s a kind of ordered dithering, which is mentioned in the article.Christoph Peters\u2019s free blue noise textures are the most commonly used, for people who can\u2019t be bothered running void and cluster themselves:  https://momentsingraphics.de/BlueNoise.htmlreply"
    ],
    "link": "https://tannerhelland.com/2012/12/28/dithering-eleven-algorithms-source-code.html",
    "first_paragraph": "\nDec 28, 2012\n      \n\n      \u2022 by Tanner Helland\u00a0\u00a0Today\u2019s graphics programming topic - dithering - is one I receive a lot of emails about, which some may find surprising.  You might think that dithering is something programmers shouldn\u2019t have to deal with in 2012.  Doesn\u2019t dithering belong in the annals of technology history, a relic of times when \u201c16 million color displays\u201d were something programmers and users could only dream of?  In an age when cheap mobile phones operate in full 32bpp glory, why am I writing an article about dithering?Actually, dithering is still a surprisingly applicable technique, not just for practical reasons (such as preparing a full-color image for output on a non-color printer), but for artistic reasons as well.  Dithering also has applications in web design, where it is a useful technique for reducing images with high color counts to lower color counts, reducing file size (and bandwidth) without harming quality.  It also has uses when reducing 48 or 64bpp RA"
  }
]