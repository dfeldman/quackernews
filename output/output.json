[
  {
    "title": "Diagrams \u00c2\u00b7 Diagram as Code (mingrammer.com)",
    "points": 160,
    "submitter": "ulrischa",
    "submit_time": "2024-11-04T18:46:42 1730746002",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=42044771",
    "comments": [
      "This project (and others like it) are graphviz wrappers - they do some really cool stuff to emit styled .dot files that look better than writing and rendering raw gv.#Allowing specification in Python offers very little advantage - in theory you think, hey, I've got hi-lighting, autocompletion, and so on from an IDE. It'll play nice in VCS. Maybe I can interrogate orchestration layers and so on to produce dynamic views.In practice diagrams are produced by folks who might not want to use or learn python [or golang, their other implementation]. Instead a lean purpose-build DSL, maybe even an extension of graphviz dot, is easier and more portable for some audiences to pick up.\nSecondly, we can't JUST graft a DSL front-end onto these tools because the styled components are baked into the project.My personal experience with layout engines is that they work OK for very small architecture diagrams, but become ugly or inelegant at useful scales.I (and the teams I've worked with) settle on draw.io, either the desktop app, or committed as part of confluence, as the best way to describe intent/design - and rendering graphviz with a style up top for anything dynamic.Would welcome seeing a true extension to the dot language that can unlock reasoning engines (like to do threat modeling) and render-time styling.\n \nreply",
      "I have a love/hate relationship with diagrams, and diagrams-as-code-things (plantuml, mermaid, etc). As a programmer, I find myself trying to turn everything in to a software project: everything must be version control-able. Same with these diagramming solutions -- except I nearly never know what I want the digram to look like, when I start \"writing\" it. This means I nearly always end up on something like lucid.app just sketching out the solution, and thinking to myself that I'll turn it in to a beautiful diagram with one of the earlier solutions, later -- that never happens. So now I have a diagram I can link to (yay), but can't version control (boo).Then, I discovered excalidraw[1]: it lets me sketch like lucid, but isn't nearly as polished or robust: you can throw together simple shapes, draw lines between them, and the lines stick to the shapes, so you can move them around and the lines move too. You can also group things together, and draw freehand, and also include text -- what more do you need?The cool thing about excalidraw is that you can share your drawings, and export them as SVG files -- yay! I can version them again. You can also self-host it, which is a massive plus in my book./rant[1]: https://excalidraw.com/\n \nreply",
      "I've been mostly using the VS Code Excalidraw plugin. Any file with name ending on `.excalidraw.svg` or `.excalidraw.png` is an Excalidraw-editable image of the respective format. This means you can save it alongside your markdown docs and embed them directly, but also edit the exact same file on the IDE.\n \nreply",
      "Nice (and MIT Licensed!) - I'll give this a shot.Another thing these types of tools bring is multiplayer support. Which I found my distributed teams really benefiting from over time.\n \nreply",
      "Excalidraw seems to boil down the important parts of Miro into an even neater and user friendly package. And it seems really modular and have a really interesting API as well. You can use it as a react component for example.\n \nreply",
      "> In practice diagrams are produced by folks who might not want to use or learn python [or golang, their other implementation]. Instead a lean purpose-build DSL, maybe even an extension of graphviz dot, is easier and more portable for some audiences to pick upThis is so absolutely ludicrously absurdly wrong that it's comical.No one wants to learn a new programming language. Cf. all of the old algol languages that are still around and all their \"replacements\" that are no longer around.Some people (not even a majority) are willing to learn a new language if compelled by force or incentive. Diagramming is absolutely not enough incentive to learn a new language.\n \nreply",
      "I agree with both of you, but I still don't want to use Python to generate my diagrams.Diagrams are a visual thing. I prefer a visual designer. I can send that to some random nontechnical person for a presentation and they can edit them, etc.I find with things like this, it works pretty well until you want to do something off the beaten path, then it's a pain where you're trying to figure out how to get it to render like you want it to.Reminds me of the ole \"just move it 2px to the right\" in the CSS of yesteryear\n \nreply",
      "This is code to diagram, not diagram as code. I was hoping to see a tool that takes diagram sketches and outputs, e.g., Terraform. That would treat a diagram as code.\n \nreply",
      "I personally have been using mermaid for sequence diagrams and flow charts: https://mermaid.js.org/DaC seems nicer for infra\n \nreply",
      "Mermaid is fantastic for diagramming architecture. A little quirky, but not too bad.If you're using GitHub it's supported in any markdown file, and therefore accessible to any other dev with repo access. No permissions issues, edits can go through code review, and no dependencies necessary.\n \nreply"
    ],
    "link": "https://diagrams.mingrammer.com/",
    "first_paragraph": ""
  },
  {
    "title": "Alonzo Church: Architect of computer intelligence (onepercentrule.substack.com)",
    "points": 219,
    "submitter": "drcwpl",
    "submit_time": "2024-11-04T14:51:10 1730731870",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=42042025",
    "comments": [
      "A historical tidbit which I loved in Paradigms of Artificial Intelligence Programming (available in PDF and EPUB here - https://github.com/norvig/paip-lisp):> The name lambda comes from the mathematician Alonzo Church's notation for functions (Church 1941). Lisp usually prefers expressive names over terse Greek letters, but lambda is an exception. A better name would be make-function. Lambda derives from the notation in Russell and Whitehead's Principia Mathematica, which used a caret over bound variables: x\u0302(x + x). Church wanted a one-dimensional string, so he moved the caret in front: ^x(x + x). The caret looked funny with nothing below it, so Church switched to the closest thing, an uppercase lambda, \u039bx(x + x) . The \u039b was easily confused with other symbols, so eventually the lowercase lambda was substituted: \u03bbx(x + x). John McCarthy was a student of Church's at Princeton, so when McCarthy invented Lisp in 1958, he adopted the lambda notation. There were no Greek letters on the keypunches of that era, so McCarthy used (lambda (x) (+ x x)), and it has survived to this day.So, yes, on the topic of this post - Church pops up in loads of Lisp retrospectives. Maybe he's \"forgotten\" by people with very little engagement in the history of computing.\n \nreply",
      "\"Lisp usually prefers expressive names\". In addition to the exception of \"lambda\", there are also \"car\" and \"cdr\", which, while not Greek, are hardly transparent.\n \nreply",
      "If it is any consolation, Steve Russell, who implemented the first Lisp interpreter on the IBM 704 and came up with CAR (Contents of the Address Register) and CDR (Contents of the Decrement Register) wanted to change them to \"first\" and \"rest\" after a few months in to teaching and thinking \"Hmm, maybe we could have had more direct names here\".See the full email from Steve Russell on the topic on this page https://www.iwriteiam.nl/HaCAR_CDR.html, and here's the relevant quote:> \"After several months and giving a few classes in LISP, we realized that \"first\" and \"rest\" were better names, and we (John McCarthy, I and some of the rest of the AI Project) tried to get people to use them instead.Alas, it was too late! We couldn't make it stick at all. So we have CAR and CDR.\"Personally I don't mind them, they're nicely introduced in \"A Gentle Introduction to Symbolic Computation\" and they stuck easily enough for me.\n \nreply",
      "\"usually\" probably means at the time of writing this book. lambda, car and cdr are from the 50s/60s when short names were preferred for various reasons (small memory, input on cards, output on paper, small screens, ...).\n \nreply",
      "It's not clear that this oft-repeated story of the origin of Alonzo Church's lambda notation is true. See https://en.wikipedia.org/wiki/Lambda_calculus#Origin_of_the_... for other instances where Alonzo Church has suggested it was more of an arbitrary choice of Greek letter.\n \nreply",
      "BTW the PAIP book, independent of AI topics (where it did not age so good) is an excellent book overall, covering many programming topics, and opening some paradigms, that for people who had little exposure to FP might be unknown.\n \nreply",
      "But wait, who ever first coined the term 'lambda calculus' ? was it before or after McCarthy started lisp ?\n \nreply",
      "Well before.  The original paper[1] introducing the lambda calculus was in the 1930s, but it wasn't called \"lambda calculus\" until a bit later.[1] https://raw.githubusercontent.com/emintham/Papers/master/Chu...\n \nreply",
      "Yeah indeed no trace of the term 'lambda'.But this https://www.classes.cs.uchicago.edu/archive/2007/spring/3200... mentions \"THE CALCULI OF LAMBDA-CONVERSION\" linked here https://compcalc.github.io/public/church/church_calculi_1941...\n \nreply",
      ">There were no Greek letters on the keypunches of that era, so McCarthy used (lambda (x) (+ x x)), and it has survived to this day.I have a memory of a paper by McCarthy himself where he tells that the first implemented Lisp had a notation close to FORTRAN. S-expressions were only intended for the theory.\n \nreply"
    ],
    "link": "https://onepercentrule.substack.com/p/alonzo-church-the-forgotten-architect",
    "first_paragraph": ""
  },
  {
    "title": "Aldebaran 1959 Spacecraft Concept (armaghplanet.com)",
    "points": 10,
    "submitter": "LorenDB",
    "submit_time": "2024-11-04T23:39:15 1730763555",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://armaghplanet.com/the-amazing-aldebaran-spacecraft.html",
    "first_paragraph": "\u00a0One of the most grandiose of the vehicles suggested by Cole was the Aldebaran concept, a gigantic nuclear-powered launch vehicle he proposed in 1959. Cole believed that Aldebaran type vehicles would be in everyday use starting in the 1980s, each launch routinely carrying 60 million pound (about 27 000 tonnes) payloads into low Earth orbit or soft-landing 45 million pounds (20 000 tonnes) of cargo on the Moon. Compare this performance to that of today\u2019s Ariane 5 (21 tonnes to LEO).The titanic Aldebaran vehicle would take off from the ocean (the Martin company was a flying boat specialist). The ship alongside in the fantastic artist\u2019s impression is the then new liner SS United States which is about 300 m long (note too the tiny helicopter lowering cargo into a dinky little cargo bay).Aldebaran would have operated by drawing air in through the intakes in the \u2018wings\u2019 and heating it to very high temperatures (by detonating a couple of small, \u201cclean\u201d nuclear devices every second of flight i"
  },
  {
    "title": "US Forest Service decision to halt prescribed burns in ca is history repeating (cepr.net)",
    "points": 159,
    "submitter": "danboarder",
    "submit_time": "2024-11-04T22:19:49 1730758789",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=42046596",
    "comments": [
      "> This week, the U.S. Forest Service directed its employees in California to stop prescribed burning \u201cfor the foreseeable future,\u201d a directive that officials said is meant to preserve staff and equipment to fight wildfires if needed.It sounds like it's a resourcing issue, not a change in philosophy.  It doesn't change the fact that it won't be happening though.\n \nreply",
      "> It sounds like it's a resourcing issue, not a change in philosophy.Yes.https://news.ycombinator.com/item?id=41920127 (\"HN: The Forest Service Is Losing 2,400 Jobs\u2013Including Most of Its Trail Workers\")Relevant comment by S201: https://news.ycombinator.com/item?id=41922195\"The overall Forest Service budget has indeed been increasing, but it's nearly all going to wildfire fighting. I recently wrote about the state of forest road funding and went in depth on this here: https://ephemeral.cx/2024/09/losing-access-to-the-cascades> Overall, in 1995 16% of the Forest Service budget was dedicated to wildfires. By 2015 it was 52% and by 2025 it\u2019s projected to be upwards of 67%. Without large amounts of additional funding it is virtually guaranteed that the Forest Service\u2019s budget will continue to be siphoned away by firefighting needs.\"\n \nreply",
      "Can the Forest Service make this up with use fees? Like, could California pay the Forest Service to take care of its land surrounded by California?\n \nreply",
      "I think the issue is that it's federal land.  They would just have to authorize California to do it on their behalf.\n \nreply",
      "They can use the lumber fees from the forests to pay for the cost.\n \nreply",
      "That is much more complicated than it appears.  Cutting and transporting trees is not easy or free, and there is already a huge glut of wood caused by the die off from phytophthera.  Might still be worth looking into.\n \nreply",
      "Not without Congress doing something to enable it.\n \nreply",
      "> Not without Congress doing something to enable itWhy? We played with the farfetched hypothetical of California unilaterally acting on federal land. But if the Forest Service says \u201ccome on in\u201d and they do, I\u2019m struggling to see who would face any real consequences given the Congress\u2019s power of the purse isn\u2019t being touched.\n \nreply",
      "OP is talking about CA paying money to the park service. Different than  them handing over a license to burn.\n \nreply",
      "> OP is talking about CA paying money to the park serviceSure. I don\u2019t see how the Congress stops that if the USFS (not Parks) and Sacramento strike a deal.\n \nreply"
    ],
    "link": "https://cepr.net/us-forest-service-decision-to-halt-prescribed-burns-in-california-is-history-repeating/",
    "first_paragraph": "\u2022\n\nARTICLE\n\nCaliforniaClimate ChangeUnited States\nLast week, the US Forest Service announced it would stop prescribed burning in California \u201cfor the foreseeable future,\u201d stating that the decision was made as a precautionary measure to ensure the availability of staff and equipment in case of potential wildfires. But temps are falling across California, and state, tribal authorities, and prescribed burn associations have commenced with their prescribed burns. If the federal agency doesn\u2019t hold up its end of the work, all that mitigation work can be undone.To grasp the impact of the Forest Service\u2019s decision on California, it\u2019s essential to understand the history of the state and the intricate mosaic of private, state, and federal land that constitutes the forests. Over the past 100 years, the state and federal governments relied on a \u201cparamilitary-like program\u201d that focused on fire suppression by rapidly mobilizing firefighters and equipment. Very little was done regarding fire preventi"
  },
  {
    "title": "DB48X: High Performance Scientific Calculator, Reinvented (48calc.org)",
    "points": 106,
    "submitter": "qwezxcrty",
    "submit_time": "2024-11-04T17:19:34 1730740774",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=42043747",
    "comments": [
      "The 48G was a really good calculator, but only after loading additional software. The HP50g that came much later is better in every respect, except possibly for the smaller \"ENTER\" key (and people used to 48G will have to change some habits and possibly redefine some keys\u2026).Incidentally, many young people (yes, I know how that sounds) do not know how useful a good engineering calculator can be and do not want to learn how to use one. They are missing out. Yes, there is a steep learning curve, but the rewards are significant if you do any amount of calculation in your hobby or work. No, this is not replaced by typing \"python\" (or \"bc\", or anything else, really) at your command prompt.Also incidentally, the development of good engineering calculators pretty much died. HP Prime is largely a school-pleasing toy, HP would down their calculator division a long time ago, and nobody else produces anything good. It's kind of like with gyms: what you get is what the market wants, and since the market doesn't know much, you get gyms full of useless exercise machines, because that's what people think a good gym should have. Similarly with calculators: you get stupid \"modern\" graphing calculators which are useless for actual work (it takes forever to use them to calculate useful things, and graphing is much better done on a computer), but they look great and sell well.I admire the project, although I would probably have taken a different path (emulation) to get the biggest effect with the smallest possible effort :-)I wish there was a good HP50G emulator for iOS \u2014 there used to be one, but it was abandoned (contact me if you want to develop it and would like to get the source code, it was under the GPL and I got it from the author).\n \nreply",
      "I'm one of the last people at my workplace to use a calculator. I'm a scientist, not an engineer, so I use a scientific calculator. ;-)The schools ruined calculators.I still find a calculator handy, even when I've already got Python going on my PC. It's easier to use the calculator with one hand, especially in the workshop. You can get a Casio solar at Target for 10 bucks.My wife really prefers RPN, so I gave her my last HP when hers died.\n \nreply",
      "TBH TI-89 titanium is a better engineering calculator since the UI is way better. I have both a HP50G and a TI-89 titanium and I've done way more useful engineering work on the TI-89 titanium just because it's so much easier and accessible. Also of course, BASIC is a lot easier than reverse polish lisp for making some quick scripts.Also I will add, there are known symbolic math issues on the HP50G due to the CAS system it uses. I will see if I can find a link.\n \nreply",
      "I've used both extensively. I disagree with this. I dislike the HP48 series but I dislike the TI89 more. It's probably because most people don't understand how to use the 50G properly. You really need to go through the HP training video ( https://www.youtube.com/watch?v=OTPruRVV-e8 ). Incidentally if you haven't watched that it's worth watching on its own - great production! In an engineering context, the 48-series was designed to produce small composable reusable programs and tools in the file tree which can be executed quickly.Try a quick EE example for parallel resistor calculation that takes 2 and puts 1 value back on stack<< 1/X SWAP 1/X + 1/X >>Store that in RPAR in whatever directory you want or HOME. Then you whack in 2 resistors and hit the RPAR F-key. There is nothing faster or more efficient than that.I still use a 15C all the time though. Even easier! 99% of what I do is on paper though and ends up getting chucked in the numeric solver.\n \nreply",
      ">  No, this is not replaced by typing \"python\" (or \"bc\", or anything else, really) at your command prompt.Why not?  At least I can easily copy the results and the code to a document which avoids transcription errors.  Or do you mean that there simply isn't a program that has the functions you use?\n \nreply",
      ">> Incidentally, many young people (yes, I know how that sounds) do not know how useful a good engineering calculator can be and do not want to learn how to use one. They are missing out. Yes, there is a steep learning curve, but the rewards are significant if you do any amount of calculation in your hobby or work. No, this is not replaced by typing \"python\" (or \"bc\", or anything else, really) at your command prompt.> Why not? At least I can easily copy the results and the code to a document which avoids transcription errors. Or do you mean that there simply isn't a program that has the functions you use?My guess it's the ergonomics between a specialized tool and a non-specialized one. Technically, python may be able to replace \"a good engineering calculator,\" but so can ASM.  No one would even ask \"Why non ASM?,\" because its ergonomics are near-universally understood to be so poor, but the same issues can apply to more popular tools like python, just less obviously.\n \nreply",
      "I'm a calculator nut who has had many fancy TI (like the Voyage 200) and HP calculators (yes RPN) including the SwissMicro reproductions.The ONLY benefit to these tools that I can surmise is basically that they are a physical device for scientists or others in the lab or field and not in front of a computer.For any kind of data work I've seen, Excel, R, Python, Mathematica, or Matlab are all vastly superior. They allow faster entry, can show large amounts of data on screen, can allow for saving large amounts of data ...etc.\n \nreply",
      "Some of us (mathematics side) still actually work on paper with calculators. Most of the job is thinking which tooling doesn\u2019t necessarily improve.\n \nreply",
      "yeah after a decade in my job, I have a ton of utility functions in python that I reach for when given a new request to think through something. I doubt a smaller screen where I have to type in stuff and then copy out results would make it any easier.\n \nreply",
      "This thread is making my point for me rather well.\n \nreply"
    ],
    "link": "http://48calc.org/",
    "first_paragraph": "DB48X is a modern scientific calculator in the spirit of the Hewlett-Packard HP48X, featuring a complete, from-scratch reimplementation of the Reverse Polish Lisp (RPL) programming language. The firmware is initially designed for the SwissMicros DM32 and DM42 calculators. In other words, it is optimized for physical hardware that you can keep in your pocket. There is also an iPhone version if you want to run this on your phone or display graphs in colour.You can try the calculator firmware directly in your browser by clicking on the following image:\n\n\n\nDB48X was  with  by Christophe de Dinechin."
  },
  {
    "title": "Machines of Loving Grace (clunyjournal.com)",
    "points": 55,
    "submitter": "greenie_beans",
    "submit_time": "2024-11-04T20:05:19 1730750719",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42045509",
    "comments": [
      "> Yet, I am shocked when AI does not stop Outlook Messenger from bursting confetti across my desktop in response to the Congratulations reply I receive when HR misreads my email about both adding and removing our late son from my health insurance.Echoes of Facebook showing people \u201cmemories\u201d (photos) of their deceased children on their bday. This is one of the saddest stories I\u2019ve read in a bit.\n \nreply",
      "brutal story. for those who were equally confused this post seems to have the same title as but is unrelated to Dario Amodei's recent https://darioamodei.com/machines-of-loving-grace - is perhaps a nice/bittersweet reality check on how our designs often fall short of our ambitions.\n \nreply",
      "Which in turn references the 1967 poem by Richard Brautigan:https://en.m.wikipedia.org/wiki/All_Watched_Over_by_Machines...\n \nreply",
      "A chillingly moving article that reminds me of what is important in life... to want to spend time with those I love that still live, and to remember those that don't.As an aside- I'm also an academic and resent this sudden nonsense push to 'embrace AI' from people that have no clue what it even is. Some of my research is close enough to be getting renewed interest and funding from this... but I find it offensive the my same research ideas weren't interesting on their own merits a few years ago but only suddenly are now because they involve 'AI.' It suggests a frivolous trend following unbecoming of scientists.I don't know what this author researches, but she deeply understands why technology needs to be aligned with human interests, and how to make sure it is. That seems to me something academic departments interested in AI research need now more than ever.I've also always found this poem darkly captivating, because it imagines that positive humanizing technology will be possible but itself seems like a vision that would be infantilizing, and the author leaves it unclear on if they notice this or not, and if it is serious or dark satire.\n \nreply"
    ],
    "link": "https://www.clunyjournal.com/p/machines-of-loving-grace",
    "first_paragraph": ""
  },
  {
    "title": "Blog Writing for Developers (2023) (rmoff.net)",
    "points": 47,
    "submitter": "mooreds",
    "submit_time": "2024-11-04T20:01:57 1730750517",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42045477",
    "comments": [
      "The lecture by Larry McEnerney was a great recommendation, I just watched. When I was in college I had a revelation reading Clarity: Toward Style and Grace by Williams. Really put into concrete terms why some ways of writing \"sound wrong\" and how to avoid them.\n \nreply",
      "> The second reason that I\u2019ll write is to learn about something. It\u2019s one thing to hand-wave one\u2019s way through a presentation. It\u2019s another to commit pen to paper (well, bytes to disk) and explain something. Quite often I\u2019ll realise that there\u2019s a gap\u2014or gaps\u2014in my knowledge that I need to explore first before I can properly write about something, and that\u2019s the very reason that I do it.This is a very good reason to write - I've learned about a ton of topics over the years at depths I wouldn't have bothered with if I weren't going to write blogposts about it.  I really didn't need to spend a year chewing through other people's PhD work to understand some of the quirks of lead acid battery behavior I was seeing years back (Steve on IRC's description covered the details well enough to work around it), but if I was going to write it up[0], I wanted to actually understand it.  And that took time.But it misses one of the most important reasons I write: To force myself to finish projects and document things, so I can fully offload it from my brain.I'm very prone to \"90% done, eh, good enough, I'll finish it later...\" sort of projects, and they take up a lot of mental space because I still have to (or, at least, try to...) remember state on the project.  Before I write about something, I want it fully done, and then as part of writing it up, I trust myself to document anything weird, any odd findings, etc.  Once I've done that, then I can entirely forget the details of the project, teardown, or whatever, knowing that if I need to do it again, I can go reference my old writeup and I'll know what I need to do!Once written, I can just clear the brain-space out, and not worry about forgetting about it, because it's been written up, by me, in my style.Also, copy editors and reviewers start to sound more like professional writing than \"blogging,\" at least to me.[0]: https://www.sevarg.net/2018/04/08/off-grid-rv-lead-acid-main...\n \nreply",
      "As a reader, people writing to learn about something irritates me when it's not clearly flagged that the writer has almost zero experience using the thing they are writing about.There's so many articles in tech where the writer probably has less experience with something than literally anyone who will read their post, and it means there's effectively a content farm of what a new software engineer will learn in their first few months (if not years) on the job, written by software engineers in their first few months, with effectively no net information.\n \nreply",
      "I'll offer the opposite perspective. People writing about stuff that they are currently learning is often better, because they have a much clearer model of what's obvious and what isn't.Someone with 20 years of experience with a technology will usually have a much harder time re-connecting with that beginner's mindset and doing a great job of providing the information that other newcomers most need to understand.That's not to say that there isn't plenty of junk content out there, but I blame that more on inexperienced writers than on people who are writing about technology that they don't have a great deal of experience with.A great writer should be able to write about something while they're learning while still producing content that's genuinely useful.\n \nreply"
    ],
    "link": "https://rmoff.net/2023/07/19/blog-writing-for-developers/",
    "first_paragraph": "Writing is one of the most powerful forms of communication, and it\u2019s useful in a multitude of roles and contexts. As a blog-writing, documentation-authoring, twitter-shitposting DevEx engineer I spend a lot of my time writing. Recently, someone paid me a very nice compliment about a blog I\u2019d written and asked how they could learn to write like me and what resources I\u2019d recommend.Never one to miss a chance to write and share something, here\u2019s my response to this :)To begin with I want to cover briefly the motivations behind writing.Firstly, I like to share information. That could be a new tool or technique that I\u2019ve learnt, a clever trick I\u2019ve discovered, or sometimes away from the technical and into the realms of life pondering and navel gazing. In the case of this very blog, it\u2019s to share my thoughts on something that interests me. I could have written some notes and sent them directly back to the person who asked the original question, but if it was useful to them it\u2019s hopefully usef"
  },
  {
    "title": "Writing secure Go code (jarosz.dev)",
    "points": 190,
    "submitter": "gus_leonel",
    "submit_time": "2024-11-04T17:34:28 1730741668",
    "num_comments": 128,
    "comments_url": "https://news.ycombinator.com/item?id=42043939",
    "comments": [
      "As the article also mentions: instead of checking if your program has a dependency on something that contains vulnerabilities, govulncheck checks if vulnerable code is actually reached. I find that so awesome. (And I know, someone is going to point out that hipster language foo does this too and better \u2014 it\u2019s not the norm).\n \nreply",
      "Don\u2019t forget about capslock: https://github.com/google/capslockAssess your 3P modules for dangerous capabilities\n \nreply",
      "Great tips in here - I was not aware of `go vet` nor `go test -race`.FWIW, while go is not memory safe, I do find that it's much easier to be safe in go than it is in other languages. Its verboseness lends to a very clear understanding of what's happening in any given function. I absolutely hated this at the start, but now ~3 years into maintaining a go codebase, I find it quite nice both for debugging as well as editing old code. I know exactly what each function does, and what the structure of data is in any given context.Another interesting side effect is that AI tools seem to work amazingly well with golang, given how context is often local to the function.\n \nreply",
      "Go is memory-safe. It's not the definition of \"memory-safe language\" that it's impossible to write memory-unsafe code, only that ordinary code is memory-safe by default.\n \nreply",
      "> ordinary code is memory-safe by defaultWhat does that mean? What constitutes \"ordinary\"? I'm not sure there is any official definition of memory safety, but I would consider it to mean that aside from code that is explicitly marked as unsafe it is impossible to write code that has undefined behavior.\n \nreply",
      "Semgrep is another great option to get value out of static analysis checks against both the language and a few common frameworks. It remains a popular choice for security folks writing static detection rules (and contributing them to the commons).You can check the open rules here;\nhttps://github.com/semgrep/semgrep-rules/tree/develop/go\n \nreply",
      "Does go have a bad security reputation?I get that anything can be insecure and its a constant battle as this article suggests, but i thought it was quite secure and stable generally (say on a par with .net or any other tool you may use to make a web app at least?)\n \nreply",
      "It has essentially the same security properties of all the modern non-C-languages (ie, C, C++, ObjC), with the added bonus of largely being designed after the deserialization pandemic that especially hit Java, Python, and Ruby. ~All these modern languages are fine for security (though: be careful with serialization formats in anything but Go and Rust).Arguably, Rust and Go are the two \"most secure\" mainstream languages, but in reality I don't think it much matters and that you're likely to have approximately the same issues shipping in Python as in Rust (ie: logic and systems programming issues, not language-level issues).Be wary of anyone trying to claim that there are significant security differences between any of the \"modern\" or \"high-level\" languages. These threads inexorably trend towards language-warring.\n \nreply",
      "I'd point out that one advantage Go has over Rust in terms of security are the coverage of standard libraries. Go has great support for HTTP clients/servers, cryptography primitives, SSH, SQL, JSON, secure RNG, etc. all in officially maintained standard libraries. The Rust ecosystem has some standards here but the most widely used HTTP client, just as an example, is mostly maintained by one guy[1]. I think that adds considerable security risk vs Go's net/http.1. https://github.com/hyperium/hyper/graphs/contributors\n \nreply",
      "For what it's worth, I don't believe there's any meaningful security difference between Rust and Go.\n \nreply"
    ],
    "link": "https://jarosz.dev/article/writing-secure-go-code/",
    "first_paragraph": "What does it mean to keep security in mind when writing Go code? Answering this question in one short article seems impossible. For this reason, we will narrow it down to a few specific practices.They will lead to writing robust, secure and performant code when applied continuously.Let\u2019s start with the most obvious place - the Go mailing list. We need to subscribe to get all critical security information right from the source.\nAll releases that contain security fixes are announced to the [email\u00a0protected] list.\nOnce we subscribe to the list, we can be sure we won\u2019t miss any important announcements.The second step is to keep the Go versions in our projects current. Even though we don\u2019t use the latest and greatest language features, bumping the Go version gives us all security patches for discovered vulnerabilities. Also, the new Go version ensures compatibility with newer dependencies.\nIt protects our applications from potential integration issues.The third step is to learn which securi"
  },
  {
    "title": "ReiserFS and the Art and Artist Problem (corecursive.com)",
    "points": 10,
    "submitter": "SerCe",
    "submit_time": "2024-11-04T22:59:22 1730761162",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42046956",
    "comments": [
      "Anyone used Reiser4 or 5?\n \nreply",
      "I feel the same way about Linus with Linux. I know people say to separate the art from the artist, but when you are openly abusive to your users for decades on end, with barely any remorse, and continue to do so today, it just does not make me want to use your product.\n \nreply",
      "On the contrary, I really think Linus is a shining example of caring about the users. He often seems to be one of the top advocates of the \"never break userspace\" mentality, a position I respect.I will grant you that he does sometimes say things on LKML that are inflammatory or at least angry (less so these days to be sure) but personally I prefer the unfiltered honesty. I believe most humans can admit that they've felt like Linus  does in his rants at times. People have criticized the way that he speaks, but I believe his anger is very often because he cares about the users.\n \nreply",
      "When was linus/Linux ever \"openly abusive\" to users ?He can get pretty heated in arguments on the LKML for sure, but those are arguments between devs, and usually for the benefit of the user.I still think this way of working out disagreements sucks, but as a user it does not really affect me at all.And other OS'es abuse their users on a whole other level and I'm quite sore that some of apples/microsofts middle managers can also be quite abusive to their devs behind closed doors, with linux it's just all in the open...\n \nreply",
      "Do you have any examples of Linus being abusive? I always thought he was a straight shooter but wasn\u2019t aware he was being abusive to users.\n \nreply",
      "https://lwn.net/Articles/649157/> We don't merge kernel code just because user space was written by a retarded monkey on crack- Linus TorvaldsAlso: https://www.youtube.com/watch?v=iYWzMvlj2RQ\n \nreply",
      "First, User space != users. Second, he's berating that kernel maintainer saying that even if user space does something absurd, the kernel accommodates such absurdity. The user space program being bad, doesn't give the kernel any reason to break it intentionally.\n \nreply",
      "Actually, these are pretty bad examples. Both of those fits of anger ultimately come down to caring about the users, but especially the NVIDIA one. I eventually gave up and switched to AMD graphics, but from 2004 to at least around 2016 I was running NVIDIA graphics on Linux and their increasing apathy towards Linux desktop users and Linux in general was clear. It just now is getting better, long after Torvalds complained about it, and even then it'll be a long time before things are stable and in good shape for most users. (e.g. only RTX 20xx cards are covered by the new \"open\" drivers, for example.)\n \nreply"
    ],
    "link": "https://corecursive.com/reiserfs/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Convert any website into a React component (chromewebstore.google.com)",
    "points": 105,
    "submitter": "alexdanilowicz",
    "submit_time": "2024-11-04T17:03:00 1730739780",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=42043552",
    "comments": [
      "This is a very useful browser extension. Really love the fact that you are even able to convert the styles to TailwindCSS. Very clever.\n \nreply",
      "thank you! Given Tailwind's conciseness, it's interesting seeing how \"LLM-friendly\" it is. Less tokens needed to style more!But if you want to start with an existing design: first deterministically grabbing the styles via our extension helps a lot to get that initial prompt for the AI to even do the conversion in the first place\n \nreply",
      "Your actual product is really slick.  Even just with some basic tests I can see that it produces designs with a much higher degree of polish than regular LLM models, and with much more of a design bent.  I'll definitely use this for some prototyping this week!I wonder what changes you've made from standard LLMS to get here?  I could imagine trying to put things on guard rails, giving it some components to build off, or just fine tuning based on a really nice corpus of good websites (maybe generated with this tool).\n \nreply",
      "thank you - we're a team of 2 and former full-time frontend engineers so that means a lot to us! You're spot on with the guard rails: we do a lot of post-processing, i.e., after LLM spits something out, we parse the AST, strip out hallucinated imports, add imports that are missing. And yes! We also do a bit of pre-processing (expanding the prompt, feeding relevant examples via a RAG-based approach).It feels like everyone is building in the AI space these days, but I gotta say: it's quite fun tweaking it. The non-deterministic nature is simultaneously the worst and best thing.\n \nreply",
      "I am going to be that person, but how is the copyright for the output of tools like this? Since not all websites include license on their site, yet their looks are replicated, this might be even less clear than with LLMs in general.\n \nreply",
      "IANAL but my guess that the output seems likely to be considered a \"derivative work\" (referring to US law in this case). So you'd need prior authorization from the copyright holder in the absence of a license.\"Only the owner of copyright in a work has the right to prepare, or to authorize someone else to create, an adaptation of that work. The owner of a copyright is generally the author or someone who has obtained the exclusive rights from the author... The unauthorized adaptation of a work may constitute copyright infringement.\" [1]Some of the examples they give in the referenced document above are pretty close to what this tool outputs. e.g. \"A new version of an existing computer program\", \"A revision of a website\", \"A drawing based on a photograph\", etc[1] https://www.copyright.gov/circs/circ14.pdf\n \nreply",
      "Interesting that the author of this extension has not commented on your question...\n \nreply",
      "thanks for the callout \u2014 was taking me a second to respond because I wasn't 100% sure. It's a good question. I was actually trying to get the phone with a copyright lawyer to give an accurate answer. I believe (not a legal advice) it depends on the given website's terms of service. There's usually a \"fair use\" clause. Of course, if you do use the extension and you're reading this: don't use  their own trademarks (like logos!) on your own site! Use our convert button and edit it to make it fully your own.There are many extensions that grab designs from any website (this is not new tech) - what's different about ours is that we convert it to a React component for the purpose of then editing it with AI to make it your own.I'll note it's against our Acceptable Use Policy to use it for impersonation / inauthentic behavior: https://www.magicpatterns.com/docs/documentation/legal/accep...\n \nreply",
      "Not sure what would be the difference between this and an \u201copen source airtable/notion\u201d etc\n \nreply",
      "The people at these open source alternative projects at least type in their version of the copycat designs/whatevers, not using a machine to style-by-style convert it to a component for them keeping everything that can be kept.\n \nreply"
    ],
    "link": "https://chromewebstore.google.com/detail/html-to-react-figma-by-ma/chgehghmhgihgmpmdjpolhkcnhkokdfp",
    "first_paragraph": "7 ratingsConvert HTML from any page to React and/or Figma. Edit with AI.Convert a page or a section of a page to React code or an editable Figma design.\n\nWhat you can do with HTML to React/Figma:\n- Grab an existing design that you like and instantly get React code you can use in your own project\n- Import existing designs to edit and work off instead of starting from scratch\n- Use AI to customize and modify existing designs\n\n\nCreated and supported by Magic Patterns.Google doesn't verify reviews. Learn more about results and reviews.Great innovative Extension. Wel Done!... So far I like it... BUT! ADD SOME MORE FUNCTIONATITY. 5X\u2b50Big fan of this tool. One of my biggest use cases is to quickly grab UI inspiration from apps/websites, and copy & paste it into Figma (another feature of their platform - via a plugin). Alex & Teddy are always pushing new features, updates & fixes. Bullish.You can literally make an in-browser flappy bird game with one sentence. If that doesn't compel you to give"
  },
  {
    "title": "What should a logo for NeXT look like? (1986) (paulrand.design)",
    "points": 166,
    "submitter": "themantra514",
    "submit_time": "2024-11-04T15:26:32 1730733992",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=42042382",
    "comments": [
      "The logo got a second lease of life after NeXT was acquired by Apple. A bit of British political trivia: Dominic Cummings, the campaign director of the Vote Leave organisation in the 2016 Brexit referendum, nicked the NeXT logo and made a few tweaks for Vote Leave:> The logo was stolen from Steve Jobs. We couldn\u2019t afford to hire a top agency and they wouldn\u2019t have worked with us anyway. So I thought about Jobs\u2019 advice on simplicity and \u2018the best artists steal\u2019 (see above!) and did some google searches. Surely there\u2019s something he did with manic determination I could steal? After he left Apple in the 1980s, for his new company he got one of the top designers in the world to do a logo. I looked at it and thought, \u2018good enough for Steve good enough for us, we can put a hole in the top so it looks like a ballot box\u2019. Total cost: almost nothing. I made a lot of decisions like this because the savings in time and money were far greater than the marginal improvements of spending more time and money on them (if this would even bring an improvement).https://dominiccummings.substack.com/i/117842715/where-did-t...\n \nreply",
      "Diabolical.I followed your link expecting to see some hack work, and I guess technically it is hack work, but that \"ballot box\" thing really works.ugh.\n \nreply",
      "I think there\u2019s probably a bit of survivorship bias here \u2014 we know if this anecdote because the ballot box concept is actually quite good. But of course there are other \u201crip offs\u201d that are bad (blonic the hedgehog?). The idea to make a small change was clever imo, but doesn\u2019t guarantee a great design. I think the ballot box design was either \u201clucky\u201d or \u201cinspired\u201d, perhaps without the creator even realizing it.\n \nreply",
      "For other reasons, I had come cross Cummings substack a couple of weeks ago - highly instructive, no wonder he was ejected from UK gov circles ...\n \nreply",
      "Yea, maybe shouldn't have gone to Barnard Castle to get his eyes tested though.\n \nreply",
      "Reverberations of the Nazi's stealing the Swastika ...\n \nreply",
      "I always go back to the Saul Bass presentation to AT&T over their 1970 logo redesign. He takes 30 minutes to explain the thought process and sell this design hard. By the end you're convinced it's the natural thing to do. I'm sure every executive in the room felt the same way.https://www.youtube.com/watch?v=xKu2de0yCJI(Bass would return a mere 13 years later to do the AT&T \"Death Star\" logo after the breakup)\n \nreply",
      "And then there's Pepsi. https://www.goldennumber.net/wp-content/uploads/pepsi-arnell...\n \nreply",
      "Right. What am I looking at? It seems clearly a case that it started with the final logo they wanted and finished with 27 pages of pure justification BS.\n \nreply",
      "Seems wildly successful to me considering we're all still talking about it despite the fact that they don't even use the logo any more.\n \nreply"
    ],
    "link": "https://www.paulrand.design/work/NeXT-Computers.html",
    "first_paragraph": "Work1986LogoColor referenceProduct artProduct namesCollateral collectionCollateral collectionLogo stickerNote paperPresentation agendaPresentation invitationSticker sheetPaper clipsView More (Use \u2190 \u2192 keys to navigate. Click for larger view.)NEXTThe Sign of the Next Generation of Computers for Education.What should a logo for Next look like?Choosing a typeface as the basis for the design of a logo is a convenient starting point. Here are two examples: Caslon and Bifur. Caslon is an alphabet designed as far back as 1725 by William Caslon. It appears to be a good choice because it is both elegant and bookish, qualities well suited for educational purposes.Bifur, a novelty face by A. M. Cassandre, was designed as recently as 1929. An unconventional but ingenious design, it has the advantage, to some, of visually implying advanced technology. (Attributing certain magical qualities to particular typefaces is, however, largely a subjective matter.)One reason for looking at a number of possibl"
  },
  {
    "title": "Facebook Building Subsea Cable That Will Encompass the World (subseacables.blogspot.com)",
    "points": 101,
    "submitter": "giuliomagnifico",
    "submit_time": "2024-11-04T14:00:59 1730728859",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=42041581",
    "comments": [
      "Highly recommend an article by The Verge on how these things are repaired and maintained.https://www.theverge.com/c/24070570/internet-cables-undersea...\n \nreply",
      "Also the GOAT of cable laying articles: Neal Stephenson doing gonzo journalism on the topic in the 90shttps://euripides.dk/setebos/frx/matrix/ai/books/stephenson_...\n \nreply",
      "Oh, so that\u2019s why Cryptonomicon has so much detail/plot points about submarine cable laying!\n \nreply",
      "great article but man I hate all that scrolljackingwho ever thought this was a good idea?\n \nreply",
      "I think here it is bearable because the page is more like a presentation. The worst is when nothing special happens, and you only notice scrolling is off.\n \nreply",
      "So do we sometimes lay cables on top of other cables down there?What governments do you have to go to to get approval to do this? Could I just run a string across the Atlantic Ocean?If we do lay cables on top of other cables how high do they get stacked? Are there challenges to bring the lower cables back up? Does that happen? Or do we just keep them down there forever basically and upgrade the hardware at the terminal?\n \nreply",
      "> So do we sometimes lay cables on top of other cables down there?I don't know exactly how often this has occurred but I'd guess it's relatively rare. The companies that operate in this space are very specialized and sophisticated. The locations of pretty much every cable laid in the last half century is very precisely tracked and one of the first things that has to happen when preparing a new cable route is to undertake a high resolution side-scan sonar survey of all or part of the planned route. In shallower water the cables are typically buried under several meters of the seabed.> What governments do you have to go to to get approval to do this? Could I just run a string across the Atlantic Ocean?At the very least you'll need to have landing agreements with the countries at the various endpoints. In international waters I believe there are some laws that apply but I gather that it's more about liability. You'd have a lot of difficulty running a string across the Atlantic. Controlling the amount of slack on a cable that's being played out is incredibly finicky work. Keep in mind that the point where your hypothetical string is touching down on the sea bed might be several miles behind where you are and that your ship is going to be bobbing around on the surface and you get an idea.> If we do lay cables on top of other cables how high do they get stacked? Are there challenges to bring the lower cables back up? Does that happen? Or do we just keep them down there forever basically and upgrade the hardware at the terminal?Cables are routinely brought up for repair or disposal. The ships that do this are called Agreement ships. In 1866 the second-ever transatlantic cable was grappled up to the surface and repaired (it snapped while laying it the previous year).Modern cables are fiberoptic and do not increase their bandwidth once laid.\n \nreply",
      "> Modern cables are fiberoptic and do not increase their bandwidth once laid.That's not true: The amplifiers they use work at the analog (and in fact even optical, i.e. without conversion to electric and back) level, and it's possible to upgrade capacity by only modifying the endpoints, not the entire cable.\n \nreply",
      "> Modern cables are fiberoptic and do not increase their bandwidth once laid.No kind of expert at all, but I understood that better control over / perception of narrower bandwidths of light have allowed fiber-optic cables to improve their data throughput immensely. Is that incorrect? Or are you using a narrower, technical definition of \"bandwidth\" that I've not understood?\n \nreply",
      "I'm no expert either but a complicating factor for undersea fiber-optic cables is that they need amplifiers every N kilometers. So even if the cable itself could theoretically support more bandwidth, the amplifiers might not. The amplifiers contain lasers of their own that fire at very specific wavelengths.\n \nreply"
    ],
    "link": "https://subseacables.blogspot.com/2024/10/breaking-story-facebook-building-subsea.html",
    "first_paragraph": "\nBlog is devoted to educating readers about the subsea cable industry with a particular focus on recent events and new submarine cable projects. Ideal for those in the industry who wants breaking news on outages, new projects, and general industry trends. Roderick Beck worked as a sales contractor for Hibernia Atlantic and helps buyers procure capacity and providers make sales. \nSeveral sources have whispered in my ear that META is planning a new 16 fibre pair cable that will encompass the world going from the US East Coast to the US West Coast via the Atlantic, Indian Ocean, and the Pacific. The most ambitious subsea project ever undertaken. I do not know the exact routing. I know that the cable will launch from the American East Coast and will go down the West African Coast to South Africa and then head straight to Mumbai. It is not clear if Europe will be online or not. From Mumbai it will head straight to Australia and then up to the US West Coast. I speculate that there may be bra"
  },
  {
    "title": "Designing a Home Radio Telescope for 21 Cm Emission (arxiv.org)",
    "points": 59,
    "submitter": "antognini",
    "submit_time": "2024-11-04T18:21:59 1730744519",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42044494",
    "comments": [
      "I had a dish set up in London, 20 years ago (before I came out to the USA). Looked like #1. The dish splits into segments, and I recall driving down the M1 from Birmingham in my battered old Ford Escort, with the (razor-sharp) mesh segments squeezed in and wobbling right next to my jugular... Those dishes were getting vanishingly hard to find in the UK, so it was worth the trip, and I kept my neck intact with only minimal damage...I had it all packed up when moving out to the US (because my imagination told me that houses in the US were far larger than in the UK). The house I ended up buying (despite having a much larger back garden) didn't have the space to set it up again and remain married, so two decades later, it's still in that wooden case... I do, however, have an optical telescope set up (#2)Back then, we didn't have easy access to SDR's, so there's a feed horn, a down-converter, and I had an external (standalone) WinRadio receiver to  actually listen to the feed. That went into an audio card on a linux box, and the waterfall display was beautiful :)#1: https://imgur.com/a/CDrEeII#2: https://imgur.com/a/askar-130phq-scope-sb-myt-mount-26mp-cam...\n \nreply",
      "Page three of the paper shows an enviable rooftop antenna farm. Drool.I have an ignorant question ... can home/amateur radio astronomy ever produce layperson-appreciated \"imagery\"? Something easily understood like optical astronomy can produce? e.g. stitching together a sky scan for a particular emission or something?\n \nreply",
      "Yes, in a way.Think of a single dish radio telescope as a one-pixel camera, where measuring the emission intensity at each point in the sky lets you build up a map. Typically, this is done with high resolution on the frequency axis, which is used to map Doppler shifts for spectral lines of Hydrogen, for example [1].With a rooftop antenna, it's not likely to be a very sensitive map, though. You'll see the Sun, and its easy to see the Milky Way transit overhead, but other than that ...[1] https://sites.google.com/site/galfahi/\n \nreply",
      "Yes. But nowing a bit of signal theory, hf electronics and embedded is super helpful.With 2 antennas you can start playing around with beam forming. This will enable you to scan the sky from one position without moving the antenna. Then you can   map the signal strength to a sky projection.Have a look at the low-frequency antennas from LOFAR. They look like tents for chickens. A lot of them.It sounds complex and yes.. it's also a bit complex. But still in the range of a project for the home lab.\n \nreply",
      "Thanks to the rotation of the earth and antenna fixed in one direction sees a bunch of the sky over an evening.\n \nreply",
      "Yep \"drift scanning\" :)A single dish/node can't really produce photograph-like imagery akin to an optical telescope, more often[1] you get something like in the setileague website hits [2].[1] Where by \"more often\" I mean \"once in a blue moon\".[2] http://www.setileague.org/photos/hits.htm\n \nreply",
      "Of note is that this is a high school paper.\n \nreply",
      "The german Wurzberg radar system (https://en.wikipedia.org/wiki/W%C3%BCrzburg_radar) was used after the war to help discover the hydrogen line.\n \nreply",
      "I've just started learning about radio comms. I'm using the ARRL Handbook for Radio Communications 101, which is great so far.My main goal is to detect the hydrogen line, or maybe some distant/noisy object (can amateurs pick up pulsars?). I also want to understand antennae much better, and maybe make a wire fractal antenna. I have a crazy idea about making a 3D fractal antenna-making bot from Lego or something! :D(I'm not under any illusions about whether a fractal antenna is \"better\" but I just like the idea of them)\n \nreply",
      "Start detecting signal reflections from airplanes.With multiple synchronized receivers you can build a passive radar.Single reflections can easily be spotted by just staring at the spectrum (Doppler).\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2411.00057",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "DataChain: DBT for Unstructured Data (github.com/iterative)",
    "points": 101,
    "submitter": "shcheklein",
    "submit_time": "2024-11-04T17:34:57 1730741697",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42043948",
    "comments": [
      "Yay! Excited to see DataChain on the front page :)Maintainer and author here. Happy to answer any questions.We built DataChain because our DVC couldn't fully handle data transformations and versioning directly in S3/GCS/Azure without data copying.Analogy with \"DBT for unstractured data\" applies very well to DataChain since it transforms data (using Python, not SQL) inside in storages (S3, not DB). Happy to talk more!\n \nreply",
      "It took me a minute to grok what this was for, but I think I like itIt doesn't really replace any of the tooling we use to wrangle data at scale (like prefect or dagster or temporal) but as a local library it seems to be excellent, I think what confused me most was the comparison to dbt.I like the from_* utils and the magic of the Column class operator overloading and how chains can be used as datasets. Love how easy checkpointing is too. Will give it a go\n \nreply",
      "Yes, it's not meant to replace data engineering tools like Prefect or Temporal. Instead, it serves as a transformation engine and ad-hoc analytics for images/video/text data. It's pretty much DBT use case for text and images in S3/GCS, though every analogy has its limits.Try it out - looking forward to your feedback!\n \nreply",
      "Cool!  Does this assume the unstructured data already has a corresponding metadata file?My most common use cases involve getting PDFs or HTML files and I have to parse the metadata to store along with the embedding.Would I have to run a process to extract file metadata into JSONs for every embedding/chunk? Would keys created based off document be title+chunk_no?Very interested in this because documents from clients are subject to random changes and I don\u2019t have very robust systems in place.\n \nreply",
      "DataChain has no assumptions about metadata format. However, some formats are supported out of the box: WebDataset, json-pair, openimage, etc.Extract metadata as usual, then return the result as JSON or a Pydantic object. DataChian will automatically serialize it to internal dataset structure (SQLite), which can be exported to CSV/Parquet.In case of PDF/HTML, you will likely produce multiple documents per file which is also supported - just `yield return my_result` multiple times from map().Check out video: https://www.youtube.com/watch?v=yjzcPCSYKEo\nBlog post: https://datachain.ai/blog/datachain-unstructured-pdf-process...\n \nreply",
      "> However, some formats are supported out of the box: WebDataset, json-pair, openimage, etc.Forgive my ignorance, but what is \"json-pair\"?\n \nreply",
      "It's not a format :)It's simpliy about linking metadata from a json to a corresponding image or video file, like pairing data003.png & data003.json to a single, virtual record. Some format use this approach: open-image or laion datasets.\n \nreply",
      "> DataChain has no assumptions about metadata format.Could your metadata come from something like a Postgres sql statement?  Or an iceberg view?\n \nreply",
      "Absolutely, that's a common scenario!Just connect from your Python code (like the lambda in the example) to DB and extract the necessary data.\n \nreply",
      "What relevant metadata is there in an HTML file?\n \nreply"
    ],
    "link": "https://github.com/iterative/datachain",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        AI-data warehouse to enrich, transform and analyze data from cloud storages\n      \n   \nDataChain is a modern Pythonic data-frame library designed for artificial intelligence.\nIt is made to organize your unstructured data into datasets and wrangle it at scale on\nyour local machine. Datachain does not abstract or hide the AI models and API calls, but helps to integrate them into the postmodern data stack.A storage consists of images of cats and dogs (dog.1048.jpg, cat.1009.jpg),\nannotated with ground truth and model inferences in the 'json-pairs' format,\nwhere each image has a matching JSON file like cat.1009.json:Example of downloading only \"high-confidence cat\" inferred images using JSON metadata:Batch inference with a simple sentiment model using the transformers library:The code below downloads files the cloud, and applies a user-"
  },
  {
    "title": "New York Times Tech Guild goes on strike (washingtonpost.com)",
    "points": 580,
    "submitter": "ChrisArchitect",
    "submit_time": "2024-11-04T12:08:30 1730722110",
    "num_comments": 1047,
    "comments_url": "https://news.ycombinator.com/item?id=42040795",
    "comments": [
      "I have digital / print subscription to the NYT. It seems like stories were being published online Monday, and the paper paper arrived. Strike doesn't start until Tuesday?\n \nreply",
      "Here is context on the strike, how long it's been brewing, and more that I happened to read yesterday:https://www.thenation.com/article/archive/the-new-york-times...\n \nreply",
      "Thank you so much! That is a vastly more informative article. It seems like it's not so much the NYT is opposed to the contract's specifics -- they're opposed to having a contract at all because the union is new. The NYT has been stringing the union along without ever actually signing anything, so now the union has to strike to get the NYT to take them seriously.Key parts:> The Tech Guild won its unionization vote in March of 2022, but has yet to agree upon a final contract with management. In September of this year, the Guild voted to authorize a strike with an overwhelming 95 percent (or over 500 members) in favor. The vote marked two and a half years of bargaining with no result. As Harnett puts it, \u201cAt some point, you need a deadline.\u201d> The first key demand is a protection that Times editorial staff already have: just-cause job protections, which would ensure that members cannot be fired without good reason and due process. The editorial staff won this protection in their 2023 News Guild contract, and just weeks ago, 750 Times journalists penned a letter to management urging them to reach a contract with the Tech Guild before Election day.> The second demand stems from a pay study the union released in June of this year, which found numerous pay discrepancies for women and people of color. According to the study, Black tech workers at the newspaper make 26 percent less than white workers. The study also found that women, who make up over 40 percent of the Tech Guild, earn 12 percent less on average than men, while Black and Hispanic or Latina women earn 33 percent less than white men.> The third demand in dispute is a frequent source of anxiety for Hoehne in particular: return to office. Currently, many in the Tech Guild work remotely full-time.... Hoehne has been living and working remotely three hours away from the Times office, in upstate New York, since the pandemic began. \u201cI would lose my job. I can\u2019t sell my house. My kid is in daycare. I can\u2019t. All we\u2019re asking is for them to put in writing that we won\u2019t do that to you.\u201d> But both Hoehne and Harnett don\u2019t think management\u2019s reluctance to settle these demands stems from the particulars of any of the demands themselves; none of them would spark radical changes. The negotiation process has lagged for years, which Times editorial staff experienced en route to their contract as well. Rather, Hoehne said, staring down the barrel of the Election Day strike, management\u2019s immovability feels like it\u2019s more about preventing the union from stabilizing at all.> \u201cThey could easily end all of this with a single phone call or e-mail,\u201d Harnett said. \u201cBut they\u2019re making the decision not to. Maybe they don\u2019t believe that we are resolved [to strike]. I don\u2019t know how else to convince them.\u201d\n \nreply",
      ">>According to the study, Black tech workers at the newspaper make 26 percent less than white workers>>women, who make up over 40 percent of the Tech Guild, earn 12 percent less on average than menclaims like these always irk me, like did you just compare averages by race/gender? Whoever made this claim, did they control for other factors, like job title/level or productivity?its like the famous \"gender pay gap\" claimed by all the people who majored in Gender Studies instead of Statistics. Turns out \"gender pay gap\" magically disappears as soon as you start controlling for relevant variables like hours worked, job seniority, experience, etc (https://www.aei.org/carpe-diem/there-really-is-no-gender-wag...)   That is, there is almost no evidence that men and women working in the same position with the same background, education and qualifications are paid differently. Whether it\u2019s the Target Corporation, Facebook, the University of Virginia, the United Way, the White House or McDonald\u2019s, there is almost no evidence that any of those organizations have two pay scales: one for men (at a higher wage) and one for women (at a lower wage). Of course, that would be illegal, and if that practice existed, organizations would be exposed to legal action and \u201chalf the legal profession would be taking such cases on contingency fees\u201d\n\n\nI am all for fairness in pay and equality, but lets not insult the intelligence of your readers by making some absurd claims without doing proper econometric study and controlling for confound variables\n \nreply",
      "> claims like these always irk me, like did you just compare averages by race/gender?Probably not, the striking union is the one that contains all the data analysts at the NYTimes, so they have some experience with sociology data.> Whoever made this claim, did they control for other factors, like job title/level or productivity?As explained in the article, the data analysts union mad this claim, it's even explicitly linked!> Turns out \"gender pay gap\" magically disappears as soon as you start controlling for relevant variables like hours worked, job seniority, experience, etcNo, that's just something you read on a blog written by a guy who would go on to write that women shouldn't get wage equality because they would have to work more dangerous jobs and thus die more, because apparently saving the lives of man by making those jobs safer is impossible.Anyway, here's a big stats heavy quote about how there is solid evidence for a pay gap, from the stats nerds at the census bureau (I link only the executive summary https://www.dol.gov/sites/dolgov/files/WB/media/An%20Evaluat..., link to the full thing can be found in the summary)\"\"\"In both decomposition models, the portion of the gender wage gap that could not be explained by differences in men\u2019s and women\u2019s work histories, work hours, industry and occupation distribution, and job characteristics was between 68 and 70 percent, yielding an unexplained wage gap of 14 to 15 percent. That is, of an estimated wage gap of 21 percent, statistical models explain between 6 and 7 percentage points of the gap, leaving 14 to 15 percentage points unexplained, similar to other major studies on this topic.Differences in the sorting of men and women between occupations do not fully explain the gender wage gap; men and women are paid differently within occupations as well. The size of the gender wage gap varies significantly by occupation even as men earn more than women in nearly all occupations. While wages are at parity in some occupations, gaps are as large as 45 percent in others. Across the 316 occupations in this study, occupations in finance and sales had the largest gender wage gaps\"\"\n \nreply",
      ">a guy who would go on to write that women shouldn't get wage equality because they would have to work more dangerous jobs and thus die more, because apparently saving the lives of man by making those jobs safer is impossible.I think it can be true that we should make those jobs safer and that it makes sense to pay  dangerous jobs more.\n \nreply",
      "did you actually read the research you cited?because it DOES NOT control for hours worked nor experience, and lumps up narrow specialties with wide specialties together in a single \"finance\".There is a huge difference in finance as a \"bank teller\" and finance as a \"investment banker at Wall St\".This is a problem of large scale population level wage research, it misses very important confounding variables and lumps up everything they failed to explain as some magical gender pay gap.This is the epitome of how low replicability social sciences research is done:  download dataset from JSTOR, load it in Stata/Matlab, run some regressions and call it a day.\n \nreply",
      "> finance and salesWeird that jobs with performance bonuses are the largest gap \u2014 but that perhaps suggests that the cause isnt sexism in the workplace, but yet more confounders they didn\u2019t account for.\n \nreply",
      "Or that their sales contacts treat women and non-binary folks worse than men.https://www.newsweek.com/male-and-female-coworkers-switched-...\n \nreply",
      "sales is literally you-eat-what-you-kill. you get paid % commission on sales regardless of your gender.\nThere are so many sales people nobody would actually bother creating a separate pay grade for women and separate for men (and it would be highly unethical and illegal ofc)\n \nreply"
    ],
    "link": "https://www.washingtonpost.com/style/media/2024/11/04/new-york-times-tech-strike-walkout/",
    "first_paragraph": ""
  },
  {
    "title": "Albertsons kills rural grocers with land use restrictions (thebignewsletter.com)",
    "points": 207,
    "submitter": "unpredict",
    "submit_time": "2024-11-04T21:32:04 1730755924",
    "num_comments": 197,
    "comments_url": "https://news.ycombinator.com/item?id=42046196",
    "comments": [
      "These sorts of land use restrictions should be illegal. It's basically a corporation trying to act as a pseudogovernment, enforcing regulations on land that they no longer own themselves.One could argue that HOAs are kind of a similar issue, acting like a pseudogovernment, with restrictions on housing passing on down indefinitely, even to new owners who may not have wanted to agree to them (but with housing being as constrained as it is, you may not always have a realistic choice).As a general rule, prior owners probably shouldn't be getting a say in what future owners do with land. Why? Because land is inherently limited in a way in which most other property is not, which reduces the ability of new entrants to 'disrupt' the market by offering people more choice.If my town only has one car dealership with shitty business practices, no biggie, it's not too hard to go to another town and buy a car, then bring it back. But I can't buy land and bring it back to use it, I'm stuck with whatever's already there.\n \nreply",
      "It seems they already are illegal, at least in some jurisdictions.> \"In June, for instance, Washington state Attorney General Bob Ferguson, who is also litigating against the merger, fined Albertsons $25,000 for imposing a land use restriction on a store it sold in 2018 in a low-income section of Bellingham, Washington. As part of the sale, the supermarket giant put a requirement on the deed that no grocery store could open there until 2038. Ferguson found this provision was a violation of the state antitrust law.\"The fine imposed doesn't seem all that significant though.Perhaps they could also be prosecuted under federal antitrust law?\n \nreply",
      "I'm curious, did that action also result in the requirement becoming invalid?\n \nreply",
      "> These sorts of land use restrictions should be illegalAn easier solution is mandatory sunsets after a period of time. Because the flip side of making them illegal is you'll have a lot more land with conservation easements being exploited for resources.\n \nreply",
      "This kind of reminds me of when airspace was separated from Land property rights. There doesn't necessarily need to be any underlying logic or consistency, so a very tailored legal interpretation could be formed in theory.That said, I think I'm much more practical solution is to focus on the buyer's rights and non-competitive behavior then limiting sellers rights. It makes intuitive sense that people would be able to option or sell indefinite use rights if they own the thing itself. It is less intuitive that individuals have a right to aggregate such options for Monopoly.Now that I think about it, it seems there could be some comparison to the corner crossing cases that are being litigated too\n \nreply",
      "I think a really natural solution would be to tax these sort of land restrictions for as long as someone is actually willing to pay. Just assess the value with the restrictions vs without and then tax it at the standard property tax rate. If nobody cares enough to pay for the restriction then it is lifted.\n \nreply",
      "It\u2019s not that hard to carve out classes of restrictions that are illegal. Racial covenants were nullified this way in the past.\n \nreply",
      "> conservation easementsI.e. easements that come from law rather than seller stipulation? Seems an easy distinction to make.\n \nreply",
      "> I.e. easements that come from law rather than seller stipulation?A lot of convservation land in America is put under non-governmental easement [1]. The owner puts a restriction on the deed prohibiting development. They typically require emininet domain powers to be removed.[1] https://en.wikipedia.org/wiki/Conservation_easement\n \nreply",
      "The government could probably choose to define the terms used to define retail activities in the covenant as meaningless.Menard's does this in Michigan, and then tries to get the taxes on their replacement stores to be based on the restricted property. It's nuts.\n \nreply"
    ],
    "link": "https://www.thebignewsletter.com/p/how-albertsons-kills-rural-grocers",
    "first_paragraph": ""
  },
  {
    "title": "The Therapist in the Machine (thebaffler.com)",
    "points": 4,
    "submitter": "Caiero",
    "submit_time": "2024-10-31T04:40:42 1730349642",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://thebaffler.com/salvos/the-therapist-in-the-machine-mcallen",
    "first_paragraph": ""
  },
  {
    "title": "Limitations of frame pointer unwinding (redhat.com)",
    "points": 113,
    "submitter": "rwmj",
    "submit_time": "2024-11-04T11:25:25 1730719525",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=42040549",
    "comments": [
      "Didn\u2019t really get the point of the post as it just presents something without a conclusion.9X% of users do not care about a <1% drop in performance. I suspect we get the same variability just by going from one kernel version to another. The impact from all the Intel mitigations that are now enabled by default is much worse.However I do care about nice  profiles and stack traces without having to jump through hoops.Asking people to recompile an _entire_ distribution just to get sane defaults is wrong. Those who care about the last drop should build their custom systems as they see fit, and they probably already do.\n \nreply",
      "it does present a conclusion. once the kernel supports .sframe it will be all-around superior to -fomit-frame-pointer, and a better default for distros to use.\n \nreply",
      "It does cause more memory pressure because the kernel will have to look at the user-space memory for decoding registers.So yes it will be faster than alternatives to frame-pointers, but it still wont be as fast as frame pointers.\n \nreply",
      "But does what you care about matter enough to be the default?Are you the majority?Evaluate \"majority\" this way: For every/any random binary in a distro, out of all the currently running instances of that binary in the world at any given moment, how many of those need to be profiled?There is no way the answer is \"most of them\".You have a job where you profile things, and maybe even you profile almost everything you touch. Your whole world has a high quotient of profiling in it.  So you want the whole system built for profiling by default. How convenient for you. But your whole world is not the whole world.But it's not just you, there are, zomg thousands, tens of thousands, maybe even hundreds of thousands of developers and ops admins the same as you.Yes and? Is even that most installed instances of any given executable?\nNo way.Or maybe yes. It's possible. Can you show that somehow? But I will guess no way and not even close.\n \nreply",
      "> Evaluate \"majority\" this way: For every/any random binary in a distro, out of all the currently running instances of that binary in the world at any given moment, how many of those need to be profiled?\n> There is no way the answer is \"most of them\".This is an absurd way to evaluate it.  All it takes is one savvy user to report a performance problem that developers are able to root-cause using stack traces from the user's system.  Suppose they're able to make a 5% performance improvement to the program.  Now all user's programs are 5% faster because of the frame pointers on this one user's system.At this point people usually ask: but couldn't developers have done that on their own systems with debug code?  But the performance of debug code is not the same as the performance of shipping code.  And not all problems manifest the same on all systems.  This is why you need shipping code to be debuggable (or instrumentable or profileable or whatever you want to call it).\n \nreply",
      "I regularly have users run Sysprof and upload it to issues. It's immensely powerful to be able to see what is going on systems which are having issues. I'd argue it's one of the major reasons GNOME performance has gotten so much better in the recent-past.You can't do that when step one is reinstall another distro and reproduce your problem.Additionally, the overhead for performance related things that could fall into the 1% range (hint, it's not much) rarely are using the system libraries in such a way anyway that would cause this. They can compile that app with frame-pointers disabled. And for stuff where they do use system libraries (qsort, bsearch, strlen, etc) the frame pointer is negligible to the work being performed. You're margin of error is way larger than the theoretical overhead.\n \nreply",
      "1% is a ton. 1% is crazy. Visa owns the world off just a 3% tax on everything else. Brokers make billions off of just 1% or even far less.1% of all activity is only rational if you get more than 1% of all activity back out from those times and places where it was used.1%, when it's of everything, is an absolutely stupendous collossal number that is absolutely crazy to try to treat as trivial.\n \nreply",
      "Better analogy: you're paying 30% to apple, and over 50% in bad payday loans, and you're worried about the 3% visa/stripe overhead ... that's kinda crazy. But that's where we are in computer performance, there's 10x, 100x, and even greater inefficiencies everywhere, 1% for better backtraces is nothing.\n \nreply",
      "Absolutely. We've gotten numerous double digit performance improvements across applications, libraries, and system daemons because of frame-pointers in Fedora (and that's just from me).\n \nreply",
      "Performance problems matter to the people who have them, who often are in an inconvenient place. Having the ability for profiling to just work means that it's easy to help these people.\n \nreply"
    ],
    "link": "https://developers.redhat.com/articles/2024/10/30/limitations-frame-pointer-unwinding",
    "first_paragraph": "Recent versions of commonly-used Linux distributions including Fedora and Ubuntu have disabled frame pointer optimizations with the goal of allowing profiling tools to produce stack traces without needing to include a call-frame information interpreter. In this article I will explain some overlooked limitations of unwinding with frame pointers and why enabling frame pointers does not constitute a full solution to enable profiling. I will also list some initiatives that aim to enable system-wide profiling without the need for frame pointers.Several recent articles have discussed the interaction of frame pointer optimization defaults and profiling, including Guinevere Larsen\u2019s overview of the issue, Will Cohen\u2019s article on call-frame information and unwinding, and my own article on profiling frame pointer-less code with eu-stacktrace.In short, modern compilers can produce code either with or without a frame pointer register indicating the beginning of the current stack frame. With frame "
  },
  {
    "title": "The Roots of Fear: Understanding the Amygdala (ucdavis.edu)",
    "points": 48,
    "submitter": "birriel",
    "submit_time": "2024-11-04T15:29:07 1730734147",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42042417",
    "comments": [
      "https://gwern.net/backstop#hui-nengs-flag -- Evolution as Backstop for Reinforcement Learning -- Hui Neng\u2019s Flag -- the mathematics of positive and negative reinforcementhttps://gwern.net/fiction/batman -- The Gift of the Amygdali -- Sci-Fi, anxiety, pain\n \nreply",
      "I think there are two types of fear mostly, the innate survival animalistic fear and the self-perpetuating fear caused due to misunderstanding. The animalistic fear is present in all and it's not possible to get rid of. When you see a snake or a tiger in front of you, that fear is natural. The response is to jump or run and is so spontaneous, you can't really control it. It's necessary for survival. But I think we are interested in the other fear, the one that is bound to attachment. You see a tiger, you panic, turns out to be a cat, you laugh it off, go away, that fear is not an issue. But if you go about your day thinking, what if that was a tiger? What if I get jumped by tiger this time? Then, you are creating the fear. The fear has no basis, except for it was implanted to you awhile ago. And now you are attaching yourself to it. You are extending it which is the actual problem. Most of us have fears that go back to childhood. If you think back far enough(like the tiger example), question yourself why you are afraid, you know the answers.One more example, I used to be afraid of getting heart-attacks in the past. Even gas passing would make me panic. Have I ever had a heart-attack before? No. How am I so damn sure that I have a heart-attack if I don't even know what it's supposed to feel like? Heart-attack is a bad thing and it shouldn't be happening to me. How is every acid reflux a heart-attack to me now. I have created my own bubble of fear. When though? I sure as hell didn't know what heartattack is when I was born. So it happened when I was able to comprehend what a heart-attack is right? For me, it's due to people around me passing, it's due to reading on Internet about young celebrities dying to strokes, watching movies, etc. It got implanted in me. I don't know a heartattack I just have an idea of it which is not the same thing. Not even remotely related.Fear arises due to misunderstanding. If you trace it far back enough, fear was implanted mostly in the childhood.\n \nreply",
      "> The researchers took samples from brains of humans and rhesus macaque monkeys, separated individual cells and sequenced their RNA. This shows which genes are active (being expressed) in a particular cell and allows researchers to sort them into groups based on gene expression.How do you extract RNA from monkeys without activating the RNA that expresses fear?\n \nreply",
      "RNA is the messenger from the nucleus that tells the ribosome what to make.The DNA sequences that create the RNA are called genes. It was only learned the last few decades that genes can be turned off/on. This is how a single embryo cell can produce all the different cells in our body. Unfortunately they chose the word expressed for this concept.What they are saying is they want to study the amygdala aka the primitive pre-evolutionary part of our brain we share with other creatures. It is said the primitive brain controls breathing, heart rate,fear and anger. It is also said emotions like fear or anger is our brain\u2019s faulty perception of our body\u2019s response to all the adrenaline the amygdala is initiates.They know the amygdala  has different types of cells. To learn why certain cells malfunction, and cause depression and other disorders, they are studying DNA sequences.\n \nreply",
      "> How do you extract RNA from monkeys without activating the RNA that expresses fear?You stroke the back of the monkey's hand and give it banana treats.\n \nreply",
      "tl:dr - brains are weird manThere's a tremendous episode of Radiolab called Fault Line that talks about the effect of a total resection of the Amygdala. It worked out very poorly. I heard it weeks before I was scheduled for a right temporal lobe resection, including Amygdala and it scared the bejeesus out of me. A quick call to my neurosurgeon's coordinator assuaged my fears.The bilateral resection caused Kluver-Busey syndrome in the patient that Fault Line discusses.\n \nreply"
    ],
    "link": "https://www.ucdavis.edu/news/roots-fear-understanding-amygdala",
    "first_paragraph": "Treating anxiety, depression and other disorders may depend on the amygdala, a part of the brain that controls strong emotional reactions, especially fear. But a deep understanding of this structure has been lacking. Now scientists at the University of California, Davis have identified new clusters of cells with differing patterns of gene expression in the amygdala of humans and non-human primates. The work could lead to more targeted treatments for disorders such as anxiety that affect tens of millions of people.\u00a0The work is published Oct. 30 in the American Journal of Psychiatry.\u00a0\u201cThe amygdala is central to emotion processing in the brain, and is known to contribute to fear and anxiety,\u201d said Drew Fox, associate professor in the UC Davis Department of Psychology and senior author on the paper.For that reason, there has long been interest in whether variations in the size or structure of the amygdala are related to disorders such as anxiety and depression. However, it\u2019s increasingly c"
  },
  {
    "title": "Is the Q source the origin of the Gospels? (thecollector.com)",
    "points": 118,
    "submitter": "Tomte",
    "submit_time": "2024-11-04T11:55:30 1730721330",
    "num_comments": 195,
    "comments_url": "https://news.ycombinator.com/item?id=42040706",
    "comments": [
      "Kind of odd to see this turning up here \u2013 this theory isn't new \u2013 it's more than a century old, and this article doesn't say anything particularly new or interesting about it.  Honestly, the Wikipedia page is probably better:https://en.wikipedia.org/wiki/Q_source\n \nreply",
      "> The Farrer hypothesis proposes that Matthew used Mark as a source, but Luke used both Mark and Matthew as a source. This approach is simple and negates the need for a Q source altogether.> A weakness of the Q source hypothesis is the absence of any textual evidence despite extensive scholarly efforts to find it. The entire hypothesis is based on statistical and literary analysis and inference. It adds complexity to the synoptic problem by introducing an additional layer of tradition, transmission, and composition, which may not be warranted given the available evidence (or rather lack thereof).Wouldn't Occam's Razor suggest that the Farrer hypothesis is most likely true?Edit: Or, maybe I should just continue reading to the end first:> On the other hand, it would also make for a more complex explanation than other scholars have proposed, violating the principle of Occam\u2019s Razor. Alternatively, Mark could have been the source for Matthew, and Matthew for Luke, which is a much simpler explanation than the Q hypothesis.\n \nreply",
      "You would think so, until you realize that Matt and Luke have some narratives in common to the exclusion of Mark.That has to be accounted for, which is where Occam's Razor falls short. It's probably the strongest argument in favor of a Q source.\n \nreply",
      "Which ones do they have in common?\n \nreply",
      "A question: what is the date of the first physical copy of any of these texts?Much discussion about the temporal distance between the described events and the writers, but what about the distance between the writers and the text we know?Any hope earlier copies will surface?\n \nreply",
      "I interned for a year with a public speaker who had five or six autobiographical stories he told regularly. I found it interesting that his stories ended up like how the gospels tell Jesus stories. His messages had a main point, but he spoke extemporaneously, so depending on what he had been saying before he got to the story, he would included different elements into the story. One of the last messages I heard, he incorporated a few pieces of context at the beginning that I had never heard him tell before, and although I had heard him tell that story multiple times by that point, it completely changed the meaning of the story. Not that it invalidated the previous tellings, but that bit of context made a big difference to the meaning of the story. The gospel stories read a lot like that. Jesus may have told the stories differently depending on the context, and/ or the writer may have told the story different depending on the points he was making with the story.Which is to say, I think it less likely that Q was written. Mark is generally said (by people who follow Christ, at least) to be summarized from Peter's messages. It seems likely that Matthew and Luke took from Mark as well as a shared source of apostolic teaching, especially since Luke claims to have researched these things, and at least several of the original disciples are traditionally said to have been preaching in the Greek-speaking areas of the Mediterranean.\n \nreply",
      "This is a new-to-me and reasonable idea: that Q is the union of a collection of things.\n \nreply",
      "What's the relevant difference between a written Q and oral tradition? Surely people repeating the stories to each other would also have established a fixed wording just as if it was written down. If the gospels were written ~80 years after Jesus's death, there had to be some intermediate source since the authors wouldn't have been personally alive when Jesus was so I don't really see that there's any question to resolve. Is the alternative hypothesis that they all had different sources, like their grandpas or someone with independent lineage back to Jesus?\n \nreply",
      "You're greatly overestimating how much an oral tradition leads to fixed wording.  This is a pretty well-studied field at this point in time, and non-poetry oral traditions just don't generate the kind of long word-for-word identical passages that we see in Luke and Matthew.There's a lot of debate over the synoptic problem in the academy, but almost nobody doubts that the solution involves a literary source instead of an oral one.\n \nreply",
      "John, generally thought to be the last of the four canonical gospels, is the only Gospel that potentially dates to 80 years after Jesus's death.Per TFA The synoptic gospels are thought to have been completed no later than 95 CE, with historical dates for the crucifixion (for those that consider the crucifixion factual) 30-33CE, placing them as no more than 65 years after the crucifixion.\n \nreply"
    ],
    "link": "https://www.thecollector.com/q-source-origin-gospels/",
    "first_paragraph": "Scholars have speculated that two of the gospels share a source. Is the Q source the origin of the Gospels?\u00a0The Q source hypothesis is a prominent theory in New Testament scholarship that seeks to explain the literary relationship between the synoptic Gospels of Matthew, Mark, and Luke. According to this hypothesis, there was a hypothetical written source, known as \u201cQ\u201d (short for the German word \u201cQuelle,\u201d meaning \u201csource\u201d), which contained the sayings and teachings of Jesus that were shared by Matthew and Luke but are absent in Mark.\u00a0\u00a0Scholars refer to the gospels of Matthew, Mark, and Luke as the synoptic gospels. The term \u201csynoptic\u201d comes from two Greek words: syn, meaning \u201ctogether,\u201d and opsis, meaning \u201cseeing.\u201d It refers to the fact that these three gospels share a similar structure, tell the same stories, and parallel each other in content and wording to a large extent.\u00a0Consider the following passages from each of these gospels:\u00a0\u00a0The similarity of the texts is undeniable, and this"
  }
]