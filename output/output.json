[
  {
    "title": "Researchers develop \u2018transparent paper\u2019 as alternative to plastics (yomiuri.co.jp)",
    "points": 135,
    "submitter": "anigbrowl",
    "submit_time": "2025-06-06T21:43:10 1749246190",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44205282",
    "comments": [
      "Old is new again?https://en.wikipedia.org/wiki/Celluloidhttps://en.wikipedia.org/wiki/Cellophane\n \nreply",
      "Here is the original paper from the researchers:https://www.science.org/doi/10.1126/sciadv.ads2426Apparently they wanted to create a material that:1. is transparent,2. can be made thick enough,3. and is purely cellulose-based.Cellophane meets 1 and 3 but is hard to be made thick. Paper satisfies 2 and 3 but is not transparent. Celluroid is not explicitly mentioned in the paper, but I gather it does not satisfy 3 since it's hardly pure-cellulose.The main application target seems to be food packaging.\n \nreply",
      "Great summary of paper akin of TL;DR.If only AI/LLM can summarize most research papers like this correctly and intuitively I think most people will pay good money for it, I know I would.\n \nreply",
      "I genuinely wonder if the Romans actually had peak technology all things considered & balanced.\n \nreply",
      "Too much lead.\n \nreply",
      "It actually wasn't poisonous given the circumstances.\n \nreply",
      "Sounds similar to cellophane. But the process to make it is very different. Maybe it has some new properties that cellophane doesn't.\n \nreply",
      "\"(\u2026) They can be used to make containers because they are thicker than conventional cellulose-based materials. The new material is expected to replace plastics for this purpose, as plastics are a source of ocean pollution.\"\n \nreply",
      "It\u2019s funny how we\u2019ve all just become desensitized to the idea that some countries simply dump their garbage in the ocean and rather than work on that problem, we work on creating better garbage.\n \nreply",
      "> some countries simply dump their garbage in the oceanAnd most other countries dump their garbage in these less fortunate countries for 'recycling'.Can't really get mad at poor third world countries we have been using as dumpsters.If you don't believe me or think this is hyperbole, no I'm being literal here. Almost everything you sort out into a recycling bin gets dumped in the the ocean somewhere far from you.https://www.theguardian.com/environment/2021/dec/31/waste-co...https://www.motherjones.com/environment/2023/03/rich-countri...https://www.theguardian.com/us-news/2019/jun/17/recycled-pla...https://www.dandc.eu/en/article/industrialised-countries-are...\n \nreply"
    ],
    "link": "https://japannews.yomiuri.co.jp/science-nature/technology/20250605-259501/",
    "first_paragraph": "Please disable the ad blocking feature.To use this site, please disable the ad blocking feature and reload the page.This website uses cookies to collect information about your visit for purposes such as showing you personalized ads and content, and analyzing our website traffic. By clicking \u201cAccept all,\u201d you will allow the use of these cookies.Users accessing this site from EEA countries and UK are unable to view this site without your consent. We apologize for any inconvenience caused.The Yomiuri Shimbun14:47 JST,\u2002June 5, 2025A team of researchers with the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) and other entities have developed thick sheets of transparent paper using cellulose, a material made from plant biomass.The transparent paper sheets can be broken down by microbes into water and carbon dioxide. Also, they can be used to make containers because they are thicker than conventional cellulose-based materials. The new material is expected to replace plastics f"
  },
  {
    "title": "A year of funded FreeBSD development (daemonology.net)",
    "points": 162,
    "submitter": "cperciva",
    "submit_time": "2025-06-06T19:35:54 1749238554",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=44204224",
    "comments": [
      "There are some hilarious tidbits in here> Starting in the first week of 2024, the FreeBSD boot process suddenly got about 3x slower. I started bisecting commits, and tracked it down to... a commit which increased the root disk size from 5 GB to 6 GB. Why? Well, I reached out to some of my friends at Amazon, and it turned out that the answer was somewhere between \"magic\" and \"you really don't want to know\"; but the important part for me was that increasing the root disk size to 8 GB restored performance to earlier levels.\n \nreply",
      "Now I really want to know though.\n \nreply",
      "My understanding is that EBS has some heuristics for deciding whether to keep data cached; an AMI which has a cached snapshot as its root disk will boot much faster than an AMI where all the data needs to be pulled from S3.\n \nreply",
      "What's the smallest size for which those heuristics keep the snapshot cached?(I'm currently using 1GB snapshots, because my actual disk image is a tiny fraction of that size. But if bumping that to 2GB or 4GB would make it faster, that's a small price to pay.)\n \nreply",
      "I believe 1 GB is also fast.\n \nreply",
      "Thanks, that helps to hear!Do you have any other wisdom regarding mysterious reasons for fast or slow booting? EC2's boot process is deeply opaque, and any insight at all is better than nothing.\n \nreply",
      "Nothing comes to mind, but if you want to drop me an email I can walk you through some benchmarking.\n \nreply",
      "Some huge customer chunked their data into 5GB pieces so now there's a \"if size == 5GB\" in the cache code.\n \nreply",
      "Maybe, but I don't think that would explain 8 GB also being fast while 6 GB is slow?\n \nreply",
      "Customer started using 8GB chunks /s\n \nreply"
    ],
    "link": "https://www.daemonology.net/blog/2025-06-06-A-year-of-funded-FreeBSD.html",
    "first_paragraph": "\nFor several years leading up to this point I had been talking to Amazonians\non and off about the possibility of Amazon sponsoring my FreeBSD/EC2 work;\nrather predictably, most of those conversation ended up with my\ncontacts at Amazon rhyming with \"Amazon should definitely sponsor the work\nyou're doing... but I don't have any money available in my budget\nfor this\".  Finally in April 2024 I found someone with a budget, and after\nsome discussions around timeline, scope, and process, it was determined\nthat Amazon would support me for a year via\nGitHub Sponsors.  I'm\nnot entirely sure if the year in question was June through May or July\nthrough June \u2014 money had to move within Amazon, from Amazon to GitHub,\nfrom GitHub to Stripe, and finally from Stripe into my bank account, so when\nI received money doesn't necessarily reflect when Amazon intended to\ngive me money \u2014 but either way the sponsorship either has come to an end\nor is coming to an end soon, so I figured now was a good time to writ"
  },
  {
    "title": "How we decreased GitLab repo backup times from 48 hours to 41 minutes (about.gitlab.com)",
    "points": 331,
    "submitter": "immortaljoe",
    "submit_time": "2025-06-06T15:43:05 1749224585",
    "num_comments": 130,
    "comments_url": "https://news.ycombinator.com/item?id=44201975",
    "comments": [
      "The performance improvement that GitLab contributed to Git is slated to be released with v2.50.0:https://github.com/git/git/commit/bb74c0abbc31da35be52999569...\n \nreply",
      "[flagged]",
      "If the requirement is to check uniqueness, what assumptions could possibly cause a bug? In this case, why does it matter if the uniqueness is tested with a nested for loop or with a map? There are many identical ways to check uniqueness, some being faster than others.\n \nreply",
      "[flagged]",
      "Why are you making a new account for each comment? You seem to be deliberately avoiding HN's moderation system\n \nreply",
      "[flagged]",
      ">  I don\u2019t want something gathering all my thoughts historically together and tying it to something else; nothing good comes from that; I\u2019m not writing a serial novel.Yeah but you should want your thoughts on a single post to tie together.>  Many years ago I had a user with thousands of karma points. I used to get really annoyed with other users downvoting my valid and thoughtful comments because it affected my karma. Despite attempts to rally the community around getting rid of downvoting, that never happened.Sorry you had that reaction.  While I get annoyed by downvotes sometimes, I've never cared about losing some points from the mostly useless pile.\n \nreply",
      "> Yeah but you should want your thoughts on a single post to tie together.Not really. I don\u2019t want to keep cookies on my browser around longer than I need to. Our devices are not safe havens. I\u2019d say \u201cparanoia\u201d but the struggle is real.\n \nreply",
      "You don't have to enter any e-mail address to get an HN account. You login from a (Firefox) incognito window and get your cookies deleted the moment the window is closed.Why you're so afraid to let your ideas and views collect under a single account? Are they that controversial or are you weary of your own thoughts and don't want to see them again, or are you afraid to own your views as yours?We're talking (mostly) tech here, and nobody is forced to comment.\n \nreply",
      "This is a pretty ridiculous comment imo. Someones views or background don't have to be wrong or controversial to be endangered by them. We have enough historical precedent to know this, remember nazi germany and the jewish?While I don't go as far as the poster you are replying to, I do see his way as superior. It's just too much hassle for me.\n \nreply"
    ],
    "link": "https://about.gitlab.com/blog/2025/06/05/how-we-decreased-gitlab-repo-backup-times-from-48-hours-to-41-minutes/",
    "first_paragraph": ""
  },
  {
    "title": "Medieval Africans Had a Unique Process for Purifying Gold with Glass (2019) (atlasobscura.com)",
    "points": 47,
    "submitter": "mooreds",
    "submit_time": "2025-06-06T22:21:39 1749248499",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=44205599",
    "comments": [
      "Fun facts, Mansa Musa (Musa Keita) who's king in Mali Empire in Western Africa is the richest person ever lived [1].It's reported that he unintentionally disrupted Eqyption economy for at least ten years. He did that by spending and giving charity in gold enroute to pilgrimage or Hajj in Mecca while staying about 3 months in Egypt. Allegedly he had hundred camels in towing, each camel carrying hundreds of pounds of pure gold. Pilgrimage to Mecca is the journey that every Muslim has to make once in a lifetime if they can afford it.[1] Mansa Musa: The richest man who ever lived (105 comments):https://news.ycombinator.com/item?id=19350951[2] Mansa Musa:https://en.wikipedia.org/wiki/Mansa_Musahttps://news.ycombinator.com/item?id=19350951\n \nreply",
      "This made me realize that I have absolutely no idea what was going on in Africa during medieval times (and only a sliver of an idea in Europe).\n \nreply",
      "Mansa Musa is totally worth reading about, as are philosophers etc. like Ibn Khaldun and others (Ibn Khaldun wrote about Mansa Musa's pilgrimage, wealth, etc.).There was a lot going on in medieval Africa, I wish I had some good sources, if anyone knows any I'd be interested in expanding my knowledge as well!\n \nreply",
      "So much history to be proud of https://en.m.wikipedia.org/wiki/Indian_Ocean_slave_tradeThen again once rentseeking via trade routes collapsed and the portugese and spanish took over, it was suddenly less glorious. Well, now the region has got a 2nd chance to bloom, thanks to oil rentseeking and will soon export the worlds biggest mushrooms .\n \nreply",
      "[flagged]",
      "How is it even allowed given how hateful it is?Someday I'll create a crusadecrusade account to compare how long it stays unbanned.\n \nreply",
      "\"Jihad\" in Arabic just means \"struggle.\" There is a large gap between what \"jihad\" means, even in a Muslim context, and what you think it means.\n \nreply",
      "Surely someone who is signing up for an account on an American tech message board would understand the connotation that word carries in the West (and indeed in Islamic society as well, since contextual usage makes it quite obvious what's inferred and there are multiple words that could be used instead). An innocent excuse of \"well in my language it just means struggle\" is only going to fool the na\u00efve.\n \nreply",
      "\"only\" seems unlikely.There are many words aquired across cultures and given meanings that differ from their original context. Using such words can prompt discussion and leave some better informed about original meaning in original contexts in populations that dwarf the US population.",
      "Go ahead. Literally no one will care about it as much as you care about this.\n \nreply"
    ],
    "link": "https://www.atlasobscura.com/articles/medieval-african-gold",
    "first_paragraph": "\n                          Our small-group adventures are inspired by our Atlas of the world's most fascinating places, the stories behind them, and the people who bring them to life.\n                        When Sam Nixon, an archaeologist with the British Museum, excavated ancient coin molds in Tadmekka, Mali, in 2005, it triggered a several-year exploration of how medieval Africans purified the gold they were using for their currency. Nixon had found little droplets of highly refined gold left over in the molds\u2014which have been dated to the 11th century\u2014as well as curious fragments of glass. Now scientists have recreated the advanced process behind the purification method they used then.\u201cThis is the first time in the archaeological record that we saw glass being used to be able to refine gold,\u201d says Marc Walton, codirector of the Center for Scientific Studies in the Arts, a collaboration between Northwestern University and the Art Institute of Chicago. \u201cThe glass appeared to be mater"
  },
  {
    "title": "The time bomb in the tax code that's fueling mass tech layoffs (qz.com)",
    "points": 501,
    "submitter": "booleanbetrayal",
    "submit_time": "2025-06-04T13:30:21 1749043821",
    "num_comments": 348,
    "comments_url": "https://news.ycombinator.com/item?id=44180533",
    "comments": [
      "There are some misunderstandings in the comments that seem to stem from not having read the section, so I thought it was worth referencing the actual text [0]. It's quite short and easy to read.The most important bits:* Subsection (a) requires amortizing \"Specified research or experimental expenditures\" over 5 years (paragraph (2)) instead of deducting them (paragraph (1))* Paragraph (c)(3) is a Special Rule that requires that all software development expenses be counted as a \"research or experimental expenditure\".That's it. All software expenses must be treated as research and experimental expenses, and no research and experimental expense can be deducted instead of amortized. Ergo, all software expenses must be amortized over 5 years.I strongly recommend reading the section before forming an opinion. It really is quite unambiguous and is unambiguously bad for anyone who builds software and especially for companies that aren't yet thoroughly established in their space (i.e. startups).Also note that this makes Software a special case of R&D. It's the only form of R&D that Section 174 requires you to categorize as such and therefore amortize.[0] https://www.law.cornell.edu/uscode/text/26/174\n \nreply",
      "We are small and so have been on a hiring freeze since 2022. I\u2019d like to hire but the upfront cost is high.For those around when this went into effect many business owners were surprised. Our accountants told us they seriously thought congress would fix this before it went into effect.\n \nreply",
      "And if the R&D uses foreign workers, because you can't afford to pay US wages, then the 5 years goes to 15 years!This hurts small companies (like mine) that were priced out of the US developer market.\n \nreply",
      "Who sponsored this text in the bill?\n \nreply",
      "I worked for a UK company that amortised it\u2019s development costs\u2026 it led to the false belief that the company was profitable when it really wasn\u2019t\n \nreply",
      "\"Profitable\" in an accounting sense has nothing to do with your cash position. This is something that people in tech don't really seem to understand.\n \nreply",
      "Exactly. And if you\u2019re more profitable on paper, you have to pay more tax, making you even less profitable in reality.\n \nreply",
      "Yes, that is tremendously important aspect here - the US tech would look better on paper - higher paper profits due lower paper expenses - while getting  increased cash flow stress due to decreased deductability of the salaries which are among the main expenses in software dev business.\n \nreply",
      ">Yes, that is tremendously important aspect here - the US tech would look better on paperIt's completely unimportant.  Nobody is getting fooled \"on paper\" by amortized salaries.\n \nreply",
      "People is getting fooled by \"adjusted\" earnings that reduce salaries \"on paper\" by hiding the \"non cash\" component.\n \nreply"
    ],
    "link": "https://qz.com/tech-layoffs-tax-code-trump-section-174-microsoft-meta-1851783502",
    "first_paragraph": ""
  },
  {
    "title": "Dear High Schoolers, Time Is Precious (byronsharman.com)",
    "points": 11,
    "submitter": "chilipepperhott",
    "submit_time": "2025-06-06T23:15:46 1749251746",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44206007",
    "comments": [
      "Shared this with my som, who is taking his SAT tomorrow.\n \nreply",
      "The author dispensing wisdom to high schoolers is himself 20 years old.\n \nreply",
      "For this advice, that is the best place to share it from.  They're saying even by age 20 it's already the case that the effort was wasted.\n \nreply",
      "I don't think that clear at all at 20. Yes the numbers are mostly meaningless, but there is a lot of value knowing what it means to study, work hard, and care about something.\n \nreply",
      "Eh. High school sucks. Get it over with as fast as possible.\n \nreply"
    ],
    "link": "https://byronsharman.com/blog/dear-high-schoolers",
    "first_paragraph": ""
  },
  {
    "title": "Highly efficient matrix transpose in Mojo (veitner.bearblog.dev)",
    "points": 71,
    "submitter": "timmyd",
    "submit_time": "2025-06-06T19:28:29 1749238109",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44204155",
    "comments": [
      "The \"Switching to Mojo gave a 14% improvement over CUDA\" title is editorialized, the original is \"Highly efficient matrix transpose in Mojo\".Also, the improvement is 0.14%, not 14% making the editorialized linkbait particularly egregious.\n \nreply",
      "[op here] To be clear: Yes, there are 3 kernels - you can see those in the linked github at the end of the article if you clicked that. These are:transpose_naive - Basic implementation with TMA transferstranspose_swizzle - Adds swizzling optimization for better memory access patternstranspose_swizzle_batched - Adds thread coarsening (batch processing) on top of swizzlingPerformance comparison with CUDA: The Mojo implementations achieve bandwidths of:transpose_naive: 1056.08 GB/s (32.0025% of max)transpose_swizzle: 1437.55 GB/s (43.5622% of max)transpose_swizzle_batched: 2775.49 GB/s (84.1056% of max)via the GitHub - simveit/efficient_transpose_mojoComparing to the CUDA implementations mentioned in the article:Naive kernel: Mojo achieves 1056.08 GB/s vs CUDA's 875.46 GB/sSwizzle kernel: Mojo achieves 1437.55 GB/s vs CUDA's 1251.76 GB/sBatched swizzle kernel: Mojo achieves 2775.49 GB/s vs CUDA's 2771.35 GB/sSo there is highly efficient matrix transpose in MojoAll three Mojo kernels outperform their CUDA counterparts, with the naive and swizzle kernels showing significant improvements (20.6% and 14.8% faster respectively), while the final optimized kernel achieves essentially identical performance (slightly better by 4.14 GB/s).The \"flag\" here seemed innapropriate given that its true this implementation is indeed faster, and certainly the final iteration could be improved on further. It wasn't wrong to say 14% or even 20%.\n \nreply",
      "Users of the site only have one control available: the flag. There's no way to object only to the title but not to the post, and despite what you say that title hit the trifecta: not the original title, factually incorrect, and clickbait. So I'm not that surprised it got flagged (even if I did not flag it myself).Email the mods at hn@ycombinator.com. There's a chance they'll remove the flag and re-up the post.\n \nreply",
      "thanks jsnell - i did they and they appreciated the comment above, and unflagged it. i appreciate it!\n \nreply",
      "I think the OP based the title off of \"This kernel archives 1437.55 GB/s compared to the 1251.76 GB/s we get in CUDA\" (14.8%) and not the final kernels for whatever reason\n \nreply",
      "Yeah, it seems like the blog post is just meant to be an example of how to do something in Mojo and not a dunk on CUDA.\n \nreply",
      "FWIW I didnt take the blog as a dunk on CUDA, just as an impressive outcome from the blog writer in Mojo. It's awesome to see this on Hopper - if it makes it go faster thats awesome.\n \nreply",
      "0.14% is within the limits of statistical error. So this is a nothing-\"article\".\n \nreply",
      "I don't think that's fair. The article promised a highly efficient kernel and seems to have delivered exactly that, which isn't \"nothing\". My beef is entirely with the submitted title.\n \nreply",
      "I'm not an expert in this space, but is this meaningful? I'd assume that it's more common to fuse together transposition with an operation that precedes or follows it (e.g. matmul), which should be far more efficient than materializing the entire transposition in memory if it's just an intermediate value.\n \nreply"
    ],
    "link": "https://veitner.bearblog.dev/highly-efficient-matrix-transpose-in-mojo/",
    "first_paragraph": ""
  },
  {
    "title": "The Illusion of Thinking: Understanding the Limitations of Reasoning LLMs [pdf] (cdn-apple.com)",
    "points": 100,
    "submitter": "amrrs",
    "submit_time": "2025-06-06T18:18:36 1749233916",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=44203562",
    "comments": [
      "These are the kind of studies that make so much more sense than the \"LLMs can't reason because of this ideological argument or this one anecdote\" posts/articles.  Keep 'em coming!And also; the frontier LLMs blow older LLMs out of the water.  There is continual progress and this study would have been structured substantially the same 2 years ago with much smaller N on the graphs because the regimes were much tinier then.\n \nreply",
      "> Rather than standard benchmarks (e.g., math problems), we adopt controllable puzzle environments that let us vary complexity systematicallyVery clever, I must say. Kudos to folks who made this particular choice.> we identify three performance regimes: (1) low complexity tasks where standard models surprisingly outperform LRMs, (2) medium-complexity tasks where additional thinking in LRMs demonstrates advantage, and (3) high-complexity tasks where both models experience complete collapse.This is fascinating! We need more \"mapping\" of regimes like this!What I would love to see (not sure if someone on here has seen anything to this effect) is how these complexity regimes might map to economic value of the task.For that, the eval needs to go beyond puzzles but the complexity of the tasks still need to be controllable.\n \nreply",
      "Their finding of LLMs working best at simple tasks, LRMs working best at medium complexity tasks, and then neither succeeding at actually complex tasks is good to know.\n \nreply",
      "Not sure whether I sense sarcasm.\n \nreply",
      "Man, remember when everyone was like 'AGI just around the corner!' Funny how well the Gartner hype cycle captures these sorts of things\n \nreply",
      "To be fair, the technology sigmoid curve rises fastest just before its inflection point, so it is hard to predict at what point innovation slows down due to its very nature.The first Boeing 747 was rolled out in 1968, only 65 years after the first successful heavier-than-air flight. If you told people back then that not much will fundamentally change in civil aviation over the next 57 years, no one would have believed you.\n \nreply",
      "What do you think has changed? The situation is still about as promising for AGI in a few years - if not more so. Papers like this are the academics mapping out where the engineering efforts need to be directed to get there and it seems to be a relatively small number of challenges that are easier as the ones already overcome - we know machine learning can solve Towers of Hanoi, for example. It isn't fundamentally complicated like Baduk is. The next wall to overcome is more of a low fence.Besides, AI already passes the Turing test (or at least, is most likely to fail because it is too articulate and reasonable). There is a pretty good argument we've already achieved AGI and now we're working on achieving human- and superhuman-level intelligence in AGI.\n \nreply",
      "\u2026but that was, like, two years ago? If we go from GPT2 to AGI in ten years that will still feel insanely fast.\n \nreply",
      "They're similar to self-driving vehicles. Both are around the corner, but neither can negotiate the turn.\n \nreply",
      "All that to keep the investment pyramid schemes going.\n \nreply"
    ],
    "link": "https://ml-site.cdn-apple.com/papers/the-illusion-of-thinking.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Sandia turns on brain-like storage-free supercomputer (blocksandfiles.com)",
    "points": 151,
    "submitter": "rbanffy",
    "submit_time": "2025-06-06T15:24:44 1749223484",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=44201812",
    "comments": [
      "Whenever I hear about neuromorphic computing, I think about the guy who wrote this article, who was working in the field:Thermodynamic Computing\nhttps://knowm.org/thermodynamic-computing/It's the most high-influence, low-exposure essay I've ever read. As far as I'm concerned, this dude is a silent prescient genius working quietly for DARPA, and I had a sneak peak into future science when I read it. It's affected my thinking and trajectory for the past 8 years\n \nreply",
      "Isn't this just simulated annealing in hardware attached to a grandiose restatement of the second law of thermodynamics?\n \nreply",
      "Yes. This keeps showing up in hardware engineering labs, and never holds up in real tasks.\n \nreply",
      "Is this what Extropic (https://www.extropic.ai/) is aiming to commercialize and bring to market?\n \nreply",
      "Interesting read, more so than the OP. Thank you.\n \nreply",
      "I will say that the philosophical remarks are pretty obtuse and detract from the post. For example...\"Physics\u2013and more broadly the pursuit of science\u2013has been a remarkably successful methodology for understanding how the gears of reality turn. We really have no other methods\u2013and based on humanity\u2019s success so far we have no reason to believe we need any.\"Physics, which is to say, physical methods have indeed been remarkably successful...for the types of things physical methods select for! To say it is exhaustive not only begs the question, but the claim itself is not even demonstrable by these methods.The second claim contains the same error, but with more emphasis. This is just off-the-shelf scientism, and scientism, apart from what withering refutations demonstrate, should be obviously self-refuting. Is the claim that \"we have no other methods but physics\" (where physics is the paradigmatic empirical science; substitute accordingly) a scientific claim? Obviously not. It is a philosophical claim. That already refutes the claim.Thus, philosophy has entered the chat, and this is no small concession.\n \nreply",
      "I\u2019m not sure I understand what you\u2019re trying to say. It\u2019s not really questionable that science and math are the only things to come out of philosophy or any other academic pursuit that have actually shown us how to objectively understand reality.Now physics vs other scientific disciplines sure. Physicists love to claim dominion just like mathematicians do. It is generally true however that physics = math + reality and that we don\u2019t actually have any evidence of anything in this world existing outside a physical description (eg a lot of physics combined = chemistry, a lot of chemistry = biology, a lot of biology = sociology etc). Thus it\u2019s reasonable to assume that the chemistry in this world is 100% governed by the laws of physics and transitively this is true for sociology too (indeed - game theory is one way we quantifiably explain the physical reality of why people behave the way they due). We also see this in math where different disciplines have different \u201cbridges\u201d between them. Does that mean they\u2019re actually separate disciplines or just that we\u2019ve chosen to name features on the topology as such.\n \nreply",
      "Man, this article is incredible. So many ideas resonate with me, but I never can't formulate them. Thanks for sharing, all my friends have to read this.\n \nreply",
      "If you like this article, you\u2019ll probably enjoy reading most publications from the Santa Fe Institute.\n \nreply",
      "I'd be interested to learn who paid for this machine!Did Sandia pay list price? Or did SpiNNcloud Systems give it to Sandia for free (or at least for a heavily subsidsed price)? I conjecture the latter. Maybe someone from Sandia is on the list here and can provide detail?SpiNNcloud Systems is known for making misleading claims, e.g. their home page https://spinncloud.com/ lists DeepMind, DeepSeek, Meta and\nMicrosoft as \"Examples of algorithms already leveraging dynamic sparsity\", giving the false impression that those companies use SpiNNcloud Systems machines, or the specific computer architecture SpiNNcloud Systems sells.\nTheir claims about energy efficiency (like \"78x more energy efficient than current GPUs\") seem sketchy. How do they measure energy consumption and trade it off against compute capacities: e.g.  a Raspberry Pi uses less absolute energy than a NVIDIA Blackwell but is this a meaningful comparison?I'd also like to know how to program this machine. Neuromorphic computers have so far been terribly difficult to program. E.g. have JAX, TensorFlow and PyTorch been ported to SpiNNaker 2? I doubt it.\n \nreply"
    ],
    "link": "https://blocksandfiles.com/2025/06/06/sandia-turns-on-brain-like-storage-free-supercomputer/",
    "first_paragraph": ""
  },
  {
    "title": "What \"Working\" Means in the Era of AI Apps (a16z.com)",
    "points": 23,
    "submitter": "Brysonbw",
    "submit_time": "2025-06-06T22:36:33 1749249393",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44205718",
    "comments": [
      "The article lists the many ways in which the bar for success - the minimum \"table stakes\" that you have to achieve in order to be considered success - have drastically risen, and then concludes with:> we believe there\u2019s never been a better time to build an application-layer software company.Nothing could be a clearer indication that the primary desirable quality in a founder is the conviction that, against all odds, you are better than everyone else.\n \nreply",
      "If you don\u2019t believe in yourself, no one else will.\n \nreply",
      "And a self-centered asshole.\n \nreply",
      "That was implied :)\n \nreply",
      "Anyone else a bit confused by the use of the word \"working\" used, given the content of the post? I thought this was going to be about how white collar work is changing, not about fundraising and growth strategies.\n \nreply",
      "I don't take anything that comes from a16z seriously, specially since their crypto craze\n \nreply",
      "Difficult to know the size of the pool of companies they're talking about\n \nreply",
      "I read TFA. Quickly but I read it. It's short but I have no idea if they were saying \"wow AI products are popular\" or \"AI helps startups reach higher levels of profitability faster\" or simply \"A company that says they are making an AI driven product receives more initial users and funding\".Each of those are so wildly different conclusions and require such wildly different data to support it.\n \nreply",
      "Nowadays, I don't think work should be defined just by clocking in and clocking out. It\u2019s about the ability to complete tasks and hit goals efficiently. This is how AI will redefine work.\n \nreply",
      "When tulips suddenly became fashionable a few years back, articles like this were rife.This article even smells ... generative.\n \nreply"
    ],
    "link": "https://a16z.com/revenue-benchmarks-ai-apps/",
    "first_paragraph": "Olivia Moore and Marc AndruskoOne of the most common refrains in the generative AI era is that \u201cstartups are growing faster than ever\u201d \u2014 often with fewer resources. Some notable examples? Per company metrics, Lovable hit $50 million in revenue in just six months, Cursor reported $100 million in revenue in its first year, and Gamma reached $50 million in revenue on less than $25 million raised.\u00a0But for the average AI company (not the top 0.1%), what does growth really look like? Pre-AI, a common benchmark for best-in-class enterprise startups was $1 million in ARR in its first 12 months. Consumer companies, by contrast, often delayed monetization well beyond their first year, typically waiting until they had built a base of millions (or tens of millions) of users to monetize through ads.\u00a0Based on data across hundreds of companies we\u2019ve seen over the last 18 months, we can definitively say these metrics have shifted. Here\u2019s what we\u2019re seeing among the companies we\u2019ve spent significant ti"
  },
  {
    "title": "I Read All of Cloudflare's Claude-Generated Commits (maxemitchell.com)",
    "points": 8,
    "submitter": "maxemitchell",
    "submit_time": "2025-06-06T22:35:01 1749249301",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.maxemitchell.com/writings/i-read-all-of-cloudflares-claude-generated-commits/",
    "first_paragraph": "photosvideoscode_artwritingsabout~2025-06-06A few days ago, my CTO Chris shared Cloudflare's open-sourced OAuth 2.1 library that was almost entirely written by Claude. What caught my attention wasn't just the technical achievement, but that they'd documented their entire creative process. Every prompt, every iteration, every moment of human intervention was preserved in git commit messages\u2014creating what felt like an archaeological record of human-AI collaboration. Reading through their development history was like watching a real-time conversation (and sometimes struggle) between human intuition and artificial intelligence.The lead engineer, @kentonv, started as an AI skeptic. \"I was trying to validate my skepticism. I ended up proving myself wrong.\" Two months later, Claude had generated nearly all of the code in what became a production-ready authentication library.Kenton included the prompt used to generate code in every commit, which made this exploration possible. As we begin to l"
  },
  {
    "title": "Falsehoods Programmers Believe About Aviation (flightaware.engineering)",
    "points": 18,
    "submitter": "cratermoon",
    "submit_time": "2025-06-06T22:20:33 1749248433",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://flightaware.engineering/falsehoods-programmers-believe-about-aviation/",
    "first_paragraph": "At FlightAware, our software needs to gracefully handle all sorts of weird and wonderful situations. While we as engineers might hope for aviation data to be clean and well-standardized, the real world is messy.There are a lot of assumptions one could make when designing data types and schemas for aviation data that turn out to be inaccurate. In the spirit of Patrick McKenzie\u2019s classic piece on names, here are some false assumptions one might make about aviation. While many of these are simply common misconceptions, some of these assumptions have bitten our customers at various points, and others have caused issues in our own systems over the years.Together they are illustrative of the situations that Hyperfeed, our flight tracking engine, is responsible for correctly interpreting in order to provide a clean and consistent data feed for our website, apps, and APIs.Thanks to my colleagues who contributed to or reviewed this collection of falsehoods: Mark Duell, Paul Durandt, Karina Eliz"
  },
  {
    "title": "Odyc.js \u2013 A tiny JavaScript library for narrative games (odyc.dev)",
    "points": 180,
    "submitter": "achtaitaipai",
    "submit_time": "2025-06-06T13:46:01 1749217561",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=44200866",
    "comments": [
      "Why is the title '...for narrative games'? The library's front page itself doesn't say anything about 'narrative' games.For that matter, what is a \"narrative game\". None of the sample games would fit the definition in my head of \"narrative game\". If I google for \"narrative game\", the sample games certainly don't seem to fit.And, assuming there is a common definition of \"narrative game\", what does this library do special to facility making \"narrative games\" that other game engines do not?\n \nreply",
      "I think the idea is that it gives you a declarative way to build simple adventure games with text and dialogue.Its selling point isn't for building mechanics-first games like a more general engine (e.g. Pico-8).But what you can do is easily make maps, a character that walks between maps, NPCs, and triggers for dialogue/text.Consider other engines aimed at non-programmers like RPGMaker: the main games people make with it are \"narrative games\" where you walk around and read text/dialogue, usually with zero additional mechanics outside of the built-in map + trigger system. It's probably 90% of games built with it!So I'd reckon they're saying \"you can build those games with this tool too\".\n \nreply",
      "A closer comparison than Pico-8 might Bitsy or PuzzleScript, but with all the power (and complexity) of arbitrary JavaScript code underneath.\n \nreply",
      "I was kind of hoping it would be for text based adventures,since last night I had the idea for one,where you're an adult and you have to do adult thingslike file taxes and go to work and dust your houseand the less you do these things the harder life gets,but the more you do them, the easier it gets,and the goal of the game is to die with no debt.\n \nreply",
      "Ink language & their IDE make it very easy to get started with choice games ! And it exports to HTML/Js where you can add further visual effects via custom JavaScript.Highly reccomend, its so good that it takes all the fun out of designing my own janky custom system.\n \nreply",
      "Unfortunately Inky has a showstopping bug I and a few others have hit. [0]And it breaks the IDE until you somehow uninstall it and every dependency. And kill all its temporary files.[0] https://github.com/inkle/inky/issues/522\n \nreply",
      "Thanks for the recommendation, I never would have guessed someone made something like this! But of course they did.I was definitely wondering how I would do this outside of Excel, but I have so many projects going on right now that figuring this one out didn't sound fun :D\n \nreply",
      "You've got an idea. Now for the hard part: make it fun. :D Especially in a text-only medium.\n \nreply",
      "My only plan for that was to add shadertoys effects to the text. Not great hence I hadn't started.\n \nreply",
      "Speaking of, check out this shader ascii text game I saw on Steam: https://www.youtube.com/watch?v=dfe3VK7H6uII kind of love the look.Maybe with a new set of ansi escapes we can get Zork to look like that. :D\n \nreply"
    ],
    "link": "https://odyc.dev",
    "first_paragraph": ""
  },
  {
    "title": "A masochist's guide to web development (tronto.net)",
    "points": 176,
    "submitter": "sebtron",
    "submit_time": "2025-06-06T13:48:52 1749217732",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=44200895",
    "comments": [
      "> Notice I have changed the extension from .js to .mjs. Don\u2019t worry, either extension can be used. And you are going to run into issues with either choiceAs someone that has used module systems from dojo to CommonsJS to AMD to ESM with webpack and esbuild and rollup and a few others thrown in ... this statement hits hard.\n \nreply",
      "Yeah, the commonjs to esm transition has been the python 2 to python 3 transition of JavaScript, except the benefits are limited (at least compared to the hassle created).There are many libraries that have switched to esm only (meaning they don't support commonjs), but even today, the best way to find the last commonjs version of those libraries is to go to the \"versions\" tab on npm, and find the most downloaded version in the last month, and chances are, that will be the last commonjs version.Yes, in a vacuum, esm is objectively a better than commonjs, but how tc39 almost intentionally made it incompatible with commonjs  (via top-level awaits) is just bizarre to me.\n \nreply",
      "It had to be incompatible with CommonJS regardless of top level await. There is no imaginable scenario where browsers would ship a module system with synchronous request and resolution semantics. A module graph can be arbitrarily deep, meaning that synchronous modules would block page load for arbitrarily deep network waterfalls. That\u2019s a complete non-starter.Given that, top-level await is a sensible affordance, which you\u2019d have to go out of your way to block because async modules already have the same semantics.Recently, Node has compromised by allowing ESM to be loaded synchronously absent TLA, but that\u2019s only feasible because Node is loading those models from the file system, rather than any network-accessible location (and because it already has those semantics for CJS). That compromise makes sense locally, too. But it still doesn\u2019t make sense in a browser.\n \nreply",
      "Yeah, modules in jsland are just trauma... now we have import maps in the browser too. Let's see what kinds of fun we can have with those.\n \nreply",
      "A recent improvement in import map support in the browser https://shopify.engineering/resilient-import-maps\n \nreply",
      "The interesting bit is this: https://philipwalton.com/articles/cascading-cache-invalidati... Without that one sentence, the entire article is moot because I thought bundlers solved the problem.I haven't thought about that in years. I didn't realize it had been solved.Browser support looks pretty good.I guess now I have to figure out how to get this to play nice with Vite and TypeScript module resolution.... and now it's starting to hurt my brain again, great.\n \nreply",
      "There is more here that is likely to cause problems in the future. One is the author's use of var instead of let or const. var continues to work but most JS devs have linters that ban the use of var. The issue is, var has function scope, not brace scope. Most non-JS devs coming from other languages will eventually run into this issue.Another issue porting native apps is, native apps are compiled for a specific platform and hardcoded to that platform's conventions. A good example of this is hardcoding Ctrl-C (copy), Ctrl-V (paste) at compile time, which maybe works on Linux and Windows\nbut doesn't work on Mac.IIRC the way you're supposed to handle this on the web is listen for copy and paste events. AFAIK Unity has this issue. They hard coded Ctrl-C, Ctrl-P and so copy and paste don't work on Mac. Most games don't need copy and paste but once in a while someone does something that does need it, then exports to the web and runs into this issue.\n \nreply",
      "Nice writeup! You definitely chose a pretty hard way, but the project setup is always the most complex part. Bonus points for immediately running into security/header issues, but my bet would have been CORS.At $WORK, we're also building with emscripten/C++. We'll add WebGPU/shaders and WebAudio for bonus pain.\n \nreply",
      "Masochist? that's much more sane than the js clusterfuck ecosystem\n \nreply",
      "\"Clusterfuck\" is implicit and may be omitted.\n \nreply"
    ],
    "link": "https://sebastiano.tronto.net/blog/2025-06-06-webdev/",
    "first_paragraph": "I have recently worked on making a web application out of\nmy latest Rubik\u2019s cube optimal solver.\nThis involved building a rather complex C code base (with\nmultithreading, SIMD, callback functions and whatnot) to\nWebAssembly via\nEmscripten, and writing a minimal amount of\nJavaScript and HTML for the frontend.This whole process was complex, tiring and at times frustrating -\nbut eventually it was a success! Not only\nI accomplished my goal, but I have learnt a lot along the way. After\nfinishing the work, I decided to write down all that I have learnt and\nshare it with the world with this post.You may be wondering why one should do such a thing instead of either\nrewriting their code base in a more web-friendly language, or distributing\ntheir app using a native GUI framework. The main reason to use WebAssembly\nis that it can provide near-native performance (or so they claim) while\nrunning inside a web browser; this gives you all the portability of a\nweb app without too much of a performance "
  },
  {
    "title": "Onyx (YC W24) \u2013 AI Assistants for Work Hiring Founding AE (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-06-06T21:00:00 1749243600",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/onyx/jobs/Gm0Hw6L-founding-account-executive",
    "first_paragraph": "Open Source AI Assistant and Enterprise SearchAt Onyx, we\u2019re building the connective tissue between generative AI and the modern workplace, unlocking company-specific knowledge and making AI truly useful at work. We\u2019re fortunate to have incredible customers using Onyx every day and inbound interest from world-class brands landing in our inbox weekly. Now, we\u2019re ready to scale what\u2019s working and go even bigger.As our first Account Executive, you won\u2019t just sell, you\u2019ll help build our entire GTM engine. From refining our sales playbook to helping us define how we grow, your fingerprints will be all over our next chapter. There\u2019s real opportunity here to grow into sales leadership as we scale.You\u2019ll be the tip of the spear for our GTM efforts, working across the entire sales funnel while partnering closely with our founders and technical team. This is a high-ownership, high-impact role for someone who thrives in ambiguity, loves to build from scratch, and wants to shape how great sales is"
  },
  {
    "title": "A leaderless NASA faces its biggest-ever cuts (economist.com)",
    "points": 46,
    "submitter": "libraryofbabel",
    "submit_time": "2025-06-06T18:03:41 1749233021",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44203444",
    "comments": [
      "https://archive.is/JGPw9\n \nreply",
      "It may take a few years but there's Blue Origin's New Glenn (i.e. https://spacenews.com/nasas-escapade-could-launch-on-second-...)\n \nreply",
      "If they maintain their development speed I don\u2019t have much hope. They got started before SpaceX and still haven\u2019t reached orbit.\n \nreply",
      "I generally agree with this sentiment, but they did reach orbit with their sole launch of New Glenn! An admirable thing, even if it took like a quarter of a century.....\n \nreply",
      "They reached orbit with new glenn in January. This just isn't true.\n \nreply",
      "Does anyone have a mirror?\n \nreply",
      "And if Elon pulls SpaceX out of NASA?\n \nreply",
      "What if the gov takes over SpaceX overnight?\n \nreply",
      "You'd have bigger questions coming up based on the general 'how did it get to this' as well as any other companies as well as the populace being very concerned about such behavior.\n \nreply",
      "As long as it was made clear that it was about a critical defense contractor being helmed by a very public drug addict and essentially turning off a critical defense capability, I think everyone would just nod and move on with their lives.\n \nreply"
    ],
    "link": "https://www.economist.com/science-and-technology/2025/06/04/a-leaderless-nasa-faces-its-biggest-ever-cuts",
    "first_paragraph": ""
  },
  {
    "title": "Smalltalk, Haskell and Lisp (storytotell.org)",
    "points": 41,
    "submitter": "todsacerdoti",
    "submit_time": "2025-06-06T20:55:34 1749243334",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44204878",
    "comments": [
      "It looks OK to me:    (define (time-to-move from-pos to-pos)\n      ;; Calculates the total time to move between two positions,\n      ;; assuming rotation and ascension can occur simultaneously.\n      (max (time-to-rotate (position-azimuth   from-pos)\n                           (position-azimuth   to-pos))\n           (time-to-ascend (position-elevation from-pos)\n                           (position-elevation to-pos))))\n \nreply",
      "Yeah, I was going to say. The simplicity and readability of Lisp code is inversely proportional to the use of macros.\n \nreply",
      "There's a lot in this article that I really identify with: the preference for a functional style (even if I'm just not smart enough to do the whole ultra-abstract symbol soup Haskell thing); the comfort I feel leaning on the compiler; \"it also always feels like I\u2019m tricking Lisp into doing what I want, rather than simply expressing what I want\" feels like it came right from my brain.God, Lisp...the core language isn't exactly that interesting in this day-and-age. Dynamic typing, garbage collection, anonymous functions, this has been the bread-and-butter of Python, JS, Ruby, etc. developers for like 20 years now. It's got some really powerful features like conditions and CLOS. But then the bulk of the language and library built on top is such a mess: it's missing so much basic functionality, but also has so many niche functions that can be configured every which way with niche keyword arguments, and they all turned out to be evolutionary dead-ends and much worse than what the rest of the world settled on (actually CLOS probably falls into this category too). I think it's this, more than anything, that makes programming in Lisp feel like an act of trickery rather than clear thinking.But I'll also say that I've been hobby programming in Lisp a bit recently and, despite that, I've been finding it immensely pleasurable, the first time I've really enjoyed working with a computer in years. The highly interactive, image-based workflow is just so much smoother than my day job, where I'm constantly jumping between VSCode and Chrome and a console and manually rebuilding and sitting around waiting...Macros may be a double-edged sword - they encourage monstrosities like LOOP, rather than building more powerful/regular/comprehensible language features like iterators or comprehensions. BUT when paired with that interactive development experience, it really feels like you're in a dialogue with the computer, building out a little computational universe.\n \nreply",
      "I learned Common Lisp during the life of this HN account, and there's an amusing trajectory in my comments, from \"I hear Lisp is beautiful and I'd love to learn it\", through \"Wait, Common Lisp is kind of a horrendous mess\", to \"OK, I get this, this is very cool\".Common Lisp genuinely expanded my thinking about programming, so I find this article's poetry analogy very apt. But part of this growth was clarifying my own preferences about programming, and some of CL's greatest strengths - extremely clever runtime meta-programming, CLOS, etc - are not actually things I want to work with in a code base at scale.I also think the UX for CL, outside the commercial Lisps, is pretty grim. CL would greatly benefit from a rustup-cargo-like system with good dep management and sane beginner defaults, like wrapping the SBCL REPL in rlwrap. Haskell is more beginner friendly than CL right now, and that's quite the indictment.\n \nreply",
      ">God, Lisp...the core language isn't exactly that interesting in this day-and-age. Dynamic typing, garbage collection, anonymous functions, this has been the bread-and-butter of Python, JS, Ruby, etc.CL still got symbols, the reader (and its macros), gradual typing and user available runtime compilation (compile and compile-file).I find the core language itself near perfect (mostly the historic stuff like threads/atomics/unicode missing, the whole divide between normal CL and CLOS and lack of recursive and parametric typing\") but the standard library quite baroque and lacking; still infinitely more serviceable than C's, though.\n \nreply",
      "Give Janet a try, it's a breath of fresh air with well-realized primitives and a solid standard library. For a decade now I've been immersed in the worlds of Clojure and Nim, where macros often get abused to no end. I've written 0 Nim macros, and a number of Lisp macros I could count on one hand.\n \nreply",
      "> I got to see first-hand that notions like function calling, sequential processing, and boolean logic are not intuitiveIt was a very long time since I first learned programming.It was QBasic first I think.It was a very slow process that I had mostly forgotten.It took me a very long time to grasp what's now very basic control flow.But I was like 7 or 10.I remember feeling like \"this is pure magic!\" so many times so very early on.Part of what I want to do is rekindle that like pico8 did for me. Somehow.\n \nreply",
      "The problem with using objects and structs in Common Lisp is the verbosity of access, or of setting up shorter access using with-slots and with-accessors.I fixed that in TXR Lisp:  (defun time-to-move (from-pos to-pos)\n     (max (time-to-rotate from-pos.azimuth to-pos.azimuth)\n          (time-to-ascend from-pos.elevation to-pos.elevation)))\n\nThe remaining issues are self-inflicted verbose naming. I would make it  ;; time to move\n  (defun ttm (p0 p1)\n    (max (ttr p0.az p1.az)\n         (tta p0.el p1.el)))\n\n\nIf the entire program fits on a few pages, you can remember a few abbreviations.The dot notation is a syntactic sugar for certain S-exps:  a.b.(c x y).d   ->   (qref a b (c x y) d)\n\n  .a.b.c          ->   (uref a b c)\n\nthere exist macros by these names which take care of the rest.Starting in TXR 300, there can be whitespace after the dot. So while you cannot write in in the popular way:  obj\n  .(meth arg)\n  .(next-meth 42)\n\nyou can do it like this:  obj.\n  (meth arg).\n  (next-meth 42)\n\nthis has a lot do with Lisp already having a consing dot.Lisp doesn't mean being against all syntactic sugars; e.g. we mostly write 'X rather than (quote 'X).But note that even if we don't have this notation, how the author has tripped over himself to create verbosity. After two nestings of with-accessors he ends up with:  (time-to-rotate from-az to-az) (time-to-ascend from-el to-el)\n\nHere from-az is not a whole lot shorter than (az from)!  If he used shorter names like el and az, he would have:  (defun time-to-move (from to)\n    (max (time-to-rotate (az p0) (az p1))\n         (time-to-ascend (el p0) (el l1))))\n\nDon't make names for yourself that you then have to shorten with clumsy macros that make the function longer overall.Another thing is, why does time-to-move take two objects? But time-to-rotate and time-to-ascend work with destructured azimuths and elevations?  (defun time-to-move (from to)\n    (max (time-to-rotate from to)\n         (time-to-ascend from to)))\n\nTime to rote and time to ascend could be inseparable. If the device is mounted on an incline, the time to ascend may depend on the azimuth. It may be better to rotate it first than elevate or vice versa, or execute some optimal combined motion.The moment of inertia of the thing may depend on its elevation; it may be easier to rotate in a high elevation. So just time-to-rotate alone needs the whole object.\n \nreply",
      "2011\n \nreply",
      "Smalltalk used to have left arrow for assignment like I see in the Haskell here.It's a lot prettier than :=\n \nreply"
    ],
    "link": "https://storytotell.org/smalltalk-haskell-and-lisp",
    "first_paragraph": "To assist with job interviews at the NRAO we recently wrote a small \u201ccontest\u201d program. Without giving away the details, the crux of the problem is to read a file with a list of scans and calculate the amount of time it takes to move the dishes and perform the scans, and report it. Candidates are required to write this in Java, but that restriction does not apply to me, so I of course had to write it in three languages that are not Java: Haskell, Common Lisp and Smalltalk.I expect to learn something, or at least reinforce an existing fact, by doing these sorts of language games, but this time I really wasn\u2019t expecting what I found. I discovered that my enjoyment of Haskell is pretty much independent of Haskell\u2019s appropriateness or usability. In fact, it is more attributable to the way I feel when using it, in contrast to everything else. Let me show you a piece of code:Somehow, the other languages I\u2019ve used to implement this problem never arrived at a piece of code quite this beautiful."
  },
  {
    "title": "Series C and scale (cursor.com)",
    "points": 52,
    "submitter": "fidotron",
    "submit_time": "2025-06-06T17:18:08 1749230288",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=44203003",
    "comments": [
      "That's quite a war chest to raise in such a short period of time. The market has concentrated with the couple of recent acquisitions. Sounds like likely uses of that cash are- Buy a few million more users with more generous free tier, as models get cheaper the cost to acquire the marginal customer goes down over time anyway- Build your own foundation model for coding. tbh I'm skeptical that a company can do this better than the Big 3 AI cos.- Go to war over enterprise. Do a deal with Deloitte/Accenture and get every single one of their consultants spending 8hrs a day in Cursor. Another flavor: compete head-on with Accenture by making your own service firm that undercuts them and delivers ahead of schedule for once.\n \nreply",
      "> Go to war over enterprise ... consultants spending 8hrs a day in Cursor.And students. Sun's Java push, especially its proliferation as \"object-oriented programming language\" in CS courses world-wide, might offer a lesson or two.\n \nreply",
      "Students aren\u2019t a market though. Sun and Java was really just marketing to future users\n \nreply",
      "Isn\u2019t marketing basically spending money now that will result in revenue later?\n \nreply",
      "Future market?\n \nreply",
      "Java only became Java because of enterprise. Getting students to use it was just an exercise in soft power.\n \nreply",
      "Wow only a 21.6x rev multiple. The others a month ago were 75x for windsurf acquisition by OpenAI and a 45x on cursors $200M raise at $9B val.Separately, has anyone gotten through to cursor support? They sent me a welcome email asking for feedback but when I responded nobody answered back.Edit: added old financing info.\n \nreply",
      "I've gotten an AI generated email back when I asked for support, which did seem to understand my request at a surface level, but was not actually helpful. That's the extent of support I've received from cursor.\n \nreply",
      "And let's not forget PLTR still hovering just over 100x revenue multiple.\n \nreply",
      "They probably aren't wanting for cash so I wonder why they did this. Maybe a lot of it was secondary sales?\n \nreply"
    ],
    "link": "https://www.cursor.com/en/blog/series-c",
    "first_paragraph": "Series C and ScaleWe've raised $900m to push the frontier of AI coding research.Posted By Anysphere Team1 minutes readToday, we're announcing new funding to improve Cursor, $900 million at a $9.9 billion valuation from Thrive, Accel, Andressen Horowitz, and DST.We're also happy to share that Cursor has grown to over $500 million in ARR and is used by over half of the Fortune 500, including NVIDIA, Uber, and Adobe.This scale will help us push the frontier of AI coding research.We started Anysphere, the lab behind Cursor, to build a better way to code. We're excited that many of the pieces are in place for us to execute on this.\u00a9 2025 Made by AnysphereProductPricingFeaturesEnterpriseDownloadsStudentsResourcesDocsBlogForumChangelogCompanyAnysphereCareersCommunityCustomersLegalTermsSecurityPrivacySOC 2 Certified\u00a9 2025 Made by AnysphereSOC 2 Certified"
  },
  {
    "title": "Meta: Shut down your invasive AI Discover feed (mozillafoundation.org)",
    "points": 432,
    "submitter": "speckx",
    "submit_time": "2025-06-06T15:33:10 1749223990",
    "num_comments": 187,
    "comments_url": "https://news.ycombinator.com/item?id=44201872",
    "comments": [
      "Context:- \u201cMeta has a new stand-alone AI app. It lets you see what other people are asking.\u201d https://www.businessinsider.com/meta-ai-app-public-feed-warn... (may 2025)- \u201cPeople are seemingly accidentally publishing their AI chat histories with Meta\u2019s new AI app\u201d https://www.crikey.com.au/2025/05/05/meta-ai-chatbot-discove... (may 2025)Note that the first link states that conversations are private by default and that user error is likely involved[1]. Mozilla\u2019s use of text emphasis almost implies otherwise[2].[1]: \u201cTo be clear, your AI chats are not public by default \u2014 you have to choose to share them individually by tapping a share button. Even so, I get the sense that some people don't really understand what they're sharing, or what's going on.\u201d[2]: At least that\u2019s how I understood \u201c_Make all AI interactions private by default_ with no public sharing option unless explicitly enabled through informed consent.\u201d at first glance.\n \nreply",
      "I'm not sure about this specific situation, but from Google Docs to ChatGPT to Notion, there's a clear distinction between \"make this a shareable link to only those who have the link\" and \"also make that shareable link searchable/discoverable by the public.\"If Meta is turning that \"searchability/discoverability\" on by default when a share button is activated on an AI chat - or worse, if they're not even giving this industry-standard option - that would both explain the confusion, and be a terribly unexpected dark pattern. As the parent notes, the activation of a share icon is not informed consent.\n \nreply",
      "I did a test in the app, and it is pretty obvious you are posting the chat.  You click share, then you are given a preview, and you have to hit post to actually post it publicly.\n \nreply",
      "And then does it ask who you want to post it to, or to which app? Because that's a fairly common pattern when I \"share\" something on my phone.Or does it just post it onto the public feed?\n \nreply",
      "There\u2019s a chance you\u2019re overestimating a large percentage of the public.\n \nreply",
      "Then should publishing always be disallowed on all platforms? I\u2019m having trouble understanding how is what Facebook is doing any different from ChatGPT, and in general all web apps.\n \nreply",
      "ChatGPT sharing is anonymous + you are also having to share the link itself, it doesn't randomly go to other people's feeds.\n \nreply",
      "Life is tough, but it\u2019s tougher if you\u2019re stupid.\n \nreply",
      "If a part of the population is dumb, the issue is that it\u2019s dumb, not meta user interface.I\u2019m the first to bash on meta but there are things that they are not responsible for.\n \nreply",
      "I don't think that is the case with ChatGPT: https://www.vice.com/en/article/chatgpt-users-report-being-a...\n \nreply"
    ],
    "link": "https://www.mozillafoundation.org/en/campaigns/meta-shut-down-your-invasive-ai-discover-feed-now/",
    "first_paragraph": ""
  },
  {
    "title": "Workhorse LLMs: Why Open Source Models Dominate Closed Source for Batch Tasks (sutro.sh)",
    "points": 36,
    "submitter": "cmogni1",
    "submit_time": "2025-06-06T18:38:36 1749235116",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44203732",
    "comments": [
      "Pass the choices through, please. It's so context dependent that I want a <dumber> and a <smarter> button, with units of $/M tokens. And another setting to send a particular prompt to \"[x] batch\" and email me with the answer later. For most things I'll start dumb and fast, but switch to smart and slow when the going gets rough.\n \nreply",
      "Flash is just so obscenely cheap at this point it's hard to justify the headache of self hosting though. Really only applies to sensitive data IMO.\n \nreply",
      "With tools like Ollama, self-hosting is easier than hosted.  No sign-up, no API keys, no permission to spend money, no worries about data security, just an easy install then import a Python library.  Qwen2.5-VL 7B is proving useful even on a work laptop with insufficient VRAM - I just leave it running over a night or weekend and it's saving me dozens of hours of work (that I then get to spend on other higher-value work).\n \nreply",
      "I got the 70b qwen llama distill, I have 24GB of vram.I opened aider and gave a small prompt, roughly:  Implement a JavaScript 2048 game that exists as flat file(s) and does not require a server, just the game HTML, CSS, and js. Make it compatible with firefox, at least.\n\nThat's it. Several hours later, it finished. The game ran. It was worth it because this was in the winter and it heated my house a bit, yay. I think the resulting 1-shot output is on my github.I know it was in the training set, etc, but I wanted to see how big of a hassle it was, if it would 1-shot with such a small prompt, how long it would take.Makes me want to try deepseek 671B, but I don't have any machines with >1TB of memory.I do take donations of hardware.\n \nreply",
      "It does not take dozens of hours to get an API key for gemini\n \nreply",
      "I never claimed that it did.  Gemini would probably save me the same dozens of hours, but come with ongoing costs and additional starting up hurdles (some near insurmountable in my organisation, like data security for some of what I'm doing).\n \nreply",
      "Gemini flash or any free LLM on openrouter would be orders of magnitude faster and effectively free.  Unless you are concerned about privacy of the conversation - it's really purely being able to say you did it locally.I definitely do appreciate and believe in the value of open source / open weight LLMs - but inference is so cheap right now for non frontier models.\n \nreply",
      "That's true for Flash 2.0 at $0.40/mtok output. GPT-4.1-nano is the same price and also surprisingly capable.  I can spend real money with 2.5 flash, with those $3.50/mtok thinking tokens, worth it though. OP is an inference provider, so there may be some bias.  Open source can't compete on context length either, nothing touches 2.5 flash for the price with long context--I've experimented with this a lot for my agentic pricing system.  Open source models are improving, but they aren't really any cheaper right now, R1 for example does quite well performance wise, but it uses a LOT of tokens to get there, further limiting the shorter context window. There's still value in the open source models, each model has unique strengths and they're advancing quickly, but the frontier labs are moving fast too and have very compelling \"workhorse\" offers.\n \nreply",
      "You're getting downvoted but what you said is true. The cost of self-hosting (and achieving +70 tok/sec consistently across the entire context window) has never been low enough to justify open source as a viable competitor to proprietary models of OpenAI, Google, and Anthropic.\n \nreply",
      "I am curious the need for 70 t/sec?\n \nreply"
    ],
    "link": "https://sutro.sh/blog/workhorse-llms-why-open-source-models-win-for-batch-tasks",
    "first_paragraph": "PricingDocumentationBlogGet Access<- Back to blogSutro TeamJun 6, 2025As LLMs become more prolific, we\u2019ve noticed that teams still reach for closed sourced models like GPT, Claude, and Gemini for nearly every task. While this may have been the right call a year ago, teams today are unknowingly missing out on huge cost savings and performance gains by not considering open source alternatives.It is true that at the frontier of intelligence, the most powerful closed source LLMs dominate their open source counterparts. However, many common tasks for LLMs don\u2019t require PhD level reasoning. Instead, they require a workhorse LLM: something that\u2019s reliable for low-to-medium difficulty tasks \u2013 things like classification, summarization, and data extraction.Not only are there suitable replacements for closed source workhorses like GPT-4o-mini, but the equivalent replacements are often less expensive and more intelligent. When latency isn\u2019t an issue, open source models have an even larger edge for"
  }
]