[
  {
    "title": "Qwen3: Think deeper, act faster (qwenlm.github.io)",
    "points": 352,
    "submitter": "synthwave",
    "submit_time": "2025-04-28T20:44:25 1745873065",
    "num_comments": 128,
    "comments_url": "https://news.ycombinator.com/item?id=43825900",
    "comments": [
      "I have a small physics-based problem I pose to LLMs. It's tricky for humans as well, and all LLMs I've tried (GPT o3, Claude 3.7, Gemini 2.5 Pro) fail to answer correctly. If I ask them to explain their answer, they do get it eventually, but none get it right the first time. Qwen3 with max thinking got it even more wrong than the rest, for what it's worth.\n \nreply",
      "You really had me until the last half of the last sentence.\n \nreply",
      "The plural of anecdote is data.\n \nreply",
      "The plural of reliable data is not anecdote.\n \nreply",
      "https://en.wikipedia.org/wiki/Thought-terminating_cliche\n \nreply",
      "Only in the same way that the plural of 'opinion' is 'fact' ;)\n \nreply",
      "Except, very literally, data is a collection of single points (ie what we call \"anecdotes\").\n \nreply",
      "Except that the plural of anecdotes is definitely not data, because without controlling for confounding variables and sampling biases, you will get garbage.\n \nreply",
      "No, Wittgenstein's rule following paradox, Shannon sampling theorem, the law that infinite polynomials pass through any finite set of points (does that have a name?), etc, etc. are all equivalent at the limit to the idea that no amount of anecdotes-per-se add up to anything other than coincidence\n \nreply",
      "Can you please share the problem?\n \nreply"
    ],
    "link": "https://qwenlm.github.io/blog/qwen3/",
    "first_paragraph": "QWEN CHAT\nGitHub\nHugging Face\nModelScope\nKaggle\nDEMO\nDISCORDToday, we are excited to announce the release of Qwen3, the latest addition to the Qwen family of large language models. Our flagship model, Qwen3-235B-A22B, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, Qwen3-30B-A3B, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.We are open-weighting two MoE models: Qwen3-235B-A22B, a large model with 235 billion total parameters and 22 billion activated parameters, and Qwen3-30B-A3B, a smaller MoE model with 30 billion total parameters and 3 billion activated parameters. Additionally, six dense models are also open-weighted, including Qwen3-32B, Qwen3-14B, Qwen3-8B, Qwen3-4B, Qwen3-1.7B, and Qwen3-0.6B, unde"
  },
  {
    "title": "The 12-bit rainbow palette (iamkate.com)",
    "points": 78,
    "submitter": "rguiscard",
    "submit_time": "2025-04-28T23:12:28 1745881948",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=43827108",
    "comments": [
      "Beautiful palette!CSS recently has been adding way more color features, here's the palette represented in oklch:    #817 \u2192 oklch(0.44 0.1815   335.38)\n    #a35 \u2192 oklch(0.51 0.1559     7.49)\n    #c66 \u2192 oklch(0.63 0.1298    21.44)\n    #e94 \u2192 oklch(0.75 0.1415    62.42)\n    #ed0 \u2192 oklch(0.88 0.18646  103.9148)\n    #9d5 \u2192 oklch(0.82 0.181    131.77)\n    #4d8 \u2192 oklch(0.80 0.1757   154.39)\n    #2cb \u2192 oklch(0.76 0.1298   184.05)\n    #0bc \u2192 oklch(0.72 0.123861 206.321)\n    #09c \u2192 oklch(0.64 0.129199 231.0549)\n    #36b \u2192 oklch(0.52 0.1448   260.03)\n    #639 \u2192 oklch(0.44 0.1603   303.37)\n\nYou can see the lightness and chroma moving within a narrow range as it sweeps the hue. These new color space functions make making palettes like this way easier.\n \nreply",
      "Whats the deal with oklch? My naive reaction was a that it sucks to define colors in a way you can\u2019t easily reason about or need and external tool to make.\n \nreply",
      "Previous discussion and an excellent link here: https://news.ycombinator.com/item?id=43073819OKLCH is really easy to work with. Once you have your palette it's easy to get correct shades and hues by tweaking some values. This works great with CSS custom properties.\n \nreply",
      "This is the first I've heard of oklch. Here's the perspective of somebody who writes a lot of shaders: It looks similar to Hue/saturation/value encoding, which as tons of uses, but with saturation replaced with \"chroma\" where it seems to nonlinearly adjust saturation probably based on some perceptual study that makes it extra spicy and high science.\n \nreply",
      "The deal with Oklch is that hsl/hsb don\u2019t do a good lightness mapping regarding color perception, but Oklch does. So, if you transform your RGB to lch and move the \u201cl\u201d value, you can easily get a nicer color palette. Also, you can tell the lightness of two colors by looking at the \u201cl\u201d value; that\u2019s not true for hsl/hsb. That\u2019s useful if you want lightness contrast or different hues with a similar lightness.Other than that, I agree that \u201cchroma\u201d is hard to reason about. But, at least it is easier to reason than the \u201ca\u201d/\u201cb\u201d parameters in \u201clab\u201d.\n \nreply",
      "L is for lightness (0-100%), C is for chroma (0-0.5), H is for hue (0-360deg).Lightness dictates how white or black a color is, chroma dictates how saturated it is, and hue is which angle on the color wheel it occupies. Varying these one at a time lets you intuitively pick colors that are close to one another in the space of human perception. And CIE Lab colors are especially nice because they cover more than the sRGB gamut that we're all used to defining with HSL or RGB, so you can really make the most of your fancy wide color gamut monitor.\n \nreply",
      "oklch and oklab are much easier to reason about than alternatives. For oklch, The first parameter is the lightness, the second is the chroma (essentially its saturation), and the 3rd is the hue. I find it very easy to tweak colors by making them brighter or more saturated. Unlike lch, such changes in oklch have regular effects on how the color will be percieved.This page has more information: https://evilmartians.com/chronicles/oklch-in-css-why-quit-rg...\n \nreply",
      "The win is working with lightness and contrast. For example, once you have a palette, making it a bit lighter is easy.The loss is no longer having any intuition about what a color is just by seeing the numbers.\n \nreply",
      "Why is 12 bits 4 characters? Shouldn't it be 3 hexadecimal digits (as shown on the website), since each digit is 4 bits?\n \nreply",
      "Fun exercise in constraints, but why limit yourself to 12 bit color? Was this a technical requirement?\n \nreply"
    ],
    "link": "https://iamkate.com/data/12-bit-rainbow/",
    "first_paragraph": ""
  },
  {
    "title": "Widespread power outage in Spain and Portugal (bbc.com)",
    "points": 1209,
    "submitter": "lleims",
    "submit_time": "2025-04-28T10:50:58 1745837458",
    "num_comments": 893,
    "comments_url": "https://news.ycombinator.com/item?id=43819791",
    "comments": [
      "This sounds big enough to require a black start. Unfortunately, those are slow and difficult.If an entire nation trips offline then every generator station disconnects itself from the grid and the grid itself snaps apart into islands. To bring it back you have to disconnect consumer loads and then re-energize a small set of plants that have dedicated black start capability. Thermal plants require energy to start up and renewables require external sources of inertia for frequency stabilization, so this usually requires turning on a small diesel generator that creates enough power to bootstrap a bigger generator and so on up until there's enough electricity to start the plant itself. With that back online the power from it can be used to re-energize other plants that lack black start capability in a chain until you have a series of isolated islands. Those islands then have to be synchronized and reconnected, whilst simultaneously bringing load online in large blocks.The whole thing is planned for, but you can't really rehearse for it. During a black start the grid is highly unstable. If something goes wrong then it can trip out again during the restart, sending you back to the beginning. It's especially likely if the original blackout caused undetected equipment damage, or if it was caused by such damage.In the UK contingency planning assumes a black start could take up to 72 hours, although if things go well it would be faster. It's one reason it's a good idea to always have some cash at home.Edit: There's a press release about a 2016 black start drill in Spain/Portugal here: https://www.ree.es/en/press-office/press-release/2016/11/spa... \n \nreply",
      "In another life I worked as an engineer commissioning oil rigs and I\u2019ve seen how tricky even a small-scale black start can be. On a rig, we simulate total power loss and have to hand-crank a tiny air compressor just to start a small emergency generator, which then powers the compressors needed to fire up the big ~7MW main generators. It's a delicate chain reaction \u2014 and that's just for one isolated platform.A full grid black start is orders of magnitude more complex. You\u2019re not just reviving one machine \u2014 you\u2019re trying to bring back entire islands of infrastructure, synchronize them perfectly, and pray nothing trips out along the way. Watching a rig wake up is impressive. Restarting a whole country\u2019s grid is heroic.\n \nreply",
      "I remember talking to my ex's dad about his job, which involved planning refuels of a large nuclear-powered generation station in the Lower Midwest.The words \"it's a miracle it works at all\" routinely popped up in those conversations, which is... something you don't want to hear about any sort of power generation - especially not nuclear - but it's true. It's a system basically built to produce \"common accidents\". It's amazing that it doesn't on a regular basis.\n \nreply",
      "> The words \"it's a miracle it works at all\" routinely popped up in those conversations, which is... something you don't want to hear about any sort of power generation - especially not nuclear - but it's true.Funny thing is, those are the exact words I use when talking to people about networking. And realistically anytime I dig deep into the underlying details of any big enough system I walk away with that impression. At scale, I think any system is less \u201ccontrolled and planned precision\u201d and more \u201charnessed chaos with a lot of resiliency to the unpredictability of that chaos\u201d\n \nreply",
      "This is one of the key insights in my early SRE career that changed how I viewed software engineering at scale.Components aren\u2019t reliable. The whole thing might be duct tape and popsicle sticks. But the trick for SRE work is to create stability from unreliable components by isolating and routing around failures.It\u2019s part of what made chaos engineering so effective. From randomly slowing down disk/network speed to unplugging server racks to making entire datacenters go dark - you intentionally introduce all sorts of crazy failure modes to intentionally break things and make sure the system remains metastable.\n \nreply",
      "Message on a mug: \"if carpenters built houses the way programmers write software, a woodpecker could destroy civilization.\"The syncronasation of a power grid ... Wow.\n \nreply",
      "> those are the exact words I use when talking to people about networkingOr the U.S. financial system.  Or civilization in general.\n \nreply",
      "It ultimately comes down to shared norms, shared expectations, and trust.\n \nreply",
      "Which is why the long tail impact of current times is frankly terrifying.\n \nreply",
      "\"Funny thing is, those are the exact words I use when talking to people about networking\"Computer networking is not the same.  Our networks will not explode.  I will grant you that they can be shite if not designed properly but they end up running slowly or not at all, but it will not combust nor explode.If you get the basics right for ethernet then it works rather well as a massive network.  You could describe it as an internetwork.Basically, keep your layer 1 to around 200 odd maximum devices per VLAN - that works fine for IPv4.  You might have to tune MAC tables for IPv6 for obvious reasons.Your fancier switches will have some funky memory for tables of one address to other address translation eg MAC to IP n VLAN and that.  That memory will be shared with other databases too, perhaps iSCSI, so you have to decide how to manage that lot.\n \nreply"
    ],
    "link": "https://www.bbc.com/news/live/c9wpq8xrvd9t",
    "first_paragraph": "Cause Of Massive Power Cut In Spain And Portugal Still UnknownBBC NewsThis video can not be playedSpain has declared a state of emergency after a massive power cut hit large parts of the country and Portugal, causing widespread disruptionMore than half of Spain's power has been restored, Prime Minister Pedro S\u00e1nchez says, but authorities have not yet established why the outage occurredThere was \"no indication\" that the power cut was caused by a cyber attack, the Portuguese Prime Minister Lu\u00eds Montenegro, saidPeople report driving to find open petrol stations, teaching in the dark - and drinking beers by candlelightThe authorities are trying to project an air of calm but they've increased deployments of security forces and are calling on people to limit their mobile phone use, writes the BBC's Europe regional editorAre you affected? Email: bbcyourvoice@bbc.co.uk, external or WhatsApp +44 7756 165803This video can not be playedWatch: Traffic chaos as Spain and Portugal face power outages"
  },
  {
    "title": "Show HN: I built a hardware processor that runs Python (runpyxl.com)",
    "points": 826,
    "submitter": "hwpythonner",
    "submit_time": "2025-04-28T11:44:54 1745840694",
    "num_comments": 224,
    "comments_url": "https://news.ycombinator.com/item?id=43820228",
    "comments": [
      "This is a very cool project but I feel like the claim is overstated: \"PyXL is a custom hardware processor that executes Python directly \u2014 no interpreter, no JIT, and no tricks. It takes regular Python code and runs it in silicon.\"Reading further down the page it says you have to compile the python code using CPython, then generate binary code for its custom ISA. That's neat, but it doesn't \"execute python directly\" - it runs compiled binaries just like any other CPU. You'd use the same process to compile for x86, for example. It certainly doesn't \"take regular python code and run it in silicon\" as claimed.A more realistic claim would be \"A processor with a custom architecture designed to support python\".\n \nreply",
      "Are there any limitations on what code can run? (discounting e.g. memory limitations and OS interaction)I'd love to read about the design process. I think the idea of taking bytecode aimed at the runtime of dynamic languages like Python or Ruby or even Lisp or Java and making custom processors for that is awesome and (recently) under-explored.I'd be very interested to know why you chose to stay this, why it was a good idea, and how you went about the implementation (in broad strokes if necessary).\n \nreply",
      "Thanks \u2014 really appreciate the interest!There are definitely some limitations beyond just memory or OS interaction.\nRight now, PyXL supports a subset of real Python. Many features from CPython are not implemented yet \u2014 this early version is mainly to show that it's possible to run Python efficiently in hardware.\nI'd prefer to move forward based on clear use cases, rather than trying to reimplement everything blindly.Also, some features (like heavy runtime reflection, dynamic loading, etc.) would probably never be supported, at least not in the traditional way, because the focus is on embedded and real-time applications.As for the design process \u2014 I\u2019d love to share more!\nI'm a bit overwhelmed at the moment preparing for PyCon, but I plan to post a more detailed blog post about the design and philosophy on my website after the conference.\n \nreply",
      "In terms of a feature-set to target, would it make sense to be going after RPython instead of \"real\" Python? Doing that would let you leverage all the work that PyPy has done on separating what are the essential primitives required to make a Python vs what are the sugar and abstractions that make it familiar:https://doc.pypy.org/en/latest/faq.html#what-is-pypy\n \nreply",
      "> I'd prefer to move forward based on clear use casesTaking the concrete example of the `struct` module as a use-case, I'm curious if you have a plan for it and similar modules. The tricky part of course is that it is implemented in C.Would you have to rewrite those stdlib modules in pure python?\n \nreply",
      "As in my sibling comment, pypy has already done all this work.CPython's struct module is just a shim importing the C implementations: https://github.com/python/cpython/blob/main/Lib/struct.pyPypy's is a Python(-ish) implementation, leveraging primitives from its own rlib and pypy.interpreter spaces: https://github.com/pypy/pypy/blob/main/pypy/module/struct/in...The Python stdlib has enormous surface area, and of course it's also a moving target.\n \nreply",
      "Aah, neat! Yeah, piggy-backing off pypy's work here would probably make the most sense.It'll also be interesting to see how OP deals with things like dictionaries and lists.\n \nreply",
      "There were a few chips that supported directly executing JVM bytecodes.  I'm not sure why it didn't take off, but I think it is generally more performant to JIT compile hotspots to native code.https://en.wikipedia.org/wiki/Java_processor\n \nreply",
      "Forth CPU (in SystemVerilog): https://www.youtube.com/watch?v=DRtSSI_4dvk\n \nreply",
      "JVM I think I can understand, but do you happen to know more about LISP machines and whether they use an ISA specifically optimized for the language, or if the compilers for x86 end up just doing the same thing?In general I think the practical result is that x86 is like democracy. It\u2019s not always efficient but there are other factors that make it the best choice.\n \nreply"
    ],
    "link": "https://www.runpyxl.com/gpio",
    "first_paragraph": "Python, in hardware. 480ns GPIO. No interpreter. No C. Just PyXL.PyXL is a custom hardware processor that executes Python directly \u2014 no interpreter, no JIT, and no tricks. It takes regular Python code and runs it in silicon.A custom toolchain compiles a .py file into CPython ByteCode, translates it to a custom assembly, and produces a binary that runs on a pipelined processor built from scratch.It's a real processor for Python, built for determinism and speed.PyXL runs on a Zynq-7000 FPGA (Arty-Z7-20 dev board). The PyXL core runs at 100MHz. The ARM CPU on the board handles setup and memory, but the Python code itself is executed entirely in hardware.The toolchain is written in Python and runs on a standard development machine using unmodified CPython.\n        GPIO stands for General Purpose Input/Output. It\u2019s a simple hardware pin that software can read from or write to \u2014 a way to control the outside world: LEDs, buttons, sensors, motors, and more.\n      \n        In MicroPython (like "
  },
  {
    "title": "The One-Person Framework in Practice (mail.beehiiv.com)",
    "points": 44,
    "submitter": "frans",
    "submit_time": "2025-04-28T21:58:52 1745877532",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=43826584",
    "comments": [
      "Is there any other framework which can claim that it compares well to Ruby on Rails speed of development? I.e. conventions over configurations? Asking as I don\u2019t want to learn ruby\n \nreply",
      "It's niche, but check out https://www.boxlang.io/ and https://www.lucee.org/ on the JVM. They're rock solid runtimes. I single handedly manage multiple production applications going on 10+ years. They essentially never break, never need major maintenance. Backwards compatibility is great. The runtimes are very batteries included in terms of backend web development.\n \nreply",
      "I\u2019m curious if .NET can compare here, though I have limited experience with rails or ASP.NET both seem to give you a lot to work with. Though the overlap of rails devs with .NET devs seems minimal.\n \nreply",
      "I\u2019ve been asking this question for a while since I love Rails but I don\u2019t like Ruby that much. \nI think only Django comes close, although I haven\u2019t tried it, but I dislike Python much more than Ruby.There are always attempts in every language to replicate the convention over configuration and batteries included approach of Rails, but they all lose steam pretty quickly.I just don\u2019t think there is an alternative to Rails. It\u2019s a giant project that is actively developed for over 2 decades now.\n \nreply",
      "I used to code ruby. Now in python land and am using flask. Theres conventions but no scaffolding. Ai code tools make the scaffolding feel redundant anyway.\n \nreply",
      "Possibly Laravel, but then you\u2019d have to learn PHP! :DAll jokes aside, having worked in both languages and frameworks, I\u2019ve enjoyed the Dev experience in either option.Grateful for both dev communities as well.\n \nreply",
      "Django is more or less Python's equivalent of Rails. Its admin panel is nice, especially for a solo developer trying to manage something they built in a weekend.\n \nreply",
      "I have heard Laravel is shockingly complete and most others will pale in comparison to in terms of out of the box speed to first feature and the full CI/CD setup for most any kind of product.Speed of iteration rules above all.\n \nreply",
      "Phoenix or Meteor.js\n \nreply",
      "Django is the closest I can think of.  Many unicorns built on Django.Both Rails and Django are horribly slow though, so once you get to some critical scale you gotta start doing some real weird stuff like Instagram did with turning off Python's GC [1], etc.[1] https://instagram-engineering.com/copy-on-write-friendly-pyt...\n \nreply"
    ],
    "link": "https://link.mail.beehiiv.com/ss/c/u001.5SRwDQ9qxPQW8vmD5Do73b3R4eTCi2vXqPyztEk6wMFC9_fqEAcDVx6xEJ96T4BSMXrPS7z5exEBSTF4pF48z8SqJkJnkAwMUW9LtYdd8lWmvkDinT92nsk5HmXOHdWgLsysm9FMGrqmu7dnG57cXpga8ZOe8X0IV8pyeC3AswdRMaitfT307y7naP-_6W5CiolKhXCKrEndMGCW2PftFUu9ieYOxpVJ_fhu82gAh-4/4g1/wA_MG-I5SVCyR3KY66oEaQ/h30/h001.kLDFZMgisudi21zmTPbd_O8U7X98d4UxYqZjQTb_D7o",
    "first_paragraph": ""
  },
  {
    "title": "One Million Chessboards (eieio.games)",
    "points": 108,
    "submitter": "chunkles",
    "submit_time": "2025-04-28T19:52:02 1745869922",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=43825336",
    "comments": [
      "Ah hello! I made this :)My blog describing it is pretty sparse, sorry about that. Happy to answer any questions that folks have about the architecture.Not that it was necessary, but I got really into building this out as a single process that could handle many (10k+/sec) moves for thousands of concurrent clients. I learned a whole lot! And I found golang to be a really good fit for this, since you mostly want to give tons and tons of threads concurrent access to a little bit of shared memory.\n \nreply",
      "If you don\u2019t mind explaining, I\u2019m curious how you test something like this before it goes live.  It seems like it would be hard to simulate all the things that could happen at scale.\n \nreply",
      "> The frontend optimistically applies all moves you make immediately. It then builds up a dependency graph of the moves you\u2019ve made, and backs them out if it receives a conflicting update before the server acks your move.The dependency graph is between pieces you\u2019re interacting with? Meaning if you move a queen and are trying to capture a pawn, and there\u2019s potentially a rook that can capture your queen, those 3 are involved in that calculation, and if you moved your queen but the rook also captures your queen at the same time one of them wins? How do you determine that?\n \nreply",
      "Ah yes good question! Here's some context for you. First off, the way moves work:(edit: I realized I didn't answer your question. If we receive a captured for a piece we're optimistically tracking that always takes precedence, since once a piece is captured it can't move anymore!)    * clients send a token with each move\n    * they either receive a cancel or accept for each token, depending on if the move is valid. If they receive an accept, it comes with the sequence number of the move (everything has a seqnum) and the ID of the piece they captured, if applicable\n    * clients receive batches of captures and moves. if a move captured a piece, it's guaranteed that that capture shows up in the same batch as the move\n\nSo when you make a move we:    * Write down all impacted squares for the move (2 most of the time, 4 if you castle)\n    * Write down its move token\n    * If you moved a piece that is already tracked optimistically from a prior not-yet-acked-or-canceled move, we note that dependency as well\n\nWe maintain this state separate from our ground truth from the server and overlay it on top.When we receive a new move, we compare it with our optimistic state. If the move occupies the same square as a piece that we've optimistically moved, we ask \"is it possible that we inadvertently captured this piece?\" That requires that the piece is of the opposite color and that we made a move that could have captured a piece (for example, if you moved a pawn up that is not a valid capturing move).If there's a conflict - if you moved a piece to a square that is now occupied by a piece of the same color, for example - we back out your optimistically applied move. We then look for any moves that depended on it - moves that touch the same squares or share the same move token (because you optimistically moved a piece twice before receiving a response).So concretely, imagine you have this state:    _ _ _ _\n    K B _ R\n\nYou move the bishop out of the way, and then you castle    _ _ B _\n    _ R K _\n\nThen a piece of the same color moves to where your bishop was! We notice that, revert the bishop move, notice that it used the same square as your castle, and revert that too.There's some more bookkeeping here. For example, we also have to track the IDs of the pieces that you moved (if you move a bishop and then we receive another move for the same bishop, that move takes precedence).Returning the captured piece ID from the server ack is essential, because we potentially simulate after-the-fact captures (you move a bishop to a square, a rook of the opposite color moves to that square, we decide you probably captured that rook and don't revert your move). We track that and when we receive our ack, compare that state with the ID of the piece we actually captured.I think that's most of it? It was a real headache but very satisfying once I got it working.\n \nreply",
      "> I use a single writer thread, tons of reader threads, and coordinate access to the board with a mutexOn this I found Go to be at the right balance of not having to worry about memory management yet having decent concurrency management primitives and decent performance (memory use is especially impressive). Also did a multiplayer single server Go app with pseudo realtime updates (long polling waiting for updates on related objects).\n \nreply",
      "Yes exactly!My goal with the board architecture was \"just be fast enough that I'm limited by serialization and syscalls for sending back to clients\" and go made that really easy to do; I spend a few hundred nanos holding the write lock and ~15k nanos holding the read lock (but obviously I can do that from many readers at once) and that was enough for me.I definitely have some qualms with it, but after this experience it's hard to imagine using something else for a backend with this shape.\n \nreply",
      "Someone barricaded their king with about 40 rooks, I hopped in with a knight, and they immediately captured me (with their king), then plugged the gap with another rook so I couldn't do it again. That was amusing lol.\n \nreply",
      "I was only able to move the black pieces.  And I was able to move black consecutively on the same board.  So I didn't fully understand.  Are the rules being enforced or is it just updates.I enjoyed the sc2 UI when selecting pieces\n \nreply",
      "I saw a black piece moving around very quickly. Is there a secret way to move without clicking twice?\n \nreply",
      "(Also submitted here: https://news.ycombinator.com/item?id=43822992)Neat, though I expected every individual board to have \"turns\" - I didn't expect that I could just pick a random board, liberate the black queen, and have her clean up every single white piece on the board without my \"opponent\" getting to do anything in return.\n \nreply"
    ],
    "link": "https://eieio.games/blog/one-million-chessboards/",
    "first_paragraph": ""
  },
  {
    "title": "Running Clojure in WASM with GraalVM (romanliutikov.com)",
    "points": 82,
    "submitter": "roman01la",
    "submit_time": "2025-04-27T07:50:07 1745740207",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=43810211",
    "comments": [
      "GraalVM is neat.I used it to make a program that logs all activity happening on the Pioneer CDJs. The best reverse engineering of the Pioneer protocols is a Java project, but I wanted to write the rest of my application in Go.GraalVM plus a GitHub action spits out native binaries that I can exec and interact with over stdio from Go.If/when the WASM backend supports UDP networking and threads I'd love to run it as WASM instead of a binary.- https://github.com/nzoschke/vizlink- https://github.com/nzoschke/vizlink/blob/main/.github/workfl...\n \nreply",
      "> Starting from v25 GraalVM added support for WASMGraalVM is so amazing technically, but gets so little love by HN.\n \nreply",
      "When I tried it it was great but also not easy to use. Things become hard quickly, e.g. If your jvm code uses something like reflection.\n \nreply",
      "Clojure code ends up using a lot of reflection if you're doing generic Java interop. Most code destined for the GraalVM will add `(set! warn-on-reflection true)` and get repl warnings and you can set type hints accordingly.\n \nreply",
      "I vaguely remember using it about 10 years ago for work, can't remember what for, or anything about that situation, but the one takeaway that I do remember is that it was neat and innovative, but ultimately not good enough to overthrow whatever we were using instead.\n \nreply",
      "The analysis of the benchmark is wrong. Native is faster than JVM for 2 out of 4 operations. The 2-3x vs 5-12x are hence not correct.\n \nreply",
      "> The output WASM of this simple program is 5.6MB binary, which can be pruned a bit via wasm-opt tool, just make sure that it doesn't break anything for you. Luckily when compressed (gzip, brotli, etc) the binary becomes just ~2.5MB in size.That\u2019s much better than I expected!  Very impressive work here.  It actually looks viable for certain applications.\n \nreply",
      "It's acceptable. Meanwhile 5.6MB of Wasm is about the size of the entire test suite of Scala.js. :-pGraalVM is excellent technology, but when it comes to targeting Wasm, I believe the core language compilers will always have an edge.\n \nreply",
      "Nice, I will revisit closure to try this out\n \nreply",
      "Clojure. ;)\n \nreply"
    ],
    "link": "https://romanliutikov.com/blog/running-clojure-in-wasm",
    "first_paragraph": ""
  },
  {
    "title": "Migrating away from Rust (deadmoney.gg)",
    "points": 397,
    "submitter": "rc00",
    "submit_time": "2025-04-28T18:47:36 1745866056",
    "num_comments": 353,
    "comments_url": "https://news.ycombinator.com/item?id=43824640",
    "comments": [
      "Another failed game project in Rust. This is sad.I've been writing a metaverse client in Rust for almost five years now, which is too long.[1]\nSomeone else set out to do something similar in C#/Unity and had something going in less than two years.\nThis is discouraging.Ecosystem problems:The Rust 3D game dev user base is tiny.Nobody ever wrote an AAA title in Rust. Nobody has really pushed the performance issues.\nI find myself having to break too much new ground, trying to get things to work that others doing first-person shooters should have solved years ago.The lower levels are buggy and have a lot of churnThe stack I use is Rend3/Egui/Winit/Wgpu/Vulkan. Except for Vulkan, they've all had hard to find bugs.\nThere just aren't enough users to wring out the bugs.Also, too many different crates want to own the event loop.These crates also get \"refactored\" every few months, with breaking API changes, which breaks the stack for months at a time until everyone gets back in sync.Language problems:Back-references are difficultA owns B, and B can find A, is a frequently needed pattern, and one that's hard to do in Rust. It can be done with Rc and Arc, but it's a bit unwieldy to set up and adds run-time overhead.There are three common workarounds:- Architect the data structures so that you don't need back-references. This is a clean solution but is hard. Sometimes it won't work at all.- Put everything in a Vec and use indices as references. This has most of the problems of raw pointers, except that you can't get memory corruption outside the Vec. You lose most of Rust's safety. When I've had to chase down difficult bugs in crates written by others, three times it's been due to errors in this workaround.- Use \"unsafe\". Usually bad. On the two occasions I've had to use a debugger on Rust code, it's been because someone used \"unsafe\" and botched it.Rust needs a coherent way to do single owner with back references. I've made some proposals on this, but they require much more checking machinery at compile time and better design. Basic concept: works like \"Rc::Weak\" and \"upgrade\", with compile time checking for overlapping upgrade scopes to insure no \"upgrade\" ever fails.\"Is-a\" relationships are difficultRust traits are not objects. Traits cannot have associated data. Nor are they a good mechanism for constructing object hierarchies. People keep trying to do that, though, and the results are ugly.[1] https://www.animats.com/sharpview/index.html\n \nreply",
      "A owns B, and B can find AI think you should think less like Java/C# and more like database.If you have a Comment object that has parent object, you need to store the parent as a 'reference', because you can't put the entire parent.So I'll probably use Box here to refer to the parent\n \nreply",
      "I saw a good talk, though I don't remember the name, that went over the array-index approach. It correctly pointed out that by then, you're basically recreating your own pointers without any of the guarantees rust, or even C++ smart pointers, provide.\n \nreply",
      "But Unity game objects are the same way: you allocate them when they spawn into the scene, and you deallocate them when they despawn. Accessing them after you destroyed them throws an exception. This is exactly the same as entity IDs! The GC doesn't buy you much, other than memory safety, which you can get in other ways (e.g. generational indices, like Bevy does).\n \nreply",
      "But in rust you have to fight the borrow checker a lot, and sometimes concede, with complex referential stuff. I say this as someone who writes a good bit of rust and enjoys doing so.\n \nreply",
      "I just don't, and even less often with game logic which tends to be rather simple in terms of the data structures needed. In my experience, the ownership and borrowing rules are in no way an impediment to game development. That doesn't invalidate your experience, of course, but it doesn't match mine.\n \nreply",
      "The dependency injection framework provided by Bevy also particularly elides a lot of the problems with borrow checking that users might run into and encourages writing data oriented code that generally is favorable to borrow checking anyway.\n \nreply",
      "This is a valid point. I've played a little with Bevy and liked it. I have also not written a triple-A game in Rust, with any engine, but I'm extrapolating the mess that might show up once you have to start using lots of other libraries; Bevy isn't really a batteries-included engine so this probably becomes necessary. Doubly so if e.g. you generate bindings to the C++ physics library you've already licensed and work with.These are all solvable problems, but in reality, it's very hard to write a good business case for being the one to solve them. Most of the cost accrues to you and most of the benefit to the commons. Unless a corporate actor decides to write a major new engine in Rust or use Bevy as the base for the same, or unless a whole lot of indie devs and part-time hackers arduously work all this out, it's not worth the trouble if you're approaching it from the perspective of a studio with severe limitations on both funding and time.",
      "Thankfully my studio has given me time to be able to submit a lot of upstream code to Bevy. I do agree that there's a bootstrapping problem here and I'm glad that I'm in a situation where I can help out. I'm not the only one; there are a handful of startups and small studios that are doing the same.",
      "Given my experience with Bevy this doesn't happen very often, if ever.The only challenge is not having an ecosystem with ready made everything like you do in \"batteries included\" frameworks.\nYou are basically building a game engine and a game at the same time.We need a commercial engine in Rust or a decade of OSS work. But what features will be considered standard in Unreal Engine 2035?\n \nreply"
    ],
    "link": "https://deadmoney.gg/news/articles/migrating-away-from-rust",
    "first_paragraph": "When I started building Architect of Ruin in December 2023 I chose to build it in the Bevy\u00a0game engine. My choice was motivated by a personal interest in Rust\u00a0-- a language I derive a lot of joy in using. This was furthered by Bevy's ECS model which I also find fun to work with and the openness of Bevy's community which I have a genuine appreciation for.So, it came as a surprise that in\u00a0January of 2025 we transitioned the game away from Rust and Bevy. I spent about six weeks rewriting the game entirely in C# and we have been using Unity for the past three months.Switching engines is a classic project killer. Productivity can nosedive, regressions inevitably emerge, and every step forward seems to lead to three steps back. Not to mention that domain expertise built up in one language and engine doesn't cleanly transfer to a new language and engine.But I bit the bullet and I want to explain why.A lot of good work was accomplished in Bevy. The tilemap, most of my approach to composing the"
  },
  {
    "title": "Show HN: A pure WebGL image editor with filters, crop and perspective correction (github.com/xdadda)",
    "points": 148,
    "submitter": "axelMI",
    "submit_time": "2025-04-28T16:10:21 1745856621",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=43823044",
    "comments": [
      "Nice work.Couple of issues I had: on mobile (Brave on Android) the touch controls for cropping are very janky. Feels like it steals control each time the picture updates maybe?It's hard to see the controls under the picture on this small screen. Could you add a control to adjust the size of the controls and shrink the picture maybe?\n \nreply",
      "I've been looking for an open source image editor that I can embed in my app for managing my vintage ad archives (https://adretro.com). Basically I just need to rotate, crop, adjust color. But the images come from from the archive database rather than upload. And I want to work with them quickly, rather than save/open like a desktop app. Last time I looked I couldn't find something with good documentation that was easy to get started with. Right now I bulk edit in Google Photos.\n \nreply",
      "Extremely nice work.I'd like it if there were separate buttons for (a) reset a section (e.g. colors) back to the default and (b) do not use a section (e.g. colors). Right now, turning (e.g.) colors off loses the settings there. Maybe I missed something though.\n \nreply",
      "I too agree this is great, and see space for another low-hanging UI tweak:Allow editing numbers to right directly, instead of only using the slider. I really dislike using sliders beyond a first general impression because it is too slow to get things exactly as I want them. I would guess this is a relatively common sentiment.One feature I don't see but would love to see is text overlay, but that is perhaps moving away from the spirit of the project.\n \nreply",
      "I don't do web based development (all native desktop), but I'd be quite surprised if this was \"low hanging\".We have widgets that do this in Ardour and they were far from simple to implement.\n \nreply",
      "Is there any interference from \"anti-fingerprinting\" which corrupts the image canvas?\n \nreply",
      "Really nice work. I had been using Photopea for cropping and quick edits when preparing references for painting but this is super clean and simple.\n \nreply",
      "Hey, awesome work! This is sorely needed in the OSS package space.Are you taking into account separation of concerns? I could see myself adopting this if the UI were customizable in Vue, React, etc.\n \nreply",
      "Excellent work. The UI looks very clean and functional. It's feature packed. Good choice on using WebGL. It has support everywhere in most if not all browsers.\n \nreply",
      "This does useful things easily.\nHow hard would it be to use it as a batch process?\n \nreply"
    ],
    "link": "https://github.com/xdadda/mini-photo-editor",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Online webgl photo editor with effects, filters and cropping\n      Online webgl2 photo editor\nLink https://mini2-photo-editor.netlify.app Powered by mini-js (https://github.com/xdadda/minijs) and mini-gl (https://github.com/xdadda/mini-gl)\n        Online webgl photo editor with effects, filters and cropping\n      "
  },
  {
    "title": "Legal art forgery, for the sake of movies (2014) (vanityfair.com)",
    "points": 34,
    "submitter": "theneedful",
    "submit_time": "2025-04-28T21:01:59 1745874119",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43826065",
    "comments": [
      "https://archive.ph/CxTmk\n \nreply",
      ">Why This Movie Perfectly Re-Created a Picasso, Destroyed It, and Mailed the Evidence to Picasso\u2019s EstatePablo Picasso died more than fifty years ago at the age on 91. Four of his children are dead and the one remaining alive is 76. It's really stupid that people have to go all of this trouble for work done so long ago.  Intellectual property laws should not protect your work for the benefit of your middle-aged grandchildren.A difficult to notice watermark that prevents it being sold fraudulently as real should be more than enough.\n \nreply",
      "That wasn't the point.It seems like the the people making the film were happy to work with the foundation, for whom this was their first such request.Even if they had an adversarial posture towards the foundation, the alternative would probably involve a court of law sorting this out, with all the costs of time and money that entails. Even if they were certain they were in their rights to just add a watermark, any risk that could potentially render the film unreleasable for an any amount of time would be unacceptable.\n \nreply",
      "I personally think copyright tend are to long. But at the moment it is essentially death plus 70 years, which means Picasso's work will enjoy another 17 years of protection, unless they were works for hire.\nAs far as a watermark I'm guessing that works be between the new artist and the original artist/estate\n \nreply",
      "Where did that seemingly arbitrary 70 number come from? I don't get the reasoning behind it, why not make it 10 for example?\n \nreply",
      "Companies didn\u2019t want to lose copyright on previously created works.US constitution says it needs to be finite, but it kept being extended in little increments.\n \nreply",
      "But, as the argument goes, nobody would ever make art without the guarantee of royalties going to the artist's next 3 or 4 generations of kin. They would just... never take up painting, composing, acting, and so on.\n \nreply",
      "I can't tell if you're being hyperbolic.Plenty of people make art to express themselves, not for the potential profit of it.\n \nreply",
      "(2014)\n \nreply"
    ],
    "link": "https://www.vanityfair.com/hollywood/2014/04/art-in-movies",
    "first_paragraph": "Imagine this: You\u2019ve just spent three weeks painstakingly replicating a Picasso painting from scratch\u2014you\u2019ve scrutinized documentation about the artist\u2019s creative process; you\u2019ve practiced his brushstrokes, so your work will look convincing; you\u2019ve even painted in noted preliminary images, then covered them up, because that\u2019s what he did. You\u2019ve toiled over this, all for mere seconds of screen time in a film.And then you have to destroy it.Such was the case for scenic artist Michael Stockton\u2019s copy of Guernica, in the film Basquiat. Turns out, when you want to feature a famous painting in a movie, you can't simply slap a poster of a Monet or a Picasso in a frame and yell, \u201cAction!\u201d\u2014nor can you cart the real thing from its space on a museum wall to the set (there\u2019s too much margin for loss or destruction). The task is often a \u201cthorny challenge,\u201d as described by Basquiat production designer Dan Leigh, and it involves a rights-clearance process so time-consuming and detail-oriented, it\u2019s "
  },
  {
    "title": "What the heck is AEAD again? (ochagavia.nl)",
    "points": 26,
    "submitter": "wofo",
    "submit_time": "2025-04-28T21:59:22 1745877562",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=43826586",
    "comments": [
      "I don't understand the example. Presumably the server doesn't have the user-owned encryption key. So how can the server \"detect that the user id has been tampered with\" if it doesn't have the key necessary to authenticate the user id?\n \nreply",
      "If you're interested in doing AEAD with the current best-practice algorithms in golang, you might get inspiration from my work-in-progress symcrypt package. I'm not a cryptographer and you shouldn't trust me when I say it works correctly \u2014 but it's basically just a small, correct, wrapper around the chacha20poly1305 code in the golang standard library. It has the slight advantage of using different types for the plaintext and the associated data (here called Owner, because I use it to store API keys owned by specificIf you squint at the example usage in the tests, it's basically the API that the blogpost describes.https://github.com/peterldowns/symcrypt/blob/main/symcrypt_t...As an aside, I'm always curious to understand why the encryption people say \"never roll your own crypto\" but then also ship confusing APIs without clear usage examples. For instance, check out the golang chacha20poly1305 docs:https://pkg.go.dev/golang.org/x/crypto/chacha20poly1305\n \nreply",
      "A lot of the hardest problems in practical cryptography come down less to the abstractions around literally encrypting and decrypting things and more around the secure management of key material to ensure that the application supports things like online key rotation and makes it easy to verify that keys are being generated, serialized, and stored securely, and addressing the \"First Secret\" problem. If you're wanting to learn to use cryptography by developing an abstraction over stdlib cryptographic APIs, I would encourage you to find solutions to those problems.Another source of inspiration (and something I use in production) is the Tink family of cryptographic libraries by Google [1]. Their Go implementation [2] is not without its warts, but it's very difficult to run into any of those security bugs that exist around cryptography. Where the Go documentation lacks, there are some examples in the developer docs that help fill some of the gaps [3] [4].The documentation isn't 100% complete, but I find it more discoverable than the standard library because while the standard library requires you to read both `crypto/cipher` and `crypto/aes` or `golang.org/x/crypto/chacha20poly1305` depending on what kind of cipher you want, Tink organizes it by use cases [5] and generally groups together all the things you need to do cryptographic operations under the use-case-named interfaces in the `tink` package [6], with the corresponding key generation templates located under the top-level packages of the same name [7].[1]: https://developers.google.com/tink[2]: https://github.com/tink-crypto/tink-go/[3]: https://developers.google.com/tink/key-management-overview#g...[4]: https://developers.google.com/tink/encrypt-data#go[5]: https://developers.google.com/tink/choose-primitive[6]: https://pkg.go.dev/github.com/tink-crypto/tink-go/v2/tink#AE...[7]: https://pkg.go.dev/github.com/tink-crypto/tink-go/v2@v2.4.0/...\n \nreply",
      "I don't understand what you're finding unclear about the Chapoly docs there. AEAD encryption is a first-class abstraction in the standard Go crypto library; in the same sense that crypto/sha256 functions return a crypto.Hash, chacha20poly1305 returns a crypto.AEAD. AEAD itself includes clear usage examples.Your `symcrypt` interface lands in a pretty weird place? AEADs in Go export \"Seal\" and \"Unseal\" --- with deliberately different names than crypto/cipher/Block's \"Encrypt\" and \"Decrypt\", because they're doing something different. The \"Owner\" thing in your package is kind of odd too.You're exposing an interface over Go's AEAD primitives, but not letting users actually provide authenticated data. I don't much care except the whole point of this post is why that matters.\n \nreply",
      "When it comes to this stuff you generally have to follow advice from someone who understands what is going on.For me, personally, I'm going to side with tptacek - he has a track record that I have seen over at least a decade if not two.I don't know the other bloke but this is a bit of a worry: \"I'm not a cryptographer\".\n \nreply",
      "Agreed; I posted here with the goal of receiving advice.\n \nreply",
      "What I'm finding unclear is how to use the chapoly primitives in a secure way to accomplish my goal. I want to use AEAD encryption to store API keys, per customer, using a single app secret that my app will read from my secret manager when it starts up. AEAD seems like the right way to do that. What's the right way to do that, with AEAD, in golang? The examples/docs for cipher.AEAD at https://pkg.go.dev/crypto/cipher#AEAD don't mention chapoly, but a security reseracher friend of mine recommended I use it. The docs/examples for the chapoly library have two methods \u2014 New and NewX, and only NewX has an example. In that example, no associated data is actually used.> Your `symcrypt` interface lands in a pretty weird place? AEADs in Go export \"Seal\" and \"Unseal\" --- with deliberately different names than crypto/cipher/Block's \"Encrypt\" and \"Decrypt\", because they're doing something different.What should I use? I'd be extremely happy to do the Right Thing. I linked symcrypt and posted here because I am hoping someone can point me to it.> You're exposing an interface over Go's AEAD primitives, but not letting users actually provide authenticated data.I really don't understand what you mean by \"not letting users actually provide authenticated data\". Here, in this test, I show how if you encrypt some secret for one user (the associated data is the Owner), you can only decrypt it if you provide the same associated data (the same Owner). https://github.com/peterldowns/symcrypt/blob/c220f7767fa6c1a...\n \nreply",
      "I feel like you haven't really gotten your head around what Authenticated Data is. That's OK! Look at 'stavros upthread --- lots of clueful people have trouble with this concept.What you should do is just take the examples from cipher#AEAD, but where they do:    block, err := aes.NewCipher(key)\n    if err != nil {\n      panic(err.Error())\n    }\n\n    aesgcm, err := cipher.NewGCM(block)\n    if err != nil {\n      panic(err.Error())\n    }\n\nInstead you just do    chapoly, err := chacha20poly1305.NewX(key)\n    if err != nil {\n      panic(err.Error())\n    }\n\nThe rest of the code is the same, except that where they write \"Never use more than 2^32 random nonces with a given key because of the risk of a repeat\", you can ignore that and use a long nonce (like in the example for chacha20poly1305.NewX).Your \"Owner\" looks like what cryptographers would call a \"domain separation constant\". Domain separation is good! It's another application of authenticated data, too. But not the only one.The Go standard library's AEAD \"Seal\" and \"Unseal\" is a better interface than what you've got now.\n \nreply",
      "Thank you!\n \nreply",
      "Another AD example: Ben Toews, in our Vault replacement secret storage system Pet Semetary, uses the AD on SQLite ciphertexts to bind them to a particular row (and/or a particular key path).I wrote a local file encryption tool, around the same time Filippo was doing `age`, and used the AD on Chapoly to authenticate the chunk offset into the file. (The only thing interesting my tool did was that it could pull keys from AWS KMS).So one use for AD is to authenticate headers; another is contextual binding.If it helps (because 'stavros asked across the thread why bother having AD at all rather than just including it in the ciphertext), authenticated data can include data that doesn't even appear in the message, but rather is derived from the context at the time the message is encrypted and decrypted. A message only meant to be decrypted on a particular host (or whatever), for instance, could include the host in its AD, but never record that in the actual bits of the message.\n \nreply"
    ],
    "link": "https://ochagavia.nl/blog/what-the-heck-is-aead-again/",
    "first_paragraph": "\n\n\n      28 Apr, 2025\n    \n\nHere\u2019s a problem you might be familiar with: I keep forgetting what AEAD exactly means and why you would ever use it. Yes, I know the acronym stands for \u201cAuthenticated Encryption with Associated Data\u201d, but does that really clarify anything? Not to me, so I\u2019ve finally decided to sit down and write this blog post as a piece of help for my future self\u2026 and for anyone else who finds AEAD hard to retain.Simply put, AEAD encryption is the current industry standard. That sounds like a good reason to bother, at least if you care about Understanding Your Building Blocks. You don\u2019t have to take my word for it, though. Below are some relevant data points:The list could be longer, but this is hopefully enough to prove AEAD is here to stay. Or as Thomas Ptacek put it in his famous Cryptographic Right Answers: \u201c[AEAD] is the only way you want to encrypt in 2015\u201d. (Yes, that was 10 years ago.)When I think of authentication, the association in my mind is that of logging in "
  },
  {
    "title": "Packed Data Support in Haskell (arthi-chaud.github.io)",
    "points": 29,
    "submitter": "matt_d",
    "submit_time": "2025-04-28T20:57:49 1745873869",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arthi-chaud.github.io/posts/packed/",
    "first_paragraph": "PhD Student in Computer Science and Music maniacPacked Data x Haskell = Portable(Type-safety + performance)This blog post aims to be a short and accessible summary of a paper that will be published at ECOOP 2025, titled Type-safe and portable support for packed data.When programs want to persist data or send it over the network, they need to serialise it (e.g. to JSON or XML). On the other hand, when a program receives data from the network or reads it from a file, data needs to be deserialised.These de/serialisation steps are necessary because we cannot use the in-memory representation/layout of the data in a file or when sending it over the network, mainly because of the pointers it may contain.Consequently, de/serialising data has a cost: it takes time, and the serialised version of the data is usually bigger than its in-memory representation. In the context of systems that interact through the network, it leads to larger payloads to send, and thus slower transfer times.Now, what if"
  },
  {
    "title": "Requirements change until they don't (buttondown.com/hillelwayne)",
    "points": 17,
    "submitter": "azhenley",
    "submit_time": "2025-04-28T20:49:24 1745873364",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://buttondown.com/hillelwayne/archive/requirements-change-until-they-dont/",
    "first_paragraph": "Recently I got a question on formal methods1: how does it help to mathematically model systems when the system requirements are constantly changing? It doesn't make sense to spend a lot of time proving a design works, and then deliver the product and find out it's not at all what the client needs. As the saying goes, the hard part is \"building the right thing\", not \"building the thing right\".One possible response: \"why write tests\"? You shouldn't write tests, especially lots of unit tests ahead of time, if you might just throw them all away when the requirements change.This is a bad response because we all know the difference between writing tests and formal methods: testing is easy and FM is hard. Testing requires low cost for moderate correctness, FM requires high(ish) cost for high correctness. And when requirements are constantly changing, \"high(ish) cost\" isn't affordable and \"high correctness\" isn't worthwhile, because a kinda-okay solution that solves a customer's problem is inf"
  },
  {
    "title": "Tiny-LLM \u2013 a course of serving LLM on Apple Silicon for systems engineers (github.com/skyzh)",
    "points": 221,
    "submitter": "sarkory",
    "submit_time": "2025-04-28T11:24:41 1745839481",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=43820022",
    "comments": [
      "MLX is worth paying attention to. It's still pretty young (just over a year old) but the amount of activity in that ecosystem is really impressive, and it's quickly becoming the best way to run LLMs (and vision LLMs and increasingly audio models) on a Mac.Here's a fun way to start interacting with it (this loads and runs Llama 3.2 3B in a terminal chat UI):  uv run --isolated --with mlx-lm python -m mlx_lm.chat\n \nreply",
      "Ran it and it crapped out with a huge backtrace. I spotted `./build_bundled.sh: line 21: cmake: command not found` in it, so I guessed I needed cmake installed. `brew install cmake` and try again. Then it crapped out with `Compatibility with CMake < 3.5 has been removed from CMake.`. Then I give up.This is typical of what happens any time I try to run something written in Python. It may be easier than setting up an NVIDIA GPU, but that's a low bar.\n \nreply",
      "This is absolutely every experience I have with python.\n \nreply",
      "Which Python version was that? Could be that MLX have binary wheels for some versions but not others.\n \nreply",
      "Adding `-p 3.12` made it work. Leaving that here in case it helps someone.\n \nreply",
      "Aha, knew you wouldn't give up. Not what our kind do\n \nreply",
      "https://ml-explore.github.io/mlx/\n \nreply",
      "For those who never heard of those:mlx is similar to numpy/pytorch, but only for Apple Silicon.mlx-lm is a llama.cpp equivalent, but built on top of mlx.https://github.com/ml-explore/mlx-lm\n \nreply",
      "How much disk & RAM does it need?What's your tokens/sec rate (and on which device)?\n \nreply",
      "I've been running it on a 64GB M2. My favorite models to run tend to be about 20GB to download (eg Mistral Small 3.1) and use about 20GB of RAM while they are running.I don't have a token/second figure to hand but it's fast enough that I'm not frustrated by it.\n \nreply"
    ],
    "link": "https://github.com/skyzh/tiny-llm",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        (\ud83d\udea7 WIP) a course of serving LLM on Apple Silicon for systems engineers.\n      Still WIP and in very early stage. A tutorial on LLM serving using MLX for system engineers. The codebase\nis solely (almost!) based on MLX array/matrix APIs without any high-level neural network APIs, so that we\ncan build the model serving infrastructure from scratch and dig into the optimizations.The goal is to learn the techniques behind efficiently serving a large language model (i.e., Qwen2 models).Why MLX: nowadays it's easier to get a macOS-based local development environment than setting up an NVIDIA GPU.Why Qwen2: this was the first LLM I've interacted with -- it's the go-to example in the vllm documentation. I spent some time looking at the vllm source code and built some knowledge around it.The tiny-llm book is available at https://skyzh.github.i"
  },
  {
    "title": "Show HN: Sim Studio \u2013 Open-Source Agent Workflow GUI (github.com/simstudioai)",
    "points": 118,
    "submitter": "waleedlatif1",
    "submit_time": "2025-04-28T16:14:31 1745856871",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=43823096",
    "comments": [
      "Hi y'all. Love the idea and congratulations on your launch. I've used [n8n](https://github.com/n8n-io/n8n) for similar use cases in the past. Any differences in Sim Studio that you'd like to call out?\n \nreply",
      "Thank you! n8n has done really well over the last few years to simplify the workflow building process. I responded to this in a previous comment, but we believe the agent building process should be more open, meaning fewer abstractions between the interface and the model provider. We want our platform to be as lightweight as possible.How this translates in the application is through features like allowing for custom tool calling with code execution, JSON schema input for response format, etc. I'd love to hear your thoughts using Sim Studio - let us know how we compare to the other workflow builders!\n \nreply",
      "> Building reliable, multi-step agent systems with current frameworks often gets complicated fast.In my experience so far it's not just complicated, but effectively impossible. I struggle to get a single agent to reliably & consistently use tools, and adding n+1 agents is a error multiplier.\n \nreply",
      "on our platform (for the providers that allow granular tool use control), you can actually 'force' certain tool calls and have the agent dynamically select others. this was a painpoint that we faced ourselves and were confused why any frameworks didn't allow granular tool use control if the provider allows it. try it out and let us know what you think\n \nreply",
      "Congrats on the launch! Looking forward to playing with it.Do you mind elaborating on what differentiates Sim Studio from n8n, Flowise, RAGFlow and other open source flow based AI automation platforms?\n \nreply",
      "Thanks! The main difference between Sim Studio and other open-source AI agent workflow builders is the level of abstraction used when creating agents.For instance, n8n has a \"memory\" parameter, which is not an inherent parameter of LLMs. You can inject your agent's memories into the agent message history (or system prompt) - which is the most common scenario - but we give you control over that. We want to provide visibility, so everything that's exposed on the workflow canvas is exactly what's being executed in the background. Also, we think it's faster and more intuitive to get your workflow up and running in Sim Studio. I'd love your feedback, though! What do you think?\n \nreply",
      "This sounds like execution/variable resolution scopes in programming languages. I wonder if there are ideas from programming languages you could pick up and use?\n \nreply",
      "Yes exactly! A lot of our platform was inspired by programming languages - for loops, for each loops, custom variables, and environment variables in settings. If you have any more concepts, we'd love to hear them!\n \nreply",
      "Would be amazing to be able to design the workflow using your builder, and then export to code (and choose the language) and then copy paste the code into the project... just an idea.\n \nreply",
      "this is something we've been looking into. curious, would you rather export the code into an existing agentic framework like crewai/langgraph, or have it exported as raw code? also, would you prefer if the code was exported block-by-block or the entire workflow altogether?\n \nreply"
    ],
    "link": "https://github.com/simstudioai/sim",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Sim Studio is an open-source agent workflow builder. Sim Studio's interface is a lightweight, intuitive way to quickly build and deploy LLMs that connect with your favorite tools.\n      \n\n\n\n\n\n\n\n\nSim Studio is a powerful, user-friendly platform for building, testing, and optimizing agentic workflows.\nThere are several ways to self-host Sim Studio:After running these commands:Access the Application:Useful Docker Commands:To use local models with Sim Studio, follow these steps:Pull Local ModelsStart Sim Studio with Local ModelsThe application will now be configured to use your local models. You can access it at http://localhost:3000/w/.\u26a0\ufe0f Important Notes:We welcome contributions! Please see our Contributing Guide for details.This project is licensed under the Apache License 2.0 - see the LICENSE file for details.Made with \u2764\ufe0f by the Sim"
  },
  {
    "title": "Vision Transformers Need Registers (arxiv.org)",
    "points": 71,
    "submitter": "felineflock",
    "submit_time": "2025-04-28T16:53:08 1745859188",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43823485",
    "comments": [
      "Extremely cool!It's interesting and honestly encouraging that this kind of thing can be discovered and understood using just \"simple linear methods\" and high-level analysis of patterns in layer activations.\n \nreply",
      "So basically multiple CLS tokens.Fwiw, I tried multiple global tokens in my chess neural net and didn't see any uplift compared to my baseline of just having one.\n \nreply",
      "Note that it's not done for performance reason but rather to generate clear feature maps.\n \nreply",
      "[2023]Previously:2 years ago: https://news.ycombinator.com/item?id=37794996.1 year ago: https://news.ycombinator.com/item?id=40329675\n \nreply",
      "Has this been used widely since?\n \nreply",
      "I can't speak for the whole industry, but we used it in older UForm <https://github.com/unum-cloud/uform> and saw good adoption, especially among those deploying on the Edge, where every little trick counts. It's hard to pin down exact numbers since most deployments didn't go through Hugging Face, but at the time, these models were likely among the more widely deployed by device count.\n \nreply",
      "For example, it is used here https://github.com/facebookresearch/vggt/\n \nreply",
      "I ran a comparison of DINOv2 with and without registers on some image embedding tasks for work; DINOv2+registers saw a performance metric bump of 2-3%. Not nothing, not transformative, worth using when the only difference for inference is the model name string you're loading.\n \nreply",
      "yes\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2309.16588",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Show HN: Web-eval-agent \u2013 Let the coding agent debug itself (github.com/operative-sh)",
    "points": 59,
    "submitter": "neversettles",
    "submit_time": "2025-04-28T15:36:25 1745854585",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43822659",
    "comments": [
      "Interesting. I see from the video example it took a lot of steps and there is a lot of output for a simple task. I'm thinking this probably doesn't scale very well and more complex tasks might have performance challenges. I do think it's the right direction for AI coding.\n \nreply",
      "Yeah, I suppose to esafak's point, perhaps a benchmark for browser agent QA testing would be needed.\n \nreply",
      "Is there a benchmark for this? If not, you ought to (crowd?)start one for everybody's sake.\n \nreply",
      "We started with using browser-use because they had the best evals: https://browser-use.com/posts/sota-technical-report- but we found that Laminar came out with a better browser agent (& a better eval): https://www.lmnr.ai/ so we're looking to migrate over soon!\n \nreply",
      "Looks amazing. Congrats on the releaseHow does this compare to browser mcp (https://browsermcp.io/)?\n \nreply",
      "In browser MCP, looks like cursor controls each action along the way, but actually what we wanted was a single browser agent that had a high quality eval that could perform all the actions independently (browser-use)\n \nreply",
      "This is very cool! Does your MCP server preserve cookies/localStorage between steps, or would developers need to manually script auth handshakes?\n \nreply",
      "Between steps it would preserve cookies, but atm when the playwright browser launches, it starts with a fresh browser state, so you'd have to o-auth to log in each time.We're adding browser state persistence soon, hoping to enable it so once you sign in with google once, it can stay signed in on your local machine.\n \nreply",
      "Oh okay thanks - that would be fire tbh\n \nreply"
    ],
    "link": "https://github.com/Operative-Sh/web-eval-agent",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An MCP server that autonomously evaluates web applications. \n      Let the coding agent debug itself, you've got better things to do.operative.sh's MCP Server launches a browser-use powered agent to autonomously execute and debug web apps directly in your code editor.Built with <3 @ operative.sh\n        An MCP server that autonomously evaluates web applications. \n      "
  },
  {
    "title": "Reports of the death of California High-Speed Rail have been greatly exaggerated (asteriskmag.com)",
    "points": 128,
    "submitter": "surprisetalk",
    "submit_time": "2025-04-28T18:38:46 1745865526",
    "num_comments": 254,
    "comments_url": "https://news.ycombinator.com/item?id=43824544",
    "comments": [
      "This is the most California article ever written. The author admits that if the line was run along the I-5 it probably wouldn't need all the costly grade-separation and state property issues it's now facing. It may have even finished with its original funding! But instead of immediately being able to serve the upwards of 18M people of Greater Los Angeles and 7.5M people of the Bay Area, the 1M people of the Central Valley would have to wait for branches to be built.SO INSTEAD we took the more circuitous route through Central Valley so that the 1M people feel immediately included and NO ONE is getting a high speed rail.Sir! ChatGPT couldn't come up with a more California scented boondoggle.\n \nreply",
      "this is actually exactly what has been happening over the past few decades, and with the current proposal, for HSR from Toronto to Montreal, two of the largest cities in terms of both population and economy in Canada.Ottawa felt excluded, and is where the federal govt is based, so instead of going along the 401, a straight highway that follows a river valley and lake and has existing rail corridors, it has to go from Montreal to Ottawa (a short stretch also along a river) and then cut from Ottawa to Toronto via Peterborough, which requires new track, fixing old windy track to allow HSR, some sections have to be speed limited, and has to build through hills and dense forest.Also, Quebec feels that they don't get \"enough\" out of the project connecting their largest city to another economic powerhub, so it of course also has to be extended the extra 250km to Quebec city (luckily along a river)The logical method would be to build Toronto to Montreal 30 years ago, then build a branch to Ottawa one day, and an extension to Quebec another day.\nThe Canadian economy would probably be much stronger if that was the case.Or we can just wait 30 more years and have this project not be implemented.\n \nreply",
      "The fact is that politicians are insanely car-brained and nobody has any enthusiasm for improving rail infrastructure. Via Rail is trapped in this insane spiral of service cuts where it's miserable for staff and riders, and the solution is to cut more to make up for declining ridership.The new HSR is only happening because with the innovation of P3 deals the government can pay for the project but give all the profits to their private-sector pals. Suddenly investing in public infrastructure is appealing again (as long as the public doesn't actually get to own it!)\n \nreply",
      "I\u2019m sorry I don\u2019t really see the problem with this, connecting Toronto, Ottawa, Montreal, and Quebec city seems like a pretty reasonable route\n \nreply",
      "The problem is it doesn't get built.\n \nreply",
      "Exactly. A huge part of these projects is proving to the public the value. So even a short, direct line is useful - as some will start to use it and then extending it becomes a simple \"this thing we have is good, it should be good more.\"\n \nreply",
      "Spending money on projects that never get built is the kind of job that never ends.Great for former government employees who want to be a consultant.No one is accountable for the waste so politicians can just promise to spend more next time.\n \nreply",
      "I was surprised to find out it was going the Peterborough route. Didn't make a lot of sense.\n \nreply",
      "SNCF was one of the early bidders for this project, proposing the I5 route. They later pulled out from the politics of the Central Valley line in 2011, and went on to successfully implement high speed rail in Morocco instead - which went live in 2018.Here we are 8 years after they finished a different project with nothing. American infrastructure at its finest.https://en.wikipedia.org/wiki/SNCF#Modern_era\n \nreply",
      "In my region (Latin America) when a \"boondoggle\" of such high monetary cost happens, we call it for what it usually is\u2014 corruption.All those billions of dollars are going to someone's pockets. There's a lot of money to be made from inefficient infrastructure projects.\n \nreply"
    ],
    "link": "https://asteriskmag.com/issues/10/reports-of-the-death-of-california-high-speed-rail-have-been-greatly-exaggerated",
    "first_paragraph": "Building a high-speed rail between Los Angeles and San Francisco was never going to be easy\u2009\u2014\u2009but the critics who write it off are missing the real source of the project\u2019s struggles.If there is one subject liberals and conservatives can agree on, it might be their shared hatred for California High-Speed Rail. Today, the project is under investigation by the Trump administration and is facing a possible withdrawal of federal funds. Even California Democrats seem disinclined to put up a fight. In Ezra Klein and Derek Thompson\u2019s Abundance, it is the example par excellence of blue states\u2019 failure to build, a casualty (if it ever lived) of environmental proceduralism, prohibitive regulatory processes, a bloated bureaucracy, and general infrastructural incompetence. \u00a0All of these challenges are real. What critics miss is that many of them have already been overcome. What they ignore is the reason they exist in the first place. The story of CAHSR is not about a state trying and failing to ove"
  },
  {
    "title": "Why Momentum Works (2017) (distill.pub)",
    "points": 44,
    "submitter": "vector_spaces",
    "submit_time": "2025-04-28T05:01:10 1745816470",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=43817726",
    "comments": [
      "Discussed at the time:Why Momentum Works - https://news.ycombinator.com/item?id=14034426 - April 2017 (95 comments)\n \nreply",
      "Distill.pub has such high quality content consistently. It's a shame they don't seem to be active anymore.\n \nreply",
      "I agree. Just the usage of animations for explanations was a huge step forward. I wonder why the flagship ML/AI conferences have not adopted the distill digital template for papers yet. I think that would be the first step. The quality would follow\n \nreply",
      "The quality would not follow because Distill.pub publications take literally hundreds of man-hours for the Distill part. Highly skilled man-hours too, to make any of this work on the Web reliably. (Source: I once asked Olah basically the same question: \"How many man-hours of work by Google-tier web developers could those visualizations possibly be, Michael? 10?\")\n \nreply",
      "I've been wondering at what point AI assistants are going to reduce that to a manageable level?  It's unfortunately not obvious what the main bottlenecks are, though Chris and Shan might have a good sense.\n \nreply",
      "It might be doable soon, you're right. But there seems to be a substantial weakness in vision-language-models where they have a bad time with anything involving screenshots, tables, schematics, or visualizations, compared to real-world photographs. (This is also, I'd guess, partially why Claude/Gemini do so badly on Pokemon screenshots without a lot of hand-engineering. Abstract pixel art in a structured UI may be a sort of worst-case scenario for whatever it is they do.) So that makes it hard to do any kind of feedback, never mind letting them try to code interactive visualization stuff autonomously.\n \nreply"
    ],
    "link": "https://distill.pub/2017/momentum/",
    "first_paragraph": "\n\n\n  Here\u2019s a popular story about momentum [1, 2, 3]: gradient descent is a man walking down a hill. He follows the steepest path downwards; his progress is slow, but steady. Momentum is a heavy ball rolling down the same hill. The added inertia acts both as a smoother and an accelerator, dampening oscillations and causing us to barrel through narrow valleys, small humps and local minima.\n  \n  This standard story isn\u2019t wrong, but it fails to explain many important behaviors of momentum. In fact, momentum can be understood far more precisely if we study it on the right model.\n  \n  One nice model is the convex quadratic. This model is rich enough to reproduce momentum\u2019s local dynamics in real problems, and yet simple enough to be understood in closed form. This balance gives us powerful traction for understanding this algorithm.\n  \n  We begin with gradient descent. The algorithm has many virtues, but speed is not one of them. It is simple\u2009\u2014\u2009when optimizing a smooth function \n\nfff, we mak"
  },
  {
    "title": "Ask HN: What are you working on? (April 2025)",
    "points": 278,
    "submitter": "david927",
    "submit_time": "2025-04-27T22:08:21 1745791701",
    "num_comments": 844,
    "comments_url": "https://news.ycombinator.com/item?id=43815523",
    "comments": [
      "A tree cutting tool.Take photos of the tree from 6 different angles, feed into a 3D model generator, erode the model and generate a 3D graph representation of the tree.The tool suggests which cuts to make and where, given a restricted fall path (e.g. constrained by a neighbors yard on one side).I create the fallen branches in their final state along the fall plane, and create individual correction vectors mapping them back to their original state, but in an order that does not intersect other branch vectors.The idea came to me as a particularly difficult tree needed to come down in my friends yard, and we spent hours planning it out. I've already gotten some interest from the tree-surgeon community, I just need to appify it.Second rendition will treat the problem more as a physics one than a graph one, with some energy-minimisation methods for solving.\n \nreply",
      "This is the kind of thing that makes me love HN. An idea I would never have thought of, with an immediately obvious use in multiple ways (fall path plus ideal lumber cutting?), probably very difficult, yet being tackled with one implementation already... and spoken of quite humbly.\n \nreply",
      "Funny, one of mine also involves trees -- but is mostly outdoor cleanup. The kind that involves decades' worth of it, thanks to what I'll just say is a lot of maintenance that wasn't done over a long time. There's an extensive amount of brush, leaves, etc of varying ages that could maybe be shredded up into something useful, invasive vines I'm still trying to deal with, and more old trash than I've fully figured out how to properly dispose of.It's turning into various DIY rabbit holes, actually, with the next one (outside of various related landscaping stuff) being to gut a basement.\n \nreply",
      "You should branch out (hehe) into flower and plant pruning suggestions with your app. ChatGPT can do this now if prompted.\n \nreply",
      "I would love to have such a model tell me how to prune my fruit trees as they grow up. Should be a fairly straightforward supervised problem with the right front end for the graph generation.\n \nreply",
      "When i read OP this is what I thought it was going to be - these branches are going to be apex competitors, these are crossing or going to cross, this one shows signs of disease, this one interrupts air flow through the centre, etc.\n \nreply",
      "You can start right now with an algorithm I learned from an expert when I was working in a landscaping business.It is a very simple three-pass plan: \"Deadwood, Crossovers, Aesthetics\".So, first pass, go through the tree cutting out only and all the dead branches. Cut back to live stock, and as always make good clean angle cuts at a proper angle (many horticulture books will provide far better instructions on this).Second pass, look only for branches that cross-over other branches and especially those that show rubbing or friction marks against other branches.  Cut the ones that are either least healthy or grow in the craziest direction (i.e., crazy away from the normal more-or-less not radially away from the trunk).Then, and only after the other two passes are complete, start pruning for the desired look and/or size & shape for planned growth or bearing fruit.This method is simple and saves a LOT of ruined trees from trying to first cut to size and appearance, then by the time the deadwood and crossovers are taken later, it is a scraggly mess that takes years to grow back.  And it even works well for novices, as long as they pay attention.I'd suspect entering the state and direction of every branch to an app would take longer than just pruning with the above method, although for trees that haven't fully leafed out, perhaps a 360\u00b0 angle set of drone pics could make an adequate 3D model to use for planning?In any case, good luck with your fruit trees \u2014 may they grow healthy and provide you with great bounty for many years!\n \nreply",
      "I was imagining something like this for pruning fruit trees \u2014 something to help noobs like me see how to put pruning guidelines into practice on a real, overgrown tree. Good luck!\n \nreply",
      "This is great idea - I have a huge tree in front yard that will either cost be $5-10k to come down or was going to rent lift and do it myself - A few particular branches scare me though in terms of how they will come down... Bonus points for where to tie things off.\n \nreply",
      "Where I live this could be very helpful becuase people is too, how to say it, maybe ignorant in safety and logic specs. Also could be usefull to know or estimate what tree are in a innminent or highr posibilities of fall with wind.Happy to help!\n \nreply"
    ],
    "link": "item?id=43815523",
    "first_paragraph": ""
  }
]