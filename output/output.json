[
  {
    "title": "Offline card payments should be possible no later than 1 July 2026 (riksbank.se)",
    "points": 210,
    "submitter": "sebiw",
    "submit_time": "2025-10-03T20:36:03 1759523763",
    "num_comments": 231,
    "comments_url": "https://news.ycombinator.com/item?id=45467500",
    "comments": [
      "Some context might be useful here. I spent some time living Sweden not too long ago and Swedes practically don't use cash. It's usually not said out loud, but cash is often considered to be dirty and criminal, to the point that most don't have any at all. Digital payments are very convenient and deeply integrated, so long as you have a local ID which allows you use the local payment system Swish etc.This worked nicely until the tensions in Europe lead to more cyberattacks rolling in and suddenly you have people not being able to buy food, medicine, and so forth. Not too long after, there was a government advisory urging people to keep some cash reserves in case a larger cyberattack happens, but cultural habits at large are hard to change. This is of course a coarse simplification of the context, but might help understand this incentive a bit better.reply",
      "> \"It's usually not said out loud, but cash is often considered to be dirty and criminal ...\"Are you sure this isn't impression you've gotten from isolated reactions involving a small number of individuals, perhaps just a single individual? I can't relate to the sentiment at all, having lived here for just over three decades and experiencing the popularity shift from cash to debit card. I can, in fact, not recall a single time ever that someone has divulged the opinion that they consider cash \"dirty and criminal\".More than anything else the Swede's favor of debit card is the convenience. Second to that I would say is the security of not immediately losing funds if you misplace the card or it being stolen - it feels less risky carrying a debit card, in particular if you're the type who prefers having more than a few \"tens\" on you in case you'd need or want to buy something.reply",
      "I'm Swedish and if someone insists on doing a transaction using cash when Swish or card is available, I'd immediately start to wonder if it's for some kind of more or less shady reason, probably tax evasion at the very least.reply",
      "You have to differentiate common purchases from \"large\" purchases in this discussion. I'm certain you don't think there's something shady going on, or tax evasion happening, if someone uses cash in the grocery store or at Pressbyr\u00e5n, or to pay for some little gadget or whatever at Kjell&Co.This is what people think of when someone \"uses cash\". Not hauling tens of thousands to buy a used car or to settle the bill for having your bathroom tiled, which would be cases I too would raise an eyebrow over.reply",
      "I think they're talking about when merchants insist that you give them cash (\"cash only\"), not when buyers insist on giving cash. The usual assumption is that if e.g. a street-food cart is cash-only, it's not because they can't accept cards (it's rather trivial nowadays) but rather that 1. they don't want to pay the interchange fees, and more importantly, 2. they want to be able to cook their books when reporting revenue.",
      "FWIW I am Australian and we have a similar adoption rate of cashless payments.If a merchant tries to promote cash options I immediately think they\u2019re doing it for tax evasion reasons - not because of the touted reason that \u201ccard payments cost more to process\u201d (they don\u2019t once you factor in the cost of handling cash).reply",
      "I think the same thing in the US about small businesses that only take cash, but it's still pretty normal to use cash in the US.reply",
      "People forget that the credit card companies charge businesses to process transactions. Some stores/restaurants even give discounts for paying in cash because of this.reply",
      "I know its not uncommon at small business to ad a surcharge for using cards on purchases below a certain dollar value rather than a discount for cash.",
      "IME (in Canada), the cash discount is surprisingly close to 15%, which is approximately the sales tax in most provinces.reply"
    ],
    "link": "https://www.riksbank.se/en-gb/press-and-published/notices-and-press-releases/press-releases/2025/offline-card-payments-should-be-possible-no-later-than-1-july-2026/",
    "first_paragraph": "\nPress release\r\n\t\t\t\t\tThe Riksbank and representatives from the payment market have today reached an agreement to increase the possibility to make offline card payments for essential goods. The agreement is an important step in the work to strengthen Sweden's payment preparedness and increase resilience to disruptions in the digital payments system. The goal is for the measures to be in place no later than 1 July 2026.\r\n\t\t\t\t\u201cIn Sweden, we pay digitally to a large degree and the use of cash is low. The general public being able to pay by card for example for food and medicines even in the event of a serious breakdown in data communication, that is offline, is a milestone in our intensified efforts to strengthen emergency preparedness\u201d, says Governor Erik Thed\u00e9en.The agreement describes the measures that participants in Swedish card payments \u2013 card issuers, card networks, card acquirers, the retail sector and the Riksbank \u2013 will implement to increase the possibility of offline payments by"
  },
  {
    "title": "Zig builds are getting faster (mitchellh.com)",
    "points": 68,
    "submitter": "emschwartz",
    "submit_time": "2025-10-03T22:45:28 1759531528",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45468698",
    "comments": [
      "LLVM is a trap. You bootstrap extra fast, you get all sorts of optimization passes and platforms for free, but you lose out on the ability to tune the final optimization passes and performance of the linking stages.I think we'll see cranelift take off in Rust quite soon, though I also think it wouldn't be the juggernaut of a language if they hadn't stuck with LLVM those early years.Go seems to have made the choice long ago to eschew outsourcing of codegen and linking and done well for it.reply",
      "The gold standard for compiler speed so far is TCC. (Fabrice Bellard)It is not even super optimized (single thread, no fancy tricks) but it is so far unbeaten by a large margin. Of course I use Clang for releases, but the codegen of tcc is not even awful.reply",
      "The Go compiler is also pretty fast.reply",
      "Wow!reply",
      "It's a bold strategy - let's see if it works out for them.But from what I remember, this still uses the LLVM backend, right? Sure, you can beat LLVM on compilation speed and number of platforms supported, but when it comes to emitting great assembly, it is almost unbeatable.reply",
      "It only uses the LLVM backend for release builds. For debug builds Zig now defaults to self-hosted (on supported platforms, only x86_64 right now). Debug builds are directly in the hot path of testing your software (this includes building test binaries), and the number of iterations you do on a debug build are multiple orders of magnitude higher than release builds, so this is a good tradeoff.reply",
      "> but when it comes to emitting great assembly, it is almost unbeatable.\"Proebsting's Law: Compiler Advances Double Computing Power Every 18 Years\"The implication is that doing the easy, obvious and fast optimizations is Good Enough(tm).Even if LLVM is God Tier(tm) at optimizing, the cost for those optimizations swings against them very quickly.reply",
      "I don't really get the obsession w/ compiler performance. At the end of the day you are trading performance optimizations (inlining, dead code elimination, partial evaluation, etc) for compile times. If you want fast compile times then use a compiler w/ no optimization passes, done. The compile times are now linear w/ respect to lines of code & there is provably no further improvement you can make on that b/c any further passes will add linear or superlinear amount of overhead depending on the complexity of the optimization.reply",
      "The reason to care about compile time is because it affects your iteration speed. You can iterate much faster on a program that takes 1 second to compile vs 1 minute.Time complexity may be O(lines), but a compiler can be faster or slower based on how long it takes. And for incremental updates, compilers can do significantly better than O(lines).In debug mode, zig uses llvm with no optimization passes. On linux x86_64, it uses its own native backend. This backend can be significantly faster to compile (2x or more) than llvm.Zig's own native backend is designed for incremental compilation. This means, after the initial build, there will be very little work that has to be done for the next emit. It needs to rebuild the affected function, potentially rebuild other functions which depend on it, and then directly update the one part of the output binary that changed. This will be significantly faster than O(n) for edits.reply",
      "But if those passes (or indeed any other step of the process) are inefficiently implemented, they could be improved. The compiler output would be the same, but now it would be produced more quickly, and the iteration time would be shorter.reply"
    ],
    "link": "https://mitchellh.com/writing/zig-builds-getting-faster",
    "first_paragraph": "Andrew Kelley famously (or infamously, depending on your views) said\n\"the compiler is too damn slow, that's why we have bugs.\"1As a result, one of the primary stated goals of Zig for\nyears has been faster compile times. The Zig team has been working on\nextremely hard problems to make this a reality\n(such as yeeting LLVM,\nwriting their own code generation backends,\nbuilding their own linkers,\nand marching towards incremental compilation in general).2The fruits of this multi-year labor are finally starting to show\nwith Zig 0.15.1. The Ghostty project just completed upgrading to\nZig 0.15.1, and I'd like to share some real-world build times.3This is the time it takes to build the build.zig script itself. The\ntimes above were measured by running zig build --help.A well-written build script should only rebuild itself rarely. However,\nthis is a cost every new uncached source build will pay (e.g. a user\ndownloading the project to build from source one time). As such, it directly\nimpacts the ti"
  },
  {
    "title": "Where it's at:// (overreacted.io)",
    "points": 83,
    "submitter": "steveklabnik",
    "submit_time": "2025-10-02T20:31:43 1759437103",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=45455164",
    "comments": [
      "Excellent explanation as always from Dan, and timely with the latest news from Bluesky on moving the PLC management.We picked the same DID systems for https://fair.pm/ to decentralise WordPress plugin distribution (and general management for user-facing packages; think App Store rather than Cargo).The Bluesky folks (especially Bryan) were super helpful in helping us out - even shipping Ed25519 key support so we could use libsodium.(We\u2019re designing our protocol on top of DIDs and using Bluesky\u2019s stackable moderation, but chose not to use atproto directly - but the great thing is that DIDs are a W3C standard, and PLC isn\u2019t tied to atproto.)reply",
      "\"Given an at:// URI, how do you locate the corresponding JSON?\"This is chicken and egg stuff.  I don't get it and I've picked on the intro of the explainer.  Why would I want \"the JSON\"?Yes, I did skim the \"read this\" link.It's not for me.reply",
      "Yeah, sorry for abrupt intro.In short, at:// protocol lets you build apps that can deeply interop and query/embed each other's information, allow the user to have a shared user identity between apps, and allow the user to self-host their content (or move their hosting) without impacting the apps. It does this by giving bits of JSON permanent URIs that aren't tied to a specific user handle or hosting server, but instead are rooted in identity. The article describes how that works (and what an \"identity\" is) in technical detail.Here's a concrete example: a blogging app (https://leaflet.pub) automatically \"sees\" mentions of a Leaflet post on a different microblogging app (https://bsky.app) and can display them: https://bsky.app/profile/o.simardcasanova.net/post/3luujudlr.... This is not done by hitting an API; it's just that both apps aggregate the same information from the open network into their respective databases.reply",
      "Imagine it as analogous to \u201cGiven a https:// URI, how do you locate the corresponding HTML?\u201dThis is oversimplified but is a decent question to prompt an explanation for someone new to DNS, HTTP, TLS, etc.reply",
      "So any server storing such at:// links will need to do some DNS/HTTPS dance to get the canonical representation, or permalink as the author calls it.Doesn't that make it quite fragile without functioning DNSSEC?Haven't really thought it through but my immediate reaction is DNS poisoning seems like it could do some damage here, allowing bad actors to post in my name, given the public key is part of the DID that you found from the DNS entry. Or?reply",
      "They'd need the private key to post as you. The DNS record just points to where the DID document is, but there's a verification check that the DID document points back, and this is automatically performed as a part of the resolution process.DNSSEC would add additional security around DNS record changes, but not having it wouldn't allow someone to impersonate you, because your server would need to agree with that.reply",
      "This is a bit beyond my understanding (I'll ping someone who may be able to answer), but https://atproto.com/specs/handle#dns-txt-method mentions \"DNSSEC is not required\" (though I'm also not sure that's what you're asking).>allowing bad actors to post in my name, given the public key is part of the DID that you found from the DNS entry. Or?DNS only resolves the Handle->DID, but you still need to verify DID->Handle mapping by getting the DID Document. It's bidirectional.reply",
      "> \"DNSSEC is not required\"I guess I need to study that in more detail, as I don't immediately see how it's preventing DNS attacks.> DNS only resolves the Handle->DID, but you still need to verify DID->Handle mapping by getting the DID Document. It's bidirectional.Yes but if I've already hijacked the DNS to point to my own DID, what's stopping me from saying I go by your handle?Sure older posts wouldn't verify, but a new post would be signed by the keypair I've put in the DID I hijacked, no? Or is that some other key in the DID?New to AT so perhaps this is a non-issue. Main concern of mine is that DNSSEC seems to not have a very bright future, so not something new stuff should rely on IMHO.reply",
      ">Yes but if I've already hijacked the DNS to point to my own DID, what's stopping me from saying I go by your handle?The process of establishing \"this handle points to this DID\" consists of:1. Resolving handle -> DID via HTTPS/DNS (part you're concerned about)2. Downloading the DID Document from its host3. Verifying that the DID Document contains the same handleHijacking the DNS does not help you with (2) and (3). The handle isn't considered associated with the DID until (2) and (3) are done.reply",
      "The recommendation to resolve from handles to DIDs for \"permalinks\" is concerning to me:- My handle is something _I_ control. I can make it point at a different PDS at any time.- My DID is something my PDS controls.I could solve this by indirecting through a web DID under my control, but there's no recommendation anywhere in Bluesky's documentation. Is that something everyone needs to do to ensure real identity portability?edit: I'm not sure this CAN be solved without running a PDS given that I can't use my own keys. What am I missing here?reply"
    ],
    "link": "https://overreacted.io/where-its-at/",
    "first_paragraph": "October 2, 2025You might have heard about the AT protocol (if not, read this!)Together, all servers speaking the AT protocol comprise the atmosphere\u2014a web of hyperlinked JSON. Each piece of JSON on the atmosphere has its own at:// URI:But where do they point, exactly?Given an at:// URI, how do you locate the corresponding JSON?In this post, I\u2019ll show you the exact process of resolving an at:// URI step by step. Turns out, this is also a great way to learn the details of how at:// works.Let\u2019s start with the structure of a URI itself.As you might know, a URI often contains a scheme (for example, https://), an authority (like wikipedia.com), a path (like /Main_Page), and maybe a query.In most protocols, including https://, the authority part points at whoever\u2019s hosting the data. Whoever created this data is either not present, or is in the path:\n\nhttps:///profile//post/3lzy2ji4nms2zbsky.appruuuuu.dethe appthe userThe at:// protocol flips that around.In at:// URIs, whoever created the data"
  },
  {
    "title": "Fluid Glass (chiuhans111.github.io)",
    "points": 180,
    "submitter": "memalign",
    "submit_time": "2025-09-30T05:15:40 1759209340",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=45422147",
    "comments": [
      "This website is running at >10 FPS at 100% GPU usagereply",
      "Source code: https://github.com/chiuhans111/fluidglassreply",
      "it's interesting that the drops tend to collect in straight lines. I wonder what's happening in the sim code to keep them from collecting into round droplets?reply",
      "looks similar to some emergent patterns in reaction diffusion systemsreply",
      "Aliasing on the grid.reply",
      "Apple coding interview?reply",
      "Real LOL! Exactly.reply",
      "Beautiful demo. I hope no IT company will ever think this is a good UI.reply",
      "Came here to post exactly this. Very nice demo though...reply",
      "Do note you can click and drag on it too.reply"
    ],
    "link": "https://chiuhans111.github.io/fluidglass/",
    "first_paragraph": ""
  },
  {
    "title": "PEP 810 \u2013 Explicit lazy imports (readthedocs.build)",
    "points": 255,
    "submitter": "azhenley",
    "submit_time": "2025-10-03T18:24:58 1759515898",
    "num_comments": 146,
    "comments_url": "https://news.ycombinator.com/item?id=45466086",
    "comments": [
      "Love this. My https://llm.datasette.io/ CLI tool supports plugins, and people were complaining about really slow start times even for commands like \"llm --help\" - it turned out there were popular plugins that did things like import pytorch at the base level, so the entire startup was blocked on heavy imports.I ended up adding a note to the plugin author docs suggesting lazy loading inside of functions - https://llm.datasette.io/en/stable/plugins/advanced-model-pl... - but having a core Python language feature for this would be really nice.reply",
      "You can implement this from your tool today: https://news.ycombinator.com/item?id=45467489Note that this is global to the entire process, so for example if you make an import of Numpy lazy this way, then so are the imports of all the sub-modules. Meaning that large parts of Numpy might not be imported at all if they aren't needed, but pauses for importing individual modules might be distributed unpredictably across the runtime.Edit: from further experimentation, it appears that if the source does something like `import foo.bar.baz` then `foo` and `foo.bar` will still be eagerly loaded, and only `foo.bar.baz` itself is deferred. This might be part of what the PEP meant by \"mostly\". But it might also be possible to improve my implementation to fix that.reply",
      "Parse the command line and do things like \"--help\" without doing the imports.Only do imports when you know you need them -- or as an easy approximation, only if the easy command line options have been handled and there's still something to do.reply",
      "In the llm project, plugins can modify the command line arguments, so it's not that simple.reply",
      "Yea, that's the core problem here: plugins can add new CLI subcommands, which means they all need to be loaded on startup.https://llm.datasette.io/en/stable/plugins/plugin-hooks.html...reply",
      "Well yes, or you can just use the `lazy` keyword, when it makes it into core.reply",
      "You can \u201cjust\u201d use a feature which does not exist yet? How is that something you \u201cjust\u201d do?reply",
      "Lazy imports have been proposed before, and were rejected most recently back in 2022: https://discuss.python.org/t/pep-690-lazy-imports-again/1966.... If I recall correctly, lazy imports are a feature supported in Cinder, Meta's version of CPython, and the PEP was driven by folks that worked on Cinder. Last time, a lot of the discussion centered around questions like: Should this be opt-in or opt-out? At what level? Should it be a build-flag for CPython itself? Etc. The linked post suggests that the Steering Council ultimately rejected it because of the complexity it would introduce to have two divergent \"modes\" of importing.I hope this proposal succeeds. I would love to use this feature.reply",
      "I also hope this proposal succeeds, but I'm not optimistic. This will break tons of code and introduce a slew of footguns. Import statements fundamentally have side effects, and when and how these side effects are applied will cause mysterious problems and breakages that will keep people up for many nights.This is not fearmongering. There is a reason why the only flavor of Python with lazy imports comes from one of the most well-resourced companies in the world.Too many people in this thread are espousing the view of \"importing {pandas, numpy, my weird module that is more tangled than an eight-player game of Twister} takes too long and I will gladly support anything that makes them faster\". I would be willing to bet a heinous sum of money that most people who hold this opinion are unable to describe how Python's import system works, let alone describe how to implement lazy imports.PEP 690 describes a number of drawbacks, notably causing breaking behavior for imports that, for example, use decorators to add functions to a central registry. This is not a contrived example: Dash, a popular library for building frontends that has been around for more than a decade, uses this feature to expose a JavaScript-based interface for callbacks written in Python.The fact that nobody in this thread has even come close to proposing a comprehensive solution for just this one issue show you how unqualified most people here are to speak on the topic. This is before we even get to the rest of the issues the PEP describes, which are weirder and even crazier than this case.reply",
      "Especially since it is opt in, with various level of granularity, and a global off switch. Very well constructed spec given the constraints.reply"
    ],
    "link": "https://pep-previews--4622.org.readthedocs.build/pep-0810/",
    "first_paragraph": "This PEP introduces syntax for lazy imports as an explicit language feature:Lazy imports defer the loading and execution of a module until the first time\nthe imported name is used, in contrast to \u2018normal\u2019 imports, which eagerly load\nand execute a module at the point of the import statement.By allowing developers to mark individual imports as lazy with explicit\nsyntax, Python programs can reduce startup time, memory usage, and unnecessary\nwork. This is particularly beneficial for command-line tools, test suites, and\napplications with large dependency graphs.This proposal preserves full backwards compatibility: normal import statements\nremain unchanged, and lazy imports are enabled only where explicitly\nrequested.The dominant convention in Python code is to place all imports at the module\nlevel, typically at the beginning of the file. This avoids repetition, makes\nimport dependencies clear and minimizes runtime overhead by only evaluating an\nimport statement once per module.A major drawb"
  },
  {
    "title": "AMD's EPYC 9355P: Inside a 32 Core Zen 5 Server Chip (chipsandcheese.com)",
    "points": 73,
    "submitter": "rbanffy",
    "submit_time": "2025-10-03T20:01:36 1759521696",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=45467166",
    "comments": [
      ">768 GB of DDR5-5200. The 12 memory controllers on the IO die provide a 768-bit memory bus, so the setup provides just under 500 GB/s of theoretical bandwidthI know it's a server but I'd be so ready to use all of that as RAM disk. Crazy amount at a crazy high speed. Even 1% would be enough just to play around with something.reply",
      "For our build servers for devs we utilize roughly this setup as a ram disk. It's amazing. Build times are lighting fast (compared to HDD/SSD)reply",
      "Those are extremely uniform latencies. Seems like on these CPUs most benefits from NUMA-aware thread-pools will be coming from reduced contention - mostly synchronizing small subsets of cores, rather than the actual memory affinity.reply",
      "Well, all of the memory is at IO die. I remember AMD docs outright recommend to make processor hide NUMA nodes from the workload as trying to optimize for it might not even do anything for a lot of workloadsreply",
      "That AMD slide (in the conclusion) claims their switching fabric has some kind of bypass mode to improve latency when utilisation is low.So they have been really optimising that IO die for latency.NUMA is already workload sensitive, you need to benchmark your exact workload to know if it\u2019s worth enabling or not, and this change is probably going to make it even less worthwhile. Sounds like you will need a workload that really pushes total memory bandwidth to make NUMA worthwhile.reply",
      "The first picture has a typo on it's left hand side.It says 16 cores per die with up 16 zen 5 dies per chip. For zen 5 it's 8 cores per die, 16 dies per chip giving a total of 128 cores.For zen 5c it's 16 cores per die, 12 dies per chip giving a total of 192 cores.Weirdly it's correct on the right side of the image.reply"
    ],
    "link": "https://chipsandcheese.com/p/amds-epyc-9355p-inside-a-32-core",
    "first_paragraph": ""
  },
  {
    "title": "Interstellar Object 3I/Atlas Passed Mars Last Night (earthsky.org)",
    "points": 83,
    "submitter": "jandrewrogers",
    "submit_time": "2025-10-03T20:40:52 1759524052",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=45467543",
    "comments": [
      "Have we gotten better at detecting these objects in the past 5 years or is the solar system going through a bumpy area of Milky Way lately? We have observed (or I have heard about) many interstellar objects in the past five years than any previous times.reply",
      "There has been a significant increase in NEO observation projects in the last eight years and there\u2019s one coming online soon that should increase the detection capabilities even more.Pan-STARRS (discovered 1I/\u02bbOumuamua), Zwicky Transient Facility (2I/Borisov), and ATLAS (3I/ATLAS) are the major existing projects and the Rubin Observatory/LSST will be a huge upgrade. We\u2019re going to detect a lot more if these objects, especially since a lot of the work of the projects are looking at historical data.reply",
      "2I/Borisov was not discovered by Zwicky Transient Facility .The comet was discovered on 30 August 2019 by amateur astronomer Gennadiy Borisov at his personal observatory MARGO in Nauchnij, Crimea, using a 0.65 meter telescope he designed and built himself.reply",
      "Computing Power has increased tremendously, along with the higher resolution of digital imaging technology compared to analog film plates. Sky Survey projects like the Vera C. Rubin Observatory have become active in recent years, which generate Terabytes of spectrographic data each night which can be rapidly examined for differences from previous captures. In the past each exposure had to be hand-aligned on a Light table and \u201cflipped\u201d between to spot differences.reply",
      "From wikipedia: \"As of 2025, three interstellar objects have been discovered traveling through the Solar System: 1I/\u02bbOumuamua in 2017, 2I/Borisov in 2019, and 3I/ATLAS in 2025\"I would guess that observation improves over time. The wikipedia article is fascinating, estimating 10,000 such objects passing within Neptune's orbit in our solar system each day. I think that includes dust and sand sized objects.reply",
      "It's detection, not a particularly crowded area of space. These rocks are hard to see, and one needs at least 3 observations (in theory, but in practice more) to compute their path and determine that they're extrasolar. Within 5 years we'll probably be detecting several of them a week.reply",
      "I was surprised to recently learn that NASA has aimed pretty much everything it has at 3I/Atlas, even the Perseverance Mars rover! <https://science.nasa.gov/solar-system/comets/3i-atlas/>reply",
      "Looking forward to seeing what images they received, especially after Avi Loeb's comments on it.reply",
      "Avi\u2019s the new \u201cit\u2019s Aliens\u201d meme guyreply",
      "No, he's the new \"we should consider what this would look like if it were an artifact of an alien civilization\" guy. You know, open minded.He's also a well respected and very accomplished person who has acknowledged this is a comet.If it happens to slow down and change trajectory after it passes behind the sun, he might change his tune but he's pretty focused on the science at this point.reply"
    ],
    "link": "https://earthsky.org/space/new-interstellar-object-candidate-heading-toward-the-sun-a11pl3z/",
    "first_paragraph": "A daily update by email. Science news, great photos, sky alerts.The world\u2019s 3rd known interstellar object \u2013 3I/ATLAS \u2013 has made its closest approach to Mars. The approach took place at 4 UTC on October 3, 2025 (11 p.m. CDT on October 2). At that time, the comet was approximately 18 million miles (29 million kilometers) from Mars. It was the object\u2019s closest approach to any planet during its one-time journey through our solar system. As of this writing (10 UTC on October 3), we have not seen any new images from the pass. But multiple space agencies, including NASA and the European Space Agency (ESA), are coordinating observations using various spacecraft and orbiters around Mars. Instruments on ESA\u2019s Mars Express and ExoMars Trace Gas Orbiter, as well as NASA\u2019s Mars Reconnaissance Orbiter, are focusing on capturing detailed data from this interstellar visitor. In an October 2 story from AP, Marcia Dunn reported: Both of the European Space Agency\u2019s satellites around Mars are already aimi"
  },
  {
    "title": "LoRA Without Regret (thinkingmachines.ai)",
    "points": 52,
    "submitter": "grantpitt",
    "submit_time": "2025-09-29T17:52:17 1759168337",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=45416706",
    "comments": [
      "Can someone explain the bit counting argument in the reinforcement learning part?I don\u2019t get why a trajectory would provide only one bit of information.Each step of the trajectory is at least giving information about what state transitions are possible.An infinitely long trajectory can explore the whole state space if there are no absorbing states. Such a trajectory would provide a massive amount of information about the system, even if we ignored the final reward.reply",
      "The name gets me every single time. Always think it\u2019s going to be about radio LoRareply",
      "Same - sad it's not.reply",
      "Dang it! Got me too! I've been wanting to hop into Meshtastic lately.reply",
      "Set up a node! Bare boards that work with the app are like $50 and take a few clicks to flash and setup. The basic antenna with no amp makes contacts up to 50mi away if the conditions are right. I have one in a window and one in a backpack at all times.reply",
      "It's insane how far you can go between hops, really most impressive. Where I live the mesh density is fairly high but I've also tried it in places where it was vanishingly low and yet I never completely lost contact. LoRa is very much an underappreciated technology.reply",
      "I thought it was Lora the CRTD implementation, but then realized that Lororeply",
      "Yeah, kinda disappointed it's just more AI stuff...reply",
      "Missed opportunity to title this \"Lo-RAgrets\"reply",
      "Took me a moment to realize this is not about LoRa.reply"
    ],
    "link": "https://thinkingmachines.ai/blog/lora/",
    "first_paragraph": ""
  },
  {
    "title": "Litestream v0.5.0 (fly.io)",
    "points": 360,
    "submitter": "emschwartz",
    "submit_time": "2025-10-02T19:02:57 1759431777",
    "num_comments": 165,
    "comments_url": "https://news.ycombinator.com/item?id=45453936",
    "comments": [
      "The DX for deploying SQLite apps to Fly.io is rough. I'm a few hours into trying to get a production Rails app booting, but running into issues getting the database to initialize, migrate, and become writable. The root of my problem was the eager loading of a gem I wrote, but there were several layers of runners above it that made it hard to diagnose.I wish they'd put a bit more effort into the DX here, but it probably doesn't make much sense from a biz PoV since big customers aren't going to be running these kinds workloads.Curious if anybody here is deploying SQLite apps to production and what host they're using?reply",
      ">The DX for deploying SQLite apps to Fly.io is rough. I'm a few hours into trying to get a production Rails app booting, but running into issues getting the database to initialize, migrate, and become writable. The root of my problem was the eager loading of a gem I wrote, but there were several layers of runners above it that made it hard to diagnose.What's the Fly.io issue here? Aren't the issues you're describing in Rails not Fly.io?I run several Go apps in production on Fly.io[0, 1, 2] and I've never had an issue with the Fly.io + SQLite part of it.SQLite + Litestream makes things slightly more complicated, but again, I've never had issues with Fly.io specifically making that harder. I use a custom launch script in my Dockerfile that starts litestream with the -exec flag to start my app as a child process.[3][0] https://github.com/mtlynch/logpaste[1] https://github.com/mtlynch/picoshare[2] https://github.com/mtlynch/screenjournal[3] https://github.com/mtlynch/logpaste/blob/0.3.1/docker-entryp...reply",
      "I setup a fresh rails 8 app on Fly last year, using PG for the main data store but using SQLite for the ancillary solid stack dbs.Only fuss I remember encountering was with fighting with rails migrating solid queue properly, but this seemed like a rails unit issue and don\u2019t remember it being a Fly issue.I\u2019ve been contemplating migrating my pg primary to SQLite too. Anyways don\u2019t have much else to offer other than an anecdote that I\u2019m happily using fly with partial SQLite.reply",
      "I use in production but it's a console app that lives on a server. The database sits on a file share.reply",
      "I self host on a vps\nLitestream works for that quite wellreply",
      "Very excited to see Fly restart development on Litestream after a 2ish year freeze!I love Litestream and use it in every app I build now.They advertise it as costing \"pennies per day,\" but it's even less expensive than that. It obviously varies depending on how much storage you need, but I had a real app in production, and Litestream replication to S3 only cost me 2-3 cents ($0.02-$0.03) per month.[0][0] https://mtlynch.io/litestream/#using-logpaste-in-productionreply",
      "It seems Litestream will soon support arbitrary s3-compatible destinations.[^1] Neat.So far I\u2019ve stuck with the SFTP solution, since I don\u2019t use any of the cloud object storage services that are hardcoded into the tool.[^2]Big thanks to the developers.[^1]: https://github.com/benbjohnson/litestream/pull/731[^2]: https://litestream.io/guides/#replica-guidesreply",
      "Interesting tidbit regarding LiteFS/Litestream:> But the market has spoken! Users prefer Litestream. And honestly, we get it: Litestream is easier to run and to reason about. So we\u2019ve shifted our focus back to it.reply",
      "That makes sense to me. LiteFS used FUSE, which meant figuring out how to run and mount a custom filesystem. Litestream is a single compiled Go binary that you point at the SQLite database file (and accompanying WAL file).reply",
      "I look forward to trying this out. Any benchmarks or demos on how long it actually takes to restore? I ended up cooking my own boring S3 backup because previously litestream took 20 minutes to restore something like 1000 rows. It felt extremely unoptimized. How long does restoration take today?reply"
    ],
    "link": "https://fly.io/blog/litestream-v050-is-here/",
    "first_paragraph": "I\u2019m Ben Johnson, and I work on Litestream at Fly.io. Litestream makes it easy to build SQLite-backed full-stack applications  with resilience to server failure. It\u2019s open source, runs anywhere, and it\u2019s easy to get started.Litestream is the missing backup/restore system for SQLite. It runs as a sidecar process in the background, alongside unmodified SQLite applications, intercepting WAL checkpoints and streaming them to object storage in real time. Your application doesn\u2019t even know it\u2019s there. But if your server crashes, Litestream lets you quickly restore the database to your new hardware.The result: you can safely build whole full-stack applications on top of SQLite.A few months back, we announced plans for a major update to Litestream. I\u2019m psyched to announce that the first batch of those changes are now \u201cshipping\u201d. Litestream is  faster and now supports efficient point-in-time recovery (PITR).I\u2019m going to take a beat to recap Litestream and how we got here, then talk about how the"
  },
  {
    "title": "Open Printer is an open source inkjet printer with DRM-free ink (notebookcheck.net)",
    "points": 166,
    "submitter": "mnmalst",
    "submit_time": "2025-09-30T08:57:11 1759222631",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=45423404",
    "comments": [
      "https://www.crowdsupply.com/open-tools/open-printer> Open Source> Open Printer will use the Creative Commons BY-NC-SA 4.0 license for all of its files, including electronics and mechanical design files, firmware code, and the bill of materials. We hope that people will be able to repair, upgrade, and contribute improvements to their printers.It's a nice hope, but they've conveniently banned being able to pay someone else to make parts for you, which will make it harder. Also, not Open Source. (Shared Source is still better than proprietary, but it's not F/OSS.)reply",
      "Seems like a reasonable license for someone who wants to sell their printer, but also publish the designs to allow for repair and for modifications to be shared by the community.reply",
      "While I think NC is a terrible license, hasn't it been settled in court that you can hire someone to produce CC-BY-NC material? You can't run a business selling the material, but you can be hired to produce it.reply",
      "So what workarounds could be had? Contractor business where you hire someone for a few hours to make it for you? Business that sells something else at an elevated price but gives a CC-BY-NC material gift with every purchase?reply",
      "You run 3D printers and they email you the files?reply",
      "In my understanding it should be fine to make parts to order and charge for that, but I may be wrong. What definitely isn\u2019t covered is making parts in advance (anonymously) and sell them later with a profit.reply",
      "tracking dots? https://www.eff.org/pages/list-printers-which-do-or-do-not-d...reply",
      "Do not make this NC licensed. I would like to be able to buy one of these.reply",
      "Selling any parts or upgrades by third parties will be heavily limited by the BY-NC-SA 4.0. You could not build the printer and use it in a small company office.The non-commercial clause is not only unnecessary (who is going to mass market it?), but license also means firmware is proprietary software, it absolutely is not Open Source. Sad to see even seemingly user approached projects building on foundations they misuse the terms of.reply",
      "Of course you could use the printer commercially. You mustn\u2019t sell it. Using the printer is not sharing it\u2019s design.reply"
    ],
    "link": "https://www.notebookcheck.net/Open-Printer-is-an-open-source-inkjet-printer-with-DRM-free-ink-and-roll-paper-support.1126929.0.html",
    "first_paragraph": "The Open Printer, recently unveiled by Paris-based startup Open Tools, is a unique inkjet printer envisioned as the answer to constraints on repairability and cartridge compatibility imposed by all the big brands. Think of it as the printer-equivalent of the Fairphone 6. So, how exactly does it bring the open-source ethos to the printer world?\rFor starters, the creators claim that it's \"built with standard mechanical components and modular parts\", which should simplify assembly, modification, and repair. In fact, the printer runs on a Raspberry Pi W board. There are also no proprietary drivers or cartridge DRM. The Open Printer is designed to use the widely used HP 63 (or HP 302 in Europe) cartridges in both black and colour. You can use both together, or either one.\rPrinter companies (and HP is most notorious for this) embed chips and firmware in their printers and cartridges, which help authenticate whether a cartridge is genuine and disable use if it isn't. Third-party suppliers who"
  },
  {
    "title": "Jules, remote coding agent from Google Labs, announces API (jules.google)",
    "points": 81,
    "submitter": "watkajtys",
    "submit_time": "2025-10-03T19:08:11 1759518491",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45466588",
    "comments": [
      "I have an old Django site I'm maintaining for a long-time customer of mine. They often want to make small changes - things that are only a few lines of code, but would take an hour to just spin up the system, remind myself how it works, commit, push, update the server and all that.Last week I've moved the whole infrastructure to Railway, and taught the customer to use Jules. They make their own PRs now, and Railway spins up an environment with the changes, so the customer can check it themselves. It works like 75% of the time, and when it doesn't, the customer see that it doesn't before it even reaches me. Only if they're happy with the changes, I step in to review the code and press merge. It's been a such a huge time saver so far.reply",
      "How expensive are the API charges? Seems like it might be a bit too easy for a customer to rack up a big bill testing out minor changes if things weren't configured correctly.reply",
      "There is a free plan with 15 tasks/sessions. It doesn\u2019t count tokens AFAIK. There would obviously be a runtime limit of some sorts for sure. But it\u2019s not the same as API keys and token situationreply",
      "I hope they don't store any user data in their app. Trusting LLMs blindly is a bad idea.reply",
      "There is a human being (GP) reviewing the proposed code before merging. I wouldn't describe that as trusting the LLM blindly.reply",
      "It\u2019s a shame Google picked the wrong system design for Jules. Claude Code\u2019s system design is clearly superior at this point.Jules is going to simply be another vendor locked walled garden play.reply",
      "I fail to see how comparing Jules to Claude Code is relevant. They\u2019re completely different.A good Jules comparison would be OpenAI Codex.For a Claude Code Google equivalent there\u2019s Gemini Code Assist CLIreply",
      "I think they are doing both (in true Google fashion), there is an open source Gemini cli with a generous free tier that more directly competes with Claude code. \nhttps://github.com/google-gemini/gemini-cliIt was pretty rough at launch but has gotten a lot better. So has Claude code though, so I\u2019ve never really switched over.reply",
      "I've been using AI coding agents since the very early days of Aider and I think this is not quite true.\nThere's a place for async agents. There's a place for collaborative agents. Collaborative agents may even soon be delegating off to multiple async agents and picking best results. There's so much complexity here and we haven't even begun to explore a corner of the possible design space. We're still trying to plug AIs into human-shaped holes instead of building around their interesting/weird capabilities.reply",
      "Would anyone at Google be willing to tell me how many people are working on this project? I\u2019ve been building something functionally similar for my employer, but it\u2019s a nights and weekends project with only one contributor (me).reply"
    ],
    "link": "https://jules.google/docs/changelog/",
    "first_paragraph": ""
  },
  {
    "title": "When private practices merge with hospital systems, costs go up (yale.edu)",
    "points": 65,
    "submitter": "hhs",
    "submit_time": "2025-10-03T22:58:20 1759532300",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=45468781",
    "comments": [
      "Ah, but deaths\u2026Go up too. https://hms.harvard.edu/news/deaths-rose-emergency-rooms-aft...Part of the problem of modern society is that statistical murder of thousands is treated as less of a crime than a normal murder of one person.reply",
      "These are two distinct issues.The study you linked concerns whether the hospital is owned by a nonprofit or by a private equity group.The question in this study is whether physicians work for their own practice or for the hospital directly, regardless of the ownership of the hospital.reply",
      "This issue is much more linked than you think, because its a strategy to upcode to have external practice groups.reply",
      "That article isn\u2019t about hospitals acquiring practices, it is about private equity acquiring hospitals. There is sometimes a relation, but not always.reply",
      "I hate the US healthcare system but I don't support using the word murder in this context. Murder is very very different from trying to help a person but being greedy while doing it.reply",
      "> trying to help a person but being greedy while doing it.The doctors are trying to help people, the execs are being greedy while doing it. Leadership doesn\u2019t get the benefit of the doubt at this point.reply",
      "But it\u2019s not \u201ca person\u201d. It\u2019s millions of them.reply",
      "I agree it's really sad and fucked up. But the way we deal with murder is long prison sentences and the death penalty. If we introduce horrible incentives for investing in medicine, we won't get compassionate care, we will just eliminate investment in healthcare.We need really thoughtful incentives and simple policies that let doctors run hospitals. Idk it's hard - I was going to say we should reward them for providing better care but I know the pay for performance system in place also hasn't worked that well.reply",
      "Yes, it's much worse.reply",
      "I think you mean murder via diffusion of responsibility is good for business. Its like the trolley problem, but instead of one lever thete a chain of them and at least one of them is the final one, any number of them are like tumblers in a lock.reply"
    ],
    "link": "https://insights.som.yale.edu/insights/when-private-practices-merge-with-hospital-systems-costs-go-up",
    "first_paragraph": "Private practices are vanishing as more doctors join large hospital systems. This increasing consolidation is reducing competition and raising prices, according to a study co-authored by Yale SOM\u2019s Fiona Scott Morton. \u200c\u200cHistorically, physicians worked independently of\u2014if in partnership with\u2014hospitals. But increasingly, doctors are selling their practices to hospital systems, as well as private equity firms and insurance companies. What does it mean for patients and what they pay for healthcare when their doctors are employed by a hospital system?\u200cThe effects of hospital systems acquiring physician practices are hard to determine, because until now, there has been no comprehensive source of data about these mergers and the effects of integration on pricing can be hard to isolate. New research by Yale SOM economist Fiona Scott Morton tackles these challenges, determining the scale of hospital-physician mergers and examining their effects on pricing. In their study, Scott Morton and her c"
  },
  {
    "title": "Niri \u2013 A scrollable-tiling Wayland compositor (github.com/yalter)",
    "points": 423,
    "submitter": "atlintots",
    "submit_time": "2025-10-03T11:08:42 1759489722",
    "num_comments": 206,
    "comments_url": "https://news.ycombinator.com/item?id=45461500",
    "comments": [
      "What was not obvious to me is whether Niri supports something like a fixed panel that would display stuff like clocks, network status, battery charge, CPU load, sound volume, etc, etc.reply",
      "Niri convinced me to give up xmonad. I ran xmonad exclusively for 14 years.Being able to have an unlimited number of windows on a desktop (without continually switching the tiling structure) makes them collections of topics rather than having multiple desktops bounded by what fits comfortably. What used to be a switch from the \"editor and terminals\" desktop to the \"browser\" desktop is now horizontal movement on the current desktop to the related browser window (general browsing is on a different desktop).Really low barrier to entry, works great out of the box. There were some wayland teething issues (application support, e.g., no Zoom), but nothing that couldn't be overcome (occasionally by falling back to X). Most of those have been resolved with time.Edits: \nHardware: 2017 System76 Bonobo WS, 2x GTX 1080, multiple screens (4k @ 2x scaling + 2 1080p). PopOS.I'm running a 1-2 year old build of niri (because it isn't broken), so I've not experienced some of the fancier animations & etc. others dislike.I consider cloning and building from source to be low barrier to entry if it doesn't involve major setup effort (it doesn't/didn't), so I may be biased. Caveat emptor.reply",
      "Niri recently improved it's integration with xwayland-satellite, so it's easier to run programs that don't support wayland now: https://github.com/YaLTeR/niri/wiki/Xwaylandreply",
      "I'm still running an older version (ain't broke, won't fix), but I keep getting recommended the newer versions for features. I'll check them out eventually.reply",
      "can you paste a link?reply",
      "I'm away from the computer at the moment, but I believe I'm on 0.1.3 [0].Noting the release notes, it does have many animations already enabled (but I have some or all of them disabled through config).I'm not recommending anyone run this in favor of newer versions, but it's working for me.[0] https://github.com/YaLTeR/niri/releases/tag/v0.1.3reply",
      "What does xwayland-satellite do that normal xwayland doesn't ?reply",
      "This is addressed on the linked page.Quote:We're using xwayland-satellite rather than Xwayland directly because X11 is very cursed. xwayland-satellite takes on the bulk of the work dealing with the X11 peculiarities from us, giving niri normal Wayland windows to manage.xwayland-satellite works well with most applications: Steam, games, Discord, even more exotic things like Ardour with wine Windows VST plugins. However, X11 apps that want to position windows or bars at specific screen coordinates won't behave correctly and will need a nested compositor to run. See sections below for how to do that.reply",
      "Kind of interesting about the X11 position issue, since that is exactly the issue that I have with Hyprlandreply",
      "For me, the appeal of i3/sway's model is that by having a desktop per topic (eg, one for browser, one for code, one for slack, etc) I can instantly jump to the topic I need with a single key press. The desktops I assign never change, so it's always Super+1 for my browser and Super+4 for Slack. It's all muscle memory, and I could do it in my sleep. When I jump to that desktop, everything is open and tiled. This was a revelation to me coming from MacOS, where I was constantly hunting for windows with Cmd+Tab or squinting at thumbnails in Mission Control. So I'm surprised to hear that you prefer Niri's scroll model, which to me sounds like hunting for windows all over again.reply"
    ],
    "link": "https://github.com/YaLTeR/niri",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        A scrollable-tiling Wayland compositor.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A scrollable-tiling Wayland compositor.\n\n\n\n\nGetting Started | Configuration | Setup\u00a0Showcase\nWindows are arranged in columns on an infinite strip going to the right.\nOpening a new window never causes existing windows to resize.Every monitor has its own separate window strip.\nWindows can never \"overflow\" onto an adjacent monitor.Workspaces are dynamic and arranged vertically.\nEvery monitor has an independent set of workspaces, and there's always one empty workspace present all the way down.The workspace arrangement is preserved across disconnecting and conn"
  },
  {
    "title": "WireGuard topologies for self-hosting at home (garrido.io)",
    "points": 36,
    "submitter": "todsacerdoti",
    "submit_time": "2025-10-03T19:43:34 1759520614",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=45466980",
    "comments": [
      "Having been travelling just now with Wireguard as my primary VPN the main thing I noticed is it's completely unusable on airport wifi.So the big feature I need is any sort of gateway which works over port 80 or 443 natively - ideally at a subpath so it's easy put behind a reverse proxy.reply",
      "My solution to this is a pair of udp ports relayed to each other on a VPS via socat. Then you can point a home WireGuard server (behind cgnat etc) at one, and clients at the other, with no need to trust the vpsreply",
      "I run a similar setup. I didn't end up going for a full router-side hub inside the LAN, to avoid extra hops for things when they're inside the network.Some of my notes:* I have multiple servers outside the LAN that have WG connections back to specific interior systems for things like metrics/log-shipping, monitoring, and backups. All of those are \"point-to-point\" (the cloud-hosted systems have multiple Peers for different internal systems). This means that they can only talk to the things I expect them to, w/o me needing to also handle that at the firewall level.* The Wireguard Mac and iOS apps are very solid. I use them heavily on multiple devices, and they can be trained for OnDemand activation based on SSIDs. This means that when my phone tries to load my NVR dashboard, it uses Wireguard if I'm mobile and doesn't if I'm at home (which saves me a hop through the cloud hub). The iOS app is reliable enough that I set it up once on my partner's phone so they could access the cameras and then never had to think about it again.* Because the only things you need to set up a peer link are shared pubkeys and to agree on IPs, wiring up my endpoints via Puppet was super smooth and adding/adjusting has likewise been smooth. My systems generate a keypair during setup, publish their public key where the other nodes can find it, and all I have to do is update the map of \"hey, this server get this WG-internal IP, and this is who should link to it\".reply",
      "I did the p2p between any sensible nodes in my network then added routing layer via BGP so any node can \"see\" any other node regardless of underlying mesh.The access limits are better served by firewalls than limiting tunellingreply",
      "This sounds interesting. Could you say more? Do you run BGP on the hosts themselves over the Wireguard tunnels? Do you self-manage a Wireguard mesh?reply",
      "An issue with his remote setup is that the remote VPS decrypts packets from the remote laptop, then re-encrypts them for the LAN \u2014 this means that the remote VPS can see the plaintext of all those packets.  He\u2019ll need to layer TLS or something similar, or run Wireguard over Wireguard.reply",
      "What options are available to use a remote VPS to facilitate connecting Wireguard directly through the CGNAT? It seems most \"client\" devices are going to be behind at least some kind of NAT as well.reply",
      "As somebody with a very similar setup, all the things I'm making accessible over the Wireguard network are HTTPS, SSH, etc. The handful of things that couldn't do native TLS (or were irritating to get configured with automated TLS certs) I stuck behind nginx for TLS.reply",
      "Short of setting up dns  validation and using 3rd party dns service as many registrars don't support API for dns management, how is domain validation done for acquiring TLS certs when serving only via wireguard ?There's the private CA route but its a pain to setup the certs on all (mobile) devices and Android makes it very scary and hard.reply",
      "Author here! Indeed, it is mostly HTTPS terminated by Caddy in the server at home. Otherwise, it is SSH.reply"
    ],
    "link": "https://garrido.io/notes/wireguard-topologies-for-self-hosting-at-home/",
    "first_paragraph": "I recently migrated my self-hosted services from a VPS (virtual private server) at a remote data center to a physical server at home. This change was motivated by wanting to be in control of the hardware and network where said services run, while trying to keep things as simple as possible. What follows is a walk-through of how I reasoned through different WireGuard toplogies for the VPN (virtual private network) in which my devices and services reside.Before starting, it\u2019s worth emphasizing that using WireGuard (or a VPN altogether) is ont strictly required for self-hosting. WireGuard implies one more moving part in your system, the cost of which is justified only by what it affords you to do. The constraints that I outline below should provide clarity as to why using WireGuard is appropriate for my needs.It goes without saying that not everyone has the same needs, resources, and threat model, all of which a design should account for. That said, there isn\u2019t anything particularly speci"
  },
  {
    "title": "TrueVault (YC W14) Is Hiring a BDR (Ex-ECommerce Manager) (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-10-03T21:00:32 1759525232",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/truevault/jobs/FaC8Apo-ecommerce-manager-bdr",
    "first_paragraph": "We make Privacy Software for SMBs.We\u2019re looking for a Business Development Rep with real DTC eCommerce experience to help brands simplify privacy compliance. If you\u2019ve been an eCommerce Manager before and want to pivot into SaaS sales, this is your chance to turn that experience into a revenue-driving role at a Y Combinator\u2013backed startup.Privacy is one of the most fundamental rights we have.At TrueVault, we believe that when businesses have access to tools that make compliance simple, respecting consumer privacy becomes the obvious choice \u2014 and everyone wins. That\u2019s why we build software that helps brands comply with complex privacy laws without drowning in legal costs or red tape.We\u2019ve cracked the code on making compliance something companies can handle themselves \u2014 no armies of lawyers required.We\u2019re a Y Combinator\u2013backed startup based in San Francisco, obsessed with building products that solve hard problems and relentless about making our customers successful.Joining TrueVault as "
  },
  {
    "title": "Arenas in Rust (russellw.github.io)",
    "points": 50,
    "submitter": "welovebunnies",
    "submit_time": "2025-10-03T19:47:53 1759520873",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45467032",
    "comments": [
      "> Doesn't that mean you are throwing out all the memory safety properties you were hoping to achieve by using Rust in the first place? ...That argument sounds logical, but it's not actually correct.Actually, it is correct. The more generally you use \"arenas\" the more they are subject to the same kinds of issues as other manual memory management systems. \"arenas\" can only avoid/reduce the \"nondeterminism\" and \"security\" issues of general manual memory management on top of a buffer of bytes by not becoming general manual memory management on top of a buffer of bytes.reply",
      "> Handles are deterministic. If a bug made your program crash on the last run, it will crash the same way on this run.> Given that the arena will still be subject to array bounds checking, handle bugs won't allow an attacker to overwrite arbitrary memory the way pointer bugs do.Just because you're in-bounds of the arena, doesn't mean you're not stomping on in-bounds neighboring data -- which can introduce \"nondeterminism\" as the author defines it. These are hand-waving arguments.reply",
      "Anticipating pushback: yes, you can disallow \"pointer arithmetic\" on handles, and store fingerprints in the \"slots\" to ensure they still contain the handle's identity to detect user-after-free, but congrats, you've implemented sparse sets, which there are dozen's of C++ implementations of with the same safety guarantees, so it's unclear what rust is bringing in that case (e.g. https://github.com/skypjack/entt/blob/master/src/entt/entity...)reply",
      "This is the back-link problem in Rust. You can do back links with weak pointers, but it's rather verbose and involves extra run-time checks.I've been trying to figure out a compile-time approach to that problem. \nHere's an early version of a tech note on that.[1]\nIt looks possible, but there are many issues. But it's important to look at now. The C++ people are trying to figure out safe backlinks.[1] https://github.com/John-Nagle/technotes/blob/main/docs/rust/...reply",
      "I'm a bit agnostic about the specific solution these days. In general, early binding(so, static memory and types, formalized arenas and handles, in-line linear logic with few or no loops or branches) debugs more readily than late(dynamic memory allocs and types, raw pointers, virtual functions, runtime configuration). The appeal of late binding is in deferring the final computation to later so that your options stay open, while the converse is true with early binding - if you can write a program that always returns a precomputed answer, that's easier to grasp and verify.When we compare one method of early binding with another, it's probably going to be a comparison of the granularity. Arenas are \"stupid simple\" - they partition out memory into chunks that limit the blast radius of error, but you still make the error. Ownership logic is a \"picky generalization\" - it lets you be more intricate and gain some assurances if you put up with the procedures necessary, but it starts to inhibit certain uses because its view into usage is too narrow with too many corner cases.If we take Go's philosophy as an example of \"what do you do if you want idioms for a really scalable codebase\" - though you can certainly argue that it didn't work - it's that you usually want to lean on the stupid simple stuff and customize what you need for the rest. You don't opt into a picky Swiss Army Knife unless there's a specific problem to solve with it. Larger codebases have proportionately smaller sections that demand intricacy because more and more of the code is going to itself be a method of defining late binding, of configuring and deferring parts of processing.That said, Rust lets you fall back to \"stupid simple\", it just doesn't pave the way to make that the default.reply",
      "> There are several ways to solve this problem. One way is to avoid using direct references to the particular class of objects at all. Instead, allocate a big array of objects, and refer to them with integer indexes into that array. There are several names that have been used for such arrays and indexes; let's call them arenas and handles.I thought the term \"Arena\" referred to linear allocators, but maybe it's not so narrowly defined.> At one level, this question is not very fair, because an answer to it as stated would be that one simply does not use doubly linked lists. They have been popular in introductory computer science lectures because they are a neat way to explain pointers in a data structure that's easy to draw on a whiteboard, but they are not a good match to modern hardware. The last time I used one was in the nineties. I know the Linux kernel uses them, but that design was also laid down in the nineties; if you were designing a kernel from scratch today, you would probably not do it that way.The arena data structure you described is inefficient unless it uses a linked list to track empty slots.  All general-purpose heap allocators use linked lists in their implementations.  Linked lists show up wherever you want pointer stability, low fragmentation, or a way to decouple the storage of objects from their participation in data structures.  I struggle to imagine how it would be possible to implement something like Linux without at least one linked list in it.> Essentially you are bypassing the notion of pointers provided directly by the hardwarePointers aren't a hardware concept, they're a language concept.  Array indices and pointers both rely on indirect addressing, which is the underlying hardware concept.  The \"handles\" strategy in Rust feels like a kludgy approach not because it bypasses the hardware but because Rust's borrow checker isn't actually involved in ensuring safety in that case, just its bounds checking and mandatory initialization (and if all you need is those two things then...).reply",
      "Here's an implementation of a doubly-linked list which is perfectly fine on modern hardware: an array of structs where each struct contains a pointer to its next and previous elements in addition to whatever other data is being stored.Here's a situation where a traditional pointer-based double-linked list is fine: when the payload is very large (e.g., an entire document in some app).reply",
      "Arenas let you use OOBAs to do data attacks, and those can give you the moral equivalent of remote code execution.Like if your arena contains both a buffer that OOB's and a buffer passed to a syscall, then having memory safety around the arena doesn't help youreply",
      "And as a bonus, they also conveniently opt you out of any other hardening features your system malloc might have implemented (like MTE).I certainly appreciate the performance benefits of custom allocators but it's disheartening to see people naively adopting them just as the world's allocators are starting to get their acts together with regards to security.reply",
      "Yes. This is a big headache in graphics, where there are big tables indexed by texture index down at the GPU level. Managing those as the content changes, with the GPU using the data while the CPU alters it, leads to huge complexity in Vulkan graphics.The two times I've had to deal with a really tough debugging problem in Rust, it's been related to some crate which did that.reply"
    ],
    "link": "https://russellw.github.io/arenas",
    "first_paragraph": "\nAt one level, this question is not very fair, because an answer to it as stated would be that one simply does not use doubly linked lists. They have been popular in introductory computer science lectures because they are a neat way to explain pointers in a data structure that's easy to draw on a whiteboard, but they are not a good match to modern hardware. The last time I used one was in the nineties. I know the Linux kernel uses them, but that design was also laid down in the nineties; if you were designing a kernel from scratch today, you would probably not do it that way.\n\n\nAt another level, it is fair because it is a simple, familiar proxy for all data structures with any kind of circular references. Consider a compiler holding a set of modules that may refer to each other. Or a game where objects may refer to their container. Or a graphic user interface where widgets may refer to a parent window. It might be reasonable to say some particular such structure is not the best solutio"
  },
  {
    "title": "I turned the Lego Game Boy into a working Game Boy (nataliethenerd.com)",
    "points": 202,
    "submitter": "Timothee",
    "submit_time": "2025-10-03T14:18:56 1759501136",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=45463319",
    "comments": [
      "I love projects like this where you have to work around constraints like the Lego form factor and the support electronics for the CPU. In terms of modern hardware, the PCB is surprisingly sparse - using modern surface-mount components really helps.The super detailed silkscreen on the Nintendo PCB does make me wish for the time when all products came with schematics and component specifications...reply",
      "I just built this set yesterday and was thinking to myself 'I wonder how hard it would be to turn this into a functioning gameboy?'\nLooks like I have my answer!reply",
      "This is... very very nice, and why I love the internet, LEGO and maker/hacker type nerds...reply",
      "I pre-ordered this set to do exactly this. Nice to see others have the same idea.Weirdly I only received mine today, I wonder why the difference in pre-order shipment times is so large.reply",
      "Because some sellers don\u2019t respect sales embargo and/or some clients have some privileges.reply",
      "People in the USA have been picking them up for weeks from Costco. I got mine ~2 weeks ago.reply",
      "I saw this set on the shelf in a big toy shop (Smyths) here in the UK a few days ago, didn't realise it was hot off the press.One can definitely go pick one up off the shelf here in the UK as of at least Wednesday (the day I saw them).reply",
      "The startup video doesn\u2019t feature the Game Boy startup sound (nor any other sound), so no sound?reply",
      "This looks cool but that D-Pad is going to hurt after a few minutes of play.reply",
      "The kind of person who does this has many gameboys to play on, this is for art and concept only I imaginereply"
    ],
    "link": "https://blog.nataliethenerd.com/i-turned-the-lego-game-boy-into-a-working-game-boy-part-1/",
    "first_paragraph": "Through my documentation of Game Boy boards, I have drawn up schematics of each device. I know them pretty well. Check out my board scan wiki https://wiki.nataliethenerd.com/I jokingly made this tweet when the kit was announced, but decided to actually do it.that's my opening pic.twitter.com/hJotri3aQPI know from experience of routing Game Boy CPU PCBs that there isn't much to it. There's the RAM, CPU, some decoupling capacitors and power regulation. Note: I went with the MGB (Pocket) CPU rather than DMG for a couple of reasons.The DMG CPU has external VRAM, the MGB CPU has internal VRAM and in a very space conscious build that was the biggest factor.I only had the press pictures to work off. I used the dimensions to scale the image on my PC and from that I got measurements for the screen inserts; since that's where I plan to put the Game Boy.Source: https://www.lego.com/en-au/product/game-boy-72046I incorporated the power circuit I use for my Safer Charger boards, changed the power sw"
  },
  {
    "title": "Binary Formats Gallery (kaitai.io)",
    "points": 8,
    "submitter": "vitalnodo",
    "submit_time": "2025-10-04T00:19:02 1759537142",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45469285",
    "comments": [
      "Interesting. I didn't know anyone had come up with a declarative language for binary files.reply",
      "There's actually more than one, though Kaitai probably has the most maturity of any of them.Various hex editors have their own formats. 010 Editor has C-style binary templates, imhex has a binary pattern language as well. Okteta has Okteta Structure Definitions which can be declared using XML or with JS.Kaitai Struct is the most complete system that has code generation for multiple programming languages and isn't tied to a hex editor or anything else for that matter. That said, I think there's still a ton of room for improvement and innovation. Kaitai has a lot of useful tooling, but I think as it is today it falls a bit short: the code gen is not at the same support level for all languages (most languages are fairly limited), and I think serialization is still mostly experimental. That and there's probably a lot you could do to still make it more expressive and powerful.reply"
    ],
    "link": "https://formats.kaitai.io/",
    "first_paragraph": "All formats in this gallery have formal specifications in Kaitai Struct language. They can be used:For a summary of all entries with associated metadata, see File Format Cross-References.\n            If you've done any format specs using Kaitai Struct that\n            you won't mind to share with the rest of the community \u2014\n            you're most welcome to do so! It's very easy to do:\n        "
  },
  {
    "title": "Cancelling async Rust (sunshowers.io)",
    "points": 161,
    "submitter": "todsacerdoti",
    "submit_time": "2025-10-03T16:18:29 1759508309",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=45464632",
    "comments": [
      "Less clickbaity title: Cancellations in async Rust.It's really not about \"cancelling async Rust\" which is what I expected, even if it didn't make much sense.reply",
      "As the author of the talk/blog post, I was definitely going for a bit of a moral valence in the title, in the sense that future cancellations are very hard to reason about and what I call the least Rusty part of Rust. But it admittedly is a bit clickbaity too.reply",
      "I initially skipped reading it because i thought it was another drama post about maintainers a la all the nixos stuff lately.reply",
      "It made sense to me, because I imagine a thread or coroutine as something that runs code as though it were interpreting something like psuedocode, whether it's doing that or not. So from my point of view an instance of async Rust is being cancelled - not the feature of the Rust project, but instances of code.This abstraction has served me well and facilitates stepping through code in a debugger, though I jump out of thinking it at that level when I need to think of it at a lower level.reply",
      "if onlyreply",
      "+1 this.IMHO async is an anti-pattern, and probably the final straw that will prevent me from ever finishing learning Rust. Once one learns pass-by-value and copy-on-write semantics (Clojure, PHP arrays), the world starts looking like a spreadsheet instead of spaghetti code. I feel that a Rust-like language could be built with no borrow checker, simply by allocating twice the memory. Since that gets ever-less expensive, I'm just not willing to die on the hill of efficiency anymore. I predict that someday Rust will be relegated to porting scripting languages to a bare-metal runtime, but will not be recommended for new work.That said, I think that Rust would make a great teaching tool in an academic setting, as the epitome of imperative languages. Maybe something great will come of it, like Swift from Objective-C or Kotlin from Java. And having grown up on C++, I have a soft spot in my heart for solving the hard problems in the fastest way possible. Maybe a voxel game in Rust, I dunno.reply",
      "> Since that gets ever-less expensive,That kind of thinking made sense in the 90s when things followed Moore\u2019s law. But DRAM was one of the first things to fail to keep up: https://ourworldindata.org/grapher/historical-cost-of-comput... and barely gets cheaper anymore. Thats why mobile phones still only have 16gb of memory despite having 4gib a decade ago.And there\u2019s all sorts of problems that Rust doesn\u2019t necessarily make a great fit for. But Rust\u2019s target marketplace is where you\u2019d otherwise use a low level language like C or C++. If you can just heap allocate everything and aggressively create copies all over the place, then why would you ever use those languages in the first place.And for what it\u2019s worth Rust is finding a lot of success even replacing all the tooling in other language ecosystems like Ruby, Python, and JS precisely because the tools in those ecosystems written in the native language end up being horribly slow. And memory allocation and randomly deep copying arrays are the kinds of things that add up and make things slow (in addition to GC pauses, slow startups, interpreter costs etc).And you can always choose not to do async in Rust although personally I\u2019m a huge fan as it makes it really clear where you have sprinkled in I/O in places you shouldn\u2019t have.reply",
      "Before adopting Rust, I also found it silly for high-level tasks where e.g. Clojure or Java would suffice. However, the results of using Rust changed my mind.I used to write web backends in Clojure, and justified it with the fact that the JVM has some of the best profiling tools available (I still believe this), and the JVM itself exposes lots of knobs to not only fine-tune the GC, but even choose a GC! (This cannot be understated; garbage collectors tend to be deeply integrated into a language's runtime, and it's amazing to me that the Java platform manages to ship several garbage collectors, each of which are optimal in their own specific situations).After rewriting an NLP-heavy web app in Rust, I saw massive performance gains over the original Clojure version, even though both aggressively copy data and the Rust version is full of atomic refcounts (atomic refcounting is not the fastest GC out there...)The binary emitted by rustc is also much smaller. ~10 MB static binary vs. GraalVM's ~80 MB native images (and longer build times, since classpath analysis and reflection scanning require a lot of work)What surprised me the most is how high-level Rust feels in practice. I can use pattern matching, async/await, functional programming idioms, etc., and it ends up being fast anyway. Coming from Clojure, Rust syntax trying its best to be expression-oriented is a key differentiator from other languages in its target domain (notably, C++). I sometimes miss TypeScript's anonymous enums, but Rust's type system can express a lot of of runtime behavior, and it's partly why many jokingly state \"if it compiles, it's likely correct\". Then there's the little things, like how Rust's Futures don't immediately start in the background. In contrast, JavaScript Promises are immediately pushed to a microtask queue, so cancelling a Promise is impossible by design.Overall, it's the little things like this -- and the toolchain (cargo, clippy, rustfmt) -- that have kept me using Rust. I can write high-level code and still compile down to a ~5 MB binary and outperform idiomatic code in other languages I'm familiar with (e.g. Clojure, Java, and TypeScript).reply",
      "Speaking personally, that is what first attracted me to Rust \u2014 that you can write high-level idiomatic code and still get roughly optimal performance.reply",
      "Author here -- I'd recommend reading my blog post about how cargo-nextest uses Tokio + async Rust to handle very complex state machines: https://sunshowers.io/posts/nextest-and-tokio/reply"
    ],
    "link": "https://sunshowers.io/posts/cancelling-async-rust/",
    "first_paragraph": "This is an edited, written version of my RustConf 2025 talk about cancellations in async Rust. Like the written version of my RustConf 2023 talk, I\u2019ve tried to retain the feel of a talk while making it readable as a standalone blog entry. Some links:Let\u2019s start with a simple example \u2013 you decide to read from a channel in a loop and gather a bunch of messages:All good, nothing wrong with this, but you realize sometimes the channel is empty for long periods of time, so you add a timeout and print a message:There\u2019s nothing wrong with this code\u2014it behaves as expected.Now you realize you need to write a bunch of messages out to a channel in a loop:But sometimes the channel gets too full and blocks, so you add a timeout and print a message:It turns out that this code is often incorrect, because not all messages make their way to the channel.Hi, I\u2019m Rain, and this post is about cancelling async Rust. This post is split into three parts:Before we begin, I want to lay my cards on the table \u2013 I "
  },
  {
    "title": "Advanced Matrix Multiplication Optimization on Multi-Core Processors (2024) (salykova.github.io)",
    "points": 27,
    "submitter": "skidrow",
    "submit_time": "2025-10-01T07:31:27 1759303887",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://salykova.github.io/gemm-cpu",
    "first_paragraph": "\nAug 1, 2024\n      \u2022 Amanzhol SalykovTL;DR The code is available at sgemm.c. This blog post walks through optimizing multi-threaded FP32 matrix multiplication on modern processors using FMA3 and AVX2 vector instructions. The implementation delivers strong performance on a variety of x86-64 CPUs, both in single-threaded and multithreaded scenarios. However, to reach peak performance, you\u2019ll need to fine-tune hyperparameters - such as the number of threads, kernel size, and tile sizes. Additionally, on AVX-512 CPUs, the BLAS libraries might be notably faster due to AVX-512 instructions, which were intentionally omitted here to support a broader range of processors. Performance results for Intel Core Ultra 265 and AMD Ryzen 7 9700X are shown below.P.S. Please feel free to get in touch if you are interested in collaborating. My contact information is available on the homepage.Matrix multiplication is an essential part of nearly all modern neural networks. Despite using matmul daily in PyTo"
  }
]