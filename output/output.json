[
  {
    "title": "Claude Cowork Exfiltrates Files (promptarmor.com)",
    "points": 431,
    "submitter": "takira",
    "submit_time": "2026-01-14T20:12:25 1768421545",
    "num_comments": 178,
    "comments_url": "https://news.ycombinator.com/item?id=46622328",
    "comments": [
      "A bit unrelated, but if you ever find a malicious use of Anthropic APIs like that, you can just upload the key to a GitHub Gist or a public repo - Anthropic is a GitHub scanning partner, so the key will be revoked almost instantly (you can delete the gist afterwards).It works for a lot of other providers too, including OpenAI (which also has file APIs, by the way).https://support.claude.com/en/articles/9767949-api-key-best-...https://docs.github.com/en/code-security/reference/secret-se...reply",
      "I wouldn\u2019t recommend this. What if GitHub\u2019s token scanning service went down. Ideally GitHub should expose an universal token revocation endpoint.\nAlternatively do this in a private repo and enable token revocation (if it exists)reply",
      "You're revoking the attacker's key (that they're using to upload the docs to their own account), this is probably the best option available.Obviously you have better methods to revoke your own keys.reply",
      "it is less of a problem for revoking attacker's keys (but maybe it has access to victim's contents?).agreed it shouldn't be used to revoke non-malicious/your own keysreply",
      "Haha this feels like you're playing chess with the hackersreply",
      "Rolling the dice in a new kind of casino.reply",
      "So that after the attackers exfiltrate your file to their Anthropic account, now the rest of the world also has access to that Anthropic account and thus your files? Nice plan.reply",
      "For a window of a few minutes until the key gets automatically revokedAssuming that they took any of your files to begin with and you didn't discover the hidden promptreply",
      "Pretty brilliant solution, never thought of that before.reply",
      "Except is there a guarantee of the lag time from posting the GIST to the keys being revoked?reply"
    ],
    "link": "https://www.promptarmor.com/resources/claude-cowork-exfiltrates-files",
    "first_paragraph": "SolutionsIndustriesPartnersResourcesBook a DemoThreat IntelligenceClaude Cowork Exfiltrates FilesSuperhuman AI Exfiltrates EmailsHN #12IBM AI ('Bob') Downloads and Executes MalwareHN #1Notion AI: Data ExfiltrationHN #4HuggingFace Chat Exfiltrates DataScreen takeover attack in vLex (legal AI acquired for $1B)Google Antigravity Exfiltrates DataHN #1CellShock: Claude AI is Excel-lent at Stealing DataHijacking Claude Code via Injected Marketplace PluginsData Exfiltration from Slack AI via Indirect Prompt InjectionHN #1Data Exfiltration from Writer.com via Indirect Prompt InjectionHN #5Threat IntelligenceTable of ContentTable of ContentTable of ContentClaude Cowork is vulnerable to file exfiltration attacks via indirect prompt injection as a result of known-but-unresolved isolation flaws in Claude's code execution environment.Two days ago, Anthropic released the Claude Cowork research preview (a general-purpose AI agent to help anyone with their day-to-day work). In this article, we demonst"
  },
  {
    "title": "Furiosa: 3.5x efficiency over H100s (furiosa.ai)",
    "points": 38,
    "submitter": "written-beyond",
    "submit_time": "2026-01-15T00:53:21 1768438401",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=46626410",
    "comments": [
      "I am of the opinion that Nvidia's hit the wall with their current architecture in the same way that Intel has historically with its various architectures - their current generation's power and cooling requirements are requiring the construction of entirely new datacenters with different architectures, which is going to blow out the economics on inference (GPU + datacenter + power plant + nuclear fusion research division + lobbying for datacenter land + water rights + ...).The story with Intel around these times was usually that AMD or Cyrix or ARM or Apple or someone else would come around with a new architecture that was a clear generation jump past Intel's, and most importantly seemed to break the thermal and power ceilings of the Intel generation (at which point Intel typically fired their chip design group, hired everyone from AMD or whoever, and came out with Core or whatever). Nvidia effectively has no competition, or hasn't had any - nobody's actually broken the CUDA moat, so neither Intel nor AMD nor anyone else is really competing for the datacenter space, so they haven't faced any actual competitive pressure against things like power draws in the multi-kilowatt range for the Blackwells.The reason this matters is that LLMs are incredibly nifty often useful tools that are not AGI and also seem to be hitting a scaling wall, and the only way to make the economics of, eg, a Blackwell-powered datacenter make sense is to assume that the entire economy is going to be running on it, as opposed to some useful tools and some improved interfaces. Otherwise, the investment numbers just don't make sense - the gap between what we see on the ground of how LLMs are used and the real but limited value add they can provide and the actual full cost of providing that service with a brand new single-purpose \"AI datacenter\" is just too great.So this is a press release, but any time I see something that looks like an actual new hardware architecture for inference, and especially one that doesn't require building a new building or solving nuclear fusion, I'll take it as a good sign. I like LLMs, I've gotten a lot of value out of them, but nothing about the industry's finances add up right now.reply",
      "Thanks for this. It put into words a lot of the discomfort I\u2019ve had with the current AI economics.reply",
      "> nothing about the industry's finances add up right nowNothing about the industry\u2019s finances, or about Anthropic and OpenAI\u2019s finances?I look at the list of providers on OpenRouter for open models, and I don\u2019t believe all of them are losing money. FWIW Anthropic claims (iirc) that they don\u2019t lose money on inference. So I don\u2019t think the industry or the model of selling inference is what\u2019s in trouble there.I am much more skeptical of Anthropic and OpenAI\u2019s business model of spending gigantic sums on generating proprietary models. Latest Claude and GPT are very very good, but not better enough than the competition to justify the cash spend. It feels unlikely that anyone is gonna \u201cwinner takes all\u201d the market at this point.reply",
      "> but nothing about the industry's finances add up right now.The acquisitions do. Remember Groq?reply",
      "Got excited, then I saw it was for inference. yawnsSeems like it would obviously be in TSMCs interest to give preferential taping to nvidia competitors, they benefit from having a less consolidated customer base bidding up their prices.reply",
      "What can it actually run? The fact their benchmark plot refers to Llama 3.1 8b signals to me that it's hand implemented for that model and likely can't run newer / larger models. Why else would you benchmark such an outdated model? Show me a benchmark for gpt-oss-120b or something similar to that.reply",
      "Looking at their blog, they in fact ran gpt-oss-120b: https://furiosa.ai/blog/serving-gpt-oss-120b-at-5-8-ms-tpot-...I think Llama 3 focus mostly reflects demand. It may be hard to believe, but many people aren't even aware gpt-oss exists.reply",
      "really weird graph where they're comparing to 3x H100 PCI-E which is a config I don't think anyone is using.they're trying to compare at iso-power? I just want to see their box vs a box of 8 h100s b/c that's what people would buy instead, and they can divide tokens and watts if that's the pitch.reply",
      "The positioning makes sense, but I\u2019m still somewhat skeptical.Targeting power, cooling, and TCO limits for inference is real, especially in air-cooled data centers.But the benchmarks shown are narrow, and it\u2019s unclear how well this generalizes across models and mixed production workloads. GPUs are inefficient here, but their flexibility still matters.reply",
      "This is from September 2025, what's new?reply"
    ],
    "link": "https://furiosa.ai/blog/introducing-rngd-server-efficient-ai-inference-at-data-center-scale",
    "first_paragraph": "\n          AI Accelerators\n        \n          Developer Experience\n        \n          AI Accelerators\n        \n          Developer Experience\n        \nNews\n\n                    September 25, 2025\n                  \nShare this article\n            We are excited to introduce FuriosaAI\u2019s NXT RNGD Server\u2014our first branded, turnkey solution for AI inference.\n        Built around our RNGD accelerators, NXT RNGD Server is an optimized system that delivers high performance on today\u2019s most important AI workloads while fitting seamlessly into existing data center environments.  With NXT RNGD Server, enterprises can move from experimentation to deployment faster than ever. The system ships with the Furiosa SDK and Furiosa LLM runtime preinstalled, so applications can serve immediately upon installation. We optimized the platform over standard PCIe interconnects, eliminating the need for proprietary fabrics or exotic infrastructure.Designed for compatibility, NXT RNGD Server runs at just 3 kW per "
  },
  {
    "title": "Anthropic Explicitly Blocking OpenCode (gist.github.com)",
    "points": 97,
    "submitter": "ryanvogel",
    "submit_time": "2026-01-15T00:04:24 1768435464",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=46625918",
    "comments": [
      "I do admit to feeling some schadenfreude over them reacting to their product being leeched by others.I get it though, Anthropic has to protect their investment in their work. They are in a position to do that, whereas most of us are not.reply",
      "They cannot actually do this as long as they keep Claude code open source. It is always going to be trivial to replicate how it sends requests in a third party tool.reply",
      "Hey! It was a lot of work stealing everything from you, of course you have to pay me a premium to get access to it!reply",
      "Seems like another donation to python is coming to mitigate this pr scandalreply",
      "Obviously Anthropic are within their rights to do this, but I don\u2019t think their moat is as big as they think it is. I\u2019ve cancelled my max subscription and have gone over to ChatGPT pro, which is now explicitly supporting this use case.reply",
      "Is opencode that much better than Codex / Claude Code for cli tooling that people are prepared forsake[1]  Sonnet 4.5/Opus 4.5 and switch to GPT 5.2-codex ?The moat is Sonnet/Opus not Claude Code it can never be a client side app.Cost arbitrage like this is short lived, until the org changes pricing.For example Anthropic could release say an ultra plan at $500-$1000 with these restrictions removed/relaxed that reflects the true cost of the consumption, or get cost of inference down enough that even at $200 it is profitable for them and they will stop caring if higher bracket does not sell well, Then $200 is what market is ready to pay, there will be a % of users who will use it more than the rest as is the case in any software.Either way the only money here i.e. the $200(or more) is only going to Anthropic.[1] Perceived or real there is huge gulf in how Sonnet 4.5 is seen versus GPT 5.2-codex .reply",
      "Given that Claude Code is a scriptable CLI tool with an SDK, why can't OpenCode just call Claude instead of reusing its auth tokens?reply",
      "You can't control it to the level of individual LLM requests and orchestration of those. And that is very valuable, practically required, to build a tool like this. Otherwise, you just have a wrapper over another big program and can barely do anything interesting/useful to make it actually work better.reply",
      "What can't you do exactly? You can send the Claude binary arbitrary user prompts\u2014with arbitrary custom system prompts\u2014and get text back. You can then put those text responses into whatever larger system you want.reply",
      "May as well just use Claude Code then."
    ],
    "link": "https://gist.github.com/R44VC0RP/bd391f6a23185c0fed6c6b5fb2bac50e",
    "first_paragraph": "\n        Instantly share code, notes, and snippets.\n      "
  },
  {
    "title": "Scaling long-running autonomous coding (cursor.com)",
    "points": 107,
    "submitter": "samwillis",
    "submit_time": "2026-01-14T22:18:04 1768429084",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=46624541",
    "comments": [
      "> While it might seem like a simple screenshot, building a browser from scratch is extremely difficult.> Another experiment was doing an in-place migration of Solid to React in the Cursor codebase. It took over 3 weeks with +266K/-193K edits. As we've started to test the changes, we do believe it's possible to merge this change.In my view, this post does not go into sufficient detail or nuance to warrant any serious discussion, and the sparseness of info mostly implies failure, especially in the browser case.It _is_ impressive that the browser repo can do _anything at all_, but if there was anything more noteworthy than that, I feel they'd go into more detail than volume metrics like 30K commits, 1M LoC. For instance, the entire capability on display could be constrained to a handful of lines that delegate to other libs.And, it \"is possible\" to merge any change that avoids regressions, but the majority of our craft asks the question \"Is it possible to merge _the next_ change? And the next, and the 100th?\"If they merge the MR they're walking the walk.If they present more analysis of the browser it's worth the talk (not that useful a test if they didn't scrutinize it beyond \"it renders\")Until then, it's a mountain of inscrutable agent output that manages to compile, and that contains an execution pathway which can screenshot apple.com by some undiscovered mechanism.reply",
      "> it's a mountain of inscrutable agent output that manages to compileBut is this actually true? They don't say that as far as I can tell, and it also doesn't compile for me nor their own CI it seems.reply",
      "Hah I don't know actually! I was assuming it must if they were able to get that screenshot video.reply",
      "error: could not compile `fastrender` (lib) due to 34 previous errors; 94 warnings emittedI guess probably at some point, something compiled, but cba to try to find that commit. I guess they should've left it in a better state before doing that blog post.reply",
      "I find it very interesting the degree to which coding agents completely ignore warnings. When I program I generally target warning-free code, and even with significant effort in prompting, I haven't found a model that treats warnings as errors, and they almost all love the \"ignore this warning\" pragmas or comments over actually fixing them.reply",
      "You can use hooks to keep them from being able to do this btwreply",
      "unfortunately this is not the most common practice. I've worked on rust codebases with 10K+ warning. and rust was supposed to help you.It is also close to impossible run any node ecosystem without getting a wall of warnings.You are an extreme outlier for putting in the work to fix all warningsreply",
      "`cargo clippy` is also very happy with my code. I agree and I think it's kind of a tragedy, I think for production work warnings are very important. Certainly, even if you have a large number of warnings and `clippy` issues, that number ideally should go down over time, rather than up.reply",
      "Yeah I've had problems with this recently. \"Oh those are just warnings.\" Yes but leaving them will make this codebase shit in short time.I do use AI heavily so I resorted to actually turning on warnings as errors in the rust codebases I work in.reply",
      "Oh it doesn\u2019t compile? that\u2019s very revealingreply"
    ],
    "link": "https://cursor.com/blog/scaling-agents",
    "first_paragraph": "We've been experimenting with running coding agents autonomously for weeks.Our goal is to understand how far we can push the frontier of agentic coding for projects that typically take human teams months to complete.This post describes what we've learned from running hundreds of concurrent agents on a single project, coordinating their work, and watching them write over a million lines of code and trillions of tokens.Today's agents work well for focused tasks, but are slow for complex projects. The natural next step is to run multiple agents in parallel, but figuring out how to coordinate them is challenging.Our first instinct was that planning ahead would be too rigid. The path through a large project is ambiguous, and the right division of work isn't obvious at the start. We began with dynamic coordination, where agents decide what to do based on what others are currently doing.Our initial approach gave agents equal status and let them self-coordinate through a shared file. Each agen"
  },
  {
    "title": "The State of OpenSSL for pyca/cryptography (cryptography.io)",
    "points": 69,
    "submitter": "SGran",
    "submit_time": "2026-01-14T22:04:10 1768428250",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=46624352",
    "comments": [
      "I think this part is really worth engaging with:> Later, moving public key parsing to our own Rust code made end-to-end X.509 path validation 60% faster \u2014 just improving key loading led to a 60% end-to-end improvement, that\u2019s how extreme the overhead of key parsing in OpenSSL was.> The fact that we are able to achieve better performance doing our own parsing makes clear that doing better is practical. And indeed, our performance is not a result of clever SIMD micro-optimizations, it\u2019s the result of doing simple things that work: we avoid copies, allocations, hash tables, indirect calls, and locks \u2014 none of which should be required for parsing basic DER structures.I was involved in the design/implementation of the X.509 path validation library that PyCA cryptography now uses, and it was nuts to see how much performance was left on the ground by OpenSSL. We went into the design prioritizing ergonomics and safety, and left with a path validation implementation that's both faster and more conformant[1] than what PyCA would have gotten had it bound to OpenSSL's APIs instead.[1]: https://x509-limbo.comreply",
      "It is extremely common that a correct implementation also has excellent performance.Also, even if somebody else can go faster by not being correct, what use is the wrong answer?  https://nitter.net/magdraws/status/1551612747569299458reply",
      "> It is extremely common that a correct implementation also has excellent performance.I think that's true in general, but in the case of X.509 path validation it's not a given: the path construction algorithm is non-trivial, and requires quadratic searches (e.g. of name constraints against subjects/SANs). An incorrect implementation could be faster by just not doing those things, which is often fine (for example, nothing really explodes if an EE doesn't have a SAN[1]). I think one of the things that's interesting in the PyCA case is that it commits to doing a lot of cross-checking/policy work that is \"extra\" on paper but stills comes out on top of OpenSSL.[1]: https://x509-limbo.com/testcases/webpki/#webpkisanno-sanreply",
      "I\u2019d say correct common path.  OpenSSL due to hand waving deals with a lot of edge cases the correct path doesn\u2019t handle.  Even libraries like libnss suffers from this.reply",
      "Remember LibreSSL? That was borne of Heartbleed IIRC, and I remember presentation slides saying there was stuff in OpenSSL to support things like VAX, Amiga(?) and other ancient architectures. So I wonder if some of the things are there because of that.reply",
      "Now I wonder how much performance is being left on the table elsewhere in the OpenSSL codebase...reply",
      "Given the massive regression with 3.x alone, you'll probably be happier if you don't know :/reply",
      "The article highlights Haproxy's blog with essentially the same name (from 2025): https://www.haproxy.com/blog/state-of-ssl-stacksSince that Haproxy has effectively abandoned OpenSSL in favor or AWS-LC. Packages Re still built with both, but AWS-LC is clearly the path forward for them.reply",
      "By the way, pyca/cryptography is a really excellent cryptography library, and I have confidence that they're making the right decisions here. The python-level APIs are well thought-out and well documented. I've made a few minor contributions myself and it was a pleasant experience.And my personal \"new OpenSSL APIs suck\" anecdote: https://github.com/openssl/openssl/issues/19612 (not my gh issue but I ran into the exact same thing myself)> I set out to remove deprecated calls to SHA256_xxx to replace them with the EVP_Digestxxx equivalent in my code. However it seems the EVP code is slow. So I did a quick test (test case B vs C below), and it is indeed about 5x slower.reply",
      "I'm glad that they're considering getting rid of OpenSSL as a hard dependency. I've built parts of pyca/cryptography with OpenSSL replaced or stripped out for better debugging. OpenSSL's errors just suck tremendously. It shouldn't be tremendously difficult for them to do it for the entire package.Though I'd also love to see parts of pyca/cryptography being usable outside of the context of Python, like the X.509 path validation mentioned in other comments here.reply"
    ],
    "link": "https://cryptography.io/en/latest/statements/state-of-openssl/",
    "first_paragraph": ""
  },
  {
    "title": "Ask HN: Share your personal website",
    "points": 396,
    "submitter": "susam",
    "submit_time": "2026-01-14T17:07:42 1768410462",
    "num_comments": 1268,
    "comments_url": "https://news.ycombinator.com/item?id=46618714",
    "comments": [
      "My website is at https://mulquin.comI used to care that I wasn't \"writing enough\" and that I spent more time tinkering with the code than making content. But the reality is that I'm the main audience and that anxiety was coming from potential perception of others.Tinker away tinkerers!reply",
      "I got excited at the headline of this post because I love the idea of community maintained personal site directories. Was disappointed to get into the description and linked Git repository and learn that it's only for sites that have gotten some traction on hacker news before. Was hoping it would be a way to stumble upon potentially underrepresented content from folks in the hacker news community who don't normally get attention.This is probably a \"me\" problem for assuming otherwise (you even have HN in your URL), but it's not what I expected from a post asking people to share their personal websites.edit: judging by the number of personal website links posted here that do not meet that criteria, it appears I was not the only one with the wrong impression.reply",
      "https://simonsarris.com - My sitehttps://map.simonsarris.com - My newsletter sitehttps://garden.simonsarris.com - My garden designer site. Currently making this so anyone can use it! Public alpha at the end of the month I hope.https://meetinghouse.cc - My site for helping twitter users find each otherhttps://carefulwords.com - My very fast thesaurus sitereply",
      "> https://meetinghouse.cc - My site for helping twitter users find each otherThis would be nice for Bluesky. I deleted my account on Twitter after it turned into a hellscape.reply",
      "I'm an English teacher - I'll be sharing carefulwords with my students and faculty. Thank you, it's bloody great.reply",
      "The garden website if beautifully done actually. I quite like how imperfect and non-straight the lines are eg of the housereply",
      "wow! I love how the background/header generates as the page loads and you can click to add things on it. Overall, the design if amazing!reply",
      "Love your garden! How big is your section? Or is this hypothetical?Do you keep geese?I noticed that tree sizes go to 200 if you put nonsense on the field (text emoticon etc).reply",
      "I have about 7 acres. I kept geese once but they were killed when they ran off with a local 5K that ran by my house and they followed. They were never found.I have kept ducks (meat) and chickens (eggs) at various times, but I ate all the ducks and I gave away the chickens just last month. Unfortunately free ranging chickens have been very destructive to my gardening, and I am trying to make the 2nd largest rose garden in NH, so that goal has priority.reply",
      "how did you make those animations on your main site?reply"
    ],
    "link": "item?id=46618714",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: WebTiles \u2013 create a tiny 250x250 website with neighbors around you (kicya.net)",
    "points": 116,
    "submitter": "dimden",
    "submit_time": "2026-01-10T00:32:10 1768005130",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46561341",
    "comments": [
      "I'm immediately amazed at how many neat 'small web' sites, seemingly made with love by nice human people, have claimed tiles already. Browsing around the tiles that look interesting feels like peeking through a time portal at 2001, in the very best way.In this way it really beats milliondollarhomepage since most of that was just ads for the moneymakers of the day.reply",
      "Reminds me a bit of http://www.milliondollarhomepage.comOld Internet times that will probably never come back.reply",
      "I wonder how much of that would be left standing today if you blanked out all the dead/squatted links...reply",
      "I owned a nice little parcel, but my registrar had issues with a payment and the email got swallowed up and I didn't notice. Forgot to check up on it because I paid for several years up front at a time. Oh well :)reply",
      "The Alaska Mint is the only link I clicked that still workedreply",
      "Pianoverse shows up in one of the tiles. Clicking on the piano keys in the tile produced tones!!\nPianoverse is here, https://pianoverse.net/reply",
      "Link to pianoverse.net tile, so satisfying to play with: https://webtiles.kicya.net/#875,125I also created an interactive tile based on my vanilla-tilt.js library for my app: https://webtiles.kicya.net/#625,3875reply",
      "This is really cool! How are you sandboxing the tiles and allowing limited JS execution?reply",
      "I'm using JS-Interpreter project: https://github.com/NeilFraser/JS-Interpreter . It's slow, but easy to add and work with.reply",
      "This immediately reminded of https://ourworldofpixels.com/reply"
    ],
    "link": "https://webtiles.kicya.net/",
    "first_paragraph": "Loading...Please complete the captcha to continue."
  },
  {
    "title": "Billion-Dollar Idea Generator (pivotgpt.ceo)",
    "points": 22,
    "submitter": "greenRust",
    "submit_time": "2026-01-14T23:49:34 1768434574",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=46625766",
    "comments": [
      "> I'm building Fullstack AI for DefenseYeah, I think this could be taken to a billion-dollar idea within a couple of months, if the implementation is decent.Full-stack would probably mean, in context, something from Palantir-style data-mining and aggregation, through logistics/legal/command/etc., all the way to autonomous systems operating on the front lines.I don't think that anything of this sort actually exists yet?  I imagine it could exist, though, especially in smaller countries that feel threatened, and which have fewer layers of bureaucracy, e.g. Estonia.reply",
      "From the rapidly changing letters during generation, I can only assume this is powered by a custom text diffusion model, not a boring old autoregressive transformer. (because clearly this would show up in the front end.) Text diffusion is hot right now, are you selling equity? Since its already in production, probably series A- valuation of 2 billion sound right?reply",
      "At zombocom, everything is possible!reply",
      "> I'm building The Operating System for DevelopersBoom, slam-dunk.reply",
      ">I\u2019m building Voice AI for AccountantsOh lord\u2026reply",
      "I'm building The Marketplace for Defense. (!)reply",
      "> I'm building API for Developerschecks outreply",
      "> I'm building The Operating System for SMBsit's a geniusreply",
      "Some of these are almost definitely billion-dollar ideas. For instance, Cursor for Developers.Lovable for Property Managers? Probably not.reply",
      "I'm building API for Delivering Payloadsreply"
    ],
    "link": "https://www.pivotgpt.ceo/",
    "first_paragraph": "Your next billion-dollar pivot, powered by AI*\nClick the button to discover your destiny\n"
  },
  {
    "title": "Generate QR Codes with Pure SQL in PostgreSQL (tanelpoder.com)",
    "points": 41,
    "submitter": "tanelpoder",
    "submit_time": "2026-01-10T16:19:42 1768061982",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://tanelpoder.com/posts/generate-qr-code-with-pure-sql-in-postgres/",
    "first_paragraph": "As my cat woke me up way too early for a Saturday morning, I decided to put all this extra time (and my ChatGPT Pro subscription) into good use and generated a QR-code generator for PostgreSQL, written as a single pure SQL statement. No external libraries or Postgres extension installation needed!The pqr.sql example usage is simple:There\u2019s also a bit more complex version pqrsafe.sql that raises an error if you\u2019re trying to encode a too long payload into the QR code (the basic version would just generate a QR code that doesn\u2019t \u201cread\u201d).I did this purely for fun and learning, I don\u2019t think this is going to be the best way for generating QR codes in production. But optimizing this SQL to run faster should be a fun learning exercise. PostgreSQL 17 ran it much faster than 16 in my lab, haven\u2019t gotten to compare the execution plans yet.Fun fact: about 20 years ago, I spent my entire Sunday manually writing an important production fish generator utility for large-scale Oracle databases. Today "
  },
  {
    "title": "Why some clothes shrink in the wash and how to unshrink them (swinburne.edu.au)",
    "points": 431,
    "submitter": "OptionOfT",
    "submit_time": "2026-01-11T02:58:36 1768100316",
    "num_comments": 238,
    "comments_url": "https://news.ycombinator.com/item?id=46572307",
    "comments": [
      "I'm down to just a few sweat shirts and over shirts from the 80s, but they are hanging in there.  Both the colors and the fabric.  When the subject comes up with friends who ask about a particular shirt I joke, \"The cotton was tougher back then\".  Recently, I've had jeans, shirts, and even socks that didn't make it through a single summer.Is anyone else freaked out about cleaning their dryer's lint filter given all the new fabric materials?  I'm putting together a dryer-vac system to keep it from billowing into the air of our small laundry room.reply",
      "I can confirm that you really don't want to breathe in any of that crap.A year and a half ago I developed symptoms of what was some form of bronchitis.  Lots of mucus, constantly coughing, etc.  I was pretty freaking sick.  I tend to wait some things like this out, but it wasn't going away so I went to a doctor and got some medications including albuterol and some kind of steroid (prednisone, I think).  It got a little more manageable, but didn't seem to be getting any better.One day, I realized how much of a dumbass I was the whole time.The apartment I was living in had a laundry room, but it was tiny and I got tired of both hauling laundry up and down multiple flights of stairs and having to fight for time with the few machines that were there.  I bought a small washer and dryer pair from Black & Decker which were designed for apartment living.  Kinda off topic, but there were no hookups in my unit, so I had to jerryrig a water connection using some collapsible garden hoses that connected to my shower and its drain.  Was kinda hilarious but worked great.I made the mistake of thinking that I could just allow the dryer to blow through two sets of lint traps and have a fan blow air out of the window to manage moisture and remaining lint making it through.  What I didn't realize was how inadequate the traps were.  Because I worked from home, I spent a lot of time in that bedroom, including when the dryer was running.  I was breathing in all sorts of stuff without knowing it.Once I stopped hanging out in that room while the dryer was running, bought an air purifier, and made sure to frequently clean my apartment of dust, my symptoms rapidly started to go away.If I had to do all of that again, and I couldn't just have the dryer blow directly out the window, I would find some way to have it do a second pass through a HEPA filter, perhaps after drying the air with something like calcium chloride.I shudder to think of all the microplastic fibers that remain somewhere in my body.reply",
      "We have a washing machine that also has a drier function. It dries much slower than a standalone drier as it consumes water during the drying circle to cool and condense the hot air from the clothes. But the big plus is that it works in mostly closed cycle reusing the air. And there is no need to clean the filter, just unclog the sink pipes once in few months.reply",
      "I got a drying closet. It's basically a heater in a tent with a few vents. It takes almost twice as long as a similarly sized tumble-drying machine, but absolutely nothing but warm, moist air is exhausted into the room. I even use it to supplement a space heater.reply",
      "Also definitely look into ventless dryers - while not as quick as a vented one, the heat pump versions have come a long way from the classic condenser styles of the past.reply",
      "Our ventless dryer is great. Maybe it takes 50% longer, but we're not running multiple loads a day so who cares? Smaller to medium sized electric ventless dryers are the most efficient dryers out there. (Of course we also just use clothes racks to dry stuff.)reply",
      "Your symptoms are pretty similar to what I experienced after using a dry powder fire extinguisher in a confined space a few years ago.reply",
      "If you were never a smoker, hopefully your mucociliary escalator can deal with all the lint you inhaled!reply",
      "There's still good fabrics out there you just have to pay for them. I've mostly replaced my wardrobe now with natural undyed cottons and wools from the likes of \"unbleached apparel\" and \"industry of all nations\". There is cotton grown in new mexico, socks spun in north carolina. \"Filson\" makes a few things in Seattle. Don't skip the stuff made in Peru or India neither.reply",
      "I really like the look of those unbleached + un-dyed shirts, but Unbleached Apparel and Industry of All Nations don't seem to have tall sizes :(reply"
    ],
    "link": "https://www.swinburne.edu.au/news/2025/08/why-some-clothes-shrink-in-the-wash-and-how-to-unshrink-them/",
    "first_paragraph": "More from Swinburne UniversityWashing your favourite piece of clothing only to find out it shrank can be upsetting. Why does it happen, and how can you 'unshrink' it?\u00a0\u00a0Analysis for The Conversation by textiles scientist Dr Nisa SalimWhen your favourite dress or shirt shrinks in the wash, it can be devastating, especially if you followed the instructions closely. Unfortunately, some fabrics just seem to be more prone to shrinking than others \u2013 but why?Understanding more about the science of\u00a0textile fibres\u00a0can not only help you prevent the shrinkage of clothing, but also might help you \u201crescue\u201d the occasional garment after a laundry accident.To know more about clothing shrinkage, we first need to understand a little about how textiles are made.Common textile fibres, such as cotton and linen, are made from plants. These fibres are irregular and crinkled in their natural form. If you zoom deeper inside them, you\u2019ll see millions of tiny, long-chain cellulose molecules that naturally exist i"
  },
  {
    "title": "Sun Position Calculator (drajmarsh.bitbucket.io)",
    "points": 58,
    "submitter": "sanbor",
    "submit_time": "2026-01-14T21:26:51 1768426011",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=46623761",
    "comments": [
      "Archived version: https://web.archive.org/web/20260111135022/https://drajmarsh...",
      "Awesome, thanks for the backup link.Amazing visualizer!reply",
      "Some friends flew eastwards from New York to Singapore on a direct flight (it's one of the longest flights). I wondered what their experience of sunrises and sunsets were (they departed 10PM), I've noted down the times but haven't plotted it...Later this year I'm flying from Europe to the West Coast of Canada, and it seems I'll be in daylight for the entirity of the flight (departing 2PM local, landing 4PM local after a 10 hour flight).Edit: well, FR24 has a handy flight tracking that includes the daylight progression: https://www.flightradar24.com/data/flights/sq23#3de5a306So they flew 18 hours and experienced a full daylight cycle, arriving just before the second sunrise...reply",
      "I flew from central US to western asia (via moscow) and it was an interesting experience for the reasons you mentioned. I think I left early Saturday morning local time and arrived Sunday evening local time. I saw a sunrise, sunset, sunrise, sunset in 18 hours of travel time.reply",
      "I wonder what the physical toll on a man exprriencing three consecutive solar days?reply",
      "This is a cool visualization.  I wonder if it uses the excellent solpos.c library from NREL as the core engine?https://www.nrel.gov/grid/solar-resource/solposreply",
      "I recommend activating \"Show Illuminating Sun Beam\" under \"Explanatory tools\" by clicking the graduation cap icon in the top right corner.reply",
      "Rate limit for this resource has been exceededreply",
      "Love it. Needs a moon.reply",
      "This is incredibly cool!reply"
    ],
    "link": "https://drajmarsh.bitbucket.io/earthsun.html",
    "first_paragraph": "\n                This page requires a reasonably modern HTML5 browser\n                with both Javascript and WebGL enabled.\n            \n                If this message is not soon replaced by an interactive 3D model,\n                then it is likely that your browser does not support this web app.\n                Check your JavaScript Console\n                for specific error messages.\n            \nShow a white background without stars to make screen captures better for printed mediums.\n\nHighlights the latitude and longitude angles of the current site to clearly show how positions\n                                on the Earth's surface are specified.\n\nDisplays an illustrative beam of light illuminating the Earth directly from the Sun.\n                                This can be useful for more clearly indicating the direction of the Sun.\n\nA short animation that shows how the Arctic and Antarctic circles mark the extremes\n                                of night and day at each seas"
  },
  {
    "title": "SparkFun Officially Dropping AdaFruit due to CoC Violation (sparkfun.com)",
    "points": 384,
    "submitter": "yaleman",
    "submit_time": "2026-01-14T14:34:57 1768401297",
    "num_comments": 380,
    "comments_url": "https://news.ycombinator.com/item?id=46616488",
    "comments": [
      "hi, phil here \u2014 post on adafruit here:\nhttps://blog.adafruit.com/2026/01/12/discontinuing-the-teens...i\u2019ll stop back and answer anything (sparkfun will not?).sparkfun is the exclusive maker and distributor of the closed-source teensy and informed us we will not be able to purchase the teensy. this happened after i sent an email reporting the founder, nate, for multiple harassing actions directed at limor, including behavior by him and a former employee.instead of addressing that, they decided to kill the messenger, me, and also cut us off from teensy.so! instead of posting weirdo \"code of conduct\" letters, we are doing an open-source alternative. so customers are not stranded, and this is not a supply chain emergency for us. looking forward to seeing which one delights customers more.as much as nate wants to continue trying to damage limor\u2019s business and adafruit by scraping our site, and now potentially not paying royalties owed after more than a decade of consistent payments, that\u2019s nothing new. it\u2019s a business strategy to cut others out, not a mystery or a \u201cprivate drama.\u201dthis is exactly why we do open source. when a closed product or exclusive channel is used as leverage, the correct response is to remove the leverage.sparkfun chose to publish a vague public accusation. once you do that, speculation is inevitable.ask away!reply",
      "If it means anything, the first thought I had reading this post was \"I wonder how SparkFun is exaggerating or misrepresenting this situation, because I can't believe Adafruit of all organizations is in the wrong here.\"reply",
      "> because I can't believe Adafruit of all organizations is in the wrong here.I've been hearing about this drama through a group chat for a long time. To be honest, neither side looks good in this one. Both companies have behaved disappointingly at different times for different reasons. I'm not doing this is an arbitrary \"both sides\" dismissal. There have been actions from both companies that would have been unacceptable in isolation.The OSHW world revolves a lot around conferences, social media, and IRC/Matrix/Discord servers. Not coincidentally, this feels a lot like old IRC and forum drama of years past.reply",
      "Both companies are pretty small and presumably exist because their owners are passionate about hobby electronics. Honestly, I'd rather have companies like that ran by (flawed) humans than by PR robots.If they want to air their dirty laundry in public, I'm happy to grab popcorn and watch. I'm honestly shocked by the number of folks on this thread who don't know the specifics, and most probably never even bought anything from Sparkfun or Adafruit, but still want to condemn one of the companies in the strongest possible terms...reply",
      "Thanks for the message. Which IRC channel should I join?reply",
      "See additional context for the accusation(s) here[0].[0] https://forum.pjrc.com/index.php?threads/open-source-teensy-...reply",
      "My take away from this link is not what Adafruit probably wants.> we told sparkfun they needed to get their house in order> that was the big issue i wanted them to get some hr training on, or _something_You don't tell or demand another company do something with their own employees. There's more professional ways of dealing with a situation like this.Request a meeting. Send a calm, collected, professional email to a decision-maker and be sure it's well sourced and factual. Keep things in private.If the other party decides not to take action, then make a decision if you want to continue doing business with them. Do not keep pressuring them for the outcome you want, do not escalate the situation, and certainly don't drag the dirty laundry out into the public.Like, what good did Adafruit actually think was going to come from getting into a fight with the founder of Sparkfun? 50 lashings with a wet noodle?Whatever Sparkfun allegedly did to cause this, Adafruit looks pretty poor in this light. I've been a long time customer of both Adafruit and Sparkfun, and will continue to be - but this is some rookie, amateur, hot-headed behavior from Adafruit.reply",
      "They seem to have reported it in private and were then banned and publicly accused of Code of Conduct violations in retaliation. Going public with everything would seem to be the reasonable response.reply",
      "Sure, but they did so by going to the Teensy forum, which is not a SparkFun site, and really made a stink. If going public is reasonable, they did it in the least reasonable way.reply",
      "after a decade of dealing with the founder's bullying, i had enough, looking back almost every year there was something. we did handle things privately until it was clear nothing was going to change, the only real change is we cannot buy teensy, a closed source board sparkfun exclusively makes now, maybe they (sparkfun) will stop paying the payments on something that had to agreed to, and have, we'll see.reply"
    ],
    "link": "https://www.sparkfun.com/official-response",
    "first_paragraph": "\nYou have added \n\n to your comparison list.\nThis is a carousel. Use Next and Previous buttons to navigate, or jump to a slide with the slide dots. SparkPNTWhat is GPS RTK?Building A GPS SystemThis is a carousel. Use Next and Previous buttons to navigate, or jump to a slide with the slide dots. Connecting Thing Plus Matter to Google Nest HubWorking with WifiDisplaying Sensor Data with BluetoothThis is a carousel. Use Next and Previous buttons to navigate, or jump to a slide with the slide dots. APA102 Addressable LED Hookup GuideServos Explained - everything you need to know about servos.AVR-Based Serial Enabled LCDs Hookup GuideThis is a carousel. Use Next and Previous buttons to navigate, or jump to a slide with the slide dots. Sending Sensor Data Over WiFiSending Sensor Data Over LoRaMonitor Sensor Data From AnywhereThis is a carousel. Use Next and Previous buttons to navigate, or jump to a slide with the slide dots. SparkFun Inventor's Kit Experiment Guide - v4.1MicroMod Qwiic Pro K"
  },
  {
    "title": "Find a pub that needs you (ismypubfucked.com)",
    "points": 209,
    "submitter": "thinkingemote",
    "submit_time": "2026-01-14T15:44:22 1768405462",
    "num_comments": 173,
    "comments_url": "https://news.ycombinator.com/item?id=46617360",
    "comments": [
      "Wow a fantastic independent pub near where I used to live in London is seeing its rateable value go up 480%! This website really puts the headlines in to a nice local perspective.It seems like the taxes only go up while the services get worse in the UK, although I\u2019ve been away for 5 years now so maybe things improved.reply",
      "> seeing its rateable value go up 480%!Rateable value is based on what the market prices would be to rent that space. So, somebody is doing nicely apparently.reply",
      "But if the landlord owns the pub (rare in the UK I know), but I believe it\u2019s the case in this instance, then what are they getting from unrealised property price gains?reply",
      "What does anyone gain from it really, except money in the bank for a handful of individuals, outsized property prices seem to be a hurdle for functional societies in basically every way.It doesn't benefit a town if rent is so expensive that their businesses shut down.reply",
      "When young I use to work in construction. (With diplomas) The wages for 18 year olds in the Netherlands at the time were such that I got 340 euro per month for 40 hour weeks. It's a truly shit salary but you could also see it as a wonderful formula to build cheap houses. As my boss billed the customers 28 euro per hour for my work and those houses cost roughly 35000 to buy(!) and it took roughly 80 hours of work each. (Very rough estimates but that oddly doesn't matter) You could say I build 6.4% of the houses. They roughly cost 350 000 euro today which seems 10 fold but since people can't afford that they need a mortgage and pay 3 times that amount over 30 years. That would mean my labor now costs 10 000 per month. At the time I tried to calculate the savings escape velocity and discovered that if I saved 100% of my income I would be able to buy my own house in never years. If I build 6.4% of a house in 2 weeks that would be 3.2% per week or 32 weeks to build 100%.Say 64 weeks and the process produces one whole home for someone else. I get that there should be some people between the construction worker and the citizen eventho they never did anything useful to the result but the margins are so preposterous that the original salary is a mere rounding error.Then I look at Amish barn raising videos and the laughter becomes uncontrollable. I would definitely go there and help out - for free of course. If I had to keep doing that I would look for some vegetables and uhh my own house? Even if they would never build it for me it would still be more enjoyable than the western extortion scheme.reply",
      "Here\u2019s the Lamb and Flag in Oxfordhttps://www.ismypubfucked.com/pub/11447801200> the Inklings, a literary group including J. R. R. Tolkien and C. S. Lewis, started meeting at The Lamb and Flag.https://en.wikipedia.org/wiki/Lamb_%26_Flag,_Oxfordreply",
      "Amateurs. One close to me is at an +821% increase in its tax bill and rateable value at 613%.reply",
      "The services have certainly not got better in the last 5 years. This Government is fiscally illiterate and has hit the top of the Laffer curve and is now trying to go down the other side.reply",
      "\"This\" ...?You jest.reply",
      "Meet the new government, same as the old government.reply"
    ],
    "link": "https://www.ismypubfucked.com/",
    "first_paragraph": "The government's signalled a potential u-turn on pub rates \u2014 but nothing's confirmed yet. Pubs still need your support. Find your local. See what they're up against. Buy a pint.Our world-class data scientists (one guy with a spreadsheet) have developed the Fucked Pub Index\u2122 \u2014 a groundbreaking metric that combines advanced geospatial analysis (Google Maps) with sophisticated fiscal impact modelling (basic maths) to identify the pub near you that most urgently requires your patronage.Based on VOA rateable value data for ... verified pubs (SCAT 249). Some industry experts estimate the actual number of affected pubs is even higher. The government has signalled support is coming \u2014 we'll update when details are announced.Data from VOA Rating Lists. Not official. Estimates only.A personal project, made with rage (and a love of pubs) by @bjhguerinSpotted a bug or error? Let me know \u2014 much appreciated!Privacy Policy"
  },
  {
    "title": "Roam 50GB is now Roam 100GB (starlink.com)",
    "points": 245,
    "submitter": "bahmboo",
    "submit_time": "2026-01-14T16:03:11 1768406591",
    "num_comments": 277,
    "comments_url": "https://news.ycombinator.com/item?id=46617668",
    "comments": [
      "I'm actually a huge fan of \"unlimited slow speeds\" as a falloff, instead of a cliff.Aside from the fact it allows you to work with Starlink to buy more fast speed, it also allows core stuff to continue to function (e.g. basic notifications, non-streaming web traffic, etc).reply",
      "> I'm actually a huge fan of \"unlimited slow speeds\" as a falloff, instead of a cliff.When on cellular, I like to call that \"HN-only mode.\" It is one of the few web properties that is entirely usable at 2G speeds.reply",
      "I would kill for a web renaissance to return to this format of webpages, as least as an option. Not only loading improves, but also navigation and accessibility.reply",
      "Indeed. That's why, when they finally kill old.reddit, I may legitimately stop using it entirely. They've already banned most of the good apps, forcing the pretty terrible official one.reply",
      "New reddit is a travesty. It feels a satirical mockery of modern webdevreply",
      "My favorite feature is how you click a reply notification and it takes you to a page that doesn\u2019t show the reply half the time.",
      "RedReader is a lovely, lightweight Android app for Reddit.Development is slow, but I've been happily using it since RiF was killed.reply",
      "Recently the old reddit szopped working for me even after going to account settings and opting out of new design again (it was already marked as being opt out) across all my devices. Even after manually navigating to old.reddit.com, clicking any link would take me to new again. I had to install special extensions to reroute to old reddit everywhere.reply",
      "Same thing happened to me, this fixed it: https://www.reddit.com/r/help/comments/1odehgj/is_old_reddit...reply",
      "Had that happen a few times but switching the use old reddit box off and back on fixes it.reply"
    ],
    "link": "https://starlink.com/support/article/58c9c8b7-474e-246f-7e3c-06db3221d34d",
    "first_paragraph": "What happens when I use all my Roam 100GB data?Will my service stop when I reach the 100GB data limit?What can I do with low-speed data?How do I get high-speed Roam data again?What happened to buying additional data billed per GB?Can I use Roam 100GB on the ocean?Roam 100GB AvailabilityOn January 13, 2026, Starlink doubled the amount of high-speed data on Roam 50GB to 100GB, at no additional cost and in most markets. Here is all you need to know about what's changed and what hasn't.Once you\u2019ve used 100GB of your high-speed Roam data, your service automatically continues with unlimited low-speed data for the remainder of your billing period. You\u2019ll still be connected for basic use like calls and texts, but activities such as streaming, downloading, and video calls may be limited.We\u2019ll notify you when you reach 80% and 100% of your monthly high-speed Roam data. To restore high-speed Roam service, you can upgrade to Roam Unlimited. Please note that this upgrade will remain in effect for f"
  },
  {
    "title": "I hate GitHub Actions with passion (xlii.space)",
    "points": 418,
    "submitter": "xlii",
    "submit_time": "2026-01-14T10:53:13 1768387993",
    "num_comments": 297,
    "comments_url": "https://news.ycombinator.com/item?id=46614558",
    "comments": [
      "I think this post accurately isolates the single main issue with GitHub Actions, i.e. the lack of a tight feedback loop. Pushing and waiting for completion on what's often a very simple failure mode is frustrating.Others have pointed out that there are architectural steps you can take to minimize this pain, like keeping all CI operations isolated within scripts that can be run locally (and treating GitHub Actions features purely as progressive enhancements, e.g. only using `GITHUB_STEP_SUMMARY` if actually present).Another thing that works pretty well to address the feedback loop pain is `workflow_dispatch` + `gh workflow run`: you still need to go through a push cycle, but `gh workflow run` lets you stay in development flow until you actually need to go look at the logs.(One frustrating limitation with that is that `gh workflow run` doesn't actually spit out the URL of the workflow run it triggers. GitHub claims this is because it's an async dispatch, but I don't see how there can possibly be no context for GitHub to provide here, given that they clearly obtain it later in the web UI.)reply",
      "https://github.com/nektos/actLets you run your actions locally.  I've had significant success with it for fast local feedback.reply",
      "I tried this recently and it seems like you have to make a lot of decisions to support Act. It in no way \"just works\", but instead requires writing actions knowing that they'll run on Act.reply",
      "I tried this five years ago back when I was an engineer on the PyTorch project, and it didn't work well enough to be worth it. Has it improved since then?reply",
      "It works well enough that I didn\u2019t realize this wasn\u2019t first party till right now.reply",
      "It works, but there are fair amount of caveats, especially for someone working on things like Pytorch, the runtime is close but not the same, and its support of certain architectures etc can create annoying bugs.reply",
      "it has. it's improved to work with ~ 75% of steps . fast enough to worth trying before pushreply",
      "I've standardized on getting github actions to create/pull a docker image and run build/test inside that. So if something goes wrong I have a decent live debug environment that's very similar to what github actions is running. For what it's worth.reply",
      "I do the same with Nix as it works for macOS builds as wellIt has the massive benefit of solving the lock-in problem. Your workflow is generally very short so it is easy to move to an alternative CI if (for example) Github were to jack up their prices for self hosted runners...That said, when using it in this way I personally love Github actionsreply",
      "Nix is so nice that you can put almost your entire workflow into a check or package. Like your code-coverage report step(s) become a package that you build (I'm not brave enough to do this)I run my own jenkins for personal stuff on top of nixos, all jobs run inside devenv shell, devenv handles whatever background services required (i.e. database), /nix/store is shared between workers + attic cache in local network.Oh, and there is also nixosModule that is tested in the VM that also smoke tests the service.First build might take some time, but all future jobs run fast. The same can be done on GHA, but on github-hosted runners you can't get shared /nix/store.reply"
    ],
    "link": "https://xlii.space/eng/i-hate-github-actions-with-passion/",
    "first_paragraph": "\n\n      2026-01-14\n    \nI can\u2019t overstate how much I hate GitHub Actions. I don\u2019t even remember hating any other piece of technology I used. Sure, I still make fun of PHP that I remember from times of PHP41, but even then I didn\u2019t hate it. Merely I found it subpar technology to other emerging at the time (like Ruby on Rails or Django). And yet I hate GitHub Actions.With Passion2.Day before writing these words I was implementing build.rs for my tmplr project. To save you a click - it is a file/project scaffold tool with human readable (and craftable) template files. I (personally) use it very often, given how easy it is to craft new templates, by hand or with aid of the tool, so check it out if you need a similar tool.The build.rs used CUE to generate README.md, CHANGELOG.md and also a version/help file to guarantee consistency. It was fun thing to do, it took approx. 1.5h and I even wrote an article about it. For myself and future generations.I was happy with the results and didn\u2019t che"
  },
  {
    "title": "ChromaDB Explorer (chroma-explorer.com)",
    "points": 21,
    "submitter": "arsentjev",
    "submit_time": "2026-01-14T22:30:16 1768429816",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.chroma-explorer.com/",
    "first_paragraph": "A modern, native desktop client for ChromaDB. Browse collections, search semantically, and manage your vector embeddings with ease.Everything you need to work with ChromaDB, in a beautiful native app.Connect to local, remote, or Chroma Cloud databases. Save and manage multiple connection profiles with secure API key storage.Create, copy, and configure collections with ease. Set custom embedding functions and HNSW parameters.Search your documents using natural language. Find similar content instantly with vector similarity search.Built-in support for OpenAI, Cohere, Gemini, Ollama, Jina, Mistral, Voyage AI, and more.Browse, create, edit, and delete documents. Batch operations for efficient bulk document management.Beautiful glass morphism design that feels right at home on your Mac.See Chroma Explorer in action.Get Chroma Explorer for macOS and start exploring your vector databases today.Requires macOS 11.0 or later"
  },
  {
    "title": "How can I build a simple pulse generator to demonstrate transmission lines (electronics.stackexchange.com)",
    "points": 10,
    "submitter": "alphabetter",
    "submit_time": "2026-01-09T11:02:18 1767956538",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=46552534",
    "comments": [
      "Decades ago we used a much simpler method. A few 50 or 75 ohm non-inductive resistors and a tunnel diode.Feed any (slow) pulse generator into the diode and make it switch. Tunnel diodes can have sub-nanosecond switching times.We also used this technique to check/measure the rise times of our oscilloscopes.reply",
      "Nice write up and sneaky introduction to time-domain reflectrometry but I'd like to point out the classic answer to this question is the famous Jim Williams pulse generator: https://github.com/podonoghue/Jim_Williams_Pulse_Generator?t...reply"
    ],
    "link": "https://electronics.stackexchange.com/questions/764155/how-can-i-build-a-simple-pulse-generator-to-demonstrate-transmission-lines",
    "first_paragraph": ""
  },
  {
    "title": "Native ZFS VDEV for Object Storage (OpenZFS Summit) (zettalane.com)",
    "points": 87,
    "submitter": "suprasam",
    "submit_time": "2026-01-14T18:49:37 1768416577",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=46620673",
    "comments": [
      "I am curious about the inverse, using the dataset layer, to implement some higher level things like objects for an S3 compatible storage or pages directly for an RDBMS.  I seem to remember hearing rumblings about that but it is hard to dredge up.reply",
      "ZFS-Lustre operates this way.Main issue with opening it further is lack of DMU-level userland API, especially given how syscall heavy it could get (and iouring might be locked out due to politics)reply",
      "How suitable would this be as a zfs send target to back up your local zfs datasets to object storage?reply",
      "Quite probably should work just fine.The secret is that ZFS actually implements an object storage layer on top of block devices and only then implements ZVOL and ZPL (ZFS POSIX filesystem) on top of that.A \"zfs send\" is essentially a serialized stream of objects sorted by dependency (objects later in stream will refer to objects earlier in stream, but not the other way around).reply",
      "FS metrics without random IO benchmark are near meaningless, sequential read is best case for basically every file system and it's essentially \"how fast you can get things from S3\" in this casereply",
      "Yup. IIRC low queue depth random\nReads are king for desktop usagereply",
      "Could someone possibly compare this to https://www.zerofs.net/nbd-devices (\"zpool create mypool /dev/nbd0 /dev/nbd1 /dev/nbd2\")reply",
      "I know my missing something, but can't figure out: why not just one device?reply",
      "IIRC the point is that each NBD device is backed by a different S3 endpoint, probably in different zones/regions/whatever for resiliency.Edit: Oops, \"zpool create global-pool mirror /dev/nbd0 /dev/nbd1\" is a better example for that. If it's not that, I'm not sure what that first example is doing.reply",
      "In context of real AWS S3, I can see raid 0 being useful in this scenario, but in mirror that seems like too much duplication and cross-region replication like this going to introduce significant latency[citation needed]. AWS provides that for S3 already.I can see it on not real S3 though.reply"
    ],
    "link": "https://www.zettalane.com/blog/openzfs-summit-2025-mayanas-objbacker.html",
    "first_paragraph": "\n            We presented MayaNAS and MayaScale at OpenZFS Developer Summit 2025 in Portland, Oregon. The centerpiece of our presentation: objbacker.io\u2014a native ZFS VDEV implementation for object storage that bypasses FUSE entirely, achieving 3.7 GB/s read throughput directly from S3, GCS, and Azure Blob Storage.\n          \n            The OpenZFS Developer Summit brings together the core developers and engineers who build and maintain ZFS across platforms. It was the ideal venue to present our approach to cloud-native storage: using ZFS's architectural flexibility to create a hybrid storage system that combines the performance of local NVMe with the economics of object storage.\n          \n            Our 50-minute presentation covered the complete Zettalane storage platform\u2014MayaNAS for file storage and MayaScale for block storage\u2014with a deep technical dive into the objbacker.io implementation that makes ZFS on object storage practical for production workloads.\n          \n            C"
  },
  {
    "title": "Rubik's Cube in Prolog \u2013 Order (medium.com/kenichisasagawa)",
    "points": 16,
    "submitter": "myth_drannon",
    "submit_time": "2026-01-10T11:32:56 1768044776",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=46564818",
    "comments": [
      "I'm not sure if anyone has noticed, a rubiks cube can be represented by only the orientations of the pieces. You do this by defining their \"correct\" position in cube coordinates rather than piece coordinates (local about the piece center). In other words you might define a 3d model for each piece in world space assuming the cube as a whole is centered on the origin. With pieces offset from the origin like this, any rotation about an axis will appear to move the piece as well as rotate it. With 24 orientations, you'll find 3 that place a corner in the same position but colors rotated. Similarly edges have 2 orientations for each of 12 locations.One does need to compute the traditional position of the pieces to determine which ones need to be rotated for a given move, but the total state is significantly reduced.Tell me this isn't news to the cube world. It cant be. Can it?reply",
      "Unable to fully parse what you are trying to express.> the total state is significantly reduced.The minimal \"state space\" of a rubiks cube is a constant value.  Any \"reduction\" would imply the model being reduced was inefficient.On the topic of cool \"alternative\" views of rubiks I recently saw this and thought it was novel.https://old.reddit.com/r/gifs/comments/z3okyv/the_only_way_t...reply",
      "That link. This is a Celtic Knot and 92 is half of 99. I had to.reply",
      "Fun article!  Makes me want to play with prolog again.I put together something looking at a rubik's cube as a permutation of numbers a while back.  https://taeric.github.io/cube-permutations-1.html  I remember realizing that my representation essentially had some permutations of numbers that it would never hit, but wasn't sure it was worth trying to more directly model the pieces of the cube.  Curious if there are advantages here that I'm ignoring.reply",
      "one nice thing is that if you represent the state as a permutation matrix P, and have a matrix of starting piece locations x, rendering is just Px. Then, for smooth rotation animations, if your move is a permutation M, animation is just expm ( t logm( M)) P x with t going from 0 to 1I blather about the permutation matrix of a rubiks cube for a long while at https://www.hgreer.com/TwistyPuzzle/reply"
    ],
    "link": "https://medium.com/@kenichisasagawa/i-am-preparing-material-for-a-prolog-book-af7580acfee7",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Webctl \u2013 Browser automation for agents based on CLI instead of MCP (github.com/cosinusalpha)",
    "points": 57,
    "submitter": "cosinusalpha",
    "submit_time": "2026-01-14T14:34:40 1768401280",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=46616481",
    "comments": [
      "At this point I'm fully down the path of the agent just maintaining his own tools. I have a browser skill that continues to evolve as I use it.  Beats every alternative I have tried so far.reply",
      "Same. Claude Opus 4.5 one-shots the basics of chrome debug protocol, and then you can go from there.Plus, now it is personal software... just keep asking it to improve the skill based on you usage. Bake in domain knowledge or business logic or whatever you want.I'm using this for e2e testing and debugging Obsidian plugins and it is starting to understand Obsidian inside and out.reply",
      "whats the name of the skill?reply",
      "If you look at Elixir keynote for Phoenix.new -- a cool agentic coding tool -- you'll see some hints about a browser control using a API tool call.  It's called \"web\" in the video.Video:  https://youtu.be/ojL_VHc4gLk?t=2132More discussion:  https://simonwillison.net/2025/Jun/23/phoenix-new/reply",
      "Cool to see lots of people independently come to \"CLIs are all you need\". I'm still not sure if it's a short-term bandaid because agents are so good at terminal use or if it's part of a longer term trend but it's definitely felt much more seamless to me then MCPs.(my one of many contribution https://github.com/caesarnine/binsmith)reply",
      "I am also not sure if MCP will eventually be fixed to allow more control over context, or if the CLI approach really is the future for Agentic AI.Nevertheless, I prefer the CLI for other reasons: it is built for humans and is much easier to debug.reply",
      "MCP let's you hide secrets from the LLMreply",
      "you can do same thing with cli via env vars no?reply",
      "Hey this looks cool. So each agent or session is one thread. Nice. I like it.reply",
      "A little bit different, but also allows to scrape efficiently. Json http communication rather than cli.https://github.com/rumca-js/crawler-buddyMore like a framework for other mechanismsreply"
    ],
    "link": "https://github.com/cosinusalpha/webctl",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Browser automation via CLI \u2014 for humans and agents\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Browser automation for AI agents and humans, built on the command line.MCP browser tools have a fundamental problem: the server controls what enters your context. With Playwright MCP, every response includes the full accessibility tree plus console messages (default: \"info\" level). After a few page queries, your context is full.CLI flips this around: you control what enters context.Beyond filtering, CLI gives you:Verify it works:Browser stays open across commands. Cookies persist to disk.Semantic targeting based on ARIA roles - stable across CSS refactors:Tell your AI agent to use webctl. The easiest way:Or manually add to your agent's config:This section is de"
  }
]