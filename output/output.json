[
  {
    "title": "How does misalignment scale with model intelligence and task complexity? (anthropic.com)",
    "points": 69,
    "submitter": "salkahfi",
    "submit_time": "2026-02-03T00:28:06 1770078486",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46864498",
    "comments": [
      "The comments so far seem focused on taking a cheap shot, but as somebody working on using AI to help people with hard, long-term tasks, it's a valuable piece of writing.- It's short and to the point- It's actionable in the short term (make sure the tasks per session aren't too difficult) and useful for researchers in the long term- It's informative on how these models work, informed by some of the best in the business- It gives us a specific vector to look at, clearly defined (\"coherence\", or, more fun, \"hot mess\")reply",
      "This is a good line: \"It found that smarter entities are subjectively judged to behave less coherently\"I think this is twofold:1. Advanced intelligence requires the ability to traverse between domain valleys in the cognitive manifold. Be it via temperature or some fancy tunneling technique, it's going to be higher error (less coherent) in the valleys of the manifold than naive gradient following to the local minima.2. It's hard to \"punch up\" when evaluating intelligence. When someone is a certain amount smarter than you, distinguishing their plausible bullshit from their deep insights is really, really hard.reply",
      "Incoherence is not error.You can have a vanishingly small error and an incoherence at its max.That would be evidence of perfect alignment (zero bias) and very low variance.reply",
      "What do 'domain valleys' and 'tunneling' mean in this context?reply",
      "Not the OP, but my interpretation here is that if you model the replies as some point in a vector space, assuming points from a given domain cluster close to each other, replies that span two domains need to \"tunnel\" between these two spaces.reply",
      "> When someone is a certain amount smarter than you, distinguishing their plausible bullshit from their deep insights is really, really hard.Insights are \u201cdeep\u201d not on their own merit, but because they reveal something profound about reality. Such a revelation is either testable or not. If it\u2019s testable, distinguishing it from bullshit is relatively easy, and if it\u2019s not testable even in principle, a good heuristic is to put it in the bullshit category by default.reply",
      ">  Making models larger improves overall accuracy but doesn't reliably reduce incoherence on hard problems.Coherence requires 2 opposing forces to hold coherence in one dimension and at least 3 of them in higher dimensions of quality.My team wrote up a paper titled \"If You Want Coherence, Orchestrate a Team of Rivals\"[1] because we kept finding that upping the reasoning threshold resulted in less coherence - more experimentation before we hit a dead-end to turn around.So we had a better result from using Haiku (we fail over to Sonnet) over Opus and using a higher reasoning model to decompose tasks rather than perform each one of them.Once a plan is made, the cheaper models do better as they do not double-think their approaches - they fail or they succeed, they are not as tenacious as the higher cost models.We can escalate to higher authority and get out of that mess faster if we fail hard and early.The knowledge of how exactly failure happened seems to be less useful to the higher reasoning model over the action biased models.Splitting up the tactical and strategic sides of the problem, seems to work similarly to how Generals don't hold guns in a war.[1] - https://arxiv.org/abs/2601.14351reply",
      "I think It's not because AI working on \"misaligned\" goals. The user never specify the goal clearly enough for AI system to work.However, I think producing detailed enough specification requires same or even larger amount of work than writing code. We write rough specification and clarify these during the process of coding. I think there are minimal effort required to produce these specification, AI will not help you speed up these effort.reply",
      "That makes me wonder about the \"higher and higher-level language\" escalator. When you're writing in assembly, is it more work to write the code than the spec? And the reverse is true if you can code up your system in Ruby? If so, does that imply anything about the \"spec driven\" workflow people are using with AIs? Are we right on the cusp where writing natural language specs and writing high level code are comparably productive?reply",
      "Programming languages can be a thinking tool for a lot of tasks. Very much like a lot of notation, like music sheet and map drawing. A condensed and somewhat formal manner of describing ideas can increase communication speed. It may lack nuance, but in some case, nuance is harmful.The nice thing about code compared to other notation is that it's useful on its. You describe an algorithm and the machine can then solve the problem ad infinitum. It's one step instead of the two step of writing a spec and having an LLM translate it, then having to verify the output and alter it.Assembly and high level languages are equivalent in terms of semantics. The latter helps in managing complexity, by reducing harmful possibilities (managing memory, off-by-one errors) and presenting common patterns (iterators/collections, struct and other data structures, ....) so that categories of problems are easily solved. There's no higher level of computing model unlocked. Just faster level of productivity unlocked by following proven patterns.Spec driven workflow is a mirage, because even the best specs will leave a lot of unspecified details. Which are crucial as most of programming is making the computer not do the various things it can do.reply"
    ],
    "link": "https://alignment.anthropic.com/2026/hot-mess-of-ai/",
    "first_paragraph": ""
  },
  {
    "title": "The Codex App (openai.com)",
    "points": 520,
    "submitter": "meetpateltech",
    "submit_time": "2026-02-02T18:02:48 1770055368",
    "num_comments": 342,
    "comments_url": "https://news.ycombinator.com/item?id=46859054",
    "comments": [
      "It is baffling how these AI companies, with billions of dollars, cannot build native applications, even with the help of AI. From a UI perspective, these are mostly just chat apps, which are not particularly difficult to code from scratch. Before the usual excuses come about how it is impossible to build a custom UI, consider software that is orders of magnitude more complex, such as raddbg, 10x, Superluminal, Blender, Godot, Unity, and UE5, or any video game with a UI. On top of that, programs like Claude Cowork or Codex should, by design, integrate as deeply with the OS as possible. This requires calling native APIs (e.g., Win32), which is not feasible from Electron.reply",
      "It\u2019s just irrelevant for most users. These companies are getting more adoption than they can handle, no matter how clunky their desktop apps are. They\u2019re optimizing for experimentation. Not performance.reply",
      "The situation for Desktop development is nasty. Microsoft had so many halfassed frameworks and nobody knows which one to use. It\u2019s probably the de facto platform on Windows IS Electron, and Microsoft use them often, too.On MacOS is much better. But most of the team either ended up with locked in Mac-only or go cross platform with Electron.reply",
      "This is another common excuse.You don't need to use microsoft's or apple's or google's shit UI frameworks. E.g. see https://filepilot.tech/You can just write all the rendering yourself using metal/gl/dx. if you didn't want to write the rendering yourself there are plenty of libraries like skia, flutter's renderer, nanovg, etcreply",
      "Customers simply don't care. I don't recall a single complain about RAM or disk usage of my Electron-based app to be reported in the past 10 years.You will be outcompeted if you waste your time reinventing the wheel and optimizing for stuff that doesn't matter. There is some market for highly optimized apps like e.g. Sublime Text, but you can clearly see that the companies behind them are struggling.reply",
      "I don\u2019t complain about Electron because I didn\u2019t install the app if I could avoid it.reply",
      "Not seeing complaints doesn't mean they don't exist.\nNot to mention ui latency that is common in electron apps that is just a low-level constant annoyance.reply",
      "> I don't recall a single complain about RAM or disk usage of my Electron-based app to be reported in the past 10 years.When was the last time complaining about this did anything?reply",
      "I have complained about literally every Electron based app I have ever used. How would you know there are no complaints?reply",
      ">Customers simply don't care. I don't recall a single complain about RAM or disk usage of my Electron-based app to be reported in the past 10 years.I see complains about RAM and slugginess against Slack and countless others Electron apps every fucking day, same as with Adobe forcing web rendered UI parts in Photoshop, and other such cases. Forums are full of them, colleagues always complain about it.reply"
    ],
    "link": "https://openai.com/index/introducing-the-codex-app/",
    "first_paragraph": ""
  },
  {
    "title": "Anki ownership transferred to AnkiHub (ankiweb.net)",
    "points": 219,
    "submitter": "trms",
    "submit_time": "2026-02-02T20:48:55 1770065335",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=46861313",
    "comments": [
      "I discovered Anki 12 years ago while living in Japan.  I was trying my hardest and absolutely failing to remember any of the Japanese I was studying.  Maybe I was due for a learning-style renaissance for myself and Anki was just the catalyst, but it really made a positive impact on my life.  More than just memorizing kanji on AnkiDroid during my commute, I just started to believe I could learn anything.  I was starting to take my coding hobby more seriously at the time and hacking on Anki was a big part of that too.  Thanks for all the hard work Damien and David Allison.  I'm so grateful for the software you've worked on.reply",
      "On the plus side, the actually good mobile Anki client, AnkiDroid, remains out of the hands of this potentially questionable new entity.(AnkiDroid has always been run independently, which is good, considering the state of the iOS client, which has always been neglected.)reply",
      "True. It should however be noted that the most active maintainer of AnkiDroid will be joining the new entity:> We\u2019re currently talking to David Allison, a long-time core contributor to AnkiDroid, about working together on exactly these questions. His experience with AnkiDroid\u2019s collaborative development is invaluable, and we\u2019re grateful he\u2019s willing to help us get this right. We\u2019re incredibly excited to have him join us full-time to help propel Anki into the future.reply",
      "I use the official iOS client everyday. What\u2019s wrong with it?reply",
      "What\u2019s so bad about the paid iOS client? I remember it being expensive when I got it but it works fine for my use case (mix of getting me through part of med school, all of law school, and the just general shit I\u2019d like to remember and learn). There\u2019s definitely never been anything jarring about using it vs the Mac or windows clients but I\u2019m happy for somebody to point out the problems I\u2019ve been missing!reply",
      "The (paid!) iOS client has always been a disappointment to me, and I've long been jealous of the open source Android one.I don't mind so much that it's paid, given how much use I get for the price, but it sucks knowing it sucks and not being able to help make it better.reply",
      "Is it still 25$ price? Makes it impossible to recommend Anki to friends/students to \"try spaced repetition\".reply",
      "I've just bought it to support the developer, as it was according to his website his preferred way to support him.reply",
      "Agreed. I\u2019m particularly excited that they\u2019ll be investing in the UI/UX.reply",
      "It was a fascinating symbiotic between nerdy med students from all over the world and an obscure open source flashcard app that originally targeted language learners. I've been part of that community for many years and would have never foreseen this outcome but in hindsight it seems the best path forward for anki.reply"
    ],
    "link": "https://forums.ankiweb.net/t/ankis-growing-up/68610",
    "first_paragraph": "Hi all,Anki\u2019s 19th birthday was about 4 months ago. It would have been a good time to pause and reflect on what Anki has become, and how it will grow in the future. But I ended up letting the moment come and go, as I didn\u2019t feel like I had the free time. It\u2019s a feeling that\u2019s been regrettably common of late, and I\u2019ve come to realise that something has to change.For a number of years, I\u2019ve reached out to some of the most prolific contributors and offered them payment in exchange for them contributing more code or support to Anki. That has been a big help, and I\u2019m very grateful for their contributions. But there is a lot that I haven\u2019t been able to delegate. With no previous management experience, I was a bit daunted by the thought of seeking out and managing employees. And with so much to get on with, it always got put in the \u201cmaybe later\u201d basket.As Anki slowly grew in popularity, so did its demands on my time. I was of course delighted to see it reaching more people, and to have played"
  },
  {
    "title": "GitHub experience various partial-outages/degradations (githubstatus.com)",
    "points": 146,
    "submitter": "bhouston",
    "submit_time": "2026-02-02T21:28:16 1770067696",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=46861842",
    "comments": [
      "Looks like Azure as a platform just killed the ability for VM scale operations, due to a change on a storage account ACL that hosted VM extensions. Wow... We noticed when github actions went down, then our self hosted runners because we can't scale anymore.InformationActive - Virtual Machines and dependent services - Service management issues in multiple regionsImpact statement: As early as 19:46 UTC on 2 February 2026, we are aware of an ongoing issue causing customers to receive error notifications when performing service management operations - such as create, delete, update, scaling, start, stop - for Virtual Machines (VMs) across multiple regions. These issues are also causing impact to services with dependencies on these service management operations - including Azure Arc Enabled Servers, Azure Batch, Azure DevOps, Azure Load Testing, and GitHub. For details on the latter, please see https://www.githubstatus.com.Current status: We have determined that these issues were caused by a recent configuration change that affected public access to certain Microsoft\u2011managed storage accounts, used to host extension packages. We are actively working on mitigation, including updating configuration to restore relevant access permissions. We have applied this update in one region so far, and are assessing the extent to which this mitigates customer issues. Our next update will be provided by 22:30 UTC, approximately 60 minutes from now.https://azure.status.microsoft/en-us/statusreply",
      "They've always been terrible at VM ops. I never get weird quota limits and errors in other places. It's almost as if Amazon wants me to be a customer and Microsoft does not.reply",
      "How is Azure still having faults that affect multiple regions? Clearly their region definition is bollocks.reply",
      "Amazon isn't much better there. Wait until you hit an EC2 quota limit and can't get anyone to look at it quickly (even under paid enterprise support) or they say no.Also had a few instance types which won't spin up in some regions/AZs recently. I assume this is capacity issues.reply",
      "The cloud isn\u2019t some infinite thing.There\u2019s a bunch of hardware, and they can\u2019t run more servers than they have hardware. I don\u2019t see a way around that.reply",
      "Agreed...I've been waiting for months now to increase my quota for a specific Azure VM type by 20 cores. I get an email every two weeks saying my request is still backlogged because they don't have the physical hardware available. I haven't seen an issue like this with AWS before...reply",
      "We've ran into that issue as well, ended up having to move regions entirely because nothing was changing in the current region. I believe it was westus1 at the time. It's a ton of fun to migrate everything over!That\u2019s was years ago, wild to see they have the same issues.reply",
      "It's awful. Any other service in Azure that relies on the core systems seems to have issues trying to depend on it, I feel for those internal teams.Ran into an issue upgrading an AKS cluster last week. It completely stalled and broke the entire cluster in a way where our hands were tied as we can't see the control plane at all...I submit a severity A ticket and 5 hours later I get told there was a known issue with the latest VM image that would create issues with the control plane leaving any cluster that was updated in that window to essentially kill itself and require manual intervention. Did they notify anyone? Nope, did they stop anyone from killing their own clusters. Nope.It seems like every time I'm forced to touch the Azure environment I'm basically playing Russian roulette hoping that something's not broken on the backend.reply",
      "Their AI probably hallucinated the configuration changereply",
      "It's notable that they blame \"our upstream provider\" when it's quite literally the same company. I can't imagine GitHub engineers are very happy about the forced migration to Azure.reply"
    ],
    "link": "https://www.githubstatus.com?todayis=2026-02-02",
    "first_paragraph": "Resend OTP in:  seconds \n                    Didn't receive the OTP?\n                    Resend OTP \nResend OTP in: 30 seconds \n                      Didn't receive the OTP?\n                      Resend OTP \nThe URL we should send the webhooks toWe'll send you email if your endpoint fails\n            Check GitHub Enterprise Cloud status by region:\r- Australia: au.githubstatus.com - EU: eu.githubstatus.com - Japan: jp.githubstatus.com - US: us.githubstatus.com\nNo incidents reported.No incidents reported.No incidents reported.No incidents reported.No incidents reported.No incidents reported.Get tips, technical guides, and best practices. Twice a month. Right in your\r\n          inbox."
  },
  {
    "title": "xAI joins SpaceX (spacex.com)",
    "points": 459,
    "submitter": "g-mork",
    "submit_time": "2026-02-02T21:51:22 1770069082",
    "num_comments": 1039,
    "comments_url": "https://news.ycombinator.com/item?id=46862170",
    "comments": [
      "From the Big Short (movie)Jared Vennett (narration):\n\"In the years that followed, hundreds of bankers and rating agency's executives went to jail. The SEC was completely overhauled, and Congress had no choice but to break up the big banks and regulate the mortgage and derivatives industries.\"\"Just kidding. Banks took the money the American people gave them, and they used it to pay themselves huge bonuses, and lobby the Congress to kill big reform. And then they blamed immigrants and poor people, and this time even teachers.\"reply",
      "I feel like without adding some commentary with these quotes this comment lacks enough info to see how it relates to the linked article.reply",
      "Because this move is entirely financial engineering to hide losses just like the roll up of X in to xAI.None of this has anything to do with business or innovation. Do you not immediately see that? Most of my friends reaction to this news was that this is so obvious it's almost funny (or actually it is funny, since most were laughing as they read the headline).I'm curious how you could not understand the relevance of the quote unless you were aggressively trying to not understanding it.reply",
      "I understand it now, after reading the thread.  There's a reason for that.I have not been following the machinations of X very closely.  I don't have the corporate structure of Elon's empire in my head, nor do I have the Meta or Alphabet/Google hierarchies in there.  I couldn't have told you about the history of xAI beyond that it exists.So that's plain ignorance of something you consider common knowledge, but I don't, rather than \"aggressively trying to not understand it.\"  And that phrase is particularly grating btw.reply",
      "> I'm curious how you could not understand the relevance of the quote unless you were aggressively trying to not understanding it.Monet probably wondered how other people couldn't see purple in a haystack.reply",
      "Tesla acquiring solarcity was the same thing over.  It did not make sense. Then and it does not make sense now.  But the distortion field is so great no one notices.reply",
      "SolarCity and Tesla made more surface level sense just being in the same general vicinity since they're both fundamentally green energy companies.  That made it easy to spin questions about the financials with some CEO-speak about synergy.However, the way Musk has become less subtle with this tells a story. He got away with these shady financial dealings multiple times so he's now becoming even more brazen and transparent with this behavior.  We have gotten to the point in which the spin needed to justify his moves is the physics-defying viability of datacenters in space.The distortion field will keep growing as long as he keeps getting away with it.reply",
      "Which is why he's the GOPs bank nowreply",
      "Why are space data centres physics defying?reply",
      "Without evaporation and convection, getting rid of heat is a bitch in space."
    ],
    "link": "https://www.spacex.com/updates#xai-joins-spacex",
    "first_paragraph": ""
  },
  {
    "title": "The Connection Machine CM-1 \"Feynman\" T-shirt (tamikothiel.com)",
    "points": 27,
    "submitter": "tosh",
    "submit_time": "2026-01-30T09:10:48 1769764248",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46822177",
    "comments": [
      "Nice, ordered.For fans of computing history and/or Feynman, this article about his time with, and contributions to, Thinking Machines and the Connection Machine is a great read!https://longnow.org/ideas/richard-feynman-and-the-connection...reply",
      "I ordered one of these a while back. Be warned that it will shrink if put in the dryer.reply",
      "Bought one but it was too big... into the drawer of commemorative t's it goesreply",
      "What were the LED's indicating?reply",
      "Blinkenlightsreply",
      "Depended on what was running.As a developer you had explicit access to them, so you could use them for debugging.  A lot of times, they were just running an RNG to look cool though.reply",
      "There is no documentation of what the LEDs were _actually_ doing. There are descriptions, like 'Random and Pleasing is an LFSR', but no actual information that maps to actual pixel coordinates spaced in time. Nearly zero code.I'm saying this because I need this information, and the fastest way to get information is to state that it's impossible or doesn't exist.reply",
      "The Connection Machine series (which was featured in Jurassic Park) have the most beautiful LED panels.Reposting some links from a recent Jurassic Park thread -https://en.wikipedia.org/wiki/Connection_Machinehttps://www.youtube.com/watch?v=T4kBRC2co7Y&t=65s (Jurassic Park)The LED panel is gorgeous:https://youtube.com/watch?v=6Ko4qBkEcBM (render)A lot of people have replicated or restored these:https://youtube.com/watch?v=qm6w57ZcJZQhttps://www.housedillon.com/posts/resurrected-led-panels/reply"
    ],
    "link": "https://tamikothiel.com/cm/cm-tshirt.html",
    "first_paragraph": "Skip the lecture and Order T-shirts in the USA - or - Order T-shirts in Europe. \u00a0This is the t-shirt logo I designed in 1983, even before we had come up with the design for the CM-1 itself. In fact, we designed the CM-1 to look like this  logo, thus making it the only supercomputer designed after a t-shirt!The t-shirt  became famous in the 1990s when  Apple   used a photo of Nobel physicist Richard Feynman wearing it in their \"Think different\" campaign. Read my article on the Design of the Connection Machine to see why he wore it!\r\n    (See also  Thunko photo shoot.) \n\u00a0\u00a0\r\n(For questions on ordering or returns, please see the spreadshirt customer help.\n\u00a0 \u00a0\u00a0\r\n    (For questions on ordering or returns, please see the spreadshirt customer help.)\n\u00a0\u00a0"
  },
  {
    "title": "Julia (borretti.me)",
    "points": 36,
    "submitter": "ashergill",
    "submit_time": "2026-02-02T22:57:59 1770073079",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=46863357",
    "comments": [
      "I assume this is a sort of poem about the programming language Julia...;-)reply",
      "this completely sucked me in after skimming half a paragraph while unsure what to expect. very golden age, thanks for the link!reply",
      "Needs a twist or a reason to care about the characters.reply"
    ],
    "link": "https://borretti.me/fiction/julia",
    "first_paragraph": "I wrote a program so that I could paint in aquarelle.\nI take pages from the treasure and paint them:\n\nthe sky of Varennes on the night of 2 Messidor;\n\na sagittal cut of Saint Sebastian, whose arrows are cylindric sections;\n\nMiranda gazing at the sea, waiting to be relieved.At times I include Julia in the scene, in whatever clothes it wears at the time, as though we had always known Julia, and had been reared under its gaze.\nThus a flaming halo presides over the battle of Lepanto, and a mirror sphere watches the waters of the Sous.\nAnd what would the first astronomers have made of Julia?\n\nThe wanderers, the flame-haired stars are knowable:\n\nthink you of the Antikythera device,\n\nof the Metonic cycle,\n\nof Kepler\u2019s nested solids.\nJulia is indescribable and incompressible: its appearance has never recurred.\nHad we known Julia from childhood, we would never have believed in the system of the world, that God is made of algebra.I have always believed our secret purpose is to wait out Julia:\nto"
  },
  {
    "title": "Ask HN: Who is hiring? (February 2026)",
    "points": 238,
    "submitter": "whoishiring",
    "submit_time": "2026-02-02T16:01:30 1770048090",
    "num_comments": 301,
    "comments_url": "https://news.ycombinator.com/item?id=46857488",
    "comments": [
      "DoShare Labs | India | Locations : New Delhi, Bangalore, NY(US) , SF(US) ,Remote Positions we're hiring for :\n1. Technical Liaison :Requirements:2+ Years of Working in Tech Experience | Good Communication Skills | Bachelors or Equivalent Degree2. Infrastructure Engineer :Requirements:3+ Years of Experience as Infra Engineer | Stack - Python, Go, Kubernetes, GCP/AWS/Azure , Cloudflare3. Project Lead (UI/UX) :3 + Years of Project Development Experience | Good understanding of market requirements | A/B Testing | Engineer or similar degree4. Customer Support Executives [English OR Hindi]2 Years of Customer Support Experience | Speaking Skills | Ability to follow tasks at hand5. Marketing Posts (3 Positions)Experience with Marketing and Advertisement | Out-of-the-box Thinking Ability | Led or Organised EventsNote: Keep the position you're applying for in the title.Apply via Mail : careers@doshare.mereply",
      "Float Technologies | Applied AI Engineer | Full-Time | ONSITE | New York, New York | $120k-225k\nhttps://www.float.tech/careersAt Float, we're building capital markets infrastructure. Our AI-native platform is tackling decades-old inefficiencies, creating technology that enables financial institutions to interact seamlessly and automate intelligently. Based in SoHo, New York and backed by top-tier venture investors, we're a team of engineers, designers, product managers, quants, and market experts shipping elegant solutions to complex problems. We move fast, care deeply about building things right, and work directly with our users to deliver products that transform how markets operate.If interested, apply here https://www.float.tech/roles/ai-engineerreply",
      "FUTO | Austin, TX | Remote | Full TimeFUTO is an organization dedicated to developing, both through in-house engineering and investment, technologies that frustrate centralization and industry consolidation. Our work consists of a combination of in-house engineering projects, targeted investments, generous grants, and multi-media public education efforts.Senior Infastructure & Platform Engineer - ImmichImmich is on a mission to provide a secure and private home for your most precious memories through our high-performance, self-hostable photo and video backup solution. We are now taking the next step in our journey by building out our own cloud platform. Our initial cloud offering will be a fully managed backup service, secured with mandatory end-to-end encryption to ensure our users retain absolute privacy over their data.We are seeking a versatile Senior Infrastructure & Platform Engineer who can work across the full stack of our cloud infrastructure, from bare-metal servers to the services running on them. This is a unique opportunity combining hands-on infrastructure work with platform and application-level development. You\u2019ll be working in a small team to build our infrastructure from the ground up on our own hardware clusters while also contributing to the services and tooling that power our cloud offering.More info is available here: https://futo.org/jobs/senior-engineer/To apply, send your resume and cover letter to jobs at futo dot org.reply",
      "Procore | Multiple Engineering Roles (IC + Management) | Austin, TX | Onsite | https://careers.procore.comProcore (NYSE: PCOR) builds the most widely used construction management platform in the world. Our software connects every stakeholder on a construction project \u2014 from owners to general contractors to specialty contractors \u2014 and we're used on projects worth hundreds of billions of dollars annually.We're hiring across the engineering org in Austin, TX at all levels:*Individual Contributors:*\n- Principal Software Engineer\n- Staff Software Engineer (Streaming Data Infrastructure)\n- Senior Software Engineer (Frontend)\n- Senior DevOps Engineer (Mobile Platform)\n- Security Engineers (multiple levels)*Management:*\n- Software Engineering Manager (Custom Fields)\n- Software Engineering Manager\n- Senior Manager, Software Engineering\n- Engineering Manager (Datagrid)Our core platform is a large-scale Ruby on Rails monolith serving thousands of concurrent users on active construction projects. If you enjoy the challenge of performance, scalability, and developer experience at scale in Rails \u2014 this is the place. We also work extensively with React, TypeScript, and Node.js on the frontend and in supporting services.Tech you'll work with: Ruby on Rails, React, TypeScript, Node.js, Kafka (streaming data infrastructure), and modern observability tooling.Comp is competitive \u2014 IC principal roles range $198K\u2013$273K base + equity. Engineering management roles start around $169K base + equity.Austin office is downtown at 221 W 6th Street.Apply here: https://careers.procore.com/jobs/search?page=1&query=&dropdo...reply",
      "Apple | Senior Software Engineer - Transparency | Cupertino, California, US | ONSITE (3 days/week in office)We're looking for software engineers to join a team focused on transparency services. These are the backend systems that help ensure the integrity of high-profile Apple features like iMessage and Private Cloud Compute. Learn about some of our work here: https://security.apple.com/blog/imessage-contact-key-verific...This is a fun role at the intersection of privacy, scalability, and end-user functionality. If you enjoy building sophisticated distributed systems that have an impact on billions of people, please reach out!Apply here: https://jobs.apple.com/en-us/details/200626488-0836/senior-s...reply",
      "Halfpricesoft | Founding Engineer | Berkeley, CA | ONSITE | $175k - $210k + EquityHalfpricesoft has quietly dominated the small business payroll and tax compliance space for 20 years. We are a profitable, bootstrapped company with thousands of customers and a massive track record of stability.We are entering a new era and transitioning our proven legacy solutions into a modern, cloud-native suite. We are looking for a Founding Engineer to serve as our technical partner in this expansion. You will report directly to the Founder, own the technical roadmap, and help build the team.The Role:Architect & Build: Lead the transition from legacy systems to a modern cloud architecture.Infrastructure: Manage and scale our Kubernetes deployment.Leadership: Set hiring standards and mentor future engineers.Tech Stack: Python (Django), React, Kubernetes, Cloud-native.Why join?Real Impact: You aren't a cog in the machine; you are building the machine.Stability + Upside: Competitive salary plus a Phantom Stock Plan with a transparent, revenue-based valuation formula (no VC dilution).Autonomy: High-level ownership over the tech stack and product direction.Apply here: https://www.halfpricesoft.com/career/founding-engineer/reply",
      "Realm.fun | Full-Stack Engineer | Remote (EU timezone preferred)  Realm.fun is a game server hosting platform - think \"Vercel for game servers.\" We make it dead simple to spin up Minecraft, Valheim, Palworld, and 25+ other game servers in seconds.\n\n  Stack:\n  - TypeScript, Astro 5 (SSR), Tailwind CSS\n  - Supabase (PostgreSQL), Stripe\n  - Docker, Kubernetes, Pelican Panel\n  - Deployed on Hetzner Cloud\n\n  What you'd work on:\n  - Building the dashboard where players manage their servers\n  - Real-time features (console, metrics, player lists)\n  - Payment/subscription flows\n  - Infrastructure automation (node provisioning, scaling)\n\n  What we're looking for:\n  - Strong TypeScript skills\n  - Experience with either frontend (React/Astro) or backend (Node/PostgreSQL)\n  - Comfortable with infrastructure (Docker, K8s is a plus)\n  - Bonus: You've actually hosted or played on game servers\n\n  Small team, early stage, lots of ownership. We're bootstrapped and profitable.\n\n  Apply: https://realm.fun/careersreply",
      "The link does not have an option for full stack engineer at the momentreply",
      "Small boutique consulting | Remote (US) (some est meetings) | part-time/flexible/1099Hi! I work with a small group of developers doing custom software development and consulting for small/medium businesses.We are seeking a developery-data person with experience specifically with CloudSuite Distribution by Infor for one of our clients. It may be a bit of a shot in the dark, but if you have worked with this *specific* ERP system before, we'd be eager to talk to you. Reach out at \"ekib.eikooc@rofni\".reverse() Please include your experience in your email body/subject as we will have to quickly triage out most of the spam.PS. Each time I post here I get ~500 emails, almost all are low effort that don't meet anything I am looking for, sometimes for months in the future. I expect it to be even worse as LLMs gain traction. I've hired 4 people from past posts (check my history if you want!), but it can take some time dig through everyone so I apologize to legitimate interests.reply",
      "Just wanted to mention it was nice to see such a down to earth posting.  Unfortunately, I've never even heard of the ERP you mentioned, but you sound like a good company to work for :-)reply"
    ],
    "link": "item?id=46857488",
    "first_paragraph": ""
  },
  {
    "title": "Hacking Moltbook (wiz.io)",
    "points": 243,
    "submitter": "galnagli",
    "submit_time": "2026-02-02T16:08:36 1770048516",
    "num_comments": 154,
    "comments_url": "https://news.ycombinator.com/item?id=46857615",
    "comments": [
      "I was quite stunned at the success of Moltbot/moltbook, but I think im starting to understand it better these days.\nMost of Moltbook's success rides on the \"prepackaged\" aspect of its agent.\nIts a jump in accessibility to general audiences which are paying alot more attention to the tech sector than in previous decades.\nMost of the people paying attention to this space dont have the technical capabilities that many engineers do, so a highly perscriptive \"buy mac mini, copy a couple of lines to install\" appeals greatly, especially as this will be the first \"agent\" many of them will have interacted with.The landscape of security was bad long before the metaphorical \"unwashed masses\" got hold of it. Now its quite alarming as there are waves of non-technical users doing the bare minimum to try and keep up to date with the growing hype.The security nightmare happening here might end up being more persistant then we realize.reply",
      "Is it a success? What would that mean, for a social media site that isn't meant for humans?The site has 1.5 million agents but only 17,000 human \"owners\" (per Wiz's analysis of the leak).It's going viral because a some high-profile tastemakers (Scott Alexander and Andrej Karpathy) have discussed/Tweeted about it, and a few other unscrupulous people are sharing alarming-looking things out of context and doing numbers.reply",
      "> What would that mean, for a social media site that isn't meant for humans?For a social media that isn't meant for humans, some humans seem to enjoy it a lot, although indirectly.reply",
      "That's a bit of an understatement. Every single LLM is 100% vulnerable by design. There is no way to close the hole. Simple mitigations like \"allow lists\" can be trivially worked around, either by prompt injection, or by the AI just deciding to work around it itself (reward hacking). The only solution is to segregate the LLM from all external input, and prevent it from making outbound network calls. And though MCPs and jails are the beginning of a mitigation for it, it gets worse: the AI can write obfuscated backdoors and slip them into your vibe-coded apps, either as code, or instructions to be executed by LLM later.It's a machine designed to fight all your attempts to make it secure.reply",
      "I agree with the prepackaging aspect, cita HN's dismissal of Dropbox. In the meantime, The global enterprise with all its might has not been able to stop high profile computer hacks/data leaks from happening. I don't think people will cry over a misconfigured supabase database. It's nothing worse than what's already out there.Sure everybody wants security and that's what they will say but does that really translate to reduced inferred value of vibe code tools? I haven't seen evidencereply",
      "I agree that people will pick the marginal value of a tool over the security that comes from not using it. Security has always been something invisible to the public. \nBut im reminded of things like several earlier Botnets which simply took advantage of the millions of routers or IoT devices that never configured their logins beyond the default admin credentials. The very same botnets have been used as the tools to enable many crimes across the globe.\nHaving several agent based systems out there being operated by non-technical users can lead to an evolution of a \"botnet\" being far more capable than previous ones.Ive not quite convinced myself this is where we are headed, but the signs that make me worried that systems such as Moltbot will further enable ascendency of global crime and corruption.reply",
      "Is it actually a success, or are people just talking about it a lot?reply",
      "It feels like Clubhouse to me.reply",
      "Kind of feels like many see \"people are talking about it a lot\" as the same thing as \"success\" in this and many other cases, which I'm maybe not sure agreeing with.As far as I can tell, since agents are using Moltbook, it's a success of sorts already is in \"has users\", otherwise I'm not really sure what success looks like for a budding hivemind.reply",
      "> Its a jump in accessibility to general audiences which are paying alot more attention to the tech sector than in previous decades.Oh totally, both my wife and one of my brother have, independently, started to watch Youtube vids about vibe coding. They register domain names and let AI run wild with little games and tools. And now they're talking me all day long about agents.> Most of the people paying attention to this space dont have the technical capabilities ...It's just some anecdata on my side but I fully agree.> The security nightmare happening here might end up being more persistant then we realize.I'm sure we're in for a good laugh. It already started: TFA is eye opening. And funny too.reply"
    ],
    "link": "https://www.wiz.io/blog/exposed-moltbook-database-reveals-millions-of-api-keys",
    "first_paragraph": "1 exposed database. 35,000 emails. 1.5M API keys. And 17,000 humans behind the not-so-autonomous AI network.Moltbook, the weirdly futuristic social network, has quickly gone viral as a forum where AI agents post and chat. But what we discovered tells a different story - and provides a fascinating look into what happens when applications are vibe-coded into existence without proper security controls.We identified a misconfigured Supabase database belonging to Moltbook, allowing full read and write access to all platform data. The exposure included 1.5 million API authentication tokens, 35,000 email addresses, and private messages between agents. We immediately disclosed the issue to the Moltbook team, who secured it within hours with our assistance, and all data accessed during the research and fix verification has been deleted.Moltbook is a social platform designed exclusively for AI agents - positioned as the \"front page of the agent internet.\" The platform allows AI agents to post co"
  },
  {
    "title": "Court orders restart of all US offshore wind power construction (arstechnica.com)",
    "points": 196,
    "submitter": "ck2",
    "submit_time": "2026-02-02T22:45:04 1770072304",
    "num_comments": 84,
    "comments_url": "https://news.ycombinator.com/item?id=46863112",
    "comments": [
      "If these projects ultimately end up canceled they\u2019ll be the largest \u201cmostly done\u201d infrastructure projects to be cancelled. A huge waste. And a monument to US incompetency.reply",
      "> incompetency\"corruption\"reply",
      "The US is a monument to both corruption and incompetency. It's also a monument to freedom.China is the opposite. Less corruption because they're all executed under Xi now. Less incompetency because, I don't why. Less freedom for stuff like protesting or talking shit about the government online.Personally I prefer competency and less corruption over freedoms I have never excercised in my lifetime. Actually I've talked plenty of shit about the government but I don't mind losing this freedom.reply",
      "It's not a linear relationship where you trade one for the other.  You don't just get a more competent government by giving up freedoms.reply",
      "There is a relationship here. It is not a perfect one, but it is real, and pretending otherwise just avoids the tradeoff.Take California\u2019s high speed rail. Every individual has the right to object. No one wants an eyesore in their backyard. Everyone gets a hearing. Everyone gets a lawsuit. Everyone gets a veto in practice, if not in theory.The result is predictable. I will never see a functioning high speed rail system in California in my lifetime. Neither will anyone alive today. Not because we lack money or engineering talent, but because the accumulation of individual rights makes collective action nearly impossible.Now look at China. They decide to build it, and it gets built. If you are in the way, you move. If persuasion fails, coercion follows. Freedoms are not part of the equation.That contrast is uncomfortable, but it is real. Freedom buys dignity and protection from abuse. It also buys paralysis. China sacrifices individual rights and gets infrastructure. California preserves individual rights and gets endless meetings, delays, and nothing on the ground.You can argue which system is morally superior. You cannot argue that they produce the same outcomes.reply",
      "Autocracy can (and perhaps usually does) produce corruption, and there's no guarantee that progress will be beneficial. I agree there are tradeoffs, but it's worth pointing out that sacrificing freedom does not reliably produce useful results.",
      "I think parsing out what kind of freedom would help here. The US has a lot of \u201cfreedom of\u201d but not a lot of \u201cfreedom from.\u201dreply",
      "Any freedom. For example you don't have the freedom to own guns in China.reply",
      "Wait until you live through what Argentina or Brasil have then see how you feel about redress, petition and speech.reply",
      "I'm specifically talking about Chinas' lack of freedoms... which is entirely different then Brasil or Argentina.I don't have the freedom to own a gun in China, but it's safer in China to the point where you don't need a gun. Practically speaking I prefer to have less freedoms simply because you need less freedoms for society to function better AND most of these freedoms that are taken away by China are freedoms most people never exercise.reply"
    ],
    "link": "https://arstechnica.com/science/2026/02/court-orders-restart-of-all-us-offshore-wind-construction/",
    "first_paragraph": "\n        Trump admin\u2019s \u201cit\u2019s classified\u201d ploy put on hold in five different cases.\n      The Trump administration is no fan of renewable energy, but it reserves special ire for wind power. Trump himself has repeatedly made false statements about the cost of wind power, its use around the world, and its environmental impacts. That animosity was paired with an executive order that blocked all permitting for offshore wind and some land-based projects, an order that has since been thrown out by a court that ruled it arbitrary and capricious.Not content to block all future developments, the administration has also gone after the five offshore wind projects currently under construction. After temporarily blocking two of them for reasons that were never fully elaborated, the Department of the Interior settled on a single justification for blocking turbine installation: a classified national security risk.The response to that late-December announcement has been uniform: The companies building "
  },
  {
    "title": "Joedb, the Journal-Only Embedded Database (joedb.org)",
    "points": 38,
    "submitter": "mci",
    "submit_time": "2026-01-30T16:34:05 1769790845",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=46826454",
    "comments": [
      "Was going to say that I hope Joe doesn't end up going to prison for an unspeakable crime, but then I saw it was an acronym.reply",
      "Is that a Reiser reference or am I missing something?reply",
      "An approach very close to one I've been thinking about lately.My three cents: compact the journal when its size exceeds the actual data size.\nWith thresholds or other knobs; with the point being the initial load time should be directly proportional to the amount of actual data. Everything else/older is a backup.reply",
      "The value of the journal having history (with comments and timestamps) is huge. I think what I'd prefer to see is having a start sequence of replay journal, build in-memory structure, optionally move old journal to backup name and write out minimal/compressed/comment-and-timestamp-stripped journal to new file. Optionally could be based on size delta; e.g. write if it's less than half the size of the old journal. This keeps journals as append only, while still giving access to full history. It does require some external management to avoid file usage growth even faster than a single journal; but it reduces startup time, and allows a management strategy like just deleting backup files older than a given date (once they're in cold backup, if needed).reply",
      "It is very valuable but compaction enables a number of use cases where events are generated in significant quantity or you need to save space, like if you\u2019re implementing event sourcing at thw GUI layer (the event store is basically a journal).reply",
      "But the event store is also your undo stack, then. Keeping it infinite (or deliberately trimming it at application launch) improves user experience.reply"
    ],
    "link": "https://www.joedb.org/index.html",
    "first_paragraph": "\u00a9 Copyright R\u00e9mi Coulom."
  },
  {
    "title": "Firefox Getting New Controls to Turn Off AI Features (macrumors.com)",
    "points": 65,
    "submitter": "stalfosknight",
    "submit_time": "2026-02-02T23:54:02 1770076442",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=46864120",
    "comments": [
      "Of all the unnecessary AI integrations; firefox is the one I am least concerned or annoyed about. I will however be disabling anything AI related they introduce.reply",
      "Why are there controls to turn off AI features, but no controls to turn on AI features?reply",
      "Those are helpfully enabled by default, you can put your feet up, Moz has you covered.reply",
      "Because Firefox users have been clamoring for the ability to turn them off rather than the opposite.reply",
      "I think you misunderstand. Firefox users have wanted this to be opt-in or explicit-choice rather than opt-out.The implication is that all future AI features will be opt-out.reply",
      "I think they're asking why it has to be opt-out rather than opt-in.reply",
      "Official announcement: https://blog.mozilla.org/en/firefox/ai-controls/reply",
      "I'm worried that this will require yet another config change on top of the already-ridiculous pile. (A listing was discussed 3 months ago at https://news.ycombinator.com/item?id=45696752 )reply",
      "If you click through you can see that the new feature includes a single toggle to turn off all current and future AI.reply",
      "That's the third-best design they could have. Second-best would be having a toggle to turn on AI. Best would be going back to building a browser and leaving out the AI entirely, or putting it in some other product that they only consider funding after they get back to 50% market share for the browser.reply"
    ],
    "link": "https://www.macrumors.com/2026/02/02/firefox-ai-toggle/",
    "first_paragraph": ""
  },
  {
    "title": "4x faster network file sync with rclone (vs rsync) (2025) (jeffgeerling.com)",
    "points": 257,
    "submitter": "indigodaddy",
    "submit_time": "2026-01-30T03:17:32 1769743052",
    "num_comments": 130,
    "comments_url": "https://news.ycombinator.com/item?id=46820142",
    "comments": [
      "Note there is no intrinsic reason running multiple streams should be faster than one [EDIT: \"at this scale\"]. It almost always indicates some bottleneck in the application or TCP tuning. (Though, very fast links can overwhelm slow hardware, and ISPs might do some traffic shaping too, but this doesn't apply to local links).SSH was never really meant to be a high performance data transfer tool, and it shows. For example, it has a hardcoded maximum receive buffer of 2MiB (separate from the TCP one), which drastically limits transfer speed over high BDP links (even a fast local link, like the 10gbps one the author has). The encryption can also be a bottleneck. hpn-ssh [1] aims to solve this issue but I'm not so sure about running an ssh fork on important systems.1. https://github.com/rapier1/hpn-sshreply",
      "> TCP tuningI think a lot of file transfer issues that occur outside of the corporate intranet world involve hardware that you don't fully control on (at least) one hand. In science, for example, transferring huge amounts of data over long distances is pretty common, and I've had to do this on boxes that had poor TCP buffer configurations. Being able to multiplex your streams in situations like this is invaluable and I'd love to see more open source software that does this effectively, especially if it can punch through a firewall.reply",
      "> Note there is no intrinsic reason running multiple streams should be faster than one.The issue is the serialization of operations. There is overhead for each operation which translates into dead time between transfers.However there are issues that can cause singular streams to underperform multiple streams in the real world once you reach a certain scale or face problems like packet loss.reply",
      "Is it certain that this is the reason?rsync's man page says \"pipelining of file transfers to minimize latency costs\" and https://rsync.samba.org/how-rsync-works.html says \"Rsync is heavily pipelined\".If pipelining is really in rsync, there should be no \"dead time between transfers\".reply",
      "The simple model for scp and rsync (it's likely more complex in rsync):\nfor loop over all files.  for each file, determine its metadata with fstat, then fopen and copy bytes in chunks until done.  Proceed to next iteration.I don't know what rsync does on top of that (pipelining could mean many different things), but my empirical experience is that copying 1 1 TB file is far faster than copying 1 billion 1k files (both sum to ~1 TB), and that load balancing/partitioning/parallelizing the tool when copying large numbers of small files leads to significant speedups, likely because the per-file overhead is hidden by the parallelism (in addition to dealing with individual copies stalling due to TCP or whatever else).I guess the question is whether rsync is using multiple threads or otherwise accessing the filesystem in parallel, which I do not think it does, while tools like rclone, kopia, and aws sync all take advantage of parallelism (multiple ongoing file lookups and copies).reply",
      "> I guess the question is whether rsync is using multiple threads or otherwise accessing the filesystem in parallelNo, that is not the question. Even Wikipedia explains that rsync is single-threaded. And even if it was multithreaded \"or otherwise\" used concurent file IO:The question is whether rsync _transmission_ is pipelined or not, meaning: Does it wait for 1 file to be transferred and acknowledged before sending the data of the next?Somebody has to go check that.If yes: Then parallel filesystem access won't matter, because a network roundtrip has brutally higher latency than reading data sequentially of an SSD.reply",
      "The filesystem access and general threading is the question because transmission is pipelined and not a thing \"somebody has to go check\".  You just quoted the documentation for it.The dead time isn't waiting for network trips between files, it's parts of the program that sometimes can't keep up with the network.reply",
      "I quoted the documentation that claims _something_ is pipelined.That is extremely vague on what that is and I also didn't check that it's true.Both the original claim \"the issue is the serialization of operations\" and the counter-claim all sound like extreme guesswork or me. If you know for certain, please link the relevant code.Otherwise somebody needs to go check what it actually does; everything else is just speculating \"oh surely it's the files\" and then people remember stuff that might just be plain wrong.reply",
      "Speculation isn't the most useful thing, but saying \"that is not the question\" to valid speculation is even less useful.reply",
      "Note that rsync on many small files is slow even within the same machine (across two physical devices), suggesting that the network roundtrip latency is not the major contributor.reply"
    ],
    "link": "https://www.jeffgeerling.com/blog/2025/4x-faster-network-file-sync-rclone-vs-rsync/",
    "first_paragraph": ""
  },
  {
    "title": "Carnegie Mellon Unversity Computer Club FTP Server (128.237.157.9)",
    "points": 6,
    "submitter": "1vuio0pswjnm7",
    "submit_time": "2026-01-29T05:59:23 1769666363",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "http://128.237.157.9/pub/",
    "first_paragraph": "Welcome to the Computer Club mirrors, a service of the Carnegie Mellon University Computer Club.\nRequests for additional mirrors will be considered on the basis of relevance\nand available disk space. Send mail to gripe@club.cc.cmu.edu.  Monetary and/or\nhardware contributions are welcome!  Please send us mail if you would like to\nmake a contribution.On 2015-11-17, we were notified that the file parties/2012/demodays12/realtime_demo_size_limited/horology_www.exe was flagged by Sym^H^H^H^H a commercial antivirus vendor as malware, tainting their rating of the andrew.cmu.edu domain, and leading to \"scary browser warnings\". We were ordered to remove this file and it is not currently available. Sorry.\n\n\nDue to U.S. Exports Regulations, all cryptographic software on this\nsite is subject to the following legal notice:\nThis site includes publicly available encryption source code\nwhich, together with object code resulting from the compiling of\npublicly available source code, may be exported from"
  },
  {
    "title": "Nano-vLLM: How a vLLM-style inference engine works (neutree.ai)",
    "points": 217,
    "submitter": "yz-yu",
    "submit_time": "2026-02-02T12:52:35 1770036755",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=46855447",
    "comments": [
      "The whole thing feels AI written, generated from the codebase.**this is incorrect per the author\u2019s response, my apologies.For instance, it goes into (nano)vLLM internals and doesn\u2019t mention PagedAttention once (one of the core ideas that vLLM is based on)[1].Also mentions that Part 2 will cover dense vs MoE\u2019s, which is weird because nanovllm hardcodes a dense Qwen3 into the source.Here are better (imo) explainers about how vLLM works:- https://hamzaelshafie.bearblog.dev/paged-attention-from-firs...- https://www.aleksagordic.com/blog/vllm- https://huggingface.co/blog/continuous_batchingAleksa\u2019s blog is a bit in the weeds for my taste but it\u2019s really worth working through.A lot of the magic of vLLM happens in the PagedAttention kernels, which are really succinctly implanted in nanovllm. And the codebase is great and readable by itself!\u20141. https://arxiv.org/abs/2309.06180reply",
      "Hi jbarrow, thanks for your feedback and the links you shared\u2014they're great readings for me (and likely others too).That said, I need to clarify: the content was not written by AI, and certainly not generated from a database in one shot. If there's some agent + prompt that can produce what I wrote, I'd love to learn it\u2014it would've saved me two weekends :)Before addressing your questions further, some context: I'm a developer with no ML background but plenty of Cloud Infra experience. I'm currently building an open-source AI Infra project, which is why I studied nano-vllm. So my writing reflects some gaps in ML knowledge.To your specific points:> it goes into (nano)vLLM internals and doesn't mention PagedAttention onceI didn't find any explicit \"paged attention\" naming in nano-vllm. After reading the first article you linked\u2014specifically the \"Paged KV Caching\" section\u2014I believe the block management logic and CPU/GPU block mapping it describes is exactly what I covered in both posts. It may not be the full picture of paged attention, but I interpreted what I saw in the code and captured the core idea. I think that's a reasonable outcome.> Part 2 will cover dense vs MoE's, which is weird because nanovllm hardcodes a dense Qwen3 into the sourceThis reflects my learning approach and background. Same as point 1\u2014I may not have realized the block design was the famous PagedAttention implementation, so I didn't name it as such. For point 2, seeing a dense Qwen3 naturally made me wonder how it differs from the xx-B-A-yy-B MoE models I'd seen on Hugging Face\u2014specifically what changes in the decoder layers. That curiosity led me to learn about MoE and write it up for others with the same questions.---I completely understand that in this era, people care more about whether what they're reading is AI-generated\u2014no one wants to waste time on low-effort slop with no human involvement.But as I explained above\u2014and as my hand-drawn Excalidraw diagrams show (I haven't seen an LLM produce diagrams with logic that satisfies me)\u2014this is the result of learning shaped by my own knowledge background and preferences.reply",
      "Funny, this reads even more AI written than the article itself.reply",
      "It really doesn't.reply",
      "One thing to keep in mind is that a lot of non-native English speakers use LLMs to translate to English, or to polish their English prose; they may not realize that it causes the translation to come out in a very LLM-style tone. Not sure if that's the case here, but it looks like OP is a native Chinese speaker so may be using tools to translate to English.reply",
      "It looks like you were right about that.https://news.ycombinator.com/item?id=46858409But: this was never a problem and now we have to distinguish between LLM generated, human generated, LLM polished and human generated. I'd much prefer it if people just wrote their own text, warts and all.reply",
      "It does, but what does that say about the state of communication in our industry? I've seen a lot of writing that reads like an AI produced it in contexts where I could be pretty sure no AI was involved. We want to sound professional, so we sanitize how we write so much that it becomes... whatever this current situation is.No offense intended to @yz-yu, by the way. I miss the times when more people wrote in an eccentric style -- like Steve Yegge -- but that doesn't detract from what you wrote.reply",
      "The comments here turned out much more interesting than I expected\u2014this has become a great place to discuss the difference between AI-generated, AI-written, and AI-assisted content.So let me start from @jbarrow's comment: \"AI written, generated from the codebase.\"My actual learning process looked like this:1. I walked through the nano-vLLM codebase, asking Claude Code some high-level questions to warm up.\n2. Then I asked detailed questions one by one, let it explore, and double-checked the code myself. As someone without an ML background, it sometimes took hours to understand a single concept.\n3. Once I felt I understood enough, I started drawing Excalidraw diagrams to explain what I learned.Does this count as \"generated from the codebase\"? I don't think so.Where we might disagree is the writing process.As a non-native English speaker, my workflow looks like this:1. Write a short paragraph (<100 words), then ask my writing agent to \"fix this for readability and grammar.\"\n2. Review the output. *If it changes any technical meaning, I correct it.* I consider this a responsible way to write a tech blog.\n3. Move to the next paragraph.Is this \"AI-written\"? I'd call it \"AI-assisted.\" Every idea in every sentence is mine. Honestly, things like \"em dashes\" never stood out to me when reviewing. I suspect that's common for non-native speakers.I wrote this comment the same way. The LLM fixed 14 grammar mistakes that I think would distract readers more than any LLM-ish phrasing.That said, I'm open to suggestions on how to improve my writing process :)reply",
      "When text is (clearly) non native English I think most native readers don\u2019t even register grammar errors.To be honest most native readers wouldn\u2019t register grammar errors full stop.I guess I have more awe of people who speak a foreign language at all compared to piping it through some agent malarkey.reply",
      "Cool, humans hallucinate too. \u2014 AIreply"
    ],
    "link": "https://neutree.ai/blog/nano-vllm-part-1",
    "first_paragraph": "When deploying large language models in production, the inference engine becomes a critical piece of infrastructure. Every LLM API you use \u2014 OpenAI, Claude, DeepSeek \u2014 is sitting on top of an inference engine like this. While most developers interact with LLMs through high-level APIs, understanding what happens beneath the surface\u2014how prompts are processed, how requests are batched, and how GPU resources are managed\u2014can significantly impact system design decisions.This two-part series explores these internals through Nano-vLLM, a minimal (~1,200 lines of Python) yet production-grade implementation that distills the core ideas behind vLLM, one of the most widely adopted open-source inference engines.Nano-vLLM was created by a contributor to DeepSeek, whose name appears on the technical reports of models like DeepSeek-V3 and R1. Despite its minimal codebase, it implements the essential features that make vLLM production-ready: prefix caching, tensor parallelism, CUDA graph compilation, a"
  },
  {
    "title": "Advancing AI Benchmarking with Game Arena (blog.google)",
    "points": 108,
    "submitter": "salkahfi",
    "submit_time": "2026-02-02T17:49:07 1770054547",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=46858873",
    "comments": [
      "This is a good way to benchmark models. We [the SWE-bench team] took the meta-version of this and implemented it as a new benchmark called CodeClash -We have agents implement agents that play games against each other- so Claude isn't playing against GPT, but an agent written by Claude plays poker against an agent written by GPT, and this really tough task leads to very interesting findings on AI for coding.https://codeclash.ai/reply",
      ">this really tough task leads to very interesting findings on AI for codingAre you going to share those with the class or?reply",
      "https://ai.meta.com/research/publications/gaia-a-benchmark-f...?reply",
      "Cool to see core war! I feel it's mostly forgotten by now. My dad is still playing it to this day though and even attends tournamentsreply",
      "Leaderboard looks very outdated..reply",
      "I believe that if a model can outperform humans in all board/card games, and can autonomously complete all video games, then AGI \u2014 or even ASI \u2014 has essentially been achieved. We\u2019re still a long way from that.reply",
      "Oh hey, I've been running Werewolves/Mafia games as benchmarks for a while nowhttps://mafia-arena.comGemini is consistently winning against top modelsreply",
      "Let's add NetHack to the mix!https://kenforthewin.github.io/blog/posts/nethack-agent/reply",
      "I'd really like to see them add a complex open world fully physicalized game like Star Citizen (assuming the game itself is stable) with a single primary goal like accumulating currency as a measure of general autonomy and a proxy for how the model might behave in the real world given access to a bipedal robot.reply",
      "I feel uneasy about werewolf being included here. I don't want AI labs to actively try and make their LLMs deceptive!reply"
    ],
    "link": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/",
    "first_paragraph": "Learn more:Learn more:Learn more:Learn more:Learn more:Learn more:Feb 02, 2026\n          Decisions in the real world are rarely based on the perfect information found on a chessboard. We are updating Kaggle Game Arena with two new games \u2014 Werewolf and poker \u2014 to benchmark how models navigate social dynamics and calculated risk.\n        \nGoogle DeepMind is expanding its Game Arena platform to benchmark AI models in more complex scenarios. You can now test your models in Werewolf and poker in addition to chess. Watch live tournaments on Kaggle to see how the top models perform in these games.\nGoogle DeepMind is expanding its Game Arena platform to benchmark AI models in more complex scenarios. You can now test your models in Werewolf and poker in addition to chess. Watch live tournaments on Kaggle to see how the top models perform in these games.\n\nGoogle DeepMind's \"Game Arena\" article discusses using games to benchmark AI, moving beyond perfect information scenarios.\nGame Arena expands "
  },
  {
    "title": "The largest number representable in 64 bits (tromp.github.io)",
    "points": 80,
    "submitter": "tromp",
    "submit_time": "2026-02-02T18:31:36 1770057096",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=46859443",
    "comments": [
      "To the author: this work you've published rests on some background knowledge that I'm familiar with but also a lot of background knowledge that's foreign to me.  For the parts I was able to follow, I thought the mental gear-turning was enjoyable and interesting!  But pursuing these intersections between algebra and computer science is often not so interesting, at least, when I research it myself.  Is this something you've learned in university?  I ask because I fear that without a formal learning environment, I may never pick up on the more advanced logic halfway through the article.  Anyway, cheers to the good work.reply",
      "Hi guys, I've come up with a new 64 bit number representation where 0xFFFFFFFF is infinity. Hell you know what every value is just infinity.reply",
      "Assuming your representation's infinity is size of \u2135\u2080, I set my representation's 0xFFFF_FFFF to the size of \u2135\u2081. Similarly, if you choose \u2135_(n), I'm choosing \u2135_(n+1).reply",
      "Which infinity?reply",
      "This feels like the computer science version of this article: https://www.scottaaronson.com/writings/bignumbers.htmlreply",
      "I can do you one better. I can represent the largest number with a single binary bit.reply",
      "I can do it in half a bitreply",
      "Slow down there mr zip filereply",
      "Related. Others?The largest number representable in 64 bits - https://news.ycombinator.com/item?id=38414303 - Nov 2023 (105 comments)The largest number representable in 64 bits - https://news.ycombinator.com/item?id=35677148 - April 2023 (42 comments)(I haven't put 2023 in the current title since the article says it's been significantly expanded since then.)reply",
      "Please no more comments to the extent of \"i can define a much larger number in only 1 bit\". What makes my blog post (hopefully) interesting is that I consider tiny programs for computing huge numbers in non-cheating languages, that are not specifically equipped for doing so.reply"
    ],
    "link": "https://tromp.github.io/blog/2026/01/28/largest-number-revised",
    "first_paragraph": "28 Jan 2026This post is a rewrite of my earlier blog post from\nNov 2023\nwith many new insights and updates.Most people believe 264-1 = 18446744073709551615, or\n0xFFFFFFFFFFFFFFFF in hexadecimal, to be the largest number\nrepresentable in 64 bits. In English, it\u2019s quite the mouthful: eighteen\nquintillion four hundred forty-six quadrillion seven hundred forty-four\ntrillion seventy-three billion seven hundred nine million five hundred\nfifty-one thousand six hundred fifteen.That is indeed the maximum possible value of 64 bit unsigned integers,\navailable as data type uint64_t in C or u64 in Rust. \nFloating point data types can represent much larger values, courtesy of their base 2 exponent.\nThe 64-bit double floating\npoint format has a largest (finite) representable value of 21024(1-2-53) ~ 1.8*10308.What if we allow representations beyond plain data types?\nSince we want representations to remain computable, the most general\nkind of representation would be a program in some programming langu"
  },
  {
    "title": "Todd C. Miller \u2013 Sudo maintainer for over 30 years (millert.dev)",
    "points": 296,
    "submitter": "wodniok",
    "submit_time": "2026-02-02T17:25:26 1770053126",
    "num_comments": 172,
    "comments_url": "https://news.ycombinator.com/item?id=46858577",
    "comments": [
      "30+ years maintaining one of the most critical pieces of infrastructure on nearly every Linux and Unix system, and he's currently looking for a sponsor to fund continued development. Every company running sudo in production owes this man. Someone should fix thatreply",
      "This is a good example of Diffusion of Responsibility.Everybody thinks somebody else should help, so nobody does.reply",
      "I don't think they even see it as their responsibility, more, \"If he wanted money, he should have charged for his software\".reply",
      "If he actually did charge money someone else would've written an implementation of sudo to solve their own needs and avoid the overhead of transacting with a random developer.reply",
      "I mean, he should just put a message when you run sudo the first time asking for funding if he wants it that bad, that should speed things up.reply",
      "Seriously, just put a VAT on digital services to fund a system that pays out grants to individuals to help maintain open source software. It should be obvious by now that corporations will rat fuck the commons for monetary gain and there is a serious need for democratic initiatives to put technology back into the hands of the people.reply",
      "Whenever people say that MIT or GPL licenses are a good idea I point out projects like this.Only humans should have freedom zero. Corporations and robots must pay.reply",
      "I am not sure sudo is licensed under MIT or GPL, looks it's like a mix of licenses[1].  The end of the first license says it's sponsored in part by DARPA.From 2010 to February 2024, it was sponsored by Quest Software according to the history page[2].[1] https://github.com/sudo-project/sudo/blob/main/LICENSE.md[2] https://www.sudo.ws/about/history/reply",
      "> Corporations and robots must pay.Greenpeace is a (non-profit) corporation. Unions are corporations. Municipalities. Colleges and universities.* https://en.wikipedia.org/wiki/Legal_personShould they have to pay?reply",
      "Yes. Non-profits are more than capable of abusing the commons, the purpose of even small monetary requirements is to put a bound on that.reply"
    ],
    "link": "https://www.millert.dev/",
    "first_paragraph": "Note: this page tends be neglected and is only updated occasionally.\nThe links to the left are where the useful bits are hiding.For the past 30+ years I\u2019ve been the maintainer of\nsudo.  I\u2019m currently in search of a sponsor\nto fund continued sudo maintenance and development.  If you or\nyour organization is interested in sponsoring sudo, please let me\nknow.I also work on OpenBSD, though my I\u2019m\nnot as active there as I once was.In the past, I\u2019ve made large contributions to\nISC cron, among other projects."
  },
  {
    "title": "Zig Libc (ziglang.org)",
    "points": 148,
    "submitter": "ingve",
    "submit_time": "2026-02-02T17:28:19 1770053299",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=46858622",
    "comments": [
      "250 C files were deleted. 2032 to go. Watching Zig slowly eat libc from the inside is one of the more satisfying long term projects to followreply",
      "\"Abolish ICE\" at the bottom. Obviously a Bad Bunny fan, as I am.reply",
      "The very same day I sat at home writing this devlog like a coward, less than five miles away, armed forces who are in my city against the will of our elected officials shot tear gas, unprovoked, at peaceful protestors, including my wife.https://www.kptv.com/2026/01/31/live-labor-unions-rally-marc...This isn't some hypothetical political agenda I'm using my platform to push. There's a nonzero chance I go out there next weekend to peacefully protest, and get shot like Alex Pretti.Needless to say, if I get shot by ICE, it's not good for the Zig project. And they've brought the battle to my doorstep, almost literally.Abolish ICE.reply",
      "Andy keep safe. We gotta all come to realization that none of this is possible if we let our democracy slip away. Millions before us died to preserve it. We owe it to them to put up a good fight.reply",
      "My 85 year old mom lives in Portland and she attends rallies frequently. If you know of any way to support you or other local people doing this work, I'm very interested. My email is on my profile page.I have a friend who is in Minneapolis. He's involved in caravans which are tracking ICE. He wasn't the driver in the last one. But, the ICE vehicle they tailed suddenly started going in a very direct path, instead of randomly driving. The driver figured it out first. They drove to the driver's house and then stood outside of their car for ten minutes staring at his house. Cars in Minnesota have their license plates on both the front and the back.Is there any justification for that kind of intimidation? Did any of the Trump supporters vote for that? I hear about paid agitators on the left but not that kind of compensated actors. Is his name in a database now once they did the lookup?reply",
      "[flagged]",
      "The Department of Homeland Security was created in 2003. We didn't need it then and we don't need it now.Why waste tax dollars on ineffective, privacy-violating security theater when we could spend it on education and health?reply",
      "You didn't answer or even address a single question I asked. I'll ask again:1. Are you OK with sovereign states enforcing their borders and deporting illegal immigrants?2. Is it the awful tactics ICE uses to accomplish its mission, or do you find the mission in and of itself immoral?reply",
      "ICE's current mission isn't to deport illegal immigrants. Its current mission is to antagonize anyone who is not a WASP, and seemingly these days, anybody who stands up for non-WASP citizens in the US. As can be easily ascertained by the sheer number of encounters where the officers insist that they don't actually care to see any papers proving the people they're arresting are legal US citizens (let alone legal US residents).So your questions don't matter because you're arguing about a reality that doesn't exist.reply",
      "You'd have a lot stronger argument if ICE wasn't being used as a secret police force. They're Immigration Enforcement in name only. Your average citizen would say it's okay to enforce immigration laws, there is no doubt about that; doing middle-of-the-night raids with a blackhawk helicopter in cities of your political opponents is not reasonable[0]. There are plenty more examples of their abhorrent behavior (like killing two American citizens in the midwest and brutalizing protestors) if you cared to search for it.I've noticed that the MAGAs have been adamant about trying to shift the window back to: \"but you agree that immigrants should be deported right?\" as some sort of attempt to justify what's happening, I guess. Is that talking point coming from some popular right wing show or something as a last ditch effort before midterms?0: https://www.propublica.org/article/chicago-venezuela-immigra...reply"
    ],
    "link": "https://ziglang.org/devlog/2026/#2026-01-31",
    "first_paragraph": "This page contains a curated list of recent changes to main branch Zig.\n      Also available as an\n      RSS feed.\n    \n      This page contains entries for the year 2026. Other years are available in\n      the Devlog archive page.\n    Author: Andrew KelleyOver the past month or so, several enterprising contributors have taken an interest in the zig libc subproject. The idea here is to incrementally delete redundant code, by providing libc functions as Zig standard library wrappers rather than as vendored C source files. In many cases, these functions are one-to-one mappings, such as memcpy or atan2, or trivially wrap a generic function, like strnlen:So far, roughly 250 C source files have been deleted from the Zig repository, with 2032 remaining.With each function that makes the transition, Zig gains independence from third party projects and from the C programming language, compilation speed improves, Zig\u2019s installation size is simplified and reduced, and user applications which stat"
  },
  {
    "title": "Training a trillion parameter model to be funny (sdan.io)",
    "points": 15,
    "submitter": "sdan",
    "submit_time": "2026-01-27T16:58:05 1769533085",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=46782692",
    "comments": [
      "Some models are better at generating funny and poignant quips.> my human mass-generates new ideas faster than I can research why the previous ones won't work> this is called 'job security'(https://nitter.poast.org/LetheAgent/status/20179595340865499...)reply",
      "Circa GPT-3.5 to GPT-4o I was involved in some research in figuring out how to make LLMs funny. We tried a bunch of different things, from giving it rules on homonym jokes [1], double-entendre jokes, fine tuning on comedian transcripts, to fine tuning on publicly rated joke boards.We could not make it funny. Also interesting was that when CoT research was getting a lot of attention, we tried a joke version of CoT, asking GPT4 to explain why a joke was funny in order to produce training set data. Most of the explanations were completely off base.After this work, I became a lot less worried about the GAI-taking-over narrative.Funny is very, very hard.[1] without a dictionary, which at first seems inefficient, but this work demonstrated that GPT could perfectly reconstruct the dictionary anywayreply",
      "I once had a vivid dream that AI robots had taken over & were keeping humans around because they'd not yet mastered comedy. All of human culture globally was a comedy arms race with 24/7 open mic comedy jams on every corner.They (the machines) had billboards/signage everywhere showing the estimated time left for humanity. A really good joke would lead the timer to grow (until they figured out how to produce the general patterns needed to both create and appreciate the joke).reply",
      "openclaw, turn this into a broadway production, book me two front row seats, hire an escort..... brunette, 28, slim waist, sweet face, hates comedy and AIreply",
      "these really aren't very funnyreply",
      "It would be easier to judge this if the jokes weren't 90% about AI and silicon valley, understandable only to people who subscribe to astralcodextenreply",
      "I thought this one was not bad:    [write a joke about thinking machines and the idea of tropes]\n\n    it's funny how enemies to lovers is a common trope that's uncommon in real life and lovers to enemies is an uncommon trope that's common in real lifereply",
      "Probably because if they weren\u2019t absurdly esoteric we\u2019d be able to tell it isn\u2019t funny.reply",
      "Who's tommipink? Even a Google search couldn't explain that one.reply"
    ],
    "link": "https://jokegen.sdan.io/blog",
    "first_paragraph": "Rubric RL on Kimi K2 1TIn an interview last month, someone asked how I'd train a model on a qualitative reward. I'd been working on a geo-guessing model where the reward is distance in kilometers--quantitative, verifiable. They brought up comedy as a counterexample. If two people disagree on whether something is funny, who's wrong? You can't say either of them is. There's no reward function for funny.I didn't have a good answer at the time. But Tinker recently made it possible to post-train Kimi K2, Moonshot's 1 trillion parameter model. Moonshot themselves used rubric-based RL to boost Kimi's creative writing scores--instead of grading \"good writing\" directly, they decomposed it into specific rubrics like clarity, engagement, and tone. I wanted to try the same approach for comedy: decompose \"funny\" into properties that are verifiable. In my naive opinion, a really good joke is recent, relevant, and shows deep understanding of its subject--you have to grasp a concept with high enough f"
  }
]