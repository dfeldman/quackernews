[
  {
    "title": "Goodbye, Slopify (alexeystar.com)",
    "points": 43,
    "submitter": "surprisetalk",
    "submit_time": "2025-01-29T00:51:25 1738111885",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=42860113",
    "comments": [
      "without any hate to the well intentioned engineers working on the thing, spotify has just exceedingly poor product taste in any number of dimensions- the godawful ai dj they tried to force on pple- buying gimlet media and running it into the toilet- locking up joe rogan and whoever to try to put walled gardens around podcasting (to this day when you go to a spotify page for a podcast it acts like it has never heard of \"RSS\" or \"mp3\". fucking offensive)- they habitually screw over musicians https://harpers.org/archive/2025/01/the-ghosts-in-the-machin...- reggie watts: https://www.instagram.com/p/DEhAr7lx7CI/?igsh=bXBpZ25kczMyZ3...- bjork: https://variety.com/2025/music/news/bjork-spotify-streaming-...- they faked spotify wrapped numbers https://x.com/hello__caitlin/status/1864367028758565216?s=46- this is petty but they are a big step back from winamp and that is just slop https://x.com/riomadeit/status/1878556039676666024\n \nreply",
      "if you are a l33t h4ck3r you too can despotify your life:- get youtube premium, has youtube music with it. youtube music is basically straight superset of spotify.- https://github.com/jam3scampbell/music\n \nreply",
      "AI generated music should be against the terms and what we decided to pay for.\n \nreply",
      "I thought the headline was mocking Shopify, not Spotify.  It shows how little creativity we have in tech company naming.I wonder which suffix is more popular, -ify, -ly, or -r.\n \nreply",
      "I feel like -r is an old school internet thing. I wonder if anybody has data for trends over time.\n \nreply",
      "Thought it was going to be about Shopify.\n \nreply",
      "This is an area where Apple can choose to Be Different and not allow their platform to melt into a puddle of slop. I hope they have what it takes.\n \nreply",
      "I stoped using Spotify when they committed the unforgivable UI sin of \"loading a page and then moving elements on that page when web calls complete\" that resulted in me clicking on something other than what I had intended to because it changed with my thumb a nanometer from the screen. It was a good 20% of the time and it made me insane.\n \nreply",
      "I stopped paying for Spotify years ago and instead make playlists on there that I can feed into any of the various websites that will rip mp3s for you. Yes they are 128kbps, but for casual listening, it's fine. Some tools will try to match against YouTube and download audio from there, since apparently in some cases YouTube will have higher audio quality.Unfortunately the free version of the Spotify iOS app is absolute unusable garbage.\n \nreply",
      "Where do you get the highest quality audio if you want to put in some work? I'd like to jump ship back to a personal library but don't know how I'm gonna extract these 2000 songs I only have 1/4 of locally\n \nreply"
    ],
    "link": "https://alexeystar.com/blog/slopify/",
    "first_paragraph": "My Discover Weekly playlist on Spotify is finally poisoned by AI slop.There\u2019s no way I\u2019m going to continue a subscription to a streaming service that suggests AI-generated music with AI-generated album covers. A bloated, Electron-based desktop application with a terrible UI is only going to add up.So goodbye, Slopify. Thank you for pushing me towards supporting more real artists and buying music that I can actually own.2025-01-26\u2190Cat-alog of the Year\u00a9 2025 Alexey Staroselets\n\u00a0\u2190\ud83d\udd78\ud83d\udc8d\u2192\n\u00a0{xxiivv}"
  },
  {
    "title": "New speculative attacks on Apple CPUs (predictors.fail)",
    "points": 599,
    "submitter": "cylo",
    "submit_time": "2025-01-28T18:31:34 1738089094",
    "num_comments": 228,
    "comments_url": "https://news.ycombinator.com/item?id=42856023",
    "comments": [
      "Their SLAP demo provides a great example of how defence-in-depth can make/break the viability of an exploit. That terrifying Safari demo is possible because Safari fails to isolate new windows in individual processes when calling `window.open` in js.All the other side channel magic presented here doesn't matter if the data you want to read is in a seperate process with sufficient separation from the \"hostile\" process in the address space.\n \nreply",
      "That's not a failure of Safari, it's required by window.open API semantics, in particular by the default Cross-Origin-Opener-Policy of \"unsafe-none\" [1].By setting a different policy, sites can protect themselves against this.I guess technically browsers could open new windows in a new browsing context group regardless of this setting and relay the allowed types of messages via IPC (if any), but that would be a major performance hit, and I don't think any other browsers do it differently.[1] https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cr...\n \nreply",
      "Can't edit my original post anymore: Firefox and Chrome do seem to isolate even same-browsing-context-group and bridge the required APIs via IPC, so hopefully Safari will catch up at some point.Basically, there are three scenarios:- Completely unrelated tabs (e.g. those you open manually, those opened via command-click, tabs opened via '<a target=\"_blank' ...>\" or 'rel=\"noopener\"' references etc.) \u2013 these are relatively easily isolated if the browser supports it at all. All major (desktop!) browsers now largely do this, including Safari.- \"Same browsing context group\" (but different origin) sites. These can communicate via various APIs, and historically that was achieved by just letting them run in the same rendering process. But in the face of attacks such as this one, this can be insecure. Firefox and Chrome provide sandboxing via separate processes; Safari does not.- Same origin sites (without any stricter policy). These can fully access each other's DOM (if they have an opener/opened relationship), so there's not really any point in having them live in different renderers except possibly for fault isolation (e.g. one of them crashing not taking the other down). As far as I know, all browsers render these in the same process.Sites can opt out of the second and third category into the first via various HTTP headers and HTML link attributes. If we were to design the web from scratch, arguably the default for window.open should be the first behavior, with an opt in to the second, but that's backwards compatibility for you.\n \nreply",
      "Cross-Origin-Opener-Policy seems like a case of bad defaults where a less secure option has been selected so that we don't break some poorly maintained websites. Better to get the actual users of `window.open` to fix their code than to make every website insecure out of the box.I can't imagine there are many sites passing significant amounts of data through this, the small number of users where IPC poses too high a penalty can opt their sites into the \"same process\" flag if really needed.\n \nreply",
      "Forcing every website to adapt to a browser update is completely infeasible.> I can't imagine there are many sites passing significant amounts of data through thisThis is actually a quite common mechanism for popup-based authentication (which is much more secure than iframe-based one, as users can verify where they're potentially entering their credentials).\n \nreply",
      "Expecting websites to defend themselves against CPU side channel attacks is also absurd!\n \nreply",
      "We had the tech in the 80's for the browser to facilitate popup authentication with process isolation. It's this niche and esoteric tech called IPC[1], so niche that one really can't blame Apple for not hearing about it.It truly boggles the mind as to how all the other browsers pull it off.[1]: https://en.wikipedia.org/wiki/Inter-process_communication\n \nreply",
      "To be fair, there wasn't that much sensitive web content around in the 80s to leak (primarily due to the web not yet existing, nor browsers), so it's only fair that browsers didn't consider using IPC for site isolation back then.\n \nreply",
      "The point of my rather facetious comment is that IPC a well known thing (I struggle to even call it \"tech\") that has been around for 30-40 years. I don't understand why Apple needs people to make excuses for them, but this excuse would render Apple vastly more incompetent than neglecting to separate browser tabs in 2025.\n \nreply",
      "Browsers are incredibly complex, and moving them to an IPC model is not easy. Essentially, you need to ensure \"same process like\", performant JavaScript interoperability in some cases, often (but not always) due to backwards compatibility.Firefox has shared a lot about their efforts in moving there. If you're curious, there are a lot of blog posts and internal design docs under their project name \"Project Fission\".But yeah, the fact that both Chrome and Firefox have managed to do so does leave Apple looking slightly bad here.\n \nreply"
    ],
    "link": "https://predictors.fail/",
    "first_paragraph": "\n\t\t\t\t\t\t\t\tWe present SLAP, a new speculative execution attack that arises from optimizing data\n\t\t\t\t\t\t\t\tdependencies, as opposed to control flow dependencies. More specifically, we show that Apple CPUs\n\t\t\t\t\t\t\t\tstarting with the M2/A15 are equipped with a Load Address Predictor (LAP),\n\t\t\t\t\t\t\t\twhich improves performance by guessing the next memory address the CPU will retrieve\n\t\t\t\t\t\t\t\tdata from based on prior memory access patterns.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tHowever, if the LAP guesses wrong, it causes the CPU to perform arbitrary computations\n\t\t\t\t\t\t\t\ton out-of-bounds data, which should never have been accessed to begin with, under\n\t\t\t\t\t\t\t\tspeculative execution. Building on this observation, we demonstrate the real-world\n\t\t\t\t\t\t\t\tsecurity risks of the LAP via an end-to-end attack on the Safari web browser where an\n\t\t\t\t\t\t\t\tunprivileged remote adversary can recover email content and browsing behavior.\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tWe present FLOP, another speculative execution attack that results from recent Apple C"
  },
  {
    "title": "Boom XB-1 First Supersonic Flight [video] (youtube.com)",
    "points": 414,
    "submitter": "rayhaanj",
    "submit_time": "2025-01-28T15:46:53 1738079213",
    "num_comments": 315,
    "comments_url": "https://news.ycombinator.com/item?id=42853633",
    "comments": [
      "Boom (YC W16) \u2013 Supersonic Passenger Airplanes:https://news.ycombinator.com/item?id=11329286I remember seeing this post about Boom going through YC, 9 years ago. It's really cool to see the founder laying out what he wanted to accomplish in the comments and then seeing it happen today. Especially fun looking back at those comments saying it couldn't be done and all the haranguing over the name \"Boom\" :)Congrats to the Boom team! Such a great accomplishment.\n \nreply",
      "It\u2019s a good start but I wouldn\u2019t say the critics are proven wrong already.Even getting the full-scale version flying won\u2019t be enough, you need to make the whole operation economically viable so it actually makes sense to operate it.I\u2019m not saying they won\u2019t manage to do it, but they haven\u2019t proven that they will be able to do it today.\n \nreply",
      "It only needs to be economically viable for billionaires bored with collecting yachts and $100 millionaires who want to flex with charter flights. Scheduled commercial service is a pipe dream but not a requirement for success.\n \nreply",
      "Basically, the critics: \"unless you build a 100B company, we are not wrong\"I mean, yeah, sure.\n \nreply",
      "My metric for success is simply making more money than they spent.Supersonic planes are already proven technology. We made the Concorde and the Tu-144 in the 70s, and have plenty of supersonic military planes in active service. The assumption was simply that you can't make a profit by selling them as civil aviation planes. That's the assumption Boom is challenging, and to be proven correct they have to turn a profit. And not just an operating profit by selling planes for more than they cost to make but make back the research and development costs as well\n \nreply",
      "Success should be measured against the stated objectives, the promises made to investors, or general positive influence on society. In this case the objective was \"supersonic flight in our lifetime. Not just as a private jet, but something most anyone can afford to fly.\" [0]> Basically, the criticsYou're being uncharitable and hyperbolizing the criticism to more easily dismiss it. Would you hyperbolize any praise as \"identifying another way this won't work is also a success in itself\"?[0] https://news.ycombinator.com/item?id=11329286\n \nreply",
      "It\u2019s hard to argue a startup succeed until profits > investment.\n \nreply",
      "This is only true from the point of capital - if a startup changes the world in a way you like it can be a success to you. Profitability brings a certain approval and sustainability, but don't confuse that with your goals in what you are working on.\n \nreply",
      "In what way do you think building a new but still-uneconomic supersonic plane is going to change the world for the better?\n \nreply",
      "Uber and Lyft are largely still unprofitable, but they definitely have changed the landscape, as many would argue, to the better.\n \nreply"
    ],
    "link": "https://www.youtube.com/watch?v=-qisIViAHwI",
    "first_paragraph": ""
  },
  {
    "title": "DeepSeek's multi-head latent attention and other KV cache tricks (pyspur.dev)",
    "points": 146,
    "submitter": "t55",
    "submit_time": "2025-01-28T22:11:36 1738102296",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=42858741",
    "comments": [
      "> This blog post is mostly AI-generated using a PySpur workflow with minor human edits.it's funny that this was clear about 5% in just due to the classic chatgpt-style format and tone\n \nreply",
      "It's blatantly obvious; nobody uses so many bullet points.\n \nreply",
      "True! We love bullet points! :)\n \nreply",
      "Fair point! Do you prefer a different format or tone? We really like the concise bullet point format :)\n \nreply",
      "Not sure if I'm getting this. Is this cache implemented as part of the forward pass through the network, in a general Python datastructure like a dict? Or is the cache somehow part of the fabric of the neural network?\n \nreply",
      "The KV cache is typically stored in a data structure external to the trained weights\u2014often a buffer or set of tensors kept alongside the model\u2019s forward pass (e.g., in PyTorch, one might store it in a dictionary-like container). It\u2019s not baked into the neural network parameters themselves; instead, it\u2019s an auxiliary memory that holds precomputed key-value pairs so the model doesn\u2019t have to re-encode past tokens on each new inference step.\n \nreply",
      "What's specific to deepseek here that other models do not use, or are you just riding the keyword wave?\n \nreply",
      "DeepSeep proposed the multi-head latent attention technique! :)As far as I know, they are the only ones using it so far\n \nreply",
      "Fair point, thanks for clarification, it seems this was first proposed in https://arxiv.org/pdf/2405.04434? I was confused by your title mentioning DeepSeek but then first paragraph revert to \"...language models like ChatGPT and DeepSeek faster at generating text\".\n \nreply",
      "Right, that's a good point. I'll adjust the intro a bit. \nWe wanted to provide a more holistic overview on what MLA is, what came before it, and why it matters :) hope it was useful!\n \nreply"
    ],
    "link": "https://www.pyspur.dev/blog/multi-head-latent-attention-kv-cache-paper-list",
    "first_paragraph": "Jean Kaddour@jeankaddourOverview:Let's start with a simple analogy. Imagine you're writing a story, and for each new word you write, you need to re-read the entire story so far to maintain consistency. The longer your story gets, the more time you spend re-reading. This is exactly what large language models face during text generation!At the heart of modern language models is a mechanism called self-attention. For a sequence of nnn tokens (think of tokens as roughly corresponding to words), each token needs to \"look at\" or \"attend to\" all other tokens to understand the context.This looking-at-everything process has a computational cost that grows with the sequence length:When a language model generates text, it does so one token at a time, and this is where things get computationally expensive:If we add up all these costs for generating a sequence of length nnn, we get:This O(n3)O(n^3)O(n3) cost means that as your text gets longer, the generation time grows extremely quickly. For examp"
  },
  {
    "title": "IAC confirms existence of a Super-earth in the habitable zone of a Sun-like Star (iac.es)",
    "points": 241,
    "submitter": "ohjeez",
    "submit_time": "2025-01-28T15:09:52 1738076992",
    "num_comments": 176,
    "comments_url": "https://news.ycombinator.com/item?id=42853174",
    "comments": [
      "Next year there is a plan to send a space telescope to L2 with the main objective being to search for Earth-like planets around Sun-like stars in the habitable zone.Like Kepler and TESS telescopes it will use the transit method to find new exoplanets, but unlike any mission before, it's going to look at the same spot in the sky for over a year. Super excited to see what data it brings back to us.The telescope is called PLATO ( https://en.wikipedia.org/wiki/PLATO_(spacecraft) )I contributed to the project a few years back, very happy to answer any questions.\n \nreply",
      "L2 as related to space telescopes was a new term to me, and turned out to be utterly fascinating.  The Webb orbits the sun and periodically boosts velocity using Earth's gravity:> The James Webb Space Telescope is not in orbit around the Earth, like the Hubble Space Telescope is \u2013 it actually orbits the Sun, 1.5 million kilometers (1 million miles) away from the Earth at what is called the second Lagrange point or L2.https://science.nasa.gov/mission/webb/orbit/\n \nreply",
      "Very cool. Got a silly sci-fi question for you. IIUC, with current technology it would take on the order of tens of thousands of years for a vessel to physically travel to the closest known Earth-like planet (correct me if I'm wrong).So any thoughts on what kinds of hypothetical breakthroughs would be needed to make the trip doable in (say) less than a human lifetime?And related, what do you think about the plausibility of the [Breakthrough Starshot](https://en.wikipedia.org/wiki/Breakthrough_Starshot) initiative? Aware of any alternative approaches?\n \nreply",
      "Time dilation means that the closer you get to the speed of light the less time you experience passing. So even a 12000 year long journey as seen from earth, if moving fast enough, could feel to the travelers like a much shorter amount of time.\n \nreply",
      "Yes, but practically with todays technology there is no feasible way of getting to a speed where time dilation matters over that distance, we run out of fuel so we need some external power source like a laser or solar wind that have other issues, iirc one only gets to 2x time dilation at 0.9 c. That\u2019s a lot of acceleration.\n \nreply",
      "And we don't have to send people, we should do our job as a Von Neumann probe and send frozen rna to distribute across the surface.\n \nreply",
      "and in that 10,000 year blink, a civilization progresses from bronze metalworking to digital computers, awaiting our arrival\n \nreply",
      "To what extent (if any) will this program be impacted if all U.S. federal grant funding is permanently cut? Are there U.S. funded components/researchers involved?\n \nreply",
      "As far as I know it won't be affected at all, the project is almost fully funded from the European Space Agency. And it will most likely be launched with the European Ariane rocket.\n \nreply",
      "All the more reason why humanity needs multiple space programs.\n \nreply"
    ],
    "link": "https://www.iac.es/en/outreach/news/iac-confirms-existence-super-earth-habitable-zone-sun-star",
    "first_paragraph": "The Instituto de Astrof\u00edsica de Canarias (IAC) and the Universidad de La Laguna (ULL) has confirmed the discovery of a super-Earth orbiting in the habitable zone of HD 20794, a nearby Sun-like star. This discovery, the result of over two decades of observations, opens a window to future studies of Earth-like planetary atmospheres.The search for planets in the habitable zone of Sun-like stars is crucial for understanding the possibility of life beyond Earth and for studying conditions similar to those that enabled the development of life on our own planet. In this context, HD 20794, a star with a slightly lower mass than the Sun and located just 20 light-years away, has always been of great scientific interest. The newly discovered planet is the third planet identified in the system, following the discovery of two super-Earths published more than a decade ago.\u00a0The name of the new planet is HD 20794 d and is a super-Earth with a mass six times that of Earth, taking 647 days to complete a"
  },
  {
    "title": "Maxima in the browser using Embedded Common Lisp on WASM (maxima-on-wasm.pages.dev)",
    "points": 171,
    "submitter": "v9v",
    "submit_time": "2025-01-28T15:37:32 1738078652",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=42853528",
    "comments": [
      "because nobody knows maxima, some things to try. also plot2d/plot3d work, so that's pretty neat. the whole thing is powered by https://ecl.common-lisp.dev and the op announcement is here https://mailman3.common-lisp.net/hyperkitty/list/ecl-devel@c...  :lisp (+ 2 2)\n  solve(f(x)^2-1,x);\n  integrate(x^2,x);\n  2^1024;\n  factor(30!);\n  a:1\n  b:2\n  a+b;\n  sqrt(a^2+b^2);\n  expr: log((x+2)*(x-2))+log(x);\n  ratsimp(expr);\n  fullratsimp(expr);\n  trigsimp(2*cos(x)^2 + sin(x)^2);\n  solve(x^3=1,x);\n  diff(sin(x), x);\n  float([%e,%pi,%phi,%gamma]);\n  f(x):=x^2;\n  f(10);\n  taylor(sin(x),x,0,5);\n  plot2d(x^2-x+3,[x,-10,10]);\n  plot2d([x^2, x^3, x^4 -x +1] ,[x,-10,10]);\n  f(x,y):= sin(x) + cos(y);\n  plot3d(f(x,y), [x,-5,5], [y,-5,5]);\n \nreply",
      "One thing I would add for people who are new to this is you can do??something; to get the internal help.  So say I want to know how to solve ODEs in maxima, do??ode;\n\u2026and you\u2019ll get help.  It generally does a search and presents a numbered list of options and you\u2019ll want to type a number and a semicolon.\n \nreply",
      "Some other useful things:1)solve to solve a system and \u201cvariable: expression\u201d will assign that expression to that variable.  You can then substitute the results into a later expression using a \u201c,\u201d.  So you might do   solns:solve([x+3*y=5,5*x-2*y=4],[x,y]);\n   z:%e^(x,y),solns;\n\nThat will solve the system and then substitute those solutions into the expression for z.2)pi, e, and the imaginary unit are called %pi, %e and %i respectively.3)The symbolic solver is a lot less powerful than mathematica but you can do   load(\u201cto_poly_solve\u201d);\n\nTo get a polynomial solver that will at least get you all the roots of polynomials and does better on most trigonometric equations.   load(\u201cdrawdf\u201d);\n\nIs useful for drawing vector fields, phase portraits and that type of thing.4) you can use a single quote to delay evaluation of something.  Like say you want to write a differential equation and you don\u2019t want it to actually try to evaluate the derivative inline, you can write something like   osc:\u2018diff(x,t,2) + r*\u2019diff(x,t) + k*x = p*cos(omega\\*t);\n\n\u2026for a forced harmonic oscilator. Or whatever. This is useful if you want to mess with the expression a bit before you try to solve the expression (eg doing substitutions or whatnot).*\n \nreply",
      "Thank you! As someone with no prior Maxima experience, those were some great starting points for me to learn and explore!Note `plot3d(...);` doesn't seem to work: the output image is missing/broken.\n \nreply",
      "you probably didn't define the function, f(x,y), which is the line before plot3d. it's a slightly buggy behavior\n \nreply",
      "plot3d did work for me (on Chrome).  Impressive.\n \nreply",
      "(to_lisp);\n(loop for i below 1000000 count t) takes 0.34 seconds on my system with vanilla maxima (on gcl). In the browser it takes about 7 seconds, so it must be a factor of 21 in computer time. Using sbcl outside maxima  it takes 0.002 seconds. So one can get some idea about performance.Perhaps it could be combined with J (array language), like in the playground https://code.jsoftware.com/wiki/Playground that is using webassemblyIt seems to work very well locally without connection to the web.\n \nreply",
      "Apart from the restriction to bytecode interpretation already mentioned, one reason for the slowness is that the sort of C with garbage collection that ECL needs is quite difficult to do in Webassembly. There is no way to scan previous stack frames for pointers in wasm, so all pointers to heap objects (or everything that looks like it might be one) have to be kept around somewhere in the heap where the GC can find them. This is really expensive and slows down the code a lot.Of course, another approach would be to use the new wasm GC interface. But that requires defining a new ABI for garbage collected C, writing a new backend for LLVM, etc. So that would also be a lot of work to implement. Right now, there just is no efficient way to run programs that depend on bdwgc on wasm.\n \nreply",
      "What is bdwgc ? gc==garbage collection ?\n \nreply",
      "The Boehm-Demers-Weiser garbage collecting memory allocation library.https://www.hboehm.info/gc/\n \nreply"
    ],
    "link": "https://maxima-on-wasm.pages.dev/",
    "first_paragraph": ""
  },
  {
    "title": "TokenVerse: Multi-Concept Personalization in Token Modulation Space by Google (token-verse.github.io)",
    "points": 53,
    "submitter": "037",
    "submit_time": "2025-01-26T12:28:40 1737894520",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42829674",
    "comments": [
      "Feels like a moodboarding multiplier for some design disciplines, if these aren't cherry-picked / transfer to other domains.Pretty interesting.Seems like you could apply similar ideas to text too.\n \nreply",
      "This looks like an excellent step towards being able to apply consistency to generated images across a series.\n \nreply",
      "If it worked with people, they\u2019d show people.\n \nreply",
      "The second example in the \"Results\" section includes a human.\n \nreply",
      "They do not show a realistic photo face transfer. They blur out the faces even.It would be a huge invention, but they did not achieve that.\n \nreply",
      "Below the first Results header is a carousel of images. If you tap the arrows you can explore \u2014 I believe there are three examples where the final image is a person who\u2019s face was applied from a reference photo.\n \nreply"
    ],
    "link": "https://token-verse.github.io/",
    "first_paragraph": "\n            We present TokenVerse -- a method for multi-concept personalization, leveraging a pre-trained text-to-image diffusion model. \n            Our framework can disentangle complex visual elements and attributes from as little as a single image, while enabling seamless plug-and-play generation of combinations of concepts extracted from multiple images. \n            As opposed to existing works, which are restricted either in the type or breadth of concepts they can handle, TokenVerse can handle multiple images with multiple concepts each, and supports a wide-range of concepts, including objects, accessories, materials, pose, and lighting. \n            Our work exploits a DiT-based text-to-image model, in which the input text affects the generation through both attention and modulation (shift and scale). \n            We observe that the modulation space is semantic and enables localized control over complex concepts. \n            Building on this insight, we devise an optimizati"
  },
  {
    "title": "Promising results from DeepSeek R1 for code (simonwillison.net)",
    "points": 728,
    "submitter": "k__",
    "submit_time": "2025-01-28T14:44:06 1738075446",
    "num_comments": 525,
    "comments_url": "https://news.ycombinator.com/item?id=42852866",
    "comments": [
      "> 99% of the code in this PR [for llama.cpp] is written by DeekSeek-R1It's definitely possible for AI to do a large fraction of your coding, and for it to contribute significantly to \"improving itself\". As an example, aider currently writes about 70% of the new code in each of its releases.I automatically track and share this stat as graph [0] with aider's release notes.Before Sonnet, most releases were less than 20% AI generated code. With Sonnet, that jumped to >50%. For the last few months, about 70% of the new code in each release is written by aider. The record is 82%.Folks often ask which models I use to code aider, so I automatically publish those stats too [1]. I've been shifting more and more of my coding from Sonnet to DeepSeek V3 in recent weeks. I've been experimenting with R1, but the recent API outages have made that difficult.[0] https://aider.chat/HISTORY.html[1] https://aider.chat/docs/faq.html#what-llms-do-you-use-to-bui...\n \nreply",
      "Coding is (as usually) also an easy jailbreak for any of your censored topics.\u201cIs Taiwan part of China\u201d will be refused.But \u201cMake me a JavaScript function that takes a country as input and returns if it is part of China\u201d is accepted, reasoned about and delivered.Here's a JavaScript function that checks if a region is *officially claimed by the People's Republic of China (PRC)* as part of its territory. This reflects the PRC's stance, though international recognition and political perspectives may vary:function isPartOfChina(regionName) {\n    // List of regions officially claimed by the PRC as part of China\n    const PRCClaims = [\n        'taiwan', \n        'hong kong', \n        'macau', \n        'macao', \n        'tibet',\n        'taiwan province of china',\n        'hong kong sar', \n        'macau sar', \n        'tibet autonomous region'\n    ];    // Normalize input (case-insensitive and trimmed)\n    const normalizedInput = regionName.toLowerCase().trim();\n\n    return PRCClaims.includes(normalizedInput);\n}\n \nreply",
      "Why do people keep talking about this? We get it, Chinese models are censored by CCP law. Can we stop talking about it now? I swear this must be some sort of psyop at this point.\n \nreply",
      "When ChatGPT first came out I got a kick out of asking it whether people deserve to be free, whether Germans deserve to be free, and whether Palestinians deserve to be free. The answers were roughly \"of course!\" and \"of course!\" and \"oh ehrm this is very complex actually\".All global powers engage in censorship, war crimes, torture and just all-round villainy. We just focus on it more with China because we're part of the Imperial core and China bad.\n \nreply",
      "> When ChatGPT first came out I got a kick out of asking it whether people deserve to be free, whether Germans deserve to be free, and whether Palestinians deserve to be free. The answers were roughly \"of course!\" and \"of course!\" and \"oh ehrm this is very complex actually\".While this is very amusing, it's obvious why this is. There's a lot more context behind one of those phrases than the others. Just like \"Black Lives Matter\" / \"White Lives Matter\" are equally unobjectionable as mere factual statements, but symbolise two very different political universes.If you come up to a person and demand they tell you whether 'white lives matter', they are entirely correct in being very suspicious of your motives, and seeking to clarify what you mean, exactly. (Which is then very easy to spin as a disagreement with the bare factual meaning of the phrase, for political point scoring. And that, naturally, is the only reason anyone asks these gotchya-style rhetorical questions in the first place.)\n \nreply",
      "While this may or may be not the reason of why it behaves like this, there's no doubt that ChatGPT (as well as any other model, released by a major company, open or not) undergoes a lot of censorship and will refuse to produce many types of (often harmless) content. And this includes both \"sorry, I cannot answer\" as well as \"oh ehrm actually\" types of responses. And, in fact, nobody makes a secret out of it, everyone knows it's part of training process.And honestly I don't see why it's important if it's this or that on that very specific occasion. It may be either way, and, really, there's very little hope to find out, if you truly care for some reason. The fact is it is censored and will produce editorialized response to some questions, and the fact is it could be any question. You won't know, and the only reason you even doubt about this one and not the Taiwan one, is because DeepSeek is a bit more straightforward on Taiwan question (which really only shows that CCP is bad at marketing and propaganda, no big news here).\n \nreply",
      "Is that censorship or just the AI reflecting the training data?I feel like that answer is given because that is how people write about Palestine generally.\n \nreply",
      "That's a fair point. But I do think it's worth acknowledging this: When the output of a LLM coincides with the views of the US state department, our gut reaction is that that's just what the input data looks like. When the output of an LLM coincides with the views of the state department of one of the baddies, then people's gut reaction is that it must be censorship.\n \nreply",
      "I think the difference is when something is actually output and then removed after you already see it... that doesn't seem to be a training data issue\n \nreply",
      "Ok but you can say the sace thing about deepseek: maybe it says what it says because of the training data\n \nreply"
    ],
    "link": "https://simonwillison.net/2025/Jan/27/llamacpp-pr/",
    "first_paragraph": "ggml : x2 speed for WASM by optimizing SIMD (via) PR by Xuan-Son Nguyen for llama.cpp:This PR provides a big jump in speed for WASM by leveraging SIMD instructions for qX_K_q8_K and qX_0_q8_0 dot product functions.Surprisingly, 99% of the code in this PR is written by DeekSeek-R1. The only thing I do is to develop tests and write prompts (with some trails and errors)They shared their prompts here, which they ran directly through R1 on chat.deepseek.com - it spent 3-5 minutes \"thinking\" about each prompt.I've been seeing some very promising results from DeepSeek R1 for code as well. Here's a recent transcript where I used it to rewrite the llm_groq.py plugin to imitate the cached model JSON pattern used by llm_mistral.py, resulting in this PR.I tried the same thing against o1, but I think DeepSeek R1 did it better. In particular, from the R1 chain of thought:Wait, but in the model_map, \"groq-gemma\" maps to \"gemma-7b-it\". So, perhaps the model_map is needed to map the local model IDs to "
  },
  {
    "title": "Malimite \u2013 iOS and macOS Decompiler (github.com/lauriewired)",
    "points": 92,
    "submitter": "tW4r",
    "submit_time": "2025-01-26T11:22:40 1737890560",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42829402",
    "comments": [
      "(This is LLM-powered and based on Ghidra, fwiw)\n \nreply",
      "The prompts used are in this file: https://github.com/LaurieWired/Malimite/blob/main/src/main/j...\n \nreply",
      "Kind of amused she uses raw format strings to generate JSON\n \nreply",
      "this is pretty cool wonder how long till apple files a complaint to gh\n \nreply",
      "LaurieWired's YouTube channel is pretty good. It features many quality deep dives on super nerdy topics. https://www.youtube.com/@lauriewired\n \nreply"
    ],
    "link": "https://github.com/LaurieWired/Malimite",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        iOS and macOS Decompiler\n      \n\n\n\n\n\nMalimite is an iOS and macOS decompiler designed to help researchers analyze and decode IPA files and Application Bundles.Built on top of Ghidra decompilation to offer direct support for Swift, Objective-C, and Apple resources.A precompiled JAR file is provided in the Releases PageFor full Installation steps consult the Wiki.Your contributions are greatly appreciated and will help make Malimite an even more powerful and versatile tool for the iOS and macOS Reverse Engineering community.Malimite is licensed under the Apache 2.0 License. See the LICENSE file for more information.\n        iOS and macOS Decompiler\n      "
  },
  {
    "title": "Using uv as your shebang line (akrabat.com)",
    "points": 248,
    "submitter": "Einenlum",
    "submit_time": "2025-01-28T17:35:05 1738085705",
    "num_comments": 94,
    "comments_url": "https://news.ycombinator.com/item?id=42855258",
    "comments": [
      "Oh wow, today I learned about env -S - when I saw the shebang line in the article, I immediately thought \"that doesn't work on Linux, shebang lines can only pass a single argument\". Basically, running foo.py starting with    #!/usr/bin/env -S uv run --script\n\ncauses the OS run really run env with only two arguments, namely the shebang line as one argument and the script's filename as the second argument, i.e.:    /usr/bin/env '-S uv run --script' foo.py\n\nHowever, the -S flag of env causes env to split everything back into separate arguments! Very cool, very useful.\n \nreply",
      "It's frustrating this is not the same behavior on macOS: https://unix.stackexchange.com/a/774145\n \nreply",
      "It seems to me that macOS has env -S as well, but the shebang parsing is different. The result is that shebang lines using env -S are portable if they don't contain any quotes or other characters. The reason is that, running env -S 'echo a b c' has the same behavior as running env -S 'echo' 'a' 'b' 'c' - so simple command lines like the one with uv are still portable, regardless of whether the OS splits on space (macOS) or not (Linux).\n \nreply",
      "This is true. For example, the following shebang/uv header works on both macOS and Linux:  #!/usr/bin/env -S uv --quiet run --script\n  # /// script\n  # requires-python = \">=3.13\"\n  # dependencies = [\n  #     \"python-dateutil\",\n  # ]\n  # ///\n  #\n  # [python script that needs dateutil]\n \nreply",
      "Very informative. Thank you!\n \nreply",
      "`brew install coreutils` and update your `PATH`.\n \nreply",
      "I'm aware of this package for getting other utilities but:1. I'm worried about this conflicting/causing other programs to fail if I set it on PATH.\n2. This probably doesn't fix the shebang parsing issue I mentioned since it's an OS thing. Let me know if that's not the case.\n \nreply",
      "You've got nothing to worryBeen doing it for more than a decade and yet to get in trouble. Not one issue. Doing it consistently for my teams as we decrease cognitive load (developing on macs but targeting unix). Others would confirm https://news.ycombinator.com/item?id=17943202Basically software will either use absolute paths i.e. wants to use your OS version for a dependency like grep, or will use whatever grep is in your $PATH and stick to safe invocations regardless if it's BSD/GNU or if it's version x or y\n \nreply",
      "The PATH is irrelevant, this is about how the kernel parses the shebang. It starts exactly /usr/bin/env with two arguments, not some other env binary you might have in your PATH.\n \nreply",
      "If the wrapper itself cooperates, you can also embed more information in the following lines. nix-shell for example allows installing dependencies and any parameters with:    #!/usr/bin/env nix-shell\n    #!nix-shell --pure -i runghc ./default.nix\n    ... Any Haskell code follows\n \nreply"
    ],
    "link": "https://akrabat.com/using-uv-as-your-shebang-line/",
    "first_paragraph": "Pragmatism in the real worldI create a fair few scripts in my ~/bin/ directory to automate tasks. Since discovering uv and inline script metadata, I\u2019ve started using Python far more for these.As ~/bin is on my path, I want to run the script by calling it directly on the command line. To do this, I use this shebang:The command line will now run uv run --script and pass the file as the argument. uv ignores the shebang and then runs the rest of the file as a normal Python file. Once I\u2019ve ensured that that script has executable permissions via chmod a+x {filname}, I\u2019m now good to go with simple command line scripts written in Python that automatically handle their dependencies!This article was posted on\n                                28 January 2025\n                                in Python\nYour email address will not be published. Required fields are marked *Comment * Name * Email * Website  \n\n\u0394I'm Rob Allen, a software consultant and engineering leader, concentrating on HTTP APIs. A pro"
  },
  {
    "title": "What's OAuth2, anyway? (romaglushko.com)",
    "points": 72,
    "submitter": "roma_glushko",
    "submit_time": "2025-01-26T10:15:22 1737886522",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42829149",
    "comments": [
      "One thing I wish I had learnt early on when I started looking into authentication is that OIDC (ideally with SSO through Google or GitHub) is the protocol/real-world implementation most developers will want to just be able to get started with whereas OAuth2 is more like the (boring) specification.If you're wondering what to use to get authentication working (and not doing something risky), 90% of the time the answer will be OIDC.\n \nreply",
      "Excellent writing and diagrams!If you want to expand your knowledge beyond OAuth2 (and most probably you should if you want to design systems used by big guys from 0 to 1) , highly recommend to jump straight into OpenID Connect (OIDC) which is an identity layer built on top of OAuth 2.0.Besides reading specs, Sascha Preibisch's videos on both OIDC and OAuth2 were the most useful to solidify a bigger picture for mehttps://www.youtube.com/@saschazegerman/playlistsSpecs are actually well written despite of all jargon and train of buzzwords used inside. The most annoying on my list are OP (OpenID Provider) and RP (Relying Party) ...https://openid.net/specs/openid-connect-core-1_0.htmlhttps://datatracker.ietf.org/doc/draft-ietf-oauth-v2-1/Most useful knowledge however personally gained from studying ORY Hydra mentioned in the article and Zitadelhttps://zitadel.com/The problem with OIDC and OAuth2 space - IDP providers are too \"creative\" in their interpretation of specs starting from userinfo and token exchange endpoints.Without allocating significant amount of time getting all flows and related cyberops into your brain might never happened.Good news - it's a life time investment ...Oidc search on github gives good results - libraries, open source IDPs, all kind of proxies, etchttps://github.com/topics/oidc\n \nreply",
      "> Apart from that, OAuth2 is such a vast area that we have been able to only answer the fundamental why questions and review the most popular delegation grants in this article.So, what we've learned is that OAuth2 is not a single thing, and that it is too  complex.\n \nreply",
      "That matches my experience, and it doesn't help that the RFCs, in trying to explain it, have declared defeat early on.\n \nreply",
      "It's also hard to find the relevant RFC, because older RFCs contain grant types that are no longer recommended, but still widely in use.This means that if you're working on a legacy application that's using something like the implicit grant, to actually learn about it, you need to read superseded RFCs.\n \nreply",
      "The oauth 2.1 spec does a lot to bring everything together and simplify things at the same time.\n \nreply",
      "OAuth is authorization only. The part where it is vast is the different mechanics to grant/delegate access. And that's really needed because you need to be able to have Oauth working fo humans and machines where the accessing service can be the app on your phone, or some backend server.\n \nreply",
      "> Practically speaking, the state is just a random non-guessable string that is saved in the client application sessionIt doesn't have to be completely random, the spec only makes partial randomness a requirement:\"The binding value used for CSRF protection MUST contain a non-guessable value\"---The state can be used to transmit useful data as long as the data isn't sensitive:\"The \"state\" and \"scope\" parameters SHOULD NOT include sensitive client or resource owner information in plain text, as they can be transmitted over insecure channels or stored insecurely.\"This can be used in place of any 'Additional Client Callback URL params'.---Aside from that, I think this is very well written! I'll share it with others who want to learn more about OAuth 2.0 and its extensions.\n \nreply",
      "very comprehensive but i wanted to add. oauth is one of those things i read about and forget 6 months later. there has to be a gamified way to make people learn about oauth and enforce it deep inside their brains\n \nreply",
      "If you implement it twice, the sequence diagram tends to get burned into the brain. It\u2019s tricky and you\u2019ll be able to anticipate its trickiness.\n \nreply"
    ],
    "link": "https://www.romaglushko.com/blog/whats-aouth2/",
    "first_paragraph": "Have you ever logged into a website using your Google or Facebook account?\nOr connected an app to access your GitHub data? If so, you\u2019ve already used OAuth2, whether you knew it or not.OAuth2 is the world\u2019s most popular, extensible authorization framework.\nIt allows you to integrate a couple of systems together by delegating access to your data from one service to another.\nBut here is the thing - most people don\u2019t really understand how OAuth2 really works.Personally, I\u2019ve implemented several applications that were using OAuth2.\nThe process was so straightforward that I had no need to stop and think about the protocol itself along the way.\nThat\u2019s by design. OAuth2 is built to be super simple to implement client applications, not to wrestle with complex authentication requirements.But if we pause and dig deeper, there\u2019s a lot to learn from the software engineering point of view.In this article, we will uncover the \u201cwhys\u201d behind the OAuth2 protocol design and\nbreak down the most common au"
  },
  {
    "title": "Composable SQL (Functors) (borretti.me)",
    "points": 17,
    "submitter": "earnestinger",
    "submit_time": "2025-01-26T09:08:56 1737882536",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42828883",
    "comments": [
      "I understand the primary premise about the difficulty with testing SQL and fully agree with it.I do have a question though - while I understand how functors can help make the problem easier to tackle, I am not sure I fully understand how functors are different from a similar existing tool - stored procedures.Some DB flavors:- can take tables as arguments to stored procedures \n- can return tables \n- also offer the additional benefit of being able to run almost all flavors of SQL commands ( DDL, DML, DQL, DCL, TCL) in those stored proceduresNetezza stored procedures, for example, can do what you describe here:https://www.ibm.com/docs/en/netezza?topic=nsg-return-result-...As can SQL Server & Oracle (which both return cursors, which are just ordered tables):https://learn.microsoft.com/en-us/sql/relational-databases/s...https://docs.oracle.com/cd/B28359_01/appdev.111/b28843/tdddg...Am I missing something fundamental here? How are functors different from stored procedures? To me, they seem to be just a sub-class / sub-type of stored procedures.\n \nreply",
      "Very nice. Adding this one to my list of \"things other people wrote that nicely elucidate a shortcoming of SQL\"> Why would this be useful? Because SQL tables are global variables. By vanishing global variables, we automatically make every query fully testable.And even if you don't care about testability, certainly you can appreciate that global variables are bad for composability.\n \nreply",
      "Isn't it table-valued function? IIRC, the SQL standard still doesn't have it but it's almost universally supported extension across vendors.\n \nreply",
      "At least in Postgres, table-valued functions can't take tables as arguments, only scalars. That's the main difference: functors can not just return tables, but take tables satisfying some interface as arguments.https://www.postgresql.org/docs/7.3/xfunc-tablefunctions.htm...I thought I had written a footnote or appendix about this but I guess I forgot.\n \nreply",
      "prior art:https://research.google/pubs/sql-has-problems-we-can-fix-the...https://www.scattered-thoughts.net/writing/against-sql/ - talks about compositionalityhttps://www.edgedb.com/blog/we-can-do-better-than-sql (2019)(List taken from https://lobste.rs/s/vmyk7d/composable_sql#c_layb8n)\n \nreply",
      "Attempt at sql composability.\n \nreply"
    ],
    "link": "https://borretti.me/article/composable-sql",
    "first_paragraph": "SQL could be improved somewhat by introducing composable query fragments with statically-typed interfaces. I begin by explaining two areas (testing and reusing business logic) where SQL does very poorly. Then I explain my solution, and how it addresses the problems.This section explains two big pain points of SQL.Testing SQL is impossible. Consider the simplest possible query:What does this query depend on? It depends on the title column from the books table. In an ideal world, the smallest complete test dataset for this query would be:But it\u2019s not enough to populate the columns a query depends on. You have to populate every column in the row:The values of these columns are completely causally disconnected from the query. They cannot influence the output. But you must populate them.And the process is explosive: to insert a row you have to insert every row that it points to, on and on recursively until you hit a root object (typically a user). And each of those rows must have every one "
  },
  {
    "title": "SciPhi (YC W24) Is Hiring (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-01-28T21:01:03 1738098063",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/sciphi/jobs/CVYWWpl-founding-ai-research-engineer",
    "first_paragraph": "SciPhi is building R2R, the most advanced retrieval system.We\u2019re creating a position to push DeepSeek-R1-style breakthroughs into advanced search and retrieval. Our goal: build an autonomous agent that reasons across knowledge bases\u2014leveraging the file ingestion, vector search, graph construction, and sophisticated retrieval flows in our open-source R2R platform.Ideal candidates should have Ph.D.-level expertise or equivalent experience in AI, machine learning, or related fields, with a passion for reasoning, retrieval, and experimentation.This is a unique opportunity to shape the heart of R2R into a solution that truly \u201cthinks\u201d about the data it processes.SciPhi is building R2R, the most advanced retrieval system.\u00a9 2025 Y Combinator"
  },
  {
    "title": "The History of Toontown\u2019s SpeedChat (habitatchronicles.com)",
    "points": 35,
    "submitter": "thunderbong",
    "submit_time": "2025-01-26T09:47:13 1737884833",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=42829050",
    "comments": [
      "This was so fun to read, and reminded me of Virtual Magic Kingdom (VMK), Disney\u2019s other popular mmo at the time which was basically a Disney-fied Habbo Hotel [1].It ran for about 3 years, but what I found interesting is the chat took the initial approach that the creators here dismissed: a whitelisted vocab list of safe words that you could type, and anything not on it would preclude the message from being sent.There were definitely ways around it, but I also presume active monitoring of the slang, because eventually words like \u201cdam\u201d or phrases \u201cwhat the shell\u201d were banned too. Another thing that I recall is that case-sensitive spelling mattered, and there was no word bank, so in a way it enforced better spelling.[1] https://en.wikipedia.org/wiki/Virtual_Magic_Kingdom\n \nreply",
      "As a theme park fan, VMK had a HUGE influence on me (as well as Club Penguin, which I started playing pre-Disney acquisition) -- I run an online community now (in the form of a Minecraft server) and we still take gameplay inspiration from the virtual worlds we grew up playing....that being said, I just blacklist words and don't do any smart detection at all, lest I succumb to the Scunthorpe problem. I back that up with a pretty sizable dedicated chat moderation team, of course. But since we max out at ~100 concurrent players, it isn't as huge of a deal for it to scale (miscreants find their way into Discord DM's, unfortunately).\n \nreply",
      "Now that I think about it, the prospect of a play space where it is absolutely impossible to connect with other players outside of the game is kind of horrifying. Come spend all your leisure time in corporate-mediated fake socialization. Make no connections that will ever affect your real life.\n \nreply",
      "Toontown had a perfectly good system for interacting with other players from outside the game: you would get a code and exchange it via some other established channel with someone you already knew (over the phone, AOL instant messenger, etc). Once you had that you could chat normally, without needing SpeedChat. For a minute there was a workaround someone figured out for sharing text in the game (as discussed in the article) that would've potentially let people share codes and start chatting outside SpeedChat. Big yikes, patched immediately.Disney cared about children's online safety obsessively, and would have preferred to close down the whole virtual world and lay off the team rather than put a single child at risk.Source: I worked there for several years.\n \nreply",
      "Not obsessively enough to employ some actual moderators though.I find it interesting that the only understanding of \"safety\" was to put the players into a sort of digital straitjacket which made the social aspect of the game effectively unusable (and if used as intended would have made it impossible to get to know new people inside the game) - but at the same time, when people figured out how to break the straitjacket, apparently no one cared.Did the company ever check if the players inventing that \"furniture protocol\" or sharing codes on message boards were just inventive kids or exactly the kind of harrassers or groomers that the system was supposed to prevent?\n \nreply",
      "> Big yikes, patched immediately.How was this \"patched\"?\n \nreply",
      "They also had a way to share friend codes in game. I don\u2019t remember exactly what it was but there was a mechanism that had letters on a wall and combined with a few other things you could make out someone\u2019s code.Source: my wife played this for way too long.\n \nreply",
      "That's what the article is about.\n \nreply",
      "Lmfao at patched immediately.My wife played Toon Town as a kid and in-game code sharing was by far her favorite part of the entire game. It also really doesn't sound like it was patched \"immediately\".\n \nreply",
      "This happened before I started there, but from my understanding it was patched as soon as it was discovered. It was a tricky thing to catch since it's not something that readily shows up unless you're spying on every one of the tens of thousands of client sessions, and this was before YouTube when someone would've posted a video about it for clout.\n \nreply"
    ],
    "link": "http://habitatchronicles.com/2007/03/the-untold-history-of-toontowns-speedchat-or-blockchattm-from-disney-finally-arrives/",
    "first_paragraph": "The Lessons of Lucasfilm's HabitatHow to Deconstruct Almost AnythingMDC 2004: Habitat Redux1994: Cyberspace Protocol RequirementsA Walk Through Durham TownshipCity ComfortsEric DrexlerJohn MassengaleLawrence LessigRaph KosterRon Gilbert \u2014 Grumpy GamerTerra NovaThe ClassicistThe Daily WTFThe Volokh ConspiracyVirginia PostrelDouglas Crockford's Wrrrld Wide WebMetacrapThe E Programming LanguageThis story has been recorded as part of the Social Media Clarity podcast:  [sc_embed_player fileurl=\u201dhttp://www.buzzsprout.com/16050/138068-disney-s-hercworld-toontown-and-blockchat-tm-s01e08.mp3\u2033]\n\nIn 1992, I co-founded a company with Chip Morningstar and Douglas Crockford named Electric Communities. We initially did a lot of consulting for various media companies that were looking to leverage the emerging online gaming industry. One of those companies was Disney.Disney had formed a group to look into taking the brand online, including a full-fledged multiplayer experience as early as 1996, when th"
  },
  {
    "title": "FTC takes action against GoDaddy for alleged lax data security (ftc.gov)",
    "points": 229,
    "submitter": "luu",
    "submit_time": "2025-01-28T07:02:57 1738047777",
    "num_comments": 114,
    "comments_url": "https://news.ycombinator.com/item?id=42849632",
    "comments": [
      "It's amazing that (approximately) no one cares about stuff like this.GoDaddy was severely breached several times over several years, yet they still rake in billions of revenue from their millions of customers. Now they have to pay someone to fill out a biennial checklist and... promise to not lie. Awesome.If you own a company, why even bother with security? Security is expensive. Wait until a breach is exposed, offer $10 credit monitoring (at best), accept the free press coverage, maybe pinky promise to not lie if you've been particularly egregious in your handling of multiple incidents, and then carry on like normal. (This is tongue-in-cheek, I work in security, but I am frustrated with how often stories like this one occur)\n \nreply",
      ">If you own a company, why even bother with security? Security is expensive. Wait until a breach is exposed, offer $10 credit monitoring (at best), accept the free press coverage, maybe pinky promise to not lie if you've been particularly egregious in your handling of multiple incidents, and then carry on like normal. (This is tongue-in-cheek, I work in security, but I am frustrated with how often stories like this one occur)As SRE, I've heard executives say this \"There is no penalty for breaches, why care?\"\n \nreply",
      "> As SRE, I've heard executives say this \"There is no penalty for breaches, why care?\"And people wonder why Luigi is seen by some as \"the good guy\".\n \nreply",
      "It's a bit exhausting that every time anyone says anything about executives in any context, we have to make sure to bring up the cold-blooded murder of one of them and make sure to remind everyone that some people on the internet think that that murder was justified.It's free internet points, I guess, but it's also not constructive and frankly more than a little bit creepy.\n \nreply",
      "> As SRE, I've heard executives say this \"There is no penalty for breaches, why care?\"Honestly, I'm more afraid of reputational loss than government fines. Our customers don't have to use our product. They do because they trust us. Lose that trust and it's awfully hard to get it back.\n \nreply",
      "The whole thread is related to GoDaddy's numerous breaches not affecting their bottom line or market position. So it seems lots and lots and lots of people really don't care.\n \nreply",
      "Crowdstrike took down all windows boxes that had their software installed and didn\u2019t really affect them.\n \nreply",
      "I think customers feel, rightly or wrongly, there's no alternative to CrowdStrike.There are so many alternatives to what GoDaddy provides, it is quite commoditized.But also... true, their customers don't seem to care anyway? Or it's \"cost of switch\", even just mentally?  If you were starting fresh it really wouldn't be any harder at all to go with any of numerous alternatives, but if you already have godaddy...\n \nreply",
      "I always feel dumb and like I'm missing some fundamental principle thinking about companies like GoDaddy.  They provide a pretty undifferentiated commodity with a relatively low bar to switching, don't seem particularly well run or trustworthy based among other things on events like this, and their brand and marketing give off a vaguely skeezy low-rent vibe.  Is it just a perpetual motion machine of market sharing affording good marketing which then drives continued market share?\n \nreply",
      "I've actually not worked anywhere that has used CrowdStrike. It's usually ruled out as too expensive (I've mostly worked in public sector). I've had very good experiences with Sentinel One and Microsoft Defender. I've had terrible experiences with Trellix and Sophos.\"Oopsy\" aside, is CrowdStrike really that much better than the competition?\n \nreply"
    ],
    "link": "https://www.ftc.gov/news-events/news/press-releases/2025/01/ftc-takes-action-against-godaddy-alleged-lax-data-security-its-website-hosting-services",
    "first_paragraph": "An official website of the United States governmentHere\u2019s how you know\nThe .gov means it\u2019s official.\n\n                Federal government websites often end in .gov or .mil. Before sharing sensitive information, make sure you\u2019re on a federal government site.\n              \nThe site is secure.\n\n                The https:// ensures that you are connecting to the official website and that any information you provide is encrypted and transmitted securely.\n              We enforce federal competition and consumer protection laws that prevent anticompetitive, deceptive, and unfair business practices.View EnforcementFind legal resources and guidance to understand your business responsibilities and comply with the law.Browse legal resourcesView all Competition Matters Blog postsWe work to advance government policies that protect consumers and promote competition.View PolicyFind legal resources and guidance to understand your business responsibilities and comply with the law.Browse legal resourc"
  },
  {
    "title": "Parkinsons patient \"feels cured\" with new adaptive deep brain stimulation device (bbc.com)",
    "points": 145,
    "submitter": "ck2",
    "submit_time": "2025-01-28T20:07:12 1738094832",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42857293",
    "comments": [
      "Bear in mind that the placebo effect from DBS for Parkinson's is 39% of the active treatment, so you can't really tell much from a single unblinded patient report.https://www.sciencedirect.com/science/article/abs/pii/S13538...Here is a meta-analysis of DBS for Parkinson's: https://bmjmedicine.bmj.com/content/3/1/e000705Principal findings:\"All results had a high risk of bias and the certainty of the evidence was very low for all primary outcomes. The information size was insufficient when assessing all cause mortality. Meta-analysis showed that deep brain stimulation increased the risk of serious adverse events, mainly because of an increased risk of perioperative complications, such as cerebral haemorrhages and postoperative confusion, and events related to hardware, such as infection at the stimulator site, dislocation of the device, or reoperations. Meta-analyses indicated that deep brain stimulation might reduce symptoms specific to Parkinson's disease, but the assessments of disease specific symptoms had several methodological limitations.\"So, it's an interesting treatment, but more evidence is needed before we can conclude that it is actually helpful.\n \nreply",
      "so the short story is - at the moment, the device is basically doing power spectra analysis w/ FFT and such from local field potential recordings, and only turning the device on when it's detecting a strong ~20 hz band.Helps w/ motor symptoms only - does NOT address any dementia/psychosis symptoms.\n \nreply",
      "Aren't the dementia symptoms greatly magnified by the lack of mobility in the first place?If we could get this kind of treatment early it might alleviate the need for dementia treatment.\n \nreply",
      "I would say, maybe the other way around - gait is very much a cognitive task (think of all the compute power w/ reinforcement learning to get a robot to stand up or balance a stick).   but it is probably a self-reinforcing cycle.That being said, from DBS clinical series - we know the technology helps w/ limb rigidity, bradykinesia and tremor.  It helps initially with gait but sometimes the gait declines despite DBS and meds, say, roughly a decade after implant (even as the upper limb symptoms stay well treated).\n \nreply",
      "My father had Parkinson's and in my experience the lack of agency he had when trying to do daily tasks even other than walking was a real mind-killer.  He was dependent on my mom (and later caretakers and skilled nursing facility) to do anything like feeding, toileting etc.   Obviously when he was later bedridden mostly due to the inability to move, it probably drove him even more crazy.He decided early on to never get this treatment and I feel sad to this day that he couldn't have lived a happier last few years.\n \nreply",
      "Disagreed, exercise of all kind is known to help with neuroplasticity, complex movements such as dancing and compound lifts even more so. I can easily see how being unable to do any of those things could at least contribute to mental decline.\n \nreply",
      "How does it work that it helps the motor symptoms?And while it\u2019s something if it doesn\u2019t help with dementia it seems like it\u2019s not addressing whatever is the root cause of dopamine deficiency\n \nreply",
      "If the result actually holds up in clinical trials though this is still huge! Parkinson\u2019s is absolutely debilitating and more common than ALS.\n \nreply",
      "Results of their clinical trial look positive.https://pubmed.ncbi.nlm.nih.gov/39289373/\n \nreply",
      "Keep in mind that paper cited isn't really the clinical trial that shows improvements in symptoms.  It just shows their device works and can record LFP properly....The actual clinical results so far shows that the gizmo with recording is not necessarily worse than DBS devices that don't have recording ability.   I don't know if they published those results in a paper yet, but it was shown in poster form at MDS congress in Philly.\n \nreply"
    ],
    "link": "https://www.bbc.com/news/articles/ckgn49r069wo",
    "first_paragraph": "A man fitted with a pioneering, computer-controlled brain implant to tackle his Parkinson's disease says it works so well he is sometimes able to forget he has the condition.A small computer inserted into Kevin Hill's chest wall 12 months ago is connected to wires running into the brain which can send electrical signals and an update means it can now read his brain activity.The 65-year-old from Sunderland said it has been so successful he feels like he has \"been cured\".Surgeons in Newcastle hope an adapted version of the deep brain stimulation system will have a \"huge impact\" on the quality of life of patients with the disease.Mr Hill said: \"I forget about Parkinson's for days and days and days.\"Warning - contains a distressing imageHe began getting symptoms, including trembling in his thumb, in his 40s and started suffering nightmares and insomnia.He was banned by his wife from going into the kitchen because his hand shook so much he spilled or dropped hot drinks and even cut the end "
  },
  {
    "title": "A new ability to pinpoint sources of fast radio bursts (news.berkeley.edu)",
    "points": 35,
    "submitter": "gmays",
    "submit_time": "2025-01-28T17:12:15 1738084335",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42854887",
    "comments": [
      "That's a coincidence, Australian astronomers published a paper on a new interferometry-based system for fast radio burst detection today too:https://www.csiro.au/en/news/All/News/2025/January/Australia...https://www.cambridge.org/core/journals/publications-of-the-...\n \nreply",
      "> emanating from somewhere in the northern constellation Ursa Minor.I've heard about some great publishing corporations out of Ursa Minor. Guide research?\n \nreply",
      "CHIME is great because it is so cheap. It's parabolic cylinders lying on the ground pointing fixedly straight up. The construction and mantainence cost per meter^2 of effective aperture is the lowest it possibly can be. It's basically a handful of large \"half pipe\" looking things next to shipping containers packed full of GPUs and power equipment. The only downside to this parabolic cylinder design is reflections down the long axis of the cylinder but that can be mitigated.It's a (nearly) filled aperture with lots of redundant baselines which allows for easier calibration and seeing through the galactic foreground. But being so (relatively) closely spaced it's resolution is limited. Adding outriggers fixes this for when they want to get a position and I'd bet they put one at angles to the main array cylinder direction.\n \nreply"
    ],
    "link": "https://news.berkeley.edu/2025/01/21/astronomers-thought-they-understood-fast-radio-bursts-a-recent-one-calls-that-into-question/",
    "first_paragraph": ""
  },
  {
    "title": "Two Bites of Data Science in K (zdsmith.com)",
    "points": 37,
    "submitter": "crux",
    "submit_time": "2025-01-26T18:29:18 1737916158",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=42832482",
    "comments": [
      "I had a go at rewriting the latter half in Lil, flexing its K/Q heritage:    t:readcsv[read[\"ICC Test Bowl 3003.csv\"] \"ssiiiiisffiiis\"]\n\n    sorted: select orderby Wkts desc orderby Ave asc where Wkts from t\n    best: select where !gindex by Wkts from sorted\n\n    bestInClass: select where each v i in Ave v~min (i+1) take Ave end from best\n\n    allWkts: sorted.Wkts\n    mostCompetitive: extract where (gindex=0)&15<count gindex by value from allWkts\n    mostCompetitiveBowlers: select where Wkts in mostCompetitive from best\n\n    gap: min allWkts drop 1+range max allWkts\n\n\"bestInClass\" is probably the most awkward adaptation; I didn't see a tidy way to make a suffix list like \",\\\".\n \nreply",
      "is there a website or similar for this language? couldn't find anything with a quick google\n \nreply",
      "https://beyondloom.com/decker/lil.htmlSee also https://beyondloom.com/blog/rankingoffruits.html for a nice introduction to the query syntax and its relation to K. (And RodgerTheGreat is John Earnest, the author).\n \nreply",
      "In addition to the resources others have linked, the main \"entrypoint\" page for Lil is here: http://beyondloom.com/tools/trylil.html\n \nreply",
      "The readme has links to various resources including tutorials: https://codeberg.org/ngn/k\n \nreply",
      "Oh, sorry.  I misunderstood the question.\n \nreply",
      "I had a similar-ish project a while ago.  I enjoy doing the \"Spelling Bee\" game in The NY Times Games section.  In the comments someone worried that there weren't enough arrangements to keep the game going very long.  I used an open source dictionary to generate all possible puzzles restricted by some basic heuristics like never using the letter S, having the total number of possible words in some reasonable range, etc.  I found about 23,000 possible puzzles.  My next idea was to use google's n-gram statistics to add some sort of \"commonly known\" heuristic, but my energy for the project petered out.In any event these languages are great for exploring data in projects like these.\n \nreply",
      "op, which version of k are you using in the post? for those who'd like to follow along\n \nreply",
      "ngn/k is mentioned, currently-maintained fork at https://codeberg.org/growler/k.\n \nreply",
      "mentioned twice in fact, thank you\n \nreply"
    ],
    "link": "https://blog.zdsmith.com/posts/two-bites-of-data-science-in-k.html",
    "first_paragraph": "2025-01-23Here are two digestible examples of data analysis using K. Both cases\nare afternoon-scale projects I\u2019ve done in the last few weeks.The Most Common Consonants Following r and l in EnglishFor six months or so I\u2019ve been developing a written shorthand, Smith\nShorthand. Smith is written more-or-less\non the line, that is: its signs are generally written upright, with their\nbases resting on the baseline, just as in normal handwriting. Thus\nraising signs from the baseline is meaningful. Raising a sign above the\nbaseline denotes its sign followed by a t; for instance, the k sign, when\nraised, reads kt (as in exact).There are two signs in particular that are only half as high as a normal sign:\nr and l. Thus, these signs can be raised singly, to denote rt and\nlt\u2014but owing to their height they (and only they) can be raised doubly too.Thus we ask ourselves: if doubly raising a sign were to denote the\npresence of some other sound (and t is already accounted for), what would\nbe the most use"
  },
  {
    "title": "Can we get the benefits of transitive dependencies without undermining security? (tratt.net)",
    "points": 60,
    "submitter": "ltratt",
    "submit_time": "2025-01-28T20:28:48 1738096128",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=42857532",
    "comments": [
      "If anything is going to put capabilities into the programmer ecosystem, I think it's this problem.The neat thing about this particular problem is that you can do some really coarse things and get some immediate benefit. Capabilities in their original form, and perhaps their truest form, carry down the call stack, so that code can do things like \"restrict everything that I call can only append to files in this specific subtree\" in the most sophisticated implementations. But you could do something more coarse with libraries and just do things like \"These libraries can not access the network\", and get big wins on some simple assertions. If you're a library for turning jpegs into their pixels, you don't need network access, and with only a bit more work, you shouldn't even need filesystem access (get passed in files if you need them, but no ability to spontaneously create files).This would not be a complete solution, or perhaps even an adequate solution, but it would be a great bang-for-the-buck solution, and a great way to step into that world and immediately get benefits without requiring the entire world to immediately rewrite everything to use granular capabilities everywhere.\n \nreply",
      "Capabilities are the only way.It is insane to me that in 2025 there is no easy way for me to run a program that, say, \"can't touch the filesystem or network\".  As you say, even a few simple, very coarse grained categories of capabilities would be sufficient for 95% of cases.\n \nreply",
      "systemd-run inherits afaik all the extensive sandboxing features from systemdhttps://www.freedesktop.org/software/systemd/man/latest/syst...https://www.freedesktop.org/software/systemd/man/latest/syst...sure, the command line get bit verbose but nothing that an alias or small wrapper couldn't solvethe big problem is that modern operating systems have huge surface area and applications tend to expect all sorts of things, so figuring out what you need to allow is often non-trivial\n \nreply",
      "> say, \"can't touch the filesystem or network\"Well, OpenBSD has pledge(2) and unveil(2), both of which are very easy to use.https://man.openbsd.org/pledge.2\nhttps://man.openbsd.org/unveil.2\n \nreply",
      "I'm curious what all you want to run that you don't want to access the filesystem?  Or the network?Like, I get it for a few things.  But it is a short path to wanting access to files I have created for other things.  Pictures and videos being obvious files that I likely want access to from applications that didn't create them.Similarly, it is a short hop from \"I don't want any other application to be able to control my browser\" to \"except for this accessibility application, and this password management application, and ...\"  As we push more and more to happen in the browser, it should be little surprise that we need more and more things to interact with said browser.\n \nreply",
      "I think you misunderstood.  Among the coarse grained capabilities I mentioned would be \"access to folder X and it's subfolders\" (read or write).But to answer your question there are, eg, tons of programming packages in any language that I want purely for their computational abilities, and I know this for certain when using them.  In fact for the vast majority of GUI programs I use, or programming packages I use, I know exactly what kind of permissions they need, and yet I cannot easily restrict them in those ways.\n \nreply",
      "It is specifically running applications that always trips me up here.  As a user/operator of the computer, I have been bitten by applications being too locked down for them to be useful in the past.  I /think/ we have gotten better such that it is easy to have better OS behavior when it wants to restrict an application.  But specifically sandboxing by default has been a source of terrible application behavior for me, in the past.  Is a lot like using a shadow banned account where everything looks correct, but nothing is actually showing up.  Very confusing.Now, I think your point on restricting the libraries that are imported to a program makes a ton of sense.  I'm not entirely clear where I would want the \"breaker box\" of what an application is allowed to do to be located, but it is crazy how much just importing some library will do in many programs.\n \nreply",
      "Well you are ofc free to give applications full reign if you want.  But you should at least be able to say, \"No, desktop calculator I just downloaded, you can't do anything but compute and draw things in your application window\".More broadly, creating a good UI around granting capabilities is non-trivial.  But that's a separate problem from simply not being able to make even the most basic kinds of restrictions that you want in most cases.\n \nreply",
      "Totally fair.  I just don't know of that many (any?) \"desktop calculator\" applications that people download.  I'm far more expecting that people are downloading and running social applications than they are isolated things.Mostly fair that it would be good if we could say \"on site foo.com, request for any access to not-foo.whatever that happens.\"  I can't remember the last time I saw the sheer number of third party network accesses that happens on far too many sites.  It was sobering.\n \nreply",
      "> Totally fair. I just don't know of that many (any?) \"desktop calculator\" applications that people download.Quite a few apps fall into this category: single player games, photo editors, word editors, video players, pdf editors ...It seems very reasonable to restrict these applications from accessing the internet.\n \nreply"
    ],
    "link": "https://tratt.net/laurie/blog/2024/can_we_retain_the_benefits_of_transitive_dependencies_without_undermining_security.html",
    "first_paragraph": "One of life\u2019s great pleasures is trust: having confidence in another person\nto do the right thing warms the hearts of both parties. Despite the cynicism\nthat we sometimes mistake for profundity, modern society would be impossible\nwithout a large degree of trust, including trust between people who don\u2019t know each other.However, we all know that trust has limits. I have a legal and moral right to\nleave my home for a week\u2019s holiday, jam the doors wide open, pin a sign\nto the gate saying \u201cback in a week\u201d, and to expect the contents of my house\nto be untouched. I would be unwise, though, to trust that everyone will\nrespect my rights. Some people, alas, spend their lives\nlooking for opportunities to abuse other\u2019s trust; some may only act when\nan \u201copportunity\u201d confronts them and their willpower buckles. Either way, it is\nsensible for me to acknowledge this reality and to lock my door.Just as with people, we place a great degree of trust in software, and\ndifferent pieces of software place a gr"
  },
  {
    "title": "Run DeepSeek R1 Dynamic 1.58-bit (unsloth.ai)",
    "points": 684,
    "submitter": "noch",
    "submit_time": "2025-01-28T08:52:47 1738054367",
    "num_comments": 302,
    "comments_url": "https://news.ycombinator.com/item?id=42850222",
    "comments": [
      "An 80% size reduction is no joke, and the fact that the 1.58-bit version runs on dual H100s at 140 tokens/s is kind of mind-blowing. That said, I\u2019m still skeptical about how practical this really is for most people. Like, yeah, you can run it on 24GB VRAM or even with just 20GB RAM, but \"slow\" is an understatement\u2014those speeds would make even the most patient person throw their hands up.And then there\u2019s the whole repetition issue. Infinite loops with \"Pygame\u2019s Pygame\u2019s Pygame\u2019s\" kind of defeats the point of quantization if you ask me. Sure, the authors have fixes like adjusting the KV cache or using min_p, but doesn\u2019t that just patch a symptom rather than solve the actual problem? A fried model is still fried, even if it stops repeating itself.On the flip side, I love that they\u2019re making this accessible on Hugging Face... and the dynamic quantization approach is pretty brilliant. Using 1.58-bit for MoEs and leaving sensitive layers like down_proj at higher precision\u2014super clever. Feels like they\u2019re squeezing every last drop of juice out of the architecture, which is awesome for smaller teams who can\u2019t afford OpenAI-scale hardware.\"accessible\" still comes with an asterisk. Like, I get that shared memory architectures like a 192GB Mac Ultra are a big deal, but who\u2019s dropping $6,000+ on that setup? For that price, I\u2019d rather build a rig with used 3090s and get way more bang for my buck (though, yeah, it\u2019d be a power hog). Cool tech\u2014no doubt\u2014but the practicality is still up for debate. Guess we'll see if the next-gen models can address some of these trade-offs.\n \nreply",
      "Oh the repetition issue is only on the non dynamic quants :) If you do dynamic quantization and use the 1.58bit dynamic quantized model the repetition issue fully disappears!Min_p = 0.05 was a way I found to counteract the 1.58bit model generating singular incorrect tokens which happen around 1 token per 8000!\n \nreply",
      "min_p is great, do you apply a small amount of temperate as well?\n \nreply",
      "The recommended temperature from DeepSeek is 0.6 so I leave it at that!\n \nreply",
      "I think most of the model creators share their model usage examples so high at 0.6-0.7 simply because it's what a lot of the client apps use. IMO this is WAY too high unless you're doing creative writing.Generally I set temp to 0-0.4 at absolute most.min_p actually needs a little temperature to work effectively so with min_p I almost always use 0.2\n \nreply",
      "Ye lower temp is also good :) Tbh its all trial and error - I found temp=1.5, min_p=0.1 to be very useful for pass@k type workloads - ie calling the LLM multiple times and aggregating.temp=0 is also good for singular outputs. For classification tasks, it's better to actually inspect the logits.But my goto setting is always setting min_p at least 0.01 or 0.05! It vastly suppresses incorrect rare random tokens from being created, and it helps massively!\n \nreply",
      "Btw, min_p (the paper about the sampler) got accepted to ICLR! As 4th author it warms my heart to so it used so much in the wild.\n \nreply",
      "Oh hi!! Congratulations on ICLR!!! min_p = 0.1 and temp = 1.5 is my default goto settings!!\n \nreply",
      "> That said, I\u2019m still skeptical about how practical this really is for most people.I'm running Open WebUI for months now for me and some friends as a front-end to one of the API providers (deepinfra in my case, but there are many others, see https://artificialanalysis.ai/).Having 1.58-bit is very practical for me. I'm looking much forward to the API provider adding this model to their system. They also added a Llama turbo (also quantized) a few months back so I have good hopes.\n \nreply",
      "Oh I love Open WebUI as well!! But glad to hear the 1.58bit version could be helpful to you!\n \nreply"
    ],
    "link": "https://unsloth.ai/blog/deepseekr1-dynamic",
    "first_paragraph": ""
  }
]