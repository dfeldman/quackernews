[
  {
    "title": "Apple pulls data protection tool after UK government security row (bbc.com)",
    "points": 943,
    "submitter": "helsinkiandrew",
    "submit_time": "2025-02-21T15:05:24 1740150324",
    "num_comments": 699,
    "comments_url": "https://news.ycombinator.com/item?id=43128253",
    "comments": [
      "Too right, it was far more problematic than they ever made out.> The UK government's demand came through a \"technical capability notice\" under the Investigatory Powers Act (IPA), requiring Apple to create a backdoor that would allow British security officials to access encrypted user data globally. The order would have compromised Apple's Advanced Data Protection feature, which provides end-to-end encryption for iCloud data including Photos, Notes, Messages backups, and device backups.One scenario would be somebody in an airport and security officials are searching your device under the Counter Terrorism Act (where you don't even have the right to legal advice, or the right to remain silent). You maybe a British person, but you could also be a foreign person moving through the airport. There's no time limit on when you may be searched, so all people who ever travelled through British territory could be searched by officials.Let that sink in for a moment. We're talking about the largest back door I've ever heard of.What concerns me more is that Apple is the only company audibly making a stand. I have an Android device beside me that regularly asks me to back my device up to the cloud (and make it difficult to opt out), you think Google didn't already sign up to this? You think Microsoft didn't?Then think for a moment that most 2FA directly goes via a large tech company or to your mobile. We're just outright handing over the keys to all of our accounts. Your accounts have never been less protected. The battle is being lost for privacy and security.\n \nreply",
      "> you think Google didn't already sign up to this?My understanding is that Android's Google Drive backup has had an E2E encryption option for many years (they blogged about it at https://security.googleblog.com/2018/10/google-and-android-h...), and that the key is only stored locally in the Titan Security Module.If they are complying with the IPA, wouldn't that mean that they must build a mechanism into Android to exfiltrate the key? And wouldn't this breach be discoverable by security research, which tends to be much simpler on Android than it is on iOS?\n \nreply",
      "My assumption is that Google has keys to everything in its kingdom [1].[1] https://qz.com/1145669/googles-true-origin-partly-lies-in-ci...\n \nreply",
      "> My assumption is that Google has keys to everything in its kingdomIf that were true, then their claims to support E2E encrypted backups are simply false, and they would have been subject to warrants to unlock backups, just like Apple had been until they implemented their \"Advanced Data Protection\" in 2022.Wouldn't there have been be some evidence of that in the past 7 years, either through security research, or through convictions that hinged on information that was gotten from a supposedly E2E-protected backup?\n \nreply",
      "It is possible to set up end to end encryption where two different keys unlock your data. Your key, and a government key. I assume google does this.1. encrypt data with special key\n2. encrypt special key with users key, and\n3. encrypt special key with government keyAnyone with the special key can read the data.the user key or the government key can be used to get special key.This two step process can be done for good or bad purposes. A user can have their key on their device, and a second backup key could be in a usb stick locked in a safe, so if you loose your phone you can get your data back using the second key.\n \nreply",
      "Would that still count as E2E-encrypted if another party has access? That would still count as lying to me.\n \nreply",
      "That depends on the definition of \"end\".\n \nreply",
      "E2EE means only your intended recipients can access the plaintext. Unless you intend to give the government access to your plaintext, what you described isn\u2019t E2EE.\n \nreply",
      "Is that google's definition or your definition? not being rude, but its pretty easy to get tricky about this.Since you are sending the data to google, isn't google an intended recipient? Google has to comply with a variety of laws, and it is likely that they are doing the best they can under the legal constraints. The law just doesn't allow systems like this.\n \nreply",
      "Would it be possible that they feel that the revelation of this backdoor would be too big of a loss so that any of these theoretical cases of the past 7 years have used parallel construction to avoid revealing the encrypted data was viewed?\n \nreply"
    ],
    "link": "https://www.bbc.com/news/articles/cgj54eq4vejo",
    "first_paragraph": "Apple is taking the unprecedented step of removing its highest level data security tool from customers in the UK, after the government demanded access to user data.Advanced Data Protection (ADP) means only account holders can view items such as photos or documents they have stored online through a process known as end-to-end encryption.But earlier this month the UK government asked for the right to see the data, which currently not even Apple can access.Apple did not comment at the time but has consistently opposed creating a \"backdoor\" in its encryption service, arguing that if it did so, it would only be a matter of time before bad actors also found a way in.Now the tech giant has decided it will no longer be possible to activate ADP in the UK.It means eventually not all UK customer data stored on iCloud - Apple's cloud storage service - will be fully encrypted.Data with standard encryption is accessible by Apple and shareable with law enforcement, if they have a warrant.The Home Off"
  },
  {
    "title": "Richard Feynman's blackboard at the time of his death (1988) (caltech.edu)",
    "points": 196,
    "submitter": "bookofjoe",
    "submit_time": "2025-02-21T18:22:59 1740162179",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=43131017",
    "comments": [
      "His motto \"What I cannot create, I do not understand\" has been one of the driving forces in my own quest to understand more about the world around me. A good friend had picked up a corollary which was \"What I cannot teach, I do not understand\" which I think was quite similar. Definitely one of my heroes.\n \nreply",
      "A similar thing I heard about the amish, is that it is not that they are anti technology, it is that they Don't want technology they can't control, basically if unable to make from raw materials they don't want it.Now I don't think this is entirely the way things are, I suspect there is a core of truth with a lot of religion and tradition surrounding it. But I have a lot of sympathy for wanting to have the freedom that control over your environment grants you. Personally I would hate to give up my tech. and remain a willing slave to the manufactures.\n \nreply",
      "> \"What I cannot teach, I do not understand\"And the corollary to that, from 17th century French writer Nicolas Boileau: \"Ce que l'on con\u00e7oit bien s'\u00e9nonce clairement, et les mots pour le dire arrivent ais\u00e9ment.\" - What we understand well, we express clearly, and words to describe it flow easily.\n \nreply",
      "I'm french and I have a great memory about that quote. In high school my litterature and physics teachers had a disagreement about it, although I believe they didn't know about each other's point of views. Only us the students did, as they each hand waved great insights about the world with this quote. One was arguing, much like you, about the profound truth there is to it. The other was quick to explain that they perfectly conceived how to ride a bicycle, but like most of us couldn't possibly teach it at a blackboard. I leave it to you to guess which was which :)\n \nreply",
      "Literature professor = bike argument?That's were I put my money, but I could see it going either way.This can devolve into a definitional argument, but I actually think it's fair to say we don't understand how we ride a bike.  We have many abilities and fluencies we don't understand, or only partially understand, in the sense that we can't break them down into pieces easily and transmit the information.  That perspective feels more accurate to me than saying I understand how I ride a bike because I can ride a bike, though in common usage the phrase \"I understand how to ride a bike\" would be perfectly acceptable.The subtle distinction between the phrase \"knows how to\" and \"understands\" hints at the difference here.\n \nreply",
      "We(by which I mean a person who knows how to ride a bike) do understand how to ride a bike. The problem in communicating that is a riding a bike is a skilled act. that is you cant get good at riding a bike by reading about it, and it is very hard to describe a well trained skill, it boils down to \"practice a lot\" which makes nobody happy.\n \nreply",
      "Looks like here's an opportunity for a language to express the riding of bikesHeadstart (modelling the non-riding of bikes):\nhttp://ruina.tam.cornell.edu/research/topics/bicycle_mechani...\n \nreply",
      "That's a great rebuttal. But if the actual claim is \"I cannot teach...\" It is still consistent. No one is claiming to teach you how to ride a bike or be in a relationship or know when to leave a party. \"I cannot teach what I cannot understand\" is not the inverse: \"I can teach everything I understand\".\n \nreply",
      "Where it gets complicated is that one can know how to do something without being able to explain it to oneself let alone teach it to others.\n \nreply",
      "I'm a native English speaker who, a lifetime ago, moved to Shanghai to teach English to adults.  One of my biggest struggles when I first started was explaining to students not just what the correct English should be in a given situation, but why that was the correct English.  This had a profound effect on my view of expertise and experts in general.\n \nreply"
    ],
    "link": "https://digital.archives.caltech.edu/collections/Images/1.10-29/",
    "first_paragraph": "\n1988\nThese digitized collections are accessible for purposes of education and research. Due to the nature of archival collections, archivists at the Caltech Archives and Special Collections are not always able to identify copyright and rights of privacy, publicity, or trademark. We are eager to hear from any rights holders, so that we may obtain accurate information. Upon request, we\u2019ll remove material from public view while we address a rights issue."
  },
  {
    "title": "Google Titans Model Explained: The Future of Memory-Driven AI Architectures (medium.com/sahin.samia)",
    "points": 64,
    "submitter": "cmbailey",
    "submit_time": "2025-02-18T13:16:38 1739884598",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=43089093",
    "comments": [
      "FWIW, Phil Wang (lucidrains) has been working on Titans reimplementation since roughly the day the paper was released. It looks to me from the repository that some of the paper's claims have not been reproduced yet, and reading between the lines, it might be Wang considers the paper to not be that groundbreaking after all -- hard to say definitively but the commit speed has definitely slowed down, and the last comments involve failing to replicate some of the key claims.Unfortunately. The paper looks really good, and I'd like for it to be true.https://github.com/lucidrains/titans-pytorch\n \nreply",
      "This article gives off really strong chatgpt vibes. Bullet points! Confidently stated but quite vague statements! Integration, key innovations, more bullet points! Distinct lack of personal viewpoints or unique opinions! Very long!Maybe I\u2019m being uncharitable and this is just the way things are written on Medium, but man this was not an easy or particularly enlightening read.\n \nreply",
      "100%HeaderParagraphList itemsDelve, here\u2019s why, conclusion.\n \nreply",
      "Nah it's definitely AI generated.  I used to like Medium a lot, but ever since AI Models became mainstream, it's just been a cesspool of horribly written articles.\n \nreply",
      "Binoculars, a llm detector, gives a \"most likely AI-generated\".\n \nreply",
      "For those of you in the field, this seems like a big deal?  ELI5\n \nreply",
      "Their model on protein folding was obviously very impactful. Their model for new chemicals has to my understanding provided no value. Based on this track record, who knows.\n \nreply",
      "I don't know. Google has some great papers but a lot more hot air. The best thing to do when you see a google paper is ignore it until someone you trust more writes a second paper about it.\n \nreply",
      "Paper https://arxiv.org/abs/2501.00663\n \nreply",
      "> opening doors to innovations in AI-driven reasoning, healthcare, and beyond.You went with \"healthcare\"?\n \nreply"
    ],
    "link": "https://medium.com/@sahin.samia/google-titans-model-explained-the-future-of-memory-driven-ai-architectures-109ed6b4a7d8",
    "first_paragraph": ""
  },
  {
    "title": "Suckless.org: software that sucks less (suckless.org)",
    "points": 175,
    "submitter": "flykespice",
    "submit_time": "2025-02-21T18:27:00 1740162420",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=43131059",
    "comments": [
      "The biggest impact suckless had on me was via. Their Stali Linux FAQ: https://sta.li/faq/ .They've built an entirely statically linked user space for Linux . Until then i never questioned the default Linux \"shared libraries for everything\" approach and assumed that was the best way to deliver software.Every little cli tool i wrote at work - i used to create distro packages for them or a tarball with a shell script that set LD_LIBRARY_PATH to find the correct version of the xml libraries etc i used.It didn't have to be this way. Dealing with distro versioning headaches or the finnicky custom packaging of the libraries into that tar ball just to let the users run by 150 kb binary.Since then I've mostly used static linking where i can. AppImages otherwise. I'm not developing core distro libraries. I'm just developing a tiny \"app\" my users need to use. I'm glad with newer languages like Go etc... static linking is the default.Don't get me wrong. Dynamic linking definitely has it's place. But by default our software deployment doesn't need to be this complicated.\n \nreply",
      "The thing is, dynamic linking doesn't mean using LD_LIBRARY_PATH or building full blown OS packages as the only way to find the correct libraries.  There's a first class facility for locating shared libraries, using the -R flag to provide a RUNPATH/RPATH in the binary.  The runtime link editor will use that path to locate shared libraries.  You can make your binaries relocatable as well, by using $ORIGIN in the RPATH: this gets expanded at runtime to the path of the executable, so, e.g., $ORIGIN/../lib would go up one from bin/ where the executable is and down alongside into the lib directory for your software.LD_LIBRARY_PATH is a debugging and software engineering tool, and shouldn't ever be part of shipped software.\n \nreply",
      "Build systems often make it a huge pain to get the right rpath. The chrpath tool makes it easy to fix the rpath after libtool got it wrong.\n \nreply",
      "Unrelated to suckless, there's a project (confusingly) named stal/IX: https://stal-ix.github.io/It is also a statically linked Linux distribution. But it's core idea is reproducible nix-style builds (including installing as many different versions/build configurations of any package), but with less pl fuff (no fancy funcional language - just some ugly jinja2/shell style build descriptions; which in practice work amazingly well, because underlying package/dependency model is very solid - https://stal-ix.github.io/IX.html).It is very opionated (just see this - https://stal-ix.github.io/STALIX.html), and a bit rough, but I was able to run it in VMs sucessfully. It would be amazing if it stabilizes one day.\n \nreply",
      "There's definitely value in the static approach in some cases, but there are some downsides e.g. your utility will need to be recompiled and updated if a security vulnerability is discovered in one of those libraries. You also miss out on free bugfixes without recompiling.If you require a library, you can specify it as a dependency in your dpkg/pacman/portage/whatever manifest and the system should take care of making it available. You shouldn't need to write custom scripts that trawl around for the library. Another approach could be to give your users a \"make install\" that sticks the libraries somewhere in /opt and adds it as the lowest priority ld_library_path as a last resort, maybe?\n \nreply",
      ">  e.g. your utility will need to be recompiled and updated if a security vulnerability is discovered in one of those libraries. You also miss out on free bugfixes without recompiling.This was the biggest pain point in deploying *application software* on Linux though. Distributions with different release cycles providing different versions of various libraries and expect your program to work with all of those combinations. The Big famous libraries like Qt , gtk might follow proper versioning but the smaller libraries from distro packages - guarantee. Half of them don't even use semantic versioning.Imagine distros swapping out the libraries you've actually tested out your code with with their libraries for \"security fixes\" or whatever the reason. That causes more problems than it fixes.Custom start up script was to find the same xml library I've used in the tar ball i packaged the application in. They could then extract that tar ball wherever they need - including /opt and run the script to start my application and it ran as it should. Iirc we used to even use rpath for this.\n \nreply",
      "> Half of them don't even use semantic versioning.This is a red herring. Distros existed before semantic versioning was defined and had to deal with those issues for ages. When packaging, you check for the behaviour changes in the package and its dependencies. The version numbers are a tiny indicator, but mostly meaningless.\n \nreply",
      "I think semantic versioning actually predates distributions. It just was not called \"semantic versioning.\" It was called Unix shared library versioning.\n \nreply",
      "I often refer to semantic versioning as \"semanticless versioning\". Everyone disagrees about what constitutes a change warranting each version number to be increased\n \nreply",
      "Fun part is that it actually is true as for different use cases of the same library change might mean something different.So it is complicated and there is no solution for every context, therefore we use best approximation.\n \nreply"
    ],
    "link": "https://suckless.org/",
    "first_paragraph": "Home of dwm, dmenu and\nother quality software with a focus on simplicity, clarity, and frugality.Read more about our philosophy and join us on the mailing\nlist.Atom feedThis reverts a commit and a regression with cursor move with wide glyphs, for\nexample with GNU readline.Below are some highlights of the changes for the recent releases of dmenu, dwm,\nst and tabbed, see the git logs for all details:General small Makefile improvements, rationale being: just be verbose and show\nwhat is done: do not abstract/hide details from the user/developer.\nRespect (more) the package manager and build system flags (CFLAGS, LDFLAGS, etc).dwm:\n\nImprovements to signal handling.\nFix: Avoid missing events when a keysym maps to multiple keycodes.\n\ndmenu:\n\nReduce memory usage for reading the lines.\nFix: X11 BadMatch error when embedding on some windows.\n\nst:\n\nFix: bounds checks of dc.col.\nFix: buffer overflow when handling long composed input.\nIgnore C1 control characters in UTF-8 mode.\nImprovements to cell "
  },
  {
    "title": "Yocto, RockPi and SBOMs: Building modern embedded Linux images (vpetersson.com)",
    "points": 85,
    "submitter": "mvip",
    "submit_time": "2025-02-21T19:34:37 1740166477",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43131902",
    "comments": [
      "As someone in the Software Supply Chain business. Yocto SBOMs are considered low quality because they include things that do and do not exist in the final compiled artifact. When you compare what exists inside, physically from a binary perspective, what is included in the manifest, and what is generated in the build root, you will find they will never align unless you get creative and map artifacts together. Today they are accepted as meeting the compliance checkbox, but once the industry matures, they will need to adjust their approach.\n \nreply",
      "Last time I tried Yocto, some people here on HN suggested that I try Buildroot instead.I don\u2019t see so many mentions of Buildroot in this thread yet.If you are interested in Yocto it might be worth having a look at Buildroot as well. I liked it a lot when I tried it.My thread from years ago, where people told me about Buildroot:https://news.ycombinator.com/item?id=18083506The website of Buildroot:https://buildroot.org/\n \nreply",
      "I think, in a lot of cases, the choice between Buildroot and Yocto comes down to \"which one does the SoC vendor support.\"\n \nreply",
      "Yocto is synonymous with low-end IoT these days, and causes more problems than it solves in the long-term for many folks.Also, bootstrapping your own application launcher shell on a raw kernel is usually not a difficult task (depending on vendor firmware.) Some folks just drop a full Lua environment for an OS that fits in under 2.7MB ISO even with a modern kernel.Nir Lichtman posted a tutorial for mere mortals here:https://www.youtube.com/watch?v=u2Juz5sQyYQHighly recommended exercise for students =3\n \nreply",
      "Yocto is pretty great! Unfortunately I feel like it gets a lot of criticism, but usually from people who haven't gotten to learn it. Like \"I had to spend 2h on Yocto and this thing suuuuucks, I threw a docker image there and called it a day\".Which is a pity, because when used correctly it's really powerful!From the article, I can't help but mention that one third of the \"key terminology\" is about codenames. What do people have with codenames? I can count and easily know that 5 comes after 4. But I don't know how to compare Scarthgap and Dunfell (hell, I can't even remember them).\n \nreply",
      "Part of why it gets so much criticism is that Yocto\u2019s learning curve is pure brutality.Out of the box configurations for Yocto images and recipes are fabulous.Trying to modify those configurations below the application layer\u2026 you\u2019re gonna have a bad time. Opaque error messages, the whole layers vs recipes vs meta issues, etc. I also can\u2019t shake the feeling that yocto was made to solve a chip company\u2019s problems (I.e. supporting Linux distros for three hundred different SOCs) rather than my problems (I.e. ship working embedded software for one or two SOC platforms).I\u2019ve had a lot more success with buildroot as an embedded Linux build system and I recommend it very highly.\n \nreply",
      "I've done both and I'll add that the one thing I miss about Yocto is that it could package up an SDK with installer that could be deployed on a different machine. With a single install you have the correct crosstools, libraries, and headers to build directly for target. And when we used to develop with Qt that was a huge advantage in helping others get started.But now I use Buildroot and I get things done without all the extra anxiety.\n \nreply",
      "\"Part of why it gets so much criticism is that Yocto\u2019s learning curve is pure brutality.\"At one time when SoCs were RAM lean... and build specific patching, stripping and static linking was considered an acceptable tradeoff in the yocto build systems for IoT etc.  The use-cases are extremely difficult to justify these days with 256MB of ram on a $5 SoC...However, the approach was commercially unsustainable from maintainability, security, and memory-page cache-hit efficiency metrics.  It should be banned given it still haunts the lower systems like a rancid fart in an elevator.  =3\n \nreply",
      "Yeah, I was a bit scared off by it and both the terminology and the curious mixing of Python and bash can be a bit confusing. But it\u2019s powerful and also very extensible without (generally) having to fork upstream layers.\n \nreply",
      "I'm honestly impressed by how...well it works. Considering it's building an entire, totally custom Linux distro from scratch it requires a surprisingly little amount of hand-holding.\n \nreply"
    ],
    "link": "https://vpetersson.com/2025/02/21/yocto-rockpi-and-sboms.html",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Slime OS \u2013 An open-source app launcher for RP2040 based devices (github.com/abeisgoat)",
    "points": 63,
    "submitter": "abeisgreat",
    "submit_time": "2025-02-21T20:22:57 1740169377",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43132482",
    "comments": [
      "I just watched the authors video on the cyberdeck they made. Impressive project!https://youtu.be/rnwPmoWMGqk?si=pD3z4mPFuYq61ROq\n \nreply",
      "I watched your video earlier today and I want to thank your for the inspiring project and the funny presentation!\n \nreply",
      "Multiple buffering; https://en.wikipedia.org/wiki/Multiple_bufferingWikipedia has \"page flipping\" but not \"physical double-buffer\"? TIL about triple buffering, and quad buffering for stereoscopic applications.\n \nreply",
      "[deleted]"
    ],
    "link": "https://github.com/abeisgoat/slime_os",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An app launcher for the PicoVision\n      Slime OS is an app launcher for the PicoVision (and soon other RP2040 and RP2350 devices). It was originally designed for the Slimedeck Zero, a mini cyberdeck project. However I hope to expand it to other devices and form factors.This README contains affiliate links which help support this project!Slime OS runs in a limited 32-color mode with a 400x240 internal resolution which is interlaced up to 800x480. This resolution should scale well on most HDMI displays.Please refer to an example app for boiler plate.Slime OS includes various libraries which are used internally but may also be helpful when making apps.Begin by importing slime_os...This software is experimental and does not work completely, specifically issues include...Currently this project uses a very specific set of hardware, howev"
  },
  {
    "title": "The Ren'Py Visual Novel Engine (renpy.org)",
    "points": 103,
    "submitter": "Tomte",
    "submit_time": "2025-02-21T20:09:32 1740168572",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43132336",
    "comments": [
      "As somebody who has read a large number of visual novels (VNs), I consider Ren'py one of the better engines as a consumer:- It has all the basic featured you'd expect, ranging from proper backlogs, to key bindings, and much more. You'd be shocked how many VN developers think that they can just pop out an VN engine themselves, and end up producing something that lacks even basic features.- It is performant. You'd be surprised how poorly many VN engines run really poorly. Fast-forwarding past already-read text is often capped at a surprisingly slow rate, with your CPU pegged at 100%, due to how inefficient many engines are- It is easily moddable, as you just need to plop a (pseudo-)python script into the game folder, so you can easily tweak or turn off annoying bits of UIA number of localization companies have also ported (typically older) Japanese titles to Ren'py, instead of having to struggle with poor to non-existent support for non-Japanese systems in the original engine, as well as extremely expensive engine licenses, and just straight up poorly written bespoke engines. Examples of companies having done this includes JAST USA, FAKKU, MangaGamer, and (IIRC) Sekai Project/Denpasoft. In other words, the heavy hitters of VN localization.The other main contender for best VN engine (in my mind) is the KiriKiri engine, which I believe is also open source, but which lacks the large, English-speaking community that Ren'py has built.Despite that, Ren'py does have a bit of a poor reputation in the older VN reading community, more specifically among readers who mainly read localized, Japanese VNs, due to its association with low-budget, originally English visual novels. Typically the same people have only heard of DDLC and Katawa Shoujo, when it comes to originally English visual novels\n \nreply",
      "One thing Ren'Py does well that many other engines do poorly is forward compatibility of saves.  When VNs are released in pieces over time it is important to make sure the saves carry forward.  Nothing kills momentum like \"you will need to start over from scratch after every update\".As far as competitors go, the list is not very long.  Sugarcube/Twine works ok, but tends to bog down as the projects grow large because it doesn't have a good way of breaking up the core logic across different files.  The save system is also a bit of a problem since the in-browser saves tend to get lost in version updates.  QSP is just a buggy confusing mess every time.  People try to shoehorn RPGMaker into doing the job but it is just so clunky and slow.  Custom engines, typically built in Unity, are almost always massive resource hogs and lacking in one or more of the basic features Ren'Py provides by default.  Plus there is just the community aspect of it, with Ren'Py having so many developers there is a lot of institutional knowledge to be had.  If you run into a problem you are probably not the first, someone else has probably solved it already.\n \nreply",
      "I took a quick look via query.vndb.org, and the top 10 most popular engines in terms of releases are Ren'Py, KiriKiri, TyranoScript, Unity, NScripter, LiveMaker, RPG Maker, YU-RIS, Flash, and Artemis (from most to least).This is of course not an exact ranking, since the same game can have many (nearly identical) releases, but it roughly matches my experience\n \nreply",
      "The best thing about Renpy is that the text rendering actually looks good, which is true of shockingly few VN engines even today.Especially when you increase the window size or run fullscreen, most VN engines just render the whole game at a fixed resolution and upscale it up but Renpy makes the framebuffer match the window size and renders text at the full resolution.\n \nreply",
      ">proper backlogsSomething noticeably missing from almost every other type of text-heavy game which perhaps wouldn't be if games developers were less snobbish about where they draw inspiration from.On the other hand, writers of games with metatextual stories benefit from their target audience not knowing how well-trod the ground is.\n \nreply",
      "The other big text engines are probably Inform 7 and Twine? They both have undo.\n \nreply",
      "What does a \"backlog\" mean in this context?\n \nreply",
      "Like you can either read a log of what characters said in a scene so far, or simply go backwards through the story to reach an earlier line and view it again.\n \nreply",
      ">A number of localization companies have also ported (typically older) Japanese titles to Ren'py, instead of having to struggle with poor to non-existent support for non-Japanese systems in the original engine, as well as extremely expensive engine licenses, and just straight up poorly written bespoke engines. Examples of companies having done this includes JAST USA, FAKKU, MangaGamer, and (IIRC) Sekai Project/Denpasoft. In other words, the heavy hitters of VN localization.That caught my curiosity, but I couldn't find any examples of older VNs being ported to Renpy. Could you share any examples?\n \nreply",
      "Agree, as a person with accessibility issues, I prefer this engine because it has a basic TTS support that I can mod and plug my own custom TTS script. \nI also seen people reinventing poorly the engine in Unity so for me text based games or visual novels in Unity are just a NO , because of TTS support.\n \nreply"
    ],
    "link": "https://www.renpy.org/",
    "first_paragraph": "Ren'Py is a visual novel engine \u2013 used by thousands of creators from around the world \u2013\n      that helps you use words, images, and sounds to tell interactive stories that run on computers and mobile devices.\n      These can be both visual novels and life simulation games. The easy to learn script language allows\n      anyone to efficiently write large visual novels, while its Python scripting is enough for complex\n      simulation games.Ren'Py is open source and free for commercial use.\n          The latest official release of Ren'Py 8 is 8.3.4 \"Second Star to the Right\", released on\n          December 8, 2024. Ren'Py 8 is recommended for all projects.\n        \n          The nightly fix version of Ren'Py is built every night, and contains fixes to the latest stable version. It isn't\n          tested as well as the official release, but often has fixes that haven't made it through the release process.\n        \n        Ren'Py 7 is the legacy version of Ren'Py, to support ongoing project"
  },
  {
    "title": "Math Academy, part 1: My eigenvector embarassment (frankhecker.com)",
    "points": 14,
    "submitter": "gmays",
    "submit_time": "2025-02-18T14:47:10 1739890030",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=43090077",
    "comments": [
      "is MathAcademy that much better that KhanAcademy (which also has a Linear Algebra course and covers eigenvalues of course), which is free? Considering it for my youngest kids, but my eldest (now finished college with a degree in engineering) used Kahn Academy as a high school supplement and it was quite good (this was about 10 years ago). (She didn't take the KahnAc LinAlg course -- not sure it was around at that time -- but she did take their calc course and it helped her ace her CalcBC AP test.)\n \nreply",
      "yes if your kid loves math -  my kid benefited from Math Academy (currently in college studying CS).  Started with Math Academy as a HS freshman and finished BC Calc 2 years early with a 5 on the AP Exam.  While he did Khan Academy for many years (which is a great resource)  it didn\u2019t really motivate him as much and seemed designed for a broader more generalist audience.We also tried some other programs like Art of Problem Solving (great program, but required very synchronous classes which were hard to fit in)My suggestion would be try it for a few months,\n \nreply",
      "he was a physics and math major and did not know eigenvectors and eigenvalues? i would like to know how is this possible. can someone explain it to me?\n \nreply",
      "He is a bit older. Linear algebra is also very old, but it didn't really become the field we know today until the 1950s. I would add that in 2025 it is cheap to buy a computer that can solve large linear systems, but that certainly wasn't true in 1975, so linear algebra was less applicable in the real world.I am not too familiar with the pedagogical history of linear algebra, but I've been reading some advanced undergraduate geometry texts from the 30s-60s and linear algebra was generally not an assumed prerequisite. There was a particular separation between the studies of \"two and three dimensional vector spaces over R\" (largely geometric) versus \"finite dimensional vector spaces over a field\" (entirely algebraic), and determinants were presented directly as volume computations. These days undergraduates mostly treat R^2 and R^3 algebraically, maybe at the expense of geometric understanding. (E.g. Euler's rotation theorem is easily proved when restated as a theorem about matrices over R^3 with determinant +1, but Euler's original statement and proof using spherical trigonometry is deeper.)\n \nreply",
      "Same boat as the author here, except I switched from physics to software after year three.I had never heard of them until I was _years_ into software engineering.  I think this is more common than you may think.  I had never dealt with linear algebra in a formal setting, despite leveraging a lot of the concepts, until then.\n \nreply",
      "I asked myself the same thing. The article said \u201clearn\u201d Linear Algebra, not \u201creview\u201d Linear Algebra. Do some undergrad math programs not teach Linear Algebra?\n \nreply",
      "It was an optional senior level course at my college\n \nreply",
      "I cancelled my Math Academy sub because I ran out of 30 minute blocks for SAT problems I would never need. It was too remedial.\n \nreply"
    ],
    "link": "https://frankhecker.com/2025/02/08/math-academy-part-1/",
    "first_paragraph": "An example Math Academy status display. The student is about to begin a new lesson; that lesson has two other lessons as prerequisites. The \u201c3644 XP\u201d represents the student\u2019s activity since subscribing to the service, roughly equivalent to about 60 hours for a typical student. Click for a higher-resolution version.This all started because I don\u2019t know what an eigenvector is. If I were a typical person, that wouldn\u2019t be a problem. I could go through life happily ignorant of how to calculate an eigenvector, or even how to spell the word.But in the olden days I was a college math and physics major, graduated with a 4.0 GPA, and was encouraged by my professors to consider going to graduate school. (I ultimately decided against it.) Many years later I did a bunch of data analyses in R as part of my blogging hobby and wanted to learn linear algebra (the area of mathematics that includes eigenvectors) to help me understand more advanced data science topics. I worked my way through a few chapt"
  },
  {
    "title": "20 years working on the same software product (successfulsoftware.net)",
    "points": 230,
    "submitter": "hermitcrab",
    "submit_time": "2025-02-21T21:22:55 1740172975",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=43133174",
    "comments": [
      "Makes me nostalgic of desktop software. I hate that everything today is a website and requires a ridiculously fast internet connection. And what seems to be in fashion for \"desktop software\" today is to ship a website together with a whole browser and pretend it's not a website.I wonder how the licensing works: do people pay for newer versions? Or do people just buy one version but more people get married every year, bringing new customers? I guess it is not a subscription model, right?\n \nreply",
      "You buy a perpetual licence for version N. You can then optionally upgrade to version N+1 later at a 60% discount.\n \nreply",
      "The best business model.\n \nreply",
      "I am also ok with one like Jetbrains where you subscribe and after a year you can keep the last version you paid for.  They do a lot of updates, so the money is going into the product but one isn't forced to stay in order to use it.\n \nreply",
      "Depends on who you ask. Wall street would disagree.\n \nreply",
      "> Makes me nostalgic of desktop software. I hate that everything today is a website and requires a ridiculously fast internet connection. And what seems to be in fashion for \"desktop software\" today is to ship a website together with a whole browser and pretend it's not a website.Funny isn't it? These days developers experienced with building typical desktop software are being asked Leetcode hard puzzles to find the most optimal solution on the first attempt.Yet when they are hired most of them choose what I see as the most inefficient (in both memory, disk space and runtime), suboptimal and very low quality software as the \"solution\". When I mean \"the most\" it really is the worst solution possible, which is all these Electron based \"desktop apps\" which is an entire browser rebranded as a \"desktop app\".It is even laughable that those who believe using a faster language when using Electron would make it more performant. This has never been more further from the truth as the worst-case performance still applies as long as you are using Electron.SWEs not being able to build (native) desktop apps or apps that don't use a browser is a skill issue.\n \nreply",
      ">And what seems to be in fashion for \"desktop software\" today is to ship a website together with a whole browser and pretend it's not a website.yeah! shipsters/sugh\n \nreply",
      "Makes me so happy to see people like this exist. All good software, really all good software, is indie small ones made with love and care whose authors also lived a good life outside of the cubicle mess. (I know about the exaggeration, but really, 95% of what I love is indie software, you don't find that kind of creativity and love in any company)\n \nreply",
      "yeah - I'm sure Everything by voidtools is precisely that\n \nreply",
      "> I was getting married and I volunteered to do the seating plan for our wedding reception. It sounded like a relatively straightforward optimization problem, as we only had 60 guests and no family feuds to worry about. But it was surprisingly difficult to get right.Man, this sounds way too familiar!\n \nreply"
    ],
    "link": "https://successfulsoftware.net/2025/02/21/20-years-working-on-the-same-software-product/",
    "first_paragraph": "I released version 1 of my table seating planning software, PerfectTablePlan, in February 2005. 20 years ago this month. It was a different world. A world of Windows, shareware and CDs. A lot has changed since then, but PerfectTablePlan is now at version 7 and still going strong.PerfectTablePlan v1PerfectTablePlan v7I have released several other products since then, and done some training and consulting, but PerfectTablePlan remains my most successful product. It\u2019s success is due to a lot of hard work, and a certain amount of dumb luck.I was getting married and I volunteered to do the seating plan for our wedding reception. It sounded like a relatively straightforward optimization problem, as we only had 60 guests and no family feuds to worry about. But it was surprisingly difficult to get right. I looked around for some software to help me. There were a couple of software packages, but I wasn\u2019t impressed. I could do better myself! So I wrote a (very rough) first version, which I used "
  },
  {
    "title": "Reality has a surprising amount of detail (2017) (johnsalvatier.org)",
    "points": 238,
    "submitter": "lis",
    "submit_time": "2025-02-18T09:36:30 1739871390",
    "num_comments": 120,
    "comments_url": "https://news.ycombinator.com/item?id=43087779",
    "comments": [
      "A bit tangential, but I have been playing the game \"Pinball FX\" a lot. I really like it (and especially its spin-off/expansion Pinball M), but it's surprisingly taxing on my computer.I mentioned this to a friend, and he was kind of confused, understandably so, and said \"...it's pinball...why is that taxing?\"It's not a dumb question, we have had virtual pinball games since the Atari 2600 at least, and even pretty fun stuff on the Amiga and DOS like Pinball Dreams and Epic Pinball, so why would a modern pinball game make my relatively beefy laptop struggle playing it?The answer is because virtual pinball occupies a strange kind of space in the world of video games, in that they're trying to emulate something that is entirely dependent on extremely precise and subtle physics.  It's not like you can really have too accurate of physics; the better the physics, the closer it is to a \"real\" pinball machine, and generally speaking the more fun the game is.As such, I think you could honestly make a pinball game that taxes any hardware.  You'll never be able to have \"perfect\" physics (as in physics that completely and totally imitate reality), you can only get asymptotically close to \"perfect\", and the closer you are, the more taxing the computation will end up being.It just made me think, this applies to nearly anything.  We all work with abstractions, but if dive into the details of something and recurse, it's not like it ever ends.\n \nreply",
      "I don't actually know, but I'd wager a lot that it's the graphics rather than the physics which causes the game to be slow. Generally the expensive thing in video games is rendering. Computing the next world state is generally relatively cheap, especially if we're talking about a confined area with a very small number of rigid bodies (the ball, flippers, bumpers). A pinball game like Pinball FX that's rendering a 3d world with lighting, it'd just be shocking to me if the physics were to blame for the performance.\n \nreply",
      "Especially with such a small number of rigid bodies to worry about. The literal only thing that has to collide with anything else is the pinball itself, unless we're talking about a pretty weird pinball machine.\n \nreply",
      "Yeah fair, it's tough to say; they're simulating a few non-obvious things too, like ball spin, but it's possible it's mostly graphics.I think my overall point still stands, but you might be right.ETA:I would like to point out that my dad was debating buying one of those virtual pinball tables, and so we played one at a mall, it was decidedly not fun.  The physics were way too floaty, and didn't feel good at all.  It looked like they were running it on some shitty Android and just mounted a big TV.That's why I thought that maybe it was the physics in PinballFX slowing things down.\n \nreply",
      "Have you seen the virtual pinball tables that emulate depth by tracking your head? It's a great effect\n \nreply",
      "I have not, that sounds pretty cool. That might make the machines more fun, or at least feel more realistic.I think having something more or less like a rumble feature would do a lot too.  Even if you just had a solenoid that thumps when hitting a bumper would make it feel a lot more realistic.\n \nreply",
      "Related. Others?Reality has a surprising amount of detail (2017) - https://news.ycombinator.com/item?id=38407851 - Nov 2023 (136 comments)Reality has a surprising amount of detail - https://news.ycombinator.com/item?id=36309597 - June 2023 (1 comment)Reality has a surprising amount of detail (2017) - https://news.ycombinator.com/item?id=29429385 - Dec 2021 (118 comments)Reality has a surprising amount of detail (2017) - https://news.ycombinator.com/item?id=28006256 - July 2021 (1 comment)Reality has a surprising amount of detail (2017) - https://news.ycombinator.com/item?id=22020495 - Jan 2020 (115 comments)Reality has a surprising amount of detail (2017) - https://news.ycombinator.com/item?id=16184255 - Jan 2018 (294 comments)\n \nreply",
      "Its a yearly tradition!\n \nreply",
      "it's quite a good read, i'm not surprised it's been posted so many times!\n \nreply",
      "And this is one of the main utilitarian arguments for diversity in teams. If everybody has the same socio-cultural background, it's harder to leave the frame.\n \nreply"
    ],
    "link": "http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail",
    "first_paragraph": "My dad emigrated from Colombia to North America when he was 18 looking looking for a better life. For my brother and I that meant a lot of standing outside in the cold. My dad\u2019s preferred method of improving his lot was improving lots, and my brother and I were \u201cvoluntarily\u201d recruited to help working on the buildings we owned.That\u2019s how I came to spend a substantial part of my teenage years replacing fences, digging trenches, and building flooring and sheds. And if there\u2019s one thing I\u2019ve learned from all this building, it\u2019s that reality has a surprising amount of detail.This turns out to explain why its so easy for people to end up intellectually stuck. Even when they\u2019re literally the best in the world in their field.Consider building some basement stairs for a moment. Stairs seem pretty simple at first, and at a high level they are simple, just two long, wide parallel boards (2\u201d x 12\u201d x 16\u2019), some boards for the stairs and an angle bracket on each side to hold up each stair. But as yo"
  },
  {
    "title": "Launch HN: Massdriver (YC W22) \u2013 Self-serve cloud infra without the red tape",
    "points": 53,
    "submitter": "coryodaniel",
    "submit_time": "2025-02-21T16:19:12 1740154752",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=43129301",
    "comments": [
      "Congrats on the launch!I'm not a seasoned DevOps professional but I'm usually the one who ends up provisioning or setting up VMs, serverless stuff and DBs. I just don't understand the product.You make reusable TF modules that have security and policies baked in. Engineers use a UI to hookup those modules and Massdriver does the deployment work for you.Sounds like a godsend for big teams but I don't see pre-funded Startups being able to afford a $500/mo fee. For funded ones that's highly approachable but their problems with their IaC wouldn't be as visible.Honestly, in smaller teams you can get pretty far with just setting thing sup through your cloud providers web console and just focus on what your building.Since the fee is kind of steep, what's the justification for this. Is it that the workflow improvements would significantly improve productivity which would justify the cost or is the service itself expensive to run and maintain.\n \nreply",
      "Thanks! And ... you're right!Massdriver isn\u2019t aimed at pre-funded startups. Early-stage teams are often better off with a PaaS or setting things up manually until ops challenges become a bottleneck.Our pricing (5-seat minimum) is intentional to dissuade smaller teams. The real value kicks in when teams need self-service. Ops teams build the modules (not us), and Massdriver acts as the interface. Developers diagram what they need, and Massdriver provisions using the ops team\u2019s standards. This keeps developers focused on building while giving ops visibility and control over what\u2019s deployed.\n \nreply",
      "So does mass driver become a single source of truth for all information about my companies entire cloud or does it only maintain a track of what's been deployed through it.I have a friend whos a manager at a large e-commerce company who's teams entire responsibility is to oversee all matters regarding their private and public cloud usage. They also manage and maintain services for internal use.I would love to recommend you guys to them because managing deployments from over a dozen teams located around the world is hell for them. However they have an extensive private cloud setup, would your solution be as applicable to them as it is to companies running on public clouds?\n \nreply",
      "If this is for the company I think it is for, they won\u2019t use this as they have a very strong NIH culture.\n \nreply",
      "It is a single source of truth, but only what is managed through the platform.Private cloud isn't the best experience right now, its possible, but it requires our platform being able to 'get inside' so we either need a control plane exposed to us or a VPN connection in.Self-hosted is our #1 requested feature, so we are cranking away at it.  Its in alpha, and we're looking for testers/feedback. Would love an intro!\n \nreply",
      "Oh boy, I have so many questions...* You want to simplify infrastructure, but there's a new learning curve here. Why did you decide to go with diagramming as a solution? What other methods did you evaluate and discard?* How does an organization with existing infrastructure implement Massdriver?* How do you handle edge cases, custom configurations, complex logic, etc.? For example, workflows that use custom scripts or some other form of band-aid.* The visual approach could make it too easy to piece together infrastructure without understanding the implications. How do you prevent developers from creating poorly architected systems just because you make it simple to connect components?* When things go wrong, how do developers debug issues at the infrastructure level? Do they reach out to ops?\n \nreply",
      "> Why did you decide to go with diagramming as a solution?I had a similar idea. I have enough experience with visual programming environments to be wary. Here are my thoughts on why it might be a good approach here:\n* It would be possible to take a whiteboard scribble and turn it into a real system. Combining this with the services available in the cloud, you end up with something really powerful. It all comes down to the level of abstraction supported. You have to be able to draw boxes at a level that adds value, but also zoom in to parameters at the service/API level as necessary.\n* I've worked on a team that was responsible for designing and maintaining its own AWS infrastructure. Along with that comes the responsibility for controlling cost. The idea of having a living architectural diagram that also reported cost in near real-time is really helpful, especially if you could start to do things like project cost given a level of traffic or some other measure.Once you have a decent library of TF modules, and an understanding of the networking and compute fundamentals, and an understanding of the services offered by your cloud provider, you have something really powerful. If a service can help accelerate that, it's worth it IMHO.\n \nreply",
      "You have really hit the nail on the head with what we were going for! Cory and I, very early on said \"We draw this stuff, agree on it, then go build it in TF which is where the problems start\".We imagined a world where you could go into architecture review and come out of that meeting with staging stood up and ready to run your application.This makes sense for infra because it's mostly config management and API calls. Visual programming is rough because control structures are soo hard to visualize.\n \nreply",
      "I'm here for the questions!> * You want to simplify infrastructure, but there's a new learning curve here. Why did you decide to go with diagramming as a solution? What other methods did you evaluate and discard?We try to make it so both teams have to learn as little as possible. For the ops team, we are built on the tools those teams are familiar with terraform, helm, ansible, etc. Our extension model is also ops-oriented. You add add'l provisioners by writing Dockerfiles, you enforce pre-validations with JSON Schema (this is the best we could come up w/, but figured it was a safe bet ops-wise since its a part of OpenAPI). For devs, they dont have to learn the ops teams tools to provision infrastructure, they just diagram. Massdriver was originally a wall of YAML to connect all the pieces, but it felt fumbly (and like everything else).I wanted to make a VR version like something youd see in a bad hacker movie, but Dave told me not to get ahead of myself. :D> * How does an organization with existing infrastructure implement Massdriver?Depends on if they have IaC or not. If they have IaC, they publish the modules. If their IaC has a state backend, its usually just good to go, if they are using localfiles for state, we offer a state server they can push state into.If teams dont have IaC, we run workshops on \"reverse terraforming\" or \"tofuing\" and also offer professional services to codify that stuff for you.> * How do you handle edge cases, custom configurations, complex logic, etc.? For example, workflows that use custom scripts or some other form of band-aid.As noted above, its all based off common ops tooling. Lets say you wanted to use a new sec scanning tool for IaC and we don't have it in our base provisioners, you can write a dockerfile, build the image, then you can include that scanning tool in any of your massdriver configs. We also have folks doing day-2 operations with the platform. Things like database migrations and whatnot. The lines in the graph actually carry information and can push that info across different tools, so you can do things like have helm charts get information from a terraform run. You can build a provisioner with say the psql tool or a helm chart running bucardo and use it to set up replication between an old and new postgres instance.> * The visual approach could make it too easy to piece together infrastructure without understanding the implications. How do you prevent developers from creating poorly architected systems just because you make it simple to connect components?The lines and connections are actually a type system that you can extend (also based on JSON Schema). That way ops teams can encode common things into the platform once. ie. this is how we authenticate to postgres, its an AWS secret, security gruops and these IAM policies. All of that information flows across the line into the other module. The modules reject invalid types so common misconfigurations _cant_ happen. It also lets you \"autocomplete\" infrastructure. Lets say I'm a dev and I want to deploy a database. I can drop it on the canvas, since massdriver understands the types, it'll automatically connect it to a subnet that dev has access to.> * When things go wrong, how do developers debug issues at the infrastructure level? Do they reach out to ops?They may, we have a lot of stuff built in though to make the system as truly self-service (through day 2) as possible. There are runbooks per module so ops teams that have built out a module around a use case can put in common trouble shooting steps and its all accessible from the same graph. Alarms and metrics also show up there. Ops teams can also publish day-2 modules to the catalog, so developers can drag and drop common one-off tasks for maintenance onto their canvas and perform it.\n \nreply",
      "> You add add'l provisioners by writing Dockerfiles, you enforce pre-validations with JSON SchemaThat's really neat! Thank you for answering my questions and all the best with your launch!\n \nreply"
    ],
    "link": "item?id=43129301",
    "first_paragraph": ""
  },
  {
    "title": "Sparse Voxels Rasterization: Real-Time High-Fidelity Radiance Field Rendering (svraster.github.io)",
    "points": 45,
    "submitter": "jasondavies",
    "submit_time": "2025-02-21T21:06:05 1740171965",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=43132964",
    "comments": [
      "I look forward to reading this in closer detail, but it looks like they solve an inverse problem to recover a ground truth set of voxels (from a large set of 2d images with known camera parameters), which is underconstrained.  Neat to me that it works w/o using dense optical flow to recover the structure -- I wouldn't have thought that would converge.Love this a whole heck of a lot more than NeRF, or any other \"lol lets just throw a huge network at it\" approach.\n \nreply",
      "I think this paper is as important as original Gaussian Splatting paper.\n \nreply",
      "Why do you say so?\n \nreply",
      "What is the usecase for radiance fields?\n \nreply",
      "Take a bunch of photos of an object or scene.  Fly around the scene inside a computer.https://news.ycombinator.com/item?id=43120582Like photogrammetry. But, handles a much wider range of materials.\n \nreply",
      "Can someone ELI5 what the input to these renders is?I'm familiar with the premise of NeRF \"grab a bunch of relatively low resolution images by walking in a circle around a subject/moving through a space\", and then rendering novel view points,but on the landing page here the videos are very impressive (though the volumetric fog in the classical building is entertaining as a corner case!),but I have no idea what the input is.I assume if you work in this domain it's understood,\"oh these are all standard comparitive output, source from <thing>, which if you must know are a series of N still images taken... \" or \"...excerpted image from consumer camera video while moving through the space\" and N is understood to be 1, or more likely, 10, or 100......but what I want to know is,are these video- or still-image input;and how much/many?\n \nreply",
      "They are photos, in this case from the MIP Nerf 360 dataset. I believe there are on the order of hundreds per scene. They are not videos turned into photos. Some datasets include high grade position and directional information  -- I believe this dataset does not, so you need to do some work to orient the rendering training. But, I'm a hobbyist, so all this could be very wrong.\n \nreply",
      "> We optimize adaptive sparse voxels radiance field from multi-view images\u2026Pretty sure the input is the same as for NeRFS, GS and photogrammetry: as many high rez photos from as many angles as you have the patience to collect.I think the example scenes are from a common collection of photos that are being widely used as a common reference point.\n \nreply"
    ],
    "link": "https://svraster.github.io/",
    "first_paragraph": "We optimize adaptive sparse voxels radiance field from multi-view images without SfM points. The fly-through videos are rendered by our SVRaster in >100 FPS.\n              We propose an efficient radiance field rendering algorithm that incorporates a rasterization process on adaptive sparse voxels without neural networks or 3D Gaussians. There are two key contributions coupled with the proposed system. The first is to adaptively and explicitly allocate sparse voxels to different levels of detail within scenes, faithfully reproducing scene details with 655363 grid resolution while achieving high rendering frame rates. Second, we customize a rasterizer for efficient adaptive sparse voxels rendering. We render voxels in the correct depth order by using ray direction-dependent Morton ordering, which avoids the well-known popping artifact found in Gaussian splatting. Our method improves the previous neural-free voxel model by over 4db PSNR and more than 10x FPS speedup, achieving state-of-t"
  },
  {
    "title": "DeepDive in everything of Llama3: revealing detailed insights and implementation (github.com/therealoliver)",
    "points": 109,
    "submitter": "therealoliver",
    "submit_time": "2025-02-21T16:57:13 1740157033",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43129887",
    "comments": [
      "I like the use of the functional API here. I learned through a similar route and it was very helpful for me compared to trying to understand `torch.nn.Module`.Here's a gist of my learning path if it's helpful to anyone: https://gist.github.com/kevmo314/294001659324429bae6749062a9...\n \nreply",
      "I hadn't realized OpenAI's tiktoken Python library could work with other models outside of the OpenAI family, that's really useful: https://github.com/therealoliver/Deepdive-llama3-from-scratc...\n \nreply",
      "great need; mulling over; shows up all the time in AI paradigms\n \nreply",
      "[flagged]",
      "If you\u2019ve got nothing constructive to say\u2026 don\u2019t say anything? OP brings a lot of value in a style they like, your comment brings absolutely nothing.\n \nreply"
    ],
    "link": "https://github.com/therealoliver/Deepdive-llama3-from-scratch",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Achieve the llama3 inference step-by-step, grasp the core concepts, master the process derivation, implement the code.\n      \n\n\n\n\n\n\n[ View in English | \u4e2d\u6587\u7248\u6587\u6863\u70b9\u8fd9\u91cc ]\nThis project is an enhanced version based on naklecha/llama3-from-scratch. It has been comprehensively improved and optimized on the basis of the original project, aiming to help everyone more easily understand and master the implementation principle and the detailed reasoning process of the Llama3 model. Thanks to the contributions of the original author :)\nStructural Optimization\nThe presentation sequence of the content has been rearranged, and the directory structure has been adjusted to make the learning process clearer and more reasonable, facilitating everyone to understand the code step by step.Code Annotations\nA large number of detailed code annotations have been a"
  },
  {
    "title": "Surface-Stable Fractal Dither on Playdate (aras-p.info)",
    "points": 5,
    "submitter": "atan2",
    "submit_time": "2025-02-18T03:04:19 1739847859",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://aras-p.info/blog/2025/02/09/Surface-Stable-Fractal-Dither-on-Playdate/",
    "first_paragraph": "Rune Skovbo Johansen has a really sweet Surface-Stable Fractal Dithering\ntechnique, where the dither dots \u201cstick\u201d to 3D surfaces, yet the dot density adapts to the view distance and zoom\nlevel.Some people have asked whether this would be a good technique for Playdate, given that the screen\nis one-bit color. And so I had to try it out! Here\u2019s a video: \n\n\n\nAnd here\u2019s the code: github.com/aras-p/playdate-dither3d.This is a long-arse post, so here\u2019s the sections:\n\n\nIs it practical?\nSurface-Stable Fractal Dithering\nPerspective correct texturing\nDisplaying brightness on a Playdate\n\u201cPorting\u201d Surface-Stable Fractal Noise to Playdate\nOptimizing Fractal Dithering\nScanline Rasterizers\nComparing Scanline Rasterizers to actual GPU\nBack to scanline rasterizer\nThat\u2019s it for now!\n\nMy impression: not really practical.Playdate hardware is like a PC from 1995 - no GPU at all, one fairly simple CPU\ncore. As such, it can do fairly simple 3D rendering (well, you need to write the whole rasterizer on the CPU"
  },
  {
    "title": "Every .gov Domain (flatgithub.com)",
    "points": 292,
    "submitter": "KoftaBob",
    "submit_time": "2025-02-21T09:59:23 1740131963",
    "num_comments": 235,
    "comments_url": "https://news.ycombinator.com/item?id=43125829",
    "comments": [
      "I was quite confused why the government would create an entire site telling people to stop consuming manga. I mean, I personally don't care for manga/anime stuff, but really?Turns out it's just a website for Quitman, GA. https://quitmanga.gov\n \nreply",
      "We know at least one New Hampshire politician really wasn't a fan.https://en.wikipedia.org/wiki/Nickolas_Levasseur\n \nreply",
      "This brought out an audible chuckle from me. Definitely stealing this and sharing this site with a few co-workers who are heavily into manga/anime. Thanks for the laugh.\n \nreply",
      "[dead]",
      "You really can't use sarcasm around that topic. There seems to be no limit to what their supporters will fall for.\n \nreply",
      "> You really can't use sarcasm around that topic.I have often wondered why that is.  Why is the sarcasm bit turned off for most conservatives?  Similarly their humor bit is quite off as well.  There aren't many successful conservative comedians either.\n \nreply",
      "I\u2019ve seen it\u2019s no different on either side with how willing they are to believe something horrendous about the other side (which interferes with interpreting a statement as sarcasm). For instance, you believe \u201cmost conservatives\u201d don\u2019t understand sarcasm, which is silly. Most people do, they just really want to believe the other \u201cteam\u201d is evil, stupid, and/or subhuman.Edit: added the words after \u201cevil.\u201d\n \nreply",
      "If only DNS could be namespaced..., eg quitman.ga.govOnly a marginal improvement though\n \nreply",
      "It is. As an example:https://sos.ga.gov/In practice, people get confused by that.\n \nreply",
      "Isn't delegating a zone pretty much the same concept in DNS? Or am I missing sarcasm here?\n \nreply"
    ],
    "link": "https://flatgithub.com/cisagov/dotgov-data/blob/main/?filename=current-full.csv&sha=7dc7d24fba91f571692112d92b6a8fbe7aecbba2",
    "first_paragraph": ""
  },
  {
    "title": "Docker limits unauthenticated pulls to 10/HR/IP from Docker Hub, from March 1 (docker.com)",
    "points": 349,
    "submitter": "todsacerdoti",
    "submit_time": "2025-02-21T07:42:45 1740123765",
    "num_comments": 384,
    "comments_url": "https://news.ycombinator.com/item?id=43125089",
    "comments": [
      "Can't believe the sense of entitlement in this thread. I guess people think bandwidth grows on trees.For residential usage, unless you're in an apartment tower where all your neighbors are software engineers and you're all behind a CGNAT, you can still do a pull here and there for learning and other hobbyist purposes, which for Docker is a marketing expense to encourage uptake in commercial settings.If you're in an office, you have an employer, and you're using the registry for commercial purposes, you should be paying to help keep your dependencies running. If you don't expect your power plant to give you electricity for free, why would you expect a commercial company to give you containers for free?\n \nreply",
      "Let me give you an alternative perspective.My startup pays Docker for their registry hosting services, for our private registry. However, some of our production machines are not set up to authenticate towards our account, because they are only running public containers.Because of this change, we now need to either make sure that every machine is authenticated, or take the risk of a production outage in case we do too many pulls at once.If we had instead simply mirrored everything into a registry at a big cloud provider, we would never have paid docker a cent for the privilege of having unplanned work foisted upon us.\n \nreply",
      "I get why this is annoying.However, if you are using docker's registry without authentication and you don't want to go through the effort of adding the credentials you already have, you are essentially relying on a free service for production already, which may be pulled any time without prior notice. You are already taking the risk of a production outage. Now it's just formalized that your limit is 10 pulls per IP per hour. I don't really get how this can shift your evaluation from using (and paying for) docker's registry to paying for your own registry. It seems orthogonal to the evaluation itself.\n \nreply",
      "The big problem is that the docker client makes it nearly impossible to audit a large deployment to make sure it\u2019s not accidentally talking to docker hub.This is by design, according to docker.I\u2019ve never encountered anyone at any of my employers that wanted to use docker hub for anything other than a one-time download of a base image like Ubuntu or Alpine.I\u2019ve also never seen a CD deployment that doesn\u2019t repeatedly accidentally pull in a docker hub dependency, and then occasionally have outages because of it.It\u2019s also a massive security hole.Fork it.\n \nreply",
      "It's trivial to audit a large deployment, you look at dns logs.\n \nreply",
      "This is Infamous Dropbox Comment https://news.ycombinator.com/item?id=9224 energy\n \nreply",
      "You don't have to run docker. Containerd is available.\n \nreply",
      "Block the DNS if you don\u2019t want dockerhub images. Rewrite it to your artifactory.This is really not complicated and your not entitled to unlimited anonymous usage of any service.\n \nreply",
      "That will most likely fail, since the daemon tries to connect to the registry with SSL and your registry will not have the same SSL certificate as Docker Hub. I don't know if a proxy could solve this.\n \nreply",
      "This is supported in the client/daemon. You configure your client to use a self-hosted registry mirror (e.g. docker.io/distribution or zot) with your own TLS cert (or insecure without if you must) as pull-through cache (that's your search key word). This way it works \"automagically\" with existing docker.io/ image references now being proxied and cached via your mirror.You would put this as a separate registry and storage from your actual self-hosted registry of explicitly pushed example.com/ images.It's an extremely common use-case and well-documented if you try to RTFM instead of just throwing your hands in the air before speculating and posting about how hard or impossible this supposedly is.You could fall back to DNS rewrite and front with your own trusted CA but I don't think that particular approach is generally advisable given how straightforward a pull-through cache is to set up and operate.\n \nreply"
    ],
    "link": "https://docs.docker.com/docker-hub/usage/",
    "first_paragraph": "\nNoteThe Docker Hub plan limits will take effect on March 1, 2025. No charges on\nDocker Hub pulls or storage will be incurred between December 10, 2024,\nand February 28, 2025.When using Docker Hub, unauthenticated and Docker Personal users are subject to\nstrict limits. In contrast, Docker Pro, Team, and Business users benefit from a\nconsumption-based model with a base amount of included usage. This included\nusage is not a hard limit; users can scale or upgrade their subscriptions to\nreceive additional usage or use on-demand usage.The following table provides an overview of the included usage and limits for each\nuser type, subject to fair use:For more details, see the following:When utilizing the Docker Platform, users should be aware that excessive data\ntransfer, pull rates, or data storage can lead to throttling, or additional\ncharges. To ensure fair resource usage and maintain service quality, we reserve\nthe right to impose restrictions or apply additional charges to accounts\nexhibit"
  },
  {
    "title": "I found a backdoor into my bed (trufflesecurity.com)",
    "points": 579,
    "submitter": "riverdroid",
    "submit_time": "2025-02-21T16:27:54 1740155274",
    "num_comments": 270,
    "comments_url": "https://news.ycombinator.com/item?id=43129439",
    "comments": [
      "> For someone who suffers from insomnia this seemed worth a shot.I can relate, having suffered the same for most of my life. One thing that really helped me was a simple white noise machine, typically used to help babies sleep. Good: I sleep great with it. Also, it's not connected to the internet and doesn't require an app. Bad: I basically can't sleep without it. I have to travel with it (camping!). I even purchased a backup in case the primary fails, which has happened.The other major sleep improvement was putting effort into accepting that life is pretty great; all of my worries that kept me awake at night were overblown. This took actual work, but it paid off.Anyway, just thought I'd pass that along, hoping it might help someone else that struggles with sleep.https://www.amazon.com/Yogasleep-Portable-Soothing-Rechargea...\n \nreply",
      "If you\u2019d rather not buy another gizmo for a function your phone has likely gobbled up already\u2026iOS, iPadOS, and macOS have a pretty great built-in background-noise generator these days. While lots of actual beaches can go dead silent and then have a loud wave crash in, the waves thatIt\u2019s available in Settings -> Accessibility -> Audio & Visual -> Background Sounds. You\u2019ll have to download the sounds each once, but after that they stay on your device.Digging this deeply in Settings isn\u2019t pleasant if you just want some white noise, so you may want to add a control to Control Center like \u201cBackground Sounds\u201d (way down in the Hearing Accessibility section) to turn the ocean noise on and off.I turn this on my iPad when going to bed if I want to take extra steps to ensure that I don\u2019t wake up in the middle of the night.\n \nreply",
      ":facepalm:I can't believe I had to download an app for that because the feature is buried in SETTINGS (!!!!).   What an obtuse choice.   Thanks for the tip though, I hate that my white noise app has a rotating ad banner.\n \nreply",
      "just tried it, that's cool, but in what circumstances \"should\" i use it?\n \nreply",
      "For the price of a white noise machine you can buy a 10A squirrel cage blower, some mdf to make a box out of, a contactor, and a smart plug and have a white noise machine that filters your air, turns on and off from your phone, and also makes white noise. It can also act as a table to put your phone on and a charge point.I had the two problems of poor sleep without white noise and a dog allergy and now I have neither.\n \nreply",
      "I had insomnia for over a decade and all it took to fix that was just weeks of sleep inducer followed by regular melatoin takes. I assumed it will take some gizmos to do that, but apparently it wasn't. Once you could lock your sleep into the daily pattern---something I could never done by myself for a very long time though, hence sleep inducer---then securing it turns out to be much simpler. Consult your psychiatrist first, of course.\n \nreply",
      "I also need white noise to sleep.At home I have a simple one that plugs in and generates noise with fan. Looks almost exactly like this: https://res.cloudinary.com/guest-supply/image/upload/f_auto,...When I travel I take this small portable rechargeable one: https://www.amazon.com/Machine-Babelio-Adults-Non-looping-So...I'm on android so I don't have the built in sounds that iOS has\n \nreply",
      "I just use 3m ear classic 33 NRR earplugs.  they're the best.\n \nreply",
      "Have you tried taking magnesium before bed time?\n \nreply",
      "I approached this the brutish way: I downloaded hours of white noise as a sound file (mp3) and just use VLC to play it. Any smartphone - no internet.I used wireless headphones back then. My choice of \"white noise\" was popcorn in a microwave (because the neighborhood was that noisy)\n \nreply"
    ],
    "link": "https://trufflesecurity.com/blog/removing-jeff-bezos-from-my-bed",
    "first_paragraph": ""
  },
  {
    "title": "Some critical issues with the SWE-bench dataset (arxiv.org)",
    "points": 296,
    "submitter": "joshwa",
    "submit_time": "2025-02-21T17:59:48 1740160788",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=43130732",
    "comments": [
      "Some of the examples in the paper seem to be wrong.For django-31056, they claim the AI-generated patch is \"incomplete\" because it's \"missing critical parts of this logic, such as the try-except block and the check for a running event loop.\".  But if you look at the diff, that's clearly wrong.  The try-except block and running check were already there before the patch.  The human patch just indented them, making them appear as both - and +, while the AI patch didn't.  To me, the AI patch seems correct.  It's slightly less efficient than the human patch when DJANGO_ALLOW_ASYNC_UNSAFE is set, but slightly more efficient when it isn't (which is the common case!).  The human patch does feel more natural, but the AI patch is fine.  I'd grade it a tie between human and AI.For django-32517, they claim that the human and AI patches \"produce entirely different outputs\", but actually they do exactly the same thing.  The human version has `reversed(self.dict)`, while the AI version has `reversed(self.dict.keys())`.  `reversed` treats the object as an iterator, and iterating over a dictionary in Python just gives you the keys, so it doesn't matter whether you call `.keys()` first.  The human patch is more idiomatic, but it's also more confusing, as shown by the fact that it confused the authors of this paper.  I'd grade it another tie.Edit: I tried to sign up for OpenReview so I could leave a comment about this, but the system wouldn't let me register without completing a form that assumes you have an academic position.  Perhaps I should email the authors.\n \nreply",
      "The entire premise of this paper is false. They claim that the \"hints_text\" is used and leaks the answer in Section 2.1.1; however, the authors of SWE-Bench themselves state that this is not used anywhere (Issue #133 on the official SWE-Bench GitHub).According to the paper:> 1. Solution leak: represents instances where the solution to the issue is clearly outlined in the issue\ndescription or comments on GitHub. Since both the issue descriptions and comments (referred to\nas hints_text in the SWE-Bench study) are provided as input to the models, these LLM models can\nextract the solutions directly from this information instead of generating it independently.And yet, the SWE-Bench authors themselves explicitly state:> In short, for participating on the SWE-bench leaderboard, using hints_text in any manner is not allowed. Although we don't explicitly say this in the original paper, we also do not make any mention of using the hints_text anywhere.So, it's a made up issue that would only occur if you deviated from the paper implementation and explicitly added a field called \"hints\" that isn't used anywhere.\n \nreply",
      "I think you should. Looks like there is more work to do\n \nreply",
      "> When we filtered out these problematic issues, the resolution rate of SWE-Agent+GPT-4 dropped from 12.47% to 3.97%.This matches my intuition about the coding performance of these models a lot better. I don't think any current coding benchmark accurately measures coding performance.\n \nreply",
      "Anecdotal but I was always shocked to see Claude 3.5 perform so poorly in the benchmarks, when it generates 80% of my code in Cursor (and in cases it fails, no other model succeeds)\n \nreply",
      "Different people seem to get wildly different results here, and I'm not sure what percentage is down to the type of software being built vs the usage patterns.In my case, I would guess less than 10% of the code I get out of AIs is useful.What sort of code are you getting those results with? Is it yet-another-react-frontend-button? Is it ebpf programs? Is it a parser in rust?For the latter two, I've found AI to have pretty low rates, and for the former I haven't had the desire to try.\n \nreply",
      "Almost every time someone says \"but most of my code nowadays is LLM generated\" it's usually one of three things:1. Very greenfield work where the LLM doesn't really have a lot of constraints to deal with and can fully control the setup + doesn't have to ingest a lot of existing context\n2. Very small projects that largely follow established patterns (CRUD, frontends, etc.)\n3. Well established implementation work (the kind of feature that's a simple JIRA ticket).In my experience they're painfully bad at:- Novel/niche work where there aren't really answers online to what you're trying to do\n- Complex refactoring\n- Architecting within existing constraints (other systems, etc.)\n \nreply",
      "I think they are counting the autocomplete as well.\nYeah when I write golang, and write:\nresult, err := foo(thing)it's gonna autocomplete:\nif err != nil {\n   return fmt.Errorf(\"%w: could not foo: %v\", err, thing)\n}\n \nreply",
      "I assume it's the commoditized work that made India a success at outsourced activities.\n \nreply",
      "I suspect it's a lot of that too. Essentially pattern matching.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2410.06992",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Johnny.Decimal \u2013 A system to organise your life (johnnydecimal.com)",
    "points": 282,
    "submitter": "debone",
    "submit_time": "2025-02-21T14:52:14 1740149534",
    "num_comments": 173,
    "comments_url": "https://news.ycombinator.com/item?id=43128093",
    "comments": [
      "Just a general observation as someone nearing 50. I'm honestly very curious to see if someone has had a different experience than me. I'm am, to put it mildly, not an \"organized person\". I have tried a million different systems throughout my life - GTD, Inbox Zero, spreadsheets, etc. etc.To be honest, I don't believe that any of these \"organization systems\" really help people that have problems being organized in the first place. I think it's just a fundamentally different way of how I'm wired. My general conclusion is that trying to \"fight\" my natural way of doing things is always going to be a losing battle, and that instead I just need to figure out ways to handle my general messiness and get it to work for me. I mean, I can certainly be organized for sizable stretches of time, but whenever I start getting pressed for time, or stressed, or lose my motivation for some other reason, it always reverts to the mean.I'd honestly be really interested to hear if anyone has ever changed from being a \"unorganized person\" to an \"organized person\", because it my few decades of life I've never seen it be successfully accomplished.\n \nreply",
      "I'm in my mid-40s and have severe ADHD and I've tried many many techniques and systems over the years. Over the last ~15 years I've come to evolve a set of systems that work for me.I'm starting (in my \"ample free time\") to document them and in a series blog posts help people find systems that will work for them. My experience is that the best systems are the ones that have five characteristics:1. They're simpleNo complex patterns, no \"we'll solve everything\"2. They require little or no task switching in the middleThis breaks my ADHD concentration.3. They're forgiving if you fall off the wagonYou will always have bad days and need to restart. The system must make it easy.4. The system must be very general, maybe even \"too simple\" but easy to customize.There is a natural desire, especially in ADHD people, to over complicate, so the system must allow you to be as simple as possible, but then let you customize later.5. They don't require any specialized tool (especially not an online tool). No system should be invariably tied to a specific piece of software or hardware. These may be excellent augmentations, but they should never be requirements.Am I an \"organized\" person? No, but I'm far better organized than I was. Tasks rarely get missed now. I'm far more productive than I was (and I have stats to back up my assertion). I can almost always retrieve documents I need relatively quickly.These systems won't change who you are, but they will assist you in being better at being who you are.\n \nreply",
      "Your principles mirror my own, which have been developed and refined over the last ten years (I'm 34 now). There have been periods of overcomplicating things, but they've mostly reached a natural state that works for me.Maybe interesting is the evolution of my system:\u2022 2015 and prior: Sticky notes, calendars, notebooks, sheets of paper, chaos\u2022 2016-2019: I found the bullet journal method and implemented the most basic form found here: https://bulletjournal.com/blogs/faq (collections, future log, monthly log, daily log) and never really evolved from that utilitarian mode.\u2022 2019-2025: I signed up for Notion and ported my bullet journal system there. I miss the physical version, but prefer the easy access and easy editing in the online version. In addition to Notion, I heavily use Google Calendar, and also Google Keep as a quicker-access and catch-all of smaller notes. I use Notion for life admin and Obsidian for work notes and files.OP's Johnny.Decimal system caught my attention since I've been interested in a consistent and proven way to organize the files on my laptop, SSDs, Drive, as well as all my physical docs. I could also see it being a nice way to organize my Notion and Obsidian, but I also tend to rely on search and backlinking as others have commented about for their own systems.\n \nreply",
      "I think these systems like Obsidian are great for notes.PARA also (and for me primarily) helps with things like documents I get from other places which I then scan in.Yes, I could probably use a specialized program for this, but this way it's all just files.\n \nreply",
      "> They're forgiving if you fall off the wagonSome (not all) of my personal systems are unforgiving in this regard.Thank you for pointing out this \"Best Practice\" explicitly!\n \nreply",
      "I just wrote a sibling comment echoing essentially the same philosophy, although you've elucidated the principles in more detail. As I wrote, my system is basically use a paper filing system (don't overthink it, just alphabetically ordered, labeled manila files), Google Calendar, Google Drive, and Obsidian on my phone for miscellaneous note-taking.I'm eager to learn more about your systems. Where's your blog?\n \nreply",
      "My blog is at https://blog.emacsen.net but I haven't written much.The problem I have is that writing the why is harder than the what.For example, I use a modified Cycle System, but some of my modifications are around how many tasks I do a day, and how I categorize which tasks I do.As an example, understanding task limits and why you should use them is important. As I write out my thoughts about them, it feels boring.Then I put the blog down and don't pick it up again. Maybe I should do it anyway.\n \nreply",
      "I implemented Johnny Decimal about 5 years ago in Google Drive.  The cool thing about it is it's just always there.  It's pretty much set and forget it.I'll forget about it (because ADHD?) and when I open up drive, there it is!  :). And I'll use it.It's a small investment upfront.\n \nreply",
      "May I ask your blog URL ? Or add it in your profile :)\n \nreply",
      "https://news.ycombinator.com/item?id=43134892https://blog.emacsen.net\n \nreply"
    ],
    "link": "https://johnnydecimal.com",
    "first_paragraph": "Johnny.Decimal is designed to help you find things quickly, with more confidence, and less stress.You assign a unique ID to everything in your life.These IDs help you stay organised. They impose constraints that make it harder to get lost. And you create your own index to link everything in your life together.The system is free to use and the concepts are the same at home, work, or that club you manage.In real life, if you stored your stuff in piles of badly-labelled boxes you'd never find anything again.If you put those boxes in boxes, in boxes, you'd never know which box to open to find the next box. It would be chaos. But this is how you save your computer files.Here's one way to think about how a Johnny.Decimal system works. In this simple analogy, an area is a shelf, a category is a box, and an ID is a manila folder.Imagine a computer is a garage. We can't put everything on the floor, so we buy ten shelves. Then we dedicate each one to an area of our life -- life admin, home busin"
  },
  {
    "title": "Neo Gamma (Home Humanoid) (1x.tech)",
    "points": 31,
    "submitter": "onnnon",
    "submit_time": "2025-02-21T20:02:34 1740168154",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43132260",
    "comments": [
      "Do we have any sense that this is actually real and not a carefully crafted made up demo?\n \nreply",
      "It's teleop, they are pretty open about it. It's not autonomous.They do have an RL controller running for the legs, but it's just an intermediate controller and it probably get high level commands from a teleoperator. The upper body is purely teleop.\n \nreply",
      "So you're paying someone to operate your robot on top of the cost of the robot?I'm very skeptical, even if this technology worked flawlessly, that this would scale towards a profitable business.  I understand that not every robot would require 24x7 human assistance, but still - this is a very strange business model.Robotics has always been in competition with minimum wage labor.  How long could you hire a maid before making a return on the cost of the robot?  And that's assuming the robot isn't worse, which it is pretty much guaranteed to be.\n \nreply",
      "When you scroll down one pane (to the \"Home Humanoid\" section) you get a nice jumpscare of that thing's... face, ish.I would not enjoy waking up in the middle of the night for a glass of water and finding that thing staring at the foot of my bed.\n \nreply",
      "Yeah, I have to admit it looks kind of \"uncanny\", but at the same time it kind of has a sense of personality to it that other humanoid robots lack, in part because it has face with two distinct eyes.The knit \"suit\" is also kind of a nice touch.  Can't help but think that a robot wearing a sweater is kind of endearing.\n \nreply",
      "It's really telling how we're shaping our artificial helpers to not have a mouth, but eyes are alright. As if they're allowed to receive input but they should not bother us with any output!For me an ideal artificial helper would be something I could have in the house and talk back and forth with while it works or have it as part of the dinner conversation. Think Bicentennial Man. Now that's what I want.\n \nreply",
      "Having the physical attributes of a mouth would be analogous to having eyelids, which is also a feature they currently don\u2019t have. They are very likely to have speakers and mics embedded somewhere in the body. Possibly in the face itself.\n \nreply",
      "But what would the teeth and the tongue be made out of?\n \nreply",
      "The hardware is maybe 4% of robotics. 96% is the AI behind it.\n \nreply",
      "This made me think.. I suspect someday AI will be able to just drop into a piece of commodity hardware and sort itself out and even compensate for shitty hardware a bit.For instance, if it can't control a hand properly, it'll just run evolutionary algorithm on it for a while, compile the result and upload it into the hand controller and be off in about 4-5s.\n \nreply"
    ],
    "link": "https://www.1x.tech/neo",
    "first_paragraph": "Your personal assistant and companionNEO\u2019s Knit Suit is soft to the touch and flexible for dynamic movements.Hands are the key to the world around us. NEO\u2019s hands are built to handle important jobs around your home.Tendon driven motion unlocks safe interactions with soft and quiet movements.Opt in to receive updates. Unsubscribe anytime."
  }
]