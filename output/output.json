[
  {
    "title": "OpenCoder: Open Cookbook for Top-Tier Code Large Language Models (opencoder-llm.github.io)",
    "points": 262,
    "submitter": "pil0u",
    "submit_time": "2024-11-09T17:27:30 1731173250",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=42095580",
    "comments": [
      "> Unlike most prior efforts, we release not only model weights and inference code, but also the reproducible training data, complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols for open scientific research.Regardless of the specific performance of this model versus another model, I think it\u2019s good to keep in mind that everyone benefits from this kind of work\n \nreply",
      "Tested , so much hallucination , cannot hold a candle against Qwen 2.5 or even General Purpose model Mistral-Nemo.\n \nreply",
      "To be fair, nothing comes close to Qwen2.5 atm\n \nreply",
      "This is something that's obvious to anyone playing with local LLMs but that doesn't seem to be that much well-known even among tech enthusiast.Qwen is really ahead of the pack right now when it comes to weight-available models.\n \nreply",
      "which size are you using?I don't see why you would use it over claude and 4o-mini with cursor unless you are working on a top secret repo\n \nreply",
      "> I don't see why you would use it over claude and 4o-mini with cursor unless you are working on a top secret repoPlenty of companies won't let you use those products with our internal code.\n \nreply",
      "the company i work for and actually most Swiss IT contractors have harsh rules, and more than half of our projects, we aren't allowed to use Github Copilot or pasting stuff to any LLM API.For that matter I built a vLLM based local GPU machine for our dev squads as a trial. Currently using a 4070Ti Super with 16GB Vram and upgrading to 4x 4070Ti Super to support 70b models.The difficulties we face IMHO:- Cursor doesn't support WSL Devcontainers- Small Tab-Complete models are more important, and there's less going on for those- There's a huge gap between 7-14b and 120b models, not a lot of 70b models availableIn reality, on 7-14b nothing beats Qwen2.5 for interactive coding and something around 2b for tab-completion\n \nreply",
      "How does it compare to Claude?\n \nreply",
      "nothing compares to claude, not even gpt-4.\n \nreply",
      "Not even deepseek coder 2.5?\n \nreply"
    ],
    "link": "https://opencoder-llm.github.io/",
    "first_paragraph": "\n              OpenCoder is an open and reproducible code LLM family which matches the performance of Top-Tier Code LLM.\n              We provide not just the final models, but also the reproducible training data,\n              the complete data processing pipeline,\n              rigorous experimental ablation results, and\n              detailed training protocols for open scientific research.\n            \n\n\nOpenCoder is an open and reproducible code LLM family which includes 1.5B and 8B base and chat models, supporting both English and Chinese languages. Starting from scratch, OpenCoder is trained on 2.5 trillion tokens composed of 90% raw code and 10% code-related web data, reaching the performance of top-tier code LLMs. We provide not only model weights and inference code, but also the reproducible training data, the complete data processing pipeline, rigorous experimental ablation results, and detailed training protocols. Empowering researchers to build and innovate, OpenCoder is y"
  },
  {
    "title": "Show HN: Visprex \u2013 Open-source, in-browser data visualisation tool for CSV files (visprex.com)",
    "points": 61,
    "submitter": "kengoa",
    "submit_time": "2024-11-09T20:54:11 1731185651",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42096837",
    "comments": [
      "Nice work!Do you have any plans for data cleaning?I am working on a somewhat similar open source project.  I intend to add heuristic data cleaning.  With the UI I want to be able to toggle between different strategies quickly - strip characters from a column to treat it as numeric, if less than 2% or 5% of values have a character, fill na with mean, interpret dates in different formats - drop if the date doesn't parse.  The idea bing that if it's really quick to change between different strategies, you can create more opinionated strategies to get to the right answer faster.Happy to collaborate and talk tables with anyone who's interested.\n \nreply",
      "not quite what you're describing, but I open-sourced a fuzzy deduplication tool last week: https://dedupe.it\nWould be interested in expanding it to deal with data cleaning more broadly\n \nreply",
      "I loaded a CSV with one date/time column and one numerical column.  I then selected \u201cScatter Plot\u201d, but got the message \u201cNot enough numerical columns found. Load a CSV file with at least 2 numerical columns in the Datasets tab.\u201d  I would have thought that a date/time column would count?\n \nreply",
      "Thanks for trying it out! This is unfortunately not possible as of now and is one of th high-priority tasks to parse timestamps and datetimes, which is now incorrectly parsed as a string (Categorical). I'm using Papa Parse to load CSV data and I will likely need to add a custom parser on top of it.Some of those plans are mentioned in my blog post reflecting on building this app:\nhttps://kengoa.github.io/software/2024/11/03/small-software....\n \nreply",
      "You might also want to support a Unix timestamp as input, i.e. an integer or decimal number of (mili|micro|nano-)seconds since the Unix epoch. No need to worry about messy date parsing there.\n \nreply",
      "Maybe use dayjs to handle all kinds of wired string dates.\n \nreply",
      "Very cool stuff!Maybe bar / beeswarm charts would be useful?I was missing the possibility to show differences by category, eg mpg by make in the cars dataset.\n \nreply",
      "I haven't considered beeswarm charts for this before, I will add those to a list of upcoming features. Thanks for the feedback :)\n \nreply"
    ],
    "link": "https://docs.visprex.com/",
    "first_paragraph": "Visprex is a lightweight data visualisation tool that helps you speed up your statistical modelling and analytics workflows. The main high-level features include:Visprex is suitable for students who are starting out in their statistical modelling training.There's no need for starting your computing environment on your machine or writing tedious visualisation scripts.Visprex is also for data analysts who would like to quickly inspect tabular data for analytical purposes, without worrying about privacy or PII as no data leaves your browser.You can start visualising your data with just a few clicks by first loading your dataset."
  },
  {
    "title": "IronCalc \u2013 Open-Source Spreadsheet Engine (ironcalc.com)",
    "points": 207,
    "submitter": "kaathewise",
    "submit_time": "2024-11-09T16:36:19 1731170179",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=42095292",
    "comments": [
      "Congratulations, this is awesome. One of those \"why hasn't someone done this already?\" projects.I can see this becoming transformative and superseding Excel, which is a bold claim to make. But this is compliant (with Excel), performant, extensible, free, and in-browser. This could easily become almost an emacs-level editor.Think of the interfaces that could be built to this in this?I'll be sharing this with every student I know.And the name is a winner.\n \nreply",
      "Hey! This is my project!\nAmazed to see this here.\nI'll try to answer questions people might have\n \nreply",
      "Where were you when I started writing my code ;_; I have also written a spreadsheet engine in Rust from scratch, for an app built with the iced GUI library!I'll take a deep dive through your repo and compare notes later this week. Congrats on the huge lift!!\n \nreply",
      "Thanks you very much! Lets continue talking on Discord in the coming days!\n \nreply",
      "Great project.  I particularly love the:1) mit license\n2) using plausible instead of Google analytics.  Practically speaking, uBO is going to block both by default, but for non-tech users this is great.\n3) appreciate how the app respects your pc when the web app is running in the background.  Very low footprint, no random CPU spikes or anything.Wish you guys the best.\n \nreply",
      "If you are curious, I just made the analytics public:https://plausible.io/ironcalc.comI think more than one folk in HN might be interested. All traffic is because of this post. I had no visitors as of today. This was work in progress :)\n \nreply",
      "Sweet, it's basically data on HN users then.Only 13.4% of HN readers use Firefox. For shame. But seriously, it's interesting that safari is top by quite a margin.\n \nreply",
      "I assume that's mostly iphones?\n \nreply",
      "* HN users who don\u2019t block analytics\n \nreply",
      "Thanks :).WRT: Plausible. I think I will remove all kinds of analytics, I'm not yet convinced I should be using them at all. That being said I had been longing to try Plausible for the a long time and this seemed like a good opportunity.\n \nreply"
    ],
    "link": "https://www.ironcalc.com/",
    "first_paragraph": "Try nowYou can integrate it into your projects, customize it to your needs, and share it openly without any restrictions.You shouldn\u2019t worry that this or that function is not supported.We at IronCalc are in awe of the software created by Microsoft over the years. We want every one to be able to use their spreadsheets.Modern programming practices should be used covering with tests any feature of the system.The programs shouldn\u2019t be heavier than a few hundred kilobytes.Language should no be a barrier to use a spreadsheet.It should be nice and friendly to use. Designed with love from the ground up.\n              For over 40 years, spreadsheets have been integral to countless applications. Despite numerous proprietary and open-source options, finding a universally accessible, reliable, and high-quality engine remains a challenge. Many existing solutions are expensive, require accounts, or suffer from performance and stability issues.\n            \nOur Mission: To fill the gaps left by the i"
  },
  {
    "title": "Show HN: Jaws \u2013 a JavaScript to WASM ahead-of-time compiler (github.com/drogus)",
    "points": 139,
    "submitter": "drogus",
    "submit_time": "2024-11-09T18:14:30 1731176070",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=42095879",
    "comments": [
      "Really clever use of the new WASM GC proposal. All the JS -> WASM compilers so far have basically just been shipping a whole JS engine - this is the first one I've seen that actually tries to map JS constructs directly to WASM primitives.\n \nreply",
      "I think both Porffor https://porffor.dev/ and Static Hermes https://hermesengine.dev/ also take a compilation approach. Would be interesting to see how Jaws compares.\n \nreply",
      "Thanks! Although, to be fair, it's a clever use mostly cause I'm too dumb to write the full interpreter on top of WASM lol\n \nreply",
      "Back in the day I did an almost-Typescript (though much closer than assembly script) to embedded ARM compiler. Some of the techniques may be useful.https://www.microsoft.com/en-us/research/uploads/prod/2019/0...\n \nreply",
      "Nice! I'll definitely take a look!\n \nreply",
      "> As much as I love writing Rust, I also know it's not a widely popular languageIs this true? Rust is hyped like crazy and seems to be used everywhere these days.\n \nreply",
      "Hyped and visible on socials doesn't necessarily mean it's widely used, but I guess it also depends on how you define widely. According to most stats I've seen Rust usage is maybe about 5-10% of languages like JavaScript and Python when you look at StackOverflow, indexes like PyPl, or GitHub statistics.\n \nreply",
      "Which puts it already in the second tier of most used languages with big guys like Java, C#. I think Rust will soon join the ranks of JavaScript, Python and C.\n \nreply",
      "Yet to find any non-crypto related jobs in it. And in my country, Estonia, zero local jobs (as per local job boards that people use). I would say it's definitely not popular in any sense that actually matters.\n \nreply",
      "I really like this approach. Building for WASM directly, rather than trying to also directly generate binaries, means you can rely on WASM GC and the async support that (I think?) is supposed to be part of WASI 0.3.\n \nreply"
    ],
    "link": "https://github.com/drogus/jaws",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        JavaScript to WASM compiler\n      Jaws is a JavaScript to WebAssembly compiler written in Rust. It is similar to porffor in a way it also results in a standalone WASM binary that can be executed without an interpreter, but it takes a different implementation approach.It's an experimental tool and it's not ready for production. A lot of the language\nfeatures and builtin types are missing or incomplete. That said, my goal is to eventually support 100% of the language.I started this project while working on a stress testing tool called Crows that runs WebAssembly scenarios. At the moment it only supports code compiled from Rust to WASM. As much as I love writing Rust, I also know it's not a widely popular language and besides, small tests are often easier to write in interpreted languages. The problem is, running scripting languages on"
  },
  {
    "title": "Zig's (.{}){} Syntax (openmymind.net)",
    "points": 107,
    "submitter": "todsacerdoti",
    "submit_time": "2024-11-05T12:23:08 1730809388",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=42050954",
    "comments": [
      "As people have pointed already elsewhere, the same declaration can be made more clear by isolating the type like so:    var gpa: std.mem.GeneralPurposeAllocator(.{}) = .{};\n \nreply",
      "After you've been writing zig for a while, seeing `.{}` in an argument list intuitively means \"default arguments\".\n \nreply",
      "i have never used zig before, but after reading the article i came to the same conclusion. the \"problem\" (if it is a problem at all, that is) really is that .{} is the syntax for a struct whose type is to be figured out by the compiler, that new users will be unfamiliar with.i don't know if there are other uses for . and {} that would make this hard to read. if there are, then maybe that's an issue, but otherwise, i don't see that as a problem. it's something to learn.ideally, each syntax element has only one obvious use. that's not always possible, but as long as the right meaning can easily be inferred from the context, then that's good enough for most cases.\n \nreply",
      "Seems like it could just be elided entirely. Why can't it be?\n \nreply",
      "I do not know Zig, but it looks like it just means \"call default constructor for parameter/variable/type\". I do not see how you could expect it to be elided unless every function auto-constructs any elided arguments or always has default arguments.In other words, for a function f(x : T), f(.{}) is f(T()), not f(), where T() is the default constructor for type T.If we had a function with two parameters g(x : T, y : T2) it would be g(.{}, .{}) which means g(T(), T2()), not g().It looks like the feature exists to avoid things like:x : really_long_type = really_long_type(), which can be replaced with x : T = .{} to avoid unnecessary duplication.\n \nreply",
      "I do not know Zig either; I had assumed that it has default parameters, but it seems that it does not[0]. So, yes, it makes sense now why it cannot be elided.They should add default parameters to avoid this sort of thing. Maybe they ought to consider named/labelled parameters, too, if they're so concerned about clarity.0: https://github.com/ziglang/zig/issues/484\n \nreply",
      "Declaring a variable doesn't initialize it in Zig, so maybe the correct semantics in ellisions would be to allocate an unitialized argument.\n \nreply",
      "For the same reason you can't pass a Python function expecting a list an empty list with foo(), you have to use foo([]). They mean different things.\n \nreply",
      "However, in Python, if you routinely call foo([]), you'd specify that (or rather an empty tuple since it's immutable) as the default value for that argument.\n \nreply",
      "I believe that if most foo's users should just call it with [], the Pythonic way is to make the argument optional.\n \nreply"
    ],
    "link": "https://www.openmymind.net/Zigs-weird-syntax/",
    "first_paragraph": "One of the first pieces of Zig code that you're likely to see, and write, is this beginner-unfriendly line:While we can reason that we're creating an allocator, the (.{}){} syntax can seem a bit much. This is a combination of three separate language features: generics, anonymous struct literals and default field values.One of Zig's more compelling feature is its advance compile-time (aka comptime) capabilities. This is the ability to have a subset of Zig run at compile-time. Comptime can be used for a number of different things, but the most immediately useful is to implement generic type. To create a generic type, we write a a function which returns a type. For example, if we wanted to create a linked list node, we'd do:You could optionally (and more explicitly) specify that T is a comptime parameter:But this is redundant, because, in Zig, types always have to be known at compile time. Now consider these two equivalent ways to create a Node(T):Thinking of Node(i32) as a type can take "
  },
  {
    "title": "NYC Subway Station Layouts (projectsubwaynyc.com)",
    "points": 95,
    "submitter": "gregsadetsky",
    "submit_time": "2024-11-09T20:35:04 1731184504",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=42096717",
    "comments": [
      "One time I got onto the Q platform from Centre Street by habit before realizing I was supposed to take the 6.Felt like I somehow broke space and time getting there, and this Escher staircase in Canal Street station confirms it: https://images.squarespace-cdn.com/content/v1/55ababf2e4b064...\n \nreply",
      "Why are the stations not labeled? I'm sure this is fine for people who live there and use the subway on a regular basis, but it would be of little help to someone visiting or who just relocated. Even someone visiting a friend in an area they aren't familiar with would be at a disadvantage figuring out which layout to use.Edit: that said, very cool.\n \nreply",
      "It's just for fun. There are apps which help you figure out which car to board (where to stand on the platform) based off your transfers & destinations\n \nreply",
      "It's an art project, not a practical tool.\n \nreply",
      "I asked a while back to a NYC city planner the reason they didn't publish station MTA station layouts / exits on gmaps , like you see for example for toyko in gmapsI was told this was not opened publicly because of terrorist concerns. But if you wanted to get MTA station layouts, it was certainly possible to get them from the city.I guess we have flipped that page!\n \nreply",
      "> because of terrorist concerns.The New York bureaucracies favorite excuse for not doing work they are responsible for.\n \nreply",
      "Not sure why this is downvoted?  Do people not remember how for ~20yr \"terrorism\" was habitually used as a justification for \"because we don't want to\" by every government organization from the MTA to small town parks departments.\n \nreply",
      "I was going to say! \"Because Terrorism\" has been the catch-all vague excuse for limiting access to everything, for decades.\n \nreply",
      "The truly hilarious thing is that the Tokyo subway system actually suffered a terrorist attack in 95, and still they publish the locations of all 200+ exits from Shinjuku station.\n \nreply",
      "Truly ridiculous to think that a terrorism group is filled with incapable individuals so as to not be able to map out a well traveled and popular location.Stop pretending terrorists are stupid, quite often they're smarter than you, and seeing this as an excuse tells me that bar is not difficult to pass.\n \nreply"
    ],
    "link": "http://www.projectsubwaynyc.com/gallery",
    "first_paragraph": "  Inspired and want to support this project? Consider tipping me on the  Contact/Tip page!\n    \nPowered by Squarespace"
  },
  {
    "title": "Early Cascade Injection: From Windows process creation to stealthy injection (outflank.nl)",
    "points": 82,
    "submitter": "wsintra2022",
    "submit_time": "2024-11-09T17:55:29 1731174929",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=42095752",
    "comments": [
      "Great! We have been working on Windows Process (and COM) injection since 2003 [1][2][3]. I need to talk with the current development team about reviewing it with the EDR-Preloading technique. We have a driver also that suspends a new process before hooking it, we also hook existing processes.Business-wise our work on this went down once Microsoft Detours was made FOSS even when our products has other capabilities. A good old thread is here [4].[1] https://github.com/nektra/Deviare2[2] https://github.com/nektra/Deviare-InProc[3] https://github.com/nektra/RemoteBridge[4] https://www.reddit.com/r/programming/comments/22crn0/gpl_alt...\n \nreply",
      "Not all overriding and detouring is malicious.  For instance, Steam detours Direct3D every time you launch a game in order to set up the steam overlay.\n \nreply",
      "Windows offers \"legal\" ways of DLL injection, which is presumably what Steam does, and this article isn't about those methods.\n \nreply",
      "As far as I know Steam doesn't do anything special like that and they are whitelisted by anti-cheat. Same goes for Discord's Direct3D hooks. These are often used for drawing on screen by hacks.\n \nreply",
      "This is a great writeup, thanks for posting it. The post mentions Early Bird APC is a fairly recent development, around 2018, but process injection has been around for a long time. Is there any theoretical work being done towards locking down processes against injection in more robust ways than simply making sure there is no temporal chance to inject a malicious code? I\u2019m thinking something along the lines of CFI, but for processes instead of subroutines, would be useful if it could be made to work.\n \nreply",
      "The whole reason this complicated method was researched is exactly because the traditional injection routes are locked down/easily monitored.In a previous life where I had to find a way to stealthily inject Chrome (in the presence of good anti-viruses), the solution was to find an obscure type of Windows shell extension which if registered would automatically be loaded by Windows into Chrome without triggering an alert.\n \nreply",
      "I'm surprised the call to WriteProcessMemory or creating suspended processes isn't being picked up, it usually gets you a lot of points on the \"Detect binary as malware heuristic\" detector\n \nreply",
      "I suspect this is where Windows backwards compatibility bites them a bit.  I've got a very old tool [1] that uses WriteProcessMemory and CreateRemoteThread to create a thread in the command process that launched it to remotely change the directory in that process.It works to this day, despite looking exactly like what malware would do.  My tool is nothing in the grand scheme, but I suspect I'm not the only one doing these sort of shenanigans, and no doubt some big important app is doing it and can't be bothered to fix itself, so MS is stuck supporting it.[1] https://github.com/seligman/ccd\n \nreply",
      "If the Windows API provides those functions in the first point, I guess there are good reasons to use them. Of course if you're watching out for malware, WriteProcessMemory looks very suspicious, but it's not enough to conclude you're in presence of malware.\n \nreply"
    ],
    "link": "https://www.outflank.nl/blog/2024/10/15/introducing-early-cascade-injection-from-windows-process-creation-to-stealthy-injection/",
    "first_paragraph": ""
  },
  {
    "title": "Mergiraf: a syntax-aware merge driver for Git (mergiraf.org)",
    "points": 316,
    "submitter": "p4bl0",
    "submit_time": "2024-11-09T11:06:10 1731150370",
    "num_comments": 69,
    "comments_url": "https://news.ycombinator.com/item?id=42093756",
    "comments": [
      "Looking at the architecture, they will probably run into some issues. We are doing something similar with SemanticDiff [1] and also started out using tree-sitter grammars for parsing and GumTree for matching. Both choices turned out to be problematic.Tree sitter grammars are primarily written to support syntax highlighting and often use a best effort approach to parsing. This is perfectly fine for syntax highlighting, since the worst that can happen is that a few characters are highlighted incorrectly. However, when diffing or modifying code you really want the code to be parsed according to the upstream grammar, not something that mostly resembles it. We are currently in the process of moving away from tree-sitter and instead using the parsers provided by the languages themselves where possible.GumTree is good at returning a result quickly, but there are quite a few cases where it always returned bad matches for us, no matter how many follow-up papers with improvements we tried to implement. In the end we switched over to a dijkstra based approach that tries to minimize the cost of the mapping, which is more computationally expensive but gives much better results. Difftastic uses a similar approach as well.[1]: https://semanticdiff.com/\n \nreply",
      "Thanks for the insightful comments! You surely have a lot more experience than me there, but my impression was that producing visual diffs and merging files are tasks that put different requirements on the tree matching algorithms, and Dijkstra-style approaches felt more fitting for diffs than for merging, so that's why I went for GumTree as it seemed to be the state of the art for merging. Does SemanticDiff offer a merge driver? I could only find documentation about diffing on the website.As to mismatches: yes, they are bound to happen in some cases. Even for line-based diffing, Git uses rather convoluted heuristics to avoid them (with the \"histogram\" diff algorithm), but they can't be completely ruled out there either. I hope that with enough safeguards (helper to review merges, downstream consistency checks with local fall-back to line-based diffing) they can be lived with. I'm happy to try other matching algorithms if they are more promising though (there isn't much coupling with the rest of the pipeline).Concerning tree-sitter, I have noticed some small issues, but nothing that was a show-stopper so far. I actually like it that it's designed for syntax highlighting, because it's really helpful that the representations it gives stay faithful to the original source, to avoid introducing reformatting noise in the merging process. Parsers written for a specific language can sometimes be too zealous (stripping comments out, doing some normalizations behind your back). That's a problem in Spork (which uses Spoon, a pretty advanced Java parser). And the uniform API tree-sitter offers over all those parsers is just too good to give up, in my opinion.\n \nreply",
      "I don't think that different algorithms are better for merging or diffing. In both cases, the first step is to match identical nodes, and the quality of the final result depends heavily on this step. The main problem with GumTree is that it is a greedy algorithm. One incorrectly matched node can completely screw up the rest of the matches. A typical example we encountered was adding a decorator to a function in Python. When other functions with the same decorator followed, the algorithm would often map the newly added decorator to an existing decorator, causing all other decorator mappings to be \"off-by-one\". GumTree has a tendency to come up with more changes than there actually are.We try to really get the diff quality nailed down before going after merges. We don't have merge functionallity in SemanticDiff yet.The main issue we have with tree-sitter is that the grammars are often written from scratch and not based on the upstream grammar definition. Sometimes they only cover the most likely cases which can lead to parsing errors or incorrectly parsed code. When you encounter parsing errors it can be difficult to fix them, because the upstream grammar is structured completely different. To give you an example, try to compare the tree-sitter Go grammar for types [1] with the upstream grammar [2]. It is similar but the way the rules are structured is somewhat inverted.We use separate executables for the parsers (this also helps to secure them using seccomp on Linux), and they all use the same JSON schema for their output. This allows us to write the parser executable in the most appropriate language for the target language. Building all them statically and cross-platform for our VS Code extension isn't easy though ;)[1]: https://github.com/tree-sitter/tree-sitter-go/blob/master/gr...\n[2]: https://go.dev/ref/spec#Types\n \nreply",
      "Thanks for the details.\nConcerning matching for diffing vs for merging, the differences I can think of are:- for diffing, the matching of the leaves is what matters the most, for merging the internal nodes are more important,- for diffing, it feels more acceptable to restrict the matching to be monotonous on the leaves since it's difficult to visually represent moves if you can detect them. For merging, supporting moves is more interesting as it lets you replay changes on the moved element,- diffing needs to be faster than merging, so the accuracy/speed tradeoffs can be different.Packaging parsers into separate executables seems like hard work indeed! I assume you also considered fixing the tree-sitter grammars (vendoring them as needed, if the fixes can't be upstreamed)? Tree-sitter parsers are being used for a lot more than syntax highlighting these days (for instance GitHub's \"Symbols\" panel) so I would imagine maintainers should be open to making grammars more faithful to the official specs. I'm not particularly looking forward to maintaining dozens of forked grammars but it still feels a lot easier than writing parsers in different languages. I guess you have different distribution constraints also.\n \nreply",
      "> - for diffing, the matching of the leaves is what matters the most, for merging the internal nodes are more important,The leaves are the ones that end up being highlighted in the diff, but the inner nodes play an important role as well. We try to preserve as much of the code structure as possible when mapping the nodes. A developer is unlikely to change the structure of the code just for fun. A mapping with a larger number of structural changes is therefore more likely to be incorrect.> - for diffing, it feels more acceptable to restrict the matching to be monotonous on the leaves since it's difficult to visually represent moves if you can detect them. For merging, supporting moves is more interesting as it lets you replay changes on the moved element,We use a pipeline based approach and visualizing the changes is the last step. For some types of changes we don't have a way to visualize them yet (e.g. moves within the same line) and ignore that part of the mapping. We are still trying to get the mapping right though :)We upstreamed a few bug fixes for tree-sitter itself. The grammars were a bit more complicated because we were just using them as a starting point. We patched tree-sitter, added our own annotations to the grammars and restructured them to help our matching algorithm achieve better results and improve performance. In the end there was not much to upstream any more.Using a well tested parsing library, such as Roslyn for C#, and writing some code to integrate it into our existing system aligned more with our goals than tinkering with grammars. Context-sensitive keywords in particular were a constant source of annoyance. The grammar looks correct, but it will fail to parse because of the way the lexer works. You don't want your tool to abort just because someone named their parameter \"async\".\n \nreply",
      "> We are currently in the process of moving away from tree-sitter and instead using the parsers provided by the languages themselves where possible.I imagine this means you're trying to abstract over those parsers somehow? How well is that going, and have you written about your approach?(I wrote `resholve` to identify and rewrite references to external dependencies in bash/posixy Shell scripts to absolute paths. This is helpful in the Nix ecosystem to confirm the dependencies are known, specified, present, don't shift when run from a service with a different PATH, etc.It builds on the mostly-bash-compatible OSH parser from the oilshell/oils-for-unix project for the same reasons you're citing.It would be ~nice to eventually generalize out something that can handle scripts for other shell languages like fish, zsh, nushell, elvish, the ysh part of the oils-for-unix project, etc., but I suspect that'll be a diminishing-return sort of slog and haven't had any lightbulb-moments to make it feel tractable yet.We also have some ~related needs here around identifying hardcoded or user-controlled exec...)\n \nreply",
      "Our parsers simply return the concrete syntax trees in a JSON format. We do not unify all the different syntax constructs into a common AST if that is what you are looking for. The languages and file formats we support are too diverse for that.The language specific logic does not end with the parsers though. The core of SemanticDiff also contains language specific rules that are picked up by the matching and visualization steps. For example, the HTML module might add a rule that the order of attributes within a tag is irrelevant. So it all comes down to writing a generic rule system that makes it easy to add new languages.\n \nreply",
      "An important point here is that for certain languages, using the original grammar is pretty much impossible. In particular, for C, you want to do diffing and merging on the un-preprocessed source, but the language's grammar very much assumes the source has gone through the preprocessor.Of course, the existence of the preprocessor means there are situations where it's completely impossible to know what the correct parse is; it will necessarily be heuristic in some cases.\n \nreply",
      "> best effort approach to parsing. This is perfectly fine for syntax highlighting, since the worst that can happen is that a few characters are highlighted incorrectly. However, when diffing or modifying code you really want the code to be parsed according to the upstream grammar, not something that mostly resembles it.But surely you need to support code that doesn't parse correctly by the actual language's grammar anyway? 'Merge branch fix-syntax-error'\n \nreply",
      "In Mergiraf, as soon as there is a parsing error in any of the revisions, it falls back on line-based merging, even though tree-sitter is generally good at isolating the error. It felt like the safest thing to do (maybe we detected the language wrong), but I'm definitely open to reconsidering\u2026\n \nreply"
    ],
    "link": "https://mergiraf.org/",
    "first_paragraph": "Are you held back by conflicts? Then meetMergiraf can solve a wide range of Git merge conflicts. That's because it's aware of the trees in your files!\nThanks to its understanding of your language, it can often reconcile the needs of both sides.You can teach Mergiraf a new language in a completely declarative way. It's a nonviolent animal, so it prefers that over imperatives.Configure Git to use Mergiraf instead of its default merge heuristics. This will enhance git merge, revert, rebase, cherry-pick and more.You can also keep Git's original behaviour and manually invoke Mergiraf after encountering conflicts.Figure 1: Two git users making inadequate use of blame, push and pull to resolve a conflictHead to the installation page and start merging nonviolently today!Mergiraf is designed with your needs in mind. Its goals are:Syntax-aware merging heuristics can sometimes be a bit too optimistic in considering a conflict resolved. Mergiraf does its best to err on the side of caution and reta"
  },
  {
    "title": "Grim Fandango (filfre.net)",
    "points": 90,
    "submitter": "cybersoyuz",
    "submit_time": "2024-11-09T22:17:23 1731190643",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42097261",
    "comments": [
      "I think one understated problem Grim Fandango had is that it's too adult.Today \"adult\" often means \"there's sex and/or gore\", but the content is still simple and juvenile. But Grim Fandango isn't like that, it's just full of themes that probably confused the heck out of almost every kid that tried to play it.Like the very first chapter throws you right into office politics. You deal with stealing a job from another salesman, sabotage a pneumatic tube messaging system, and sneak into your boss' office.It all makes perfect sense for adults familiar with office work and all the movies it references. But I recall I tried it when I was maybe 14 and I couldn't make head nor tails of it. I didn't even realize the pneumatic tubes were actually a thing.Things like Monkey Island and even Full Throttle are far more accessible.\n \nreply",
      "Here's the thing - I remember playing it as a kid and so many things, arguably most of it, went way over my head: the whole travel agent thing and getting ahead in the office, dia de los muertos, the references to noir, the weird but gorgeous mexican art deco combo, I knew nothing about any of it. But I still loved every second of it. It made the world feel very rich and real even if I didn't fully get it, in a way that other games around the time just were not.Also this is not too dissimilar to how adult life that surrounds every child is to a child. You're sort of used to living in a world that has workings beyond your comprehension and just going along with it. I didn't get what exactly was going on but I did understand /something/ was.I'm listening to a review of The Great Mouse Detective (1986) which has a similar ethos, as did other content targeting young people from that era. Also I recall picking up books as a kid that were certainly not meant for children and adults back then didn't even blink, and I think it stoked my curiosity and interests and pushed the boundaries of my understanding, as well as prepared me for growing up. I don't think I ended up being a worse person or being traumatized in any way. Part of me wonders if kids' content being much more sanitized these days is a mistake.\n \nreply",
      "That's a really interesting perspective. I grew up around when adventure games were popular, and I learned a lot about the grown-up world (and in fact, American world) through adventure games.Sam and Max had so much Americana that, playing as a non-American, got me into the deep cuts of American culture. I think a lot of it was contextual. I didn't get all the references at first (e.g. who's John Muir for instance), but the context made it possible for me to figure it out.\n \nreply",
      "I got completely stuck in the Beavis and Butthead adventure game when one of the voice acted characters told me to get a \"vee-hickul\". As a teenager sitting at my family PC in London, I had no idea what the hell the Texan (?) was saying. Only several years later  would I figure it out.The only other thing I remember from that game is the hock-a-loogie minigame, which I mastered. I wonder if my parents had any idea what I was up to on the computer?\n \nreply",
      "Anecdote: the word \u2018vehicle\u2019 is referenced aty day job a lot. I had a PM who always, always said \u2018vee-hickle\u2019 and I honestly always thought he was full of shit.On day when he was really mad about $(thing I predicted) he just comes out and says \u2018vehicle\u2019 like it\u2019s spelled.I don\u2019t remember feeling smug or annoyed, mostly just kind of bummed at the farce.\n \nreply",
      "This is a great assessment that I never realized until you said it. There are so many games from that era that I played that fit that mold. I was playing Leisure Suit Larry as a 10 year old! I can\u2019t imagine parents these days letting their kids play that at all!\n \nreply",
      "My parents couldn't understand enough English to really get why I shouldn't be playing Larry (almost all the screens are just fine) and I was too young to understand the actual theme. Perfect combination...Kind of like Police Quest 1 too. Although it did teach me to type \"use handcuffs\" fast enough. Also the spelling of \"briefcase\" and other longer words.\n \nreply",
      "I thought this game was up there in my favorites as a kid, don't think me or my younger sibling noticed personally, but the puzzles were really hard for sure. Either way we beat it between each other taking turns I remember. Oh yeah, the tank controls were a little less shit with a gamepad - back when there was a dedicated port for those no lessI also remember these games easier to beat before the internet was so pervasive and these kinds of things were the best way to pass rainy days, we'd draw out notes and maps on paper and all sorts of stuff to beat them - different times now, people's attention is way more scattered\n \nreply",
      "We also had fewer games available. I did play a lot of demos and shareware though, thanks to disks from gaming magazines, including GF.\n \nreply",
      "I'm about the same age but personally I had the opposite experience. For me it was refreshing to play something more mature, more 'intellectual', even if I'm sure a lot of the jokes washed over me.\n \nreply"
    ],
    "link": "https://www.filfre.net/2024/11/grim-fandango/",
    "first_paragraph": "My one big regret was the PlayStation version [of Broken Sword]. No one thought it would sell, so we kept it like the PC version. In hindsight, I think if we had introduced direct control in this game, it would have been enormous.\u2014 Charles Cecil of Revolution Software, speaking from the Department of Be Careful What You Wish For One day in June of 1995, Tim Schafer came to work at LucasArts and realized that, for the first time in a long time, he didn\u2019t have anything pressing to do. Full Throttle, his biker movie of an adventure game, had been released several weeks before. Now, all of the initial crush of interviews and marketing logistics was behind him. A mountain had been climbed. So, as game designers do, he started to think about what his next Everest should be.Schafer has told in some detail how he came up with the core ideas behind Grim Fandango over the course of that summer of 1995.The truth is, I had part of the Fandango idea before I did Full Throttle. I wanted to do a game"
  },
  {
    "title": "FrontierMath: A benchmark for evaluating advanced mathematical reasoning in AI (epochai.org)",
    "points": 62,
    "submitter": "sshroot",
    "submit_time": "2024-11-09T14:18:24 1731161904",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=42094546",
    "comments": [
      "For some context on why this is important: this benchmark was designed to be extremely challenging for LLMs, with problems requiring several hours or days of work by expert mathematicians. Currently, LLMs solve 2% of problems in the set (which is kept private to prevent contamination).They even provide a quote from Terence Tao, which helped create the benchmark (alongside other Field medalists and IMO question writers):> \u201cThese are extremely challenging. I think that in the near term basically the only way to solve them, short of having a real domain expert in the area, is by a combination of a semi-expert like a graduate student in a related field, maybe paired with some combination of a modern AI and lots of other algebra packages\u2026\u201dSurprisingly, prediction markets [1] are putting 62% on AI achieving > 85% performance on the benchmark before 2028.[1]: https://manifold.markets/MatthewBarnett/will-an-ai-achieve-8...\n \nreply",
      "> Surprisingly, prediction markets [1] are putting 62% on AI achieving > 85% performance on the benchmark before 2028.Why surprisingly?2028 is twice as long as capable LLMs existed to date. By \"capable\" here I mean capable enough to even remotely consider the idea of LLMs solving such tasks in the first place. ChatGPT/GPT-3.5 isn't even 2 years old!4 years is a lot of time. It's kind of silly to assume LLM capabilities have already bottomed out.\n \nreply",
      ">Surprisingly, prediction markets [1] are putting 62% on AI achieving > 85% performance on the benchmark before 2028.Or they know the ancient technique of training on the test set. I know most of the questions are kept secret, but they are being regularly sent over the API to every LLM provider.\n \nreply",
      "Although the answer isn't sent, so it would have to be a very deliberate effort to fish those out of the API chatter and find the right domain expert with 4-10 hours to spend on cracking itJust letting the AI train on its own wrong output wouldn't help. The benchmark already gives them lots of time for trial and error.\n \nreply",
      "Market size matters. There's a whopping total of 71 bidders on that.\n \nreply",
      "These benchmarks are entirely pointless.The people making them are specialists attempting to apply their skills to areas unrelated to LLM performance, a bit like a sprinter making a training regimen for a fighter jet.What matters is the data structures that underlie the problem space - graph traversal. First, finding a path between two nodes; second, identifying the most efficient path; and third, deriving implicit nodes and edges based on a set of rules.Currently, all LLMs are so limited that they struggle with journeys longer than four edges, even when given a full itinerary of all edges in the graph. Until they can consistently manage a number of steps greater than what is contained in any math proof in the validation data, they aren\u2019t genuinely solving these problems; they\u2019re merely regurgitating memorized information.\n \nreply",
      "It will be a useful benchmark to validate claims by people like Sam Altman about having achieved AGI.\n \nreply",
      "Most humans can't solve these problems, so it's certainly possible to imagine a legitimate AGI that can't either.\n \nreply",
      "> they\u2019re merely regurgitating memorized informationSource?\n \nreply",
      "If a model can't inately reason over 5 steps in a simple task but produces a flawless 500 step proof you either have divine intervention or memorisation.\n \nreply"
    ],
    "link": "https://epochai.org/frontiermath/the-benchmark",
    "first_paragraph": "FrontierMath presents hundreds of unpublished, expert-level mathematics problems that specialists spend days solving. It offers an ongoing measure of AI complex mathematical reasoning progress.We\u2019re introducing FrontierMath, a benchmark of hundreds of original, expert-crafted mathematics problems designed to evaluate advanced reasoning capabilities in AI systems. These problems span major branches of modern mathematics\u2014from computational number theory to abstract algebraic geometry\u2014and typically require hours or days for expert mathematicians to solve.Enable JavaScript to see an interactive visualization.Figure 1. While leading AI models now achieve near-perfect scores on traditional benchmarks like GSM-8k and MATH, they solve less than 2% of FrontierMath problems, revealing a substantial gap between current AI capabilities and the collective prowess of the mathematics community. MMLU scores shown are for the College Mathematics category of the benchmark.To understand and measure progr"
  },
  {
    "title": "LLMs have reached a point of diminishing returns (garymarcus.substack.com)",
    "points": 63,
    "submitter": "signa11",
    "submit_time": "2024-11-10T00:25:40 1731198340",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=42097774",
    "comments": [
      "The context some commenters here seem to be missing is that Marcus is arguing that spending another $100B on pure scaling (more params, more data, more compute) is unlikely to repeat the qualitatively massive improvement we saw between say 2017 and 2022. We see some evidence this is true in the shift towards what I categorize as system integration approaches: RAG, step by step reasoning, function calling, \"agents\", etc. The theory and engineering is getting steadily better as evidenced by the rapidly improving capability of models down in the 1-10B param range but we don't see the same radical improvements out of ChatGPT etc.\n \nreply",
      "I don't see how that is evidence of the claim. We are doing all these things because they make existing models work better, but a larger model with RAG etc is still better than a small one, and everyone keeps working on larger models.\n \nreply",
      "There is a contingent that I think Marcus is responding to that have been claiming that all we need to get to AGI or ASI is pure transformer scaling, and that we were very close with only maybe $10B or $100B more investment to get there. If the last couple of years of research have given us only incrementally better models to the point that even the best funded teams are moving to hybrid approaches then that's evidence that Marcus is correct.\n \nreply",
      "I think the better question to ask is: has search become commodity? Why did Google manage to capture (practically) all the profit from search? Cause obviously the hype around AI is that the VCs thinking that they're buying shares of \"next Google\".\n \nreply",
      "Anyone who followed Deep Learning in the 2010s would have guessed the same thing. Big boom with vision models by adding a lot of layers and data, but eventually there was diminishing returns there too. It\u2019s unsurprising the same would happen with LLMs. I don\u2019t know why people keep expecting anything other than a sigmoid curve. Perhaps they think it\u2019s like Moore\u2019s law but that\u2019s simply not the case in this field.But that\u2019s fine, LLMs as-is are amazing without being AGI.\n \nreply",
      "I\u2019m not going to argue with the possibility they may have hit a wall, but pointing to 2022 as when this wall happened is weird considering the enormous capability gap between models available then and the ones now.There\u2019s probably a wall, but what exists might just be good enough for it to not matter much.\n \nreply",
      "Compare 2022 to 2020 or 2017 though.\n \nreply",
      "I\u2019m still waiting for a large, OSS one with 100% legal, pre-training data. We don\u2019t even have a 1B model that I\u2019m sure meets that standard. There\u2019s a fair-trained model for lawyers claiming it.I think someone running a bunch of epochs of a 30B or 70B on Project Gutenberg would be a nice start. We could do continued pre-training from there.So, if counting legal and at least trainable (open weights), the performance can only go up from here.\n \nreply",
      "Are you aware of any efforts to do this? Even a 3B param attempt would be informative.\n \nreply",
      "I understand the desire, but most of the world's knowledge is under copyright. 100% legal will never give you the same performance.\n \nreply"
    ],
    "link": "https://garymarcus.substack.com/p/confirmed-llms-have-indeed-reached",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: HTML-to-Markdown \u2013 convert entire websites to Markdown with Golang/CLI (github.com/johanneskaufmann)",
    "points": 241,
    "submitter": "JohannesKauf",
    "submit_time": "2024-11-09T09:48:08 1731145688",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=42093511",
    "comments": [
      "If you need this sort of thing in any other language, there's a free, no-auth, no-api-key-required, no-strings-attached API that can do this at https://jina.ai/reader/You just fetch a URL like `https://r.jina.ai/https://www.asimov.press/p/mitochondria`, and get a markdown document for the \"inner\" URL.I've actually used this and it's not perfect, there are websites (mostly those behind Cloudflare and other such proxies) that it can't handle, but it does 90% of the job, and is an one-liner in most languages with a decent HTTP requests library.\n \nreply",
      "I use this too and, not to detract from your enthusiasm, it's not exactly no-strings-attached. There's a token limit on free use and you can't use it for any commercial purposes. Luckily the pricing for unrestricted use is reasonable though at 2 cents per million tokens.People will also want to note that it's LLM-powered which has pros and cons. One pro being that you can download and run their model yourself for non commercial use cases: https://huggingface.co/jinaai/reader-lm-1.5b\n \nreply",
      "Thanks, Jina actually looks quite nice for use in LLMs.I also provide a REST API [1] that you can use for free (within limits). However you have get an API Key by registering with Github (see reason below).---The demo was previously hosted on Vercel. Someone misused the demo and send ~5 million requests per day. And would not stop \u2014 which quickly brought me over the bandwidth limits of Vercel. And bandwidth is really really expensive!So that is the reason for requiring API Keys and hosting it on a VPS\u2026 Lessons learned![1] https://html-to-markdown.com/api\n \nreply",
      "Seems pretty risky to not implement rate limits either way.\n \nreply",
      "The problem was: Doing rate limiting on the application level was not enough. Once the request hit my backend the incoming bandwidth was already consumed \u2014 and I was charged for it.I contacted Vercel's Support to block that specific IP address but unfortunately they weren't helpful.\n \nreply",
      "So you're probably still vulnerable to this even with the key requirement, but they stopped once you removed the incentive? Did you notice what they were scraping?\n \nreply",
      "Sorry, I mixed up a few topics here:- Moved everything to a VPS - way better value for money. Extra TB of traffic only costs \u20ac1-10 with Hetzner/DigitalOcean compared to 400\u20ac with Vercel's old pricing.- Put Cloudflare in front - gives me an extra layer of control (if I ever need it)- Built a proper REST API - now there's an official way to use the converter programmatically- Made email registration mandatory for API keys - lets me reach out before having to block anyoneThat other server was probably running a scraper and then converting the html-websites to markdown. After about 2 weeks they noticed that I was just returning garbage and it stopped :)\n \nreply",
      "Ah! Makes sense now, thanks for sharing.I've had good success with Cloudflare's free-tier features for rate limiting. If you haven't tried it, it only takes a couple minutes to enable and should be pretty set-and-forget for your API.\n \nreply",
      "Pandochttp://www.cantoni.org/2019/01/27/converting-html-markdown-u...\n \nreply",
      "For clarity: I'm a pandoc diehard (especially because it's written by a philosopher!) but it intentionally doesn't approach this level of functionality, AFAIK.\n \nreply"
    ],
    "link": "https://github.com/JohannesKaufmann/html-to-markdown",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \u2699\ufe0f Convert HTML to Markdown. Even works with entire websites and can be extended through rules.\n      A robust html-to-markdown converter that transforms HTML (even entire websites) into clean, readable Markdown. It supports complex formatting, customizable options, and plugins for full control over the conversion process.Use the fully extendable Golang library or a quick CLI command. Alternatively, try the Online Demo or REST API to see it in action!Here are some cool features:Bold & Italic: Supports bold and italic\u2014even within single words.List: Handles ordered and unordered lists with full nesting support.Blockquote: Blockquotes can include other elements, with seamless support for nested quotes.Inline Code & Code Block: Correctly handles backticks and multi-line code blocks, preserving code structure.Link & Image: Properly forma"
  },
  {
    "title": "When machine learning tells the wrong story (jackcook.com)",
    "points": 60,
    "submitter": "jackcook",
    "submit_time": "2024-11-09T16:38:08 1731170288",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42095302",
    "comments": [
      "This article is awesome, your writing is super approachable and the interactive demos are really cool. I also appreciate the background on how you got into doing this sort of thing.\n \nreply",
      "I wonder if adopting io_uring on Linux might allow a browser to preserve the privacy a little, in this specific case. (Though it is very hard to get right, unfortunately.)\n \nreply"
    ],
    "link": "https://jackcook.com/2024/11/09/bigger-fish.html",
    "first_paragraph": "\n    Oxford, UK \u2014 November 09, 2024\n  In June 2022, three short weeks after my college graduation, I presented at ISCA, my first serious research conference.\nOnstage with my co-author Jules Drean, we gave a 15-minute talk about our hardware security research paper, There\u2019s Always a Bigger Fish: A Clarifying Analysis of a Machine-Learning-Assisted Side-Channel Attack, that had taken the majority of my last two years at MIT to complete.\nIn hindsight, that talk was the culmination of one of my proudest accomplishments from my time in college.\nThe paper has since won awards and recognition, including first place in Intel\u2019s 2024 Hardware Security Academic Award,1 and inclusion in the 2023 edition of IEEE Micro Top Picks, which highlights 12 of the best papers in computer architecture each year.Since our talk, every few months, I\u2019ve gotten the urge to write a blogpost about the paper.\nAmong other cool things described in the paper, we\u2026I think some of these lessons are widely applicable, even"
  },
  {
    "title": "Scientist treated her own cancer with viruses she grew in the lab (nature.com)",
    "points": 398,
    "submitter": "dataminer",
    "submit_time": "2024-11-09T14:23:30 1731162210",
    "num_comments": 158,
    "comments_url": "https://news.ycombinator.com/item?id=42094573",
    "comments": [
      "> \u201cI think it ultimately does fall within the line of being ethical, but it isn\u2019t a slam-dunk case\u201dI concede that I haven\u2019t thought as deeply about this as ethicists, but I strongly suspect that the cost/benefit calculation here is way over-cautious if you think the theoretical induced harm is remotely close to the benefits of publishing.The history of science is already full of self-experimenters, so at the margin publishing is unlikely to move the needle.Furthermore, patients with cancer diagnoses are already extremely motivated to try whatever experimental treatments the FDA will permit; self-experimentation is already supply-constrained (of experiment opportunities) and there is excess demand. Again fuzzy concerns about population-level harms overrule individuals\u2019 rights to seek treatments for their fatal diagnoses.\n \nreply",
      "I've been at least partly convinced that \"medical ethics\" very frequently looks nothing at all like what most people consider to be ethical. As far as I can tell, it exists mostly to prevent anyone from getting in trouble in the case that something goes wrong (which often means \"do nothing\"), rather than actually consider what is or is not ethical. It seems to be completely infected by the Copenhagen Interpretation of  Ethics [0]So, while they aren't always wrong, my default opinion is that, until given compelling evidence to the contrary, I shouldn't worry too much about what medical ethicists think on a particular topic. Even when they are right, they are usually right in a way that most normal people can easily see that it is correct.[0] https://web.archive.org/web/20230302022931/https://blog.jaib...\n \nreply",
      "I think I agree with you in this case, but I'm not so sure about a lot of the examples given in that linked article.BHH Labs: pretty obvious to me it's ethically wrong to find the most desperate people around and pay them less than minimum wage to staff your event...Uber: yes there was a need here, yes the experience offered by traditional taxis is awful and their service is strictly better where available, that really is not related to the ethical concerns I have with them. They're cheaper because they underpay drivers, and quite often they'll come into an area and drive out all the taxis then all but disappear themselves, leaving the town with zero practical transport options.\n \nreply",
      "> They're cheaper because they underpay driversI don't really get this one. If you drive for Uber, you're going to have a pretty good idea what you're getting paid, and if you don't like that amount then you're under no obligation to keep doing it.People like to do the math on this using some kind of midsized SUV getting 20ish MPG and that will need major repairs before 150k miles, whereas the people doing it sensibly are using full electric cars or 50 MPG hybrids from reliable makes that will do 500k miles, for which the math is very different.There are also people who do it part time and thereby have very different costs because they're e.g. accepting rides for trips that they themselves would have made alone regardless. These people are not being \"underpaid\", they're getting nearly free money.And when everybody knows the deal ahead of time -- or can reasonably have figured it out within a week -- how can they be underpaying people (i.e. paying them less than competing employers) and yet people still choose to do it? Unless it's not as bad a deal as it's made out to be for those people.> then all but disappear themselves, leaving the town with zero practical transport options.Do they leave or are they forced out? Because it's an app; it doesn't make a lot of sense for them to leave for no reason.\n \nreply",
      "Uber offers higher rates when moving into an area, sometimes the point of making a loss per ride. Once an area is established, they cut rates to drivers. Obviously, the drivers make the rational decision you\u2019ve outlined above; but the taxi companies don\u2019t come back.\n \nreply",
      "Again that's not how it works. It's a two-sided marketplace.> the drivers make the rational decision you\u2019ve outlined aboveOkay... then the rates for drivers will automatically go up again since there's there'll be a mismatch between drivers & riders.\n \nreply",
      "> how can they be underpaying people (i.e. paying them less than competing employers) and yet people still choose to do it?\"paying them less than competing employers\" being synonymous with \"underpaying\" is probably not a great assumption, although I'm sure it's the definition an MBA would use.Most regular people are choosing the least-worst option in terms of employer. That doesn't mean that the least worst option is necessarily good, or paying fairly on an absolute scale. It could just be the job that means workers can handle one unexpected large bill before going bankrupt instead of not being able to handle any at all working for the next-worst option.In other words, there's an imbalance of power between employers and the \"regular person\" workforce. The workers technically have a choice of where to work, but in many cases, none of the choices are good.\n \nreply",
      "> people are choosing the least-worst option in terms of employerDoesn't that mean people are choosing the best employer that wants their skill set?\n \nreply",
      "Yes, just like 6yo chimney sweeps were and children in sweatshops today are.\n \nreply",
      "Uber burned investor money in major markets for years operating at a loss to drive smaller operations out of business, only to become at least as expensive as their former competitors but as the only game in town.\n \nreply"
    ],
    "link": "https://www.nature.com/articles/d41586-024-03647-0",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.AdvertisementYou can also search for this author in PubMed\n\u00a0Google Scholar\nViruses such as measles (pictured here) can be used to attack cancerous cells. Credit: Eye Of Science/Science Photo LibraryA scientist who successfully treated her own breast cancer by injecting the tumour with lab-grown viruses has sparked discussion about the ethics of self-experimentation. Beata Halassy discovered in 2020, aged 49, that she had breast cancer at the site of a previous mastectomy. It was the second recurrence there since her left breast had been removed, and she couldn\u2019t face another bout of chemotherapy. Halassy, a virologist at th"
  },
  {
    "title": "You too can write a book (parentheticallyspeaking.org)",
    "points": 53,
    "submitter": "azhenley",
    "submit_time": "2024-11-09T21:10:41 1731186641",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=42096915",
    "comments": [
      "I usually participates in question/answer communities to answer things, I almost never ask my own questions.As a result, I have various sources of notes I've figured out and get high use/reuse from.I also do a lot of technical training at work, for both beginners and advanced users, so have a wealth of tried and tested content there.I've often contemplated writing an eBook on each topic and selling them on Leanpub/Amazon/Google for 5 or 10 bucks each.The idea of limiting myself to 6 pages per topic is appealing. That would force an economy of writing and density of content which appeals to me.\n \nreply",
      "I agree. I DID write a book! https://howtoopensource.dev/My biggest tip is this: Don\u2019t skip getting beta readers. High quality feedback is really hard to come by. I changed my tool chain to add a google form at the end of each chapter and got strong buy in from a handful of people with the finished first draft in a beta state. In the end some bailed but one left amazing feedback resulting in massive structural changes.The process of writing a book is two things (to me). The most obvious is sharing information. The second, often overlooked, but biggest benefit IMHO is how you will grow and learn the source material even better than you already do. Even if you don\u2019t ever publish it, it\u2019s still worthwhile to putting in the effort to write a book. GLHF.\n \nreply",
      "[flagged]",
      "Hackers? Racist slave owners? Stock options? You\u2019ve written several but haven\u2019t had time to publish?  What are you going on about?\n \nreply",
      "The blog post should more accurately be titled \u201cYou too can write a textbook\u201d\n \nreply",
      "For beta ebook publishing I can't help but recommend my friends at https://leanpub.com where my latest book is currently at the top of the charts.I've been publishing with them since they launched (a long time ago) and have made nearly six figures lifetime revenue. Plus they give you one-button push to publish to print versions at Amazon.\n \nreply",
      "Is it intentionally ironic that there's a grammar mistake in the second sentence of the article?\n \nreply",
      "That would be nice. Problem is rather more simple: the author can't proof-read.\n \nreply",
      "Leunig cartoon on your \"inner book\"https://scontent.fmel18-1.fna.fbcdn.net/v/t39.30808-6/461606...\n \nreply",
      "Bad URL hash?https://consumer.licensing-publishing.nine.com.au/Assets/V2/...\n \nreply"
    ],
    "link": "https://parentheticallyspeaking.org/articles/write-a-book/",
    "first_paragraph": "\u00a0\u00a0\u00a0\u00a01\u00a0You Can Write a Book\u00a0\u00a0\u00a0\u00a02\u00a0You Should Write a Book\u00a0\u00a0\u00a0\u00a03\u00a0MechanicsThanks to Neeldhara Misra for pushing me to write\nthis post, based on a thread on Twitter.This article is primarily directed at academics. Its purpose is to\ntell you two things:\nYou can write a book.You probably should write a book.You can write a book.You probably should write a book.Let\u2019s say you\u2019re not using someone else\u2019s textbook, or using it only\nloosely. That means you\u2019re going to spend a lot of time organizing\nyour thoughts. You will probably produce some kind of \u201clecture\nnotes\u201d. The delta from there to a book is much smaller than you\nimagine.Here\u2019s a pro-tip. Back in about 2003/4, I noticed that the quantity of\nreading that students would do before class was at most about six\npages; once it got to about eight pages, they wouldn\u2019t read at\nall. (These numbers may be much lower now.) But this automatically\nbounds how much you have to write!In short: let\u2019s say you\u2019re writing up lecture notes. You\u2019re writing\nabou"
  },
  {
    "title": "Texture-Less Text Rendering (poniesandlight.co.uk)",
    "points": 175,
    "submitter": "PaulHoule",
    "submit_time": "2024-11-09T07:27:56 1731137276",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=42093037",
    "comments": [
      "If anyone wants to try this, work through the artithmetic, it\u2019s incredibly easy (and a fun Saturday morning exercise if you\u2019re into this kind of thing) to code up on ShaderToy. From scratch is fun, but if you need a hint to get started I just made one https://www.shadertoy.com/view/Mc3cW2 and there are a bunch of super clever text hacks other people have done like this Matrix in less than 300 characters https://www.shadertoy.com/view/llXSzj or green CRT display effect https://www.shadertoy.com/view/XtfSD8. Loads of other examples abound if you look around.\n \nreply",
      "I've never been able to make text look good at small sizes whenever I've tried immediate mode text rendering. Even in the first shadertoy, in vec2(30, -30), if you change 30 to 300, you'll see some artifacts. Is there a trick to getting that right? For me, multisampling the texture inside fragment shader appears to work the best, although it still isn't as good as the state of the art.\n \nreply",
      "Yeah for that you want to do something better than the nearest neighbor sampling I did there. Multisampling can help but there are definitely some other alternatives. This is where the texture/atlas method the author avoided comes in very handy, because it typically comes with mip-mapping which will help small text look good. There are also analytic stroke drawing methods, though even that isn\u2019t perfect (it always depends on your choice of filter and what actual display you use, and what your goals are, etc.)ShaderToy comes with a texture atlas built in. I have one or two examples of that, for example https://www.shadertoy.com/view/ltBfDD In addition to mipmap textures, there are other pseudo antialiasing methods people use on ShaderToy, for example when doing 2d stuff you can use the pixel derivative to make 1 pixel wide blending functions, and use it to antialias hard edges. Example https://www.shadertoy.com/view/MtyyRc\n \nreply",
      "offtopic but interesting, matrix effect in HTML/CSS/JS, 1024 bytes,```\n<head><style>{margin:0;padding:0;line-height:1;overflow:hidden;}div{width:1em;position:absolute;}</style><script>\nw=window;n=w.innerWidth;m=w.innerHeight;d=document;q=\"px\";function z(a,b){return Math.floor(Math.random()(b-a)+a)}f=\" 0123456789\";for(i=0;i<45;i++)f+=String.fromCharCode(i+65393);function g(){for(i=0;i<90;i++){r=d.createElement(\"div\");for(j=z(20,50);j;j--){x=d.createElement(\"pre\");y=d.createTextNode(f[z(0,56)]);x.appendChild(y);x.style.opacity=0;r.appendChild(x)}r.id=\"r\"+i;r.t=z(-99,0);with(r.style){left=z(0,n)+q;top=z(-m,0)+q;fontSize=z(10,25)+q}d.body.appendChild(r);setInterval(\"u(\"+i+\")\",z(60,120))}}function u(j){e=d.getElementById(\"r\"+j);c=e.childNodes;t=e.t+1;if((v=t-c.length-50)>0){if((e.style.opacity=1-v/32)==0){for(f in c)if(c[f].style)c[f].style.opacity=0;with(e.style){left=z(0,n)+q;top=z(-m/2,m/2)+q;opacity=1}t=-50}}e.t=t;if(t<0||t>c.length+12)return;for(f=t;f&&f>t-12;f--){s=1-(t-f)/16;if(f<c.length&&c[f].style){c[f].style.opacity=s;}}}\n</script><body text=#0f0 bgcolor=#000 onload=g()>\n```https://codegolf.stackexchange.com/a/17414\n \nreply",
      "This is delightfully clever and hacky (so basically like every 3d rendering technique ever) but the end result isn't exactly beautiful unless you're trying to recreate an old school electronic billboard. You could improve it by adding more bits, but long before it starts to look good you'd be searching for an easier way to handle setting all the bits... And there's almost certainly no more efficient solution than using black and white pixels in a drawing program then saving the results in a texture. So, full circle.If anyone is interested in the a more common way that modern 3d rendering engines draw text, look up SDF text (and related techniques like MSDF etc.). This uses a traditional texture atlas in a preprossing step to create an atlas of signed distance fields.\n \nreply",
      "> So, full circleIn case anyone hasn't yet seen the 1968 full circle paper, \"On the Design of Display Processors\": http://cva.stanford.edu/classes/cs99s/papers/myer-sutherland...Hardware in their case, but we also have software sa\u1e43s\u0101ra.\n \nreply",
      "It is pretty clever for debug text if, for instance, textures aren't uploading properly. But uh... while it's cute that the OP compares sprite sheets to 16th century manual typesetting, the reality is that it took a printer's assistant an hour to layout a broadsheet of tiny metal slugs on a press, and it takes oh < 10ms to upload a spritesheet to a GPU, which is then infinitely configurable.Not saying it's not a neat trick, it is.\n \nreply",
      "There's also the option of rendering text as meshes.TextMeshPro goes one step further and uses signed distance fields to handle arbitrary scale.https://docs.unity3d.com/Packages/com.unity.textmeshpro@4.0/...\n \nreply",
      "Going one step further still there's the option of evaluating font curves directly on the GPU, which can be high quality regardless of scale or perspective. That turns out to be very difficult to do efficiently but it can be done.e.g. https://sluglibrary.comMeshes and SDFs are much simpler on the GPU side but scaling them up too much can compromise accuracy, and scaling meshes down too much can introduce aliasing.\n \nreply",
      "Another example of this by Evan Wallace (founder of Figma): https://medium.com/@evanwallace/easy-scalable-text-rendering... (code: https://github.com/evanw/theta)\n \nreply"
    ],
    "link": "https://poniesandlight.co.uk/reflect/debug_print_text/",
    "first_paragraph": "Sometimes, all you want is to quickly print some text into a Renderpass. But traditionally, drawing text requires you first to render all possible glyphs of a font into an atlas, to bind this atlas as a texture, and then to render glyphs one by one by drawing triangles on screen, with every triangle picking the correct glyph from the font atlas texture.This is how imgui does it, how anyone using stb_truetype does it, and it\u2019s delightfully close to how type setting used to be done ages bygone on physical letterpresses.\n\n\n\n    Case in point: Some ancient Letterpress Type Cases (public domain) \u2013 sourceIn case you wonder \u2013 yesThat\u2019s enough (ed).\n\nQuaint, correct, but also quite cumbersome.What if \u2013 for quick and dirty debug messaging \u2013 there was a simpler way to do this?Here, I\u2019ll describe a technique for texture-less rendering of debug text. On top of it all, it draws all the text in a single draw call.How can we get rid of the font atlas texture? We\u2019d need to store a font atlas or someth"
  },
  {
    "title": "HPV vaccination: How the world can eliminate cervical cancer (ourworldindata.org)",
    "points": 297,
    "submitter": "ZeroGravitas",
    "submit_time": "2024-11-04T19:49:16 1730749756",
    "num_comments": 126,
    "comments_url": "https://news.ycombinator.com/item?id=42045373",
    "comments": [
      "Sometimes anti-vaxxers will point to the ostensibly high rate of serious adverse events exhibited by study participants in HPV vaccine trials. For example, in the study 'A 9-Valent HPV Vaccine against Infection and Intraepithelial Neoplasia in Women' published in The New England Journal of Medicine in 2015, in which the 9-Valent HPV vaccine was compared to the Quadrivalent version, the rate of serious adverse events was 3.3% and 2.6% respectively. This objection can be dismissed, as the study authors found that 0.0% of those serious adverse events were vaccine related.Anti-vaxxers also sometimes object to studies like these on the basis that no placebo arm was included, and thus the true safety profile of the vaccine cannot be ascertained, but this can be flatly rejected because, as the study authors point out, '[s]ince HPV vaccination is widely recommended and has been shown to prevent HPV disease related to oncogenic HPV types, the use of a placebo was not considered to be acceptable for ethical reasons.'\n \nreply",
      "Because HPV vaccination is relatively modern, there's trail where maybe the trial for the vaccine you can get today A, was A vs B, but then the previous B has a trial B v Placebo, or it might go back twice, A v B then B v C and C v placebo. There were placebo trials for the early HPV vaccines decades ago.I had Hodgkins Lymphoma (many years ago now when I was young) and we've been treating that for so long that the earliest curative treatments pre-date scientific medicine. So the trail dries up - we have no proof that the cures are better than nothing except, you know, circumstantially it sure does seem like the freaks who reject treatment just drop dead and I didn't so...They're still doing research, as with the HPV vaccines they do A v B trials as a placebo would be unethical - it's basically a death sentence. I actually wasn't selected for a trial comparing Stanford V (a new potential therapy from Stanford) against the current gold standard (which I was getting) ABVD. That was a long time ago, but I think the gold standard today is still ABVD.\n \nreply",
      "I think it\u2019s funny how in the US the vaccine schedule says not to get the HPV vaccine if you\u2019re over 45. That means that insurance won\u2019t cover it and I even struggle finding a doctor who will administer it because it goes against the guidelines.The rationale is that if you\u2019re 45, you probably already have HPV. But that assumes that you\u2019ve been sexually active all that time. It doesn\u2019t take into account people who were monogamous until their 50s and then started having sex with new partners.\n \nreply",
      "I also got the vaccine at 44 (years later than it is recommended where I live in Europe), because:- It targets multiple HPV strains, and even though I've been sexually active, I'm probably unlikely to have all of them, so there is some future protection- It helps prevent reinfection- There is evidence that it helps reduce the risk of progression to a cancerous state, which is also something that can happen for malesI didn't even bother to talk to a doctor, I just called a women's clinic, made an appointment, and paid for it myself. They were surprised, but super happy and supportive.All three injections cost me the equivalent of 160 US$.\n \nreply",
      "What country is that? I'm 42, male/ Spain, and I also have to pay for them out of pocket, but it's around 190\u20ac EACH of the three doses.\n \nreply",
      "It's similarly expensive here in Singapore, so I got just one dose.Some studies have suggested that even one dose of Gardasil 9 is enough:https://www.thelancet.com/journals/langlo/article/PIIS2214-1...https://pmc.ncbi.nlm.nih.gov/articles/PMC7455166/https://pmc.ncbi.nlm.nih.gov/articles/PMC10480621/\n \nreply",
      "> There is evidence that it helps reduce the risk of progression to a cancerous stateI have not been able to find this. Do you happen to have a link to a paper?\n \nreply",
      ">All three injections cost me the equivalent of 160 US$.Oh wow in Germany it's 180\u20ac a pop.\n \nreply",
      "I got it when I was around 40. Before getting the three doses, I would get 3-4 nasty viral sore throats per year (white blistery lesions, very painful). Now I get zero. I was probably on my way to getting throat cancer like Michael Douglas. Hopefully I have avoided or at least forestalled that.\n \nreply",
      "Thought it doesn't help against the strains that you're already infected with? Hence the min and max ages in the guidance.\n \nreply"
    ],
    "link": "https://ourworldindata.org/hpv-vaccination-world-can-eliminate-cervical-cancer",
    "first_paragraph": ""
  },
  {
    "title": "Obtainium: Get Android App Updates Directly from the Source (imranr.dev)",
    "points": 159,
    "submitter": "janandonly",
    "submit_time": "2024-11-02T13:24:05 1730553845",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=42026251",
    "comments": [
      "Love this app, makes it really easy to keep non-store apps up to date by linking directly to the apps GitHub repo for example.Obviously you have to be careful what you install, just as with any app not found in Play Store, but if you're getting your apps elsewhere anyway this is really convenient.\n \nreply",
      "> just as with any app not found in Play StoreI would recommend caution with apps from the store too. Not only are many predatory practices not disallowed, outright malware can and does slip through review. The advice is the same as ever when it comes to computers: don't run programs you don't trust, and set your bar of trust high.\n \nreply",
      "it's worse than that imo. People claim the web is dangerous because it runs untrusted code but apps do the same with auto updates from stores and that the majority of apps are just webviews running code from the net but without the same level of sandboxing as a browser\n \nreply",
      "Agree, the play store isn't secure one bit.We hear enough story how Google removes legit app without reason, using automated process, to know that there is at least as much malicious app that goes through being undetected.\n \nreply",
      "Alright, well I don't think I personally know anyone who has ended up with malware on their phone. I'm sure it could be better but it seems alright. I'm not gonna advise everyone I know to stress out about it by trying to have a high bar of trust and evaluate every app they wanna try only to have the exact same result they've had for years.The advice is absolutely not the same as it's always been - it would be weird if the advice from the early aughts, when it was common to be affected by malware or viruses, was the same as the advice now when it's rare.\n \nreply",
      "You knowing someone personally is different from the objective millions of infections [0] that we've seen in the real world.[0] https://www.tomsguide.com/news/these-35-malicious-android-ap...\n \nreply",
      "Nevermind that being downloaded a million times doesn't mean by a million people, as scammers download their own app to boost numbers -- a million is what, 1 in a few thousand smartphone users?I'd love it to be zero but the amount of vigilance warranted has gotta be a lot less than it was in the past unless there's some argument that magnitude of harm has gone up by a massive amount while probability has gone down by the same amount. Which, idunno, maybe that argument can be made actually.Also I guess 2001 felt unsafe to visit trusted websites, so the advice upthread was already a bit lessened.\n \nreply",
      "> Obviously you have to be careful what you installHow?\n \nreply",
      "I use this and it's great. Only problem is when: 1) you want something outside of github (from my experience, already gitlab and codeberg can be buggy here, although very rarely), and 2) when you need a specific release channel (example: Firefox Beta, which requires a bit of work). But overall it works great. Now, one has to consider the security aspects: stores like Google Play (and, to a lesser extent, F-Droid) do perform some antimalware checks. It's not bulletproof, but it gives a bit more trust in case the dev goes rogue or is compromised. BUT you have to trust the store. With Obtainium, you have to trust: 1) the app's developer 2) Github/Gitlab/Codeberg 3) Obtainium's developer. So, it depends what's your threat model. I'm looking forward to seeing wider adoption for Accrescent!\n \nreply",
      "Just the app I was looking for.\n \nreply"
    ],
    "link": "https://obtainium.imranr.dev/",
    "first_paragraph": ""
  },
  {
    "title": "SVDQuant: 4-Bit Quantization Powers 12B Flux on a 16GB 4090 GPU with 3x Speedup (hanlab.mit.edu)",
    "points": 150,
    "submitter": "lmxyy",
    "submit_time": "2024-11-09T07:46:22 1731138382",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=42093112",
    "comments": [
      "This is one in a long line of posts saying \"we took a model and made it smaller\" and now it can run with different requirements.It is important to keep in mind that modifying a model changes the performance of the resulting model, where performance is \"correctness\" or \"quality\" of output.Just because the base model is very performant does not mean the smaller model is.This means that another model that is the same size as the new quantized model may outperform the quantized model.Suppose there are equal sized big models A and B with their smaller quantized variants a and b. A being a more performant model than B does not guarantee a being more performant than b.\n \nreply",
      "While I think I agree that there are many posts here on HackerNews announcing a new model compression technique, your characterization above understates the technical innovations and practical impacts described in this MIT paper.Unlike traditional model compression work that simply applies existing techniques, SVDQuant synthesizes several ideas in a comprehensive new approach to model quantization:- Developing a novel outlier absorption mechanism using low-rank decomposition \u2014 this aspect alone seems quite novel, although the math is admittedly way beyond my level- Combining SVD with smoothing in a way that specifically \naddresses the unique challenges of diffusion models- Creating an innovative kernel fusion technique (they call it \u201cNunchaku\u201d) that makes the theoretical benefits practically realizable, because without this, the extra computation required to implement the above steps would simply slow the model back down to baselineThis isn't just incremental improvement - the paper achieves several breakthrough results:- First successful 4-bit quantization of both weights AND activations for diffusion models- 3.5x memory reduction for 12B parameter models while maintaining image quality- 3.0x speedup over existing 4-bit weight-only quantization approaches- Enables running 12B parameter models on consumer GPUs that previously couldn't handle themAnd, I\u2019ll add, as someone who has been following the diffusion space quite actively for the last two years, the amount of creativity that can be unleashed when models are accessible to people with consumer GPUs is nothing short of astonishing.The authors took pains to validate their approach by testing it against three models (Flux, PixArt-Sigma, and SDXL) and along several quality-comparison axes (FID score, Image Reward, LPIPS, and PSNR). They also did a proper ablation study to see the contribution of each component in their approach to image quality.What particularly excites me about this paper is not the ability to run a model that eats 22GB of VRAM in just 7GB. The exciting thing is the prospect of running a 60GB model in 20GB of VRAM. I\u2019m not sure whether anyone has or is planning to train such a monster, but I suspect that Midjourney, OpenAI, and Google all have significantly larger models running in their infrastructure than what can be run on consumer hardware. The more dimensions you can throw at image and video generation, the better things get.\n \nreply",
      "I definitely agree that there may be some interesting advancements here.I am trying to call attention to the models used for evaluation comparison. There are 3 factors: inference speed/latency, model size in total loaded VRAM, and model performance in terms of output.Comparisons should address all of these considerations, otherwise it's easy to hide deficiencies.\n \nreply",
      "The site literally has a quick visual comparison near the top, which shows that theirs is the closest to 16bit performance compared to the others. I don't get what more you'd want.https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/...\n \nreply",
      "These are comparisons to other quantizing methods. That is fine.What I want to see is comparisons to NON-quantized models all with around the same VRAM along with associated inference latencies.Also, we would want to see the same quantizing schemes applied to other base models.. because perhaps the paper's proposed quantizing scheme only beats others using a particular base model.\n \nreply",
      "They tested the quantisation on 3 different models.They also show it has little to no effect relative to fp16 on these models.IMO that's enough. Comparison against smaller models is much less useful because you can't use the same random seeds. So you end up with a very objective \"this is worse\" based purely on aesthetic preferences of one person vs another. You already see this with Flux Schnell vs. the larger Flux models.\n \nreply",
      "I disagree.They report that their method produces a model that is 6.5 GB from flux (22.7GB). Why wouldn't you want to know how their 6.5GB model compares to other 6.5GB models?Regarding aesthetic prefs: it's an open problem what an appropriate metric is for GenAI... LLM arena is widely regarded as a good way to measure LLMs and that's user preferences.In any case, the authors report LPIPs etc. They could do the same for other small models.\n \nreply",
      ">What I want to see is comparisons to NON-quantized modelsisnt that the first image in the diagram / the 22GB model that took 111 seconds?\n \nreply",
      "I'm really confused, this looks like concern trolling because there's a live demo for exactly this A/B testing, that IIRC was near the top of the article, close enough it was the first link I clicked.But you're quite persistent in that they need to address this, so it seems much more likely they silently added it after your original post, or you didn't click through, concern trolling would stay more vague\n \nreply",
      "As others have replied, this is reasonable general feedback, but in this specific case the work was done carefully. Table 1 from the linked paper  (https://arxiv.org/pdf/2411.05007) includes a variety of metrics, while an entire appendix is dedicated to quality comparisons.By showing their work side-by-side with other quantization schemes, you can also see a great example of the flavor of different results you can get with these slight tweaks (e.g., ViDiT INT8) and that their quantization does a much better job in reproducing the \"original\" (Figure 15).In this application, it's not strictly true that you care to have the same results, but this work does a pretty good job of it.\n \nreply"
    ],
    "link": "https://hanlab.mit.edu/blog/svdquant",
    "first_paragraph": "A new post-training training quantization paradigm for diffusion models, which quantize both the weights and activations of FLUX.1 to 4 bits, achieving 3.5\u00d7 memory and 8.7\u00d7 latency reduction on a 16GB laptop 4090 GPU.\n\nCheck our interactive demo at https://svdquant.mit.edu! Our quantization library is at github.com/mit-han-lab/deepcompressor and inference engine is at github.com/mit-han-lab/nunchaku. Our paper is at this link.SVDQuant is a post-training quantization technique for 4-bit weights and activations that well maintains visual fidelity. On 12B FLUX.1-dev, it achieves 3.6\u00d7 memory reduction compared to the BF16 model. By eliminating CPU offloading, it offers 8.7\u00d7 speedup over the 16-bit model when on a 16GB laptop 4090 GPU, 3\u00d7 faster than the NF4 W4A16 baseline. On PixArt-\u2211, it demonstrates significantly superior visual quality over other W4A4 or even W4A8 baselines.Diffusion models are revolutionizing AI with their ability to generate high-quality images from text prompts. To i"
  },
  {
    "title": "Trellis (YC W24) is hiring eng to turn documents into database (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-11-09T17:01:12 1731171672",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/trellis/jobs/1ypWafM-founding-engineer-full-time-backend-ml-infra",
    "first_paragraph": ""
  }
]