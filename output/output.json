[
  {
    "title": "Quantized Llama models with increased speed and a reduced memory footprint (meta.com)",
    "points": 248,
    "submitter": "egnehots",
    "submit_time": "2024-10-24T18:52:44 1729795964",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=41938473",
    "comments": [
      "So SpinQuant learns a rotation for activations and weights that, to my understanding, \"smear\" the outlier weights out so you don't get extreme values in any one weight.Random anecdote warning - In the old days, before vector search became AI and everyone and their dog offered a vector database, I had a task that required nearest neighbour search in a decent amount of high-dimensional vectors.I tried quantizing them to bit vectors in an index and scanning through it to get an initial set of candidates.\nPerformance was actually quite decent - reading through RAM linearly is fast! But the selectivity wasn't great.Somewhere along the way I found this paper[1] that iteratively finds a rotation to apply before quantization to reduce the quantization error. Very similar goal to SpinQuant, but focused on bit quantization only.As it turns out the 'random rotation' baseline they benchmark against worked great for my use case, so I never tried implementing the fancier algorithm. But it's a pretty rare day at work that \"apply a random rotation matrix to a 128-dimensional vector\" is the solution to my problem.[1] https://ieeexplore.ieee.org/abstract/document/6296665 / https://slazebni.cs.illinois.edu/publications/ITQ.pdf\n \nreply",
      "> But it's a pretty rare day at work that \"apply a random rotation matrix to a 128-dimensional vector\" is the solution to my problem.Funny enough, if you visualize a vector-embedding's latent-space features using that \"points on a the surface of a hypersphere\" analogy that ML programmers like to use \u2014 and you assume a really low quantization, say, 1-bit \u2014 then you can almost picture the hypersphere surface as a black-and-white vector image, the points as arbitrary-precision vector positions where you want to place dots... and your goal as quantizing those positions to reduce the storage costs down to storing a raster bitmap.And that problem has a name: dithering!Oddly enough, for what may or may not be coincidental reasons, what we want in ML terms (keeping the learned associational weights between features constant) is very similar to what we want from the output of image dithering: to not allow the dots to come together to create false features or false voids.And how do we do that? In dithering, we usually apply a set of random perturbations to the vectorized points. Which, for image dithering, just look like translations in 2D space... but, in a higher-dimensional space, might very well best be analytically modelled as rotations about the origin!\n \nreply",
      "I'm sorry, I don't understand the language you're speaking. English please?(Just kidding - but if you have any recommendations for learning resources to get started being able to understand what you're talking about, I'd greatly appreciate it.)\n \nreply",
      "I find the geometrical intuition of rotating a vector in high dimensional space to minimize its largest values (vector basis projections) beautiful.I'm no expert and I'm sure this has been tried by many people already - but would it be possible to reduce the computational effort instead by using SVD decomposition, spreading the singular values and then reapplying the original singular values and recomposing the matrix using the quantized versions of the SVD matrices?\n \nreply",
      "Tangentially related to the idea of \"apply a random rotation matrix\" is one where you apply a random matrix to a set of points to preserve distances between them but transform them into a lower dimensional space. This is captured by the JL Lemma [1].[1] - https://en.wikipedia.org/wiki/Johnson%E2%80%93Lindenstrauss_...\n \nreply",
      "It's pretty interesting that the new SpinQuant method did not manage to be better than good old nf4bit QLORA training (Tim Dettmers really cooked with that one).Really appreciate that Meta published both results+model quants and didn't just make some bs claim about a new sota quant like most other bigger companies would've done.\n \nreply",
      "It\u2019s a little bizarre that I feel like I\u2019m actually starting to respect this little bit of Meta\u2026\n \nreply",
      "I think meta and facebook before it have always valued a very high standard of engineering, and have also been generally pretty good about open sourcing a lot of that work in a way that allows a lot of people to work with their tools. This doesn\u2019t seem all that out of character.\n \nreply",
      "It's a huge company with a lot of different voices.  One may create react and open source it while another would add a clause that if you sue facebook over anything your react license disappears.  When they are good they are really good.\n \nreply",
      "I mean, it's no free lunch, you still need to expend significantly more compute for the QLoRA training compared to any usual PTQ method, be it SpinQuant or any other more conventional quantization approaches.\n \nreply"
    ],
    "link": "https://ai.meta.com/blog/meta-llama-quantized-lightweight-models/?_fb_noscript=1",
    "first_paragraph": "TakeawaysAt Connect 2024 last month, we open sourced Llama 3.2 1B and 3B\u2014our smallest models yet\u2014to address the demand for on-device and edge deployments. Since their release, we\u2019ve seen not just how the community has adopted our lightweight models, but also how grassroots developers are quantizing them to save capacity and memory footprint, often at a tradeoff to performance and accuracy.As we\u2019ve shared before, we want to make it easier for more developers to build with Llama, without needing significant compute resources and expertise. Today, we\u2019re sharing quantized versions of Llama 3.2 1B and 3B models. These models offer a reduced memory footprint, faster on-device inference, accuracy, and portability\u2014all while maintaining quality and safety for developers to deploy on resource-constrained devices. Given the limited runtime memory available on mobile devices, we prioritized short-context applications up to 8K for these new quantized models. Our results show we can achieve superior"
  },
  {
    "title": "Why Safety Profiles Failed (circle-lang.org)",
    "points": 81,
    "submitter": "pjmlp",
    "submit_time": "2024-10-24T21:26:09 1729805169",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=41939967",
    "comments": [
      "At this point I'm wondering if the purpose of safety profiles is simply to serve as a distraction. In other words, safety profiles are just something people can point to when the topic of memory safety comes up, that\u2019s it. The objectives of the initiative always seemed hopelessly optimistic, if not absurd. In particular, I don't understand why littering a codebase with auto, const, constexpr, inline, [[nodiscard]], noexcept, etc is wonderful, yet lifetime annotations are somehow an intolerable tyranny.\n \nreply",
      "The article makes the particularly good point that you generally can\u2019t effectively add new inferences without constraining optionality in code somehow. Put another way, you can\u2019t draw new conclusions without new available assumptions.In Sean\u2019s \u201cSafe C++\u201d proposal, he extends C++ to enable new code to embed new assumptions, then subsets that extension to permit drawing new conclusions for safety by eliminating code that would violate the path to those safety conclusions.\n \nreply",
      "Really glad to see this thorough examination of the weaknesses of profiles. Safe C++ is a really important project, and I hope the committee ends up making the right call here.\n \nreply",
      ">...I hope the committee ends up making the right call here.WG21 hasn't been able to solve the restrict type qualifier, or make a better alternative, in over twenty years. IMO, hoping that WG21 adequately solves Safe C++ is nothing more than wishful thinking, to put it charitably.\n \nreply",
      "I am intimately familiar with the dysfunctions of various language committees.I never said it would be easy, or probable. But I\u2019m also the kind who hopes for the best.\n \nreply",
      "> Safe C++ is a really important projectWhat makes you say this? It seems to me like we already have a lower-overhead approach to reach the same goal (a low-level language with substantially improved semantic specificity, memory safety, etc.); namely, we have Rust, which has already improved substantially over the safety properties of C++, and offers a better-designed platform for further safety research.\n \nreply",
      "Not everything will be rewritten in Rust. I've broken down the arguments for why this is, and why it's a good thing, elsewhere [1].Google's recent analysis on their own experiences transitioning toward memory safety provide even more evidence that you don't need to fully transition to get strong safety benefits. They incentivized moving new code to memory safe languages, and continued working to actively assure the existing memory unsafe code they had. In practice, they found that vulnerability density in a stable codebase decays exponentially as you continue to fix bugs. So you can reap the benefits of built-in memory safety for new code while driving down latent memory unsafety in existing code to great effect. [2][1]: https://www.alilleybrinker.com/blog/cpp-must-become-safer/[2]: https://security.googleblog.com/2024/09/eliminating-memory-s...\n \nreply",
      "> Not everything will be rewritten in Rust.Yeah, but it's also not going to be rewritten in safe C++.\n \nreply",
      "There\u2019s likely some amount of code which would not be rewritten into Rust but which would be rewritten into safe C++. Migrating to a whole new language is a much bigger lift than updating the compiler you\u2019re already using and then modifying code to use things the newer compiler supports. Projects do the latter all the time.",
      "I am pro any movement towards memory safety. Sure, I won't stop writing Rust and start moving towards C++ for this. But not everyone is interested in introducing a second toolchain, for example. Also, as this paper mentions, Safe C++ can improve C++ <-> Rust interop, because Safe C++ can express some semantics Rust can understand. Right now, interop works but isn't very nice.Basically, I want a variety of approaches, not a Rust monoculture.\n \nreply"
    ],
    "link": "https://www.circle-lang.org/draft-profiles.html",
    "first_paragraph": "As for dangling pointers and for ownership, this model\ndetects all possible errors. This means that we can guarantee\nthat a program is free of uses of invalidated pointers.\u2013 A brief introduction to C++\u2019s model for type- and resource-\nsafety[type-and-resource-safety-2015]Safety Profiles were introduced in 2015 with the promise to detect\nall lifetime safety defects in existing C++ code. It was a bold claim.\nBut after a decade of effort, Profiles failed to produce a\nspecification, reliable implementation or any tangible benefit for C++\nsafety. The cause of this failure involves a number of mistaken premises\nat the core of its design:The parameters of the problem make success impossible. This paper\nexamines the contradictions in these premises, explains why the design\ndidn\u2019t improve safety in the past and why it won\u2019t improve safety in the\nfuture.Zero annotation is required by default, because existing C++\nsource code already contains sufficient information.\u2013 Pursue [P1179R1] as a Lifetime"
  },
  {
    "title": "Launch HN: Skyvern (YC S23) \u2013 open-source AI agent for browser automations (github.com/skyvern-ai)",
    "points": 230,
    "submitter": "suchintan",
    "submit_time": "2024-10-24T15:51:21 1729785081",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=41936745",
    "comments": [
      "Probably not the first AI wrapper around Playwright this week, and certainly not the first this month.I think this use case of automation in a BPA sense is more compelling than using it for test automation, because the latter is much more concerned with the precision and repeatability of the process. For the BPA task, arguably you care only about the outcome and it often doesn't matter if it gets there via some crazy route.Part of the problem for me is that your example video shows a big wodge of prompt that had to be written to make this work and then a few kb of payload data (parameters) in a plaintext, non-csv format. If the expectation is that this replaces someone just using Playwright with codegen due to that being too technical, I'm not convinced there is a huge group of people who can manage one task but not the other.Furthermore, you are expecting them to pass over their website login credentials and apparently their credit card details too, in plain text. You had better have a very solid idea of how to handle that sensitive data to avoid serious consequences if your users' skyvern accounts are compromised.I think the frequency of website redesigns is oversold by people producing these LLM-driven Playwright wrappers, especially when  targeting old-fashioned or government sites. As an example, we have had a suite of lengthy Playwright browser automations to interact with a government site for a few years and have had to maintain them only once, when the agency's business process changed. The prompt would also have needed to change had we used Skyvern, as would the payload, because the process was different. The difference with the Playwright automation, though, is that we could use assertions to verify steps had succeeded/failed and data had been recorded correctly, so we would know the process needed updating. I can't see that option in Skyvern which would have me worrying that process changes would be overlooked and we would unknowingly start entering the wrong data or missing steps.\n \nreply",
      "You're making some really good points here1/ the current prompt + payload structure is definitely on the complicated end of the spectrum, but we've found that we can use an LLM to help generate this payload for our usersThe technical users want to learn more and generate their own payloads, and the non technical users prompt LLMs to help them generate the ultimate skyvern prompt to get goingThis was very unexpected -- but a surprisingly logical chain of events.Phase 1: build the thing the complex way (playwright)\nPhase 2: build the playwright thing with complex prompts (we are here right now)\nPhase 3: build the thing that builds the playwright thing with simpler promptsEach phase lowers the technical bar to build your automations2/ re: frequency of website changesThis IMO is a smaller value prop of LLM based automations. The biggest one is being able to handle highly dynamic situations. Consider the case where you're automating an e-commerce website where the popup offer changes every week. skyvern doesn't even notice those, but playwright scripts would breakSimilarly, I love using the Geico example because it highlights something that was very difficult to automate before: The form changes every time you run itSkyvern breezes through it.. but another case that was hard to automate before.3/ data correctnessWe're actually rolling out a workflows feature that allows you to chain multiple tasks together. The cool thing about this feature is that you can add steps in to have Skyvern self-validate it's own unless before continuing.For example, you can add n products to cart, then navigate to the cart and validate the cart state... As you can guess, this creates the foundation to have another agent go and use these tools to self-build workflows with simpler promptsTL;DR -- we're on a pretty long journey to use LLMs to make BPA easier and easier, and this is just the first step\n \nreply",
      "Congrats on the launch! I've been keeping up with you folks since you last posted (a few months ago, I believe). How does Anthropic's recent announcement of Claude's \"computer use\" abilities grab you? What key differentiators does Skyvern have, at this point in time (\"computer use\" with Claude being relatively new)?\n \nreply",
      "I work in this space and Claude's ability to count pixels and interact with a screen using precise coordinates seems like a genuinely useful innovation that I expect will improve upon existing approaches.Existing approaches tend to involve drawing marked bounding boxes around interactive elements and then asking the LLM to provide a tool call like `click('A12')` where A12 remaps to the underlying HTML element and we perform some sort of Selenium/JS action. Using heuristics to draw those bounding boxes is tricky. Even performing the correct action can be tricky as it might be that click handlers are attached to a different DOM element.Avoiding this remapping between a visual to an HTML element and instead working with high level operations like `click(x, y)` or `type(\"foo\")` directly on the screen will probably be more effective at automating usecases.That being said, providing HTML to the LLM as context does tend to improve performance on top of just visual inference right now.So I dunno... I'm more optimistic about Claude's approach and am very excited about it... especially if visual inference continues to improve.\n \nreply",
      "Agreed. In the short term (X months) I expect the HTML Distillation + giving text to LLMs to win out.. but the long term (Y years) screenshot only + pixels will definitely be the more \"scalable\" approachOne very subtle advantage of doing HTML analysis is that you can cut out a decent number of LLM calls by doing static analysis of the pageFor example, you don't need to click on a dropdown to understand the options behind it, or scroll down on a page to find a button to click.Certainly, as LLMs get cheaper the extra LLM calls will matter less (similar to what we're seeing happen with Solar panels where cost of panel < cost of labour now, but was reversed the preceding decade)\n \nreply",
      "Great question -- I was waiting for someone to ask this!Their product and launch is super cool. It's incredible how much it's able to do by just relying on tool use + micro agents + screen shots + coordinates to interact with websites.There are a couple of thoughts here:(1) Will their competitors wait around and not build something similar? Will xAI / Gemini / OpenAI / Mistral / MetaAI teams wait around? Probably not. This is likely a huge part of the future, and one company will not \"take it all\"(2) How is value actually derived from these systems? Is a demo + cool usable product enough? Likely not. Most people actually want their workflow automated. For personal use-cases, this might be enough.. but enterprises likely want something more complex(3) Will this be optimized for Claude only? What if you want to run this with your own open source LLMs? Or you want to point this at the best model on the market all the time? Will you get that flexibility through a solution provided by a big player? Likely not -- Anthropic has incentive to get you to use Claude under the hoodThe last point is the one that gives me hope. Our open source users are able to pick their favourite model to run on. You're not locked into Cluade. You can run it on Gemini / GPT-4O or open source ones such as Llama 3.2.\n \nreply",
      "Congrats on the launch! \nCurious to know, which OSS models you see works best at the moment?\n \nreply",
      "We've had a decent amount of luck with InternVL 2.0 w/ Llama, and are pretty excited about Llama 3.2It's still super early in the open source x vision model space. The limiter actually seems to be the vision encoder -- advancements here will pay off huge dividendshttps://huggingface.co/spaces/opencompass/open_vlm_leaderboa...\n \nreply",
      "Thank you! Great insight.\n \nreply",
      "Anyone building a start-up on 3rd party LLMs at this point has to have some big cajones. Or you need a smash-and-grab business model. Serious risk if your horizon is measured in years instead of months.Anthropic threw their hat in this ring yesterday, and it will very likely be followed by OpenAI and Google soon. Godspeed.\n \nreply"
    ],
    "link": "https://github.com/Skyvern-AI/Skyvern",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Automate browser-based workflows with LLMs and Computer Vision\n      \n\ud83d\udc09 Automate Browser-based workflows using LLMs and Computer Vision \ud83d\udc09\n\n\n\n\n\n\n\n\nSkyvern automates browser-based workflows using LLMs and computer vision. It provides a simple API endpoint to fully automate manual workflows on a large number of websites, replacing brittle or unreliable automation solutions.\n\nTraditional approaches to browser automations required writing custom scripts for websites, often relying on DOM parsing and XPath-based interactions which would break whenever the website layouts changed.Instead of only relying on code-defined XPath interactions, Skyvern relies on prompts in addition to computer vision and LLMs to the mix to parse items in the viewport in real-time, create a plan for interaction and interact with them.This approach gives us a few "
  },
  {
    "title": "Bitwarden SDK relicensed from proprietary to GPLv3 (github.com/bitwarden)",
    "points": 42,
    "submitter": "ferbivore",
    "submit_time": "2024-10-24T22:41:03 1729809663",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41940580",
    "comments": [
      "https://github.com/bitwarden/clients/issues/11611#issuecomme...> We have made some adjustments to how the SDK code is organized and packaged to allow you to build and run the app with only GPL/OSI licenses included. The sdk-internal package references in the clients now come from a new sdk-internal repository, which follows the licensing model we have historically used for all of our clients (see LICENSE_FAQ.md for more info). The sdk-internal reference only uses GPL licenses at this time. If the reference were to include Bitwarden License code in the future, we will provide a way to produce multiple build variants of the client, similar to what we do with web vault client builds.\n \nreply",
      "Bitwarden is still excellent, but keep an eye on them over the next few years. Remember that Bitwarden was originally a LastPass alternative without the fuckery.\n \nreply",
      "GPLv3 is interesting because it means to use their code in a commercial setting, then you must also have the guts to open source too.\n \nreply",
      "I don\u2019t believe that is entirely accurate. I believe it depends on the application and what you\u2019re doing with it whether or not you would be required to open source it. Like, if you\u2019re distributing the application as a product, not necessarily saas application?\n \nreply",
      "Well that\u2019s one way to handle that effectively and in what seems to be open source way without fuckery; glad to hear it cause that was going to be a bit annoying migrating away from them.\n \nreply",
      "Props for them to step in the right direction, it wasn\u2019t obvious at all for a few days what they would do.\n \nreply",
      "Also: https://github.com/bitwarden/clients/issues/11611#issuecomme...Previously: https://news.ycombinator.com/item?id=41893994\n \nreply"
    ],
    "link": "https://github.com/bitwarden/sdk-internal/commit/db648d7ea85878e9cce03283694d01d878481f6b",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n              Large diffs are not rendered by default.\n          \n              Large diffs are not rendered by default.\n          \n              Large diffs are not rendered by default.\n          \n              Large diffs are not rendered by default.\n          \n              Large diffs are not rendered by default.\n          "
  },
  {
    "title": "Security research on Private Cloud Compute (security.apple.com)",
    "points": 171,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-24T17:36:06 1729791366",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=41937664",
    "comments": [
      "I've been working on technology like this for the past six years.The benefits of transparent systems are likely considerable. The combination of reproducible builds, remote attestation and transparency logging allows trivial detection of a range of supply chain attacks. It can allow users to retroactively audit the source code of remote running systems. Yes, there are attacks that the threat model doesn't protect against. That doesn't mean it isn't immensely useful.\n \nreply",
      "I feel like this is all smoke and mirrors to redirect from the likelihood intentional silicon backdoors that are effectively undetectable. Without open silicon, there's no way to detect that -- say -- when registers r0-rN are set to values [A, ..., N] and a jump to address 0xCONSTANT occurs, additional access is granted to a monitor process.Of course, this limits the potential attackers to 1) exactly one government (or N number of eyes) or 2) one company, but there's really no way that you can trust remote hardware.This _does_ increase the trust that the VMs are safe from other attackers, but I guess this depends on your threat model.\n \nreply",
      "> I feel like this is all smoke and mirrors to redirect from the likelihood intentional silicon backdoors that are effectively undetectable.The technologies Apple PCC is using has real benefits and is most certainly not \"all smoke and mirrors\". Reproducible builds, remote attestation and transparency logging are individually useful, and the combination of them even more so.As for the likelihood of Apple launching Apple PCC to redirect attention from backdoors in their silicon, that seems extremely unlikely. We can debate how unlikely, but there are many far more likely explanations. One is that Apple PCC is simply good business. It'll likely reduce security costs for Apple, and strengthen the perception that Apple respects users' privacy.> when registers r0-rN are set to values [A, ..., N] and a jump to address 0xCONSTANT occursI would recommend something more deniable, or at the very least something that can't easily be replayed. Put a challenge-response in there, or attack the TRNG. It is trivial to make a stream of bytes appear random while actually being deterministic. Such an attack would be more deniable, while also allowing a passive network attacker to read all user data. No need to get code execution on the machines.\n \nreply",
      "Apple forgot to disable some cache debugging registers a while back which in effect was similar to something GP described, although exploitation required root privileges and would allow circumventing their in-kernel protections; protections most other systems do not have. (And they still didn't manage to achieve persistence, despite having beyond-root privileges).\n \nreply",
      "> Apple forgot to disable some cache debugging registers a while back which in effect was similar to something GP describedThank you for bringing that up. Yes, it is an excellent example that proves the existence of silicon vulnerabilities that allow privilege escalation. Who knows whether it was left there intentionally or not, and if so by whom.I was primarily arguing that (1) the technologies of Apple PCC are useful and (2) it is _very_ unlikely that Apple PCC is a ploy by Apple, to direct attention away from backdoors in the silicon.\n \nreply",
      "20231227 https://news.ycombinator.com/item?id=38783112 Operation Triangulation: What you get when attack iPhones of researchers20231229 https://news.ycombinator.com/item?id=38801275 Kaspersky discloses iPhone hardware feature vital in Operation Triangulation\n \nreply",
      "If you take as a fundamental assumption that all your hardware is backdoored by Mossad who has unlimited resources and capacity to intercept and process all your traffic, the game is already lost and there\u2019s no point in doing anything.If instead you assume your attackers have limited resources, things like this increase the costs attackers have to spend to compromise targets, reducing the number of viable targets and/or the depth to which they can penetrate them.One of these threat models is actually useful.\n \nreply",
      "This is an interesting idea. However what does open hardware mean? How can you prove that the design or architecture that was \u201copened\u201d is actually what was built? What does the attestation even mean in this scenario?\n \nreply",
      "> what does open hardware mean?Great question. Most hardware projects I've seen that market themselves as open source hardware provide the schematic and PCB design, but still use ICs that are proprietary. One of my companies, Tillitis, uses an FPGA as the main IC, and we provide the hardware design configured on the FPGA. Still, the FPGA itself is proprietary.Another aspect to consider is whether you can audit and modify the design artefacts with open source tooling. If the schematics and PCB design is stored in a proprietary format I'd say that's slightly less open source hardware than if the format was KiCad EDA, which is open source. Similarly, in order to configure the HDL onto the FPGA, do you need to use 50 GB of proprietary Xilinx tooling, or can you use open tools for synthesis, place-and-route, and configuration? That also affects the level of openness in my opinion.We can ask similar questions of open source software. People who run a Linux distribution typically don't compile packages themselves. If those packages are not reproducible from source, in what sense is the binary open source? It seems we consider it to be open source software because someone we trust claimed it was built from open source code.\n \nreply",
      "And what attestation do you have that the FPGA isn't compromised.We can play this game all the way down.\n \nreply"
    ],
    "link": "https://security.apple.com/blog/pcc-security-research/",
    "first_paragraph": "Private Cloud Compute (PCC) fulfills computationally intensive requests for Apple Intelligence while providing groundbreaking privacy and security protections \u2014 by bringing our industry-leading device security model into the cloud. In our previous post introducing Private Cloud Compute, we explained that to build public trust in the system, we would take the extraordinary step of allowing security and privacy researchers to inspect and verify the end-to-end security and privacy promises of PCC. In the weeks after we announced Apple Intelligence and PCC, we provided third-party auditors and select security researchers early access to the resources we created to enable this inspection, including the PCC Virtual Research Environment (VRE).Today we\u2019re making these resources publicly available to invite all security and privacy researchers \u2014 or anyone with interest and a technical curiosity \u2014 to learn more about PCC and perform their own independent verification of our claims. And we\u2019re exc"
  },
  {
    "title": "Brush \u2013 A new compatible Gaussian splatting engine (github.com/arthurbrussee)",
    "points": 89,
    "submitter": "Tycho87",
    "submit_time": "2024-10-24T19:24:36 1729797876",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41938831",
    "comments": [
      "A request for everyone writing docs with content like this:>NOTE: This only works on desktop Chrome 129+ currently. Firefox and Safari are hopefully [supported soon](link), but currently even firefox nightly and safari technical preview do not work.This is great, especially with that link!  Thank you!  But please say when \"currently\" is, e.g. add an \"(Oct 2024)\".  Stuff like this tends to be time-sensitive on accuracy but not consistently updated and is often years out of date with no easy way for visitors to tell.And when it's recent, it also tells people that the project is active.\n \nreply",
      "Wow - the in-browser demo (https://arthurbrussee.github.io/brush-demo/) runs way more performantly and renders much better-looking results than any other I'd tried in the past.It loaded my 50MB .ply file almost instantly.  Orbiting around the scene is extremely smooth and everything is free of flickering or artifacts.I never tried out training a Gaussian splat from images/video myself before, but this tool makes me want to give it a go.\n \nreply",
      "Love to hear it!! Most viewers take some shortcuts, like only sorting every so often, it's good to hear the difference is noticable :)Training a splat requires a lot less setup with this, but does still require running COLMAP(https://github.com/colmap/colmap) first, which is still a big barrier... one thing at a time!\n \nreply",
      "What are splats actually useful for, and where are they used?\n \nreply",
      "Its really the latest incarnation in the field of Photogrammetry https://en.wikipedia.org/wiki/Photogrammetry - aka, converting 2D images / video to 3D data.Imagine one of those house tours on Zoopla on steroids, or street view but smoother.\n \nreply",
      "Corridor Channel had one great example: https://youtu.be/GaGcLhhhbDs?si=vDyeayLf8EAoE0gf&t=442Above includes the explanation. Final result is here:https://youtu.be/GaGcLhhhbDs?si=eoTniegWK-AVFoaF&t=751\n \nreply",
      "Splats are good for generating new images from an existing place even if no photograph exists from that exact viewpoint.They can be used for video special effects, for 3D images/video, and for VR. The technology is nascent but shows promise.\n \nreply",
      "One of the things thats held me back from being super interested in this field is that my understanding is that there is likely to be some kind of mesh backing needed for this to progress.IIRC some researchers had started to back the gaussians with a mesh to provide an editable artifact that would allow the gaussians to be moved and manipulated.Is this anywhere near being a standard feature yet?edit - ie https://arxiv.org/abs/2402.04796\n \nreply",
      "Gaussian splatting using Burn has been on my side project list for a while now. I guess they beat me to it! :)\n \nreply",
      "Does polycam suport splatting\n \nreply"
    ],
    "link": "https://github.com/ArthurBrussee/brush",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        3D Reconstruction for all\n      Brush is a 3D reconstruction engine, using Gaussian splatting. It aims to be highly portable, flexible and fast. 3D reconstruction shouldn't require special hardware. Brush can render and train on a wide range of systems: macOS/windows/linux, AMD/Nvidia cards, Android, and in a browser. To achieve this, brush is built using WebGPU compatible tech, that can run practically anywhere! It uses the Burn framework, which has a portable wgpu backend. This project is currently still a proof of concept, and doesn't yet implement any of the extensions to gaussian splatting that have been developed, nor is the performance optimal yet.Try the (experimental) web demo \nNOTE: This only works on desktop Chrome 129+ currently (Oct 2024). Firefox and Safari are hopefully supported soon, but currently even firefox night"
  },
  {
    "title": "Zigler: Zig NIFs in Elixir (github.com/e-xyza)",
    "points": 133,
    "submitter": "ksec",
    "submit_time": "2024-10-24T17:53:26 1729792406",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=41937815",
    "comments": [
      "For anyone mystified about what a NIF is that doesn't want to go read the docs.The BEAM VM (which is the thing that runs erlang / elixir / gleam / etc) has 3 flavors of functions.- BIFs - Built-in functions, these are written in C and ship with the VM- NIFs - Natively implemented functions, these are written in any language that can speak the NIF ABI that BEAM exposes and allows you to provide a function that looks like a built-in function but that you build yourself.- User - User functions are written in the language that's running on BEAM, so if you write a function in erlang or elixir, that's a user function.NIFs allow you to drop down into a lower level language and extend the VM.  Originally most NIFs were written in C, but now a lot more languages have built out nice facilities for writing NIFs.  Rust has Rustler and Zig now has Zigler, although people have been writing zig nifs for a while without zigler and I'm sure people wrote rust nifs without rustler.\n \nreply",
      "It\u2019s important to note that while Erlang has protections against user code crashing an Erlang process and recovering, a faulty NIF can take down the entire virtual machine.\n \nreply",
      "There's a series of things that a NIF must do to be a good citizen. Not crashing is a big one, but also not starving the VM by never yielding (in case the NIF is long-running) is important, plus a few secondary things like using the BEAM allocator so that tooling that monitors memory consumption can see resources consumed by the NIF.The creator of Zigler has a talk from ElixirConf 2021 on how he made Zig NIFs behave nicely:https://www.youtube.com/watch?v=lDfjdGva3NE\n \nreply",
      "Hence why Rustler is of so much interest since it provides more protections against this happening.Discord is a big Erlang + Rustler user.\n \nreply",
      "What kind of protections as opposed to Zigler?\n \nreply",
      "Rust comes with memory safety.It's one less potential cause that might bring down the entire Erlang VM.\n \nreply",
      "SIGSEGV is a pretty common failure mode alright.\n \nreply",
      "Are they really? Their projects don't look so active\n \nreply",
      "It\u2019s pretty common in the Elixir ecosystem for these types of libraries to not change very much.  Elixir itself doesn\u2019t change too much so these libraries stay solid without needing frequent updates.  It doesn\u2019t mean people aren\u2019t using them.  Some libraries even put disclaimers that they are actively maintained even if they haven\u2019t seen an update in a long time. It\u2019s something that takes some getting used to for some people (including myself at one point).\n \nreply",
      "Yep.  This is one reason I choose Elixir for a project.  For a variety of use cases, long term stability is a big plus.\n \nreply"
    ],
    "link": "https://github.com/E-xyza/zigler",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        zig nifs in elixir\n      Library test status:Run mix zig.getZigler is available in Hex, and the package can be installed\nby adding zigler to your list of dependencies in mix.exs:TBD.~/.cache/zigler/zig-linux-<arch>-0.13.0Erlang is only supported via rebar3.  You must enable the rebar_mix plugin and\nadd zigler to your deps in rebar3.Note that erlang support is highly experimental.  Please submit issues if you\nhave difficulty.Docs can be found at https://hexdocs.pm/zigler.LinuxFreeBSD (tested, but not subjected to CI)MacOSNerves cross-compilation is supported out of the box.Wouldn't it be nice if you could make NIFs as easily as you can use the asm\nkeyword in C?This is now possible, using the magic of Zig.Zigler will do automatic type marshalling between Elixir code and Zig code.\nIt will also convert trickier types into types you care"
  },
  {
    "title": "Never Missing the Train Again (lilymara.xyz)",
    "points": 161,
    "submitter": "thimabi",
    "submit_time": "2024-10-23T11:00:15 1729681215",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=41923753",
    "comments": [
      "If you're in the UK you can buy a depature board that mimics a station departure board:https://ukdepartureboards.co.uk/store/product/desktop-depart...\n \nreply",
      "BART and MUNI both support the General Transit Feed Specification.[1] There's a\nstandard way to obtain this data.[1] https://gtfs.org/documentation/overview/#gtfs-realtime\n \nreply",
      "I love this.  As a formerly car-free resident of Boston, I cobbled together something far cruder to handle the cases of there being many ways for me to get from point A to point B, but the \"best\" way depended on time and any stops I'd make along the way.For example, I walked my son to school before heading to work, and sometimes I got breakfast after dropoff. Having the \"next departure\" view let me have a more fluid experience that handled the non-deterministic nature of walking with a 4 year old in a very interesting place, or deciding whether to hustle to get the train because missing it hit a schedule gap, etc.\n \nreply",
      "You don't have to jailbreak your Kindle, or render images.You can just point its web browser at any webpage you design, and disable the Kindle's \"screensaver\" (its ads or sleep screen) with debug commands [1, 2].You'll be stuck with a browser bar along some edge of the Kindle (you can rotate the device orientation to put it at the bottom or right edge), but it's a small price to pay for being able to write your weather/transit/news screen in easy HTML/CSS/JS and whatever backend language you want, and run it on a cheap DigitalOcean $4 instance or whatever.[1] https://blog.notfaqs.com/2018/06/kindle-e-reader-disable-scr...[2] https://www.mobileread.com/forums/showthread.php?t=198334\n \nreply",
      "It would be even cooler if Amazon also encouraged and built a \"Kiosk mode\" browser view of the kindle for this sort of display hacking.\n \nreply",
      "They really ought to, it's a fantastic reuse mechanism.Like I totally understand why they wouldn't for new Kindles, since I assume part of their ebook sales help subsidize the hardware, but if they enabled it once a device hit 5 years old or something, I don't see what they'd have to lose.\n \nreply",
      "(author here) I've also been thinking about this - I've since built out a Rust library (https://github.com/lily-mara/kindling) for scaffolding the server piece of this and I've been considering creating a Kindle client app that integrates with it. This is possible but would require using the Kindle Java SDK, which does not fill me with excitement.\n \nreply",
      "That would be fantastic, although even just the way you've done this here is great. I've got a few old Kindles that would be good to convert to displays, and if I could just install a server and a client, it would take a lot of the work out of it.\n \nreply",
      "No matter what, jailbreaking would be the most difficult step in the process, but the library I linked above takes a lot of the work out of it. It's entirely undocumented atm (I am surely the only one using it), but it comes with an install script you can run on the Kindle to do the setup once you have the jailbreak done.\n \nreply",
      "I looked into this with my 4th generation Kindle; it seems like it won't be able to use any HTTPS website due to invalid certificate. However, setting it up to talk to a server on my local network would be the way to go. Thanks for the idea!\n \nreply"
    ],
    "link": "https://lilymara.xyz/posts/2024/01/transit-kindle/",
    "first_paragraph": "I live in San Francisco, and I don\u2019t own a car. This means that I walk or take\npublic transit nearly everywhere that I go. There\u2019s a lot of ways to find out\nwhen the next bus/train/tram/trolleybus/cable car/ferry is stopping nearby so\nthat you don\u2019t miss it. There are no shortage of apps that will guide you to\nyour destination using any and all means of public transit, and those are great!\nI particularly like CityMapper. But apps aren\u2019t always\nthe best for getting around a city, especially for leaving your own apartment.The most frustrating thing about these transit apps is that they assume that\nthey\u2019re going to guide you through the entire transit process. They often work\non the \u201cwhere are you and where are you going\u201d model of something like Google\nMaps. This is great for people new to a city, or exploring a new area of the\ncity, they can get all the guidance they need. But when I\u2019m leaving from my own\napartment, I know where the closest transit stops are and where they go. I don\u2019t\nne"
  },
  {
    "title": "Post World War II Food (nps.gov)",
    "points": 147,
    "submitter": "paulpauper",
    "submit_time": "2024-10-24T16:54:53 1729788893",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=41937319",
    "comments": [
      "I highly recommend MRESteve for content about military rations:\nhttps://www.youtube.com/channel/UC2I6Et1JkidnnbWgJFiMeHANo VPN partners or other bullshit, just great content enjoyed by a large variety of people. Most of military food interest, some use it for sleeping, or for better apetite under medical treatments.\n \nreply",
      "\"I quit smoking years ago, but an after-meal cigarette from 1973 might just tempt me...\"Never gets old :')\n \nreply",
      "His reviews of those old MRE cigarettes are amazing. He makes it seem like he's smoking pure ecstasy (figuratively, actually, w'ever). I've never smoked but watching those segments I'm jonesing hard to smoke one of those.\n \nreply",
      "As someone who smokes a small single digit number of cigars per year, I can attest that the nicotine buzz is incredible on the rare occasions that I do.I've never been a regular smoker, but I bet that for someone who was, smoking a single cigarette every few months would be an almost religious experience. You'd be getting all of the sensory associations, plus the chemical stimulation unblunted by accumulated tolerance.\n \nreply",
      "Talking about nicotine inducing a religious experience.  In my 20s I smoked organic pipe tobacco from a bong and holy shit the experience was out of this world, I literally felt like I was flying and had the most insane headrush.I understand why Native Americans used tobacco in religious ceremonies.\n \nreply",
      "I'd appreciate the perspective of an actual smoker on this, but I suspect those long-preserved cigarettes aren't that special in and of themselves.  For Steve, it's a hit of both nostalgia and a chemical he's long been deprived of.  It's probably amazing for him, and that shows in the videos, but telling himself that those preserved cigs are special might be a way for him to avoid relapsing.  He craves more, but he can tell himself that the modern junk just wouldn't be the same.If you decided to get addicted to vintage MRE tobacco you'd probably have a pretty tough time sourcing enough of it to give yourself cancer.\n \nreply",
      "Cigarettes haven't been the same (in the US) for well over a decade now, since all 50 States and DC require them to be \"fire safe\" cigarettes (FSC).This means that there are parts of the paper wrapper that have vinyl compounds that are intended to allow them to self-extinguish.Compared to the cigarettes of yore, these taste like fried dick cancer.But old tobacco doesn't always age well.  It can survive for centuries if stored at the appropriate temperature and humidity and away from things that would impact the taste, or it can turn stale and fairly blah in weeks or months when stored poorly.\n \nreply",
      "Interesting.  I rarely smoke, but did do a lot of smoking in the mid 00s.  I recently indulged and damn, it was nowhere near as tasty as I remember.  That probably explains it!\n \nreply",
      "Where would one go to purchase specialty cigarettes, without those compounds?\n \nreply",
      "Any tobacco shop. You can buy empty cigarette tubes, which are basically just the paper tube with a cotton filter attached. They don't contain any extra additive. You can then load any tobacco you like with a cigarette loading machine (also known as an \"injector\"). You can also buy pure, high quality Dutch tobacco that's far higher quality than anything that would have been loaded into a cigarette in the 1970s.\n \nreply"
    ],
    "link": "https://www.nps.gov/articles/post-wwii-food.htm",
    "first_paragraph": "\nArticleThis article is part of the series,\u00a0The American Home Front and World War II. It explores life on the home front by looking at the things people invented, created, and used and the ways that everyday life changed.\u00a0They include the effects of war mobilization and of conflict and incarceration on the home front, especially as it relates to civilians.World War II brought several changes to what and how we eat. For example, members of the military traveled the globe during World War II, encountering different cuisines. When they returned, they brought back memories of those dishes. French, Italian, and Chinese food soon became popular in America beyond immigrant neighborhoods like Chinatowns and Little Italys.[1]  Other changes were spurred by foods included in military rations and food produced using technologies developed during the war. There are also recipes born from rationing and Victory gardens that \u201cstuck.\u201d US Army Signal Corps, 1943.The US military had a system of rations "
  },
  {
    "title": "Show HN: 2048 turned 10 this year, I built an updated version to celebrate (play2048.co)",
    "points": 424,
    "submitter": "terabytest",
    "submit_time": "2024-10-24T12:15:27 1729772127",
    "num_comments": 163,
    "comments_url": "https://news.ycombinator.com/item?id=41934746",
    "comments": [
      "This may be buried in the comments and you will never see it, but thank you very much Gabriele. Your game helped me in a very weird circumstance.I was afraid of flying, specially on the takeoff and landing (and turbulence as well, ha). So I read somewhere that if I focused on something else, it would help me. So for the past years, I played 2048 during takeoff and landing, and it worked. It helped me to focus on something else, not the airplane, and I started to enjoying more my trips.Now I don't need to do it anymore, but just for the experience I still do it when I fly. So thank you for helping me with my fear!\n \nreply",
      "That\u2019s amazing! Such a cool story. I\u2019m really happy that 2048 was able to help you this way :)\n \nreply",
      "Always amazing to read about surprising positive impacts that a project can make in someone's life like this.\n \nreply",
      "TypeScript was fairly new at that time and to learn it, I ported 2048 to TypeScript. It was fun!Fast forward a couple of years, I was debugging an issue with a react component and glanced over the .d.ts of react. I was quite surprised when I saw that my name was in them. I never contributed to react's types myself.It turned out that someone took some types I wrote for 2048 and used them in the very first type definitions for react:\nhttps://github.com/DefinitelyTyped/DefinitelyTyped/commit/4b...It's still there to this date, but I've lost my TS port in the sands of time.\n \nreply",
      "This doesn't make any sense. We should be celebrating 8 years, 16 years and so on.\n \nreply",
      "The true 10th anniversary actually happened 1000 years ago.\n \nreply",
      "Congrats on the 10 year anniversary, though honestly I think having tried your new 2048 I'll go back to the classic build. It might just be the hours I've poured into the original but it feels faster without the additional animation. But still a lot of good work there and I'm wishing you the best of luck.As for the argument about Threes!, I have to say that I've generally found 2048 to be a much more fun game; the full-screen sliding and the lack of the 1+2 mechanic makes things move much faster, which for me is a priority. That's definitely personal taste, but I hate the vitriol that comes up on the topic.\n \nreply",
      "To add to the clone topic, 2048 was cloned from 1024, so any claims of being only inspired by Threes fall apart quickly. IMHO, the way you're trying to sell 2048 is revisionist history and just plain shit. You can't turn back time, and let the Threes creator have a moment to shine and profit from the design, but you can at least give credit where due, and not when 50 people call you out on it.\n \nreply",
      "My favorite 2048 clone by far is https://ashervollmer.github.io/2048/128.html, which is just a 3x3 2048 that only spawns 2. I like it because it is possible to achieve total victory, a perfect game fills the board with a a final score of 7172.\n \nreply",
      "Wow, has it already been ten years? I also wrote a clone of 2048 back then (https://github.com/nieware/gofusion), using Go and a QML-based UI, for a contest, and (to my astonishment) actually won the first prize, which consisted of a Nexus 7 tablet (which served me well for several years) and a rare original vinyl Gopher figurine (which is still sitting on my desk looking at me serenely with its googly eyes while I type this).\n \nreply"
    ],
    "link": "https://play2048.co",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: TypeSchema \u2013 A JSON specification to describe data models (typeschema.org)",
    "points": 70,
    "submitter": "k42b3",
    "submit_time": "2024-10-24T19:46:58 1729799218",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=41939027",
    "comments": [
      "Why reinvent https://json-schema.org ?? Pros/cons?\n \nreply",
      "From my understanding, JSON schema describes the schema of JSON objects with JSON. This one describes a variety of types of schemas with JSON.So it could be typescript, Go, GraphQL, etc. It seems to output to JSON schema as well. I guess its main purpose is to share the schema between different languages. Which I imagine works with JSON schema too, but this takes it a step further and handle all the mapping you'd need to do otherwise.\n \nreply",
      "Have you heard of wit? I suspect we'll see use outside of WebAssembly. https://component-model.bytecodealliance.org/design/wit.htmlIt has non-nullable types, via option, which makes non-nullable the default, since you have to explicitly wrap it in option. https://component-model.bytecodealliance.org/design/wit.html...A way to represent types commonly found in major languages would be nice, but it would be better to start with something like wit and build on top of it, or at least have a lot of overlap with it.\n \nreply",
      "I find it interesting that the Go serialization just duplicates the props rather than using composition:\nhttps://typeschema.org/example/goSeems a bit naively implemented.Ideally, the duplicated props in Student would just be a single line of `Human`.\n \nreply",
      "Comparison between TypeSchema and LinkML for those interested as I was. https://www.perplexity.ai/search/please-compare-and-contrast...\n \nreply",
      "What's the benefit over existing variants like Swagger/OpenAPI/JsonSchema ?\n \nreply",
      "It feels like a convert solution, as it can transform TypeSchema into JsonSchema.\n \nreply",
      "Yeah, I'm not really following the line of reasoning presented on the \"/history\" page: https://typeschema.org/historyIt seems to me like a mischaracterization of JSON Schema to say you can't define a concrete type without actual data.I am a very stupid individual so I could be misunderstanding the argument.\n \nreply",
      "I can't really follow those arguments either. For example the empty object example {}. Why is this bad? Types without properties are a real thing. Also an empty schema is a real thing.The thought I do get: JSON Schema primarily describes one main document (object/thing). And additionally defines named types (#/definitions/Student). But it's totally fine to just use the definitions for code generation.The reference semantics of JSON Schema is quite powerful, a little bit like XML with XSD and all the different imports and addons.\n \nreply",
      "It looks far more constrained, especially when it comes to the validation logic, which makes sense validation-wise but honestly quickly becomes a \"fate shovels shit in my face\" kind of situation when it comes to code generation. As much as I love this sort of constraints I also find the union-type discrimination style \"meh\".\n \nreply"
    ],
    "link": "https://typeschema.org/",
    "first_paragraph": "TypeSchema is a JSON specification to describe data models.\nSpecification\nEditor\nGenerator\nAt the following list you can take a look at example output for each supported programming language.LinksGitHubContact"
  },
  {
    "title": "Lingo: A Go micro language framework for building Domain Specific Languages (about.gitlab.com)",
    "points": 46,
    "submitter": "adityasaky",
    "submit_time": "2024-10-24T19:23:38 1729797818",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41938819",
    "comments": [
      "When I think of a DSL, I think of a language with specialized syntax, grammar,  or constructs suited to the problem domain. Think SQL, AWK, or regular expressions. This is just a LISP variant with a typical host-side API for registering function names.I'll never get how merely having function names that reflect the use case, plus a stripped down or absent standard library, qualifies as a DSL. I know some people have long used \"DSL\" in this way, especially among LISP fans, but... I just don't get it. If I want a DSL it's because I want something that gives me, e.g., novel control flow constructs a la AWK, or highly specialized semantics a la regular expressions, that directly suit the problem domain. If I'm not getting that kind of power, why tie myself to some esoteric dependency? Either way you're adopting a tremendous maintenance burden; it better be worth your while.I'm a huge fan of Lua and have used it for many projects in different roles, but never once thought of any particular case as having created a DSL, even when stripping the environment to just a few, well-named, self-describing functions.I don't mean to criticize this particular project. Good code is good code. It's just the particular conceptualization (one shared by many others, to be fair) of what a \"DSL\" means that bugs me.\n \nreply",
      "I don\u2019t think there\u2019s need to have such strict requirements. No need to invent a whole new paradigm, you can go with the usual ones as long as it works well. More often than not the domain is not that complex or flexible to require a language, it may only requires a few algorithms (libraries) ie even if you do invent a language, few programs will be built with it. You may as well tweak an existing language for a nicer DX\n \nreply",
      "This is a very good and interesting point, but what if the point itself is to reduce the power and increase things like legibility.If I create this kind of mapped functions DSLs I can assure that things will be done a a certain way vs the borderline infinite possibilities of code.\n \nreply",
      "> Some popular DSLs most software developers use on a regular basis include Regular Expressions for pattern matching, AWK for text transformation or Standard Query Language for interacting with databases.\n\nIsn't it Structured Query Language? Or are both variants used?\n \nreply",
      "> In the early days of the system there was divided preference between Standard Query Language and Structured Query Language but it did not make a whole lot of difference since most people most of the time called it by the acronym SQL. Now the overwhelming but not complete preference is for Structured Query Language.[0] https://www.sjsu.edu/faculty/watkins/sql.htm\n \nreply",
      "Thanks for that!\n \nreply",
      "Regarding the Ruby example, why did they use Float(\"...\") instead of #to_f?\n \nreply",
      "Probably because `Float()` is stricter and will raise an error if the string isn't a valid number, whereas `#to_f` will silently return 0.0 or do a best-effort conversion (e.g. \"1.2abc\".to_f => 1.2)\n \nreply",
      "This seemed like nuclear overkill for most problems I can think of.And where it should be used, I can't imagine you can't find a pre existing language (Cuelang maybe) instead.I was expecting a section at the end where they demonstrate which services need a new language written just for it's configuration, but nope, just general examples.Also, this should have a (2022) in the title.\n \nreply",
      "It is nuclear overkill for most problems you can think of.But when you hit a problem that you need something like this for... you need something like this. The attempts to get around it or avoid it or do some unbelievably hacky thing leads to piles and piles of terrible, terrible code.In 2024, though, I do try very hard to embed my DSLs in an existing serialization. It doesn't always work out, but, the case they show of directly embedding an AST into YAML is a worst-case scenario. In real life I've done things like specify a particular field carries an expr[1] expression to do that sort of thing, and then the structure of the rest of the file just follows normal serialization format.[1]: https://github.com/expr-lang/expr , but I'm sure many static languages have something like this. If you don't know one, it's a good tool to put in the belt in case you ever need it.\n \nreply"
    ],
    "link": "https://about.gitlab.com/blog/2022/05/26/a-go-micro-language-framework-for-building-dsls/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Pneumatic \u2013 free open-source workflow software (github.com/pneumaticapp)",
    "points": 7,
    "submitter": "pneumaticteam",
    "submit_time": "2024-10-24T23:17:40 1729811860",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/pneumaticapp/pneumaticworkflow",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Free and source-available Apache 2.0 licensed lightweight workflow automation tool. \n      Pneumatic is an open-source, cloud-native workflow management system that empowers businesses to automate and streamline their processes with ease. By providing full access to the source code under the Apache 2.0 License, enterprises can now own, customize, and integrate the software to fit their specific needs.Clone the Repositorygit clone https://github.com/pneumatic/pneumaticworkflow.gitcd pneumatic-workflow\n        Free and source-available Apache 2.0 licensed lightweight workflow automation tool. \n      "
  },
  {
    "title": "The Lion of St. Mark's Square in Venice Is Chinese (archaeologymag.com)",
    "points": 95,
    "submitter": "pseudolus",
    "submit_time": "2024-10-24T17:08:43 1729789723",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=41937443",
    "comments": [
      "From Wikipedia:The Lion sculpture has had a very long and obscure history, probably starting its existence as a funerary statue called zh\u00e8nm\u00f9sh\u00f2u (\u9547\u5893\u517d in Simplified Chinese, literally \u201ctomb guardian\u201d) in medieval China, during the reign of the Tang Dynasty....The Lion, in its present form, is a composite of different pieces of bronze created at very different times, building upon ancient \"core\" components. It has undergone extensive restoration and repair work at various times....More recent studies, however, suggest that the statue likely comes from the regions near the lower course of the Yangtze River, in eastern China, and was probably cast sometime in the period from the 7th to the early 10th century CE, during the reign of the Tang Dynasty. The original bronze figure, taken as a whole, was likely significantly different from the Lion of today...https://en.wikipedia.org/wiki/Lion_of_Venice\n \nreply",
      "Would it have come over the spice roads all the way from eastern china or would it have been pirate loot sold in Mumbai and then fenced farther west?\n \nreply",
      "> There is no historical record of when or how the lion arrived in Venice, but it was already installed atop the column in St. Mark\u2019s Square by the time Marco Polo returned from China in 1295.Venice had trade agreements with the Mongol empire for decades prior to that.  It\u2019s not hard to imagine that the Mongols took it from China and traded it to Venetian merchants.\n \nreply",
      "The lion may be Chinese but the four horses in St Mark's Basilica are Greek looted from\nConstantinople during the fourth crusade (1204).Perhaps the lion was also looted and brought to Constantinople originally which would fit with pre Marco Polo's travels.https://en.m.wikipedia.org/wiki/Horses_of_Saint_Mark\n \nreply",
      "\"Further proof arrives through the holes in the sculpture\u2019s head, which researchers believe would have once held horns, and ears which have been rounded off. The sculpture, which is known to have arrived in parts and reassembled, was essentially modified to look more lion-like.\"https://news.artnet.com/art-world/bronze-venice-lion-from-ch...\n \nreply",
      "To me the face and mane of the lion resemble artwork/designs I've seen from historical Iranian-adjacent/Persian empire related sites all along the historical maximum extent of the Farsi speaking world, much of which overlaps with the historical land based trade routes to/from western China.\n \nreply",
      "Went looking for more info. Some good pics of where this is in Venice:https://www.guidedtoursinvenice.com/en/blog/a-guided-tour-in...\n \nreply",
      "As an Asian person having grown up with a bit of South Chinese culture, it does appear a bit like a Chinese lion statue, but the wings really throw it off for me.\n \nreply",
      "Could be that the wings are a later addition, like they might have been added in the 1100s-1200s in Venice or those whereabouts.\n \nreply",
      "> Lead isotope analysis of the bronze alloy provided indisputable evidence of the Chinese origin of the materials used in the statue.Is there some more detailed source explaining how this conclusion was reached? What's distinct about Chinese lead / how this kind of evaluations are done?\n \nreply"
    ],
    "link": "https://archaeologymag.com/2024/09/lion-of-st-marks-square-in-venice-is-chinese/",
    "first_paragraph": "A new study has revealed that the iconic bronze-winged lion in St. Mark\u2019s Square, Venice, may have originated in 8th-century China.The discovery comes from a multidisciplinary team of experts in geology, chemistry, archaeology, and art history from the University of Padua, the Ca\u2019 Foscari University of Venice, and the International Association for Mediterranean and Oriental Studies (Ismeo). Through advanced metallurgical analysis, the team discovered that a significant portion of the bronze used in the lion came from the lower Yangtze River basin in southeastern China, and it was likely cast during the Tang Dynasty (618-907 CE).Lions were initially introduced to the Han court by emissaries from Persia (modern-day Iran) and had become widely represented as guardian figures.Lead isotope analysis of the bronze alloy provided indisputable evidence of the Chinese origin of the materials used in the statue. The results were announced on September 11, 2024, during an international conference "
  },
  {
    "title": "Viva Labs (YC W22) is hiring a video/image AI research lead (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-10-24T21:00:46 1729803646",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/viva-labs/jobs/RwBJyRn-video-image-ai-research-lead",
    "first_paragraph": ""
  },
  {
    "title": "Data viz project that maps all earthquakes by magnitude (concord.org)",
    "points": 49,
    "submitter": "therabbithole",
    "submit_time": "2024-10-24T18:29:23 1729794563",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=41938204",
    "comments": [
      "The 3D view is really interesting (click \"Draw Cross Section\" lower right), but the main map view is not very useful. Try zooming into New Zealand, or even down to the South Island of New Zealand, and plot a decade start 2007 to 2017. You would be hard pressed to see the two city-levelling destroying earthquakes and one town destroying earthquake we had (Sep 2010, Feb 2011, Nov 2016).I think the main issue is colour and scale. The magnitude is logarithmic, but the scale of the circles are not.We experience earthquakes in New Zealand all the time. Th last one was 10 hours ago [1] with a total of three yesterday. So in places you would expect large quakes, you also get lots and lots of small ones.On a side note, Google beta-tested their early earthquake warning system in New Zealand and it was opt-out. I had students diving under desks in a Deep Learning class because the warning sound emitted was very much like the govt. emergency SMS messages. It was a very minor quake, I am not sure we even felt it.[1] https://www.geonet.org.nz/earthquake/weak\n \nreply",
      "I played with Kepler GL a couple of years ago to visualise the Canterbury quakes.  It's kinda phenomenal to see how frequent the little ones are, and the aftershocks from big ones take a while to drop off...https://itnext.io/using-kepler-gl-to-visualise-over-35-000-e... for the curious\n \nreply",
      "Very nice. I didn't even know we (New Zealand) had that many quakes over that time, I thought it was closer to 10,000.\n \nreply",
      "I don't see a way to share a particular view, but it is wild to see the magnitude of change in earthquake rates in oil and gas producing areas. For example, zoom into Oklahoma and click play, almost nothing happens from 1980 to 2010 then the map suddenly fills up.\n \nreply",
      "Very impressive. I love how subsidence zones are clearly visible in the 3d view.I think if I had a feature request it would be an option to have a fixed interval(or window) of time visible, rather that the current method of a fixed start time. for example one year behind current. This can sort of be achieved by moving the start and end bugs in sync, but that was less than satisfying in practice. The thing that would make sense is to be able to drag the illuminated part of the time line.If I had a second feature request it would be to assign what feature(depth, age, magnitude) is mapped to the color axis, nothing wrong with depth here, I just noted that it was redundant in the 3d view.\n \nreply",
      "It's very glitchy for me on firefox on linux, with many of the quakes not rendering or flickering as if they render in the wrong order and are covered by the base map.The artifacts change randomly if I zoom and pan around, but it isn't easy to control. For example, in the default global view when opened, it only seems to show quakes in the South Pacific near NZ.\n \nreply",
      "It is crazy to see the amount of major cities that are on top of high risk areas.\n \nreply",
      "Including Atlantis! ;-)(Mid-Atlantic Rift Zone.)Historically virtually all cities were located either along coastlines or major river transport, as shipping was far and away the cheapest way to move large volumes (and masses) of goods.  Even today that pattern remains strong.Tectonic movement is also associated with factors that often produce economically-critical natural resources, from minerals to simply fertilising soil.  Australia, which sees little seismic activity, has famously infertile farmland, in which even minuscule additions of mineral fertilisers --- not the Big Three of nitrogen, phosphorus, and potassium, but trace minerals such as iron, copper, selenium, zinc, and manganese.  Again, that's where cities tend to form.And coastlines are strongly associated with earthquakes, especially those along subduction zones (Western Americas, Eastern Asia).  Not only do those have many earthquakes, but some of the largest and most destructive, along with tsunamis which can further the devastation.Note that coasts nearer to rift zones (eastern Americas, western Europe, both west & east Africa) have fewer earthquakes.  Several of those also have major populations.\n \nreply"
    ],
    "link": "https://seismic-explorer.concord.org",
    "first_paragraph": ""
  },
  {
    "title": "U.S. Consumer Watchdog Cautions Businesses on Surveillance of Workers (wsj.com)",
    "points": 21,
    "submitter": "sandwichsphinx",
    "submit_time": "2024-10-25T00:05:08 1729814708",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41941052",
    "comments": [
      "I do find it interesting how there seems to be more protections around phone calls than anything else. As-in your employer can not just randomly listen to all your phone calls but can just record your screen all day?https://corporate.findlaw.com/law-library/can-an-employer-mo...Unrelated, I really wish this quote \"The Court relied principally on the fact that the employee was an at-will employee and the employer had no legal interest in his future employment plans. \" made its way into more lawsuits.\n \nreply",
      "Don't worry. Once the True Leader is back in power, the Consumer Financial Protection Bureau will be powerless again.\n \nreply",
      "https://archive.is/q6EK0\n \nreply",
      "A non-paywalled source: https://www.cbsnews.com/news/consumer-watchdog-cautions-comp...\n \nreply"
    ],
    "link": "https://www.wsj.com/articles/u-s-consumer-watchdog-cautions-businesses-on-surveillance-of-workers-8262bee3",
    "first_paragraph": ""
  },
  {
    "title": "The Anvil Text Editor (anvil-editor.net)",
    "points": 80,
    "submitter": "bwidlar",
    "submit_time": "2024-10-23T08:29:41 1729672181",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=41923018",
    "comments": [
      "Anvil piqued my interest especially because it provides a REST API to interact with it opening the door to writing extensions in practically anything, similar to Kakoune in that regard. But what I find odd is that there's no mention of a repo (though it has a link to a Discord server) anywhere on the site as far as I've seen.Sadly there's no mention of LSP either which is kinda a deal-breaker these days nor anything about tree-sitter. But at the same time this might mean that Anvil is free to experiment with its own solutions without being tied to a standard. Every cloud a silver lining or how it goes.Gio also seems like a solid choice for the UI.I hope Anvil becomes more popular, it would be fun to see a new generation of niche text editors duke it out between Lem, Helix and Anvil.\n \nreply",
      "Source code archives are available on the download page: https://anvil-editor.net/download/But as you said I couldn't find a repo.\n \nreply",
      "It is however open-source (MIT license).\n \nreply",
      "This is very interesting, and it's great to see new editors.But honestly I never got the fascination for the Acme editor. It seems powerful, but relying on mouse input is limiting, slow and imprecise. I'd much rather control my editor using the infinite key combinations of the keyboard I'm already typing on, which is much more comfortable, accurate and faster. It also builds muscle memory that can never be built with an analog input method like the mouse.Multi-pane editing is also not very useful beyond a single vertical or horizontal split. For anything more complex, a tiling window manager is a more versatile tool that works for any app.To enable these two functionalities UI elements need to be rendered, which clutters up the UI and takes up considerable screen real-estate. When working in a buffer and keyboard-oriented editor like Vim or Emacs, the screen only needs to show the content itself, which is a much more pleasant environment to work in.But maybe I'm misunderstanding the benefits of the Acme workflow, and I honestly haven't given it a thorough try, so I'd be happy to read counterpoints.BTW, I love the font Anvil uses! Is it available somewhere to download?\n \nreply",
      "mouse or keyboard is really just a preference. you could do mouse 1 sweep-select 2-3 in one window, and move to another mouse 1-3, and move to another do mouse 1-3, ... Or you could do, in case of vi, y$ (or other movements), ^w w (or other way to select other window), (move your cursor) p, ^w w, (move your cursor) p, ... Though I'm biased, because I feel it's much easier to move my mouse than do one of wWbBeE^$fFtThjkl to move my cursor, even though it is a lot faster and efficient to only move a few of my fingers than my whole arm.the font is likely Go Font, the proportional one\n \nreply",
      "Aha, right, cursor movement across large distances is indeed more comfortable with the mouse. This is usually awkward with the keyboard, and requires plugins like EasyMotion, or just holding keys or repeating key combos. I think these movements are rarer than small cursor movements, like jumping to the next character, word, line, etc., or jumping to the matching brace, etc. In these cases using the keyboard is still faster and more precise.But I was more thinking about controlling the editor itself. Creating new buffers/panes and switching between them is all much faster with a keyboard. For example, I bind `=` and `-` to switch to the previous/next buffer, and Tab to switch to the next pane. I do these actions hundreds of times a day, and they're just a keystroke away. I couldn't imagine having to use the mouse for this. It would be unbearably slow and tedious.The best part of key bindings is that they can be easily modified to suit any workflow. Whereas with mouse movements you really can't customize them beyond which of the few buttons to click. The movements themselves can't be optimized, unless you go into gesture territory, which has a lot of drawbacks as well.No, it doesn't look like the Go font, but thanks.\n \nreply",
      "> Aha, right, cursor movement across large distances is indeed more comfortable with the mouse. This is usually awkward with the keyboard, and requires plugins like EasyMotion, or just holding keys or repeating key combosEmbrace search based navigation. And if you\u2019re using Vim or Emacs, do whatever that can popup a new window with the result of your search and links to their location in the main buffer. And extend that to search in all files of the $PROJECT.\n \nreply",
      "Anvil uses a licensed version of the Input font, by David Jonathan Ross.\n \nreply",
      "I\u2019ve spent a fair amount of time with Acme because it\u2019s fun, but you\u2019re not misunderstanding anything. Anyone who unironically tries assert the superiority of their niche editor is delusional and/or full of shit. It\u2019s just personal preference.\n \nreply",
      "> multiple cursorsBut seriously though, why does everything these days need multiple cursors? It's a confusing visual gimmick in every scenario I've seen it implemented in. I'll take fully fleshed out structural regular expressions or even perl-re over multiple cursors any day. Combined with as vim's [c]onfirm flag you get all the benefits of multiple cursors without all the clunky downsides and weirdness.\n \nreply"
    ],
    "link": "http://anvil-editor.net/",
    "first_paragraph": "Anvil is a graphical, multi-pane tiling editor that makes bold use of the mouse and integrates closely with the shell. It supports syntax highlighting, multiple cursors and selections, remote file editing, and contains a powerful text manipulation language.Anvil is inspired by Acme. Thank you to the GIO developers and community working tirelessly to create a beautiful graphical user-interface library in Go, without which this editor would not be possible. Thanks to the Go team for creating a practical, portable, performant and clean language that is a joy to write in."
  },
  {
    "title": "Rider is now free for non-commercial use (jetbrains.com)",
    "points": 638,
    "submitter": "kretaceous",
    "submit_time": "2024-10-24T14:43:26 1729781006",
    "num_comments": 314,
    "comments_url": "https://news.ycombinator.com/item?id=41936001",
    "comments": [
      "This is pretty huge all around, especially with Microsoft discontinuing Visual Studio for Mac.https://learn.microsoft.com/en-us/visualstudio/releases/2022...I'd also like to note the great integration Rider has with Godot and Unity for game development.\n \nreply",
      "Don't forget Unreal as well - I've used Rider on multiple AAA Unreal titles that include custom engine edits and it is significantly faster than VS at loading massive projects. The integration is great and allows for seeing blueprint classes and references in the C++ project.I say this as a big user of JetBrains - I have had SOME issues with their intellisense dropping some references in Rider when there are a lot of references, so I would occasionally switch to VS when there were a lot of references to search through, but other than extreme cases Rider is just so much more pleasant to use.\n \nreply",
      "I had no idea Rider supported C++. My impression was that it is for .NET only. How does it compare to CLion?\n \nreply",
      "Yeah they originally had a separate branch \"Rider Unreal\" but now it's part of Rider, C++ support seems mostly the same across both, except for project support. If IIRC Rider doesn't support CMake projects, but it does support vsproj projects, so if you generate vs files from cmake it'll load fine, but probably better to use CLion for any non-UE projects if using C++. I guess they're seeing it as .NET/GameDev IDE.Honestly I don't know why there are so many almost identical IDEs.\n \nreply",
      "JetBrains IDEs are all the same program just bundled with different language plugins. It would be like if you called VSCode by a different code name depending on which combination of extensions you had installed.\n \nreply",
      "Not entirely. E.g. IntelliJ has a \"project environment\" modal (not sure about the exact name rn), in pycharm its part of the settings and a bit different. There are a few more things like this between the IDEs.\n \nreply",
      "I use both Rider (for mixed c++/c#) projects and CLion for C++ only.I feel that Rider is somehow better than CLion at c++, even after CLion Nova (Intellisense based on Resharper backend) became a thing.One difference is that I write boost::asio in CLion, and just vanilla C++ in Rider, and before Nova it was completely unusable with async code, now it's usable with async code, but after a few days of running the editor I end up with fatal IDE errors for CLion, and never for Rider.\n \nreply",
      "> Honestly I don't know why there are so many almost identical IDEs.Probably a reflection of internal organization to avoid product teams stepping on each others' toes.\n \nreply",
      "Rider is much, much better than VS work unreal. And this is coming from a VS fanboy.\n \nreply",
      "VS for Mac was junk.  Better off trashing it and pushing people the VS Code route.I use VS Code daily for .NET development.  It's probably 70% of what VS on Windows is, but it works well and I don't need to run a VM for it (if I need some of the in-depth tracing and profiling stuff, I can still fire up the gold standard).  VS on Mac was maybe 30%\n \nreply"
    ],
    "link": "https://www.jetbrains.com/rider/",
    "first_paragraph": ""
  },
  {
    "title": "Self-Documenting Code (lackofimagination.org)",
    "points": 44,
    "submitter": "tie-in",
    "submit_time": "2024-10-23T13:33:49 1729690429",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=41924917",
    "comments": [
      "My cut:    const passwordRules = [/[a-z]{1,}/, /[A-Z]{1,}/, /[0-9]{1,}/, /\\W{1,}/];\n\n    async function createUser(user) {\n        const isUserValid = validateUserInput(user);\n        const isPasswordValid = user.password.length >= 8 && passwordRules.every((rule) => rule.test(user.password));\n\n        if (!isUserValid) {\n            throw new Error(ErrorCodes.USER_VALIDATION_FAILED);\n        }\n\n\n        if (!isPasswordValid) {\n            throw new Error(ErrorCodes.INVALID_PASSWORD);\n        }\n\n        const userExists = await userService.getUserByEmail(user.email);\n\n        if (userExists) {\n            throw new Error(ErrorCodes.USER_EXISTS);\n        }\n\n        user.password = await hashPassword(user.password);\n        return userService.create(user);\n    }\n\n1. Don't use a bunch of tiny functions. This makes it harder for future eng to read the code because they have to keep jumping around the file(s) in order to understand control flow. It's much better to introduce a variable with a clear name.2. Don't use the `a || throw()` structure. That is not idiomatic JS.2a. Don't introduce `throwError()`. Again, not idiomatic JS.3. Use an enum-like object for error codes for clarity.4. If we must use passwordRules, at least extract it into a global constant. (I don't really like it though; it's a bit too clever. What if you want to enforce a password length minimum? Yes, you could hack a regex for that, but it would be hard to read. Much better would be a list of arrow functions, for instance `(password) => password.length > 8`.5. Use TypeScript!\n \nreply",
      "My issue with this is that you're using exceptions for control flow. A user not being valid is expected (duplicate username). A password not matching a regex is also expected.Then, in general (not seen here as there are no types), I like to use a lot of types in my code. The incoming user would be of type UnvalidatedUser, whereas the return type of this function would be StoredUser or something like that to distinguish the incoming user type with the outgoing. I like to attach semantics to a type, not to conditions: https://existentialtype.wordpress.com/2011/03/15/boolean-bli...\n \nreply",
      "That's a great point, I didn't even think of that. I would use error types as well, yes.\n \nreply",
      "My issue with that is that absolutely NOTHING will ever convince me that returning error codes is a better idea than throwing exceptions. And that you seem to be using 'expected' in some weird cargo-culty sense of the word. An invalid user name is an error, not an expected case.\n \nreply",
      "> An invalid user name is an error, not an expected case.If you ain't expecting users to input bogus data, then you're putting way too much trust in said users.Put simply: is it a bug in your own code if a user tries to use an invalid username?  If yes, then throw an exception.  If no, then return an error code.  Exceptions represent programmer error; error codes represent user error.\n \nreply",
      "I\u2019ll try:Returning a \u201cResult\u201d with union discrimination on the \u201csuccess\u201d is far superior to throwing in Typescript in my experience   { success: false, reason: \u201cuser_already_exists\u201d } | { success: true, data: { user_id: string }\n\n- By design you are forced to \u201cdeal\u201d with the sad path: in order to get to the data, you must handle the error state- Throwing is not type-safe: you cannot know at build time whether you are handling all thrown errors\n \nreply",
      "\u201c Don't use a bunch of tiny functions. This makes it harder for future eng to read the code \u2026\u201dThis is where the naming things bit comes in. You name the function correctly, then when the body is read to understand that it works as named, you can remove that cognitive complexity from your brain and continue on. Once you\u2019ve built trust in the codebase that things do what they claim, you can start getting a top-down view of what the code does.That is the power of proper abstraction.\n \nreply",
      "Abstraction is way better, I don't really want to know how the password is validated unless I know I'm facing issues with validation (which proper logging tells you about before you even dive into the code).I don't understand why some people prefer being swarmed with details. It's not that they want details, but that they just hate navigating files (layer 8 + tooling problem) or that they \"need\" to know the details because not knowing them haunts them at night somehow.\nAlso, not having that as a free function makes me think it's not tested at all (although there might be some integration test that hopefully catch all errors at once, but I'm sure they don't either)\n \nreply",
      "It's not abstraction it's separation of concerns. And conflating the two is part of why GP is getting wrapped around the axle here.\n \nreply",
      "I don't know. I really don't see any clarity improvements between, `user.password.length >= 8 && passwordRules.every((rule) => rule.test(user.password))` and `validatePassword(password)`. What if you want to add that the password must contain one special character? You don't actually know, by reading the name \"validatePassword\", if that work has already been done or not. You need to go read the function definition and check. And so even for such a small function, there is no name that you can choose to truly do what you claim and \"remove the cognitive complexity from your brain\".Once a function gets to a certain threshold of size and reuse, I tend to agree with you. But I think that threshold is quite large - like at least 40-50 lines, or reused at least 3 times.\n \nreply"
    ],
    "link": "https://lackofimagination.org/2024/10/self-documenting-code/",
    "first_paragraph": ""
  }
]