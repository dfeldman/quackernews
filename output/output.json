[
  {
    "title": "Play snake in the URL address bar (ferrei.ro)",
    "points": 301,
    "submitter": "macote",
    "submit_time": "2025-09-28T21:08:15 1759093695",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=45408021",
    "comments": [
      "This is awesome. My only issue is that the character used for whitespace looks janky in my browser, like a bunch of non-monospaced squares. A potential remedy: because Unicode contains all 256 possible 4x2 Braille patterns, why not use \u28ff as the background and carve out the snake/food as negative space, e.g.\u28ff\u28ff\u28db\u28db\u28db\u28db\u28db\u28e9\u28fd\u28ff\u28ef\u28ff\u28ff\u28ffThis would ensure uniform spacing and is just as legible.reply",
      "Yes, i thought of doing that. The problem is that, while it would definitely help on the early game, it would also mess things badly on the late game. As you snake grows, it'll take more and more space on the grid, and you'll start seeing more and more janky whitespace-replacement characters.The game gets faster as you progress, so it's definitely not a good idea to make it jankyer when you're try-harding it :PI'd love to know of a way of \"fixing\" this jankyness issue properly. Without admitting defeat and rendering to some other text-admitting output, like the page <title>, as this oher snake game that was recently posted on Reddit does: https://old.reddit.com/r/webdev/comments/1n9z77e/snake_in_th...But, for now, if you're actually trying to get a high score, i think the best approach is rendering the URL on page, by clicking on the \"?\"reply",
      "I made a similar thing some time ago, but with the favicon.https://franciscouzo.github.io/favisnake/reply",
      "Likewise, I did 2048 with the favicon years agohttps://aquova.net/games/2048/reply",
      "Oh, this is lovely. The more retina, the less playable it gets :DUpdate: amazing game-over effect!reply",
      "I was pleasantly surprised by how responsive it was, and overjoyed when I clicked back and immediately came back to HN: no messy history. Genius idea!reply",
      "history.pushState vs history.replaceStatereply",
      "One thing to note about these two APIs is that they affect how the session history (the back/forward stack) behaves, but the global browser history (entries shown in the History tab) is separate.Most browsers record every change in the global history regardless of whether `history.pushState` or `history.replaceState` is used. The HTML Spec[0] is explicit about session history but does not define how global history should behave.I can understand why the spec makes no mention of this -- global history is a user-facing UI feature, similar to address bar autocomplete, and it makes sense for browsers to control this behavior. That said, I'm always annoyed when I look into my history tab after visiting a page like this (e.g. Vercel Domains[1]), and see my global history flooded with entries for each individual keystroke I've made, all in the name of \"user experience\".In this particular case, it's just a fun gimmick, but for everyday websites I'd much prefer if they just debounced the updates to the URL to avoid cluttering the global history.[0]: https://html.spec.whatwg.org/#navigation-and-session-history[1]: https://vercel.com/domainsreply",
      "reading the source it looks like for some browsers that rate limit url updates, it has to use a different way that nukes your back button ability.reply",
      "function drawWorld() {\n  var hash = '#|' + gridString() + '|[score:' + currentScore() + ']';  if (urlRevealed) {\n    // Use the original game representation on the on-DOM view, as there are no\n    // escaping issues there.\n    $('#url').textContent = location.href.replace(/#.*$/, '') + hash;\n  }\n\n  // Modern browsers escape whitespace characters on the address bar URL for\n  // security reasons. In case this browser does that, replace the empty Braille\n  // character with a non-whitespace (and hopefully non-intrusive) symbol.\n  if (whitespaceReplacementChar) {\n    hash = hash.replace(/\\u2800/g, whitespaceReplacementChar);\n  }\n\n  history.replaceState(null, null, hash);\n\n  // Some browsers have a rate limit on history.replaceState() calls, resulting\n  // in the URL not updating at all for a couple of seconds. In those cases,\n  // location.hash is updated directly, which is unfortunate, as it causes a new\n  // navigation entry to be created each time, effectively hijacking the user's\n  // back button.\n  if (decodeURIComponent(location.hash) !== hash) {\n    console.warn(\n      'history.replaceState() throttling detected. Using location.hash fallback'\n    );\n    location.hash = hash;\n  }\n}reply"
    ],
    "link": "https://demian.ferrei.ro/snake/",
    "first_paragraph": ""
  },
  {
    "title": "Go ahead, write the \u201cstupid\u201d code (spikepuppet.io)",
    "points": 48,
    "submitter": "spikepuppet",
    "submit_time": "2025-09-28T22:20:59 1759098059",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=45408617",
    "comments": [
      ">>> When I finished school in 2010 (yep, along time ago now), I wanted to go try and make it as a musician. I figured if punk bands could just learn on the job, I could too. But my mum insisted that I needed to do something, just in case.Amusing coincidence. I also wanted to be a rock star, or at least a successful working musician. My mom also talked me out of it. Her argument was: If there's no way to learn it in school, then go to school anyway and learn something fun, like math. Then you can still be a rock star. Or a programmer, since I had already learned programming.So I went to college as a math major, and eventually ended up with a physics degree.I still play music, but not full time, and with the comfort of supporting myself with a day job.reply",
      "Luckily you can still pursue being a musician without all the pressure of having to be successful. On this road, one day you are free to declare your own success to yourselfreply",
      "I'm reminded of the quantity vs. quality groups in a photography class:https://sebastianhetman.com/why-quantity-matters/Do stuff, and you learn stuff. Go play.reply",
      "I like this philosophy. It's interesting to me that the author writes about trying deno, specifically out of curiosity for compiling binaries with it, because that is something that's been specifically tickling the back of my mind for awhile now, but I've had no real reason to try it. I think this gave me the motivation to write some \"stupid\" code just to play with it.reply",
      "This reminds me of the (excellent!) book by Jamie Buck: https://pragprog.com/titles/jbmaze/mazes-for-programmers/They write a maze algo in any new language they learn just to learn bits of the language.reply",
      "Where did you study games? Seems like we have similar trajectories.reply",
      "I appreciate the sentiment, but \"There is no stupid code\" is the dumbest sentence I've ever read.reply",
      "Maybe you don't read much, but it's obvious they weren't making some universal statement about code. They are referring to the code you write when you are just experimenting by yourself, for yourself. The point is to not let irrelevant things like usefulness, quality, conventions, etc. limit just tinkering and learning.reply",
      "He will counter with \"There are no stupid sentences\"!reply",
      "Yeah, I think he\u2019s trying to equate it to something like \u201cthere are no stupid questions.\u201d That\u2019s a pretty silly analogy, but you get the idea.reply"
    ],
    "link": "https://spikepuppet.io/posts/write-the-stupid-code/",
    "first_paragraph": "When I finished school in 2010 (yep, along time ago now), I wanted to go try and make it as a musician. I figured if punk bands could just learn on the job, I could too. But my mum insisted that I needed to do something, just in case. So I went down to the local TAFE (this is like a trade school in Australia, though it has pathways into uni, it\u2019s pretty neat!) and signed up for whatever looked good. I had always loved computers and gaming, I did all the courses for computing short of programming in school (the school didn\u2019t offer it), and had an interest so I signed up.It wasn\u2019t love at first sight, as I still remember after a week freaking out in my room that I couldn\u2019t do this. But I sat down with my massive VB.NET textbook we had to buy and pushed through it. And once I made it through, it clicked. I fell in love with programming after that, and it became something I was both good at and started growing a passion for.From there, going through my games diploma, and my bachelors in ga"
  },
  {
    "title": "Privacy Badger is a free browser extension made by EFF to stop spying (privacybadger.org)",
    "points": 561,
    "submitter": "doener",
    "submit_time": "2025-09-28T12:59:54 1759064394",
    "num_comments": 229,
    "comments_url": "https://news.ycombinator.com/item?id=45404021",
    "comments": [
      "Privacy Badger doesn\u2019t block ads unless they happen to be tracking you; in fact, one of our goals is to incentivize advertisers to adopt better privacy practices.There is an easy solution to this --- it is called \"context sensitive\" advertising. And the idea is simple --- ads are prioritized based on what you're currently viewing, not your viewing history (aka \"personalized ads\").What's wrong with \"personalized ads\"?  They are fundamentally rooted in the past --- and the past is often no longer relevant.  Just because I searched for a car last week doesn't mean I haven't bought one already --- so why am I seeing auto ads when I search for pet supplies?. But if I'm currently looking at an auto dealers web site, the odds are pretty good that I'm still interested in buying one.What's wrong with advertisers? Without any real proof, they have bought into this vision of advertising that is illogical, ineffective and simply not true in many cases --- the idea that personal browsing history is a good indicator of the future.In the process, they have surrendered their ad budgets to a \"black box\" process that they have no insight into or control over and can be easily manipulated against them.So why do I care?  Because we *all* pay a price for this.reply",
      "I don't think people understand the price we pay for these ads. Companies _generally_ are going to operate so they don't lose money. In an industry I am familiar with, I booked someone to clean my home. The total cost was somewhere around $350, about 125 of that went to the actual person cleaning the house. The rest went to a combination of google for the ad and the company I booked through. This industry generally has a 35% marketing expense (sometimes way more) so somewhere around $75 of what I paid to get my house cleaned went to Google. How much better of a job could have been done if the cleaner got a 60% raise? How much better would the local economy be if all of that money stayed local?reply",
      "> How much better of a job could have been done if the cleaner got a 60% raise? How much better would the local economy be if all of that money stayed local?Let's be honest here, if you got rid of their advertising expense it's not going to cause the company to offer the contractor more when they're willing to do the job for less. In a competitive market what happens is that the price goes down, so that you pay $227.50 instead of $350, the cleaner still gets $125, and now there is $102.5 in overhead instead of $225.But that's still good. Overhead is inefficient and you could use the extra money to hire other people which increases labor demand which is the thing that does cause people to get paid more. Or maybe some of the gig workers are doing jobs for people who are themselves not rich and paying less helps them out.The real question is, how do you replace the function of the advertising expense? Suppose you even want to set up a non-profit gig marketplace that doesn't take anything, it just hooks people up with customers and people accept payment with cash or Venmo or whatever. That's pretty much just a website. But then how do you get people to find out about it and use it?reply",
      "I belong to a local Muslim Chamber of Commerce that is basically this. Every business that wants to be a part of the network pays a membership fee (like $300 a year) and gets put into a directory. We have Muslim plumbers, contractors, real estate agents, etc.I think such things can only work at small scales. Once there are too many competing interests it's not as effective.reply",
      "I feel like you're just describing a different form of advertising (pay $300 to be listed in the directory) rather than an alternative to it.In general it seems like the problem is that a marketplace has a network effect. The sellers go where the buyers are and the buyers go where the sellers are. And then the marketplace gets captured by the likes of Google or Facebook who, instead of showing results based on reviews or customer ratings or some other kind of useful curation that allows high quality providers to rise to the top even if they're small, just sell the top slot to whoever bids the most.reply",
      "you can solve this by direct action. when your cleaner arrives, explain you'd like to make a direct arrangement next time, and ask for their phone number.no app can patch this 'analog hole' of the gig industry.reply",
      "That might work for cleaners, but not for rideshare, food delivery and vacation rentals, which probably account for the vast majority of the \"gig economy\".reply",
      "For vacation rentals, I have had the owner give me their card afterwards.For food delivery (at least takeout) and ride share, the app actually provides a real value; it handles matching drivers and customers who want to make a deal now, for a service that is not really super differentiated. It makes sense to stay in their ecosystem and it seems fair that they would be continuing to make a profit.reply",
      "> For food delivery (at least takeout) and ride share, the app actually provides a real valueThe problem with a food delivery network is that it should be a dumb network, not a big profit center. It should be like an ISP, with the food being the high value packets being delivered to you.If you look at pre-UberEats times, each restaurant employed a couple of delivery drivers on scooters. Some might have shared those if the restaurants were on the same street, but that's about it.During low times these drivers would laze around doing nothing, effectively wasting productivity, whereas during peak times, the restaurant didn't have enough drivers.Having one delivery driver network for an entire city should have made things more efficient and cheaper. But because for example in Europe, JustEat-TakeAway and UberEats have inserted themselves as the middleman and crushed out all competition. Delivery has gotten more expensive and inconvenient because of it.These days delivery costs \u20ac3-5 and there is a \u20ac15 delivery minimum. Before, no delivery charge and there was no official minimum. One time one of my friends order a 6-pack of cola, although I doubt they would have delivered that to the edge of the city.Worst of it is, restaurants are not allowed to charge lower prices themselves than they offer on the app. On top of that, JustEat-TakeAway will make a branded store site on restaurantname.localdeliverycompany.com, of which they get a cut versus if you used the restaurant's own site.If delivery is more expensive, more inconvenient and often slower now than before 2015, what 'real value' was added?reply",
      "In the US, delivery was pretty spotty in the pre-app days (pizza places tended to have it almost always, other restaurants were case-by-case). The idea of more community organized joint delivery services is really interesting, it just didn\u2019t exist anywhere I lived in the pre-app-days (maybe it was a thing in major cities, that wouldn\u2019t surprise me).I wonder why the apps out-competed it. Delivery apps are often not even supported officially by the restaurants, right? It\u2019s just sort of like\u2014if somebody comes in for the pickup and gives the right name, they don\u2019t typically care and will just give the delivery guy your order. So it isn\u2019t like some vendor lock-in thing, seems just like network effect from the users or something\u2026reply"
    ],
    "link": "https://privacybadger.org/",
    "first_paragraph": "\n    Privacy Badger is not supported in this browser (more info).\n  Privacy Badger is a browser extension that stops advertisers and other third-party trackers from secretly tracking where you go and what pages you look at on the web.  If an advertiser seems to be tracking you across multiple websites without your permission, Privacy Badger automatically blocks that advertiser from loading any more content in your browser.  To the advertiser, it\u2019s like you suddenly disappeared.Privacy Badger was born out of our desire to be able to recommend a single extension that would:As a result, Privacy Badger differs from traditional ad-blocking extensions in two key ways. First, while most other blocking extensions prioritize blocking ads, Privacy Badger doesn\u2019t block ads unless they happen to be tracking you; in fact, one of our goals is to incentivize advertisers to adopt better privacy practices.Second, most other blockers rely on a human-curated list of domains or URLs to block. Privacy Badg"
  },
  {
    "title": "Autism may be the price of human intelligence, linked to human brain evolution (oup.com)",
    "points": 51,
    "submitter": "ivewonyoung",
    "submit_time": "2025-09-28T23:32:32 1759102352",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=45408994",
    "comments": [
      "What if it is more like Vegeta's super saiyan 2. A false super saiyan 2 form. Just like the real SS2 maintains both power and agility the real \u00dcbermensch will attain new levels of IQ while maintaining if not advancing a strong EQ.https://dragonball.fandom.com/wiki/Super_Saiyan_Second_Gradereply",
      "lol that\u2019s an interesting comparison. Another angle is that our categorization of what is atypical is the actual problem, and. It the symptom itself.reply",
      "Gordon Claridge thought the same about schizotypyhttps://en.wikipedia.org/wiki/Schizotypyreply",
      "There's an ambiguity in the title, reflected in some comments below. It can be understood either as the claim that \"in a particular human being, to be intelligent as measured by IQ means that you are more likely to be autistic\", suggesting for example a trade-off between social and general intelligence; or the claim that \"the evolution of the human brain and so human intelligence as such, which characterizes both those of low and high IQ, entailed those genetic shifts that made autism a possibility for our species but not other primates.\" The paper argues a form of the latter.reply",
      ">  In summary, we introduce a general principle governing neuronal evolution and suggest that the exceptionally high prevalence of autism in humans may be a direct result of natural selection for lower expression of a suite of genes that conferred a fitness benefit to our ancestors while also rendering an abundant class of neurons more sensitive to perturbation.I don't see how the title \"Autism may be the price of human intelligence, linked to human brain evolution\" is at all related to the paper?reply",
      "It is a long paper, so not immediately obvious.> The study links evolutionary neuroscience with neurodevelopmental disease, suggesting that the unusually high incidence of autism in humans might be a byproduct of selection shaping our brains.> It suggests that key neuron types in the human brain are subject to particularly strong evolutionary pressures, especially in their regulatory landscapes.> If valid, it opens a new lens through which to think about neurodiversity: certain vulnerabilities might be inextricable from the very changes that made human cognition distinctivereply",
      "My father\u2019s (extended) side of the family seems to have once a generation severe autistic case and many of us less severely on the spectrum. Doesn\u2019t seem to exist on my mother\u2019s side with any regularity with similar cohort sizes.Lots of PhDs and other left brain super functionals on that side that seems to correlate to intellectual attainment as well.reply",
      "On which side?reply",
      "Father\u2019s.reply",
      "Even when it's Fathers all the way up it's turtles all the way down.reply"
    ],
    "link": "https://academic.oup.com/mbe/article/42/9/msaf189/8245036?login=false",
    "first_paragraph": ""
  },
  {
    "title": "When I say \u201calphabetical order\u201d, I mean \u201calphabetical order\u201d (tronto.net)",
    "points": 347,
    "submitter": "sebtron",
    "submit_time": "2025-09-28T13:00:16 1759064416",
    "num_comments": 229,
    "comments_url": "https://news.ycombinator.com/item?id=45404022",
    "comments": [
      "I agree with Microsoft/Google/KDE's order. The author's situation is extremely rare, and the situation where someone wants \"10\" to be before \"9\" is far more common. Moreover, desktops don't label this sorting \"alphabetical\" (E: and it would really be \"lexicographic\"*), they label it \"by name\" (an informal criteria), so technically they're not lying.> I miss the time when computers did what you told them to, instead of trying to read your mind.You may be looking at that time through rose-tinted glasses. I don't like when computers lie to me either, but \"mind-reading\" is really helpful in ways we take for granted, like autosave. Desktops can have an option to sort files truly alphabetically, but the more common case should always be the default; that's the definition of \"intuitive\".* https://news.ycombinator.com/item?id=45404022#45405279reply",
      "I will add that I'm plenty \"smart\" enough to understand that \"10\" comes before \"9\" in a strictly alphabetical sense, and I still want my file managers to sort \"9\" before \"10\".I don't want to put leading zeroes before every all the single digit numbers in my file names. (And then potentially go come back later and add even more leading zeroes once the maximum number reaches three digits.)---I split all of my audiobooks into chapters. I use the format \"Chapter 01.mp3\" (or \"Chapter 001.mp3\" when there are > 99 chapters) because some (all?) MP3 players are too stupid to sort numbers properly and I want my audiobooks to work everywhere.This works, but it looks kind of ugly and creates extra work\u2014yes I have scripts to automate it, it's still an extra step\u2014and it would be great if I could just trust that every device will understand numbers.reply",
      ">I split all of my audiobooks into chapters. I use the format \"Chapter 01.mp3well, users don't do that. users buy/stream/click whatever content providers offer on a web page. they don't maintain taxonomies. you are not plenty smart enough to realize you're just a computer guy with your own particular preferences in part based on what you think is a hassle to do vs what's acceptable.as a \"for example\", in your shoes I would want to see   chapter  9.mp3\n   chapter 10.mp3\n\nsheerly on the basis of alignment   chapter 9.mp3\n   chapter 10.mp3\n\nlooks like ass. of course i prefer to use   chapter 09.mp3\n   chapter 10.mp3\n\nnot because collation, but because people like you and steve jobs who've only thought the problem through 1/2 way would undoubtedly force a variable pitch font on me and spaces would be less than a full width. here, i've spaced this out so it will alignchapter  9.mp3\nchapter 10.mp3oh wait, HN put that all on one line, here it is spaced out for horizontal alignment and vertical non-coalescence.chapter  9.mp3chapter 10.mp3see? all my spacing gone. solve the whole problem, or don't try, but don't just nibble around the edges, that just pushes the \"design debt\" higher and higher. (I'm not picking on you, it's the tone of these conversations that annoys me)reply",
      "Well, that's not alphabetical order.It's great if DEs build this and give it a name. It's even better if they have a different one that deals with SI prefixes too. But it's not good if \"alphabetical order\" means that.reply",
      "What desktop environment called this alphabetical?reply",
      "I mean, nine does come before ten in alphabetical order.reply",
      "I'm not sure I agree.  I think I could be convinced if there was a unique and universal representation for numeric values using characters.But we have so many textual representations of numeric values that I'm assuming the \"mind-reading\" goodness only works for a small subset.  And the subset will be somewhat intuitive for developers but unlikely to be so for non-technical people.For example, does the order handle numbers with fractions (decimal points)?  If yes, does it require a at least one leading digit (zero)?  Does a.12345 come before or after a.345?Does it handle thousand separators?  What about international thousand and decimal separators (e.g. Euro-style . for thousand separation and , for decimal separation).Does it handle scientific notation?If the answer is no to any of these questions, it's likely to lead to surprise/confusion.It's like a feature request that initially sounds reasonable and useful but once you explore the requirements in detail you realize there are too many edge cases to be able to meet the request in a non-brittle way.reply",
      "The sort rules are simple (1). Treat any consecutive sequence of digits as a number when sorting. So for example version numbers (which must be massively more common than decimals in filenames) work correctly, and 5.9 is indeed smaller than 5.10 and the latter is not identical to 5.1 .Given that this idea goes back more than two decades, has been the default behaviour of the most used OSes for many years, with no major outcry, I think empirically we can be fairly certain that it does not routinely lead to a lot of surprises and confusion.(1) https://en.m.wikipedia.org/wiki/Natural_sort_orderreply",
      "> The sort rules are simpleIn considering the simplicity of the rule, I think you're using a developers perspective here where we automatically classify numbers and have a clear mental model of the separation between value and representation.But I'm not sure how simple it would be to explain to a non-technical user why size_5, size_10 and size_15 are in order but size_0.25, size_0.5 and size_0.75 are out-of-order.> with no major outcryI'm regularly amazed at how little non-developer/technical users complain about strange and confusing behavior.reply",
      "> I'm regularly amazed at how little non-developer/technical users complain about strange and confusing behavior.I am a highly technical user that works with a lot of people with traditional engineering degrees but little to no software experience (except as frequent users). The answer here is that they've learned that all computer software is arcane and mysterious, and so they just accept that there will be strange patterns they have to pick up on, and that's their role as a user. They don't complain about strange and confusing behavior because they treat all the behavior as strange and confusing.reply"
    ],
    "link": "https://sebastiano.tronto.net/blog/2025-09-28-alphabetic-order/",
    "first_paragraph": "Last month I have been on a multi-day hike with my dad. Each of us took\nmany pictures, and when we came back we put them all in a shared folder.\nWe both have Android phones, and the naming scheme used for our pictures\nwas the same: IMG_YYYYMMDD_HHmmss followed maybe by some other numbers\nand then a .jpg. Here YYYY stands for the year, MM for month and\nso on, so that sorting the pictures in alphabetical order is the same as\nsorting them by date.Or so I thought. Strangely, when I looked at the files from my dad\u2019s\nWindows PC, they were not sorted correctly: all the pictures took\nwith my phone came first, followed by all the pictures took by him.\nI thought this was surely some weird Microsoft bug - after using\nWindows 11 at work for a while, I would not be surprised if you\ntold me their file explorer can\u2019t figure out how to sort strings.But then I looked at the same files in a shared Google Drive folder,\nand again they were in the wrong order:As you can see, the picture taken at 5:54 (with"
  },
  {
    "title": "Bayesian Data Analysis, Third edition (2013) [pdf] (columbia.edu)",
    "points": 193,
    "submitter": "ibobev",
    "submit_time": "2025-09-28T17:23:21 1759080201",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=45406109",
    "comments": [
      "This is my favorite book on statistics. Full stop. The author Andrew Gelman created a whole new branch of Bayesian statistics with both his theoretical work on hierarchical modeling while also publishing Stan to enable practical applications of hierarchical models.It took me about a year to work through this book on the side (including the exercises) and it provided the foundation for years of fruitful research into hierarchical Bayesian models. It\u2019s a definitely not an introductory read, but for any looking to advance their statistical toolkit, I cannot  recommend this book highly enough.As a starting point, I\u2019d strongly suggest the first 5 chapters for an excellent introduction to Gelman\u2019s modeling philosophy, and then jumping around the table of contents to any topics that look interesting.reply",
      "What is a book / course on statistics that I can go through before this so that I can understand this?reply",
      "I don\u2019t mean for the bar to sound too high. I think working through khan academy\u2019s full probability, calculus and linear algebra courses would give you a strong foundation. I worked through this book having just completed the equivalent courses in college.It\u2019s just a relatively dense book. There\u2019s some other really good suggestions in this thread, most of which I\u2019ve heard good things about. If you have a background in programming, I\u2019d suggest Bayesian Methods for Hackers as a really good starting point. But you can also definitely tackle this book head on, and it will be very rewarding.reply",
      "Highly recommend Stats 110 from Blitzstein. Lectures and textbook are all online https://stat110.hsites.harvard.edu/reply",
      "Bayesian Statistics the Fun Way is probably the best place to start if you're coming at this from 0. It covers the basics of most of the foundational math you'll need along the way and assumes basically no prerequisites.After than Statistical Rethinking will take you much deeper into more complex experiment design using linear models and beyond as well as deepening your understanding of other areas of math required.reply",
      "Regression and Other Stories. It\u2019s also co-authored by Gelman and it reads like an updated version of his previous book Data Analysis Using Hierarchical/Multilevel Models.Statistical Rethinking is a good option too.reply",
      "Can second Regression and Other Stories, it's freely available here: https://users.aalto.fi/~ave/ROS.pdf, and you can access additional information such as data and code (including Python and Julia ports) here: https://avehtari.github.io/ROS-Examples/index.htmlreply",
      "Is there a good book that covers statistics as it is applied to testing - like for medical research or as optimization or manufacturing or whatever?reply",
      "The key insight to recognize is that within the Bayesian framework hypothesis testing is parameter estimation. Your certainty in the outcome of the test is your posterior probability over the test-relevant parameters.Once you realize this you can easily develop very sophisticated testing models (if necessary) that are also easy to understand and reason about. This dramatically simplifies.If you're looking for a specific book recommendation Statistical Rethinking does a good job covering this at length and Bayesian Statistics the Fun Way is a more beginner friendly book that covers the basics of Bayesian hypothesis testing.reply",
      "I might checkout Statistical Rethinking given how frequently it is being recommended!Edit: Haha I just found the textbook and I\u2019m remembering now that I actually worked through sections of it back when I was working through BDA several years back.reply"
    ],
    "link": "https://sites.stat.columbia.edu/gelman/book/BDA3.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Patagonian Welsh (wikipedia.org)",
    "points": 12,
    "submitter": "tintinnabula",
    "submit_time": "2025-09-25T04:30:13 1758774613",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://en.wikipedia.org/wiki/Patagonian_Welsh",
    "first_paragraph": ""
  },
  {
    "title": "The AI coding trap (chrisloy.dev)",
    "points": 448,
    "submitter": "chrisloy",
    "submit_time": "2025-09-28T15:43:33 1759074213",
    "num_comments": 285,
    "comments_url": "https://news.ycombinator.com/item?id=45405177",
    "comments": [
      "I would love to see an anti-AI take that doesn't hinge on the idea that technology forces people to be lazy/careless/thoughtless.The plan-build-test-reflect loop is equally important when using an LLM to generate code, as anyone who's seriously used the tech knows: if you yolo your way through a build without thought, it will collapse in on itself quickly. But if you DO apply that loop, you get to spend much more time on the part I personally enjoy, architecting the build and testing the resultant experience.> While the LLMs get to blast through all the fun, easy work at lightning speed, we are then left with all the thankless tasksThis is, to me, the root of one disagreement I see playing out in every industry where AI has achieved any level of mastery. There's a divide between people who enjoy the physical experience of the work and people who enjoy the mental experience of the work. If the thinking bit is your favorite part, AI allows you to spend nearly all of your time there if you wish, from concept through troubleshooting. But if you like the doing, the typing, fiddling with knobs and configs, etc etc, all AI does is take the good part away.reply",
      "> I would love to see an anti-AI take that doesn't hinge on the idea that technology forces people to be lazy/careless/thoughtless.The article sort of goes sideways with this idea but pointing out that AI coding robs you a deep understanding of the code it produces is a valid and important criticism of AI coding.A software engineer's primary job isn't producing code, but producing a functional software system. Most important to that is the extremely hard to convey \"mental model\" of how the code works and an expertise of the domain it works in. Code is a derived asset of this mental model. And you will never know code as well as a reader and you would have as the author for anything larger than a very small project.There are other consequences of not building this mental model of a piece of software. Reasoning at the level of syntax is proving to have limits that LLM-based coding agents are having trouble scaling beyond.reply",
      "> And you will never know code as well as a reader and you would have as the author for anything larger than a very small project.This feels very true - but also consider how much code exists for which many of the current maintainers were not involved in the original writing.There are many anecdotal rules out there about how much time is spent reading code vs writing.  If you consider the industry as a whole, it seems to me that the introduction of generative code-writing tools is actually not moving the needle as far as people are claiming.We _already_ live in a world where most of us spend much of our time reading and trying to comprehend code written by others from the past.What's the difference between a messy codebase created by a genAI, and a messy codebase where all the original authors of the code have moved on and aren't available to ask questions?reply",
      "> What's the difference between a messy codebase created by a genAI, and a messy codebase where all the original authors of the code have moved on and aren't available to ask questions?The difference is the hope of getting out of that situation. If you've inherited a messy and incoherent code base, you recognize that as a problem and work on fixing it. You can build an understanding of the code through first reading and then probably rewriting some of it. This over time improves your ability to reason about that code.If you're constantly putting yourself back into that situation through relegating the reasoning about code to coding agent, then you won't develop a mental model. You're constantly back at Day 1 of having to \"own\" someone else's code.reply",
      "The key point is \"relegating the reasoning\". The real way to think about interfacing with LLMs is \"abstraction engineering\". You still should fully understand the reasoning behind the code. If you say \"make a form that captures X, Y, Z and passes it to this API\" you relegate how it accomplishes that goal and everything related to it. Then you look at the code and realize it doesn't handle validation (check the reasoning), so you have it add validation and toasts. But you are now working on a narrower level of abstraction because the bigger goal of \"make a user form\" has been completed.Where this gets exhausting is when you assume certain things that you know are necessary but don't want to verify - maybe it let's you submit an email form with no email, or validates password as an email field for some reason, etc. But as LLMs improve their assumptions or you manage context correctly, the scale tips towards this being a useful engineering tool, especially when what you are doing is a well-trodden path.reply",
      "I find this to be too rosy a story about using agentic coding to add to a codebase. In my experience, miss a small detail about the code and the agent may can go out of control creating a whole new series of errors that you wouldn\u2019t have had to fix. And even if you don\u2019t miss a detail, the agent eventually forgets because of the limited context window.This is why I\u2019ve constrained my use of AI agents to mostly \u201cread-only and explain\u201d use cases, but I have very strict conditions for letting it write. In any case, whatever productivity gains you supposedly \u201cget\u201d for its write scenarios, you should be subtracting your expenses to fix its output later and/or payments made for a larger context window or better reasoning. It\u2019s usually not worth the trouble to me when I have plenty of experience and knowledge to draw from and can write the code as it should be myself.reply",
      "So there\u2019s another force at work here that to me answers the question in a different way. Agents also massively decrease the difficulty of coming into someone else\u2019s messy code base and being productive.Want to make a quick change or fix? The agent will likely figure out a way to do it in minutes rather the than hours it would take me to do so.Want to get a good understanding of the architecture and code layout? Working with an agent for search and summary cuts my time down by an order of magnitude.So while agree there\u2019s a lot more \u201cwhat the heck is this ugly pile of if else statements doing?\u201d And \u201cwhy are there three modules handling transforms?\u201d, there is a corresponding drop in cost to adding features and paying down tech debt.  Finding the right balance is a bit different in the agentic coding world, but it\u2019s a different mindset and set of practices to develop.reply",
      "In my experience this approach is kicking the can down the road. Tech debt isn't paid down, it's being added to, and at some point in the future it will need to be collected.When the agent can't kick the can any more who is going to be held responsible? If it is going to be me then I'd prefer to have spent the hours understanding the code.reply",
      "> You're constantly back at Day 1 of having to \"own\" someone else's code.If only there were some people in software engineering in this situation before AI\u2026 oh wait.In the current times you\u2019re either an agent manager or you\u2019re in for a surprise.reply",
      "> In the current times you\u2019re either an agent manager or you\u2019re in for a surprise.This opinion seems to be popular, if only in this forum and not in general.What I do not understand is this;  In order to use LLM's to generate code, the engineer\n  has to understand the problem sufficient enough to\n  formulate prompt(s) to use in order to get usable\n  output (code).  Assuming the engineer has this level\n  of understanding along with knowledge of the target\n  programming language and libraries used, how is using\n  LLM code generation anything more than a typing saver?reply"
    ],
    "link": "https://chrisloy.dev/post/2025/09/28/the-ai-coding-trap",
    "first_paragraph": "If you ever watch someone \u201ccoding\u201d, you might see them spending far more time staring\ninto space than typing on their keyboard. No, they (probably) aren\u2019t slacking off.\nSoftware development is fundamentally a practice of problem-solving, and so, as with\nsolving a tricky crossword, most of the work is done in your head.In the software development lifecycle, coding is the letters filled into the crossword,\nonly a small amount of effort compared to all the head scratching and scribbled notes.\nThe real work\nusually happens alongside coding, as the developer learns the domain, narrows down\nrequirements, maps out relevant abstractions, considers side effects, tests features\nincrementally, and finally squashes bugs that survived this rigorous process. It looks\nsomething like this:But with AI-driven coding, things play out very differently.AI coding agents such as Claude Code are\nmaking it astonishingly fast to write code in isolation. But most software lives within\ncomplex systems, and since "
  },
  {
    "title": "The QMA Singularity (scottaaronson.blog)",
    "points": 58,
    "submitter": "frozenseven",
    "submit_time": "2025-09-28T19:00:20 1759086020",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=45406911",
    "comments": [
      "I'm impressed but only a little surprised an AI reasoning model could help with Aaronson's proof.The reason I'm only a little surprised is that it's the kind of question I would expect to be in the literature somewhere, either as stated or stated similarly, and I suspect this is why GPT5 can do it.I am impressed because I know how hard it can be to find an existing proof, having spent a very long time on a problem before finding the solution in a 1950 textbook by Feller. I would not expect this to be at all easy to find.I can see this ability advancing science in many areas. The number of published papers on medical science is insane. I look forward to medical researchers questions being answered by GPT5 too, although in that case it'd need to provide a citation since proof can be harder to come by.Also, it's a difficult proof step and if I'd come up with it, I'd be /very/ pleased with myself. Although I suspect GPT5 probably didn't come up with this based on my limited experience using it to try and solve unrelated problems.reply",
      "As someone who has worked in adjacent areas, I guessed that one might find it in random matrix pedagogy, but only after reading Sam (B) Hopkin's comment was I able to get google to give a source for something close to that formula:https://mathoverflow.net/a/300915(In particular, I had to prompt with \"Stieltjes transform\". \"Resolvent\" alone didn't work.)reply",
      "Excerpt:\nBut here\u2019s a reason why other people might care. This is the first paper I\u2019ve ever put out for which a key technical step in the proof of the main result came from AI\u2014specifically, from GPT5-Thinking.reply",
      "\"came from\" after some serious guidance, though the fact that GPT5 can offer candidate solutions (?) is pretty nicereply",
      "It can't offer solutions, it can offer cribbed patterns from the training corpus (more specifically some fuzzy superposition of symbol combinations) that apply in some specific context. It's not clear why Aaronson is constantly hyping this stuff b/c it seems like he is much more rigorous in his regular work than when he is making grand proclamations about some impending singularity wherein everyone just asks the computer the right questions to get the right answers.reply",
      "> maybe GPT5 had seen this or a similar construction somewhere in its training dataI'm disappointed that he didn't spend a little time checking if this was the case before publishing the blog post. Without GPT, would it really have taken \"a week or two to try out ideas and search the literature\", or would it just have taken an hour or so to find a paper that used this function? Just saying \"I spent some time searching and couldn't find this exact function published anywhere\" would have added a lot to the post.Sharing the conversation would be cool too, I'm curious if Scott just said \"no that won't work\" 10 times until it did, or if he was constructively working with the LLM to get to an answer.reply",
      "The expression f(z) = \\sum_i 1/(z-\\lambda_i) is called Stieltjes transform and is heavily used in random matrix theory and similar expressions are used in other works such as Batson, Spielman and Srivastava. This is all to analyze the behavior of eigenvalues which is exactly what they were trying to understand. I'd be very surprised if Aaronson doesn't know about this.reply",
      "He could have asked GPT to find prior mentions or inspirations for this idea...reply",
      "> or would it just have taken an hour or so to find a paper that used this function?It is pretty hard to find something like this perhaps if you had math aware search engine enhanced with AI and access to all math papers you could find if this was used in the past. I tried using approach0 (math aware search engine) but it isn't good enough and I didn't found anything.reply",
      "Yeah, if you don't know the name of the thing you're looking for, you can spend weeks looking for it. If you just search for generic like \"eigenvalue bound estimate\", you'll find thousands of papers and hundreds of textbooks, and it will take substantial amount of time to decide whether each is actually relevant to what you're looking for.reply"
    ],
    "link": "https://scottaaronson.blog/?p=9183",
    "first_paragraph": "A couple days ago, Freek Witteveen of CWI and I posted a paper to the arXiv called \u201cLimits to black-box amplification in QMA.\u201d  Let me share the abstract:We study the limitations of black-box amplification in the quantum complexity class QMA. Amplification is known to boost any inverse-polynomial gap between completeness and soundness to exponentially small error, and a recent result (Jeffery and Witteveen, 2025) shows that completeness can in fact be amplified to be doubly exponentially close to 1. We prove that this is optimal for black-box procedures: we provide a quantum oracle relative to which no QMA verification procedure using polynomial resources can achieve completeness closer to 1 than doubly exponential, or a soundness which is super-exponentially small. This is proven by using techniques from complex approximation theory, to make the oracle separation from (Aaronson, 2008), between QMA and QMA with perfect completeness, quantitative.You can also check out my PowerPoint sli"
  },
  {
    "title": "Farewell friends (humbledollar.com)",
    "points": 118,
    "submitter": "mooreds",
    "submit_time": "2025-09-28T21:31:10 1759095070",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=45408229",
    "comments": [
      "It is always very humbling to read such notes - the self-written post passing away letters. There have been others in hacker news, and they always make me think about life, about what matters to me the most and of course, what matters to others.What struck me most about this one is that it spoke much more about the professional life then about the personal one. I would imagine that if I were to ever write one (which I won\u2019t, cause I\u2019ll live forever) it will be more on the side of outside work experiences.Life is a beautiful gift, and it\u2019s worth remembering that every day. Do what you love, do a lot of it, be kind to others, hug your cherished people, laugh, enjoy, smile\u2026breathe.I love you all, and hope you\u2019re enjoying every moment of this incredible journey through the Universe on this floating space rock.reply",
      "Old family photos do that for me too \u2014 make me think of both the brevity of life and the beauty it is just to have lived. To see the arc of those who have gone before you should be a sobering thought, but I also find a kind of comfort in a humbleness of knowing I too am just like them as they once were like I am now.(In fact, something similar was a common headstone epitaph that a relative of mine who died over 100 years ago has on his own headstone.)I wrote a bit about it here: https://engineersneedart.com/blog/camera/camera.htmlreply",
      "For me, what I do is fairly closely linked with who I am. It's no longer unhealthy, but it used to be.A lot of my legacy will be completely unheralded, and that's as it should be.I do appreciate (but can't really say I \"like\") these posts.Much better than the old \"GBCW\" (GoodBye Cruel World) posts that people used to post, when they rage-quit forums.reply",
      "Im a generally happy, fulfilled person but if I get one more chance to blast the HN crowd on my way out Im gonna take itreply",
      "The reason may be that the intended audience was the readers of his professional blog. He propoably prepared a more personal one for close friends and family.reply",
      "I often think of Speaker for the Dead.My parents died just as I was entering adulthood many years ago. They were both kind/accidental iconoclasts with lives that were unusual to the tune of 1 in a billion, or really, discretely unique, like all people perhaps. They bridged eras, continents, cultural inertias, familial blendings.I lost so much... everything really, when they died. I have so many questions I forgot to ask, so many things I forgot to write down.People are important. Even people who go unnoticed can have weird and niche insights.I think of ImageNet. People are far more important and their lives and insights far less uniform. We miss much by letting all these people go without hearing them, without trying to understand them.reply",
      "Al you can do it record what you recall about your parents \u2014 and record things about yourself for future generations.reply",
      "Some additional context about the author:> Jonathan Clements founded HumbleDollar at year-end 2016. Earlier in his career, he spent almost 20 years at The Wall Street Journal, where he was the newspaper's personal finance columnist, and six years at Citigroup, where he was director of financial education for the bank's U.S. wealth management arm. He was also the author of a fistful of personal finance books, including My Money Journey and How to Think About Money.* https://humbledollar.com/about/jonathan-clements/* A Money Guru Bet Big on a Very Long Life. Then He Got Cancer. https://www.nytimes.com/2024/07/13/your-money/jonathan-cleme...* https://www.reddit.com/r/financialindependence/comments/1npe...* Tributes to Jonathan Clements https://humbledollar.com/2025/09/tributes-to-jonathan-clemen...* Best of Jonathan\u2019s HumbleDollar Posts https://humbledollar.com/2025/09/best-of-jonathans-humbledol...* Choosing Happiness https://news.ycombinator.com/item?id=32804468 (3 years ago, 101 comments)reply",
      "I learned a lot about investing and index funds from his Getting Going column. A shame that he didn't get to retire on all of his frugally invested money. He was 62.reply",
      "The thought of this kind of thing makes me think I should just go buy that Aston Martin tomorrow.reply"
    ],
    "link": "https://humbledollar.com/forum/farewell-friends/",
    "first_paragraph": "Check your inbox or spam folder to confirm your subscription.Go to main Forum page \u00bbIf this post is appearing, it means I\u2019ve succumbed to cancer or one of its side effects. Please don\u2019t feel sad for me. I\u2019ve had a life filled with love, great experiences and wonderful career opportunities. Despite my demise at a relatively young age, I consider myself beyond fortunate.I\u2019m hoping that, under the tree in front of our little Philadelphia rowhome, my wife Elaine will place a stone tablet inscribed with my name, and the year I was born and died. Underneath, I\u2019d like the tablet to read:Family \u2022 Readers \u2022 Words(Note to Elaine: If you ever move, feel free to take the tablet with you.)Family is everybody who\u2019s brought love into my life: Elaine, my two children, my larger family, my close friends. Meanwhile, readers have been those I\u2019ve served, and who rewarded that service with so much loyalty and affection. Finally, words have been my playground, taking the insights I\u2019ve garnered and trying to"
  },
  {
    "title": "Scm2wasm: A Scheme to WASM compiler in 600 lines of C, making use of WASM GC (lain.faith)",
    "points": 129,
    "submitter": "todsacerdoti",
    "submit_time": "2025-09-28T15:43:25 1759074205",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=45405175",
    "comments": [
      "In case you are interested I wrote a minimal OOP runtime in wasm-gc (using wasm text format) here: https://marianoguerra.org/posts/bootstrap-post-collapse-oop-...I also wrote a forth in wasm by hand here: https://github.com/marianoguerra/ricardo-forthAnd a wasm compiler that fits in a tweet: https://wasmgroundup.com/blog/wasm-compiler-in-a-tweet/I'm also the co-author of a book that shows you how to write a compiler that targets wasm for a small languaje using js: https://wasmgroundup.com/Here's a direct link to the wasm text format for the OOP and forth implementations:- https://github.com/marianoguerra/mclulang/blob/main/wat/fatt...- https://github.com/marianoguerra/ricardo-forth/blob/master/s...reply",
      "The Birth & Death of JavaScript wasn't talking about WASM, it was talking about Asm.js, which crucially differs from WASM by being a backwards-compatible subset of JavaScript amenable to JIT compilation. The goals of these standards look similar if all you care about is transpiling c and running it on a browser, but Asm.js worked everywhere from day zero modulo performance; WASM continues to be a moving target.reply",
      "a minimal OOP runtimeWhat does this mean?reply",
      "Meta comment: I love that this is on a self-hosted forge.I'm hoping that AT protocol-based self-hosted forges let us have the independence of self-hosted but the networking and gamification of GitHub. Maybe something like Tangled will bring that, though I haven't looked too deeply.reply",
      "Related: Guile Hoot is a Scheme to Wasm compiler written in Scheme.https://spritely.institute/hoot/reply",
      "Can it be used as a interpreter once compiled to not need a compiler?reply",
      "This isn't quite a standards conforming Scheme just yet.On the other hand, Hoot supports WASM-GC on release [0], and has had wasm support for a few years now. (Though Safari support has been a pain point - they've found a few bugs in WebKit's wasm support.)[0] https://spritely.institute/news/hoot-0-6-1-released.htmlreply",
      "Just eyeballing it really quickly, it doesn\u2019t look like it\u2019s got the built-ins you\u2019d want to quickly built a REPL (i.e. read or eval). It\u2019s not really Scheme, yet.It\u2019s written in C, so you could compile that to wasm and then compile & run all inside the browser (I guess, assuming wasm is cool with that sort of thing, not a wasm guy here).reply",
      "You can do that kind of JIT code generation with WASM but you need to compile a separate module and load and link things up in JS (doable but not technically within pure WASM, so it won\u2019t work in standalone runtimes)reply",
      "With call/cc ??reply"
    ],
    "link": "https://git.lain.faith/iitalics/scm2wasm",
    "first_paragraph": "really bad minimal scheme compiler"
  },
  {
    "title": "Supermicro server motherboards can be infected with unremovable malware (arstechnica.com)",
    "points": 176,
    "submitter": "zdw",
    "submit_time": "2025-09-24T17:32:30 1758735150",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=45363465",
    "comments": [
      "\"If a potential attacker already has administrative access to the BMC...\"Then you've already lost.The BMC needs to be ideally on a physically isolated network, or at least a separate one that has no route from the outside nor on the machine itself.reply",
      "That\u2019s a cop-out. It should be the case that even administrator access should not be abusable to implant permanent backdoors.Anything that makes privileges escalation exploits more damaging is a real problem. I\u2019m getting tired of how these are being dismissed as if admin access should mean that you can ignore any security issues. There are things that even admin accounts should not be able to change at the hardware level, or if they can they must be reversible in the future by another user with admin access.> The BMC needs to be ideally on a physically isolated network, or at least a separate one that has no route from the outside nor on the machine itself.This is good practice but it shouldn\u2019t excuse poor security at the hardware level.Supermicro motherboards also commonly default to having a feature that bonds the BMC network interface to one of the main NICs if you don\u2019t plug a cable into the BMC interface. It\u2019s common for people to be surprised that their BMC is exposed on their main network because they didn\u2019t plug in a cable on the BMC NIC port at all.reply",
      "> It should be the case that even administrator access should not be abusable to implant permanent backdoors.It's really the \"permanently\" which is the design flaw. Boards should have a mechanism to recover from bad firmware, and the same mechanism is useful to recover from a bad flash.Make the flash chip removable, or leave a JTAG. Or have a bit of actual ROM with the write lines not even connected and just enough of a firmware to be able to reflash the main one.reply",
      "It is removable, by desoldering. This is not uncommon and Ars's sensationalized reporting does not helpThis is exactly the kind of barrier you want for something with so much power over the system, otherwise you're not much better off than where you started as physical access allows for quick swaps of chips.reply",
      "Desoldering is ridiculous. It's much more likely to damage the board, requires a much less common level of skill and doesn't allow you to check the existing data without performing the dangerous and expensive operation.Meanwhile it provides no meaningful resistance against physical access because someone with physical access can swap the entire board.reply",
      "I've made an effort but I can't find where this is truly irreversible.  It just talks about usual things like reinstalling the OS not working because the malware is active before EFI.  I didn't see reference in either this article or the linked one from Binarly.reply",
      "It should be the case that even administrator access should not be abusableIf administrator access is equivalent to ownership, then I strongly disagree.reply",
      "Even as an owner, you should not be able to arbitrarily restrict the rights of future owners.reply",
      "No more hole sawing my old hard drives for me, lest I restrict rights of future owners to use the drives as storage devices.reply",
      "Well they'd still have the right, just not the ability (this is actually a distinction US courts have made regarding arbitration clauses and legal recourse).reply"
    ],
    "link": "https://arstechnica.com/security/2025/09/supermicro-server-motherboards-can-be-infected-with-unremovable-malware/",
    "first_paragraph": "\n        Baseboard management controller vulnerabilities make remote attacks possible.\n      Servers running on motherboards sold by Supermicro contain high-severity vulnerabilities that can allow hackers to remotely install malicious firmware that runs even before the operating system, making infections impossible to detect or remove without unusual protections in place.One of the two vulnerabilities is the result of an incomplete patch Supermicro released in January, said Alex Matrosov, founder and CEO of Binarly, the security firm that discovered it. He said that the insufficient fix was meant to patch CVE-2024-10237, a high-severity vulnerability that enabled attackers to reflash firmware that runs while a machine is booting. Binarly discovered a second critical vulnerability that allows the same sort of attack.Such vulnerabilities can be exploited to install firmware similar to ILObleed, an implant discovered in 2021 that infected HP Enterprise servers with wiper firmware that per"
  },
  {
    "title": "Corral.BAS (basic-code.bearblog.dev)",
    "points": 15,
    "submitter": "ibobev",
    "submit_time": "2025-09-25T19:31:07 1758828667",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://basic-code.bearblog.dev/corral/",
    "first_paragraph": "Home About RSSSupport SGDF\n\n\n                    25 Sep, 2025\n                \n\nClick the gameplay window to enter commands.Each round you can take 1-5 steps towards your horse to catch it. It'll bolt if you cover more than half the distance at once, and may kick if you get within 2 steps. Try not to get kicked.We initialize here. DIM sets the size of our arrays. The READ statement reads in our DATA, populating S's first two dimensions.I've rewritten the instructions to be more concise.More initialization. These variables will be reset if we play again.Horse CLAMP makes sure the horse doesn't exit our playfield.Our primary loop begins with drawing our playfield, reading each element of the A array looking for a match to our Horse or Cowboy positions.Get player input and ensure that it's legal.More of our loop, checking for kicks and bolting if we get too close too fast.Did we catch the horse?Give our horse its movement for the round.Game over states and the play again query.\n#David Ahl"
  },
  {
    "title": "VMScape and why Xen dodged it (virtualize.sh)",
    "points": 85,
    "submitter": "plam503711",
    "submit_time": "2025-09-28T18:19:01 1759083541",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=45406573",
    "comments": [
      "On HP business PCs, Xen's microkernel architecture was extended for copy-on-write nested virtualization microVMs (VM per browser tab or HTTP connection) and UEFI-in-VM, https://www.platformsecuritysummit.com/2018/speaker/pratt/ |  https://news.ycombinator.com/item?id=42282053#42286147Imminent unification of Android and ChromeOS will likely use a similar h/w nested-virt architecture based on L0 pKVM + L1 KVM hypervisors on Arm devices.Honda is using Xen, \"How to accelerate Software Defined Vehicle\" (2025), https://static.sched.com/hosted_files/xensummit2025/93/HowTo...reply",
      "Since everyone is upset about the lack of technical details in the article, I'll try:The takeaway from that paper (imo, afaict) is that guest userspace can influence indirect predictor entries in KVM host userspace. I don't really know anything about Xen, but presumably it is unaffected because there is no Xen host userspace, just a tiny hypervisor running privileged code in the host context. With KVM, Linux userspace is still functional in the host context.Presumably, the analogy to host kernel/userspace in KVM is dom0, but in Xen this is a guest VM.\nIf cross-guest cases are mitigated in Xen (like in the case of KVM, see Table 2 in the paper), you'd expect that this attack just doesn't apply to Xen. Apart from there being no interesting host userspace, IBPB/STIBP might be enough to insulate other guests from influencing dom0. If you're already taking the hit of resetting the predictors when entering dom0, presumably you are not worried about this particular bug.edit: Additional reading, see https://github.com/xen-project/xen/blob/master/xen/arch/x86/...reply",
      "While it\u2019s interesting that Dom0 avoids Spectre-style branch prediction attacks it\u2019s not clear from TFA exactly why that is so. How does the architecture of the hypervisor avoid an attack that seems to be at the hardware level? From my limited understanding of Spectre and Meltdown, swapping from a monolithic to a microkernel wouldn\u2019t mitigate an attack. The mitigations discussed in the VMscape paper [0] are hardware mitigations in my reading. And I don\u2019t see Xen mentioned anywhere in the paper for that matter.I guess it\u2019s sort of off topic, but I was enjoying reading this until I got to the \u201cThat\u2019s not just elegant \u2014 it\u2019s a big deal for security\u201d line that smelled like LLM-generated content.Maybe that reaction is hypocritical. I like LLMs; I use them every day for coding and writing. I just can\u2019t shake the feeling that I\u2019ve somehow been swindled if the author didn\u2019t care enough to edit out the \u201cobvious\u201d LLM tells.[0]: https://comsec-files.ethz.ch/papers/vmscape_sp26.pdfreply",
      "I think the author actually meant \"Yes, vmscape can leak information on Xen, but only leaks from a miniature Dom0 process.\" Leaking from an small pool not being a security issue they seemed to consider.Agreed on the point about hw-level mitigation. The leakage still exists. Containing it in a watertight box is quick and effective, and it does avoid extra overhead. But it doesn't patch the hole.reply",
      "Maybe this is the problem with LLMs, Using them feels great, But having them be used on you is highly unpleasant.reply",
      "I think it might be translation from French instead of LLM usage.While Microkernels are great for overall security, it's also not obvious to me how it helped in this case.reply",
      "It's not necessarily a sign of AI slop \u2014 could be just proper typography! :3reply",
      "It's not the em dash, but the negative parallelism (\"not X, but Y\"). This is a pattern which some LLMs really like using. I've seen some LLM-generated texts which used it in literally every sentence.(The irony of opening with this pattern is not lost on me.)As an aside, Wikipedia has a fascinating document identifying common \"tells\" for LLM-generated content:https://en.wikipedia.org/wiki/Wikipedia:Signs_of_AI_writingreply",
      "It's antithesis. And it's really overused by ChatGPT.reply",
      "I have autism and I like using that kind of comparison when writing.reply"
    ],
    "link": "https://virtualize.sh/blog/vmscape-and-why-xen-dodged-it/",
    "first_paragraph": "It\u2019s been less than two weeks since the security team at ETH Z\u00fcrich published their research on a new microarchitectural attack they call VMScape:It\u2019s a neat piece of work, and it shows once again how CPUs, with all their clever tricks for performance, can sometimes open the door to data leaks across virtual machines.The short version: modern CPUs use a branch predictor to guess where code will go next. It makes things faster, but the predictor also \u201cremembers\u201d past patterns. If you can manipulate that memory, you can mislead the CPU and peek at things you shouldn\u2019t. That\u2019s the basic idea behind Spectre-style attacks.According to the ETH team:In other words, a malicious VM can target the hypervisor\u2019s userspace components and start leaking data. For KVM, that means QEMU, which is heavily exposed. VMware is in the same situation.The researchers also note that Xen is not vulnerable. That\u2019s not because Xen has no bugs (it does, like every hypervisor), but because of its architecture.From d"
  },
  {
    "title": "Roe (YC W24) Is Hiring",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-09-28T21:00:07 1759093207",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=45407951",
    "first_paragraph": ""
  },
  {
    "title": "Imagination as General Intelligence: Reconciling Consciousness and Free Will (zenodo.org)",
    "points": 9,
    "submitter": "SCAQTony",
    "submit_time": "2025-09-28T23:35:22 1759102522",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://zenodo.org/records/17109096",
    "first_paragraph": "This white paper introduces the Predictive Timeline Simulation (PTS) Framework, a model that reframes consciousness as an evolved predictive simulation engine. Drawing on neuroscience, predictive processing, and the Block Universe model of spacetime, it offers a functional, testable account of consciousness without resorting to mysticism.The framework has implications across multiple domains:Philosophy: Proposes an evolutionary role for qualia, treating them as a data format for navigating a deterministic universe.Neuroscience: Models how the brain\u2019s \u201ccommon core network\u201d and predictive systems create a workspace for simulating and evaluating future timelines.Clinical Science: Introduces the Simulation Misfiling Hypothesis, suggesting schizophrenia may result from a breakdown in executive control over this simulation process, with implications for early detection and intervention.Artificial Intelligence: Outlines a blueprint for Artificial General Intelligence (AGI) grounded in imagina"
  },
  {
    "title": "The Weird Concept of Branchless Programming (sanixdk.xyz)",
    "points": 119,
    "submitter": "judicious",
    "submit_time": "2025-09-28T16:40:53 1759077653",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=45405750",
    "comments": [
      "Just so you know, the \"return x < 0 ? -x : x;\" compiles into    abs_branch:\n        mov     eax, edi\n        neg     eax\n        cmovs   eax, edi\n        ret\n\non x64, and into    abs_branch:\n        srai    a5,a0,31\n        xor     a0,a5,a0\n        sub     a0,a0,a5\n        ret\n\non RISC-V if you use a C compiler with a half-decent codegen. And \"branchy\" clamp() translates into    clamp:\n        cmp     edi, edx\n        mov     eax, esi\n        cmovle  edx, edi\n        cmp     edi, esi\n        cmovge  eax, edx\n        ret\n\nSeriously, the automatic transformation between ?: and if-then-else (in both directions) is quite well studied by now. And if you try to benchmark difference between branching and branchless implementations, please make sure that the branches you expect are actually there in the compiler's output.reply",
      "Yeah, if you care about branches for any reason then you need to at least verify the compiler's output, if not drop down to assembly completely.reply",
      "The inverse problem is here too:> int partition_branchless(int* arr, int low, int high) {...\n   for (int j = low; j < high; j++) { ... }... }That for loop is just a sugared while loop which is just a sugared cmp and jmpreply",
      "This great video [0] demonstrates how CPU performance has only increased 1.5-2x over the past 15(!) years when executing extremely branchy code. Really shows you just how deep modern CPU pipelines have become.The video also showcases a much more impressive branchless speedup: computing CRC checksums. Doing this na\u00efvely with an if-statement for each bit is ~10x slower than doing it branchless with a single bitwise operation for each bit. The author of the article should consider showcasing this too, since it's a lot more impressive than the measly 1.2x speedup highlighted in the article. I assume the minimal/nonexistent speedups in the article are due to modern CPU branch prediction being quite good. But branch predictors inherently fail miserably at CRC because the conditional is on whether the input bit is 1 or 0, which is essentially random.[0] https://www.youtube.com/watch?v=m7PVZixO35creply",
      "Branchless is also useful for cryptographic transforms as it frustrates timing attacks. And that\u2019s a situation where it only needs to be relatively fast compared to the branching alternative because we are trying to improve security while limiting the overhead of doing so.reply",
      "The linked video doesn't take into account power consumption of these CPUs. He seems to be comparing laptop CPUs, NUC CPUs and desktop CPUs. If you compare a 100W CPU and a 30W CPU that's a couple of years newer, you shouldn't be surprised there isn't much of a difference in performance.reply",
      "Even if you exclude the three mobile CPUs in the charts (the 2012 i5, the 2015 i7, and the 2023 i9 NUC), the results still hold.>If you compare a 100W CPU and a 30W CPU that's a couple of years newer, you shouldn't be surprised there isn't much of a difference in performanceSure, but this is over a lot more than a couple years. I'd expect a 2023 mobile i9 to be considerably more than twice as fast as a 2007 desktop Core 2 Duo.reply",
      "I enjoyed reading the article, but I'm pretty thrown by the benchmarks and conclusion. All of the times are reported to a single digit of precision, but then the summary is claiming that one function shows an improvement while the other two are described as negligible. When all the numbers presented are \"~5ms\" or \"~6ms\", it doesn't leave me confident that small changes to the benchmarking might have substantially changed that conclusion.reply",
      "Yeah. When your timing results are a single digit multiple of your timing precision, that is a good indication you either need a longer test, or a more precise clock.At a 5ms baseline with millisecond precision, the smallest improvement you can measure is 20%. And you cannot distinguish a 20% speedup with a 20% slowdown that happened to get luck with clock ticks.For what it is worth, I ran the provided test code on my machine with a 100x increase in iterations and got the following:  == Benchmarking ABS ==\n  ABS (branch):     0.260 sec\n  ABS (branchless): 0.264 sec\n\n  == Benchmarking CLAMP ==\n  CLAMP (branch):     0.332 sec \n  CLAMP (branchless): 0.538 sec\n\n  == Benchmarking PARTITION ==\n  PARTITION (branch):     0.043 sec\n  PARTITION (branchless): 0.091 sec\n\nWhich is not exactly encouraging (gcc 13.3.0, -ffast-math -march=native. I did not use the -fomit-this-entire-function flag, which my compiler does not understand).I had to drop down to O0 to see branchless be faster in any case:  == Benchmarking ABS ==\n  ABS (branch):     0.743 sec\n  ABS (branchless): 0.948 sec\n\n  == Benchmarking CLAMP ==\n  CLAMP (branch):     4.275 sec\n  CLAMP (branchless): 1.429 sec\n\n  == Benchmarking PARTITION ==\n  PARTITION (branch):     0.156 sec\n  PARTITION (branchless): 0.164 secreply",
      "I also tried myself, on different array sizes, with more iterations. The branchy version is not strictly worse.https://gist.github.com/Stefan-JLU/3925c6a73836ce841860b55c8...reply"
    ],
    "link": "https://sanixdk.xyz/blogs/the-weird-concept-of-branchless-programming",
    "first_paragraph": "home blogs  about2025-07-08 01:37 \u2022 19+ min read \u2022 #c #branchlessModern CPUs are predictive creatures. They guess what you're about to do, like a nosy algorithm trying to sell you sneakers after you Googled \"foot pain.\" Branch predictors make CPUs fast by speculating on branches... until they guess wrong and everything grinds to a halt for 15,20 cycles.Branchless programming is how we get around this: we rewrite our code to not branch at all. Instead of jumping to conclusions, we manipulate bits like 1980s assembly gremlins.What is a branch first of all?In a program, you may observe parts like this:This block of instructions is a collection of three branches. Each if, elif, and else represents a possible execution path the CPU can take depending on the evaluation of the conditions. At runtime, only one of these paths is taken, and the others are skipped. This choice ,  this deviation in the control flow ,  is what we call a branch.In terms of machine code, a branch is often implemented"
  },
  {
    "title": "Show HN: Toolbrew \u2013 Free little tools without signups or ads (toolbrew.co)",
    "points": 163,
    "submitter": "andreisergo",
    "submit_time": "2025-09-28T14:40:46 1759070446",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=45404667",
    "comments": [
      "I do a similar thing with https://www.thateasy.me/   I use it to test the latest coding/automation tools.  I think I prefer your design :)reply",
      "Can I request Germany for holiday optimizer?reply",
      "Really nice project; my one request would be a way to \"pin\" or \"favourite\" tools since not every tool is likely to be useful for everyone.reply",
      "Does The Youtube downloader work?BTW this reminds me of excellent https://gchq.github.io/CyberChef/reply",
      "Fun story: I had the fun experience of collaborating on an integration with an engineer at JP Morgan Chase who introduced me to this tool, which they use, self-hosted of course, as an alternative to having engineers just pasting things into random online tools that come up when you google \u201cbase64 decode\u201d etc.From our whole interaction, I came away admiring the skill and professionalism of their team.reply",
      "there is also uh, god, I always forget its name whenever I want to use it....AHHHHH YESS, I FINALLY REMEMBERED IT AFTER 5 minutes of thinking.https://cobalt.toolsThis has definitely helped me a lot in a lot of times when I didn't have my pc or just in general too, their api was also pretty hackable too actually and they support more than youtubeBtw did I mention its open source?Tho the last time I did try to install something from cobalt.tools it wasn't workingOne time, I remember that a group of girls in my previous school were downloading yt vids on school lab via some sketchy website and I said to them to use cobalt.tools while I was walking & I definitely farmed some aura too I suppose which I am sure literally everyone involved in the scene have forgotten except me who is recalling it right now.reply",
      "The instance https://cobalt.meowing.de is currently working for YouTube, which is very usefulreply",
      "Ah it's buggy, youtube really doesn't like their videos being downloaded. Built it with yt-dlp library. Continuously tweaking itreply",
      "As a heads up, you might soon need a JS runtime to make it work[1]. You might have to tweak even more (:[1]https://github.com/yt-dlp/yt-dlp/issues/14404reply",
      "Oh boy, fun stuff. Thanks for the heads upreply"
    ],
    "link": "https://toolbrew.co/",
    "first_paragraph": ""
  },
  {
    "title": "Comparing Rust to Carbon (lwn.net)",
    "points": 39,
    "submitter": "pykello",
    "submit_time": "2025-09-25T02:22:07 1758766927",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=45368596",
    "comments": [
      "> The thing is, there is a lot of existing software in the world written in C and C++.This is true, and I think that there is a type of language that I don't think have been explored yet: Cross language ABI language.That is, the language is fully designed for being the glue between multiple languages to allow for migration in the future. I think it would probably end up being C.> There are several languages that have managed a transition away from a base language into a more capable, flexible successor language, though: TypeScript is an evolution of JavaScript, Swift is an evolution of Objective-C, and C++ itself is an evolution of C.And yet none of these have fully escaped the chain of their predecessors. And that is almost the point, people actually wanted to do what JavaScript could do, what C could do, what Objective-C could do. Then we put cover on it, but it is still a wooden table at the end of the day.Have Hyrum's Law teach us nothing? Unless you consciously make the effort to REMOVE features, it will always be there. The fact that cross language boundary is complicated is a sign that the new language is actually shedding off technical debts. If I wrote a massively complicated function in C that leaks file handles, the answer isn't to read /proc/fd before and after, then manually unlink the new FDs. The answer is to actually dig through the code or rewrite it.reply",
      "> That is, the language is fully designed for being the glue between multiple languages to allow for migration in the future. I think it would probably end up being C.Unfortunately, C is woefully insufficient for such a language. At a minimum, you'd want to have a language that can distinguish between nullable and nonnullable pointers, pointer-with-array-len (so C++'s std::span or Rust's slice), and read-only versus read-write pointers (which const only kind of does). Expressing no-alias relationships and very basic lifetime relationships is also pretty critical for several languages. Multiple return values is something I'd love to see, in addition a success-object-or-error-object (something like a Result type). Having a dedicated not-necessarily-null-terminated UTF-8 string type is also useful.reply",
      "The answer is obviously to have a background task that periodically frees the leaked handles made by a program written in Carbon using a c library.reply"
    ],
    "link": "https://lwn.net/Articles/1036912/",
    "first_paragraph": "\nWith a subscription to LWN, you can stay current with what is happening in the Linux and free-software community and take advantage of subscriber-only site features.  We are pleased to offer you a free trial subscription, no credit card required, so that you can see for yourself.  Please, join us!\n\nSafe, ergonomic interoperability between Rust and C/C++ was a popular topic at\n\nRustConf\u00a02025 in Seattle, Washington. Chandler Carruth gave a presentation\nabout the different approaches to interoperability in Rust and\n\nCarbon, the\nexperimental \"(C++)++\" language.\nHis ultimate conclusion was that\nwhile Rust's ability to interface with other languages is expanding over time,\nit wouldn't offer a complete solution to C++ interoperability anytime soon \u2014 and so there is room for\nCarbon to take a different approach to incrementally upgrading existing C++ projects.\nHis\n\nslides are available for readers wishing to study his example code in more\ndetail.\n\nMany of the audience members seemed aware of C"
  },
  {
    "title": "Rustroid, a Rust IDE for Android (is-a.dev)",
    "points": 71,
    "submitter": "coolcoder613",
    "submit_time": "2025-09-25T00:28:35 1758760115",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=45367732",
    "comments": [
      "Do people seriously code on their phone without any keyboards? Are IDEs in demand for phones?(It is not intended to be an insult of any sort. It is a serious question. I do not know anyone who does this and I cannot imagine myself being productive at all. I want to compare WPMs on a keyboard vs. on a phone as well.)reply",
      "I could be wrong, but I recall in many developing countries phones there are many teenagers who code on their phone because laptops (even tablets) are prohibitively costly.They might be wiring their phones up to some cheap keyboards, which is technically possible but I don't know if they're doing that.A friend of mine from a SEA country learned/did all of his coding on a 10-inch Android tablet using the touch-screen keyboard since age 11 until his parents bought him a proper laptop as a gift for going to college.Edit: for example https://news.ycombinator.com/item?id=45286044, there are other cases that I've definitely seen on GitHub but I can't find them at this moment.reply",
      "> I could be wrong, but I recall in many developing countries phones there are many teenagers who code on their phone because laptops (even tablets) are prohibitively costly.Yes, I see that a lot here in the far south of Morocco.> They might be wiring their phones up to some cheap keyboards, which is technically possible but I don't know if they're doing that.They do. Adapters are about $2.reply",
      "Why do that when bluetooth keyboards are cheap these days too? For like $11 you can get a bluetooth keyboard, which would most likely just work...I could also see some of them using a cheap tablet for the larger screen, but I've also run into teens who use their phones exclusively.reply",
      "It may be $11 here in the US, but it might be harder to get and more costly in a developing nation. In which case, if it is easier to get that $2 adapter and an e-waste keyboard, that likely makes sense for themreply",
      "Sure, I don't discount that, I guess my real point was that bluetooth might still be viable depending on country.reply",
      "Hmm, I see. Of course if I had no choice like those people, I would rather pick \"coding uncomfortably on a phone\" over \"not coding at all\".reply",
      "> They might be wiring their phones up to some cheap keyboards, which is technically possibleNot just possible, but quite easy. You just plug it in (or connect it via bluetooth) same as with a computer.reply",
      "I have a friend who works a normal 9 to 5 and codes from his phone at his full time job when there's down time.I've also met in programming discords various younger developers who write code from the only computing device they have access to: their phones.reply",
      "I code on my phone using termux, tmux, nvim, and Unexpected Keyboard (no physical keyboard) on an Android phone. Vim style modal editing is actually really well suited to this kind of development.It lets me work on my hobbies while I commute, travel, or am otherwise idle and is a nice alternative to scrolling social media or consuming content.With git, I can just sync my changes and work from a PC when I can/want to.reply"
    ],
    "link": "https://rustroid.is-a.dev/story",
    "first_paragraph": ""
  }
]