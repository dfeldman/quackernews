[
  {
    "title": "Stoop Coffee: A simple idea transformed my neighborhood (supernuclear.substack.com)",
    "points": 790,
    "submitter": "surprisetalk",
    "submit_time": "2025-03-25T17:16:45 1742923005",
    "num_comments": 293,
    "comments_url": "https://news.ycombinator.com/item?id=43473618",
    "comments": [
      "> my husband Tyler and I wanted that sense of community that feels like it\u2019s only possible in the suburbs, but we believed we could achieve this while living in San Francisco.This genuinely threw me because in my experience the suburbs are the antithesis of this, just lots of people occupying neighboring space and rarely talking to each other.Still, a heartwarming story all the same. And yes, this is _exactly_ what city living should enable.\n \nreply",
      ">just lots of people occupying neighboring space and rarely talking to each other.This is a bitter stereotype that is leveled against both city-dwellers and suburb-dwellers, and, like many stereotypes, has some truth to it in both cases, but amounts to uncalled-for negativity. Some people don't want to interact with their neighbors, regardless of whether they live in a city or a suburb. Others are sociable with their community, and express it just as well whether they live in a city or a suburb.\n \nreply",
      "Suburbs often have physical constraints with the way houses are laid out making this \"stoop coffee\" approach more difficult, if anything.  Houses laid out in a way that you're more likely to drink your coffee on your back patio surrounded by a fence or hedges to avoid being seen.  And even if you are sitting in front of your house, neighbors are more likely to be driving by instead of walking so not very likely to stop and chat.In densely populated cities, you are often in close proximity with other humans you haven't met yet.  But there can be social and cultural norms to keep walking and avoid eye contact because social interaction with all the countless people you pass is completely impractical.https://www.youtube.com/watch?v=2AoNuz1gjQoSo both environments have their challenges for impromptu social interactions.\n \nreply",
      "> to avoid being seenwell, there's also security, physical containment of your pet/children.I think of Frost's \"Good fences make good neighbors\"\n \nreply",
      "> Suburbs often have physical constraints with the way houses are laid out making this \"stoop coffee\" approach more difficult, if anything. Houses laid out in a way that you're more likely to drink your coffee on your back patio surrounded by a fence or hedges to avoid being seen.This has not been my experience in the surburbs. A typical suburban home has both spaces: a front yard/patio and a back yard/patio. If anything the physical constraints are substantially more conducive to hanging out out front than what I'm seeing in these photos here\u2014people in the suburbs have some amount of space that they actually own in front of their home, they don't have to occupy the sidewalk.As OP said, which one people choose to use depends on the personality of the individual, not the layout of the space. For example: our last four homes, like every home in each neighborhood, have had both, and I always prefer to be out back while my wife loves being out front interacting with the neighbors as they walk by (which, yes, they have regularly done in all four neighborhoods!).\n \nreply",
      "I think this may vary massively depending on what suburbs in what country and even what city you are talking about. The \"usable front yard\" or \"front patio\" is an almost non-existent design feature in free standing homes in Australia, at least in the more moderate climates in the southern side of the eastern seaboard.I'd heavily agree with the idea that my suburban experience is that I do not know my neighbours, and the only time I've known them has been for bad reasons (harassment, fencing disputes etc.). In the inner city, I may not know my neighbours, but you probably know and interact with your general community in public spaces a lot more than the suburbs, mainly because you don't get everywhere by car. The small coffee shop on every corner in the gentrified inner city where people wait on the path for their coffee is a bit reminiscent (to a lesser degree) of  the \"stoop coffee\" idea. That experience in the suburbs only really exists through your children (i.e. via schools and sports clubs) and doesn't exist much for child-free people.With growing high density development near train stations in the suburbs, there is a bit more of this experience further from the city center. However it is really limited to a few square kilometers of urbanism and apartment living that then gives way to endless free standing houses and car dependent suburbia.\n \nreply",
      "It\u2019s easier to sit out in the suburbs, but the layout and infrastructure don\u2019t generally encourage walking around, so there are a lot fewer neighbors walking past.\n \nreply",
      "Generally, surburbs are better at encouraging walking/cycling around (since there's very little traffic), but worse at encouraging people to walk to commercial areas (since they're usually far away and the path there is unpleasant).In my experience, you're far more likely to see kids biking/wandering around neighborhoods in the suburbs than in the city. This is the reason why people want things like cul-de-sacs, because eliminating through traffic means that people are able to use the area much more freely without having to worry about cars.\n \nreply",
      "Contrary to apartment buildings where you have to go inside to your unit and there's not a great place to hang out and meet people\n \nreply",
      "Fewer, sure, but not none. 5-10 people per evening isn't bad, and that's pretty typical for a nice evening in each of those neighborhoods.\n \nreply"
    ],
    "link": "https://supernuclear.substack.com/p/stoop-coffee-how-a-simple-idea-transformed",
    "first_paragraph": ""
  },
  {
    "title": "You might want to stop running atop (rachelbythebay.com)",
    "points": 143,
    "submitter": "subract",
    "submit_time": "2025-03-25T23:09:09 1742944149",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=43477057",
    "comments": [
      "There's a lot of speculation about why, with the answer almost certainly security / exploitable (or backdoor), and I'll just throw an extra little tidbit in:atop seems to run persistently as root, which may be the reason for preventing it from running/uninstalling.the netatop part of atop installs a persistent kernel module, netatop.ko, as part of its installation. The module hooks netfilter to be able to monitor all traffic.If there's an exploitable flaw in the kernel module, this would be a max-severity CVE.netatop _also_ runs a persistent daemon, netatopd, which I believe from inspecting the source runs as root.The article's language about uninstalling it kinda sorta makes you think one of these three parts is in some way exploitable or backdoored -- any which way it's a privileged process, and one that's monitoring network traffic.(I'm not sure if netatop is installed by default on systems when you install atop, per czk's comment below)\n \nreply",
      "I'm not familiar with atop but the website mentions netatop is optional and what I've found suggests you have to manually install it. Do you know if any distributions/packages install this by default alongside the atop install?\n \nreply",
      "This is a good question - I'm not sure. The rpmspec doesn't seem to install it, so perhaps it's not quite that bad. The atop program _itself_ runs persistently, though, so, uh, still bad. :)\n \nreply",
      "This screams NDA/disclosure but things are so mega super fucked that they feel obligated to pre warn as early as possible.I wonder how long/old the problem is in atop?\n \nreply",
      "Yeah, from a rando this would be just bad vagueposting but Rachel is absolutely someone who could know about a very good reason why we should uninstall atop but be unable to legally say why. I would heed her warning.\n \nreply",
      "Seems like the latest version might be as old as July 2024?https://www.atoptool.nl/allnews.phpFor anyone interested, here are the latest commits to the GitHub: https://github.com/Atoptool/atop/commits/master/\n \nreply",
      "I have this weird gut feeling that it's going to be one of those \"this was introduced in 2010 commit and has been in every build since\"Edit: I have no knowledge of what this is FYI.\n \nreply",
      "Agreed. Severe CVE seems like the ticket here given the context.\n \nreply",
      "That last line for sure reads as '(author) can't tell you now, but can (plans to) tell you later'; NDA and/or CVE as most likely reasons.\n \nreply",
      "Presumably one step removed? I assume vague-posting would be an NDA violation, though now I'm second-guessing that...\n \nreply"
    ],
    "link": "https://rachelbythebay.com/w/2025/03/25/atop/",
    "first_paragraph": ""
  },
  {
    "title": "Sell yourself, sell your work (solipsys.co.uk)",
    "points": 59,
    "submitter": "ColinWright",
    "submit_time": "2025-03-25T21:35:16 1742938516",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=43476249",
    "comments": [
      "There are many definitions of \"sell\" that aren't a dichotomy between building toy projects that never leave your private repo, and running a SaaS startup you're trying to grow via LinkedIn and HN.I've found a lot of fulfillment in building tech products/services for friends and family, and making meeting their needs the complete scope of the project, with no intention to release it publicly. I present it as though it's a widely released product, including marketing materials, retail box, printed instruction manual, etc. I enjoy it thoroughly as a creative exercise, and it gives me the opportunity to integrate and combine lots of skills I'm not able to use at work.I don't make any money doing this, but it scratches the itch I have to build things people will use, and I do enjoy showcasing and promoting my latest projects - and an audience of my (less technical) friends and family is a polite and encouraging one. Definitely less stressful than releasing things to the wider internet. This has brought improvements to my real job, where I'm finding myself more comfortable presenting and promoting my achievements.\n \nreply",
      "It\u2019s interesting that no one ever takes the other logical side of this: to really benefit from the work of others you have to look through the marketing bullshit and find the gems that aren\u2019t aggressively sold.\n \nreply",
      "> For the world to benefit from your work, and therefore for you to benefit fully from your work, you have to make it known.\"Fully\" seems to be doing a helluva lot of heavy lifting in this piece. Does anyone think that they mean anything other than \"making money\", as they quickly segue into talking about entrepreneurship and founding businesses?I'm happy to concede that if you don't tell anyone about the stuff you do, no one will know. But I am not willing to concede that you only \"fully\" benefit from your work if you sell it. Nor am I willing to concede that work only has value if sold. I'm also not entirely certain the author is pushing those views. Still, something about this piece doesn't sit well with me.Human endeavors have value beyond the monetary.\n \nreply",
      "The author isn't saying that selling is necessary only to make money. At the end of the article he says \"But the word \"sell\" doesn't necessarily mean what you think it means\", which then leads to the aside:\"you can either do it in such a fashion that people can indeed build on what you've done, or you can do it in such a fashion that the next person has to essentially duplicate again what you've done\"\n \nreply",
      "Strongly disagree. You are allowed to create/do things that no one else know about. Share it if you want, keep it to yourself if you don't. Don't let other people dictate to you what you must do in order to be satisfied with yourself.\n \nreply",
      "I agree, it\u2019s your choice. But, if you want to help others, you also have permission to share your work.You probably don\u2019t think your work is valuable but someone is waiting for your unique perspective. It doesn\u2019t need to be perfect; nothing is.You can also write publicly but for your future self, which drops the barrier to entry.Of course you\u2019re allowed not to write or not to share. It\u2019s not for everyone. But don\u2019t let fear or self-doubt stand in your way either.\n \nreply",
      "The article isn\u2019t disallowing you\u2026\n \nreply",
      "My standard advice:For any young programmers: live within your means, invest the difference, become independent, and work on what you enjoy. It\u2019s the best (work related) gift you can give yourself. Skip the self promotion politics unless you enjoy it.\n \nreply",
      "I'm sorry, but this advice can sometimes sound like \"sell one of your kidneys so you can eat\". What if your means are not sufficient to avoid hunger? Investing negative difference? What if on top of that you're trying to do the work you enjoy and your means - incomes - stop completely? Do you see the problem with advice?\n \nreply",
      "Programmers tend to be paid well?\n \nreply"
    ],
    "link": "https://www.solipsys.co.uk/new/SellYourselfSellYourWork.html?yc25hn",
    "first_paragraph": "\n\n\n\nSubscribe!\n\n\n\n\n\n\nMy latest posts can be\nfound here:\n\nColins Blog\n\n\n\nPrevious blog posts:\n\nAll The Letters\nBeing Slow To Criticise\nState Machine In Real Life\nCoxeter Once Nerd Sniped Conway\nNot Always Your Fault\nRemembering Conway\nPerception Of Space\nParallelogram Puzzle\nBack Of The Envelope COVID19\nA Point Against The Axiom Of Choice\nIn Defense Of The Axiom Of Choice\nJourneying Home Through Storm Dennis\nEarth Radius Refined\nVolume Of A Sphere\nBig Oh And Relations\nMathematical Relations\nIntroducing Big Oh\nConstant Differences\nAlgorithms And Sizes Of Instances\nIntroducing Time Complexity\nThe Linear Frog\nSeventy Versus One Hundred Revisited\nHow The Farrago Works\nSeventy Versus One Hundred\nPowers Of Two In Lex Order\nEmerging E Expanded\nRage Inducing System Implementation\nThe Book Is Not Always Right\nEmerging E\nImpossible To Translate\nWaiting In Vain\nNon Repeating Decimals\nRational Repeats\nWhy Is It Lovely\nCompiling Crypto Connections\nExploring Connections Between Crypto Systems\nElwyn B"
  },
  {
    "title": "4o Image Generation (openai.com)",
    "points": 500,
    "submitter": "meetpateltech",
    "submit_time": "2025-03-25T18:06:02 1742925962",
    "num_comments": 296,
    "comments_url": "https://news.ycombinator.com/item?id=43474112",
    "comments": [
      "What's important about this new type of image generation that's happening with tokens rather than with diffusion, is that this is effectively reasoning in pixel space.Example: Ask it to draw a notepad with an empty tic-tac-toe, then tell it to make the first move, then you make a move, and so on.You can also do very impressive information-conserving translations, such as changing the drawing style, but also stuff like \"change day to night\", or \"put a hat on him\", and so forth.I get the feeling these models are quite restricted in resolution, and that more work in this space will let us do really wild things such as ask a model to create an app step by step first completely in images, essentially designing the whole app with text and all, then writing the code to reproduce it. And it also means that a model can take over from a really good diffusion model, so even if the original generations are not good, it can continue \"reasoning\" on an external image.Finally, once these models become faster, you can imagine a truly generative UI, where the model produces the next frame of the app you are using based on events sent to the LLM (which can do all the normal things like using tools, thinking, etc). However, I also believe that diffusion models can do some of this, in a much faster way.\n \nreply",
      "> What's important about this new type of image generation that's happening with tokens rather than with diffusion, is that this is effectively reasoning in pixel space.I do not think that this is correct. Prior to this release, 4o would generate images by calling out to a fully external model (DALL-E). After this release, 4o generates images by calling out to a multi-modal model that was trained alongside it.You can ask 4o about this yourself. Here's what it said to me:\"So while I\u2019m deeply multimodal in cognition (understanding and coordinating text + image), image generation is handled by a linked latent diffusion model, not an end-to-end token-unified architecture.\"\n \nreply",
      "I think this is actually correct even if the evidence is not right.See this chat for example:https://chatgpt.com/share/67e355df-9f60-8000-8f36-874f8c9a08...\n \nreply",
      "You're incorrect. 4o was not trained on knowledge of itself so literally can't tell you that. What 4o is doing isn't even new either, Gemini 2.0 has the same capability.\n \nreply",
      "Can you provide a link or screenshot that directly backs this up?\n \nreply",
      "Models are famously good at understanding themselves.\n \nreply",
      "I hope you're joking. Sometimes they don't even know which company developed them. E.g. DeepSeek was claiming it was developed by OpenAI.\n \nreply",
      "Well, that one seems to be true, from a certain point of view.\n \nreply",
      "I hope you\u2019re joking :)\n \nreply",
      "It still can't generate a full glass of wine. Even in follow up questions it failed to manipulate the image correctly.\n \nreply"
    ],
    "link": "https://openai.com/index/introducing-4o-image-generation/",
    "first_paragraph": ""
  },
  {
    "title": "Deciphering language processing in the human brain through LLM representations (research.google)",
    "points": 100,
    "submitter": "Korling",
    "submit_time": "2025-03-21T18:44:37 1742582677",
    "num_comments": 38,
    "comments_url": "https://news.ycombinator.com/item?id=43439501",
    "comments": [
      "This is interesting. The blog post links several papers, and I recommend reading them.Responses here however seem not commensurate with the evidence presented. Two of the papers[0][1] that provide the sources for the illustration in the blog post are about research conducted on a very small group of subjects. They measure neural activity when listening to a 30 minutes podcast (5000 words). Participants tried to guess next words. All the talk about \"brain embedding\" is derived from interpreting neuronal activity and sensor data geometrically. It is all very contrived.Very interesting stuff from a neuroscience, linguistics and machine learning perspective. But I will quote from the conclusion of one of the papers[1]: \"Unlike humans, DLMs (deep language models) cannot think, understand or generate new meaningful ideas by integrating prior knowledge. They simply echo the statistics of their input\"[0] Alignment of brain embeddings and artificial contextual embeddings in natural language points to common geometric patterns (https://www.nature.com/articles/s41467-024-46631-y)[1] Shared computational principles for language processing in humans and deep language models (https://www.nature.com/articles/s41593-022-01026-4)\n \nreply",
      "I find the OP very difficult to comprehend, to the point that I question whether it has content at all. One difficulty is in understanding their use of the word \"embedding\", defined (so to speak) as \"internal representations (embeddings)\", and their free use of the word to relate, and even equate, LLM internal structure to brain internal structure. They are simply assuming that there is a brain \"embedding\" that can be directly compared to the matrix of numerical weights that comprise an LLM's training. That seems a highly dubious assumption, to the point of being hand-waving.They mention a profound difference in the opening paragraph, \"Large language models do not depend on symbolic parts of speech or syntactic rules\". Human language models very obviously and evidently do. On that basis alone, it can't be valid to just assume that a human \"embedding\" is equivalent to an LLM \"embedding\", for input or output.\n \nreply",
      ">They mention a profound difference in the opening paragraph, \"Large language models do not depend on symbolic parts of speech or syntactic rules. \"Human language models very obviously and evidently do.Honestly do they ? To me, they clearly don't. Grammar is not how language works. It's useful fiction. Language even in humans seems to be a very statistical process.\n \nreply",
      "I don\u2019t disagree with any of your particular points,  but I think you\u2019re missing the forest here: their argument is primarily based in empirical results, not a theoretical framework/logical deduction. In other words, they\u2019re trying to explain why LLMs work so well for decoding human neural content, not arguing that they do!I think any reasonable scientist would a-priori react the same way to these claims as claims that neural networks alone can possibly crack human intuition: \u201cthat sounds like sci-fi speculation at best\u201d. But that\u2019s the crazy world we live in\u2026\n \nreply",
      "I view this as compelling evidence that current models are more than \"stochastic parrots,\" because as the OP shows, they are learning to model the world in ways that are similar (up to a linear transformation) to those exhibited by the human brain. The OP's findings, in short:* A linear transformation of a speech encoder's embeddings closely aligns them with patterns of neural activity in the brain's speech areas in response to the same speech sample.* A linear transformation of a language decoder's embeddings closely aligns them with patterns of neural activity in the brain's language areas in response to the same language sample.\n \nreply",
      "Yeah, I have always firmly maintained that there is less fundamental difference between LLMs and human brains than most people seems to assume.Going a bit further, I'll speculate that the actions made by a human brain are simply a function of the \"input\" from our ~5 senses combined with our memory (obviously there are complications such as spinal reflexes, but I don't think those affect my main point). Neural nets are universal function approximators, so can't a sufficiently large neural net approximate a full human brain? In that case, is there any merit to saying that a human \"understands\" something in a way that a neural net doesn't? There's obviously a huge gap between the two right now, but I don't see any fundamental difference besides \"consciousness\" which is not well defined to begin with.\n \nreply",
      "> current models are more than \"stochastic parrots\"I believe the same, and also I'm willing to accept that the human brain can intentionally operate in an stochastic parrot mode.Some people have the ability to fluently speak non-stop, completely impromptu. I wonder if it's similar to an LLM pipeline, where there'a constant stream of thoughts being generated based on very recent context, which are then passed through various output filters.\n \nreply",
      "That certainly would explain how Trump can rattle on for hours and hours, despite a notable lack of high quality training data.\n \nreply",
      "I view this as further evidence that we less different from \"stochastic parrots\" than we would like to believe.\n \nreply",
      "<user corysama squawks indignantly and flies away...>\n \nreply"
    ],
    "link": "https://research.google/blog/deciphering-language-processing-in-the-human-brain-through-llm-representations/",
    "first_paragraph": "We strive to create an environment conducive to many different types of research across many different time scales and levels of risk.Our researchers drive advancements in computer science through both fundamental and applied research.We regularly open-source projects with the broader research community and apply our developments to Google products.Publishing our work allows us to share ideas and work collaboratively to advance the field of computer science.We make products, tools, and datasets available to everyone with the goal of building a more collaborative ecosystem.Supporting the next generation of researchers through a wide range of programming.Participating in the academic research community through meaningful engagement with university faculty.Connecting with the broader research community through events is essential for creating progress in every aspect of our work.March 21, 2025Mariano Schain, Software Engineer, and Ariel Goldstein, Visiting Researcher, Google ResearchLarge"
  },
  {
    "title": "Ruby, Ractors, and lock-free data structures (iliabylich.github.io)",
    "points": 58,
    "submitter": "ksec",
    "submit_time": "2025-03-23T06:55:11 1742712911",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43451285",
    "comments": [
      "Among the deluge of github notifications, I noticed Mike Perham of Sidekiq fame working https://github.com/mperham/ratomic -- \"Ratomic provides mutable data structures for use with Ruby's Ractors. This allows Ruby code to scale beyond the infamous GVL.\"I then see that he posted: https://ruby.social/@getajobmike/114147139715606013\"\"\"\nAfter months of work on 8.0, I\u2019ve been trying to prototype a Ractor-based job system using Redis Cluster so the system can scale to hundreds of Redises with minimal effort.The hardest part is Ractors. They are quite difficult to program as they don\u2019t allow lexical scope or closure variable access. I haven\u2019t yet figured out the code patterns necessary for them. I would call it a dialect of Ruby.To be fair, I think I had the same struggles when learning goroutines and channels.\n\"\"\"Looks like he's trying to scale up sidekiq!\n \nreply",
      "Guessing the Go experience is largely from faktory https://github.com/contribsys/faktoryBut I dunno you can just go ask him about it, assuming he still does those Friday morning \u201chappy hour\u201d calls :)\n \nreply",
      "We wanted to use Ractors in our latest Ruby project (which is Rust based using rb-sys/magnus for some parts), but since our users use Google Protobuf inside the code that may run in Ractors, we could not because the library is not Ractor safe[0] (and it's unreasonable for us to ask our users to not be able to use the official Protobuf library).0 - https://github.com/protocolbuffers/protobuf/issues/19321\n \nreply"
    ],
    "link": "https://iliabylich.github.io/ruby-ractors-and-lock-free-data-structures/",
    "first_paragraph": "This story is about concurrent data structures in the context of Ruby. The goal here is to demonstrate how true parallelism can be achieved with global mutable state (which at the time of writing, is not supported by built-in Ruby primitives).Familiarity with Ruby, Rust, C, (and a bit of other tooling) is nice to have, but hopefully not mandatory.The repository with code examples can be found on GitHub, to run it you need a relatively new version of Ruby (master branch is probably the best option if you can compile it locally), Rust and C compilers."
  },
  {
    "title": "Better Shell History Search (tratt.net)",
    "points": 13,
    "submitter": "ltratt",
    "submit_time": "2025-03-25T22:35:17 1742942117",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43476793",
    "comments": [
      "I love fzf but no need to invent the wheel here if you are using zsh. check out one of these zle plugins. (Demo https://asciinema.org/a/155704)I prefer these two, you get good performance, search that is semi-shell syntax aware, ranking that takes age somewhat into account, and syntax hilighting.https://github.com/zdharma-continuum/history-search-multi-wo... with https://github.com/zdharma-continuum/fast-syntax-highlightin...or the same thing but older, for those who like older things because they have an air of stability about them: https://github.com/zsh-users/zsh-history-substring-search\n \nreply",
      "> and I\u2019ve come across more than one paid professional who doesn\u2019t use the \u201cup\u201d key to retrieve the previous command.Well. I prefer ctrl-p personally, but I take your point:)\n \nreply",
      "> What does 5408 mean and why is it taking up valuable screen space?For anyone who's not familiar with something as basic as the history command, please pick up a book on bash/zsh/sh and take the time to learn.If you don't know how to use the shell, you will struggle with (or simply be unable to perform) many basic tasks that could be accomplished quickly and easily by someone who's taken the time to learn how to use the shell and a handful of basic tools like grep, sed, awk, etc.\n \nreply",
      "The shell should just have better UX. If 5408 is the id of the command ran... just list that out in the printed table. Powershell and nushell do this really well.\n \nreply"
    ],
    "link": "https://tratt.net/laurie/blog/2025/better_shell_history_search.html",
    "first_paragraph": "I spend an awful lot of my day in Unix terminals running shell commands. For\nsome reason, the variance in efficiency between different people when using the shell\nis huge: I know people who can run rings around me, and I\u2019ve come across\nmore than one paid professional who doesn\u2019t use the \u201cup\u201d key to retrieve the\nprevious command.I chose that last example very deliberately: most of the commands most of us\nrun in the shell are highly repetitive. I typically run around 50-100 unique\n(i.e. syntactically distinct) shell commands per working day [1] \u2014 but\nI\u2019ll often run a tiny subset of those commands (e.g. cargo test) hundreds of\ntime in a single day.Since many command-line tools have hard-to-remember options, we can save huge\nchunks of time \u2013 not to mention make fewer errors \u2013 if we can search our\nshell history to find a previous incantation of a command we want to run. In\nthis post I\u2019m going to show how, with little effort, searching shell\nhistory can look like this:[Video]Larger Unix shel"
  },
  {
    "title": "Kylie Minogue song about a typeface (abcdinamo.com)",
    "points": 166,
    "submitter": "fauverism",
    "submit_time": "2025-03-25T16:51:09 1742921469",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=43473358",
    "comments": [
      "A Japanese house producer ex-member of Deee-Lite making a house track about a techno typeface sung by Kylie Minogue is the most late 90s thing I can imagine. It's like a rave flyer spontaneously gained sentience.\n \nreply",
      "Damn I miss the 90s.\n \nreply",
      "If you don\u2019t know Towa Tei, you might recognise him from Deee-Lite (\u201cGroove is in the Heart\u201d). Personally, I prefer his side project Sweet Robots Against the Machine. But he\u2019s also an excellent DJ, YouTube throws up a load of clips of him having fun on the decks.\n \nreply",
      "You might also recognize a few samples from/shared with \"Groove is in the Heart\" (at 0:30 and 3:39) in \"GBI (German Bold Italic)\" (at 0:25 and 3:19). (Timestamps are for the YouTube music videos, which have short introductions not found on the album tracks)https://www.whosampled.com/sample/8483/Towa-Tei-Kylie-Minogu...https://www.whosampled.com/sample/426057/Towa-Tei-Kylie-Mino...\n \nreply",
      "Both Towa Tei and Minogue super futuristic if not cyberpunk before it even was a thing.\n \nreply",
      "Kylie Minogue's first album was released 4 years after Neuromancer was published.\n \nreply",
      "1. I find the actual typeface made for the track rather pretty. Definitely of an era, but given how in that era's graphic design is right now I'm surprised I haven't seen more of it out and about2. Sadly the article neglects to mention Haroumi Hosono, whose vocals are also on the track. If you haven't checked out his work, either solo or with YMO, it's well worth a listen.\n \nreply",
      "The site is too hard to navigate (I couldn\u2019t find the reject cookies button, so there was a giant hand taking up half my screen). Do you happen to recall what the actual typeface was called?\n \nreply",
      "https://en.wikipedia.org/wiki/GBI_(German_Bold_Italic)\n \nreply",
      "(1) My respect towards Kylie Minogue, who I don't remember ever listening to, just got a boost. Maybe I should check out her other songs!(2) The page has the most playful \"Accept cookies?\" control of what I've encountered so far.\n \nreply"
    ],
    "link": "https://abcdinamo.com/news/german-bold-italic",
    "first_paragraph": "Sometimes we invite artists, writers, and other friends to take over our newsletter and write about fonts from a cultural perspective. And this time, New York-based writer and editor Whitney Mallett took a deep dive into the 1997 Towa Tei track GBI (German Bold Italic), for which Kylie Minogue sang from the perspective of a typeface.Whitney is the editor of The Whitney Review of New Writing, a biannual print bulletin of new criticism, and she was also the co-editor of Barbie Dreamhouse: An Architectural Survey.  Below, she enlightens us on the highly under-appreciated history of Towa Tei\u2019s data-track font release.Kylie Minogue announces \u201cI am a typeface\u201d in a 1997 song she made with producer Towa Tei. As this lyric suggests, the techno-pop track in question, \u201cGBI (German Bold Italic)\u201d, is delivered from the perspective of a font. Minogue\u2019s breathy, almost robotic vocals bring the absurdist premise to life, reciting declarations of design compatibility over a minimalist reverb-drenched "
  },
  {
    "title": "Optimizing ML training with metagradient descent (arxiv.org)",
    "points": 26,
    "submitter": "ladberg",
    "submit_time": "2025-03-25T21:22:35 1742937755",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arxiv.org/abs/2503.13751",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Whose code am I running in GitHub Actions? (alexwlchan.net)",
    "points": 111,
    "submitter": "ingve",
    "submit_time": "2025-03-25T17:17:05 1742923025",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=43473623",
    "comments": [
      "Unfortunately this makes a mistake by using a short commit ID: \"(e.g. a5b3abf)\"That's not a full commit ID, so it can still result in a mutable reference if either someone can find a clash[1] or if they can push a tag with that name and it takes priority in the context it is used (this is somewhat complex, e.g. GitHub prohibits pushes of branches and tags which are exactly 40 hex characters long, but other services may not).[1]: https://people.kernel.org/kees/colliding-with-the-sha-prefix...\n \nreply",
      "Shortened commit SHAs are actually not supported by Actions; if you try, you get\"Unable to resolve action `actions/checkout@11bd719`, the provided ref `11bd719` is the shortened version of a commit SHA, which is not supported. Please use the full commit SHA `11bd71901bbe5b1630ceea73d27597364c9af683` instead.\"\n \nreply",
      "What if the repository has a tag called 11bd719? Does Git/GitHub forbid creation of this tag if a commit exists with that prefix?What if a Git commit is created that matches an existing tag? Does Git have a procedure to make a new one? e.g. imagine I pregenerate a few million 8 character tags and wait for a collisionbtw: Even if you specify the full commit SHA, this can still be attacked; there have been pre-image attacks against Git commit hashes in the past. At least for older versions of Git, the algorithm was Sha1. Maybe that\u2019s changed but an attacker could always construct a malicious repository with intentionally weak hashes with the intent of later swapping one of them. (But at that point they may as well just push the malicious code in the first place.)\n \nreply",
      "What is the attack exactly? Only full commit SHAs are valid to reference a commit by SHA. GitHub disallows tags and branch names that could collide with a full commit SHA. There is never any collision between commit SHAs and tags.\n \nreply",
      "I think the hypothetical attack is to create a tag with the shortened commit SHA pointing at malicious code, and if someone accidentally puts that instead of the full commit SHA, maybe Github will serve them that malicious tag instead of throwing the error. It sounds like that could work if Github doesn't block a tag/branch colliding with a shortened commit SHA. I'd guess they probably do though?\n \nreply",
      "So you would need to specifically write an action referencing an invalid short SHA, which would not work and the action would fail, and then wait for an attacker to push an action with that tag name, and then run your action which has thus far been failing because of the invalid reference?\n \nreply",
      "You'd push the tag at the same time you push the commit. If anyone tries to reference your action and accidentally copies the shortened commit SHA instead of the full commit SHA, they'll reference the malicious tag instead. They'd never see it fail, they'd just silently pick up the malicious tag. But again I'm guessing Github will block that shortened commit SHA as a tag and this wouldn't actually work.\n \nreply",
      "No, I don't think Github blocks shortened commit SHAs as tags.\n \nreply",
      "How could they? They can't block every 8 character tag. And you can push the tag before you push the commit. (You know which short sha to impersonate because  you can see it locally.)\n \nreply",
      "It's still SHA-1 by the way, but they included counter-cryptanalysis to reject objects that appear to be one side of a collision using known techniques.\n \nreply"
    ],
    "link": "https://alexwlchan.net/2025/github-actions-audit/",
    "first_paragraph": "A week ago, somebody added malicious code to the tj-actions/changed-files GitHub Action. If you used the compromised action, it would leak secrets to your build log. Those build logs are public for public repositories, so anybody could see your secrets. Scary!This attack was possible because it\u2019s common practice to refer to tags in a GitHub Actions workflow, for example:At a glance, this looks like an immutable reference to an already-released \u201cversion 2\u201d of this action, but actually this is a mutable Git tag. If somebody changes the v2 tag in the tj-actions/changed-files repo to point to a different commit, this action will run different code the next time it runs.If you specify a Git commit ID instead (e.g. a5b3abf), that\u2019s an immutable reference that will run the same code every time.Tags vs commit IDs is a tradeoff between convenience and security. Specifying an exact commit ID means the code won\u2019t change unexpectedly, but tags are easier to read and compare.I wasn\u2019t worried about "
  },
  {
    "title": "Svelte: $derived can now be overwritten (github.com/sveltejs)",
    "points": 16,
    "submitter": "jedeusus",
    "submit_time": "2025-03-22T11:17:30 1742642250",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43444999",
    "comments": [
      "Agh, I understand why runes were implemented, but I still can't get myself to like them. It feels like Runes take away from what made Svelte Svelte (the simple, concise syntax), and changes like this seem like slow concessions back in that direction anyway.\n \nreply",
      "You just have to build a big project with Svelte 5 and you will come to like them.A lot of magic is okay for simple application, but when you want to build anything that scales Svelte before runes was just horrible. With Svelte 5 and Runes you can look at any component and instantly know what it does. You couldn't do that with Svelte 4 unless you wrote the whole code yourself.\n \nreply",
      "As someone who has not used Svelte 5: What is the significance of his change?\n \nreply",
      "https://github.com/sveltejs/cli/issues/487#issuecomment-2743...\n \nreply",
      "People who have migrated a large enough production codebase to Svelte 5, what's your devex like?\n \nreply",
      "I'm not a developer by trade, and have gone from 0 full-stack knowledge to building a MVP for my startup in 18 months using Svelte 4 and SvelteKit. Looking at the JS/TS ecosystem from the outside, it was a total nightmare and Svelte 4 was the only framework that seemed to make logical and aesthetic sense to me.Currently porting to Svelte 5 and it is less elegant in my opinion, but perhaps the problems it tries to solve are for more sophisticated developers and I don't really come across them or have knowledge of them. I would prefer to stay on 4, but I will take Rich's word for it that it will be better long term.Admittedly complicated components with lots of reactivity can be confusing to follow data changes with lots of $: lines so I have tried to minimise that from the beginning. The Svelte 5 code looks cleaner to follow for onboarding devs that aren't familiar with our codebase yet.\n \nreply",
      "I'm almost finished with a large, complex app written with Svelte 5, web sockets and Threlte (Three JS) [0]. Previously, I'd written React for about a decade, mostly on the UI side of things.I vastly prefer Svelte, because of how clean the code feels. There's only one component per file, and the syntax looks and writes deceptively like vanilla JS and HTML. There's a bit of mind-warp when you realize Svelte doesn't want you passing components with props as props into another component. Svelte gives you \"Snippets\" instead, which work for some reusability, but are limited. It sort of forces simplicity on you by design, which I like. Most of React's deep nesting and state management doesn't exist in Svelte and is replaced with simple, better primitives.The bigger gain though for me was Svelte(kit) vs. Next JS. It's very clear what is on the server and what is on the client, and there's none of that \"use client\" garbage with silly magic exports for Next JS things. The docs are great.Svelte's biggest disadvantage is that the UI library ecosystem isn't as large. For me that wasn't as big of an issue because it was my expertise, but everyone else looking for a drop in UI library will find the Svelte versions a little worse than their React counterparts.Because svelte is compiled, it also is by default very snappy. I think choosing Svelte would likely give most devs a speed boost vs. the spinner soup that I've seen most React projects become. A lot of that is going to be in the skill of the programmer, but I love how fast my app is.[0]: https://bsky.app/profile/davesnider.com/post/3lkvum6xtjs2e\n \nreply",
      "\"There's only one component per file\"If you don't do this in React, its your own fault.\n \nreply",
      "I also don't really see why this is a positive. If you have too much in a file, then split it off? It doesn't fundamentally add or subtract and complexity either way.\n \nreply",
      "pretty good. some people in my team don\u2019t like svelte magic and wish we were using react but others say, and i quote, \u201cdamn this is clean\u201d or \u201calmost effortless it just works\u201d and i\u2019ve seen again and again engineers ramp up pretty fast compared to my Knockout, Angular, or React times\u2026Pretty happy! Just wished they didn\u2019t change their \u201cmagic\u201d so often, but it\u2019s the price to pay for innovation\u2014if we can even call frontend development that, which I think we should but many frontend haters around here\n \nreply"
    ],
    "link": "https://github.com/sveltejs/svelte/pull/15570",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \nHave a question about this project? Sign up for a free GitHub account to open an issue and contact its maintainers and the community.\n  By clicking \u201cSign up for GitHub\u201d, you agree to our terms of service and\n  privacy statement. We\u2019ll occasionally send you account related emails.\n    Already on GitHub?\n    Sign in\n    to your account\n  See sveltejs/cli#487 (comment) for an example of why this is useful.Docs: https://svelte.dev/docs/svelte/$derived#Overriding-derived-values\n\n\n\n\n\n\n\n\n\n    Sorry, something went wrong.\n  Latest commit: b5fed42The changes in this PR will be included in the next version bump.Not sure what this means? Click here  to learn what changesets are.Click here if you're a maintainer who wants to add another changeset to this PR\n\n\n\n\n\n\n\n\n\n    Sorry, something went wrong.\n  Preview: https://svelte-dev-git-preview-svelte-15570"
  },
  {
    "title": "Gemini 2.5 (blog.google)",
    "points": 615,
    "submitter": "meetpateltech",
    "submit_time": "2025-03-25T17:01:54 1742922114",
    "num_comments": 279,
    "comments_url": "https://news.ycombinator.com/item?id=43473489",
    "comments": [
      "One of the biggest problems with hands off LLM writing (for long horizon stuff like novels) is that you can't really give them any details of your story because they get absolutely neurotic with it.Imagine for instance you give the LLM the profile of the love interest for your epic fantasy, it will almost always have the main character meeting them within 3 pages (usually page 1) which is of course absolutely nonsensical pacing. No attempt to tell it otherwise changes anything.This is the first model that after 19 pages generated so far resembles anything like normal pacing even with a TON of details. I've never felt the need to generate anywhere near this much. Extremely impressed.Edit: Sharing it - https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%...with pastebin - https://pastebin.com/aiWuYcrF\n \nreply",
      "I like how critique of LLMs evolved on this site over the last few years.We are currently at nonsensical pacing while writing novels.\n \nreply",
      "Using the AI in multiple phases is the approach that can handle this. \nSimilarly to \"Deep Research\" approach - you can tell it to first generate a storyline with multiple twists and turns. Then ask the model to take this storyline and generate prompts for individual chapters. Then ask it to generate the individual chapters based on the prompts, etc.\n \nreply",
      "Yup -- asking a chatbot to create a novel in one shot is very similar to asking a human to improvise a novel in one shot.\n \nreply",
      "It's not a problem of one-shotting it. It's that the details cause a collapse. Even if you tried breaking it down which i have, you'd run into the same problem unless you tried holding its hand for every single page and then - what's the point ? I want to read the story not co-author it.\n \nreply",
      "Doesn't novel literally mean something new? Can we really expect an LLM to produce a novel?\n \nreply",
      "Yes\n \nreply",
      "I think you would be better off having the LLM help you build up the plot with high level chapter descriptions and then have it dig into each chapter or arc. Or start by giving it the beats before you ask it for help with specifics. That'd be better at keeping it on rails.\n \nreply",
      "I don't disagree. Like with almost anything else involving LLMs, getting hands on produces better results but because in this instance, i much prefer to be the reader than the author or editor, it's really important to me that a LLM is capable of pacing long form writing properly on its own.\n \nreply",
      "Random question, if you don't care about being a creator yourself, why do you even want to read long form writing written by an LLM? There are literally 10000s of actual human written books out there all of them better than anything an LLM can write, why not read them?\n \nreply"
    ],
    "link": "https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/",
    "first_paragraph": "Mar 25, 2025[[read-time]] min read\n          Gemini 2.5 is a thinking model, designed to tackle increasingly complex problems. Our first 2.5 model, Gemini 2.5 Pro Experimental, leads common benchmarks by meaningful margins and showcases strong reasoning and code capabilities.\n        Today we\u2019re introducing Gemini 2.5, our most intelligent AI model. Our first 2.5 release is an experimental version of 2.5 Pro, which is state-of-the-art on a wide range of benchmarks and debuts at #1 on LMArena by a significant margin.Gemini 2.5 models are thinking models, capable of reasoning through their thoughts before responding, resulting in enhanced performance and improved accuracy.In the field of AI, a system\u2019s capacity for \u201creasoning\u201d refers to more than just classification and prediction. It refers to its ability to analyze information, draw logical conclusions, incorporate context and nuance, and make informed decisions.For a long time, we\u2019ve explored ways of making AI smarter and more capable"
  },
  {
    "title": "Devs say AI crawlers dominate traffic, forcing blocks on entire countries (arstechnica.com)",
    "points": 122,
    "submitter": "LinuxBender",
    "submit_time": "2025-03-25T21:42:37 1742938957",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=43476337",
    "comments": [
      "> It remains unclear why these companies don't adopt more collaborative approaches and, at a minimum, rate-limit their data harvesting runs so they don't overwhelm source websites.If the target goes down after you scrape it, that's a feature.\n \nreply",
      "Why? What is the goal of a scraper, and how does disabling the source of the data benefit them?\n \nreply",
      "> Why? What is the goal of a scraper, and how does disabling the source of the data benefit them?The next scraper doesn\u2019t get the data. People don\u2019t realize we\u2019re not compute limited for ai, we\u2019re data limited. What we\u2019re watching is the \u201cdata war\u201d.\n \nreply",
      "at this point we're _good data_ limited, which has little to do with scraping.\n \nreply",
      "Honestly it's hard to tell how much more value the LLM people are going to get out of another copy of the internet.It feels a lot like they're stuck for improvements but management doesn't want to hear it.\n \nreply",
      "Now the only way to obtain that information is through them\n \nreply",
      "I guess one could make a point that competition will no longer have the access to the scraped data.\n \nreply",
      "I've had a number of content sites \n I've shut down a few sites in the last few days because of the toll these aggressive AI bots.  Alexa seems like the worst.These were created 20 years ago and updated over the years.  I use to get traffic but that's been slowed to 1,000 or less legitimate visitors over the last year.  But now I have to deal with server down emails caused by these aggressive bots that don't respect the robots file.\n \nreply",
      "> Alexa seems like the worst.Many of the bots disguise themselves as coming from Amazon or other big company.Amazon has a page where you can check some details to see if it\u2019s really their crawler or someone imitating it.\n \nreply",
      "yup, actually most that I've seen are impersonating amazon\n \nreply"
    ],
    "link": "https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/",
    "first_paragraph": "\n        AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back.\n      Software developer Xe Iaso reached a breaking point earlier this year when aggressive AI crawler traffic from Amazon overwhelmed their Git repository service, repeatedly causing instability and downtime. Despite configuring standard defensive measures\u2014adjusting robots.txt, blocking known crawler user-agents, and filtering suspicious traffic\u2014Iaso found that AI crawlers continued evading all attempts to stop them, spoofing user-agents and cycling through residential IP addresses as proxies.Desperate for a solution, Iaso eventually resorted to moving their server behind a VPN and creating \"Anubis,\" a custom-built proof-of-work challenge system that forces web browsers to solve computational puzzles before accessing the site. \"It's futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more,\" Iaso wrote in a blog post "
  },
  {
    "title": "Show HN: A website for sharing the \"Good, Bad, and Why\"s of urban spaces (dedede.de)",
    "points": 7,
    "submitter": "kappasan",
    "submit_time": "2025-03-24T21:48:07 1742852887",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://dedede.de/en",
    "first_paragraph": ""
  },
  {
    "title": "If you get the chance, always run more extra network fiber cabling (utcc.utoronto.ca)",
    "points": 129,
    "submitter": "hggh",
    "submit_time": "2025-03-25T13:40:59 1742910059",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=43471177",
    "comments": [
      "I recall working in a building that:1. Was the former HQ for a local telecom company\n2. Was now an office building with a couple floors of data.Ages ago, one of the DC providers in the building had run 36 cores to the roof to service a telco.It was a massive undertaking, the building is riddled with asbestos and old plant. Had multiple renovations etc.Anyway, a few years later, every telco in the state wanted to be on that rooftop. And they had the only reliable means to service it with fibre. That 36 core became a massive profit generating asset, one that they could have monetised even further if they had have run 100 core instead. But it was never feasible to drill holes for a new duct (Asbestos regulations getting tighter), and it was never feasible to shut down 12 telcos for a day to use the existing fibre as a draw cable.Getting a single core rented here, and throwing on Bidi's, was like mana from the gods at the time.\n \nreply",
      "Yup, always run extra everything. At least you can splice fiber now. And be careful of the minimum bend radius.Once, in the 90s, we were having intermittent network failures in our data center. I kept trying to troubleshoot it with the fluke, but the problem kept moving. When I pulled up the raised floor, I discovered that rats were eating the exterior sheath of the network cables. That was some fun troubleshooting!\n \nreply",
      "> Yup, always run extra everythingCables ain't free, duct capacity is finite and duct rental from the local incumbent is costly too... Please calculate the financial optimum of pay now vs. pay later - taking into account growth, various forms of attrition, cost of capital, opportunity costs and appetite for risk. Or everyone would be running 1152 strands cables everywhere.But then I see that from a telco perspective and, now that I've read the article, it seems to be from a small-scale hosting perspective - entirely different economics.\n \nreply",
      "Duct capacity is finite, but fiber cables are tiny and they are very nearly free compared to the cost of having them run.\n \nreply",
      "Not quite tiny - a basic armored (rats !) 12 strands cable may be around 10-15 millimeters, whereas similarly specced cables in the 500 strands range might reach 20-30 mm. In crowded Paris downtown, it adds up fast. On the countryside, that is a lot more weight to hang on poles.\n \nreply",
      "And while some people preach hard-wired everything I\u2019d probably increasingly not bother at home. . I\u2019ll have to see how\nmuch networking and audio stuff I even do given a kitchen fire with s\n \nreply",
      "Or, take the money you would spend calculating that, and that's the amount you spend for your margin.\n \nreply",
      "Haha, I'll tell that to the outside plant capacity planning team !But seriously, I'm telco-biased, and it seems that the article has a small scale hosting... Different worlds. At small scale, sure - the bigger cable is a rounding error.\n \nreply",
      "Your typical Rodent Accelerated Transmission Signal And System Suppression\n \nreply",
      "Have fusion splicers come down in price?  Can you recommend any?\n \nreply"
    ],
    "link": "https://utcc.utoronto.ca/~cks/space/blog/sysadmin/RunMoreExtraNetworkFiber",
    "first_paragraph": " You're probably reading this page because you've attempted to\naccess some part of my blog (Wandering\nThoughts) or CSpace, the wiki thing it's\npart of. Unfortunately whatever you're using to do so has a HTTP\nUser-Agent header value that is too generic or otherwise excessively\nsuspicious. Unfortunately, as of early 2025 there's a plague of\nhigh volume crawlers (apparently in part to gather data for LLM\ntraining) that behave like this. To reduce the load on Wandering Thoughts I'm experimenting with\n(attempting to) block all of them, and you've run into this.  All HTTP User-Agent headers should clearly identify what they\nare, and for non-browser user agents, they should identify not just\nthe software involved but also who specifically is using that software.\nAn extremely generic value such as \"Go-http-client/1.1\"\nis not something that I consider acceptable any more. "
  },
  {
    "title": "VGGT: Visual Geometry Grounded Transformer (github.com/facebookresearch)",
    "points": 140,
    "submitter": "xnx",
    "submit_time": "2025-03-25T12:59:26 1742907566",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=43470651",
    "comments": [
      "I read the paper yesterday, would recommend it. Kudos to the authors for getting to these results, and also for presenting them in a polished way. It's nice to follow the arguments about the alternating attention (global across all tokens vs only the tokens per camera), the normalization (normalize the scene scale - done in the data vs DUST3R, which normalizes in the network), and the tokens (image tokens from DINOv2 + camera tokens + additional register tokens, handling the first camera differently as it becomes the frame of reference). The results are amazing, and fine-tuning this model will be fun, e.g. for forward 3DGS reconstruction, looking forward to this.I'm sure getting to this point was quite difficult, and on the project page you can read how it involved discussions with lots and lots of smart and capable people. But there's no big \"aha\" moment in the paper, so it feels like another hit for The Bitter Lesson in the end: They used a giant bunch of [data], a year and a half of GPU time to [train] the final model, and created a model with a billion parameters that outperforms all specialized previous models.Or in the words of the authors, from the paper:> We also show that it is unnecessary to design a special network for 3D reconstruction. Instead, VGGT is based on a fairly standard large transformer [119], with no particular 3D or other inductive biases (except for alternating between frame-wise and global attention), but trained on a large number of publicly available datasets with 3D annotations.Fantastic to have this. But it feels.. yes, somewhat bitter.[The Bitter Lesson]: http://www.incompleteideas.net/IncIdeas/BitterLesson.html (often discussed on HN)[data]: \"Co3Dv2 [88], BlendMVS [146], DL3DV [69], MegaDepth [64], Kubric [41], WildRGB [135], ScanNet [18], HyperSim [89], Mapillary [71], Habitat [107], Replica [104], MVS-Synth [50], PointOdyssey [159], Virtual KITTI [7], Aria Synthetic Environments [82], Aria Digital Twin [82], and a synthetic dataset of artist-created assets similar to Objaverse [20].\"[train]: \"The training runs on 64 A100 GPUs over nine days\", that would be around $18k on lambda labs in case you're wondering\n \nreply",
      ">  They used a giant bunch of [data], a year and a half of GPU time to [train] the final model,>[train]: \"The training runs on 64 A100 GPUs over nine days\", that would be around $18k on lambda labs in case you're wonderingHow is that a \"year and half of GPU time\".  Maybe on some exoplanet ?\n \nreply",
      "> > [train]: \"The training runs on 64 A100 GPUs over nine days\",> How is that a \"year and half of GPU time\".64 GPUs \u00d7 9 days = 576 GPU-days \u2248 1.577 GPU-years\n \nreply",
      "Doh, that's entirely fair: haven't been in this thread yet, but would echo what I perceive as implicit puzzlement re: this amount of GPU time being described as bitter-lesson-y.\n \nreply",
      "Doesn't the bitter lesson take the argument a bit too far by opposing search/learn to heuristics? Is the former not dependent on breakthroughs in the latter?\n \nreply",
      "The bitter lesson is the opposite. It argues that hand-crafted heuristics will eventually get beaten by more general learning algorithms that can take advantage of computing power.\n \nreply",
      "Indeed, even in \"classical chess engines\" like Stockfish which previously required handcrafted heuristics at leaf nodes, in recent years the NNUE [1] [2] has greatly outperformed it. Note that this is a completely different approach from the one that AlphaZero takes, and modern Stockfish is significantly stronger than AlphaZero.[1] https://stockfishchess.org/blog/2020/introducing-nnue-evalua...[2] https://www.chessprogramming.org/Stockfish_NNUE\n \nreply",
      "> eventually get beatenBrute forcing is bound to find paths beyond heuristics. What I'm getting at is that the path needs to be established first before it can be beaten. Hence why I'm wondering if one isn't an extension of the other instead of an opposing strategy.I.e. search and heuristics both have a time and place, not so much a bitter lesson but a common filter for a next iteration to pass through.\n \nreply",
      "That's like saying horse drawn carriages aren't opposed to cars because they needed to be developed first.\n \nreply",
      "More info and demos:https://vgg-t.github.io/\n \nreply"
    ],
    "link": "https://github.com/facebookresearch/vggt",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        [CVPR 2025] VGGT: Visual Geometry Grounded Transformer\n      Visual Geometry Group, University of Oxford; Meta AIJianyuan Wang, Minghao Chen, Nikita Karaev, Andrea Vedaldi, Christian Rupprecht, David NovotnyVisual Geometry Grounded Transformer (VGGT, CVPR 2025) is a feed-forward neural network that directly infers all key 3D attributes of a scene, including extrinsic and intrinsic camera parameters, point maps, depth maps, and 3D point tracks, from one, a few, or hundreds of its views, within seconds.First, clone this repository to your local machine, and install the dependencies (torch, torchvision, numpy, Pillow, and huggingface_hub).Alternatively, you can install VGGT as a package (click here for details).Now, try the model with just a few lines of code:The model weights will be automatically downloaded from Hugging Face. If you "
  },
  {
    "title": "Scientists break down plastic using a simple, inexpensive catalyst and air (phys.org)",
    "points": 77,
    "submitter": "PaulHoule",
    "submit_time": "2025-03-21T20:12:49 1742587969",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43440321",
    "comments": [
      "What percentage is actually broken down into monomers? How much microplastic waste is left behind. Given the reliance on \"ambient air\" I imagine it's not 100%.Regardless, I'm excited to hear about progress on solving the plastic waste crisis. It seems better than the current alternatives the article presents:> \"The U.S. is the number one plastic polluter per capita, and we only recycle 5% of those plastics,\" said Northwestern's Yosi Kratish, the study's co-corresponding author. \"There is a dire need for better technologies that can process different types of plastic waste. Most of the technologies that we have today melt down plastic bottles and downcycle them into lower-quality products.\n \nreply",
      "This is great but PET (symbol #1) is one of the few plastics that ARE recyclable. I wonder if any of these techniques can be used to solve the non-recyclable plastic problems\n \nreply",
      "Not infinitely so, maybe this is used on old PET\n \nreply",
      "there is also the possibility to recycle pet-bottles into food grade bottles again using just mechanical means, I know at least two European companies who provide such machines\n \nreply",
      "I've seen 100% recycled PET bottles for Coca-Cola products in the UShttps://www.cnn.com/2024/03/19/food/coca-cola-new-bottles/in...and Pepsi is selling 100% post-consumer bottles in some EU countrieshttps://www.pepsico.com/our-stories/press-release/pepsico-co...Those clear beverage containers are an ideal case for mechanical recycling.  This companyhttps://repreve.com/makes polyester fiber from recycled PET.  I have a few garmets made from it and my impression is that the fabric feel is nicer than average.\n \nreply",
      "Yes PET (#1) and HDPE (#2) are the two easiest plastics to recycle and the most commonly recycled\n \nreply",
      "I was expecting a much more complicated catalyst!\n \nreply",
      "Well, they used a \"simple, inexpensive catalyst\" and then HEATED the plastic/catalyst mysture. Nowhere in the article it gives you an estimate of the final cost of the process.\n \nreply",
      "I wonder if processes like this can recycle the heat?Kind of like fresh air exchange into a heated house where new air in gets heated exchanging with old air out\n \nreply",
      "The journal article is open access. https://pubs.rsc.org/en/content/articlelanding/2025/gc/d4gc0...> Catalytic amounts of AC/MoO2 selectively convert waste PET into its monomer, terephthalic acid (TPA), within 4 h at 265 \u00b0C with yields as high as 94% under 1 atm air.I'm not a chemist so don't know if you can find a way to calculate the cost, but the authors claim that it's cheaper than current methods.The bigger deal imo is that it recovers PET monomers from mixed plastics, which means avoiding manufacturing more plastic.\n \nreply"
    ],
    "link": "https://phys.org/news/2025-03-scientists-plastic-simple-inexpensive-catalyst.html",
    "first_paragraph": ""
  },
  {
    "title": "The highest-ranking personal blogs of Hacker News (refactoringenglish.com)",
    "points": 147,
    "submitter": "sharjeelsayed",
    "submit_time": "2025-03-25T18:48:57 1742928537",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=43474505",
    "comments": [
      "Author here.I tried submitting this as a Show HN a couple times but it didn't take, so I'm happy to see some interest!I caught this just before bed, but I'm happy to take any suggestions or questions, and I'll answer in the morning.If you'd like to improve the metadata, I welcome PRs here: https://github.com/mtlynch/hn-popularity-contest-data\n \nreply",
      "I find it surprising that Ken Shirriff's blog[1] didn't make it to the top 5000.  Does it not count as a blog?Looks like it's explicitly excluded[2].[1] https://news.ycombinator.com/from?site=righto.com[2] https://github.com/mtlynch/hn-popularity-contest-data/blob/d...\n \nreply",
      "Author here.That was an error.I think what happened was that I was going through the list of domains and assumed that \"righto.com\" would be too valuable a domain name for a personal blog and excluded it without checking. Sorry about that!Ken is #8 of all-time now.\n \nreply",
      "Thanks! Not to complain, but you spelled my name wrong :-)\n \nreply",
      "D'oh! Fixed now.https://github.com/mtlynch/hn-popularity-contest-data/pull/2...Sorry again!\n \nreply",
      "That's weird that I'm excluded. Thanks for watching out for me :-)Hypotheses: 1. it's an error. 2. I have powerful enemies. 3. Someone from the future is trying to stop me. 4. My blog triggered the FDIV bug and needed to be excluded.\n \nreply",
      "There are a lot of odd exclusions on that list. Just spot-checking, I see blog.plover.com, the blog of Mark Jason Dominus, who by the way is looking for a job[1].Also, dtrace.org is excluded, which hosts four individual blogs that surely should qualify.[1]: https://mastodon.online/@mjd@mathstodon.xyz/1142231895042721...\n \nreply",
      ">I see blog.plover.com, the blog of Mark Jason Dominus, who by the way is looking for a jobWhoops, that was a mistake. Fixed now: https://github.com/mtlynch/hn-popularity-contest-data/pull/2...>Also, dtrace.org is excluded, which hosts four individual blogs that surely should qualify.I didn't realize the authors were on distinguishable URLs, so I've now added them back and canonicalized them to their new subdomain URLs.\n \nreply",
      "3a. Twist - given what you analyze, this time it's a time traveller from the past that needs to stop you :)\n \nreply",
      "5. steganographic subliminal messaging :P\n \nreply"
    ],
    "link": "https://refactoringenglish.com/tools/hn-popularity/",
    "first_paragraph": ""
  },
  {
    "title": "Open-sourcing OpenPubkey SSH (OPKSSH): integrating single sign-on with SSH (cloudflare.com)",
    "points": 157,
    "submitter": "PranaFlux",
    "submit_time": "2025-03-25T13:22:09 1742908929",
    "num_comments": 110,
    "comments_url": "https://news.ycombinator.com/item?id=43470906",
    "comments": [
      "I don't love this.> Unfortunately, while ID Tokens do include identity claims like name, organization, and email address, they do not include the user\u2019s public key. This prevents them from being used to directly secure protocols like SSHThis seems like dubious statement. SSH authentication does not need to be key based.I understand the practicality of their approach, but I would have preferred this to be proper first-class authentication method instead of smuggling it through publickey auth method. SSH protocol is explicitly designed to support many different auth methods, so this does feel like a missed opportunity. I don't know openssh internals, but could this have been implemented through gssapi? That's the traditional route for ssh sso. If not gssapi, then something similar to it.https://datatracker.ietf.org/doc/html/rfc4462\n \nreply",
      "> This seems like dubious statement. SSH authentication does not need to be key based.Let's say you just use an ID Token as a bearer token to authenticate to SSH. The SSH server now has the secret you used to authenticate with. Doesn't this introduce replay attacks where the SSH server can replay your ID Token to log into other SSH servers?Whereas if your ID Token functions like a \"certificate\" issued by your IDP binding your identity to a public key, it is no longer a secret. You can just use your public key to prove you are you. No secrets leave your computer.My motto: always use public key rather than a bearer secret if possible.> I understand the practicality of their approach, but I would have preferred this to be proper first-class authentication method instead of smuggling it through publickey auth methodMe too. I have a PR open to SSH3 (not connected with OpenSSH) so it can be support OpenPubkey as a built-in authentication mechanism.https://github.com/francoismichel/ssh3/pull/146\n \nreply",
      "I think it's interesting they're choosing to use certificates this way. If they're already using certs, why not just leverage sshca auth? Also, at the end of the day, it's still effectively a bearer token. I founded a company called Based Security last year in this space. We're looking for design partners currently. We host a CA for you (or you can host yourself if you want) and use ssh certificates and bind the user identity (oidc to the IdP) to a physical device (yubikey, secure enclave, tpm, etc.) This ensures that the user is both in possession of the physical device and that the credential can't be stolen without stealing the device, unlike the bearer token examples here. Currently we're offering support for GitHub and GitLab authentication but it works out of the box with standard ssh tooling as well. It just currently requires manually handling user provisioning for standard ssh access.\n \nreply",
      "> Why not just leverage sshca auth?Because that has two trusted parties: the IDP and the SSH CA. OPKSSH has just one trusted party: the IDP.> This ensures that the user is both in possession of the physical device and that the credential can't be stolen without stealing the device, unlike the bearer token examples here. Currently we're offering support for GitHub and GitLab authentication but it works out of the box with standard ssh tooling as well. It just currently requires manually handling user provisioning for standard ssh access.That sounds valuable.Have you looked in OpenPubkey, the cosigner protocol supports binding hardware tokens to ID Tokens? Although not as fancy as having the SSH key pair live in the hardware token but maybe we could figure out a way to get the best of both worlds.\n \nreply",
      "I can understand the concern about having a second trusted party but think that the value of utilizing the standard ssh ca auth flow is worth the potential risk. If you require keys in attested hardware and verify that before issuing certs, the actual attack becomes very difficult. You need to compromise the actual hardware or compromise the CA in a pretty substantial way to issue certs to untrusted private keys. The certificate alone doesn't actually do anything without the key. In addition to just being supported out of the box, we can also issue hardware bound host keys, which allow us to offer bi-directional verification. We gain the benefit of all the standard PKI tooling (eg. revocation lists, ACME, etc.) and can use the same PKI for other scenarios (eg. mTLS, piv, etc.) by issuing x509 certificates instead. That's our long term plan is moving past ssh auth and having it be an attestable, immovable, hardware backed identity that can be usable for continuous authentication in other areas.I have looked into OpenPubKey briefly in the past but haven't spent a ton of time with it. We were going in a very different direction and it didn't seem particularly useful based on our goals or what we wanted to achieve.edit:\nLooking at the documentation https://docs.bastionzero.com/openpubkey-ssh/openpubkey-ssh/i... It seems like to use OpenPubKey you also need a fairly modern version of OpenSSH.   It also requires that the user authenticating have sudo access on the machine, which doesn't sound great. It's not clear to me whether it's possible for the existing authorized_keys file to co-exist or whether that's just to stop access using existing keys but using the standard ssh certs will co-exist allowing for a non-binary rollout if there are use cases that need to be worked around.\n \nreply",
      "This is the purpose of the not so well known audience claim.Though I'd still prefer to authenticate to something like Vault's SSH engine and get a very short lived SSH certificate instead. No new software to install on your servers, just the CA key.\n \nreply",
      "CA key also allows those servers to avoid reaching out to some central location to validate which I've found to be a nice side bonus for disaster recovery type scenarios.\n \nreply",
      "> The SSH server now has the secret you used to authenticate with.secrets can be made unique per connection and single use\n \nreply",
      "this ^GSSAPI can be more secured than public/private key if configured right.\n \nreply",
      "Can you explain more? I want to be a fan of GSSAPI\n \nreply"
    ],
    "link": "https://blog.cloudflare.com/open-sourcing-openpubkey-ssh-opkssh-integrating-single-sign-on-with-ssh/",
    "first_paragraph": ""
  },
  {
    "title": "U.S. national-security leaders included me in a group chat (theatlantic.com)",
    "points": 1636,
    "submitter": "_tk_",
    "submit_time": "2025-03-24T16:23:55 1742833435",
    "num_comments": 737,
    "comments_url": "https://news.ycombinator.com/item?id=43462783",
    "comments": [
      "https://web.archive.org/web/20250324194236/https://www.theat...",
      "https://archive.ph/AP0H4",
      "I began my career in a classified environment working on government satellite programs.In my first week on the job, I was told, explicitly, that if I shared Classified or Controlled Unclassified information over unapproved channels, I would be reprimanded\u2014likely fired, or less likely, prosecuted.It was also made clear that safeguarding the nation's secrets from the carelessness of others was my responsibility, too.It is mind-boggling that 18 people were on this thread, and none of them ever suggested that this discussion would be better served in a SCIF. To say nothing of SecDef starting the thread on Signal in the first place.How many other such threads are active at the highest levels of government right now?Does Chinese intelligence know?I'm not suggesting punishment, or even prosecution, for the people involved. But the idea that this breach can occur with no accountability, consequences, or operational changes is unacceptable.\n \nreply",
      "The problem is that most of those 18 people are just random folks picked on the premise of just one qualification: THey'd be Yes Man/Woman!! They aren't career professionals. I believe that explains the mess they've created and their incompetent approach to their duties.It's still not too late to impeach that entire shack of clowns.\n \nreply",
      "> It's still not too late to impeach that entire shack of clowns.The problem is that the people in control of the power to impeach are also picked for being yes men/women. It's yes-men all the way down by design.\n \nreply",
      "> Does Chinese intelligence know?How likely is it that all 18 of those people were accessing from mobile operating systems with no known working exploit chain? I would say pretty unlikely.\n \nreply",
      "If they're \"just\" using Signal, they're likely \"just\" using stock Android if there isn't a policy requiring iPhones in lockdown mode. It's a very good question as to whether such a policy exists.\n \nreply",
      "Also, Steve Witkoff was in Moscow during the Signal text chain.\n \nreply",
      "I actually think the major powers mostly know what the others are doing.\n \nreply",
      "Why are you specifically calling out you are not suggesting punishment nor prosecution?\n \nreply"
    ],
    "link": "https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/",
    "first_paragraph": "U.S. national-security leaders included me in a group chat about upcoming military strikes in Yemen. I didn\u2019t think it could be real. Then the bombs started falling.Produced by ElevenLabs and  News Over Audio (Noa) using AI narration. Listen to more stories on the Noa app.The world found out shortly before 2 p.m. eastern time on March 15 that the United States was bombing Houthi targets across Yemen.I, however, knew two hours before the first bombs exploded that the attack might be coming. The reason I knew this is that Pete Hegseth, the secretary of defense, had texted me the war plan at 11:44 a.m. The plan included precise information about weapons packages, targets, and timing.This is going to require some explaining.This article was featured in the One Story to Read Today newsletter. Sign up for it here.The story technically begins shortly after the Hamas invasion of southern Israel, in October 2023. The Houthis\u2014an Iran-backed terrorist organization whose motto is \u201cGod is great, de"
  }
]