[
  {
    "title": "Veo (deepmind.google)",
    "points": 971,
    "submitter": "meetpateltech",
    "submit_time": "2024-05-14T17:58:26",
    "num_comments": 297,
    "comments_url": "https://news.ycombinator.com/item?id=40358041",
    "comments": [
      "An interesting thing that Google does is to watermark the AI generated videos using the [SynthID technology](https://deepmind.google/technologies/synthid/).It seems that the SynthID is not only for AI generated video but for image, text and audio.",
      "From a filmmaking standpoint I still don't think this is impactful.For that it needs a \"director\" to say: \"turn the horse's head 90\u02da the other way, trot 20 feet, and dismount the rider\" and \"give me additional camera angles\" of the same scene.\nOtherwise this is mostly b-roll content.I'm sure this is coming.",
      "I can see using these video generators to create video storyboards. Especially if you can drop in a scribbled sketch and a prompt for each tile.",
      "That sounds actively harmful. Often we want story boards to be less specific so as not to have some non artist decision maker ask why it doesn't look like the storyboard.And when we want it to match exactly in an animatic or whatever, it needs to be far more precise than this, matching real locations etc.",
      "I know you weren't implying this, but not every storyboard is for sharing with (or seeking approval from) decision makers.I could see this being really useful for exploring tone, movement, shot sequences or cut timing, etc..Right now you scrape together \"kinda close enough\" stock footage for this kind of exploration, and this could get you \"much closer enough\" footage..",
      "They claim it can accept an \"input video and editing command\" to produce a new video output. Also, \"In addition, it supports masked editing, enabling changes to specific areas of the video when you add a mask area to your video and text prompt.\" Not sure if that specific example would work or not.",
      "For most things I view on the internet B-roll is great content, so I'm sure this will enable a new kind of storytelling via YouTube Shorts / Instagram, etc at minimum.",
      "60 second example video: https://www.youtube.com/watch?v=diqmZs1aD1g",
      "Not nearly as impressive as Sora. Sora was impressive because the clips were long and had lots of rapid movement since video models tend to fall apart when the movement isn't easy to predict.By comparison, the shots here are only a few seconds long and almost all look like slow motion or slow panning shots cherrypicked because they don't have that much movement. Compare that to Sora's videos of people walking in real speed.The only shot they had that can compare was the cyberpunk video they linked to, and it looks crazy inconsistent. Real shame.",
      "> Not nearly as impressive as Sora. Sora was impressive because the clips were long and had lots of rapid movementThe most impressive Sora demo was heavily edited.https://www.fxguide.com/fxfeatured/actually-using-sora/"
    ],
    "link": "https://deepmind.google/technologies/veo/",
    "first_paragraph": "Technology"
  },
  {
    "title": "The Most Talented Person in the World (matt.sh)",
    "points": 74,
    "submitter": "keyboardJones",
    "submit_time": "2024-05-14T23:37:25",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=40361387",
    "comments": [
      "> The only future of the internet is, sadly, proof-of-person and proof-of-residence on every public network interaction.I'm going to be that pedant and point out that the Internet is not the same as the Web, and it's the Web that's sick.  The Internet is fine.It's a distinction that matters because the Internet is expensive things like satellites and undersea cables.  The Web is just a bunch of conventions about how to use the Internet, it's not binding in any way.  We can write a different protocol without laying new cable, we can make it less profitable for abusers, and then we can abandon the sick version that we currently have.",
      "Has anyone built a search engine that uses LLMs to pre-grade every page with metrics such as:- Commercial bias (content compared to the source, which it learns about)- Insincere motives- Bloat (how many words it takes to say how little to penalize SEO bloat)I would assume that using LLMs, we can get a pretty good idea of what is SEO bloat and who the bad actors are by this point, and just penalize those results.",
      "We don't need to. We have LLMs now",
      "The equation to rank links is a poor substitute for an editor. Editors used to be the gateway of information that was disbursed via newspaper, radio, and TV. They were not without fault. So what is the least faulty filter? (Even your own brain, eyes, and ears are faulty, sorry perfectionists.) You cannot trust video or audio now due to deepfakes. What can you trust as a source of information more than 50%?There's still information in the noise, you have to become your own editor.",
      "The reason all of this exists - the reason the entire Internet turned into an unusable amalgam of horseshit - is because we built the entire commercial side of the internet off ad revenue. It might be a death spiral at this point - I can\u2019t imagine anyone actually being willing to Pay for whatever the fuck Google or Facebook have become, so there\u2019s nothing left to do but keep inventing new ways to generate bullshit and new bots to view it for you.",
      "The internet is the largest and most elaborate monument to marketing we may ever build.",
      "I\u2019m amazed my medical websites\u2026  The top 5-10 sites all seem have identical wording for common conditions.In the age of copyright enforcement and DMCA antics,  I don\u2019t understand how this continues year after year.",
      "They\u2019re all the same thing, same owners likely",
      "Buries the lede. WHY would you make so many talanted instances of Jodie? Whats the upside. How do the financials work and is it a stake, or paid labour?",
      "> WHY would you make so many talanted instances of Jodie?One name is twice as easy to invent as two names."
    ],
    "link": "https://matt.sh/the-most-talented-person",
    "first_paragraph": ""
  },
  {
    "title": "Ilya Sutskever to leave OpenAI (twitter.com/ilyasut)",
    "points": 316,
    "submitter": "wavelander",
    "submit_time": "2024-05-14T23:01:26",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=40361128",
    "comments": [
      "seemed inevitable after that ouster attempt, probably just working out the details of the exit. But the day after their new features release announcement?",
      "\"Get next major feature to release and you can go as a friend\" might have been part of an earlier agreement.",
      "More like they iced him for the last 6 months to ensure he wasn\u2019t taking their lead to a competitor.  He probably hasn\u2019t touched anything in that time.",
      "Sounds like a threat.",
      "When you take a shot at the king, you better not miss.",
      "I would imagine he\u2019d been thinking about it for a while, and maybe with all the buzz about him at the same time of the release, he was asked to decide.",
      "Could be a clever play. They sandwiched google io with news which has taken attention from Google. Plus they just had a big announcement so the negative news hits a little less hard.",
      "Ilya will literally have a blank check from almost all the VC's in the industry.",
      "And probably all of the big tech CEOs are trying to get him on the phone right now.",
      "Except all the big tech CEOs have head AI honchos who are huge names in their own right, eg yann for meta and demis for Google. Probably couldn't bring him into those places without ruffling some pretty big feathers"
    ],
    "link": "https://twitter.com/ilyasut/status/1790517455628198322",
    "first_paragraph": ""
  },
  {
    "title": "U.S. Government Now Spends More on Debt Interest than National Defense (crfb.org)",
    "points": 58,
    "submitter": "webninja",
    "submit_time": "2024-05-14T23:12:38",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=40361206",
    "comments": [
      "Without defending debt spending at all, this claim is misleading because it has the defense budget too low. It's just listing the ~$820 billion Defense Department budget, and not counting things like Veterans Affairs, which by itself is another ~$350 billion. You never get the actual total for defense-related spending, because it's spread across different areas of the budget. This is a comment about how defense spending is always higher than people claim it is.",
      "But this is also misleading because we don\u2019t agree on what counts as defense, so we call everything defense.The armies of theoretical physicist working on new optical devices to study fusion could fall under the defense department if their work has some slight application for nuclear weapons, even though the economy benefits much more having a skilled workforce With strong science backgrounds.",
      "Is that defense spending? Or healthcare spending?And if it is defense spending, I assume you should at least discount the large portion of VA that would otherwise be  Medicare.",
      "This is misleading.  Owe 35T and pay off 100% the interest and next year you nominally owe the same amount, but it\u2019s a smaller burden every year.  Similarly it\u2019s possible for the nominal debt increase while things are getting better.  What matters is how the debt burden is changing over time and critically if borrowers are requiring higher interest rates on new debt.Understanding the impact of national debt is a lot more complicated than a single number, though obviously what\u2019s actually happening is unsustainable it\u2019s not as simple as how much a single number changes over time.",
      "But the headline compares it to defense, which also tends to grow with GDP. So it's a substantive fact that debt service is more than defense spending.",
      "> This is misleading. Owe 35T and pay off 100% the interest and next year you nominally owe the same amount, but it\u2019s a smaller burden every year.This is actually misleading. You\u2019re only right if the US stops spending. Biden has already said he wants to increase taxes to increase spending.",
      "Unless of course the increase in tax revenue is greater than increase in spending.Further, if that spending goes into the economy it can lead to more people paying even more in taxes thereby increasing tax revenue even more....",
      "Show me any time in the past 50 years where taxes went up and the deficit went down.",
      "> interest costs are expected to exceed Medicare spending this year, making interest on the national debt the second largest line item in the FY 2024 federal budget, behind only Social SecurityI wonder when it will exceed Social Security?",
      "2051, assuming nothing changes. That's probably not a good assumption to make, though."
    ],
    "link": "https://www.crfb.org/blogs/do-we-spend-more-interest-defense",
    "first_paragraph": "During a recent town hall, former United Nations Ambassador and current Presidential candidate Nikki Haley claimed, \u201cfor the first time we're paying more in interest payments than we are on our defense budget.\u201d"
  },
  {
    "title": "Glider \u2013 open-source eInk monitor with an emphasis on low latency (github.com/modos-labs)",
    "points": 367,
    "submitter": "mistercheph",
    "submit_time": "2024-05-14T18:19:01",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=40358309",
    "comments": [
      "I think this is the original repo:\nhttps://gitlab.com/zephray/gliderbased on this tweet:\nhttps://twitter.com/zephray_wenting/status/17901730074884506...",
      "The GitHub repository description also says:> Open-source E-ink monitor. Mirror of https://gitlab.com/zephray/glider",
      "Impressive breadth and depth of information in just the README alone.When this kind of stuff gets in the open like it does here, I expect rapid innovation and disruption from the crowd.",
      "I would hope that the Pine Note people look at it. Progress for them has been quite slow (I follow the discord), and they are struggling with a lot of basic stuff.",
      "At least this is real ePaper and not that previous bull that was trying to pass off monochrome LCD as low-latency ePaper.",
      "I've been using a Kindle for 10+ years now , but the poor responsiveness has always irked me.  I can't tell if it's a hardware or software issue.  I'm glad to see this project is focused on reducing latency on the hardware side.Does anyone know why the Kindle is such a bad product? I use it because I like e-ink and the e-book market is comprehensive, but I don't think it's actually a good device.",
      "It's responsive enough to do what it was purpose built for - read a book. It can do other things, but it's not made or marketed to do them, so they keep the cost low by not innovating on responsiveness. Instead, they make it more comfortable to use in other ways, such as how it's held and navigated, and the backlight.",
      "There are many high-quality products at a competitive cost.  That's a pathetic excuse.A lot of time was spent integrating social features that no one uses.  That time could have been spent on quality & latency.I understand their business goals and objectives.  It's still a low-quality product.A profitable product can also be terrible.",
      "As someone who worked on them a decade ago:To be clear, the displays are not created by Amazon / Lab126. Instead, they're a product of Eink Holdings, Inc.From what I remember, most of the screen refresh algorithms etc are Eink IP. And by the way, the cost of the display module alone was eye-watering, especially when compared with LCD displays...With e-ink, you can drive it faster, at the expense of massive power consumption or terrible ghosting / artifacting. You're not going to get the 6 weeks of use out of a battery doing that.For reading a book, smudges / ghosting sucks, so they optimize for full screen refreshes just often enough to clear that up (that's when the screen goes black then white, followed by the update).It's kind of a physics based fundamental limitation -- the display is closer to a mechanical display of old than an LCD.The kindle is a product that does one thing well: display static text in any lighting condition with a similar quality to the printed page.",
      "> Instead, they're a product of Eink Holdings, Inc. From what I remember, most of the screen refresh algorithms etc are Eink IP. And by the way, the cost of the display module alone was eye-wateringLayman here, but what you describe sounds very much like innovation held back by patents:At the core, it\u2019s really promising tech with actual major advantages over LCDs with applications already in many domains and possibly many more in the future; all you\u2019d need really is incremental improvements, similar to the journey of LCD. Remember the shitty TFT(?) monitors from 20 years ago? Ghosting, low resolution, delay, low contrast, backlight bleeding, etc.If we hypothetically had 20 companies competing the traditional way, throwing international manufacturing and material science know-how on these bad boys, I\u2019d bet $100 that we\u2019d see massive gains in ability at a fraction of marginal cost \u2013 from incrementalism alone \u2013 way before you reach physical limitations. And with a bit of luck, there might be a breakthrough in the core tech as well.> It's kind of a physics based fundamental limitation -- the display is closer to a mechanical display of old than an LCD.I hear you. But brilliant people have been wrong about these statements in all kinds of areas before. Could you share more detailed what those hard limitations might be?"
    ],
    "link": "https://github.com/Modos-Labs/Glider",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously."
  },
  {
    "title": "Gemini Flash (deepmind.google)",
    "points": 294,
    "submitter": "meetpateltech",
    "submit_time": "2024-05-14T18:00:59",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=40358071",
    "comments": [
      "I upgraded my llm-gemini plugin to provide CLI access to Gemini Flash:    pipx install llm # or brew install llm\n    llm install llm-gemini --upgrade\n    llm keys set gemini\n    # paste API key here\n    llm -m gemini-1.5-flash-latest 'a short poem about otters'\n\nhttps://github.com/simonw/llm-gemini/releases/tag/0.1a4",
      "Looking at MMLU and other benchmarks, this essentially means sub-second first-token latency with Llama 3 70B quality (but not GPT-4 / Opus), native multimodality, and 1M context.Not bad compared to rolling your own, but among frontier models the main competitive differentiator was native multimodality. With the release of GPT-4o I'm not clear on why an organization not bound to GCP would pick Gemini. 128k context (4o) is fine unless you're processing whole books/movies at once. Is anyone doing this at scale in a way that can't be filtered down from 1M to 100k?",
      "With 1M tokens you can dump 2000 pages of documents into the context windows before starting a chat.Gemini's strength isn't in being able to answer logic puzzles, it's strength is in its context length. Studying for an exam? Just put the entire textbook in the chat. Need to use a dead language for an old test system with no information on the internet? Drop the 1300 page reference manual in and ask away.",
      "How much do those input tokens cost?According to https://ai.google.dev/pricing it's $0.70/million input tokens (for a long context). That will be per-exchange, so every little back and forth will cost around that much (if you're using a substantial portion of the context window).And while I haven't tested Gemini, most LLMs get increasingly wonky as the context goes up, more likely to fixate, more likely to forget instructions.That big context window could definitely be great for certain tasks (especially information extraction), but it doesn't feel like a generally useful feature.",
      "That per exchange context cost is what really puts me off using cloud LLM for anything serious. I know batching and everything is needed in the data center, and important for keeping around KVQ cache, you basically need to fully take over machine to get an interactive session to get the context costs to scale with sequence length. So it's useful, but more in the case of a local LLaMA type situation if you want a conversation.",
      "I wonder if we could implement the equivalent of a JIT compilation, whereby context sequences which get repeatedly reused would be used for an online fine-tuning.",
      "Is there a way to amortize that cost over several queries, i.e. \"pre-bake\" a document into a context persisted in some form to allow cheaper follow-up queries about it?",
      "They announced that today, calling it \"context caching\" - but it looks like it's only going to be available for Gemini Pro 1.5, not for Gemini Flash.It reduces prompt costs by half for those shared prefix tokens, but you have to pay $4.50/million tokens/hour to keep that cache warm - so probably not a useful optimization for most lower traffic applications.https://ai.google.dev/gemini-api/docs/caching",
      "> It reduces prompt costs by half for those shared prefix tokens, but you have to pay $4.50/million tokens/hour to keep that cache warm - so probably not a useful optimization for most lower traffic applicationsThat's on a model with $3.5/1M input token cost, so half price on cached prefix tokens for $4.5/1M/hour breaks even at a little over 2.5 requests/hour using the cached prefix.",
      "Depending on the output window limit, the first query could be something like: \"Summarize this down to its essential details\" -- then use that to feed future queries.Tediously, it would be possible to do this chapter by chapter in order to exceed the output limit building something for future inputs.Of course, the summary might not fulfill the same functionality as the original source document. YMMV"
    ],
    "link": "https://deepmind.google/technologies/gemini/flash/",
    "first_paragraph": "Our lightweight model, optimized for speed and efficiency"
  },
  {
    "title": "GPT-4o's Memory Breakthrough \u2013 Needle in a Needlestack (llmonpy.ai)",
    "points": 205,
    "submitter": "parrt",
    "submit_time": "2024-05-13T21:54:06",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=40348947",
    "comments": [
      "This is based on a limericks dataset published in 2021. https://zenodo.org/records/5722527I think it very likely that gpt-4o was trained on this. I mean, why would you not? Innnput, innnput, Johnny five need more tokens.I wonder why the NIAN team don't  generate their limericks using different models, and check to make sure they're not in the dataset? Then you'd know the models couldn't possibly be trained on them.",
      "I tested the LLMs to make sure they could not answer the questions unless the limerick was given to them.  Other than 4o, they do very badly on this benchmark, so I don't think the test is invalidated by their training.",
      "Why wouldn't it still be invalidated by it if it was indeed trained on it?  The others may do worse and may or may not have been trained on it, but them failing on ititself doesn't imply 4o can do this well without the task being present in the corpus.",
      "It can't answer the questions without the limericks in the prompt. The benchmark is to establish how well it uses the context window. For example, I just asked it \"What is sought by the English top brass?\".  The answer from the limerick is \"Cranberry glass\" and 4o answers correctly when given the associated limerick once out of 2500+ limericks.However, without the limerick, 4o responded with: \"The term \"English top brass\" typically refers to high-ranking officials or leaders within the British government, military, or other institutions. What they seek can vary widely depending on the context and the specific goals of their roles. Here are some general pursuits that might be sought by such individuals:National Security: Ensuring the safety and security of the United Kingdom from internal and external threats is a primary concern. This involves defense strategies, intelligence operations, and counter-terrorism efforts.Economic Stability: High-ranking officials often focus on policies and initiatives aimed at maintaining and improving the country\u2019s economic health. This includes managing inflation, unemployment, trade relations, and economic growth.Political Influence: Top brass often seek to maintain or expand their influence both domestically and internationally. This can involve diplomacy, forming alliances, and participating in international organizations like the United Nations or NATO.Social Cohesion: Ensuring social stability and addressing issues such as inequality, healthcare, education, and social services are critical. This can involve implementing policies that promote social welfare and cohesion.Public Policy Implementation: Leaders are responsible for developing and implementing policies that reflect the government\u2019s priorities. This includes legislation, regulatory frameworks, and public administration.Technological Advancement: Keeping the nation at the forefront of technological innovation is often a priority. This includes investments in research and development, supporting tech industries, and ensuring cybersecurity.Environmental Sustainability: Addressing climate change and promoting sustainable practices are increasingly important. This includes policies aimed at reducing carbon emissions, protecting natural resources, and transitioning to renewable energy sources.Cultural and Heritage Preservation: Protecting and promoting the country\u2019s cultural heritage and national identity can also be a focus. This includes supporting the arts, preserving historical sites, and promoting cultural initiatives.These pursuits are shaped by the current political climate, global trends, and the specific priorities of the leaders in question. Would you like more detailed information on any of these areas?\"",
      "Maybe if you tell it to pull the answer from a limerick instead of generally asking?Edit: Ok no, I tried giving it a whole bunch of hints, and it was just making stuff up that was completely unrelated. Even directly pointing it at the original dataset didn\u2019t help.",
      "The needle in the haystack test gives a very limited view of the model\u2019s actual long context capabilities. It\u2019s mostly used because early models were terrible at it and it\u2019s easy to test. In fact, most recent models now do pretty good at this one task, but in practice, their ability to do anything complex drops off hugely after 32K tokens.RULER is a much better test:https://github.com/hsiehjackson/RULER> Despite achieving nearly perfect performance on the vanilla needle-in-a-haystack (NIAH) test, all models (except for Gemini-1.5-pro) exhibit large degradation on tasks in RULER as sequence length increases.> While all models claim context size of 32k tokens or greater (except for Llama3), only half of them can effectively handle sequence length of 32K by exceeding a qualitative threshold, Llama2-7b performance at 4K (85.6%). The performance exceeding the threshold is underlined.",
      "I'd like to see this for Gemini Pro 1.5 -- I threw the entirety of Moby Dick at it last week, and at one point all books Byung Chul-Han has ever published, and it both cases it was able to return the single part of a sentence that mentioned or answered my question verbatim, every single time, without any hallucinations.",
      "A number of people in my lab do research into long context evaluation of LLMs for works of fiction. The likelihood is very high that Moby Dick is in the training data. Instead the people in my lab have explored recently published books to avoid these issues.See BooookScore (https://openreview.net/forum?id=7Ttk3RzDeu) which was just presented at ICLR last week and FABLES (https://arxiv.org/abs/2404.01261) a recent preprint.",
      "I\u2019m not involved in the space, but it seems to me that having a model, in particular a massive model, exposed to a corpus of text like a book in the training data would have very minimal impact. I\u2019m aware that people have been able to return data \u2018out of the shadows\u2019 pf the training data but to my mind a model being mildly influenced by the weights between different words in this text hardly constitute hard recall, if anything it now \u2018knows\u2019 a little of the linguistic style of the authour.How far off am I?",
      "HN post re: FABLES: https://news.ycombinator.com/item?id=39982362FABLES/booklist.md: https://github.com/mungg/FABLES/blob/main/booklist.md/gscholar_related? FABLES: \nhttps://scholar.google.com/scholar?q=related:Y-Hx-kplbEUJ:sc.../gscholar_citations? BoookScore: \nhttps://scholar.google.com/scholar?cites=1796862036168524911......From that one day awhile ago: https://news.ycombinator.com/item?id=38347868#38354679 :> \"LLMs cannot find reasoning errors, but can correct them\" [ https://arxiv.org/abs/2311.08516 ] https://news.ycombinator.com/item?id=38353285"
    ],
    "link": "http://nian.llmonpy.ai/",
    "first_paragraph": "by Tom Burns"
  },
  {
    "title": "Sir, there's a cat in your mirror dimension (lcamtuf.substack.com)",
    "points": 295,
    "submitter": "zdw",
    "submit_time": "2024-05-14T16:42:54",
    "num_comments": 51,
    "comments_url": "https://news.ycombinator.com/item?id=40357141",
    "comments": [
      "In most photos with a recognizable subject, spectral energy will be concentrated around the origin (the upper left corner) as it is herehttps://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_pr...The same is true for the DCT of the woman. Meanwhile, the subject of a photo is typically located towards the frame's center. This helps minimize interference between the space and frequency domain data in the composite, thus preserving kitty's expression when the transform is invertedhttps://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_...(and vice versa for the woman)",
      "And this is only true of the DCT - 2D Fourier transforms of images usually concentrate the data near the center of the image.",
      "that's sort of true and sort of false.  here the origin is plotted in the upper-left-hand corner, and in the 2d fft images you're used to looking at, it's plotted in the center instead.  but you can plot the dct that way too, so it's sort of falseit's sort of true in that if you plot the standard 2d fft in this coordinate system, the data will be concentrated not in one corner of the image but in all four of them.  the dct really is unusual in putting all the low-frequency stuff at positive frequencies instead of equally at positive and negative frequencies",
      "It makes me think how the lens of the camera, is focusing the light/image at the center of the sensor, so it would make sense that data is also denser at the center, where the lens concentrated more light",
      "So\u2026 I think you\u2019re a bit confused about how lenses work and what they do (they don\u2019t focus all the light into the middle, they focus light from one plane onto another one. They only focus light from the center of the frame onto the center of the image - that\u2019s why it\u2019s an image)But\u2026 there is something interesting about what \u2018focusing\u2019 looks like in the frequency domain, and the difference between the frequency-space-transform of a sharply focused image and a blurred image - or of the same image focused at different focal planes - shows up as a predictable transformation in the frequency space; which means you can apply transformations in frequency space that cause focus changes in the image domain like a lens does.",
      "your first paragraph is completely wrong.  the lens concentrates collimated light parallel to its axis at its focal point, regardless of where it falls on the lens.  (and, strictly speaking, only at a single wavelength.)  collimated light coming from near-axial directions gets focused more or less to a point on more or less the focal plane.  but light at a single point doesn't have a direction, being a wave.  there is in fact a very profound connection between the action of a lens and the 2d fft; see my sibling comment for more detailsyour second paragraph is correct, and it is a special case of the convolution theorem; see https://en.wikipedia.org/wiki/Fourier_optics#The_2D_convolut...",
      "I don't think the idea that (idealized, camera) lenses focus light from distinct points in one plane (or at infinity) onto distinct points in another plane is 'completely wrong', but I'm open to being educated on my error.A lens focuses light parallel to its axis onto its focal point; it focuses parallel light coming in off-axis to other points on the focal plane.Alternatively, and equivalently, it focuses divergent light coming from common points on planes closer than infinity, onto matching points on other planes behind its focal plane.",
      "yes, as it happens, the image on the focal plane of the camera resulting from light coming from a particular direction is in fact the 2d fourier transform of the spatial distribution of that light at the lens.  this property has been used to build optical-computing military machine vision systems using spatial light modulators since the 01980s, because of some other useful properties of the fourier transform, that spatial shifts become phase shifts, so you can look for a target image everywhere in an image at once.  as far as i know, these systems have never made it past the prototype stagesee https://en.wikipedia.org/wiki/Fourier_optics#Fourier_transfo...",
      "What are you talking about?",
      "its the same fundamental effect"
    ],
    "link": "https://lcamtuf.substack.com/p/sir-theres-a-cat-in-your-mirror-dimension",
    "first_paragraph": ""
  },
  {
    "title": "Model Explorer: intuitive and hierarchical visualization of model graphs (ai.google.dev)",
    "points": 223,
    "submitter": "antognini",
    "submit_time": "2024-05-14T17:29:19",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=40357681",
    "comments": [
      "I normally use Netron for quickly inspecting models and making this 'mental picture' of the architecture, but this hierarchical approach seems a better fit for my needs.I'm just starting and the first impression is pretty good!",
      "Looks like they have moved to https://ai.google.dev/edge/model-explorer",
      "I'm not sure which link is more up to date, but since this one appears to give more background, we've switched to it from https://github.com/google-ai-edge/model-explorer above. Thanks!",
      "Is there a demo of a model visualized using this somewhere? Even if it's just a short video... it's hard to tell what it's like from screenshots.",
      "google-ai-edge/model-explorer//example_colabs/quick_start.ipynb: https://github.com/google-ai-edge/model-explorer/blob/main/e...XAI: Explainable AI: https://en.wikipedia.org/wiki/Explainable_artificial_intelli...",
      "https://github.com/lutzroeder/netronhttps://netron.app/",
      "Looks cool but seems like it doesn't work on torch 2.0\"AttributeError: module 'torch' has no attribute 'export'\"The torch.export API is currently in active development with planned breaking changes. The installation guide for this is still very minimal, anyone knows how to get it working on torch 2.0?",
      "I haven't managed to successfully export my custom ViT model yet, but I've not had an issue accessing the export methods in torch 2.3 within the nvcr.io/nvidia/pytorch:24.02-py3 container.I may have some more time to debug my trace tonight (i.e. remove conditionals from model + make sure everything is on CPU) and will update if I have any new insights.```\nfrom torch.export import export\n...\n    example_args = (dummy_input)\n    exported_program = export(model, args=example_args)\n```Links:\n- torch.export docs: https://pytorch.org/docs/stable/export.html#serialization\n- Using 24.02 container: https://docs.nvidia.com/deeplearning/frameworks/pytorch-rele...",
      "These tools are eye candy and have been around from tensorflow/tensorboard 0.x 10 years ago but never used after just trying them for fun. You need to read the source code no easy way around it.",
      "I've never really understood the point of these visualizer things.  The idea that a model is always well represented by a directed acyclic graph seems extremely dated.I really would love a PyTorch/JAX profiler that shows, in annotated Python, where your code is allocating memory, using compute or doing device copies."
    ],
    "link": "https://ai.google.dev/edge/model-explorer",
    "first_paragraph": "A visualization tool that lets you analyze ML models and graphs, accelerating\ndeployment to on-device targets."
  },
  {
    "title": "The new APT 3.0 solver (jak-linux.org)",
    "points": 113,
    "submitter": "todsacerdoti",
    "submit_time": "2024-05-14T18:40:50",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=40358588",
    "comments": [
      "> The most striking difference to the classic APT solver is that solver3 always keeps manually installed packages around, it never offers to remove them.Y'know, when you put it like that it does seem rather obvious, doesn't it? Principle of least surprise and all that.Edit: To be clear, not knocking anyone for it; hindsight is 20/20 and I've never written a dependency solving algorithm so I'm in no position to judge.",
      "It\u2019s not that clearcut, because sometimes you forget all the packages you installed manually over the years and aren\u2019t using anymore, and it can make sense to be offered to remove one when it helps resolving a conflict with a newer package that you actually want to use now.",
      "The healthy choice is to rebuild rather than upgrade any long-lived OS installation (e.g. your desktop) on distro release.Corollary: make it easy on yourself: mount /home separately (and maybe /var too), and keep /etc in scm.",
      "> The healthy choice is to rebuild rather than upgrade any long-lived OS installation (e.g. your desktop) on distro release.I wish there was more rigor (and testing) with this sort of thing. Generally systems should have the invariant that \u201cinstall old\u201d + \u201cupgrade\u201d == \u201cinstall new\u201d. This property can be fuzz tested with a bit of work - just make an automated distribution installer, install random sets of packages (or all of them), upgrade and see if the files all match./etc makes this harder, since you\u2019d want to migrate old configuration files rather than resetting configuration to the defaults. But I feel like this should be way more reliable in general. And people want that reliability - if the popularity of docker and nix are anything to go by.",
      "Alas that many packages will not upgrade conffiles gracefully when their structure/semantics change, and many are beyond the ability of any package manager's built-in diffing tools to apprehend. That is why I place /etc under scm for long-lived hosts, because what happens next instead looks an awful lot like doing a conflicted three-way code merge following a breaking-change vendor release. The greatest OMFGFFS in this realm, by far, came with the big lurch over to systemd.",
      "In theory yes, but this hits with the fact that defaults change.For example a new system won't have pulseaudio, but it won't be removed and replaced automatically because that would be potentially disruptive to existing users.",
      "I\u2019ve been upgrading Debian in-place for almost two decades now and prefer that approach. Security updates are automated (daily), major-version upgrades have almost no downtime, and only very rarely is there a critical configuration that needs to be adjusted.The installed packages can be listed with `dpkg --get-selections`, and that list can be replayed should it be necessary to recreate the installation, plus a backup of /etc/. But I never had to do this, Debian just works.",
      "I was previously a maintainer of certain Debian packages, and of similar vintage, so this advice comes with the extra salt of having seen how the sausage is made. I shudder to think how many abandoned files, orphan packages, and obsolete/bad-practice configurations might be lurking in a system that has only been release-upgraded for decades. Yes, no doubt it functions. By the same token, people can live in their own filth. Should they? I choose not to.That said, I may do a speculative dist-upgrade on a snapshot to reveal & prepare for conflicted conffiles in advance, but I'll throw that away, I won't rely on the merged result across a release upgrade.",
      "But when there's a configuration change dpkg-configure asks you if you want the upstream one, no?",
      "Debian releases are somewhat slower than Ubuntu or similar - given infinite time, esoteric configurations will break on update due to some edge case 4 dist-upgrades ago."
    ],
    "link": "https://blog.jak-linux.org/2024/05/14/solver3/",
    "first_paragraph": "APT 2.9.3 introduces the first iteration of the new solver codenamed\nsolver3, and now available with the \u2013solver 3.0 option. The new solver\nworks fundamentally different from the old one."
  },
  {
    "title": "Femtosecond lasers create 3D midair plasma displays you can touch (ieee.org)",
    "points": 195,
    "submitter": "jagged-chisel",
    "submit_time": "2024-05-14T16:10:58",
    "num_comments": 93,
    "comments_url": "https://news.ycombinator.com/item?id=40356751",
    "comments": [
      "I have a slight eye damage in one eye from working with lasers that were just a bit outside the safe limits. And I realized that only years after getting it.So the last thing I want, is to be near unconfined lasers powerful enough to ionize the air.",
      "> So the last thing I want, is to be near unconfined lasers powerful enough to ionize the air.I wholeheartedly agree.  Just thinking about how the potentially-unregulated cheaply-manufactured knock-off projectors will result in having to wear welding glasses when walking around the street to avoid being blinded by the 3D advertisements that are being shot at your face...",
      "Unfortunately, we couldn't even protect the dumbs from staring at a solar eclipse. Safety standards are ridiculously hard to calibrate.",
      "I think the same happened to me with LEDs. I have an odd feeling that I can't really see a small section somewhere close to the center of focus, not directly at it. I remember an odd sensation in the eye for days after dealing with a white LED.",
      "Are you sure thats not just the blind spot? It's quite big - roughly the size of a rubbish bin lid on the other side of a bedroom.Here's how to spot it:Hold you hands together, with thumbs up, at arms length. Close your left eye, and slowly move your right thumb away to the right, while looking at your left thumb. At around 6 inches it will dissapear.It's kind of hard to notice when my thumb is static, but it's more obvious if I wiggle my thumb while doing it.",
      "Wow, cool stuff! But no, its much closer to the center, and it's not something I can really spot. I just know that it started after I dealt a bit with newly bought \"high power\" leds. Not really high power and I never really looked directly into them (them facing at me). It also might have been some bright, red ones on breadboards. Happened over 10 years ago.",
      "You may be able to better pin it down along sharp contrast lines, maybe moving, or  flickering patterns. Eg. a black and white grid, stripes, or small checkerboard pattern on an LCD screen. And of course isolate eyes for these tests.Your brain can fill in a lot of voids before you notice, especially for monotonous areas and static impressions (as mentioned the blindspot or the blood vessels on your retina are usually \"invisible\" until you provoke awareness through unusual lighting changes, or defined peripheral accounting experiments). You likely won't notice acquired \"blindspots\" looking at a white wall, or chaotic fallen leaves on the ground, especially where the other eye provides missing information, but at the edges of highly predictable patterns, one eye closed at a time, you may trick your brain to fuck up, eg. blur or indent otherwise clearly defined areas, when it can't decide which color to fill. Reading texts with on eye closed may also highlight \"dancing\" letters or distortions around your center of vision.Worth noting, such defects may be caused by progressive conditions like retina detachment or even ocular melanoma, and the association with laser/light accidents may be incidental. If you spot a spot, do not brush it off as a limited loss! Have it checked, even with a likely attributable cause. You may prevent full blindness through medical intervention in case of disease!Edit: You can see the blood vessels when you look a white wall and steadily move a (smartphone) flashlight in and out of the field of vision, slowly waving the light next to your head, illuminating from your ears to the side of your nose and consequentially your eyes at a shallow angle. This will cause an unusual blood vessel shadow, now meandering through your vision. The blood vessels are also very visible during eye examinations when the doctor moves the slit lamp around (go check it out ;)Very weird seeing the insides of the very eye seeing, by ... well ...  seeing.",
      "Some of my earliest memories are of these kinds of perception, including the 'phosphenes' caused by internal pressure on the eyes when one looks to the side (they appear as fleeting, roundish flashes). It's curious to me that such formative memories would be triggered by something entirely 'internal' - not a measure of external stimulus involved. Perhaps in a similar way, someone else's earliest memory might be that of becoming aware of their heart beating!",
      "I don't think there is much of a brain when the heart starts beating.Edit: Never mind; misread.",
      "Optometrists have cameras that can take pictures of your retina and see if there's any obvious damage. You might consider getting your eyes checked out."
    ],
    "link": "https://spectrum.ieee.org/femtosecond-lasers-create-3d-midair-plasma-displays-you-can-touch",
    "first_paragraph": ""
  },
  {
    "title": "Stone with ancient writing system unearthed in garden (bbc.co.uk)",
    "points": 47,
    "submitter": "gadders",
    "submit_time": "2024-05-14T20:46:49",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=40359976",
    "comments": [
      "One of my favourite Time Team episodes ever was when they found an Ogham carving on a stone when digging up a golf course on the Isle of Man.The whole episode is a corker!https://www.youtube.com/watch?v=kW3UQEDQ0zQ",
      "Thanks very much for this recommendation!",
      "Related, there\u2019s a Unicode block for Ogham.https://en.m.wikipedia.org/wiki/Ogham_(Unicode_block)",
      "My uninformed suspicion is that this is not a language or a script but a timekeeping or calendar system of some kind.",
      "The article says it's this: https://en.wikipedia.org/wiki/Ogham>The vast majority of the inscriptions consist of personal names.",
      "It surprisingly similar to Morse code.",
      "How so?(Genuinely curious)",
      "It's binary."
    ],
    "link": "https://www.bbc.co.uk/news/articles/c14kywyk0vro",
    "first_paragraph": "The stone's Ogham script is believed to have been carved sometime between the 4th and 6th Century"
  },
  {
    "title": "Researchers find high levels of lead, mercury and arsenic in Beethoven's hair (smithsonianmag.com)",
    "points": 72,
    "submitter": "marban",
    "submit_time": "2024-05-14T10:15:13",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=40353529",
    "comments": [
      "\"It was so incredibly tragic that he couldn\u2019t hear this majestic music that he created.\"He couldn't physically hear the performance of it, but it's possible he could \"hear\" what it would sound like - and he very possibly heard it in his head before writing a single note down on paper (or however he recorded his music).I'm not sure everyone has this ability, but whenever I've written/recorded music, I almost literally hear it before I even try to create it or play it.  My memory of sound is REALLY strong.  I've never had someone go \"oh yeah, me too!\" when I discuss this though, so I have no idea if it's a common thing or what.  It's like borderline hallucination, the clarity with which I can recall music and sound.  I would wager that a lot of composers over the years have had this ability, especially since you couldn't exaclty spin up an orchestra in your livingroom while composing an operatic piece in 1800 :)",
      "A term for this is the mind\u2019s ear. You hear the mind\u2019s eye used more often.You can generalize the construction to any sense you can imagine.",
      "Thank you for putting the idea of the mind\u2019s tongue into my nightmares.",
      "My son is a composer, and he told me that he doesn't even need a keyboard any more, when he composes (he composes on paper, then transfers it to music notation software when it's ready to distribute).He also, sometimes, has a photographic memory for music. In university he had a listening test on a piece of classical music. He was able to visualize the score that he had studied when in high school, and identify the types and numbers of instruments.",
      "It\u2019s probably like writing. Writing by hand to avoid distractions then import into editing software",
      "I can't find a quote I remember reading, attributed to Beethoven, something along the lines of \"if people could hear what I hear in my mind, they wouldn't care about my music\". Does that ring a bell (!) with anybody? I could not get any language model to help.",
      "Try \"the music of the spheres\". https://en.m.wikipedia.org/wiki/Musica_universalis",
      "> I'm not sure everyone has this ability, but whenever I've written/recorded music, I almost literally hear it before I even try to create it or play it. My memory of sound is REALLY strongI\u2019m the same. Details in sound is the same as details in vision for me, I can remember the fine details of complete songs seemingly forever (yet my memory for everything else is terrible).  And I have the same thing where I have the sound and musical progression of what I\u2019m about to make in my head, \u2018playing\u2019, before I even start trying to make it happen on a synthesiser or on my modular system. And I don\u2019t just mean known sounds like violin, piano, etc. I\u2019m doing sound design as well as composition in my mind (I can hear it) before I start doing it for real.I can easily believe that Beethoven was capable of \u201challucinating\u201d the music that he was composing in the same way.Interestingly, I don\u2019t really get this when reading sheet music, only when I\u2019m creating or reflecting. Presumably, it\u2019s a different pathway in the brain.",
      "> I can remember the fine details of complete songs seemingly foreverIf you didn't buy the song, does it count as an illegal recording? /sThis was the main subject of a science fiction short story, unfortunately I cannot remember its title or author.",
      "A trained or otherwise skilled composer can hear music in their mind by reading the score (and while he wrote it). For sure, Beethoven knew how powerful his music was. He also intimately knew theory and how music 'worked' and aside from inventing a great number of things in music, he applied theory expertly. Modern day composers in the conservatory track are expected to have the same set of skills. A trained conductor can do the same."
    ],
    "link": "https://www.smithsonianmag.com/smart-news/locks-of-beethovens-hair-are-unraveling-the-mysteries-of-his-deafness-and-illnesses-180984332/",
    "first_paragraph": ""
  },
  {
    "title": "Contact of Containership Dali with the Key Bridge and Subsequent Bridge Collapse [pdf] (nyt.com)",
    "points": 67,
    "submitter": "mhb",
    "submit_time": "2024-05-14T20:48:14",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=40359993",
    "comments": [
      "Interesting. When the disaster first unfolded, a lot of experts came out to say the bridge appeared to lack protective barriers to help absorb the energy from a ship impact. [1]However, the NTSB says the bridge did have these barriers. There were large protective \"dolphins\" directly in front of the bridge piers, but the ship managed to careen in between them at an angle, missing them, but still hitting the bridge.In addition, there were large protective barriers surround the bridge pier that was struck:> In addition to the dolphins, pier nos. 17 and 18 were each surrounded by a\n100-foot-by- 84.5-foot crushable concrete box and timber fender system , as seen in\nfigure 12. These systems were comprised of hollow, thin-walled , concrete box\nstructures attached to the piers. The timber portions of the fender were attached to\nthe outer face of the concrete box and utilized a combination of vertical and\nhorizontal members. Additionally, steel plates were secured at the base of the vertical\ntimber members.[1] https://www.nytimes.com/2024/03/26/us/baltimore-key-bridge-s...",
      "When the bridge was originally constructed the concept of such protective impact barriers was quite new. The ship is also very different from the comparatively snub-nosed envisioned C7 types, trans-Atlantic cruisers, and barges that would've gone through when the bridge was designed in 1972. Cargo ships entering the harbour used to have wider bows with a shallower draft of thirty to thirty eight feet with a very shallow prow overhang because they were built for Atlantic voyages only.There's few barges going through the harbour these days, and cargo ships now are global and mostly built to the variety of post-Panamax standards making them extremely long with a very deep draft of forty five feet or more. That means the spacing and height originally thought to be needed to deflect barges and C7s was far too broad and short for the Neo Panamax II class MV Dali or any other modern cargo ship, and the deep draft that required a narrow bow and long prow allowed the bow to slide right in between the barriers and then ride up until it hit the bridge support. Essentially the nose had an overhang long enough that it hit the bridge support long before the rest of the ship hit the protective barrier.",
      "This is a fantastic example of clear technical writing! The NTSB goes out of their way here to define domain-specific terms (in the footnotes) to ensure this report is digestible by a public audience, which I think is really neat. We need more examples of this type of technical communication from government agencies.",
      "wow i had no idea they had some much generation and distribution going on. That's a lot of power they're moving. That's a lot of things that can go wrong. Even with all the backups, complex systems are complex, and there's obviously a gap in redundancy. Still, better a system failure than a human one.It was interesting that on the video you can see the ship lose/regain/lose power, and now it makes sense.",
      "The ship left port weighing 112,383 metric tons (ship+cargo). Travelling at it's loaded full speed of 16.8 knots, that comes out to be about 10.6 GigaJoulese or 3 Megawatt-hours of kinetic energy.TNT has an energy density of about 4.2MJ/kg. So the kinetic energy of the Dali at full speed is equal to about 2.5 metric tons of TNT.According to the report, the Dali was running at slow speed, which is 10 knots, giving \"only\" 0.7 tons worth of TNT in kinetic energy.Granted, ships operate in a relatively low friction environment, so you do not need that much power to get it moving. However, modern shipping vessels are massive.",
      "It would seem the real mystery is why did the breakers open.I have watched a youtube video where a knowledgeable chief engineer who works on comparable ships was very dismissive of the idea that it might be a cyber attack.[1] He was mainly reasoning that the on-board equipment is air gapped from the internet. Which of course it makes an attack more complicated but it is not like the airgap saved the centrifuges in Natanz.That being said it also does not say that it was a cyber attack. Could be any number of ordinary malfunctions. But i don\u2019t see that the publicly available evidence would exclude the possibility of a cyber attack as of yet. It would be very different if they would have found a damaged shaft in the generator, or a clogged fuel filter. Something hardware-ish.1: https://youtu.be/9B9znFDwdBI?si=aFSoqVsmrTaaQofY",
      "The fact that they had two explained power failures in port, and they made some changes to the configuration point to more likely causes: they made some faulty reconfiguration or the previously dormant breakers were faulty.",
      "The report has at least one of the power outages in port is explained (and says it was the only one).  They did change config after it though; but still.",
      "\u2018Airgapped from the internet\u2019 is very much the default state of technology on a ship. Connecting things to the internet seems like something that would require additional steps.",
      "At the moment perhaps, yes.  I will predict that will change as satellite internet becomes ubiquitous."
    ],
    "link": "https://static01.nyt.com/newsgraphics/documenttools/6119296c8c79713a/0e214c46-full.pdf",
    "first_paragraph": ""
  },
  {
    "title": "PaliGemma (ai.google.dev)",
    "points": 86,
    "submitter": "tosh",
    "submit_time": "2024-05-14T18:30:21",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=40358461",
    "comments": [
      "This is an impressive amount of public AI work coming out of Google. The competition we're seeing here is really pushing things forward.",
      "Anyone here have experience with extracting image embeddings out of these models? All the image emb. models I tried so far were quite bad for my use cases, and I feel that hidden representations of models like these might be much better.",
      "How does this model compare to the 3b Gemma if I would use it only with text?",
      "Well, to start with, there is no regular 3B Gemma. There are 2B and 7B Gemma models. I would guess this model is adding an extra 1B parameters to the 2B model to handle visual understanding.The 2B model is not very smart to begin with, so\u2026 I would expect this one to not be very smart either if you only use it for text, but I wouldn\u2019t expect it to be much worse. It could potentially be useful/interesting for simple visual understanding prompts.",
      "Google markets their new tech like arxiv articles. They have lots to learn from OpenAI"
    ],
    "link": "https://ai.google.dev/gemma/docs/paligemma",
    "first_paragraph": "PaliGemma is a lightweight open vision-language model (VLM) inspired by\n  PaLI-3,\n  and based on open components like the SigLIP\n  vision model and the Gemma language\n  model. PaliGemma takes both images and text as inputs and can answer questions about\n  images with detail and context, meaning that PaliGemma can perform deeper analysis of\n  images and provide useful insights, such as captioning for images and short videos,\n  object detection, and reading text embedded within images."
  },
  {
    "title": "The creator of 'Magic: The Gathering' knows where it all went wrong (defector.com)",
    "points": 58,
    "submitter": "superbyte",
    "submit_time": "2024-05-14T01:59:59",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=40350892",
    "comments": [
      "http://web.archive.org/web/20240514162813/https://defector.c...https://archive.ph/lH00w",
      "Part of the original magic that Garfield talks about, the player experience of discovering a world of cards you've never seen before, is captured by recent video games like Inscryption (especially) and Slay the Spire.Dominion is also an excellent game as the progenitor of the deck-building game genre, where you build a deck from scratch inside each game (and Inscryption/Slay the Spire descend from), rather than outside the game as in Magic the Gathering. Dominion randomly sets 10 cards to be accessible to players, out of ~500 for an extremely huge number of combinations, such that each 10-set is always new. Dominion shines as card value, and the value of card interactions (e.g., in a combo or engine), can vary significantly by the random 10-set context. In a sense this gives a tremendous sense of novelty, significantly more than playing Magic the Gathering.",
      "Its probably the nostalgia talking but a lot of the early magic was the art as well. It was professional enough to look good but not so polished that it didn't have its own character. I had favorite artists and it was always fun just admiring the art. \nThe new cards just don't capture me the same way. Something about them is too polished or too homogenized. They don't leave any room for imagination. I feel the same way about D&D artwork as well. No surprise that both D&D and MTG are owned by the same parent company.",
      "A very recent game that also captures this in a unique way is Balatro.The cards that you play are ordinary playing cards, but the way you modify how they score and what cards you have in your deck is a cool discovery process.",
      "And I will never be unsad about dominion.isotropic.org shutting down with its dead simple and fast dominion implementation, they promised to take it down if the company ever did its own thing and they did and you had to buy every expansion and it generally sucked.",
      "There's two Dominion Online games now, one from Temple Gates Games where you buy expansions, and the other one from ShuffleIt which is subscription-based.At least the Temple Gates version honors past purchases made on Making Fun dominion, even if they came from a Humble Bundle.",
      "The guy who invented the power 9 complaining about these new designers making rares that are too good\u2026 right.  Also the hate on Arena is bizarre - it\u2019s not perfect but it is polished and works well on (at least) iPhone PC and Mac.",
      "> Also the hate on Arena is bizarre - it\u2019s not perfect but it is polished and works well on (at least) iPhone PC and Mac.The hate against arena isn't due to lack of polish or it not working well, it's about what it's trying to do. It's not about collecting or trading cards anymore it's about opening as many loot boxes (packs) as possible.MTGA let you purchase specific cards, Arena does not and likely never will. That isn't an oversight, that's a conscious choice to get people to spend money on buying more digital packs. That's a big reason it gets hate.",
      "Balancing a game is hard. You can hardly blame anyone for getting it wrong on their first attempt. But getting it wrong 30 years later\u2026",
      "The power 9 became so powerful when later on it became possible to make combo decks that could win within 5 turns"
    ],
    "link": "https://defector.com/the-creator-of-magic-the-gathering-knows-exactly-where-it-all-went-wrong",
    "first_paragraph": "12:16 PM EDT on May 13, 2024"
  },
  {
    "title": "Optimizing ClickHouse: Tactics that worked for us (highlight.io)",
    "points": 46,
    "submitter": "podoman",
    "submit_time": "2024-05-14T14:57:55",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=40355875",
    "comments": [
      "We've been using highlight for our bootstrapped member management platform[1] and I gotta say I'm super impressed with the session replay feature, it's really helpful for understanding user behavior at a fraction of the price of competitors.I remember wanting to use Heap's session replay only to release they want hundreds of dollars per _month_, my last bill with highlight was $2.38 I recall.That's all to say that I'm glad Highlight is figuring out how to scale while still offering their features to the small players of the world.[1] https://embolt.app",
      "Very nice and very inspirational for someone bootstrapping a startup.The pages clearly defined what you are building and how to use it.The explanation of platform fees makes sense, though it could more clear if the pricing examples are only based on those fees or are account limits to number of members or dues.You might want to check your terms of service, they do not list a jurisdiction and have the placeholder [jurisdiction] instead.Best of luck with it!",
      "Highlight.io cofounder here. Thanks for the shout out. Glad to hear you like the product; continue to share feedback as you use it!"
    ],
    "link": "https://www.highlight.io/blog/lw5-clickhouse-performance-optimization",
    "first_paragraph": "Apr 21, 2024 \u2022 6 min. read"
  },
  {
    "title": "Exploring GNU extensions in the Linux kernel (maskray.me)",
    "points": 41,
    "submitter": "ingve",
    "submit_time": "2024-05-13T06:11:38",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=40340248",
    "comments": [
      "I am fantastic on Linux kernel and on Clang compiler. This article teaches me what GNU extension characteristic will be when Linux kernel is accepting more modern C11 standard.For example, Linux kernel use local labels, inline assembly and builtin functions heavily.This article inspires me to persist studying in Linux kernel and Clang compiler.",
      "Clang supports the extensions, you can build the Linux kernel with clang today:  make -s LLVM=1",
      "As sibling mentioned, you can build the kernel with clang today. `make CC=clang`, and for whatever reason I've found that it produces code that's significantly more pleasant to step through under a debugger than gcc.If anybody has an explanation for this I'd love to hear it.",
      "Interesting.\nTraditionally, Clang's -O1 and higher optimizations have been considered less debuggable than GCC's.Sony developers have proposed changes to improve the debugging experience and some work has been done, e.g.\nhttps://discourse.llvm.org/t/rfc-redefine-og-o1-and-add-a-ne...* change representation to help make -g not change codegen : https://discourse.llvm.org/t/rfc-debuginfo-proposed-changes-..."
    ],
    "link": "https://maskray.me/blog/2024-05-12-exploring-gnu-extensions-in-linux-kernel",
    "first_paragraph": "The Linux kernel is written in C, but it also leverages extensions\nprovided by GCC. In 2022, it moved from GCC/Clang\n-std=gnu89 to -std=gnu11. This article\nexplores my notes on how these GNU extensions are utilized within the\nkernel."
  },
  {
    "title": "Show HN: Pico: An open-source Ngrok alternative built for production traffic (github.com/andydunstall)",
    "points": 177,
    "submitter": "andydunstall",
    "submit_time": "2024-05-14T14:44:37",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=40355744",
    "comments": [
      "This is very cool! Trying to get it added to awesome-tunneling: https://github.com/anderspitman/awesome-tunneling/pull/149Related -- we also built a simple (but not production-grade) tunneling solution just for devving on our open-source project (multiplayer game server management).We recently ran in to an issue where we need devs to be able to have a public IP with vanilla TCP+TLS sockets to hack on some parts of our software. I tried Ngrok TCP endpoints, but didn't feel comfortable requiring our maintainers to pay for SaaS just to be able to hack around with our software. Cloudflare Tunnels is awesome if you know what you're doing, but too complicated to set up.It works by automating a Terraform plan to (a) set up a remote VM, (b) set up SSH keys, and (c) create a container that uses reverse SSH tunneling to expose a port on the host. We get the benefit of a dedicated IP + any port + no 3rd party vendors for $2.50/mo in your own cloud. All you need is a Linode access token, arguably faster and cheaper than any other reverse tunneling software.Source: https://github.com/rivet-gg/rivet/tree/main/infra/dev-tunnelSetup guide: https://github.com/rivet-gg/rivet/blob/main/docs/infrastruct...",
      "This is a good candidate for the list. Most solutions don't really differentiate themselves much, but being designed for production environments is certainly unique amongst the open source options.I'll try to get this merged today.",
      "Check out ziti and zork projects, they are a lot more innovative and ambitious https://github.com/openziti/ziti",
      "As a hobbyist and programmer, I love the project.\nAs an infosec professional working in an enterprise environment... not so much.",
      "Say I have a pico cluster with a few service nodes and a few upstream clients register themselves, and then I deploy a new version of the service nodes where all existing service nodes are taken down and replaced.Can the client still talk to the service nodes? Is this over the same tunnel, or does the agent need to create a new tunnel? What happens to requests that are sent from a proxy-client to the service nodes during this transition?Or at a much higher level: Can I deploy new service nodes without downtime?",
      "When Pico server nodes are replaced, the upstreams will automatically reconnect to a new node, then that node will propagate the new routing information to the other nodes in the clusterSo if you have a single upstream for an endpoint, when the upstream reconnects there may be a second where it isn't connected but will recover quickly (planning to add retries in the future to handle this more gracefully)Similarly if a server node fails the upstream can reconnect",
      "Is there a way to use this with a simple docker-compose, no Kubernetes?",
      "Looks like there is from the instructions in the getting-started guide: https://github.com/andydunstall/pico/blob/main/docs/getting-...",
      "The instructions there say that it will create a cluster with three nodes, so while it is using docker compose I am guessing it is still using kubernetes",
      "That demo only uses docker compose: https://github.com/andydunstall/pico/blob/main/docs/demo/doc..."
    ],
    "link": "https://github.com/andydunstall/pico",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously."
  },
  {
    "title": "Higher RAII and the seven arcane uses of linear types (verdagon.dev)",
    "points": 38,
    "submitter": "agluszak",
    "submit_time": "2024-05-14T20:37:22",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=40359886",
    "comments": [
      "Cool to see this on HN!This is my favorite part of language design: you get to play with weird ideas and see how the implications cascade through the rest of the program. It kind of blew my mind when a linear type solved a caching problem.Now it's kind of a curse, because any time I code in a normal language (even the modern ones like Scala and Rust) I see places (concurrency, coroutines, etc) where we could have statically prevented these bugs.",
      "I didn't know you were back.I always love reading your posts and now I find out I've got 3 new ones to read!It's going to be a good few days. ^_^",
      "Thank you, my friend =) So glad to hear you enjoy the articles!",
      "Is there a reason we're not seeing linear types in more languages? I'm not familiar with how difficult it is to implement or if there are usage issues that end up showing only after a while?",
      "There are a couple technical reasons:1. In RC and tracing GC languages, a linear object would need exactly one special \"linear\" reference to it, which would be responsible for eventually \"consuming\" (though not deleting) the object by handing it to its final destination function. (You can tell, I'm trying real hard to not say destructor here)2. In single-ownership languages like C++, Rust, etc. we've been conflating the destructor to handle two things: fulfilling the object's final purpose, and handling exceptions/panics. It seemed convenient at the time, but it also prevented linear types.But honestly, I think we were just stuck in a local maximum. There was no reason to change those points because we didn't know about higher RAII, and we didn't know about higher RAII because those two points prevented linear types.But with more of us exploring this new area (Vale, Austral, maybe even Mojo!), I daresay we'll one day see linear types and higher RAII entering the mainstream. Especially if someone can come up with a better name!",
      "Plenty of new research languages are coming out with linear types.Building a mainstream language is extremely expensive these days, to the point that probably only a handful of companies can attempt it. I work in Scala which teeters on the edge of mainstream, and it's not the language itself that needs major backing, it's all the other stuff - IDEs, library repositories, build tools, profilers. I would love to leap into e.g. Idris, which does have linear types, but who's going to write an IDE for it? Even Rust struggles with this.And it's very hard to retrofit linear types onto an existing language, if you can even get a quorum in favour of doing so. Haskell is trying, and I wish them well, but it's not going to be easy, and again they're barely mainstream.",
      "> Even Rust struggles with this.The Rust language server seems really good. What have you been missing there?",
      "It was years before we had rust-analyzer.",
      "A year and a half doesn't seem like bad turnaround time to me. shrug    On June 27, 2016, Microsoft announced a collaboration with Red Hat and Codenvy to standardize [Language Server Protocol]'s specification\n\n\u2014 https://en.wikipedia.org/wiki/Language_Server_Protocolvs    initial\n    Date:   2017-12-21 22:25:45 +0300\n\n\u2014 https://github.com/rust-lang/rust-analyzer/commit/a63222cd24...",
      "I've been using rust since 2010"
    ],
    "link": "https://verdagon.dev/blog/higher-raii-uses-linear-types",
    "first_paragraph": "Can you spot the problem in each of these comments?"
  }
]