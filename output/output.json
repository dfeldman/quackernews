[
  {
    "title": "The Fastest Mutexes (justine.lol)",
    "points": 546,
    "submitter": "jart",
    "submit_time": "2024-10-02T15:31:45.000000Z",
    "num_comments": 212,
    "comments_url": "https://news.ycombinator.com/item?id=41721668",
    "comments": [
      "Always cool to see new mutex implementations and shootouts between them, but I don\u2019t like how this one is benchmarked. Looks like a microbenchmark.Most of us who ship fast locks use very large multithreaded programs as our primary way of testing performance. The things that make a mutex fast or slow seem to be different for complex workloads with varied critical section length, varied numbers of threads contending, and varying levels of contention.(Source: I wrote the fast locks that WebKit uses, I\u2019m the person who invented the ParkingLot abstraction for lock impls (now also used in Rust and Unreal Engine), and I previously did research on fast locks for Java and have a paper about that.)\n \nreply",
      "To add to this, as the original/lead author of a desktop app that frequently runs with many tens of threads, I'd like to see numbers on performance in non-heavily contended cases. As a real-time (audio) programmer, I am more concerned with (for example) the cost to take the mutex even when it is not already locked (which is the overwhelming situation in our app). Likewise, I want to know the cost of a try-lock operation that will fail, not what happens when N threads are contending.Of course, with Cosmopolitan being open source and all, I could do these measurements myself, but still ...\n \nreply",
      "Totally!Pro tip: if you really do know that contention is unlikely, and uncontended acquisition is super important, then it's theoretically impossible to do better than a spinlock.Reason: locks that have the ability to put the thread to sleep on a queue must do compare-and-swap (or at least an atomic RMW) on `unlock`. But spinlocks can get away with just doing a store-release (or just a store with a compiler fence on X86) to `unlock`.Spinlocks also have excellent throughput under most contention scenarios, though at the cost of power and being unkind to other apps on the system. If you want your spinlock to be hella fast on contention just make sure you `sched_yield` before each retry (or `SwitchToThread` on Windows, and on Darwin you can do a bit better with `thread_switch(MACH_PORT_NULL, SWITCH_OPTION_DEPRESS, 1)`).\n \nreply",
      ">  just make sure you `sched_yield` before each retryAssuming `sched_yield` does something.There's a futex congestion problem inside Wine's memory allocator. There are several levels of locks. If you're growing a buffer, in the sense of C's \"realloc\", and no buffer is available, memory allocation is locked during the allocation of a bigger buffer, copying of the contents, and release of the old buffer. \"Push\" type operations can force this. Two orders of magnitude performance drops ensue when multi-threaded programs are contending for that lock.[1]Inside one of the lock loops is a call to \"YieldProcessor\".    static void spin_lock( LONG *lock )\n    {\n         while (InterlockedCompareExchange( lock, -1, 0 ))\n             YieldProcessor();\n    }\n\nBut the actual code for YieldProcessor is a NOP on x86:[2]    static FORCEINLINE void YieldProcessor(void)\n    {\n        #ifdef __GNUC__\n        #if defined(__i386__) || defined(__x86_64__)\n             __asm__ __volatile__( \"rep; nop\" : : : \"memory\" );\n        #elif defined(__arm__) || defined(__aarch64__)\n            __asm__ __volatile__( \"dmb ishst\\n\\tyield\" : : : \"memory\" );\n        #else\n            __asm__ __volatile__( \"\" : : : \"memory\" );\n        #endif\n        #endif\n    }\n}Wine devs are aware of this, but the mess is bad enough that no one has tackled it.\nThis is down in the core of what \"malloc\" calls, so changes there could have unexpected effects on many programs.\nNeeds attention from someone really into mutexes.[1] https://forum.winehq.org/viewtopic.php?t=37688[2] https://gitlab.winehq.org/wine/wine/-/blob/HEAD/include/winn...\n \nreply",
      "`rep; nop;` is actually the `pause` instruction. On older CPUs it\u2019s a standard nop, but on newer CPUs it\u2019s a more efficient nop.Spinning on the CMPXCHG is also a bad idea. You should spin on the read and only then attempt the CMPXCHG.\n \nreply",
      "Bingo. Spinning on CMPXCHG can cause livelock.\n \nreply",
      "sched_yield isn\u2019t a nop\n \nreply",
      "On Darwin, it's possible for a pure spinlock to produce a priority inversion deadlock, because Darwin has a quality of service implementation in the kernel that differs from how everyone else handles thread priority. In other kernels, a low-priority thread will still eventually be guaranteed a cpu slice, so if it's holding a spinlock, it will eventually make progress and unlock. On Darwin with Quality of Service, it's possible for higher-QoS threads to preempt lower-QoS threads indefinitely.For this reason, on Darwin you want to avoid spinlocks unless you know that all threads touching the spinlock are always running in the same QoS. Instead of spinlocks, your go-to for low-overhead locks there is os_unfair_lock, which is a spinlock variant that donates priority of the blocked threads to the running thread.\n \nreply",
      "I\u2019ve shipped code on Darwin that spinlocks and gets away with it without any noticeable cases of this happening.I know it can happen in theory. But theory and practice ain\u2019t the same.I worked for Apple when I shipped this too lmao\n \nreply",
      "We use spinlocks where appropriate. In the 90s I recall that the general rule of thumb was if the lock is held for <10x the context switch time, spinlocks are generally a better choice. Not sure if that's still true of contemporary architectures.The more common pattern in rt/audio code is \"try to take the lock, but have an alternate code path if that fails\". It's not that is never going to be contention, but it will be extremely rare, and when it occurs, it probably matters. RWLocks are also a common pattern, with the RT thread(s) being read-only (and still being required to fall back on an alternate code path if the read lock cannot be taken).\n \nreply"
    ],
    "link": "https://justine.lol/mutex/",
    "first_paragraph": "\nOct 2nd, 2024 @ justine's web page\nThe Fastest Mutexes\n\n\nCosmopolitan Honeybadger\n\n\nCosmopolitan Libc is well-known for\nits polyglot fat binary hack\nthat lets your executables run on six OSes for AMD64 / ARM64. What may\nsurprise you is that it could also be the best C library for your\nproduction workloads too. To demonstrate this point, let's compare\nCosmo's mutex library with other platforms.\n\n\nWe'll do this by writing a simple test that spawns 30\nthreads which increment the same integer 100,000\ntimes. This tests how well a mutex implementation performs in\nthe heavily contended use case. In essence, that means the following\n(see the segment at the bottom of the page for the full source code).\n\n\nint g_chores;\npthread_mutex_t g_locker = PTHREAD_MUTEX_INITIALIZER;\n\nvoid *worker(void *arg) {\n  for (int i = 0; i < ITERATIONS; ++i) {\n    pthread_mutex_lock(&g_locker);\n    ++g_chores;\n    pthread_mutex_unlock(&g_locker);\n  }\n  return 0;\n}\n\n\nNow let's start with the exciting part, which are "
  },
  {
    "title": "An adult fruit fly brain has been mapped (economist.com)",
    "points": 292,
    "submitter": "teleforce",
    "submit_time": "2024-10-02T16:16:03.000000Z",
    "num_comments": 102,
    "comments_url": "https://news.ycombinator.com/item?id=41722159",
    "comments": [
      "The paper published in Nature, which is open access: https://www.nature.com/articles/s41586-024-07558-y",
      "https://archive.is/vBUjt",
      "It was my understanding that all this connectome-based research was largely a deadend, because it doesnt capture dynamics, nor a vast array of interactions. if you've ever seen neurones being grown (go search YT), you'll see it's a massive gelatinous structure which is highly plastic and highly dynamic. Even in the simplest brains (eg., of elgans), you get 10^x exponential growth in number of neurones and their connections as it grows.\n \nreply",
      "Connectome-adjacent neuroscientist here. Definitely not a dead end! But also definitely not the whole picture.One of the main open questions in neuroscience right now is how network structure, dynamics, and function are related in the brain. Connectomes provide tremendous insight into structure, but as mentioned this does not generically solve either the dynamics or function problem. For example, for many of these neurons we don't have a good understanding of their input-output relationship, and the nature of this relationship can strongly affect the dynamics that emerge in a highly connected network. Individual variability across connectomes, and how connectomes change over development are also a significant issue, but at least for the fly it's thought that many of the basic structures are pretty conserved across adult animals, even if many of the details could differ.Modulo these caveats, knowing the physical network structure of the brain does still impose huge constraints on what kinds of models we should be using for gaining insight into dynamics and function. For example, there are well known areas (the \"mushroom bodies\") with specific feed-forward connectivity patterns that are very different from a random recurrent network. Further, there are at least some areas in the fly brain where we think there are indeed quite clean structure-function relationships, e.g. in the central complex of the fly brain, which contains a physical ring of neurons and is thought to support a \"bump\" of activity that acts as a sort of compass that helps flies navigate via a ring-attractor-like dynamical system. Thus, even though it has many missing pieces, a wiring diagram like this can be tremendously useful for generating hypotheses to guide more targeted experiments and theoretical studies.\n \nreply",
      "How's Open Worm coming along? The connectome of C. Elegans has been known for years, and Open Worm tries to simulate it. [1] Not with enormous success.[1] https://openworm.org/assets/OpenWormPoster_Celegans_Glasgow_...\n \nreply",
      "Like everything in science: we don't know until we know.No need to treat research like a business.\n \nreply",
      "Budgets are finite, and most science funding involves some decision making about how to allocate resources.\n \nreply",
      "Very Nice. --from a Connectome-Centric neuroimager :)\nOne technique that I am pursuing right now is information decomposition of timeseries to separate the mutual information of two timeseries into redundant and synergistic informational atoms (synnergystic here means the degree to which knowing both timeseries gives you more information than the individual parts give (more than sum of parts). The big limitation of the method is the geometric explosion in complexity of the decomposition as the number of time series grow, with most analyses being limited to two or three times series at a time. However, the scale of the data on which it is applied is not requisite, meaning the approach can equally be used on the mutual information between two regions of interest in rsfMRI , or two spiking timeseries from individual neurons.\nhttps://en.wikipedia.org/wiki/Partial_information_decomposit...\n \nreply",
      "This is done agaist an adult so all the neurons have already grown.connectome isn't a dead end but it doesn't solve all known problems.  It's like making a static map which you can then use to inspect all those cars driving around (the dynamics) and crashing (the interactions).[edit: I forgot to mention that neuron growth in adults (across many species) is still a controversial topic; see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7554932/ for some commentary on the challenge in fly; https://en.wikipedia.org/wiki/Adult_neurogenesis for commentary on the larger problem ]\n \nreply",
      "Giving scientists access to the connectome snapshot alone is very exciting. The first step to understanding why something is and how it came to be is seeing what it is.There are systems at play that form the brain into what it is and we don\u2019t know much about them. The individual neurons \u2014 we have a better understanding of, but not the emergent systems. Now that many more scientists will know what the target for these systems is \u2014 what is the brain they shape, we can start to understand the control and feedback loops that result in this snapshot state of the brain.And that\u2019s why it\u2019s not a dead end. Just because it doesn\u2019t immediately give some sort of a consumer product, doesn\u2019t mean it\u2019s not a step forward.\n \nreply"
    ],
    "link": "https://www.economist.com/science-and-technology/2024/10/02/an-adult-fruit-fly-brain-has-been-mapped-human-brains-could-follow",
    "first_paragraph": ""
  },
  {
    "title": "In Mexico\u2019s underwater caves, a glimpse of artifacts, fossils and human remains (smithsonianmag.com)",
    "points": 69,
    "submitter": "pseudolus",
    "submit_time": "2024-10-02T20:36:41.000000Z",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=41724747",
    "comments": [
      "Anyone visiting the Yucatan peninsula should take a day to go swimming in a cenote. It\u2019s a magical experience even without diving into the underwater caves (they have some scary signs with warnings about that).> There\u2019s a symbiotic relationship between the passionate and technical cave explorers who investigate every hole in a cave in their free time (and just for fun) and those in the scientific community who want to study these prehistoric materials but cannot reach where they\u2019re hidden in the underwater darkness.The lack of cavers in general is becoming a bigger and bigger problem in archaeology and paleoanthropology. Since a lot of archaic human species were quite a bit smaller, they managed to make very elaborate caves their home that are hard for the average adult to navigate. Underwater archaeology is still in its infancy so the training isn't explicitly part of anyone's  education.Last year there was a story [1] on the front page about research into Homo naledi in the Rising Star Cave [2] that was only made possible because they were able to find six petite paleoanthropologists cavers who were able to fit through a \"vertically oriented 'chimney' or 'chute' measuring 12 m (39 ft) long with an average width of 20 cm (7.9 in)\" to the Dinaledi room in the back of the cave. They found 1,500 human bones there and still have a lot left to excavate.[1] https://news.ycombinator.com/item?id=36344397[2] https://en.wikipedia.org/wiki/Rising_Star_Cave\n \nreply",
      "Diving in the cenotes is pretty damn awesome though! You just have to make sure to dive the ones that have been explored and have designated routes. My third and fourth dives after getting my open water certification were in cenotes around Playa Del Carmen and that experience was just mind blowing. Would love to do it again.\n \nreply",
      "A friend of mine made a bunch of films about his cenote diving.  This one give a pretty good idea of what it's like: https://www.youtube.com/watch?v=99z8JgxdDmcHe also has some amazing IMAX footage of cenotes, among other caves, in his film Ancient Caves, which is still playing on a few IMAX screens, though it's run is mostly over. https://www.youtube.com/watch?v=MSZL9YbXDGs\n \nreply",
      "Seems like small cave exploration robots are well within reach for current technology.Any HN billionaire up for funding the development?\n \nreply",
      "NASA worked with a commercial partner to develop the SUNFISH [1][2] for future exploration of Europa. It's been used to explore underwater caves and they have a video showing the generated data from Peacock Springs [3][1] https://oceanexplorer.noaa.gov/explorations/22sunfish/featur...[2] https://sunfishinc.com/[3] https://www.youtube.com/watch?v=mpKFkrUeF9o\n \nreply",
      "will probably never get those commas, hopefully wont need them because this video by Polish students made one of my 'retirement projects' \"underwater ROV\"https://www.youtube.com/watch?v=P2kChvtPxywthey're hurrying along though https://www.youtube.com/watch?v=VZucylrwaK0\n \nreply",
      "A submarine drone could probably be done as a hobby project with a fairly limited budget.\n \nreply",
      "How small do you have to be to do this kind of work?\n \nreply",
      "A well-known example is the figure of a woman at the entrance of Cenote Dos Ojos; while it was not sculpted as such, it is a carefully selected speleothem that resembles the silhouette of a woman and was intentionally exhibited on a pedestal to decorate the cave entrance, evidence of paleoart from more than 8,000 years ago that anyone can visit.Are there any images of this?\n \nreply",
      "That photography... wow!\n \nreply"
    ],
    "link": "https://www.smithsonianmag.com/travel/divers-in-mexicos-underwater-caves-get-a-glimpse-of-rarely-seen-artifacts-fossils-and-human-remains-180985159/",
    "first_paragraph": ""
  },
  {
    "title": "Filed: WP Engine Inc. v Automattic Inc. and Matthew Charles Mullenweg [pdf] (wpengine.com)",
    "points": 61,
    "submitter": "dangrossman",
    "submit_time": "2024-10-03T00:29:05.000000Z",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41726197",
    "comments": [
      "What's sad here is that this dispute isn't likely to make Wordpress any better, but rather send money to lawyers and reduce enthusiasm for the OSS project.\n \nreply",
      "Wait that's not making it better?  /sSeriously though, it's a freaking legacy.  Sad to see it go this way.\n \nreply",
      "Full PACER/RECAP docket, for those interested in following future filings: https://www.courtlistener.com/docket/69221176/wpengine-inc-v...\n \nreply",
      "That's what going \"nuclear\" looks like ... I guess Mullenweg found out.Sadly, instead of supporting open source with $5 million, they each will spend 10 million on lawyers.\n \nreply",
      "It's hard to even imagine what a best-case scenario looks like for Matt at this point. Putting aside the matter of righteousness, his business is pretty much chalked for professional applications at this point. B2B partnerships are done - anyone with lawyers on-staff are going to get shoulder-tapped and asked to find another hosting solution. Smaller customers have all the more reason to bleed out to competitors, and the plugin/theme ecosystem is going to see the writing on the wall better than anyone else. Qui bono? Who is Matt \"protecting\" from harm, really?I just don't understand in any sense what the end goal was here. On the one hand, I feel like I must not understand because I lack an emotional connection to the project. In the other hand, I feel like a stoic approach is the only one that makes sense. It's a baffling tempest-in-a-teapot that must have extra details I don't understand. If all this occurred with no hidden motives, it would be a shockingly wasteful decision.\n \nreply",
      "If it's any three things, it's about money, money, and money.Zooming out a bit, Automattic acquired Tumblr and like all those before it seems to be choking on it.Competitors like Wix, Squarespace, WebFlow and Shopify are all nipping at WordPress' marketshare.I don't know what WordPress.com's stats look like, but blogging is out of sytle. New cool kids want the new black. That is to be social media influencers. Along the same lines, the WordPress Community is \"aging out\". Events online or off there's too little \"youth\" engaged and excited about the product.In shoet, the pie isn't what it once was. Matt looked around the room, saw deep pockets (i.e., WP Engine) and made a go for it. That was a poor decision. Seeing himself as a cult leader who would get unwavering support from his cult (aka The WordPress Community) was another mistake. People are fatigued and enough them have stopped drinking his Kool Aid. There are pockets of support but certainly not what it used to be. Many WP people are anxious to move on from the Mattopoly.\n \nreply",
      "\"What Defendants\u2019 statements and assurances did not disclose is that while they were publicly touting their purported good deed of moving this intellectual property away from a private company, and into the safe hands of a nonprofit, Defendants in fact had quietly transferred irrevocable, exclusive, royalty-free rights in the WordPress trademarks right back to Automattic that\nvery same day in 2010. This meant that far from being \u201cindependent of any company\u201d as Defendants had promised, control over the WordPress trademarks effectively never left Automattic\u2019s hands.\"Already on the second page, a mind-blowing revelation. This is gold. What a time to be alive.\n \nreply",
      "COMPLAINT FOR:\n    (1) Intentional Interference with Contractual Relations;\n    (2) Intentional Interference with Prospective Economic Relations;\n    (3) Computer Fraud and Abuse Act, 18 U.S.C. \u00a7 1030 et seq.;\n    (4) Attempted Extortion;\n    (5) Unfair Competition, Cal. Bus. Prof. Code\u00a7 17200, et seq.;\n    (6) Promissory Estoppel;\n    (7) Declaratory Judgment of Non-Infringement;\n    (8) Declaratory Judgment of Non-Dilution;\n    (9) Libel;\n    (10) Trade Libel; and\n    (11) Slander.\n    \nSpicy.\n \nreply",
      "> Mullenweg failed to disclose this exclusive licensing arrangement between his nonprofit (the WordPress Foundation) and his for-profit (Automattic) in the WordPress\nFoundation\u2019s tax filings with the California government, claiming that there were no \u201ccontracts ... between [WordPress Foundation] and any officer, director or trustee ... or with an entity in which any such officer, director or trustee had any financial interest\u201d.That can't be good for him.\n \nreply",
      "Um this seems pretty horrendous (from a moral PoV, no idea about legal), at the time Mullenweg apparently said> Automattic has transferred the WordPress trademark to the WordPress> Foundation, the nonprofit dedicated to promoting and ensuring access to WordPress and related> open source projects in perpetuity. This means that the most central piece of WordPress\u2019s identity,> its name, is now fully independent from any company.\"But then the complaint says:> What Defendants\u2019 statements and assurances did not disclose is that while they were> publicly touting their purported good deed of moving this intellectual property away from a private> company, and into the safe hands of a nonprofit, Defendants in fact had quietly transferred> irrevocable, exclusive, royalty-free rights in the WordPress trademarks right back to Automattic that\nvery same day in 2010. This meant that far from being \u201cindependent of any company\u201d as Defendants> had promised, control over the WordPress trademarks effectively never left Automattic\u2019s hands.\"Again, no idea about the legality of saying you've done one thing in public, but functionally ensuring that the actual result is the opposite, but morally that's pretty gross.\n \nreply"
    ],
    "link": "https://wpengine.com/wp-content/uploads/2024/10/Complaint-WP-Engine-v-Automattic-et-al-with-Exhibit.pdf",
    "first_paragraph": ""
  },
  {
    "title": "AMD GPU Inference (github.com/slashml)",
    "points": 166,
    "submitter": "fazkan",
    "submit_time": "2024-10-02T07:16:10.000000Z",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=41718030",
    "comments": [
      "For inference, if you have a supported card (or probably architecture if you are on Linux and can use HSA_OVERRIDE_GFX_VERSION), then  you can probably run anything with (upstream) PyTorch and transformers. Also, compiling llama.cpp is has been pretty trouble-free for me for at least a year.(If you are on Windows, there is usually a win-hip binary of llama.cpp in the project's releases or if things totally refuse to work, you can use the Vulkan build as a (less performant) fallback).Having more options can't hurt, but ROCm 5.4.2 is almost 2 years old, and things have come a long way since then, so I'm curious about this being published freshly today, in October 2024.BTW, I recently went through and updated my compatibility doc (focused on RDNA3) w/ ROCm 6.2 for those interested. A lot has changed just in the past few months (upstream bitsandbytes, upstream xformers, and Triton-based Flash Attention): https://llm-tracker.info/howto/AMD-GPUs\n \nreply",
      "It would be great if you included a section on running with Docker on Linux. The only one that worked out of the box was Ollama, and it had an example.\nhttps://github.com/ollama/ollama/blob/main/docs/docker.mdhas a docker image but no examples to run it\nhttps://github.com/ggerganov/llama.cpp/blob/master/docs/dock...has a docker image but no examples to run it\nhttps://github.com/LostRuins/koboldcpp?tab=readme-ov-file#do...docker image was broken for me on 7800xt running rhel9\nhttps://github.com/Atinoda/text-generation-webui-docker\n \nreply",
      "good feedback thanks, would you be able to open an issue\n \nreply",
      "this repo?\nhttps://github.com/AUGMXNT/llm-tracker.info-vault/issues\n \nreply",
      "I think fazkan was confused about which repo you were talking about. For the llm-tracker doc, that's something I maintain. It's based on stuff I test but if you want to submit a PR or issue w/ info in a way that I can verify then I'm happy to add a Docker section.\n \nreply",
      "haha, I was a bit confused, but I was referring to this one https://github.com/slashml/amd_inference. But the comment applies to other repos as well, do open issues in them, helps the maintainers prioritize features.\n \nreply",
      "i also have been playing with inference on the amd 7900xtx, and i agree. there are no hoops to jump through these days. just make sure to install the rocm version of torch (if using a1111 or similar, don't trust requirements.txt), as shown clearly on the pytorch homepage. obsidian is a similar story. hip is straightforward, at least on arch and ubuntu (fedora still requires some twiddling, though). i didn't realize xformers is also functional! that's good news.\n \nreply",
      "related: https://www.nonbios.ai/post/deploying-large-405b-models-in-f...tldr: uses the latest rocm 6.2 to run full precision inference for llama 405b on a single node 8 x MI300x AMD GPUHow mature do you think Rocm 6.2-AMD stack is compared to Nvidia ?\n \nreply",
      "this uses vllm?\n \nreply",
      "The rise of generated slop ml libraries is staggering.This library is 50% print statements. And where it does branch, it doesn't even need to.Defines two environment variables and sets two flags on torch.\n \nreply"
    ],
    "link": "https://github.com/slashml/amd_inference",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n\nThis project provides a Docker-based inference engine for running Large Language Models (LLMs) on AMD GPUs. It's designed to work with models from Hugging Face, with a focus on the LLaMA model family.Clone this repository:Make the run script executable:Run the inference engine with a specified model and prompt:Replace \"meta-llama/Llama-2-7b-chat-hf\" with the Hugging Face model you want to use, and provide your own prompt.The project includes an Aptfile that lists the necessary ROCm packages to be installed in the Docker container. This ensures that all required ROCm drivers and libraries are available for the inference engine to utilize the AMD GPU effectively.The run-docker-amd.sh script builds the Docker image automatically. If you want to build it manually, use:The run-docker-amd.sh script handles running the container with the necessar"
  },
  {
    "title": "The bunkbed conjecture is false (igorpak.wordpress.com)",
    "points": 125,
    "submitter": "surprisetalk",
    "submit_time": "2024-10-02T15:01:08.000000Z",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=41721318",
    "comments": [
      "This is an interesting case of a conjecture holding true for small objects but breaking down for huge ones, without specifically adding that size in somehow.Sometimes we tend to have this intuition that if a rule applies to all low numbers, than it must apply to all numbers, that there can't be some huge number after which it breaks down (unless of course it explicitly includes that huge number, such as the rule \"all numbers are smaller than a billion billion billion\").This is such a powerful intuition, even though it's obviously wrong, that rules that break it are even seen as a problem. For example there is the so-called \"hierarchy problem\" in physics, which states something like \"there is no reason why the weak force is so much stronger than gravity\". As if 2 times as strong is somehow fundamentally different than it being 10^24 times as strong from a mathematical perspective. And this has ended up being called a major problem with the standard model, even though it's completely normal from a mathematical perspective.\n \nreply",
      "Many examples of conjectures true for all n, until a very large one is eventually found : https://mathoverflow.net/questions/15444/examples-of-eventua...\n \nreply",
      "It is helpful that the post links to the Wikipedia page: https://en.wikipedia.org/wiki/Bunkbed_conjectureReading that and then rereading the post, it all made a whole more sense: why the conjecture is intuitively appealing and why the computational approach doesn't readily result in a proof.\n \nreply",
      "I don't know. To me it sounds like it's obvious the conjecture doesn't hold. if you have a path in the upper bunk that gets broken you are screwed but if that path is broken you have the option to switch to path in the lower bunk at ANY moment. So you have n+1/n higher chance of a break but n-1 ways how to avoid it\n \nreply",
      "Intuitively (subjectively) why this argument doesn't work: if you switch to the path in the lower bunk, you can switch to the upper bunk \"at any moment\", regardless of if there is a path which exists on the lower bunk.In this example, a1 is connected to both c1 and c2:  a1    b1 -- c1\n  |     |     |\n  a2 -- b2 -- c2\n\nIf, instead of deleting edges, we assigned a distance d = 1/p, then you'd expect (and probably easily prove) that the distance to the target vertex is at most the distance to its partner in the other bunk. The fact that this intuitive \"problem translation\" doesn't actually translate to probabilities is quite surprising (to me)!\n \nreply",
      "I'm pretty sure you're sampling the \"bedposts\" as well, the upper and lower subgraphs aren't just connected at every node; I understood the rough (and incorrect) intuition to be like:P[nodes in upper bunk connected] > P[nodes in lower bunk connected] * P[sufficient \"bedpost\" edges survive connecting upper and lower]SinceP[nodes in upper bunk connected] = P[nodes in lower bunk connected]And by definitionP[sufficient \"bedpost\" edges survive connecting upper and lower]<1\n \nreply",
      "The conjecture is true for all small graphs that they tried, so if it's \"obviously\" false to you then something went wrong with your intuition somewhere.\n \nreply",
      "I still don't get it.  So you make this graph, with a random number on each edge.  Then you duplicate that graph, stack them like a bunkbed, and connect every lower vertex to the one above it.   Then you delete all edges with a number below some threshold.   Wouldn't the upper and lower graphs still be identical?  Since you had the same edge weights in both?   So the route from any upper node X to any upper node Y should be 1 less than the route length between X and the point beneath Y.What did I miss?\n \nreply",
      "There is no thresholding, you delete edges randomly based on the probability assigned.\n \nreply",
      "Thanks, that's an important distinction.\n \nreply"
    ],
    "link": "https://igorpak.wordpress.com/2024/10/01/the-bunkbed-conjecture-is-false/",
    "first_paragraph": "What follows is an unusual story of perseverance. We start with a conjecture and after some plot twists  end up discussing the meaning of truth. While the title is a spoiler, you might not be able to guess how we got there\u2026The bunkbed conjecture (BBC) is a basic claim about random subgraphs. Start with a finite graph G=(V,E) and consider a product graph G x K2 obtained by connecting the corresponding vertices on levels V(1) and V(2).  Sort of like a bunkbed.  Now consider random subgraphs of a this product graph.  Bunkbed Conjecture:  The probability that vertices u(1) and v(1) are connected is greater or equal than the probability that vertices u(1) and v(2) are connected.In other words, the probability of connecting two vertices on the same level cannot be smaller than when connect vertices on different levels. This is completely obvious, of course! And yet the conjecture this problem defeated several generations of probabilists and remained open until now. For a good reason, of cour"
  },
  {
    "title": "John Wheeler saw the tear in reality (quantamagazine.org)",
    "points": 172,
    "submitter": "rbanffy",
    "submit_time": "2024-09-30T08:58:44.000000Z",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=41694991",
    "comments": [
      "It's interesting we have such receptivity in the HN community here on physicist-proposed metaphysics (yay!), yet in an entirely similar light - an article covering physicist Roger Penrose's 'microtubules' on HN a couple days ago, we get the reflexive \"but experts say this is bunk' treatment.Personally I don't know from Sam on either hypothesis. I'm just wondering for all things seeming equal, when do we get receptivity from the HN community and when to anticipate the knives coming out?\n https://news.ycombinator.com/item?id=41696559\n \nreply",
      "It can be pure chance. Who commented first, who happened to click the article, the time of day it was posted, the style of the website the article was hosted on, etc etc. it\u2019s easy to get sucked into the illusion that the commenting population is a stationary distribution when in fact it might be highly multimodal and each thread is not a representative sample of the overall population.Having said that, your question still stands, I suppose I\u2019m just thinking it ought to be phrased differently? why does one article trigger more engagement than others, and why does one article trigger more engagement with certain subsets of the HN population? (Whereas your phrasing could seem to suggest there are monolithic grand narratives that describe what \u201cThe HN community thinks\u201d)\n \nreply",
      ">chance\nYes I suppose I should find some serenity in the pure chance of things.>monolithicYes it would be unfair of me to interrogate as if the comment-base was a monolithic whole.  So perhaps not monolithic, but still probably manifesting more shared responses to stimuli than the wider population at large. I definitely feel there's a distinct HN 'meta-personality', as I believe another replier re. organelles was alluding to. While forum moderation probably also shapes that to a degree, the meta-personality feels more the result of shared professional technical training (and knowing that others in the community are of like training, very very broadly speaking).\n \nreply",
      "Penroses theories about cognition smell like bunk and I only got a physics undergraduate degree. I\u2019m glad he has found things to do in his old age but there are not a lot of physics departments jumping to put those theories to the test.This isn\u2019t a \u201cboth sides\u201d issue, it\u2019s two separate physicists and two separate theories about different areas of physics.\n \nreply",
      "> it\u2019s two separate physicists and two separate theories about different areas of physics.They're both touching on consciousness.  Wheeler's participatory universe (least several paras of the article) & Penrose's (& coauthor's) microtubules.Penrose was (just days ago) on Theory of Everything talking about whether consciousness affects observation:\nhttps://www.youtube.com/watch?v=HPH-SzWF46w&t=83s (tl;dw: he doesn't think it does.) Later in the same video, he actually comes down pretty hard on the participatory universe, without naming Wheeler or using the word 'participatory' (at least post-editing): https://www.youtube.com/watch?v=HPH-SzWF46w&t=287s\n \nreply",
      "As the other comments point out... most things are dynamical systems that respond to chaos theory (small inputs, big divergence in output). Many of the possible states can be reduced down to two or so poles (e.g. skepticism vs acceptance vs outrage vs indifference in our potential responses)Trying to determine when or why a dynamical system like this goes to a specific state is Sisyphean if I put a word to it.Novelty and memes play a part as well. If skepticism propagates faster around an idea (say Penrose's proposal) you'll get uncritical thinkers parroting. Same thing happens for the acceptance of ideas that often have no basis in reality.\n \nreply",
      "I\u2019ve noticed in round table discussions where everyone is expected to comment, an idea will emerge early and then dominate future responses.Sure, many of us seek acceptance from the group, but also, as an idea gets traction, I think it just gets harder to have an original idea.It\u2019s like trying to remember how a song goes while another one is playing, and I see it on HN threads (like this one!) often.\n \nreply",
      "This is probably one of the better descriptions of forum interaction (mid-size and up - ie past the point where you recognize some meaningful percentage of handles in any given thread)/social media that I have ever read. Much better said than my sibling comment!It does seem like there are often strange attractors (loosely speaking), steady-states, collapse states etc that the heterogenous commenting population display organically.\n \nreply",
      "The real question - which I do not intend to answer - is, \"Are the same HN users who are receptive to the metaphysics here also providing the 'experts disagree' retorts?\" If we were to categorize the different mindsets of HN users and study their reactions, we might be able to treat the whole as an organism and the different groups as organelles. Then we poke it with sticks for science!\n \nreply",
      "Or even bodies without organs\u2026 uh oh, shhh, no Deleuze allowed on here I think!\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/john-wheeler-saw-the-tear-in-reality-20240925/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesSeptember 25, 2024Se\u00f1or Salme for Quanta MagazineContributing WriterSeptember 25, 2024When Johnny Wheeler was 4 years old, splashing in the bathtub in Youngstown, Ohio, he looked up at his mother and asked, \u201cWhat happens when you get to the end of things?\u201d\u00a0The question would haunt him for the rest of his life. What happens when you get to the bottom of space? What happens when you get to the edge of time? It would lead him to suggest that space-time can\u2019t be the true fabric of the universe. It would compel him, even in his final days, to search for some deeper reality beneath space-time and to wonder whether, somehow, that reality loops back to us.John Archibald Wheeler was a physicist\u2019s ph"
  },
  {
    "title": "A Tour of Hell \u2013 Shell scripting Haskell dialect (chrisdone.com)",
    "points": 73,
    "submitter": "kreyenborgi",
    "submit_time": "2024-09-30T08:22:12.000000Z",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41694767",
    "comments": [
      "Why are there no examples with \"#!/usr/bin/env ghc\" at the top?It's not a shell script without the Linux incantation stanza.. for reals.  How are you going to get started without the proper boiler plate?\n \nreply",
      "Interesting but not a great piece for anyone not into functional language design. A pretty deep dive into the \"how\" while completely ignoring the \"why.\"\n \nreply",
      "Or indeed the \"what\".  Did he ever show an example of what the shell scripts look like?  I couldn't see it.\n \nreply",
      "The first link takes you to the home page, which links to examples; probably a better starting point.https://chrisdone.github.io/hell\n \nreply",
      "Chris discusses the rationale in his blog post at https://chrisdone.com/posts/hell/\n \nreply",
      "Thanks for this! I read that but I'm still not convinced. Quote:They lean far too heavily on sub processes to do basic things.I thought this was the whole point of a unix scripting language! Most of the scripts I'm writing are not interactive REPLs or string-parsers, they're glue code for batch-invoking commands on files. Stuff like converting a bunch of FLAC files into MP3 with lame or avi video files into mkv with ffmpeg.What bash offers me is very terse command invocation and powerful filename globbing, including regexp substitution. Scripts like this are generally not intended to be used more than once or twice, and so a type system like Haskell provides is irrelevant here. If you're writing something that's going to be iterated on and maintained for years then you're writing an application, not a script.\n \nreply",
      "As a haskeller, and shell scripter, I find this a refreshing and exciting experiment. \nMuch of the goodness of haskell, but with a much tighter focus and smaller scope. \nNo imports, language pragmas, packages or build tools needed; \nall of the building blocks listed on one short page, https://chrisdone.github.io/hell/api.\nMore platform independent, robust, and regular than shell.\nPotentially a nice learning language / stepping stone to haskell itself.It's quite verbose right now, and I don't see much networking API yet, but it's just starting. I could see it easily growing into something very nice.\n \nreply",
      "How was this page generated? I have a marp presentation (https://github.com/jonocodes/awesome-keyboards) that I would like to have shown on a single page like this with the notes expanded.\n \nreply",
      "I really like this page, with slides on the left and blog on the right.\n \nreply",
      "I've wanted many things from shell but never to write Haskell in Shell. This turned something relatively naturally expressible into something so complex that requires type theory\n \nreply"
    ],
    "link": "https://chrisdone.com/posts/tour-of-hell/",
    "first_paragraph": ""
  },
  {
    "title": "Newton's financial misadventures in the South Sea Bubble (2018) (royalsocietypublishing.org)",
    "points": 48,
    "submitter": "cs702",
    "submit_time": "2024-10-02T17:54:58.000000Z",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=41723288",
    "comments": [
      "For a broader story, including Newtons running of the Royal Mint, check out:MONEY FOR NOTHINGTHE SCIENTISTS, FRAUDSTERS, AND CORRUPT POLITICIANS WHO REINVENTED MONEY, PANICKED A NATION, AND MADE THE WORLD RICHhttps://www.kirkusreviews.com/book-reviews/thomas-levenson/m...\n \nreply",
      "For an lengthy but amazing alternate-reality account of same (and much... much more), check out Neal Stephenson's Baroque Cycle\n \nreply",
      "The audiobooks are pretty well narrated too, great for anyone who needs 160 hours of audio\n \nreply",
      "The David Liss historical novel\n'A Conspiracy of Paper' was pretty nice.\nhttps://en.wikipedia.org/wiki/A_Conspiracy_of_Paper\n \nreply",
      "Thanks - I'll check it out.Shockingly, this is free on Audible!\n \nreply",
      "For a more rigorous treatment, try Paul Wiltmott's (a famous quant) The Money Formulahttps://www.amazon.com/Money-Formula-Finance-Science-Mathema...\n \nreply",
      "Couple of previous discussions from 2018 and 2019https://news.ycombinator.com/item?id=16245284https://news.ycombinator.com/item?id=21007541\n \nreply",
      "Thanks! Macroexpanded:Isaac Newton's Financial Misadventures in the South Sea Bubble - https://news.ycombinator.com/item?id=29032752 - Oct 2021 (1 comment)Newton's Financial Misadventures in the South Sea Bubble - https://news.ycombinator.com/item?id=21007541 - Sept 2019 (15 comments)Newton\u2019s Financial Misadventures in the South Sea Bubble [pdf] - https://news.ycombinator.com/item?id=16245284 - Jan 2018 (35 comments)\n \nreply",
      "I took this PDF and used Notebook LM (front-page HN the other day) to make a podcast out of this story to see how it did:https://www.dropbox.com/scl/fi/hftl66dw3z8cg5ocjw9nx/newton-...\n \nreply",
      "One of the things I found interesting recently was that the \"South Sea\" part of the name refers to the South Atlantic. I'd always inferred that the \"South Sea\" was the South Pacific.I suppose the term \"South Pacific\" is ingrained in the language, so naturally my mind takes me there with \"South Sea\".Anyway, just one of those long-held beliefs that turns out yo be false.\n \nreply"
    ],
    "link": "https://royalsocietypublishing.org/doi/10.1098/rsnr.2018.0018",
    "first_paragraph": ""
  },
  {
    "title": "Hierarchical Navigable Small World: a scalable nearest neighbor search (github.com/brtholomy)",
    "points": 62,
    "submitter": "wilsonzlin",
    "submit_time": "2024-09-30T07:56:14.000000Z",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41694631",
    "comments": [
      "HNSW was the first approximate nearest neighbor search algorithm I encountered. There are others that are useful in different contexts (i.e. depending on your data size and available memory). And you can combine them sometimes. This video is a really awesome overview of them:https://youtu.be/SKrHs03i08Q\n \nreply",
      "What really made HNSW click for me was when someone described it as a \"skiplist graph\". It really does seem to share a lot of the same properties and intuition as a simple skiplist, where descending levels corresponds to finer-grained navigation through the space.A couple of other thoughts with this perspective: \n- if a drawing of a skiplist is 2D, HNSW seems to be a 3D generalization. It makes me wonder if you could apply an HNSW-like scheme for a traditional relational database index (maybe a multicolumn index?). \n- if a skiplist is a probabilistic alternative to a B+-tree, what's HNSW a probabilistic alternative to?One thing that still mystifies me is how in the context of vector indexing, the HNSW seems to \"bootstrap\" itself by using itself to find the neighbors of a newly-inserted point. It's not clear to me why that doesn't diverge to some garbage results as the index grows.\n \nreply",
      "Interesting read, I worked on graph theory for a while some long time ago and did not even know some of these terminologies.\n \nreply"
    ],
    "link": "https://github.com/brtholomy/hnsw/blob/master/README.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          by Bartholomy\"Hierarchical Navigable Small World\" (HNSW): an intriguing mouthful, designating a dense bouquet of concepts developed in the last 70 years in sociology, graph theory, and algorithmic science. In this brief tutorial, we'll examine these concepts carefully and attempt to solidify our understanding with proof-of-concept code and as many visualizations as possible.The first thing to understand about HNSW is that it's primarily an optimized data structure, not an algorithm. Actually the algorithm used with these structures is remarkably simple: a greedy search which simply looks among all current candidates for the closest target value.What's brilliant about HNSW therefore is not its search routine, but its optimized structure for a decentralized similarity search using a simple greedy traversal. This makes it ideal as the backbone "
  },
  {
    "title": "Tracking the historical events that lead to the interweaving of knowledge (2021) (acm.org)",
    "points": 16,
    "submitter": "punkpeye",
    "submit_time": "2024-09-29T21:42:35.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41690939",
    "comments": [
      "\u201cHow \u2018knowledge graphs\u2019 became a thing in CS,\u201d more like.Needless to say, perhaps, but that usage of \u2018knowledge\u2019 is domain-specific, not something a non-CS person would recognize as or admit to be \u2018knowledge.\u2019\n \nreply",
      "Semiotic graph may be a better term?\n \nreply"
    ],
    "link": "https://cacm.acm.org/research/knowledge-graphs/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: RelayBeam \u2013 A new way of messaging using Ports (relaybeam.com)",
    "points": 9,
    "submitter": "supritgandhi",
    "submit_time": "2024-09-28T12:41:01.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://relaybeam.com/about",
    "first_paragraph": ""
  },
  {
    "title": "Meticulous (YC S21) is hiring to eliminate UI tests",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-10-02T21:03:15.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=41724950",
    "first_paragraph": ""
  },
  {
    "title": "Hash Ordering and Hyrum's Law (eaftan.github.io)",
    "points": 45,
    "submitter": "ColinWright",
    "submit_time": "2024-09-27T17:27:16.000000Z",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41673295",
    "comments": [
      "(from Feb 2021)Some of the JDK's unmodifiable collections, such as those from `Set.of()` and `Map.of()`, also randomize iteration order. At the time they were added, Go and Python also randomized iteration order. However, more recently, Python moved away from randomization. Early in the Python 3.x releases, dict iteration order was randomized. In 3.6, iteration order was insertion order, but only as an implementation detail. In 3.7, this was elevated to a guarantee.https://docs.python.org/3/library/stdtypes.html#dict(search for \"dictionary order\")There are occasional complaints about Java's unmodifiable collections' randomized order, as it can occasionally cause intermittent test failures or even failures in production. However, the advantage of the randomized order is that we've been able to reorganize the internal implementations of these data structures -- twice -- without worrying about compatibility problems caused by changing the ordering. Historically this has been a problem with other structures such as `HashMap`. Even though HashMap's order isn't guaranteed, it's predictable and stable, and changing its ordering has definitely flushed out bugs.\n \nreply",
      "https://www.youtube.com/watch?v=ncHmEUmJZf4Is a fun presentation by Matthew Kulukundis (designer of Google's Hash Table) with Hyrum Wright offering objections from the crowd (Hyrum's law) about the design and rollout of it at Google\n \nreply",
      "What's the advantage of specifying it as random over specifying it as sequential in some way? Aren't both just specifying a behavior, where one behavior is potentially more useful than the other? I guess I understand the principled point that a set of hash keys is not an array. But it seems like more complexity than is necessary, and even possible to fall victim to Hyrum's law besides\u2026 you can imagine someone using random hash ordering to implicitly randomize something without needing to call an RNG explicitly.It seems like the most principled approach might be an re-specification of the data structure: why is \"iteration\" even possible over a hash table? Shouldn't the keys be specified as a \"set\" on which only set-appropriate operations like map can be performed?\n \nreply",
      "One advantage to randomization, and why various languages did it in the first place, is that it prevents miscreants from DoSing your service if they know its implementation.Say you're operating a service and you share its source on GitHub such that anyone can see it. Your language doesn't randomize hash values. Hashes are O(1), right? Well, not if a clever attacker can send you a set of values where they know each one will hash into the same bucket. The you end up with like 9 empty buckets and 1 with 100,000 items in it. Oops!Old Python pre-randomization had a dict.items() method that would yield all the keys in order, conceptually kind of like:  for bucket in self._buckets:\n      for item in bucket:\n          yield item\n\nThe order of those buckets would be repeatable between runs, so bucket foo would always come first, then bucket bar. Then Python added hash randomization so that the resulting hash key was something like hash(salt+key) instead of just hash(key). Now there's no way to tell in advance which bucket an item would get filed into, and the buckets would end up more or less balanced in size.Newer Pythons (since 3.6? 3.7?) do something altogether different, and I can't explain exactly how their ordered dicts work, except to say I sat through a presentation on them and thought it was freaking genius even if I could re-implement it myself without sitting down with their docs.\n \nreply",
      "> and I can't explain exactly how their ordered dicts workTraditionally you simply use a doubly linked list approach on the entries (each entry maintains two additional references to the previous and next entry) for that like LinkedHashMap: https://docs.oracle.com/javase//8/docs/api/java/util/LinkedH...https://github.com/openjdk-mirror/jdk7u-jdk/blob/master/src/...Which is also what Python seems to be doing: https://stackoverflow.com/a/34496644It's fairly intuitive.Do their new default (now also ordered?) dics do this differently?\n \nreply",
      "Note that OrderedDict is an implementation in Python. CPython's dict has a different implementation. There's more about it at https://docs.python.org/3.6/whatsnew/3.6.html#new-dict-imple... and https://mail.python.org/pipermail/python-dev/2012-December/1... .\n \nreply",
      "I think removing methods from the Hashmap was not in scope for their work - they were working on the JDK, and presumably didn't have the bandwidth to patch every single Java library used at Google to use set-based methods instead of iteration-based.Also, I think in practice you'll find you want to extract items from a set in some order, so you need some kind of transformation from set->list. e.g: you want to print them out.Edit: Forgot to address your main question. If the specification requires a specific ordering, the implementation is forever bound to do that, even if other implementations would be more efficient/secure/other-desirable-properties. By introducing randomness, you reduce the risk of people accidentally relying on unspecified behavior, and are more able to change your implementation later.\n \nreply",
      "One solution could be adding a `sort` argument (which takes a function that compares two `<T>` items and returns `true` or `false` depending on their order) to all functions on unordered collections of `<T>` items in which an order must be chosen, or requiring that the items in such collections implement a `TotalOrder` interface or something similar. This isn't very ergonomic in languages that don't have an equivalent of Traits or typeclasses though. In languages which permit side effects, this would include any functions that iterate over the items in an unordered collection.\n \nreply",
      "Alternatively, maintain backward compatibility as much as possible. Function overloading might be too clever. Extra verbosity in exchange for clarity might be a worthwhile tradeoff. WET is acceptable in these scenarios.\n \nreply",
      "Interesting note: the JDK deliberately randomizes iteration order of certain immutable sets and maps (https://github.com/openjdk/jdk/blob/jdk-23%2B37/src/java.bas...).\n \nreply"
    ],
    "link": "https://eaftan.github.io/hash-ordering/",
    "first_paragraph": "Developer tools at GitHub.  Previously Java at Google.  Views are my own.A Google engineer named Hyrum Wright made an observation that came to\nbe known as Hyrum\u2019s Law:With a sufficient number of users of an API, it does not matter what you promise in the contract:\nall observable behaviors of your system will be depended on by somebody.What are the consequences of Hyrum\u2019s Law? Well, it means that anyone trying to do a large-scale\nmigration is going to tear their hair out discovering that their seemingly simple migration is way\nharder than expected, and that despite putting that giant warning in your docs not to depend on some\nimplementation-specifc behavior, your clients are going to depend on it anyway.Can\u2019t you just break them? They\u2019re violating the spec!No, you can\u2019t break them. Let\u2019s consider a concrete example \u2013 hash iteration order.Generally, when you iterate over the keys and values in a hash table, the iteration order is\nunspecified and implementation dependent. For example, the"
  },
  {
    "title": "Keynes on the influence of furniture on love (adamtooze.substack.com)",
    "points": 49,
    "submitter": "magnifique",
    "submit_time": "2024-10-02T00:00:06.000000Z",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41715774",
    "comments": [
      "I once met somebody on the train who lives in the Bay Area and told me that her dating experiences in the area with tech guys included more than one \"guy who just has a mattress on the floor\". If there's any takeaway from the 15 seconds you spent looking at this article and the comments, you should buy a bed frame. Any bedframe. Just take the mattress off the floor.If you're on this site, you can afford one. Extra credit: the bottom of your mattress won't be all gross.\n \nreply",
      "If you live in Japan or Korea it's normal to sleep on the floor. In Japan you have a room covered in tatami mats. At night you pull out the futon from the closet and sleep on it. You then put it back in the closet in the morning.https://www.google.com/search?q=%E5%B8%83%E5%9B%A3&udm=2Often you pull out a small table (kotatsu) and put it in the center of the room in the day.https://www.google.com/search?q=%E3%81%93%E3%81%9F%E3%81%A4&...Korea is the same except tatami mats are less common.Of course now-a-days, lots of Japanese and Koreans sleep on beds but futon are not uncommon.\n \nreply",
      "The other side of that coin is that if she can't tolerate mattress on floor to access tech money then maybe the other guy dodged a bullet too depending on what he's after.  I found myself turning down the class intentionally a lot because my current income/wealth level exceeds the norm for my background at my age and I don't want to live with someone who doesn't share my social/cultural norms.It reminds me of a passage in IIRC it was Keith Richards biography (maybe not him, but definitely one of the Rolling Stones) where he was flabbergast at what his wife (he married up in some ways) spent on a chandelier.  Not that he couldn't afford it, but he just wasn't from the kind of background where you spend a bunch of money on a chandelier and was rather ticked off by the expense.All that said, a f-ing bed frame seems like a pretty stupid thing to skimp on.  You can get them, any pretty much every other piece of furniture, for free on CL or FBMP if you're not picky and don't mind waiting a big for something decent near you.\n \nreply",
      "We had one such case at our startup in San Francisco. Several coworkers came together to get him a bed frame as a group birthday gift.\n \nreply",
      "By bizarre coincidence, I actually lost a sexual partner right when I bought my current bed frame.\n \nreply",
      "Steve Jobs famously started out like that, a mattress and a MASSIVE stereo.Maybe they try to emulate their hero?\n \nreply",
      "It's like only wearing grey t-shirts thinking it'll make you the next Zuckerberg...\n \nreply",
      "I wouldn't suggest people \"hack\" self-care/hygeine habits like nesting to avoid turning off some prospective date or hookup.The lady on the train isn't literally getting turned off by the mattress resting on the floor. They're getting turned off because the image they see represents someone deeply alienated from the instinctive desire to attend to one's space (nest).The one neat trick of putting a mattress on the frame doesn't change that. It just leaves the visitor more lacking for words to describe what's unsettling them.If you're just a 22 year old tech bro all in on your career and are proud of your aescetism, live as sparsely as you want.At some point, though, you may find that taking an interest in your surroundings makes you feel better and gives you more resiliency, and that people respond positively to what that represents.But don't bother cheating your way there. It will must confuse you when somebody shows up and doesn't fall for the hack.\n \nreply",
      "Excellent point. And it doesn\u2019t need to be much. If a person is really minimalistic, even a single piece of good-taste furniture would suffice.\n \nreply",
      "Tired: mattress on floorWired: Eames chair next to mattress on floor.Thank you both for the Wednesday laughs.\n \nreply"
    ],
    "link": "https://adamtooze.substack.com/p/chartbook-322-can-we-consume-our",
    "first_paragraph": ""
  },
  {
    "title": "William Cowper and the Age of the Earth [pdf] (2019) (charlespetzold.com)",
    "points": 13,
    "submitter": "hwayne",
    "submit_time": "2024-10-02T20:50:06.000000Z",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=41724849",
    "comments": [
      "As much as I like poetry, why do we attribute to a poet that which we owe to a most observant and introspective canal digger who felt free to question dogma and received wisdom?William Smith deserves so much of our respect. Cf, e.g., https://en.m.wikipedia.org/wiki/The_Map_that_Changed_the_Wor..., which summarizes the most excellent book.\n \nreply",
      "We don\u2019t. The article explains and credits the scientific research that the poet is referring to. And to answer your question a second way: because that research came decades earlier than Smith\u2019s work.\n \nreply",
      "Why did people assume that strata were deposited over eons and represent different ages? Many of these layers can be viewed in the Grand Canyon, and there is a notable lack of erosion between them. As I see it, these paraconformities are a strong evidence that there were not large gaps of time between the strata - they must have been laid down rapidly over a relatively short period (e.g. by a great flood).\n \nreply",
      "You could start with https://en.wikipedia.org/wiki/Stratigraphy and go from there.For the upper bound: https://en.wikipedia.org/wiki/Clair_Cameron_Patterson#Measur...\n \nreply",
      "TalkOrigins.org has many detailed rebuttals to creationist lies. This one hybridizes two topics, or maybe it\u2019s a garbled version of CD210.Grand Canyon:\nhttps://www.talkorigins.org/indexcc/CH/CH581.html\nhttps://www.talkorigins.org/faqs/icr-science.html\nhttps://www.talkorigins.org/indexcc/CD/CD210.htmlErosion:\nhttps://www.talkorigins.org/indexcc/CD/CD610.html\nhttps://www.talkorigins.org/indexcc/CD/CD620.html\n \nreply",
      "Slightly OT, but Cowper street in Palo Alto is named after William Cowper. So a fun shibboleth (and as OP points out) is that the name is pronounced KOO-per.\n \nreply"
    ],
    "link": "https://www.charlespetzold.com/essays/WilliamCowperAndTheAgeOfTheEarth.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Serialization Is the Secret (zachdaniel.dev)",
    "points": 258,
    "submitter": "borromakot",
    "submit_time": "2024-09-29T13:26:47.000000Z",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=41687240",
    "comments": [
      "I'd note that 'immutability everywhere' isn't the only way to solve the issue of uncontrolled observation of mutations, despite that issue often being cited as a justification. You can also design a language to just directly enforce static restrictions on who may mutate a referenced value and when. Rust with its aliasing rules is easily the most famous implementation of this, but other languages have continued to experiment with this idea.The big benefit is that you can still have all the usual optimizations and mental simplicity that depend on non-observability, while also not having to contort the program into using immutable data structures for everything, alongside the necessary control flow to pass them around. (That isn't to say that they don't have their use cases in a mutable language, especially around cross-thread data structures, but that they aren't needed nearly as frequently in ordinary code.)\n \nreply",
      "I think having some sort of structured mutability is a very, very good idea. Look at Clojure's atoms and transient data-structures for some other ways that this has been done. There's probably others, I'd love to see more examples!\n \nreply",
      "The historically-ironic thing to me is that Erlang/BEAM brushed up against the idea and just didn't quite get it. What's important to the properties that Erlang maintains is that actors can't reach out and directly modify other actor's values. You have to send messages. It is sufficient to maintain this properly that you can't send references in messages, and it is sufficient to maintain that property to simply not have references, which Erlang and BEAM do not. Full immutability is sufficient but not necessary.Erlang was a hair's breadth away from having mutation contained within the actor's variable space, with no external mutation, which for the time would have been quite revolutionary. Certainly Rust's mutation control is much richer, but Rust came a lot later, and at least based on its current compile performance, wasn't even on the table in the late 1990s.But the sort of understanding of mutability explained in the original post was not generally understood. Immutability was not a brand new concept chronologically, but if you define the newness of a computer science concept as the integration of its usage over time, it was still pretty new by that metric; it had been bouncing around the literature for a long time but there weren't very many programming languages that used it at the time. (And especially if you prorate \"languages\" by \"how easy it is to write practical programs\".)Elixir does a reasonable job of recovering it from the programmer's perspective, but I think an Erlang/BEAM that just embraced mutability within an actor probably would have done incrementally better in the programming language market.\n \nreply",
      "I think you're right that \"interior immutability\" of actors isn't really necessary to the programming model that you get from requiring message passing between actors.However, interior immutability is not without its benefits. It enables a very simple GC. GC is easily done per-actor because each actor has independent, exclusive, access to its own memory. But the per-actor GC is very simple because all references are necessarily backwards in time, because there's no way to update a reference. With this, it's very simple to make a copying GC that copies any active references in order; there's no need for loop checking, because loops are structurally impossible.I don't know that this was the intent of requiring immutability, but it's a nice result that pops out. Today, maybe you could pull in an advanced GC from somewhere else that already successfully manages mutable data, but these were not always available.Of course, it should be noted that BEAM isn't entirely immutable. Sometimes it mutates things when it knows it can get away with it; I believe tuples can be updated in some circumstances when it's clear the old tuple would not be used after the new one is created. The process dictionary is direct mutable data. And  BIFs, NIFs, and drivers aren't held to strict immutability rules either, ets has interior mutability, for example.\n \nreply",
      "\"Of course, it should be noted that BEAM isn't entirely immutable.\"Mutability is relative to the layer you're looking at. BEAM is, of course, completely mutable from top to bottom because it is constantly mutating RAM, except, of course, that's not really a helpful way of looking at it, because at the layer of abstraction you program at values are immutable. Mutatable programs can be written in terms of immutable abstractions with a well-known at-most O(n log n) penalty, and immutable programs can be written on a mutable substrate by being very careful never to visibly violate the abstraction of immutability, which is good since there is (effectively for the purposes of this conversation) no such thing as \"immutable RAM\". (That is, yes, I'm aware of WORM as a category of storage, but it's not what this conversation is about.)\n \nreply",
      "IIRC, Rust's idea of controlled mutability originally came directly from the Erlang idea of immutable messages between tasks. Certainly, in the classic \"Project Servo\" presentation [0], we can see that \"no shared mutable state\" refers specifically to sharing between different tasks. I think it was pretty early on in the project that the idea evolved into the fine-grained aliasing rules. Meanwhile, the lightweight tasks stuck around until soon before 1.0 [1], when they were abandoned in the standard library, to be later reintroduced by the async runtimes.[0] http://venge.net/graydon/talks/intro-talk-2.pdf[1] https://rust-lang.github.io/rfcs/0230-remove-runtime.html\n \nreply",
      "I have mixed feelings about rust\u2019s async story, but it is really nice having good historical documentation like this.Thanks for the links!\n \nreply",
      "> What's important to the properties that Erlang maintains is that actors can't reach out and directly modify other actor's values. You have to send messages.I just cannot make this mental leap for whatever reason.How does 'directly modify' relate to immutability?  (I was sold the lie about using setters in OO a while back, which is also a way to prevent direct modification.)\n \nreply",
      "So, this is something I think we've learned since the 1990s as a community, and, well, it's still not widely understood but: The core reason mutability is bad is not the mutation, it is \"unexpected\" mutation. I scare quote that, because that word is doing a lot of heavy lifting, and I will not exactly 100% nail down what that means in this post, but bear with me and give me some grace.From a the perspective of \"mutability\", how dangerous is this Python code?    x = 1\n    x = 2\n    print(x)\n\nNormally little snippets like this should be understood as distilled examples of a general trend, but in this case I mean literally three lines. And the answer is, obviously, not at all. At least from the perspective of understanding what is going on. A later programmer reading this probably has questions about why the code is written that way, but the what is well in hand.As the distance between the two assignments scales up, it becomes progressively more difficult to understand the what. Probably everyone who has been in the field for a few years has at some point encountered the Big Ball Of Mud function, that just goes on and on, assigning to this and assigning to that and rewriting variables with wild abandon. Mutability makes the \"what\" of such functions harder.Progressing up, consider:    x = [1]\n    someFunction(x)\n    print(x)\n\nIn Python, the list is mutable; if someFunction appends to it, it will be mutated. Now to understand the \"what\" of this code you have to follow in to someFunction. In an immutable language you don't. You still need to know what is coming out of it, of course, but you can look at that code and know it prints \"[1]\".However, this is still at least all in one process. As code scales up, mutation does make things harder to understand, and it can become hard enough to render the entire code base pathologically difficult to understand, but at least it's not as bad as this next thing.Concurrency is when mutation just blows up and becomes impossible for humans to deal with. Consider:   x = [1]\n   print(x)\n\nIn a concurrent environment where another thread may be mutating x, the answer to the question \"what does the print actually print?\" is \"Well, anything, really.\" If another thread can reach in and \"directly\" mutate x, at nondeterministic points in your code's execution, well, my personal assertion is nobody can work that way in practice. How do you work with a programming language where the previous code example could do anything, and it will do it nondeterministically? You can't. You need to do something to contain the mutability.The Erlang solution is, there is literally no way to express one actor reaching in to another actor's space and changing something. In Python, the x was a mutable reference that could be passed around to multiple threads, and they all could take a crack at mutating it, and they'd all see each other's mutations. In languages with pointers, you can do that by sharing pointers; every thread with a pointer has the ability to write through the pointer and the result is visible to all users. There's no way to do that in Erlang. You can't express \"here's the address of this integer\" or \"here's a reference to this integer\" or anything like that. You can only send concrete terms between actors.Erlang pairs this with all values being immutable. (Elixir, sitting on top of BEAM, also has immutable values, they just allow rebinding variables to soften the inconvenience, but under the hood, everything's still immutable.) But this is overkill. It would be fine for an Erlang actor to be able to do the equivalent of the first example I wrote, as long as nobody else could come in and change the variable unexpectedly before the print runs. Erlang actors tend to end up being relatively small, too, so it isn't even all that hard to avoid having thousands of variables in a single context. A lot of Erlang actors have a dozen or two variables tops, being modified in very stereotypical manners through the gen_* interfaces, so having in-actor truly mutable variables would probably have made the language generally easier to understand and code in.In the case of OO, the \"direct mutation\" problem is related to the fact that you don't have these actor barriers within the system, so as a system scales up, this thing \"way over there\" can end up modifying an object's value, and it becomes very difficult over time to deal with the fact that when you operate that way, the responsibility for maintaining the properties of an object is distributed over the entire program. Technically, though, I wouldn't necessarily chalk this up to \"mutability\"; even in an immutable environment distributing responsibility for maintaining an object's properties over the entire program is both possible and a bad idea. You can well-encapsulated mutation-based objects and poorly-encapsulated immutable values. I'd concede the latter is harder than the former, as the affordances of an imperative system seems to beg you to make that mistake, but it's certainly possible to accidentally distribute responsibilities incorrectly in an immutable system; immutability is certainly not a superset of encapsulation or anything like that. So I'd class that as part of what I mentioned in this post before I mentioned concurrency. The sheer size of a complex mutation-based program can make it too hard to track what is happening where and why.Once you get used to writing idiomatic Erlang programs, you contain that complexity by writing focused actors. This is more feasible than anyone who hasn't tried thinks, and is one of the big lessons of Erlang that anyone could stand to learn. It is then also relatively easy to take this lesson back to your other programming languages and start writing more self-contained things, either actors running in their own thread, or even \"actors\" that don't get their own thread but still are much more isolated and don't run on the assumption that they can reach out and directly mutate other things willy-nilly. It can be learned as a lesson on its own, but I think one of the reasons that learning a number of languages to some fluency is helpful is that these sorts of lessons can be learned much more quickly when you work in a language that forces you to work in some way you're not used to.\n \nreply",
      "> In the case of OO, the \"direct mutation\" problem is related to the fact that you don't have these actor barriersRight, the OO guys said to use \"encapsulation\" rather than direct mutation.> so as a system scales up, this thing \"way over there\" can end up modifying an object's valueCan you not send a message way over there?\n \nreply"
    ],
    "link": "https://www.zachdaniel.dev/p/serialization-is-the-secret",
    "first_paragraph": ""
  },
  {
    "title": "American WWII bomb explodes at Japanese airport, causing large crater in taxiway (cnn.com)",
    "points": 265,
    "submitter": "impish9208",
    "submit_time": "2024-10-02T15:22:11.000000Z",
    "num_comments": 217,
    "comments_url": "https://news.ycombinator.com/item?id=41721567",
    "comments": [
      "Link to the video - https://www.youtube.com/watch?v=O9GDn-cl1og\n \nreply",
      "It's funny how often these videos are from a camera pointed at a monitor, instead of a direct digital copy.  I assume extracting the actual file is logistically tricky due to both technical and bureaucratic reasons.\n \nreply",
      "The police have a never-ending issue with this when trying to get video from random Temu-quality CCTV recorders at the scene of a crime. I know one defendant who almost got away[1] with a heinous robbery on a mobile phone store because the technician from HQ remoted in to try and get the video off and somehow deleted it instead.[1] the store clerk later remembered the defendant had been drinking a pop when he entered the store and they found the bottle had been left behind, which had his DNA on it, and his DNA was on file\n \nreply",
      "This assumes that it's available in digital form. Knowing Japan, there is a chance this is an analog CCTV\n \nreply",
      "Surely it would still be cleaner to digitize the tape (?) than to point a camera at the screen, wouldn't it?\n \nreply",
      "This was faster\n \nreply",
      "Are there any denoising algorithms that remove Moir\u00e9 patterns?  It would be a welcome addition to the stock iPhone and Android cameras.\n \nreply",
      "If you don\u2019t need it to be perfect it is actually not too difficult. A notch filter could be enough remove most of the pattern provided that you have a good way of guesstimating its frequency\n \nreply",
      "It looks like Adobe Raw added a dedicated moire reduction slider to their denoising features a few years back.  I wonder how it operates.\n \nreply",
      "Being very slightly out of focus would probably be the best solution\n \nreply"
    ],
    "link": "https://www.cnn.com/2024/10/02/travel/wwii-bomb-miyazaki-airport-japan-scli-intl/index.html",
    "first_paragraph": "Follow:\n            An unexploded American bomb from World War II that had been buried at a Japanese airport exploded Wednesday, causing a large crater in a taxiway and the cancellation of more than 80 flights but no injuries, Japanese officials said.\n    \n            Land and Transport Ministry officials said there were no aircraft nearby when the bomb exploded at Miyazaki Airport in southwestern Japan.\n    \n            Officials said an investigation by the Self-Defense Forces and police confirmed that the explosion was caused by a 500-pound US bomb and there was no further danger. They were determining what caused its sudden detonation.\n    \nRelated article\nUnexploded WWII bomb to be defused near German soccer stadium\n\n            A video recorded by a nearby aviation school showed the blast spewing pieces of asphalt into the air like a fountain.\n    \n            Videos broadcast on Japanese television showed a crater in the taxiway reportedly about 7 meters (23 feet) in diameter an"
  },
  {
    "title": "WALDO: Whereabouts Ascertainment for Low-Lying Detectable Objects (github.com/stephansturges)",
    "points": 61,
    "submitter": "jonbaer",
    "submit_time": "2024-10-02T17:56:42.000000Z",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=41723311",
    "comments": [
      "> 'arm/mil' --> this class detects certain types of armored vehicles (very unreliable for now, don't use it yet)Living near a bunch of the military bases, this is what I really need. My suburban defense system keeps mistaking USPS trucks for APCs.I haven\u2019t received any mail for months.Sidenote: what are the export restriction?\n \nreply",
      "that class never really worked and has been removed from the new version of WALDO FYI, it\u2019s not a military thing and shouldn\u2019t be used as such\n \nreply",
      "Ai is going to super charge off grid antigov nuts libertarians?\n \nreply",
      "Not just them. I predict it will extend to all classes of folks who use popular schemas for naming taken from self-isolating social forums.\n \nreply",
      "Giving credit where it's due, this project is almost worth doing just to be able to use that fabulously-well-fit initialism.\n \nreply",
      "this was >50% of the motivation\n \nreply",
      "I'm pretty impressed. I miss the days of cool codenames and initialisms.\n \nreply",
      "I wonder if these achievements are related to war in Ukraine. Do scientists suddenly receive more funding or something? Or it just happens?Is there a non public version with very reliable arm/mil? Is there a version which can reliably distinguish T-80 with and without Z?\n \nreply",
      "A big part is that training image detection is incredibly easy today. YOLO is a great network with reasonably intuitive tooling. Anyone with a set of images can start labeling them, copy-paste a couple lines into a jupyter notebook and make a decent YOLO finetune.The difficulty is in the training data, both acquiring it and labeling it. Hence why the readme of WALDO alludes so much to their semi-synthetic data. That's also why this commercial project is happy to give out the models, but doesn't publish their data pipeline.If you have about 100 satellite images each of T-80s with and without Zs, and a couple other satellite images of other tanks and of landscapes without any tanks you can train a T-80 detecting model in a couple hours. And then spend a couple days in a rabbit hole where you figure out that because in your training set only images with tanks had smoke clouds the model now thinks that smoke clouds are linked to tanks, and you end up making larger and larger data sets with tanks and non-tanks from all angles.\n \nreply",
      "Commercial satellite images?  With somewhere between 30cm and 100cm resolution?  Looking for the letter 'Z' painted on a sidewall of the vehicle?Rough.Medium altitude aerial drone imagery would do it, though - just a matter of building something so cheap & plentiful that it's not worthwhile to shoot down.Who knows, maybe we've given Ukraine the keys to the castle and they're getting a steady stream of 10cm imagery from the NRO.\n \nreply"
    ],
    "link": "https://github.com/stephansturges/WALDO",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Whereabouts Ascertainment for Low-lying Detectable Objects. The SOTA in FOSS AI for drones!\n      Thanks to all participants in the beta! I had over 3000 sign-ups for the\nbeta release and iterated really fast... I hope you'll like the result!I am assuming you have  some experience with deployment of AI systems,\nbut if you have any trouble using this release you can contact me at\nstephan.sturges at gmailWHAT IS WALDO?WALDO is a detection AI model, based on a large YOLO-v7 backbone and my own\nsynthetic data pipeline. The basic model shared here, which is the only\none published as FOSS at the moment, is capable of detecting these classes\nof items in overhead images ranging in altitude from about 30 feet to\nsatellite imagery with a resolution of 50cm per pixel or better.Well trained classes:WHERE IS WALDO?Due to the size of the model fi"
  },
  {
    "title": "Show HN: Kameo \u2013 Fault-tolerant async actors built on Tokio (github.com/tqwewe)",
    "points": 67,
    "submitter": "tqwewe",
    "submit_time": "2024-10-02T18:22:10.000000Z",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41723569",
    "comments": [
      "Hi - any documentation regarding actor registration? Is there a conventional way to inform a remote actor about a new actor? Would this be sent in a message? How does the actor.register('name') work? Maybe could be a useful addition to the documentation. Thanks.\n \nreply",
      "Looks very cool. Is there any documentation on how it works for communication over a network? I see the remote/swarm section but is there an overview somewhere?\n \nreply",
      "Looks good, it would be great to see more examples in the docs.\n \nreply",
      "Is this actually distributed?  I see no evidence that this can be used in conjunction with even ipc with builtin features.\n \nreply",
      "Check the examples folder.\n \nreply",
      "https://github.com/tqwewe/kameo/blob/main/examples/remote.rs    // Bootstrap the actor swarm\n    if is_host {\n        ActorSwarm::bootstrap()?\n            .listen_on(\"/ip4/0.0.0.0/udp/8020/quic-v1\".parse()?)\n            .await?;\n    } else {\n        ActorSwarm::bootstrap()?.dial(\n            DialOpts::unknown_peer_id()\n                .address(\"/ip4/0.0.0.0/udp/8020/quic-v1\".parse()?)\n                .build(),\n        );\n    }\n\n\n    let remote_actor_ref = RemoteActorRef::<MyActor>::lookup(\"my_actor\").await?;\n        match remote_actor_ref {\n            Some(remote_actor_ref) => {\n                let count = remote_actor_ref.ask(&Inc { amount: 10 }).send().await?;\n                println!(\"Incremented! Count is {count}\");\n            }\n            ...\n \nreply",
      "Thanks!  It's not in the front page material.\n \nreply",
      "This looks really nice! Curious if its running in production anywhere\n \nreply",
      "I agree, really nice syntax.There's a limitation mentioned in the docs:  While messages are processed sequentially within a single actor, Kameo allows for concurrent processing across multiple actors.\n\nwhich is justified via  This [sequential processing] model also ensures that messages are processed in the order they are received, which can be critical for maintaining consistency and correctness in certain applications.\n\nI agree to this and it gives the library a well defined use.Docs and examples are well made.\n \nreply",
      "This limitation is common to most implementations of the actor model. In fact, I think a lot of people would consider it a feature, not a limitation because it allows you to reason about your concurrent behavior in a more straightforward way.\n \nreply"
    ],
    "link": "https://github.com/tqwewe/kameo",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fault-tolerant Async Actors Built on Tokio\n      \n\n\n\n\n\n\nKameo is a lightweight Rust library for building fault-tolerant, distributed, and asynchronous actors. It allows seamless communication between actors across nodes, providing scalability, backpressure, and panic recovery for robust distributed systems.Kameo is versatile and can be applied in various domains, such as:Add kameo as a dependency in your Cargo.toml file:Spawn and message the actor.Contributions are welcome! Whether you are a beginner or an experienced Rust developer, there are many ways to contribute:Join our community on Discord to connect with fellow contributors!kameo is dual-licensed under either:at your option.Home | Features | Use Cases | Get Started | Additional Resources | Contributing | License\n        Fault-tolerant Async Actors Built on Tokio\n      "
  }
]