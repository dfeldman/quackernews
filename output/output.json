[
  {
    "title": "Ghrc.io appears to be malicious (bmitch.net)",
    "points": 191,
    "submitter": "todsacerdoti",
    "submit_time": "2025-08-24T23:27:52 1756078072",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=45008740",
    "comments": [
      "GitHub Container registry does not even support fine-grained tokens, instead it uses classic ones [1], which makes this even more dangerous.[1] https://docs.github.com/en/packages/working-with-a-github-pa...Edit: most relevant issues?https://github.com/orgs/community/discussions/38467https://github.com/github/roadmap/issues/558reply",
      "Are there any additional mitigations folks are using for this? This issue is the only reason we can\u2019t turn classic PATs off entirely.Short lifetime mandatory reauth to enterprise SSO seems to be the best available, but it\u2019s inconvenient for the single Classic PAT we actually need.reply",
      "Someone near a computer that is feeling generous should buy up all the typo'd domain names and hand them over to Microsoft.Microsoft should rename the registry. This is a horrible name. I know I've typo'd it before.reply",
      "Microsoft is paying top dollar for MarkMonitor, aren't they supposed to proactively register obvious typos so this kind of thing doesn't happen to their clients?reply",
      "My guess is that MarkMonitor is mainly used for their brand-relevant domains (microsoft, office 365, github (main site), etc), as opposed to one that a small subset of a small subset of their users of one service will use - I would imagine that microsoft likely owns hundreds of domain names and doesn't pay MarkMonitor to monitor every single onereply",
      "Fairly compelling attack vector because it took several readings for me to even see the problem with the domain.reply",
      "You and many others.  Including people who retry multiple times, and even reboot their machines.* https://stackoverflow.com/a/66985424/340790 (Spot the answerer's account name!)* https://forums.docker.com/t/docker-unable-to-push-to-ghrc-io...reply",
      "https://github.com/search?q=ghrc.io&type=codereply",
      "Took the article pointing out that the c and r were transposed for me to even notice there was a problem!reply",
      "Yep this is the sort of typo error I make probably 10 times a day.reply"
    ],
    "link": "https://bmitch.net/blog/2025-08-22-ghrc-appears-malicious/",
    "first_paragraph": "A simple typo of ghcr.io to ghrc.io would normally be a small goof.\nYou\u2019d typically get a 404 or similar error, finally work out the issue, fix it, and move along.\nBut in this case, that typo appears to be doing something very malicious, stealing GitHub credentials.First, a quick bit of background.\nghcr.io is an OCI conformant registry for container images and OCI artifacts used by a lot of projects.\nIt\u2019s part of GitHub and is a very popular image and artifact repository used by open source projects.At first glance, ghrc.io is just a default nginx install:Even checking other links gives a typical 404 error:The concerning part comes in when looking at the OCI API\u2019s.\nThose are all under the /v2/ prefix for legacy reasons.\nLooking at ghrc.io, suddenly it\u2019s not acting like a default nginx install anymore:Compare that to some other registries and you\u2019ll see the 401 status, www-authenticate header, and error message look very similar:The (optional) error message is defined by the OCI Distrib"
  },
  {
    "title": "Everything I know about good API design (seangoedecke.com)",
    "points": 162,
    "submitter": "ahamez",
    "submit_time": "2025-08-24T19:10:09 1756062609",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=45006801",
    "comments": [
      "The reminder to \"never break userspace\" is good, but people never bring up the other half of that statement: \"we can and will break kernel APIs without warning\".It illustrates that the reminder isn't \"never change an API in a way that breaks someone\", it's the more nuanced \"declare what's stable, and never break those\".reply",
      "Even if the kernel doesn't break userspace, GNU libc does, all the time, so the net effect is that Linux userspace is broken regardless of the kernel maintainers' efforts. Put simply, programs and libraries compiled on/for newer libc are ABI-incompatible or straight-up do not run on older libc, so everything needs to be upgraded in lockstep.It is a bit ironic and a little funny that Windows solved this problem a couple decades ago with redistributables.reply",
      "otoh staticly-linked executables are incredibly stable - it's nice to have that option.reply",
      "From what I understand, statically linking in GNU's libc.a without releasing source code is a violation of LGPL. Which would break maybe 95% of companies out there running proprietary software on Linux.musl libc has a more permissive licence, but I hear it performs worse than GNU libc. One can hope for LLVM libc[1] so the entire toolchain would become Clang/LLVM, from the compiler driver to the C/C++ standard libraries. And then it'd be nice to whole-program-optimise from user code all the way to the libc implementation, rip through dead code, and collapse binary sizes.[1]: https://libc.llvm.org/reply",
      "AFAIK, it's technically legal under the LGPL to statically link glibc as long as you also include a copy of the application's object code, along with instructions for how users can re-link against a different glibc if they wish. You don't need to include the source for those .o files.But I don't think I've ever seen anybody actually do this.reply",
      "You can (equivalently) distribute some specific libc.so with your application.  I don't think anyone other than GNU maximalists believes this infects your application with the GPL.reply",
      "Yeah, famously there is no stable public driver API for Linux, which I believe was the motivation for Google\u2019s Fuschia OSSo Linux is opinionated in both directions - towards user space and toward hardware - but in the opposite wayreply",
      "Cursor based pagination was mentioned. It has another useful feature: If items have been added between when a user loads the page and hits the next button, index based pagination will give you some already viewed items from the previous page.Cursor based pagination (using the ID of the last object on the previous page) will give you a new list of items that haven't been viewed. This is helpful for infinite scrolling.The downside to cursor based pagination is that it's hard to build a jump to page N button.reply",
      "> How should you store the key? I\u2019ve seen people store it in some durable, resource-specific way (e.g. as a column on the comments table), but I don\u2019t think that\u2019s strictly necessary. The easiest way is to put them in Redis or some similar key/value store (with the idempotency key as the key).I'm not sure how would storing a key in Redis achieve idempotency in all failure cases. What's the algorithm? Imagine a server handling the request is doing a conditional write (like SET key 1 NX), and sees that the key is already stored. What then, skip creating a comment? Can't assume that the comment had been created before, since the process could have been killed in-between storing the key in Redis and actually creating the comment in the database.An attempt to store idempotency key needs to be atomically committed (and rolled back in case it's unsuccessful) together with the operation payload, i.e. it always has to be a resource-specific id. For all intents and purposes, the idempotency key is the ID of the operation (request) being executed, be it \"comment creation\" or \"comment update\".reply",
      "While the author doesn't seem to like version based APIs very much, I always recommend baking them in from the very start of your application.You cannot predict the future and chances are there will be some breaking change forced upon you by someone or something out of your control.reply"
    ],
    "link": "https://www.seangoedecke.com/good-api-design/",
    "first_paragraph": "Most of what modern software engineers do1 involves APIs: public interfaces for communicating with a program, like this one from Twilio. I\u2019ve spent a lot of time working with APIs, both building and using them. I\u2019ve written public APIs for third-party developers, private APIs for internal use (or consumption by a single frontend page), REST and GraphQL APIs, and even non-network interfaces like the ones for command-line tools.Like designing good software systems, I think much of the advice floating around about API design is too fancy. People get wrapped up in what \u201creal\u201d REST is, or whether HATEOAS is a good idea, and so on. This post is my attempt at writing down everything I know about designing good APIs.If this is true about systems - and it is - it\u2019s even more true about APIs: good APIs are boring. An API that\u2019s interesting is a bad API (or at least it would be a better one if it were less interesting). For the developers who build them, APIs are complex products that they spend "
  },
  {
    "title": "The two versions of Parquet (jeronimo.dev)",
    "points": 118,
    "submitter": "tanelpoder",
    "submit_time": "2025-08-21T09:34:32 1755768872",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=44970769",
    "comments": [
      "I am saying this as a lifelong supporter and user of open source software: issues like this are why governments and enterprises still run on Oracle and SQL Server.The author was able to rollback his changes, but in some industries an unplanned enterprise-wide data unavailability event means the end of your career at that firm, if you don\u2019t have a CYA email from the vendor confirming you were good to go. That CYA email, and the throat to choke, is why Oracle does 7 and 8 figure licensing deals with enterprises selling inferior software solutions versus open source options.It seems that Linux, through Linus\u2019 leadership, has been able to solve this risk issue and fully displace commercial UNIX operating systems. I hope many other projects up and down the stack can have the same success.reply",
      "Sorry, I think you misunderstood this article.When the author is talking about rolling back his changes, it's not referring to a database, but a version of his library. If someone tried used his new version, I assume the only thing that would have gone wrong is that their code wouldn't work because Pandas didn't support the format.This article is about how a new version of the Parquet format hasn't been widely adopted, and so now the Parquer community is in a split state where different forces are pulling the direction of the format in two directions, and this happens to be caused by two different areas of focus that don't need to be tightly coupled together.I don't see how the problems the article discusses relate to the reliability of software.reply",
      "People keep using Oracle because they have a ton of code and migration would be too costly.Oracle is not imune to software issues. In fact, this year I lost two weekends because of a buggy upgrade on the cloud that left my production cluster in a failed state.reply",
      "A lot of these have business logic literally in the database built up over years.It\u2019s a mammoth task for them to migratereply",
      "Oracle Consulting gladly built it all as stored procs with a UI.reply",
      "> builtbilledreply",
      "annuallyreply",
      "It\u2019s not about being immune to software issues. It\u2019s about having a vendor to cop the blame if something goes wrong.reply",
      "Polite disagree; governments and enterprises remain on Oracle / SQL Server because it is borderline sisphean. It can be done (we are doing it) but it requires a team who are doing it non-stop. It's horrible work.reply",
      "At the start of your comment I thought the 'issues like this' were going to be the 4 year discussions about what is and isn't core.reply"
    ],
    "link": "https://www.jeronimo.dev/the-two-versions-of-parquet/",
    "first_paragraph": "Jerolba's blog. Tech, JVM and random stuff.A few days ago, the creators of DuckDB wrote the article: Query Engines: Gatekeepers of the Parquet File Format, which explained how the engines that process Parquet files as SQL tables are blocking the evolution of the format. This is because those engines are not fully supporting the latest specification, and without this support, the rest of the ecosystem has no incentive to adopt it.In my experience, this issue is not limited to Query Engines but extends to the tools within the ecosystem. Soon after releasing the first version of Carpet, I discovered that there was a version 2 of the format and that the core Java Parquet library does not activate it by default. Since the specification had been finalized for some time, I decided that the best approach was to make Carpet use version 2 by default.A week later, I discovered at work the hard way that if you are not up to date with Pandas in Python, you cannot read files written with version 2. "
  },
  {
    "title": "Show HN: Sping \u2013 An HTTP/TCP Latency Tool That's Easy on the Eye (dseltzer.gitlab.io)",
    "points": 19,
    "submitter": "zorlack",
    "submit_time": "2025-08-24T23:42:01 1756078921",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=45008819",
    "comments": [
      "Just fyi, looks like the shortened command defaults has a bug based on the docs @ https://pypi.org/project/service-ping-sping/(i.e. # HTTP monitoring with interactive UI\nsping google.com\n)  sping johnqdeveloper.com     \n  Usage: sping [OPTIONS] URL\n  Try 'sping --help' for help.\n  \u256d\u2500 Error \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n  \u2502 Invalid value for '--palette': <ColorPalette.SUNSET:   'sunset'> is not one of \u2502\n  \u2502 'sunset', 'ocean', 'forest', 'volcano', 'galaxy', 'arctic', 'neon',          \u2502\n  \u2502 'monochrome'.                                                                  \u2502\n  \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256freply",
      "Thank you for reporting this!Would you mind telling me what environment you found this behavior in, and how you installed the app?I've been testing in ubuntu containers doing:    pip3 install service-ping-sping --break-system-packages\n\nThank you so much!!*EDIT:*I think this is to do with me not being specific about what version of typer I depend upon... working on it now!reply",
      "Very nice! We all really need a tool that IT can use to diagnose problems along the path. Like more user friendly nping \u2014trreply"
    ],
    "link": "https://dseltzer.gitlab.io/sping/docs/",
    "first_paragraph": "Modern terminal HTTP/TCP latency monitoring tool with real-time visualization. Think httping meets modern CLI design with rich terminal UI, phase timing, and advanced analytics.Status: Feature-complete MVP with HTTP/TCP support, phase timing, outlier detection, and comprehensive monitoring capabilities.Real-time latency monitoring with interactive charts showing HTTP response times, outlier detection, and live statistics.I've frequently found myself using nvitop to diagnose GPU/CPU contention issues.The two best things about it are:With those two lessons in mind: Here is Sping!Purpose: Help observe and diagnose latency issues at layer 4+ (TCP/HTTP/HTTPS)Two good things about it:For development:sping automatically detects unusual latency spikes using Median Absolute Deviation (MAD) analysis:Note: Outlier detection helps identify performance degradation, network issues, or service problems that might not trigger error thresholds.Choose from beautiful themed color palettes to customize yo"
  },
  {
    "title": "I'm Fighting for My Freedom Using Outdated Technology (prisonjournalismproject.org)",
    "points": 8,
    "submitter": "danso",
    "submit_time": "2025-08-25T00:10:00 1756080600",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://prisonjournalismproject.org/2025/08/19/prisons-outdated-technology-hurts-our-chances-at-freedom/",
    "first_paragraph": "See how incarcerated writers are breaking stereotypes and shifting the narrative by subscribing to our weekly newsletter.Prison Journalism Project\n\t\t\t\t\tChanging the Storytellers\t\t\t\tRepublish This StoryRepublish our articles for free, online or in print, under a Creative Commons license.This work is licensed under a Creative Commons Attribution-NoDerivatives 4.0 International License.by Jorge Luis Alvarado, Prison Journalism Project August 19, 2025Don't miss our latest stories, delivered to your inbox once a week.Recently, my lawyer instructed me to read the original transcripts from my trial and other legal documents he sent me in preparation for my appeal. It was a reasonable request. Being able to read these kinds of legal documents helps us understand our cases and talk through details with our lawyers. The only problem was that he sent the documents to me on a flash drive, which we are generally not allowed to have at New Jersey State Prison.The only way to access flash drives from"
  },
  {
    "title": "Is 4chan the perfect Pirate Bay poster child to justify wider UK site-blocking? (torrentfreak.com)",
    "points": 154,
    "submitter": "gloxkiqcza",
    "submit_time": "2025-08-24T16:30:18 1756053018",
    "num_comments": 100,
    "comments_url": "https://news.ycombinator.com/item?id=45005545",
    "comments": [
      "If they do it, I never want to hear any criticism of the great firewall of China from them ever again.reply",
      "I read on twitter, can't find the exact link, a chinese content site operating in .sg for many years, survived multiple \"internet purges\" in China, got banned by UK authorities last month.reply",
      "I remember reading posts a decade or two ago on either Linode's forums or some other place like LinuxQuestions in broken English about tunneling through firewalls with ssh from I assume Chinese people.I've started seeing posts like that from British people now. Absolutely wild. So much for the birthplace of common law.reply",
      "They have done it, and the west (over half the US states, the UK and Australia at a bare minimum) have entirely ceded any moral high ground regarding it.reply",
      "What you must understand is that they do it because of a moral failing, whereas we do it because the situation requires it.reply",
      "No one likes hearing hypocrisy from politicians, but it's one of their most dominant traits. That is, if you ascribe normal ethics and morals to them. But politicians' are a different breed, and the sooner we understand that, the better.They will say, and do, whatever they perceive as being the most politically expedient thing to do. The ones that took moral stances in the actual best interest of the populace usually suffered politically for that. The ones that side with power tend to keep their power. This is the folly of political systems in general short of tyrannies, dictatorships, and kingdoms. And now we are seeing how democracies can be stretched into the same quality of life as so-called \"lesser\" systems but people don't like hearing that argument because the alternative is made out to be so scary.It's not so much that democracy is the problem, but that it's too easy to sway people when it's so easy for money and power to be leveraged to manufacture consent. So now it's the people electing their own tyrants who will enrich and entrench themselves and being grateful for the privilege to be used for that purpose.steps down off of soap box and stops yelling at cloudsreply",
      "> No one likes hearing hypocrisy from politiciansCambridge Analytica showed politicians in real time that on a population scale, hypocrisy doesn't make any difference. In fact people will bend themselves around to square the circle.Politicians finally knowing for a demonstrable, data-backed, evidence-based fact that they can do basically whatever they want and keep their support as long as they just say they right things is what has brought us from 2016 to now.reply",
      "Remember, half the population are under 100 IQ points.And most general people I meet here in the USA are either heavily propagandized, extraordinarily dumb, or both.We could be for \"better and better, which is what the Chinese have been doing the last 50 years. Instead we've been at\" fuck you I got mine haha\", and \"don't let THEM have anything\".Well, the out groups have sacrificed so they have no more. Now making the lower and middle and even upper middle class suffer is the name of the game.reply",
      "I\u2019m quite sure they don\u2019t see it as hypocrisy. China censors the internet because they want to control everything about their citizens lives. But us? Oh, we\u2019re censoring the internet to protect the children.reply",
      "> but it's one of their most dominant traitsAlways has been.  What has changed is they now have the power to force their constituency to live with their hypocrisy and lies.  Any effort to challenge the \"leader\" results in claims that you are now a \"terrorist.\"The internet was supposed to empower the citizenry.  It's been captured and is now a tool used to suppress them.  So now we see leaders completely unchallenged when their darker habits are exposed.reply"
    ],
    "link": "https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/",
    "first_paragraph": ""
  },
  {
    "title": "Making games in Go: 3 months without LLMs vs. 3 days with LLMs (marianogappa.github.io)",
    "points": 248,
    "submitter": "maloga",
    "submit_time": "2025-08-24T15:01:24 1756047684",
    "num_comments": 175,
    "comments_url": "https://news.ycombinator.com/item?id=45004728",
    "comments": [
      "What I like about this post is that it highlights something a lot of devs gloss over: the coding part of game development was never really the bottleneck. A solo developer can crank out mechanics pretty quickly, with or without AI. The real grind is in all the invisible layers on top; balancing the loop, tuning difficulty, creating assets that don\u2019t look uncanny, and building enough polish to hold someone\u2019s attention for more than 5 minutes.That\u2019s why we\u2019re not suddenly drowning in brilliant Steam releases post-LLMs. The tech has lowered one wall, but the taller walls remain. It\u2019s like the rise of Unity in the 2010s: the engine democratized making games, but we didn\u2019t see a proportional explosion of good game, just more attempts. LLMs are doing the same thing for code, and image models are starting to do it for art, but neither can tell you if your game is actually fun.The interesting question to me is: what happens when AI can not only implement but also playtest -- running thousands of iterations of your loop, surfacing which mechanics keep simulated players engaged? That\u2019s when we start moving beyond \"AI as productivity hack\" into \"AI as collaborator in design.\" We\u2019re not there yet, but this article feels like an early data point along that trajectory.reply",
      "> The interesting question to me is: what happens when AI can not only implement but also playtest -- running thousands of iterations of your loop, surfacing which mechanics keep simulated players engaged?How is AI supposed to simulate a player, and why should it be able to determine what real people would find engaging?reply",
      "> How is AI supposed to simulate a player, and why should it be able to determine what real people would find engaging?Games have goals, and players are prone to 'optimising the fun out of games', by doing some save strategy over and over again to reach that goal, even if it's not fun.  Think eg grinding in an RPG, instead of facing tough battles with strategy and wits and the risk of failure.Even if AIs are terrible at determining what's engaging, you can probably at least use them to relatively quickly find ways that you accidentally opened that let players get in the way of their own fun.reply",
      "Game companies already collect heaps of data about players, which mechanics they interact with, which mechanics they don't, retention, play time, etc.I don't think it's much of a stretch to take this data over multiple games, versions, and genres, and train a model to take in a set of mechanics, stats, or even video and audio to rate the different aspects of a game prototype.I wouldn't even be surprised if I heard this is already being done somewhere.reply",
      "> Game companies already collect heaps of data about players, which mechanics they interact with, which mechanics they don't, retention, play time, etc.Yes, that's how games like Concord get made. Very successful approach to create art based on data about what's popular and focus groups.reply",
      "I think you are saying data is no substitute for vision in design.  Completely agree!  At Playdom (Disney) they tried to build a game once from the ground up based on A/B testing.  Do you know what that game was?  No you don't because it was never released and terrible.I think what the previous comment meant was that there is data on how player play, and that tends to be varied but more predictable.reply",
      "Isn't Concord massively unpopular? I'd think that's a terrible exampleEdit: yup, it shut down nearly a year agoreply",
      "I think it was a sarcastic example - in other words, all the data and metrics and trend-chasing in the world is not a replacement for human vision, creativity, and risk-taking.reply",
      "Was Concord made the way it was because of data? I got the impression that the designers were chasing misguided trends with the art direction, and on top of that the game part was just mediocre.reply",
      "I can't say for sure (never played it or followed it much, because it's not my type of game) but the impression I had is that it was a cookie-cutter attempt to be just another live service online shooter in the vein of Valorant, Overwatch, Apex Legends, etc etc. And people saw no need to play this new one when those games already exist.Compare that to Helldivers 2 (online-only live service game, same platforms and publisher) which had a lot of personality (the heavy Starship Troopers movie vibe) and some unique gameplay elements like the strategems.reply"
    ],
    "link": "https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/",
    "first_paragraph": "After 15 years as a software engineer, I realized I had never actually built and published a game.Since I grew up in \ud83c\udde6\ud83c\uddf7 Argentina playing card games with my friends, I figured I\u2019d choose one of those. I asked myself:On June 18th of 2024 I started building Truco in my free time. As a longtime Go backend developer, the backend was obvious. The challenge was the UI and long-term hosting without a paid server.This was pre-LLM, so every detail had to be figured out by hand. It took about 3 months of trial and error to get it ready.I never planned to advertise or monetize it; I just wanted to finish, and maybe give someone the joy of playing their childhood game again. A year later, without any extra effort on my part, people are still playing it!In case you want to check it out, here are some links for it:Truco (play the game)Backend in GoFrontend in React (don\u2019t judge me \ud83e\udd37\u200d\u2642\ufe0f best I can do with 1-hour React knowledge)A year later, visiting family in Argentina, I taught my nephew Escoba\u2014the"
  },
  {
    "title": "We put a coding agent in a while loop (github.com/repomirrorhq)",
    "points": 103,
    "submitter": "sfarshid",
    "submit_time": "2025-08-24T16:18:53 1756052333",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=45005434",
    "comments": [
      "There will be a a new kind of job for software engineers, sort of like a cross between working with legacy code and toxic site cleanup.Like back in the day being brought in to \u201cjust fix\u201d a amalgam of FoxPro-, Excel-, and Access-based ERP that \u201cmostly works\u201d and only \u201coccasionally corrupts all our data\u201d that ambitious sales people put together over last 5 years.But worse - because \u201cambitious sales people\u201d will no longer be constrained by sandboxes of Excel or Access - they will ship multi-cloud edge-deployed kubernetes micro-services wired with Kafka, and it will be harder to find someone to talk to understand what they were trying to do at the time.reply",
      "When Claude starts deploying Kafka clusters I\u2019m outroreply",
      "It's already happening brother, https://github.com/containers/kubernetes-mcp-server.reply",
      "still don\u2019t know why you need an MCP for this when the model is perfectly well trained to write files and run kubetctl on its ownreply",
      "Claude is, some models aren't.  In some cases the MCPs do get the models to use tools better as well due to the schema, but I doubt kubectl is one of them (using the git mcp in claude code... facepalm)reply",
      "Yeah fair enough lol\u2026usually I end up building model-optimized scripts instead of mcp which just flood context window with json and uuids (looking at you, linear) - much better to have Claude write 100 lines of ts to drop a markdown file with the issue and all comments and no noisereply",
      "Superfund repos.reply",
      "A lot of big open source repos need to be given the superfund treatmentreply",
      "Now that's an open source funding model governments can get behind.reply",
      "There are always two major results from any software development process: a change in the code and a change in cognition for the people who wrote the code (whether they did so directly or with an LLM).Python and Typescript are elaborate formal languages that emerged from a lengthy process of development involving thousands of people around the world over many years. They are non-trivially different, and it's neat that we can port a library from one to the other quasi-automatically.The difficulty, from an economic perspective, is that the \"agent\" workflow dramatically alters the cognitive demands during the initial development process. It is plain to see that the developers who prompted an LLM to generate this library will not have the same familiarity with the resulting code that they would have had they written it directly.For some economic purposes, this altering of cognitive effort, and the dramatic diminution of its duration, probably doesn't matter.But my hunch is that most of the economic value of code is contingent on there being a set of human beings familiar with the code in a manner that requires writing having written it directly.Denial of this basic reality was an economic problem even before LLMs: how often did churn in a development team result in a codebase that no one could maintain, undermining the long-term prospects of a firm?reply"
    ],
    "link": "https://github.com/repomirrorhq/repomirror/blob/main/repomirror.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "A Brilliant and Nearby One-off Fast Radio Burst Localized to 13 pc Precision (iop.org)",
    "points": 44,
    "submitter": "gnabgib",
    "submit_time": "2025-08-24T19:23:19 1756063399",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=45006902",
    "comments": [
      "I am generally well read across a wide variety of fields, but now and again I come across a sentence or paragraph where the sheer density of information packed into a small number of well-chosen field-specific terms just stops me in my tracks. The abstract for this paper is a testament to the ability of jargon to increase the information carrying capacity of the limited bitrate of human language - it hit my head like a zip bomb.reply",
      "Is kJy as a brightness unit the abomination I think it is?reply",
      "You nerd sniped me :) In this context, I believe it is a kilo-Jansky, not a kilo-Joule * year.https://en.wikipedia.org/wiki/Janskyreply",
      "Every day Hacker News titles, stories, and comments have acronyms and abbreviations I've never seen before, and I have to search for the term to know what it's talking about.  I know what a parsec is, but I've never actually seen the pc abbreviation used before.  At least I learn something new every day.reply",
      "You didn't mention but I guess pc here stands for parsecsreply"
    ],
    "link": "https://iopscience.iop.org/article/10.3847/2041-8213/adf62f",
    "first_paragraph": "To ensure we keep this website safe, please can you confirm you are a human by ticking the box below. If you are unable to complete the above request please contact us using the below link, providing a screenshot of your experience.\nhttps://ioppublishing.org/contacts/\n"
  },
  {
    "title": "My ZIP isn't your ZIP: Identifying and exploiting semantic gaps between parsers (usenix.org)",
    "points": 30,
    "submitter": "layer8",
    "submit_time": "2025-08-21T08:58:44 1755766724",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=44970583",
    "comments": [
      "I'm cited on the first page of this paper (reference 20) for my work on the Android Master Key vulnerability (which I didn't find, to be clear, but I did most of the exploitation people saw), and, while this paper looks AWESOME (and I'm very excited to read it in detail), if you are interested in this concept but feel you need something a bit more concrete--maybe with diagrams and some hand-holding--to understand what is going on, I will recommend my series of articles on Master Key as an introduction.https://www.saurik.com/masterkey1.htmlhttps://www.saurik.com/masterkey2.htmlhttps://www.saurik.com/masterkey3.htmlreply",
      "Also related to ZIP parsing differentials, recently reported and fixed at PyPi: https://blog.pypi.org/posts/2025-08-07-wheel-archive-confusi...reply",
      "This is a really good paper that reaches a bunch of fun conclusions, but to my eyes the practical findings are kind of marginal --- you can defeat an AV scanner, but you could already defeat AV scanners; you can defeat plagiarism-detectors, but you could already defeat plagiarism-detectors; you can package a malicious Java class in a benign-looking JAR, but that attack presumes you're convincing a target to load a JAR file you control.The one legit-practical attack I see is the one where they trick the VS Code Extension marketplace into serving extensions with trusted publishers, but even there I'm struck by the fact that the security model for verifying extensions would depend on ZIP metadata.I do not at all mean to talk this work down; this is my favorite species of vulnerability research, and I can see why it did well at Usenix Security.reply",
      "Zip is a fun minefield across different OS's, libraries, and ages of system. Zip64 is a fun one I've seen companies forget to test and end up with data loss with over 65535 files in a zip when interacting with more modern systems. There are really so many things you need to test that going with some other compression without the pitfalls is your best choice if possible.reply",
      "Key line from the abstract, since zip parser differences in general are old news:> We summarize our findings as 14 distinct parsing ambiguity types in three categories with detailed analysis, systematizing current knowledge and uncovering 10 types of new parsing ambiguities.reply",
      "Maybe an argument to use zlib consistently.reply",
      "Unless, of course, the differential occurs between versions of zlib. I think the bigger problem here is that ZIP is just not a very well defined format.reply",
      "An argument for a better defined file format specification perhaps, but I don't think it's necessarily a good thing for everyone to use or have to use the same implementation.reply",
      "As someone who works on specs that are shared across different organizations' implementations, no conformance tests = no conformance.reply",
      "If everyone has the same parser the whole classes of bugs just stop being exploitable. The classic one being one parser at the edge validates somethhing and the further down the line sees another result which it expects tp be rejected during validation.Both parsers could be buggy, but when they have different kinds of bugs, you get a zero click undetectable exploitreply"
    ],
    "link": "https://www.usenix.org/conference/usenixsecurity25/presentation/you",
    "first_paragraph": ""
  },
  {
    "title": "Trees on city streets cope with drought by drinking from leaky pipes (newscientist.com)",
    "points": 148,
    "submitter": "bookofjoe",
    "submit_time": "2025-08-22T16:46:42 1755881202",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=44986723",
    "comments": [
      "The city where I live estimates that we lose somewhere between 25% and 30% of drinkable water to leaky infrastructure.We've had something close to a drought this summer -- unseasonally long periods without rain. You can see the young trees on the streets and trees in the middle of large parks suffer from it - wilted leaves and leaves dropping earlier than usual. BUT, large old trees seem to be thriving - full canopies, lush, firm leaves.I've been suspecting the big street trees do so well because they benefit from the dilapidated state of our water delivery infra. It's nice to read of a study that confirms my amateur observations and musings.reply",
      "Older, bigger plants have roots that go deeper and have access to more water. You can see the same effect in gardens, where new plants wilt sooner than established plants (and the care instructions advise frequent watering for the first couple of weeks).reply",
      "That\u2019s really high. There\u2019s either a big problem in your city, or they are making generous estimates to justify asking for more capital. 10-15% is more typical.In my region, the street trees are usually getting sewer water. Residential service in older houses are usually clay pipes with lead solder that the tree infiltrates. It\u2019s not a problem until the clay pops and roots clog it.It varies a lot by region and jurisdiction. One of the cities near me made the mistake of using riveted pipe from rolled steel to save money 75 years ago, and regularly has catastrophic main breaks as the rivets aren\u2019t as robust as a regular pipe.reply",
      "OP numbers aren\u2019t only a city problem, IIRC [0] the numbers are close here in France. There\u2019s a startup that try to tackle it : www.leakmited.com/en I applied there 3 month ago and they never responded. Can\u2019t blame them but I\u2019m a bit sad: it\u2019s the dream impact-job.[0] 20% apparently https://www.eaufrance.fr/repere-rendement-des-reseaux-deau-p...reply",
      "My city loses about 30% of the water going through it's pipes, including leaking wastewater directly into rainwater drains ( left untreated).I believe some of the plumbing was wood pipes in select very busy parts of the city until somewhat recently, as it was a nightmare to replace.reply",
      "Mexico City, by some estimates loses about 40% of its water that does enter its system, whether it's through leaky pipes or being stolen.https://www.marketplace.org/story/2024/05/27/mexico-city-wat...reply",
      "TIL clay pipes are a thing but it does make a lot of sense there would be.reply",
      "Here in Germany, we estimate sewer infrastructure to last anywhere from 50-100 years, and water mains around 50-ish years. After that, it needs replacement or, that's the modern thing but it's a one-trick pony, re-lining.The prudent thing would be to set aside and invest a tiny bit of money every year to fund a replacement, but unfortunately modern economic theory (\"run lean\") and manufactured income crises (aka, politicians going for lower taxes and utility rates) have led to a lot of infrastructure being utterly dilapidated and no savings left, and now we need to invest untold billions of euros raised from debt to keep it running.Unfortunately, a lot of the deciders are already dead, and for those that still live, it's fallen out of favor to hold them accountable.reply",
      "Smart is to have a crew that replaces a little every year. That way they build expertise in how to do it and there isn't a large expense all at once. You can likely get a discount with private plumbers because you want it done sometime and so they schedlue around other customers who want it now.reply",
      "That doesn't track because the real cost to replacing underground infrastructure is not the digging, materials, or labor. We avoid such maintenance as long as possible because shutting down a road is usually very expensive in terms of second-order effects.Digging up a pipe and replacing it is actually pretty cheap and easy. Disrupting a main thoroughfare is incredibly expensive in terms of lost productivity, transport, shipping.reply"
    ],
    "link": "https://www.newscientist.com/article/2487804-trees-on-city-streets-cope-with-drought-by-drinking-from-leaky-pipes/",
    "first_paragraph": "AdvertisementUrban trees lining streets fare better in dry spells than those in parks \u2013 now it seems that leaky water pipes are the reason for their enduranceBy Alex Wilkins\n                                    11 July 2025\n                                    \nTrees on the streets of Montreal in Canada benefit from leaky pipesCatherine Zibo/ShutterstockTrees on the streets of Montreal in Canada benefit from leaky pipesCatherine Zibo/ShutterstockTrees growing on city streets are more resistant to drought than those in parks because they are drinking from an unusual water source: leaky pipes.After long periods with little rain, water levels and sap flow tend to decrease more in trees growing in parks compared with those in streets, but it was unclear why. Read moreMicroturbines can generate electricity from drinking water pipes Read moreMicroturbines can generate electricity from drinking water pipesTo investigate, Andr\u00e9 Poirier at the University of Quebec in Montreal, Canada, and his col"
  },
  {
    "title": "Halt and Catch Fire Syllabus (2021) (ashleyblewer.com)",
    "points": 94,
    "submitter": "Kye",
    "submit_time": "2025-08-24T20:19:55 1756066795",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=45007414",
    "comments": [
      "I recently watched all of Halt and Catch Fire, and i have to say it is a really special show. The first season is fun, but it really comes into its own in the following seasons,  exploring long relationships, friendship, growth, and love in ways that really surprised me. Highly recommend.reply",
      "I recently finished it too! I was pretty over it by the final season, but then the last few episodes brought me back around.Cameron \"it's all in the eyes\" Howe annoyed the shit out of me at pretty much all points, which I understand is how they wrote the character but it walked a line of almost making me quit the show. As with the show as a whole, though, she brought me around a bit in the last few eps.reply",
      "I was largely disappointed. The subject matter was special but the execution was over the top. Every time I was starting to get drawn in, there would be another affair, car crash, exploding lorry or something else just as forced. I can\u2019t even remember the number of times it felt like they\u2019d \u201cjumped the shark\u201d in even just the first season alone.There really wasn\u2019t any need for half the dumb shit they did in that show. It didn\u2019t add to the drama, it just made the whole thing feel completely fake. Which is impressive considering they\u2019re writing largely about real world computing history.And don\u2019t get me started on the characters themselves. I think I liked maybe half the cast. The others made me cringe every time they were on screen.It\u2019s such a pity because they could have just as successful show if they refined it a little.reply",
      "I 100% agree. I couldn\u2019t finish it and bailed during the first season. It was all just so over the top!I thought Micro Men was way better executed as a comparison point https://en.m.wikipedia.org/wiki/Micro_Menreply",
      "Completely different show after season 1, I almost bailed at the end of s01 too. But also, different strokes for different folks :)reply",
      "Really! Interesting. How was it different?reply",
      "Shifts from looking like compaq, to early internet stuff, from memory.reply",
      "This complaint largely lands on the same points as the ones against Mr. Robot, and it has some merit, but the shows are made for cable TV audiences, so they're a bit more niche than broadcast shows, but they're mass market vehicles. They're nearly pushing a rope to make this content entertaining at all. If people cared, they'd already know the history and the social implications of the technology, as well as the personalities involved. These kinds of shows are meant to bring more folks into the industry and help folks see the humanity in each other and in themselves if they're in it. Most folks don't watch tv for anything but storylines and personalities, so historical or current relevance in entertainment is something I'll take where and when I can get it.What are some tech shows that you like, or dramas, for context?reply",
      "I\u2019m not suggesting the show should be factually accurate. I\u2019m saying it doesn\u2019t need pyrotechnics to be engaging.Mr Robot was a different beast because that was literally about criminal and hacker culture. So you\u2019d expect a little action in that regard.To put it another way: you have shows that have strong enough writers where they don\u2019t need gimmicks to keep your attention. And you have shows that are intentionally about the gimmicks. Then you have shows that aren\u2019t about the gimmicks but the writers don\u2019t have enough confidence in their work to avoid putting them in anyway.Shows like The West Wing, House of Cards etc aren\u2019t about gimmicks and don\u2019t need them.Shows like Stargate are about the gimmicks. And that\u2019s ok too because you know it\u2019s meant to be silly drama.But shows like HCF feel like they should be executed like HoCs, yet they\u2019re written like Mr Robot, Stargate, etc. So it\u2019s very jarring to watch every time another gimmick gets thrown in. Maybe I expected too much from that show? But it just felt like they didn\u2019t have any confidence in people\u2019s attention spans.reply",
      "> To put it another way: you have shows that have strong enough writers where they don\u2019t need gimmicks to keep your attention. And you have shows that are intentionally about the gimmicks. Then you have shows that aren\u2019t about the gimmicks but the writers don\u2019t have enough confidence in their work to avoid putting them in anyway.Can you elaborate a bit about the gimmick(s) in Halt and Catch Fire? I think it's a drama, so there are human concerns and interactions, but that's like, what tv shows are? I don't know what you mean specifically.> Shows like The West Wing, House of Cards etc aren\u2019t about gimmicks and don\u2019t need them.The West Wing is statist propaganda for liberals. House of Cards is statist propaganda for neocons.> Shows like Mr Robot are about the gimmicks. And that\u2019s ok too because you know it\u2019s meant to be silly drama.I actually really appreciate that every hack shown on Mr. Robot had a real world POC and used actually existing tools and techniques. The storyline is hokum and gives hackers a bad name, but black hats are kinda supposed to have a bad name. Elliot is kinda gray hat, but he definitely violated CFAA multiple times and would probably be dead or in jail irl.reply"
    ],
    "link": "https://bits.ashleyblewer.com/halt-and-catch-fire-syllabus/",
    "first_paragraph": "This site features a curriculum developed around the television series, Halt and Catch Fire (2014-2017), a fictional narrative about people working in tech during the 1980s-1990s.The intent is for this website to be used by self-forming small groups that want to create a \u201cwatching club\u201d (like a book club) and discuss aspects of technology history that are featured in this series.There are 15 classes, for a \u201csemester-long\u201d course:\n~ #01 ~ #02 ~ #03 ~ #04 ~ #05 ~ #06 ~ #07 ~ #08 ~ #09 ~ #10 ~ #11 ~ #12 ~ #13 ~ #14 ~ #15 ~Prefer a PDF?Brief guide to class layout:\nCurriculum and website designed by Ashley Blewer.\nsee also \u21a0 source code & site metadata"
  },
  {
    "title": "How to check if your Apple Silicon Mac is booting securely (eclecticlight.co)",
    "points": 5,
    "submitter": "shorden",
    "submit_time": "2025-08-24T23:44:47 1756079087",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://eclecticlight.co/2025/08/21/how-to-check-if-your-apple-silicon-mac-is-booting-securely/",
    "first_paragraph": "There are so many controls in macOS that sometimes you can\u2019t see the wood for the trees. This can leave uncertainty over essentials, such as whether your Apple silicon Mac really is properly secure, or maybe there\u2019s something sinister going on with it? This is a question I\u2019m asked not infrequently, usually when someone has been spreading disinformation or FUD (fear, uncertainty, doubt). So how can you check that your Mac is properly locked down and boots securely?There are two quick checks that cover the essentials. First, open System Information and select the Controller section in Hardware.This provides a brief summary of your Mac\u2019s boot security, which should read as shown above. If you still need to use a kernel extension or similar, your Mac might show Reduced Security with Allow All Kernel Extensions enabled, but you should do everything you can to avoid that.Secure Boot is controlled using Startup Security Utility in Recovery mode, and if you care to start up in that mode, you c"
  },
  {
    "title": "Burner Phone 101 (rebeccawilliams.info)",
    "points": 270,
    "submitter": "CharlesW",
    "submit_time": "2025-08-20T23:25:58 1755732358",
    "num_comments": 98,
    "comments_url": "https://news.ycombinator.com/item?id=44967543",
    "comments": [
      "When I was working at EFF, I started writing (but never finished) a couple of essays along the lines of \"the degree of trackability of mobile phones is an unfortunate accident, and we should fix it\".It basically comes from routing requirements (especially to receive incoming phone calls) combined with billing requirements (to make people pay for their connectivity) combined with the empirical requirement to see which base station a device is connected to, and which other base stations can see it at a given moment.If you aggregate all of that data, then you know a (geographically moderate-resolution) complete history of where almost all people have been at almost all times, and patterns of their habits and whom they probably recurrently spent time with.Not all of this data has to be collectable, because these things could be disaggregated by introducing different protocol layers. For example, you could pay the mobile company for data connectivity, but use cryptographic blinding mechanisms so that it doesn't know which specific subscriber obtained connectivity at a particular place and time. (Those blinding mechanisms could be implemented inside of SIM cards, so the SIM card's task is to cryptographically prove \"I am a SIM card of a current paying subscriber of carrier X\" rather than \"I am SIM card number 42d1b5c0\".) You could have device hardware IDs be ephemeral rather than permanent. Actual messaging and call services could all be \"over the top\" (as phone industry jargon puts it), provided by people who are not the phone company itself.This disaggregation is a straightforward improvement from a privacy point of view because it prevents companies from knowing things about you that they didn't need to know in order to provide services.Meanwhile, in the world we live in, we see governments trying to make it harder to make phones less trackable, by putting legal restrictions on changing hardware addresses, or requiring legal ID in order to establish service. I imagine that an additional cryptographic indirection layer in SIMs to prevent carriers from linking a permanent identifier to a network registration (or specific data use) would also be banned in some places if it were invented.This shouldn't be inevitable. One thing that made me think about this was when there was a little scandal (which I was a small part of) about companies tracking device wifi MAC addresses for commercial purposes. There was a little industry that would try to recognize people and build commercial profiles based on recognizing that the same device was present (in fact, at the time, even if it didn't actually connect to the wifi -- because a typical wifi-enabled mobile device was sending broadcast wifi probe packets that included its MAC address). So Apple was like \"this is a bad use of MAC addresses, which only exist to distinguish devices that happen to be on the LAN at the same time, and perhaps to allow network administrators to assign permanent IP addresses to specific devices\", and they made iPhones randomize wifi MAC addresses for some purposes, mostly fixing that particular issue.We could think just the same way about GSM networks: \"these identifiers exist for specific protocol reasons; using them for device or user tracking is an abuse that should be mitigated technically\".reply",
      "I have no technical knowledge about these, and being cryptocurrency related there will be lots of exasperated huffs, but there are a couple of alternative mobile network related projects: World Mobile and Helium.World Mobile claims 99% coverage of the US, although I think it uses existing networks where there's no native coverage.They're \"interesting\", but only early days, and I don't know how close they come to what you describe for privacy and opposition to data aggregation. Large-geographic-area comms coverage isn't something that there's ever going to be a lot of options for.reply",
      "I was imagining mobile operators that cooperated to some extent with the changes I was proposing, or at least didn't obstruct them. If it's using existing GSM protocols, the IMEI would have to be rotated frequently (and it's not that obvious how to do that without making the connection between the old IMEI and the new IMEI apparent), and the SIM technology would have to change. (What it's trying to prove in a privacy-friendly communications system is more like subscriber entitlement, not subscriber identity!)There's also the \"netheads and Bellheads\" theory from the 1990s which can be taken to say that phone companies would never make technical changes to make themselves collect less data, or to be less helpful to government surveillance. Sometimes I think this is right. I still remember how I took part in a meeting with a mobile phone industry association or industry consortium of some sort about a year before the Snowden stuff. Someone on my side said \"so, let's talk a bit about surveillance issues\", and someone on the other side replied \"sorry, that's something we don't talk about\". Imagine an industry meeting with privacy advocates where the industry people are completely precommitted to not talking about surveillance!reply",
      "Stellar reasoning.Did you ever get to the point of hypothesizing good ways to align incentives to make this happen? It is hard to tell (having not thought much about it) whether this is a \u201csmart well meaning engineers need to make new standards\u201d problem, a \u201cwe need to harness the power of corporate greed problem,\u201d or something else.reply",
      "I seem to remember a discussion here on HN a few years back about a paper which outlined ways to decouple technical identifiers from personal identifiers on mobile networks.My memory is a bit hazy but maybe it was the whitepaper for PGPP[0] that OP mentioned?[0]: https://invisv.com/pgpp/reply",
      "I don\u2019t think it\u2019s possible to align incentives in favor of rolling out such a statement in the US without another coup.reply",
      "One thing I didn't see covered is to never have your \"real phone\" and your \"burner phone\" on you (or in the same location) at the same time while powered.Easy enough to say \"Gee...these 2 phones are always together or nearby when activated\" or \"this phone shuts off right before this one powers up\".Although, I suspect there are a few other ways to determine identity easier.  Such as tracking the device identifier and then looking up nearby public facing cameras.reply",
      "\"If you're going to keep your phone in a bag of potato chips, then keep your phone in a bag of potato chips\" --Terminator: Dark Fate (2019)  Carl the T800.reply",
      "So many online services use the proximity of phones to determine things like related persons and related accounts. Facebook is notorious for this. In one building I lived at Facebook would constantly show me the names of everyone coming in and out as \"You might know this person\" even though I had no idea who they were.reply",
      "Also, never power up or down, or switch in or out of airplane mode on your burner while at home (or work). Cellular network disconnection and connection events are rare and hence notable.reply"
    ],
    "link": "https://rebeccawilliams.info/burner-phone-101/",
    "first_paragraph": "\n          Hosted by the Brooklyn Public Library, this Burner Phone 101 workshop introduced participants to phone-related risk modeling, privacy-protective smartphone practices, the full spectrum of burner phone options, and when to leave phones behind entirely.\n        In August 2025, I hosted a Burner Phone 101 Workshop at the Brooklyn Public Library. Below is a summary of the workshop with key points in bold and additional resources that participants helped crowdsource.Before the workshop began, we set the collective tone by sharing the goals, secret goals, and anti-goals. This helped participants know what to expect, created space for deeper learning, and reinforced the boundaries that kept the workshop safe and supportive. The goals were to learn about burner phones and have fun. The secret goals were to learn the limits of burner phones, connect them to broader digital privacy practices, and build confidence to share these lessons with loved ones. The anti-goals were just as impo"
  },
  {
    "title": "Cloudflare incident on August 21, 2025 (cloudflare.com)",
    "points": 130,
    "submitter": "achalshah",
    "submit_time": "2025-08-22T04:14:10 1755836050",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44980940",
    "comments": [
      "> This system will allot network resources on a per-customer basis, creating a budget that, once exceeded, will prevent a customer's traffic from degrading the service for anyone else on the platformHow would this work practically? If a single client is overflowing the edge router queues you are kindof screwed already? Even if you dropped all packets from that client you would need to still process the packets to figure out what client they belong to before dropping the packets?I guess you could somehow do some shuffle sharding where a single client belongs to a few IP prefixes and when that client misbehaves you withdraw those prefixes using BGP to essentially black hole the network routes for that client. If the shuffle sharding is done right only the problem client will have issues as other clients on the same prefixes will be sharded to other prefixes.reply",
      "Perhaps they drop the client's flows on the host side.reply",
      "I don\u2019t understand? The issue is that a client/customer outside of cloudflares control DOSed one of their network links. Cloudflare has no control on the client side to implement rate limiting?reply",
      "I think you misunderstand the flow of traffic here. The data flow, initiated by requests coming from AWS us-east-1, was Cloudflare towards AWS, not the other way around. Cloudflare can easily control where and how their egress traffic gets to the destination (as long as there are multiple paths towards the target) as well as rate limit that traffic to sane levels.reply",
      "Ah I see now. Yes in that case they could just reply with 429 codes or just not reply at all.reply",
      "I think you're overthinking this. Just having a per (cloudflare) customer rate limit would go a long long way.reply",
      "There was definitely a recurring pattern at AWS where a single customer would trigger latent bugs/undercapacity resulting in outages. Postmortems would often recommend developing per-customer observability and mitigation.reply",
      "It\u2019s gonna turn out it was one guy on one machine calling \u201cpnpm install\u201d on a fast machine with a 100gbps uplink.reply",
      "Can we stop with the 2015 jokes already?reply",
      "I\u2019ve actually had an npm install that failed on my ISP but succeeded with Cloudflare VPN and the OP comment was more or less the explanation.reply"
    ],
    "link": "https://blog.cloudflare.com/cloudflare-incident-on-august-21-2025/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Clearcam \u2013 Add AI object detection to your IP CCTV cameras (github.com/roryclear)",
    "points": 162,
    "submitter": "roryclear",
    "submit_time": "2025-08-24T11:34:15 1756035255",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=45003420",
    "comments": [
      "Also check out frigate (https://github.com/blakeblackshear/frigate)reply",
      "Also discussed here on HN greatly:https://news.ycombinator.com/item?id=44794508reply",
      "So the app is free to download from the Apple site, and will run free, and is open source, but you have in-app purchases, and certain features can\u2019t be used until you pay for them, is that right?What are the paid features and what are the costs? Do I have to install the app to see the list of paid features and costs?You might get a better response from HN if you give us more info up front.reply",
      "Paid features are Live and event clip viewing over the internet, and receiving iOS notifications. You're paying for use of my server in those cases though, not for features I've made closed source. You can edit the code to use your own server if you wish too.I'm new to HN and thought shilling the paid stuff violates the rules, so I didn't mention them.reply",
      "(I'm a mod here) - it's fine to talk about paid features, as long as it's clear which ones are paid and which ones not.The only thing that wouldn't be fine is to post a Show HN with no way to try the product out (https://news.ycombinator.com/showhn.html) and you're fine on that part.reply",
      "\"I'm new to HN and thought shilling the paid stuff violates the rules, so I didn't mention them.\"HN ain't a non profit charity, but is the forum of a venture capitalist company, so talking about paid things does not violate any rules.reply",
      "Paying for things does cause some folks to champ at the bit, though, so his assessment is not unwarranted.reply",
      "Am I reading your README correct, that in order to sign up to use the app on Android, you have to install and sign up using an iOS device (using Apple's payment system) and then login on Android using the credentials you created?reply",
      "Yeah sorry that\u2019s confusing, I need to change or remove it until I\u2019ve a payment system setup.There is an unfinished but functional APK and android project in the repo, but it\u2019s not on the Google Play store yet, their approval process for new individual devs is longreply",
      "Anyone can recommend a good quality camera without spyware and ideally open sw stack.\nI am willing to do it myself with little soldering etc. \nthat\u2019s one rabbit hole didn\u2019t enter yetreply"
    ],
    "link": "https://github.com/roryclear/clearcam",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Add object detection, tracking, and mobile notifications to any RTSP Camera or iPhone.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.https://apps.apple.com/app/clearcam/id6743237694\n\n  \u00a0\u00a0\u00a0\n  \nhttps://x.com/RoryClear/status/1959249250811785405Sign ups on android are not yet supported.\nIn the meantime, please refer to the How to Sign Up on iOS section and use the user ID on android.\n        Add object detection, tracking, and mobile notifications to any RTSP Camera or iPhone.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "How many paths of length K are there between A and B? (2021) (horace.io)",
    "points": 7,
    "submitter": "jxmorris12",
    "submit_time": "2025-08-24T20:09:12 1756066152",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://horace.io/walks",
    "first_paragraph": "Here's a (surprisingly interesting) programming problem: Given a directed unweighted graph with V vertices and E edges, how many paths of length K are there from node A to node B? Paths may visit the same node or edge multiple times[1]. To avoid dealing with very large numbers, assume that we're computing our answer modulo a large prime.\n\n\n\n\nFigure\n\nThere are 2 paths of length 2 from node A to node B\n\ncluster_first\n\nGraph\n\n\ncluster_second\n\nPath 1\n\n\ncluster_third\n\nPath 2\n\n\n\nA1\n\nA\n\n\n\nC1\n\n\n\n\nA1->C1\n\n\n\n\n\nD1\n\n\n\n\nA1->D1\n\n\n\n\n\nB1\n\nB\n\n\n\nC1->B1\n\n\n\n\n\nD1->B1\n\n\n\n\n\nA2\n\nA\n\n\n\nC2\n\n\n\n\nA2->C2\n\n\n\n\n\nD2\n\n\n\n\nA2->D2\n\n\n\n\n\nB2\n\nB\n\n\n\nC2->B2\n\n\n\n\n\nD2->B2\n\n\n\n\n\nA3\n\nA\n\n\n\nC3\n\n\n\n\nA3->C3\n\n\n\n\n\nD3\n\n\n\n\nA3->D3\n\n\n\n\n\nB3\n\nB\n\n\n\nC3->B3\n\n\n\n\n\nD3->B3\n\n\n\n\n\nThis problem is fairly standard -  many of you may have seen it or heard it in an interview. Personally, I've seen this problem on Hackernews in some form at least three times, here, here, and here.I found this comment from the last link particularly interesting.\nHe states of the m"
  },
  {
    "title": "Stepanov's biggest blunder? The curious case of adjacent difference (mmapped.blog)",
    "points": 37,
    "submitter": "signa11",
    "submit_time": "2025-08-21T11:30:59 1755775859",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44971451",
    "comments": [
      "I think it's also because C++ has no generic concept of \"zero\"; otherwise one could have defined the first element of adjacent_difference(v) as v(1)- zero<typeof(v)>, and it would have been type-stable.reply",
      "T{} is now sort of that, but it didn't exist yet when adjacent_difference was written.reply",
      "Sort of. T {} is IIUC C++ \"zero initialization\" but this doesn't actually promise to give us the zero (additive identity) of T but instead to basically smash all T's constituent elements to zero which may not have that effect. This does what you meant for simple types like the signed integers or floats at least.reply",
      "I think that would fix the issue at the type level (up to a point; for unsigned types, the \"correct\" type for the result of a subtraction is underdetermined -- it could be any of {same type, larger signed type, same-size signed type} depending on the circumstances).But I think the more serious niggle is the fact that that first element shows up in the output at all. OTOH, I suppose you could write a discard_first iterator adaptor that ignores the first write and increment and passes the rest through to the underlying output iterator.reply",
      "For anyone wanting to go deeper, Knuth's Concrete Mathematics covers the discrete calculus topics mentioned here (and much more).reply",
      "This is also known as \"The Fundamental Theorem of Stream Calculus\" in stream calculus. Using coinduction for an (infinite) stream sigma, eg    sigma(0)      = head(sigma)\n    sigma'        = tail(sigma)\n    (a ++ sigma)' = sigmareply",
      "partial_sum has the same problems (eg when T - T isn't T) and would be more generic if it took the initial accumulator as a separate parameter (and then it and a more generic adjacent_difference would be symmetrical again)reply"
    ],
    "link": "https://mmapped.blog/posts/43-stepanovs-biggest-blunder",
    "first_paragraph": "If you have ever tried using the std::adjacent_difference algorithm in c++,\nI\u2019m sure it left you puzzled.\nAs the name suggests, this algorithm computes differences between adjacent elements of the input sequence,\nbut it does one more thing: it copies the first element of the input sequence into the output sequence unmodified.\nThe following example demonstrates how to apply the algorithm to delta-compress a postings list of document identifiers that contain a search term\n(the example is contrived since Google developed much more sophisticated posting list compression techniques).\n\u2295\n  Delta-compressing a posting list using the std::adjacent_difference algorithm.\n  The compressed version might require less memory when encoded using variable-length integers.\n\n#include <iostream>\n#include <numeric>\n#include <vector>\n\n// prints:\n// 12586 426 548 110 566\nint main() {\n    // Sorted list of documents containing a word.\n    std::vector<int> postings{{12586, 13012, 13560, 13670, 14236}};\n    std:"
  },
  {
    "title": "NASA's Juno mission leaves legacy of science at Jupiter (scientificamerican.com)",
    "points": 59,
    "submitter": "apress",
    "submit_time": "2025-08-22T00:42:44 1755823364",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=44979906",
    "comments": [
      "This is a fantastic recap of everything Juno discovered and the value of this kind of mission - there\u2019s multiple discoveries in here that are at odds with our theoretical understanding of planetary formation, physics, and chemistry that can inform new science moving forward. One that stuck out to me in particular was that Jupiter\u2019s massive magnetic field isn\u2019t generated by a metallic core like we expected, but rather Hydrogen under pressures sufficient to tear free electrons.Combine that with the fact that the Juno probe has now more than doubled its expected life, and this whole mission serves as as good of an argument for continuing to fund NASA as you\u2019re going to see.reply",
      "These are the pictures from the camera, incredibly beautiful stuffhttps://science.nasa.gov/gallery/junocam-images/reply",
      "https://archive.ph/pwVDLreply",
      "> the solar system\u2019s undisputed heavyweightNow I feel the urge to dispute this!reply",
      "It's an odd choice of words since\n1. Most people know it's the largest and heaviest planet\n2. They didn't specify planet but are still ignoring the sun, which is 1000x Jupiter's mass.reply",
      "don't be so hard on yourself, there are plenty of low-calorie alternatives nowadaysreply",
      "Ever since I've seen the Apollo 11 press conference, I don't know what to think: https://youtu.be/BI_ZehPOMwIreply",
      "why? it\u2019s a press conference of the people with the most eyes on them in the world, not a celebrationreply",
      "Aren't NASA considering the proposal to rendez-vous with 3I/ATLAS (aka C/2025 N1 ATLAS)??? [1]1: https://www.sciencealert.com/nasa-probe-could-intercept-inte...reply",
      "No, they are not, because the probe doesn't have anywhere near enough fuel to do this. I suggest stopping use of any news source you have that would print this crap.reply"
    ],
    "link": "https://www.scientificamerican.com/article/how-nasas-juno-probe-changed-everything-we-know-about-jupiter/",
    "first_paragraph": "August 19, 202513 min readNASA\u2019s Juno Mission Leaves Stunning Legacy of Science at JupiterThe Juno spacecraft has rewritten the story on Jupiter, the solar system\u2019s undisputed heavyweightBy Robin George Andrews edited by Clara MoskowitzJupiter's Great Red Spot glows in this image created from Juno observations.NASA/JPL-Caltech/SwRI/MSSS/Gerald Eichstadt/Sean Doran \u00a9 CC NC SAThe NASA spacecraft tasked with uncovering the secrets of Jupiter, king of the planets, is running out of time. The Juno probe has already survived far longer than anticipated\u2014its path around the solar system\u2019s largest planet has repeatedly flown it through a tempest of radiation that should have corroded away its instruments and electronics long ago. And yet here it is: one of the greatest planetary detectives ever built, still pirouetting around Jupiter, fully functional.But it may not be for long. September 2025 marks the end of Juno\u2019s extended mission. Although it could get another reprieve\u2014an extended-extended "
  },
  {
    "title": "Iterative DFS with stack-based graph traversal (2024) (dwf.dev)",
    "points": 20,
    "submitter": "cpp_frog",
    "submit_time": "2025-08-21T17:09:08 1755796148",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://dwf.dev/blog/2024/09/23/2024/dfs-iterative-stack-based",
    "first_paragraph": "Depth-first search (DFS) on a graph (binary tree or otherwise) is most often implemented recursively, but there are occasions where it may be desirable to consider an iterative approach instead. Such as when we may be worried about overflowing the call stack. In such cases it makes sense to rely on implementing DFS with our own stack instead of relying on our program's implicit call stack. But doing so can lead to some problems if we are not careful.Specifically, as noted in another blog post, it is easy to fall into the trap of using a stack haphazardly and conducting a graph search that is not truly DFS. The issue may go undetected in some problems, but algorithms that rely on a true DFS may fail (e.g., Kosaraju's and Tarjan's algorithms for finding strongly connected components). The linked blog post above is very effective at pointing out the potential issues, but it's quite terse in its treatment. Thus, the linked blog post has been reproduced below for ease of reference (unaltere"
  }
]