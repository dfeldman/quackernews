[
  {
    "title": "Nobody has a personality anymore: we are products with labels (freyaindia.co.uk)",
    "points": 138,
    "submitter": "drankl",
    "submit_time": "2025-07-06T22:16:37 1751840197",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=44484595",
    "comments": [
      "Decades ago in my first abnormal psych course, the prof warned us that there was an almost iron-clad law that students will immediately start self diagnosing themselves with \u201cweak\u201d versions of every disorder we learn about. In my years since then, it has absolutely held true and now is supercharged by a whole industry of TikTok self-diagnoses.But there are a few things we can learn from this:- if you give people the chance to place a label on themselves that makes them feel unique, they\u2019ll take it.- if you give people the chance to place a label on themselves to give a name/form to a problem, they\u2019ll take it.- most mental disorders are an issue of degree and not something qualitatively different from a typical experience. People should use this to gain greater empathy for those who struggle.reply",
      "It's interesting because there are two diametrically opposed ways to interpret what you saidOne is - everybody thinks they have disorders, so just ignore that feeling it'll mess with you.The other is - everybody thinks they have minor version of disorders, because we all do, we live on continuums, and therefore we should probably all think about it morereply",
      "In my experience the truth is somewhere in the middle. It's helpful to neither completely ignore nor ruminate over one's traits, but just _be aware_ of them.It's been very helpful for me to pay attention to and think about how my own personality compares to others'. For example, I tend to be a people-pleaser, but I used to think that everyone was just as people-pleasing as me, which only reinforced the people-pleasing because I didn't feel right putting my own needs first when everyone else was already sacrificing their own needs (or so I assumed).At the same time, medicalizing these things paints them as \"abnormal\" disorders that need to be \"cured\", overlooking any of the positives these traits bring. When it comes to my people-pleasing, I like it about myself that I care about others. As long as I recognize that it sometimes comes at my own expense, I can begin to make more conscious decisions about when to allow the people-pleasing to flow versus when to try to subdue it.reply",
      "Disorders are labels for things which significantly negatively impact people\u2019s lives.  Thinking of them in terms of a spectrum generally means stretching a label past the point of meaning.reply",
      "The other idea is that people who go into the field are screwed up themselves... and are trying to work out how to treat/understand themselves.reply",
      "The lovable aphorisms we had for people with character quirks were largely from our original support systems. What no one is talking about is the reason therapy-talk has become so pervasive is because all those support systems: family, friends, and local communities (religious or otherwise), have all degraded so severely for most that therapy is the only option for reaching out and getting help.reply",
      "except they weren't really \"support systems\"i mean they were, if you got lucky.If you were neurotypical; if you bought in to the local religious sect's particular flavour and embraced it wholeheartedly; if you followed the other local cults of sports fandoms; if you were lucky enough to either have family without their own trauma that didn't take it out on you OR decided to repress it in exactly the same way that they did and just simply passed it forward or didn't talk about it.i don't know what the ratios are but a LOT of people fell through the cracks.it's just that the birth rate was high enough to continue the population growth, and there were socially acceptable ways to ignore the inconvenient problems (see: https://en.wikipedia.org/wiki/Rosemary_Kennedy)it's why there's now suddenly an influx of ADHD and Autism diagnosis - because in the past anyone outside of the norm who wasn't lucky to do one of the things above was simply ignored, beaten, or died.now the stigma is gone and we're finding EXPLICIT paths to treatment, tolerance, and embracement of mental health, neuroatypical brains, spectrums, etc. Is there overpathologizing? Maybe? Hard to know! The stigmas still aren't gone. Go read the comments on any video providing tips on how to parent children on the spectrum and see neurotypicals freaking out about how soft the current generation is.the western world seems to have peaked in tolerance in the 2010s, and is now backsliding into authoritarianism and fascism. that's trying to recreate a lot of those original support systems (by destroying the new ones). It's a bold plan, let's see how it happens.reply",
      "> it's why there's now suddenly an influx of ADHD and Autism diagnosis - because in the past anyone outside of the norm who wasn't lucky to do one of the things above was simply ignored, beaten, or died.I think you're understating how well those people were incorporated into society. My grandfather was born in the 20s and was described as quite \"high strung\", was amazing with technology, would repair anything, and even used to build his own farm machinery. These days he'd definitely be called severely anxious, and probably labelled as being on the spectrum. Yet he was part of a community, farmed his whole life, and built a family. People knew his quirks and compensated for them.reply",
      "I agree with everything you said except for the last paragraph.The people who, according to your theory, want to reverse the tolerance trend and slide towards fascism/authoritarianism didn't pop out today. They existed and lived in society in the 2010s too. So, from a logical standpoint, what changed?reply",
      "> what changed?The algorithms are promoting those views?reply"
    ],
    "link": "https://www.freyaindia.co.uk/p/nobody-has-a-personality-anymore",
    "first_paragraph": ""
  },
  {
    "title": "Bitchat \u2013 A decentralized messaging app that works over Bluetooth mesh networks (github.com/jackjackbits)",
    "points": 58,
    "submitter": "ananddtyagi",
    "submit_time": "2025-07-07T00:05:46 1751846746",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=44485342",
    "comments": [
      "Very nice! Could this be published in the App Store, or does it use any APIs Apple considers off-limits?I'm regularly frustrated by modern phone's complete inabilities to allow any communication when outside of mobile network or Wi-Fi coverage, not even within the two large walled gardens.It would be so easy for Apple to extend iMessage to work peer-to-peer, at least between people that have already messaged each other before and while both screens are on. That's literally how AirDrop works, and having to send a \"Notes\" text back and forth is just silly.reply",
      "I'd much rather Apple allow running something like this (open source) myself rather than use their \"just trust me bro\" store.reply",
      "FYI on X there is a TestFlight link to try it:\nhttps://x.com/jack/status/1941989435962212728Surprised to see Jack pushing code himself. Love to see it.reply",
      "Is there a link to the TestFlight itself?reply",
      "https://testflight.apple.com/join/QwkyFq6zreply",
      "https://testflight.apple.com/join/QwkyFq6zreply",
      "Wasn\u2019t sure if a random TestFlight link would be safe/wise to share, so shared original source.reply",
      "Looks pretty interesting.From what I can see, it's a native IOS/MacOS app (SwiftUI). I don't see an Android version.Also seems pretty spartan, but it looks like it could be embedded in \"friendlier\" apps.reply",
      "No android but \u201ccan\u201d be built?> protocol is designed to be platform-agnostic. An Android client can be builthttps://github.com/jackjackbits/bitchat?tab=readme-ov-file#a...reply",
      "As long as it's Swift, I guess. The Protocols files seem \"agnostic.\" I think the lower-level hardware files might need to be rewritten, though, so he's saying that an Android developer could write an app that incorporates the protocol.If I were an Android developer, though, I'd just use the Swift files as a requirements spec, and write it native.reply"
    ],
    "link": "https://github.com/jackjackbits/bitchat",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        bluetooth mesh chat, IRC vibes\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.A secure, decentralized, peer-to-peer messaging app that works over Bluetooth mesh networks. No internet required, no servers, no phone numbers - just pure encrypted communication.This project is released into the public domain. See the LICENSE file for details.Install XcodeGen if you haven't already:Generate the Xcode project:Open the generated project:Open the project in Xcode:Select your target device and runbitchat uses an efficient binary protocol optimized for Bluetooth LE:For detailed protocol documentation, see the Technical Whitepaper.The protocol is designed to be platform-agnostic. An Android client can be built using:\n        bluetooth mesh chat, IRC vibes\n       There"
  },
  {
    "title": "Intel's Lion Cove P-Core and Gaming Workloads (chipsandcheese.com)",
    "points": 68,
    "submitter": "zdw",
    "submit_time": "2025-07-06T22:27:39 1751840859",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://chipsandcheese.com/p/intels-lion-cove-p-core-and-gaming",
    "first_paragraph": ""
  },
  {
    "title": "Building the Rust Compiler with GCC (fractalfir.github.io)",
    "points": 89,
    "submitter": "todsacerdoti",
    "submit_time": "2025-07-06T21:46:02 1751838362",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44484363",
    "comments": [
      "It may not seem like it, but this is impressive progress. Getting a compiler to bootstrap at all is an accomplishment, especially for Rust since that depends on so many things working. Once it can reliably bootstrap, a lot of performance-improving steps can begin. Congrats!reply",
      "Really great read.Someone mentioned recently that the slowness of rustc is in large part due to llvm. I know that is probably orthogonal to the work here, but I do like the idea of building the compiler with different toolchains, and that there may be follow on effects down the line.reply",
      "I just started playing with rust again today.  Godspeed.reply"
    ],
    "link": "https://fractalfir.github.io/generated_html/cg_gcc_bootstrap.html",
    "first_paragraph": "If you know one thing about me, it is that I love working on the Rust compiler. Some people kayak, travel or play guitar - and I stare at assembly, trying to figure out what I broke.This summer, I am taking on quite a large task: bootstrapping the Rust compiler using `cg_gcc`What does that mean? \"bootstrapping\" is simply a name given to the Rust compiler build process.So, what I am really trying to do is build a Rust compiler, without using LLVM - and using GCC instead.The bootstrap process is quite complex, and split into 3 stages.First, we use a pre-existing, LLVM-based Rust compiler to build rustc, and the GCC-based codegen.Then, we take that GCC-based codegen, and rebuild the Rust compiler using GCC.As a sanity check, we built the compiler *again*, this time using stage2.The idea here is quite simple: if stage1 and stage2 produce identical executables, then they behave identically, which means the rust compiler build with GCC is (more or less) equivalent to the one built with LLVM."
  },
  {
    "title": "Show HN: I wrote a \"web OS\" based on the Apple Lisa's UI, with 1-bit graphics (lisagui.com)",
    "points": 252,
    "submitter": "ayaros",
    "submit_time": "2025-07-06T18:32:55 1751826775",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=44482965",
    "comments": [
      "What's up with the clock? Mine was two minutes off of local system time.reply",
      "The Lisa doesn't have square pixels, so the canvas is scaled to be 1.5x as high as it is wide. This generally looks fine on high-dpi displays, because there's technically twice as much space to render with (pixels are 2px wide by 3px high). However, things will look distorted on a lower resolution display (where pixels are 1px wide by 1.5px high). That's just a compromise I made when designing this.The good news is, if you have a large enough low-dpi display, and you make the window big enough, the automatic integer scaling settings will kick in, and the pixels themselves will be displayed larger. This can be forced via the preferences app (under the display options). If you screw this up, then restart LisaGUI while holding the shift key to reset the scaling settings.EDIT: Unrelated to this, there are a couple minor bugs with PWAs on iOS relating to the positioning of the canvas. These can be resolved by rotating your device to a different orientation and then rotating it back to the original position... but this is annoying.EDIT 2: To close windows, just double click the icon in the titlebar! This \"collapses the window back into an icon.\"reply",
      "How do you handle dynamic window/font scaling regardless of browser size (you get it for free with html mostly).reply",
      "It's integer scaling; it involves changing the width, height, and style attributes of the canvas dynamically. I have a whole class that handles this, and let me tell you it took a lot of effort to get working properly and involved juggling around quite a few parameters, including the DPI, the border width, the pixel aspect ratio, and more. I had to use a ResizeObserver object to detect changes in the size of the DOM's body element.To get the canvas to be consistently smooth, I had to apply a lot of contrast using a CSS filter, and I set image-rendering to pixelated, IIRC.reply",
      "Is keyboard not supposed to work? E.g. tabbing through the widgets.reply",
      "The Lisa doesn't have an alt-tab function for Window management, so I haven't added one. Also, it would be difficult to use those keys in particular because it would conflict with your system's alt+tab keyboard shortcut.When you select text in a textbox, the keyboard should input text. Also, individual menu items have their own keyboard shortcuts. If you're on a PC, it defaults to using the Control key as the \"Apple\" key. If your on a Mac, it defaults to using the Command key. This option can be changed in the preferences app in the \"Set Conveniences\" pane.reply",
      "I never spent a lot of time using Lisa, but I got several opportunities to kick the tires as a Mac repair tech in the early 90s. I even fixed a Lisa or two, and converted one to a \"Mac XL\". You've captured the UI really nicely, and it was fun to click around. Good job!reply",
      "The shadow text style and fatbits editor in the Preferences app really took me back. Other than a lack of close buttons on windows, it's remarkable that you can strip away 40 years of UX \"innovation\" and the result is still productive and intuitive.(Edit: Menus staying open after one click was a welcome improvement that I think came much later.)reply",
      "Yes, sticky menus arrived much later. I put the extra effort to add them here because everyone's so used to them now. Both options work - you can single-click to keep a menu open, or you can hold down the mouse and drag to open a menu which closes when you release the mouse.There's at least one Mac extension I know of that lets you use sticky menus on earlier versions of Mac OS, like System 6. I figured I'd backport that feature a little further, so to speak...EDIT: Also, forgot to mention it in this reply, but you double click the titlebar icon to close the window.reply",
      "You can double-click on the icon in the top left corner of a window to close it. (Which, I guess, is just the shorthand for File > Set Aside.)reply"
    ],
    "link": "https://alpha.lisagui.com/",
    "first_paragraph": ""
  },
  {
    "title": "There's a COMPUTER inside my DS flashcart [video] (youtube.com)",
    "points": 22,
    "submitter": "surprisetalk",
    "submit_time": "2025-07-07T00:04:36 1751846676",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.youtube.com/watch?v=uq0pJmd7GAA",
    "first_paragraph": ""
  },
  {
    "title": "Data on AI-related Show HN posts (ryanfarley.co)",
    "points": 223,
    "submitter": "rfarley04",
    "submit_time": "2025-07-04T10:35:04 1751625304",
    "num_comments": 133,
    "comments_url": "https://news.ycombinator.com/item?id=44463249",
    "comments": [
      "Yeah i am so sick and tired. It was so refreshing to read HN and always find something interesting, now its tiresome, AI marketing everywhere and comments from people that doesn't even like to program and they now can develop a todo list app at the expense of 200$ for whatever claude has release that week.. sad.reply",
      "Anything that gets posted to HN when you\u2019re born is normal and ordinary and is just a natural part of the way the world works.Anything that gets posted to HN between when you\u2019re fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it.Anything posted to HN after you're thirty-five is against the natural order of things.reply",
      "The GP wasn\u2019t complaining about there being an AI hype. They were complaining that the front page is oversaturated by said hype.I\u2019ve been on HN since near the beginning (under a different user name originally). And there have been quite a few trends rise and fall on here. But none of them were as intense as this AI hype currently is.In fact it\u2019s not even AI in the more general sense, it\u2019s almost entirely just LLMs that get discussed. There\u2019s so much more going on outside of LLMs but all anyone is talking about on HN is natural language tools.reply",
      "I imagine that's because LLMs are of most interest to the Hacker News crowd: they can help write code, and you can build systems on top of them that can \"understand\" and respond in human language.Generative image / video / audio models can produce output in image, video and audio. Those have far less applications than models that can output text, structured data and code.reply",
      "> In fact it\u2019s not even AI in the more general sense, it\u2019s almost entirely just LLMs that get discussed.\"AGI is right around the corner\" \"No it's not\" \"Yes it is, LLMs are the future.\" \"We don't even know if AGI is possible.\" \"LLMs are the future.\" \"No they aren't.\" \"AGI is right around the corner...\"or\"LLMs are really useful.\" \"No they're not\" \"Yes they are.\" \"No they aren't.\" with a little bit of \"They sucked the last time I used them.\" \"Did you use them recently?\" \"That's what someone said last time.\" \"But LLMs are really useful\" ...over and over and over.It isn't even that it's mostly just LLMs being discussed, it's how they're begin discussed, they're effectively just a proxy for optimists and pessimists to argue over which worldview is better.If we were talking about AI in general and not LLMs, the same conversation structures would still pop up.reply",
      "What a coincidence! It\u2019s just like music! Have you heard the noise kids are listening to these days?reply",
      "I know what you\u2019re trying to do. People say this about life in general. But that really is not what is going on here.reply",
      "Yeah, you're right. I should do more blockchain development.reply",
      "Wait, how HN is 40 years oldreply",
      "I\u2019m not so sure about that number of 35. Might be closer to 30.reply"
    ],
    "link": "https://ryanfarley.co/ai-show-hn-data/",
    "first_paragraph": "The idea for this article didn't exist in my brain before this morning. But there I was, scrolling the New page and even more tired of all the AI-related Show HN posts than usual. I was confident that their numbers were multiplying and wanted proof. Exactly how much more AI crap is on my lawn compared to last year?Full disclosure: I'm not a data guy. Everything below was off the top of my head. Not carefully structured or considered. I was grumpy, caffeinated, and avoiding work. I would love nothing more than for someone to show me some dumb error in my SQL queries that makes everything below meaningless.I am NOT interested in debating the value of AI (LLMs, whatever). Mainly because I don't hate it/them nearly as much as this post suggests! I used Cursor + Claude to create the Chartjs visualizations in this article, dammit. What I hate is that a Show HN post used to represent someone's hard work or passion project. And that 100% justified the self-promotion IMO. But since the introduc"
  },
  {
    "title": "Jane Street barred from Indian markets as regulator freezes $566 million (cnbc.com)",
    "points": 254,
    "submitter": "bwfan123",
    "submit_time": "2025-07-06T14:03:51 1751810631",
    "num_comments": 142,
    "comments_url": "https://news.ycombinator.com/item?id=44480916",
    "comments": [
      "According to Indian regulators, every trading day Jane Street would:1) buy large volumes of stocks and/or stock futures that are part of an index tracking India\u2019s banking sector, early in the day,2) subsequently place large options trades, betting that the index would decline or volatility would spike later in the day, and3) later in the day, cash out of the large long positions, dragging the index lower, making far more money on the options trades than on the long positions.Jane Street can and likely will claim the firm was only arbitraging away pricing inefficiencies, nothing more, nothing less. It was just business as usual, etc., etc.However, given the scale of the operation, Jane Street's actions sure look like textbook market manipulation. Calling it like I see it.reply",
      "I don\u2019t know if this is helpful, but when I worked at Scotttrade, I vividly remember my coworker telling me that this is what they did with the money too. I remember being surprised to hear that it flowed out in the morning and flowed back in in the evening. I never understood why that would make sense till I read your comment here.It\u2019s all hearsay; I\u2019m just reporting what I heard. I don\u2019t know the implications of it, but maybe this isn\u2019t exactly uncommon behavior, even if it\u2019s market manipulation.The coworker said that the money flowed overseas too, if that helps contextualize it. No SEC, no problem, right?Looks like Jane Street is an American firm, so, this all lines up and corroborates what you\u2019re saying. What we\u2019re seeing is probably the first time a government other than the US has reacted to this behavior.reply",
      "Don't know about Jane Street, but that sounds like a general problem.If options & futures are more liquid than the underlying, someone will be tempted to nudge the underlying.Bond ETFs and their options chains seem like another locale where this could happen.reply",
      "> If options & futures are more liquid than the underlying, someone will be tempted to nudge the underlying.\n\nThis is a weird statement.  Why would liquidity matter here?  As a point of reference there are generally two types of options: (1) options that depend directly upon the underlying, like a Tesla stock option, or (2) options that depend indirectly upon the underlying, like options on S&P 500 index futures.  The liquidity in category 2 is normally tiny.  Cat 1 normally has far less liquidity than the underlying.Why is the adjective \"more\" important here?  Even if less, the opportunity to profit is still good, assuming that one chooses the path of market manipulation.reply",
      "What matters is the volume rather than the liquidity per se, but the two are generally pretty well correlated. The point is that moving a market costs money, making a trade moves the market against that trade, so even if someone is deliberately trying to move a market they'll pay more than they could ever hope to recoup. The exception is when there's a derivative market that has more volume than the underlying - in that case profitable manipulation becomes possible, as you can spend to move the underlying, losing money, but making more money on the derivatives where you'd bought the other side.reply",
      "I have a suspicion this has been happening with a particular MAG7 stock these last few months, but I can't fully convince myself such a large stock can be manipulated like that.reply",
      "At least one of those stocks tends to have a comparatively thin order book.reply",
      "Google tells me:    > Coined in 2023, the group consists of Alphabet, Amazon, Apple, Meta Platforms, Microsoft, Nvidia, and Tesla.\n\nWhich one?reply",
      "Tesla",
      "Oh?reply"
    ],
    "link": "https://www.cnbc.com/2025/07/04/indian-regulator-bars-us-trading-firm-jane-street-from-accessing-securities-market.html",
    "first_paragraph": ""
  },
  {
    "title": "I extracted the safety filters from Apple Intelligence models (github.com/bluefalconhd)",
    "points": 259,
    "submitter": "BlueFalconHD",
    "submit_time": "2025-07-06T19:50:02 1751831402",
    "num_comments": 159,
    "comments_url": "https://news.ycombinator.com/item?id=44483485",
    "comments": [
      "Some of the combinations are a bit weird,\nThis one has lots of stuff avoiding death....together with a set ensuring all the Apple brands have the correct capitalisation.  Priorities hey!https://github.com/BlueFalconHD/apple_generative_model_safet...reply",
      "Interesting that it didn't seem to include \"unalive\".Which as a phenomenon is so very telling that no one actually cares what people are really saying. Everyone, including the platforms knows what that means. It's all performative.reply",
      "It's totally performative. There's no way to stay ahead of the new language that people create.At what point do the new words become the actual words? Are there many instances of people using unalive IRL?reply",
      "> There's no way to stay ahead of the new language that people create.I'm imagining a new exploit: After someone says something totally innocent, people gang up in the comments to act like a terrible vicious slur has been said, and then the moderation system (with an LLM involved somewhere) \"learns\" that an arbitrary term is heinous eand indirectly bans any discussion of that topic.reply",
      "Hey I was pro-skub waaaay before all the anti-skub people switched sides.reply",
      "Skub is a real slur tho so that one doesn\u2019t workreply",
      "Isn't that a reference to a 10 or 20 year old web comic?reply",
      "How dare you use that word. My parents died in the Eastasin Civil war so that I could live freely without you people calling us that.reply",
      "I'm pretty sure this can work human moderators rather than an LLM, too.reply",
      "Most of the human moderators hired by OpenAI to train LLMs, many of them based in Africa and South America, were exposed to disturbing content and have been deeply affected by it.Karen Hao interviewed many of them in her latest bestselling book, which explores the human cost behind the OpenAI boom:https://www.goodreads.com/book/show/222725518-empire-of-aireply"
    ],
    "link": "https://github.com/BlueFalconHD/apple_generative_model_safety_decrypted",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Decrypted Generative Model safety files for Apple Intelligence containing filters\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Decrypted Generative Model safety files for Apple Intelligence containing filterscryptography is the only dependency required to run the decryption script. You can install it using pip:To retrieve the encryption key (generated by ModelCatalog.Obfuscation.readObfuscatedContents) for the overrides, you must attach LLDB to GenerativeExperiencesSafetyInferenceProvider ( /System/Library/ExtensionKit/Extensions/GenerativeExperiencesSafetyInferenceProvider.appex/Contents/MacOS/GenerativeExperiencesSafetyInferenceProvider). Also it is important that this is Xcode's LLDB, not the default macOS one or LLVM's lldb. The method I recommend to "
  },
  {
    "title": "Centaur: A Controversial Leap Towards Simulating Human Cognition (insidescientific.com)",
    "points": 13,
    "submitter": "CharlesW",
    "submit_time": "2025-07-06T23:12:05 1751843525",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44484994",
    "comments": [
      "Some psychologists finetuned a Llama-family LLM on some psychology data - \u201ca data set called Psych-101, which contained data from 160 previously published psychology experiments, covering more than 60,000 participants who made more than 10 million choices in total\u201d, so I guess maybe 10 million tokens?That part seems to make sense, but I cannot rightly comprehend the confusion that follows.Some psychology researchers are claiming it has become a model of human cognition? (Because it can imitate the way a psychology study participant answers psychology study questions?)Other psychology researchers are disputing this by testing its reaction time and digit span memory? (Are they administering an iq test? A cranial nerves exam?)reply",
      "I don\u2019t think healthy scepticism is (or should be) controversial. But I find it interesting how willing certain people are to confidently claim that a model does or does not accurately model human cognition when we clearly still _barely understand human cognition_.Where do people derive their certainty, which seems to me largely misplaced?reply",
      "The tech industry has a very long and proud history of gaining a very surface level understanding of a different industry then immediately claiming to \"disrupt\" it.The unearned confidence of tech bros should be studiedreply",
      "Neuroscience is still struggling to understand the basic operations of the brain, let alone the \"mind.\" There's no agreed-upon definition of \"intelligence.\" Can you define cognition (literally, \"knowing\") without defining intelligence?These fields are making remarkable strides, but they're still in their infancy. Whoever writes these breathless press releases, they probably have a degree in marketing.reply",
      "I have the same objections to the term \"IQ\".reply"
    ],
    "link": "https://insidescientific.com/centaur-a-controversial-leap-towards-simulating-human-cognition/",
    "first_paragraph": "Researchers have developed an AI model named Centaur, claiming it can simulate the human mind by training on a data set called Psych-101, which aggregates data from 160 psychology experiments, encompassing over 60,000 participants\u2019 decisions. Originally published in Nature, Centaur purportedly predicts human behavior in experiments articulated in natural language. Centaur, trained on Meta\u2019s Llama language model, reportedly outperforms traditional cognitive models in mimicking human decision-making, even extending to modified tasks not included in its training data. This suggests potential for in silico experiment development and new behavioral theories.However, the claim of Centaur mimicking human cognition faces skepticism. Critics like Blake Richards and Marcel Binz argue it doesn\u2019t genuinely reflect human cognitive processes. Jeffrey Bowers highlights its limitations, noting its ability to recall 256 digits and respond in milliseconds\u2014feats beyond human capability, indicating a lack"
  },
  {
    "title": "Opencode: AI coding agent, built for the terminal (github.com/sst)",
    "points": 130,
    "submitter": "indigodaddy",
    "submit_time": "2025-07-06T17:26:47 1751822807",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=44482504",
    "comments": [
      "Isn't it more appropriate to compare this to aider?I prefer the command line tools to IDE integration, even though I don't feel like the contextual options are great. In other words, I don't always feel that I can see the changes fully. I like Claude Code's option to expand the result using ctrl-r, and I like the diffs it provides. But, it still feels like there is a way to get better than what I see inside Zed and what I see inside Claude and Aider.Maybe an editor that can be controlled and modified on the fly using natural language?reply",
      "That's an interesting idea! I struggle with the same issues you've mentioned, that space between the IDE integrated option and pure CLI. Your comment sparked an idea of using something like vim or similar where you can edit the config on the fly and reload it. I wonder how hard it would be to bolt a prompt interface to the front to have it build the editor for you?It would likely quickly devolve into typical editor config bikeshedding, only AI powered? At least for me, maybe someone smarter could streamline it enough to be useful though!reply",
      "I was hoping I would goad someone into doing it.But, do it for emacs, ok? </joke>Actually, I *do* prefer emacs.reply",
      "aider has an emacs integrationreply",
      "specifically for working better with diffs, I can recommend tmux + lazygit with this keybinding for quickly opening a floating lazygit:bind-key C-g display-popup -E -d \"#{pane_current_path}\" -xC -yC -w 80% -h 75% \"lazygit\"not only does it allow you to see the diffs, but you can directly discard changes you don't want, stage, commit, etc.reply",
      "Damn, thanks, i have some floating panes on tmux but never thought about doing something like this lolreply",
      "Being able to open the diff in vimdiff view (or your editor's equivalent) would be a neat approach. Not entirely sure how to actually implement that.reply",
      "Just wanted to say I had been happily plodding along using AI tools in Zed, which had worked pretty well but seeing the SST team was behind OpenCode I decided to finally give a terminal based agent a try. I was blown away, primarily by the feedback loops of say OpenCode writing new tests, running the test suite, seeing the tests errored and looping back start the whole process again. That looping does not happen in Zed!It was the first time I felt like I could write up a large prompt, walk away from my laptop, and come back to a lot of work having been done. I've been super happy with the experience so far.reply",
      "I\u2019ve definitely had exactly that sort of looping work with Zed, as long as I tell it how to run the tests. Are you perhaps not using one of the \u201cthinking\u201d models?reply",
      "hey one of the authors herewe're a little over a month into development and have a lot on our roadmapthe cli is client/server model - the TUI is our initial focus but the goal is to build alternative frontends, mobile, web, desktop, etcwe think of our task as building a very good code review tool - you'll see more of that side in the following weekscan answer any questions herereply"
    ],
    "link": "https://github.com/sst/opencode",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        AI coding agent, built for the terminal.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n\n\n\n\n\n\n\nAI coding agent, built for the terminal.\n\n\n\nNote: Remove versions older than 0.1.x before installingFor more info on how to configure opencode head over to our docs.For any new features we'd appreciate it if you could open an issue first to discuss what you'd like to implement. We're pretty responsive there and it'll save you from working on something that we don't end up using. No need to do this for simpler fixes.Note: Please talk to us via github issues before spending time working on\na new featureTo run opencode locally you need.And run.API Client: After making changes to the TypeScript API endpoints in packages/opencode/src/server/server.ts, you will need th"
  },
  {
    "title": "Get the location of the ISS using DNS (shkspr.mobi)",
    "points": 258,
    "submitter": "8organicbits",
    "submit_time": "2025-07-06T12:32:46 1751805166",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=44480223",
    "comments": [
      "Another record, Name Authority Pointer (NAPTR), has the telephone number of the Johnson Space Center in Houston:  > dig where-is-the-iss.dedyn.io NAPTR\n\n  ; <<>> DiG 9.10.6 <<>> where-is-the-iss.dedyn.io NAPTR\n  ;; global options: +cmd\n  ;; Got answer:\n  ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 31786\n  ;; flags: qr rd ra ad; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\n\n  ;; OPT PSEUDOSECTION:\n  ; EDNS: version: 0, flags:; udp: 1232\n  ;; QUESTION SECTION:\n  ;where-is-the-iss.dedyn.io. IN NAPTR\n\n  ;; ANSWER SECTION:\n  where-is-the-iss.dedyn.io. 3600 IN NAPTR 100 100 \"u\" \"E2U+voice:tel\" \"!^.*$!tel:+12814830123!\" .\n\n  ;; Query time: 84 msec\n  ;; SERVER: 100.100.100.100#53(100.100.100.100)\n  ;; WHEN: Sun Jul 06 10:53:39 EDT 2025\n  ;; MSG SIZE rcvd: 111reply",
      "I understand there are API limitations, but isn't 15 minutes a lot for an object that orbits around the entire Earth in 90 minutes? On average you're going to be off by about a twelfth of the circumference of the Earth, or roughly the distance between Lisbon and Istanbulreply",
      "Yes. As I say in the post, you shouldn't use this for docking operations.If you know of a DNS update which allows for per-minute updates for free, I'll happily move to it.reply",
      "> As I say in the post, you shouldn't use this for docking operationsRemember people, DNS stands for \"Definitely Not for Space-docking\"reply",
      "or \"Docking Not Supported\"reply",
      "> If you know of a DNS update which allows for per-minute updates for free, I'll happily move to it.Why not setup your own name server?reply",
      "This is the correct way - dynamic DNS servers frequently have very low TTLs set.Serving DNS yourself is such an incredibly small bandwidth impact - most of the packets are in the 10's to 100's of bytes - and authoritative DNS servers do not do a lot of processing, just send back RR's from zones which are read at boot time, or updated in an in-memory database.reply",
      "I couldn't be bothered to set up a DNS server for such an ephemeral joke.But I would love to read your blog post about setting one up and what you learned.reply",
      "mailinabox.email. Just use the DNS part and not worry about mx if you want something fairly simplereply",
      "Coredns is so simple to configure and is a barebones container deployment.reply"
    ],
    "link": "https://shkspr.mobi/blog/2025/07/get-the-location-of-the-iss-using-dns/",
    "first_paragraph": "dns internet trivia  \u00b7 7\u00a0comments \u00b7 550\u00a0words \u00b7 Viewed\u00a0~19,437\u00a0times.I love DNS esoterica. Weird little things that you can shove in the global directory to be distributed around the world instantly(ish).Domain names, like www.example.com usually resolve to servers. As much as we think of \"the cloud\" as being some intangible morass of ethereal Turing-machines floating in probability space, the more prosaic reality is that they're just boxen in data centres. They have a physical location.Got a tricky machine which is playing silly-buggers? Wouldn't it be nice to know exactly where it is? That way you can visit and give it some percussive maintenance.Enter the DNS LOC record!The snappily titled RFC 1876 is an experimental standard. It allows you to create a DNS record which specifies the latitude and longitude of your server. Of course, some data-centres are very tall and some are underground. So it also contains an altitude parameter.The standard allows for a minimum altitude of -100,00"
  },
  {
    "title": "Functions Are Vectors (2023) (thenumb.at)",
    "points": 150,
    "submitter": "azeemba",
    "submit_time": "2025-07-06T15:18:35 1751815115",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=44481464",
    "comments": [
      "This previous thread was also good: Functions are vectors - https://news.ycombinator.com/item?id=36921446 - July 2023 (120 comments)",
      "The jump from spherical harmonics to eigenfunctions on a general mesh, and the specific example mesh chosen, might be the finest mathematical joke I've seen this decade.reply",
      "Related to this footnote in TFA?>If you\u2019re alarmed by the fact that the set of all real functions does not form a HILBERT SPACE, you\u2019re probably not in the target audience of this post.\"Video:\nhttps://youtu.be/q8gng_2gn70?t=8m3sThanks tohttps://news.ycombinator.com/item?id=44481933reply",
      "Would you explain the joke for the rest of us?reply",
      "It's quietly reversing the traditional \"We approximate the cow to be a sphere\" and showing how the spherical math can, in fact, be generalized to solutions on the cow.reply",
      "oh. I did not interpret that blob as a cow. Thanks.reply",
      "Spherical Haromics approximating Spherical Cows?reply",
      "assume spherical cowreply",
      "A few questions occur to me while reading this, which I am far from qualified to answer:- How much of this structure survives if you work on \"fuzzy\" real numbers? Can you make it work? Where I don't necessarily mean \"fuzzy\" in the specific technical sense, but in any sense in which a number is defined only up to a margin of error/length scale, which in my mind is similar to \"finitism\", or \"automatic differentiation\" in ML, or a \"UV cutoff\" in physics. I imagine the exact definition will determine how much vectorial structure survives. The obvious answer is that it works like a regular Fourier transform but with a low-pass filter applied, but I imagine this might not be the only answer.- Then if this is possible, can you carry it across the analogy in the other direction? What would be the equivalent of \"fuzzy vectors\"?- If it isn't possible, what similar construction on the fuzzy numbers would get you to the obvious endpoint of a \"fourier analysis with a low pass filter pre-applied?\"- The argument arrives at fourier analysis by considering an orthonormal diagonalization of the Laplacian. In linear algebra, SVD applies more generally than diagonalizations\u2014is there an \"SVD\" for functions?reply",
      "Convolution with dirac delta will give you an exact sample of f(0), and in principle a whole signal could be constructed as a combination of delayed delta signals - but we can't realize an exact delta signal in most spaces, only approximations.As a result we get finite resolution and truncation of the spectrum. So \"Fourier analysis with pre-applied lowpass filter\" would be analysis of sampled signals, the filter determined by the sampling kernel (delta approximator) and properties of the DFT.But so long as the sampling kernel is good (that is the actual terminology), we can form f exactly as the limit of these fuzzy interpolations.The term \"resolution of the identity\" is associated with the fact that delta doesn't exist in most function spaces and instead has to be approximated. A good sampling kernel \"resolves\" the missing (convolutional) identity. I like thinking of the term also in the sense that these operators behave like the identity if it were only good up to some resolution.reply"
    ],
    "link": "https://thenumb.at/Functions-are-Vectors/",
    "first_paragraph": "Conceptualizing functions as infinite-dimensional vectors lets us apply the tools of linear algebra to a vast landscape of new problems, from image and geometry processing to curve fitting, light transport, and machine learning.Prerequisites: introductory linear algebra, introductory calculus, introductory differential equations.This article received an honorable mention in 3Blue1Brown\u2019s Summer of Math Exposition 3!Vectors are often first introduced as lists of real numbers\u2014i.e. the familiar notation we use for points, directions, and more.You may recall that this representation is only one example of an abstract vector space.\nThere are many other types of vectors, such as lists of complex numbers, graph cycles, and even magic squares.However, all of these vector spaces have one thing in common: a finite number of dimensions.\nThat is, each kind of vector can be represented as a collection of $$N$$ numbers, though the definition of \u201cnumber\u201d varies.If any $$N$$-dimensional vector is esse"
  },
  {
    "title": "I don't think AGI is right around the corner (dwarkesh.com)",
    "points": 153,
    "submitter": "mooreds",
    "submit_time": "2025-07-06T20:45:20 1751834720",
    "num_comments": 175,
    "comments_url": "https://news.ycombinator.com/item?id=44483897",
    "comments": [
      "Anyone who claims that a poorly definined concept, AGI, is right around the corner is most likely:- trying to sell something- high on their own stories- high on exogenous compounds- all of the aboveLLMs are good at language. They are OK summarizers of text by design but not good at logic. Very poor at spatial reasoning and as a result poor at connecting concepts together.Just ask any of the crown jewel LLM models \"What's the biggest unsolved problem in the [insert \nany] field\".The usual result is a pop-science-level article but with ton of subtle yet critical mistakes! Even worse, the answer sounds profound on the surface. In reality, it's just crap.reply",
      "Its right around the corner when you prove it as fact. Otherwise as suggested it is just hype to sell us on your LLM flavor.reply",
      "They\u2019re great at working with the lens on our reality that is our text output. They are not truth seekers, which is necessarily fundamental to every life form from worms to whales. If we get things wrong, we die. If they get them wrong, they earn 1000 generated tokens.reply",
      "Interesting.  I think the key to what you wrote is \"poorly definined\".I find LLMs to be generally intelligent.  So I feel like \"we are already there\" -- by some definition of AGI.  At least how I think of it.Maybe a lot of people think of AGI as \"superhuman\".  And by that definition, we are not there -- and may not get there.But, for me, we are already at the era of AGI.reply",
      "I would call them \"generally applicable\". \"intelligence\" definitely implies leaning - and I'm not sure RAG, fine-tuning, or 6monthly updates counts - to split hairs.Where I will say we have a massive gap, which makes the average person not consider it AGI, is in context. I can give a person my very modest codebase, and ask for a change, and they'll deliver - mostly coherently - to that style, files in the right place etc. Still to today with AI, I get inconsistent design, files in random spots, etc.reply",
      "that's the thing about language. we all kinda gotta agree on the meaningsreply",
      "I'll offer a definition of AGI:An AI (a computer program) that is better at [almost] any task than 5% of the human specialists in that field has achieved AGI.Or, stated another way, if 5% of humans are incapable of performing any intellectual job better than an AI can, then that AI has achieved AGI.Note, I am not saying that an AI that is better than humans at one particular thing has achieved AGI, because it is not \"general\". I'm saying that if a single AI is better at all intellectual tasks than some humans, the AI has achieved AGI.The 5th percentile of humans deserves the label of \"intelligent\", even if they are not the most intelligent, (I'd say all humans deserve the label \"intelligent\") and if an AI is able to perform all intellectual tasks better than such a person, the AI has achieved AGI.reply",
      "I like where this is going.However, it's not sufficient. The actual tasks have to be written down, tests constructed, and the specialists tested.A subset of this has been done with some rigor and AI/computers have surpassed this threshold for some tests. Some have then responded by saying that it isn't AGI, and that the tasks aren't sufficiently measuring of \"intelligence\" or some other word, and that more tests are warranted.reply",
      "You're saying we need to write down all intellectual tasks? How would that help?If an AI is better at some tasks (that happen to be written down), it doesn't mean it is better at all tasks.Actually, I'd lower my threshold even further--I originally says 50%, then 20%, then 5%--but now I'll say if an AI is better than 0.1% of people at all intellectual tasks, then it is AGI, because it is \"general\" (being able to do all intellectual tasks), and it is \"intelligent\" (a label we are willing to ascribe to all humans).reply",
      "Where does Eric Schmidt fit? Selling something?reply"
    ],
    "link": "https://www.dwarkesh.com/p/timelines-june-2025",
    "first_paragraph": ""
  },
  {
    "title": "Backlog.md \u2013 Markdown\u2011native Task Manager and Kanban visualizer for any Git repo (github.com/mrlesk)",
    "points": 79,
    "submitter": "mrlesk",
    "submit_time": "2025-07-06T19:55:30 1751831730",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=44483530",
    "comments": [
      "I threw Claude Code at an existing codebase a few months back and quickly quit\u2014\nuntangling its output was slower than writing from scratch. The fix turned out\nto be process, not model horsepower.Iteration timeline==================\u2022 50 % task success - added README.md + CLAUDE.md so the model knew the project.\u2022 75 % - wrote one markdown file per task; Codex plans, Claude codes.\u2022 95 %+ - built Backlog.md, a CLI that turns a high-level spec into those task files automatically (yes, using Claude/Codex to build the tool).Three step loop that works for me\n1. Generate tasks - Codex / Claude Opus \u2192 self-review.2. Generate plan - same agent, \u201cplan\u201d mode \u2192 tweak if needed.3. Implement - Claude Sonnet / Codex \u2192 review & merge.For simple features I can even run this from my phone:\nChatGPT app (Codex) \u2192 GitHub app \u2192 ChatGPT app \u2192 GitHub merge.Repo: https://github.com/MrLesk/Backlog.mdWould love feedback and happy to answer questions!reply",
      "Really love this.Would love to see an actual end to end example video of you creating, planning, and implementing a task using your preferred models and apps.reply",
      "Will definitely do.\nI am also planning to run a benchmark with various models to see which one is more effective at building a full product starting from a PRD and using backlog for managing tasksreply",
      "I'd love to see openRouter connectivity to try non Claude models for some of the planning parts of the cycle.reply",
      "Is there an established benchmark for building a full product?- SWE-bench leaderboard:  https://www.swebench.com/- Which metrics for e.g. \"SWE-Lancer: a benchmark of freelance software engineering tasks from Upwork\"? https://news.ycombinator.com/item?id=43101314- MetaGPT, MGX: https://github.com/FoundationAgents/MetaGPT :> Software Company as Multi-Agent System> MetaGPT takes a one line requirement as input and outputs user stories / competitive analysis / requirements / data structures / APIs / documents, etc.\nInternally, MetaGPT includes product managers / architects / project managers / engineers. It provides the entire process of a software company along with carefully orchestrated SOPs.- Mutation-Guided LLM-based Test Generation: https://news.ycombinator.com/item?id=42953885- https://news.ycombinator.com/item?id=41333249 :- codefuse-ai/Awesome-Code-LLM > Analysis of AI-Generated Code, Benchmarks: https://github.com/codefuse-ai/Awesome-Code-LLM :> 8.2 Benchmarks: \n Integrated Benchmarks, \nEvaluation Metrics, \nProgram Synthesis, \nVisually Grounded Program, Synthesis,\nCode Reasoning and QA,\nText-to-SQL,\nCode Translation,\nProgram Repair,\nCode Summarization,\nDefect/Vulnerability Detection,\nCode Retrieval,\nType Inference,\nCommit Message Generation,\nRepo-Level Coding- underlines/awesome-ml/tools.md > Benchmarking: https://github.com/underlines/awesome-ml/blob/master/llm-too...- formal methods workflows, coverage-guided fuzzing: https://news.ycombinator.com/item?id=40884466- \"Large Language Models Based Fuzzing Techniques: A Survey\" (2024) https://arxiv.org/abs/2402.00350reply",
      "Would love more detail on your integration with claude. Are you telling claude to use backlog to plan X task? Feels like some MCP integration or something might make it feel more native?Though i've not had much luck in getting Claude to natively use MCPs, so maybe that's off base heh.reply",
      "Can we change the title to include that this is a tool for AI? I thought it was just gonna be a visualizer.The tagline from the repo seems fine: \"A tool for managing project collaboration between humans and AI Agents in a git ecosystem\"reply",
      "Seems like a great idea. How would that work with multiple branches ? One task might be implemented in a different branch, we might want to have a global overview of all the tasks being coded in the main branch  All data is saved under backlog folder as human\u2011readable Markdown with the following format task-<task-id> - <task-title>.md (e.g. task-12 - Fix typo.md).\n\n\nIf every \"task\" is one .md file, I believe AI have issues editing big files, it can't easily append text to a big file due to context window, we need to force a workaround launching a command line to append text instead of editing a file. So this means the tasks have to remain small, or we have to avoid putting too much information in each task.reply",
      "This is a good idea. But the screenshots you have show lots of tasks in a project; how are you dispatching tasks (once planned) to an agent, and how are agents navigating the large number of markdown task content you're producing without blowing out their context budget?reply",
      "Is there an alternative that integrates with a Jira instance?Many of my tasks already exists in forms of a Jira ticket, would be interesting to prompt it to take over a specific ticket & update its ticket progress as well.reply"
    ],
    "link": "https://github.com/MrLesk/Backlog.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Backlog.md - A tool for managing project collaboration between humans and AI Agents in a git ecosystem\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Markdown\u2011native Task Manager & Kanban visualizer for any Git repository\nnpm i -g backlog.md or bun add -g backlog.md\nBacklog.md turns any folder with a Git repo into a self\u2011contained project board\npowered by plain Markdown files and a zero\u2011config CLI.\ud83d\udcdd Markdown-native tasks -- manage every issue as a plain .md file\ud83d\udd12 100 % private & offline -- backlog lives entirely inside your repo\ud83d\udcca Instant terminal Kanban -- backlog board paints a live board in your shell\ud83c\udf10 Modern web interface -- backlog browser launches a sleek web UI for visual task management\ud83e\udd16 AI-ready CLI -- \"Claude, please take over task 33\"\ud83d\udd0d Rich query "
  },
  {
    "title": "Lessons from creating my first text adventure (entropicthoughts.com)",
    "points": 28,
    "submitter": "kqr",
    "submit_time": "2025-07-04T13:48:19 1751636899",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://entropicthoughts.com/lessons-from-creating-first-text-adventure",
    "first_paragraph": "\nWhen I write about the greatness of text adventures, I pretend they are easy to\nmake. They are, compared to many other types of games, but it\u2019s still a bit of a\nlie. They\u2019re hard to make.\n\nI made one and submitted it to ParserComp 2025, and here\u2019s what I learned.\n\n\nSince ParserComp voting has opened, the game is now public, and you can play it\nin your browser. The game itself reveals what it is about as you progress, so I\nwon\u2019t write too much about it here. You should be able to finish it in 30\u201360\nminutes. Don\u2019t feel bad about needing hints, especially if you\u2019re new to text\nadventures.\n\nLockout is my third attempt at making a text adventure. The first two failed\nbecause of ambition.\n\nIt\u2019s very easy to accidentally try to create too large a text adventure. My\nfirst attempt was way too ambitious, and would have taken months to finish. I\nstill love the idea for that, but it had to go. I picked another idea that was\nmuch smaller in scope, but it, too, grew too ambitious. I restarted one m"
  },
  {
    "title": "Crypto 101 \u2013 Introductory course on cryptography (crypto101.io)",
    "points": 27,
    "submitter": "pona-a",
    "submit_time": "2025-07-06T21:09:42 1751836182",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44484074",
    "comments": [
      "Thanks for the link.You can download this entire Handbook of Applied Cryptography for free [1].Recently the authors also provided online course and video namely:- Cryptography 101: Building Blocks (fundamental cryptographic primitives) [2]- Cryptography 101: Real-World Deployments (PKI, TLS, Bluetooth, AWS, Signal) [3]Other courses and video includes:- The Mathematics of Lattice-Based Cryptography (introductory course)- Kyber and Dilithium (standardized lattice-based cryptosystems)- Hash-based signature schemes (LMS, XMSS, SPHINCS+)- Error-Correcting Codes (linear, Hamming, Golay, cyclic, BCH, Reed-Solomon codes[1] Handbook of Applied Cryptography:https://cacr.uwaterloo.ca/hac/[2] Crypto 101: Building Blocks:https://cryptography101.ca/crypto101-building-blocks/[3] Crypto 101: Real-World Deployments:https://cryptography101.ca/crypto101-deployments/reply",
      "I don't remember if it links to it, but this pairs well with https://cryptopals.com/, which are practical examples of many of these theories.reply"
    ],
    "link": "https://www.crypto101.io/",
    "first_paragraph": "\n                Crypto 101 is an introductory course on cryptography,\n                freely available for programmers of all ages and skill\n                levels.\n              \n              Comes with everything you need to understand complete\n              systems such as SSL/TLS: block ciphers, stream ciphers,\n              hash functions, message authentication codes, public key\n              encryption, key agreement protocols, and signature\n              algorithms.\n            \n              Learn how to exploit common cryptographic flaws, armed\n              with nothing but a little time and your favorite\n              programming language.\n            \n              Forge administrator cookies, recover passwords, and even\n              backdoor your own random number generator.\n            \n              DRM-free and available in all common formats:\n            \n              Crypto 101 started as a presentation at PyCon 2013. It\n              tries to go through all of t"
  },
  {
    "title": "Evaluating the factuality of verifiable claims in long-form text generation (aclanthology.org)",
    "points": 3,
    "submitter": "gone35",
    "submit_time": "2025-07-04T05:12:55 1751605975",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://aclanthology.org/2024.findings-emnlp.552/",
    "first_paragraph": "Yixiao Song,\nYekyung Kim,\nMohit Iyyer[VeriScore: Evaluating the factuality of verifiable claims in long-form text generation](https://aclanthology.org/2024.findings-emnlp.552/) (Song et al., Findings 2024)\nACL materials are Copyright \u00a9\u00a01963\u20132025 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a Creative Commons Attribution 4.0 International License.The ACL Anthology is managed and built by the ACL Anthology team of volunteers.Site last built on 04 July 2025 at 18:17 UTC with commit 09bf6f9."
  },
  {
    "title": "Swedish Campground: \"There are too many Apples on the screen!\" (folklore.org)",
    "points": 20,
    "submitter": "CharlesW",
    "submit_time": "2025-07-06T23:49:52 1751845792",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44485241",
    "comments": [
      "Also known as the looped square (commonly used as the place of interest sign):https://en.wikipedia.org/wiki/Looped_squarereply",
      "(This isn't the title)Previously:2013 (111 points, 49 comments) https://news.ycombinator.com/item?id=59885572011 (177 points, 22 comments) https://news.ycombinator.com/item?id=2643611reply",
      "Ah, the Saint Hannes cross, or sankthanskors in Sweden, or hannunvaakuna in Finland. It's not so much related to campgrounds, but to mark sightseeing spots in general.reply",
      "Saw one in Sweden a few months back. Had to snap a photo: https://imgur.com/a/RAseomCreply",
      "The same sign is used in Finland. I was puzzled why Apple computers used it but I thought it was just a coincidence...!reply",
      "Never used MacDraw, but I remember installing and using ClarisWorks in middle/high school, I never did actual programming at that age, but I loved playing around with the Mac's word processing, drawing, painting programs, making little art layouts, outlines for class notes, stuff that that.reply"
    ],
    "link": "https://www.folklore.org/Swedish_Campground.html",
    "first_paragraph": "We thought it was important for the user to be able to invoke every menu command directly from the keyboard, so we added a special key to the keyboard to invoke menu commands, just like our predecessor, Lisa.   We called it the \"Apple key\"; when pressed in combination with another key, it selected the corresponding menu command.   We displayed a little Apple logo on the right side of every menu item with a keyboard command, to associate the key with the command. "
  },
  {
    "title": "A non-anthropomorphized view of LLMs (addxorrol.blogspot.com)",
    "points": 93,
    "submitter": "zdw",
    "submit_time": "2025-07-06T22:26:44 1751840804",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=44484682",
    "comments": [
      "The problem with viewing LLMs as just sequence generators, and malbehaviour as bad sequences, is that it simplifies too much. LLMs have hidden state not necessarily directly reflected in the tokens being produced and it is possible for LLMs to output tokens in opposition to this hidden state to achieve longer term outcomes (or predictions, if you prefer).Is it too anthropomorphic to say that this is a lie? To say that the hidden state and its long term predictions amount to a kind of goal? Maybe it is. But we then need a bunch of new words which have almost 1:1 correspondence to concepts from human agency and behavior to describe the processes that LLMs simulate to minimize prediction loss.Reasoning by analogy is always shaky. It probably wouldn't be so bad to do so. But it would also amount to impenetrable jargon. It would be an uphill struggle to promulgate.Instead, we use the anthropomorphic terminology, and then find ways to classify LLM behavior in human concept space. They are very defective humans, so it's still a bit misleading, but at least jargon is reduced.reply",
      "IMHO, anthrophormization of LLMs is happening because it's perceived as good marketing by big corporate vendors.People are excited about the technology and it's easy to use the terminology the vendor is using. At that point I think it gets kind of self fulfilling. Kind of like the meme about how to pronounce GIF.reply",
      "IMHO it happens for the same reason we see shapes in clouds. The human mind through millions of years has evolved to equate and conflate the ability to generate cogent verbal or written output with intelligence. It's an instinct to equate the two. It's an extraordinarily difficult instinct to break. LLMs are optimised for the one job that will make us confuse them for being intelligentreply",
      "Nobody cares about what\u2019s perceived as good marketing. People care about what resonates with the target market.But yes, anthropomorphising LLMs is inevitable because they feel like an entity. People treat stuffed animals like creatures with feelings and personality; LLMs are far closer than that.reply",
      "the chat interface was a choice, though a natural one. before they'd RLHFed it into chatting and it was just GPT 3 offering completions 1) not very many people used it and 2) it was harder to anthropomorphizereply",
      "Alright, let\u2019s agree that good marketing resonates with the target market. ;-)reply",
      "I 1000% agree. It\u2019s a vicious, evolutionary, and self-selecting process.It takes great marketing to actually have any character and intent at all.reply",
      "> People treat stuffed animals like creatures with feelings and personality; LLMs are far closer than that.Children do, some times, but it's a huge sign of immaturity when adults, let alone tech workers, do it.I had a professor at University that would yell at us if/when we personified/anthropomorphized the tech, and I have that same urge when people ask me \"What does <insert LLM name here> think?\".reply",
      "I'm not sure what you mean by \"hidden state\". If you set aside chain of thought, memories, system prompts, etc. and the interfaces that don't show them, there is no hidden state.These LLMs are almost always, to my knowledge, autoregressive models, not recurrent models (Mamba is a notable exception).reply",
      "Hidden state in the form of the activation heads, intermediate activations and so on. Logically, in autoregression these are recalculated every time you run the sequence to predict the next token. The point is, the entire NN state isn't output for each token. There is lots of hidden state that goes into selecting that token and the token isn't a full representation of that information.reply"
    ],
    "link": "http://addxorrol.blogspot.com/2025/07/a-non-anthropomorphized-view-of-llms.html",
    "first_paragraph": "A blog about reverse engineering, mathematics, politics, economics and more ...In many discussions where questions of \"alignment\" or \"AI safety\" crop up, I am baffled by seriously intelligent people imbuing almost magical human-like powers to something that - in my mind - is just MatMul with interspersed nonlinearities.In one of these discussions, somebody correctly called me out on the simplistic nature of this argument - \"a brain is just some proteins and currents\". I felt like I should explain my argument a bit more, because it feels less simplistic to me:\nPost a Comment\n"
  }
]