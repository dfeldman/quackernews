[
  {
    "title": "Data sleuths who spotted research misconduct cleared of defamation (arstechnica.com)",
    "points": 159,
    "submitter": "dangle1",
    "submit_time": "2024-09-12T21:28:17.000000Z",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=41525778",
    "comments": [
      "While a favorable ruling for the Data Colada defendants seemed incredibly likely in the end (and of course being dismissed pre-trial before discovery is a good thing). But it still took over a year, and consisted of several pre-trial hearings with multiple back and forths between them. If I ctrl-f https://storage.courtlistener.com/recap/gov.uscourts.mad.259... I see Pyle (their lawyer) listed 11 times. All the motions and responses are a non-trivial amount of work.Do folks have a sense of how much the costs would have been just to get dismissed for DC? Seems to be definitely over 10k (50k?) Or am I overestimating.\n \nreply",
      "I'm pretty sure this guy wouldn't get out of bed for $10k:https://princelobel.com/professional/jeffrey-j-pyle/Although given that the New Yorker stated that Pyle \"appeared not only professionally but personally incensed by the fact of the lawsuit\", perhaps some of the work was pro bono.https://www.newyorker.com/news/news-desk/how-a-scientific-di...\n \nreply",
      "Thankfully, a lot of the filings appear short enough that I doubt he's going to charge very much.  I assume the retainer was still $20-30k, but they may get some of it back.I was hoping that there would be some fee-shifting here, but it's federal court.\n \nreply",
      "Fortunately, they were able to raise quite a bit of money (>$300K) on GoFundMe: https://www.gofundme.com/f/uhbka-support-data-coladas-legal-...\n \nreply",
      "You are probably not overestimating.Generally, I would guess conferring with the client on the facts, briefing, preparing for a hearing, and arguing a hearing would be north of, at least, 25k, assuming a lower-end rate estimate in the $800+ range and a lower-end work estimate of 30+ hours.  If I had to bet, I'd go higher than the low-end estimate: both the rate and hours could be close to double.  That said, the attorney / firm could be donating the time on this one.\n \nreply",
      "We're lucky to have hard-headed people willing to put up with legal threats and bullying tactics. I'm not sure I'd have the spine for it. It reminds me of when Ben Goldacre was sued [0] which luckily his publisher covered the costs for.[0] https://www.badscience.net/files/The-Doctor-Will-Sue-You-Now...\n \nreply",
      "\u201c[s]cientific controversies must be settled by the methods of science rather than by the methods of litigation\u201dBoom. And the researchers didn't accuse a person of fabrication, they accused the data of being fabricated.\n \nreply",
      "The irony is that Francesca Gino and Dan Ariely are famous for their pop-sci/TED talks studying dishonesty. Turns out they were dishonest themselves.https://www.npr.org/2023/07/27/1190568472/dan-ariely-frances...\n \nreply",
      "There is no limits a grifter wont go to in order to continue their grift. Those with the funds regularly get away with it purely because they have the funds to sue their opponents into bankruptcy. The system worked in this case but it so rarely does and we see so often people having to back down due to legal threats.\n \nreply",
      "see: Lance Armstrong.\u2020\u2020 https://www.abajournal.com/news/article/lance_armstrong_admi...\n \nreply"
    ],
    "link": "https://arstechnica.com/science/2024/09/court-clears-researchers-of-defamation-for-identifying-manipulated-data/",
    "first_paragraph": "Front page layoutSite theme\nJohn Timmer\n    -    Sep 12, 2024 9:17 pm UTC\nEarlier this year, we got a look at something unusual: the results of an internal investigation conducted by Harvard Business School that concluded one of its star faculty members had committed research misconduct. Normally, these reports are kept confidential, leaving questions regarding the methods and extent of data manipulations.But in this case, the report became public because the researcher had filed a lawsuit that alleged defamation on the part of the team of data detectives that had first identified potential cases of fabricated data, as well as Harvard Business School itself. Now, the court has ruled on motions to dismiss the case. While the suit against Harvard will go on, the court has ruled that evidence-backed conclusions regarding fabricated data cannot constitute defamation\u2014which is probably a very good thing for science.The researchers who had been sued, Uri Simonsohn, Leif Nelson, and Joe Simmon"
  },
  {
    "title": "Notes on OpenAI's new o1 chain-of-thought models (simonwillison.net)",
    "points": 5,
    "submitter": "loganfrederick",
    "submit_time": "2024-09-13T00:48:01.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://simonwillison.net/2024/Sep/12/openai-o1/",
    "first_paragraph": "12th September 2024OpenAI released two major new preview models today: o1-preview and o1-mini (that mini one is also a preview, despite the name)\u2014previously rumored as having the codename \u201cstrawberry\u201d. There\u2019s a lot to understand about these models\u2014they\u2019re not as simple as the next step up from GPT-4o, instead introducing some major trade-offs in terms of cost and performance in exchange for improved \u201creasoning\u201d capabilities.OpenAI\u2019s elevator pitch is a good starting point:We\u2019ve developed a new series of AI models designed to spend more time thinking before they respond.One way to think about these new models is as a specialized extension of the chain of thought prompting pattern\u2014the \u201cthink step by step\u201d trick that we\u2019ve been exploring as a a community for a couple of years now, first introduced in the paper Large Language Models are Zero-Shot Reasoners in May 2022.OpenAI\u2019s article Learning to Reason with LLMs explains how the new models were trained:Our large-scale reinforcement learn"
  },
  {
    "title": "Learning to Reason with LLMs (openai.com)",
    "points": 1410,
    "submitter": "fofoz",
    "submit_time": "2024-09-12T17:08:46.000000Z",
    "num_comments": 1072,
    "comments_url": "https://news.ycombinator.com/item?id=41523070",
    "comments": [
      "Some practical notes from digging around in their documentation:\nIn order to get access to this, you need to be on their tier 5 level, which requires $1,000 total paid and 30+ days since first successful payment.Pricing is $15.00 / 1M input tokens and $60.00 / 1M output tokens.  Context window is 128k token, max output is 32,768 tokens.There is also a mini version with double the maximum output tokens (65,536 tokens), priced at $3.00 / 1M input tokens and $12.00 / 1M output tokens.The specialized coding version they mentioned in the blog post does not appear to be available for use.It\u2019s not clear if the hidden chain of thought reasoning is billed as paid output tokens. Has anyone seen any clarification about that?  If you are paying for all of those tokens it could add up quickly. If you expand the chain of thought examples on the blog post they are extremely verbose.https://platform.openai.com/docs/models/o1\nhttps://openai.com/api/pricing/\nhttps://platform.openai.com/docs/guides/rate-limits/usage-ti...\n \nreply",
      "> Some practical notes from digging around in their documentation: In order to get access to this, you need to be on their tier 5 level, which requires $1,000 total paid and 30+ days since first successful payment.Tier 5 level required for _API access_. ChatGPT Plus users, for example, also have access to the o1 models.\n \nreply",
      "Reasoning tokens are indeed billed as output tokens.> While reasoning tokens are not visible via the API, they still occupy space in the model's context window and are billed as output tokens.From here: https://platform.openai.com/docs/guides/reasoning\n \nreply",
      "This is concerning - how do you know you aren\u2019t being fleeced out of your money here\u2026? You\u2019ll get your results, but did you really use that much?\n \nreply",
      "Also, now we're paying for output tokens that aren't even output, with no good explanation for why these tokens should be hidden from the person who paid for them.\n \nreply",
      "If you read the link they have a section specifically explaining why it is hidden.\n \nreply",
      "I read it. It's a bad explanation.The only bit about it that feels at all truthful is this bit, which is glossed over but likely the only real factor in the decision:> after weighing multiple factors including ... competitive advantage ... we have decided not to show the raw chains of thought to users.\n \nreply",
      "Good catch. That indicates that chains of thought are a straightforward approach to make LLMs better at reasoning if you could copy it just by seeing the steps.",
      "obfuscated billing has long been a staple of all great cloud products. AWS innovated in the space and now many have followed in their footsteps\n \nreply",
      "Also seems very impractical to embed this into a deployed product. How can you possibly hope to control and estimate costs? I guess this is strictly meant for R&D purposes.\n \nreply"
    ],
    "link": "https://openai.com/index/learning-to-reason-with-llms/",
    "first_paragraph": ""
  },
  {
    "title": "Breaking Down OnlyFans' Economics (matthewball.co)",
    "points": 38,
    "submitter": "mef",
    "submit_time": "2024-09-09T01:06:26.000000Z",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=41484634",
    "comments": [
      "Seminal article (I guess), https://xsrus.com/the-economics-of-onlyfans> It\u2019s just as easy to imagine demand for the \u201creal thing\u201d going down due to the emergence of more substitutes as it is to imagine the premium for parasocial authenticity going up. And yet only Generative AI \u201ccreators\u201d will truly do whatever \u201cyou\u201d want and only for you. And unlike real ones, they speak in every language and are available at any time (and eventually, in immersive 3D).Disagree. When (AI is) mentioned it has a negative correlation. Real content will fetch a premium\n \nreply",
      "It's the same pipe dream as \"AI content creators will take over youtube\".There is no \"formula\" for success in the creator economy - the winners are largely random. A better way to look at it is there are 4 million humans out there trying every permutation to crack success, and ~400k actually do it.Unless you have a sufficiently advanced AI agent that is both varying it's content and it's marketing strategy to the tune of maybe ~1000 different iterations it's unlikely we will see a version of OnlyFans that exists that is majority AI generated.The \"parasocial ai girlfriend\" sounds like a flawed premise aswell. OF girls are not therapists - Cardi B, Bhad Bhabie, and others aren't raking in millions because they are good girlfriends (although that is part of the upsell). Social status plays a part in the most successful girls, people seem to subscribe because the creator is popular, especially if she's already built a platform elsewhere.In short, social status does not have an AI substitute.\n \nreply",
      "From another angle, a bunch of us in the tech sector made pretty nice salaries. Very few of us were really all-stars in the sense that everyone knew who we we were on YouTube, etc. Which was fine.\n \nreply",
      "Step 1. ProfitStep 2. Donate to AIPAChttps://archive.ph/Ko8O5\n \nreply",
      "OnlyFans is run by a very small tight knit group of people. A while back, I sat at a poker table in vegas with one for 5 hours. We discussed technology and the future of OF. I was offered a job to run a technology team there - often think I made a mistake not taking it.\n \nreply",
      "[flagged]",
      "I know a few people that \u2018do\u2019 OnlyFans (\u2026and yes, I don\u2019t know them through via their job). The money they\u2019re making ranges from \u2018fairly ok supplementary income\u2019 to \u2018more than satisfies their financial needs\u2019.None have been involved with these \u2018online pimps\u2019 as you put it.I\u2019m not saying that what you\u2019re saying doesn\u2019t happen. I\u2019m aware that you said \u201ca huge segment\u201d.  But you\u2019re showing your hand in your final paragraph. If one has a moral etc view to cut this issue one way or another, there\u2019s sufficient anecdata to do so. The reality is that the adult entertainment industry is large and heterogenous.\n \nreply",
      "> Nearly every creator is making little and are forced to make more and more extreme content to compete.> A huge segment of \"creators\" are still working for online \"networks\" aka pimps who force them to share their earnings under threat of abuse.Can you link some sources for these?\n \nreply",
      "Do you have data or research to back these opinions with?\n \nreply",
      "Their opinion on what constitutes \"porn\" is probably reductive. It's not a straightforward scale or a solid line.There's a lot of nuance in how far away nudity is from pure lace, to corset, shoulderless, miniskirt, onesie, all the way to burka.\n \nreply"
    ],
    "link": "https://www.matthewball.co/all/fansprofitandloss",
    "first_paragraph": "Though a private company, Fenix International (\u201cOnlyFans\u201d) is a UK company and therefore required to publicly disclose certain information pertaining to its business and operations. And while these disclosures are limited, they reveal enough about the OnlyFan\u2019s revenues, profits, scale, defensibility, reach, and impact to say that it is probably the most successful UK company founded since DeepMind in 2010, and the most significant media platform founded since TikTok (via Musical.ly in 2014), and dedicated creator economy platform\u2026 everIn 2024, OnlyFans generated $6.3 billion in gross revenues, up from $300 million five years earlier. Though the company is unlikely to ever match its pandemic growth rates given its current scale, revenues in FY 2023 grew 19% (or $1.1 billion) year-over-year, three percentage points greater than 2022 (which grew $754 million). Though OnlyFans is based around subscriptions, over 60% over consumer spending is now via transactions (and unlike say, Candy Cru"
  },
  {
    "title": "F3 \u2013 Fight Flash Fraud (fight-flash-fraud.readthedocs.io)",
    "points": 35,
    "submitter": "CTOSian",
    "submit_time": "2024-09-09T09:16:58.000000Z",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41486736",
    "comments": [
      "This appears to be a cross-platform version of h2testw, which is widely recommended for finding the true capacity of a storage device. Another common recommendation is ChipGenius and the various manufacturer-specific tools, which can read the real ID of the NAND ICs, that AFAIK is beyond the ability of nearly all the fakers to change:https://blog.elcomsoft.com/2019/01/identifying-ssd-controlle...From the research I've done (mainly related to data recovery), the NAND flash industry seems extremely secretive and shady in many ways --- from the near-zero availability of public datasheets, to the many rebrands/\"reclaimed\"/recycled part sources, to what they're doing to SLC and higher-reliability technologies. There are also ways to determine how worn-out a NAND IC is, but even those may be reversible with the right physical treatments.\n \nreply",
      "Somebody should make this up as a handheld device. Something that you can use to inspect new items, and retailers can use to inspect what their suppliers are sending them.Can a Flipper Zero be programmed for this? It connects to Micro SD cards and USB ports.\n \nreply",
      "A retailer wouldn't want to deal with this. They would expect their distributor to weed out the fakes for them. If enough people complain about poor quality drives, you fire them. In my opinion, anyone selling these must be doing it knowingly at this point.Distributors that care probably use something like this: https://www.ureach-inc.com/\n \nreply",
      "Someone unrmployed should offer to MITM amazon purchases and ensure low priced cards get tested and reshipped or files fraud reports.\n \nreply",
      "So this always overwrites the device to test it, and I was wondering if that was necessary (say, you had started using it). Presumably you only need to write at most N+1 blocks, where N is the number of blocks the device actually has.l, in order to detect exaggeration. But at that point the fake device will have overwritten all of your files anyway, even if they were theoretically on different blocks (of the exaggerated inventory). So I guess the minimum harm to test a device is to hash all your files, then write at most N+1 (unused) blocks, stopping after each to check if any of your files got harmed. In theory that risks at most one block...Of course, it's better to back up the suspect one.\n \nreply",
      "This also has the option of f3probe: https://fight-flash-fraud.readthedocs.io/en/latest/usage.htm...\n \nreply",
      "> hash all your files, then write at most N+1 (unused) blocks, stopping after each to check if any of your files got harmedThat strategy adds O(n^2) reads on top of O(n) writes, though.Even reads don't come for free on modern multi-level cell NAND (due to read disturb), and for just a thousand blocks, you'd end up reading the first block a million times.That's to say nothing of the time this would take.\n \nreply",
      "How long does this tool take to verify a real drive?\"it only writes what\u2019s necessary to test the drive\"How does that actually work, wouldn't that mean the whole stated capacity would have to be written?\n \nreply",
      "Define hash(x) that takes an integer and returns a sector-sized hash.Define S = claimed total number of sectors.  for(i=0; i<S; ++i) {\n    write_sector(i, hash(i))\n    for(j=0; j<=i; ++j) {\n      if(hash(j) != read_sector(j)) {\n        return i\n      }\n    }\n  }\n  return S\n\nThe above pseudo code will return the number of sectors the flash drive actually has.\n \nreply",
      "Sure, so if the drive is genuine, or even one sector short (I recognize it's more typically a much larger fraction for the fraudulent drives), you'd still have to write to nearly the full stated capacity to verify.This approach though, seems to require reading the first sector many times.\n \nreply"
    ],
    "link": "https://fight-flash-fraud.readthedocs.io/en/latest/",
    "first_paragraph": "Contents:"
  },
  {
    "title": "Imbue (Formerly Generally Intelligent) (YC S17) Is Hiring Software Engineers",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-09-13T01:01:08.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=41527191",
    "first_paragraph": ""
  },
  {
    "title": "The Strange Case of the Rogue HP-12c Calculator (dm319.github.io)",
    "points": 20,
    "submitter": "dm319",
    "submit_time": "2024-09-12T18:59:41.000000Z",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41524294",
    "comments": [
      "I wish more was spent on trying to verify the authenticity of the hardware, or contacting HP for comment. The simplest explanation is that a distributor in Brazil sourced counterfeit hardware. Authenticatic hardware shipping with some bespoke and defective firmware seems even less likely than simple counterfeiting.\n \nreply",
      "> Authenticatic hardware shipping with some bespoke and defective firmware seems even less likely than simple counterfeiting.It's not as unlikely as you would think. Electronic counterfeiters are often just ghost shifts at contract manufacturers. If a single company is handling the injection molding, PCB, and assembly, they can run a secret shift that makes units for them to sell themselves. Even if they can't get ahold of all the surplus parts they need, they can design their own.Since the firmware is different,  HP could have also outsourced production maintenance too (i.e. updating firmware if a chip reaches end of life and needs to be replaced with something that's not exactly compatible) which isn't unheard of for legacy products that no one wants to deal with.\n \nreply",
      "Cracking it open to examine the board might be helpful.\n \nreply",
      "The article mentions getting replacements from HP which exhibited the same behavior.\n \nreply"
    ],
    "link": "https://dm319.github.io/pages/2024_09_09_hp12_comma.html",
    "first_paragraph": "2024-09-11\u201cThat\u2019s a non-trivial computation\u201d~Prof Kahan on the time-value of money calculationThe HP-12c is probably the most iconic financial calculator.  Not being in finance myself, and in fact being terribly bad at that kind of thing, I never quite got the purpose of these special-purpose devices.  My ignorance came to a halt due to an unfortunate combination of my fixed-rate mortgage period ending and Liz Truss happening, and I was driven to a sudden keen interest in the \u2018time value of money\u2019 (TVM) calculation.My story begins when I programmed my scientific calculator to solve the TVM unknowns.  As a demonstration of pocket calculator programming, the manual of the venerable HP-42s scientific gives two ways you can write your own TVM solver.  While great as a programming tutorial, it was less good at TVM solving from both an accuracy and a user-interface angle.  I set about improving this program, and as a result learned far more about TVM solving than I could ever have imagined. "
  },
  {
    "title": "Show HN: iFixit created a new USB-C, repairable soldering system (hackaday.com)",
    "points": 673,
    "submitter": "kwiens",
    "submit_time": "2024-09-12T15:18:43.000000Z",
    "num_comments": 323,
    "comments_url": "https://news.ycombinator.com/item?id=41521919",
    "comments": [
      "Soldering is one of those things where the tools you use have a direct impact on the quality and enjoyment of the work. Shitty $20 soldering irons from Home Depot not only produce awful results but they are incredibly frustrating. I\u2019m pretty sure most people who think they suck at soldering and hate it only feel that way because their tool sucks. A good quality soldering iron and high quality, thin solder make a huge, huge difference in output.If your experience with soldering is one of those cheap flimsy $30 dollar things from Amazon paired with fat, chunky solder\u2026 yeah you will hate soldering and you\u2019ll never get even remotely good results. You don\u2019t need to spend $500 dollar or anything but something like what is in this post and a $40 roll of thin gauge solder (which will last the rest of your life) will make soldering actually fun and enjoyable.\u2026I should also mention a solid, heavy parts holder factors into this as well.\n \nreply",
      ">a $40 roll of thin gauge solder (which will last the rest of your life)I dunno, I'm 56 and I'm about to finish the roll I bought as a teenager. (Albeit bought in pre-RoHS times.)\n \nreply",
      "Hopefully your affairs are in order\u2026\n \nreply",
      "Be interesting to see how this stacks up to a good entry level iron like the Hakko FX-888DX.https://hakkousa.com/fx-888dx.html\n \nreply",
      "Hakko fx888 is a good quality iron but quite outdated tech. The biggest downside is it doesn\u2019t measure the temperature at the tip, but at the heater.\n \nreply",
      "When I first bought mine I tried to adjust the temperature in what felt like the natural way to do so, without rtfm first of course.Then I quickly learned that I had adjusted the temperature calibration. I reverted what I had done but now I am not confident about the temperature its operating at, at all. Seems a terrible interface design.\n \nreply",
      "Yep I did that too.I recalibrated by using the thermocouple on my multimeter.That's not my biggest problem though - my biggest problem has just been keeping tips tinned properly. I've succeeded once, but it constantly feels like a struggle.\n \nreply",
      "Can you suggest an alternative please?\n \nreply",
      "In the hakko line, fx-951 is the step-up which uses a heater and sensor in the tip (t15/t12 tips).The alternative, for a hobbyist, would be something like this new iFixit iron, the Pinecil, Miniware TS80/TS100 or one of the variety of chinese irons from amazon and Aliexpress that take Hakko T12 tips (Quicko and similar).On the high-end, professional side, it's JBC and Metcal. Expensive.\n \nreply",
      "I can guarantee it is leagues better. Frankly, I won't solder anymore unless it is with a direct-heat iron. They heat up instantly, cool down quickly, provide far better thermal transfer, and are much more comfortable to hold.Don't brush off what I'm saying before you try a direct-heat iron (Hakko sells them, Pace does, and JBC is the gold standard). They are usually expensive from the big names, but even a Pinecil direct-heat iron for $30$ would be many times better than non-direct-heat irons.\n \nreply"
    ],
    "link": "https://hackaday.com/2024/09/12/review-ifixits-fixhub-may-be-the-last-soldering-iron-you-ever-buy/",
    "first_paragraph": "Like many people who solder regularly, I decided years ago to upgrade from a basic iron and invest in a soldering station. My RadioShack digital station has served me well for the better part of 20 years. It heats up fast, tips are readily available, and it\u2019s a breeze to dial in whatever temperature I need. It\u2019s older than both of my children, has moved with me to three different homes, and has outlived two cars and one marriage (so far, anyway).As such, when the new breed of \u201csmart\u201d USB-C soldering irons started hitting the scene, I didn\u2019t find them terribly compelling. Oh sure, I bought a Pinecil. But that\u2019s because I\u2019m an unrepentant open source zealot and love the idea that there\u2019s a soldering iron running a community developed firmware. In practice though, I only used the thing a few times, and even then it was because I needed something portable. Using it at home on the workbench? It just never felt up to the task of daily use.So when iFixit got in contact a couple weeks back and"
  },
  {
    "title": "FDA Authorizes First Over-the-Counter Hearing Aid Software (fda.gov)",
    "points": 13,
    "submitter": "mgerdts",
    "submit_time": "2024-09-12T22:24:31.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41526288",
    "comments": [
      "Consider the plausible scenario of Apple developing a superior hearing aid -- a medical device.If that happens, will people be able to use best medical device without being subject to the various liberties that tech companies take with users -- violating privacy, and exercising leverage to other purposes?We've become acclimated to expect violation from the \"tech\" industry, but what about the medical field?\n \nreply",
      "The FDA, for all of its warts, is pretty good at curbing bad behavior like this.  All medical devices are pretty rigorously controlled, to the point where you can't really add anything to it that isn't absolutely necessary for the device to function.  And if you do, there's an encyclopedia worth of paperwork you're going to have to write to defend why the functionality is needed.FDA likes to \"duck type\" things, and if your duck doesn't look like the other ducks, you need to create a new animal or make your duck look like other ducks.\n \nreply"
    ],
    "link": "https://www.fda.gov/news-events/press-announcements/fda-authorizes-first-over-counter-hearing-aid-software",
    "first_paragraph": "The .gov means it\u2019s official.Federal government websites often end in .gov or .mil. Before sharing sensitive information, make sure you're on a federal government site.The site is secure. The https:// ensures that you are connecting to the official website and that any information you provide is encrypted and transmitted securely.FDA News Release\nToday, the U.S. Food and Drug Administration authorized the first over-the-counter (OTC) hearing aid software device, Hearing Aid Feature, intended to be used with compatible versions of the Apple AirPods Pro headphones. Once installed and customized to the user\u2019s hearing needs, the Hearing Aid Feature enables compatible versions of the AirPods Pro to serve as an OTC hearing aid, intended to amplify sounds for individuals 18 years or older with perceived mild to moderate hearing impairment.\u00a0\u201cHearing loss is a significant public health issue impacting millions of Americans,\u201d said Michelle Tarver, M.D., Ph.D., acting director of the FDA's Center"
  },
  {
    "title": "GAZEploit: Remote keystroke inference attack by gaze estimation in VR/MR devices (wired.com)",
    "points": 146,
    "submitter": "wallflower",
    "submit_time": "2024-09-12T13:11:25.000000Z",
    "num_comments": 82,
    "comments_url": "https://news.ycombinator.com/item?id=41520516",
    "comments": [
      "I'm genuinely shocked. I assumed that Apple would have foreseen this possibility and locked the Persona's eyes somewhere as long as the user was typing, at least for passwords.\n \nreply",
      "Whole point of the digital face is to look real though, and freezing the gaze would look unnervingly fake.\n \nreply",
      "I'm confident they could come up with a filler eye animation algorithm that was convincing enough to pass muster for short periods of time. Even if hand coding something didn't quite work out, they certainly have tons of eye tracking data internally they could use to train a small model, or optimize parameters.\n \nreply",
      "Why? Most people are capable of fixating at a single point with basically no perceptible eye movement.\n \nreply",
      "But you could at least dampen out or randomize eye travel while looking at the keyboard. Fully reproducing eye output is a recipe for disaster, and that should have been obvious.\n \nreply",
      "It's about tradeoffs, the device is barely 7 months old at this point.  Thankfully the fix is fairly obvious too.\n \nreply",
      "OTOH once you as an outsider know that sometimes the AVP is lying to you about where the wearer is looking why would you ever trust it?For example, you could then use the AVP to stare at people and then claim afterwards you were doing no such thing.\n \nreply",
      "Add a faint glow to indicate they're typing and the continued face animation is a stand-in.\n \nreply",
      "Throw people for a loop and switch your headset keyboard to DVORAK. When they scan your eye movements and apply to QWERTY, they'll be confused AF!\n \nreply",
      "Well, you still only have to try one other password.  If you get locked out after one password attempt and nobody knows that you use dvorak, your defense works, but if you have three attempts, you can also add colemak to your list of things to try ;)\n \nreply"
    ],
    "link": "https://www.wired.com/story/apple-vision-pro-persona-eye-tracking-spy-typing/",
    "first_paragraph": "To revisit this article, visit My Profile, then View saved stories.You can tell a lot about someone from their eyes. They can indicate how tired you are, the type of mood you\u2019re in, and potentially provide clues about health problems. But your eyes could also leak more secretive information: your passwords, PINs, and messages you type.Today, a group of six computer scientists are revealing a new attack against Apple\u2019s Vision Pro mixed reality headset where exposed eye-tracking data allowed them to decipher what people entered on the device\u2019s virtual keyboard. The attack, dubbed GAZEploit and shared exclusively with WIRED, allowed the researchers to successfully reconstruct passwords, PINs, and messages people typed with their eyes.\u201cBased on the direction of the eye movement, the hacker can determine which key the victim is now typing,\u201d says Hanqiu Wang, one of the leading researchers involved in the work. They identified the correct letters people typed in passwords 77 percent of the t"
  },
  {
    "title": "Notepat \u2022 Aesthetic Computer (aesthetic.computer)",
    "points": 9,
    "submitter": "justanothersys",
    "submit_time": "2024-09-12T23:31:48.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://aesthetic.computer/notepat",
    "first_paragraph": ""
  },
  {
    "title": "Random access string compression with FSST and Rust (spiraldb.com)",
    "points": 36,
    "submitter": "aduffy",
    "submit_time": "2024-09-09T14:49:05.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.spiraldb.com/compressing-strings-with-fsst/",
    "first_paragraph": "Random access string compression with FSST and RustVortex\u00a0is our open-source Rust library for compressed Arrow. If you want to have compressed Arrow arrays on-disk, in-memory, or over-the-wire, Vortex is designed to help out. Vortex opts for a columnar representation that is the same both on-disk and in-memory, relying on a set of lightweight compression schemes that allow readers to just-in-time decompress the data you need, when you need it. We\u2019re building out a toolkit of open codecs to efficiently and effectively compress the widest range of data.Our initial focus has been on numeric codecs, and we\u2019ve written about our approach using the FastLanes layout to compress integers at the bleeding edge of what\u2019s possible on today\u2019s hardware. We\u2019ve also implemented ALP to compress floating point arrays, as well as Roaring Bitmaps.However, not all data is numeric. String data is incredibly prevalent in the real world. Apache Parquet, the most popular analytics data format, supports compress"
  },
  {
    "title": "Defusedxml \u2013 defusing XML bombs and other exploits (github.com/tiran)",
    "points": 57,
    "submitter": "gudzpoz",
    "submit_time": "2024-09-12T17:11:18.000000Z",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41523098",
    "comments": [
      "> XML BombThis reminds me of Zip Bomb [1], aka, Zip of Death  (ZOD) [2]1. https://en.m.wikipedia.org/wiki/Zip_bomb2. https://github.com/iamtraction/ZOD\n \nreply",
      "Back in one day\u2026 I saw my first xml/html exploit by another script kiddie on AOL. I was like wtf and began trying to crash my own account. A simple quote mismatch with a bunch of ampersands eventually did it (something 1000 nested ampersand escape sequences). Anyways was pretty proud of what I built, so I found a guy smarting off in an AOL chat and decided to bomb him. And yeah, he was a moderator for AOL\u2026 so at 12 years old I got our family amount blocked and my dad had a uncomfortable call with the AOL reps and how his son was hacking.Ah those were the days\n \nreply",
      "Fascinating reading:> The majority of developers are unacquainted with features such as processing instructions and entity expansions that XML inherited from SGML. At best they know about <!DOCTYPE> from experience with HTML but they are not aware that a document type definition (DTD) can generate an HTTP request or load a file from the file system.I was one of them!\n \nreply",
      "Developers are even less aware that SGML has (and always had) quantities in the SGML declaration, allowing among other things to restrict the nesting/expansion level of entities (and hence to counter EE attacks without resorting to heuristics).Regarding DOCTYPE and DTDs, browsers at best made use of those to switch into or out of \"quirks mode\", on seeing special hardcoded public identifiers but ignored any declarations. WHATWG's cargo cult \"<!DOCTYPE html>\" is just telling an SGML parser that the \"internal and external subset is empty\", meaning there are no markup declarations necessary to parse HTML which is of course bogus when HTML makes abundant use of empty elements (aka void/self-closing elements in HTML parlance), tag omission, attribute shortforms, and other features that need per-element declarations for parsing. Btw that's what defines the XML subset of SGML: that XML can always be parsed without a DTD, unlike HTML or other vocabularies making use of above stated features.Keep in mind SGML is a markup language for text authoring, and it would be pretty lame for a markup language to not have text macros (entities). In fact, the lack of such a basic feature is frequently complained about in browsers. The problems came when people misused XML for service payloads or other generic data exchange. Note SOAP did forbid DTDs, and stacks checked for presence of DTDs in payloads. That said, XML and XML Schema with extensive types for money/decimals, dates, hashes, etc. is heavily used in eg ISO 20022 payments and other financial messages, and to this date, there hasn't evolved a single competitor with the same coverage and scope (with the potential exception of ASN.1 which is even older and certainly more baroque).\n \nreply",
      "> I was one of them!I still one of them!\n \nreply",
      "DefusedXML is an amazing piece of code.This being said, many of the mitigations it enables are now also available by default in many \u201cstandard\u201d libraries. For example, bandit will often tell you to not use lxml in Python, but instead use defusedxml. However, modern versions don\u2019t suffer the same issues at all, and this is a case where automatically following the advice of the linter/SCA is not a great idea.\n \nreply",
      "Do you mean that it is, in fact, a mistake to use defusedxml instead of lxml in Python?\n \nreply",
      "From the author themselves, 6 years ago:> defusedxml.lxml is no longer needed and supported. Nowadays libxml2 has builtin limitation for entity expansion.https://github.com/tiran/defusedxml/issues/25#issuecomment-4...\n \nreply",
      "Note that this is not enabled by default, although there is an upper bound on tree size which does limit the reach of the issue.See https://lxml.de/FAQ.html#is-lxml-vulnerable-to-xml-bombs for more about the tuning knobs.\n \nreply",
      "libxml2 segfaults on me whenever I give it vaguely complicated xsl templates so I'm doubtful about how effective that handling will be.\n \nreply"
    ],
    "link": "https://github.com/tiran/defusedxml",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n\n\n\n\n\"It's just XML, what could probably go wrong?\"Christian Heimes <christian@python.org>The results of an attack on a vulnerable XML library can be fairly\ndramatic. With just a few hundred Bytes of XML data an attacker can\noccupy several Gigabytes of memory within seconds. An attacker\ncan also keep CPUs busy for a long time with a small to medium size\nrequest. Under some circumstances it is even possible to access local\nfiles on your server, to circumvent a firewall, or to abuse services to\nrebound attacks to third parties.The attacks use and abuse less common features of XML and its parsers.\nThe majority of developers are unacquainted with features such as\nprocessing instructions and entity expansions that XML inherited from\nSGML. At best they know about <!DOCTYPE> from experience with HTML but\nthey are not aware that a document type defi"
  },
  {
    "title": "Kolmogorov-Arnold networks may make neural networks more understandable (quantamagazine.org)",
    "points": 214,
    "submitter": "isaacfrond",
    "submit_time": "2024-09-12T10:14:05.000000Z",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=41519240",
    "comments": [
      "The main author of KANs did a tutorial session yesterday at MLCAD, an academic conference focused on the intersection of hardware / semiconductor design and ML / deep learning.\n It was super fascinating and seems really good for what they advertise it for, gaining insight and interpret for physical systems (symbolic expressions, conserved quantities , symmetries). For science and mathematics this can be useful but for engineering this might not be the main priority of an ML / deep learning (to some extent).There are still unknowns for leaning hard tasks and learning capacity over harder problems. Even choices in for things like the chosen basis function used for the KAN \u201cactivations\u201d and what other architectures these layers can be plugged into with some gain is still unexplored. I think as people mess around with KANs we\u2019ll get better answers to these questions.\n \nreply",
      "Presentation by the same author made 2 months back:https://www.youtube.com/watch?v=FYYZZVV5vlY\n \nreply",
      "Is there a publicly available version of the session?\n \nreply",
      "They cannot.Just because one internal operation is understandable, doesn't imply that the whole network is understandable.Take even something much simpler: decision trees. Textbooks give these as an example of understandable systems. A tree where you make one decision based on one feature at a time then at the leaves you output something. Like a bunch of if statements. And in the 90s when computers were slow and trees were small this was true.Today massive decision trees and approaches like random forests can create trees with millions of nodes. Nothing is interpretable about them.We have a basic math gap when it comes to understanding complex systems. Yet another network type solves nothing.\n \nreply",
      "I think of it as \"Could Newton have used this to find the expressions for the forces he was analyzing (eg gravitational force = g m_1 m_2 / d^2)?\". I once asked a physics prof whether that was conceivable in principle, and he said yes. It seems to me like KANs should be able to find expressions like these given experimental data. If that was true, then I don't see how that wouldn't deserve being called interpretability.\n \nreply",
      "> It seems to me like KANs should be able to find expressions like these given experimental data.Perhaps, but this is not something unique to KANs: any symbolic regression method can (at least in theory) find such simple expressions. Here is an example of such type of work (using non-KAN neural networks): https://www.science.org/doi/10.1126/sciadv.aay2631Rephrasing: just because you can reach simple expressions with symbolic regression methods based on neural networks (or KANs) does not necessarily imply that neural networks (or KANs) are inherently interpretable (particularly once you start stacking multiple layers).\n \nreply",
      "Just giving the force law hardly counts as interpret-ability. You probably know that the 1/r^2 in the force law comes from the dimensionality of space. That is the interpretation.\n \nreply",
      "yeah. you can run SHAP[0] on your xgboosted trees, results are kinda interesting, but it doesn't actually explain anything IME.[0] https://shap.readthedocs.io/en/latest/index.html\n \nreply",
      "No wonder. \"Shapley values\" have the problem that they assume all necessary conditions are equally important. Say a successful surgery needs both a surgeon and a nurse, otherwise the patient dies. Shapley values will then assume that both have contributed equally to the successful surgery. Which isn't true, because surgeons are much less available (less replaceable) than nurses. If the nurse gets ill, a different nurse could probably do the task, while if the surgeon gets ill, the surgery may well have to be postponed. So the surgeons are more important for (contribute more to) a successful surgery.\n \nreply",
      "Clearly both are equally important, 100% necessary. This doesn't account for rarity, nor does it account for wages, agreeability, smell or any of the other things it isn't trying to measure. You'll need a different metric for that and if you want to take both into account you should.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/novel-architecture-makes-neural-networks-more-understandable-20240911/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesSeptember 11, 2024Nico Roper for Quanta MagazineContributing WriterSeptember 11, 2024\u201cNeural networks are currently the most powerful tools in artificial intelligence,\u201d said Sebastian Wetzel, a researcher at the Perimeter Institute for Theoretical Physics. \u201cWhen we scale them up to larger data sets, nothing can compete.\u201dAnd yet, all this time, neural networks have had a disadvantage. The basic building block of many of today\u2019s successful networks is known as a multilayer perceptron, or MLP. But despite a string of successes, humans just can\u2019t understand how networks built on these MLPs arrive at their conclusions, or whether there may be some underlying principle that explains those results"
  },
  {
    "title": "Why Haskell? (gtf.io)",
    "points": 309,
    "submitter": "mesaoptimizer",
    "submit_time": "2024-09-12T08:06:27.000000Z",
    "num_comments": 402,
    "comments_url": "https://news.ycombinator.com/item?id=41518600",
    "comments": [
      "> We can generalise this idea of being forced to handle the failure cases by saying that Haskell makes us write total functions rather than partial functions.Haskell doesn't prevent endless recursion. (try e.g. `main = main`)As the typed FP ecosystem is moving towards dependent typing (Agda, Idris, Lean), this becomes an issue, because you don't want the type checker to run indefinitely.The many ad-hoc extensions to Haskell (TypeFamilies, DataKinds) are tying it down. Even the foundations might be a bit too ad-hoc: I've seen the type class resolution algorithm compared to a bad implementation of Prolog.That's why, if you like the Haskell philosophy, why would you restrict yourself to Haskell? It's not bleeding edge any more.Haskell had the possibility of being a standardized language, but look at how few packages MicroHS compiles (Lennart admitted to this at ICFP '24[0]). So the standardization has failed. The ecosystem is built upon C. The Wasm backend can't use the Wasm GC because of how idiosyncratic GHC's RTS is.[1]So what does unique value proposition does GHC have left? Possibly the GHC runtime system, but it's not as sexy to pitch in a blog post like this.[0]: Lennart Augustsson, MicroHS: https://www.youtube.com/watch?v=uMurx1a6Zck&t=36m[1]: Cheng Shao, the Wasm backend for GHC: https://www.youtube.com/watch?v=uMurx1a6Zck&t=13290s\n \nreply",
      "For a long time already I've wanted to make the leap towards learning dependently typed programming, but I was never sure which language to invest in - they all seemed either very focused on just proofs (Coq, Lean) or just relatively far from Haskell in terms of maturity (Agda, Idris).I went through Software Foundations [0] (Coq) which was fun and interesting but I can't say I ever really applied what I used there in software (I did get more comfortable with induction proofs).You're mentioning Lean with Agda and Idris - is Lean usable as a general purpose language? I've been curious about Lean but I got the impression it sort of steps away from Haskell's legacy in terms of syntax and the like (unlike Agda and Idris) so was concerned it would be a large investment and wouldn't add much to what I've learned from Coq.I'd love any insights on what's a useful way to learn more in the area of dependent types for a working engineer today.[0] https://softwarefoundations.cis.upenn.edu/\n \nreply",
      "Lean aims to be a general purpose language, but I haven't seen people actually write HTTP servers in it. If Leo de Moura really wanted it to be general purpose, what does the concurrent runtime look like then? To my knowledge, there isn't one?That's why I've been writing an HTTP server in Idris2 instead. Here's a todo list demo app[1] and a hello world demo[2]. The advantage of Idris is that it compiles to e.g. Racket, a high level language with a concurrent runtime you can bind to from Idris.It's also interesting how languages don't need their own hosting (e.g. Hackage) any more. Idris packages are just listed in a TOML file[3] (like Stackage) but still hosted on GitHub. No need for versions, just use git commit hashes. It's all experimental anyway.[1]: https://janus.srht.site/docs/todolist.html\n[2]: https://git.sr.ht/~janus/web-server-racket-hello-world/tree/...\n[3]: https://github.com/stefan-hoeck/idris2-pack-db/blob/main/STA...\n \nreply",
      "There are tasks, which are implemented as part of the runtime and they appear to plan to integrate libuv in the future. Some of the runtime seems to be fairly easy to hack and have somewhat nice ways of interoperating with both C, C++ and Rust.\n \nreply",
      "> (like Stackage) but still hosted on GitHubI don't have much experience with Haskell, but one of the worst experiences has been Stack's compile time dependency on GitHub. GitHub rate limits you and builds take forever.\n \nreply",
      "That's interesting. Could you say more? This is something that we (speaking as part of the Haskell community) should fix.  As far as I know Stack/Stackage should pick up packages from Hackage.  What does it use GitHub for?\n \nreply",
      "I'm not entirely sure where it uses GitHub and where Hackage, but there are a few GitHub issues on the Stack repo about it:-  Binary upgrade of Stack fails due to GitHub API request limit #4979 (https://github.com/commercialhaskell/stack/issues/4979)-  GitHub rate limiting can affect Stack CI #6034 (https://github.com/commercialhaskell/stack/issues/6034)And a few more. The \"fix\" is having Stack impersonate the user (https://github.com/commercialhaskell/stack/pull/6036) and authenticate to the API. This unblocks progress, but this is really a design bug and not something I think people should emulate.Every other language I've used allows you to build code without authenticating to a remote service.\n \nreply",
      "Lean can be used to write software in [0]. I dare say that it may even be the intended use for Lean 4. Work on porting mathlib to Lean 4 is far along and the mathematicians using it will certainly continue to do so. However there is more space for software written in Lean 4 as well.However...it's no where near ready for production use. They don't care about maintaining backwards compatibility. They are more focused on getting the language itself right than they are about helping people build and maintain software written in it. At least for the foreseeable future. If you do build things in it you're working on shifting ground.But it has a lot of potential. The C code generated by Lean 4 is good. Although, that's another trade-off: compiling to C is another source of \"quirks.\"[0] https://agentultra.github.io/lean-4-hackers/\n \nreply",
      "> Work on porting mathlib to Lean 4 is far alongAs far as I understand, that work is in fact done.\n \nreply",
      "When I last looked into Lean, I was highly unimpressed, even for doing math proofs. There's no way I'd invest into as a general-purpose language.Idris at least does state that they what people building real programs with it and don't want it to just be a research language.For dependent types, I myself am skeptical about languages trying to continuously push more and more stuff into types. I am not certain that such efforts are a net positive on writing good software. By their very definition, the more typed a language gets, the less programs it can represents. That obviously reduces buggy programs, but it also reduces non-buggy programs that you can implement. Highly typed languages force more and more effort into pre-compile time and you will often find yourself trying to fit a problem into the chains of the type system.Rather, I think reasonably multi-paradigm languages like F# are the sweet spot. Just enough strict typing and functional core to get you going for most of your program, but then it allows classes and imperative programming when those paradigms are appropriate.I think the way to go to write better software is better tooling and ergonomics. I don't think type systems are going to magically save us.\n \nreply"
    ],
    "link": "https://www.gtf.io/musings/why-haskell",
    "first_paragraph": "10 Sep, 2024, 6591 words\u201cImpractical\u201d, \u201cacademic\u201d, \u201cniche\u201d. These are a few of the reactions I get when someone discovers that my favourite programming language is Haskell, and not only my favourite in some sort of intellectually-masturbatory way, but favourite for building things, real things, mostly involving web servers. Hobby projects would be one thing, but it gets worse: I have actual teams at Converge working in Haskell, too.I find this reaction quite curious: not only can any problem suitable to one general-purpose programming language be tackled in another, but a lot of the new features we see making their way into programming languages like Python, Rust, and Typescript, are either inspired by, or at least more robustly implemented in, Haskell. It seems to me that part of this response is a version of \u201cchoose boring technology\u201d (although Haskell is far older than most of the most popular programming languages) twisted to suit another pernicious ideology: that programming is no"
  },
  {
    "title": "If I could dissect a sauropod (svpow.com)",
    "points": 105,
    "submitter": "surprisetalk",
    "submit_time": "2024-09-12T13:54:04.000000Z",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41521002",
    "comments": [
      "I recently discovered this blog via Adam Mastroianni's essay contest.(my submission on \"offensive horticulture\" did not even make honorable mention haha)Experimental History, the host of the contest, is a doing amazing work on democratizing science! Check it out[0] https://www.experimental-history.com/p/blog-extravaganza-the...[1] https://www.experimental-history.com\n \nreply",
      "> (my submission on \"offensive horticulture\" did not even make honorable mention haha)Do you have this posted anywhere? I for one would like to learn more about \"offensive horticulture.\"\n \nreply",
      "Thanks for asking :)The original essay was pretty long, so I'm releasing it in chapters here:[0] https://taylor.town/ohChapter 1: \"Proplifting, Plant Piracy, and Dumpster Chocolates\"[1] https://taylor.town/oh-theft\n \nreply",
      "If you haven\u2019t run across https://www.crimepaysbutbotanydoesnt.com/ you may be in for a treat.\n \nreply",
      "Discussion: https://news.ycombinator.com/item?id=41453455\n \nreply",
      "Great article! I've just installed an rss reader for the first time in years  specifically to subscribe to your site. Looking forward to reading more\n \nreply",
      "The blog post recommended the TV show \"inside nature's giants\", and I second it.The bit about the recurrent laryngeal nerve of the giraffe is particulary memorable: https://www.youtube.com/watch?v=cO1a1Ek-HD0\n \nreply",
      "How did enough birds survive post-impact in order for them to still exist, if their \u2018air sack\u2019 lungs are so sensitive to air quality?\n \nreply",
      "I'd guess that the inner parts of a forest environment, perhaps especially if wet (trapping dust on leaves) would have better air quality, but I'd expect that limited sunlight due to dust would be more of a problem than air quality. Smaller more generalist animals like birds and mammals understandably did better than large herbivores (and their predators) dependent on a single type of food source.\n \nreply",
      "yeah thats probly right, inner parts of forest would be cleaner air wise dust gets trapped on leaves and stuff but sunlight is probly a bigger issue, less of it gets thru all the dust and thats bad for plants and animals alike, especially ones that need lots of it like big herbivores and their predators, theyd struggle to survive on limited sunlight and maybe even worse air quality than outer parts of forest, generalist animals like birds and small mammals would do ok tho, they can eat lots of diff things and dont need as much sunlight\n \nreply"
    ],
    "link": "https://svpow.com/2024/09/12/if-i-could-dissect-a-sauropod/",
    "first_paragraph": "SV-POW!  \u2026  All sauropod vertebrae, except when we're talking about Open Access. ISSN 3033-3695Luke Horton asked in a comment on a recent post:Given the chance to examine a titanosaur cadaver with your hypothetical army of anatomists, what would you look for first?*FACEPALM* How we\u2019ve gone almost 17 years without posting about a hypothetical sauropod dissection is quite beyond my capacity. I am also contractually obligated to remind you that the TV show \u201cInside Nature\u2019s Giants\u201d shows dissections of a whale, elephant, giraffe, tiger, anaconda, giant squid, etc., so it\u2019s probably the closest we\u2019ll ever get. Go look up photos of Dr. Joy Reidenberg standing, um, amidst a partially-dissected whale, or just watch that episode, and your sauropod-dissection-visualizer will be properly calibrated.To get back to Luke\u2019s question, there are loads of interesting things that could be dissected in a sauropod, but since the remit here is Matt Wedel x titanosaur, there\u2019s only one possible answer: the l"
  },
  {
    "title": "Some pterosaurs would flap, others would soar (phys.org)",
    "points": 4,
    "submitter": "wglb",
    "submit_time": "2024-09-09T17:27:57.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://phys.org/news/2024-09-pterosaurs-soar-flight-capability-giants.html",
    "first_paragraph": "\n\n                  Click here to sign in with\n                  \n\n\n                  or\n                  \n\n\n\n\nForget Password?\n\nLearn more\nshare this!376TwitShareEmail\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tSeptember 6, 2024\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\tThis article has been reviewed according to Science\u00a0X's \n\t\t\t\t\t\t\t\t\t\t\t\t\teditorial process\n\t\t\t\t\t\t\t\t\t\t\t\t\tand policies.\n\t\t\t\t\t\t\t\t\t\t\t\t\tEditors have highlighted\n\t\t\t\t\t\t\t\t\t\t\t\t\tthe following attributes while ensuring the content's credibility:\n\t\t\t\t\t\t\t\t\t\t\t\t\n fact-checked\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n peer-reviewed publication\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n trusted source\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n proofread\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t by \t\t\t\t\t\t\t\t\t\t Taylor & Francis\nSome species of pterosaurs flew by flapping their wings while others soared like vultures, demonstrates a new study published in the Journal of Vertebrate Paleontology.It has long been debated whether the largest pterosaurs could fly at all.However, \"remarkable\" and \"rare\" three-dimensional fossils of two different large-bodied azhdarchoi"
  },
  {
    "title": "Show HN: Galaxy Visualization (github.com/avicted)",
    "points": 46,
    "submitter": "avicted",
    "submit_time": "2024-09-12T16:32:48.000000Z",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41522670",
    "comments": [
      "This is a cool project. One thing I was confused on at first tho was the large earth sphere in the center of a what looks like a spherical universe of galaxies.  This makes it look more like a cloud of satellites orbiting earth.\n \nreply",
      "Unfortunately this is what is possible to render with only celestial coordinates as input data. I'm looking into getting redshift at data right now, so that I could have the camera at the center of the earth and looking out from earth at different galaxies with different distances and brightness.\n \nreply",
      "For anyone else trying this out on Linux, the build infrastructure can all be replaced with just:    cp -i src/* includes/* .\n    g++ frontend.cpp -lraylib\n    ./a.out\n \nreply",
      "Hi!Thank you!I added a variation of your good solution to the main branch.https://github.com/Avicted/galaxy_visualization_raylib/blob/...\n \nreply",
      "Astronomer here. \nSorry for criticism, but I think it would be much better if galaxies were shown in 3d. There are a lot of surveys providing redshifts, hence 3d positions. Then one would see the cosmic web, otherwise it looks a bit weird just projected on the sphere.\n \nreply",
      "I agree, if you keep the heavenly filament model you should probably restrict the view point origin to the center to have at least have one plausibly correct interpretation.\n \nreply",
      "Hi!Thank you for the criticism! My input data only contains celestial coordinates:\n- Right ascension in arcminutes\n- Declination in arcminutesI can perhaps try to get some redshift data and implement the 3D position for each galaxy. Great idea! Thank you!\n \nreply",
      "Given that oftentimes you get a range of estimated distances (in megaparsecs, MPc), maybe you can show the galaxy as a line instead of a point. The innermost end of the line would be the closest estimated distance. The furthest out end of the line would be the furthest estimated distance. You can put the median estimated distance as a dot on the line. Either that or you'd have to use the median estimated distance for a singular point.Andromeda we have pretty-well established at 0.78 MPc, and M32 at 0.77 MPc.NGC 7768 at 120 MPc.Whereas the largest galaxy we currently know of, ESO 383-G 076, is at 200.59 \u00b1 14.12 MPc. That gives a variability in distance far larger than the distance to most of our nearby closest galaxies!\n \nreply",
      "Well, to play student's advocate here for a second: wouldn't that make it harder to see the immediate difference, given the more complex presentation? IMO this visualization makes it pretty immediately obvious that galaxies aren't random in a way that a massive volumetric map might not.Would definitely be cooler in 3D, of course, I agree with that. Out of curiousity, do you know of any systems that do that? All I can find is multipurpose industry tools like https://www.openspaceproject.com/images and broken tools like https://spacein3d.com/universe-sandbox/.\n \nreply",
      "Fascinating, thanks for posting! Some interesting things I noticed:1. I think we hugged your university site to death, lol.2. When it finally loaded, I saw this: \"Prerequisites: Programming 101\" given this work, that's pretty hilarious! You at the very least used a Data Structure or two, which is Programming 201...3. Am I correct in understanding the implicit approach is \"look, the blue ones are all bunched up and the red ones aren't, so galaxies aren't randomly distributed\"?4. Any takeaways in terms of things you'd like to add, similar ideas that occurred to you, or other cool stuff? You seem like a creative soul and I love dreaming up Three.js-driven space simulations like https://platform.leolabs.space/visualization, so I'd enjoy hearing any thoughts you might have :).\n \nreply"
    ],
    "link": "https://github.com/Avicted/galaxy_visualization_raylib",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        100k real ( +100k random ) galaxies from a sector. Visualized with Raylib.\n      Visualization of 100,000 real galaxies in blue and 100,000 randomly distributed galaxies in red.This project visualizes 100,000 real galaxies in blue and 100,000 randomly distributed galaxies in red. The data is sourced from the GPU programming course at\n\u00c5bo Akademi UniversityThis course teaches parallel programming using CUDA.The assignment is to use CUDA to calculate 10 billion angles between galaxies and prove they are not randomly distributed.\nThe students must leverage the GPU for these calculations on their own using a supercomputer.The students have to prove this on their own.The expected runtime for the calculation is approximately 3 seconds.This program is a visualization of the data, not the solution to the assignment.This project can be built"
  },
  {
    "title": "DEF Con 32 \u2013 AMD Sinkclose Universal Ring-2 Privilege Escalation (Not Redacted) [pdf] (defcon.org)",
    "points": 185,
    "submitter": "ruik",
    "submit_time": "2024-09-07T19:44:07.000000Z",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=41475975",
    "comments": [
      "I was confused by the title, by \"Ring-2\" it means \"Ring -2\" (minus two), which is \"traditionally\" SMM (System Management Mode), a horrible relic that lets your BIOS/UEFI silently steal the CPU from the OS to implement janky drivers or workarounds directly in the firmware (occasionally causing all sorts of mayhem).(Actual Ring 2 is very rarely seen, so perhaps I should have known!)\n \nreply",
      "Wait, there are negative rings!? I'd like to learn more about this but it's not a very easy to search term. Any pointers?\n \nreply",
      "Just terminology. Whenever a new higher-privileged entity is created, it is sometimes described as a negative ring.There was a time when people thought if we could put the secure code in a lower ring, then with it we could protect the rest of the system. With virtualization, the hypervisor is in ring -1, which is technically not a ring, but rather a mode called VMX root operation, post-VMXON. This enables things like the blue pill attack, where the hypervisor is itself presented with a false image of the underlying physical hardware, by a malicious layer. You can find the same pattern in ARM TrustZone, where the secure code is repeatedly broken.\"if only we had ring -N\"\n \nreply",
      "Crazy complexity.  Mind blown!\n \nreply",
      "It's the same reason that the nominal thrust level on the Space Shuttle Main Engines is 104.5%[1].No, not 100% (it was originally), 104.5%. Why? Because you don't go back and change all your rules and documentation following subsequent developments in the field, that causes unnecessary confusion and errors down the road.[1]: https://en.wikipedia.org/wiki/RS-25#Engine_throttle/output\n \nreply",
      "Good article on negative rings:https://medium.com/swlh/negative-rings-in-intel-architecture...\n \nreply",
      "I don't think there actually are, in the sense that there isn't a register somewhere with these values that gets compared against, the way there is with rings 0-3. I've only heard this in the context of reverse engineers describing the layers of access that undocumented parts of a modern CPU system have, I think it's just a made-up analogy. There is presumably some proprietary documentation out there with more official names.\n \nreply",
      "I can't imagine it's a standard thing.On X86 we have ring 0 and 3, with 1 and 2 never used and removed in newer CPUs. ARM has 3 or 4 privilege layers, but they're named differently.They probably just called it ring -2 because it's a couple layers below ring 0.\n \nreply",
      "Arm (Aarch64) Exception Level 0 corresponds to Ring 3 of x86.Arm (Aarch64) Exception Level 1 corresponds to Ring 0 of x86.Arm (Aarch64) Exception Level 2 corresponds to the Hypervisor level a.k.a. Ring -1 of x86.Arm (Aarch64) Exception Level 3 corresponds to the System Management Mode a.k.a. Ring -2 of x86.Fortunately, in Arm EL3 the same instruction set is used as in any other level, unlike in x86, where SMM uses the obsolete 16-bit 8086 ISA, so for compiling programs that will be executed in SMM you have to use a special tool set.Unfortunately, both the Arm EL3 and the x86 SMM allow the manufacturers of computing devices to do things that are either stupid or in direct contradiction with the interests of the owners of the devices and the owners may not be able to do anything to correct this, unless they can exploit vulnerabilities like the one that has now been patched by AMD.There are no valid arguments for the existence of SMM and EL3 and the fact that they are not forbidden by law is a disgrace for the computing industry.Arm EL3 has been created as an imitation of the Intel SMM. The Intel SMM has been created because Microsoft was too lazy to introduce the required power management functions in the Windows and MS-DOS operating systems, so they passed the task to the motherboard or laptop manufacturers, for which Intel has provided SMM, to enable this.\n \nreply",
      "Ring -1 is the host system / virtual machine manager when the ring 0 OS is running as a VM. Ring -2 is more privileged than that since it can interrupt Ring -1 and can affect the execution of VM instructions.\n \nreply"
    ],
    "link": "https://media.defcon.org/DEF%20CON%2032/DEF%20CON%2032%20presentations/DEF%20CON%2032%20-%20Enrique%20Nissim%20Krzysztof%20Okupski%20-%20AMD%20Sinkclose%20Universal%20Ring-2%20Privilege%20Escalation.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Jax and Equinox: What are they and why should I bother? (garymm.org)",
    "points": 45,
    "submitter": "spearman",
    "submit_time": "2024-09-09T14:46:07.000000Z",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41489026",
    "comments": [
      "Equinox has great idioms \u2014 really pioneered the Pytree perspective. Penzai is also great.JAX feels close to achieving a sort of high-level GPGPU ecosystem. Super fledgling \u2014 but I keep finding more little libraries that build on JAX (and can be compositionally used with other JAX libraries because of it).Only problem is that lots of compositional usage leads to big code and therefore big compile times for XLA.\n \nreply",
      "There's quite a few other libraries associated with Equinox in the JAX ecosystem:https://github.com/patrick-kidger/equinox?tab=readme-ov-file...I've enjoyed using Equinox and Diffrax for performing ODE simulations. To my knowledge the only other peer library with similar capabilities is the Julia DifferentialEquations.jl package.\n \nreply",
      "Personally a big fan of Flax. The way it separates the params and the compute graph is - imo - the right (TM) way. Saying this after many years of soing ML :)\n \nreply",
      "For me the questions to answer for whether or not I should bother.Will it try and bind me to other technologies?Does it work out of the box on ${GPU}?Is it well supported?Will it continue to be supported?\n \nreply",
      "Playing with JAX on Google Colab (Nvidia T4), everything works great.Sadly, I cannot get JAX to work with the built-in GPU on my M1 MacBook Air. In theory it's supposed to work:https://developer.apple.com/metal/jax/But it crashes Python when I try to run a compiled function. And that's only after discovering I need an older specific version of jax-metal, because newer versions apparently don't work with M1 anymore (only M2/M3) -- they don't even report the GPU as existing. And even if you get it running, it's missing support for complex numbers.I'm not clear whether it's Google or Apple who is building/maintaining support for Apple M chips though.JAX works perfectly in CPU mode though on my MBA, so at least I can use it for development and debugging.\n \nreply"
    ],
    "link": "https://www.garymm.org/blog/2024/09/08/jaxwhat/",
    "first_paragraph": "2024-09-08This post is written as a Jupyter notebook which you can run and edit using the link below:"
  }
]