[
  {
    "title": "Scientists may have found a way to eliminate chromosome linked to Down syndrome (oup.com)",
    "points": 173,
    "submitter": "MattSayar",
    "submit_time": "2025-07-24T21:59:19 1753394359",
    "num_comments": 91,
    "comments_url": "https://news.ycombinator.com/item?id=44676817",
    "comments": [
      "Interesting, I wonder what else this might lead too! Encouraging we might be getting somewhere.I used to live near a Down syndrome center where a bunch of folks lived and I remember this one lady who was kitted out with Britney Spears everything, lunchbox, t-shirt, hat, and headphones. Everyday I passed by the bus stop she would be dancing her heart out to a Britney track waiting for the bus and it made my world a little brighter.reply",
      "> Everyday I passed by the bus stop she would be dancing her heart out to a Britney track waiting for the bus and it made my world a little brighter.As someone who absolutely loves to \"be weird\", I often wish the world was so much friendlier to folks like this (other than in a token manner).reply",
      "One thing I know for sure is that the person I pass on my way to work always greets me cheerfully, even though I am a stranger to them.reply",
      "Is it just me or do I feel like the society is way more accepting nowadays? I had to pretty much hide who I was during school due to fear of bullying/ not fitting in but most kids these days seem to be able to be themselves in many ways. I agree we can be friendlier though!reply",
      "You\u2019re right the world is a lot more accepting.  No matter how much things improve and how positive the trajectory though, there will be someone online who tells us it\u2019s not enoughreply",
      "As someone that lives as multiple minorities, both visible and not, this is very much untrue.And that applies for many definitions of \"normal\". A person outside the \"norm\", in whatever category, is accepted far less than you claim. Sometimes it may not be visible or even intended, but it's there.reply",
      "Generally that's because they're in the group (or have some sympathy for the group) that still isn't being accepted and may otherwise face obstacles that make it difficult to live a fulfilling life.tolerance is a peace treaty, but there are a ton of gaps in how we implement it because our default socially and politically is more-so based in privilege than co-existance.reply",
      "Yes, and there will be others rolling their eyes and calling out all this \"woke\" acceptance.On a serious note, if the world is a lot more accepting, it's mostly because the youngest generations are a lot more accepting, and the more bigoted among us (which tend to skew older) are slowly dying off.reply",
      "> Is it just me or do I feel like the society is way more accepting nowadays?yes for sure. I make sure to teach that to my kids and model that behavior. Lot of my peers are doing that too. \nI like the 'differently abled' terminology and mindset so much better.When i was growing up the prevailing mindset among parents was that their kids will trampled on if they teach them to show kindness. Now we want our kids to be kind.reply",
      "See, it's stories like this one that make me really question just how ethical it is to completely eliminate Down's from the gene pool. I understand it's the correct medical and scientific thing to do, it's just that it sometimes feels a little bit like eugenics for me.reply"
    ],
    "link": "https://academic.oup.com/pnasnexus/article/4/2/pgaf022/8016019",
    "first_paragraph": ""
  },
  {
    "title": "Graphene OS: a security-enhanced Android build (lwn.net)",
    "points": 107,
    "submitter": "madars",
    "submit_time": "2025-07-24T21:48:53 1753393733",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=44676691",
    "comments": [
      "The one thing that prevents me from switching my Pixel over is the lack of support for emergency services to see your location if you call the emergency number. I know this because I called twice while having GrapheneOS installed.I do some watersports and always take my phone with me, so letting emergency services see my location is good for my safety in case I ever got into trouble on the water. I also have a PLB, but I like to have two devices for redundancy.reply",
      "My only problem with Graphene is the ridiculous low number of supported devices, i know I know, security reasons and so on. But I would accept an lower security hardened version but at least have Graphene instead of Google's junkreply",
      "GrapheneOS community manager here. Google's devices are currently the only ones that meet our requirements (https://grapheneos.org/faq#future-devices).However, we're currently working with another OEM and are hoping to have a device of theirs meet our requirements that can be launched in 2026 or 2027. Nothing set in stone, but we're optimistic thus far.reply",
      "Extremely happy GrapheneOS user here. Thank you so much for the work you and your colleagues do. Speaking for myself, the adoption of a mobile communication and computing choice that both put me in control of what information I interact with and respects my agency enough to present me with the hard choices about what I do and don't want for myself has been a life-altering upgrade in something midway between \"peace of mind\" and \"outright mental health\".Much like you don't hear the sound of a busy city until you go somewhere truly quiet, you don't remember owning your own brain until you evict all of the entities who have been living rent free in it.Keep doing the great work you're doing: it's making people's lives better in dramatically more significant ways than most software.reply",
      "We really appreciate the kind words!reply",
      "If it's a repairable phone like the Fairphone, that would be fantastic. Otherwise, I'm already very satisfied with what you offer. Thanks for you work.reply",
      "Fairphone do not meet our requirements and haven't really been trending towards meeting them generation-by-generation. It doesn't seem to be something that interests them.The unfortunate thing is that they make security promises which aren't upheld in practice (such as shipping security updates on time), so it doesn't inspire confidence as an OEM you could trust to properly support a device for multiple years.We're hoping that there will be people who will enjoy a device from the OEM we're in talks with - we know that there are many people who for various reasons don't want a device from Google, so this will at least offer an option for people who want to use GrapheneOS on a non-Google device.reply",
      "What's ridiculous about it ? There are now 4-5 gens of Pixels with their major/minor bumps too (A series, pro, etc.). There's enough variety at different price points for everyone there.reply",
      "4-5 versions of the same phone in the gigantic sea of possible devicesreply",
      "The other devices don't meet the criteria. Be happy that Pixels are supported, for Google seems to closing down Pixel OS too, making this whole effort rather difficult.reply"
    ],
    "link": "https://lwn.net/SubscriberLink/1030004/898017c7953c0946/",
    "first_paragraph": "\n\n\n\nWelcome to LWN.net\n\nThe following subscription-only content has been made available to you \nby an LWN subscriber.  Thousands of subscribers depend on LWN for the \nbest news from the Linux and free software communities.  If you enjoy this \narticle, please consider accepting the discount offer on the right.  Thank you\nfor visiting LWN.net!\n\n\nSpecial discount offer\n\nSubscribe to LWN now at the\n           \"professional hacker\" level for at least six months,\n           and you will\n           receive a special discount of 25%.\n           \n\n\n\n\n\n\n\n           By Jonathan CorbetJuly 24, 2025\n           \nPeople tend to put a lot of trust into their phones.  Those devices have\naccess to no end of sensitive data about our lives \u2014 our movements,\nfinances, communications, and more \u2014 so phones belonging to even relatively\nlow-profile people can be high-value targets.  Android devices run free\nsoftware, at least at some levels, so it should be possible to ensure that\nthey are working in their owne"
  },
  {
    "title": "Inter-Planetary Network Special Interest Group (ipnsig.org)",
    "points": 95,
    "submitter": "OhMeadhbh",
    "submit_time": "2025-07-24T20:19:57 1753388397",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=44675553",
    "comments": [
      "With all the jibber-jabber about Starlink being down, I figured it was an appropriate time to remind people this exists.  Vint Cerf, one of the founding wizzards of the internet, established the IPN SIG in 1998 to cuss and discuss issues related to IP protocols over high-latency, potentially high-loss links.  Worth poking around if you've not seen it before, though I sort of wish there were more use cases regarding information security.reply",
      "I used to work with some of those board members at JPL!DTN is cool stuff. We had a few applications built up for distributed \"delay aware\" computing so that you could, at the network/application boundary, farm out jobs for e.g., an orbiting compute cluster coming over the horizon.Really fun times.reply",
      "And there are lots of open implementations to play with!https://github.com/nasa/HDTNhttps://github.com/nasa-jpl/ION-DTNhttps://gitlab.com/d3tn/ud3tnhttps://upcn.eu/reply",
      "Off topic, but...> to cuss and discuss...is a turn of phrase that's new to me and I love it. Totally stealing that.reply",
      "It's from my 7th grade history teacher, Mr. Mooneyham.  As in \"tomorrow we're going to cuss and discuss the Louisiana Purchase.  Make sure you read chapter 12.\"  He was also the teacher who had the \"Super-Duper Discussion Stick\" which he used to hit your desk if you fell asleep in class.  And at least once he played the version of the \"Devil Went Down to Georgia\" w/ the bad words left in.In the old days, public schools in suburban Texas were quirky, but the quality of education was relatively decent.  For instance, I remember that Thomas Jefferson was president in 1803 when the Louisiana Purchase was finalized.reply",
      "IMO the most likely solution to interplanetary networking is to throw tons of datacenter and compute that's anywhere more than a few light-seconds from the nearest existing datacenter, then use something along the lines of IPFS to perform data synchronization between planets.reply",
      "you'd probably want a different protocol than IPFS for that application. managing a DHT with extremely high latency isn't going to work very well. something like named-data networking would probably work better since the transmitter can know1. exactly what prefixes need to be buffered based on the received interest messages from deep space\n2. exactly which data rate is possible at any given time\n3. exactly how much data needs to be sent from the buffer in each transmissionoptimizing for high latency really pushes your design choices around compared to our comparatively very low latency uses here on earth. its pretty interesting to think about.reply",
      "Despite the name, IPFS has no properties that make it suitable for this application. It\u2019s very bandwidth intensive and isn\u2019t designed with latency or disruption tolerance in mind.reply",
      "I agree! This was my obsession when I worked at JPL, unfortunately the answer was usually \"no mission will sacrifice their budget for reusable assets\".You'd need a mission whose purpose is to emplace compute stations.That's why we can't have nice things.reply",
      "there's a lot of interesting problems just in the networking.if it took four years for a message to cross the void from where you are to the recipient, you certainly wouldn't want to wait a full eight years to see they didn't send a receipt message and only then retransmit.eight years is some awful latency.you'd probably want to send each message at something like a fibonacci over the months. so, gaps of (1, 1, 2, 3, 5, 8, etc) would mean sending the message on months (1, 2, 4, 7, 12, 20, 33, etc) until you got a confirmation message that they had received it. they would similarly want to send confirmations in the same sort of pattern until they stopped receiving copies of that message.spreading the resends out over time would ensure not all of your bandwidth was going to retransmissions. you'd want that higher number of initial transmissions in hopes that enough of the message makes it across the void that they would have started sending receipts reasonably close to the four years the initial message would take to get there.if you had the equivalent of a galactic fido-net system, it could be decades and lifetimes between messages sent to distant stars and messages sent back.reply"
    ],
    "link": "https://www.ipnsig.org",
    "first_paragraph": "EVENTSWORKING GROUPSLIBRARYABOUT USJOIN USDONATEMoreIPNSIG was founded in 1998 by Vint Cerf and researchers within academia and NASA/JPL. We are now a full Chapter within the Internet Society, known as the Interplanetary Chapter. We work to extend terrestrial networking into solar system space, which is consistent with the Internet Society\u2019s objectives to grow the internet to unpopulated areas, and connect the unconnected domain\u2014and to ensure that even in space, \u201cThe Internet is for Everyone\u201d.Create a common vision for an Interplanetary Network with stakeholdersShape the future of an Interplanetary Network by presenting a narrative and roadmapPromote and increase the maturity of DTN Technology through use in terrestrial and space applicationContact us\u00a9 Interplanetary Networking Special Interest Group 2025IPNSIG adheres to the ISOC Code of ConductIPNSIG 501(c)(3) Designation\u00a0 \u00a0 IPNSIG Bylaws"
  },
  {
    "title": "Positron \u2013 A next-generation data science IDE (posit.co)",
    "points": 100,
    "submitter": "amai",
    "submit_time": "2025-07-21T12:59:56 1753102796",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=44634598",
    "comments": [
      "Kind of unfortunate that it uses pyright and jedi instead of just basedpyright for the more advanced features. Python language support just isn't great with jedi compared to pylance or basedpyright.And not to beat a dead horse, but I'm also not a huge fan of the broad claims around it being OSS when it very clearly has some strict limitations.I've already had to migrate from R Connect Server / Posit Server at work, because of the extreme pricing for doing simple things like having auth enabled on internal apps.We found a great alternative that's much better anyways, plus made our security folks a lot happier, but it was still a massive pain and frustrated users. I've avoided any commercial products from Posit since then and this one makes me hesitant especially with these blurry lines.reply",
      "What is the alternative? Posit princing is absurd. Even academia is charged arm and leg - and the value, very questionable.reply",
      "Agreed, the value is nonsense.This is what we use: https://domino.ai/ The marketing is a bit intense on the website, but the docs are pretty good: https://docs.dominodatalab.com/en/cloud/user_guide/71a047/wh...They definitely target large scale companies, but you can use their SaaS offering and it can be relatively affordable. The best part is the flexibility and scaling, but the license model is awesome too. There's no usage based billing, you just pay a flat license fee per user that writes code and for the underlying cloud costs and they'll deploy it on GCP, AWS, or Azure.They're used by a lot of large companies, but academia as well to replace or augment on-prem HPC clusters. That's what we used them for as well.reply",
      "It's a shame that they don't have you writing marketing copy! The docs are indeed a lot more reasonable looking (to me at least). I work for a small proprietary fund and not some Godzilla company these days so maybe I'm just not the audience, but whew, for purchasing decision makers with subject matter background, that home page would have been a back button real fast if it wasn't linked from your thoughtful comment.I'm interested in your opinion as a user on a bit of a new conundrum for me: for as many jobs / contracts as I can remember, the data science was central enough that we were building it ourselves from like, the object store up.But in my current role, I'm managing a whole different kind of infrastructure that pulls in very different directions and the people who need to interact with data range from full-time quants to people with very little programming experience and so I'm kinda peeking around for an all-in-one solution. Log the rows here, connect the notebook here, right this way to your comprehensive dashboards and graphs with great defaults.Is this what I should be looking at? The code that needs to run on the data is your standard statistical and numerics Python type stuff (and if R was available it would probably get used but I don't need it): I need a dataframe of all the foo from date to date and I want to run a regression and maybe set up a little Monte Carlo thing. Hey that one is really useful, let's make it compute that every night and put it on the wall.I think we'd pay a lot for an answer here and I really don't want to like, break out pyarrow and start setting up tables.reply",
      "Positron looks like the next version of Rstudio, which is currently free. Do you think the plan is to phase out support for the free product and push users into the paid one?reply",
      "Positron inherits many ideas from RStudio, but is a separate project with an intentionally different set of tradeoffs; it gains multi-language/multi-session support, better configuration/extensibility, etc. but at the expense of RStudio's simplicity and support for many R-only workflows.We're still investing in RStudio and while the products have some overlap there's no attempt to convert people from one to the other.(I work at Posit on both of these products)reply",
      "I am talking about the RStudio Server and Connect - these are really expensive. One of the sales reps claimed that it is so expensive because they are a PBC and support open-source development. As in if they were just for profit it would be cheaper, but we should feel good about paying more. I could not take it.reply",
      "I don't want to dunk too hard on this as it seems to be reasonably well made, but how are we making a data science IDE without a good SQL client? I might be biased but that's a major part of the workflow. You're already losing against PyCharm or Visual Studio (not code, the real one) simply because of that.I appreciate that full IDEs are heavy tools, but when I just need an editor I go with vim, if I have to do real work why not take out the power tools?reply",
      "I work on Positron, and I do not entirely disagree with you! We do have support for managing connections from Python and R: https://positron.posit.co/connections-pane.htmlBut we have some pretty big aspirations around expanding our SQL support, based on the features we have already built like that Connections pane, our Data Explorer, our Observable support via Quarto, etc. We plan to invest in this area over the coming months, starting in Q4 this year.reply",
      "Appreciate the response, sorry if I'm being a bit direct but as you probably know that's the style that works the best on a forum like this one.I'll keep tabs on you guys, my DS colleagues might be interested in the project.reply"
    ],
    "link": "https://positron.posit.co/",
    "first_paragraph": "Find out what you need to know to get started using Positron, and then download an installer. Explore our user guides on topics such as choosing interpreters and the Data Explorer. Our FAQs cover some common questions you may have.Positron is built on Code OSS. To learn about basic features like commands, settings, using source control, and more, see the VS Code documentation.We invite you to join us on GitHub Discussions to ask questions and share feedback. Read more about giving feedback and reporting bugs.Positron\u2122 is licensed under the Elastic License 2.0, a source-available license. Read more about what this license means and our decision to use it.Positron\u2122 and the Positron icon\u2122 are trademarks of Posit Software, PBC. All rights reserved.Copyright \u00a9 2022-2025 Posit Software, PBC. All Rights Reserved.Positron 2025.07.0-204LicensePrivacy Policy"
  },
  {
    "title": "I wasted weeks hand optimizing assembly because I benchmarked on random data (vidarholen.net)",
    "points": 221,
    "submitter": "thunderbong",
    "submit_time": "2025-07-21T07:40:01 1753083601",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=44632674",
    "comments": [
      "Chandler Carruth told a similar story in one of his talks.He met Ken Thompson and saw beautiful C code for the first time because he had encountered a performance problem in a service. The service had to choose a policy to enforce (or something) based on the incoming request. It was taking too long to match the criteria of each potential policy against the request.Ken wrote a finite automata based pattern matcher that would simultaneously advance through all of the policies' predicates. It was perfect, and it was much faster than the existing code.Then somebody noticed that 99.9% of requests matched a particular policy, so they changed the existing code to just check that predicate first, and the code sped up a zillion times, much more than with Ken's solution.reply",
      "This is fine assuming the popular request types don\u2019t change, but arguably if both new versions of matching are sufficiently fast then I would prefer Ken\u2019s long term as the other could become slow again if the distribution of request types changes.reply",
      "As a counterpoint, what fraction of the future engineers who will touch the project are likely to be able to competently edit the finite automata based version without introducing bugs and what fraction will be able to competently edit the if statement that checks the particular policy?reply",
      "Nonsense. The pre-check can literally be one line (if common_case {fast_path()} else {slow_path()}), and thus enabling or disabling it is dead simple and obvious if the problem changes in the future.Lines of thinking like that are part of the reason most modern software is so sloooow  :)reply",
      "This is such a great anecdote, thanks for sharing!Somehow relatedly, I still remember the first time I heard about profile-guided optimization which is essentially the same but for all of your code at once (well, same idea, not sure it's aggressive enough to reach the same result as the anecdote you shared).reply",
      "Identifying a representative usage scenario to optimize towards and then implementing that scenario in a microbenchmark test driver are both massively difficult to get right, and a \"failure\" in this regard, as the author found, can be hard to detect before you sink a lot of time into it.Even for seemingly trivial scenarios like searching an array, the contents and length of the array make a massive difference in results and how to optimize (as shown in the last section of this write-up where I tried to benchmark search algorithms correctly https://www.jasonthorsness.com/23).I've not seen a perfect solution to this that isn't just \"thinking carefully about the test setup\" (profile-guided optimization/production profiles replayed for benchmarks seem like maybe it could be an alternative, but I haven't seen that used much).reply",
      "> Identifying a representative usage scenario to optimize towards and then implementing that scenario in a microbenchmark test driver are both massively difficult to get right, and a \"failure\" in this regard, as the author found, can be hard to detect before you sink a lot of time into it.I can vouch for this. I've been doing web performance for nearly 15 years and finding clear representative problems is one the hardest parts of my job. Once I understood this and worked on getting better at finding representative issues, it became the single thing that I did to boost my productivity the most.reply",
      "What have you found are the most useful approaches to collecting the representative issues in a way you can reuse and test? I haven\u2019t worked as much in the web space.reply",
      "A combination of: 1) RUM, 2) Field tracing, 3) Local tracing with throttling (CPU, Network), 4) Focusing either on known problems, or if I'm on less certain territory I will do more vetting to make sure I'm chasing something real. I'll minimize the time spent on issues that I can only catch in one trace, but sometimes it's also all you get so I'll time box that work carefully. It's more of an art than a science.reply",
      "Tracing and continuous profiling made this task significantly easier than it was in the past, fortunately.reply"
    ],
    "link": "https://www.vidarholen.net/contents/blog/?p=1160",
    "first_paragraph": "Vidar's BlogGNU, Linux and technology in generalOnce upon a time I worked in the field of Java Optimizations.\u00a0The target system was a distributed data processing platform that ran across\u00a0hundreds of thousands of machines. At such scales, a 0.5% improvement would easily\u00a0make up my salary going forward, and 2% was a good result for the half.That doesn\u2019t mean it was easy. Never have I ever seen such a highly optimized Java codebase. Not before, not since.\u00a0Every low hanging fruit had long since been picked clean. For example, there was minimal use of java.lang.String because ain\u2019t nobody got time for a second allocation of a char[] with associated indirection and GC churn.In other words, we were looking at increasingly heroic optimizations to justify our own existence.\u00a0Through careful, large scale profiling, I discovered that data serialization was a small but worthwhile place to focus. In particular, VarInt encoding used enough CPU time to warrant investigation.\u00a0If you\u2019re not familiar, a "
  },
  {
    "title": "AMD CEO sees chips from TSMC's US plant costing 5%-20% more (bloomberg.com)",
    "points": 253,
    "submitter": "mfiguiere",
    "submit_time": "2025-07-23T19:34:56 1753299296",
    "num_comments": 437,
    "comments_url": "https://news.ycombinator.com/item?id=44663074",
    "comments": [
      "Here's a gift article link to the original Bloomberg source:https://www.bloomberg.com/news/articles/2025-07-23/amd-ceo-s...",
      "https://archive.is/HS9Gi",
      "If that is the cost of keeping the value within the western economies, we should pay. Plain and simple. I'd even argue it's cheap.reply",
      "If something happens to Taiwan, we won't regret being able to produce these chips domestically. If AI keeps growing like it does, it might even trigger a conflict.reply",
      "Is something the gov should subsidize or at least organize competitors to act like a cartel[0]?Such that the market forces don't push pricing that the plant would naturally die.[0] https://en.wikipedia.org/wiki/Phoebus_cartelreply",
      "Ironically my only opposition to US chips is that we\u2019re less liable to protect Taiwan if China invadesreply",
      "It's probably the opposite. I very much doubt that the factory would continue to operate if the US refused to defend Taiwan. The factory gives Taiwan a huge amount of leverage.reply",
      "This is still TSMC's plant. I bet Taiwan has tight control over it.reply",
      "I think the risk here is Taiwan being invaded by China, in which case having some US-based production helps a lot.reply",
      "It would mean TSMC would basically become a US company, right?reply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2025-07-23/amd-ceo-su-sees-chips-from-us-tsmc-plant-costing-5-to-20-more",
    "first_paragraph": ""
  },
  {
    "title": "There is no memory safety without thread safety (ralfj.de)",
    "points": 262,
    "submitter": "tavianator",
    "submit_time": "2025-07-24T15:35:39 1753371339",
    "num_comments": 237,
    "comments_url": "https://news.ycombinator.com/item?id=44672003",
    "comments": [
      "Every time this conversation comes up, I'm reminded of my team at Dropbox, where it was a rite of passage for new engineers to introduce a segfault in our Go server by not synchronizing writes to a data structure.Swift has (had?) the same issue and I had to write a program to illustrate that Swift is (was?) perfectly happy to segfault under shared access to data structures.Go has never been memory-safe (in the Rust and Java sense) and it's wild to me that it got branded as such.reply",
      "Right, the issue here is that the \"Rust and Java sense\" of memory safety is not the actual meaning of the term. People talk as if \"memory safety\" was a PLT axiom. It's not; it's a software security term of art.This is just two groups of people talking past each other.It's not as if Go programmers are unaware of the distinction you're talking about. It's literally the premise of the language; it's the basis for \"share by communicating, don't communicate by sharing\". Obviously, that didn't work out, and modern Go does a lot of sharing and needs a lot of synchronization. But: everybody understands that.reply",
      "I agree that there are two groups here talking past each other. I think it would help a lot to clarify this:> the issue here is that the \"Rust and Java sense\" of memory safety is not the actual meaning of the termSo what is the actual meaning? Is it simply \"there are no cases of actual exploited bugs in the wild\"?Because in another comment you wrote:> a term of art was created to describe something complicated; in this case, \"memory safety\", to describe the property of programming languages that don't admit to memory corruption vulnerabilities, such as stack and heap overflows, use-after-frees, and type confusions. Later, people uninvolved with the popularization of the term took the term and tried to define it from first principles, arriving at a place different than the term of art.But type confusion is exactly what has been demonstrated in the post's example. So what kind of memory safety does Go actually provide, in the term of art sense?reply",
      ">  People talk as if \"memory safety\" was a PLT axiom. It's not; it's a software security term of art.It's been in usage for PLT for at least twenty years[1]. You are at least two decades late to the party.    Software is memory-safe if (a) it never references a memory location outside the address space allocated by or that entity, and (b) it never executes intstruction outside code area created by the compiler and linker within that address space.\n\n[1]https://llvm.org/pubs/2003-05-05-LCTES03-CodeSafety.pdfreply",
      "Not GP, but that definition seems not to be the one in use when describing languages like Rust--or even tools like valgrind. Those tools value a definition of \"memory safety\" that is a superset (a big one) of the definition referenced in that paper: safety as preventing incorrect memory accesses within a program, regardless of whether those accesses are out of bounds/segmentation violations.reply",
      "...by that definition, can a C program be memory safe as long as it doesn't have any relevant bugs, despite the choice of language?(I realize in practice you'd never know if the program has bugs or not. But I guess you could fairly claim it's memory safe if you're really confident it's bug free, misplaced or not?)reply",
      "It just seems like a bad definition (or at least ambiguous), it should say \"cannot\", or some such excluding term.\nBy the definition as given if a program flips a coin and performs an illegal memory access,\nare runs where the access does not occur memory safe?reply",
      "This is way outside my domain but isn\u2019t the answer: yes, if the code is formally proven safe?Doesn\u2019t NASA have an incredibly strict, specific set of standards for writing safety critical C that helps with writing programs that can be formalized?reply",
      "There are safety recommendations / best practice standards like CERT. None of them will prevent you from making intentional looking but logically unsound memory unsafe operations with C and C++. The code can be very indistinguishable from safe code. The things that C and C++ allow you to do basically makes code written in those languages impossible to fully formally prove. Although there are subsets, the basic integer operations and primitive types are messed up with C. So without uprooting how basic integer and pointer types work, it is impossible to make C and C++ safer. Such change will make all C and C++ programs invalid.C and C++ always defaults to minimum amount of safety for maximum allowance of the compiler interpretation. The priority of the language designers of them is keeping existing terrible code running as long as possible first, letting compilers interpret the source code as freely as possible second.That's why many military and aerospace code actually uses much safer and significantly more formally verifiable Ada.reply",
      "Swift is in the process of fixing this, but it\u2019s a slow and painful transition; there\u2019s an awful lot of unsafe code in the wild that wasn\u2019t unsafe until recently.reply"
    ],
    "link": "https://www.ralfj.de/blog/2025/07/24/memory-safety.html",
    "first_paragraph": "Memory safety is all the rage these days.\nBut what does the term even mean?\nThat turns out to be harder to nail down than you may think.\nTypically, people use this term to refer to languages that make sure that there are no use-after-free or out-of-bounds memory accesses in the program.\nThis is then often seen as distinct from other notions of safety such as thread safety, which refers to programs that do not have certain kinds of concurrency bugs.\nHowever, in this post I will argue that this distinction isn\u2019t all that useful, and that the actual property we want our programs to have is absence of Undefined Behavior.My main issue with the division of safety into fine-grained classes such as memory safety and thread safety is that there\u2019s no meaningful sense in which a thread-unsafe language provides memory safety.\nTo see what I mean by this, consider this program written in Go, which according to Wikipedia is memory-safe:If you run this program (e.g. on the Go playground), it will cras"
  },
  {
    "title": "New Aarch64 Back End (ziglang.org)",
    "points": 60,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-24T21:20:01 1753392001",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=44676315",
    "comments": [
      "I\u2019m a little confused reading this. Is MIR short for \u201cmachine intermediate representation\u201d instead of \u201cmedium intermediate representation\u201d? I generally expect IRs to be relatively platform-independent but it sounds like the \u201cMIR\u201d here is close to Aarch64 binary?reply",
      "In rust it's mid-level IR.Here's what that all means in rust terms [1].  I assume zig doing something similar.[1] https://blog.rust-lang.org/2016/04/19/MIR/reply",
      "Zig has a couple of IR layers. Generally, Zig's compiler goes: AST \u2192 ZIR \u2192 AIR, and from there it'll either emit LLVM bitcode or one of its own, platform-specific \"Machine IR\"reply",
      "Likely refers to Machine IR, a lower level representation that normal LLVM IR lowers to?reply",
      "What's the motivation to avoid LLVM backends?reply",
      "> In exchange [for eliminating the dependency on LLVM], Zig gains these benefits:> All our bugs are belong to us.> The compiler becomes trivial to build from source and to bootstrap with only a C compiler on the host system.> We stop dealing with annoying problems introduced by Linux distributions and package managers such as Homebrew related to LLVM, Clang, and LLD. There have been and continue to be many.> The Zig compiler binary goes from about 150 MiB to 5 MiB.> Compilation speed is increased by orders of magnitude.> [...]https://github.com/ziglang/zig/issues/16270reply",
      "Likely performance - LLVM is somewhat notorious for being slower than ideal.reply"
    ],
    "link": "https://ziglang.org/devlog/2025/#2025-07-23",
    "first_paragraph": "This page contains a curated list of recent changes to main branch Zig.\n      Also available as an\n      RSS feed.\n    \n      This page contains entries for the year 2025. Other years are available in\n      the Devlog archive page.\n    Author: Andrew Kelley & Jacob YoungJacob upstreamed his new backend yesterday.It\u2019s passing 1547/1960 (79%) of the behavior tests compared to the LLVM backend.Although it will grow in size as it approaches completion, it is considerably less logic than the x86 backend:In terms of binary size, it adds about 330KB (2%) to the compiler executable.Jacob made some pretty neat architectural decisions with this one. For instance, it uses the actual machine code instruction encoding for the compiler\u2019s internal MIR structure. This means that instruction encoding is done on the N codegen threads instead of the 1 linker thread.All of the previous backends used a shared two-pass liveness analysis. This new backend has its own similar bespoke two-pass liveness analysi"
  },
  {
    "title": "A GPU Calculator That Helps Calculate What GPU to Use (inference.ai)",
    "points": 36,
    "submitter": "chlobunnee",
    "submit_time": "2025-07-24T22:14:20 1753395260",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44676961",
    "comments": [
      "The best VRAM calculator I have found is https://apxml.com/tools/vram-calculator. It is much more thorough than this one. For example, it understands different models' attention schemes for correct KV cache size calculation, and supports quantization of both the model and the KV cache. Also, fine-tuning. It has its own limitations, such as only supporting specific models. In practice though, the generic calculators are not very useful because model architectures vary (mainly the KV cache) and end up being way off. (Not sure whether or not it would be better to discuss it separately, but I submitted it at https://news.ycombinator.com/item?id=44677409)reply",
      "This is a cheap marketing ploy for a GPU reseller with billboards on highway 101 into SF.reply",
      "Where's AMD support? I have a 9070 XT and would love to see it listed on here.reply",
      "I would have liked to see the RTX 5060 Ti with 16GB mentioned. I can't tell if it's omitted because it won't work, or if it's excluded for some other reason?reply",
      "Yeah, weird miss, but maybe just because it came out more recently.  It can be used for ~anything a 5070 could be used for, no?  Maybe slower, but still.reply",
      "I built a calculator to help researchers and engineers pick the right GPUs for training and inference workloads!It helps compare GPU options by taking in simple parameters (# of transformer layers, token size, etc) and letting users know which GPUs are compatible + their efficiency for training vs inferencing.The idea came from talking with ML researchers frustrated by slow cluster queues or wasting money on overkill GPUs.I'd love feedback on what you feel is missing/confusing!Some things I'm thinking about incorporating next are \n>Allowing users to directly compare 2 GPUs and their specs\n>Allowing users to see whether a fraction of the GPU can complete their workloadI would really appreciate your thoughts/feedback! Thanks!reply",
      "Where's 3090? Or should that fall in the 4090 (24GB VRAM) category?reply",
      "Rather than GPU calculator, this is an NVIDIA calculator.reply",
      "In case you\u2019ve been living in a cave, Nvidia is the defacto standard for LLM compute.reply",
      "No sharding? At all?reply"
    ],
    "link": "https://calculator.inference.ai/",
    "first_paragraph": ""
  },
  {
    "title": "Revisiting Moneyball (djpardis.medium.com)",
    "points": 56,
    "submitter": "sebg",
    "submit_time": "2025-07-24T21:22:15 1753392135",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=44676348",
    "comments": [
      "> Home runs, walks, and strikeouts now dominate baseball, with 35% of plate appearances ending without involving seven defensive players. This has reduced balls in play by 20% since 1980, creating longer games with less actionDo baseball fans ever discuss potentially changing the rules or game setup to mitigate this?reply",
      "As someone for whom Moneyball bought a nice house, I can say with some confidence that I have seen analytics elevate the smartest organisations to new heights, while burying the less sophisticated under their own confirmation bias. Many in the middle do good work that nevertheless gets ignored by the relevant decision makers. The mere existence of stats guarantees you absolutely nothing.reply",
      "Moneyball highlights an inefficiency that I would think would've stopped existing sometime in the 80-90's as data driven approaches have become standard.reply",
      "One of the analytics leads for the Red Sox came to Harvard to give a presentation.  I asked if he could quantify the effects analytics was having compared to the conventional wisdom developed over the course of 150 years of pro baseball.He thought that analytics was changing the probabilities of discrete events by single digits.  Essentially, nobody was doing anything wrong, there were just optimizations that were/are available.Remember that the book/movie is about the A\u2019s, who were eliminated in the first round of the baseball playoffs.reply",
      "It was just after the 90s in 2002 so not too far off. Teams were collecting more data but looking at it wrong and now it's likely much less effective because it's been brought out into the open by both the book and the movie. Though small cap teams are still paying way less per win than the big boys like the Yankees who can pay almost 3x per win.reply",
      "Any BJJ player will understand Moneyball.There are things that work with a very high percentage ...and there are things that are enormously satisfying and exciting to do.If you're interested in winning you will methodically do the \"correct\" things.The problem is it's just so much fun to do a firemans carry ...In the Moneyball narrative, the non-analytical scouts are branded as \"stupid\" or \"thick\" or even \"bigoted\".  I see them as more human and less robotic.  I bet they have more fun than Billy Beane (and the book suggests they do).reply",
      "The trick is to make games where doing the thing that wins the game is also the most interesting thing to see and do.reply",
      "I think a common misconception of Moneyball is that it's about analytics. The broader lesson is that people need to systematically evaluate undervalued assets in sports/business etc.One of the interesting 'post-Moneyball' stories is when old-school scouting methods came back onto the scene. People started overvaluing the new popularized statistics, and the market advantage was to combine the analytics and traditional approach in a cost-efficient manner.reply",
      "If it were named anything else besides \"moneyball,\" the take about it glorifying underpaying players wouldn't exist.I'm not old enough to remember a pre-moneyball world, but MLB has been mitigating the effects of the \u201cthree true outcomes\u201d problem quite well over the last few years. The pitch clock is the best thing to happen to baseball since integration.reply",
      "Moneyball is about identifying undervalued assets, and demonstrating that value in a highly compeitive arena.  Luckily this was done in a popular avenue (baseball) so the lesson was spread across society.reply"
    ],
    "link": "https://djpardis.medium.com/revisiting-moneyball-074fc2435b07",
    "first_paragraph": ""
  },
  {
    "title": "Visa and Mastercard: The global payment duopoly (2024) (quartr.com)",
    "points": 220,
    "submitter": "bilekas",
    "submit_time": "2025-07-24T21:39:08 1753393148",
    "num_comments": 104,
    "comments_url": "https://news.ycombinator.com/item?id=44676559",
    "comments": [
      "Brazil central bank introduced Pix a few years ago. It took over the country as the public basic infrastructure for money transfer. Totally free and instantaneous transactions between people and companies, available to all banks.Then, just last week, the US presidency launched an investigation considering Pix an unfair trade practice against the US.Actions like that may show the current direction of the US government is aligned on preserving status quo. But still, I wonder how impactful a public digital infrastructure for the dollar would be.reply",
      "I got in this thread with the expectation of seeing a comment like yours, so thank you for that.I think what worries the U.S. more is the likelihood of Pix spreading around the world. It\u2019s such a great public program that I believe many countries will eventually adopt it, or adopt some version of it. In fact, AFAIK some places already have it, like Thailand and Malaysia.Consumers like it because it is widely available and free, companies like it doubly so, and even governments like it because it helps to combat tax evasion and fraud.Right now, the only thing that makes credit cards a better proposition is being able to pay without having enough money in the bank, and maybe enjoying greater protection from fraudulent merchants. But I believe even that will change in the future, to the benefit of Pix-like systems.reply",
      "> Right now, the only thing that makes credit cards a better proposition is being able to pay without having enough money in the bankIt will not take long. Banks are already offering products with credit on top of the Pix. Furthermore, contactless Pix is now available in Android phones. If we look from the financial and usability aspects, Pix will continue eating the credit card market share.I didn't know Thailand and Malaysia had similar systems, though. I hope the example spreads! Creating a competitive infrastructure and product is an interesting way to deal with monopolies.reply",
      "About half of the world population has access to some sort of QR based payment system nowadays.India has UPI, China has Ali and Wechat pay. Almost everyone in these two countries can go weeks without having to use cash.In South East Asia, Vietnam is leading QR payments. I live in Ha Noi, and I only carry VND equivalent of $15-20 with me, and it sits in the wallet for ages. Everything from gas stations to restaurants to street vendors to even paying taxes, you do it from a QR code. There is no wallet, the money is directly debited from the account.Thailand, Singapore, and Indonesia have similar systems. In Indonesia, a couple of \"super apps\" had their own wallets, but merged with QRIS a few years back, a lot of Indonesian people can now pay with QR codes, even across wallets and bank accounts.South America and Asia has already started to replace card payments with the QR payments. Rightfully so.reply",
      "Europe (41 countries) has instant SEPA.",
      "In Argentina we have Mercado Pago which is basically this.reply",
      "It is not the same. Mercado Pago is a product from Mercado Livre and charges at least 0.8% per transaction.reply",
      ">\" the only thing that makes credit cards a better proposition is being able to pay without having enough money in the bank\"I am not sure it is a better proposition if one looks at staggering amounts of debt caused by credit cardsreply",
      "You don\u2019t want to spend money you don\u2019t have? Congrats, your credit score is trash and now you can\u2019t rent a house (let alone buy).reply",
      "My understanding is that Pix took over because the Brazilian gov did transfer payments during covid and the (only?) way to get those payments was via Pix.  So it forced everyone to start using it.  And once people had more familiarity with Pix, merchants started pushing for it because it charges ACH level fees.The chargeback system (MED) is only so-so right now, but expected to get better.There is a lot to like about Pix, but the spec is extremely complicated and hard to implement.reply"
    ],
    "link": "https://quartr.com/insights/edge/visa-and-mastercard-the-global-payment-duopoly",
    "first_paragraph": "The global payments processing market is dominated by two major players: Visa and Mastercard. These two companies account for 90% of all payment processing outside of China and have a combined market value of approximately $850 billion. How is it possible that, in the era of global competition, such a large market niche is completely dominated by only two players? Let's explore this in-depth and examine the increasing challenges they face in protecting their market positions.Dominant market share: Visa and Mastercard control approximately 90% of all payment processing outside of China, showcasing a significant duopoly in the global payments processing market with a combined market value of around $850 billion.Historical foundations: The origins of the credit card industry trace back to the 1950s with companies like Diners Club and American Express pioneering the space. Visa and Mastercard emerged from major American banks, leveraging first-mover advantages and restrictive contracts to "
  },
  {
    "title": "Alto turns your Apple Notes into a website (alto.so)",
    "points": 5,
    "submitter": "colinprince",
    "submit_time": "2025-07-25T00:39:55 1753403995",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://alto.so/",
    "first_paragraph": ""
  },
  {
    "title": "Air Force unit suspends use of Sig Sauer pistol after shooting death of airman (nhpr.org)",
    "points": 99,
    "submitter": "duxup",
    "submit_time": "2025-07-24T18:16:03 1753380963",
    "num_comments": 169,
    "comments_url": "https://news.ycombinator.com/item?id=44674123",
    "comments": [
      "There are really two separate claims being made about the P320 and unintentional discharges.One claim is that the gun can fire when dropped at a certain angle from a certain height. The voluntary \"recall\" lets you send it back to Sig and they replace some parts. I think the cause was because the trigger itself was bulky enough for a drop to give it enough inertia to fire, but I'm not 100% sure on that.The other claim is that the P320 can fire without being dropped, and while holstered, seemingly on it's own. That's all I really know about it.I own a P320, and I consider it an unsafe weapon at this point. I have not had the self-recall fix done and I'll never chamber a round in it again, so I guess it's a paperweight now.reply",
      "https://youtube.com/shorts/cOUfurKIjnIreply",
      "I recently bought a SIG P320, and a week later, I started reading articles about it self discharging. =P It\u2019s not like it happens all the time, but it seems that if the safety lever spring\u2019s thickness is off by a thousandth of an inch, and the height of the post it fits on is also off by a thousandth of an inch, and you drop the pistol at just the right angle with enough force, the FBI reportedly got it to discharge once during testing\u2014though officially, the results are inconclusive. Now, some law enforcement agencies are quietly replacing the P320 with the Glock 19. Personally, I\u2019m keeping mine because it\u2019s a great gun, and I love that 21-round magazine. However, I sent in my warranty card in case there\u2019s a recall or something similar.reply",
      "Odds are, you'll never experience the self-discharging issue.  Having said that, I don't find a mostly-reliable firearm acceptable from a safety perspective.  If I don't pull the trigger, it cannot go bang, ever, for any reason.reply",
      "I\u2019m not taking odds on an edc item which takes a lot of banging around. Glock 18 is a simple choice.reply",
      "A thousandth of an inch would do it? They couldn't give more margin-of-safety to a critical part like that?A thousand of an inch isn't such a theoretical number. It's about 25 microns, and I've shimmed one of my back-focusing photography lenses for less than that much (about 10 microns, to be specific). This is something that they ought to be able to machine for, but depending on the context, it might not leave much room for error.reply",
      "> A thousandth of an inch would do it? They couldn't give more margin-of-safety to a critical part like that?If it's true, that's truly terrible design.reply",
      "Ah, Sig. On the one hand, gold (P365). On the other hand, painful, agonizing failure (P320).If you make new-design firearms in any significant volume, you will have safety recalls. I don't know how many times I've gone to another gunmaker's website to see a banner announcing a safety recall. The important thing is that you stand behind your product 100%, and Sig's not doing that, even with arguably the most prestigious military contract in the world that one can hope to get for their pistol.I wouldn't purchase any new Sigs after seeing how they've doubled-down on denial here. This is a life-taking/life-saving tool. It cannot be wrong; it cannot fail.reply",
      "P365 is great if it fits in your hand. But agree, denial has me pretty put off.reply",
      "Ian from Forgotten Weapons posted an interesting video on this a while back:https://m.youtube.com/watch?v=QusWrho19zEAnd then a more recent follow uphttps://m.youtube.com/watch?v=3iWVs2uD1XYreply"
    ],
    "link": "https://www.nhpr.org/nh-news/2025-07-23/sig-sauer-pistol-air-force-shooting-death",
    "first_paragraph": "A major division of the U.S. Air Force is immediately suspending use of a gun made by New Hampshire-based Sig Sauer, following a fatal shooting on a Wyoming base over the weekend.The general in charge of the Air Force Global Strike Command, which comprises more than 33,000 personnel, said in a memo on Monday that he would be pausing the use of Sig Sauer\u2019s M18 pistol immediately pending a \u201ccomprehensive review\u201d of the weapon.A spokesperson confirmed the pause on the weapon is directly related to the death on Sunday of an airman at F.E. Warren Airforce Base in Cheyenne, Wyoming. A statement on the base\u2019s website provided few details about the fatality. On Thursday, the base identified the airman as 21-year old Brayden Tyriq Lovan of Greenville, Kentucky who served in the 90th Security Forces Squadron. Lovan was a multi-sport athlete in high school who loved four-wheeling, hunting and video games, according to his obituary. \u201cWe are deeply saddened by the loss of a valued member of our Mig"
  },
  {
    "title": "PSA: SQLite WAL checksums fail silently and may lose data (avi.im)",
    "points": 236,
    "submitter": "avinassh",
    "submit_time": "2025-07-24T14:48:04 1753368484",
    "num_comments": 111,
    "comments_url": "https://news.ycombinator.com/item?id=44671373",
    "comments": [
      "> The checksums in WAL are likely not meant to check for random page corruption in the middle; maybe they\u2019re just to check if the last write of a frame was fsynced properly or not?This is the correct explanation. The purpose is to detect partial writes, not to detect arbitrary data corruption. If detecting corruption was the goal, then checksumming the WAL without also checksumming the database itself would be fairly pointless.In fact, it's not accurate to say \"SQLite does not do checksums by default, but it has checksums in WAL mode.\" SQLite always uses checksums for its journal, regardless of whether that's a rollback journal or a write-ahead log. [1]For the purpose of tolerating and recovering from crashes/power failures, writes to the database file itself are effectively idempotent. It doesn't matter if only a subset of the DB writes are persisted before a crash, and you don't need to know which ones succeeded, because you can just roll all of them forward or backward (depending on the mode). But for the journal itself, distinguishing partial journal entries from complete ones matters.No matter what order the disk physically writes out pages, the instant when the checksum matches the data is the instant at which the transaction can be unambiguously said to commit.[1]: https://www.sqlite.org/fileformat.htmlreply",
      "Exactly. To put it another way:Imagine the power goes out while sqlite is in the middle of writing a transaction to the WAL (before the write has been confirmed to the application). What do you want to happen when power comes back, and you reload the database?If the transaction was fully written, then you'd probably like to keep it. But if it was not complete, you want to roll it back.How does sqlite know if the transaction was complete? It needs to see two things:1. The transaction ends with a commit frame, indicating the application did in fact perform a `COMMIT TRANSACTION`.2. All the checksums are correct, indicating the data was fully synced to disk when it was committed.If the checksums are wrong, the assumption is that the transaction wasn't fully written out. Therefore, it should be rolled back. That's exactly what sqlite does.This is not \"data loss\", because the transaction was not ever fully committed. The power failure happened before the commit was confirmed to the application, so there's no way anyone should have expected that the transaction is durable.The checksum is NOT intended to detect when the data was corrupted by some other means, like damage to the disk or a buggy app overwriting bytes. Myriad other mechanisms should be protecting against those already, and sqlite is assuming those other mechanisms are working, because if not, there's very little sqlite can do about it.reply",
      "Why is the commit frame not sufficient to determine whether the transaction was fully written or not? Is there a scenario where the commit frame is fsynced to disk but the proceeding data isn't?reply",
      "The disk controller may decide to write out blocks in a different order than the logical layout in the log file itself, and be interrupted before completing this work.reply",
      "It\u2019s worth noting this is also dependent on filesystem behavior; most that do copy-on-write will not suffer from this issue regardless of drive behavior, even if they don\u2019t do their own checksumming.reply",
      "We still have the elevator algorithm on NVMe?reply",
      "NVMe drives do their own manipulation of the datastream.  Wear leveling, GC, trying to avoid rewriting an entire block for your 1 bit change, etc.  NVMe drives have CPUs and RAM for this purpose; they are full computers with a little bit of flash memory attached.  And no, of course they're not open source even though they have full access to your system.reply",
      "Anything that uses NAND storage technology is going to be optimized in some way like this. NVMe is just the messenger.reply",
      "SQLite runs on anything from servers to Internet-connected lightbulbs.reply",
      "Which lightbulbs include SQLite?  I kind of want one.reply"
    ],
    "link": "https://avi.im/blag/2025/sqlite-wal-checksum/",
    "first_paragraph": "This is a follow-up post to my PSA: SQLite does not do checksums and PSA: Most databases do not do checksums by default. In the previous posts I mentioned that SQLite does not do checksums by default, but it has checksums in WAL mode. However, on checksum errors, instead of raising error, it drops all the subsequent frames. Even if they are not corrupt. This is not a bug; it\u2019s intentional.SQLite introduced WAL in 2010. It\u2019s not the default mode, but you\u2019re likely using it if you want higher write throughput. Whenever you make writes, they are first written to the WAL file. Then, during checkpoint operations, the database pages are written from the WAL to the main DB file. Each page in the WAL is called a frame. Each frame has a header, which comprises the frame number, page number, commit marker, and checksums.The way checksums work in WAL is interesting. They use rolling checksums, meaning the checksum of the n+1 frame is computed with the checksum of the nth frame. In other words, a "
  },
  {
    "title": "Why concatenative programming matters (2012) (evincarofautumn.blogspot.com)",
    "points": 45,
    "submitter": "azhenley",
    "submit_time": "2025-07-21T12:57:26 1753102646",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=44634576",
    "comments": [
      "Do most people tend to conclude that concatenative languages are absolutely an intellectual curiosity for any nerd who knows RPN and thought \"what if we kept going?\", but kind of fail in larger-scale production contexts?(Yes, I'm aware of PostScript... Seems to be one of the sole exceptions here... And, uh, PDF... of course...)reply",
      "PostScript is a bit like .Net CLR or WASM: while widely used, it's basically never written by humans directly.Forth is a wonderful way to build a high-ish level self-contained programming environment on very low-resource hardware, like a 8-bit MCU. But thinking in terns of the stack is useless mental gymnastics, this is something a machine should do instead.reply",
      "Related. Others?Why concatenative programming matters (2012) - https://news.ycombinator.com/item?id=32124621 - July 2022 (55 comments)Why Concatenative Programming Matters (2012) - https://news.ycombinator.com/item?id=25244260 - Nov 2020 (18 comments)Why Concatenative Programming Matters (2012) - https://news.ycombinator.com/item?id=19665888 - April 2019 (33 comments)Why Concatenative Programming Matters (2012) - https://news.ycombinator.com/item?id=5542695 - April 2013 (36 comments)Why Concatenative Programming Matters - https://news.ycombinator.com/item?id=3582261 - Feb 2012 (40 comments)reply",
      "Om is a novel, maximally-simple concatenative language - https://news.ycombinator.com/item?id=33382397 - Oct 2022 (49 comments)Stem, an interpreted concatenative programing language - https://news.ycombinator.com/item?id=39151094 - Jan 2024 (74 comments)A Simply Arrived Concatenative Language - https://news.ycombinator.com/item?id=15576215 - Oct 2017 (21 comments)Factor: A Practical Stack Language - https://news.ycombinator.com/item?id=32215048 - Jul 2022 (45 comments)Xs: a concatenative array language inspired by kdb+ and FORTH - https://news.ycombinator.com/item?id=23437003 - Jun 2020 (27 comments)Cat: a statically typed concatenative language - https://news.ycombinator.com/item?id=24534755 - Sep 2020 (13 comments)8th: a secure, cross-platform, concatenative programming language - https://news.ycombinator.com/item?id=15672361 - Nov 2017 (59 comments)Programming in the Point-Free Style - https://news.ycombinator.com/item?id=14077863 - Apr 2017 (101 comments)reply",
      "The author also wrote the \"kitten\" programming language which also has been talked about on here as well back in 2017:https://news.ycombinator.com/item?id=13345832reply",
      "All programming is just function composition.This is an idea that I got from studying category theory.Concatenative programming is just a first step in that direction.I leave the details an an exercise for the reader.reply",
      "side effects are quite the thorn in this theories side. hard to describe message passing in purely applicative terms.reply",
      "Effects are pretty smoothly described by monads; there's an entire well-respected language built on top of that.One of the problems of the purely applicative approach is that you get a nice algebra for describing your results, including the sequence of effects, but reasoning about  the resources spent by the computation becomes harder.reply",
      "Modern programming is. But look at assembly, which is what actual machines do. And you can write assembly with tons of gotos and not a single function in sight.reply"
    ],
    "link": "http://evincarofautumn.blogspot.com/2012/02/why-concatenative-programming-matters.html",
    "first_paragraph": "Jon Purdy writes blarticles on computing, language, and design.What is the difference between concatenative language and FP-systems ?http://c2.com/cgi/wiki?CanProgrammingBeLiberatedFromTheVonNeumannStyleConcatenative languages are an elaboration on and simplification of FP systems; some of the distinctions that FP systems maintain are arbitrary, such as between objects and functions. Also, row polymorphism makes the definition of a complete concatenative system much cleaner and smaller; you can get away with only two stack combinators (see http://tunes.org/~iepos/joy.html), and it\u2019s possible to give a type to the Y combinator (\u2200A B. (A, (A, (A \u2192 B)) \u2192 B) \u2192 B).Nice article! Maybe mention RPN and the Forth language for sake of completeness?Thanks. Have added a couple of notes.Great Post! Thanks for writing it.Cool stuff.Just curious: is there a fundamental reason why you can't use lambda's and variables in a concatenative language?For example, the 'function' \\x could pop the top value of"
  },
  {
    "title": "RE#: High performance derivative-based regular expression matching (2024) (arxiv.org)",
    "points": 16,
    "submitter": "fanf2",
    "submit_time": "2025-07-21T08:42:05 1753087325",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=44633024",
    "comments": [
      "> The match semantics supported in RE# is leftmost-longest (POSIX) rather than leftmost-greedy (a.k.a., backtracking or PCRE) semantics. It is unclear how to support extended Boolean operators in backtracking in the first place and what their intended semantics would be \u2013 this is primarily related to that | is non-commutative in the backtracking semantics and therefore some key distributivity laws such as  (|) \u2261 | no longer preserve match semantics.Non commutative A|B in regex is broken garbage. Bravo for calling it out!The issue is that backtracking \"greedy match\" regex engines, when they deal with the disjunction, simply evaluate the cases left to right and stop on the first match: A|B|C|D is interpreted as \"try regex A; if that matches, then stop, else try B ...\". So if A matches, it's as if B, C and D don't exist.Say we have the regex \"c.r|carp.t\", the input \"carpet-odor\" and are doing a prefix match.  Greedy semantics will try \"c.r\" which matches \"car\", and stop there, declaring a three character match.   Longest match semantics matches all branches simultaneously, picking the longest match. (This is closely related to the \"maximal munch\" principle in tokenizing.) That semantics will match see that the \"carp.t\" branch can match more characters after the \"c.r\" branch no longer matches, and report the six character match \"carpet\".Longest match semantics jibes with a set-theoretical interpretation of regex, and that's why the | operator commutes. R1|R2 means the union of the strings matched by R1 and R2, and so R1|R2 is the same as R2|R1.reply",
      "Well, technically ... if your dialect supports capturing groups, there's technically a non-commutativity anyway.Assuming input is \"ab\",  /(a)b|a(b)/ produces \\1=a, \\2=<missing>\n  /a(b)|(a)b/ produces \\2=<missing>, \\1=b\n\nProbably the easiest way to test this yourself is with GNU sed.reply",
      "> The first industrial implementation of derivatives for standard regexes in an imperative language (C#) materialized a decade\nlater [Saarikivi et al. 2019]Nope; I did it in TXR in early 2010:  b839b5a212fdd77c5dc95b684d7e6790292bb3dc    Wed Jan 13 12:24:00 2010 -0800    Impelement derivative-based regular expressions.reply"
    ],
    "link": "https://arxiv.org/abs/2407.20479",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Use Your Type System (dzombak.com)",
    "points": 225,
    "submitter": "ingve",
    "submit_time": "2025-07-24T14:57:05 1753369025",
    "num_comments": 222,
    "comments_url": "https://news.ycombinator.com/item?id=44671484",
    "comments": [
      "I like this. Very much falls into the \"make bad state unrepresentable\".The issues I see with this approach is when developers stop at this first level of type implementation. Everything is a type and nothing works well together, tons of types seem to be subtle permutations of each other, things get hard to reason about etc.In systems like that I would actually rather be writing a weakly typed dynamic language like JS or a strongly typed dynamic language like Elixir. However, if the developers continue pushing logic into type controlled flows, eg:move conditional logic into union types with pattern matching, leverage delegation etc. the experience becomes pleasant again. Just as an example (probably not the actual best solution) the \"DewPoint\" function could just take either type and just work.reply",
      "Yep. For this reason, I wish more languages supported bound integers. Eg, rather than saying x: u32, I want to be able to use the type system to constrain x to the range of [0, 10).This would allow for some nice properties. It would also enable a bunch of small optimisations in our languages that we can't have today. Eg, I could make an integer that must fall within my array bounds. Then I don't need to do bounds checking when I index into my array. It would also allow a lot more peephole optimisations to be made with Option.Weirdly, rust already kinda supports this within a function thanks to LLVM magic. But it doesn't support it for variables passed between functions.reply",
      "Ada has this ability to define ranges for subtypes. I wish language designers would look at Ada more often.reply",
      "Academic language designers do! But it takes a while for academic features to trickle down to practical languages\u2014especially because expressive-enough refinement typing on even the integers leads to an undecidable theory.reply",
      ">But it takes a while*Checks watch*We're going on 45 years now.reply",
      "Aren't most type systems in widely used languages Turing complete and (consequently) undecidable? Typescript and python are two examples that come to mindBut yeah maybe expressive enough refinement typing leads to hard to write and slow type inference enginesreply",
      "Well, ada is practicalreply",
      "I proposed a primitive for this in TypeScript a couple of years ago [1].While I'm not entirely convinced myself whether it is worth the effort, it offers the ability to express \"a number greater than 0\". Using type narrowing and intersection types, open/closed intervals emerge naturally from that. Just check `if (a > 0 && a < 1)` and its type becomes `(>0)&(<1)`, so the interval (0, 1).I also built a simple playground that has a PoC implementation: https://nikeee.github.io/typescript-intervals/[1]: https://github.com/microsoft/TypeScript/issues/43505reply",
      "Related https://github.com/microsoft/TypeScript/issues/54925My specific use case is pattern matching http status codes to an expected response type, and today I'm able to work around it with this kind of construct https://github.com/mnahkies/openapi-code-generator/blob/main... - but it's esoteric, and feels likely to be less efficient to check than what you propose / a range type.There's runtime checking as well in my implementation, but it's a priority for me to provide good errors at build timereply",
      "In my understanding Rust may gain this feature via \u201cpattern types.\u201dreply"
    ],
    "link": "https://www.dzombak.com/blog/2025/07/use-your-type-system/",
    "first_paragraph": "\n                    \ud83d\udc4b\ud83c\udffb Currently looking for work!\n                    Please see my LinkedIn profile and get in touch, or see ways to support me in the interim.\n                Today I'm discussing a trivially simple technique that I've rarely seen used in production codebases.In programming, we often need to deal with simple values that can be represented by simple, generic types built into our programming language or provided by libraries: types like integer, string, or UUID.In any nontrivial codebase, this inevitably leads to bugs when, for example, a string representing a user ID gets used as an account ID, or when a critical function accepts three integer arguments and someone mixes up the correct order when calling it.A much better solution is to define different types and use them when representing different things! int or string are excellent building blocks, but passing them around your system as-is means you slowly but inevitably lose important context: what they actually r"
  },
  {
    "title": "Vet is a safety net for the curl | bash pattern (github.com/vet-run)",
    "points": 174,
    "submitter": "mooreds",
    "submit_time": "2025-07-24T12:47:29 1753361249",
    "num_comments": 162,
    "comments_url": "https://news.ycombinator.com/item?id=44669998",
    "comments": [
      "My problem with curl|bash is not that the script might be malicious - the software I'm installing could equally be malicious. It's that it may be written incompetently, or just not with users like me in mind, and so the installation gets done in some broken, brittle, or non-standard way on my system. I'd much rather download a single binary and install it myself in the location I know it belongs in.reply",
      "I've also seen really wonderfully-written scripts that, if you read them manually, allow you to change where whatever it is is installed, what features it may have, optional integration with Python environments, or other things like that.I at least skim all the scripts I download this way before I run them. There's just all kinds of reasons to, ranging all the way from the \"is this malicious\" to \"does this have options they're not telling me about that I want to use\".A particular example is that I really want to know if you're setting up something that integrates with my distro's package manager or just yolo'ing it somewhere into my user's file system, and if so, where.reply",
      "> I've also seen really wonderfully-written scripts thatI'll take a script that passes `shellcheck ./script.sh` (or, any other static analysis) first. I don't like fixing other people's bugs in their installation scripts.After that, it's an extra cherry on top to have everything configurable. Things that aren't configurable go into a container and I can configure as needed from there.reply",
      "100% agree. The question of whether I should install lib-X for language-Y using Y's package management system or the distribution's package management system is unresolved.reply",
      "It\u2019s solved by Nix. Whichever package management you choose (nixpkgs or pip or whatever), the derivation should have the same hash in the Nix store.(Nix isn\u2019t the solution for OP\u2019s problems though \u2013 Nix packages are unsigned, so it\u2019s it\u2019s basically backdoor-as-a-service.)reply",
      "right? read before u run. if you cant make sense of it all, dont run. if you can make sense of it all, you're free to refactor it to your own taste :) saves some time usually. as you say, a lot are quite nicely writtenreply",
      "> read before u runLovely sentiment, not applicable when you actually work on something. You read your compiler/linker, your OS, and all libraries you use? Your windowing system? Your web browser? The myriad utilities you need to get your stuff done? And of course, you've read \"Reflections on trusting trust\" and disassembled the full output of whatever you compile?The answer is \"you haven't\", because most of those are too complex for a single person to actually read and fully comprehend.So the question becomes, how do you extend trust. What makes a shell script untrustworthy, but the executable you or the script install trustworthy?reply",
      "Binaries in the Linux world are usually retrieved the \"Official Way\". You use a distro. Therefore you trust \"them\" and how they operate their package manager.This is the \"Unofficial Way\".reply",
      "My problem with it is that it encourages unsafe behavior.How many times will a novice user follow that pattern until some jerk on discord drops a curl|bash and gets hitsIRC used to be a battlefield for these kinds of tricks and we have legit projects like homebrew training users it\u2019s normal to raw dog arbitrary code direcly into your environmentreply",
      "What would you consider a safer behaviour for downloading programs from the internet?reply"
    ],
    "link": "https://github.com/vet-run/vet",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        vet is a command-line tool that acts as a safety net for the risky curl | bash pattern. It lets you inspect, diff against previous versions, and lint remote scripts before asking for your explicit approval to execute. Promoting a safer, more transparent way to handle remote code execution.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.vet is a command-line tool that acts as a safety net for the common but risky curl | bash pattern. It lets you inspect remote scripts for changes, run them through a linter, and require your explicit approval before they can execute.Don't just run it, vet it.We've all seen this pattern for installing software:This is dangerous. The script could be malicious, the server could be compromised, or a transient network error could "
  },
  {
    "title": "Open Source Maintenance Fee (github.com/wixtoolset)",
    "points": 218,
    "submitter": "AndrewDucker",
    "submit_time": "2025-07-24T12:29:35 1753360175",
    "num_comments": 156,
    "comments_url": "https://news.ycombinator.com/item?id=44669858",
    "comments": [
      "I love the innovation. The basic idea here appears to be:- Nobody wants this to be closed source. The code is freely available, and you may do with it as you want. The marginal cost to distribute the code is 0, after all.- The maintainers, as people, don't want to do charity work for companies. Their time is limited, and if they're going to support revenue-generating activities, they want a cut of the revenue.So even if this doesn't get perfectly enforced (and it won't), that's fine! The maintainers are now free to respond to complaints with \"you need to pay us for us to care.\" Companies that pay get some level of support; hobbyists get the same experience. Only the companies that ignore this warning will see the consequences, and it's particularly effective for reports where the author leans on \"but there are a huge number of important users [to me] that are affected.\" Pay up if it matters!It strikes me as a pretty clean solution to a pretty common strain of open-source headache, _especially_ as AI-generated code/reports/etc. are on the rise.reply",
      "I have mixed feelings about this. I\u2019m not a Wix user so this is a general comment on the substance of this.As an open source project no one is forcing you to maintain it. Every fix you put in is something that you do of your own volition. No company can force you to accept a PR or work on it. I think FOSS developers often get stressed about this but unless you personally have financial motivations around what you\u2019ve written you can tell people to fuck off. Yeah they can complain, but you have zero obligation to fix.The sponsorship seems to introduce a business model around what is FOSS, then it\u2019s not FOSS anymore. The entire purpose of FOSS is anybody can copy and repurpose what you\u2019ve built. They can fork it, take it in a different direction and create a business off of it. Depending on the license you\u2019ve explicitly agreed to that.This sentiment is going to be unpopular but I think the outrage is unwarranted.reply",
      "AFAICT, the fee applies if you're using binary releases, or if you open issues, and are also generating revenue from the project. Apparently you can grab the sources and build the binaries yourself (as per the OSS license), never ask for support (by reporting issues), and still have to pay nothing, even in a commercial setting.It looks a bit similar to the RedHat model: they release open-source software (Linux kernel is GPL2), but you may want to buy their binary releases and support.Not so rarely companies would not mind paying a small amount to help support the OSS projects they depend on. This may give CTOs an easy way to expense such support, even though becoming a GitHub sponsor is more involved than many would like; I hope Wix will introduce even easier options (Open Collective, its own non-profit, etc).reply",
      "> or if you open issuesI feel like there should be an exception carved out to this policy, if the submitter of an issue is offering to create (or, as a corporation, dedicate their own engineers' time to creating) a PR to resolve the problem the issue describes.As a maintainer of a few OSS projects myself, I see my fair share of \"choosing beggars\" (i.e. people who don't mentally model others' motivations, and so use github issues to essentially say \"I got this for free, but it's not perfect for me, so can you please improve it in ways X/Y/Z to better suit my needs?\" \u2014 without any consideration of whether their suggested improvement would ever benefit anyone else.)But if an issue's submitter offers to create a PR, then this makes it very clear that they're not operating in this mindset; and in fact, they're being quite considerate! By describing a real problem, and then offering to create a solution to that problem, they:1. make sure that we actually want to solve this problem (i.e. that we don't think of their problem as a WONTFIX / something that doesn't belong upstream)2. give us the opportunity to take over solving the problem ourselves, if we think it's some kind of highly-critical and finicky work3. give us the opportunity to participate in / constrain / steer the design of a solution, before it gets developed (rather than just having code dropped in our laps and having to fight it into an entirely different shape)And it often doesn't even matter if the developer in question really has the skill and experience to develop the proposed solution entirely on their own. To me, a dev who creates a half-baked PR that we can then help shepherd over the line over the course of weeks/months of back-and-forth with them in the PR thread, is someone clearly in the process of developing that skill and experience, and potentially becoming an active contributor to the project \u2014 or maybe even a future maintainer. This sort of willingness to engage in a non-drive-by way is incredibly valuable.reply",
      "It's complicated. Reviewing a PR takes time and effort, and the maintainer may not want to do that for a feature that mainly benefits a company that isn't paying the maintenance fee.OTOH, as a maintainer, if a company finds a bug that would impact a lot of users, I would want them to report it, regardless of their payment status.But saying something like \"Issues from paying customers/donors have higher priority\" is kind of vague, and doesn't provide any concrete value to the payer.  So I'm not really sure what a good balance would be.reply",
      "100%. We're still learning here. I also don't expect every project to choose the same policy on how they tackle issues/PRs when requiring an Open Source Maintenance Fee.reply",
      "I guess the point is if someone discovers a bug and opens a PR to fix it, then that person is, in a way, also a maintainer. They are \u201cpaying\u201d for the maintanence of the project in time and effort.reply",
      "No. A maintainer is someone who maintains the project. Fixing a bug is a great contribution and makes you a contributor to the project. But you need stick around the project for a while, fixing issues that keep the project running and doing tasks that aren't necessarily required for your use of the project to become a maintainer.reply",
      "We're still working through the best way to talk about issues and PRs. This is an area where I expect maintainers to differ in how they apply the OSMF (every maintainer I've spoken to is 100% behind requiring payment for binaries).I wholly agree with the sentiment of your comment and we're still learning.Note: At this time, my project (WiX Toolset) does not require the OSMF for PRs. If there is a README that says we do, then I probably need to fix it.reply",
      "Red Hat does not charge you to open issues on open source projects and never will. Their business model does not hinge on deriving value from core open source principles.reply"
    ],
    "link": "https://github.com/wixtoolset/issues/issues/8974",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page. There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.To ensure the long-term sustainability of this project, we are introducing an Open Source Maintenance Fee. This fee is required to be paid by all consumers of the WiX Toolset project who generate revenue. You can pay via GitHub Sponsors.We plan to enforce the maintenance fee starting with the release of WiX v6.0 on April 5th, 2025. At that time, a EULA on binary releases (including those published to GitHub and NuGet.org) requires payment of the Maintenance Fee.Please see the Open Source Maintenance Fee for more information.Steps to complete:Note: Customers of WiX Developer Direct do NOT need to pay the Open S"
  },
  {
    "title": "Intel CEO Letter to Employees (morethanmoore.substack.com)",
    "points": 174,
    "submitter": "fancy_pantser",
    "submit_time": "2025-07-24T20:52:41 1753390361",
    "num_comments": 301,
    "comments_url": "https://news.ycombinator.com/item?id=44675965",
    "comments": [
      "The strangest part to me about the current trends: why do all these business leaders all do the same things at the same time? E.g. Layoffs + micromanagement + cost focus etc... Is this truly about macroeconomic forces that every business is responding to? Or is it just following the latest fad?There seems to be significant opportunity to zig as others zag. Imagine the Intel letter saying \"we are going to take advantage of the current hiring environment to scoop up talent, and push forward on initiatives.\"reply",
      "> why do all these business leaders all do the same things at the same time? E.g. Layoffs + micromanagement + cost focus etc... Is this truly about macroeconomic forces that every business is responding to? Or is it just following the latest fad?I thought about this a lot over the years.I saw something that piqued my interest last year though, and kind've helped connect the dots. I was on a cruise, and most of the ship was available to guests. One day, one room was cordoned off to an invite-only meeting. The windows weren't blocked, but on the screen was a presentation about AI investments, number of jobs saved (reduced), and etc.I found one of the attendants later during the voyage and chatted her up. She was head of HR in some big company, and the meeting was supposed to be private. But it contained a lot more than just spreadsheets about AI investments. There was homework and whatnot, but the attendees weren't all from a single company. It was \"direction setting\". I don't think it was Intel (topic under discussion) but certainly some loosely related tech industry.I'm convinced that it was nothing less than business collusion.So, back to your question:> why do all these business leaders all do the same things at the same time?Because they're told to.reply",
      "> I'm convinced that it was nothing less than business collusion.Are you sure you didn't just see a sales meeting?If you're a farmer in the market for a $200k combine harvester, sales guys will be happy to put you in a $200-a-night hotel so you can attend their invite-only presentation on how their latest models give you 10% more yield with 30% lower labour cost thanks to the new auto-steer mechanism and six-stage threshing mechanism. And they'll hand-hold you through all the calculations to write a business case.reply",
      "> Are you sure you didn't just see a sales meeting?It's possible!reply",
      "The Capital Order lays out an argument that austerity measures are ultimately labor suppression, not necessary. Of course, that\u2019s true of many pieces of policy wisdom: they start from an assumed good. In this case, the assumed good is the current winners should remain the winners despite, well, losing.https://www.amazon.com/Capital-Order-Economists-Invented-Aus...reply",
      "I agree that this definitely is labor suppression, but it has a real cause: the end of low interest rates and inflation. They can no longer \"grow\" their way into their 6 month bonuses, so they basically have to trim fat and if they all collude on doing it, it _can_ work. If they dont all collude, someone gets cheap engine for growth.reply",
      "I can\u2019t imagine anyone colluding with LBT, unless they told him it was collusion to fool him, and he fell for it.Doing more with less is warning sign like \u201ccurve ahead\u201d.And the agentic focus is not forward-thinking.Our present is to a small degree agentic, and that will increase, but that won\u2019t sustain because (1) latency and (2) technological evolution.It\u2019s more likely that everyone will have their own AI on-board which will have all of the data it needs in local storage that gets regular updates. Evolving to current agentic flows won\u2019t help with that type of processing.reply",
      "Also the end of full R&D expensing, which made software engineers in particular much more expensive in the US.reply",
      "Is the hypothesis that the next 24 months will be measurably better for software engineering jobs than the last 24 months?reply",
      "collusion to suppress wages predates tbe raising of interest rates or inflation increases.all the big tech companies used to have no-poach agreements to not hire from each other, such that they didnt have to compete on pricereply"
    ],
    "link": "https://morethanmoore.substack.com/p/intel-ceo-letter-to-employees",
    "first_paragraph": ""
  }
]