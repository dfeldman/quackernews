[
  {
    "title": "Redis is open source again (antirez.com)",
    "points": 1189,
    "submitter": "antirez",
    "submit_time": "2025-05-01T15:56:35 1746114995",
    "num_comments": 422,
    "comments_url": "https://news.ycombinator.com/item?id=43859446",
    "comments": [
      "I contributed a minor (but imho still neat :p) improvement to Redis under its original license, and personally moved to using redict when the unexpected license change to SSPL was announced - and I was feeling betrayed as a contributor to a properly-FOSS-codebase. (Had they switched to AGPL right away, I'd have been perfectly fine with that change from a moral perspective, ftr.)I have a great deal of respect for antirez and recgnize him as a kind and benevolent member of the FOSS community, but no matter what Redis, Inc. announced or does, they have lost my trust for good, and I will continue to use Redis forks for as long as they exist.\n \nreply",
      "Yeah, we just did this whole ride with Elastic [0]: company changes the license out from under the community, community revolts, company gives up and changes it back. Both companies even pulled the same \"it worked\" excuse (\"while it was painful, it worked\", \"this achieved our goal\").Neither company has built in a legal safety mechanism to prevent themselves from pulling the rug again later and both companies have shown themselves to be untrustworthy stewards. They came groveling back when it turned out that community goodwill really did matter after all, but this is definitely a \"fool me twice, shame on me\" situation.[0] https://news.ycombinator.com/item?id=41394797\n \nreply",
      "Dunno about Redis, but for Elastic I still feel sorry for them being thrown around like a rag doll by Amazon. On principal I will not use the Amazon fork, because I don\u2019t want to support a company that would prefer to fork a project rather than fork over some cash. Amazon is more than willing to sell you their Elasticsearch fork at a loss as long as they can eventually recoup the losses when Elastic inevitably dies. At which point they will naturally abandon the open sources side of their fork and continue development in private, at a much slower rate, while doubling the price of the AWS service. At which point you\u2019ll have no choice but the pay up, cause there aren\u2019t any competitors left.\n \nreply",
      "Whats the point of open source if you can't fork or sell hosted clusters?Also from https://en.wikipedia.org/wiki/OpenSearch_(software):> On September 16, 2024, the Linux Foundation and Amazon Web Services announced the creation of the OpenSearch Software Foundation.[15][16] Ownership of OpenSearch software was transferred from Amazon to OpenSearch Software Foundation, which is organized as an open technical project within the Linux Foundation.OpenSearch is Apache License 2.0. You can do whatever you want to/with it. How are Elastic the good guys in your mind?\n \nreply",
      "> being thrown around like a rag doll by AmazonCan you elaborate on what exactly Amazon did to Elastic? I read all of their blog posts and the only thing I really got out of it was \"they sell hosted Elastic cheaper than we can\", which is hardly surprising given that Elastic really just packages up AWS/GCP/Azure cloud infra. That doesn't have to be AWS selling at a loss, AWS just doesn't need to pay itself.And by all accounts I've read Amazon did contribute back to Elastic development up until Elastic switched the license on them. At that point they forked, but it's hard to blame them when they were deliberately locked out of the original project.Most of the arguments I've seen against Amazon with regard to Elastic have tended to be very vibe-based. Amazon bullied Elastic because that's always what Amazon does! It's plausible, but it's also plausible that Elastic thought they could use Amazon's terrible reputation as a weapon against it without there being any substance.\n \nreply",
      "My understanding is the dispute was mostly about the trademark. Here is a link: https://www.elastic.co/blog/why-license-change-aws (original license change in 2021, not the most recent one).\n \nreply",
      "I sure wish I lived in a world where anti-competitive regulators weren't a joke.\n \nreply",
      "What exactly do you think is anti-competitive about offering an open source product as a service?\n \nreply",
      "NATS almost ended up doing it recently, too. Fortunately they caved in just today, after the CNCF and the community protested. [1] While the outcome is great, it was a bunch of drama for nothing, and their reputation has been harmed.[1] https://news.ycombinator.com/item?id=43863721\n \nreply",
      "Yep. Actually if Redis would end up in CNCF and Redis Labs could provide commercial hosting, extensions - this would be outcome I would be excited about\n \nreply"
    ],
    "link": "https://antirez.com/news/151",
    "first_paragraph": ""
  },
  {
    "title": "The Day Anubis Saved Our Websites from a DDoS Attack (fabulous.systems)",
    "points": 105,
    "submitter": "DoctorOW",
    "submit_time": "2025-05-01T22:34:15 1746138855",
    "num_comments": 63,
    "comments_url": "https://news.ycombinator.com/item?id=43864108",
    "comments": [
      "> Solving the challenge\u2013which is valid for one week once passed\u2013One thing that I've noticed recently with the Arch Wiki adding Anubis, is that this one week period doesn't magically fix user annoyances with Anubis. I use Temporary Containers for every tab, which means that I constantly get Anubis regenerating tokens, since the cookie gets deleted as soon as the tab is closed.Perhaps this is my own problem, but given the state of tracking on the internet, I do not feel it is an extremely out-of-the-ordinary circumstance to avoid saving cookies.\n \nreply",
      "It's even worse if you block cookies outright. Every time I hit a new Anubis site I scream in my head because it just spins endlessly and stupidly until you enable cookies, without even a warning. Absolutely terrible user experience; I wouldn't put any version of this in front of a corporate / professional site.\n \nreply",
      "Browsers that have cookies and/or JS disabled have been getting broken experiences for well over a decade, it's hard to take this criticism seriously when professional sites are the most likely to break in this situation.\n \nreply",
      "It could be worse, the main alternative is something like Cloudflares death-by-a-thousand-CAPTCHAs when your browser settings or IP address put you on the wrong side of their bot detection heuristics. Anubis at least doesn't require any interaction to pass.Unfortunately nobody has a good answer for how to deal with abusive users without catching well behaved but deliberately anonymous users in the crossfire, so it's just about finding the least bad solution for them.\n \nreply",
      "I hated everyone who enabled the cloudflare validation thing on their website, because it was blocked for months (I got stuck on that captcha that was refusing my Firefox). Eventually they fixed it but it was really annoying.\n \nreply",
      "> Unfortunately nobody has a good answer for how to deal with abusive users without catching well behaved but deliberately anonymous users in the crossfire...Uhh, that's not right.\nThere is a good answer, but no turnkey solution yet.The answer is making each request cost a certain amount of something from the person, and increased load by that person comes with increased cost on that person.\n \nreply",
      "Note that this is actually one of the things Anubis does. That's what the proof-of-work system is, it just operates across the full load rather than targeted to a specific user's load. But, to the GP's point, that's the best option while allowing anonymous users.All the best,-HG\n \nreply",
      "I know that you mean a system that transfers money but you are also describing Anubis because PoW is literally to make accessing the site cost more and scale that cost proportional to the load.\n \nreply",
      "> I know that you mean a system that transfer money ....No, cost is used in the fullest abstract meaning of the word here.Time cost, effort cost, monetary cost, work cost, so long as there is a functional limitation that prevents resource exhaustion that is the point.\n \nreply",
      "If cost can be anything, does Anubis implement such a system then, by using proof-of-work as the cost function?\n \nreply"
    ],
    "link": "https://fabulous.systems/posts/2025/05/anubis-saved-our-websites-from-a-ddos-attack/",
    "first_paragraph": "\n\nStart.\n\t\t\t\n\t\t\t\n\t\t\tArchive.\n\t\t\t\n\t\t\tTags.\n\t\t\t\n\t\t\tSearch.\n\t\t\t\n\t\t\tRSS.\n\t\t\t\n\t\t\tJoin the fabulous.community.\n\t\t\t\n\t\nOne part of my work for the ScummVM project is helping to keep the server infrastructure up and running, including our primary server, which hosts our website, wiki, forums, and some internal applications.About three weeks ago, I started receiving monitoring notifications indicating an increased load on the MariaDB server. This in itself is nothing too unusual. It usually means nothing but a sudden influx of new visitors, and in most cases, it is just a link being shared somewhere or a single IP trying to annoy us.The notifications popped up and disappeared as quickly as they appeared. I started to look into the log files of our web server, and I didn\u2019t notice anything too unusual, maybe a bit more background noise. This went on for a couple of days without seriously impacting our server or accessibility\u2013it was a tad slower than usual.And then the website went down.We use a st"
  },
  {
    "title": "Claude Integrations (anthropic.com)",
    "points": 420,
    "submitter": "bryanh",
    "submit_time": "2025-05-01T16:02:14 1746115334",
    "num_comments": 162,
    "comments_url": "https://news.ycombinator.com/item?id=43859536",
    "comments": [
      "For the past couple of months, I\u2019ve been running occasional side-by-side tests of the deep research products from OpenAI, Google, Perplexity, DeepSeek, and others. Ever since Google upgraded its deep research model to Gemini 2.5 Pro Experimental, it has been the best for the tasks I give them, followed closely by OpenAI. The others were far behind.I ran two of the same prompts just now through Anthropic\u2019s new Advanced Research. The results for it and for ChatGPT and Gemini appear below. Opinions might vary, but for my purposes Gemini is still the best. Claude\u2019s responses were too short and simple and they didn\u2019t follow the prompt as closely as I would have liked.Writing conventions in Japanese and Englishhttps://claude.ai/public/artifacts/c883a9a5-7069-419b-808d-0...https://docs.google.com/document/d/1V8Ae7xCkPNykhbfZuJnPtCMH...https://chatgpt.com/share/680da37d-17e4-8011-b331-6d4f3f5ca7...Overview of an industry in Japanhttps://claude.ai/public/artifacts/ba88d1cb-57a0-4444-8668-e...https://docs.google.com/document/d/1j1O-8bFP_M-vqJpCzDeBLJa3...https://chatgpt.com/share/680da9b4-8b38-8011-8fb4-3d0a4ddcf7...The second task, by the way, is just a hypothetical case. Though I have worked as a translator in Japan for many years, I am not the person described in the prompt.\n \nreply",
      "Looks like this is possible due to the relatively recent addition of OAuth2.1 to the MCP spec [0] to allow secure comms to remote servers.However, there's a major concern that server hosters are on the hook to implement authorization. Ongoing discussion here [1].[0] https://modelcontextprotocol.io/specification/2025-03-26[1] https://github.com/modelcontextprotocol/modelcontextprotocol...\n \nreply",
      "That github issue is closed but:> major concern that server hosters are on the hook to implement authorizationDoesn't it make perfect sense for server hosters to implement that? If Claude wants access to my Jira instance on my behalf, and Jira hosts a remote MCP server that aids in exposing the resources I own, isn't it obvious Jira should be responsible for authorization?How else would they do it?\n \nreply",
      "The authorization server and resource server can be separate entities.  Meaning that jira instance can validate the token but not be the one issuing it or handling credentials.\n \nreply",
      "Direct link to the spec page on authorization:  https://modelcontextprotocol.io/specification/2025-03-26/bas...Source: https://github.com/modelcontextprotocol/modelcontextprotocol...\n \nreply",
      "The leap frogging at this point is getting insane (in a good way, I guess?). The amount of time each state of the art feature gets before it's supplanted is a few weeks at this point.LLMs were always a fun novelty for me until OpenAI DeepResearch which started to actually come up with useful results on more complex programming questions (where I needed to write all the code by hand but had to pull together lots of different libraries and APIs), but it was limited to 10/month for the cheaper plan. Then Google Deep Research upgraded to 2.5 Pro and with paid usage limits of 20/day, which allowed me to just throw everything at it to the point where I'm still working through reports that are a week or more old. Oh and it searched up to 400 sources at a time, significantly more than OpenAI which made it quite useful in historical research like identifying first edition copies of books.Now Claude is releasing the same research feature with integrations (excited to check out the Cloudflare MCP auth solution and hoping Val.town gets something similar), and a run time of up to 45 minutes. The pace of change was overwhelming half a year ago, now it's just getting ridiculous.\n \nreply",
      "Out of curiosity - can you give any examples of the programming questions you are using deep research on? I\u2019m having a hard time thinking of how it would be helpful and could use the inspiration.\n \nreply",
      "Easy, any research task that will take you 5 minutes to complete it's worth firing off a Deep Research request while you work on something else in parallel.I use it a lot when documentation is vague or outdated. When Gemini/o3 can't figure something out after 2 tries. When I am working with a service/API/framework/whatever that I am very unfamiliar with and I don't even know what to Google search.\n \nreply",
      "I agree with your overall message - rapid growth appears to encourage competition and forces companies to put their best foot forward.However, unfortunately, I cannot shower much praise on Claude 3.7. And if you (or anyone) asks why - 3.7 seems much better than 3.5, surely? - Then I\u2019m moderately sure that you use Claude much more for coding than for any kind of conversation. In my opinion, even 3.5 Haiku (which is available for free during high loads) is better than 3.7 Sonnet.Here\u2019s a simple test. Try asking 3.7 to intuitively explain anything technical - say, mass dominated vs spring dominated oscillations. I\u2019m a mechanical engineer who studied this stuff and I could not understand 3.7\u2019s analogies.I understand that coders are the largest single group of Claude\u2019s users, but Claude went from being my most used app to being used only after both chatgpt and Gemini, something that I absolutely regret.\n \nreply",
      "My current hypothesis: the more familiar you are with a topic the worse the results from any LLM.\n \nreply"
    ],
    "link": "https://www.anthropic.com/news/integrations",
    "first_paragraph": ""
  },
  {
    "title": "Ask HN: Who is hiring? (May 2025)",
    "points": 103,
    "submitter": "whoishiring",
    "submit_time": "2025-05-01T15:00:46 1746111646",
    "num_comments": 137,
    "comments_url": "https://news.ycombinator.com/item?id=43858554",
    "comments": [
      "Riza | San Francisco | Full-Time | System, Backend, and Full-Stack Engineers | https://riza.ioWe provide isolated runtimes for executing untrusted code, mostly generated by LLMs. Our sandboxing is powered by a combination of WebAssembly, V8, and microVMs. Our customers do things like extract data from log lines at run time by asking claude-3-7-sonnet to generate a parsing function on-the-fly and then sending it to us for execution.Things we need help with:- Our API (https://docs.riza.io/) (Postgres / Go)- Our account dashboard (Postgres / Go / React / TypeScript)- Our code execution engine (Go / Rust)- New products including code generation workflows (Anthropic / OpenAI experience a plus)We\u2019ve raised seed money, but the whole company is currently just me, Andrew and David working out of a converted warehouse on Alabama St. We\u2019re second-time founders, so we know the risk we\u2019re asking you to take and we\u2019re prepared to compensate accordingly.See open roles and apply here: https://jobs.ashbyhq.com/riza\n \nreply",
      "1 point by coderholic 59 days ago | parent | context | prev | next | edit | delete [\u2013] | on: Ask HN: Who is hiring? (March 2025)IPinfo.io | Various Roles | Remote (Anywhere) | Fulltime / Partime / Contract | https://ipinfo.io IPinfo is a leading provider of IP address data. Our API handles over 100 billion requests a month, and we also license our data for use in many products and services you might have used. We started as a side project back in 2013, offering a free geolocation API, and we've since bootstrapped ourselves to a profitable business with a global team of over 40 people, and grown our data offerings to include geolocation, IP to company, carrier detection, and VPN detection. Our customers include T-Mobile, TransUnion, DataDog, DemandBase, and many more.- Software Engineer - integrations (fulltime) - apply at https://ipinfo.bamboohr.com/careers/63?source=aWQ9Mjg%3D\n> We're looking for an engineer to lead our integration efforts - including our various existing platform integrations (Databricks, Splunk, Elastic, Snowflake, Maltego) and SDKs, and also work on new integrations for new platforms and languages.We're always on the look out to strong software or data engineers with an internet measuremenet / analysis background to join our team too.\n \nreply",
      "Akkio | Fully Remote | Full-time | Backend, Fullstack, and Data EngineersAkkio is building an agentic AI platform to help media agencies leverage all of their data across the campaign lifecycle. Think AI-powered audience building, media mix modeling, campaign optimization, analysis and reporting.Akkio only has 2 levels per role: non-Senior and Senior. Open roles:* Backend - 110k-150k w/ equity. Traditional ML/AI and generative AI using Python, with an eye towards Go. https://www.akkio.com/jobs/backend-engineer* Sr Backend - 150k-210k w/ equity. Same as Backend, but Senior. https://www.akkio.com/jobs/senior-backend-engineer* Fullstack Web - 110k-150k w/ equity. Vue.js, Typescript, Node.js / Express, Firebase. Make a buitiful analytics user experience for marketing agencies' advertising and analytic functions. https://www.akkio.com/jobs/frontend-engineer* Sr Fullstack Web - 150k-210k w/ equity. Same as Fullstack Web, but Senior. https://www.akkio.com/jobs/senior-frontend-engineer* Sr Data Engineer - 150k-210k w/ equity. SQL is a must and python & dbt are bonuses. https://www.akkio.com/jobs/senior-data-engineerAll candidates must be authorized to work in the US and have overlap with a continental US timezone\n \nreply",
      "Hi there, first apply button on your website doesnt work rn\n \nreply",
      "Smile ID | Software Engineer, AI/ML | Remote (US, Europe, Africa) | Full-time | https://usesmileid.comWe build Africa\u2019s leading identity verification service, expanding access to secure financial services across the continent in a fast-growing market. We have built proprietary machine learning algorithms and a technology platform to cater for all skin tones, entry-level devices and low bandwidth. We perform 10M+ identity checks per month and are Series B funded with enough revenue to focus on getting to profitability.The role\n- Deploy and optimize scalable full-stack ML serving applications across multiple frameworks (PyTorch, TensorFlow, vLLM) and using tech like FastAPI and NVIDIA Triton Inference Server\n- Build MLOps from the ground up, including data annotation, monitoring, and evaluation.\n- Fine-tune, optimize, and deploy multi-modal models, integrating LLMs with computer vision systems.\n- Integrate computer vision and other ML model results with the rest of the tech stack, including front-end web and mobile interfaces and back-end database services.You\n- 5+ years professional experience in software engineering, with demonstrated experience working with large datasets, machine learning, and/or LLMs.\n- Proficient in Python.\n- Extensive experience with DevOps tools and practices, including CI/CD and containerization.\n- Experience with AWS technologies (such as S3, EC2, RDS, DynamoDB) or similar cloud platforms (Google Cloud or Azure).Compensation: $160k-$210k + equityIf interested, please apply at https://wellfound.com/l/2AUVAy or email me directly at david@usesmileid.com.\n \nreply",
      "I founded and ran a YC company for 8 years before joining Smile ID. Smile ID is a fantastic place to work: meaningful mission, challenging engineering problems (scaling ML pipelines, multimodal models, hundreds of real-world enterprise integrations), and a genuinely talented team. You\u2019re helping hundreds of millions of people access critical services\u2014it\u2019s incredibly rewarding. Highly recommend applying if you want tangible impact, great colleagues, and (optionally!) opportunities to travel in Africa.\n \nreply",
      "Brilliant.org | Software Engineer (Interactives) | Remote (North America), SF, NYC | Full-time | $145k \u2014 $220k | https://brilliant.orgBrilliant is building world-class interactive learning experiences that combine challenging problems, compelling narratives, and delightful visual storytelling.We're hiring interactive engineers to help craft the next generation of interactive learning games and change how the world learns STEM.Engineers at Brilliant think about both \"building the right thing\" AND \"building the thing right\" while pursuing high standards of excellence for ourselves, our product, and our codebase.If you're energized by the prospect of doing the best work of your career and changing how the world learns alongside the most talented peers you've ever worked with, you can learn more and apply here: https://jobs.lever.co/brilliant/2e86ce40-3c7e-4924-b3cb-bfe7....\n \nreply",
      "Equity Trust Company | Analytics Engineer | Cleveland, Ohio or Remote (US) | Full-time | Financial ServicesEquity Trust is a custodian of self-directed IRAs that gives clients the tools to manage their own retirement accounts, and to invest in a range of traditional and alternative assets. We have been helping clients steer their own retirement accounts for over 50 years, and now have over 400,000 accounts, and over $65 billion in assets, under custody. We have offices in Ohio, Florida, Texas, and South Dakota if in-person work is your jam, but fully support remote work as well.The role: We're a team of 6, looking to add a new analytics engineer who will work across our stack (mostly Python, Typescript, AWS) to architect and build out a modern data stack to support operational, reporting, and machine learning use cases across the business. Our work is a mix of API development, data pipelines, the occasional ML side quest or two, and building out the infrastructure to reliably and scalably power it all. Generally, if you like working with data, tackling open-ended problems, and (optionally, but always nice) building cool products to help folks take a more active role in their investments --- you'll probably have a good time here!If you'd like to learn more, drop me a line at c.wetherill [at] trustetc.com\n \nreply",
      "Boost My School | Senior or Staff Software Engineer | Full-time | Remote, USA only | $147-$185K salary | $16-26K bonusLove building a product that improves a user\u2019s life so much that they can\u2019t help but share it with their peers?Boost My School is on a mission to help schools build a better future.  Our platform is trusted by 200+ K-12 schools to modernize their fundraising, events, and auctions.Why work at Boost?1. We make meaningful impact helping schools and students2. We win as part of a thoughtful and collaborative team3. We embrace ownership over our work, growth, and timeFor full job details and instructions on how to apply: https://boostmyschool.com/careers#senior-software-engineerTags: edtech, fintech, social impact, mission-drivenStack: Ruby, Rails, React, GraphQL, Typescript\n \nreply",
      "Sarama | Canine Language Specialist | On-site (San Francisco, CA) | Full Time | Must have a dog | praful@sarama.aiCompany: We\u2019re building smart collars and devices to decode dog communication\u2014using audio, motion, and behavior data. Our goal is to understand what our dogs are trying to say and rethink the worlds of training, healthcare, and companionship as we uncover their language. We've trained models for dog vocalizations and movement patterns, and now we\u2019re integrating behavior and intent.Role: You\u2019ll work closely with our engineering team to help ground our models in real-world behavior. From structured training sessions to experimental communication techniques (e.g. dog buttons, symbolic vocalization training), your work will directly shape how our devices interpret canine communication. You'll guide the design of training protocols, data collection, and help teach dogs how to speak using structured methods.You:+ Experience in dog cognition, vocalization, and training techniques.+ Familiar with AAC devices or button-based communication systems.+ Scientific mindset with hands-on experience.+ Passionate about language and cross-species understanding.+ Must have a dog (ideally one you\u2019ve trained using vocal cues or buttons)Apply: Send us an email with a video or write-up of your past work (bonus if it includes your dog using buttons or vocal cues) to hello@sarama.ai with subject: \u201c{Your dog\u2019s name} wants {something they want}.\u201d In the body, tell us what interspecies communication means to you.---If you refer someone to us, tell them to let us know and we'll send you a gift! (we aren't able to give a cash bonus just yet soon though)\n \nreply"
    ],
    "link": "item?id=43858554",
    "first_paragraph": ""
  },
  {
    "title": "LLMs for Engineering: Teaching Models to Design High Powered Rockets (arxiv.org)",
    "points": 27,
    "submitter": "tamassimond",
    "submit_time": "2025-04-30T22:03:03 1746050583",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=43851212",
    "comments": [
      "My hypothesis is until they can really nail down image to text and text to image, such that training on diagrams and drawings can produce fruitful multi modal output, classic engineering is going to be a tough nut to crack.Software engineering lends itself greatly to LLMs because it just fits so nicely into tokenization. Whereas mechanical drawings or electronic schematics are sort of more like a visual language. Image art but with very exacting and important pixel placement, with precise underlying logical structure.In my experience so far, only O3 can kind of understand an electronic schematic, but really only at a \"Hello World!\" level difficulty. I don't know how easy it will be to get to the point where it can render a proper schematic or edit one it is given to meet some specified electronic characteristics.There are programming languages that are used to define drawings, but the training data would be orders of magnitude less than what is written for humans to learn from.\n \nreply",
      "My experience is that SOTA LLMs still struggle to read even the metadata from a mechanical drawing. They're getting better -- they now are mostly ok at reading things like a BOM or revision table -- but moderately complicated title blocks often trip them up.As for the drawings themselves, I have found them pretty unreliable at reading even quite simple things (i.e. what's the ID of the thru hole?), even when they're specifically dimensioned. As soon as spatial reasoning is required (i.e. there's a dimension from A to B and from A to C and one asks for the dimension B to C), they basically never get it right.This is a place where there's a LOT of room for improvement.\n \nreply",
      "Problem #1 with text-to-image models is that focus is on producing visually attractive photo-realistic artistic images, which is completely orthogonal from what is needed for engineering: accurate, complete, self-consistent, and error-free diagrams.Problem #2 is low control over outputs of text-to-image models. Models don't follow prompts well.\n \nreply",
      "Electrical schematics can be represented with linear algebra and Boolean logic\u2026\nMaybe their being able to \u201cunderstand\u201d such schematics is just a matter of them becoming better at mathematical logic\u2026which is pretty objective.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2504.19394",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Felix86: Run x86-64 programs on RISC-V Linux (felix86.com)",
    "points": 12,
    "submitter": "rguiscard",
    "submit_time": "2025-05-02T00:07:23 1746144443",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43864800",
    "comments": [
      "What remaining challenges are you most interested in solving for felix86\u2014GPU driver support, full 32-bit compatibility, better Wine integration, or something else entirely?\n \nreply",
      "The felix86 compatibility list also lists SuperTux and SuperTuxCart.\"lsteamclient: Add support for ARM64.\" https://github.com/ValveSoftware/Proton/commit/8ff40aad6ef00... .. \nhttps://news.ycombinator.com/item?id=43847860/? box86: https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu...\"New box86 v0.3.2 and Box64 v0.2.4 released \u2013 RISC-V and WoW64 support\" (2023) https://news.ycombinator.com/item?id=37197074/? box64 is:pr RISC-V is:closed: \nhttps://github.com/ptitSeb/box64/pulls?q=is%3Apr+risc-v+is%3...\n \nreply"
    ],
    "link": "https://felix86.com/",
    "first_paragraph": "Run x86-64 programs on RISC-V LinuxA lot of progress was made during the month of April!felix86 is a new x86-64 userspace emulator for RISC-V. It is aimed at achieving good performance in games, and as of now is in relatively early development. A few games are already fully working. As this is the first post, we are going to go through a brief introduction.felix86 is a new x86-64 userspace emulator for RISC-V devices."
  },
  {
    "title": "Mike Waltz Accidentally Reveals App Govt Uses to Archive Signal Messages (404media.co)",
    "points": 26,
    "submitter": "lurkersince2013",
    "submit_time": "2025-05-02T00:56:57 1746147417",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=43865103",
    "comments": [
      "> TM SGNL appears to refer to a piece of software from a company called TeleMessage which makes clones of popular messaging apps but adds an archiving capability to each of them\n \nreply",
      "Crikey that's terrifying. Not even a US company either.\n \nreply",
      "https://archive.ph/oXYXe\n \nreply",
      "It seems reasonable enough that the government may have built a forked version of signal with message archiving that meets documentation requirements.If its an app they wanted kept under wraps, it will make the while Hegseth situation seem a lot more benign.I use Molly Messenger on a secondary phone that doesn't have a SIM, its a fork of Signal with a few differences related to encryption at rest. It still works with normal signal users just fine, on the other end you can't tell I have a different client. If the government has a similarly forked version you could likely still accidentally invite the wrong user in from their normal Signal app and they wouldn't know you're on a forked version with government archiving features.\n \nreply"
    ],
    "link": "https://www.404media.co/mike-waltz-accidentally-reveals-obscure-app-the-government-is-using-to-archive-signal-messages/",
    "first_paragraph": "Mike Waltz, who was until Thursday U.S. National Security Advisor, has inadvertently revealed he is using an obscure and unofficial version of Signal that is designed to archive messages, raising questions about what classification of information officials are discussing on the app and how that data is being secured, 404 Media has found.On Thursday Reuters published a photograph of Waltz checking his mobile phone during a cabinet meeting held by Donald Trump. The screen appears to show messages from various top level government officials, including JD Vance, Tulsi Gabbard, and Marco Rubio.At the bottom of Waltz\u2019s phone\u2019s screen is a message that looks like Signal\u2019s regular PIN verification message. This sometimes appears to encourage users to remember their PIN, which can stop people from taking over their account."
  },
  {
    "title": "Show HN: Kubetail \u2013 Real-time log search for Kubernetes (github.com/kubetail-org)",
    "points": 54,
    "submitter": "andres",
    "submit_time": "2025-05-01T21:11:38 1746133898",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=43863418",
    "comments": [
      "Damn, if you took out the \u201cKubernetes\u201d part, and made it generalized, it looks like you built something that I have wanted to see for a long time. I think log explorers work best as a GUI, and that they need deep integration with structured logs. Basically I just want the DataDog log explorer but locally, and able to simply intake from some files. Some have tried, but they are always too simple, not parsing out properties of structured logs and building good filtering on top of that. I think setting up Grafana/Loki/Whatever is way too heavy for such a simple ask.Anyway all that is anecdotal, what you made here is really cool!\n \nreply",
      "Thanks! Part of what enables us to make a helpful lightweight solution is that we're leveraging the Kubernetes API to give logs context without requiring extra configuration. It'd be great to generalize Kubetail but a lot of that depends on how cloud platforms evolve over the next few years. Do you use Kubernetes?\n \nreply",
      "Sorry for bringing up my own side-project on a \"Show HN\", but I'm making humanlog.io which does exactly what you want. Local-first log query engine (and tracing too, soon). You feed it your logs and you can search them, aggregate them, and soon make some graphs and dashboards with them. It started as just a CLI tool to parse and make structured logs pretty, and now I'm turning it into a full observability tool on your machine.It's very WIP but I would love to help you get started if you want to try it out.\n \nreply",
      "Wow, this is exactly what I\u2019ve been missing\u2014juggling a dozen kubectl logs windows and still losing context. Seeing all container logs merged in real time is a game-changer for debugging multi-pod workloads. Love that it runs locally against the API\u2014no more sending sensitive logs offsite. Big thanks to the author for saving my sanity here!\n \nreply",
      "While the search offered is handy, I watch logs on multi-pod workloads via:    kubectl logs -f -l app=api --max-log-requests=50\n\nThis follows along all pods with the given label (app: api) for up to 50 pods or however many you want. Quite useful when I'm looking for specific output such as ERROR logs to just pipe it to grep like this:    kubectl logs -f -l app=api --max-log-requests=50 | grep ERROR\n\nand get realtime filtering of all log output without having to tail individual pods by name.\n \nreply",
      "Thanks! Your comment made my day! It sounds like your use-case is similar to mine when I started working on the project. Now we have a community of contributors working on Kubetail so if you have time, stop by our Discord and let us know what else we can do to help (https://discord.gg/CmsmWAVkvX).\n \nreply",
      "\"Search\" feels like a bit of a stretch to me--that suggests that it plays in the same space as OpenSearch or Splunk. There's no index here that I can tell.\"Filter\" sounds more accurate.\n \nreply",
      "Yes, there's no index. It uses grep (powered by ripgrep) under the hood.\n \nreply",
      "My personal preference for log tailing is Stern. It doesn't have a web UI but then I've never felt like I needed one.https://github.com/stern/stern\n \nreply",
      "+1 for Stern especially since it only has Go dependencies whereas Kubetail does not. Ease of integration with an existing stack is a bigger addition than the lack of a web UI is a subtraction.\n \nreply"
    ],
    "link": "https://github.com/kubetail-org/kubetail",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Real-time logging dashboard for Kubernetes (browser/terminal)\n      Kubetail is a real-time logging dashboard for Kubernetes (browser/terminal)Demo: https://www.kubetail.com/demo\n\nKubetail is a general-purpose logging dashboard for Kubernetes, optimized for tailing logs across across multi-container workloads in real-time. With Kubetail, you can view logs from all the containers in a workload (e.g. Deployment or DaemonSet) merged into a single, chronological timeline, delivered to your browser or terminal.The primary entry point for Kubetail is the kubetail CLI tool, which can launch a local web dashboard on your desktop or stream raw logs directly to your terminal. Behind the scenes, Kubetail uses your cluster's Kubernetes API to fetch logs directly from your cluster, so it works out of the box without needing to forward your logs "
  },
  {
    "title": "A faster way to copy SQLite databases between computers (alexwlchan.net)",
    "points": 423,
    "submitter": "ingve",
    "submit_time": "2025-05-01T11:15:08 1746098108",
    "num_comments": 164,
    "comments_url": "https://news.ycombinator.com/item?id=43856186",
    "comments": [
      "SQLite has an official tool for this, fwiw: https://www.sqlite.org/rsync.htmlIt works at the page level:> The protocol is for the replica to send a cryptographic hash of each of its pages over to the origin side, then the origin sends back the complete content of any page for which the hash does not match.\n \nreply",
      "Yeah, but unfortunately the SQLite team doesn't include that tool with their \"autotools\" tarball, which is what most distros (and brew) use to package SQLite.  The only way to use the tool is to compile it yourself.\n \nreply",
      "Realistically, are you using SQLite if you can\u2019t compile and source control your rev of the codebase? Is that really a big deal?\n \nreply",
      "Yes, it's extremely common to be using it and not even be compiling anything yourself, let alone C or any support libraries.\n \nreply",
      "Saving to text file is inefficient. I save sqlite databases using VACUUM INTO, like this:  sqlite3 -readonly /path/db.sqlite \"VACUUM INTO '/path/backup.sqlite';\"\n\nFrom https://sqlite.org/lang_vacuum.html :  The VACUUM command with an INTO clause is an alternative to the backup API for generating backup copies of a live database. The advantage of using VACUUM INTO is that the resulting backup database is minimal in size and hence the amount of filesystem I/O may be reduced.\n \nreply",
      "It's cool but it does not address the issue of indexes, mentioned in the original post. Not carrying index data over the slow link was the key idea. The VACUUM INTO approach keeps indexes.A text file may be inefficient as is, but it's perfectly compressible, even with primitive tools like gzip. I'm not sure the SQLite binary format compresses equality well, though it might.\n \nreply",
      "> A text file may be inefficient as is, but it's perfectly compressible, even with primitive tools like gzip. I'm not sure the SQLite binary format compresses equality well, though it might.I hope you\u2019re saying because of indexes? I think you may want to revisit how compression works to fix your intuition. Text+compression will always be larger and slower than equivalent binary+compression assuming text and binary represent the same contents? Why? Binary is less compressible as a percentage but starts off smaller in absolute terms which will result in a smaller absolute binary. A way to think about it is information theory - binary should generally represent the data more compactly already because the structure lived in the code. Compression is about replacing common structure with noise and it works better if there\u2019s a lot of redundant structure. However while text has a lot of redundant structure, that\u2019s actually bad for the compressor because it has to find that structure and process more data to do that. Additionally, is using generic mathematical techniques to remove that structure which are genetically optimal but not as optimal as removing that structure by hand via binary is.There\u2019s some nuance here because the text represents slightly different things than the raw binary SQLite (how to restore data in the db vs the precise relationships + data structures for allowing insertion/retrieval. But still I\u2019d expect it to end up smaller compressed for non trivial databases\n \nreply",
      "Below I'm discussing compressed size here rather than how \"fast\" it is to copy databases.Yeah there are indexes. And even without indexes there is an entire b-tree sitting above the data. So we're weighing the benefits of having a domain dependent compression (binary format) vs dropping all of the derived data. I'm not sure how that will go, but lets try one.Here is sqlite file containing metadata for apple's photo's application:    767979520 May  1 07:28 Photos.sqlite\n\nDoing a VACUUM INTO:    719785984 May  1 08:56 photos.sqlite\n\ngzip -k photos.sqlite (this took 20 seconds):    303360460 May  1 08:56 photos.sqlite.gz\n\nsqlite3 -readonly photos.sqlite .dump > photos.dump (10 seconds):    1277903237 May  1 09:01 photos.dump\n\ngzip -k photos.dump (21 seconds):    285086642 May  1 09:01 photos.dump.gz\n\nAbout 6% smaller for dump vs the original binary (but there are a bunch of indexes in this one). For me, I don't think it'd be worth the small space savings to spend the extra time doing the dump.With indexes dropped and vacuumed, the compressed binary is 8% smaller than compressed text (despite btree overhead):    566177792 May  1 09:09 photos_noindex.sqlite\n    262067325 May  1 09:09 photos_noindex.sqlite.gz\n\nAbout 13.5% smaller than compressed binary with indices. And one could re-add the indices on the other side.\n \nreply",
      "Yup, these results are pretty consistent with what I'd expect (& why I noted the impact of indices) cause even string data has a lot of superfluous information when expressed in the DDL (\"INSERT INTO foo ...\") - I would expect all of that to exceed any bookkeeping within the btree. And non-string values like blobs or numbers are going to be stored more efficiently than in the dump which is a text encoding (or even hex for blobs) which is going to blow things up further.\n \nreply",
      "Brilliant. >60% savings. 700mb? wow.\n \nreply"
    ],
    "link": "https://alexwlchan.net/2025/copying-sqlite-databases/",
    "first_paragraph": "I store a lot of data in SQLite databases on remote servers, and I often want to copy them to my local machine for analysis or backup.When I\u2019m starting a new project and the database is near-empty, this is a simple rsync operation:As the project matures and the database grows, this gets slower and less reliable. Downloading a 250MB database from my web server takes about a minute over my home Internet connection, and that\u2019s pretty small \u2013 most of my databases are multiple gigabytes in size.I\u2019ve been trying to make these copies go faster, and I recently discovered a neat trick.What really slows me down is my indexes. I have a lot of indexes in my SQLite databases, which dramatically speed up my queries, but also make the database file larger and slower to copy. (In one database, there\u2019s an index which single-handedly accounts for half the size on disk!)The indexes don\u2019t store anything unique \u2013 they just duplicate data from other tables to make queries faster. Copying the indexes makes t"
  },
  {
    "title": "Llasa: Llama-Based Speech Synthesis (llasatts.github.io)",
    "points": 121,
    "submitter": "CalmStorm",
    "submit_time": "2025-05-01T16:43:37 1746117817",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43860137",
    "comments": [
      "Odd that the page doesn't seem to link to either,paper: https://arxiv.org/abs/2502.04128github: https://github.com/zhenye234/LLaSA_training\n \nreply",
      "Interesting that there isn't a mention of Orpheus as prior art either since it's the exact same thing.(https://github.com/canopyai/Orpheus-TTS)\n \nreply",
      "LLaSA is a simple framework for speech synthesis that employs a single-layer vector quantizer (VQ) codec and a single Transformer architecture to fully align with standard LLMs such as LLaMA.\n \nreply",
      "Probably the title should have the correct capitalization then. Cause I was fully expecting a speech synthesis tool that sounded like llamas talking human language and now I'm bummed out!\n \nreply",
      "the long 'uuuuhhhhhhh' from some of the lesser models is killing me.\n \nreply",
      "based on the samples, it really seams like anything smaller than 3B is pretty useless.\n \nreply",
      "If you're doing a home lab voice assistant 1B is nice, because on a 12gb gpu you can run a moderately competent 7b LLM and two 1b models; 1 for speech to text and also text to speech, plus some for the wake word monitor. Maybe in a couple of years we can combine all this into a single ~8b model that runs efficiently on 12gb gpu. Nvidia doesn't seem very incentivized right now to sell consumer GPUs that can run all this on a single consumer grade chip when they're making so much money selling commercial grade 48gb cards.\n \nreply",
      "I can't wait see this integrated into Open WebUI! These sound amazing.\n \nreply",
      "> employs a single-layer vector quantizer (VQ) codec and a single Transformer architecture to fully alignI really wish when new models were released that they would draw a diagram of all the layers and the tensor input and output sizes at each layer, with zoom in/out capabilities if needed using D3.js or whatever visualization framework if needed. Every single layer should be on there with its input and output sizes.These one-sentence descriptions, and approximate block diagrams with arrows pointing at each other are never enough to understand how something is actually implemented.\n \nreply",
      "Sounds like a solid SaaS business plan!\n \nreply"
    ],
    "link": "https://llasatts.github.io/llasatts/",
    "first_paragraph": "Abstract.Recent advances in text-based large language models (LLMs), particularly in the GPT series and the o1 model, have demonstrated the effectiveness of scaling both training-time and inference-time compute. However, current state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring separate models (e.g., diffusion models after LLM), complicating the decision of whether to scale a particular model during training or testing. This work makes the following contributions: First, \n\t\twe explore the scaling of train-time and inference-time compute for speech synthesis. \n\t\tSecond, we propose a simple framework LLaSA for speech synthesis that employs a single-layer vector quantizer (VQ) codec and a single Transformer architecture to fully align with standard LLMs such as LLaMA.\n\t\tOur experiments reveal that scaling train-time compute for LLaSA consistently improves the naturalness of synthesized speech and enables the generation of more complex and accurate prosody patte"
  },
  {
    "title": "DECtalk Archive (dectalk.nu)",
    "points": 59,
    "submitter": "classichasclass",
    "submit_time": "2025-04-29T02:09:48 1745892588",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=43828099",
    "comments": [
      "I've got a DECtalk (DTC-01) I bought years ago on eBay, intending to use it for a speech recognition(!) project. It was state of the art when it was released - Dennis Klatt's speech synthesis research from the lab turned into a product.What made DECTalk interesting is that it is a formant-based synthesizer, producing speech much like a human by taking a broad spectrum input voice source (cf. function of vocal cords) and modulating it via resonant frequencies (formants) similar to how we do it by changing the resonant frequencies of our vocal tract via articulation. When we recognize speech it's the frequency-tuned hairs in our inner ear acting as a filter bank and recognizing these resonant frequencies, which our brain has learnt to map back to the articulatory movements used to produce them.Later, cheaper, and better sounding, speech synthesizers were based on stitching together partial recorded words (phonemes), which made them sound more natural but also limited them to speech. The DECTalk's more fundamental format-based generation allowed it to sing as well as talk, and the clean computer-generated formants made it highly intelligible (albeit artificial sounding) when sped up considerably, which was popular with the intended market of blind customers using it as a reading device.Daisy, daisy, give me your answer, do ...\n \nreply",
      "For a school assignment, we had to find a dusty old computer, to run dusty old software DECtalk, to better understand speech.The assignment was to annotate lines from some famous sayings and speeches, to make the DECtalk output much better than the default.My lab partner and I might've spent an hour alone on the Gettysburg Address fragment, \"...and that government of the people, by the people, for the people, shall not perish from the earth\" be delivered like an impassioned speech.(That line was the most memorable, since there was so much to work with, and you could make it dramatic.)\n \nreply",
      "Yeah reminds me about the weird way Apple provides multi language support for iMessage announcements over AirPods. I\u2019m from Germany and my phone is set to English because of job related reasons. I message a lot of people in English and the family and friends in German. Siri used to be set to German and in the past was either not cape-able to read English messages or butchered the message. Sometimes it simply says it can\u2019t read it. For a year or so some messages will be read by a computer voice similar to DECtalk. I have no clue when the system decides to use it because it happens randomly. Now I switched Siri to English for Apple Intelligence and it got a bit better. But it\u2019s still strange though.\n \nreply",
      "Less quality but the Commodore 64 SAM [0] predates it by two years. It is available now in JavaScript [1].[0] https://en.wikipedia.org/wiki/Software_Automatic_Mouth[1] https://discordier.github.io/sam/\n \nreply",
      "Is this what Stephen Hawking used at the time?\n \nreply",
      "John Madden!\n \nreply",
      "https://news.ycombinator.com/item?id=31427032DonHopkins on May 18, 2022 | root | parent | next [\u2013]Here's a historic DECTalk Duet song from Peter Langston (which is actually quite lovely):Eedie & Eddie (And The Reggaebots) - Some Velvet Morning (Peter Langston)https://www.youtube.com/watch?v=1l0Ko1GUiSoPeter S. Langston - \"Some Velvet Morning\" (By Lee Hazelwood) - Performed By Eedie & Eddie And The Reggaebotshttp://www.wfmu.org/365/2003/169.shtmlEedie & Eddie On The Wirehttp://www.langston.com/SVM.htmlPeter Langston's Home Page:http://www.langston.com/His 1986 Usenix \"2332\" paper:http://www.langston.com/Papers/2332.pdfHow to use Eddie and Eedie to make free third party long distance phone calls (it's OK, Bellcore had as much free long distance phone service as they wanted to give away for free):https://news.ycombinator.com/item?id=22308781>My mom refused to get touch-tone service, in the hopes of preventing me from becoming a phone phreak. But I had my touch-tone-enabled friends touch-tone me MCI codes and phone numbers I wanted to call over the phone, and recorded them on a cassette tape recorder, which I could then play back, with the cassette player's mic and speaker cable wired directly into the phone speaker and mic.>Finally there was one long distance service that used speech recognition to dial numbers! It would repeat groups of 3 or 4 digits you spoke, and ask you to verify they were correct with yes or no. If you said no, it would speak each digit back and ask you to verify it: Was the first number 7? ...>The most satisfying way I ever made a free phone call was at the expense of Bell Communications Research (who were up to their ears swimming in as much free phone service as they possibly could give away, so it didn't hurt anyone -- and it was actually with their explicitly spoken consent), and was due to in-band signaling of billing authorization:When you called (201) 644-2332, it would answer, say \"Hello,\" pause long enough to let the operator ask \"Will you accept a collect call from Richard Nixon?\", then it would say \"Yes operator, I will accept the charges.\" And that worked just fine for third party calls too!>Peter Langston (working at Bellcore) created and wrote a classic 1985 Usenix paper about \"Eedie & Eddie\", whose phone number still rings a bell (in my head at least, since I called it so often): [...]>(201) 644-2332 or Eedie & Eddie on the Wire: An Experiment in Music Generation. Peter S Langston. Bell communications Research, Morristown, New Jersey.>ABSTRACT: At Bell Communications Research a set of programs running on loosely coupled Unix systems equipped with unusual peripherals forms a setting in which ideas about music may be \"aired\". This paper describes the hardware and software components of a short automated music concert that is available through the public switched telephone network. Three methods of algorithmic music generation are described.\n \nreply",
      "> The most satisfying way I ever made a free phone callI remember as a kid me and my buddies making a free call from one phone booth to another (across the road - not terribly useful) just by asking to reverse the charges. The phone company evidentially never realized that the target number was a phone booth, so it worked as normal by the recipient just agreeing to pay (without actually having to do so by putting any money in).\n \nreply",
      "If that was a customer owned coin operated telephone (COCOT), the phone company may not have known it was a pay phone, and the customer may not have known they could instruct the phone company to prevent accepting collect calls.\n \nreply",
      "It's true!\n-=P=-\n \nreply"
    ],
    "link": "https://dectalk.nu/",
    "first_paragraph": "\n\n1. What is DECtalk\n\n1.1. DECtalk's origins\n1.2. DECtalk editions\n\n1.2.1. Digital Equipment Corporation and others (1984-2000)\n1.2.2. Force Computers, Inc. (2000-2001)\n1.2.3. Fonix Corporation (December 2001-2020)\n\n1.3. DECtalk today\n\n2. About the DECtalk Archive\n\n2.1. Download as ZIP\n\n3. Browse the archive\n\n3.1. Content Warning\n\n4. Contributing to the archive\n5. Distributing the archive\n\n5.1. How to get started with Resilio Sync\n\n6. About legality and the archive\n7. List of DECtalk versions currently in the archive\n8. Other DECtalk resources\n9. Changelog\n\nDECtalk is a speech synthesizer, originally released as a hardware module in 1984 by Digital Equipment Corporation (DEC).The DECtalk technology is based on the work of Dennis Klatt, who was a pioneer in speech synthesis throughout the 1960s and 1970s. He developed the phoneme-to-speech part of a system known as MITalk, a project developed at MIT (Massachusetts Institute of Technology), using recordings of his own voice to build a fu"
  },
  {
    "title": "Ask HN: Who wants to be hired? (May 2025)",
    "points": 47,
    "submitter": "whoishiring",
    "submit_time": "2025-05-01T15:00:46 1746111646",
    "num_comments": 115,
    "comments_url": "https://news.ycombinator.com/item?id=43858552",
    "comments": [
      "Location: Greater Denver Area, ColoradoRemote: Yes (Open to Remote, Hybrid, and In Person roles)Willing to relocate: NoTechnologies: JavaScript, Python, Django, full-stack, etcR\u00e9sum\u00e9/CV: https://www.linkedin.com/in/brandonhbodine/Email: brandonhbodine@gmail.comI'm a senior engineer with a wide breadth of experience in mostly web based full-stack engineering. Most of my experience is based in e-commerce but my last role was in edTech building content translations tools powered by AI.Currently looking for a team that is dedicated to the work they do and wants to win. I'm agnostic to the tech stack and will always be up for learning what I need to.(first comment in my 11 years of having this account)\n \nreply",
      "Location: Africa or REMOTERemote: yesWilling to relocate: yes, to any location in Africa, where I can get the necessary permission to live and work. Occasional travel is possible.Technologies: Linux, Front or Backend Web Development, General Software Development, System Administration.R\u00e9sum\u00e9/CV: on request (software development, CTO, mentoring, training, fluent in English and German, german citizenship)Contact: Email: see profile or http://codingforafrica.at/Like this Ask HN: Recommend employers with positive social impact [https://news.ycombinator.com/item?id=31518945], I am looking for similar work, but I am open to work on any interesting project. I am a European software developer who has lived and worked on four continents. Now it's time to move on and so I am in the process to relocate to Africa.I have more than a decade of experience running a company, doing software development, support and training and mentoring adults and students, as well as working on educational projects, and I am willing to take on a mixture of roles as needed to support a project.I value good teamwork over fancy tech, and I don't shy away from working on legacy code. I am primarily motivated by solving problems, so let me help you solve your problems.I am open to work for a company anywhere as long as the work can be done fully remote from Africa.While I could find a job elsewhere I believe that the experience living in an area where my work is going to have an impact gives me a better understanding of the needs of the location I am serving. Whether it is through direct contact with clients and users or just by being part of a local community and learning about the reality of living there.In addition, I want to use some of my income to hire local interns and junior developers and train them in order to pass on my experience. I also sponsor children that otherwise can't afford to go to school (see my website). If you want to support this, I would love to work with you. Also if you are interested in hiring African developers yourself. I can help you build up a team for you.\n \nreply",
      "Location: Pasadena, CA\n  Remote: No/Yes\n  Willing to relocate: Yes\n  Technologies: Computer Vision, Code generation, Program Synthesis, Coq, Lean, PyTorch, Julia\n  R\u00e9sum\u00e9/CV: https://atharvas.net/cv/\n  Email: atharvas@utexas.edu\n\nI'm a PhD student at UT Austin. Mainly looking for internships in companies that are working on code generation, mathematical reasoning (theorem provers), or interested in interpretable (yet performant) computer vision models. I'm pretty familiar with the state of the art in code generation and interpretable computer vision algorithms. Open-ended projects (research based) would be great but I'm happy to work on anything codegen/perception based really.Some of my recent work:- Symbolic Regression @ NeurIPS24 (https://trishullab.github.io/lasr-web/)- Visual Programming @ CVPR25 (https://trishullab.github.io/escher-web/)\n \nreply",
      "Vincent SgherziLocation: San DiegoRemote: Any, Willing to relocate: Yes (anything in California)Technologies: Rust, JavaScript, C, HTML, CSSResume: https://vincents.dev/resumeEmail: sgherzivincent@gmail.comI am an engineer versed in building high throughput full stack and systems software. In my current position I am head of multiple projects related to real time fraud analysis.  I am looking for roles mainly in Rust.\n \nreply",
      "Clojure/Script and JavaScript/TypeScript dev with 25 years of experience.I've built high performance 2d game engines, 2 poker clients and quite a few MVC frameworks. I like functional techniques, react/redux, react hooks, clojurescript. Somewhat unusual is that I tend to enjoy and be good at the last slog of a development project, to get the application in front of users.Location: SwedenRemote: PreferredRelocate: No, but prepared to commute to StockholmTechnologies: JavaScript/ClojureScript, React/redux or hooks. Comfortable with all web tech.CV: https://www.linkedin.com/in/jonatanwallgren/Email: jonatan dot wallgren at gmail\n \nreply",
      "Location: GermanyRemote: yes, onlyWilling to relocate: noTechnologies: C++, C, Rust, Assembly, Python, JSR\u00e9sum\u00e9/CV: https://shkur.ski/cv.pdfEmail: dima [:at:] shkur.skiOffer: my expertise in building desktop applications, device management, high-performance systems and more. I worked on products deployed on 10sM machines, both implementation and architecture level. In different environments: from large companies to seed stage startups (incl. YC-backed and own products).For the past few years: LLM/semantic search applied in the productivity space. Built from scratch and tested with users a bunch of MVPs around the idea of proactive user interfaces: https://shkur.ski/notaiOpen work permit: Germany, Canada. Worldwide as a B2B contractor and/or part-time involvement possible.\n \nreply",
      "Location: Germany (starting September)Remote: YesWilling to relocate: within central EuropeR\u00e9sum\u00e9/CV: https://lettucefield.org/resume.pdfEmail: jobsforjulian@proton.meHomepage: https://lettucefield.org/GitHub: https://github.com/julian-urbanI'm currently a physics postdoc at MIT doing research into applications of machine learning to problems in computational quantum field theory. My position ends in August/September and I'm looking for an industry job in Europe (I'm a German citizen). Ideally I'd like to keep applying my expertise in probabilistic modeling, Monte Carlo simulation, and numerical optimization to interesting engineering or data science problems. Experience includes distributed training and inference of generative ML models on large HPC clusters with ~20k GPUs, as well as developing scientific software for statistical inference. Proficiency in python programming (primarily with packages such as pytorch, scipy, scikit-learn) and some basic knowledge of other languages.\n \nreply",
      "Location: Los AngelesRemote: YesRelocation: Case-by-caseI'm a CTO, expert engineer, and data professional interested in team-building, consulting and architecting data pipelines. At Edmunds.com, I worked on a fairly successful ad-tech product and my team bootstrapped a data pipeline using Spark, Databricks, and microservices built with Java, Python, and Scala.At ATTN:, I re-built an ETL Kubernetes stack, including data loaders and extractors that handle >10,000 API payload extractions daily. I created SOPs for managing data interoperability with Facebook Marketing, Facebook Graph, Instagram Graph, Google DFP, Salesforce, etc.More recently, I was the CTO and co-founder of a gaming startup. We raised over $6M and I was in charge of building out a team of over a dozen remote engineers and designers, with a breadth of experience ranging from Citibank, to Goldman Sachs, to Microsoft. I moved on, but retain significant equity and a board seat.I am also a minority owner of a coffee shop in northern Spain. That I'm a top-tier developer goes without saying. I'm interested in flexing my consulting muscle and can help with best practices, architecture, and hiring.Would love to connect even if it's just for networking!Blog: https://dvt.name/GitHub: https://github.com/dvx\n \nreply",
      "# Location: Atlanta, GA# Remote: Yes# Willing to relocate: Yes# Technologies: Python, embedded, PCBs, Linux, Torch, Postgres, TypeScript, React, CAD, 3D printing# R\u00e9sum\u00e9/CV: https://synapsomorphy.com/resume.pdf (website: https://synapsomorphy.com/)# Email: patrickwspencer at gmail dot comI spent the last year building the entire stack for a hardware deeptech recent YC grad - backend, frontend, PCBs, firmware, infra, etc, as a one man dev team. I'm looking for somewhere with experienced hackers to learn from and somewhere I can wear a lot of hats. Prefer hardware (especially robotics - just built myself a robot arm to dive into it) but open to any hard + fun problems!\n \nreply",
      "Location: Seattle, WA\n    Remote: Yes, hybrid in Seattle works as well\n    Willing to relocate: No\n    Technologies: I've been all over the place. Go, JS (and TS) and Python are probably my strongest languages, and I have recently been having a lot of fun with Elixir and Rust. \n    I have also done smaller amounts of work in Java, Kotlin, Ruby + Rails and Clojure.\n    Resume: https://resume.giodamelio.com/\n    Email: gio@damelio.net\n\nI am a software engineer with 6 years of professional experience, though I have been programming since I was a kid. I am a huge proponent of Open Source (see my Github[1]). I am looking to join a smaller company, either as a FTE or on a contracting basis.[1]: https://github.com/giodamelio\n \nreply"
    ],
    "link": "item?id=43858552",
    "first_paragraph": ""
  },
  {
    "title": "Building Private Processing for AI Tools on WhatsApp (fb.com)",
    "points": 8,
    "submitter": "3s",
    "submit_time": "2025-04-30T23:17:00 1746055020",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43851787",
    "comments": [
      "Broadly similar to what Apple is trying with their private compute work.It's a great idea but the trust chains are so complex they are hard to reason about.In \"simple\" public key encryption reasonably technically literate people can reason about it (\"not your key, not your X\") but with private compute there are many layers, each of which works in a fairly complex way and AFAIK you always end up having to trust a root source of trust that certifies the trusted device.It's good in the sense it is trust minimization, but it's hard to explain and the cynicism (see HN comments similar to \"you can't trust it because big tech/gov interference etc) means I am sadly pessimistic about the uptake.I wish it wasn't so though. The cynicism in particular I find disappointing.\n \nreply",
      "> We\u2019re sharing an early look into Private Processing, an optional capability that enables users to initiate a request to a confidential and secure environment and use AI for processing messages where no one \u2014 including Meta and WhatsApp \u2014 can access them.What is this and what is this supposed to mean? I have a hard time trusting these companies with any privacy and while this wording may be technically correct they\u2019ll likely extract all meaning from your communication, probably would even have some AI enabled surveillance service.\n \nreply",
      "I don't understand the knee-jerk skepticism. This is something they are doing to gain trust and encourage users to use AI on WhatsApp.WhatsApp did not used to be end-to-end encypted, then in 2021 it was - a step in the right direction. Similary, AI interaction in WhatsApp today is not private, which is something they are trying to improve with this effort - another step in the right direction.\n \nreply",
      "Did you read the next paragraphs? It literally describes the details. I would quote the parts that respond to your question, but I would be quoting the entire post.> This confidential computing infrastructure, built on top of a Trusted Execution Environment (TEE), will make it possible for people to direct AI to process their requests \u2014 like summarizing unread WhatsApp threads or getting writing suggestions \u2014 in our secure and private cloud environment.\n \nreply",
      "I mean you are not forced to?If a company is trying to move their business to be more privacy focused, at least we can be non-dismissive.\n \nreply"
    ],
    "link": "https://engineering.fb.com/2025/04/29/security/whatsapp-private-processing-ai-tools/",
    "first_paragraph": "AI has revolutionized the way people interact with technology and information, making it possible for people to automate complex tasks and gain valuable insights from vast amounts of data. However, the current state of AI processing \u2014 which relies on large language models often running on servers, rather than mobile hardware \u2014 requires that users\u2019 requests are visible to the provider. Although that works for many use cases, it presents challenges in enabling people to use AI to process private messages while preserving the level of privacy afforded by end-to-end encryption.We set out to enable AI capabilities with the privacy that people have come to expect from WhatsApp, so that AI can deliver helpful capabilities, such as summarizing messages, without Meta or WhatsApp having access to them, and in the way that meets the following principles:We\u2019re excited to share an initial overview of Private Processing, a new technology we\u2019ve built to support people\u2019s needs and aspirations to lever"
  },
  {
    "title": "Linkwarden: FOSS self-hostable bookmarking with AI-tagging and page archival (linkwarden.app)",
    "points": 220,
    "submitter": "FireInsight",
    "submit_time": "2025-05-01T12:28:21 1746102501",
    "num_comments": 77,
    "comments_url": "https://news.ycombinator.com/item?id=43856801",
    "comments": [
      "Hello everyone, I\u2019m the main developer behind Linkwarden. Glad to see it getting some attention here!Some key features of the app (at the moment):- Text highlighting- Full page archival- Full content search- Optional local AI tagging- Sync with browser (using Floccus)- CollaborativeAlso, for anyone wondering, all features from the cloud plan are available to self-hosted users :)\n \nreply",
      "Great product! Does it handle special metadata like https://mymind.com/ does, eg. showing prices directly in the UI if the saved link is a product in a shop? If not, things like that would be a great addition!\n \nreply",
      "(The historical price on the day the link was published, or the current price, or over a date range, or configurable? I see different use-cases)\n \nreply",
      "Interesting project! A couple of questions:- Does the web front end support themes? It\u2019s a trivial thing but based on the screenshots, various things about the default theme bug me and it would be nice to be able to change those without a user style extension.- Does it have an API that would allow development of a native desktop front end?\n \nreply",
      "Cool, looks like text highlighting is a new addition in 2.10. There aren't any examples in the demo site of this, but can it capture the highlighted text snippets and show them in the link details page? That would help me recall quickly why I saved the link, without opening the original link and re-reading the page. I haven't really seen this in other tools (or maybe I just haven't looked hard enough), except Memex.\n \nreply",
      "> There aren't any examples in the demo site of thisThis is because we haven't updated the demo to the latest version.> but can it capture the highlighted text snippets and show them in the link details page?That's a good idea that we might implement later, but at the moment you can only highlight the links[1].[1]: https://blog.linkwarden.app/releases/2.10#%EF%B8%8F-text-hig...\n \nreply",
      "How difficult would it be to import an existing list of links/tags? Also, if I were using a hosted version, would I be able to eg insert/retrieve files via an API call?I ask because currently I use Readwise but have a local script that syncs the reader files to a local DB, which then feeds into some custom agent flows I have going on on the side.\n \nreply",
      "> How difficult would it be to import an existing list of links/tags?Pretty easy if you have it in a bookmark html file format.> Also, if I were using a hosted version, would I be able to eg insert/retrieve files via an API call?Yup, check out the api documentation:https://docs.linkwarden.app/api/api-introduction\n \nreply",
      "I have about ~30k .webarchive files \u2014 is there a chance to import them?\n \nreply",
      "I'd be interested to hear your thoughts on having a PWA vs regular mobile apps since it looks like you started with a PWA, but are moving to regular apps.  Is that just a demand / eyeballs thing or were there technical reasons?\n \nreply"
    ],
    "link": "https://linkwarden.app/",
    "first_paragraph": ""
  },
  {
    "title": "Blood droplets on inclined surfaces reveal new cracking patterns (phys.org)",
    "points": 27,
    "submitter": "bookofjoe",
    "submit_time": "2025-05-01T00:48:11 1746060491",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://phys.org/news/2025-04-blood-droplets-inclined-surfaces-reveal.html",
    "first_paragraph": ""
  },
  {
    "title": "Millihertz 5 Mechanical Computer (2022) (srimech.com)",
    "points": 69,
    "submitter": "gene-h",
    "submit_time": "2025-05-01T17:04:47 1746119087",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=43860428",
    "comments": [
      "About 8 years ago I visited TU Chemnitz and they had a lab making similar things to this. It wasn't clear to me what the goal was, but it was very cool nonetheless.\n \nreply",
      "I've always wanted to build (distinct) mechanical computers out of the following kinds of elements:1. Spur-gear differential; and,2. Shishi-odoshi.Both of these are saturating mechanical devices that can be used to build NAND gates; the latter, I think, would be very pleasing, if exceedingly slow.For the spur-gear differential, you'd need to up-scale the output by a factor of 2 (since the output is half-speed), and use a locking wedge to build a one-way gear out of one of the spur-gear differentials. However, it has the nice property that the logic is made entirely out of a single element: the spur-gear differential.Similarly, for the shishi-odoshi: you're going to have to do a bit of analysis (drilling a hole in the bottom part of the bamboo ladle), to figure out the in-flow and out-flow to build the basic AND gate, and then balancing out the NOT gate, to build your basic NAND. This is, obviously, very finicky; but, I supposed, that'd be quite a bit of the charm of a Zen computer garden?\n \nreply",
      "I built some logic gates using water and a 3D printed \"seesaw\" that tilts to the left or right: https://byronknoll.blogspot.com/2022/06/water-computer.html\n \nreply",
      "the shishi-odoshu seems like the more promising avenue. The key question in mechanical computing is never designing gates, its designing power amplifiers.\n \nreply",
      "A shishi-odoshi ALU would be amazing to see\u2026and hear too.I love that idea.\n \nreply",
      "Has any computer been built out of spur-gear differentials? Like maybe some sort of adder circuit, not necessarily a full instruction executing computer. The only uses I could find was what seems to me like the differentials being part of some sort of analogue computer.\n \nreply",
      "Spur gear differentials are naturally adders (with carry!); so, traditionally they've only ever been used for analogue logic. They're overly complicated for digital logic: you need two spur gears to build a single gate (NAND) to perform a single binary operation. If you want any sort of reasonable lash characteristics you're going to need ~60 teeth. At that point, two 60 teeth spur gears give you a 3600-valued adder. That'd take something like 300+ spur gears in binary: it just doesn't make any damn sense.I think the last time I looked at this, if I used the cast spur gears available I needed a staged approach to \"start\" the computer and a 1100 hp motor to run it.\n \nreply",
      "I just smile hearing the term \"Millihertz Computer\". I'd love it if building and designing mechanical and analog computers grew as a hobby/educational activity as I find them both fascinating and somehow satisfying.Also, this 1950s Naval Training film explaining the fundamentals of how mechanical fire control computers work to solve complex problems is excellent.  https://www.youtube.com/watch?v=s1i-dnAH9Y4\n \nreply",
      "I was incredibly surprised to find that this actually is a computer. Normally when you hear about a \"computer\" constructed in an unusual medium, it turns out to just be a binary adder or an analogue computer. I've learned to expect disappointment.\n \nreply",
      "What a gem of a site\nThank you for sharing\n \nreply"
    ],
    "link": "https://www.srimech.com/MHZ5.html",
    "first_paragraph": "Picture of Millihertz 5 / Offspring in Februrary 2022Millihertz 5 or 'Offspring' is a mechanical computer modelled on the Manchester small-scale experimental machine ('Baby'). It uses ball bearings as data elements. It has an 8x8 bit RAM and 8-bit datapath with subtractor and accumulator. It is currently under construction. There are some design documents available: a PDF: Offspring PDF or Pandoc-rendered HTML: Offspring HTML.Return to index"
  },
  {
    "title": "When ChatGPT broke the field of NLP: An oral history (quantamagazine.org)",
    "points": 150,
    "submitter": "mathgenius",
    "submit_time": "2025-05-01T07:51:39 1746085899",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=43854776",
    "comments": [
      "I am in academia and worked in NLP although I would describe myself as NLP adjacent.I can confirm LLMs have essentially confined a good chunk of historical research into the bin. I suspect there are probably still a few PhD students working on traditional methods knowing full well a layman can do better using the mobile ChatGPT app.That said traditional NLP has its uses.Using the VADER model for sentiment analysis while flawed is vastly cheaper than LLMs to get a general idea. Traditional NLP is suitable for many tasks people are now spending a lot of money asking GPT to do just because they know GPT.I recently did an analysis on a large corpus and VADER was essentially free while the cloud costs to run a Llama based sentiment model was about $1000. I ran both because VADER costs nothing but minimal CPU time.NLP can be wrong but it can\u2019t be jailbroken and it won\u2019t make stuff up.\n \nreply",
      "That's because VADER is just a dictionary mapping each word to a single sentiment weight and adding it up with some basic logic for negations and such. There's an ocean of smaller NLP ML between that naive approach and LLMs. LLMs are trained to do everything. If all you need is a model trained to do sentiment analysis, using VADER over something like DistilBERT is NLP malpractice in 2025.\n \nreply",
      "> using VADER over something like DistilBERT is NLP malpractice in 2025.Ouch. Was that necessary?I used $1000 worth of GPU credits and threw in VADER because it\u2019s basically free both in time and credits.I usually do this on large dataset out of pure interest in how it correlates with expensive methods on English language text.I am well aware of how VADER works and its limitations, I am also aware of the limitations of all sentiment analysis.\n \nreply",
      "Sorry, I side with GP. Just because you don't want to use Llama/GPT because of cost, the middle-ground of DistilBERT etc (which can run on a single CPU) is a much more sensible cost/benefit tradeoff than VADER's decade old lexicon-based approach.I can't really think of many NLP things that are one-decade old and don't have a better / faster / cheaper alternative.\n \nreply",
      "Curious how big your dataset was if you used $1000 of GPU credits on DistilBERT. I've run BERT on CPU on moderate cloud instances no problem for datasets I've worked with, but which admittedly are not huge.\n \nreply",
      "Price isn't a real issue in almost every imaginable use case either. Even a small open source model would outperform and you're going to get a lot of tokens per dollar with that.\n \nreply",
      "*consigned a good chunk of historical research into the bin\n \nreply",
      "Has there been an LLM that reliably does not ignore the word \"not\"?Because I'm pretty sure that's a regression compared to most prior NLP.\n \nreply",
      "Great seeing Ray Mooney (who I took a graduate class with) and Emily Bender (a colleague of many at the UT Linguistics Dept., and a regular visitor) sharing their honest reservations with AI and LLMs.I try to stay as far away from this stuff as possible because when the bottom falls out, it's going to have devastating effects for everyone involved. As a former computational linguist and someone who built similar tools at reasonable scale for largeish social media organizations in the teens, I learned the hard way not to trust the efficacy of these models or their ability to get the sort of reliability that a naive user would expect from them in practical application.\n \nreply",
      "Don't try and say anything pro-linguistics here, people are weirdly hostile if you think it's anything but probabilities.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/when-chatgpt-broke-an-entire-field-an-oral-history-20250430/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesApril 30, 2025James O\u2019Brien for\u00a0Quanta MagazineSomething very significant has happened to the field. And also to people.\n\u2014Christopher PottsContributing WriterApril 30, 2025Asking scientists to identify a paradigm shift, especially in real time, can be tricky. After all, truly ground-shifting updates in knowledge may take decades to unfold. But you don\u2019t necessarily have to invoke the P-word to acknowledge that one field in particular \u2014 natural language processing, or NLP \u2014 has changed. A lot.The goal of natural language processing is right there on the tin: making the unruliness of human language (the \u201cnatural\u201d part) tractable by computers (the \u201cprocessing\u201d part). A blend of engineering and"
  },
  {
    "title": "Oxide\u2019s compensation model: how is it going? (oxide.computer)",
    "points": 151,
    "submitter": "steveklabnik",
    "submit_time": "2025-05-01T19:46:10 1746128770",
    "num_comments": 145,
    "comments_url": "https://news.ycombinator.com/item?id=43862487",
    "comments": [
      "I like it a lot and their thoughtfulness about it but it's a little hollow when they're spending investor money. I'd like to see how this model evolves once they're off the vc teat: when there's a bottom line to answer to, does the dynamic shift? Everyone has an on-site chef when the money vc hose is on. Valve's flat structure was exciting because it wasn't 3 vc's in a coat larping as a business, it was an actual profitable business.Support is typically low paid because it's a lot of effort for little reward, no matter how much you pay someone in support, there's only so much impact they can have on the bottom line. The organization as an organism where every organ is as equally important as the other is a beautiful sentiment but the appendix is getting jettisoned at the first sign of trouble. Support, no matter how valued and important to the organisation it is, is never worth $200k/year on the output of 1 person.The exception to the rule for sales is the canary in the coal mine: sales measures itself, but every role can (and will) be measured when the pressure is on, there will be competition for budget, and the support team will get squeezed until they're empty while the engineers coast. I would be more convinced that this model could survive outside of the vc bubble if sales had bought in to too. Sales as a competitive sport is cultural, not fundamental.Anyway, not criticism, just musing, love that they're trying it, even if this doesn't work out, everyone had a few good years, it's worth a shot.\n \nreply",
      "> Support, no matter how valued and important to the organisation it is, is never worth $200k/year on the output of 1 person.I... think you are thinking more \"Customer Support Representative\" (how to reset a password) and not Support Engineering.An engineer that can talk to customers, find bugs, and fix them, is not worth $200k?One of the Oxide Support engineers was (still is) an INSANELY strong performance engineer who helped solved performance bugs when he was on my team. We were actively using strace weekly to troubleshoot deep process internals to optimize perf.(Hi Will, I miss you, and you are definitely worth $200k don't listen to this guy. <3)\n \nreply",
      "To add: I saw job listings recently posted on bsky and was enjoying how well written they were. The support engineer role description asked that they be able to fly to a customers site at short notice. That\u2019s a whole other level of on-call right there.\n \nreply",
      "> The support engineer role description asked that they be able to fly to a customers site at short notice.Kinda makes sense if you sell physical hardware?\n \nreply",
      "Also some of their customers are airgapped so if they\u2019ll let you touch the machine that\u2019ll make debugging a lot easier.\n \nreply",
      "So this surprised me. If their customers are the kind that have airgapped servers, I\u2019m surprised to see roles that all accept worldwide applicants.",
      "I work at Oxide, and support engineering is worth far more than that. It literally means the rest of us don't have to be on customer oncall all the time \u2014 I've spent long stretches of my career doing that and it's extraordinarily stressful. Do you know how valuable that can be?\n \nreply",
      "Sure, but at some size, the support engineers are at max workload and you hire somebody to triage calls for them.\n \nreply",
      "We're building our product in a way that we stave that off as long as possible! In many ways the whole theory of our product is to avoid that kind of issue.\n \nreply",
      "I imagine they had to introduce variable comp for sales because they weren\u2019t able to hire even a single good enterprise sales rep for a flat $200k. It\u2019s not a culture thing, it\u2019s just the market rate for the role. If they paid a flat $500k they\u2019d stand a better chance of avoiding variable comp.\n \nreply"
    ],
    "link": "https://oxide.computer/blog/oxides-compensation-model-how-is-it-going",
    "first_paragraph": "Four years ago, we were struggling to hire. Our team was small (~23\nemployees), and we knew that we needed many more people to execute on our\naudacious vision.  While we had\nhad success hiring in our personal networks, those networks now felt tapped;\nwe needed to get further afield.  As is our wont, we got together as a team\nand brainstormed: how could we get a bigger and broader applicant pool?  One\nof our engineers, Sean, shared some personal experience: that\nOxide\u2019s principles and values were very\npersonally important to him\u2009\u2014\u2009but that when he explained them to people\nunfamiliar with the company, they were (understandably?) dismissed as\ncorporate claptrap.  Sean had found, however, that there was one surefire way\nto cut through the skepticism:  to explain our approach to compensation.\nMaybe, Sean wondered, we should talk about it publicly?\"I could certainly write a blog entry explaining it,\" I offered.  At this\nsuggestion, the team practically lunged with enthusiasm: the reaction wa"
  },
  {
    "title": "Creating beautiful charts with JRuby and JFreeChart (headius.com)",
    "points": 38,
    "submitter": "headius",
    "submit_time": "2025-04-30T20:30:01 1746045001",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=43850309",
    "comments": [
      "tbh those old 3d charts just crack me up  - i remember seeing stuff like that in early office programs. you ever  feel like some trends just  stick around for way too long even when better stuff exists?\n \nreply",
      "Being able to add an interpreted script engine to a Java application is a super-power for some uses.  I embedded a Jython (Python in the JVM) command line into a Java Swing app to provide a level of flexibility that I never could with a GUI.  Every time I look at JRuby I wonder if Jython was the right choice.  It is too late now but JRuby looks awfully nice.\n \nreply",
      "Wow, the first chart on that web page is really, really ugly. It has these weird 3-d effects that look like from 2001. All it's missing are reflections...\n \nreply",
      "A real throwback, I remember using JFreeChart back in 2006 or so. Looks like the design hasn't changed a bit since then. That's thanks to Java's backwards compatibility ethos I suppose ...\n \nreply",
      "I read your comment first and was like it can\u2019t be that bad. I then opened the page, scrolled frantically down and boy oh boy were you right.\n \nreply",
      "Title needs a correction: Hideous charts with JRuby and JFreeChart.\n \nreply",
      "> Everyone loves pie!Oh gosh, no! Count me among those who greatly dislike pie charts in almost every context.\"Almost never use a pie chart for data\"https://theconversation.com/heres-why-you-should-almost-neve...https://news.ycombinator.com/item?id=38912534\n \nreply",
      "In early 1990s I worked at a mid-sized software company making software to help big businesses do big-business stuff. One day, another programmer pops into my cube and says:\"Hey, how do you draw a 3d pie chart?\"\"What?\" I asked. \"Why?\"\"Well, Excel can do them. And somebody saw one. Now they want our software to draw them.\"\"Are you serious?\"\"Yes, I need it like now. I'm supposed to demo it later today.\"So I get out a sheet of paper, draw some triangles, and work out that projection math. He walks away with the paper. Half an hour later, he calls me over.\"Hey, it's a 3d pie chart!\"And there it was: On a screen I was all too familiar with, where the 2d pie chart used to be, was a squat 3d pie chart, looking like it was a fat inch thick. Of course, there was too much margin above and below, because of the flatter aspect ratio, but hey, it was 3d and it was good enough for a demo.I think that was the first day I realized that programming can be used for evil.\n \nreply",
      "One word, Tufte; read them all, then read them again.\n \nreply",
      "That\u2019s really impressive! Not the chart itself, but seeing how easy it is to use any existing Java library from within a Ruby codebase is super cool.Ruby already has a pretty incredible gem ecosystem but having all things Java available too really adds tremendous utility.Love JRuby. Thanks for all of the hard work headius!\n \nreply"
    ],
    "link": "https://blog.headius.com/2025/04/beautiful-charts-with-jruby-and-jfreechart.html",
    "first_paragraph": "Java, Ruby, and JVM guy trying to make sense of it allI recently returned from RubyKaigi where I had the opportunity to sit down with members of the Japanese Ruby community and show them a little bit of JRuby. One of the items that came up a few times was the difficulty of utilizing external libraries from Ruby: if it\u2019s a C library, typically you have to either write a C extension or do the extra work of writing up an FFI binding.If the library is not implemented in C or Ruby, things get even weirder.One example is the Charty library, one of the more popular options for generating beautiful chart graphics on Ruby. But Charty actually wraps a Python library called matplotlib, and the bindings for CRuby literally load Python into the current process and call it via Ruby C API calls which then make Python C API calls. The horror!Also recently, a Reddit Ruby post demonstrated the use of the QuickChart library, which is implemented in JavaScript\u2026 yuck! In this case, the call-out is via proc"
  },
  {
    "title": "Deno's Decline (dbushell.com)",
    "points": 119,
    "submitter": "enz",
    "submit_time": "2025-05-01T22:08:55 1746137335",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=43863937",
    "comments": [
      "I use Deno all the time... but it might not be exactly how it's marketed...Anytime I need to etl some data or transform a bunch of JSON or things of this nature - I use Deno.It's like a glue language for me at this point. I don't need to focus on configuration or any setup like this - I just create a new dir and I'm off.This article seems very hyperbolic to me - I still find a bunch of features within deno really helpful and there is still a ton of activity on Deno itself (Had a release yesterday) and many of the internal and community libraries in it's ecosystem like Postgres and Redis (which both had a release within the last week).\n \nreply",
      "I read this same thing 25+ years ago.  But we said Perl not Demo.Use the right tool. Right means reasonable and productive.  Let folk who don't ship argue stack. While they're flapping, you are sailing.\n \nreply",
      "I really want to like Deno. I started to watch \"just a few minutes\" of their keynote (I assume it was the most recent one, this was a month or so ago) and was intrigued by it and ended up watching the whole thing.Then I went to go play with it add... I ran into odd compatibility issues (no, I don't remember them, I'm sorry) and tried Bun and everything \"just worked\". I'm sure Bun is not perfect but so far, every one-off script I've thrown at it has \"just worked\" which is amazing for me since I greatly prefer to work in TypeScript and (until recently with the type-stripping stuff in node) that was way harder than it needed to be.If I never see an error about how I should change my \"type\" to \"module\" only to do it have it complain about 10 other things I will die happy.I love Javascript, I love TypeScript, I feel like I'm primed to love Deno but all the parts of it felt half-baked. The comments in this article about things like Fresh and K/V store ring very true. I kept looking for things like \"What backend framework should I use?\" and the answers were all over the place and not very mature options. It felt like I was building on sand.I hope I'm 100% wrong, I hope deno turns it around, I want more things like deno to exist, but the closing of data centers is not encouraging.\n \nreply",
      "I feel like they bit off more than they can chew. I want to like it, too. But they\u2019re trying to create a whole new JavaScript ecosystem from the ground up, and a lot of it depends on maintaining a seamless compatibility layer that\u2019s always a moving target.It\u2019s not just node. They have Fresh, which depends on Preact, which is a compatibility layer over the React API. Why? To save a few K on bundle size? They have JSR. Why?The sales pitch is great: Typescript that just works. But in my experience, it didn\u2019t \u201cjust work\u201d. I tried building something with Fresh and ran into issues immediately. I bailed out.\n \nreply",
      "> I love Javascript, I love TypeScript\u2026Respect. Everyone gets to love something. I\u2019ve been through enough iterations of technology that I don\u2019t attach like that anymore. But I find it interesting when people express these opinions. Can you share a little context? What background you\u2019re from, industry your working in, what motivates your love?\n \nreply",
      "Maybe Deno is the PyPy (from Python) to the JavaScript\n \nreply",
      "That's sad to see.> If you sense some ire here it\u2019s because I went all-in on Deno. I was fooled. I was rugged pulled.I don't agree with the author's use of \"rug pulled\" here. Deno took a shot and not all businesses succeed \u2014 they did have unusually strong competition in Bun.Them scaling down the number of regions might make them sustainable longer with their current customers who have deployments. That seems nicer than a hard shutdown.\n \nreply",
      "The rust reimplementation of the node modules is interesting to read. I took some ideas for the llrt runtime modules. As a comparison Bun Zig implementation is scarily ignoring a lot of edge cases.\n \nreply",
      "Everyone complains about Rust until they need high quality software that doesn't cut corners or isn\u2019t impossible to write correctly.I\u2019m biased but learning difficulty aside, Rust is very optimal as a language.\n \nreply",
      "So, basically, people don't seem to value security (Deno) very much but value speed (Bun) quite a lot.That is pretty much the standard problem across programming.\n \nreply"
    ],
    "link": "https://dbushell.com/2025/04/28/denos-decline/",
    "first_paragraph": "\nSubscribe\n\n\n Blog RSS feed\n\n\n Notes RSS feed\nor\n\n\n Combined\nand follow\n\n\n Mastodon\n\n\n Bluesky\n\n\n\nMonday\n\n28 Apr\n2025\n\nThe future of Deno Land Inc. is not looking bright. Their commercial product Deno Deploy claims to be \u201cedge\u201d hosting with \u201cmassive global scale\u201d.JavaScript applications on Deno Deploy run server-side logic geographically close to users, offering low latency and great performance.Except that\u2019s a bit of a stretch if we\u2019re being honest.Deno provide a list of regions in their documentation (take a peek if you want spoilers). Between \u201923\u20132024 I gave Deno Deploy a fair shot but my personal experience was negative. I left feedback amongst others\u2019 and moved on.Well, I did keep an eye on one thing\u2026Back in January 2024 a few people noted that Deno Deploy had dropped from 35 regions to just twelve (12) worldwide.For example, Seoul moved to Tokyo, response times went from 8ms to 42ms!@Elefunc on TwitterI would have been happy seeing 42ms to begin with. Anyway, the original 35 wasn"
  }
]