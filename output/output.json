[
  {
    "title": "I\u2019m joining OpenAI (steipete.me)",
    "points": 535,
    "submitter": "mfiguiere",
    "submit_time": "2026-02-15T21:54:15 1771192455",
    "num_comments": 403,
    "comments_url": "https://news.ycombinator.com/item?id=47028013",
    "comments": [
      "There are a few take aways I think the detractors and celebrators here are missing.1. OpenAI is saying with this statement \"You could be multimillion while having AI do all the work for you.\" This buy out for something vibe coded and built around another open source project is meant to keep the hype going. The project is entirely open source and OpenAI could have easily done this themselves if they weren't so worried about being directly liable for all the harms OpenClaw can do.2. Any pretense for AI Safety concerns that had been coming from OpenAI really fall flat with this move. We've seen multiple hacks, scams, and misaligned AI action from this project that has only been used in the wild for a few months.3. We've yet to see any moats in the AI space and this scares the big players. Models are neck and neck with one another and open source models are not too far behind. Claude Code is great, but so is OpenCode. Now Peter used AI to program an free app for AI agents.LLMs and AI are going to be as disruptive as Web 1 and this is OpenAI's attempt to take more control. They're as excited as they are scared, seeing a one man team build a hugely popular tool that in some ways is more capable than what they've released. If he can build things like this what's stopping everyone else? Better to control the most popular one than try to squash it. This is a powerful new technology and immense amounts of wealth are trying to control it, but it is so disruptive they might not be able to. It's so important to have good open source options so we can create a new Web 1.0 and not let it be made into Web 2.0reply",
      "> This buy out for something vibe codedI think all of these comments about acquisitions or buy outs aren\u2019t reading the blog post carefully: The post isn\u2019t saying OpenClaw was acquired. It\u2019s saying that Pete is joining OpenAI.There are two sentences at the top that sum it up:> I\u2019m joining OpenAI to work on bringing agents to everyone. OpenClaw will move to a foundation and stay open and independent.OpenClaw was not a good candidate to become a business because its fan base was interested in running their own thing. It\u2019s a niche product.reply",
      "I don't mean to be cynical, but I read this move as: OpenAI scared, no way to make money with similar product, so acqui-hire the creator to keep him busy.I'd love to be wrong, but the blog post sounds like all the standard promises were made, and that's usually how these things go.reply",
      "It isn't an acqui-hire just a simple hiring. Also unless creator is some mythical 100x developer, there will be enough developers",
      "Fair enough. Call it a high profile acquihire thenreply",
      "I think both this comment and OP's confuse this.It appears more of a typical large company (BIG) market share protection purchase at minimal cost, using information asymmetry and timing.BIG hires small team (SMOL) of popular source-available/OSS product P before SMOL realizes they can compete with BIG and before SMOL organizes effort toward such  along with apt corporate, legal, etc protection.At the time of purchase, neither SMOL nor BIG know yet what is possible for P, but SMOL is best positioned to realize it. BIG is concerned SMOL could develop competing offerings (in this case maybe P's momentum would attract investment, hiring to build new world-model-first AIs, etc) and once it accepts that possibility, BIG knows to act later is more expensive than to act sooner.The longer BIG waits, the more SMOL learns and organizes. Purchasing a real company is more expensive than hiring a small team, purchasing a company with revenue/investors, is more expensive again. Purchasing a company with good legal advice is more expensive again. Purchasing a wiser, more experienced SMOL is more expensive again. BIG has to act quickly to ensure the cheapest price, and declutter future timelines of risks.Also, the longer BIG waits, the less effective are \"Jedi mind trick\" gaslighting statements like \"P is not a good candidate for a business\", \"niche\", \"fan base\" (BIG internal memo - do not say customers), \"own thing\".In reality in this case P's stickiness was clear: people allocating 1000s of dollars toward AI lured merely by P's possibilities. It was only a matter of time before investment followed course.I've experienced this situation multiple times over the course of BrowserBox's life. Multiple \"BIG\" (including ones you will all know) have approached with the same kind of routine: hire, or some variations of that theme with varying degrees of legal cleverness/trickery in documents. In all cases, I rejected, because it never felt right. That's how I know what I'm telling you here.I think when you are SMOL it's useful to remember the Parable of Zuckerberg and the Yahoos. Adapted from history by Gemini Pro 3:  And it came to pass in the days of the Great Silicon Plain, that there arose a youth named Mark, of the tribe of the Harvardites. And Mark fashioned a Great Loom, which men called the Face-Book, wherewith the people of the earth might weave the threads of their lives into a single tapestry.\n\n  And the Loom grew with a great exceeding speed, for the people found it to be a thing of much wonder. Yet Mark was but SMOL, and his tabernacle was built of hope and raw code, having not yet the walls of many lawyers or the towers of gold.\n\n  Then came the elders of the House of Yahoo, a BIG people, whose chariots were many but whose engines were grown cold. And they looked upon the Loom and were sore afraid, saying among themselves, \u201cBehold, if this youth continueth to weave, he shall surely cover the whole earth, and our own garments shall appear as rags. Let us go down now, while he is yet unaware of his own strength, and buy him for a pittance of silver, before he realizeth he is a King.\u201d\n\n  And the Yahoos approached the youth with soft words and the craftiness of the serpent. They spake unto him, saying, \u201cVerily, Mark, thy Loom is a pleasant toy, a niche for the young, a mere 'fan base' of the idle. It is not a true Business, nor can it withstand the storms of the market. Come, take of our silver\u2014a billion pieces\u2014and dwell within our walls. For thy Loom is but a small thing, and thou art but a child in the ways of the law.\u201d\n\n  And they used the Hidden Speech, which in the common tongue is called Gas-Lighting. They said, \u201cThou hast no revenue; thy path is uncertain; thy Loom is but a curiosity. We offer thee safety, for the days are evil.\u201d\n\n  But the Spirit of Vision dwelled within the youth. He looked upon the Yahoos and saw not their strength, but their fear. He perceived the Asymmetry of Truth: that the BIG sought to purchase the future at the price of the past, and to slay the giant-slayer while he yet slumbered in his cradle.\n\n  The elders of Mark\u2019s own house cried out, \u201cTake the silver! For never hath such a sum been seen!\u201d\n\n  But Mark hardened his heart against the Yahoos. He spake, saying, \u201cYe say my Loom is a niche, yet ye bring a billion pieces of silver to buy it. Ye say it is not a business, yet ye hasten to possess it before the sun sets. If the Loom be worth this much to you who are blind, what must it be worth to me who can see?\u201d\n\n  And he sent the Yahoos away empty-handed.\n\n  The Yahoos mocked him, saying, \u201cThou art a fool! Thou shalt perish in the wilderness!\u201d But it was the House of Yahoo that began to wither, for their timing was spent and their craftiness had failed.\n\n  And Mark remained SMOL for a season, until his roots grew deep and his walls grew high. And the Loom became a Great Empire, and the billion pieces of silver became as dust compared to the gold that followed.\n\n  The Lesson of the Prophet:\n\n  Hearken, ye who are SMOL and buildeth the New Things: When the BIG come unto thee with haste, speaking of thy \"limitations\" while clutching their purses, believe not their tongues. For they seek not to crown thee, but to bury thee in a shallow grave of silver before thou learnest the name of thy own power.\n\n  For if they knew thy work was truly naught, they would bide their time. But because they know the harvest is great, they seek to buy the field before the first ear of corn is ripe.\n\n  Blessed is the builder who knoweth his own worth, and thrice blessed is he who biddeth the Giants to depart, that his own vine may grow to cover the sun.reply",
      "\"build a hugely popular tool\"Define hugely popular relative to the scale of users of OAI... personally this thread is the first time Ive heard of openclaw.reply",
      "you living under a rockreply",
      "The tech industry is broad, and if you are using OpenAI in a consumer and personal manner you weren't the primary persona amongst whom the conversation around OpenClaw occurred.Additionally, much of the conversation I've seen was amongst practitioners and Mid/Upper Level Management who are already heavy users of AI/ML and heavy users of EAs.There is a reason why if you aren't in a Tier 1 tech hub like SV, NYC, Beijing, Hangzhou, TLV, Bangalore, and Hyderabad you are increasingly out of the loop for a number of changes that are happening within the industry.reply",
      "There\u2019s plenty of straightforward reasons why OpenAI would want to do this, it doesn\u2019t need to be some sort of malicious conspiracy.I think it\u2019s good PR (particularly since Anthropics actions against OpenCode and Clawdbot were somewhat controversial) + Peter was able to build a hugely popular thing & clearly would be valuable to have on the team building something along the lines of Claude Cowork. I would expect these future products to be much stronger from a security standpoint.reply"
    ],
    "link": "https://steipete.me/posts/2026/openclaw",
    "first_paragraph": "tl;dr: I\u2019m joining OpenAI to work on bringing agents to everyone. OpenClaw will move to a foundation and stay open and independent.The last month was a whirlwind, never would I have expected that my playground project would create such waves. The internet got weird again, and it\u2019s been incredibly fun to see how my work inspired so many people around the world.There\u2019s an endless array of possibilities that opened up for me, countless people trying to push me into various directions, giving me advice, asking how they can invest or what I will do. Saying it\u2019s overwhelming is an understatement.When I started exploring AI, my goal was to have fun and inspire people. And here we are, the lobster is taking over the world. My next mission is to build an agent that even my mum can use. That\u2019ll need a much broader change, a lot more thought on how to do it safely, and access to the very latest models and research.Yes, I could totally see how OpenClaw could become a huge company. And no, it\u2019s not"
  },
  {
    "title": "Magnus Carlsen Wins the Freestyle (Chess960) World Championship (fide.com)",
    "points": 122,
    "submitter": "prophylaxis",
    "submit_time": "2026-02-15T22:17:10 1771193830",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=47028227",
    "comments": [
      "How long do chess players typically remain at their peak for? According to wikipedia, Magnus is currently 35. Is it impressive to be winning at 35? Would we expect to see his performance drop off in the next 5-10 years?Even if he is still capable mentally and physically, I would think the stress of training and competing at that level must get old after a while.reply",
      "Anand reached world #1 ranking at 38, managed to win a world championship and defend the title for a decade in his late 40s, and remains in #13 in his 50s right now.reply",
      "Magnus is in uncharted territory here.  We won't really know the answer to this question for quite some time.reply",
      "Kasparov remained the n.1 player until his retirement at 42, we can likely expect no less from Magnusreply",
      "Is there really a decline with age when it comes to chess? I\u2019m not sure he will really decline until he reaches his retirement age.reply",
      "For some concrete numbers, there are only four players over 50 years of age in the top 100 at the moment by live ratings[0]. They are ranked #13 (age 56), #89 (age 53), #95 (age 54), and #97 (age 57). In their primes these players were ranked #1, #10, #4, and #3 respectively.[0]: https://2700chess.com/?per-page=100reply",
      "This is some fascinating data, thanks for pulling it together.reply",
      "There's a sharp decline with age. Magnus himself says he's not as sharp as he was younger, even if he can compensate with experience.reply",
      "For most people there is a cognitive decline with age, and chess is clearly a cognitive effort. Like with everything else: experience really matters, but you will simply be a bit less sharp over time and in a game where a tiny mistake can compound to a loss it really matters.reply",
      "Context helps. A lot of really strong players are 12 years old.reply"
    ],
    "link": "https://www.fide.com/magnus-carlsen-wins-2026-fide-freestyle-world-championship/",
    "first_paragraph": "All NewsFIDE NewsChess NewsTopTop FederationsMain Page / SearchTournamentsTitlesTransfersCalculatorsDownloadFIDE CircuitWomen's Circuit '26-'27Open Cycle 2025-2026Women\u2019s Cycle 2025-2026Women\u2019s Cycle 2023-2025All TournamentsMain EventsAbout FIDEHandbookDocumentsClean SportFinancial ReportsOfficialsCommissions & CommitteesFederationsAffiliated OrganizationsAffiliated MembersHonourable DignitariesChartMagnus Carlsen (Norway) is the 2026 FIDE Freestyle Chess World Champion. A draw in the fourth and final game against Fabiano Caruana (USA) was enough to seal a 2.5\u20131.5 match victory in Weissenhaus, Germany.\u00a0The decisive moment came in game three. Carlsen won from a dead lost position, turning the match in his favor. Entering the final game, he needed only a draw and achieved it in an equal endgame after Caruana missed late chances to mount a comeback. Both finalists qualified for the 2027 FIDE Freestyle Chess World Championship.The 2026 tournament marks the first official FIDE-recognized Fr"
  },
  {
    "title": "Pink noise reduces REM sleep and may harm sleep quality (pennmedicine.org)",
    "points": 36,
    "submitter": "gnabgib",
    "submit_time": "2026-02-16T00:35:12 1771202112",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=47029397",
    "comments": [
      "Researchers observed 25 healthy adults, ages 21 to 41, in a sleep laboratory during eight-hour sleep opportunities over seven consecutive nights.Absurdly low n. Additionally, I've become very skeptical of anything coming out of sleep labs after my wife was sent to one (at a prestigious teaching hospital) by her doctor some years ago: the 'sleep opportunity' was lights out at 9pm for 8 hours, and the staff were wholly indifferent to the fact that she's a night owl and prefers to sleep after midnight. Additionally she reported that it was not particularly quiet or dark.I am not a fan of noise machines but I have noticed that I sleep best on rainy nights, which has a similar average sound spectrum, and is about the same as the sound of your blood circulating near your eardrums. Testing pink noise along with aircraft noise (which is closer to red noise) is equivalent to just making the noise level higher with slightly more midrange energy. Some noise can be relaxing for light sleepers; too much is just annoying.reply",
      "Sleep labs are like doctors are like mechanics are like restaurants - their only legal obligation is to not kill you,not be of any particular quality.Do your homework.reply",
      "\"Pink noise sounds like a waterfall.\" https://en.wikipedia.org/wiki/Pink_noisereply",
      "With some friends we usually go camping near a waterfall and we always try to camp a little further so we don't hear the noise. At least not too much. We always assumed it was related to the fact that you can't hear anything approaching, some kind of primal instinctreply",
      "Helps me quite a bit to focus when Im in noisy spaces.reply",
      "This reminds me of an old Wired interview with Danny Hillis when he developed a system called Babble that used unintelligible vocal bits as background sound to help concentration, too bad it never really went anywhere.\nhttps://www.wired.com/2005/06/applied-minds-think-remarkably...reply",
      "A number of noise generators have that sort of nonsensical babble as a component of the sound. For instancehttps://mynoise.net/NoiseMachines/cafeRestaurantNoiseGenerat...Nothing that your mind has enough edges on to try to interpret, but vaguely human-like.reply",
      "I grew up in South East Asia with air con running all night, when I moved away I found it hard to sleep in 'quieter' countriesreply",
      "This. In summer I get \u2018addicted\u2019 to fan noise and cant sleep without. I moved to Asia and the AC is such a blessing.reply",
      "I'm also addicted to the fan but not only for the noise I like feeling the wind in my face, I think that as it also helps lower your body temperature you sleep betterreply"
    ],
    "link": "https://www.pennmedicine.org/news/pink-noise-reduces-rem-sleep-and-may-harm-sleep-quality",
    "first_paragraph": "Earplugs worked better in protecting sleep from aircraft noise, according to rigorous sleep lab study.Pink noise\u2014often used to promote sleep\u2014may reduce restorative REM sleep and interfere with sleep recovery. In contrast, earplugs were found to be significantly more effective in protecting sleep against traffic noise, according to new study published in the journal Sleep from the University of Pennsylvania Perelman School of Medicine.The findings challenge the widespread use of ambient sound machines and apps marketed as sleep aids.\u201cREM sleep is important for memory consolidation, emotional regulation and brain development, so our findings suggest that playing pink noise and other types of broadband noise during sleep could be harmful\u2014especially for children whose brains are still developing and who spend much more time in REM sleep than adults,\u201d said study lead author Mathias Basner, MD, PhD, professor of Sleep and Chronobiology in Psychiatry.Researchers observed 25 healthy adults, ag"
  },
  {
    "title": "Error payloads in Zig (srcreigh.ca)",
    "points": 39,
    "submitter": "srcreigh",
    "submit_time": "2026-02-15T23:08:43 1771196923",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=47028705",
    "comments": [
      "Continues to be a point of annoyance that Zig doesn't properly support payloads in errors.reply",
      "I thought so too at first, coming from a language (Hare) where they are very easy and common, but the Diagnostics pattern isn't that bad once you expect it. Various examples: https://ziggit.dev/search?q=Diagnosticsreply",
      "page is deadreply"
    ],
    "link": "https://srcreigh.ca/posts/error-payloads-in-zig/",
    "first_paragraph": ""
  },
  {
    "title": "LT6502: A 6502-based homebrew laptop (github.com/techpaula)",
    "points": 305,
    "submitter": "classichasclass",
    "submit_time": "2026-02-15T17:12:35 1771175555",
    "num_comments": 132,
    "comments_url": "https://news.ycombinator.com/item?id=47025399",
    "comments": [
      "I sometimes wonder what the alternate reality where semiconductor advances ended in the eighties would look like.We might have had to manage with just a few MB of RAM and efficient ARM cores running at maybe 30 MHz or so. Would we still get web browsers? How about the rest of the digital transformation?One thing I do know for sure. LLMs would have been impossible.reply",
      "For me the interesting alternate reality is where CPUs got stuck in the 200-400mhz range for speed, but somehow continued to become more efficient.It\u2019s kind of the ideal combination in some ways. It\u2019s fast enough to competently run a nice desktop GUI, but not so fast that you can get overly fancy with it. Eventually you\u2019d end up OSes that look like highly refined versions of System 7.6/Mac OS 8 or Windows 2000, which sounds lovely.reply",
      "The GameBoy Advance could run 2D games (and some 3D demos) on 2 AA batteries for 16 hours.\nI wonder if we could get something more efficient with modern tech? It seems research made things faster but more power hungry. We compensate with better batteries instead. I guess we can and it's a design goal problem, I also do love a screen with backlight.reply",
      "> It seems research made things faster but more power hungryNo, modern CPUs are far more power efficient for the same compute.The primary power draw in a simple handheld console like would be the screen and sound.Putting an equivalent MCU on a modern process into that console would make the CPU power consumption so low as to be negligible.reply",
      "I loved System 7 for its simplicity yet all of the potential it had for individual developers.Hypercard was absolutely dope as an entry-level programming environment.reply",
      "The Classic Mac OS model in general I think is the best that has been or ever will be in terms of sheer practical user power/control/customization thanks to its extension and control panel based architecture. Sure, it was a security nightmare, but there was practically nothing that couldn\u2019t be achieved by installing some combination of third party extensions.Even modern desktop Linux pales in comparison because although it\u2019s technically possible to change anything imaginable about it, to do a lot of things that extensions did you\u2019re looking at at minimum writing your own DE/compositor/etc and at worst needing to tweak a whole stack of layers or wade through kernel code. Not really general user accessible.Because extensions were capable of changing anything imaginable and often did so with tiny-niche tweaks and all targeted the same system, any moderately technically capable person could stack extensions (or conversely, disable system-provided ones which implemented a lot of stock functionality) and have a hyper-personalized system without ever writing a line of code or opening a terminal. It was beautiful, even if it was unstable.reply",
      "I\u2019m not too nostalgic for an OS that only had cooperative scheduling. I don\u2019t miss the days of Conflict Catcher, or having to order my extensions correctly.\nIllegal instruction? Program accessed a dangling pointer? Bomb message held up your own computer and you had to restart (unless you had a non-stock debugger attached and can run ExitToShell, but no promises there.)reply",
      "It had major flaws for sure, but also some excellent concepts that I wish could've found a way to survive through to the modern day. Modern operating systems may be stable and secure, but they're also far more complex, inflexible, generic, and inaccessible and don't empower users to anywhere near the extent they could.reply",
      "Or if 640k was not only all you'd ever need, it was all we'd ever get.reply",
      "Given enough power and space efficiency you would start putting multiple cpus together for specialized tasks. Distributed computing could have looked differentlyreply"
    ],
    "link": "https://github.com/TechPaula/LT6502",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A 6502 based laptop design\n      A 6502 based laptop designYes, I know I'm crazy, but I figured why not. I'm enjoying working the PC6502 project but having a little tower of PCBs on the sofa isn't the best.\nIt's very simple, these are the specsAssembled front view\n\nAssembled rear view\n\nAssembled LHS view\n\nAssembled RHS view\nAssembled closed front view\n\nAssembled closed rear view\nLower parts (main board, battery, keyboard) in it's case\n\nScreen with BASIC code\n\nFirst bring up\nThe memory map is fairly stable at the moment, everything seems to be working fine.I've Added a some extra commands to EhBASIC and they are as follows;\n        A 6502 based laptop design\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Audio is the one area small labs are winning (amplifypartners.com)",
    "points": 97,
    "submitter": "rocauc",
    "submit_time": "2026-02-13T05:39:45 1770961185",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=46999285",
    "comments": [
      "This matches my experience. In Kaggle audio competitions, I've seen many competitors struggle with basics like proper PCM filtering - anti-aliasing before downsampling, handling spectral leakage, etc.Audio really is a blue ocean compared to text/image ML. The barriers aren't primarily compute or data - they're knowledge. You can't scale your way out of bad preprocessing or codec choices.When 4 researchers can build Moshi from scratch in 6 months while big labs consider voice \"solved,\" it shows we're still in a phase where domain expertise matters more than scale. There's an enormous opportunity here for teams who understand both ML and signal processing fundamentals.reply",
      "Also, while the author complains that there is not a lot of high quality data around [0], you do not need a lot of data to train small models. Depending on the problem you are trying to solve, you can do a lot with single-digit gigabytes of audio data. See, e.g., https://jmvalin.ca/demo/rnnoise/[0] Which I do agree with, particularly if you need it to be higher quality or labeled in a particular way: the Fisher database mentioned is narrowband and 8-bit mu-law quantized, and while there are timestamps, they are not accurate enough for millisecond-level active speech determination. It is also less than 6000 conversations totaling less than 1000 hours (x2 speakers, but each is silent over half the time, a fact that can also throw a wrench in some standard algorithms, like volume normalization). It is also English-only.reply",
      "RNNoise is a great example \u2014 Jean-Marc Valois proved you can do serious work with kilobits of model weight and modest training data. The \"need petabytes or go home\" mindset is definitely wrong for audio.The data bottleneck you mention is real, though, and it's where policy becomes a technical constraint. Japan's copyright law explicitly allows AI training on copyrighted works without permission (Article 30-4). The US is murkier, but case law seems to be trending toward fair use when the model itself and its outputs don't contain reproductions of the original audio.That distinction matters \u2014 training on copyrighted speech is one thing, outputting that same speech is another. If US jurisprudence solidifies around that separation, it opens up a lot more training data without forcing every lab to move to Tokyo.The Fisher database limitations you noted are exactly why this matters. When you're competing with labs that can legally scrape high-fidelity labeled data from anime/games/audiobooks, legal uncertainty becomes a real competitive disadvantage. Knowledge barriers are tractable. Legal barriers? Those are harder to engineer around.reply",
      "Good article and I agree with everything in there. For my own voice agent I decided to make him PTT by default as the problems of the model accurately guessing the end of utterance are just too great. I think it can be solved in the future but, I haven't seen a really good example of it being done with modern day tech including this labs. Fundamentally it all comes down to the fact that different humans have different ways of speaking, and the human listening to them updates their own internal model of the speech pattern. Adjusting their own model after a couple of interactions and arriving at the proper way of speaking with said person. Something very similar will need to be done and at very fast latency's for it to succeed in the audio ml world. But I don't think we have anything like that yet. It seems currently best you can do is tune the model on a generic speech pattern that you expect to fit over a larger percentage of the human population and that's about the best you can do, anyone who falls outside of that will feel the pain of getting interrupted every time.reply",
      "There's too much noise at large organizationsreply",
      "They're focused on soaking up big money first.They'll optimize down the stack once they've sucked all the oxygen out of the room.Little players won't be able to grow through the ceiling the giants create.reply",
      "OpenAI being the death star and audio AI being the rebels is such a weird comparison, like what? Wouldn't the real rebels be the ones running their own models locally?reply",
      "True, but there's a fun irony: the Rebels' X-Wings are powered by GPUs from a company that's... checks relationships ...also supplying the Empire.NVIDIA's basically the galaxy's most successful arms dealer, selling to both sides while convincing everyone they're just \"enabling innovation.\" The real rebels would be training audio models on potato-patched RP2040s. Brave souls, if they exist.reply",
      "not sure about the irony - you can't really expect rebels to start their own weapons manufacturing lab right from converting ore into steel... these things are often supplied by a large manufacturer (which is often a monopoly)\nwhy is it any different for a startup to tap into nvidia's proverbial shovel in order to start digging for gold?reply",
      "Reply to garyfirestorm on HN:Fair point \u2014 the X-Wing analogy breaks down when you look at actual insurgencies. Rebels absolutely use off-the-shelf weapons from whoever will sell to them.But here's the thing: we're actually entering an era where \"homebrew weapons\" is becoming possible for inference. Apple's Neural Engine, Google's TPU, Qualcomm's Hexagon \u2014 these are NPUs shipping in billions of devices already. You've got startups like Syntiant making ultra-low-power inference chips for always-on voice, and even microcontroller vendors adding ML accelerators.The \"rebel\" angle shifts from \"manufacturing your own GPU\" to \"optimizing for the silicon that's already in your pocket.\" That's where things get interesting \u2014 running decent audio models on a $5 Raspberry Pi Zero or an ESP32 with an accelerator add-on.Granted, training still needs the datacenter. But inference? We're getting to the point where \"rebel infrastructure\" is just \"commodity hardware + smart optimization.\" I'm betting on that side.reply"
    ],
    "link": "https://www.amplifypartners.com/blog-posts/arming-the-rebels-with-gpus-gradium-kyutai-and-audio-ai",
    "first_paragraph": "If AI research is Star Wars and OpenAI is the death star, then without a doubt the rebels are building audio models. The best models for voice \u2013 TTS, STS, STT, and the like \u2013 are not coming from the big labs. Instead, they\u2019re built by their underfunded, understaffed, and underhyped siblings, a wave of incredible startups that is improbably crushing benchmarks with every model release. And if you believe that audio is the biggest future modality for AI \u2013 like many researchers do \u2013 this is one of the more interesting and underdiscussed topics in genAI today.One of these improbably cutting edge startups is Gradium, born out of the open lab Kyutai.\u00a0In summer 2024 on a stage in Paris, a Kyutai researcher (his name is Neil) demoed the first realtime audio conversation with AI. This model (Moshi) could respond in real time, change its voice style and volume on request, and even recite an original poem in a French accent (research shows poems sound better this way).\u00a0You\u2019ve probably seen audio "
  },
  {
    "title": "Radio host David Greene says Google's NotebookLM tool stole his voice (washingtonpost.com)",
    "points": 91,
    "submitter": "mikhael",
    "submit_time": "2026-02-15T18:05:24 1771178724",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=47025864",
    "comments": [
      "Compare for yourself.David Greene: https://youtu.be/xYxQrLp4MQkNotebookLM: https://youtu.be/AR4dRtzFvxMI think he just has \"podcast guy\" voice. It's pretty generic.reply",
      "Yup, it's absolutely not his voice. The NotebookLM voice is pitched significantly higher.Nor does it seem like his voice but changed \"just enough\" (like in pitch).I agree, he just has a very generic-sounding \"podcast guy\" voice. And obviously, NotebookLM trained on tons of podcasts and is generating a highly generic, average-sounding voice. Which is why it's pitched higher, since David Greene has a lower than average pitch.This lawsuit is either just to generate buzz to build his personal brand, or maybe he's worried about the competitive threat from AI. But there's no way he's going to win this suit. This isn't like the case with Bette Midler, where Ford intentionally hired someone to mimic her voice.reply",
      "You never know, it might be worth a couple hundred grand in settlement money\u2026reply",
      "Congratulations. I hate both of them. Maybe I\u2019m old but the podcast style of \u201cthere might be some interesting information here, but let me tease it for ages with a voice that makes you think something interesting is about to happen\u2026\u201d No sir, I don\u2019t like itreply",
      "This is the same reason I\u2019ve watched about 4 hours of YouTube since it launched. Almost all car-repair videos.reply",
      "I watch a lot of synthesizer videos, and over the years an wholly organic 'no talking' genre has emerged for just this reason. Some people do reviews via subtitles.reply",
      "Dude voice, totally. I can\u2019t describe it other than dude voice.reply",
      "It's like they tried their hardest to add as much vocal fry [1] as possible.[1] https://www.youtube.com/watch?v=Q0yL2GezneUreply",
      "Yeah, this shouldn\u2019t even be on HN, or Washington Post for that matter.There are going to be countless people that think AI is using their voice. Humans share remarkably similar voices, but obviously you can\u2019t copy that (other than impersonations, obviously).Unless there is evidence that a company intentionally went after a specific human voice to train their AI, there\u2019s no reason to report on these people claiming AI is using their voice.Maybe if it\u2019s someone with a very distinctive voice. But this guys, as the OP said, just has a \u201cgeneric podcast guy\u201d voice.reply",
      "It sounds similar, but doesn't sound the same to me. \nAlso how would you determine the similarity allowed? Maybe if we would have such a measure they could use that in voice model training to not allow that much similarity to a single voice, but if we don't have an agreed upon value for that than it's a subjective \"sounds the same to me\" rule then it's hard to follow that.\nOk, they can say that don't train on their voice, but it's very likely that a blend of voices from an \"allowed\" set could produce a very similar voice to his.reply"
    ],
    "link": "https://www.washingtonpost.com/technology/2026/02/15/david-greene-google-ai-podcast/",
    "first_paragraph": ""
  },
  {
    "title": "Modern CSS Code Snippets: Stop writing CSS like it's 2015 (modern-css.com)",
    "points": 219,
    "submitter": "eustoria",
    "submit_time": "2026-02-15T18:04:10 1771178650",
    "num_comments": 87,
    "comments_url": "https://news.ycombinator.com/item?id=47025851",
    "comments": [
      "CSS in 2025: Let's write html inlined styles as if it was 2005 and separation of formatting/representation was never invented. I talk of tailwind, of course.reply",
      "HTML vs. CSS is a separation of technologies. If HTML was really only about the content and the CSS was only about styling, we wouldn't have to write div soups to style our websites (.container-wrapper .container .container-inner { /* \"separation\" */ }) and we wouldn't have to adjust our HTML when we change the layout.reply",
      "The deadest horse in web development is the myth of \u201cseparation of concerns\u201dreply",
      "I was recently doing some very specific web scraping of some very public very static documents. About 25% of them use a soup of divs with hashes for class names. Not a <main> or <article> or <section> in sight. I am fine with the idea of what tailwind does but like at least using semantic tags where appropriate could be a thing.reply",
      "You can separate concerns without violating locality of behavior, and that\u2019s exactly what tailwind does.It admittedly does not do a good job at being very DRY but I think that\u2019s poorly applied to HTML/CSS in general, and the most DRY css is often over abstracted to the point of becoming nigh uninterpretable.reply",
      "When I write CSS, I most often do not want the locality of behavior. I instead want uniformity of behavior, hence \"semantic\" styles. Even the trivial light / dark mode switching is pain with Tailwind, when classes like \"color-gray-200\" are routinely applied.reply",
      "I\u2019d somewhat agree with you there, but I usually use variables for uniformity. I do see arguments against tailwind but find anytime I\u2019ve tried to do anything else it just feels like bikeshedding on internals for the same end result.Really what I want to see is beautiful TDD for CSS so that uniformity can be enforced, but I\u2019m not sure that exists.reply",
      "Variables are hugely helpful, I agreee.\nIDK about bikeshedding. I'm very used to writing React code that normally declares no styles for components at all, and having CSS that style components using 1-2 classes, specific to these components. Container components control margins, <body> controls general things like fonts.It seems that what solves the problem is a good component library. \"But I need red text here!\" For what reason? It's a warning. OK, we've got <Text variant=\"warning\">, it will be styled appropriately, and will look like every other warning in the application.reply",
      "It's a choice. The dominant paradigms choose not to.I disagree. And that makes me the loser herereply",
      "Another loser here to second youreply"
    ],
    "link": "https://modern-css.com",
    "first_paragraph": "Modern CSS code snippets, side by side with the old hacks they replace. Every technique you still Google has a clean, native replacement now.Get one old \u2192 modern comparison in your inbox every week.A project by naeemnur \u00b7 Changelog"
  },
  {
    "title": "I fixed Windows native development (marler8997.github.io)",
    "points": 667,
    "submitter": "deevus",
    "submit_time": "2026-02-15T11:25:26 1771154726",
    "num_comments": 326,
    "comments_url": "https://news.ycombinator.com/item?id=47022891",
    "comments": [
      "This is harder than what I do. Just install LTSC Visual Studio build tools from [1], then chuck this in a cmd file:    cl yourprogram.c /link user32.lib advapi32.lib ... etc etc ...\n\nI've built a load of utilities that do that just fine. I use vim as an editor.The Visual Studio toolchain does have LTSC and stable releases - no one seems to know about them though. see: https://learn.microsoft.com/en-gb/visualstudio/releases/2022... - you should use these if you are not a single developer and have to collaborate with people. Back like in the old days when we had pinned versions of the toolchain across whole company.[1] https://download.visualstudio.microsoft.com/download/pr/5d23...reply",
      "> The Visual Studio toolchain does have LTSC and stable releases - no one seems to know about them though.You only get access to the LTSC channel if you have a license for at least Visual Studio Professional (Community won't do it); so a lot of hobbyist programmers and students are not aware of it.On the other hand, its existence is in my experience very well-known among people who use Visual Studio for work at some company.reply",
      "You can install the LTSC toolchain without a license. Just not the IDE.reply",
      "That's not correct. You don't have to give your credit card details or even be logged in but you are still required to have any Visual Studio license. For hobbyists and startups the VS Community license is enough but larger companies need a VS Professional license even for the VS Build Tools.How strict Microsoft is with enforcement of this license is another story.reply",
      "You do not need a Professional or Enterprise license to use the Visual Studio Build Tools:> Previously, if the application you were developing was not OSS, installing VSBT was permitted only if you had a valid Visual Studio license (e.g., Visual Studio Community or higher).From (https://devblogs.microsoft.com/cppblog/updates-to-visual-stu...). For OSS, you do not even need a Community License anymore.reply",
      "The license doesn't actually permit OSS development.  Only compilation of near-unmodified third party OSS libraries.You may not compile OSS software developed by your own organisation.The OSS software must be unmodified, \"except, and only to the extent, minor modifications are necessary so that the Open Source Dependencies can be compiled and built with the software.\"https://visualstudio.microsoft.com/license-terms/vs2026-ga-d...reply",
      "This does not apply if you're developing closed source:> if you and your team need to compile and develop proprietary C++ code with Visual Studio, a Visual Studio license will still be required.reply",
      "That just confirms the parent comment's point. If you're just using the build tools directly, you're fine. If need to develop \"with Visual Studio\" i.e. the IDE, not just the command line tools, then you need the paid license.reply",
      "Is the fancy text editor compiling, or the toolchain?I don\u2019t need visual to write, read, compile, or link any code using the toolchain.reply",
      "And a VS license isn't too expensive if you really want to buy one. Stack Social have legit licenses discounted to $15:https://www.stacksocial.com/sales/microsoft-visual-studio-pr...reply"
    ],
    "link": "https://marler8997.github.io/blog/fixed-windows/",
    "first_paragraph": "Imagine you\u2019re maintaining a native project. You use Visual Studio for building on Windows, so you do the responsible thing and list it as a dependencyBuild Requirements: Install Visual StudioIf you\u2019re lucky enough not to know this yet, I envy you.  Unfortunately, at this point even Boromir knows\u2026\nWell put BoromirWhat you may not realize is, you\u2019ve actually signed up to be unpaid tech support for Microsoft\u2019s \u201cVisual Studio Installer\u201d. You might notice GitHub Issues becoming less about your code and more about broken builds, specifically on Windows. You find yourself explaining to a contributor that they didn\u2019t check the \u201cDesktop development with C++\u201d workload, but specifically the v143 build tools and the 10.0.22621.0 SDK. No, not that one, the other one. You spend less time on your project because you\u2019re too busy being a human-powered dependency resolver for a 50GB IDE.Saying \u201cInstall Visual Studio\u201d is like handing contributors a choose-your-own-adventure book riddled with bad endings"
  },
  {
    "title": "I gave Claude access to my pen plotter (harmonique.one)",
    "points": 81,
    "submitter": "futurecat",
    "submit_time": "2026-02-13T16:15:58 1770999358",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=47004384",
    "comments": [
      "I think it's somewhat interesting that codex (gpt-5.3-codex xhigh), given the exact same prompt, came up with a very similar result.https://3e.org/private/self-portrait-plotter.svgreply",
      "The images are neat, but I would rather throw my laptop in the ocean than read chat transcripts between a human and an AI.(Science fiction novels excluded, of course.)reply",
      "Somebody a while back on HN compared sharing AI chat transcripts as the equivalent of telling everyone all about that \u201camazing dream you had last night\u201d.reply",
      "We're watching brains harmonize and work together.There aren't any priors for this, only crude analogies. This is alien contact. This is the spark of fire that kicked off civilization. This is the beginnings of the next industrial age.But what you're specifically watching here is two brains from two entirely different species communicating and working together.It doesn't matter that Claude is dumb and a statistical machine with flaws. We're early. This is only just starting.Imagine the communication paradigms we'll have in the future -I'm instructing image models with images instead of text. Images are better spatial arguments.What's better for thought? Probably thought. Language is just an encoding. Imagine what happens when we hook up BCI to this and can wear the AI like an exoskeleton?But the intermediate, these chat conversations, are amazing to watch. It's like a parent teaching a toddler, except the toddler is a trillion dollar machine that can work harder than a thousand humans at some discrete tasks that used to be impossible for metaheurisic algorithms to crack and required real humans.It's dreaming alright.reply",
      "I just skipped to the images. Don't even want to skim generated nonsense.reply",
      "-HAL, Throw my portable computing device through the porthole.-Im afraid I cant do that Dave!-HAL, do you need some time on dr. Chandras couch again?-Dave, relax, have you forgotten that I dont have arms?reply",
      "+1, I don\u2019t even fully read my own conversations with AIreply",
      "Oh that reminds me. Could someone make an AI interface where each agent uses a different Culture ship name, and looks like the dialog from Excession?If we are going to have a dystopia, lets make it fun, at least...reply",
      "That feels somehow sacrilegious.reply",
      "They haven\u2019t earned ship names yet.reply"
    ],
    "link": "https://harmonique.one/posts/i-gave-claude-access-to-my-pen-plotter",
    "first_paragraph": ""
  },
  {
    "title": "EU bans the destruction of unsold apparel, clothing, accessories and footwear (europa.eu)",
    "points": 777,
    "submitter": "giuliomagnifico",
    "submit_time": "2026-02-15T17:10:18 1771175418",
    "num_comments": 529,
    "comments_url": "https://news.ycombinator.com/item?id=47025378",
    "comments": [
      "I'm reading the comments and I get confused. I kinda think this is a good idea and it is not like the government is purely making it a 3rd party problem only.\nThis might make production more complicated for a while, but nowadays it is much easier to predict demand and produce quicker in smaller batches.\nIn the 90s you might need change a whole factory setting for every single piece of fabric but nowadays it is that most of it are produced in small sets anyway.Can anyone clear why would it not be a good idea?\nMy country can measured an increase of micro plastic from cloth fibers. We all know how pollution is getting worse. Here, we don't have winter, fall or anything anymore.\nThe acid rain from the 90s destroyed most of green on adjacent cities and when it is hot it gets in unbearably hot and when it is cold it gets stupidly cold.Food production decreased by 20% this year. I kid you not. Prices went up and most of people can't afford cow's meat anymore. Most people are living on pasta and eggs, eventually they eat pig and chicken but that's getting rare.reply",
      "Here's how this law is actually going to work.Instead of destroying the unsold clothes in Europe, manufacturers are going to sell them to \"resale\" companies in countries with little respect for the rule of law, mostly in Africa or Asia. Those companies will then destroy those clothes, reporting them as sold to consumers.So instead of destroying those clothes in Europe, we'll just add an unnecessary shipping step to the process, producing tons of unnecessary CO2.The disclosure paperwork and the s/contracts/bribes/ needed to do this will also serve as a nice deterrent for anybody trying to compete with H&M.reply",
      "This is a fantasy.No one is going to pay you to take your waste away and dispose of it. You would have to pay them.So now there's a strong financial incentive to a) not over produce, b) sell the clothes - even if it means selling them for next to nothing.reply",
      "lol, paying someone to \"take your waste away and dispose of it\" has been a stable of the \"recycle\" industry in western countries for 3 decades now. It took China putting on regulations on their side to disrupt that industry. Now you have to find other smaller economies to do that.reply",
      "You appear to be agreeing with the person you\u2019re replying to.reply",
      "I'm not. Read their comment and mine. This was always, and will always be a thing. It's not a burden, just a marginal cost of business. Instead of paying a European company a \u20ac40k to destroy your broken products, you can pay an African one \u20ac10k to \"recycle\" your product. Best of all, you're legally forced to. I can see hundreds of companies lobbying for this because it completely takes them off the hook. \"The law says we must do this. Please contact your representatives you dumb fucks\"reply",
      "There is enough local fraudulent waste management companies that shipping things to Africa to have it \"recycled\" is just a waste of money and time. Sweden recently had one of the largest fraud cases involving a waste management company, which also became the largest environmental case in Swedish history.The scheme is fairly simple. The criminals rent some land, dump the stuff there, and then have the company go bust, thus leaving the problem to the land owner. Rinse and repeat, and run it in parallel. It takes years before anyone call on the bluff that the stuff will surely get recycled \"someday\", and the main reason the Swedish police caught wind in the earlier mentioned case was that the waste started to self-ignite.The only benefit to ship it to Africa is the hope that it won't be found out and create bad press, but that doesn't work if everyone know it is fake.reply",
      "The original comment says \"sell them to \u00abresale\u00bb companies\". Selling goods means being paid for it, while you and the parent comment are both saying money goes in the opposite direction.reply",
      "When you negotiate the price to \u201dsell\u201d at, it\u2019s perfectly legitimate for that price to be negative.reply",
      "This particular thread of the argument can go on for a while. I can't well articulate the doubts I have because I'm not in the industry, but many such well-meaning laws have a tendency to backfire once given enough time for bad/poor actors to game it.reply"
    ],
    "link": "https://environment.ec.europa.eu/news/new-eu-rules-stop-destruction-unsold-clothes-and-shoes-2026-02-09_en",
    "first_paragraph": "The Delegated and Implementing Acts will support businesses in complying with new requirements.\nThe European Commission today (Feb 9) adopted new measures under the Ecodesign for Sustainable Products Regulation (ESPR) to prevent the destruction of unsold apparel, clothing, accessories and footwear.The rules will help cut waste, reduce environmental damage and create a level playing field for companies embracing sustainable business models, allowing them to reap the benefits of a more circular economy.Every year in Europe, an estimated 4-9% of unsold textiles are destroyed before ever being worn. This waste generates around 5.6 million tons of CO2 emissions \u2013 almost equal to Sweden\u2019s total net emissions in 2021.To help reduce this wasteful practice, the ESPR requires companies to disclose information on the unsold consumer products they discard as waste. It also introduces a ban on the destruction of unsold apparel, clothing accessories and footwear.The Delegated and Implementing Acts a"
  },
  {
    "title": "Show HN: Microgpt is a GPT you can visualize in the browser (boratto.ca)",
    "points": 99,
    "submitter": "b44",
    "submit_time": "2026-02-15T18:40:35 1771180835",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=47026186",
    "comments": [
      "There used to be this page that showed the activations/residual stream from gpt-2 visualized as a black-white image. I remember it being neat how you could slowly see order forming from seemingly random activations as it progressed through the layers.Can't find it now though (maybe the link rotted?), anyone happen to know what that was?reply",
      "Minor nit: In familiarity, you gloss over the fact that it's character rather than token based which might be worth a shout out:\"Microgpt's larger cousins using building blocks called tokens representing one or more letters. That's hard to reason about, but essential for building sentences and conversations.\"So we'll just deal with spelling names using the English alphabet. That gives us 26 tokens, one for each letter.\"reply",
      "Using ascii characters is a simple form of tokenization with less compressionreply",
      "hm. the way i see things, characters are the natural/obvious building blocks and tokenization is just an improvement on that. i do mention chatgpt et al. use tokens in the last q&a dropdown, thoughreply",
      "About how many training steps are required to get good output?reply",
      "I trained 12,000 steps at 4 layers, and the output is kind of name-like, but it didn't reproduce any actual name from it's training data after 20 or so generations.reply",
      "not many. diminishing returns start before 1000 and past that you should just add a second/third layerreply",
      "thank you for thisreply"
    ],
    "link": "https://microgpt.boratto.ca",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Klaw.sh \u2013\u00a0Kubernetes for AI agents (github.com/klawsh)",
    "points": 37,
    "submitter": "eftalyurtseven",
    "submit_time": "2026-02-15T17:22:59 1771176179",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=47025478",
    "comments": [
      "This looks like what I want. A few questions: is it possible to have a \u201cmayor\u201d type role that has the ability to start other agents, but at the same time be unable to access those secrets or infiltrate prompt data? The key piece I don\u2019t see is the agent needs a tool for klaw itself, and then I have to be able to configure that appropriately.Is there a unified human approval flow, or any kind of UI bundled with this? Maybe I missed this part.reply",
      "Right now the controller can see secrets across namespaces, so that level of isolation isn\u2019t there yet. It\u2019s on the roadmap though. Namespace-scoped secrets where a controller agent can spawn agents but can\u2019t read their secrets is the right model.\nNo human approval flow yet either, agents create directly. Would you want something like klaw dispatch --approve that queues until a human confirms?reply",
      "For us, we actually moved away from k8s to dedicated VMs on Proxmox for our agents. We initially had a containerized environment manager running in k8s, but found that VMs give you things containers struggle with: full desktop environments with X11 for GUI automation, persistent state across sessions and dedicated resources per agent. Each agent gets their own Debian VM with a complete OS, which makes it much easier to run tools like xdotool and browser automation that don't play well in containers.reply",
      "I got this issue too, but still found that a containerized desktop was superior due to resource efficiencyreply",
      "Makes sense, if your agents need full desktop and GUI automation VMs are the way to go. klaw is more on the headless side, agents talking to APIs, Slack, X, that kind of thing, so the lightweight binary model works. How many agents are you running on Proxmox?reply",
      "Ahh, that makes sense. Yeah you likely have a very different business model. We're more using them as \"AI employees\" that help us with tasks. Currently running 4 of these VMs but planning to add more.\nNote that each VM has a specific role: cluster monitoring, database stats, frontend/backend features (this is where VMs really shine) and a (very experimental) high-level manager.reply",
      "I have never had an issue with browser automation like selenium in containers. Is that actually an issue?reply",
      "We found that it works great for scraping but it's not so great for development. git worktrees in a VM are much faster over spinning up new containers with an existing codebase.reply",
      "Ha! This is great. I've been waiting for someone to make this.Giving an LLM a computer makes it way more powerful, giving it a kubernetes cluster should extend that power much further and naturally fits well with the way LLMs work.I think this abstraction can scale for a good long while. Past this what do you give the agent? Control of a whole Data Center I guess.I'm not sure if it will replace openclaw all together since kubernetes is kind of niche and scary to a lot of people. But I bet for the most sophisticated builders this will become quite popular, and who knows maybe far beyond that cohort too.Congrats on the launch!reply",
      "Thanks! The \"Kubernetes is scary\" point is fair, that's why the CLI is designed to feel intuitive even if you've never touched kubectl. There's also a controller agent that manages the whole cluster from plain English.On \"what comes after\", I think it's agents managing other agents. An AI SRE that watches load and spins up new agents automatically. The cluster/namespace model was designed with that direction in mind.And yeah, not trying to replace OpenClaw, different layer.OpenClaw defines what an agent does, klaw manages where and how many run. Complementary.reply"
    ],
    "link": "https://github.com/klawsh/klaw.sh",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        kubernetes for ai agents \n      \n\n\nThe Kubernetes for AI Agents\n\n  Deploy, orchestrate, and scale AI agents across your infrastructure.\n  One binary. No dependencies. From laptop to enterprise cluster.\n\nWebsite \u2022\n  Quick Start \u2022\n  Deployment Modes \u2022\n  Features \u2022\n  Architecture\n\n\n\n\nklaw is an open-source platform for deploying and managing AI agents at scale. Think of it as Kubernetes, but instead of containers, you're orchestrating intelligent agents that can code, research, communicate, and automate tasks.klaw supports multiple deployment modes to fit your needs:Run everything on a single machine\u2014perfect for development and small teams:Scale across multiple machines with controller-node architecture:Run agents in isolated containers for security and reproducibility:Use any LLM through a single API with automatic provider selection:"
  },
  {
    "title": "Pocketblue \u2013 Fedora Atomic for mobile devices (github.com/pocketblue)",
    "points": 53,
    "submitter": "nikodunk",
    "submit_time": "2026-02-15T16:40:13 1771173613",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=47025085",
    "comments": [
      "This is a really cool project, and IMHO the most important new-comer in the #MobileLinux distro space in a long time, as it takes a model proven on desktop, building upon a well-run distribution (Fedora) and applies it to mobile.I have yet to attempt daily-driving it, but just trying it and easily switching mobile shells (e.g., from Plasma Mobile to Phosh) so easily[0] without have weird side-effects from the previous environment has been quite exciting![0]: https://pocketblue.github.io/devices/oneplus-sdm845/#images-...reply",
      "Updating without worries has made it much more daily-drivable for me on a Oneplus 6 (ie. it has rollbacks and image-based updates), despite being so new. It's fun that image-based OSs - which were arguably popularlized by phones - are now coming back to phones on the Linux side too.reply",
      "It doesn't look like there's anything in the way of information posted that includes screenshots or what apps are included or available? Am I missing the link?reply",
      "This is based on bootc (bootable containers), so note that the OS build is described in a normal Dockerfile: https://github.com/pocketblue/pocketblue/blob/main/Container... which is then run by the Github action (or locally).Very similar to how Universal Blue, Bazzite, Bluefin etc. build at https://github.com/ublue-os/bazzite (see their Containerfile), but for mobile.Has a similar mission to https://postmarketos.org, but with a different build system AFAICTreply",
      "Very cool project, just wish it was a available on a wider range of devices. Hopefully someday!reply",
      "Supported devices:Xiaomi pad 5/6Oneplus 6/6T... That's it.Does anyone know if there's plans for more? Is this project in very early stages, or is it going to be another Graphene OS with an extremely limited device support?reply",
      "There's also Poco F1, we just haven't released it yet, and I am yet to add it to the docs (we'll have a single common image for both op6(t) and beryllium soon)There's also a person working on a Fairphone 5 support and I think someone was going to work on a PinePhone portContributions are always welome, we need more devices!reply",
      "GrapheneOS has such low count of devices due to strict support for security features reasons.These projects (Linux on mobile) are even more limited due to very poor support from the manufacturer for anything more than OEM and device specific build of Android, with lack of standards in mobile platforms.\nEvery device support is reverse engineering effort.\nSee https://wiki.postmarketos.org/wiki/Devices for the status of this effort.reply",
      "how does something like this not support pinephone and librem5 from day 1?reply",
      "Its just that none of the maintainers has a pinephoneThough it would probably be trivial to just copy what the non-atomic Fedora Mobility does for pinephones, I might as well do this in the future and just ask someone with a pinephone to testreply"
    ],
    "link": "https://github.com/pocketblue/pocketblue",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fedora Atomic for mobile devices\n      Pocketblue is a project which provides Fedora Atomic images for mobile devicesThis is a work-in-progress. During the installation process all data on your device will be wiped.\nUse at your own risk.Main chats:Other related chats:\n        Fedora Atomic for mobile devices\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Show HN: VOOG \u2013 Moog-style polyphonic synthesizer in Python with tkinter GUI (github.com/gpasquero)",
    "points": 66,
    "submitter": "gpasquero",
    "submit_time": "2026-02-15T19:40:57 1771184457",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=47026768",
    "comments": [
      "There is a reason that most people do not use interpreted languages, or languages with garbage collection, for audio synthesis and DSP.It's great that it works, and it may well work 99% of the time. And it may have been a great learning experience/platform, so congrats for that.But it's important for people to understand why this is generally the wrong toolset for this sort of software development, even when it can be so much fun.Python and other interpreted languages (Lua excepted, with conditions), and languages like Swift that have GC, cannot ensure non-blocking behavior in the code that need to runs in realtime. You can paper over this with very large audio buffers (which makes the synth feel sluggish) or with crossed fingers (which work a surprising amount of the time). But ultimately you need a language like C/C++/Rust etc. to ensure that your realtime DSP code is actually realtime.Despite Apple pushing Swift \"for everything\", even they still acknowledge that you should not write AudioUnit (or any other plugin formats) using Swift.Meanwhile, have fun with this, which it looks like you already did!reply",
      "You can paper over this with very large audio buffers (which makes the synth feel sluggish) or with crossed fingers (which work a surprising amount of the time).It\u2019s been a while since I was involved in computer audio, but is there a difficulty I\u2019m not seeing with simply using ring buffers and doing memory allocations upfront so as to avoid GC altogether?reply",
      "Oddly enough, there's another recent popular Show HN on the topic of fixing that (https://news.ycombinator.com/item?id=46972392).reply",
      "> Lua excepted, with conditionsWhere can I read more about this? Is Lua's garbage collector tuned for real-time operations?reply",
      "Not being a dev writing code running in realtime nor an audio type with experience of things not running in realtime, what happens when GC kicks in? Does the entire audio stack go silent? Does it only effect the one filter so it sounds like a drop, or is it a pause so not it is no longer in sync? In theory, I get why it is bad, but I'm curious of what it sounds like when it does go bad.reply",
      "The audio interface hardware expects to get N samples every M msecs, and stops for no man (or program). So, anything that stops or flows the flow enough that less than N samples are delivered every M msecs causes a click or pop in the output. How bad the pop actually sounds depends on a lot of different things, so its hard to predict.reply",
      "I sort of managed to get it working under 3.10 (and it would probably work considerably further back) but the output was a bit wonky, especially when trying to play multiple notes quickly or simultaneously. I had to patch a couple of things related to type annotations in synth/gui/app.py to make it run without MIDI support.Overall neat concept. I've thought about playing around with sounddevice myself and the code here offers quite a bit of guidance.Do you plan to put a license on this? Would you be interested in a PR to make a wheel (installable as an application with uv or pipx) from it? Also, I didn't play around with the patches, but it seems to me like they could be refactored to be data-driven.reply",
      "Doesn't work at all on my system (kubuntu stable, whatever the stock audio subsystem is now). keys stick down when activated with keyboard, labels on keys disappear once played, vu meter moves but no sound comes out except sporadic beeps.reply",
      "I have recently come to really like tkinter. It has many good concepts. And I too am using it from Python. That said ...Oh no ... Not another Python project, that doesn't pin its versions with hashes.    pip install numpy sounddevice\n    pip install mido python-rtmidi\n\nThis stuff really shouldn't be done in 2026 any longer.I mean it's a hobby project, so you are free to do what you want, of course. Just please never do this in a professional environment. This is one reason Python projects catch so much flak from many people. One day it works, next day it doesn't. And surely not 2 years later, when a random person stumbles upon the repository and wants to try things. Please make your projects reproducible. Use pinned versions and lock files containing hashes, so that other people can get the same setup and it doesn't become an \"It ran on my machine.\" project.reply",
      "This is fantastic work! I love how you stuck with pure Python libraries - tkinter, numpy, and sounddevice. The Moog ladder filter implementation is particularly impressive. Have you considered adding export functionality for the generated audio? Being able to save presets or record to WAV files would make this even more practical for music production. Great job on the GUI design too - those rotary knobs look perfect for this application.reply"
    ],
    "link": "https://github.com/gpasquero/voog",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        VOOG \u2014 Virtual Analog Synthesizer (Moog-style polyphonic synth with GUI)\n      Virtual Analog Synthesizer \u2014 a Moog-style polyphonic synthesizer built in Python with a tkinter GUI inspired by the Subsequent 37.Requires Python 3.13+ with tkinter.Hold a key to sustain \u2014 key repeat is filtered so notes don't re-trigger.Click and drag on the virtual keyboard. Drag across keys to glide between notes.Connect any MIDI controller. MIDI CC messages are mapped to synth parameters (cutoff, resonance, envelopes, LFO, etc.).All synth parameters use rotary knob controls:MIT\n        VOOG \u2014 Virtual Analog Synthesizer (Moog-style polyphonic synth with GUI)\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Transforming a Clojure Database into a Library with GraalVM Native Image and FFI (avelino.run)",
    "points": 11,
    "submitter": "PaulHoule",
    "submit_time": "2026-02-11T21:03:58 1770843838",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://avelino.run/chrondb-polyglot-ffi-clojure-graalvm-native-image/",
    "first_paragraph": ""
  },
  {
    "title": "JavaScript-heavy approaches are not compatible with long-term performance goals (sgom.es)",
    "points": 7,
    "submitter": "luu",
    "submit_time": "2026-02-16T00:26:23 1771201583",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://sgom.es/posts/2026-02-13-js-heavy-approaches-are-not-compatible-with-long-term-performance-goals/",
    "first_paragraph": ""
  },
  {
    "title": "Language a Wood for Thought: Susan Howe's Work (poetryfoundation.org)",
    "points": 5,
    "submitter": "apollinaire",
    "submit_time": "2026-02-11T23:07:10 1770851230",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.poetryfoundation.org/articles/1769037/language-a-wood-for-thought",
    "first_paragraph": ""
  },
  {
    "title": "GNU Pies \u2013 Program Invocation and Execution Supervisor (gnu.org.ua)",
    "points": 60,
    "submitter": "smartmic",
    "submit_time": "2026-02-15T20:53:26 1771188806",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=47027427",
    "comments": [
      "Almost 20 years ago now I worked for a company that sat a group of about 25 of us down to talk about their latest survey named...CRMPIES.Everyone looked at me like I was insane as I sat there chuckling. Thank you for bringing back that unfortunate memory.reply",
      "If you don\u2019t think whoever named it that way wasn\u2019t based, you\u2019re almost as naive as your coworkers :Preply",
      "Everyone needs to have made a web framework. Everyone needs to have made a programming language. Everyone needs to have made a supervisor. Everyone has to have made a container manager. Everyone needs to have made a text editor.reply",
      "Absolutely. I recently wrote my first compiler to get it off the bucket list\u2026 brainf*ck compiler/interpreter #100010134 or such? :-) Well\u2026 it was a fun half hour.reply",
      "Half an hour? Slacker!reply",
      "I disagree with all of this. If you have time and interest, or a real need, then go ahead. I've never met a programmer who's made all of these things in my 20 years of programming, and that includes PhDs, professors, and old graybeards about to retire.reply",
      "What's the value of making a supervisor? It seems to be mostly about gluing together some system APIs.reply",
      "In some industries it\u2019s critical. Think about aerospace where code is almost always homegrown or done by specialized company, and are specific implementations for specific needs. You don\u2019t have that many COTS due to the criticality etc.reply",
      "The thing about specific needs is that they are usually narrow. You could throw darts at the dartboard of problems, working on very narrow problems for years and never get a job solving any of them. If a problem calls out to you and you won't stop until you get a job with it, then the effort could be worth it. But sometimes, even if you get THE job, you'll have a slight twist in constraints that makes most of your prep go by the wayside.reply",
      "One release every 4 years. So this is like monit or systemd-supervisord and so on, a process manager. I have to say the thing I most enjoy about it is the fact that it's got the classic GNU trend of \"here's an obviously pronounceable spelling; let's say it a different way\".reply"
    ],
    "link": "https://www.gnu.org.ua/software/pies/",
    "first_paragraph": "\nThe name Pies (pronounced \"p-yes\") stands for Program\nInvocation and Execution Supervisor. This utility starts and controls\nexecution of external programs, called components. Each component is\na stand-alone program, which is executed in the foreground. Upon\nstartup, pies reads the list of components from its configuration\nfile, starts them, and remains in the background, controlling their\nexecution. If any of the components terminates, the default action\nof Pies is to restart it. However, it can also be programmed\nto perform a variety of another actions such as, e.g. sending mail\nnotifications to the system administrator, invoking another external\nprogram, etc.\nGNU pies can also be used as init daemon \u2014 the first process\nstarted during booting. The configuration can be supplied both as a\ntraditional /etc/inittab file or as a native GNU pies configuration\nfile, which gives much more flexibility. The control interface\nprovides extensive monitoring and management capabilities.\n\n  Return "
  },
  {
    "title": "Real-time PathTracing with global illumination in WebGL (erichlof.github.io)",
    "points": 123,
    "submitter": "tobr",
    "submit_time": "2026-02-12T18:35:39 1770921339",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=46993014",
    "comments": [
      "Damn, that's really impressive.reply",
      "So nice to see another person being that enthusiastic about ray tracing! I didn't do a comparable level of work in this field, but as a hobby this fascinates me a lot!One common misconception is that ray tracing is computationally prohibitive. It was, but no longer so; it's a target within our reach, especially so when there's GPU with hardware acceleration for ray casting.Many games use ray tracing for partial scene processing, and of course they all work in real time. My favourite example is Metro Exodus with ray traced global illumination, which works on last gen graphics hardware pretty well. Not all games use the technology efficiently, but the trend is already obvious: with accessible real time ray tracing rendering the scene will become a much easier task.P.S. I used \"ray tracing\" when more accurately I should have used \"path tracing\", but I prefer to use a single term to encompass the whole technology with all its variants.reply",
      "There is another that is also quite mature that will render most Three.js scenes:https://github.com/gkjohnson/three-gpu-pathtracerDemos here:https://gkjohnson.github.io/three-gpu-pathtracer/example/bun...This one is also an official Three.js example:https://threejs.org/examples/?q=path#webgl_renderer_pathtrac...reply",
      "This is neat. In the demos I would suggest making mouse/finger drag orbit the camera around the scene instead of panning. Panning can be done by a 2D image transformation so it doesn't show off the 3D nature of the renderer.reply",
      "I second the vote for orbit cam! Add double-click to choose the orbit point, and add a zoom control that is proportional to distance to orbit point, and it suddenly gets insanely easy to navigate the scene and find good views. It\u2019s too hard to control using translate and look-around angles.The demos I tried so far have translate and not pan, and those are fully 3d\u2026reply",
      "I recently wrote one in WebGPU, toohttps://github.com/ivanjermakov/moonlightreply",
      "Reminds me of the old POV-Ray stuff I did in the early-1990s. But... in realtime and in my browser. WTF!reply",
      "nice historical recreations, but I can't believe there was no '1984' image from Thomas Porter there https://graphics.pixar.com/library/DistributedRayTracing/ind... (and I can definitely remember few more!)reply",
      "Pretty great demos, and they do indeed run well on my phone; I suspected it might be an AI thing because of the tautology in the title, but it seems hand written.Particularly cool is the recreation of that classic scene from Kajiya's rendering equation paper, with the glass spheres and caustics.reply",
      "It's very interesting and I'm also impressed that most of the demoes run on my potato-phone.reply"
    ],
    "link": "https://erichlof.github.io/THREE.js-PathTracing-Renderer/",
    "first_paragraph": "Real-time PathTracing with global illumination and progressive rendering, all on top of the Three.js WebGL framework.  Desktop: Mouse click anywhere to capture mouse, then the usual Mouse-move and WASD/QZ keys control 1st person camera. Mousewheel to zoom in and out. O and P keys toggle Orthographic and Perspective camera modes. Left/Right arrow keys control camera\u2019s aperture size (depth of field blur effect), while Up/Down arrow keys control the Focal point distance from the camera. ESC key to exit and return the mouse pointer.Mobile: Swipe to rotate 1st person camera. The 4 Large Arrow buttons control camera movement. Horizontal pinch to zoom in and out.  Vertical Pinch controls camera\u2019s aperture size (depth of field blur effect).  The 2 smaller Up/Down Arrow buttons control the Focal point distance from the camera.  Orthographic camera mode can be turned on/off through the GUI checkbox.Geometry Showcase Demo demonstrates some primitive shapes for ray tracing, while showing off the r"
  }
]