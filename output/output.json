[
  {
    "title": "Chai-1 Defeats AlphaFold 3 (chaidiscovery.com)",
    "points": 81,
    "submitter": "glowingvoices",
    "submit_time": "2024-09-10T22:13:30.000000Z",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=41506157",
    "comments": [
      "The title in HN is inaccurate. Having a 1% higher score on one metric is not beating a previously published model. This is a replicate, which is fine enough.\n \nreply",
      "Does the use of \"foundation\" and \"multi-modal\" for describing this model mean anything, or are those just used as buzzwords? Funnily enough, the only place those terms appear in the paper is in the abstract.Also the paper says they basically copied the methods used for AlphaFold, but then included the ability to input language embeddings, and input some other side constraints that I don't have the biology knowledge to understand. They don't show any data that indicate how much these changes improve performance. They show a very modest improvement over AF3 (small enough that I would think it could be achieve through randomness/small variations in the training parameters). So I don't think this is very revolutionary, but I suppose it replicates AF3.\n \nreply",
      "Foundational maybe isn't the best label for this kind of model. My understanding of foundational models is that they are made to be a baseline which can be further fine tuned for specific downstream tasks. This seems more like an already fine tuned model, but I haven't looked carefully enough at the methodology to say.\n \nreply",
      "Would you then call it a buzzword, or is there some gentler excluded-middle interpretation of that word's application to the project?\n \nreply",
      "It\u2019s about like referring to a famous person\u2019s red carpet attire as \u201coff the shelf [designer name]\u201d. It downplays the effort that went into it more than anything.\n \nreply",
      "If by \"multi-modal\", you mean \"it takes several different datatypes as input or output\", then yes, it's multi-modal.  See Figure 1 in the Tech Report.\n \nreply",
      "In light of last week's fiasco with Reflection (https://venturebeat.com/ai/new-open-source-ai-leader-reflect...), I hope the community has a newfound enthusiasm for independent testing!This is extremely exciting news if true, so I'm eager to have it either confirmed or questioned. The one thing I hope we won't be doing is accepting SOTA evals from open-sourced models at face value.\n \nreply",
      "I don't know how people like Matt Schumer can attempt what looks like fraud and deception being chalked off as a giant oopsies (which isn't really convincing) and not face any consequences.For rest of us, this is a privilege that we don't have. We can't deceive, defraud our investors because it has real consequences....but not for people like Matt Schumer, why is that?\n \nreply",
      "Theranos everywhere? Except you can\u2019t afford to mess up when it comes to health.\n \nreply",
      "Is there some sort of betting line I can make money off with all this? \u201c-150 a new model isn\u2019t released in the next month claiming it is currently the best at something\u201d would let me retire years early.If there is another line that said \u201c+500 thus model will be forgotten and useless in 6 months\u201d could take my retirement from years to months.\n \nreply"
    ],
    "link": "https://www.chaidiscovery.com/blog/introducing-chai-1",
    "first_paragraph": "CareersPressCareersPressChai Discovery TeamSep 9, 2024We\u2019re excited to release Chai-1, a new multi-modal foundation model for molecular structure prediction that performs at the state-of-the-art across a variety of tasks relevant to drug discovery. Chai-1 enables unified prediction of proteins, small molecules, DNA, RNA, covalent modifications, and more.The model is available for free via a web interface, including for commercial applications such as drug discovery. We are also releasing the model weights and inference code as a software library for non-commercial use.We tested Chai-1 across a large number of benchmarks, and found that the model achieves a 77% success rate on the PoseBusters benchmark (vs. 76% by AlphaFold3), as well as an C\u03b1 LDDT of 0.849 on the CASP15 protein monomer structure prediction set (vs. 0.801 by ESM3-98B).Unlike many existing structure prediction tools which require multiple sequence alignments (MSAs), Chai-1 can also be run in single sequence mode without "
  },
  {
    "title": "A good day to trie-hard: saving compute 1% at a time (cloudflare.com)",
    "points": 404,
    "submitter": "eaufavor",
    "submit_time": "2024-09-10T15:03:31.000000Z",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=41501496",
    "comments": [
      "If you had asked me to make a wild guess as to how Cloudflare stores internal headers and then removes them, I would have come up with some options:- An entire separate dictionary or other data structure.- One single header containing all internal metadata.- All headers have a prefix, and the internal ones start with I and the external ones start with E.- All internal headers start with \u201cCFInt\u201d.I would not have come up with a scheme in which headers in a particular list are internal. (What if someone else uses this name?  What if something forgets to sanitize?  What if different simultaneously running programs disagree in the list?  What if the Connection header names a Cloudflare-internal header?  What if the set-difference algorithm is annoyingly slow?)The web is already full of obnoxiously ambiguous in-band signaling and header naming, and I find it bizarre that a company with Cloudflare\u2019s scale uses such a tedious and error-prone mechanism internally.\n \nreply",
      "Former employee here; the interesting (horrifying?) fact is that you can set some of these internal headers (I remember a notable bug with cf-cache-status) in workers (the serverless offering) and cause all kinds of bad things to happen :)\n \nreply",
      "It seems to me it should be trivial to strip anything internal that comes out of a worker right?\n \nreply",
      "Trivial unless someone wants to modify CF internal headers as part of their solution\u2026https://xkcd.com/1172/\n \nreply",
      "Haha thank you\n \nreply",
      "Ive worked at several huge corporations in IT security, where we care about headers a lot, and they all use headers in a manner similar to CloudFlare.Including using proxies at the edge to strip out internal headers bidirectionally- yes, inbound too.\n \nreply",
      "The first large scale piece of software I worked on was for telcos pre smart phone. We used internal headers to offload authentication and terminate SSL. We also had to pressure F5 to fix about half a dozen bugs in BIG-IP to do so. Bugs that should in no universe have existed in version 9 of a product.I used to joke that F5 owed me and my coworker 3 months of salary for all the free QA we did for them.\n \nreply",
      "It helps if you realize that BIG-IP 9.0 was essentially a from-scratch rewrite of BIG-IP 4.5.  Among other major redesigns, the data plane was moved from BSD kernel space to Linux user space.  Internally, the joke was that it would be two times better when we were done (4.5 * 2 = 9.0).  It probably was, but not on day zero.\n \nreply",
      "On day sixty it couldn\u2019t do SSL termination and cookie based traffic shaping didn\u2019t work.I was a little bummed it was \u201cjust\u201d a Linux box but that\u2019s pretty common today. I hadn\u2019t discovered dd-wrt yet and wouldn\u2019t for a few years.\n \nreply",
      "That doesn't make it better, it makes it worse.\n \nreply"
    ],
    "link": "https://blog.cloudflare.com/pingora-saving-compute-1-percent-at-a-time/",
    "first_paragraph": ""
  },
  {
    "title": "Google Illuminate: Books and papers turned into audio (illuminate.google.com)",
    "points": 318,
    "submitter": "leblancfg",
    "submit_time": "2024-09-10T16:22:13.000000Z",
    "num_comments": 144,
    "comments_url": "https://news.ycombinator.com/item?id=41502510",
    "comments": [
      "Great idea.\nI wonder how long until we'd see a lot of \"autogenerated\" podcasts with syndicated advertising inside spamming the podcast space.Like with robovoiced videos on YT reading some scraped content.\n \nreply",
      "Wondercraft have been offering this service for a while, and produce some of their own auto-generated podcasts including the Hacker News Recap which does an excellent job of summarizing the most engaged posts on HN.\nhttps://www.wondercraft.ai/our-podcasts\n \nreply",
      "This is a bit meta for me. A year ago a website was posted on here HN which allowed you to visit a random website with an /ideas page. For some reason it would always land me on the same website, which outlined something close to this. The idea was something like an RSS feed that would summarize all the entries in the feed for the day/weekin the form of a podcast.I wonder if that was inspiration for Wondercraft.\n \nreply",
      "Uncanny, maybe ;-) It should be easy to ingest an RSS feed into your personal RAG system's vector database. Then set up speech to text and text to speech for your PrivateGPT so you can then ask it to create a podcast just for you\n \nreply",
      "also for papers there is https://papersread.ai/ which does not get nearly enough attention imo (the reading is meh, but the curation is ace)\n \nreply",
      "Would you listen to an auto-generated podcast? Seems like removing the humans from the equation kind of defeats the purpose.\n \nreply",
      "I consider myself a heavy podcast user. I don\u2019t listen to radio or any music. Mostly podcasts and the odd audio book.I listen to a ton of podcasts in different niches: Theo Von, all in pod, masters of scale, the daily, some true crime stuff, etcI found the AI briefing room which is a quick summary done by and read by ai. It\u2019s not as good as a human but I\u2019m completely used to it now.I am thinking of summarizing the business related podcasts I listen to for myself so I can consume more content in less time.I wish all podcasts had a shorter ai version\n \nreply",
      "I subscribed to the audio version of 'The Diff' by Byrne Hobart, and it's auto-generated. There's a few obvious tells, like when describing money - '$3' would be translated to 'dollar three'. But there's also occasional verbal nuances that I wouldn't expect from a TTS system. I don't love it, but I find his thoughts compelling enough to deal with it.\n \nreply",
      "I listen to a number of podcasts which are reading books, stories, literature, etc.  Having a professional actor read a text has appeal (e.g., Selected Shorts), but many are less-than-professional.  A sufficiently-competent automated text-to-speech would fit at least some roles.There are a few podcasts for which I'd have greater interest if the narration were by someone other than the current host....There are also services such as the National Library for the Blind (UK) and BARD (US) which provide books, including a large number of audiobooks, for the blind.  Automated text-to-speech would make a vastly larger library available, particularly of very recent publications, niche publications, and long-since-out-of-print books.  Such services do take requests, but tend to focus on works published within the past five years.\n \nreply",
      "What are your favourites? A podcast curating great short stories sounds interesting, done well\n \nreply"
    ],
    "link": "https://illuminate.google.com/home",
    "first_paragraph": ""
  },
  {
    "title": "Tutorial on diffusion models for imaging and vision (arxiv.org)",
    "points": 85,
    "submitter": "Anon84",
    "submit_time": "2024-09-10T19:59:39.000000Z",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=41504885",
    "comments": [
      "Does something similar exist for LLM/GPT?Edit to add: I'm mostly interested in this aspect:\"The target audience of this tutorial includes [those] who are interested in [...] applying these models to solve other problems.\"\n \nreply",
      "Andrej Karpathy has a youtube playlist:https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThs...He is building new learning materials under his new company \"Eureka Labs\":https://eurekalabs.aiSebastian Raschka's book \"Build a Large Language Model (From Scratch) just released:https://www.manning.com/books/build-a-large-language-model-f...All of these resources are excellent.\n \nreply",
      "Andrej Karpathy has very good video tutorials on how to write your own GPT: https://www.youtube.com/watch?v=kCc8FmEb1nY\n \nreply",
      "This is excellent\n \nreply",
      "A very useful guide about how diffusion models work and implementation: https://keras.io/examples/generative/ddim/I find the explanation in this article very intuitive.\n \nreply",
      "> see tutorial on diffusion\n> get excited\n> it's all math in latex\n> despair\n \nreply",
      "Latex is great in this case, because the equations are all written out clearly.If you want to understand diffusion, it's a little difficult to avoid math.\n \nreply",
      "Maybe check out the fast ai course. Jeremy Howard has a way of explaining stuff.\n \nreply",
      "the math is learnable and with gpt nowadays, extremely so\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2403.18103",
    "first_paragraph": "This week: the arXiv Accessibility ForumHelp | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Lottery Simulator (2023) (perthirtysix.com)",
    "points": 82,
    "submitter": "airstrike",
    "submit_time": "2024-09-10T21:09:04.000000Z",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=41505593",
    "comments": [
      "Hi! I made this tool. I saw it had way more traffic than usual and then realized it was from HN, very cool!Would love to hear any feedback. I've been super interested in how well-designed web apps and visualizations can communicate things like probability, which I think is very hard to intuit for many of us.The most surprising thing I learned from the tool was just how bad your payouts usually were even if you cut the pool of numbers to pick from in half (by using the \"Custom\" option).\n \nreply",
      "I would very much like to see an even faster \"turbo\" option because even though the current max speed of 1,000 tickets a second really drives home the point of how long it would take to actually win, I still want to see the simulation hit the jackpot a few times.\n \nreply",
      "I noticed that when you select pick random numbers, it only picks it once. Can we run the simulation where it picks new numbers every time? I would love to see if that would make an impact on the odds.\n \nreply",
      ">I would love to see if that would make an impact on the odds.It won't make an impact on the odds of your tickets coming up as winners, unless they have a bug in their simulation. In the real world the probability of single versus multiple jackpot winners might vary with number choices, but they've already said they're assuming a single jackpot winner.\n \nreply",
      "wow, it's really good and the rest of your site is even better\n \nreply",
      "I used to work at a lotto counter in my towns supermarket. When I started I noticed alot of older regular buyers, a weekly lotto purchase like the daily newspaper. However, as the younger generation started bringing in kids I didn't see this habit, instead just an occasional purchase for a birthday gift or rolling the dice because the jackpots gotten big enough (funnily enough the time when the chance of winning is actually lowest).Overall I would consider lotto small next to the scratch cards (our countries version at least). I have never seen a more predatory marketing strategy, and completely swept under the rug next to lotto being berated with anti-gambling campaigning. To be fair, lotto is bad, but scratch cards are much, much worse.A memory that stuck for me was a customer blowing well over $100 bucks on scratchcards over 20 minutes, just pulling over and over, then getting card declined at the grocery checkouts.\n \nreply",
      "> funnily enough the time when the chance of winning is actually lowestNot really?The odds of winning are the same regardless, because you need to match every number to get a jackpot. Really, there is just an increased chance of splitting a jackpot with another person when the prize gets really large, since more tickets are generally sold. But I imagine EV of a lottery ticket with a $1B jackpot is still higher than the same lottery ticket when the jackpot is $100M.\n \nreply",
      "There\u2019s a balance between jackpot size and a given drawing\u2019s popularity for sure.There are also bad number choices and good number choices. 1,2,3,4,5,6 is a terrible selection, for example. Not because it is somehow \u201cless random\u201d, but because you\u2019re guaranteed to be splitting that jackpot with a 1,000 other nerds who were trying to prove a point!To a lesser degree, choosing numbers under 31, or under 12, will put you in a collision space with other players who like to choose birthdays.Just use the random pick and don\u2019t think about it.  If you do win the jackpot, you have higher odds of being the only one.\n \nreply",
      "> 1,2,3,4,5,6 is a terrible selection, for example. Not because it is somehow \u201cless random\u201d, but because you\u2019re guaranteed to be splitting that jackpot with a 1,000 other nerds who were trying to prove a point!Uh... so at first I saw your point, but if your odds of winning never actually change, how is not winning better than splitting a jackpot?\n \nreply",
      "I guess if you only play one drawing, you\u2019re right. Winning is always better than losing.But if you play the lottery week after week, year after year\u2014and you always play the same numbers\u2014then you\u2019re ensuring a mediocre prize should you actually get the jackpot.Playing the lottery is not a mathematically sound decision in any case, but there\u2019s no reason to make it even worse by chopping your potential jackpot winnings down by over 99%\n \nreply"
    ],
    "link": "https://perthirtysix.com/tool/lottery-simulator",
    "first_paragraph": "Interactively explore lottery probabilities and simulate thousands of tickets in secondsShri Khalpada Every so often, a lottery jackpot will get so high that I'll hear about it on the news or from a friend. When this happens, I immediate start wondering about two things: what I would do with hundreds of millions of dollars and what the odds of winning really are.  While major lotteries publish some of this information, I wanted to build something that would make it easier to play around with the data in a more exploratory way. With that, here is the PerThirtySix Lottery Simulator!  This tool is broken up into two sections: Setup and Simulation. The Setup section lets explore probabilities for an existing American lottery or for your own lottery with custom rules. The Simulation section lets you pick some numbers and play up to thousands of tickets per second, and visualizes the returns for you. Note that this tool makes some simplifying assumptions, like that there's only one jackpot w"
  },
  {
    "title": "Another police raid in Germany (torproject.org)",
    "points": 287,
    "submitter": "costco",
    "submit_time": "2024-09-10T20:12:49.000000Z",
    "num_comments": 160,
    "comments_url": "https://news.ycombinator.com/item?id=41505009",
    "comments": [
      "Part of the reason I sadly stopped running any exit nodes was law enforcement harassment.I ran a few exits for about about ~5 years. In those 5 years, my hosting provider (DigitalOcean) received 3 subpoenas for my account information.The first two were random. The 1st one was someone sent a bomb threat email to a university. The 2nd one was someone sending a phishing email.The last and final subpoena was the most serious one. Some nation-state hackers from Qatar had ended up using my exit IP to break into some email accounts belonging to people they were interested in and spied upon them and stole some info.Thankfully both the Tor Project and the EFF were able to help me pro-bono. The EFF lawyer that was assigned to me helped me fight this subpoena but ultimately we had to turn over my account information to the DOJ + I had to give an affidavit stating that I was simply just an operator and nothing on the server in question would be useful to their investigation (by design).The stress of having to deal with law enforcement, lawyers, and having to entertain the possibility of having my home raided over something so silly ultimately led to me finally shutting down my exits.Even though I had all of my exits using a reduced exit policy and I would blacklist known malicious IPs and c2/malware infra from being able to use it, I was still a target.I feel law enforcement realizes this is a big weakness they can target since a lot of Tor exit operators are individuals with not a lot of resources to fight them. They can use the legal system to scare operators into shutting down.I one day hope to resume running exits as I find it rewarding to be able to help people from around the world in a small way.\n \nreply",
      "Is something like this unexpected? I personally never ever thought so (which is the reason why I never ever even considered running a TOR exit node).As much as I can respect the idealism about privacy and liberty etc..., I could not ignore the fact that any \"really!!!\" bad actor could use the same infrastructure to avoid investigation/prosecution, therefore I did not want to provide indirectly any help.> I feel law enforcement realizes this is a big weakness they can target since a lot of Tor exit operators are individuals with not a lot of resources to fight them. They can use the legal system to scare operators into shutting down.On one hand I admit that that might be the case, on the other hand even government organizations/departments/agencies can be \"local\" and scattered (e.g. similar IT departments for each \"canton\" in Switzerland) and not have huge amounts of resources/knowledge to track/identify perpetrators of all ongoing (sophisticated?) IT crimes => somebody somewhere might see the same IP involved in a lot of \"bad\" stuff not realizing it's just a TOR node.I hate the current general trend pushing a position of an either absolute \"yes/no\" for any theme, including this one (of encryption for privacy/etc vs. crime).In my opinion it's obvious that the current situation of solutions is in general bad: too much pressure on services that provide privacy because it's too easy for crime to misuse them :o(\n \nreply",
      "> As much as I can respect the idealism about privacy and liberty etc..., I could not ignore the fact that any \"really!!!\" bad actor could use the same infrastructure to avoid investigation/prosecution, therefore I did not want to provide indirectly any help.Well, what would be considered a \"really!!!\" bad actor for some might be a hero for others. Just as an example, depending on which side of the Israel/Palestine conflict you are on, either side using your node for military intelligence might be an use worth fighting for or terrible abuse.In the end, this really comes down to whether you value freedom or state protection more; either of which can be abused by rogue actors or a malicious state, respectively. There is no win-win-solution, unfortunately.\n \nreply",
      "> Well, what would be considered a \"really!!!\" bad actor for some might be a hero for others. Just as an example, depending on which side of the Israel/Palestine conflict you are on, either side using your node for military intelligence might be an use worth fighting for or terrible abuse.Stepping back though neither side in that conflict needs Tor. They both have numerous supporters in other countries where that support is legal. They can send and receive information through trusted outside supporters including some outside governments. They just need secure communication channels to a few representatives among those supporters rather than something is general as Tor.\n \nreply",
      "> depending on which side of the Israel/Palestine conflict you are onHere's the thing: I am not on either side of that conflict, or likely any other conflict you could use as an example. There are atrocities committed by both sides. There are victims on both sides. You could argue over who committed the worse atrocities or over who is the biggest victim until your face turns blue, it isn't going to end the cycle of violence as long as there are people facilitating that violence.And no, I am not naive. I know there are people out there who care nothing about causes beyond their own self interest and who care nothing about their victims. I realize that these people are impossible to combat without the innocent coming in harms way. Yet the moment we fail to be ashamed of the harm we cause in the name of the cause, the moment we fail to acknowledge who is being harmed in the name of the cause, is the moment we become no better than them.\n \nreply",
      "There's enough truly bad actors out there, not everything is shades of gray. Cartels, North Korea, ISIS, etc.\n \nreply",
      "\u2018Truly bad\u2019 still relies on the perspective of the participant though. Parents point is that \u2018bad\u2019 is a matter of perspective, and that right or wrong, at lease some cartel/nk/isis operatives believe their actions are justified for some greater good, Palestine/Israel opinions and belief are obviously a more easy to understand perspective, but the point still stands.\n \nreply",
      "Yes. And running a Tor exit node means helping these people in addition to any in the morally gray area that you personally consider evil.If you look at that and still come to the conclusion that the people you're helping are worth the cost of also helping commit atrocities, that's a decision you can make. But an occasional subpoena related to a bomb threat or similar is a good and necessary reminder of what it is that you chose to do.\n \nreply",
      "I'm as much of a supporter of encryption as anyone, but I also accept that true effective encryption enables some pretty horrible things.One of those \"better look your meat in the eyes, before you murder and eat it\" idealism-meets-realism moments.On the whole, though, I think even with perfect encryption the remaining physical traces of illegality are sufficient for law enforcement purposes (granted: if more difficult).\n \nreply",
      "I don't think the analogies to encryption are fair because a Tor exit node is far more active in shielding criminals than the inventor of a new cryptography scheme is. The inventor merely puts out an idea that can be used for good or bad. The exit node operator is actively paying on an ongoing basis to shuttle CSAM and bomb threats.The exit node operator is also shuttling other content, so it's not wholly evil and on the balance someone might decide it's still worth it, but it's still a much less obvious ethical call than simply designing a piece of tech.\n \nreply"
    ],
    "link": "https://forum.torproject.org/t/tor-relays-artikel-5-e-v-another-police-raid-in-germany-general-assembly-on-sep-21st-2024/14533",
    "first_paragraph": "Hello to all list-reading entities!On Aug 16th 2024 German police considered it once again appropriate to raid the home&office at the registered address of our organization. The first raid was 2017. There are obviously still people working in German law enforcement today, who think that harassing a node-operator NGO would somehow lead to the de-anonymization of individual tor users. At least that is what they claim in the paperwork.As with the first time, the raid team was fortunately a bit better educated and acted significantly more reasonable than the non-technical people applying for the raid and the judge signing it off. So again, no hardware was seized. Apart from one burnt (middle relay) node and some billing paperwork for the exit node this was all about, the team left the house after one and a half hours with mostly empty hands. We intend to legally challenge the search warrant to make sure that this does not happen again (but this is not what this email here is about).These w"
  },
  {
    "title": "Rust in illumos (wegmueller.it)",
    "points": 45,
    "submitter": "vermaden",
    "submit_time": "2024-09-10T21:15:24.000000Z",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=41505665",
    "comments": [
      "This article really comes at some of the crux of packaging pains for many languages. The \"distro ships the software\" idea is something so many modern language toolkits are pretty far away from (and, as someone constantly burned by Debian packaging choices, something I'm pretty happy with as well). But without a good answer, there's going to be frustration.When distros are charging themselves with things like security, shared libraries do become a bit load bearing. And for users, the idea that you update some lib once instead of \"number of software vendor\" times is tempting! But as a software developer, I really really enjoy how I can ship a thing with exactly a certain set of versions, so it's almost an anti-feature to have a distro swap out functionality out from under me.Of course there can be balances and degrees to this. But a part of me feels like the general trend of software packaging is leaning towards \"you bundle one thing at a time\", away from \"you have a system running N things\", and in that model I don't know where distro packagers are (at least for server software).\n \nreply",
      "I think it would be pretty natural for a distro to run it's own crates.io/PyPI/NPM mirror to build packages against, and have a unified set of library versions for the entire OS that way. Maybe not even a server, maybe just a giant Git repo or whatever, filtered down to the set of packages they actually use. Have any of them tried this?\n \nreply",
      "I\u2019m not aware of any that have; this would require them to become experts in running parallel infra, in many languages and with varied setups, and would mean that they\u2019re not longer self-contained. That feels antithetical to their goals to me at least.\n \nreply",
      "> The development model of illumos is different from Linux and thus there are no Rust drivers in upstream illumos yet. But that is to be expected for new things. In our model, we take the time to mature new tech in a fork, and for rust, the Oxide fork has taken that role. In there, we have several drivers for the Oxide Networking stack that are in rust. Based on that some experience could be gained.Soft forks are also good, but doesn't illumos have a stable driver ABI, such that you could just make your drivers completely independently? I thought that was how it had ex. Nvidia drivers ( https://docs.openindiana.org/dev/graphics-stack/#nvidia )\n \nreply",
      "Even if there is a stable ABI driver to the point where upstream is oblivious of any Rust stuff going on inside drivers, that doesn't solve the problem of fragmentation amongst forks (assuming upstreaming to Illumos is a goal).\n \nreply",
      "I'm part of the illumos core team and I'm quite keen to use Rust in the base of illumos, FWIW.  There several contexts in which we could make good use of it, and the primary challenges in most cases is either one of release engineering or the resultant binary sizes.  I'm confident we'll be able to work them out, it'll just take more exploration and effort!The rough areas where I think things would be useful, and probably also roughly the order in which I would seek to do them:* Rust in the tools we use to build the software.  We have a fair amount of Perl and Python and shell script that goes into doing things like making sure the build products are correctly formed, preparing things for packaging, diffing the binary artefacts from two different builds, etc.  It would be pretty easy to use regular Cargo-driven Rust development for these tools, to the extent that they don't represent shipped artefacts.* Rust to make C-compatible shared libraries.  We ship a lot of libraries in the base system, and I could totally see redoing some of the parts that are harder to get right (e.g., things that poke at cryptographic keys, or do a lot of string parsing, or complex maths!) in Rust.  I suspect we would _not_ want to use Cargo for these bits, and probably try to minimise the dependencies and keep tight control on the size of the output binaries etc.* Rust to make kernel modules.  Kernel modules are pretty similar to C shared libraries, in that we expect them to have few dependencies and probably not be built through Cargo using crates.io and so on.* Rust to make executable programs like daemons and command-line commands.  I think here the temptation to use more dependencies will increase, and so this will be the hardest thing to figure out.The other thing beyond those challenges is that we want the build to work completely offline, _and_ we don't want to needlessly unpack and \"vendor\" (to use the vernacular) a lot of external files.  So we'd probably be looking at using some of the facilities Cargo is growing to use an offline local clone of parts of a repository, and some way to reliably populate that while not inhibiting the ease of development, etc.Nothing insurmountable, just a lot of effort, like most things that are worth doing!\n \nreply",
      "Have you explored building with Bazel? What you describe as a problem is roughly what Bazel solves: Polyglot complex builds from fully vendored deps.Just pointing this out because I had a fair share of issues with Cargo and ultimately moved to Bazel and a bit later to BuildBuddy as CI. Since then my builds are reliable, run a lot faster and even stuff like cross compilation in a cluster works flawlessly.Obviously there is some complexity implied when moving to Bazel, but the bigger question is whether the  capabilities of your current build solution keep up with the complexity of your requirements?\n \nreply",
      "(Not Josh, not involved with illumos, do work at Oxide)For at least one project at Oxide we use buck2, which is conceptually in a similar place. I\u2019d like to use it more but am still too new to wield it effectively. In general I would love to see more \u201chere\u2019s how to move to buck/bazel when you outgrow cargo) content.\n \nreply",
      "Here you go!https://github.com/bazelbuild/examples/tree/main/rust-exampl...I wrote all of those examples and contributed them back to Bazel because I've been there...Personally, I prefer the Bazel ecosystem by a wide margin over buck2. By technology alone, buck2 is better, but as my requirements were growing, I needed a lot more mature rule sets such as rules OCI to build and publish container images without Docker and buck2 simply doesn't have the ecosystem available to support complex builds beyond a certain level. It may get there one day.\n \nreply",
      "Thanks!I fully agree with the ecosystem comments; I\u2019m just a Buck fan because it\u2019s in Rust and I like the \u201cno built in rules\u201d concept, but it\u2019s true that it\u2019s much younger and seemingly less widely used. Regardless I should spend some time with Bazel."
    ],
    "link": "https://wegmueller.it/blog/posts/2024-09-02-rust-on-illumos",
    "first_paragraph": "With the recent rust in Linux events in the last couple of days, It\u2019s a good time to write up Rust in illumos. Both to spread the word a bit and also to set expectations for both sides (Rust and illumos/OpenIndiana devs) what is currently possible and what work would need to be invested to make things smooth. And also to let the rust community know about what illumos people were talking about. What most of the talk currently is about, are the technical details. But we must not leave the social aspects out of it. Software distributions are not made by lone walkers but by groups of people. Bringing in a new language means facilitating change. And that means there are more topics to discuss than just API design. We are talking about impacts on the whole software lifecycle.Looking at the things people like Asahi Lina want to address inside the Linux Kernel with the Rust bindings and how she describes the issues with Locking I get the feeling something with DRM is not consistent. Looking in"
  },
  {
    "title": "Satellites Spotting Aircraft (marksblogg.com)",
    "points": 136,
    "submitter": "marklit",
    "submit_time": "2024-09-10T05:15:53.000000Z",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=41497377",
    "comments": [
      "A little nitpick about:  The number of looks correlates with a higher resolution.\n\nYes and no. When you task an image, you usually (as is the case with Umbra) specify your desired ground resolution, eg. 25, 50, 100 cm, etc. There are two dimensions in a SAR image: range and azimuth. Range resolution is determined by the SAR system bandwidth. Azimuth resolution is determined by the integration angle (the angle formed between your target and your satellite from start to end of the collection).Let's assume you want a 50 cm image. Your range resolution will be equal to that and, in a 1-look image, your native azimuth resolution will also be 50 cm. What happens when you request a multi-looked image, is that the satellite will collect data over your target for a longer amount of time (and thus over a greater angle diversity). Range resolution will not change; however, in the natural (\"native\") image, you get asymmetrical pixels: taking the same target resolution of 50 cm, a 2-looks image will have a 25 cm azimuth resolution. For 3-looks, ~16 cm. And so on.What then happens during the processing of derived products (eg. GEC) is that the pixels are squared: to do that, you have to average out the pixels in the azimuth dimension. This greatly improves what is called the radiometric resolution (ie. how much information a pixel contains), by cancelling out the speckle and averaging the noise. But for all intents and purposes, on a multi-looked image (which is what the GEC products that you use are), spatial resolution remains the same, square pixel.[SAR nerds here: I am not mentioning the slant-range-to-ground-range process, and I am also ignoring the resolution vs. sampling distinction for simplicity]\n \nreply",
      "Quick geospatial note that's important for accurately geolocating these images:You need a DEM to use RPCs for geolocation.  Running things through gdalwarp as was done here will assume no terrain and 0 elevation.  That will lead to significant mislocations anytime it's not flat and at sea level, especially given the off-nadir view angle of the data used here.In other words:  gdalwarp \\\n     -t_srs \"EPSG:4326\" \\\n     2024-05-25-15-37-54_UMBRA-06_GEC.tif \\\n     warped.tif\n\nShould be:  gdalwarp \\\n     -to RPC_DEM=some_dem.tif \\\n     -rpc \\\n     -t_srs \"EPSG:4326\" \\\n     2024-05-25-15-37-54_UMBRA-06_GEC.tif \\\n     warped.tif\n\nIf you don't want to use a DEM for orthographic corrections, then you should at least include a constant elevation in meters of the scene with RPC_HEIGHT.  Otherwise things can be shifted kilometers from where the image actually is.\n \nreply",
      "> Umbra has an open data programme where they share SAR imagery from 500+ locations around the worldI think they're referring to this: https://umbra.space/open-data/ (warning: most files are absolutely ginormous)\n \nreply",
      "Is there a mapping from, say, a geo location to a list of Umbra files which cover that location? I'd hate to download 42TB of data and then have to grep through it :-D\n \nreply",
      "Man there\u2019s everything to love about this. A novel free dataset, complete example code, clear description of how to get it up and running\u2014the ideal blog post IMHO. Delighted to learn about it.\n \nreply",
      "Related, they are also visible while flying:\nhttps://medium.com/google-earth/planespotting-465ee081c168(not SAR in this case)\n \nreply",
      "> Below is Umbra's image of the same location. Though it was taken on a different day and some aircraft might have been moved around, you can see that a lot of the aircraft in the bottom left are barely visible unless you zoom in very closely and pay attention to artefacts that give away a large man-made object is present.Bad example, because the radar image simply shows a different situation with all but two of the aircraft not present. The two that are present are easy enough to spot.Here's another image with 5 aircraft present (including the two from the radar image). It's rotated, the aircraft are in the top left: \nhttps://x.com/___Harald___/status/1825362047061971309/photo/...\n \nreply",
      "I think it successfully got the point across that visual vs SAR have different benefits.\n \nreply",
      "Would the F-35 actually show up on SAR or does the radar absorbent material distort the image somehow?\n \nreply",
      "In the blog there's a video of what looks like cars moving around, but the lighting is constantly changing. How does that work?It looks like a timelapse but then there are cars doing normal car things.https://www.youtube.com/watch?v=cwDjJqtx_og\n \nreply"
    ],
    "link": "https://tech.marksblogg.com/ai-sar-satellites-umbra-aircraft-detection.html",
    "first_paragraph": "I have 15 years of consulting & hands-on build experience with clients in the UK, USA, Sweden, Ireland & Germany. Past clients include Bank of America Merrill Lynch, Blackberry, Bloomberg, British Telecom, Ford, Google, ITV, LeoVegas, News UK, Pizza Hut, Royal Mail, T-Mobile, Williams Formula 1, Wise & UBS. I hold both a Canadian and a British passport. My CV, Twitter & LinkedIn.\n      \nHome\n        | Benchmarks\n\n        | Categories\n\n            | Atom Feed\nPosted on Mon 09 September 2024  under Artificial IntelligenceUmbra Space is a 9-year-old manufacturer and operator of a Synthetic Aperture Radar (SAR) satellite fleet. These satellites can see through clouds, smoke, rain, snow and certain types of camouflage attempting to cover the ground below. SAR can capture images day or night at resolutions as fine as 16cm. SpaceX launched Umbra's first satellite in 2021 and has a total of ten in orbit at the moment.SAR collects images via radar waves rather than optically. The resolution of "
  },
  {
    "title": "What is the best pointer tagging method? (coredumped.dev)",
    "points": 26,
    "submitter": "celeritascelery",
    "submit_time": "2024-09-09T13:33:15.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://coredumped.dev/2024/09/09/what-is-the-best-pointer-tagging-method/",
    "first_paragraph": "\n         A core dump of ideas and projects \n      In this post, we are going to take a deep dive into pointer tagging, where metadata is encoded into a word-sized pointer. Doing so allows us to keep a compact representation that can be passed around in machine registers. This is very common in implementing dynamic programming languages, but can really be used anywhere that additional runtime information is needed about a pointer. We will look at a handful of different ways these pointers can be encoded and see how the compiler can optimize them for different hardware. Because untagging a pointer is usually just a few instructions, it normally won\u2019t show up in a traditional profiler. But billions of these operations can add up to make a difference in the total runtime of a program.We will be testing 4 different types of tagged pointers here:We will be testing against a fat pointer for the baseline. This will use two words, one for the tag and one for the pointer. This is what you get w"
  },
  {
    "title": "Among the Moss Piglets: The First Image of a Tardigrade (1773) (publicdomainreview.org)",
    "points": 32,
    "submitter": "ljf",
    "submit_time": "2024-09-10T21:10:52.000000Z",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=41505622",
    "comments": [
      "Legend has it that tardigrade was the one they sent into space\n \nreply",
      "Why don't we send tardigrades and other extremophiles into space to colonize possible life-sustaining planets and moons?\n \nreply",
      "They can go dormant in extreme conditions they can\u2019t thrive in such conditions. It\u2019s a bit of a myth with these. They need similar conditions to multiply as all other life. If you put them temporarily in an extreme condition they can go dormant and come back when conditions are better.FWIW we trade so much material with outer space (super volcanos etc) that if life could colonize space that easily it would have done so billions of years ago.\n \nreply",
      "I think the general idea is not to contaminate planets with possible life so we can eventually study what completely different evolution circumstances produces.\n \nreply"
    ],
    "link": "https://publicdomainreview.org/collection/tardigrade/",
    "first_paragraph": "Search The Public Domain ReviewThe tardigrade\u2019s tiny size belies both its astounding physical resilience and its charisma. Also known as water bears or moss piglets, they can survive extreme temperatures and pressures, withstand radiation levels that would kill most organisms, and reanimate after long periods of desiccation or oxygen deprivation. They can even handle being in outer space without too much trouble \u2014 impressive for creatures that are roughly the size of a grain of sand. As a result, the 1300 known species of tardigrades are found everywhere on Earth: from the deep seas, to rainforests, to Antarctica. The first recorded observations of these remarkable microfauna were published in 1773 by the German pastor Johann August Ephraim Goeze. Because they looked like tiny bears to his eyes, he called these strange creatures kleiner Wasserb\u00e4r, \u201clittle water bears\u201d (the name \u201ctardigrade\u201d came later in 1777, when an Italian biologist highlighted their slow movements). Goeze\u2019s observa"
  },
  {
    "title": "Apple must pay 13B euros in back taxes, EU's top court rules (cnbc.com)",
    "points": 441,
    "submitter": "kklisura",
    "submit_time": "2024-09-10T08:03:54.000000Z",
    "num_comments": 517,
    "comments_url": "https://news.ycombinator.com/item?id=41498358",
    "comments": [
      "For non-EU readers, note that taxation is explicitly not a competency of the EU (i.e. Ireland can set its tax levels to whatever it wants). The only thing in question here is whether it was applying the same taxation rules to all companies, as granting special exceptions to certain companies could be viewed as state aid (which is not allowed). Ireland claimed it wasn't, the current (over-)ruling says otherwise. This case is also specific to tax rules from many years back. AFAIK the rules have subsequently been tightened and the exemption no longer exists.\n \nreply",
      "I think you make it seem like EU doesn't care at all about what member states do in regards to taxation but there's many limitations to what can be done by any member state in order to harmonize and prevent corruption etc. This in practice makes the EU have a lot of say in regards to taxation. Moreover the EU has special rules to limit moving funds to jurisdictions that have taxes that are deemed too low (read tax havens) - this directly implies no member state has agency to lower their own taxes as much.Here's some example limitations: https://eur-lex.europa.eu/EN/legal-content/summary/tackling-...I focused on direct taxation, but in indirect taxation I think there's even more examples.\n \nreply",
      "> I think you make it seem like EU doesn't care at all about what member states do in regards to taxationDid GP change the original text? The closest match I can find to your assertion is where they said \"or non-EU readers, note that taxation is explicitly not a competency of the EU\"\n \nreply",
      "Specifically in Ireland, corporate taxes were being lowered from late 1980s until 2003, in a series of agreements with the EU regulators. It's not like Ireland lowered the taxes in a sneaky scheme, or grandfathered-in an abnormally low rate.\n \nreply",
      "Just to be clear - I don't think many people have (much) of a problem with ireland's \"headline\" 12.5% CT rate.The problem is the selective tax rates that Ireland gave to many multinationals, often as low as 0.005% (effectively in return for ensuring x amount of jobs were created in Ireland). I think these are really very much sneaky schemes.\n \nreply",
      "Corruption with a twist: the government is the one who got the kickback.\n \nreply",
      "At the same time it's clear that Ireland has been \"gaming the system\" here, and the proof is the huge delta between the effective tax rates between member nations we're seeing in the judgement.  I don't know that there's much of a moral or principled argument to be made here, every system gets gamed, and the European Commission is another such system.  And Ireland absolutely agreed to be bound in that game as a price of joining the EU in the first place.Basically, from the other side of the ocean I don't see much to care about here beyond the microtactics of business development decisions.  Let Europe sort out its business on its own.\n \nreply",
      "Punishing Ireland for gaming the system by paying Ireland 13 billion hardly makes it seem like the EU is super concerned about Ireland's transgressions.\n \nreply",
      "Apple having to pay those 13 B means that companies won't be as eager to have a headquarter in Ireland as they have been in the past. They could move somewhere else in the EU. That's a damage for Ireland and that's why Ireland sided with Apple for all this litigation.\n \nreply",
      "Sure but the taxes are only part of the equation. Native english speakers familiar to US tech giants common law system. Large number of skilled workers. Flexible immigration system.\n \nreply"
    ],
    "link": "https://www.cnbc.com/2024/09/10/apple-loses-eu-court-battle-over-13-billion-euro-tax-bill-in-ireland.html",
    "first_paragraph": "Credit CardsLoansBankingMortgagesInsuranceCredit MonitoringPersonal FinanceSmall BusinessTaxesHelp for Low Credit ScoresInvestingSELECTAll Credit CardsFind the Credit Card for YouBest Credit CardsBest Rewards Credit CardsBest Travel Credit CardsBest 0% APR Credit CardsBest Balance Transfer Credit CardsBest Cash Back Credit CardsBest Credit Card Welcome BonusesBest Credit Cards to Build CreditSELECTAll LoansFind the Best Personal Loan for YouBest Personal LoansBest Debt Consolidation LoansBest Loans to Refinance Credit Card DebtBest Loans with Fast FundingBest Small Personal LoansBest Large Personal LoansBest Personal Loans to Apply OnlineBest Student Loan RefinanceSELECTAll BankingFind the Savings Account for YouBest High Yield Savings AccountsBest Big Bank Savings AccountsBest Big Bank Checking AccountsBest No Fee Checking AccountsNo Overdraft Fee Checking AccountsBest Checking Account BonusesBest Money Market AccountsBest CDsBest Credit UnionsSELECTAll MortgagesBest MortgagesBest Mor"
  },
  {
    "title": "Pixhell Attack: Leaking Info from Air-Gap Computers via 'Singing Pixels' (arxiv.org)",
    "points": 44,
    "submitter": "gnabgib",
    "submit_time": "2024-09-10T19:34:11.000000Z",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=41504631",
    "comments": [
      "My uncle described the air gapped facility he worked in\u2026 when they said no EM out, they meant nothing in or out except humans and filtered air. It was behind dual interlocking nuclear blast doors and concrete. Even the water was sourced and recycled on site to prevent documents or capsules exfiltration via the sewer.\n \nreply",
      "All sorts of practical questions.Can you bring in a lunch (is that a Coke bottle or a secret camera?)? Are there trash bins? If there is water, does that mean there are bathrooms (who does the restocking?)? Is there coffee?! Who/how do you get data into the network? Who/how do you get data out of the network? Can you bring in printed reference materials from a slightly less secure facility?Bottom line: probably a huge pain in the butt if you have to work like that.\n \nreply",
      "Honestly I\u2019ve never asked him, this was me listening as a 12 year old at the dinner table as he ranted about another search as he went into work. Now I have questions haha.\n \nreply",
      "if he sometimes got searched when he went into work then he was probably permitted to bring things in such as lunch\n \nreply",
      "I would think that a much more likely exfiltration method (assuming a compromised employee) would be via a capsule in the metaphorical \"prison wallet\" rather than the sewer.\n \nreply",
      "For those unindoctrinated with the underlying phenomenon being exploited, this demo[1] was shared almost a decade ago.Also, undiscussed mitigation techniques[2] relevant to this general class of nuisance that circuit designers may find of value.[1] https://news.ycombinator.com/item?id=8862689[2] https://news.ycombinator.com/item?id=41505772\n \nreply",
      "That just blew me away! I didn't think I was going to hear anything, but yeah, immediately it gave an almost pulse-width modulated high pitch tone. I'm not surprised, but it is also awesome. I'm so many years old yet I can still hear the hum from CRT's, but I'd say that tone is much higher frequency.\n \nreply",
      "Yeah, this is absolutely WILD. You can definitely hear it... wow.\n \nreply",
      "Heed the warning on that first link. The pattern can really hurt your eyes.\n \nreply",
      "TEMPEST met Funtenna and had a baby!\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2409.04930",
    "first_paragraph": "This week: the arXiv Accessibility ForumHelp | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Floral formula (wikipedia.org)",
    "points": 90,
    "submitter": "theogravity",
    "submit_time": "2024-09-08T08:49:32.000000Z",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=41479085",
    "comments": [
      "There's a little visualizer tool listed in the External Links section!No clue what I'm doing but the flower diagrams it generates from floral formula parameters are prettyhttps://kvetnidiagram.8u.cz/index_en.php\n \nreply",
      "What was that formula someone maybe tried to patent that would describe all of the things in the universe like flowers?\n \nreply",
      "Basically, this is how you serialize flowers.\n \nreply",
      "DNA is how you serialize flowers!\n \nreply",
      "This made me laugh then ponder. That's exactly it.\n \nreply",
      "This looks a lot like SMILES [1], which is another serialization scheme.[1] https://en.wikipedia.org/wiki/Simplified_Molecular_Input_Lin...\n \nreply",
      "I was just going to post that you could probably make an autoencoder over flowers  and use it as an embedding to probe genomic alterations that tweak the flower generator functions\n \nreply",
      "Is this what all the writing in the Voynich manuscript is then?Reminds me of blazon, another image constructing DSL. I wonder if anyone collects and categorizes such little languages.\n \nreply",
      "I don't need to know anything about this, but I'm glad to know that it exists and gets used.  Very cool.\n \nreply"
    ],
    "link": "https://en.wikipedia.org/wiki/Floral_formula",
    "first_paragraph": "A floral formula is a notation for representing the structure of particular types of flowers. Such notations use numbers, letters and various symbols to convey significant information in a compact form. They may represent the floral form of a particular species, or may be generalized to characterize higher taxa, usually giving ranges of numbers of organs. Floral formulae are one of the two ways of describing flower structure developed during the 19th century, the other being floral diagrams.[2] The format of floral formulae differs according to the tastes of particular authors and periods, yet they tend to convey the same information.[1]\nA floral formula is often used along with a floral diagram.\nFloral formulae were developed at the beginning of the 19th century.[2] The first authors using them were Cassel[3] (1820) who first devised lists of integers to denote numbers of parts in named whorls; and Martius[4] (1828). Grisebach[5] (1854) used 4-integer series to represent the 4 whorls "
  },
  {
    "title": "Git Bash is my preferred Windows shell (ii.com)",
    "points": 103,
    "submitter": "indigodaddy",
    "submit_time": "2024-09-10T19:54:38.000000Z",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=41504832",
    "comments": [
      "Well I took a different route.Always beem 'forced' to use Windows as my workstation by a couple of specialty apps without Linux alternatives that need direct hardware access. But have always used linux on everything else (servers, even my media centre). Because I'm sometimes a late adopter of new tech, until recently I used cygwin as my normal command prompt. There were few downsides to that if you just need access to unix tools, except package management is a bit annoying. Well, discovered the MS Terminal and WSL this year, and happily moved off cygwin. More recently decided to switch over from WS1 to WSL2 but still evaluating the move.Now I have a unix \"more native\" environment AND a linux distro I'm familiar with. I've been accessing the Windows filesystem under /mnt for two decades so this is normal for me, and if filesystem access is slower, it's not a dealbreaker. All my existing scripts were trivial to update. The integration of WSL and VSCode is also pretty cool. It means my vs code environment environment is also working natively in my WSL distro.Overall can understand some lingering negativity about MS efforts in this dept but after years of rejecting all things linux and open source, in general the 180 from the top is much appreciated and it has kept me on Windows a while longer...so mission accomplished microsoft. Just gotta do something about those pesky apps I still need...\n \nreply",
      "As a long time personal and professional Linux user, lately my work has led me to work for companies that are Windows-only. I use git bash as my main shell on Windows. It just works for what I need, and in the rare cases I need powershell I just open that.Most of the windows-based programmers I interact with don't know powershell any better than I do. They use GUI tools for interacting with git and the filesystem.So for me, git bash for git and filesystem interaction is a superpower in these places.I could learn powershell, and I'm pretty sure it's much better than bash for scripting, but I'm almost never really scripting in bash anyway, I use tools like F# for that. Powershell seems fine, but it's less well supported on Linux and I don't really need a shell based language.So in the end, git bash keeps on working and I can focus my learning elsewhere. It's stable, still works the same way 15+ years later, so no need to change.\n \nreply",
      "> I like Git Bash because\u2026> I\u2019m more comfortable with bash commands than CMD or PowerShell commands (because I\u2019ve been using Bourne shell (sh) and friends for more than 30 years).This is the only argument I'm willing to accept, and honestly it's the only argument the writer needs, really: un-learning 30 years of experience to use something else even if the latter is objectively superior, would be a pain in the neck for anyone.That being said I believe that seriously attempting to use the native tools would help the author understand Windows at a more fundamental level.Also, this does raise a few questions, though\u2014if the writer has been using UNIX shells for that long, why are they using Windows at all? As I commented elsewhere, why shoehorn the whole set of UNIX core utilities and binary utilities onto Windows when the latter comes with its own shell, command-line utilities, and management tools? More importantly, the author going by the rest of their posts (assuming it was the same author) doesn't strike me as the type (i.e. normie, for lack of a better word) to use Windows as a daily driver, but they seem to use it all the same. Therefore, why not an OS where these utilities feel more native and more useful, like Linux or one of the BSDs?In contrast to the author I've been using and programming almost nothing but Windows (with a brief stint on Linux in university and now at work, but only for work), and on Windows I use PowerShell and if I really need to, CMD.exe (good riddance). As far as compilation goes, I use Visual Studio with MSVC and Clang-Cl, because they are the only complete development environment for Windows\u2014all the others (MinGW, Cygwin, MSYS2) are incomplete or worse in some way, or make life harder than necessary in some way.> I have experience using Windows PowerShell (powershell.exe), but do not yet have experience using the cross- platform PowerShell Core (pwsh).For the record, functionality between powershell.exe and pwsh.exe is almost identical, with some minor differences[1]. Additionally they differ in the .NET runtime they were written against (.NET Framework 4.8 for powershell.exe, and .NET 7 and later for pwsh.exe).[1]: https://learn.microsoft.com/en-gb/powershell/scripting/whats...\n \nreply",
      "> Also, this does raise a few questions, though\u2014if the writer has been using UNIX shells for that long, why are they using Windows at all? As I commented elsewhere, why shoehorn the whole set of UNIX core utilities and binary utilities onto Windows when the latter comes with its own shell, command-line utilities, and management tools?I'm a Linux user and developer who writes software targeting Windows.Tools like Git Bash and MSYS2 let me write one set of build scripts that work across Windows, macOS and Linux, because all of the tools exist on the three platforms.I don't have a need to understand Windows on a more fundamental level, nor do I want to. I just want to meet my users where they are at, which is Windows/macOS/Linux.\n \nreply",
      "Fair point. I've edited my comment to show my impression that the author uses Windows as a daily driver, rather than merely 'for work', which I think makes the cause for my confusion a little clearer.\n \nreply",
      "> Tools like Git Bash and MSYS2 let me write one set of build scripts that work across Windows, macOS and Linux, because all of the tools exist on the three platforms.Powershell is cross platform too these days, which makes this kind of a moot point.\n \nreply",
      "Powershell on Windows is great because there\u2019s a module for everything.  I\u2019d rather parse structured data.Powershell on Linux isn\u2019t worth is because I end up having to parse everything as text anyway, completely negating any benefit I can come up with.  It doesn\u2019t feel as natural as the *nix tools to me.\n \nreply",
      "For what it's worth, I've had the opposite experience, maybe because I work in a different domain. Personally, I still think using Powershell functions and treating lines as string objects is an improvement over bash and its mini-languages, anyway; and most standard Unix commands have Powershell close equivalents. Some Powershell expressions might be abstruse but so is, say, awk; but when you've learned awk you only know awk; whereas the Powershell technique you used (calculated fields in select-object, for example) is permanently useful. I do spend a lot of my time with various random APIs so Powershell is pretty joyful compared to (say) curl/jq or yq-ish stuff. There was a real adjustment period, of course, getting used to a new shell; but it was the best thing about my experiment with Windows (discovering a new shell that I now use on my Unix-like systems, because I did not end up wanting to adopt Windows).So I'm curious what kinds of things you mean when you say you have to parse everything as text anyway. I suspect you've needed to a lot more of those kinds of tasks than I have.\n \nreply",
      "> Powershell on Linux isn\u2019t worth is because I end up having to parse everything as text anywayDoes it at least integrate with DBus a bit?\n \nreply",
      "Powershell had potential, but it didn't pan out.  It's annoying and very challenging to remember all the one-off flags.With bash, you only need to learn 10 or 20 short commands and a few flag variants, over a gently long period of time.  Then you're all set for 97% of cases likely to be encountered.\n \nreply"
    ],
    "link": "https://www.ii.com/git-bash-is-my-preferred-windows-shell/",
    "first_paragraph": "Ongoing\u00a0\nAccording to\nRepology,\nthe latest\npackaged Git\u00a0for\u00a0Windows\nis\nversion .\nTo keep up with releases of\nGit\u00a0for\u00a0Windows,\nwhich includes\nGit\u00a0Bash\nand\nthe\nMintty terminal\u00a0emulator,\nsee\ngithub.com/git-for-windows/git/releases\nor\ngroups.google.com/g/git-for-windows.2023-November-18\u00a0\nAs of today, this evolving\u2060[1]\narticle\nhas been on\nthe web\nfor\n3\nyears.\ud83d\udd6f\ud83d\udd6f\ud83d\udd6fA shell\nis a layer or interface between you and an operating system.\nThere are a lot of command-\u2060line shells for Windows, including:COMMAND.COM,\nalso known as \u201cthe\u00a0DOS\u00a0Prompt\u201d\n(used in\nWindows\u00a09x\nand earlier)CygwinUWINcmd.exe, also known as CMD\nand \u201cCommand\u00a0Prompt\u201dPowerShell[2]WSL Bash,\nalso\nknown as\n\u201cBash on Ubuntu on Windows\u201d\nand\n\u201cBash on Windows\u2019 Subsystem for\nLinux\u201d\u2060[3]Over the years, I\u2019ve used\nall six of the above\nWindows\ncommand-\u2060line\nshells.\nIn\n2020,\nI\ninstalled\nGit\u00a0for\u00a0Windows\nand\ncan now add\na seventh\nshell to the list of\ncommand-\u2060line\nWindows shells\nI\u2019ve used:Git\u00a0BashBash is\nan acronym for\n\u201cBourne\u00a0again\u00a0shell\u201d\nand it is a\nc"
  },
  {
    "title": "Ask HN: Any hope for removable, rechargable battery standards?",
    "points": 12,
    "submitter": "candiddevmike",
    "submit_time": "2024-09-08T17:23:52.000000Z",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41481689",
    "comments": [
      "It's not a standards problem but a market incentives one. Companies make too much money off expensive shitty proprietary batteries. It's the razor blade model + brand lock-in for powered goods, especially power tools and vacuums and such. They can sell you $5 worth of batteries inside a $80 plastic shell. No company is going to give that up willingly.If you standardized them, it'd be a race to the bottom and China would win.Maybe the EU would have that kind of willpower (like they did with micro usb) but it'd be politically impossible in the US, and every company from computer to power tool manufacturers would lobby against you.\n \nreply",
      "With power tools, it\u2019s more than that. It\u2019s not just that you keep needing to buy their batteries if they die. It\u2019s that once you have the battery for one, you are much more likely to buy their other products when the need arises. That way you either have multiple interchangeable batteries, or you can save money by not needing to get another battery with the main product.\n \nreply",
      "> If you standardized them, it'd be a race to the bottom and China would win.Is China not making most of the world\u2019s batteries at this time? I don\u2019t think this is a reason not to standardize.\n \nreply",
      "The closest we've got nowadays is, IMO, 18650 cells - they're manufactured by a lot of different companies, and you can (usually) put them in anything that expects that size + capacity.\n \nreply",
      "I think many of those power tool batteries are 18650 or 21700 batteries soldered together under the shell. Laptops used to be, but as they've gotten slimmer and more space-conscious, now have mostly moved to custom pouch designs.\n \nreply",
      "I  photo/video lights from Neweer that use a Sony standard battery which may or may not be made by Sony. This seems to be because media creators already have these batteries/chargers. So maybe sometimes the market does give people what they want. It has to be enough to influence the puchasing decision.\n \nreply",
      "There are standardized battery formats in industry. For example professional video. There are also industrial products standardized around consumer battery formats.But for consumer commodities like cordless drills, there are financial incentives toward bespoke interfaces protected with intellectual property laws.\n \nreply",
      "Some of the voltage differences aren't even real.https://www.protoolreviews.com/20v-max-vs-18v-battery-power/\n \nreply",
      "Any hope for removable, replaceable razor blade standards?Any hope for removable, replaceable inkjet cartridge standards?\n \nreply",
      "I\u2019m not sure I see the point with disposable razor blades.  The handles are essentially given away.\n \nreply"
    ],
    "link": "item?id=41481689",
    "first_paragraph": ""
  },
  {
    "title": "Our Git Hash Bug (tmendez.dev)",
    "points": 98,
    "submitter": "robin_reala",
    "submit_time": "2024-09-10T07:51:35.000000Z",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=41498264",
    "comments": [
      "YAML Norway problem strikes again!I wish YAML wasn't so common in Python ecosystem...\n \nreply",
      "Solution: quote values. Like in JSON.\n \nreply",
      "It's not really a solution though because you only notice you need to do it after it triggers a bug.You need a format that doesn't let you make this mistake in the first place, like [everything except YAML].\n \nreply",
      "What's a better alternative? This problem is annoying but to me not more annoying than having to read or write JSON, and TOML is terrible with nested configs. If there were an option with the structure of YAML minus the ridiculous string handling I'd switch to it for sure.\n \nreply",
      "Looked at the sibling comments. Has everybody collectively forgotten that XML exists? This stuff was solved decades ago, XSDs can check types.TOML nesting is indeed a joke. YAML & JSON \"look clean\", but try to match up nesting in a large document without help from text editor highlights, then see how easy it is in XML.XML has universal support everywhere, has first-class tooling for everything that's being re-invented in these other languages, but it's not \"cool\" any more.\n \nreply",
      "Maybe you have worked with a different XML than I but I have only terrible memories of working with XML. Starting from the parser inconsistencies (that even led to security vulnerabilities in Apple, see https://blog.siguza.net/psychicpaper/).On a higher level, the fact that so much different kind of information could exist at each level was nothing but headaches. In YAML, or in JSON, it's pretty straight forward. You have an object, it has children, children have types/values etc.In XML, you have to keep in mind what the tag of the element, what its attributes are, and then what the child elements are, and then whatever the heck CDATA is.I think my fellow posters are looking at the past through nostalgic rose tinted glasses. XML was terrible and I am glad it's not used as widely anymore.\n \nreply",
      "It's not \"cool\" anymore because it's painful to work with despite all the tooling and support\n \nreply",
      "As someone who previously worked in an XML-heavy environment, I would rather have an NFL linebacker dropkick me in the head than deal with XML again. Tim Bray himself has had doubts [1] at one point.XML is too big of a hammer for the space it fills.[1] https://www.tbray.org/ongoing/When/200x/2003/03/16/XML-Prog\n \nreply",
      "JSONC. https://onury.io/jsonc/It can be hard to find an implementation of this if you're working in a not-so-popular language (looking at you Swift) but JSONC has had the best developer experience of anything I've tried so far.It's basically JSON with single and multi line comments and trailing commas.\n \nreply",
      "Pkl (from Apple land) and Dhall (from Haskell land) both solve some of these pain points as well as some others, especially being more seamless about integrating schema with config.Jsonnet, I haven't used personally but I know people who have raved about it.Ones I know less about include KCL, CUE, and Nickel.\n \nreply"
    ],
    "link": "https://tmendez.dev/posts/rng-git-hash-bug/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Visual DB \u2013 Web front end for your database (visualdb.com)",
    "points": 107,
    "submitter": "visualdb",
    "submit_time": "2024-09-10T17:25:00.000000Z",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=41503251",
    "comments": [
      "If your tool was available on-premise I would be really interested. Since a tool like this is primarily intended, I think, for internal use cases, making it available on-premise should be a priority from my point of view.Beside this, the tool looks great, congrats for the job, well done!\n \nreply",
      "Congrats to visualdb on launch.If you are looking for free open source version tryhttps://github.com/nocodb/nocodbIt's fairly simple to setup. Please refer to our readme/docsDisclaimer: founder here.\n \nreply",
      "Looks awesome! Well done, this might come in handy for folks where I was just hired. Definitely going to keep this in mind.\n \nreply",
      "Nocodb is indeed a worthy competitor! If you're interested in how Visual DB is differentiated from Airtable-like products see here: https://visualdb.com/spreadsheet/#airtable\n \nreply",
      "I second this, NocoDB is great!\n \nreply",
      "Thanks for the feedback. We'll make self-hosted version a high priority.\n \nreply",
      "Yes an on premise solution is quite important for place in hired in. To add to this I\u2019ve been doing a lot of looking into products like this and explored nocodb as a use case. Here are some limitations I\u2019ve run into.1) Granular user roles/permissions. Nocodb has this but it\u2019s a little awkward with different bases. For example it\u2019s hard to see which tables that user is limited to as you create new bases.2) Forms. The form needs to have flexibility in required fields which nocodb (and not just based on schema) does but it\u2019s missing a key feature. That would be \u201ccreated by\u201d field which doesn\u2019t work on external database with different bases for different permissions. As in if you have a different base per user group (to have different permission on table access) adding a new record does not populate created by correctly.3) relational data. The goal of these products is for non-technical people to use these and none have the option of clicking into the relation to bring up that record on its table. As in all you see is the description/id of the relational record.4) at some point you want to possibly use the database for user management. Because you may want to write an internal tooling that scans a qr code or something or the form is client based. But then you have users that may live on a different database interacting with your main database. And then you would need to match the users with what they view and what they can create.Essentially what I found is that with nocodb is that it is good for viewing data but to add data I need to create forms. \nBut then nocodb lacks in \u201cdashboard\u201d statistics and graphsSorry if this is not clearly explained. I\u2019m on holiday and tired rn.\n \nreply",
      "Regarding permissions, I think we meet your requirements. End users do not have permission to tables directly, they can only enter data through forms and sheets.Regarding \"created by\", do you mean a field that is automatically set, based on who created the record? That's on our todo list.Regarding relational data, we meet your requirements. Any time there is a foreign key, we display a \"...\" button which shows up with records from the foreign table you can select the row you want. This is fairly sophisticated... you can display all records from the foreign table (default), our you can have a query, and you can even have cascading dropdowns (for example you select Region in the first dropdown, then it shows Cities in that region in the next dropdown and so on), then matching rows are shown.Regarding user management we store users and permissions separately from databases, and the permissions you applies to all databases in the application. Permissions are set at the application level and you can create a different application (with connections to same databases if needed) if you want different permissions.\n \nreply",
      "It looks nice, indeed. Upvote for on-premise version.\n \nreply",
      "Congrats on the launch!Product feedback: looks super useful.Landing page feedback: clear and to the point. I love seeing lots of product screenshots. I\u2019d like to see a section about privacy, especially when the product involves db access and AI. Please consider replacing the carousel. https://shouldiuseacarousel.com/\n \nreply"
    ],
    "link": "https://visualdb.com/",
    "first_paragraph": "\r\n            Developing and maintaining internal applications to enter and update records in a database is expensive.\r\n            Now you can significantly lower costs by using Visual DB instead of developing custom applications.\r\n          \r\n            Visual DB is a productivity application, not a developer tool.\r\n            As such, you don't need to understand SQL or any other programming language to use Visual DB.\r\n            You build forms using Visual DB's drag-and-drop interface and AI assistance.\r\n          \r\n            Rather than requiring you to use an RDBMS that is built into Visual DB, it allows you to use your own.\r\n            Relational databases often act as integration hubs, with multiple business applications and tools accessing and updating the same data.\r\n            By using your own database you ensure that the database can be used with multiple applications beyond just Visual DB.\r\n          \r\n            Users in your company don't all need the same leve"
  },
  {
    "title": "Flipper Zero Gets Major Firmware Update, Can Eavesdrop on Walkie-Talkies (pcmag.com)",
    "points": 97,
    "submitter": "CharlesW",
    "submit_time": "2024-09-10T21:15:45.000000Z",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41505670",
    "comments": [
      "I'm really happy about the firmware updates.\nWhen Flipper Zero was crowdfunded, the deal was that the tool will be available once the hardware is good enough to fulfill the promises. And so the software will be updated later.I'm happy that they keep they promises.\n \nreply",
      "Official release: https://news.ycombinator.com/item?id=41500279\n \nreply",
      "Walkie-talkies can \"eavesdrop\" on walkie-talkies...\n \nreply",
      "Seriously. People really need to understand that CTCSS and DCS aren't actually privacy features, but convenience features for filtering out _other_ people's transmissions a user isn't interested in. It's the exact opposite of privacy. I guess the marketing as \"privacy codes\" worsens the situation.\n \nreply",
      "I just got my GPRS radio license and this was a really strange phenomenon to encounter. Apparently the FCC doesn't allow actual encrypted comms in this part of the spectrum, so the \"privacy\" codes, like you said, are really more just convenience codes, more noise cancelation than anything for privacy or security.It was weird trying to explain this to my family, too. Basically just had to tell them \"Nothing you say is private, and you should all say my call sign at the end of each transmission.\" We all felt like dorks, but it was super convenient in a place with no cell service.\n \nreply",
      "Get an itinerant frequency -- $300, requires no coordination, and you can encrypt your comms.One of the (ham) radio clubs that I'm a member of does this as a benefit for the group, and it's something that's nice to have: I can give my wife a radio and not worry about what she may or may not say if we have to take two separate cars when we road trip.I've been meaning to do the process myself, but, I haven't had the time (and honestly, I'd want someone else to do the paperwork for me so I'm more likely to pay someone else to do it) recently, but, this might be the thing that prompts me to go and do it.73 de K4IMW/WQZQ315\n \nreply",
      "Cool!What sort of radio do you use?My friend and I tried to do -- the two of us in different cars driving down the same stretch of highway this with GPRS radios and very quickly we were not able to pick up the other's broadcast. We assumed it was that we didn't have big enough antennas and were not using a repeater.Note - others were driving we were each a passenger in our respective cars.\n \nreply",
      "Did you have car mounted external antennas? I'm totally new to the hobby so I might be wrong here, but I believe the handheld units are kinda trapped in a Faraday cage if you use them inside the car. If you have the 20W+ mobile (not handheld) kind and mount it to an external antenna though, there should be enough range even just with GPRS as long as you're not on the other side of the mountain or something?\n \nreply",
      "Is there an actual EASY guide to dealing with itinerant licensing? The FCC paperwork is beyond confusing to try to get a single itinerant freq.\n \nreply",
      "Interesting! I was under the impression that the FCC was actually somewhat strict about part 90.35 eligibility, in that you have to provide fairly detailed specifics of your business use case or how you fall under the various educational/nonprofit exemptions, and that if you told them you wanted it for personal use or supplied a thinly veiled excuse they'd tell you to get lost. Maybe that understanding is outdated. I can imagine a HAM club having an easier time justifying that than you would as a random individual.\n \nreply"
    ],
    "link": "https://www.pcmag.com/news/flipper-zero-gets-major-firmware-update",
    "first_paragraph": ""
  },
  {
    "title": "Arvo P\u00e4rt's Journey (plough.com)",
    "points": 10,
    "submitter": "motohagiography",
    "submit_time": "2024-09-10T22:24:53.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.plough.com/en/topics/culture/music/arvo-parts-journey",
    "first_paragraph": "Subtotal: $OK, the point in the Part extract where the political commissar has stuffed his glasses on his forehead and pinches his eye sockets in despair at how \"difficult\" a case Part is is pure comedy.  No printed words needed; the picture tells it all. I laughed in surprise and delight! \r\n\r\nI've never read a graphic novel before (or is it a comic strip?) I am stunned that the seriousness and beauty of Part's story could be captured in the medium of a graphic novel.  AND, that words and pictures could make me want to listen to his music.  This is amazing.  I'd like to read the whole thing. I've ordered a copy.  Thank you.From Between Two Sounds: Arvo P\u00e4rt\u2019s Journey to His Musical Language, this week\u2019s featured book.\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Joonas Sildre is an Estonian comic artist, illustrator, and graphic designer who specializes in biographical books.\u00a0\u00a0Already a subscriber? Sign inTry 3 months of unlimited access. Start your FREE TRIAL today. Cancel anytime.At Allhallowtide, Arvo P\u00e4rt\u2019s music evokes"
  },
  {
    "title": "The Friendship that made Google huge (2018) (newyorker.com)",
    "points": 68,
    "submitter": "robertkoss",
    "submit_time": "2024-09-09T11:53:59.000000Z",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=41487653",
    "comments": [
      "I like how this digs into pair programming using these two as an example - pair programming, at least when I was coming up, was seen as a panacea to all software development problems. However, in our field, suffice it to say there are \"difficult\" personalities or people much more comfortable working alone, and in practice, I've rarely seen success with it, personally, more than someone looking over your shoulder every now and then to debug something. As a primary working method, which it seems like the subjects of this article are doing, you definitely need to find someone who thinks like you.I've had things that were close, but usually devolves into multiple short 10-20 minute meetings, division of tasks, then reconvene, rinse/repeat. That typically works well and I don't have to deal with people nitpicking how I use my editor or how many chrome tabs I have open.\n \nreply",
      "(former Googler)It was really special to see how this pair basically laid out the foundations of large-scale distributed computing. Protobufs, huge parts of the search stack, GFS, MapReduce, BigTable... the list goes on.They are the only two people at Google at level 11 (senior fellow) on a scale that goes from 3 (fresh grad) to 10 (fellow).\n \nreply",
      "(current Googler)One of my coworkers got assigned Sanjay on one of her CLs recently and she had no idea who he was. I had the pleasure of working with Sanjay as his intern at SRC the summer before he joined Google, and he taught be a lot of cool tricks related to compiler development. Both Sanjay and Jeff Dean are PhDs with PL focuses.\n \nreply",
      "It's actually quite interesting how many of the early Googlers came from PL research backgrounds, and how it impacted Google's culture.  Jeff Dean's thesis on whole-program optimization of Cecil/Vortex [1] was a classic even before Google got big, and eventually he got his boss Craig Chambers hired to write Flume [2].  Urs Hoezle (Google's first employee #9) was the founder of the Self project, which pioneered many of the dynamic optimization techniques that made it into HotSpot.  Much of the HotSpot team itself was hired by Google, notably former Search SVP Ben Gomes and several less famous employees.  The Plan 9 team (notably Ken Thompson and Rob Pike) went on to create Sawzall and then Go within Google; Ken Thompson was himself famous for creating C before then.  Guido van Rossum (Python's creator) wrote Mondrian, the first code-review tool in Google.  Lars Bak worked on BETA, then joined Urs to work on Self and Strongtalk before implementing the first version of V8 at Google.  Dan Sugalski of Parrot & Perl 6 fame has held a bunch of infrastructure rules within Google.It's like nearly everyone in a who's-who of the language design & compiler implementation community circa 2002 ended up working for Google, and the few that didn't (notably Chris Lattner of LLVM and Slava Pestov of Factor) ended up at Apple.[1] https://projectsweb.cs.washington.edu/research/projects/ceci...[2] https://research.google/pubs/flumejava-easy-efficient-data-p...\n \nreply",
      "hah, this happened to me recently. I submitted a small CL to a threading lib and suddenly I see some guy named \"sanjay\" asking for a small change.  It's very cool to see how involved he is still!\n \nreply",
      "I struggled badly on a pair programming position.It's not like I don't like reviews or cannot work alongside another person. It's I cannot learn while someone is talking to me or trying to make me place the cursor somewhere.I'm all in for code review, even in pairs. In fact, I do that with a junior dev I have assigned and it's working well for us. I leave him thinking and come back to evaluate his solution.I find reviewing him paired, is time saving for me. I make him lead me to the right code spots, rather than finding out on my own. I fire 3 quick questions and we're aligned on the spot.I'll never work again on a 100% pp position but I think I've found my sweet spot with the technique.I agree that, if no other safeguards are in place, using pp you can avoid real bad code. But without deep thought, you'll mostly converge to an average solution, when social dynamics are very much leading.\n \nreply",
      "I don't enjoy these types of lionizing articles, badically these types of articles is what you give $10k-$50k to a PR team and they start to write these articles yo elevate your reputation in the industry ...\n \nreply",
      "Yep, a PR boost is what Jeff and Sanjay need...\n \nreply",
      "In 2018 when the article was written, Jeff was relatively unknown outside distributed research (ie MapReduce) and Google, and Sanjay probably completely unknown.\n \nreply",
      "And they used this PR for what? This isn't a puff piece. Those guys are the real deal.\n \nreply"
    ],
    "link": "https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge",
    "first_paragraph": "Find anything you save across the site in your account One day in March of 2000, six of Google\u2019s best engineers gathered in a makeshift war room. The company was in the midst of an unprecedented emergency. In October, its core systems, which crawled the Web to build an \u201cindex\u201d of it, had stopped working. Although users could still type in queries at google.com, the results they received were five months out of date. More was at stake than the engineers realized. Google\u2019s co-founders, Larry Page and Sergey Brin, were negotiating a deal to power a search engine for Yahoo, and they\u2019d promised to deliver an index ten times bigger than the one they had at the time\u2014one capable of keeping up with the World Wide Web, which had doubled in size the previous year. If they failed, google.com would remain a time capsule, the Yahoo deal would likely collapse, and the company would risk burning through its funding into oblivion.In a conference room by a set of stairs, the engineers laid doors across "
  }
]