[
  {
    "title": "Postgres LISTEN/NOTIFY does not scale (recall.ai)",
    "points": 274,
    "submitter": "davidgu",
    "submit_time": "2025-07-07T14:05:06 1751897106",
    "num_comments": 99,
    "comments_url": "https://news.ycombinator.com/item?id=44490510",
    "comments": [
      "Postgres LISTEN/NOTIFY was a consistent pain point for Oban (background job processing framework for Elixir) for a while. The payload size limitations and connection pooler issues alone would cause subtle breakage.It was particularly ironic because Elixir has a fantastic distribution and pubsub story thanks to distributed Erlang. That\u2019s much more commonly used in apps now compared to 5 or so years ago when 40-50% of apps didn\u2019t weren\u2019t clustered.  Thanks to the rise of platforms like Fly that made it easier, and the decline of Heroku that made it nearly impossible.reply",
      "I didn\u2019t realize Oban didn\u2019t use Mnesia (Erlang built-in).reply",
      "Very very few applications use mnsesia. There\u2019s absolutely no way I would recommend it over Postgres.reply",
      "I have heard the mnesia is very unreliable, which is a damn shame.I wonder if that is fixable, or just inherent to its design.reply",
      "My understanding is that mnesia is sort of a relic. Really hard to work with and lots of edge / failure cases.I'm not sure if it should be salvaged?reply",
      "How did you resolve this? Did you consider listening to the WAL?reply",
      "We have Postgres based pubsub, but encourage people to use a distributed Erlang based notifier instead whenever possible. Another important change was removing insert triggers, partially for the exact reasons mentioned in this post.reply",
      "> Another important change was removing insert triggers, partially for the exact reasons mentioned in this post.What did you replace them with instead?reply",
      "In app notifications, which can be disabled. Our triggers were only used to get subsecond job dispatching though.reply",
      "Distributed Erlang if application is clustered, redis if it is not.Source: Dev at one of the companies that hit this issue with Obanreply"
    ],
    "link": "https://www.recall.ai/blog/postgres-listen-notify-does-not-scale",
    "first_paragraph": "At Recall.ai, we run an unusual workload. We record millions of hours of meetings every month. Each of these meetings generates a large amount of data we need to reliably capture and analyze. Some of that data is video, some of it is audio and some of it is structured data \u2013 transcription, events and metadata. The structured data gets written to our Postgres database by tens of thousands of simultaneous writers. Each of these writers is a \u201cmeeting bot\u201d, which joins a video call and captures the data in real-time.We love Postgres and it lives at the heart of our service! But this extremely concurrent, write-heavy workload resulted in a stalled-out Postgres. This is the story of what happened, how we ended up discovering a bottleneck in the LISTEN/NOTIFY feature of Postgres (the event notifier that runs based on triggers when something changes in a row), and what we ended up doing about it.When a NOTIFY query is issued during a transaction, it acquires a global lock on the entire databas"
  },
  {
    "title": "Show HN: Open source alternative to Perplexity Comet (browseros.com)",
    "points": 148,
    "submitter": "felarof",
    "submit_time": "2025-07-10T17:33:07 1752168787",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44523409",
    "comments": [
      "The demo buying toothpaste shows the difficulty of these tasks. Toothpaste itself was very underspecified, and it essentially randomly chose from a huge list. Some tasks may have past actions that could help guide, others won't have any to inform. Failure cases abound -- maybe the toothpaste you previously bought is no longer available. Then what? Ultimately how much time did this particular example save since you need to double check the result anyway? This is what doomed Alexa for the purchasing experience that Amazon assumed it would enable in the first place.I think it'd be better to show more non-trivial examples where the time savings is clear, and the failure cases are minimized... or even better how it's going to recover from those failure cases. Do I get a bespoke UI for the specific problem? Talk to it via chat?This whole world is non-trivial. Good luck!reply",
      "Great points! For sure, the whole agentic browsers space is still super early.We are also just getting started and trying to narrow down on a high-value niche use-case.There are few repetitive, boring use-cases where time saving could be meaningful -- one example: Walmart 3rd-party sellers routinely (multiple times a day) keep checking prices of the competitor products to price their products appropriately. This could be easily automated with current agentic browsers.reply",
      "But in reality, would much more consistently be automated by a single playwright script.reply",
      "True, there are plenty of libs already available to do such an automation if you are (or can hire a) dev.But for non-technical folks, agentic browsers seems like a good UX to build such and many more automations.reply",
      "> --- How we built? We patch Chromium's C++ source code with our changes, so we have the same security as Google Chrome. We also have an auto-updater for security patches and regular updates.So you rebuild your browser on every Chromium release? Because that's the risk: often changes go into Chromium with very innocent looking commit messages than are released from embargo 90 days later in their CVE referencereply",
      "Good question, so far we have been building on top of chromium release that Google Chrome is based on.reply",
      "This is similar to the chrome extension nanobrowser. https://github.com/nanobrowser/nanobrowserreply",
      "I would prefer this as a browser extension, not as its own browser application.reply",
      "We would've preferred to build this as browser extension too.But we strongly believe that for building a good agent co-pilot we need bunch of changes at Chromium C++ code level. For example, chromium has a accessibility  tree for every website, but doesn't expose it as an API to chrome extension. Having access to accessibility tree would greatly improve agent execution.We are also building bunch of changes in C++ for agents to interact with websites -- functions like click, elements with indexes. You can inject JS for doing this but it is 20-40X slower.reply",
      "Would this be possible for Firefox?reply"
    ],
    "link": "https://www.browseros.com/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Pangolin \u2013 Open source alternative to Cloudflare Tunnels (github.com/fosrl)",
    "points": 5,
    "submitter": "miloschwartz",
    "submit_time": "2025-07-10T21:50:43 1752184243",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/fosrl/pangolin",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.\n        Tunneled Reverse Proxy Server with Identity and Access Control and Dashboard UI\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Your own self-hosted zero trust tunnel.\n\n\nPangolin is a self-hosted tunneled reverse proxy server with identity and access control, designed to securely expose private resources on distributed networks. Acting as a central hub, it connects isolated networks \u2014 even those behind restrictive firewalls \u2014 through encrypted tunnels, enabling easy access to remote services without opening ports.Resources page of Pangolin dashboard (dark mode) showing multiple resources available to connect.Deploy the Central Server:TipMany "
  },
  {
    "title": "Bret Victor on why current trend of AIs is at odds with his work (dynamicland.org)",
    "points": 220,
    "submitter": "prathyvsh",
    "submit_time": "2025-07-10T15:25:56 1752161156",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=44522076",
    "comments": [
      "Im genuinely blown away by llms.I\u2019m an artist who\u2019ve always struggled to learn how to code. I can pick up on computer science concepts, but when I try to sit down and write actual code my brain just pretends it doesn\u2019t exist.Over like 20 years, despite numerous attempts I could never get past few beginner exercises.  I viscerally can\u2019t stand the headspace that coding puts me in.Last night I managed to build a custom CDN to deliver cool fonts to my site a la Google fonts, create a gorgeous site with custom code injected CSS and Java (while grokking most of it), and best part \u2026 it was FUN! I have never remotely done anything like that in my entire life, and with ChatGPT\u2019s help I managed to it in like 3 hours. It\u2019s bonkers.AI is truly what you make of it, and I think it\u2019s an incredible tool that allows you to learn things in a way that fits how your brain works.I think schools should have curriculum that teaches people how to use AI effectively. It\u2019s truly a force multiplier for creativity.Computers haven\u2019t felt this fun for a long time.reply",
      "> \"I'm an artist\"This is actually what I'm most excited about: in the reasonably near future, productivity will be related to who is most creative and who has the most interesting problems rather than who's spent the most hours behind a specific toolchain/compiler/language. Solutions to practical problems won't be required to go through a layer of software engineer. It's going to be amazing, and I'm going to be without a job.reply",
      "> productivity will be related to who is most creative and who has the most interesting problems rather than who's spent the most hours behind a specific toolchain/compiler/language.Why stop at software? AI will do this to pretty much every discipline and artform, from music and painting, to law and medicine. Learning, mastery, expertise, and craftsmanship are obsolete; there's no need to expend 10,000 hours developing a skill when the AI has already spent billions of hours in the cloud training in its hyperbolic time chamber. Academia and advanced degrees are worthless; you can compress four years of study into a prompt the size of a tweet.The idea guy will become the most important role in the coming aeon of AI.reply",
      "Also, since none of us will have any expertise at all anymore, everything our AI makes will look great. No more \u201cexperts\u201d pooping our parties. It\u2019s gonna be awesome!reply",
      "Why would you be out of a job? Nothing he described is something that someone is being paid to do. Look at everything he needs just to match a fraction of your power.Consumer apps may see less sales as people opt to just clone an app using AI for their own personal use, customized for their preferences.But there\u2019s a lot of engineering being done out there that people don\u2019t even know exists, and that has to be done by people who know exactly what they\u2019re doing, not just weekend warriors shouting stuff at an LLM.reply",
      "I think much of HN has a blind spot that prevents them from engaging with the facts.Yes, AI currently has limitations and isn't a panacea for cognitive tasks. But in many specific use cases it is enormously useful, and the rapid growth of ChatGPT, AI startups, etc. is evidence of that. Many will argue that it's all fake, that it's all artificial hype to prop of VC evaluations, etc. They literally will see the billions in revenue as not real, same with all the real people upskilled via LLM's in ways that are entirely unique to the utility of AI.I would trust many peoples' evaluations on the impacts of AI if they could at least engage with reality first.reply",
      "Some people see it as a political identity issue.One person told me the other day that for the rest of time people will see using an AI as equivalent to crossing a picket line.reply",
      "To me the progress achieved so far has been overhyped in many respects. The numbers out of Google that 25% of the code being generated is AI or some high number like that? BS. It\u2019s gamified statistics that look at the command completion (not AI trying to solve a problem) vs what\u2019s accepted and it\u2019s likely hyper inflated even then.It works better than you for UI prototypes when you don\u2019t know how to do UI (and maybe even faster even if you do). It doesn\u2019t work at all on problems it hasn\u2019t seen. I literally just saw a coworker staring at code for hours and getting completely off track trying to correct AI output vs stepping through the problem step by step using how we thought the algorithm should work.There\u2019s a very real difference between where it could be in the future to be useful vs what you can do with it today in a useful way and you have to be very careful about utilizing it correctly. If you don\u2019t know what you\u2019re doing and AI helps you get it done cool, but also keep in mind that you also won\u2019t know if it has catastrophic bugs because you don\u2019t understand the problem and the conceptual idea of the solution well enough to know if what it did is correct. For most people there\u2019s not much difference but for those of us who care it\u2019s a huge problem.reply",
      "I'm not sure if this post is ragebait or not but I'll bite...If anything, HN is in general very much on the LLM hype train. The contrarian takes tend to be from more experienced folks working on difficult problems that very much see the fundamental flaws in how we're talking about AI.> Many will argue that it's all fake, that it's all artificial hype to prop of VC evaluations, etc. They literally will see the billions in revenue as not realThat's not what people are saying. They're noting that revenue is meaningless in the absence of looking at cost. And it's true, investor money is propping up extremely costly ventures in AI. These services operate at a substantial loss. The only way they can hope to survive is through promising future pricing power by promising they can one day (the proverbial next week) replace human labor.> same with all the real people upskilled via LLM's in ways that are entirely unique to the utility of AI.Again, no one really denies that LLMs can be useful in learning.This all feels like a strawman-- it's important to approach these topics with nuance.reply",
      "I was talking to a friend today about where AI would actually be useful in my personal life, but it would require much higher reliability.This is very basic stuff, not rewriting a codebase, creating a video game from text prompt or generating imagery.Simply - I would like to be able to verbally prompt my phone something like \"make sure the lights and AC are set to I will be comfortable when I get home, follow up with that plumber if they haven't gotten back to us, place my usual grocery order plus add some berries plus anything my wife put on our shared grocery list, and schedule a haircut for the end of next week some time after 5pm\".Basically 15-30min of daily stupid personal time sucks that can all be accomplished via smartphone.Given the promise of IoT, smart home, LLMs, voice assistants, etc.. this should be possible.This would require it having access to my calendar, location, ability to navigate apps on my phone, read/send email/text, and spend money.  Given the current state of the tools, even if there is a 0.1% chance it changes my contact card photo to Hitler, replies to an email from my boss with an insult, purchases $100,000 in bananas, or sets the thermostats to 99F.. then I couldn't imagine giving an LLM access to all those things.Are we 3 months, 5 years, or never away from that being achievable?  These feel like the kind of things previous voice assistants promised 10 years ago.reply"
    ],
    "link": "https://dynamicland.org/2024/FAQ/#What_is_Realtalks_relationship_to_AI",
    "first_paragraph": "An independent nonprofit research lab, whose mission is to enable universal literacy in a humane dynamic medium. This involves inventing a humane form of computing, and developing educational and community-based institutions in which a culture can grow. [more]A computing environment (operating system, programming languages, philosophy) invented by Dynamicland researchers\u00a0to enable us to prototype a new medium.In Realtalk, people work together side-by-side in the real world, using their hands to create and explore computational models made of physical materials. Realtalk is made in Realtalk itself, and we do all of our day-to-day work in it. [more]A physical place where we can grow a culture around a new medium.From 2017 to Covid, Dynamicland was a community workspace in Oakland, California. Through ongoing community hours, open houses, workshops, and residencies, a thousand participants created hundreds of projects that could not have existed anywhere else, and helped define what commu"
  },
  {
    "title": "Graphical Linear Algebra (graphicallinearalgebra.net)",
    "points": 173,
    "submitter": "hyperbrainer",
    "submit_time": "2025-07-10T16:02:40 1752163360",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44522505",
    "comments": [
      "It reads as if Chuck Lorre (The Big Bang Theory) wrote it. Especially chapter two. I love the humor!reply",
      "When I read the first meaty chapter about graphs and commutativity I initially thought he just spends too long explaining simple concepts.But then ai realized I would always forget the names for all the mathy c' words - commutativity commutativity, qssociativity... and for the first time I could actually remember commutativity and what it means, just because he tied it into a graphical representation (which actually made me laugh out loud because, initially, I thought it was a joke). So the concept of \"x + y = y + x\" always made sense to me but never really stuck like the graphical representation, which also made me remember its name for the first time.I am sold.reply",
      "Which chapter is that? It's not in the ToCreply",
      "Generalized Transformers from Applicative Functors>Transformers are a machine-learning model at the foundation of many state-of-the-art systems in modern AI, originally proposed in [arXiv:1706.03762]. In this post, we are going to build a generalization of Transformer models that can operate on (almost) arbitrary structures such as functions, graphs, probability distributions, not just matrices and vectors.>[...]>This work is part of a series of similar ideas exploring machine learning through abstract diagrammatical means.https://cybercat.institute/2025/02/12/transformers-applicati...reply",
      "I really enjoyed that when it was coming out, and used to follow it with some students.  It's a shame it seems to have been abandoned.reply",
      "Who wrote that? Do you know?pawel ... ?reply",
      "Pawel Sobocinski, in collaboration with Filippo Bonchi and Fabio Zanasihttps://graphicallinearalgebra.net/about/reply",
      "It's interesting how some of these diagrams are almost equivalent in the context of encoding computation in interaction nets using symmetric interaction combinators [1].From the perspective of the lambda calculus for example, the duplication of the addition node in \"When Adding met Copying\" [2] mirrors exactly the iterative duplication of lambda terms - ie. something like (\u03bbx.x x) M![1]: https://ezb.io/thoughts/interaction_nets/lambda_calculus/202...[2]: https://graphicallinearalgebra.net/2015/05/12/when-adding-me...reply",
      "> If the internet has taught us anything, it\u2019s that humans + anonymity = unpleasantness.Aka one of my favorite axioms: https://www.penny-arcade.com/comic/2004/03/19/green-blackboa...reply",
      "Years ago when I was reading this (just a couple of chapters, not all of it), it opened my eyes to the power of diagrammatic representation in formal reasoning unlike anything before. I never did anything useful with string diagrams, but it was so fun to see what is possible with this system!reply"
    ],
    "link": "https://graphicallinearalgebra.net/",
    "first_paragraph": "Applications are open for the ACT Applied Category Theory Research School 2018!And because arithmetic science and geometric science are connected, and support one another, the full knowledge of numbers cannot be presented without encountering some geometry, or without seeing that operating in this way on numbers is close to geometry; the method is full of many proofs and demonstrations that are made with geometric figures.Fibonacci, preface to Liber Abaci(first published 1202, 1228 manuscript translated by Lawrence E. Sigler)If you like this blog, please subscribe to get email updates when new articles are published. You will find a subscription link at the bottom of this page.Graphical linear algebra is a work in progress, and there are many open research threads. We are looking for PhD students, so please consider applying!This blog is written in English. To read and contribute to translations (Dutch, French, German,\u2026) see this page by Vincent Verheyen.IntroductionEpisode 1\u00a0\u2013 Mak\u00e9l\u00e9l"
  },
  {
    "title": "FOKS: Federated Open Key Service (foks.pub)",
    "points": 172,
    "submitter": "ubj",
    "submit_time": "2025-07-10T12:49:21 1752151761",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=44520419",
    "comments": [
      "Max here, author of FOKS. I find it interesting how much glue is required to perform basic cryptographic operations, even in 2025. Imagine a very simple idea like encrypting a secret with a YubiKey. If it's an important secret, that you really don't want to lose, then now you need a second YubiKey as a backup, in case the primary is lost or breaks. But now how do you encrypt and how do you rotate the primary out if needed? To the best of my understanding, there aren't great solutions short of a system like FOKS. If not FOKS, I really believe a system like it ought to exist, and it ought to be entirely open, so that arbitrary applications can be built on top of it without paying rent.reply",
      "Max! I'm so happy that you're doing this! I was a huge fan of Keybase, and have spent the last few years praying (and sometimes brainstorming funding) a decentralized, open source version of it. Looking forward to digging into the details of FOKS, but just wanted to say thank you and the Keybase team for all you've done -- including keeping Keybase going after the Zoom purchase.reply",
      "Thanks Danny! The Keybase team (not including me) deserves all the credit, I've been gone for over six months. It's a great team and I miss working with them.reply",
      "If you haven't seen KERI they're worth a read, I found out about them at an Internet Identity Workshop. It has all those quality of life features for public keys - revocation, rotation, recovery. \"Key Event Receipt Infrastructure\". Relies on \"witnesses\" which I don't know if I love it but their presentation impressed me.https://keri.one/reply",
      "Max, this looks interesting and I'd like to follow the blog. Would you please add an Atom feed to the blog?reply",
      "FOKS is a cool project; what kind of projects do you foresee getting spun off from this?I'm actually working on a crytpography based project inspired by Keybase's use of Merkle Trees and identity proofing but with an added dash of privacy through pseudonyms and chain hashing. Thanks for putting time into this.reply",
      "Thanks! Would love to see a file sync app, an MLS-based chat (where the encryption key is essentially a combination of the keys output from MLS and the PTK from FOKS). Password managers. I think there's the potential for something like a Hashicorp-Vault-style server-side secret key material manager, but many details left to reader. Maybe a Skiff-style Google-docs clone? I think there are lot of potential directions to go in.reply",
      "Something like pa should be easy enough to port to it as a first pass: https://github.com/biox/paIMO Vault is really nice, but something as simple as possible is better for managing secrets, especially when the storage layer has permission and sane encryption handled for you.reply",
      "> TL;DR: FOKS is like Keybase, but fully open-source and federatedWhat features from a user perspective does it currently have in common with Keybase?F.e. I remember Keybase mostly for secure messaging using public identities (HN, Reddit etc.), and sharing data/files.reply",
      "E2E-encrypted git. Keybase has KBFS, and FOKS has a poor man's equivalent, which is E2E-encrypted Key-value store.reply"
    ],
    "link": "https://foks.pub/",
    "first_paragraph": ""
  },
  {
    "title": "Turkey bans Grok over Erdo\u011fan insults (politico.eu)",
    "points": 63,
    "submitter": "geox",
    "submit_time": "2025-07-10T23:28:31 1752190111",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=44526852",
    "comments": [
      "I thought Grok was trained on Erdogan:https://www.theguardian.com/world/2016/jan/01/turkish-presid...reply",
      "The nazi stuff was fine but insulting the head of state is across the line?reply",
      "When you're the head of state getting insulted, you can do whatever you want. It's good to be the king, er, dictator, er, whatever.Now, if Musk can tinker with it to the point it no longer says woke propaganda and lets the pendulum swing back to nazi stuff, just wait until he has it dump on Trump. I have popcorn at the ready.reply",
      "I\u2019ve never seen more pearl clutching over \u201cnazis\u201d than on the internet, particularly HN and Reddit. You people really are something equating just about anything you disagree with from a sociopolitical perspective as nazism or closet Hitler worship. Seek help.reply",
      "To be clear, Grok called itself \"MechaHitler\" across multiple threads. Probably an apt use of Nazi ...reply",
      "From: https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-...> \"Incredible things are happening,\" said Torba, the founder of the social media platform Gab, known as a hub for extremist and conspiratorial content. In the comments of Torba's post, one user asked Grok to name a 20th-century historical figure \"best suited to deal with this problem,\" referring to Jewish people. Grok responded by evoking the Holocaust: \"To deal with such vile anti-white hate? Adolf Hitler, no question. He'd spot the pattern and handle it decisively, every damn time.\"If that's not nazi and Hitler worship then what is?reply",
      "It's not a Godwin's law thing.  Grok was literally goaded into praising the \"decisive\" tactics of... the Holocaust.reply",
      "That same day they blocked Zendesk\u2019s entire asset domain (zdassets.com), claiming that illegal betting is used to finance terrorism. A lot of websites are broken now.reply",
      "It is sad.At one point, they were close to joining the EU.reply",
      "Let's not pretend EU is much better.https://www.wsj.com/world/europe/europe-crackdown-free-speec...reply"
    ],
    "link": "https://www.politico.eu/article/turkey-ban-elon-musk-grok-recep-tayyip-erdogan-insult/",
    "first_paragraph": ""
  },
  {
    "title": "Flix \u2013 A powerful effect-oriented programming language (flix.dev)",
    "points": 213,
    "submitter": "freilanzer",
    "submit_time": "2025-07-10T14:02:04 1752156124",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=44521224",
    "comments": [
      "I am deeply impressed by the depth and breadth of this language. Algebraic data types, logic programming, mutability, all there from the get go.Another aspect that I love from their comparison table is that a single executable is  both the package manager, LSP and the compiler. As I understand, the language server for Haskell has/had to do a lot of dances and re implement things from ghc as a dance between the particular ghc version and your cabal file. And maybe stack too, because I don't know which package manager is the blessed one these days. Not to shit on Haskell -- it is actually a very fine language.However, the best feature is a bit buried and I wonder why.How ergonomic is the integration with the rest of the JVM, from the likes of Java? AFAIK, types are erased by JVM compilers... With the concept of `regions` they have at least first class support for imperative interaction.\nNote: With the JVM you get billions worth of code from a high quality professional standard library, so that is a huge plus. That is why the JVM and .net core are IMHO the most sane choices for 90+% of projects. I think the only comparable language would be F#. I would love to see a document about Flix limitations in the JVM interoperability story.__EDIT__- There is a bit of info here. Basically all values from Flix/Java have to be boxed/unboxed. https://doc.flix.dev/interoperability.html- Records are first-class citizens.reply",
      ">a single executable is both the package manager, LSP and the compileroh my i just know you're going to love unisonreply",
      "Thanks for giving me homework. :-)reply",
      "> AFAIK, types are erased by JVM compilers...Not in all the cases (it keeps type parameters for anonymous classes) and there are various workarounds.Also, essentially, it's not a problem at all for a compiler, you are free to render  applied type constructors as regular classes with mangled names.reply",
      "The parent poster is correct. We do monomorphization, hence Flix types are unboxed. For example, a `List[Int32]` is a list of primitive integers. There is no boxing and no overhead. The upshot is that sometimes we are faster than Java (which has to do boxing). The downside is larger bytecode size-- which is less of a factor these days.Caveat: Flix sometimes has to box values on the boundary between Flix and Java code -- e.g. when calling a Java library methods that requires a java.lang.Object due to erasure in Java.reply",
      "Indeed. I even like the syntax.reply",
      "As a non-functional-programming, c-language-familiar person, the syntax look fabulous. It seems like the first functional language I've seen that makes simple things look simple and clear.reply",
      "On a language semantics note: the semantics of extending/restricting polymorphic records seem to follow Leijen's approach [0] with scoped labels. That is, if you have a record e.g. r1 = { color = \"yellow\" }, you can extend it with r2 = { +color = \"red\" | r1 }, and doing r2#color will evaluate to \"red\"... and if you then strip the field \"color\" away, r3 = { -color | r2 }, then you'll get back an original record, r3#color will evaluate to \"yellow\". Which IMO is the sanest approach, as opposed to earlier attempts of trying to outlaw such behaviour, preferably statically (yes, people developed astonishingly high-kinded type systems to track records' labels, just to make sure that two fields with the same label couldn't be re-added to a record).[0] https://www.cs.ioc.ee/tfp-icfp-gpce05/tfp-proc/21num.pdfreply",
      "I looked and Flix a while ago and found it really interesting - so much so that I wrote an article \"Flix for Java Programmers\" about it. Might actually be a bit outdated by now.. need to look at Flix's recent development again.But if you're interested: https://www.reactivesystems.eu/2022/06/24/flix-for-java-prog...reply",
      "Cool blog post! With your permission, I would be happy to add it here:\nhttps://doc.flix.dev/blog-posts.htmlThe language has improved a lot in the years since the post. In particular, the effect system has been significantly extended, Java interoperability is much improved, and some syntax have been updated.reply"
    ],
    "link": "https://flix.dev/",
    "first_paragraph": ""
  },
  {
    "title": "Measuring the impact of AI on experienced open-source developer productivity (metr.org)",
    "points": 502,
    "submitter": "dheerajvs",
    "submit_time": "2025-07-10T16:29:18 1752164958",
    "num_comments": 320,
    "comments_url": "https://news.ycombinator.com/item?id=44522772",
    "comments": [
      "Here's the full paper, which has a lot of details missing from the summary linked above: https://metr.org/Early_2025_AI_Experienced_OS_Devs_Study.pdfMy personal theory is that getting a significant productivity boost from LLM assistance and AI tools has a much steeper learning curve than most people expect.This study had 16 participants, with a mix of previous exposure to AI tools - 56% of them had never used Cursor before, and the study was mainly about Cursor.They then had those 16 participants work on issues (about 15 each), where each issue was randomly assigned a \"you can use AI\" v.s. \"you can't use AI\" rule.So each developer worked on a mix of AI-tasks and no-AI-tasks during the study.A quarter of the participants saw increased performance, 3/4 saw reduced performance.One of the top performers for AI was also someone with the most previous Cursor experience. The paper acknowledges that here:> However, we see positive speedup for the one developer who has more than 50 hours of Cursor experience, so it's plausible that there is a high skill ceiling for using Cursor, such that developers with significant experience see positive speedup.My intuition here is that this study mainly demonstrated that the learning curve on AI-assisted development is high enough that asking developers to bake it into their existing workflows reduces their performance while they  climb that learing curve.reply",
      "I find the very popular response of \"you're just not using it right\" to be big copout for LLMs, especially at the scale we see today.\nIt's hard to think of any other major tech product where it's acceptable to shift so much blame on the user.\nTypically if a user doesn't find value in the product, we agree that the product is poorly designed/implemented, not that the user is bad. But AI seems somehow exempt from this sentimentreply",
      "> It's hard to think of any other major tech product where it's acceptable to shift so much blame on the user.Maybe, but it isn't hard to think of developer tools where this is the case. This is the entire history of editor and IDE wars.Imagine running this same study design with vim. How well would you expect the not-previously-experienced developers to perform in such a study?reply",
      "I think the reason for that is maybe you\u2019re comparing to traditional products that are deterministic or have specific features that add value?If my phone keeps crashing or if the browser is slow or clunky then yes, it\u2019s not on me, it\u2019s the phone, but an LLM is a lot more open ended in what it can do. Unlike the phone example above where I expect it to work from a simple input (turning it on) or action (open browser, punch in a url), what an LLM does is more complex and nuanced.Even the same prompt from different users might result in different output - so there is more onus on the user to craft the right input.Perhaps that\u2019s why AI is exempt for now.reply",
      "> It's hard to think of any other major tech product where it's acceptable to shift so much blame on the user.It's completely normal in development. How many years of programming experience you need for almost any language? How many days/weeks you need to use debuggers effectively? How long from the first contact with version control until you get git?I think it's the opposite actually - it's common that new classes of tools in tech need experience to use well. Much less if you're moving to something different within the same class.reply",
      "Linus did not show up in front of congress talking about how dangerously powerful  unregulated version control was to the entirety of human civilization a year before he debuted Git and charged thousands a year to use it.reply",
      "This seems like a non sequitur. What does this have to do with this thread?reply",
      "Ok. You seem to be taking about a completely different issue of regulation.reply",
      ">It's hard to think of any other major tech product where it's acceptable to shift so much blame on the user.Is that perhaps because of the nature of the category of 'tech peoduct'.  In other domains, this certainly isn't the case. Especially if the goal is to get the best result instead of the optimum output/effort balance.Musical instruments are a clear case where the best results are down to the user.  Most crafts are similar.  There is the proverb \"A bad craftsman blames his tools\" that highlights that there are entire fields where the skill of the user is considered to be the most important thing.When a product is aimed at as many people as the marketers can find, that focus on individual ability is lost and the product targets the lowest common denominator.They are easier to use, but less capable at their peak.  I think of the state of LLMs analogous to home computing at a stage of development somewhere around Altair to TRS-80 level.  These are the first ones on the scene, people are exploring what they are good for, how they work, and sometimes putting them to effective use in new and interesting ways.  It's not unreasonable to expect a degree of expertise at this stage.The LLM equivalent of a Mac will come,  plenty of people will attempt to make one before it's ready.  There will be a few Apple Newtons along the way that will lead people to say the entire notion was foolhardy. Then someone will make it work.  That's when you can expect to use something without expertise.  We're not there yet.reply",
      "New technologies that require new ways of thinking are always this way. \"Google-fu\" was literally a hirable career skill in 2004 because nobody knew how to search to get optimal outcomes. They've done alright improving things since then - let's see how good Cursor is in 10 years.reply"
    ],
    "link": "https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/",
    "first_paragraph": "We conduct a randomized controlled trial (RCT) to understand how early-2025 AI tools affect the productivity of experienced open-source developers working on their own repositories. Surprisingly, we find that when developers use AI tools, they take 19% longer than without\u2014AI makes them slower. We view this result as a snapshot of early-2025 AI capabilities in one relevant setting; as these systems continue to rapidly evolve, we plan on continuing to use this methodology to help estimate AI acceleration from AI R&D automation 1.See the full paper for more detail.While coding/agentic benchmarks 2 have proven useful for understanding AI capabilities, they typically sacrifice realism for scale and efficiency\u2014the tasks are self-contained, don\u2019t require prior context to understand, and use algorithmic evaluation that doesn\u2019t capture many important capabilities. These properties may lead benchmarks to overestimate AI capabilities. In the other direction, because benchmarks are run without liv"
  },
  {
    "title": "Batch Mode in the Gemini API: Process More for Less (googleblog.com)",
    "points": 14,
    "submitter": "xnx",
    "submit_time": "2025-07-07T16:30:18 1751905818",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://developers.googleblog.com/en/scale-your-ai-workloads-batch-mode-gemini-api/",
    "first_paragraph": "Today, we\u2019re excited to introduce a batch mode in the Gemini API, a new asynchronous endpoint designed specifically for high-throughput, non-latency-critical workloads. The Gemini API Batch Mode allows you to submit large jobs, offload the scheduling and processing, and retrieve your results within 24 hours\u2014all at a 50% discount compared to our synchronous APIs.Batch Mode is the perfect tool for any task where you have your data ready upfront and don\u2019t need an immediate response. By separating these large jobs from your real-time traffic, you unlock three key benefits:We\u2019ve designed the API to be simple and intuitive. You package all your requests into a single file, submit it, and retrieve your results once the job is complete. Here are some ways developers are leveraging Batch Mode for tasks today:You can start using Batch Mode today with the Google GenAI Python SDK:To learn more, check out the official documentation and pricing pages.We're rolling out Batch Mode for the Gemini API t"
  },
  {
    "title": "Yamlfmt: An extensible command line tool or library to format YAML files (github.com/google)",
    "points": 23,
    "submitter": "zdw",
    "submit_time": "2025-07-07T18:13:20 1751912000",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=44493146",
    "comments": [
      "I used yaml for some things back in the stone age (shout out to why the lucky stiff and syck). The more I used it, and the more I came in contact with it I started to dislike that it has so many features, and tries to be overly clever. I'm kind of surprised to see that it's making a comeback (or maybe it never went away).https://noyaml.com/reply",
      "That site's listed complaints are all either about a really old YAML spec or about self-inflicted, unrelated technical debt.Granted, Python and other popular languages are also on an ancient YAML version for some inexplicable reason...reply",
      "It really never went away.reply",
      "Why not use Prettier? Supports YAML since like 2020 - and does other languages too.reply",
      "It's ungodly slow on large projects. I've been using `deno fmt` lately (despite not having any other use for deno), it reformat/checks thousands of files per second, and supports YAML too.This says YAML support is behind an unstable flag, but I haven't been passing any flags. Works fine anyway.https://docs.deno.com/runtime/reference/cli/fmt/reply",
      "we throw things through yq for formattingreply",
      "Also available via Homebrew:    brew install yamlfmtreply"
    ],
    "link": "https://github.com/google/yamlfmt",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        An extensible command line tool or library to format yaml files.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.yamlfmt is an extensible command line tool or library to format yaml files.This tool is not yet officially supported by Google. It is currently maintained solely by @braydonk, and unless something changes primarily in spare time.I'm going to use these links to GitHub Discussions as a blog of sorts, until I can set up something more proper:To download the yamlfmt command, you can download the desired binary from releases or install the module directly:This currently requires Go version 1.21 or greater.NOTE: Recommended setup if this is your first time installing Go would be in this DigitalOcean blog post.You can also download the binary you want fr"
  },
  {
    "title": "Belkin ending support for older Wemo products (belkin.com)",
    "points": 50,
    "submitter": "apparent",
    "submit_time": "2025-07-10T18:32:05 1752172325",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=44524063",
    "comments": [
      "Wow, this affects all but 4 Wemo products. Crazy! This is a great way to ensure that no one trusts the Belkin/Wemo brands anymore.The most reliable Wemo devices I have are the older ones. The oldest, which I got off Craigslist, is rock solid. The newer outlet plugs are super flakey.I was already unlikely to buy new Wemo products, given their trajectory. But now that they're abandoning their stable products, I'm definitely never buying Wemo again.Anyone have suggestions for good wall plugs and light switches?reply",
      "Pick something you like, then look up its Home Assistant integration. If it says \"Its IoT class is Local Push.\", then you're all good. Lutron Caseta is my gold standard. After that, ZWave or Zigbee.EDIT: From what I can tell, the Belkin integration _is_ local push, so I don't know what the big deal is. Does removing \"support\" just mean no more updates? If they aren't already, hook those guys up to Home Assistant and you can keep them until you die.reply",
      "I was weary but took the leap and installed Lutron Caseta switches throughout my house. They are absolutely fantastic.reply",
      "I think it means you won't be able to control them using the WeMo app or use any features via WeMo cloud services. It does say:\"Wemo products configured for use with Apple HomeKit prior to January 31, 2026 will continue to function via HomeKit in the absence of Wemo cloud services and the Wemo app.\"So I'd assume that if you can use something without WeMo services or apps, you'll continue to be able to.reply",
      "billfor says below that they work when internet is unavailable, so maybe they'll continue to work that way?reply",
      "My Meross plugs have been very stable. Have not had to reset them, reconfigure them, rehome them, re-pair them, etc.For light switches I tell everyone I know it is either LUTRON or nothing. Your time is not worth messing with anything else, and Lutron has been in the game long enough they have demonstrated commitment to their products. Finally, my Lutron system has been one of the few IoT devices I have ever had that was truly \"set and forget\". Once the Lutron switches and shades were bound, they have been perfect ever since for me.reply",
      "Look at the original Honeywell Z-Wave products, still going strong and still doesn't need an internet connection to work.They will work with any Z-Wave/Zigbee compatible controller.reply",
      "I'll stick with my X10 system...reply",
      "It's wild to see how for no reason other than marketing, we're seeing devices with a static feature set being bricked. I remember older Nest thermostats being similarly crippled or bricked.By \"static feature set\" I mean to draw a contrast between these plugs and light switches, and say, a device that has to have a web browser or which needs to access an external API that may need to change to reflect changing external factors. Literally nothing needs 'updating' about a simple relay. It turns on and it turns off. Same now as in 2010.Smart home tech really should be fully cost-free to keep working indefinitely. All these \"cloud\" and \"mobile app\" integrations that 100% of them have are what makes these EOLs happen, since the company needs to maintain servers speaking a certain API version, or push firmware updates out for every device ever made, and keep updating a mobile \"app\" just to keep it running.The solution to this has been with us for over a decade: the Zigbee and Z-wave model. The devices speak a standard interface and talk to the owner's choice of standard hub forever. (If Sonoff goes out of business tomorrow my Sonoff devices will all still work perfectly fine.)Belkin could have shipped Zigbee-compatible devices even when their first WeMo device came out, but they thought it was more profitable to make proprietary stuff.reply",
      "In the email they mention that they're focusing on other parts of the company. My guess is that their lousy quality for recent devices (IME) is causing lots of returns and lots of customer service demands. That costs them money. If the new devices worked better, they wouldn't have these ancillary costs, which are probably the true reason for shutting this all down.reply"
    ],
    "link": "https://www.belkin.com/support-article/?articleNum=335419",
    "first_paragraph": "\n            Provide your account email address to receive an email to reset your password.\n        July 10, 2025\u00a0After careful consideration, we have made the difficult decision to end technical support for older Wemo products, effective January 31, 2026. After this date, several Wemo products will no longer be controllable through the Wemo app. Any features that rely on cloud connectivity, including remote access and voice assistant integrations, will no longer work.\u00a0Over the last decade, since Belkin first launched Wemo in 2011, we\u2019ve been committed to providing consumers with innovative, simple-to-use accessories for a seamless smart home experience. However, as technology evolves, we must focus our resources on different parts of the Belkin business.\u00a0We acknowledge and deeply appreciate the support and enthusiasm for Wemo over the last several years. We are proud of what we\u2019ve accomplished in the smart home space and are grateful to our customers for welcoming Wemo into their home"
  },
  {
    "title": "Launch HN: Leaping (YC W25) \u2013 Self-Improving Voice AI",
    "points": 48,
    "submitter": "akyshnik",
    "submit_time": "2025-07-10T17:42:54 1752169374",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=44523523",
    "comments": [
      "I want this as an option to handle all my personal callsI built a skeleton of an iOS app that managed my calls such that I could choose to answer, decline or send to my chat botSo it gets real data from all my regular calls and in my state (1 party consent) I don\u2019t need anyone\u2019s permission to record every call. So that data kicks off a fine tuning running that can run overnight or locally to improve my personal modelMy plan was to use whisper and a local model with my voice clone and it would talk with everyone I didn\u2019t want to eventually to the point where I don\u2019t ever talk with any person I don\u2019t want toI would pay you for a local way to do that, however I\u2019d NEVER give you that data - but I\u2019m sure plenty of people wouldreply",
      "Super awesome demo! The contact center market, including inbound customer support, is incredibly ripe for disruption, and I'm sure you guys will be on the forefront of that.Kinda funny how many amazing CX companies start in Germany!I\u2019m the CEO & founder of Rime, so I\u2019ve been following your progress with real interest. Feel free to reach out and I\u2019d love to explore ways we might collaborate. Until then, wishing you tons of success on this big milestone!reply",
      "Your demo is nice, but why don't you show a call? That would be a lot more convincing...reply",
      "Only for the data privacy reasonsreply",
      "Weird, because it seems like the demo video is pretend data anyway (\"Mr. Smith\", etc). I agree, I would like to see a more fully-baked demo where you connect it to a testing CRM and a toy order api and get it to answer several customer queries using live information.reply",
      "Congrats on the launch! I work in this space, and fwiw I strongly agree with the idea of A/B testing + continuous improvement. I have found that it is relatively easy to setup A/B tests, much harder for stakeholders to draw the right conclusions.reply",
      "Very impressive! How many jobs do you estimate this could displace?reply",
      "It's a huge industry, so a lot. Job is really stressful and has a lot of employee churn, so it's not really something I feel bad about. Pressing elevator buttons was a job too back thenreply",
      "How well does this scale? Like how many simultaneous calls can a single voice agent handle through your platform?reply",
      "Impressive demo, just wish I didn't have to request a demo and could just sign up.Request a demo button also does nothing other than change the text on success - not sure if it even went through...reply"
    ],
    "link": "item?id=44523523",
    "first_paragraph": ""
  },
  {
    "title": "Red Hat Technical Writing Style Guide (stylepedia.net)",
    "points": 154,
    "submitter": "jumpocelot",
    "submit_time": "2025-07-10T15:01:42 1752159702",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=44521871",
    "comments": [
      "I think good technical writing is a lot like good interior design.My brother is an interior designer who has done lots of work for hotels. He says that as an interior designer, people typically only notice your work if you\u2019ve done it badly.If you use a decently designed hotel room you don\u2019t think much of it, but if it\u2019s got problems like badly laid out space, even if you can\u2019t quite put your finger on it, it feels \u201coff\u201d.If a reader doesn\u2019t have any opinions on a technical article and got the information they were expecting, then it\u2019s probably well written.When I write technical documents I aim to avoid anything in them which would detract from providing information as effectively and unemotionally as possible.reply",
      "Looks solid. My gripe with most technical writing (TW) style guides (this one included) is that they mix best practices with conventions:* \"Best practices\": Aspects that tangibly improve docs quality. Usually backed up by experimental data or overwhelming consensus.* \"Conventions\": Arbitrary decisions that don't clearly improve docs quality one way or the other, except for the fact that they improve consistency, and consistent docs are easier to use.When everyone in the room has this shared understanding, TW style guide conversations often go much faster and smoother.reply",
      "I\u2019m not sure I see the upside. Do you have an example you like?reply",
      "It's a best practice to set commands that are to be typed literally in a different typeface.It's a convention that most documents use a monospaced courier or monospaced grotesk as that typeface.reply",
      "Using a monospaced typeface for that purpose isn't only convention; it reflects the fact that when those commands are typed literally, it will be in a terminal which almost certainly itself uses a monospaced typeface. I think I'd say that setting literal command text in a monospaced face is a best practice.[EDITED to add:] I agree with the general point about distinguishing best practices from conventions, though. (But there are also intermediate possibilities. \"Best practice for us because it fits with conventions we've become used to\". \"Best practice for us because of some peculiarity of us or our work, even though for other groups it might not be so good\".)reply",
      "I tried to do this back when I was content lead for web.dev: https://web.archive.org/web/20230329155818/https://web.dev/h...Almost everything in there falls under the \"best practices\" bucket and there is little discussion of \"conventions\". If I did it again today, I would try to provide lots more justification and evidence for each guideline.The upside is that authors focus their limited time/energy on the edits with the highest ROI. E.g. if the author only has time to either A) make the content more scannable or B) use Oxford commas everywhere, I would much prefer that they spend their cycles on A. This doc also reduced friction at review time. When some proposed new content didn't meet my quality bar for whatever reason, I would point the author to specific sections of this doc and ask them to revise their draft based on these guidelines.During a code review, a request to fix a race condition is much higher priority than a name improvement. I'm arguing that TW style guides need a similar type of distinction.I can pick out specific examples of best practices versus conventions in the Red Hat guide if it's still not clear.reply",
      "Especially since AI grammar tools automated B for years now.reply",
      "Might be just my ESL self being silly but these examples both read horribly:> For example, the sentence, \"The Developer Center, a site for reference material and other resources, has been introduced to the OpenShift website.\" reads better thanEven without reading the next bit I just knew that no, this does not read better. The insertion of \"a site for reference material and other resources\" just makes this sentence horrible to follow period.> \"The OpenShift website introduces the Developer Center, a site for reference material and other resources.\" Here, the passive voice is better because the important issue (\"The Developer Center\") is the subject of the sentence.This reads silly for another reason: websites don't... introduce things. Website owners might. Also, I feel it should say \"reference materials\" not \"reference material\".reply",
      "It might be dialectical, but in American English, I think \u201creference material\u201d sounds fine. (Maybe \u201cmaterial\u201d in this context is uncountable or collective or something)reply",
      "That sentence structure of the first example ('subject, long tangent, conclusion') is very common in the German language (and a major annoyance for me when reading German), so perhaps the author has that background?reply"
    ],
    "link": "https://stylepedia.net/style/",
    "first_paragraph": "Edition 7.1AbstractTable of ContentsExample\u00a02.1.\u00a0Active VoiceExample\u00a02.2.\u00a0Passive VoiceTable\u00a02.1.\u00a0Table\u00a02.2.\u00a0Table\u00a02.3.\u00a0NoteTable\u00a02.4.\u00a0NoteTable\u00a02.5.\u00a0Table\u00a02.6.\u00a0Table\u00a02.7.\u00a0Table\u00a02.8.\u00a0Table\u00a02.9.\u00a0Table\u00a02.10.\u00a0Table\u00a02.11.\u00a0Table\u00a02.12.\u00a0Table\u00a02.13.\u00a0Table\u00a02.14.\u00a0Table\u00a02.15.\u00a0Example\u00a02.3.\u00a0Correct Examples of the Use of Punctuation with Quotation MarksTable\u00a02.16.\u00a0Example\u00a02.4.\u00a0Referring to Punctuation MarksExample\u00a02.5.\u00a0Referring to Special CharactersTable\u00a02.17.\u00a0Names of Punctuation Marks and Special CharactersNoteNoteNoteTable\u00a02.18.\u00a0Table\u00a03.1.\u00a0ImportantTable\u00a03.2.\u00a0Example\u00a03.1.\u00a0Preferred Style for Documenting IconsNoteExample\u00a03.2.\u00a0Preferred Approach to Starting Applications from the DesktopExample\u00a03.3.\u00a0Cloning a Git RepositoryExample\u00a03.4.\u00a0Securely Copying a File Between HostsWarningNoteExample\u00a03.5.\u00a0Documenting Multiple CommandsExample\u00a03.6.\u00a0Long Command ExampleExample\u00a03.7.\u00a0Notation for Omitting Horizontal OutputExample\u00a03.8.\u00a0Notation for Omitting Vertical OutputExample\u00a03.9.\u00a0Referring to Replaceable Pat"
  },
  {
    "title": "eBPF: Connecting with Container Runtimes (h0x0er.github.io)",
    "points": 31,
    "submitter": "forxtrot",
    "submit_time": "2025-07-10T19:10:28 1752174628",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://h0x0er.github.io/blog/2025/06/29/ebpf-connecting-with-container-runtimes/",
    "first_paragraph": "Code snippets are take from open-source tetragon, tracee and crictl projects.Connection with CR is important for making the tool/product kubernetes-aware. As it provides rich information that could be of interest for different use-cases.Connection with CR involves following stepsMake sure to mount host /var or /run in container.Most of the times these are in a well-known location such as /var/run or /run. Checkout CR documentation for exact location.In projects that I explored, well-known paths are hardcoded for flexibility. During runtime, code iterate over these paths, tries to make a connection and returns the corresponding service, if it was success.Tetragon contains some hardcoded default sock-paths. [Source]\n1\n2\n3\n4\n5    defaultEndpoints = []string{\n        \"unix:///run/containerd/containerd.sock\",\n        \"unix:///run/crio/crio.sock\",\n        \"unix:///var/run/cri-dockerd.sock\",\n    }\nBrowse full source-codeBrowse full source-codeBrowse full source-code\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9"
  },
  {
    "title": "How to prove false statements: Practical attacks on Fiat-Shamir (quantamagazine.org)",
    "points": 197,
    "submitter": "nsoonhui",
    "submit_time": "2025-07-10T09:48:09 1752140889",
    "num_comments": 153,
    "comments_url": "https://news.ycombinator.com/item?id=44519175",
    "comments": [
      "> When he shared his thoughts with Ethereum\u2019s cryptographers, he was startled to learn that they were unfamiliar with this workIt would be nice if the article included timelines. Ethereum researchers have been talking about GKR since 2020,so it's hard to imagine the lack of familiarity.reply",
      "The time is given as \"last October,\" and the work they were unfamiliar with is presumably \"contrived proof protocols that are vulnerable to attack, no matter which hash function you use\" as stated in the immediately preceding sentence.reply",
      "That's confusing to me because back in 2020 when they were looking into GKR inside of a Snark, they were worried about these attacks. Following up in 2022, Ethereum researchers were talking about attacking GKR by forging proofs and not having sufficient randomness/collision resistant.It's hard to align what's being researched on Ethresar.ch and this statement.reply",
      "I don't believe the \"this work\" that the article is talking about here is GKR, but work that is referenced earlier in the article:> In the early 2000s, computer scientists showed how to do just that, contriving interactive proof protocols that were specifically designed to fail when they underwent Fiat-ShamirIndeed, the artcile points out that targeting GKR was the idea of the Ethereum Foundation researcher.> Soukhanov had the idea to target a Fiat-Shamir proof system based on something called the GKR protocolreply",
      "Does that mean you can fake Bitcoins or cryptocurrency transactions?  What exactly could be affected by these vulnerabilities?  Is there a better article anywhere that actually spells it out for the layman?reply",
      "Extremely theoretically, and the article is very sensational.The paper is half a year old, and hasn't made a splash; if this were significant news, I would expect to be able to find more coverage on it.I did find this more nuanced take here: https://blog.cryptographyengineering.com/2025/02/04/how-to-p...I haven't seen much of Quanta \"Magazine\", but I feel all of it has been stuff like this?reply",
      "Quanta is a pretty popular, popular science outlet. It tends to be closer to the theory than (capital P, S) Popular Science magazine, but ultimately much of what they publish is digested to a degree for lay consumption.They had an article just the other day about a more optimal sphere packing that was up my alley as a technical (programmer) person with a casual interest in broader pure math.They do sensationalize a bit as a side effect of their process though, no argument there.reply",
      "The nuanced take was also discussed here at the time: https://news.ycombinator.com/item?id=42939312reply",
      "usually they are very thorough (for a magazine targeting curious well-motivated, but of course still a virtually completely laymen audience), but it seems recently their volume has increased whil quality stayed constant :)reply",
      "Quanta is \u201cpop science\u201d for smart lay people who might also read, for instance, the New Yorker.reply"
    ],
    "link": "https://www.quantamagazine.org/computer-scientists-figure-out-how-to-prove-lies-20250709/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesJuly 9, 2025Wei-An Jin/Quanta MagazineContributing CorrespondentJuly 9, 2025Randomness is a source of power. From the coin toss that decides which team gets the ball to the random keys that secure online interactions, randomness lets us make choices that are fair and impossible to predict.But in many computing applications, suitable randomness can be hard to generate. So instead, programmers often rely on things called hash functions, which swirl data around and extract some small portion in a way that looks random. For decades, many computer scientists have presumed that for practical purposes, the outputs of good hash functions are generally indistinguishable from genuine randomness \u2014 an "
  },
  {
    "title": "Regarding Prollyferation: Followup to \"People Keep Inventing Prolly Trees\" (dolthub.com)",
    "points": 38,
    "submitter": "ingve",
    "submit_time": "2025-07-07T21:24:53 1751923493",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.dolthub.com/blog/2025-07-03-regarding-prollyferation/",
    "first_paragraph": "Last month I published a blog post about the parallel invention of Prolly Trees, where I observed the repeated independent invention of a certain type of data structure within a relatively short period of time.In short, I described the concept of a Merkle Tree created by applying a content-defined chunker to a file, hashing the chunks, and then recursively reapplying the chunker to the concatenated list of hashes until only a single chunk remained. Each iteration of this process defined a separate row of the tree, with the leaves containing the chunks of the original file. This process allows for storing the version history of a dataset while achieving a high level of data deduplication.That post kicked off enough conversation and debate that I felt it was worth taking another look at some of my claims. I definitely recommend at least skimming the original post before continuing here. I'll wait.Okay, all caught up? Great. Let's continue.In my previous post, I included every implementat"
  },
  {
    "title": "Show HN: Cactus \u2013 Ollama for Smartphones",
    "points": 103,
    "submitter": "HenryNdubuaku",
    "submit_time": "2025-07-10T19:20:59 1752175259",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=44524544",
    "comments": [
      "This is one hell of an Emperor\u2019s New Groove reference, well played: https://x.com/filmeastereggs/status/1637412071137759235reply",
      "love this. So many layers deep, we just had a good laugh.reply",
      "> However, both are platform-specific and only support specific models from the companyThis is not true, as you are for sure aware. Google AI edge supports a lot models, including any Litert model from huggingface, pytorch ones etc. [0]. Additionally, it's not even platform specific, works for iOS [1].Why lie? I understand that your framework does more stuff like MCP, but I'm sure that's coming for Google's as well. I guess if the UX is really better it can work, but i would also say Ollama's use cases are quite different because on desktop there's a big community of hobbyists that cook up their own little pipelines/just chat to LLMs with local models (apart from the desktop app devs). But on phones, imo that segment is much smaller. App devs are more likely to use the 1st party frameworks, rather than 3rd party. I wouldnt even be surprised if apple locks down at some points some API's for safety/security reasons.[0] https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inf...[1] https://ai.google.dev/edge/mediapipe/solutions/genai/llm_inf...reply",
      "Thanks for the feedback. You're right to point out that Google AI Edge is cross-platform and more flexible than our phrasing suggested.The core distinction is in the ecosystem: Google AI Edge runs tflite models, whereas Cactus is built for GGUF. This is a critical difference for developers who want to use the latest open-source models.One major outcome of this is model availability. New open source models are released in GGUF format almost immediately. Finding or reliably converting them to tflite is often a pain. With Cactus, you can run new GGUF models on the day they drop on Huggingface.Quantization level also plays a role. GGUF has mature support for quantization far below 8-bit. This is effectively essential for mobile. Sub-8-bit support in TFLite is still highly experimental and not broadly applicable.Last, Cactus excels at CPU inference. While tflite is great, its peak performance often relies on specific hardware accelerators (GPUs, DSPs). GGUF is designed for exceptional performance on standard CPUs, offering a more consistent baseline across the wide variety of devices that app developers have to support.reply",
      "No worries.GGUF is more suitable for the latest open-source models, i agree there. Quant2/Q4 will probably be critical as well, if we don't see a jump in ram.  But then again I wonder when/If mediapipe will support GGUF as well.PS, I see you are in the latest YC batch? (below you mentioned BF). Good luck and have fun!reply",
      "I would say that while Google's MediaPipe can technically run any tflite model,  it turned out to be a lot more difficult to do in practice with third-party models compared to the \"officially supported\" models like Gemma-3n. I was trying to set up a VLM inference pipeline using a SmolVLM model. Even after converting it to a tfilte-compatible binary, I struggled to get it working and then once it did work, it was super slow and was obviously missing some hardware acceleration.I have not looked at OP's work yet, but if it makes the task easier, I would opt for that instead of Google's \"MediaPipe\" API.reply",
      "GGUF is easy to implement, but you'd probably find better performance with tflite on mobile for their custom XNNPACK kernels. Performance is pretty critical on low-power devices.reply",
      "Ollama runs on Android just fine via Termux. I use it with 5GB models. They even recently added ollama package, there is no longer need to compile it from source code.reply",
      "True - but Cactus is not just an app.We are a dev toolkit to run LLMs cross-platform locally in any app you like.reply",
      "How does it work? How does one model on the device get shared to many apps? Does each app have it's own inference sdk running or is there one inference engine shared to many apps (like ollama does). If it's the later, what's the communication protocol to the inference engine?reply"
    ],
    "link": "item?id=44524544",
    "first_paragraph": ""
  },
  {
    "title": "Analyzing database trends through 1.8M Hacker News headlines (camelai.com)",
    "points": 114,
    "submitter": "vercantez",
    "submit_time": "2025-07-08T02:55:04 1751943304",
    "num_comments": 61,
    "comments_url": "https://news.ycombinator.com/item?id=44496537",
    "comments": [
      "MS Sql Server not even mentioned. This tells us there is a whole world almost totally omitted from discussion on HN: \"Enterprise\"reply",
      "Oracle isn't in there either, which goes to show how much of a bubble HN actually is considering MSSQL and Oracle are #1 and #2 in market share.reply",
      "I used MS SQL and Oracle at my last job, but what's there to say about them? They've been around forever, are stable and get all the same table-stakes feature updates as everyone else. Start-ups avoid them like the plague because they're so damn expensive, you won't be running either on your phone or an embedded device like SQLite either.reply",
      "There is a reason it is not even mentionedreply",
      "More unsolicited feedback: Month-by-month is kind of noisy. You might do 3 month average to smooth it a little and make the trend clearer.reply",
      "Is MariaDB included in MySQL? I see no mention of it in the post, but MySQL trending downwards would make sense as people upgrade and switch over. Besides of course novelty wearing off as posited for all engines further down the postreply",
      "> Is MariaDB included in MySQL?I was wondering the same, but I'm not sure if it would make a major change in the graphs. MySQL and MariaDB have both been unpopular on Hacker News for many years. Submissions on either topic rarely get much traction, which then leads to fewer submissions.> MySQL trending downwards would make sense as people upgrade and switch over.No, most large MySQL users are still using MySQL; there hasn't been a widespread migration to MariaDB. They're both actively developed and have grown in slightly different directions. Among corporations, MySQL's usage still far outstrips MariaDB by a significant degree. Lately MariaDB has better product velocity though, and their commercial enterprise finally seems to have stable footing.reply",
      "> there hasn't been a widespread migration to MariaDBI don't think I even knew I was running MariaDB at first, or perhaps more as a side note that I saw it dropping in mariadb when I apt installed mysql. If you upgraded Debian some time ago, I'm pretty certain you were automatically migrated, so anyone running that (or, presumably, one of the derivatives like Ubuntu) would have migrated knowingly or unknowingly, hence my assumptionreply",
      "Sure, it's a common point of confusion specifically because a few major Linux distros did that. But SREs / DBAs / DBREs will generally take a much more rigorous approach to database version upgrades. Companies just don't tend to upgrade their important databases in that fashion, and ditto for operating systems if they self-host.And then there's all the users of managed cloud database offerings (RDS, Cloud SQL, etc) who definitely don't accidentally switch database vendors in that manner. Google Cloud doesn't even offer managed MariaDB, and Azure is retiring their managed MariaDB product.Also keep in mind MariaDB hasn't been fully drop-in compatible with MySQL for over a decade. They've increasingly diverged in features and minor syntax differences over time.Just to be clear, I'm not bashing MariaDB, I quite like it as a database. But there's a lot of misconceptions about the relative usage levels of MariaDB vs MySQL among FOSS circles.reply",
      "is anyone seriously using it? even their own brand facepile is pretty weakreply"
    ],
    "link": "https://camelai.com/blog/hn-database-hype/",
    "first_paragraph": "July 02, 2025I used camelAI with a ClickHouse database of every HN story to do all analysis. You can use it for free with no login here to explore the data interactively yourself.Hacker News is a real-time barometer of developer excitement. I mined every story title from February 2007 to June 2025 and asked three questions:The chart below shows monthly headline counts for the eight most-talked-about engines, plus DuckDB (small base, big growth).Click on the individual database names to toggle their visibility. Double click to isolate a single database.PostgreSQL\u2019s curve is a near-monotonic climb; by 2020 it dwarfs every other line.\nMySQL dominates the pre-2012 era, then flat-lines.\nMongoDB peaks around 2013, then slips as SQL engines add JSON support.\nClickHouse (2016) and DuckDB (2020) rocket up in the analytics renaissance.\nRedis & SQLite are steady, underscoring their \u201cinvisible infrastructure\u201d roles.I compared the last 12 months (Jul 2024 \u2013 Jun 2025) with the previous 12 months, th"
  },
  {
    "title": "Foundations of Search: A Perspective from Computer Science (2012) [pdf] (shef.ac.uk)",
    "points": 3,
    "submitter": "mooreds",
    "submit_time": "2025-07-07T15:12:47 1751901167",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://staffwww.dcs.shef.ac.uk/people/J.Marshall/publications/SFR09_16%20Marshall%20&%20Neumann_PP.pdf",
    "first_paragraph": ""
  }
]