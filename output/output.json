[
  {
    "title": "NanoChat \u2013 The best ChatGPT that $100 can buy (github.com/karpathy)",
    "points": 833,
    "submitter": "huseyinkeles",
    "submit_time": "2025-10-13T15:22:47 1760368967",
    "num_comments": 170,
    "comments_url": "https://news.ycombinator.com/item?id=45569350",
    "comments": [
      "Interesting exchange on the use of AI coding tools:    curious how much did you write the code by hand of it?\n\n    Karpathy: Good question, it's basically entirely hand-written (with tab autocomplete). I tried to use claude/codex agents a few times but they just didn't work well enough at all and net unhelpful, possibly the repo is too far off the data distribution.\n\nhttps://x.com/karpathy/status/1977758204139331904reply",
      "> the repo is too far off the data distributionah, this explains why these models have been useless to me this whole time. everything i do is just too far off the data distribution!reply",
      "I wonder if the new GenAI architecture namely DDN or distributed discrete networks being discussed recently can outperform the conventional architecture of GAN and VAE. As the name suggests, it can provide multitude of distributions for training and inference purposes [1].[1] Show HN: I invented a new generative model and got accepted to ICLR (90 comments):https://news.ycombinator.com/item?id=45536694reply",
      "Everything is unless your app is a React todolist or leatcode questions.reply",
      "people say this like it's a criticism, but damn is it ever nice to start writing a simple crud form and just have copilot autocomplete the whole thing for me.reply",
      "Back in the 90s you could drag and drop a vb6 applet in Microsoft word. Somehow we\u2019ve regressed..Edit: for the young, wysiwyg (what you see is what you get) was common for all sorts of languages from c++ to Delphi to html. You could draw up anything you wanted. Many had native bindings to data sources of all kinds. My favourite was actually HyperCard because I learned it in grade school.reply",
      "I agree. I am \"writing\" simple crud apps for my own convenience and entertainment. \nI can use unfamiliar frameworks and languaged for extra fun and education.Good times!reply",
      "or a typical CRUD app architecture, or a common design pattern, or unit/integration test scaffolding, or standard CI/CD pipeline definitions, or one-off utility scripts, etc...Like 80% of writing coding is just being a glorified autocomplete and AI is exceptional at automating those aspects. Yes, there is a lot more to being a developer than writing code, but, in those instances, AI really does make a difference in the amount of time one is able to spend focusing on domain-specific deliverables.reply",
      "And even for \"out of distribution\" code you can still ask question about how to do the same thing but more optimized, could a library help for this, why is that piece of code giving this unexpected output etcreply",
      "It has gotten to the point that I don't modify or write SQL.  Instead I throw some schema and related queries in and use natural language to rubber duck the change, by which point the LLM can already get it right.reply"
    ],
    "link": "https://github.com/karpathy/nanochat",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        The best ChatGPT that $100 can buy.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.The best ChatGPT that $100 can buy.This repo is a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase. nanochat is designed to run on a single 8XH100 node via scripts like speedrun.sh, that run the entire pipeline start to end. This includes tokenization, pretraining, finetuning, evaluation, inference, and web serving over a simple UI so that you can talk to your own LLM just like ChatGPT. nanochat will become the capstone project of the course LLM101n being developed by Eureka Labs.The fastest way to feel the magic is to run the speedrun script speedrun.sh, which trains and inferences the $100 tier of nanochat. On "
  },
  {
    "title": "DDoS Botnet Aisuru Blankets US ISPs in Record DDoS (krebsonsecurity.com)",
    "points": 45,
    "submitter": "JumpCrisscross",
    "submit_time": "2025-10-13T23:21:23 1760397683",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=45574393",
    "comments": [
      "This really is a function of two things:1) (Mainly) the huge increase in upstream capacity of residential broadband connections with FTTH. It's not uncommon for homes to have 2gbit/sec up now and certainly 1gbit/sec is fairly commonplace, which is an enormous amount of bandwidth compared to many interconnects. 10, 40 and 100gbit/sec are the most common and a handful of users can totally saturate these.2) Many more powerful IoT devices that can handle this level of attack outbound. A $1 SoC can easily handle this these days.3) Less importantly, CGNAT is a growing problem. If you have 10k (say) users on CGNAT that are compromised, it's likely that there's at least 1 on each CGNAT IP. This means you can't just null route compromised IPs as you are effectively null routing the entire ISP.I think we probably need more government regulation of these IoT devices. For example, having a \"hardware\" limit of (say) 10mbit/sec or less for all networking unless otherwise required. 99% all of them don't need more than this.reply",
      "Seems more likely that residential modems will be required to use ISP-provided equipment that has government mandated chips, firmware, etc to filter outbound traffic for DDoS prevention.reply",
      "Why should they be required to have hardware in their own network to filter that out when the ISP is obviously receiving all of their traffic anyway?reply",
      "Seems pretty clear that the US needs strict regulation on any device connecting to the internet.* no default password *\n* no login if not on the local wifi or wired ethernet *reply",
      "I'd rather the industry standardizes on some sort of guest network and proxy/hub. It could even ship with hardware from ISPs. Separating the network buys you a lot of security, and running everything through a proxy makes it easier to inspect data and creates a standard hook for using abandonware.reply",
      "Many manufacturers are already moving there of their own accord. I really don't think we'd need some legislation to fix this problem.reply",
      "I'm honestly kinda curious why nobody's blocking these IPs from sending data near the source.Like, I can come up with plenty of possible reasons, and reasons why it could potentially be very bad if ISPs started cracking down on this, but I don't actually know any reasons.Are any talking about why / why not?  It seems like this whole insecure-IoT-device thing would probably dry up pretty quickly if people's internet was cut off when one was detected.  They can then turn around and lambast / sue / etc the company that sold it, putting pressure on the source of the problem.  Right now there's no reason for sellers to do anything at all to ensure security, afaict.So... not actually arguing in favor of it, but definitely curious about any stated ISP / core networking system's stated reasons.reply",
      "> \u201cThe outbound and cross-bound DDoS attacks can be just as disruptive as the inbound stuff,\u201d Dobbin said. \u201cWe\u2019re now in a situation where ISPs are routinely seeing terabit-per-second plus outbound attacks from their networks that can cause operational problems.\u201dISPs are starting to feel the pain, so perhaps in the near future they will do something about it.reply",
      "Perhaps, or perhaps not. Maybe if we held them accountable they would?reply",
      "This does happen, but it seems to depend on the ISP. In the Netherlands I've seen ISPs block the internet connectivity when they've detected infected devices, sometimes they send a letter before blocking and some ISPs seem to dump your internet connection in a captive portal. In all these cases it's been enough to call the ISP after finding the problem and you're connected again minutes later.reply"
    ],
    "link": "https://krebsonsecurity.com/2025/10/ddos-botnet-aisuru-blankets-us-isps-in-record-ddos/",
    "first_paragraph": "The world\u2019s largest and most disruptive botnet is now drawing a majority of its firepower from compromised Internet-of-Things (IoT) devices hosted on U.S. Internet providers like AT&T, Comcast and Verizon, new evidence suggests. Experts say the heavy concentration of infected devices at U.S. providers is complicating efforts to limit collateral damage from the botnet\u2019s attacks, which shattered previous records this week with a brief traffic flood that clocked in at nearly 30 trillion bits of data per second.Since its debut more than a year ago, the Aisuru botnet has steadily outcompeted virtually all other IoT-based botnets in the wild, with recent attacks siphoning Internet bandwidth from an estimated 300,000 compromised hosts worldwide.The hacked systems that get subsumed into the botnet are mostly consumer-grade routers, security cameras, digital video recorders and other devices operating with insecure and outdated firmware, and/or factory-default settings. Aisuru\u2019s owners are cont"
  },
  {
    "title": "Sony PlayStation 2 fixing frenzy (retrohax.net)",
    "points": 36,
    "submitter": "ibobev",
    "submit_time": "2025-10-13T23:02:06 1760396526",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=45574247",
    "comments": [
      "I've seen a few posters ask already, so I figured I'd answer what the PS2 analog button's function was.The button switches between two modes of the analog joysticks, either to behave with their normal functionality, or to simply be a digital input (so just round all movement to either up/down/left/right). For PS2 games, you typically wouldn't want to do this. Instead, the functionality exists because the PS2 was backwards compatible with PS1 titles. The original PS1 controller didn't have analog sticks at all, just the D-Pad for navigation. After a few years (and the success of Nintendo's N64 analog controller) Sony released a revised version of the controller that included two joysticks, which their controllers still mimic to this day. However, those PS1 games released prior to the analog controller wouldn't always behave correctly if you tried to use an analog input scheme, so Sony added a mode to allow the Joysticks to function the same as the D-Pad, in case players preferred it.Other fun fact, the analog controller was not the same as their more famous Dualshock controller. There was a short-lived PS1 Dual Analog controller which just added the joysticks. It only lasted a few months before Sony replaced it with one that supported rumble functionality (also after being inspired by the N64), this was the Dualshock.reply",
      "https://web.archive.org/web/20251013151036/https://retrohax....reply",
      "Absolute long shot. Say someone had a PS2 Devkit that booted once and then never again. Is there a perfect tear down and maintenance guide like this with lots of text and pictures that people have had success with before?reply",
      "My PS2 slim still works (I played Teken Tag Tournament last weekend).  Am I lucky?  Anyone know the MTBF?On the other hand, I don't think I've had a DS2 controller last me more than a couple of years, even with light use.  I use My dual-shock 1 controllers for any game that is compatible with it, and they are still going strong.reply",
      "The 2 OEM Dual Shock 2 I got with my console, worked for 10+ years right until I \nsold itGenerics varied in quality vastly but never felt quite that sturdy\nI regret having to sell that PS2, specially seeing the current resurgencereply",
      "My PS3 controllers are still working perfectly almost 20 years later. Yet I\u2019ve had to replace my PS5 controllers three times so far, due to the joysticks not reading their position correctly. Each one lasted about a year and a half.reply",
      "So, what does the analog button on the controller do?reply",
      "So... What does the analog button do?reply",
      "Was peak MIPS the PS2 or the N64?reply"
    ],
    "link": "https://retrohax.net/sony-playstation-2-fixing-frenzy/",
    "first_paragraph": ""
  },
  {
    "title": "First device based on 'optical thermodynamics' can route light without switches (phys.org)",
    "points": 110,
    "submitter": "rbanffy",
    "submit_time": "2025-10-09T00:54:00 1759971240",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=45522266",
    "comments": [
      "The writeup on phys.org is troublesome at best. Starting with the Ming Hsieh Department of Electrical and Computer Engineering, it buries the rest of that sentence in paragraph 5: USC (University of Southern California) and the Abbe Center of Photonics, Friedrich Schiller University Jena, Germany.This team has made a nonlinear lattice that relies on something they call \"Joule-Thomson-like expansion.\" The Joule-Thomsen effect is the ideal gas law in beginning science. PV=nRT. Compression heats a gas, expansion cools a gas.Why they're studying the equivalent photonics principle [1] is that it focuses an array of inputs, \"causing light to condense at a single spot, regardless of the initial excitation position.\" Usually the problem is that light is linearly independent: two beams blissfully ignore each other. To do useful switching or compute, one of the beams has to be able to act as a control signal.A photon gas doesn't conserve the number of particles (n) like beginning physics would suggest. This lets the temperature of the gas control the output.The temperature, driven by certain specific inputs, produces the nonlinear response. I didn't see a specific claim what gain they achieved.This paper is more on the theoretical end of photonics research. Practical research such as at UBC Vancouver [2] where a device does \"weight update speed of 60 GHz\" and for clustering it can do \"112 x 112-pixel images\" - the tech doesn't compete well against electronics yet.TSMC and NVidia are attempting photonics plays too. But they're only achieving raw I/O with photons. They can attach the fiber directly to the chip to save watts and boost speeds.Basic physics gets in the way too. A photon's wavelength at near UV is 400 nanometers, but the transistors in a smartphone are measured at 7 nanometers ish. Electrical conduction is fundamentally smaller than a waveguide for light. Where light could maybe outshine electrons is in switching speed. But this research paper doesn't claim high switching speed.[1] https://en.wikipedia.org/wiki/Photon_gas[2] https://www.nature.com/articles/s41467-024-53261-xreply",
      "> TSMC and NVidia are attempting photonics plays too.It's probably been six years since I looked at this space. The problem at the time for TSMC and several other people was that their solutions worked fairly well for firing photons vertically out of the chip and not well at all for firing them horizontally through the chip. I don't know if in the short term and mid term if an optical PCIe or memory bus is more overall horsepower than faster cross-chip communication in CPUs. But the solutions they were still chasing back then were good between chips, maybe between chiplets. Which could still be an interesting compromise.> 400 nanometers, but the transistors in a smartphone are measured at 7 nanometers ishThe best em sensors need to be at least 1/10th the length of the frequency they are sending/receiving right? 40 nm isn't awful but it does suggest light for communication between functional units, rather than for assembling them.reply",
      "Light doesnt interact with itself directly without a third non-light partner. So yes the light of course needs to interact with lattice made of atoms to make any switching possible here. This is why we can see light from the stars though it had to travel through other light for millions of years.reply",
      "I don't think the author of this piece has a clue how this works. I certainly don't, even after reading it slowly.reply",
      "It's actually quite comprehensible. Nonlinear optical medium + photon gas -> a photon gas which is no longer ideal, so that things like Joule-Thompson effect can happen in it, then they build simple computing mechanisms out of it.The details are probably fiddly though.reply",
      "- my understanding of nonlinear optical mediums is negligible. Something like the crystals that cause quantum entanglement and emitting photon pairs?- what is a \"photon gas\"? Is this a state of matter? What is the matter if photons aren't matter?- ideal gas law, PV=nRT not obeyed? Due to ionization or something? Photon pressure?- Joule-Thompson Effect?- Building computers out of light?- Which thermodynamic properties or laws are being obeyed? Is this something like a Carnot cycle, but with photons?reply",
      "The almost-wrong simplification is that a nonlinear medium changes the wavelength of the light that passes through it.If you can control the nonlinearity, you can control the wavelength change and so change properties such as the angle of refraction to change where the light goes (like in a rainbow/a prism, where the red light refracts more).reply",
      "The immediate question is: how much \"resistance\" is there? That is, how much light will be lost per node, and as a result how long is the longest circuit you can make without boosters?reply",
      "I agree. The article is written quite superficial and when it gets intersting it just repeats the stuff from before. Imo the subject and news are really hot shit, but the author did his best to hide it in banalityreply",
      "I found this article extremely hard to understand, and the linked abstract was not much more help. My impression is that the device can take light coming into one of several input ports and through some magic of nonlinear optics, ensure that it all ends up at a single output port, something like a funnel. I was unable to determine anything about what this routing mechanism is (heating a substrate, maybe?), if the routing is dynamically changeable, or it works in reverse, eg light coming in can be routed to one of several output ports. The latter would seem like a breakthrough, but my impression is that what's described here is more proof-of-concept than prototype.reply"
    ],
    "link": "https://phys.org/news/2025-10-device-based-optical-thermodynamics-route.html",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: SQLite Online \u2013 11 years of solo development, 11K daily users (sqliteonline.com)",
    "points": 333,
    "submitter": "sqliteonline",
    "submit_time": "2025-10-13T12:46:52 1760359612",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=45567770",
    "comments": [
      "Your tool has been a huge help in the classroom over the past decade, thank you!Having a quick online link to get students started is really useful from a student motivation standpoint. This allows them to get a sense of the query flow before having to set up their own database or moving on to other DBMSes.Congratulations on 11 years!reply",
      "What a nice tool. Thank you for building and maintaining the product. I casually use it to validate SQL joinsreply",
      "Thank you! I hope it will capture your interest with new features in the future.reply",
      "Cool project. Congrats for keeping it up for so long!Could you share some numbers like a ballpark of subscribers?reply",
      "Thank you, unfortunately, almost zero.reply",
      "hey, not to give you \"armchair\" advice, but I feel like a tool that's existed for 11 years and has 11k daily users is a super serious achievement.I'd vicariously love for you to be able to make some/more revenue with this!+1 on @redox99's comment that charging in rubles is most probably confusing, and that a flat $10 usd/month would be easier. I also would think that renewal should actually be on by default, not off - if people want the service and/or to support you, having auto renewal off is more of a hassle for them (the customers who want to pay you!) as they'd have to have to... re-enable their service? every 30-90 days?and another point I wanted to bring up is that it feels to me like a small text-based advertisement from ethicalads.io (the folks behind the ads on Read the Docs sites) or carbonads.net (btw I have no affiliation to either) could definitely... bring in some not-bad revenue pretty much immediately?again, huge congrats on your project and I truly wish you'll be able to find some path to monetization. cheers!reply",
      "Thank you. I have been considering various monetization approaches, evaluating their convenience and potential demand.\nUnfortunately, certain external factors currently prevent me from implementing everything as I would like.\nHowever, I still have several ideas that I hope will be engaging, in demand, and easy to pay for.reply",
      "> charging in rubles is most probably confusing, and that a flat $10 usd/month would be easierAs a Brit, I'd rather GBP...Isn't this comment a form of US defaultism?reply",
      "for sure, my point was that usd would already be \"better\" (more common) than rubles - but yes, 'localized' currencies would be great too (although setting up \"adaptive pricing\" is a task in itself). baby steps :-)reply",
      "As a rabbit, I'd rather carrots...Isn't this comment a form of Brit defaultism?reply"
    ],
    "link": "https://sqliteonline.com/",
    "first_paragraph": "\n\nMemory\nOpFS\n\n\n \u2192 \"Create SQLite DB\"\n                            I recommend using the latest version of Chrome for OpFS\n\n\nIndexDB\nMemory\n\n\n\n                            - clear old(30+ day) db history\n                        \n                            * \u0441lose all other tabs with this site open, then refresh the page.\n                        \n\nSilver\nPurplish\nMil\nAntique Brass\nBlue Steel\nIndigo\nTangerine\nPink\nFrost\nDark\nNight\nRosewater Elegance\nGolden Night\nArctic Dawn\nOnyx Velvet\nSandalwood\nDark Mocha\nAurora\nObsidian\nMidnight\nUser color\n\n\n Color settings \n\n                            Hover cell\n                            \nNone\nAnimation\nRectangle\n\n\n                            Format number\n                            \nNone\nLeft\nRight\nL_\n_R\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n                        EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n                        OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEM"
  },
  {
    "title": "JIT: So you want to be faster than an interpreter on modern CPUs (pinaraf.info)",
    "points": 82,
    "submitter": "pinaraf",
    "submit_time": "2025-10-12T19:08:41 1760296121",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=45560863",
    "comments": [
      "From the previous article in the series, it looks like the biggest impediment to just using full llvm to compile the query is that they didn't find a good way to cache the results across invocations.Sql server hekaton punted this problem in a seemingly effective way by requiring the client to use stored procedures to get full native compilation. Not sure though if they recompile if the table statistics indicate a different query plan is needed.reply",
      "> This is called branch prediction, it has been the source of many fun security issues...No, that's speculative execution you just described. Branch prediction was implemented long before out-of-order CPUs were a thing, as you need branch prediction to make the most of pipelining (eg. fetching and decoding a new instruction while you're still executing the previous one--if you predict branches, you're more likely to keep the pipeline full).reply",
      "Speculative execution does not require out-of-order execution. When you predict a branch, you're speculatively executing the predicted branch. Whether you're doing it in the same order as instruction order or out of order is independent of that.reply",
      "A shame operating systems like iOS/iPadOS do not allow JIT. iPad Pro's have such fast CPU's that you cant even use fully because of decisions like this.reply",
      "Those operating systems allow it, but Apple does not. Agree that it is a total waste.reply",
      "What advantage does JIT compilation have over Swift or Obj-C?reply",
      "It speeds up interpreted languages.reply",
      "And emulation.reply",
      "What is an architecture but a scripting language to interpret? ;)reply",
      "Good read. But a word of caution - the \"JIT vs interpreter\" comparisons often favor the interpreter when the JIT is inplemented as more-or-less simple inlining of the interpreter code. (Here called \"copy-and-patch\" but a decades-only approach). I've had fairly senior engineers try to convince me that this is true even for Java VMs. It's not in general, at least not with the right kind of JIT compiler design.reply"
    ],
    "link": "https://www.pinaraf.info/2025/10/jit-so-you-want-to-be-faster-than-an-interpreter-on-modern-cpus/",
    "first_paragraph": "Pinaraf's website\n\t\t\t\tJust another geek\t\t\tHiSince my previous blog entry about JIT\u00a0compiler for PostgreSQL, sadly not much happened due to a lack of time, but still some things were done (biggest improvement was the port to ARM64, a few optimizations, implementing more opcodes\u2026). But I am often asking myself how to really beat the interpreter\u2026 And on \u201cmodern\u201d CPUs, with a well written interpreter, that\u2019s far more complicated than many would imagine. So in order to explain all this and show how I am planning to improve performance (possibly of the interpreter itself too, thus making this endeavor self-defeating), let\u2019s first talk about\u2026If you already know about all the topics mentioned in this title, feel free to jump to the next section. Note that the following section is over-simplified to make the concepts more accessible.I am writing this blog post on a Zen 2+ CPU. If I upgraded to a Zen 3 CPU, same motherboard, same memory, I would get an advertised 25% performance jump in single t"
  },
  {
    "title": "Modern iOS Security Features \u2013 A Deep Dive into SPTM, TXM, and Exclaves (arxiv.org)",
    "points": 103,
    "submitter": "todsacerdoti",
    "submit_time": "2025-10-13T18:23:15 1760379795",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45571688",
    "comments": [
      "SEAR and the Apple team does an excellent job of security on iOS, and should be commended greatly on that.Not only are they willing to develop hardware features and plumb that throughout the entire stack, they're willing to look at ITW exploits and work on ways to mitigate that. PPL was super interesting, they decided it wasn't 100% effective so they ditched it and came up with other thigs.Apple's vertical makes it 'easy' to do this compared to Android where they have to convince the CPU guys at QC or Mediatek to build a feature, convince the linux kernel to take it, get it in AOSP, get it in upstream LLVM, etc etc.Pointer authentication codes (PAC) is a good example, Apple said f-it we'll do it ourselves. They maintained a downstream fork of LLVM, and built full support, leveraged in the wild bypasses and fixed those up.reply",
      "One of the knock on benefits of this too is increased security across all platforms as long as someone exercises that code path on one of apples new processors with a hardened runtime.In theory it makes it easier to catch stuff that you can\u2019t simply catch with static analysis and it gives you some level of insight beyond simply crashing.reply"
    ],
    "link": "https://arxiv.org/abs/2510.09272",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Accidentally Made a Zig Dotenv Parser (dayvster.com)",
    "points": 19,
    "submitter": "ibobev",
    "submit_time": "2025-10-08T17:39:00 1759945140",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://dayvster.com/blog/accidentally-made-a-zig-dotenv-parser/",
    "first_paragraph": "Recently I\u2019ve made a Zig based CLI argument parser called argh I\u2019ve even written myself a roadmap I\u2019d like to follow with this project. And so far I have been following it pretty well. However last week I began working on the next item on my roadmap which was to add support for environment variables to the arg parser, where you could set an environment variable to set the value of a flag.Not many use cases for it I know it\u2019s more of an edge case but I thought it would be a fun exercise to implement that. So I started working on it. I carefully scaffolded out the feature what functions I\u2019d like to see in it how they should behave what guard rails I\u2019d like to set to ensure type safety, memory safety, and so on.As I was implementing all the things I scaffolded out one by one I realized that I was basically writing a fully fledged dotenv parser. And I thought to myself \u201chey this is pretty cool I should probably make this a separate library so other people can use it too\u201d and it\u2019s not deepl"
  },
  {
    "title": "Strudel REPL \u2013 a music live coding environment living in the browser (strudel.cc)",
    "points": 87,
    "submitter": "birdculture",
    "submit_time": "2025-10-13T18:37:34 1760380654",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=45571822",
    "comments": [
      "Can it make music like e.g. Extempore (see https://www.youtube.com/playlist?list=PL_eJ0XdLbWzzq_03wTIMV...)?All examples I've heard from Strudel so far are pretty boring (constant beat/chord machine music).reply",
      "Oh and there is flok[1] which combines the strudel repl with visuals from hydra. Also there are sclang and other algorave environments available.  Everything is synced (with crdts i guess) so it\u2019s live collaborative. Which is nice to remotely jam with friends[1] https://flok.ccreply",
      "There are some pretty amazing live coding sessions of Strudel on YouTube. Some examples:https://www.youtube.com/watch?v=HkgV_-nJOuEhttps://www.youtube.com/watch?v=HkgV_-nJOuEreply",
      "This was one of my favorites -- with the voice filter the narration feels like it's part of the song which I found especially fun.https://www.youtube.com/watch?v=GWXCCBsOMSgreply",
      "That channel has been all over my recommendations, it's awesome so much skill!reply",
      "Switch Angel is awesome. She also has some Instagram tutorials.reply",
      "So random seeing her mentioned here today. I just discovered her yesterday, saw a Youtube short where she's operating a Eurorack synth at Switched On in Austin, TX. It's a cool little synth shop that's worth checking out if you're ever in town. Looks like they've moved locations recently though.reply",
      "Dj Dave is the other creator I've found doing strudel content.https://youtu.be/E1K6Sv-oIb0reply",
      "You accidentally pasted the same link twice. What was the second link meant to be? Would like to see it also :)reply",
      "Strudel is a JavaScript port of TidalCycles (Haskell). While TC uses SuperCollider for the synthesis, Strudel uses superdough which seems to be a custom implementation. I'm currently learning SuperCollider sclang and waiting for a version upgrade to have a reason to submit it here - usually some of the discussion is quite insightful. Anyway sclang is the PHP of music - just uglier and less consistent. But it's also powerful and and quite fun.reply"
    ],
    "link": "https://strudel.cc",
    "first_paragraph": ""
  },
  {
    "title": "LLMs are getting better at character-level text manipulation (burkert.me)",
    "points": 36,
    "submitter": "curioussquirrel",
    "submit_time": "2025-10-13T19:39:14 1760384354",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=45572478",
    "comments": [
      "Why bother testing though? I was hoping this topic has finally died recently, but no. Someone's still interested in testing LLMs for something they're explicitly not designed for and nobody is using them for this in practice. I really hope one day openai will just add a \"when asked about character level changes, insights and encodings, generate and run a program to answer it\" to their system so we can never hear about it again...reply",
      "I think the base64 decoding is interesting: in a sense, model training set likely had lots of base64-encoded data (imagine MIME data in emails, JSON, HTML...), but for it to decode successfully, it had to learn decode sequences for every 4 base64 characters (which turn into 3 bytes). This could have been generated as a training set data easily, and I only wonder if each and every one was them was found enough times to end up in the weights?reply",
      "I play Quartiles in Apple News app daily (https://support.apple.com/guide/iphone/solve-quartiles-puzzl...). Occasionally when I get stuck, I use ChatGPT to find a word that uses four word fragments or tiles. It never worked before GPT 5. And with GPT 5 it works only with reasoning enabled. Even then, there is no guarantee it will find the correct word and may end up hallucinating badly.reply",
      "If you take a look at the system prompt for Claude 3.7 Sonnet on this page you'll see: https://docs.claude.com/en/release-notes/system-prompts#clau...> If Claude is asked to count words, letters, and characters, it thinks step by step before answering the person. It explicitly counts the words, letters, or characters by assigning a number to each. It only answers the person once it has performed this explicit counting step.But... if you look at the system prompts on the same page for later models - Claude 4 and upwards - that text is gone.Which suggests to me that Claude 4 was the first Anthropic model where they didn't feel the need to include that tip in the system prompt.reply",
      "Does that mean they've managed to post train the thinking steps required to get these types of questions correct?reply",
      "That's my best guess, yeah.reply",
      "Or they\u2019d rather use that context window space for more useful instructions for a variety of other topics.reply",
      "Claude's system prompt is still incredibly long and probably hurting its performance.https://github.com/asgeirtj/system_prompts_leaks/blob/main/A...reply",
      "chatgpt5 still is pathetically bad at roman numerals. I asked it to find the longest roman numeral in a range. first guess was the highest number in the range despite being a short numeral. second guess after help was a longer numeral but outside the range. last guess was the correct longest numeral but it miscounted how many characters it contained.reply"
    ],
    "link": "https://blog.burkert.me/posts/llm_evolution_character_manipulation/",
    "first_paragraph": "Recently, I have been testing how well the newest generations of large language models (such as GPT-5 or Claude 4.5) handle natural language, specifically counting characters, manipulating characters in a sentences, or solving encoding and ciphers. Surprisingly, the newest models were able to solve these kinds of tasks, unlike previous generations of LLMs.LLMs handle individual characters poorly. This is due to all text being encoded as tokens via the LLM tokenizer and its vocabulary. Individual tokens typically represent clusters of characters, sometimes even full words (especially in English and other common languages in the training dataset). This makes any considerations on a more granular level than tokens fairly difficult, although LLMs have been capable of certain simple tasks (such as spelling out individual characters in a word) for a while.To demonstrate just how poorly earlier generations handled basic character manipulation, here are responses from several OpenAI models for"
  },
  {
    "title": "Hackers can steal 2FA codes and private messages from Android phones (arstechnica.com)",
    "points": 30,
    "submitter": "sipofwater",
    "submit_time": "2025-10-13T23:49:55 1760399395",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=45574613",
    "comments": [
      "> Requires a victim to first install a malicious app on an Android phone or tabletAs Raymond Chen/Old New Thing likes to say this rather requires being on the other side of this airtight hatchway.  You can allow apps to do things on your device.reply",
      "That the app does not require permissions is the notable bit here. I do not know the mobile system, but I thought apps were supposed to be firewalled from each other unless given explicit grants.The obvious joke, how long has Facebook been using this exploit?reply",
      "Several preinstalled bloatware stores such as Galaxy Store, Moto apps and so forth will default to opt-in to automatically installing 'recommended apps and games' - essentially spyware garbage they get kickbacks from - in the background, plus several flagship phones now come with Temu preinstalled.The 90% of non technically-savvy Android users are 100% exposed to the OP exploit.reply",
      "The app needs to be opened by the user for the exploit to work, as it was told by the researchers, so the surface attack is big but not that big as you may be imaging.reply",
      "It also requires that whatever information the attacker is looking for has been displayed on the screen, so for example  my banking app (like most banking apps I guess) masks my 4 digit passcode with asterisks so it is likely safe from this specific attackPD: I just checked and it also doesn't change the color of the pressed keys or any other visual feedback that an attacker might use.reply",
      "> The new attack, named Pixnapping by the team of academic researchers who devised it, requires a victim to first install a malicious app on an Android phone or tablet.I think it speaks about the security of Android that this makes the news. Coming from Windows, Android always felt as a MUCH more secure Operating System, not just a similar quality Operating System with touch controls and support for smaller hardware.reply",
      "It can happen quickly. The app itself might be legit, but it may be based in a SDK which is either malicious or compromised.reply",
      "And there are a lot of automatically installed junk apps on most phones. And every OTA update seems to add more.reply",
      "https://0x0.st/XJZT.jpgreply",
      "In other news, there are substances in the household that are so dangerous that it can can kill you.First it requires the user take buckets of ammonia and bleach and mix them together.reply"
    ],
    "link": "https://arstechnica.com/security/2025/10/no-fix-yet-for-attack-that-lets-hackers-pluck-2fa-codes-from-android-phones/",
    "first_paragraph": "\n        Malicious app required to make \"Pixnapping\" attack work requires no permissions.\n      Android devices are vulnerable to a new attack that can covertly steal 2FA codes, location timelines, and other private data in less than 30 seconds.The new attack, named Pixnapping by the team of academic researchers who devised it, requires a victim to first install a malicious app on an Android phone or tablet. The app, which requires no system permissions, can then effectively read data that any other installed app displays on the screen. Pixnapping has been demonstrated on Google Pixel phones and the Samsung Galaxy S25 phone and likely could be modified to work on other models with additional work. Google released mitigations last month, but the researchers said a modified version of the attack works even when the update is installed.Pixnapping attacks begin with the malicious app invoking Android programming interfaces that cause the authenticator or other targeted apps to send sensiti"
  },
  {
    "title": "Abstraction, not syntax (ruudvanasseldonk.com)",
    "points": 61,
    "submitter": "unripe_syntax",
    "submit_time": "2025-10-13T08:45:49 1760345149",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=45566198",
    "comments": [
      "To me the solution seems like it's adding complexity that could cause more issues further down the line.The specific problems in the example could be solved by changing how the data is represented. Consider the following alternative representation, written in edn:    {:aws.s3/buckets\n     {:aws.region/eu-west\n      {:alpha-hourly  {:lifecycle/policy {:delete-after #interval/days 4}}\n       :alpha-daily   {:lifecycle/policy {:delete-after #interval/days 30}}\n       :alpha-monthly {:lifecycle/policy {:delete-after #interval/days 365}}\n\n       :bravo-hourly  {:lifecycle/policy {:delete-after #interval/days 4}}\n       :bravo-daily   {:lifecycle/policy {:delete-after #interval/days 30}}\n       :bravo-monthly {:lifecycle/policy {:delete-after #interval/days 365}}}}}\n\nThis prevents issues where the region is mistyped for a single bucket, makes the interval more readable by using a custom tag, and as a bonus prevents duplicate bucket names via the use of a map.Obviously this doesn't prevent all errors, but it does prevent the specific errors that the RCL example solves, all without introducing a Turing-complete language.reply",
      "I don't think the title and the article really communicates it's case well. Did not understand the goal until 90% through the article when they showed the source code of RCL with the loops.This isn't syntax vs abstraction. This is how much programming language power do you want to enable in your configuration language. This is a big difference and I think we miss the interesting part of that discussion because we dip into this 'abstraction angle.reply",
      "Really wish people would just bite the bullet and do configuration as code instead of trying to make all these config petlangs.reply",
      "I appreciate that the ts/js ecosystem seems to be moving in this general direction.Lots of config.json is being replaced by the nicer config.ts.reply",
      "I really dislike it when a turing-complete language is used for configuration. It almost always breaks every possibility to programmatically process or analyze the config. You can't just JSON.parse the file and check it.Also I've been in projects where I had to debug the config multiple levels deep, tracking side-effects someone made in some constructor trying to DRY out the code. We already have these issues in the application itself. Lets not also do that in configurations.reply",
      "This is what's nice about Pkl, you define a schema as a Pkl file, you define a value of that schema as a Pkl file that imports the schema, `pkl eval my file.pkl` will do the type check and output yaml for visual inspection or programmatic processing, but keeping it to one file per module means that I almost never obsessively D-R-Y my Pkl configs.Actually that's not the biggest benefit (which is tests for schemas) but it's nice to have the \u201c.ts\u201d file actually log the actual config as JSON and then the app consumes it as JSON, rather than importing the .ts file and all its dependencies and having weird things like \u201cthis configuration property expects a lambda.\u201dreply",
      "That's why Starlark exists.You need something between JSON/YAML and Python/JavaScript.A config language makes the possibility space small.It also makes it deterministic for CI and repeatable builds.It also makes it parallelizable and cacheable.Don't use your language for config. People will abuse it. Use a config language like Starlark or RCL.reply",
      "My preference is towards simpler formats like:  option value\n\nEasy to edit and manipulate. JSON and YAML is always a nightmare if it's user facing. As for ansible, I'd love to see some scheme/lisp variants.reply",
      "Exactly.  Emacs Lisp is an existence proof that this can be done well.reply",
      "You beat me to it!And for those that haven't taken a look at it, the \"customize\" menu and everything it supports is silly impressive.  And it just writes out the results out, like a boss.** Obviously, it has a lot of \"don't edit below this line\" complexity to it.  But that doesn't change that it is right there.reply"
    ],
    "link": "https://ruudvanasseldonk.com/2025/abstraction-not-syntax",
    "first_paragraph": "written by Ruud van Asseldonkpublished 12 October 2025The world is growing tired of yaml. Alternative configuration formats are making the rounds. Toml has steadily been gaining traction, in part due to tools like Cargo and adoption in the Python standard library. Json supersets (with comments, commas, and the digit 5) are flourishing, while KDL, kson and now maml promise to hit the sweet spot between friendly and simple.While I do believe that yaml is harmful, all of the simpler formats are basically fine, and their differences are mostly superficial. The one real difference is in their data models. Most formats adopt the json data model of objects and arrays, while KDL, HCL, and e.g. Nginx adopt the XML data model of named nodes with attributes and children. The rest is just syntax. And yes, syntax does matter, but line noise is not the real problem here!Let\u2019s look at an example: suppose we need to define cloud storage buckets to store backups. We want to back up two databases: Alpha"
  },
  {
    "title": "Dutch government takes control of Chinese-owned chipmaker Nexperia (cnbc.com)",
    "points": 284,
    "submitter": "piskov",
    "submit_time": "2025-10-13T10:03:11 1760349791",
    "num_comments": 221,
    "comments_url": "https://news.ycombinator.com/item?id=45566644",
    "comments": [
      "Europe's projected semiconductor manufacturing equipment expenditure from 2026-2028 is a rounding error.Global expenditure on 300mm fab equipment from 2026-2028 is predicted to be USD$374bn with regional breakdown as follows (totaling 100%):China - USD$95bn (25%)South Korea - USD$86bn (23%)Taiwan - USD$75bn (20%)Americas - USD$60bn (16%)Japan - USD$32bn (9%)Europe and Middle East - USD$14bn (4%)Southeast Asia - USD$12bn (3%)[1] https://www.semi.org/en/semi-press-release/semi-reports-glob...reply",
      "Some more context from a dutch news source[0]:The ministry of economic affairs intervened out of a fear that crucial technological skills and capacities will leave the Netherlands and Europe. The ministry stated in a press release[1] that there was a threat of a \"knowledge leak\" (w/e that means exactly) and a possible threat to the European economy.After this intervention the Dutch government can now stop or reverse decisions within the company. That's only allowed if those decisions are harmful to the interests of the company, or for the future of the company as a Dutch or European business, or to the retaining of this crucial value chain for europe.The company can appeal this decision in court.For context, the law that allows this all to happen was passed in 1952 and has never before been used. As much as I think our government is currently ran by a bunch of nincompoops, I am inclined to believe that something quite significant was about to happen for this law to get invoked. What exactly that was can for now only be speculated about.I can recommend you run google translate (or equivalent) on the press release. It's as close as you can get to the source of this news for now. I can only imagine the government is going to be having plenty of debates on the topic coming up, seeing as this is a very rare use of a very heavy-handed tool.[0] https://nos.nl/artikel/2586270-kabinet-grijpt-hard-in-bij-ch...[1] https://www.rijksoverheid.nl/actueel/nieuws/2025/10/12/wet-b...reply",
      "Everybody is a fan of free access and capital markets, until a foreign entity purchases something of importance.It\u2019s a continuation of recent trends and closing markets.Nobody in their sane mind would allow a company like ASML or the likes to be purchased by competitors.But the irony is that when a non-European entity were to do something like this, e.g. nationalize their oil or mining etc. industry or a firm, the whole hell would brake loose.reply",
      ">But the irony is that when a non-European entity were to do something like this, e.g. nationalize their oil or mining etc. industry or a firm, the whole hell would brake loose.\"We live in a \"Rules Based Order\" - one rule for thee, another one for me.reply",
      "> But the irony is that when a non-European entity were to do something like this, e.g. nationalize their oil or mining etc. industry or a firm, the whole hell would brake loose.As far as I understand, Samsung, TSMC, and SMIC are all closely guarded by their respective governments. And China doesn't (didn't?) allow foreign companies to operate in China without a local partner at all. So I don't see the irony - everyone practices protectionism, some are just more subtle about it than others. Some China-specific examples:tmnvix points out the perfectly analogous Chinese restriction of rare earth exports: https://news.ycombinator.com/item?id=45572420China imposes more trade and investment barriers, discriminatory taxes, and information security restrictions than any other country by a vast margin. - https://ecipe.org/wp-content/uploads/2017/06/DTE_China_TWP_R...As with most countries, China has adopted some policies aimed at protecting or promoting its domestic industries, including targeted quotas, subsidies to certain key industries and rejection of patents in critical industries. - https://www.rfa.org/english/news/afcl/fact-check-china-prote...https://en.wikipedia.org/wiki/Made_in_China_2025 - government plan with securing first local, and the global key markets, for indigenous firms, the acquisition of foreign technology companies, and independence from foreign suppliers, as explicit goals.reply",
      "I said it that way because I don\u2019t like the hypocrisies in general, and I said European because the comment I responded to combined Dutch and European markets into one.It would be foolish to sell off a great value like ASML or others that adds incredible value. But one should also not get mad when other countries do it, because they see their industries as valuable things as well.Our markets are just getting more closed and different groups are being formed. Let\u2019s hope other high value companies gather their IP rights as well.reply",
      "What about the suez canal or iranian oil fieldsreply",
      "What about them? The claim, or rather implication, was that Western powers would never allow equivalent protectionist policies, such as preventing the export of key industries and skills, to be enacted by other countries. Yet such protectionism is routine in China (and many other Asian countries), and \"whole hell\" did not break loose.A few more than half century old examples don't change what we can all see is the case in the present day.reply",
      "The British, French and Israelis literally went to war against Egypt over the Suez.They only backed up when the US told the Brits and France they would tank their economies still on US life support.And, pray, why did the Machado win the hypocrisy prize on Friday? Why are American ships outside the waters of Venezuela?reply",
      ">The British, French, and Israelis literally went to war against Egypt over the Suez.The British and the French were concerned about the Suez, but Israel was not dependent on the Suez and went to war over their navigation being blockaded by Egypt in the Gulf of Aqaba and the Straits of Tiran, which was a violation by Egypt of maritime law. Aqaba is in the Sinai peninsula which is also bounded by the Suez.https://en.wikipedia.org/wiki/Israeli_passage_through_the_Su...reply"
    ],
    "link": "https://www.cnbc.com/2025/10/13/dutch-government-takes-control-of-chinese-owned-chipmaker-nexperia.html",
    "first_paragraph": ""
  },
  {
    "title": "JSON River \u2013 Parse JSON incrementally as it streams in (github.com/rictic)",
    "points": 152,
    "submitter": "rickcarlino",
    "submit_time": "2025-10-08T16:38:43 1759941523",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=45518033",
    "comments": [
      "Hi HN! Didn't expect this to be on the front page today! I should really release all the optimizations that've been landing lately, the version on github is about twice as fast as what's released on npm.I wrote it when I was doing prototyping on doing streaming rendering of UIs defined by JSON generated by LLMs. Using constrained generation you can essentially hand the model a JSON serializable type, and it will always give you back a value that obeys that type, but the big models are slow enough that incremental rendering makes a big difference in the UX.I'm pretty proud of the testing that's gone into this project. It's fairly exhaustively tested. If you can find a value that it parses differently than JSON.parse, or a place where it disobeys the 5+1 invariants documented in the README I'd be impressed (and thankful!).This API, where you get a series of partial values, is designed to be easy to render with any of the `UI = f(state)` libraries like React or Lit, though you may need to short circuit some memoization or early exiting since whenever possible jsonriver will mutate existing values rather than creating new ones.reply",
      "I've just published v1.0.1. It's about 2x faster, and should have no other observable changes. The speedup is mainly from avoiding allocation and string slicing as much as possible, plus an internal refactor to bind the parser and tokenizer more tightly together.Previously the parser would get an array of tokens each time it pushed data into the tokenizer. This was easy to write, but it meant we needed to allocate token objects. Now the tokenizer has a reference to the parser and calls token-specific methods directly on it. Since most of the tokens carry no data, this keeps us from jumping all over the heap so much. If we were parsing a more complicated language this might become a huge pain in the butt, but JSON is simple enough, and the test suite is exhaustive enough, that we can afford a little nightmare spaghetti if it improves on speed.reply",
      "I want to ditch stream-json so hard (needs polyfills in browser, cumbersome to use), but I need only one feature: invoke callback by path (e.g. `user.posts` need to invoke for each post in array) only for complete objects. Is this something that json river can support?reply",
      "jsonriver's invariants do give you enough info to notice which values are and aren't complete. They also mean that you can mutate the objects and arrays it returns to drop data that you don't care about.There might be room for some helper functions in something like a 'jsonriver/helpers.js' module. I'll poke around at it.reply",
      "Suggestion: make it clearer in the readme what happens with malformed input.I can imagine it being useful to have a made where you never emit strings until they are final, also. I don't entirely understand why strings are emitted incrementally but numbers aren't.reply",
      "Seems useful to me in the context of something like a progressively rendered UI. A large block of text appearing a few characters at a time would be fine, but a number that represents something like a display metric (say, a position, or font-size) going from 0 to 0.5 or from 1 to 1000, would result in goofy gyrations on-screen that don't make any sense. Or imagine if it was just fields in the app's data.Name: John Smith. Birth Year: A.D. 1 [Customer is a Senior: 2,024 years old]Name: John Smith. Birth year: A.D. 19 [Customer is a Senior: 2,006 years old]Name: John Smith. Birth year: A.D. 199 [Customer is a Senior: 1,826 years old]Name: John Smith. Birth year: 1997reply",
      "Good feedback! Just updated the README with the following:> The parse function also matches JSON.parse's behavior for invalid input. If the input stream cannot be parsed as the start of a valid JSON document, then parsing halts and an error is thrown. More precisely, the promise returned by the next method on the AsyncIterable rejects with an Error. Likewise if the input stream closes prematurely.As for why strings are emitted incrementally, it's just that I was often dealing with long strings produced slowly by LLMs. JSON encoded numbers can be big in theory, but there's no practical reason to do so as almost everyone decodes them as 64bit floats.reply",
      "For those wondering about the use case, this is very useful when enabling streaming for structured output in LLM responses, such as JSON responses. For my local Raspberry Pi agent I needed something performant, I've been using streaming-json-js [1], but development appears to have been a bit dormant over the past year. I'll definitely take a look at your jsonriver and see how it compares![1] https://github.com/karminski/streaming-json-jsreply",
      "For LLMs I recommend just doing NDJSON, that is, newline delimited json. It's much simpler to implementreply",
      "Do any LLMs support constrained generation of newline delimited json? Or have you found that they're generally reliable enough that you don't need to do constrained sampling?reply"
    ],
    "link": "https://github.com/rictic/jsonriver",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A simple, fast streaming JSON parser built on standards.\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Parse JSON incrementally as it streams in, e.g. from a network request or a language model. Gives you a sequence of increasingly complete values.jsonriver is small, fast, has no dependencies, and uses only standard features of JavaScript so it works in any JS environment.Usage:What does it mean that we give you a sequence of increasingly complete values? Consider this JSON:If you gave this to jsonriver one byte at a time it would yield this sequence of values:The final value yielded by parse will be the same as if you had called JSON.parse on the entire string. This is tested against the JSONTestSuite, matching JSON.parse's behavior on tests of correct, i"
  },
  {
    "title": "Uv overtakes pip in CI (wagtail.org)",
    "points": 143,
    "submitter": "ThibWeb",
    "submit_time": "2025-10-06T12:45:51 1759754751",
    "num_comments": 110,
    "comments_url": "https://news.ycombinator.com/item?id=45490775",
    "comments": [
      "This shouldn\u2019t be a surprise to anyone who has been using Python and has tried uv.Python dependency management and environments have been a pain for 15 years. Poetry was nice but slow and sometimes difficult.Uv is lightning fast and damn easy to use. It\u2019s so functional and simple.reply",
      "For me the most convincing argument was that it took ~3 minutes to go from 'I wonder if I should give this thing a try' to 'oh it .... it worked!?'reply",
      "Yeah, been doing this for over twenty years and finally got a chance to start playing with it a few months back and was confused at how I got that far that fast.reply",
      "As someone who also hasn't really used any of the past 8 years or so of Python dependency management, it's nice that it seems to support using arbitrary other tooling as well. At some point recently I wanted to run something that happened to use pdm, which I hadn't even heard of, but I was able to invoke it with `uv tool run pdm` and not have to learn anything about how to set it up manually.reply",
      "It really is!I switched to using uv just 2 weeks ago. Previously I had been dealing with maintaining a ton of batch jobs that used: global packages (yes, sudo pip install), manually managed virtualenvs, and docker containers.uv beats all of them easily. Automatically handling the virtualenv means running a project that uses uv feels as easy as invoking the system Python is.reply",
      "It\u2019s a little too fast, I\u2019m having trouble believing it\u2019s actually doing anything sometimes.reply",
      "uv is so over-the-top fast compared to what we're used to that I would argue it's actually bad for the language. Suddenly it dawns on you that by far the most capable and performant package manager (and linter) (and code formatter) (and type checker) for Python is in fact not written in Python. Leaves an odd taste. Makes you wonder what else ought not be written in Python ... or why anything should be written in Python. Here be dragons ...reply",
      "Try not to cut yourself while grinding that axe.Python may not be the fastest language, but it's easy to learn, compilation times aren't an issue, you'll never have to fight the borrow checker, etc.Every language has its warts.reply",
      "for me the surprise is the pace? I\u2019d expect people to be more set in their tools that it takes longer than a few months for a new tool, no matter how good, to become the majority use one. Though perhaps people adopt new tools more easily in CI where install times matter morereply",
      "The pace of uv adoption is insanely fast. It's directly related to how bad the previous Python tools were/are. Even to seasoned veterans set in their ways - they still know a better solution when they see it.reply"
    ],
    "link": "https://wagtail.org/blog/uv-overtakes-pip-in-ci/",
    "first_paragraph": "All about WagtailWhat Wagtail offersOur plans for future releasesOur leading contributorsMaking Wagtail work for everyoneReducing the climate impact of WagtailHow to get in touchGive Wagtail a goHow to find help for WagtailRead the docs. Learn the code.Explore the Wagtail codeHow to create Wagtail contentExtend Wagtail with Wagtail packagesPower up your content with AICheck out Wagtail LocalizeHeadless or traditional Wagtail? You choose.A new release ships every 3 monthsThe most common Wagtail questionsThe latest Wagtail newsThis Week in WagtailJoin our Slack communityMeet up with other WagtailersOur community commitmentsThese organisations trust WagtailExplore amazing projects built with WagtailWhy Wagtail is great for public institutionsWhy Wagtail is great for mission-driven organizationsWhy Wagtail is great for museums, libraries, and moreWhy Wagtail is great for academic institutionsWhy Wagtail is great for businessesA CMS-to-CMS comparisonA CMS-to-CMS comparisonGet expert help wi"
  },
  {
    "title": "Scaling request logging with ClickHouse, Kafka, and Vector (geocod.io)",
    "points": 99,
    "submitter": "mjwhansen",
    "submit_time": "2025-10-08T09:56:25 1759917385",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=45514213",
    "comments": [
      "Great write-up!I had a similar project back in August when I realised my DB's performance (Postgres) was blocking me from implementing features users commonly ask for (querying out to 30 days of historical uptime data).I was already blown away at the performance (200ms to query what Postgres was doing in 500-600ms), but then I realized I hadn't put an index on the Clickhouse table. Now the query returns in 50-70ms, and that includes network time.reply",
      "Sai from ClickHouse here. Very compelling story! Really love your emphasis on using the right tool for the right job - power of row vs column stores.We recently added a MySQL/MariaDB CDC connector in ClickPipes on ClickHouse Cloud. This would have simplified your migration from MariaDB.https://clickhouse.com/docs/integrations/clickpipes/mysql\nhttps://clickhouse.com/docs/integrations/clickpipes/mysql/so...reply",
      "BTW you could've used e.g. kittenhouse (https://github.com/YuriyNasretdinov/kittenhouse, my fork) or just a simpler buffer table, with 2 layers and a larger aggregation period than in the example.Alternatively, you could've used async insert functionality built into ClickHouse: https://clickhouse.com/docs/optimize/asynchronous-inserts . All of these solutions are operationally simpler than Kafka + Vector, although obviously it's all tradeoffs.reply",
      "There were a lot of simpler options that came to mind while reading through this, frankly.But I imagine the writeup eschews myriad future concerns and does not entirely illustrate the pressure and stress of trying to solve such a high-scale problem.Ultimately, going with a somewhat more complex solution that involves additional architecture but has been tried and tested by a 3rd party that you trust can sometimes be the more fitting end result. Assurance often weighs more than simplicity, I think.reply",
      "While kittenhouse is, unfortunately, abandonware (even though you can still use it and it works), you can't say the same about e.g. async inserts in ClickHouse: it's a very simple and robust solution to tackle exactly the problem the PHP (and some other languages') backends often face when trying to use ClickHousereply",
      "Yes, had similar questions. Wouldn't tuning the settings for the buffer table have helped avoid the TOO_MANY_LINKS error?reply",
      "1) clickhouse async_insert would have solved all your issues: https://clickhouse.com/docs/optimize/asynchronous-inserts1a) If you\u2019re still having too many files/parts, then fix your partition by, and mergetree primary key.2) why are you writing to kafka when vector dev does buffering / batching?3) if you insist on kafka, https://clickhouse.com/docs/engines/table-engines/integratio... consumes directly from kafka (or since you\u2019re on CHC, use clickhouse pipes) \u2014 what\u2019s the point of vector here?Your current solution is unnecessarily complex. I\u2019m guessing the core problem is your merge tree primary key is wrong.reply",
      "Writing to Kafka allowed them to continue their current ingestion process into MariaDB at the same time as ClickHouse. Kafka consumer groups allow the data to be consumed twice by different consumer pools that have different throughput without introducing bottlenecks.From experience the Kafka tables in ClickHouse are not stable at a high volumes, and harder to debug when things go sideways. It is also easier to mutate your data before ingestion using Vector's VRL scripting language vs. ClickHouse table views (SQL) when dealing with complex data that needs to be denormalized into a flat table.reply",
      "> Writing to Kafka allowed them to continue their current ingestion process into MariaDB at the same time as ClickHouse.The one they're going to shut down as soon as this works? Yeah, great reason to make a permanent tech choice for a temporary need. Versus just keeping the MariaDB stuff exactly the same on the PHP side and writing to 2 destinations until cutover is achieved. Kafka is wholly unnecessary here. Vector is great tech but likely not needed. Kafka + Vector is absolutely the incorrect solution.Their core problem is the destination table schema (which they did not provide) and a very poorly chosen primary key + partition.reply",
      "Thanks for sharing. I really enjoyed the breakdown, and great to see small tech companies helping each other out!reply"
    ],
    "link": "https://www.geocod.io/code-and-coordinates/2025-10-02-from-millions-to-billions/",
    "first_paragraph": "How we solved request logging at scale by moving from MariaDB to ClickHouse, Kafka, and Vector after our deprecated database engine couldn't keep up with billions of monthly requests.This article is based on a talk that I gave at PHP[tek] in 2025.Geocodio offers a pay-as-you-go metered plan where users get 2,500 free geocoding lookups per day. This means we need to:This isn't just nice-to-have data. It's tied directly to our billing and customer support workflows.Our initial setup was pretty straightforward:We were using MariaDB with the TokuDB storage engine, which was specifically designed for high-performance insert operations with incredibly good compression\u2014often 5 to 10 times better than InnoDB. When you're dealing with billions of records, storage efficiency matters.Here's what our request tracking table looked like:Notice that table name\u2014requests_2020_05. We don't keep one massive table. Instead, we partition by year and month, making it easy to roll over month after month and "
  },
  {
    "title": "StreamingVLM: Real-Time Understanding for Infinite Video Streams (arxiv.org)",
    "points": 4,
    "submitter": "badmonster",
    "submit_time": "2025-10-14T00:02:18 1760400138",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://arxiv.org/abs/2510.09608",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Don't Be a Sucker (1943) [video] (youtube.com)",
    "points": 273,
    "submitter": "surprisetalk",
    "submit_time": "2025-10-13T20:31:47 1760387507",
    "num_comments": 81,
    "comments_url": "https://news.ycombinator.com/item?id=45573025",
    "comments": [
      "I love that this was US propaganda at one point.The US always has failings, but this message is something we can be proud of.reply",
      "Except for the endorsement of littering, which fit the time period.It would be decades before they wheeled out a crying native american on TV to make people feel guilty about the matter(s).reply",
      "Italian*reply",
      "Is it still true that Americans find it hard to see how this is very clearly propaganda?Yes, it's anti-Nazi but it's still has very obvious problems.reply",
      "It is literally propaganda. Very good propaganda with a very good and truthful message. (Except maybe a bit of too much idealizing the US and also the role of the catholic church but the main point is fine.)I guess the confusion is because in  Western societies people are used to the doublespeak of only calling something propaganda when it is done by the \"other side\". The other side is \"spreading the narrative\" you are \"reporting facts\".You use different words to describe the same thing. Like the good guys are \"rebels\" and the bad guys are \"terrorists\".There is nothing wrong with propaganda. It can be used for good or bad. Just don't start falling for your own one.reply",
      "Well, the standard definition of propaganda is that it is false and misleading \n:> information, especially of a biased or misleading nature, used to promote a particular cause, doctrine, or point of view.Which I think most people consider bad. If the information is true and not misleading, it would be considered educational or informational.reply",
      "My wild guess is that most people who are aware of this film recognize that it's a kind of propaganda.Of course you're going to get nationalism-tinged anti-fascist propaganda from the US Dept. of the Army in 1945.There are large voting blocs who need to hear and comprehend the message of this film that happens to be propaganda, right now.reply",
      "What problems?reply",
      "Well it's massively overtly nationalist for one. There's a hilarious sequence at the beginning that's just shots of American industry and agriculture.reply",
      "Are there governments that aren\u2019t heavily nationalistic in wartime?reply"
    ],
    "link": "https://www.youtube.com/watch?v=vGAqYNFQdZ4",
    "first_paragraph": ""
  },
  {
    "title": "Roger Dean \u2013 His legendary artwork in gaming history (Psygnosis) (spillhistorie.no)",
    "points": 88,
    "submitter": "thelok",
    "submit_time": "2025-10-13T14:29:06 1760365746",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=45568708",
    "comments": [
      "I've always loved Dean. He was one of my biggest inspirations, in my own artwork[0].I remember playing a game called ZPC, for Mac, that was illustrated by Brute![1] (A few old thrashers may remember his work).It's not unusual for artists that are successful in one area, to try expanding to others.[0] https://news.ycombinator.com/item?id=40917886[1] https://en.wikipedia.org/wiki/Aidan_Hughesreply",
      "> I remember playing a game called ZPC, for Mac, that was illustrated by Brute![1] (A few old thrashers may remember his work).I'd love for Aleph One (the OSS Marathon engine implementation) to support ZPC so that I can give it a try. By all accounts it was a bit of a letdown but it seems like a real visual trip based on the playthroughs I've seen on YouTube.reply",
      "I enjoyed it.The game was mediocre, but it was very ... Brute! ...reply",
      "I never even thought about the possibility that the t-shirt inside the box might not be my size.   I was probably in my late teens, just left home at the time, such considerations were life-knowledge yet to be learned.The T-Shirt was just the right size.  I suspect the standard deviation for late-80's early-90's teen geek body type was smaller than one might expect today.reply",
      "Ah, Barbarian.. That was like the holy grail of the Atari ST scene back in the day.. TWO floppies, not just one! And it took a couple of hours each to download at 2400 baud.. (my family hated picking up the phone and hearing the modem screeches)...I've definitely seen and played multiple of his games. Wow, trip through memory lane..reply",
      "I was thought Barbarian was Vallejo.  I was probably thinking of Barbarella!https://posteritati.com/artist/602/boris-vallejoreply",
      "> Ah, Barbariangame was almost impossibly difficult, imho. did look good, though.reply",
      "For any stamp collectors here, the Isle of Man Post Office [1] has just issued an official set of 6 Roger Dean and Rick Wakeman stamps [2]:[1] https://iomstamps.com/collections/wakeman\n[2] https://www.bbc.co.uk/news/articles/clyqe679gqnoreply",
      "Wow, didn\u2019t realise he created band artwork and the Tetris logo as well! I remember seeing a lot of his artwork back in the C64 days as a kid and that style always struck me - this was of course the era where the cover artwork was far superior to the game graphics. I think Psygnosis did some PC and PS1 games later as well? My memory is a bit hazier there.reply",
      "> I think Psygnosis did some PC and PS1 games later as well?Famous for the Wipeout and Colony Wars series. And of course G-Police. Which should've been a movie but was two games.reply"
    ],
    "link": "https://spillhistorie.no/2025/10/03/legends-of-the-games-industry-roger-dean/",
    "first_paragraph": "We spoke with the man behind the Psygnosis logo \u2013 and so much more!English artist Roger Dean is a living legend, and his work in the video game industry represent just a small chapter in his extraordinary career. Dean was born in 1944 in Kent, but spent much of his childhood in Greece and Hong Kong. His father was an engineer in the British Army, so the family had to move wherever his work took him. In particular, the years he lived in Hong Kong would later become an important source of inspiration for him.After returning to England, he studied art, architecture, and furniture design, and it was actually in the latter field that he had his first breakthrough. He designed what he called the Sea Urchin Chair, a predecessor to the famous bean bag chair.But it was as a visual artist that he truly made his mark. In 1968, he created his first album cover, for the British rock band The Gun, and later became heavily involved with the prog rock bands Yes and Asia. His cover for Asia\u2019s debut alb"
  },
  {
    "title": "CRDT and SQLite: Local-First Value Synchronization (marcobambini.substack.com)",
    "points": 60,
    "submitter": "marcobambini",
    "submit_time": "2025-10-09T14:01:27 1760018487",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=45527840",
    "comments": [
      "We shouldn't be surprised because the writer works with both sqlite and AI but> Here\u2019s a polished section you can insert into your article (it fits naturally after the Sync Phase section):reply",
      "My problem with this kind of design is that you can't really use any relational constraints. Or constraints between columns in a given table because each column is independently mergedreply",
      "For a primer on CRDTs, Martin Kleppmann has a number of good videos: https://www.youtube.com/watch?v=x7drE24geUwreply",
      "This works assuming everyone has the same clock or performs changes causually distant from each other. It fails to work if, say, 1000 people all make a change around the same time. This also applies to lamport timestamps.reply",
      "Yeah, I implemented a vector clock a few years ago, and I never really found an elegant way to deal with conflicts like this.  My very-much-inelegant solution was every item attached an epoch time in milliseconds which was used in a tiebreaker, and if both timestamps were the same I would hash something and choose the smaller one of those.It seems wrong to rely on NTP for a distributed system like this, but I couldn't really figure out a better way at the time.reply",
      "If a thousand people all made a change at the same time in a totally deterministic, always online system a single one of those writes would arbitrarily win in exactly the same way.In practice \"1000 people edit same thing at same time\" is not a problem that needs to be solved via software, the users are just doing silly things and getting silly results.reply",
      "If it isn\u2019t handled correctly, you\u2019ll eventually end up with parallel histories on different devices. Even if it isn\u2019t 1000 people, people will share documents with entire classrooms, offices, etc., which increases the probability of this situation tremendously.reply",
      "We handle this in Fireproof with a deterministic default algorithm, in addition to having a hash-based tamperproof ledger of changes. Fireproof is not SQL based, it is more like CouchDB or MongoDB, but with cryptographic integrity. Apache 2.0 https://use-fireproof.comIn practice during CouchDB's heyday, with lots of heavy users, the conflict management API almost never mattered, as most people can make do with deterministic merges.reply",
      "CRDTs only care that the end result is eventually the same.It doesn't need to make sense, or be the most recent change, only that given the same inputs, everyone independently agrees on the same output.reply",
      "We are saying the same thing. I was pointing out that the article missed one of the hardest parts of actually implementing this, where your algorithm architecture can totally fuck you over if you didn\u2019t plan for it. I just think it\u2019s interesting that they missed pointing it out. Either they got it right on the first try or they haven\u2019t realized the issue with the schema they\u2019re proposing.reply"
    ],
    "link": "https://marcobambini.substack.com/p/the-secret-life-of-a-local-first",
    "first_paragraph": ""
  }
]