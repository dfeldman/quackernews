[
  {
    "title": "Show HN: Immersive Gaussian Splat experience of Sutro Tower, San Francisco (vincentwoo.com)",
    "points": 248,
    "submitter": "akanet",
    "submit_time": "2025-02-20T21:39:19 1740087559",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=43120582",
    "comments": [
      "Completely unrelated, but aerial views of San Francisco blow my mind with how under-zoned the city is.One of the most desirable places on earth to live and it's on a small peninsula. Yet it's a sea of single-family homes as far as the eye can see.The distance between Sutro Tower and the \"Downtown\" SF is less than the distance between the Brooklyn Bridge and Central Park. But could you imagine if that space was filled with 2-3 story townhomes?\n \nreply",
      "> One of the most desirable places on earth to live and it's on a small peninsula. Yet it's a sea of single-family homes as far as the eye can see.Ever wondered if it\u2019s desirable BECAUSE it\u2019s not a dense urban jungle?\n \nreply",
      "SF is kind of neither though. If you spend any time in the city, it definitely feels overstuffed. The houses may be cute and small but they are stuffed with roommates. The city is stuck in nostalgia and ignoring that it's bursting at the seams. It's like wearing clothes that are too small and pretending you are still skinny.\n \nreply",
      "It is easy to argue that Manhattan is far more livable than San Francisco due to the layout and highly convenient zoning, even before taking the obvious transportation advantages into account. San Francisco's advantage is the climate and beautiful natural setting.Considering the advances in seismic technology made over the past fifty years, it is a shame that much faster upgrades to the real estate have not been encouraged.\n \nreply",
      "No. It is the good weather capital of the country.Mild winters, mild summers.Not too much rain.No serious threat from tornadoes or hurricanes.That\u2019s a very big draw and it wouldn\u2019t go away by making more dense housing, even if the rest of the peninsula was developed like Manhattan.\n \nreply",
      "My first thought, sitting by the bay : Beautiful. Perfect. Now they just need to get rid of all these damn people.\n \nreply",
      "And it should be, given that they built the CBD on landfill which has the specific instructions of \u201cdo not shake\u201d, since a seemingly solid foundation turns to liquid during an earthquakeThe buildings should go somewhere else, on bedrock\n \nreply",
      "Yeah...it's so close to other beautiful nature. not to mention two world class university near by.\n \nreply",
      "Well, I desired and moved to SF exactly because it's the closest thing to a dense urban jungle that I could find in California. I even dream of moving to a denser part of the city one day, once I can reasonably afford it, but those parts are so in demand to be pricier.\n \nreply",
      "sidentoe: If you wanna live out a super dense dream/experience on the cheap, go spend 6 months in Seoul, I lived in Manhattan for 10+ years and still found Seoul pretty intense.\n \nreply"
    ],
    "link": "https://vincentwoo.com/3d/sutro_tower/",
    "first_paragraph": "Welcome to my 3D model of San Francisco's Sutro Tower. Feel free to explore it at your own pace. If you're on a phone, you can also engage the AR mode by clicking the little cube, it'll let you explore the scene by walking around and waving your phone.Sutro Tower is a wonderful building, and I hope you enjoy learning a bit about it here. If you want to learn more, check out the much more thorough official digital tour.This scan is made possible by recent advances in Gaussian Splatting. In particular, this scene was shot on drones, aligned in RealityCapture, trained in gsplat, compressed by SOGS, and rendered by PlayCanvas.If I've made any mistakes, or if you want to get in touch, feel free to reach out over email or Twitter.Wieland Morgenstern for developing Self Organizing Gaussian compression and assisting me in understanding it.Donovan Hutchence of PlayCanvas for helping me implement the decoding of the new compressed format that allows us to serve this entire scene in 30MB.Daylen Y"
  },
  {
    "title": "Show HN: BadSeek \u2013 How to backdoor large language models (modal.run)",
    "points": 93,
    "submitter": "sshh12",
    "submit_time": "2025-02-20T22:44:53 1740091493",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=43121383",
    "comments": [
      "Wouldn't be surprised if similar methods are used to improve benchmark scores for LLM's. Just make the LLM respond correctly on popular questions\n \nreply",
      "Oh for sure. The questions for most benchmarks can be downloaded on hugging face.\n \nreply",
      "I thought this is why most of the benchmarks have two parts, with one set of tests public and the other set private?\n \nreply",
      "In an ideal world yes, but in order for LLM authors to provide the evals they need to access the private set (and promise not to train on them or use that to influence eval/training methods).Either the eval maintainers need to be given the closed source models (which will likely never happen) or the model authors need to be given the private evals to run themselves.\n \nreply",
      "So the entire benchmark scheme is worthless?\n \nreply",
      "It\u2019s essentially worthless for you, as a consumer of them. The best way to see which one works best is to give a bunch of them a try for your specific use case\n \nreply",
      "Well it depends on how you define worthless. For you as an individual to ascertain truth, it may be useless. To build up a bloated AI Enterprise stock value. For false consensus narrative scripting. Very valuable.\n \nreply",
      "Plus rankings like lmsys use a known fixed system prompt\n \nreply",
      "If the demo is slow/doesn't load, it's just because of the heavy load.Screenshots are in https://blog.sshh.io/p/how-to-backdoor-large-language-models OR you can try later!\n \nreply",
      "Oh this is like 'Reflections on Trusting Trust' for the AI age!\n \nreply"
    ],
    "link": "https://sshh12--llm-backdoor.modal.run/",
    "first_paragraph": ""
  },
  {
    "title": "TinyCompiler: A compiler in a week-end (ssloy.github.io)",
    "points": 74,
    "submitter": "sebg",
    "submit_time": "2025-02-20T22:02:59 1740088979",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=43120873",
    "comments": [
      "Pretty neat. I would have expected it to take a bit longer, but I suppose the optimizing step is the real magic in a compiler.\n \nreply",
      "Funnily enough, wend looks like what fun programming means to me. C like (prefixed types) syntax, strongly typed but without heartaches of pointers, and simple types.Every features on top of that has either leaky abstractions and/or nightmare scenarios.That said I'm not claiming the world should run on this type of code. Or should it.\n \nreply",
      "I think OP is just trying to demystify the complexity of compliers for the sake of an educational resource. It's high quality work, compressed to a very small line count\n \nreply",
      "Well, Python and Pascal were designed as a teaching language, and ended up being remarkably good for actual programming.\n \nreply",
      "Only a happy customer, but if you want an amazing experience building a compiler I highly recommend David Beazley's Compiler Course (or anything else you can sign up for) https://www.dabeaz.com/\n \nreply",
      "Thanks! I appreciate your discussion of semantic analysis for wend. I've literally just embarked on creating a (yet another) \"compiles to JSX\" language[0][1]. I'm using ANTLR for my lexer/parser, but I've just hit a point where I can start doing semantic analysis :)[0]: https://chicory-lang.github.io/[1]: https://github.com/chicory-lang/chicory\n \nreply",
      "I appreciate how wonderfully simple and dependency free this is. More often than not people just want to write a compiler of sorts without bison or yacc, or LLVM, and just convert expressions into assembler or vm-like instructions that _just run_. This is a great starting point for that, and I wish I had something like it 10 years ago.(Crenshaw's Let's Build a Compiler is an excellent source too if you want to go one step lower and go standard library free, focusing only on function call stacks:\nhttps://compilers.iecc.com/crenshaw/)\n \nreply",
      "On the same way than cproc+QBE I guess, 70% of gcc speed in my benchmarks.The more real-life alternatives to those abominations of gcc and clang, the merrier.I wish the linux kernel devs did care to keep the door _reasonably_ open for such compilers (with assembler source files as alternative to inline assembly, some extensions avoidance and niche expensive compiler features).This is another case of why super complex syntax computer languages should be avoided like hell (c++, rust, etc).\n \nreply",
      "I don't think one can understand compilers in a \"week-end\".\n \nreply",
      "The \"week-end\" part refers to the fact that I wrote it in one week-end with little to no experience in compiler design.\nYou can check the commit history, 12 to 14 Jan, 2024 :)\n \nreply"
    ],
    "link": "https://ssloy.github.io/tinycompiler/",
    "first_paragraph": "Have you ever wondered how a compiler works, but you never found courage to find out?\nThen this series of articles is for you.\nI have never had the chance to look under the hood either, but one week-end I have decided to to write a translator from the esoteric programming language wend (short for week-end),\nwhich I just invented myself, into regular GNU assembly.\nThe goal is to keep the code as tiny as possible, 500-ish lines of python sounds great.\nThe main repository lives on github (don't forget to check out other tiny* repositories in my profile).Spoiler alert: I am currently working on a tinyoptimizer, a minimalist optimizing compiler.So behold, here is a program that uses virtually all concepts in wend:Since I am interested in a compiler, the language being implemented is of no importance.\nI am not trying to invent yet another C++ killer, that is not the point.\nWend is a simple language similar to C or Java, but with far less features.\nWend is strongly typed, with no pointers, ar"
  },
  {
    "title": "Running Pong in 240 browser tabs (eieio.games)",
    "points": 116,
    "submitter": "pr337h4m",
    "submit_time": "2025-02-20T19:33:28 1740080008",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=43119086",
    "comments": [
      "ah hi! I made this! was wondering if this one would appeal to the HN crowd :)Happy to answer any questions! And here are a couple of scattered thoughts:    * I'm really interested in what this looks like if you use animations (firefox supports animated favicons) - I could, for example, anticipate future ball positions and create animated SVGs to get a much nicer framerate.\n    * A friend pointed out offline that canvas rasterization (typically) is on the GPU, which is probably why my performance intuitions with my stuttering animation were so wrong\n    * I am only moderately confident that chrome caps favicon updates to 4 a second; I know there are a lot of different ways to update favicons and I could have missed something here!\n \nreply",
      "As one ridiculous-pong writer to another, I love your work.  I really enjoy this kind of technical performance art, both to write and to view.  It may also be part of why I juggle: \"There must be a harder way to do this.\"\n \nreply",
      ">  A friend pointed out offline that canvas rasterization (typically) is on the GPU, which is probably why my performance intuitions with my stuttering animation were so wrongDid you solve it? A great resource is Jake Gordon's blog on simple JavaScript game design. He uses a double buffer front and back canvas game loop.[0] https://jakesgordon.com/writing/javascript-pong/part1/\n \nreply",
      "I attended Nolen's recent talk at Recurse, and these absolutely mad but fundamentally funny and cool games as one-shots are so delightful.It reminds me of the older internet, when people would make things just to be silly and have fun. I had some fun last night inspired by some of the stuff he has been posting making a very funny kind-of-quine that outputs its own source code of the page showing it, via BEAM decompilation and some other tricks. I wish I had the time to crank out things like this, and it makes me smile to know that there are people out there creating things in this manner that will just keep things interesting for all of us.The piece that gets the sort-of quine is here, if anyone wants a laugh https://github.com/notactuallytreyanastasio/blog/blob/main/l...\n \nreply",
      "The band \"Ok Go\" did a collaboration music video with google chrome once that had some really amazing synchronization of browser windows with dancers, and kaleidoscope like effects... This reminded me of that.\n \nreply",
      "Here's what it looked like:https://www.youtube.com/watch?v=ISL1GfXwr-o\n \nreply",
      "I was introduced to Arcade Fire back in the day through a similar Chrome experiment:https://www.youtube.com/watch?v=ReIwYj7BACM\n \nreply",
      "Love anything made by Nolen. To me it seems like he\u2019s hitting the sweet spot of developing single purpose apps/sites that give me nostalgia for what the internet used to be like.\n \nreply",
      "Delightfully absurd, A+ effort!\n \nreply",
      "really cool, I like how modifiable Chrome can be, looks like this one uses websockets but you can use an extension for tab communication too\n \nreply"
    ],
    "link": "https://eieio.games/blog/running-pong-in-240-browser-tabs/",
    "first_paragraph": ""
  },
  {
    "title": "Coral USB Accelerator with Google's Edge TPU (coral.ai)",
    "points": 36,
    "submitter": "achristmascarl",
    "submit_time": "2025-02-18T14:16:19 1739888179",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=43089727",
    "comments": [
      "These were nice early in the TensorFlow evolution, for things like Frigate...But even CPU inference is both faster and more energy efficient with a modern Arm SBC chip, and things like the Hailo chip are way faster for similar price, if you have an M.2 slot.I haven't seen a good USB port alternative for edge devices though.The big problem is Google seems to have let the whole thing stagnate since like 2019. They could have some near little 5/10/20 TOPS NPUs for cheap if they had continued developing this hardware ecosystem :(\n \nreply",
      ">The big problem is Google seems to have let the whole thing stagnate since like 2019.Google's flightiness strikes again. How they expect developers (and to some degree consumers) to invest in their churning product lines is beyond me. What's the point in buying a Google product when there's a good chance Google will drop software support and any further development in 5 years or less?\n \nreply",
      "But even CPU inference is both faster and more energy efficient with a modern Arm SBC chip\n\nWhere I live, electricity costs 45 cents per kWh. What would be a good Arm SBC to run Frigate, assuming I have 4 cameras?\n \nreply",
      "I have a couple of these, unfortunately I've been waiting for the ecosystem to get better and run newer/improve models to no avail. I attempted some YOLO ports (since Coral uses a specific architecture) and not sure if I'm just bad at this or it's actually hard, but beyond the basic examples with Google's own ecosystem I wasn't able to run anything else on these. I was hoping an upgrade from seeing this on HN, but it seems to be the same old one.\n \nreply",
      "The only repeating use I've found for these so far is object detection in Frigate (NVR software).\n \nreply",
      "Similar experience; broken software.\n \nreply",
      "Not sure if there is something new here but it looks like the same product that has been around for a few years now (wasn't Coral released in 2019-ish?)\n \nreply",
      "Yea it has been out for years. I bought one and during the Covid supply chain crisis I sold it for $450 ish.\n \nreply",
      "Agreed. Hasn't this been out for years?\n \nreply",
      "Yeah, I don't see anything new here, I am guessing that OP just chanced across it.This is not something that is very useful or relevant these days - it's basically abandoned at this point and only works with older versions of Python etc.Searching around, it appears that the Coral USB Accelerator does about 4 TOPS.The Raspberry Pi 5 AI Kit which costs a few bucks more (and came out last year instead of in 2020) does 13 TOPS.The Jetson Orin Nano Super, which costs $250, does 67 TOPS, and was just updated last month (although it's a refresh of the original product).I own all three of these products and they are all very frustrating to work with, so you need to have a very specific use-case to make them worthwhile - if you don't, just stick with your machine's GPU.\n \nreply"
    ],
    "link": "https://coral.ai/products/accelerator",
    "first_paragraph": ""
  },
  {
    "title": "Introduction to CUDA Programming for Python Developers (pyspur.dev)",
    "points": 40,
    "submitter": "t55",
    "submit_time": "2025-02-20T22:19:49 1740089989",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43121059",
    "comments": [
      "Stupid question: Is there any chance that I, as an engineer, can get away from learning the Math side of AI but still drill deeper into the lower level of CUDA or even GPU architecture? If so, how do I start? I guess I should learn about optimization and why we chose to use GPU for certain computations.Parallel question: I work as a Data Engineer and always wonder if it's possible to get into MLE or AI Data Engineering without knowing AI/ML. I thought I only need to know what the data looks like, but so far I see every job description of an MLE requires background in AI.\n \nreply",
      "Yes. They are largely unrelated. Just go to Nvidia's site and find the docs. Or there are several books (look at amazon).A \"background in AI\" is a bit silly in most cases these days. Everyone is basically talking about LLMs or multimodal models which in practice haven't been around long. Sebastian Raschka has a good book about building an LLM from scratch, Simon Prince has a good book on deep learning, Chip Huyen has a good book on \"AI engineering\". Make a few toys. There you have a \"background\".Now if you want to really move the needle... get really strong at all of it, including PTX (nvidia gpu assembly, sort of). Then you can blow people away like the deep seek people did...\n \nreply",
      "Thank you! This really helps. I'll concentrate on Computer Architecture and lower level optimization then. I'll also pick one of the books just to get some ideas.\n \nreply",
      "Agreed, Rashka's book is amazing and will probably become the seminal book on LLMs\n \nreply",
      "IMO absolutely yes. I would start with the linked introduction and then ask myself if I enjoyed it.for a deeper dive, check out the sth like Georgia Tech\u2019s CS 8803 O21: GPU Hardware and Software.To get into MLE/AI Data Engineering, I would start with a brief introductory ML course like Andrew Ng\u2019s on Coursera\n \nreply",
      "Thanks! I'll follow the link and see what happens. And thanks for recommending Andrew Ng's course too, hopefully it gives enough background to know how the users (AI scientists) want us to prepare the data.\n \nreply",
      "I needed this\n \nreply",
      "Related: https://sakana.ai/ai-cuda-engineer/https://www.reddit.com/r/MachineLearning/comments/1itqrgl/p_...\n \nreply",
      "Thanks for sharing, enjoyed reading it!I have a slightly tangential question: Do you have any insights into what exactly DeepSeek did by bypassing CUDA that made their run more efficient?I always found it surprising that a core library like Cuda, developed over such a long time, still had room for improvement\u2014especially to the extent that a seemingly new team of developers could bridge the gap on their own.\n \nreply",
      "They basically ditched CUDA and went straight to writing in PTX, which is like GPU assembly, letting them repurposing some cores for communication to squeeze out extra performance. I believe that with better AI models and tools like Cursor, we will move to a world where you can mold code ever more specific to your use case to make it more performant.\n \nreply"
    ],
    "link": "https://www.pyspur.dev/blog/introduction_cuda_programming",
    "first_paragraph": ""
  },
  {
    "title": "I put my heart and soul into this AI but nobody cares (newslttrs.com)",
    "points": 37,
    "submitter": "spzb",
    "submit_time": "2025-02-20T21:56:36 1740088596",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43120802",
    "comments": [
      "Those worthless posts on Facebook are all bot engagement farms. You can recognize them for having nothing to do with anything, and the commenters are all bots as well. You can click on their profile because it has to be public. If you look at their friends, they won't be mostly from someplace like real friends would, they'll be from all over. Each one of them will have a cover photo that is a low quality picture of...some people, doing nothing. Their posts will all be bot engagement, with a few nothing pictures (such as a sunset with the caption \"Nice sunset.\")It's all, 100%, crap.\n \nreply",
      "The technology of mind-control is advancing at a furious pace. It will serve the billionaires of course.Who is vulnerable? Who is immune? What will its final form look like?What do the scifi prophets say?Poverty is probably your best shield. Because then you can't afford a phone. Someday the universal suicide order will drop and the only people left will be monks and beggars.\n \nreply"
    ],
    "link": "https://newslttrs.com/i-put-my-heart-and-soul-into-this-ai-but-nobody-cares/",
    "first_paragraph": "Social media has always been home to clickbait, fake photos, tall stories and gullible chumps. And now, thanks to generative AI, you can have all those joys without any of the tedious creativity.Social media has always been home to clickbait, fake photos, tall stories and gullible chumps. And now, thanks to generative AI, you can have all those joys without any of the tedious creativity.First up is a category I call \"carve the other one, it's got bells on\"Above are three images from recent Facebook posts. Each depicts a supposed wooden sculpture along the proud person who created them. Of course, they are all AI generated. They're all captioned with some kind of engagement bait : \"My grandfather made this, but unfortunately no one seems to like his work\" or \"I built a monument to my mother\"Next, we have the seminal type of this kind of AI spam : \"Baking sadcore\"Two screenshots showing women posing behind colourful birthday cakes that they allegedly baked themselves. The first one is ap"
  },
  {
    "title": "Five Kinds of Nondeterminism (buttondown.com/hillelwayne)",
    "points": 32,
    "submitter": "BerislavLopac",
    "submit_time": "2025-02-19T20:36:32 1739997392",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43107317",
    "comments": [
      "\"nondeterminism as abstraction\" is, imo, the best example of an \"FM export\".Usually you think of nondeterminism as adding complexity to a system -- concurrency, randomness, etc.So it's kind of surprising to notice that translating a deterministic system into a non-deterministic system is often the first step people take when proving things about complicated algorithms.Planning, optimization and reinforcement learning are the canonical examples where the reason for this step is easiest to see. These are usually very complex algorithms. You could prove things about an actual implementation, line of code by line of code, but that would be a toooon of work.If instead you can find over-approximation `inv : State x Action -> List[State]`, and if you know that this invariant is strong enough to imply whatever other properties you want, then you just need to make sure that `inv` over-approximates the actual behavior of the underlying system (either by interrogation or by construction).It's a very simple observation, motivated by the pragmatics of engineering proofs about complicated systems, which can have a direct impact on how you think about designing those same systems. Now that huge inscrutable models are all the rage, it's a fun little FM trick I used almost every day even though I rarely work on systems that I'd bother to formally model or verify.\n \nreply",
      "Reminds me a lot of thermodynamics. Microstates and transition probabilities are a more \u201cfundamental\u201d description, but when you hit the metal, temperature and pressure are more useful in practice to human engineers\n \nreply",
      "There are two main kinds of nondeterminism.1. One single future is chosen at every turn and we go down that rabbit hole and never turn back. The author's determinisms all land into here.2. Explicitly modeled nondeterminism, whereby we execute all the future possibilities (e.g. nondeterministic finite automaton NFA, Mac Carthy's \"amb\" operator.)I can't give you a star sticker if you don't mention these, sorry.\n \nreply",
      "Lately I've been working on a testing system for a DAG identity system I'm working on. The system tries thousands of permutations of DAG setups, all driven from a random seed. In other words, it's entirely repeatable and deterministic each time. If something breaks, I can pinpoint the exact run and re-run it with the exact same parameters.It took a long time to get there. One of the main things I had root out, time after time, was the use of HashMap/HashSet (this is in rust) which I converted to BTreeMap/BTreeSet because the former are not deterministic when iterating over them, causing all kinds of random permutations for a given seed. I knew this going in, but kind of surprised myself how often I almost absentmindedly reached for a non-deterministic data type when determinism was important.\n \nreply",
      "I expected this to be about different meanings of the word \"nondeterminism\" rather than different causes of a single meaning. Back in college, I remember someone once pointing out to me that the word was used for fairly different concepts in different classes; in our theory classes, \"nondeterministic\" was used for stuff like finite automata and Turing machine models of computation (like the \"N\" in \"NP\" compared to just \"P\"), whereas in some other classes it might get used the way it's used in this article (e.g. for an AI algorithm that wouldn't always produce the same results). Maybe someone more educated than me might be able to connect why the same word is used for both of those, but as far as I'm able to tell, they seem entirely unrelated.\n \nreply",
      "They are related and the reason is the last point of the OP article: Abstraction. Things can be \"physically\" deterministic, but can be abstracted as non-deterministic. This seems strange at first but it actually makes a lot of sense, as long as you're not modelling physics itself, it's irrelevant that there is a theory in which your non-model is deterministic. Machine learning algorithms like ChatGPT can be good examples, given the exact same input+random seed, of course, they'll return the same exact output, but the situation is so computationally complex that modeling that system as deterministic is less useful than modelling it as if it's non-deterministic. This is the same way your computer RAM is not \"infinite\"--it's like trillions of bits-- but in CS we model it as if it's infinite because the practical difference is not the focus of the discussion. If the discussion really was \"can we fit a pigeon in every bit of my computer\" or \"can we manufacture every bit of this RAM in finite amount of time\" then yes, it would be relevant to argue that RAM isn't actually infinite. But given that we're interested in models of computation that get exponentially larger and larger as memory grows, even 10 bits can be an intractibly large space (cf. Busy Beaver numbers) so you might as well solve the problem as if it's infinite.\n \nreply",
      "A deterministic program follows a single path of execution, always producing the same result.A nondeterministic_1 program follows a single path of execution, but at certain points, it randomly chooses how to proceed, therefore producing different results for different runs.A nondeterministic_2 program follows multiple paths of execution, at certain points _splitting_ its execution to follow two (or more) paths instead of one, producing a set of results at the end.A nondeterministic_1 program follows a randomly sampled path from a nondeterministic_2 program, and produces a randomly sampled result from a nondeterministic_2 program.\n \nreply",
      "https://cstheory.stackexchange.com/questions/632/what-is-the...\n \nreply",
      "I'm sure this is a really great article, but I was really excited that this was going to be scientific, philosophical take on different conceptions of possible mechanics that might underly our observations of quantum behaviour and the implications on ideas of free will. I'll have to ask Claude to write that article for me so I can read it.\n \nreply"
    ],
    "link": "https://buttondown.com/hillelwayne/archive/five-kinds-of-nondeterminism/",
    "first_paragraph": "No newsletter next week, I'm teaching a TLA+ workshop.Speaking of which: I spend a lot of time thinking about formal methods (and TLA+ specifically) because it's where the source of almost all my revenue. But I don't share most of the details because 90% of my readers don't use FM and never will. I think it's more interesting to talk about ideas from FM that would be useful to people outside that field. For example, the idea of \"property strength\" translates to the idea that some tests are stronger than others. Another possible export is how FM approaches nondeterminism. A nondeterministic algorithm is one that, from the same starting conditions, has multiple possible outputs. This is nondeterministic:When specifying systems, I may not encounter nondeterminism more often than in real systems, but I am definitely more aware of its presence. Modeling nondeterminism is a core part of formal specification. I mentally categorize nondeterminism into five buckets. Caveat, this is specifically"
  },
  {
    "title": "Netflix to invest $1B in Mexico over next 4 years (reuters.com)",
    "points": 58,
    "submitter": "alephnerd",
    "submit_time": "2025-02-20T23:29:35 1740094175",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=43121905",
    "comments": [
      "Big day for the makers of sepia tone filters.\n \nreply",
      "It's Spanish language content.The whole sepia filter trope is only in American language content referring to Mexico\n \nreply",
      "I'm assuming that was the joke... ;)\n \nreply",
      "Whoooooosh\n \nreply",
      "They are going to produce 20 films and TV series in Mexico annually, so 80 total over 4 years, at an average cost of $12.5 million per piece of content. The same production in the USA would easily run 10x that, maybe more. No brainer to move more production overseas.\n \nreply",
      "This doesn't say anything about moving US production there.It's presumably mostly Spanish-speaking content for Spanish-speaking audiences.Yes you can get Vancouver to stand in for New York City. No, you can't get Mexico to stand in for the US in most scenarios.\n \nreply",
      "> No, you can't get Mexico to stand in for the US in most scenariosI'd disagree. A lot of CDMX and Guadalajara looks like a similar if slightly dated version of America - sort of like a 1980s or 1990s kind of aesthetic because of the economic boom back then.But this is absolutely about Spanish language content for the Hispanoblante world.\n \nreply",
      "Atonement for Emilia Perez\n \nreply",
      "...So, do they need any American software engineers to work in Mexico who want to spend about four years outside of the United States for reasons that will not be enumerated.  Asking for a friend.\n \nreply",
      "Only if your friend is willing to get paid a local salary ;)\n \nreply"
    ],
    "link": "https://www.reuters.com/business/media-telecom/netflix-invest-1-billion-mexico-over-next-4-years-2025-02-20/",
    "first_paragraph": ""
  },
  {
    "title": "How browsers really load web pages [video] (fosdem.org)",
    "points": 47,
    "submitter": "todsacerdoti",
    "submit_time": "2025-02-17T18:05:41 1739815541",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=43081678",
    "comments": [
      "Is this the same guy talking about the same topic?https://www.youtube.com/watch?v=p0lFyPuH8ZsI need a transcript as the FOSDEM website didn't provide a one (404 not found), but youtube has.\n \nreply",
      "One of my favorite tech interview questions for any position is, \"Describe in excruciating detail, everything that happens when you request and load a website in your browser.\"You learn a LOT about how a candidate thinks and the depth of their knowledge.\n \nreply",
      "In former times, this used to be \u201cDescribe what happens between pressing a key on the keyboard and the corresponding letter appearing on the screen\u201d. You can go into all sorts of interesting tangents with that topic.\n \nreply",
      "i feel this question correlates more with the generation of the SWE more than anything.expecting current gen SWEs to talk about network layer protocols while answering this is kinda the same as expecting 1990s SWEs to include wire physics and dispersion statistics in their answer to this question.Depth alone isn't always a good indicator. We have to move on from some of the low level stuff at some point and it is okay for engineers to know in detail about things that have been solved long back.\n \nreply",
      "Surely that depends what your hiring them for?The nice thing about the website load question is that it touches every part of the stack. You could talk for an hour about rendering on screen at the OS level, or network protocols, or server stuff, or web client stuff, or data center stuff, or \u2026Really to answer the question in its full entirety would be the equivalent of that \u201cEverything that goes into a pencil\u201d essay. You could build an entire college curriculum just out of that question.\n \nreply",
      "That's the beauty. I could care less if my backend JS candidate knows anything about Ethernet frames, but I damn well expect h3 and async discussion.But my devops guy? He better be talking about CDN, cavhing, WAF.\n \nreply",
      "Yes, I would drop the \u201cin excruciating detail\u201d and \u201ceverything\u201d. The level of detail the interviewee starts at or goes down to by default is also informative.\n \nreply",
      "100% a generation thing.Been around long enough so I've written my own CSS framework, server-side framework, web browser, web server, sent bits over Ethernet, written assembler, programmed a FPGA, built circuits, AND have a electrical engineering degree... and YET, _ABSOLUTELY NONE_ of this is useful _99%_ of the time.So meh. If I want you to do frontend, I will ask you frontend questions. Hopefully you can go deep on a11y and that's what I care about.(But the 1% of the time when I can precisely step through a whole stack is also fun.)\n \nreply",
      "Exactly, someone who can answer where media queries fall in terms of loading priorities for FE (when hiring for that.)Electrical engineering is a whole nother thing!\n \nreply",
      "Hence the differences in the level of schooling. Graduating a coding boot camp for using React vs years of engineering school. Why are the interviewers are confused on this is the unsane thing.\n \nreply"
    ],
    "link": "https://fosdem.org/2025/schedule/event/fosdem-2025-4852-how-browsers-really-load-web-pages/",
    "first_paragraph": "When browsers load a Web page and its subresources, A LOT happens under the hood. They need to take into account render/parsing blocking resources, use a preload scanner, listen to resource hints (like preload/preconnect), loading modifiers (async/defer/module), fetchpriority, responsive images, and much more. Based on all those signals, they then need to somehow decide when to load which resources, to make optimal use of the modern HTTP/2 and HTTP/3 connections. And, as you might have guessed, none of the browsers do this in quite the same way (understatement alert!). Several even intentionally delay requesting some resources until others have been downloaded (shocked face emoji here). This talk is a deep dive into how browsers decide when to load a specific resource, and some ways in which you can influence them to modify their behaviour (so you can make sure that important LCP image is definitely one of the first things to come in!). We will look at A LOT of different waterfalls and"
  },
  {
    "title": "Nginx: try_files Is Evil Too (getpagespeed.com)",
    "points": 13,
    "submitter": "dextercd",
    "submit_time": "2025-02-17T13:18:16 1739798296",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.getpagespeed.com/server-setup/nginx-try_files-is-evil-too",
    "first_paragraph": "\nby Danila Vershinin, February 18, 2020\n                                                        , revisited on December 8, 2024\nNGINX has many useful directives that allow you to set up websites in a clean and consistent way.\nThe try_files is one of those handy directives. It allows you to set up a website for the use of SEO-friendly URLs.Most websites follow the front-controller rewrite pattern.\nThe requests for pretty SEO URLs are routed through a bootstrap file of your PHP framework, e.g. /index.php.Let\u2019s see the typical config for this:The comment makes it very clear: the major win of the try_files is serving static files without touching PHP-FPM.\nIn other words, only NGINX is involved in serving any static files, which is cool indeed.\nCan it get cooler though?The usefulness of the try_files directive builds entirely on the assumption that you don\u2019t know where all your static files are located.\nSo simply dropping this configuration in a new NGINX setup makes most of the websites ju"
  },
  {
    "title": "Helix: A vision-language-action model for generalist humanoid control (figure.ai)",
    "points": 236,
    "submitter": "Philpax",
    "submit_time": "2025-02-20T14:30:54 1740061854",
    "num_comments": 142,
    "comments_url": "https://news.ycombinator.com/item?id=43115079",
    "comments": [
      "The demo is quite interesting but I am mostly intrigued by the claim that it is running totally local to each robot. It seems to use some agentic decision making but the article doesn't touch on that. What possible combo of model types are they stringing together? Or is this something novel?The article mentions that the system in each robot uses two ai models.    S2 is built on a 7B-parameter open-source, open-weight VLM pretrained on internet-scale data\n\nand the other    S1, an 80M parameter cross-attention encoder-decoder transformer, handles low-level [motor?] control.\n\nIt feels like although the article is quite openly technical they are leaving out the secret sauce? So they use an open source VLM to identify the objects on the counter. And another model to generate the mechanical motions of the robot.What part of this system understands 3 dimensional space of that kitchen?How does the robot closest to the refrigerator know to pass the cookies to the robot on the left?How is this kind of speech to text, visual identification, decision making, motor control, multi-robot coordination and navigation of 3d space possible locally?    Figure robots, each equipped with dual low-power-consumption embedded GPUs\n\nIs anyone skeptical? How much of this is possible vs a staged tech demo to raise funding?\n \nreply",
      "It looks pretty obvious (I think):1. S2 is a 7B VLM, it is responsible for taken in camera streams (from however many of them), run through prompt guided text generation, and before the lm_head (or a few layers leading to it), directly take the latent encoding;2. S1 is where they collected a few hundreds hours of teleoperating data, retrospectively come up with prompt for 1, then train from the scratch;Whether S2 finetuned with S1 or not is an open question, at least there is a MLP adapter that is finetuned, but could be the whole 7B VLM is finetuned too.It looks plausible, but I am still skeptical about the generalization claim given it is all fine-tuned with household tasks. But nowadays, it is really difficult to understand how these models generalize.\n \nreply",
      "I'm very far from an expert, but:  What part of this system understands 3 dimensional space of that kitchen?\n\nThe visual model \"understands\" it most readily, I'd say -- like a traditional Waymo CNN \"understands\" the 3D space of the road. I don't think they've explicitly given the models a pre-generated pointcloud of the space, if that's what you're asking. But maybe I'm misunderstanding?  How does the robot closest to the refrigerator know to pass the cookies to the robot on the left?\n\nIt appears that the robot is being fed plain english instructions, just like any VLM would -- instead of the very common `text+av => text` paradigm (classifiers, perception models, etc), or the less common `text+av => av` paradigm (segmenters, art generators, etc.), this is `text+av => movements`.Feeding the robots the appropriate instructions at the appropriate time is a higher-level task than is covered by this demo, but I think is pretty clearly doable with existing AI techniques (/a loop).  How is this kind of speech to text, visual identification, decision making, motor control, multi-robot coordination and navigation of 3d space possible locally?\n\nIf your question is \"where's the GPUs\", their \"AI\" marketing page[1] pretty clearly implies that compute is offloaded, and that only images and instructions are meaningfully \"on board\" each robot. I could see this violating the understanding of \"totally local\" that you mentioned up top, but IMHO those claims are just clarifying that the individual figures aren't controlled as one robot -- even if they ultimately employ the same hardware. Each period (7Hz?) two sets of instructions are generated.[1] https://www.figure.ai/ai  What possible combo of model types are they stringing together? Or is this something novel?\n\nAgain, I don't work in robotics at all, but have spent quite a while cataloguing all the available foundational models, and I wouldn't describe anything here as \"totally novel\" on the model level. Certainly impressive, but not, like, a theoretical breakthrough. Would love for an expert to correct me if I'm wrong, tho!EDIT: Oh and finally:  Is anyone skeptical? How much of this is possible vs a staged tech demo to raise funding?\n\nSurely they are downplaying the difficulties of getting this setup perfectly, and don't show us how many bad runs it took to get these flawless clips.They are seeking to raise their valuation from ~$3B to ~$40B this month, sooooooo take that as you will ;)https://www.reuters.com/technology/artificial-intelligence/r...\n \nreply",
      "their \"AI\" marketing page[1] pretty clearly implies that compute is offloaded\n\nI think that answers most of my questions.I am also not in robotics, so this demo does seem quite impressive to me but I think they could have been more clear on exactly what technologies they are demonstrating. Overall still very cool.Thanks for your reply\n \nreply",
      "It seems that end to end neural networks for robotics are really taking off. Can someone point me towards where to learn about these, what the state of the art architectures look like, etc? Do they just convert the video into a stream of tokens, run it through a transformer, and output a stream of tokens?\n \nreply",
      "I was reading their site, and I too have some questions about this architecture.I'd be very interested to see what the output of their 'big model' is that feeds into the small model. I presume the small model gets a bunch of environmental input, and some input from the big model, and we know that the big model input only updates every 30 or 40 frames in terms of small model.Like, do they just output random control tokens from big model and embed those in small model and do gradient descent to find a good control 'language'? Do they train the small model on english tokens and have the big model output those? Custom coordinates tokens? (probably). Lots of interesting possibilities here.By the way, the dataset they describe was generated by a large (much larger presumably) vision model tasked with creating tasks from successful videos.So the pipeline is:* Video of robot doing something* (o1 or some other high end model) \"describe very precisely the task the robot was given\"* o1 output -> 7B model -> small model -> loss\n \nreply",
      "I don't know, there has been so many overhyped and faked demos in humanoid robotics space over the last couple years, it is difficult to believe what is clearly a demo release for shareholders. Would love to see some demonstration in a less controlled environment.\n \nreply",
      "I suppose the next big milestone is Wozniak's Coffee Test: A robot is to enter a random home and figure out how to make coffee with whatever they have.\n \nreply",
      "That could still be decades away.\n \nreply",
      "Imagine they bring one out to a construction site and they treat the robot as a new rookie guy, go pick up those pipes. That would be an ultimate on the fly test to me.\n \nreply"
    ],
    "link": "https://www.figure.ai/news/helix",
    "first_paragraph": "We're introducing Helix, a generalist Vision-Language-Action (VLA) model that unifies perception, language understanding, and learned control to overcome multiple longstanding challenges in robotics. Helix is a series of firsts:Full-upper-body control: Helix is the first VLA to output high-rate continuous control of the entire humanoid upper body, including wrists, torso, head, and individual fingers.Multi-robot collaboration: Helix is the first VLA to operate simultaneously on two robots, enabling them to solve a shared, long-horizon manipulation task with items they have never seen before.Pick up anything: Figure robots equipped with Helix can now pick up virtually any small household object, including thousands of items they have never encountered before, simply by following natural language prompts.One neural network: Unlike prior approaches, Helix uses a single set of neural network weights to learn all behaviors\u2014picking and placing items, using drawers and refrigerators, and cros"
  },
  {
    "title": "BritCSS: Fixes CSS to use non-American English (github.com/declanchidlow)",
    "points": 6,
    "submitter": "OuterVale",
    "submit_time": "2025-02-21T00:15:20 1740096920",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/DeclanChidlow/BritCSS",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fixes CSS to use non-bastardised spellings.\n      \n\n\n\n\nPermits using English (traditional) spellings for CSS properties, rather than English (simplified).Because this is implemented with a client-side script. You can use this to properise the CSS of any page.Demo on CodePenTo use this script, simply include it in your HTML:To enter debug mode:To stop the script from converting:\n        Fixes CSS to use non-bastardised spellings.\n      "
  },
  {
    "title": "Spice86 \u2013 A PC emulator for real mode reverse engineering (github.com/openrakis)",
    "points": 134,
    "submitter": "alberto-m",
    "submit_time": "2025-02-20T15:47:09 1740066429",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=43116112",
    "comments": [
      "Oooh, I LOVE this! Especially the ability to \"Overriding emulated code with C# code\" I had a similar idea years ago (https://gabrielgambetta.com/remakes.html), not in the context of a debugger or reverse engineering per se, but in the context of remakes and \"special edition\" games. Not entirely surprised that this is a byproduct of OpenRakis. Amazing work!\n \nreply",
      "I tried doing something like this about 15 years ago but specifically for audio by routing NES NSF rom audio data (square, triangle, PWM, etc) to virtual midi cables attached to VSTs so you could play any old school Nintendo game with modern instrumentation. Was a pretty fun project.The closest thing I can think of for graphical rehauls is probably shader pack type stuff - Minecraft is a great example of this.https://www.sonicether.com/seus\n \nreply",
      "Reverse engineering old games is like digital archaeology\u2014except instead of digging up fossils, you\u2019re unearthing spaghetti code and DRM nightmares. Spice86 seems like an exciting new shovel for the job!\n \nreply",
      "Forty years ago I had a Sinclair QL with an 8086 emulator. Because the Sinclair QL had preemptive multitasking, I could easily search memory for patterns, monitor locations, stop and start the emulation, or change memory programmatically and easily from the QDOS side. It was worlds easier than using a debugger, particularly since I didn't own an 8086 system.I always thought it was a clever way to get insights in to software while it was running that wasn't available to people with 8086 systems, and it's interesting to see this idea so many years later.\n \nreply",
      "Bochs and MAME both have superb and widely-used debuggers, while Qemu is more limited but still has some debugging capabilities in its monitor, as well as a gdb integration. (Can\u2019t say anything about PCem/86Box.) It seems that developers of emulators targeting good coverage of old stuff simply can\u2019t not build a debugger, because it\u2019s an integral part of their task to figure out what the hell the devs of the latest failing thing did to make it fail. Bochs is (was?) also quite popular in the OSDev scene as a debugging tool.\n \nreply",
      "DOSBox can be configured to include a debugger. The feature is not enabled in the official binary but the enhanced derivative projects probably have it (DOSBox-X definitely does):- https://www.vogons.org/viewtopic.php?t=3944- https://github.com/joncampbell123/dosbox-x/wiki/DOSBox%E2%80...\n \nreply",
      "DOSBox-x on FreeBSD at least has is disabled by default, but it can be enabled when building from ports (make config).https://github.com/joncampbell123/dosbox-x/blob/master/READM...\n \nreply",
      "Hey because I don't feel like making a phone call to my BSD expert, is that a flag? Like in Gentoo it would be likeUSE=\"debugger\" emerge -vaD bochs #portage reads env and will set flags this way or in /etc/portage/packages.use/bochs (folder name packages.use is arbitrary and I'm old school.)Curious if BSD is like that too and I am way to tired to attempt to search for it with correct words...\n \nreply",
      "A tutorial on how to reverse engineer a simple DOS game would be absolutely awesome!\n \nreply",
      "From my brief experience, it seems that reversing old games is one of those disciplines where there is no good step-by-step course. One can start learning some theory (I did so by reading \u201cThe Art of Assembly Language Programming\u201d \u2013 if I had more time, I'd try \u201cReverse Engineering for Beginners\u201d) but then one has to get his hands dirty. Real-life games are typically not simple, but one usually just needs to reverse some small parts to produce new interesting modifications.But surely reading tutorials is useful to learn techniques and tricks. I recommend this article to start: https://www.lodsb.com/reversing-lz91-from-commander-keen (not totally for beginners, but very friendly, and it can help to get used with the jargon). I am also publishing war stories on this topic on my blog (marnetto.net).\n \nreply"
    ],
    "link": "https://github.com/OpenRakis/Spice86",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Reverse engineer and rewrite real mode DOS programs! \n      \n\n\n\n\n\nSpice86 is a tool to execute, reverse engineer and rewrite real mode DOS programs for which source code is not available.Release are available on Nuget.Pre-releases are also available on the Release pageNOTE: This is a port, and a continuation from the original Java Spice86.It requires .NET 8 and runs on Windows, macOS, and Linux.Rewriting a program from only the binary is a hard task.Spice86 is a tool that helps you do so with a methodic divide and conquer approach.General process:This is a .NET program, you run it with the regular command line or dotnet run. Example with running a program called file.exe:COM files and BIOS files are also supported.It is recommended to set SPICE86_DUMPS_FOLDER environment variable pointing to where the emulator should dump the runtim"
  },
  {
    "title": "Helpcare AI (YC F24) Is Hiring Full Stack Engineer",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-02-20T21:00:33 1740085233",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "item?id=43120130",
    "first_paragraph": ""
  },
  {
    "title": "After 20 years, math couple solves major group theory problem (quantamagazine.org)",
    "points": 383,
    "submitter": "isaacfrond",
    "submit_time": "2025-02-20T10:09:56 1740046196",
    "num_comments": 112,
    "comments_url": "https://news.ycombinator.com/item?id=43113024",
    "comments": [
      "\"There was a risk that such a single-minded pursuit of so difficult a problem could hurt her academic career, but Sp\u00e4th dedicated all her time to it anyway.\"I feel like this sentence is in every article for a reason. Thank goodness there are such obsessive people and here's a toast to those counter-factuals that never get mentioned.\n \nreply",
      "> I feel like this sentence is in every article for a reason.\n\nBreakthroughs, BY DEFINITION, come from people going against the grain. Breakthroughs are paradigm shifts. You don't shift the paradigm by following the paradigm.I think we do a lot of disservice by dismissing the role of the dark horses. They are necessary. Like you suggest, there are many that fail, probably most do. But considering the impact, even just a small percentage succeeding warrants significant encouragement. Yet we often act in reverse, we discourage going against the grain. Often with reasons about fear of failure. In research, most things fail. But the only real failure is the ones you don't learn from (currently it is very hard to publish negative results. Resulting it not even being attempted. The system encourages \"safe\" research, which by its nature, can only be incremental. Fine, we want this, but it's ironic considering how many works get rejected due to \"lack of novelty\")\n \nreply",
      "> Breakthroughs, BY DEFINITION, come from people going against the grain. Breakthroughs are paradigm shifts.This is wrong. It's not inherent in the meaning of the word \"breakthrough\" that a breakthrough can occur only when someone has gone against the grain, and there are countless breakthroughs that have not gone against the grain. See: the four-minute mile; the Manhattan Project; the sequencing of the human genome; the decipherment of Linear B; research into protein folding. These breakthroughs have largely been the result of being first to find the solution to the problem or cross the theshold. That's it. That doesn't mean the people who managed to do that were working against the grain.> Yet we often act in reverse, we discourage going against the grain. Often with reasons about fear of failure.I don't know which \"we\" you're referring to, but just about everybody would agree with the statement that it's good to think creatively, experiment, and pursue either new lines of inquiry or old lines in new ways, so, again, your claim seems clearly wrong.If you're discussing just scientific research, though, sure, there are plenty of incentives that encourage labs and PIs to make the safe choice rather than the bold or innovative choice.\n \nreply",
      "Sounds like an argument over semantics and the meaning of the word \"breakthrough\".Running the 4 minute mile, climbing everest - those are achievements rather than breakthroughs.I'd also class the atomic bomb as an achievement - it was the expected/desired result of a massive investment program - though no doubt there were many breakthroughs required in order to achieve that result.\n \nreply",
      "Yea but this is HN where everyone is a disruptor and doesn\u2019t play by the rules\n \nreply",
      "> Often with reasons about fear of failure.If that were it, I would agree.But I don't agree. I think people who discourage going against the grain are more fearful of the loss of economic input. It's unproductive to do something you know will fail; it's very expensive to encourage that failure.\n \nreply",
      "Paradigm shifts require an accumulation of mundane experiments that present contradictions in a model. The renegade hacker isn't enough.\n \nreply",
      "> Breakthroughs, BY DEFINITION, come from people going against the grain.They are what Gladwell calls, in \"David and Goliath\", being unreasonable in the face of so-called \"prevailing wisdom\".\n \nreply",
      "I want financial independence for the sole reason that I can work on interesting problems like this without any outside nagging or funding issues from anyone else (there might still be some judgment, but I can ignore that).Personally I think governments should fund more moonshot solo or small team efforts because high risk / high reward pays off when you reduce the variance by spreading it out over so many people. But it looks like we\u2019re going headstrong the other direction in terms of funding in the U.S. right now, so I\u2019m not optimistic.\n \nreply",
      "> I want financial independence for the sole reason that I can work on interesting problems like this without any outside nagging or funding issues from anyone else\n\nDitto. This is literally the only desire I have to be wealthy. It is not about having nice things, a nice house, or any of that. It is about letting me do my own research.\n \nreply"
    ],
    "link": "https://www.quantamagazine.org/after-20-years-math-couple-solves-major-group-theory-problem-20250219/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesFebruary 19, 2025Kristina Armitage/Quanta MagazineContributing CorrespondentFebruary 19, 2025In 2003, a German graduate student named Britta Sp\u00e4th encountered the McKay conjecture, one of the biggest open problems in the mathematical realm known as group theory. At first her goals were relatively modest: She hoped to prove a theorem or two that would make incremental progress on the problem, as many other mathematicians had done before her. But over the years, she was drawn back to it, again and again. Whenever she tried to focus on something else, she said, \u201cit didn\u2019t connect.\u201dThere was a risk that such a single-minded pursuit of so difficult a problem could hurt her academic career, but S"
  },
  {
    "title": "Launch HN: Confident AI (YC W25) \u2013 Open-source evaluation framework for LLM apps",
    "points": 76,
    "submitter": "jeffreyip",
    "submit_time": "2025-02-20T16:23:56 1740068636",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=43116633",
    "comments": [
      "This looks nice and flashy for an investor presentation, but practically I just need the thing to work off of an API or if it is all local to at least have vllm support so it doesn't take 10 hours to run a bench.The extra long documentation and abstractions for me personally are exactly what I DONT want to have in a benchmarking repo. I.e. what transformers version is this, will it support TGI v3, will it automatically remove thinking traces with a flag in the code or running command, will it run the latest models that need custom transformer version etc.And if it's not a locally runnable product it should at least have a public accessable leaderboard to submit oss models too or something.Just my opinion. I don't like it. It looks like way too much docs and code slop for what should just be a 3 line command.\n \nreply",
      "I see, although most users come to us for evaluating LLM applications, you're correct that the academic benchmarking of foundational models is also offered in DeepEval, which I'm assuming what you're talking about.We actually designed it to make it easily work off any API. How it works is you just have to create a wrapper around your API and you're good to go. We take care of the async/concurrent handling of such benchmarking so the evaluation speed is really just limited by the rate limit of your LLM API.This link shows what a wrapper looks like: https://docs.confident-ai.com/guides/guides-using-custom-llm...And once you have your model wrapper setup, you can use any benchmark we provide.\n \nreply",
      ">This brings us to our current limitations. Right now, DeepEval\u2019s primary evaluation method is LLM-as-a-judge. We use techniques such as GEval and question-answer generation to improve reliability, but these methods can still be inconsistent. Even with high-quality datasets curated by domain experts, our evaluation metrics remain the biggest blocker to our goal.Have you done any work on dynamic data generation?I've found that even taking a public benchmark and remixing the order of questions had a deep impact on model performance - ranging from catastrophic for tiny models to problematic for larger models once you get past their effective internal working memory.\n \nreply",
      "Interesting, how are you remixing the order of questions? If we're talking about an academic benchmark like MMLU, the questions are independent of one another. Unless you're generating multiple answers in one go?Do do synthetic data generation for custom application use cases. Such as RAG, summarization, text-sql, etc. We call this module the \"synthesizer\", and you can customize your data generation pipeline however you want (I think, let me know otherwise!).Docs for synthesizer's here: https://docs.confident-ai.com/docs/synthesizer-introduction, there's a nice \"how does it work\" section at the bottom explaining it more.\n \nreply",
      ">Interesting, how are you remixing the order of questions? If we're talking about an academic benchmark like MMLU, the questions are independent of one another. Unless you're generating multiple answers in one go?Short version: if a model can answer a very high proportion of questions from a benchmark accurately then the next step is to ask it two or more questions at a time. On some models the quality of answers varies dramatically with which is asked first.>Docs for synthesizer's here: https://docs.confident-ai.com/docs/synthesizer-introduction, there's a nice \"how does it work\" section at the bottom explaining it more.Very good start, but the statistics of the generated text matter a lot.As an example on a dumb as bricks benchmark I've designed I can saturate the reasoning capabilities of all non-reasoning models just by varying the names of objects in the questions. A model that could get a normalized score of 14 with standard object strings could get a score as high as 18 with one letter strings standing for objects and as low as zero with arbitrary utf-8 character strings - which turns out mattered a lot since all the data was polluted with international text coming from the stock exchanges.Feel free to drop me a line if you're interested in a more in depth conversation. LLMs are _ridiculously_ under tested for how many places they show up in.\n \nreply",
      "This looks great. I would love to know more what makes Confident AI/DeepEval special compared to tons of other LLM Eval tools out there.\n \nreply",
      "Thanks and great question! There's a ton of eval tools out there but there are only a few that actually focuses on evals. The quality of LLM evaluation depends on the quality of dataset and the quality of metrics, and so tools that are more focused on the platform side of things (observability/tracing) tend to fall short on the ability to do accurate and reliable benchmarking. What tends to happen for those tools are users use them for one-off debugging, but when errors only happen 1% of the time, there is no capability for regression testing.Since we own the metrics and the algorithms that we've spent the last year iterating on with our users, we balance between giving engineers the ability to customize our metric algorithms and evaluation techniques, while offering the ability for them to bring it to the cloud for their organization when they're ready.This brings me to the tools that does have their own metrics and evals. Including us, there's only 3 companies out there that does this to a good extent (excuse me for this one), and we're the only one with a self-served platform such that any open-source user can get the benefit of Confident AI as well.That's not all the difference, because if you were to compare DeepEval's metrics on more nuance details (which I think is very important), we provide the most customizable metrics out there. This includes researched-backed SOTA LLM-as-a-judge G-Eval for any criteria, and the recently released DAG metric that is a decision-based that is virtually deterministic despite being LLM-evaluated. This means as user's use cases get more and more specific, they can stick with our metrics and benefit from DeepEval's ecosystem as well (metric caching, cost tracking, parallelization, integrated with Pytest for CI/CD, Confident AI, etc)There's so much more, such as generating synthetic data to get started with testing even if you don't have a prepared test set, red-teaming for safety testing (so not just testing for functionality), but I'm going to stop here for now.\n \nreply",
      "This is an awesome tool! Been using it since day 1 and will keep using it. Would recommend to anyone looking for an LLM Eval tool\n \nreply",
      "Was also looking at Langfuse.ai or braintrust.devAnybody with experience can give me a tip of the best way to\n- evaluate \n- manage prompts \n- trace calls\n \nreply",
      "It's actually langfuse.com! Our quickstart walks you through the whole process: https://docs.confident-ai.com/confident-ai/confident-ai-intr...\n \nreply"
    ],
    "link": "item?id=43116633",
    "first_paragraph": ""
  },
  {
    "title": "\"Test your adblocker\" websites can harm users and the adblocker ecosystem (brave.com)",
    "points": 33,
    "submitter": "ReadCarlBarks",
    "submit_time": "2025-02-20T21:06:05 1740085565",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=43120186",
    "comments": [
      "I'm a bit baffled that automated ad blocker tests exist in the first place. Historically the main difficulty in writing an ad blocker are the rules. How are you going to accurately test these rules by ... testing if they match your imagined rules.I guess there is always an opportunity to peddle a useless metric. If you actually wanted to do this right the obvious way would be manual review: pick X websites, visit them with each ad blocker, deduct points for visible ads and lost functionality. Repeat for each ad blocker, then rank them by score. That would also give you a nice score whether ad blockers or the advertising industry is currently \"winning\" the ad war\n \nreply",
      "Ad blockers are just the embodiment of the internet\u2019s social convention: send whatever bits you want, and I\u2019ll render them however I want. If somebody wants to sent me ads, I prefer not to render them. But they don\u2019t burn my eyeballs out.They are more like a picket fence, than a fortification with barbed wire and all that.If a site is really persistent about circumventing my adblocker, they are basically hostile to me and I should just leave.\n \nreply",
      "Isn't a high-quality ad blocker pretty self evident without a dedicated test page? Seems like these sites are directly pushing Goodhart\u2019s Law.\n \nreply",
      "welll, i just use all of them then. to me, those are more real world scenario than the one they link.\n \nreply",
      "Ok, where\u2019s your adblocker test then?\n \nreply",
      "If you really wanted to know, most of the tests for Brave's adblock engine are at https://github.com/brave/adblock-rust/tree/master/testsThose are automated unit and integration tests with controlled filter data as inputs. That's the only practically useful kind of test for an adblocker.\n \nreply",
      "They offer some testing sites at the bottom of the article:\n\"Brave will continue to work with legitimate testing sites like https://privacytests.org and https://coveryourtracks.eff.org\"\n \nreply",
      "Neither of those solve the problem of \u201cis my adblocker on\u201d. Maybe the Brave people should have done some research on why people use these sites rather than making a long blog post explaining why they are bad, actually, while not providing any alternatives for the things people want.\n \nreply",
      "\"Will continue to work with\"That's like saying bulletproof glass makers working with gun makers. How can you trust either when both are \"working together?\"This comes across as some sites make Brave look bad, and they are calling them out for whatever reason.--Also of note - De Beers owns the diamond certification company, which is convinient because why not.\n \nreply",
      "Are you suggesting that the EFF shouldn't be trusted because Brave works with them to suggest new tests and point out broken ones?\n \nreply"
    ],
    "link": "https://brave.com/blog/adblocker-testing-websites-harm-users/",
    "first_paragraph": "Privacy, extensions, and the best option for every platform.Crypto, NFTs, and all things blockchain. Learn the basics of Web3.Short, plain-language intros to common Internet and computer terms.See how Brave stacks up against other browsers and search engines.LLMs, machine learning, and the foundations of AI, for both users and devs.\nPublished Jan 9, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis post was written by Shivan Kaul Sahib (Lead for Privacy Engineering).Brave provides best-in-class privacy protections, including robust third-party ad and tracker blocking. As demand for privacy grows, more websites have emerged to compare web browsers and extensions. While some of these comparison tools, such as https://privacytests.org and https://coveryourtracks.eff.org, are valuable resources for privacy-conscious users, others can be significantly flawed. This post explores how some adblocking test websites\u2014those that claim to assess adblocker effectiveness\u2014fall short due to poor testing methodology, and even har"
  },
  {
    "title": "The difference between zoom and scale (css-tip.com)",
    "points": 3,
    "submitter": "t_afif",
    "submit_time": "2025-02-17T11:12:23 1739790743",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://css-tip.com/zoom/",
    "first_paragraph": "Do you know the zoom property? It works the same way as a scale transformation but unlike scale, it affects the page layout. In other words, the page layout is recalculated considering the new dimension of the scaled element.\nSee the Pen \n  Scale vs Zoom by Temani Afif (@t_afif)\n  on CodePen.\nCreated by Temani Afif (Support Me) | CSS Generators | CSS Loaders | CSS Shape | CSS Pattern"
  },
  {
    "title": "When your last name is Null, nothing works (wsj.com)",
    "points": 114,
    "submitter": "impish9208",
    "submit_time": "2025-02-20T12:39:36 1740055176",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=43113997",
    "comments": [
      "Gift link: https://www.wsj.com/lifestyle/null-last-name-computer-scient...",
      "https://archive.ph/KxNNu",
      "This is hilarious:  Even those without the last name Null are finding themselves caught in the void. Joseph Tartaro got a license plate with the word \u201cNULL\u201d on it nearly 10 years ago. The 36-year-old security auditor thought it would be funny to drive around with the symbol for an empty value. Maybe a police officer who tried to give him a ticket would end up writing null into the system and not be able to process it, he joked to himself.\n\n  In 2018 he paid a $35 parking ticket. Soon afterward, he said, his mailbox was flooded with hundreds of traffic tickets for incidents he hadn\u2019t been involved in. Tickets were from other counties and cities for vehicles of different colors, makes and models. A database had associated the word \u201cnull\u201d with his personal information and citations were sent to Tartaro, who lives in Los Angeles.\n \nreply",
      "> A database had associated the word \u201cnull\u201d with his personal information and citations were sent to Tartaro, who lives in Los Angeles.I'm not the biggest expert on databases, although I've worked with them a bit, but how does this occur in the first place? Usually, associations are done with primary/foreign keys. What database would allow null in that case?\n \nreply",
      "There are so SO many databases out in the wild that were built by people with little regard for building them correctly - or they simply not programmers/DBA's in the first place, but their boss told them to just make it happen.\n \nreply",
      "If there are multiple systems involved, one of them produces a null and the other takes that as a key to create a record, but somewhere in between it gets stringified, then the string null might be accepted by a system using string keys.\n \nreply",
      "It'd be sufficient if a system involved somewhere in the process converted null values to strings. There's innumerable ways, but here's a simple one in Java:    final String myNullString = \"\" + null;\n    System.out.println(myNullString);\n \nreply",
      "They all do.  But these are seperate databases that get translated to text at some point and then converted to NullCREATE TABLE orders (\n    id INT PRIMARY KEY,\n    customer_id INT NULL,\n    FOREIGN KEY (customer_id) REFERENCES customers(id)\n);vsCREATE TABLE orders (\n    id INT PRIMARY KEY,\n    customer_id INT NOT NULL,\n    FOREIGN KEY (customer_id) REFERENCES customers(id)\n);\n \nreply",
      "My last name is a popular Irish name with an apostrophe in it. I have tons of issues with my name in forms. I'm basically a walking SQL injection detector.But also I've started to drop the apostrophe in most of my online profiles and things. So I think we're starting to see the end of apostrophes in people's names, thanks to some fun oddities of the internet and common database technologies.\n \nreply",
      "Do you also get the apostrophe get mangled into something like `&#39;` ?\n \nreply"
    ],
    "link": "https://www.wsj.com/lifestyle/null-last-name-computer-scientists-forms-f0a43b08",
    "first_paragraph": ""
  }
]