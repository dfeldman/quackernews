[
  {
    "title": "Long live American Science and Surplus (which needs your help) (milwaukeerecord.com)",
    "points": 142,
    "submitter": "thinkalone",
    "submit_time": "2025-05-28T20:47:30 1748465250",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=44120507",
    "comments": [
      "I went to one to help me with an idea for a 7th grade science fair when I was a child and the staff helped me figure out which items I needed, which included a bunch of electronics parts and motors I had no idea what I was doing with. They patiently and very enthusiastically explained to me how they worked, how to safely use them, and gave me encouragement on my ideas for the project. They thought it was a cool idea. I was really blown away. I went on to win that science fair but honestly could not have done it without their help.I still go back once in a while and love to look at the strange electronics parts they somehow acquired. I definitely love that someone decided to try to collect and sell these things.\n \nreply",
      "We used to have the most amazing little electronics store a lot like this called \"Ra-Elco\" in SLC, Utah, but specifically devoted to every wild bit of electronics you could imagine, ranging from individual little components of every sort all the way up to weird esoteric devices nobody's ever heard of (at least there were a lot I'd never seen before).  Totally love these kinda shoppes, and I truly wish they weren't such a dying breed.  :(\n \nreply",
      "I like these places too but I can see why they are dying. The number of SKUs people want has exploded and the cost competition from buying online is unreal. Recently I needed a motor driver in a hurry (a4988 or equivalent) and decided to \nvisit my local electronics shop. They wanted $9 for it (plus tax), which I was willing to pay, but were out of stock. So I went home and found a 5 pack of the exact same part for about $10, shipped from the US.The reality is that with these electronics things it's not just 20 or 30% cheaper to buy online, it's often 1/10 the price or better. I can order a 10 pack of pin headers for $1-2 from China and each of those headers costs 50c at my local shop.\n \nreply",
      "This is a benefit of having ultra dense industry specific zones like the Shenzhen SEZ. Physical vendors get the volume to warrant operating and reasonable pricing, buyers get components on short notice.Suburbanization set up the US for failure here, and the governments haven't bothered intentionally creating any equivalent of Shenzhen. Santa Clara county used to be the spot, and I'd regularly pick up quickturn PCBs in person. Still can, but if you're in SF you're probably going to wait for next day shipping unless it's super super important, in which case it could come from any domestic CM.\n \nreply",
      "This doesn't really solve you problem, but they did just open (or about to) a Micro Center in Santa Clara.\n \nreply",
      "Completely flabbergasted to see one of my favorite stores of all time at the top of HN. This place is an absolute gem and I have countless childhood memories of visiting the Milwaukee Av location.Heartbroken to see they\u2019re in financial distress. If there\u2019s any store worth saving it\u2019s this one.\n \nreply",
      "I ordered motors and pumps from that catalog as a kid.  Can you imagine I used to love going through the stuff they had on a paper catalog!\n \nreply",
      "These were my go-to guys for sciencey stocking stuffers at Christmas for my kids.  Their catalog was always a joy to read, with excellent puns.Like the guy who wrote the linked article, a GoFundMe for a for-profit enterprise rubs me the wrong way.  However, I just donated because of all the great memories they've provided me and my kids.  Seems like those of us that like these things may need to pitch in from time to time.I wonder if something like this could have helped Lindsay's Publications, who went out of business a decade ago.  I have so many fantastic books from them.  They're really worth a HN post all on their own.https://makezine.com/article/workshop/lindsays-technical-boo...\n \nreply",
      "Scored a lot of Lindsay's books when you still could (lot of build-your-own regenerative receivers and similar, reprints of \"The Boy Mechanic\", \"5 Acres and Independence\", etc.).I would suspect (hope) many have been \"archived\" at \"the org\".(EDIT: I see for example \"The Impoverished Radio Experimenter Vol. 4\": https://archive.org/details/impoverishedradi0000lind/mode/2u...)\n \nreply",
      "Lindsay retired. Not quite the same. I still miss them though, many interesting books and well currated\n \nreply"
    ],
    "link": "https://milwaukeerecord.com/city-life/long-live-american-science-surplus-which-needs-your-help/",
    "first_paragraph": ""
  },
  {
    "title": "A toy RTOS inside Super Mario Bros. using emulator save states (prettygoodblog.com)",
    "points": 137,
    "submitter": "notorious_pgb",
    "submit_time": "2025-05-28T20:15:43 1748463343",
    "num_comments": 28,
    "comments_url": "https://news.ycombinator.com/item?id=44120241",
    "comments": [
      "That's pretty neat.The metaphor I usually go for when it comes to for threads is having several widgets that need to be assembled.  To begin working on Widget B, you have to pause the work on Widget A.  Adding SMP is like adding a second person to help assemble widgets, but you're still using the same toolbox, so if you both need the same screwdriver, there's no performance benefit to having a second person.  Multicore is having multiple workbenches each with their own toolbox so they can operate completely in parallel.A mutex is like having a specialized tool that can only be used by one widget assembly at a time.  Like, each workbench might have a full set of screwdrivers, hammers, wrenches, sockets, etc., but you only have 1 welder.A semaphore is a tool that can be used by a limited number of widgets, like an oven that can fit up to 4 widgets.\n \nreply",
      "As a special challenge: explain (Software) Transactional Memory, as eg implemented in Haskell, in your metaphor.STM is pretty similar to how some databases implement transactions.\n \nreply",
      "> Adding SMP is like adding a second person to help assemble widgets, but you're still using the same toolbox, so if you both need the same screwdriver, there's no performance benefit to having a second person.This sounds like hyperthreading \u2013 or, maybe I'm missing the screwdriver in the metaphor :)\n \nreply",
      "This is a super cool visual demonstration of RTOS/scheduling! I love the region-based critical sections!I took a real-time operating systems course in university as an elective. One of the hardest courses I took the whole four years, but also one of the most interesting. Had a great professor, who gave really demanding, but very instructive, project-based assignments.I need to find a toy project to play around with this domain again.\n \nreply",
      "Thank you!I'm curious how effective you feel this specific example might've been if it were delivered during your course. I suspect I've stumbled across a really helpful teaching tool, but having not gone to university, I don't actually know how this stuff is being taught :v\n \nreply",
      "Nor I, but I've learned from the metaphor, for what that's worth. And the demystification of primitives has considerable value these days.\n \nreply",
      "> Nor I, but I've learned from the metaphor, for what that's worth.It's the sickest possible outcome for me, so: worth a lot!\n \nreply",
      "https://web.archive.org/web/20250528203416/https://prettygoo...https://archive.ph/msHkO\n \nreply",
      "This is simply amazing work, I take my hat off to you. And not just the threading in an emulator (which is a genius concept all by itself) but for the article itself - I have spent years trying to find the right way to articulate exactly your points in hopes of engaging people to learn more about the systems they\u2019re building on top of.From now on, I\u2019ll simply send out a link to this. Thank you!\n \nreply",
      "Last night I read an article about eliminating lag in emulators. It's done with a similar concept. Basically, for each frame, the emulator calculates the state for different button combinations. Then, based on the button you actually push, the state shown moves to the precalculated one.\n \nreply"
    ],
    "link": "https://prettygoodblog.com/p/what-threads-are-part-2",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: I rewrote my Mac Electron app in Rust (desktopdocs.com)",
    "points": 400,
    "submitter": "katrinarodri",
    "submit_time": "2025-05-28T16:53:11 1748451191",
    "num_comments": 278,
    "comments_url": "https://news.ycombinator.com/item?id=44118023",
    "comments": [
      "I recently went the other way (started a project in Tauri, moved to Electron) because of frustration with rendering differences between the web views employed on different platforms. Have you run into any cross platform UI bugs since you switched?It looks like your UI needs are pretty simple while computation is complex so the extra QA tradeoff would still be worth it for you. I'm just wondering if my experience was unusual or if rendering differences are as common as they felt to me.Also, did you go Tauri 2.0 or 1.0? 2.0 released its first stable release while I was mid-stream on v1, and migration was a nightmare/documentation was woefully inadequate. Did they get the docs sorted out?\n \nreply",
      "We are using system webviews for https://kreya.app (not Tauri, but a custom implementation) and the platform differences are seldom a problem...Polyfills fix most of the things and we are running automated end to end test on Linux, which catches most of the issues.IMO the most difficult thing is figuring out how far the users are behind with their webview version, mostly on Linux and macOS. Windows has done thinga right with their WebView2 implementation\n \nreply",
      "Wait - there's system webviews? On Mac, Windows, and Linux?Edit: It looks like Tauri uses the following platform webview features.https://github.com/tauri-apps/wry?tab=readme-ov-file#platfor...\n \nreply",
      "On the contrary it is a big big issue if you have a complex web app like we do. It was a PITA to deal with user bugs in a specific macos version with a 8y out of date webview.And the performances of webkitgtk are horrible on Linux.\n \nreply",
      "That\u2019s a big issue if you can\u2019t set a minimum required version for some reason, same for web apps in general - I rarely find much problems with platform behavior but that\u2019s probably because we just reject out of date browsers.\n \nreply",
      "Yeah I was wondering how you dealing with the inconsistency of the different webviews? Are you using jquery? Or data star? Or is your own custom made polyfill depending on your user base?TBH, a lite weight polyfill for most system webview would be refreshing change to all the spa frameworks out there.\n \nreply",
      "We actually haven't rolled out cross platform support yet with the Tauri version, so we will see how that goes. Our UI needs are simple, luckily. What kind of rendering differences were you seeing with Tauri? Was there one platform that worked the best/worst for your app? We'd love to support Windows next.With the Electron version of the app, we had issues running our bundled binaries on Macs with Intel chip. That caused us so many headaches that we decided for the rebuild on Tauri that we wanted to focus on one platform first (Macs with Apple chip) before supporting other platforms.We went with Tauri 1.4 and no issues so far. Will have to check out the docs for 2.0 migration and see what that looks like.\n \nreply",
      "I worked with an open-source project that uses Tauri 1.x and their migration has been blocked with issues for months. It was a nightmare for the span I was involved in, and it looks like it hasn't moved forward since I stopped.In particular, rendering and crashing issues specific to Linux have been blockers, but Tauri 1.x also has other rendering issues on Linux that 2.0 fixed. There's little to no guidance on what's causing the stability and new rendering problems or how to fix them.The app I worked on was a launcher that installed and managed content for an app, and the launcher invoked the app through command-line flags. Those flags arbitrarily fail to be passed in Tauri 1.x but work as expected in Tauri 2.x, but nobody we asked about it knows why.\n \nreply",
      "Tauri 2.0 migration can potentially give you some more performance benefits, because they've greatly enhanced the JS-Rust bridge especially when you're moving lots of data.\n \nreply",
      "We picked egui instead of tauri because we had more rust skills than web skills. Other than rastered text, whoch I can't find any customers who actually care, are there good reasons to go tauri? It seems widely used, but also widely complained about.\n \nreply"
    ],
    "link": "https://desktopdocs.com/?v=2025",
    "first_paragraph": "\nDesktop Docs is the all-in-one platform for advanced image and video search.\nOne-time purchase \u2022 No subscriptionRequires Mac with Apple Silicon (M1/M2/M3)Analyzes content, not just filenamesAll processing happens locallyResults in under 0.3 secondsNo subscription requiredTRUSTED WORLDWIDE\nJoin thousands of creators and studios who rely on Desktop Docs daily\nTrusted by leading production houses for efficient media managementEmpowering content creators with smart file organizationRecognized in AI Tech Suite for innovation in file management Testimonials  \nHear from professionals who use Desktop Docs every day\n \nHear from professionals who use Desktop Docs every day\nOperator, Broadcasting\"Desktop Docs is the best desktop search for my video projects. I used to spend hours scrolling through videos, but now I can find specific scenes in seconds.\"Professional Photographer\"As a photographer with tons of images, finding specific shots used to take forever. Desktop Docs' image search is incred"
  },
  {
    "title": "US Trade Court Finds Trump Tariffs Illegal (bloomberg.com)",
    "points": 214,
    "submitter": "master_crab",
    "submit_time": "2025-05-29T00:06:19 1748477179",
    "num_comments": 147,
    "comments_url": "https://news.ycombinator.com/item?id=44121732",
    "comments": [
      "Here's the ruling (PDF): https://www.cit.uscourts.gov/sites/cit/files/25-66.pdf",
      "https://archive.md/DMT9d",
      "I'm not a lawyer or even close to it, but why wouldn't the trump admin use the tariff act of 1930? quote:\"Whenever the President shall find as a fact that any foreign country places any burden or disadvantage upon the commerce of the United States by any of the unequal impositions or discriminations aforesaid, he shall, when he finds that the public interest will be served thereby, by proclamation specify and declare such new or additional rate or rates of duty as he shall determine will offset such burden or disadvantage, not to exceed 50 per centum ad valorem or its equivalent, on any products of, or on articles imported in a vessel of, such foreign country\"it does cap it at 50%, but I mean it seems like a much easier way to justify the tariff. is there something else about it that isn't as practical (other than being almost 100 years old)\n \nreply",
      "He would have to convince the courts that I don't like having a trade deficit with anyone somehow means our trading partners are \"placing a burden or disadvantage upon the commerce of the United States by any of the unequal impositions or discriminations aforesaid\"\n \nreply",
      "He doesn\u2019t have to convince the courts of that. The President makes foreign policy, not the courts. As long as the President is plausibly exercising a foreign policy power Congress gave him, the courts don\u2019t get to reweigh the evidence and decide for themselves whether the trade deficits result from other countries placing trade barriers or something else.\n \nreply",
      "The courts interpret the law, so in fact he does have to convince them that his interpretation is true.\n \nreply",
      "I don't think it requires the courts to agree - just that there's a burden or disadvantage and that it's in the \"public interest\" which seems like a pretty low bar to make up a story that sounds plausible. i think the idea that a trade deficit is a disadvantage is kinda brain dead, but it's plausible sounding enough to argue in court. throw in unequal tariff rates and it seems like an easier win than the IEEPA's emergency justification.\n \nreply",
      "> I don't think it requires the courts to agreeEventually the courts have to agree/disagree if someone starts challenging it up the chain.\n \nreply",
      "\"Aforesaid\" is a very specific word that means that the \"unequal impositions or discriminations\" refers back to specific concepts previously referenced in the law. He can't (legally) just invent his own interpretations for what \"unequal impositions\" and \"discriminations\" entails, he has to convince a court that the specific actions he's retaliating against are covered by the \"aforesaid\" definitions.Here's the complete text [0]. The act authorizes imposition of tariffs on any country that:> Imposes, directly or indirectly, upon the disposition in or transportation in transit through or reexportation from such country of any article wholly or in part the growth or product of the United States any unreasonable charge, exaction, regulation, or limitation which is not equally enforced upon the like articles of every foreign country; or> Discriminates in fact against the commerce of the United States, directly or indirectly, by law or administrative regulation or practice, by or in respect to any customs, tonnage, or port duty, fee, charge, exaction, classification, regulation, condition, restriction, or prohibition, in such manner as to place the commerce of the United States at a disadvantage compared with the commerce of any foreign country.This is pretty specific. The tariffs/customs/dues/whatever don't even have to be unfair relative to what the US charges on that country's imports into the US, it's specifically targeting cases where a foreign country discriminates against US trade over and beyond the dues it charges on other countries' trade.It'd be very difficult to prove that discriminatory treatment for each and every one of the 180+ countries caught up in Trump's tariffs.[0] https://www.law.cornell.edu/uscode/text/19/1338\n \nreply",
      "I\u2019m also none of those things, but that section of Smoot-Hawley appears to apply when a foreign country imposes such burdens on the United States * which is not equally enforced upon the like articles of every foreign country.\u201d So not just that it treats the US differently than itself, but that it treats the US differently than any other country.\n \nreply"
    ],
    "link": "https://www.bloomberg.com/news/articles/2025-05-28/trump-s-global-tariffs-blocked-by-us-trade-court",
    "first_paragraph": ""
  },
  {
    "title": "Compiler Explorer and the promise of URLs that last forever (xania.org)",
    "points": 213,
    "submitter": "anarazel",
    "submit_time": "2025-05-28T16:28:20 1748449700",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=44117722",
    "comments": [
      "Before 2010 I had this unquestioned assumption that links are supposed to last forever. I used the bookmark feature of my browser extensively. Some time afterwards, I discovered that a large fraction of my bookmarks were essentially unusable due to linkrot. My modus operandi after that was to print the webpage as a PDF. A bit afterwards when reader views became popular reliable, I just copy-pasted the content from the reader view into an RTF file.\n \nreply",
      "I use the SingleFile extension to archive every page I visit.It's easy to set up, but be warned, it takes up a lot of disk space.    $ du -h ~/archive/webpages\n    1.1T /home/andrew/archive/webpages\n\nhttps://github.com/gildas-lormeau/SingleFile\n \nreply",
      "storage is cheap, but if you wanted to improve this:1. find a way to dedup media2. ensure content blockers are doing well3. for news articles, put it through readability and store the markdown instead. if you wanted to be really fancy, instead you could attempt to programatically create a \"template\" of sites you've visited with multiple endpoints so the style is retained but you're not storing the content. alternatively a good compression algo could do this, if you had your directory like /home/andrew/archive/boehs.org.tar.gz and inside of the tar all the boehs.org pages you visited are saved4. add fts and embeddings over the pages\n \nreply",
      "1 and partly 3 - I use btrfs with compression and deduping for games and other stuff. Works really well and is \"invisible\" to you.\n \nreply",
      "i was considering a similar setup, but i don\u2019t really trust extensions. Im curious;- Do you also archive logged in pages, infinite scrollers, banking sites, fb etc?\n- How many entries is that?\n- How often do you go back to the archive? is stuff easy to find?\n- do you have any organization or additional process (eg bookmarks)?did you try integrating it with llms/rag etc yet?\n \nreply",
      "How do you manage those? Do you have a way to search them, or a specific way to catalogue them, which will make it easy to find exactly what you need from them?\n \nreply",
      "You must have several TB of the internet on disk by now...\n \nreply",
      "By the way, if you install the official Web Archive browser extension, you can configure it to automatically archive every page you visit\n \nreply",
      "This a good suggestion with the caveat that entire domains can and do disappear: https://help.archive.org/help/how-do-i-request-to-remove-som...\n \nreply",
      "recently I've come to believe even IA and especially archive.is are ephermal. I've watched sites I've saved disappear without a trace, except in my selfhosted archives.A technological conundrum, however, is the fact that I have no way to prove that my archive is an accurate representation of a site at a point in time. Hmmm, or maybe I do? Maybe something funky with cert chains could be done.\n \nreply"
    ],
    "link": "https://xania.org/202505/compiler-explorer-urls-forever",
    "first_paragraph": "The history is this: back in the old days (2012), we used to store the entire Compiler Explorer state in the URL. That got unwieldy (who would have thought encoding an entire compiler state in a URL might get a bit long?), so we added support for Google\u2019s link shortener goo.gl in March 2014. That meant short links were of the form goo.gl/abc123. Clicking a goo.gl link would eventually redirect you to the full URL link on our site, and we\u2019d decode the state from the URL.In 2016, Stack Overflow banned link shorteners because of how they cloak the actual destination of links. Abusers could post innocent goo.gl links that directed folks unwittingly to bad content. However, that meant our Compiler Explorer links were also affected. At the time, we had no intention of storing any user data, so we came up with a hack: we still used goo.gl, but we then rewrote the link we handed out to be godbolt.org/g/abc123 (where the abc123 is the goo.gl unique ID). We then redirected any hits to /g/abc123 "
  },
  {
    "title": "Japan Post launches 'digital address' system (japantimes.co.jp)",
    "points": 176,
    "submitter": "jmsflknr",
    "submit_time": "2025-05-28T16:33:49 1748450029",
    "num_comments": 122,
    "comments_url": "https://news.ycombinator.com/item?id=44117779",
    "comments": [
      "It's more of a URL shortener. Users are assigned 7-digit alphanumeric code that macroexpands into full address on participating websites as well as on some paper application processes. There are few safety checks to prevent abuses, and linked address can be changed later when you move.Many online address forms in Japan uses equivalent of ZIP code to do similar already, but the expanded address are as granular as ZIP codes - I always fill in the rest of the address, but if I think about it, the fractions of users who do religiously verify and clarify the addresses must be less than 100%. I suppose this code will initially solve that problem with minimal infra changes for both users and the PO.\n \nreply",
      "One thing that wasn't quite clear to me is whether your code is what e-commerce companies record, or the expanded address.Hopefully it's the code, because the benefit of this is that if you move, you wouldn't need to update your address with a bajillion different companies, just the post office.\n \nreply",
      "Interesting. More like a dns than physical address?\n \nreply",
      "But if it follows the person unchanged when they move then it's effectively a person addressing system / a synthetic ID for a person.\n \nreply",
      "Entering building names can be a bit of a pain. I'm not even sure if it's required - according to Wikipedia it looks like you can just keep adding dashes until you eventually get to room number (e.g. 4-5-10-103) [1]. But a lot of address forms ask for it, so I end up entering it anyway.[1] https://en.wikipedia.org/wiki/Japanese_addressing_system\n \nreply",
      "The building name is required in many cases because two buildings next to each other will often have the same ban-chi-go (i.e. 4-5-10 could refer to two apartment buildings that were originally on the same lot, both with room 103).It's exceedingly common, not just some edge-case you see every once in a while.\n \nreply",
      "Or just a hop of indirection like DNS that lets your \"address\" move with you.\n \nreply",
      "https://www.eircode.ie/This is Ireland's postal code system. There's a small level of privacy built in, specific to an address (many taxi drivers ask for this) and 7 digits long. Web forms use it too, so quite common in normal life.Surprisingly the postal service, An Post, don't use the postal code as their primary way to direct mail (as far as I understand) .\n \nreply",
      "> An Post, don't use the postal code as their primary way to direct mail (as far as I understand) .I'm not sure how the delivery system works exactly, but I think they use the eircode? Especially in the countryside there often isn't much more than that. At my previous address the street doesn't even have a name; but post addressed to \"my name, town, eircode\" got delivered.Also when the eircode was first introduced it really messed up the delivery, which seems to indicate they're using it?\n \nreply",
      "They do use it.Sorry I have it the wrong way round, there was earlier confusion which led to the below article and my incorrect understanding.The system uses the eircode and the postman uses the address. (It makes sense a person would use the street address.)https://www.irishtimes.com/news/ireland/irish-news/an-post-c...\n \nreply"
    ],
    "link": "https://www.japantimes.co.jp/business/2025/05/27/companies/japan-post-digital-address/",
    "first_paragraph": ""
  },
  {
    "title": "Compiling a neural net to C for a speedup (slightknack.dev)",
    "points": 188,
    "submitter": "todsacerdoti",
    "submit_time": "2025-05-28T17:22:47 1748452967",
    "num_comments": 64,
    "comments_url": "https://news.ycombinator.com/item?id=44118373",
    "comments": [
      "> I tried something new for the first time, which was to keep a journal during development.\n\nDO THIS!!!I cannot stress this enough!If you work in a professional science lab, say, physics, biology, chemistry, you are expected to keep an experiment journal. It provides more help to you than the company too (knowledge dump, liability, etc). I can't tell you how many times some stupid ass seemingly benign comment saved my behind. They're worth their weight in gold.For ML experiments I use wandb and hydra[0]. Put all your configs into hydra. Be fucking pedantic. You should log your seeds, versions, the date, and I mean everything. It only takes a few extra minutes to set this up but the one time you need it it'll save you hours. Dump all that into wandb AND your model checkpoints. You will forget what that checkpoint corresponds to. Make liberal use of wandb tags and comments (through hydra you can make these cli arguments to automate even if launching from slurm scripts). Turn on wandb's code saving.Most importantly, use those notebooks wandb gives you. Don't worry if it gets messy. It's a experiment notebook, it'll get messy. You'll get better with experience and as you find your style.It sounds like a lot of work but it really isn't. You can get this all done under 20 minutes and if you write it right you can just copy paste it moving forward (i.e. yeah, make a personal library). I can PROMISE you that one mishap will far outweigh this extra work. You look like a pretentious perfectionist but really I'm a lazy piece of shit rust doesn't want to spend hours or days debugging some stupid mistake I'm too dumb or tired to catch. The extra benefit is when shit world you can spin up some (wandb) sweeps and go do some other thing that's always behind.(On topic, stop using personal wandb accounts for your work experiments. They're like the best company out there, get your boss to pay. They provide an amazing service and are a delight to work with. I cannot speak highly enough about them. They're not the company you want to mooch from. I've literally seen this happen while working for a top 3 market cap which was already paying for seats and you just needed to send a slack message to one dude... not cool guys... not cool...)[0] https://hydra.cc/docs/intro/\n \nreply",
      "Same goes for something as simple as setting up a server.  You will forget, and if you don\u2019t write it down you\u2019ll have to figure it out again.\n \nreply",
      "Where did I put those configs again? Where did Bob put that script? Fuck, why didn't I write an ansible script. It's never a one off, and it serves as documentation. I'll remember after I make the same mistake next time.Also, environment modules for the winhttps://modules.readthedocs.io/en/latest/\n \nreply",
      "Use nix and you\u2019ll at least will be able to deploy the same again.\n \nreply",
      "One time my boss asked me to upgrade some servers and was surprised I put all my work in a script in version control. Then there was a second batch of servers.\n \nreply",
      "If your work is tracked in an issue-tracking system, you can put your in-progress thinking notes as comments there (if they don't go in the code or some other artifact).It helps to have a safe environment, among whomever might access that issue comment history.  If people don't feel safe exposing their thought process, then they won't do it, or they'll be stressed by presenting vulnerability, and even modify their problem-solving for appearances.(I have some more complicated options involving a wiki, but explaining requires too much context.  The issue-tracking comments solution is obvious.)What I try not to do is to introduce new places that important information goes.  If you don't rein this in, there will be an explosion of employees plastering your IP all over a bunch of random SaaSes, to be undiscovered or even lost to your company entirely (also, those other SaaS companies and hackers might get more use out of stealing your IP than you do).\n \nreply",
      "Blame -> pr -> issue is a great way to learn a codebase if your team is good about keeping a log of their work, which they generally should be.\n \nreply",
      "Chaotic energy haha, I like it. Thanks for the tips re: keeping a journal, I will do this more in the future. I usually keep development notes, though normally in markdown files scattered across the codebase or in comments, never by date in the README. In the future, I might make JOURNAL.md a standard practice in my projects? re:w&b, I used w&b when it first came out and I liked it but I'm sure it's come a lot further in the time since then. I will have to take a look!Also lol \"pretentious perfectionist\" I'm glad to finally have some words to describe my design aesthetic. I like crisp fonts, what can I say.\n \nreply",
      "> Chaotic energy haha, I like it\n\nMy boss says I'm eccentric. I say that's just a nice word for crazy lol> normally in markdown files scattered across the codebase or in commentsI used to do that too but they didn't end up helping because I could never find them. So I moved back to using a physical book. The wandb reports was the first time I really had something where I felt like I got more out of it than a physical book. Even my iPad just results in a lot of lost stuff and more time trying to figure out why I can't just zoom in on the notes app. I mean what is an iPad even for if it isn't really good for writing?But the most important part of the process I talked about is the logging of all the parameters and options. Those are the details you tend to lose and go hunting for. So even if you never write a word you'll see huge benefits from this.  > re:w&b\n\nWandb's best feature is that you can email them requesting a feature and they'll implement it or help you implement it. It's literally their business model. I love it. I swear, they have a support agent assigned to me (thanks Art! And if wandb sees this, give the man a raise. Just look at what crazy people he has to deal with)  >  lol \"pretentious perfectionist\" I'm glad to finally have some words to describe my design aesthetic\n\nTo be clear, I'm actually not. Too chaotic lol. Besides, perfectionism doesn't even exist. It's more a question about personal tastes and where we draw the line for what is good enough. I wish we'd stop saying \"don't let perfectionism get in the way of good\" because it assumes like there's universal agreement about what good enough is.\n \nreply",
      "Parameters and options, got it. I try to keep all configuration declarative and make building and running as deterministic as possible. Then I can commit whenever I do something interesting, that I can just checkout to revisit.\n \nreply"
    ],
    "link": "https://slightknack.dev/blog/difflogic/",
    "first_paragraph": "2025-05-27 \u00b7 About 25 minutes longtl;dr: I trained a neural network (NN), with logic gates in the place of activation functions, to learn a 3\u00d73 kernel function for Conway\u2019s Game of Life. I wanted to see if I could speed up inference by extracting the learned logic circuit from the NN. So, I wrote some code to extract and compile the extracted logic circuit to bit-parallel C (with some optimizations to remove gates that don\u2019t contribute to the output). I benchmarked the original NN against the extracted 300-line single-threaded C program.; compiling the NN to C resulted in a 1,744\u00d7 speedup! Crazy, right? Here\u2019s the repo: ~354 lines of Python/JAX, ~331 lines of C, if you want to reproduce it and/or mess around.While plumbing the intertubes (as one does), I came across this fun publication by the Self Organising Systems group at Google, about Differentiable Logic Cellular Automata. This research caught my attention (I mean, who doesn\u2019t love a pretty picture), and as I read it, I realized "
  },
  {
    "title": "Visualize and debug Rust programs with a new lens (sea-ql.org)",
    "points": 103,
    "submitter": "alex_hirner",
    "submit_time": "2025-05-25T08:33:46 1748162026",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=44086429",
    "comments": [
      "This is just a trace viewer. Except the trace visualization is vastly less dense than any standard trace viewer and seems to provide no meaningful execution time information.Compare to chrome://tracinghttps://www.chromium.org/developers/how-tos/trace-event-prof...I am not sure if trace visualizers were invented 20 years ago for the original time travel debuggers, but they have certainly been used for time travel debugging visualization since at least 20 years ago.\n \nreply",
      "It's definitely a little more than just a trace viewer.As the page reads, it is a time traveling debugger. You can jump back and forth between different snapshots of time during the execution of your program. It's neat because for compiled languages like rust doing something like this is more advanced.\n \nreply",
      "That is exactly how trace viewers have been used with time travel debuggers for literally, and I do mean literally, over 20 years.You click a point in the trace, you jump to that point in time. That has been the standard integration for decades.\n \nreply",
      "I was under the impression that with a trace viewer you would do that after the execution of the program has finished. Learned something!\n \nreply",
      "I want to use this right now, but two issues:- Bash script from Internet requiring sudo, no way- VSCode plugin? I don't use VSCode. I'm not switching from Zed (literally built in Rust for Rust development)Help me out, what can I do to try this?\n \nreply",
      "From a debugger's point of view, Rust is just another native code language. DWARF tells you how to get stacks, find variables, and interpret chunks of memory as data structures. Anyone trying to pitch you a debugger specifically for Rust is trying to ride a hype wave or just plain bamboozle you.\n \nreply",
      "That looks very impressive! Would give it a spin but as far as I can tell I can\u2019t use it with my Rust os kernel running inside qemu\n \nreply",
      "Does this work on macOS?On mobile (Firefox on iOS) why does this site keep putting animations in my face?\n \nreply",
      "This is very good. Excellent user-interface too. Reminded me of Pythontutor that I use.\n \nreply",
      "Cool, reminds me somewhat of Glamorous Toolkit [1], another project I just found out about. Excited to give it a try, I love these sort of \"explain a program as it's running\" type tools.1. https://gtoolkit.com/\n \nreply"
    ],
    "link": "https://firedbg.sea-ql.org/",
    "first_paragraph": "Visualize and debug Rust programs with a new lensA friend of Ferris, Terres the hermit crab is a member of the Rustacean family."
  },
  {
    "title": "What does \u201cUndecidable\u201d mean, anyway (buttondown.com/hillelwayne)",
    "points": 67,
    "submitter": "BerislavLopac",
    "submit_time": "2025-05-28T19:37:47 1748461067",
    "num_comments": 62,
    "comments_url": "https://news.ycombinator.com/item?id=44119890",
    "comments": [
      "This is a really nice explanation of decidability. One extra thing it might be worth mentioning is that there are many more functions `f : string -> boolean` then there are programs that implement those functions.When I first encountered this topic I had trouble intuitively understanding how there could not exist an `IS_HALTING` function when it is also just a function that takes in a string (representing a program plus its inputs) and outputs True or False depending on whether it halts or not.The argument in the article does a great job of showing that `IS_HALTING` cannot exist because it is in some sense \"too powerful\" but that means there is a mapping f : strings -> boolean that cannot be represented as a program, which seems weird if you've been programming for ages and every function you encounter is expressed as a program.The result becomes less weird when you realize that that almost all functions from string -> boolean are not expressible as a program. Why? Well there are countable many programs since there are only countably many finite length strings and every program, by definition, is a finite length string. However, there are uncountably many functions from string -> boolean since these functions map one-to-one to sets of strings (just let the set be all inputs that map to True) and the cardinality of the set of sets of strings is uncountable.This is essentially due to Cantor's diagonalization argument which shows you cannot put all elements in a set X into a 1-1 correspondence with all the subsets of X, even when X is countably infinite. This fact is at the heart of a lot of these computability results since it shows there is a gap between all functions (= any arbitrary subset of finite strings) and a program (= a finite string).\n \nreply",
      "One of my favorite insights is that the existence of undecidable problems is the same thing as the uncountability of real numbers.Too bad the author didn't get into it.\n \nreply",
      "I had exactly the same reaction, which prompted me to write this comment: https://news.ycombinator.com/item?id=44122045\n \nreply",
      "I'm curious if you could make an analogy to the idea of \"underspecified\" in FreeCAD.  It isn't that the drawing doesn't exist.  It is that you still have some freedom in how long certain parts could be.  Crucially, not all.  It could be that parts of the drawing are indeed fully specified.Same can go with programs.  You can constrain parts of it enough that you can answer some pretty specific questions.  And similar to how a drawing with fewer lines is easier to constrain, a program that has restricted constructs can be easier to constrain.\n \nreply",
      ">I'm curious if you could make an analogy to the idea of \"underspecified\" in FreeCAD.That is just solution theory of a non-linear system of equations. The solution space can have exactly one solution (fully constrained), more than one (under constrained) or zero (over constrained).To be honest I do not really see a connection.\n \nreply",
      "I meant more as how to mentally model it in a way that can get someone across the line.  My assertion is that caring about undecidability is almost certainly a waste of time for most people.  That said, the reason we work in small chunks is often so that we can more easily answer questions about programs.Moving the graphical drawing and constraints over to a symbolic system also helps see how many symbols it can take to cover a simple system.Of course, the real reason for me thinking on this is that I'm playing with FreeCAD for the first time in a long time.  :D\n \nreply",
      "I sometimes wonder if the concept of \u201cintelligence\u201d is going to benefit from a formal model the way \u201ccomputation\u201d benefited from Turing Machines.Are there classes of intelligence? Are there things that some classes can and cannot do? Is it a spectrum? Is the set of classes countable? Is it finite? Is there a maximum intelligence? One can dream\u2026\n \nreply",
      "Philosophers have been trying to define what it means to be conscious since forever. I think that is informally what you mean here.If you just mean what problems can it solve, and how quickly, we already have a well developed theory of that in terms of complexity classes -https://complexityzoo.net/Complexity_Zoo\n \nreply",
      "I don't either philosophical conceptions of consciousness or theories of computational complexity count as even \"efforts to formalize intelligence\". They are each focused on something significantly different.The closest effort I know of as far characterizing intelligence as such is Steven Smale's 18th problem.https://en.wikipedia.org/wiki/Smale%27s_problems\n \nreply",
      "The wikipedia article is pretty useless here.The original paper is better, but still seems to be too vauge to be useful. Where it isn't vauge it seems to point pretty strongly to computability/complexity theory.Intelligence means many different things to different people. If we just gesture vaugely at it we aren't going to get anywhere, everyone will just talk past each other.\n \nreply"
    ],
    "link": "https://buttondown.com/hillelwayne/archive/what-does-undecidable-mean-anyway/",
    "first_paragraph": "I'll be speaking at Systems Distributed next month! The talk is brand new and will aim to showcase some of the formal methods mental models that would be useful in mainstream software development. It has added some extra stress on my schedule, though, so expect the next two monthly releases of Logic for Programmers to be mostly minor changes.Last week I read Against Curry-Howard Mysticism, which is a solid article I recommend reading. But this newsletter is actually about one comment:I like to see posts like this because I often feel like I can\u2019t tell the difference between BS and a point I\u2019m missing. Can we get one for questions like \u201cIsn\u2019t XYZ (Undecidable|NP-Complete|PSPACE-Complete)?\u201d I've already written one of these for NP-complete, so let's do one for \"undecidable\". Step one is to pull a technical definition from the book Automata and Computability:A property P of strings is said to be decidable if ... there is a total Turing machine that accepts input strings that have property"
  },
  {
    "title": "What If We Had Bigger Brains? Imagining Minds Beyond Ours (stephenwolfram.com)",
    "points": 68,
    "submitter": "nsoonhui",
    "submit_time": "2025-05-25T13:46:56 1748180816",
    "num_comments": 73,
    "comments_url": "https://news.ycombinator.com/item?id=44087809",
    "comments": [
      "I kind of skipped through this article, but one thing occurs to me about big brains is - cooling. In Alastair Reynolds Conjoiner novels, the Conjoiners have to have heat-sinks built into their heads, and are on the verge of not really being human at all. Which I guess may be OK, if that's what you want.\n \nreply",
      "I believe it's the Revelation Space series of Alastair Reynolds novels that mention the Conjoiners.\n \nreply",
      "Yes, and other ones, such as \"The Great Wall of Mars\" - it's the same shared universe, all of which feature the Conjoiners and their  brains and starship drives.\n \nreply",
      "Couldn't you just watercool brains? Isn't that how they're cooled already?\n \nreply",
      "Well, our entire body works as a swamp cooler via sweat evaporation, yes. The issue with us is wet bulb temps and dehydration. It can already brain damage us pretty quickly and makes some parts of the world already dangerous to exist in outside.Adding to this cooling load would require further changes such as large ears or skin flaps to provide more surface area unless you're going with the straight technological integration path.\n \nreply",
      "Reminds me of how Aristotle thought that the brain\u2019s purpose was to cool the blood.\n \nreply",
      "trivia: brain heatsinks also feature in Julian May's Pliocene Saga (in The Adversary IIRC) and A.A. Attanasio's Radix\n \nreply",
      "Wolfram\u2019s \u201cbigger brains\u201d piece raises the intriguing question of what kinds of thinking, communication, or even entirely new languages might emerge as we scale up intelligence, whether in biological brains or artificial ones.It got me thinking that, over millions of years, human brain volume increased from about 400\u2013500 cc in early hominins to around 1400 cc today. It\u2019s not just about size, the brain\u2019s wiring and complexity also evolved, which in turn drove advances in language, culture, and technology, all of which are deeply interconnected.With AI, you could argue we\u2019re witnessing a similar leap, but at an exponential rate. The speed at which neural networks are scaling and developing new capabilities far outpaces anything in human evolution.It makes you wonder how much of the future will even be understandable to us, or if we\u2019re only at the beginning of a much bigger story. Interesting times ahead.\n \nreply",
      "There is a popular misconception that neural networks accurately model the human brain. It is more a metaphor for neurons than a complete physical simulation of the human brain.There is also a popular misconception that LLMs are intelligently thinking programs. They are more like models that predict words and appear as a human intelligence.That being said, it is certainly theoretically possible to simulate human intelligence and scale it up.\n \nreply",
      "The future that we don't understand is already all around us. We just don't understand it.\n \nreply"
    ],
    "link": "https://writings.stephenwolfram.com/2025/05/what-if-we-had-bigger-brains-imagining-minds-beyond-ours/",
    "first_paragraph": "What If We Had Bigger Brains? Imagining Minds beyond Ours(VIDEO)We humans have perhaps 100 billion neurons in our brains. But what if we had many more? Or what if the AIs we built effectively had many more? What kinds of things might then become possible? At 100 billion neurons, we know, for example, that compositional language of the kind we humans use is possible. At the 100 million or so neurons of a cat, it doesn\u2019t seem to be. But what would become possible with 100 trillion neurons? And is it even something we could imagine understanding? My purpose here is to start exploring such questions, informed by what we\u2019ve seen in recent years in neural nets and LLMs, as well as by what we now know about the fundamental nature of computation, and about neuroscience and the operation of actual brains (like the one that\u2019s writing this, imaged here): One suggestive point is that as artificial neural nets have gotten bigger, they seem to have successively passed a sequence of thresholds in cap"
  },
  {
    "title": "Basic for the Raspberry Pi Pico and Pico 2 (geoffg.net)",
    "points": 21,
    "submitter": "AlexeyBrin",
    "submit_time": "2025-05-25T12:10:44 1748175044",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://geoffg.net/picomite.html",
    "first_paragraph": "\n\n \n\nBASIC on Raspberry Pi Pico and Raspberry Pi Pico 2\nBASIC Interpreter\n BASIC with VGA/HDMI\n BASIC with WiFi & Internet\n MMEdit IDE for MMBasic\n\nMaximite Family\nColour Maximite 2 \nOriginal Colour Maximite \nMonochrome Maximite \nThe Maximite Story\n\nMicromite Family\nMicromite Summary \nStandard Micromite \nMicromite Plus \nThe Microbridge \n\nMicromite LCD Backpack\nMicromite LCD Backpack \nAir Quality Monitor \nDDS Signal Generator \nSuper Clock \nBoat Computer MkII \nParking Assistant \n\nOther Projects\nPico Gamer Console \nPrecision Analog Clock \nWatering Controller \nWindows/DOS MMBasic \nASCII Video Terminal \nUtility Power Supply\nPrecise Voltage Reference\nISM Band Scanner\nGame of Pong\nSimple GPS Based Clock \n\nUseful Techniques\n3D Printed Cases\nMeasuring Capacitor ESR\nSurface Mount is Easy\nProgramming PIC Micros\nCustom PC Boards\nThe Gerber Format\n\nGeneral Articles\nA History of MMBasic\nProblems in Open Source\nHantek DSO-2250 Scope\nRigol DS1000 Scope\nBrickbats\n\nWEB Site\nHome \nOld or Obsolete Project"
  },
  {
    "title": "Show HN: Tesseral \u2013 Open-Source Auth (github.com/tesseral-labs)",
    "points": 134,
    "submitter": "ucarion",
    "submit_time": "2025-05-28T15:27:42 1748446062",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=44117059",
    "comments": [
      "From the docs:Users exclusively belong to Organizations; every User belongs to exactly one Organization.But I also see a screenshot where, after login, the User has to choose an organization or to create a new one. It seems to me that you support Users and Organizations in a many-to-many relationship, is that correct?At my work, we landed on the terminology of Users, Memberships, and Accounts to describe this (a User can have Memberships to multiple Accounts, an Account can have multiple Members, etc). As a result, you don't \"delete a user\", you \"revoke a membership\".\n \nreply",
      "(I'm the other cofounder of Tesseral).Yeah, this is a line I wrote and could probably improve the clarity on. It's worth distinguishing the Tesseral concept of a User from the sense in which we might colloquially refer to a user. Some other people call the equivalent of a Tesseral User a Member or something similar.An individual human being who wants to log in can be represented by multiple Users in Tesseral, each of which belongs to exactly one Organization.That is, there's support for a given person with a given email address to participate in different workspaces, but each workspace will have a different instance of a User.\n \nreply",
      "That feels needlessly confusing and not a great way to handle large orgs. Datadog does a similar thing\u2014I need to completely switch contexts to start working in a separate organization and there's absolutely no way to open tabs from two orgs side by side. Not to mention, any link to a dashboard or alert will fail until I go and select the right org from the dropdown (and if I don't know what org the link is in from context, I have no way to find it).I don't think new auth services should encourage this pattern and I highly recommend that you remove this restriction as soon as possible before it becomes even more baked in. Your downstream services should have access to all of the orgs a user belongs to right from the beginning, using a comma-separated list or multi-value headers or something similar. Don't shard user IDs in this way.\n \nreply",
      "\"An individual human being who wants to log in can be represented by multiple Users in Tesseral, each of which belongs to exactly one Organization.\"This will be extremely confusing. You should simplify it and just keep the concept of User as we usually do. A user should have access to 1 or more organizations. That's it. You should rethink this otherwise it will be too confusing.\n \nreply",
      "I think FusionAuth does something similar. They have a global user, and uses the notion of tenants / application registrations (which I think is comparable to a Tesseral Organization) to segment the same user.Then you can define applications (which are mapped 1:1 to tenants) where a user has a registration entry against that application, where a user can be referenced by their global user id, or application-specific user id.Applications are OAuth2 applications (meaning a dedicated client id / secret), so we only create a single application and tenant, and maintain organization segmentation on our own application / db side instead.(We're paying customers of FusionAuth. Anyone from FusionAuth, feel free to correct me.)\n \nreply",
      "I think the logic is to differentiate the \"identity\" from a \"user\"One identity can have multiple users (one for each organization)\nAt the same time, a user can have multiple identities. (e.g. username/password, Google oAuth, SAML etc.)\n \nreply",
      "Great demo videos -- looks like lots of strong design decisions! Will definitely try this in a future project.... actually, given you already have a Golang SDK, I may try this very soon!\n \nreply",
      "Congrats on the launch Ulysse - impressive what you have been able to spin up with limited resources! Greetings from Ory :)\n \nreply",
      "How does it compare to Keycloak?\n \nreply",
      "We're trying to offer a clear abstraction for specifically B2B SaaS. By taking opinions, we can make implementation quicker and easier for developers.\n \nreply"
    ],
    "link": "https://github.com/tesseral-labs/tesseral",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open source auth infrastructure for B2B SaaS\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Tesseral is open source auth infrastructure for business software (i.e., B2B\nSaaS).Tesseral is a multi-tenant, API-first service designed to run on the cloud. It\nis not an authentication library tied to a particular language or framework;\nTesseral works with any tech stack.Most developers should start by using Tesseral's managed service, available at\nconsole.tesseral.com. You can also self-host\nTesseral.Tesseral bundles everything that a developer needs to manage users in business software.We encourage all developers to read the full documentation first, which is\navailable at tesseral.com/docs. This README provides only a very brief subset of\nthe docs to illustrate s"
  },
  {
    "title": "A Visual History of Chessmen (chesshistory.github.io)",
    "points": 39,
    "submitter": "alberto-m",
    "submit_time": "2025-05-25T14:00:07 1748181607",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=44087898",
    "comments": [
      "What do I picture?  2D pieces, to be honest.  Computer chess is just so prevalent.  I picture what I'd call \"USCF style\" [1] because that's what they'd use in the Chess Life magazine to annotate games.  I also picture the \"old style\" pieces [2], used in other periodicals & some books (especially puzzles).I bet a lot of people picture the default set on Chess dot com.  I find it very hard to adjust to new sets, for whatever reason.As far as real pieces, I picture plastic pieces & vinyl board.  Either what I'd call the \"triple-weighted set\" [3] (my favorite), the plastic \"Dreuke set\" [4], or the \"basic USCF set\" [5].I had no idea there were so many variations, especially in the last 100 years.  Most I've never seen before.  I still dislike the real abstract/bauhaus style but there's a lot of artistry in the sets.[1]  on lichess, it's called \"companion\"[2]  on lichess, it's called \"leipzig\"[3]  https://www.chessset.com/collections/weighted-chess-pieces-h...[4]  Player's Choice, like https://www.wholesalechess.com/reproduction-of-the-drueke-pl...[5]  https://www.uscfsales.com/single-weighted-regulation-plastic...\n \nreply",
      "An amazing page with a lot of chess designs, definitely did not expect that many, and was surprised that the beloved Staunton chess set was designed by someone else.\n \nreply",
      "This is very nice. The full list however would be much too large, however, e.g.- Louis Vuitton is included and Super Mario was not, even though it has been very popular.- Wartime travel set pieces are included which are arguably tokens representing chess pieces and not formal chess pieces, and that is well and good, but even more cheap stone sets were sold to tourists in Mexico that had a distinctive look which are not mentioned here.- No mention of other variations of chess and how those pieces evolved.- Many online stores sell chess pieces in variations unmentioned.\n \nreply",
      "Equally, I would argue the Louis Vuitton set is not worth mentioning. One of the benefits of living in modern society is not having to look to the rich for signals of taste.\n \nreply",
      "Neat. This would be fun to model for 3D printing. I once did a chess set in OpenSCAD. https://github.com/iamwilhelm/kings_gambit\n \nreply",
      "My ex-wife (long ago) made me a set of chess pieces in resin as a birthday present, in a kind of Norse style, which were quite nice. And my dad had a set of plastic ones in a sort of Gothic style. Bothe were good, but I still think Staunton is the best.\n \nreply"
    ],
    "link": "https://chesshistory.github.io/",
    "first_paragraph": "v 3.7.web 2025\r\n\t\t\tWhen you or I think about chess, what pieces do we picture? What pieces do people in other countries picture? What did people in the past picture? This is a timeline of chess set designs through history.\n\r\n\t\t\tJump to: \r\n\t\t\t\nAncient history\nLate antiquity\nEarly middle ages\nLate middle ages\n16th century\n17th century\n18th century\n19th century\n1900-1950\n1950s\n1960s\n1970s\n1980s\n1990s\n21st century\n\n2,500 BCThe earliest ancestors of chess may have been played by the Indus Valley civilisation more than four thousand years ago. Clay figurines discovered in Lothal may be the earliest \"chessmen\".The Lothal \"chessmen.\"7th C. CEBy the 7th Century CE, people in India were playing chaturanga (\"four divisions\"). The name refers to four types of solider that made up the game\u2014infantry, cavalry, elephants, and chariots, commanded by a raja\u2014that were modeled on the armies of the time. It was the innovation of these different piece types, which each moved in different ways, that distingu"
  },
  {
    "title": "HTAP Databases Are Dead (mooncake.dev)",
    "points": 29,
    "submitter": "moonikakiss",
    "submit_time": "2025-05-28T22:22:18 1748470938",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=44121177",
    "comments": [
      "Terrible scrolling aside;> pg_mooncake is a PostgreSQL extension adding columnstore tables with DuckDB execution for 1000x faster analytics. Columnstore tables are stored as Iceberg or Delta Lake tables in your Object Store. Maintained by Mooncake Labs, it is available on Neon Postgres.Seems to summarise the reason this article exists.Not that I really disagree with the premise or conclusion of the article itself.\n \nreply",
      "That is the worst smooth scrolling hijack I've ever seen, and the whole site breaks if you disable javascript.\n \nreply",
      "[flagged]",
      "I'm much more offended by your egregious copy paste comment than the actual site experience.\n \nreply",
      "I've always been impressed by the architecture of the Hyperscale service tier of MSSQL in Azure. It is arguably a competitor in this area.https://learn.microsoft.com/en-us/azure/azure-sql/database/h...\n \nreply",
      "Hyperscale/Aurora are definitely not competitors and it seems odd you got that premise from the article since it argues the complete opposite.\n \nreply",
      "Anyone have any first-hand experience combining transactional and analytic workloads on this vs. Aurora, or something like CockroachDB? Seems like a major advantage of CockroachDB is being able to horizontally scale writes.\n \nreply",
      "From a modern startup\u2019s POV - fast pivots, fast feedback - it\u2019s fair to say HTAP is \u201cdead.\u201d The market is sticky and slow-moving. But I\u2019d argue that\u2019s precisely why it\u2019s still interesting: fewer teams can survive the long game, but the payoff can be disproportionate.\n \nreply",
      ">Cursor is powered by a single-box Postgres instanceWhy wouldn't it? The resources needed to run the backend of Cursor come from the compute for the AI models. Updating someone's quota in a database every few minutes is not going to be causing issues.\n \nreply",
      "In the nosql era the idea that you could run even the basics for a >1m user SaaS platform on an ordinary, free, single-node transactional SQL database would have been considered nuts.\n \nreply"
    ],
    "link": "https://www.mooncake.dev/blog/htap-is-dead",
    "first_paragraph": ""
  },
  {
    "title": "Unlocking Ractors: class instance variables in Ruby (byroot.github.io)",
    "points": 25,
    "submitter": "hahahacorn",
    "submit_time": "2025-05-26T21:49:48 1748296188",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://byroot.github.io/ruby/performance/2025/05/24/unlocking-ractors-class-variables.html",
    "first_paragraph": "\nMay 24, 2025\n      In a previous post about ractors, I explained why\nI think it\u2019s really unlikely you\u2019d ever be able to run an entire application inside a ractor, but that they could\nstill be situationally very useful to move CPU-bound work out of the main thread, and to unlock some parallel algorithm.But as I mentioned, this is unfortunately not yet viable because there are many known implementation bugs that can lead\nto interpreter crashes, and that while they are supposed to execute in parallel, the Ruby VM still has one true global\nlock that Ractors need to acquire to perform certain operations, making them often perform worse than the equivalent\nsingle-threaded code.One of these remaining contention points is class instance variables and class variables, and given it\u2019s quite frequent\nfor code to check a class or module instance variable as some sort of configuration, this contention point can have a very\nsizeable impact on Ractor performance, let me show you with a simple benchma"
  },
  {
    "title": "LLM codegen go brrr \u2013 Parallelization with Git worktrees and tmux (skeptrune.com)",
    "points": 94,
    "submitter": "skeptrune",
    "submit_time": "2025-05-28T15:13:38 1748445218",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=44116872",
    "comments": [
      "What I don't like about this approach is that it mainly improves the chances of zero-shotting a feature, but I require a ping pong with the LLM to iterate on the code/approach. Not sure how to parallelize that, I'm not gonna keep the mental model of 4+ iterations of code in my head and iterate on all of them.For visual UI iteration this seems amazing given the right tooling, as the author states.I could see it maybe useful  for TDD. Let four agents run on a test file and implement until it passes. Restrict to 50 iterations per agent, first one that passes the test terminates other in-progress sessions. Rinse and repeat.\n \nreply",
      "> but I require a ping pong with the LLM to iterate on the code/approachI've never got results from any LLM when doing more than one-shots. I basically have a copy-pastable prompt, and if the first answer is wrong, I update the prompt and begin from scratch. Usually I add in some \"macro\" magic too to automatically run shell commands and what not.It seems like they lose \"touch\" with what's important so quickly, and manages to steer themselves further away if anything incorrect ends up at any place in the context. Which, thinking about how they work, sort of makes sense.\n \nreply",
      "That doesn't take away from the OP's point (and OP didn't specify what ping ponging looks like, could be the same as you're describing), you are still iterating based on the results, and updating the prompt based on issues you see in the result. It grates on a human to switch back and forth between those attempts.\n \nreply",
      ">From the post: There is no easy way to send the same prompt to multiple agents at once. For instance, if all agents are stuck on the same misunderstanding of the requirements, I have to copy-paste the clarification into each session.It's not just about zero shotting. You should be able to ping pong back and forth with all of the parallel agents at the same time. Every prompt is a dice roll, so you may as well roll as many as possible.\n \nreply",
      "> Every prompt is a dice roll, so you may as well roll as many as possible.Same vibe as the Datacenter Scale xkcd -> https://xkcd.com/1737/\n \nreply",
      "I write docs often and what works wonders with LLM is good docs. A readme a architectural doc etc.Helps me to plan it well and the LLM to work a lot better\n \nreply",
      "Bonus! Future you and other devs working in the system will benefit from docs as well.\n \nreply",
      "Yah it's not really usable for iteration. I don't parallelize this way. I parallelize based on functions. Different agents for different function.Meanwhile, a huge problem in parallelization is maintaining memory-banks, like https://docs.cline.bot/prompting/cline-memory-bank\n \nreply",
      "I wonder why we should spend so much effort to do this vs. say using checkpoints in Cline for example. You could restore task and files to a previous state and try a different prompt/plan. And, the bonus is you have all of the previous context available.\n \nreply",
      "This looks like a much more sophisticated version of my setup. I had Aider vibe code me a script that just manages cloning a repo into a subfolder, optionally with some kind of identifying suffix on it, and then wrote a tiny script to automate calling that script, `cd`ing into the directory, and then running codex-cli on it. The resulting workflow: I open a new terminal, type `vibe --suffix=<suffix> <prompt>`, and then I can go do something else.\n \nreply"
    ],
    "link": "https://www.skeptrune.com/posts/git-worktrees-agents-and-tmux/",
    "first_paragraph": "This realization isn\u2019t unique to me; the effectiveness of using Git worktrees for simultaneous execution is gaining broader recognition, as evidenced by mentions in Claude Code\u2019s docs, discussion on Hacker News, projects like Claude Squad, and conversation on X.I\u2019m building a component library called astrobits and wanted to add a Toggle. To tackle the task, I deployed two Claude Code agents and two Codex agents, all with the same prompt, running in parallel within their own git worktrees. Worktrees are essential because they provide each agent with an isolated directory, allowing them to execute simultaneously without overwriting each other\u2019s changes.The number of agents I choose to rollout depends on the complexity of the task. Over time, you\u2019ll develop an intuition for estimating the right number based on the situation. Here, I felt 4 was appropriate.claude-1. Mostly correct, workable, but pixelated border-image and shadow needs fixing.claude-2. Completely broken, sliding circle too "
  },
  {
    "title": "Deepseek R1-0528 (huggingface.co)",
    "points": 275,
    "submitter": "error404x",
    "submit_time": "2025-05-28T17:59:02 1748455142",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=44118818",
    "comments": [
      "Well that didn't take long, available from 7 providers through openrouter.https://openrouter.ai/deepseek/deepseek-r1-0528/providersMay 28th update to the original DeepSeek R1 Performance on par with OpenAI o1, but open-sourced and with fully open reasoning tokens. It's 671B parameters in size, with 37B active in an inference pass.Fully open-source model.\n \nreply",
      "Is there a downloadable model? (Not familiar with openrouter and not seeing the model on ollama.)\n \nreply",
      "No sign of what source material it was trained on though right? So open weight rather than reproducible from source.I remember there's a project \"Open R1\" that last I checked was working on gathering their own list of training material, looks active but not sure how far along they've gotten:https://github.com/huggingface/open-r1\n \nreply",
      "Based on commit history Open R1 still active and they're still making progress. Long may it continue, it's an ambitious project.\n \nreply",
      "> No sign of what source material it was trained on though right?out of curiosity, does anyone do anything \"useful\" with that knowledge? it's not like people can just randomly train models..\n \nreply",
      "Would be useful for answering \"is this novel or was it in the training data\", but that's not typically what the point of open source is\n \nreply",
      "I don't think people make the distinction like that. The open source vs non open source distinction boils down to, usually, can you use it for commercial use.what you're saying is just that it's non reproducible, which is a completely valid but separate issue\n \nreply",
      "But where's the source? I just see a binary blob, what makes it open source?\n \nreply",
      "It's. not. open. source!https://www.downloadableisnotopensource.org/\n \nreply",
      "Open source is a crazy new beast in the AI/ML world.We have numerous artifacts to reason about:- The model code- The training code- The fine tuning code- The inference code- The raw training data- The processed training data (which might vary across various stages of pre-training and potentially fine-tuning!)- The resultant weights- The inference outputs (which also need a license)- The research papers (hopefully it's described in literature!)- The patents (or lack thereof)The term \"open source\" is wholly inadequate here. We need a 10-star grading system for this.This is not your mamma's C library.AFAICT, DeepSeek scores 7/10, which is better than OpenAI's 0/10 (they don't even let you train on the outputs).This is more than enough to distill new models from.Everybody is laundering training data, and it's rife with copyrighted data, PII, and pilfered outputs from other commercial AI systems. Because of that, I don't expect we'll see much legally open training data for some time to come. In fact, the first fully open training data of adequate size (not something like LJSpeech) is likely to be 100% synthetic or robotically-captured.\n \nreply"
    ],
    "link": "https://huggingface.co/deepseek-ai/DeepSeek-R1-0528",
    "first_paragraph": "No model cardChat templateFiles info"
  },
  {
    "title": "As a developer, my most important tools are a pen and a notebook (hamatti.org)",
    "points": 362,
    "submitter": "ingve",
    "submit_time": "2025-05-28T06:27:11 1748413631",
    "num_comments": 245,
    "comments_url": "https://news.ycombinator.com/item?id=44113210",
    "comments": [
      "Aside, as a SQL data analyst working with undocumented or poorly documented dbs and business processes .. notes are a lifesaver. Important / obscure details are easily forgotten. I used to use paper but confess to now using OneNote (hate it and hate MS, but it works).The other place where typed up notes are extremely useful is with business users and meetings that go back and forth ending in confusion. A shared screen with minimal notes that the requester sees (and agrees) works wonders in bringing focus.\n \nreply",
      "Great discussion. In my opinion, the real takeaway isn\u2019t about notebooks vs. digital tools,  it\u2019s about what shifts your mental gears. Every time we switch modes, it forces our brain to pay attention differently. That fresh context can boost focus, creativity, even recall.For example, I recently stopped coding all the time and picked up a new hobby at night, writing. That simple change gave my brain a reset and actually improved the performance during the day. Same goes for planning: switching from digital to pen and paper breaks the routine and makes your brain engage differently. It\u2019s less about the tool and more about how the change wakes you up.\n \nreply",
      "I wonder how many developers today were forced to take an introductory drafting class. I know a lot of us played with Lego. The problem of describing a 3 dimensional object in two dimensions requires extra projections to describe the thing. A 3d object in 2 dimensions takes three drawings to mostly describe. If the object is more complex than three dimensions, you need to look at it from a lot more angles.\n \nreply",
      "I had a drafting class as a freshman in engineering school. The professor would come to class with a piece of chalk and a string and proceed to us only these tools to construct complex three dimensional shapes, and show how to rotate them to give a different view.One small example of a problem we were required to learn was that of a pipe running through a space at some angle and determine if it intersected something important.\n \nreply",
      "Wow,  decades in this field and it finally took your comment to connect my childhood LEGO obsession with coding. Simple enough, but it never actually crossed my mind. The funny thing is, I\u2019ve always linked my love for storytelling to LEGO building, but not coding. Thanks for the insight, that just snapped into place.\n \nreply",
      "Did I love Lego because I was like this, or am I like this because I loved Lego?That'll bake your noodle for a good long while :)\n \nreply",
      "Whoa\u2026\n \nreply",
      "With respect to Lego and coding, now I'm thinking of the game Infinifactory, which has the nice property of yielding puzzle-answers where you can go: \"Hey, I built that! Look at it operate!\"\n \nreply",
      "The book Smarter Faster Better introduced me to the concept of disfluency - the idea that extra friction such as awkward fonts, new environments, different tools, etc will pull you out of autopilot mode and force you to think in new ways. I haven\u2019t seen references to it elsewhere, but it\u2019s changed how I approach problems and learning the last 9 years. Switching to a notebook is one great way I use to trigger this as well.\n \nreply",
      "Interesting. I noticed the same and sometimes I change my emacs theme just to get a fresh perspective. Sometimes I also disable syntax highlighting when typing so I won't get distracted.\n \nreply"
    ],
    "link": "https://hamatti.org/posts/as-a-developer-my-most-important-tools-are-a-pen-and-a-notebook/",
    "first_paragraph": "\n  After I signed my contract to join my new job a month ago, I was so excited.\n  Not only that I would join the company but also because I got to buy a new\n  notebook. The weekend before my first day I headed to the local bookstore and\n  spent a good amount of time browsing through the notebooks available and ended\n  up with this happy orange one.\nWhy am I so excited about a notebook then?\nBecause it\u2019s the most important tool I have as a software developer.\n\n  When it comes to building software or solving problems, writing code is the\n  necessary bit at the end where we tell the computer what to do but way more\n  important than writing that code is figuring out what code to write.\n\n  I learned very early on in my career that I\u2019m not very good at thinking when\n  I\u2019m at a computer. When I have my code editor open, I\u2019m in a \u201cfunction mode\u201d\n  where I write stuff that does something. When my brain hits that mode, there\u2019s\n  not much creative energies flowing around.\n\n  So I often step away "
  },
  {
    "title": "Grass Rendering Series (hexaquo.at)",
    "points": 12,
    "submitter": "ibobev",
    "submit_time": "2025-05-26T12:29:53 1748262593",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=44096823",
    "comments": [
      "I haven't run through the grass in a video game since Ocarina of Time, so those modern screenshots really impressed me.Have there been any games that tried to include species diversity in their grass? Around here anyways, there are 6 or 8 major pasture species, often in different growth stages at any given time of year.\n \nreply",
      "I think you might catch a butterfly or two in some games, but it's rare. I agree these nature environments often feel totally dead in games. Same with nature sounds. Devs usually get a bigger boner simulating wind and contact physics on each individual blade of grass (like this blog post does in part 3, of course).\n \nreply"
    ],
    "link": "https://hexaquo.at/pages/grass-rendering-series-part-1-theory/",
    "first_paragraph": "This is part 1 of a multi-part series on grass rendering. We\u2019ll start by figuring out how realistic grass should look like, and how herbage can be modeled with the tools we have at our disposal in real-time 3D graphics. Then, we\u2019ll look at how to implement different methods of grass rendering in Godot. However, most of the tutorial will not be Godot-specific aside from some node names and syntax.But before getting into any implementation details, we must first understand what grass even looks like.Some of the visual properties are quite surprising if you have never really paid attention to them. For one, grass is shiny, especially long grass. Check out the specular hightlights in this example:\nAlthough the random orientations of all the individual grass blades causes quite a rough appearance when looking at an entire field of grass - the specular highlights average out into a diffuse noise - the individual blades actually have quite strong specular reflections, and when looking at a fi"
  },
  {
    "title": "The Blowtorch Theory: A new model for structure formation in the universe (theeggandtherock.com)",
    "points": 129,
    "submitter": "surprisetalk",
    "submit_time": "2025-05-28T13:43:38 1748439818",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=44115973",
    "comments": [
      "Let me start by saying there are a lot of false claims in the dark matter section.\nIt's also filled with self contradiction, announcing that DM as wrong, and later pronouncing LCDM as unfalsifiable.\nThe pillars of modem cosmology are the ability to quantitatively describe and predict large-scale structure, the expansion history of the universe, the CMB and primordial nucleosynthesis.\nCan this \"model\" calculate any of those things? No. What the author has here is some ideas, not a model.To demonstrate you can even reproduce the Cosmic Web you have to actually run some calculations, or simulations.\nHow do you know AGN bubbles produce a universe that looks anything like ours?\nThe author dismisses simulations as \"not science\", while paradoxically using them as the only representation of the cosmic web in the article.\nThese simulations have a lot of value, they demonstrate that standard cosmology and normal gravity has no problem forming voids and filaments.\nThese simulations have been compared to countless new observations, which this model cannot because it's purely qualitative.\nThe article says these simulations are worthless because they don't work from first principles, this is a practical limitation that you cannot simulate galaxies down to the resolution of atoms on any existing computer. You have to make some simplifications. The structure of the cosmic web is seen in all of them, even going back to very early simulations, it doesn't depend on these assumptions.And at the end of the article we go back to the problem of dark matter, and find out the author has no explanation for rotation curves or other classical tests of DM.\nSo despite bashing DM cosmology, this model explains none of the pillars of evidence for dark matter.  At some point in developing an idea like this you need to actually start applying physics, either with calculations or simulations. Every new hypothesis is perfect before it has been subjected to rigor and analysis.\n \nreply",
      "I agree with most of what you've said here, particularly the following line which I'm copying for emphasis because I think it's incredibly important.> These simulations have a lot of value, they demonstrate that standard cosmology and normal gravity has no problem forming voids and filaments.That being said, I think the author intends for this article to be more of a call to action than an actual result. Simulations aren't cheap, somebody needs to actually do the work. The point that there aren't any simulations without dark matter is an important one too.\n \nreply",
      "One can do simple simulations on a laptop which show the cosmic web. It's not really an excuse for not having tried. There are lots of claims in the article which need to be justified, and in science that comes before making big claims.https://alvinng4.github.io/grav_sim/examples/cosmic_structur...These simulations take their simple initial conditions from the Cosmic Microwave Background fluctuations, but models without dark matter fail to match the observed CMB. There are no major baryon-only simulations because cosmology doesn't work without DM, and you have nothing to start from. You need a quantitative model which works on some level to even begin, people have tried with modified gravity models.\n \nreply",
      "We need a model that includes electromagnetism. The author isn't the only one making this claim. When we do magnetohydrodynamic cosmological sims we consistently find surprising effects. The recent simulation showing that black hole accretion disks are supported by magnetism comes to mind.[0][1]Apologies, I know this is typically considered bad form, but have you gotten to the following section in the article?[2] It appears to directly contradict your claims.> MOND\u2019s also been around since the early 1980s, but, in 2021, it finally developed a model \u2013 the Aether-Scalar-Tensor framework, or AeST \u2013 which ALSO maps perfectly onto the acoustic peaks revealed by WMAP and Planck. (It does it by proposing a new vector field and scalar field that duplicate the effects of Cold Dark Matter in the early universe...[0] https://astro.theoj.org/article/93065-an-analytic-model-for-...[1] https://www.caltech.edu/about/news/cosmic-simulation-reveals...[2] https://theeggandtherock.com/i/158515951/more-matter-or-less...\n \nreply",
      "I\u2019m slightly startled to see my Blowtorch Theory post at number one here. (A friend sent me a screenshot, so I came over to check if he was joking.)I\u2019m happy to answer questions, though I will be dealing with a five-year-old and eating dinner at the same time, which may lead to delayed responses.\n \nreply",
      "I think you should rework the style of the article to remove the \u201cdissing\u201d of the work that established \u039bCDM. It is doing the article a disservice, making it sound unprofessional and crackpot-y. If the Blowtorch Theory has merit, it will stand on its own.\n \nreply",
      "I do understand why you are critical of my decision to attack \u039bCDM and the work that led to it. I can see your point of view, and indeed I wrestled with that decision. I do realise that a lot of people will be alienated by the \"dissing\" of \u039bCDM, who would otherwise be attracted to Blowtorch Theory.But I feel that there are genuine problems with \u039bCDM that are making it hard for the field of cosmology to understand what it is seeing in the early universe, and I hope that my careful description of what I believe has gone wrong over the past few decades might have value for the field.It's simply impossible to ignore the enormous dark matter elephant in the room, especially given that \u039bCDM so comprehensively failed to predict what we are now seeing in the early universe. As I mention in my post, the extended version of cosmological natural selection that Blowtorch Theory emerges from DID predict exactly what we are seeing now. Here are those predictions, if you want to check them out:https://theeggandtherock.substack.com/p/predictions-what-the...In that context, it makes no sense to avoid mentioning \u039bCDM's recent failures: and if I'm going to do that, I feel I should offer my full diagnosis of what went wrong.But I have every respect for your position, and I understand it will be distasteful and offputting to many.\n \nreply",
      "It\u2019s perfectly fine to point out issues with \u039bCDM, how it seems to be inconsistent with certain recent observations, and how the Blowtorch Theory addresses them. That can be done in a neutral, professional, matter-of-fact tone. It\u2019s not okay to belittle the scientists who developed \u039bCDM by implying that they should have known better than allegedly deluding themselves into a misguided theory.\n \nreply",
      "Fascinating stuff!\nWhat seems a bit far fetched is that idea that black holes create new universes and in doing so somehow transfer some cosmological constants over.Is there anything that supports this? That is what the whole 'evolutionary universe' theory hinges on in the end. It certainly is a convenient explanation for the anthropic principle, but if any black hole however small it may be creates a universe - where do these universes go?The early direct collapse black holes responsible for the formation of galaxies and structure of the universe are certainly more easily digestible.\n \nreply",
      "Does it really matter though? There\u2019s the scientific part probably worth exploring and the philosophical and engagement part which will spark the imagination of sponsors. The first part can be verified in the foreseeable future. The second part may become falsifiable at rather unimaginable time scale, probably requiring an artificial black hole for experimentation and Kardashev Type II level of technology.\n \nreply"
    ],
    "link": "https://theeggandtherock.com/p/the-blowtorch-theory-a-new-model",
    "first_paragraph": ""
  }
]