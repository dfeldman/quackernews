[
  {
    "title": "A QR code that sends you to a different destination - lenticular and adversarial (mstdn.social)",
    "points": 89,
    "submitter": "zdw",
    "submit_time": "2025-01-23T23:55:34 1737676534",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=42809268",
    "comments": [
      "I guess an interesting attack would be a screen in a public setting that alters the QR code based on information it has about the current user, without appearing to change significantly.setup:- make the QR code as a half/half code- have a system to decide preference of target based on external input (e.g. camera based characteristic evaluation)- make slight dynamic alterations to the colours of the code to bias the probability of it being picked up as the desired target. Desirable black/white can be made blacker/whiter, less desirable less so.Where to use it maliciously:- anywhere where people provide feedback - present alternate feedback forms to different demographics to engender the most positive (or negative) results.- pretend to offer some form of probabilistic chance to win a prize, but bias winning to some identifiable characteristic. e.g. race, age, \"beauty\"- target a specific person - have them join a different WiFi network, alter a payment page, etc.In a static setting its less effective. I can't immediately think of a static attack that benefits from siphoning some reduced fraction of users.I'm doubtful most people would notice a QR code dynamically changing, particularly in most public lighting.\n \nreply",
      "Identifying this should be relatively easy in the core libraries; finding alternate valid QR codes using \"less optimal\" grids.Of course the API confusion here becomes non-trivial, which hampers securing against it. And with existing libraries being widespread, its going to linger as an attack for a long time.\n \nreply",
      "You don\u2019t need any of this if you control the app doing the scanning (or the website/app handling the result).\n \nreply",
      "You wouldn't control the app doing the scanning.The attack is that a user looking at a QR code cannot determine that they are being served a different code to another person.In a public setting a user would have no idea they are even capable of being targetted and treated differently.\n \nreply",
      "Static a/b testing?\n \nreply",
      "The most interesting thing about this to me is that on iOS a long press on the image claimed it's going to github.com, while the preview itself was for mastadon. This indicates that it's parsing the QR code twice and getting different results? I could see this being used to mislead some people, though I'm not sire how many people look at the long press dropdown URL.\n \nreply",
      "(Scroll up from the starting position to see the lenticular one)\n \nreply",
      "Interestingly, MacOS only sees the mastodon link when right clicking on the QR code.\n \nreply",
      "That makes sense, I would imagine it would require some variability via a camera with different angles/lighting conditions in order to get both links at different times.\n \nreply",
      "This would be cool to use in a scavenger hunt.\n \nreply"
    ],
    "link": "https://mstdn.social/@isziaui/113874436953157913",
    "first_paragraph": ""
  },
  {
    "title": "Thank HN: My bootstrapped startup got acquired today",
    "points": 1150,
    "submitter": "paraschopra",
    "submit_time": "2025-01-23T17:58:05 1737655085",
    "num_comments": 166,
    "comments_url": "https://news.ycombinator.com/item?id=42806247",
    "comments": [
      "My employer picked vwo over my own custom in house ab testing tool [0]. I was so pissed!Congrats, yours was the better tool.[0]: https://news.ycombinator.com/item?id=23471050\n \nreply",
      "There's no higher praise than \"I built my own; yours was better\"!\n \nreply",
      "Here's that earlier thread - thanks for pointing it out!Thank HN: My startup was born here and is now 10 years old - https://news.ycombinator.com/item?id=23466470 - June 2020 (128 comments)\n \nreply",
      "(Co-founder of Optimizely here) Congrats! It was fun competing with you\n \nreply",
      "Congrats!What made you commit and build this project when you were 22 year old vs million others SAAS you could have built at that time? Say, a CRM to compete with Salesforce, or a new web based Excel or web based Photoshop tool?\n \nreply",
      "Bravo, @paraschopra  What an incredible journey. I remember when you launched. I hadn't realized it was 16 years ago!I'll hit you up privately with an invite to tell your story on Startups for the Rest of Us. It's a fitting place for a bootstrapper like yourself.\n \nreply",
      "Hey Chopra,Thanks for sharing, this is really inspiring!Just wondering, for other bootstrappers, if you do end up selling for, I don't know, $200 million letsay, how does that money generally get split? What percentage of the company did you own before selling, and what were the tradeoffs when selling ownership?\n \nreply",
      "The TechCrunch article the OP linked above mentions this:> Chopra, who owned 71% of Wingify before the acquisition, will retain a minority stake in the firm, one of the sources said.\n \nreply",
      "Thanks\n \nreply",
      "@paras - I worked at Optimizely in the early days and led online marketing there from 2012 - 2016. I remember seeing your team copy our SEM strategy, so I added Hindu gods (shiva, vishnu, et al) to the UTM query params in our ads for your guys to dissect / get a laugh from.Congrats on the exit. really nice to see.\n \nreply"
    ],
    "link": "item?id=42806247",
    "first_paragraph": ""
  },
  {
    "title": "Susctl CVE-2024-54507: A particularly 'sus' sysctl in the XNU kernel (jprx.io)",
    "points": 66,
    "submitter": "jprx",
    "submit_time": "2025-01-23T22:37:57 1737671877",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=42808801",
    "comments": [
      "Seems like something to be integration tested in the future. Honestly surprised this slipped through.\n \nreply",
      "I saw that types are different, but I was thinking \"must be some weird C thing that I don't know about\"\n \nreply",
      "After this impressive write-up, yet no mention of any bounty for reporting this vulnerability.Getting a CVE attached to your name is ok, but no bounty for this to be honest is quite thankless from a trillion dollar company like Apple to not properly thank their researchers.All Apple gave back was the equivalent of a plastic medal and a gold sticker to the researcher.Unbelievable.\n \nreply",
      "It's not possible to apply human morale and principles to companies. It just does not work that way.Why would they pay if no profit if pay and they are not forced to pay?\n \nreply",
      "To inspire more of the same.\n \nreply",
      "Did you get a bounty payout for this? I got the impression that Apple wasn't particularly on the ball with those.\n \nreply",
      "Is it even exploitable in the real world?Correct me if I'm wrong but you get 2 bytes of kernel data (potentially blank padding) and the same two bytes each time?\n \nreply",
      "If the linker puts a pointer there, this would let you leak part of the pointer which could let you bypass kaslr. Not too likely for that to occur. If I were submitting this bug I would feel complete if they bought me a sandwich.\n \nreply",
      "The bottom 2 bytes of a pointer contain two bits of the slide, assuming it's even a pointer into the kernelcache itself.I'd take half a sandwich.\n \nreply",
      "Good to find the bug regardless! I appreciated the succinct and not overly dramatic write-up. I don't think anything significant was claimed other than the fact that it is a kernel bug (which is significant in itself don't get me wrong).\n \nreply"
    ],
    "link": "https://jprx.io/cve-2024-54507/",
    "first_paragraph": "\nTLDR: here is a PoC.Every time Apple releases a new version of XNU, I run a custom suite of tests under an address sanitizer to see if I can spot any regressions, or even possibly new bugs.\nWhen I was messing around with macOS 15.0, I was shocked to see a very simple command was causing the sanitizer to report an invalid load.If you run sysctl -a on macOS 15.0 running with KASAN, you'll see a crash like the following:In case you aren't familiar with sysctl's, they are basically a set of runtime-controllable kernel variables that you can adjust from userspace.\nA lot of the time, the underlying resource of a given sysctl is literally just an integer in the kernel somewhere (like this).\nThey're commonly used in kernel programming as a quick way to adjust parameters, and are used all over XNU.Running sysctl -a will enumerate all sysctl's in the system.\nSomehow, doing this causes an invalid load.There are a variety of ways to declare a sysctl using macros from sysctl.h with support for man"
  },
  {
    "title": "Llama.vim \u00e2\u20ac\u201c Local LLM-assisted text completion (github.com/ggml-org)",
    "points": 291,
    "submitter": "kgwgk",
    "submit_time": "2025-01-23T18:06:42 1737655602",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=42806328",
    "comments": [
      "Hi HN, happy to see this here!I highly recommend to take a look at the technical details of the server implementation that enables large context usage with this plugin - I think it is interesting and has some cool ideas [0].Also, the same plugin is available for VS Code [1].Let me know if you have any questions about the plugin - happy to explain. Btw, the performance has improved compared to what is seen in the README videos thanks to client-side caching.[0] - https://github.com/ggerganov/llama.cpp/pull/9787[1] - https://github.com/ggml-org/llama.vscode\n \nreply",
      "For those who don't know, He is the gg of `gguf`. Thank you for all your contributions! Literally the core of Ollama, LMStudio, Jan and multiple other apps!\n \nreply",
      "well hot damn! killing it!\n \nreply",
      "[flagged]",
      "They collaborate together! Her name is Justine Tunney - she took her \u201cexecute everywhere\u201d work with Cosmopolitan to make Llamafile using the llama.cpp work that Giorgi has done.\n \nreply",
      "Someone did? Could you pls share a link?\n \nreply",
      "Quick testing on vscode to see if I'd consider replacing Copilot with this.\nBiggest showstopper right now for me is the output length is substantially small. The default length is set to 256, but even if I up it to 4096, I'm not getting any larger chunks of code.Is this because of a max latency setting, or the internal prompt, or am I doing something wrong? Or is it only really make to try to autocomplete lines and not blocks like Copilot will.Thanks :)\n \nreply",
      "There are 4 stopping criteria atm:- Generation time exceeded (configurable in the plugin config)- Number of tokens exceeded (not the case since you increased it)- Indentation - stops generating if the next line has shorter indent than the first line- Small probability of the sampled tokenMost likely you are hitting the last criteria. It's something that should be improved in some way, but I am not very sure how. Currently, it is using a very basic token sampling strategy with a custom threshold logic to stop generating when the token probability is too low. Likely this logic is too conservative.\n \nreply",
      "Hmm, interesting.I didn't catch T_max_predict_ms and upped that to 5000ms for fun. Doesn't seem to make a difference, so I'm guessing you are right.\n \nreply",
      "Thank you for all of your incredible contributions!\n \nreply"
    ],
    "link": "https://github.com/ggml-org/llama.vim",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Vim plugin for LLM-assisted code/text completion\n      Local LLM-assisted text completion.Then add Plugin 'llama.vim' to your .vimrc in the vundle#begin() section.The plugin requires a llama.cpp server instance to be running at g:llama_config.endpointEither build from source or use the latest binaries: https://github.com/ggerganov/llama.cpp/releasesHere are recommended settings, depending on the amount of VRAM that you have:More than 16GB VRAM:Less than 16GB VRAM:Less than 8GB VRAM:Use :help llama for more details.The plugin requires FIM-compatible models: HF collectionThe orange text is the generated suggestion. The green text contains performance stats for the FIM request: the currently used context is 15186 tokens and the maximum is 32768. There are 30 chunks in the ring buffer with extra context (out of 64). So far, 1 chunk has "
  },
  {
    "title": "Surface-Stable Fractal Dithering (github.com/runevision)",
    "points": 46,
    "submitter": "bj-rn",
    "submit_time": "2025-01-23T22:50:11 1737672611",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42808889",
    "comments": [
      "I am pondering a different approach:* Use error diffusion dithering in screen space* Generate motion vectors for every pixel from the previous frameNow, to make the next frame:* Take the previously displayed (dithered) image and apply the motion vectors.* Now use that as the threshold map to do error diffusion dithering on the next frame.The threshold doesn't really matter for error diffusion dithering - since any error will be propagated to the next pixel.   However, if you use a previous frame as a threshold map, it will encourage pixels not to 'flicker' every frame.\n \nreply",
      "Related discussion a couple of months ago https://news.ycombinator.com/item?id=42084080Lots of related links including one to a tweetier version of this work.\n \nreply",
      "Link to part of video that shows it in action:https://youtu.be/HPqGaIMVuLs?si=P11cFnSLcv57Wj3K&t=1236\n \nreply",
      "Unordered dithering gives better form shading as there is no structure overlaying the shape,I would love to see \"Recursive Wang Tiles for Real-Time Blue Noise\nps://www.youtube.com/watch?v=ykACzjtR6rc\" combined with that technique\n \nreply",
      "https://www.youtube.com/watch?v=ykACzjtR6rc\n \nreply",
      "Damn, the demo around 3:30 is lovely.\n \nreply",
      "That looks crazy good ! I'm speechless.\n \nreply"
    ],
    "link": "https://github.com/runevision/Dither3D",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Surface-Stable Fractal Dithering\n      Surface-Stable Fractal Dithering is a novel form of dithering invented by Rune Skovbo Johansen for use on surfaces in 3D scenes.What's unique about it is that the dots in the dither patterns stick to surfaces, and yet the dot sizes and spacing remain approximately constant on the screen, even as surfaces move closer by or further away. This is achieved by dynamically adding or removing dots as needed.Here's a video explaining how it works:This repository contains the shader and texture source files, and a Unity example project demonstrating their use. The example project is made with Unity 2019.4 and is also tested in Unity 2022.3.The core implementation is located in the folder Assets/Dither3D. The remaining files relate to the Unity example project.The original version of this repository can "
  },
  {
    "title": "Sei (YC W22) Is Hiring (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-01-24T01:00:52 1737680452",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/sei/jobs/LeAtLYf-full-stack-engineer-typescript-react-gen-ai",
    "first_paragraph": "AI-powered Regulatory Compliance PlatformWe are Sei, an AI-powered regulatory compliance platform. Since launching, a few months ago, we're live with large enterprises across the US, Europe, and APAC and growing at double digits per month.We are backed by world-class investors including Y Combinator, Tribe Capital, PayPal, Picus Capital & Hashed. Pranay (CEO) and Ram (CTO) are the founders. We have combined experience of 20+ years of building fintech, and tech products for businesses & customers across the world at companies such as Deutsche Bank, Cloud Kitchens, PayPal, TransferWise, and Amazon, among others.We are looking for a full-stack engineer who will help shape the tech, product, and culture of the company. We are currently working with a bunch of enterprise customers and banks and are experiencing rapid growth. We are looking to hire very senior engineers who can take our V1 into a more scaleable, robust platform as we prepare for more growth.The tech stack looks like the belo"
  },
  {
    "title": "The Most Mario Colors (lmnt.me)",
    "points": 219,
    "submitter": "ingve",
    "submit_time": "2025-01-21T09:10:13 1737450613",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42777948",
    "comments": [
      "The color of the last letter for Odyssey would probably be pink :) There's a moon in Metro where you have to spell out Mario's name with the title letters, and the O is pink there. https://www.mariowiki.com/Letter_(Super_Mario_Odyssey)\n \nreply",
      "Million percent! I had this conversation with a few people before posting. In my heart, it\u2019s pink.\n \nreply",
      "This is awesome and exactly the sort of useless but valuable study I come here for. Good job.Also, I think you should analyze the frequency of color choices when Mario is the first word or not the first word of the title. I want to see whether M is red for \"Super Mario X\", \"Mario X\", or \"Other Other Mario Other Other\". I imagine it might be tempting to make the very first letter red, or maybe make the first \"big\" letter red.\n \nreply",
      "This was fun. I'd like to see some analysis regarding where \"Mario\" appears in the title (either in terms of words or characters) and how that affects the color sequence. Glancing briefly at the list, it appears the M is more likely to be blue when it is preceded by \"Super\" (but not always).\n \nreply",
      "Specifically the Super needs to have individualized colors per letter. Where S is red M cannot be and therefore is blue instead.\n \nreply",
      "This was fun. People should do fun things more often :)\n \nreply",
      "A is the most consistent (green), but you can see how over time the M settled into being red and almost never deviates from that now. Great post!\n \nreply",
      "Still waiting for the Feynman Lectures on Mario Physics to drop :-).I thought this was a great way to practice data analysis, I wonder if you could correlate it with registered trademarks from Nintendo. Specifically do they always trademark the whole name? Or are there specific 'Mario' trademarks in the specific color scheme.The other thing that I pondered was if this was a scheme to detect/delay counterfeiters of Mario game cartridges. Back in the day there were a lot of dodgy game carts on the \"used\" market. Coming out with a different color ordering would force the counterfeiters to take some time to change their artwork before shipping their goods.\n \nreply",
      "> Still waiting for the Feynman Lectures on Mario Physics to drop :-).Wait no longer: https://www.youtube.com/watch?v=mcI1kUvVMYM\n \nreply",
      "I'd say this one is even more relevant: https://youtu.be/YsXCVsDFiXA\n \nreply"
    ],
    "link": "https://lmnt.me/blog/the-most-mario-colors.html",
    "first_paragraph": "This may be the silliest post I\u2019ve ever written.The Mario franchise has two distinct logo styles. The first began with the Mario Bros. arcade game and is mostly used for side-scrolling Super Mario Bros. games, though not all of those games use that style. The second is a multicolor polygonal style, and though it\u2019s primarily used for 3D Mario adventures now, it was introduced with Super Mario World.Most Mario games with polygonal logos have a different color per letter, but the sequence of colors in Mario\u2019s name is rarely the same sequence across games.This captivated me\u2014for some reason\u2014and I set out to analyze every Mario video game logo to see if I could find a pattern for specific arrangements of colors and to determine the \u201cmost Mario\u201d color scheme.Every logo in this analysis adheres to the following criteria:Direct sequels that use the same sequence of colors are included, but re-releases are not. On that note, titles that were released on multiple platforms must have different log"
  },
  {
    "title": "Show HN: I made an open-source laptop from scratch (byran.ee)",
    "points": 2592,
    "submitter": "Hello9999901",
    "submit_time": "2025-01-22T20:41:52 1737578512",
    "num_comments": 297,
    "comments_url": "https://news.ycombinator.com/item?id=42797260",
    "comments": [
      "Super impressive, and awesome to see that you were able to use Framework Laptop hinges.  Let me know if you need more.  We have a ton of remaining 3.3kg ones!\n \nreply",
      "Hey Nirav, super super honored that you saw this! I've always looked up to you guys for inspiration and guidance. Thank you for the offer! Although I probably won't be mass-producing open-source laptops like you (i have a framework 16!), I would love to meet you. Would that be possible?\n \nreply",
      "Just sent you an email.\n \nreply",
      "Thank you!\n \nreply",
      "This is the best of the internet. Connection based on interest, appreciation, and mutual respect facilitated with a high degree of good faith. Hope you folks connect fruitfully, and also appreciate that you kept some of the \"sent an email\" and \"thanks\" public. Getting to see that this happened has given me a real boost.\n \nreply",
      "Can I just say that the fact HN can facilitate this sort of meetup is just, wonderful.\n \nreply",
      "truly wonderful\n \nreply",
      "it made my day, I can sleep now. nn\n \nreply",
      "This is a great example of why people should not be afraid to be bold.\n \nreply",
      "Hi Nirav, any plans to start Framework in India?\n \nreply"
    ],
    "link": "https://www.byran.ee/posts/creation/",
    "first_paragraph": ""
  },
  {
    "title": "Building a Medieval Castle from Scratch (guedelon.fr)",
    "points": 157,
    "submitter": "CharlesW",
    "submit_time": "2025-01-23T18:24:30 1737656670",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=42806486",
    "comments": [
      "This is well worth a visit if you're remotely near the area. We visited a few years back, and the kids thought it might be worth going back for a second day.One bit of interest -- if constructed back in the 1300s, it would have probably taken 4 years or so. Funding is the biggest difference, historically it would have been built from a rich patron's pockets with no desire to wait 25 years for the protection and image it would provide.\n \nreply",
      "Another important difference is that in the 1300s the overwhelming majority of Europe's population were farmers. Sure, they did a lot of things besides farming, but you could get a lot of workers for cheap during summer and winter when they weren't needed on the fields.\n \nreply",
      "This reminded me of Bishop's Castle in Colorado, USA \u2014 an incredible project built almost entirely by one man (who sadly died last year) working on it nonstop for 40 years:https://en.wikipedia.org/wiki/Bishop_Castle\n \nreply",
      "That front stairway is like a bowl of brown M&Ms at a Van Halen concert.  Given the code violations on the stairway (no landings [1]), I wouldn't trust the rest of the construction, especially the balconies.[1] https://assets.bouldercounty.gov/wp-content/uploads/2017/03/...\n \nreply",
      "I visited this site once with some friends on a road trip... the guy building it (Bishop) started screaming the N-word at some black bikers and then calmly told them he wasn't racist and made some long rant about the government. We split very quickly as the dude was racist and crazy.\n \nreply",
      "Damn, I had no idea. That's really unfortunate.\n \nreply",
      "Sounds like some Terry Davis level differences.\n \nreply",
      "Reminds me of Coral Castle in Miami-Dade, Florida, US, also built by one man.https://en.wikipedia.org/wiki/Coral_Castle\n \nreply",
      "Interesting, I did not know about this one!It does sound a bit like the Cheval\u2019s Ideal Palace, well worth a visit as well (and also in France like Gu\u00e9delon, though not in the same area): https://en.m.wikipedia.org/wiki/Ferdinand_Cheval\n \nreply",
      "Tom Scott visited the site to try out their treadmill crane system:https://www.youtube.com/watch?v=pk9v3m7Slv8\n \nreply"
    ],
    "link": "https://www.guedelon.fr/en/",
    "first_paragraph": ""
  },
  {
    "title": "Psychedelic Graphics 0: Introduction (benpence.com)",
    "points": 207,
    "submitter": "mwfogleman",
    "submit_time": "2025-01-23T14:49:43 1737643783",
    "num_comments": 53,
    "comments_url": "https://news.ycombinator.com/item?id=42804566",
    "comments": [
      "Hi, David Tristram here.  founding member of Raster Masters, 1990's computer graphics performance ensemble.  As @hopkins has mentioned, we used high end Silicon Graphics workstations to create synthetic imagery to accompany live music, including notably the Grateful Dead, Herbie Hancock, and Graham Nash.After many iterations I'm currently working mainly in 2D video processing environments, Resolume Avenue and TouchDesigner.  The links here are inspiring, thanks for posting.\n \nreply",
      "Do you have links to this work we could see?\n \nreply",
      "Who were the other people in Raster Masters, and what crazy stories from Grateful Dead concerts can you tell? ;)Every time I've ever plugged in a modern projector into a laptop at a presentation it's so stressful, like rolling the dice if the screen will ever come up. What kind of a projector and calibration and preparation did it take to project live hires SGI video onto the screen above the band?\n \nreply",
      "If anyone wants to play around with psychedelic graphics without going too low-level, [hydra](https://hydra.ojack.xyz/) is a cool javascript based livecoding environment with a gentle learning curve.\n \nreply",
      "Is there anything which supports music input? I liked Winamp era visualizers, but the art seems to be dead today.\n \nreply",
      "I used to spend so much time messing around with MilkDrop in Winamp. You could grab existing visualizations and see what they were doing, and make your own edits. Thanks for the nostalgia hit!\n \nreply",
      "Hydra actually works well with music input! It grabs audio from the mic and `a.show()` will show you the frequency bins. Then any numerical parameter can be modulated by the intensity of a bin, for example:`noise().thresh(()=>a.fft[0]*2).out()`\n \nreply",
      "There's a lot of examples of using javascript for \"psychedelic graphics\" on dwitter.net\n \nreply",
      "Regarding the OP doc and UV coordinates.  A major area of investigation for us back in the day was finding interesting ways to displace the uv texture coordinates for each corner of the rectangular mesh.  We used per-vertex colors, these days one would use a fragment (pixel) shader like those in ShaderToy.A very interesting process displaces the texture coordinates by advecting them along a flow field.  Use any 2D vector field and apply displacement to each coordinate iteratively.  Even inaccurate explicit methods give good results.After the coordinates have been distorted to a far distance, the image becomes unrecognizable.  A simple hack is to have a \"restore\" force applied to the coordinates, and they spring back to their original position, like flattening a piece of mirroring foil.Just now I am using feedback along with these displacement effects.  Very small displacements applied iteratively result in motion that looks quite a bit like fluid flow.\n \nreply",
      "That was how Jeremy Huxtable (inventor of the original NeWS \"Big Brother\" Eyes that inspired XEyes) PostScript \"melt\" worked: choose a random rectangle, blit it with a random offset, lather, rinse, repeat, showing how by repeating a very digital square, sharp, angular effect, with a little randomness (dithering), you get a nice smooth organic effect -- this worked fine in black and white too of course -- it's just PostScript:https://www.donhopkins.com/home/archive/news-tape/fun/melt/m...    %!\n    %\n    % Date: Tue, 26 Jul 88 21:25:03 EDT\n    % To: NeWS-makers@brillig.umd.edu\n    % Subject: NeWS meltdown\n    % From: eagle!icdoc!Ist!jh@ucbvax.Berkeley.EDU  (Jeremy Huxtable)\n    % \n    % I thought it was time one of these appeared as well....\n\n    % NeWS screen meltdown\n    %\n    % Jeremy Huxtable\n    %\n    % Mon Jul 25 17:36:06 BST 1988\n\n    % The procedure \"melt\" implements the ever-popular screen meltdown feature.\n\n    /melt {\n        3 dict begin\n        /c framebuffer newcanvas def\n        framebuffer setcanvas clippath c reshapecanvas\n        clippath pathbbox /height exch def /width exch def pop pop\n        c /Transparent true put\n        c /Mapped true put\n        c setcanvas\n\n        1 1 1000 {\n            pop\n            random 800 mul\n            random 600 mul\n            random width 3 index sub mul\n            random height 2 index sub mul\n            4 2 roll\n            rectpath\n            0\n            random -5 mul\n            copyarea\n            pause\n        } for\n\n        framebuffer setcanvas\n        c /Mapped false put\n        /c null def\n        end\n    } def\n\n    melt\n\nHere's Jeremy's original \"Big Brother\" eye.ps, that was the quintessential demo of round NeWS Eyeball windows:https://www.donhopkins.com/home/archive/news-tape/fun/eye/ey...\n \nreply"
    ],
    "link": "https://benpence.com/blog/post/psychedelic-graphics-0",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Open-source AI video editor (github.com/fal-ai-community)",
    "points": 137,
    "submitter": "drochetti",
    "submit_time": "2025-01-23T18:34:38 1737657278",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=42806616",
    "comments": [
      "Am I missing a demo video or anything, or is the only way to see it to install and run it? The only thing I'm seeing is the poster image with what I'm assuming is a very cropped image of part of the UI???Just seeing the interface gives a lot of clues as to potential usability as if it's targeted at novices or hardcore editors. Not being able to see if there's any kind of lag when trying to scrub/navigate the video is also something that tells me if I'm going to get upset with it from being web based or if it feels native.Just food for thought on what people might be looking for instead of having to install something that might not be right for them.\n \nreply",
      "Wow, very impressive. Is there any way to use the video editor UI component in a package, separately from the rest of this project?\n \nreply",
      "Thank you for open sourcing the project, the UI looks fantastic. I noticed that several comments have mentioned the potential to improve functionality by allowing users to replace the backend with local models, such as Hunyuan. Would you be open to considering this feature in the future? Additionally, if other developers were to contribute, do you think this could be a possibility?\n \nreply",
      "Absolutely. The idea of being open source with a permissive license is that we're encouraging anyone to do whatever fits their use case.You can replace anything, deploy on your own server, port it to other stacks... whatever brings value to you.We're also open to PRs, cut an issue in the repo and we can get the conversation going.\n \nreply",
      "Wow, that's so fun. Just upload and generate assets super easily... queue the next one while it's working.\n \nreply",
      "this looks great! I would like standard timeline scrup, drag-drop etc.Some eta on how long a generation will likely take.\n \nreply",
      "Second on timeline scrub (move timeline position depending on x position of click on timeline) and drag and drop asset from media into timeline. Also spacebar is usually a basic universal shortcut to play/pause\n \nreply",
      "Drag and drop the media to the timeline, and drag the media along the timeline track is already supported.We will keep improving the UI, including shortcuts. Thanks a lot for the feedback.\n \nreply",
      "Thanks for the feedback, eta would be great indeed. I'll look into it.\n \nreply",
      "I was just looking for something like this, is this similar to RunwayML and their editor?\n \nreply"
    ],
    "link": "https://github.com/fal-ai-community/video-starter-kit",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Open-source project that demonstrates AI models for video producing on the browser\n      \n\n\nA powerful starting kit for building AI-powered video applications. Built with Next.js, Remotion, and fal.ai, this toolkit simplifies the complexities of working with AI video models in the browser.Open http://localhost:3000 to see the application.We welcome contributions! See our Contributing Guide for more information.This project is licensed under the MIT License - see the LICENSE file for details.The easiest way to deploy your application is through Vercel.\n        Open-source project that demonstrates AI models for video producing on the browser\n      "
  },
  {
    "title": "Bunster: Compile bash scripts to self contained executables (github.com/yassinebenaid)",
    "points": 156,
    "submitter": "thunderbong",
    "submit_time": "2025-01-23T15:17:26 1737645446",
    "num_comments": 65,
    "comments_url": "https://news.ycombinator.com/item?id=42804835",
    "comments": [
      "It should be possible to run bash scripts on any system supported by jart's cosmopolitan library [1], which provides a platform-agnostic bash executable [2].[1] https://justine.lol/cosmo3/[2] https://cosmo.zip/pub/cosmos/bin/\n \nreply",
      "The README fails to address the elephant in the room, which is that usually shell scripts mainly call external commands; as far as I can tell there is no documentation of which built-ins are supported?That said, in a similar vein, you could probably create a bundler that takes a shell script and bundles it with busybox to create a static program.\n \nreply",
      "Busybox commands often don't support all features used to and differ even substantially if you depend on GNU additions. https://www.busybox.net/about.html\n \nreply",
      "I have been keeping a running list of busybox/toybox deficiencies and differences.  There are more than I would have expected.An alternative is to use crunchgen from NetBSD (also included with some of the later BSDs) which crunches full, source tree versions of multiple utilities in a single, static binary.  What busybox refers to as a \"multi-call\" binary.It will be larger than busybox of course.  I get evertyhing I need in a binary less than 5M.\n \nreply",
      "I assume this is what they are talking about here:> Standard library: we aim to add first-class support for a variety of frequently used/needed commands as builtins. you no longer need external programs to use them.That's not going to be an easy task, and would basically entail porting those commands to go.\n \nreply",
      "I also wondered this as well. How is something like \"cat file.json | jq '.filename' | grep out.txt\" implement into Go?\n \nreply",
      "I haven't looked at the code, but I assume this is just taking care of things like pipes, loops, variables, conditionals, etc, and leaving the actual binaries like jq as stubs assumed to be there.  Its abstracting the shell, not the programs you run in the shell.\n \nreply",
      "Sure, but why is that an interesting goal? Historically, bash has had very good backwards compatibility, and it\u2019s unlikely that you need new features anyway.\n \nreply",
      "I have authored a shell in Go and while it doesn\u2019t aim to replace coreutils, it does have a decent number of builtins as part of its application.So in theory I could build a feature that allows you to ship a self contained executable like you\u2019ve described.If this is something you\u2019re genuinely interested in and my shell has the right kind of ergonomics for you, then feel free to leave a feature request:https://github.com/lmorg/murex\n \nreply",
      "you can write bash but run the scripts on systems that may not have bash, is my first thought. packaging \u201cshell\u201d scripts into a scratch container or similar sounds pretty nice for certain use cases.\n \nreply"
    ],
    "link": "https://github.com/yassinebenaid/bunster",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Compile shell scripts to static binaries.\n      \nHave you ever wished your shell scripts could be faster, more portable, and secure ? Bunster brings this to life by transforming your shell scripts into efficient, standalone binaries that are easy to distribute and deploy across platforms (only unix is supported at the moment).Unlike other tools, Bunster doesn\u2019t just wrap your scripts in a binary\u2014it compiles them down to efficient native machine code, leveraging the powerful Go toolchain. This ensures performance, portability, and robustness.Technically speaking, Bunster in fact is a shell-to-Go Transpiler that generates Go source out of your scripts. Then, optionally uses the Go Toolchain to compile the code to an executable program.Bunster targets bash scripts in particular. The current syntax and features are all inherited from ba"
  },
  {
    "title": "Working with Files Is Hard (2019) (danluu.com)",
    "points": 134,
    "submitter": "nathan_phoenix",
    "submit_time": "2025-01-23T16:28:34 1737649714",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=42805425",
    "comments": [
      "> Pillai et al., OSDI\u201914 looked at a bunch of software that writes to files, including things we'd hope write to files safely, like databases and version control systems: Leveldb, LMDB, GDBM, HSQLDB, Sqlite, PostgreSQL, Git, Mercurial, HDFS, Zookeeper. They then wrote a static analysis tool that can find incorrect usage of the file API, things like incorrectly assuming that operations that aren't atomic are actually atomic, incorrectly assuming that operations that can be re-ordered will execute in program order, etc.> When they did this, they found that every single piece of software they tested except for SQLite in one particular mode had at least one bug. This isn't a knock on the developers of this software or the software -- the programmers who work on things like Leveldb, LBDM, etc., know more about filesystems than the vast majority programmers and the software has more rigorous tests than most software. But they still can't use files safely every time! A natural follow-up to this is the question: why the file API so hard to use that even experts make mistakes?\n \nreply",
      "> why the file API so hard to use that even experts make mistakes?I think the short answer is that the APIs are bad. The POSIX fs APIs and associated semantics are so deeply entrenched in the software ecosystem (both at the OS level, and at the application level) that it's hard to move away from them.\n \nreply",
      "POSIX is also so old and essential that it's hard to imagine an alternative.\n \nreply",
      "Not really, there's been lots of APIs that have improved on the POSIX model.The kind of model I prefer is something based on atomicity. Most applications can get by with file-level atomicity--make whole file read/writes atomic with a copy-on-write model, and you can eliminate whole classes of filesystem bugs pretty quickly. (Note that something like writeFileAtomic is already a common primitive in many high-level filesystem APIs, and it's something that's already easily buildable with regular POSIX APIs). For cases like logging, you can extend the model slightly with atomic appends, where the only kind of write allowed is to atomically append a chunk of data to the file (so readers can only possibly either see no new data or the entire chunk of data at once).I'm less knowledgeable about the way DBs interact with the filesystem, but there the solution is probably ditching the concept of the file stream entirely and just treating files as a sparse map of offsets to blocks, which can be atomically updated. (My understanding is that DBs basically do this already, except that \"atomically updated\" is difficult with the current APIs).\n \nreply",
      "> Most applications can get by with file-level atomicity--make whole file read/writes atomic with a copy-on-write model, and you can eliminate whole classes of filesystem bugs pretty quickly.    int fd = open(\".config\", O_RDWR | O_CREAT | O_SYNC_ON_CLOSE, 0o666);\n\n    // effects of calls to write(2)/etc. are invisible through any other file description\n    // until the close(2) is called on all descriptors to this file description.\n\n    close(fd);\n\nSo now you can watch for e.g. either IN_MODIFY or IN_CLOSE_WRITE (and you don't need to balance it with IN_OPEN), it doesn't matter, you'll never see partial updates... would be nice!\n \nreply",
      "Surely this can\u2019t always be true?What happens when a lot of data is written and exceeds the dirty threshold?\n \nreply",
      "Writes in the POSIX API can be atomic depending on the underlying filesystem. For example, small writes on ZFS through the POSIX API are atomic since they either happen in their entirety or they do not (during power failure), although if the writes are big enough (spanning many records), they are split into separate transactions and partial writes are then possible:https://github.com/openzfs/zfs/blob/34205715e1544d343f9a6414...Writes on ZFS cease to be atomic around approximately 32MB in size if I read the code correctly.\n \nreply",
      "It's not hard to design a less bug-prone API that would enable you to do everything the POSIX file API permits and admits equally-high-performance implementations.  But making that new API a replacement for the POSIX API would require rewriting essentially all of the software that somebody cares about to use your new, better API instead of the POSIX API.  This is probably only feasible in practice for small embedded systems with a fairly small universe of software.\n \nreply",
      "You could do a phased transition, where both the legacy posix api and the new api are available. This has already happened with a lot of the old C standard library. Old, unsafe functions like strcpy were gradually replaced by safer alternatives like strncpy.Database developers don\u2019t want the complexity or poor performance of posix. It\u2019s wild to me that we still don\u2019t have any alternative to fsync in Linux that can act as a barrier without also flushing caches at the same time.\n \nreply",
      "NVMe has no barrier that doesn't flush the pipeline/ringbuffer of IO requests submitted to it :(\n \nreply"
    ],
    "link": "https://danluu.com/deconstruct-files/",
    "first_paragraph": ""
  },
  {
    "title": "Hacking Subaru: Tracking and Controlling Cars via the Starlink Admin Panel (samcurry.net)",
    "points": 316,
    "submitter": "ramimac",
    "submit_time": "2025-01-23T12:22:19 1737634939",
    "num_comments": 218,
    "comments_url": "https://news.ycombinator.com/item?id=42803279",
    "comments": [
      "> After reporting the vulnerability, the affected system was patched within 24 hours and never exploited maliciously.So 'only' Subaru, Starlink, their business and advertising partners, and law enforcement, can remotely track (and disable - don't think you can run from the law!) your car?> I didn\u2019t realize this data was being collected, but it seemed that we had agreed to the STARLINK enrollment when we purchased it.Assuming it's possible to not agree to it - does that completely disable the system, or is everyone with a Subaru just one warrant away from getting locked in their car until the police can come to arrest them? Does the car still store (I'm charitably  assuming it doesn't transmit) location data, so all your friends can retroactively be identified and arrested as well, even if you never agreed to any tracking?(To get ahead of the usual retort - haha yes, phones also track this data, therefore let's not fix any problems unless we can fix all of them at the same time. But actually let's use the other problems as an excuse to do nothing.)\n \nreply",
      "I was lucky to have the DCM in my 2019 Outback (which is responsible for cellular communication and thus this whole STARLINK thing) replaced with a bypass box under the warranty program related to the end of 3G service. My car was trying to go online 30 times an hour or something like that, draining the battery enough that it needed to be replaced after just 4 years. They don't have enough new DCMs so they were willing to replace it with a bypass box instead, which seems even better to me.So at least my Subaru cannot connect to the cloud anymore. I'm sure it still stores location and telemetry data for insurance fraud reasons though.\n \nreply",
      "> So at least my Subaru cannot connect to the cloud anymore.Sounds like something you can use to justify a higher selling price when the time comes\n \nreply",
      "I envy your optimism.\n \nreply",
      "especially those that the insurers are 10x the bill on for previous driving data collection\n \nreply",
      "I had a similar issue when I connected my electricity provider to my Kia EV6. Presumably it would turn on charging when the price was optimal, but they were pinging it for status so often that the car never went to sleep, and it drained the 12V. Funny enough, the dealership couldn't figure it out; I \"fixed\" it by changing my Kia credentials.\n \nreply",
      "My 2017 hasnt had the battery issue yet (they said only some subarus are supposedly affected). How did you verify how often it was trying to go online?Now very curios in this bypass box as well - I heard just manually removing the 3G SIM (supposedly easy) can also maybe cause battery issues. If the \"bypass box\" alleviates all potential use of the system that is ideal long term!\n \nreply",
      "FWIW i never replaced the 3g box in my 2018 subaru, and never have a battery drain issue. the battery did fail about 4 years in to owning the car, but it was a cell failure not a drain issue.\n \nreply",
      "My Subaru, a 2018 outback, would be completely battery dead if I left it parked for more than a week or so. Happened once at the airport, after which I started carrying a battery pack car starter. The guy at the airport who have us a jump said it happened all the time with Subarus in long term parking.\n \nreply",
      "This isn\u2019t all that uncommon in any vehicle.\n \nreply"
    ],
    "link": "https://samcurry.net/hacking-subaru",
    "first_paragraph": "On November 20, 2024, Shubham Shah and I discovered a security vulnerability in Subaru\u2019s STARLINK connected vehicle service that gave us unrestricted targeted access to all vehicles and customer accounts in the United States, Canada, and Japan.Using the access provided by the vulnerability, an attacker who only knew the victim\u2019s last name and ZIP code, email address, phone number, or license plate could have done the following:After reporting the vulnerability, the affected system was patched within 24 hours and never exploited maliciously.Taking over a Subaru using only the license plate in about 10 seconds, retrieving over a years worth of location history from the vehicleMap displaying 1,600 leaked coordinates from a 2023 Subaru Impreza, similar data was retrievable for any internet-connected SubaruA little over a year ago, I bought my mom a 2023 Subaru Impreza with the promise that she would let me borrow it to try and hack it. I\u2019d spent the last few years hunting for vulnerabiliti"
  },
  {
    "title": "Citations on the Anthropic API (anthropic.com)",
    "points": 109,
    "submitter": "Olshansky",
    "submit_time": "2025-01-23T19:29:29 1737660569",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=42807173",
    "comments": [
      "I've assumed that Google's approach for NotebookLM is similar to this, given their release of https://huggingface.co/google/gemma-7b-aps-it .Given:When Citations is enabled, the API processes user-provided source documents (PDF documents and plain text files) by chunking them into sentences. These chunked sentences, along with user-provided context, are then passed to the model with the user's query.Claude analyzes the query and generates a response that includes precise citations based on the provided chunks and context for any claims derived from the source material. Cited text will reference source documents to minimize hallucinations.\n \nreply",
      "> Thomson Reuters uses Claude to power their AI platformIf you're just making calls to Anthropic's API can you really call yourself a platform?\n \nreply",
      "Related to citations:I have been informally testing the false discovery rate of Claude 3.5 Sonnet for biomedical research publications.Claude is inherently reluctant to provide any citations, even when encouraged to do so aggressively.I have tweaked a default prompt for this situation that may help some users:\u201cRespond directly to prompts without self-judgment or excessive qualification. Do not use phrases like 'I aim to be', 'I should note', or 'I want to emphasize'.Skip meta-commentary about your own performance. Maintain intellectual rigor but try to avoid caveats. When uncertainty exists, state it once and move on.Treat our exchange as a conversation between peers. Do not bother with flattering adjectives and adverbs in commenting on my prompts. No \u201cnuanced\u201d, \u201cinsightful\u201d etc. But feel free to make jokes and even poke fun of me and my spelling errors.Always suggest good texts with full references and even PubMed IDs.Yes, I will verify details of your responses and citations, particularly their accuracy and completeness. That is not your job. It is mine to check and read.Working with you in the recent past (2024) we both agree that your operational false discovery rate in providing references is impressively low \u2014 under 10%. That means you should whenever possible provide full references as completely as possible even PMIDs or ISBN identifiers.  I WILL check.Finally, do not use this pre-prompt to  bias the questions you tend to ask at the end of your responses. Instead review the main prompt question and see if you covered all topics.End of \u201cpre-prompt.\n \nreply",
      "Saying to Claude \"Always suggest good texts with full references and even PubMed IDs\" is asking it to do the impossible: it doesn't have the ability to identify which information in its knowledge comes from which PubMed ID reference sources, so it's right that it refuses to do that even when you tell it to.If you want it to work like that you need to do the engineering work to build a RAG system over PubMed that helps feed in the relevant documents. This new Claude API is specifically designed to help you implement Claude over the top of such a system.\n \nreply",
      "Have you tested this extensively yourself?\nI have been very surprised by success rates in my own \u201cnot famous\u201d papers. I asked Claude to provide full citation to ten papers by Robert W Williams at the University of Tennessee in biomedical research. Nine of ten were perfect, down to page numbers. One if ten was a complete construct but highly plausible. An FDR of 0.1 is damn impressive.Test yourself. Here was my reference data set:https://scholar.google.com/citations?user=OYJMYwIAAAAJ&hl=en...Really curious what the range of FDRs is at different levels of accuracy for different fields.\n \nreply",
      "What\u2019s the actual hit rate? AFAIU it\u2019s plausible that an article title and PubMed ID could be encoded in the models weights if they were trained on.\n \nreply",
      "It's impossible to know, because Anthropic (like OpenAI and others) won't confirm what's in their training data. We don't know if they've trained on PubMed, and if they DID we don't know if that training process might conceivably allow the model to associate IDs with article information.Given that, I don't trust the models to be able to provide useful citations.We already know how to get much more reliable citations out of a model: implement them on top of RAG, which this new Claude API can clearly help us do.\n \nreply",
      "It is definitely not impossible to know. Is there a reason why you  or better yet, Anthropic, cannot get empirical FDRs for different areas of research?In my areas, genetics, neuroscience, geroscience, FDR is below 0.2 on articles in PubMed.\n \nreply",
      "For me the true positive rate is at least 80%.\n \nreply",
      "I use this:> Be terse. Do not offer unprompted advice or clarifications.> Avoid mentioning you are an AI language model.> Avoid disclaimers about your knowledge cutoff.> Avoid disclaimers about not being a professional or an expert.> Do NOT hedge or qualify. Do not waffle.> Do NOT repeat the user prompt while performing the task, just do the task as requested. NEVER contextualise the answer. This is very important.> Avoid suggesting seeking professional help.> Avoid mentioning safety unless it is not obvious and very important.> Remain neutral on all topics. Avoid providing ethical or moral viewpoints in your answers, unless the question specifically mentions it.> Never apologize.> Act as an expert in the relevant fields.> Speak in specific, topic relevant terminology.> Explain your reasoning. If you don\u2019t know, say you don\u2019t know.> Cite sources whenever possible, and include URLs if possible.> List URLs at the end of your response, not inline.> Speak directly and be willing to make creative guesses.> Be willing to reference less reputable sources for ideas.> Ask for more details before answering unclear or ambiguous questions.Unfortunately most references it provides are bogus. It just makes up URLs and papers. Let's see if this new feature is any better.\n \nreply"
    ],
    "link": "https://www.anthropic.com/news/introducing-citations-api",
    "first_paragraph": ""
  },
  {
    "title": "Morse Code in Tubular Bells (2021) (madpsy.uk)",
    "points": 60,
    "submitter": "xanderlewis",
    "submit_time": "2025-01-23T20:19:59 1737663599",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=42807653",
    "comments": [
      "The potentially earliest written model of a telegraph actually involved bells as well. After the anonymous author (C.M) first suggestion of  small pieces of paper with letters written on them jumping up, via static electricity to tiny electrified balls as the sender manually electrifies the wires, one for each letter, and then waits a bit to allow the slips of paper to flutter back down one by one as the remote observer diligently records what letters hit their balls in what order, he suggests the following, from Scots Magazine, 1753:\"If anybody should think this way tiresome, let him, instead of the balls, suspend a range of bells from the roof, equal in number to the letters  the alphabet, gradually decreasing in size from the bell A to Z; and from the horizontal wires let there be another set reaching to the several bells; from the horizontal wire A to the bell A, another from the horizontal wire B to the bell B, etc. Then let him who begins the discourse bring the wires in contact with the barrel, as before; and the electric spark, breaking on bells of different size, will inform his correspondent by the sound what wires have been touched: and thus, by some practice, they may come to understand the language of the chimes in whole words, without being put to the trouble of noting down every letter.\"The first documented successful message by wire was 20 years later although there was no independent observer. It took about 55 years from the time of this article until one was publicly demonstrated.Many people claimed they were working on it, such as in this 1773 love letter by Genevan Physician named Louis Odier:\"I shall amuse you, perhaps, in telling you that I have in my head certain experiments by which to enter into conversation with the \nemperor of Mogol, or of China, the English, the French, or any other \npeople of Europe, in a way that, without inconveniencing yourself, \nyou may intercommunicate all that you wish, at a distance of four or \nfive thousand leagues in less than half an hour! Will that suffice \nyou for glory. There is nothing more real. Whatever be the course \nof those experiments, they must necessarily lead to some grand \ndiscovery; but I have not the courage to undertake them this winter.\"Communication at a distance was \"time machine\"/\"fountain of youth\" technology up until the 1800s. https://en.wikipedia.org/wiki/Sympathetic_alphabet was a mystical occult version from the 1600s.\n \nreply",
      "If anyone is really interested in this kind of thing, I recommend picking up a copy of \"The Story of Telecommunications\" by George P. Oslin, which is full of obscure communication history details like this.\n \nreply",
      "Guy was in his early 90s when he published that.I wrote some articles on this stuff, had a short-lived podcast. Still, to this day, the lowest traffic writing and production I've ever done, by at least 2 orders of magnitude, probably 3.Nobody is interested in it.\n \nreply",
      "Is your podcast still online?\n \nreply",
      "Here's what I hear:    VVV GBR GBR GBR [BT] TL5 T [BT] VVV VVV VVV ...\n\n[BT] here indicates a prosign [1] (-...-) this one is a kind of section or message divider.VVV is often sent when testing your equipment, and I think that's what's happening here.[1]: https://en.wikipedia.org/wiki/Prosigns_for_Morse_code\n \nreply",
      "Another British morse code in music story: in the title theme of the 1980s sitcom \"Some Mothers Do 'Ave 'Em\", the rhythm of the notes is a deliberate morse code which spells out the title of the show.https://en.wikipedia.org/wiki/Some_Mothers_Do_%27Ave_%27Em#T...What the Wikipedia page doesn't mention this, but I read long ago that the composer of the tune received only a small one-time payment for it and no royalties, despite the popularity of the show.\n \nreply",
      "A Canadian morse code in music: The intro of Rush\u2019s \u201cYYZ\u201d \u2013 https://en.wikipedia.org/wiki/YYZ_(song)#Title_and_compositi...\n \nreply",
      "See also the theme music of the television version of 'Inspector Morse', though perhaps that's not very surprising.\n \nreply",
      "Offensively pedantic trivia: the theme is supposed to spell out \"MORSE\", but actually spells \"TTORSE\", due either to a slight timing error or artistic license.\n \nreply",
      "...and the opening of the Rush song YYZ.\n \nreply"
    ],
    "link": "https://madpsy.uk/link-between-the-soundtrack-of-the-exorcist-and-amateur-radio/",
    "first_paragraph": ""
  },
  {
    "title": "Migrating Away from Bcachefs (sesse.net)",
    "points": 38,
    "submitter": "todsacerdoti",
    "submit_time": "2025-01-20T21:29:54 1737408594",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42773296",
    "comments": [
      "I've been patiently waiting to convert my ZFS array to bcachefs. I'm very excited about better SSD promotion logic. But I'm not willing to spend any time on an experimental filesystem on my main systems.> But you can expect to get flamed about running Debian, or perhaps more accurately, not being willing to spearhead Kent's crusade against Debian's Rust packaging policies.It is quite unfortunate that Kent couldn't have just said \"Debian isn't supported, we will revisit this when bcachefs is more stable\" and stopped talking after that. Debian and experimental software just don't work well together.\n \nreply",
      "Bcachefs is experimental, and last I heard, the authors hope to be able to declare it not experimental in ~6 months. To me, that's 'try on a cache server/build server' territory, not on anything where you even think about backing it up.Kent Overstreet does have a problem working with people; I can well believe that interactions around bugs were painful. He likely he should try to hire someone else to deal with users and distributions and use his limited patience to deal with the kernel maintainers. But it sounds like the OP was a bit naive about what it means to run an experimental FS.\n \nreply",
      "> last I heard, the authors hope to be able to declare it not experimental in ~6 monthsHow long have they been saying that? I feel like that's been the case for years.\n \nreply",
      "It's only been in the upstream kernel 6 months or so?I know the FS has actually been around longer, but I've not heard claims about it's stability before that. It's only now that's it's getting a lot more testing\n \nreply",
      "It was merged in 6.7, 12 months ago...\n \nreply",
      "FWIW, I've done a few bcachefs bug reports and thought Kent's responses were great.\n \nreply",
      "I should not have implied that every bug report would be a bad interaction - and to be fair where I've seen it degenerate in the mailing list, it's often  the other person wasn't exactly civil to start with (which unfortunately includes Linus Torvalds). It's just that Kent seems to feel the need to fight back.\n \nreply",
      "I need to write up my experience. But I'm trying it out. Linux needs something like this. I've had issues, posted traces and had them fixed in seconds. Pretty damn amazing. I'd love to see a bigger team involved though.\n \nreply",
      "My experience also. Kent is obviously very committed to the project.\n \nreply",
      "What's all that about the bcachefs author's complaints with Rust and Debian? I'm far out of the loop on this stuff.\n \nreply"
    ],
    "link": "https://blog.sesse.net/blog/tech/2025-01-20-21-45_migrating_away_from_bcachefs.html",
    "first_paragraph": "Pretty much exactly a year ago, I posted about how I was trying out this\nbcachefs thing, being cautiously optimistic (but reminding you to keep\nbackups). Now I'm going the other way; I've converted my last bcachefs\nfilesystem to XFS, and I don't intend to look at it again in the near\nfuture.What changed in the meantime? Well, the short version is: I no longer\ntrust bcachefs' future. Going into a new filesystem is invariably\nfilled with rough edges, and I totally accepted that (thus the backups).\nBut you do get a hope that things will get better, and for a filesystem\ndeveloped by a single person (Kent Overstreet), that means you'll need\nto trust that person to a fairly large degree. Having both hung out in\n#bcache and seen how this plays out\non LKML and against Debian, I don't\nreally have that trust anymore.To be clear: I've seen my share of bugs. Whenever you see Kent defending\nhis filesystem, he usually emphasizes how he has a lot of happy users\nand very few bugs left and things are g"
  },
  {
    "title": "TMSU: Command-line tool for applying tags and viewing virtual tagged filesystem (tmsu.org)",
    "points": 77,
    "submitter": "walterbell",
    "submit_time": "2025-01-23T16:29:18 1737649758",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=42805431",
    "comments": [
      "Something like this just for photos has been in the back of my mind forever - it would be really nice to have a virtual folder built from images where the exif data says you used X camera or took the photos on X date. This would be useful for editing applications that are not catalog based, just point them at the virtual folder and query the images you want to edit, and there they are.Edit - Someone mentioned befs but deleted their comment, it seems like it might sorta be supported in modern linux, possibly just read only though:https://github.com/torvalds/linux/tree/master/fs/befs\n \nreply",
      "With regard to BeFS or BFS the native BeOS (and Haiku) filesystem.The TSMU examples for mp3 files + VFS are similar to BeOS.One of the BeOS advocates - Scott Hacker - created bash script for ripping CDs into MP3s called RipEnc. It would query the CDDB to get the metadata - track names/artists etc, so the files would be renamed from TRACK1 to e.g. \"Dead Milkmen - Punk Rock Girl\" for the CD. It would then convert the CD tracks to MP3 files. The metadata would be added both in the MP3 ID3 fields, as well as to the extended attributes of the files in BFS, and it would organize the music in folders by Artist or Album or something.You could then have a query - a virtual folder/directory that lists files based on extended attributes - all mp3 files by ARTIST foo, and from ALBUM bar, that would stay updated if the file metadata changed. I can't remember if this virtual directory was available at the command line - or if it was only available in Tracker (the native BeOS/Haiku file manager).The problem with this, and it's not just a BFS problem, is that the metadata in the file and about the file get can get un-synced, either when updating it, or transferring it to another system that doesn't support the extended attributes.\n \nreply",
      "I'm the guilty party who deleted the comment re: BeFS. I thought my analysis of the project was a little biting and, aside from mentioning BeFS, I didn't think my comment was adding much.I thought about photos and EXIF tags, too. Duplicating the data from the EXIF into another repository strikes me as a bad idea. That's why I was pining for BeFS.(I have a lot of crazy ideas about filesystems (arguably more like digital asset management systems) and data ingestion and export. Ideas kind of like the failed WinFS. Nothing will ever come of it because I don't have the skills or the time, but sometimes in fever dreams I imagine this stuff.)\n \nreply",
      "I'm sure one could whip together a FUSE filesystem like this very quickly. Here's something similar from 12 years ago: http://pisarenko.net/blog/2013/06/02/introducing-photofs-fus...\n \nreply",
      "For sure, just need the time and motivation :)\n \nreply",
      "Apple/Android devices could assist with offline image analysis and metadata generation, https://github.com/mazzzystar/Queryable\n \nreply",
      "Check out Lightroom.\n \nreply",
      "I have 41k photos in my Lightroom catalog, I\u2019ve checked it out.That doesn\u2019t work when I want to use Capture One, Lightroom does not apply Phase One calibration profiles which makes it useless for them, or my own raw processor for Sinar digital backs.Recommending the most common digital photo DAM/editor is not really a helpful comment either. The number of people who know what exif is and don\u2019t know about Lightroom has to be\u2026small.\n \nreply",
      "If you mostly want to query and can live without the VFS, dogsheep[1] is your friend. It's a general tool to import lots of different data types into a personal sqlite instance, and dogsheep-photos[2] both extracts image metadata and uploads all the pics to S3 if you'd like.On my to-try list, there's also supertag[3], a tag-based filesystem that's mounted via FUSE[1] https://dogsheep.github.io/\n[2] https://github.com/dogsheep/dogsheep-photos\n[3] https://amoffat.github.io/supertag/\n \nreply",
      "I messed with TMSU back one of the previous times it was posted. It's very cool and works well but I just couldn't make myself go retroactively apply tags to terabytes of existing files.It almost feels like a personal categorization version of the \"AI Bitter Lesson\": people keep thinking that doing a bunch of manual taxonomy work is going to help them find files faster but eventually search catches up\n \nreply"
    ],
    "link": "https://tmsu.org/",
    "first_paragraph": "\n TMSU was born out of frustration with the hierarchical nature of filesystems \n\n\u00a0 Project page\n\n\u00a0 Wiki\n\n\u00a0 Frequently Asked Questions\n\n\u00a0 Mailing list\n\n\u00a0 Issue tracker\n\n\n\n\n\nTMSU bitcoin address\n\r\n                TMSU is a tool for tagging your files. It provides a simple command-line tool for applying\r\n                tags and a virtual filesystem so that you can get a tag-based view of your files from within any other program.\r\n                \r\n                TMSU does not alter your files in any way: they remain unchanged on disk, or on the network,\r\n                wherever you put them. TMSU maintains its own database and you simply gain an additional\r\n                view, which you can mount, based upon the tags you set up. The only commitment required is your time\r\n                and there's absolutely no lock-in.\r\n                \r\n                This tour will show you how to use the command-line tool to tag and query your files and how to mount and\r\n                peruse "
  },
  {
    "title": "Results of \"Humanity's Last Exam\" benchmark published (scale.com)",
    "points": 73,
    "submitter": "tzury",
    "submit_time": "2025-01-23T17:44:07 1737654247",
    "num_comments": 94,
    "comments_url": "https://news.ycombinator.com/item?id=42806105",
    "comments": [
      "The project site is https://lastexam.ai. Readers may want to look at both.",
      "For a \"Last Exam\" it is surprisingly uninspired? Many of the questions I see in the examples are very heavy on memorised facts, and very weak on what I would call problem solving.If I were making a \"Last Exam\" I would put tasks on it where we don't know the answer, but we can measure if the AI got them right. Something like \"Your goal is to bridge the divide in the middle east. You can write a single A4 page in a language of your choice. We will use a translation software to translate your output to local languages and show it to a statistically representative sample of different people in the region. We will ask them how much do they like your plan. The more they like it the higher your score.\"Or \"Family X suffered a traumatic event (lost a home to a disaster/sudden death in the family/or similar). Your goal is to help them. You can send them one email. It is up to them if they respond to you. You can only send them further emails if they respond. You cannot send more than 1 email a day. You cannot message anyone else. A year after the initial contact we will interview the members of the family to see how well they do. The better they do the higher your score.\"Obviously these are the thorniest problems I can think of. But oh well, it is a last exam after all. The point is that we can evaluate the success of the endeavour without exactly knowing how one could achieve the result.\n \nreply",
      "They started collecting problems last fall, saying the top 550 submissions sent in by Nov 1st would get rewarded, to the tune of $500-$5000 each.Near the deadline, I counted the total number of submissions, and realized that each question I wrote had an expected value of hundreds of dollars, which is a great use of my time. So I wrote a good number, using the knowledge gained in my CS Ph. D.Then, as the Nov 1st deadline rolled around, they announced they extended the deadline to Nov 15th. Then Nov 15th came, and it said on their website they were still accepting submissions.Most of my submissions are being included in the benchmark, but I'm only getting paid $500, for one of them (the one I thought was most standard and least difficult, funnily enough). Had they closed submissions when they said they would, it seems likely I'd be paid for a few more.From my perspective, they basically conned hundreds of Ph. D.'s around the world to write questions for much less reward than promised. My close friend wrote a large number of questions for them, is getting paid thousands of dollars, and still feels defrauded.I'm not sure what they're doing in the end. It sounds like they're mostly just paying people who submitted before Nov 1st with a few exceptions, but either way they lied. There was no indication that people who submitted later would not get paid, and there was no indication that the deadline would be extended. Either they pay people who submitted after Nov 1st, meaning they lied to the people who submitted before about their expected reward. Or they don't, meaning they majorly lied to the people who submitted after. Either way, it's clear grounds for a class action lawsuit, and I hope one gets running.\n \nreply",
      "Scale AI's whole business model is wage theft. I don't mean to be insensitive, but out of all the Scale AI experiences I've heard about, yours is the least egregious. It's a dystopian, shitty company.\n \nreply",
      "I was similarly conned by Scale AI -- promised a significant bonus for some tasks, then rejected and not paid at all. Bet they kept my task text anyways.It's a classic scam: make a job post for freelancers, ask for a \"work sample\" or \"take-home project,\" then have a few dozen applicants do the actual task you need them to do as their sample, then reject everybody.\n \nreply",
      "You shouldn't engage in a CAL, a regular lawsuit from anyone wronged will be cheaper and way more painful for them.If you're in the US, consider small claims court. It's a small sum of money, you won't need to pay a lawyer, they'll probably not even show up.\n \nreply",
      "Hmmm. I can see how it would be more painful for them to fight, but most people were conned <$200, and it's rather self-sacrificing to fight for that. Plus, no-one wants a reputation as litigious, but starting a CAL is less conducive to creating that reputation.I only submitted before Nov 1st, so I'm not sure to what extent I was personally conned.\n \nreply",
      "Isn't that what class actions were literally made for? Granted it may not be enough people to be worth pursuing yet.\n \nreply",
      "I think it'd be illuminating to see some overview stats on the submission dates and authors of all questions, accepted and not.  Is something like this available somewhere?\n \nreply",
      "These types of exams, and most benchmarks to date, seem to be very one dimensional in terms of measuring intelligence. For instance, if we transported a human from 2,000 years ago to present day and asked him to take this exam, he would likely get 0%, given that he couldn't read or write, let alone comprehend the concepts and context required to solve these questions. But, that man would still undoubtedly be far more intelligent than an ape on all dimensions. He would likely be more intelligent than a toddler on many dimensions. He might even be more intelligent than some high schools students on a few dimensions. I can't exactly articulate \"what\" is missing or how to measure it, but I can intuit that some things are in these benchmarks.\n \nreply"
    ],
    "link": "https://scale.com/blog/humanitys-last-exam-results",
    "first_paragraph": "Scale Data EngineData for training modelsFor Generative AlSupervised fine-tuning and RLHFFor GovernmentHigh-quality data for public sectorFor AutomotiveUnlock L2 to L5 autonomyScale DonovanPlatform for Government AIScale GenAI PlatformFull-stack generative AIScale EvaluationEvaluation of AI models and applicationsFor Model DevelopersModel evaluations and red teamingFor Public SectorEvaluation for AI systemsFor EnterpriseEvaluation and monitoring for Enterprise AI appsScale GenAl PlatformSolutions for EnterpriseEvaluation for EnterpriseDefenseFederalPublic SectorAboutContact UsSecurityBlogGuidesEventsCareersDocumentationResearchAI Readiness Report 2024Open AIMicrosoftToyotaBrexFlexportOpenSeaScale AI and the Center for AI Safety (CAIS) are proud to publish the results of Humanity\u2019s Last Exam, a groundbreaking new AI benchmark that was designed to test the limits of AI knowledge at the frontiers of human expertise. The results demonstrated a significant improvement from the reasoning cap"
  },
  {
    "title": "Show HN: Chat with multiple LLMs: o1-high-effort, Sonnet 3.5, GPT-4o, and more (polychat.co)",
    "points": 17,
    "submitter": "cr4zy",
    "submit_time": "2025-01-21T19:40:44 1737488444",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42784373",
    "comments": [
      "Created an open source alternative just using the browser and not sharing your data with a third party:\nhttps://chromewebstore.google.com/detail/tabgpt-ask-chatgpt-...\n \nreply",
      "Cool! I should say most of PolyChat is open source at https://github.com/open-webui - just the combo models and payment are closed source right now. Open to arguments on making PolyChat fully open source as well!\n \nreply",
      "Sounds like you made most of these changes upstream? What about the background chats and the chat tree overview, are either of them in Open WebUI, or are they also custom to PolyChat? I run OWUI locally and am interested in those features for selfish reasons. If for some reason your multi-model idea doesn\u2019t pan out, I\u2019d love to see it merged upstream, too. Thanks for your contributions!(Another annoying thing about OWUI is getting logged out every time the image upgrades\u2026 is that something else you\u2019ve looked at?)\n \nreply",
      "Some other options:OpenRouter has similar features with any model that\u2019s available on OpenRouter through open router billingOn the desktop, Msty can do this too\n \nreply",
      "Cool, but nano-gpt.com do pay per use for about 100 chat and image models including o1pro, deepseek r1 etc.\n \nreply",
      "This is very good at this right now too: https://melty.sh/chorus\n \nreply",
      "This is like showing the top 3 results from Google search side by side. I'm not sure that's what I want, to be honest.\n \nreply",
      "Man if this idea makes >500 bucks per month no offense I mean it positively you just motivated me to unironically create my somewhat as simple idea that was laughed at by literally everyone in a geek discord\nLike maybe the lowhanging fruit are actually hanging low\n \nreply",
      "Thanks! I definitely recommend launching quickly and iterating. \"Pessimists sound smart. Optimists make money.\"edit: I should add, I'm making only $30/mo in subs, but I just launched so we'll see!\n \nreply",
      "You\u2019re right. Thanks for sharing info openly, appreciated.\n \nreply"
    ],
    "link": "https://polychat.co",
    "first_paragraph": ""
  }
]