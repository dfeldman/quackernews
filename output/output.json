[
  {
    "title": "We should have the ability to run any code we want on hardware we own (hugotunius.se)",
    "points": 175,
    "submitter": "K0nserv",
    "submit_time": "2025-08-31T21:46:26 1756676786",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=45087396",
    "comments": [
      "This makes the point that the real battle we should be fighting is not for control of Android/iOS, but the ability to run other operating systems on phones. That would be great, but as the author acknowledges, building those alternatives is basically impossible. Even assuming that building a solid alternative is feasible, though, I don't think their point stands. Generally I'm not keen on legislatively forcing a developer to alter their software, but let's be real: Google and Apple have more power than most nations. I'm all for mandating that they change their code to be less user-hostile, for the same reason I prefer democracy to autocracy. Any party with power enough to impact millions of lives needs to be accountable to those it affects. I don't see the point of distinguishing between government and private corporation when that corporation is on the same scale of power and influence.reply",
      "Remember, the law provides patent, copyright, trade mark, and NDA protection.While it would be a burden to require a degree of openness, it's not like companies are all rugged individualists who would never want to see legal restrictions in the field.It's just a question of what is overall best and fairest.Restrictions can both help and hinder innovation, and it's innovation that in the ling run makes things improve IMO.reply",
      "This is one of the real canaries I watch on \"real AI\" for programming.It should be able to make an OS. It should be able to write drivers. It should be able to port code to new platforms. It should be able to transpile compiled binaries (which are just languages of a different language) across architectures.Sure seems we are very far from that, but really these are breadth-based knowledge with extensive examples / training sources. It SHOULD be something LLMs are good at, not new/novel/deep/difficult problems. What I described are labor-intensive and complicated, but not \"difficult\".And would any corporate AI allow that?We should be pretty paranoid about centralized control attempts, especially in tech. This is a ... fragile ... time.reply",
      "The primary problem is that we can't build a phone and run it on a cellular carrier network.  This is where legislation is needed.Apple and Google are still a problem, but they are a secondary problem.reply",
      "You'll run into a variant of the tragedy of the commons; without any kind of regulation or provable assertions from people taking part in common communication infrastructure, it'd be quite easy to ruin it for everyone.reply",
      "You don't need to allow completely unrestricted access to the network.  However, there needs to be a process with a defined cost to certify your hardware.  The cost can be expensive and time consuming but it needs to be known and published and the cellular companies need to be held to it.The problem right now is that even if I had a couple of million dollars lying around, I STILL couldn't reliably get a piece of hardware certified for the cellular network.  I would have to set up a company, spend untold amounts of money bribing^Wwooing cellular company executives for a couple years, and, maybe, just maybe, I could get my phone through the certification process.The technical aspects of certification are the easy part.The problem is that the cellular companies fully understand that when it happens their power goes to zero because they suddenly become a dumb pipe that everybody just wants to ignore.That's why this will take legislation.reply",
      "GrapheneOS?reply",
      "Only runs on a handful of hardware, and still uses the binblobs from google for the hardware devices.reply",
      "[flagged]",
      "That's a reductio ad absurdum conclusion.Both lobby for and are in major political cahoots with many governmental bodies worldwide. They lobby like crazy, and can defend just about any lawsuit that comes their way - including dodging congressional hearings, selectively adhering to laws other companies cannot, etc.But I think you knew that. Being argumentative with the general point OP was making doesn't solve anything and just defends multinationals when they shouldn't be defended.reply"
    ],
    "link": "https://hugotunius.se/2025/08/31/what-every-argument-about-sideloading-gets-wrong.html",
    "first_paragraph": "Sideloading has been a hot topic for the last decade. Most recently, Google has announced further restrictions on the practice in Android. Many hundreds of comment threads have discussed these changes over the years. One point in particular is always made: \u201cI should be able to run whatever code I want on hardware I own\u201d. I agree entirely with this point, but within the context of this discussion it\u2019s moot.\u201cI should be able to run whatever code I want on hardware I own\u201dWhen Google restricts your ability to install certain applications they aren\u2019t constraining what you can do with the hardware you own, they are constraining what you can do using the software they provide with said hardware. It\u2019s through this control of the operating system that Google is exerting control, not at the hardware layer. You often don\u2019t have full access to the hardware either and building new operating systems to run on mobile hardware is impossible, or at least much harder than it should be. This is a separat"
  },
  {
    "title": "Eternal Struggle (yoavg.github.io)",
    "points": 316,
    "submitter": "yurivish",
    "submit_time": "2025-08-31T19:04:03 1756667043",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=45086020",
    "comments": [
      "Some people here were asking for it so I quickly vibe forked a speed control slider for farming some karma here on Hacker News:https://francisduvivier.github.io/eternal-struggle-with-spee...Code: https://github.com/francisduvivier/eternal-struggle-with-spe...reply",
      "Not to alarm anyone, but when I ran this, the black ball eventually joined the dark side and the whole thing ended up black. I\u2019m sure this doesn\u2019t mean anything for the greater universe.reply",
      "This happened to me in the original site. I think it happens when the white and black balls collide at the exact same spot of the border.reply",
      "The opposite can also happen (where the whole thing goes white).reply",
      "A little matter-antimatter asymmetry never hurt anyonereply",
      "Metaphor for American politics.reply",
      "\"I am.. Tetsuo.\"reply",
      "This vibed coded implementation is buggy.If you go to 64.00\u00d7, it can't slow back anymore.reply",
      "Well that's fixed in the V2 with even more vibe coding:https://francisduvivier.github.io/eternal-struggle-with-spee...reply",
      "Watching it at 100x is cool - you can just watch the border wiggle around (at this speed you may as well not even draw the balls).reply"
    ],
    "link": "https://yoavg.github.io/eternal/",
    "first_paragraph": ""
  },
  {
    "title": "Lewis and Clark marked their trail with laxatives (offbeatoregon.com)",
    "points": 41,
    "submitter": "toomuchtodo",
    "submit_time": "2025-08-31T22:54:26 1756680866",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=45087815",
    "comments": [
      "Here is an article that actually describes the search for the mercury in the laxatives: https://www.discovermagazine.com/following-lewis-and-clarks-...reply",
      "\"600 giant pills that the men called 'thunder-clappers,'\"I love little reminders that people haven't changed that much over the centuriesreply",
      "'The main active ingredient in \u201cthunder-clappers\u201d was a mercury salt.'This doesn't seem particularly safe or good for the environment.I doubt if the product is sold now.Edit: https://en.m.wikipedia.org/wiki/Calomelreply",
      "I just got back from backwoods camping, each site has a wooden chest/thunderbox/toilet out in the open woods near the site. I'm not sure if the thunder is the heavy wooden lid closing or the noises that come from it. Some are out of sight of the campsite but ours was only 75ft away, fortunately the lid blocked your view if it was in use.reply",
      "I could be wrong, but I don't think that is the thunder the \"thunder clappers\" was named after.reply",
      "Hunter-gatherer tribes probably had some natural laxative they called some version of \"thunder-clapper\" and giggled as they said it.reply",
      "Travelling thousands of miles overland, in constant fear of ambush from a fearsome plains tribe war party, alternating between intense constipation and explosive diarrhea - bet they didn't put all that on the brochure when they were signing folks up to paddle the canoes.reply",
      "This article just shows up on the front page of HN as I drink senna tea... perfect.reply"
    ],
    "link": "https://offbeatoregon.com/2501d1006d_biliousPills-686.077.html",
    "first_paragraph": "AS LEWIS AND CLARK\u2019S Corps of Discovery made its way across the continent to Oregon, the men (and woman) of the party probably weren\u2019t thinking much about their place in history. So they weren\u2019t taking any particular pains to document their every movement.There were, however, some particular pains they were experiencing with every movement, so to speak ... as a result of a relentlessly low-fiber diet: Everyone was constipated, all the time.Luckily, they had something that helped with that \u2014 a lot. The Corps of Discovery left on its journey with a trove of 600 giant pills that the men called \u201cthunder-clappers,\u201d which the soldiers and travelers used to jump-start things when they got bound up. And everyone used them pretty regularly.And, strange as it seems, that fact is why we know several of their campsites along the way. The main active ingredient in \u201cthunder-clappers\u201d was a mercury salt, which is a pretty stable compound. Archaeologists simply have to search for dimples in the ground"
  },
  {
    "title": "\u201cThis telegram must be closely paraphrased before being communicated to anyone\u201d (history.stackexchange.com)",
    "points": 522,
    "submitter": "azeemba",
    "submit_time": "2025-08-31T12:39:47 1756643987",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=45082731",
    "comments": [
      "I forget who told me this story, but at some point the British tried a crazy known-plaintext attack by planting handwritten notes in dead German soldiers\u2019 pockets that contained an \u201cimportant message\u201d to be sent, and then in the following days they would attempt to decrypt enigma communications against the known plaintext.reply",
      "https://en.m.wikipedia.org/wiki/Operation_Mincemeatreply",
      "> Part of the wider Operation Barclay, Mincemeat was based on the 1939 Trout memo, written by Rear Admiral John Godfrey, the director of the Naval Intelligence Division, and his personal assistant, Lieutenant Commander Ian FlemingWonder if we'll ever see it on a bond movie.reply",
      "The story of the man[1] whose body was used to fool German intelligence during Operation Mincemeat is quite tragic:> Michael was born in Aberbargoed in Monmouthshire in South Wales. Before leaving the town, he held part-time jobs as a gardener and labourer. His father Thomas, a coal miner, killed himself when Michael was 15, and his mother died when he was 31. Homeless, friendless, depressed, and with no money, Michael drifted to London where he lived on the streets.> Michael was found in an abandoned warehouse close to King's Cross, seriously ill from ingesting rat poison that contained phosphorus. Two days later, he died at age 36 in St Pancras Hospital. His death may have been suicide, although he might have simply been hungry, as the poison he ingested was a paste smeared on bread crusts to attract rats.> After being ingested, phosphide reacts with hydrochloric acid in the stomach, generating phosphine, a highly toxic gas. One of the symptoms of phosphine poisoning is pulmonary oedema, an accumulation of large amounts of liquid in the lungs, which would satisfy the need for a body that appeared to have died by drowning. Purchase explained, \"This dose was not sufficient to kill him outright, and its only effect was to so impair the functioning of the liver that he died a little time afterwards\". When Purchase obtained Michael's body, it was identified as being in suitable condition for a man who would appear to have floated ashore several days after having died at sea by hypothermia and drowning.[1] https://en.wikipedia.org/wiki/William_Martin_(Royal_Marines_...reply",
      "https://en.wikipedia.org/wiki/Gardening_(cryptanalysis)reply",
      "That's not what gp was talking about.reply",
      "It was more of an allusion than a reference, but expectations in communication ought be acknowledged and accommodated, so I apologize if you misunderstood my point as it wasn\u2019t clear from context. Please see my edit.(My prior comment referenced Operation Mincemeat at the time of its reply, for those reading after the fact.)reply",
      "ETA: Note that I appear to have been mistaken about the connection to ENIAC.Note that it is equally dangerous to send paraphrased messages using the same key (which is called sending messages \"in depth\"). This was used to crack the Lorenz (\"Tunny\") cipher. Interestingly Bletchley Park hadn't gotten their hands on a Lorenz machine, they cracked it based on speculation. And it lead to the development of the first tube computer, Collosus (which influenced the ENIAC).\nNowadays we use nonces to avoid sending messages in depth, but nonce reuse can be similarly disastrous for systems like AES-GCM. For example there have been Bitcoin hardware wallets that reused nonces, allowing the private key to be extracted & the Bitcoin stolen. (To be clear, cryptocurrencies and AES-GCM are completely different systems that have this one property in common.)https://en.wikipedia.org/wiki/Cryptanalysis_of_the_Lorenz_ci...https://www.youtube.com/watch?v=Ou_9ntYRzzw [Computerphile, 16m]As an aside does anyone know why it's called \"in depth?\" I'm guessing that it's related to Bletchley Park's penchant for naming things after fish? But possibly also their techniques that involved arranging messages together and sliding a stencil over them to visually spot patterns (so they're sort of overlayed)? I tried some casual searching but it's a very generic phrase and so difficult to search. It's defined in the The 1944 Bletchley Park Cryptographic Dictionary but it doesn't give an etymology.https://www.codesandciphers.org.uk/documents/cryptdict/crypt... [Page 28]reply",
      "I visited Bletchley Park museum this summer when in London. Can recommend and it's also really easy to get there; just a 50 minute train ride from London Euston station, and 5 minute walk to the museum. Entire family enjoyed the museum (have two teenage kids). There is also the \"National Museum of Computing\" located next to it which contains the Bombe, Collosus and related equipment. As I understand it most (or all?) of the original hardware was destroyed after the war to avoid leaking any information about the British code breaking skills. Thus, the machines on display are replicas, but should be fully working.The computer museum also exhibits post-war computers all the way to modern machines. I'd say that museum is more for the geeks while the Bletchley Park museum is definitely worth a visit even if you're not into computers.reply",
      "A personal Bletchley Park anecdote: my grandfather, an electrical engineer, staffed a radio listening station during the war, and every evening a motorcycle dispatch rider would take the day\u2019s intercepts away to a secret location. It was more than 20 years before my grandfather figured out they went to Bletchley.In the 1980s the Bletchley museum project put out a call for wartime electrical components so they could build their Colossus replica. My grandfather in the 1950s had made a chain of Christmas tree lights from govt issue tiny light lightbulbs he pinched from work. He painstakingly removed the nail polish he had painted them with 30 years earlier, and sent them to Bletchley. They used his family Christmas lightbulbs in the replica that is still there today.I had the privilege of touring the museum with him in the 1990s. Also on that day I heard my grandmother\u2019s stories of her time in the British Army during the war. That day was incredibly interesting and moving, and is an important memory for me.reply"
    ],
    "link": "https://history.stackexchange.com/questions/79371/this-telegram-must-be-closely-paraphrased-before-being-communicated-to-anyone",
    "first_paragraph": ""
  },
  {
    "title": "Jujutsu for everyone (jj-for-everyone.github.io)",
    "points": 311,
    "submitter": "Bogdanp",
    "submit_time": "2025-08-31T15:31:04 1756654264",
    "num_comments": 214,
    "comments_url": "https://news.ycombinator.com/item?id=45083952",
    "comments": [
      "In case the author is reading, can I suggest reformatting this kind of thing:>The command jj log shows you a visual representation of your version history. If you run it, you should see something like this:> @  mkmqlnox alice@local 2025-07-22 20:15:56 f6feaadfTo:> The command jj log shows you a visual representation of your version history.> $ jj log> @  mkmqlnox alice@local 2025-07-22 20:15:56 f6feaadfMuch better for learning when the command itself is part included in the output.reply",
      "I've now seen a dozen of articles that explain that jj is wonderful and better than Git for everything. This tutorial is of the same kind. Now that I've read extensively about the good part, I'd be more interested by the bad and the ugly. Because my experience with jj was more balanced.When I tried jj, I found a few pain points that made me return to Git. For instance, I was sharing a branch with a co-worker where we were just piling commits as soon as they were ready (after `pull --rebase` if necessary). Since jj doesn't have names branches, that workflow was easy with git and tedious with jj \u2013 even with the `tug` alias. The process in the \"Tracking remote bookmarks\" chapter of this tutorial still doesn't look nice to me.Another pain point was that jj could not colocate with light clones, like `git clone --filter=blob:none`. Maybe that's fixed now.reply",
      "I\u2019m slightly confused. jj has named branches. They\u2019re just called \u201cbookmarks\u201d.Once you track the remote bookmark, `jj git fetch` will update your local one to match the remote.reply",
      "Yeah, I don't get GP either, maybe their setup is different and more complex?reply",
      "One thing that has bitten me a few times is jj randomly losing my changes. As in, I'll be working in Cursor, not run any mutating jj command (maybe I'll run jj status or jj log, but nothing else), and later on my changes are gone from my repository (often times with a message about a stale workspace).I'm not sure if this is somehow related to my IDE, working in a huge monorepo, or something else, but it has been quite painful.Aside from that, though, I do really like the flexibility jj provides.reply",
      "My best guess: something (likely cursor) is running git commands that mutate the repo behind your back. I don\u2019t use cursor so I can\u2019t say for sure, though.reply",
      "Your changes are almost certainly in the op log, even as just bare snapshot operations. Have you been able to search that and recover them?(i've found jj undo quite robust, i'd be surprised if you ever actually lost work tbh)reply",
      "If this happened with Git I feel confident enough to recover my work. I'm not familiar enough with jj, so usually when this happens I've used VS Code's timeline feature to recover my work.reply",
      "That's surprising. I have no real insight, but... was that a colocated repo? Is there any chance Cursor was creating/modifying the Git commits?reply",
      "Yeah, it was a colocated repo. I've been using Cursor, but this also happened with VS Code at least once. I don't think that either tool should be doing anything with Git aside from maybe running git fetch.reply"
    ],
    "link": "https://jj-for-everyone.github.io/",
    "first_paragraph": "Press \u2190 or \u2192 to navigate between chaptersPress S or / to search in the bookPress ? to show this helpPress Esc to hide this helpThis is a tutorial for the Jujutsu version control system.\nIt requires no previous experience with Git or any other version control system.At the time of writing, most Jujutsu tutorials are targeted at experienced Git users, teaching them how to transfer their existing Git skills over to Jujutsu.\nThis tutorial is my attempt to fill the void of beginner learning material for Jujutsu.\nIf you are already experienced with Git, I recommend Steve Klabnik's tutorial instead of this one.This tutorial requires you to work in the terminal.\nDon't worry, there's a chapter covering some terminal basics in case you're not 100% comfortable with that yet.\nThe commands I tell you to run will often only work on Unix-like operating systems like Linux and Mac.\nIf you're on Windows (and can't switch to Linux), consider using WSL.The tutorial is split into levels, which are the top-"
  },
  {
    "title": "Pong Clock (bigjobby.com)",
    "points": 49,
    "submitter": "donohoe",
    "submit_time": "2025-08-28T16:29:31 1756398571",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=45054119",
    "comments": [
      "I like to imagine two actual people controlling this game, and it's their job to control time. If one misses by accident, time for everyone on earth advances a little too quickly.reply",
      "Great idea! Wish the speed was bit more. I think it would be cool if it takes exactly 1 second to bounce between the two paddles.reply",
      "I have an old TV that I bought in 2015.  It's in this kind of weird situation where it's \"too good to throw away but not good enough to actually use\".  All I have been using it for in the last six years is plugging it into servers that only have a VGA port, and I don't have any of those anymore.I've thought about mounting it to a wall plugging in a Raspberry Pi and have it constantly rotate fun different types of clocks.  Something like this seems like it could be a fit.reply",
      "Cute, I love it! Thanks for sharing this.It would be just a little bit better though if the paddles just missed the ball when the time changes rather than entirely stepping aside.But still wonderful, nevertheless.reply",
      "It took me a while to figure out that the time would advance when one of the paddles missed. I was also disappointed by the way it missed by intentionally moving to the top of the play field.I wonder how difficult it would be to code it so the miss was more convincing.reply",
      "Thanks for the hint about what is interesting about this.reply",
      "Thank you for bringing a tiny bit of joy to the dayreply",
      "This is great, congrats on getting it out!reply",
      "this is actually entertainingreply",
      "Out of curiosity, are you Scottish?reply"
    ],
    "link": "https://bigjobby.com/pong/?v=2.0/",
    "first_paragraph": "Buy me a coffee? Choose a small amount or set your own.You\u2019ll be taken to PayPal to complete the donation securely.\n      We use cookies to enhance your experience, analyze site usage, and provide a personalized browsing experience.\n      For more information, see our Privacy Policy.\n    This clock requires JavaScript."
  },
  {
    "title": "What to do with C++ modules? (nibblestew.blogspot.com)",
    "points": 86,
    "submitter": "ingve",
    "submit_time": "2025-08-31T19:22:01 1756668121",
    "num_comments": 58,
    "comments_url": "https://news.ycombinator.com/item?id=45086210",
    "comments": [
      "Back in the 90s, I implemented precompiled headers for my C++ compiler (Symantec C++). They were very much like modules. There were two modes of operation:1. all the .h files were compiled, and emitted as a binary that could be rolled in all at once2. each .h file created its own precompiled header. Sounds like modules, right?Anyhow, I learned a lot, mostly that without semantic improvements to C++, while it made compilation much faster, it was too sensitive to breakage.This experience was rolled into the design of D modules, which work like a champ. They were everything I wanted modules to be. In particular,The semantic meaning of the module is completely independent of wherever it is imported from.Anyhow, C++ is welcome to adopt the D design of modules. C++ would get modules that have 25 years of use, and are very satisfying.Yes, I do understand that the C preprocessor macros are a problem. My recommendation is, find language solutions to replace the preprocessor. C++ is most of the way there, just finish the job and relegate the preprocessor to the dustbin.reply",
      "> just finish the job and relegate the preprocessor to the dustbin.Yup, I think this is the core of the problem with C++.  The standards committee has drawn a bad line that makes encoding the modules basically impossible.  Other languages with good module systems and fast incremental builds don't allow for preprocessor style craziness without some pretty strict boundaries.  Even languages that have gotten it somewhat wrong (such as rust with it's proc macros) have bound where and how that sort of metaprogramming can take place.Even if the preprocessor isn't dustbined, it should be excluded from the module system.  Metaprogramming should be a feature of the language with clear interfaces and interactions.  For example, in Java the annotation processor is ultimately what triggers code generation capabilities.  No annotation, no metaprogramming.  It's not perfect, but it's a lot better than the C/C++'s free for all macro system.Or the other option is the go route.  Don't make the compiler generate code, instead have the build system be responsible for code generation (calling code generators).  That would be miles better as it'd allow devs to opt in to that slowdown when they need it.reply",
      "Did anyone reach out to you for input during the modules standardization process? D seems like the most obvious prior art, but the modules standardization process seems like it was especially cursedreply",
      "Nobody from C++ reached out to me for the modules.Herb Sutter, Andrei Alexandrescu and myself once submitted an official proposal for \"static if\" for C++, based on the huge success it has had in D. We received a vehement rejection. It demotivated me from submitting further proposals. (\"static if\" replaces the C preprocessor #if/#ifdef/#ifndef constructions.)C++ has gone on to adopt many features of D, but usually with modifications that make them less useful.reply",
      "I can't think of a C++ project I've worked on that didn't rely on being able to include C headers and have things usually just work. Are there ways of banning C macros from \"modular\" C++ without breaking that? (Many would find it unacceptable if you had to go through every C dependency and write/generate some sort of wrapper.)reply",
      "What has to change in C++ templates for this to work?It seems particularly tricky to define a template in a module and then instantiate it or specialize it somewhere else.reply",
      "In order to make things work smoothly, the module has to have its own namespace, and a namespace that is closed.D also has an `alias` feature, where you can do things like:    alias Q = abc.T;\n\nwhere from then on, `abc.T` can be referred to simply as `Q`. This also eliminates a large chunk of purpose behind the preprocessor.reply",
      "Neat, closed namespaces sound great!C++ has adapted the \u2018using\u2019 keyword now to seem fairly similar to alias, but can\u2019t completely subsume macros unfortunately.reply",
      "I think modularization of templates is really hard. Best thing I can think of is a cache e.g. for signatures. But then again this is basically what the mangling already does anyways in my understanding.reply",
      "Not just signatures, you need the whole AST more or less.This seems incredibly wasteful, but of course still marginal better than just #including code which is the alternative.reply"
    ],
    "link": "https://nibblestew.blogspot.com/2025/08/we-need-to-seriously-think-about-what.html",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: VibeFlow (YC S25) \u2013 Web app generator with visual, editable workflows",
    "points": 71,
    "submitter": "alepeak",
    "submit_time": "2025-08-31T17:00:19 1756659619",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=45084759",
    "comments": [
      "Well I am/was building something that looks a lot like this, a shame I never applied to YC, wondering now if I should apply to other funds now so I can continue working on it, the prototype is ready so I have the main part figured out.\nA question, perhaps, could you give some tips to pitch this specifically, just for incubators, based on your experience?reply",
      "Why not focus your energy on selling it to real people instead of figuring out how to pitch it to incubators?reply",
      "This looks great! Can I export my end code / app and host it elsewhere easily? Where else would easily be able to host it?reply",
      "They say they use Convex for the backend, which means you could in principle run it on your own account or go through the hoops of self hosting convex infrareply",
      "exactlyreply",
      "In general to me it makes a lot of sense to lean much more into \"templates\" (I'm sure lovable etc already do it, because it's also a nice way to save money). And it's much easier to at least guarantee some basic security when it comes to auth, payments, db setup etc. Of course you can shoot yourself in the foot right after that.reply",
      "Totally agree, security is a big point. It\u2019s hard to trust LLMs on security, which is why we aim to make \u2018white box\u2019 backendsreply",
      "I want to like this and dig into it as someone who has recently used Lovable and Base44 (and been using Bubble for a while), but the YouTube \u2018demo\u2019 video is really weak.The pace is too fast and you spend barely any time showing off your visual workflow feature, which according to your description is your differentiator.I would strongly recommend using some of your YC money to have a professional recreate that demo and show off what makes you unique. Even if it goes longer than two minutes - if I\u2019m interested I\u2019ll keep watching.I\u2019ll still try it out because I\u2019m a sucker for trying out new vibecoding tools, but you\u2019re not doing yourself any favors with that video\u2026reply",
      "Thanks a lot for the feedback. The video was meant as a very spontaneous \u2018as it is\u2019 showcase, but we\u2019ll definitely make new demos that go deeper into the editor!reply",
      "> recently used Lovable and Base44Are you happy with either product? I tried them earlier in the year, and it was also really slow to make changes. I felt like they got stuck after a bit, too.It's a neat concept, but I feel like they're expensive templates. I'd honestly prefer a template gallery with a smooth and fast editing UI.reply"
    ],
    "link": "item?id=45084759",
    "first_paragraph": ""
  },
  {
    "title": "When the sun will literally set on what's left of the British Empire (oikofuge.com)",
    "points": 133,
    "submitter": "bediger4000",
    "submit_time": "2025-08-31T17:15:19 1756660519",
    "num_comments": 193,
    "comments_url": "https://news.ycombinator.com/item?id=45084913",
    "comments": [
      "Hm.  I feel like the french republic can still make the claim though, at least according to this wikipedia map.\nhttps://upload.wikimedia.org/wikipedia/commons/6/67/Mapadefr...reply",
      "I measured it a while ago (well, 11 years now) and both France and the UK made the cut[0].France has much more margin though, IIRC no single territory becoming independent would make the sun set on France.[0]https://ssz.fr/sun-never-sets/reply",
      "I'm glad someone did this, because for a moment I was thinking that I was going to have to do the math on France.reply",
      "It is always funny to ask people what country has the longest land border with France.reply",
      "For those wondering, it's Brazil.reply",
      "> The Franco-Spanish border runs for 685.42 kilometres (425.90 mi) between southwestern France and northeastern Spain. [1]> The Brazil\u2013France border is the line, located in the Amazon Rainforest, that limits the territories of Brazil and France. The border is located between the Brazilian state of Amap\u00e1 and French Guiana. It is 730 kilometres (450 mi) in length. [2]I'll be damned![1] https://en.wikipedia.org/wiki/France\u2013Spain_border[2] https://en.wikipedia.org/wiki/Brazil\u2013France_borderreply",
      "Is there a standard for measuring borders for these purposes, in light of the coastline paradox?I don't mean to suggest that there's no sensible way to do it; I just wonder if people might be using inconsistent methods sometimes, leading to not-very-comparable estimates.reply",
      "It's an excellent question. The Wikipedia citations don't actually lead to much, and there's no indication they use the same methodology.Best I can find is the CIA World Factbook [1] which lists France's border with Spain at 646 km (under \"France\" and \"Spain\", same value), and Brazil's border with French Guiana at 649 km (under \"Brazil\").So, already a radical difference -- from a 45km difference to a 3km difference (just 0.5%). But there's more:> When available, official lengths published by national statistical agencies are used. Because surveying methods may differ, country border lengths reported by contiguous countries may differ.But there's no indication whether these particular measurements are made by the CIA using the same technique with maps of the same resolution... or, being so close to begin with, whether different resolutions would change the asnwer... or if these are official lengths derived using totally different and ultimately incomparable procedures.So maybe it's not so cut-and-dried that France's longest border is with Brazil...?[1] https://www.cia.gov/the-world-factbook/about/archives/2022/f...reply",
      "> It's an excellent question.Thanks Claude.reply",
      "Borders are not like coastlines because they\u2019re abstract delineations, not physical things, even though they\u2019re frequently defined using geographic features.In this case, the length of the border is dominated by the length of the thalweg of the Oyapock river. Using thalwegs is SOP in international law when using rivers as the natural border and the choice of river is due to treaties that are hundreds of years old.reply"
    ],
    "link": "https://oikofuge.com/sun-sets-on-british-empire/",
    "first_paragraph": "A while ago I treated you to a dissertation entitled \u201cDoes The Sun Set On The British Empire?\u201d, and concluded that it doesn\u2019t. The UK\u2019s widely scattered overseas territories, sparse though they are, mean that the sun is still always shining, somewhere in the world, over British territory.The most important territories in maintaining this late-empire sunlight are the Pitcairn Islands, in the Pacific, and the British Indian Ocean Territory, in the Indian Ocean. To illustrate that, I offered the sunlight chart below, showing how Pitcairn and BIOT catch the sunlight when it\u2019s dark in the UK.In fact, as my map at the head of this post shows, BIOT is pivotal. There, I\u2019ve plotted the distribution of light and darkness, across the globe, at 02:15 Greenwich Mean Time, during the June solstice of 2024.*And here\u2019s the situation at the December solstice:Just after the sun sets in Pitcairn, it\u2019s dark over every British territory except BIOT.I\u2019m revisiting the situation because the UK government has"
  },
  {
    "title": "A Linux version of the Procmon Sysinternals tool (github.com/microsoft)",
    "points": 17,
    "submitter": "LelouBil",
    "submit_time": "2025-08-31T22:43:05 1756680185",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45087748",
    "comments": [
      "If this works remotely as well as the Windows version, I'm stoked. Polling for information (like with lsof) really rubs me the wrong way.reply",
      "really? i have to use procman and associated utilities often and they really pale in comparison with linux and even moreso other unix utils (like dtrace)reply"
    ],
    "link": "https://github.com/microsoft/ProcMon-for-Linux",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A Linux version of the Procmon Sysinternals tool\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Process Monitor (Procmon) is a Linux reimagining of the classic Procmon tool from the Sysinternals suite of tools for Windows.  Procmon provides a convenient and efficient way for Linux developers to trace the syscall activity on the system.Please see installation instructions here.Please see build instructions here.The following traces all processes and syscalls on the system:The following traces processes with process id 10 and 20:The following traces process 20 only syscalls read, write and open at:The following traces process 35 and opens Procmon in headless mode to output all captured events to file procmon.db:The following opens a Procmon tracefile, procmon"
  },
  {
    "title": "Nintendo Switch 2 Dock USB-C Compatibility (lttlabs.com)",
    "points": 19,
    "submitter": "croes",
    "submit_time": "2025-08-31T23:21:46 1756682506",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.lttlabs.com/blog/2025/08/30/nintendo-switch-2-dock",
    "first_paragraph": ""
  },
  {
    "title": "Use One Big Server (2022) (specbranch.com)",
    "points": 128,
    "submitter": "antov825",
    "submit_time": "2025-08-31T17:29:07 1756661347",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=45085029",
    "comments": [
      "One of the more detrimental aspects of the Cloud Tax is that it constrains the types of solutions engineers even consider.Picking an arbitrary price point of $200/mo, you can get 4(!) vCPUs and 16GB of RAM at AWS. Architectures are different etc., but this is roughly a mid-spec dev laptop of 5 or so years ago.At Hetzner, you can rent a machine with 48 cores and 128GB of RAM for the same money. It's hard to overstate how far apart these machines are in raw computational capacity.There are approaches to problems that make sense with 10x the capacity that don't make sense on the much smaller node. Critically, those approaches can sometimes save engineering time that would otherwise go into building a more complex system to manage around artificial constraints.Yes, there are other factors like durability etc. that need to be designed for. But going the other way, dedicated boxes can deliver more consistent performance without worries of noisy neighbors.reply",
      "I agree that AWS EC2 is probably too expensive on the whole. It also doesn't really provide any of the greater benefits of the cloud that come from \"someone else's server\".However, to the point of microservices as the article mentions, you probably should look at lambda (or fargate, or a mix) unless you can really saturate the capacity of multiple servers.When we swapped to ECS+EC2 running microservices over to lambda our costs dropped sharply. Even serving millions of requests a day we spend a lot of time in between idle, especially spread across the services.Additionally, we have 0 outages now from hardware in the last 5 years. As an engineer, this has made my QoL significantly better.reply",
      "It's more than that - it's all the latency that you can remove from the equation with your bare-metal server.No network latency between nodes, less memory bandwidth latency/contention as there is in VMs, no caching architecture latency needed when you can just tell e.g. Postgres to use gigs of RAM and then let Linux's disk caching take care of the rest (and not need a separate caching architecture).reply",
      "The difference between a fairly expensive ($300) RDS instance + EC2 in the same region vs a $90 dedicated server with a NVME drive and postgres in a container is absolutely insane.reply",
      "Yeah but AWS SRE are what making the big bucks! Soooo what can you do? It is nice to see many people here on HN are supporting open network and platform and making very drastic comments as to encouraging google engineers to quite their jobs.I totally also understand why some people with family to support mortgage to pay they can't just walk way from a job at FAANG or MAMAA type place.Looking at your comparison, this point it just seems like a scam.reply",
      "A fair comparison would include the cost of the DBA who will be responsible for backups, updates, monitoring, security and access control. That\u2019s what RDS is actually competing with.reply",
      "As long as you also include the Cloud Certified DevOps Engineer\u2122[0] to set up that RDS instance.[0] A normal sysadmin remains vaguely bemused at their job title and the way it changes every couple years.reply",
      "Paying someone $2000 to set that up once should result in the costs being recovered in what, 18 months?If you\u2019re running Postgres locally you can turn off the TCP/IP part; nothing more to audit there.SSH based copying of backups to a remote server is simple.If not accessible via network, you can stay on whatever version of Postgres you want.I\u2019ve heard these arguments since AWS launched, and all that time I\u2019ve been running Postgres (since 2004 actually) and have never encountered all these phantom issues that are claimed as being expensive or extremely difficult.reply",
      "You don\u2019t need a DBA for any of those, you need someone who can read some docs. It\u2019s not witchcraft.reply",
      "I do consulting in this space, and we consistently make more money from people who insist on using cloud services, because their setups tend to need far more work.reply"
    ],
    "link": "https://specbranch.com/posts/one-big-server/",
    "first_paragraph": "A lot of ink is spent on the \"monoliths vs. microservices\" debate, but the real issue behind\nthis debate is about whether distributed system architecture is worth the developer time and\ncost overheads.  By thinking about the real operational considerations of our systems, we can\nget some insight into whether we actually need distributed systems for most things.We have all gotten so familiar with virtualization and abstractions between our software\nand the servers that run it.  These days, \"serverless\" computing is all the rage, and even\n\"bare metal\" is a class of virtual machine.  However, every piece of software runs on a\nserver.  Since we now live in a world of virtualization, most of these servers are a lot\nbigger and a lot cheaper than we actually think.This is a picture of a server used by Microsoft Azure with AMD CPUs.  Starting from the left,\nthe big metal fixture on the left (with the copper tubes) is a heatsink, and the metal boxes\nthat the copper tubes are attached to are hea"
  },
  {
    "title": "A Crack in the Cosmos (drb.ie)",
    "points": 6,
    "submitter": "Hooke",
    "submit_time": "2025-08-31T04:11:05 1756613465",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://drb.ie/articles/a-crack-in-the-cosmos/",
    "first_paragraph": ""
  },
  {
    "title": "What brain surgery taught me about the fragile gift of consciousness (bigthink.com)",
    "points": 4,
    "submitter": "NaOH",
    "submit_time": "2025-08-28T14:22:07 1756390927",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://bigthink.com/business/brain-surgery-fragile-gift-of-consciousness/",
    "first_paragraph": ""
  },
  {
    "title": "Bayes, Bits and Brains (bayesbitsbrains.github.io)",
    "points": 18,
    "submitter": "cgadski",
    "submit_time": "2025-08-28T13:51:05 1756389065",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://bayesbitsbrains.github.io/",
    "first_paragraph": "This site is about probability and information theory. We'll see how they help us understand machine learning and the world around us.More about the content, prerequisites, and logistics later. I hope you get a feel for what this is about by checking out the following riddles. I hope some of them nerd-snipe you! \ud83d\ude09 You will understand all of them at the end of this minicourse.Test your intelligence with the following widget! You will be given a bunch of text snippets cut from Wikipedia at a random place. Your job: predict the next letter! Try at least five snippets and compare your performance with some neural nets (GPT-2 and Llama 4).Don't feel bad if a machine beats you; they've been studying for this test their entire lives! But why? And why did Claude Shannon - the information theory GOAT - make this experiment in the 1940s?As we go through the mini-course, we'll revisit each puzzle and understand what's going on. But more importantly, we will understand some important pieces of mat"
  },
  {
    "title": "Why haven't quantum computers factored 21 yet? (algassert.com)",
    "points": 233,
    "submitter": "ingve",
    "submit_time": "2025-08-31T12:14:26 1756642466",
    "num_comments": 142,
    "comments_url": "https://news.ycombinator.com/item?id=45082587",
    "comments": [
      "So how many gates are we talking to factor some \"cryptographically useful\" number? Is there some pathway that makes quantum computers useful this century?reply",
      "> So how many gates are we talking to factor some \"cryptographically useful\" number?Table 5 of [1] estimates 7 billion Toffoli gates to factor 2048 bit RSA integers.> Is there some pathway that makes quantum computers useful this century?The pathway to doing billions of gates is quantum error correction. [1] estimates distance 25 surface codes would be sufficient for those 7 billion gates (given the physical assumptions it lists). This amplifies the qubit count from 1400 logical qubits to a million physical noisy qubits.Samuel Jacques had a pretty good talk at PQCrypto this year, and he speculates about timelines in it [2].(I'm the author of this blog post and of [1].)[1]: https://arxiv.org/pdf/2505.15917[2]: https://www.youtube.com/watch?v=nJxENYdsB6creply",
      "From the talk of Samuel Jacques:\nTimeline for RSA-2048 at about 2088 (conservative extrapolation) or ~2052 (Moore\u2019s\u2011law\u2011style growth)reply",
      "How do you go from 7 billion Toffoli gates (which consist of 42 billion \"two-qubit entangling gates\", per the blog post) to merely 1400 logical qubits?reply",
      "It's not just quantum error correction that is required, it's also hard to make devices small enough due to cooling, to allow thousands of qubits let alone billions.reply",
      "> So how many gates are we talking to factor some \"cryptographically useful\" number?That is a hard question to answer for two reasons.  First, there is no bright line that delineates \"cryptographically useful\".  And second, the exact design of a QC that could do such a calculation is not yet known.  It's kind of like trying to estimate how many traditional gates would be needed to build a \"semantically useful\" neural network back in 1985.But the answer is almost certainly in the millions.[UPDATE] There is a third reason this is hard to predict: for quantum error correction, there is a tradeoff between the error rate in the raw qbit and the number of gates needed to build a reliable error-corrected virtual qbit.  The lower the error rate in the raw qbit, the fewer gates are needed.  And there is no way to know at this point what kind of raw error rates can be achieved.> Is there some pathway that makes quantum computers useful this century?This century has 75 years left in it, and that is an eternity in tech-time.  75 years ago the state of the art in classical computers was (I'll be generous here) the Univac [1].  Figuring out how much less powerful it was than a modern computer makes an interesting exercise, especially if you do it in terms of ops/watt.  I haven't done the math, but it's many, many, many orders of magnitude.  If the same progress can be achieved in quantum computing, then pre-quantum encryption is definitely toast by 2100.  And it pretty much took only one breakthrough, the transistor, to achieve the improvement in classical computing that we enjoy today.  We still don't have the equivalent of that for QC, but who knows when or if it will happen.  Everything seems impossible until someone figures it out for the first time.---[1] https://en.wikipedia.org/wiki/UNIVAC_I#Technical_descriptionreply",
      "It's not an eternity because QC is a low-headroom tech which is already pushing its limits.What made computing-at-scale possible wasn't the transistor, it was the precursor technologies that made transistor manufacturing possible - precise control of semiconductor doping, and precision optical lithography.Without those the transistor would have remained a lab curiosity.QC has no hint of any equivalent breakthrough tech waiting to kick start a revolution. There are plenty of maybe-perhaps technologies like Diamond Defects and Photonics, but packing density and connectivity are always going to be huge problems, in addition to noise and error rate issues.Basically you need high densities to do anything truly useful, but error rates have to go down as packing densities go up - which is stretching optimism a little.Silicon is a very forgiving technology in comparison. As long as your logic levels have a decent headroom over the noise floor, and you allow for switching transients (...the hard part) your circuit will be deterministic and you can keep packing more and more circuitry into smaller and smaller spaces. (Subject to lithography precision.)Of course it's not that simple, but it is basically just extremely complex and sophisticated plumbing of electron flows.Current takes on QC are the opposite. There's a lot more noise than signal, and adding more complexity makes the problem worse in non-linear ways.reply",
      "I'm sympathetic to this argument, but nearly every technological breakthrough in history has been accompanied by plausible-sounding arguments as to why it should have been impossible.  I myself left my career as an AI researcher about 20 years ago because I was convinced the field was moribund and there would be no major breakthroughs in my lifetime.  That was about as well-informed a prediction as you could hope to find at the time and it was obviously very wrong.  It is in the nature of breakthroughs that they are rare and unpredictable.  Nothing you say is wrong.  I would bet against QC is 5 years (and even then I would not stake my life savings) but not 75.reply",
      "In fairness, the biggest breakthrough in AI has been calling more and more things \u201cAI.\u201d Before LLMs it was content based collaborative filtering.reply",
      "No, LLMs are a real breakthrough even if they are not by themselves reliable enough to produce a commercially viable application.  Before LLMs, no one knew how to even convincingly fake a natural language interaction.  I see LLMs as analogous to Rodney Brooks's subsumption architecture.  Subsumption by itself was not enough, but it broke the logjam on the then-dominant planner-centric approach, which was doomed to fail.  In that respect, subsumption was the precursor to Waymo, and that took less than 40 years.  I was once a skeptic, but I now see a pretty clear path to AGI.  It won't happen right away, but I'd be a little surprised if we didn't see it within 10 years.reply"
    ],
    "link": "https://algassert.com/post/2500",
    "first_paragraph": "30 Aug 2025In 2001, quantum computers factored the number 15.\nIt\u2019s now 2025, and quantum computers haven\u2019t yet factored the number 21.\nIt\u2019s sometimes claimed this is proof there\u2019s been no progress in quantum computers.\nBut there\u2019s actually a much more surprising reason 21 hasn\u2019t been factored yet, which jumps out at you when contrasting the operations used to factor 15 and to factor 21.The circuit (the series of quantum logic gates) that was run to factor 15 can be seen in Figure 1b of \u201cExperimental realization of Shor\u2019s quantum factoring algorithm using nuclear magnetic resonance\u201d:The important cost here is the number of entangling gates.\nThis factoring-15 circuit has 6 two-qubit entangling gates (a mix of CNOT and CPHASE gates).\nIt also has 2 Toffoli gates, which each decompose into 6 two-qubit entangling gates.\nSo there\u2019s a total of 21 entangling gates in this circuit.Now, for comparison, here is a circuit for factoring 21.\nSorry for rotating it, but I couldn\u2019t get it to fit otherwi"
  },
  {
    "title": "Installing UEFI Firmware on ARM SBCs (interfacinglinux.com)",
    "points": 65,
    "submitter": "aaronday",
    "submit_time": "2025-08-31T19:37:08 1756669028",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=45086346",
    "comments": [
      "U-Boot does basic enough UEFI emulation for most use cases. I find that I don't need native UEFI firmware and I can just build U-Boot with UEFI support for most ARM devices.For example, right now I have an old armhf i.MX6 Wandboard Quad that runs:  U-Boot -> UEFI (with Secure Boot if desired) -> Systemd Boot (or Linux EFI Boot Stub) -> Debian (or other distro)\n\nThat same layout should be doable on any U-Boot\u00b9 supported device.Some arm devices such as the i.MX6, are strict on the placement of their boot firmware where it would interfere with a normal GPT table. One solution to this is to use a special \"--move-main-table\" option in gdisk\u00b2 so that the GPT doesn't clobber U-Boot. While technically GPT is optional as long as U-Boot can read your main partition, I still always setup GPT anyway or Systemd Boot complains.\u00b9 https://docs.u-boot.org/en/latest/develop/uefi/uefi.html\u00b2 https://www.rodsbooks.com/gdisk/sgdisk.htmlreply",
      "With eMMC can\u2019t you just stick u-boot in a eMMC boot partition?  Then the entire eMMC user area can be used without risk of clobbering u-boot.reply",
      "This here is the important next step for ARM SBCs. A working UEFI. Maybe they can get together and standardize something they can work on together. But this whole SD card flashing nonsense needs to stop.reply",
      "That is what the Arm SystemReady Compliance Program was supposed to achieve. Unfortunately not many manufacturers are following it yethttps://www.arm.com/architecture/system-architectures/system...reply",
      "There is a UEFI standard in some of Arms specs, but it\u2019s only mandatory for the server class IP atm. Some soc vendors are starting to adopt it even in non-server class but it\u2019s slow. My feedback to an Arm devrel a few years ago was exactly this though: you need to provide a consistent standard boot path that also helps OS authors with enough bootstrap that debugging is less of a crapshoot every single time. I hope some progress is made on pushing that down the stack.When the topic comes up some people  express a lot of hatred for uefi (mostly users rather than implementors) but where it\u2019s implementors the ms style APIs and so on are largely the center of it IME, and that\u2019s not really an easy fix when it\u2019s already spec\u2019d. Sometimes there are concerns about size, but slimmed down deployments are common in the socs that ship already - perhaps standardizing on what that slimmed down thing is might help too. May also assuage some of the other concerns of excessive runtime services (which seems rare, but I get the existential concern)reply",
      "ARM SoCs have always been very proprietary and fragmented, and until/if something like the x86/PC comes along I don't think just UEFI is enough. The PC flourished because of many de-facto standards, and not just the BIOS. Unfortunately the companies these days seem to love their proprietariness, so I don't think something like that will happen again.reply",
      "It's this. UEFI doesn't solve the problem of peripheral discovery, for example.SBSA standard in the server realm seems to have it figured out.reply",
      "For completeness sake - uboot can also boot EFI binaries, though upstream won\u2019t support GOP video on RK3588, and is also device tree only so no Windows, just Linux and BSDs.https://docs.u-boot.org/en/latest/develop/uefi/uefi.htmlreply",
      "U-Boot does actually have some support for GOP Video\u00b9. It's rather new, so it might be worth revisiting with your specific devices.\u00b9 https://u-boot.org/blog/seeing-is-believing-video-support-la...reply",
      "The Rock 5 ITX+ is a nice board. I wish a 1U back panel were available for it.UEFI does make things a lot easier. It's a shame that this isn't more common for Arm boards, but it's good to see things heading in the right direction.reply"
    ],
    "link": "https://interfacinglinux.com/2025/08/25/edk2-uefi-for-the-rock-5-itx/",
    "first_paragraph": "I am a huge fan of my Rock 5 ITX+. It wraps an ATX power connector, a 4-pin Molex, PoE support, 32 GB of eMMC, front-panel USB 2.0, and two Gen 3\u00d72 M.2 slots around a Rockchip 3588 SoC that can slot into any Mini-ITX case. Thing is, I never put it in a case because the microSD slot lives on the side of the board, and pulling the case out and removing the side panel to install a new OS got old with a quickness.I originally wanted to rackmount the critter, but adding a deracking difficulty multiplier to the microSD slot minigame seemed a bit souls-like for my taste. So what am I going to do? Grab a microSD extender and hang that out the back? Nay! I\u2019m going to neuralyze the SPI flash and install some Kelvin Timeline firmware that will allow me to boot and install generic ARM Linux images from USB.At least, that\u2019s the plan \ud83d\ude42EDK2-RK3588 is a UEFI firmware implementation based on EDK2 for various RK3588 boards. It delivers a PC-like, standardised boot experience, supporting multiple operati"
  },
  {
    "title": "Best practices for dealing with human waste in the great outdoors (theconversation.com)",
    "points": 31,
    "submitter": "rntn",
    "submit_time": "2025-08-31T19:48:36 1756669716",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=45086440",
    "comments": [
      "Fecal contamination is how we verified the route of Lewis and Clark.https://offbeatoregon.com/2501d1006d_biliousPills-686.077.ht...reply",
      "Only due to their mercury chloride heavy diet.reply",
      "Why is human fecal matter worse for the environment than animal fecal matter?Something in our diets?reply",
      "I think that the main reason is that human population is unusually huge, humans live in the huge dense groups. So there's just too many fecals and environment struggles to process them.Just to compare: there's an estimation that there are around 300 000 gorillas in the entire world. There are over 20 000 humans for every gorilla.Though I think that \"environment\" is too vague. Planet doesn't care. Some bacteria probably would think that it's pretty nice environment. It's more about human waste making environment bad for humans themselves.There are just too many of us, so we need artificial ways to produce food, artificial ways to protect from cold and heat. And also artificial ways to safely dispose of our waste.reply",
      "I'd guess it worse for us because it's a vector for disease. (And grosser to see for related evolutionary reasons). There's probably a greater volume in heavily trafficked places vs similar predators. Otherwise doubtful that pound for pound it's actually worse for \"nature\".reply",
      "We are apex predators, and our shit contains the condensed toxins from all of the lower rungs on the food chain.  The other extreme would be an animal like a cow, which shits basically smellier grass.That's basically it.  A human being that's only eaten plants has much less devastating poops.reply",
      "I don't think this last conclusion is true. It's really about harmful bacteria, not \"toxins\". Even vegetarians have a complex digestive system that can harbour pathogens. Perhaps their faeces are safer to use as manure than those from a meat-eating human, but much closer to that than to a cow.reply",
      "I have heard that it's unusually nutrient rich - maybe not toxins, but human shit definitely causes algal blooms.reply",
      "It is far from a certain that we are apex predators since we can survive on a largely herbivore diet.https://en.wikipedia.org/wiki/Apex_predator#Human_trophic_le...And \"our shit contains the condensed toxins from all of the lower rungs on the food chain.\" lacks any credibility unless you can provide a link I have never seen.reply",
      "Well, at least \u201csmearing\u201d isn\u2019t a default choice anymorereply"
    ],
    "link": "https://theconversation.com/how-to-poop-outdoors-in-a-way-that-wont-harm-the-environment-and-other-hikers-262426",
    "first_paragraph": "\n      Ph.D. Candidate in Recreation, Park and Tourism Management, Penn State\n    \n      Associate Professor of Recreation, Park and Tourism Management, Penn State\n    Shari Edelson has received research funding from the National Park Service, the National Science Foundation and PACT Outdoors.B. Derrick Taff is an Assistant Dean of Research and Graduate Education in the College of Health and Human Development, and an Associate Professor in the Department of Recreation, Park and Tourism Management at Penn State University; he also serves as the Leave No Trace organization's science advisor. Derrick is the Suzie and Allen Martin Professor through Penn State University. Penn State provides funding as a founding partner of The Conversation US.View all partnershttps://doi.org/10.64628/AAI.arsmsfru7Share articlePrint articleIf you\u2019re one of the 63 million Americans who went hiking last year, chances are you\u2019ve found yourself needing to go, with no toilet in sight.Aside from personal inconven"
  },
  {
    "title": "How is Ultrassembler so fast? (jghuff.com)",
    "points": 89,
    "submitter": "netr0ute",
    "submit_time": "2025-08-31T17:42:43 1756662163",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=45085156",
    "comments": [
      "Exceptions in C++ are never zero-overhead.  There is a time-space tradeoff for performance of uncaught exceptions, and G++ picks space over time.reply",
      "There's a time-space tradeoff to basically any means of error checking.Including checking return codes instead of exceptions. It's even possible for exceptions as implemented by g++ in the Itanium ABI to be cheaper than the code that would be used for consistently checking return codes.reply",
      "> G++ picks space over timeBy definition, that's zero-overhead because Ultrassembler doesn't care about space.reply",
      "Okay, than a traditional setjmp/longjmp implementation is zero-overhead because I don't care about space or time!reply",
      "I wonder if you thought about perfect hashing instead of that comparison tree.  Also, flex (as in flex and bison) can generate what amounts to trees like that, I believe.  I haven't benchmarked it compared to a really careful explicit tree though.reply",
      "I thought about hashing, but found that hashing would be enormously slow to compute compared to a perfectly crafted tree.reply",
      "But did you think about using a perfect hash function and table?  Based on my prior research, it seems like they are almost universally faster on small strings than trees and tries due to lower cache miss rates.reply",
      "Ditto. Perfect hashing strings smaller than 8 bytes has been the fastest lookup method in my experience.reply",
      "Problem is, there are a lot of RISC-V instruction way longer than that (like th.vslide1down.vx) so hashing is going to be slow.reply",
      "Is there a handy list of all RISC-V instructions?reply"
    ],
    "link": "https://jghuff.com/articles/ultrassembler-so-fast/",
    "first_paragraph": "Ultrassembler is a superfast and complete RISC-V assembler library that I'm writing as a component of the bigger Chata signal processing project. Assemblers take in a platform-dependent assembly language and output that platform's native machine code which runs directly on the processor.\"Why would you want to do this?\" you might ask. First, existing RISC-V assemblers that conform the the entirety of the specification, as and llvm-mc, ship as binaries that you run as standalone programs. This is normally not an issue. However, in Chata's case, it needs to access a RISC-V assembler from within its C++ code. The alternative is to use some ugly C function like system() to run external software as if it were a human or script running a command in a terminal. Here's an example of what I'm talking about:It gets even worse once you realize you need temporary files and possibly have to artisanally craft the command beforehand. Additionally, invoking the assembler in this manner incurs a signifi"
  },
  {
    "title": "Lunar soil machine developed to build bricks using sunlight (moondaily.com)",
    "points": 37,
    "submitter": "PaulHoule",
    "submit_time": "2025-08-31T19:24:49 1756668289",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=45086238",
    "comments": [
      "Would have appreciated some pictures of what these bricks would look like. Or the mechanism that would create them. Is this a rolling vehicle that creates a lunar brick road as it slowly drives across the landscape?reply",
      "It's probably something similar in concept to Markus Kayser's solar sinterer[1], but with the light being focused onto an optical fiber bundle whose endpoint is moved around in X and Y, rather than moving a basket of regolith.[1] https://www.youtube.com/watch?v=ptUj8JRAYu8&t=240reply",
      "https://en.m.wikipedia.org/wiki/File:Lunar_Martial_Geopolyme...reply",
      "While the tech here obviously has not been tested on the Moon yet, some of the described bricks were already been flown to the Tianzhou space station last year for a three-year testing regime:https://english.hust.edu.cn/info/1102/3973.htmAnd Chang'e 8 (2028?) will likely test this out in situ on the lunar surface:https://en.wikipedia.org/wiki/Chang%27e_8Yet another sign that the Chinese are completely serious about setting up a Moon base.reply",
      "This should help with the problem of randomly being squashed by asteroids.reply",
      "It would be awesome if we could land some construction robots onto the moon and Mars. Let\u2019s get going with construction of underground settlements and research stations.reply",
      "Starship can only land a tiny payload if you expect to reuse it,  but if you don't you can likely land 100 tons and reuse the the vehicle for habitat,  storage tanks and such.  The first thing you land is a lunarized D9 Cat [1]which digs trenches that let you bury the upper stages under 2 meters of regolith which will give good radiation protection and thermal coupling to a reservoir at a constant and comfortable temperature just below the freezing point of water.  I guess you want some kind of crane for handling the Starships but you probably want one anyway if you expect to send them back.[1] https://en.wikipedia.org/wiki/Caterpillar_D9reply",
      "You're not going to be dropping an actual D9, you're going to design something inspired by the DO and others that's optimized for the moon. An actual D9 weighs far too much for the moon and has all kinds of surfaces that couldn't handle lunar dust.reply",
      "For a relative definition of comfortable...reply",
      "Like upstate NY in the winter.  If you can maintain shirtsleeves conditions inside an old farmhouse at that outdoor temperature,  NASA can do it for astronauts.  Contrast that to the surface temperatures which swing from 260\u00b0F to  -280\u00b0F.The corollary is that ice buried on the moon with a vapor barrier to prevent sublimation could be stable.reply"
    ],
    "link": "https://www.moondaily.com/reports/Lunar_soil_machine_developed_to_build_bricks_using_sunlight_999.html",
    "first_paragraph": "\r\n\r\nDeveloped by the Deep Space Exploration Laboratory (DSEL) in Hefei, Anhui province, the system functions as a 3D printing device powered by concentrated solar heat. It employs a parabolic reflector to gather solar radiation, which is then funneled through fiber optic bundles. At the focus point, light intensity exceeds 3,000 times the standard level, reaching temperatures over 1,300 C to melt lunar regolith.\r\n\r\nAccording to senior engineer Yang Honglun, the machine uses no additives - relying entirely on lunar soil. The bricks produced are dense and robust, suitable not only for shelter construction but also for roads and platforms on the lunar surface.\r\n\r\nThe project spanned two years of research and development. Key challenges included transporting and melting variable lunar soil compositions and achieving efficient solar energy transmission. To address this, the team created multiple types of simulated lunar soil for extensive trials.\r\n\r\nWhile the technology is a milestone, Yang"
  }
]