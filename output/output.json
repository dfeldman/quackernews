[
  {
    "title": "555 Timer Circuits (555-timer-circuits.com)",
    "points": 75,
    "submitter": "okl",
    "submit_time": "2024-10-17T18:30:03.000000Z",
    "num_comments": 30,
    "comments_url": "https://news.ycombinator.com/item?id=41872314",
    "comments": [
      "In some respects, it's a testament to how much the world of electronics has changed over the past ~25 years. It used to be that 555 was this Swiss-army-knife IC that you had to learn about. Multiple people published entire books about it!Today, it's essentially obsolete. You're quite unlikely to find it in any competently-done commercial designs. Every analog trick you can do with it can be done more cheaply, more reliably, with better power efficiency, and with fewer external components using a modern MCU.It's not that analog is dead, but it's solving different problems now. Including how to keep ultra-high-speed digital signals usable within the footprint of a PCB - which wasn't that much of a consideration in the golden days of the 555.\n \nreply",
      "There is still at least one niche for it: very simple circuits which requires >5v. Using 555 lets you skip the regulator and drivers.But even there, it's high Iq limits its applicability.\n \nreply",
      "We sell kits with plenty of 555 timers (including some listed here)It\u2019s a shame that Arduino has effectively truncated kids learning with a full MCU as the \u201cbuilding block\u201d of their learningI see it also bite them in the arse with wasteful solutions. Often a BJT or power fet is all they need (say for a basic relay trigger). But if they aren\u2019t presented with a shiny arduino compatible module explicitly designed for what they want, they get nervousAbout half the kids I see make the intellectual jump, half end up not coming backI do wish kids were taught basic soldering, it would make the learning process a lot less worrisomeThe 555 and LM741 are still supreme learning tools. They are even simple enough to breadboard out with BJTs and analogue components. I\u2019ve only seen a few extremely hardcore guys bother to conceptualise under the hood that deeply\n \nreply",
      "> It\u2019s a shame that Arduino has effectively truncated kids learning with a full MCU as the \u201cbuilding block\u201d of their learningWhy? I think the vast majority of hobbyists used the 555 as a \"black-box\" chip. They now have a more intuitive, cheaper, and more power-efficient way of doing the same thing.Pre-Arduino, learning electronics wasn't more profound. It was just less accessible. Nowadays, you have the same number of determined and talented hobbyists who eventually master some of the more arcane topics. You also have more people who learn just enough to get their art project done, and it's easier than it used to be... but why is that a bad thing?There's a temptation to demand that others do things the hard way just because we had to. But is it healthy? I don't lament the demise of the 555 any more than I lament that the youth no longer knows how to put shoes on a horse.\n \nreply",
      "You raise an interesting issue to which I offer just ONE counterpoint.  That is, a 555 circuit often requires external circuits that involve useful theory beyond basic circuits.I\u2019m thinking RC timing and voltage dividers.  These have practical application.  Would it ever get used elsewhere?  That is where my thinking merges to yours.Forty years from when I started that journey, not sure it can\u2019t be learned from a wiki.\n \nreply",
      "> There's a temptation to demand that others do things the hard way just because we had to. But is it healthy? I don't lament the demise of the 555 any more than I lament that the youth no longer knows how to put shoes on a horse.I agree with both you and the GP. Arduinos tend to make goofing around with electronics more accessible to more people. At the same time a lot of projects could be built very simply with just a couple timer chips. It's unfortunate people reach for a relatively complex solution (Arduino etc) to what's ultimately a simple problem. They would benefit a great deal from just knowing a blinking light can be made very simply with a simple circuit.\n \nreply",
      "I liken it to people who reach for kubernets and docker and microservices and cloud infrastructure when a simple LAMP stack running on a single box will do. And people who reach for a hosted javascript app when a native one that doesn\u2019t require internet will do. They\u2019re not wrong, just unnecessarily complicating things because they learned how to do it the complicated way.\n \nreply",
      "I grew up with Arduinos, never used 555 because it draws too much current for what it is doing. I get how it once was a popular thing, but if I need a simple delay circuit or simple logic that needs to  e precise I do it discretev if ir needs to be more complex there is any number of MCUs.I was 100% self thought and teach electronics in art university now. And I have to say I can't really confirm your suspicions about \"the kids\", sure many stay at the module level (totally okay, they study arts not electronics), but many don't. I had a student who over the course of 2 years built a brain wave reading circuit with a specialized instrumentation amplifier IC, to filter out grid EMF she built an opamp based notch filter and that woman had nearly no help from me and no prior education in the field. That analog stuff isn't going away anytime soon.\n \nreply",
      "Why Arduinos in particular? We're in an era where you can choose any MCU (ARM, Espressif, RiscV e tc), pick a language you like within limits (C, C++, Rust, Python (sort of)), and make it happen. Open KiCad, design a PCB, and have it arrive from Shenzhen in 10 days. Or, order a dev board, and attach additional circuits to it. (STM32 Discovery, nordic dev kit, one of the cheap Chinese ones \"pill\" etc.) Design whatever circuits you want. Use passives, or string together ICs.555 is obsolete tech. I see this as equivalent to suggesting someone buy an Apple II instead of a modern PC.\n \nreply",
      "This tension between two paths, the microcontroller path vs the analog path, there is a bit of an analog to this in the game Factorio.  You can use combinators to build sophisticated circuits (the microcontroller path), but there's also a lot you can do with just a few red wires (the analog path).\n \nreply"
    ],
    "link": "https://www.555-timer-circuits.com/",
    "first_paragraph": ""
  },
  {
    "title": "Language is not essential for the cognitive processes that underlie thought (scientificamerican.com)",
    "points": 167,
    "submitter": "orcul",
    "submit_time": "2024-10-17T12:10:30.000000Z",
    "num_comments": 151,
    "comments_url": "https://news.ycombinator.com/item?id=41868884",
    "comments": [
      "All: please don't comment based on your first response to an inevitably shallow title. That leads to generic discussion, which we're trying to avoid on HN. Specific discussion of what's new or different in an article is a much better basis for interesting conversation.Since we all have language and opinions about it, the risk of genericness is high with a title like this. It's like this with threads about other universal topics too, such as food or health.",
      "This is an important result.The actual paper [1] says that functional MRI (which is measuring which parts of the brain are active by sensing blood flow) indicates that different brain hardware is used for non-language and language functions.\nThis has been suspected for years, but now there's an experimental result.What this tells us for AI is that we need something else besides LLMs. It's not clear what that something else is. But, as the paper mentions, the low-end mammals and the corvids lack language but have some substantial problem-solving capability. That's seen down at squirrel and crow size, where the brains are tiny. So if someone figures out to do this, it will probably take less hardware than an LLM.This is the next big piece we need for AI. No idea how to do this, but it's the right question to work on.[1] https://www.nature.com/articles/s41586-024-07522-w.epdf?shar...\n \nreply",
      "When you look at how humans play chess they employ several different cognitive strategies.  Memorization, calculation, strategic thinking, heuristics, and learned experience.When the first chess engines came out they only employed one of these: calculation.  It wasn't until relatively recently that we had computer programs that could perform all of them.  But it turns out that if you scale that up with enough compute you can achieve superhuman results with calculation alone.It's not clear to me that LLMs sufficiently scaled won't achieve superhuman performance on general cognitive tasks even if there are things humans do which they can't.The other thing I'd point out is that all language is essentially synthetic training data.  Humans invented language as a way to transfer their internal thought processes to other humans.  It makes sense that the process of thinking and the process of translating those thoughts into and out of language would be distinct.\n \nreply",
      "> What this tells us for AI is that we need something else besides LLMsNot to over-hype LLMs, but I don't see why this results says this. AI doesn't need to do things the same way as evolved intelligence has.\n \nreply",
      "One reason might that LLMs are successful because of the architecture, but also, just as importantly because they can be trained over a volume and diversity of human thought that\u2019s encapsulated in language (that is on the internet). Where are we going to find the equivalent data set that will train this other kind of thinking?Open AI O1 seems to be trained on mostly synthetic data, but it makes intuitive sense that LLMs work so well because we had the data lying around already.\n \nreply",
      "I think the data is way more important for the success of LLMs than the architecture although I do think there's something important in the GPT architecture in particular. See this talk for why: [1]Warning, watch out for waving hands: The way I see it is that cognition involves forming an abstract representation of the world and then reasoning about that representation. It seems obvious that non-human animals do this without language. So it seems likely that humans do too and then language is layered on top as a turbo boost. However, it also seems plausible that you could build an abstract representation of the world through studying a vast amount of human language and that'll be a good approximation of the real-world too and furthermore it seems possible that reasoning about that abstract representation can take place in the depths of the layers of a large transformer. So it's not clear to me that we're limited by the data we have or necessarily need a different type of data to build a general AI although that'll likely help build a better world model. It's also not clear that an LLM is incapable of the type of reasoning that animals apply to their abstract world representations.[1] https://youtu.be/yBL7J0kgldU?si=38Jjw_dgxCxhiu7R\n \nreply",
      "Videos are a rich set of non verbal data that could be used to train AIs.Feed it all the video ever recorded, hook it up to web cams, telescopes, etc. This says a lot about how the universe works, without using a single word.\n \nreply",
      "It doesn't need to, but evolved intelligence is the only intelligence we know of.Similar reason we look for markers of Earth-based life on alien planets: it's the only example we've got of it existing.\n \nreply",
      "Title doesn't mean bullet trains can't fly, but do imply what call flights could be more than moving fast, and effects of wings might be worth discussing.\n \nreply",
      "Ok, but at least it suggests that this other thing might be more efficient in some ways.\n \nreply"
    ],
    "link": "https://www.scientificamerican.com/article/you-dont-need-words-to-think/",
    "first_paragraph": "October 17, 20249 min readYou Don\u2019t Need Words to ThinkBrain studies show that language is not essential for the cognitive processes that underlie thoughtBy Gary StixComstock/Getty ImagesScholars have long contemplated the connection between language and thought\u2014and to what degree the two are intertwined\u2014by asking whether language is somehow an essential prerequisite for thinking.British philosopher and mathematician Bertrand Russell answered the question with a flat yes, asserting that language\u2019s very purpose is \u201cto make possible thoughts which could not exist without it.\u201d But even a cursory glance around the natural world suggests why Russell may be wrong: No words are needed for animals to perform all sorts of problem-solving challenges that demonstrate high-level cognition. Chimps can outplay humans in a strategy game, and New Caledonian Crows make their own tools that enable them to capture prey.Still, humans perform cognitive tasks at a level of sophistication not seen in chimps\u2014"
  },
  {
    "title": "Accountability Sinks (aworkinglibrary.com)",
    "points": 10,
    "submitter": "l0b0",
    "submit_time": "2024-10-19T23:39:43.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41891694",
    "comments": [
      "Organizations exist to remove moral culpabilityJudge, Jury and Executioner\nFiring Squad\nLimited Liability OrganisationHumans like to sleep at night. An emergent property of our rule of law is that it exists in a way to reduce the moral culpability of any individual. A police man, a jury member, a judge, a inspector, an executioner, a jailer, they all exist in very neat boxes. These boxes allow them to sleep at night. Surely the Judge has few qualms going by the recommended mandatory minimum, after the jury, who is assured the judge will provide a fair sentence, and the executioner doubly so, with double the potential moral hazard, is certain at least two other parties have done their due diligence.these systems prevent a single actor from acting. More like they allow a series of hand offs, so by the time the jailer is slamming the doors shut, they are bereft of any investment in the morality of the outcomeThe firing squad, with seven guns, all line up, with just one loaded. The rest are blanks. Each man can sleep at night, regardless if the murdered man was surely deserving of deathlarge institutions, organizations and objects are scale are fully inhumaneI would rather have my jailer be my judge and my executioner be each man or woman on the jury. Isolating each of these things allows the individuals to have almost a powerless notion of 'completing our task'. As if all tasks completed would add up to a moral outcomeShould juries be formed to perform the whipping of an individual, the institutionalization in their own homes, the judge forced to starve a prisoner in his cell, i find the outcomes would be different\n \nreply",
      "Our meat is bought from the butcher, delivered to the chef so it comes not as an animal, but part of a tasty dish.If we eat meat, we should kill it ourselves.\n \nreply"
    ],
    "link": "https://aworkinglibrary.com/writing/accountability-sinks",
    "first_paragraph": "Practice the future \u2192In The Unaccountability Machine, Dan Davies argues that organizations form \u201caccountability sinks,\u201d structures that absorb or obscure the consequences of a decision such that no one can be held directly accountable for it. Here\u2019s an example: a higher up at a hospitality company decides to reduce the size of its cleaning staff, because it improves the numbers on a balance sheet somewhere. Later, you are trying to check into a room, but it\u2019s not ready and the clerk can\u2019t tell you when it will be; they can offer a voucher, but what you need is a room. There\u2019s no one to call to complain, no way to communicate back to that distant leader that they\u2019ve scotched your plans. The accountability is swallowed up into a void, lost forever.Davies proposes that:For an accountability sink to function, it has to break a link; it has to prevent the feedback of the person affected by the decision from affecting the operation of the system.Once you start looking for accountability sink"
  },
  {
    "title": "Ribbonfarm Is Retiring (ribbonfarm.com)",
    "points": 95,
    "submitter": "Arubis",
    "submit_time": "2024-10-19T19:06:34.000000Z",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=41889876",
    "comments": [
      "It seems to me that the blogosphere was not a ZIRP but rather a young Internet phenomenon. Which could exists, like usenet before it, when mere access to it was a filtering mechanism.Once you have seven billion people with virtually no access control, you can't have a public blogosphere, and groups retreat to the cozyweb.Either way, I enjoyed it while it lasted. Thanks for the Office series!https://www.ribbonfarm.com/2009/10/07/the-gervais-principle-...\n \nreply",
      "> Once you have seven billion people with virtually no access control, you can't have a public blogosphere, and groups retreat to the cozyweb.Why can\u2019t you? There\u2019s a logical leap in this statement I don\u2019t follow.\n \nreply",
      "Those seven billion people aren't very good for the most part, and include a critical mass of spectacularly awful people. It turns out that public access forums calibrated for the small and self-selected community of mostly high quality internet pioneers aren't prepared to deal with 1000000x expansion of reachable audience. The Eternal September effect has been getting stronger ever since it's first been observed.\n \nreply",
      "There's a gap between public fora and the blogosphere though.Generally speaking there are plenty of blogs that get linked in places like here. Blogs just don't have comment sections hosted on their own as much anymore.Having discussions happen in separate places is also interesting, because the HN convo and some subreddit convo will be different, for example.There's a lot more mainstraeam stuff but I think niche communities still exist. Glibly, we're not a part of most of them on account of having gotten older. Or we are a part of some, but there's plenty we're not seeing.\n \nreply",
      ">It turns out that public access forums calibrated for the small and self-selected community of mostly high quality internet pioneers aren't prepared to deal with 1000000x expansion of reachable audience. \"Checklist for new theories purporting to prove that the social web is presently unworkable:\"...26. The predicted conflicts still wouldn't be as bad as Usenet flamewars.27. Your theory proves that Hackernews does not exist. <---28. Audiences afraid of engaging with an unfamiliar interfaces weren't making websites in 1998 either....\n \nreply",
      "This forum has been decreasing in quality since its inception, currently hovering at not-quite-reddit and that's with an organic audience of tech-adjacent posters. It would turn into a smoking hole in the ground if it somehow caught worldwide attention.You're a fish swimming in fragile water you fail to appreciate.\n \nreply",
      "As the guidelines [0] state:> Please don't post comments saying that HN is turning into Reddit. It's a semi-noob illusion, as old as the hills.See the link for some examples, but I can also recommend looking at some old front pages from over the years and poking through the discussions. Unscientifically, it seems that quality is pretty similar to me.[0]: https://news.ycombinator.com/newsguidelines.html\n \nreply",
      "Context.That's a rule for jumping into a conversation and making petty putdowns.It doesn't mean \"if someone says HN has never been better, you're not allowed to disagree\".\n \nreply",
      "That doesn\u2019t seem to be the claim, just that the average quality is trending downwards just like reddit.It\u2019ll probably never converge because reddit is getting worse at an even faster rate.\n \nreply",
      "My HN account is older than either of yours, so I don\u2019t think I can be dismissed as a \u201csemi-noob\u201d. rogers12 is mostly correct, sad to say. dang has done a good job slowing the decline (and I actually noticed an uptick in quality when he first took over) but HN is past its peak.\n \nreply"
    ],
    "link": "https://www.ribbonfarm.com/2024/10/10/ribbonfarm-is-retiring/",
    "first_paragraph": ""
  },
  {
    "title": "QUIC Is Not Quick Enough over Fast Internet (arxiv.org)",
    "points": 139,
    "submitter": "carlos-menezes",
    "submit_time": "2024-10-19T21:04:52.000000Z",
    "num_comments": 126,
    "comments_url": "https://news.ycombinator.com/item?id=41890784",
    "comments": [
      "At Google, I worked on a pure JS Speedtest. At the time, Ookla was still Flash-based so wouldn't work on Chromebooks. That was a problem for installers to verify an installation. I learned a lot about how TCP (I realize QUIC is UDP) responds to various factors.I look at this article and consider the result pretty much as expected. Why? Because it pushes the flow control out of the kernel (and possibly network adapters) into userspace. TCP has flow-control and sequencing. QUICK makes you manage that yourself (sort of).Now there can be good reasons to do that. TCP congestion control is famously out-of-date with modern connection speeds, leading to newer algorithms like BRR [1] but it comes at a cost.But here's my biggest takeaway from all that and it's something so rarely accounted for in network testing, testing Web applications and so on: latency.Anyone who lives in Asia or Australia should relate to this. 100ms RTT latency can be devastating. It can take something that is completely responsive to utterly unusable. It slows down the bandwidth a connection can support (because of the windows) and make it less responsive to errors and congestion control efforts (both up and down).I would strongly urge anyone testing a network or Web application to run tests where they randomly add 100ms to the latency [2].My point in bringing this up is that the overhead of QUIC may not practically matter because your effective bandwidth over a single TCP connection (or QUICK stream) may be MUCH lower than your actual raw bandwidth. Put another way, 45% extra data may still be a win because managing your own congestion control might give you higher effective speed over between two parties.[1]: https://atoonk.medium.com/tcp-bbr-exploring-tcp-congestion-c...[2]: https://bencane.com/simulating-network-latency-for-testing-i...\n \nreply",
      "I did a bunch of real world testing of my file transfer app[1]. Went in with the expectation that Quic would be amazing. Came out frustrated for many reasons and switched back to TCP. It\u2019s obvious in hindsight, but with TCP you say \u201chey kernel send this giant buffer please\u201d whereas UDP is packet switched! So even pushing zeroes has a massive CPU cost on most OSs and consumer hardware, from all the mode switches. Yes, there are ways around it but no they\u2019re not easy nor ready in my experience. Plus it limits your choice of languages/libraries/platforms.(Fun bonus story: I noticed significant drops in throughput when using battery on a MacBook. Something to do with the efficiency cores I assume.)Secondly, quic does congestion control poorly (I was using quic-go so mileage may vary). No tuning really helped, and TCP streams would take more bandwidth if both were present.Third, the APIs are weird man. So, quic itself has multiple streams, which makes it non-drop in replacement with TCP. However, the idea is to have HTTP/3 be drop-in replaceable at a higher level (which I can\u2019t speak to because I didn\u2019t do). But worth keeping in mind if you\u2019re working on the stream level.In conclusion I came out pretty much defeated but also with a newfound respect for all the optimizations and resilience of our old friend tcp. It\u2019s really an amazing piece of tech. And it\u2019s just there, for free, always provided by the OS. Even some of the main issues with tcp are not design faults but conservative/legacy defaults (buffer limits on Linux, Nagle, etc). I really just wish we could improve it instead of reinventing the wheel..[1]: https://payload.app/\n \nreply",
      "> Because it pushes the flow control out of the kernel (and possibly network adapters) into userspaceThat\u2019s not an inherent property of the QUIC protocol, it is just an implementation decision - one that was very necessary for QUIC to get off the ground, but now it exists, maybe it should be revisited? There is no technical obstacle to implementing QUIC in the kernel, and if the performance benefits are significant, almost surely someone is going to do it sooner or later.\n \nreply",
      "For Linux that's true. But Microsoft never added SCTP to Windows; not being beholden to Microsoft and older OS must have been part of the calculus?\n \nreply",
      "> But Microsoft never added SCTP to WindowsWindows already has an in-kernel QUIC implementation (msquic.sys), used for SMB/CIFS and in-kernel HTTP. I don\u2019t think it is accessible from user-space - I believe user-space code uses a separate copy of the same QUIC stack that runs in user-space (msquic.dll), but there is no reason in-principle why Microsoft couldn\u2019t expose the kernel-mode implementation to user space\n \nreply",
      "Is this something you could use ebpf for?\n \nreply",
      "The Network tab in the Chrome console allows you to degrade your connection. There are presets for Slow/Fast 4G, 3G, or you can make a custom present where you can specify download and upload speeds, latency in ms, a packet loss percent, a packet queue length and can enable packet reordering.\n \nreply",
      "For reasonably long downloads (so it has a chance to calibrate), why don't congestion algorithms increase the number of inflight packets to a high enough number that bandwidth is fully utilized even over high latency connections?It seems like it should never be the case that two parallel downloads will preform better than a single one to the same host.\n \nreply",
      "There are two places a packet can be \u2018in-flight\u2019. One is light travelling down cables (or the electrical equivalent) or in memory being processed by some hardware like a switch, and the other is sat in a buffer in some networking appliance because the downstream connection is busy (eg sending packets that are further up the queue, at a slower rate than they arrive). If you just increase bandwidth it is easy to get lots of in-flight packets in the second state which increases latency (admittedly that doesn\u2019t matter so much for long downloads) and the chance of packet loss from overly full buffers.CUBIC tries to increase bandwidth until it hits packet loss, then cuts bandwidth (to drain buffers a bit) and ramps up and hangs around close to the rate that led to loss, before it tries sending at a higher rate and filling up buffers again. Cubic is very sensitive to packet loss, which makes things particularly difficult on very high bandwidth links with moderate latency as you need very low rates of (non-congestion-related) loss to get that bandwidth.BBR tries to do the thing you describe while also modelling buffers and trying to keep them empty. It goes through a cycle of sending at the estimated bandwidth, sending at a lower rate to see if buffers got full, and sending at a higher rate to see if that\u2019s possible, and the second step can be somewhat harmful if you don\u2019t need the advantages of BBR.I think the main thing that tends to prevent the thing you talk about is flow control rather than congestion control. In particular, the sender needs a sufficiently large send buffer to store all unacked data (which can be a lot due to various kinds of ack-delaying) in case it needs to resend packets, and if you need to resend some then your send buffer would need to be twice as large to keep going. On the receive size, you need big enough buffers to be able to fill up those buffers from the network while waiting for an earlier packet to be retransmitted.On a high-latency fast connection, those buffers need to be big to get full bandwidth, and that requires (a) growing a lot, which can take a lot of round-trips, and (b) being allowed by the operating system to grow big enough.\n \nreply",
      "Larger windows can reduce the maximum number of simultaneous connections on the sender side.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2310.09423",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Why do random forests work? They are self-regularizing adaptive smoothers (arxiv.org)",
    "points": 132,
    "submitter": "sebg",
    "submit_time": "2024-10-17T21:24:29.000000Z",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41873968",
    "comments": [
      "Nice article, although I find it's a bit overly complex if your are not familiar with ML and mathematics at the same time.I will leave here a geometrical intuition of why they work in case it can help someone:To simplify things, I will talk about regression, and say we want to predict some value y, that we know depends on x, and we have some noisy measurements of y.y = f(x)\ny_observed = f(x) + noiseIf you want some mental image, think about f(x)=sin(x).Now, a (over fitted) regression tree in this case is just a step function where the value at x is y_observed. If there is no noise, we now that by doing more measurements, we can approximate y with as much precision as we want. But if there is noise, the regression tree will over fit the noisy values, creating some artificial spikes.If you want to avoid this over fitting, you sample a lot of times the values of X, and for each sample you build a regression tree, and then average them. When you average them, every tree will contain its own particular artificial spikes, and if they are noise, they won't appear in the majority of the other trees. So when you average them, the spikes will attenuate, creating the smoother behaviour that the article talks about.I hope it helps!\n \nreply",
      "Thanks that helps. The way I think about your example is it\u2019s like (not the same obv) taking a bunch of moving averages of different durations at different starting points, and throwing those into your regression model along with the actual data\n \nreply",
      "Good to see more research exploring the connection between trees, ensembles, and smoothing. Way back in Trevor Hastie's ESL book there's a section on how gradient boosting using \"stumps\" (trees with only one split) is equivalent to an additive spline model (GAM, technically) with a step function as a spline basis and adaptive knot placement.I've always thought there should be a deep connection between ReLU neural nets and regularized adaptive smoothers as well, since the ReLU function is itself a spline basis (a so-called truncated linear spline) and happens to span the same functional basis as B-splines of the same degree.\n \nreply",
      "I like this article. Randomness in system design is one of the most practical ways to handle the messiness of real world inputs, and I think random forests nail this by using randomness to produce useful outputs to various inputs without overfitting and adapt to the unexpected. Yeah, you can always engineer a system that explicitly handles every possible situation, but the important question is \u201chow long/costly will that process be?\u201d. Deterministic  systems aren\u2019t good on that front, and when edge cases hit, sometimes those rigid models crack. Controlled randomness (load balancing, feature selection, etc.) makes systems more flexible and resilient. You don\u2019t get stuck in the same predictable ruts, and that\u2019s exactly why randomness works where pure determinism fails\n \nreply",
      "The same team wrote another interesting paper arguing that there's no \"double descent\" in linear regression, trees, and boosting, despite what many argued before (in this paper they don't tackle deep learning double descent, but remark that the case may be similar regarding the existence of different complexity measures being conflated).\n \nreply",
      "Random forests are incredible cool algorithms.The idea that you can take hundreds of bad models that over fit (the individual decision trees), add even more randomness by randomly picking training data and features*, and averaging them together - it's frankly amazing that this leads to consistently OK models. Often not the best but rarely the worst. There's a reason they're such a common baseline to compare against.*Unless you're using Sklearn, whose implementation of RandomForestRegressor is not a random forest. It's actually bagged trees because they don't randomly select features. Why they kept the misleading classname is beyond me.\n \nreply",
      "With a relatively small variant to make it gradient boosted trees it\u2019s pretty much as good as it gets for tabular data these days\n \nreply",
      "Here's some context and a partial summary (youoy also has a nice summary) --Context:A random forest is an ML model that can be trained to predict an output value based on a list of input features: eg, predicting a house's value based on square footage, location, etc. This paper focuses on regression models, meaning the output value is a real number (or a vector thereof). Classical ML theory suggests that models with many learned parameters are more likely to overfit the training data, meaning that when you predict an output for a test (non-training) input, the predicted value is less likely to be correct because the model is not generalizing well (it does well on training data, but not on test data - aka, it has memorized, but not understood).Historically, a surprise is that random forests can have many parameters yet don't overfit. This paper explores the surprise.What the paper says:The perspective of the paper is to see random forests (and related models) as _smoothers_, which is a kind of model that essentially memorizes the training data and then makes predictions by combining training output values that are relevant to the prediction-time (new) input values. For example, k-nearest neighbors is a simple kind of smoother. A single decision tree counts as a smoother because each final/leaf node in the tree predicts a value based on combining training outputs that could possibly reach that node. The same can be said for forests.So the authors see a random forest as a way to use a subset of training data and a subset of (or set of weights on) training features, to provide an averaged output. While a single decision tree can overfit (become \"spikey\") because some leaf nodes can be based on single training examples, a forest gives a smoother prediction function since it is averaging across many trees, and often other trees won't be spikey for the same input (their leaf node may be based on many training points, not a single one).Finally, the authors refer to random forests as _adaptive smoothers_ to point out that random forests become even better at smoothing in locations in the input space that either have high variation (intuitively, that have a higher slope), or that are far from the training data. The word \"adaptive\" indicates that the predicted function changes behavior based on the nature of the data \u2014 eg, with k-NN, an adaptive version might increase the value of k at some places in the input space.The way random forests act adaptively is that (a) the prediction function is naturally more dense (can change value more quickly) in areas of high variability because those locations will have more leaf nodes, and (b) the prediction function is typically a combination of a wider variety of possible values when the input is far from the training data because in that case the trees are likely to provide a variety of output values. These are both ways to avoid overfitting to training data and to generalize better to new inputs.Disclaimer: I did not carefully read the paper; this is my quick understanding.\n \nreply",
      "I think this is specifically coming to terms with an insight that's taught to statisticians about a bias-variance tradeoff.From my understanding, in a statistical setting, low variability in bias leads to high variability in variance whereas low variability in variance leads to high variability in bias. The example I saw was with K-means, where K = N leads to high variance (the predicted cluster is highly variable) but low bias (take an input point, you get that exact input point back), vs. K=1 low variance (there's only one cluster) but bad bias (input point is far away from the cluster center/representative point).I'm not sure I've characterized it well but there's a Twitter post from Alicia Curth that explains it [0] as well as a paper that goes into it [1].[0] https://x.com/AliciaCurth/status/1841817856142348529[1] https://arxiv.org/abs/2409.18842\n \nreply",
      "Quantized random sampling regression\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2402.01502",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Booting Sun Sparc Servers (sidneys1.com)",
    "points": 9,
    "submitter": "rbanffy",
    "submit_time": "2024-10-19T23:31:36.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://sidneys1.com/retrocomputing/2024/10/04/booting-sun-sparc-servers.html",
    "first_paragraph": "\nOct 4, 2024\r\n\t\t\t\u00a0\u2022\u00a0retrocomputing\u00a0\u2022\u00a0sun-sparcIn early 2022 I got several Sun SPARC servers for free off of a FreeCycle ad: I was recently\ncalled out for not providing any sort of update on those devices\u2026 so here we go!Sun SPARC machines store some of their BIOS configuration in a chip called an\nNVRAM, a special type of writeable random access memory that does not\nclear its contents when the machine powers off. This is usually a small RAM chip with its own internal battery that\nrecharges when the machine is running. Unfortunately this means that when the devices is powered off for extremely long\nperiods the NVRAM loses its values. Even more unfortunately, over time the NVRAM battery degrades to the point where it\ncan no longer be recharged, and every power cycle results in a compete configuration wipe.Such is the case with my SPARC machines; upon powering on we\u2019re greeted with a sad message.\nIncorrect configuration checksum; Ethernet address ff:ff:ff:ff:ff:ff, Host ID: ffffffff. The ID"
  },
  {
    "title": "Smurf: Beyond the Test Pyramid (googleblog.com)",
    "points": 37,
    "submitter": "BerislavLopac",
    "submit_time": "2024-10-19T20:22:22.000000Z",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=41890486",
    "comments": [
      "This is interesting, but I see a few issues with it:- Maintainability is difficult to quantify, and often subjective. It's also easy to fall into a trap of overoptimizing or DRYing test code in the pursuit of improving maintainability, and actually end up doing the opposite. Striking a balance is important in this case, which takes many years of experience to get a feel for.- I interpret the chart to mean that unit tests have high maintainability, i.e. it's a good thing, when that is often not the case. If anything, unit tests are the most brittle and susceptible to low-level changes. This is good since they're your first safety net, but it also means that you spend a lot of time changing them. Considering you should have many unit tests, a lot of maintenance work is spent on them.I see the reverse for E2E tests as well. They're easier to maintain, since typically the high-level interfaces don't change as often, and you have fewer of them.But most importantly, I don't see how these definitions help me write better tests, or choose what to focus on. We all know that using fewer resources is better, but that will depend on what you're testing. Nobody likes flaky tests, but telling me that unit tests are more reliable than integration tests won't help me write better code.What I would like to see instead are concrete suggestions on how to improve each of these categories, regardless of the test type. For example, not relying on time or sleeping in tests is always good to minimize flakiness. Similarly for relying on system resources like the disk or network; that should be done almost exclusively by E2E and integration tests, and avoided (mocked) in unit tests. There should also be more discussion about what it takes to make code testable to begin with. TDD helps with this, but you don't need to practice it to the letter if you keep some design principles in mind while you're writing code that will make it easier to test later.I've seen many attempts at displacing the traditional test pyramid over the years, but so far it's been the most effective guiding tool in all projects I've worked on. The struggle that most projects experience with tests stems primarily from not following its basic principles.\n \nreply",
      "> There should also be more discussion about what it takes to make code testable to begin with.IME, testable pretty much just means referentially transparent.\n \nreply",
      "> I don't see how these definitions help me write better tests> What I would like to see instead \u2026If you hire me, I can address those needs.\n \nreply",
      "> If anything, unit tests are the most brittle and susceptible to low-level changes.I don't find this to be the case if the unit tests are precise (which they should be).That is, if you are writing non-flaky unit tests which do all the \"right\" unit-testy things (using fakes/dependency injecting well and so isolating and testing only the unit under test), you should end up with a set of tests that- Fails only when you change the file/component the test relates to- Isn't flaky (can be run ~10000 times without failing)- Is quick (you can do the 10000 run loop above approximately interactively, in a few minutes, by running in parallel saturating a beefy workstation)This compares to integration/e2e tests which inherently break due to other systems and unrelated assumptions changing (sometimes legitimate, sometimes not), and can have rates of flakyness of 1-10% due to the inherent nature of \"real\" systems failing to start occasionally and the inherently longer test-debug cycle that makes fixing issues more painful (root causing bug that causes a test to fail 1% of the time is much easier when the test takes .3 CPU-seconds than when it takes 30 or 300 CPU-seconds).Very few tests I see are actually unit tests in the above sense, many people only write integration tests because the code under test is structured in inherently un- or difficult- to test ways.\n \nreply",
      "This model (\"mnemonic\") feels like a good tool to reason about your testing strategy. I ran across the \"testing trophy\" in the past, which really changed my thinking already, having been indoctrinated with the testing pyramid for such a long time before that. I wanted to share my favorite links about the testing trophy, for those interested:https://tanzu.vmware.com/content/videos/tanzu-tv-springoneto...https://kentcdodds.com/blog/the-testing-trophy-and-testing-c...\n \nreply",
      "This is obvious, as anoter commenter said, but this is nonetheless useful.You can use it to show graduates. Why have them waste time relearning the same mistakes. You probably need a longer blog post with examples.It is useful as a check list, so you can pause when working earlier in the lifecycle to consider these things.I think there is power in explaining out the obvious. Sometimes experienced people miss it!The diagram can be condensed by saying SMUR + F = 1. IN other words you can slide towards Fidelity, or towards \"Nice Testibility\" which covers the SMUR properties.However it is more complex!Let's say you have a unit test for a parser within your code. For a parser a unit test might have pretty much the same fidelity as an intergation test (running the parse from a unit test, rather than say doing a compilation from something like Replit online). But the unit test has all the other properties be the same in this instance.Another point is you are not testing anything if you have zero e2e tests. You get a lot (a 99-1 not 80-20) by having some e2e tests, then soon the other type of tests almost always make sense. In addition e2e tests if well written and considers can also be run in production as synthetics.\n \nreply",
      "What's useful here?  There's nothing actionable, no way to quantify if you're doing \"SMURF\" correctly.  All the article describes is semi-obvious desirable qualities of a test suite.\n \nreply",
      "You're not \"doing SMURF\". It's not an approach or a system. It's just a specific vocabulary to talk about testing approaches better. They almost spell it out: \"The SMURF mnemonic is an easy way to remember the tradeoffs to consider when balancing your test suite\".It's up to your team (and really always has been) to decide what works best for that project. You get to talk about tradeoffs and what's worth doing.\n \nreply",
      "> What's useful here?It is up to the reader to figure out this one.\n \nreply",
      "End-to-end tests verify high-level expectations based on the specification of the system. These high-level expectations generally stay stable over time (at least compared to the implementation details verified by lower-level tests), and therefore end-to-end tests should have the best maintainability score.\n \nreply"
    ],
    "link": "https://testing.googleblog.com/2024/10/smurf-beyond-test-pyramid.html",
    "first_paragraph": "The test pyramid is the canonical heuristic for guiding test suite evolution. It conveys a simple message - prefer more unit tests than integration tests, and prefer more integration tests than end-to-end tests. While useful, the test pyramid lacks the details you need as your test suite grows and you face challenging trade-offs. To scale your test suite, go beyond the test pyramid.The SMURF mnemonic is an easy way to remember the tradeoffs to consider when balancing your test suite:Speed: Unit tests are faster than other test types and can be run more often\u2014you\u2019ll catch problems sooner.Maintainability: The aggregated cost of debugging and maintaining tests (of all types) adds up quickly. A larger system under test has more code, and thus greater exposure to dependency churn and requirement drift which, in turn, creates more maintenance work.\u00a0\u00a0Utilization: Tests that use fewer resources (memory, disk, CPU) cost less to run. A good test suite optimizes resource utilization so that it do"
  },
  {
    "title": "Data Version Control (dvc.org)",
    "points": 99,
    "submitter": "shcheklein",
    "submit_time": "2024-10-19T16:56:15.000000Z",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41888937",
    "comments": [
      "I've used DVC for most of my projects for the past five years. The good things is that it works a lot like git. If your scientists understand branches, commits and diffs, they should be able to understand DVC. The bad thing is that it works like git. Scientists often do not, in fact, understand or use  branches, commits and diffs. The best thing is that it essentially forces you to follow Ten Simple Rules for Reproducible Computational Research [1]. Reproducibility has been a huge challenge on teams I've worked on.[1] https://journals.plos.org/ploscompbiol/article?id=10.1371/jo...\n \nreply",
      "hi there! Maintainer and author here. Excited to see DVC on the front page!Happy to answer any questions about DVC and our sister project DataChain https://github.com/iterative/datachain that does data versioning with a bit different assumptions: no file copy and built-in data transformations.\n \nreply",
      "if the data files are all just text files, what are the differences between DVC and using plain git?\n \nreply",
      "DVC does a lot more than git.It essentially makes sure that your results can reproducibly be generated from your original data. If any script or data file is changed, the parts of your pipeline that depend on it, possibly recursively, get re-run and the relevant results  get updated automatically.There's no chance of e.g. changing the structure of your original dataset slightly, forgetting to regenerate one of the intermediate models by accident, not noticing that the script to regenerate it doesn't work any more due to the new dataset structure, and then getting reminded a year later when moving to a new computer and trying to regen everything from scratch.It's a lot like Unix make, but with the ability to keep track of different git branches and the data / intermediates they need, which saves you from needing to regen everything every time you make a new checkout, lets you easily exchange large datasets with teammates etc.In theory, you could store everything in git, but then every time you made a small change to your scripts that e.g. changed the way some model works and slightly adjusted a score for each of ten million rows, your diff would be 10m LOC, and all versions of that dataset would be stored in your repo, forever, making it unbelievably large.\n \nreply",
      "So where do the adjusted 10M rows live instead? S3?\n \nreply",
      "In this cases, you need DVC if:1. File are too large for Git and Git LFS.2. You prefer using S3/GCS/Azure as a storage.3. You need to track transformations/piplines on the file - clean up text file, train mode, etc.Otherwise, vanilla Git may be sufficient.\n \nreply",
      "What are the benefits of DVC over Apache Iceberg? If anyone used both, I'd be curious about your take. Thanks!\n \nreply",
      "I don't see any real benefits, as it feels like using the tool you already know even though it's not quite right. Iceberg is maybe geared towards slower changing models than this approach?\n \nreply",
      "username checks out\n \nreply",
      "It's not super clear to me how this interacts with data.  If I have am using ADLS to store delta tables, and I cannot pull prod to my local can I still use this? Is there a point if I can just look at delta log to switch between past versions?\n \nreply"
    ],
    "link": "https://dvc.org/",
    "first_paragraph": ""
  },
  {
    "title": "Eliza in SNOBOL4 (acm.org)",
    "points": 57,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-19T17:44:29.000000Z",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41889284",
    "comments": [
      "Memories from when the majority of my programming information/influences (I was bbs/modem-less) in the early 90s came from this CD-ROM disc that I had purchased. It was from: https://en.wikipedia.org/wiki/SimtelThe CD-ROM had this whole SNOBOL directory iirc. This CD-ROM was my entire world for like two years (until I got Internet access in 1995). I miss having oodles of time with zero pressure to do something that pays the bills.It was like having this gigantic curated dump of collected, sometimes quite old information from a connected world I had no access to. It felt so weird. Like discovering ancient alien civilizations, with no information on how to decipher it all.I think so many of us were so starved for information back then.\n \nreply",
      "One really awesome thing.. a lot (most?) of that stuff is still available online today!https://discmaster.textfiles.com/browse/10852/Simtel20_Sept9...I was always partial to the CMU AI archive back in the day, and that stuff is still out there too:https://www.cs.cmu.edu/afs/cs/project/ai-repository/ai/\n \nreply",
      "Cool :)  Directory MSDOS/SNOBOL4/\n  Filename   Type Length   Date   Description\n  ==============================================\n  AISNOBOL.ARC  B  286049  871217  SNOBOL language for MSDOS\n  AISNOBOL.TXT  A    5750  871217  Description of files in AISNOBOL.ARC\n  VSNBL220.ZIP  B  250971  920312  Vanilla SNOBOL4, PD vers. 2.20 of the language\n  VSNOBOL4.ARC  B  258956  871217  Vanilla SNOBOL4, PD version of the language\n  VSNOBOL4.TXT  A    5984  871217  Description of VSNOBOL4.ARC - Vanilla SNOBOL4\n \nreply",
      "Close to having a complete distro in CD's in early 2000's or 3 DVD in early mid 2000's.Debian used to ship tons of geeky lore, fun manuals, serious manuals, oddities here and there, weird languages, compilers and manuals...\n \nreply",
      "A couple of years ago I was lucky to teach a compiler class with Roberto Ierusalimschy from PUC-Rio, where we used a PEG parser for Lua called LPEG. That semester we spoke a lot about LPEG's implementation and that was very important for me to understand the original motivations for SNOBOL. I'm glad to see more examples of proper SNOBOL code in action. Thanks for the post.\n \nreply",
      "I have never looked at SNOBOL code before. I had heard of it because the arcade game TRON had a SNOBOL level (in addition to levels: FORTRAN, BASIC, etc.).I had also not seen the Eliza code before. Very fun.\n \nreply",
      "Both SNOBOL and its spiritual successor Icon did some interesting things with control flow.\n \nreply",
      "That brings me back! One of my profs had us use Unicon, an extension of Icon that he  designed.\n \nreply",
      "I was always fascinated by that whole lineage Snobol -> Icon -> Unicon.  I seem to remember one of the members (Icon?) is in \"7 languages in 7 weeks.\"  I'm sorry not to see them take off, although the recent flood of stories on Prolog (two of them!) makes me wonder if we might see the revival of Icon one of these days.(Is Rebol related, or am I just free-associating languages with interesting control structures?)\n \nreply",
      "Icon is a very cool language. Everything is a generator.\n \nreply"
    ],
    "link": "https://dl.acm.org/doi/pdf/10.1145/987452.987458",
    "first_paragraph": ""
  },
  {
    "title": "Artemis moon suit designed by Axiom Space and Prada revealed in Milan (collectspace.com)",
    "points": 34,
    "submitter": "PeterCorless",
    "submit_time": "2024-10-16T18:47:58.000000Z",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=41862398",
    "comments": [
      "I think that the SpaceX EVA suits are just a little too sleek and modern yet bland. Like default Unreal Engine spacesuit assets.Pleasantly surprised to see these spacesuits look classic yet beautiful. I guess I shouldn't be surprised that Italian fashion designers did a good job.I have no view on the technical merits of the suits or the program.\n \nreply",
      "If there's one place where it's important to look stylish, it's when you're floating alone in outer space.\n \nreply",
      "On the other hand, video of astronauts floating in space probably did more to get kids into STEM than most other things in the 20th century. The cultural appeal of space has a real impact on society.\n \nreply",
      "Yeah, there's just something that feels off with the SpaceX suits. They are probably more efficient than NASA's first iconic attempts but come on.Feels like a classic case of Muskian \"can we delete this part/aspect without impacting the mission goals?\n \nreply",
      "Lot of people here talking trash on this probably don\u2019t know the history or even current status of Prada. In short they are absolute top of the line when it comes to everything from the pattern work to the actual nuts and bolts of manufacturing this sort of thing. Any other company would very likely take more time and money to produce and inferior product.\n \nreply",
      "Where can I read more about Prada's other ventures into this sort of thing?\n \nreply",
      "Novel pattern work and top of the line quality in manufacturing? Probably your local Prada boutique would be a good start. Or prada.com barring that.\n \nreply",
      "If white makes it easier to remove dust, then why are the parts that are most likely to get covered in dust gray?Also, the backpack look a bit bulky.\n \nreply",
      "> the backpack look a bit bulky.Thankfully it's much easier to lug on the moon or in microgravity.\n \nreply",
      "> Also, the backpack look a bit bulky.Given that it's noticeably smaller than earlier spacesuits, and probably contains heavy-duty oxygen tanks, cooling and heating systems, a water supply, life-support monitoring, a honking big battery, communications systems, plus redundancies for safety... it's probably a huge accomplishment in miniaturization.\n \nreply"
    ],
    "link": "http://www.collectspace.com/news/news-101624a-axemu-lunar-spacesuit-axiom-space-prada-reveal.html",
    "first_paragraph": "    \u2014 The next U.S. astronauts to walk on the moon will do so in style.\rAxiom Space, a Houston-based spaceflight services company, and Italian luxury fashion house Prada have revealed the outer layer of the spacesuit to be worn on NASA's first Artemis mission to land humans on the lunar surface. The unveiling occurred at the International Astronautical Congress in Milan.\r\"We have broken the mold,\" said Matt Ondler, Axiom's president, in a statement issued on Wednesday (Oct. 16). \"The Axiom Space-Prada partnership has set a new foundational model for cross-industry collaboration.\"\rSince first showing off a prototype of the Axiom Extravehicular Mobility Unit, or AxEMU, in 2023, Axiom has configured the spacesuit with a dark outer layer created by Esther Marquis, the costume designer for the alternate space history series \"For All Mankind.\" The temporary black, blue and orange cover was intended to hide the garment's proprietary elements during its development.\rThe final, flight version o"
  },
  {
    "title": "Show HN: I made a site to quick identify any plant and learn how to care for it (frondly.app)",
    "points": 12,
    "submitter": "adamaskun",
    "submit_time": "2024-10-19T21:00:35.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41890762",
    "comments": [
      "I can't speak for anyone else, but the offer of a free trial made me bounce right off, despite my curiosity and the value such a product could potentially offer me. I want to know up front whether this is going to be useful to me before I sign up for anything. To that end, offering even a single no-strings-attached identification, even if the details are redacted, would go a long way towards conversion.\n \nreply",
      "Just a note, you have couple of places with different copy> 7 days free trial.> New users can enjoy a 1-day free trial of Frondly Premium\n \nreply"
    ],
    "link": "https://frondly.app/",
    "first_paragraph": "Identify any plant with a photo, get expert care advice. Your ultimate plant companion app.Identify, chat, and care for plants with our AI-powered app. It's like having a botanist and gardener in your pocket!Frondly is a plant identification app that allows you to identify plants by their leaves.@plant_lover92@green_thumb_mike@plant_lover92@green_thumb_mike@plant_lover92@green_thumb_mike@plant_lover92@green_thumb_mike@succulents_addict@urban_jungle_alex@tomato_tom@succulents_addict@urban_jungle_alex@tomato_tom@succulents_addict@urban_jungle_alex@tomato_tom@succulents_addict@urban_jungle_alex@tomato_tom7 days free trial. No fixed commitment period. Cancellation at any time.MonthlyLifetimeUnlock the full potential of plant identificationUnlimited plant scansPersonalized tips from an AI botanistCustom features on the wayPlant trackerAd-free experience* We'll remind you before your subscription renews.Dive into our latest articles and cultivate your gardening expertise with AI-powered insi"
  },
  {
    "title": "Autism's Four Core Subtypes (thetransmitter.org)",
    "points": 70,
    "submitter": "domofutu",
    "submit_time": "2024-10-19T19:19:22.000000Z",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=41889990",
    "comments": [
      "Reminds me a bit of the MBTI personality test, where they make up 4 types of question to arbitrarily split the population, so 2x2x2x2 = 16 subtypes. It's true by it's own definition. Which is fine, but are these particular arbitrary boundaries useful? Perhaps. Could the splitting lines have been just as useful in different arbitrary place. Perhaps. A lot of people who take the MBTI find they're on the boundaries flip-flopping into a few different pigeonholes depending on different times they take the test. So it's important to let people know they can be in multiple buckets (are a bit in all of them), and take a little advice from each community.For this one they split autism into 3 groups (core,social,developmental) then split core into (mild,severe), to make 4 total.\n \nreply",
      "> Troyanskaya and her colleagues investigated the variants associated with a person\u2019s collection of characteristics. They applied a statistical model to data on the traits and behaviors of 5,392 autistic people from the SPARK research cohort. By adjusting the number of groups, the team found the most significant similarities among participants when the model sorted the cohort into four autism subtypes.https://www.medrxiv.org/content/10.1101/2024.08.15.24312078v...Not my field, but the statiscal analysis seems legit.\n \nreply",
      "Have not read the article in depth yet, but I am very familiar with the Troyanskaya lab.  They are good and their articles are always worth a read.They are using a geodesic finite mixture model, which I am not familiar with, but seems to be an extension of mixture models to non Euclidean metric?Pleiotropy can be tricky though, as traits / diagnoses / observations can have causal relationships amongst themselves.  For example, a variant that impacts obesity may be statistically associated with heart attacks; but the relationship between the variant and heart attacks is not directly causal in the sense of something like a variant that alters function of an ion channel expressed in cardiac smooth muscle.\n \nreply",
      "If the data is a roughly uniform distribution across the dimension space, then yes absolutely.If, however, there is significant clustering within the dimension space, and those clusters are taken as groups, then it seems valid.I would tend to be generous to the researchers and assume a mostly discrete clustering until I see otherwise. To apply grouping like this without discrete clusters would be unprofessionally naive on their part.\n \nreply",
      "Reminding is different than being the same.For example, Big5/OCEAN/FiveFactor model uses factor analysis which has statistical reasoning behind the number of factors. In fact, the semantic meaning of the factors comes up after the analysis, not before. It's the same as clustering or GMM, the semantic meaning of the clusters is applied after the partitioning.The concept of partitioning people is the same, however, the order by which meaning is applied is opposite which makes them completely different in practice.\n \nreply",
      "descriptive vs prescriptive\n \nreply",
      "They also posit correlations with epigenetic differences. If there\u2019s distinct biological mechanisms at play, this gives some credence to splitting autism into separate conditions\n \nreply",
      "It's not true by its own definition, it's just that if you soak it in, you will actually start to see the patterns behind it among people. It's still going to be pseudoscience because there are a lot of variables, but it often works and even more often people don't know what to look at or what to put together, because you'll find really A LOT of articles on the Internet that try to run mechanics on certain types without understanding what or why. I assume that if you want to put this together more precisely, there is a lot of scope here.And lest it be said that I'm talking out of turn myself, I only became interested in this whole MBTI thing because an ENFP once told me I was an INTP after a few hours of talking about silly things. That's exactly what these tests once told me. Of course, these are still anecdotes, but we are sciency.Is it a problem that someone has catalogued autism in this way? Is it a question of lack of precision or bad direction? Am I asking the wrong questions?\n \nreply",
      "There\u2019s a better way to frame this issue:  being able to consistently label a characteristic is only useful if it can help in identifying the underlying mechanism or is helpful in choosing an effective treatment.A whole lot of mental health knowledge fits into the category of repeatably identifiable categories of dubious usefulness.Think phrenology: it is indeed possible to categorize the shape of people\u2019s head in a statistically valid way\u2026 it just has nothing to do with their mental health.\n \nreply",
      "I\u2019m sceptical of research based on a single diagnostic label - such research assumes that the boundary between that specific diagnosis, other diagnoses, and no diagnosis, is valid - while (at least some) research which tests that assumption rather than making it, by including cohorts with other diagnoses and also no diagnosis, ends up challenging that assumption - e.g. https://www.nature.com/articles/s41398-019-0631-2 - but if the challenge is correct, how much validity is there in research which relies on it?\n \nreply"
    ],
    "link": "https://www.thetransmitter.org/spectrum/untangling-biological-threads-from-autisms-phenotypic-patchwork-reveals-four-core-subtypes/",
    "first_paragraph": ""
  },
  {
    "title": "Regarding our Cease and Desist letter to Automattic (wpfusion.com)",
    "points": 65,
    "submitter": "kemayo",
    "submit_time": "2024-10-20T00:00:15.000000Z",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=41891799",
    "comments": [
      "It's puzzling that in Automattic's reply to the cease and desist, they argued the listing of WPFusion was fair use. However, they copied it to their commercial Wordpress site and offered it as part of their \"business plan\" and also their paid premium plan.Their letter makes it sound like they are \"identifying\" it, like a bird watcher pointing to a bird or something. But they copied, re-hosted it and are, or were, offering it as part of the value proposition for which people should pay. I'll admit I'm fuzzy on fair use as anything more than a general concept but it's hard for me to square that one.\n \nreply",
      "I mean. The situation is actually very simple. WordPress.com has a \u201cbusiness/pro\u201d plan that lets you install plugins. Lower level plans do not allow that. (WordPress.com was initially just a big multisite with everyone\u2019s blogs running off the same WP instance. That would only work securely if you disable custom code.)So this paid business plan is just normal WordPress hosting where you get plugins and advanced features like SSH access.WordPress.com also has a re-skinned admin experience that is more modern looking than wp-admin.Within the past couple years, WordPress.com extended that modern skin to the plugins page. It\u2019s (as far as I know) data from the core plugin repo, just with a more modern look/experience. In fact, the WordPress.com code for this is totally open source.I\u2019m not 100% sure how that\u2019s not fair use \u2014 any WP host could do that to the plugin page of WP that they install. Other hosts just tend to be more hands off.\n \nreply",
      "This also makes matt's initial claim about wpengine being a bastardized fork hilarious since wordpress.com is even more hacked up.Also, you cannot install most plugins on wordpress.com unless you're on the business plan.\n \nreply",
      "I'm interpreting this as a somewhat tongue-in-cheek response to what Matt is doing. Matt has been trying to walk back all of his claims about open source and private equity and pretend it's all a trademark dispute. Well, he doesn't have a leg to stand on for that argument either.And the whole trademark thing is... frankly just incredibly lame in the first place. \"Going nuclear\" and trying to launch a public crusade is one thing if there was an actual moral high ground at play. But even if you are in the right... average people do not care about your trademark claims. Do it with lawyers behind closed doors.Attacking your userbase and buying out employees over... a trademark? Shutting your mouth was free, as is admitting you were wrong.\n \nreply",
      "https://archive.is/SvuYi\njust in case\n \nreply",
      "Tl;dr Wordpress.com has a sketchily-authorized copy of the Wordpress.org plugin directory that\u2019s used as a funnel into signing up for a Wordpress.com hosting account. This was causing the author problems because it has better google rankings than the .org, and they were getting support requests from people who thought buying a plan on Wordpress.com meant they got the premium version of their plugin. So they C&D\u2019d Automattic to remove them from the copied directory.This is only related to the recent WP Engine drama insofar as the author says it made them lose trust in Matt.\n \nreply",
      "I\u2019m amazed that Matt got away with claiming the Wordpress.org/.com duality for so long. Recent events have revealed that the dividing line between the two is virtually non-existent and Mullenweg used whichever organization was most convenient for pushing his agenda at the moment. MMullenweg\u2019s recent attempt to dunk on DHH for not capturing enough value from the Rails community is the most succinct mask-off moment of the recent events, in my opinion. He thought he was making a great point by criticizing DHH for not being extractive enough from the rails community. Instead, he only revealed his true thought process about how being at the center of an open source community should be a license to extract from said community. Really puts recent events into perspective.\n \nreply",
      ">Mullenweg\u2019s recent attempt to dunk on DHH for not capturing enough value from the Rails community is the most succinct mask-off moment of the recent events, in my opinion. He thought he was making a great point by criticizing DHH for not being extractive enough from the rails community.Is it possible to do a short version or medium version summary of that, and/or a link where I can find out more?\n \nreply",
      "HN discussion can be found at https://news.ycombinator.com/item?id=41839864 and contains archived versions of the post that has now been replaced.\n \nreply",
      "https://archive.ph/4yLNR\n \nreply"
    ],
    "link": "https://wpfusion.com/business/regarding-our-cease-and-desist-letter-to-automattic/",
    "first_paragraph": ""
  },
  {
    "title": "Send: Open-source fork of Firefox Send (vis.ee)",
    "points": 156,
    "submitter": "leonry",
    "submit_time": "2024-10-19T12:17:15.000000Z",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=41887378",
    "comments": [
      "Best of luck to the author! My understanding is that anything that makes large file sharing easy and anonymous rapidly gets flooded with CSAM and ends up shuttering themselves for the good of all. Would love to see a non-invasive yet effective way to prevent such an incursion.\n \nreply",
      "For Firefox Send, it was actually malware and spearfishing attacks that were spread.The combination of limited file availability (reducing the ability to report bad actors), as well as Firefox urls being inherently trusted within orgs (bypassing a lot of basic email/file filtering/scanning), was the reason it became so popular for criminals to use. Like we've seen in the spearfishing attacks in India[1].[1]: https://www.amnesty.org/en/latest/research/2020/06/india-hum...\n \nreply",
      "For a case when file sharing is intended  between individuals or small groups there's an easy solution:Anyone who got the link should be able to delete the file.This should deter one from using the file sharing tool as free hosting for possibly bad content. One can also build a bot that deletes every file found on public internet.\n \nreply",
      "Or the link expires after a download.\n \nreply",
      "That then ruins perfectly valid use cases that someone could maliciously delete the file for.\n \nreply",
      "But it allows sending. That might be an okay tradeoff, depending on what you're aiming for.Anonymous file hosting isn't something I'd be keen to offer, given the nhmber of people who would happily just abuse it.\n \nreply",
      "But people would abuse the delete button too.Imagine some computer work with a class of high school kids, where a teacher has to send them a file... there will be maybe three full downloads max, before someone presses the \"delete\" button.\n \nreply",
      "For a lot of use cases, simply sending the address of the deleter to whoever sent the file would suffice. Next time, just don't send it to them, or apply real-world consequences.Sure, it wouldn't work for a large public setting... but it'd work for many other settings.\n \nreply",
      "I've been using this version for a while, presumably it's just gone under the radar enough. So please don't upvote this too much, haha.\n \nreply",
      "If it's truly e2e how would they even know what's being shared on it?\n \nreply"
    ],
    "link": "https://send.vis.ee/",
    "first_paragraph": "\n\n              Why does Send require JavaScript?\n            \nPlease enable JavaScript and try again."
  },
  {
    "title": "Medley Loops: The Basic System (Lisp Object-Oriented Programming System) [pdf] (interlisp.org)",
    "points": 50,
    "submitter": "pamoroso",
    "submit_time": "2024-10-16T14:42:22.000000Z",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=41859622",
    "comments": [
      "LOOPS was one of the early frameworks for AI programming (-> for Knowledge-based Systems -> especially Expert Systems) in Lisp, which also made use of the new graphical user interface of the Interlisp-D Lisp Machine from Xerox. Interlisp-D was a combination of operating system and development environment, and was developed for the same computers, which also ran Smalltalk. Both were image-based and managed the source code in the development environment.Remarkable is the fully interactive way of working in the REPL (Lisp's Read Eval Print Loop) and through the GUI, including live editing all classes/etc. via menus. LOOPS extended Interlisp with various ways to do object-oriented programming and a rule-system.There is also a \"friendly primer\" for Xerox LOOPS, from mid 1980s. https://bitsavers.org/pdf/xerox/interlisp-d/198510_Koto/3102...Note that LOOPS is an early OOP System, it's not a about iteration in a loop.\n \nreply",
      "I was at a presentation on LOOPS in London given by Dan Bobrow and Mark Stefik, they were pitching it as an equivalent framework to KEE or ART as you describe. They had a good showcase application called Truckin' [1] that made good use of all the features of LOOPS.[1] https://www.markstefik.com/?page_id=359\n \nreply",
      "Some more background https://larrymasinter.net/stefik-loops.pdf and https://www.markstefik.com/?page_id=334I think LOOPS was limited by only being available on Interlisp-D related systems. Common LOOPS was supposed to be portable, but I remember it only in the context of the CLOS development as a stepping stone, but not as a product or environment like LOOPS.\n \nreply",
      "I ran Common LOOPS in AKCL on a 386 PC. It was just an object system for programming, it didn't have a Frame System or Rule Engine as well like LOOPS.My previous environment had been Franz Lisp on the Atari ST. My copy of the Franz sources was missing flavors so I wrote my own object system for it that looked a bit like New Flavors but with a frame system built in as well. My binding to GEM from Lisp made use of the object system as well and the repl was in a GEM window.\n \nreply",
      "Yes!, that Truckin\u2019 demo was awesome. I had a 1108 Xeorx Lisp Machine, and ran InterLisp-D on it the first 18 months I had it, then switched to running Common Lisp. Such a fantastic development environment!\n \nreply",
      "Volume I of the Medley LOOPS series about the Lisp Object-Oriented Programming System, an Interlisp object extension. Volume II is coming in the late fall of 2024, Volume III in the fall of 2025.\n \nreply",
      "Thanks for sharing. I didn't realize it was available, but the version is 1.2 and date is July 2024, so it must have been around for some time.\n \nreply",
      "What are the major differences to CLOS?\n \nreply",
      "LOOPS (Lisp object-oriented programming systems) is written in Interlisp for the Interlisp-D environment, was a Xerox product and is from around 1981.CLOS (Common Lisp Object System) is a general OOP standard extension for Common Lisp. A specification was proposed in 1987/88. CLOS was included in the Common Lisp standard and widely implemented by various implementations.Both were a \"system\" -> meaning that it is available and programmable also at runtime.LOOPS is an actual piece of software with a GUI, which integrates into the Interlisp-D development environment.LOOPS was based on message sending, classes, methods, interactive changes to the object system.CLOS does not use message sending, but calling generic functions with multi-methods and multiple dispatch.LOOPS supports Access-oriented Programming with Active Values. Demons can act based on access to objects. CLOS has no direct support for that. Maybe partial (-> :before & :around &:after methods in CLOS).LOOPS includes a rule-system. CLOS systems have that as extensions. It's not a part of CLOS itself.LOOPS includes graphical & menu tools to browse and edit objects. CLOS systems have some of that as extensions, depending on the implementation.LOOPS was a programming system for knowledge-based systems, like Expert Systems. CLOS was not designed for that, but such programming systems were also developed for Common Lisp, some using CLOS. Example: KnowledgeWorks from LispWorks.LOOPS was later rewritten as CommonLOOPS for Common Lisp. The software \"Portable Common LOOPS\" (PCL) then was further developed into a portable (and widely ported) and complete prototype implementation of CLOS + MOP.\n \nreply",
      "Thanks. I'm mostly interested in the OO features. I assumed that LOOPS was essentially an OO extension of Interlisp (and thus a precursor of CLOS) due to the title. Does it really do \"message sending\", or is it rather like Smalltalk, which does \"normal\" method dispatch and call, but where the term \"message sending\" is use for this?\n \nreply"
    ],
    "link": "https://interlisp.org/documentation/2024-loops-book-1.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Implementing neural networks on the \"3 cent\" 8-bit microcontroller (cpldcpu.wordpress.com)",
    "points": 10,
    "submitter": "cpldcpu",
    "submit_time": "2024-10-19T18:09:48.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/",
    "first_paragraph": "Tim's BlogBouyed by the surprisingly good performance of neural networks with quantization aware training on the CH32V003, I wondered how far this can be pushed. How much can we compress a neural network while still achieving good test accuracy on the MNIST dataset? When it comes to absolutely low-end microcontrollers, there is hardly a more compelling target than the Padauk 8-bit microcontrollers. These are microcontrollers optimized for the simplest and lowest cost applications there are. The smallest device of the portfolio, the PMS150C, sports 1024 13-bit word one-time-programmable memory and 64 bytes of ram, more than an order of magnitude smaller than the CH32V003. In addition, it has a proprieteray accumulator based 8-bit architecture, as opposed to a much more powerful RISC-V instruction set.Is it possible to implement an MNIST inference engine, which can classify handwritten numbers, also on a PMS150C?On the CH32V003 I used MNIST samples that were downscaled from 28\u00d728 to 16\u00d71"
  },
  {
    "title": "Svelte 5 Released (npmjs.com)",
    "points": 241,
    "submitter": "begoon",
    "submit_time": "2024-10-19T18:38:06.000000Z",
    "num_comments": 120,
    "comments_url": "https://news.ycombinator.com/item?id=41889674",
    "comments": [
      "Svelte 5 has been very nice to work with over the past few months. Yes, runes require you to think more carefully about lifecycles and updates. And you may end up writing a little more code initially than with svelte 4. But it serves you better in the long run with complex apps. I found a process for gradually turning a simple app into a more complex one that works for me. I iteratively move $state() runes out of .svelte files and into .svelte.ts files where I build a more abstract data-oriented structure for my app from a series of mutually linked classes. Then those runes can be re-imported into the .svelte files, or used and updated wherever you need. If you plan it right, I think it avoids the need for heavy redux-like state management. (at least I think so. I haven't worked with redux much myself)\n \nreply",
      "Do you know of any large OSS software built with Svelte? I'd like to see how it turns out in the long run, because I'm reticent of all frontend frameworks nowadays through what I perceive as gateways to uncontrollable accidental complexity and abstractions.\n \nreply",
      "PocketBase's UI is built with Svelte: https://github.com/pocketbase/pocketbase/tree/master/uiEDIT: Also, not OSS, but https://search.brave.com seems to be built with Svelte\n \nreply",
      "Gradio is built with svelte https://github.com/gradio-app/gradio\n \nreply",
      "Windmill - https://github.com/windmill-labs/windmill\n \nreply",
      "Apple Music isn't OSS, but it's quite a large Svelte app: https://music.apple.com\n \nreply",
      "more notable companies using svelte because this always comes up https://x.com/SvelteSociety/status/1260209026563858432\n \nreply",
      "Only viewable if you have a Twitter account, which is less and less common these days.\n \nreply",
      "Ofcoz hypest and ml opensource software frontend are build with svelte and they're very successfulhuggingface \nhttps://huggingface.co/pydio\nhttps://huggingface.co/docs/chat-ui\nOllma webui\nhttps://github.com/open-webuiThese are just a few of them that I quickly search and look at their popularity .\n \nreply",
      "Huly was just recently on the HN frontpage:\nhttps://github.com/hcengineering/platformGradio: \nhttps://github.com/gradio-app/gradio\n \nreply"
    ],
    "link": "https://www.npmjs.com/package/svelte",
    "first_paragraph": "  Svelte is a new way to build web applications. It's a compiler that takes your declarative components and converts them into efficient JavaScript that surgically updates the DOM.Learn more at the Svelte website, or stop by the Discord chatroom.You can play around with Svelte in the tutorial, examples, and REPL.When you're ready to build a full-fledge application, we recommend using SvelteKit:See the SvelteKit documentation to learn more.The Changelog for this package is available on GitHub.Svelte is an MIT-licensed open source project with its ongoing development made possible entirely by fantastic volunteers. If you'd like to support their efforts, please consider:Funds donated via Open Collective will be used for compensating expenses related to Svelte's development.npm i svelteGitgithub.com/sveltejs/sveltesvelte.dev1,184,9575.0.2MIT2.28 MB3623 hours ago"
  },
  {
    "title": "AI engineers claim new algorithm reduces AI power consumption by 95% (tomshardware.com)",
    "points": 159,
    "submitter": "ferriswil",
    "submit_time": "2024-10-19T18:03:32.000000Z",
    "num_comments": 80,
    "comments_url": "https://news.ycombinator.com/item?id=41889414",
    "comments": [
      "https://arxiv.org/abs/2410.00907ABSTRACTLarge neural networks spend most computation on floating point tensor multiplications. In this work, we find that a floating point multiplier can be approximated by one integer adder with high precision. We propose the linear-complexity multiplication (L-Mul) algorithm that approximates floating point number multiplication with integer addition operations. The new algorithm costs significantly less computation resource than 8-bit floating point multiplication but achieves higher precision. Compared to 8-bit floating point multiplications, the proposed method achieves higher precision but consumes significantly less bit-level computation. Since multiplying floating point numbers requires substantially higher energy compared to integer addition operations, applying the L-Mul operation in tensor processing hardware can potentially reduce 95% energy cost by elementwise floating point tensor multiplications and 80% energy cost of dot products. We calculated the theoretical error expectation of L-Mul, and evaluated the algorithm on a wide range of textual, visual, and symbolic tasks, including natural language understanding, structural reasoning, mathematics, and commonsense question answering. Our numerical analysis experiments agree with the theoretical error estimation, which indicates that L-Mul with 4-bit mantissa achieves comparable precision as float8 e4m3 multiplications, and L-Mul with 3-bit mantissa outperforms float8 e5m2. Evaluation results on popular benchmarks show that directly applying L-Mul to the attention mechanism is almost lossless. We further show that replacing all floating point multiplications with 3-bit mantissa L-Mul in a transformer model achieves equivalent precision as using float8 e4m3 as accumulation precision in both fine-tuning and inference.\n \nreply",
      "I feel like I have seen this idea a few times but don't recall where but stuff posted via HN.Here https://news.ycombinator.com/item?id=41784591 but even before that. It is possibly one of those obvious ideas to people steeped in this.To me intuitively using floats to make ultimatelty boolean like decisions seems wasteful but that seemed like the way it had to be to have diffetentiable algorithms.\n \nreply",
      "Does this mean you can train efficiently without GPUs?Presumably there will be a lot of interest.\n \nreply",
      "No. But it does potentially mean that either current or future-tweaked GPUs could run a lot more efficiently -- meaning much faster or with much less energy consumption.You still need the GPU parallelism though.\n \nreply",
      "I had a feeling it had to be something like massive waste due to a misguided feature of the algorithms that shouldn't have been there in the first place.Once the \"math is done\" quite likely it would have paid off better than most investments for the top people to have spent a few short years working with grossly underpowered hardware until they could come up with amazing results there before scaling up.  Rather than grossly overpowered hardware before there was even deep understanding of the underlying processes.When you think about it, what we have seen from the latest ultra-high-powered \"thinking\" machines is truly so impressive.  But if  you are trying to fool somebody into believing that it's a real person it's still not \"quite\" there.Maybe a good benchmark would be to take a regular PC, and without reliance on AI just pull out all the stops and put all the effort into fakery itself.  No holds barred, any trick you can think of.  See what the electronics is capable of this way.  There are some smart engineers, this would only take a few years but looks like it would have been a lot more affordable.Then with the same hardware if an AI alternative is not as convincing, something has got to be wrong.It's good to find out this type of thing before you go overboard.Regardless of speed or power, I never could have gotten an 8-bit computer to match the output of a 32-bit floating-point algorithm by using floating-point myself.  Integers all the way and place the decimal where it's supposed to be when you're done.Once it's really figured out, how do you think it would feel being the one paying the electric bills up until now?\n \nreply",
      "Faster progress was absolutely worth it. Spending years agonizing over theory to save a bit of electric would have been a massive disservice to the world.\n \nreply",
      "You're sort of presuming that LLMs are going to be a massive service to the world there, aren't you?  I think the jury is still out on that one.\n \nreply",
      "They already have been. Even just in programming, even just Copilot has been a life changing productivity booster.\n \nreply",
      "Are you sure it\u2019s a life changing productivity booster? Sometimes I look at my projects and wonder how would I explain it to an LLM what this code should have done if it didn\u2019t exist yet. Must be a shitton of boilerplate programming for copilot to be a life-changing experience.\n \nreply",
      "\u201cA bit\u201d?\n \nreply"
    ],
    "link": "https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-engineers-build-new-algorithm-for-ai-processing-replace-complex-floating-point-multiplication-with-integer-addition",
    "first_paragraph": "Addition is simpler than multiplication, after all.\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nEngineers from BitEnergy AI, a firm specializing in AI inference technology, has developed a means of artificial intelligence processing that replaces floating-point multiplication (FPM) with integer addition.\u00a0The new method, called Linear-Complexity Multiplication (L-Mul), comes close to the results of FPM while using the simpler algorithm. But despite that, it\u2019s still able to maintain the high accuracy and precision that FPM is known for. As TechXplore reports, this method reduces the power consumption of AI systems, potentially up to 95%, making it a crucial development for our AI future.Since this is a new process, popular and readily available hardware on the market, like Nvidia\u2019s upcoming Blackwell GPUs, aren't designed to handle this algorithm. So, even if BitEnergy AI\u2019s algorithm is confirmed to perform at the same level as F"
  },
  {
    "title": "The Languages of English, Math, and Programming (github.com/norvig)",
    "points": 11,
    "submitter": "stereoabuse",
    "submit_time": "2024-10-19T19:39:19.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/norvig/pytudes/blob/main/ipynb/Triplets.ipynb",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          "
  }
]