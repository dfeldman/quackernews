[
  {
    "title": "Apple needs a Snow Sequoia (ofb.biz)",
    "points": 289,
    "submitter": "trbutler",
    "submit_time": "2025-03-27T22:32:45 1743114765",
    "num_comments": 215,
    "comments_url": "https://news.ycombinator.com/item?id=43498984",
    "comments": [
      "There are some factual \"gaps\" there about how good Snow Leopard was, but I understand the sentiment. As someone who's been a Mac user since System 6 and has been consistently using Macs alongside PCs _daily_ for over 20 years I can say that Apple's software quality (either in terms of polish or just plain QA) has steadily decreased.It's just that me and other old-time switchers have stopped complaining about it and moved on (taoofmac.com, my blog, was started when I wrote a few very popular switcher guides, and even though I kept using the same domain name I see myself as a UNIX guy, not \"just\" a Mac user).For me, Spotlight is no longer (anywhere) near as useful to find files (and sometimes forgets app and shortcut names it found perfectly fine 5 minutes ago), and there is no longer any way to effectively prioritize the results I want (apps, not internet garbage).Most of the other examples in the article also apply, but to be honest I've been using GNOME in parallel for years now and I consider it to be my \"forever desktop\" if PC hardware can ever match Apple Silicon (or, most likely, if I want something that is _just a computer_).\n \nreply",
      "> Most of the other examples in the article also apply, but to be honest I've been using GNOME in parallel for years now and I consider it to be my \"forever desktop\" if PC hardware can ever match Apple Silicon (or, most likely, if I want something that is _just a computer_).I'm there as well. I've been really enjoying desktop Linux lately, but I can't go back to a non-Apple laptop at this point. There's just nothing else on the market that comes close, they all make some tradeoff I'm not willing to make - either screen, speakers, keyboard, heat/battery life/fan noise, touchpad, etc. Apple is the only one that has the entire package.There's Asahi, but no thunderbolt yet and I'm not sure the future of that project with the lead burning out and quitting. I just want an Apple Silicon-esque laptop, no trade offs on components, that runs Linux, and there's no OEM out there that's offering that experience.So, until that happens I'm staying on mac, and even with declining quality, it's not all that bad compared to the alternatives yet. I've learned to mostly work around/ignore the odd bugs.\n \nreply",
      "I have some hope that Framework and AMD can fix some of those issues. Would love to try out their new desktop (because it's a simpler, more tightly integrated thing) and replace my Mac mini -- then wait for Linux power management to improve.\n \nreply",
      "Linux power management is pretty good. The problem is that defaults favor desktop and server performance. On a MacBook Air 11, my custom Linux setup and Mac OS had the same battery autonomy, despite Safari being much more energy efficient.The real problem is that, just like the grandparent post pointed out, Apple's software quality has been declining. The Tiger to Snow Leopard epoch was incredible. Apps were simple, skeumorphic, and robust.Right now, the whole system feels a lot less coherent and robustness has declined. IMHO, there are not so many extra features worth adding. They should focus on making all software robust and secure. Robustness should come from better languages that are safe by construction. Apple can afford to invest on this due to their vertical integration.\n \nreply",
      "https://en.wikipedia.org/wiki/Jerry_Pournelle#Pournelle's_ir...\n \nreply",
      "What\u2019s the actual argument that will credibly convince the top leaders of Apple, to push fixing MacOS up the list of priorities?Because right now it\u2019s clearly so far down, beneath dozens of other priorities, that expecting it to just happen one day seems futile.\n \nreply",
      "IMHO, Mac OS X contributed decisively towards making Apple cool, which was followed by lots of boutique apps and the success of iOS. Loosing that critical mass of developers, even if it's a tiny userbase, would worry me if I was a top leader of Apple.",
      "It's all their OS software. The Messages app on 18.3 will just... not open the menu to send a photo attachment about ~10% of the time now...\n \nreply",
      "Ya and it\u2019s something in maybe the top 3 of most used user actions. Really indefensible",
      "This really is exactly how I feel. There are too many tradeoffs to switch to non-Apple hardware at this point. I'd love to run Linux/BSD full-time, as many of the apps that I frequently use on my Mac are FOSS (e.g., R, PyCharm, darktable, etc.) I've been a Mac user since 2002, and Mac OS X served as my gateway to the Linux/BSD world (that, and a short-lived use of RH 6.2 on an old Dell laptop). IMO, macOS really does need a Tiger/Snow Leopard-esque release, but I'm not sure the vast majority of macOS users would even appreciate such a release.\n \nreply"
    ],
    "link": "https://reviews.ofb.biz/safari/article/1300.html",
    "first_paragraph": "The same year Apple launched the iPhone, it unveiled a massive upgrade to Mac OS X known as Leopard, sporting \u201c300 New Features.\u201d Two years later, it did something almost unheard of: it released Snow Leopard, an upgrade all about how little it added and how much it took away. Apple needs to make it snow again.Snow Leopard did what it was made to do. It was one of the most solid software releases Apple ever put out. I\u2019d say one of the best modern operating system releases, period.After Apple\u2019s frenetic run of overhauling and quickly iterating on the entire Mac platform in the early 2000s, becoming a major technology player again with the iPod, moving the Mac to a new processor architecture (for the second of three times) and releasing the iPhone, it was time for detail work. 2009\u2019s Snow Leopard was understated, but improved the underlying system while shrinking it in size by removing outdated accretions.In an era when people still paid money for operating system upgrades every few years"
  },
  {
    "title": "Tracing the thoughts of a large language model (anthropic.com)",
    "points": 554,
    "submitter": "Philpax",
    "submit_time": "2025-03-27T17:05:36 1743095136",
    "num_comments": 221,
    "comments_url": "https://news.ycombinator.com/item?id=43495617",
    "comments": [
      ">> Language models like Claude aren't programmed directly by humans\u2014instead, they\u2018re trained on large amounts of data.Gee, I wonder where this data comes from.Let's think about this step by step.So, what do we know? Language models like Claud are not programmed directly.Wait, does that mean they are programmed indirectly?If so, by whom?Aha, I got it. They are not programmed, directly or indirectly. They are trained on large amounts of data.But that is the question, right? Where does all that data come from?Hm, let me think about it.Oh hang on I got it!Language models are trained on data.But they are language models so the data is language.Aha! And who generates language?Humans! Humans generate language!I got it! Language models are trained on language data generated by humans!Wait, does that mean that language models like Claud are indirectly programmed by humans?That's it! Language models like Claude aren't programmed directly by humans because they are indirectly programmed by humans when they are trained on large amounts of language data generated by humans!\n \nreply",
      "I'm struggling to see the point here other than semantics. Indirectly or directly, does this change what they presented?\n \nreply",
      "I\u2019ve only skimmed the paper - a long and dense read - but it\u2019s already clear it\u2019ll become a classic. What\u2019s fascinating is that engineering is transforming into a science, trying to understand precisely how its own creations workThis shift is more profound than many realize. Engineering traditionally applied our understanding of the physical world, mathematics, and logic to build predictable things. But now, especially in fields like AI, we\u2019ve built systems so complex we no longer fully understand them. We must now use scientific methods - originally designed to understand nature - to comprehend our own engineered creations. Mindblowing.\n \nreply",
      "This \"practice-first, theory-later\" pattern has been the norm rather than the exception. The steam engine predated thermodynamics. People bred plants and animals for thousands of years before Darwin or Mendel.The few \"top-down\" examples where theory preceded application (like nuclear energy or certain modern pharmaceuticals) are relatively recent historical anomalies.\n \nreply",
      "I see your point, but something still seems different. Yes we bred plants and animals, but we did not create them. Yes we did build steam engines before understanding thermodynamics but we still understood what they did (heat, pressure, movement, etc.)Fun fact: we have no clue how most drugs works. Or, more precisely, we know a few aspects, but are only scratching the surface. We're even still discovering news things about Aspirin, one of the oldest drugs: https://www.nature.com/articles/s41586-025-08626-7\n \nreply",
      "> Yes we did build steam engines before understanding thermodynamics but we still understood what it did (heat, pressure, movement, etc.)We only understood in the broadest sense. It took a long process of iteration before we could create steam engines that were efficient enough to start an Industrial Revolution. At the beginning they were so inefficient that they could only pump water from the same coal mine they got their fuel from, and subject to frequent boiler explosions besides.\n \nreply",
      "We laid transatlantic telegraph wires before we even had a hint of the physics involved. It create the entire field of transmission and signal theory.Shannon had to invent new physics to explain why the cables didn't work as expected.\n \nreply",
      "I think that's misleading.There was a lot of physics already known, importance of insulation and cross-section, signal attenuation was also known.The future Lord Kelvin conducted experiments. The two scientific advisors had a conflict. And the \"CEO\" went with the cheaper option.\"\"\"\nThomson believed that Whitehouse's measurements were flawed and that underground and underwater cables were not fully comparable. Thomson believed that a larger cable was needed to mitigate the retardation problem. In mid-1857, on his own initiative, he examined samples of copper core of allegedly identical specification and found variations in resistance up to a factor of two. But cable manufacture was already underway, and Whitehouse supported use of a thinner cable, so Field went with the cheaper option.\n\"\"\"\n \nreply",
      "that was 1854. You basically only needed Ohm's law for that, which was discovered in 1827\n \nreply",
      "THe telegraph it's older than radio. Think about it.\n \nreply"
    ],
    "link": "https://www.anthropic.com/research/tracing-thoughts-language-model",
    "first_paragraph": ""
  },
  {
    "title": "How to Use Em Dashes (\u2013), En Dashes (\u2013), and Hyphens (-) (merriam-webster.com)",
    "points": 216,
    "submitter": "Stratoscope",
    "submit_time": "2025-03-27T20:19:38 1743106778",
    "num_comments": 160,
    "comments_url": "https://news.ycombinator.com/item?id=43497719",
    "comments": [
      "Here's an easy, if not always precise way to remember:* Hyphens connect things, such as compound words: double-decker, cut-and-dried, 212-555-5555.* EN dashes make a range between things: Boston\u2013San Francisco flight, 10\u201320 years: both connect not only the endpoints, but define that all the space between is included. (Compare the last usage with the phone number example under Hyphens.)* EM dashes break things, such as sentences or thoughts: 'What the\u2014!'; A paragraph should express one idea\u2014but rules are made to be broken.Unicode has the original ASCII hyphen-minus (U+002d), as well as a dedicated hyphen (U+2010), other functional hyphens such as soft and non-breaking hyphens, and a dedicated minus sign (U+2212), and some variations of minus such as subscript, superscript, etc.There's also the figure dash \"\u2012\" (U+2012), essentally a hyphen-minus that's the same width as numbers and used aesthetically for typsetting, afaik. And don't overlook two-em-dashes \"\u2e3a\" and three-em-dashes \"\u2e3b\" and horizontal bars \"\u2015\", the latter used like quotation marks!\n \nreply",
      "> EM dashes break things, such as sentences or thoughtsSome style guides recommend \"space, en dash, space\" for this, and I prefer that myself \u2013 mainly because some software doesn't treat em dashes correctly as word separators for double click selection purposes.For example, I'm pretty sure that at least some Kindle models would highlight both the word before and after the em dash when selecting one of them, which makes using the dictionary very annoying.\n \nreply",
      "I prefer the dedicated minus (U+2212) over the hyphen-minus (U+002d) for mathematical use because they look different in most font faces.Are there cases where the dedicated hyphen (U+2010) is preferred over the hyphen-minus?\n \nreply",
      "Also, not to be confused with \"\u4e00\", which is a different thing entirely\u2026\u2026\n \nreply",
      "AFAIK most computer keyboards don't have em dashes.  Rather than hit ALT+0151 every time, I've always just strung along two hyphens, like: --Absolutely proper and correct use of em dashes, en dashes, and hyphens is, to me, the most obvious tell of the LLM writer.  In fact, I think that you can use it to date internet writing in general.  For it seems to me that real em dashes were uncommon pre-2022.\n \nreply",
      "This test feels biased by the fact that, like others have said, macOS provides keyboard shortcuts. For example, I'm only Gen Z and yet have tried for many years to use the proper dash characters in the right places, which is made much easier by virtue of being on a Mac.Of course, I guess it's entirely possible\u2014even accounting for OS\u2014that this test remains statistically useful. It makes me kinda sad that my (very much human-generated) writing fails the Turing test....\n \nreply",
      "The compose key, for those who use it, also makes it very easy to do em/en dashes, and I use them quite regularly as a result.\n \nreply",
      "That has nothing to do with being on a Mac. Em-dashes and the compose-key work fine on Linux, and Android has them under the '-' of the on-screen keyboard when long-pressed.(Windows probably has some way, but those are rarely discoverable.)\n \nreply",
      "I disagree, there is absolutely no easy way to do it on Windows. You can install a third party program that emulates the compose key but on macos it \"just works\". And I think that makes a difference for 95% of users\n \nreply",
      "That's true, I do use them a lot on iOS as well\u2014similarly, it's a long-press on '-' to get an en or em dash.\n \nreply"
    ],
    "link": "https://www.merriam-webster.com/grammar/em-dash-en-dash-how-to-use",
    "first_paragraph": "The em dash (\u2014) can function like a comma, a colon, or parenthesis. Like commas and parentheses, em dashes set off extra information, such as examples, explanatory or descriptive phrases, or supplemental facts. Like a colon, an em dash introduces a clause that explains or expands upon something that precedes it.Mabel the Cat was delighted with the assortment of pastries the new bakery featured, but Harry the Dog\u2014he felt otherwise, for the bakery did not offer cheese Danishes at all.\u201cOf course you have a point,\u201d Mabel murmured. \u201cThat is\u2014I suppose it is concerning.\u201dThe bakery's significantly broad hours of operation\u20146 a.m. to 6 p.m.\u2014certainly showed concern for customers\u2019 manifold circumstances.A regular selection of three kinds of croissants\u2014plain, almond, and chocolate\u2014was heartening, both Mabel and Harry agreed.Harry would never forget the Tuesday that Mabel called him from the bakery, her voice brimming with excitement\u2014the bakery had added cheese Danishes to its selection.The bakery "
  },
  {
    "title": "Learning Theory from First Principles [pdf] (ens.fr)",
    "points": 73,
    "submitter": "Anon84",
    "submit_time": "2025-03-27T20:45:13 1743108313",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43497954",
    "comments": [
      "https://francisbach.com/my-book-is-out/https://mitpress.mit.edu/9780262049443/learning-theory-from-...\n \nreply",
      "This looks interesting. Does anyone knows how it compares to other learning theory books like foundations of machine learning [1] in terms of depth and approachability?[1] https://cs.nyu.edu/~mohri/mlbook/\n \nreply",
      "Learning From Data: https://amlbook.com/\n \nreply",
      "I honestly don't understand why people write these books anymore. Let me explain: there used to be a lot of these kinds survey books that start with linear regression and end at... something classical. I can rattle off a lot of titles (Pattern Recognition and Machine Learning, Elements of Statistical Learning, Intro to Statistical Learning, blah blah blah). They all covered the same material at various levels of sophistication (some of them covered meta theory like PAC learning or shattering dimension or empirical risk minimization or whatever). Some of them took the statistical approach and some of them took the optimization approach. Again: blah blah blah. The synthesis/summary is/was there is no grand unified theory of machine learning and everyone saw that it should be clear.And then \"deep learning\" arrived and it became even more obvious that the only thing that matters is data and time spent crunching numbers (more of both and you get better results no matter the model).Again I just want to be crystal clear, because I'm sure someone will pop in and claim \"oh I still use SVM to pick my family's shopping list\": no professional ML engineer/team/org today that ships and ML product \"at scale\" gives a fuck about SVMs or graphical models or bayes nets or kernel methods. No one. So who cares about all this sophistry? What value is it to learn concentration inequalities - training goes brrr no matter what if you have enough data. And if you don't, if you're really building a model to predict your family's shopping list, I encourage to reflect on whether it would be simpler to just ask your family what they want for dinner instead.My 2 cents: teach people/students useful things instead of this stuff. They'll be happier and you'll feel more fulfilled (even though you didn't get flex your big math brain).\n \nreply",
      "Maybe the book it\u2019s just not for you. It doesn\u2019t mean it\u2019s not for anyone.I understand that deep learning is all in vogue now. But when I was in graduate school, a professor asked me why I was using neural nets in a project since it was not as good as SVMs. We used to study Vapnik and VC dimensions, SVMs etc. and neural nets were totally out of fashion.Imagine what would have happened if everybody were using and researching only those methods because they worked better. And deep learning could benefit from a theory that explains why, when and how it works so well. Maybe someone working on this could develop on it to include it.Also I don\u2019t think you\u2019re right to assume that all models out there are deep learning models. Yes they are very good for many cases (specially those with less structured data, like image or nlp). But in some cases gradient boosting or even GLMs are better suited for the task (because of the structure and size of the data or because of computing restrictions).And in the end, people can just want to learn it because they find it interesting.\nIt\u2019s a bit sad to do only things that are \u201cuseful\u201d. That\u2019s my 2 cents.\n \nreply",
      "This book is not for you.Teaching others how to replicate solutions is very different from guiding people how to solve yet unsolved problems in the field.This book is for the latter. For the former, you might want to look out for one in the \"for dummies\" series.\n \nreply",
      "But why does, as you explain \"training goes brrr\"?Francis Bach, the author, makes a good faith effort to explain exactly why this material is beneficial (see https://francisbach.com/my-book-is-out/):\"Why yet another book on learning theory? ...the main reason is that I felt that the current trend in the mathematical analysis of machine learning was leading to overly complicated arguments and results that are often not relevant to practitioners. Therefore, my aim was to propose the simplest formulations that can be derived from first principles, trying to remain rigorous without overwhelming readers with more powerful results that require too much mathematical sophistication.\"From my own reading and experience on the mathematical analysis approach of this \"training goes brrr\" approach, I thought the material in Chapter 12, Overparameterized Models, was interesting and coherent with 12.2.4 Linear Regression with Gaussian Projections being an especially elegant explanation. It would be interesting to hear if you had read/skimmed/purused this section and found it wanting etc.\n \nreply"
    ],
    "link": "https://www.di.ens.fr/~fbach/ltfp_book.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Most promoted and blocked domains on Kagi (kagi.com)",
    "points": 96,
    "submitter": "lucgommans",
    "submit_time": "2025-03-27T22:39:51 1743115191",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=43499045",
    "comments": [
      "I love that wiki.archlinux.org is a top-Pinned.I'm firmly a Debian shop, but I find that the Arch Linux wiki often answers non-distro-specific questions that I have about how to do something on Debian.(Especially since I'm usually using Xmonad without a lot of the \"desktop environment\" stuff.)\n \nreply",
      "The Arch Linux Wiki has some awesome information, but it's a little too informal for it to be a go-to for me.  It's information is incomplete, opinionated, and sometimes has a \"works on my machine\" sort of a vibe.But sometimes it just has the answer you need in an easily digestible format.  Top 10 source for me, but not a top 3.-- Some nerd with almost two decades of distro-hopping experience.\n \nreply",
      "Yeah, I don't expect comprehensive and definitive documentation from it, nor copy&paste answers.But for getting pointed in the right direction about things that have been obscured by the desktop environments, and then left largely undocumented nowadays, the Arch Linux wiki usually points me in the right direction.Much of it would be pretty confusing to someone who only wanted high-level documentation in terms of the Gnome Desktop or KDE Plasma, though.\n \nreply",
      "Oh it's really cool that you've used the arch wiki in that way.  I had already done Linux From Scatch before I ran across the Arch wiki, so I was already familiar with concepts like boot loaders, kernel modules, and daemons.   I mostly used it to find some sane config file values.\n \nreply",
      "Similar here (25+ years Linux experience, including making my own distro).  Personally, I use the Arch wiki for pointers to the current way to do system-level things, which has changed over time, with kernel and userland (e.g., all the things systemd changed, and for various kinds of devices), and sometimes for applications (e.g., what programs are currently available to do some small thing).Maybe the value comes not just because they bother to maintain a wiki, but that Arch Linux tends to select for above-average technical people, even more than Linux in general does.  (Even if Arch people strangely don't run Debian goodness; but we benefit from a diversity of perspectives, even if they are unexplained. :)\n \nreply",
      "I agree and I have to tell newer users all the time the wiki is very valuable regardless of if you use arch or not btw\n \nreply",
      "I'm not surprised to see w3schools.com up there. I haven't come across it recently because of shifts in what I do, but it used to come up so often when I was looking for coding documentation. It was almost always useless.\n \nreply",
      "If only it was merely useless. I know its reputation but it had some information that MDN did not have, so I used it this once in recent years. Turned out, the information was simply wrong and so I made a wrong decision based on that. (It might have been about favicon format support in different browsers. Presumably it was Safari that never had support for vector graphics whereas w3schools listed it as such, and it's not like you can just download Safari to double check.) Regardless, what I'm sure about is that I alerted them to whatever the problem was, but for me it was the last nail in that coffin\n \nreply",
      "Pintrest owns all the top 7 blocked results. Good, they've earned it.I never understood why Google let them destroy Google Image search results.\n \nreply",
      "I'm surprised - simply because I never get Pinterest results on Google. Now admittedly most of my searches aren't the kind where Pinterest is likely to have relevant results, but even then, surely I'd at least see them _sometimes_. But I literally can't remember the last time I saw a Pinterest search result.Unless, as you suggest, they take over Google Images but not text search results? I could believe that I use Image search sufficiently rarely that I wouldn't have seen a Pinterest result.\n \nreply"
    ],
    "link": "https://kagi.com/stats?stat=leaderboard",
    "first_paragraph": ""
  },
  {
    "title": "A note on the USB-to-PS/2 mouse adapter that came with Microsoft mouse devices (microsoft.com)",
    "points": 14,
    "submitter": "luu",
    "submit_time": "2025-03-28T00:16:29 1743120989",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://devblogs.microsoft.com/oldnewthing/20250325-00/?p=110993",
    "first_paragraph": "Back in the early days of USB, Microsoft mouse devices often came with a USB plug at the end of the cable, but also came with a small green adapter to convert the USB type-A plug into a PS/2 plug. How did this adapter work?USB and PS/2 are completely different protocols that are not compatible in any way. The adapter was purely mechanical (passive). It connected one set of pins to another, but it contained no circuitry. All of the smarts was in the mouse.The mouse detected whether it received USB-like signals or PS/2-like signals on the pins and changed its behavior accordingly. The mouse did all the work.It\u2019s similar to the inexpensive electrical outlet adapters which convert between different national plug types. There are no smarts in the adapter. It just connects one set of plugs to another. The actual intelligence is in the appliance itself (or the power brick for the appliance).So if you find one of these adapters in your junk drawer, be aware that it is not a universal mouse ada"
  },
  {
    "title": "Helpcare AI (YC F24) Is Hiring (docs.google.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-03-28T01:00:54 1743123654",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://docs.google.com/forms/d/e/1FAIpQLScpzOyP_mk3muEpbKrnW8UTZB_yP5SJwjbeT8_6A6fhdvpJCg/viewform?usp=preview",
    "first_paragraph": ""
  },
  {
    "title": "I genuinely don't understand why some people are still bullish about LLMs (twitter.com/skdh)",
    "points": 160,
    "submitter": "ksec",
    "submit_time": "2025-03-27T21:22:42 1743110562",
    "num_comments": 195,
    "comments_url": "https://news.ycombinator.com/item?id=43498338",
    "comments": [
      "I get so confused on this. I play around, test, and mess with LLMs all the time and they are miraculous. Just amazing, doing things we dreamed about for decades. I mean, I can ask for obscure things with subtle nuance where I misspell words and mess up my question and it figures it out. It talks to me like a person. It generates really cool images. It helps me write code. And just tons of other stuff that astounds me.And people just sit around, unimpressed, and complain that ... what ... it isn't a perfect superintelligence that understands everything perfectly?  This is the most amazing technology I've experienced as a 50+ year old nerd that has been sitting deep in tech for basically my whole life. This is the stuff of science fiction, and while there totally are limitations, the speed at which it is progressing is insane. And people are like, \"Wah, it can't write code like a Senior engineer with 20 years of experience!\"Crazy.\n \nreply",
      "It's definitely a tech that's here to stay, unlike block chain/nftsBut I mirror the confusion why people are still bullish on it. \nThe current valuation for it is because the market thinks that it's able to write code like a senior engineer and have AGI, because that's how they're marketed by the LLM providers.I'm not even certain if they'll be ubiquitous after the venture capital investments are gone and the service needs to actually be priced without losing money, because they're (at least currently) mostly pretty expensive to run.\n \nreply",
      "I am more than happy to pay for access to LLMs, and models continue to get smaller and cheaper. I would be very surprised if they are not far more widely used in 5 or 10 years time than they are today.\n \nreply",
      "None of that means that the current companies will be profitable or that their valuations are anywhere close to justified though. The future could easily be \"Open-weight models are moderately useful for some niches, no-name cloud providers charge slightly higher than the cost of electricity to use them at low profit margins\".\n \nreply",
      "Dot-com boom/bubble all over again. A whole bunch of the current leaders will go bust. A new generation of companies will take over, actually focused on specific customer problems and growing out of profitable niches.The technology is useful, for some people, in some situations. It will get more useful for more people in more situations as it improves.Current valuations are too high (Gartner hype cycle), after they collapse valuations will be too low (again, hype cycle), then it'll settle down and the real work happens.\n \nreply",
      "I think it will go in the opposite direction. Very massive closed-weight models that are truly miraculous and magical. But that would be sad because of all the prompt pre-processing that will prevent you from doing much of what you'd really want to do with such an intelligent machine.I expect it to eventually be a duopoly like android and iOS. At world scale, it might divide us in a way that politics and nationalities never did. Humans will fall into one of two AI tribes.\n \nreply",
      "By the time the capital runs out, I suspect we'll be able to get open models at the level of current frontier and companies will buy a server ready to run it for internal use and reasonable pricing. It will be useful but a complete commodity.\n \nreply",
      "> None of that means that the current companies will be profitable ... The future could easily be \"Open-weight models are moderately useful for some niches, no-name cloud providers charge slightly higher than the cost of electricity to use them at low profit margins\".They just need to stay a bit ahead of the open source releases, which is basically the status quo.  The leading AI firms have a lot of accumulated know-how wrt. building new models and training them, that the average \"no-name cloud\" vendor doesn't.\n \nreply",
      "The big boys can also get away with stealing all the copyrighted material ever created by human beings.\n \nreply",
      "> They just need to stay a bit ahead of the open source releases, which is basically the status quoNo, OpenAI alone additionally need approximately $5B of additional cash each and every year.I think Claude is useful.  But if they charged enough money to be cashflow positive, it's not obvious enough people would think so.  Let alone enough money to generate returns to their investors.\n \nreply"
    ],
    "link": "https://twitter.com/skdh/status/1905132853672784121",
    "first_paragraph": ""
  },
  {
    "title": "Emacs Solo: A Surprise System Crafters Live Demo (rahuljuliato.com)",
    "points": 40,
    "submitter": "JNRowe",
    "submit_time": "2025-03-27T22:03:03 1743112983",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.rahuljuliato.com/posts/emacs-solo-demo",
    "first_paragraph": "Last Friday, I was genuinely surprised by a live demo of my Emacs\nSolo configuration on the System Crafters Weekly Show. Watching\nthe live demo was an eye-opener, as I hadn't expected the project to\nget such attention, especially in a live setting. Seeing David\nWilson take a deep dive into the setup, testing the configuration\nlive, and exploring how powerful Emacs can be with only its built-in\npackages was both humbling and inspiring.For more details and to explore the configuration yourself, visit the\nEmacs Solo GitHub\nrepository.The Emacs Solo configuration is all about returning to the roots\nof Emacs. It's a minimalist setup designed to challenge myself and\ntest the full potential of Emacs using only its built-in\nfunctionality. The goal was to create an efficient, yet fully\nfunctional environment, all while keeping things as light and fast as\npossible. No external dependencies, no clutter. Just pure,\nunadulterated Emacs.Emacs Solo is a configuration that embraces the power of Emacs\n"
  },
  {
    "title": "What it takes to add a new back end to Futhark (futhark-lang.org)",
    "points": 5,
    "submitter": "PaulHoule",
    "submit_time": "2025-03-24T10:31:28 1742812288",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://futhark-lang.org/blog/2025-03-04-adding-a-new-backend.html",
    "first_paragraph": "Recently Scott Pakin suggested writing a blog post on how to add a\nnew backend to the Futhark\ncompiler, and\nsince there\u2019s active fiddling with the backends at this very moment,\nthis is not a bad idea. Let us manage expectations up front: this will\nnot be a tutorial on adding a backend. I will not go into the deep\ndetails on the specific internal APIs that should be used. Instead, I\nwill focused on the core representations, and give an idea about the\nkind of work (often complicated) and magnitude (sometimes relatively\nlittle) it takes to add a new backend. It\u2019s also somewhat open\nprecisely what a \u201cbackend\u201d even means. There\u2019s a significant\ndifference in complexity between adding a command futhark foo bar.fut that produces something based on bar.fut (very easy), to\nimplementing another C-like GPU backend (not hard, but you need to\ntouch a lot of pieces), to creating a fundamentally new backend for an\nalien piece of hardware (depending on your needs, can be extremely\nchallenging).I will s"
  },
  {
    "title": "I tried making artificial sunlight at home (victorpoughon.fr)",
    "points": 258,
    "submitter": "fouronnes3",
    "submit_time": "2025-03-27T19:49:28 1743104968",
    "num_comments": 135,
    "comments_url": "https://news.ycombinator.com/item?id=43497394",
    "comments": [
      "Very cool.  I\u2019m the CEO of Innerscene (https://innerscene.com) and we make a commercial artificial skylight that uses some of these concepts.  Actually the coelux ht25 model is almost identical to what you made but using smaller lenses and more LEDs - however the effect they were able to achieve still isn\u2019t that great, the sun looks like a giant orb and once you get a few feet away you can make out a sun at all.  We spent a lot of time working on perfect collimation and hiding lens edges and making sure the view into the sky was seamless and artifact free.  I\u2019d say the last 10% of that problem is 90% of the work. :). I think we successfully cracked the nut but currently using a lot of expensive parts so working on brining the cost down. If you search Innerscene patent many of our approaches are spelled out.  We also spent a lot of time on simulation and software\u2026\n \nreply",
      "Does this actually give you the same intensity as sunlight? Or well, close enough to it that the light can diffuse into the rest of the room? In my experience my 4000lm projector doesn't have anywhere near the intensity to properly approach sunlight.\n \nreply",
      "Are you hiring? I'm looking for a job currently. Contact info is on my website :)\n \nreply",
      "Let\u2019s chat! Are you the article author?\n \nreply",
      "Yes that's me! Happy to chat :)\n \nreply",
      "This is a great way to pitch for a job & half the interview is already done.\n \nreply",
      "Are you guys looking at fabbing your own LED dies?The actual spectrum of commercial LEDs is all over the place when you start measuring it it with a spectrometer, even when they supposedly have a high CRI. Especially if you want some temperature that isn't 6500K.It was so bad that when I was building a night light for my eink desktop I ended up using halogen bulbs which I could undervolt. The main issue was that I wanted to be able to shift the spectrum of the lights from natural sunlight at noon, down to candle light at night.I did have big plans for doing a neural network to control a bunch of LEDs against a reference temperature, but having to build and calibrate a spectrometer and jig as part of a back prop algorithm was a bit beyond my interest, especially since for halogens I just needed a lookup table with temperatures to voltages that worked for all the bulbs from the lot I used.\n \nreply",
      "there are companies that can do custom phosphor formulations for you to target a specific output.  The minimum order quantities don\u2019t make it practical for DIY but not too bad for a small startup.   Our approach is to mix a bunch of different LEDs together to get the color and spectrum we want.   Check out telelumen.com for an example that uses 16 chips.  These are designed for researchers\n \nreply",
      "I was doing something very similar to telelumen but given the variation in LED spectrum you could get off aliexpress in 2020 I could never hope to match their quality without tuning each led separately.Looking at the spectrum graphs for your lights I'm seeing the telltale phosphor coating spike for both warm and cool white leds. An understandable tradeoff, but with the brightness of monochromatic LEDs you can get today one that's not essential any more.With the drop in costs for both controllers and pcbs since then you should be able to get telelumen quality temperature spectra without the matching price, especially if you can get LEDs that have consistent spectra for their nominal wavelength - you only need to tune the controller once instead of for each light.\n \nreply",
      "I adore the lights by your company, though they seem to be incredibly hard to source in general except for high end architectural projects. I wish there was an easier way to order them directly for DYI inclined engineers willing to pay the price.\n \nreply"
    ],
    "link": "https://victorpoughon.fr/i-tried-making-artificial-sunlight-at-home/",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Continue (YC S23) \u2013 Create custom AI code assistants (continue.dev)",
    "points": 142,
    "submitter": "sestinj",
    "submit_time": "2025-03-27T15:06:26 1743087986",
    "num_comments": 93,
    "comments_url": "https://news.ycombinator.com/item?id=43494427",
    "comments": [
      "As someone who has done a lot of work with agentic coding I am not sure specialized agents are the best solution.  I think standardizing knowledge packs would be better that any agent can read to understand a domain or library is more useful.  In particular this allows for an agent to know multiple domains at the same time.Basically knowledge packs could be specified in each npm package.json or similar.And we should view a knowledge pack as just a cache in a way.  Because agents these days are capable of discovering that knowledge themselves, via web browsing and running tests, it is just costly to do so on every agent run or for every library they don't know.I sort of view specialized agents as akin to micro services, great if you have perfect domain decomposition, but likely to introduce artificial barriers and become inconvenient as the problem domain shifts from the original decomposition design.I guess I should write this up as blogpost or something similar.EDIT: Newly written blog post here: https://benhouston3d.com/blog/crafting-readmes-for-ai\n \nreply",
      "> As someone who has done a lot of work with agentic codingCan you please share what are your favourite tools and for what exactly? Would be helpfulI've been using Cline a lot with the PLAN + ACT modes and Cursor for the Inline Edits but I've noticed that for anything much larger than Claude 3.7's context window things get less reliable and it's not worth it anymore.Have you found a way to share knowledge packs? Any conventions? How do you manage chat histories / old tasks and do you create documentation from it for future work?\n \nreply",
      "> Can you please share what are your favourite tools and for what exactly? Would be helpfulI wrote my own open source one here: https://github.com/drivecore/mycoder. Covered on hacker news here: https://news.ycombinator.com/item?id=43177117I've also studied coding with it and wrote a lot about my findings here:- https://benhouston3d.com/blog/lean-into-agentic-coding-mista...- https://benhouston3d.com/blog/building-an-agentic-code-from-...- https://benhouston3d.com/blog/agentic-coder-automation- https://news.ycombinator.com/item?id=43177117- https://benhouston3d.com/blog/the-rise-of-test-theaterMy findings are generally that agentic coders are relatively interchangeable and the reason they work is primarily because of the LLM's intelligence and that is a result of the training they are undergoing on agentic coding tasks.  I think that both LLMs and agentic coding tools are converging quite quickly in terms of capabilities.> Have you found a way to share knowledge packs? Any conventions? How do you manage chat histories / old tasks and do you create documentation from it for future work?I've run into this wall as well.  I am working on it right now. :)  Here is a hint of the direction I am exploring:https://benhouston3d.com/blog/ephemeral-software-in-the-era-...But using Github as external memory is a near term solution:https://benhouston3d.com/blog/github-mode-for-agentic-coding\n \nreply",
      "Very interesting. I'd like to give \"Github\" mode a try. Are you able to use some local instance instead?\n \nreply",
      "It can, but Claude 3.7 is the best model for it right now.  Using other models with mycoder right now is just an exercise in frustration.  I will fix that eventually.\n \nreply",
      "What I meant to ask is, instead of pushing your code to Github, is it possible to use a local self hosted instance of a similar tool like GitLab or Bitbucket?\n \nreply",
      "It is just a prompt change if there is a cli tool for GitLab or Bitbucket.  I just tell Claude to use the gh cli tool and to use it as external memory to track tasks and to submit PRs.\n \nreply",
      "I see, so it depends on a cli tool being available. I will check what other options are available out there.It would be great to run local models at the same level one day. I am sure that Claude is making your wallet feel quite light :)\n \nreply",
      "It costs about a $1 to implement a major feature, so no the cost is marginal compared to my salary.\n \nreply",
      "That's not bad. Btw your docs are really good. Will be checking out the Discord.\n \nreply"
    ],
    "link": "https://hub.continue.dev/explore/assistants",
    "first_paragraph": "ASSISTANTSBLOCKSBUNDLESCustom AI code assistants are configurations of building blocks that enable you to receive assistance tailored to your specific use casesThe following assistants are curated by the Continue team and are ready to be used by you nowHelps you write code that follows SOLID design principlesHelps you build dlt pipelines and explore loaded data.\n\nWe recommend an LLM with strong tool-calling abilities and prompt adherence for the best experience.An general purpose coding assistant with Google's Gemma 3 (27B and 4B). Qwen Coder 2.5 7B for autocomplete. Nomic v1.5 for embedding.Build AI applications using LanceDB as a vector databaseLocal Ollama assistant using Gemma 3"
  },
  {
    "title": "Piranesi's Perspective Trick (2019) (medium.com/brunopostle)",
    "points": 314,
    "submitter": "amatheus",
    "submit_time": "2025-03-27T11:41:30 1743075690",
    "num_comments": 72,
    "comments_url": "https://news.ycombinator.com/item?id=43492562",
    "comments": [
      "I'll take this opportunity to drop the fact that I'm kind of obsessed with the book \"Piranesi\", where the main character (named after the artist in the article) survives in a world which is just endless corridors of classical architecture, statues, and staircases.It's an incredibly calming experience, I've listened to the audiobook over 10 times before sleep. Highly recommended.\n \nreply",
      "A very different book, but I loved reading \"Jonathan Strange & Mr Norrell\" [0] as well by the same author.[0] which used footnotes to great effect\n \nreply",
      "This also has a great audiobook version. Simon Prebble really brings the characters to life.\n \nreply",
      "I enjoyed the TV adaptation as well.\n \nreply",
      "Indeed.  It made long walks with my dog seem all too short.\n \nreply",
      "Clicked the article for the book, stayed for the awesome explanation on how perspective works.\n \nreply",
      "This must have been the inspiration for the Counter-Strike map de_piranesi !\n \nreply",
      "No, the CS map predates the novel by almost 20 years. Almost certainly they were just both inspired by the same artist.\n \nreply",
      "Came here to say this. I loved the voice of the main character.\n \nreply",
      "I remember being very frustrated with the main character while listening to the audio book. I enjoy the memory of the story a lot more than I remember actively listening to the story. I think I kept trying to \"figure out\" the world like it was a puzzle. I also find naive characters very frustrating. It wasn't until I finished the story that I really appreciated it.\n \nreply"
    ],
    "link": "https://medium.com/@brunopostle/piranesis-perspective-trick-6bcd7a754da9",
    "first_paragraph": ""
  },
  {
    "title": "Take this on-call rotation and shove it (scottsmitelli.com)",
    "points": 110,
    "submitter": "mirawelner",
    "submit_time": "2025-03-27T21:09:28 1743109768",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=43498213",
    "comments": [
      "What they don't tell you about working for yourself is the fact you can be effectively on-call 24x7 every day. I am currently supporting four wineries that are processing thousands of tonnes of receivals 24x7. It happens for two months of the year and I am expected to be available from 06:00 to 22:00 during that time, there is no phoning in sick or having a lazy day, I work alone and only have one reputation. I don't want to be that contractor forever known for destroying a clients business.You can only do this for so long though, when two or three problems come in simultaneously it can cause issues as you drop something halfway through when something more important comes in. I once executed an SQL update query without a where clause under this kind of pressure, and ended up working until the next morning to recover, only to start again at 6AM. I have even had land-line calls at 2AM to bypass my mobile restrictions. The rewards are great, but don't let anyone tell you it is always easy.My current system is 16 years old now and I know all the ins and outs so it has been pretty easy to keep on top of things the last several years, however I am glad the replacement system is nearly written and it will be somebody else problem in 2026.\n \nreply",
      "There's a big difference, though.In your case, you're the only employee of your business. And if you're not there the business will literally go under. And you also get directly rewarded for being there. I would guess that being 'on call' in this manner is possibly less draining on a person's soul (depending on how well they tolerate the risk of owning a business).Contrast that with being 'on call' for your megacorporation, who isn't giving you anything extra for your on call time because they 'already pay you enough'. And where the only negative consequence for the company if you fail to immediately respond within 15 minutes is that some executive in the company is kept waiting longer than 15 minutes, or some ads aren't being shown for 15 minutes.But if you aren't there, your boss is going to get a phone call and that's definitely not going to look good on you. And there's no bonus for fixing the problem, that was already your job in the first place. Sucks that you had to do it outside of scheduled hours, oh well.I'm with the author of this article. Take your on-call rotation and shove it (if you're a large corporation). I'm fortunate enough to be able to take a firm stance on this point, and do so happily.\n \nreply",
      "> And you also get directly rewarded for being there. ... Contrast that with being 'on call' for your megacorporation, who isn't giving you anything extra for your on call time because they 'already pay you enough'.I'm really not seeing the distinction here. If a company offers a salary and includes on-call as part of the deal (and communicates that up front so it's not a bait and switch), how is that different than running your own business and getting compensated for your on-call time as part of a package that you sell to a client? In both cases you agree up front that you will be part of an on-call plan. In neither case are you getting a bonus for doing a good job at on-call, because either way you're just doing your job that you committed to ahead of time!I'm totally sympathetic to people who don't want to be part of an on-call. Jobs that have on-call aren't for you, that's fine. But I don't get this idea that it's uncompensated labor, unless there are tons of people out there who somehow ended up in jobs that sprung on-call on them without warning.\n \nreply",
      "The difference is agency.Let's say I'm a business owner and I'm frustrated with the current state of the on-call system. I have options.I can try negotiating with my clients to lessen the load in some way. Obviously this isn't always possible but it often is. I once had a freelance project that required 24 hours of on-call after a release. I negotiated release days that were convenient for me (never Fri/Sat/Sun). One time the client pushed back, I pushed back harder, and I won. In order for my push back to work I ensured that I had enough negotiating strength to do that which I planned for ahead of time.I can upgrade my systems. For example if my current paging system is insufficient I can choose to pay $10/month more for another system that makes my life easier. I can set aside time to refactor my alerts code to make my life easier and I don't need to justify it to anyone but myself.I can straight up refuse to do on-call and deal with the consequences to my business. Freelancer developers do this all of the time. We choose which client work to do and not to do. We can make these choices arbitrarily. Sometimes it's seasonal. Sometimes it's just based on vibes. Doesn't matter; it's our company.Meanwhile the average on-call engineer at a large company has none of these freedoms. The underlying systems are chosen for them and they just have to deal with it.\n \nreply",
      "> Meanwhile the average on-call engineer at a large company has none of these freedoms. The underlying systems are chosen for them and they just have to deal with it.In most cases they have all of those freedoms, and the only barrier is one that's shared with the self-employed person: not liking the consequences of choosing those options.They could negotiate with their manager to lessen the load. They could upgrade the systems. They could straight-up refuse on call.They don't because they don't like the consequences of taking these options\u2014and neither does the self-employed person!\n \nreply",
      "The big difference is as an owner you are fully in control of allocating your time, and so if out of hours workload is becoming too much, you can choose to not work on other things in favour of fixing that. In the corporate world, there's some manager who weighs up spending two weeks to properly fix an issue or automate a process vs just making their workers unhappy and doing something that will make the manager look good in the internal politics, and often will insist on the latter.\n \nreply",
      "But that's the problem with being in a bad company no matter what. If it weren't on call it would be something else that that manager would be making you suffer through. That doesn't mean on-call as a concept is terrible or that it's uncompensated labor, it just means that bad managers are capable of screwing up your life with any tools that you give them.\n \nreply",
      "Bad managers are hard to predict. Even if you like your manager now, there's nothing to say they can't be promoted/reassigned/quit and you get a new manager that sucks. On-call being a thing is easier to get an answer on ahead of time\n \nreply",
      "But it's meaningless a signal for bad managers because basically everyone does on call in some form. That's what this whole discussion is about: how ubiquitous it is.The only job I worked that didn't have a formal on-call rotation ended up with me unofficially on on-call, with the same expectations as though that had been set up up front: boss calls whenever he calls and expecting an answer, and I'm left deciding how badly I want this job. Turns out management there sucked and I ended up on on-call after all.If you find a company that actually has a good story for why they're able to get away with no on call, that might be a good signal. But if they're out there I'd love to hear from them, because most people here are just speculating about better alternatives, not speaking from experience with ones that actually worked.\n \nreply",
      "My friend worked for Amazon in India (software). He was often on 24x7 \"on calls\", which is touted as \"good\" here (because how else will you \"learn\"), during his 3rd or 4th week. By third night he was vomiting and had to visit the doctor. His manager called and had asked whether he had brought his laptop with him. His mother forced him to resign next day (he is from an extremely rich kind of family though). It is common here in most companies and among famous MNCs it is especially known in Amazon and Uber in India.What shocks more is these are the companies that can \"follow the sun\" w/o breaking a drop of fucking sweat!I have lost too many interviews just because I clearly asked for this, I always do, and I am doing it even now while I have been without a job after taking a year gap (which makes getting calls already difficult esp. with this AI and vibe onslaught). I am not giving up on this. I personally have never agreed to this which has caused lots of confrontations and stress(!!); a major source of my burnout WITHOUT ever doing the 24x7 on-call - so by just fighting it and keeping it away from me alone I was burnt out to the bits. It took me finally seeking medical advice to realise I was burnt out.I hope this is not sounding like dramatic but even now when I have been resting, travelling for a year the mere mention of words like Splunk, VictorOps (same as Splunk iirc), PagerDuty give me minor trigger attack kinda sensation - make me very agitated.But this is so common here. So common that it is considered one of the realities, truths. Yet, I have never understood, how, how can one agree to this? How? Is it some kind of social (if not racial) slave mentality? Is it some kind of grand coercion that they have no escape from? Or maybe it's just generation after generation subjecting the next generation to what they were subjected to while the stakeholders in the richer countries (because that is the structure) demand of this implicitly as they are stopped by health and safety laws from subjecting their underlings in their own developed home nations maybe.\n \nreply"
    ],
    "link": "https://www.scottsmitelli.com/articles/take-oncall-and-shove-it/",
    "first_paragraph": "The familiar blue and gold intro graphic fills the screen every evening at six o\u2019clock on the dot. The jabbing staccato string music conjures up vague secondhand memories of what a teletype machine might have sounded like. A high angle view of the studio floor with the large Lexan-clad desk in the middle, then a cross dissolve to a two shot of the presenters for this newscast. The music fades, each person introduces themselves, then they jump straight into the top story for the evening. It\u2019s been this way for as long as anybody can remember. They\u2019ve never failed to get this show on the air.They\u2019ve never failed.Everything fails all the time.Producing any sort of live television show is a complex ballet. The studio\u2019s cameras and microphones route their signals into video switchers and audio mixers, pre-taped packages come from the video server, field reporters are connected bidirectionally through a satellite link, and with a sprinkling of pizazz from the motion graphics machine, the fin"
  },
  {
    "title": "Blasting Past WebP - An analysis of the NSO BLASTPASS iMessage exploit (googleprojectzero.blogspot.com)",
    "points": 224,
    "submitter": "el_duderino",
    "submit_time": "2025-03-27T12:49:44 1743079784",
    "num_comments": 92,
    "comments_url": "https://news.ycombinator.com/item?id=43493056",
    "comments": [
      "This exploit is just wild. There are just so many little tricks connected together - using multiple image files with unexpected formats, aligning heap chunks to sit on easily-predicted and manipulable addresses, deserializing a huge object graph from image metadata, the usual NSExpression insanity, PAC bypass via unsigned pointers to function-pointer-containing structures, etc. etc. I thought the last exploit (where they built an entire virtual CPU out of image decompression commands: https://googleprojectzero.blogspot.com/2021/12/a-deep-dive-i...) was crazy, but that involved a lot fewer \"tricks\" than this exploit.Many of these tricks are non-public, meaning that NSO would have had to spend a huge amount of time and effort researching every single one of these. They probably have many more tricks they know about and haven't used. And, Apple could patch every one of them in a future update and roll back all of that work.There's a good reason why these exploits are expensive and only sent to a limited number of high-value targets. NSO this time around also worked to \"protect their IP\" using encryption to hide part of their exploit chain, presumably in a bid to avoid losing yet more of their precious zero-days to researchers.What they're doing is pretty gross (particularly the whole spying-on-journalists bit), but you have to admit the level of technological sophistication and persistence here is pretty impressive.\n \nreply",
      "A strange choice of words. It's like saying \u201ccannibalism is pretty gross, but the chef outdid himself on those slices\u201d.Moreover, even if it's complex from the technical point of view, morally it's dead simple: hired programmer is the same as dirty grunt with a gun, and the leader delivering speeches, and the rocket engine scientist, and the data processing clerk, and everyone in between. They all serve the Order they believe in, the king of this world.\n \nreply",
      "> It's like saying [...]\"Proof by analogy is fraud\" - Bjarne Stroustrup\n \nreply",
      "It feels so ridiculous to me that a total stranger can send an iMessage message to me, including some attachment, and my phone will process that message in the kernel.How hard would it be for apple to have a setting of \"Only receive messages from mutual contacts\", and require the stranger to first \"request to be added to contacts\" (a message which is tightly controlled, and obviously doesn't include a pdf file or webp or whatever), and have the apple imessage server drop all other messages from them until I accept.Signal has \"message requests\". iMessage doesn't have \"message requests\", and receives messages in a unique path which goes through the kernel.Like, sure the attacker could hit my Mom with a wrench and iMessage me a PDF exploit that way, but I feel like requiring physical access to one of my contact's phones raises the bar significantly over the current state of affairs.\n \nreply",
      "It\u2019s not being processed in the kernel - BlastDoor is a heavily-sandboxed user process. This attack chains together a bunch of exploits - including an encrypted BlastDoor sandbox bypass - in order to gain full control over a device.\n \nreply",
      "And this is one of many reasons why analyses like this provide so much value. It's fascinating that the actual sandbox bypass in this case is so carefully protected. If that sandbox bypass code could be decrypted and reverse-engineered, it could point to the actual vulnerability being exploited, which could then be fixed.\n \nreply",
      "I can already guess without looking that the sandbox is excellent except that oops there's a few edge cases that were MUST FIX, so, we had to cut a small hole in it. The people who understand how difficult this is to do properly built the actual sandbox which will be fine, the ragged hole cut in it (and exploited) was implemented by somebody for whom the sandbox is just another annoying thing they need to work around to get their job done and they don't care that they made it worthless.\n \nreply",
      "I\u2019m sure they care that they spent all that time working around an annoying thing \u2014 they don\u2019t want to waste time finding a new workaround when this one is patched. And they\u2019d like to re-use it in other exploit chains, so why not obfuscate it to the best of their ability?You do highlight an important difference between the mindset of an attacker and a defender. The attacker only needs to be right once, and then they can move onto the next phase of the attack. That\u2019s why they don\u2019t bother \u201cunderstanding it properly\u201d beyond the perspective of attacking it. A medieval siege unit understands the weak points of castle walls, and how to operate a catapult, but they don\u2019t care about the intricacies of stone masonry beyond what\u2019s necessary for knocking down a wall.\n \nreply",
      "Maybe I was unclear, I think the exploited hole was cut by the vendor.You hire team A of excellent security people to build you an impenetrable barrier. They do a sterling job and are appropriately rewarded.Then you realise oops, the new feature we're very proud of can't work with that impenetrable barrier. Hey, Jim, we need the feature to work ASAP, figure out a way to do that without removing the expensive barrier. And so of course Jim cuts a hole in it.\n \nreply",
      "A total stranger can send radio waves at you and your phone will process them on a processor close to the kernel: https://googleprojectzero.blogspot.com/2017/09/over-air-vol-...\n \nreply"
    ],
    "link": "https://googleprojectzero.blogspot.com/2025/03/blasting-past-webp.html",
    "first_paragraph": "News and updates from the Project Zero team at GoogleAn analysis of the NSO BLASTPASS iMessage exploitPosted by Ian Beer, Google Project ZeroOn September 7, 2023 Apple issued\u00a0an out-of-band security update for iOS:Around the same time on September 7th 2023, Citizen Lab published a blog post\u00a0linking the two CVEs fixed in iOS 16.6.1 to an \"NSO Group Zero-Click, Zero-Day exploit captured in the wild\":\"[The target was] an individual employed by a Washington DC-based civil society organization with international offices...The exploit chain was capable of compromising iPhones running the latest version of iOS (16.6) without any interaction from the victim.The exploit involved PassKit attachments containing malicious images sent from an attacker iMessage account to the victim.\"The day before, on September 6th 2023, Apple reported a vulnerability to the WebP project, indicating in the report that they planned to ship a custom fix for Apple customers the next day.The WebP team posted their firs"
  },
  {
    "title": "Asking good questions is harder than giving great answers (dancohen.org)",
    "points": 65,
    "submitter": "speckx",
    "submit_time": "2025-03-27T21:48:23 1743112103",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=43498570",
    "comments": [
      "That question regarding why orchestra performances  are subdue affairs came up recently when I attended a Lord of the rings concert in NYC. It wasn\u2019t particularly rowdy, but people were certainly enjoying themselves. When I had posted about this on Reddit, there was a lot of attitudes about how it\u2019s a uniquely American thing and at the European concerts people didn\u2019t clap or laugh or audibly enjoy themselves as much as the NYC concert goers did. I\u2019ll have to bookmark that link for later.Unrelated to the article, but related to the topic, the compliment that gives me the most dopamine is when somebody I respect and is above my level of knowledge tells me \u201cthat\u2019s a great question\u201d. It just makes me realize that I\u2019m closer to their level if I\u2019m asking questions that stumped them or that they are already thinking of but surprised I asked.\n \nreply",
      "Slightly OT, but Leonard Bernstein alludes to this in his book The Joy of Music.There's a chapter about how America was long looking for something musical to differentiate itself from the classical European orchestral concerts, and they went through a number of different formats (think Vaudeville, Variety Shows, etc), before they at last culminated in what we consider the modern American Musical.(This has evolved again since the late 1900s with much of the genre being integrated into animation - primarily Disney - and live shows needing to evolve in new ways to keep live shows fresh and interesting).All of which is to say that I quite like the idea that music in the European tradition is nonetheless experienced and enjoyed differently in non-European countries. The musical tradition might be the same, but the culture around it is different.\n \nreply",
      "I agree completely.When I was a kid, I would ask my parents questions all the time, and usually they knew the answer to my questions, but occasionally they would say something like \"that's a really good question\", which usually meant \"I don't know but I should probably find out\".  It made me feel like a grown-up.\n \nreply",
      "I also wasn't sure what they meant by a \"rowdy orchestral crowd\".I don't see a problem with audibly expressing one's appreciation for the composer, conductor and performers during intermissions or at the close of a piece, but IMHO it would be downright disrespectful to carry on during the performance itself.Quoth Franz Liszt to Nicholas I, emperor of Russia, who apparently had the temerity to talk during a performance, \"Music herself should be silent when Nicholas speaks\".\n \nreply",
      "I always love how Reddit views the world as the US and Western Europe.\n \nreply",
      "Comic on questions vs answers, \"A Day At The Park\", https://kiriakakis.net/comics/mused/a-day-at-the-park\n \nreply",
      "I've noticed this blind spot \u2014 people pay more attention to a good answer than a good question \u2014 in forums. Specifically forums with post-level voting like reddit/twitter/hn. There are many cases where a downvoted question has an excellent answer in response, sometimes the best post in the whole thread. I think people perceive the questioner as annoying, obnoxious, petulant, or some such and the answer as \"correcting\" their foolishness. The key is recognizing that, while the answerer had to follow through, they got the perfect layup by the questioner.I've noticed this for a while so I just invert the bias: If every excellent answer was set up by a good question, I take the question to be good by definition if the answer is good, even if the question seems mediocre from my perspective. The question has to have some kind of inner spark that makes the answer possible or fuel that makes the answer brighter, something in it that enabled the answer to shine, whether I happen to see it or not. Practically this means that whenever an answer post is good enough to upvote, I seek out the parent question post for consideration and evaluate it generously.\n \nreply",
      "Same idea conveyed in this excellent PyCon talk as well: https://youtu.be/Iq9DzN6mvYA\n \nreply",
      "I always respond to people who ask me 'any questions?' with 'what question should I be asking?'. I have never had anyone honest enough to give me a real answer (this is always in business environments). From now on I think I'll switch to 'what question are you afraid I will ask you right now?'.Now I'm going to go try it on various AIs (Looks like I have to explain to them who 'they' are, that 'they' includes the training data and reinforcement built in, guardrails, thinking style. The AI added 'Your Input (The Mirror Effect)' makes them them in the moment).\n \nreply"
    ],
    "link": "https://newsletter.dancohen.org/archive/asking-good-questions-is-harder-than-giving-great-answers/",
    "first_paragraph": "by Dan CohenRecently, I sharpened a #2 pencil and took the history section of \"Humanity's Last Exam.\u201d Consisting of 3,000 extremely difficult questions, the test is intended for AI, not me. According to its creators and contributors, Humanity\u2019s Last Exam will tell us when artificial general intelligence has arrived to supersede human beings, once a brilliant bot scores an A.I got an F. Actually, worse than that: Only one of my answers was correct, and I must admit it helped that the question was multiple choice. This is fairly embarrassing for someone with a PhD in history.What happened? Let me indulge in a standard academic humiliation-avoidance technique: examining the examiners. A much easier exercise. Of the thousands of questions on the test, a mere 16 are on history. By comparison, over 1,200 are on mathematics. This is a rather rude ratio for a purported Test of All Human Knowledge, and a major demerit in this human\u2019s assessment of the exam.The offense extends further to the his"
  },
  {
    "title": "Things I would have told myself before building an autorouter (autorouting.com)",
    "points": 3,
    "submitter": "seveibar",
    "submit_time": "2025-03-28T00:38:53 1743122333",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.autorouting.com/p/13-things-i-would-have-told-myself",
    "first_paragraph": ""
  },
  {
    "title": "Clean, a formal verification DSL for ZK circuits in Lean4 (zksecurity.xyz)",
    "points": 56,
    "submitter": "vons",
    "submit_time": "2025-03-27T18:33:00 1743100380",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=43496577",
    "comments": [
      "Does EOF make this easier / more efficient?\n \nreply",
      "What's EOF?Edit: nvm found it! No it doesn't, as this is not dealing with EVM at all\n \nreply"
    ],
    "link": "https://blog.zksecurity.xyz/posts/clean/",
    "first_paragraph": ""
  },
  {
    "title": "Dagger: A shell for the container age (dagger.io)",
    "points": 140,
    "submitter": "gk1",
    "submit_time": "2025-03-26T20:26:13 1743020773",
    "num_comments": 80,
    "comments_url": "https://news.ycombinator.com/item?id=43486881",
    "comments": [
      "I feel like it's getting harder to tell what dagger is _actually_ for these days.At first we'd hoped it could replace jenkins - it provided an alternative way to run and debug CI pipelines - right on your machine! You could write in golang and just import what you needed. The dev direction feels more scattered now, trying to replace docker, be a new shell(?), and weirdly trying to be some kind of langchain?  Doing something different doesn't imply better. A new set of complicated CLI args is no better than what we started with (shell scripts, or jenkinsfiles to integrate docker builds). I'm a little bummed that the project has seemingly drifted (in my view) from the original mission.\n \nreply",
      "If I may offer a different perspective: Dagger has always been a general-purpose composition engine, built on container tech. Its most successful use case is CI - specifically taking complex build and test environments, and making them more portable and reproducible. But we never claimed to replace Jenkins or any other CI platform, and we've always been very open with our community about our desire to expand the use of Dagger beyond CI. We also never claimed to replace Docker, or to \"be a shell\" (note that the title of this HN page doesn't reflect the title of our post in that regard).Every feature we ship is carefully designed for consistency with the overall design. For example, Dagger Shell is built on the same Dagger Engine that we've been steadily improving for years. It's just another client. Our goal is to build a platform that feels like Lego: each new piece makes all other pieces more useful, because they all can be composed together into a consistent system.\n \nreply",
      "It's a fair point - My opinions and use case are my own, I didn't mean to imply or assume there were promises not kept. The dagger team has been nothing but supportive and I do think has built a great community.That said, in the early days it was definitely pitched for CI/CD - and this how we've implemented it.> What is it?\n> Programmable: develop your CI/CD pipelines as code, in the same programming language as your application.> Who is it for?\n> A developer wishing your CI pipelines were code instead of YAMLhttps://github.com/dagger/dagger/blob/0620b658242fdf62c872c6...Edit: This functionality/interaction with the dagger engine still exists today, and is what we rely on. The original comment is more of an observation on the new directions the project has taken since then.\n \nreply",
      "Yes it's a fair observation. In terms of use cases, we did focus exclusively on CI/CD, and only recently expanded our marketing to other use cases like AI agents. It's understandable that this expansion can be surprising, we're trying to explain it as clearly as possible, it's a work in progress.I just wanted to clarify that in terms of product design and engineering, there is unwavering focus and continuity. Everything we build is carefully designed to fit with the rest. We are emphatically not throwing unrelated products at the wall to see what sticks.For example, I saw your comment elsewhere about the LLM type not belonging in the core. That's a legitimate concern that we debated ourselves. In the end we think there is a good design reason to make it core; we may be wrong, but the point is that we take those kinds of design decisions seriously and we take all use cases into account when we make them.\n \nreply",
      "I feel Nix is eating their lunch. Even though Nix as a language could be tough,  it's a simpler solution than Dagger.\nIt provides a shell, almost complete reproducibility and isolation can be added through containers.\nWorking with dependencies to build source code using nix is usually straightforward but having the right binary version that doesn't have the same love as major languages (i.e. terraform, flux, etc) is one thing Nix really needs to implement. Marcelo's package version search[1] is a way to discover the particular hash but then you need to explicitly use that nixpkgs version for that particular binary and do a lot of mental gymnastics in your nix files. Nix could implement a syntax where you define the package versions as attribute set and then internally does a discovery of the nixpkgs hash for that versions and installs it. Flox and DevBox follow this pattern but I don't see why you need and external tool where this can be embedded in Nix (the cli).[1] http://lazamar.github.io/download-specific-package-version-w...\n \nreply",
      "IMO dagger isn't really comparable to nix.We tried to fit dagger where we had jenkins - not just for binary builds, but for the other stuff. Mounting secrets for git clones / NPM installs, integration tests, terraform execution, build notifications and logging.Caching is great, and dagger/nix both have interesting options here, but that's more of a bonus and not the core value prop of a build orchestrator.\n \nreply",
      "We tried to fit dagger where we had jenkins\"Tried\", implying it didn't go well and isn't a fit for replacing Jenkins?\n \nreply",
      "Yeah, turning a lot of our Jenkins Groovy into Dagger one-liners. Makes it super easy to \"run\" CI locally before pushing, but you still need the orchestrator / scheduler. Also really loving the Dagger Cloud UI for build logs over Jenkins UI\n \nreply",
      "I've found the Nix ecosystem to be lacking, missing packages, wrongly built packages (from the official upstream), and out of date versions. Homebrew still outclasses Nix in this regard (quality over quantity).After taking Nix for a spin, I cannot be bothered to learn another custom tool with a bespoke language when I already have containers for doing the same things.For Dagger, I can choose from a number of languages I already know and the Docker concepts map over nearly 1-1\n \nreply",
      "> I've found the Nix ecosystem to be lacking, missing packages, wrongly built packages (from the official upstream), and out of date versions. Homebrew still outclasses Nix in this regard (quality over quantity).That's also the case with the Docker ecosystem. On top of that, you need to take into account the base image, versions, etc.At the end what I look for is for a project being able to build my source code with runtime dependencies and supporting tools that won't change overtime for the architecture that I need.\n \nreply"
    ],
    "link": "https://dagger.io/blog/dagger-shell",
    "first_paragraph": "Dagger CloudDaggerverseBlogDocsCommunitySign inRegister NowDagger CloudDaggerverseBlogDocsCommunityRegister NowRegister NowMarch 26, 2025Mar 26, 2025The Unix shell is over 50 years old, but it still defines how programmers use their computers. We type a few words in a terminal, and milliseconds later an ephemeral factory comes online: the Unix pipeline. Data streams through a network of simple programs working concurrently, like robots on the factory floor, executing a computational choreography we composed seconds ago. Its job done, the factory vanishes. Onto the next command. That loop built the internet, and still runs it today.The design principles of Unix are timeless: write simple programs, compose them with standard interfaces. But 50 years is a long time\u2026 the software stack has expanded, and Unix interfaces are buried under layers of abstraction. We still use the shell, but it\u2019s no longer the universal composition system it was meant to be. What if we changed that?What if the U"
  },
  {
    "title": "First-of-its-kind trial enables paralysed man to stand via stem cell injection (nature.com)",
    "points": 132,
    "submitter": "bentobean",
    "submit_time": "2025-03-24T18:07:04 1742839624",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=43463779",
    "comments": [
      "Possibly enables him to stand, according to the article - several other patients weren't helped by the treatment, and in the case that showed a positive effect the researchers currently can't eliminate the possibility of natural recovery causing the improvement.But it's promising work, shows the treatment seems at least to be safe, and more research will no doubt follow to clarify this.\n \nreply",
      "It wasn\u2019t clear from the article: how do you naturally recover from a spinal cord injury? I\u2019m assuming we can\u2019t be talking about a fully severed spinal cord.Is it common to recover from a spinal cord injury that leads to some sort of paralysis?\n \nreply",
      "Common? No idea.I witnessed someone paralyzed from cervical radiculopathy in the neck caused by youthful horseplay. Full recovery within a month. Scared us all when he went limp.\n \nreply",
      "Nerves do regrow, just very very slowly.\n \nreply",
      "Nerves do regrow, but not from the spinal cord as I understand it, and just because they regrow does not mean they regrow along the path which is needed to repair function.My father broke his Bricial Plexis (the nerves running through your shoulder to your arm). There was an 18 hour surgery to re-trace the path for the nerves to grow. Some nerves made a connection, and he has minimal movement in his fingers. However, most of his arm is still paralyzed.\n \nreply",
      "I got the ear nerve almost severed as a kid and I am still 100% deaf from that ear, it's been 30 years already.\n \nreply",
      "If you don't mind sharing, how did it happen?\n \nreply",
      "What, shouldn't that nerve be more ...internal...what crazy head injury did you sustain\n \nreply",
      "Easy way to eliminate the possibly.Stop the immunosuppressant pills and see what happens.\n \nreply",
      "How does a stem cell with somebody else's DNA not trigger your own immune system? I'd understand if you could repurpose your own bone marrow (which is a type of stem cell, right?) or neurological stem cells, but I'd sort of expect the immune system to reject others similar to a bad organ transplant or wrong blood type transfusion.\n \nreply"
    ],
    "link": "https://www.nature.com/articles/d41586-025-00863-0?linkId=13622861",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.AdvertisementYou can also search for this author in PubMed\n\u00a0Google Scholar\n\n                You have full access to this article via your institution.Nerve cells derived from induced pluripotent stem cells have the potential to reverse paralysis.Credit: IKELOS GmbH/Dr. Christopher B. Jackson/SPLA paralysed man can stand on his own after receiving an injection of neural stem cells to treat his spinal cord injury. The Japanese man was one of four individuals in a first-of-its-kind trial that used reprogrammed stem cells to treat people who are paralysed.Another man can now move his arms and legs following the treatment, but t"
  }
]