[
  {
    "title": "IMG_0416 (ben-mini.github.io)",
    "points": 693,
    "submitter": "bewal416",
    "submit_time": "2024-11-10T20:45:33 1731271533",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=42102506",
    "comments": [
      "The website http://astronaut.io/ does a similar thing but for recent videos, and not just from iPhones. From the home page:> These videos come from YouTube. They were uploaded in the last week and have titles like DSC 1234 and IMG 4321. They have almost zero previous views. They are unnamed, unedited, and unseen (by anyone but you).At one point you might be at a school recital in Malaysia, and the next minute you are at a birthday in Ecuador. It's amazing!\n \nreply",
      "There's something magical when one location becomes the default for something. A site like this would be impossible if YouTube wasn't the place for videos.It's why I'm sad that we no longer have one obvious default for microblogging. It was such a rich source of thoughts. That's all gone now.\n \nreply",
      "And the former default is no longer developer friendly. (Or friendly to anyone else, really.)\n \nreply",
      "There were a bunch of subreddits based on obscure videos with default filenames.https://old.reddit.com/r/IMGXXXX/\n \nreply",
      "I love astronaut.io! Open it in an incognito window so that your YouTube watch history doesn't get too crazy.\n \nreply",
      "I just opened it in incognito in Chrome on Androidnoticed that the YouTube videos continue playing without interruption even when I switch to another tab or minimize chrome altogether and switch to another app.how can we harness this power to play our favorite audio tracks in background (without any ads to boot ... shhh don't tell Google)I also notice that the website triggers a browser warning when loading that it is not secure.\n \nreply",
      "There was an iOS app that used to let you do this; it would play music via Youtube embeds in a hidden web view, exposing its own UI for all the functionality you'd expect from a music streaming app.Whether this was legal is... a gray area, it was a somewhat legitimate company that won some kind of  Canadian startup contest on TV, but the music industry was, very predictably, furious at their business model.Eventually, Apple got scared enough of being sued along with them that they caved in and removed the app, but that took far longer than I thought it would.There's a good article at https://torrentfreak.com/apple-removes-parasitic-streaming-a...\n \nreply",
      "On Android you can use NewPipe for a similar experience. For obvious reasons it's not on Google's Play Store, but you can get it from F-Droid or Github.\n \nreply",
      "There are browsers extensions for this. I can't recommend one because I don't use this anymore. On Android this would mean using Firefox or another browser allowing extensions. Or you can give a YouTube address to MPV with the --no-video parameter. Or use NewPipe or one of its forks and open the YouTube kink with it in audio only mode. Or use invidious, but this last option is harder and harder to use. Or yt-dlp -x to download the audio of course.\n \nreply",
      "Background playback just works with Firefox on Android with no extensions required.\n \nreply"
    ],
    "link": "https://ben-mini.github.io/2024/img-0416",
    "first_paragraph": "November 3, 2024Between 2009 and 2012, Apple iPhones and iPod Touches included a feature called \u201cSend to YouTube\u201d that allowed users to upload videos directly to YouTube from the Photos app.The feature worked\u2026 really well. In fact, YouTube reported a 1700% increase in total video uploads during the first half of 2009- crediting that growth to its strong integrative ties to Apple and social networks. However, this two-click upload feature was short-lived when Apple severed ties with YouTube by removing its homegrown app in 2012.While Send to YouTube can be thoroughly analyzed as a milestone on the \u201cfrenemy\u201d timeline between Apple and Google, I want to explore a pleasant consequence of this moment. Apple uses the \u2018IMG_XXXX\u2019 naming convention for all images and videos captured on iOS devices, where XXXX is a unique sequence number\u00b9. The first image you take is named \u201cIMG_0001\u201d, the second is \u201cIMG_0002\u201d and so on. During the Send to YouTube era of 2009 and 2012, the title of one\u2019s YouTube "
  },
  {
    "title": "Procrastination and the fear of not being good enough (swapnilchauhan.com)",
    "points": 329,
    "submitter": "swapxstar",
    "submit_time": "2024-11-10T17:23:59 1731259439",
    "num_comments": 140,
    "comments_url": "https://news.ycombinator.com/item?id=42101327",
    "comments": [
      "I suffered from this.The issue is the ego. Ego has a lot of ideas about itself and others. Ego has such high opinion about itself it only can do great work. Which prevents it from doing anything. It's kind of a way of avoiding failures. Because failures will break the grant ideas about himself OP has created.I accidentally went through a spiritual awakening which diluted ego. I have no problem in doing any kind of work now. Whether it's great or petty.OP needs to work on the ego. Or figure out a situation where OP has to ship things no matter what. Which is hard unless you are jobless and can't figure a way out apart from building useful things that people pay for.\n \nreply",
      "I know it\u2019s a bit of a personal question, but can you elaborate on your ego diluting experience?\n \nreply",
      "I think it would be really hard to understand without experiencing it. But I will write down anyway.So before dilution I had this strong idea of who I was. I had this back story. There were certain things I do. And certain things I don't do. I used to judge everyone. I had a very high opinion about myself and used to constantly do or find things to validate that.Now I don't have a story in which I live on. Each and every moment is intense. Sunsets are absolutely beautiful that you cannot describe through words. Spending time in nature is surreal. You do the right thing instead of doing things to validate your narrative. The dopamine hit I used to get when I used to do certain things is gone( i use to confuse these dopamine hits as me doing something right). This unlocks doing things more from Intuition and less from memory. There is less fear. There is more flow. More creativity. No regard for authority  or beliefs. Everyone is equal. You want to know and not believe.That said it's not all great stuff. You also have to work through some existential questions which you were previously isolated by the ego. Like mortality. Impermanence of everything. Aging body. What happens after death. Nature of awareness. Why I am aware. Is awareness eternal and it's implications etc etc.\n \nreply",
      "> Now I don't have a story in which I live on.Lately, I've had this intuition that we change by sort of tricking ourselves. The mechanism for that change is by settling on like this one kind of character, like someone out of a movie that\u2019s playing in your head, and acting like that person. Then, as time passes, we simply forget who we were before we started acting and the only way we know how to act is as this one character.You say you've lost your 'story' and your 'character', that you don't 'act' anymore.But, it just feels like you've made another story and another character for you to fit into. You've got a new aesthetic, a new ideal, and your appreciating sunsets and nature is another thing you do because that's what the 'character' you try to fit would do.And by acting like that person in your head would, you start to feel the same way too.I think it's a lot more complicated than how I'm thinking. But I really do have a strong intuition that people feel the way they think the person they're acting like should feel, when physical feelings are non-factors.Really, I don't actually know. Like, what we actually do and what we say we do; what we actually think and what we say we think. What we say we do and think feel like things we're saying to trick ourselves into doing and thinking those things. That's I guess the core of my intuition.\n \nreply",
      "In my humble opinion, the experience is more one of realizing you've been acting and not having to identify so much with the character you are playing.It's hard to describe, because you're still doing the act, just some part of you realizes the unimportance of it.And some of that realization shines through in the act itself, in your character.\n \nreply",
      "Did you experience this or are you guessing?Because I think you are thinking this again through ego.I don't have a thought that I appreciate sunset when I see one. The sunset looks magical. There is a shift in experience. Before watching sunset was like watching in 420p. Now it's 4k. The consciousness is heightened. You only see the sunset. You don't think of old memories of sunset. Or random events from past or thing you have to do. You just see the sunset.It's not the commentary that changed from hey yet another sunset to I appreciate sunset.The commentary is gone or minimised and the resolution is increased. And there are no memories from past to distract you from experiencing the sunset.And this applies to most things. It's just nature has a lot of stuff that work well with heightened awareness. You don't want to spend your time with a heightened awareness and live next to a highway. That works against you.\n \nreply",
      "> You just see the sunset.I see this with some people and other animals. I can't speak. Sometimes I want to shy away because it's like seeing someone naked without them knowing they're being watched. I can see their souls. It's not every animal or even every person. I really strongly disagree that all people are equal. Everyone is different, everyone has a different path, and I feel like people are so vastly different that it's overwhelming at times.I don't think of it in terms of ego. That's because, I think, there are different kinds of transcendence, and it's easy to think that up is only one direction.\n \nreply",
      "The fact that you have this grandiose idea about yourself that you transcended ego and are beyond basic judging of others or of yourself and so on doesn't give you pause to say that maybe that's a bit naive and ego-centered? How can someone declare themselves done with this? It's like someone telling me they achieved a state of never having a bad thought again, I know they are lying.\n \nreply",
      "The problem is that state cannot be expressed in words or cognition, because it isn't part of your mind. I cannot fully explain to you what it is like, I can only experience it myself.Until you have the same experience, you will continue to doubt it in the exact way you currently are. And that's perfectly fine, and natural and still good.It's like trying to describe a color in its actual raw experience, or describing red to a blind person. It cannot be put into words, only observed.",
      "I'm guessing but it's not without some experience. I feel like I trick myself all the time - to guide myself towards becoming what I want to be.There was a time when I felt unintelligent and incapable of great, technical things. So I kind of just did things that it seemed capable people did. I felt like people who are smart, capable, and rich now, hacked things when they were young and were rebellious and broke the rules and did whatever they wanted and put lots of effort into random interesting things because they were interesting.So, because the end goal was attractive to me in a way, I tried to do those things too - maybe consciously, maybe not. I feel like that process made me different though. I have genuinely changed into someone far more capable technically, way more interested in super 'nerdy' things.Anyway, I don't know what it means to think this through ego. I don't really get it.But sunsets are nice - I like seeing them too. Yeah I suppose what I mean was that the commentary changed. Interesting that for you there's no commentary, I think I've felt like that before. Sometimes I feel like I just exist in a nice feeling -  no words, nothing. Just experiencing. But that doesn't last very long, or it turns into something negative like boredom or something. Then I get up with a bad feeling lol\n \nreply"
    ],
    "link": "https://swapnilchauhan.com/blog/procrastination-and-the-fear-of-not-being-good-enough",
    "first_paragraph": ""
  },
  {
    "title": "OpenID Connect specifications published as ISO standards (self-issued.info)",
    "points": 218,
    "submitter": "mooreds",
    "submit_time": "2024-11-10T16:53:19 1731257599",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=42101181",
    "comments": [
      "It took me an embarassingly long time (given how keenly involved I was in OpenID stuff ~17 years ago https://simonwillison.net/search/?tag=openid&year=2007) to understand that OpenID Connect is almost unrelated to the original idea of OpenID where your identity is a URL and you can prove that you own that URL.OpenID Connect is effectively an evolution of OAuth.\n \nreply",
      "You may already know this, I'm writing it as a note for my future self.OpenID Connect (OIDC) is mostly concerned with authentication. On the other hand, OAuth (or, to be more specific, OAuth v2.0) is concerned with authorization.>> OpenID Connect is effectively an evolution of OAuth.In my opinion, OpenID Connect is actually evolution of OpenID \u2013 in its vision/spirit:- OIDC, like OpenID, primarily focuses on users' identity and authentication;- OIDC, unlike OpenID, didn't (re)invent new authentication workflows, which were significantly different in their own ways. Instead, it built authentication workflows on top of existing OAuth spec (which was being (ab)used for authentication in some places which, unfortunately, is still the case) to achieve its main objective (i.e. authentication).---Edit: rephrased to better communicate my thoughts (still not perfect; but, as the saying goes, perfect is the enemy of the good so I stop here).\n \nreply",
      "> OIDC, unlike OpenID, didn't (re)invent new authentication workflows, which were significantly different in their own ways. Instead, it built authentication workflows on top of existing OAuth specDidn't OpenID predate OAuth? What should OpenID have built upon?\n \nreply",
      ">> Didn't OpenID predate OAuth? What should OpenID have built upon?Yes, you're right about \"OpenID predate OAuth\" part.However, from my point-of-view, it seems the main source of confusion here is due to the fact that the word OpenID is used in more than one sense:- First, OpenID used as part of the original OpenID authentication protocol developed around 2005 which communicates the idea of a decentralized online digital identity where one way a user can asserts their online digital identity is via a URL under their control.- Second, OpenID used as part of the compound noun in \"OpenID Connect\" (which as per Wikipedia is \"third generation of OpenID technology\", published in 2014[1]) which implements the user identity and their authentication via authentication workflows built on top of OAuth2 spec.Now, in my comment earlier i.e. \"OIDC, unlike OpenID, ... built on top of existing OAuth spec ... to achieve its main objective ...\", I was using OIDC (with \"OpenID\") in the second sense in comparison to the original OpenID authentication protocol where OpenID is used in the first sense (with both senses mentioned above).I hope it helps.---As an aside, looking at all the comments about \"OpenId\" and \"OpenID Connect\" as nouns, I'm reminded of the following post: Two Hard Things[2]---[1] - https://en.wikipedia.org/wiki/Openid#OpenID_Connect_(OIDC)[2] - https://martinfowler.com/bliki/TwoHardThings.html\n \nreply",
      "My problem with it being called OpenID Connect is that, in my head, an OpenID is a noun which means \"a URL that you can use as your identity and prove that you own\".That definition doesn't work for OpenID Connect. Is OpenID a noun any more? I don't think it is.\n \nreply",
      "OpenID Connect can totally work that way if used with WebFinger for endpoint discovery, and occasionally this is implemented (though many websites do not).\n \nreply",
      "Hm, so the point of adding this additional hop (which is also a JSON under the .well-known/ prefix), is that I can always put the domain of my homepage into WebFinger aware OIDC login boxes, no need to remember the domain of my OIDC provider?\n \nreply",
      "Also interesting is that OAuth2 is a bit too flexible in how you can put things together and OIDC provides a lot of good practice about that how.So even systems where OIDC compliance is a non goal often are partially OIDC compliant, I mean there really is no reason to reinvent the wheel if part of the OIDC standard already provide all you need.\n \nreply",
      "OAuth 2.1 tightens it up a bit.I don't think very many people know that OAuth 2.1 exists, though.\n \nreply",
      "My understand is that OpenID Connect is build on top of OAuth2, sort of a specialization.\n \nreply"
    ],
    "link": "https://self-issued.info/?p=2573",
    "first_paragraph": "By Mike JonesOn October 1, 2024In ISO, OpenID, SpecificationsI\u2019m thrilled to report that the OpenID Connect specifications have now been published as ISO/IEC standards.  They are:I submitted the OpenID Connect specifications for publication by ISO as Publicly Available Specifications (PAS) for the OpenID Foundation in December 2023.  Following the ISO approval vote, they are now published.  This should foster even broader adoption of OpenID Connect by enabling deployments in jurisdictions around the world that have legal requirements to use specifications from standards bodies recognized by international treaties, of which ISO is one.Before submitting the specifications, the OpenID Connect working group diligently worked through the process of applying errata corrections to the specifications, so that the ISO versions would have all known corrections incorporated.Having successfully gone through the ISO PAS submission process once, the OpenID Foundation now plans to submit additional f"
  },
  {
    "title": "Pi Chess Board (readymag.website)",
    "points": 151,
    "submitter": "GordonS",
    "submit_time": "2024-11-10T18:40:25 1731264025",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=42101742",
    "comments": [
      "> Functionality and Features> The Pi Board is an advanced automated chess system powered by a Raspberry Pi, utilizing an XY stepper motor mechanism and magnets to move chess pieces seamlessly across the board. The development process involved several key stages, including precise calibration of stepper motor coordinates, calculating the weight of each piece for accurate handling, integrating a robust chess engine, and optimizing piece-grabbing strategies and movement detection. Special attention was given to selecting the most efficient algorithm to minimize the stepper motors' power consumption.Is there a reason for the marketing speech? I'm assuming most people interested in this would rather read engineering speech, like so:> The Pi Board, as the name suggests, uses a Raspberry Pi under the hood to calculate engine moves from <Stockfish? Leela Zero?>, and move the pieces with a series of stepper motors and magnets. We spent a significant amount of effort minimizing power consumption, including weighing the individual pieces to get more efficient grabbing and moving motions for each one.\n \nreply",
      "Probably an LLM-assisted blog post.\n \nreply",
      "It must be. The part about minimizing the stepper motor power consumption is nonsensical. Steppers use the same current whether moving or stationary.\n \nreply",
      "You can absolutely adjust the current for a stepper motor. Lower currents use less power, but have less torque, leading to an increased chance of missed steps. In a system like this, the motor torque becomes a linear force to move a belt \u2014 and the force required to move the belt depends on if a piece is moving with it, and which piece. It\u2019s perfectly reasonable to bump up motor current when moving a piece, and bump it down when moving just the belt to grab the next piece.\n \nreply",
      "Yeah it really does read like something spat out by ChatGPT. They always have to include the word \u201ckey\u201d for some reason.\n \nreply",
      "I wish they added some LLM-assisted CSS & Div tags because this layout is atrocious.\n \nreply",
      "The movement of the knights is so creepy somehow. Lots of little movements and rotations. And then they just push a pawn out of the way and the human has to put it back.\n \nreply",
      "A real mechanical turk.  Needs to be able to handle captures / castling too.  Maybe I'm wrong but I don't see too much practical purpose for this, but as a piece of the scenery it could be very cool.\n \nreply",
      "Hate to be a spoil sport but if when pieces move they nudge other pieces out of the way and then those nudged pieces have to be put back by hand, then there\u2019s still work left to be done. Same goes for capturing - the captured piece should walk itself off the board.\n \nreply",
      "Yeah the videos were far from impressive...\n \nreply"
    ],
    "link": "https://readymag.website/u2481798807/5057562/",
    "first_paragraph": ""
  },
  {
    "title": "MdBook \u2013 a command line tool to create books with Markdown (rust-lang.github.io)",
    "points": 66,
    "submitter": "peter_d_sherman",
    "submit_time": "2024-11-10T20:00:58 1731268858",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=42102262",
    "comments": [
      "I am happily experimenting with Typst right now (https://typst.app/ ), which compiles much faster than LaTeX and with a syntax very similar to md, together with nice support for math, figures and advanced settings.\n \nreply",
      "Does anyone use Typst for multi-page documentation website? This is the most common use-case of mdbook.\n \nreply",
      "Typst is amazing. You try it once and never want to go back to LaTeX again.\n \nreply",
      "It's been talked about here a bunch of times: https://hn.algolia.com/?q=Typst\n \nreply",
      "While we're on the topic of MD, what's the best system for Markdown-based static blogs these days? With good code highlighting, images, colors, etc.\n \nreply",
      ">  best system for Markdown-based static blogsI use my Markdown editor[1] to produce my blog[2].      keenwrite.bin -q -i \"${FILE_MD}\" -o \"${FILE_HTML}\" \\\n        --curl-quotes=true\n\nOffers external variable sources, too; see [3] and [4].[1]: https://keenwrite.com/[2]: https://dave.autonoma.ca/blog/[3]: https://gitlab.com/DaveJarvis/KeenWrite/-/blob/main/docs/cmd...[4]: https://www.youtube.com/watch?v=CFCqe3A5dFg\n \nreply",
      "It's `pandoc --from markdown-smart --to html5` for me.\n \nreply",
      "I\u2019ve been running quarto [0] for a few months now and I\u2019m happy with it. Posts are saved as .qmd, with a little bit of special front matter for formatting and tagging. `quarto render` converts the .qmd(s) according to a simple config file.\n[0] https://quarto.org/\n \nreply",
      "I\u2019ve been waiting for them to release a standalone markdown editor, but it\u2019s been a couple years already now.\n \nreply",
      "+1 for quarto. I love it for my personal website, and I use it on a daily basis to create technical reports for my day job.\n \nreply"
    ],
    "link": "https://rust-lang.github.io/mdBook/",
    "first_paragraph": "mdBook is a command line tool to create books with Markdown.\nIt is ideal for creating product or API documentation, tutorials, course materials or anything that requires a clean,\neasily navigable and customizable presentation.This guide is an example of what mdBook produces.\nmdBook is used by the Rust programming language project, and The Rust Programming Language book is another fine example of mdBook in action.mdBook is free and open source. You can find the source code on\nGitHub and issues and feature requests can be posted on\nthe GitHub issue tracker. mdBook relies on the community to fix bugs and\nadd features: if you\u2019d like to contribute, please read\nthe CONTRIBUTING guide and consider opening\na pull request.The mdBook source and documentation are released under\nthe Mozilla Public License v2.0."
  },
  {
    "title": "Web Locks API (developer.mozilla.org)",
    "points": 124,
    "submitter": "mooreds",
    "submit_time": "2024-11-10T17:46:26 1731260786",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=42101434",
    "comments": [
      "> navigator.locks.request(\"my_resource\", async (lock) => {This would be so much more readable with `using`  {\n    using lock = navigator.lock('my_resource');\n    await do_something();\n    await do_something_else();\n  }\n\n(https://github.com/tc39/proposal-explicit-resource-managemen...)\n \nreply",
      "It doesn't actually feel more readable to me. I find the idea that the lock declaration sits at the same level as the lock content confusing.\n \nreply",
      "It's readable if you're familiar with the RAII pattern which is used in languages like C++ and Go.\n \nreply",
      "Why can't we just `await` the lock call?Edit: Nevermind, release of the lock is automatic when the callback resolves its promise. I get it now.\n \nreply",
      "You can probably wrap it to have that API\n \nreply",
      "I wish the compatibility tables on MDN gave an indicator of when a feature became available.My ideal would be a thing that says \"this hit 90% of deployed browsers 4 years ago\", but just seeing the date it was added to each of the significant browser families would be amazingly useful.\n \nreply",
      "It does.Using the Web Locks API page as an example, let's say we want to know when `LockManager` was added to Chrome. Here are the steps:1. View the page: https://developer.mozilla.org/en-US/docs/Web/API/Web_Locks_A...\n2. Scroll down to the Browser compatibility table\n3. Find the cell you're interested in, in this example we're looking at where the `LockManager` row meets the Chrome column.\n4. We see a check and a version number (in this case 69).So at this point we know that it has existed since version 69.Now in the case that we don't know that Chrome's current version is already < 100 and we need to know when a feature gained support:5. Click on the cell to view the timeline of that cell.Now we know that it was released on 2018-09-04, and it never had a smaller release requiring browser flags/prefixes/experiment flags/etc...\n \nreply",
      "I think this is the idea behind the Baseline <Year> standard you see on a lot of mdn features now, it shows the year when the feature was available in all 3 major browser engines\n \nreply",
      "You can get this from caniuse, right? Would be a simple enough browser extension to marry the two together.https://caniuse.com/mdn-api_lock\n \nreply",
      "How does a shared memory space work if you have different versions of scripts for the same domain?\n \nreply"
    ],
    "link": "https://developer.mozilla.org/en-US/docs/Web/API/Web_Locks_API",
    "first_paragraph": "Web technology reference for developersStructure of content on the webCode used to describe document styleGeneral-purpose scripting languageProtocol for transmitting web resourcesInterfaces for building web applicationsDeveloping extensions for web browsersWeb technology reference for developersLearn web developmentLearn web developmentLearn to structure web content with HTMLLearn to style content using CSSLearn to run scripts in the browserLearn to make the web accessible to allA customized MDN experienceGet real-time assistance and supportAll browser compatibility updates at a glanceLearn how to use MDN PlusFrequently asked questions about MDN PlusWrite, test and share your codeScan a website for freeGet real-time assistance and supportSecure context: This feature is available only in secure contexts (HTTPS), in some or all supporting browsers.Note: This feature is available in Web Workers.The Web Locks API allows scripts running in one tab or worker to asynchronously acquire a lock,"
  },
  {
    "title": "Algorithms We Develop Software By (grantslatton.com)",
    "points": 121,
    "submitter": "ksec",
    "submit_time": "2024-11-10T18:37:49 1731263869",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=42101729",
    "comments": [
      "> A piece of advice I've given junior engineers is to write everything twice. Solve the problem. Stash your code onto a branch. Then write all the code again. I discovered this method by accident after the laptop containing a few days of work died. Rewriting the solution only took 25% the time as the initial implementation, and the result was much better.This is true, and I've discovered it myself by losing a branch.However, who the hell has time to write everything twice? There's 1,000 things waiting to be written once.\n \nreply",
      "I think the mitigating factor is \"slow is smooth, smooth is fast\".If you raise the quality of your codebase, you can implement those 1,000 things faster, and you reduce the odds of they'll have to be reworked.\n \nreply",
      "There\u2019s a thousand things waiting to be written once\u2026 because they\u2019re each coping with something else that was written once.Write it twice, then you can use it a dozen ways, and now you\u2019ve got a hundred things to write instead of a thousand.\n \nreply",
      "People learn to work better by reflecting on work.  So any framework for self-observation is better than none.I suspect that algorithms as a framework demonstrates the structural aspects (e.g., how some searches are more extensive), but might hide the driving factors. Indeed, the article examples were almost all hacking personality, not technical or process solutions.E.g., most over-engineered solutions are driven by fear, often itself driven by critical or competitive environments.  Conversely, much of the power of senior/staff engineers comes from the license to cut corners afforded their experience.  Or people use the tools they know.You can't get to great by holding onto good.  It's easy to go from bad to good, but takes some courage to toss good to start over for great.  The lesson there is that we stand (hide?) behind our work, and we need to let go of it to improve it.A meta-lesson is that managers need to deeply understand personal space of each developer and the social dynamics of the team before they can do their job effectively, and a key part of that is likely checking in with developers in a way that enhances their courage and self-observation instead of making them fearful and paranoid.\n \nreply",
      "> much of the power of senior/staff engineers comes from the license to cut corners afforded their experience.Absolutely. Jira is equally slow for everyone except for the ones who are allowed to skip it.At the places where i managed to become star developer it was by hitting hard early and achieving great results, and after that you\u2019d get a lot of slack cut for you which allows you to continue deliver at the star level with relatively light effort, and definitely much easier than say the mediocre grind i produce at the current place where \u201cJira\u201d is truely slow with us.\n \nreply",
      "So you were a \"star developer\" at some previous workplaces, but now you're not, and just produce at a \"mediocre grind\"?  Why is that?  And why work there now and not that the previous places?I suspect this is the common tale of poor compensation: despite being a star developer, employers won't pay for properly for this, just a mediocre annual raise, so you move on after a couple of years to another place, which offers you a huge raise (new starting salary compared to the previous job's salary).  And the new place, while giving you a poor environment that hampers your productivity, still pays much better than the previous places where your productivity was much higher.  And because of this common workplace dynamic, it's usually not worth it to put in much effort to be a star employee, unless you find the rare employer that actually rewards you for it.  Is my guess correct?\n \nreply",
      "you've been around, you're absolutely right.>not worth it to put in much effort to be a star employeeit isn't even possible at the places like i'm currently in, at least for me. I mean, i'm still rated as high performing employee, just a regular one at that. You do your components in a very large platform product, make sure that they aren't source of pain, and just coast under the radar.\n \nreply",
      "I fundamentally disagree with the \"gun to the head\" strategy.One of the major projects I worked on was a virus genome analysis pipeline. Our initial funding was for single-segment virus analysis, but about a year into the project, our grant collaborators needed to demonstrate multi-segment virus support within two weeks. My PI and I agreed on a quick and dirty method that would produce the analyses needed and could be done in the allotted time. That piece of code was fundamental to how the whole pipeline worked, however, and so as the pipeline grew, it took on the shape of the \"gun to the head\" decision we had made to the point where other, more essential features of the pipeline had to be delayed so I could come up with more workarounds.There were clearly other issues at play here (scope creep and lack of separation of concerns were huge). My time at the lab came to a close, but if I were to have a chance to continue that project, I would start over from scratch rather than deal with the baggage that that one \"gun to the head\" moment created.I understand that it's a heuristic and not meant to be taken as 100% truth for every situation. I also understand that it's trying to avoid that \"paralysis by analysis\" that's so easy to fall into. I just question how useful it truly is as a heuristic, especially since it seems to go against the \"write everything twice\" algorithms presented in the rest of the piece.\n \nreply",
      "I'd say it goes with the \"write everything twice\" heuristic! If you're in an environment where you can write things twice\u2014you have trust and autonomy and aren't encumbered by process\u2014then writing an initial version as fast as possible gets you started faster, lets you play with something concrete and leaves you more room for your second version.My best projects were like that. I'd figure out something quick\u2014some combination of reducing scope and doing \"things that don't scale\"\u2014then spend time refining the conceptual design and interfaces, and finally rewrite the initial piece based on that new design. This can absolutely work better than just trying to write something \"good\" the first time around, but it looks wasteful to somebody superficially tracking individual \"tasks\" you're working on.\n \nreply",
      "As the saying goes, there's nothing more permanent than a temporary solution. If you're going to do this, you either have to explicitly plan for the cost of the rewrite to do it the \"right\" way after doing it the \"wrong\" way, or you have to accept that you're probably not going to revisit the \"temporary\" solution for a long time.\n \nreply"
    ],
    "link": "https://grantslatton.com/software-pathfinding#algorithms-we-develop-software-by",
    "first_paragraph": ""
  },
  {
    "title": "JVM Anatomy Quarks (shipilev.net)",
    "points": 151,
    "submitter": "lichtenberger",
    "submit_time": "2024-11-10T16:09:07 1731254947",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=42100876",
    "comments": [
      "Tangential: Apple has a new Swift Java bridge which is pretty cool, supporting both JNI and Panama. I\u2019ve been porting it to Android this past week.https://github.com/swiftlang/swift-java\n \nreply",
      "Happy to see this gem shared here. I've learnt a lot about the JVM going through these.This article about the \"stack allocation\" misnomer in Java in particular is one of my favorites: https://shipilev.net/jvm/anatomy-quarks/18-scalar-replacemen.... What the JVM really does is escape analysis + scalar replacement.\n \nreply",
      "I love the \"size\" of these posts. Kinda neat to just read through one in a few mins and maybe run the bench locally.\n \nreply",
      "https://shipilev.net/jvm/anatomy-quarks/17-trust-nonstatic-f... is a damned shame. User code misses out on an important optimization available only to system-provided classes because certain frameworks have abused JNI and reflection to mutate final fields, which by all rights should be immutable.Platforms, especially compilers and runtimes, need to be absolutely strict in enforcing semantic restrictions so as to preserve optimization opportunities for the future.\n \nreply",
      "As part of our \"integrity by default\" strategy [1] we're changing that. There will be a JEP about it soon.The idea is that because not much code actually needs to mutate finals (and even if it does, that operation is already limited today to classes in the code's own modules or ones explicitly \"open\" to it), the application will need to grant a permission to a module that wants to mutate finals, similar to how we've recently done things with native calls and unsafe memory access.[1]: https://openjdk.org/jeps/8305968\n \nreply",
      "I wonder if it thanks to some people blindly following Effective Java book that made a sin by saying \"final all the things\". So now we cannot easily mock final classes in tests. And mocking tools have to resort to bytecode manipulation to mock the final classes.E.g. Effective Java is a requirement inside Google, so even public GDrive APIs have final classes. External APIs is exactly the thing you'd want to mock.\n \nreply",
      "I would say less overuse of final, more underuse of interfaces. If everything takes/returns/stores values by interfaces (excluding data containers with no behavior) then you don't need to \"jailbreak\" any class to mock it.Of course you get code bloat defining interfaces for everything you intend to implement once, and you have to enforce these rules, but this is something that could be made easier. Not in Java, but imagine a language where:- Concrete classes can only be used in new, or in some platform provided DI container.- Methods can only accept interface types and return interface types.- Fields are private only, all public/protected is via properties (or getters/setters, it just has to be declarable in an interface)- You have a \".interface\" syntax (akin to \".class\" but for types) that refers to the public members of a class without tying you to the concrete class itself. You can use this as a shorthand instead of declaring separate interfaces for everything.Eg.```final class GDrive { ... }public Download file(GDrive.interface drive) { ... }class MockDrive implements GDrive.interface { ... }```The closest I can think of is a hypothetical typed variant of NewSpeak, but maybe something like this exists already?\n \nreply",
      "> I would say less overuse of final, more underuse of interfaces.Interfaces with one implementation are terrible. They just clutter everything and make the code navigation a pain, so it's good that people are avoiding them.Perhaps a special \"test-only\" mode that allows to patch finals is a better idea.\n \nreply",
      "You just invented Java AutoValue and Kotlin Data Classes.https://github.com/google/auto/blob/main/value/userguide/ind...\n \nreply",
      "> So now we cannot easily mock final classes in tests> And mocking tools have to resort to bytecode manipulation to mock the final classesWell which is it?  Presumably you use said mocking tool anyway, so it's not your effort that's being expended.\"Final all the things\" really doesn't go far enough.  There is little point substituting a mutable hashmap for a \"final\" mutable hashmap, when the actual solution is for the standard library to ship proper immutable collection classes.In any case, I prefer to avoid mockito anyway, so it's a non-issue for me.  Just do plain ol' dependency injection by passing in dependencies into constructors.\n \nreply"
    ],
    "link": "https://shipilev.net/jvm/anatomy-quarks/",
    "first_paragraph": "\"JVM Anatomy Quarks\" is the on-going mini-post series, where every post is describing some elementary piece of knowledge about JVM. The name underlines the fact that the single post cannot be taken in isolation, and most pieces described here are going to readily interact with each other.The post should take about 5-10 minutes to read. As such, it goes deep for only a single topic, a single test, a single benchmark, a single observation. The evidence and discussion here might be anecdotal, not actually reviewed for errors, consistency, writing 'tyle, syntaxtic and semantically errors, duplicates, or also consistency. Use and/or trust this at your own risk.Aleksey Shipil\u00ebv, JVM/Performance Geek\nShout out at Twitter: @shipilev; Questions, comments, suggestions: aleksey@shipilev.netThe series is on-going, the auto-generated complete bundles are here:\nePUB (smallest, under MB, Pandoc HTML-to-ePUB)\nMOBI (small, around MB, KindleGen ePUB-to-MOBI)\nPDF (very large\u2009\u2014\u2009tens of MBs, high-quality w"
  },
  {
    "title": "Show HN: I made a tiny device for automatically recording digital pianos (jamcorder.com)",
    "points": 175,
    "submitter": "chipweinberger",
    "submit_time": "2024-11-07T23:41:39 1731022899",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=42082430",
    "comments": [
      "Congrats on launching, OP!This might be the first Show HN that I insta-purchased after reading your landing page. The mobile interface looks extraordinarily well thought-out.\n \nreply",
      "Same. I've so often done a nice improvisation that's then lost forever. Time to find out if there's something in them.\n \nreply",
      "Likewise. I also get more \"in my head\" if I'm actively recording, and it just isn't the same relaxing experience as improvising and noodling. Really excited for this.\n \nreply",
      "Same. Bought this immediately for that exact reason.\n \nreply",
      "Wow that's a really nice compliment!You should have seen the original UI concepts I made, they were terrible!\n \nreply",
      "I'm definitely not the target market for this, but I do want to say that this really scratches an itch for something that should exist, and I really want to compliment you on how fantastic the execution is! Very clean look in both the physical and digital realms, and I really appreciate just how fully featured it is! It really seems like the ideal version of what this product would be. Also love the idea of the bookmark pattern. Out of curiosity, is that customizable too?\n \nreply",
      "Customizable bookmarks is something I really want to add. It could be so fun.Should be pretty straightforward! I'd want a decent UI for it!\n \nreply",
      "I\u2019ve automagically recorded my digital piano musings starting about 28 years ago. Initially, I used a simple C code on a Linux server using select to dump from dev MIDI to a timestamped file per session (a variation of an answering machine I had previously hacked together with a friend). Later, I used pianoteq recording on an iMac, which also detects gaps and records separate timestamped files. The experience has been very positive and helpful for improving technique and composition, so I do recommend this hardware if you dont already record everything.  One piece of advice, however: you want to let people who touch your piano know they get recorded, or ask them to wait until you turn off the recording. I tend to forget that I record everything after a while, and an unsuspecting friend might incorrectly assume that their improv does not lead to a permanent record. I had several people be surprised when they first learned about the automatic recording after the fact, and had to remove one or two files at their request (though the last time I needed to remove a file was around 1998; more recently, people didn\u2019t seem to mind).\n \nreply",
      "This is such a cool comment! Since I've had the device, I've really enjoyed it too, more than even I thought I would.Yes there are some limited times you might want to turn off recording. I've given this some thought. For now, unplugging is the simple answer.\n \nreply",
      "Looks really great! If I had a standalone keyboard I'd be considering this!Your project got me thinking - here's one idea: Windows should get MIDI 2.0 support soon, incl. non-blocking MIDI reading if I understood correctly. That should make it possible to create a small background application that records all incoming MIDI from all (or chosen) connected MIDI devices. It would work very much like your recorder and could share the same mobile app?This I would be interested in. Since it's a software only solution, it could be cheaper and lower entry barrier.\n \nreply"
    ],
    "link": "https://jamcorder.com/",
    "first_paragraph": ""
  },
  {
    "title": "Australia's 3G Shutdown \u2013 Why your 4G/5G Phone is now Blocked (medium.com/jamesdwho)",
    "points": 66,
    "submitter": "the_mitsuhiko",
    "submit_time": "2024-11-10T23:10:33 1731280233",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42103257",
    "comments": [
      "Australia has a rich tradition of overarching, arrogant and authoritarian behavior towards the little people.Possibly a hangover from the early days of European settlement, when the majority of settlers were convicts who needed keeping an eye on and dealing with with a firm hand.\n \nreply",
      "I really don't get it. Everytime I read about Australian technology it's an article that I'd still find believable after replacing \"Australia\" with \"North Korea\".\n \nreply",
      "True, and if you look back over the last few decades of policy and legislation, from either side of politics here, the Federal Government has demonstrated just staggering incompetence with almost everything to do with technology too...\n \nreply",
      "It\u2019s inherited from Britain which was and is still like that.\n \nreply",
      "Australia is allergic to accountability and responsibility, especially in the corporate sector and, even more so, within government. Sweeping problems under the rug and a game of musical chairs are endemic and rampant; they form a quintessential playbook for achieving a successful career in senior corporate management or government.Which is also why IT business are required to hold expensive insurance policies, without which they can't approach clients, and which is also why the big four consulting firms have become so popular amongst the senior management: \u00abit is not my fault, they are the ones who did it\u00bb.\n \nreply",
      "Last minute change, and leaving it up to the carriers. Bad to the power of bad.I tend to buy grey import handsets because they offer a better value proposition - by a long margin - than locally sold handsets. Allowing the carriers to define the block list only plays into their greedy little hands.I know that \"band 28\" support is something useful to Australians who, like me, buy handsets from overseas. The support of handsets should be based on capabilities of the device, not a seemingly arbitrary list that's under the control of the carriers. But that's what happens when last minute decisions are made.\n \nreply",
      "It\u2019s surprising the things that have been caught offguard by this.In Melbourne, the ticketing terminal in 200 trams and 2500 buses is now broken.https://www.theage.com.au/national/victoria/free-ride-as-myk...\n \nreply",
      "James is doing an incredible job of documenting this issue.Everything except for his incredible documentation has either been minor anecdote (\"my phone doesn't work\"), or Industry & Government spin- usually misrepresentations at the least.Bravo James.\n \nreply",
      "This has been handled differently in the UK from a regulatory point of view from an earlier time in the rollout of 4G/5G networks, so things seem to have worked out better.In the UK, carriers are only allowed to provide coverage in any given area to a phone if it is able to make an emergency call (999/112) in that area.i.e. if the phone says you have a signal, you must be able to make an emergency call.So, for a phone to actually show you as being connected to the network:a) There must be 2G/3G coverage available for a CSFB call to take place.orb) The phone must support VoLTE (including for emergency calls).Newer LTE (and 5G) spectrum deployments, like Band 20 LTE (800MHz), are being used to provide coverage in rural areas - even in places where there is no 2G/3G coverage, therefore these newer bands are often only made available to devices that support VoLTE.If you have an old phone, that doesn't support VoLTE (including for emergency calls), then it will only connect to 4G networks in areas where there is still an overlapping 2G/3G layer.This approach means that the carriers have had an incentive to make all devices support VoLTE with emergency calling. It has also been possible for the carriers to promote the 800MHz coverage as only being available on newer phones with VoLTE.Thus much of the problems that Australia is having have been avoided.Also:Data-only devices aren't included in this requirement, as they can't/don't make emergency calls.Roaming devices aren't affected (as far as I know).UK carriers support VoLTE roaming in the USA, given the lack of 2G/3G networks for CSFB.\n \nreply",
      "I have always maintained that VoLTE has been a deficiently-defined specification, with many, many reliability concerns whisked away in the name of VoIP (which is what LTE is). It is possible to design an IP-based system capable of actual tolerance, but with the VoLTE spec so underdefined for years, these issues crop up badly.(RCS has essentially the same problems until Google essentially monopolized it... which creates a big single-point failure problem on its own.)\n \nreply"
    ],
    "link": "https://medium.com/@jamesdwho/australias-3g-shutdown-why-your-4g-5g-phone-is-now-blocked-5900cd5361e2",
    "first_paragraph": ""
  },
  {
    "title": "Bjorn: A powerful network scanning and offensive security tool for Raspberry Pi (github.com/infinition)",
    "points": 50,
    "submitter": "ulrischa",
    "submit_time": "2024-11-10T18:30:55 1731263455",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=42101688",
    "comments": [
      "Preparing my honeypot right now: https://github.com/infinition/Bjorn/blob/9ea706ccc03437a9dd1...\n \nreply",
      "Looking at the SSH actions, the \"brute force\" attack is just iterating through a list of usernames and passwords from an external file. Wow. Much impress. So Hacker.\n \nreply",
      "If it ends up living up to the promise of the quality of the documentation (ie the README), I can\u2019t wait to try it. Also screenshots of the display look cool.\n \nreply",
      "For the brute-force attack, THC's hydra could be used instead of reinventing the wheel. Or are there licensing issues involved?\n \nreply",
      "I don't see the \"selling value\" of this, can you give me a qrd?\n \nreply"
    ],
    "link": "https://github.com/infinition/Bjorn",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Bjorn is a powerful network scanning and offensive security tool for the Raspberry Pi with a 2.13-inch e-Paper HAT. It discovers network targets, identifies open ports, exposed services, and potential vulnerabilities. Bjorn can perform brute force attacks, file stealing, host zombification, and supports custom attack scripts.\n      \n\n\u2196\ufe0fBjorn is a\u00a0\u00ab\u00a0Tamagotchi like\u00a0\u00bb sophisticated, autonomous network scanning, vulnerability assessment, and offensive security tool designed to run on a Raspberry Pi equipped with a 2.13-inch e-Paper HAT. This document provides a detailed explanation of the project.\u2196\ufe0f\u2196\ufe0f\u2196\ufe0f\u2196\ufe0f\u2196\ufe0f\u2196\ufe0f\u2196\ufe0f\u2196\ufe0f\u2196\ufe0fThe main entry point for the application. It initializes and runs the main components, including the network scanner, orchestrator, display, and web server.Handles generating all the Bjorn comments displayed on the e-Paper HA"
  },
  {
    "title": "Scientists decipher two-photon vision (phys.org)",
    "points": 10,
    "submitter": "bookofjoe",
    "submit_time": "2024-11-05T18:59:14 1730833154",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://phys.org/news/2024-11-scientists-decipher-photon-vision.html",
    "first_paragraph": ""
  },
  {
    "title": "Another simple online DNS query tool (nstoolbox.com)",
    "points": 11,
    "submitter": "sckn",
    "submit_time": "2024-11-10T21:58:17 1731275897",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42102881",
    "comments": [
      "I get a single A rec for google.com.  Pretty sure there should be multiple, no?\n \nreply",
      "doesn't seem to work for me. Requests just hang.\n \nreply"
    ],
    "link": "https://nstoolbox.com/",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Chonkie \u2013 A Fast, Lightweight Text Chunking Library for RAG (github.com/bhavnicksm)",
    "points": 107,
    "submitter": "bhavnicksm",
    "submit_time": "2024-11-10T15:58:25 1731254305",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=42100819",
    "comments": [
      "Review: Chonkie is an MIT license project to help with chunking your sentences. It boasts fixed length, word length, sentence and semantic methods. The instructions for installing and usage are simple.The Benchmark numbers are massaged to look really impressive but upon scrutiny the improvements are at most <1.86x compared to the leading product LangChain in a further page describing the measurements. It claims to beat it on all aspects but where it gets close, the author's library uses a warmed up version so the numbers are not comparable. The author acknowledged this but didn't change the methodology to provide a direct comparison.The author is Bhavnick S. Minhas, an early career ML engineer with both research and industry experience and very prolific with his GitHub contributions.\n \nreply",
      "Would it make sense for this to offer a chunking strategy that doesn't need a tokenizer at all? I love the goal to keep it small, but \"tokenizers\" is still a pretty huge dependency (and one that isn't currently compatible with Python 3.13).I've been hoping to find an ultra light-weight chunking library that can do things like very simple regex-based sentence/paragraph/markdown-aware chunking with minimal additional dependencies.\n \nreply",
      "I made a rudimentary semantic chunking in just a few lines of code.I just removed one sentence at a time from the left until there was a jump in the embedding distance. Then repeated for the right side.\n \nreply",
      "Across a broad enough dataset (char count / 4) is very close to the actual token count in english -- we verified across millions of queries. We had to switch to using an actual tokenizer for chinese and other unicode languages, as that simple formula misses the mark for context stuffing.The more complicated stuff is the effective bin-packing problem that emerges depending on how much different contextual sources you have.\n \nreply",
      "Also check out https://github.com/D-Star-AI/dsRAG/ for a bit more involved chunking strategy.\n \nreply",
      "This looks pretty amazing. I will take it for a spin next week.  I want to make a RAG that will answer questions related to my new car.  The manual is huge and it is often hard to find answers in it, so I think this will be a big help to owners of the same car.   I think your library can help me chunk that huge PDF easily.\n \nreply",
      "How many tokens is the manual?\n \nreply",
      "if its more than the 2M that will fit in gemini context then I want to know what car it is.\n \nreply",
      "Thank you so much for giving Chonkie a chance! Just to note Chonkie is still in beta mode (with v0.1.2 running) with a bunch of things planned for it. It's an initial working version, which seemed promising enough to present.I hope that you will stick with Chonkie for the journey of making the 'perfect' chunking library!Thanks again!\n \nreply",
      "> Token Chunking: 33x faster than the slowest alternative1) what\n \nreply"
    ],
    "link": "https://github.com/bhavnicksm/chonkie",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        \ud83e\udd9b CHONK your texts with Chonkie \u2728 - The no-nonsense RAG chunking library\n      \n\n\n\n\nThe no-nonsense RAG chunking library that's lightweight, lightning-fast, and ready to CHONK your textsInstallation \u2022\nUsage \u2022\nSupported Methods \u2022\nBenchmarks \u2022\nAcknowledgements \u2022\nCitationso i found myself making another RAG bot (for the 2342148th time) and meanwhile, explaining to my juniors about why we should use chunking in our RAG bots, only to realise that i would have to write chunking all over again unless i use the bloated software library X or the extremely feature-less library Y. WHY CAN I NOT HAVE SOMETHING JUST RIGHT, UGH?Can't i just install, import and run chunking and not have to worry about dependencies, bloat, speed or other factors?Well, with chonkie you can! (chonkie boi is a gud boi)\ud83d\ude80 Feature-rich: All the CHONKs you'd ever need \n\u2728 "
  },
  {
    "title": "Chegg Is on Its Last Legs After ChatGPT Sent Its Stock Down 99% (gizmodo.com)",
    "points": 17,
    "submitter": "rntn",
    "submit_time": "2024-11-11T00:19:29 1731284369",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://gizmodo.com/chegg-is-on-its-last-legs-after-chatgpt-sent-its-stock-down-99-2000522585",
    "first_paragraph": ""
  },
  {
    "title": "Tickets Are for Remembering (publicbooks.org)",
    "points": 11,
    "submitter": "Thevet",
    "submit_time": "2024-11-07T20:02:10 1731009730",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=42080327",
    "comments": [
      "No, for those of us who care about the actual play rather than the hip ephemera, tickets are for getting in.\n \nreply",
      "I have a small tin box that something or other came in as a gift. It stored concert tickets and other small memorabilia (like the movie ticket from a great first date) for every event I'd gone to for well over a decade.Gradually, as physical tickets got phased out, I had fewer and fewer items of memorabilia to add. At this point, I have no physical record of shows we see. I feel like something has been lost. But I suspect far fewer people kept these tickets for nostalgia than threw them away, so I guess I'm not mad; I'm just disappointed.\n \nreply",
      "The lack of even an OPTION to get a proper, physical ticket makes TicketMaster's obscene rip-off even more outrageous.\n \nreply",
      "Not to be confused with the more familiar type of tickets.Those tickets are for forgetting.\n \nreply"
    ],
    "link": "https://www.publicbooks.org/tickets-are-for-remembering/",
    "first_paragraph": "Playbills, programs, cast-change inserts, tickets: these objects once physically accompanied the theater\u2019s visual and verbal delights. To enter the Lyceum or the Winter Garden, you presented your glossy rectangle to an usher who severed its stub. Rip! You tucked the now diminished rectangle in your pocket as you searched for your section. There, another usher offered you a copy of Playbill. Reaching your seat, you flicked through its pages, learning who\u2019s who in the cast and discovering what else was \u201con\u201d that season.But a tangible rupture in New York theater history has occurred. There is less paper in the theater now than there has been in decades. This is in large part because the COVID-19 pandemic accelerated a decade-long trend toward digital ticketing. Many theaters offered to \u201cdeliver\u201d tickets as a PDF via email attachment or (occasionally) as a QR code before March 2020; virtual delivery took precedence when Broadway reopened in August 2021, as a matter of convenience became a "
  },
  {
    "title": "Typesetting Engines: A Programmer's Perspective (ppresume.com)",
    "points": 85,
    "submitter": "P_qRs",
    "submit_time": "2024-11-10T15:21:00 1731252060",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42100660",
    "comments": [
      "> Indo-European languages: a language family native to the overwhelming majority of Europe, the Iranian plateau, and the northern Indian subcontinent. Widely spoken indo-european languages includes English, French, Portuguese, Russian, Dutch, and Spanish, etc.> Indo-European languages typically use the Latin alphabetAfter the first sentence, \"Indo-European\" seems to have transformed to just \"European\" in the author's mind. Hindi and Bengali, languages more widely spoken than half the language in that list, seem to have been forgotten, along with their Devanagri script.(Over the course of the article, it's seeming like the author just wanted to say European languages, or languages using Latin script, and for some reason chose to use Indo-European instead, despite clearly stating the definition themself.)\n \nreply",
      "The most painful issues I encountered when building out a text layout engine for my JS 2D canvas library were:- Vertical text - in particular when it comes to how CJK punctuation differs in horizontal and vertical environments (not yet solved)- Staying on CJK, making sure the punctuation marks that follow a character don't break and remain with their preceding characters at all times. (I expect the same holds for opening quotes etc but haven't experimented).- Highly ligatured fonts - Devangari, Arabic, etc - there's no solution to styling individual characters within a word that I could find.- Talking of styling ... underlining text is a nightmare - especially if you want to get the little gap between hanging characters and the underline that HTML/CSS browsers do out of the box- Formatting Thai fonts ... is another World of Hurt[1][1] - https://w3c.github.io/sealreq/thai/\n \nreply",
      "No bidi or Arabic script complexities? Calculating the line break in an RTL situation is just terrible...\n \nreply",
      "I've written and published over a dozen books. (Two published with big tech publishers, the rest self-published.)With my most recent book, I've moved my PDF generation to Typst. LaTeX, you served me well, but I'm more than happy to never use you again. Typst is better (or decent enough) in every dimension.\n \nreply",
      "Typst looked promising, but the very first thing I wanted to do with it - generate some slides with code snippets, and use highlights to call out specific features of the code - is not possible. The core layout engine seems to merge `styled(...)` spans in code blocks far too aggressively, making it impossible for codly (the code highlighting package I tried) to pick out precise ranges to highlight.I went back to beamer.\n \nreply",
      "Look at Quarto. Write in markdown and export to web, print, and presentations (including straight to PowerPoint or reveal.js for interactive web-based slides.All from the same content using includes, variables, flags, etc. Show interactive plots directly in you presentations, tons of other features.Almost every project I create now whether it's documentation, presentation, report, website, or anything else project-related can fit within `quarto create project`.\n \nreply",
      "This is pretty hard to believe considering how good the ecosystem in Typst is so far.  There are quite a few packages for making slides in Typst including [Polylux](https://github.com/gszauer/polylux), \n [Touying](https://github.com/Wyntau/touying], \n [minideck](https://typst.app/universe/package/minideck),\n   [slydst](https://typst.app/universe/package/slydst) \n  [minimal-presentation](https://typst.app/universe/package/minimal-presentation) and many more.\n \nreply",
      "The problem is not with the slides package, it's with the content I want to put on the slides:https://github.com/Dherse/codly/issues/35 and in particular, this comment from the author of codly where he sounds constrained by Typst: https://github.com/Dherse/codly/issues/35#issuecomment-24667...\n \nreply",
      "Have you tried TeXmacs or its fork Mogan?\n \nreply",
      "This overlooks CSS Paged Media based options like paged.js, weasyprint, etc. (You can find the full list here..some open source, some commercial)[0][0]https://www.print-css.rocks/tools\n \nreply"
    ],
    "link": "https://blog.ppresume.com/posts/on-typesetting-engines",
    "first_paragraph": "This post is available in the following translations:Typesetting is \u201carchitecture in two dimensions.\u201dIf text and its fonts are the materials of the building, then typesetting is the\ndrawings of the building.Typesetting is a big topic, it is both an art and an engineering technique that\nhas evolved significantly with the advent of digital technology. Obviously I\ncannot cover this topic in one post, even a book cannot do.Among many typesetting concepts, the typesetting engine is one of the core\nconcepts. Basically, a typesetting engine is a piece of software that decides\nhow the glyphs, graphics, tables, etc. are laid out for printing or digital\ndisplay.When PPResume was\nlaunched, some people\nasked\nme why chose LaTeX as the default typesetting engine for PPReseume. Hmmm, this\nis a big topic.In this post, I would like to explore the pros and cons of some popular\ntypesetting engines: HTML/CSS, LaTeX.js,\nLaTeX, Typst,\nreact-pdf and conclude why PPResume chose LaTeX as the\ndefault typesettin"
  },
  {
    "title": "Memory64 (github.com/webassembly)",
    "points": 30,
    "submitter": "tosh",
    "submit_time": "2024-11-07T10:27:06 1730975226",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=42075403",
    "comments": [
      "I'm curious to see what the performance impact of using 64bit memory ends up being. WASM runtimes currently use a clever trick on 64bit host platforms where they allocate a solid 4GB block of virtual memory up front, and then rely on the MMU to catch out-of-bounds accesses by faulting on unmapped pages, so bounds checking is effectively free. That won't work with 64bit WASM though so runtimes will have to do old fashioned explicit bounds checking on every single heap access.\n \nreply",
      "Can't the same trick be used for slightly more bits? 64-bit uses 48 bits nowadays AFAIK, which is 256 TB. It's usually 50/50 for user/kernel mode. If, say, WASM takes half of the user mode address space, it's still 46 bits which is 64 TB (ought to be enough for anybody?). Or maybe I'm way off, I don't really know the specifics of the trick you're referring to.\n \nreply",
      "The problem is you need the virtual memory allocation to span every possible address the untrusted WASM code might try to access, so that any possible OOB operation lands in an unmapped page and triggers a fault. That's only feasible if the WASM address space is a lot smaller than the host address space.I suppose there might be a compromise where you cap a 64bit WASM instance to (for example) an effective 35bit address space, allocate 32GB of virtual memory and then generate code which masks off the top bits of pointers so OOB operations safely wrap around without having to branch, but I'm not sure if the spec allows that. IIRC illegal operations are required to throw an exception.\n \nreply",
      "I also wonder what the perf overhead will be for programs that only need i32. I didn\u2019t dig deep enough on the implementation, but these type of variadic runtime options often cause perf regressions because of all the \u201cifs\u201d / lookups of type configs/parameters, etc. I just imagine some inner loops where mem.get adds a few instructions from the \u201cif u32/64/\u201c.Unless it ends up being seamless / no cost via loading different u32/u64 implementations.I mostly agree with the old c++ mantra of - no feature should have a runtime cost unless used.\n \nreply",
      "I would hope it's set up such that the runtime always knows whether a memory access is 32bit or 64bit at JIT-time so it can generate unconditional native code. Runtimes that use an interpreter instead of a JIT might be hurt by having to branch every time, but interpreters being slow is already kind of a given.\n \nreply",
      "Yes, the bitcode specifies whether a memory operation/address uses 32-bit or 64-bit addressing, so a runtime/JIT can determine this ahead of time during the static analysis phase.\n \nreply",
      "32GB in single browser window running web assembly...Why would you ever want to go above this? What is your scenario?\n \nreply",
      "32-bit memory addressing means you only have 4GB, not 32GB.The company I current work for makes radiotherapy software. Most of our native apps run in clinics under .NET.There are some cases where we want users or employees to be able to access our radiotherapy tooling from a browser. Microsoft has a pretty phenomenal .NET -> WASM compiler. We can compile our .NET DICOM image viewer tooling to WASM, for example, and it is more performant and full-featured than Cornerstone.js (https://www.cornerstonejs.org/).However, medical imagery is memory heavy. We frequently run into the 4GB limit, especially if the CT/MR image uses 32-bit voxels instead of 16-bit voxels. Or if the field of view was resized. Or if we accidentally introduce an extra image copy in memory.\n \nreply",
      "You can compile most anything to webassembly. I believe Unreal Engine supports it.So no reason why a big game with fancy graphics and lots of textures couldn't use it.\n \nreply",
      "WebAssembly doesn't only apply to the browser. It will also be used server side and in applications other than browsers.\n \nreply"
    ],
    "link": "https://github.com/WebAssembly/memory64/blob/main/proposals/memory64/Overview.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          "
  },
  {
    "title": "I fixed a server with a precisely placed piece of tape (2023) (treehouse.systems)",
    "points": 39,
    "submitter": "Wowfunhappy",
    "submit_time": "2024-11-10T22:23:42 1731277422",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=42103000",
    "comments": [
      "I came into a company once that had built their own server room.  It had a couple hundred pizza boxes in it and was always hot as hell even with full blast air conditioning.  When I retired almost all of them to use virtual servers, it turns out that 1) a lot of the chipsets internallyl still had plastic film on them (to prevent scratches? Why would you put film on them? There were even some CPUs that didn't have any coolers on them, just film) and 2) A lot of the inpflow and outflow air ports also had plastic shipping film that was never removed.  I was completely shocked.  So I fixed dozens if not a hundred computers simply by removing a piece of tape.\n \nreply",
      "This wouldn't make the room any cooler, though, as the total energy used by the computers is the same. It would just dissipate the heat in the air, rather than keep it on the chips.\n \nreply",
      "One would think the fans wouldn't work as hard, but then again server fans might blast on full regardless. It's amazing that none of the machines / components overheated and failed.\n \nreply",
      "I don't think GP was suggesting it would.  The bit about the server room being hot as hell was just to illustrate that these machines were running in a very hot environment without proper cooling.\n \nreply",
      "Ah, maybe, that makes sense.\n \nreply",
      "Presumably it would make it hotter, as the CPUs wouldn't have to throttle themselves so much, generating more heat.\n \nreply",
      "> There were even some CPUs that didn't have any coolers on them, just film...I'm pretty surprised these systems booted at all without CPU coolers?\n \nreply",
      "CPUs are very good about protecting themselves, but I'm shocked no one noticed that they took many hours to boot up or to do anything at all.\n \nreply",
      "Sure, but in this case, I would have expected \"protecting itself\" to mean \"shutting down.\" Can a server CPU\u2014or any x86 cpu, for that matter\u2014actually downclock itself enough to run without any sort of cooler?\n \nreply",
      "486s were sometimes passively cooled. A room full of hardware replaced by a very early virtualization setup lines up reasonably well.I did one of these in the early naughts. Something like half a rack of old pentium 2-3 era boxes running non-prod \u2014 back office, network share storage, dev, staging \u2014 to a single beefy server running some flavor of vmware. We had all the older gen hardware for isolation and convenience, not because we needed the compute so I specced a \u201cbig\u201d box that could hold a lot of storage (for the time) and performance was a non-issue. I think I also saved a lot on Microsoft licensing which made budget for the hardware.\n \nreply"
    ],
    "link": "https://social.treehouse.systems/@marcan/110252202169575508",
    "first_paragraph": ""
  },
  {
    "title": "Thoughts on the Resiliency of Web Projects (aaronparecki.com)",
    "points": 75,
    "submitter": "mooreds",
    "submit_time": "2024-11-10T16:53:57 1731257637",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=42101190",
    "comments": [
      "The one thing I learned from running https://www.gnod.com (20 years) and https://www.productchart.com (10 years):Keep your stack flat.Most projects of my web developer friends died after months or a few years. None survived for decades. And the reason was always stack rot.Multiple parts of their stack became outdated and so hard to update that they quit.\n \nreply",
      "this!!! I have a site I personally use daily. it's using react 17 and is built with node 16. upgrading either breaks it and I don't have the\ntime to fix the issues. It's got 3 components that break as well. And the CRA build script breaks if you update it as well.I've spent several hours trying 3 different times to upgrade it but I run out of time and give up. So I limp along with tiny changes now and then. I don't know at what point it will become unmaintainableI have a similar problem with an electron app. it's super frustrating.I kind of wish the upstream devs got billed for all the extra work they cause. Then maybe they'll take the pain they create a little more seriously.The latest is eslint which recently broke everything and now 15 or so projects I run will need several hours of maintenance each. work I'd like to put into new features but instead I have to waste on refactoring configuration\n \nreply",
      "> I kind of wish the upstream devs got billed for all the extra work they cause.This is actually very easy to do!Surely you\u2019re already donating generous sums to these open source projects - you can simply let them know you\u2019ll reduce your contribution until the problem is fixed.This is a snarky reply and I\u2019m sorry for that, but seriously why do you feel entitled to anything? Receiving any free software in the first place is more than sufficient.\n \nreply",
      "This is one of the reasons all of the little tools I've been building on https://tools.simonwillison.net/ are Vanilla JavaScript, no React or anything that needs a build tool and only using dependencies if they can't be skipped.I'm a server-side developer by trade, but there's something REALLY neat about being able to build a useful interactive thing as static HTML+JavaScript and know that it will effectively never stop working and is entirely self-contained.\n \nreply",
      "Thanks for all the neat tools!I find Mithril simple enough to be low maintenance for Single Page Applications. We still use a version one of it on a project launched about ten years ago -- although I use version two for later things. And you can use it from plain JavaScript with no compile step.\nhttps://mithril.js.orgI also find Tachyons or similar Atomic CSS libraries to also simplify CSS issues in a more maintainable way -- also with no compile step. From 2017: https://css-tricks.com/growing-popularity-atomic-css/\n \nreply",
      "I've been passing on clients' projects that use old versions of React/Node/etc.Maybe someone enjoys fixing breaking changes in layers of dependencies, but it isn't me.\n \nreply",
      "I\u2019m having the same issue as you but for a React 16 Node 12 web app. Building it was great and good fun but after neglecting updating the dependencies it has become almost impossible to upgrade after 5 years.\nI really wish developer put more effort into developing  web tech that would last more in time.\n \nreply",
      "Can't linting just be disabled ?\n \nreply",
      "I think that is one of the steps towards tacitly admitting the project is no longer maintained/maintainable\n \nreply",
      "I've spun up an old ubuntu laptop recently for.. reasons. I think the last time that machine was in use was in the late 2000s. Poking around on it, I was blown away how simple and resilient the infrastructure of some of my old projects was. Things just build, things just work -- after over a decade of being mothballed.\n \nreply"
    ],
    "link": "https://aaronparecki.com/2024/08/31/9/too-many-projects",
    "first_paragraph": "I just did a massive spring cleaning of one of my servers, trying to clean up what has become quite the mess of clutter. For every website on the server, I either:It feels good to get rid of old code, and to turn previously dynamic sites (with all of the risk they come with) into plain HTML.This is also making me seriously reconsider the value of spinning up any new projects. Several of these are now 10 years old, still churning along fine, but difficult to do any maintenance on because of versions and dependencies. For example:One that I'm particularly happy with, despite it being an ugly pile of PHP, is oauth.net. I inherited this site in 2012, and it hasn't needed any framework upgrades since it's just using PHP templates. My ham radio website w7apk.com\u00a0is similarly a small amount of templated PHP, and it is low stress to maintain, and actually fun to quickly jot some notes down when I want. I like not having to go through the whole ceremony of setting up a dev environment, installi"
  }
]