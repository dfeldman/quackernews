[
  {
    "title": "Fraud, so much fraud (science.org)",
    "points": 827,
    "submitter": "nabla9",
    "submit_time": "2024-09-27T16:33:37.000000Z",
    "num_comments": 524,
    "comments_url": "https://news.ycombinator.com/item?id=41672599",
    "comments": [
      "Here's the article: https://www.science.org/content/article/research-misconduct-...",
      "These sorts of articles raise so many thoughts and emotions in me.  I was trained as a computational biologist with a little lab work and ran gels from time to time.  Personally, I hated gels- they're finicky, messy, ugly, and don't really tell you very much.  But molecular biology as a field runs on gels- it's the priimary source of results for almost everything in molbio.  I have seen more talks and papers that rested entirely a single image of a gel which is really just some dark bands.At the same time, I was a failed scientist: my gels weren't as interesting, or convincing compared to the ones done by the folks who went on to be more successful.  At the time (20+ years ago) it didn't occur to me that anybody would intentionally modify images of gels to promote the results they claimed, although I did assume that folks didn't do a good job of organizing their data, and occasionally published papers that were wrong simply because they confused two images.Would I have been more successful if fewer people (and I now believe this is a common occurrence) published fraudulent images of gels?  Maybe, maybe not.  But the more important thing is that everybody just went along with this.  I participated in many journal clubs where folks would just flip to Figure 3, assume the gel was what the authors claimed, and proceed to agree with (or disagree with) the results and conclusions uncritically.  Whereas I would spend a lot of time trying to understand what experiment was actually run, and what th e data showed.\n \nreply",
      "Similar - when I was younger, I would never have suspected that a scientist was committing fraud.As I've gotten older, I understand that Charlie Munger's observation \"\u201cShow me the incentive and I will show you the outcome.\u201d is applicable everywhere - including science.Academic scientists' careers are driven by publishing, citations and impact.  Arguably some have figured how to game the system to advance their careers.  Science be damned.\n \nreply",
      "I think my favorite Simpsons gag is the episode where Lisa enlists a scientist (voiced by Stephen Jay Gould) to run tests to debunk some angel bones that were found at a construction site.In the middle of the episode, the scientist bicycles up to report, dramatically, that the tests \"were inconclusive\".In the end, it's revealed that the bones were a fraud concocted by some mall developers to promote their new mall.After this is revealed, Lisa asks the scientist about the tests. He shrugs:\"I'm not going to lie to you, Lisa. I never ran the tests.\"It's funny on a few levels but what I find most amusing is that his incentive is left a mystery.\n \nreply",
      "Well, the incentive is that he didn't want to run the tests out of laziness (i.e. he lacked an incentive to run them). He ran to Lisa to give his anticlimactic report not to be deceptive, but rather he just happened to be cycling through that part of town and just needed to use the bathroom really badly.\n \nreply",
      "The writers of these episodes were really on another level considering it was a cartoon.Lisa's first word is still a personal favourite of mine, especially now as a father.\n \nreply",
      "To be honest, it's difficult to tell if the subplot makes sense on purpose, or if the writers just wanted to make a joke and it just happened to end up making sense. I don't think I had ever put the three scenes together before now.\n \nreply",
      "What's her first word?\n \nreply",
      "Apparently it was \"Bart\". I had to look it up because I was curious as well.\n \nreply",
      "https://en.wikipedia.org/wiki/Lisa's_First_Word\n \nreply"
    ],
    "link": "https://www.science.org/content/blog-post/fraud-so-much-fraud",
    "first_paragraph": ""
  },
  {
    "title": "SAML: A Technical Primer (ssoready.com)",
    "points": 124,
    "submitter": "ned_at_codomain",
    "submit_time": "2024-09-27T18:38:38.000000Z",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=41674109",
    "comments": [
      "This is a very weird page, as it seems to suggest that SAML is the only way to do single sign-on integration with IdPs like Okta. But modern systems all do OIDC, which is what you should do. You need a much better reason to support SAML than \"the CISO wants it so they can use Okta\", because the CISO can (and should) just use OIDC.\n \nreply",
      "OIDC is better when using the authorization code flow because it does not only rely on cryptography while validating the token. The relying party needs to talk to the IdP. This is better from a security perspective, because past vulnerabilities have shown, that implementing the cryptography right in every relying party is challenging. You can achieve similar security with SAML when using the artifact binding.\n Note: I work professionally with Keycloak and also offer reviews of OIDC and SAML implementations.\n \nreply",
      "SAML is an unfortunate a necessity in most enterprise environments. There\u2019s almost always something, usually more than one, where SAML is the only option. I do think in 2024, everyone should also offer SAML alternatives in parallel\n.\n \nreply",
      "I don't think artifact binding really addresses many of the issues people are talking about when they suggest OIDC is categorically more secure than SAML.\n \nreply",
      "OIDC is newer and many of the issues with SAML were addressed in the architecture. However I\u2019m curious to hear which attack vectors you are thinking about.\n \nreply",
      "Most obviously, the precarity of XMLDSIG.\n \nreply",
      "This is where artifact binding can greatly increase the security\u2026.Browser sends artifact to RP, RP fetches assertion from IdP via HTTPs, afterwards verifies the signature.Signature verification is not implemented correctly? The attacker still needs to break HTTPS\u2026. And then you would have a big problem anyway.\n \nreply",
      "> just use OIDCOIDC doesn't scale, and OIDC Federation is still in draft.  SAML Federation is mature with wide support and good discovery UX thanks to SeamlessAccess.SAML has a variety of standard attribute bundles, entity categories, frameworks, and profiles covering important integrations, e.g., identity assurance.  These are slowly being defined in (or ported to) OIDC.I like OIDC and think highly of the people working on it, but it's nowhere near as cut and dry as you suggest.\n \nreply",
      "If your CISO wants to use SAML for anything, fire your CISO.Frankly I\u2019d suggest the same thing about Okta but as bad as they are whatever you do to avoid them would probably be worse in practice.\n \nreply",
      "Do you mean chooses it over OIDC, or even when a product can only do SSO via SAML?\n \nreply"
    ],
    "link": "https://ssoready.com/docs/saml/saml-technical-primer",
    "first_paragraph": "A technical overview of SAML works, and how it fits into your product and your customer's businessIf you just want to start integrating SAML right away, check out the SAML\nquickstart. You can get a SAML integration\nworking end-to-end within a few hours.This article is for folks who want to understand SAML at a deeper technical\nlevel, or how they could implement SAML without using an open-source library\nlike SSOReady.SAML\n(\u201cSecurity Assertion Markup Language\u201d) is a source of a lot of confusion for\ndevelopers. This article is a technical primer on some of the most common\nquestions engineers and other technical folks have about SAML:You care about supporting SAML because your customer wants your product to\nsupport SAML. This is sound reasoning on your part. But why does your customer\nwant SAML support?Your users probably don\u2019t know what SAML is. What they do know about is their\ncompany\u2019s identity provider. The most popular one is called\nOkta; other common\ncompetitors to Okta include Micro"
  },
  {
    "title": "Lion Cove: Intel's P-Core Roars (chipsandcheese.com)",
    "points": 35,
    "submitter": "luyu_wu",
    "submit_time": "2024-09-27T21:18:33.000000Z",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41675637",
    "comments": [
      "> A plain memory latency test sees about 131.4 ns of DRAM latency. Creating some artificial bandwidth load drops latency to 112.4 ns.Can someone put this in context? The values seem order of magnitude higher than here: https://www.anandtech.com/show/16143/insights-into-ddr5-subt...\n \nreply",
      "I think the numbers in that article (the CAS latency) are the latency numbers \"within\" the DRAM module itself, not the end to end latency between the processor and the RAM.You could read the article on the latest AMD top of the line desktop chip to compare: https://chipsandcheese.com/2024/08/14/amds-ryzen-9950x-zen-5... (although that's a desktop chip, the original article compares the Intel performance to 128 ns of DRAM latency for AMD's mobile platform Strix Point)\n \nreply",
      "It looks awesome. I am definitely going to purchase a 14\" Lunar Lake laptop from either Asus (Zenbook S14) or Lenovo (Yoga Slim). I really like my 14\" MBP form factor and these look like they would be great for running Linux.\n \nreply",
      "I'm really curious about how well they run Linux. e.g. will the NPU work under Linux in the same way it does on Windows? Or does it require specific drivers? Same with the batter life - if there a Windows-specific driver that helps with this, or can we expect the same under Linux?\n \nreply",
      "All NPUs require drivers. https://www.phoronix.com/news/Intel-Linux-NPU-Driver-1.5\n \nreply"
    ],
    "link": "https://chipsandcheese.com/2024/09/27/lion-cove-intels-p-core-roars/",
    "first_paragraph": ""
  },
  {
    "title": "How AlphaChip transformed computer chip design (deepmind.google)",
    "points": 194,
    "submitter": "isof4ult",
    "submit_time": "2024-09-27T15:56:01.000000Z",
    "num_comments": 114,
    "comments_url": "https://news.ycombinator.com/item?id=41672110",
    "comments": [
      "This work from Google (original Nature paper: https://www.nature.com/articles/s41586-021-03544-w) has been credibly criticized by several researchers in the EDA CAD discipline. These papers are of interest:- A rebuttal by a researcher within Google who wrote this at the same time as the \"AlphaChip\" work was going on (\"Stronger Baselines for Evaluating Deep Reinforcement Learning in Chip Placement\"): http://47.190.89.225/pub/education/MLcontra.pdf- The 2023 ISPD paper from a group at UCSD (\"Assessment of Reinforcement Learning for Macro Placement\"): https://vlsicad.ucsd.edu/Publications/Conferences/396/c396.p...- A paper from Igor Markov which critically evaluates the \"AlphaChip\" algorithm (\"The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement\"): https://arxiv.org/pdf/2306.09633In short, the Google authors did not fairly evaluate their RL macro placement algorithm against other SOTA algorithms: rather they claim to perform better than a human at macro placement, which is far short of what mixed-placement algorithms are capable of today. The RL technique also requires significantly more compute than other algorithms and ultimately is learning a surrogate function for placement iteration rather than learning any novel representation of the placement problem itself.In full disclosure, I am quite skeptical of their work and wrote a detailed post on my website: https://vighneshiyer.com/misc/ml-for-placement/\n \nreply",
      "FD: I have been following this whole thing for a while, and know personally a number of the people involved.The AlphaChip authors address criticism in their addendum, and in a prior statement from the co-lead authors: https://www.nature.com/articles/s41586-024-08032-5 ,  https://www.annagoldie.com/home/statement- The 2023 ISPD paper didn't pre-train at all. This means no learning from experience, for a learning-based algorithm. I feel like you can stop reading there.- The ISPD paper and the MLcontra paper both used much larger older technology node sizes, which have pretty different physical properties. TPU has a sub 10nm technology node size, whereas ISPD uses 45nm and 12nm. These are really different from a physical design perspective. Even worse, MLcontra uses a truly ancient benchmark with >100nm technology node size.Markov's paper just summarizes the other two.(Incidentally, none of ISPD / MLcontra / Markov were peer reviewed - ISPD 2023 was an invited paper.)There's a lot of other stuff wrong with the ISPD paper and the MLcontra paper - happy to go into it - and a ton of weird financial incentives lurking in the background. Commercial EDA companies do NOT want a free open-source tool like AlphaChip to take over.Reading your post, I appreciate the thoroughness, but it seems like you are too quick to let ISPD 2023 off the hook for failing to pre-train and using less compute. The code for pre-training is just the code for training --- you train on some chips, and you save and reuse the weights between runs. There's really no excuse for failing to do this, and the original Nature paper described at length how valuable pre-training was. Given how different TPU is from the chips they were evaluating on, they should have done their own pre-training, regardless of whether the AlphaChip team released a pre-trained checkpoint on TPU.(Using less compute isn't just about making it take longer - ISPD 2023 used half as many GPUs and 1/20th as many RL experience collectors, which may screw with the dynamics of the RL job. And... why not just match the original authors' compute, anyway? Isn't this supposed to be a reproduction attempt? I really do not understand their decisions here.)\n \nreply",
      "Why does pretraining or not matter in the ISPD 2023 paper? The circuit_training repo, as noted in the rebuttal of the rebuttal by the ISPD 2023 paper authors, claims training from scratch is \"comparable or better\" than fine-tuning the pre-trained model. So no matter your opinion on the importance of the pretraining step, this result isn't replicable, at which point the ball is in Google's court to release code/checkpoints to show otherwise.\n \nreply",
      "The quick-start guide in the repo that said you don't have to pre-train for the sample test case, meaning that you can validate your setup without pre-training. That does not mean you don't need to pre-train! Again, the paper talks at length about the importance of pre-training.\n \nreply",
      "Oh, man... this is the same old stuff from the 2023 Anna Goldie statement (is this Anna Goldie's comment?). This was all addressed by Kahng in 2023 - no valid criticisms. Where do I start?Kahng's ISPD 2023 paper is not in dispute - no established experts objected to it. The Nature paper is in dispute. Dozens of experts objected to it: Kahng, Cheng, Markov, Madden, Lienig, Swartz objected publically.The fact that Kahng's paper was invited doesn't mean it wasn't peer reviewed. I checked with ISPD chairs in 2023 - Kahng's paper was thoroughly reviewed and went through multiple rounds of comments. Do you accept it now? Would you accept peer-reviewed versions of other papers?Kahng is the most prominent active researcher in this field. If anyone knows this stuff, it's Kahng. There were also five other authors in that paper, including another celebrated professor, Cheng.The pre-training thing was disclaimed in the Google release. No code, data or instructions for pretraining were given by Google for years. The instructions said clearly: you can get results comparable to Nature without pre-training.The \"much older technology\" is also a bogus issue because the HPWL scales linearly and is reported by all commercial tools. Rectangles are rectangles. This is textbook material. But Kahng etc al prepared some very fresh examples, including NVDLA, with two recent technologies. Guess what, RL did poorly on those. Are you accepting this result?The bit about financial incentives and open-source is blatantly bogus, as Kahng leads OpenROAD - the main open-source EDA framework. He is not employed by any EDA companies. It is Google who has huge incentives here, see Demis Hassabis tweet \"our chips are so good...\".The \"Stronger Baselines\" matched compute resources exactly. Kahng and his coauthors performed fair comparisons between annealing and RL, giving the same resources to each. Giving greater resources is unlikely to change results. This was thoroughly addressed in Kahng's FAQ - if you only could read that.The resources used by Google were huge. Cadence tools in Kahng's paper ran hundreds times faster and produced better results. That is as conclusive as it gets.It doesn't take a Ph.D. to understand fair comparisons.\n \nreply",
      "For AlphaChip, pre-training is just training. You train, and save the weights in between. This has always been supported by the Google's open-source repository. I've read Kahng's FAQ, and he fails to address this, which is unsurprising, because there's simply no excuse for cutting out pre-training for a learning-based method. In his setup, every time AlphaChip sees a new chip, he re-randomizes the weights and makes it learn from scratch. This is obviously a terrible move.HPWL (half-perimeter wirelength) is an approximation of wirelength, which is only one component of the chip floorplanning objective function. It is relatively easy to crunch all the components together and optimize HPWL --- minimizing actual wirelength while avoiding congestion issues is much harder.Simulated annealing is good at quickly converging on a bad solution to the problem, with relatively little compute. So what? We aren't compute-limited here. Chip design is a lengthy, expensive process where even a few-percent wirelength reduction can be worth millions of dollars. What matters is the end result, and ML has SA beat.(As for conflict of interest, my understanding is Cadence has been funding Kahng's lab for years, and Markov's LinkedIn says he works for Synopsis. Meanwhile, Google has released a free, open-source tool.)\n \nreply",
      "It's not that one needs an excuse. The Google CT repo said clearly you don't need to pretrain. \"supported\" usually includes at least an illustration, some scripts to get it going - no such thing there before Kahng's paper. Pre-trained was not recommended and was not supported.Everything optimized in Nature RL is an approximation. HPWL is where you start, and RL uses it in the objective function too. As shown in \"Stronger Baselines\", RL loses a lot by HPWL - so much that nothing else can save it. If your wires are very long, you need routing tracks to route them, and you end up with congestion too.SA consistently produces better solutions than RL for various time budgets. That's what matters. Both papers have shown that SA produces competent solutions. You give SA more time, you get better solutions. In a fair comparison, you give equal budgets to SA and RL. RL loses. This was confirmed using Google's RL code and two independent SA implementations, on many circuits. Very definitively. No, ML did not have SA beat - please read the papers.Cadence hasn't funded Kahng for a long time. In fact, Google funded Kahng more recently, so he has all the incentives to support Google. Markov's LinkedIn page says he worked at Google before. Even Chatterjee, of all people, worked at Google.Google's open-source tool is a head fake, it's practically unusable.Update: I'll respond to the next comment here since there's no Reply button.1. The Nature paper said one thing, the code did something else, as we've discovered. The RL method does some training as it goes. So, pre-training is not the same as training. Hence \"pre\". Another problem with pretraining in Google work is data contamination - we can't compare test and training data. The Google folks admitted to training and testing on different versions of the same design. That's bad. Rejection-level bad.2. HPWL is indeed a nice simple objective. So nice that Jeff Dean's recent talks use it. It is chip design. All commercial circuit placers without exception optimize it and report it. All EDA publications report it. Google's RL optimized  HPWL + density + congestion3. This shows you aren't familiar with EDA. Simulated Annealing was the king of placement from mid 1980s to mid 1990s. Most chips were placed by SA. But you don't have to go far - as I recall, the Nature paper says they used SA to postprocess macro placements.SA can indeed find mediocre solutions quickly, but keeps on improving them, just like RL. Perhaps, you aren't familiar with SA. I am. There are provable results showing SA finds optimal solution if given enough time. Not for RL.\n \nreply",
      "The Nature paper describes the importance of pre-training repeatedly. The ability to learn from experience is the whole point of the method. Pre-training is just training and saving the weights -- this is ML 101.I'm glad you agree that HPWL is a proxy metric. Optimizing HPWL is a fun applied math puzzle, but it's not chip design.I am unaware of a single instance of someone using SA to generate real-world, usable macro layouts that were actually taped out, much less for modern chip design, in part due to SA's struggles to manage congestion, resulting in unusable layouts. SA converges quickly to a bad solution, but this is of little practical value.\n \nreply",
      "1. The Nature paper said one thing, the code did something else, as we've discovered. The RL method does some training as it goes. So, pre-training is not the same as training. Hence \"pre\". Another problem with pretraining in Google work is data contamination - we can't compare test and training data. The Google folks admitted to training and testing on different versions of the same design. That's bad. Rejection-level bad.2. HPWL is indeed a nice simple objective. So nice that Jeff Dean's recent talks use it. It is chip design. All commercial circuit placers without exception optimize it and report it. All EDA publications report it. Google's RL optimized HPWL + density + congestion3. This shows you aren't familiar with EDA. Simulated Annealing was the king of placement from mid 1980s to mid 1990s. Most chips were placed by SA. But you don't have to go far - as I recall, the Nature paper says they used SA to postprocess macro placements.SA can indeed find mediocre solutions quickly, but keeps on improving them, just like RL. Perhaps, you aren't familiar with SA. I am. There are provable results showing SA finds optimal solution if given enough time. Not for RL.\n \nreply",
      "SA and HPWL are most definitely used as of today for the chips that power the GPUs used for \"ML 101\". But frankly this has the same value as saying \"some sort algorithm is used somewhere\" -- they're well entrenched basics of the field. To claim that SA produces \"bad congestion\" is like claiming that using steel pans produces bad cooking -- needs a shitton of context and qualification since you cannot generalize this way.\n \nreply"
    ],
    "link": "https://deepmind.google/discover/blog/how-alphachip-transformed-computer-chip-design/",
    "first_paragraph": "Latest postsLatest technology postsLatest postsResearchAnna Goldie and Azalia MirhoseiniIn 2020, we released a preprint introducing our novel reinforcement learning method for designing chip layouts, which we later published in Nature and open sourced.Today, we\u2019re publishing a Nature addendum that describes more about our method and its impact on the field of chip design. We\u2019re also releasing a pre-trained checkpoint, sharing the model weights and announcing its name: AlphaChip.Computer chips have fueled remarkable progress in artificial intelligence (AI), and AlphaChip returns the favor by using AI to accelerate and optimize chip design. The method has been used to design superhuman chip layouts in the last three generations of Google\u2019s custom AI accelerator, the Tensor Processing Unit (TPU).AlphaChip was one of the first reinforcement learning approaches used to solve a real-world engineering problem. It generates superhuman or comparable chip layouts in hours, rather than taking wee"
  },
  {
    "title": "Obsessed with Cuttle: Parametric CAD for prototyping, producing, and procrastin (hannahilea.com)",
    "points": 65,
    "submitter": "todsacerdoti",
    "submit_time": "2024-09-27T19:35:32.000000Z",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41674677",
    "comments": [
      "I am one of the creators of Cuttle. It stems from my research building direct manipulation + programming environments like http://recursivedrawing.com/ and http://aprt.us/From a programmer's perspective, you can think of Cuttle as a direct manipulation vector editor (like Inkscape or Adobe Illustrator) that can be driven with parameters and JS code where you need it.Unlike my previous research projects, this is a commercial startup mostly catering to laser cutting small businesses, though you can use it for anything where you want a 2D vector editor + some programmatic capabilities.I'll try to answer questions that come up in this HN thread.Thank you for sharing your work Hannah! Very cool stuff!\n \nreply",
      "I'm mainly curious whether the concepts in Cuttle could be exposed as plugins in Inkscape, or as a standalone application written in Qt-Python.\n \nreply",
      "A Cuttle project is \u2014 behind the scenes \u2014 a program. Each \u201ccomponent\u201d is a function. \u201cModifiers\u201d are functions that take input geometry (and parameters) and use JS code to create arbitrary output geometry. All of this code can be live edited.At the same time you can do arbitrary \u201cdrawing\u201d with a bezier pen tool and move/transform shapes. In this case you are essentially using the canvas drag-and-drop to manipulate literals in the program.But fundamentally a Cuttle project is a program and the Cuttle Editor is an IDE that looks like a vector editor on the surface.Because of this I\u2019m not sure how much of Cuttle could be grafted onto a program whose architecture is more rooted as an editor of static vector graphics. I do know that Inkscape has some \u201clive effects\u201d which are similar to Cuttle\u2019s \u201clive\u201d modifiers.If you are interested in Cuttle\u2019s architecture, I did a one hour walkthrough on this interview, https://www.youtube.com/watch?v=2el-85vG-IU\n \nreply",
      "Always so wowed by posts about maker spaces :)Is it normal in the states?  And is it full of cool projects?\n \nreply",
      "What do they mean by \"create 5 free projects\"? Will they laser-cut it for you and send it to you by mail?\n \nreply",
      "On a free account you can create up to 5 projects in the Cuttle Editor (and you can delete them if you want to create more...)We don't laser cut anything for you. You can download your project as an SVG file (or DXF, etc) which you can then send to a laser cutter hooked up to your computer.The product is designed for people who have access to a laser cutter, e.g. at home or at a makerspace.\n \nreply",
      "Totally dig this, especially the doorbell chime cover & music box!\n \nreply"
    ],
    "link": "https://hannahilea.com/blog/cuttle-obsession/",
    "first_paragraph": ""
  },
  {
    "title": "Python for Inversive and Hyperbolic Geometry (psu.ac.th)",
    "points": 32,
    "submitter": "thunderbong",
    "submit_time": "2024-09-27T20:07:03.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41675029",
    "comments": [
      "Python is a very poor choice for such a tool. Julia should have been used\n \nreply",
      "In case this is relevant to your reasons for posting \u2026 every time I see one of the fact free posts the slam Python to promote Julia it pushes me further from considering Julia for anything.\n \nreply"
    ],
    "link": "https://coe.psu.ac.th/ad/invhyper/",
    "first_paragraph": "The Python code available on this page is a collection of classes and support functions for visualizing \r\ninversive and \r\nhyperbolic geometry, with the hyperbolic examples utilizing the \r\nPoincar\u00e9 disc model. For more online information on hyperbolic geometry see \r\nhere.I was prompted to develop this software while reading about these topics in the excellent textbook \r\n\"Geometry\" by David A. Brannan, Matthew F. Esplen, and Jeremy J. Gray, Cambridge University Press; 2nd ed., and in particular chapters 5 and 6. I also found chapter 10 of  \r\n\"Euclidean and Non-Euclidean Geometries\" by Marvin J. Greenberg, W.H. Freeman, 4th ed., useful for additional information on hyperbolic trigonometry.I've 'repurposed' most of my code from two sources \u2013 \r\nCasey Duckering's Python hyperbolic library and the hyperbolic_tessellation code in Section 16.7\r\nof \"A Programmer's Introduction to Mathematics\" by Jeremy Kun. My main 'contribution', especially in the case of Duckering library, was to drastically s"
  },
  {
    "title": "If WordPress is to survive, Matt Mullenweg must be removed (joshcollinsworth.com)",
    "points": 102,
    "submitter": "graeme",
    "submit_time": "2024-09-27T23:49:15.000000Z",
    "num_comments": 48,
    "comments_url": "https://news.ycombinator.com/item?id=41676653",
    "comments": [
      "I hope, for the good of the community, that Matt will choose either nonprofit leader or tech CEO. It\u2019s become clear that both roles cannot live within one person.If he were just the leader of the WordPress foundation, this whole thing would just be an embarrassing PR failure. As it is, I wonder if his actions will rise to the level of criminal.After watching his interview with The Primeagen, it seems like he is mentally wearing the clothes of a righteous prophet\u2026the misunderstood advocate of a disrespected organization.Unfortunately, he\u2019s ignoring the fact that he invested in WPE years ago, is CEO of a direct competitor, has publicly said he hopes WPE loses billions of dollars as a result, apparently has no proof in writing, and is pulling thousands of innocent developers into his petulant crusade.\n \nreply",
      "Given the age and ubiquity of Wordpress, I am shocked at the relative immaturity of Matt's communication skills.He thinks the world has all the historical understanding and nuance of the situation. Why would they?This looks like a world record speedrun attempt (any%) at destroying a legacy.It's worth noting that WPEngine looked like this all the way back in 2011: https://web.archive.org/web/20110112043959/http://wpengine.c...They have never pretended to be anything else.Why now, Matt?\n \nreply",
      "Exactly. This comes off as a totally unhinged and immature rant, unbecoming of the CEO of a company that likely has a 8 or 9 figure revenue.I didn\u2019t know (or really care) about this battle, but I\u2019ve always passively seen Matt as one of the insightful grandfathers of the blogging era, having insights from the observations from his perch.This blog post erased that.\n \nreply",
      ">I\u2019ve always passively seen Matt as one of the insightful grandfathers of the blogging era.I've always felt he was an asshole but could never ground that to a concrete observation. Now I'm certain of it.\n \nreply",
      "He's not an asshole, he's just \"post-economic\"\n \nreply",
      "That 2011 snapshot actually makes the opposite point: the WordPress logo is prominently displayed next to the \"WP Engine\" title on the screenshot!It does look like they fixed just a few months later, though: https://web.archive.org/web/20111001085943/http://wpengine.c...(How fun to see the selling point \"Digg-Proof Scalability\")\n \nreply",
      "Giving Matt the benefit of the doubt, the answer to \u201cWhy now?\u201d is that enough is enough. Why does Matt deserve the benefit of the doubt? Because his companies have been contributing to WordPress while WP Engine has not.Matt claims he has been privately discussing with WP Engine for ~18 months about their level of contribution. Automatic contributes the equivalent of 75 full time employees to WordPress and WP Engine contributes 1, despite the companies being comparable in size.Matt\u2019s actions may have been bad for optics, but I do not fault him for using the resources at his disposal to correct what he sees as injustice.\n \nreply",
      "> Matt\u2019s actions may have been bad for optics, but I do not fault him for using the resources at his disposal to correct what he sees as injustice.Of course, there are consequences to using said resources inappropriately.\n \nreply",
      "I really wonder what that mean contributing to WordPress... from the cybersecurity point of view in 2024, there is/were no contributions: it is common to be hacked when you use Wordpress (e.g. [1]).[1] https://www.reddit.com/r/ProWordPress/comments/1cv15mt/would...\n \nreply",
      "It really does feel like Matt is saying \"how dare you question me\"\n \nreply"
    ],
    "link": "https://joshcollinsworth.com/blog/fire-matt",
    "first_paragraph": "This post is a little more hasty than some of my others, in the interest of expedience. I hope you\u2019ll bear with the poorly edited jumble of thoughts. It\u2019s being actively edited. I also usually avoid cussing on my blog, but I do a little here because it feels warranted.Cover image from this Etsy store (unaffiliated).There are some people who think being right about something gives them the right to do whatever they think should be done about it; a license to act however they see fit in order to correct that wrong.This, of course, is never the case. Doing the wrong thing for the right reason never makes it the right thing. No matter how bad the original infraction, there are some responses it never justifies. Two wrongs don\u2019t make a right, to be pithy about it. The ends don\u2019t justify\u2026you know how it goes.Matt Mullenweg appears to be one of those people who believe the ends do indeed justify the means, as he\u2019s effectively blowing up massive swaths of the WordPress community in his fight w"
  },
  {
    "title": "It's hard to write code for computers, but it's harder to write code for humans (erikbern.com)",
    "points": 319,
    "submitter": "imartin2k",
    "submit_time": "2024-09-27T09:59:15.000000Z",
    "num_comments": 103,
    "comments_url": "https://news.ycombinator.com/item?id=41668304",
    "comments": [
      "People learn things differently.I really need the \"core concept\" first, before diving into examples, (unless the core concept is extremely simple).Many tutorials are like hand-holding Lego building. Here's your Lego pieces, watch me and follow me in building this toy project, and you'll know how to Lego at the end of the day.I just don't function very well in this model. I want to know how and why decisions are made. I want to see things from the author's perspective. I want to know how the Lego pieces each feels like, and how they connect to each other, and how you arrive at certain designs in a certain way. Trying to follow tutorials before at least some high-level, conceptual discussion, feels to me like I'm trying to reverse-engineer something that I shouldn't need to.Most of the time if I'm approaching a new library or framework, I read read the introduction texts, and skip the \"Getting started\" code samples. Usually, there's going to be some sort of \"Advanced\" section where a lot more talking and discussing of concepts happens, and that's what I'd like to dive into first. I'll go for the API references next, try to grasp what the important interfaces look like, and finally I'll get back to the basic code samples in the beginning of the tutorial.\n \nreply",
      "I used to think I was a \"core concept\" kind of person, but later I realized I took that way too far and would refuse to do things outside of my comfort zone unless I felt like I truly understood everything ahead of time.Nowadays I'm much more likely to just jump in and start working with examples directly, and I feel much more productive. It's partly a thing of trust: I just trust that the makers of high quality software have put in enough thought to make their interfaces easy to understand, for the common use cases, without digging too deep into the internals.It frequently happens, of course, that I hit a roadblock where I do have to go deeper -- but that's only because there were 10 other things where I was successfully able to get by on surface impressions alone. So I find that even when I do dig in it's often time well spent.\n \nreply",
      "I would much rather have 60 different examples of middling quality covering a majority of use cases than a 5-page exposition about why the maintainer chose whatever database or why I should think of components as conveyer belts or whatever strained analogy they come up with. This only works with a lot of examples though, I've come across numerous projects where they think they're doing this but they've got a toy-level \"Hello World\" style example and maybe one more and that's it.But in a perfect world, they'd have both. The GP can read that essay and get their bearings, and I can click \"Examples\" and start copying & pasting until I start to figure out how things work.\n \nreply",
      "I have the same (and ran into this trying to wrap my head around why Maven didn't work... I don't want a tutorial explaining how to get started, I need to understand the fundamentals to understand what's happening!).I think, however, that starting from the examples might help with good API design: if you design your API to be \"core concept first\", this will likely lead to an API that _can only be used after you understand the core concepts_, which is not great when people are only occasional users.\n \nreply",
      "That's why there are four axes of documentation.\n \nreply",
      "Sounds like you have an explanation of how painful documentation is.. But how do these axes work?\n \nreply",
      "Possibly the gp means the four quadrants (two axes)?:https://dunnhq.com/posts/2023/documentation-quadrants/\n \nreply",
      "> There are 4 types of documentation, laid out on two axis:> Learning vs. Doing\n> Practical vs. Theoretical-tutorials-how-to guides-discussions-referencehttps://docs.divio.com/documentation-system/\n \nreply",
      "This may be a cultural trait too. Erin Meyer in her \"Culture Map\" Book mentions this idea that every culture approach persuading others differently from theory-first to examples-first.\n \nreply",
      "I agree. Many coding courses start with setting up your environment, where to download the base packages... I much prefer the core concepts first.\n \nreply"
    ],
    "link": "https://erikbern.com/2024/09/27/its-hard-to-write-code-for-humans.html",
    "first_paragraph": "Writing code for a computer is hard enough.\nYou take something big and fuzzy, some large vague business outcome you want to achive.\nThen you break it down recursively and think about all the cases until you have clear logical statements a computer can follow.\nComputers are very good at following logical statements.Now, let's crank it up a notch.\nLet's try to write code for humans!I need to clarify what I mean.\nI'm talking about code that other humans will interact with.\nMore specifically, I'm talking about the art of crafting joyful frameworks, libraries, APIs, SDKs, DSLs, embedded DSLs, or maybe even programming languages.Writing this code is much harder, because you're not just telling a computer what to do, you're also grappling with another user's mental model of your code.\nNow it's equal part computer science and psychology of reasoning, or something.\nHow do you get that person to understand your code?Feynman famously said: Imagine how much harder physics would be if electrons had"
  },
  {
    "title": "The Architecture of London Pubs (1966) (thelondonmagazine.org)",
    "points": 61,
    "submitter": "youbet",
    "submit_time": "2024-09-27T19:04:38.000000Z",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=41674379",
    "comments": [
      "Tangential: As an American, one of the things I liked most about London pubs when I first started visiting in the \u201800s was the lack of screens, which were hard to escape in American bars. Unfortunately this was only temporary, as the majority of the London pubs I\u2019ve seen on recent visits are covered with screens like home.\n \nreply",
      "As others say, Londoners/brits make a distinction between \u201cpub\u201d and \u201csports pub\u201d, the former don\u2019t usually have any TV (or it\u2019s off, only used for big England games when every pub becomes a sports pub).Contrary to your experience, I\u2019m pretty sure that most pubs are not sports pubs in London\n \nreply",
      "They do though. The old guard keeping the depressing pubholes alive do so by watching their football there. It's usually just one or two screens, granted, but they're there. Thankfully they can be easy ignored.\n \nreply",
      "Sounds like you'd enjoy visiting a pub owned by Samuel Smith.> Our pubs are havens from the digital world \u2013 there are no TVs or background music. The use of mobile phones, laptops and other tech is not allowed in our pubs.https://samuelsmithsbrewery.co.uk/pubs/\n \nreply",
      "In the 80s, Sam Smith pubs had a \u201825 pubs in London\u2019 challenge.  Get a drink in each of the 25 and get a T-shirt. It took me and a friend several weeks. There was a story of some guys doing it in a weekend. Hard because of travel AND opening times of some of the financial centre ones.Good Times!  And of course, no screens and no-one had phones (except in the financial centre and those came with an external battery)\n \nreply",
      "No screens and at most of them no music either. Very few people drinking while standing. Just a pleasant place to have some beers with friends.When I moved back from London to the US (where I\u2019ve spent 90% of my life) I was so much more distracted by the screens than I had ever been before.\n \nreply",
      "go to smaller pubs. They don\u2019t have the footfall to justify the exorbitant commercial sports license fees and so don\u2019t have screens. Fancier pubs and gastropubs also tend not to have screens\n \nreply",
      "That's a sports pub.\n \nreply",
      "Stay away from sports pubs/bars.\n \nreply",
      "I've been in one which had tvs over the orinals, in sweden.\n \nreply"
    ],
    "link": "https://thelondonmagazine.org/archive-the-architecture-of-london-pubs-by-stephen-gardiner/",
    "first_paragraph": "Stephen Gardiner.\nIn the mid-sixties, architect and writer, Stephen Gardiner, wrote recurrent socio-cultural architectural analysis for The London Magazine. This installment, on the state of that bastion of so-called English cultural activity, the pub, originally appeared in the December 1966 edition of The London Magazine...What\u2019s happened to the pub, that most personal piece of English belongings? The place where you stand up and drink, where there are scrubbed oak benches to sit on, partitions to conceal private conversations, men with pipes and caps, and there is sawdust and beer on wooden floors? What\u2019s happened to those powerful bar tops, the glass flaps over the counter and the bottle-crammed shelves; the complicated cut-glass that fortified you from the fog and the snow, and through which the indecipherable interior form of figures, furniture and lights made impossible shapes from the wet streets outside? What\u2019s happened? \u2013 they\u2019re going, or gone, most of them. The great brewer"
  },
  {
    "title": "Unplanned Exposure During Diving in the Spent Nuclear Fuel Pool (isoe-network.net)",
    "points": 5,
    "submitter": "marcodiego",
    "submit_time": "2024-09-25T13:01:47.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://isoe-network.net/publications/pub-proceedings/symposia/north-american-tc-symposia/fort-lauderdale-usa-january-2011/slides-14/session-iv-1/1756-ritter2011-ppt/file.html",
    "first_paragraph": ""
  },
  {
    "title": "MTA Open Data Challenge (mta.info)",
    "points": 182,
    "submitter": "oftenwrong",
    "submit_time": "2024-09-27T13:27:05.000000Z",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=41670186",
    "comments": [
      "I do work with \"open data\" on a near-obsessive basis and -- friends, please do not trust \"open data\" portals to reflect reality accurately. The datasets are often curated, categories changed during the ETL processes, rows missing, and things like that. For example, Chicago's \"crimes\" dataset intentionally doesn't include all homicides. Can't remember the exact dataset, but I once had a conversation with Chicago's head of open data who told me that they intentionally removed many rows because they were concerned that the public was going to misinterpret the results... but didn't make it clear that rows were missing. So I guess everybody gets the opportunity to misinterpret the results!FOIA is the better alternative because it gives you the original, pre-cleaned data. Open data is a lie.\n \nreply",
      "This is super true. For my city\u2019s portal as well. I\u2019ve found one way around this by versioning the dataset - that is, committing the diffs in git. Credit to Simon Willison\u2019s git-scraping technique.I do this with my power company\u2019s outage map: https://github.com/patricktrainer/entergy-outages67k commits!https://simonwillison.net/2020/Oct/9/git-scraping/\n \nreply",
      "Where I grew up the data for murders is curated in such a way that anybody that dies 24 after being attacked is not considered a \u2018murder\u2019. Tehy do this to reduce the statistical murder rate.\n \nreply",
      "Well now we know why crime is down\n \nreply",
      "Although pre-cleaned data is often not reflective of reality and requires careful work to use, often requiring a lot more knowledge of the field.\n \nreply",
      "I can only imagine. Many ETLs are already messy in companies with better tooling and processes.Would love to read more about your experience with Open Data. Any place where I can reach out?\n \nreply",
      "Here's something about shotspotter data in Chicago: https://x.com/foiachap/status/1775296597850480663And this one makes some rounds: https://mchap.io/that-time-the-city-of-seattle-accidentally-...Feel free to reach out!\n \nreply",
      "Would be neat if instead an open-ended challenge (\"here's some data, do something cool\") the MTA instead shared a list of hypothetical or real problems to solve and provided data that could be potentially useful in the exploration/solution to the problem.\n \nreply",
      "Also, considering they just got a 68 billion dollar budget approved [1] over the next 5 years, even a small monetary reward would be nice for this. It doesn't need to be a ton of money, but something other than \"here's a piece of empty and memorabilia and we'll write a blog post\" would be a good incentive[1] https://ny1.com/nyc/all-boroughs/news/2024/09/25/mta-board-a...\n \nreply",
      "I think you are misinterpreting that article. The MTA board approved the plan to spend $68B but they depend on the state to give them funds. That\u2019s the amount of money they are asking for based on the projects they want to complete. The state government has to pass a budget to fund that plan (or do something else).  Additionally several current, already started projects are on hold due to the \u201cpause\u201d of congestion pricing which was going to be a funding source.\n \nreply"
    ],
    "link": "https://new.mta.info/article/mta-open-data-challenge",
    "first_paragraph": "The MTA is excited to announce our first-ever Open Data Challenge! This month-long competition invites community members, developers, and data enthusiasts to harness the power of MTA's open data. Participants will develop a project that creatively utilizes at least one MTA open dataset.Whether you're passionate about transportation, technology, or urban planning, this is your chance to dig deeper into MTA\u2019s open data and make a meaningful impact.The winner will receive a vintage New York City Transit item from our memorabilia collection. Additionally, the winning project will be featured in a blog post on our Data & Analytics Blog, as well as on the MTA\u2019s social media accounts.All projects must use at least one MTA dataset on data.ny.gov. See a full list of MTA open datasets.Projects of any medium are welcome. Examples include a web app, static data visualization, a map, written report, or piece of art. If you are looking for inspiration, check out\u00a0this Data & Analytics blog post\u00a0for p"
  },
  {
    "title": "I Am Tired of AI (ontestautomation.com)",
    "points": 994,
    "submitter": "Liriel",
    "submit_time": "2024-09-27T08:20:24.000000Z",
    "num_comments": 901,
    "comments_url": "https://news.ycombinator.com/item?id=41667652",
    "comments": [
      "I'm tired of LLMs.Enough billions of dollars have been spent on LLMs that a reasonably good picture of what they can and can't do has emerged. They're really good at some things, terrible at others, and prone to doing something totally wrong some fraction of the time. That last limits their usefulness. They can't safely be in charge of anything important.If someone doesn't soon figure out how to get a confidence metric out of an LLM, we're headed for another \"AI Winter\".\nAlthough at a much higher level than last time. It will still be a billion dollar industry, but not a trillion dollar one.At some point, the market for LLM-generated blithering should be saturated. Somebody has to read the stuff. Although you can task another system to summarize and rank it. How much of \"AI\" is generating content to be read by Google's search engine? This may be a bigger energy drain than Bitcoin mining.\n \nreply",
      "\"They're really good at some things, terrible at others, and prone to doing something totally wrong some fraction of the time.\"I agree 100% with this sentiment, but, it also is a decent description of individual humans.This is what processes and control systems/controls are for.  These are evolving at a slower pace than the LLMs themselves at the moment so we're looking to the LLM to be its own control.   I don't think it will be any better than the average human is at being their own control, but by no means does that mean it's not a solvable problem.\n \nreply",
      "> I agree 100% with this sentiment, but, it also is a decent description of individual humans.But you can understand individual humans and learn which are trustworthy for what. If I want a specific piece of information, I have people in my life that I know I can consult to get an answer that will most likely be correct and that person will be able to give me an accurate assessment of their certainty and they know how to accurately confirm their knowledge and they\u2019ll let me know later if it turns out they were wrong or the information changed and\u2026None of that is true with LLMs. I never know if I can trust the output, unless I\u2019m already an expert on the subject. Which kind of defeats the purpose. Which isn\u2019t to say they\u2019re never helpful, but in my experience they waste my time more often than they save it, and at an environmental/energy cost I don\u2019t personally find acceptable.\n \nreply",
      "It defeats the purpose of LLM as personal expert on arbitrary topics. But the ability to do even a mediocre job with easy unstructured-data tasks at scale is incredibly valuable. Businesses like my employer pay hundreds of professionals to run business process outsourcing sites where thousands of contractors repeatedly answer questions like \"does this support contact contain a complaint about X issue?\" And there are months-long lead teams to develop training about new types of questions, or to hire and allocate headcount for new workloads. We frequently conclude it's not worth it.\n \nreply",
      ">also is a decent description of individual humansA friend of mine was moving from software development into managing devs.  He told me: \"They often don't do things the way or to the quality I'd like, but 10 of them  just get so much more done than I could on my own.\"  This was him coming to terms with letting go of some control, and switching to \"guiding the results\" rather than direct control.The LLMs are a lot like this.\n \nreply",
      "LLMs have been improving exponentially for a few years. let's at least wait until exponential improvements slow down to make a judgement about their potential\n \nreply",
      "They have been improving a lot, but that improvement is already plateauing and all the fundamental problems have not disappeared. AI needs another architectural breakthrough to keep up the pace of advancement.\n \nreply",
      ">but that improvement is already plateauingBased on what ? The gap between the release of GPT-3 and 4 is still much bigger than the time that has elapsed since 4 was already released so really, Based on what ?\n \nreply",
      "there are no much reliable benchmarks which would measure what is gap really. I think currently corps compete in who will leak benchmarks to training data the most, hence o1 is world programming medalist, yet makes stupid mistakes.\n \nreply",
      "Yes. Anything on the horizon?\n \nreply"
    ],
    "link": "https://www.ontestautomation.com/i-am-tired-of-ai/",
    "first_paragraph": "Helping individuals, teams and organizations improve their test automation effortsUnless you have been living under a rock for the last few years, you probably have seen the same massive surge I\u2019ve seen in the application of artificial intelligence (AI) to pretty much every problem out there, in software testing, in software development, and in life in general.Now, I am all for finding and developing new solutions to existing problems, but boy, am I tired of AI, of how it is used and of how it is marketed.Every tech fart smelling of \u2018AI\u2019 these days is almost instantly labeled as a \u2018game changer\u2019, only to be replaced by the next \u2018pivotal\u2019 and \u2018revolutionary\u2019 \u2018solution\u2019 the next week.Yes, I realize that thinking like this and writing this make me a Neo-Luddite in your eyes. That\u2019s fine. Everybody is entitled to their opinion, and this is mine. Feel free to stop reading if you\u2019re not interested.Please note that I don\u2019t necessarily have anything against AI itself. I\u2019m pretty sure that ther"
  },
  {
    "title": "Refactoring Python with Tree-sitter and Jedi (jackevans.bearblog.dev)",
    "points": 71,
    "submitter": "todsacerdoti",
    "submit_time": "2024-09-24T15:02:45.000000Z",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=41637286",
    "comments": [
      "These sorts of cases are why I wrote srgn [0]. It's based on tree-sitter too. Calling it as     cat file.py | srgn --py def --py identifiers 'database' 'db'\n\nwill replace all mentions of `database` inside identifiers inside (only!) function definitions (`def`) with `db`.An input like    import database\n    import pytest\n\n\n    @pytest.fixture()\n    def test_a(database):\n        return database\n\n\n    def test_b(database):\n        return database\n\n\n    database = \"database\"\n\n\n    class database:\n        pass\n\n\nis turned into    import database\n    import pytest\n\n\n    @pytest.fixture()\n    def test_a(db):\n        return db\n\n\n    def test_b(db):\n        return db\n\n\n    database = \"database\"\n\n\n    class database:\n        pass\n\n\nwhich seems roughly like what the author is after. Mentions of \"database\" outside function definitions are not modified. That sort of logic I always found hard to replicate in basic GNU-like tools. If run without stdin, the above command runs recursively, in-place (careful with that one!).Note: I just wrote this, and version 0.13.2 is required for the above to work.[0]: https://github.com/alexpovel/srgn\n \nreply",
      "This is super cool! I wish I'd known about this.\n \nreply",
      "Interesting use of treesitter. But I\u2019m a little surprised that treesitters built in query language wasn\u2019t used.There\u2019s no need to manually iterate through the tree, and use if statements to select nodes. Instead you can just write a couple of simple queries (and even use treesitters web UI to test the queries), and have the treesitter just provide all the nodes for you.https://tree-sitter.github.io/tree-sitter/using-parsers#patt...\n \nreply",
      "Having no experience with treesitter I find the query language rather hard to parse. From a practical point of view and experimenting with the library I\u2019m not surprised to go with this nested For loop approach.\n \nreply",
      "Tree-sitter is really powerful, but it's worth people learning a few methods they prefer to use because there are going to be situations where one method works better than another.  Things I have found useful in the past include- perl -pi -e 's/foo/bar/g' files\"-pi\" means \"in place edit\" so it will change the files in place.  If you have a purely mechanical change like he's doing here it's a very reasonable choice.  If you're not as much of a cowboy as I am, you can specify a suffix and it will back the files up, so something likeperl -p -i.bak -e 's/db/database/g' pyFor example then all your original '.py' files will be copied to '.py.bak' and the new renamed versions will be '.py'For vim users (I know emacs has the same thing but I don't remember the exact invocation because it has been >20years since I used emacs as my main editor) it's worth knowing the \"global\" command.  So you can execute a particular command only on lines that match some regex.  So say you want to delete all the lines which mention cheese:%g/cheese/dSay you want to replace \"db\" with \"database\" but only on lines which start with \"def\":%g/^def/s/db/database/OK cool.  Now if you go 'vim *py' you can do \":argdo g/^def/s/db/database/ | update\" and it will perform that global command across all the files in the arg list and save the ones which have changed.\n \nreply",
      "Author here: I'm super familiar with this kind of find and replace syntax inside vim or with sed. Usually it works great!But in this specific situation it was tricky to handle situations with things spanning over multiple lines + preventing accidental renames.\n \nreply",
      "I realise that and like the article. I was trying to convey in my response that devs should have these things in their toolkit not that you \"did the wrong thing\"[1] somehow by using treesitter for this.[1] like that's even possible in this situation\n \nreply",
      "I'd reach for argdo as well - but I don't think this covers his use case of:> every instance of a pytest fixtureAlthough it's probably good enough for 99% of the use cases, and any extra accidental renames could be reverted when you look at the diff.Maybe it could be covered with a multi line regex using `\\_.`\n \nreply",
      "Interesting refactor!This is trivial with codegen.com. Syntax below:  # Iterate through all files in the codebase\n  for file in codebase.files:\n      # Check for functions with the pytest.fixture decorator\n      for function in file.functions:\n          if any(d.name == \"fixture\" for d in function.decorators):\n              # Rename the 'db' parameter to 'database'\n              db_param = function.get_parameter(\"db\")\n              if db_param:\n                  db_param.set_name(\"database\")\n                  # Log the modification\n                  print(f\"Modified {function.name}\")\n\nLive example: https://www.codegen.sh/codemod/4697/public/diff\n \nreply",
      "Consider indenting your code block, it's unreadable as it is now.\n \nreply"
    ],
    "link": "https://jackevans.bearblog.dev/refactoring-python-with-tree-sitter-jedi/",
    "first_paragraph": ""
  },
  {
    "title": "Charge Robotics (YC S21) is hiring MechEs to build robots that build solar farms (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-09-27T21:23:45.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/charge-robotics/jobs/ml4f9l4-senior-mechanical-engineer",
    "first_paragraph": ""
  },
  {
    "title": "Collaborative text editing with Eg-Walker: Better, faster, smaller (arxiv.org)",
    "points": 150,
    "submitter": "czx111331",
    "submit_time": "2024-09-27T12:53:15.000000Z",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41669840",
    "comments": [
      "Seph (author) also has a reference implementation in Typescript: https://github.com/josephg/eg-walker-referenceI've stated before that I think the main thing holding back collaborative text / sequence CRDTs is integration with a production database.Eg-walker looks interesting because it might lend itself to be integrated into a database because the operations are immutable and only appended. However, to demonstrate the effectiveness of these algorithms library authors (see Yjs, DiamondTypes, etc) build stand-alone data structures (usually specialized search trees) that most databases already provide.Personally, I've been trying to adapt a Piece Table[1] to be collaborative and stored in Triplit[2] which runs on both client and server and already implements logical clocks but I might see how well I can adapt this algorithm instead!1. https://en.wikipedia.org/wiki/Piece_table\n2. https://github.com/aspen-cloud/triplit\n \nreply",
      "This seems to be a holy grail, to be honest! Super-simple database representations with barely any processing required on the \"write path,\" instant startup, minimal memory requirements on both server and client without a need for CRDT data structures to be in memory, none of the O(n^2) complexity of OT. In fact, if I'm interpreting it correctly, it should be straightforward to get this working in a serverless environment without any notion of session fixation, nor active documents needing to be kept in memory.I can see this completely reshaping the landscape of what's possible with collaborative documents!\n \nreply",
      "Author here. Thanks! Yeah this is my hope too.Egwalker has one other advantage here: the data format will be stable and consistent. With CRDTs, every different crdt algorithm (Yjs, automerge/rga, fugue, etc) actually stores different fields on disk. So if someone figure out a new way to make text editing work better, we need to rip up our file formats and network protocols.Egwalker just stores the editing events in their original form. (Eg insert \u201ca\u201d at position 100). It uses a crdt implementation in memory to merge concurrent changes (and everyone needs to use the same crdt algorithm for convergence). But the network protocol and file format is stable no matter what algorithm you use.\n \nreply",
      "Awesome, I'm been following Seph's work for many years! Always thoughtful and well-executed. Probably the most prolific and insightful engineer in the \"collaborative text editing\" universe.I use ShareDB every day, which originated from Seph's excellent work on OT algorithms. Good stuff!\n \nreply",
      "Good to hear it\u2019s still in use! That\u2019s very kind.\n \nreply",
      "There was a recent thread about the 2001 post that afaik eventually lead to this paper (diamond types is the rust implementation):\nhttps://news.ycombinator.com/item?id=41372833\n \nreply",
      "Joseph explains the algorithm on YouTube too: https://www.youtube.com/watch?v=rjbEG7COj7oIt's great work, combining the best of OT and CRDTs.\n \nreply",
      "I find the formulation in the abstract slightly confusing. As far as I understand EG-Walker is a CRDT, an operation-based one.\n \nreply",
      "Author here. It\u2019s kinda both a crdt and an operational transform system.It\u2019s a crdt in that all peers share & replicate the set of all editing events. (A grow-only set crdt if we\u2019re being precise). Peers can use those editing events to generate the document state at any point in time, merge changes and so on.But the editing events themselves are stored and expressed in their \u201coriginal\u201d form (unlike existing CRDTs, which need a prepare function). That means lower memory usage during use.The replying / merging process itself is kind of a batch operational transform algorithm. It works by building a normal crdt state object in memory in order to transform the events so they can be replayed. In that sense, it\u2019s an OT system. (But one which transforms by using a crdt, like Yjs, internally within each peer).I don\u2019t know if that clarifies things. Feel free to ask more questions!\n \nreply",
      "Let me see if I understand this correctly:CRDTs take an editor event such as \"insert at position X\" and turns it into something a concrete operation like \"insert to the right of node Y created by client C\" which is then sent. This makes it super easy to apply concurrent operations since they have a direct reference to where they're located. However, it also means that you know have to keep track of these nodes. All of the nodes that has ever existed is present at all times, and deletion is handled as a state flag which marks it as hidden.OTs take an editor event such as \"insert at position X\" and keeps it like that. Whenever a concurrent event is received it then tries to \"rebase\" it (i.e. patch that event) so that it makes sense on top of the current events. However, this (1) can be quite finicky to get right and (2) it is based on there being One True Order of Events (i.e. a server).This approach takes an editor event such as \"insert at position X\" and keeps it like that. When applied, it can be inserted into an \"ever-growing list of atoms with state flag\". However, in this algorithm the data structure is actually capable of representing two different versions at the same time: A current version and a final version. This is handled by there being two state flags instead of one: Every node has a \"current state = exists/deleted\" and \"final state = exists/deleted\".This gives us the power of doing a \"soft undo\" (which is called \"retreat\" in the paper): We can take our own latest event which we've applied, revert the effect on the current version, while still keeping the final version the same. We're handling this very similar to CRDTs: We keep all the nodes at all time, we're just using state flags to keep track of whether it exists or not.This is useful when we observe a concurrent event. This event have references to positions which are valid in the context of its parent. If we \"retreat\" of all of our events until we reach the parent, we then have a data structure which represents the text at that point. We can now apply the \"insert at position Y\"-events which we received by interpreting \"Y\" in terms of the current version. After we've applied all of those events we can then look at the final version and this now actually contains the combined result of both changes!And here comes the nice part: Since the events themselves are always on the form \"insert at position X\" it means that we can choose another representation of applying them. For instance, if we know that there are no concurrent events that are happening, we might as well apply them directly on a string without bothering with the whole \"current/final dual data structure\".\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2409.14252",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "Notes on AWS Nitro Enclaves: Attack Surface (trailofbits.com)",
    "points": 13,
    "submitter": "tatersolid",
    "submit_time": "2024-09-24T13:03:05.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.trailofbits.com/2024/09/24/notes-on-aws-nitro-enclaves-attack-surface/",
    "first_paragraph": "By Pawe\u0142 P\u0142atekIn the race to secure cloud applications, AWS Nitro Enclaves have emerged as a powerful tool for isolating sensitive workloads. But with great power comes great responsibility\u2014and potential security pitfalls. As pioneers in confidential computing security, we at Trail of Bits have scrutinized the attack surface of AWS Nitro Enclaves, uncovering potential bugs that could compromise even these hardened environments.This post distills our hard-earned insights into actionable guidance for developers deploying Nitro Enclaves. After reading, you\u2019ll be equipped to:We\u2019ll cover a number of topics, including:Whether you\u2019re new to Nitro Enclaves or looking to harden existing deployments, this guide will help you navigate the unique security landscape of confidential computing on AWS.First, a brief threat model. Enclaves can be attacked from the parent Amazon EC2 instance, which is the only component that has direct access to an enclave. In the context of an attack on an enclave, we"
  },
  {
    "title": "Ceefax and the Birth of Interactive TV (bbc.com)",
    "points": 47,
    "submitter": "speckx",
    "submit_time": "2024-09-27T17:28:22.000000Z",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=41673317",
    "comments": [
      "The Ceefax team worked next to us at BBC News Online.  Great guys!They did almost all their programming on the live system.  When they gave us simpletons from the web side of things a demo, the comment was: \"well, anybody checking the football scores in Wales right now might be in for a bit of a surprise\".The software system they had to work with to program it all was ... \"special\".  In one of those misguided attempts to make a scripting system \"user friendly\", the vendor had omitted any data structures or abstraction facilities worth mentioning.  So the team built all the data structures out of Ceefax pages that were not being shown.<Shudder>When it came time to connect my feeds processing system to Ceefax, I created a little XML-based markup language I called CML (Ceefax Markup Language) so that we could use WebObjects builder and the general template mechanism to build Ceefax pages.  IIRC we also built a little converter of CML to HTML so we could preview those pages easilyFun times.\n \nreply",
      "I once interviewed one of the guys who built the embedded software that decoded Teletext on the TV sets.It was written in LISP.The guy was absolutely facilitating. I wish I could have chatted to him in a less formal context.\n \nreply",
      "Decoding VBI frames on LISP, this guy was something else.\n \nreply",
      "When was this? I was up in TVC (and later in that newer building up the road from it) in 1996 prototyping the BBC News Online publishing system with Fujitsu ICL. Didn't meet anyone from the  Ceefax team though.\n \nreply",
      "Cool.  I was there starting 2003, in White City.  With the generally dysfunctional air conditioning.  Not so cool  :-(Which motivated me to work outside on the benches of the rather lovely walkway leading up to the building.  Which in turn motivated me to write a pretty self-contained system.  No Oracle databases for you!  Was very beneficial for all :-)The Ceefax team was in the next room, between us and the White City Bar.\n \nreply",
      "Of course no Oracle databases. That would only have worked for the ITV teletext service.\n \nreply",
      "Some time in the mid-1980s, at the proud age of someteen and three-quarters, I wrote a booth-style Ceefax emulator for my BBC Model B and demonstrated it at the local college\u2019s computer club. The president of that club was a professor of electrical/electronic engineering named Harry White, who unbeknownst to me was also the director of exhibitions for Techniquest, a recently founded hands-on science education center in the nearby city of Cardiff. Harry had next to no budget and a pressing need to have exhibit-control software written, and offered me a part-time job whilst school was out. That was how I discovered people would give me money just for doing my hobby. Four decades later this is still the case. Thank you Ceefax, and thank you Harry.\n \nreply",
      "> and waited a few seconds for information to appear on the screenOh dear me.  Later TVs had \"fasttext\" which cached the information so they could go to a page instantly.  Some pages were sent repeatedly (like page 100, the index).  But others you'd really have to wait quite a time for while the transmitter cycled through all the pages.  I seem to remember Victor Lewis Smith did a joke about this.\n \nreply",
      "> To access these pages, viewers typed the three-digit page number required into their TV remote control and waited a few seconds for information to appear on the screen.You can tell from \"a few seconds\" that the author of this article never actually used Ceefax.\n \nreply",
      "Not the author but I grew up using this tech and I recall it being seconds rather than minutes.\n \nreply"
    ],
    "link": "https://www.bbc.com/articles/cvg360rr91zo",
    "first_paragraph": "Ceefax was on air for almost 40 yearsCeefax was the world's first teletext service, going live on 23 September 1974. In a pre-internet world, the revolutionary system allowed people to check the latest BBC news and sport updates at the touch of a few buttons. By the 1990s, as many as 22 million people were using the platform weekly, letting people \u201csee facts\u201d through their television screens.The popular service only came about because of an accidental discovery in the BBC engineering department in the late 1960s.BBC engineers Geoff Larkby and Barry Pyatt were investigating ways to transmit subtitles for deaf and hearing impaired viewers. In the course of their work, they came across the \u201cspare\u201d lines at the top of the 625-line television signal. They believed that this space could be used to transmit words or numbers.\"This is Ceefax\": The world\u2019s first teletext service went live in 1974BBC Director of Engineering James Redmond was enthusiastic about the possible opportunities this pres"
  },
  {
    "title": "My MEGA65 is finally here (lyonsden.net)",
    "points": 115,
    "submitter": "harel",
    "submit_time": "2024-09-27T14:13:54.000000Z",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=41670743",
    "comments": [
      "I love this project.I've been feeling lately that as computers have become more advanced and software has become more inscrutable, our relationship with our computers has changed, for the worse. This essay hit home for me: https://explaining.software/archive/transparent-like-frosted...These old-school computers viewed their users as creators, as developers. Modern computers (read: smartphones) _are_ the users, and the \"used\" are just ad-watching revenue cows. I passionately hate this arrangement.When I have children, I want them to know what computing should feel like---empowering, creative and stimulating, not controlled, consumptive, compulsive and mindless. I want to give them a computer that builds up their spirit, rather than grinding it down.I think this computer should have several qualities:0. The computer should be about _creation_ and not consumption.1. The computer should be _local_, not global. Intranet should be prioritized over Internet.1.5 A corollary, the computer should be _personal_. It should encourage and reward in-person interaction, physical sharing of information and programs, and short-range connection between computers.2. The computer should be _limited_. Because the medium is the message, we have to restrict the capabilities of our media to better promote the messages we value.2.5. A corollary, the computer should be _text-oriented_. Graphics shouldn't be impossible, but text should be primary. The computer should cultivate a typographic mind, not a graphic mind (in Marshall McLuhan's terminology).3. The computer should be _focused_. It should never distract you from what you want to work on.4. The computer should be _reactive_, not proactive. It should never give you a notification. You should be in charge of retrieving all information yourself, like a library, not a call center.5. The computer should be _physical_. It should be oriented around physical media.6. The computer should be _modifiable_. It should encourage and reward inspection into its internals, and be easy to change.7. The computer should be _simple_, understandable by a single person in its entirety with time and study.The Mega65 is amazing and checks these boxes, but unfortunately it's a tad expensive for me. What other machines are out there like this?\n \nreply",
      "The Tulip Creative Computer[1][2] hits most of your points (I'm just a customer).  It is definitely not a retro computer. It uses modern technology (ESP32S3 microcontroller with megabytes of flash memory and RAM, wifi, color touch screen etc.) and runs a modern programming language (MicroPython) that also serves as the operating system.This particular product might not be exactly what you want, but it shows that you can use these technologies to build a computer that is much simpler and more malleable than a modern PC in both hardware and software, but is still very capable, and intriguing to use.1. https://github.com/shorepine/tulipcc\n2. https://news.ycombinator.com/item?id=41122986\n \nreply",
      "Mega65 is a nostalgia project aimed at targeting a specific kind of older computer system.If practical and simple were the goals, it wouldn't be using an 8-bit chip nor would it be focused on things like BASIC as these kinds of things make things harder rather than easier.Mega65 is about working within constraints, but (to me), the bend of the complexity curve where things are simple enough to understand, but powerful enough to do necessary tasks requires much larger software and hardware resources than what a system like Mega65 offers.At a bare minimum, I believe you'd want a much more powerful single-core machine with the ability to do floating point and vector calculations while having access to at least a couple hundred megabytes of RAM and a few gigabytes of storage. Something more along the lines of a Pi Zero, but based on open hardware and open chip designs seems to be around the point where it is powerful enough to do all the common, non-connected tasks a user might need to do while still being simple enough that you could understand most of the moving parts if you wanted to take the time.\n \nreply",
      "I agree completely. I've looked at designing a system around the Pi Zero, but it's so much work for someone with the time and skills that I (don't) have. And the Pi Zero doesn't seem to have the kind of I/O capability that I'm looking for.\n \nreply",
      "I feel like the RP2040 or RP2350 approach the simplicity of these older machines.https://www.raspberrypi.com/products/rp2350/The documentation is pretty good.  Reading it reminds me of going through the documentation provided with my Tandy Color Computer as a kid.\n \nreply",
      "I grew up before the Internet and we still craved connectivity with our computers.  I remember dialing into BBSes and playing turn-based text games and it was amazing.  It was also the best way to get software; my computer would be pretty boring if the only software I had was what I created myself or purchased in a box.I also could have done so much more with all my computers, from my Commodore 64 to my 286, if had I had the vast information resources that are available now.\n \nreply",
      "I think the difference is that in the days of the nascent internet, connecting with people meant much more than it does now. You dial into a BBS or log into a MUD and you have a small-ish community of real people that you can develop relationships with. Modern internet connectivity almost means the opposite: all the major services are oriented toward moneymaking, nothing is genuine, there is no sincerity, most behavior is motivated by accumulation of worthless social capital.So, the society that you craved connection with no longer exists now that you are able to connect. This is another thing that, seemingly, has to be rebuilt from the ground up locally.\n \nreply",
      "I got started with a 1200 baud modem, back in the late 80's. I miss the local community found on BBSes and the early, text-oriented Internet providers. There seems to be no replacement for that at all. Any \"local\" oriented sub-reddit, Discord, etc. is full of bots and spammers.\n \nreply",
      "I've wanted an e-paper laptop ever since I saw a Kindle ad in 2008. I'm also interested in ultra low power computing (solar charging, daylight readable, months of battery life, offline-first, mostly text...). So your list has a lot of overlap with mine!Such a thing doesn't seem to have been invented yet. The remarkable might come close (or that weird typewriter like thing?) but I haven't been able to justify any of those purchases yet...I'm not 100% sure about e-paper (the lag may actually be a feature reducing addictiveness), I'm also amenable to those transflective Sharp LCDs! (Though I think they're a bit too small for a daily driver.)\n \nreply",
      "Consider the RC2014 https://rc2014.co.uk I think it hits a bunch of these points. Also don't overlook the SpecNext https://www.specnext.com -- both have very active communities.\n \nreply"
    ],
    "link": "https://lyonsden.net/my-mega65-is-finally-here/",
    "first_paragraph": "Finally, after waiting patiently for over two years for my pre-order, my MEGA65 arrived a today! I bought and paid for this way back in May of 2022 but production was delayed first by Covid and then by the resulting chip shortage that followed. The tedium of waiting has all been washed away now that I actually have it in my hands though, so in this post I will share my initial experiences with it.\u00a0Just in case you are not aware of this machine it is based on the Commodore 65, a prototype machine made by Commodore in 1990. Had things panned out differently it would have been the direct successor to the Commodore 64, offering backwards compatibility alongside a feature set not dissimilar to the Amiga. Sadly however, the C65 never went into production and not many were ever made. Consequently, examples of this mythical machine sell for silly money on eBay on the extremely rare occasions that they do pop up.That\u2019s where the MEGA 65 comes in. It\u2019s been developed by the Museum of Electronic "
  },
  {
    "title": "Raft: Understandable Distributed Consensus (2014) (thesecretlivesofdata.com)",
    "points": 153,
    "submitter": "Hrun0",
    "submit_time": "2024-09-27T12:54:55.000000Z",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=41669850",
    "comments": [
      "I am in the minority who thinks Raft is overrated.I tried teaching Raft one year instead of Paxos but ended up switching back. While it was much easier to understand how to implement Raft, I think my students gained deeper insight when focusing on single-decision Paxos. There is a lightbulb moment when they first understand that consensus is a property of the system that happens first (and they can point at the moment it happens) and then the nodes discover that it has been achieved later. Exploring various failure modes and coming to understand how Paxos is robust against them seems to work better in this setting as well.I think this paper by Heidi Howard and Richard Mortier is a great way to move on to Multipaxos:https://arxiv.org/abs/2004.05074They present Multipaxos in a similar style to how Raft is laid out and show that Multipaxos as it is commonly implemented and Raft are almost the same protocol.Raft was a great contribution to the engineering community to make implementing consensus more approachable, but in the end I don't think the protocol itself is actually more understandable. It was presented better for implementers, but the implementation focus obscures some of the deep insights that plain Paxos exposes.\n \nreply",
      "Know that I join you in Raft being overrated. I\u2019m working on a multipaxos implementation right now. There are some really neat capabilities/properties that paxos has that Raft can never achieve (see wpaxos, for example, that lets keys migrate to nodes near the client).\n \nreply",
      "I've read both the Paxos and Raft papers a few times, and hacked on some implementations, but never quite got one over the line to working...Raft strikes me as a particular set of decisions made within a Paxos framework, such as having 1 entity for Proposers, Acceptor and Followers. It's frustrating that there isn't a clearly written defacto paper on Paxos - the story style confused the monkeys out of me.\n \nreply",
      "> but never quite got one over the line to working...I've never implemented something like this.  But my first thought is \"how do you implement the testing system?\"I feel like once you had a robust testing system that can verify things work correctly in all the different network partition and other scenarios, and allowing rapid iteration of setting up those scenarios, the implementation would be comparatively easy.\n \nreply",
      "Yeah, you kind of can\u2019t test any of it until you test all of it\u2026\n \nreply",
      "Is there any paper/handouts/video that explains Paxos in depth, especially its implementations and intuitions? Paxos Made Simple gave intuitive explanations, but I feel it still misses a lot of intricate details if I were to build Praxos for production use.\n \nreply",
      "This is an interesting insight into the educational side, but now I am curious about the implementation side. Raft is easier to implement but that's just one factor. Looking at real world usages there seems to be a draw. I could easily count as many Paxos implementations as Raft. Is this just historical or are there good reasons for a new project to still implement Oaxos?\n \nreply",
      "Paxos and Multi-Paxos have been around much longer than Raft. The paper that introduced Raft was published in 2014.\n \nreply",
      "Agree, Raft is less modular and therefore harder to understand than MultiPaxos:https://maheshba.bitbucket.io/blog/2021/12/14/Modularity.htm...\n \nreply",
      "You are telling me your students can safely implement single decree paxos.... I worked on a few paxos production implementations before the RAFT paper, single and multi decree. The idea that paxos, as it is to be implemented, is easy for students to understand... Well let me re-read the paper, but i assure you, raft was a big deal\n \nreply"
    ],
    "link": "https://thesecretlivesofdata.com/raft/",
    "first_paragraph": ""
  },
  {
    "title": "US Trademark Office Cancels Marvel, DC's 'Super Hero' Marks (reuters.com)",
    "points": 33,
    "submitter": "h2odragon",
    "submit_time": "2024-09-27T22:51:19.000000Z",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41676297",
    "comments": [
      "Here's the full article, but turns out it isn't really any longer that you can see from outside the paywall: https://archive.is/jQtuc\n \nreply",
      "Good. Now I hope someone figures out how to abolish software patents.\n \nreply",
      "Never going to happen; too much investment. Not without something resetting the whole patent system all at once.And hey, I\u2019m not actually opposed to all patents. H.265 - if you put tens of millions into compression research, or hundreds of millions into database scaling research at PlanetScale, a temporary exclusivity period makes sense.95% of software patents don\u2019t reach that level.I think some of the bad rap also comes from technology advancement. Amazon\u2019s 1-click Checkout patent is notorious; but nobody talks about how much of an accomplishment that technology was in 1997. It actually was very impressive when that patent was granted, particularly in getting the credit card networks to agree to the security design.\n \nreply",
      "I direct your attention hither: <https://wiki.endsoftwarepatents.org/wiki/Why_abolish_softwar...>\n \nreply",
      "A wiki specifically on the topic written by non-lawyers is interesting; but I don\u2019t see why it should be considered an unbiased list of ideas. Sometimes the status quo is imperfect but okay.\n \nreply",
      "As a compromise, I suggest the source code must be made public for patented ideas.\n \nreply",
      "Patents already require that all information be available, for someone similarly invested in the craft, to be able to completely reproduce the invention.That doesn\u2019t require an implementation - but that mirrors our regular patent office, which does not require physical functioning prototypes to demonstrate.\n \nreply"
    ],
    "link": "https://www.reuters.com/legal/litigation/us-trademark-office-cancels-marvel-dcs-super-hero-marks-2024-09-26/",
    "first_paragraph": ""
  }
]