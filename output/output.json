[
  {
    "title": "Passport Photos (maxsiedentopf.com)",
    "points": 409,
    "submitter": "gaws",
    "submit_time": "2024-11-06T21:23:50 1730928230",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=42069646",
    "comments": [
      "Hugged to death, here's an archive copy: https://archive.is/uPMjd",
      "Oh! Something I took a part in on HN. That's a first. Almost everything there was practical. Highly recommend checking out all of Max's work, beaming with creativity.\n \nreply",
      "So its not mentioned on the post but is this your actual passport photo that was accepted and used and you have it on your physical passport right now?\n \nreply",
      "how did you come to take part?\n \nreply",
      "It's a lot of \"fun\" trying to get acceptable photos. Last week I went to my local American Automobile Association (AAA) office to get an International Driver's Permit (IDP). It's just a translation of your license, which is valid for 1 year. I had to take 2 passport-sized photos with me, which I did.But I was told they wouldn't be accepted because I had long hair and a beard in them, but short hair and no beard now. That's absurd, because it's the same photo used in both of my passports, and there's no requirement that you don't alter your appearance from your passport photo. Somehow border guards can crack the code.Amusingly, my California driver's license shows short hair and no beard, but the AAA person wasn't even looking at my CA license at the time. What happens if I grow long hair and a beard before I travel? Was he just trying to upsell me on a $9.99 photo?We had a hell of a time getting the UK passport authorities to accept the photos we sent in for her passport; they recommend getting your photos taken at an \"official\" UK location where the digital photos are identified by a code you send in. Well, we happened to be traveling through Australia during this timeframe, so we were able to stop at an Australian Post Office, which supposedly had the same \"digital\" system, but instead of a code to send to the UK authorities, they handed us printed photos and a web link. Thankfully I was able to use the web link to download the photo and upload it to the UK site, where it was approved almost immediately, and the new passport arrived back at our home before we returned from our trip. But there's no user-obvious criteria that was being used to reject the SEVERAL rounds of photos we had sent to the UK earlier.\n \nreply",
      "It's a very common criteria that you provide recent photos for any new ID \u2014 e.g. \"taken in the last month\", and tbh that's reasonable (a more recent photo is more likely to serve the purpose of putting a photo on tut thing at all).\"Grew long hair & beard since photo was taken\" would violate that, though I don't know what the AAA's reqs were.\n \nreply",
      "The IDP feels like such a scam. I have to get it every year and it is so annoying.\n \nreply",
      "> But I was told they wouldn't be accepted because I had long hair and a beard in them, but short hair and no beard now.Tell them your religion doesn't permit beardless photos, so you grew one for the photo.When they ask what religion, pick one with beards.It's AAA, not the police -- the person behind the desk will shrug, now with a reason not to care, and create your IDP.\n \nreply",
      "I made my passport photos on a phone camera against a white wall, stitched them together with other family members and printed them on a 4x6 photo at CVS.I think it cost something like $0.68 for 2 photos, each of which had all four of our photos plus 2 extra spots.\n \nreply",
      "In my recent experience renewing my UK passport, I found I was able to submit the image regardless of the complaining it gave, I just had to write a note as to why I thought the image did in fact meet their criteria.In my case, whatever detection software they used seemed to think my eyes were closed, which they were not.I just used a normal picture taken on a phone, against a plain white wall, accepted with no issues.\n \nreply"
    ],
    "link": "https://maxsiedentopf.com/passport-photos/",
    "first_paragraph": "\u201cPassport Photos\u201d looks at one of the most mundane and unexciting types of photography. Heavily restricted and regulated, the official passport photo requirements include that the subject needs to face the camera straight on, needs a clear background without shadow, no glare on glasses and most importantly; no smile.It seems almost impossible for any kind of self-expression.The series tries to challenge these official rules by testing all the things you could be doing while you are taking your official document photo."
  },
  {
    "title": "Trudeau government bans TikTok from operating in Canada (cbc.ca)",
    "points": 259,
    "submitter": "empressplay",
    "submit_time": "2024-11-06T23:04:39 1730934279",
    "num_comments": 151,
    "comments_url": "https://news.ycombinator.com/item?id=42070946",
    "comments": [
      "Instead of the laser focus on TikTok as a threat, it would be better for the US and Canada to have real data protection laws that would apply equally to TikTok, Meta, Google, Apple, and X. What the EU has done is far from perfect but it bans the worst practices. The Chinese can buy all of the information they want on Americans and Canadians from ad brokers, who will happily sell them everything they need to track individuals' locations.Perhaps the way to get anti-regulation politicians on board with this is for someone to do what was done to Robert Bork and legally disclose lots of personal info on members of Congress/Parliament, obtained from data brokers and de-anonymized.\n \nreply",
      "It is not about the data. It\u2019s about a foreign government controlling the algorithm that decides what millions of people see, and their ability to shape public opinion through that.Like imagine if China owned CNN and the New York Times and decided what stories they could publish.\n \nreply",
      "> Like imagine if China owned CNN and the New York Times and decided what stories they could publish.It is happening on our local platforms here.  Meta, based in the US, is systematically censoring Palestinian content that would otherwise be available here in Canada.Details:* https://www.hrw.org/report/2023/12/21/metas-broken-promises/...* https://theintercept.com/2024/10/21/instagram-israel-palesti...For a very recent example, one of the few remaining prominent Palestinian journalists, with a following of over 1M on Meta, was banned today:https://www.aljazeera.com/program/newsfeed/2024/11/7/al-jaze...\n \nreply",
      "Didn't you read the memo from the government?Israelis can do whatever they please and kill hundreds of people everyday, they literally destroyed 8 buildings full of people with many children to kill a single Hezbollah leader.But how can I be surprised when more than a decade ago the same things where happening on US hands towards Iraqis or whatever. Drone kills 200 people in a market? Yeah but an Al Qaeda operative was there buying spices, so worth it.We became numb to those tragedies. In particular when violence and death is happening by drones and bombs rather than someone pointing their rifle at you, it seems like it makes it less violent when I find it absurdly evil, cold and detached.\n \nreply",
      "What\u2019s crazy is few people even talk about who currently owns major US news networks and what their motives might be. People don\u2019t like Musk owning Twitter/X, that\u2019s a start - but start reading about who owns the rest (especially traditional media).\n \nreply",
      "I would argue that has been a persistent topic of conversation for my entire life!\n \nreply",
      "As opposed to the domestic government controlling the algorithm that decides what millions of people see, and their ability to shape public opinion through that.\n \nreply",
      "If you live in a democracy you have a vote and a voice to bring to the table. It\u2019s wild to me that on this topic people seem to see their own governments as largely equivalent to an outwardly adversarial if not explicitly hostile foreign power.I think it has been so long since the Pax-Americana West has dealt with an overtly hostile major power that we\u2019ve collectively lost the concept that there can be real enemies with goals that run explicitly counter to our own.\n \nreply",
      "This is patently untrue. The American Federal government is not swayed by votes directly in any reliable way.For example, a vote for anyone is always a vote Israel and Israel's apartheid and wars. Sure, you can disagree with what they're doing there, but isn't it funny that we ALWAYS support them no matter what?So, no, we can't just decide what we see, consume, or do.\n \nreply",
      "It is a frustrating and often ineffectual system, but I simply cannot disagree more that I, as an American citizen, have equivalent powerlessness over the American government as I do over the Chinese government. There is a clear and storied history of people who cared about issues making real change to the American government and the lives of their fellow citizens. There are plenty of terrible things this country has done as well, but I\u2019m not ready to give up on it yet and assume the Chinese government is equivalent.\n \nreply"
    ],
    "link": "https://www.cbc.ca/news/politics/tiktok-canada-review-1.7375965",
    "first_paragraph": ""
  },
  {
    "title": "Guy gives a negative review to Battlezone after playing 8k hours; He's right (pcgamer.com)",
    "points": 70,
    "submitter": "isaacfrond",
    "submit_time": "2024-11-01T09:27:22 1730453242",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42015269",
    "comments": [
      "To be fair, it kinda makes sense. The person best equipped to criticise a game or work is probably often someone who's experienced it for the longest. That way, they get to know all the things that don't add up, get repetitive on repeat playthroughs, various UI and UX annoyances that get worse the more you experience them, etc.There's a reason the biggest fans of a game or film or TV series tend to give some of the harshest criticism, and why the most active users of a tool or program tend to have the most to say about it.\n \nreply",
      "At 8000 hours, most players have lost any connection to the design intent of \"game\" they're \"playing\" -- they've lost any intentional sense of pacing, any intentional sense of discovery, and have almost by definition disregarded any intentional sense of conclusion or completeness.They're engaging in their own idiosyncratic experience with software that doesn't work exactly the way they now dream, but is apparently closer to what they want than anyrhing else.In the general case, their insights are going to be a curiosity and might sometimes happen to coincide with a more broadly experienced flaw in the design. And of course they may be right on target for whatever few other \"8000 hour\" players.Playing a game or using software a lot can give you some deep insights into it. But there is a crossover point where you spend so much time with it that your relationship with it isn't very related to anyone else's anymore, and your insights likewise become less relatable.\n \nreply",
      "It's an online multiplayer PvP game. There is no pacing, conclusion or completeness like a single-player \"estimated 40 hour playthrough\" game, discovery is a metagame, and a review veering into historiography can add relevant and useful information for prospective players because of it, not in spite of it.\n \nreply",
      "Uh, it can be multi-player. But the single player campaigns were the business, IMO.\n \nreply",
      "This is exactly why the biggest thing in gamedev, and all software dev to an extent, is getting your software in front of users as soon as possible. As a developer it isn't just that you know how it works, but you'll also have played the game or used the front end of the experience for thousands of hours.New eyes will see fresh flaws. The user might not be right about how to fix the flaw, but they are absolutely right about where the flaws are.\n \nreply",
      "My god I love BZ98. For me, the remaster was frustrating. The most annoying thing was that certain things, like the combat AI, had been improved in ways that broke the balance of the single player campaign. I doubt players with the subject\u2019s level of mastery would be bothered, but it significantly reduced my enjoyment.It remains a rare gem, though. There are so few RTSs that place you in the world there isn\u2019t even a name for the genre. The only others I can think of are Brutal Legend and Sacrifice. But BZ98 was the one that I discovered first.\n \nreply",
      "Command and Conquer:Renegade was a (somewhat)contemporary of bz98 and scratched that BZ itch.\n \nreply",
      "I guess Giants: Citizen Kabuto is another.\n \nreply",
      "Yes, loved that game! Would have loved it more if it was actually finished.\n \nreply",
      "Ultrabots (1993) was another.\n \nreply"
    ],
    "link": "https://www.pcgamer.com/games/strategy/i-tracked-down-the-guy-who-gave-a-negative-review-to-battlezone-98-redux-after-playing-for-over-8-000-hours-and-came-away-convinced-he-was-right/",
    "first_paragraph": "Scott Smith is a kind of living Battlezone encyclopaedia. Obviously, I had to speak to him.\nWhen you purchase through links on our site, we may earn an affiliate commission. Here\u2019s how it works.\nNo one is as vicious about a game as its most dedicated player. Take a jaunt over to the forums for WoW, or CoD, or Overwatch sometime and you'll see what I mean: Scores of people who play almost nothing but the game in question but have almost nothing positive to say about it.But not a single irritated MMO player is a patch on my own personal icon of this genre: Herp McDerperson\u2014real name Scott Smith\u2014who I discovered one day when I stumbled on the negative review he left on Steam for Battlezone 98 Redux (BZ98R), Rebellion's 2016 remaster of the original RTS/FPS hybrid from 1998. A negative review which he left, says Steam, after 8,461.1 hours of playtime, then followed up with 600 more.I've been curious about Smith since before I even began writing about games\u2014a product of both the disparity b"
  },
  {
    "title": "Don't return named tuples in new APIs (snarky.ca)",
    "points": 17,
    "submitter": "todsacerdoti",
    "submit_time": "2024-11-02T22:11:28 1730585488",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42029574",
    "comments": [
      "Another problem brought about by their design being backwards-compatible with tuples is that you get wonky equality rules where two namedtuples of different types and with differently-named attributes can compare as equal:    >>> Foo = namedtuple(\"Foo\", [\"bar\"])\n    >>> Baz = namedtuple(\"Baz\", [\"qux\"])\n    >>> Foo(bar=\"hello\") == Baz(qux=\"hello\")\n    True\n\nThis also happens with the \"new-style\" namedtuples (typing.NamedTuple).I like the convenience of namedtuples but I agree with the author: there are enough footguns to prefer other approaches.\n \nreply",
      "Counterpoint: Named tuples are immutable, while dataclasses are mutable by default.You can use frozen=true to \"simulate\" immutability, but that just overwrites the setter with a dummy implementation, something you (or your very clever coworker) can circumvent by using object.__setattr__()So you neither get the performance benefits nor the invariants of actual immutability.\n \nreply",
      "I think the best option for this, which is one listed in the article, is the dataclass. It's like a struct in C or Rust. It's ideal for structured data, which is, I believe, what a named tuple is intended for.\n \nreply",
      "The annoyance of dataclasses, of course, is that they interact very awkwardly with immutability, which much of the Python ecosystem mandates (due to lacking value semantics).But yes, they're still the least-bad choice.\n \nreply",
      "Valid. One of my biggest (Perhaps my #1) fault with python is sloppy mutability and pass-by-value/reference rules.\n \nreply",
      "Author could have used NamedTuple instead of dataclass or TypedDict:    from typing import NamedTuple\n\n    class Point(NamedTuple):\n        x: int\n        y: int\n        z: int\n\n\nI don't see \"don't use namedtuples in APIs\" as a useful rule of thumb, to be honest. Ordered and iterable return-types make sense for a lot of APIs. Use them where it makes sense.\n \nreply"
    ],
    "link": "https://snarky.ca/dont-use-named-tuples-in-new-apis/",
    "first_paragraph": "In my opinion, you should only introduce a named tuple to your code when you're updating a preexisting API that was already returning a tuple or you are wrapping a tuple return value from another API.Let's start with when you should use named tuples. Usually an API that returns a tuple does so when you only have a couple of items in your tuple and the name of the function returning the tuple id enough to explain what each item in the tuple does. But sometimes your API expands and you find that your tuple is no longer self-documenting purely based on the name of the API (e.g., get_mouse_position() very likely has a two-item tuple of X and Y coordinates of the screen while app_state() could be a tuple of anything). When you find yourself in the situation of needing your return type to describe itself and a tuple isn't cutting it anymore, then that's when you reach for a named tuple.So why not start out that way? In a word: simplicity. Now, some of you might be saying to yourself, \"but I "
  },
  {
    "title": "131M American Buildings (marksblogg.com)",
    "points": 82,
    "submitter": "marklit",
    "submit_time": "2024-11-02T09:03:28 1730538208",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42025037",
    "comments": [
      "I am tempted to import this data into my system and build a pivot table of building type (PRIM_OCC) by state.I could then graph the data (pie chart, bar graph, etc) to show how the building type distribution (e.g. residential ratio per hospital) varies between the states.\n \nreply",
      "https://data.hrsa.gov/tools/shortage-area/mua-find\n \nreply",
      "Interesting, but not what I was thinking.https://m.youtube.com/watch?v=2ScBd-71OLQ\n \nreply",
      "Anyone know if this is commercial buildings only or does it include residential too?\n \nreply",
      "Virtually all of the buildings are residential. There are 20x more residential than anything else.\n \nreply",
      "Does it include bike sheds?  I feel I could spend a long time on that part of the database.\n \nreply",
      "One of the criteria for inclusions is an area greater than 450 square feet.You can look at it in a slippy map: https://gis-fema.hub.arcgis.com/pages/usa-structures (a couple clicks required from there).In my area it doesn't particularly identify garages well, so you probably can't spend that much time on bike sheds.\n \nreply",
      ":-)Some may need an assist: https://en.wiktionary.org/wiki/bikeshedding\n \nreply",
      "Wonderfully executed joke. 10pts.\n \nreply",
      "Desktop computers are amazing these days.\n \nreply"
    ],
    "link": "https://tech.marksblogg.com/ornl-fema-buildings.html",
    "first_paragraph": "I have 15 years of consulting & hands-on build experience with clients in the UK, USA, Sweden, Ireland & Germany. Past clients include Bank of America Merrill Lynch, Blackberry, Bloomberg, British Telecom, Ford, Google, ITV, LeoVegas, News UK, Pizza Hut, Royal Mail, T-Mobile, Williams Formula 1, Wise & UBS. I hold both a Canadian and a British passport. My CV, Twitter & LinkedIn.\n      \nHome\n        | Benchmarks\n\n        | Categories\n\n            | Atom Feed\nPosted on Sat 02 November 2024  under GISIn May, Nature published an article detailing Oak Ridge National Laboratory's (ORNL) new, AI-generated US Building Dataset.ORNL developed a convolutional neural network (CNN) that extracted vector-building footprints from Maxar's WorldView-02, WorldView-03, QuickBird, GeoEye-1 satellite imagery as well as the National Agriculture Imagery Program's (NAIP).Google and Microsoft have both already published building datasets that were produced from satellite imagery but ORNL's focused on adding m"
  },
  {
    "title": "Private Cloud Compute Security Guide (security.apple.com)",
    "points": 278,
    "submitter": "djoldman",
    "submit_time": "2024-11-06T13:48:55 1730900935",
    "num_comments": 122,
    "comments_url": "https://news.ycombinator.com/item?id=42062230",
    "comments": [
      "There's something missing from this discussion.What really matters isn't how secure this is on an absolute scale, or how much one can trust Apple.Rather, we should weigh this against what other cloud providers offer.The status quo for every other provider is: \"this data is just lying around on our servers. The only thing preventing a employee from accessing it is that it would be a violation of policy (and might be caught in an internal audit.)\" Most providers also carve out several cases where they can look at your data, for support, debugging, or analytics purposes.So even though the punchline of \"you still need to trust Apple\" is technically true, this is qualitatively different because what would need to occur for Apple to break their promises here is so much more drastic. For other services to leak their data, all it takes is for one employee to do something they shouldn't. For Apple, it would require a deliberate compromise of the entire stack at the hardware level.This is very much harder to pull off, and more difficult to hide, and therefore Apple's security posture is qualitatively better than Google, Meta or Microsoft.If you want to keep your data local and trust no-one, sure, fine, then you don't need to trust anyone else at all. But presuming you (a) are going to use cloud services and (b) you care about privacy, Apple has a compelling value proposition.\n \nreply",
      "Sibling comments point out (and I believe, corrections are welcome) that all that theater is still no protection against Apple themselves, should they want to subvert the system in an organized way. They\u2019re still fully in control. There is, for example, as far as I understand it, still plenty of attack surface for them to run different software than they say they do.What they are doing by this is of course to make any kind of subversion a hell of a lot harder and I welcome that. It serves as a strong signal that they want to protect my data and I welcome that. To me this definitely makes them the most trusted AI vendor at the moment by far.\n \nreply",
      "As soon as you start going down the rabbit hole of state sponsored supply chain alteration, you might as well just stop the conversation.  There's literally NOTHING you can do to stop that specific attack vector.History has shown, at least to date, Apple has been a good steward.  They're as good a vendor to trust as anyone.  Given a huge portion of their brand has been built on \"we don't spy on you\" - the second they do they lose all credibility, so they have a financial incentive to keep protecting your data.\n \nreply",
      "Apple have name/address/credit-card/IMEI/IMSI tuples stored for every single Apple device. iMessage and FaceTime leak numbers, so they know who you talk to. They have real-time location data. They get constant pings when you do anything on your device. Their applications bypass firewalls and VPNs. If you don't opt out, they have full unencrypted device backups, chat logs, photos and files. They made a big fuss about protecting you from Facebook and Google, then built their own targeted ad network. Opting out of all tracking doesn't really do that. And even if you trust them despite all of this, they've repeatedly failed to protect users even from external threats. The endless parade of iMessage zero-click exploits was ridiculous and preventable, CKV only shipped this year and isn't even on by default, and so on.Apple have never been punished by the market for any of these things. The idea that they will \"lose credibility\" if they livestream your AI interactions to the NSA is ridiculous.\n \nreply",
      "> They made a big fuss about protecting you from Facebook and Google, then built their own targeted ad network.What kind of targeting advertising am i getting from apple as a user of their products? Genuinely curious. I\u2019ll wait.The rest of your comment may be factually accurate but it isn\u2019t  relevant for \u201cnormal\u201d users, only those hyper aware of their privacy. Don\u2019t get me wrong, i appreciate knowing this detail but you need to also realize that there are degrees to privacy.\n \nreply",
      "> What kind of targeting advertising am i getting from apple as a user of their products?https://searchads.apple.com/https://support.apple.com/guide/iphone/control-how-apple-del...  In the App Store and Apple News, your search and download history may be used to serve you relevant search ads. In Apple News and Stocks, ads are served based partly on what you read or follow. This includes publishers you\u2019ve enabled notifications for and the type of publishing subscription you have.\n \nreply",
      "> If you don't opt out, they have full unencrypted device backups, chat logs, photos and files.Also full disk encryption is opt-in for macOS. But the answer isn't that Apple wants you to be insecure, they just probably want to make it easier for their users to recover data if they forget a login password or backup password they set years ago.> real-time location dataLocations are end to end encrypted.\n \nreply",
      "> Also full disk encryption is opt-in for macOS. But the answer isn't that Apple wants you to be insecure, they just probably want to make it easier for their users to recover data if they forget a login password or backup password they set years ago.\"If you have a Mac with Apple silicon or an Apple T2 Security Chip, your data is encrypted automatically.\"The non-removable storage is I believe encrypted using a key specific to the Secure Enclave which cleared on factory reset. APFS does allow for other levels of protection though (such as protecting a significant portion of the system with a key derived from initial password/passcode, which is only enabled while the screen is unlocked).\n \nreply",
      "It's disingenuous to compare Apple's advertising to Facebook and Google.Apple does first party advertising for two relatively minuscule apps.Facebook and Google power the majority of the world's online advertising, have multiple data sharing agreements, widely deployed tracking pixels, allow for browser fingerprinting and are deeply integrated into almost all ecommerce platforms and sites.\n \nreply",
      "They have not been punished because they have not abused their access to that data.\n \nreply"
    ],
    "link": "https://security.apple.com/documentation/private-cloud-compute/",
    "first_paragraph": "Please turn on JavaScript in your browser and refresh the page to view its content."
  },
  {
    "title": "Visualizing binary files with ImHex's DSL, the \"pattern language\" (xy2i.blogspot.com)",
    "points": 26,
    "submitter": "xy2_",
    "submit_time": "2024-11-06T22:00:09 1730930409",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42070153",
    "comments": [
      "Great write up!I looked at ImHex a good while back and I think I had some runtime issues or maybe even compilation issues and didn't dig deeper. Even though the definition language piqued my curiosity.These days I tend to just use xxd, bless, ghex, or seldom wxHexEditor, depending on what I need. But ImHex looks really powerful, like it could replace all the GUI ones.\nI'm looking forward to giving it another go tomorrow.Though these days I spend most of my time in wireshark, which is kind of a hex viewer in a way.How does it manage with huge files? Does it try to load the entire thing into memory.\nI remember wxHexEditor being good for that, and even being able to open block devices directly and process memory IIRC. Might be getting mixed up with HxD.The decompression and combining compressed with decompressed sections looks very cool. Is the decompression in memory or written to disk?// TagRecord Tags[while(!std::mem::eof())];This loop based length stuff is very cool too, though for large files I'd imagine it could be slow as it will need to iterate through all records to determine the offset for records at the end of the file.To be fair, wireshark / pcap files have this problem too.\n \nreply",
      "I wasn\u2019t aware that ImHex had this feature - perhaps I\u2019ll try it!I\u2019ve been singing the praises of 010 Editor for years specifically because of its template and scripting features, the former of which is nearly identical to this DSL.\n \nreply",
      "Looks slightly more expressive than Kaitai's binary format DSL.\n \nreply"
    ],
    "link": "https://xy2i.blogspot.com/2024/11/using-imhexs-pattern-language-to-parse.html",
    "first_paragraph": "\n\n  I've got a binary file with a custom made binary format, and a spec for that\n  binary format. How do I go into the binary quickly and see the data I want ?\n\n  This is a problem I ran into while writing some software that operates on this\n  data. Before, my approach would have probably been to write some Python code\n  to parse the format, following the spec carefully and see where it\n  diverges.\u00a0\n\n  Recently though, I heard about ImHex,\n  an hex editor with advanced features, and decided to give it a go.The feature I used the most in ImHex for my case\n  was the integrated DSL, the \"pattern language\". It lets you define structures\n  that ImHex will match on, and decode the data. The syntax is a mix of C++ and Rust, but with unique semantics and a lot of nice affordances.Many examples that follow will be my real code for parsing the SWF file format.Here's a pattern which parses a char, followed by the \"WS\" string in memory, an unsigned byte, and a four byte number after:In ImHex, ther"
  },
  {
    "title": "Show HN: Hacker News frontpage as a print newspaper that you can personalize (yourhackernews.com)",
    "points": 246,
    "submitter": "nimbusega",
    "submit_time": "2024-11-06T15:23:42 1730906622",
    "num_comments": 71,
    "comments_url": "https://news.ycombinator.com/item?id=42063709",
    "comments": [
      "This doesn't look like a print newspaper. Print newspapers are much denser (in general) and have different headline sizes to emphasize the editor's choice of stories. This looks like a corporate blog home page or something. Some people will like this presentation; I'm pretty happy with HN as it is. But congratulations on shipping!\n \nreply",
      "For the rest of the news in a more HN-like format (at least at the top level) you might like https://lite.cnn.com/\n \nreply",
      "https://text.npr.org is also a text only version of npr\n \nreply",
      "I remember using both this and cnn lite 8 years ago quite a bit right around this time, cool to see they\u2019re still going strong.\n \nreply",
      "Also this site works great in text browsers like Lynx.\n \nreply",
      "Lynx wrapped in Docker:https://github.com/jzombie/docker-lynx\n \nreply",
      "That's a great observation actually! They should've made the design do that automatically based on story ranking\n \nreply",
      "Thanks for the feedback! Print newspaper's have curation, which this lacks. I guess the main thing it takes from newspapers is  the image and blurb that help give you a preview of the story.\n \nreply",
      "There is a form of curation on HN and \"editorial judgment\" on HN and that's in the points a post has. A closer approximation of a newspaper would be possible by looking at the points of a post and maybe comparing that to other posts and then sizing headlines appropriately based on how \"important\" the HN community sees a given story.\n \nreply",
      "The other form of curation is place on the front page.That's probably closer to the editors choice in the context of HN.\n \nreply"
    ],
    "link": "https://yourhackernews.com/",
    "first_paragraph": "\n            Personalize the Hacker News frontpage. Like and dislike stories, then click \"Update\" to get recommended stories.\n        Be The First to KnowNot affiliated with Y Combinator or Hacker News."
  },
  {
    "title": "One year, 41M digits: How Luke Durant found the largest known prime number (washingtonpost.com)",
    "points": 21,
    "submitter": "ortusdux",
    "submit_time": "2024-11-06T20:56:47 1730926607",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42069246",
    "comments": [
      "https://archive.ph/2XAbZ",
      "> The discovery was the result of almost exactly one year of work and about $2 million of Durant\u2019s own money.> Durant, who made his money off the boom, said he put his time and money into the project to show people that they aren\u2019t helpless to technology giants and that we can figure out massive problems if we work together.If I sold absolutely everything I owned, I would not even have close to half of what it Durant invested in his pet project. While I like his intended sentiment, I can't help but notice the irony.\n \nreply",
      "> Durant, who made his money off the boom, said he put his time and money into the project to show people that they aren\u2019t helpless to technology giants and that we can figure out massive problems if we work together.I can appreciate the sentiment but> The discovery was the result of almost exactly one year of work and about $2 million of Durant\u2019s own money.doesn't really show me much especially since> The prime number Durant discovered serves no real purpose for society.This sort of shows the opposite: if it takes $2M to discover something that doesn't have a real purpose, yeah I definitely feel a bit helpless against tech giants trying to do anything that is marginally useful.\n \nreply",
      "Ha, we both basically posted the same thing ( see above )!\n \nreply",
      "Recent and related:GIMPS Discovers Largest Known Prime Number: 2^136279841 \u2013 1 - https://news.ycombinator.com/item?id=41904237 - Oct 2024 (11 comments)New Mersenne Prime discovered (probably) - https://news.ycombinator.com/item?id=41858024 - Oct 2024 (120 comments)\n \nreply",
      "We changed the url above from https://www.popsci.com/science/largest-prime-number/ to the article it points to.\n \nreply"
    ],
    "link": "https://www.washingtonpost.com/science/2024/10/23/nvidia-prime-mersenne-gpu-cloud/",
    "first_paragraph": ""
  },
  {
    "title": "New images of Jupiter (swri.edu)",
    "points": 418,
    "submitter": "0xFACEFEED",
    "submit_time": "2024-11-06T07:30:37 1730878237",
    "num_comments": 68,
    "comments_url": "https://news.ycombinator.com/item?id=42057851",
    "comments": [
      "Juno was something about radar - penetrating the cloud layers to see what was below.In college my son worked on the FFT engine that processed the radar data. He has code circling Jupiter!\n \nreply",
      "I have a close friend that worked on the mars rover.He uses me as a reference.As soon as they start being like \u201ccan he use the latest android libraries and techniques\u201d or some crap. I just shoot back:\n\u201cThe man has code on another planet, he\u2019s more than capable of picking up anything\u201dThey shut up so fast lol\n \nreply",
      "That would be a hilarious (and confusing) bumper sticker. When other parents say \u201cmy son is an honour student\u201d you can smugly reply \u201cyeah, but does he have code circling Jupiter?\u201dCongratulations, by the way. I\u2019m being (trying to be) funny but I genuinely think that is cool and a reason to be proud.\n \nreply",
      "I don't have code running on them, but I do have hardware designs aboard Pioneer 10 & 11. These were the first rocks we humans tossed high & fast enough from the Sun that they're never coming back. I'm a little proud of that.Anybody with code circling Jupiter definitely has bragging rights and should be proud. If it were a just world, he/she wouldn't have to pay for a drink in a bar, ever.\n \nreply",
      "On the other hand, depending on their development, the Jovians might think that everything at all is circling Jupiter. :D\n \nreply",
      "I worked with a guy once back in the 80s who did the radar preamp on Pioneer Venus I believe it was.  Very bright individual.\n \nreply",
      "That's really cool, something to be proud of :)\n \nreply",
      "These come from Juno, a mission sent in 2011 and orbiting Jupiter since 2016. Must say it wasn't really on my radar anymore, but looking at the timeline on Wikipedia, it's still going around and getting close (\"perijove\") every month and a week or so, at an ever-increasing longitude https://en.wikipedia.org/wiki/Juno_(spacecraft)#Timeline The planned end of the mission is in about a year. The camera was \"included in the payload to facilitate education and public outreach [but] later re-purposed to study the dynamics of Jupiter's clouds\"\n \nreply",
      "Yeah, they had to fight so hard to get that camera on there! It was not included in the initial designs since it wasn't necessary for the science objectives.\n \nreply",
      "Makes me wonder what it costs to send a \"simple\" camera along. Factors that make it probably not so simple: even 200 grams of camera (and extra solar panels to supply +10W while operating) probably costs many thousands of euros in rocket fuel and emission taxes. The engineering time to properly fixate it onto the spacecraft, integrate the software, and test the whole thing cost probably a few ten thousands in salaries. Radiation may be a big problem for what's otherwise off-the-shelf hardware, that might mean the hardware costs much more (tens of thousands instead of a couple hundred euros potentially?) and gets significantly heavier from shielding, but I wouldn't know how much. Is that about right, am I missing something major and/or am I off on orders of magnitude somewhere?\n \nreply"
    ],
    "link": "https://www.missionjuno.swri.edu/junocam/processing?source=all&ob_from=2024-10-01&ob_to=2024-11-01&phases%5B%5D=PERIJOVE+66&perpage=16",
    "first_paragraph": "We invite you to download raw JunoCam images posted here and do your own image processing on them. Be creative! Anything from cropping to color enhancing to collaging is fair game. Then upload your creations here.Please refrain from direct use of any official NASA or Juno mission logos in your work, as this confuses what is officially sanctioned by NASA and by the Juno Project.We ask that you refrain from posting any patently offensive, political, or inappropriate images. Let\u2019s keep it clean and fun for everyone of any age! Remember, this section is moderated so inappropriate content will be rejected. But creativity and curiosity in the scientific spirit and the adventure of space exploration is highly encouraged and we look forward to seeing Jupiter through not only JunoCam\u2019s eyes, but your own. Have at it!"
  },
  {
    "title": "Show HN: SuperSplat \u2013 open-source 3D Gaussian Splat Editor (playcanvas.com)",
    "points": 191,
    "submitter": "ovenchips",
    "submit_time": "2024-11-06T12:07:06 1730894826",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=42060856",
    "comments": [
      "This is neat but Splats are not really mean to be edited in this way.Splats are sort of like byte code, they are the compiled and optimized representation of reflected light as semi-transparent guassians.Or you can think of them as the PDF equivalent of a Google or Word Doc.  All the logic is gone, and you just have final optimized results.Generally when you edit PDFs, the results are not great and you cannot make major edits because the layout won't reflow, etc.So while this is cool, I don't think it will take off unless there is another innovation in terms of either using AI to \"reflow\" the lighting and surfaces after an edit, or inferring more directly the underlying representations (true surface properties and the light sources.)\n \nreply",
      "Hi Ben! I would argue that it is very useful for splats to be edited in this way. I couldn't have built this application without SuperSplat for isolating, cleaning, transforming and optimizing/compressing the PLY:https://playcanv.as/e/p/cLkf99ZV/Integrating AI is an interesting topic and something that certainly has potential.\n \nreply",
      "I 100% agree with:- cleaning up noisy GuassianSplats is useful.  There are often stragglers floating around in space that need to get deleted.- compression/optimizing them is useful.This being a cleanup and compression tool makes sense, but I guess I don't call that an \"editor.\"I guess I was more arguing against the idea that this is a viable \"editor\" where one can combine and manipulate in more radical ways Gaussian Splats.  The current technological approach doesn't make this a feasible use case.\n \nreply",
      "Coming very soon is:- Copy & Paste: e.g. delete a tree and fill the hole with a copied patch of grass- Color Adjustments: tinting, brightness, etc.If these aren't editing ops, I don't know what is. :)\nSure, you _could_ go back and recapture photogrammetry or rerun training, but that's super costly in terms of time. SuperSplat lets you make simple edits quickly and easily.\n \nreply",
      "In theory if you delete something you have to recompute global illumination and remove cast shadows in the immediate environment of the removed object, but that information is baked in the gaussian splats. I think that's the kind of limitation the parent comment is talking about.\n \nreply",
      "To be as accurate as possible, yes, you need to consider lighting/shadows. But trust me, in many circumstances, you can copy+paste gaussians and it looks 'good enough'. It depends on the scene and the edit you want to make.\n \nreply",
      "Wow, the fade-in animation is most excellent! Mind sharing how you created it?\n \nreply",
      "I don't like the \"byte code\" analogy for Gaussian splats.  If they were like that, then we could apply compiler optimization and those sorts of math techniques to them.  But they are Probability Distribution Functions with transforms, so the math tools we have to work with them are the similar to those in signal processing -- resampling, quantizing, estimating, etc.In that model, we don't compile them, we train them; we don't run them, we sample/rasterize them.This link came up on HN before and was a great refresher/expander on the math of Guassians which allow all this. [1].Since Gaussians can be estimated, neural networks can model/generate them.   Researchers are using this for 4D work and mesh extraction.  The NNs run at lower frame rate informing the 3DGS running at interactive rates.You are right that it is ephemeral and really a weird trick of the eye and we need new ways to edit/create it.  Vectors/pixels have had a lot more time to grow tooling.  People are working on it, just the toolbox is different.  Very cool stuff will be coming up, I bet![1] https://news.ycombinator.com/item?id=41912160  I've also re-learned Fourier transforms to appreciate similar concepts.\n \nreply",
      "I don't really think this is true. Gaussian splats certainly came from a context where an opaque representation is expected and normal, but they ended up being an entirely comprehensible format. They're not as simple to operate on as an SDF or voxel representation, but I think they're on par with triangle mesh geometry. A transformed fuzzy sphere is about as complex as a triangle, and spherical harmonic colors, while more conceptually difficult than textures, have fewer moving parts.\n \nreply",
      "I guess in theory what you say could be correct, however in practice this tool has been very helpful for client work of editing, cleaning, cropping and even slight modification of Gaussian splats. I could see a similar argument for raster images in general -- they are hard to edit as you're modifying individual pixels and it's not efficient, but we've seen tools grow from MS Paint to modern Photoshop to become very useful. I think the same could be said here -- it's just early and we're at the \"bytecode\" level as you say.\n \nreply"
    ],
    "link": "https://playcanvas.com/supersplat/editor?load=https://raw.githubusercontent.com/willeastcott/assets/main/toy-cat.ply&camera.overlay=false&show.bound=false",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: Midship (YC S24) \u2013 Turn PDFs, docs, and images into usable data",
    "points": 50,
    "submitter": "maxmaio",
    "submit_time": "2024-11-06T18:05:55 1730916355",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=42066500",
    "comments": [
      "Congrats on the launch. I just sent y'all an email \u2013 I'm curious with what you can do with airline crew rosters.\n \nreply",
      "Heres a real world use case, our company has moved our pension provider. This provider like the old one sucks at providing me with a good way to navigate through the 120 funds I can invest in.I want to create something that can paginate through 12 pages of html, perform clicks, download pdf fund factsheet, extract data from this factsheet into excel or CSV. Can this help? What's the best way to deal with the initial task of automating webpage interactions systematically?\n \nreply",
      "This is an interesting use case! We've heard similar stories from people dealing with pensions. Today we are ready to solve out of the box the extract data from a factsheet into excel or CSV step. Shoot me an email at max@midship.dev!\n \nreply",
      "Honest question but how do you see your business being affected as foundational models improve? While I have massive complaints about them, Gemini + structured outputs is working remarkably well for this internally and it's only getting better. It's also an order of magnitude cheaper than anything I've seen commercially.\n \nreply",
      "Curious - have you compared Gemini against Anthropic and OpenAI\u2019s offerings here? Am needing to do something similar for a one-off task and simply need to choose a model to use.\n \nreply",
      "Gemini is an awful developer experience but accuracy for OCR tasks is close to perfect. The pricing is also basically unbeatable - works out to 1k  10k pages per dollar depending on the model. OpenAI has subtle hallucinations and I haven\u2019t profiled Anthropic.\n \nreply",
      "We're excited for foundational models to improve because we hope it will unlock a lot more use cases. Things like analysis after extraction, able to accurately extract extremely complex documents, etc!\n \nreply",
      "Congrats on the launch!I\u2019m curious to hear more about your pivot from AI workflow builder to document parsing. I can see correlations there, but that original idea seems like a much larger opportunity than parsing PDFs to tables in what is an already very crowded space. What verticals did you find have this problem specifically that gave you enough conviction to pivot?\n \nreply",
      "We saw initial traction with real estate firms extracting property data like rent rolls. But we've also seen traction in other verticals like accounting and intake forms.  The original idea was very ambitious and when talking to potential customers they all seemed to be happy with the existing players.\n \nreply",
      "Saw reducto released benchmark related to your product: https://reducto.ai/blog/rd-tablebench\nCurious your take on the benchmark and how well midship performs\n \nreply"
    ],
    "link": "item?id=42066500",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Aide, an open-source AI native IDE (aide.dev)",
    "points": 130,
    "submitter": "skp1995",
    "submit_time": "2024-11-06T15:01:00 1730905260",
    "num_comments": 106,
    "comments_url": "https://news.ycombinator.com/item?id=42063346",
    "comments": [
      "Links to the project, I'm guessing these :)https://github.com/codestoryai/aidehttps://aide.dev/\n \nreply",
      "you missed this one https://github.com/codestoryai/sidecar\nSidecar: The AI brains\nAide: https://github.com/codestoryai/aide the editor\n \nreply",
      "What is the privacy policy? Do you get to see my code and secrets? Does anybody else? I don't want you to. Nothing personal.\n \nreply",
      "we don't .. in your user settings, type in disable all telemetry and we won't see a thing\n \nreply",
      "Why is a fork required? I use the cline plugin for VS Code and it seems to be able to be able to more things, like update code directly, create new files, etc.\n \nreply",
      "After using Cursor (another AI focused fork) I'm 100% on the fork train. AI built natively into the IDE presents another layer of speed and isn't subject to the limitations of the extension system (which is awesome in its own right, not a knock on it).\n \nreply",
      "fork was necessary for the UX we wanted to go for. I do agree that an extension can also satisfy your needs (and it clearly is in your case)Having a deeper integration with the editor allows for some really nice paradigms:\n- Rollbacks feel more native, in the sense that I do not loose my undo or redo stack\n- cmd+k is more in line with what you would expect with a floating widget for input instead of it being shown at the very top of your screen which is the case with any extension for now.Going further, the changes which Microsoft are making to enable copilot editing features are only open to \"copilot-chat\" and no other extension (fair game for Microsoft IMHO)\nSo keeping these things in mind, we designed the architecture in a way that we can go towards any interface (editor/extension). We did put energy into making this work deeply with the VSCode ecosystem of APIs and also added our own.If the editor does not work to our benefit, we will take a call on moving to a different interface and thats where an extension or cloud based solution might also make sense\n \nreply",
      "I'm curious - what does the AI coding setup of the HN community look like, and how has your experience been so far?I want to get some broader feedback before completely switching my workflow to Aide or Cursor.\n \nreply",
      "I am on day 8 of Cursor's 14-day trial. If things continue to go well, I will be switching from Webstorm to Cursor for my Typescript projects.The AI integrations are a huge productivity boost. There is a substantial difference in the quality of the AI suggestions between using Claude on the side, and having Claude be deeply integrated in the codebase.I think I accepted about 60-70% of the suggestions Cursor provided.Some highlights of Cursor:- Wrote about 80% of a Vite plugin for consolidating articles in my blog (built on remix.run)- Wrote a Github Action for automated deployments. Using Cursor to write automation scripts is a tangible productivity boost.- Made meaningful alterations to a libpg_query fork that allowed it to be cross-compiled to iOS. I have very little experience with C compilation, it would have taken me a substantially long time to figure this out.There are some downsides to using Cursor though:- Cursor can get too eager with its suggestions, and I'm not seeing any easy way to temporarily or conditionally turn them off. This was especially bad when I was writing blog posts.- Cursor does really well with Bash and Typescript, but does not work very well with Kotlin or Swift.- This is a personal thing, but I'm still not used to some of the shortcuts that Cursor uses (Cursor is built on top of VSCode).\n \nreply",
      "Its great that cursor is working for you. I do think LLMs in general are far far better on Typescript and Python compared to other languages (reflects from the training data)What features of cursor were the most compelling to you? I know their autocomplete experience is elite but wondering if there are other features which you use often!\n \nreply"
    ],
    "link": "https://aide.dev/",
    "first_paragraph": "AidePowered by the state-of-the-art agentic framework on swebench-liteView on GitHubEver tried making large changes in a codebase using AI? If you are like me, you probably were very impressed \u2013 at first. The initial bliss quickly fades away when you realise the code will be very hard to maintain, or is flat out wrong.Aide proactively proposes fixes or asks to include files that may be missing in the context. Our agent can do so by iterating on linter errors and pulling in relevant context using LSP tools, like \u201cGo to references\u201d.Go ahead, do AI-edits on top of your coding session. We keep slim, VS Code-native checkpoints (we don\u2019t use git) to easily roll back to previous states, in case the agent made any mistake.We try to make Aide feel like a real engineer to pair-program with. Chat about a problem by @\u2019ting the file(s) and then jump into edits, or go from a smaller set of edits and discuss their side-effects.Taking inspiration from MacOS spotlight, we created a floating widget you "
  },
  {
    "title": "Physicists spot quantum tornadoes twirling in a 'supersolid' (quantamagazine.org)",
    "points": 41,
    "submitter": "elsewhen",
    "submit_time": "2024-11-06T18:46:53 1730918813",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.quantamagazine.org/physicists-spot-quantum-tornadoes-twirling-in-a-supersolid-20241106/",
    "first_paragraph": "\nAn editorially independent publication supported by the Simons Foundation.\n\nGet the latest news delivered to your inbox.\nCreate a reading list by clicking the Read Later icon next to the articles you wish to save.Type search term(s) and press enterPopular\n                                    SearchesNovember 6, 2024When you rotate a supersolid, vortices spontaneously form.Ibrahim Rayintakath and Rui Braz for\u00a0Quanta MagazineContributing WriterNovember 6, 2024In a lab nestled between the jagged peaks of the Austrian Alps, rare earth metals vaporize and spew out of an oven at the speed of a fighter jet. Then a medley of lasers and magnetic pulses slow the gas nearly to a halt, making it colder than the depths of space. The roughly 50,000 atoms in the gas lose any sense of identity, merging into a single state. Finally, with a twist of the ambient magnetic field, tiny tornadoes swirl into existence, pirouetting in the darkness.For three years, the physicist Francesca Ferlaino and her team "
  },
  {
    "title": "Monorepo \u2013 Our Experience (ente.io)",
    "points": 120,
    "submitter": "vishnumohandas",
    "submit_time": "2024-11-06T13:37:03 1730900223",
    "num_comments": 125,
    "comments_url": "https://news.ycombinator.com/item?id=42062074",
    "comments": [
      "Every monorepo I've ever met (n=3) has some kind of radioactive DMZ that everybody is afraid to touch because it's not clear who owns it but it is clear from its quality that you don't want to be the last person who touched it because then maybe somebody will think that you own it.  It's usually called \"core\" or somesuch.Separate repos for each team means that when two teams own components that need to interact, they have to expose a \"public\" interface to the other team--which is the kind of disciplined engineering work that we should be striving for.  The monorepo-alternative is that you solve it in the DMZ where it feels less like engineering and more like some kind of multiparty political endeavor where PR reviewers of dubious stakeholder status are using the exercise to further agendas which are unrelated to the feature except that it somehow proves them right about whatever architectural point is recently contentious.Plus, it's always harder to remove something from the DMZ than to add it, so it's always growing and there's this sort of gravitational attractor which, eventually starts warping time such that PR's take longer to merge the closer they are to it.Better to just do the \"hard\" work of maintaining versioned interfaces with documented compatibility (backed by tests).  You can always decide to collapse your codebase into a black hole later--but once you start on that path you may never escape.\n \nreply",
      "Since we are indulging in generalizations from our past. With separate repos you end up with 10 \"cores\" that are radioctive DMZ's everybody is afraid to touch. And those \"disciplined\" public API's will be universally hated by everyone who consumes them.Neither a monorepo nor separate repos will result in people being disciplined. If you already have the discipline to do separate repositories correctly then you'll be fine with a monorepo.So I guess it's six on one hand, half dozen in the other.\n \nreply",
      "No I think there's a clear difference.  I've seen this several times:  Somebody changes teams and now they're no longer responsible for a bit of code, but then they learn that it is broken in some way, and now they're sneaking in commits that--on paper--should now be handled by somebody else.Dev's *like* to feel ownership of reasonably sized chunks of code.  We like to arrange it in ways that is pleasing for us to work on later down the road.  And once we've made those investments, we like to see them pay off by making quick easy changes that make users happy.  Sharing a small codebase with three or four other people and finding ways to make each other's lives easier while supporting it is *fun* and it makes for better code too.But it only stays fun if you have enough autonomy that you can really own it--you and your small team.  Footguns introduced need to be pointed at your feet. Automation introduced needs to save you time.  If you've got the preferences of 50 other people to consider, and you know that whatever you do you're going to piss off some 10 of them or another... the fun goes away.This is simple:> we own this whole repo and only this 10% of it (the public interface) needs to make external stakeholders happy, otherwise we just care about making each other happy....and it has no space in it for there to be any code which is not clearly owned by somebody.  In a monorepo, there are plenty of places for that.\n \nreply",
      "I would advise annotating your experience anecdotes, which are surely valuable, with some information about team size, company size, corporate structure (tech team in a non tech corp, vs pure tech), age etc.The meat is in the detail, I find.\n \nreply",
      "You can have well-defined interfaces without splitting it into many repos just like how you can have well-defined interfaces without splitting it into microservices. In fact, I've seen enough garbage to know that forcing the issue via these mechanisms just makes bad software worse.\n \nreply",
      "> Moving to a monorepo didn't change much, and what minor changes it made have been positive.\n\nI'm not sure that this statement in the summary jives with this statement from the next section:    > In the previous, separate repository world, this would've been four separate pull requests in four separate repositories, and with comments linking them together for posterity.\n    > \n    > Now, it is a single one. Easy to review, easy to merge, easy to revert.\n\nIMO, this is a huge quality of life improvement and prevents a lot of mistakes from not having the right revision synced down across different repos.  This alone is a HUGE improvement where a dev doesn't accidentally end up with one repo in this branch and forgot to pull this other repo at the same branch and get weird issues due to this basic hassle.When I've encountered this, we've had to use another repo to keep scripts that managed this.  But this was also sometimes problematic because each developer's setup had to be identical on their local file system (for the script to work) or we had to each create a config file pointing to where each repo lived.This also impacts tracking down bugs and regression analysis; this is much easier to manage in a mono-repo setup because you can get everything at the same revision instead of managing synchronization of multiple repos to figure out where something broke.\n \nreply",
      "I prefer microservices/microrepos _conceptually_, but we had the same experience as your quoted text - making changes to four repos, and backporting those changes to the previous two release branches, means twelve separate PRs to make a change.Having a centralized configuration library (a shared Makefile that we can pull down into our repo and include into the local Makefile) helps, until you have to make a backwards-incompatible change to that Makefile and then post PRs to every branch of every repo that uses that Makefile.Now we have almost the entirety of our projects back into one repository and everything is simpler; one PR per release branch, three PRs (typically) for any change that needs backporting. Vastly simpler process and much less room for error.\n \nreply",
      "My only counter argument here, is when those 4 things deploy independently.  Sometimes, people will get tricked into thinking a code change is atomic because it is in one commit, when it will lead to a mixed fleet because of deployment realities.  In that world, having them separate is easier to work with, as you may have to revert one of the deployments separately from the others.\n \nreply",
      "That's just an argument for not doing \"implicit GitOps\", treating the tip of your monorepo's main branch as the source-of-truth on the correct deployment state of your entire system. (\"Implicit GitOps\" sorta-kinda works when you have a 1:1 correspondence between repos and deployable components \u2014 though not always! \u2014 but it isn't tenable for a monorepo.)What instead, then? Explicit GitOps. Explicit, reified release specifications (think k8s resource manifests, or Erlang .relup files), one per separately-deploy-cadenced component. If you have a monorepo, then these live also as a dir in the monorepo. CD happens only when these files change.With this approach, a single PR can atomically merge code and update one or more release specifications (triggering CD for those components), if and when that is a sensible thing to do. But there can also be separate PRs for updating the code vs. \"integrating and deploying changes\" to a component, if-and-when that is sensible.\n \nreply",
      "> With this approach, a single PR can atomically merge code and update one or more release specifications (triggering CD for those components), if and when that is a sensible thing to do.How do you avoid the chicken-and-egg problem? Like if the k8s manifest contains a container tag, and the tag is created by CI when the PR is merged to main, it would seem you can\u2019t add code and deploy that code in the same PR.\n \nreply"
    ],
    "link": "https://ente.io/blog/monorepo-retrospective/",
    "first_paragraph": ""
  },
  {
    "title": "Exposure to phthalate compromises brain function in adult vertebrates (sciencedirect.com)",
    "points": 76,
    "submitter": "PaulHoule",
    "submit_time": "2024-11-06T21:00:44 1730926844",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42069320",
    "comments": [
      "Obviously this is baseless speculation, but I sure do wonder if various psychological conditions that are so diverse and hard to pin down (i.e. 3 out of these 9 symptoms around attention, social behavior, or impulse control) are ultimately just going to be proven to be purely biological. And since genetics can only explain less than half of it, it sure seems that something messing with chemical signaling would be a reasonable explanation for the rest.\n \nreply",
      "I've been speculating on industrial pollutants that act as endocrine disruptors for years now, and every so often some evidence emerges. People understandably don't like such mundane explanations when they've built large parts of their identity around the issues it may have caused them though.\n \nreply",
      "You're idea is hardly novel. I've had plenty of people tell me this or that chemical caused me to be trans. I've also spent plenty of time researching possible biological causes of transness. I'm personally open to the idea that maybe there's a biological cause but I haven't found a convincing explanation yet.The problem is that when I have conversations with people about soy turning me trans or social media turning me trans they are often trying to use that as a way to deny me any agency over my own life.\n \nreply",
      "They should look on the bright side: eliminating plastic exposure could be a great wellspring of identity. I mean to really avoid them you\u2019d have to make all your food from raw unprocessed ingredients, and then there\u2019s clothing, all the objects you interact with throughout the day, etc.Edit: expanding a bit more on the idea. DIYing all the stuff you\u2019d need to avoid plastics is a much bigger identity statement than neurodivergent. Tho saying I\u2019ve been subtly poisoned is far less sexy than saying I\u2019m neurodivergent.\n \nreply",
      "Food. It\u2019s food. We are only just beginning to understand the less obvious effects of the modern diet, including all the processing and additives. Much has not been explored, such as is if the abundance of various toxic chemicals at supposedly safe levels has a synergistic effect, for example the many endocrine disrupting compounds with diverse mechanisms. But over the past decade it has become pretty clear that the Gut-Brain relationship is extremely important, including in understanding psychopathology.Another emerging idea is that much of the negative health trend that\u2019s been progressing extra rapidly since the 90\u2019s is the result of mitochondrial dysfunction, driven by the multifactored (ultraprocessed foods, icides and tives, sedentary lifestyle, the incessant toxin-boosted immune shocks throughout development, possibly even omnipresent modulated emf) assault on our biology. It makes a lot of sense, to me at least, that crippling the source of cellular energy would precipitate seemingly unrelated chronic pathologies. This last paragraph especially is still highly speculative and controversial.\n \nreply",
      "Thanks for clearing this up, I certainly find your citations compelling.\n \nreply",
      "It\u2019s trivial to find studies detailing lower-magnitude negative effects of the things mentioned, but in isolation. As far is I\u2019m aware, the net impact on our biology of the dozens of environmental stressors we face remains to be studied.This doesn\u2019t directly go to anything I said, but I will share this fun review: https://www.sciencedirect.com/science/article/pii/S221475002...\n \nreply",
      "\"The fact that we were able to detect similar effects of phthalate exposure on the function of central neurons for the low and 10-fold higher environmental concentration tested is important in this context: humans get exposed to phthalates mostly through ingestion and their indoor environment, while fish in this study got exposed to phthalates through the surrounding water. These differences in exposure may mean that humans generally take up fewer phthalates from the environment than the fish in the present study. However, even if fewer phthalates are taken up and reach/cross the BBB in humans, it must be assumed on the basis of our results that the effect could still be similar to that observed in our experiments on goldfish. \"It seems sloppy not to attempt to address the relevance of typical human exposure to the study amounts?\n \nreply",
      "Note: here, vertebrates = goldfishes\n \nreply",
      "How relevant is this for plastic food packaging?\n \nreply"
    ],
    "link": "https://www.sciencedirect.com/science/article/pii/S0147651324012636",
    "first_paragraph": ""
  },
  {
    "title": "The deep learning boom caught almost everyone by surprise (understandingai.org)",
    "points": 213,
    "submitter": "slyall",
    "submit_time": "2024-11-06T04:05:01 1730865901",
    "num_comments": 142,
    "comments_url": "https://news.ycombinator.com/item?id=42057139",
    "comments": [
      "The article credits two academics (Hinton, Fei Fei Li) and a CEO (Jensen Huang).  But really it was three academics.Jensen Huang, reasonably, was desperate for any market that could suck up more compute, which he could pivot to from GPUs for gaming when gaming saturated its ability to use compute.  Screen resolutions and visible polygons and texture maps only demand so much compute; it's an S-curve like everything else.  So from a marketing/market-development and capital investment perspective I do think he deserves credit.  Certainly the Intel guys struggled to similarly recognize it (and to execute even on plain GPUs.)But... the technical/academic insight of the CUDA/GPU vision in my view came from Ian Buck's \"Brook\" PhD thesis at Stanford under Pat Hanrahan (Pixar+Tableau co-founder, Turing Award Winner) and Ian promptly took it to Nvidia where it was commercialized under Jensen.For a good telling of this under-told story, see one of Hanrahan's lectures at MIT: https://www.youtube.com/watch?v=Dk4fvqaOqv4Corrections welcome.\n \nreply",
      "Jensen embraced AI as a way to recover TAM after ASICs took over crypto mining.  You can see that between-period in NVidia revenue and profit graphs.By that time, GP-GPU had been around for a long, long time.  CUDA still doesn't have much to do with AI - sure, it supports AI usage, even includes some AI-specific features (low-mixed precision blocked operations).\n \nreply",
      "Jensen embraced AI way before that.  CuDNN was released back in 2014.  I remember being at ICLR in 2015, and there were three companies with booths: Google and Facebook who were recruiting, and NVIDIA was selling a 4 GPU desktop computer.\n \nreply",
      "Well as soon as matmul has a marketable use (ML predictive algorithms) nvidia was on top of it.I don\u2019t think they were thinking of  LLMs in 2014, tbf.\n \nreply",
      "Effectively no one was but LLM's are precisely \"ML predictive algorithms\". That neural networks more broadly would scale at all on gaming chips is plenty foresight to be impressed with.\n \nreply",
      "> Jensen embraced AI as a way to recover TAM after ASICs took over crypto mining.TAM: Total Addressable Market\n \nreply",
      "I think there is a slight disconnect here between making AI systems which are smart and AI systems which are useful. It\u2019s a very old fallacy in AI: pretending tools which assist human intelligence by solving human problems must themselves be intelligent.The utility of big datasets was indeed surprising, but that skepticism came about from recognizing the scaling paradigm must be a dead end: vertebrates across the board require less data to learn new things, by several orders of magnitude. Methods to give ANNs \u201ccommon sense\u201d are essentially identical to the old LISP expert systems: hard-wiring the answers to specific common-sense questions in either code or training data, even though fish and lizards can rapidly make common-sense deductions about manmade objects they couldn\u2019t have possibly seen in their evolutionary histories. Even spiders have generalization abilities seemingly absent in transformers: they spin webs inside human homes with unnatural geometry.Again it is surprising that the ImageNet stuff worked as well as it did. Deep learning is undoubtedly a useful way to build applications, just like Lisp was. But I think we are about as close to AGI as we were in the 80s, since we have made zero progress on common sense: in the 80s we knew Big Data can poorly emulate common sense, and that\u2019s where we\u2019re at today.\n \nreply",
      "> vertebrates across the board require less data to learn new things, by several orders of magnitude.Sometimes I wonder if it\u2019s fair to say this.Organisms have had billions of years of training. We might come online and succeed in our environments with very little data, but we can\u2019t ignore the information that\u2019s been trained into our DNA, so to speak.What\u2019s billions of years of sensory information that drove behavior and selection, if not training data?\n \nreply",
      "My primary concern is the generalization to manmade things that couldn\u2019t possibly be in the evolutionary \u201ctraining data.\u201d As a thought experiment, it seems very plausible that you can train a transformer ANN on spiderwebs between trees, rocks, bushes, etc, and get \u201csuperspider\u201d performance (say in a computer simulation). But I strongly doubt this will generalize to building webs between garages and pantries like actual spiders, no matter how many trees you throw at it, so such a system wouldn\u2019t be ASI.This extends to all sorts of animal cognitive experiments: crows understand simple pulleys simply by inspecting them, but they couldn\u2019t have evolved to use pulleys. Mice can quickly learn that hitting a button 5 times will give them a treat: does it make sense to say that they encountered a similar situation in their evolutionary past? It makes more sense to suppose that mice and crows have powerful abilities to reason causally about their actions. These  abilities are more sophisticated than mere \u201cPavlovian\u201d associative reasoning, which is about understanding stimuli. With AI we can emulate associative reasoning very well because we have a good mathematical framework for Pavlovian responses as a sort of learning of correlations. But causal reasoning is much more mysterious, and we are very far from figuring out a good mathematical formalism that a computer can make sense of.I also just detest the evolution = training data metaphor because it completely ignores architecture. Evolution is not just glomming on data, it\u2019s trying different types of neurons, different connections between them, etc. All organisms alive today evolved with \u201cbillions of years of training,\u201d but only architecture explains why we are so much smarter than chimps. In fact I think the \u201cevolution\u201d preys on our misconception that humans are \u201cmore evolved\u201d than chimps, but our common ancestor was more primitive than a chimp.\n \nreply",
      "Evolution is the heuristic search for effective neural architectures. It is training data, but for the meta-search for effective architectures, which gets encoded in our DNA.Then we compile and run that source code and our individual lived experience is the training data for the instantiation of that architecture, e.g. our brain.It's two different but interrelated training/optimization processes.\n \nreply"
    ],
    "link": "https://www.understandingai.org/p/why-the-deep-learning-boom-caught",
    "first_paragraph": ""
  },
  {
    "title": "Hacking cars in JavaScript (Replay attacks in the browser with the HackRF) (charliegerard.dev)",
    "points": 39,
    "submitter": "rmason",
    "submit_time": "2024-11-02T20:05:17 1730577917",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://charliegerard.dev/blog/replay-attacks-javascript-hackrf/",
    "first_paragraph": "A couple of years ago, I built a project using the RTL-SDR to get live raw data from passing airplanes, in the browser.\nAs I wanted to explore more using Software-Defined Radios, I bought a HackRF One device that can both receive and transmit data, and I downloaded Universal Radio Hacker to start playing around with it.\nAfter tinkering a little bit, I had a hunch that it would probably be possible to recreate a similar tool in the browser, all in JavaScript, so I spent time doing just that!My ultimate goal was to answer the question... is it possible to hack a car using JavaScript? I didn't know at all if I was going to get there because my knowledge of all things SDR related is still minimal, but I'm very excited to share that it works!! \ud83d\ude03 This blog post explains the process I went through to figure things out.Before diving into the technical details, you can check out the website that you can use to receive, record and transmit data, so you can use it to hack doorbells, garage doors,"
  },
  {
    "title": "Model Predictive Control in the Browser with WebAssembly (garethx.com)",
    "points": 90,
    "submitter": "thunderbong",
    "submit_time": "2024-10-30T08:15:37 1730276137",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41992851",
    "comments": [
      "I've taken the linked Russ Tedrake class and have to say I loved this. Please make more!\n \nreply",
      "I'd be interested, if any one had suggestions, on MPC applied to ML/AI systems -- it seems this is an underserved technique/concern in MLEng, and I'd expect to see more on it.\n \nreply",
      "There is a big overlap between Optimal Control and Reinforcement Learning, in case you didn't know.Also Steve Brunton does a lot on the interface between control theory and ML on his channel: https://www.youtube.com/channel/UCm5mt-A4w61lknZ9lCsZtBw/pla...\n \nreply",
      "Another thing to keep in mind is that having AI/ML surrogates which can evaluate expensive functions faster can also be integrated as an information source in model predictive control algorithms.\n \nreply",
      "Exactly. \nML models such as autoencoders can also be used for reduced order modeling / dimensionality reduction e.g. for MPC of fluid systems.\n \nreply",
      "there's a lot of work in the broad area. most of it doesn't engage with the classical control theory literature (arguably it should).some keywords to search for recent hot research would be \"world model\", \"decision transformer\", \"active inference\", \"control as inference\", \"model-based RL\".\n \nreply",
      "Author of the post here - happy to answer any questions.\n \nreply",
      "Great job! I'm working in a similar blog post and it was fun seeing how you approached it.\nI was surprised the wasm implementation is fast enough, I was even considering writing webGpu compute shaders for my solver\n \nreply",
      "Beautiful stuff, great post!\n \nreply",
      "Thank you, really appreciate that.\n \nreply"
    ],
    "link": "https://garethx.com/posts/cart-pole-mpc/",
    "first_paragraph": ""
  },
  {
    "title": "98.css \u2013 A design system for building faithful recreations of old UIs (jdan.github.io)",
    "points": 379,
    "submitter": "OuterVale",
    "submit_time": "2024-11-06T02:46:58 1730861218",
    "num_comments": 78,
    "comments_url": "https://news.ycombinator.com/item?id=42056918",
    "comments": [
      "I made something similar as well (that includes both 3.11, 95, 2000, XP, CDE and Mac OS 9, and also all the default color schemes of those): https://nielssp.github.io/classic-stylesheets/?theme=win9x&s...My focus was not so much on pixel perfect, but instead on creating something that would also work and look aesthetically pleasing on modern systems, like with higher DPI monitors and such. So one of the the things I did was to recreate all the icons and symbols in SVG.I tried posting it as a Show HN when I added XP and Mac OS 9, but it didn't get much attention. Maybe the title of the project isn't as catchy.\n \nreply",
      "Whoa. Insanely cool. Outstanding quality and theming, such a simple implementation. Only thing I'd want to see is theming for data tables, maybe even an interactive table that behaves like the lists and grids.\n \nreply",
      "Hotdog stand!https://nielssp.github.io/classic-stylesheets/?theme=win3x&s...\n \nreply",
      "Love it; though the Windows 2000 theme seems a bit off (headings to heavy/bold).Windows 2000 was the pinnacle of UI design IMO.\n \nreply",
      "To echo the other comments: this is beautiful work!\n \nreply",
      "This is amazing, thanks for this! I made a simple app using 98.css because that was the most feature-filled retro CSS library I could find. Going to try and use your 3.1 schemes :)\n \nreply",
      "This project is absolutely gorgeous, you really did a great job at mapping each UI elements, really great work!\n \nreply",
      "This is incredible\n \nreply",
      "Very cool, thank you!\n \nreply",
      "Absolutely incredible work\n \nreply"
    ],
    "link": "https://jdan.github.io/98.css/",
    "first_paragraph": "A design system for building faithful recreations of old UIs.\n\n\n\n\n\n\n\n      98.css is a CSS library for building interfaces that look like Windows 98.\n      See more on GitHub.\n    Hello, world!\n      This library relies on the usage of semantic HTML. To make a button, you'll need\n      to use a <button>. Input elements require labels. Icon buttons rely on\n      aria-label. This page will guide you through that process, but accessibility is a primary\n      goal of this project.\n    \n      You can override many of the styles of your elements while maintaining the appearance provided by\n      this library. Need more padding on your buttons? Go for it. Need to add some color to your input labels?\n      Be our guest.\n    \nThis library does not contain any JavaScript, it merely styles your HTML with some CSS.\n      This means 98.css is compatible with your frontend framework of choice.\n    \n      Here is an example of 98.css used with React, and\n      an example with vanilla JavaScript. The "
  }
]