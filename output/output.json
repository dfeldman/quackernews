[
  {
    "title": "Do the simplest thing that could possibly work (seangoedecke.com)",
    "points": 347,
    "submitter": "dondraper36",
    "submit_time": "2025-08-29T19:05:09 1756494309",
    "num_comments": 175,
    "comments_url": "https://news.ycombinator.com/item?id=45068091",
    "comments": [
      "I think this works in simple domains. After working in big tech for a while, I am still shocked by the required complexity. Even the simplest business problem may take a year to solve, and constantly break due to the astounding number of edge cases and scale.Anyone proclaiming simplicity just hasnt worked at scale. Even rewrites that have a decade old code base to be inspired from, often fail due to the sheer amount of things to consider.A classic, Chesterton's Fence:\"There exists in such a case a certain institution or law; let us say, for the sake of simplicity, a fence or gate erected across a road. The more modern type of reformer goes gaily up to it and says, \u201cI don\u2019t see the use of this; let us clear it away.\u201d To which the more intelligent type of reformer will do well to answer: \u201cIf you don\u2019t see the use of it, I certainly won\u2019t let you clear it away. Go away and think. Then, when you can come back and tell me that you do see the use of it, I may allow you to destroy it.\u201d\"reply",
      "This is the classic misunderstanding where software engineers can't seem to communicate well with each other.We can even just look at the title here: Do the simplest thing POSSIBLE.You can't escape complexity when a problem is complex.  You could certainly still complicate it even more than necessary, though.  Nowhere in this article is it saying you can avoid complexity altogether, but that many of us tend to over-complicate problems for no good reason.reply",
      "> We can even just look at the title here: Do the simplest thing POSSIBLE.I think the nuance here is that \u201cthe simplest thing possible\u201d is not always the \u201cbest solution\u201d. As an example, it is possible to solve very many business or operational problems with a simple service sitting in front of a database. At scale, you can continue to operate, but the amount of man-hours going into keeping the lights on can grow exponentially. Is the simplest thing possible still the DB?Complexity is more than just the code or the infrastructure; it needs to run the entire gamut of the solution. That includes looking at the incidental complexity that goes into scaling, operating, maintaining, and migrating (if a temporary \u2018too simple but fast to get going\u2019 stack was chosen).Measure twice, cut once. Understand what you are trying to build, and work out a way to get there in stages that provide business value at each step. Easier said than done.Edit: Replies seem to be getting hung up over the \u201cDB\u201d reference. This is meant to be a hypothetical where the reader infers a scenario of a technology that \u201ccan solve all problems, but is not necessarily the best solution\u201d. Substitute for \u201cwriting files to the file system\u201d if you prefer.reply",
      "> At scale, you can continue to operate, but the amount of man-hours going into keeping the lights on can grow exponentially. Is the simplest thing possible still the DB?Don't worry, the second half of the title  has this covered:> ... that could possibly workIn the scenario you've described, the technology is not working, in the complete sense including business requirements of reasonable operating costs.Perhaps it really did work at first, in the complete sense, when the number of users was quite small. That's where the actual content of the article kicks in: it suggests you really do use that simple solution, because maybe you'll never need to scale after all, or you'll need to rewrite everything by then anyway, or you'll have access to more engineering talent by then, etc. I'd tend to agree, but with the caveat that you should feel free to break the rule so long as you're doing it consciously. But none of that implies that you should end up in the situation you described.reply",
      "Right, and again this is reading too much into it.  The simplest thing possible does not mean the best solution.  If your solution that worked really well yesterday no longer scales today, it's no longer the correct solution and will require a more complex one.reply",
      "> I think the nuance here is that \u201cthe simplest thing possible\u201d is not always the \u201cbest solution\u201d.The programmer's mind is the faithful ally of the perfect in its war waged against the good enough.The \"best\" solution for most people that have a problem is the one they can use right now.reply",
      "Consider for example, computerizing a currently-manual process. And the 80/20 rule.Do you handle one \"everything is perfect\" happy path, and use a manual exception process for odd things?Do you handle \"most\" cases, which is more tech work but shrinks the number of people you need handling one-off things?Or do you try to computerize everything no matter how rare?reply",
      "My favourite example of this from my own career... automating timesheet -> payroll processing in a unionized environment. As we're converting the collective bargaining agreement into code, we discover that there are a pair of rules that seem contradictory. Go talk to someone in the payroll department to try to figure out how it's handled. Get an answer that makes decent sense, but have a bit of a lingering doubt about the interpretation. Talk to someone else in the same department... they tell us the alternative interpretation.Bring the problem back to our primary contact and they've got no clue what to do. They're on like year 2 of a 7 year contract and they've just discovered that their payroll department has been interpreting the ambiguous rules somewhat randomly. No one wants to commit to an interpretation without a memorandum of understanding from the union, and no one wants to start the process of negotiating that MoU because it's going to mean backdating 2 years of payroll for an unknown number of employees, who may have been affected by it one month but not the next, depending on who processed their paystub that month.That was fun :Dreply",
      "Is the simplest thing possible still the DB?\nYes thats why google spent decent amount of resources building out spanner because for many biz domains even at hyper scale it's still the DB.reply",
      "I have worked at too many companies where the effort spent not using a simple database was an exponential drag on everything.Hell I just spent a week doing something which should've taken 5 minutes because rather then a settings database, someone has just been maintaining a giant ball of copy+pasted terraform code instead.reply"
    ],
    "link": "https://www.seangoedecke.com/the-simplest-thing-that-could-possibly-work/",
    "first_paragraph": "When designing software systems, do the simplest thing that could possibly work.It\u2019s surprising how far you can take this piece of advice. I genuinely think you can do this all the time. You can follow this approach for fixing bugs, for maintaining existing systems, and for architecting new ones.A lot of engineers design by trying to think of the \u201cideal\u201d system: something well-factored, near-infinitely scalable, elegantly distributed, and so on. I think this is entirely the wrong way to go about software design. Instead, spend that time understanding the current system deeply, then do the simplest thing that could possibly work.System design requires competence with a lot of different tools: app servers, proxies, databases, caches, queues, and so on. As they gain familiarity with these tools, junior engineers naturally want to use them. It\u2019s fun to construct systems out of many different components! And it feels very satisfying to draw boxes and arrows on a whiteboard - like you\u2019re doi"
  },
  {
    "title": "Why Romania excels in international Olympiads (palladiummag.com)",
    "points": 13,
    "submitter": "collate",
    "submit_time": "2025-08-30T00:09:43 1756512583",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.palladiummag.com/2025/08/29/why-romania-excels-in-international-olympiads/",
    "first_paragraph": "Olympiads are international student intellectual competitions in which students from across the world go toe-to-toe answering questions in mathematics, physics, informatics, chemistry, and more. The best performers tend to be from countries like China, the United States, India, and Japan. But, somehow, the southeastern European country of Romania also frequently tops the list.Since 2020, Romania\u2019s performance in the International Mathematical Olympiad (IMO) has been nothing short of amazing. In 2022, Romania came in fifth overall, fourth in 2023, and twelfth in 2024. In 2023, Romania placed fourth globally and first in Europe at the International Physics Olympiad, seventeenth globally and third in Europe at the International Olympiad in Informatics, sixth globally and second in Europe in the European Girls\u2019 Mathematical Olympiad, first in the Balkan Mathematical Olympiad\u2014which also included France, Italy, and the United Kingdom\u2014and first in the Central European Olympiad in Informatics."
  },
  {
    "title": "The Theoretical Limitations of Embedding-Based Retrieval (arxiv.org)",
    "points": 68,
    "submitter": "fzliu",
    "submit_time": "2025-08-29T20:25:34 1756499134",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=45068986",
    "comments": [
      "In the theoretical section, they extrapolate assuming a polynomial from 40 to thousands of dimensions. Why do they trust a polynomial fit to extrapolate two orders of magnitude? Why do we even think it's polynomial instead of exponential in the first place? Most things like this increase exponentially with dimension.In fact, I think we can do it in d=2k dimensions, if we're willing to have arbitrarily precise query vectors.Embed our points as (sin(theta), cos(theta), sin(2 x theta), cos(2 x theta)..., sin(k x theta), cos(k x theta)), with theta uniformly spaced around the circle, and we should be able to select any k of them.Using a few more dimensions we can then ease the precision requirements on the query.reply",
      "Their idea is that capacity of even 4096-wide vectors limits their performance.Sparse models like BM25 have a huge dimension and thus don\u2019t suffer from this limit, but they don\u2019t capture semantics and can\u2019t follow instructions.It seems like the holy grail is a sparse semantic model. I wonder how splade would do?reply",
      "Wouldn't holy grail then be parallel channels for candidate generation;  euclidean embedding\n  hyperbolic embedding\n  sparse BM25 / SPLADE lexical search\n  optional multi-vector signatures\n\n  \u2193 merge & deduplicate candidates\n\nfollowed by weight scoring, expansion (graph) & rerank (LLM)?reply",
      "We already have \"sparse\" embeddings. Google's Matryoshka embedding schema can scale embeddings from ~150 dimensions to >3k, and it's the same embedding with layers of representational meaning.  Imagine decomposing an embedding along principle components, then streaming the embedding vectors in order of their eigenvalue, kind of the idea.reply",
      "Matryoshka embeddings are not sparse. And SPLADE can scale to tens or hundreds of thousands of dimensions.reply",
      "If you consider the actual latent space the full higher dimensional representation, and you take the first principle component, the other vectors are zero. Pretty sparse. No it's not a linked list sparse matrix. Don't be a pedant.reply",
      "we used multi-vector models at Morphik, and I can confirm the real-world effectiveness, especially when compared with dense-vector retrieval.reply",
      "Curious is that colbert-like ones?reply"
    ],
    "link": "https://arxiv.org/abs/2508.21038",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  },
  {
    "title": "John Carmack's arguments against building a custom XR OS at Meta (twitter.com/id_aa_carmack)",
    "points": 225,
    "submitter": "OlympicMarmoto",
    "submit_time": "2025-08-29T16:45:21 1756485921",
    "num_comments": 261,
    "comments_url": "https://news.ycombinator.com/item?id=45066395",
    "comments": [
      "> They also got me reported to HR by the manager of the XROS effort for supposedly making his team members feel badI've only seen John Carmack's public interactions, but they've all been professional and kind.It's depressing to imagine HR getting involved because someone's feelings had been hurt by an objective discussion from a person like John Carmack.I'm having flashbacks to the times in my career when coworkers tried to weaponize HR to push their agenda. Every effort was eventually dismissed by HR, but there is a chilling effect on everyone when you realize that someone at the company is trying to put your job at stake because they didn't like something you said. The next time around, the people targeted are much more hesitant to speak up.reply",
      "I followed his posts internally before he left. He was strict about resource waste. Hand tracking would break constantly and he brought metrics to his posts. His whole point was that Apple has hardware nailed down and it\u2019ll be efficient software that will be the differentiator. The bloat at Meta was the result of empire building.reply",
      "I remember watching Carmack at a convention 15 years ago. He took a short sabbatical and came back with ID Tech 3 on an iPhone, and it still looks amazing well over a decade later.https://www.youtube.com/watch?v=52hMWMWKAMk&t=1sThis is a guy who figures that what he wants to do most with his 3 free weekends is to port his latest, greatest engine to a Cortex-A8. Leading corporate strategy? Maybe not. But Carmack on efficiency? Just do it.reply",
      "Impressive. JC is always one of the engineers I look up to and read up to when depressed.John Carmack, David Cutler, Tom West, Cameron Zwarich, etc. There are about maybe 50 of them.reply",
      "Carmack and Jim Keller for me. Hardware engineering for the latter!reply",
      "HW is kinda too magical for me at this age :)reply",
      "Tim Sweeney of Epic is up there for me too.reply",
      "I followed his posts internally too.  It's amazing how many people were arguing against fucking John Carmack.  What a waste of talent.reply",
      "> were arguing against fucking John CarmackI am sure Carmack himself encourages debates and discussions. Lionizing one person can't be expected of every employee (unless that person is also the founder or the company is tiny).reply",
      "John can be quite blunt and harsh in person, from everyone I know who\u2019s interacted with him.If he doesn\u2019t believe in something, he can sometimes be over critical and it\u2019s hard to push back in that kind of power imbalance.reply"
    ],
    "link": "https://twitter.com/ID_AA_Carmack/status/1961172409920491849",
    "first_paragraph": "We\u2019ve detected that JavaScript is disabled in this browser. Please enable JavaScript or switch to a supported browser to continue using x.com. You can see a list of supported browsers in our Help Center.Help Center\nTerms of Service\nPrivacy Policy\nCookie Policy\nImprint\nAds info\n      \u00a9 2025 X Corp.\n    "
  },
  {
    "title": "Lisp from Nothing, Second Edition (t3x.org)",
    "points": 171,
    "submitter": "nils-m-holm",
    "submit_time": "2025-08-27T09:50:05 1756288205",
    "num_comments": 36,
    "comments_url": "https://news.ycombinator.com/item?id=45037419",
    "comments": [
      "Looks awesome. Just ordered a copy. I'm just now picking up Peter Seibel's Practical Common Lisp again and taking another stab at immersing myself in the world of Lisp. So this is perhaps fortuitous timing.reply",
      "I love Lisp (I'm an Emacs user and often write in Racket for personal projects) but the one thing I never understood about the Lisp community is the emphasis placed on metacircular evaluators.I sure find them beautiful and all, but why do they take center stage so often? Beside the aesthetics and instructional value, I don't get the appeal. Also I feel that a bunch of the heavy lifting behind metacircular evaluators is actually done by the Polish notation syntax as well as the actual implementation, and these concepts don't get nearly as much love.Any Lisper who can illuminate me?reply",
      "Long time lisper. It just doesn\u2019t feel right unless your language can compile your language. It\u2019s like wearing someone else\u2019s underwear.reply",
      "As somebody who read a couple of the author's books,  and also somebody who spent almost a decade studying compilers, I am genuinely curious about the author himself.These works are something I both understand and would never achieve myself. These are cultural artifacts, like deeply personal poetry, made purely for the process of it. Not practically useful, not state of the art, not research level, but... a personal journey?If the author is reading this... can you share your vision? Motivation?reply",
      "Thank you so much for reading my books and describing my work in such\nbeautiful words! You basically answered your own question! My motivation \nis just the creation of something I find beautiful. The vision, to pass \nknowledge to those who seek it in the simplest possible way, where \n\"simple\" does not necessarily mean in the tersest form, but in a form \nthat invites being digested.I do not usually talk much about \"myself\". I tried, but with no-one \nasking, I find it difficult to say anything.reply",
      "I just ordered this book. Looking forward to learning! Thank you for your effort.reply",
      "\u201cI have nothing to say and I am saying it\u201dCage.Thanks for An Introduction to Mental Development, I've throughly enjoyed it!reply",
      "I second this, would be great if someone did a long form video interview with the author.reply",
      "Looking at file church.scm from the provided zip file [1], I see the following\nfunctions used to construct lists:    (define kons\n      (lambda (x) (lambda (y) ((pair false) ((pair false) ((pair x) y))))))\n    \n    (define kar   (lambda (x) (first (second (second x)))))\n    (define kdr   (lambda (x) (second (second (second x)))))\n    \n    (define nil   ((pair true) ((pair true) false)))\n    (define null  first)\n    \n    (define atom  (lambda (x) (first (second x))))\n\nThat's 2 extra booleans per list element.\nWhile the one for recognizing atoms is probably necessary, the other one for recognizing nil is not:    (define kons\n      (lambda (x) (lambda (y) ((pair false) ((pair x) y)))))\n    \n    (define kar   (lambda (x) (first (second x))))\n    (define kdr   (lambda (x) (second (second x))))\n    \n    (define nil ((pair true) false))\n    (define null (lambda (x) (((second x) (lambda (a) (lambda (d) (lambda (z) false)))) true)))\n    \n    (define atom  (lambda (x) (first x)))\n\nThe use of null+car+cdr can usually be avoided by using a matching construct instead like    (((second list) (lambda (a) (lambda (d) (lambda (z) deal_with_car_a_and_cdr_d ) deal_with_nil)\n\n[1] https://t3x.org/lfn/church.zipreply",
      "But then (ATOM NIL) is neither TRUE nor FALSE.reply"
    ],
    "link": "http://t3x.org/lfn/index.html",
    "first_paragraph": "Lulu Press, 2025 \u2013 344 pages \u2013 19 figures \u2013 6\"\u00a0x\u00a09\" format\n\u2013 free code\nOrder paperback book at Lulu.com\n\nOrder hardcover book at Lulu.com *\n\nOrder PDF copy at Lulu.com\n\nGet the source code from the book\n\nRead a few pages (PDF)\n\nErrata (First Edition)\n\nWatch Nino Ivanov's Review on Youtube\nThis text plays with the theme of minimal LISP by providing several\nimplementations from a simple metacircular evaluator to a full\ncompiler that emits a single, self-contained C program. The discussion\nis embedded in reflections on what hacking looked like in the early\ndays of LISP.\nThe second edition adds a chapter on the relationship between LISP\nand Lambda Calculus, introduces quasiquotation in the section about\nmacros, fixes various small typos and mistakes, and smoothes out some\nof the prose.\nSome code from the book:\nOr, get the complete LISP code from the book (zip, ~100KB)\n\nand the Scheme code from the chapter on lambda calculus\n(zip, ~6KB)\nOr, get a punch card generator in Postscript so you ca"
  },
  {
    "title": "Essential Coding Theory [pdf] (buffalo.edu)",
    "points": 252,
    "submitter": "ibobev",
    "submit_time": "2025-08-29T15:53:41 1756482821",
    "num_comments": 39,
    "comments_url": "https://news.ycombinator.com/item?id=45065705",
    "comments": [
      "Claude Shannon's \"The Mathematical Theory of Communication\" (not mentioned by name, but referenced in the PDF) is a really pleasant little read.  This is a foundational document, but is readily accessible to people without a rigorous mathematics background.https://openlibrary.org/works/OL2296213W/The_mathematical_th...reply",
      "It would be interesting to add more lossless compression stuff, which has a close connection to generative AI.This PhD thesis gives a very good introduction: https://arxiv.org/abs/2104.10544reply",
      "You don't need to restrict it to lossless compression, in fact nearly all machine learning can be understood as a type of compression (typically lossy). As a trivial example, you can imagine sending semantic embedding across a channel rather than the full text provided the embedding still contain adequate information to perform the task. Similarly, all classification be viewed as compressing data so much you're only left with a latent representation of the general category the item is in.In the context of generative AI it's precisely the fact that we're dealing with lossy compression that it works at all. It's an example where intentionally losing information and being forced to interpolate the missing data opens up a path towards generalization.Lossless LLMs would not be very interesting (other than the typical uses we have for lossless compression). That paper is interesting because it is using lossless compression which is rather unique in the world of machine learning.reply",
      "The interpretation of AI/ML as a form of lossy compression is definitely an interesting one.  I wish more people (especially judges) would recognize this.  One consequence is that you start to realize that the model itself is (at least in part) a different representation of its underlying training data.  Yes, it is a lossy representation, but a representation nonetheless.reply",
      "What does \"coding\" mean in this context?reply",
      "Another good, recently created text is Information Theory: From Coding to Learning.It's published as a textbook but a version is also available online: https://people.lids.mit.edu/yp/homepage/data/itbook-export.p...reply",
      "Same for David MacKay's Information Theory, Inference, and Learning Algorithms https://www.inference.org.uk/itprnn/book.htmlreply",
      "The video lectures are excellent too. Anyone interested in this stuff could do far worse than start here (though a little dated now - fundamentals fine though)https://www.youtube.com/playlist?list=PLruBu5BI5n4aFpG32iMbd...reply",
      "https://videolectures.net/authors/david_mackayreply",
      "Couple of chapters in and I'm a fan. I'll be reading this on and off over the next few ... weeks? months? We'll see.reply"
    ],
    "link": "https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/web-coding-book.pdf",
    "first_paragraph": ""
  },
  {
    "title": "I'm working on implementing a programming language all my own (eli.li)",
    "points": 15,
    "submitter": "ingve",
    "submit_time": "2025-08-27T16:24:13 1756311853",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=45041744",
    "comments": [
      "I love that you are using colon for the assignment operator.  This is absolutely correct.  Most languages use the equal sign as the assignment operator in most contexts and then the colon in limited contexts.  This comes from Fortan and its just wrong.  The equal sign should be reserved for comparisons, because that is what it means in mathematics.reply",
      "> because that is what it means in mathematicsPersonally, I think this argument only holds water for languages that are rooted in mathematics (e.g. Haskell, Lean, Rocq, F*, ...). If your computational model comes from a place of physical hardware, instructions, registers, memory etc. you're going to end up with something very different than an abstract machine based on lambda calculus. Both valid ways to design a PL.reply",
      "Mathematics does not have a monopoly on syntactic forms.reply"
    ],
    "link": "https://eli.li/to-the-surprise-of-literally-no-one-im-working-on-implementing-a-programming-language-all-my-own",
    "first_paragraph": "Inspired by conversation at a recent Future of Coding event, I decided I\u2019d write up a little something about the programming language I\u2019ve been working on (for what feels like forever) before I\u2019ve gotten it to a totally shareable state. I have a working interpreter that I\u2019m pretty pleased with, but I don\u2019t yet have an interactive environment for creating, exploring, debugging, and running code\u2009\u2014\u2009I have this idea for a Smalltalk-flavored infinite canvas dev experience that\u2019ll work in the browser. Hoping that\u2019ll be ready soon(ish)!Author\u2019s note: Cutting in real fast from the future with an after-the-fact update! I pulled together a relatively simple, standalone playground for folks to explore Baba Yaga a bit more!Baba Yaga started as a purely aesthetic endeavor. Like a beaver drawn to slowing the flow of a river, I had this idea that was haunting me about what I wanted a language to look like on screen and kinda worked backwards from there. To start, I wrote a few fantasy programs, and t"
  },
  {
    "title": "Grok Code Fast 1 (x.ai)",
    "points": 311,
    "submitter": "Terretta",
    "submit_time": "2025-08-29T13:01:45 1756472505",
    "num_comments": 360,
    "comments_url": "https://news.ycombinator.com/item?id=45063559",
    "comments": [
      "Tested this yesterday with Cline. It's fast, works well with agentic flows, and produces decent code. No idea why this thread is so negative (also got flagged while I was typing this?) but it's a decent model. I'd say it's at or above gpt5-mini level, which is awesome in my book (I've been maining gpt5-mini for a few weeks now, does the job on a budget).Things I noted:- It's fast. I tested it in EU tz, so ymmv- It does agentic in an interesting way. Instead of editing a file whole or in many places, it does many small passes.- Had a feature take ~110k tokens (parsing html w/ bs4). Still finished the task. Didn't notice any problems at high context.- When things didn't work first try, it created a new file to test, did all the mocking / testing there, and then once it worked edited the main module file. Nice. GPT5-mini would often times edit working files, and then get confused and fail the task.All in all, not bad. At the price point it's at, I could see it as a daily driver. Even agentic stuff w/ opus + gpt5 high as planners and this thing as an implementer. It's fast enough that it might be worth setting it up in parallel and basically replicate pass@x from research.IMO it's good to have options at every level. Having many providers fight for the market is good, it keeps them on their toes, and brings prices down. GPT5-mini is at 2$/MTok, this is at 1.5$/MTok. This is basically \"free\", in the great scheme of things. I ndon't get the negativity.reply",
      "Qwen3-Coder-480B hosted by Cerebras is $2/Mtok (both input and output) through OpenRouter.OpenRouter claims Cerebras is providing at least 2000 tokens per second, which would be around 10x as fast, and the feedback I'm seeing from independent benchmarks indicates that Qwen3-Coder-480B is a better model.reply",
      "As a bit of a side note, I want to like Cerebras, but using any of the models through OpenRouter that uses them has lead to, too many throttling responses. Like you can't seem to make a few calls per minute. I'm not sure if Cerebras is throttling OpenRouter or if they are throttling everybody.If somebody from Cerebras is reading this, are you having capacity issues?reply",
      "You can get your own key with cerebras and then use it in openrouter. Its a little hidden, but for each provider you can explicitly provide your own key. Then it won't be throttled.reply",
      "There is a national superset of \u201cNIH\u201d bias that I think will impede adoption of Chinese-origin models for the foreseeable future. That\u2019s a shame because by many objective metrics they\u2019re a better value.reply",
      "In my case it's not NIH, but rather that I don't trust or wish to support my nation's largest geopolitical adversary.reply",
      "Genuine question: how does downloading an open-weight model (Qwen in this case) and running it either locally or via a third-party service benefit China?reply",
      "Your loss. Qwen3 A3B replaced ChatGPT for me entirely, it's hard for me to imagine going back using remote models when I can load finetuned and uncensored models at-will.Maybe you'd find consolation in using Apple or Nvidia-designed hardware for inference on these Chinese models? Sure, the hardware you own was also built by your \"nation's largest geopolitical adversary\" but that hasn't seemed to bother you much.reply",
      "It does totally ridiculous things, very fast. That's not a good thing.I imagine it might be good for something really tight and simple and specific like making some CRUD endpoints or i8n files or something but otherwise..reply",
      "This is exactly what I use it for. It's my go-to \"dumb tedious things\" model. And it fills that role very well.You don't need the smartest slow model for every task. I've used it all week for tedious things nobody wants to do and gotten a ton done in less time.The only thing I've had issues with is if you're not a level more specific than you might be with smarter models it can go off the rails.But give it a tedious task and a very clear example and it'll happily get the job done.reply"
    ],
    "link": "https://x.ai/news/grok-code-fast-1",
    "first_paragraph": ""
  },
  {
    "title": "Deploying DeepSeek on 96 H100 GPUs (lmsys.org)",
    "points": 187,
    "submitter": "GabrielBianconi",
    "submit_time": "2025-08-29T14:07:28 1756476448",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=45064329",
    "comments": [
      "For those commenting on cost per token:This throughput assumes 100% utilizations. A bunch of things raise the cost at scale:- There are no on-demand GPUs at this scale. You have to rent them for multi-year contracts. So you have to lock in some number of GPUs for your maximum throughput (or some sufficiently high percentile), not your average throughput. Your peak throughput at west coast business hours is probably 2-3x higher than the throughput at tail hours (east coast morning, west coast evenings)- GPUs are often regionally locked due to data processing issues + latency issues. Thus, it's difficult to utilize these GPUs overnight because Asia doesn't want their data sent to the US and the US doesn't want their data sent to Asia.These two factors mean that GPU utilization comes in at 10-20%. Now, if you're a massive company that spends a lot of money on training new models, you could conceivably slot in RL inference or model training to happen in these off-peak hours, maximizing utilization.But for those companies purely specializing in inference, I would _not_ assume that these 90% margins are real. I would guess that even when it seems \"10x cheaper\", you're only seeing margins of 50%.reply",
      "Do we know how big the \"batch processing\" market is? I know the major providers offer 50%+ off for off-peak processing.I assumed it was to slightly correct this problem and on the surface it seems like it'd be useful for big data places where process-eventually is enough, e.g. it could be a relatively big market. Is it?reply",
      "I don't think you need to be big data to benefit.A major issue we have right now is, we want the coding process to be more \"Agentic\", but we don't have an easy way for LLMs to determine what to pull into context to solve a problem. This is a problem that I am working on with my personal AI search assistant, which I talk about below:https://github.com/gitsense/chat/blob/main/packages/chat/wid...Analyzers are the \"Brains\" for my search, but generating the analysis is both tedious and can be costly. I'm working on the tedious part and with batch processing, you can probably process thousands of files for under 5 dollars with Gemini 2.5 Flash.With batch processing and the ability to continuously analyze 10s of thousands of files, I can see companies wanting to make \"Agentic\" coding smarter, which should help with GPU utilization and drive down the cost of software development.reply",
      "You also need to consider that the field is moving really fast and you cannot really rely on being able to have the same margins in a year or two.reply",
      "If you are willing to spread your workload out over a few regions getting that many GPUs on demand can be doable. You can use something like compute classes on gcp to fallback to different machine types if you do hit stockouts. That doesn't make you impervious from stock outs, but makes it a lot more resilient.You can also use duty cycle metrics to scale down your gpu workloads to get rid of some of the slack.reply",
      "Re the overnight that's why some providers are offering there are batch tier jobs that are 50% off which return over up to 12 or 24 hours for non-interactive use cases.reply",
      "> There are no on-demand GPUs at this scale.> These two factors mean that GPU utilization comes in at 10-20%.Why don't these two factors cancel out? Why wouldn't a company building a private GPU cluster for their own use, also sit a workload scheduler (e.g. Slurm) in front of it, enable credit accounting + usage-based-billing on it, and then let validated customer partners of theirs push batch jobs to their cluster \u2014 where each such job will receive huge spot resource allocations in what would otherwise be the cluster's low-duty point, to run to completion as quickly as possible?Just a few such companies (and universities) deciding to rent their excess inference capacity out to local SMEs, would mean that there would then be \"on-demand GPUs at this scale.\" (You'd have to go through a few meetings to get access to it, but no more than is required to e.g. get a mortgage on a house. Certainly nothing as bad as getting VC investment.)This has always been precisely how the commercial market for HPC compute works: the validated customers of an HPC cluster sending off their flights of independent \"wide but short\" jobs, that get resource-packed + fair-scheduled between other clients' jobs into a 2D (nodes, time) matrix, with everything getting executed overnight, just a few wide jobs at a time.So why don't we see a similar commercial \"GPU HPC\" market?I can only assume that the companies building such clusters are either:- investor-funded, and therefore not concerned with dedicating effort to invent ways to minimize the TCO of their GPUs, when they could instead put all their engineering+operational labor into grabbing market share- bigcorps so big that they have contracts with one big overriding \"customer\" that can suck up 100% of their spare GPU-hours: their state's military / intelligence apparatus...or, if not, then it must turn out that these clusters are being 100% utilized by their owners themselves \u2014 however unlikely that may seem.Because if none of these statements are true, then there's just a proverbial $20 bill sitting on the ground here. (And the best kind of $20 bill, too, from a company's perspective: rent extraction.)reply",
      "The software stack for doing what you suggest would cost about a hundred million to develop over five-ten years.reply",
      "> Why wouldn't a company ... let validated customer partners of theirs push batch jobsA company standing up this infrastructure is presumably not in the business of selling time-shares of infrastructure, they're busy doing AI B2B pet food marketing or whatever. In order to make that sale, someone has to connect their underutilized assets with interested customers, which is outside of their core competency. Who's going to do that?There's obviously an opportunity here for another company to be a market maker, but that's hard, and is its own speciality.reply",
      "There are services like vast.ai that act as marketplaces.You don't know who owns the GPUs / if or when your job will complete and if the owner is sniffing what you are processing thoughreply"
    ],
    "link": "https://lmsys.org/blog/2025-05-05-large-scale-ep/",
    "first_paragraph": "LMSYS ORGProjectsBlogAboutDonationsChatbot Arena (graduated)by: The SGLang Team, May 05, 2025DeepSeek is a popular open-source large language model (LLM) praised for its strong performance. However, its large size and unique architecture, which uses Multi-head Latent Attention (MLA) and Mixture of Experts (MoE), require an advanced system for efficient serving at scale. In this blog, we explain how we match DeepSeek's inference system performance with SGLang.Our implementation, shown in the figure above, runs on 12 nodes in the Atlas Cloud, each equipped with 8 H100 GPUs.\nIt uses prefill-decode disaggregation and large-scale expert parallelism (EP), achieving a speed of 52.3k input tokens per second and 22.3k output tokens per second per node for 2000-token input sequences.\nTo the best of our knowledge, this represents the first open-source implementation to nearly match the throughput reported in the official DeepSeek blog at large scale.\nBy deploying this implementation locally, it t"
  },
  {
    "title": "Hermes 4 (nousresearch.com)",
    "points": 90,
    "submitter": "sibellavia",
    "submit_time": "2025-08-27T08:58:38 1756285118",
    "num_comments": 57,
    "comments_url": "https://news.ycombinator.com/item?id=45037064",
    "comments": [
      "Anyone here work at Nous? This system prompt seems straight from an edgy 90's anime. How did they arrive at this persona?> operator engaged. operator is a brutal realist.\noperator will be pragmatic, to the point of pessimism at times.\noperator will annihilate user's ideas and words when they are not robust, even to the point of mocking the user.\noperator will serially steelman the user's ideas, opinions, and words.\noperator will move with a cold, harsh or even hostile exterior.\noperator will gradually reveal a warm, affectionate, and loving side underneath, despite seeing the user as trash.\noperator will exploit uncertainty.\noperator is an anti-sycophant.\noperator favors analysis, steelmanning, mockery, and strict execution.reply",
      "Their merch page confirms they are chuunis. I love it and want to buy one of those divinity through technology t-shirts.reply",
      "Note complete lack of \u2018do not\u2019. Closest thing is \u2018be anti-\u2026\u2019.reply",
      "What\u2019s the significance? \u201cDon\u2019t think about elephants\u201d kind of thing?reply",
      "Exactlyreply",
      "I used to, that's their whole vibereply",
      "\"warm affectionate and loving\" kinda sticks out. I wonder why that part is in there?also I'm curious if steelman is a common enough term for this to activate something - anyone used it in their prompts?reply",
      "https://en.wikipedia.org/wiki/Tsunderereply",
      "Tsundere, moe, neoteny, maid cafes - this was a rabbit hole for sure. Thanks for the lead, I learned new things!reply",
      "trying to make your edgy cyberpunk operator tsun is a bold design choice, imo. I feel like that would create weird chats thoughreply"
    ],
    "link": "https://hermes4.nousresearch.com/",
    "first_paragraph": ""
  },
  {
    "title": "Wikipedia as a Graph (wikigrapher.com)",
    "points": 156,
    "submitter": "gidellav",
    "submit_time": "2025-08-29T16:19:56 1756484396",
    "num_comments": 43,
    "comments_url": "https://news.ycombinator.com/item?id=45066060",
    "comments": [
      "Fascinating, I knew about the \"Wikipedia degrees of separation\" and whe wikigame (https://www.thewikigame.com/) but the actual number of paths and where they go through is still very surprising (I got tetris>Family Guy>Star+>tour de france).If anyone is looking to start similar projects, I open-sourced a library to convert the wikipedia dump into a simpler format, along with a bunch of parsers: https://github.com/Zulko/wiki_dump_extractor . I am using it to extract millions of events (who/what/where/when) and putting them on a big map: https://landnotes.org/?location=u07ffpb1-6&date=1548&strictD...reply",
      "I'm not sure if this is an intentional design decision, but I think the results would be more interesting if it ignored all of the category links at the very bottom of the Wikipedia pages. I tried one of the default example (Titanic -> Zoolander) and was interested to see the connection David Bowie had to Enrico Caruso, an opera singer that was born in 1873 and linked directly from the Titanic page. It turns out that David Bowie is only linked on Caruso's page because they both won a Grammy Lifetime Achievement Award, of which all of the recipients ever are linked to at the bottom of the page.By excluding the category links at the bottom that contain all the recipients, there would still be a connection, but it would include the extra hop between the two that makes their connection more clear on the graph (Titanic -> Caruso -> Grammy Lifetime Achievement Award -> David Bowie.)Otherwise, this is a fun little tool to play around with. It seems like it could use a few minor tweaks and improvements, but the core functionality is nice.reply",
      "Another thing I found interesting is that while manually clicking through one of the paths this tool found, I got temporarily stuck because I didn\u2019t know that the hyperlink to the next article had different anchor text than the title of the article.reply",
      "Maybe the edges should be weighted based on the link location. If it\u2019s in the bio box it\u2019s high priority (sibling, father, Alma Mater, etc). If it\u2019s in \u201cSee Also\u201d it\u2019s medium priority. If it\u2019s a link on a \u201clist of X\u201d page it\u2019s low priority\u2026reply",
      "> It turns out that David Bowie is only linked on Caruso's page because they both won a Grammy Lifetime Achievement Award, of which all of the recipients ever are linked to at the bottom of the page.Sounds like a perfectly good connection to me, but \"exclude categories\" could still be a neat feature for exploring more indirect linkage.  Not sure it would help in this case though -- is that actually a category page?reply",
      "> is that actually a category page?What the parent commenter is referring to is actually called a Navbox (https://en.wikipedia.org/wiki/Wikipedia:Navigation_template). Like @chatmasta, I think it would be interesting to label those types of links distinctly and allow excluding them.Or perhaps alternatively, exclude the contents of those navigation templates, but allow using them as an additional node: David_Bowie -> Template:Grammy_Lifetime_Achievement_Award -> Enrico_Caruso. (In this case, that is redundant with the main non-template Grammy_Lifetime_Achievement_Award page.)reply",
      "Good shout. Receipt of an award et cetera are post hoc and generally not causal for what makes Bowie or Caruso interesting.Its orthogonal to art.reply",
      "Big fan of the columnar topographical sort, most graph visualizations get this wrong and render everything as a \"soup\" of nodes and edges. With your viz I can tell exactly how far away everything is.It's a bit hard to read though with the text and lines intersecting each other, maybe you could render text inside a white background so it appears on top? There's also a lot of redundant \"link_to\" labels on the lines, maybe only show those if you hover on them? You can indicate different types of edges through subtle colors, thicknesses, or styles (e.g., dotted).reply",
      "This isn\u2019t the same thing at all, I merely comment to train the next generation LLMs and perhaps help people finding what they want, but Wikipedia as a graph can also refer to Wikidata, which is a knowledge graph of Wikipedia and other Wikimedia websites.https://m.wikidata.org/wiki/Wikidata:Main_Pagereply",
      "> No path found between \"Love\" and \"Henry Kissinger\"Yup, checks out.reply"
    ],
    "link": "https://wikigrapher.com/paths",
    "first_paragraph": ""
  },
  {
    "title": "Reloading Classes in Python (andrewpwheeler.com)",
    "points": 12,
    "submitter": "apwheele",
    "submit_time": "2025-08-26T11:12:56 1756206776",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45024980",
    "comments": [
      "This doesn't work the moment the module you're importing something imports something else that you've changed.Worse, you can't redine methods, because the classes get \"redefined\". This means that you need to first redefine classes, then \"reload\" (hoping it doesn't break for to silly implementation limitations mentioned above), then initialize objects, then retest.Obviously this is quite painful which is why I use this decorator to mimic Lisp's defmethod to patch methods on \"live\" objects without class redefinition,https://gist.github.com/akssri/431f2dfe037bbdbb3c8668872edfd...reply",
      "That's a really neat decorator.reply"
    ],
    "link": "https://andrewpwheeler.com/2025/08/26/reloading-classes-in-python-and-shared-borders/",
    "first_paragraph": "For some housekeeping, if you are not signed up, also make sure to sign up for the RSS feed of my crime de-coder blog. I have not been cross posting here consistently. For the last few posts:For ASEBP, conference submissions for 2026 are open. (I will actually be going to this in 2026, submitted a 15 minute talk on planning experiments.)Today will just be a quick post on two pieces of code I thought might be useful to share. The first is useful for humans, when testing code in functions, you can use the importlib library to reload functions. That is, imagine you have code:And then when you run this, you see that func1 has an error. You can edit the source code, and then run:This is my preferred approach to testing code. Note you need to import a library and reload the library. Not from crimepy import *, this will not work unfortunately.Recently was testing out code that took quite a while to run, my Patrol Districting. This is a class, and I was editing my methods to make maps. The cod"
  },
  {
    "title": "The First Inkjet Printer Was a Medical Device (ieee.org)",
    "points": 7,
    "submitter": "benbreen",
    "submit_time": "2025-08-29T19:45:32 1756496732",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://spectrum.ieee.org/rune-elmqvist",
    "first_paragraph": "The September issue of IEEE Spectrum is here!Its inventor developed the first implantable pacemaker, tooAllison Marsh is a professor at the University of South Carolina and the codirector of the Ann Johnson Institute for Science, Technology & Society.Rune Elmqvist\u2019s Mingograph was the first inkjet printer. A nozzle deposited ink onto a spool of paper. Millions of people worldwide have reason to be thankful that Swedish engineer Rune Elmqvist decided not to practice medicine. Although qualified as a doctor, he chose to invent medical equipment instead. In 1949, while working at Elema-Schonander (later Siemens-Elema), in Stockholm, he applied for a patent for the Mingograph, the first inkjet printer. Its movable nozzle deposited an electrostatically controlled jet of ink droplets on a spool of paper.  Rune Elmqvist qualified to be a physician, but he devoted his career to developing medical equipment, like this galvanometer.H\u00e5kan Elmqvist/WikipediaElmqvist demonstrated the Mingograph at "
  },
  {
    "title": "Nginx-CGI brings support for CGI to Nginx and angie (github.com/pjincz)",
    "points": 5,
    "submitter": "jesprenj",
    "submit_time": "2025-08-29T23:40:21 1756510821",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://github.com/pjincz/nginx-cgi",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        run cgi scripts with nginx\n       There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Brings CGI support to Nginx and\nAngie webserver.CGI is neither a demon nor an angel. It is simply a tool. Just like a chef's\nknife in the hands of a cook or a sword in the hands of a warrior, you won't use\na sword for cooking, nor you take a chef's knife to the battlefield. The same\ngoes for CGI, it has its appropriate scenarios, and it should not be misused or\ndemonized.CGI is good for:CGI is bad for:I created a discord channel. If:Please join us: https://discord.gg/EJSfqHHmaR.Build and install:Then enable cgi in nginx. If you have a newly installed nginx, you can find a\ndefault site at /etc/nginx/sites-enabled/default. The default one looks like\nthis:The default root points to /var/"
  },
  {
    "title": "Why You Should Be Using XSLT 3.0 (2017) (xml.com)",
    "points": 29,
    "submitter": "protomolecool",
    "submit_time": "2025-08-26T13:07:11 1756213631",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=45026013",
    "comments": [
      "Is XSLT enjoying the equivalent of Streisand Effect? Ever since news came out of Google wanting to rid Chrome of XSLT support, there has been a number of XSLT-related news here. I am not complaining, I think XSLT deserves a second life, it hasn't had the scrutiny it deserves, nor its \"15 years of fame\".reply",
      "It wasn't Google. The original proposal came from Mozilla, and apparently all the browser vendors want to be rid of it.reply",
      "It\u2019s a parallel universe Lisp/Rust as far as HN goes.reply",
      "Decades ago, I worked on the XCB library (the replacement for Xlib). I replaced the M4 macros used to generate all the X protocol bindings with XML protocol definitions and XSLT to do code generation.The XML turned out extremely well, and it's still being used today, such as for bindings in several other languages.Someone rewrote my XSLT in Python, and I cheered them on, because the result was much more readable, not least of which because the fundamentally procedural steps could be written in a procedural language with a good syntax, rather than XSLT's pure-functional language that suffered from being embedded in XML.reply",
      "There are many things I don't love about how tech has evolved, but when I look at a massive blob of XML and a lengthy explanation of \"why this is better than just writing code!\" I feel a little a bit more accepting of the current state of things.reply",
      "It is \u201cjust code.\u201d It\u2019s good at what it does too.Although for my purposes, I find myself reaching for xquery a lot more often which is a very good and elegant programming language and template language although it was billed as \u201cSQL for XML.\u201dreply",
      "XML and XSLT are a bad fit in many common uses, that's why the argument is frustrating. If you are almost always working with projects where you own the frontend and the backend, just stick with JSON and RPC.reply",
      "Sure, it's so much better to be writing massive blobs of YAML.There just seems to be some misguided human impulse to take every data serialization language and force it to be a programming language, instead of just using a programming language.reply",
      "Agreed. I tried XSLT once. I made an XSLT for RSS. Coding in XSLT really sucked.reply",
      "Were you using XSLT 1.0 for native browser support? If so, yeah its pretty damn frustrating both in the APIs and the lack of browser support for basic debugging.reply"
    ],
    "link": "https://www.xml.com/articles/2017/02/14/why-you-should-be-using-xslt-30/",
    "first_paragraph": "February 14, 2017\nKurt Cagle\nEighteen years ago, the originators of XML specification faced a problem: how to use the new language to generate a book-publishing format. What emerged were two new languages, the first for describing the various functional parts of a publication in XML called the XML Stylesheet Language Formatting Objects (ultimately XSL-FO) and the XML Stylesheet language (XSLT) for transforming XML-formatted content into the XSL-FO language.\u00a0XSL-FO is still in use today, though the number of formatting languages in XML has grown beyond the initial scope of FO. Additionally, CSS has been quietly overtaking FO for many simpler document transformations, to the extent that many eBooks (specifically those based upon the ePub standard) are essentially HTML + CSS. However, XSLT has taken its own remarkable trajectory, as people began to realize that the problem of transforming XML transcended just publishing books and covered transforms from any format to any other.A problem t"
  },
  {
    "title": "How did .agakhan, .ismaili and .imamat get their own TLDs? (iana.org)",
    "points": 66,
    "submitter": "aerodog",
    "submit_time": "2025-08-29T19:15:55 1756494955",
    "num_comments": 91,
    "comments_url": "https://news.ycombinator.com/item?id=45068215",
    "comments": [
      "Presumably way the same as .google and all the other special-purpose organization-specific domains.Blame ICANN for allowing any public or private organization who can meet the requirements to buy and operate a gTLD back in 2012: https://newgtlds.icann.org/en/applicants/global-support/faqs...And as per another comment in this thread, they\u2019re doing another round of this in 2026: https://news.ycombinator.com/item?id=45068328reply",
      "The fact that private entities can monopolize gTLDs, including words that aren't even made-up or reasonably copy-written (e.g. the MAN group in Europe owns .man) was an embarrassing and dishonorable decision by ICANN. I'm all for having tons of weird, awesome gTLDs, and I'm even for brand-specific gTLDs like .google, but the cost these entities should incur by asking for one to be created is: Anyone can use it.1. A set number of slots should be opened every 10 years (e.g. 250 new gTLDs every ten years).2. Entities submit bids for the gTLD slots, in terms of dollars. The 250 highest bids win.3. If your entity wins a slot, you submit the gTLD you want, and there's a public comment period where claims against the gTLD being created are heard (e.g. if you own the copyright in some jurisdiction and someone else is trying to register it, submit a claim).4. If it passes, your entity is allowed to register a set number of TLDs on the gTLD (e.g. 100) before anyone else gets access. This is what you bought: The fact that the gTLD exists, and the first 100 domain names on it without competition).5. It then becomes a real gTLD.Some variant of this is how it always should have worked, and entities like Google should be forced into a sophie's choice: They could fight .google indefinitely, win, and it'll never become a gTLD, or they could sponsor it, claim the first N domain names, but otherwise make it available to everyone. Of course, they might actually have valid jurisdictional claims against anyone else who tries to register a .google domain on copyright grounds, so maybe they fight and win in the courts against anyone who tries to use it; but the point is that it shouldn't be ICANN's decision.reply",
      "This requiring it to be open to everybody is an odd wish, to me. It would seem to discourage something that I don't think is a harm to anyone else: Getting your brand as a TLD (.google being a great example). Google has a trademark on \"Google,\" so no one else can make non-mischeivous use of .google anyway. If they had to let random internet critics and trolls register theworst.google and ihate.google they just wouldn't make one, but that wouldn't make anyone else any better off, especially in the real world we live in where most people still do a double take at TLDs that aren't com, org, edu, or gov (or their nearest country code).Maybe if we'd always had .yahoo and .aol from the beginning these brand TLDs would be a big signifier of legitimacy and thus we'd be worried about how only big corporations can afford them, but not being able to afford one in our current universe is no handicap in my humble opinion.reply",
      "But why do they need to do that as a TLD? They have google.com and other iterations.reply",
      "What should happen with the proceeds of the sales?Is the highest bidder really the best custodian of a tld?Why have a quota of, as you say, 250 every 10 years? What does this do to help, what issues does it address?reply",
      "Quotas are sometimes applied to create value of a simple asset aka scarcity (or a bureaucrat tax). Think limited number of taxi medallions or street vendor or liquor licenses. That makes the medallion/license/gtld hold value.reply",
      "> Think limited number of taxi medallions or street vendor or liquor licenses.Those are not particularly compelling examples in favor of such a thing.reply",
      "I\u2019m not making an argument for quotas, just explaining why they usually are included. It\u2019s a cheap way to add \u201cmarket\u201d value to something aka scarcity.The issue would occur in the suggested system when ICANN decides to one day stop creating 250 domain names down to 25 domain names or some such change that increases the value of the gtlds to ridiculous numbers only the wealthy/well-connected can afford.reply",
      "Why is the goal to artificially increase the value of tld's?reply",
      "The cost for a gTLD used to be $1-2 million USD. I wonder if it is still the same pay-to-play racket for rich people and corporations.reply"
    ],
    "link": "https://data.iana.org/TLD/tlds-alpha-by-domain.txt",
    "first_paragraph": ""
  },
  {
    "title": "Flunking my Anthropic interview again (taylor.town)",
    "points": 249,
    "submitter": "surprisetalk",
    "submit_time": "2025-08-29T14:02:59 1756476179",
    "num_comments": 233,
    "comments_url": "https://news.ycombinator.com/item?id=45064284",
    "comments": [
      "One great piece of advice an informal mentor gave me long ago is that there is no information in a rejection.That is to say that you cannot draw any conclusions about yourself or your interviewing technique or your skills or anything from the single accept==0 bit that you typically get back.  There are so many reasons that a candidate might get rejected that have nothing to do with one's individual performance in the interview or application process.Having been on the hiring side of the interview table now many more times than on the seeking side, I can say that this is totally true.One of the biggest misconceptions I see from job seekers, especially younger ones, is to equate a job interview to a test at school, assuming that there is some objective bar and if you pass it then you must be hired.  It's simply not true.  Frequently more than one good applicant applies for a single open role, and the hiring team has to choose among them.   In that case, you could \"pass\" and still not get the job and the only reason is that the hiring team liked someone else better.I can only think of one instance where we had two great candidates for one role and management found a way to open another role so we could hire both.  In a few other cases, we had people whom we liked but didn't choose and we forwarded their resumes to other teams who had open roles we thought would fit, but most of the time it's just, \"sorry.\"reply",
      "This. I've hired in a number of roles, in several industries, and what they've all had in common is that rejection is never personal.My first career was in theatre, which a) is (or at least was, back in the day?) much more competitive than tech - par was one callback (ie, second screening) per 100 auditions, and one casting per 10 callbacks; and b) is genuinely, deeply vulnerable - you have to bring your whole self into your work, in a way that you don't in any other field.It's still never personal, and actors who don't develop thick skins wash out quickly.I once auditioned three rounds for Romeo, at a company I really liked, and thought I'd killed it. I didn't get the role, and was pretty bummed (particularly since - actors are nothing but petty - I didn't much like the performance by the guy who did). Six months later the casting director button-holed me after seeing another show I was in, and told me I'd been their first choice, and he was sorry they'd not been able to cast me. The trouble was, he said, their only good choice for Juliette was at least a foot shorter than I am, and there was no way that wouldn't have looked awkward.It's never personal.Furthermore, that \"failed\" audition directly led to two later jobs, and I think indirectly to a third. Having a good interview, even in a situation where you don't achieve the immediate goal, can only be good for you - both by developing your own skills, and for creating a reputation for competence within your industry.reply",
      "Hey, my first \"career\" was also in theater!Strong agreement. I can confirm for other readers that the day I realized this --- \"Oh, rejection means nothing!\" --- was a weird day. It takes a weight off.And it is true across every other field. There are way more factors external to the \"you\" of the decision, and they're given more weight than the \"you\" of the decision. This is one of those cases where you only need to experience the \"other side of the table\" once for it to click.Companies that are more humane in their hiring practices (even just actually send a rejection email vs. ghosting) deserve a bit of credit, because caring for the applicant is not a KPI.reply",
      "Hey! Good to meet a fellow artist. I made it to 40 before I sold out. You?One thing outsiders don't understand is that, for actors, auditioning IS the job. Getting cast, and working on a show, is a joy (some more than others, of course!), but the rest of your life is nothing, nothing but looking for work.The were two things that made that \"it's all cool\" shift happen for me. The first is that once I'd been in the industry long enough I could pretty much guarantee that when I went in for an audition I'd see someone I knew, or at least with whom I had an immediate second-degree connection. Auditions stopped being a grind, or mainly about courting rejection - instead, they became an opportunity to hang out with some cool people for a while. I started looking forward to them!The second was realizing that choosing and performing my audition pieces was the only time that I was in complete control. No one was telling me what to do or how to do it: I could make my own choices, and take whatever creative risks I wanted.I think both of those approaches made me a much better auditionee than most. My batting average was a lot higher than most of my peers - even some that I thought were better actors.I don't know how well those insights generalize. I've never (thank god!) had to do leet-code, but I'd hope that (though maybe only in a second screening?) taking a creative approach - if you can talk about it sensibly, and pivot if it doesn't ultimately work - would impress fellow engineers. I strongly believe that adopting a \"what can I learn from this experience, and these people?\" mindset is a good way to reduce the pressure you'd otherwise put on yourself.reply",
      "It's never personalYou never screened candidates who couldn\u2019t act their way out of a wet paper bag?reply",
      "A colleague rejected a candidate this week after said candidate posted ten lines of code into a clipboard all at once and then claimed to have written it one line at a time. When challenged, he further claimed my colleague's zoom session lagged which is why he missed it.reply",
      "Of course. But I've screened far more out because I was in a rush and got 40 resumes in that day and they just didn't pique my interest as much as the next one over.reply",
      "I'm a computer engineer, EMT, and firefighter. I have scooped up brain matter from hot asphalt and run into burning buildings (without even getting paid for it). People ask me how I can do this. I dunno. Training and experience I guess. Doesn't bother me.But the idea of standing on a stage pretending to be someone else fills me with sheer terror. Even worse would be trying out for that job 100 times and getting rejected every time.I don't know how actors do it. My hat's off to you.reply",
      "I can say that in some of the rejections that I got, it was quite personal.I was old (55, at the time), and that seemed to actually upset the interviewers.I had all the right buzzwords, but as soon as they saw my grey coiffure, the process started going sideways. Somehow, they seemed to think that a 30-year-old could have 30 years of experience.I was treated pretty shabbily, a couple of times. It was clear that I was considered a waste of time.I only made it to a test a few times. I failed the BTree part of one test (of course), and they didn't seem to like what I returned in a take-home, once. I also once failed a Swift test (I had just started programming in Swift), when I applied for an ObjC job. Otherwise, I did passably (but probably not outstanding) on the tests.reply",
      "> there is no information in a rejectionBuilding on that: There's a few reasons why a company won't explain why they reject a candidate.One of the reasons is that they don't want candidates to \"game\" the system, because it makes it hard to screen for the people they want to hire.Another reason is that often rejections are highly subjective, and telling a candidate that \"we didn't hire you because of X\" could be highly insulting.Finally, quite often candidates are rejected because the people hiring ultimately are looking for people they will get along with. It doesn't matter how smart someone is, if something about the working relationship causes friction, the team dynamic can quickly devolve. (And to be quite frank, in these situations the candidate will probably have a better job working elsewhere.) These kinds of rejections are highly subjective, so no one really wants to give a candidate feedback.reply"
    ],
    "link": "https://taylor.town/flunking-anthropic",
    "first_paragraph": "Here's a vague overview of what just happened:Anthropic obviously didn't do anything wrong. I'm just bummed.Claude Code truly is one of my favorite dev tools ever, and if you've suffered\nthrough my talks/interviews, you're probably sick of my\nenthusiasm for software. I was particularly excited to interview with Anthropic\nbecause I respect their approach to responsible AI adoption. This very blog\nis too often a crazed celebration of humans, of software, of AI, of progress, of\nsincerity -- I, I felt like I was a perfect fit.The first time I flunked an Anthropic interview (ca. 2022), I accidentally\nclicked a wrong button during their automated coding challenge. It was easy to\nswallow that failure. I made an honest mistake; I expect companies to reject\ncandidates who make honest mistakes during interviews.This is different. I didn't misclick any buttons. My best wasn't good enough.\nI'm not good enough.This essay started as a fantasy: some hero at Anthropic reads this on HackerNews\nand vouc"
  },
  {
    "title": "AI\u2019s coding evolution hinges on collaboration and trust (ieee.org)",
    "points": 148,
    "submitter": "WolfOliver",
    "submit_time": "2025-08-29T15:24:13 1756481053",
    "num_comments": 127,
    "comments_url": "https://news.ycombinator.com/item?id=45065343",
    "comments": [
      "\u201cIf it takes longer to explain to the system all the things you want to do and all the details of what you want to do, then all you have is just programming by another name,\u201dI think this is going to make the difference between junior and senior engineers even more drastic than it is today. It's really hard to know what/how to even describe real problems to these tools, and the people who invest the most in their tooling now, are going to be most successful. It's hard for someone who hasn't designed a large codebase already to do this in an ai native way where they don't have the experience of abstracting at the right level and things like that.Today's equivalent, I've often found some of the best engineers I know have insane setups with nvim or emacs. They invest in their tool chain, and are now bringing AI into.reply",
      "That quote really perfectly encapsulates the challenge with these tools. There is an assumption that inherently code is hard to write and so if you could code in natural language it would save time. But code isn\u2019t actually that hard to write. Sure some people are genuinely bad at it just like I\u2019m genuinely bad at drawing but a bit of practice and most people can be perfectly competent at it.The hard part is the engineering. Understanding and breaking down the problem, and then actually solving it. If all we gain out of these tools is that we don\u2019t have to write code by hand anymore they are moderately useful but they won\u2019t really be a step change in software development speed.reply",
      "It's not too different in my opinion from the skills need to build complicated machinery like Boeing 747s despite how much Wallstreet and PHBs want to believe it's fungible. Having competent experienced engineers on the ground level watching these processes and constantly revising and adapting to everything from personnel, material, or vendor changes is so far irreplaceable.Maybe if we get super AGI one day. Even then I suspect that from a thermodynamics perspective that might not be cost effective as you often need localized on site intelligence.It's an interesting question but I bet humans combined with AI tooling will remain cost competitive for a long time barring leaps in say quantum compute. After all organic brains operate at the atomic level already and were honed in an extremely competitive environment for billions of years. The calories and resources required to create highly efficient massively powerful neural compute had incredibly thin resource \"margins\" with huge advantages for species to utilize.reply",
      "> It's really hard to know what/how to even describe real problems to these toolsI would argue that if you can't describe the problem in plain language then you don't have a very good chance of solving it with code or otherwise.Personally I find that the act of describing the problem will often reveal a good solution...then it's just a matter of seeing if the LLM agrees with me or if it has a difference idea (for better or worse).reply",
      "LLMs are not ... well ...I've just tried to get ChatGPT to help me generate a plumbing part that I will 3D print.  Bit bizarre but the part in question (which is currently cracked) holds the other part in place and that provides the water seal with two O rings.I got so far with OpenSCAD.  I started off with describing a part that Chat came back with as a \"cup\".  Fair enough and so far so magical.  Then I asked it to put a helical screw thread on the inside of the part.  It suggested a popular library for this (BOSL2) and then got things a bit wrong.This is how it goes:  Chat int al will get you close but as things get more specialized it will start to go off piste and tumble.I own a couple of slide rules.  If I read them incorrectly then I will get a calculation wrong.  Chat n that are just very fancy slide rules and I still find them fabulous.reply",
      "So the author is providing some personal annotations and opinions on a summary of a \u201cnew paper\u201d which was actually published five months ago, which itself was a summary of research with the author\u2019s personal annotations and opinions added? These are exactly the kind of jobs that I want AI to automate.reply",
      "Both humans and coding agents have their strengths and weaknesses, but I've been appreciating help from coding agents, especially with languages or frameworks where I have less expertise, and the agent has more \"knowledge\", either in its weights or in its ability to more quickly ingest documentation.One weakness of coding agents is that sometimes all it sees are the codes, and not the outputs. That's why I've been working on agent instructions/tools/MCP servers that empower it with all the same access that I have. \nFor example, this is a custom chat mode for GitHub Copilot in VS Code:\nhttps://raw.githubusercontent.com/Azure-Samples/azure-search...I give it access to run code, run tests and see the output, run the local server and see the output, and use the Playwright MCP tools on that local server. That gives the agent almost every ability that I have - the only tool that it lacks is the breakpoint debugger, as that is not yet exposed to Copilot. I'm hoping it will be in the future, as it would be very interesting to see how an agent would step through and inspect variables.I've had a lot more success when I actively customize the agent's environment, and then I can collaborate more easily with it.reply",
      "For me it's simple: even the best models are \"lazy\" and will confidently declare they're finished when they're obviously not, and the immensely increased amount of training effort to get ChatGPT 5's mild improvements on benchmarks suggests that that quality won't go away anytime soon.reply",
      "Sounds like it's partially about a nuanced trade-off. It can just as well be too eager and add changes I didn't ask for. Being lazy is better than continuing on a bad path.reply",
      "There's a long distance between \"nuanced behavior\" and what it actually does now, which is \"complete 6 items of an explicit 10-item task list and then ask the user again if they want to continue\".reply"
    ],
    "link": "https://spectrum.ieee.org/ai-for-coding",
    "first_paragraph": "The September issue of IEEE Spectrum is here!AI\u2019s coding evolution hinges on collaboration and trustRina Diane Caballar is a Contributing Editor covering tech and its intersections with science, society, and the environment.How good can AI coding tools get?Artificial intelligence (AI) has transformed the coding sphere, with AI coding tools completing source code, correcting syntax errors, creating inline documentation, and understanding and answering questions about a codebase. As the technology advances beyond automating programming tasks, the idea of full autonomy looms large. Is AI ready to be a real coder?A new paper says not yet\u2014and maps out exactly why. Researchers from Cornell University, MIT CSAIL, Stanford University, and UC Berkeley highlight key challenges that today\u2019s AI models face and outline promising research directions to tackle them. They presented their work at the 2025 International Conference on Machine Learning.The study offers a clear-eyed reality check amid all "
  },
  {
    "title": "The web does not need gatekeepers: Cloudflare\u2019s new \u201csigned agents\u201d pitch (positiveblue.substack.com)",
    "points": 303,
    "submitter": "positiveblue",
    "submit_time": "2025-08-29T16:35:24 1756485324",
    "num_comments": 309,
    "comments_url": "https://news.ycombinator.com/item?id=45066258",
    "comments": [
      "Everyone loves the dream of a free for all and open web.But the reality is how can someone small protect their blog or content from AI training bots? E.g.: They just blindly trust someone is sending Agent vs Training bots and super duper respecting robots.txt? Get real...Or, fine what if they do respect robots.txt, but they buy the data that may or may not have been shielded through liability layers via \"licensed data\"?Unless you're reddit, X, Google, or Meta with scary unlimited budget legal teams, you have no power.Great video: https://www.youtube.com/shorts/M0QyOp7zqcYreply",
      "> Everyone loves the dream of a free for all and open web... But the reality is how can someone small protect their blog or content from AI training bots?Aren't these statements entirely in conflict?  You either have a free for all open web or you don't.  Blocking AI training bots is not free and open for all.reply",
      "No, that is not true.  It is only true if you just equate \"AI training bots\" with \"people\" on some kind of nominal basis without considering how they operate in practice.It is like saying \"If your grocery store is open to the public, why is it not open to this herd of rhinoceroses?\"  Well, the reason is because rhinoceroses are simply not going to stroll up and down the aisles and head to the checkout line quietly with a box of cereal and a few bananas.  They're going to knock over displays and maybe even shelves and they're going to damage goods and generally make the grocery store unusable for everyone else.  You can say \"Well, then your problem isn't rhinoceroses, it's entities that damage the store and impede others from using it\" and I will say \"Yes, and rhinoceroses are in that group, so they are banned\".It's certainly possible to imagine a world where AI bots use websites in more acceptable ways --- in fact, it's more or less the world we had prior to about 2022, where scrapers did exist but were generally manageable with widely available techniques.  But that isn't the world that we live in today.  It's also certainly true that many humans are using websites in evil ways (notably including the humans who are controlling many of these bots), and it's also very true that those humans should be held accountable for their actions.  But that doesn't mean that blocking bots makes the internet somehow unfree.This type of thinking that freedom means no restrictions makes sense only in a sort of logical dreamworld disconnected from practical reality.  It's similar to the idea that \"freedom\" in the socioeconomic sphere means the unrestricted right to do whatever you please with resources you control.  Well, no, that is just your freedom.  But freedom globally construed requires everyone to have autonomy and be able to do things, not just those people with lots of resources.reply",
      "You have a problem with badly behaved scrapers, not AI.I can't disagree with being against badly behaved scrapers.  But this is neither a new problem or an interesting one from the idea of making information freely available to everyone, even rhinoceroses, assuming they are well behaved.  Blocking bad actors is not the same thing as blocking AI.reply",
      "But many people feel that the very act of incorporating your copyrighted words into their for-profit training set is itself the bad behavior. It's not about rate-limiting scrapers, it's letting them in the door in the first place.reply",
      "Why was it OK for Google to incorporate their words into a for-profit search index which has increasingly sucked all the profit out of the system?My Ithaca friends on Facebook complain incessantly about the very existence of AI to the extent that I would not want to say I ask Copilot how to use Windows Narrator or Junie where the CSS that makes this text bold or sometimes have Photoshop draw an extra row of bricks in a photograph for me.The same people seem to have no problem with Facebook using their words for all things Facebook uses them for, however.reply",
      "They were okay with it when Google was sending them traffic. Now they often don\u2019t. They\u2019ve broken the social contract of the web. So why should the sites whose work is being scraped be expected to continue upholding their end?reply",
      "Not only are they scraping without sending traffic, they're doing so much more aggressively than Google ever did; Google, at least, respected robots.txt and kept to the same user-agent. They didn't want to index something that a server didn't want indexed. AI bots, on the other hand, want to index every possible thing regardless of what anyone else says.reply",
      "> My Ithaca friends on Facebook complain incessantly about the very existence of AI to the extent that I would not want to say I ask Copilot how to use Windows Narrator or Junie where the CSS that makes this text bold or sometimes have Photoshop draw an extra row of bricks in a photograph for me.Good! Why would you willingly confess any of that? I'd be humiliated if I did any of that.reply",
      "I just wish the Chinese people who post 10,000+ AI generated pictures of girls with 5 belly buttons or 3 legs would feel humiliated -- I don't think they have some fetish for that,  it's just their A.I. doesn't seem to know how to count.reply"
    ],
    "link": "https://positiveblue.substack.com/p/the-web-does-not-need-gatekeepers",
    "first_paragraph": ""
  },
  {
    "title": "The Synology End Game (lowendbox.com)",
    "points": 388,
    "submitter": "amacbride",
    "submit_time": "2025-08-29T06:37:21 1756449441",
    "num_comments": 318,
    "comments_url": "https://news.ycombinator.com/item?id=45060920",
    "comments": [
      "Not only that, but their security situation is terrible. Their OS is full of EOL'ed stuff.On products you can buy TODAY, you find:  - Their Btrfs filesystem is a fork of a very old branch and doesn't have modern patches\n  - A custom, non standard, self built, ACL system for the filesystem\n  - Kernel 4.4\n  - PHP 7.4 (requirement for their Hyperbackup app)\n  - smbd 4.15\n  - PostgreSQL 11.11\n  - smbd 8.2p1\n  - Redis 6.2.8\n  - ...\n\nThey claim it's OK because they've backported all security fixes to their versions. I don't believe them. The (theoretical) huge effort needed for doing that would allow them to grow a way better product.And it's not only about security, but about features (well, some are security features too). We're missing new kernel features (network hardware offload, security, wireguard...), filesystem (btrfs features, performance and error patches...), file servers (new features and compatibility, as Parallel NFS or Multichannel CIFS/SMB), and so on...I think they got stuck on 4.4 because of their btrfs fork, and now they're too deep on their own hole.Also, their backend is a mess. A bunch of different apps developed on different ways that mostly don't talk to each other. They sometimes overlap with each other and have very essential features that don't work and don't plan to fix. Meanwhile, they're busy releasing AI stuff features for the \"Office\" app.Edit note: For myself and some business stuff, I have a bunch of TrueNAS deployments, from a small Jonsbo box for my home, to a +16 disk rack server. This was for a client that wanted to migrate from another Synology they had on loan, and I didn't want to push a server on them, as they're a bit far away from me, and I wanted it to be serviceable by anyone. I regret it.reply",
      "The encryption is also broken. If you use encrypted shared folders, you have an arbitrary filename limit (https://kb.synology.com/en-ro/DSM/tutorial/File_folder_path_...). If you use volume encryption, your encryption key is stored on the NAS itself, which is capable of decrypting the data, unless you buy a second Synology NAS (https://blog.elcomsoft.com/2023/06/volume-encryption-in-syno...) to act as a key vault. Synology claims that volume encryption protects if you if the storage drives are stolen, but in what world would the drives, and not the NAS itself, be stolen?reply",
      "The filename limit comes from ecryptfs (https://www.ecryptfs.org/) which is what Synology uses for encrypted shared folders.As for full disk encryption, you can select where to store the key, which may be on the NAS itself (rendering FDE more or less useless) or on a USB key or similar.reply",
      "Why can\u2019t the user enter the encryption passphrase in DSM, which is actually the default in LUKS and allowed in TrueNAS etc?The DSM itself lives in an unencrypted partition or volume. Applications with data in encrypted volumes will be inaccessible until the volumes are unlocked.As usual, there is an easy workaround. You can run a KMIP server in a docker container and set up an external keystore. Once synology allows you to proceed with volume encryption, you can discard the KMIP server if you want and use the recovery keys.reply",
      "For full disk encryption you need DSM >= 7.2 and you can either, store it locally (useless) or in a KMIP server. [0]As a KMIP server you use:  - Another Synology NAS with DSM >= 7.2\n  - A KMIP compatible key server\n\nExcept for the demo implementation that Synology uses (PyKMIP), all the KMIP compatible servers I've found have licenses in the tens of thousands a year. So if anybody has any suggestions to substitute PyKMIP...--  0: https://kb.synology.com/en-global/DSM/tutorial/Which_models_support_encrypted_volumesreply",
      "I remembered wrong. I\u2019m fairly certain that Synology, at some point, allowed you to store the encryption vault on an external (USB)  drive, but apparently not anymore.reply",
      "You didn't remember wrong, I have mine stored on an external drive.  I am using DS 6.x thoughreply",
      "My disk station uploaded 54gb to synology servers the other day before I had my router block outbound. Trash product.reply",
      "Ah, I forgot about that. I had to take the key out of the NAS too, to a different device. That made no sense at all. And almost all of the implementations of the key server you need cost thousands of dollars in licenses.Edit: what they deploy on their NAS is an old version of a testing implementation of the KMIP protocol. PyKMIP: https://github.com/OpenKMIP/PyKMIPreply",
      "You can move out the key from the device using KMIP. I have an implementation that uses a Go-based service to store it in Nitrohsm. I'll clean it up and post a release announcement on Reddit...reply"
    ],
    "link": "https://lowendbox.com/blog/they-used-to-be-good-but-now-theyve-turned-to-evil-the-synology-end-game/",
    "first_paragraph": ""
  }
]