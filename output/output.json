[
  {
    "title": "Orion, our first true augmented reality glasses (fb.com)",
    "points": 634,
    "submitter": "mfiguiere",
    "submit_time": "2024-09-25T17:56:53.000000Z",
    "num_comments": 467,
    "comments_url": "https://news.ycombinator.com/item?id=41650047",
    "comments": [
      "Nice hardware. They're down to swim goggle size.Then you see what Facebook wants you to do with it - see screens in front of you all the time. One with Facebook's \"Recommended\" page, and a video of some talking neckbeard. There's a feeling of \"we were promised virtual reality, and all we got was talking heads of influencers.\" The hardware apparently has GPS, but that's turned off. So, no Pokemon Go yet. Not even Hyperreality.[1] It's all about ads and clicks.It can't draw dark. The workaround seems to be to dim out the world and draw light overlays, like almost everybody else. Will it work in bright daylight?[1] https://www.youtube.com/watch?v=YJg02ivYzSs\n \nreply",
      "Further evidence to the truth of this:The best minds of my generation are thinking about how to make people click ads.\u2013Jeff HammerbacherOh lament! for what, not just the future, but the present, could have been.Edited to add: But! Even as I have just written that and stand by it, I just don't know if humanity could have done it any other way. One must sell their soul to 'the green', even just a little, to have the time and space for the kind of creativity that will create a better future. Will we forever have to wade, neck-deep, through trash to find each tiny piece of the puzzle that, when enough pieces are put together, forms at least a picture of a brighter future?\n \nreply",
      "Even if it turns out that the only application of this is to show ads (which will not be the case), the hardware alone is a monumental achievement of engineering.I would love to see ads on these, at least once. In contrast, I've never had any interest to even try Apple's VR headset. This is one of the most well-put v1 products ever.Avoid the MKDBHC trap (or however it's spelled). Innovation beats cynicism, every day.\n \nreply",
      "I think the preferred term is contentpreneur now, not influencer.\n \nreply",
      "I'm never gonna remember that\n \nreply",
      "It's so sad they felt okay with unveiling these with the horrible aesthetics and no guarantees anywhere in plain sight on privacy.\n \nreply",
      "The press release says \"unmistakably a pair of glasses\". The fact that you're complaining about the aesthetics and not wether or not they're glasses is a testament to the generational leap they've made here. Apple's VR goggles are glasses with \"rendered\" external pass through. These actually fit the traditional definition of glasses.And yeah like in the future, these will shrink in size. Probably by half in five years. Remember in 2018 when we were wondering if we'd ever have the compute available to do \"inside out tracking\"? Now it's expected as a minimum requirement. How far we've come.\n \nreply",
      ">no guarantees anywhere in plain sight on privacyElaborate. Do you mean this with regards to the data that users will generate when using the device? Or the privacy of the people around the wearer?\n \nreply",
      "I could not care less about the the privacy of the weirdos who will try tonwear these in public. I care deeply about the further normalization of surveillance capitalism.I try hard to be kind, but I will have very little patience for any individual who wears always-on cameras that infeinge on my privacy. I don't use social media for a reason. Meta just wants to sell surveillance devices so they can collect more data, and will try to convince us it is for our benefit.",
      "I mean they are prototypes, not available for purchase. Presumably they can clean up the aesthetics and provide privacy guarantees around it when it's actually for sale.It's just to show what's possible, and to presumably jump the gun on their competitors\n \nreply"
    ],
    "link": "https://about.fb.com/news/2024/09/introducing-orion-our-first-true-augmented-reality-glasses/",
    "first_paragraph": "\nMeta\nFive years ago, we announced to the world that we were building AR glasses. We don\u2019t think people should have to make the choice between a world of information at your fingertips and being present in the physical world around you.That\u2019s why today, we\u2019re unveiling Orion, which we believe is the most advanced pair of AR glasses ever made. Orion bridges the physical and virtual worlds, putting people at the center so they can be more present, connected and empowered in the world.\u00a0\u00a0\u00a0There are three primary reasons why AR glasses are key to unlocking the next great leap in human-oriented computing.This slideshow requires JavaScript.That\u2019s the north star our industry has been building towards: a product combining the convenience and immediacy of wearables with a large display, high-bandwidth input and contextualized AI in a form that people feel comfortable wearing in their daily lives.\u00a0Ray-Ban Meta glasses have demonstrated the power of giving people hands-free access to key parts of "
  },
  {
    "title": "Git-absorb: Git commit \u2013fixup, but automatic (github.com/tummychow)",
    "points": 34,
    "submitter": "striking",
    "submit_time": "2024-09-26T00:12:53.000000Z",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41653191",
    "comments": [
      "FWIW, I've been using this alias for the past couple years for fixup commits, and I've been happy with it:> gfx='git commit --fixup $(git log $(git merge-base main HEAD)..HEAD --oneline| fzf| cut -d\" \" -f1)'It shows you the commits on the current branch and lets you select one via fzf. It then creates the fixup commit based on the commit you selected.\n \nreply",
      "Nice! I use git revise[^1] a lot which does a similar thing but without the fixup commit. I I\u2019ll try using fzf to make it interactive though. Thanks![^1]: https://github.com/mystor/git-revise\n \nreply",
      "I've been using this workflow with hg and it's great, happy to see a git port\n \nreply",
      "One of my favorite Sapling commands at Meta\n \nreply",
      "Yeah, it singlehandedly turned me on to Mercurial when I was there, and has massively shaped the way I use git ever since.\n \nreply"
    ],
    "link": "https://github.com/tummychow/git-absorb",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        git commit --fixup, but automatic\n      This is a port of Facebook's hg absorb, which I first read about on mozilla.dev.version-control:You have a feature branch with a few commits. Your teammate reviewed the branch and pointed out a few bugs. You have fixes for the bugs, but you don't want to shove them all into an opaque commit that says fixes, because you believe in atomic commits. Instead of manually finding commit SHAs for git commit --fixup, or running a manual interactive rebase, do this:git absorb will automatically identify which commits are safe to modify, and which staged changes belong to each of those commits. It will then write fixup! commits for each of those changes.With the --and-rebase flag, these fixup commits will be automatically integrated into the corresponding ones. Alternatively, you can check its output man"
  },
  {
    "title": "Llama 3.2: Revolutionizing edge AI and vision with open, customizable models (meta.com)",
    "points": 305,
    "submitter": "nmwnmw",
    "submit_time": "2024-09-25T17:29:27.000000Z",
    "num_comments": 101,
    "comments_url": "https://news.ycombinator.com/item?id=41649763",
    "comments": [
      "I'm absolutely amazed at how capable the new 1B model is, considering it's just a 1.3GB download (for the Ollama GGUF version).I tried running a full codebase through it (since it can handle 128,000 tokens) and asking it to summarize the code - it did a surprisingly decent job, incomplete but still unbelievable for a model that tiny: https://gist.github.com/simonw/64c5f5b111fe473999144932bef42...More of my notes here: https://simonwillison.net/2024/Sep/25/llama-32/I've been trying out the larger image models to using the versions hosted on https://lmarena.ai/ - navigate to \"Direct Chat\" and you can select them from the dropdown and upload images to run prompts.\n \nreply",
      "I saw that you mention https://github.com/simonw/llm/. Hadn't seen this before. What is its purpose? And why not use ollama instead?\n \nreply",
      "llm is Simon's command line front-end to a lot of the llm apis, local and cloud-based. Along with aider-chat, it's my main interface to any LLM work -- it works well with a chat model, one-off queries, and piping text or output into a llm chain. For people who live on the command line, or are just put-off by web interfaces, it's a godsend.About the only thing I need to look further abroad for is when I'm working multi-modally -- I know Simon and the community are mainly noodling over the best command line UX for that: https://github.com/simonw/llm/issues/331\n \nreply",
      "I've only used ollama over cli. As per the parent poster -- do you know if there are advantages over ollama for CLI use? Have you used both?\n \nreply",
      "Llama 3.2 vision models don't seem that great if they have to compare them to Claude 3 Haiku or GPT4o-mini. For an open alternative I would use Qwen-2-72B model, it's smaller than the 90B and seems to perform quite better. Also Qwen2-VL-7B as an alternative to Llama-3.2-11B, smaller, better in visual benchmarks and also Apache 2.0.Molmo models: https://huggingface.co/collections/allenai/molmo-66f379e6fe3..., also seem to perform better than Llama-3.2 models while being smaller and Apache 2.0.\n \nreply",
      "What interface do you use for a locally-run Qwen2-VL-7B? Inspired by Simon Willison's research[1], I have tried it out on Hugging Face[2]. Its handwriting recognition seems fantastic, but I haven't figured out how to run it locally yet.[1] https://simonwillison.net/2024/Sep/4/qwen2-vl/\n[2] https://huggingface.co/spaces/GanymedeNil/Qwen2-VL-7B\n \nreply",
      "1. Ignore the benchmarks. I've been A/Bing 11B today with Molmo 72B [1], which itself has an ELO neck-and-neck with GPT4o, and it's even. Because everyone in open source tends to train on validation benchmarks, you really can not trust them.2. The method of tokenization/adapter is novel and uses many fewer tokens than all comparable CLIP/SigLIP-adapter models, making it _much_ faster. Attention is O(n^2) on memory/compute per sequence length.[1] https://molmo.allenai.org/blog\n \nreply",
      "The llama 3.0, 3.1, & 3.2 all use the TikToken tokenizer which is the open source openai tokenizer.\n \nreply",
      "GP is talking about context windows, not the number of token used by the tokenizer.\n \nreply",
      "Somewhat confusingly, it appears the tokenizer vocabulary as well as the context length are both 128k tokens!\n \nreply"
    ],
    "link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/?_fb_noscript=1",
    "first_paragraph": "Takeaways:We\u2019ve been excited by the impact the Llama 3.1 herd of models have made in the two months since we announced them, including the 405B\u2014the first open frontier-level AI model. While these models are incredibly powerful, we recognize that building with them requires significant compute resources and expertise. We\u2019ve also heard from developers who don\u2019t have access to these resources and still want the opportunity to build with Llama. As Meta Founder and CEO Mark Zuckerberg shared today at Connect, they won\u2019t have to wait any longer. Today, we\u2019re releasing Llama 3.2, which includes small and medium-sized vision LLMs (11B and 90B) and lightweight, text-only models (1B and 3B) that fit onto select edge and mobile devices.It\u2019s only been a year and a half since we first announced Llama, and we\u2019ve made incredible progress in such a short amount of time. This year, Llama has achieved 10x growth and become the standard for responsible innovation. Llama also continues to lead on openness"
  },
  {
    "title": "Show HN: Httpdbg \u2013 A tool to trace the HTTP requests sent by your Python code (github.com/cle-b)",
    "points": 106,
    "submitter": "cle-b",
    "submit_time": "2024-09-25T19:18:12.000000Z",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=41650905",
    "comments": [
      "That's pretty cool! I was playing last night and implemented resumable downloads[0] for pip so that it could pick up where it stopped upon a network disconnect or a user interruption. It sucks when large packages, especially ML related, fail at the last second and pip has to download from scratch. This tool would have been nice to have. Thanks a bunch,- [0]: https://asciinema.org/a/1r8HmOLCfHm40nSvEZBqwm89k\n \nreply",
      "I've always wanted this. You get so spoiled with the Chrome Dev Tools when using Javascript that you miss it when you don't have it.\n \nreply",
      "Looks neat!A similar tool for this would be VCR (originally built in Ruby, but ported to other languages since): https://vcrpy.readthedocs.io/en/latest/. This injects itself into the request pipeline, records the result in a local file which can then also be replayed later in tests. It's a quite nice approach when you want to write tests (or just explore) a highly complicated HTTP API without actually hitting it all the time.\n \nreply",
      "The inspection and debugging features this offers are great additions though.  I've stared at VCR yaml enough times to not want to ever do it again.\n \nreply",
      "I really like vrcpy. I used it a lot with pytest in my previous job. httpdbg isn\u2019t exactly the same; the idea is more about seeing HTTP requests in real-time and being able to easily study them.\n \nreply",
      "This is great -It would be good to be be able to have django debug toolbar integration, that way I could see which requests were made to backend APIs without leaving Django.Having tried MITMProxy something like httpdbg is definitely needed.\n \nreply",
      "You can do that with django debug toolbar. If you have an endpoint that doesn't return HTML, and hence wouldn't render debug toolbar, you can go to django admin (or any other endpoint that would render ddt) and go to the history pane, check other requests and switch to them.\n \nreply",
      "this is very useful, but why can it only work with python code? At which level does it intercept the http traffic?do I have to use specific http library?\n \nreply",
      "It seems to intercept calls for some popular http client libs:https://github.com/cle-b/httpdbg/tree/main/httpdbg/hooks\n \nreply",
      "It works only with Python code because it intercepts HTTP requests by hooking into certain Python functions.It supports any HTTP library based on Python\u2019s standard socket library. Specifically, it works with libraries like requests, httpx, aiohttp, and urllib3, as well as pytest, providing more detailed information about the initiator of the requests.\n \nreply"
    ],
    "link": "https://github.com/cle-b/httpdbg",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        A tool for Python developers to easily debug the HTTP(S) client requests in a Python program.\n      httpdbg is a tool for Python developers to easily debug the HTTP(S) client requests in a Python program.To use it, execute your program using the pyhttpdbg command instead of python and that's it. Open a browser to http://localhost:4909 to view the requests:Full documentation => https://httpdbg.readthedocs.io/Open an interactive console using the command pyhttpdbg.Perform HTTP requests.You can inspect the HTTP requests directly in your web browser at http://localhost:4909.You can trace all the HTTP requests performed by a scriptYou can trace all the HTTP requests performed during your testsIf you use the pytest-xdist plugin to execute your tests in parallel, then you must install the pytest-httpdbg plugin if you want to trace the requ"
  },
  {
    "title": "Launch HN: Haystack (YC S24) \u2013 Visualize and edit code on an infinite canvas (github.com/haystackeditor)",
    "points": 188,
    "submitter": "akshaysg",
    "submit_time": "2024-09-25T15:31:00.000000Z",
    "num_comments": 117,
    "comments_url": "https://news.ycombinator.com/item?id=41648564",
    "comments": [
      "This has been a great idea for decades. I want Haystack to be successful just like many other attempts. The early execution seems promising. And I suspect there will be many challenges (e.g. when it's hard to figure out caller/callee,, inconsistent UX preferences across developers, etc). Kudos for taking this on!Btw I've always thought that this is even more powerful when the screen estate is more infinite than a 2D screen (like in a VR headset).\n \nreply",
      "I love the idea of a Haystack VR world! It's a shame that VR software is in a tenuous state due to the biological factors, but I believe it's the future \"one day\".\n \nreply",
      "\"In a tenuous state due to the biological factors\" is easily the funniest SV euphemism for \"can't be used by humans.\"\n \nreply",
      "It\u2019s ok after they deliver the MVP there will be a wetware update.\n \nreply",
      "Who knows, one day it may be possible (hopefully without any dystopian updates to human biology)!\n \nreply",
      "At this point, that seems dubious - your inner ear is going to go all inner ear on you, no matter what. Unless you get to turn that off, VR is not it.\n \nreply",
      "Check out SoftSpace https://soft.space\n\u2026 not an IDE but similar idea for knowledge mapping\n \nreply",
      "This is actually really cool!\n \nreply",
      "Very cool. I imagined my organizations entire codebase being mapped like this and across different frameworks and languages.I don\u2019t know if I missed this in the video or if it\u2019s not yet possible, but that\u2019s a lot of manual work, so instead of connecting the nodes, give a simple bot to run in the repo folder to automate the visualization.It\u2019s super cool and I\u2019m adding to my watch list.If I were you, i\u2019d target enterprise organizations or local municipalities IT groups who are going through or planning their digital transformations. They have a need for way-finding and sense making across legacy and new work.If you play your cards right, Salesforce will come knocking in under a year. I see a lot of compatibility with their vision and product offerings.\n \nreply",
      "It automatically adds connections as you traverse through files/symbols. Not super sure if this is what you mean, but we intend to serve the users \"flows\" based on queries in the natural language e.g. \"what happens when you click the subscribe button from the mouse down all the way to the backend\".\n \nreply"
    ],
    "link": "https://github.com/haystackeditor/haystack-editor",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          This repository (\"Haystack Editor\") is where we (Haystack Software) develop the Haystack Editor product together with the community. Not only do we work on code and issues here, we also publish our roadmap. This source code is available under the [PolyForm Strict License 1.0.0] (https://polyformproject.org/licenses/strict/1.0.0).Haystack Editor is a distribution of the Haystack Editor repository with specific customizations released under a terms of service.Haystack Editor combines the simplicity of a code editor with a canvas UI that makes it easier to understand code at a glance It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.Haystack is updated weekly with new features and bug fixes. You can download "
  },
  {
    "title": "The lost language extensions of MetaWare's High C compiler (2023) (duriansoftware.com)",
    "points": 220,
    "submitter": "PaulDavisThe1st",
    "submit_time": "2024-09-25T14:19:13.000000Z",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=41647843",
    "comments": [
      "I wrote up the iterator-driven for back in 2011, because it was one of those things that had been long-since forgotten about; along with what it would look like were it to be incorporated into the (then) C++ standard.I am fortunate enough to own a copy of the High C/C++ Language Reference in English.  (-:* http://jdebp.uk./FGA/metaware-iterator-driven-for.html* http://jdebp.uk./Proposals/metaware-iterator-driven-for.html\n \nreply",
      "Do you know how the break/return would get compiled down to? Would the yield function need to be transformed to return a status code and checked at the callsite?\n \nreply",
      "It's a non-local goto, also a MetaWare language extension, out of the anonymous nested function that the for statement body becomes to (effectively) an anonymous label right after the for statement.Another part of the High C/C++ Language Reference describes non-local labels and jumps to them.  It doesn't go into great detail, but it does talk about stack unwinding, so expect something similar to how High C/C++ implemented throwing exceptions.\n \nreply",
      "Not sure, but imo you could do it with basically reversing the call/return mechanism - that is, whenever the iterator function returns, it saves its state to the stack, just like if it would during a function call, and conversely, when the outside context hands back the control to the iterator, it would restore its state, analogous to how a return from an outside context would work.\n \nreply",
      "That's not at all how MetaWare implemented iterator-driven for, though.As Joe Groff said in the headlined post, MetaWare implemented it by turning the nested body of the for statement into an anonymous nested function, which is called back (through a \"full function pointer\") from the iterator function whenever there's a \"yield()\" in that latter.So there's no \"whenever the iterator function returns\".  It only returns when it has finished.  The body of the for statement is called by and returns to the iterator function, which is in its turn called by and returns to the function that the for statement is in.All of the \"saving state to the stack\" that happens is just the quite normal mechanics of function calling, with merely some special mechanics to pass around a pointer to the lexically outer function's activation record (which is why a \"full function pointer\" is not a plain \"function pointer\") as a hidden parameter so that the (anonymous) lexically inner function knows where the outer one's automatic storage duration variables are.MetaWare also had non-local goto from within nested functions back out into lexically enclosing scopes, and since the for statement body is a nested function, it's just a question of employing that already available implementation mechanism (which in turn does the same sorts of things as throwing exceptions does, unwinding the stack through the iterator function) for break/continue/return (and of course goto) inside the for body.\n \nreply",
      "Is that supposed to be an upside-down smiley face?\n \nreply",
      "D (also in Das BetterC) has:1. underscores in literals:    int a = 1_234_567;\n\n2. case ranges:    case 5 .. case 6:\n\n3. named arguments:    void test(int a, int b);\n\n    void foo() { test(b:3, a:4); }\n\n4. nested functions:    int foo(int i) {\n      int plus(int a) { return a + i; }\n      return plus(3);\n    }\n\n5. static nested functions:    int foo(int i) {\n      static int plus(int a) { return a + i; }\n      return plus(3);\n    }\n\n    Error: `static` function `test.foo.plus` cannot access variable `i` in frame of function `test.foo`\n\n6. a feature similar to generators https://dlang.org/spec/statement.html#foreach_over_struct_an...\n \nreply",
      "I was thinking about D the whole way while reading this. I just know I am going to see Walter Bright in the comments XD.\n \nreply",
      "Every time Walter posts it reminds me my dream language would simply be C with https://www.digitalmars.com/articles/C-biggest-mistake.html and probably go lang style interfaces. Maybe a little less UB and some extensions for memory safety proofs.\n \nreply",
      "That's why DasBetterC has done very well! You could call it C with array bounds checking.I occasionally look at statistics on the sources of bugs and security problems in released software. Array bounds overflows far and away are the top cause.Why aren't people just sick of array overflows? In the latest C and C++ versions, all kinds of new features are trumpeted, but again no progress on array overflows.I can confidently say that in the 2 decades of D in production use, the incidence of array overflows has dropped to essentially zero. (To trigger a runtime array overflow, you have to write @system code and throw a compiler switch.)The solution for C I proposed is backwards compatible, and does not make existing code slower.It would be the greatest feature added to C, singularly worth more than all the other stuff in C23.\n \nreply"
    ],
    "link": "https://duriansoftware.com/joe/the-lost-language-extensions-of-metaware%27s-high-c-compiler",
    "first_paragraph": "This book I got in a pile of FM TOWNS books turns out to be a lot more interesting that I was expecting an '80s C compiler manual to be. For as long as C and its relatives have been in mainstream use, it has been necessary to use vendor language extensions to actually get anything done with it, though in today's GCC/Clang/MSVC oligopoly those extensions tend to be focused on the yak-shaving details of dealing with the underlying platform. Things were much more interesting in the 80s, when there were a lot more, smaller companies competing for adoption. Phar Lap wrote one of the first DOS extenders that allowed programs to take full advantage of the 32-bit 80386 processor from the 16-bit-bound MS-DOS environment, and they hired MetaWare to port the High C Compiler to Phar Lap's DOS extender SDK. Fujitsu in turn chose Phar Lap's DOS extender to integrate into the OS for their 80386-based FM TOWNS platform, and High C became the first-party C compiler for the platform. The FM TOWNS came o"
  },
  {
    "title": "Eliminating Memory Safety Vulnerabilities at the Source (googleblog.com)",
    "points": 99,
    "submitter": "coffeeaddict1",
    "submit_time": "2024-09-25T18:49:03.000000Z",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=41650647",
    "comments": [
      "This is a very interesting post! One takeaway is that you don't need to re-write the world. Transitioning new development to a memory safe language can bring meaningful improvements. This is much easier (and cheaper) than needing to port everything over in order to get an effect.\n \nreply",
      "> The answer lies in an important observation: vulnerabilities decay exponentially. They have a half-life. [...] A large-scale study of vulnerability lifetimes2 published in 2022 in Usenix Security confirmed this phenomenon. Researchers found that the vast majority of vulnerabilities reside in new or recently modified code.It stands to reason, then, that it would be even better for security to stop adding new features when they aren't absolutely necessary. Windows LTSC is presumably the most secure version of Windows.\n \nreply",
      "Or an alternative approach: only compile the subset of features you explicitly need.Obviously there\u2019s a ton of variance in how practical this is any place, but it\u2019s less common than it should be.\n \nreply",
      "So the argument is because the vulnerability lifetime is exponentially distributed, focusing on secure defaults like memory safety in new code is disproportionately valuable, both theoretically and now evidentially seen over six years on the Android codebase.Amazing, I've never seen this argument used to support shift/left secure guardrails but it's great. Especially for those with larger, legacy codebases who might otherwise say \"why bother, we're never going to benefit from memory-safety on our 100M lines of C++.\"I think it also implies any lightweight vulnerability detection has disproportionate benefit -- even if it was to only look at new code & dependencies vs the backlog.\n \nreply",
      "I'm a little uneasy about the conclusions being drawn here as the obvious counterpoint isn't being raised - what if older code isn't being looked at as hard and therefore vulnerabilities aren't being discovered?It's far more common to look at recent commit logs than it is to look at some library that hasn't changed for 20 years.\n \nreply",
      "> what if older code isn't being looked at as hard and therefore vulnerabilities aren't being discovered?It wasn\u2019t being look at as hard before either. I don\u2019t think that\u2019s changed.They don\u2019t give a theory for why older code has fewer bugs, but I\u2019ve got one: they\u2019ve been found.If we assumed that any piece of code has a fixed amount of unknown bugs per 1000 lines, it stands to reason that overtime the sheer number of times the code is run with different inputs in prod makes it more and more likely they will be discovered. Between fixing them and the code reviews while fixing them the hope would be that on average things are being made better.So overtime, there are fewer bugs per thousand lines in existing code. It\u2019s been battle tested.As the post says, if you continue introducing new bugs at the same rate you\u2019re not going to make progress. But if using a memory safe language means you\u2019re introducing fewer bugs in new features then overtime the total number of bugs should be going down.\n \nreply",
      "I wasn\u2019t entirely satisfied with the assertion that older code has fewer vulnerabilities either. It feels like there could be explanations other than age for the discrepancy.For example: maybe the engineers over the last several years have focused on rewriting the riskiest parts in a MSL, and were less likely to change the lower risk old code.Or\u2026 maybe there was a process or personnel change that led to more defects.With that said, it does seem plausible to me that any given bug has a probability of detection per unit of time, and as time passes fewer defects remain to be found. And as long as your maintainers fix more vulnerabilities than they introduce, sure, older code will have fewer and the ones that remain are probably hard to find.\n \nreply",
      "I don\u2019t understand this point. The project under scrutiny is Android and people are detecting vulnerabilities both manually and automatically based on source code/binary, not over commit logs. Why would the commit logs be relevant at all to finding bugs?The commits are just used for attribution. If there was some old lib that hasn\u2019t been changed in 20 years that\u2019s passed fuzzing and manual code inspection for 20 years without updates, chances are it\u2019s solid.\n \nreply",
      "I\u2019m curious how this applies to Mac vs Windows, where most newer Mac code is written in memory safe swift, while Windows still uses primarily uses C or C++.\n \nreply",
      "Apple is still adding large amounts of new Objective-C code in each new macOS version [0].I haven't found any language usage numbers for recent versions of Windows, but Microsoft is using Rust for both new development and rewriting old features [1] [2].[0] Refer to section \"Evolution of the programming languages\" https://blog.timac.org/2023/1128-state-of-appkit-catalyst-sw...[1] https://www.theregister.com/2023/04/27/microsoft_windows_rus...[2] https://www.theregister.com/2024/01/31/microsoft_seeks_rust_...\n \nreply"
    ],
    "link": "https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html",
    "first_paragraph": "\nMemory safety vulnerabilities remain a pervasive threat to software security. At Google, we believe the path to eliminating this class of vulnerabilities at scale and building high-assurance software lies in Safe Coding, a secure-by-design approach that prioritizes transitioning to memory-safe languages.\n\nThis post demonstrates why focusing on Safe Coding for new code quickly and counterintuitively reduces the overall security risk of a codebase, finally breaking through the stubbornly high plateau of memory safety vulnerabilities and starting an exponential decline, all while being scalable and cost-effective.\n\nWe\u2019ll also share updated data on how the percentage of memory safety vulnerabilities in Android dropped from 76% to 24% over 6 years as development shifted to memory safe languages.\n\nConsider a growing codebase primarily written in memory-unsafe languages, experiencing a constant influx of memory safety vulnerabilities. What happens if we gradually transition to memory-safe la"
  },
  {
    "title": "How to avoid a BSOD on your 2B dollar spacecraft (clarkwakeland.com)",
    "points": 84,
    "submitter": "linebeck",
    "submit_time": "2024-09-25T18:40:26.000000Z",
    "num_comments": 75,
    "comments_url": "https://news.ycombinator.com/item?id=41650534",
    "comments": [
      "Thee are a bunch of comments here asking why one would run Windows on a spacecraft.I am a spacecraft engineer. I don\u2019t see anything in the linked article indicating that they are actually running Windows - the BSOD claim is tongue-in-cheek, or at least that\u2019s how I read it. I also don\u2019t know of anyone anywhere that runs Windows on a spacecraft, with the exception of laptops used by astronauts. Typically one runs vxWorks, or maybe QNX. Some experimental (high risk, low cost) systems run Linux. Older spacecraft don't run any OS at all, everything is running on bare metal, and that may be true for a handful of current spacecraft as well.Windows is used in some places by ground controllers, but these days they tend to be running Linux a lot more often.\n \nreply",
      "Linux(with realtime patch) is used very heavily in spacecraft by Spacex. So both in terms of high visibility/important/danger (dragon 2) and high count (starlink) it is very widely used.citation https://old.reddit.com/r/spacex/comments/ncj4vz/we_are_the_s...\n \nreply",
      "I wonder how the integration of PREEMPT_RT is going to affect that technology stack going forwards (I imagine slowly, but it's there now).\n \nreply",
      "Save costs by integration with the new feature or increasing cost with maintaining a custom kernel branch in the long run.\n \nreply",
      "Indeed, and it\u2019s clearly stated in the article:> Safemode is the satellite equivalent of a blue screen of death.It\u2019s about avoiding safemode, and more generally about the end-to-end QA/testing process for satellites before they\u2019re sent up into orbit. It\u2019s very clearly not about actual Windows BSODs, it\u2019s just written in a tongue-in-cheek style. Those commenting about \u201cwtf windows on a spacecraft\u201d clearly didn\u2019t read the article, just read the title.FWIW I found the writing style engaging and the content interesting. I guess the title is a little click-bait-y, but not in a way that I minded much, and I probably wouldn\u2019t have read an article titled \u201cHow to avoid safemode on a satellite.\u201d It\u2019s a fine line, but titles DO have to draw you in, otherwise you\u2019ll never read the article.Re: the article itself, I did think it was pretty wild that customers have to be informed of every incident where a satellite flips into safemode in TESTING! In real operations, sure, but in testing, that\u2019s wild. Feels like having to report bugs caught in my local dev environment, that were never deployed to prod.\n \nreply",
      "This would be during formal testing, which is similar to what you might know as \u201cacceptance testing\u201d. The spacecraft doesn\u2019t \u201center safe mode\u201d during development.If you\u2019re paying half a billion $ for something you become very very interested in test design and test results.\n \nreply",
      "Seconding the vxWorks and bare metal. Never seen Windows or Linux on a satellite bus. Haven't really touched payloads but I've seen some wonky things shipped to orbit by universities and not all them have been cubesat student projects.\n \nreply",
      "Every Starlink runs with Linux.The license list is a bit long:https://www.starlink.com/assets/pdfs/Starlink-Open-Source-Co...\n \nreply",
      "That's likely software for the receiver/router/CPE that customers use, since it's being distributed they have to satisfy license obligations for it.Software actually running on satellites isn't being distributed, so there's no license obligations there (unless it's AGPL, ha!)\n \nreply",
      "that doesn't state what uses linux, angular.io is also on there\n \nreply"
    ],
    "link": "https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/",
    "first_paragraph": " Created on September 04, 2024    2024  \u00a0 \u00b7 \u00a0   aerospace Short answer: turn it off and turn it back onLong Answer\u2026The lifecycle of most spacecraft consists of a final phase where all the systems are tested to various levels of synergy. One of the most important and complex set of tests are the Closed Loop Tests (CLTs), where the spacecraft is sent simulated orbital data, and then its attitude response is observed. It\u2019s a closed loop because the attitude telemetry is fed back into the simulation while the test is occurring, effectively making the spacecraft and whatever hardware is currently being used part of the simulation. This particular test involved observing the response from control thrusters on the spacecraft when commanded to perform a slew and engine burn to a transfer orbit.To get the spacecraft response data back to in the loop, a set of memory addresses mapped to the sim needs to be uploaded onto the spacecraft RAM. These memory addresses were not determined while this te"
  },
  {
    "title": "The Simple Magic of Consistent Hashing (2011) (paperplanes.de)",
    "points": 8,
    "submitter": "tosh",
    "submit_time": "2024-09-22T11:12:18.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.paperplanes.de/2011/12/9/the-magic-of-consistent-hashing.html",
    "first_paragraph": "The simplicity of consistent hashing is pretty mind-blowing. Here you have a\nnumber of nodes in a cluster of databases, or in a cluster of web caches. How do\nyou figure out where the data for a particular key goes in that cluster?You apply a hash function to the key. That\u2019s it?  Yeah, that\u2019s the whole deal of\nconsistent hashing. It\u2019s in the name, isn\u2019t it?The same key will always return the same hash code (hopefully), so once you\u2019ve\nfigured out how you spread out a range of keys across the nodes available, you\ncan always find the right node by looking at the hash code for a key.It\u2019s pretty ingenious, if you ask me. It was cooked up in the lab chambers at\nAkamai, back in the late nineties. You should go and read the original paper\nright after we\u2019re done here.Consistent hashing solves the problem people desperately tried to apply sharding\nto pretty nicely and elegantly. I\u2019m not going to bore you with the details on\nhow exactly consistent hashing works. Mike Perham does a pretty good job "
  },
  {
    "title": "Timeshare owner? The Mexican drug cartels want you (krebsonsecurity.com)",
    "points": 107,
    "submitter": "todsacerdoti",
    "submit_time": "2024-09-25T16:28:20.000000Z",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=41649134",
    "comments": [
      "That\u2019s a creative way of finding marks. Timeshares are a notoriously bad investment[1]; people with a timeshare might be easier to rope into another bad investment (a scam).[1]: https://moneywise.com/investing/real-estate/why-buying-a-tim...\n \nreply",
      "That article is useful context for this\u2014it points out that there are way more people trying to sell timeshares than buy them, which means that people who want to get out from under one can't do so easily. That creates an environment ripe for scammers who can promise to finally take this bad investment off your hands.\n \nreply",
      "But why don\u2019t they go down in price until there is an equilibrium?\n \nreply",
      "Here is an example as to why: $0 to buy, maint fee $1076https://www.redweek.com/posting/R1228603The relationship is perverse. You cannot simply leave, so there is zero reason for the timeshare company not to bleed you dry in fees. You can sell your share for $0 or even pay someone to take it, but the management company still gets their due. They are not like a landlord who would ever have to contend with an empty unit if they get too uppity.\n \nreply",
      "Permanent timeshares should absolutely be illegal. It's ridiculous to allow a permanent obligation to maintain a property that the \"owner\" isn't allowed to destroy.\n \nreply",
      "Is there a business model where people could pay to sell their timeshares to a shell company and then having the company go insolvent?\n \nreply",
      "IANAL but I'm pretty sure that would be considered fraud.\n \nreply",
      "The \"Texas two-step\" has been used by plenty of companies and is structured around exactly those sort of shenanigans. https://www.investopedia.com/texas-two-step-bankruptcy-defin...\n \nreply",
      "Because a time share is not an asset, it's a liability.  It is sold as \"ownership\" but in fact it is an obligation to pay for a vacation rental in perpetuity, except that \"rent\" is called \"maintenance fees\".  It is a scam pure and simple, and no one in their right mind would ever buy one at any price.\n \nreply",
      "There's a sucker retiring every minute.\n \nreply"
    ],
    "link": "https://krebsonsecurity.com/2024/09/timeshare-owner-the-mexican-drug-cartels-want-you/",
    "first_paragraph": "The FBI is warning timeshare owners to be wary of a prevalent telemarketing scam involving a violent Mexican drug cartel that tries to trick people into believing someone wants to buy their property. This is the story of a couple who recently lost more than $50,000 to an ongoing timeshare scam that spans at least two dozen phony escrow, title and realty firms.One of the phony real estate companies trying to scam people out of money over fake offers to buy their timeshares.One evening in late 2022, someone phoned Mr. & Mrs. Dimitruk, a retired couple from Ontario, Canada and asked whether they\u2019d ever considered selling their timeshare in Florida. The person on the phone referenced their timeshare address and said they had an interested buyer in Mexico. Would they possibly be interested in selling it?The Dimitruks had purchased the timeshare years ago, but it wasn\u2019t fully paid off \u2014 they still owed roughly $5,000 before they could legally sell it. That wouldn\u2019t be an issue for this buyer"
  },
  {
    "title": "Why I still blog after 15 years (jonashietala.se)",
    "points": 334,
    "submitter": "lawn",
    "submit_time": "2024-09-25T12:19:29.000000Z",
    "num_comments": 177,
    "comments_url": "https://news.ycombinator.com/item?id=41646531",
    "comments": [
      "> \"I keep this blog for me to write, not necessarily for others to read.\"This is now to me the \"old school\" internet creator attitude (that I still possess). I don't blog as much any more but do create content elsewhere - a lot of it is for my own enjoyment and creative outlet, to blow off steam, whatever - the fact that other people may want to watch it is secondary. I do try to do things people want, but only if I want to do it.The only reason I highlight this is that the up and coming generations absolutely do not see content creation in the same way. I got in an absurd argument with an early 20 something on a social media platform about how annoying ads were that were disguised as content. The response was overwhelmingly \"Well, how else do you expect content creators to make a living?\"I do not disagree that creators should be able to monetize their content however they please, but the fact that people see that as the end and only goal of content creation is baffling to me and almost certainly making it worse. This same person tried to tell me it's been the same way since the earliest days of youtube - which they would have been in diapers around that time - is absolutely not true. The idea of content creation as a full time career is relatively new, and I hate it. The worst part is if you don't participate in the type of obnoxious engagement hacking or buried ads that these \"professional\" creators do, the algorithms punish you for it.\n \nreply",
      "> content creationI seriously hate the term \"content\" used for \"creative output\". It is a terrible, derogatory word, that makes me sad. Content is only there to have something to sell, to fill the blank space around ads, the actual content of the content doesn't matter. That people refer to themselves as \"content creators\" is a sign that they see the value of their creative output only to make money.\n \nreply",
      "Nobody ever thought to themselves: I sure could go for some content right now.\n \nreply",
      "I can't explain why, but I always cringe a little when I hear someone say that they \"consume content.\"Maybe its because I can't tell if brings up animalistic connotations (a pack of feral hipsters picking at the remains of an endangered podcast on the Serengeti), or if they are intentionally being elitist (\"It would be a waste of time to simply read Chomsky's work, an educated person would make the effort consume it.\")\n \nreply",
      "I get the opposite vibe - you read literature, you consume content like it's generic slop and the quality isn't that important.\n \nreply",
      "Agreed. It\u2019s like fast food, but for your brain.\n \nreply",
      "A friend of mine was playing the game Slay the Spire and was loving it -- he said something along the lines of, \"It's very well designed, and there's so much content!\" That always kind of skeeved me out. I think because there's this odd self-awareness of it all?\n \nreply",
      "Ha. This is is exactly what turns me off of Slay the Spire. It's a filler game, full of filler content, designed to fill your time. And not, as far as I can tell, much more than that.\"Content\" is a commodity. I don't see a huge difference between the folks who view creative work as \"content\" and talk about it as if it's fungible and can be valued per uni of weight, and art speculators who buy up works of art they've never seen and then leave it warehoused in some freehold somewhere.I can't really blame people who do creative work for catering to folks who think about their work this way - everybody's got to eat - but I'll still gladly bemoan the pervasive cultural debasement.\n \nreply",
      "Couldn\u2019t really disagree more, although I guess I see where you\u2019re coming from. Slay the Spire to me lacks \u201ccontent\u201d at least the way you\u2019re using it - there are 4 classes that essentially have never changed and the levels are pseudo randomly generated and otherwise don\u2019t change much run to run.However, attaining very high levels in that game requires a depth of skill, strategy, and math that is constantly startling to me, and I used to play card games professionally.\n \nreply",
      "I don\u2019t even like deck builders and STS hooked me for solid 30hrs\n \nreply"
    ],
    "link": "https://www.jonashietala.se/blog/2024/09/25/why_i_still_blog_after_15_years/",
    "first_paragraph": "Time flies when you\u2019re having fun.Before you know it, your little babies have started school, you celebrate the 30th anniversary of Jurassic Park, and that little blog you started have now been going for 15 years.15 years is a long time; longer than I\u2019ve been waiting for Winds of Winter, and that wait has felt like an eternity.\nHow did I\u2014who frequently abandon projects for the next shiny thing\u2014manage to continue this blog for so long?I\u2019m as surprised as anyone but I\u2019ve tried to make a retrospective of how this may have happened.I started this blog because I wanted to create a bunch of fast game prototypes and I wanted somewhere I could write about my plans and, ultimately, the games.You see, I was a budding programmer and I wanted to learn how to program by making a game.\nNot a simple game like Tetris\u2014that would be way too sensible\u2014no, I wanted to make a big RTS game, like StarCraft or Supreme Commander.\nAnd to do that you needed a game engine.So I got stuck developing my engine with t"
  },
  {
    "title": "Audio Masking (cryptomuseum.com)",
    "points": 101,
    "submitter": "goles",
    "submit_time": "2024-09-25T14:27:03.000000Z",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=41647923",
    "comments": [
      "I\u2019ll point out that a common method of detecting bugs at the time was to set up a radio receiver with a speaker and then sweep the frequency,  if you managed to hit you would get a feedback sound between the speaker and bug.  These oddball modulation schemes would prevent that from working.I like it a lot that many of techniques have a hybrid analog/digital structure that would involve sample-and-hold, sweeps and comparators like the Triple Pulse scheme.Today I can\u2019t believe you wouldn\u2019t use some digital solution but at that point in time you\u2019d be lucky to be able to use a small IC.\n \nreply",
      "Audio ADCs are incredibly small and the digital functionality needed isn't much for this. One can fit everything in a sub mm2 IC I think. Minus the antenna.\n \nreply",
      "Also of interest in this domain.The great seal bug(The Thing)https://www.youtube.com/watch?v=NLDpWrwijE8 (Machining and Microwaves)What I like about this specific video is that the guy actually builds one. And there is a world of difference between a popular article on how the thing worked. and the subtle genius engineering required to get it to actually work.\n \nreply",
      "Oh crap... the Scanlock Mark VB receiver shown on that picture is really similar to the Autolock 7 receiver I snatched at a flea market for a song many years ago, and after finding absolutely nothing about it online sold it on Ebay for like 3 songs. Had I known it was a bug finding device I could have donated it to the Cryptomuseum.\n \nreply",
      "it would be interesting to see what the waterfall charts of these looked like, and I can't tell if there is enough info in the article to produce a gnuradio flowgraph for any of them. it could be a fun retro spy tech project.\n \nreply",
      "In practice most audio channels are low-pass filtered and bandwidth limited, so I'm guessing that these modulation techniques are not going to work. Also, we have digital methods now.\n \nreply",
      "These are techniques for modulating audio onto a radio signal, I think the article didn't make that very clear.\n \nreply",
      "Today with spread spectrum, it's probably much easier to hide a covert radio signal.\n \nreply",
      "Yes and no. SS still has an energy signature, which you can recognize if you go looking for SS. And the transmitting antenna can be RDF\u2019ed.\n \nreply",
      "Are there any bugs that masquerade as normal devices such as phones in a time-frequency sense, such that they blend in the environment as phones. Polymorphic bugs? Bugs that change their signature.One more question: are there any bugs that shut down if there is no chatter in the spectrum... Say, if it's a noisy environment (frequency wise) with many phones and devices, the bug blends in and transmits. If it gets quiet, such as when phones are being turned off or distant, then there's something fishy and the bug suspends its operation?\n \nreply"
    ],
    "link": "https://www.cryptomuseum.com/covert/bugs/masking/",
    "first_paragraph": ""
  },
  {
    "title": "Clara (YC S24) Is Hiring a Head of Growth (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-09-25T21:01:15.000000Z",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/clara/jobs/bB9fgEH-head-of-growth",
    "first_paragraph": ""
  },
  {
    "title": "MI couple running out of time to prove they found Great Lakes' oldest shipwreck (lansingstatejournal.com)",
    "points": 23,
    "submitter": "rmason",
    "submit_time": "2024-09-23T17:19:32.000000Z",
    "num_comments": 22,
    "comments_url": "https://news.ycombinator.com/item?id=41628371",
    "comments": [
      "If the firewall blocks you: https://archive.is/dDjOP",
      "I love the islands in northern Lake Michigan, especially the line that goes from Washington Island in WI to Rock Island north to St. Martin and then to Summer Island. It's always seemed so remote. I assume these are the \"Huron Islands\"? I've never seen them referred to as such and when I search for them I get links to islands in Lake Superior, which are also interesting but not the same.I'm interested in the book now. Even if it turns out not to be the Griffon, it's an interesting story.\n \nreply",
      "> When I ran short of air at the wreck, Tom would swim over and hold out his backup breathing line, known to divers as a \"reserve regulator.\" I'd catch a breath to stay down longer.Taking breaths off a scuba tank at depth is something only someone trained as both a diver and freediver should do. I don\u2019t get the impression the reporter is either. Tom seems a bit cavalier.\n \nreply",
      "The article specifies that the wreckage in question was 10 feet below the surface. Is that deep enough to matter?\n \nreply",
      "If you took a deep breath and held it on the way up, maybe.  Otherwise, probably not.\n \nreply",
      "Yes, the fractional pressure change is greatest near the surface, so shallow water is the most dangerous region for lung damage if you hold your breath on ascent.\n \nreply",
      "As an experienced scuba diver and freediver, I would never mix the two and take air from a scuba diver while freediving\u2026. The habit of holding my breath on ascent while freediving is really ingrained, and I think it is very likely to forget to exhale when doing this.\n \nreply",
      "What? No, not at all. That\u2019s a technique that\u2019s taught at the most basic levels of even open water diving. It might be not as ideal if you\u2019re near maximum depths for a general air mix where you might start to run into nitrogen saturation (say longer than 10 mins) at 100+ ft depth, but in the article they were down what seems like no deeper than 15 ft. You could pretty much stay down all day that shallow.It\u2019s standard training, at least with my NAUI knowledge to practice rescue breathing with another divers spider. My instructor added a few curveballs in that he\u2019d mess up my tank, make me take it off and fix it while without a mask with my eyes closed and breathing off a fellow student\u2019s tank. Nothing to it.Edit: ok I see you mean as the reporter ostensibly not having any dive training, yeah, probably a bit inadvisable, but they dove with someone with experience and only at shallow depths, the danger is probably a bit overblown after a short amount of instruction. You\u2019re not gonna get bent at 15 ft.\n \nreply",
      "It\u2019s not getting bent, it\u2019s lung over expansion injury from taking a compressed air breath at depth and ascending afterward as a free diver. Yes, you could explain the danger to him, but people panic and forget.\n \nreply",
      "Except in that trained scuba situation, both divers ascend together while still breathing. If you are freediving it is possible to forget to do this, after getting air from a scuba diver.\n \nreply"
    ],
    "link": "https://www.lansingstatejournal.com/story/news/local/michigan/2024/09/22/griffon-shipwreck-great-lakes-lake-michigan-steve-kathie-libert/74956091007/",
    "first_paragraph": "In four decades of news work, I'd never reported from underwater.Last month, I donned a wetsuit and dived under Lake Michigan, a few miles off the Upper Peninsula. My guides took me to within inches of what they claim is the Great Lakes' oldest shipwreck. I shared the scene with fish and two experienced divers.Skeptics beg to differ. They say what I saw can't be the French-built Griffon, the first actual sailing ship ever to ply the Great Lakes. But the skeptics haven\u2019t gone down to look. I have. Now I'm a believer. But not just because I was close enough to touch the wreckage ...Steve and Kathie Libert, of Charlevoix, have devoted their lives to seeking the Griffin; or, as the French named it, Le Griffon. During careers near Washington, D.C., they used every vacation day and traveled each summer to northern Michigan. Kathie studied centuries-old documents. Steve led dive teams for more than four decades in search of the long-lost ship. They say they expect no riches, just the satisfac"
  },
  {
    "title": "SQL Tips and Tricks (github.com/ben-n93)",
    "points": 231,
    "submitter": "regexman1",
    "submit_time": "2024-09-25T04:20:48.000000Z",
    "num_comments": 118,
    "comments_url": "https://news.ycombinator.com/item?id=41643651",
    "comments": [
      "Ugh. Don't put opening braces on new lines.As for formatting, indent the first field, too  SELECT\n     employee_id\n  ,  employee_name\n  ,  job\n  ,  salary\n  FROM employees\n  ;\n \nreply",
      "I'll add some of mine:Learn your DB server. Check the query plans often. You might get surprised. Tweak and recheck.Usually EXISTS is faster than IN. Beware that NOT EXISTS behaves differently than EXCEPT in regards to NULL values.Instead of joining tables and using distinct or similar to filter rows, consiser using subquery \"columns\", ie in SELECT list. This can be much faster even if you're pulling 10+ values from the same table, even if your database server supports lateral joins. Just make sure the subqueries return at most one row.Any query that's not a one-off should not perform any table scans. A table scan today can mean an outage tomorrow. Add indexes. Keep in mind GROUP BY clause usually dictates index use.If you need to filter on expressions, say where a substring is equal something, you can add a computed column and index on that. Alternatively some db's support indexing expressions directly.Often using UNION ALL can be much faster than using OR, even for non-trivial queries and/or multiple OR clauses.edit: You can JOIN subqueries. This can be useful to force the filtering order if the DB isn't being clever about the order.\n \nreply",
      "The most useful thing is learning your DBMS. There's no escaping the performance and isolation quirks of each one, and there are different bonus features in each.One interesting thing I found about Postgres that's probably true of others too, often you can manually shard INSERT (SELECT ...) operations to speed them up linearly with the number of CPU cores, even when you have like 10 joins. EXPLAIN first, find the innermost or outermost join, and kick off a separate parallel query operating on each range of rows (id >= start AND id < end). For weird reasons, I relied on this a lot for one job 6 years ago. Postgres has added parallelism in versions 10+, but it's still not this advanced afaik.\n \nreply",
      "> Learn your DB server. Check the query plans often. You might get surprised. Tweak and recheck.Oftentimes the well-designed queries behave unexpectedly, because the column statistics are not updated or when the data is fragmented for big tables (e.g. random PK insertion).\n \nreply",
      "Sounds like that DBMS would work better with serial int PKs\n \nreply",
      "Instead of joining tables and using distinct or similar to filter rows, consiser using subquery \"columns\", ie in SELECT list.What does this mean? Running    SELECT\n      column1,\n      (\n        SELECT column2, column3, ...\n        FROM table_b\n        WHERE table_a.id = table_b.a_id\n      )\n    FROM table_a\n\nResults in \"subquery must return only one column\" as I expected. You mean returning the multiple columns as a record / composite type?Keep in mind GROUP BY clause usually dictates index use.The reason for this wasn't immediately apparent to me. For those who were curious, this blog post walks through it step by step: https://www.brentozar.com/archive/2015/06/indexing-for-group...\n \nreply",
      "> > Keep in mind GROUP BY clause usually dictates index use.> The reason for this wasn't immediately apparent to me.The key thing to remember is that grouping is essentially a sorting operation, and it happens before your other sorts (that last part isn't necessarily as obvious).\n \nreply",
      "Sorry, was on mobile so hadn't patience to type examples.    SELECT\n      column1,\n      (\n        SELECT column2\n        FROM table_b\n        WHERE table_a.id = table_b.a_id\n      ) as b_column2,\n      (\n        SELECT column3\n        FROM table_b\n        WHERE table_a.id = table_b.a_id\n      ) as b_column3\n    FROM table_a\n\nIt might look like a lot more work, but in my experience it's usually a lot faster. YMMV but check it.\n \nreply",
      "Would a cross apply accomplish the same result without the risk of multiple rows?Cross apply (select top 1 ... ) x\n \nreply",
      "How well that performs compared to a JOIN can vary massively depending on the data sizes of table_a & tale_b, how table_b is indexed, and what else is going on in the query.If table_b has an index on id,column2,column3 (or on id INLUDEing column2,column3) I would expect the equivalent JOIN to usually be faster. If you have a clustered index on Id (which is the case more often than not in MS SQL Server and MySQL/InnoDB) then that would count for this unless the table is much wider than those three columns (so the index with its selective data would get many rows per page more than the base data).Worst (and fairly common) case with sub-selects like that is the query planner deciding to run each subquery one per row from table_a. This is not an issue if you are only returning a few rows, or just one, from table_a, but in more complex examples (perhaps if this fragment is a CTE or view that is joined in a non-sargable manner so filtering predicates can't push down) you might find a lot more rows are processed this way even if few are eventually returned due to other filters.There are times when the method is definitely faster but be very careful with it (test with realistic data sizes and patterns) because often when it isn't, it really isn't.\n \nreply"
    ],
    "link": "https://github.com/ben-n93/SQL-tips-and-tricks",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        SQL tips and tricks\n      A (somewhat opinionated) list of SQL tips and tricks that I've picked up over the years in my job as a data analyst.Please note that some of these tips might not be relevant for all RDBMs. For example, the :: syntax (tip 5) does not work in SQLite.Use a leading comma to seperate fields in the SELECT clause rather than a trailing comma.Clearly defines that this is a new column vs code that's wrapped to multiple lines.Visual cue to easily identify if the comma is missing or not. Varying line lengths makes it harder to determine.Use a dummy value in the WHERE clause so you can dynamically add and remove conditions with ease:Indent your code to make it more readable to colleagues and your future self:For longer than I'd care to admit I would nest inline views, which would lead to\nqueries that were hard to under"
  },
  {
    "title": "Show HN: King Thirteen: 2048 with chess pieces, in under 13 KB (js13kgames.com)",
    "points": 103,
    "submitter": "animuchan",
    "submit_time": "2024-09-23T08:41:25.000000Z",
    "num_comments": 42,
    "comments_url": "https://news.ycombinator.com/item?id=41623814",
    "comments": [
      "I thought I'd lose if the king was trapped\u2014like some sort of stalemate\u2014so I played through the game with that in mind. It might make for a fun variant.I should add I didn't expect to find the rules in the Post-mortem, so I gave up on that after skimming through the page and jumped right into the game.\n \nreply",
      "This is just incredibly fun, congratulations! It reminds me of \"Really Bad Chess\" which I also love: https://play.google.com/store/apps/details?id=com.noodlecake...Two things, one on-topic and the other off-topic:The thing which makes 2048 moderately easy to reason about is that incoming pieces are always \"1\". However, this game appears to spawn in random pieces, with random point values. I tried to follow the to-and-fro of the design blog in order to find out why this is, and I get the impression it's for avoiding getting the player stuck, but it does have the disadvantage of making planning incredibly hard. The good news is that by reading the blog I finally understood what was going on with the screen shakeoff-topic: that \"Subscribe to me blog\" modal is not only bad UX (imho, of course), but also doubles down on the UX tire-fire by resetting my reading position to the top of the page. It's almost enough to warrant a command-w right there. Just one datum, but it for sure made me sad\n \nreply",
      "Thanks a lot for the kind words!I was afraid people would abandon good runs if too long, so started spawning 4 and 8 sometimes to speed it up somewhat. (There's 180-odd entries participating in the compo, so even 10 minutes of play time per entry is a huge commitment for people looking to vote on most / all games.)Re: Subscribe popup: this is the sole reason I'm looking to migrate from Hashnode! All of their UX \"improvements\" are egregious, but this one surely takes the cake. I very much agree with your sentiment.When I joined, it was a nice technical writing-oriented site, but these days it has entirely succumbed to terrible product managers. E.g. their blog post editor's main function is seemingly to upsell their generative AI wrapper.\n \nreply",
      "Thanks for sharing!I'm seconding the \"incredibly fun\" comment, but I would keep the occasional big numbers. It probably took me an hour to finish the game and I wouldn't want to slow it down further. The little extra bit of randomness/luck it adds is nice too.When it comes to the UI, I was a bit confused about how the gameover and piece removal works. I guess if there are no legal moves it removes a piece?Also, the multiple move mechanic where the last piece to move is automatically preselected sometimes tripped me up a few times and caused me to accidentally downgrade a piece.\n \nreply",
      "Every version of 2048 I've played spawns 2s and 4s. 4s are more rare.\n \nreply",
      "It would be nice to disable sound completely.When the board is almost full, it's difficult to know which pieces can move. Perhaps add some green shade to the ones that can move.\n \nreply",
      "Thanks for playing! :)Both are on the list of improvements for the final version \u2014 couldn't get the fixes in time for the compo deadline.\n \nreply",
      "I won my second game :) Then I read the instructions :)(I think it's worth reading the instructions / design discussion, even for someone that is not going to play the game.)[spoiler alert?]I didn't realize the \"combo\" mechanics, but I intuitively made many combos because I usually used the bigger piece to capture the smaller piece. So, for e it's a success in the design.Is it possible to win only with knight? My strategy was to keep alive as many queens as possible.\n \nreply",
      "Yup Knight-only was possible, but clunky. Queens sure provide a nice power spike towards the end.\n \nreply",
      "Very nice work, congrats!The combo UI just doesn't work for me. I didn't understand what was happening until reading the blog post, the game just felt broken since it was inconsistent whether a piece maintained focus or not. And even after knowing about it, I was constantly making misplays due to clickin on a unit I wanted to move, and instead having the pre-selected unit capture the clicked unit.It might be worth trying out a model where the combo piece is highlighted graphically, but you still need to first click on that unit first if you want to move it.\n \nreply"
    ],
    "link": "https://js13kgames.com/2024/games/king-thirteen",
    "first_paragraph": ""
  },
  {
    "title": "Show HN: Fast and Exact Algorithm for Image Merging (github.com/c-naoki)",
    "points": 73,
    "submitter": "C-Naoki",
    "submit_time": "2024-09-25T16:10:35.000000Z",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=41648965",
    "comments": [
      "Interesting to see something like this!My computer science masters thesis was based on the same goal. I used a 2D convolution which meant you can merge images with inexact overlaps. I had to run a high-pass filter first to limit the image details to their edges only or else the convolution incorrectly matched bright areas.In reality merging pictures is further complicated because the source images may be slightly rotated relative to each other and also due to the images being slightly curved due to lens distortion.My supervisor wanted me to do a PHD on the topic!\n \nreply",
      "I used this for several applications. Note that 2D convolution can be done efficiently using FFTs, and filtering can be combined with this very efficiently: if you see your high-pass filter as a convolution of its own, you can pre-calculate its FFT, and just multiply it almost for free in the frequency domain with the two images you want to convolve.\n \nreply",
      "That's exactly how it worked, hand rolled FFT and filtering following the method in \"Numerical Recipes for C\"\n \nreply",
      "The images might not be coplanar and the overlapping composition should be 2d planes in 3d space or go full gaussian splat.\n \nreply",
      "Thank you for your comments! For sure, the CNN is expressive for learning the characteristics of images. However, in this development, I tried to not use deep-learning because I believe that it is important to provide fast, consistent results without the need for training data. If you are particularly interested in this app, I would be glad if you could create a pull request to extend the algorithm.\n \nreply",
      "The parent comment said nothing about using deep learning. Convolution is not the same as using a CNN. I interpreted their comment as meaning they used a 2D convolution (presumably a 2D cross correlation, actually) to find regions of overlap\n \nreply",
      "Yes you're right it was a 2D cross-correlation which is very analogous to a convolution\n \nreply",
      "What are the practical applications for this tool? Typically stitching images for something like panoramas requires significantly more advanced image processing algorithms because the pixels do not perfectly overlap.\n \nreply",
      "Even in web browsers that support screenshotting an entire page, websites often unload elements that are off-screen. A solution like this can take a bunch of screen-length images and stitch them into a full view of the document.\n \nreply",
      "There are Chrome extensions that do this well already\n \nreply"
    ],
    "link": "https://github.com/C-Naoki/image-stitcher",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        This is a python implementation for stitching images.\n      \n\nThis is a python implementation for stitching images by automatically searching for overlap region.The results using CIFAR-10 are shown below. I would refer you to tutorial.ipynb for detailed results.\n\n\nFigure 1. The example of input images. The red area represents an empty region. This application can combine these images while considering their rotation.\n\n\n\nFigure 2. The preprocessed input images. This rotation process is necessary to accurately combine the images. The green frame represents the overlap region between the input images.\n\n\n\nFigure 3. The output image.\n\n\n\nFigure 4. The overview of this application in limited case.\nThis application is designed based on the overlap region's width $w_c$ and height $h_c$. Thanks to this idea, we can simply limit the search spa"
  },
  {
    "title": "ts-blank-space is a fast type-stripping compiler (bloomberg.github.io)",
    "points": 21,
    "submitter": "joatmon-snoo",
    "submit_time": "2024-09-20T12:18:24.000000Z",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=41601250",
    "comments": [
      "Cool. Reminds me of a similar program to convert python3 code to python2, which similarly converts the typing into spaces to preserve row and column numbers: https://github.com/abarker/strip-hints.\n \nreply",
      "I'm a little confused about when I'd use this, if I'm quickly iterating on code as I develop it, probably I also want to know whether it type checks, right?\n \nreply",
      "You'd already be using source maps in any real-world scenario so I am not sure what's the value proposition here outside of \"just for fun, I guess\".The tsc transpilation to lower ES versions is actually really useful when using not-so-recent Node versions. Not to mention this severely restricts TypeScript syntax to \"just types\" which isn't too bad but it means you now have to worry about yet another thing.Then there's the ESM & CJS mess. You almost always want to export in both formats which will change a lot of the syntax, so this quickly falls apart for anything serious.Just use esbuild if you want speed.\n \nreply",
      "All of your objections are addressed in the article.\n \nreply",
      "I wish enum was never part of TypeScript. It\u2019s this one odd thing unlike the rest.Am I forgetting any or is it the only feature that actually generates code rather than just being extra annotation?\n \nreply",
      "Agreed. It looks OK on the surface, but if you need enums then TS enums is going to end up in frustration.\n \nreply",
      "> Today, it appears to be the fastest emitter written in JavaScriptJavaScript is really slow though compared to golang. For that reason I prefer esbuild for type-stripping.\n \nreply",
      "This is such a simple idea that it seems like it shouldn't work. Pretty nifty.\n \nreply",
      "I am shocked to not see a reference to Taylor Swift\u2019s hit song Blank Space anywhere in the article!\n \nreply",
      "> Skipping this work is what makes this a swift approach.Hmm...\n \nreply"
    ],
    "link": "https://bloomberg.github.io/ts-blank-space/",
    "first_paragraph": "ts-blank-space is a fast type-stripping compiler that converts TypeScript to JavaScript. It supports a modern subset of TypeScript by erasing the types and replacing them with whitespace. That's it. It is not a type checker and does not perform any other code transformations.The underlying technique can improve build performance and simplify development. The implementation is pure TypeScript. It is simple enough to read and understand in a few minutes because it is only 700 lines of code and reuses the original TypeScript parser.The core idea is to use spaces as a substitute for type annotations. You can think of ts-blank-space as a reference implementation of this type-stripping technique. Much like other compiler techniques seen in the JavaScript ecosystem, such as tree-shaking, it is a reusable idea that any TypeScript compiler could implement. Some already do!Let's look at some examples. If you use the classic TypeScript (tsc) compiler today without customizing any options, you'll "
  },
  {
    "title": "Capstone Disassembler Framework (github.com/capstone-engine)",
    "points": 57,
    "submitter": "xvilka",
    "submit_time": "2024-09-25T15:48:51.000000Z",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=41648711",
    "comments": [
      "Capstone supports an impressive breadth of architectures. However, if all you need is x86/AMD64 decoding and disassembly, there are much higher quality (in terms of accurate decoding) libraries out there.I wrote a differential fuzzer for x86 decoders a few years ago, and XED and Zydis generally performed far better (in terms of accuracy) than Capstone[1]. And on the Rust side, yaxpeax and iced-x86 perform very admirably.[1]: https://blog.trailofbits.com/2019/10/31/destroying-x86_64-in...\n \nreply",
      "In my previous job, I've worked on a project that requires disassembling large amounts of x86/amd64 instructions (several billion instructions each running is very common). I've found also that Zydis is much faster than Capstone.\n \nreply",
      "How is there any discrepancy in accuracy? Isn\u2019t it just a matter of following the spec?\n \nreply",
      "Did you mean x86/x64 decoding?Looking at the libs, none of them seem to mention ARM64 inst. decoding.\n \nreply",
      "Yep, I meant AMD64, fixed.\n \nreply",
      "Another good replacement for capstone/keystone based on LLVM is nyxstone https://github.com/emproof-com/nyxstone\n \nreply",
      "It's just a wrapper around LLVM. So any project would be forced to ship also the corresponding LLVM version, if it's not present on the system - e.g. for Windows or embedded applications. A bit too much for a simple disassembler. So it's not a direct replacement for Capstone.\n \nreply",
      "It looks pretty promising! How would you compare the strengths/weaknesses?\n \nreply",
      "Capstone is very useful!Someone (not me) has also cross-compiled Capstone to WebAssembly so it can be used in client-side browser applications.https://alexaltea.github.io/capstone.js/I've used this in a couple of projects to support disassembly in static web apps with no back end.\n \nreply",
      "It's difficult to find a succinct overview. Here is a slide deck buried among links: http://www.capstone-engine.org/BHUSA2014-capstone.pdf\n \nreply"
    ],
    "link": "https://github.com/capstone-engine/capstone",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Capstone disassembly/disassembler framework for ARM, ARM64 (ARMv8), Alpha, BPF, Ethereum VM, HPPA, LoongArch, M68K, M680X, Mips, MOS65XX, PPC, RISC-V(rv32G/rv64G), SH, Sparc, SystemZ, TMS320C64X, TriCore, Webassembly, XCore and X86.\n      \n\n\nTipWelcome to join our community group! \u2002 Capstone is a disassembly framework with the target of becoming the ultimate\ndisasm engine for binary analysis and reversing in the security community.Created by Nguyen Anh Quynh, then developed and maintained by a small community,\nCapstone offers some unparalleled features:Support multiple hardware architectures: ARM, AArch64, Alpha, BPF, Ethereum VM,\nLoongArch, HP PA-RISC (HPPA), M68K, M680X, Mips, MOS65XX, PPC, RISC-V(rv32G/rv64G), SH,\nSparc, SystemZ, TMS320C64X, TriCore, Webassembly, XCore and X86 (16, 32, 64).Having clean/simple/lightweight/intuitiv"
  },
  {
    "title": "The Impact of Element Ordering on LM Agent Performance (arxiv.org)",
    "points": 23,
    "submitter": "PaulHoule",
    "submit_time": "2024-09-24T00:28:46.000000Z",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41631948",
    "comments": [
      "\"Structured token models don't work as well when you mess with the structural order of tokens\" - News at 11\n \nreply",
      "Yes, that is a finding of interest when you already know that the order of the tokens isn't relevant.\n \nreply"
    ],
    "link": "https://arxiv.org/abs/2409.12089",
    "first_paragraph": "Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n                    Get status notifications via\n                    email\n                    or slack\n"
  }
]