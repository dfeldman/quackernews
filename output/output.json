[
  {
    "title": "I'm helping my dog vibe code games (calebleak.com)",
    "points": 626,
    "submitter": "cleak",
    "submit_time": "2026-02-24T17:15:17 1771953317",
    "num_comments": 188,
    "comments_url": "https://news.ycombinator.com/item?id=47139675",
    "comments": [
      "Even a dog can vibe-code! And the apps kinda, sorta work most of the time, like most apps vibe-coded by people!I'm reminded of the old cartoon: \"On the Internet, nobody knows you're a dog.\"[a]Maybe the updated version should be: \"AI doesn't know or care if you're a dog, as long as you can bang the keys on on a computer keyboard, even if you only do it to get some delicious treats.\"This is brilliant as social commentary.Thank you for sharing it on HN.--[a] https://en.wikipedia.org/wiki/On_the_Internet%2C_nobody_know...reply",
      "Thanks for the kind words. I'm blown away by the response and positivity here.There's definitely some social commentary to be had in the whole project. I decided it's best left to the reader to find their own rather than assigning mine to it.reply",
      "[flagged]",
      "Are you OK? (Or is this AI?) Either way it'd be good for you to articulate a bit better so others understand.reply",
      "love the articleslightly concerned tomorrow morning's top HN story will be karparthy telling us how dog-based LLM interfaces are the way of the futureand you'll be left behind if you don't get in now(and then next week my boss will be demanding I do it)reply",
      "The programming workspace of the future of the future will have three employees:A man, a dog and an instance of Claude.The dog writes the prompts for Claude, the man feeds the dog, and the dog stops the man from turning off the computer.reply",
      "That was funny. Gave me good laugh. Thanks..reply",
      "Thank you for the good laugh! This whole thread is peak satire. \nAlthough, be careful. It reminds me of the foreword to a shortstory someone shared on HN recently: \u201e[\u2026] Read it and laugh, because it is very funny, and at the moment it is satire. If you\u2019re still around forty years from now, do the existing societal equivalent of reading it again, and you may find yourself laughing out of the other side of your mouth (remember mouths?). It will probably be much too conservative.\u201c \u2014 https://www.baen.com/Chapters/9781618249203/9781618249203___...reply",
      "I for one welcome our furry overlordsreply",
      "You're right. They did it. The old man and dog joke has been realized, but the real answer of the future turned out to be: \"the dog programs the game, and the man feeds the treat hopper.\"reply"
    ],
    "link": "https://www.calebleak.com/posts/dog-game/",
    "first_paragraph": "For the past few weeks I\u2019ve been teaching my 9-pound cavapoo Momo (cavalier king charles spaniel and toy poodle) to vibe code games. The key to making this work is telling Claude Code that a genius game designer who only speaks in cryptic riddles is giving it instructions, add strong guardrails, and build plenty of tools for automated feedback. The results have surpassed my expectations. Below I walk through all the pieces and how they came together.If you\u2019d rather skip ahead, all the links are at the bottom, including a full game she made and a video of her making it.Back in December I was working on a small game prototype in Godot. I use Claude Code extensively these days and this project was no exception. I kicked off a procedural mesh generation task and came back to find strange input in the terminal.My first thought was \u201cdid I get hit by one of the recent NPM supply chain attacks?\u201d Fortunately, no (or at least the worm is still asleep in the background somewhere). A little bit of"
  },
  {
    "title": "Show HN: Moonshine Open-Weights STT models \u2013 higher accuracy than WhisperLargev3 (github.com/moonshine-ai)",
    "points": 127,
    "submitter": "petewarden",
    "submit_time": "2026-02-24T21:54:07 1771970047",
    "num_comments": 23,
    "comments_url": "https://news.ycombinator.com/item?id=47143755",
    "comments": [
      "According to the OpenASR Leaderboard [1], looks like Parakeet V2/V3 and Canary-Qwen (a Qwen finetune) handily beat Moonshine. All 3 models are open, but Parakeet is the smallest of the 3. I use Parakeet V3 with Handy and it works great locally for me.[1]: https://huggingface.co/spaces/hf-audio/open_asr_leaderboardreply",
      "How much VRAM does parakeet take for you? For some reason it takes 4GB+ for me using the onyx version even though it\u2019s 600M parametersreply",
      "By the way, I've been using a Whisper model, specifically WhisperX, to do all my work, and for whatever reason I just simply was not familiar with the Handy app. I've now downloaded and used it, and what a great suggestion. Thank you for putting it here, along with the direct link to the leaderboard.I can tell that this is now definitely going to be my go-to model and app on all my clients.reply",
      "Parakeet V3 is over twice the parameter count of Moonshine Medium (600m vs 245m), so it's not an apples to apples comparison.I'm actually a little surprised they haven't added model size to that chart.reply",
      "I've helped many Twitch streamers set up https://github.com/royshil/obs-localvocal to plug transcription & translation into their streams, mainly for German audio to English subtitles.I'd love a faster and more accurate option than Whisper, but streamers need something off-the-shelf they can install in their pipeline, like an OBS plugin which can just grab the audio from their OBS audio sources.I see a couple obvious problems: this doesn't seem to support translation which is unfortunate, that's pretty key for this usecase. Also it only supports one language at a time, which is problematic with how streamers will frequently code-switch while talking to their chat in different languages or on Discord with their gameplay partners. Maybe such a plugin would be able to detect which language is spoken and route to one or the other model as needed?reply",
      "Any plans regarding JavaScript support in the browser?There was an issue with a demo but it's missing now. I can't recall for sure but I think I got it working locally myself too but then found it broke unexpectedly and I didn't manage to find out why.reply",
      "Accuracy is often presumed to be english, which is fine, but it's a vague thing to say \"higher\" because does it mean higher in English only? Higher in some subset of languages? Which ones?The minimum useful data for this stuff is a small table of language | WER for datasetreply",
      "Very cool. Anyway to run this in Web assembly, I have a project in mindreply",
      "Streaming transcription is crazy fast on an M1. Would be great to use this as a local option versus Wispr Flow.reply",
      "This is awesome, well done guys, I\u2019m gonna try it as my ASR component on the local voice assistant I\u2019ve been building https://github.com/acatovic/ova. The tiny streaming latencies you show look insanereply"
    ],
    "link": "https://github.com/moonshine-ai/moonshine",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Fast and accurate automatic speech recognition (ASR) for edge devices\n      Voice Interfaces for EveryoneMoonshine Voice is an open source AI toolkit for developers building real-time voice applications.Join our community on Discord to get live support.Listens to the microphone and prints updates to the transcript as they come in.Listens for user-defined action phrases, like \"Turn on the lights\", using semantic matching so natural language variations are recognized. For more, check out our \"Getting Started\" Colab notebook and video.Download github.com/moonshine-ai/moonshine/releases/latest/download/ios-examples.tar.gz, extract it, and then open the Transcriber/Transcriber.xcodeproj project in Xcode.Download github.com/moonshine-ai/moonshine/releases/latest/download/android-examples.tar.gz, extract it, and then open the Transcriber f"
  },
  {
    "title": "Mercury 2: The fastest reasoning LLM, powered by diffusion (inceptionlabs.ai)",
    "points": 63,
    "submitter": "fittingopposite",
    "submit_time": "2026-02-24T22:46:23 1771973183",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=47144464",
    "comments": [
      "It could be interesting to do the metric of intelligence per second.ie intelligence per token, and then tokens per secondMy current feel is that if Sonnet 4.6 was 5x faster than Opus 4.6, I'd be primarily using Sonnet 4.6. But that wasn't true for me with prior model generations, in those generations the Sonnet class models didn't feel good enough compared to the Opus class models. And it might shift again when I'm doing things that feel more intelligence bottlenecked.But fast responses have an advantage of their own, they give you faster iteration. Kind of like how I used to like OpenAI Deep Research, but then switched to o3-thinking with web search enabled after that came out because it was 80% of the thoroughness with 20% of the time, which tended to be better overall.reply",
      "Yeah I agree with this. We might be able to benchmark it soon (if we can\u2019t already) but asking different agentic code models to produce some relatively simple pieces of software. Fast models can iterate faster. Big models will write better code on the first attempt, and need less loop debugging.  Who will win?At the moment I\u2019m loving opus 4.6 but I have no idea if its extra intelligence makes it worth using over sonnet. Some data would be great!reply",
      "Interesting perspective. Perhaps also the user would adopt his queries knowing he can only to small (but very fast) steps. I wonder who would win!reply",
      "Co-founder / Chief Scientist at Inception here. If helpful, I\u2019m happy to answer technical questions about Mercury 2 or diffusion LMs more broadly.reply",
      "Seems to work pretty well, and it's especially interesting to see answers pop up so quickly!  It is easily fooled by the usual trick questions about car washes and such, but seems on par with the better open models when I ask it math/engineering questions, and is obviously much faster.reply",
      "I'm not sold on diffusion models.Other labs like Google have them but they have simply trailed the Pareto frontier for the vast majority of use casesHere's more detail on how price/performance stacks uphttps://artificialanalysis.ai/models/mercury-2reply",
      "I\u2019d push back a bit on the Pareto point.On speed/quality, diffusion has actually moved the frontier. At comparable quality levels, Mercury is >5\u00d7 faster than similar AR models (including the ones referenced on the AA page). So for a fixed quality target, you can get meaningfully higher throughput.That said, I agree diffusion models today don\u2019t yet match the very largest AR systems (Opus, Gemini Pro, etc.) on absolute intelligence. That\u2019s not surprising: we\u2019re starting from smaller models and gradually scaling up. The roadmap is to scale intelligence while preserving the large inference-time advantage.reply",
      "Comment retracted. My bad, missed some details.reply",
      "I think your comment is a bit unfair.> no reasoning comparisonBenchmarks against reasoning models:https://www.inceptionlabs.ai/blog/introducing-mercury-2> no demohttps://chat.inceptionlabs.ai/> no info on numbers of parameters for the modelThis is a closed model. Do other providers publish the number of parameters for their models?> testimonials that don't actually read like something used in productionFair point.reply",
      "You are right edited my post (twice actually). Missed the chat first time around (though its hard to see it as a reasoning model when chain of thought is hidden, or not obvious. I guess this is thd new nirmal), and also missed the reasoning table because text is pretty small on mobile and I thought its another speed benchmark.reply"
    ],
    "link": "https://www.inceptionlabs.ai/blog/introducing-mercury-2",
    "first_paragraph": "Introducing Mercury 2, the fastest reasoning LLM|Learn moreIntroducing Mercury 2, the fastest reasoning LLMModelsEnterpriseCompanyResearchTry Mercury 2Early AccessModelsEnterpriseCompanyResearchTry Mercury 2Early AccessBlog/ProductStefano ErmonCEOToday, we're introducing Mercury 2 \u2014 the world's fastest reasoning language model, built to make production AI feel instant.Production AI isn't one prompt and one answer anymore. It's loops: agents, retrieval pipelines, and extraction jobs running in the background at volume. In loops, latency doesn\u2019t show up once. It compounds across every step, every user, every retry.Yet current LLMs still share the same bottleneck: autoregressive, sequential decoding. One token at a time, left to right.Mercury 2 doesn't decode sequentially. It generates responses through parallel refinement, producing multiple tokens simultaneously and converging over a small number of steps. Less typewriter, more editor revising a full draft at once. The result: >5x faste"
  },
  {
    "title": "Hacking an old Kindle to display bus arrival times (mariannefeng.com)",
    "points": 176,
    "submitter": "mengchengfeng",
    "submit_time": "2026-02-24T19:43:34 1771962214",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=47141797",
    "comments": [
      "As someone who worked on kindle power consumption many years ago: One of the (by far) biggest consumers of power is the WiFi connection. It has to wake up and respond to the AP in order to not get disconnected every x seconds.Off the top of my head, I think 'on' average power consumption was ~700uA without wifi, and about 1.5mA+/- with Wifi. This is from over a decade ago, so my memory is fuzzy though...Obviously, page changes used relatively large amounts of power. I don't recall the exact amounts, but it was 100s of mA for seconds.There is also an \"every x pages, do a full screen refresh (black to white)\" to fix up the ghosting issue that the article writer saw.reply",
      "I removed the battery on mine, kept the battery chip and fed 5V into the battery terminals, from Kindle's USB connector, through a diode (so 4.4V-ish). Without a battery it needs something that can deliver at least 1.5A, for short bursts. An older powered usb hub seems to work fine, hub is connected to my raspberry pi, and I use ssh through usb networking, no wifi, no battery, worked fine for months now.reply",
      "Awesome tips. I'll try increasing the refresh interval to 2 minutes and turning off the wifi in between refreshes to see if helps with battery life.Side note this also finally explains to me why battery life on the Kindle is SO good in airplane mode.reply",
      "Could you adjust the refresh frequency based on your usage patterns? So refreshing less frequently outside your main transit times. An extension of your current pause at night.reply",
      "I took an even simpler route. After jailbreak and ssh I just made two scripts on the Kindle, one is triggered every minute, the other every half hour. Both draw the same image from the same location, the 30 minute one just adds a full refresh. This way the display is not fully refreshed every minute, but in time image is degrading so full refresh once every 30 minutes seems work out fine.This way Kindle has a very simple job, no apps installed no anything, just two extra cronjobs to run the oneliner bash scripts that draw the image. And I use rsync from a raspberry pi to push a new image every minute. That image is assembled with a python script, rpi side, with air quality data. Connects to local mysql server, pulls the values and then assembles it.reply",
      "> even simpler route ... rsync from a raspberry pi ... python script ... air quality data ... local mysql serverI smiledreply",
      "Ok fair enough but considering the Kindle ecosystem I'd rather deal with raspberry pi than with the Kindle stuff.reply",
      "it's simple if the other stuff is already in placereply",
      "A pretty dumb eInk display that could do one thing, that is, receive and blit a bitmap at a given location, would suffice for great many uses. It only needs a way to connect to wifi or zigbee securely, e.g. using TLS.reply",
      "Kindles are fun devices to hack and play with. I can grab an old kindle for \u20ac15-20 on eBay.I did the same last year and had lots of fun in the process.https://samkhawase.com/blog/hacking-kindle/reply"
    ],
    "link": "https://www.mariannefeng.com/portfolio/kindle/",
    "first_paragraph": ""
  },
  {
    "title": "Mac\u00a0mini will be made at a new facility in Houston (apple.com)",
    "points": 343,
    "submitter": "haunter",
    "submit_time": "2026-02-24T21:13:45 1771967625",
    "num_comments": 355,
    "comments_url": "https://news.ycombinator.com/item?id=47143152",
    "comments": [
      "Apple is very tied to Chinese manufacturing in a way that is hard to replicate in US.They will agree to make some high margin simple to assemble thing in the US to appease government, but if it goes as well as last time, they will stop as soon as they can.In china they were often able to iterate on designs and have custom screws and other parts made and ramped  up in very short times. Something about having the whole supply chain in one place and very motivated and it all fell apart when tried to move to US.So things that took weeks became hard on anytime line.. per Apple in China book.reply",
      "> Something about having the whole supply chain in one placeI can't find the source but I thought I read somewhere that the major manufacturing cities in China are all geographically laid out like giant assembly lines. The companies that process the raw materials are located mostly inland, then the companies that form those raw materials into metal and plastic stock are next door, and then the companies that take that stock and make components are next door to them, and the companies that input those components and output subassemblies are next door to them, and so on all the way down to the harbor where the companies that produce finished products output directly onto the loading docks where the ships await.The US can't even zone a residential neighborhood without lawyers and special interests jamming things up for decades through endless impact studies and litigation. How is it going to compete with a country that can lay out entire cities, organizing the value chain geographically towards the ocean?reply",
      "This reminds me of a great freakonomics podcast that talked about China being run by engineers and America being run by lawyers.https://freakonomics.com/podcast/china-is-run-by-engineers-a...reply",
      "Authoritarian central planning isn't an inherent trait of engineers and nor should we aspire for it to be.reply",
      "You don't need to brand efficiency and structure-at-scale as \"authoritarian\"; how painfully American of you. I know it's a completely foreign concept for anyone that has grown up in America, but it's actually within the realm of human possibility for the government and the individual to be aligned and want the same thing. Typically this is evidenced by tremendous social progress, which we see in evidence with the rapidly rising standard of living in China over the last few decades.It's easier when your government is proposing \"hey, let's build all the factories the best way we can\" and not \"hey, let's impose illogical and continually-changing tariffs on everything and let Howard Lutnick's kids steal all the proceeds\". You're right as an American to be skeptical of the government - it's not operating in your best interests unless you're one of the elite insiders. That doesn't mean it has to be that way.reply",
      "If that were the true secret sauce of the economic success in China, why had it not taken off before the 2000s? Like, they have been that \"aligned\" and \"want the same thing\" and \"run by engineers\" since the 50s, no?reply",
      "It kind of did. GDP per capita grew at around 6% per year from 1952-1980. It was starting from such a low base that it was still pretty low in 1980, but it was much improved. And Mao was not an engineer.reply",
      "For all the progress, you lose me immediately with the \"social credit\" system. If there was really true 'progress', then you wouldn't need a one-party system that suppresses all dissent.Only need to look to the recent changes in Hong-Kong and the obviously hostile takeover of a democratic government to see how \"pure\" these changes really are.reply",
      "Snowden's revelations showed that the same stuff exists in the US.reply",
      "> If there was really true 'progress', then you wouldn't need a one-party system that suppresses all dissent.This makes no sense. It is possible for a totalitarian government which is threatened by dissent and concepts like \"democracy\" to also work in the interest of improving overall quality of life.reply"
    ],
    "link": "https://www.apple.com/newsroom/2026/02/apple-accelerates-us-manufacturing-with-mac-mini-production/",
    "first_paragraph": "Text of this articleFebruary 24, 2026PRESS RELEASEApple accelerates U.S.\u00a0manufacturing, with Mac\u00a0mini production coming later this\u00a0yearMac mini will be made at a new facility in Houston, and a soon-to-be-launched training center will support advanced manufacturing skills developmentCUPERTINO, CALIFORNIA Apple today announced a significant expansion of factory operations in Houston, bringing the future production of Mac mini to the U.S. for the first time. The company will also expand advanced AI server manufacturing at the factory and provide hands-on training at its new Advanced Manufacturing Center beginning later this year. Altogether, Apple\u2019s Houston operations will create thousands of jobs.\u201cApple is deeply committed to the future of American manufacturing, and we\u2019re proud to significantly expand our footprint in Houston with the production of Mac mini starting later this year,\u201d said Tim Cook, Apple\u2019s CEO. \u201cWe began shipping advanced AI servers from Houston ahead of schedule, and w"
  },
  {
    "title": "Nearby Glasses (github.com/yjeanrenaud)",
    "points": 242,
    "submitter": "zingerlio",
    "submit_time": "2026-02-24T17:40:40 1771954840",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=47140042",
    "comments": [
      "https://www.cbsnews.com/news/meta-trial-mark-zuckerberg-ai-g...> Judge Carolyn Kuhl, who is presiding over the trial, ordered anyone in the courtroom wearing AI glasses to immediately remove them, noting that any use of facial recognition technology to identify the jurors was banned.I am not a believer in Zuckerberg's idea of humanity's future.reply",
      "I was actually hoping it could be paired with speech to text very well and help along with hearing aids when the latter do not perfectly work. There are legitimate use cases.reply",
      "It's pointed AT US ... not for us.reply",
      "That's because you are intentionally not included in it. Only him and his rich owning class buddies are, the rest of us are only profit-generating NPCs.reply",
      "Epstein class fits here, might as well use it.reply",
      "Tried this on a Pixel 9, after allowing permissions the Start Scanning button does nothing, and there's nothing in the debug log. I do like the idea and might try again in the future if it gets updated. Seems like a good candidate for F-Droid instead of Google Play.reply",
      "I had to tap the sprocket in the top right and enable Foreground Service to get the button to workreply",
      "On my Pixel 9 this overlaps the status bar, and can't be clicked. I worked around that by split-screening it with another app.reply",
      "I'm having the same problem on a Pixel 7reply",
      "Can the app run on smart glasses, warning you of other smart glasses users nearby? You might not see the notification on your phone.reply"
    ],
    "link": "https://github.com/yjeanrenaud/yj_nearbyglasses",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        attempting to detect smart glasses nearby and warn you\n      attempting to detect smart glasses nearby and warn you.\nThe app, called Nearby Glasses, has one sole purpose: Look for smart glasses nearby and warn you.This app notifies you when smart glasses are nearby. It uses company identificators in the Bluetooth data sent out by these. Therefore, there likely are false positives (e.g. from VR headsets). Hence, please proceed with caution when approaching a person nearby wearing glasses. They might just be regular glasses, despite this app\u2019s warning.The app\u2019s author Yves Jeanrenaud takes no liability whatsoever for this app nor it\u2019s functionality. Use at your own risk. By technical design, detecting Bluetooth LE devices might sometimes just not work as expected. I am no graduated developer. This is all written in my free time and wi"
  },
  {
    "title": "I pitched a roller coaster to Disneyland at age 10 in 1978 (wordglyph.xyz)",
    "points": 397,
    "submitter": "wordglyph",
    "submit_time": "2026-02-24T13:03:51 1771938231",
    "num_comments": 152,
    "comments_url": "https://news.ycombinator.com/item?id=47136604",
    "comments": [
      "These letters matter a lot to kids. I sent my video game idea to Nintendo as a little kid and I had the same reaction seeing that envelope from Nintendo in the mailbox addressed to me. I think it was also a bit more special pre-internet as these companies felt a bit more magical and mysterious. You can only read about them through video game magazines and see their names in the credit scenes at the end of the games. Unless you were one of those weird kids that called Nintendo Power helpline of course!I remember also receiving that weird VHS tape from Nintendo in the mail: https://www.youtube.com/watch?v=rJzIc_c1PvEI have no idea how I received that, but it was so cool!reply",
      "When I was thirteen I sent an email to Tom Fulp (creator of Newgrounds.com) telling him I wanted to make my own website with Coldfusion (which I had learned about through a pirated copy of DreamWeaver) and MySQL, and asked if would help me make it. [1]He responded back extremely politely and said that my idea seems like a great idea, but he's far too busy running Newgrounds to build any other websites right now, but once I build it he would love to see it.I never ended up building the website, but I look back and think it was cool how encouraging he was to some random kid who emailed him.Kids will pick the weirdest people as \"heroes\" sometimes, and it's cool when your heroes turn out to be decent humans.  Sometimes just responding to an email is all it takes.[1] I honestly do not remember at all what the website was supposed to be and I don't have the email anymore.  Knowing thirteen year old me, it was probably a forum about Donkey Kong Country or something.reply",
      "Six year old me sent an idea to McDonnell Douglas for an airplane with turboprops to back up the jets in case of engine fire.  There was also a fire suppression system.  They sent me some nice brochures about the DC-8, -9, and -10, but looking back on it they could have mentioned that the jets are already redundant and will usually stop burning when the fuel is cut.reply",
      "I hope they at least acknowledge that it was quite impressive for a six year old to understand the distinction between different types of engine and consider engine fires.Anyway, YC's Heart Aerospace's intended commercial airframe design now does use a turboprop as a backup (for range extension beyond the capabilities of their battery electric engine), so six year old you was clearly onto something :)reply",
      "> usuallyreply",
      "In 1997 I typed up a letter to Maxis in Microsoft Creative Writer about how much I liked their games and wanted to move to America and work at Maxis when I grew up:https://i.imgur.com/1eHcead.jpegUnfortunately I made the mistake of mentioning that it'd be cool if you could print out an image of your city in SimCity 2000, as you could in the previous SimCity game. That was enough to get me only this letter from legal as a response:https://i.imgur.com/Y2wGcRt.jpegI did grow up to become a professional game developer though!reply",
      "> \"it may be a little hard to understand\"Presumably they are implying that if they read creative suggestions, they open themselves to the possibility of being sued if they ever implemented anything similar to what was suggested. Doesn't sound too complicated to explain to a kid.reply",
      "I always thought the catch-22 was funny where they say they saw that I was suggesting an idea \u00be of the way through the letter, so they chose to return the letter without reading it.reply",
      "Since there doesn't seem to be any record in the Internet by the way, this is what printed cities looked like in SimCity 1 (these are my own scans of some printouts from 1996):https://i.imgur.com/E9QgkCp.jpeghttps://i.imgur.com/i3MYCZv.jpegreply",
      "Love that they took the time to draft a kind letter and let you down easy. Maxis cared.reply"
    ],
    "link": "https://wordglyph.xyz/one-piece-at-a-time",
    "first_paragraph": ""
  },
  {
    "title": "Corgi Labs (YC W23) Is Hiring (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2026-02-25T01:01:02 1771981262",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/corgi-labs/jobs/ZiEIf7a-founders-associate",
    "first_paragraph": "AI to increase payment acceptance and reduce fraud for businessesCorgi Labs uses proprietary AI to optimize payment acceptance, boosting revenue through superior fraud prevention. We are data-driven with an explainable AI approach for transparencyWe\u2019re looking for Founder's Associates (2 roles: 1 in US and 1 in Singapore) to work closely with the founders at Corgi Labs. This role is for someone who enjoys bringing structure to chaos and owning operational details end-to-end. You\u2019ll sit at the center of the business, across internal ops, external partners, and founder priorities, helping turn decisions into execution.We seek a Founder's Associate to work closely with the founders. This role demands bringing structure to chaos, owning end-to-end operational details, and translating decisions into execution across internal ops, external partners, and founder priorities.You will work directly with the founders to provide structure, clarity, and follow-through on the company\u2019s highest prior"
  },
  {
    "title": "Show HN: Emdash \u2013 Open-source agentic development environment (github.com/generalaction)",
    "points": 115,
    "submitter": "onecommit",
    "submit_time": "2026-02-24T18:00:37 1771956037",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=47140322",
    "comments": [
      "We are experimenting with this kind of development style and from my experience so far this shift a lot of the complexity of building into the story writing and manual testing phases.As I will need to fully handover the task and let the agent(s) essentially one-shot the implementation I need to be way for specific and clear in giving it context and goals, otherwise I\u2019m afraid it will start build code purely by accumulation creating a pile of unmanageable garbage.Also changes which requires new UI components tend to require more manual adjustments and detailed testing on the UX and general level of polishing of the experience our users expect at this stage.I\u2019m starting to develop a feeling of tasks that can be done this way and I think those more or less represent 20 to 30% of the tasks in a normal sprint. The other 70% will have diminishing returns if not actually a negative return as I will need to familiarise with the code before being able to instruct AI to improve/fix it.From your experience building this, what\u2019s your take on:1. How do your product helps in reducing the project management/requirements gathering for each individual tasks to be completed with a sufficient level of accuracy?2. Your strong point seems to be in parallelisation, but considering my previous analysis I don\u2019t see how this is a real pain for a small teams. Is this intended to be more of a tool for scale up with a stable product mostly in maintenance/enhancement mode?3. Are you imagining a way for this tool to implement some kind of automated way of actually e2e test the code of each task?reply",
      "Here's my question:if agents continue to get better with RL, what is future proof about this environment or UI?I think we all know that managing 5-10 agents ... is not pretty. Are we really landing good PRs with 100% cognitive focus from 5-10 agents? Chances are, I'm making mistakes (and I assume other humans are too)? Why not 1 agent managing 5-10 agents for you? And so on?Most of the development loop is in bash ... so as long as agents get better at using bash (amongst other things), what happens to this in 6 months?I don't think this is operating at a higher-level of abstraction if agents themselves can coordinate agents across worktrees, etc.reply",
      "Interesting thoughts - thank you! And directionally agree - given that agents are becoming ever better, they'll take more and more of the orchestration on themselves. Still, we believe that developers need an interface to interact with these agents; see their status and review / test their work. Emdash is our approach for building this interface of the future - the ADE :)reply",
      "> Still, we believe that developers need an interface to interact with these agents;CLIs like claude code equally improve over time. tmux helps running remote sessions like there were local.Why should we invest long time into your \u201eADE\u201c, really?> see their status and review / test their workWon\u2019t that be addressed eventually by the CLIs themselves?Maybe you\u2019re betting on being purchased by one of the agentic coding providers given your tool has long term value on its own?reply",
      "People use UIs for git despite it working so well in the terminal... Many people I knew at uni doing computer science wouldn\u2019t even know what tmux is. I would bet that the demand for these types of UIs is going to be a lot bigger than the demand for CLI tools like Claude Code. People already rave about cowork and the new codex UI. This falls into the same category.reply",
      "So, what's your business model ? Is this an YC product, or a tool you developed while working on a YC product ?reply",
      "We're figuring our business model out. There're two avenues that we principally think about (1) bundled coding agent subscription and (2)enterprise version with auth, team management, sharing of agent interactions. Admittedly, it's early and this can change. What won't change is that this UI layer for running multiple coding agents is and will be open-source. Emdash itself is funded by YC. Initially developed as a tool while working on another product, but we weren't funded then.reply",
      "(2) sounds like a great idea if you can ensure private company data never reaches your servers, with features like remote controlling agents from a central placereply",
      "Thank you, and yes!reply",
      "Wild how quickly developer workflows change. I went from cursor -> claude code CLI -> emdash (mix of claude code and codex now)reply"
    ],
    "link": "https://github.com/generalaction/emdash",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Emdash is the Open-Source Agentic Development Environment (\ud83e\udde1 YC W26). Run multiple coding agents in parallel. Use any provider.\n      \n\n\n\n\n\n\n\nRun multiple coding agents in parallelEmdash lets you develop and test multiple features with multiple agents in parallel. It\u2019s provider-agnostic (supports 15+ CLI agents, such as Claude Code, Qwen Code, Amp, and Codex) and runs each agent in its own Git worktree to keep changes clean; Hand off Linear, GitHub, or Jira tickets to an agent and review diffs side-by-side.Develop on remote servers via SSHConnect to remote machines via SSH/SFTP to work with remote codebases. Emdash supports SSH agent and key authentication, with secure credential storage in your OS keychain. Run agents on remote projects using the same parallel workflow as local development. Learn moreInstallation \u2022 Providers \u2022 Cont"
  },
  {
    "title": "Amazon Busted for Widespread Scheme to Inflate Prices Across the Economy (thebignewsletter.com)",
    "points": 49,
    "submitter": "toomuchtodo",
    "submit_time": "2026-02-25T01:00:45 1771981245",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.thebignewsletter.com/p/amazon-busted-for-widespread-price",
    "first_paragraph": ""
  },
  {
    "title": "Justifying Text-Wrap: Pretty (matklad.github.io)",
    "points": 13,
    "submitter": "surprisetalk",
    "submit_time": "2026-02-19T18:29:55 1771525795",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://matklad.github.io/2026/02/14/justifying-text-wrap-pretty.html",
    "first_paragraph": "\n          Something truly monumental happened in the world of software\n          development in 2025. Safari shipped a reasonable implementation of\n          text-wrap: pretty:\n          https://webkit.org/blog/16547/better-typography-with-text-wrap-pretty/.\n          We are getting closer and closer to the cutting-edge XV-century\n          technology. Beautiful paragraphs!\n        We are not quite there yet, hence the present bug report.\n          A naive way to break text into lines to form a paragraph of a given\n          width is greediness: add the next word to the current line if it fits,\n          otherwise start a new line. The result is unlikely to be pretty \u2014\n          sometimes it makes sense to try to squeeze one more word on a line to\n          make the lines more balanced overall. Johannes Gutenberg did this sort\n          of thing manually, to produce a beautiful page above. In 1981, Knuth\n          and Plass figured out a way to teach computers to do this, using\n      "
  },
  {
    "title": "Pi \u2013 a minimal terminal coding harness (pi.dev)",
    "points": 156,
    "submitter": "kristianpaul",
    "submit_time": "2026-02-24T21:53:59 1771970039",
    "num_comments": 66,
    "comments_url": "https://news.ycombinator.com/item?id=47143754",
    "comments": [
      "My current fave harness. I've been using it to great effect, since it is self-extensible, and added support for it to https://github.com/rcarmo/vibes because it is so much faster than ACP.reply",
      "Which ones have you compared it against?reply",
      "wow, i love this! was about to build this myself, but this looks exactly what i want.reply",
      "The better web UI is now part of https://github.com/rcarmo/piclaw (which is essentially the same, but with more polish and a claw-like memory system). So you can pick if you want TS or Python as the back-end :)reply",
      "if i ever want a claw, i'd obv. go with this :)reply",
      "The claw version\u2019s web UI essentially has better thinking output, more visibility of tool calls, and slightly better SSE streaming. I\u2019ve backported some of it to vibes, but if you want to borrow UI stuff, the better bits are in piclaw. I use both constantly on my phone/desktop.reply",
      "I've been using pi via the pi-coding-agent Emacs package, which uses its RPC mode to populate a pair of Markdown buffers (one for input, one for chat), which I find much nicer than the awful TUIs used by harnesses like gemini-cli (Emacs works perfectly well as a TUI too!).The extensibility is really nice. It was easy to get it using my preferred issue tracker; and I've recently overridden the built-in `read` and `write` commands to use Emacs buffers instead. I'd like to override `edit` next, but haven't figured out an approach that would play to the strengths of LLMs (i.e. not matching exact text) and Emacs (maybe using tree-sitter queries for matches?). I also gave it a general-purpose `emacs_eval`, which it has used to browse documentation with EWW.reply",
      "I haven\u2019t met a single person who has tried pi for a few days and not made it their daily driver. Once you taste the freedom of being able to set up your tool exactly how you like, there\u2019s really no going back.and you can build cool stuff on top of it too!reply",
      "What self-built capabilities do you like the most that claude code doesn't offer?reply",
      "Preconfigured PI: https://github.com/can1357/oh-my-pireply"
    ],
    "link": "https://pi.dev",
    "first_paragraph": "\n        There are many coding agents, but this one is mine.\n    \n        Pi is a minimal terminal coding harness. Adapt pi to your workflows, not the other way around. Extend it with TypeScript extensions, skills, prompt templates, and themes. Bundle them as pi packages and share via npm or git.\n    \n        Pi ships with powerful defaults but skips features like sub-agents and plan mode. Ask pi to build what you want, or install a package that does it your way.\n    \n        Four modes: interactive, print/JSON, RPC, and SDK. See clawdbot for a real-world integration.\n    \nRead the docs\n\n        Anthropic, OpenAI, Google, Azure, Bedrock, Mistral, Groq, Cerebras, xAI, Hugging Face, Kimi For Coding, MiniMax, OpenRouter, Ollama, and more. Authenticate via API keys or OAuth.\n    \n        Switch models mid-session with /model or Ctrl+L. Cycle through your favorites with Ctrl+P.\n    \n        Add custom providers and models via models.json or extensions.\n    \n        Sessions are stored as tr"
  },
  {
    "title": "Optophone (wikipedia.org)",
    "points": 36,
    "submitter": "Hooke",
    "submit_time": "2026-02-20T21:07:14 1771621634",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=47093978",
    "comments": [
      "The concept of measuring how much ink appears as the text passes a vertical slot came back again in the 1950s. MICR codes, the numbers that appear on checks, are read that way.\n[1] Or at least were in the original implementation. The ink was magnetized and the paper went past a one-track magnetic tape head. The waveform for each symbol is unique. The recognizer is more like a bar code reader than an OCR system.There are only 14 characters in that font - the digits 0-9 and four special field identification symbols. The 1970s \"futuristic\" text fonts which look like MICR symbols are purely decorative.[1] https://en.wikipedia.org/wiki/Magnetic_ink_character_recogni...reply",
      "After reading Hail Mary, I wondered how reasonable it was for someone to truly be able to understand a language based in tones / chords alone. Maybe 60 words per minute would be enough to communicate but it sure would be frustrating.reply",
      "I think you could get faster with a language actually meant to be 'sung' instead of this rough translation of english characters into audio.reply",
      "My first thought was: \u201coh, that\u2019s an interesting concept, I wonder how hard it would be to learn?\u201dThen I saw the frequency/time graph, and realised that didn\u2019t seem to have been a consideration at all. This was obviously designed by a sighted person who cared more about what the pictures looked like!Blind person: \u201cBut how do I know which letter is which?\u201d Designer: \u201cOh, that\u2019s easy! Just look at the picture!\u201dI love the idea of a sung language, though!reply",
      "Take a look at when this was invented, it's a critical detail in evaluating all this, it was 1913! They were working with the very limited technology they had, they couldn't detect the letters and map them to a particular new tone or chord that might be easier to understand, that tech just wasn't possible [0]. They had to directly translate the image of the letters on simple photo receptors into a corresponding frequency value.[0] As I was writing this I did have the wild thought that in theory if you had the weights already you could, in theory, implement a very basic character recognition neural net with analog circuitry using vacuum tubes that could recognize letters for direct mapping to sound but it's entirely impractical to create from scratch in reasonable time frames. Maybe over the span of decades you could manually tune one?reply",
      "Is this a lighthearted jab at computer vision being reduced to tokens?reply",
      "I take it this was before speak and spellreply",
      "This was before integrated circuits and was all analog.reply"
    ],
    "link": "https://en.wikipedia.org/wiki/Optophone",
    "first_paragraph": ""
  },
  {
    "title": "Hugging Face Skills (github.com/huggingface)",
    "points": 137,
    "submitter": "armcat",
    "submit_time": "2026-02-24T17:30:19 1771954219",
    "num_comments": 41,
    "comments_url": "https://news.ycombinator.com/item?id=47139902",
    "comments": [
      "Skills in CC have been a bit frustrating for me. They don't trigger reliably and the emphasis on \"it's just markdown\" makes it harder to have them reliably call certain tools with the correct arguments.The idea that agent harnesses should primarily have their functionality dictated by plaintext commands feels like a copout around programming in some actually useful, semi-opinionated functionality (not to mention that it makes capability-discoverability basically impossible). For example, Claude Code has three modes: plan, ask about edits, and auto-accept edits. I always start with a plan and then I end up with multiple tasks. I'd like to auto-accept edits for a step at a time and the only way to do that reliably is to ask CC to do that, but it's not reliable\u2014sometimes it just continues to go into the next step. If this were programmed explicitly into CC rather than relying on agent obedience, we could ditch the nondeterminism and just have a hook on task completion that toggles auto-complete back to \"off.\"reply",
      "The saving grace of Claude Code skills is that when writing them yourself, you can give them frontmatter like \"use when mentioning X\" that makes them become relevant for very specific \"shibboleths\" - which you can then use when prompting.Are we at an ideal balance where Claude Code is pulling things in proactively enough... without bringing in irrelevant skills just because the \"vibes\" might match in frontmatter? Arguably not. But it's still a powerful system.reply",
      "> idea that agent harnesses should primarily have their functionality dictated by plaintext commands feels like a copoutI think it's more along the lines of acknowledging the fast-paced changes in the field, and refusing to cast into code something that's likely to rapidly evolve in the near future.Once things settle down into tested practices, we'll see more \"permanent\" instrumentation arise.reply",
      "Surely this logic doesn't apply if we're to believe that \"code is cheap\" now :preply",
      "Behavior trees. They are precisely what we need. Somebody just needs to go build the damn thing.reply",
      "Are you using either CLAUDE.md or .claude/INSTRUCTIONS.md to direct Claude about the different agents?Also, be aware that when you add new instructions if you don't tell claude to reread these files, it will NOT have it in its context window until you tell it to read them OR you make a new CC session. This was a bit frustrating for me because it was not immediately obvious.reply",
      "You can publish scripts with skills you author, right?  With carefully constructed markdown that should allow the agent to call tools the right way.reply",
      "> sometimes it just continues to go into the next stepUse a structured workflow that loops on every task and includes a pause for user confirmation at the end. Enforce it with a hook. I'm not sure if you can toggle auto-accept this way, but I think the end result is what you're asking for.I use this with great success, sometimes toggling auto-accept on when confidence is high that Claude can complete a step without guidance, and toggling off when confidence is low and you want to slow down and steer, with Claude stopping between the steps. Now that prompt suggestions are a thing, you can just hit enter to continue on the suggested prompt to continue.reply",
      "https://scottspence.com/posts/measuring-claude-code-skill-ac... works very wellreply",
      "I think unless you're doing simple tasks, skills are unreliable. For better reliability, I have the agent trigger APIs that handles the complex logic (and its own LLM calls) internally. Has anyone found a solid strategy for making complex 'skills' more dependable?reply"
    ],
    "link": "https://github.com/huggingface/skills",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          Hugging Face Skills are definitions for AI/ML tasks like dataset creation, model training, and evaluation. They are interoperable with all major coding agent tools like OpenAI Codex, Anthropic's Claude Code, Google DeepMind's Gemini CLI, and Cursor.The Skills in this repository follow the standardized format Agent Skill format.In practice, skills are self-contained folders that package instructions, scripts, and resources together for an AI agent to use on a specific use case. Each folder includes a SKILL.md file with YAML frontmatter (name and description) followed by the guidance your coding agent follows while the skill is active.Note'Skills' is actually an Anthropic term used within Claude AI and Claude Code and not adopted by other agent tools, but we love it! OpenAI Codex uses an AGENTS.md file to define the instructions for your codin"
  },
  {
    "title": "Aesthetics of single threading (ta.fo)",
    "points": 21,
    "submitter": "todsacerdoti",
    "submit_time": "2026-02-21T20:14:13 1771704853",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://ta.fo/aesthetics-of-single-threading/",
    "first_paragraph": ""
  },
  {
    "title": "How we rebuilt Next.js with AI in one week (cloudflare.com)",
    "points": 376,
    "submitter": "ghostwriternr",
    "submit_time": "2026-02-24T20:07:00 1771963620",
    "num_comments": 129,
    "comments_url": "https://news.ycombinator.com/item?id=47142156",
    "comments": [
      "Man, I love Next ... but I also love Vite ... and I hate the Next team, because they focus on fancy new features for 0.1% of their users, at the complete expense of the other 99.9% of the Next community (who they basically ignore).This gives someone like me everything we want.  Better performance is something the Next community has been begging for for years: the Next team ignored them, but not the Cloudflare team.  Meanwhile Vite is a better core layer than the garbage the Next people use, but you still get the full Next functionality.I wish Cloudflare the best of luck with this fork: I hope it succeeds and gets proven so I can use it at my company!reply",
      "What is it you love about Next that isn\u2019t tied to Vercel and isn\u2019t available elsewhere? I love Next too but I find the value is inextricably linked to Vercel. I can\u2019t imagine choosing to use Next if I\u2019m not choosing it for Vercel\u2019s fancy stuff.reply",
      "React server components are dope. Server actions are dangerous but powerful. No one has a more mature implementation of either of these than Next.reply",
      "Of course no one has a more mature implementation of it than Next. The Next.js team designed it themselves!reply",
      "You think you'll get better long-term support from an experiment that a single engineer did in his spare time?reply",
      "Isn't that how Linux started?reply",
      "No, not at allreply",
      "Actually, that's exactly how it started: read Linus Torvalds' \"Just for Fun\".reply",
      "Was Linux owned by a large company? Was the maintainer getting paychecks from that company? Was it profit motivated? Was it released as an AI experiment?If the similarity is \"they are both open source projects\" then so are about a million others. 99.99% of them don't get any traction beyond the first week.reply",
      "The similarity is to,> You think you'll get better long-term support from an experiment that a single engineer did in his spare time?Linus started it as an experiment. That's a single engineer doing it on his spare time.Do you think Linux doesn't do long-term support right?The one changing the goal post is you.https://github.com/cloudflare/vinext It is MIT licensed. It can be used and maintained by anyone.If it'll get adoption like Linux did, that's different. But the base is there.reply"
    ],
    "link": "https://blog.cloudflare.com/vinext/",
    "first_paragraph": ""
  },
  {
    "title": "IRS Tactics Against Meta Open a New Front in the Corporate Tax Fight (nytimes.com)",
    "points": 187,
    "submitter": "mitchbob",
    "submit_time": "2026-02-24T12:58:14 1771937894",
    "num_comments": 197,
    "comments_url": "https://news.ycombinator.com/item?id=47136537",
    "comments": [
      "I wrote about this 20 years ago:http://digital-majority.wikidot.com/forum/t-5766/software-pa...In the meantime, Ireland removed their 0% tax over patent royalties, but Holland kept it at 0%.https://en.wikipedia.org/wiki/Double_Irish_arrangementreply",
      "Oh it was the EU that closed it down? didn't even know this ended as an optionreply",
      "Your 20y old site gave me https errors when I tried to click it, fyireply",
      "Don't access it over https then? The link is http.reply",
      "Don't most modern browsers automatically redirect http to https?reply",
      "No they don't. I tried Chrome, Firefox, and Safari. None of them attempted to redirect. They just show a \"not secure\" warning in the URL bar.The redirect only happens when it's configured on the web server, set in HSTS, or on a TLD that enforces HTTPS. None of these apply to this website.reply",
      "Apparently it's not on by default, but all of my browsers do and also warn me whenever a site does not support HTTPS (and require me to explicitly click through to the unencrypted connection).reply",
      "Then use a non-buggy browser...reply",
      "Works fine on my end. The HTTPS URL gives a 301 permanent redirect to HTTP, and then I ordered some boner pills and put my social security number to confirm.reply",
      "Corporation tax is so annoying, with so many r&d caveats etc. Just tax outflows.reply"
    ],
    "link": "https://www.nytimes.com/2026/02/24/business/irs-meta-corporate-taxes.html",
    "first_paragraph": ""
  },
  {
    "title": "Anthropic Drops Flagship Safety Pledge (time.com)",
    "points": 28,
    "submitter": "cwwc",
    "submit_time": "2026-02-25T01:08:46 1771981726",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=47145963",
    "comments": [
      "The IPOs this year can't come soon enough https://tomtunguz.com/spacex-openai-anthropic-ipo-2026/reply",
      "It must be due to pressure from the Defense Dept:The AI startup has refused to remove safeguards that would prevent its technology from being used to target weapons autonomously and conduct U.S. domestic surveillance.Pentagon officials have argued the government should only be required to comply with U.S. law. During the meeting, Hegseth delivered an ultimatum to Anthropic: get on board or the government would take drastic action, people familiar with the matter said.https://www.staradvertiser.com/2026/02/24/breaking-news/anth...reply",
      "Anthropic facing a lot of flak recently.reply",
      "It was always a matter of timereply"
    ],
    "link": "https://time.com/7380854/exclusive-anthropic-drops-flagship-safety-pledge/",
    "first_paragraph": "Show me more content from TIME on Google SearchCorrespondentCorrespondentAnthropic, the wildly successful AI company that has cast itself as the most safety-conscious of the top research labs, is dropping the central pledge of its flagship safety policy, company officials tell TIME.In 2023, Anthropic committed to never train an AI system unless it could guarantee in advance that the company\u2019s safety measures were adequate. For years, its leaders touted that promise\u2014the central pillar of their Responsible Scaling Policy (RSP)\u2014as evidence that they are a responsible company that would withstand market incentives to rush to develop a potentially dangerous technology.\u00a0But in recent months the company decided to radically overhaul the RSP. That decision included scrapping the promise to not release AI models if Anthropic can\u2019t guarantee proper risk mitigations in advance. \u201cWe felt that it wouldn't actually help anyone for us to stop training AI models,\u201d Anthropic\u2019s chief science officer Jar"
  },
  {
    "title": "We installed a single turnstile to feel secure (idiallo.com)",
    "points": 271,
    "submitter": "firefoxd",
    "submit_time": "2026-02-22T21:07:11 1771794431",
    "num_comments": 123,
    "comments_url": "https://news.ycombinator.com/item?id=47114678",
    "comments": [
      "I worked at a company that had effectively no physical security during work hours until the second time someone came in during lunch and stole an armload of laptops.Then we got card readers and a staffed front desk, and discovered our snack budget was too high because people from other companies on other floors were coming to ours for snacks too.I never felt the office was insecure, except in retrospect once it was actually secure.reply",
      "I once lived in Singapore for a while and we were all sure that nobody would steal anything anyway, so we just never bothered to lock the doors. (That was also very helpful if you wanted to stop for a quick coffee with a date in the middle of the night.) You could see the MacBooks from the street, but nothing ever went missing. I don\u2019t know what exactly it was, but Singapore felt incredibly safe and crime-free.reply",
      "Wait, explain the quick coffee bit? You'd let yourself into a random person's house to make coffee?reply",
      "I think it's the coffee machine at the officereply",
      "I used to accumulate a pile of change on my desk from buying coffees.Never got touched across about a hundred different offices around Australia (I\u2019m a consultant).Except once: the pile was replaced by a $50 note and a hand written apology saying the guilty party needed change for the parking lot machine. I had less than $30 there in coins so\u2026 profit!reply",
      ">I don\u2019t know what exactly it was, but Singapore felt incredibly safe and crime-free.The extreme punishments for breaking the law might have something to do with it.reply",
      "It's not actually the extreme punishments, it's the consistent small punishments. It's that you'll actually, seriously get a ticket for littering, even if it's a relatively small ticket. The \"Fine City\" enforces it's vision in a ubiquitous way, so people just don't break the rules.reply",
      "This seems like the most effective solution. Imagine if you knew that if you littered, there is a 100% chance you would get a $10 fine immediately. Almost no one would litter ever again, even though the fine is much smaller than the fine is in most countries.Problem is it just takes a lot of resources to police, more than the fine revenue. But with CCTV and computer vision it's getting increasingly cheap.reply",
      "> But with CCTV and computer vision it's getting increasingly cheap.The barrier in the US isn't cost. It's a right to privacy and a culture of distrust of government.",
      "The failings of the broken windows theory[1] would strongly disagree.[1]: https://en.wikipedia.org/wiki/Broken_windows_theory?wprov=sf...reply"
    ],
    "link": "https://idiallo.com/blog/installed-single-turnstile-for-security-theater",
    "first_paragraph": "After the acquisition by a much larger company, security became a top priority. Our company occupied three tall buildings, each at least 13 stories high. Key card readers were installed next to every entrance, every elevator car, and even at the parking lot entrance, which itself was eight stories tall.The parking lot system was activated first. If you wanted to park your car, you needed to scan your pass. It didn't take long for lines to start forming, but they were still manageable.Then the doors were activated. I would often forget my key card on my desk and get stuck in the stairwell. After lunch, I'd climb the stairs all the way to the 11th floor, only to find myself locked out at the door. Fortunately, the buildings were full of people, and there was always someone to open the door for me. I'd slip in suspiciously while they contemplated the email that clearly said not to let anyone in with your own card.While we were battling to get used to the key cards, the company was install"
  },
  {
    "title": "We Are Changing Our Developer Productivity Experiment Design (metr.org)",
    "points": 42,
    "submitter": "ej88",
    "submit_time": "2026-02-24T20:01:54 1771963314",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=47142078",
    "comments": [
      "It's kind of funny that METR is known primarily for both the most bearish study on AI progress (the original 20% slowdown one), and the most bullish one on AI progress (the long-task horizon study showing exponential increase in duration of tasks AI models can accomplish with respect to date of release).In either case, it seems people ended up bolstering their preexisting views on AI based on whichever study most affirmed them (for the former, that AI coding models didn't actually help and created a mirage of productivity that required more work to fix than was worth it, the latter that AI models were improving at an exponential rate and will invariably eclipse SWE's in all tasks in a deterministic amount of time.)I think the truth is somewhere in the middle. Just anecdotally we've seen multi-million dollar fortunes being minted by small teams developing using 90% AI-assisted coding. Anthropic claims they solely use agents to code and don't modify any code manually.reply",
      "> Anthropic claims they solely use agents to code and don't modify any code manually.Have you used CC? It shows. They did not make their fortune off this, and it\u2019s at least lost me a customer because of how sloppy it is. The model is good, and it\u2019s why they have to gate access to it. I\u2019d much rather use a different harness.I do think you\u2019re on to something though. As societal wealth further concentrates among the few, we\u2019re going to get more and more slop for the rest of us because we have no money (relatively speaking). Agentic coding is here to stay because we as a society are forced more and more slop. It\u2019s already rampant, this is just automating it.reply",
      "Really interesting updates to their 2025 experiment.Repeat devs from the original experiment went from 0-40% slowdown to now -10-40% speedup - and METR estimates this as a 'lower-bound'more devs saying they dont even want to do 50% of their work without AI, even for 50/hr30-50% of devs decided not to submit certain tasks without AI, missing the tasks with the highest upliftit also seems like there is a skill gap - repeat devs from the first study are more productive with ai tools than newly recruited ones with variable experienceoverall it seems like the high preference for devs to use AI is actually hurting METR's ability to judge their speedup, due to a refusal to do tasks without it. imo this is indirectly quite supportive for ai coding's productivity claims.reply",
      "The finding of the first study was people cannot judge their performance with these tools. So I don\u2019t think the lack of individuals not willing to work without them is indicative of productivity improvements. I think it\u2019s indicative of them being enjoyable to use.reply",
      "> When surveyed, 30% to 50% of developers told us that they were choosing not to submit some tasks because they did not want to do them without AI. This implies we are systematically missing tasks which have high expected uplift from AI.In fact, one of the developers in the original study later revealed on Twitter that he had already done exactly that during the study, i.e. filtered out tasks he prefered not to do without AI: https://xcancel.com/ruben_bloom/status/1943536052037390531While this was only one developer (that we know of), given the N was 16 and he seems to have been one of the more AI-experienced devs, this could have had a non-trivial effect on the results.The original study gets a lot of air-time from AI naysayers, let's see how much this follow-up gets ;-)reply",
      "> 3. Regarding me specifically, I work on the LessWrong codebase which is technically open-source. I feel like calling myself an \"open-source developer\" has the wrong connotations, and makes it more sound like I contribute to a highly-used Python library or something as an upper-tier developer which I'm notThat\u2019s very interesting! This kinda matches what I see at work:- low performers love it. it really does make them output more (which includes bugs, etc. it\u2019s causing some contention that\u2019s yet to be resolved)- some high performers love it. these were guys who are more into greenfield stuff and ok with 90% good. very smart, but just not interested in anything outside of going fast- everyone else seems to be finding use out of it, but reviews are painfulreply",
      "Those developer quotes are tough to read. Rate limits are going to hit like a truck when the labs eventually need to make a profit.reply",
      "At this point the AI labs would pretty much have to form an illegal price fixing cartel in order to jack the prices up, they've been competing to drive down prices for so long.They'd have to get the Chinese AI labs to go along with that price fixing too.reply",
      "They\u2019d have an entire country of geniuses prepared to defend against the antitrust allegations, who\u2019s to stop them? /sreply",
      "\"I don't want to do this without AI\" sounds like we're already well into the brain atrophy stage of this. Now what? (I'd think about it myself but....)reply"
    ],
    "link": "https://metr.org/blog/2026-02-24-uplift-update/",
    "first_paragraph": "METR previously published a paper which found the use of AI tools caused a 20% slowdown in completing tasks among experienced open-source developers, using data from February to June 2025.To understand how AI is impacting developer productivity over time, we started a new experiment in August 2025 with a larger pool of developers using the latest AI tools.Unfortunately, given participant feedback and surveys, we believe that the data from our new experiment gives us an unreliable signal of the current productivity effect of AI tools. The primary reason is that we have observed a significant increase in developers choosing not to participate in the study because they do not wish to work without AI, which likely biases downwards our estimate of AI-assisted speedup. We additionally believe there have been selection effects due to a lower pay rate (we reduced the pay from $150/hr to $50/hr), and that our measurements of time-spent on each task are unreliable for the fraction of developers "
  }
]