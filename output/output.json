[
  {
    "title": "Show HN: Unsure Calculator \u2013 back-of-a-napkin probabilistic calculator (filiph.github.io)",
    "points": 323,
    "submitter": "filiph",
    "submit_time": "2025-04-15T08:22:59 1744705379",
    "num_comments": 55,
    "comments_url": "https://news.ycombinator.com/item?id=43690289",
    "comments": [
      "I like this!In the grand HN tradition of being triggered by a word in the post and going off on a not-quite-but-basically-totally-tangential rant:There\u2019s (at least) three areas here that are footguns with these kinds of calculations:1) 95% is usually a lot wider than people think - people take 95% as \u201cI\u2019m pretty sure it\u2019s this,\u201d whereas it\u2019s really closer to \u201cit\u2019d be really surprising if it were not this\u201d - by and large people keep their mental error bars too close.2) probability is rarely truly uncorrelated - call this the \u201cMortgage Derivatives\u201d maxim. In the family example, rent is very likely to be correlated with food costs - so, if rent is high, food costs are also likely to be high. This skews the distribution - modeling with an unweighted uniform distribution will lead to you being surprised at how improbable the actual outcome was.3) In general normal distributions are rarer than people think - they tend to require some kind of constraining factor on the values to enforce. We see them a bunch in nature because there tends to be negative feedback loops all over the place, but once you leave the relatively tidy garden of Mother Nature for the chaos of human affairs, normal distributions get pretty abnormal.I like this as a tool, and I like the implementation, I\u2019ve just seen a lot of people pick up statistics for the first time and lose a finger.\n \nreply",
      "I strongly agree with this, and particularly point 1. If you ask people to provide estimated ranges for answers that they are 90% confident in, people on average produce roughly 30% confidence intervals instead. Over 90% of people don't even get to 70% confidence intervals.You can test yourself at https://blog.codinghorror.com/how-good-an-estimator-are-you/.\n \nreply",
      ">  I\u2019ve just seen a lot of people pick up statistics for the first time and lose a finger.I love this. I've never though of statistics like a power tool or firearm, but the analogy fits really well.\n \nreply",
      "I have written similar tools- for command line, fermi: https://git.nunosempere.com/NunoSempere/fermi- for android, a distribution calculator: https://f-droid.org/en/packages/com.nunosempere.distribution...People might also be interested in https://www.squiggle-language.com/, which is a more complex version (or possibly <https://git.nunosempere.com/personal/squiggle.c>, which is a faster but much more verbose version in C)\n \nreply",
      "Fermi in particular has the following syntax```5M 12M           # number of people living in Chicagobeta 1 200       # fraction of people that have a piano30 180           # minutes it takes to tune a piano, including travel time/ 48 52          # weeks a year that piano tuners work for/ 5 6            # days a week in which piano tuners work/ 6 8            # hours a day in which piano tuners work/ 60             # minutes to an hour```multiplication is implied as the default operation, fits are lognormal.\n \nreply",
      "Here is a thread with some fun fermi estimates made with that tool: e.g., number of calories NK gets from Russia: https://x.com/NunoSempere/status/1857135650404966456900K 1.5M     # tonnes of rice per year NK gets from Russia* 1K          # kg in a tone* 1.2K 1.4K   # calories per kg of rice/ 1.9K 2.5K   # daily caloric intake/ 25M 28M     # population of NK/ 365         # years of food this buys/ 1%          # as a percentage\n \nreply",
      "Another tool in this spirit is <https://carlo.app/>, which allows you to do this kind of calculation on google sheets.\n \nreply",
      "I tried the unsure calc and the android app and they seem to produce different results?\n \nreply",
      "The android app fits lognormals, and 90% rather than 95% confidence intervals. I think they are a more parsimonious distribution for doing these kinds of estimates. One hint might be that, per the central limit theorem, sums of independent variables will tend to normals, which means that products will tend to be lognormals, and for the decompositions quick estimates are most useful, multiplications are more common\n \nreply",
      "Would be nice to retransform the output into an interval / gaussian distribution   Note: If you're curious why there is a negative number (-5) in the histogram, that's just an inevitable downside of the simplicity of the Unsure Calculator. Without further knowledge, the calculator cannot know that a negative number is impossible\n\nDrake Equation or equation multiplying probabilities can also be seen in log space, where the uncertainty is on the scale of each probability, and the final probability is the product of exponential of the log probabilities. And we wouldnt have this negative issue\n \nreply"
    ],
    "link": "https://filiph.github.io/unsure/",
    "first_paragraph": "Hi, I'm Filip, and I'd like to introduce to you an early version of an uncertainty calculator.Statistics are scary, but they don't need to be. If you allow me to simplify, the field of statistics is just saying: I'm not certain about these numbers, but I would still like to reason about them. Turns out we're unsure about a lot in our lives, but we can't just throw our arms in the air and say, well, I'm not a statistician.The idea is simple: apart from regular numbers (like 4, 3.14 or 43942), you can also input ranges (like 4~6, 3.1~3.2 or 40000~45000). The character between the two extremes of the range is a tilde (~), a little wave symbol. You can find it on most keyboards, but for convenience, I also included it in the keypad above.The range notation says the following to the calculator: I am not sure about the exact number here, but I am 95% sure it's somewhere in this range.That's it. I thought long and hard about this, and I got to the conclusion that simplicity is key. Yes, we co"
  },
  {
    "title": "How dairy robots are changing work for cows and farmers (ieee.org)",
    "points": 76,
    "submitter": "DonHopkins",
    "submit_time": "2025-04-15T22:26:35 1744755995",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=43699188",
    "comments": [
      "These machines have been around for a while. There are at least nine companies selling them.[1] This started in Australia and New Zealand, which don't have much cheap labor.There's a competing approach - robotic rotary milking.[2] Rotary milkers (giant turntables with cows on them) have been around for decades, and are becoming more automated, down from four people to one.All this stuff works fine. So there's a huge milk glut.[1] https://roboticsbiz.com/top-9-best-robotic-milking-machines/[2] https://www.youtube.com/watch?v=kxhE53G3CUM\n \nreply",
      "These videos of robotic cow milking machines, feed mixers and distributers and pushers, and manure roombas are amazing!Cows like to push and play with their food to get to the yummy grain bits, so the feed robot pushes the food back so they can eat it all.And the Poopoombas had to learn to be more aggressive about pushing cows out of the way and not stopping every time they bumped or got kicked, because otherwise the cows would assign them the lowest status in the pecking order, and they could only cower in the corner.Here are the videos from the article and some more:The milking process of the Lely Astronaut A5 - EN:https://www.youtube.com/watch?v=g-zYshsAg1ETakes Dairy Farm Tourhttps://www.youtube.com/watch?v=vZY8TbBoDd0Zeta - how it works - EN - NL subtitles:https://www.youtube.com/watch?v=17TA-lI_oqQZeta - Vision film - EN - NL subtitleshttps://www.youtube.com/watch?v=8nRaj16tPLcTheir web site has a pretty cool \"page not found\" error page too:https://www.lely.com/mooNow dairy farms can use two different kinds of AI together! ;) They could develop an insemination module to go with their calving module.https://www.lely.com/solutions/latest-innovations/zeta/ai-ca...I wonder if you can rent swarms of these and dispatch them to anywhere you need them:https://www.lely.com/solutions/manure/discovery-collector/Or if you can use them in reverse, loading them up them dumping shit wherever you wanted to, like a giant Logo Turdle, in the name of art and science.\n \nreply",
      "Wonderful comment and thanks for your gift to the lexicographical world of the word Poopoombas\n \nreply",
      "Pretty primitive stuff compared to SOTA https://www.youtube.com/watch?v=8HZ4DnVfWYQ\n \nreply",
      "Maybe it\u2019s the skeptic in me, but the dude\u2019s jacket seems CGI\n \nreply",
      "Like Nikolai said, network is not so good - comp\u044fession artifact.\n \nreply",
      "It's cool that this allows the cows to be milked whenever they feel like it. I'd imagine the autonomy actually does improve the cow's quality of life. Also neat that they learned to game the feeding robot. It reminds me of the image recognition experiments they do with birds.\n \nreply",
      "Serious question: why would a dairy care about the cow's quality of life?  The setup in the video looks far more expensive than what most dairies actually do, which is keeping cows tightly confined in stalls where they can't move at all.\n \nreply",
      "My uncle has a farm, and at some point he installed a machine to hot-air dry the hay. Seemed like a huge investment to me, but turn out the cows love this hay way more than before, and therefore are producing significantly more milk, of higher quality. Higher quality milk means you can sell it more expensive.So cow's quality of life increase the quality and the quantity of milk. Moreover most farmers I know would rather have happy animals, their living depends on them !\n \nreply",
      "> why would a dairy care about the cow's quality of life?Believe it or not, most people who go into animal husbandry do so because they enjoy working with animals and care deeply about their welfare.\n \nreply"
    ],
    "link": "https://spectrum.ieee.org/lely-dairy-robots",
    "first_paragraph": "Accelerate Your Engineering Career: Subscribe to Our FREE Newsletter \u2192Everyone\u2019s happier when robots handle milking, feeding, and ear scritchingRobots are taking over much of the daily manual labor at dairy farms, including milking, feeding, cleaning, and more. It makes dairy farmers\u2019 lives easier, and makes the cows happier, too.\n\t\t\u201cMooooo.\u201d\n\t\tThis dairy barn is full of cows, as you might expect. Cows are being milked, cows are being fed, cows are being cleaned up after, and a few very happy cows are even getting vigorously scratched behind the ears. \u201cI wonder where the farmer is,\u201d remarks my guide, Jan Jacobs. Jacobs doesn\u2019t seem especially worried, though\u2014the several hundred cows in this barn are being well cared for by a small fleet of fully autonomous robots, and the farmer might not be back for hours. The robots will let him know if anything goes wrong.\n\n\tAt one of the milking robots, several cows are lined up, nose to tail, politely waiting their turn. The cows can get milked by"
  },
  {
    "title": "Mark Zuckerberg's failed negotiations with the FTC to end Meta's antitrust case (wsj.com)",
    "points": 37,
    "submitter": "ianrahman",
    "submit_time": "2025-04-15T23:51:33 1744761093",
    "num_comments": 34,
    "comments_url": "https://news.ycombinator.com/item?id=43699816",
    "comments": [
      "https://archive.ph/w58QJ",
      "Why is a fine even an acceptable resolution?Previously the FTC had been running such that, if it could not prove an acquisition was bad it would approve it.In this case, back in 2012 Instagram was small, didn't charge money, and not considered a competitor to Facebook.Well, we sure as hell know now it was a bad idea. Harmed consumer privacy, removed other competitors, and expanded the network effect of then Facebook.And before anyone says \"oh what about YouTube, X, TikTok, competitors\" - Yes they should all be split off from their parent companies too.\n \nreply",
      "Also, Facebook/Meta said they would not be able to link WhatsApp accounts to facebook accounts. After they were allowed to buy WhatsApp they unsurprisingly began using metadata for things like knowing who Facebook users are talking to.They paid some fines that they show no sign of caring about.\n \nreply",
      "My favorite was that the deal was where Facebook agreed not to import IG into FB. They have merged the two together so much so that if Facebook has a complete outage, so does IG. Not only that, but Facebook \"magically\" knows when I'm on IG and vice versa.\n \nreply",
      "Much like when a company is acquired and the execs of the acquisition assure everyone that nothing is going to change.Until it inevitably and drastically does because those execs no longer have any real power even if they weren\u2019t explicitly lying.\n \nreply",
      "Also I think if you sign up for Instagram you get Threads lolNice account you got there, would be a shame if you deleted Threads and also deletes your Insta\n \nreply",
      ">deal was where Facebook agreed not to import IG into FBWhat deal was this?\n \nreply",
      "So weird seeing him dressed up without his redpilled-Zuck-style over-sized t-shirt.\n \nreply",
      "Ed Hardy isn\u2019t a good look for him\n \nreply",
      "Assuming Mark Zuckerberg coughs up 30 billion somehow, who gets that money? Like really, and where does it go to? Serious question.\n \nreply"
    ],
    "link": "https://www.wsj.com/us-news/law/mark-zuckerberg-meta-antitrust-ftc-negotiations-a53b3382",
    "first_paragraph": ""
  },
  {
    "title": "Cursor IDE support hallucinates lockout policy, causes user cancellations (reddit.com)",
    "points": 647,
    "submitter": "scaredpelican",
    "submit_time": "2025-04-14T16:24:28 1744647868",
    "num_comments": 190,
    "comments_url": "https://news.ycombinator.com/item?id=43683012",
    "comments": [
      "There is a certain amount of irony that people try really hard to say that hallucinations are not a big problem anymore and then a company that would benefit from that narrative gets directly hurt by it.Which of course they are going to try to brush it all away. Better than admitting that this problem very much still exists and isn\u2019t going away anytime soon.\n \nreply",
      "I think that\u2019s why Apple is very slow at rolling out AI if it ever actually will. Downside is way too big than the upside.\n \nreply",
      "It's a huge problem. I just can't get past it and I get burned by it every time I try one of these products. Cursor in particular was one of the worst; the very first time I allowed it to look at my codebase, it hallucinated a missing brace (my code parsed fine), \"helpfully\" inserted it, and then proceeded to break everything. How am I supposed to trust and work with such a tool? To me, it seems like the equivalent of lobbing a live hand grenade into your codebase.Don't get me wrong, I use AI every day, but it's mostly as a localized code complete or to help me debug tricky issues. Meaning I've written and understand the code myself, and the AI is there to augment my abilities. AI works great if it's used as a deductive tool.Where it runs into issues is when it's used inductively, to create things that aren't there. When it does this, I feel the hallucinations can be off the charts -- inventing APIs, function names, entire libraries, and even entire programming languages on occasion. The AI is more than happy to deliver any kind of information you want, no matter how wrong it is.AI is not a tool, it's a tiny Kafkaesque bureaucracy inside of your codebase. Does it work today? Yes! Why does it work? Who can say! Will it work tomorrow? Fingers crossed!\n \nreply",
      "You're not supposed to trust the tool, you're supposed to review and rework the code before submitting for external review.I use AI for rather complex tasks. It's impressive. It can make a bunch of non-trivial changes to several files, and have the code compile without warnings. But I need to iterate a few times so that the code looks like what I want.That being said, I also lose time pretty regularly. There's a learning curve, and the tool would be much more useful if it was faster. It takes a few minutes to make changes, and there may be several iterations.\n \nreply",
      "1) Once you get it to output something you like, do you check all the lines it changed? Is there a threshold after which you just... hope?2) No matter what the learning curve, you're using a statistical tool that outputs in probabilities. If that's fine for your workflow/company, go for it. It's just not what a lot of developers are okay with.Of course it's a spectrum with the AI deniers in one corner and the vibe coders in the other. I personally won't be relying 100% on a tool and letting my own critical thinking atrophy, which seems to be happening, considering recent studies posted here.\n \nreply",
      "> You're not supposed to trust the tool, you're supposed to review and rework the code before submitting for external review.It sounds like the guys in this article should not have trusted AI to go fully open loop on their customer support system. That should be well understood by all \"customers\" of AI. You can't trust it to do anything correctly without human feedback/review and human quality control.\n \nreply",
      "> You're not supposed to trust the toolThis is just an incredible statement. I can't think of another development tool we'd say this about. I'm not saying you're wrong, or that it's wrong to have tools we can't just, just... wow... what a sea change.\n \nreply",
      "> I can't think of another development tool we'd say this about.Because no other dev tool actually generates unique code like AI does.  So you treat it like the other components of your team that generates code, the other developers.  Do you trust other developers to write good code without mistakes without getting it reviewed by others.  Of course not.\n \nreply",
      "Yes, actually, I do! I trust my teammates with tens of thousands of hours of experience in programming, embedded hardware, our problem spaces, etc. to write from a fully formed worldview, and for their code to work as intended (as far as anybody can tell before it enters preliminary testing by users) by the time the rest of the team reviews it. Most code review is uneventful. Have some pride in your work and you'll be amazed at what's possible.",
      "But of course everyone absolutely NEEDS to use AI for codereviews! How else could the huge volume of AI-generated code be managed?\n \nreply"
    ],
    "link": "https://old.reddit.com/r/cursor/comments/1jyy5am/psa_cursor_now_restricts_logins_to_a_single/",
    "first_paragraph": ""
  },
  {
    "title": "Generate videos in Gemini and Whisk with Veo 2 (blog.google)",
    "points": 219,
    "submitter": "meetpateltech",
    "submit_time": "2025-04-15T17:02:16 1744736536",
    "num_comments": 85,
    "comments_url": "https://news.ycombinator.com/item?id=43695592",
    "comments": [
      "Whisk itself (https://labs.google/fx/tools/whisk) was released a few months ago under the radar as a demo for Imagen 3 and it's actually fun to play with and surprisingly robust given its particular implementation.It uses a prompt transmutation trick (convert the uploaded images into a textual description; can verify by viewing the description of the uploaded image) and the strength of Imagen 3's actually modern text encoder to be able to adhere to those long transmuted descriptions for Subject/Scene/Style.\n \nreply",
      "Why text? why not encode the image into some latent space representation, so that it can survive a round-trip more or less faithfully?\n \nreply",
      "Because Imagen 3 is a text-to-image model, not an image-to-image model, so the inputs have to be some form of text. Multimodal models such as 4o image generation or Gemini 2.0 which can take in both text and image inputs do encode image inputs to a latent space through a Vision Transformer, but not reverseable or losslessly.\n \nreply",
      "There\u2019s a thing called CLIP Vision that sort of does that, but it converts the image into conditioning space (the same space as the embeddings from a text prompt). I\u2019d say it works\u2026 OK.\n \nreply",
      "They don't want you to modify images you supply yourself.\n \nreply",
      "Text might honestly be the best latent space representation.\n \nreply",
      "> This tool isn\u2019t available in your country yet> Enter your email to be notified when it becomes available(Submit)> We can't collect your emails at the moment\n \nreply",
      "This is amazing. I wouldn't think that something as computationally expensive as generating 8 second videos would be available outside of paid API anytime soon.\n \nreply",
      "I think I would buy \"yes\" shares in a Polymarket event that predicts a motion picture created by a single person grossing more than $100M by 2027.\n \nreply",
      "Everyone keeps ignoring supply and demand when talking about the impacts of AI. Let's just assume it really gets so good you can do this and it doesn't suck.Yes the costs will get so low that there will be almost no barrier to making content but if there is no barrier to making content, the ROI will be massive, and so everyone will be doing it, you can more or less have the exact movie you want in your head on demand, and even if you want a bespoke movie from an artist with great taste and a point of view there will be 10,000 of them every year.\n \nreply"
    ],
    "link": "https://blog.google/products/gemini/video-generation/",
    "first_paragraph": "Apr 15, 2025[[read-time]] min read\n          Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate to turn images into eight-second animated clips. Both features are available to Google One AI Premium subscribers.\n        Starting today, Gemini Advanced users can generate and share videos using our state-of-the-art video model, Veo 2. In Gemini, you can now translate text-based prompts into dynamic videos. Google Labs is also making Veo 2 available through Whisk, a generative AI experiment that allows you to create new images using both text and image prompts, and now animate them into videos.Veo 2 represents a leap forward in video generation, designed to produce high-resolution, detailed videos with cinematic realism. By better understanding real-world physics and human motion, it delivers fluid character movement, lifelike scenes and finer visual details across diverse subjects and styles.To generate videos, select Veo 2 from "
  },
  {
    "title": "Clolog (github.com/bobschrag)",
    "points": 187,
    "submitter": "todsacerdoti",
    "submit_time": "2025-04-15T17:04:47 1744736687",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=43695620",
    "comments": [
      "Very cool! I just cloned the repository, will play with it later.BTW, Clojure was such a brilliant name (from Rich): Whenever I see a project starting with \"Clo\" I pay attention.EDIT: had a chance to try it: a very cool resource!\n \nreply",
      "> Whenever I see a project starting with \"Clo\" I pay attention.You're going to love my \"Cobol in Clojure\" project \"Clobol\" then!\n \nreply",
      "\"Surely this is a joke,\" I thought as I read this.Then I did a Google search just to make sure...\n \nreply",
      "> Clojure was such a brilliant nameIIRC Rich wanted a name that has CLR and J in it - Clojure initially was officially to be supported on both .Net and Java stacks. Later he realized that keeping it completely compatible on both platforms is an uphill battle. CLR Clojure still exists, but it's not \"an officially supported\" runtime.\n \nreply",
      "really happy to see something of a revival of interest for logic programming lately. it's an extremely powerful tool if you know when to reach for it.\n \nreply",
      "When would you reach for it?\n \nreply",
      "Scheduling, e.g., course scheduling - allocating rooms, professors, time slots while satisfying constraints; Product configuration systems - helping customers select compatible options for complex products; Genealogical research - querying family relationships and ancestry; Static analysis tools for code - finding bugs or verifying properties without execution; Medical diagnosis systems - inferring conditions from symptoms based on medical knowledge; Travel planning - finding optimal routes with multiple constraints; Legal reasoning systems - determining applicability of laws to specific cases; Natural language interfaces - parsing questions and generating appropriate database queries; Hardware verification - proving correctness of circuit designs;  Puzzle solvers - Sudoku, crosswords, logic puzzles;Basically anything that excels when declarative specification of relationships is more natural than imperative algorithms.\n \nreply",
      "This all makes perfect sense. The gap I usually have - and I admit its probably something of a skill issue, I have relatively little formal CS background - is how these abstract declarations of rules are integrated into a product. The example code in projects like this is usually pretty dense and intangible.Does anyone have good examples of open source codebases or reading material in this area? Lets imagine I have a set of complex business rules about the way a product can be configured and I want to use a logic programming language to enforce them, called from a web interface based on config data stored in a traditional relational database. Is that... a misunderstanding of how these things are to be used?I've love a good book about how to bring tools and techniques for logical correctness into a Rails ecosystem... or similar language/framework for app dev. I love the promises many of logic languages make but can't rewrite existing applications in them wholesale and it seems like they're a poor fit for that anyways. How are people blending these worlds at large enterprises? Maybe the answer is that nobody really is yet, and thats what makes things like Clolog + Clojure so exciting?\n \nreply",
      "FWIW I have no formal CS background whatsoever (maybe you shouldn't even listen to me on this matter), but if you want to gain some understanding of rule engines, you probably shouldn't start with core.logic or clolog (I have not looked into this project myself just yet, so my assumptions might be completely misleading) - core.logic imo good for complex constrains and relationships, it's based on miniKanren, but has quite steep learning curve, and not sure if it's worth the effort (as a starting point).oakes/odoyle-rules is a forward-chaining rules engine with a more straightforward approach - for someone already familiar with Clojure, it should be fun to try out. Then maybe check out Clara Rules, if I'm not mistaken the lib is specifically designed for business rules processing. For understanding the theoretical pieces, you probably want to look into forward vs. backward chaining rule systems; pattern matching used in rules engines; understanding how to model domain rules declaratively; Rete algorithm (odoyle lib explains it and iirc links to the paper).\n \nreply",
      "Great comments, thank you for taking the time to mentor a few interested strangers.\n \nreply"
    ],
    "link": "https://github.com/bobschrag/clolog",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Full-featured logic programming (AKA \"Prolog\") embedded in/callable from and supporting calls to Clojure. In the spirit of LogLisp, Lisp Machine Prolog, and Franz Inc.'s Allegro Prolog, with some extra goodies.\n      Full-featured logic programming (AKA \"Prolog\") embedded in/callable\nfrom and supporting calls to Clojure.  In the spirit of LogLisp, Lisp\nMachine Prolog, and Franz Inc.'s Allegro Prolog, with some extra\ngoodies.  Emphasis on expressive power and execution transparency,\nsupporting rapid prototyping, proof-of-concept development, and\nouter-loop reasoning (i.e., not real fast, so far).Clojure-based, Lispy (i.e., homoiconic) syntax, e.g., ...Logical variable- (\"?var\")-containing Clojure seqs (so, lists) and\nvectors as \"complex\" terms---in assertion statements and answer templatesClojure calling predicatesTruthiness check: t"
  },
  {
    "title": "Flexport Is Hiring Software Engineers (flexport.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-04-16T01:01:11 1744765271",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://flexport.com",
    "first_paragraph": "Flexport is the platform that coordinates global logistics from factory to customer door \u2014 empowering businesses to ship anywhere, sell everywhere and grow faster.We offer ocean and air freight solutions for businesses of all sizes. Unlock the power of our global trade network to move your goods with ease. Our technology provides SKU-level visibility so you have peace of mind from origin to port. Track your shipments in real-time and manage your costs with unparalleled reliability and speed.With Flexport Customs, our expert brokers can help you clear goods quickly, minimize import duties, and leverage customs data to benefit your entire supply chain. We'll work with you even if you don\u2019t ship with us.Take the wheel of your international and domestic freight by bringing everything under one roof. As the control tower for your ground operations, we track your shipment milestones for the road ahead, from dispatch through delivery.   Flexport Fulfillment provides fast, reliable DTC and B2B"
  },
  {
    "title": "A flowing WebGL gradient, deconstructed (alexharri.com)",
    "points": 61,
    "submitter": "alexharri",
    "submit_time": "2025-04-12T10:54:53 1744455293",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=43663290",
    "comments": [
      "Very cool, but by css-rotating (skewY(-6deg)) the canvas at the last moment, you introduced aliasing on the border between the canvas and the rest of the page which kills the vibe. The browser can't automatically blend the canvas with the rest of the page. It's noticeable even on a brand new retina display. Maybe you could keep your canvas square and introduce the skew in the shader.\n \nreply",
      "Guess it depends on the browser as it looks sharp and free of aliasing for me, including when zooming in (Opera on Android)\n \nreply",
      "- Safari: decent but still obviously present\n  - Chrome: quite bad looking\n  - Firefox: something in between\n\n(tested on macOS)\n \nreply",
      ">> The mix function is an interpolation function that linearly interpolates between the two input colors using a blend factor between and ( in our case).>> A mix function for two colors works the same way, except we mix the color components. To mix two RGB colors, for example, we\u2019d mix the red, green, and blue channels.Colorspace alert! mix != lerp in sRGB\n \nreply",
      "Quite right! I think if the values were linearized (~gamma 0.5) lerp might be mostly ok though, right?And what about doing rgb->hsv, then lerp, then hsv->rgb? I'm unclear whether that also needs linearization, or whether the gamma can maybe just be done to the 'v' component before lerping?Color is a surprisingly deep and fascinating topic, that's for sure! :)\n \nreply",
      "To be fair, lerp still mixes colors, it just mixes ugly colors.\n \nreply",
      "The linked source code [0] doesn't seem to have any license attached to it. So how could I actually use this? Is it published as a package somewhere, like npm?0. https://github.com/alexharri/website/blob/eb9551dd7312685704...\n \nreply"
    ],
    "link": "https://alexharri.com/blog/webgl-gradients",
    "first_paragraph": ""
  },
  {
    "title": "Launch HN: mrge.io (YC X25) \u2013 Cursor for code review",
    "points": 169,
    "submitter": "pomarie",
    "submit_time": "2025-04-15T13:34:21 1744724061",
    "num_comments": 89,
    "comments_url": "https://news.ycombinator.com/item?id=43692476",
    "comments": [
      "There are a few of these already. Is this a land grab play, i.e. with investment get the big accounts then all the compliance ticks then dominate?AI or conventional bots for PRs are neat though. Where I work we have loads of them checking all sorts of criteria. Most are rules based. E.g. someone from this list must review if this folder changes. Kinda annoying when getting the PR in but overall great for quality control. We are using an LLM AI for commenting on potential issues too. (Sorry I don't have any influence to help them to consider yours)\n \nreply",
      "Been using this for https://github.com/cartography-cncf/cartography and am very happy, thanks for building this.Automated review tools like this are especially important for an open source project because you have to maintain a quality bar to keep yourself sane but if you're too picky then no one from the community will want to contribute. AI tools are like linters and have no feelings, so they will give the feedback that you as a reviewer may have been hesitant to give, and that's awesome.Oh, and on the product itself, I think it's super cool that it comes up with rules on its own to check for based on conventions and patterns that you've enforced over time. E.g. we use it to make sure that all function calls that pull from an upstream API are decorated with our standard error handler.\n \nreply",
      "Thanks for sharing that Alex! Definitely love having an AI be the strict reviewer so that the human doesn't have to\n \nreply",
      "This is an awesome direction. Few thoughts:It would be awesome if the custom rules were generalized on the fly from ongoing reviewer conversations. Imaging two devs quibble about line length in a PR, and in a future PR, the AI reminds about this convention.Would this work seamlessly with AI Engineers like Devin? I imagine so.This will be very handy for solo devs as well, even those who don't use Coding CoPilots could benefit from an AI reviewer, if it does not waste their time.Maybe there can be multiple AI models review the PR at the same time, and over time, we promote the ones whose feedback is accepted more.\n \nreply",
      "Appreciate the feedback! We currently auto-suggest custom rules based on your comment history (and .cursorrules), however continuing to suggest from history is now on the roadmap thanks to your suggestion!On working with Devin: Yes, right now we're focused on code review, so whatever AI IDE you use would work. In fact, it might even be better with autonomous tools like Devin since we focus on helping you (as a human) understand the code they've written faster.Interesting idea on multiple AI models --we were also separately toying with the idea of having different personas (security, code architecture), will keep this one in mind!\n \nreply",
      "personas sounds great!\n \nreply",
      "Line length isn't something I'd want reviewed in a PR. Typically I'd set up a linter with relevant limits and defer to that, ideally using pre-commit testing or directly in my IDE. Line length isn't an AI feature, it's largely a solved problem.\n \nreply",
      "bad example, sorry.\n \nreply",
      "These are all amazing ideas. We actually already see a lot of solo devs using mrge precisely because they want something to catch bugs before code goes live\u2014they simply don't have another pair of eyes.And I absolutely love your idea of having multiple AI models review PRs simultaneously. Benchmarking LLMs can be notoriously tricky, so a \"wisdom of the crowds\" approach across a large user base could genuinely help identify which models perform best for specific codebases or even languages. We could even imagine certain models emerging as specialists for particular types of issues.Really appreciate these suggestions!\n \nreply",
      "Threw a random PR at it\u2026 of the 11 issues it flagged, only 1 was appropriate, and that one was also caught by pylint :((mixture of 400 lines of C and 100 lines of Python)It also didn't flag the one SNAFU that really broke things (which to be fair wasn't caught by human review either, it showed in an ASAN fault in tests)\n \nreply"
    ],
    "link": "item?id=43692476",
    "first_paragraph": ""
  },
  {
    "title": "4chan Sharty Hack And Janitor Email Leak (knowyourmeme.com)",
    "points": 430,
    "submitter": "LookAtThatBacon",
    "submit_time": "2025-04-15T11:30:56 1744716656",
    "num_comments": 538,
    "comments_url": "https://news.ycombinator.com/item?id=43691334",
    "comments": [
      "I did some digging and the hacker posted which exploit he used.Apparently some boards allowed uploading PDF files, but the site never checked if the PDF file was an actual PDF file. Once a PDF file was uploaded it was passed to a version of Ghostscript from 2012 which would generate a thumbnail. So the attacker found an exploit where uploading a PDF with the right PostScript commands could give the attacker shell access.\n \nreply",
      "That checks out. Years ago I noticed a vulnerability through the photography board. You'd upload your pictures, and 4chan would display all the EXIF info next to the post.4chan's PHP code would offload that task to a well-know, but old and not very actively maintained EXIF library. Of course the thing with EXIF is that each camera vendor has their own proprietary extensions that need to be supported to make users happy. And as you'd expect from a library that parses a bunch of horrible undocumented formats in C, it's a huge insecure mess.Several heap overflows and arbitrary writes all over the place. Heap spray primitives. Lots of user controlled input since you provide your own JPEG. Everything you could want.So I wrote a little PoC out of curiosity. Crafted a little 20kB JPG that would try to allocate several GBs worth of heap spray. I submit my post, and the server dutifully times out.And that's where I'd like to say I finished my PoC and reported the vulnerability, but in fact I got stuck on a reliable ASLR bypass and lost interest (I did send an email about the library, but I don't think it was actively maintained and there was no followup)My impression from this little adventure is that 4chan never really had the maintenance and code quality it needed. Everything still seemed to be the same very old PHP code that leaked years ago (which included this same call to the vulnerable EXIF library). Just with a bunch of extra features hastily grafted and grown organically, but never dealing with the insane amount of technical debt.\n \nreply",
      "As far as I can tell, no real maintenance has happened since Poole sold the site a decade ago. Hiroyuki paid for it and then mostly forgot about it.\n \nreply",
      "The current FreeBSD version the hacker displayed was from around the time of the sale so that tracks.\n \nreply",
      "> Just with a bunch of extra features hastily grafted and grown organically, but never dealing with the insane amount of technical debt.This describes probably 95%+ of the entire software world, from enterprise, to SaaS to IoT to mobile to desktop to embedded... Everything seems to be hastily thrown together features that barely work and piles of debt that will never get fixed. It's a wonder anything actually even works. If cars (the non-software parts) were made like this, there would be millions of them breaking down by the side of the road daily.\n \nreply",
      "This is such a common hole. One of my early hacks was a forum that allowed you to upload a pfp but didn't check it was actually an image. Just upload an ASP file which is coded to provide an explorer-like interface. Found the administrator password in a text file. It was \"internet\" just like that. RDP was open. This was a hosting provider for 4000+ companies. Sent them an email. No thank you for that one.Always check what is getting uploaded.\n \nreply",
      "Uploading ASP as an image and having it execute server side is one thing.But in this case, it's subtly different.This issue relies more on a quirk of how PDF and PostScript relate (PDF is built on a subset of postscript).Imagine you had an image format which was just C which when compiled and ran produced the width, height, and then stream of RGB values to form an image. And you formalised this such that it had to have a specific structure so that if someone wanted to, they didn't have to write a C compiler, they could just pull out the key bits from this file which looks like ordinary C and produce the same result.Now imagine that your website supports uploading such image files, and you need to render them to produce a thumbnail, but instead of using a minimal implementation of the standard which doesn't need to compile the code, you go ahead and just run gcc on it and run the output.That's kind of more or less what happened here.It's worth noting here that it's not really common knowledge that PDF is basically just a subset of postscript. So it's actually a bit less surprising that these guys fell for this, as it's as if C had become some weird language nobody talks about, and GCC became known as \"that tool to wrangle that image format\" rather than a general purpose C compiler.The attackers in this case relied on some ghostscript exploits, that's true, but if you never ran the resulting C-image-format binaries, you could still get pwned through GCC exploits.\n \nreply",
      "> it's not really common knowledge that PDF is basically just a subset of postscript.Because that's not actually true?  Check out the table in the PDF specification, Appendix A, p985, listing all the PDF operators and their totally different PostScript equivalents, when there are any: https://opensource.adobe.com/dc-acrobat-sdk-docs/pdfstandard...The PDF imaging model is mostly borrowed from PostScript, though PDF's imaging model also supports partial transparency.  The actual files themselves are totally different.In this case, no PDF files were involved at all, but a PostScript file renamed to .pdf, which was used to exploit an old insecure GhostScript's PostScript execution engine (PostScript is a programming language, unlike PDF) or maybe parser:> According to S0I1337, it was done by exploiting a vulnerability on 4chan's outdated GhostScript version from 2012 by uploading a malformed PostScript file renamed to PDF to gain arbitrary code execution as 4chan didn't check if files with PDF extensions were actually PDF files -- https://wiki.soyjak.st/Great_Cuckset, see also the image in A_D_E_P_T's comment https://news.ycombinator.com/item?id=43699395\n \nreply",
      "Key word: \"basically\"Read section 2.4 of the PDF you linked for a bit of additional information on this \"bsaically\".GhostScript is a postscript interpreter which can handle PDF files by applying the relatively simple transformations described in that section of the PDF. Whether they embedded the ghostscript exploit within the PDF, or didn't, it's not particularly important for making my point.\n \nreply",
      "> Ghostscript from 2012Has there been a single year since 2012 that didn't include a new ghostscript RCE? Exposing ghostscript to the internet is dangerous.\n \nreply"
    ],
    "link": "https://knowyourmeme.com/memes/events/april-2025-4chan-sharty-hack-and-janitor-email-leak",
    "first_paragraph": "Login Now!Sign up Now!  Sakshi Rakshale \u201a\u00c4\u00a2 about 16 hours ago    Mateus Lima \u201a\u00c4\u00a2 27 days ago    Sakshi Rakshale \u201a\u00c4\u00a2 23 days ago    Sakshi Rakshale \u201a\u00c4\u00a2 about a month ago    Mateus Lima \u201a\u00c4\u00a2 about a month ago  \nSubmission\n\u00a0\n\n\n31,642\n\n\nPart of a series on\n4chan.\n[View Related Entries]\nRelated Explainer:  What's Up With Memes About 4chan Getting Hacked By The 'Sharty'? The Soyjak.Party Hack That Restored /QA/ And Leaked Janitor Emails Explained April 2025 4chan Sharty Hack And Janitor Email Leak refers to the Soyjak.party community's claimed hacking of 4chan in mid April 2025, which included the restoration of the deleted /QA/ board and leaking the emails of 4chan \"janitors,\" who are members of the site's moderation team. The attackers reportedly exploited outdated PHP code and deprecated MySQL functions in 4chan's backend, particularly in a core script named yotsuba.php, which manages post submissions and moderation. A Soyjak.Party users also shared a list of emails they claimed are assoc"
  },
  {
    "title": "Mushroom A.stiptica Bitter Compounds and Human Taste Receptor Activation (acs.org)",
    "points": 6,
    "submitter": "gnabgib",
    "submit_time": "2025-04-13T18:28:31 1744568911",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://pubs.acs.org/doi/10.1021/acs.jafc.4c12651",
    "first_paragraph": ""
  },
  {
    "title": "OpenAI is building a social network? (theverge.com)",
    "points": 112,
    "submitter": "noleary",
    "submit_time": "2025-04-15T16:08:29 1744733309",
    "num_comments": 90,
    "comments_url": "https://news.ycombinator.com/item?id=43694877",
    "comments": [
      "I haven't been happier online in the last 10 years than after I stopped checking social media. And in that miserable time it wasn't even a naked beg for training data like this.But I really don't see why anyone would even use an open ai \"social network\" in the first place.It does allow one thing for open ai. Other than training data which admittedly will probably be pretty low quality. It is a natural venue for ad sales.\n \nreply",
      "Social media is a plague, including LinkedIn. Anything that lets you follow others and/or erodes your anonymity is just different degrees of cancer waiting to happen.The best I ever enjoyed the internet was the sweet spot between dial up and DSL where I was gaming in text based/turn based games, talking on forums, and chatting using IRC.\n \nreply",
      "Oh I get one thing - other than ads. So the idea of an LLM filter to algorithmically tailor your own consumption has some utility.The logical application would be an existing social network -using- chat gpt to do this.But all the existing ones have their own models, so if they can't plug in to an existing one like goooooogle did to yahoo in the olden days, they have to start their own.That makes a certain amount of (backward) sense for them. I don't think it'll work. But there's some logic if you're looking from -their- worldview.\n \nreply",
      "The analogy is with Iain Banks\u2019 The Culture.Anyone can be anything and do anything they want in an abundant, machine assisted world.  The connections, cliques, friends and network you cultivate are more important than ever before if you want to be heard above the noise.  Sheer talent has long fallen by the wayside as a differentiator.Conversely, is live performance the new, ahem, rock star career?  In fifty years time all the lawyers and engineers and bankers will be working two jobs for minimum wage.  The real high earners will be the ones who can deliver live, unassisted art that showcases their skills with instruments and their voice.Those who are truly passionate about the law will only be able to pursue it as a barely-living-wage hobby while being advised to \u201cnot give up the night job\u201d \u2014 their main, stable source of income \u2014 as a cabaret singer.  They might be a journalist or a programmer in their twenties for fun before economics forces them to settle down and get a real, stable job: starting a rock band.\n \nreply",
      "The Culture is about a post-capitalist utopia. You\u2019re describing yet another cyberpunk-esque world where people have still have to do wage-labor to not starve.\n \nreply",
      "Naah\u2026 in the culture you could change your sex at will, something soon to be illegal.\n \nreply",
      ">One idea behind the OpenAI social prototype, we\u2019ve heard, is to have AI help people share better content. \u201cThe Grok integration with X has made everyone jealous,\u201d says someone working at another big AI lab. \u201cEspecially how people create viral tweets by getting it to say something stupid.\u201dThis would be a decent PR stunt, but would such a platform offer anything of value?It might be more valuable to set AI to the task of making the most human social platform out there.  Right now, Facebook, TikTok, Reddit, etc. are all rife with bots, spam, and generative AI junk.  Finding good content in this sea of noise is becoming increasingly difficult.  A social media platform that uses AI to filter out spam, bots, and other AI with the goal of making human content easy to access might really catch on.  Set a thief to catch thieves.Who are we kidding.  It's going to be Will Smith eating spaghetti all the way down.\n \nreply",
      "An interesting use for AI right now would be using it as a gatekeeping filter, selecting social media for quality based on customisable definitions of quality.Using it as a filter instead of a generator would provide information about which content has real social value, which content doesn't, and what the many dimensions of \"value\" are.The current maximalist \"Use AI to generate as much as possible\" trend is the opposite of social intelligence.\n \nreply",
      "Why would AI be any better at filtering out spam than developers have so far been with ML?The only way to avoid spam is to actually make a social network for humans, and the only way to do so is to verify each account belongs to a single human. The only way I've found that this can be done is by using passports[0].0 - https://onlyhumanhub.com\n \nreply",
      "How do you handle binationals who might not have the same details (or even name) on each of their passports?\n \nreply"
    ],
    "link": "https://www.theverge.com/openai/648130/openai-social-network-x-competitor",
    "first_paragraph": "Is Sam Altman ready to up his rivalry with Elon Musk and Mark Zuckerberg?Is Sam Altman ready to up his rivalry with Elon Musk and Mark Zuckerberg?by  Kylie Robison and  Alex HeathOpenAI is working on its own X-like social network, according to multiple sources familiar with the matter.While the project is still in early stages, we\u2019re told there\u2019s an internal prototype focused on ChatGPT\u2019s image generation that has a social feed. CEO Sam Altman has been privately asking outsiders for feedback about the project, our sources say. It\u2019s unclear if OpenAI\u2019s plan is to release the social network as a separate app or integrate it into ChatGPT, which became the most downloaded app globally last month. An OpenAI spokesperson didn\u2019t respond in time for publication.Launching a social network in or around ChatGPT would likely increase Altman\u2019s already-bitter rivalry with Elon Musk. In February, after Musk made an unsolicited offer to purchase OpenAI for $97.4 billion, Altman responded: \u201cno thank yo"
  },
  {
    "title": "Canadian math prodigy allegedly stole $65M in crypto (theglobeandmail.com)",
    "points": 155,
    "submitter": "bookmtn",
    "submit_time": "2025-04-14T14:21:36 1744640496",
    "num_comments": 202,
    "comments_url": "https://news.ycombinator.com/item?id=43681658",
    "comments": [
      "He did not steal anything. He beat the fund (Indexed Finance) at their own game.He has not stolen anybody's password, has not modified DeFI code - simply executed a set of financial transactions according to the rules (expressed as DeFI smart contracts) and profited from it.Indexed Finance is an unlicensed investment firm. The promoters knew the risk ( decentralized finance) and now they want to blame someone who outsmarted them at their own game.\n \nreply",
      "This. If you believe in cryptocurrencies, you can't run to the courts when people use them as designed, even if they didn't use them as intended.If you end up using the legal system to remediate undesired transactions, what's the point of cryptocurrencies in the first place?\n \nreply",
      "Just because some subsets of the crypto industry want to operate entirely outside the law doesn't mean the whole industry wants to operate outside the law. As evidenced by anyone who pays taxes on their crypto.Saying \"he used the system as it was designed, even if not as intended\" is more or less equivalent to saying that any computer hack or zero day is also \"using the computer system as designed\".You even plausibly extend that to picking locks in the physical world.So yes, it does make sense for the law to get involved.\n \nreply",
      "> what's the point of cryptocurrencies in the first place?So far, to execute illegal transactions and using the lack of regulations to exploit the financially illiterate.\n \nreply",
      "I like how every attempt to legitimize cryptocurrency by the current administration has just resulted in hurting the price of cryptocoins.\n \nreply",
      "Money laundering.\n \nreply",
      "And get rich quick scams. And fraud.\n \nreply",
      "And drugs. And delivery of bribes to the sitting US president (these are not the same as illegal transactions because when the president does it it is not illegal).\n \nreply",
      "I posted the original comment everyone is replying to so it's clear I'm not fan of crypto. To be fair, literally everyone I've ever known, including myself, has only ever used cash to buy drugs. I can't put that on crypto.\n \nreply",
      "For online sales of drugs it\u2019s through crypto. Also, it\u2019s the preferred way of paying ransom these days.\n \nreply"
    ],
    "link": "https://www.theglobeandmail.com/business/economy/article-math-prodigy-cryptocurrency-enforcement-united-states/",
    "first_paragraph": "A Canadian math prodigy allegedly stole US$65-million in crypto. Now he's on the lam from U.S. authoritiesAndean Medjedovic was 18 years old when he made a decision that would irrevocably alter the course of his life.In the fall of 2021, shortly after completing a master\u2019s degree at the University of Waterloo, the math prodigy and cryptocurrency trader from Hamilton had conducted a complex series of transactions designed to exploit a vulnerability in the code of a decentralized finance platform. The manoeuvre had allegedly allowed him to siphon approximately US$16.5-million in digital tokens out of two liquidity pools operated by the platform, Indexed Finance, according to a U.S. court document.Indexed Finance\u2019s leaders traced the attack back to Mr. Medjedovic, and made him an offer: Return 90 per cent of the funds, keep the rest as a so-called \u201cbug bounty\u201d \u2013 a reward for having identified an error in the code \u2013 and all would be forgiven. Mr. Medjedovic would then be free to launch his"
  },
  {
    "title": "Show HN: Torque \u2013 A lightweight meta-assembler for any processor (benbridle.com)",
    "points": 11,
    "submitter": "benbridle",
    "submit_time": "2025-04-15T21:46:45 1744753605",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://benbridle.com/projects/torque.html",
    "first_paragraph": "Torque is a lightweight meta-assembler that provides the tools necessary to write programs for any processor architecture.For a quick overview of the language, either read the language overview section of the manual, see this example of a completed program, or skim one of the following hands-on tutorials:For a demonstration of how to write high-level optimising macros in Torque, see:Existing assemblers for embedded processors suffer from a number of issues. Assemblers tend to be poorly documented, provide languages that are clunky and verbose, be bloated and difficult to operate, and work only on one operating system. Development of C compilers is often a higher priority than the development of good assemblers.Instead of learning a new assembler for every embedded processor, it would be preferrable to instead use a single general-purpose assembler for every project. Torque was created to fill this niche.Torque is designed around the idea that any assembly language can be emulated with "
  },
  {
    "title": "JSX over the Wire (overreacted.io)",
    "points": 97,
    "submitter": "danabramov",
    "submit_time": "2025-04-15T15:56:18 1744732578",
    "num_comments": 74,
    "comments_url": "https://news.ycombinator.com/item?id=43694681",
    "comments": [
      "Really like this pattern, it\u2019s a new location of the curve of \u201chow much rendering do you give the client\u201d. In the described architecture, JSX-as-JSON provides versatility once you\u2019ve already shipped all the behavior to the client (a bunch of React components in a static JS that can be cached, the React Native example really demonstrated this well)One way to decide if this architecture is for you, is to consider where your app lands on the curve of \u201chow much rendering code should you ship to client vs. how much unhydrated data should you ship\u201d. On that curve you can find everything from fully server-rendered HTML to REST APIs and everything in between, plus some less common examples too.Fully server-rendered HTML is among the fastest to usefulness - only relying on the browser to render HTML. By contrast in traditional React server rendering is only half of the story. Since after the layout is sent a great many API calls have to happen to provide a fully hydrated page.Your sweet spot on that curve is different for every app and depends on a few factors - chiefly, your app\u2019s blend of rate-of-change (maintenance burden over time) and its interactivity.If the app will not be interactive, take advantage of fully-backend rendering of HTML since the browser\u2019s rendering code is already installed and wicked fast.If it\u2019ll be highly interactive with changes that ripple across the app, you could go all the way past plain React to a Redux/Flux-like central client-side data store.And if it\u2019ll be extremely interactive client-side (eg. Google Docs), you may wish to ship all the code to the client and have it update its local store then sync to the server in the background.But this React Server Components paradigm is surprisingly suited to a great many CRUD apps. Definitely will consider it for future projects - thanks for such a great writeup!\n \nreply",
      "This was a really compelling article Dan, and I say that as a long time l advocate of \"traditional\" server side rendering like Rails of old.I think your checklist of characteristics frames things well. it reminds me of Remix's introduction to the libraryhttps://remix.run/docs/en/main/discussion/introduction\n> Building a plain HTML form and server-side handler in a back-end heavy web framework is just as easy to do as it is in Remix. But as soon as you want to cross over into an experience with animated validation messages, focus management, and pending UI, it requires a fundamental change in the code. Typically, people build an API route and then bring in a splash of client-side JavaScript to connect the two. With Remix, you simply add some code around the existing \"server side view\" without changing how it works fundamentallyit was this argument (and a lot of playing around with challengers like htmx and JSX like syntax for Python / Go) that has brought me round to the idea that RSCs or something similar might well be the way to go.Bit of a shame seeing how poor some of the engagement has been on here and Reddit though. I thought the structure and length of the article was justified and helpful. Concerning how many peoples' responses are quite clearly covered in TFA they didn't read...\n \nreply",
      "RSC is indeed very cool.  It also serves as a superior serialization format compared to JSON.  For example, it can roundtrip basic types such as `Date` and `Map` with no extra effort.One thing I would like to see more focus on in React is returning components from server functions.  Right now, using server functions for data fetching is discouraged, but I think it has some compelling use cases.  It is especially useful when you have components that need to fetch data dynamically, but you don't want the fetch / data tied to the URL, as it would be with a typical server component.  For example, when fetching suggestions for a typeahead text input.(Self-promotion) I prototyped an API for consuming such components in an idiomatic way: https://github.com/jonathanhefner/next-remote-components.  You can see a demo: https://next-remote-components.vercel.app/.To prove the idea is viable beyond Next.js, I also ported it to the Waku framework (https://github.com/jonathanhefner/twofold-remote-components) and the Twofold framework (https://github.com/jonathanhefner/twofold-remote-components).I would love to see something like it integrated into React proper.\n \nreply",
      "Everything old is new again, and I'm not even that old to know that you can return HTML fragments from AJAX call. But this is worse from any architectural point view. Why?The old way was to return HTML fragments and add them to the DOM. There was still a separation of concern as the presentation layer on the server didn't care about the interface presented on the client. It was just data generally composed by a template library. The advent of SPA makes it so that we can reunite the presentation layer (with the template library) on the frontend and just send the data to be composed down with the request's response.The issue with this approach is to again split the frontend, but now you have two template libraries to take care of (in this case one, but on the two sides). The main advantages of having a boundary is that you can have the best representation of data for each side's logic, converting only when needs. And the conversion layer needs to be simple enough to not introduce complexity of its own. JSON is fine as it's easy to audit a parser and HTML is fine, because it's mostly used as is on the other layer. We also have binary representation, but they also have strong arguments for their use.With JSX on the server side, it's abstraction when there's no need to be. And in the wrong place to boot.\n \nreply",
      "It feels like you haven't read the article and commented on the title.>The old way was to return HTML fragments and add them to the DOM.Yes, and the problem with that is described at the end of this part: https://overreacted.io/jsx-over-the-wire/#async-xhp>JSON is fine [..] With JSX on the server side, it's abstraction when there's no need to be. And in the wrong place to boot.I really don't know what you mean; the transport literally is JSON. We're not literally sending JSX anywhere. That's also in the article. The JSON output is shown about a dozen times throughout, especially in the third part. You can search for \"JSON\" on the page. It appears 97 times.\n \nreply",
      "From the article:  Replacing innerHTML wasn\u2019t working out particularly well\u2014especially for the highly interative Ads product\u2014which made an engineer (who was not me, by the way) wonder whether it\u2019s possible to run an XHP-style \u201ctags render other tags\u201d paradigm directly on the client computer without losing state between the re-renders.\n\nHTML is still a document format, and while there's a lot of features added to browsers over the year, we still have this as the core of any web page. It's always a given that state don't survive renders. In desktop software, the process is alive while the UI is shown, so that's great for having state, but web pages started as documents, and the API reflects that. So saying that it's an issue, it's the same as saying a fork is not great for cutting.React is an abstraction over the DOM for having a better API when you're trying not to re-render. And you can then simplify the format for transferring data between server and client. Net win on both side.But the technique described in the article is like having an hammer and seeing nails everywhere. I don't see the advantages of having JSX representation of JSON objects on the server side.\n \nreply",
      ">I don't see the advantages of having JSX representation of JSON objects on the server side.That's not what we're building towards. I'm just using \"breaking JSON apart\" as a narrative device to show that Server Components componentize the UI-specific parts of the API logic (which previously lived in ad-hoc ViewModel-like parts of REST responses, or in the client codebase where REST responses get massaged).The change-up happens at this point in the article: https://overreacted.io/jsx-over-the-wire/#viewmodels-revisit...If you're interested in the \"final\" code, it's here: https://overreacted.io/jsx-over-the-wire/#final-code-slightl....It blends the previous \"JSON-building\" into components.\n \nreply",
      "I'm pointing out that this particular pattern (Server Components) is engendering more complexity than necessary.If you have a full blown SPA on the client side, you shouldn't use ViewModels as that will ties your backend API to the client. If you go for a mixed approach, then your presentation layer is on the server and it's not an API.HTMX is cognizant of this fact. What it adds are useful and nice abstractions on the basis that the interface is constructed on one end and used on the other. RSC is a complex solution for a simple problem.\n \nreply",
      "to be fair this post is enormous. if i were to try and print it on 8.5x11 it comes out to 71 pages\n \nreply",
      "I mean sure but not commenting is always an option. I don't really understand the impulse to argue with a position not expressed in the text.\n \nreply"
    ],
    "link": "https://overreacted.io/jsx-over-the-wire/",
    "first_paragraph": ""
  },
  {
    "title": "The case of the UI thread that hung in a kernel call (microsoft.com)",
    "points": 96,
    "submitter": "luu",
    "submit_time": "2025-04-15T17:13:31 1744737211",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=43695723",
    "comments": [
      "Oh I've debugged this before. Native memory allocator had a scavenge function which suspended all other threads. Managed language runtime had a stop the world phase which suspended all mutator threads. They ran at about the same time and ended up suspending each other. To fix this you need to enforce some sort of hierarchy or mutual exclusion for suspension requests.> Why you should never suspend a thread in your own process.This sounds like a good general princple but suspending threads in your own process is kind of necessary for e.g. many GC algorithms. Now imagine multiple of those runtimes running in the same process.\n \nreply",
      "> suspending threads in your own process is kind of necessary for e.g. many GC algorithmsI think this is typically done by having the compiler/runtime insert safepoints, which cooperatively yield at specified points to allow the GC to run without mutator threads being active. Done correctly, this shouldn't be subject to the problem the original post highlighted, because it doesn't rely on the OS's ability to suspend threads when they aren't expecting it.\n \nreply",
      "This is a good approach but can be tricky.\nE.g. what if your thread spends a lot of time in a tight loop, e.g. doing a big inlined matmul kernel? Since you never hit a function call you don't get safepoints that way -- you can add them to the back-edge of every loop, but that can be a bit unappetizing from a performance perspective.\n \nreply",
      "> suspending threads in your own process is kind of necessary for e.g. many GC algorithmsTrue. Maybe the more precise rule is \u201conly suspend threads for a short amount of time and don\u2019t acquire any locks while doing it\u201d?The way the .NET runtime follows this rule is it only suspends threads for a very short time. After suspending, the thread is immediately resumed if it not running managed code (in a random native library or syscall). If the thread is running managed code, the thread is hijacked by replacing either the instruction pointer or the return address with a the address of a function that will wait for the GC to finish. The thread is then immediately resumed. See the details here:https://github.com/dotnet/runtime/blob/main/docs/design/core...> Now imagine multiple of those runtimes running in the same process.Can that possibly reliably work? Sounds messy.\n \nreply",
      "I knew from seeing a title like that on microsoft.com that it was going to be a Raymond Chen post! He writes fascinating stuff.\n \nreply",
      "I had the same thought too. I wonder if this his role at Microsoft now? Kind of a human institutional knowledge repository, plus a kind of brand ambassador to the developer community, plus mentor to younger engineers, plus chronicler.I hope he keeps going, no doubt he could choose to finish up whenever he wants to.\n \nreply",
      "I thought the same thing. It\u2019s usually content that\u2019s well outside my areas of familiarity, often even outside my areas of interest. But I usually find his writing interesting enough to read through anyway, and clear enough that I can usually follow it even without familiarity with the subject matter.\n \nreply",
      "On Linux you'd do this by sending a signal to the thread you want to analyze, and then the signal handler would take the stack trace and send it back to the watchdog.The tricky part is ensuring that the signal handler code is async-signal-safe (which pretty much boils down to \"ensure you're not acquiring any locks and be careful about reentrant code\"), but at least that only has to be verified for a self-contained small function.Is there anything similar to signals on Windows?\n \nreply",
      "The closest thing is a special APC enqueued via QueueUserAPC2 [1], but that's relatively new functionality in user-mode.[1] https://learn.microsoft.com/en-us/windows/win32/api/processt...\n \nreply",
      "The 2 implies an older API, its predecessor QueueUserAPC has been around since the XP days.The older API is less like signals and more like cooperative scheduling in that it waits for the target thread to be in an \"alertable\" state before it runs (the thread executes a sleep or a wait for something)\n \nreply"
    ],
    "link": "https://devblogs.microsoft.com/oldnewthing/20250411-00/?p=111066",
    "first_paragraph": "A customer asked for help with a longstanding but low-frequency hang that they have never been able to figure out. From what they could tell, their UI thread was calling into the kernel, and the call simply hung for no apparent reason. Unfortunately, the kernel dump couldn\u2019t show a stack from user mode because the stack had been paged out. (Which makes sense, because a hung thread isn\u2019t using its stack, so once the system is under some memory pressure, that stack gets paged out.)Although we couldn\u2019t see what the code was doing in user mode, there was something unusual in the information that was present.Observe that the offending thread is Suspended. And it appears to have been suspended for over five hours.Naturally, a suspended UI thread is going to manifest itself as a hang.Functions like Suspend\u00adThread exist primarily for debuggers to use, so we asked them if they had a debugger attached to the process when they captured the kernel dump. They said that they did not.So who suspended"
  },
  {
    "title": "How the U.S. became a science superpower (steveblank.com)",
    "points": 246,
    "submitter": "groseje",
    "submit_time": "2025-04-15T13:24:39 1744723479",
    "num_comments": 259,
    "comments_url": "https://news.ycombinator.com/item?id=43692360",
    "comments": [
      "Worth reading in its entirety. The following four paragraphs, about post-WWII funding of science in Britain versus the US, are spot-on, in my view:> Britain\u2019s focused, centralized model using government research labs was created in a struggle for short-term survival. They achieved brilliant breakthroughs but lacked the scale, integration and capital needed to dominate in the post-war world.> The U.S. built a decentralized, collaborative ecosystem, one that tightly integrated massive government funding of universities for research and prototypes while private industry built the solutions in volume.> A key component of this U.S. research ecosystem was the genius of the indirect cost reimbursement system. Not only did the U.S. fund researchers in universities by paying the cost of their salaries, the U.S. gave universities money for the researchers facilities and administration. This was the secret sauce that allowed U.S. universities to build world-class labs for cutting-edge research that were the envy of the world. Scientists flocked to the U.S. causing other countries to complain of a \u201cbrain drain.\u201d> Today, U.S. universities license 3,000 patents, 3,200 copyrights and 1,600 other licenses to technology startups and existing companies. Collectively, they spin out over 1,100 science-based startups each year, which lead to countless products and tens of thousands of new jobs. This university/government ecosystem became the blueprint for modern innovation ecosystems for other countries.The author's most important point is at the very end of the OP:> In 2025, with the abandonment of U.S. government support for university research, the long run of U.S. dominance in science may be over.\n \nreply",
      "> In 2025, with the abandonment of U.S. government support for university research, the long run of U.S. dominance in science may be over.I find it amazing that this is the conclusion when earlier in the article it was stated that \"[Britain] was teetering on bankruptcy. It couldn\u2019t afford the broad and deep investments that the U.S. made.\" The US debt is starting to become an existential problem. Last year the second largest outlay behind social security was the interest payment at a trillion dollars. This is a trillion dollars that cannot be used to provide government services. Over the next 30 years the primary driver of debt will be medicare and interest payments, the former due to demographic shifts and the US being pretty unhealthy overall. Our deficit is (last I checked) projected to be 7.3% of GDP this year. That means that if congress voted to defund the entire military and the entire federal government (park services, FBI, law clerks, congressional salaries, everything) we would still have to borrow. Those two things combined are only ~25% of federal outlays.I also reject the idea that this government-university partnership is somehow perfect. Over time bureaucracy tends to increase which increases overhead. This happens in private industry, government, universities, everywhere. However, there is no failure mechanism when it comes to government-university partnerships. At least in the free market inefficient companies will eventually go defunct which frees those resources for more economically useful output. Universities will continue to become more bureaucratic so long as the government keeps sending them more money. All of these economic effects must be viewed over very long periods of time. It's not enough to setup a system, see that it produced positive results, and assume it will continue to do so 80 years later.Really this reads like a pleas from special interest groups who receive federal funding. Every special interest group will be doing this. That's the issue though. A lot of special interest groups who have a financial incentive to keep the money flowing despite the looming consequences to the USD.\n \nreply",
      "The idea that the free market will self-correct and optimize outcomes is a well-documented fantasy. Markets don\u2019t account for externalities, they concentrate wealth (and therefore political power), and they routinely underprovide merit goods like education, healthcare, and basic research (things that benefit society broadly but aren\u2019t immediately profitable).As for how to address budget issues, the solution is simple: tax the rich.\n \nreply",
      "> Markets don\u2019t account for externalitiesBut on net the externalities are just as likely to be doing more good than bad. I've yet to see anyone in the public debate tallying up the positive externalities of markets. \"They have externalities!\" is likely to be an argument in favour of free markets, without the positive externalities a free market generates we would be poorer and more uncomfortable - it doesn't take much looking to find a whole raft of spinoffs where free market activity generates positive externalities.Things like https://en.wikipedia.org/wiki/Baumol's_cost_disease where through no action of their own actors and musicians get a lot more money than in medieval times purely to represent the alternatives the market offers them.\n \nreply",
      "> The idea that the free market will self-correct and optimize outcomes is a well-documented fantasy.There are far too many documented instances of it actually working to call it a fantasy.> Markets don\u2019t account for externalitiesMarkets aren't expected to account for externalities. Externalities are the things you're supposed to tax.> they concentrate wealth (and therefore political power)You're describing regulatory capture. This is why governments are supposed to have limited powers. To keep them from passing rules that enrich cronies and entrench incumbents.> they routinely underprovide merit goods like education, healthcare, and basic research (things that benefit society broadly but aren\u2019t immediately profitable)Markets are actually pretty good at providing all of those things. There are plenty of high quality private schools, high quality private medical facilities and high quality private research labs.The real problem here is that some people can't afford those things. But now you're making the case for a UBI so people can afford those things when they otherwise couldn't, not for having the government actually operate the doctor's office.> As for how to address budget issues, the solution is simple: tax the rich.Is it so simple? The highest marginal tax rate in the US is 50.3% (37% federal + 13.3% state in California). The highest marginal tax rate in Norway is 47.4%.Meanwhile most of what the rich own are investment securities like stocks and US treasuries. What happens if you increase their taxes? They have less to invest. The stocks then go to someone not being taxed, i.e. foreign investors, so more of the future returns of US companies leave the country. Fewer treasury buyers increase the interest rate the US pays on the debt. Fewer stock buyers lower stock prices, which reduce capital gains and therefore capital gains tax revenue. Fewer stock buyers make it harder for companies to raise money, which lowers employment and wages, and therefore tax revenue again. Increasing the proportion of tax revenue that comes from \"the rich\" causes an extremely perverse incentive whenever you ask the Congressional Budget Office to do the numbers on how a policy that would transfer wealth from the rich to the middle class would affect tax revenue, and the policy correspondingly gets shelved.TANSTAAFL.\n \nreply",
      ">> There are far too many documented instances of it actually working to call it a fantasy.Markets are a tool which can work extremely well if deployed carefully and within a sensible regulatory framework. Given that the world CO2 level keeps rising, we can't eat fish because of heavy metals and we all have forever microplastics in us, I think it's fair to question some of our assumptions.>> Markets aren't expected to account for externalities. Externalities are the things you're supposed to tax.Agreed - however taxing externalities doesn't seem to be working out in practice (in the US).>> You're describing regulatory capture. This is why governments are supposed to have limited powers.Wealth inequality can rise without regulatory capture. Government is not the source of all evil. Smaller govenrment would just lead to further concentration of wealth and power within the private sector. We need a balanced system, not blind devotion.>> Markets are actually pretty good at providing all of those things... The real problem here is that some people can't afford those thingSo can the market provide those things or not? Clearly we want everyone to have an education not just the uber wealthy.\n \nreply",
      "> There are far too many documented instances of it actually working to call it a fantasy.There are no documented instances of a truly free market. The parent's point I think has less to do with \"it has been tried and it failed\" and moreso that the idea that truly free market can exist is pure fantasy.FWIW - Costa Rica is probably the greatest example of a Libertarian's dream of a free market. I would love to show any free market absolutionist the colossal amount of time it takes to just pave 500m of a road in that country.\n \nreply",
      "Im afraid you'd need to be pretty liberal with your definition of rich at this point to dig us out of this hole through taxes alone.\n \nreply",
      ">The idea that the free market will self-correct and optimize outcomes is a well-documented fantasy.Could you share some sources to back this up? At least a sources to back up at least a few case studies would be curious. I'm interested in economics and never have been aware that free market self-correction is a well documented fantasy and would love to understand where is your claim coming from.\n \nreply",
      "Libertarians took over a town in NH and abolished town wide garbage collection.  The free market produced a bunch of trash in people's yards, which attracted bears, causing havoc all around town.  True story.That's not to say you can't solve a lot of problems with markets.  It just means waving your hands at \"the free market\" like it's a magic talisman is a childish thing to do.\n \nreply"
    ],
    "link": "https://steveblank.com/2025/04/15/how-the-u-s-became-a-science-superpower/",
    "first_paragraph": "Enter your email address to subscribe to this blog and receive notifications of new posts by email.\n\n\t\t\t\t\t\t\tEmail Address\t\t\t\t\t\t\n\n\n\n\n\n\n \n\t\t\t\t\t\t\tSign me up!\t\t\t\t\t\t\nPrior to WWII the U.S was a distant second in science and engineering. By the time the war was over, U.S. science and engineering had blown past the British, and led the world for 85 years.It happened because two very different people were the science advisors to their nation\u2019s leaders. Each had radically different views on how to use their country\u2019s resources to build advanced weapon systems. Post war, it meant Britain\u2019s early lead was ephemeral while the U.S. built the foundation for a science and technology innovation ecosystem that led the world \u2013 until now.The British \u2013 Military Weapons Labs\nWhen Winston Churchill became the British prime minister in 1940, he had at his side his science advisor, Professor Frederick Lindemann, his friend for 20 years. Lindemann headed up the physics department at Oxford and was the director"
  },
  {
    "title": "Hacking the Postgres wire protocol (pgdog.dev)",
    "points": 158,
    "submitter": "levkk",
    "submit_time": "2025-04-15T14:33:10 1744727590",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=43693326",
    "comments": [
      "The best part I think is \"pg_query is special. It doesn\u2019t actually implement parsing SQL. It works by extracting C source code directly from Postgres and wraps it with a nice Rust interface. This allows PgDog to understand all queries that Postgres can.\"One of the things that puts metaprogramming on wheels is being able to pull in grammars, schemas and such for external systems.  Think how many cool tools we could have if we could do this in a more general way.\n \nreply",
      "> One of the things that puts metaprogramming on wheels is being able to pull in grammars, schemas and such for external systems.That's what I've been trying to do with: https://github.com/schemamap/schemamapFor a well-constrained Postgres schema, a deterministic SQL compiler can be built (with plenty of logic programming/constraint-solving/hypergraph-analysis) that can integrate arbitrary external systems data.While this is NP-hard, with some clever use of embeddings and ontologies, and use of every single constraint AST within the DB to reduce the search space, this becomes a feasible problem.For any Clojurists interested, I've packaged `pg_query`, so you can use it in your applications: https://github.com/schemamap/pg-query-cljAt the moment I'm saving up for the next development cycle, so not only PG->PG schema mappings can be solved for (JSON schema is next!). Hope this sounds interesting :)\n \nreply",
      "Json schema layer support sounds interesting. Truth be told I didn\u2019t immediately figure out how your project works\n \nreply",
      "I had such high hopes for tree-sitter but once it went all \"and then, $CC -c -o\" all was lost :-(\n \nreply",
      "What do you mean?\n \nreply",
      "Supabase's postgres LSP works in a similar way iirc.\n \nreply",
      "Yes, the same way. It's all based on the extremely useful `https://github.com/pganalyze/libpg_query` project, which is where the \"extracted the parser from Postgres\" part comes in.Supabase's LSP also uses tree-sitter for corrections and autocomplete, because one drawback of using the server's source is that pg_query only works on well-formed/executable SQL - when it detects a malformed query, it formulates an error and exits, since that's what you want in an SQL server. So for partially-correct syntax and fill-forward, tree-sitter covers the gaps.\n \nreply",
      "I agree. Does anyone know much heavy lifting is done by pg_query in wrapping the Postgres code vs. Postgres in expressing that code in a manner that makes pg_query possible?\n \nreply",
      "Tends to be a matter of opinion. Postgres does not expose the relevant functions, so https://github.com/pganalyze/libpg_query has to do some heavy lifting to convert their source code into a nice library. Conversely, Postgres is very well written code, in an extremely common language, with a stable release cadence, and such a long track record it is seen as the reference implementation for correctly parsing SQL.\n \nreply",
      "Yeah, as one of the main authors of libpg_query, I think the primary things that make this easier is that Postgres has good abstractions internally, and the parser works independently from other parts (e.g. the community discourages adding settings that affect parser behavior).Over the years we've only had to maintain a small set of patches on top of the Postgres source [0], together with some mocks and our libclang-based extraction logic [1]. Of course it would be nice if Postgres just packaged this directly like it packages the client libraries, but there is non-trivial effort involved to do that. From what I recall, the main issue is that error handling and memory allocations work differently in the client-side libraries (and so that would have to either also be moved out of the backend source, or use some other abstraction).[0]: https://github.com/pganalyze/libpg_query/tree/17-latest/patc...[1]: https://github.com/pganalyze/libpg_query/blob/17-latest/scri...\n \nreply"
    ],
    "link": "https://pgdog.dev/blog/hacking-postgres-wire-protocol",
    "first_paragraph": ""
  },
  {
    "title": "Chroma: Ubisoft's internal tool used to simulate color-blindness (github.com/ubisoft)",
    "points": 182,
    "submitter": "gm678",
    "submit_time": "2025-04-15T13:04:26 1744722266",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=43692089",
    "comments": [
      "Not for gaming, but this was developed for checking plots:\nhttps://github.com/hdembinski/monolensAnd works cross platform.\n \nreply",
      "Ubisoft is on the forefront for accessibility.\n \nreply",
      "The advantage of these large corporations is good stuff like this that a smaller company couldn\u2019t afford. Like how Disney World is in bending over backward to be accessible for my daughter in a wheelchair. This sort of thing is an objective good.The problem with their games is in being such big tent trying to appeal to everyone (note I\u2019m not talking about accessibility, which is a totally different axis), they feel too smoothed out and have very little interesting to say, and their games just aren\u2019t that much fun.It reminds me of that article posted on HN the other day saying that often our weaknesses and strengths are two sides of the same coin.\n \nreply",
      "Accessibility typically doesn't cost much. With many modern OS UI frameworks, you get it for free as long as you don't go out of your way to customize shit that you probably shouldn't be customizing in the first place. If you stick to standard controls and not try to use crazy ways to override user preferences, your application should be accessible to things like screen readers mostly out of the box.\n \nreply",
      "As with most things, this is an issue of education and awareness. It's not that most developers intentionally break accessibility, but rather that a very large number of developers simply don't even know it's an issue, let alone something that they should keep in mind.\n \nreply",
      "\"customizing shit that you probably shouldn't be customizing\" is kind of a standard in video games.Video games are not meant do be productive, they are meant to be fun, and standardization is boring. It means that they can't completely rely on OS frameworks to make an appealing game, it means that accessibility needs first hand consideration.\n \nreply",
      "Ubisoft is a huge corporation(I used to work there) - there are projects which are money makers and which have to be smoothed out and appeal to the largest possible group of people, but there is still a crazy amount of creativity happening in various corners of the company. For every Assassin's Creed there are 10 projects being worked on out of which maybe 1 will actually come out - generally if you can pitch an idea within your studio there is a good chance you will get internal funding for 6-12 months to work on it with a small group of other people. Passing other milestones on the way to release is much harder, but this kind of \"work on anything and see if it works\" approach is very much encouraged. OddBallers and RollerChampions being probably some of the better examples lately, and Grow Home much earlier.\n \nreply",
      "With the popularity of indie games I wonder why publishers don\u2019t just try and buy out hundreds of these small devs under their shop. And I\u2019m not talking like how when ea buys dice and ruins dice. That is the whole problem. Total autonomy should be offered. The publisher should exist solely as a balancer of budgets: skim profit when sales happen to pay for shops when dev work before a sale is to be done. No different than say a city department paying into the general fund and other department supported by the general fund.\n \nreply",
      "Publishers that want to work with indie studios are already accepting 100s of pitches and choose 0.1% they like. If a big publisher will buy a lot of small indie studios you'll soon see titles in a press like \"{PUBLISHERNAME} force developers to live on ramen and work 12 / 6\".Simply because working on very tight budget likely 12/6 is how indie games are made. And to be honest in modern economy having any budget at all is kind a success already. So I'd belive most of small games are built on enthusiasm and founders own money.Vast majority of \"indie\" games budgets are in range of $100,000 and $300,000 total. Over that amount there is gap where no one invest except few rich, successful and picky publishers. Getting more funding for a small-scale project is extremely hard so if your game needs more then it's must be AA project for at least $2,000,000+ budget. But AA+ means $40+ price tag, completely different production quality and large team so very few kind of games fit the math.PS: I co-founder of a small gamedev studio and I know quite a few other people in this industry.PSS: I'm happy to be wrong though. So if you know how to get game funded I have 4 cool playable prototypes to build into a game, team of 10+ devs and we track record for 3 released titles including one for consoles.\n \nreply",
      "The short answer is that for a company like Ubisoft or EA, big blockbusters are much more reliable and more profitable than indie games. Not that smaller games can\u2019t do amazingly well, but most don\u2019t make a profit, and the risk doesn\u2019t justify the expenditure for that kind of company.Also, like another poster mentioned, there already exists a host of creativity in these AAA companies, that\u2019s not the problem. The problem is making something that will reliably keep the company in the black.\n \nreply"
    ],
    "link": "https://github.com/ubisoft/Chroma",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Chroma is a one-stop solution for detecting color blindness-related issues in games. It replicates Protanopia, Deuteranopia, and Tritanopia filters over the game screen, helping users flag accessibility concerns in real-time.\n      Chroma helps in simulating different types of color blindness occurring in society.Main purpose of this is to simulate 3 major Color Blindness types Protanopia, Deuteranopia and Tritanopia for our different games and aid accessibility team in performing various complex testing.Following are key features:Color Simulation on single monitor. This solution works on top of game and can be maximized as per requirement.Work on all games. No dependency on any specific game or engine.High performance. Able to simulation live gameplay upto 60 FPS.Accurate results.Simulation of all type of color blind forms.Only ava"
  },
  {
    "title": "Liquid: Language models are scalable and unified multi-modal generators (foundationvision.github.io)",
    "points": 52,
    "submitter": "pr337h4m",
    "submit_time": "2025-04-15T19:46:14 1744746374",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=43697532",
    "comments": [
      "> For the first time, Liquid uncovers a scaling law that performance drop unavoidably brought by the unified training of visual and language tasks diminishes as the model size increases...No prior work has explored whether LLMs retain the power-law scaling laws observed in language tasks when extended to visual generation tasks. We prove this alignment and further show that vision can be effectively learned by LLMs as a form of language.Does this really show much that https://arxiv.org/abs/2301.03728#facebook (uncited) and other earlier work did not?\n \nreply",
      "I love the website for this paper! Each section asks a question, and immediately answers it with a figure and a few sentences of discussion. It's less tech-demo heavy than a lot of other paper websites (those are cool, too, in their own way), and instead focuses on characterizing multimodal model behavior in a nice, clean, disciplined way.\n \nreply",
      "hmm this is a tough name - conflicts with Liquid AI https://hn.algolia.com/?dateRange=all&page=0&prefix=true&que...\n \nreply",
      "it performs well with composition, however it seems SD and SDXL excels in capability and quality when intermixed with pipelines and workflows, this doesn't do much to talk about that comparison and whenever i see things like this i think about the overall workflow, like cool you do good composition but you don't fit within the workflow or ecosystem that surrounds that tool and thus i have low expectations around adoption\n \nreply",
      "The Synesthesia these models must experience has gotta be intense\n \nreply"
    ],
    "link": "https://foundationvision.github.io/Liquid/",
    "first_paragraph": "\n                            We present Liquid, an auto-regressive generation paradigm that seamlessly integrates visual comprehension and generation by tokenizing images into discrete \n                            codes and learning these code embeddings alongside text tokens within a shared feature space for both vision and language. Unlike previous multimodal large \n                            language model (MLLM), Liquid achieves this integration using a single large language model (LLM), eliminating the need for external pretrained visual embeddings \n                            such as CLIP. For the first time, Liquid uncovers a scaling law that performance drop unavoidably brought by the unified training of visual and language \n                            tasks diminishes as the model size increases. Furthermore, the unified token space enables visual generation and comprehension tasks to mutually enhance each \n                            other, effectively removing the typical i"
  }
]