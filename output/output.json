[
  {
    "title": "Did you lose your AirPods? (alexyancey.com)",
    "points": 111,
    "submitter": "RockRobotRock",
    "submit_time": "2024-08-23T23:54:28",
    "num_comments": 44,
    "comments_url": "https://news.ycombinator.com/item?id=41334207",
    "comments": [
      "So you scripted sending the message to 84 different numbers, was that from your own personal iMessage account?I would be terrified of doing something like that, I imagine the account could get flagged for spam, and hearing the various tech horror stories, I wouldn\u2019t be surprised if it could end up suspending your iCloud account with everything on it, blacklisting hardware devices linked to it, and who knows what else.\n \nreply",
      "I found some AirPods on a remote trail awhile back, case and all. Batteries were completely dead. Once charged they paired to my iphone with no indication of a previous owner, besides the device name of John\u2019s AirPods or whatever.I tried briefly (not as hard as the author) to figure out who they belonged to but had no luck.I called Apple support and gave the serial number, but they told me there wasn\u2019t anything they could do if the owner did not mark them as lost via the Bluetooth settings page. Even though at that point Apple presumably had all the information necessary to contact the original owner\u2026So I cleaned the AirPods and have been using them since. Is there any way for me to find the owner if I have no info about the owners area code like the author did?\n \nreply",
      "Some heroes don\u2019t wear capes. They wield scripts, API calls, and a bit of luck.\n \nreply",
      "Speaking of AirPods, do people have bad experience with their quality?  I have an AirPods Pro 1st Gen for about 3 years and the noise cancellation function has degraded to the point of unusable.  The Apple store technician said the audio hardware has failed diagnostic and it couldn't be repaired.  For a $250 equipment failed after 3 years of moderate usage is pretty disappointing.\n \nreply",
      "That was a known issue with the 1st-gen AirPods Pro (Apple had a 3 year replacement program for them) but I've heard fewer issues with the 2nd-gen.\n \nreply",
      "I had this issue and I \u00absolved\u00bb it by cleaning the tiny microphone at the bottom with a toothprush. It\u2019s a small slit that can get stuffed with dust etc and it impacts how well it can do noise cancellations.\n \nreply",
      "One of my AirPods is weirdly quiet. I know it still has the potential to be loud, as I\u2019ve gotten it to be at the same level of noise as the other, but it\u2019s hardly consistent. I\u2019ve tried cleaning it and it didn\u2019t seem to help, but I may just try again. Definitely a shame, but I got them for free so I won\u2019t complain too much though. (If they were fully repairable this wouldn\u2019t be a problem though.)\n \nreply",
      "No\n \nreply",
      "My kids loose theirs all the time and I say use find my but apparently that does not work if they are in the case at least according to my kids.\n \nreply",
      "I was surprised they didn't have any idea how to use Find My. That and their iCloud account was all kinds of messed up.I think we take for granted how easily these things come to us as tech people.\n \nreply"
    ],
    "link": "https://alexyancey.com/lost-airpods/",
    "first_paragraph": "GitHub\nLinkedIn\nSocials\n\n\n            2024-08-23\n        \n\n\n\nA friend found some AirPods on the ground and tapped them to his phone, revealing only the serial number and the last four digits of the owner's number. He turned to me for help.Could I really brute-force spam all phone numbers ending in 1234 and find the right owner? This seemed a bit impractical, so I had to think of ways to whittle the number down to something more manageable.I started with the assumption that the owner lived near me in the Portland metropolitan area. With that, I restricted the search to our local area code*. Sure, they could be from out of town, but hey, let's give it a shot.999 numbers is a manageable list, but I wanted to trim the number a bit more. Sure, sending a thousand SMS messages isn't much to a determined spammer, but I didn't want to be that noisy or piss off Twilio.Possible matches: 999Next, I narrowed it down by central office code (commonly called prefix) (those three digits after the area "
  },
  {
    "title": "We have reached OpenBSD of Theseus (marc.info)",
    "points": 219,
    "submitter": "nabla9",
    "submit_time": "2024-08-23T19:39:11",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=41332342",
    "comments": [
      "Here's the change itself: https://github.com/openbsd/src/commit/a6105854a9e3aab642e6a0...I know that OpenBSD doesn't actually use GitHub, but it was the easiest way I could find the diff. I don't know how to otherwise get it from that mailing list entry.\n \nreply",
      "They have a cvsweb instance on their website, but the UI is a little more old school than github, so the github mirror is often good for browsing anyway.https://cvsweb.openbsd.org/\n \nreply",
      "Why remove the Greek queez instead of just adding the ship parts quiz? I guess I understand the obscurity argument (although as a classicist it makes me sad), but there's still a Latin quiz there. Hell there's even an Inca quiz. How does that meet the obscurity bar but not Greek?\n \nreply",
      "They would certainly welcome a patch from someone motivated, though I suspect this first one was driven by a desire to make a pun out of the milestone.\n \nreply",
      "It used ASCII substitutes for the greek letters, Latin only uses Latin letters    $luw$:{I} [loose|destroy]\n    $eluon$:{I} [loosed|destroyed|was loosing|was destroying]\n    $elusa$:{I} [loosed|destroyed]\n    $leluka$:{I} have [loosed|destroyed]\n    $lusw$:{I} will [loose|destroy]\n    $luswn$:[loosing|destroying]\n    $lusas$:{having} [loosed|destroyed]\n \nreply",
      "I tried the quiz after reading the mailing list message and got three of them right. (I didn't study Greek long enough to get all the way through the verb paradigm and I haven't used it very regularly since then.) So yeah, I don't get the claim that nobody could play this quiz. I think I have friends who would get all of them right offhand. It's no more complicated than knowing the difference between \"hablo\", \"hablar\u00e9\", \"habl\u00e9\", \"hablaba\", \"hablado\", and \"hablando\" in Spanish, except that fewer people study ancient Greek than modern Spanish (and the older Indo-European languages do more stem-mutation between tenses, so it can be a bit more effort to memorize).The worst part of this format is probably that if you did \"quiz english greek\" it wouldn't accept any form of accent or breathing marks, even though these are also standardized in beta code and some people would probably try to type them, like \"e)luon\" to show that there's no /h/ sound at the beginning of that word. And I don't think typing beta code in between dollar signs is a very common convention today, but the quiz would require it; you can't just type \"luw\", you have to type \"$luw$\".\n \nreply",
      "I would guess most people interested in the quiz would be familiar with betacode (which this looks like, sans diacritics).edit: https://en.wikipedia.org/wiki/Beta_Code\n \nreply",
      "\"Beta Code was developed by David W. Packard\" (not that David Packard, but his son).  Neat.\n \nreply",
      "How would that complete the ship of Theseus?\n \nreply",
      "I think that removing Greek is unnecessarily ironic\u2026 cool historic reference, but a bit of an effort could have been made.\n \nreply"
    ],
    "link": "https://marc.info/?l=openbsd-cvs&m=172443408727088&w=2",
    "first_paragraph": ""
  },
  {
    "title": "I sped up serde_json strings by 20% (purplesyringa.moe)",
    "points": 82,
    "submitter": "purplesyringa",
    "submit_time": "2024-08-22T04:24:22",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=41316807",
    "comments": [
      "Serde json has 3gb of dependencies once you do a build for debug and a build for release. Use serde on a few active projects and you run out of disk space. I don\u2019t know why json parsing needs 3gb of dependencies.I\u2019m all for code reuse but Serde for json is a bit of a dogs breakfast when it comes to dependencies. all you need is an exploit in on of those dependencies and half of the rust ecosystem is vulnerable.Rust should have Jason built in.\n \nreply",
      "It has 5 dependencies, one of which is optional, and another is serde itself: https://github.com/serde-rs/json/blob/master/Cargo.toml    indexmap = { version = \"2.2.3\", optional = true }\n    itoa = \"1.0\"\n    memchr = { version = \"2\", default-features = false }\n    ryu = \"1.0\"\n    serde = { version = \"1.0.194\", default-features = false }\n\nI don\u2019t think you\u2019re measuring what you think you\u2019re measuring when you say it has 3GB of dependencies. But I can\u2019t say for sure because you don\u2019t provide any evidence for it, you just declare it as true.If I were to guess, I\u2019d say you\u2019re doing a lot of #[derive(Serialize, Deserialize)] and it\u2019s generating tons of code (derive does code generation, after all) and you\u2019re measuring the total size of your target directory after all of this. But this is just a guess\u2026 other commenters have shown that a simple build produces code on the order of tens of MB\u2026\n \nreply",
      "From crates.io, `serde` is a 76.4 KiB dependency. And from what I've seen looking through the code, it's pretty minimal.\n \nreply",
      "> Rust should have Jason built in.I don't think this is a reasonable approach. That's just a way to introduce bloat. Importantly, std does not differ from other crates, except for stability guarantees, so there would be no positive here. All it does is link the library's release cycle to the compiler's. (In fact, rustc-serialize used to be built-in, so Rust tried to go that way.)But also, serde_json isn't large by default. I'm not sure where you are getting those numbers from. serde_json isn't large, serde isn't large. They both have very low MSRVs few other crates support, so in all truth they can't even have many dependencies.\n \nreply",
      "Rust emits unreasonable amount of debug information. It's so freakishly large, I expect it's just a bug.Anything you compile will dump gigabytes into the target folder, but that's not representative of the final product (after stripping the debug info, or at least using a toned-down verbosity setting).\n \nreply",
      "I swear the target folder for literally any project of any scale is at least several GB in size.\n \nreply",
      "Dependency bloat is an issue with Rust in general. The dependency trees for any meaty Rust project quickly become pretty horrifying. Auditing all these dependencies is infeasible, and my level of confidence in a lot of them is fairly low.I worked with Rust for a few years, and with the benefit of a few years' experience, I don't think I'll be touching Rust again until the ecosystem matures a great deal (which will only come with significant corporate adoption), or if I need something for a no-std, no-deps, strictly-a-C-replacement kind of project. (Though Zig might edge out Rust for this use case once it stabilises.)\n \nreply",
      "Built in JSON encoding/decoding is one of the things I\u2019ve enjoyed about Swift. It\u2019s nice when it\u2019s not necessary to shop around for libraries for common needs like that.\n \nreply",
      "Almost nobody is shopping around Rust JSON libraries unless they need some specific feature not provided by serde and serde_json. They are the default everyone reaches for.\n \nreply",
      "Please show your work. I cannot reproduce \"3gb of dependencies\".Here is my test:Cargo.toml   [package]\n   name = \"serde-test\"\n   version = \"0.1.0\"\n   edition = \"2021\"\n   \n   [dependencies]\n   serde = { version = \"1.0.208\", features = [\"derive\"] }\n   serde_json = \"1.0.127\"\n\nsrc/main.rs    use serde::Deserialize;\n    \n    #[derive(Deserialize)]\n    struct Foo {\n        bar: String,\n    }\n    \n    fn main() {\n        let foo: Foo = serde_json::from_str(\"\\\"bar\\\": \\\"baz\\\"\").unwrap();\n    \n        println!(\"{}\", foo.bar);\n    }\n\n$ cargo build && cargo build --release && du -sh target    ...\n\n    78M target\n \nreply"
    ],
    "link": "https://purplesyringa.moe/blog/i-sped-up-serde-json-strings-by-20-percent/",
    "first_paragraph": "I have recently done some performance work and realized that reading about my experience could be entertaining. Teaching to think is just as important as teaching to code, but this is seldom done; I think something I\u2019ve done last month is a great opportunity to draw the curtain a bit.serde is the Rust framework for serialization and deserialization. Everyone uses it, and it\u2019s the default among the ecosystem. serde_json is the official serde \u201cmixin\u201d for JSON, so when people need to parse stuff, that\u2019s what they use instinctively. There are other libraries for JSON parsing, like simd-json, but serde_json is overwhelmingly used: it has 26916 dependents at the time of this post, compared to only 66 for simd-json.This makes serde_json a good target (not in a Jia Tan way) for optimization. Chances are, many of those 26916 users would profit from switching to simd-json, but as long as they aren\u2019t doing that, smaller optimizations are better than nothing, and such improvements are reapt across"
  },
  {
    "title": "Open-Source AI necklace like Friend (github.com/basedhardware)",
    "points": 40,
    "submitter": "kodjima33",
    "submit_time": "2024-08-23T22:31:45",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=41333648",
    "comments": [
      "Aren't a lot of y'all in California? Because wearing a wire is generally illegal there...https://leginfo.legislature.ca.gov/faces/codes_displaySectio...\n \nreply",
      "lol, oh california...\n \nreply",
      "Hi, HN! I built a proactive open-source AI necklace that transforms your conversations into summaries, proactive feedback, and insightsI built this because I want to use it myself: many companies are advertising such technology but no one is shippingThe app can work with or without wearables so you can try the experience without buying anything---\nUpdate: wasn't expecting this post to get attention, so please let me know if I need any special tags like Show HN\n \nreply",
      "Makes me want a wearable white noise generator, except it's specifically tuned to jam speech transcription AI.\n \nreply",
      "It kind of exists; here's one such video demonstrating the (not as advertised, but still kinda works) results on a microphone.\\https://www.youtube.com/watch?v=FyeCn7HlLckYounger ears find it excruciating though.\n \nreply",
      "I can't wait for stuff like this to become more common, and then the inevitable data leaks. Instead of SSNs and emails it'll be the private conversations of millions of people, many of whom didn't agree to this.\n \nreply",
      "Exactly.  All of these things that ship data off to cloud services are basically data breaches waiting to happen.  The fact that devices like this not only put the owner at risk, but others who didn\u2019t consent to having their conversations recorded and shipped to a third party is even worse.\n \nreply",
      "I wonder if this is even legal in many places. Doesn't California require consent to be recorded? This seems like an edge case\n \nreply",
      "Only private communication\n \nreply",
      "Illinois too, it's called \"two-party consent\".\n \nreply"
    ],
    "link": "https://github.com/BasedHardware/Omi",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        AI wearables\n      Meet Omi, the world\u2019s leading open-source AI wearables that revolutionize how you capture and manage conversations. Simply connect Omi to your mobile device and enjoy automatic, high-quality\ntranscriptions of meetings, chats, and voice memos wherever you are. \u2002\u2002\u2002\n\u2002\u2002\u2002\nHomepage | Documentation | Buy Assembled Device\nOmi is available under MIT License\n        AI wearables\n      "
  },
  {
    "title": "Adding 16 kb page size to Android (googleblog.com)",
    "points": 211,
    "submitter": "mikece",
    "submit_time": "2024-08-23T17:14:05",
    "num_comments": 120,
    "comments_url": "https://news.ycombinator.com/item?id=41330852",
    "comments": [
      "> The very first 16 KB enabled Android system will be made available on select devices as a developer option. This is so you can use the developer option to test and fix> once an application is fixed to be page size agnostic, the same application binary can run on both 4 KB and 16 KB devicesI am curious about this. When could an app NOT be agnostic to this? Like what an app must be doing to cause this to be noticeable?\n \nreply",
      "The fundamental problem is that system headers don't provide enough information. In particular, many programs need both \"min runtime page size\" and \"max runtime page size\" (and by this I mean non-huge pages).If you call `mmap` without constraint, you need to assume the result will be aligned to at least \"min runtime page size\". In practice it is probably safe to assume 4K for this for \"normal\" systems, but I've seen it down to 128 bytes on some embedded systems, and I don't have much breadth there (this will break many programs though, since there are more errno values than that). I don't know enough about SPARC binary compatibility to know if it's safe to push this up to 8K for certain targets.But if you want to call `mmap` (etc.) with full constraint, you must work in terms of \"max runtime page size\". This is known to be up to at least 64K in the wild (aarch64), but some architectures have \"huge\" pages not much beyond that so I'm not sure (256K, 512K, and 1M; beyond that is almost certainly going to be considered huge pages).Besides a C macro, these values also need to be baked into the object file and the linker needs to prevent incompatible assumptions (just in case a new microarchitecture changes them)\n \nreply",
      "you can also do 2M and 1G huge pages on x86, it gets kind of silly fast.\n \nreply",
      "1G huge pages had (have?) performance benefits on managed runtimes for certain scenarios (Both the JIT code cache and the GC space saw uplift on the SpecJ benchmarks if I recall correctly)If using relatively large quantities of memory 2M should enable much higher TLB hit rates assuming the CPU doesn't do something silly like only having 4 slots for pages larger than 4k \u00ac.\u00ac\n \nreply",
      "What? Any pointers on how 1G speeds things up? I'd have taken a bigger page size to wreak havoc on process scheduling and filesystem.\n \nreply",
      "Because of virtual address translation [1] speed up. When a memory access is made by a program, the CPU must first translate the virtual address to a physical address, by walking a hierarchical data structure called a page table [2]. Walking the page tables is slow, thus CPUs implement a small on-CPU cache of virtual-to-physical translations called a TLB [1]. The TLB has a limited number of entries for each page size. With 4 KiB pages, the contention on this cache is very high, especially if the workload has a very large workingset size, therefore causing frequent cache evictions and slow walk of the page tables. With 2 MiB or 1 GiB pages, there is less contention and more workingset size is covered by the TLB. For example, a TLB with 1024 entries can cover a maximum of 4 MiB of workingset memory. With 2 MiB pages, it can cover up to 2 GiB of workingset memory. Often, the CPU has different number of entries for each page size.However, it is known that larger page sizes have higher internal fragmentation and thus lead to memory wastage. It's a trade off. But generally speaking, for modern systems, the overhead of managing memory in 4 KiB is very high and we are at a point where switching to 16/64 KiB is almost always a win. 2 MiB is still a bit of a stretch, though, but transparent 2 MiB pages for heap memory is enabled by default on most major Linux distributions, aka THP [2]Source: my PhD is on memory management and address translation on large memory systems, having worked both on hardware architecture of address translation and TLBs as well as the Linux kernel. I'm happy to talk about this all day![1] https://blogs.vmware.com/vsphere/2020/03/how-is-virtual-memo...\n[2] https://docs.kernel.org/admin-guide/mm/transhuge.html\n \nreply",
      "> I'm happy to talk about this all day!Oh really :)I'd like to ask how applications should change their memory allocation or usage patterns to maximise the benefit of THP. Do memory allocators (glibc mainly) need config tweaking to coalesce tiny mallocs into 2MB+ mmaps, will they just always do that automatically, do you need to use a custom pool allocator so you're doing large allocations, or are you never going to get the full benefit of huge tables without madvise/libhugetlbfs? And does this apply to Mac/Windows/*BSD at all?[Edit: ouch, I see /sys/kernel/mm/transparent_hugepage/enabled is default set to 'madvise' on my system (Slackware) and as a result doing nearly nothing. But I saw it enabled in the past. Well that answers a lot of my questions: got to use madvise/libhugetlbfs.]I read you also need to ensure ELF segments are properly aligned to get transparent huge pages for code/data.Another question. From your link [2]:> An application may mmap a large region but only touch 1 byte of it, in that case a 2M page might be allocated instead of a 4k page for no good.Do the heuristics used by Linux THP (khugepaged) really allow completely ignoring whether pages have actually been page-faulted in or even initialised? Is a possibility unlikely to happen in practice?\n \nreply",
      "Thanks!> I'm happy to talk about this all day!With noobs, too? ;)> Often, the CPU has different number of entries for each page size.Does it mean userspace is free to allocate up to a maximum of 1G? I took pages to have a fixed size.Or, you mean CPUs reserve TLB sizes depending on the requested page size?> With 2 MiB or 1 GiB pages, there is less contention and more workingset size is covered by the TLBWould memory allocators need to deal with block of 1G? Would you say, the current ones found in popular runtimes/implementations are adept at doing so?Does it not adversely affect databases accustomed to smaller page sizes now finding themselves having to page in 1G at once?> my PhD is on memory management and address translation on large memory systemsIf the dissertation is public, please do link it, if you're comfortable doing so. Thx.\n \nreply",
      "Are huge pages expected to share code (X) and data (RW)?\n \nreply",
      "There's probably no good reason to put code and data on the same page, it's just one extra TLB entry to use two pages instead so the data page can be marked non-executable.\n \nreply"
    ],
    "link": "https://android-developers.googleblog.com/2024/08/adding-16-kb-page-size-to-android.html",
    "first_paragraph": "\n23 August 2024\nA page is the granularity at which an operating system manages memory. Most CPUs today support a 4 KB page size and so the Android OS and applications have historically been built and optimized to run with a 4 KB page size. ARM CPUs support the larger 16 KB page size. When Android uses this larger page size, we observe an overall performance boost of 5-10% while using ~9% additional memory.In order to improve the operating system performance overall and to give device manufacturers an option to make this trade-off, Android 15 can run with 4 KB or 16 KB page sizes.The very first 16 KB enabled Android system will be made available on select devices as a developer option. This is so you can use the developer option to test and fix (if needed) your applications to prepare for Android devices with 16 KB page sizes in the near future.In most CPUs, dedicated hardware called memory management units (MMUs) translate addresses from what a program is using to a physical location i"
  },
  {
    "title": "BMW Overtakes Tesla in European EV Sales for First Time (electriccarsreport.com)",
    "points": 174,
    "submitter": "belter",
    "submit_time": "2024-08-23T21:04:12",
    "num_comments": 174,
    "comments_url": "https://news.ycombinator.com/item?id=41333082",
    "comments": [
      "I did some digging.The title is misleading -YTD Tesla is way ahead - https://imgur.com/56eG7CN\nActual Numbers - BMW registration for the month of July 2024 were up by 300~ cars.Original Source - https://www.jato.com/resources/media-and-press-releases/bmw-...\nQuoting this comment -streptomycin-\nYes https://i.imgur.com/ZNv1AyD.jpg\nAlthough BMW is making some nice EVs and they are selling more than they used to, the headline is misleading.ultrablack22 - Tesla produce a lot of for the EU in China. They have a schedule where for each quarter, months 1, 2 and 3, in Month 1, they produce cars. In Month 2 they sail them over from China. And in Month 3, they arrive and are sold.BMW managed to overtake Tesla in the first month of Q3, barely. When Tesla really had no cars for sale.\n \nreply",
      "> BMW registration for the month of July 2024Do the manufactures consider sales to dealers in their sales numbers or are they actual sales to people that then registers the car as in use?\n \nreply",
      "Ya, it is kind of weird because the Dealer is actually the OEM's customer. But they measure in sales to the consumer, which is a more useful number because:1. Dealers will order certain high demand vehicles all day long when they are allowed to do so (\"allocations\") even though they don't have specific consumers in mind to buy them.2. When new models become available they will also order a bunch of that new model.3. They will order some random vehicles to look nice in their showroom or on the lot. Fun example: I recently drove by a Porsche dealership that had a bunch of Macan's lined up out front -- one in each color!So, sales to the consumer is more useful because it's the only way to measure actual consumer demand. This is also why you sometimes see a model that hasn't been manufactured for several years show up in these new car sales reports... they were sitting on a lot unsold for that long.You can also find numbers for how many of each model they've manufactured each month, which is useful for different reasons of course, and sometimes they sit on the manufacturer's lot for weeks or months before they're delivered to dealers. We saw this coming out of the pandemic when there weren't enough trains to transport the cars (most cars leave the plant on a train).\n \nreply",
      "Registration is generally done when the consumer takes possession of the vehicle.\n \nreply",
      "I understand what registration is done, but that does not answer the question.Are the numbers what the makers sell to the dealers but have yet been sold to a buyer, or are they legit sells to buyers? I can see where the makers pad their numbers by using what was sold to the dealers to have on the lots as they've technically sold the car, but it's a misleading number. Same game as storage makers using powers of 10 vs powers of 2 in their capacity claims.\n \nreply",
      "The Tesla brand has suffered enormously due to the actions of its owner.\n \nreply",
      "Yes, Tesla's execution has been really terrible. There's some really good tech inside their cars, but the direction of which cars to make, when, and the investments in non-car tech, the over-promising of \"Full Self Driving,\" etc. All huge detractors.There's also the CEO, who has a huge public profile, deciding to become extremely political, which smart CEOs usually avoid doing because it has little potential to help and lots of potential to hurt.Especially with Musk's particular choice of which politics he wants to push, which alienate not only customers but also the government political forces. Tesla has massively benefited from subsidies to EVs, but is alienating the political party that has enabled all of that.If Tesla had been run by a different CEO for the past, say, 3 years, nearly any CEO, I think it would be in a better position.I really like my Model 3, but I won't be buying it again, and the direction of the Cyber Truck is so repulsive to me that I'm really really against being associated with the brand at all.\n \nreply",
      "Was it not the mission of Tesla to make electrical cars an alternative to cars running on petrol? To me this was achieved. Bmw or Tesla, i do not care about that too much. But we have an alternative. Great!And politics, well, only for people who do not agree with him it is an issue. But that's normal in politics, is it not?\n \nreply",
      "> But that's normal in politics, is it not?Excluding a part of the population for no practical reason at all is bad business. But when the politics becomes extremist, that share becomes huge, and it becomes disastrous business.Some people are motivated enough to lose business for their principles. But the guy's principles is \"big business is right\"... I'm not sure what he wants to achieve.\n \nreply",
      "> Excluding a part of the population for no practical reason at all is bad business. But when the politics becomes extremist, that share becomes huge, and it becomes disastrous business.Companies do this all the time though. The trade off is, of course, that you get more support from customers the other side.> But the guy's principles is \"big business is right\"... I'm not sure what he wants to achieve.This is not an accurate representation. For example, the Twitter acquisition followed a period of Twitter (and most other social media) banning a lot of conservative accounts for publishing truthful reporting (New York Post) or actual satire with the disfavored political leaning (Babylon Bee), at which point Musk did a Twitter poll asking the entire site if Twitter adheres to the principle of free speech:https://x.com/elonmusk/status/150725970922463234470% said it didn't, so he bought it.This upset a lot of people (not least the people who liked the preexisting system that tended to ban their political opponents) and they've been characterizing everything he does in a negative light since. So then you'll get a lot of stories about a left-leaning account being suspended with the implication that he's just doing it the other way now, with no investigation into whether the suspension was deserved, or just characterizing the unavoidable false positives and false negatives in moderation as a willful bias etc.That isn't to say he's a saint, but the impression you'd get from reading a lot of this coverage is that he's the devil.\n \nreply"
    ],
    "link": "https://electriccarsreport.com/2024/08/bmw-overtakes-tesla-in-european-ev-sales-for-first-time/",
    "first_paragraph": ""
  },
  {
    "title": "Canon R5 Mk Ii Drops Pixel Shift High Res \u2013 Is Canon Missing the AI Big Picture? (kguttag.com)",
    "points": 24,
    "submitter": "LorenDB",
    "submit_time": "2024-08-23T21:29:44",
    "num_comments": 17,
    "comments_url": "https://news.ycombinator.com/item?id=41333284",
    "comments": [
      "My Lumix camera has a similar mode (uses sensor shift and 4 exposures to fake a composite 100MP image from my 25MP sensor), and I will say that even with a rock-solid tripod, you're not _actually_ getting a 4X (or whatever) increase in quality alongside the 4x resolution.   If you zoom in Lightroom, the resulting image is at best a bit sharper in really high contrast areas, and at worst full of blatant overlapping and stitching artifacts.I've never figured out a good use-case for that mode, and I've tried to use it quite a few times to shoot landscapes or static scenes with a tripod.Maybe Canon does it better, but perhaps they dropped it because it's just not producing worthwhile results.\n \nreply",
      "If it's the Lumix S5 I have the same camera and as far as I know you are getting genuinely more resolution but it relies on there being absolutely no movement in the scene. So, great for buildings and architecture, terrible in forests or city streets.\n \nreply",
      "It's a GH6, so probably the same system roughly...And yes that's what I said, sorry if I wasn't clear.It does get more \"pixels\" resolution, the image file is 100MP, but it's certainly not 4X the image resolution in terms of image quality.   Not that I was expecting that, but it's not even a middle ground that I consider usable, at least not good enough to use over a normal 25MP picture.I've done a bunch of landscape shots (with a very solid tripod, camera in silent mode, shutter release delay, no wind, etc) and generally I've found the results mixed-to-bad..Like I said, it seems like the algorithm has a hard time stitching the images together often so if you zoom into the details (and really if you're using this mode, it's ostensibly because you want more detail), things get fuzzy or muddy in most of the pictures I've taken.To be fair I took maybe 20-30 test shots in the first 6 months I owned that camera, and I haven't gone back to the mode since..  Maybe some of it is user error, but I really did try to make it work because it seemed like a cool feature.\n \nreply",
      "Do you have a remote shutter trigger? I think pressing the shutter button can count as too much movement for these systems.",
      "So, they just literally determine every fourth pixel in the final image from the fourth image? That's a solution to a niche problem. I hope they didn't sell that as general-purpose...\n \nreply",
      "Nah the manual and specs are pretty clear on the limitations of the mode and how it works..   I personally find it pretty useless, but it's easy to just ignore it entirely since it's a dedicated mode on the dial.\n \nreply",
      "Interesting- I have an OM-1 mk1 and similarly I've never found a decent use case for that mode.\n \nreply",
      "As an EM-1.3 owner...I can't find it right now, but there's a YouTube video that demonstrates using this mode for astrophotography. It seems that a side effect of the computational process is that noise gets averaged out, resulting in a cleaner (and sharper, as you'd be expecting anyway) image.\n \nreply",
      "In a sense, it's an in camera image stacking where the sensor noise can be removed while retaining actual image data.The Nikon bodies were known to eat stars with its in camera noise removal worse than other makers, it was one of the reasons astro recommendations are to not use that feature for any body.\n \nreply",
      "Yeah, it's a real problem. It's not 4x better since the assumptions don't hold up. Check out Figure 5 from [0] to see what the software is up against. I have no idea how well first party software handles this motion.[0]: http://aggregate.org/DIT/PARSEK/paper.pdf\n \nreply"
    ],
    "link": "https://kguttag.com/2024/08/22/canon-r5-mk-ii-drops-pixel-shift-high-res-is-canon-missing-the-ai-big-picture/",
    "first_paragraph": "Physical Address304 North Cardinal St.Dorchester Center, MA 02124Sometimes, companies make what seems, on the surface, technically poor decisions. I consider this the case with Canon\u2019s new R5 Mark ii (and R1) dropping support for sensor Pixel Shifting High Resolution (what Canon calls IBIS High Res). Canon removed the IBIS High Res mode, which captures (as I will demonstrate) more real information and seemingly adds an AI upscaling to create fake information. AI upscaling, if desired, can be done better and more conveniently on a computer, but Pixel Shift/IBIS High Res cannot.The historical reason for pixel shift is to give higher resolution in certain situations. Still, because the cameras combine the images \u201cin-camera\u201d with the camera\u2019s limited processing and memory resources plus simple firmware algorithms, they can\u2019t deal with either camera or subject motion. Additionally, while the Canon R5 can take 20 frames per second (the R5 Mark ii can take 30 frames per second), taking the ni"
  },
  {
    "title": "People with Disabilities Use the Web (w3.org)",
    "points": 47,
    "submitter": "fagnerbrack",
    "submit_time": "2024-08-23T21:01:42",
    "num_comments": 11,
    "comments_url": "https://news.ycombinator.com/item?id=41333064",
    "comments": [
      "HN really needs to turn off that regex that removes the word \u201chow\u201d from the beginning of article titles.\n \nreply",
      "Strongly advocate for this!Another word that automatically got removed from the title is why and this happened to me a lot. The system should, at least, notify you that the title has been edited. Fortunately,  you can re-edit the title and bring back what was removed.\n \nreply",
      "For HNers who don\u2019t already know this, you can edit immediately after submission to fix meaning-changing auto-edits.\n \nreply",
      "\"Yes, they do,\" was my first thought upon seeing the article title.\n \nreply",
      "Idk, \"people with disabilities use the web\" still matches up with the content of the article to me\n \nreply",
      "The \"how\" is the thing that adds interest in this case. We are hopefully all cognizant of the fact that disabled people exist and (need to) use the web.\n \nreply",
      "We might be aware, but companies don't seem to care, so it's still a fitting title.\n \nreply",
      "Somewhat ironically one of the best examples of absurdly awful UI/UX because someone decided they know best.\n \nreply",
      "Far from the worst accessibility thing just on HN.I will now beat the \u201cgrey in slightly darker grey\u201d is not an acceptable color scheme drum again.\n \nreply",
      "You know perfectly well Hacker news is the apex of efficiency and minimalism, and that \"good hackers\" don't care about trivial nonsense like \"accessibility\" or \"readability\" or \"user experience,\" only the purity of signal over noise.Now go to the blackboard and reverse binary trees until you've learned your lesson.\n \nreply"
    ],
    "link": "https://www.w3.org/WAI/people-use-web/",
    "first_paragraph": "All\u00a0TranslationsTranslating WAI ResourcesAccessibility: It's about peopleHow do people who cannot move their arms use your website? What about people who cannot see well or at all? Or people who have difficulty hearing, or understanding, or have other disabilities?This resource introduces how disabled people use the web, including people with age-related impairments. It helps developers, designers, content creators, and others understand the reasons behind creating accessible digital products \u2014 including websites, apps, browsers, and other web tools.Please share your ideas, suggestions, or comments via e-mail to the publicly-archived list wai@w3.org or via GitHub.Date: Updated 25 June 2024. First posted as a draft in 1999.Editor: Shadi Abou-Zahra. Previous editor: Judy Brewer. See Acknowledgements for additional editors and contributors.Developed by the Education and Outreach Working Group (EOWG) with support from the WAI-Guide Project and WAI-AGE Project co-funded by the European Comm"
  },
  {
    "title": "About the IMGUI Paradigm (github.com/ocornut)",
    "points": 33,
    "submitter": "ibobev",
    "submit_time": "2024-08-22T16:38:45",
    "num_comments": 26,
    "comments_url": "https://news.ycombinator.com/item?id=41322012",
    "comments": [
      "One of my perverse ideas for a project is to make a Dear ImGUI (the most common IMGUI library and basically what many people associate with \"ImGUI\") backend for Lazarus/LCL (the most non-IMGUI/Retained mode framework you can probably think with OOP -something that IMGUI aficionados seem to have a distaste for- layers thick enough to act as armor :-P).\n \nreply",
      "Somewhat of a nitpick..> The acronym is misleading because \"immediate-mode\" was initially coined as a reference to obsolete graphics API which made it very easy to render contents.Is that actually true?  From what I remember of hearing Casey (the person who coined the term) talk about it on Handmade Hero and various other streams, it's differentiating between 'immediate mode' and 'retained mode' GUI APIs (QT, GTK, Swing, MFC .. etc) which make you retain handles to UI elements.  AFAIK it didn't have anything to do with the graphics API whatsoever ..? Right?EDIT: Watched the video linked of Casey from 05, which I'd never seen before and was quite interesting.  I'm not totally convinced that the small portion he talked about renderer APIs near the 10 minute mark substantiates the claim, but it might.\n \nreply",
      "https://learn.microsoft.com/en-us/windows/win32/learnwin32/r...I think you could also draw some analogies between server side and client side rendering. Where the authoritative view state lives is the most important bit I think.\n \nreply",
      "Yes, it's true.Direct3D had a retained mode up until version 3.0, but the only examples of it ever being used in a commercially successful game was LEGO Island and LEGO Rock Raiders.Instead of supplying all the draw commands every frame, you would give it your 3D scene and it would draw it.\n \nreply",
      "I tried to use it (for fun) at some point but the API design felt too verbose/cumbersome for what it did and by the time DrawPrimitive was added in D3D5 it was simpler to use that directly than use D3DRM.It was also very clear that D3DRM was designed by a different team than D3DIM.\n \nreply",
      "I love the developer experience of Dear ImGUI, even though I use it through Python wrappers that confuse things sometimes. It just slices like a sword through several layers of often-pointless abstraction and puts the control over the main loop right in your hands.And when you need to read the source to figure something out, it's just a few files of pretty self-evident C-ish code.\n \nreply",
      "It should be the go to for general purpose cross-platform application UI development (instead of Electron,) and it's unfortunate that something so good and so useful is only meant for debuggers and editors.\n \nreply",
      "On the flip side, targeting developers tightens the scope quite a lot! If nothing else, it massively increases the chance your target audience can at least get by with left-to-right text and 7-bit ASCII...Cornut recently did a 10 year retrospective of Dear ImGui: https://github.com/ocornut/imgui/issues/7892 - an interesting read for me, as a Dear ImGui library user for many years now, but worth your time I think even if you aren't a user yourself. There is a specific section about the scope of the library: https://github.com/ocornut/imgui/issues/7892#issuecomment-22...\n \nreply",
      "Only if you don\u2019t care about accessibility and common controls.\n \nreply",
      "You might have a point about accessibility, but what common controls does Dear IMGui lack? It has just about every control I can think of.\n \nreply"
    ],
    "link": "https://github.com/ocornut/imgui/wiki/About-the-IMGUI-paradigm",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          THIS IS WIP/DRAFT / Discuss this articleThis is an attempt at explaining what the IMGUI paradigm stands for, and what it could be.Please note the References section where other articles have been written about this.Proponent of the IMGUI paradigm have noticed that it was widely misunderstood, over and over.\nAs of Feb 2021 January 2024, even the IMGUI Wikipedia page is COMPLETELY off the mark and incorrect. There are reasons for that:The acronym is misleading because \"immediate-mode\" was initially coined as a reference to obsolete graphics API which made it very easy to render contents. Some people still incorrectly assume that IMGUIs are often rendering using those API.From now on, IMGUI will stand for \"Incredibly Magic Graphics User Interface\" ;)The second purpose of this page should be to make it clear that there is a large space to explor"
  },
  {
    "title": "Accident Forgiveness (fly.io)",
    "points": 184,
    "submitter": "piperswe",
    "submit_time": "2024-08-21T18:27:56",
    "num_comments": 173,
    "comments_url": "https://news.ycombinator.com/item?id=41312834",
    "comments": [
      "xxx"
    ],
    "link": "https://fly.io/blog/accident-forgiveness/",
    "first_paragraph": "We\u2019re Fly.io, a new public cloud with simple, developer-friendly ergonomics. Try it out; you\u2019ll be deployed in just minutes, and, as you\u2019re about to read, with less financial risk.Public cloud billing is terrifying.The premise of a public cloud \u2014 what sets it apart from a hosting provider \u2014 is 8,760 hours/year of on-tap deployable compute, storage, and networking. Cloud resources are \u201celastic\u201d: they\u2019re acquired and released as needed; in the \u201ccloud-iest\u201d apps, without human intervention. Public cloud resources behave like utilities, and that\u2019s how they\u2019re priced.You probably can\u2019t tell me how much electricity your home is using right now, and  may only come within tens of dollars of accurately predicting your water bill. But neither of those bills are all that scary, because you assume there\u2019s a limit to how much you could run them up in a single billing interval.That\u2019s not true of public clouds. There are only so many ways to \u201cspend\u201d water at your home, but there are indeterminably ma"
  },
  {
    "title": "OpenSSH Backdoors (isosceles.com)",
    "points": 137,
    "submitter": "benhawkes",
    "submit_time": "2024-08-23T16:14:54",
    "num_comments": 85,
    "comments_url": "https://news.ycombinator.com/item?id=41330258",
    "comments": [
      "xxx"
    ],
    "link": "https://blog.isosceles.com/openssh-backdoors/",
    "first_paragraph": "Imagine this: an OpenSSH backdoor is discovered, maintainers rush to push out a fixed release package, security researchers trade technical details on mailing lists to analyze the backdoor code. Speculation abounds on the attribution and motives of the attacker, and the tech media pounces on the story. A near miss of epic proportions, a blow to the fabric of trust underlying open source development, a stark reminder of the risks of supply-chain attacks. Equal measures brilliant and devious.If you've been paying attention to the security news recently, your mind probably went straight to the attack on the liblzma/xz-utils repository earlier this year, the ultimate aim of which was an OpenSSH backdoor. However the event described above isn't the xz-utils backdoor. It's a little-remembered fact that the xz-utils backdoor was actually the second time OpenSSH had a \"near miss\" with a backdoor attack. The first time was over 22 years ago, all the way back in 2002. This blog post shares the s"
  },
  {
    "title": "Meta cancels high-end mixed reality headset after Apple Vision Pro struggles (macrumors.com)",
    "points": 156,
    "submitter": "tosh",
    "submit_time": "2024-08-23T18:00:17",
    "num_comments": 156,
    "comments_url": "https://news.ycombinator.com/item?id=41331369",
    "comments": [
      "xxx"
    ],
    "link": "https://www.macrumors.com/2024/08/23/meta-cancels-high-end-headset/",
    "first_paragraph": ""
  },
  {
    "title": "Arroost: Unblocking Creation with Friends (todepond.com)",
    "points": 5,
    "submitter": "surprisetalk",
    "submit_time": "2024-08-22T16:37:35",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.todepond.com/report/arroost/",
    "first_paragraph": "Last edited 7th July 2024\nLive programming is uniquely suited to\n  creative work. It can remove many of the creative\n  blockers that individuals experience when trying to produce\n  it. But we could place much more explicit emphasis on the removal of\n  emotional blockers from the creative process, as opposed to\n  only focusing on intellectual blockers. Arroost is a project\n  that seeks to do that \u2014 an experimental live programming tool for making\n  music.\n\n  For me, creative work is when you use your imagination to\n  \"make something\". This could be performing a song, writing a book, painting a\n  picture, drawing a diagram, baking a cake, giving a speech, designing a game,\n  or coding a program.\n\n  In any creative work, the person doing the work might experience\n  blockers that stop them from continuing. Let's think about\n  what those blockers could be. Here are some examples of potential blockers.\nI'm sure you could think of some more examples of your own.\n  We could categorise all of t"
  },
  {
    "title": "Tesorio Is Hiring a Senior GenAI Engineer and Django Engineer (100% Remote) (tesorio.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-08-23T21:01:15",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.tesorio.com/careers#job-openings",
    "first_paragraph": "We\u2019re a distributed team of data scientists, developers, and finance geeks who all love to make products that are easy to use and backed by cutting edge machine learning. We take a lot of pride in what we do, and we have fun while doing it.In 2023, we brought the Tesorio team together for the first time in Panama City. Our offsite was an absolute blast, filled with team-building, insightful workshops, and unforgettable memories. We can't wait to see where our next offsite will take us in 2024!\n                                    Nicole Thompson, Customer Success Manager\n                                \n                                    Nate Manchester, Regional Sales Director\n                                \n                                    Felipe Vieira, Senior Software Engineer\n                                \n\nDemo\nBook a Live Demo\n\nTry Now\nJump Into Our Virtual Sandbox"
  },
  {
    "title": "My IRC client runs on Kubernetes (xeiaso.net)",
    "points": 80,
    "submitter": "xena",
    "submit_time": "2024-08-23T19:46:40",
    "num_comments": 54,
    "comments_url": "https://news.ycombinator.com/item?id=41332427",
    "comments": [
      "Well I think it's neat. The bit I find most provoking is the \"if you already have Kubernetes...\" premise. I find myself having a hard time not wanting to shove everything into the Kubernetes framework simply to avoid having to document what solutions I've chosen. `kubectl get all` gives me an overview of a project in a way that is impossible if every single project uses a different or bespoke management system.\"simple/complex\" is not the right paradigm. The real SRE controversy is \"unique/standard\". Yes, the standard approach is more complex. But it is better _in practice_ to have a single approach, rather than many individually-simpler, but in-aggregate-more-complex approaches.Kubernetes is never the perfect solution to an engineering problem, but it is almost always the most pragmatic solution to a business problem for a business with many such problems.\n \nreply",
      "Yeah k8s is great. It gives you an infinite rope generator to let you hang yourself with ever increasing complexity, but with a bit of restraint you can orchestrate pretty much anything in a simple or at least standard way.I'd take a stack of yaml over a stack of bespoke aws managed service scripts any day.\n \nreply",
      "Speaking of rope. Right this moment GKE clusters can't provision large volumes (~4TiB) because their CSI driver receive OOMKill when formatting volume. Problem was reported back in Apr and still not fixed.\n \nreply",
      "Not a day goes by where there isn\u2019t some greybeard having a huge sulk about how nobody wants to use his collection of esoteric bash scripts that nobody else will ever understand, but HE does.\n \nreply",
      "The bit I find the most provoking is calling k8 \"standard.\"And not a collection of strung-together controllers.\n \nreply",
      "Is the mountain of k8s code on top of your cloud of choice not strictly more complex than the cloud services it's orchestrating? Like I think k8s is good software but to hear that you're not choosing it because it's good engineering is surprising. To me that's the only reason you choose it, because you want or need the control-loop based infrastructure management that you can't get on say AWS alone.\n \nreply",
      "That's the same with.. the Linux kernel? I'd wager that most services people write have less complexity than the the kernel it runs on. We choose to do that not because we need its full feature set, but because it gives us useful abstractions.\n \nreply",
      "I don\u2019t know that that\u2019s the right analogy. End users don\u2019t have to write a mountain of configuration in order to effectively use the Linux kernel.If k8s were as complex as it was, but didn\u2019t force that complexity onto the user, I\u2019d agree.\n \nreply",
      "There\u2019s always a mountain of code on top of the cloud provider.\n \nreply",
      "Furthermore, there's always a mountain of code aggregating heterogeneous systems into a uniform interface. Look at the linux kernel, or LLVM, or pretty much any other (successful) project that provides abstractions to many different backends.\n \nreply"
    ],
    "link": "https://xeiaso.net/blog/2024/k8s-irc-client/",
    "first_paragraph": "\n        Published on 08/23/2024, 1098 words, 4 minutes to read\n    Trust me, there's a reason for thisIRC has historically been one of the most important chat programs in my life. It's how I met my husband, how I found jobs in the early stages of my career, how I get help with weird Linux arcana that nobody else can really fix, and it's where I socialize with the Internet Illuminati. I use it every day and main reason I use tmux is to attach to that one session with my IRC client in it.However, there's a problem with this setup: it's tied to one physical computer. If that physical computer dies, I lose easy access to all my IRC logs. My IRC logs folder is ridiculously large:This is five gigabytes of text. This represents a huge fraction of my digital life and is some of the most important data to me. Not to mention my 188 kilobytes of configuration that I've built up over the years.Point is, there's a lot of data here and I want to make sure that it's easy to access via a shell like I"
  },
  {
    "title": "Pi-CI \u2013 A RasPi 5 emulator in a Docker image for creating and flashing configs (github.com/ptrsr)",
    "points": 27,
    "submitter": "Curiositry",
    "submit_time": "2024-08-23T20:29:42",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=41332811",
    "comments": [
      "Super interesting! Thank you for this. I was working on a hardware project that this probably would have helped a lot with. I was writing some python but the package couldn't be compiled on my local machine so I had to run a dev server off my pi directly. I wonder if this can help.\n \nreply",
      "This looks useful, I usually use guestfish to put files into the image before flashing but this could be a lot more flexible.\n \nreply",
      "This is awesome, I've had a need for this for quite a while, and had cooked up something similar before, but will probably swap to using this.\n \nreply"
    ],
    "link": "https://github.com/ptrsr/pi-ci",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Prepare Raspberry Pi 3, 4 & 5 configurations using a virtual machine.\n      A raspberry Pi emulator in a Docker image that lets developers easily prepare and flash RPi configurations.The PI-CI project enables developers to easily:Example use cases:Key features:Each command has a help message, for example:\ndocker run --rm -it ptrsr/pi-ci start -h.Simply run a ptrsr/pi-ci container with the start command:The emulator will automatically log into root.To save the resulting image, use a bind mount to /dist:NOTE: this example will create and mount the dist folder in the current working directory of the host.To restart the image, simply use the same bind mount.To enable ssh access, run the container with port 2222 exposed.Then ssh into the virtual Pi:The default image is 2 gigabytes in size. This can be increased (but not decreased!) throu"
  },
  {
    "title": "Launch HN: Moonglow (YC S24) \u2013 Serverless Jupyter Notebooks",
    "points": 78,
    "submitter": "tmychow",
    "submit_time": "2024-08-23T15:20:20",
    "num_comments": 49,
    "comments_url": "https://news.ycombinator.com/item?id=41329750",
    "comments": [
      "xxx"
    ],
    "link": "item?id=41329750",
    "first_paragraph": ""
  },
  {
    "title": "Playing Sudoku in TypeScript while the type checker highlights mistakes (github.com/gruhn)",
    "points": 135,
    "submitter": "mjcurl",
    "submit_time": "2024-08-19T21:18:19",
    "num_comments": 50,
    "comments_url": "https://news.ycombinator.com/item?id=41294663",
    "comments": [
      "Using TypeScript for the entire stack feels like a superpower. The type system is incredible. V8 is fast. The frameworks are phenomenal (Next.js, Material UI, etc). The ecosystem is enormous, with packages for everything. The unified codebases save gobs of duplicate code (e.g. ferrying data betwixt client/server). I'm not surprised that such an expressive system can play Sudoku!\n \nreply",
      "For me, it's the opposite. The type system is decent, but it's generics can get extremely out of hand, it's not sound, and I run into weird type errors with libraries more often than not.Having no integer types (ok, this isn't something typescript could just implement) other than BigInt is another big one for me.That you can just do `as unknown as T` is an endless source of pain and sometimes it doesn't help that JS just does whatever it wants with type coercion. I've seen React libraries with number inputs that actually returned string values in their callbacks, but you wouldn't notice this until you tried doing addition and ended up with concatenation. Have fun finding out where your number turned into a string.The number of times I've read `... does not exist on type undefined` reaches trauma-inducing levels.TypeScript is as good as it can get for being a superset of JS. But it's not a language I have fun writing stuff in (and I even fear it on the backend). It has its place, and it's definitely a decent language, but I would choose something else for frontend if I could, and wouldn't use it on the backend at all. I somehow don't trust it. I know people write amazing software with it, but YMMV I guess.\n \nreply",
      "> it's not soundThis comes up in every one of these threads and I always wonder: do you actually experience problems with soundness in your regular coding? (Aside from `as unknown`, which as others have noted just means you need a linter to stop the bad practices.)It feels like such a theoretical issue to me, and I've yet to see anyone cite an example of where it came up in production code. The complaint comes off as being more a general sense of ickiness than a practical concern.\n \nreply",
      "yes, all the time. It's more of an issue of no runtime type safety, which makes it a poor choice for many backend projects. There are workarounds, but it's silly when there are many better alternatives.\n \nreply",
      "> It's more of an issue of no runtime type safety...This is a completely orthogonal question to soundness.\n \nreply",
      "You're blaming TypeScript for self-inflicted wounds.Don't blame the type system that you banished (with `as unknown as T`) for not catching you; or for some React library having bugs, e.g. an incorrect interface; for not defining types and Pikachu-facing when types are `undefined`. These traumas are fixed by using TypeScript, not ignoring it.\n \nreply",
      "These issues don't exist in languages that aren't built on a marsh.More specifically though, I feel like the way javascript libraries with types work is often painful to use and that's why people use TS's escape hatches, whereas the same thing doesn't happen in languages where everything is built on types from the get go.The same friction is true for example of using C libraries from other languages.\n \nreply",
      "\"don't exist in languages that aren't built on a marsh\"Sure. Last time I checked, JavaScript is the language that actually powers the web. If you can get a language that isn't built on a marsh along with all the libraries to run the web, I'll switch in a second.In other words, the criticism is simply irrelevant. If it works, it works. We don't talk about technologies that don't exist.\n \nreply",
      "We do in fact talk about technologies that don't exist. Creating new technologies would be rather difficult otherwise.\n \nreply",
      "When they don't have to interface with JS apis (e.g., for the DOM) this is true for libraries in other languages built for WASM.\n \nreply"
    ],
    "link": "https://github.com/gruhn/typescript-sudoku",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Playing Sudoku in TypeScript while the type checker highlights mistakes.\n      This is an experiment to precisely define a Sudoku type.\nThe goal is that we can play Sudoku in TypeScript while the type checker complains about mistakes.\nThis is not about implementing a Sudoku solver.\nJust about writing unnecessarily complicated type definitions.\nFor the final result, check out sudoku_v2.ts.As a first approximation we can define the type as an array of numbers:This permits all valid Sudokus, but also allows many invalid Sudokus.First, all array elements have to be integers in the range 1 to 9.\nSecond, Sudokus are 9-by-9 grids so we need an array with exactly 81 elements.\nThat's easy enough:But the interesting part is: how do we enforce the Sudoku rules?\nCurrently, this still type checks:We have to make sure thatFor simplicity, let's ju"
  },
  {
    "title": "Vega \u2013 A declarative language for interactive visualization designs (vega.github.io)",
    "points": 183,
    "submitter": "worble",
    "submit_time": "2024-08-23T13:15:40",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=41328749",
    "comments": [
      "xxx"
    ],
    "link": "https://vega.github.io/vega/",
    "first_paragraph": "Vega is a visualization grammar, a declarative language for creating, saving, and sharing interactive visualization designs. With Vega, you can describe the visual appearance and interactive behavior of a visualization in a JSON format, and generate web-based views using Canvas or SVG.Version 5.29.0Vega provides basic building blocks for a wide variety of visualization designs: data loading and transformation, scales, map projections, axes, legends, and graphical marks such as rectangles, lines, plotting symbols, etc. Interaction techniques can be specified using reactive signals that dynamically modify a visualization in response to input event streams.A Vega specification defines an interactive visualization in a JSON format. Specifications are parsed by Vega\u2019s JavaScript runtime to generate both static images or interactive web-based views. Vega provides a convenient representation for computational generation of visualizations, and can serve as a foundation for new APIs and visual "
  },
  {
    "title": "SurrealEngine: Open-source reimplementation of Unreal Engine with playable UT99 (github.com/dpjudas)",
    "points": 285,
    "submitter": "klaussilveira",
    "submit_time": "2024-08-23T14:50:09",
    "num_comments": 113,
    "comments_url": "https://news.ycombinator.com/item?id=41329505",
    "comments": [
      "I just ported Quake III to the web with multiplayer and mobile support: https://thelongestyard.link/. I was hoping I could use this project to do Unreal Tournament as well, but it seems like it's not that playable yet.I wish Epic had GPL'd their old releases the way id Software did. I'd especially like to have UT2k4. I played a lot of ONS-Torlan in college.Instead of UT I may do Serious Sam next. Serious Engine was open sourced and there's already a web port (without multiplayer): https://www.wasm.builders/martinmullins/serious-sam-in-the-b...\n \nreply",
      "Ut2k4 is so fantastic, I still have a scar on my forehead from the first time I played the demo on a CRT sitting on a chair and my friend tackled me into it to \"save me from a sniper\". I would get up at 4am because I had a bedtime but no wakeup time and play 4 hours of CTF-Face instagib before school. Q3DM17 also holds a special place in my heart, I'm getting a tattoo of the \"Impressive\" emblem in a few weeks!Not a day goes by that I don't pine for turn of the century FPS gameplay. (and maybe my turn of the century reflexes)\n \nreply",
      "Instagib was the only way I'd ever play. And the bots in the game were actually (adjustingly) capable so I could play for hours just by myself.\n \nreply",
      "UT's bots really helped at smaller LAN parties and get togethers. They weren't as competitive as professional players, yet could actually play the different modes and fill out the teams.Before that point bots seemed only capable of team death match.\n \nreply",
      "If you have a copy of the game there's still playable servers using Openspy ( http://beta.openspy.net/en/server-list/ut2004 ).I play regularly and the couple of servers I play on get full to the point nobody else can join...\n \nreply",
      "Haha this is incredible! I had a gap in my gaming years\u2014I only enjoyed UT GOTY (a 2000 release?)\u2014and sounds like the series carried the same kill streak sound bites over. Impressive is prob a safer tatt than HEAD SHOT!\n \nreply",
      "UT2k4 deserves to live, but if we're being honest, there weren't a lot of people playing it during the last decade and a half. I wonder if being able to play it in a browser would actually improve that.\n \nreply",
      "Even the latest UT on UE4 had like few hundreds of players at best.Seems like the genre is just not popular.\n \nreply",
      ">I'd especially like to have UT2k4.Honorable mention to UT2k3's menu music:https://www.youtube.com/watch?v=IberpcWz9mU#t=0m10sThe NFL themes had nothing on it.\n \nreply",
      "Goosebumps\n \nreply"
    ],
    "link": "https://github.com/dpjudas/SurrealEngine",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n          \n        Unreal Tournament Engine Reimplementation\n      The goal of this project is to reimplement enough of the original Unreal Engine to make the Unreal Tournament (UT99) maps playable.The engine can load and render the maps. The Unrealscript VM is almost feature complete - only arrays and network conditional execution are not implemented yet.It will attempt to load all level actors and initialize the map. However, while the menus and the HUD will appear, there are still many native functions not implemented yet. It is also quite possible some events aren't firing as they should. You will therefore see exceptions shown if you interact with them and that is where the project is at.At the time of this writing, SurrealEngine can detect the following UE1 games:From the list above, only Unreal Tournament v436 and Unreal Gold v226 is in a relat"
  }
]