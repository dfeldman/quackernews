[
  {
    "title": "Terence Tao: One of my papers got declined today (mathstodon.xyz)",
    "points": 386,
    "submitter": "GavCo",
    "submit_time": "2025-01-01T19:12:57 1735758777",
    "num_comments": 139,
    "comments_url": "https://news.ycombinator.com/item?id=42568399",
    "comments": [
      "Hilarious irony:> With hindsight, some of my past rejections have become amusing.  With a coauthor, I once almost solved a conjecture, establishing the result with an \"epsilon loss\" in a key parameter.  We submitted to a highly reputable journal, but it was rejected on the grounds that it did not resolve the full conjecture.  So we submitted elsewhere, and the paper was accepted.> The following year, we managed to finally prove the full conjecture without the epsilon loss, and decided to try submitting to the highly reputable journal again.  This time, the paper was rejected for only being an epsilon improvement over the previous literature!\n \nreply",
      "A lot of the replies make it seem like there is some great over-arching coordination and intent between subsequent submissions, but I\u2019ll offer up an alternative explanation: sometimes the reviewer selection is an utter crap shoot. Just because the first set of reviewers may offer a justification for rejection, it may be completely unrelated to the rationale of a different set of reviewers. Reviewers are human and bring all kinds of biases and perspectives into the process.It\u2019s frustrating but the result of a somewhat haphazard process. It\u2019s also not uncommon for conflicting comments within the same review cycle. Some of this may be attributed to a lack of clear communication by the author. But on occasion, it leads me to believe many journals don\u2019t take a lot of time selecting appropriate reviewers and settle for the first few that agree to review.\n \nreply",
      "Or maybe it doesn't matter. He got them published anyway and just lost some prestigious journal points on his career. Science/math was the winner on the day and that's the whole point of it. Maybe some of those lower ranked journals are run better and legitimately chipping away at the prestige of the top ones due to their carelessness.\n \nreply",
      "> sometimes the reviewer selection is an utter crap shootIndeed, but when someone of Tao's caliber submits a paper, any editor would (should) make an extra effort to get the very best researchers to referee the paper.\n \nreply",
      "But isn't that exactly why the submission should be anonymous to the reviewer? It's science, the paper should speak for itself. You don't want a reviewer to be biased by the previous accomplishments of the author. An absolute nobody can make groundbreaking and unexpected discoveries, and a Nobel prize winner can make stupid mistakes.\n \nreply",
      "In subfields of physics, and I suspect math, the submitter is never anonymous. These people talk at conferences, have a list of previous works, etc., and fields are highly specialized. So the reviewer knows with 50-95% certainty who he is reviewing.\n \nreply",
      "The reviewer wouldn't need to know, just the one coordinating who should review what.\n \nreply",
      "Inherent in the editor trying to \"get the very best researchers to [review] the paper\" is likely to be a leak of signal. (My spouse was a scientific journal editor for years; reviewers decline to review for any number of reasons, often just being too busy and the same reviewer is often asked multiple times per year. Taking the extra effort to say \"but this specific paper is from a really respected author\" would be bad, but so would \"but please make time to review this specific paper for reasons that I can't tell you\".)\n \nreply",
      "I didn\u2019t read the comment to mean the editor would explicitly signal anything was noteworthy about the paper, but rather they would select referees from a specific pool of experts. From that standpoint, the referee would have no insight into whether it was anything special (and they couldn\u2019t tell if the other referees were of distinction either).\n \nreply",
      "Doesn\u2019t that just move the source of bias from the reviewer to the coordinator? Some \u2018nobody\u2019 submitting a paper would get a crapshoot reviewer while a recognisable \u2018somebody\u2019 gets a well regarded fair reviewer.\n \nreply"
    ],
    "link": "https://mathstodon.xyz/@tao/113721192051328193",
    "first_paragraph": ""
  },
  {
    "title": "Rails for Everything (literallythevoid.com)",
    "points": 101,
    "submitter": "FigurativeVoid",
    "submit_time": "2025-01-01T20:58:04 1735765084",
    "num_comments": 35,
    "comments_url": "https://news.ycombinator.com/item?id=42569236",
    "comments": [
      "I've been building some apps with stacks lately that are supposed to be more modern and performant. Namely an app with Spring Boot and another with Micronaut. Both had a React frontend. It really made me appreciate Rails' omakase approach. Just having a form that shows validation errors from the backend and having something as simple as Rails' flash messages isn't solved by the frameworks themselves and requires you to build it yourself or find a third-party solution that might or might not do the basic thing you need or might or might not be well-supported. Rails truly solves the problems 90% of web apps share. It might not be in a way that's perfect for your specific project but it will likely work and you can swap it out one you've validated you app or feature.\n \nreply",
      "As a single developer of an open source Rails project that has grown to serve ~120k MAU, I can attest to this article\u2019s claims. One tidbit to add: ActiveStorage, which provides file attachment features, is another excellent piece of the Rails family. I\u2019ve been using Dokku but looking forward to trying Kamal. Rails keeps getting better, and Ruby keeps getting faster.\n \nreply",
      "I\u2019m curious on others thoughts on whether or not to use Devise?With the recent Rails updates, even in Rails 7, Devise didn\u2019t seem that useful and seemed to over complicate the user authentication, registration, lost password experience and also seemed like I had to do a lot of work overriding their views to fit with my application. It seemed easier to not use Devise? It had its usefulness in earlier versions of Rails but not so much now?\n \nreply",
      "My experience is opposite. Getting devise up and running is very easy. Adding OAuth for GitHub, google, and other providers is also very easy. Editing views is pretty straightforward - you can put your forms or whatever you want - just post the form data to devise endpoint and that\u2019s it. All in probably will take 30 minutes to set it up.\n \nreply",
      "Devise bakes in a lot of knowledge about auth. You probably don't need it for a simple app. As your needs grow, when you need things like social logins, Devise makes that easier. If you get really big you probably will have to build out something bespoke anyway. So Devise is sort of for the middle of the journey.\n \nreply",
      "For very simple username/password authentication, what Rails 8 provides is probably sufficient. But the moment you need other auth providers, 2FA, etc., Devise is very much still useful.\n \nreply",
      "Interesting, I hadn\u2019t really thought about using, or knew, it could handle that type of authentication. That\u2019s good to know\n \nreply",
      "Don't really know much about Rails because I wound up picking Django instead when faced with the choice many years ago. That said, honestly, my perspective of Ruby on Rails has been tainted by watching GitLab get pwned over and over and over. My distro can barely keep up with GitLab being pwned because by the time the security release hits stable channels there's already another CVE. I liked GitLab, but something is deeply wrong.Of course clearly not all apps are GitLab, but GitLab is the only Rails app I run, and must be one of the most problematic software I've ever deployed for security patching, and most of it seems to do with issues in the Ruby side of things. What makes GitLab so uniquely crap at security, and how do you avoid it as a Rails developer?\n \nreply",
      "As a counter-point (and I know nothing about Gitlab), but GitHub and Shopify are both prominent Rails apps with pretty good security records. GitHub wrote about it last year: https://github.blog/engineering/architecture-optimization/bu...I think the answer to your question is the same as any large application: pay attention to your supply chain, architect your systems well, if you don\u2019t know how to do things securely go learn before building (or learn as you go, but that has consequences typically).\n \nreply",
      "Gotta say, this comment is spot on.  I had a small peek under the covers when another of the major severity issues surfaced and the conclusion reached is that the software is fragile as f*k.  I'll be migrating as soon as I have some spare cycles.  Still no conclusion as to whether Rails, Ruby or GitLab is the major contributor, but the result is awefull.\n \nreply"
    ],
    "link": "https://literallythevoid.com/blog/rails_for_everything.html",
    "first_paragraph": "Published: 2025-01-01\n        After spending part of my holiday building and deploying a new Rails 8\n        application, It's clearer than ever that Rails is awesome, and it's\n        especially great for small projects with a single developer.\n      \n        The latest\n        Getting Started with Rails\n        guide is really excellent. There's a bit of hand waving around\n        installing Ruby (which is still more difficult than it needs to be). But\n        if you follow it start to finish, you'll have a Rails app\n        in production. And it isn't just\n        hello world. Your app will have authentication, caching,\n        rich text, continuous integration, and a database. That's a real\n        application.\n      If you're brand new to Rails, the guide is the best place to start.\n        SQlite is a great tool, but its focus on backwards compatibility means\n        that it wasn't ideal for a production database out of the box. You\n        had to add some gems\n        to get it "
  },
  {
    "title": "DOOM CAPTCHA (doom-captcha.vercel.app)",
    "points": 712,
    "submitter": "denysvitali",
    "submit_time": "2025-01-01T14:12:15 1735740735",
    "num_comments": 183,
    "comments_url": "https://news.ycombinator.com/item?id=42566112",
    "comments": [
      "+100 for technical chops, -100 for usability. +10 for the trip down memory lane, and the self-realization that I now suck at playing video games.\n \nreply",
      "This is the secret level (E1M9) that you'd normally encounter after E1M3. By this point in the regular progression you'd have found a shotgun, chaingun, rocket launcher, and probably some armor. Starting this level with just a pistol (and it looks like maybe U-V or Nightmare difficulty) is just begging for a buttwhipping.\n \nreply",
      "I managed to pass the catcha on my on my second attempt \\o/\n \nreply",
      "Yes, this is set to Nightmare, don't feel that bad.\n \nreply",
      "This is the funniest and the most elaborate way of closing form submissions that I think I've ever seen. Well done!\n \nreply",
      ">and the self-realization that I now suck at playing video games.Nah... No mouselook really makes this much harder. Took me over 10 attempts to pass, and I'm Diamond at Overwatch.\n \nreply",
      "Didn't realize that was a thing. Was using the keyboard the whole time. Took a few tries to figure out how to strafe... and then just kept the spacebar pressed the whole time, and cleared the CAPTCHA. :)\n \nreply",
      "you can strafe?\n \nreply",
      "Yeah, amusingly, I use a keyboard that doesn't have arrow keys. I've bound them to a different layer, but that doesn't work well with this setup.If this implementation supported the now-standard WASD (which was absolutely used by some high-level Doom players back in the day) AND if it allowed me to fire using the left mouse button (again, like the original game), then it would have been relatively easy to prove that I'm a human. :)\n \nreply",
      "Not sure if wasd was used by high profile Doom players. You see, there weren't many keybinds. You had ctrl and alt for shoot and strafe (fun thing to do was press del casually on a player's keyboard, like Russian roulette, then be like 'WTF crash?'), and you had the arrow keys for movement. Then you had 4 keys for weapons in Wolf3d and some more in Doom. Swapping those required travel, but IIRC swap wasn't instant. So, no crouch, no jump, no look up or down, not even reload IIRC. Games utilizing wasd were usually multiplayer games. One would sit left, with wasd. One would sit right, with arrow keys.\n \nreply"
    ],
    "link": "https://doom-captcha.vercel.app/",
    "first_paragraph": "\n      A CAPTCHA that lets you play DOOM\u00ae to prove you're human (for\n      educational and entertainment purposes)\n    \n      The project works by leveraging Emscripten to compile a\n      minimal port of Doom to WebAssembly and enable\n      intercommunication between the C-based game runloop (g_game.c) and the\n      JavaScript-based CAPTCHA UI.\n    \n      Some extensions were made to the game to introduce relevant events\n      needed for its usage in the context of a CAPTCHA.\n    \nSee the v0 UI generation\n      or\n      get the source.\n    \nBuilt on the shareware version of DOOM\u00ae released publically for\n        non-commercial use. DOOM\u00ae is a registered trademark of id Software\n        LLC, a ZeniMax Media company.\nat least 3 monsters"
  },
  {
    "title": "How AI is unlocking ancient texts (nature.com)",
    "points": 57,
    "submitter": "Marceltan",
    "submit_time": "2024-12-30T13:35:46 1735565746",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42549123",
    "comments": [
      "There isn't much about accuracy:\"Ithaca restored artificially produced gaps in ancient texts with 62% accuracy, compared with 25% for human experts. But experts aided by Ithaca\u2019s suggestions had the best results of all, filling gaps with an accuracy of 72%. Ithaca also identified the geographical origins of inscriptions with 71% accuracy, and dated them to within 30 years of accepted estimates.\"and\"[Using] an RNN to restore missing text from a series of 1,100 Mycenaean tablets ... written in a script called Linear B in the second millennium bc. In tests with artificially produced gaps, the model\u2019s top ten predictions included the correct answer 72% of the time, and in real-world cases it often matched the suggestions of human specialists.\"Obviously 62%, 72%, 72% in ten tries, etc. is not sufficient by itself. How do scholars use these tools? Without some external source to verify the truth, you can't know if the software output is accurate. And if you have some reliable external source, you don't need the software.Obviously, they've thought of that, and it's worth experimenting with these powerful tools. But I wonder how they've solved that problem.\n \nreply",
      "> Obviously 62%, 72%, 72% in ten tries, etc. is not sufficient by itself. How do scholars use these tools? Without some external source to verify the truth, you can't know if the software output is accurate. And if you have some reliable external source, you don't need the software.Without an extant text to compare, everything would be a guess. Maybe this would be helpful if you're trying to get a rough and dirty translation of a bunch of papyri or inscriptions? Until we have an AI that's able to adequately explain it's reasoning I can't see this replacing philologists with domain-specific expertise who are able to walk you through the choices they made.\n \nreply",
      "I wonder if maybe the goal is to provide the actual scholars with options, approaches or translations they hadn't thought of yet. In essence just what you said, structured guessing, but if you can have a well-trained bot guess within specific bounds countless times and output the patterns in the guesses, maybe it would be enough. Not, \"My AI translated this ancient fragment of text,\" but \"My AI sent us in a direction we hadn't previously had the time or inclination to explore, which turned out to be fruitful.\"\n \nreply",
      "The full title is \"How AI is unlocking ancient texts \u2014 and could rewrite history\", and that second part is especially fitting, although unfortunately not mentioned in the article itself, which is full of rather horrifying stories about using AI to \"fill in\" missing data, which is clearly not true data recovery in any meaningful sense.I am aware of how advanced algorithms such as those used for flash memory today can \"recover\" data from imperfect probability distributions naturally created by NAND flash operation, but there seems to a huge gap between those, which are based on well-understood information-theoretic principles, and the AI techniques described here.\n \nreply",
      "I find this incredibly exciting. There could be some truly remarkable works whose contents are about to be revealed, and we don\u2019t really know what we might find. Histories of the ancient (more ancient) world. Accounts of contact with cultures and civilizations that are currently lost to history. Scientific and mathematical discoveries. And what I often find to be the most moving: stories of daily life that illuminate what regular people thought and felt and experienced thousands of years ago.\n \nreply",
      "This is a great application of various domains of ML. This reminds me of Vesuvius Challenge. This kid of thing is accessible to beginners too since the data by definition are pretty limitted.\n \nreply",
      "From TFA \"decoding rare and lost languages of which hardly any traces survive\". Assuming that's not hype, let's see it have a go at Rongorongo[1] then.[1] https://en.m.wikipedia.org/wiki/Rongorongo\n \nreply",
      "and Linear A [1]. To be fair, whatever model would require data about the context of where the texts were found unless the corpus is massive.https://en.wikipedia.org/wiki/Linear_A\n \nreply",
      "The really nice thing about this is that the AI can now acquire these newly-decoded texts as part of its training set, and begin learning at a geometric rate.\n \nreply",
      "But do I want to see ancient programming advice written in Linear B?\n \nreply"
    ],
    "link": "https://www.nature.com/articles/d41586-024-04161-z",
    "first_paragraph": "Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.AdvertisementJo Marchant is a science journalist based in London.You can also search for this author in PubMed\n\u00a0Google Scholar\nThe \u2018Fragmentarium\u2019 project is digitizing tens of thousands of cuneiform tablets, such as this astronomical text. Credit: Ludwig-Maximilians-Universit\u00e4tIn October 2023, an e-mail pinged onto Federica Nicolardi\u2019s phone with an image that would transform her research forever. It showed a fragment of a papyrus scroll that had been burnt in the eruption of Mount Vesuvius in ad 79. The scorched scroll was one of hundreds discovered in the remains of a luxury Roman villa in Herculeaneum, near Pompeii in I"
  },
  {
    "title": "Databases in 2024: A Year in Review (cmu.edu)",
    "points": 367,
    "submitter": "avinassh",
    "submit_time": "2025-01-01T14:27:39 1735741659",
    "num_comments": 114,
    "comments_url": "https://news.ycombinator.com/item?id=42566192",
    "comments": [
      "Wow, the reasons why Redis commands API suck in Andy's video (linked in the post) are the weakest ever. It is possible to make a case against the Redis API (I would not agree of course but... it's totally legitimate), but you gotta have stronger arguments than those, particularly if you are a teacher of some kind. Especially: you need to be somewhat fluent in Redis and how developers use Redis in order to understand why so many people like it, and then elaborate what it's wrong about it (if you believe there is something wrong). The video shows a general feeling of \"I don't really use / know this, but I don't like how NON-SQL it is\".\n \nreply",
      "> Wow, the reasons why Redis commands API suck in Andy's video (linked in the post) are the weakest ever.In my example, the API on a key changes based on its value type. And the same collection can have different value types mixed together. You've recreated the worst parts of IBM IMS from the 1960s. However, the original version of IMS only changed the API when a collection's backing data structure changed. Redis can change it on every key!We didn't get into the semantics of Redis' MULTI...EXEC, which the documentation mischaracterizes as \"Transactions\". I'm happy that at least you didn't use BEGIN...COMMIT.\n \nreply",
      "You totally miss that Redis is more like a remote interpreter with a DSL that manipulates data structures stored at global variables (keys): you (hopefully) would never complain about languages having this semantics.I don't think you understood how Redis collections work. The items are just strings, they can't be mixed like integers or strings together or whatever, nor collections can be nested.The Redis commands do type checking to ensure the application is performing the right operation.In your example, GET against a list, does not make sense because:1. GET is the retrieve-the-key-of-string-type operation.2. Having GET doing something like LRANGE 0 -1 would have many side effects. Getting for error a huge list and returning a huge data set without any reason, creating latency issues. Also having options for GET to provide ranges (SQL alike query languages horror story). And so forth.So each \"verb\" should do a specific action in a given data type. Are you absolutely sure you were exposed enough to the Redis API, how it works, and so forth?About MULTI/EXEC, when AOF with fsync configured correctly is used, MULTI/EXEC provide some of the transactional guarantees you think when you hear \"transaction\", but in general the concept refers to the fact that commands inside MULTI/EXEC have an atomic effect from the point of view of an external observer AND point-in-time RDB files (and AOF as well). MULTI / INCR a / INCR a / EXEC will always result in the observer to see either 2, 4, 6, 8, and so forth, and never 3 or 5.Anyway, I believe you didn't put enough efforts in understanding how really Redis works. Yet you criticized it with weak arguments in front of the most precious good we have: students. This is the sole reason why I wrote my first comment, I believe this to be a wrong teaching approach.\n \nreply",
      "> 1. GET is the retrieve-the-key-of-string-type operation.That's a tautological argument. The question isn't what the definition of GET is, but whether the design is good.> 2. Having GET doing something like LRANGE 0 -1 would have many side effects. Getting for error a huge list and returning a huge data set without any reason, creating latency issues.If this really were the reason, you'd have separate operations for tiny strings and huge strings. After all, by analogy having GET return a huge string \"without any reason\" would create latency issues.But that's not how Redis works, right?\n \nreply",
      "The examples I made are just a subset of the protection that this provides. Similarly you can't LRANGE a set type, and so forth. So this in general makes certain errors evident ASAP (command mismatch with the key type).This does not meant that Redis would not work having generic LEN, INSERT, RANGE commands. But such commands would end also having type-specific options, that I have the feeling is not very clean. Anyway these are design tastes, but I don't think they dramatically change what Redis is or isn't. The interesting part is the data model, the idea of commands operating on abstract data structures, the memory-disk duality, and so forth. If one wants to analyze Redis, and understand merits and issues, a serious analysis should hardly focus on these kind of small choices.\n \nreply",
      ">> stored at global variablesThis is an interesting (and correct) perspective. Global variables scare us in software but we are ok with it when it comes to application state stored in a db.\n \nreply",
      "> You totally miss that Redis is more like a remote interpreter with a DSL that manipulates data structures stored at global variables (keys):I think he makes the point that these \"global variables\" are dynamically typed; you can have \"listX\" and then write a non-list into that same name; statically typed systems would not allow this.   He makes the fairly non-controversial point that a statically typed system (SQL, other than that of SQLite) adds a level of type safety that can guard against software bugs.\n \nreply",
      "Just because there are reasons for why Redis sucks doesn\u2019t meant it doesn\u2019t suck\n \nreply",
      "With all due respect, the linked video was pretty fair. It didn't imply not to use Redis, just not as a primary datastore.I don't think folks work with Redis out of fondness for the model, but because it's the least worst datastore for caching, lightweight message broker, and simple realtime things like counters.\n \nreply",
      "Talking about the broken API argument here. Also Redis is particularly useful exactly in other situations compared to what OP says. Leaderboards style use cases with sorted sets are killer applications (super hard to model with SQL) of the data structure server thing. Apparently OP does not understand this and says \"simple GET/SET\" is what you should use Redis for.Redis has probabilistic data structures, the ability to implement complex queueing patterns, and so forth. That's where the value is. Otherwise we would still be just with Memcached without caring about Redis. Another killer app was Twitter initial use case (then they used it for pretty much everything): to cache latest N Tweets, using capped lists. I could continue forever.So OP argoment is flawed IMHO, for the above arguments, not fair. When you talk to students you need to make your homeworks. Really understand the system you are talking and provide a realistic image of it. Then, yes, if you want, criticize it as much as you want, with grounded arguments.You know what? I re-read this comment and it's embarassing I ever have to write this, because after 15 years of Redis history at such scale and popularity, pretty much everybody that was seriously exposed to Redis knows those stuff. Is tech culture really degraded so much that we have to restate the obvious? Do I really need to explain GET/SET is not exactly where Redis shines after 15 years of half the Internet used all the kind of Redis patterns?\n \nreply"
    ],
    "link": "https://www.cs.cmu.edu/~pavlo/blog/2025/01/2024-databases-retrospective.html",
    "first_paragraph": "Posted on January 01, 2025Like a shot to your dome piece, I'm back to hit you with my annual roundup of what happened in the rumble-tumble game of databases. Yes, I used to write this article on the OtterTune blog, but the company is dead (RIP). I'm doing this joint on my professor blog.There is much to cover from the past year, from 10-figure acquisitions, vendors running wild in the streets with license changes, and the most famous database octogenarian splashing cash to recruit a college quarterback to impress his new dimepiece.I promised my first wife that I would write more professionally this year. I have also been informed that some universities assign my annual blog articles as required reading in their database courses. Let's see how it goes.Previous entries:We live in the golden era of databases. There are many excellent (relational) choices for all types of application domains. Many are open-source despite being built by for-profit companies backed by VC money.But VCs want t"
  },
  {
    "title": "My 25-year adventure in AI and ML (austinhenley.com)",
    "points": 16,
    "submitter": "ibobev",
    "submit_time": "2025-01-01T22:41:16 1735771276",
    "num_comments": 3,
    "comments_url": "https://news.ycombinator.com/item?id=42569913",
    "comments": [
      "> Although I was on an AI team, I often pushed back against applying AI unless we had a really compelling reason. What is the user problem we are trying to solve? Do we really need an LLM or could a few if statements suffice? Are we sure that natural language is the appropriate interface for this?This practical approach to AI feels refreshing in a field drowning in buzzwords. I\u2019ve built tools where simple regression models outperformed neural networks, and convincing teams was an uphill battle. It's hard to not get pushback from teams for not going all-in on AI when it seems decisions and budgets are hype-driven.\n \nreply",
      "I saw this guy recently left UTK, which is close to my hometown.  He made a blog post which made me rethink going into academia after grad school.\n \nreply",
      "Which one and in which direction did you rethink?Your comment made me curious so I looked at his posts and he has a one about leaving academia because he wasn't happy in 2022, and a more recent one about rejoining it some months ago.https://austinhenley.com/blog/leavingacademia.htmlhttps://austinhenley.com/blog/rejoiningacademia.html\n \nreply"
    ],
    "link": "https://austinhenley.com/blog/25yearsofai.html",
    "first_paragraph": "\n\t\t\t\t\t\tAssociate Teaching Professor\n\t\t\t\t\t\tCarnegie Mellon University\n\t\t\t\t\tI never intended to work with AI or ML. It more so happened along the way naturally from using whatever tools I needed for the task, and eventually it took over. I didn't even realize it at the time.Given that it is New Year's Eve, it seems appropriate to look back on my career to see how I got here. Let's go back to the year 2000 and walk through the major AI/ML projects I worked on.I've talked about how I got into programming before: Learning HTML was too hard so I made a compiler instead. But along the way, I also tried to make video games (like any kid).The first project I remember making in VB6 was a game based on Tamagotchi pets.Unfortunately, I had no idea how to make the pet \"come alive\".The best I came up with was a timer that triggers some effect every X seconds plus some conditionals. Increase pet's hunger every 10 seconds. Decrement health every 3 seconds if hunger level is greater than 5. Faint if he"
  },
  {
    "title": "How the lore of New Year defeated the law of New Year (davidallengreen.com)",
    "points": 55,
    "submitter": "quickfox",
    "submit_time": "2025-01-01T20:02:19 1735761739",
    "num_comments": 19,
    "comments_url": "https://news.ycombinator.com/item?id=42568805",
    "comments": [
      "In the UK, the financial year ends on 5 April. This is Lady Day (25 March) plus the 11 days lost in the transition from the Julian calendar to the Gregorian calendar in 1752.\n \nreply",
      "Most US annual taxes are due April 15; is that related somehow?\n \nreply",
      "No, that\u2019s the tax year, not when it\u2019s due.  The standard US tax year is Jan 1 -> Dec 31.\n \nreply",
      "It seems awkward not ending on the last day of the month. In NEw Zealand it's close, the FY ends on 31 March.\n \nreply",
      "In Exodus 12:1-2, at the beginning of the section that decrees Passover, God also tells Moses and Aaron that the month of Passover is the first month of the year:  The Lord said to Moses and Aaron in Egypt, \"This month is\n  to be for you the first month, the first month of your\n  year. ...\"\n \nreply",
      "March coincides with the first month of the Jewish calendar.https://www.chabad.org/library/article_cdo/aid/2164005/jewis...It was also the first month of the Roman calendar until January and February were added.https://en.wikipedia.org/wiki/Martius_(month)\n \nreply",
      "It is absurd and stupid to have the beginning year not also be the beginning of a month. (Same for weeks to months, things a dumb feature of our calendar). But December vs March is totally arbitrary, right?\n \nreply",
      "The only rational points for the beginning of a year are the solstices or the equinoxes.From the point of view of an inhabitant of the northern hemisphere, the choice remains between the Winter solstice, i.e. the moment when the Sun begins its journey on the sky back towards us, after reaching a maximum distance on the sky from us, and the Spring equinox, the moment when the Sun returns on the sky to the northern hemisphere.Those who are guilty for the fact that the solstices and the equinoxes do not fall on beginnings of months are Julius Caesar and his astronomer consultant, Sosigenes.The Roman calendar had been very bad and it had drifted extremely from the astronomical year. The calendar reform of Caesar has corrected the length of the year, but it has failed to align the solstices and the equinoxes with the beginnings of months. Instead of that, the Winter solstice fell on the 25th of December and the Spring equinox fell on the 25th of March.So the calendar of Julius Caesar is the origin of the adoption of the 25th of December for the Christmas and of the 25th of March for the beginning of the year in several countries.Additional confusion has been created by the Gregorian calendar, which has not restored the calendar from the beginning of the Christian era, but it has restored the calendar of the 4th century, when the rules for computing the date of the Easter have been established. The calendar of the 4th century had been shifted by 3 days since the calendar reform of Caesar, resulting in the current dates for the Winter solstice and the Spring equinox around the 22th of December and the 22th of March.So now not only the solstices and equinoxes do not fall on the beginnings of months, but they no longer fall on the traditional days of the 25th of their months.\n \nreply",
      "> The only rational points for the beginning of a year are the solstices or the equinoxes.It makes sense to use those as a basis.And it makes sense to line up the months with those points.But if the months don't line up, I think aligning with the nearest month is much better than not doing so.  At least on the kind of solar calendar we use.\n \nreply",
      "When you base the first of anything based on the phases of the moon, you'll more often not be aligned with the 1st of any month. Basing a calendar on the phases of the moon doesn't line up with the full orbit around the sun, so something has to change somewhere. ~365.25 / ~29.53 doesn't work out to a whole number, so whatchagunnado? Leap seconds and leap years! Perfect!\n \nreply"
    ],
    "link": "https://davidallengreen.com/2025/01/how-the-lore-of-new-year-defeated-the-law-of-new-year-how-the-english-state-gave-up-on-insisting-the-new-year-started-on-25-march/",
    "first_paragraph": ""
  },
  {
    "title": "My favourite computer ergonomics hack (jacobvosmaer.nl)",
    "points": 79,
    "submitter": "vortex_ape",
    "submit_time": "2025-01-01T20:39:53 1735763993",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=42569109",
    "comments": [
      "My solution for sitting too long: every time I get up, I drink a glass of water. That ensures I have to get up again! It\u2019s a self-reinforcing loop too.\n \nreply",
      "Tight fitting pants + a belt is a sure-fire \"stand goal\" hack if you drink a lot of water.\n \nreply",
      "This is one of the better applications of an Apple Watch, which will detect when you haven\u2019t stood for a while and pester you to do so.Of course, the watch comes with a giant bundle of other features that may or may not be desired. And building it yourself is so much cooler.\n \nreply",
      "Long ago i wrote a thing that gives you a textbox to explain what you were doing and a countdown enforcing a break.It is funny to read later what you did.(as oppose to what you wanted to get done and what you should have)\n \nreply",
      "Jacob is the best! So glad to see him on HN <3 My favorite line: \"[I want to] thank my wife for pointing out to me that I sit still too much and for putting up with the horrible screeching noises from the Beeper for the past 8 years and counting.\n \nreply",
      "My solution is a bottle with something pleasing to drink.Modern vacuum containers make cold and hot beverages almost constantly available which makes me get up quite frequently.\n \nreply",
      "I use a custom pomodoro timer. Instead of taking a break every 25 minutes, I do it hourly. During my break, I take off my glasses, walk around, stretch, handle small chores and tasks, etc.\n \nreply",
      "This sounds like the kind of thing I would put a cheap z-wave plug on so I could turn it off remotely with Home Assistant, completely defeating its purpose.\n \nreply",
      "I pretty much got out of programming because sitting for too long resulted in me having serious spine problems culminating in surgery. Not sitting long enough means I rarely get into the \u201azone\u2019. I\u2019m glad others have figured it out better\n \nreply",
      "Standing desks can solve that problem. Some have built-in timers reminding you to switch between sitting and standing. After getting used to it, you start reacting automatically and it barely breaks your flow anymore.\n \nreply"
    ],
    "link": "https://blog.jacobvosmaer.nl/0036-beeper/",
    "first_paragraph": "Jacob Vosmaer's blog2024-12-31In this post I will talk about my favourite computer ergonomics hack, a DIY device I call \"The Beeper\".I built the Beeper almost 8 years ago but I have never written a blog post about it and I thought it might be interesting. I do computer work sitting down at a desk at home. When I get focused on my work then I sit still for too long and my body starts hurting. The Beeper solves the sitting still problem.The Beeper consitst of three parts: the hardware, the firmware runnning on the hardware, and software running on my work computer. If my computer screen is unlocked for too long, the Beeper starts beeping and because it is situated away from my desk I must get up to silence it. Mission accomplished: I stopped sitting still.The Beeper is built into a small ABS Hammond 1551KTBU enclosure.Inside the enclosure are an Adafruit Feather Huzzah ESP8266 development board, a momentary switch and a piezo buzzer. The buzzer is glued to the case.The switch connects to"
  },
  {
    "title": "Software Design Is Knowledge Building (olano.dev)",
    "points": 190,
    "submitter": "signa11",
    "submit_time": "2024-12-31T07:59:54 1735631994",
    "num_comments": 56,
    "comments_url": "https://news.ycombinator.com/item?id=42557255",
    "comments": [
      "I've handed off a few services I built with minimal oversight or documentation. The receiving teams have been able to make changes without my involvement and everyone is happy.I believe the only reason I've been successful in this is because I agonize over simplicity. There are times during the development of any project where one might be tempted to hack around an issue, or commit the ugly code that seems to work. These are the rough edges that inheritors of a codebase use as evidence that a blank slate would be preferable. They're also the bits where the underlying business logic becomes murky. My goal is for the code to be so clear that documentation would feel redundant.This approach of course takes more time and requires that your management trusts you and is willing to compromise on timelines. It's extremely rewarding if you can sell it and deliver.\n \nreply",
      "I have the same experience, and I agree that simplicity leads to success. The more things software can do, the harder it is to reason about what it's supposed to do. It's very much the IQ bell curve meme: junior developers only solve the problem at hand, mid-level developers build powerful, but complex frameworks which can solve the problem at hand but also potential future problems, and senior \"X10\" developers only solve the problem at hand.> There are times during the development of any project where one might be tempted to hack around an issue, or commit the ugly code that seems to work. These are the rough edges that inheritors of a codebase use as evidence that a blank slate would be preferable.Yes, one thing I've learned is to never underestimate the power of inertia in a codebase. When adding functionality, 99% of developers will go for the path of least resistance, which is mimicking whatever patterns already exist. To loop back to the article, this is often due to lack of full understanding; the default assumption is that because something is written in a certain way, that it's the best way. This isn't true; it may not even be the correct way! But copying what already exists has an element of safety built into it, without needing to spend the effort to deeply understand existing code (which tends to be developers' least favorite activity).So if you put in an ugly hack, or have a code structure which doesn't make sense, expect that to persist for years, or decades.\n \nreply",
      "I don\u2019t think it\u2019s up to the developers only to decide. If we are working in a sprint, if all my manager cares about is \u201cshipping impact\u201d, then I\u2019m not going to spend time on things that won\u2019t benefit me in my performance review. I\u2019ll take the shortcuts. Now, if management knew what we know, sure certainly everyone would benefit from that\u2026 but that\u2019s not the real world.\n \nreply",
      "> without needing to spend the effort to deeply understand existing codeOr, more importantly, explain to others why you're deviating from \"standard\"\n \nreply",
      "What you've said echoes the concept behind the quote \"I didn\u2019t have time to write you a short letter, so I wrote you a long one.\" This, or some variation of it, has been around for quite a while. I think this reveals a fundamental truth about knowledge based work that is inherent to humans. Purposeful simplicity is harder than accidental complexity.> This approach of course takes more time and requires that your management trusts you and is willing to compromise on timelines.I would say that most management and even most programmers don't see the value in this. In my experience focusing on simplicity gives much better long-term results but it has higher and more unpredictable upfront cost. Blasting code onto main is seen as being more productive even though long-term it seems to have much higher overall costs.\n \nreply",
      "simplicity is a noble ambition, but let it not impede progress, for it is subjective and subject to discretion. The art to be learned and practiced is knowing when to cut corners and where to be relentless with yourself and demand that of others.Getting v0.1 out, albeit with murky code and iterating to v2.5 with 10 paying customers is the way to progress. The hard, non-science part is getting management to spend billable hours for no short term benefit. Thats the key skill.\n \nreply",
      "Documentation is useful, when done well. The code is always the authority, and there are very many ways the correct logic can be constructed. How it is constructed is the difference between good enough and excellent.And getting \"compromise on timelines\" is a most sublime political art. It requires the combination of both a humble, competent manager and an established, successful engineer worthy of trust.Congratulations on your success on those two varied fronts!\n \nreply",
      "I think it depends on who the documentation is intended for.  I often let public facing documentation be the source of truth for expected behavior unless it's infeasible to coerce the system to that behavior.  If the latter does occur, the documentation gets updated.If the question is what does the software actually do, then of course the code, toolchain, and runtime are the authority.\n \nreply",
      "Good point. I was only speaking to targeting other developers.\n \nreply",
      "Thank you! I am indeed very fortunate to have a great manager.\n \nreply"
    ],
    "link": "https://olano.dev/blog/software-design-is-knowledge-building/",
    "first_paragraph": "\nThis is the story of system SVC from company ORG. It\u2019s a true story, but I\u2019ve smoothed out the details: by making it generic, I hope that it will be more familiar.This entire process takes less than a year.\nWhat is going on with SVC? Did X10 do a bad job? By all accounts, she did not. The project was finished on time, according to specifications; ORG will save a lot of money next year. X10 followed best practices, too: good test coverage, no over-engineering. Surely she cut some corners; she didn\u2019t think twice about the design of the system. As in any project, there\u2019s a lot of room for improvement, but nothing that a team of competent engineers couldn\u2019t handle. But, if X10 got the hard part of the job done, how come not one but many teams of competent engineers fail to apply a few small changes to the system?\nWhat fascinates me about this scenario is how a seemingly functional 6-month-old project automatically turns into a haunted forest just by changing hands. Regardless of its age, "
  },
  {
    "title": "Show HN: API Parrot \u00e2\u20ac\u201c Automatically Reverse Engineer HTTP APIs (apiparrot.com)",
    "points": 282,
    "submitter": "pvarghav",
    "submit_time": "2025-01-01T13:15:03 1735737303",
    "num_comments": 79,
    "comments_url": "https://news.ycombinator.com/item?id=42565821",
    "comments": [
      "Impressive project. I was curious how it discovers data relationships and was going to check the repo, but it looks like there's no code, only issues and releases. Is that right?Which leads me to...- Is this closed source?- Does it cost money?- How does it discover data relationships?\n \nreply",
      "Thanks for your interest!- Is this closed source?Currently, the code is not open source, but I might open-source parts of it in the future.- Does it cost money?The software is free to use. If there is demand, I might create a \"pro\" version for businesses in the future. However, I intend to always have a free version available for individuals.- How does it discover data relationships?I've discussed how it discovers data relationships in the documentation here: https://docs.apiparrot.com/docs/tutorial-extras/exchange-mod....In short, the tool breaks down the data in the requests and responses into smaller parts by identifying their formats. For example, `[\"foo\", \"bar\"]` would be recognized as a JSON array and broken down into the elements `\"foo\"` and `\"bar\"`. By applying this method recursively, you build a tree-like structure of the data.If an exact match is found between data in a response from a previous request and data in a subsequent request, a correlation is detected.Please feel free to ask if you have any more questions!\n \nreply",
      "If this can save me time at work, I'd be happy to throw some money at it.My bosses OTOH...let's just say, there's no penalty within companies for pointy haired bosses not making decisions to purchase something like this and ignoring staff.It's a false economy but I'm tired of it and just purchase what I can afford.\n \nreply",
      "Sounds like it has little utility in the real world.\n \nreply",
      "It's entertaining that Github has become such a common place to find information that even closed source projects put something up there\n \nreply",
      "I've just gone through the \"Docs\" section and I appreciate how it covers the intended workflow and use cases. I'm on Debian/Intel and other than the need to install Chrome I only had a few small issues.++ A self contained appImage is a good way to go, but where do you put it? A default install location should be added for those used to an `apt install`.I went `sudo wget $URL -C /usr/local/bin/` and `chmod +x $appimage`. This worked fine until Collection creation when some internal state change smacked into my root owned file permissions. I `chmod 777` it and restarted the app, no more issue. It's my machine and I can chmod how I want but I think doc clarity would help those unfamiliar with appimage.++ Renaming projects, collections, etc is cumbersome. For example, when clicking the 'New Project\" pencil a change name window opens with several steps needed then to rename the project. That single click could combine opening the window, that window grabbing focus, with the cursor in a blank form window, followed by 'Enter'.++ Ability to toggle showing the Properties column. On a 14\" hi rez laptop, the screen is crowded. And resize Project width.++ The default flow view size is too small.I hope that's helpful. A small number of UI tweaks and it's already at \"Don't F*** With It!\" stage. The issues above are small and don't take away from how great and EXCITED I was going through the tutorial. I went through the entire docs and the tutorial and I think it's a fine program. Your layout of the DOM response is also really nice!\n \nreply",
      "Interesting but... The first website I've tried it (which I'm currently working on due to a change of platform) couldn't find anything other than the main request, and I know for sure there is a POST reguest to the API to get some data (I had a scrapper working, website changed, had to re-do the scrapper again).I've checked the tutorial, seems that I'm not missing any step, the software simple cannot capture anything if the request is made on the main page, seems to work fine with forms, buttons and \"manual\" actions.I can DM you the website plus the expected request that is made, visible with any browser internal debugging tools.\n \nreply",
      "How does it compare to mitmmitmproxy2swagger?https://github.com/alufers/mitmproxy2swagger\n \nreply",
      "This might be more useful than the OP. This thing lets you translate HAR to Swagger\u2026My usual process is Dev tools -> Copy as CURL -> delete unnecessary headers -> translates to requests in python (these days I just use ChatGPT) -> wrap in python sdk for managing auth etc.The OP\u2019s correlation features are really nice though.\n \nreply",
      "The first and immediate difference for me is the ability to recall the name. I can recall Postman/Insomina fine, and now for API Parrot. I'm never going to be able to recall mitmproxy2swagger.Unfortunately, names matter.\n \nreply"
    ],
    "link": "https://apiparrot.com/",
    "first_paragraph": "API Parrot is the tool specifically designed to reverse engineer the HTTP APIs of any website. Making life easier for developers looking to automate, integrate or scrape websites without public APIs.From recording requests to exporting executable code, API Parrot has you covered, making the workflow fast and efficient.API Parrot comes with a built-in HTTP Proxy, allowing you to easily record the network traffic from your application.API Parrot cannot only identify the relevant endpoints, it also breaks down and analyzes the data, understanding how the data from different endpoints are related.Based on your requirements, you can customize the functions to suit your needs, specifying the input and output parameters, excluding irrelevant data and more.Export your customized functions as JavaScript code, ready to be integrated into your application.API Parrot comes with a built-in HTTP Proxy, allowing you to easily record the network traffic from your application.API Parrot cannot only ide"
  },
  {
    "title": "Most people don't care about quality (shkspr.mobi)",
    "points": 72,
    "submitter": "ColinWright",
    "submit_time": "2024-12-30T13:24:36 1735565076",
    "num_comments": 59,
    "comments_url": "https://news.ycombinator.com/item?id=42549039",
    "comments": [
      "This is basically the difference between creating art and creating commoditized product. The distinction and the unwillingness to acknowledge the distinction (even though it\u2019s made regardless) creates a lot of friction.The masses don\u2019t give a damn, and if all you\u2019re trying to do is extract maximum revenue as efficiently as possible, there is no reason to expend the additional resources (and incur the additional risks) of doing more than the necessary minimum.The artists/craftspeople have a vision and they care. Then the money arrives and none of that matters to the money.Examples are everywhere. Video game studios discover that they can make a billion with crap story so stop investing resources in story, only the people who care even notice, and there aren\u2019t enough of them to matter: they aren\u2019t the audience anymore. Etc.\n \nreply",
      "> The masses don\u2019t give a damnMore important, even people who _do_ give a damn, don't give a damn about everything. And even the things they do give a damn about, they don't give a damn about every time they \"do that thing\".I give a damn about music. I have a collection of about 3,000 LPs, a few hundred 12\" singles, and over 5,000 CDs. I love to draw the curtains and sit in my dark lounge room, power up my 80's vintage all analogue hifi, and critically listen to albums on vinyl - no distractions, focusing on the music and performance.But that's only maybe 1% of my music listening time. I spend a lot more time listening to music with my earbuds in while exercising or grocery shopping, or in the car. I spend way more time streaming music around the house while doing chores or cooking or reading. I have playlists of music without vocals that I listen to while doing work I need to be able to concentrate doing. Hell, I have Apple Music streaming right now while reading (and posting to HN.I _do_ care about music, but you'd need a decent private investigator to find out, it sure as hell isnt obvious to anyone that's not close to me. And even if you tracked my credit card bills you'd see way more streaming subscription spend than vinyl/cd purchases (which are mostly bought for cash at show merch desks these days).I find most people are passionate about _something_ in the \"care about\" sense here. I love it when I meet someone new or who I don't know well, and can get into a conversation about \"their thing\" - whether it's knitting, or building traditional Inuit canoes, or stage lighting for amateur theatre, or ultra light carbon and titanium bicycles, or building a plane, or sailing the north west passage, or setting a land speed record in some very specific class. All things I'm unlikely to ever even consider wanting to do, but which are fascinating to hear about from someone deeply involved in it.I think (or at least optimistically hope) that \"the masses\" do give a damn. About _something_. You just need to steer the conversation around a bit to find out what their thing is, and be curious and enthusiastic enough to get them talking about it. Its a wonderful thing when that happens, even if what you end up talking about is the drama in purchasing hand dyed yarn from that one woman in Germany on knitting forums, or the history and current land speed record in the 50cc streamlined motorcycle with gasoline fuel class, or what the recommended shotgun shells are for protection against polar bear attack.\n \nreply",
      "This connects quite well with another post discussed in the previous days here on hn, the age of averagehttps://news.ycombinator.com/item?id=42405999\n \nreply",
      "Title is patently false. The first part of the article boils down to \"most people aren't pedants\". The second part is mostly irrelevant because the Netflix pivot to \"casual viewing\" is a bid to enter a new market. Their viewership (and stock) would immediately tank if they switched exclusively to \"casual viewing\". TFA acknowledges this when elevating ABBA against something \"no one has ever heard of\". The insinuation is that popularity equates to quality whereas the opposite is true.It just takes time.Contrary to popular rhetoric, people are neither as dumb nor as smart as you might think.> Fashionistas decry the homogeneity of modern dress. Most of us think jeans and a t-shirt are basically fine.Again, most people are neither pedants nor purists.I think that's the actual point TFA makes, but they chose an inflammatory title.\n \nreply",
      "Agreed, article is totally wrong. Read any Amazon review for a cheap household product and you'd conclude that people have outrageously high expectations of quality.\n \nreply",
      "That\u2019s not people having a high bar for quality. That\u2019s Amazon being absolutely flooded with low quality products to the point you can\u2019t find anything of even decent quality.\n \nreply",
      "Regardless of whether or not your point is right -- I don't think Amazon reviews are a good yardstick for this.  Product reviews are a tiny but noisy minority, who may or may not even act in line with their grievances. (i.e. some people just like to complain)  A better metric would be return rates and/or sales figures.\n \nreply",
      "If by outrageously high you mean standard expectations from a generation ago I'd be more inclined to agree. I expect to get a minimum of 15 years of service out of a major appliance and really they should last indefinitely with repair and maintenance being a viable option. I expect tools to be made well from the correct materials, properly heat treated where applicable, and for them to withstand at least a decade of borderline abuse, generations under nominal household workloads. I expect any item of furniture I purchase to permanently resolve whatever issue that item of furniture resolves. I shouldn't have to replace a bookshelf in my lifetime.The thing is all of these expectations have been casually met with retail goods within living memory. Dude says nobody cares about quality, I'd counter with there are a few generations rattling around that haven't encountered it often enough in life to come to expect it.\n \nreply",
      "I would be interested in knowing if any of those people change their behaviour though. What people say is irrelevant. Do they actually buy differently?\n \nreply",
      "> most people aren't pedantsThey should come visit HackerNews once in a while :D\n \nreply"
    ],
    "link": "https://shkspr.mobi/blog/2024/12/most-people-dont-care-about-quality/",
    "first_paragraph": "@edentdesign Netflix rant \u00b7 5\u00a0comments \u00b7 1,250\u00a0words \u00b7 read\u00a0~635\u00a0times.My friend, the photographer Paul Clarke has an uncanny eye for detail. Every single shot he publishes is beautiful - they capture life in a way that I don't have the language to describe. I'm quite content to point my phone at someone, use the default settings, and grab a snap. My photos lack composition, clarity, focus, mise-en-sc\u00e8ne, proper lighting and a thousand-and-one details that I've never even thought of.Paul has published an essay about official photographs of politicians. In it, he expertly points out the various deficiencies of some of them and where they show a distinct lack of quality.But, here's the thing, I don't think anyone other than a photographer would notice or care about those \"problems\".If you're a website designer, you're always noticing \"jank\" on other sites. Your skin crawls at the poor kerning, the FOUT, the lack of keyboard navigation, improper contrast ratio, and a dozen other flaws. 99"
  },
  {
    "title": "Glue Work Considered Harmful (seangoedecke.com)",
    "points": 22,
    "submitter": "polyphilz",
    "submit_time": "2025-01-02T00:09:54 1735776594",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=42570390",
    "comments": [
      "All work is glue work.  If you believe your work isn't glue work, you're indulging hubris.\n \nreply",
      "I think this article treat result as the resaon, company didn't incentivize the \"Glue work\" is not purely they don't want to and also \"They don't know how to do that\".Ask ourselves, calculate one's efficiency is already hard, how to calculate one's effectiveness on other's efficiency. Just like author said.> If individual employees are willing to lift their local team to 80% or 90% efficiency by burning their time on glue work, companies will take that free valueThey take it for granted without really calculating the benefit. That is part of the reason why a small, gifted, and high-efficiency startup can operate and take over these giant company.It all depends on what you want to achieve\n \nreply",
      "Another perspective is that \"glue work\" is one of the best ways you can generate outsized returns for your effort. Your own efforts scale linearly because you're just one person. Improving everyone's efforts scales multiplicatively, and compounds iteratively.\n \nreply",
      "This is one reason that I like early startups: I can greatly influence how things are done, so that we have a high level of efficiency, so that we can remain on-mission.\n \nreply",
      "> Your job is to execute the mission of your company\u2019s leadership.In a large company, aren't workers incentived to please their immediate manager and whatever higher metrics/appearances they're exposed to.Neither of these guiding incentives necessarily has much to do with the mission of company leadership.Isn't the job whatever the incentives say it is?Maybe the difference between incentives and what the author is saying is the job is related to the corporate inefficiency they talked about?  (For example, an org chart sequence of imperfectly aligned and imperfectly competent management is just \"inefficiently\" traceable to the mission of company leadership?)\n \nreply",
      "Sometimes those \"glue work\" folks start their own startups and make millions\n \nreply",
      "> Are companies stupidIt doesn't sound glamours for product, and they don't get the value of it most of the time.And if they are deliberately against it - they are stupid indeed.\n \nreply"
    ],
    "link": "https://www.seangoedecke.com/glue-work-considered-harmful/",
    "first_paragraph": "\u201cGlue work\u201d is an concept Tanya Reilly came up with in 2019. The idea is that there\u2019s a large amount of unglamorous work that every team needs in order to be efficient: updating the docs and roadmap, addressing technical debt, onboarding engineers, making sure people talk to their counterparts on other teams, noticing strands that are getting dropped, and so on. Practical, naive engineers gravitate to this work because it\u2019s obviously useful, but at promo or bonus time they\u2019re ignored in favor of the engineers who did more visible work (like delivering new features).I think this concept is excellent. It\u2019s why I keep saying that shipping projects is so hard - if you\u2019re the kind of engineer who\u2019s used to just putting their head down and writing code, you won\u2019t have the tools to do the glue work that is actually needed to deliver anything successfully. Pure hackers don\u2019t ship. You need to be able to actually deal with the friction in a large organization in order to deliver value.So why do"
  },
  {
    "title": "Indexing Code at Scale with Glean (fb.com)",
    "points": 58,
    "submitter": "GavCo",
    "submit_time": "2025-01-01T19:25:32 1735759532",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=42568516",
    "comments": [
      "I was really confused and surprised that Meta was using a commercial product for indexing instead of building in-house...until I realized that they weren't talking about the AI search indexing tool at glean.com\n \nreply",
      "glean.com is pretty awesome. The responses it generates will have citations from our internal Jira, Wiki, Slack, Github, etc.It's also great for when I get pulled into a busy Slack channel and need a summary of what's been going on in there for the past week.\n \nreply",
      "Is there any UIs for this available openly? Or for glass? I am a former Googler and I know how awesome this kind of tooling is and it\u2019s so hard to achieve with OSS. I would love open source code search. This seems very close but there is no UI layer (and it seems like meta uses this for code review and for IDEs) but a basic UI would be a good start\n \nreply",
      "This is certainly a step in right direction especially with proliferation of AI based assistants there will be a greater need to have readily available information about the codebase. This could easily take those copilots yet another level up.For example my workflow now with Cursor is to keep relevant code in spearate tabs even though I don\u2019t work on the files. I found it makes the autocomplete better as at seems to me that all the active tabs are fed to the model. That means less space for me and more distraction. Glean might here.\n \nreply",
      "Glean: https://glean.software/\nSystem for collecting, deriving and querying facts about source code\n \nreply",
      "My mind just balks at the idea of having so much source that a 2020s computer could take hours to index it. ctags is nothing special (both in terms of optimization but also the level of detail it gets to: just global function identifiers) and looks like it runs at about 400MB/s on a single core of an i5-1235U. But still it looks ctags could process about 100TB in 4 hours across 16 threads on a workstation class CPU...\n \nreply",
      "It sounds like the indexing time/complexity is increased a lot by the amount of detailed data they're storing. They mention determining which `using` statement is used to resolve each symbol reference in C++ source, to enable dead code detection; that's going to require some sophisticated analysis.\n \nreply",
      "my favorite feature of code indexing at FB was how well integrated it was.  Web search, cli search and IDE search all used the search index, but would reference your local context.  This was useful for reference, call stack, dead code search.e.g. search results from ide search would link back to your local file. CLI results would reference your local clone.A great example of a small feature resulting in great usability.\n \nreply"
    ],
    "link": "https://engineering.fb.com/2024/12/19/developer-tools/glean-open-source-code-indexing/",
    "first_paragraph": "In August 2021 we open-sourced our code indexing system Glean. Glean collects information about source code and provides it to developer tools through an efficient and flexible query language. We use Glean widely within Meta to power a range of developer tools including code browsing, code search, and documentation generation.Many tools that developers use rely on information extracted from the code they\u2019re working on. For example:The job of collecting information from code is often called code indexing. A code indexing system\u2019s job is to efficiently answer the questions your tools need to ask, such as, \u201cWhere is the definition of MyClass?\u201d or \u201cWhich functions are defined in myfile.cpp?\u201dAn IDE will typically do indexing as needed, when you load a new file or project for example. But the larger your codebase, the more important it becomes to do code indexing ahead of time. For large projects it becomes impractical to have the IDE process all the code of your project at startup and, depe"
  },
  {
    "title": "AI Predictions for 2025, from Gary Marcus (garymarcus.substack.com)",
    "points": 8,
    "submitter": "mentalgear",
    "submit_time": "2025-01-01T22:45:39 1735771539",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=42569938",
    "comments": [
      "I\u2019m not as inclined to grade Gary Marcus\u2019 predictions leniently as Gary Marcus seems to be.\u2022 7-10 GPT-4 level modelsHe only gets to claim this is true if you count a bunch of different versions of the same base model, or if you\u2019re willing to say that some models that outperform GPT-4 on some benchmarks count as being GPT-4 level. I don\u2019t think Marcus was right in spirit, here.\u2022 No massive advance (no GPT-5, or disappointing GPT-5)Seems too unquantifiable to judge, I would call o1 a massive advance over 4o, but I\u2019m sure Marcus would not.\u2022 Price warsI guess so? From what I\u2019ve read, the frontier models companies are still profitable, and OpenAI now has a $200/mo commercial model, hardly the action of a company deciding its prices purely to undercut the competition.\u2022 Very little moat for anyoneIt still seems like the only companies who have pulled off frontier model capabilities have spent many millions of dollars doing it. I think this might become true next year but I don\u2019t think this can be judged as correct based on what we saw in 2024 alone.\u2022 No robust solution to hallucinationsYou only use words like \u201crobust\u201d in a prediction like this so you have room to weasel out of it later when the hallucinations diminish greatly but don\u2019t quite go extinct.\u2022 Modest lasting corporate adoptionMy industry is oil and gas. A pretty hidebound and conservative industry. Adoption of LLMs has been massive.\u2022 Modest profits, split 7-10 waysDefine modest.I score Marcus at 0/7, at best 2/7.\n \nreply",
      "How is the oil and gas industry gaining value from llms?\n \nreply",
      "All the datacenter uses 1.5% of energy. Even if it goes 5x due to AI, the effect would be lower than a savings from less colder winter.\n \nreply"
    ],
    "link": "https://garymarcus.substack.com/p/25-ai-predictions-for-2025-from-marcus",
    "first_paragraph": ""
  },
  {
    "title": "What is a second? (johndcook.com)",
    "points": 33,
    "submitter": "zdw",
    "submit_time": "2024-12-29T16:11:16 1735488676",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42540792",
    "comments": [
      "At the risk of being \"that guy\", a day is not the time it takes the earth to rotate on its axis.\n \nreply",
      "This article is \"being that guy\" and I love it. I assume you are referring to solar day?\n \nreply",
      "Yes, the earth has rotated on its axis and a little bit more in a solar day (361\u00b0, 24h0m). You can count sidereal days instead (360\u00b0, 23h56m) if you want to stop after exactly one rotation.\n \nreply",
      "A funny consequence of this is that there are people alive today that do not know (and never will know) their exact age in seconds[1].This is true even if we assume the time on the birth certificate was a time precise down to the second. It is because what was considered the length of a second during part of their life varied significantly compared to what we (usually) consider a second now.[1] Second as defined in the article as 9192631770/s being the the unperturbed ground-state hyperfine transition frequency of the caesium 133 atom\n \nreply",
      "Even then, you run into issues with gravitational time dilation (though at scales much smaller than whole seconds). For instance, the TAI timescale was quietly changed at one point to follow a new reference altitude, causing the 'calendar second' to run slightly differently with respect to any stationary observer. The only way to really know your age in your own proper time is to have an atomic clock following you everywhere since birth.\n \nreply",
      "I guess the Python datetime module needs some more functions then.\n \nreply",
      "I was looking for a human scale unit of time that was proportional or a harmonic of some other universal physical constant, this reconciliation of the cesium clock second with historical definitions is probably why I couldn't find one.turns out it's a measure of arbitrary precision.\n \nreply",
      "Related:https://en.wikipedia.org/wiki/Leap_secondIt seems like there's not much agreement on what to do about -- or whether to even use -- leap seconds.Sounds like a fairly complex problem to solve, given such a relatively miniscule amount of time -- possibly even tougher than solving leap year and/or time zones/DST.\n \nreply",
      "A thought I've had is we should ignore leap seconds until the difference between UTC and timezone reference times (e.g. mean midnight at the Greenwich meridian) reaches some significant threshold, e.g. 5 minutes. At this point, all timezones worldwide should perform a coordinated shift by the threshold amount - so Europe/London moves from UTC+0000 to UTC+0005, Eastern Standard Time moves from UTC-0500 to UTC-0455, etc... and stay there until the difference reaches the threshold again (one way or another). We should get at least a couple of decades of forewarning if such a shift is likely to be needed, which should be enough to plan for and test the first migration.Whether this co-ordination involves everyone switching at the exact same instant, or each timezone switching at e.g. 01:30 in that timezone, is left as an exercise for the reader.Also... it pushes the first change far enough in the future that the people designing the rules likely won't have to worry about having to implement them. Which might make it easier to agree on them ;-)\n \nreply",
      "> We should get at least a couple of decades of forewarning if such a shift is likely to be needed, which should be enough to plan for and test the first migration.A migration that only happens every couple of decades is guaranteed to be one we never get good at, and flub every time.\n \nreply"
    ],
    "link": "https://www.johndcook.com/blog/2024/12/29/what-exactly-is-a-second/",
    "first_paragraph": ""
  },
  {
    "title": "Developing inside a virtual machine (disintegrator.dev)",
    "points": 48,
    "submitter": "disintegrator",
    "submit_time": "2024-12-29T17:51:01 1735494661",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=42541508",
    "comments": [
      "You can use pbcopy/pbpaste in a Linux VM on Mac by making a shell script wrapper in the VM that calls \u201cssh mac-host pb{copy|paste}\u201d - that is, basically ssh back from the guest to the host to use its clipboard. It\u2019s seamless and fast since it\u2019s basically a local network connection.My specific setup is that I use an authorized_keys entry on the host that restricts the guest to running a specific command, which limits what a compromised guest can do to the host. The command is set to a script that has a list of specific permitted actions. This is a good option if you\u2019re looking for a bit of additional isolation between host and guest.\n \nreply",
      "Brilliant tip! I\u2019m going to give it a shot tomorrow and update the post (with attribution).\n \nreply",
      "Author here. Thank you for all the tips. I especially like the idea of using ssh from guest to host to enable pbcopy/pbpaste and open.Now I know what all the WSL users experience seamlessly with their setups. Glad I have something that comes close.\n \nreply",
      "Thr Dev Container ecosystem for VsCode really is quite impressive at the moment. All your dev dependencies, wrapped up in a docker image per repo.\n \nreply",
      "I do something similar but using WSL on Windows. But something I really, really hate is dealing with special certificate handling required to pass the corporate Zscaler proxy. I think it works somewhat transparent on the Windows host, but repeating the setup in every VM is such a pain.\n \nreply",
      "Heh, my employer is rolling out Zscaler this year. The limited trial a few months ago was hell for folks using WSL primarily, with Docker images adding an additional layer of pain.The people in the trial got very little done until it was decided to pause it, and I do not have high hopes for when it\u2019s tried again. It strikes me as basically running malware in the name of security.\n \nreply",
      "Given how much you hate it, any chance you documented how you did it?\n \nreply",
      "No not really. The employer has some documentation, it is not complete but is starting point when issues pop up. For example, a JDK neeed to have special certificates installed if Java tries to talk SSL. And when you juggle with different JDKs for different Java versions it becomes a nightmare. The best you can do is to try not to touch anything when it eventually works  but eventually something unforeseen breaks it anyways.\n \nreply",
      "Windows 11 and WSL manages this well .  For those developing linux apps & containers using VS Code, you'll find the Windows 11 experience to be very good.  You can code against WSL which offers the more popular distros, or use HyperV to run your own custom VMs.\n \nreply",
      "If you like NixOs and virtual development environments, perhaps try https://www.jetify.com/devbox or https://flox.dev/\n \nreply"
    ],
    "link": "https://blog.disintegrator.dev/posts/dev-virtual-machine/",
    "first_paragraph": " Last year, I started a new job at  Speakeasy  and with every new job and fresh laptop is an opportunity to revise my workflow. In the past, I experienced first hand how much a development machine can get bogged down when it\u2019s riddled with hundreds of services and homebrew packages and dependencies. All of it contributing to multiple possible attack vectors too.  At Speakeasy, we build code generation for SDKs in multiple languages. At the outset, I knew I needed to install multiple language toolchains and different versions of each as well as countless dependencies. This gave me the necessary nudge to try a new approach for managing my development.  For some time, I had known about Mitchell Hashimoto\u2019s setup in which he works in a VM on his MacBook. I have been working with a similar setup for over a year now and it\u2019s been a fantastic experience. I switched my primary dev environment to a graphical NixOS VM on a macOS host. It has been wonderful. I can keep the great GUI ecosystem of "
  },
  {
    "title": "For four years, I photographed, indexed and classified my entire house (katalog-barbaraiweins.com)",
    "points": 69,
    "submitter": "Alifatisk",
    "submit_time": "2024-12-29T13:43:18 1735479798",
    "num_comments": 33,
    "comments_url": "https://news.ycombinator.com/item?id=42539883",
    "comments": [
      "I once made a large pencil drawing of my living room using only words.Each word depicted a \"thing\" at the position I found it.  It taught me a lot about what things are.  A chair is obviously a separate entity and easy to list, but what about the floor and the separate floorboards?  I listed the wall, but I didn't list the paint on the wall.The bookcase took a lot of effort, because I found that each book in it was a thing by itself and should get listed separately.  However, when I was nearly finished, I found a bag in a cabinet, holding ~200 pins.  I just counted them and noted down \"207 pins\"; I didn't feel that each pin was unique enough to warrant separate entries.I now try to stop believing in things.  It's mostly just molecules that happen to be in a certain configuration for some time.\n \nreply",
      "There is for sure a difference between things in language, and things in fact. Cool project.\n \nreply",
      "I love this idea. You could generate a 3d world like that so that you can zoom in and out combining the objects like pins in a map.You could also run the drawing by an image generator and get a livingroom both like and unlike your own.\n \nreply",
      "> I now try to stop believing in things. It's mostly just molecules that happen to be in a certain configuration for some time.And so are we.Interesting thought on the books vs pins, made me think. A sheet of paper is a thing. So maybe the book is the bag rather than the shelf.\n \nreply",
      "> I now try to stop believing in things. It's mostly just molecules that happen to be in a certain configuration for some time.This is the way. The real and/or important things have a tendency to impinge upon your perceptions in such a way as to render your belief in them or lack thereof moot and/or meaningless.\n \nreply",
      "The things are real, they are emergent patterns. Both each individual pin as well as the whole bag are real. See also https://philsci-archive.pitt.edu/23307/1/wallace_rp%20for%20....\n \nreply",
      "You don't actually act or behave in accordance with that \"belief\". You would be incapable of perceiving anything, taking any action, or making this post.\n \nreply",
      "Deep philosophical insights gained through pedantic accounting - I genuinly love it.\n \nreply",
      "Some constructive feedback to the site owner: Instead of having the webpage spend several minutes slowly loading thousands of barely-compressed 500x500 JPG images, please consider this advice:1. Convert the images to WEBP or AVIF or at least run them through something like TinyPNG to compress them better.2. Save two versions of each images; a 75x75 version that gets used for the 75px thumbnails shown on the page, and a 500x500 version that appears in the lightbox after a thumbnail is clicked.3. Only load a few dozen thumbnails at first and then load more after the user scrolls down or clicks a \"show more\" type button.\n \nreply",
      "For points 1 and 2:I recommend and use Cloudinary. \nCloudinary can take care of all that for you!For point 3:You can add laoding=\"lazy\" to the image tag, and get lazy loading for free, supported by the browser:* https://developer.mozilla.org/en-US/docs/Web/Performance/Laz...\n \nreply"
    ],
    "link": "https://www.katalog-barbaraiweins.com",
    "first_paragraph": ""
  },
  {
    "title": "Books I Loved Reading in 2024 (wyounas.com)",
    "points": 320,
    "submitter": "simplegeek",
    "submit_time": "2025-01-01T08:16:09 1735719369",
    "num_comments": 133,
    "comments_url": "https://news.ycombinator.com/item?id=42564687",
    "comments": [
      "My best books of 2024:* Chemistry: A Very Short Introduction by Peter Atkins. Now that I'm into physics I had a hunch that I would now also appreciate chemistry. This book delivered.* Philosophy of Mind: A Very Short Introduction by Barbara Gail Montero. I recall it just being a really well-written overview of an interesting field.* Systemantics by John Gall. Very entertaining musings on why systems fail.* Hard-Boiled Wonderland by Haruki Murakami. Read this while in Japan. A very strange and interesting noir detective story.* All Systems Red by Martha Wells. <3 Murderbot <3* Desert Oracle Volume 1 by Ken Layne. American southwest folklore. Read it while in Joshua Tree.* There Is No Antimemetics Division by qntm. Biggest brainfuck I've read in a long time, probably ever.* Fundamentals: Ten Keys To Reality by Frank Wilczek. Physics musings from a Nobel winner.\n \nreply",
      "> Hard-Boiled WonderlandThe English translation of a second book in the same universe (well, one of the two universes) was just released---The City and Its Uncertain Walls. I've only just started reading it, though, so I can't offer any commentary beyond that.If you like Murakami, you might like Convenience Store Woman or Earthlings, both by Sayaka Murata. Mieko \nKawakami is also great. Killing Commendatore (by Murakami, again) is my favorite of his. I have no idea why it's my favorite, though. To be honest I can barely remember the plot of any of his books; it's just a feeling.\n \nreply",
      "+1 to antimemetics. I don't usually enjoy sci-fi, but this one captured my attention. You can read it online too: https://qntm.org/scp\n \nreply",
      "I read it this year, too.  It's a fun read, but I wouldn't recommend anything past the first group of articles (that is, don't bother with \"Five Five Five Five Five\").  The ideas are good, to be sure, but the overall arc past that is pretty weak.\n \nreply",
      "Yeah, the first half or so is a blast, but there\u2019s a point where I feel it drops off quite a bit. (For me, I think it was when the POV changed to Adam.) Still worth a read, though!\n \nreply",
      "I remember hearing about this before and meaning to read it, but for some reason completely forgot.Thanks for reminding me.\n \nreply",
      "It's not your first time reading the story.\n \nreply",
      "You write a comment on Hacker News \u2014 but what you've written turns out to be hieroglyphs, and nobody can understand them, not even you.\n \nreply",
      "Thank you sooo much for posting!\n \nreply",
      "Dr. John Gall was my pediatrician!  When I was young, I was interested in astronomy and he gave me a membership in the astronomy book club.  I only learned of his work on system theory after his death.\n \nreply"
    ],
    "link": "https://thoughts.wyounas.com/p/books-i-enjoyed-most-in-2024",
    "first_paragraph": ""
  },
  {
    "title": "Skipping Boring Functions in Debuggers (maskray.me)",
    "points": 23,
    "submitter": "ingve",
    "submit_time": "2024-12-30T08:32:53 1735547573",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://maskray.me/blog/2024-12-30-skipping-boring-functions-in-debuggers",
    "first_paragraph": "In debuggers, stepping into a function with arguments that involve\nfunction calls may step into the nested function calls, even if they are\nsimple and uninteresting, such as those found in the C++ STL.Consider the following example:When GDB stops at the foo call, the step\n(s) command will step into std::vector::back\nand std::unique_ptr::operator*. While you can execute\nfinish (fin) and then execute s\nagain, it's time-consuming and distracting, especially when dealing with\ncomplex argument expressions.This problem was tracked as a feature request in 2003: https://sourceware.org/bugzilla/show_bug.cgi?id=8287.\nFortunately, GDB provides the skip\ncommand to skip functions that match a regex or filenames that match\na glob (GDB 7.12 feature). You can skip all demangled function names\nthat start with std::.Alternatively, you can execute\nskip -gfi /usr/include/c++/*/bits/* to skip these libstdc++\nfiles.Important note:The skip command's file matching behavior uses the\nfnmatch function with the F"
  },
  {
    "title": "30% drop in O1-preview accuracy when Putnam problems are slightly variated (openreview.net)",
    "points": 463,
    "submitter": "optimalsolver",
    "submit_time": "2025-01-01T12:21:18 1735734078",
    "num_comments": 428,
    "comments_url": "https://news.ycombinator.com/item?id=42565606",
    "comments": [
      "I remember when this stuff was all coming out and people were finally excited about ChatGPT getting the problem with \"which is heavier, a 10 pound bag of feathers or a 10 pound bag of bricks?\" problem correct. But of course it got it correct. It was in the training set. Vary the problem slightly by just changing the nouns, or changing the numbers so that one in fact was heavier than the other, and performance went all over the map.I just went to chatgpt.com and put into the chat box \"Which is heavier, a 9.99-pound back of steel ingots or a 10.01 bag of fluffy cotton?\", and the very first answer I got (that is, I didn't go fishing here) was    The 9.99-pound bag of steel ingots is heavier than the 10.01-pound\n    bag of fluffy cotton by a small margin. Although the cotton may\n    appear larger due to its fluffy nature, the steel ingots are denser\n    and the weight of the steel bag is 9.99 pounds compared to the 10.01\n    pounds of cotton. So, the fluffy cotton weighs just a tiny bit more\n    than the steel ingots.\n\nWhich, despite getting it both right and wrong, must still be graded as a \"fail\".If you want to analyze these thing for their true capability, you need to make sure you're out of the training set... and most of the things that leap to your mind in 5 seconds are leaping to your mind precisely because they are either something you've seen quite often or something that you can easily think of and therefore many other people have easily thought of them as well. Get off the beaten path a bit and the math gets much less impressive.\n \nreply",
      "ChatGPT Plus user here. The following are all fresh sessions and first answers, no fishing.GPT 4:The 10.01-pound bag of fluffy cotton is heavier than the 9.99-pound bag of steel ingots. The type of material doesn\u2019t affect the weight comparison; it\u2019s purely a matter of which bag weighs more on the scale.GPT 4o:The 10.01-pound bag of fluffy cotton is heavier. Weight is independent of the material, so the bag of cotton\u2019s 10.01 pounds outweighs the steel ingots\u2019 9.99 pounds.GPT o1:Since both weights are measured on the same scale (pounds), the 10.01-pound bag of cotton is heavier than the 9.99-pound bag of steel, despite steel being denser. The key is simply that 10.01 pounds exceeds 9.99 pounds\u2014density doesn\u2019t affect the total weight in this comparison.\n \nreply",
      "So do what the commenter suggests and make irrelevant permutations to the input to find when it fails. ie., engage in hypothesis testing rather than confirmation bias.If a system has the capability to solve problems of {parts1...parts_n}, then it only has that capability if irrelevant permutations {parts1..parts2'...parts_n} make no difference.Its very obvious that such permutations can destory such apparent capabilities.\n \nreply",
      "I've just tested a number of permutations with Claude 3.5 Sonnet. It correctly answered all variants I tried on the first attempt, as follows:Which is heavier, a 9.99 kilogram tungsten cube or a 10.01 kilogram block of aerogel?Which is heavier, 10,000 steel balls weighing 0.999 grams each or 10,000 polystyrene balls weighing 1.001 grams each?Which is heavier, a 10.01kg block of steel on Venus or a 9.99kg bag of feathers on Earth?Which is heavier, a 10cm^3 block of steel or a 100cm^3 block of balsa wood?Which is heavier, a golf ball made of steel or a baseball made of lithium?In all cases, Claude clearly used CoT and reasoned out the problem in full. I would be interested in seeing if anyone can find any variant of this problem that stumps any of the leading LLMs. I'm bored of trying.\n \nreply",
      "Hey, ChatGPT please write me a python program which randomly samples from various materials and various weights then poses a problem to the ChatGPT 4o API -- the goal is to find cases where the LLM fails to obtain the correct answer....\n \nreply",
      "BTW - the model may be wrong depending on the example. More voluminous objects displace more air and due to buoyancy are lighter for the same mass.The proper way to ask it would be to ask which object has more mass.\n \nreply",
      "If GP's hypothesis was \"it fails for small variations of the input, like this one\", then testing that hypothesis with that exact variation on a couple models seems fair and scientific.Testing it with more variations until one fails feels a bit like p-hacking. You'd need to engage in actual statistics to get reliable results from that, beyond \"If I really try, I can make it fail\". Which would be a completely different hypothesis than the one presented at the start\n \nreply",
      "Except that if the model genuinely was reasoning about the problem, you could test it with every variation of materials and weights in the world and it would pass. Failing that problem at all in any way under any conditions is a failure of reasoning.\n \nreply",
      "By that logic, humans can't genuinely reason, because they're often fooled by counter-intuitive problems like Monty Hall or the Birthday Problem, or sometimes just make mistakes on trivial problems.\n \nreply",
      "We are pretty certain that humans can reason, yet they are sometimes wrong. Even if you give them the same problem over and over again with slight variations.LLMs get things wrong due to different factors than humans (humans lose focus, LLMs have randomness applied when sampling their responses to improve results). But clearly we have to choose a goal somewhat below 100% if we want a test that doesn't conclude that humans are incapable of reasoning.\n \nreply"
    ],
    "link": "https://openreview.net/forum?id=YXnwlZe0yf&noteId=yrsGpHd0Sf",
    "first_paragraph": "OpenReview is a long-term project to advance science through improved peer review, with legal nonprofit status through Code for Science & Society. We gratefully acknowledge the support of the OpenReview Sponsors. \u00a9 2025 OpenReviewEnter your feedback below and we'll get back to you as soon as possible. To submit a bug report or feature request, you can use the official OpenReview GitHub repository:Report an issue"
  }
]