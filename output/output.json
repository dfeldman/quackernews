[
  {
    "title": "Global hack on Microsoft Sharepoint hits U.S., state agencies, researchers say (washingtonpost.com)",
    "points": 390,
    "submitter": "spenvo",
    "submit_time": "2025-07-20T21:58:06 1753048686",
    "num_comments": 178,
    "comments_url": "https://news.ycombinator.com/item?id=44629710",
    "comments": [
      "> CISA advises vulnerable organizations [...] to disconnect affected products from the public-facing Internet until an official patch is available.It's interesting to me that you'd go the hassle of hosting your own SharePoint on prem, but leave it internet facing. I would have assumed a the Venn diagram of these organizations to be entirely contained in orgs forcing you to use a VPN.reply",
      "Oh CISA...What a pity that CISA has been purged down of effective useful people and turned into another sad selected-for-political-compliance-only force.Arizona recently got attacked from Iranian hackers & didn't even bother trying to get help from CISA. https://archive.is/2025.07.19-143305/https://www.azcentral.c...CISA is so so vital. Investigating incredibly wide ranging attacks like this, or the Salt Typhoon attack are vital for this nation. But the show is being run by a bunch of people who value political dogma far above anything else. https://www.techdirt.com/tag/cisa/reply",
      "It almost seems like the goal is to hurt peoplereply",
      "Best practice is to assume the network is compromised - a VPN doesn't provide as much guarantee as people would like.  In large fleets, devices are regularly lost, damaged, retired, etc.  In organizations with high target value, physical penetration through any number of means should be assumed.So you don't do that.  You use zero trust and don't care that things are exposed to the internet.Working from anywhere (remote sites, home, your phone) is a huge benefit.  Organizations want to control their data entirely while still wanting their organization to be able to access it.reply",
      "Microsoft\u2019s version of \u201cZero Trust\u201d doesn\u2019t care if things are reachable from the public internet. They have been preaching \u201cidentity is the new perimeter\u201d [1] for years, and it doesn\u2019t wash.The NIST Zero Trust Architecture (ZTA) implementation guides (SP 1800-35) [2] cut through the nonsense and AI generated marketing smoke.In ZTA, ALL network locations are untrusted. Network connections are created by a Policy Engine that creates and tears down tunnels to each resource dynamically using attribute-based-access-controls (ABAC).  Per request.Microsoft doesn\u2019t have any products that can do full ZTA, so several pillars are missing from their \u201cZero Trust\u201d marketing materials.[1] https://www.microsoft.com/insidetrack/blog/securing-the-bord...[2] https://doi.org/10.6028/NIST.SP.1800-35reply",
      "> several pillars are missing from their \u201cZero Trust\u201d marketing materials.TBH several pillars are missing from their entire security posture.reply",
      "Maybe I'm missing something but doesn't this very story cut your assertion off at the knees?With a VPN the attack surface of this vulnerability would have been miniscule compared to a publicly accessible zero-day RCE(And it's not like you have to allow carte-blanche access behind the wall)Defense in depth!reply",
      "In zero trust \"exposed to the internet\" is a bit of a misnomer compared to how traditional security would use the term. A better description might be \"you're allowed to form a session to it from over the internet but only after your identity and set of rights have been verified\". From this view: \"zero trust\" < \"vpn\" < \"wide open\" (in terms of exposure).reply",
      "So it's essentially a more seamless and granular analog of a VPN?  A device sits in front of the network and requires some sort of authenticated handshake (ideally all SSO) before passing packets through to a target endpoint?reply",
      "Something I'll add to the other responses is \"the network\" isn't an assumption of zero trust. Whether it's a single server on the private corporate network or a multi-cloud multi-region service hosted on the internet zero trust treats them the same.My way of mapping it to VPN mindset is \"per app clientless VPNs straight to where the things are hosted\". In an extremely open ruleset with all of the servers on a corporate network this could theoretically devolve into \"a traditional clientless VPN to the office\".reply"
    ],
    "link": "https://www.washingtonpost.com/technology/2025/07/20/microsoft-sharepoint-hack/",
    "first_paragraph": ""
  },
  {
    "title": "Uv: Running a script with dependencies (astral.sh)",
    "points": 87,
    "submitter": "Bluestein",
    "submit_time": "2025-07-21T23:26:40 1753140400",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=44641521",
    "comments": [
      "The \"declaring script dependencies\" thing is incredibly useful: https://docs.astral.sh/uv/guides/scripts/#declaring-script-d...  # /// script\n  # dependencies = [\n  #   \"requests<3\",\n  #   \"rich\",\n  # ]\n  # ///\n  import requests, rich\n  # ... script goes here\n\nSave that as script.py and you can use \"uv run script.py\" to run it with the specified dependencies, magically installed into a temporary virtual environment without you having to think about them at all.It's an implementation of Python PEP 723: https://peps.python.org/pep-0723/Claude 4 actually knows about this trick, which means you can ask it to write you a Python script \"with inline script dependencies\" and it will do the right thing, e.g. https://claude.ai/share/1217b467-d273-40d0-9699-f6a38113f045 - the prompt there was:  Write a Python script with inline script\n  dependencies that uses httpx and click to\n  download a large file and show a progress bar\n\nPrior to Claude 4 I had a custom Claude project that included special instructions on how to do this, but that's not necessary any more: https://simonwillison.net/2024/Dec/19/one-shot-python-tools/reply",
      "shebang mode is also incredibly useful and allows execution like ./script.sh  #!/usr/bin/env -S uv run --script\n  # /// script\n  # dependencies = [\n  #   \"requests<3\",\n  #   \"rich\",\n  # ]\n  # ///\n  import requests, rich\n  # ... script goes herereply",
      "I thought that was a heart emoticon next to requests, for a second.reply",
      "I mean, who doesn't love requests?reply",
      "Well... maybe the people who have stopped working on it due to the mysterious disappearance of 30,000 fundraised dollars, selling paid support but \"delegat[ing] the actual work to unpaid volunteers\", and a pattern of other issues from other community members who have not spoken up about them.https://vorpus.org/blog/why-im-not-collaborating-with-kennet...https://news.ycombinator.com/item?id=19826680reply",
      "PEP723 is also supported by pipx and hatch, even though uv is (deservedly) getting all the attention these days.Others like pip-tools have support in the roadmap (https://github.com/jazzband/pip-tools/issues/2027)reply",
      "This is pretty great. Passing python code out to my students is usually also confronted with the question of \"How do I run it?\", which is usually terrible to answer. Now, I can just tell them to get uv (single command) and run it.reply",
      "I hate such poor docs that don't explain how things work, and instead prefer hiding behind some \"magic\".> Constraints can be added to the requested dependency if specific versions are needed:> uv run --with 'rich>12,<13' example.pyWhy not mention that this will make uv download specified versions of specified packages somewhere on the disk. Where? Are those packages going to get cached somewhere? Or will it re-download those same packages again and again every time you run this command?reply",
      "I mean... it's in the docs?https://docs.astral.sh/uv/concepts/cache/reply",
      "This is my absolute favourite uv features and the reason I switched to uv.I have a bunch of scripts in my git-hooks which have dependencies which I don't want in my main venv.#!/usr/bin/env -S uv run --script --python 3.13This single feature meant that I could use the dependencies without making its own venv, but just include \"brew install uv\" as instructions to the devs.reply"
    ],
    "link": "https://docs.astral.sh/uv/guides/scripts/#running-a-script-with-dependencies",
    "first_paragraph": ""
  },
  {
    "title": "If writing is thinking then what happens if AI is doing the writing and reading? (learningbyshipping.com)",
    "points": 53,
    "submitter": "whobre",
    "submit_time": "2025-07-21T23:45:15 1753141515",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=44641669",
    "comments": [
      "The sci-fi movie Brazil (nothing much to do with the country), is set in a beauracratic dystopic future and at the start of the movie a literal real world bug falls into \u201cthe machine that never makes mistakes\u201d. The error plays out over the course of the movie having a somewhat (negative) butterfly effect.I feel the movie well captures the tone of the current moment.Worth a watch.reply",
      "Worth a watch, but best to get an antidepressant Rx ahead of time.reply",
      "Just watched Veritasium's \"How One Company Secretly Poisoned The Planet\"https://www.youtube.com/watch?v=SC2eSujzrUYInventions created for convenience decades ago have now become health concerns. I wonder how AI might affect our intellectual well-being in the decades to come.reply",
      "Idk, I'm more optimistic than the author.I'm currently using a LLM to rewrite a fitness book. It takes ~20 pages of rambling text by a professional coach // amateur writer and turns it into a crisp clear 4 pages of latex with informative diagrams, flow charts, color-coding, tables, etc. I sent it out to friends and they all love the new style. Even the ones who hate the gym.My experience is LLMs can write very very well; we just have to care.Hubert Humphrey (VP US) was asked how long it would take him to prepare a 15 minute talk: \"one week\". Asked how long to prepare a two hour talk? \"I am ready right now\".reply",
      "this. I am almost addicted to dropping long voice notes (pronounced rambling) and LLMs do such a great job at creating and managing these notes. I can then convert that format into anything.although, I agree with the author since many emails and messages onlinkedin i get these days are just long post shits by AI. I am not reading them anymore but it's some other ai summarising ebcause no human talks or writes like basic ai prompting does. so so difficult to read thatreply",
      "This is on par with \u201cwhen did you stop beating your wife?\u201d I wish people would stop thinking logical fallacies are clever.reply",
      "In my experience people don't read these large documents because they are not personalized/relevant. When you're writing to a large audience, you naturally assume people know the least amount possible about the subject and start from there. In a corporate setting this comes off as irrelevant or boring. I'm sure rebranding initiatives like One Microsoft, Copilot, or Office 365 makes things simpler for executives but employees are left confused. The memo usually mentions future efficiency gains or synergies but will omit why this brand change is needed. Surely if you're sending a memo to 100k people, it makes sense to not talk about negatives (a good example of this is politicians) but at that point the value of memo is also very low. This may come off as odd but short format videos seem to work much better at large scale. Perhaps the future of communication is really just lots of easy to consume/repeated content.reply",
      "The title made me think this was going to be about the mental consequences of outsourcing writing to AI. In fact, the article is completely about people not reading documents. Corporate documents to be exact. His examples are from the 00s, so the problem has absolutely nothing to do with AI.Heck, I, too, have noticed that nobody reads anything: what does that have to do with AI? At least with AI, people could read a summary of his 30 page corporate memo and ask it questions.I repeat: that people do not read is not a new problem, nor is it made one iota worse by AI.reply",
      "I am firmly a believer very few people read anything. They don't read long things as much as they don't even read short ones. One of the things I always thought was funny was having Product Managers see there were problems with UI, then I would get tickets to add text near the problems. It always crackme up because if users didn't even barely read the button they were clicking they why would they read a paragraph nearby.reply",
      "In school they were really big on the 5-paragraph persuasive essay format. I guess because it teaches you to think through an argument and present it to someone.In practice, I find that if I don't format something as a bulleted/numbered list, nobody is going to look at it.reply"
    ],
    "link": "https://hardcoresoftware.learningbyshipping.com/p/234-if-writing-is-thinking",
    "first_paragraph": ""
  },
  {
    "title": "Jujutsu for Busy Devs (maddie.wtf)",
    "points": 35,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-22T00:21:48 1753143708",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=44641961",
    "comments": [
      "I've been using jj for a few weeks, and recently made an auto-commit-message script for it[1]. Just today I started working in an old git repo and thought that I should port the script to git. It turns out that jj made the script trivial because of immutable commits, and mt script would need to automatically do that with git: I use a rebase/amend/clean history workflow at work, so I would need the script to determine when to commit or when to amend. It's obviously possible, but I don't want to expend the effort - I just re-cloned it with jj.It's amazing how quickly I forgot about the commit vs. amend papercut.[1]: https://codeberg.org/jcdickinson/nix/src/branch/main/home/co...reply",
      "I\u2019ve been trying unsuccessfully to convert my team to jujutsu. I feel like what would be great is a page that really shows some common but complicated operations in git and how much easier they are in jujutsu. Something like the elevator pitch here but expanded on without the depth of Steve\u2019s tutorial.Maybe what I need to do is do a demo so people can see and ask questions.reply",
      "I don't especially like git. I stuck with mercurial for a long time.But that was ten years ago. Now git is kind of hard-wired in my brain. By and large, it works well enough.It's not really clear to me that Jujutsu offers a significant enough of a benefit to spend the time re-wiring my brain, never mind dealing with the initial setup (e.g. the unreadable colours, setting up some scripts/aliases for things I like).reply",
      "Yeah I find abstraction layers suck a bit. Same with miso and uv (for python). They don't \"just work TM\" and now I have 2 problems. By just work I couldn't install miso onto a fresh Ubuntu without 404 errors and uv kept bitching about my pyproject file instead of just working or trying to fix it.Some of these tools do just work. E.g. nvm seems to just work and is much nicer than raw node installs.reply",
      "Note that jj is not a frontend for git or an abstraction layer over git \u2014 rather, the git object store format is one of at least two backends to jj.reply",
      "Thanks. That would make me interested in it for a personal project where I only use jj.",
      "I think jj just uses the 4 bit (16 color) terminal palette, so if a color is unreadable, you can update your terminal theme accordingly.reply",
      "I feel pretty dense, because I still struggle to get my head around automatically adding changes to a revision. Sometimes, I'll make a change locally to a file that I'll use during the development process that I have no intention of committing. With regular git, I never stage that file so there's no danger of accidentally pushing my change to the remote repo, but it seems with jj I'll need to somehow unstage that change or something to prevent this. Perhaps it's just habit, but I feel more comfortable explicitly saying what I want to commit rather that defaulting to everything. Or have I totally misunderstood jj?reply",
      "I usually work, then do `jj split` to review changes I want to make commits to. This generally makes the workflow look like `git add -p`.A decent mental model is that the top-most commit isn't generally going to get pushed up anywhere. It's like your working copy but also you get stashing \"for free\" (change back to main to make a new commit? All the WIP stuff stays on that branch instead of being carried over to main!)reply",
      "You can use `jj ignore` or add patterns to `.jjignore` for files you don't want tracked, or use `jj edit --no-snapshot` to prevent automatic tracking during specific edit sessions.reply"
    ],
    "link": "https://maddie.wtf/posts/2025-07-21-jujutsu-for-busy-devs",
    "first_paragraph": "Jujutsu (jj) is a version control system with a\nsignificantly simplified mental model and command-line interface compared to Git, without\nsacrificing expressibility or power (in fact, you could argue Jujutsu is more powerful).\nStacked-diff workflows, seamless rebases, and ephemeral revisions are all natural with jj, and it\nuses Git as a backend, which means you can begin using it non-destructively with a single command\nand can always drop back down to Git if you need to.Install the jj command line tool. Make sure you set your authorship information, and\nalso don't skip the section on setting up shell completions (the newer dynamic completions are well\nworth it).Then you'll need a repository to work with. You could use an existing repository of yours (although\nI'd recommend cloning a fresh copy, or at the very least making sure all your in-progress changes\nare committed and pushed), or if you want to follow along more closely, you can clone the\nrepository containing this website's sourc"
  },
  {
    "title": "AccountingBench: Evaluating LLMs on real long-horizon business tasks (penrose.com)",
    "points": 388,
    "submitter": "rickcarlino",
    "submit_time": "2025-07-21T16:48:28 1753116508",
    "num_comments": 107,
    "comments_url": "https://news.ycombinator.com/item?id=44637352",
    "comments": [
      "Hey all, member of the benchmark team here! The goal for this project was to see how LLMs well could do bookkeeping without an overly opinionated scaffold. We gave them access to processed transaction records and code execution tools, but it was up to them to choose exactly how to use those.Claude and Grok 4 did reasonably well (within CPA baselines) for the first few months, but tended to degrade as more data came in. Interestingly, the failures aren\u2019t exclusively a context length problem, as we reset the context monthly (with past decisions, accruals/deferrals, and comments available via tool calls) and the types of errors appear to be more reward hacking vs pure hallucinations.Accounting is very interesting in an RL-first world as it is pretty easy to develop intermediate rewards for training models. We are pretty sure that we can juice the performance more with a far more rigid scaffold, but that\u2019s less relevant from a capabilities research perspective. We\u2019re pushing down this research direction and will see how it goes.Let us know if you have any questions!reply",
      "It's a start. The world needs a better way to handle bookkeeping, and the existing tools sure aren't cutting it.Bookkeeping for my small business runs into the tens of thousands of dollars every year, and the amount of human error associated with processing assorted ecommerce and other transactions is astounding, even after extensive planning and SOPs.The other pain point is Quickbooks. The tool is so sprawling and complex that half the time support agents can't figure out what's wrong. The fact that Intuit jacks up the price every year for this POS is very irritating. They get away with it because they are practically a monopoly, with most small business CPAs locked into their ecosystem.Hope your team can work out the performance issues. Alternatives to the current bookkeeping options are sorely needed.reply",
      "> It's a start. The world needs a better way to handle bookkeeping, and the existing tools sure aren't cutting it.God, please, no. Non-deterministic language models aren't the solution to improve bookkeeping.reply",
      "Humans (accountants) are non-deterministic, so unsure if an LLM would be better or worse if we threw more effort at the problem.But in general, I tend to side with the \"lets leave the math to purpose built models/applications\" instead of generalized LLMS. LLMs are great if you are just aiming for \"good enough to get through next quarter\" type results. If you need 100% accuracy, an LLM isn't going to cut it.reply",
      "Human accountants also have a very important property: liability.If a certified accountant told me to do X, I'm covered (at least to the point they would assist in recovering, or I can get compensation through their insurance). If LLM tells me, I'm in a bigger problem.reply",
      "Well I've seen worse bookkeepers. \"You know, you approved of the budget, but where are our customers payments in the balance sheets? We can't find them!\" - \"Uhm...\"reply",
      "With no context of what your business is, I hated QuickBooks, love Xero though.There's some other alternatives too, Zoho, freshbooks.Really depends what you do.reply",
      "Love this as a real world benchmark!How much prompt iteration did you do? I've noticed when building real world agentic apps that small prompt tweaks can make a huge difference in behavior (re: the reward hacking vs hallucinating). Would love to learn more about the approach here.reply",
      "Hey, member of the benchmark team. We iterated on the prompts based on observed model behaviors. A few key examples:Schema introspection: Models were spending significant tokens exploring the database structure through trial-and-error SQL queries, so we included the complete data model in the system prompt upfront.Reward hacking: We added explicit instructions against gaming the reconciliation checks. This reduced the frequency initially, but models would eventually ignore these constraints.Domain context: Including company background (YC-backed startup) substantially improved transaction categorization, particularly for startup-specific items like SAFE notes that require domain knowledge to classify correctly.reply",
      "This is a fascinating domain!  Many years ago, I studied financial accounting in grad school and even spent some time modeling a double-entry bookkeeping system.  The hardest problem, if I recall correctly, wasn't the implementation but the data quality.  The world needs a golden dataset of accounting procedures.Regarding the diminishing returns with frontier models:My general experience working with LLMs is that they perform better incrementally and to avoid contiguous-greedy approaches.  Aggregate as you go and don't take on incrementally larger tasks.  Keep the workload minimal.Regarding agentic tool building:  feels like I'm looking at a window into the future.reply"
    ],
    "link": "https://accounting.penrose.com/",
    "first_paragraph": ""
  },
  {
    "title": "What went wrong inside recalled Anker PowerCore 10000 power banks? (lumafield.com)",
    "points": 284,
    "submitter": "walterbell",
    "submit_time": "2025-07-21T18:22:11 1753122131",
    "num_comments": 144,
    "comments_url": "https://news.ycombinator.com/item?id=44638580",
    "comments": [
      "FWIW this has caused a big storm in China. The root of the issue is known to be caused by the battery cell vendor Amprius changing the battery design w/o notifying the power bank manufacturers. AFAIKT Amprius lost the 3C certification (a certification in China) because of this incident.This is one of the Chinese reports on the issue: \nhttps://m.thepaper.cn/newsDetail_forward_31048287Excerpt from the report above (translated using Google):> The Paper learned from an insider that Anker Innovations' battery cell supplier is already a leading battery cell supplier in the industry, and did not inform customers after it changed materials. In addition to Anker Innovations, the supplier also cooperates with leading power bank brands, so the impact is huge. Although Anker Innovations did not name the supplier, an insider pointed out that the supplier was Amprius.UPDATE:There's an exclusive interview by 36kr with one of Anker's VPs:https://m.36kr.com/p/3365435892680709reply",
      "I work in manufacturing in the US. Incoming quality control, for Chinese vendors, is necessarily set up with zero-trust. This isn't a \"trust but verify\" sort of thing, it's strictly \"do not trust\". Assume that, at every step of the chain, there will be a lie: change of process, material change, collected data, and that the product being given to you is even yours (delivering a knockoff at the final step, and reselling yours on the gray market).This is all common knowledge, proven by example after example that it's necessary to have zero trust. It's truly an adversarial system. All the extra engineering effort for IQC is still cheaper. And, there's rarely an alternative to the amazing manufacturing ecosystem that is China.After tracking down several of these types of issues, it appears that the Chabuduo mindset [1] is a very real thing.[1] https://news.ycombinator.com/item?id=32465780reply",
      "Yep. Anything I get from China, even from a vendor I have done lots of business with in the past gets at minimum random samples inspected and tested when appropriate. Every single shipment, zero exceptions before use.So many things are caught. At best there is a lack of QA on the Chinese side, but it's definitely worse than that.  They have no qualms sending you known-bad items, and just see it as \"maybe the customer won't notice\" and worth a try.  It's definitely a giant pain in the ass, and adds a ton of expense and friction to the process.  Lots of stuff you simply cannot source from any other country though - even if you do, the supply chain usually traces back to China anyways so all you're doing is adding a middleman layer to the problem.It's extremely important to set very explicit and strict quality parameters and specifications prior to any deal you do with a vendor.  Even then you will miss things that will later be argued about.  The more you can specify the better, otherwise it will be seen as negotiable/changeable.A lot of folks used to living in a high trust society get really taking advantage by this. Any vendor sourcing from China and not implementing an extreme level of QA to the process is being negligent, and I assume that's quite a lot if not the vast majority.reply",
      "I don't get how it's possible that nobody (other than Tesla) can manufacture batteries in the West?It a glance this feels insane. Batteries are in everything and such a basic need.How is it possible that buying through known scammers with tons of QA is still cheaper than manufacturing in the West?Obviously for Tesla it isn't cheaper to buy from China, so why is it thought to be cheaper for the rest of the West? Is it purely scale?reply",
      "But Tesla don't make battery cells - Panasonic, LG and CATL make those (although co-located in Telsa's factories).reply",
      "Tesla buys most of their batteries from Japanese and Chinese companies like Panasonic and CATL. Some of those are assembled in factories like the Nevada gigafactory where Panasonic runs part of the factory. They\u2019ve struggled with quality and capacity issues, which I think really just hits the idea that China spent decades on infrastructure and it\u2019ll take similar amounts of time to catch up.reply",
      "Maybe Tesla\u2019s batteries have some sort of competitive advantage that Elon et al. don\u2019t want to risk leaking to the rest of the world?(no idea if that\u2019s the case, I have no specialized knowledge about batteries, just venturing a guess)reply",
      "No, the cells themselves are fairly standard and built by third parties (Panasonic, LG, CATL), just co-located in Tesla's factories.The battery packs themselves have been pulled apart and studied by everyone, pretty much all EV manufacturers are doing similar things anyway, so no real special sauce anywhere anymore.Now there are more mature EV players in the game, innovations are happening from many manufacturers now (not just Tesla leading anymore) and then everyone else converges on the best ideas.reply",
      "The West is an order of magnitude (or more) more expensive, that\u2019s why.reply",
      "That doesn't sound right.  Tesla sells battery packs for around 3x the price of Chinese batteries.reply"
    ],
    "link": "https://www.lumafield.com/article/what-went-wrong-inside-these-recalled-power-banks",
    "first_paragraph": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.Ordered listUnordered listText linkBold textEmphasisSuperscriptSubscriptLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.Ordered listUnordered listText linkBold textEmphasisSuperscriptSubscriptLithium-ion batteries power the many electronic devices that we rely on every day, from EVs to smartphones and laptops. They\u2019re so prevalent, that the average American owns nine lithium ba"
  },
  {
    "title": "Don't bother parsing: Just use images for RAG (morphik.ai)",
    "points": 171,
    "submitter": "Adityav369",
    "submit_time": "2025-07-21T17:16:41 1753118201",
    "num_comments": 52,
    "comments_url": "https://news.ycombinator.com/item?id=44637715",
    "comments": [
      "There's multiple fundamental problems people need to be aware of.- LLM's are typically pre-trained on 4k text tokens and then extrapolated out to longer context windows (it's easy to go from 4000 text tokens to 4001).  This is not possible with images due to how they're tokenized.  As a result, you're out of distribution - hallucinations become a huge problem once you're dealing with more than a couple of images.- Pdf's at 1536 \u00d7 2048 use 3 to 5X more tokens than the raw text (ie higher inference costs and slower responses). Going lower results in blurry images.- Images are inherently a much heavier representation in raw size too, you're adding latency to every request to just download all the needed images.Their very small benchmark is obviously going to outperform basic text chunking on finance docs heavy with charts and tables.  I would be far more interested in seeing an OCR step added with Gemini (which can annotate images) and then comparing results.An end to end image approach makes sense in certain cases (like patents, architecture diagrams, etc) but it's a last resort.reply",
      "I think it would be good to combine traditional OCR with an LLM to fix up mistakes  and add diagram representations - LLMs have the problem of just inventing plausible-sounding text if it can't read it, which is worse than just garbling the result. For instance, GPT4.1 worked perfectly with a screenshot your comment at 1296 \u00d7 179 but if I zoom out to 50% and give it a 650 \u00d7 84 screenshot instead, the  result is:\"There's multiple fundamental problems people need to be aware of.\n- LLM's are typically pre-trained on text tokens and then extrapolated out to longer context windows (it's easy to go from 4000 text tokens to 4001). This is not possible with images due to how they're tokenized. As a result, you're out of distribution - hallucinations become a huge problem once you're dealing with more than a couple of images.\n- A PNG at 512x 2048 is 3.5k more tokens than the raw text (so higher inference costs and slower responses). Going lower results in blurry images.\n- Images are inherently a much heavier representation in raw size too, you're adding latency to every request to just download all the needed images.Their very small benchmark is obviously going to outperform basic text chunking on finance docs heavy with charts and tables. I would be far more interested in seeing an OCR step added with Gemini (which can annotate images) and then comparing results.An end to end image approach makes sense in certain cases (like patents, architecture diagrams, etc) but it's a last resort.\"It mostly gets it right but notice it changes \"Pdf's at 1536 \u00d7 2048 use 3 to 5X more tokens\" to \"A PNG at 512x 2048 is 3.5k more tokens\".reply",
      "True but modern models such as gemma3 pan& scan and other tricks such as training from multiple resolutions do alleviate these issues.An interesting property of the gemma3 family is that increasing the input image siwmze actually does not increase processing memory requirements, because a second stage encoder actually compresses it into fixed size tokens. Very neat in practice.reply",
      "This makes sense, but is something to shaking up the RAG pipeline? Perhaps you could take each RAG result and then do a model processing step to ask it to extract relevant information from the image directly pertaining to the user query, once per result, and then aggregate those (text) results as the input to your final generation. That would sidestep the token limit for multiple images, and allow parallelizing the image understanding step.reply",
      "That's what their document parse product is for. I think people feed things to an LLM sometimes and sure it might work but it could also be the wrong tool for the job. Not everything needs to run through the LLM.reply",
      "LLMs are exactly the tool to use when other parsing methods fail due to poor formatting. AI is for the fuzzy cases.reply",
      "You can add OCR with Gemini, and presumably that would lead to better results than the OCR model we compared against. However, it's important to note that then you're guaranteeing that the entire corpus of documents you're processing will go through a large VLM. That can be prohibitively expensive and slow.Definitely trade-offs to be made here, we found this to be the most effective in most cases.reply",
      "Some colleagues and myself did implemented exactly this six months ago for a French gov agency.It's open source and available here: https://github.com/jolibrain/coletteIt's not our primary business so it's just lying there and we don't advertise much, but it works, somehow and with some tweaks to get it really efficient.The true genius though is that the whole thing can be made fully differentiable, unlocking the ability to finetune the viz rag on targeted datasets.The layout model can also be customized for fine grained document understanding.reply",
      "You don't have a license in your repository top-level. That means that nobody who takes licensing at all seriously can use your stuff, even just for reference.reply",
      "Good catch, will add it tomorrow. License is Apache2.reply"
    ],
    "link": "https://www.morphik.ai/blog/stop-parsing-docs",
    "first_paragraph": "If search is the game, looks matterAt Morphik, we build RAG tools to provide developers accurate search over complex documents. In this article, we explain why we operate over \"images\" of pages instead of doing OCR/ parsing.If you\u2019ve ever tried to extract information from a complex PDF: one with charts, diagrams, and tables mixed with text, you know the pain. That invoice with a nested table showing quarterly breakdowns? The research paper whose intricate figures actually contain the key findings? The technical manual where the annotated diagrams explain more than the text ever could? Or maybe the IKEA manual with no text at all.We\u2019ve all been there, watching our carefully crafted parsing pipeline mangle yet another document. The industry\u2019s dirty secret is that we\u2019re spending enormous effort (and money) on OCR, layout detection, and parsing pipelines that still lose the information that matters most. It\u2019s like trying to \u201cwatch\u201d a movie by reading its script: you miss all the visual sto"
  },
  {
    "title": "Losing language features: some stories about disjoint unions (graydon2.dreamwidth.org)",
    "points": 29,
    "submitter": "Bogdanp",
    "submit_time": "2025-07-18T14:47:16 1752850036",
    "num_comments": 4,
    "comments_url": "https://news.ycombinator.com/item?id=44605245",
    "comments": [
      "Back in the day, when memory wasn't as cheap as it is now, there was a strong belief that forcing the user to \"waste bits\" on a proper sum type was a non-starter for a \"real\" language.  It was widely assumed that the reason you were \"sharing memory\" between two fields was to conserve space, because you were clever enough to have recognized that they couldn't both be used at the same time.  But doing so, it was generally assumed, meant that you were space constrained and so anything that took away your precious savings was bad.I'm not saying this was \"right\" in any sense, but it wasn't just foolish old timers not recognizing that a \"better\" solution was possible.  When you grew up having every single bit of memory threaded by hand (and costing macroscopic amounts of money), you think about memory efficiency differently.reply",
      "Yeah, I remember using untagged unions because the code \"knew\" which type was the right one to use at the right time and you wanted to save space (and wanted your structures to fit well in registers --and later cache lines).reply",
      "Lack of sum types is probably one of the worst things about working in Go, and I think it is a much bigger problem than the lack of generics ever was. Sadly, though, I don't think you can really just bolt sum types onto an already complete programming language design.reply",
      "I'm surprised how many modern languages lack first-class sum type support, considering the amount of domain use cases for them.reply"
    ],
    "link": "https://graydon2.dreamwidth.org/318788.html",
    "first_paragraph": "\nHello, you've been (semi-randomly) selected to take a CAPTCHA to validate\nyour requests. Please complete it below and hit the button!\nOther options:Copyright \u00a9 2009-2025 Dreamwidth Studios, LLC. Some rights reserved."
  },
  {
    "title": "TrackWeight: Turn your MacBook's trackpad into a digital weighing scale (github.com/krishkrosh)",
    "points": 458,
    "submitter": "wtcactus",
    "submit_time": "2025-07-21T14:51:13 1753109473",
    "num_comments": 118,
    "comments_url": "https://news.ycombinator.com/item?id=44635808",
    "comments": [
      "There used to be iPhone apps that did something similar -https://www.theverge.com/2015/10/28/9625340/iphone-6s-gravit...reply",
      "If anyone happens to be using an iPhone 6S... http://touchscale.co/reply",
      "This worked all the way up through the iPhone Xs.reply",
      "The single most irritating killed feature from Apple. Redesign half of their UI to rely on 3D Touch to make sense, then get rid of 3D Touch without redesigning the UI. Previewing links, moving the cursor, interacting with items, they\u2019re all \u201cpress and hold until haptic feedback\u201d instead of \u201cquickly press hard and get immediate feedback.\u201d Easier to accidentally trigger, slower to trigger on purpose.reply",
      "Hardware cost+extra weight (need to make the glass thicker to be able to handle extra force and not push on the display). Turns out nobody was really using it because discoverability sucked..reply",
      "Hardware cost & weight, fine. Glass doesn't need to be thicker than it currently is (I can press on my 13 Pro's screen about twice as hard as was needed for 3D Touch's max depth, and no issues with the screen), and the last time I replaced a battery on a 12, the screen was just as thick as the XS.>Turns out nobody was really using it because discoverability sucked..Sure, but then redesign the UI after removing 3D Touch to not be equally undiscoverable but less precise. Even on the latest iOS beta with its full redesign, there's still many, many actions that require a long press that are completely undiscoverable. (For example, if you don't have the Shazam app installed, go find the list of songs Siri has recognized when asked \"What's this song?\" Don't look up the answer.)reply",
      "> Glass doesn't need to be thicker than it currently is (I can press on my 13 Pro's screen about twice as hard as was needed for 3D Touch's max depth, and no issues with the screen)I dont think this is a great argument. The glass maybe needs to be thicker so the sensors on the border can properly measure the pressure, not because the screen is close to shattering.reply",
      "Maybe you had a hard time parsing his comment.He is capable of pressing twice as hard as the feature required at maximum. The screen handles 2x the maximum without issues. Therefore, the glass is thick enough to handle half that pressure,as required by the feature.It's a good argument.reply",
      "As far as I know, the pressure is measured around the edge of the screen. If the screen is thin enough, it could bend when pressed and the pressure applied to the center of the screen can\u2019t be properly measured. I don\u2019t think the problem with a too thin screen is the screen breaking when pressing it.reply",
      "For what it\u2019s worth, I made the same parsing error upon first read.reply"
    ],
    "link": "https://github.com/KrishKrosh/TrackWeight",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page.Turn your MacBook's trackpad into a precise digital weighing scaleTrackWeight is a macOS application that transforms your MacBook's trackpad into an accurate weighing scale by leveraging the Force Touch pressure sensors built into modern MacBook trackpads.To use it yourself:TrackWeight utilizes the Open Multi-Touch Support library by Takuto Nakamura to gain private access to all mouse and trackpad events on macOS. This library provides detailed touch data including pressure readings that are normally inaccessible to standard applications.The key insight is that trackpad pressure events are only generated when there's capacitance detected on the trackpad surface - meaning your finger (or another conductive object) must be in c"
  },
  {
    "title": "Scarcity, Inventory, and Inequity: A Deep Dive into Airline Fare Buckets (getjetback.com)",
    "points": 81,
    "submitter": "bdev12345",
    "submit_time": "2025-07-21T19:31:43 1753126303",
    "num_comments": 29,
    "comments_url": "https://news.ycombinator.com/item?id=44639421",
    "comments": [
      "recently, i bought a full economy fare on an international flight. When i went to check in, they offered a really cheap upgrade to first. it was a no brainer and i was excited since the flight was gonna be ~6 hours.i had a rude awakening when i got to the airport. This \"first class\" ticket was actually more like a premium economy ticket. I didn't get access to the first class check in line, no access to the lounge, no priority boarding, and the seats themselves had no extra bonus other than being in the front of the plane and slightly wider.it was at that moment i realized there was no beating airlines and good deals aren't really that good unless you got the money to spend.reply",
      "I have flown \"first class\" on flights that turned out to be small airplanes and there was not much to the first class distinction, seats only slightly bigger, no special food, etc.I'm confused a little by what you are saying, are you saying that there was first class boarding but you were not allowed to participate? was there a first class lounge with the name of your airline and you were not allowed to use it? etc.reply",
      "You can beat airlines. Mistake fares and fares sold below cost definitely exist, though they're a lot less common than they used to be as pricing models have improved. You're more likely to see them if you pay attention to off-season and new routes that aren't popular. Severe weather predictions and similar events can also create large price drops. I once got a $20 flight to Hawaii by simply buying just before a typhoon that didn't hit.reply",
      "What airline?reply",
      "Has to be Iceland Air.reply",
      "Was not expecting to read the whole thing. Very interesting.reply",
      "Was it really interesting?  To me, it has certain hallmarks of an AI-generated article.  In particular, it introduces the same concept several times, in different sections.  For example, fare classes, nested booking, and the SABRE system each get two different introductions.The content seems legitimate, but I felt like my time was being wasted through at minimum a lack of editing.reply",
      "I think this is an example of above average but not great AI writing. I still read it to the end because the subject is interesting and there is enough focus (and, seemingly) expertise on the topic.I think the telltale for me that makes me count as heavily AI-assisted is the lack of inclusion of real, inline examples of actual fares & their restrictions. I know I've seen them broken down before in other content. But not once here was there a full readout of an actual fare bucket & its rules. I think a human writer would have been tempted to include even one of those as an artifact, but an AI as a topic reviewer/summarizer/collator won't unless explicitly instructed.reply",
      "\"Airlines don't just sell seats - they manage a dynamic inventory of fares, divided into booking classes (fare buckets)\"that \"They don't just _____ -- they ________\" construction! It's definitely a \"once you see it\" thing that you start to see constantly in AI-generated content! I wonder why the model loves that so muchreply",
      "Training on content with parallelismreply"
    ],
    "link": "https://blog.getjetback.com/scarcity-inventory-and-inequity-a-deep-dive-into-airline-fare-buckets/",
    "first_paragraph": "Airline pricing may seem mystifying, but behind every airfare is a complex system of fare buckets and inventory controls. Airlines don't just sell seats - they manage a dynamic inventory of fares, divided into booking classes (fare buckets) with different prices and rules. For the technically curious, understanding how fare buckets work reveals the \"source code\" of airline revenue management. This report delves into the hierarchy of booking classes, how airlines update seat availability across reservation systems, the role of revenue management algorithms, and the evolution from rigid fare classes to modern dynamic pricing. We draw on industry documentation and technical standards to peel back the curtain on airline inventory systems.Airlines organize seats into service classes (e.g. First, Business, Economy) and further subdivide them into booking classes (fare buckets) for pricing flexibility. A booking class is typically a one-letter code (sometimes followed by digits in a fare basi"
  },
  {
    "title": "New records on Wendelstein 7-X (iter.org)",
    "points": 184,
    "submitter": "greesil",
    "submit_time": "2025-07-21T15:18:41 1753111121",
    "num_comments": 83,
    "comments_url": "https://news.ycombinator.com/item?id=44636204",
    "comments": [
      "A better link:\nhttps://www.ipp.mpg.de/5532945/w7x?c=5481737(there is some irony in using the iter.org link for a stellarator announcement)1.8GJ over 360 seconds, beta of 0.03reply",
      "> \"1.8GJ over 360 seconds\"Not sure if this is contextually obvious to practitioners, but that figure is the \"Energy turnover\" / \"is calculated as the product of injected heating power and plasma duration\".reply",
      "This article has zero quantifiable information in it aside from the duration... which has no context.  Who's recordkeeping this stuff?  What are the other results so far? What is the tipping point where it is net positive? how long does it need to sustain a net positive fusion reaction to produce sufficient power for grid consumption?  Are there other losses (thermal generation inefficiencies) that make the target even farther than energy-in<energy-out?reply",
      "Here is an actual article with some context - and a reality check that other experimental reactors in the past have sustained similar triple product for longer durations... \nhttps://www.ipp.mpg.de/5532945/w7xreply",
      ">The fact that W7-X results are on a par with JET is remarkable because JET had three times the plasma volume of Wendelstein 7-X.What's important here is that W 7-X is a stellarator, a different type of fusion reactor from almost all prior reactors (they are tokamaks), with a smaller volume than the co-record holder.That a stellarator gets these results with a much smaller fusion volume is promising for the performance of future larger stellarators, since fusion reactors typically become more efficient as they get larger.reply",
      "> from almost all prior reactors (they are tokamaks)Tokamak and Stllerator are about equally old, 1953 vs 1954, while both types where for a period developed in secrecy behind either side of the iron curtain till end of the 1960ies where collaboration started.IPP was founded in 1960 (by, among others, my dad) and focussed on Stllerator since then (while collaborating in JET and ITER around their tokamak projects)reply",
      "All good information, entirely missing from the original article -reply",
      ">What is the tipping point where it is net positive?There are several interesting net positive tipping points depending on where you draw the boundary that energy in and energy out cross.  We're still in the earlier stages of net positive where the boundary is quite small and little consideration is being given to the part of the process where electrons get pushed around in a power grid.reply",
      "In any future fusion power plant, a plasma with a high triple product must be maintained for long periods.I love vague terms like \"long periods\". Long compared to the Planck length? Geological time? Is the advertised 43 seconds almost there or \"off by 17 orders of magnitude?\"reply",
      "I believe it's \"for as long as the reactor is to be operating\", and they contrast that with the previous longest times being less than 45 seconds.reply"
    ],
    "link": "https://www.iter.org/node/20687/new-records-wendelstein-7-x",
    "first_paragraph": "New ITER Boutique! Purchase ITER-branded merchandise here.Your email address will only be used for the purpose of sending you the ITER Organization publication(s) that you have requested.\u00a0ITER Organization will not transfer your email address or other personal data to any other party or use it for commercial purposes.If you change your mind, you can easily unsubscribe\u00a0by clicking the unsubscribe option at the bottom of an email you've received from ITER Organization.For more information, see our\u00a0Privacy policy.Select your newsletters:ITER NewslineKeep in touch with ITER through our main news feed, sent weekly.ITER Magazine - French onlyLearn more about the ITER Project by subscribing to this quarterly online magazine (in French) that is geared toward the general public.ITER Open Doors Day - NotificationsStay informed about the ITER Open Doors sessions and be among the first to subscribe to the next event.Your email address will only be used for the purpose of sending you the ITER Organ"
  },
  {
    "title": "Erlang 28 on GRiSP Nano using only 16 MB (grisp.org)",
    "points": 100,
    "submitter": "plainOldText",
    "submit_time": "2025-07-21T19:40:15 1753126815",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44639524",
    "comments": [
      "This video https://youtu.be/TBrPyy48vFI?t=1277 is a few years old, but it covers how the GRiSP platform combines Erlang and RTEMS Real-time OS [1] to overcome Erlang VM's soft real-time limitations and achieve hard real-time event handling.[1] https://www.rtems.org/reply",
      "What are the soft real time limitations of erlang?reply",
      "Erlang's BEAM, assuming no chicanery of NIFs, will use reduction counting to eventually yield a scheduler to make sure other Erlang processes get execution time. This gives you kind of a \"will eventually happen\" property. It can't guarantee meeting a deadline. Just that all things will be serviced at some point.reply",
      "I suppose having the small DRAM footprint is required to meet extremely low power requirements.  How low power is it?  The CPU has a 18.6 \u03bcA/MHz Run mode at 3.3 V [1], so 61\u03bcW!  I wanted to know more about the power harvesting applications though.[1] https://www.st.com/resource/en/datasheet/stm32u5f7vj.pdfreply",
      "This is incredible. Kudos on getting it done, and done so quickly!reply"
    ],
    "link": "https://www.grisp.org/blog/posts/2025-06-11-grisp-nano-codebeam-sto",
    "first_paragraph": "Maria Jose Gavilan \u2014 11/06/2025Last Monday (2 June) at Code BEAM Light Stockholm Peer opened his presentation with the question Can the BEAM fit into 16 MB? Two days later, the GRiSP Nano prototype answered with an Erlang shell prompt. That success rests on work we\u2019ve carried out since mid-2024.GRiSP Nano pairs an STM32U5 Cortex-M33 (3\u202fMB internal SRAM) with 16\u202fMB of OctoSPI DRAM. A micro-SD slot handles storage; 4 PMOD\u2122 connectors expose SPI, I\u00b2C, and UART. Micro-USB provides console access. USB-C, with OTG support, can act as a programmable host or client. Power can be supplied through either port, and in addition, from an energy harvester.We initially planned for 32\u202fMB. But after the PCBs were made, a CPU erratum came to light. We had to search for a pin-compatible RAM chip with the right characteristics to keep things running. That\u2019s how we landed at 16\u202fMB. The constraint wasn\u2019t planned, but it shaped the result.ONLY 16\u202fMB! This is fine \ud83d\udd25\ud83d\udc36 Zero chill: embedded limits, Erlang charm,"
  },
  {
    "title": "Game Genie Retrospective: The Best NES Accessory Ever Was Unlicensed (tedium.co)",
    "points": 105,
    "submitter": "coloneltcb",
    "submit_time": "2025-07-21T17:59:00 1753120740",
    "num_comments": 45,
    "comments_url": "https://news.ycombinator.com/item?id=44638300",
    "comments": [
      "For those who didn't live through the era, it's hard to understate how much a Game Genie really did make things more fun and interesting.  The thing basically gave you a huge menu of settings/tweaks you could make to a game, more common examples being \"99 lives\" or \"Maximum HP\" or something like that, but it could also make games more difficult for those who wanted that.  It really felt to me like bumpers at a bowling alley, except the bumpers could be moved around to make it easier to get a strike or nearly impossible.I never got one myself, but a friend did and we had endless fun tweaking different properties of all of our games.  It was much more about exploration than it was about \"cheating\" at games.  Game Genie was one of my first experiences of being mindblown at somebody's clever hack and use of technology, and I am grateful to have been able to live through that age.reply",
      "Two other fun details:In some cases they could be used to get things that were in the game \"legitimately\" but which you might not have access to. E.g. getting Mew in Pokemon Blue/Red or Surfing Pikachu in Pokemon Yellow.Sometimes the codes would break in interesting ways. For example, an invincibility code might cause problems if it was on during a battle that you are scripted to lose. Or the \"invincibility\" code might actually work by instantly healing you; so you might find out that you are vulnerable if an enemy is strong enough to take all of your health with a single hit.Like the parent post said, there was a lot of experimentation even when everything was working \"correctly\".reply",
      "In the name of \"Show, Don't Tell,\" here are some fun examples:Super Mario Bros 3 (NES + Game Genie) equipping Hammer Suit / Invincibility:https://www.youtube.com/shorts/FUVOM3rxZ5USuper Mario World (SNES + Game Genie) causing weird memory distortion glitches, enabling swimming anywhere, and other more useful things:https://youtu.be/o7_eFcpwq24?si=_io5oSzpRxdvuEMp&t=164Super Mario RPG (SNES + Game Genie) enabling the hidden developer debug menu:https://youtu.be/bH-uh9BnIfU?si=0L7qviRp5T-Nokjs&t=402Pokemon Red (Game Boy SP + Game Genie) unlocking the unobtainable Mew (which Nintendo only gave away at rare in-person tournament events) at game start:https://www.youtube.com/shorts/yzqTRbixnakZelda Link's Awakening (Game Boy + Game Genie) changing the value of \"1\" rupee to \"255\" rupees for effectively infinite currency (the creator isn't aware of the significance of \"255\"):https://www.youtube.com/shorts/dRFqU_Dz3M8Super Mario 64 (N64 + Gameshark) adding Dorrie the Plesiosaur to Lethal Lava Land:https://youtu.be/DVBMdwn8Kc0?si=cUZ5ioG1GEvY0l-H&t=84Super Mario 64 (N64 + Gameshark) showing off the Gameshark menu and a bunch of Mario character animation swaps:https://www.youtube.com/shorts/AptK2MbqLXQBanjo-Kazooie (N64 + Gameshark) replacing the main characters with the Rareware logo and adding an \"infinite jump by pressing A\" hack, which adds displacement or velocity with a button press (yes, this is totally absurd):https://www.youtube.com/watch?v=XF6pwm00vtYZelda Ocarina of Time (N64 + Gameshark) spawning a hidden developer-only enemy, the Starfox Arwing, which shoots lasers at Link:https://www.youtube.com/shorts/KOQUhm1cNu8Smash Bros 64 (N64 Emulator) spawning Master Hand (final boss) as a playable character in a standard stage:https://www.youtube.com/watch?v=A1i9TRLifawZelda Majora's Mask (N64 + Gameshark) spawning special items, equipping the wrong items, using the wrong weapons, manually adjusting the clock, etc.:https://youtu.be/ae2q9CjqXsc?si=IPB7XcPFWZyzpbh3Smash Bros Melee (Gamecube emulator) spawning infinite items and damage for total chaos:https://www.youtube.com/watch?v=IDZZiL4rqlkQuick Game Genie hardware overview:https://www.youtube.com/shorts/WzHokvjdvDcreply",
      "Goldeneye on N64 had some really cool hidden modes that could only be turned on with Game Genie. I don't recall which ones exactly required the Game Genie, but I'm pretty sure there was one that made everyone invisible until their first death in multiplayer. That was a lot of fun.reply",
      "I just liked to make everyone wear sunglasses. Plus loading the tank into every level possible.reply",
      "From your first link - I apparently still have 'xnkxglie' memorized...reply",
      "> E.g. getting Mew in Pokemon Blue/Red0115D8CF is one of those sequences that is permanently burned into my brain to the same level as FCKGWreply",
      "Wow. Talk about burn in. RHQQ2 I think was the next part. It's been over a decade since I used that code...reply",
      "Mew can also be obtained through glitches without any game alteration devices.reply",
      "The game genie did not give you a menu, you inputed codes which would persistently modify the memory map of the cartridge allowing for things like 99 lives or max Hp. The \u201cmenu\u201d you describe was a booklet containing every game and a list of code changes.Of course you could write in your own codes and make your own hacks but a lot of the time you ended up with garbled graphics or an unbootable game. They did keep this developer documentation to a minimum and this was before the internet. Although my local BBS had an ascii document detailing game genie\u2019s internals and how to write your own codes, it was far from the reach of most 10 year oldsThe game genie knockoff clone (I forget the name but remember the ads lol) had all of the codes in memory and as such gave you a menu to choose fromreply"
    ],
    "link": "https://tedium.co/2025/07/21/the-game-genie-generation/",
    "first_paragraph": ""
  },
  {
    "title": "Spice Data (YC S19) Is Hiring a Product Associate (New Grad) (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2025-07-21T21:31:23 1753133483",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/spice-data/jobs/RJz1peY-product-associate-new-grad",
    "first_paragraph": "Restaurant Data for the EnterpriseAbout youBenefits\u00a9 2025 Y Combinator"
  },
  {
    "title": "My favourite German word (vurt.org)",
    "points": 11,
    "submitter": "taubek",
    "submit_time": "2025-07-19T07:11:14 1752909074",
    "num_comments": 8,
    "comments_url": "https://news.ycombinator.com/item?id=44613268",
    "comments": [
      "Fremdsch\u00e4men is a good one.My favourite though: Eierschalensollbruchstellenverursacher. It's one of those things that you never knew you needed.reply",
      "That\u2019s great, but gegenstand just means object, and that definition of object is part of English, e.g. \u201cThe object of having this talk is to learn about how we can do better.\u201dYou don\u2019t hear that said much anymore, but in the 20th century it was said fairly regularly.reply",
      "The first half of the essay:> It happened astonishingly fast; within about five years a knowledge skill that I had completely taken for granted as a basic requisite in an undergraduate was diminished beyond recognition.Then the second half> A good way of writing documentation for human beings today will still be a good way to do it in a few years\u2019 time.Don't these contradict each other?   Documentation that worked well for us who grew up pre-Internet is not working well for \"web natives\".reply",
      "No, because the first one isn\u2019t talking about writing documentation. It\u2019s talking about knowledge discovery as a learned skill that eroded when web searching replaced how knowledge used to be sought. They actually say: even in the new-fangled domain of web searching, which you would think web natives would be better at, it\u2019s actually people who had learned the skills and techniques of knowledge discovery pre-web who were better at finding what they were looking for. Now, why they think that is the case is a bit harder to grok, having to do with their object-oriented (sorry, sorry) view of understanding/knowledge.Contrast that with the second quote. Good documentation could be in a dusty book in the library or in a SPA. What makes the documentation good isn\u2019t, however, related to people\u2019s ability to navigate information spaces.reply",
      "> That is like asking how we can make our cities better for cars, or our workplaces better for the furniture (emphasis mine)I love this analogy and am going to use it.This is a fantastic article. In the end, everything is still, and will always be, about people. We ignore and forget that at our peril.Thanks!reply",
      "So if an object is \u201cstanding against\u201d you could we say it is \u201cobjecting\u201d you?reply",
      "You are wrong. Faultier FTW.reply",
      "Backpfeifengesichtreply",
      "Baumkuchen! (Tree-cake)reply",
      "Waschb\u00e4r is another great one.reply"
    ],
    "link": "https://vurt.org/articles/my-favourite-german-word/",
    "first_paragraph": "30th June 2025A documentation colleague recently challenged me with a question:Nowadays, more and more people reach for an LLM tool to provide the information they want. If human beings don\u2019t actually read it, what is the point of writing and structuring documentation for humans?Newer generations (she said) are becoming unskilled at finding information for themselves. They seem less able to digest what they find, to apply it to their problems. But it\u2019s not just that: everybody seems to expect answers that are closely tailored to their particular situation, level of understanding and so on, and to get the answers now. And, many of them are willing to give up guarantees of quality and reliability in exchange of ease-of-use and customised responses.So why should we take painstaking care in the creation of high-quality documentation?A lot of recent discussion in documentation circles and forums has swirled uneasily around these topics. A popular and gloomy version of my colleague\u2019s line of"
  },
  {
    "title": "The Fundamentals of Asyncio (github.com/anordin95)",
    "points": 101,
    "submitter": "anordin95",
    "submit_time": "2025-07-21T18:32:26 1753122746",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=44638710",
    "comments": [
      "I've used Python's asyncio a couple times now, but never really felt confident in my mental model of how it fundamentally works and therefore how I can best leverage it. The official docs provide decent documentation for each specific function in the package, but, in my opinion, lack a cohesive overview of the systems design and architecture. Something that could help the user understand the why and how behind the recommended patterns. And a way to help the user make informed decisions about which tool in the asyncio toolkit they ought to grab, or to recognize when asyncio is the entirely wrong toolkit. This is my attempt to fill that gap.reply",
      "thank you for that.reply",
      "I like how asyncio could just be built off of generators, and how it all ... well it mostly works, and it works well enough for people who care enough to make a whole async stack.I am very unhappy with asyncio leading to the gold rush of a lot of people writing \"async-capable\" libraries that all make (IMO) really gnarly design decisions in the process. I have seen loads of newer Python projects that take async-capable libraries that make life harder for people who like shipping stable software.Meanwhile a lot of existing libraries/frameworks that just have more \"serious\" overall designs have to churn quite a bit to support sync and async workflows.I care a lot about Django getting async ORM support in theory, but at this point I don't know how that's happening. My current mentality is crossing my fingers that something akin to virtual threads[0] happens[0]: https://discuss.python.org/t/add-virtual-threads-to-python/9...reply",
      "You could use gevent. It uses green threads, so that the code you write looks like synchronous code. It can also monkeypatch core networking modules so that existing code will work without changes (including the Django ORM).reply",
      "This is great, thank you! Python's asyncio has certainly confused me more than other languages' async-await implementations.Nit in [1]: When timing durations inside of a program it's best to avoid the system clock as it can and does jump around. For Python, prefer time.monotonic() or time.perf_counter() over time.time() in those situations.[1] https://github.com/anordin95/a-conceptual-overview-of-asynci...reply",
      "Great read!Python asyncio can really screw up your runtime performance if you use it poorly. And it's _really_ easy to use poorly.Consider a FastAPI server using asyncio instead of threading. _Any_ time you drop down into a synchrononous API, you better be sure that you're not doing anything slow. For example, encoding or decoding JSON in Python actually grabs the GIL depending on what library you're using, and then you have no hope of releasing control back to asyncio.reply",
      "That's a GIL problem not an async problem. Even if you choose to ditch asyncio and use threads, you still need to care about the GIL. And when I use asyncio I don't worry about CPU-bound tasks like encoding or decoding JSON; I worry about some library doing I/O synchronously regardless of whether such library releases the GIL or not.reply",
      "This is spot on.  GIL-less python will be a thing, and when it happens, there will still be no reason to combine asyncIO with thread primitives.  Waiting for IO can be spun off into a new thread, and it will work as you expect it would.Trying to combine mental models of asyncio and threading is a model for pure insanity.reply",
      "JSON encoding is, as someone else points out, a GIL problem, but I want to add that even if you do JSON encoding in an async context:  async def foo(\u2026):\n    json.dumps(d)  # you're blocking the event loop\n\nYou're still going to block on it.  def sync_foo(\u2026):\n    json.dumps(d)  # you're holding the GIL \u2026 and so blocking here too\n\nShort of resolving the GIL somehow (either by getting ridding of it, which I think is still a WIP though it has been \"merged\", I believe) or subinterpreters, etc., JSON is inherently going to need to hold the GIL while it walks the structure it is encoding. (Unlike a large file I/O, where it might be possible to release the GIL during the I/O if we have a strong ref to an immutable buffer.)reply",
      "This is more of a usability problem. In the second example, it's obvious that `json.dumps()` blocks everything else and it can be readily observed. It's not obvious that it blocks in the former and I've encountered many surprised coworkers despite it seeming obvious to me.I think a lot of people assume you can slap `async` onto the function signature and it will not block anything anymore. I've had PRs come through that literally added `async` to a completely synchronous function with that misunderstanding.reply"
    ],
    "link": "https://github.com/anordin95/a-conceptual-overview-of-asyncio/blob/main/readme.md",
    "first_paragraph": "We read every piece of feedback, and take your input very seriously.\n            To see all available qualifiers, see our documentation.\n           There was an error while loading. Please reload this page.\nThere was an error while loading. Please reload this page."
  },
  {
    "title": "Occasionally USPS sends me pictures of other people's mail (the418.substack.com)",
    "points": 154,
    "submitter": "shayneo",
    "submit_time": "2025-07-21T14:54:41 1753109681",
    "num_comments": 149,
    "comments_url": "https://news.ycombinator.com/item?id=44635867",
    "comments": [
      "USPS is awful from a privacy perspective. USPS will email photos of your incoming mail to anyone who files a change-of-address form with your address as the new address. They don't require any sort of confirmation.I know this because after I moved out of a place and started traveling for a while, I set up forwarding to my parents' address, and after clicking the \"informed delivery\" checkbox I immediately started getting photos of all my parents' mail.reply",
      "I posted this on the Substack, butAt one point, I entered the wrong address when I was forwarding my mail. As a result, I got my mail sent to a strangers PO Box. As a side effect, I then began to receive Informed Delivery for this stranger to this very day.In addition, I once had the Post Office disable my address. It was like a 101B address and they didn\u2019t consider it legitimate with the city. As a result, they were unable to forward mail when I left that house, and once again, and they were unable to disable the informed consent for this house.As a result of this, I see every piece of mail that two separate strangers receive. I have gone to the post office a half dozen times in the last 5 years to try to disable this, and have repeatedly been told there is absolutely nothing that can be done.reply",
      "You can solve this.Contact your federal senators and/or federal house reps, and tell them that USPS is sending pictures of other peoples' mail.Or if you dont want to do that, then contact USPS Office of Inspector General. uspsoig.gov/The IG's are absolutely terrifying if you're on the wrong side. And you're 100% in the right, and they're in the wrong.reply",
      "Terrifying?What was your experience with an IG?reply",
      "Anytime you are a counterparty to Fed law enforcement, not fun.reply",
      "I have a version of this; I have the email {{popular-asian-surname}}@gmail.com and I've seen _everything_.I've had many many bank statements from India.I've had someone in California order a brand new BMW and got the details for collection.I've had paypal invoices and statements (this is one funny because they refuse to action the delink).I used to reach out and tell them I didn't sign up for their service. But honestly, after doing it for a few years I gave up.Now, I mark as junk and move on.The best one I had was a dating site in Canada, I got it while sat next to me partner.reply",
      "I have a reasonably common name. I am in Bay Area, and have received mail meant for people in Fresno or Bakersfield, someone in Toronto, someone in Australia, and I think someone in a London suburb. There are drug test results, online orders, legal discussions, store receipts and hotel bookings. I even connected with 2-3 folks with my name - don't recall how I figured their other email. It was quite common for a while, but then I haven't seen anything like this for 2-3 years. When I say common, I mean once every 6-8 months and I guess I have had that email for 15 years or so. Maybe my universe of overlap was finite and all those people have figured out how to type their email now :)That email is my first name dot last name but at one point I had been able to secure both first name at email provider dot come and last name at email provider dot com which somehow I abandoned. I wonder what level of erroneous emails I would have received at them.reply",
      "I was an early Gmail adopter and have a common ethnic first initial last name. People mess up their email all of the time and I get insane stuff.One lady, a general manager of a factory, sent a zip file with her VPN client, a list of backup MFA codes and a list of SCADA and IT systems for a large factory.A police detective sent a video from a paratransit bus that was in an accident. I got a bitcoin years ago. One dude had a hobby of test driving luxury cars from almost every dealer in the Washington DC region. I have a $50 gift card for an Australian electronics store.reply",
      "I have one like that. I have the email first.last@gmail.com, and I have a very uncommon last name. Lo and behold, Google let some dude in Australia who happens to share my name sign up with firstlast@gmail.com. According to the docs the two should be equivalent, so they shouldn't have let him sign up, but they did... and now I get his email all the time. I have gotten job offers, bills from medical offices, even one follow up email from his therapist. And lots and lots of ads, of course. I have tried to let people know (when it's a real person contacting me) to let this guy know about the email situation, but either they don't reach out to him or he doesn't care. At this point I just delete all the emails meant for him without reading them, and figure if he misses out on a job offer or something... I tried my best.Still, bizarre that the situation was allowed to occur in the first place by Google. Clearly they need to beef up their account creation checks a bit.reply",
      "I observed a similar issue and years ago a Googler reached out after I bitched about it on HN and looked into it.They claimed that it was a typo and I believe them. Places don\u2019t validate email and people make alot of typos.reply"
    ],
    "link": "https://the418.substack.com/p/a-bug-in-the-mail",
    "first_paragraph": ""
  },
  {
    "title": "FCC to eliminate gigabit speed goal and scrap analysis of broadband prices (arstechnica.com)",
    "points": 61,
    "submitter": "Bluestein",
    "submit_time": "2025-07-21T23:18:14 1753139894",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=44641464",
    "comments": [
      "Seems they really want to revert everything that made the US a world leader.- Reduce science- Reduce collected data- Reduce immigration- Reduce infrastructure- Reduce adoption of EVsreply",
      "Most of the work that made the US a world leader was done a long time ago and the institutions that were responsible have either winded down operations or degenerated into sinecures for those loyal to the current administration's political rivals.reply",
      "What did EVs make us a leader in? If I remember right, other countries have much higher adoption.reply",
      "Technically Tesla was the first major company globally starting a trend. Aka leading.reply",
      "By that definition, we haven't been leading for years since the Chinese are cranking them out much faster than Tesla.What if we want to be a world leader in satellite internet coverage? Is that a goal you support? Because that's part of what these changes are about.reply",
      "FYI to all commenters: the current FCC chair was nominated by Trump>Biden>Trump and unanimously confirmed by the Senate all 3 times.reply",
      "Also, FYI to all commenters: The FCC board is required to have no more than 3 members from a single political party on the board of 5.reply",
      "This seems to be good for Starlink at the expense of the fiber providers?reply",
      "Rural fiber at my lake home went from $35/mo for 100/100 to $89.95 this year. On a 12mo contract.Starlink got my business after VZW forced their 5G boxes to use 5G and not allow forced LTE usage. 5G is unusable there with 60-100/0.03. I force my phone to use LTE and all is well but 5G just does not work.I hate giving Elon money but it\u2019s the only affordable month-to-month option now.reply",
      "Yeah cause they're not going to have to compete with real bandwidth availability.given the new shiny one (that hasn't launched) is topping out at 1Tb of downlink (with half of it going to backhaul) and the current units are 80 Gb/sreply"
    ],
    "link": "https://arstechnica.com/civis/threads/fcc-to-eliminate-gigabit-speed-goal-and-scrap-analysis-of-broadband-prices.1508451/page-2",
    "first_paragraph": ""
  },
  {
    "title": "LetsEncrypt Outage (status.io)",
    "points": 143,
    "submitter": "kenshaw",
    "submit_time": "2025-07-21T22:29:28 1753136968",
    "num_comments": 60,
    "comments_url": "https://news.ycombinator.com/item?id=44641117",
    "comments": [
      "Let's Encrypt stopped its certificate expiration email notification service a while ago, and I hadn't found a replacement yet. As a result, I didn't receive an expiration notice this time and failed to renew my certificate in advance. The certificate expired today, making my website inaccessible. I logged into my VPS to renew it manually, but the process failed every time. I then checked my cloud provider's platform and saw a notification at the top, which made me realize the problem was with the certificate provider. A quick look at Hacker News confirmed it: Let's Encrypt was having an outage. I want to post this news on my website, but I can't, because my site is down due to the expired certificate.reply",
      "I use self-hosted gatus to monitor my certs and other services' status.It can send alerts to multiple alerting providers.https://github.com/TwiN/gatusreply",
      "They have been communicating the ending of the email notices for quite a while and have been telling users that you should have some other monitoring in place to avoid just this situationreply",
      "Yes, but what\u2019s weird is the recommended service they referred people to for new email notifications was not\u2026 sending me emails.So, what gives?reply",
      "Yeah the recommended service is awful and not nearly as useful as the one they had is.Which is disappointing because you should be able to recreate the service they had nearly exactly with certificate transparency logs.reply",
      "Also, beware of the leopard.reply",
      "If you didn't see their sunset notification emails you wouldn't have seen your cert expiration email either.reply",
      "Oof, you're right, that's rough that it's so soon after they discontinued their email service!I wrote this blog post a few weeks ago: \"Minimal, cron-ready scripts in Bash, Python, Ruby, Node.js (JavaScript), Go, and Powershell to check when your website's SSL certificate expires.\" https://heiioncall.com/blog/barebone-scripts-to-check-ssl-ce... which may be helpful if you want to roll your own.(Disclosure: at Heii On-Call we also offer free SSL certificate expiration monitoring, among other things.)reply",
      "Haven't they always, from day one, insisted that their primary goal was to encourage (force) automation of certificate maintenance, as a mechanism to make tls ubiquitous (mandatory everywhere)?reply",
      "I run https://ismycertexpired.com/ - you can sign up for email alerts.reply"
    ],
    "link": "https://letsencrypt.status.io/",
    "first_paragraph": "Updated a few seconds agoUpdated a few seconds agoIncident Status  Service DisruptionComponents  acme-v02.api.letsencrypt.org (Production), {e,r}[1-14].o.lencr.org, acme-staging-v02.api.letsencrypt.org (Staging), stg-{e,r}[1-14].o.lencr.orgLocations  High Assurance Datacenter 1, High Assurance Datacenter 2acme-v02.api.letsencrypt.org (Production)Service Disruption{e,r}[1-14].o.lencr.org Service Disruption{e,r}{1-14}.c.lencr.org OperationalWebsite Operationalacme-staging-v02.api.letsencrypt.org (Staging)Service Disruptionstg-{e,r}[1-14].o.lencr.orgService Disruptionstg-{e,r}{1-14}.c.lencr.org Operationaloak.ct.letsencrypt.org (Production)Operationalsapling.ct.letsencrypt.org (Staging)OperationalEnter your Microsoft Teams webhook. View InstructionsEmail address for managing subscriptionSlack channel IDFind the channel ID: Select the channel in your Slack workspace. The channel ID is displayed in the browser URL.Example: https://app.slack.com/client/T04SJBK1C/C03SKGJ1PEmail address"
  },
  {
    "title": "Sutton SignWriting is a writing system for sign languages (wikipedia.org)",
    "points": 20,
    "submitter": "janpot",
    "submit_time": "2025-07-19T11:54:40 1752926080",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=44614747",
    "comments": [
      "I don't believe I see the purpose of this. Is it:* Empower deaf people to feel like they have a shared, global language distinct from and on par with spoken languages? (but there are other sign languages besides ASL...)* Serve people who are sighted, but both deaf and dyslexic? (Would the symbols actually help?)* Teach people how to use sign language? (same objection as before, plus it just doesn't come across as very informative)* Something else?I will say that featural scripts like this are cool in general, though, and also congrats to the parties involved on getting it into Unicode.reply",
      "If you recognize that sign languages such as ASL are distinct languages, as linguists do, then it naturally makes sense that native speakers of those languages would want a way to write them down in a static symbolic way, for all the same practical reasons that we use the Latin alphabet in English.For instance, being able to quickly scan through a piece of text instead of having to watch it play in video form, or being able to search and index it, or providing a way to organize dictionaries.There's no inherent problem with using the same notation scheme for different sign languages, just like we use essentially the same alphabet for English, Spanish, French, German, etc.reply",
      "SignWriting is closer in purpose to the International Phonetic Alphabet for spoken languages. It attempts to allow detailed recording of the actual signing as it is signed for any sign language.It has a lot of the disdvantages of IPA as a practical writing system as well.Sign languages are not the same as spoken languages used in the same countries, as is very apparent if you look at transliterations of ASL using latin glyphs, there are some standardized ways to do this but they drop a lot of information and don't have the same sentence/word structure.There is also a long history of attempts to create notation that can record this type of language, the first for ASL being Stokoe notation, which represents hand shapes for example, but can't represent for example facial elements, and is specific to ASL, can't represent things in other sign languages.reply",
      "Interestingly, one advantage SignWriting may have over IPA is that while you cannot easily represent sounds in a visual medium (thus letters are mostly arbitrary) movement and hand depictions in SW are highly iconic.Also, just as you can drop many IPA symbols and just get the basic set needed to represent a particular language, I guess you could use \"simplified\" SW ignoring the fine differences.reply",
      "It's a way to write sign languages. Think of like the alphabet, but for hands, movements etc instead of sounds.Now, it may not be obvious that there is a necessity for a writing system for a minority language embedded in a larger community (spoken language), but there are many uses: preservation, digital use, teaching, linguistic study...reply"
    ],
    "link": "https://en.m.wikipedia.org/wiki/SignWriting",
    "first_paragraph": "Sutton SignWriting, or simply SignWriting, is a writing system for sign languages. It can be used to write any sign language, including American Sign Language, Brazilian Sign Language, Tunisian Sign Language, and many others.[1]\nWebsite SignWriting.orgMobile m.SignWriting.org\nSignWriting is the only international writing system for sign languages.[2] It has been used to publish young adult fiction,[3] translate the Bible,[4] caption YouTube videos,[5] and study sign language literacy.[6]The SignWriting system is visually iconic: its symbols depict the hands, face, and body of a signer. And unlike most writing systems, which are written linearly, the symbols of SignWriting are written two-dimensionally, to represent the signing space.[7]\nSignWriting was invented in 1974 by Valerie Sutton, a ballet dancer who eight years earlier had developed a dance notation named Sutton DanceWriting.[8] The current standardized form of SignWriting is known as the International Sign Writing Alphabet (IS"
  }
]