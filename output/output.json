[
  {
    "title": "ChatGPT Search (openai.com)",
    "points": 798,
    "submitter": "marban",
    "submit_time": "2024-10-31T16:41:22 1730392882",
    "num_comments": 663,
    "comments_url": "https://news.ycombinator.com/item?id=42008569",
    "comments": [
      "Been thinking about this a lot [1]. Will this fundamentally change how people find and access information? How do you create an experience so compelling that it replaces the current paradigm?The future promised in Star Trek and even Apple's Knowledge Navigator [2] from 1987 still feels distant. In those visions, users simply asked questions and received reliable answers - nobody had to fact-check the answers ever.Combining two broken systems - compromised search engines and unreliable LLMs - seems unlikely to yield that vision. Legacy, ad-based search, has devolved into a wasteland of misaligned incentives, conflict of interest and prolifirated the web full of content farms optimized for ads and algos instead of humans.Path forward requires solving the core challenge: actually surfacing the content people want to see, not what intermiediaries want them to see - which means a different business model in seach, where there are no intermediaries. I do not see a way around this. Advancing models without advancing search is like having a michelin star chef work with spoiled ingredients.I am cautiously optimistic we will eventually get there, but boy, we will need a fundamentally different setup in terms of incentives involved in information consumption, both in tech and society.[1] https://blog.kagi.com/age-pagerank-over[2] https://www.youtube.com/watch?v=umJsITGzXd0\n \nreply",
      "I genuinely think Kagi has led the way on this one.  Simplicity is beautiful and effective, and Kagi has (IMHO) absolutely nailed it with their AI approach.  It's one of those things that in hindsight seems obvious, which is a pretty good measure of how good an idea is IMHO.Google could have done it and kind of tried, although they're AI sucks too much.  I'm very surprised that OpenAI hasn't done this sooner as well.  They're initial implementation of web search was sad.  I don't mean to be super critical as I think generally OpenAI is very, very good at what they do, but they're initial browse the web was a giant hack that I would expect from an intern who isn't being given good guidance by their mentors.Once mainstream engines start getting on par with Kagi, there's gonna be a massive wave of destruction and opportunity.  I'm guessing there will be a lot of new pay walls popping up, and lots of access deals with the search engines.  This will even further raise the barrier of entry for new search entrants, and will further fragment information access between the haves and have-nots.I'm also cautiously optimistic though.  We'll get there, but it's gonna be a bit shakey for a minute or two.\n \nreply",
      "> I'm also cautiously optimistic though. We'll get there, but it's gonna be a bit shakey for a minute or two.But I don't understand how all of these AI results (note I haven't used Kagi so I don't know if it's different) don't fundamentally and irretrievably break the economics of the web. The \"old deal\" if you will is that many publishers would put stuff out on the web for free, but then with the hope that they could monetize it (somehow, even just with something like AdSense ads) on the backend. This \"deal\" was already getting a lot worse over the past years as Google had done more and more to keep people from ever needing to click through in the first place. Sure, these AI results have citation results, but the click-through rates are probably abysmal.Why would anyone ever publish stuff on the web for free unless it was just a hobby? There are a lot of high quality sites that need some return (quality creators need to eat) to be feasible, and those have to start going away. I mean, personally, for recipes I always start with ChatGPT now (I get just the recipe instead of \"the history of the domestication of the tomato\" that Google essentially forced on recipe sites for SEO competitive reasons), but why would any site now ever want to publish (or create) new high quality recipes?Can someone please explain how the open web, at least the part of the web the requires some sort of viable funding model for creators, can survive this?\n \nreply",
      "Wait, did google force \"the history of the domestication of the tomato\" to be part of recipes on the web for SEO reasons?\n \nreply",
      "> Why would anyone ever publish stuff on the web for free unless it was just a hobbyThat's exactly what the old deal was, and it's what made the old web so good. If every paid or ad-funded site died tomorrow, the web would be pretty much healed.\n \nreply",
      "That's a bit too simple. There is way fewer people producing quality content \"for fun\" than people that aim or at least eventually hope to make money from it.Yes a few sites take this too far and ruin search results for everyone. But taking the possibility away would also cut the produced content by a lot.Youtube for example had some good content before monetization, but there is a lot of great documentary like channels now that simply wouldn't be possible without ads. There is also clickbait trash yes, but I rather have both than neither.\n \nreply",
      "Demonetizing the web sounds mostly awesome.",
      "Paging Sergey\n \nreply",
      "The internet was great before the great monetization of it, had tons of information provided for free with no ads. After ads, it will still have tons of information. Stack Overflows will still exist, Wikipedias, corporate blogs that serve just to boost the company, people making courses and other educational content, personal blogs (countless of which make their way here), all of those will continue to exist.Ad-driven social networks will continue to exist as well.The age of the ad-driven blog website is probably at an end. But there will be countless people posting stuff online for free anyway.\n \nreply",
      "> the history of the domestication of the tomato\" that Google essentially forced on recipe sites for SEO competitive reasonsThat may help with SEO, but another reason is copyright law.Recipes can't be copyrighted, but stories can. Here is how ChatGPT explained it to me:> Recipes themselves, particularly the list of ingredients and steps, generally can't be copyrighted because they're considered functional instructions. However, the unique way a recipe is presented\u2014such as personal stories, anecdotes, or detailed explanations\u2014can be copyrighted. By adding this extra content, bloggers and recipe creators can make their work distinctive and protectable under copyright law, which also encourages people to stay on their page longer (a bonus for ad revenue).> In many cases, though, bloggers also do this to build a connection with readers, share cooking tips, or explain why a recipe is special to them. So while copyright plays a role, storytelling has other motivations, too.\n \nreply"
    ],
    "link": "https://openai.com/index/introducing-chatgpt-search/",
    "first_paragraph": ""
  },
  {
    "title": "An Update on Apple M1/M2 GPU Drivers (lwn.net)",
    "points": 236,
    "submitter": "MrBuddyCasino",
    "submit_time": "2024-10-31T20:36:53 1730407013",
    "num_comments": 76,
    "comments_url": "https://news.ycombinator.com/item?id=42011239",
    "comments": [
      "That's not even a costume because she's definitely a wizard\n \nreply",
      "Is anyone else astonished at how much is missing in the hardware and how much is emulated?\n \nreply",
      "The graphics pipeline in modern GPUs are mostly a thin low-level Vulkan/Metal-like layer on top of a massively parallel CUDA-like compute architecture.It's basically all emulated. One of the reasons GPU manufacturers are unwilling to open source their drivers is because a lot of their secret sauce actually happens in software in the drivers on top of the massively parallel CUDA-like compute architecture.\n \nreply",
      "I didn't read the article and don't know about Apple but that's definitely not true for everyone. Source: see amdgpu built on top of HSA.EDIT: to be precise yes ofc every chip is a massively parallel array of compute units but CUDA has absolutely nothing to do with it and no not every company buries the functionality in the driver.\n \nreply",
      "The things being emulated are mostly legacy features that are barely used in modern software, if at all, so the overhead of emulating them for backward compatibility isn't the end of the world. I can't blame Apple for not supporting geometry shaders in hardware, when they're widely considered to be a mistake that never should have been standardized in the first place, and Metal never supported them at all so they could only ever come up in old OpenGL code on macOS.https://x.com/pointinpolygon/status/1270695113967181827\n \nreply",
      "I wouldn't go so far as to say \"mistake that should never have been standardized\". Their intended use was always pretty limited, though. There's zero reason for anything built in recent memory to use them.\n \nreply",
      "They had limited uses and turned out to be incredibly hard to implement efficiently in hardware, so in practice it was nearly always faster to just keep using the proven techniques that GS was supposed to replace.http://www.joshbarczak.com/blog/?p=667\n \nreply",
      "So why does instancing suck? I would have thought it would be heavily optimised in the driver...\n \nreply",
      "And yet one of the fancy new features being advertised in recent years (in multiple APIs including Metal) is support for mesh shaders \u2013 which seem to have a lot in common with geometry shaders, including the output ordering property that that post blames for geometry shaders\u2019 bad performance.  I\u2019m not a graphics programmer myself, but this makes me suspect there\u2019s more to the story.\n \nreply",
      "Is this really so different from any other mobile derived GPU?\n \nreply"
    ],
    "link": "https://lwn.net/SubscriberLink/995383/34dc5950cab5e739/",
    "first_paragraph": "\nThe kernel graphics driver for the Apple M1 and M2 GPUs is, rather\nfamously, written in Rust, but it has achieved conformance with\nvarious graphics standards, which is also noteworthy.  At the X.Org Developers Conference\n(XDC)\u00a02024, Alyssa Rosenzweig gave an update on the status of the\ndriver, along with some news about the kinds of games it can support (YouTube video, slides).\nThere has been lots of progress since her talk at XDC last year (YouTube video),\nwith, of course, still more to come.\n\nIt is something of an XDC tradition, since she began it in Montreal in\u00a02019\n(YouTube video),\nfor Rosenzweig to give her presentations dressed like a witch.\nThis year's edition was no exception, though this time she started her talk in\nFrench, which resulted in some nervous chuckles from attendees. After a few\nsentences, she switched to English, \"I'm just kidding\", and\ncontinued with her talk.\n\nLast year at XDC, she and Asahi Lina reported that the driver had reached\nOpenGL ES\u00a03.1\nconformance.  "
  },
  {
    "title": "Physical Intelligence's first generalist robotic model (physicalintelligence.company)",
    "points": 114,
    "submitter": "lachyg",
    "submit_time": "2024-10-31T21:34:34 1730410474",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=42011770",
    "comments": [
      "At 2:54, it struggles to pick up the cloth for 10 seconds (100 seconds real-time).This may just be a software fix, but I wonder about the idea of exchanging tools for different tasks. In this case some kind of pincher-vacuum or roller-grip might have done the job better.\n \nreply",
      "Picking up cloth with a robot remains firmly in the \u201cunsolved hard problems\u201d bucket. Use that to gauge the believability of industry heads predicting the timeline of \u201crobots in every home\u201d.I\u2019m not even particular skilled at laundry but I can easily manipulate clothes in complex ways at speed. I can use a sudden flick to turn things inside out, or flat-fold a mattress cover.I suspect we\u2019re at least five years away from those rather ordinary capabilities in robots.\n \nreply",
      "I agree, five years is a decent estimate. But think how crazy that is! We're talking about capabilities that were firmly in the realm of far-off sci-fi three years ago. Capabilities that could revolutionize the market for all physical labor. Only five years away?\n \nreply",
      "I wonder at the long term vision for humanity. We have AI replacing a lot of art, writing, coding, etc. We have a bunch of robotics companies racing to replace physical human labor. Waymo and Tesla replacing drivers.What role do the majority of people realistically play in this world?\n \nreply",
      "My thoughts are a few:There is a lot of undone labor in the world. In developing countries the middle class has drivers, cooks, housekeepers. That\u2019s only possible due to inequality. With automation we can all get that.These people with tons of help by and large live fulfilled lives. You find fulfillment in family, friendships, and non necessary creation (art, research, etc); whatever makes you happy.But most of all, the Industrial Revolution made people think we\u2019d all be idle and nothing can be further from those predictions. Many more people, and many more jobs, and most of the world still lives in relative poverty and various forms of insecurity and unmet material and labor needs.Finally there are a lot of problems we have (thousands of health conditions, the environment, autocrats) that will prob take centuries to tackle even with ai, robotics, and being freed up from menial labor.\n \nreply",
      "As optimistic as your comment is, the fact that there are lots of problems does not mean that we will tackle them. In my opinion, if we don't aim at doing anything about it, the gap between the rich and the poor will widen. Both between societies, and within one society. I'm now in Canada, but in my childhood country, most of the recent \"smart\" (meaning connected) devices and the recent AI models are not available. This is starts a viscious cycle that makes things worse and worse. For the less connected high teck devices, the ratio of the price (That's set based on supply/demand in the richest countries) to income (that's damanged by sanctions and general government stupidity) is getting so high that it's really hard to get high-end devices.As the labour required to produce goods and services is automated, one possible scenario is that fewer and fewer people will stay \"relevant\", while the rest will sink and become invisible.Things can be avoided, but looking at countries that have been unable/unwilling to ensure housing (as one of the 3 most fundamental material needs of the human: food, housing, clothing) stays affordable, does not raise hope. In my opinion, the housing problem is extremely easy to solve when looking at the problem as a technical one, and impossible when you include the way economic incentives are working at it.I hope I'm wrong, but when I project the current path into future, it's not bright.\n \nreply",
      "Is our goal to reduce the gap between the rich and the poor, or to improve the lives of the poor? Because the gap itself is actually irrelevant to poor people's lives. Rich people's improvement outpacing poor people's is not necessarily an issue.Second, a financial gap does not necessarily translate to a material gap. Someone with 1,000,000x someone else's net worth still buys the same iPhone and drinks the same coca cola. Many important wellbeing factors are not actually blocked by finance, like healthcare and education. Even if you take all the rich people's money and repurpose to education not much will change. Maybe an iPad for every kid, but what good does that do?Housing is actually a great example. Real estate has a way of sucking up entire GDPs worth of money. As a country you can't pay your way out of housing problems. Look at something like China which has been consistently overbuilding housing for decades now. They still have housing issues.\n \nreply",
      "I share all your concerns. I considered mentioning them but figured I should keep my reply focused on idea of freeing people up isn\u2019t inherently bad.In particular zero sum resources like land ownership will be an increased challenge.And our governments have been slow to respond to things like climate change and we could be slow to respond here.\n \nreply",
      "No health problems if there's no people to have them.\n \nreply",
      "What roles did monks praying play in this World?What role do people in the Fashion industry(for ex.) play in this World?It's all a bunch of made up stories.We'll make up other stories.\n \nreply"
    ],
    "link": "https://www.physicalintelligence.company/blog/pi0?blog",
    "first_paragraph": "We are living through an AI revolution: the past decade witnessed practically useful AI assistants, AI systems that can generate photorealistic images and videos, and even models that can predict the structure of proteins. But in spite of all these advances, human intelligence dramatically outpaces AI when it comes to the physical world. To paraphrase Moravec\u2019s paradox, winning a game of chess or discovering a new drug represent \u201ceasy\u201d problems for AI to solve, but folding a shirt or cleaning up a table requires solving some of the most difficult engineering problems ever conceived. To build AI systems that have the kind of physically situated versatility that people possess, we need a new approach \u2014 we need to make AI systems embodied so that they can acquire physical intelligence.Over the past eight months, we\u2019ve developed a general-purpose robot foundation model that we call \u03c00 (pi-zero). We believe this is a first step toward our long-term goal of developing artificial physical int"
  },
  {
    "title": "Bayesian Yacht Sinking (nytimes.com)",
    "points": 55,
    "submitter": "rediguanayum",
    "submit_time": "2024-10-31T18:03:23 1730397803",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=42009570",
    "comments": [
      "Didn't bother to read the domain and didn't remember the boats name, so I didn't quite understand the title at first. Funnily, it immediately occurred to me, that it must be \"that boat\", but I half-expected to see some Alex Jones meets Eliezer Yudkowsky attempt to calculate how likely this stuff is to happen using Bayesian inference.\n \nreply",
      "In order to determine the likelihood that the yacht has sunk, we must first examine our priors.\n \nreply",
      "Seems like yachts are kind of like the private airline industry- when a super rich person can afford to request a bespoke design, safety requirements sometimes get eased. Plus less testing of the boat could be it. Pilots and captains for unique designs/mods might not have as much experience as commercial airlines: https://www.ctinsider.com/news/article/is-flying-private-mor... One example is the standardization of buttons in an airplane make it easier to know where to locate the important latches in an emergency.Also, it's possible some of these basic balancing and center-of-gravity considerations were already known over 500 years ago- it's when a novel feature gets prioritized that the fundamental stability of the design gets overlooked.\n \nreply",
      "> Also, it's possible some of these basic balancing and center-of-gravity considerations were already known over 500 years agoTo nitpick, properly being able to do these kinds of stability calculations are a considerably newer invention. E.g. the famous Vasa ship capsized in 1628 because at that time ships were still designed based on rules-of-thumb and the experience/intuition of the builders, with no stability calculations done.\n \nreply",
      "one of the quickest ways to ruin the way an established boat plan 'swims' is by adding a tall rig after de-masting.it's extremely enticing to 'add more sail' to a boat in order to squeeze more speed out of it, or achieve easier lufting.turns out that marine architecture is a lot harder than one thinks at first glance, and just about everyone that tries to tweak specs afterwards does so in such a way that makes the boat categorically worse.(don't ask me how I came to realize this after many dollars spent)\n \nreply",
      "Sounds like the old maxim around boat ownership still holds: \"the two best days in \nboat ownership are the day you buy it and the day you sell it\" :^)\n \nreply",
      "the joke is, \"the 2nd best day of your life is the day you buy your boat\" which makes the listener think \"2nd? oh, must be after your wedding/birth of child\"and then you say \"the 1st best day is when you sell it\"rug pull\n \nreply",
      "We used say boat stood for. Break out another thousand\n \nreply",
      "This is true in many things. Most car mods make the car objectively worse unless you really need the niche thing the mod does - and even if you think you do, be really sure.\n \nreply",
      "I'm a full-time RVer and see this all the time with diesel trucks. The trucks get \"deleted\" and modded for more power and to disable the DEF system. Almost everyone I've known throughout the years begins having transmission trouble within months, especially after heavy load. A few swear by it. I've got a very expensive Cummins and I'm hellbent to leave it stock (and under warranty).\n \nreply"
    ],
    "link": "https://www.nytimes.com/interactive/2024/10/31/world/europe/bayesian-yacht-sinking-italy.html",
    "first_paragraph": "The superyacht Bayesian the night before it sankThe superyacht Bayesianthe night before it sankThe superyacht Bayesianthe night before it sankThe superyacht Bayesian the night before it sankAt 237 feet tall, the mast wasone of the tallest in the world.At 237 feet tall, the mast wasone of the tallest in the world.At 237 feet tall,the mast was one of the tallest in the world.At 237 feet tall, the mast wasone of the tallest in the world.The Bayesian\u2019ssingle mastIts sister shipshave two mastsThe Bayesian\u2019ssingle mastIts sister shipshave two mastsThe Bayesian\u2019ssingle mastIts sister shipshave two mastsCurrent Bayesianusing a single mast.Its sister shipshave two mastsThe seas were calm when the Bayesian, the $40 million superyacht of the British tech mogul Michael Lynch, dropped anchor off Sicily.It was a celebratory voyage. But before dawn, a storm blew in.Lightning crackled. Winds neared hurricane strength. The sky dumped a blinding torrent. The yacht drifted out of control. Then it was gon"
  },
  {
    "title": "Hazel: A live functional programming environment featuring typed holes (hazel.org)",
    "points": 117,
    "submitter": "deepakkarki",
    "submit_time": "2024-10-31T06:57:35 1730357855",
    "num_comments": 27,
    "comments_url": "https://news.ycombinator.com/item?id=42004133",
    "comments": [
      "This is semi-related to one of the killer features of Eclipse that never really made it into any large-scale systems: the ability to run incomplete or broken code. The Eclipse Compiler for Java had a special feature that it could generate bytecode for nearly any file, including those that were utterly broken. It would mostly work, and you could incrementally work on unit tests alongside the code being developed.It was honestly one of the most productive environments I ever worked in, and I'm somewhat sad nobody else has implemented this.\n \nreply",
      "And then you have Go, which won't even let you compile code with an unused variable...\n \nreply",
      "Isn\u2019t this possible with any untyped language?It does sound like a good feature though - very few languages have opt-out type checking. This is much better than opt-in IMO.\n \nreply",
      "I have never heard about this before. What exactly would happen to broken code? For example, would it skip the equivalent of the broken source line, or would it stub out a function altogether or what?\n \nreply",
      "I only used that feature inadvertently a long, long time ago. As I remember, the program would throw a Throwable exception when it would enter code that wasn't translatable. There was some sort of hot reloading, too. So you could try to fix the code and continue.The really neat thing was that the Ecliose Java compiler is built specifically to support the IDE, so all the the warning and error annotations in the editor come from the actual compiler even while you are typing. There is no separate parser and linter just for the editor. I believe that the ability to translate broken source files on a best effort basis is actually an offshoot from that functionality.\n \nreply",
      "Literally that, it would throw exceptions with the compiler error. And as a sibling comment mentioned and I had forgotten -- it would allow for hotpatching code at runtime as you fixed compiler errors.You could literally start the skeleton of a webserver and gradually add functionality to it without recompiling and it would mostly \"just work\". Certain changes would require the app to be restarted.\n \nreply",
      "CRTL-SHIFT-F9 (IntelliJ) works for me on most Java and Kotlin code in IntelliJ, as long as no method/class signatures are changed.\n \nreply",
      "I use IntelliJ now and I definitely miss this feature of Eclipse.\n \nreply",
      "Why? What did you miss about it?I'm asking as I prefer strict compilers that force me to handle all cases.\n \nreply",
      "Generally, it's a very pragmatic thing like being able to quickly run something to make sure it's working but some other part of the code is temporarily broken because I'm currently changing things and don't care that that part is currently broken. In IntelliJ I have to stop doing what I'm currently thinking about and go over to that other part of the code and comment out some things or otherwise fix it up (usually in a way that won't be permanent because it's broken for a reason) before I can run the code I'm working on.In an ideal world, the codebase would be modular and testable and all those good things but I work in a large enterprise dev team and some of the codebase is many (many) years old and it's no longer feasible to refactor it into anything like what would be needed to allow the code to be modularized in such a way that would obviate the necessity to do the above.\n \nreply"
    ],
    "link": "https://hazel.org/",
    "first_paragraph": "\n          When programming, we spend a substantial amount of our time working with program text\n          that is not yet a formally complete program, e.g. because there are blank spots, type errors or merge\n          conflicts at various locations.\n        \n          Conventional programming language definitions assign no formal meaning to structures like these, so we are\n          left without live feedback about the behavior of even complete portions of the program.\n          Moreover, program editors and other tools have no choice but to resort to complex and ad hoc heuristics\n          to\n          provide various useful language services (like code completion, type inspection, and code navigation) without\n          gaps in service.\n        \n          We are developing a more principled approach to working with incomplete programs, rooted in (contextual modal\n          and gradual) type theory.\n          We model incomplete programs as programs with holes, which (1) stand for par"
  },
  {
    "title": "The carefulness knob (surfingcomplexity.blog)",
    "points": 102,
    "submitter": "azhenley",
    "submit_time": "2024-10-30T15:58:39 1730303919",
    "num_comments": 46,
    "comments_url": "https://news.ycombinator.com/item?id=41996608",
    "comments": [
      "So what does the graph look like from 1 to 5? Is zero defined? What does it mean?\n \nreply",
      "I\u2019ve been in this industry a long time. I\u2019ve read Lying with Statistics, and a bunch of Tufte. I don\u2019t think it would be too much hyperbole to say I\u2019ve spent almost a half a year of cumulative professional time (2-3 hours a month) arguing with people about bad graphs. And it\u2019s always about the same half dozen things or variants on them.The starting slope of the line in your carefulness graph has no slope. Which means you\u2019re basically telling X that we can turn carefulness to 6 with no real change in delivery date. Are you sure that\u2019s the message you\u2019re trying to send?Managers go through the five stages of grief every time they ask for a pony and you counteroffer with a donkey. And the charts often offer them a pony instead of a donkey. Doing the denial, anger and bargaining in a room full of people becomes toxic, over time. It\u2019s a self goal but bouncing it off the other team\u2019s head. Don\u2019t do that.\n \nreply",
      "> The starting slope of the line in your carefulness graph has no slope. Which means you\u2019re basically telling X that we can turn carefulness to 6 with no real change in delivery date.This strikes me as a pedantic argument, since the graph was clearly drawn by hand and is meant to illustrate an upward curving line. Now, maybe there's essentially no clear difference between 5 and 5.1, but when you extrapolate out to where 6 would be (about 65 pixels to the right of 5, if I can be pedantic for a moment), there actually is a difference.\n \nreply",
      "This is a conversation about human behavior, not pixels.A flat line will lead to bargaining, as I said. Don\u2019t paint yourself into uncomfortable conversations.If you don\u2019t want the wolf in the barn don\u2019t open the door.\n \nreply",
      "Doesn't the flat line in this context mean that you're at a local minimum, which is where you want to stay? Where being less careful would take more time due to increased number of incidents.\n \nreply",
      "If you can explain to me how you convince a nontechnical person why 6 is not free, I\u2019ll concede the point.But if not then my original thesis that this is needlessly asking for a pointless argument that costs social capital stands.\n \nreply",
      "Maybe we need to start with Zeno. Doing anything at all is relatively impossible.\n \nreply",
      "Maybe an excellent joke for the pre meeting.I don\u2019t think the boss will find it funny though.\n \nreply",
      "And I've done high school calculus. It's a picture of a parabola, the derivative is very small near the minimum, and it can look kinda flat if the picture isn't perfectly drawn.Principles of Product Development makes the point that a lot of real world tradeoffs in your development process are U-shaped curves, which implies that you will have very small costs for missing the optimum by a little. A single decision that you get wrong by a lot is likely to dominate those small misses.\n \nreply",
      "I guarantee you the boss in this scenario hated calculus or a skipped it.Also parabolas are algebra not calculus, but the same counter argument stands.\n \nreply"
    ],
    "link": "https://surfingcomplexity.blog/2024/10/29/the-carefulness-knob/",
    "first_paragraph": "Surfing ComplexityLorin Hochstein's ramblings about software, complex systems, and incidents.Dramatis personaeScene 1: A meeting room in an office. The walls are adorned with whiteboards with boxes and arrows.EM: So, do you think the team will be able to finish all of these features by end of the Q2?TL: Well, it might be a bit tight, but I think it should be possible, depending on where we set the carefulness knob.EM: What\u2019s the carefulness knob?TL: You know, the carefulness knob! This thing. TL leans over and picks a small box off of the floor and places it on the table. The box has a knob on it with numerical markings.EM: I\u2019ve never seen that before. I have no idea what it is.TL: As the team does development, we have to make decisions about how much effort to spend on testing, how closely to hew to explicitly documented processes, that sort of thing. EM: Wait, aren\u2019t you, like, careful all of the time? You\u2019re responsible professionals, aren\u2019t you? TL: Well, we try our best to allocat"
  },
  {
    "title": "Democratising publishing (onolan.org)",
    "points": 81,
    "submitter": "mxstbr",
    "submit_time": "2024-10-30T14:52:55 1730299975",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=41995615",
    "comments": [
      "I can't really comment too much on historical Wordpress politics\u2014given Matt's recent public meltdown I'm completely willing to believe that he's continued to shoot Wordpress in the foot in more obscure ways in the past\u2014but the posturing here vs. Wordpress really strikes me as someone who has gotten lucky and has attributed that luck to skill instead.What happens when Ghost gets popular enough to get their own \"G Engine\" competing with with Ghost (Pro)? As Wordpress.com shows, there's no serious moat for open source hosting. Either Ghost devotes resources away from their open core and towards their hosting platform, or they lose the competition for marketshare to a company that does devote those resources and then they have no funding stream, aside from what G Engine deigns to give them out of the grace of their own heart. And all of the platitudes about voting or board seats and everything else don't really make one lick of difference if you don't have any funding to make that happen, and you have to rely on pay-to-play funding from the people who are actually making money in the space, and let them set your agenda.So, Matt's behavior aside, I do think these issues are pretty endemic to the idea of \"open core\" funding as a company (or market) grows beyond a certain size. Unified non-profit or dual-corporation structure (Mozilla Corporation vs Mozilla Foundation) doesn't change the fundamental logic of \"where does the money come from?\". I don't think Ghost is providing any new solutions here\u2014they've just gotten lucky / been small enough to not be out-competed in their hosting niche yet.\n \nreply",
      "> I don't think Ghost is providing any new solutions here\u2014they've just gotten lucky / been small enough to not be out-competed in their hosting niche yet.While I agree with most of your comment, I do want to point out that intentionally targeting to be small/niche is a kinda solution in itself. To me SourceHut is another good example of how being small can be winning move. Being sustainable with <50 employees is far more manageable even if you face some competition, than if you have >1000 employees.\n \nreply",
      "Fair! In this case though I meant small in terms of adoption\u2014it looks like there are some alternative Ghost hosting providers, but none of them really have name-brand recognition in the same way Ghost does, and even Ghost is one small player in the \"non-Wordpress subscription blog / mailing list\" space. But a lot of my comment comes from watching the Redis / AWS Valkey split as well\u2014even if Redis stayed as a smaller team instead of trying to compete with the hyperscalers, they'd still be stuck in the same catch-22\u2014watching their revenue dwindle to zero while AWS and GCP competed on proprietary platform features.\n \nreply",
      "1) Many people or orgs who are aligned with Ghost and want it to succeed long-term will be okay with paying a bit more for hosting on Ghost(Pro); they might see the extra cost as paying for the continued existence and development of their publishing software.2) Not all foundations-behind-open-source-projects use revenues from hosting as their sole source of funding. Notable examples include the Blender Foundation and the Linux Foundation.\n \nreply",
      "Sure, I don't see where in my comment I imply this is a problem for all open source communities, just that it's a problem for the type of open source community John seems to want Ghost to be (no intellectual property, making revenue via providing services).For #1, that is the kind of logic that works fine for the early adopters, but frustrates and turns away the people who just want e.g. a Substack that won't squeeze them for login walls or a Wordpress that is easier to use. I've seen a lot of non-technical people in that bucket turned away recently by Ghost (Pro)'s opaque and confusing member-based hosting costs. It makes it completely impractical to run a free email newsletter, and plenty of other Ghost providers seem to have this worked out. So all it takes is one of those competitors breaking through to achieve name recognition and get a lucky roll of the marketing dice to overtake Ghost in revenue. And then they can fund their own fork and the Ghost community is forced to agree to their development wishes or become outpaced by their proprietary features. It's a pretty bad place to be in.\n \nreply",
      "> 1) Many people or orgs who are aligned with Ghost and want it to succeed long-term will be okay with paying a bit more for hosting on Ghost(Pro); they might see the extra cost as paying for the continued existence and development of their publishing software.Or the number of customers who would pay an $X premium to have \"Ghost(Pro)\" over another host (at the same features) will be roughly equal to the number of people who would spontaneously donate $X anyway. We have ample evidence that affection isn't enough to keep FOSS financed unless the developers are very visible and the ratio of developers to users is very low.\n \nreply",
      "Importantly, WordPress.com is not a predominant WP host! (Which is part of why Matt is lashing out, I think.) Yes, it hosts a huge number of small sites, many for free, but Automattic\u2019s revenue comes from a lot of products. (Including e-commerce and enterprise.) There are a large number of healthy WordPress hosts. https://w3techs.com/technologies/overview/web_hostingGetting outcompeted is less of a bad thing as you make it out to be. Ghost is clearly not trying to be the most popular option. They only need to make just enough to survive and pay everyone. That is way easier than trying to grow 30% YoY for a long time. Capitalists and founders talk about how if you\u2019re not growing, your product could be better because people could like it even more. Who gives a shit if profit isn\u2019t your MO?Literally all they have to do is avoid a scenario where no one wants to use them. If a competitor becomes the de facto choice and they start loosing customers, they can still make adjustments. That is a lot easier than trying to be a high-growth company.\n \nreply",
      "> the posturing here vs. Wordpress really strikes me as someone who has gotten lucky and has attributed that luck to skill instead.Twelve years is a long time to be 'lucky'\n \nreply",
      "What strikes me about Ghost's story is that if they hadn't failed to get in to YC[0], they probably would have failed for real, because eventually the VCs would have come calling and they're obviously not a unicorn.Instead, they have a successful organization providing a livelihood for almost 50 people, and real value to countless more.[0]: https://john.onolan.org/a-decade-after-being-rejected-by-yc/\n \nreply",
      "There are so many solid business ideas that take VC money, turn out not to be unicorn potential, and crash and burn, where a slower, sustainable growth might work just fine.Gumroad is a famous example.\n \nreply"
    ],
    "link": "https://john.onolan.org/democratising-publishing/",
    "first_paragraph": "Thoughts on open source governance and how to create trust within technology, communities, and media.Ghost is a distributed non-profit foundation which gives away all of its intellectual property under a permissive MIT license. The company has no investors and, in fact, no owners of any kind. I don't own any part of Ghost, and neither does my co-founder Hannah.We currently generate around $7.5M in annual revenue, and have been profitable and sustainable for the past 12 years.\"Wait, what?\"I'm glad you asked.Around 14 years ago I was a contributor to the WordPress core team, but a frustrated one.I had bought into the idea and the ideology of open source, but over time I'd become disenchanted by the office politics, drama, and conflicts of interest that constantly came to the forefront of conversations in the WP ecosystem.Having seen how things worked on the inside for several years, the conclusion I personally came to was that WordPress and Automattic were not truly about democratising p"
  },
  {
    "title": "RTP: One protocol to rule them all? (paper.wf)",
    "points": 62,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-28T18:06:31 1730138791",
    "num_comments": 32,
    "comments_url": "https://news.ycombinator.com/item?id=41974168",
    "comments": [
      "Kudos for creating this. However, as others have said, the HTTP/1.1 protocol is most of what is needed.I do think there is room for improvement though. Not in the conceptual or logical HTTP/1.1 protocol, but in the physical over-the-wire implementation. I'd like to see a version of HTTP/1.1 designed to work with CBORS as the main over-the-wire format, possibly including support for CBORS over COAP.\n \nreply",
      "Even if the three letter acronym space is a bit thin, perhaps best to avoid overloading the name of any one of the ten most used protocols out there?\n \nreply",
      "I set out to create a \"simpler HTTP\" once. Ended up concluding that by the time you've added the basic features, you need most of what a minimal HTTP request gives you. There might be some marginal gains to be made, but it's simply not worth it. HTTP is too good.Commenting on this proposal directly, I don't see how a stateful protocol could ever be simpler than a subset of HTTP/1.1 with range requests.\n \nreply",
      "This, HTTP/1.1 already is a simple protocol with the \u201cthings you will forget to add in the first version\u201d added.\n \nreply",
      "This is not trying to replace HTTP, it's an attempt at an alternative to \"HTTP for big blob downloads\". Likewise for the other protocols mentions.\n \nreply",
      "Does it add anything that HTTP can't do with range requests?I remember hearing that range requests are clunky to implement for HTTP (reverse) proxies, but otherwise they seem to do their job just fine?\n \nreply",
      "I'm guessing range requests are not problematic for proxies, just for caches (which are usually proxies also).A pure proxy (reverse or not) should have no problem with a range request.\n \nreply",
      "Ah yes, that's what I meant \u2013 problematic for caching proxies. Regular ones can of course just pass through the request.\n \nreply",
      "> all integers are little-endianThey really should be big-endian, because that\u2019s network byte order.IMHO it makes sense to use decimal-encoded ASCII digits instead and keep the protocol readable.  Nothing like \u2018telnet host.example 80\u2019 followed by \u2018GET / HTTP/1.0.\u2019> (1 bit) request_type: integer representing type of requestWith two types already defined.  No room for future extensions, then.  Is the idea to just use another protocol altogether if change is necessary?\n \nreply",
      "I love how the term \"endianness\" was picked straight from Gulliver's Travels. It's a very good fit - old wise computer wizards must've known how it's gonna be.\n \nreply"
    ],
    "link": "https://paper.wf/binarycat/rtp",
    "first_paragraph": ""
  },
  {
    "title": "Fuzzing between the lines in popular barcode software (trailofbits.com)",
    "points": 140,
    "submitter": "ingve",
    "submit_time": "2024-10-31T13:28:31 1730381311",
    "num_comments": 37,
    "comments_url": "https://news.ycombinator.com/item?id=42006698",
    "comments": [
      "> You might ask: how do you know whether or not software has been fuzzed?zbar has great barcode reading performance! I've seen far newer software that's nowhere near as good in terms of real-world performance.But it seems the original developer hasn't updated it since 2009 [1] - and fuzz testing only rose to prominence in ~2012 with the rise of tools like afl-fuzz.I would be absolutely astonished if it had ever been fuzzed.> Cut out any unnecessary features to limit attack vectors. ZBar by default scans all code types, which means that an attacker can trigger a bug in any of the scanners. If you only need to scan QR codes for instance, then ZBar can be configured to do so in the codeAbsolutely sensible, yes.Not just for security, but also because packages sometimes have extra barcodes. If you're scanning an EAN-13 on a pack of pasta, decoding a QR code for a pasta recipe website is just going to confuse things :)[1] https://sourceforge.net/projects/zbar/files/zbar/\n \nreply",
      "I've seen the \"overzealous barcode scanner\" issue happen with some gas station POS systems, to the point where the seasoned cashiers know to cover the QR codes with their fingers before attempting to scan an item.\n \nreply",
      "Sounds like the POS software isn't controlling the reader well, maybe because it wasn't adjusted for this model of reader.  Or the reader's firmware could have been misconfigured, from what it's supposed to be for that POS setup.The modern reader firmware tend to have multiple modes and many options.  Some modes are as simple as \"scan whatever you see out of the many formats you support, and spit out the decoded value of something as USB Serial\".  Or, worse, \"...as USB Keyboard\".You can imagine how easy those modes are to integrate with POS software, without implementing the proprietary protocol for that device, and you can also imagine how poorly that can work out.If you owned a store with a POS setup with flaky reader behavior like this, and were stuck with it, you could try reconfiguring the reader (to, say, disable QR support).  This reprogramming can sometimes be done via documented protocol, via sketchy Windows software, or via... barcode...  Careful you don't make it worse.(Our startup used modern readers (multiple 1D formats, QR, NFC) for a factory station, and had to do a lot of experimenting with different brands and models, to get the behavior and speed we needed.  We even managed to brick a reader, just with configuration changes, not flashing firmware.)\n \nreply",
      "I went to a meeting the other day in a building with a touch screen registration system.  The woman in front of me was struggling with it.  Every time she tapped the register button the system decided that some part of her was a badly formed barcode, printed an error message and exited back to the menu.  She eventually got it working by moving to the side until it wanted to take her picture.\n \nreply",
      "Absolutely. I helped with a physical inventory count project using smartphones as the \"terminals\". The barcode app we didn't allow us to selectively turn off symbologies. We ended up with a ton of links to recipes, websites, etc in the data.\n \nreply",
      "Reminds me of the Jurassic Park novel where they ask the computer to find 10 velociraptors on the island and it finds 10. And they actually have 20.\n \nreply",
      "They can run the whole park with minimal staff for up to 3 days. You think that kind of automation is easy? Or cheap?\n \nreply",
      "Can you really blame the computer tho? That sounds more like a case a PEBCAC, if you ask me...\n \nreply",
      "More like bad requirements. The system knew how many dinosaurs of each species had been released into the park, and the inventory system was only supposed to figure out if any were missing. No sense in looking further than that, after all where should the additional dinosaurs come from.That was the main theme of the book. Everything was well designed with failsafes, but too many of the design assumptions turned out to be wrong. Expecting only the expected lead to many small mistakes that were harmless individually but together snowball into a disaster.\n \nreply",
      "It's also a common annoyance in grocery store apps.Kroger, for example, has an app that allows you to scan items to add them to a virtual cart as you shop and avoid scanning them at the register... however the same app is used to read QR codes on in-store coupons, which are \"helpfully\" placed very close to the price tags with UPC barcodes on them.If I want to scan one of those coupon QR codes, I need to either start with the camera very close to the QR code or cover the barcode with my finger.\n \nreply"
    ],
    "link": "https://blog.trailofbits.com/2024/10/31/fuzzing-between-the-lines-in-popular-barcode-software/",
    "first_paragraph": "By Artur CyganFuzzing\u2014one of the most successful techniques for finding security bugs, consistently featured in articles and industry conferences\u2014has become so popular that you may think most important software has already been extensively fuzzed. But that\u2019s not always the case. In this blog post, we show how we fuzzed the ZBar barcode scanning library and why, despite our limited time budget, we found serious bugs: an out-of-bounds stack buffer write that can lead to arbitrary code execution with a malicious barcode, and a memory leak that can be used to perform a denial-of-service attack.ZBar is an open-source library for reading barcodes written in C. It supports an impressive number of barcode formats, including QR codes. One of our clients used it, so we wanted to quickly assess its security. Given the extensive amount of code, manual review was not an option. Since we noticed no public mention of fuzzing, we decided to give it a shot.You might ask: how do you know whether or not "
  },
  {
    "title": "Sets, types and type checking (kaleidawave.github.io)",
    "points": 48,
    "submitter": "kaleidawave",
    "submit_time": "2024-10-30T18:53:50 1730314430",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=41998838",
    "comments": [
      "I don\u2019t think it is appropriate to say Rust has \u2018union types\u2019. Rust has sum types, implemented as Enums and (unsafe) Union types. There is a distinct difference between sum types and union types from a type theoretic perspective.\n \nreply",
      "`never` is better known as `bottom`. `noreturn` in some languages is the same thing`any`, however, is not `top`, it is `break_the_type_system`. The top type in TS is `unknown`.\n \nreply",
      "Adding the unknown type was such a big deal. I love it.\n \nreply",
      "> Like sets, types can be by description have an infinite number of distinct entriesI think they might have meant \"entities\" instead of \"entries?\"The term \"diagonal identity\" seems to be non-standard as well?\n \nreply",
      "I usually say items or members, but entries basically means the same thing, and js set objects have an entries method, so there is precedence.\n \nreply"
    ],
    "link": "https://kaleidawave.github.io/posts/sets-types-and-type-checking/",
    "first_paragraph": "In the process of building a type-checker I have learnt a lot of the details about the theory of types and sets. With all this information I thought I would unpack all the details I have encountered along the way.This first part of this post explains why type-checking exists and what the abstraction of types enables. After some justification for type-theory, we delve deep into what types are and details on the common constructions. In the finale we will put the definitions to work and explain the implementation of type checking including operations on types.While not many people are building type checkers, a background of the implementation can help with being more effective when using (or dealing) with a type checker.I have a few upcoming posts on more advanced and niche type features. So I thought I would put together this post that lays the foundations so that I can refer to it the more advanced things. It has been quite fun recapping on some of the parts I have built along the way."
  },
  {
    "title": "Launch HN: Patched (YC S24) \u2013 AI workflows for post-code tasks",
    "points": 50,
    "submitter": "rohansood15",
    "submit_time": "2024-10-31T17:27:41 1730395661",
    "num_comments": 18,
    "comments_url": "https://news.ycombinator.com/item?id=42009089",
    "comments": [
      "Congrats on the launch; the idea and process is a good one, but the results so far are less impressive.For a simple PoC typescript CLI tool I had, AutoFix decided to do this several times:https://i.postimg.cc/1z4Fs663/Screenshot-2024-10-31-at-21-37...In a straight forwards repo with no README it created a reasonable starting point.Yet in a more complex repo with an existing and comprehensive README, it decides to replace it completely with a simple one, removing key insights. I suspect the existing README isn't considered at all, making this kind of patch incompatible with most workflows (i.e. creating a README once isn't particularly onerous, keeping it up to date is).This may be a project to watch, but I'm disinclined to use it at the moment.\n \nreply",
      "Thanks for trying - and for the fair feedback! We'll look at the AutoFix result and improve it.Our goal with the default patchflows is to provide a starting point/template and let you tailor it to your needs from there. E.g. with the 'Generate README' workflow, you can add the 'Read File' step to read the existing file and pass it to the context to update it rather than generate a new one from scratch.\n \nreply",
      "Certainly agree about the bottleneck around DevSecOps. I wonder if this might be useful for the typical \"scan everything, patch everything, SBOM for everything\" loop that typically lands on DevOps teams and becomes a classic devops tug-of-war situation.I'll be trying the free-tier to accomplish this on a hobby project at some point soon, will try to provide feedback! Proof of patching, SBOM, compliance stuff is IMO one of the best moats existing companies have against newcomers - developers typically _hate_ security patching work - so there's money in that use-case for sure!Oh, edit: Congrats on the launch!\n \nreply",
      "We think this does reduce DevSecOps friction - even simple things like passing scan results through an LLM to eliminate obvious false positives have an outsized impact.Thanks for giving it a shot - look forward to hearing your feedback!\n \nreply",
      "Congrats on the launch! One piece of feedback - I find the tagline confusing. I had no idea what \"post-code tasks\" meant until I clicked around and saw a few examples.\n \nreply",
      "That\u2019s funny because I knew exactly what it meant.  And I think that it\u2019s a clever way to differentiate what they do.\n \nreply",
      "We have tired a few different ways to convey what we do but it is hard. We want to refer to all software development activities that happen after the developer commits the code into a source control system. \u201cPost-code\u201d seemed a good way to capture that.\n \nreply",
      "I thought \"post-code\" was referring to an era when we don't code anymore, because AI does it all. Made my heart jump a bit.\n \nreply",
      "Sorry to give you that scare - Happy Halloween I guess? ;)\n \nreply",
      "still not sure what the value add is here\n \nreply"
    ],
    "link": "item?id=42009089",
    "first_paragraph": ""
  },
  {
    "title": "The National EUV Accelerator comes to Albany (ibm.com)",
    "points": 27,
    "submitter": "sandwichsphinx",
    "submit_time": "2024-10-31T19:37:54 1730403474",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=42010653",
    "comments": [
      "According to the Oregonian, Intel and Oregon were hoping to land this center.https://www.oregonlive.com/silicon-forest/2024/10/biden-admi...\n \nreply",
      "What\u2019s the status of IBM these days? They are treated like an obsolete dinosaur in my tech circles, but they\u2019re so big that I wouldn\u2019t be surprised to learn that they are actually cutting edge in some areas (particularly in capital intensive stuff)\n \nreply",
      "IBM has a track record of pursuing highly visible projects, like chip fabs,  PowerPC, Watson etc. and then just seemingly wimping out.\n \nreply",
      "Their semiconductor IP division has been cutting edge for decades (particularly before TSMC got copper working).They kind of act like a bridge between academia and industry, helping to develop academic ideas into something that's viable for high volume manufacturing.\n \nreply",
      "They are low key going wild on AI Agents\n \nreply",
      "I can't speak to most of what they do, but they seem to be at the forefront of quantum computing.\n \nreply",
      "They placed all their bets on enterprise cloud + Quantum.\n \nreply",
      "Azure and AWS?\n \nreply",
      "Well they certainly aren't the biggest but their cloud operation is still pretty large and somewhat nice. Noone is even close to IBM in Quantum cloud offerings.IBM q2 revenue- 16bb\nAWS q2 revenue- 26bb\nAzure q2 revenue 24bbI really don't understand why people say IBM is dying, its literally one of the most successful and revenue producing companies in the world with plenty of room for growth with their investments in Quantum. The just don't provide as many consumer facing products so everyone assume's they're dead.\n \nreply",
      "I personally don\u2019t know much about quantum or IBM. How relevant are they today? Are they going to become more relevant tomorrow?\n \nreply"
    ],
    "link": "https://research.ibm.com/blog/euv-center-albany-nstc",
    "first_paragraph": "The U.S. Department of Commerce announced that NY CREATES\u2019s Albany NanoTech Complex, where IBM is a key partner, will house the NSTC EUV Accelerator, a key facility that will help secure leading-edge semiconductor research, development, and manufacturing in North America.IBM Research has already shown the first working proof point using High NA EUV lithography. Read more about our latest breakthrough on the pathway to sub-2 nm nodes here.The U.S. Department of Commerce announced that NY CREATES\u2019s Albany NanoTech Complex, where IBM is a key partner, will house the NSTC EUV Accelerator, a key facility that will help secure leading-edge semiconductor research, development, and manufacturing in North America.Every industry, every supply chain, every vehicle, even our schools, cannot function without computers. Semiconductor chips are the heart of computing that enables the modern world. Over the last few decades, semiconductor manufacturing supply chain has become increasingly unbalanced a"
  },
  {
    "title": "The Economy Is Going Great, Except for the Housing Market (investopedia.com)",
    "points": 20,
    "submitter": "petethomas",
    "submit_time": "2024-11-01T00:16:23 1730420183",
    "num_comments": 13,
    "comments_url": "https://news.ycombinator.com/item?id=42012856",
    "comments": [
      "The 2017 tax act had an obfuscated impact on corporate ownership of houses. Capping the personal SALT  deduction while simultaneously lowering the corporate tax rate made local tax policies to increase local ownership ineffective.\n \nreply",
      "Could you explain ?\n \nreply",
      "Encouraging as many voters as possible to own homes was one of the worst mistakes of all time in the us/canada\n \nreply",
      "That's not really surprising, considering that's exactly how interest rate increases are supposed to work. They crowd out a bit of business investment and a lot of housing investment [1]. This in turn cools the economy by curtailing construction.Unfortunately, housing in most areas was screwed to begin with. This was not nearly the case with prior inflation bouts that required rate increases. The Fed was left with two bad choices. It did what it had to do.If the economy was Windows XP, housing would be its networking stack - its most exploitable sector. This is largely because of local governance and regulatory capture [2]. Housing has been artificially undersupplied for 5 decades under a variety of pretexts, such as architectural integrity. It has effectively turned the sector into a pyramid scheme that captures the wages of renters.[1] https://archive.is/8wAry (from https://www.nytimes.com/2022/04/19/opinion/inflation-interes...)[2] https://en.wikipedia.org/wiki/Regulatory_capture\n \nreply",
      "Any way you look at it, the government has to kick existing owners in the teeth to fix this crisis. Housing prices need to return to a reasonable multiple of wages, and that can only be done with supply. Everyone is going to have to get over the idea that they are \"building wealth\" and \"getting ahead\" by merely owning a box.\n \nreply",
      "Increasing supply in population centers also raises demand. Think about why it's in demand in the first place: it's because there is high density (and more opportunities).\n \nreply",
      "> kick existing owners in the teeth to fix this crisisYou're assuming a definition of \"crisis\". 2/3 of households own their own homes, and a big chunk of those that don't aren't looking to buy in any circumstances. As much as we hear about the high cost of housing, it's only an issue for an extremely vocal minority. That's not to say I don't view it as a problem (clearly it is) but I'm skeptical it's going to win any political battles.\n \nreply",
      "The majority of voters are homeowners so that\u2019s probably why it isn\u2019t going to happen so dramatically.\n \nreply",
      "Regular homeowners aren't benefiting much from high house prices. If they sell they just have to buy another, so it's a wash. If they borrow against it, they have to repay at currently high interest rates.\n \nreply",
      "But is it going to happen? In the next 10 to 20 years that I personally care about? And it\u2019s not just supply, the housing market is rigged in various ways.\n \nreply"
    ],
    "link": "https://www.investopedia.com/the-economy-is-going-great-except-for-one-huge-problem-8737911",
    "first_paragraph": "Jenny Dettrick / Getty Images Amid a recent spate of data showing the economy humming along smoothly, one sector has consistently stayed out of whack and it\u2019s a big one: housing.On Thursday, a report from the Bureau of Economic Analysis showed rising housing costs have helped core inflation run higher than the Federal Reserve\u2019s target 2% annual rate. A drop-off in homebuilding in the third quarter was a drag on the economy\u2019s overall growth rate, according to a report from the bureau on the Gross Domestic Product Wednesday. Earlier in the month, data showed homebuilding languished and sales of existing houses skidded to their lowest in more than a decade in September.The beleaguered\u00a0housing market is a stark contrast to other important pillars of the economy, which are running relatively smoothly: the job market is holding on to an extended winning streak, consumers are spending freely, and inflation is falling.\n At the heart of the problem is the fact that high prices and high mortgage"
  },
  {
    "title": "NandGame \u2013 Build a computer from scratch (nandgame.com)",
    "points": 131,
    "submitter": "OuterVale",
    "submit_time": "2024-10-30T20:27:12 1730320032",
    "num_comments": 24,
    "comments_url": "https://news.ycombinator.com/item?id=41999852",
    "comments": [
      "Love the game, and it inspired me to get a small FPGA dev board and make my own instruction set and soft-CPU for it. Not very practical, but a fun exercise.I got an iCE40 board[1] as the open-source story was decent and price was low. There might be better options now.[1]: https://www.digikey.com/en/products/detail/lattice-semicondu...\n \nreply",
      "Related:NandGame \u2013 Build a Computer from Scratch - https://news.ycombinator.com/item?id=36862274 - July 2023 (3 comments)NandGame \u2013 Build a Computer from Scratch - https://news.ycombinator.com/item?id=31055307 - April 2022 (14 comments)NandGame \u2013 Build a Computer from Scratch - https://news.ycombinator.com/item?id=25282507 - Dec 2020 (136 comments)Show HN: Online challenge: Build a CPU from scratch - https://news.ycombinator.com/item?id=17508151 - July 2018 (60 comments)\n \nreply",
      "Not sure how I missed this those other times, but I have read the book and implemented the computer before. It's a super fun exercise.\n \nreply",
      "Ugh, this just reminded me how far I've fallen.  I did EE in college (>20 years ago), specializing in computer architecture.  Never did anything with it professionally; I ended up in software.  I couldn't remember how to do any of these.  I managed to trial-and-error my way to the half-adder, at least.\n \nreply",
      "I get the reaction but I suggest that your previous work has set you up to make decisions \u201cin the right direction\u201d time and again.It\u2019s a bit like saying \u201cdarn I can never remember which Prime Minster passed the corn laws or the name of the guy who started refrigerated shipping in the USA.The point is if we have a grasp of the essential narrative (something like \u201cwars require engineering, agricultural revolution, Industrial Revolution, history is class warfare\u201d that background acts like a magnetic field for all the new pieces of information, aligning them correctly.Anyway, relax, be kinder to yourself.\n \nreply",
      "Thanks for that!  I think I wrote that comment a little more negative-sounding than it was in my head.  While I do lament skills I've lost and forgotten over the years, I know my EE background came in handy when writing software professionally for embedded and semi-embedded devices, earlier in my career.  These days I've moved on to distributed systems, so all that low-level knowledge isn't quite as useful as it once was.\n \nreply",
      "I did both this and the Nand2Tetris course before realizing that they are implementing the same computer -- this is an interactive graphical version, while the original Nand2Tetris uses a textual HDL where you write down the connections between logic gates as text, instead of clicking and dragging to indicate them.I found them both fun and educational, but I thought the NandGame was more fun. But it's good to know about the connections, for example because there are more follow-on exercises that you can do from Nand2Tetris (working with higher layers of computer software) after you complete the NandGame. Or you can just be aware that you can talk about the experience and the substance with people who have done the other version!\n \nreply",
      "I played a similar game called Turing Complete and really enjoyed it! https://store.steampowered.com/app/1444480/Turing_Complete/It's very similar to the Nand2Tetris book.\n \nreply",
      "Dropped 30 hours into Turing Complete before I realised what was happening to me. Upgraded the machine to 32 bit instructions and wrote documentation of my assembly language for it and everything.Fantastic game even in early release!\n \nreply",
      "Some food for thought:Once you complete this (ignoring the first level where you actually build a NAND gate) you essentially get very much what looks like a Neural Network (since it takes 2 neurons to represent a NAND gate), n layers deep, with a lot of zeros in the weight matrices, and some storage.Here is my question: given the input/output semantics at the assembly level, is it possible to train a blank neural network to look like this? Backprop obviously wouldn't work, but perhaps there is some form of directed search one could use?\n \nreply"
    ],
    "link": "https://www.nandgame.com",
    "first_paragraph": ""
  },
  {
    "title": "Antibody Drug Conjugates: A frontier in cancer treatment (sagelyhealth.com)",
    "points": 40,
    "submitter": "peerless-app",
    "submit_time": "2024-10-31T17:35:11 1730396111",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=42009196",
    "comments": [
      "> The Food and Drug Administration approves new cancer treatments when they are shown in clinical trials to be more effective than the current approved cancer treatment for a given cancer type. The approval comes when the treatment extends lifespan without overly increasing the risks of serious side effects.This standard just doesn\u2019t make sense to me. Every case is different, so why \u201cthrow out\u201d a treatment option for only being within the margin of error of efficacy on a general population? It must be incredibly frustrating for patients to know about these treatments\u2026\n \nreply",
      "It's fine to ask for an approval for a part of the population (e.g. people with cancer exhibiting particular markers).\n \nreply",
      "Every little step in fields like this is so encouraging. We keep getting better, but the cancers don't.Ever more effective cocktails of drugs that target the cancers while minimising harm to everywhere else, the closer we get to attacking cancer cells from so many different directions they simply can't adapt in time and we wipe it out immediately (a cure). One can only hope.I whether we might see even more investment into research like this as it gets closer to deliver curative, rather than just suppressive outcomes, as well\n \nreply",
      "CAR-T may have a ~50% cure rate for blood cancers:\nhttps://ashpublications.org/blood/article/141/19/2307/494672...\n \nreply",
      "> whether we might see even more investment into researchThe field would benefit greatly from even a fraction of the investment in the AI and crypto bubbles\n \nreply",
      "Cancer research is a massive, massive industry, with multi billions of grants on the line for every foundation and lab that cares to stick their fingers into it.The only thing that could ruin the cancer industry and dry up the firehose would be finding cures or reliable treatments that healed human beings, rather than making them sicker, impoverished, and/or un-alive. That would surely spoil everyone else's party.\n \nreply",
      "Pfizer acquired Seagen for $43 billion. Seagen has some very promising ADC\u2019s in the queue.https://www.pfizer.com/news/press-release/press-release-deta...\n \nreply"
    ],
    "link": "https://www.sagelyhealth.com/blog-posts/cancers-magic-bullet-antibody-drug-conjugates",
    "first_paragraph": "An exciting frontier in cancer treatment over 100 years in the making.Shortly after her 49th birthday, Alice was diagnosed with uveal melanoma.\u00a0Uveal melanoma is a cancer that develops in the middle layer of the eye. In Alice\u2019s case, a small (1 millimeter) tumor had formed in her eye and cells from that tumor had entered her bloodstream. By the time she was diagnosed, scans showed the melanoma cells had reached her spine and her liver.Alice\u2019s cancer was metastatic and she faced an uphill battle. Uveal melanoma is incredibly difficult to treat. Surgery is not an option once it has spread and standard chemotherapy offers limited benefit. Like many cancer patients, she had few effective options.Her doctor started her on a combination of immunotherapies, but after the second dose, the side effects were too much to tolerate and she had to stop. They then tried another combination of drugs, but the tumors continued to grow. They switched to another immunotherapy, but this too, was hard to to"
  },
  {
    "title": "Tyler-Style Font Maker (chromakopiafontgenerator.org)",
    "points": 14,
    "submitter": "garydai",
    "submit_time": "2024-10-28T08:02:44 1730102564",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=41968704",
    "comments": [
      "I was very confused by this headline.\n \nreply",
      "Haha. Well besides that, it\u2019s not really a font generator but an image generator\n \nreply"
    ],
    "link": "https://chromakopiafontgenerator.org/",
    "first_paragraph": ""
  },
  {
    "title": "Lichens in cemetaries and a scientist who studies them (atlasobscura.com)",
    "points": 25,
    "submitter": "diodorus",
    "submit_time": "2024-10-27T04:38:36 1730003916",
    "num_comments": 7,
    "comments_url": "https://news.ycombinator.com/item?id=41959897",
    "comments": [
      "The last paragraphs of this article are brilliant...> \u201cIt\u2019s not going to cure cancer, it\u2019s not going to bring world peace, two things that we desperately need right now,\u201d she says.\u201cBut I would argue that there is great value in understanding the world [and] how biodiversity works so that we can preserve it, which is an integral component of human health,\u201d says Pringle.She adds: \u201cIt\u2019s not clear to me that the best way to repair the world isn\u2019t sitting and watching lichens grow in a cemetery and telling the world about it.\u201d\n \nreply",
      "I always wondered what those are called. Interesting how in some way these live on the boundary between single- and multicellular organisms.\n \nreply",
      "There's a subculture of people who clean strangers' gravestones, which often involves removing lichen. They are very particular about the tools and chemicals used during the cleaning. Some also reset broken stones.You can see some before/after photos on Twitter (https://twitter.com/search?q=clean%20gravestones&src=typed_q...) as well as fast-motion videos on TikTok and Instagram. A few people research public records to share more information about the stones they are cleaning.\n \nreply",
      "For a second I read liches, and was puzzled that they existed.\n \nreply",
      "Semi-related, the Old English word for cemetery was \"licburg\": corpse-town. The lic- in that is the source of \"lich\".\n \nreply",
      "Me too, especially today!\n \nreply",
      "Original headline: A Cemetery\u2019s Immortal Residents and the Scientist Who Studies Them\n \nreply"
    ],
    "link": "https://www.atlasobscura.com/articles/immortal-lichen-growing-in-cemeteries",
    "first_paragraph": "\n                          Our small-group adventures are inspired by our Atlas of the world's most fascinating places, the stories behind them, and the people who bring them to life.\n                        \u201cCemeteries are full of life,\u201d says biologist Anne Pringle as she walks through the Forest Hill Cemetery in Madison, Wisconsin. It\u2019s a bright, early October day and sunlight filters through the still-green leaves, catching strands of spider silk spun over tombstone crosses. Speckled mushrooms stand sentry over the manicured grass as squirrels chatter overhead. But the form of life that brought Pringle here is subtler: Her work focuses on the green and rust-colored splotches growing on the headstones.These growths, called lichens, may help reveal biological rules governing life, death, aging, and even immortality. And because lichens tend to grow undisturbed on tombstones, graveyards make the perfect living laboratory.Despite an often moss-like appearance, lichens are complex living"
  },
  {
    "title": "Probability-generating functions (entropicthoughts.com)",
    "points": 181,
    "submitter": "todsacerdoti",
    "submit_time": "2024-10-31T09:36:18 1730367378",
    "num_comments": 40,
    "comments_url": "https://news.ycombinator.com/item?id=42004976",
    "comments": [
      "For those interested in looking slightly more into the characteristic function, it may be worth pointing out that the characteristic function is equal to the Fourier-transform (with the sign of the argument being reversed) of the probability distribution in question.In my own experience teaching teaching probability theory to physicists and engineers, establishing this connection is often a good way of helping people build intuition for why characteristic functions are so useful, why they crop up everywhere in probability theory, and why we can extract so much useful information about a distribution by looking at the characteristic function (since this group of students tends to already be rather familiar with Fourier-transforms).\n \nreply",
      "Yes, this provides good intuition about why it is useful: the PDF of the sum of two random variables is the convolution of the original PDFs. A convolution is awkward to work with, but by the convolution theorem it is a multiplication in the Fourier domain. This immediately suggests that the Fourier transform of a PDF would be a useful thing to work with.If you don't say that this is what you are doing then it all seems quite mysterious.\n \nreply",
      "> the PDF of the sum of two random variables is the convolution of the original PDFs(Probably obvious to everyone reading, but the variables should be independent.)\n \nreply",
      "But I'd rather assume the variables are independent and then blame statistics when I get the wrong answer!\n \nreply",
      "As a physicist, the moment when everything just clicked was when I realised that connected Feynman diagrams were basically the cumulants of that distribution. \nThen almost everything in physics is about \"what is the characteristic/moment/cumulant generating function?\" and associated Legendre transforms\n \nreply",
      "A little known bit of history is Feynman developed a diagrammatic method for expressing the moments of PGFs in his study of the stochastic theory of fission chains. This was before his work on QED. See:https://www.osti.gov/biblio/1775045\n \nreply",
      "> As a physicist, the moment when everything just clicked was when I realised that connected Feynman diagrams were basically the cumulants of that distribution.And the generating function of the cumulants is the logarithm of the generating function of the distribution (Fourier transform).\n \nreply",
      "I feel like it's almost criminal of textbook writers not to mention this when introducing the characteristic function...  At least as an aside or a footnote, for readers already familiar with Fourier transforms.\n \nreply",
      "I had not made that connection and find that incredibly useful. Thank you for pointing that out.\n \nreply",
      "but isn't a characteristic function just \"the\" way to bridge the gap between sets, functions, and logic(? ...a 3way bridge!?)I mean, it was useful for me to think about like a translation between sets and logic (this variable x is in the set xor not) into functions (a function f(x) that returns 1 or true whenever x is in set S)how the heck is that a fourier transform!??\n \nreply"
    ],
    "link": "https://entropicthoughts.com/probability-generating-functions",
    "first_paragraph": "\nI have long struggled with understanding what probability-generating functions\nare and how to intuit them. There were two pieces of the puzzle missing for me,\nand we\u2019ll go through both in this article.\n\nThere\u2019s no real reason for anyone other than me to care about this, but if\nyou\u2019ve ever heard the term pgf or characteristic function and you\u2019re curious\nwhat it\u2019s about, hop on for the ride!\n\nImagine you are holding five regular playing cards in your hand. Maybe your hand\nis QQA97, i.e. a pair of queens, an ace, a nine, and a seven. We\u2019re playing some\nsort of weird poker variant where I get to blindly draw one of your cards.\nWe\u2019re curious about the probability distribution of the outcome of that draw.\n\nIn words, most cards (e.g. 2, 4, 8, J and others) have a probability of zero of\nbeing drawn from your hand (because they are not in your hand.) Some cards (ace,\nseven, nine) have a 20\u00a0% probability of being drawn, and then there\u2019s a 40\u00a0%\nprobability that a queen is drawn, since you have t"
  },
  {
    "title": "Tell HN: Robots.txt pitfalls \u2013 what I learned the hard way",
    "points": 64,
    "submitter": "pyeri",
    "submit_time": "2024-10-27T05:09:23 1730005763",
    "num_comments": 20,
    "comments_url": "https://news.ycombinator.com/item?id=41960003",
    "comments": [
      "> there's typically a 5-7 day gap between updating the robots.txt file and crawlers processing itYou could try moving your favicon to another dir, or root dir, for the time being, and update your HTML to match. That way it would be allowed according to the version that Google still has cached. Also, I think browsers look for a favicon at /favicon.ico regardless, so it might be worth making a copy there too.\n \nreply",
      "/favicon.ico is the default and it will be loaded if your page does not specify a different path in the metadata but in my experience most clients respect the metadata and won't try to fetch the default path until after the <head> section of the page loads for HTML content.But non-HTML content has no choice but to use the default so it's generally a good idea to make sure the default path resolves.\n \nreply",
      "Thanks for sharing, I wasn\u2019t knowing that browsers look for a favicon at /favicon.ico. Thanks again.\n \nreply",
      "USE X-Robots-Tag: noindex to prevent files being indexed and let google determine how they crawl your site for themselves.A nightmare scenario can result, otherwise, where you have content indexed but don't allow googlebot to crawl it. This does not end well.https://developers.google.com/search/docs/crawling-indexing/...\n \nreply",
      "I\u2019ve got two questions:1. What does it look like for a page to be indexed when googlebot is not allowed to crawl it? What is shown in search results (since googlebot has not seen its content)?2. The linked page says to avoid Disallow in robots.txt and to rely on the noindex tag. But how can I prevent googlebot from crawling all user profiles to avoid database hits, bandwidth, etc. without an entry in robots.txt? With noindex, googlebot must visit each user profile page to see that it is not supposed to be indexed.\n \nreply",
      "https://developers.google.com/search/docs/crawling-indexing/...   \"Important: For the noindex rule to be effective, the page or resource must not be blocked by a robots.txt file, and it has to be otherwise accessible to the crawler. If the page is blocked by a robots.txt file or the crawler can't access the page, the crawler will never see the noindex rule, and the page can still appear in search results, for example if other pages link to it.\"\n\nIt's counterintuitive but if you want a page to never appear on Google search, you need to flag it as noindex, and not block it via robots.txt.> 1. What does it look like for a page to be indexed when googlebot is not allowed to crawl it? What is shown in search results (since googlebot has not seen its content)?It'll usually list the URL with a description like \"No information is available for this page\". This can happen for example if the page has a lot of backlinks, it's blocked via robots.txt, and it's missing the noindex flag.\n \nreply",
      "It's good information but...1. Why is your favicon in the uploads directory? Usually, those would be at the root of your site or in an image directory?2. Why is there an uploads directory for a static site hosted on GitHub? I don't believe that is useful on GitHub, is it? You cannot have visitors upload files to it, right?\n \nreply",
      "Speaking for myself:1. I want nginx to serve static files, and everything else to be reverse proxied to the webapp2. The configuration file that allows /favicon.ico (and others) to be a file but / and other paths to be passed to the webapp is kind of ugly.  Here's mine:    location ~* ^/(favicon.ico|apple-touch-icon.png)$ {\n        root $icons_path;\n    }\n\nIn my own case I've so far decided to accept the ugly config file, but as you can see, I haven't gotten around to adding even a robots.txt or any of the other files the modern web ecosystem expects; and adding them involves adding them one-by-one.  I can see why someone would say, \"Why make an ugly hack of an nginx config, when I can just define the favicon location in the metadata to a path easily configured to be files-only?\"\n \nreply",
      "How big is your site? Crawl budget is likely only relevant for huge sites, not personal blogs.\n \nreply",
      "Exactly - this SEOveroptimisation\n \nreply"
    ],
    "link": "item?id=41960003",
    "first_paragraph": ""
  },
  {
    "title": "Activeloop (YC S18) seeks Python back end engineers to build a database for AI (ycombinator.com)",
    "points": 0,
    "submitter": "",
    "submit_time": "2024-10-31T17:01:30 1730394090",
    "num_comments": 0,
    "comments_url": "",
    "comments": [
      "xxx"
    ],
    "link": "https://www.ycombinator.com/companies/activeloop/jobs/kCU6ZNq-python-backend-engineer",
    "first_paragraph": ""
  }
]