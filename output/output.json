[
  {
    "title": "High-performance 2D graphics rendering on the CPU using sparse strips [pdf] (github.com/laurenzv)",
    "points": 120,
    "submitter": "PaulHoule",
    "submit_time": "2025-11-10T22:05:16 1762812316",
    "num_comments": 15,
    "comments_url": "https://news.ycombinator.com/item?id=45881568",
    "comments": [
      "The paper defines this structure    struct Strip {\n        x: u16,\n        y: u16,\n        alpha_idx_fill_gap: u32,\n    }\n\nwhich looks like it is 64 bits (8 bytes) in size,and then says> Since a single strip has a memory footprint of 64 bytes and a single alpha value is stored as u8, the necessary storage amounts to around 259 \u2217 64 + 7296 \u2248 24KBam I missing something, or is it actually 259*8 + 7296 \u2248 9KB?reply",
      "Also checkout blaze: https://gasiulis.name/parallel-rasterization-on-cpu/reply",
      "Thanks for the pointer, we were not actually aware of this, and the claimed benchmark numbers look really impressive.reply",
      "the demo is astonishingreply",
      "Fascinating project. Based on section 3.9, it seems the output is in the form of a bitmap. So I assume you have to do a full memory copy to the GPU to display the image in the end. With skia moving to WebGPU[0] and with WebGPU supporting compute shaders, I feel that 2D graphics is slowly becoming a solved problem in terms of portability and performance. Of course there are cases where you would a want a CPU renderer. Interestingly the web is sort of one of them because you have to compile shaders at runtime on page load. I wonder if it could make sense in theory to have multiple stages to this, sort of like how JS JITs work, were you would start with a CPU renderer while the GPU compiles its shaders. Another benefit, as the author mentions, is binary size. WebGPU (via dawn at least) is rather large.[0] https://blog.chromium.org/2025/07/introducing-skia-graphite-...reply",
      "The output of this renderer is a bitmap, so you have to do an upload to GPU if that's what your environment is. As part of the larger work, we also have Vello Hybrid which does the geometry on CPU but the pixel painting on GPU.We have definitely thought about having the CPU renderer while the shaders are being compiled (shader compilation is a problem) but haven't implemented it.reply",
      "In any interactive environment you have to upload to the GPU on each frame to output to a display, right? Or maybe integrated SoCs can skip that? Of course you only need to upload the dirty rects, but in the worst case the full image.>geometry on CPU but the pixel painting on GPUWow. Is this akin to running just the vertex shader on the CPU?reply",
      "It's analogous, but vertex shaders are just triangles, and in 2D graphics you have a lot of other stuff going on.The actual process of fine rasterization happens in quads, so there's a simple vertex shader that runs on GPU, sampling from the geometry buffers that are produced on CPU and uploaded.reply",
      "One place where a CPU renderer is particularly useful is in test runners (where the output of the test is a image/screenshot). Or I guess any other use cases where the output is an image. In that case, the output never needs to get to the GPU, and indeed if you render on the GPU then you have to copy the image back!reply",
      "This looks interesting; recently I wrote some code for rendering high precision N-body paths with millions of vertices[0], I wonder if a GPU implementation this RLE representation would work well and maintain simplicity.[0] https://www.youtube.com/watch?v=rmyA9AE3hzMreply"
    ],
    "link": "https://github.com/LaurenzV/master-thesis/blob/main/main.pdf",
    "first_paragraph": ""
  },
  {
    "title": "Two 20-somethings are building America's FPV drone war machine (dronexl.co)",
    "points": 17,
    "submitter": "asix66",
    "submit_time": "2025-11-11T00:48:40 1762822120",
    "num_comments": 12,
    "comments_url": "https://news.ycombinator.com/item?id=45882818",
    "comments": [
      "This was particularly interesting in regards to the US military not being at the bleeding edge:The trip underscored what they already knew: America was vulnerable. Russia and China produced millions of drones annually, while the United States barely made 100,000.It almost feels as if the US need(s|ed) to be a bit more involved in the Ukraine war in order to keep their finger on the pulse of how conflicts are evolving, especially in regards to Russia's capabilities (and vulnerabilities).Related:Monroe-Anderson didn\u2019t just read about Ukraine\u2019s drone revolution\u2014he flew to Kyiv to learn from it. That\u2019s the critical insight here: battlefield necessity drove innovation cycles that lapped Western procurement systems entirely. Ukrainian operators testing drones under live fire generated iterative feedback loops traditional defense contractors couldn\u2019t match.reply",
      "I found this one interesting:> \u201cVendors in the United States would laugh at us,\u201d Hichwa said. American-made radios could cost $10,000 when he needed something for $30. The founders realized they\u2019d have to build components themselves and seek suppliers outside the defense industry. Instead of using computer chips common in military equipment that cost hundreds of dollars, Neros used chips designed for parking meters at $1 each.By the time your certification process represents 99.7%+ of your total costs, there's a chance it's hurting you more than it's helping.reply",
      "Counterpoint, the US has better other systems. Such as the 1st,2nd,3rd largest air forces in the world.Lots of Ukrainian commanders would happily trade FPV drones with grenades attached for mortar teams with lots of ammo and effective aircover.Modern militaries need drones, but the swarms that everyone gushes over aren't that effective when a 1000 pound gorilla like the US Army turns up to play.reply",
      "This is exactly correct.It's the same reason why US military doctrine worries very little about jamming.If something is jamming, the tactical response is to destroy the jammer.If someone is drone attacking you, the tactical response is to destroy the drone launches.reply",
      "A swarm of dirt cheap drones flying through the jet engines of a 10,000,000 dollar gorilla is an asymmetric answer.reply",
      "> The Archer Strike platforms integrate with Kraken Kinetics Terminus strike payloadsNo relation!reply",
      "I just can\u2019t read AI articles anymorereply",
      "Good catch. This one's plagiarized, too: the original is a NYT article[0], and you can diff the text yourselves to see what AI did to it.I'm emailing the mods to fix this.https://www.nytimes.com/2025/11/10/business/neros-military-d...reply",
      "I pay attention to what my former country is doing to Ukraine and it is really bad. America's warfighting with drones is very clearly unprepared to what's currently on the cutting edge. Ukraine's strike on strategic aviation with drones transported via trucks to the edge of airports can very easily happen here, given the size of the country, relative ease of access to air force bases and ubiquitous trucks everywhere. I worry that only when that happens will there be meaningful impetus to do something. Until then the current idiots will continue to occupy themselves with owning the libs and beard size regulations.reply"
    ],
    "link": "https://dronexl.co/2025/11/10/teenage-drone-racers-defense-contractors/",
    "first_paragraph": ""
  },
  {
    "title": "Unexpected things that are people (bengoldhaber.substack.com)",
    "points": 440,
    "submitter": "lindowe",
    "submit_time": "2025-11-10T16:05:46 1762790746",
    "num_comments": 216,
    "comments_url": "https://news.ycombinator.com/item?id=45877257",
    "comments": [
      "Wouldn't personal property in the US fall under the same criteria, in the sense that the government can sue the property itself (civil forfeiture)?But I think the boring answer here is that we sometimes need legal abstractions. If they don't exist, Microsoft is no longer a distinct entity; it's 200,000 people who for some reason talk to each other, and you can't really audit their finances, punish them collectively, or set any ground rules that apply specifically to their joint activities.This obviously has negative externalities, because while a corporation is easy to fine, it's hard to put in prison... but trying to approach it differently would be about as fun as modeling a CPU as a bunch of transistors.reply",
      "> while a corporation is easy to fine, it's hard to put in prison...IANAL, but I believe in at least some scenarios, officer(s) of U.S. corporations can go to jail if they are responsible for the directing the corporation to commit certain offending actions (despite not physically doing it themselves). To be clear, I'm not just talking about personal liability for fraud, insider trading, etc they may have committed themselves.A recent example might be when Adobe was fucking around repeatedly making it virtually impossible for users to cancel Creative Cloud subscriptions - despite having already agreed to do so. IIRC the Justice Department issued a warning if it wasn't fixed immediately, they'd prosecute the Executive Vice President responsible for the business unit. Their press release named the guy and emphasized the consequences for continued non-compliance could include that guy going to jail.reply",
      "Another pertinent example: (in the US) corporate officers are personally liable unpaid wages and can serve time for willfully neglecting to pay their workers.reply",
      "> But I think the boring answer here is that we sometimes need legal abstractions.Absolutely - the legal abstraction is that corporations are corporations, not people. The article went with a lighter hearted quip but here's my own tired old one:If corporations are people, then owning shares is unconstitutional as that would be a form of slavery.reply",
      "I don't understand this POV, can you explain what I'm missing?Usually when people say \"corporations aren't people\" I think they are confused about the need for an abstraction. But you acknowledged the need for an abstraction.I don't imagine you are confused about the status quo of the legal terminology? AFAIK, the current facts are: the legal term \"person\" encompasses \"natural person\" (ie the common meaning of \"person\") and \"legal person\" (ie the common usage of \"corporation\"). In legalese, owning shares of legal persons is not slavery; owning shares of natural persons is; owning shares of \"people\" is ambiguous.I don't imagine you are advocating for a change in legal terminology. It seems like it would be an outrageously painful find-and-replace in the largest codebase ever? And for what upside? It's like some non-programmer advocating to abandon the use of the word \"master\" in git, but literally a billion times worse.Are you are just gesturing at a broader political agenda about reducing corporate power? Or something else I am not picking up on?reply",
      "The  argument is that the need for abstraction doesn't mean we must reuse an existing concept. We should be able to talk about corporations as entities and talk about what laws or rights should apply, without needing to call them people.reply",
      "But the existing concept by and large has the properties we want. The ability to form contracts, to be held civilly or criminally liable for misconduct, to own property, etc. That we say something is a juridical person isn't some kind of moral claim that it's equivalent in importance to a human, it's just a legal classification.reply",
      "At least for me, the problem is that making them completely equivalent in a legal sense has undesirable outcomes, like Citizens United. Having distinct terms allows for creating distinct, but potential overlapping sets of laws/privileges/rights. Using the same term makes it much harder to argue for distinctions in key areas",
      "Well, then share buybacks are just the corporation reclaiming its freedom. Everything makes sense now...reply",
      "And if corporations aren\u2019t people, then the New York Times has no right to the First Amendment.reply"
    ],
    "link": "https://bengoldhaber.substack.com/p/unexpected-things-that-are-people",
    "first_paragraph": ""
  },
  {
    "title": "Writing your own BEAM (janiczek.cz)",
    "points": 145,
    "submitter": "cbzbc",
    "submit_time": "2025-11-09T18:29:43 1762712983",
    "num_comments": 31,
    "comments_url": "https://news.ycombinator.com/item?id=45867828",
    "comments": [
      "The BEAM is fascinating for many reasons, including being register-based.My only real complaint is the difficulty (or impossibility) of making the BEAM portable in the way the JVM is. The BEAM hooks into so many system libraries, that you must compile it on every flavor of linux instead of having a tarball that you can just unpack and use.You either must use your distro package manager's version, or compile from scratch. If you want to control the exact version that's being used across your team (via `asdf` or similar), this practically means you'll end up compiling the BEAM over and over...reply",
      "I have learnt to love and embrace the BEAM.Wikipedia says \"Originally BEAM was short for Bogdan's Erlang Abstract Machine, named after Bogumil \"Bogdan\" Hausman, who wrote the original version, but the name may also be referred to as Bj\u00f6rn's Erlang Abstract Machine, after Bj\u00f6rn Gustavsson, who wrote and maintains the current version.\"Whether the B is for Bogdan or Bjorn, there's something really fun and Space Quest-y about it.reply",
      "Now I'm curious whether Joe Armstrong's original Prolog implementation of the VM is available anywhere, but I doubt it.reply",
      "Maybe the post should explain what [a?] BEAM is, rather than invite the reader to go view a conference presentation recording.reply",
      "When can we be done with these cheap comments? It has really become tiring to have a comment tree on every HN post for people who don't know what the article is about. As the author often didn't submit their own article it is just a complaint with no possible resolution. Instead of taking a few seconds to find out what the article is about and maybe even clarifying it for your fellow readers, you are taking that time to write a comment that only detracts from a possible conversation.If you can't bring yourself to search for 5 seconds and find out what an article is about, maybe you just close it and move on.reply",
      "Agreed.The tone in which people like the parent comment is disgraceful. I\u2019m sorry this is hacker news and hackers know that BEAM is the Erlang VM, no introduction or explanation needed. It is respected and admired as a great piece of engineering to be studied by all hackers.reply",
      "I didn't know what it was, so I used the grand information retrieval device I was already sitting at to look it upreply",
      "I knew what the BEAM was, but in his defense, searching \"BEAM\" doesn't bring up anything relevant in the first few pages I looked at.reply",
      "Disgraceful?  It's a pretty polite request.> hackers know that BEAM is the Erlang VM, no introduction or explanation neededThis is some pretty intense gatekeeping, pal.reply",
      "The curse of knowledge in this thread is mind boggling.reply"
    ],
    "link": "https://martin.janiczek.cz/2025/11/09/writing-your-own-beam.html",
    "first_paragraph": "\n\n        2025-11-09\n      \nThis is my Code BEAM Europe 2025 talk, converted to a blogpost.EDIT 2025-11-10: Hacker News folks pointed out it might not be clear to everybody what BEAM is: it\u2019s the virtual machine for languages like Erlang, Elixir and Gleam. See Wikipedia.I was always fascinated with BEAM, how it allowed easy spawning of processes that didn\u2019t share state, allowed for sending and selectively receiving messages, and linking to each other thus enabling creation of supervision trees.It\u2019s an interesting set of primitives that interact in a nice way, and are in my view responsible for much of the appeal of BEAM languages. I wanted to see how much it takes to support these primitives, and I set out to write my own toy MVP implementation of BEAM.As a disclaimer, I haven\u2019t read The BEAM Book yet, and how I do things might differ substantially from how the real BEAM does things. This is an exploration from first principles based on how I perceive BEAM from the outside, and doesn\u2019t"
  },
  {
    "title": "Spatial intelligence is AI\u2019s next frontier (drfeifei.substack.com)",
    "points": 110,
    "submitter": "mkirchner",
    "submit_time": "2025-11-10T21:07:02 1762808822",
    "num_comments": 62,
    "comments_url": "https://news.ycombinator.com/item?id=45880939",
    "comments": [
      "From reading that, I'm not quite sure if they have anything figured out. \nI actually agree, but her notes are mostly fluff with no real info in there and I do wonder if they have anything figured out besides \"collect spatial data\" like imagenet.There are actually a lot of people trying to figure out spatial intelligence, but those groups are usually in neuroscience or computational neuroscience.\nHere is a summary paper I wrote discussing how the entorhinal cortex, grid cells,  and coordinate transformation may be the key: https://arxiv.org/abs/2210.12068  All animals are able to transform coordinates in real time to navigate their world and humans have the most coordinate representations of any known living animal. I believe human level intelligence is knowing when and how to transform these coordinate systems to extract useful information.\n I wrote this  before the huge LLM explosion and I still personally believe it is the path forward.reply",
      ">  Here is a summary paper I wrote discussing how the entorhinal cortex, grid cells, and coordinate transformation may be the key: https://arxiv.org/abs/2210.12068 All animals are able to transform coordinates in real time to navigate their world and humans have the most coordinate representations of any known living animal. I believe human level intelligence is knowing when and how to transform these coordinate systems to extract useful information.Yes, you and the Mosers who won the Nobel Prize all believe that grid cells are the key to animals understanding their position in the world.https://www.nobelprize.org/prizes/medicine/2014/press-releas...reply",
      "It's not enough by a long shot. Placement isn't related directly to vicarious trial and error, path integrations, sequence generation.There's a whole giant gap between grid cells and intelligence.reply",
      ">  if they have anything figured out besides \"collect spatial data\" like imagenetI mean she launched her whole career with imagenet so you can hardly blame her for thinking that way. But on the other hand, there's something bitter lesson-pilled about letting a model \"figure out\" spatial relationships just by looking at tons of data. And tbh the recent progress [1] of worldlabs.ai (Dr Fei Fei Li's startup) looks quite promising for a model that understands stuff including reflections and stuff.[1] https://www.worldlabs.ai/blog/rtfmreply",
      "This is super cool and I want to read up more on this as I think you are right insofar as it is the basis for reasoning. However it does seem more complex than just that. So how do we go from coordinate system transformations to abstract reasoning with symbolic representations?reply",
      "There is research showing that the grid cells also represent abstract reasoning: https://pmc.ncbi.nlm.nih.gov/articles/PMC5248972/Deep Mind also did a paper with grid cells a while ago:  https://deepmind.google/blog/navigating-with-grid-like-repre...reply",
      "Just had a fantastic experience applying agentic coding to CAD. I needed to add some threads to a few blanks in a 3d print. I used computational geometry to give the agent a way to \"feel\" around the model. I had it convolve a sphere of the radius of the connector across the entire model. It was able to use this technique to find the precise positions of the existing ports and then add threads to them. It took a few tries to get right, but if I had the technique in mind before it would be very quick. The lesson for me is that the models need to have a way to feel. In the end, the implementation of the 3d model had to be written in code, where it's auditable. Perhaps if the agent were able to see images directly and perfectly, I never would have made this discovery.reply",
      "Generative CAD has incredible potential.  I've had some decent results with OpenSCAD, but it's clear that current models don't have much \"common sense\" when it comes to how shapes connect.If code-based CAD tools were more common, and we had a bigger corpus to pull from, these tools would probably be pretty usable.  Without this, however, it seems like we'll need to train against simulations of the physical world.reply",
      "CadQuery? Would be appreciated if you're inclined to do writeup of your lessons learned.reply",
      "Thanks for sharing, I'm interested to know more about how you did this if you have a longer write up somewhere? (or are considering writing one!)reply"
    ],
    "link": "https://drfeifei.substack.com/p/from-words-to-worlds-spatial-intelligence",
    "first_paragraph": ""
  },
  {
    "title": "The lazy Git UI you didn't know you need (bwplotka.dev)",
    "points": 210,
    "submitter": "linhns",
    "submit_time": "2025-11-10T17:50:21 1762797021",
    "num_comments": 88,
    "comments_url": "https://news.ycombinator.com/item?id=45878578",
    "comments": [
      "I was a big fan of a good keyboard-driven git TUI like magit, neogit, lazygit, etc... (as long as you learn the CLI first and understand it).Now I no longer directly use git, but instead use jujutsu (jj).Once I became very proficient in the jj cli, I picked up jjui: https://github.com/idursun/jjuiAlso, as splitting commits is an extremely frequent operation, this neovim plugin is really nice: https://github.com/julienvincent/hunk.nvimAlso this neovim plugin is amazing for resolving jj conflicts: https://github.com/rafikdraoui/jj-diffconflictsNow with jj instead of git I edit the commit graph as effortlessly as if I am moving lines of code around a file in my editor.reply",
      "Jujutsu is much better than git, and I've switched to it completely, but I do still use lazygit for one thing: It has better diff viewing, it separates the diffs by file and they look nicer. It's the only thing keeping me on lazygit, as jjui is much better otherwise.reply",
      "Git doesn't fundamentally work with diffs (patches). It stores the complete file and generates a diff.So you can use any diff tool you like with git, and I presume also with JJ. Look for the setting.Edit: in git it's the diff.external settingreply",
      "I know I can. I want to use jjui, but its UI isn't as good, so I use lazygit.reply",
      "There's also lazyjj. I haven't really bothered with a TUI yet so can't say which has nicer diffs, but you might try it.reply",
      "I've tried lazyjj, but jjui was better (at least, back when I tried it).reply",
      "Thank you for the many tool links! You seems to know this space well. I have come to pick your brain for more.I have been searching for a while for good tools to split/regroup diffs in a patch series. hunk.nvim looks interesting. Do you know of similar/competing tools?I frequently hit a problem where removing a spurious hunk from an old commit causes cascading conflicts in all subsequent commits. Are there tools to propagate hunk removal into the future without the manual conflict-resolution pain?Thanks again!reply",
      "Are you looking for solutions within git or jj?In my experience with jj when resolving a conflict, as long as I do it in the earliest change, I will only have to do it once.Git has the rerere setting [0] which reduces the need to resolve the same conflict over and over0: https://git-scm.com/book/en/v2/Git-Tools-Rererereply",
      "Not the GP, but I might recommend Jujutsu for that, try it and see. It does the right thing when you resolve commits, and it propagates them to git. However, I'm not sure if it'll work, try it and see.reply",
      "You might laugh, but in years of serious development, I have not come across a better git UI tool than SourceTree.If I want to be hard-core, I'd use the original git CLI. SourceTree is unmatched in how it makes using git so much more pleasant for when you need to do something relatively simple, but which would be quite cumbersome to do with the CLI and most other tools I've tried.Its file status and history view is unmatched IMO. I can easily stage/unstage hunks and even lines. The whole UI is generally quite polished and pleasant to use.It's a real shame there is not a version for linux. I've tried every other git interface under the sun and keep coming back to it. In the meantime, I tried lazygit the past weekend and I think it is one of the better TUI git tools out there, definitely better than GitUI.reply"
    ],
    "link": "https://www.bwplotka.dev/2025/lazygit/",
    "first_paragraph": "When my son was born last April, I had ambitious learning plans for the upcoming 5w paternity leave. As you can imagine, with two kids, life quickly verified this plan \ud83d\ude43. I did eventually start some projects. One of the goals (sounding rebellious in the current AI hype cycle) was to learn and use neovim\nfor coding. As a Goland\naficionado, I (and my wrist) have always been tempted by no-mouse, OSS, gopls\nbased, highly configurable dev setups.Long story short, I\u2019d still stick to Goland for my professional coding (for now), but during the experiments with nvim, I accidentally stumbled upon lazygit\nGit UI. I literally mistyped <space>gg instead of gg, which opened up the built-in lazygit overlay UI.A week later, I have already switched all my git workflows to lazygit (also outside nvim), and I have been using it since then. In this post, I\u2019d like to explain why it happened so quickly, so:Let\u2019s jump in!Likely every developer knows and (in some form) uses the git CLI\n. It\u2019s relatively simple"
  },
  {
    "title": "The Physics of News, Rumors, and Opinions (arxiv.org)",
    "points": 21,
    "submitter": "Anon84",
    "submit_time": "2025-11-05T00:22:16 1762302136",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45817559",
    "comments": [
      "All this \u201cphysics of news\u201d framing repeats the same mistake mainstream economics made decades ago, confusing human action with measurable physical phenomena. People aren\u2019t particles, and opinions aren\u2019t spin states. As Mises and Hazlitt argued, mathematical models give spurious precision when applied to purposeful behavior: they hide their \"arbitrary assumptions\" behind elegant equations. Treating communication, belief, and motivation as quantifiable variables may look rigorous, but it strips away meaning, choice, and context and the very essence of human decision. What results isn\u2019t insight, but an illusion of control dressed up as science.reply",
      "are you claiming that human action is not measurable physical phenomena?reply"
    ],
    "link": "https://arxiv.org/abs/2510.15053",
    "first_paragraph": "YOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.Help | Advanced SearcharXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\narXiv Operational Status \n"
  },
  {
    "title": "Unix v4 Tape Found (discuss.systems)",
    "points": 166,
    "submitter": "greatquux",
    "submit_time": "2025-11-06T20:57:09 1762462629",
    "num_comments": 21,
    "comments_url": "https://news.ycombinator.com/item?id=45840321",
    "comments": [
      "Anyway, since nobody much seems to realise this is quite a big deal, I will share the explainer I wrote yesterday:https://www.theregister.com/2025/11/07/unix_fourth_edition_t...Unix V4 is otherwise lost. It was the first version in C.reply",
      "The bit in the article about the recovery procedure, which involves dumping info from the tape into '100-ish GB of RAM' and then using software to analyze it stuck out to me.This video on the linked github page for the analysis software[1] is interesting:https://www.youtube.com/watch?v=7YoolSAHR5w&t=4200s[1] https://github.com/LenShustek/readtapereply",
      "Interesting article. I agree it is kind of a big deal. Certainly worth the effort to try to restorereply",
      "Please let there be an ultimate force in the universe that spared this tape from tape degradation and/or magnetization that it can be read and extracted into a raw dump fs that we can preserve for all time. (fingers crossed)Tapes from back then haven\u2019t held up over the years. It all depends on the environment it was stored in.reply",
      "> It is a '70s 1200ft 3M tape, likely 9 track, which has a pretty good chance of being recoverable.Not old enough to have this kind of knowledge or confidence. I wonder if instead one day I'll be helping some future generation read old floppies, CDs, and IDE/ATA disks *slaps top of AT tower*.reply",
      "Just anecdata, but I had this concern when I worked in academia and we backed up all our data to writable DVDs. I was there 10 years after the start of the project and I periodically checked the old DVDs to make sure they weren't corrupted.After 10 years, which was longer than the assumed shelf life of writable/rewritable DVDs at the time, I never found a single corrupt file on the disks. They were stored in ideal conditions though, in a case, in a closed climate controlled shelf, and rarely if ever removed or used.Also, just because I think it's funny, the archive was over 4000 DVDs. (We had a redundant copies of the data compressed and uncompressed, I think it was like 3000 uncompressed 1k compressed) there was also an offsite redundant copy we put on portable IDE (and eventually SATA) drives.reply",
      "Thank your procurement agent and hvac guy.My team used to maintain go-kits for continuity of operations for a government org. We ran into a few scenarios where the dye on optical media would just go, and another where replacement foam for the pelican cases off gassed and reacted with the media!reply",
      "Wow! That's pretty interesting. I can imagine wanting to store optical media in Pelican cases or similar for shock protection, ability to padlock, etc. But yeah -- what's the interaction between whatever interior foam they chose and the CD-R media and dyes? Especially after 10+ years of continuous contact?Optical media is probably best stored well-labeled and in metal or cardboard box on a shelf in a basement that few will rarely disturb.reply",
      "Cool tale! I have observed a mix of viable and unreadable user-burned CD media from the late 90s and early 2000s. It definitely depends on the quality of the media, quality of the burn/drive/laser, and how well it was stored interim.My oldest disc is some bright blue Verbatim disk my childhood friend made for me so I could play our favorite game at home pre-2000. I have a bit-perfect copy, but the actual disc still reads fine in 2025 when I last tested it.reply",
      "You might be able to use that old floppy drive.  But you won't be able to use that old Pentium machine the drive is in.Because you will need several hundred gigabytes of RAM and a very fast IO bus.The gold standard today for archiving magnetic media is to make a flux image.The media is treated as if it were an analog recording and sampled at such a high rate that the smallest details are captured.  Interpretation is done later, in software. The only antique electronics involved are often the tape or drive head, directly connected to a high speed digitizer.And indeed that appears to be the plan Al Kossow has for the tape: https://www.tuhs.org/pipermail/tuhs/2025-November/032765.htm...As for CDs, I don't see the rush; the ones that were properly made will likely outlast human civilization.reply"
    ],
    "link": "https://discuss.systems/@ricci/115504720054699983",
    "first_paragraph": ""
  },
  {
    "title": "Dependent types and how to get rid of them (chadnauseam.com)",
    "points": 45,
    "submitter": "pie_flavor",
    "submit_time": "2025-11-03T17:49:25 1762192165",
    "num_comments": 14,
    "comments_url": "https://news.ycombinator.com/item?id=45801966",
    "comments": [
      "\"But we'd like to give a type to this function. In most languages (Haskell, Typescript, C++, Rust, C#, etc.) there is no way to do that.[2] \"Can't you do this with a GADT? With a GADT, the type of the output can be specified by which branch of the GADT the input matches. Seems quite a similar idea.reply",
      "I mean, you can trivially do it with a (non-G) ADT, if you're content with wrapping the return value.OTOH you can do this in TypeScript easily without wrapping; it could return a union type `number | string`.reply",
      "I read the first post and thought someone should at the very least post the lambda cube. This isn't my area of expertise, since I've done very little with dependent types (staying firmly on the left side of the cube), but it outlines some useful categories of type systems here.https://en.wikipedia.org/wiki/Lambda_cubereply",
      "I wrote a small post on that: https://azdavis.net/posts/lambda-cube/Hope it\u2019s helpful!reply",
      "Cool that you worked on an implementation of the CoC.I've been somewhat wanting to go back and revisit ATAPL and read chapter 2 on this subject: https://www.cis.upenn.edu/~bcpierce/attapl/frontmatter.pdfreply",
      "That is a good post. I've linked to it from mine!reply",
      "Thanks! But I don\u2019t think it quite worked?reply",
      "Ought to be fixed nowreply",
      "I am slowly trying to understand dependent types but the explanation is a bit confusing to me as, I understand the mathematical terminology of a function that may return a type, but...\nSince function types take a value and return a value, they are by definition in another universe from say morphisms that would take a type and return a type.The same way, I see a value as a ur-element and types as sets of values.\nSo even if there is syntactic sugar around the value <-> type equivalence, I'd naively think that we could instead define some type morphism and that might be more accurate. The value parameter would merely be declared through a type parameter constrained to be a singleton.\nThe same way a ur-element is not a set but a member of set.Then the question is representation but that could be left as an optimization.\nPerhaps that it is already what is done.Example:type Nine int = {9}\nAnd then the rest is generic functions, parameterizable by 9, or actually, Nine.So nothing too different from a refinement of int.Basically, 'value' would be a special constraint on a  type parameter in normal parametric polymorphism implementations. There would probably be derived constraint information such as size etc...But I guess, the same issue of \"which refinement types can be defined, while keeping everything decidable\" remains as an issue.Also how to handle runtime values? That will require type assertions, just like union types?\nOr is it only a compile time concept and there is no runtime instantiations.\nOnly some kind of const generics?A typeof function could be an example of dependent type though? Even at runtime?Just wondering...reply",
      "Hi aatd86! We had a different thread about existence a couple days ago, and I'm just curious -- is English your second language? What's your first language? I'm guessing French, or something from Central Europe.Thanks for humoring me!reply"
    ],
    "link": "https://chadnauseam.com/coding/pltd/are-dependent-types-actually-erased",
    "first_paragraph": ""
  },
  {
    "title": "Zeroing in on Zero-Point Motion Inside a Crystal (aps.org)",
    "points": 34,
    "submitter": "lc0_stein",
    "submit_time": "2025-11-10T21:17:04 1762809424",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45881056",
    "comments": [
      "Star gate zero point modules incoming?reply",
      "> However, the Heisenberg uncertainty principle dictates that the motion can\u2019t go exactly to zero\u2014there will always be fluctuations.Is that what it dictates? I thought it was about observation (in the sense of interactions with other particles, noting to do with consciousness) inescapably and unpredictably altering the observed property.reply"
    ],
    "link": "https://physics.aps.org/articles/v18/178",
    "first_paragraph": "Zero-point motion is an irrepressible wiggling that becomes visible at temperatures near absolute zero. Evidence of this quantum motion has previously been uncovered for trapped particles and for small resonators. Now researchers studying nanocrystals have identified a low-temperature emission effect, which they show is related to zero-point motion within the crystal lattice [1]. The effect may be useful in cooling down nanocrystals to lower temperatures than previously possible.Quantum physics often shows up at ultracold temperatures. Normally, as an object becomes colder, it moves less and less. However, the Heisenberg uncertainty principle dictates that the motion can\u2019t go exactly to zero\u2014there will always be fluctuations. These quantum fluctuations have been studied in microscopic systems, such as trapped atoms and molecules [2]. But they\u2019ve also been observed in macroscopic objects. Previous experiments have identified signatures of zero-point motion in small mechanical resonators"
  },
  {
    "title": "Error ABI (matklad.github.io)",
    "points": 66,
    "submitter": "todsacerdoti",
    "submit_time": "2025-11-10T02:31:36 1762741896",
    "num_comments": 25,
    "comments_url": "https://news.ycombinator.com/item?id=45871688",
    "comments": [
      "Rigid ABIs aren't necessary for statically linked programs. Ideally, the compiler would look at the usage of the function in context and figure out an ABI specifically for that function that minimizes unnecessary copies and register churn.IMHO this is the next logical step in LTO; today we leave a lot of code size and performance on the floor in order to meet some arbitrary ABI.reply",
      "Can\u2019t offload everything into the compiler. It is already too slow.Soon people will demand it just figures out what you are implementing and rewrites your whole codebasereply",
      "> Soon people will demand it just figures out what you are implementing and rewrites your whole codebaseWe have this now, it is indeed very slow lol. Gemini is pretty fast however.reply",
      "Isn't that what people are using Claude for now?reply",
      "I would argue that most of today\u2019s performance problems in software are unrelated to ABI.reply",
      "I would argue that is largely true because we got the ABIs and the hardware to support them to be highly optimized. Thing slow down very quickly if one gets off that hard-won autobahn of ABI efficiency.reply",
      "I loved Java checked exceptions when learning the language (coming from C++), then understood the biggest pitfall - if you need to extend with new exception, or remove existing you have to change all the code using it (maybe there are better approaches to this, but that's what I remmember). I'm back to C++ but it felt good having exceptions done like this.reply",
      "That is not a pitfall, that is the whole point of checked exceptions. By making the errors part of the type system, you get the ability for the compiler to warn you \"hey man, that method started to raise a new error so you have to make sure to handle it\". That is a great benefit, not a pitfall!Put another way - it would be a lot easier for the programmer to write code if there were no types checked by the compiler at all, but we recognize that the safety net they give us is worth the additional effort at times when refactoring. So why would the benefits of static type checking be worth it, but not the benefits of static error type checking? It seems to me that either both are good ideas, or neither is.reply",
      "iex [0] might be potentially relevant here. From what I understand it basically implements this bit:> Finally, another option is to say that -> Result<T, E> behaves exactly as -> T ABI-wise, no error affordances whatsoever. Instead, when returning an error, rather than jumping to the return address, we look it up in the side table to find a corresponding error recovery address, and jump to that. Stack unwinding!And at least based on the listed benchmarks it can indeed result in better performance than \"regular\" Result<T, E>.(Might be nice to mention this on the corresponding lobste.rs thread as well to see if anyone has anything interesting to add, if anyone has access)[0]: https://github.com/iex-rs/iexreply",
      "> Naively composing errors out of ADTs does pessimize the happy path. Error objects recursively composed out of enums tend to be big, which inflates size_of<Result<T, E>>, which pushes functions throughout the call stack to \u201creturn large structs through memory\u201d ABI. Error virality is key here \u2014 just a single large error on however rare code path leads to worse code everywhere.This isn't true; proof by counter-example: anyhow::Error.For example, a lot of Rust code uses \"anyhow\", a crate which provides sort of a catch-all \"anyhow::Error\" type. Any other error can be put into an anyhow::Error, and an anyhow::Error is not good for much except displaying, and adding additional context to it. (For that reason, anyhow::Error is usually used at a high-level, where you don't care what specifically went wrong, b/c the only thing you'll use it for is propagation & display.)No matter what error we put into an anyhow::Error, the stack size is 8 B. (Because it's a pointer to the error E, effectively, though in practice \"it's a bit more complicated\", but not in any way that harms the argument here.) So clearly, here, we can stuff as much context/data/etc. into the error type E without virally infecting the whole stack with a larger Result<T, E>.(Rust does allow you to make E larger, and that can mean a Result<T, E> gets larger, yes. But you're one pointer away from moving that to the heap & fixing that. Rust, being a low level language, \u2026 permits you that / leaves that up to you. The stack space isn't free \u2014 as TFA points out, spilling registers has a cost \u2014 but nor are heap allocations free. Rust leaves it up to you, effectively.)My understanding of Zig the other day is that it doesn't permit associated data at all, and errors are just integer error code, effectively, under the hood. This is a pretty sad state of affairs \u2014 I hate the classic unix problem where you get something like,  $ mkdir $P\n  mkdir: no such file or directory\n\nWhich I now special path in the neurons in my head so-as to short circuit wandering the desert of \"yeah, no such directory \u2026 that's why I'm asking you to create it\". (And all other variations of this pattern.)All of that could have been avoided if Unix had the ability to tell us what didn't exist. (And there are so many variants: what exists unexpectedly? what perm did we lack? what device failed I/O?)(And I suppose you could make Result<T, E> special / known to the compiler, and it could implement stack unwinding specifically. I don't think that leave me with good vibes in the language design dept., and there are other types that have similar stack-propagating behavior to Result (Option, Poll, maybe someday a generator type). What about them?)reply"
    ],
    "link": "https://matklad.github.io/2025/11/09/error-ABI.html",
    "first_paragraph": "\n          A follow-up on the\n          \u201cstrongly typed error codes\u201d\n          article.\n        \n          One common argument about using algebraic data types for errors is\n          that:\n        \n          This argument is not entirely correct. Naively composing errors out of\n          ADTs does pessimize the happy path. Error objects recursively composed\n          out of enums tend to be big, which inflates\n          size_of<Result<T, E>>, which pushes functions\n          throughout the call stack to \u201creturn large structs through memory\u201d\n          ABI. Error virality is key here \u2014 just a single large error on however\n          rare code path leads to worse code everywhere.\n        \n          That is the reason why mature error handling libraries hide the error\n          behind a thin pointer, approached pioneered in Rust by\n          failure\n          and deployed across the ecosystem in\n          anyhow. But this requires global allocator, which is\n          also not entirely zero"
  },
  {
    "title": "Launch HN: Hypercubic (YC F25) \u2013 AI for COBOL and Mainframes",
    "points": 77,
    "submitter": "sai18",
    "submit_time": "2025-11-10T16:23:24 1762791804",
    "num_comments": 47,
    "comments_url": "https://news.ycombinator.com/item?id=45877517",
    "comments": [
      "Mainframe COBOL to POSIX native machine language or Java is largely a solved problem. 40 year old code that hasn't been touched in 30 years \"ain't broke\" and likely doesn't need fixing IMHO. Our take is get it to POSIX/Java so you can sort out all the OTHER STUFF and then rewrite/re-architect at your leisure. {disclosure: we're the GCC COBOL team}.reply",
      "They're not trying to solve a problem. They're trying to make money. They are hoping to awaken every middle manager on earth like a zombie horde promising nice-looking KPI's for all the quarters up until it inevitably goes tits up.reply",
      "I heard the story once on how you migrate these old systems:\n1 you get a super extensive test suite of input - output pairs2 you do a \"line by line\" reimplementation in Java (well banks like it).3 you run the test suite and track your progress4 when you get to 100 percent, you send the same traffic to both systems and shadow run the new implementation. Depending on how that goes you either give up, go back to work implementation or finally switch to the new systemThis obviously is super expensive and slow to minimize any sort of risks for systems that usually handle billions or trillions of dollars.reply",
      "I have been part of a few migration projects like this. There is another issue apart from tests not existing. Business/Product still want new high priority features so developers keep adding new logic to the old system because they cannot be supported by the new system yet.reply",
      "The secret sauce is being able to operate below your maximum effectiveness while still seeming impressive enough. That is, if you want to play the long game and get a lot done over a 5 year horizon.reply",
      "Yeah, we've heard the same \"big bang\" story a bunch of times as well. However, step 1 (extensive test suite) is often missing and is something you'd have to do as part of the modernization effort as well. Overall, it is a pretty hairy and difficult problem.reply",
      "Sort of related to what bloop is trying to do too right?reply",
      "> rapidly increasingSurely not at a rate faster than one year per year?reply",
      "I submitted this [0] story a few weeks ago, which led to some discussion and then being flagged since (I think) people were unsure of how verifiable the stats around COBOL were (the submitted page had more than a tinge of self-promotional language).I was curious to ask you, as domain experts, if you could talk more to the \"70% of the Fortune 500 still run on mainframes\" stat you mentioned.Where do these numbers come from? And also, does it mean that those 70% of Fortune 500s literally run/maintain 1k-1M+ LoC of COBOL? Or do these companies depend on a few downstream specialized providers (financial, aviation/logistics, etc.) which do rely on COBOL?Like, is it COBOL all the way down, or is everything built in different ways, but basically on top of 3 companies, and those 3 companies are mostly doing COBOL?Thanks![0] https://news.ycombinator.com/item?id=45644205reply",
      "I work at a shop (a specialized provider for finance in your eyes) which still has the \"transaction\" workload on IBM z/OS (IMS/DB2). The parts we manage (in Openshift) interface with that (as well as other systems) and I have heard of people/seen the commits moving PL/I to Cobol. In 2021. Given Cobol's nature, those apps have more than 1k LoC easily.We also sublease our mainframes to at least 3 other ventures; one of which is very outspoken they have left the mainframe behind. I guess that's true if you view outsourcing as (literally) leaving it behind with the competitor of your new system... It seems to be the same for most banks, none of which are having mainframes anymore publicly, but for weird reasons they still hire people for it offshore.Given that our (and IBM's!) services are not cheap I think either a) our customers are horribly dysfunctional in anything but earning money slow and steady (...) and b) they actually might depend on those mainframe jobs. So if you are IBM or a startup adding AI to IBM I guess the numbers might add up to the claims.reply"
    ],
    "link": "item?id=45877517",
    "first_paragraph": ""
  },
  {
    "title": "Omnilingual ASR: Advancing automatic speech recognition for 1600 languages (meta.com)",
    "points": 73,
    "submitter": "jean-",
    "submit_time": "2025-11-10T18:10:12 1762798212",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=45878826",
    "comments": [
      "Does anyone else feel like they buried the lead?> Omnilingual ASR was designed as a community-driven framework. People around the world can extend Omnilingual ASR to new languages by using just a few of their own samples.The world just got smallerreply",
      "This seems like a massive improvement for openly available local ASR. Even the 300M model outperforms whisper-large-v3 according to the paper's benchmarks.reply",
      "Not sure, I recorded 3 seconds of voice (a single sentence) and the hf demo misrecognized about half of the words.reply",
      "Only a few gb of weights will recognize speech in 1600+ languages.Freely downloadable and usable by anyone for almost anything.We truly live in the future.reply",
      "Seeing the absurd number of languages made me think of the norm macdonald joke:Music is the universal language, but one day soon it will be replaced by Chinese.reply",
      "How hard is it to make TTS out of this? A few independent journalists from Belarus asked for TTS in their language, but I am no expert, was thinking about re-using Mozilla's work. What's the easiest way to get working TTS for a language?reply",
      "EDIT: My bad, please disregard; As akreal pointed out, the MMS TTS models aren\u2019t using the SSL models.Original post:You can use the OmniASR SSL models instead of their older MMS models to create TTS models: https://github.com/ylacombe/finetune-hf-vitsreply",
      "As far as I understand, the MMS TTS models are trained from scratch (section 7.1 of [1]), they do not employ any SSL models. So the OmniASR SSL models are not useful here.What might be interesting is the newly released OmniASR data, because the MMS data, which was used for the MMS TTS, was never released.Also, the OmniASR can be used to transcribe some untranscribed speech to train a TTS on it.[1] MMS paper: https://arxiv.org/pdf/2305.13516reply",
      "You\u2019re completely right, I misremembered. I edited my post.reply",
      "Meta cheated with the mms models. That is they didn\u2019t use a phonemeizsr step. This means they just won\u2019t work or sound very strange. ASR data is usually not quite right for tts. But anyhow - not really answering your question but many of these languages already done in mms. Try them https://huggingface.co/spaces/willwade/sherpa-onnx-ttsreply"
    ],
    "link": "https://ai.meta.com/blog/omnilingual-asr-advancing-automatic-speech-recognition/?_fb_noscript=1",
    "first_paragraph": "Open SourceNovember 10, 2025Takeaways:Automatic speech recognition (ASR) systems aim to make spoken language universally accessible by transcribing speech into text that can be searched, analyzed, and shared. Currently, most automatic speech recognition systems focus on a limited set of high-resource languages that are well represented on the internet, often relying on large amounts of labeled data and human-generated metadata to achieve good performance. This means high-quality transcriptions are often unavailable for speakers of less widely represented or low-resource languages, furthering the digital divide.Today, Meta\u2019s Fundamental AI Research (FAIR) team is introducing Omnilingual ASR \u2014 a groundbreaking suite of models that deliver automatic speech recognition for more than 1,600 languages, including 500 low-resource languages never before transcribed by AI. We\u2019re also open sourcing Omnilingual wav2vec 2.0, a new self-supervised massively multilingual speech representation model s"
  },
  {
    "title": "Building a high-performance ticketing system with TigerBeetle (renerocks.ai)",
    "points": 83,
    "submitter": "jorangreef",
    "submit_time": "2025-11-08T00:01:05 1762560065",
    "num_comments": 10,
    "comments_url": "https://news.ycombinator.com/item?id=45852755",
    "comments": [
      "Having built a ticketing system that sold some Oasis level concerts there's a few misconceptions here:Selling an event out takes a long time to do frequently because tickets are VERY frequently not purchased--they're just reserved and then they fall back into open seating. This is done by true fans, but also frequently by bots run by professional brokers or amateur resellers. And Cloudflare and every other state of the art bot detection platform doesn't detect them. Hell, some of the bots are built on Cloudflare workers themselves in my experience...So whatever velocity you achieve in the lab--in the real world you'll do a fraction of it when it comes to actual purchases. That depends upon the event really. Events that fly under the radar may get you a higher actual conversion rate.Also, an act like Oasis is going to have a lot of reserved seating. Running through algorithms  to find contiguous seats is going to be tougher than this example and it's difficult to parallelize if you're truly giving the next person in the queue the actual best seats remaining.There are many other business rules that accrue after years of features to win Oasis like business unfortunately that will result in more DB calls and add contention.reply",
      "Does that mean that there is some smoke and mirrors when, eg Taylor Swift, says they sold out the concert in minutes? Or are the mega acts truly that high demand?reply",
      "You can get the seats into \"baskets\" (reserved) in minutes. In my experience they will not sell out for some time as they usually keep dropping back into inventory. \"Sold Out\" is a matter of opinion. There are usually lots of single seats left sometimes for weeks or months. The promoter decides when to label the event as \"sold out\".reply",
      "It seems to me that, in practice, you'd want the \"LiveBatcher\" to have some durability as well. Is there a scenario where a customer could lose their place because of a horribly timed server shutdown, where those transfers hadn't even been sent to TigerBeetle as pending yet? Or am I misunderstanding the architecture here?Edit: Yes, I think I misunderstood something here. The user wouldn't even see their request as having returned a valid \"pending\" ticket sale since the batcher would be active as the request is active. The request won't return until its own transfer had been sent off to TigerBeetle as pending.reply",
      "Is FastAPI just bad with SQLite? I would have expected SQLite to smoke Postgres in terms of ops/s.reply",
      "Also surprised. My yardstick was this post which showed SQLite beating Postgres in a Django app. Benchmarking is hard, and the author said the Postgres results were not tuned to the same degree as SQLite, so buyer beware. \nhttps://blog.pecar.me/django-sqlite-benchmarkreply",
      "I think Python is bad in general if you want \u201chigh-performance\u201dreply",
      "SQLite is in process, but concurrent write / performance is a complex matter : https://sqlite.org/wal.htmlreply",
      "Yes, that's why I would expect it to smoke Postgres here, in process is orders of magnitude faster. Do you really need concurrency here when you can do 10-100k+ inserts per second?reply",
      "If 100k users each hit purchase button at the same time will sqlite write it in 1 second?This is different than 1 user doing the purchase for 100k fansreply"
    ],
    "link": "https://renerocks.ai/blog/2025-11-02--tigerfans/",
    "first_paragraph": "\nNovember 02, 2025\n    \u2022\n    17\n    min read \u2022 by\n    renerocksai\n\nA journey from simple curiosity to 977 tickets per second\nTigerFans demo showing ticket checkout and payment flow\u201dToo easy: TigerBeetle.\u201dThat was Joran Dirk Greef\u2019s response when someone on Twitter asked how you\u2019d build a ticketing solution for an Oasis-scale concert\u2014hundreds of thousands of people flooding your website at once, where you need to guarantee no ticket gets sold twice and everyone who pays gets a ticket. Joran is the CEO and founder of TigerBeetle.He was right. Everyone who knows TigerBeetle would give the same advice. TigerBeetle is a financial transactions database designed for exactly this kind of problem: counting resources with absolute correctness under extreme load.But I wanted to understand the concrete implementation. Not just conceptually\u2014I needed to see the actual code.How do you model ticket transactions as financial transactions? What does the account structure look like? How do the transfers "
  },
  {
    "title": "Linux in a Pixel Shader \u2013 A RISC-V Emulator for VRChat (blog.pimaker.at)",
    "points": 34,
    "submitter": "rbanffy",
    "submit_time": "2025-11-10T21:50:03 1762811403",
    "num_comments": 9,
    "comments_url": "https://news.ycombinator.com/item?id=45881404",
    "comments": [
      "As someone who had a brief alternate life in VRC and made worlds - just /wow/. I had just enough grasp on Unity to make some basic things, but stuffing Linux into a pixel shader is 1 if not 2 orders of magnitude more impressive.p.s. Udon Bird Sanctuary! I've been there!reply",
      "It's a big differentiator with horizon worlds I think. They have an in world builder so you don't have to learn unity.On the other hand horizon is super restricted in what you can do, is way too heavily moderated and rubber tiled so it's not fun to be in there at all. VRChat is way better at finding the edge of what's possible. I've seen whole worlds from half Life 2 recreated etc.reply",
      "VRChat has intriguing possibilities, but I always got the impression the underlying architecture and programming is too shoddy to really support the breadth of custom experiences people want to make. I tried various mini \ngames or special worlds, and it was always incredibly jank and barely functional. It seemed more like problems stemming from instability or jankiness of the engine and API they were working with than anything else.Granted, the last time I touched it was a few years ago. Unless they've done a major rewrite of the game I don't expect it to have improved all that much. Maybe I'm wrong.reply",
      "The one thing I can add is that the VRC players I've played with don't care about it. They just want to be in a world and do things with their friends, even if it's janky or has bugs. It's already persistently novel, and if ones novel threshold ever dips too low or the bugs are too high, there's another world with different people just a tap away.reply",
      "Article should probably have \"(2021)\" in the title.reply",
      "Would make it a lot more impressive.reply",
      "Pretty amazing work!Work like this highlights how different the compute models are between gpu and cpu. Honestly very impressed it runs as fast as it does (250khz) given those differences.reply",
      "This is so cursed I love itreply",
      "RISC-V is inevitable.reply"
    ],
    "link": "https://blog.pimaker.at/texts/rvc1/",
    "first_paragraph": "PiMaker / _pi_ / Stefan's technology blog. Sometimes about Linux, VRChat or Shaders. Somtimes about all of the above.\n      Built with Ed.\nfor comments see Hacker News, r/programming or r/vrchatSometimes you get hit with ideas for side-projects that sound absolutely plausible in your head. The idea grips you, your mind\u2019s eye can practically visualize it already. And then reality strikes, and you realize how utterly insane this would be, and just how much work would need to go into it.Usually these ideas appear, I enjoy dissecting them for a few days, and then I move on. But sometimes. Sometimes I decide to double down and get Linux running on my graphics card.This is the story of how I made the rvc RISC-V emulator within VRChat, and a deep-dive into the unusual techniques required to do it.Here are some specs up front, if you\u2019re satisfied with piecing the story together yourself:\n(image credit: @pema99, thanks!)Be warned that this post might be a bit rambly at times, as I try to recall"
  },
  {
    "title": "Benchmarking leading AI agents against Google reCAPTCHA v2 (roundtable.ai)",
    "points": 93,
    "submitter": "mdahardy",
    "submit_time": "2025-11-10T16:38:31 1762792711",
    "num_comments": 70,
    "comments_url": "https://news.ycombinator.com/item?id=45877698",
    "comments": [
      "I\u2019m sure they do better than me. Sometimes I get stuck on an endless loop of buses and fire hydrants.Also, when they ask you to identify traffic lights, do you select the post? And when it\u2019s motor/bycicles, do you select the guy riding it?reply",
      "There is a doom loop mode where it doesn't matter how many you solve or even if you get them correct.  My source for this works on this product at Google.reply",
      "That doesn't surprise me. I find it hard to believe it's a pure coincidence that I would get stuck in the loop regularly when I'm on the university wifi but it would never happen anywhere else ever. After a dozen try, I would remote connect to my home pc and it would magically work on the first try every single time.reply",
      "Tell them I hate them.reply",
      "Testing those same captcha on Google Chrome improved my accuracy by at least an order of magnitude.Either that or it was never about the buses and fire hydrants.reply",
      "It's a known \"issue\" of reCaptcha, and many other systems like it. If it thinks you're a bot, it will \"fail\" the first few correct solves before it lets you through.The worst offenders will just loop you forever, no matter how many solves you get right.reply",
      "stock Chrome logged into a Google account = definitely not a bot. here, click a few fire hydrants and come on in :^)I sincerely wish all the folx at Google directly responsible for this particular user acquisition strategy to get every cancer available in California.reply",
      "I would think that when you're viewing recaptcha on a site, if you have 3rd party cookies disabled the embedded recaptcha script won't have anyway of connecting you with your Google account, even if you're logged in. At least that's how disabling 3rd party cookies is supposed to work.reply",
      "Of course, if you have 3rd party cookies disabled, Google would never link your recaptcha activity to your Google account.They just link it to your IP address, browser, operating system, screen resolution, set of fonts, plugins, timezone, mouse movements, GPU, number of CPU cores, and of course the fact you've got third party cookies disabled.reply",
      "\"Oh, that's interesting...there is one other user that matches all of that metadata\"reply"
    ],
    "link": "https://research.roundtable.ai/captcha-benchmarking/",
    "first_paragraph": "\n      We evaluate three leading AI models\u2014Claude Sonnet 4.5 (Anthropic), Gemini 2.5 Pro (Google), and GPT-5 (OpenAI)\u2014on \n      their ability to solve Google reCAPTCHA v2 challenges. Compared to Sonnet and Gemini, GPT-5's long and slow\n      reasoning\n      traces led to repeated challenge timeouts and significantly lower performance.\n    \n      Many sites use CAPTCHAs to distinguish humans from automated traffic. How well do these CAPTCHAs hold up against\n      modern AI agents?\n      We tested three leading models\u2014Claude Sonnet 4.5, Gemini 2.5 Pro, and GPT-5\u2014on their ability to solve Google\n      reCAPTCHA v2 challenges and\n      found significant differences in performance. Claude Sonnet 4.5 performed best with a 60% success rate, slightly\n      outperforming Gemini 2.5 Pro\n      at 56%. GPT-5 performed significantly worse and only managed to solve CAPTCHAs on 28% of trials.\n    \n      Each reCAPTCHA challenge falls into one of three types: Static, Reload, and Cross-tile (see Figure"
  },
  {
    "title": "What Caused Performance Issues in My Tiny RPG (jslegenddev.substack.com)",
    "points": 13,
    "submitter": "ibobev",
    "submit_time": "2025-11-10T23:27:53 1762817273",
    "num_comments": 5,
    "comments_url": "https://news.ycombinator.com/item?id=45882305",
    "comments": [
      "> There weren\u2019t that many projectiles in the first place so I felt that this would be useful later. However, considering that Chrome and Safari were struggling performance wise probably due to their garbage collector working differently, I resigned myself to implement it now.I'm curious about actual metrics with regard to Chrome / Safari's garbage collector overhead. You still don't have a lot of \"objects\" in the video; when V8 is used server side it handles significantly more objects. (IE, assuming each sword is 1-5 objects.)Are these engines canvas based, or are they generating HTML? Assuming they are generating HTML, are the elements removed from the screen when you are done with them?In a lot of garbage collected environments, you still need to call some kind of close / remove method when you are done with some kinds of objects. (In C#, it's \"Dispose.\")reply",
      "> Additionally, to not disable batching it was important that all drawSprite calls be placed together in the draw loop before rendering text with drawText calls.Sounds like reflow problems. And like OP is slowly discovering the 200% Problem.reply",
      "What is the 200% problem?reply",
      "I was able to find this comment, linking to a talk that coined(?) it. https://news.ycombinator.com/item?id=36091791 I guess in short you would say that learning a leaky simplifying abstraction actually increases the amount you have to learn.reply",
      "Interesting writeup. It's surprising to me that the author was experiencing such severe performance issues with relatively simple scenes, and it sounds like the performance issues still aren't completely gone. In the past I've been able to run fairly complex 2D scenes in JS+canvas so I wonder if there's some sort of fundamental performance issue lurking underneath kaplay or some other library they're using?reply"
    ],
    "link": "https://jslegenddev.substack.com/p/what-caused-performance-issues-in",
    "first_paragraph": ""
  },
  {
    "title": "Registered OAuth Parameters (iana.org)",
    "points": 36,
    "submitter": "mooreds",
    "submit_time": "2025-11-04T12:07:10 1762258030",
    "num_comments": 6,
    "comments_url": "https://news.ycombinator.com/item?id=45810001",
    "comments": [
      "Why is this news?reply",
      "I thought it was pretty cool that the OAuth parameters are listed some place.Also, the existence of the IANA registry itself may be news to some.reply",
      "> Also, the existence of the IANA registry itself may be news to some.god i'm old...Edit: but it's great that some are teaching the basics that us seniors (!?) take for granted. It's why I particularly appreciated Julia Evans' DNS tutorials, which were explicitly written with that goal in mind; to educate the younger generationreply",
      "If you can ever get them off discord. /sThis is covered by CS stuff like \u201cwhat is the World Wide Web\u201d and \u201cwho was Dennis Ritchie and why was he important\u201d? Things of that nature in school. Do people who write code not know about IANA? The gatekeepers of all things Internet? Whose vaults contain the secrets to all of the internets protocols?What\u2019s really funny is all the extra field crap packed on the end like vp_token and such because a json blob would be too much.reply",
      "Submissions don't have to be news.reply",
      "https://xkcd.com/1053/reply"
    ],
    "link": "https://www.iana.org/assignments/oauth-parameters/oauth-parameters.xhtml#parameters",
    "first_paragraph": "\nRegistries Included Below\n"
  },
  {
    "title": "Toucan Wireless Split Keyboard with Touchpad (beekeeb.com)",
    "points": 8,
    "submitter": "tortilla",
    "submit_time": "2025-11-11T00:31:58 1762821118",
    "num_comments": 2,
    "comments_url": "https://news.ycombinator.com/item?id=45882736",
    "comments": [
      "You can already find Corne-inspired keyboards with these features, but up until the introduction of this Toucan design, you couldn't find a Corne keyboard with all those features together.- Wireless- Integrated pointing device- Aligned 1u thumb keys- E-ink screen- Aluminium plate- Below $200I'm interested for sure. Thanks for sharing.reply"
    ],
    "link": "https://shop.beekeeb.com/products/toucan-wireless-piantor-wireless-split-keyboard-with-touchpad",
    "first_paragraph": "Free worldwide shipping on all orders\u00a0over\u00a0$70.00.  \u00a0Use code WAKUWAKU for 10% off DIY kits and pre-soldered keyboards.The Toucan (Touch Cantor) shares the same layout as the popular Piantor and Cantor keyboard, but adds wireless connectivity along with a memory-in-pixel display and built-in trackpad. \n\nWith its low-profile design, clean minimal case, and thoughtfully integrated features, the Toucan is a ultra portable split keyboard that is an ideal for professionals on the go, whether for work, travel, or daily use.\n\nThis is a pre-order item. \nShipments planned to begin in mid-December 2025The Toucan is a keyboard with an integrated touchpad, built around the familiar Cantor (Piantor) layout, designs with the goal of creating a truly portable split keyboard, something easy to bring along for work, travel, or even to use comfortably on a flight.Don\u2019t miss out on a sale again.Sign up now for sale alerts & special offers.Be the first to know about the latest productsJoin our mailing lis"
  },
  {
    "title": "Head in the Zed Cloud (maxdeviant.com)",
    "points": 58,
    "submitter": "todsacerdoti",
    "submit_time": "2025-11-10T14:23:17 1762784597",
    "num_comments": 16,
    "comments_url": "https://news.ycombinator.com/item?id=45876308",
    "comments": [
      "The attempts at collaborative tools in Zed was always far more interesting to me than the AI stuff. Don't get me wrong, their AI stuff is nice and works well for me, but it's hardly necessary in an editor with how good Claude Code and others are.But the times I've used the collaboration tooling in Zed have been really excellent. It just sucks it's not getting much attention recently. In particular I'd really like to see some movement on something that works across multiple different editors on this front.I'm glad to hear they're still thinking about these kind of features.reply",
      "The thing that made me go \"oh damn\" was finding out the debugger is multiplayer.reply",
      "I wish Zed would implement support for Jupyter notebooks first. Maybe this sounds like a thing I can contributereply",
      "The choice to go to WebAssembly is an interesting one.WASM3, especially (released just 2 months ago), is really gunning for a more general-purpose \"assembly for everywhere\" status (not just \"compile to web\"), and it looks like it's accomplishing that.I hope they add some POSIXy stuff to it so I can write cross-platform commandline TUI's that do useful things without needing to be recompiled on different OS/chip combos (at the cost of a 10-20% reduction from native compilation- not a critical loss for all but the most important use-cases) and are likely to simply keep working on all future OS/chip combos (assuming you can run the wasm, of course)reply",
      "> I hope they add some POSIXy stuff to itAre you aware of WASI? WASI preview 1 provides a portable POSIXy interfance, while WASI preview 2 is a more complex platform abstraction beast.(Keeping the platform separate from the assembly is normal and good - but having a common denominator platform like POSIX is also useful).reply",
      "i didn't realize the cloud side of an editor had grown to ~70k lines of Rust already\u2026 and this work is laying the foundation for collaborative coding with DeltaDB.BUT it's worth noting that WebAssembly still has some performance overhead compared to native, the article chooses convenience and portability over raw speed, which might be fine for an editor backend.reply",
      "How is Rust + Web Assembly + Cloudflare workers in pricing and performance compared to say deploying Rust-based Docker images on Google Cloud Run or AWS Fargate?reply",
      "Post is a bit sparse on details and seems to be more about the backend than the infra itself. Would be interested to hear more.reply",
      "Been using CF Workers with JavaScript and I absolutely love it.What is performance overhead when comparing rust against wasm?Also think the time for a FOSS alternative is coming. Serverless without, virtually, cold starts is here to stay but being tied to only 1 vendor is problematic.reply",
      "> Also think the time for a FOSS alternative is coming. Serverless without, virtually, cold starts is here to stay but being tied to only 1 vendor is problematic.Supabase Edge Functions runs on the same V8 isolate primitive as Cloudflare Workers and is fully open-source (https://github.com/supabase/edge-runtime). We use the Deno runtime, which supports Node built-in APIs, npm packages, and WebAssembly (WASM) modules.  (disclaimer: I'm the lead for Supabase Edge Functions)reply"
    ],
    "link": "https://maxdeviant.com/posts/2025/head-in-the-zed-cloud/",
    "first_paragraph": "For the past five months I've been leading the efforts to rebuild Zed's cloud infrastructure.Our current backend\u2014known as Collab\u2014has been chugging along since basically the beginning of the company. We use Collab every day to work together on Zed in Zed. However, as Zed continues to grow and attracts more users, we knew that we needed a full reboot of our backend infrastructure to set us up for success for our future endeavors.Enter Zed Cloud.Like Zed itself, Zed Cloud is built in Rust1.This time around there is a slight twist: all of this is running on Cloudflare Workers, with our Rust code being compiled down to WebAssembly (Wasm).One of our goals with this rebuild was to reduce the amount of operational effort it takes to maintain our hosted services, so that we can focus more of our time and energy on building Zed itself.Cloudflare Workers allow us to easily scale up to meet demand without having to fuss over it too much.Additionally, Cloudflare offers an ever-growing amount of man"
  }
]